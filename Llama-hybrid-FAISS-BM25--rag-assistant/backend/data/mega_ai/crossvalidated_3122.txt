[site]: crossvalidated
[post_id]: 3122
[parent_id]: 3117
[tags]: 
According to this paper In the current state-of-the-art, the designer of an RL system typically uses prior knowledge about the task to add a specific set of options to the set of primitive actions available to the agent. Also see section 6.2 Learning Task Hierarchies in the same paper. The first idea that comes to my mind is that if you don't know task hierarchies, you should start with non-hierachial reinforcement learning and trying to discover the structure afterwards or while learning, i.e. you are trying to generalize your model. To me this task looks similar to Bayesian model merging technique for HMM (for example see this thesis )
