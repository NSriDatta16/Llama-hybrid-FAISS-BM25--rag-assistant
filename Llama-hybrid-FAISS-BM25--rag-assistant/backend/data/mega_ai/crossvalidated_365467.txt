[site]: crossvalidated
[post_id]: 365467
[parent_id]: 
[tags]: 
why does data external from training and testing my neural network perform much worse than statistical accuracy?

I've got a problem with my neural network (used to recognize audio signals, an expansion of the UrbanSound dataset problem): when I fit the model the accuracy of both train and validation is near 90%. Then, using some testing data the accuracy drops to 80%. The main problem is that when I try to classify a file recorded by myself, or some audio from video on youtube: the accuracy drops really low, making really bad predictions. I don't understand where the problem could be: I already split the audio in chunks of 1 second (with 80% of overlapping) for training to get similar but different audio samples. I don't use regularization (L1-L2 or dropout) because it worsen the accuracy results my neural network has 132 features as input, 2 layers with 100 neurons each and a final layer with 14 labels, and I'm using Keras to build it I'm fairly new to machine learning and I fear I'm missing something obvious, so I'm up for any advice.
