[site]: crossvalidated
[post_id]: 453153
[parent_id]: 
[tags]: 
Bayesian Nonparametric Latent feature model

For quite a long time I've been trying to understand the paper "Bayesian Nonparametric Latent feature model" (by Zoubin Ghahramani et al.) [ http://mlg.eng.cam.ac.uk/zoubin/papers/GhaGriSol06.pdf] . In a nut shell the following model is described: We have $N$ objects. A matrix $X$ of a size $N \times D$ , where the row $x_i$ of this matrix consists of measurements of $D$ observable properties of the $i$ -th object Each object is represented by a vector of latent features $f_i$ and the properties $x_i$ are generated from a distribution determined by those latent feature model. $F=[f_1^T f_2^T ... f_N^T]^T$ indicates the latent feature values of all $N$ objects. $p(F)$ a prior over features $P(X|F)$ a distribution over observed property matrices conditioned on those features The matrix $F$ can be break into two components: A binary matrix $Z$ indicating which features are possessed by each object, with $z_{ik}=1$ if object $i$ has the feature $k$ and $0$ otherwise. A second matrix $V$ indicating the value of each feature for each object. $F$ is an element-wise product of $Z$ and $V$ . In the paper it is written that if the latent variable $f_i \in \{1, ..., K\}$ and $K$ then this is a description of finite mixture model. A really don't see how. Could someone please clarify this to me
