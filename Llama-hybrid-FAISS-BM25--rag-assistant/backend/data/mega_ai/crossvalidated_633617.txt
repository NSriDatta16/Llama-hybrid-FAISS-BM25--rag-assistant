[site]: crossvalidated
[post_id]: 633617
[parent_id]: 633056
[tags]: 
This seems to be trying to answer the question "if a center had a population that had the average rate for the country, how would the center's rate of events look like". It's making the assumption that any deviation from what is expected would be proportionally the same at all risk levels and that the prediction behind the expected cases is correct (without that relating observed to expected is problematic in the first place, of course - the document mentions those limitations:"[...] risk-adjustment modelling cannot entirely eliminate differences in patient characteristics among centres because not all pre-admission influences are adjusted for [...]"). If it's okay to compare expected vs. observed, then just looking at the ratio (e.g. 2.0 = doubled rate over what is expected, 0.5 = halved rate vs. what is expected) already gives you very similar information. However, you could argue that re-scaling it to a somewhat representative average gives you have idea of what this means in terms of absolute numbers, which could be helpful to e.g. contextualize that a 50% increase in events might be not as bad as it sounds because events are incredibly rare vs. a 5% increase in a common event might mean a much larger increase in the absolute number of events. As the document also points out providing something like confidence intervals is also useful, because for rare events some centers must inevitably (because the event must occur somewhere...) get some imbalances (e.g. 1 observed event when 0.01 was expected = 100 $\times$ increase over what's expected), but this could very easily be chance variation which confidence intervals would highlight. You'd still have the issue that you look at lots of centers and lots of confidence intervals, you would by chance get plenty excluding 1.0 (for the ratio) or the average rate (for the re-scaled number) simply because you look at so many of them.
