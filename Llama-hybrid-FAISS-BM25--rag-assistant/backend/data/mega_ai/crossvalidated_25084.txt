[site]: crossvalidated
[post_id]: 25084
[parent_id]: 25078
[tags]: 
For 2-class problems, you can use the GBM package in R , which will iteratively fit classification trees to the residuals from the loss function. Unfortunately it does not yet support multi-class problems. This seems like a problem that's well suited for boosting, but I don't know of any boosting packages that support k-class problems. I think the problem is writing an appropriate loss function for the multiple classes. The glmnet packages has a multinomial loss function, perhaps you can look through it's source code for some pointers. You could try writing your own boosting algorithm, or you could turn your problem into k binary classification problems (one class vs. all other classes), fit a gbm model to each problem, and average the class probabilities from each model.
