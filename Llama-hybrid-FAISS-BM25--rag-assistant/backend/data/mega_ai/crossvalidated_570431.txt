[site]: crossvalidated
[post_id]: 570431
[parent_id]: 449071
[tags]: 
I stumbled on this question with the same thought process as the OP. The other answers clarify the underlying principles for thinking about linearity in terms of the model parameters and model inputs. But if someone is interested in the solution (or the class of solutions) from neural networks history, similar to what the OP came up with, it falls under the category of Higher-Order Networks, for example, Sigma-Pi , Pi-Sigma etc, explained as an evolution here , where some of these networks use SLP (as the OP wondered).
