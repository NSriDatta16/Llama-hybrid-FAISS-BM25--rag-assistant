[site]: crossvalidated
[post_id]: 347301
[parent_id]: 
[tags]: 
Does maximum likelihood estimation analysis treat model parameters as variables which is contrary to frequentist view?

As far as I understand (strict) Frequentists treat hypothesis (model parameters) as fixed and don't allow to assign probabilities to a range of model parameters. That is the reason why they compute confidence intervals through variation in data, not variation in model parameters. Maximum-likelihood estimation is considered to be frequentist approach. But if you search for best fit parameter value that maximizes likelihood function then you are automatically assigning probabilities to other parameter values (they are not improbable anymore, just less likely than best fit). In other words, you cannot take a derivative of likelihood function $\dfrac{dP(E|H)}{dH} = 0$ because H is fixed in P(E|H) if you are frequentist. So MLE is really just MAP $\dfrac{dP(H|E)}{dH} = 0$ with implicit flat priors. To sum up, in MLE one has to treat model parameters as a variable with different likelihoods given experimental data. Then doesn't it become Bayesian (with implicit flat prior) and stops being frequentist?
