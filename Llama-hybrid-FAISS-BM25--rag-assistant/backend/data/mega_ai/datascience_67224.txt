[site]: datascience
[post_id]: 67224
[parent_id]: 67214
[tags]: 
Variance in a feature (defined as the average of the squared differences from the mean) is important in machine learning because variance impacts the capacity of the model to use that feature. For example, if a feature has no variance (e.g., is not a random variable), the feature has no ability to contribute to task performance. A zero variance feature will be constant for different levels of the target. Additionally, some machine learning models make strong assumptions about the distribution of features. Variance is one way to check for distributional assumptions.
