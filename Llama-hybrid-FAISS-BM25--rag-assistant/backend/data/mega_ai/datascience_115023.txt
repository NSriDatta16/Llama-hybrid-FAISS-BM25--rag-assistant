[site]: datascience
[post_id]: 115023
[parent_id]: 115020
[tags]: 
Assuming you are talking about getting a features impact scores ranking (i.e. sort features by their relevance on model predictions), I would go for a permutation importance methodology. It is a model-agnostic approach which you can use providing an already fit model and a evaluation dataset. The concept is to relate the highest drops in model performance with the most important features, when the values of these ones are shuffled. The process it follows could be defined by the following steps: Make model predictions on a sample of records Select a column, shuffle its values and predict again with the model Get the the drop (if any) of model performance on this new shuffled dataset VS the initial one Average this difference across all predictions Repeat the steps above for all features Scikit-learn provides something like this with its permutation importance functionality , I hope it helps. Other source of info here
