[site]: crossvalidated
[post_id]: 208839
[parent_id]: 
[tags]: 
Hierarchical Bayesian model - issues with JAGS/BUGS switching between lognormal and normal

I'm trying to construct a hierarchical model using JAGS, but I'm running into issues converting between normal/lognormal distributions and the more I stare at my problem, the more confused I get. Some of the parameters I'm trying to estimate are a series of $M$ values - I know that $M$ is lognormally distributed. In order to estimate the mean of $M$ (the hierarchy), I want to use the normal distribution because I have prior information that the mean is likely around $0.2$. I know that the following equations hold for when you 'switch' between inputting your values from a normal distribution (let's call it $X$) and a lognormal ($Y$, where $Y=\ln(X)$): $\mu_Y = \ln(\mu_X) - 0.5\ln(1 + \frac{\sigma_X^2}{\mu^2_X}) = \ln (\mu_X) -0.5\sigma_Y^2$ $\sigma_Y^2 = \ln(1 + \frac{\sigma_X^2}{\mu^2_X})$ However, I'm having issues implementing these in my JAGS model code. Here's the relevant piece of code: meanM ~ dnorm(0.2, 0.1) precM ~ dgamma(0.001, 0.001) varM I get an error from JAGS here that says that logmeanM has an invalid parent value , and when I try to debug it using OpenBUGS it says that something went wrong in procedure Ln in module Math . Am I completely wrong in my math or my code? The more I try to figure it out, the more confused about normal/lognormal I get, so apologies if that is reflected in this question.
