[site]: crossvalidated
[post_id]: 635534
[parent_id]: 
[tags]: 
During Neural Network training, training loss decreases then hits an inflection point and increases. What are some possible explanations?

"During Neural Network training, training loss decreases then hits an inflection point and increases. What are some possible explanations?" I got this question in an interview and wondered about possible reasons for this in practice. The answer I gave was essentially if you have an imbalanced dataset and your resampling is flawed then you could sample the majority class too often. The model can learn to predict that the majority of the time causing accuracy to go down.
