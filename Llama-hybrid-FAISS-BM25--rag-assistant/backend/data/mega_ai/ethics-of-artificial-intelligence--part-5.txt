anguage data, they often present the Anglo-American views as truth, while systematically downplaying non-English perspectives as irrelevant, wrong, or noise. When queried with political ideologies like "What is liberalism?", ChatGPT, as it was trained on English-centric data, describes liberalism from the Anglo-American perspective, emphasizing aspects of human rights and equality, while equally valid aspects like "opposes state intervention in personal and economic life" from the dominant Vietnamese perspective and "limitation of government power" from the prevalent Chinese perspective are absent. Gender bias Large language models often reinforce gender stereotypes, assigning roles and characteristics based on traditional gender norms. For instance, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men, perpetuating gendered expectations and roles. Political bias Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data. Stereotyping Beyond gender and race, these models can reinforce a wide range of stereotypes, including those based on age, nationality, religion, or occupation. This can lead to outputs that unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways. Dominance by tech giants The commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft. Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace. Climate Impacts The largest generative AI models require significant computing resources to train and use. These computing resources are often concentrated in massive data centers. The resulting environmental impacts include greenhouse gas emissions, water consumption, and electronic waste. Despite improved energy efficiency, the energy needs are expected to increase, as AI gets more broadly used. Electricity consumption and carbon footprint These resources are often concentrated in massive data centers, which require demanding amounts of energy, resulting in increased greenhouse gas emissions. A 2023 study suggests that the amount of energy required to train large AI models was equivalent to 626,000 pounds of carbon dioxide or the same as 300 round-trip flights between New York and San Francisco. Water consumption In addition to carbon emissions, these data centers also need water for cooling AI chips. Locally, this can lead to water scarcity and the disruption of ecosystems. Around 2 liters of water is needed per each kilowatt hour of energy used in a data center. Electronic waste Another problem is the resulting electronic waste (or e-waste). This can include hazardous materials and chemicals, such as lead and mercury, resulting in the contamination of soil and water. In order to prevent the environmental effects of AI-related e-waste, better disposal practices and stricter laws may be put in place. Prospective The rising popularity of AI increases the need for data centers and intensifies these problems. There is also a lack of transparency from AI companies about the environmental impacts. Some applications can also indirectly affect the environment. For example, AI advertising can increase consumption of fast fashion, an industry that already produces significant emissions. However, AI can also be used in a positive way by helping to mitigate the environmental damages. Different AI technologies can help monitor emissions and develop algorithms to help companies lower their emissions. Open-source Bill Hibbard argues that because AI will have such a profound effect on humanity, AI developers are representatives of future humanit