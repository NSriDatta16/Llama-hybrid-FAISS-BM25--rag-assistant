[site]: datascience
[post_id]: 26811
[parent_id]: 
[tags]: 
How to find and use the top features for XGBoost?

Suppose I have data with X_train, X_test, y_train, y_test given. As it is a classification problem I want to use XGBoost . The issue is that there are more than 300 features. I have found online that there are ways to find features which are important. But as I have lot of features it's causing an issue. My current code is below. How can I modify it to say select top n ( n = 20) features and use them for training the model. I tried sorting the features based on importance but it doesn't work. import xgboost as xgb gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train,y_train) predictions = gbm.predict(X_test)
