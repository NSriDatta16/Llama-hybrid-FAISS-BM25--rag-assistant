[site]: datascience
[post_id]: 35859
[parent_id]: 33493
[tags]: 
There are many things to consider to have a model in production. The main ones your are asking about are: Functionality Architecture Functionality For your model to be used in production from a web server, you can host an API which exposes your model. For example, you have a Flask Python server running, where you map an endpoint (e.g. GET http:// /prediction/image.jpg ) to the predict() function of your model. Then you mentioned making it a continuous online-learner . Most classifiers will improve with more data if that data is annotated (i.e. labeled), but for that, you need to manually annotate them and re-feed them to your system and retrain your model. If you could automatically confidently label new data, you wouldn't need to improve your system. So, I would say, some manual labor would be required (labeling), but the rest can be automated. You can add more end-points to your web server, where you can upload more training data, and the system re-trains your model, takes care of versioning and re-loads the latest trained model. Architecture Storage You mention pickle files and you are afraid that they are too large on disk. However, nowadays, with cloud solutions, this is often not a problem. You can use Blob-Storage solutions and prices are often very low (e.g. https://azure.microsoft.com/en-us/services/storage/blobs/ will cost $0.002$euros/GB/month). You can, of course, keep many pickles there, for versioning (recommended). However, if you want to minimize costs, you could only store the latest model. Further, if your API is used often, you don't want to keep reloading your model every time. It would be better to have it always available in RAM. It is not expensive, again, to host a server with a lot of RAM in the cloud. Layout An architecture layout you can have is: +----------------+ +--------------+ | | | | | ADMIN SERVER | -------> | BLOB STORAGE | | | | | +----------------+ +--------------+ | ^ | | | +-----------+-----------+ | | | | +------------------+ +----------------+ | | | | | | | PREDICT SERVER | | PREDICT SERVER | | | | | | | +------------------+ +----------------+ | ^ ^ | | | | +------------------+ | | | | | +--------------> | | QUEUE | | | | | | +------------------+ Here, the ADMIN SERVER takes care of all the functionalities of re-training the model and uploading new models to the storage and publishing jobs to the queue for the PREDICT SERVERS to fetch the latest models from BLOB STORAGE . The BLOB STORAGE holds the models. The PREDICT SERVER s expose your predict() funtion, so your model is accessible to other systems. Here, the models are stored in RAM for faster predictions. Depending on the usage of your model, you might want to have $\geq1$ server for predictions. Since you model is persisted on BLOB STORAGE and not on your local hard-disk, this is possible, they can all fetch the latest model. The QUEUE is how the ADMIN SERVER can communicate with all PREDICT SERVER s.
