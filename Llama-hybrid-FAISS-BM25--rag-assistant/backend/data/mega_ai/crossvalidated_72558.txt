[site]: crossvalidated
[post_id]: 72558
[parent_id]: 72520
[tags]: 
I would do the forward stepwise selection, adding predictors as long as the correlation with residuals is significant, and then do some regularization (ridge, lasso, elastic nets). There are 2-3 metaparameters: forward stepwise termination constraint, and 1 or 2 regularization parameters. These metaparameters are determined via cross-validation. If you want to take into account non-linearity, you could try random forest, which produces good results when there are many predictors. But it is slow.
