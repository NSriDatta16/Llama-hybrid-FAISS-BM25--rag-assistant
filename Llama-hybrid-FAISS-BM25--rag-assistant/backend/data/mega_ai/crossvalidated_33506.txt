[site]: crossvalidated
[post_id]: 33506
[parent_id]: 27808
[tags]: 
I am also a chemoinformatician, so I can be wrong, but since there is no any answer, I'll put here my suggestions. Really, I don't see a problem here. The mean of random variables is also a random variable. So, you have to obtain a k x R matrix of *mean_figure_of_merit2D* (each mean is taken from Q *figure_of_merit2D*). Then transform this matrix to a vector like dim(mean_figure_of_merit2D) (You can also go straightly to the vector form in the cross-validation cycle) Obtain *mean_figure_of_merit3D* the same way. And then - as the Bouckaert and Frank's paper stating - x m s t=m/sqrt((1/(k*R)+n2/n1)*s^2 More repetitions (R) are made - then the distribution of t will be closer to Student's t-distribution - more correct p-value will be obtained. BUT even if you'll prove that 3D descriptors are better than 2D (or vice versa ) - this inference has no value, since it concerns the prespecified dataset treated with prespecified algorithm that was run with the prespecified parameters - and thus cannot be extrapolated. I'll better recommend you to combine your descriptors together and thus increase the chance to obtain more predictive model. And one else point: since random forest algorithm is using bagging , you don't need to cross-validate your model - the out-of-bag statistics is unbiased (see http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr ).
