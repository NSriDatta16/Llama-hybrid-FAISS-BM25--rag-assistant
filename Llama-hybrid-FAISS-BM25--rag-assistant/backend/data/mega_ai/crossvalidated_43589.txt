[site]: crossvalidated
[post_id]: 43589
[parent_id]: 43542
[tags]: 
That is a clever idea but any idea that there is a standard approach or even ever will be is misplaced. First of all if its a randomized study and you follow Fisher's argument (for what is called Fishers exact NULL) all parameters in both groups are exactly equal so one is testing for a possible difference in means given exactly the same variances. Many statisticians and some Bayesians (e.g. Don Rubin) accept this as a sensible answer or approach. Otherwise you have a composite NULL for which a fully satisfactory test needs to have the same type one error rate uniformly for all parameter values in the NULL (i.e. a similar test ) and usually that is not possible. In particular, here it is known as the Fisher-Beren's problem which I believe remains an open question - is there a fully satisfactory test of a difference in means with arbitrary variances? There are lots of approximate methods that in differing ways come close, and I would bet one or more is based on a weighted sum of p_values. In the Bayesian approach you run into difficult and confusing prior specifications :-( In general, statistics is "all fully sorted out" only? when there is just one unknown parameter. And the idea that you can include all uncertainties in say the construction of a test (even if you relax the requirement for similarity) or a prior is also I believe miss-placed. Alternatively, this paper argues that you should not expect or want to insure yourself against all uncertainties S Stigler. The changing history of robustness Applying statistics means never being certain about your uncertainty assessments ;-)
