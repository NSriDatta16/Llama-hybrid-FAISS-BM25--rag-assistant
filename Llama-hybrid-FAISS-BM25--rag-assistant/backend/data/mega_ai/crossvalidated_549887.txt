[site]: crossvalidated
[post_id]: 549887
[parent_id]: 549866
[tags]: 
I upgraded your question due to its more general importance in practice. As background, I am in the process of filing an algorithmic patent that asserts the falsity of the following statement for many distributions: Note, however, that any attempt to estimate weights for combinations will introduce additional variance, and the end result may well be worse than if you had used a simple unweighted average. The apparent secret to combining relates quite intuitively, and applies particularly, to small samples where robust methods can suggest new information content that can apparently increase accuracy. As a simple example, consider the mode of a distribution (which equals, or is mathematically related to, the mean) for which one wants an improved mean estimate over the sample mean. As such, a clustering of points in the middle range of the sorted sample (where one would expect the mode) can be quite informative in shifting a combined estimator towards the true mean and away from the sample mean which is easily distorted by outliers and in small unrepresented samples. The process is, however, as expected heavily dependent on the parent distribution and sample size. My comment relates to my analysis that was confirmed over repeated simulations for over a dozen distributions commonly found in applications. Quite simply, it is a question of new robust information content introduced. Adding it improves, and surprisingly, it is not a major issue on how to precisely weigh it, as in the effort of discovering/inventing the new information metric. As to your question, my suggested answer for large data sets that appear relevant to your decision making, just either average (as was suggested) or be selective as to which data set model appears to be more in line with your goals/data going forward. An understanding of the differences in the predictive classifications with respect to information content may also be a path to selecting a single model.
