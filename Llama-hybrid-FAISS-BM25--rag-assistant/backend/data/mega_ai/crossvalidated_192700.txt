[site]: crossvalidated
[post_id]: 192700
[parent_id]: 192451
[tags]: 
Many recent effective CNN structures use small filters that preserve the spatial resolution, for example the VGG network and the 100-layer residual network . I think most importantly having the same input and output size allows for simply stacking up more layers without affecting(decreasing) the spatial resolution, so that we can build deeper networks. Moreover, with such spacial consistency we can, add some operation between the input and output of a set of layers, as in the residual network , Formally, denoting the desired underlying mapping as $H(x)$, we let the stacked nonlinear layers fit another mapping of $F(x) := H(x)âˆ’x$. or concatenate the output from filters of different sizes, as in the inception network .
