[site]: crossvalidated
[post_id]: 548128
[parent_id]: 
[tags]: 
Semi-supervised classification objective from Kingma et al

In this 2014 paper, Kingma et al. develop different methods to do semi-supervised learning with VAEs. In one of their proposed solutions ("M2"), they approach this problem by incorporating the labels (y) as a causal factor in the generative model, s.t. images depend (through a generative model parameterized by a neural network; the decoder of the VAE) on both these labels (e.g. MNIST digit classes) and other latent variables (z). The labels (y) are partially observed: for some items in the data set, we have labels, while for others we don't. The other latents are never observed - discovering them is part of the learning process. They then derive the ELBO loss for a VAE with this generative model. They observe that, for labeled images, this loss does not end up training the encoder network to produce good class labels (since the class labels are given for these cases, the ELBO does depend on the decoder's ability to use these class labels to reconstruct good images, but not on the encoder's ability to generate good class labels). This is undesirable, as it means that the classification part of the network effectively only learns from unlabeled examples. So, they augment their loss function with a classification loss (equation 9), which is basically just the cross-entropy between the class probabilities produced by the encoder, and the true labels, but scaled by a certain factor. They then say the following: While we have obtained this objective function by motivating the need for all model components to learn at all times, the objective 9 can also be derived directly using the variational principle by instead performing inference over the parameters $\pi$ of the categorical distribution, using a symmetric Dirichlet prior over these parameters. And this is where they lose me. I would really like to understand how such a derivation would work, as I assume this also produces the scale factor that they apply to this term in the loss (which otherwise seems like a hyperparameter that would need to be tuned empirically). However, I just don't understand what they mean with this sentence. Specifically, $q_\phi(y|x)$ is a categorical distribution produced by the encoder. Its parameters are just the category probabilities, which they denote by the vector $\pi_\phi(x)$ . Thus, the entries in $\pi$ simply are the probabilities in $q_\phi(y|x)$ . So "performing inference over the parameters $\pi$ ", presumably just means "estimating those numbers", or perhaps "optimizing variational beliefs over those numbers". I just don't see how you get from that idea to a loss term $E_{\tilde{p_l}(\mathbf{x},y)}\left[ -\log q_\phi(y|\mathbf{x}) \right]$ . Can anyone explain this?
