[site]: datascience
[post_id]: 36988
[parent_id]: 36970
[tags]: 
At the basic level, CNNs work by finding spatially-linked correlations i.e. places in the input which often appear close together. For this reason, creating cartesian projections of your data from the polar information sounds like the natural way to go about it. If there is some inherent structure to your raw data, it might be possible to use something like a CNN, but you'd have to think carefully about the architecture. Here are a couple of other thoughts that cross my mind that might help you brainstorm or find related research papers: Casting the polar data into images, as you describe your method, not only increases the dimensions of the data, but usually the sparsity of the data. This makes it very difficult to train something like a CNN, which generally works best for dense chunks of information, such as a photograph. If your data is sparse, you might consider some other pre-processing such as adding blur to the projections. Polar coordinates with a distance metric is essentially the same as a point cloud. If you represent a series as scans, instead of a set of images, but rather as a 3d pointcloud, you could look into models such a PointNet, PointNet++, VoxelNet (see the example projects at the bottom of that linked webpage). There are examples of object detection or segmentation in 3d pointclouds, which might give you other ideas for your case - all available openly in Tensorflow or another DL framework. How well do you understand your data? Perhaps some further exploration or visualisation might help spark some ideas or at least provide a better feeling for approaches that could work. Try plotting the cartesian coordinates of your data (if you can map many frames to a global origin), using something like PyntCloud ( an example ).
