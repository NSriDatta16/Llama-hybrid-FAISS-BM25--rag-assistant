[site]: crossvalidated
[post_id]: 174333
[parent_id]: 
[tags]: 
Can you write a probability based on the relative entropy?

Suppose we have a graphical model $X\rightarrow \Theta \rightarrow D$ where all the distributions are Gaussian Mixture Models. Suppose further that the distribution of $X$ has more components than the distribution of $\Theta$, so information is lost from $X$ to $D$. In this case I observe $D$ and I want to find the marginal distribution of $X$ given $D$. I believe the way to do this is with hierarchical bayesian inference: First Bayes rule: $$ p(X|D) = \frac{p(D|X)p(X)}{p(D)} $$ But here the likelihood function $p(D|X)$ should be considered the marginal likelihood over all values of the latent variable $\Theta$: $$ p(D|X) = \int_\Theta p(D|\Theta,X)p(\Theta|X)d\Theta $$ The first term in that integral should be pretty easy to compute, since $\Theta$ contains the parameters of a GMM: $$ p(D|X,\Theta) = p(D|\Theta) = \prod_i \sum_k \pi_{ik}N(d_i|\mu_k,\Sigma_k) $$ What thing I can't figure out is how to compute $p(\Theta|X)$. Neither of these are observed, so we are talking about the probability of one distribution given another one. I understand that the KL divergence is one way to consider the difference between two PDFs. Can we use $D_{KL}$ as a probability? $$ p(\Theta|X) = \exp \left[-D_{KL}(\Theta||X)\right] $$ where $D_{KL}$ is the K-L divergence. However, this last part is purely based on the intuition that $\Theta$ should have a PDF that looks like that of $X$.
