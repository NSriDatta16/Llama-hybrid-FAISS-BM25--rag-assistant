[site]: crossvalidated
[post_id]: 272743
[parent_id]: 272723
[tags]: 
Does this mean that you have data for each individual each of the twenty years? In that case, you should account for that in the modeling (with time series methods or, maybe, a random effect for each person). Apart from that, sample size here is sufficiently large that the better fit with logit just might be real. If it gives better prediction is more doubtful. My reason for saying so is the following: The logit function approaches its asymptotes much more slowly than the probit. We can take logit coefficients and divide by approximately 1.6 to get probit coefficients, see http://andrewgelman.com/2006/06/06/take_logit_coef/ Then we can make the following plot comparing the two models: I once had a large bioassay dataset where probit fit (marginally) better than logit. In that case the explanation is clear: the probit, going faster close to $0 / 1$ , models better that above certain toxicity level, all the organisms die (and below certain level, there is no toxicity at all). In your case it is the opposite: The covariables can never predict with certainty a default (or not), so the probit gives oversecure predictions, and for that reason the logit is better. With your kind of data I would use the logistic fit for risk calculations in future, even if the probit had happened to fit better under training ! (that of course is a kind of Bayesian thinking, if the data goes against prior information, sometimes it is better to stick to the prior!) Also look at Difference between logit and probit models
