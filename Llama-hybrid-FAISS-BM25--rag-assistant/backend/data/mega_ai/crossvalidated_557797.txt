[site]: crossvalidated
[post_id]: 557797
[parent_id]: 557796
[tags]: 
With most learning algorithms, one can compare the models resulting from applying the algorithm on samples of data by the parameters of the models. This claim is not true in general. There are models with thousands, or millions, of parameters like neural networks where there is no meaningful way of comparing the models based on the parameters. There are nonparametric models with a theoretically infinite number of parameters. In fact, you could meaningfully compare only the simplest models, like small linear models, in terms of parameters. Random forest is a collection of decision trees that do not have parameters per se . You could plot all the trees from one random forest and compare them to another, but this would mean comparing hundreds of trees to each other.
