[site]: datascience
[post_id]: 52867
[parent_id]: 52778
[tags]: 
First, I recommend NOT binning continous variables in any way. The amount of information lost and numerical problems makes it rarely a good decision. This is especially true in your case where you will be sacking a lot of degrees of freedom in your model by binning (which are necessary if you want statistical power, i.e. rejecting the null when you should). If you want to account for non linearities, either use splines or better yet, use an algorithm that doesn't assume a linear relationship between (some function of) y and your predictors. Second, I would be extremely cautious with doing any sort of statistical inference (determining importance/significance of predictors) with machine learning algorithms that primarily (if not fully) were created for predictive, rather than explanatory reasons. In other words, I would stick with logistic regression in this case, since most ML algorithms don't allow for much, if any, proper statistical inference. You are right to consider multicollinearity in this case. Severe collinearity will adversely affect p values and confidence intervals, and make inference hard, if not impossible. But this is why you need to have a hypothesis first as to what could possibly influence your target, to carefully specify your model, and to check the assumptions related to your chosen model (and fix or note any violations). Simply throwing a bunch of predictors into a model won't work here since you actually care about interpreting the model and its statistical output. To be honest, I recommend going to the cross validated SE for more information rather than here, which primarily focuses on predictions, not inference.
