[site]: crossvalidated
[post_id]: 232455
[parent_id]: 180169
[tags]: 
The K-S test compares two probability density functions (see e.g. Wikipedia ). To my knowledge, it is not meant to compare measurements with errors. One way to approach your problem is perhaps to fit an ensemble of PDF models to your data, for instance using a Monte Carlo approach to sample sensible model parameters. This leads to two sets of models, one set for each of your distributions. Then use the K-S test to compare all models in one set to all models in the other set. You can then study the resulting set of K-S statistics, for instance by looking at its distribution, or by just taking the average and variance. This way you are back to one K-S statistic and an error on that value. Whether this is solid statistics, I wouldn't dare to say. Edit: The Wikipedia page also suggests using Monte Carlo: If either the form or the parameters of $F(x)$ are determined from the data $X_i$ the critical values determined in this way are invalid. In such cases, Monte Carlo or other methods may be required, but tables have been prepared for some cases. Details for the required modifications to the test statistic and for the critical values for the normal distribution and the exponential distribution have been published,[5] and later publications also include the Gumbel distribution.[6] The Lilliefors test represents a special case of this for the normal distribution. The logarithm transformation may help to overcome cases where the Kolmogorov test data does not seem to fit the assumption that it came from the normal distribution.
