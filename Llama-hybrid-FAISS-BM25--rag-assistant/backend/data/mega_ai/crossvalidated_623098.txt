[site]: crossvalidated
[post_id]: 623098
[parent_id]: 623047
[tags]: 
Yes, it does make sense. The Bayesian success run theorem is based on the assumption that your observations are independent Bernoulli with parameter $p$ , where $p$ is the probability that a piece is defect-free. Our prior distribution for $p$ is a $\mathrm{Unif}(0,1)$ , which is meant to convey that we have no prior information about the value of $p$ . In this model, examining a sample of $N_A$ pieces then another sample of $N_B$ pieces and finding them all defect-free is the same as examining a sample of $N_A+N_B$ pieces. The lower bound for the reliability is, thus, exactly as you stated it. The key is that (conditional on $p$ ) these are independent Bernoulli trials.
