[site]: crossvalidated
[post_id]: 620951
[parent_id]: 620894
[tags]: 
After some back-and-forth with @Tim and @Sextus Empiricus (thank you both!) I think I have a clearer answer to my question: First let's get notation down: $X_i$ is a random variable. $x_i$ is the realized value of observing/measuring $X_i$ . It is a fixed number. $\mathbf{X} = \{X_1, ..., X_N\}$ is a set of i.i.d random variables. This is a set of random variables. $\pmb{\mathsf{x}} = \{x_1, ..., x_N\}$ is a set or realizations of the random variables $\{X_1, ..., X_n\}$ . This is a set of fixed numbers. It would seem that the following is technically incorrect (as Bishop does): "we have a random variable $X$ and the data $\pmb{\mathsf{x}} = \{x_1, ...,x_n\}$ are $N$ independently drawn observations of the random variable $X$ ". Once a random variable is observed, you cannot observe it again. So, technically speaking, this is does not make true mathematical sense. The technically correct way to denote a fixed dataset (as Bayesians do) is to say: we have a set of realizations $\pmb{\mathsf{x}} = \{x_1, ..., x_N\}$ corresponding to observing the set of i.i.d random variables $\{X_1, ..., X_N\}$ . A potential alternative to denote a fixed dataset (as Bayesian do) is to say: we have a set of values $\{x_1, ..., x_N\}$ that were all independently sampled from the same distribution $p(x)$ . What you'll often see in Frequentist texts is a dataset that is not yet realized (because they treat the dataset as random). Something like: we have a set of data comprised of i.i.d random variables $\{X_1, ..., X_N\}$ . The benefit of this is that we can remark on properties of these data as they were random variables. For example, we can explore the properties of "estimators" which are functions of the random variables.
