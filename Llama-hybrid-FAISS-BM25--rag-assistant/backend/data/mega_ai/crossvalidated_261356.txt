[site]: crossvalidated
[post_id]: 261356
[parent_id]: 
[tags]: 
Understanding the Proof for why Jeffreys' prior is invariant

I was reviewing the section of Andrew Gelman's "Bayesian Data Analysis" on uninformative priors, and came across this explanation for why Jeffreys' prior is invariant to parameterization. My question is simply how Gelman reasoned from the first line of the equation to the second. EDIT: So using the chain rule, is this the correct reasoning? If we take $\theta(\phi)$ as a function of $\phi$ , then $$ \frac{d^2\log p(y \mid \phi)}{d\phi^2} = \frac{d}{d\phi} \left( \frac{d \log p(y\mid\theta(\phi))}{d \theta} \frac{d\theta}{d\phi} \right) = \frac{d^2 \log p(y\mid\theta(\phi))}{d \theta^2} \left|\frac{d\theta}{d\phi} \right|^2 $$
