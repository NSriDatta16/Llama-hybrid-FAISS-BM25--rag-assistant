[site]: crossvalidated
[post_id]: 87422
[parent_id]: 3931
[tags]: 
Variance is simply defined as the average of the squared deviations from the mean. Accordingly, we should calculate the variance using the following formulas: Variance of the population: $\sigma^2= \frac{\sum_{i}^{N}(X_i-\mu)^2}{N}$ where $\mu$ is the mean and $N$ is the size of the population. Variance of a sample (e.g. sample $t$ ): $\sigma^2_t= \frac{\sum_{i}^{n}(X_i-\overline{X})^2}{n}$ where $\overline{X}$ is the mean and $n$ is the size of this small sample. However, we select a sample not just to describe a small part, but to make inferences about the whole population. We try to estimate the population variance only by using the values from the sample. For inference, we define sample variance as an estimator of the population variance. The aim and the formula of the good sample variance $S^2$ is different from those of the useless variance of a sample $\sigma^2_t$ . We will try to derive a formula for sample variance . We have two random variables, the trait $X$ and the sample mean $\overline{X}$ . Sample mean is a random variable because it gets different values from sample to sample. The mean and variance of it can be derived easily: $E(\overline{X}) =E(\frac{1}{n}\sum_{i}^{n}X_i) =\frac{1}{n}E(\sum_{i}^{n}X_i) =\frac{1}{n}\sum_{i}^{n}E(X_i) =\frac{1}{n}n\mu=\mu$ $Var(\overline{X}) =Var(\frac{1}{n}\sum_{i}^{n}X_i) =\frac{1}{n^2}Var(\sum_{i}^{n}X_i) =\frac{1}{n^2}\sum_{i}^{n}Var(X_i) =\frac{1}{n^2}n\sigma^2=\frac{\sigma^2}{n}$ As a trivial note, the deviations of individual observations from the sample mean looks larger than the deviations of sample means from the population mean (i.e. $\sigma^2_t > \frac{\sigma^2}{n}$ ). It makes sense because taking average smooths extreme values of individual observations. To make inference about the population variance, note that the deviatons of $X$ from $\mu$ involves two kinds of deviations. First, within a sample, the random variable $X$ deviates from sample mean $\overline{X}$ with variance $\sigma^2_t$ . Second, between samples, the random variable $\overline{X}$ also deviates from $\mu$ with variance $\frac{\sigma^2}{n}$ . Intiutively, we can add up within sample and between samples variances and get $\sigma^2=\sigma^2_t+\frac{\sigma^2}{n}$ . After solving for the population variance, we get $\sigma^2=\sigma^2_t \times\frac{n}{n-1}$ . Note that, this is not a formal definition of population variance. Although we can't calculate the population variance using sample observations, we just derived the formula for its estimator, the so-called sample variance . $S^2=\sigma^2_t \times\frac{n}{n-1} =\frac{\sum_{i}^{n}(X_i-\overline{X})^2}{n-1}$ . If adding up two kind of variances doesn't make sense, one can also prove that $E[S^2]=\sigma^2$ is true. Most of the confusion about the division by $n-1$ comes from the misconception that the sample variance $S^2$ is the same thing as the variance of sample $\sigma^2_t$ . This answer tries to distinguish them and give intiutive proof for sample variance.
