[site]: crossvalidated
[post_id]: 193350
[parent_id]: 94896
[tags]: 
If you write Bayes theorem as $$ p(C|X) = \frac{ p(X|C)p(C) }{ p(X) } $$ then $p(C|X)$ is posterior distribution, $p(X|C)$ is likelihood and $p(C)$ is prior , while $p(X)$ is normalizing constant. In fact, $p(X)$ is $$ p(X) = \int p(X|C)p(C) dC $$ and is used so that we obtain results in probability scale . However in fact if you use MCMC simulation for estimation, it is not needed and the formula reduces to $$ p(C|X) \propto p(X|C)p(C) $$ As already mentioned by others, there is no reason to be interested in $p(C)/p(X)$ because normalizing our prior probability, i.e. our guess that we made before seeing the data, leads nowhere. I guess this is why it has no name.
