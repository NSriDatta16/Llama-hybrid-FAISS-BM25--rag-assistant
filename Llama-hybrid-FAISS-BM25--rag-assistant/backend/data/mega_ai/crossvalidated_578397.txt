[site]: crossvalidated
[post_id]: 578397
[parent_id]: 
[tags]: 
Expected Number of Transitions for a Markov Chain to Reach a Certain State

I am trying to find out the number of times a die needs to be rolled before observing a 4 followed by a 6. I would like to model this problem using a discrete time Markov chain with 3 states: State 1: Start State 2: Rolling a 4 State 3: Rolling a 6 Immediately after Rolling a 4 (Absorbing State) I recognize that : State 1 has a 5/6 probability of going to State 1, and State 1 has a 1/6 probability of going to State 2 State 2 has a 4/6 probability of going to State 1, State 2 has a 4/6 probability of going to State 2 and State 2 has a 1/6 probability of going to State 3 State 3 has a probability of 1 of going to State 3 Using the R programming language. I wrote a small simulation to demonstrate which state the Markov chain is likely to be in after each step: library(expm) library(ggplot2) library(reshape2) mat1.data I plotted the graph below: My Question: Its clear to see that as the number of iterations ("steps") go on, we are more and more likely to a roll a 4 followed by a 6 â€“ but is there some way we can determine the "average number of times we need to roll a die before observing a 4 followed by a 6"? I tried to set up a Markov chain to try and find "number of rolls" needed before observing a 4 followed by a 6, but I can't seem to figure this out. Can someone please show me how to mathematically determine the average number of rolls needed before observing a 4 followed by a 6?
