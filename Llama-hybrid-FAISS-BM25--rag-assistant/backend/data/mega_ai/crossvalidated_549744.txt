[site]: crossvalidated
[post_id]: 549744
[parent_id]: 549700
[tags]: 
Ok if you have not assigned the stimulus at random then you can still model the problem using a Multinomial distribution: $y_{i}âˆ¼Multinomial()$ where $y_{i}$ is the vector of outcomes each time the particpant chooses one of the {a,b,c,d}. For example, in your example dataset $y_{1} = [1,0,0,0]$ where the partcipant chose "a" getting 1 and the other elements zero. Then we can model the probability of participant $i$ choosing $j$ as: $ \theta_{i,j}=\frac{e^{\beta X_{i} }}{\sum_{j} e^{\beta X_{i} }} $ Where $X_{i}$ is the vector of stimulus and $\beta$ is its effect. For example, if you give the 1st participant "b" as the stimuli then you have $X_{1} = [0,1,0,0]$ . You can fit this model and estimate the $\beta$ to see if it's zero meaning no effect by the stimulus on the choices or a significant effect. You can fit this model in R Stan using a Bayesian framework like this: rm(list = ls()) library(tidyverse) library(rstan) #Simulating 200 observations n = 200 #Creating the stimulus matrix which is unbalanced stimuli_matrix = matrix(NA, ncol = 4, nrow = n) set.seed(123) for(i in 1:n){ samp = rmultinom(1, 1, prob = c(0,0.5,0.5,0)) stimuli_matrix[i,] = as.vector(samp) } colnames(stimuli_matrix) % select(Y.A, Y.B, Y.C, Y.D) %>% as.matrix(), X = df[,5:8] ) stan_run In this example that I created, the stimuli has a significant effect on the choices and it's correctly estimated by the model: print(stan_run, pars = "beta") > print(stan_run, pars = "beta") Inference for Stan model: cde133b8626006f7ba99d226760af33f. 4 chains, each with iter=2000; warmup=1000; thin=1; post-warmup draws per chain=1000, total post-warmup draws=4000. mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat beta 5.06 0.02 0.71 3.81 4.56 5.01 5.51 6.59 2240 1 Samples were drawn using NUTS(diag_e) at Mon Oct 25 23:25:03 2021. For each parameter, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat=1).
