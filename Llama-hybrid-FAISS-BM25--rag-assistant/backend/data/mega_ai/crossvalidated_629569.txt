[site]: crossvalidated
[post_id]: 629569
[parent_id]: 
[tags]: 
How to interpret a regression discontinuity analysis?

I am attempting to conduct a regression discontinuity analysis in Python and I'm struggling with understanding the results. I don't pretend to be a statistician and I'm hoping you helpful experts can lend me a hand. Perhaps I'm not even using the correct testing framework. Context : I have an app that I want to determine if it has a positive impact on improving a metric (or any statistically significant impact for that matter). Let's say the metric is a sleep score that can be 0 to 100%, but is usually between 50% and 100% (see the chart below and the following code snippet for dummy data). I have data from 90 days prior to using the app, and 90 days after using the app, and the threshold day occurs on day 90 (0-180 total). Note that this analysis is for n=1 (just my own data). Questions: What can I claim based on the results below? The pre-treatment coefficient is -5.83 and the p-value is 0.001. Is it accurate to say that "the treatment had a statistically significant positive impact on my sleep score", since pre-treatment sleep score is estimated to be 5.83 points lower than post-treatment? Or "Using the app helped improve my sleep score compared to when I was not using the app"? Or is there a better way to summarize the results? What do I make of the R-squared score of 0.059? That implies that the model does not explain much of the variability in sleep score. Combined with the statistically significant p-value, does this suggest that there is a relationship, but the effect size is just very small? If I want to extend this analysis to say, thousands of users, what is the best way to do that? Do I gather all of the data, compute a global average sleep score per day pre and post treatment, and then do one analysis like I've done here? Or do I somehow average the results of thousands of analyses? Any help or advice would be greatly appreciated, thank you so much. # create df with dummy data dft = pd.DataFrame({'date': pd.date_range(start='2022-01-01', end='2022-06-29'), 'metric': (np.random.randint(50, 100) if i OLS Regression Results ============================================================================== Dep. Variable: metric R-squared: 0.059 Model: OLS Adj. R-squared: 0.053 Method: Least Squares F-statistic: 11.06 Date: Tue, 24 Oct 2023 Prob (F-statistic): 0.00107 Time: 16:56:17 Log-Likelihood: -698.11 No. Observations: 180 AIC: 1400. Df Residuals: 178 BIC: 1407. Df Model: 1 Covariance Type: nonrobust ==================================================================================== coef std err t P>|t| [0.025 0.975] ------------------------------------------------------------------------------------ Intercept 80.1667 1.240 64.648 0.000 77.720 82.614 treatment[T.pre] -5.8333 1.754 -3.326 0.001 -9.294 -2.373 ============================================================================== Omnibus: 8.285 Durbin-Watson: 1.936 Prob(Omnibus): 0.016 Jarque-Bera (JB): 3.861 Skew: 0.010 Prob(JB): 0.145 Kurtosis: 2.283 Cond. No. 2.62 ==============================================================================
