[site]: crossvalidated
[post_id]: 100136
[parent_id]: 100121
[tags]: 
1) You could think about this method as a random walk approach. When the proposal distribution $x \mid x^t \sim N( x^t, \sigma^2)$, it is commonly referred to as the Metropolis Algorithm. If $\sigma^2$ is too small, you will have a high acceptance rate and very slowly explore the target distribution. In fact, if $\sigma^2$ is too small and the distribution is multi-modal, the sampler may get stuck in a particular mode and won't be able to fully explore the target distribution. On the other hand, if $\sigma^2$ is too large, the acceptance rate will be too low. Since you have three dimensions, your proposal distribution would have a covariance matrix $\Sigma$ which will likely require different variances and covariances for each dimension. Choosing an appropriate $\Sigma$ may be difficult. 2) If your proposal distribution is always $N(\mu, \sigma^2)$, then this is the independent Metropolis-Hastings algorithm since your proposal distribution does not depend on your current sample. This method works best if your proposal distribution is a good approximation of the target distribution you wish to sample from. You are correct that choosing a good normal approximation can be difficult. Neither method's success should depend on the starting value of the sampler. No matter where you start, the Markov chain should eventually converge to the target distribution. To check convergence, you could run several chains from different starting points and perform a convergence diagnostic such as the Gelman-Rubin convergence diagnostic.
