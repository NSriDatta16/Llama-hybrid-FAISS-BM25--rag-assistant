[site]: crossvalidated
[post_id]: 304946
[parent_id]: 
[tags]: 
Correct way of making a ROC curve out of n times k-fold cross-validation predictions

I wish to plot ROC curves ("ROCR" R package) of cross-validation probability predictions to compare different models obtained with Adaboost boosted tree algorithms ("gbm" R package). For instance, I wish to perform a 10 times 10-fold cross validation for a dataset with 1000 cases. For each time, each case will have it's value predicted once, resulting in 10 folds of 100 predictions for each repetition, 1000 in total. In this manner I'll obtain 10 times 10 folds of 100 predictions, 10,000 predictions in total. Is it correct for me to just join all predictions in one 10,000 dataset, compare it to the correct classification and make a single ROC curve out of it? Or should I somehow average the predictions for each fold each time and make a ROC curve out of 1000 average predictions? Should I compare the models using the same folds? Is there any additional statistic that I should report and plot in this case to help decide which model performs better? Please provide code examples in R if possible.
