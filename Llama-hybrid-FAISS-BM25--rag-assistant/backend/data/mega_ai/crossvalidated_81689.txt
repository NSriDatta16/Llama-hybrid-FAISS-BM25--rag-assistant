[site]: crossvalidated
[post_id]: 81689
[parent_id]: 81684
[tags]: 
"An experience that I know should produce precisely a certain result" sounds like knowledge about the effect size (or "strength"; see also effect-size here on CV) of the cause-effect relationship. If you want to collect evidence that might falsify the null hypothesis (see also hypothesis-testing ), according to which: $H_0:$ effect size of cause-effect relationship $=0$ (i.e., no cause-effect relationship) And you want to know how much data (i.e., how many observations) you'd need to collect to stand a fair chance of rejecting the null hypothesis, your question concerns power (see also the tags I added to your question), so you should look into performing a power analysis that's right for your purposes (which you may want to specify, if you have any in mind). If you know what the strength of the relationship (effect size) should be in the population , you can figure out how many observations you'd need to collect to falsify the null hypothesis, or to fit confidence intervals (see also confidence-interval ) to your effect size estimate that don't include zero. If you have higher requirements for the validity of your effect size estimate than that it be on the right side of zero (e.g., a negative correlation for an inversely proportional relationship ), you may want to narrow your confidence intervals further than that, or increase your confidence level. These are slightly distinct (but directly related) issues: How wide is the margin of error (confidence interval, basically) around your estimate? How sure are you that your margins of error include the real parameter ? These are issues for you to decide as aspects of your statistical goal before you start collecting data, or at least before you stop collecting and before you start analyzing it, if you're genuinely concerned about interpreting your $p$ value in terms of an $\alpha$ (Type I / false alarm) error rate that you want to accept in advance for rejecting a null hypothesis (see Wagenmakers, 2007 ). If you just have some sense of how narrow you want your margin of error around your estimate to be, or how confident you want to be that your margin of error will end up overlapping with the real parameter, you can use power analysis to figure out how much data you need to collect to reach those goals, and you don't necessarily have to do this before analyzing your data. You may also want to read Geoff Cumming's spot in the APA Education Directorate: http://www.apa.org/education/ce/confidence-intervals.pdf ‎. And then there are Bayesian methods (see also bayesian , among other tags here on CV)...I'll let someone else cover those if they care to. (+1 for anyone who does from this guy right here!) Reference Wagenmakers, E. J. (2007). A practical solution to the pervasive problems of $p$ values. Psychonomic Bulletin & Review, 14 (5), 779–804.
