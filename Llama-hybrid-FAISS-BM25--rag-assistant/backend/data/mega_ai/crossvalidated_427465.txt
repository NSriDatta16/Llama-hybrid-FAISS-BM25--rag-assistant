[site]: crossvalidated
[post_id]: 427465
[parent_id]: 283512
[tags]: 
Is 50/50 an appropiate split? Depending on what you want to achieve with that split it may or may not be appropriate. How many times should I repeat this? Sufficiently often, so that all cases have been tested and you have either a sufficient number of surrogate models to show they are stable, or all cases have been tested at least 3 times, so that you can show the predictions are stable. If models/predictions are not stable, further increase the repetitions until model stability is not the concern for your performance estimate any more. If I do repeat it more than once, does it become just as "good" as stronger methods, such as k-fold cv? It will stay more biased (compared to the performance of the model trained on the whole data set) as fewer cases are available for training. If you want to use the model you actually tested, you'll have to decide which of the many models you calculated. And those models will probably on average be worse than the model trained on the whole data set (again as fewer training cases are available). If you do sufficient repetitions as suggested above, the random uncertainty of the performance estimate will be as good as with any other resampling technique done properly.
