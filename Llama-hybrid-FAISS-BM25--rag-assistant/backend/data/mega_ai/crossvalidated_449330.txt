[site]: crossvalidated
[post_id]: 449330
[parent_id]: 448197
[tags]: 
I cannot guarantee that this is a ''standard approach''. However, in my opinion it is a sensible way of modeling this. First approach: Model annual log returns directly You could, in principle, take your 10-20 data points and fit a distribution to them. I would suggest a Bayesian model as this will give you a nice way to quantify the uncertainty arising from few available observations. However, in my opinion, there's no need to throw away so many data points (in case they are available). Note that the annual log return is just the sum over the daily log returns within that year. Hence, you could also opt for a Second approach: Model daily log returns and infer annual log returns Using the fact that the sum over the daily log returns gives you the annual log return, it is a better way forward to directly model daily log returns. Hence, you want to fit a distribution to the daily log returns. Many people will choose a normal distribution. However, it has been shown that financial returns often exhibit fatter tails. Hence, I would suggest a t-distribution or a Laplace-Distribution . You can either directly estimate the moments of these distributions or assume a zero mean (which will be a sensible thing to do for most daily asset returns time series) and only estimate the remaining moments of these distributions (i.e. variances). You can then simply take 365 samples from your fitted distribution of log returns, add them up and this will be equal to one draw from your annual return distribution. Note that all of the above assumes that there is no time dependence between today and tomorrow. As stated above, in my opinion a zero mean assumption for log returns won't hurt too bad. However, in case you want to do a full and proper time series analysis, you could for instance fit an ARIMA model to the log returns after choosing a proper ARIMA structure using model selection criteria and simulate 365 data points from this model. Again, adding them up will give you your annual log return. However, if you assume normally distributed errors, the tails of the errors will likely be too thin to properly capture volatility in financial return data. Depending on how far you want to take this, you could also opt for more complicated models. At least in a Bayesian setting it's not too much of a hassle to fit e.g. an $AR(p)$ process with t-distributed errors to combine the benefits of time series analysis and fat tailed distributions. It all basically boils down to why you need to model these returns and how much effort you want to put in the model. I hope that the points I mentioned help you find a good solution for you.
