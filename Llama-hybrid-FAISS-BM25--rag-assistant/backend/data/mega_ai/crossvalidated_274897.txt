[site]: crossvalidated
[post_id]: 274897
[parent_id]: 
[tags]: 
Using Shape Context to classify OpenCV contours with KNN

I have a set of 2D polygons represented as OpenCV contours that I would like to use to train a KNN classifier on using shape context. I am using the OpenCV python "cv2.createShapeContextDistanceExtractor" as the custom metric for the KNN classifier from sklearn. The issue I am having is that the shapes can't be represented in the form that the KNN expects, which are numpy arrays of dim I thought about possibly putting all the points into a 1D numpy array such that the x,y coordinate of each point are next to eachother. Then the custom metric function will parse them back into contour form to be inputted into the shape context extractor provided by OpenCV. However, this doesn't deal with issue of the input vectors not having the same size. Is there a better method for dealing with these issues? I thought about using an SVM and training it on the shape context of each input contour. However, it seems OpenCV can only compute the distance between the shape context of two contours.
