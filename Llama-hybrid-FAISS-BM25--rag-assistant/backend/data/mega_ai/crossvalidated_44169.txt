[site]: crossvalidated
[post_id]: 44169
[parent_id]: 
[tags]: 
Experimental Design for Comparative Responses

Suppose I were looking to optimize the amount of certain spices in a chili spice recipe. The textbook experimental design would have me encode the amount of each spice in the design variable, choose some kind of design matrix, cook up a pot of chili for each row of the design matrix (one would have to take some shortcuts in the kitchen!), and assign a numeric dependent variable for each choice of the design variables. This latter operation is tricky for something like chili (or my real application, which is a secret); more likely a taste-tester could taste two different recipes and determine which is better, but assigning a numeric score is subject to all kinds of problems (drift over time, etc). So I have a two part question, and they are intertwined: Given the results of a number of such comparisons, how should one pick the optimal vector of design variables? (As a first pass, I might look into "Noisy Sorting" , but something less fancy, based on logistic regression, say, might be a better choice.) Once the evaluation method has been chosen, how should I design the experiment?
