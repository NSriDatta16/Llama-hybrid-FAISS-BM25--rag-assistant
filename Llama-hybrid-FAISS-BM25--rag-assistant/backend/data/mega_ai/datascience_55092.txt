[site]: datascience
[post_id]: 55092
[parent_id]: 
[tags]: 
Pytorch convolution input reshaping

I am new to CNNs, and I'm trying to follow along with a Pytorch DCGAN tutorial by reimplementing it in Keras. Clearly there are some differences in the frameworks, but in particular I am struggling to understand how the input noise vector is handled per the following image of the generator architecture: The code goes on to define the first layer of the network as: # input is Z, going into a convolution nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False), nn.BatchNorm2d(ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4 Where nz = 100 (size of noise vector) and ngf = 64. How does that work? Is the noise vector implicitly reshaped by that first convolutional layer to a (?, 4, 4) tensor, as suggested by the diagram? How would that even work? Is there an implicit dense connection between the noise vector and the convolutional layer? How does that first layer result in a tensor of shape (64*8, 4, 4) per the comment?
