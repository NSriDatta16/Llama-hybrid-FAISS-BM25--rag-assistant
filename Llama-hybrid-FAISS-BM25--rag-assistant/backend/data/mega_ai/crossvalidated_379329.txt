[site]: crossvalidated
[post_id]: 379329
[parent_id]: 379319
[tags]: 
In order to have a measure of the perfomance of our model $f(x)$ on approximating the map $x \rightarrow y$ , we define an error (cost) function that measures the distance between our target $y$ and our estimate $\hat{y} = f(x)$ which we desire to minimize. An usual error term choice is the mean squared error MSE, which is the squared (direction insensitive) residuals, averaged over all sampled data pairs $(x_i,y_i), i=1,...,N$ . This average is our approximation of the expected value of this residuals and can be written $\mathbb{E}[(y - f(x))^2]$ . The values of $f(x)$ will follow a distribution, governed by the inputs $x_i$ , and other factors such as model choice, parameterization and so on. We can compare the performance of this model against a 'perfect' model $y = f(x) + \epsilon$ . Having defined this perfect model $f(x)$ , we call our model an estimate of this, thus now called $\hat{f}(x)$ and used in you equations.
