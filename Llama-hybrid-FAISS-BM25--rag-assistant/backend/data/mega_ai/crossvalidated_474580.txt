[site]: crossvalidated
[post_id]: 474580
[parent_id]: 157741
[tags]: 
In such a case, you may have a biased estimator since data will be imbalanced as you mentioned. But this is ok as long as you are aware to the different mis-classification errors (and their costs) and their interpretations. All errors cost the same? Yet, the question of whether to take care of the bias and how - depends on the interpretation of the final model. If you want to remove the bias during training , this is not different than an imbalanced binary classifier. You can use proper overfitting and balancing strategies such as under/over-sampling, or setting sample/class weight to the estimator. More important, one should also use the appropriate performance metrics to validate the model and investigate the misclassifications properly; balanced accuracy score, ROC AUC scores for each class ("one-vs-one"/"one-vs-all" and averaging by taking the support into account), plot AUCs for each class (TPR vs FPR, and precision-recall curves), and plot confusion matrix for each class. Although you're using "one-vs-all" strategy, validating the model as "one-vs-one" metrics will provide you additional validation on different biases.
