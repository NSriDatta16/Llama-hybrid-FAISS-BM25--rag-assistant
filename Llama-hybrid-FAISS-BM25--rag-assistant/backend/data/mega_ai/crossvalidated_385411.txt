[site]: crossvalidated
[post_id]: 385411
[parent_id]: 385407
[tags]: 
To quote from Meyn & Tweedie's Markov Chains & Stochastic Stability , on page 175, a state $\alpha$ is recurrent for a Markov chain $(\Phi_t)_t$ if $\mathbb{E_\alpha}[\eta_\alpha]=\infty$ (infinite expected number of visits) and transient if $\mathbb{E_\alpha}[\eta_\alpha] (finite expected number of visits), when $$\eta_\alpha=\sum_{t=1}^\infty \mathbb{I}_\alpha(\Phi_t)$$ is the number of visits. This definition does not involve nullity or positivity. To further quote from Meyn & Tweedie's Markov Chains & Stochastic Stability , on page 453, a state $\alpha$ is null if $$\lim_{t \to \infty} P^t(\alpha,\alpha) = 0$$ and positive if $$\lim\sup_{t \to \infty} P^t(\alpha,\alpha) > 0$$ If a state $\alpha$ is transient then it is necessary null, while if a state $\alpha$ is positive, it is necessary recurrent . An important result (see Theorems 10.0.1 & 10.4.9 in Meyn & Tweedie's Markov Chains & Stochastic Stability ) is that an irreducible recurrent Markov chain $(\Phi_t)_t$ admits a unique (up to multiplicative constants) invariant measure. When the measure is finite the chain is necessarily positive recurrent, while in the opposite case, it is null recurrent.
