[site]: crossvalidated
[post_id]: 614268
[parent_id]: 
[tags]: 
Making a decision tree with numeric data

Working with decision tree and I have couple of questions: Should I always do random forest before or I can just do the decision tree, skip the random forest part? Should I always have a training data set and test set? Or, I can run the model just on the orginal data? What method is suitable if you don't have any factors in the data set all are numeric? Root node error: here we have 101653/118 = 861.46, seemse a lot? Is it now overfitted? Possible solutsions? Added the code and giving background on my data: ob.prcnt is value % of eaten insects in specific place I also have 11 variables that are all specific percentage of habitat in sampling place. I would like to see how these habitat amounts affect the insects eaten %. A good guide on decision tree and how to do them in R is appreciated! > fit.tree14 #fit.tree14 > #summary(fit.tree14) > rpart.plot(fit.tree14, extra=1, type=2, digits=3, + clip.right.labs=TRUE, under=TRUE, + branch=1, tweak = 1.1, gap=6, space=1) #, main = "2015", cex.main = 1.5) > > #rpart.rules(fit.tree) > printcp(fit.tree14) Regression tree: rpart(formula = ob.prcnt ~ ., data = P14_Q1) Variables actually used in tree construction: [1] Agricultural.land.excluding.permanent.grassland Semi.natural.habitat [3] Woody.linear Root node error: 101653/118 = 861.46 n= 118 CP nsplit rel error xerror xstd 1 0.096492 0 1.00000 1.0270 0.12096 2 0.015656 2 0.80702 0.9749 0.12522 3 0.011298 4 0.77570 1.0441 0.13470 4 0.010000 5 0.76440 1.0522 0.13746
