[site]: crossvalidated
[post_id]: 294937
[parent_id]: 
[tags]: 
Recursive feature elimination (rfe) performs poorly with binary outcome

Backward elimination with random forests does not work as expected in a simple test case with binary outcome and three continuous predictors. Below, I generate a binary outcome based on a single predictor, X2. The other two predictors, X1 and X3 are noise. I then use backward elimination via the rfe function in caret with random forests via package randomForest. The rfe algorithm consistently fails to isolate X2 as the only important predictor. Of course, glm has no problem getting it right because the model is correctly specified. But given the importance rankings from randomForest, which clearly favor X2, I was expecting better accuracy from rfe. Any ideas for how to improve performance with rfe? library(caret) library(randomForest) rfDGP It's not the seed. I've tried 1, 12, 123, 1234, and 12345 and none gets it right. It's also not the use of "Accuracy". I've used "Kappa", and "ROC" and neither helps (see below). (out_kap
