[site]: crossvalidated
[post_id]: 336556
[parent_id]: 336442
[tags]: 
Generally not, but potentially yes under misspecification. The issue you are looking for is called admissibility. A decision is admissible if there is no less risky way to calculate it. All Bayesian solutions are admissible and non-Bayesian solutions are admissible to the extent that they either match a Bayesian solution in every sample or at the limit. An admissible Frequentist or Bayesian solution will always beat an ML solution unless it is also admissible. With that said, there are some practical remarks that make this statement true but vacuous. First, the prior for the Bayesian option has to be your real prior and not some prior distribution used to make an editor at a journal happy. Second, many Frequentist solutions are inadmissible and a shrinkage estimator should have been used instead of the standard solution. A lot of people are unaware of Stein's lemma and its implications for out of sample error. Finally, ML can be a bit more robust, in many cases, to misspecification error. When you move into decision trees and their cousins the forests, you are not using a similar methodology unless you are also using something similar to a Bayes net. A graph solution contains a substantial amount of implicit information in it, particularly a directed graph. Whenever you add information to a probabilistic or statistical process you reduce the variability of the outcome and change what would be considered admissible. If you look at machine learning from a composition of functions perspective, it just becomes a statistical solution but using approximations to make the solution tractable. For Bayesian solutions, MCMC saves unbelievable amounts of time as does gradient descent for many ML problems. If you either had to construct an exact posterior to integrate or use brute force on many ML problems, the solar system would have died its heat death before you got an answer. My guess is that you have a misspecified model for those using statistics, or inappropriate statistics. I taught a lecture where I proved newborns will float out windows if not appropriately swaddled and where a Bayesian method so radically outperformed a Frequentist method on a multinomial choice that the Frequentist method broke even, in expectation, while the Bayesian method doubled the participants' money. Now I abused statistics in the former and took advantage of the inadmissibility of the Frequentist estimator in the latter, but a naive user of statistics could easily do what I did. I just made them extreme to make the examples obvious, but I used absolutely real data. Random forests are consistent estimators and they seem to resemble certain Bayesian processes. Because of the linkage to kernel estimators, they may be quite close. If you see a material difference in performance between solution types, then there is something in the underlying problem that you are misunderstanding and if the problem holds any importance, then you really need to look for the source of the difference as it may also be the case that all models are misspecified.
