[site]: crossvalidated
[post_id]: 630063
[parent_id]: 
[tags]: 
How do i prioritize which features to use in my machine learning model before the feature engineering stage?

I am encountering a probably fairly common problem where I have too many features, lets say 500 possible features. I only want to pick the top 10-50 features that would be the most predictive of y, or eliminate as many of them as I can before I do preprocessing. The reason for this is that I have 10 million rows, and a sns.pairplot() would obviously take forever. What are the comprehensive list of things I could do to exclude unimportant features, sorted from least computationally expensive to most computationally expensive? This is specifically for before the modeling portion, we're not talking about .feature_importance__ after a model has already been built. Eg. Highest correlated X's vs. y Highest dispersion/variance within X Use Lasso/Ridge (computationally expensive) Recursive Feature Addition (what else?)
