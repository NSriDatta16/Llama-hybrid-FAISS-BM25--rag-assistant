[site]: crossvalidated
[post_id]: 441365
[parent_id]: 441350
[tags]: 
If they are independent, identically distributed (IID) normal random variables, you simple add the means from period to period, and the stdev is the square root of the sum of the squares of the stdevs of each observation. So, if you have 1 week of "typical" data, a year's worth of prediction is 52 times the mean, but only about 7 times the weekly stdev (actually square root of 52, but 52 is very close being the square root of 49). The reason is that, for a normal distribution, we often talk about the mean an standard deviation. stdev is easier to visualize, but the real parameters for a normal distribution is the mean (average, which sums) and variance, which is sigma-squared where "sigma" is the stdev. If your example is for real, though, I would worry about seasonality, which could make a big difference in your thinking.
