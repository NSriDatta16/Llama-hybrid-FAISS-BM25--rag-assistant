[site]: crossvalidated
[post_id]: 535561
[parent_id]: 
[tags]: 
How can we attribute observations to observers in a hierarchical Bayesian model?

I am trying to make a hierarchical Bayesian model of latent variables based on many observations by noisy oracles. I want to leverage the information of which observations are from which oracles, as I expect each oracle to be somewhat internally consistent. However, as I try to express these observations to a model using PyMC3, I can’t figure out how to do so without creating a very sparse set of observations with mostly null values. More specifically, I have several dozen cookie recipes that I would like to infer the latent quality of. Each recipe has been implemented one or more times to create batches, and each batch has been tasted by 100 people. Each time a cookie is tasted by a person, it results in a noisy binary observation of whether the person approves of that cookie from that batch. My problem is that while there are 30 recipes and 100+ observations per recipe, each person only provides an observation on 5 of the recipes, including 2 observations of the gold standard recipe. This means that my observations are quite sparse - for any observation, only 5 out of 30 recipes have values. This is presumably well beyond the level at which it would be reasonable to impute missing values. The obvious solution to this would be to consider every observation as independent and ignore attributions of observations to oracles. However, I believe that this will sacrifice a substantial amount of information, since I expect each oracle to have some internal “approval threshold” that determines which latent qualities are high enough to be observed as a 1 or 0. My question then, is whether there is a way to express these observations to a hierarchical Bayesian model like PyMC3 without sacrificing the observation attribution information.
