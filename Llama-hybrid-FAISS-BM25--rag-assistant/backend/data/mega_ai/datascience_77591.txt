[site]: datascience
[post_id]: 77591
[parent_id]: 77578
[tags]: 
I think your understanding of the output vector is not correct (Not just for Neural Network but any Model) We don't encode the output to reduce the dimension. Output has not much contribution on the RAM and computation, it's the input size and dimension. Simple OHE Or just the label encoding will work( Loss function will change as per the case) What you should decide first - Is this a Multi-class problem or Multi-label This will decide your Encoding i.e. [1, 1, 0, 0, 1] Or [1, 0, 0, 0, 0] This will decide the last layer's Activation Function and the Model's Loss function It is obvious that for such a high output dimension, you will need a very large input dataset with a good variance over all the 10K class . To reduce output dimension - You may use any clustering technique Or your domain knowledge to club different classes. And then, you should plan about Torch and TensorFlow
