[site]: crossvalidated
[post_id]: 637677
[parent_id]: 
[tags]: 
Justification of independence assumption for latent variables in Expectation Maximization algorithm

When deriving the ELBO/free energy in the EM algorithm, it is often done in a "general" case of observed and latent variables and then an assumption of independent (or iid) variables is brought in. For example, letting $\mathbf X$ be an observed variable and $\mathbf Z$ being unobserved/latent variable we can the ELBO/free energy as \begin{align} \mathcal F\left(q(\mathbf Z), \boldsymbol \theta \right) & = \log p(\mathbf X \lvert \boldsymbol \theta) -\sum_{\mathbf{Z}} q\left(\mathbf{Z}\right) \log \frac{q\left(\mathbf{Z}\right)}{p\left(\mathbf{Z} \mid \mathbf{X}, \boldsymbol{\theta}\right)} \\ &= \log p(\mathbf X \lvert \boldsymbol \theta) -D_{\mathbb{K} \mathbb{L}}\left(q\left(\mathbf{Z}\right) \| p\left(\mathbf{Z} \mid \mathbf{X}, \boldsymbol{\theta}\right)\right) \\ &= \sum_{\mathbf Z} q(\mathbf z) \log \frac{p(\mathbf X, \mathbf Z \lvert \boldsymbol \theta)}{q(\mathbf Z)}. \end{align} The argument continues that in (typical) cases where the observed variable $\mathbf X $ is composed of independent observations, it can be decomposed as $(\mathbf x_1, \ldots, \mathbf x_N)$ (e.g. a dataset of $N$ independent observations). Also, the latent variable can be decomposed as independent $(\mathbf z_1, \ldots, \mathbf z_N)$ but not justification is given for this latent variable independence (see [1], [2]). This is the step I don't see as necessarily obvious. Under the assumption of both independence of data and of latent variables we can factor $p(\mathbf X, \mathbf Z) = \prod_{n=1}^N p(\mathbf x_n, \mathbf z_n)$ and it can be shown ([1], [2]) that the ELBO/free energy can be rewritten as \begin{align} \mathcal F\left(q(\mathbf Z), \boldsymbol \theta \right) & = \sum_{n=1}^N \sum_{\mathbf z_n} q_n(\mathbf z_n) \log \frac{p(\mathbf x_n, \mathbf z_n \lvert \boldsymbol \theta)}{q_n(\mathbf z_n)}. \end{align} So, how can we justify that the latent variables are independent? Do the latent variables have to be independent for the observed variables to be independent? If so, why? What would happen if the latent variables were not independent? References [1]: pg.6; Neal, R.M., Hinton, G.E. (1998). A View of the Em Algorithm that Justifies Incremental, Sparse, and other Variants. Learning in Graphical Models. NATO ASI Series, vol 89. Springer, Dordrecht. https://doi.org/10.1007/978-94-011-5014-9_12 [2]: pg.453 Christopher M. Bishop. 2006. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-Verlag, Berlin, Heidelberg.
