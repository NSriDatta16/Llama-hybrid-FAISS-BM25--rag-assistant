[site]: datascience
[post_id]: 108295
[parent_id]: 
[tags]: 
Trainning CNN Metric Learning gradient is constantly 1

I'm training a CNN with shirts and bodycon photos. I have these two classes and about 15k photos. I'am trying to do Metric Learning with a Contrastive Loss, but my CNN is not learning because gradients are constantly 1. I'am using the pretrained resnet18 with Identity as last layer and cosine similarity for distances (I've tried with Euclidean too). Does anybody know why ? I'am defining the contrastive loss using label matrix, which is, for every pair of images, 1 if they belong to same class or 0 if not. The error I'am getting is about 2.9 all time, so it is not learning anything. My code: class ContrastiveLoss(nn.Module): def __init__(self, margin=5.0): super(ContrastiveLoss, self).__init__() self.margin = margin def forward(self, distances, labels): m = 5 loss = 0 total = 0 #Paralelizar distances = torch.from_numpy(distances).detach() labels = torch.from_numpy(labels).detach() # torch D_2 = torch.multiply(distances,distances) A = torch.multiply(D_2,labels) D_2_m = (5 - D_2).clip(min=0) B = torch.multiply(D_2_m,(1 - labels)) loss = torch.sum(A+B)/2 total = len(A) * (len(A) - 1) / 2 return loss / total criterion = ContrastiveLoss() from sklearn.metrics import pairwise_distances from scipy.spatial.distance import cosine def get_label_matrix(labels): labels = labels.cpu().detach().numpy() lab_mat = np.empty([len(labels),len(labels)]) for i,lab in enumerate(labels): for j,lab_2 in enumerate(labels): if lab == lab_2: lab_mat[i][j] = 0 else: lab_mat[i][j] = 1 return lab_mat def train(CNN, train_loader, optimizer,criterion, num_epochs, model_name='model.ckpt', device='cpu'): CNN.train() # Set the model in train mode total_step = len(train_loader) losses_list = [] criterion = criterion # Iterate over epochs for epoch in range(num_epochs): # Iterate the dataset loss_avg = 0 nBatches = 0 for i, (images, labels) in enumerate(train_loader): # Get batch of samples and labels images = images.to(device) labels = labels.type(torch.LongTensor).to(device) outputs = CNN(images) distance = 1-pairwise_distances(outputs.cpu().detach().numpy(), metric="cosine") #distance = distance_matrix(outputs.cpu().detach().numpy(),outputs.cpu().detach().numpy()) # Forward pass loss = criterion(distance,get_label_matrix(labels)).requires_grad_() # Backward and optimize optimizer.zero_grad() print(loss.data) print(loss.grad) loss.backward() print(loss.grad) optimizer.step() loss_avg += loss.cpu().item() nBatches+=1 if (i+1) % 50 == 0: print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, i+1, total_step, loss_avg / nBatches)) print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, i+1, total_step, loss_avg / nBatches)) losses_list.append(loss_avg / nBatches) torch.save(CNN.state_dict(), SPRINT_path+ '/' + model_name) return losses_list if torch.cuda.is_available(): resnet18 = resnet18.cuda() criterion = criterion.cuda() print("GPU ready to fight") learning_rate = 0.01 optimizer = torch.optim.SGD(resnet18.parameters(),lr = learning_rate, weight_decay=1e-5, momentum=0.9) device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') model = resnet18.to(device) losses = train(model, train_loader, optimizer, criterion, num_epochs=10, model_name='toy_model.ckpt', device=device) ```
