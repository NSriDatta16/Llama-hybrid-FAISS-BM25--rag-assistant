[site]: datascience
[post_id]: 117824
[parent_id]: 
[tags]: 
Tensorflow text classification with 'int' and 'tf-idf' vectorizer

My question is simple. I tried a text classification with both 'int' and 'tf-idf' vectorizers. I'd expect it would classify better with tf-idf but the scores are 0.65 for 'int' and 0.60 for 'tf-idf'. Why is this the case? My Model: MAX_TOKENS_NUM = 100000 # Maximum vocab size. MAX_SEQUENCE_LEN = 40 # Sequence length to pad the outputs to. EMBEDDING_DIMS = 100 model_simple = tf.keras.models.Sequential() model_simple.add(tf.keras.Input(shape=(1,), dtype=tf.string)) model_simple.add(vectorize_layer) model_simple.add(layers.Dense(EMBEDDING_DIMS, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(1e-3))) model_simple.add(layers.Dropout(0.1)) model_simple.add(layers.Dense(EMBEDDING_DIMS, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(1e-3))) model_simple.add(layers.Dropout(0.1)) # model_simple.add(tf.keras.layers.Embedding(MAX_TOKENS_NUM + 1, EMBEDDING_DIMS)) # # model.add(layers.Dropout(0.1)) # model_simple.add(layers.GlobalAveragePooling1D()) # model.add(layers.Dropout(0.1)) model_simple.add(layers.Dense(len(labels))) model_simple.summary() model_simple.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=tf.metrics.SparseCategoricalAccuracy())
