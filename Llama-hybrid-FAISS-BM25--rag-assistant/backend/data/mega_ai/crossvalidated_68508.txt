[site]: crossvalidated
[post_id]: 68508
[parent_id]: 
[tags]: 
Issues with implementing neural network

I am trying to use neural network to learn a non linear function mapping input to outputs. However, I am having some issues with it. I used tansig activation function for the hidden layers and for the output I used logsig. I scaled the output variables in the range [0 1]. The input variables were standardized to zero mean and unit std. I learn the neural network. Now when I test my NN model on either the train set or a different test set, the outputs are always greater than 0.5. Why is it so? My targets could be anything from 0 to 1. However, my outputs from the model are at least 0.5. Any suggestions what could have happened? I have around 600 features with 5000 training examples and 10 neurons in the hidden layer and a single output I tried with tansig activation function for the hidden layers and a linear activation function for the output layers and I got the following. This is somewhat better than before. However, I am a bit surprised why bias is introduced
