[site]: crossvalidated
[post_id]: 34200
[parent_id]: 34188
[tags]: 
There's no conjugate prior for this likelihood. Likelihoods that admit conjugate distributions correspond to data distributions that are members of some exponential family . Having a non-linear function of the parameters in the log-likelihood makes it impossible for the data distribution to belong to an exponential family. Even though there's no conjugate prior, one possibility for a reasonable log-prior is $L_0({\bf p} ; {\bf j}, {\bf N} ) = \sum_i [j_i \log(p_i) + (N_i - j_i) \log (1 - p_i)]$ You can think of this log-prior as equivalent to a log-likelihood for a data set in which each person did a set of questions alone and correctly answered $j_i$ out of $N_i$. This interpretation allows you to set the prior parameters ${\bf j}$ and ${\bf N}$ in a reasonably intuitive way. I'd be somewhat surprised if even small values of $N_i$ (e.g., 2 to 4) did not provide good regularization. Note that $j_i$ and $N_i$ need not be integers. It seems to me that you're thinking of using the plug-in predictive distribution. May I suggest you go full Bayes and use the posterior predictive distribution instead? It would require MCMC , which may be more trouble than you're willing to go to. (If you're using Matlab I can recommend an MCMC routine that would shorten your coding time considerably.)
