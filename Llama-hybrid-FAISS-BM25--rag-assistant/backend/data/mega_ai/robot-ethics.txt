Robot ethics, sometimes known as "roboethics", concerns ethical problems that occur with robots, such as whether robots pose a threat to humans in the long or short run, whether some uses of robots are problematic (such as in healthcare or as "killer robots" in war), and how robots should be designed such that they act "ethically" (this last concern is also called machine ethics). Alternatively, roboethics refers specifically to the ethics of human behavior towards robots, as robots become increasingly advanced. Robot ethics is a sub-field of the ethics of technology. It is closely related to legal and socio-economic concerns. Serious academic discussions about robot ethics started around 2000, and involve several disciplines, mainly robotics, computer science, artificial intelligence, philosophy, ethics, theology, biology, physiology, cognitive science, neurosciences, law, sociology, psychology, and industrial design. History and events One of the first publications directly addressing and setting the foundation for robot ethics was "Runaround", a science fiction short story written by Isaac Asimov in 1942, which featured his well-known Three Laws of Robotics. These three laws were continuously altered by Asimov, and a fourth – or "zeroth" – law was eventually added to precede the first three, in the context of his science fiction works. The short term "roboethics" was most likely coined by Gianmarco Veruggio. Roboethics was also highlighted in 2004 with the First International Symposium on Roboethics. In discussions with students and non-specialists, Gianmarco Veruggio and Fiorella Operto thought that a good debate could push people to take an active part in the education of public opinion, make them comprehend the positive uses of the new technology, and prevent its abuse. Anthropologist Daniela Cerqui identified three main ethical positions emerging from the two days of debate: those who see robotics as purely technical and disclaim ethical responsibility, those interested in short-term ethical questions (such as compliance with existing conventions), and those interested in long-term ethical questions (including the digital divide). Some other important events include: 2004: the Fukuoka World Robot Declaration. 2017: in the Future Investment Summit in Riyadh, a robot named Sophia (and referred to with female pronouns) is granted Saudi Arabian citizenship, becoming the first robot ever to have a nationality. This attracts controversy due to legal ambiguity, for instance over whether Sophia can vote or marry, or whether a deliberate system shutdown is to be considered murder. Additionally, news outlets contrasted it with the limited rights that Saudi women have. 2017: The European Parliament passed a resolution addressed to the European Commission concerning Civil Law Rules on Robotics. Computer scientist Virginia Dignum noted in a March 2018 issue of Ethics and Information Technology that the general societal attitude toward artificial intelligence (AI) has, in the modern era, shifted away from viewing AI as a tool and toward viewing it as an intelligent "team-mate". In the same article, she assessed that, with respect to AI, ethical thinkers have three goals, each of which she argues can be achieved in the modern era with careful thought and implementation. The three ethical goals are as follows: Ethics by Design (the technical/algorithmic integration of ethical reasoning capabilities as part of the behavior of artificial autonomous system, see machine ethics); Ethics in Design (the regulatory and engineering methods that support the analysis and evaluation of the ethical implications of AI systems as these integrate or replace traditional social structures); and Ethics for design (the codes of conduct, standards and certification processes that ensure the integrity of developers and users as they research, design, construct, employ and manage artificial intelligent systems, see § Law below). In popular culture Roboethics