[site]: crossvalidated
[post_id]: 324708
[parent_id]: 323867
[tags]: 
What you have there is commonly called the exploration term. The upper confidence bound is the empirical mean plus this exploration term. Let's consider each term separately: $c$ is a constant which lets the user set the exploration/exploitation trade-off. For theoretical results it is often optimized for the problem at hand (e.g. k-armed bandits with Gaussian priors). $\sqrt{1/n_i}$ is proportional to the posterior standard deviation after $n_i$ samples of action $i$ . Essentially this says that as you pull an arm more often, there is less unknown about the arm. $\sqrt{ln(N_i)}$ ensures that you don't stop exploring too early. As $N_i$ becomes very large, the sample variances become small enough that we need to compensate to ensure that we never completely stop exploring. Most of the technical math is to show that $\sqrt{ln(N_i)}$ is just enough (but not too much) compensation. For a more technical description, the paper by Auer et al. is a good starting point. Auer, Peter, Nicolo Cesa-Bianchi, and Paul Fischer. "Finite-time analysis of the multiarmed bandit problem." Machine learning 47.2-3 (2002): 235-256.
