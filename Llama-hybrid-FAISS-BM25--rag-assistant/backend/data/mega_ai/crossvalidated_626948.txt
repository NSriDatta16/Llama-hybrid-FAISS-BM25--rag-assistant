[site]: crossvalidated
[post_id]: 626948
[parent_id]: 
[tags]: 
Getting negative predictions while fitting a Bayesian linear regression model

I am trying to fit a Bayesian linear regression model on a data set of $3$ years. I have used both pymc and pytorch libraries and the NUTS sampler for sampling. The dependent variable is Sales, and the independent variables are Media_1 spends, Media_2 spends, Media_3 spends, Competition_1 spends, Competition_2 spends, trend and price. The sales have an increasing trend. I have set the priors of the media variables as HalfNormal(2) since the beta coefficients of media variables are considered to be positive. For competition spends I have specified the prior to be negative HalfNormal(2) distribution and for price also I have set a negative HalfNormal distribution as a prior. For trend the prior is set to Normal(0,2). After running the Bayesian linear regression model both by pymc and pytorch, I am getting a negative Sales prediction which ideally should not be the case. The model is over attributing to the negatively related variables like Competition spends and price. The beta coefficients of the variables are in the same range. Also, the MAPE for the model is way too high. The actual and the predicted Sales are not in a similar range. Can anyone suggest why am I getting negative predictions? How can I get positive predictions from the model for each time period?
