[site]: crossvalidated
[post_id]: 70794
[parent_id]: 
[tags]: 
Interpretation of PCA Report from Machine Learning Toolkit

I am using a Machine Learning package called Orange . This software provides a Python interface and a visual programming GUI. I am using the GUI at present. There were 48 original variables. I have been using the PCA widget for dimensionality reduction and I want to investigate the relationship of PCA components to the original variables. I have done a little reading but that seem to be confusing me. My naive understanding is that PCA transforms the data set by a linear combination of the original variables. Is it possible find out the contribution of the original variables to the PC? The PCA widget produces a report, a snippet is below (didn't bother to include all PC). Comp.1 Comp.2 Comp.3 Comp.4 .... Std. deviation 0.593 0.388 0.296 0.238 .... Proportion Var 35.160 15.021 8.739 5.672 .... Cumulative Var 35.160 50.181 58.920 64.592 ... So if PC1 has a Proportion of Var 35.16, then essentially this is 35.16% of each of the original variables + proportion of PC2 etc? The widget also provides EigenVector (2x48). Do I need to do some magic with the EigenVectors to assess the influence of the original variables? Finally, if some PCA components have proportion of variance of zero or close to zero does this mean I have some poor/bad/redundant features? If so, is there a simple way to determine which they are form the PCA results?
