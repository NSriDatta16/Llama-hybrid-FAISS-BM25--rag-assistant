[site]: crossvalidated
[post_id]: 348742
[parent_id]: 
[tags]: 
ROC curve and parameter selection

I am employing the concept of ROC curve to select one class SVM classifier's parameters as follows: I have a dataset which include a normal class and an abnormal class. I train the One class SVM on normal class data and then try to predict the abnormal data. Since I originally know which are normal and which are abnormal, after the classifier predicts its classification, I calculate the True positive rate and false positive rate. I build a grid of parameters gamma (10^-9～10^-2) and nu(0.001～0.01) for the classifier and measure the true positive rates and false positive rates as described above for each hyperparameter combination. Since I want to determine the best hyperparameters, I plot these TPR and FPR set like in ROC curve concept (i.e plotting 1-fpr in X axis against tpr in Y axis) and select the set of hyperparameters that are closest to the (1,1) point in the graph. Is ROC supposed to be used in this way ? Can this be called ROC ? Are there any pitfalls by using the ROC concept in this way to determine hyper parameters ? Note: The reason I use one class SVM instead of a normal SVM that would require teaching variable y is because in real world deployment of this model I would not be able to get the "y" variable and I can not deploy already trained model because the test cases are too many and I can't develop a model that generalizes well over all the possible types of test cases. So I want the model to be able to recognize "abnormal" from learning what is "normal".
