[site]: crossvalidated
[post_id]: 33581
[parent_id]: 29653
[tags]: 
Thanks, I didn't realize it was as simple as: sum(residuals(f1, type="pearson")^2) However please note that Pearsons residual varies depending on whether it is calculated by covariate group or by individual. A simple example: m1 is a matrix (this one is the head of a larger matrix): m1[1:4,1:8] x1 x2 x3 obs pi lev yhat y obs 1 1 44 5 0.359 0.131 1.795 2 obs 0 1 43 27 0.176 0.053 4.752 4 obs 0 1 53 15 0.219 0.062 3.285 1 obs 0 1 33 22 0.140 0.069 3.080 3 Where x1-3 are predictors, obs is no. observations in each group, pi is probability of group membership (predicted from regression equation), lev is leverage, the diagonal of the hat matrix, yhat the predicted no. (of y=1) in the group and y the actual no. This will give you Pearson's by group. Note how it's different if y==0: '$ fun1 Thus nr If there are large numbers of subjects with y=0 covariate patterns, then Pearons residual will be much larger when calculated using the 'by group' rather than the 'by indiviual' method. See e.g. Hosmer & Lemeshow "Applied Logistic Regression", Wiley, 200.
