[site]: crossvalidated
[post_id]: 328564
[parent_id]: 134754
[tags]: 
Expanding Frank Harrells answer, to derive likelihood function you first need to define the probabilistic model of the problem. In the case of logistic regression , we are talking about a model for binary target variable (e.g. male vs female, survived vs died, sold vs not sold etc.). For such data, Bernoulli distribution is the distribution of choice. Notice that using $\{0, 1\}$ or $\{-1, +1\}$ coding is not a part of the definition of the problem, it is just a way of encoding your data, the labels are arbitrary and can be changed. In this case we decide to use the $\{0, 1\}$ labels because they have some nice properties , but the main problem in logistic regression is estimating the probability of "success" . We use the $\{0, 1\}$ encoding, because the model is defined in terms of Bernoulli distribution that uses such labels. If you insisted on defining the likelihood function in terms of a distribution that assigns $1-p$ probability for $-1$ and $p$ probability for $+1$ , then you would need to use such distribution in your likelihood function. The distribution would have the following probability mass function $$ g(x) = p^{(x+1)/2} (1-p)^ {1-(x+1)/2} $$ what basically reduces to Bernoulli distribution for $(X+1)/2 \in \{0, 1\} $ .
