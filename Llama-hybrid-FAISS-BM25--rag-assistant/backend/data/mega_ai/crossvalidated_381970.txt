[site]: crossvalidated
[post_id]: 381970
[parent_id]: 
[tags]: 
How to get consistency in neural network and eliminate possibility of NaN values?

I'm using a neural network(Keras,LSTM) for time series regression. Whenever I run the network, I get different outputs for the prediction. This is presumably due to the randomised weight initialization. Sometimes the loss becomes NaN. Is setting the seed to a certain value okay? I thought the models were supposed to converge to around the same values regardless of the seed value? How can I remove the NaN loss that I get sometimes?
