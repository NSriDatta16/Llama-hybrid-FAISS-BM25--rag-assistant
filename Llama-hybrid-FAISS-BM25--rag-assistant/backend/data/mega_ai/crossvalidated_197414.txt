[site]: crossvalidated
[post_id]: 197414
[parent_id]: 197398
[tags]: 
Typically one uses proportion $70\%$ to training and $30\%$ to validation. The reason behind this is the following: using a testing procedure you want to estimate a performance of algorithm A for a sample size $n$. If you keep too small number of objects for training, you get estimate of performance of algorithm A at sample size $c n$ with $c$ small - so you will add negative bias to your estimate. But of you keep too small amount of data for validation then you will get big variance in estimates as quality will depend on small number of objects selected for validation. To remove variance you can use cross-validation - numerous splits to training and validation sets with averaging of the result. So, empirical rules like the one described above try to find a tradeoff between bias and variance of algorithm performance estimate. Note, that also in many cases you will need to perform specific split. For example, you can split data with stratification: for training and validations sets shares of a first class objects are the same.
