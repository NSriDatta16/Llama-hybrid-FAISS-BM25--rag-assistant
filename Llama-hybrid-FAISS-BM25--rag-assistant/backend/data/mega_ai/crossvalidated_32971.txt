[site]: crossvalidated
[post_id]: 32971
[parent_id]: 
[tags]: 
Interpreting logistic regression

I need to perform a logistic regression to to see if a group of variables which are found to be significantly associated with an outcome (by univariate tests) have significant impact on the outcome when they are put together. In this case, from my reading, I gathered that in SPSS I need to use the enter method. When I applied this method, my new model decreased the prediction percent (not sure if this is the correct term) in the classification table in comparison to the constant only model (90.5 in constant only to 89.8 in new model). I have excluded multiple collinearity earlier. Omnibus Tests of Model Coefficients Chi-squaredf Sig. Step 1 Step 27.441 7 .000 Block 27.441 7 .000 Model 27.441 7 .000 Model Summary Step -2 Log likelihood Cox & Snell R Square Nagelkerke R Square 1 164.185a .086 .184 (a Estimation terminated at iteration number 6 because parameter estimates changed by less than .001) Hosmer and Lemeshow Test Step Chi-square df Sig. 1 6.317 7 .503 Given my objective of seeing if the independent variables when put together can have a significant impact on the outcome or not, can I use this model for that purpose to identify the variables that have and do not have independent effects on the outcome when compared together? In answer to the comments: As for the "measure of predictive accuracy", could I please know it in layman's terms please? My statistical vocabulary is inefficient to answer precisely though I understand what is should mean. I ran collinearity diagnostics to see there is an issue of multicollinearity between independent variables. I cannot paste the ROC curve itself, but the tables is given below, given the values I guess I may still use the model as it is rather than changing any other parameter. Opnion on this is welcome. Thank you everyone for suggestions. Area Under the Curve Test Result Variable(s): Predicted probability Area Std. Error a Asymptotic Sig. b Asymptotic 95% Confidence Interval Lower Bound Upper Bound .756 .042 .000 .67 .839 The test result variable(s): Predicted probability has at least one tie between the positive actual state group and the negative actual state group. Statistics may be biased. a Under the nonparametric assumption b Null hypothesis: true area = 0.5 Now I have an additional problem, or two rather 1. I have another outcome variable, again my onjective is to identify independant predictors for the given outcome amongst predictors with a p 0.8) in ROC despite not improving the correctly classified rates. Can I take this as being evidence of these covariants not haveing independant effects on the outcome? (number of independant variables available 7) As the dependant variable in this is 30 day mortality, I think I can try Cox regression. However, the only time dependant variable I have is length of hospitalization, I am not too sure if I can use this at the "time" cage in SPSS. Thank you in advance. (I am not too sure if I need to post this as a new question)
