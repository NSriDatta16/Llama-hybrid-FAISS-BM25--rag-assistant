[site]: datascience
[post_id]: 40185
[parent_id]: 
[tags]: 
PCA and FastICA in scikit-learn giving near identical results

So after importing my data, transforming it, and splitting into training and test sets I tried running this script for PCA: pca = PCA(random_state=2, n_components=2).fit_transform(X_train) pca = pd.DataFrame(pca, columns=["X1","X2"]).assign(y = np.array(y_train)) pca.plot.scatter(x='X1', y='X2', c='y', colormap='viridis') Giving me this graph I then ran this script for ICA: ica = FastICA(random_state=34, n_components=2).fit_transform(X_train) ica = pd.DataFrame(ica, columns=["X1","X2"]).assign(y = np.array(y_train)) ica.plot.scatter(x='X2', y='X1', c='y', colormap='viridis') If you look closely, you'll see these graphs are exactly the same. Except flipped over the X1 axis. Any idea what could cause this? I was expecting ICA to produce something very different from PCA
