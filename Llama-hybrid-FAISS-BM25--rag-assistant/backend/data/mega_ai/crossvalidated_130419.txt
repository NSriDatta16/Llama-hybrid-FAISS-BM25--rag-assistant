[site]: crossvalidated
[post_id]: 130419
[parent_id]: 107874
[tags]: 
First 18 isn't a lot of features at all and you should see if you can get more data. Google uses a ridiculous number of features in their ad targeting and takes a different online/game theoretical approach to choosing what ad to show to the audience Second, skewed class labels like this are a common problem. Search terms to look at include imbalanced or unbalanced classification and "skew insensitive". There are a bunch of approaches you can and should try: Stratified cross validation to make sure you end up with enough positives in the test. Under/over sampling as others have mentioned or roughly balanced bagging for random forests. There are also methods for generating new minority class samples and sampling representative majority class samples. I saw a python library for this here. Class weighted or cost sensitive learning can work well and there are versions of many methods that can do this (though not in scikit learn). Boosting (gradient or adaptive) can work well. Transductive or one class approaches which treat the data as positive and unlabeled can work well though they assume the positives are members of a larger class of possible positives. Hellinger distance decision trees are gaining some bus for working well on unbalanced data. Most of these approaches essentially reflect that you care more about getting the positives right then getting the negatives wrong. Within scikit.learn you're limited in the number of these you can try without some custom code but there are lots of other libraries out there if you google around though they'll be in a mix of languages.
