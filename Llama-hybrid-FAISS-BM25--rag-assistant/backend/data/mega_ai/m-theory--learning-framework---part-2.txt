rangle \qquad (1)} In other words, the dot product of transformed image and a template is equal to the dot product of original image and inversely transformed template. For instance, for image rotated by 90 degrees, the inversely transformed template would be rotated by −90 degrees. Consider the set of dot products of an image I {\displaystyle I} to all possible transformations of template: { ⟨ I , g ′ t ⟩ ∣ g ′ ∈ G } {\displaystyle \lbrace \langle I,g^{\prime }t\rangle \mid g^{\prime }\in G\rbrace } . If one applies a transformation g {\displaystyle g} to I {\displaystyle I} , the set would become { ⟨ g I , g ′ t ⟩ ∣ g ′ ∈ G } {\displaystyle \lbrace \langle gI,g^{\prime }t\rangle \mid g^{\prime }\in G\rbrace } . But because of the property (1), this is equal to { ⟨ I , g − 1 g ′ t ⟩ ∣ g ′ ∈ G } {\displaystyle \lbrace \langle I,g^{-1}g^{\prime }t\rangle \mid g^{\prime }\in G\rbrace } . The set { g − 1 g ′ ∣ g ′ ∈ G } {\displaystyle \lbrace g^{-1}g^{\prime }\mid g^{\prime }\in G\rbrace } is equal to just the set of all elements in G {\displaystyle G} . To see this, note that every g − 1 g ′ {\displaystyle g^{-1}g^{\prime }} is in G {\displaystyle G} due to the closure property of groups, and for every g ′ ′ {\displaystyle g^{\prime \prime }} in G there exist its prototype g ′ {\displaystyle g^{\prime }} such as g ′ ′ = g − 1 g ′ {\displaystyle g^{\prime \prime }=g^{-1}g^{\prime }} (namely, g ′ = g g ′ ′ {\displaystyle g^{\prime }=gg^{\prime \prime }} ). Thus, { ⟨ I , g − 1 g ′ t ⟩ ∣ g ′ ∈ G } = { ⟨ I , g ′ ′ t ⟩ ∣ g ′ ′ ∈ G } {\displaystyle \lbrace \langle I,g^{-1}g^{\prime }t\rangle \mid g^{\prime }\in G\rbrace =\lbrace \langle I,g^{\prime \prime }t\rangle \mid g^{\prime \prime }\in G\rbrace } . One can see that the set of dot products remains the same despite that a transformation was applied to the image! This set by itself may serve as a (very cumbersome) invariant representation of an image. More practical representations can be derived from it. In the introductory section, it was claimed that M-theory allows to learn invariant representations. This is because templates and their transformed versions can be learned from visual experience – by exposing the system to sequences of transformations of objects. It is plausible that similar visual experiences occur in early period of human life, for instance when infants twiddle toys in their hands. Because templates may be totally unrelated to images that the system later will try to classify, memories of these visual experiences may serve as a basis for recognizing many different kinds of objects in later life. However, as it is shown later, for some kinds of transformations, specific templates are needed. Theoretical aspects From orbits to distribution measures To implement the ideas described in previous sections, one need to know how to derive a computationally efficient invariant representation of an image. Such unique representation for each image can be characterized as it appears by a set of one-dimensional probability distributions (empirical distributions of the dot-products between image and a set of templates stored during unsupervised learning). These probability distributions in their turn can be described by either histograms or a set of statistical moments of it, as it will be shown below. Orbit O I {\displaystyle O_{I}} is a set of images g I {\displaystyle gI} generated from a single image I {\displaystyle I} under the action of the group G , ∀ g ∈ G {\displaystyle G,\forall g\in G} . In other words, images of an object and of its transformations correspond to an orbit O I {\displaystyle O_{I}} . If two orbits have a point in common they are identical everywhere, i.e. an orbit is an invariant and unique representation of an image. So, two images are called equivalent when they belong to the same orbit: I ∼ I ′ {\displaystyle I\sim I^{\prime }} if ∃ g ∈ G {\displaystyle \exists g\in G} such that I ′ = g I {\displaystyle I^{\prime }=gI} . Conversely, two orbits a