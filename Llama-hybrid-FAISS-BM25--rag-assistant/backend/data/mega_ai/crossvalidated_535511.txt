[site]: crossvalidated
[post_id]: 535511
[parent_id]: 535490
[tags]: 
Having too many variables can be a huge issue : if you have variables with less direct impact, they'll impact your Random Forest and make it less efficient. You have to find the right balance. Just so you understand, you should try applying your model with only the 5, 10 and 20 "best features" according to you (arbitrary) and see how accuracy evolves. Then if there's a real change, you can apply more precise feature selection algorithms. Another thing : One good way to do it is train your algorithm to one season (2019-2020 for example) and test it to another (2020-2021), so your classes (ranked 1-5, 6-10, 11-15, ...) are represented the same as the reality. Here you seem to randomly cut your dataset, which can cause issues when you only have 270 entries.
