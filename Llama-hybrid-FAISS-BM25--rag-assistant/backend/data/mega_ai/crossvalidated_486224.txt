[site]: crossvalidated
[post_id]: 486224
[parent_id]: 473858
[tags]: 
Not sure but bias alignment might refer to the detail that both query and keys vectors are offset by positional encoding, i.e. the attention query can be specified more like: "[How] is this source token, with respect to it's position, related to this target token with respect to it's position?". But more likely the wording is supposed to be interpreted like what bomzh explained in his answer.
