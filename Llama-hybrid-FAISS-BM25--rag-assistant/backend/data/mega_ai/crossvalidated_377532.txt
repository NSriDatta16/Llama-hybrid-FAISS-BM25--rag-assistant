[site]: crossvalidated
[post_id]: 377532
[parent_id]: 377527
[tags]: 
There are a few different issues here. Probably the main issue is that model selection (whether using p-values or AICs, stepwise or all-subsets or something else) is primarily problematic for inference (e.g. getting p-values with appropriate type I error, confidence intervals with appropriate coverage). For prediction , model selection can indeed pick a better spot on the bias-variance tradeoff axis and improve out-of-sample error. For some classes of models, AIC is asymptotically equivalent to leave-one-out CV error [see e.g. http://www.petrkeil.com/?p=836 ], so using AIC as a computationally efficient proxy for CV is reasonable. Stepwise selection is often dominated by other model selection (or averaging ) methods (all-subsets if computationally feasible, or shrinkage methods). But it's simple and easy to implement, and if the answer is clear enough (some parameters corresponding to strong signals, others weak, few intermediate), then it will give reasonable results. Again, there's a big difference between inference and prediction. For example if you have a couple of strongly correlated predictors, picking the incorrect one (from a "truth"/causal point of view) is a big problem for inference, but picking the one that happens to give you the best AIC is a reasonable strategy for prediction (albeit one that will fail if you try to forecast a situation where the correlation of the predictors changes ...) Bottom line: for moderately sized data with a reasonable signal-to-noise ratio, AIC-based stepwise selection can indeed produce a defensible predictive model; see Murtaugh (2009) for an example. Murtaugh, Paul A. "Performance of several variable‚Äêselection methods applied to real ecological data." Ecology letters 12, no. 10 (2009): 1061-1068.
