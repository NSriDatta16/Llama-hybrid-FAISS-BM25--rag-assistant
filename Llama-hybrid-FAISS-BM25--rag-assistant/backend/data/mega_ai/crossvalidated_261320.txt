[site]: crossvalidated
[post_id]: 261320
[parent_id]: 
[tags]: 
Linear regression response variable far way from Gaussian

The book Introduction to Categorical Data Analysis, Agresti 2007, says Historically, early analyses of nonnormal responses often attempted to transform Y so it is approximately normal, with constant variance. Then, ordinary regression methods using least squares are applicable. In practice, this is difficult to do. With the theory and methodology of GLMs, it is unnecessary to transform data so that methods for normal responses apply. This is because the GLM fitting process uses ML methods for our choice of random component, and we are not restricted to normality for that choice. I understand, we have discrete response variable and or counting variable we can use other link functions to do logistic regression and Poisson regression. But how do we deal with linear regression response variable far way from Gaussian (still a continuous number, not but skewed and have many outliers)? If we do not do it (transform to Gaussian) any more, does it mean all the estimation of the coefficient are good, but std error, $t$-value and $p$-value are not valid?
