[site]: crossvalidated
[post_id]: 570355
[parent_id]: 
[tags]: 
What part of a dataset do I apply a traditional, statistical analysis to linear regression?

Note: I've edited my question as recommended below by @EdM. Suppose I have a supervised learning problem on a sizeable tidy dataset with real valuesâ€”-e.g., the dataset has 100,000 rows or observations. I with to apply a linear regression and understand that there are two basic forms of linear regression analysis: explanation and prediction. If I desire the former, I study the relationships between the features and target variable of the linear model: some examples are captured by hypothesis tests, R-squared and F-statistics, and so forth. If I desire the latter, I use machine learning, by which I split the dataset into training, validation, and testing sets on which to fit the linear model and optimize it. By optimization or "learning" of the linear model, I mean the minimization of the model's mean-squared error by application of gradient descent and regularization. My question is: suppose I wish to do both forms of analysis. Do I first do explanatory anlysis on the relationships between the features and target variables on the whole dataset, before I split the dataset and do the predicitive analysis, which imvolves the machine learning I described above?
