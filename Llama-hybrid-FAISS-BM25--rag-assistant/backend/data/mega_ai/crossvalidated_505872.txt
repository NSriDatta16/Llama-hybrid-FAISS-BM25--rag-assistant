[site]: crossvalidated
[post_id]: 505872
[parent_id]: 
[tags]: 
R: GLM Fisher Scoring Algorithm vs. Optim BFGS

I hope some of you can help me figure this out: When fitting a simple logistic regression we can use R‘s GLM package with family=binomial(). As far as I’m concerned, it uses the Fisher Scoring algorithm. We can solve the same problem with R’s optim package by feeding it the likelihood-function and minimizing that with e. g. the BFGS algorithm. However, those two options differ substantially in computation speed with increasing sample size and number of parameters. While GLM stays in the realm of seconds, optim & BFGS increase to minutes, hours, even days. Can anyone tell me, what the difference is, or rather, why GLM with the Fisher Scoring algorithm has such a big advantage in terms of computation speed. Furthermore, I want to eventually write my own likelihood function. Would it be possible to estimate that with the GLM package, utilizing its speed advantage, instead of optim? Thank you for your help!
