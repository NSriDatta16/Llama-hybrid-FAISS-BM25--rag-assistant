[site]: crossvalidated
[post_id]: 585815
[parent_id]: 585577
[tags]: 
Assuming $\sigma_n$ is a known parameter, the question is about simulating from the posterior distribution of $(\mu,\sigma^2)$ given a sample of $x(k)'s$ (e.g., $x(1),\ldots,x(K)$ ) $$p(\mu,\sigma|x(1),\ldots,x(K))\propto p(\mu,\sigma)\times f(x(1),\ldots,x(K)|\mu,\sigma)$$ As expressed in the question, this joint distribution density $$f(x(1),\ldots,x(K)|\mu,\sigma)$$ is not easily computed and hence an MCMC algorithm is difficult to implement, incl. the specific case of the Gibbs sampler. One traditional approach in simulation (and found in one of the earliest Gibbs samplers, see Tanner & Wong, 1987) is to complement the vector to be simulated, $(\mu,\sigma)$ , with latent or auxiliary variables in order to achieve a manageable joint density. We call this method demarginalisation in our book and it simply means that simulating from the marginal density $p(\cdot)$ can proceed by (i) constructing a manageable but otherwise arbitrary joint density $q(\cdot,\cdot)$ such that $p$ is its marginal: $$p(u)=\int q(u,v)\,\text dv$$ and (ii) simulate from this joint $q$ a sample of $(u_i,v_i)_{i=1,\ldots,I}$ 's, because the $u_i$ 's will then be distributed from $p$ . In the current setting, the latent variables are naturally available as made of the $\mathbf U=U_1,\ldots,U_M$ and $\mathfrak B=\beta_1,\ldots,\beta_M$ since the original model can be decompose as the hierarchy of distributions \begin{align} x(k)|\mathbf U,\mathfrak B &\sim \mathcal N\left(\sum_{m}^{M} \exp\{i (U_m k + \beta_m)\},\sigma_n^2\right)\\ U_m|\mu,\sigma &\sim \mathcal N\left(\mu,\sigma^2\right)\\ \beta_m &\sim \mathcal U(0,2\pi)\\ \mu,\sigma &\sim p(\mu,\sigma) \end{align} and the associated demarginalisation is $$p(\mu,\sigma|x(1),\ldots,x(K)) = \int p(\mu,\sigma,\mathbf U,\mathfrak B|x(1),\ldots,x(K))\,\text d(\mathbf U,\mathfrak B)$$ Furthermore, thanks to the hierarchical decomposition $$p(\mu,\sigma,\mathbf U,\mathfrak B|x(1),\ldots,x(K))\propto p(\mu,\sigma)\times\prod_m \mathfrak u(\beta_m)\times\prod_m \varphi(U_m|\mu,\sigma)\times\prod_{k=1}^K\varphi(x(k)|\mathbf U,\mathfrak B)$$ the joint distribution can be easily simulated by a Gibbs sampler based on the full conditional. Obviously, if $M$ and/or $K$ is large, this sampler may be time consuming and slowly mixing.
