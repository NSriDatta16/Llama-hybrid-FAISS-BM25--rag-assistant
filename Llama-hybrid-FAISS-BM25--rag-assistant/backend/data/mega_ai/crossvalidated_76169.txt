[site]: crossvalidated
[post_id]: 76169
[parent_id]: 
[tags]: 
Convergence of value iteration

Why is the termination condition of the value-iteration algorithm ( example http://aima-java.googlecode.com/svn/trunk/aima-core/src/main/java/aima/core/probability/mdp/search/ValueIteration.java ) as it is? In the MDP (Markov Decision Process) we have $||U_{i+1}-U_i|| $U_i$ is a vector of utilities $U_{i+1}$ is the vector of updated utilities $\text{error}$ is the error bound used in the algorithm $\gamma$ is the discount factor used in the algorithm Where does "$\text{error}\cdot(1-\gamma)/\gamma$" come from? Is the term "$/\gamma$" because every step is discounted by $\gamma$? But then what about $\text{error}\cdot(1-\gamma)$? And how big must $\text{error}$ be?
