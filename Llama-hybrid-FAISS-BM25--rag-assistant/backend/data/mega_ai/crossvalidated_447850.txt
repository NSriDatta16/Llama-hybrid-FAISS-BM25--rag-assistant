[site]: crossvalidated
[post_id]: 447850
[parent_id]: 447837
[tags]: 
Is my understanding correct? Yes, in general I would say that it is, and that your classifier might be using some different parameters to work better with your unbalanced classes. However, AUC curve with an SVM might not be completely "truthful", and this brings me to the next point Is SVM using a threshold of 0.5? First of all, I suggest reading this post and its answer . SVMs do not make a probability model, but optimize the position of the separating hyperplane between the classes. Therefore classification does not use a probability threshold, since they do not model probability at all. The AUC curve can be obtained either using some "synthetic " predict_proba method or using the decision_function one. The first one is not necessarily stable, and documentation suggests that it is not even guaranteed to match the results of the classification itself (meaning that there is no clear threshold). The second one is based on distances from the hyperplane, and you could find ROC points by "varying" the bias term and moving the hyperplane. However this is a parameter that is optimized during the fitting, so in my opinion tuning it manually afterwards seems a bit weird (however, I am not an SVM expert so someone might have a say on this). Does it make sense (both mathematically and from a ML point of view) to tune this parameter, for example by using cross-validation? Linking to the previous point, I would not use the probabilities (also, outputting them makes the fitting much longer) nor I would manually tweak the bias term. I think one way to try and use a different operating point would be to tune the class_weight and sample_weight parameters, which should allow you to deal with unbalanced classes. Edit: Thanks @EdM for the very interesting comment. Indeed, in one of the papers suggested in that question ( this one ) the author changes the bias parameter b manually from the one that better separates the classes to the one that obtains the best balance in recall and precision. However, as it mentions, the classifier is not technically an SVM anymore, as it optimizes a different function.
