[site]: crossvalidated
[post_id]: 186933
[parent_id]: 
[tags]: 
Over sampling imbalance data in SVM

Basically I have a medium size data set (20,000 observations) with only 200 being in group 1, thus an imbalanced data set. My goal is to predict as much group 1 class as possible without sacrificing too much false positive. With some research, I understand putting class.weight = c('1'=100,'0'=0.5) in svm() would be a method to specify different misclassification penalty for groups. Over sampling the minority group or subset the majority group would also be solutions to the data imbalance. However, I am not sure how the latter would help the situation because the prediction proportion for positive should ultimately be small even the training data set is "balanced." So my question would be the following: 1) When using over sampling the minority class, how would I adjust the prediction (or the model) so the prediction will ensure only a small proportions are assigned to be class 1? 2) During the fitting for svm() with the original data, how should I specify the value cost ? I could tune it with tune() but the running time increase tremendously after I put class.weight=c('1'=100,'0'=0.5) Thanks!
