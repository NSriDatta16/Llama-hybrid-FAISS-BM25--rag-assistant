[site]: crossvalidated
[post_id]: 587359
[parent_id]: 
[tags]: 
Do you tune hyperparameters for neural networks one at a time?

I wondered whether tuning hyperparameters, such as the learning rate or the amount of layers and neurons, is done seperately or alltogether. E.G. you first tune the amount of neurons and when getting acceptable error rates you continue with tuning the learning rate. I know there are different methods such as the grid search or bayesian optimization, but in my case I have to tune the hyperparameters manually, because I am forced to use SPSS. Therefore I was wondering which way I should try my luck. Best regards
