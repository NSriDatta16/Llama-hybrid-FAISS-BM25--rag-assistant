[site]: crossvalidated
[post_id]: 397739
[parent_id]: 397724
[tags]: 
No, we cannot. Otherwise, the already-determined next action $A'$ would be thrown away. In SARSA, next action $A'$ is selected in the middle of current step loop, and it replaces $A$ in the next step (more precisely, at the end of current step). In other words, at the beginning of next step, $A$ should be the already-selected action $A'$ from current step, we cannot throw $A'$ away by selecting $A$ from a new Îµ-greedy search. On the other hand, in Q-learning, only one action is involved in each loop, thus, if the only action $A$ is selected at the beginning of each step, nothing is thrown away.
