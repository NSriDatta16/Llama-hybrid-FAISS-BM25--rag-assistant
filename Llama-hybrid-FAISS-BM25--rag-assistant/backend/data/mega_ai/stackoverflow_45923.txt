[site]: stackoverflow
[post_id]: 45923
[parent_id]: 45824
[tags]: 
To solve this problem I implemented a simple filter that would look at the User-Agent header in the HTTP request and compare it to a list of known robots. I got the robot list from www.robotstxt.org . It's downloadable in a simple text-format that can easily be parsed to auto-generate the "blacklist".
