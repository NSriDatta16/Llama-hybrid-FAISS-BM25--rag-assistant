[site]: crossvalidated
[post_id]: 161865
[parent_id]: 161844
[tags]: 
In a very simple case, you have one training set and one test set. You train on the training set and then you test on the test set. As you have trained on the training set, the network has already seen the data and the optimization method was optimized for this data. Hence the error on the test set should be higher. If you have hyper parameters which you want to optimize, you will split your training set into a training and a development set. You train for different choices on the training set, see the error on the development set and at the end, when you think everything is fine, you test on the test set. The test set should NEVER be used for optimization. n-fold cross-validation makes better use of your data. You make $n$ disjunct sets $b_1, \dots, b_n$ of data. One bin $b_i$ is your test set and the rest $T_i = b_1 \cup \dots \cup b_n \setminus b_i$ is your training data. You train on $T_i$ and test on $b_i$ for all $i \in 1, \dots, n$. Then you average the error. You should not use this for hyper parameter optimization as this will add knowledge of the test set to your system. Hyper parameter optimization should only be done on the training set.
