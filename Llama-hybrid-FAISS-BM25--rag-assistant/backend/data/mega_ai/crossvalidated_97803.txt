[site]: crossvalidated
[post_id]: 97803
[parent_id]: 
[tags]: 
Equivalence of log linear and logistic regression for categorical variables

This question is similar to Does every log-linear model have a perfectly equivalent logistic regression? but my problem is understanding the proof.Every proof is very similar to the one found on: http://teaching.sociology.ul.ie/SSS/lugano/node58.html . for a $n$ by $2$ contingency table $$\log(\mu_{ij} ) = \lambda_0 + \lambda^A_i + \lambda^B_j + \lambda^{AB}_{ij} $$ $$\log(\mu_{i1} ) - \log( \mu_{i0}) =logit(p) = (\lambda^B_1 - \lambda^B_2) +(\lambda^{AB}_{i1}-\lambda^{AB}_{i2} )$$ reparamitised to $$logit(p)= \alpha+ \beta_i$$ This proves that log linear models have an equivalent logistic model. I'm convined this result is true from numericla result. My problem with the proof is that the $\lambda$'s are estimated from a Poisson likelihood and the $\alpha$ and $\beta_i$ are estimated from a bernoulli/ binomial log likelihood. How is it that they're the same? Do we need to go a step further and show that the $\alpha$ and $\beta_i$ found from the likelihood for logistic regression also maximise the likelihood for the log linear model?
