[site]: crossvalidated
[post_id]: 113555
[parent_id]: 
[tags]: 
Point Estimate of normally distributed threshold parameter with unknown mean and variance

I'm new to Bayesian analysis an applied what I learned in John Kruschke's book to simplified versions of a model I previously fitted with non-Bayesian methods. For those simplified versions, even though I think they are already quite complex, I got sensible posterior distributions (using MCMC) whose means corresponded to the non-bayesian parameter estimates. Now I'm adding back the complexity and encounter some difficulties. Let me first describe my model in a simplified form: I have several levels $x_i$ which range from -100 to 100 in steps of 10 including 0. The observed values are binomially distributed at each level, hence $y_i \sim B(N_i, p_i)$ The $N_i$ are known from the data and the $p_i$ are determined by a function that has several parameters. For simplification consider $p_i = f(\theta)$, where $\theta$ contains some parameters for which the estimation was unproblematic. Now, for small levels $|x_i| $t \sim N(\mu,\sigma)$ So I added this layer setting up hyperpriors for $\mu$ and $\sigma$. The logic is that this threshold may vary normally for the individual observations. I'm not quite sure about the choice of the hyperprior distributions, though. Currently I use an inverse gamma on $\sigma$ and a uniform on $\mu$. In JAGS I defined the "blending situation" as follows: ... p[i] = t)*f(theta[i]) + (abs(x[i]) where f(theta) and g(theta) are quite complex terms with exponentials and different rate parameters. So the problem arises now when I run the MCMC (in JAGS). I set up monitors for all parameters including $t$, $\mu$, $\sigma$. I expected that mean($t$) would at least roughly correspond to the posterior of $\mu$ and sd($t$) to the posterior of $\sigma$, but they don't (depending on prior choices, especially the $\sigma$ if larger by factor 10 or more). Neither, the posterior of $t$ or the posteriors of $\mu$ and $\sigma$ match with the values previously obtained with non-Bayesian methods. When I simulate data points (posterior predictive check) they deviate from the data (as would be expected with these "wrong" $t$-estimates). So I would appreciate any hints regarding what may go wrong. Concretely, it would be helpful to know ... ... whether there is something fundamentally wrong with blending two functions (that return parameters for a distribution) with a threshold parameter like this in MCMC sampling. ... whether $\mu$ and $\sigma$ usually agree with the posterior statistics of a lower level parameter $t \sim N(\mu,\sigma)$. ... whether point estimates should be taken from the posterior of $t$ or of the posteriors of $\mu$ and $\sigma$. ... whether it could be that the model is too complex (it has also parameters that are likely correlated). ... whether the problem is likely to originate from wrong hyperpriors. ... whether when in a JAGS/BUGS model definition a parameter occurs twice (as $t$ in this case) one common sample or two independent samples are use (which in my situation would lead to the fact that the cases are not mutually exclusive as they are supposed to be). I'm sorry that the description of the problem got so long. I numbered the more concrete questions for reference in case someone can help with specific onces. However, any comments regarding this approach in general are also highly welcome. Many thanks and best regards Jan
