[site]: datascience
[post_id]: 63818
[parent_id]: 63761
[tags]: 
urllib parse seems like the function for you. With this you are able to extract keywords from the net location and the path separately if you desire to process them separately or even if you want to join them back again later. The result should look something like this: from urllib.parse import urlparse o = urlparse('https://www.forbes.com/sites/forbesagencycouncil/2018/09/06/how-to-use-content-marketing-to-boost-your-recruiting-efforts') ParseResult(scheme='https', netloc='www.forbes.com:443', path='sites/forbesagencycouncil/2018/09/06/how-to-use-content-marketing-to-boost-your-recruiting-efforts', params='', query='', fragment='') A second step will have to do with string parsing and string splits so something like .split("/") .split("-") Will work just fine to split the path of the example's URLs into words. Also, remember to transform each word into lowercase. After that stemming is a good idea so that all related terms are grouped into the same category. It's not necessary but it's a good idea. Finally counting the occurrences of the words will give you the rank of the top "keywords" in those URLs.
