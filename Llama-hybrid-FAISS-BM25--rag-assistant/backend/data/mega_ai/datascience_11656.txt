[site]: datascience
[post_id]: 11656
[parent_id]: 
[tags]: 
Overfitting for minority class after SMOTE w/ random forests

I used SMOTE to make a predictive model, with class 1 having 1800 samples and 35000+ of class 0 samples. Hence, as per SMOTE, synthetic samples were created and the random forest was trained. However, I am now getting most results as class 1 when I test my model. I just tried to test it on the training set and this is what I got: Without SMOTE With SMOTE I've also tried hyperparameter optimisation, but that hasn't worked Thanks PS: Used SMOTE implementation in pandas with UnbalancedDataset library
