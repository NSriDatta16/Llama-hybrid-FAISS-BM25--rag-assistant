[site]: datascience
[post_id]: 73606
[parent_id]: 
[tags]: 
Word2Vec with CNN

I am trying to classify documents using CNN (convolutional neural network) with Word2Vec embeddings. However to do this, it requires me to trim all texts to the same length. I just pad all the training documents to the size of the longest, and I don't think this is the best solutions, as during the testing phase, there can come a longer document and I may remove a significant part of it by trimming. I found that there is Doc2Vec, which may solve this problem, but I don't understand how it can be used in conjunction with CNN.
