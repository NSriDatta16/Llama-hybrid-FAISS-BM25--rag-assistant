[site]: crossvalidated
[post_id]: 383220
[parent_id]: 350897
[tags]: 
Let me explain. In stacking you split your data in two. One holdout set (10 - 20%). One training set (80 - 90%). You train your base learners individually on the training set using the same cross-validation method for each. You must use the same cross-validation fold indices for all base learners. This is because you can only train the metaclassifier on the predicted probabilities of those test-fold sections and the original raw data associated these rows; because these rows weren't used for building the base-learners. Note: Not a single training fold can overlap a testing fold. If row 37 is inside a test fold; it cannot occur in any training fold. Otherwise you will be passing information from layer to the next. Use 10 to 20% of the training set rows as test-folds. Now use each trained base learning to predict on the holdup set, and write new probability variables to it (Example: SVM_probs_up, LDA_probs_up). Once the metaclassifier is trained using the test-fold probabilities from each base learner + the raw data from the same rows, then use the meta-classier to predict on the holdout set for your final results. With Blending the training set is also split. But instead of using cross-validation you just take out 30% - 40% straight away (training-validation-set) and then train the base-learners on the remaining 60% - 70% of the training set. Then predict to training-validation-set and holdout-set, writing these as new variables to both sets. Then train the metaclassifier on the training validation set, then predict using the metaclassifier on the holdout set for your final results.
