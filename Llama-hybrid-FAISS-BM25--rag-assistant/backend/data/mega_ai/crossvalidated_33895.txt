[site]: crossvalidated
[post_id]: 33895
[parent_id]: 33888
[tags]: 
Causal theory offers another explanation for how two variables could be unconditionally independent yet conditionally dependent. I am not an expert on causal theory and am grateful for any criticism that will correct any misguidance below. To illustrate, I will use directed acyclic graphs (DAG). In these graphs, edges ( $-$ ) between variables represent direct causal relationships. Arrowheads ( $\leftarrow$ or $\rightarrow$ ) indicate the direction of causal relationships. Thus $A \rightarrow B$ infers that $A$ directly causes $B$ , and $A \leftarrow B$ infers that $A$ is directly caused by $B$ . $A \rightarrow B \rightarrow C$ is a causal path that infers that $A$ indirectly causes $C$ through $B$ . For simplicity, assume all causal relationships are linear. First, consider a simple example of confounder bias : Here, a simple bivariable regression will suggest a dependence between $X$ and $Y$ . However, there is no direct causal relationship between $X$ and $Y$ . Instead, both are directly caused by $Z$ , and in the simple bivariable regression, observing $Z$ induces a dependency between $X$ and $Y$ , resulting in bias by confounding. However, a multivariable regression conditioning on $Z$ will remove the bias and suggest no dependence between $X$ and $Y$ . Second, consider an example of collider bias (also known as Berkson's bias or berksonian bias, of which selection bias is a special type): Here, a simple bivariable regression will suggest no dependence between $X$ and $Y$ . This agrees with the DAG, which infers no direct causal relationship between $X$ and $Y$ . However, a multivariable regression conditioning on $Z$ will induce a dependence between $X$ and $Y$ , suggesting that a direct causal relationship between the two variables may exist when in fact, none exist. The inclusion of $Z$ in the multivariable regression results in collider bias. Third, consider an example of incidental cancellation: Let us assume that $\alpha$ , $\beta$ , and $\gamma$ are path coefficients and that $\beta = -\alpha\gamma$ . A simple bivariable regression will suggest no dependence between $X$ and $Y$ . Although $X$ is, in fact, a direct cause of $Y$ , the confounding effect of $Z$ on $X$ and $Y$ incidentally cancels out the effect of $X$ on $Y$ . A multivariable regression conditioning on $Z$ will remove the confounding effect of $Z$ on $X$ and $Y$ , allowing for the estimation of the direct effect of $X$ on $Y$ , assuming the DAG of the causal model is correct. To summarize: Confounder example: $X$ and $Y$ are dependent in bivariable regression and independent in multivariable regression conditioning on confounder $Z$ . Collider example: $X$ and $Y$ are independent in bivariable regression and dependent in multivariable regression conditioning on collider $Z$ . Incidental cancellation example: $X$ and $Y$ are independent in bivariable regression and dependent in multivariable regression conditioning on confounder $Z$ . Discussion: The results of your analysis are not compatible with the confounder example but are compatible with both the collider example and the incidental cancellation example. Thus, a potential explanation is that you have incorrectly conditioned on a collider variable in your multivariable regression and have induced an association between $X$ and $Y$ even though $X$ is not a cause of $Y$ and $Y$ is not a cause of $X$ . Alternatively, you might have correctly conditioned on a confounder in your multivariable regression that was incidentally cancelling out the true effect of $X$ on $Y$ in your bivariable regression. I find using background knowledge to construct causal models helpful when considering which variables to include in statistical models. For example, if previous high-quality randomized studies concluded that $X$ causes $Z$ and $Y$ causes $Z$ , I could make a strong assumption that $Z$ is a collider of $X$ and $Y$ and not condition upon it in a statistical model. However, if I merely had an intuition that $X$ causes $Z$ , and $Y$ causes $Z$ , but no strong scientific evidence to support my intuition, I could only make a weak assumption that $Z$ is a collider of $X$ and $Y$ , as human intuition has a history of being misguided. Subsequently, I would be skeptical of inferring causal relationships between $X$ and $Y$ without further investigating their causal relationships with $Z$ . In lieu of or in addition to background knowledge, there are also algorithms designed to infer causal models from the data using a series of tests of association (e.g. PC algorithm and FCI algorithm, see TETRAD for Java implementation, PCalg for R implementation). These algorithms are very interesting, but I would not recommend relying on them without a strong understanding of the power and limitations of causal calculus and causal models in causal theory. Conclusion: Contemplation of causal models does not excuse the investigator from addressing the statistical considerations discussed in other answers here. However, I feel that causal models can nevertheless provide a helpful framework when thinking of potential explanations for observed statistical dependence and independence in statistical models, especially when visualizing potential confounders and colliders. Further reading: Gelman, Andrew. 2011. " Causality and Statistical Learning ." Am. J. Sociology 117 (3) (November): 955–966. Greenland, S, J Pearl, and J M Robins. 1999. “ Causal Diagrams for Epidemiologic Research .” Epidemiology (Cambridge, Mass.) 10 (1) (January): 37–48. Greenland, Sander. 2003. “ Quantifying Biases in Causal Models: Classical Confounding Vs Collider-Stratification Bias .” Epidemiology 14 (3) (May 1): 300–306. Pearl, Judea. 1998. Why There Is No Statistical Test For Confounding, Why Many Think There Is, And Why They Are Almost Right . Pearl, Judea. 2009. Causality: Models, Reasoning and Inference . 2nd ed. Cambridge University Press. Spirtes, Peter, Clark Glymour, and Richard Scheines. 2001. Causation, Prediction, and Search , Second Edition. A Bradford Book. Update: Judea Pearl discusses the theory of causal inference and the need to incorporate causal inference into introductory statistics courses in the November 2012 edition of Amstat News . His Turing Award Lecture , entitled "The mechanization of causal inference: A 'mini' Turing Test and beyond" is also of interest.
