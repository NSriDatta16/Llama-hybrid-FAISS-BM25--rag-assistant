[site]: crossvalidated
[post_id]: 308513
[parent_id]: 
[tags]: 
ROC-AUC is higher than accuracy score - what does this mean?

I'm evaluating the performance of a trained neural network, and I'm getting the following stats: AUC-ROC: 0.91 accuracy: 0.85 How should I interpret this result? I'll add that the accuracy is a result of one-hotting the output and comparing it against the label, where as the AUC-ROC is calculated using the probabilistic (ie. range 0->1) output of a label. I'm not sure if it is correct to compare the metrics when doing this.
