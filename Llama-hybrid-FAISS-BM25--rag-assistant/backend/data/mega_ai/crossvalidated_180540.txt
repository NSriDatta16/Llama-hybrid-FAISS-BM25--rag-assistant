[site]: crossvalidated
[post_id]: 180540
[parent_id]: 180530
[tags]: 
I find it hard to deduce what you are after, but I am assuming that the task at hand is to recommend up to three TED talks based on a given transcript. If so, and given your bag-of-word recommendation you would essentially want to find up to three networks which are closest in feature representation as the input transcript. The most simple way to solve this using a neural network would be to train a (noisy) auto encoder on the transcripts that you have available. I would either choose for a noisy one, or reduce the dimension of the hidden state, such that the hidden state representation of the auto-encoder is forced to "learn" about the transcripts. In other words, it can not simply produce an identity transform. Then after having successfully trained such an auto-encoder I would put each transcript through this auto-encoder and then compare the hidden state representations of these transcripts to the hidden state representation of the input transcripts. This can be done by for example computing the mean squared error over the hidden state representation, after which you can select the 3 transcripts which match best. This approach is likely to work better then to directly compute the MSE over the feature representations of each transcript and compare them, as by forcing the auto-encoder to "compress" the feature representation (i.e. via noise or lower-dimensional hidden state) you will ensure that the hidden state representation captures more "high-level" characteristics of each transcripts. This higher level representations are likely (when compared) to yield better recommendations.
