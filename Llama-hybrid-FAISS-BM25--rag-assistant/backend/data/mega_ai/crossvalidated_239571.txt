[site]: crossvalidated
[post_id]: 239571
[parent_id]: 
[tags]: 
What is Contextual Embedding?

I understand word embeddings and word2vec. In this paper: https://arxiv.org/pdf/1603.01547.pdf they are saying a new type of word embedding. Our model uses one word embedding function and two encoder functions. The word embedding function e translates words into vector representations. The first encoder function is a document encoder f that encodes *every word from the document* d *in the context of the whole document*. We call this the **contextual embedding**. Is this some new way of encoding, How can I implement this? Thanks .
