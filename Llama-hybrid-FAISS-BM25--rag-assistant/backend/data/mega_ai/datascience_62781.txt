[site]: datascience
[post_id]: 62781
[parent_id]: 62765
[tags]: 
I cannot run the code, but I guess it's because scoring you've chosen, in particular, roc_auc . This metric/loss function is only for binary classification while you have a multiclass problem. You can try just accuracy_score , but it works bad when classes have different ratios in dataset. People on Kaggle very often use MultiClass Log Loss for this kind of problems. Here's the code, I found it here . import numpy as np def multiclass_log_loss(y_true, y_pred, eps=1e-15): """Multi class version of Logarithmic Loss metric. https://www.kaggle.com/wiki/MultiClassLogLoss idea from this post: http://www.kaggle.com/c/emc-data-science/forums/t/2149/is-anyone-noticing-difference-betwen-validation-and-leaderboard-error/12209#post12209 Parameters ---------- y_true : array, shape = [n_samples] y_pred : array, shape = [n_samples, n_classes] Returns ------- loss : float """ predictions = np.clip(y_pred, eps, 1 - eps) # normalize row sums to 1 predictions /= predictions.sum(axis=1)[:, np.newaxis] actual = np.zeros(y_pred.shape) rows = actual.shape[0] actual[np.arange(rows), y_true.astype(int)] = 1 vsota = np.sum(actual * np.log(predictions)) return -1.0 / rows * vsota However, I guess for GridSearchCV in sklearn it's not enough. You can use custom scorers like function above, but you need to add make_scorer decorator: NOTE that when using custom scorers, each scorer should return a single value. Metric functions returning a list/array of values can be wrapped into multiple scorers that return one value each. (from sklearn documentation) from sklearn.metrics import make_scorer @make_scorer def multiclass_log_loss(y_true, y_pred, eps=1e-15): # function from snippet above Pay attention to model outputs and inputs of this function, shape should be the same. Also, I would recommend reading GridSearchCV documentation - it may help as well.
