[site]: crossvalidated
[post_id]: 13321
[parent_id]: 
[tags]: 
Bayesian estimation of a mean with tighter constraints than the observations

The basic problem I have is very similar to a classic Bayesian estimation problem: there is a real valued parameters $p\in[0,1]$, that I would like to estimate via observations $o_i$. It is also the case that $$ p=\lim_{N\to\infty}{1\over N}\sum_{i=1}^N o_i, $$ so this problem is very closely analogous to estimating a probability. Here is the catch: $o_i\in[-1,1]$ Due to the similarity with estimating a probability, I would like to do something like a Bayesian update about my knowledge of $p$, where the prior would be a Beta distributed RV. However, since $p\in[0,1]$ it would seem like the prior would only have support in $[0,1]$, but that would mean that any $o_i\in[-1,0]$ would have not lead to any useful information about $p$, which is simply incorrect. On the other hand, if I have the prior have support over the whole $[-1,1]$ interval and perform the usual Bayesian update, the posterior distribution will indicate $\Pr(p\in[-1,0])\not=0$, which is also incorrect. What is the appropriate prior and update rule in this case? Has anyone seen problems similar to this one?
