[site]: crossvalidated
[post_id]: 187289
[parent_id]: 
[tags]: 
VAR lag selection heavily depends on maximum lag investigated

I am fitting an Error Correction Model with two monthly price time series. In Stata I am using the varsoc command to determine the number of lags that are appropriate. varsoc variable1 variable2 If I run varsoc with the default 4 maxlags , the suggested lag length using AIC/FPE is 3. However, if I run varsoc with maxlag(12) option, 12 lags are suggested. If I use maxlag(20) , 13 lags are suggested. Why is varsoc so sensitive to the number of maxlag ? If this is the case, how should I decide which maxlag to use? Running varsoc on the time series seperately yields 8 lags (if a larger maxlag is chosen).
