[site]: crossvalidated
[post_id]: 185995
[parent_id]: 
[tags]: 
Signal-to-noise ratio for probabilistic PCA

Consider the probabilistic PCA model where you have $n$ i.i.d centered obserbations $x_1,...,x_n\in \mathbb{R}^p$ drawn from $$\forall i\leq n, \; \; \; \; x_i = W y_i + \varepsilon_i,$$ where $W$ is an unknown deterministic $p \times d$ matrix, $y_i\sim\mathcal{N}(0,1)$ are i.i.d random latent vectors and $\varepsilon_i$ are i.i.d Gaussian noise terms of variance $\sigma^2$. The principal feature of this model is that the pricipal axes of the data can be found using the maximum-likelihood estimator of $W$ (hence the name probabilistic PCA). For more details about PPCA, the following classical article by Tipping and Bishop is easily accessible online: M. Tipping, C. Bishop, Probabilistic Principal Component Analysis , Journal of the Royal Statistical Society (Series B) , 61, pp. 611â€“622 (1999) How would you define a signal-to-noise ratio for this model ? A natural way would be to divide the "variance" of $W y_i$ by $\sigma^2$ however I encounter two problems: $W$ is unknown so is it okay to replace it by some estimate ? even if $W$ were known, how would you define the "variance" of the vector $W y_i$ ? Simply taking the trace of its covariance matrix (which is $W W^T$) seems a bit arbitrary but could be a simple way to do it.
