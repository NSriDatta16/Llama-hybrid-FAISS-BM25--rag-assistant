[site]: crossvalidated
[post_id]: 439224
[parent_id]: 91473
[tags]: 
Your model assumes the success of a nest can be viewed as a gamble: God flips a loaded coin with sides labeled "success" and "failure." The outcome of the flip for one nest is independent of the outcome of the flip for any other nest. The birds do have something going for them, though: the coin might heavily favor success at some temperatures compared to others. Thus, when you have the chance to observe nests at a given temperature, the number of successes equals the number of successful flips of the same coin --the one for that temperature. The corresponding Binomial distribution describes the chances of successes. That is, it establishes the probability of zero successes, of one, of two, ... and so on through the number of nests. One reasonable estimate of the relationship between the temperature and how God loads the coins is given by the proportion of successes observed at that temperature. This is the Maximum Likelihood estimate (MLE). For example, suppose you observe $7$ nests at a temperature of $10$ degrees and $3$ of those nests are successful. The MLE is $3/7.$ That is, we estimate that God's coin has a $3/7$ chance of showing success. The corresponding Binomial distribution is plotted in the first row of the figure (see below) under the heading "10 Degrees." It represents the chances with the heights of vertical line segments. The red segment corresponds to the observed value of $3$ successes. The temperatures must vary in your data. As a running example, let's suppose that at temperatures $5,10,15,20$ degrees you observed $0,3,2,3$ successes among $2,7,5,3$ nests. This dataset is plotted by the gray circles in the "Fit" panels of the figure. The height of a circle represents its success rate. The circle areas are proportional to the numbers of nests (thereby emphasizing the data with more nests). The top row of the figure shows the MLEs at each of the four observed temperatures. The red curve in the "Fit" panel traces out how the coin is loaded, depending on temperature. By construction, this trace passes through each of the data points. (What it does at intermediate temperatures is unknown; I have crudely connected the values to emphasize this point.) This "saturated" model is not very useful, precisely because it gives us no basis to estimate how God will load the coins at intermediate temperatures. To do that, we need to suppose there is some kind of "trend" curve that relates coin loadings to temperature. The bottom row of the figure fits such a trend. The trend is limited in what it can do: when plotted in appropriate ("log odds") coordinates, as shown in the "Logit Response" panels at left, it can only follow a straight line. Any such straight line determines the loading of the coin at all temperatures, as shown by the corresponding curved line in the "Fit" panels. That loading, in turn, determines the Binomial distributions at all temperatures. The bottom row plots those distributions for the temperatures where nests were observed. (The dashed black lines mark the expected values of the distributions, helping to identify them fairly precisely. You don't see those lines in the top row of the figure because they coincide with the red segments.) Now a tradeoff must be made: the line might pass closely to some of the data points, only to veer far from others. This causes the corresponding Binomial distribution to assign lower probabilities to most of the observed values than before. You can see this clearly at 10 degrees and 15 degrees: the probability of the observed values is not the highest possible probability, nor is it close to the values assigned in the upper row. Logistic regression slides and wiggles the possible lines around (in the coordinate system used by the "Logit Response" panels), converts their heights into Binomial probabilities (the "Fit" panels), assesses the chances assigned to the observations (the four right panels), and chooses the line that gives the best combination of those chances. What is "best"? Simply that the combined probability of all the data is as large as possible. In this way no single probability (the red segments) is allowed to be truly tiny, but usually most of the probabilities will not be as high as they were in the saturated model. Here is one iteration of the logistic regression search where the line was rotated downwards: First, notice what stayed the same: the gray points in the "Fit" scatterplot are fixed because they represent the data. Likewise, the ranges of values and the horizontal positions of the red segments in the four Binomial plots also are fixed, because they also represent the data. However, this new line loads the coins in a radically different way. In so doing, it changes the four Binomial distributions (the gray segments). For instance, it gives the coin about a 70% success rate at a temperature of $10$ degrees, corresponding to a distribution whose probabilities are highest for 4 to 6 successes. This line actually does a great job of fitting the data for $15$ degrees but a terrible job of fitting the other data. (At 5 and 20 degrees the Binomial probabilities assigned to the data are so tiny you cannot even see the red segments.) Overall, this is a much worse fit than the ones shown in the first figure. I hope this discussion has helped you develop a mental image of the Binomial probabilities changing as the line is varied, all the while keeping the data the same. The line fit by logistic regression attempts to make those red bars overall as high as possible. Thus, the relationship between logistic regression and the family of Binomial distributions is deep and intimate. Appendix: R code to produce the figures # # Create example data. # X $p.hat temperature), max(X $temperature), length.out=101)) Y$ p.hat $lambda.hat lambda.hat))
