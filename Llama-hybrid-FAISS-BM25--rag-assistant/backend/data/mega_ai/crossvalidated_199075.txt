[site]: crossvalidated
[post_id]: 199075
[parent_id]: 198994
[tags]: 
Let's interpret "computing the arithmetic mean" as estimation using the Method of Moments (MoM). I believe that's faithful to the original question since the method substitutes sample averages for theoretical ones. It also address @Xi'an's concern about an arbitrary parameter (from an arbitrary model). If you're still with me, then I think a great place to go is Examples where method of moments can beat maximum likelihood in small samples? The question text points out that "Maximum likelihood estimators (MLE) are asymptotically efficient; we see the practical upshot in that they often do better than method of moments (MoM) estimates (when they differ)," and seeks specific cases where MoM estimators achieve a smaller mean squared error than its MLE counterpart. A few examples that are provided are in the context of linear regression, the two-parameter Inverse Gaussian distribution, and an asymmetric exponential power distribution. This idea of "asymptotic efficiency" means that maximum likelihood estimators are probably close to using the data to its fullest potential (to estimate the parameter in question), a guarantee you don't get with method of moments in general. While maximum likelihood is not always "better" than working with averages, this efficiency property (if only in the limit) makes it a go-to method for most frequentists. Of course, the contrarian could argue that with the increasing size of data sets, if you're pointing at the right target with a function of averages, go with it.
