[site]: crossvalidated
[post_id]: 612072
[parent_id]: 
[tags]: 
Do imbalanced datasets make removing poor target predictors easier?

I have an imbalanced fraud dataset with ~ $1.4$ % fraudulent samples across 50,000 rows with 600 columns. I'm performing a binary classification task on this dataset. I've performed an EDA; some columns are $99$ % the same value. The $1$ % of entries that are not the same have a lower fraud rate of ~ $1$ %. I believe that makes this column predictive of "non-fraud". But is that useful to me when the dataset's average is so strongly predictive of fraud anyway? My intuition is no, because of the imbalance. I think it's okay to drop these columns from the feature selection process. Is that a sensible practice when dealing with a highly imbalanced dataset? Edit: This is a follow up to this question: What should you do with near constant columns? I consider this question different because I'm asking about a specific subset of near-constant columns that I believe should be removed, given the imbalanced nature of my dataset. Instead of asking about near-constant columns being removed in general.
