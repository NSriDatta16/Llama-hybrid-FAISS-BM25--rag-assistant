[site]: crossvalidated
[post_id]: 602296
[parent_id]: 601970
[tags]: 
I gave some replies in the the comments, so here I will try to work with the suggested data generation process, where: $$ y_j = \int dx\,K_j\left(x\right)\cdot f\left(x\right) $$ I am not sure what the $\int_j$ means, domain that depends on the variable? I think this can be incorporated into the $K_j$ , so let the domain stay general. The aim is to find $f$ and the current method of approximation is splines, which can be expressed as: $$ f\left(x\right)=\sum_i\,a_iq^{(i)}\left(x\right) \quad or\quad f\left(x\right)=\sum_{ik}\,a_{ik} q^{(ik)}\left(x\right) $$ Where $q^{(i)}\left(x\right)$ could be $x^i$ , for series expansion, but could also be something like: $$ q^{(ik)}=\begin{cases}x^i,\,x\in \Omega_k\\ 0,\,otherwise\end{cases} $$ which would accommodate splines ( $\Omega_k$ is some domain where piecewise polynomial is used). You may need to re-use the same coefficients within different spline functions to get continuity right, this can be dealt with appropriately with a similar formalism, it would still be a sum of functions multiplied by some coefficients, which you want to find. Next, let $$ b_j^{ik}=\int\,dx\,K_j\left(x\right) \,q^{(ik)}\left(x\right) $$ These integrals can be computed analytically or numerically, but it should be a finite one-off as I understand, so should be ok. The problem is then reduced to $$ y_{j}=\sum_{r} b^{(r)}_j a_r $$ Where $r$ runs either over $i$ or ${ik}$ combinations. The problem is thus reduced to linear-algebra type exercise. One easy way to tackle it, with uncertainty, is to let $a_r$ be multivariate normal (which is what you would have been assuming if you were fitting with least squares anyway), and use conjugate Bayesian approach , which is fully analytic (for multivariate normal likelihood). All you will need to do is to handle the matrix multiplication by $b^{(r)}_j$ (it will transform your covariance matrix). So this way you should be able to handle very many params and still get uncertainty handled. You could also use SVD to decompose the matrix $b^{(r)}_j$ and thus reduce it to problem of univariate normal likelihood, and then apply conjgate approach. This will also offer an opportunity to explicitly set some small eigenvalues to zero, which will serve as a regularization
