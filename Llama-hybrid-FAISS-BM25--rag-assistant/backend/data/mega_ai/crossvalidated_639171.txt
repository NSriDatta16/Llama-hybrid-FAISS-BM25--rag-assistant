[site]: crossvalidated
[post_id]: 639171
[parent_id]: 
[tags]: 
VAE with linear decoder and nonlinear encoder, does this just learn a linear decomposition of the data?

There are a number of variational autoencoder(VAE) methods that have nonlinear encoders and linear decoders. The concept of using the linear decoder is to improve the interpretability (which features does the latent variable contribute to) of the VAE. The weights in the decoder will inform us of which features are more important for each latent variable in the VAE. A VAE statistically can be broken up into two parts, the encoder network (inference network) and latent distribution with the decoder (generative model). The generative network is analogous to the statistical model of the VAE. Thus, if the generative model is linear won't the method be a linear decomposition of the data? Irrespective of the encoder being nonlinear. So is there really a need for the encoder to be nonlinear, unless it benefits for inference or training reasons. Papers with such methods. VEGA: VEGA is an interpretable generative model for inferring biological network activity in single-cell transcriptomics LDVAE: Interpretable factor models of single-cell RNA-seq via variational autoencoders
