[site]: crossvalidated
[post_id]: 509774
[parent_id]: 408719
[tags]: 
There are two main ways for handling observations that are not actually Gaussian: Keep using a Gaussian likelihood (noise model), but in a transformed space. I.e., instead of modelling $y = f(x) + \epsilon$ where the noise is normal-distributed, $\epsilon \sim \mathcal{N}(0, \sigma^2)$ , using $g(y) = f(x) + \epsilon$ . Your transform $g(\cdot)$ can be deterministic - a common choice is the log-transform, particularly if your observations $y$ are constrained to be positive. This means you are still doing exact GP regression. You can also learn the transform as in a Warped Gaussian process . Use a more appropriate likelihood, this depends very much on your problem. But the equivalent to the log-transform above would be a Log-Normal likelihood function. Then the GP model is no longer closed-form, and you will have to do some kind of approximation (e.g. MCMC, Expectation Propagation, or variational inference - see this video ).
