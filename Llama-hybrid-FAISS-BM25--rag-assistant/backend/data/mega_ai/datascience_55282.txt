[site]: datascience
[post_id]: 55282
[parent_id]: 53438
[tags]: 
You can try a leave-one-out cross validation (LOOCV) scheme. If you have $n$ data points, create $n-1$ models. For each model, the training set the entire data set minus one point, the testing set only being that one point, for each point. You can average the error on the unseen point as an unbiased estimate. I would also look into Random Forests, they will allow you to combine the entire data set and use bagging to find estimates of performance.
