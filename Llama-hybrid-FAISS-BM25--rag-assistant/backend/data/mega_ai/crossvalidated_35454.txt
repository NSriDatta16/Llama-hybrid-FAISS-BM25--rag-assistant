[site]: crossvalidated
[post_id]: 35454
[parent_id]: 
[tags]: 
Distance invariant approaches to find the "main" difference between two distributions in R$^n$

If I have a population of vectors in R$^n$ and some special subset has a different distribution, I could try and use PCA to describe the main axes of these distributions and, if they are aligned differently, that would give me a quick way to describe the difference in orientation between the two. However PCA is dependent on the scale of the components of the vectors. So what is an analagous approach that can cleanly describe the "main" difference in the the two populations given that they have different covariance matrices, but doesn't depend on the scaling given to the componenents? It is possible the answer is more easily stated in terms of the two Mahalanobis distances one gets from the two distributions. Anyway, I'm sure there is a standard way to describe the "main" difference between two such distributions, but I don't know what it is. P.S. Yes, assume they have the same mean.
