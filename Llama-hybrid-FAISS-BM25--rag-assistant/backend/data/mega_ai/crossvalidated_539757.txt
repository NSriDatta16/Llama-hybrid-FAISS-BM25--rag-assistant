[site]: crossvalidated
[post_id]: 539757
[parent_id]: 
[tags]: 
Dynamically adjusting parameters of Markov chain

I am using a Metropolis algorithm to generate samples from a complicated (high-dimensional) probability distribution. As is common, the proposed updates depend on some "step size" parameter $\epsilon$ , such that too small $\epsilon$ leads to very small updates and thus long auto-correlations too large $\epsilon$ leads to small acceptance-rates and thus long auto-correlations. Common wisdom is that one should choose $\epsilon$ such that the overall acceptance probability is somewhere in the 50%-90% range in order to optimize for autocorrelation times. Usually this tuning is done by hand, i.e. using a couple of trial runs. No the question: Is it valid to adjust $\epsilon$ dynamically during the Markov process? By "valid" I mean, is the stationary distribution of the process still the same? For example I could track the acceptance-rate so far, and: If the rate is $ , decrease $\epsilon$ a little If the rate is $>0.9$ , increase $\epsilon$ a little I could do this automatic adjustment after every step. I dont see why this would be wrong (after all, the stationary distribution does not depend on $\epsilon$ ). But it seems very fishy to me to make the simulation parameters dependent on the simulation results. Could someone help me to wrap my head around this?
