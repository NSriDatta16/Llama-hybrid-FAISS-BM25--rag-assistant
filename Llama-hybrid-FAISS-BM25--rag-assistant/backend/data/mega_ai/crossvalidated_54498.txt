[site]: crossvalidated
[post_id]: 54498
[parent_id]: 
[tags]: 
Does every log-linear model have a perfectly equivalent logistic regression?

I am trying to fit a log-linear model to a large number of variables from survey data. There are some reasons that it might be preferable to fit logistic regressions to that data instead. Several authorities suggest that these are equivalent. However, I have some reasons to doubt this. Log-linear models treat all variables equivalently, while logistic regression requires that one variable be identified as the response variable. In the least-squares context, it is not generally the case that for Y = a+bX + ε versus X = c+dY + ε the parameter d is even approximately equal to 1/b. This is because the first equation minimizes vertical error, while the second minimizes horizontal error. These will be equal only if the errors are symmetrical around the estimated line. So I am worried that this might be true of the logistic regression also. (2) is actually just a specific form of (1), i. e. a possible asymmetry in the regression format from the choice of a particular variable as response. If all the variables in the log-linear model are involved in one or more interaction terms, I do not see how a logistic regression can be equivalent. How would one express the interactions in which the response variable is involved in the context of a logistic regression? In response to Bill Huber, I am using the term log-linear model in a considerably more restricted sense than Wikipedia. I am referring to models of categorical or ordinal count data, arranged in tables, where the coefficients are the total table count, the marginal counts for each factor divided by the total table count (serving as proxies for probabilities), and various interaction terms. This is the sense used in Agresti, “Categorical Data Analysis”, among others.
