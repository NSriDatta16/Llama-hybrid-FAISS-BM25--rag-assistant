[site]: datascience
[post_id]: 65781
[parent_id]: 51136
[tags]: 
I just want to stress an important point: ConvLSTM() layers have been excluded from the new TensorFlow 2.0 , which is largely based on Keras in models' specification. It is substituted by ConvLSTM2D() layers, that take different arguments as input. (see docs here ). (An alternative is to manually create a combination of Conv2D() and LSTM() layers.) That is to say that ConvLSTM() layers might disappear in the not-too-distant future, and that studying how ConvLSTM2D() layers work might be a good investment. However, coming to your questions: in keras, the convLSTM layer does not require a timestep argument. So I assume it infers the number of timesteps from the input_shape. Is my understanding correct ? When working with RNNs, you should specify the lenght of the input series (the number o ftimesteps) from within input_shape . is the above understanding regarding a convLSTM layer shape correct ? I'm not sure I understood what you're asking here. What do you mean with: I should pad my input data with "blank" radar images. Indeed, this seems the way to create a many to many convLSTM layer where I need to predict timesteps ahead. ? How should I use these outputs to perform the desired regression You can predict: one value at a time, with one output node at the end of the model, and then iterate prediction many values at a time, with multiple output nodes use a seq2seq model, in which you predict a sequence of the same length of the input, but shifter forward of one o more steps This is all up to your preferences/needs. why batch normalization is useful It's very useful between Convolutional and Dense layers, it's a regularization technique that helps activation functions work as expected, and allows the model to better capture non-linearities. However, I don't recommend using with Recurrent architectures, since the distortion of the output time series would decrease model's quality. (Please keep in mind this is just a personal opinion.)
