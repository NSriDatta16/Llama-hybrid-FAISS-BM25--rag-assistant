[site]: datascience
[post_id]: 106400
[parent_id]: 105155
[tags]: 
YOLO is an object detection algorithm, considering your usecase of recognising alphanumeric characters it would be ideal to go for OCR (optical character recognition) which works great for written and handwritten characters. It's also ideal to opt for text detectors like EAST or CRAFT . I would suggest to go for keras OCR which is a packaged version of CRAFT text detector and Keras CRNN recognition model. Another one is Tesseract which is an optical character recognition engine supporting various operating systems. Now coming to your questions at hand. SIZE of dataset for training : A minimum 1500 images per class * is recommended as per official YOLOv5 documentation, best performance tips *. However this will vary based on your chosen model. They have mentioned YOLOv5 provides best results for Datasets with Images per class : $≥1.5k$ images per class Instances per class . $≥10k$ instances (labeled objects) per class total Image variety : Recommends images from different times of day, different seasons, different weather, different lighting, different angles, different sources (scraped online, collected locally, different cameras) etc. Label consistency . All instances of all classes in all images must be labelled. Partial labelling will not work. Label accuracy. Labels must closely enclose each object. No space should exist between an object and it's bounding box. No objects should be missing a label. Background images. Background images are images with no objects that are added to a dataset to reduce False Positives (FP). We recommend about 0-10% background images to help reduce FPs (COCO has 1000 background images for reference, 1% of the total) Rotation of Text and shapes $≥40$ % of rotated alphanumeric images is a good ratio to consider. There are couple of things you need to also keep in mind, Fonts distinction whilst rotation of images ensuring the following will be correctly identified. Also Keep in mind how various fonts would affect in recognising these combinations of alphabets and numbers when rotated ( W,M ) (6,9) (P, d) (L,7) (I,1) (Z,N) (0,O) (V,^, ) if you are also considering symbols Label Creation There are many open source labeling tools LabelIMG, Labelbox, ImageTagger, LabelMe These are the top software for labelling: SuperAnnotate, Appen, Amazon Sagemaker Ground Truth, V7, Dataloop, Hive Data and Innotescus Video and Image Annotation Platform PreProcessing steps : Image preprocessing for OCR handwritten characters follows the below steps image binarization waste clearing or waste filtering algorithms text lines detection character detection This research paper explains various transformation processes image enhancement (reducing the noise and detecting the useful objects), binarization (excluding information redundancy), and allocation of dot matrix ﬁelds. Discrete smoothing to binary image, which helps to eliminate some noise(blurred boundaries, obliterated corners, separate points) References EAST : An Efficient and Accurate Scene Text Detector:[LINKS: Research paper ] CRAFT : Character-Region Awareness For Text detection: [LINKS: Research paper | Github | Project ] R2CNN : Rotational Region CNN for Orientation Robust Scene Text Detection Rotation-Sensitive Regression for Oriented Scene Text Detection keras OCR Image preprocessing for OCR handwritten characters Preprocessing of alphanumeric images to be recognized by autonomous computing systems
