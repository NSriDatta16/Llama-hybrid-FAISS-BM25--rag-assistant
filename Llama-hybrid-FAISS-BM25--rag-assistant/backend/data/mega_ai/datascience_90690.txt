[site]: datascience
[post_id]: 90690
[parent_id]: 87093
[tags]: 
The dimensions for an embedding space are only be accidentally interpretable. However, vectors through the space can be interpretable. That is why word analogies are possible in an embedding space . The addition / subtraction of word vectors describe another vector through the embedding space. For example, "king" - "man" + "woman" approximate the "queen" vector. Words are consistently used in relationship to other words. Word embeddings can model these consistent relationship by finding which words co-occur together and projection the words into lower dimension space that retains the most common occurrences.
