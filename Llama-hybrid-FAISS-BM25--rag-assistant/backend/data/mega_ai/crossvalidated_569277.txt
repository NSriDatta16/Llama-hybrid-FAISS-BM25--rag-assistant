[site]: crossvalidated
[post_id]: 569277
[parent_id]: 
[tags]: 
loss bounded below when using MSE regardless of the model I choose, is this normal?

I've been experimenting with regression models and when checking the loss of some models (MLP, RNN, CNN) I constructed using MSE, the evaluation loss is bounded below by 1.1331, and the training loss is bounded below by 1.1101 (except for the MLP model which has higher bounds) All 3 models are using the same test/ train data. Is this to be expected? I feel that the models reach the bound very quickly and there must be something going wrong.
