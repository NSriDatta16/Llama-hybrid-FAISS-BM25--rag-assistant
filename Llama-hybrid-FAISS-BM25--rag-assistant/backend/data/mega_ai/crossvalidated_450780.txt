[site]: crossvalidated
[post_id]: 450780
[parent_id]: 
[tags]: 
sklearn f1_score=weighted not matching sample_weight specification

I am trying to figure out exactly what this is doing: sklearn.metrics.f1_score(y_pred, y_test, sample_weight=[...]) Numerically it simply does not seem to be consistent with whatever the average='weighted' parameter is doing. For example, I have y_test in a Pandas Series. I also put y_pred in a corresponding Series with matching index. counts = y_test.value_counts().sort_index() weights = 1/counts f1_score(y_pred, y_test, average='macro') # -> 0.8797748729121277 f1_score(y_pred, y_test, average='weighted') # -> 0.9139386189258313 I am not here worried about exactly why those vary, or the degree to which they do. I understand the idea of weighting the per-label score by its support. It seems like I should be able to get the same answer by manually specifying sample_weights: f1_score(y_pred, y_test, average='macro', sample_weight=y_test.map(counts)) # -> 0.7868154451418584 Clearly this is numerically different. If I assign the sample weights based on y_pred I get a number that is close to, but not identical with, the simple macro averaging. What's actually happening numerically behind the scenes? FWIW, prediction_score and recall_score show similar behavior where I cannot get a numeric match between average=weighted and a manual sample_weight. As a secondary question, why is weighting based on support rather than exactly the inverse?! It seems intuitive that getting uncommon targets right should be more important rather than less important. I can do that manually with sample_weight, but I'd really like to understand more accurately exactly what is happening with either.
