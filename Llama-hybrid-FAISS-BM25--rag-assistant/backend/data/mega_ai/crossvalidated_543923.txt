[site]: crossvalidated
[post_id]: 543923
[parent_id]: 182807
[tags]: 
Yes. This happens even when people don't want it to. It happens when people train catagorization networks with very unbalanced datasets, then network will often catagorize every input as the most common class in the training set. It also happens in GANs, with so called " mode collapse ", where the generative portion of the network learns to produce a single output that always tricks the adversarial part.
