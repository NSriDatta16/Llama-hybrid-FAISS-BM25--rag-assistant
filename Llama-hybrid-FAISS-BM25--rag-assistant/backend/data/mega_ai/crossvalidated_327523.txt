[site]: crossvalidated
[post_id]: 327523
[parent_id]: 327496
[tags]: 
The loss function calculates the difference between an output vector (that can have a single dimension, in which case it is a scalar), and the expected output vector (again, it can have a single dimension). EDIT : Vector here means an ordered list of scalars. (Furthermore, there is dependence between those scalars in the multiclass case, if they represent a probability : their sum is 1). The neural network doesn't do dot products, it does matrix multiplication, between the input (vector, aka N*1 matrix) and a weight matrix. Supplementary note : For classification, the output of typical networks is a multi dimensional vector representing the probability of each class (as predicted by the network, generally indicating the confidence of the network in its prediction). The loss function used in such cases is typically cross entropy, not euclidian distance. There are other techniques (changing the representation of the output and/or the loss function), but this is the more standard approach.
