[site]: crossvalidated
[post_id]: 117346
[parent_id]: 
[tags]: 
Use of infinity norm instead of SSE for machine learning accuracy?

Are there any examples or arguments in favor of using an infinity norm (or equivalent) over sum of squared errors or root mean squared error for evaluating machine learning algorithms?
