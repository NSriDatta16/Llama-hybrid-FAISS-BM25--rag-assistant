[site]: crossvalidated
[post_id]: 641144
[parent_id]: 
[tags]: 
How can I compute a counterfactual query for discrete binary variables?

In computing counterfactual queries for structural causal models (SCMs), J. Pearl says to go through 3 steps. Abduction Action Prediction In his book, Causal Inference in Statistics, he shows how to compute a counterfactual query for a SCM with continuous variables where the relationships are modeled as linear regression models. I am wondering if it is possible to compute a counterfactual query when the SCM models the relationships as non-linear models (e.g. Random Forest Classifier, let's say). The model relationship could be as follows, where $f_H$ and $f_Y$ could be any machine learning model handling discrete data (to make it simple, let's just say $X, H, Y$ are binary). In fact, I tried computing a counterfactual query with scikit-learn's RandomForestClassifier. $X = U_X$ $H = f_H (X) + U_H$ $Y = f_Y (X, H) + U_Y$ In abduction, given some observation that has happened, $\{X=x, H=h, Y=y\}$ , I compute $U$ . I am using Random Forest Classifier and the predict_proba() function. $U_X = X$ $U_H = H - f_H(X)$ $U_Y = Y - f_Y(X, H)$ In action, I set H=2. Finally, in prediction, I compute the following. $Y_{H=2} = f_Y (X, H=2) + U_Y$ Although something is computed at the end with the prediction step, I am not sure how to interpret it, as I expect the values to be a probability in the range $[0, 1]$ , but, I see values $Y_{H=2} > 1$ depending on how I play around with with the inputs. Here are my questions/concerns. Is this approach wrong although it follows in shape and form the three steps in computing counterfactuals? If it's wrong, is there an example of how to apply the 3 steps to discrete data? What is the interpretation when $Y_{H=2} > 1$ ? I think this question is moot if the answer to the first question above clarifies that this approach is not the right way to compute counterfactual queries with discrete data.
