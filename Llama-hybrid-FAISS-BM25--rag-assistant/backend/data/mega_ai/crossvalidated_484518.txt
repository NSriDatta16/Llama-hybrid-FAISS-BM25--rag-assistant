[site]: crossvalidated
[post_id]: 484518
[parent_id]: 
[tags]: 
Gibbs sampling proposals for bivariate normal?

I'm very familiar with Metropolis-Hastings, having implemented the algorithm myself to handle "toy problems." Gibbs sampling, however, is a bit trickier for me as I'm not quite certain what is/isn't required. I gather it flows as follows: for i in iterations: x_i+1 = P(x|y = y_i) y_i+1 = P(y|x = x_i+1) After some number of "burn in" iterations, the sampler will converge on the true target distribution. This is all well and good but I'm unclear on a few points: Are these conditional distributions derived manually? If so, how are points proposed? (I understand the acceptance to always be 100% in Gibbs) Some problems, like image denoising, use actual tabular data; is data typically provided to a Gibbs sampler? To make things more concrete, I'd like help sampling from a fictitious example. Say I want to sample from the bivariate normal distribution N(mean=[0,1],cov=[[1,0.75],[0.75,0.5]]) . Is the conditional distribution simply derived via Bayes rule? P(x|y) = P(x,y)/P(y) = N(mean=[0,1],cov=[[1,0.75],[0.75,0.5]]) / N(mean=0,sigma=1) P(y|x) = P(x,y)/P(x) = N(mean=[0,1],cov=[[1,0.75],[0.75,0.5]]) / N(mean=1,sigma=0.5) To me this seems a bit like circular logic. How can we sample from this conditional distribution if it references a joint distribution and the whole point is to get the joint distribution? Likewise, I'm not sure how points from these conditional distributions are proposed. I understand that "Metropolis within Gibbs" exists, but at this point I'm more interested in "vanilla Gibbs". To answer this question, please help me organize a design to sample from the mentioned bivariate normal with an eye for the questions laid out above. Thank you!
