[site]: datascience
[post_id]: 777
[parent_id]: 
[tags]: 
Getting GitHub repository information by different criteria

New to the Data Science forum, and first poster here! This may be kind of a specific question (hopefully not too much so), but one I'd imagine others might be interested in. I'm looking for a way to basically query GitHub with something like this: Give me a collection of all of the public repositories that have more than 10 stars, at least two forks, and more than three committers. The result could take any viable form: a JSON data dump, a URL to the web page, etc. It more than likely will consist of information from 10,000 repos or something large. Is this sort of thing possible using the API or some other pre-built way, or am I going to have to build out my own custom solution where I try to scrape every page? If so, how feasible is this and how might I approach it?
