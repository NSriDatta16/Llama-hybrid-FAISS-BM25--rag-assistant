[site]: datascience
[post_id]: 10715
[parent_id]: 10713
[tags]: 
If the feature is discrete/categorial/binary, it won't use the already used feature to split at further levels in any given branch of the tree. But key thing to note here is that the same feature can be used in a different branch of the tree at a different level. In the above diagram, we can see that same 'size' feature has been used at two levels 'level 1' and 'level 2', but in different branches of the tree. On the other hand, if the variable is a continuous value, it uses threshold splits at each level and in this case, same feature can be used multiple times in any given branch of the decision tree. Since random forests is an ensemble of decision trees, the same theory applies to Random Forests as well. Reference: http://www.cse.msu.edu/~cse802/DecisionTrees.pdf
