[site]: stackoverflow
[post_id]: 4400951
[parent_id]: 4207641
[tags]: 
I have some suggestions: For IO-bound benchmark, before each test run, load the entire data from a dump into the server. Then shut the server down and start it up again. The initial queries in your test suite will need to do physical IO to read the blocks. Subsequent ones will benefit from the earlier ones bringing pages into cache. For memory-bound benchmark, do the same, but don't shut the server down after loading the data. I am assuming of course, that such a small (50M rows == small) table will fit into memory (Your 8G buffer pool divided by 50M rows = 170 bytes average per row). If it doesn't, revise the above. If you are interested in the newer innodb engine, be sure to use "Barracuda" file format (which needs to be set in the config file, at server startup, before you create any tables) to take advantage of the new features. Then you can test with compression enabled (which will make the data smaller and may at least speed up the IO-bound tests a bit). Depending on your application, you may also want to try it on a large table. This will of course need a lot longer to run (presumably loading 50M rows is pretty quick).
