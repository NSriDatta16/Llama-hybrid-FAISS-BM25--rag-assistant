[site]: crossvalidated
[post_id]: 545062
[parent_id]: 
[tags]: 
Making Sense of Differences Between Durbin-Watson Test, ACF, and auto.arima

Trying to make sense of my results. I'm trying to assess if an intervention had an effect on infection rates using an interrupted time series design. I have monthly data on infection rates for approximately 4 years. I developed a simple segmented regression design, and following advice from articles I've read like this one . I ran a Durbin-Watson test on the residuals from my model (with infection as the dependent and time as independent), and, lo and behold, the test statistic = 1.24 and p = 0.001. I went ahead with trying to select an ARIMA model. When mapping the ACF, I see the following: I took a look at the output from auto.arima from the forecast package, which suggested a regression with ARIMA(0,0,0) errors, which I understand would be the same thing as my initial linear regression. The AIC of the (0,0,0) and the (1,0,0) are extremely similar (within .01 of each other) but I'm not sure that the difference is meaningful. My question is, what do I make of the suggestion of AR(1) from the DW test in light of no other evidence of autocorrelation? Am I missing / violating some assumption of the DW test that renders it unusable in this situation? I'd like to use the simpler model for the benefit of my audience if possible, but I'd like my conclusions to be as strong as possible. I'm a final year student in a medicine program, please forgive me if I've missed some introductory concept here. I also included a plot of the residuals from the linear model. I see what looks like a strong negative correlation from index 20 - 25. That's not related temporally to my intervention, I was wondering if this is what's driving the positive DW test.
