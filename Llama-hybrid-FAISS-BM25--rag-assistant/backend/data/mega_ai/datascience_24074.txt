[site]: datascience
[post_id]: 24074
[parent_id]: 24063
[tags]: 
Essentially you are correct, there are a lot of calculations necessary to process inputs and train neural networks. You have some terminology a bit wrong or vague. E.g. In a feedforward meural network each neuron of the first layer multiplied with all the neurons of the second layer. The neurons do not multiply together directly. A common way to write the equation for a neural network layer, calling input layer values $x_i$ and first hidden layer values $a_j$ , where there are N inputs might be $$a_j = f( b_j + \sum_{i=1}^{N} W_{ij}x_{i})$$ where $f()$ is the activation function $b_j$ is the bias term, $W_{ij}$ is the weight connecting $a_j$ to $x_i$ . So if you have $M$ neurons in the hidden layer, you have $N\times M$ multiplications and $M$ separate sums/additions over $N+1$ terms, and $M$ applications of the transfer function $f()$ And in addition to a forward pass in a typical Neural network they also have a backward pass that because of my calculations doing earlier they are 1,800 derivatives (gradient) for the entire backward pass. It doesn't work quite so directly, and there as a small factor of more calculations involved (you do not calculate each derivative with a single multiplication, often there are a few, some results are re-used, and other operations may be involved). However yes you do need to calculate a derivative for each weight and bias term, and there are roughly that number of weights in your network that require the calculations done. Your suggested numbers are actually quite small compared to typical neural networks used for image problems. These typically perform millions of computations for a forward pass. That's why a CPU computer takes so long to train a model because it has to do about 3,600 (1,800 + 1,800 ) mathematical operations. Actually that is a trivial number of calculations for a modern CPU, and would be done in less than a millisecond. But multiply this out by a few factors: You must do this for each and every example in the training data Your example network is small, think bigger This does not include the activation function calculations - typically slower than a multiply Your rough estimate ignores some of the necessary operations, so as a guesstimate, multiply number of CPU-level operations by 3 or 4 from your analysis. . . . and the number of operations does start to get to values where CPUs can take hours or days to perform training tasks in practice.
