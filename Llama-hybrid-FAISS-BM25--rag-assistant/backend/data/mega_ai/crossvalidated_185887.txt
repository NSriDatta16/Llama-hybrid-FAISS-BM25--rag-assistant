[site]: crossvalidated
[post_id]: 185887
[parent_id]: 185836
[tags]: 
In classification sometimes its not enough just to predict labels. I mean what happens in the case that you have two models that predict the exact same output/labels? Which one would you choose? In the binary case (classes 0 and 1) for example, if you extract the predicted probabilities that an observation belongs to class 1, you are gonna choose the model that gives you the highest possible predicted probabilities for the samples that actually belong to class 1 and the lowest possible predicted probabilities for the samples that actually belong to class 0. It's like maximizing the margin between the 2 classes. Logloss is also differentiable and can be used when training for example neural networks with back propagation. In terms of unbalanced datasets its better to use the weighted version of Logloss, since the largest class is still gonna bias the results.
