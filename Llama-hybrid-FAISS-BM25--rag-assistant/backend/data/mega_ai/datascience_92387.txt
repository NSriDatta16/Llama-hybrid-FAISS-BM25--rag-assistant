[site]: datascience
[post_id]: 92387
[parent_id]: 
[tags]: 
How to use in built Keras ADDITIVE ATTENTION Layer for image captioning?

I have Designed an Encoder-Decoder Model for Image Captioning . Now, I want to improve my Model. So, I thought of putting an Attention Layer in my Encoder-Decoder model. But, I am struggling with how to use Keras Attention layer API in my model. What are the input and output of the Attention layer(i.e what is query, key ,value provided in documentation) and how to get them? Here we are using a feature vector of the image from a pre-trained Xception Model. How to manipulate or change this code to add the Attention Layer of Keras Library ( https://keras.io/api/layers/attention_layers/additive_attention/ ) to built an image captioning Model to this Encoder-Decoder Model? Here is my Previous Encoder-Decoder Model.. def caption_model(vocab_size,max_len): # features from the CNN model squeezed from 2048 to 256 nodes inputs1 = Input(shape=(2048,)) fe1 = Dropout(0.5)(inputs1) fe2 = Dense(256, activation='relu')(fe1) # LSTM sequence model inputs2 = Input(shape=(max_length,)) se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2) se2 = Dropout(0.5)(se1) se3 = LSTM(256)(se2) # Merging both models decoder1 = add([fe2, se3]) decoder2 = Dense(256, activation='relu')(decoder1) outputs = Dense(vocab_size, activation='softmax')(decoder2) # tie it together [image, seq] [word] model = Model(inputs=[inputs1, inputs2], outputs=outputs) model.compile(loss='categorical_crossentropy', optimizer='adam') # summarize model print(model.summary()) plot_model(model, to_file='model.png', show_shapes=True) return model ```
