[site]: datascience
[post_id]: 5140
[parent_id]: 5138
[tags]: 
I also found confusing the definition of likelihood the first time I encountered it. The only thing you need to remember is that likelihood refers to the probability of your data given a parameter. That is, $$L(\theta| X) = P(X|\theta)$$ As you can see, the likelihood focuses on the parameter, so you're asking "What is the likelihood of this parameter given some observations?" In this case, the phrase "given some observation" assumes the observations $X$ are fixed and the parameter $\theta$ is not fixed. On the other hand, if you describe the same in terms of probability, you're trying to measure the probability of some observations $X$ given a fixed parameter $\theta$. It is only a matter of usage. In the case of logistic regression, the likelihood function is described as: $$L(\beta| y) = \prod_{i}^{N} \pi_{i}^{y_{i}}(1-\pi_{i})^{n_{i} - y_{i}}$$ where $\beta$ is the vector of parameters $\{\pi_{i}| i=1,...,N \}$and $y$ is the vector of Bernoulli variables. As you can see, this is the same (by definition) as $P(y|\beta)$ and that is what you have in the equation above: The product of the probabilities for each observation $y_{i}$ given its parameter $\pi_{i}$. As usual, each probability $\pi_{i}$ is equal to the inverse of the logit function. In Naive Bayes, you have the same basic idea. The likelihood is defined as $L(p_{k}|x) = \prod_{i}^{N}p_{ki}^{x_{i}}(1-p_{ki})^{(1-x_{i})}$ where $p_{k}$ is a vector of parameters describing the probabilities of a class $k$ generating a word $x_{i}$). In the EM algorithm, the likelihood is again $L(\theta|X,Z)$, where $\theta$ are your parameters, $X$ your observations and $Z$ are latent variables. The fact that you have a latent variables shouldn't confuse you, because this variable will be "integrated out" in the expectation step of the algorithm. In the previous equations, the calculation you need to do is self-evident if you think about it starting from your observations: First, I have some observations. Then I want to calculate the probability of obtaining these observation using some model. Most models require parameters to be fitted. So I want to calculate the probability of these observations given those parameters. That is, $p(X|\theta)$. Now, if you need to talk about likeliihood, then you simply write $L(\theta|X)$.
