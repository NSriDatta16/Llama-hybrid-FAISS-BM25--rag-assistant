[site]: crossvalidated
[post_id]: 543734
[parent_id]: 543733
[tags]: 
Isn't that something that would require linear relationships? The assumption is that the effect of covariates is linear on the log odds scale. You might see logistic regression written as $$ \operatorname{logit}(p) = X \beta $$ Here, $\operatorname{logit}(p) = \log\left( \frac{p}{1-p} \right)$ . Additionally, remember that linearity does not mean straight lines in GLM. Regarding the errors, the normality assumption isn't required because the errors will be zero or 1? Not quite. Logistic regression estimates a probability, the error (meaning observation minus prediction) will be between 0 and 1. Why doesn't Logistic Regression require the error and linear relationship assumptions that Linear Regression require? Logistic regression is still a linear model, it is just linear in a different space so as to respect the constraint that $0 \leq p \leq 1$ . AS for your titular question regarding the error term and its variance, note that a binomial random variable's variance depends on its mean ( $\operatorname{Var}(X) = np(1-p)$ ). Hence, the variance chances as the mean changes, meaning the variance is (technically) heteroskedastic (i.e. non-constant, or at the very least changes based on what $X$ is because $p$ changes based on $X$ ).
