[site]: crossvalidated
[post_id]: 55192
[parent_id]: 
[tags]: 
Weight Size in Neural Networks

I am using a Neuronal Network in combination with Reinforcement Learning. The network should learn the values of three actions in given states. The reward from the environment is scaled to [-0.9,0.9]. The network consists of one input layer with 30 nodes of which not more than three are activated at the same time. The hidden layer consists of 30 nodes as well and tanh is used as activation function. The output layer consists of said three nodes, which also are activated using tanh. When training my network, it often finds solutions for the given task, but often enough the values returned by the network are getting closer and closer to -1 and 1, although the reward is normalized to [-0.9,0.9]. Through debugging I found out that the weight from the hidden to the output layer are getting bigger and bigger. Since the weight size is used for the backpropagation, a huge error is passed through the network, causing even bigger weights and so on. Is there a way to prevent the network from getting this vicious circle?
