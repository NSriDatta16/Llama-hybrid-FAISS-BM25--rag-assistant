[site]: crossvalidated
[post_id]: 476167
[parent_id]: 
[tags]: 
How to calculate mean and SD between $T_1$ and $T_2$ based on mean and SD from $T_0$ to $T_1$ and $T_0$ to $T_2$?

I am performing a meta-review about the transition of control in semi-automated cars, for which I am trying to retrieve specific means and standard deviations. I am not sure if I am using the right approach to do so. For each driver, the transition of control can be divided into multiple stages, beginning at stage $S_0$ , going through stages $S_1, S_2, ..., S_{n-1}$ and ending at stage $S_n$ . I am reviewing literature in order to see how much time passes on average until each stage is reached. The literature I found generally reports the mean and standard deviation for the time needed from $S_0$ to $S_x$ (so, from $S_0$ to $S_1$ , from $S_0$ to $S_2$ , ..., from $S_0$ to $S_n$ ). However, I would also like to get an estimate of the mean and standard deviation from stage to stage (e.g. from $S_1$ to $S_2$ ). For the mean time from $S_1$ to $S_2$ I suppose that I can simply subtract the mean of $S_1$ from the mean of $S_2$ . However, for the standard deviation I can't imagine that I can do the same. I've stumbled across following formula to calculate the standard deviation for difference between means using the standard error: $SD = \sqrt{(SE_1^2 + SE_2^2)}$ Which I found here: http://personal.psu.edu/drh20/100/fall2012/lectures/lectureNotes/lecture31Nov14.pdf The standard error for each stage could then be calculated using the formula: $SE = SD/\sqrt{N}$ However, I can't tell, if this applies to my problem, because it is applied to two independent samples in the source. Can I use this formula for my problem, or is there another way to do it?
