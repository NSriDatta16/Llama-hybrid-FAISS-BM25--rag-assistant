[site]: datascience
[post_id]: 121093
[parent_id]: 
[tags]: 
Llimit/masking the space of actions to the legal ones only: A -> A(S)

I have difficulties on coding a way to limit the available actions as a function of the current agent state S. I am trying to use https://keras.io/examples/rl/ppo_cartpole/ (that works quite fine) and tf_agents.agents.PPOClipAgent (that I am not able to make work properly as I wrote in another post). More specifically, I don't want to punish the model in case it tries an illegal action, it is misleading, and the actions are actually really a priori not available. Besides, I don't want to change the selected action in the step function in another one or in a "no action": it is also misleading for the training, and the model will be unaware that its choice has been changed. What I really would like to implement is a limitation of the available choices if needed. Does anyone know an elegant way to do it with the PPO code example of Keras or with TF-Agents?
