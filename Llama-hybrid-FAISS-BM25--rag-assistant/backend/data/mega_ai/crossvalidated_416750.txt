[site]: crossvalidated
[post_id]: 416750
[parent_id]: 
[tags]: 
Two simultaneous time series vars. Want "confidence" intervals for one's prediction (not forecast per se) of the other

Let me know if this is a duplicate. This seems to differ from other time series questions I've seen in that I'm not trying to forecast the future. Maybe that will mean only a difference in the application but not the math itself -- not sure. I'm new to time series analysis in general (besides basics like moving averages, etc.), though I'm familiar with basic frequentism. The scenario is that I have two time series variables. One variable could be number of google searches per day in the US for "Game of Thrones". The other could be the same thing, but in Europe. One is strongly predictive of the other . They both fluctuate significantly, but do so together -- at a glance, it's rare that Europe is less than 25% or more than 30% the number of google searches in a day than the US on that same day. I have lots of data from both countries on the same days. But say next week I want to use the US search numbers to predict Europe's numbers for that same week without looking. How could I produce interval bands of some sort such that Europe that week should lie within those bands with some guarantee, perhaps due to some (credible) parametric assumptions? One case where this might be interesting is in a quasi-experimental setting. There's some intervention -- maybe Game of Thrones becomes rated R in Europe and I want to see if this caused Europe's time series to go outside of these bands. I want to "see" if Europe ceases to behave how we would expect based on what we're seeing in the US. Looking for simpler, tried and true approaches (maybe Bayesian if that helps), rather than cutting edge . Hopefully something that's easy for me to briefly justify to non-math people. Thanks
