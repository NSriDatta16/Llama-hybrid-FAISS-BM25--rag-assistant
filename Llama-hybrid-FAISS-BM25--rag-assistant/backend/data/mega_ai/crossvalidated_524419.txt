[site]: crossvalidated
[post_id]: 524419
[parent_id]: 
[tags]: 
MCMC algorithm for Hierarchical Bayes model with variable number of mixture components

I am trying to develop an MCMC algorithm for clustering $n$ data-points $y_{1},y_{2},\dots,y_{n}$ using a Gaussian mixture model, but with a prior defined on the number of components K. The hierarchical Bayesian model is specified as follows: $$\lambda \sim \textbf{Gamma}(\nu_{1},\nu_{2})$$ $$K |\lambda\sim \textbf{Poisson}(\lambda)$$ $$\boldsymbol{\phi}|K,\alpha {\sim} \textbf{Dirichlet}_{K}(\frac{\alpha}{K},\frac{\alpha}{K},\ldots,\frac{\alpha}{K})$$ $$z_{i}|\boldsymbol{\phi},K\overset{i,i.d}{\sim}\textbf{Categorical}(\boldsymbol{\phi})$$ $${\mu}_{l}|K,\mu,\tau^{2}\overset{i,i.d}{\sim}\textbf{Normal}(\mu,\tau^{2})\quad l=1,2,\dots,K$$ $${\sigma}_{l}^{2}|K,a,b\overset{i,i.d}{\sim}\textbf{Inverse-Gamma}(a,b) \quad l=1,2,\dots,K$$ $$y_{i}|z_{i}=l,K,\mu_{l},\sigma_{l}^{2}\overset{i,i.d}{\sim}\textbf{Normal}(\mu_{l},\sigma_{l}^{2})\quad i=1,2,\dots,n$$ $\nu_{1},\nu_{2},\alpha,\mu,\tau^{2},a$ and $b$ are assumed to be fixed hyperparameters. All notations follow conventions followed in Wikipedia. Can a Gibbs sampler be designed for this model? While attempting to do so, I faced trouble with deriving the full conditional of the number of mixture components K, as well as the full conditional of $\lambda$ . I believe that perhaps one or more Metroplis-Hastings steps is(are) required in order to develop the MCMC algorithm I want, often referrred to as a Metroplis-within-Gibbs algorithm. What would be the Metroplis-Hastings step(s) and the proposal distribution(s) in that case? Edit: It seems that it is not possible to build a traditional Gibbs sampler or Metropolois=within-Gibbs sampler and I was referred to Reversible MCMC algorithms proposed by Richardon and Green. What could be an appropriate Reversible MCMC algorithm appropriate for this model?
