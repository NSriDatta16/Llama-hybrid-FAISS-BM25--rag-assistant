[site]: crossvalidated
[post_id]: 178497
[parent_id]: 
[tags]: 
Reporting result of classifiers

I am using a binary classifier in my research. I wanna report the obtained result of classifier, but I am not sure about it. The learning prosedure is as follows: for (iteration in 1:10) # for more accuracy { 1- Divide data to train and test partitions, 2- Train_result[iteration]: Train classifier using 'train' data using cross-validation and save 'classification error', 3- Test_result[iteration]: Test the trained classifier in step (1) performance using 'test' data and save 'classification error', 4- TrainTest_result[iteration]: Use the trained classifier in step (1) to classify all, 'train and test', data and compute its 'classification error'. } TrainError_avg = mean(Train_result) TestError_avg = mean(Test_result) TrainTest_result_avg = mean(TrainTest_result) I should report which of the above three measures, 'TrainError_avg' , 'TestError_avg' , or 'TrainTestError_avg' , in my paper? If I want to plot ROC curve , I should plot ROC curve for which of them? Besides, Should I average between ROC over all iterations? I appreciate if you could clear these stuff to me.
