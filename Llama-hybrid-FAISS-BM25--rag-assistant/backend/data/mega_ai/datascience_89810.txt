[site]: datascience
[post_id]: 89810
[parent_id]: 9175
[tags]: 
About the type of convolutions Suppose the input layers has the $k_{input}$ channels, than the number of parameters to be learned by neural network is: $$ 3 \cdot 3 \cdot k_{input} \cdot k_1 + 5 \cdot 5 \cdot k_1 \cdot k_2 $$ Because each of the input channels of the image is mapped to one of the output channels. There is a separate filter to each pair $(c_{input}, c_{output})$ , which are indexing the channels of the image. One can think of the convolution filter as a tensor of shape $(c_{input}, c_{output}, s_1 \ldots s_d)$ , where $d$ is the spatial dimensionality of the data. Usefulness of the 1x1 convolutions On the one hand, one can put nonlinearity after, such that the filter + activation performs a nonlinear operation, changing the output in some complicated way. Another point, which makes them useful and is the cornerstone in the MobileNet https://arxiv.org/abs/1704.04861 , that number of operations in ordinary convolution scales multiplicatively with the increase of the filters size and number of channels: $$ c_{input} \cdot c_{output} \cdot n_1 \cdot n_2 $$ For 2D convolution. Setting the $n_1 = n_2$ one works with not so much parameters , combining them with depthwise convolutions. Via $1 \times 1$ convolutions one can reduce the number of feature from $c_1$ to $c_2 in some educated way, where the network itself learns, hopefully, the optimal way to perform the dimensionality reduction. Bonus questions Pooling is applied feature wise, for each channel one obtains a downsampled image contructed via some aggregation function ( max , average ) of the multiple pixels, belonging to the same channel - no interaction between different channels (R, G, B), for instantce. You do not slide over feature map, convolution kernel comprises all feature maps from the $c_{in}$ to $c_{out}$ .
