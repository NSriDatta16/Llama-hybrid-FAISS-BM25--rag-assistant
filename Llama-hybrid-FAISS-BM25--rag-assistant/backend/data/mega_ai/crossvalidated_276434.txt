[site]: crossvalidated
[post_id]: 276434
[parent_id]: 
[tags]: 
Random Forest Prediction Error Mismatch

I am getting confusing results from the below model when backtesting. The code splits the dataset into a training and a testing set (70/30) and as far as I can tell keeps the data separated so that the results found in t are in fact representative. However, when testing the model against a real life progression of the timeseries data where the last days data ( New Data.csv ) is added to Data.csv as more information becomes available, the accuracy of the model does not hold up at all. The mean OOB error is about 20% (which for my purposes is fine), yet the forecast of VarX for new.data has an error rate of 58% (half a years worth of daily data). Is there anything about the below code that would explain the mismatch between the two predictions, and am I missing something else? Intuitively the prediction of new.data should be treated as just another OOB sample, but it clearly achieves nowhere near the same accuracy over time. If I've been unclear let me know and I will do my best to rectify it. Note the for loop in particular: library(MASS) library(randomForest) library(caTools) library(pROC) ##Storing the data set into DataFrame DataFrame
