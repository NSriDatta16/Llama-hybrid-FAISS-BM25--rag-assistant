[site]: datascience
[post_id]: 109743
[parent_id]: 
[tags]: 
regression model behaves (predicts) like classification

I have a simple data: data = { 'X': [], 'y': [] } data['X'].extend( [1, 3, 6, 10, 20, 30, 45, 60, 95, 115, 190, ]) data['y'].extend( [80, 60, 41, 27, 20, 16, 11, 8.5, 7.7, 6.8, 5.6, ]) df = pd.DataFrame(data) X = df.drop(columns='y', axis=1).values y = df['y'].values I make a simple model from xgboost import XGBRegressor regr_XGBR = XGBRegressor() regr_XGBR.fit(X, y) A plot looks perfect plt.scatter(X,y) plt.plot(X, regr_XGBR.predict(X), color = 'blue') plt.show() After I try to predict some values, the result looks like a classification model (similar to KNeighbors). Also I tried with poly but nothing changed. print(regr_XGBR.predict(([[3]]))) print(regr_XGBR.predict(([[3.2]]))) print(regr_XGBR.predict(([[3.5]]))) print(regr_XGBR.predict(([[4]]))) print(regr_XGBR.predict(([[4.2]]))) [59.874977] [59.874977] [59.874977] [59.874977] [59.874977] PS I spent a lot of time trying to solve this problem and got stuck. I would be glad to know at least a direction in solving this issue. PSS Also I tried to search for similar problems but didn't find anything similar to my issue. I will be glad for any help!
