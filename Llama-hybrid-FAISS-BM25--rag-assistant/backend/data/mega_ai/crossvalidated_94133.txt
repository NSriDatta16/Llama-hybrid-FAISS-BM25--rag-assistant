[site]: crossvalidated
[post_id]: 94133
[parent_id]: 94118
[tags]: 
The difference between $\epsilon$-SVR and $\nu$-SVR is how the training problem is parametrized. Both use a type of hinge loss in the cost function. The $\nu$ parameter in $\nu$-SVM can be used to control the amount of support vectors in the resulting model. Given appropriate parameters, the exact same problem is solved. 1 Least squares SVR differs from the other two by using squared residuals in the cost function instead of hinge loss. 1 : C.-C. Chang and C.-J. Lin. Training $\nu$-support vector regression: Theory and algorithms . Neural Computation, 14(8):1959-1977, 2002.
