[site]: crossvalidated
[post_id]: 431020
[parent_id]: 
[tags]: 
Why is the expected gradient of a density not parallel to the expected gradient of the log density?

I'm confused by a seemingly counter-intuitive property of the interaction between distributions, log transforms, expectations and gradients. Suppose I have some distribution over random variable $x$ parameterized by $\theta$ . (Unless I'm mistaken), the MLE for the distribution is the same as the MLE for the log of the distribution. $$\theta^* = \underset{\theta}{\operatorname{argmax}} p(x;\theta) = \underset{\theta}{\operatorname{argmax}} \log p(x;\theta)$$ If $p(x;\theta)$ is differentiable with respect to $\theta$ , I believe that the gradient of the distribution with respect to $\theta$ is parallel to the gradient of the log distribution since $$\nabla_{\theta} \log p(x ; \theta) = \frac{1}{p(x ; \theta)} \nabla_{\theta} p(x ; \theta)$$ This means that performing gradient ascent on $\log p(x;\theta)$ is the same as performing gradient ascent on $p(x; \theta)$ . In contrast, if I consider the expected value of the gradient of the distribution $\langle \nabla_{\theta} p(x;\theta) \rangle_{p(x;\theta)}$ against the expected value of the gradient of the log density $\langle \nabla_{\theta} \log p(x;\theta) \rangle_{p(x;\theta)}$ , the two are perpendicular since the mean of the gradient of the log density is 0: $$ \begin{align*} \langle \nabla_{\theta} \log p(x;\theta) \rangle_{p(x;\theta)} &= \int dx \, p(x;\theta) \nabla_{\theta} \log p(x;\theta)\\ &= \int dx \, p(x;\theta) \frac{1}{p(x;\theta)} \nabla_{\theta} p(x;\theta)\\ &= \int dx \, \nabla_{\theta} p(x;\theta)\\ &= \nabla_{\theta} \int dx \, p(x;\theta)\\ &= \nabla_{\theta} 1\\ &= 0 \end{align*} $$ This seems contradictory. For any specific sample from the density, the two gradients point in the same direction, but averaged over multiple samples, they don't. Why is the expected gradient of a density not parallel to the expected gradient of the log density?
