[site]: crossvalidated
[post_id]: 481194
[parent_id]: 
[tags]: 
Is the analysis of residual variance still ANOVA? What about the regression, generalized models, quantile regression?

I noticed the term ANOVA used in many contexts. The one we are taught is ANOVA using the general linear model and only categorical independent variables. We ask if the variables affect the continuous outcome, or in other words, if there are differences between means across groups determined by the values of the categorical variables. But this is immediately equivalent to test main effects in the regression model. When we have variables with levels: A={A1, A2, A3} and B={B1, B2}, then the regression analysis will tell us about the coefficients for certain combinations of Ai and Bi (for example A2_B3) vs. the intercept, which is the combination of baseline values (A1_B1). If we wanted to ask if the A is a statistically significant effect, we test jointly A1, A2, A3. Same for B and their interaction A:B. In R, for example, this is done using anova() procedure, which compares nested models: A + B + A:B vs: A, B and A + B. This is called also "analysis of variance table". And so far I can understand it, because in both cases we speak about the same general linear model. All the statistical assumptions about group normality (which also means residual normality here) and homogeneity of variance (which also means homoscedasticity of variance) hold. But now, I want to add continuous variables. Such ANOVA with continuous variables is ANCOVA = ANOVA adjusted for numerical covariates. But again, when we employ the linear model for that, Y = X0 + X1b1 (for A_1_B2) + x2b2 (for A2_B1) + .... _ xnbn (for some continuous variable Z), we can also test the main effects for A, B and now also Z. And again we use the "anova()" procedure - the analysis of residual variance table. Let's go deeper. If I have a linear model with repeated data with clearly violated independence over time and issues with variance, I can employ a linear model fit via Generalized Least Square. And again, I can test the main effects with anova() executed over the GLS fit linear model, to compare nested models term by term. Now the assumption of homogeneity of variable doesn't hold for the raw data. That's why we used the GLS! Let's go even deeper and run some GLM, a logistic regression. We can also use the anova() to compare nested models and find the main effects = to say if categorical variable A, B and continuous variable Z affect the binary outcome. Now it is called "analysis of deviance table" rather than "residual variance". And now neither assumption for the raw data is met! We can also ask for the anova() for quantile regression, generalized additive models. This goes into madness. Maybe this just unfortunate name of the anova() function, which should be called "joint_analysis_of_contrasts()". But other software also use the term "type 3 ANOVA" to analyze the main effects. Maybe we have been taught only the very special case of it. Is ANOVA run over a GLM or GAM still the good old ANOVA, even if it handles continuous variables and allows me to violate all assumptions known from the linear model? Is this all ANOVA or only a "replacement word" for a more generic analysis? And second question, how should I name properly the analysis in my article? "The main effects of the model have been evaluated using the ANOVA-type analysis", or "[...] analysis of residual variance analysis" or "[...] joint analysis of model coefficients" or any other wording that will be understood and accepted by reviewers. Please help me to organize my knowledge about that.
