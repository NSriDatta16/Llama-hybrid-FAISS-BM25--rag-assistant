[site]: datascience
[post_id]: 121789
[parent_id]: 121738
[tags]: 
You could use sentence transformer library to calculate the similarity between different phrases. It also works for multi worded tokens. from sentence_transformers import SentenceTransformer, util import compress_fasttext import numpy as np mpnet_v2 = SentenceTransformer('all-mpnet-base-v2') sentence1 = "property damage" sentence2 = "damage done to the property" # encode sentences to get their embeddings embeb_r_large1 = mpnet_v2.encode(sentence1, convert_to_tensor=True) # compute similarity scores of two embeddings mpnetv2_score = util.pytorch_cos_sim(embeb_r_large1, embeb_r_large2) print(f'similarity score is : {mpnetv2_score}') #result #similarity score is : 0.8635872602462769
