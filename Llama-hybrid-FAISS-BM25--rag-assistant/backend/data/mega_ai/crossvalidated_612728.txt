[site]: crossvalidated
[post_id]: 612728
[parent_id]: 
[tags]: 
What are effective methods to maximize an unknown noisy function?

I have a function that takes a few hundred parameters and which returns a score I want to optimize for - It's a piece of software attempting to play a game against another player. The parameters partially determine the actions of the player and so have an effect on my final score I would like to find a set of parameters that optimizes the likely outcome of the played game. I'm facing several difficulties: The game is chaotic, so except for the most sensitive parameters, most of the hundreds of parameters have only a small individual effect. The game is computationally heavy to run. I will likely only have around 10000 datapoints I can gather with my limited computational resources. The only way I can even get to 10k datapoints is by running it in parallel. Single threaded approaches may not work for me I don't have a derivative of my function Parameters can be floats, integers or booleans. Some of the ints/floats may not currently have the right sign. Booleans tend to be the most impactful parameters, but I think these are mostly set right now Some parameters can entirely shut down my player if brought outside of acceptable ranges. I do not always know these acceptable ranges. While I am adjusting parameters, I am also adjusting the software, which subtly or not so subtly changes the meaning and ideal value of some parameters Due to the difficulty, I am not expecting to find even a local maximum let alone a global one, I am happy if I can get some of the most important parameters in the right order of magnitude without messing the less important parameters up too much. So far the best approach I've found and am currently using is: Randomly vary a subset of parameters by picking a value from a normal distribution around the currently selected best value. (booleans are randomly flipped) Play a game (selfplay), then store the used parameters and final score in a file Collect datapoints from my last n games, for floats and integers calculate a Pearson correlation coefficient (p) for every parameter correlated with my score. Then adjust every parameter x by setting x = x + abs(p) * y * p, where y is a scaling factor. Booleans are flipped if p indicates I should Occasionally manually adjust parameters based on what seems nonsensical. I've alternated optimizing for different rating values, not just the score, but also whether my bot has won and other relevant game specific values such as how many gamepieces I own at the end This (clearly flawed) approach at least seems to make my parameters drift closer to their ideal on average. But, if I pick a low scaling factor y, my parameter convergence is way too slow. If I pick a high y, there's a lot of unintended drift. I often observe (regardless of y and n) that my performance score decrease after a optimization attempt. I've tried some other approaches such as machine learning (neural nets and random forest trees) for parameter optimization, but with little luck. There probably isn't enough data to prevent overfitting on my noisy data Are there better approaches I can use here to optimize my parameters?
