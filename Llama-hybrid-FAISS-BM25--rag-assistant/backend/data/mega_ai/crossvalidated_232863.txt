[site]: crossvalidated
[post_id]: 232863
[parent_id]: 200396
[tags]: 
Check out this paper: DART: Dropouts meet Multiple Additive Regression Trees (Arxiv PDF) . Their interpertation of dropout is this: instead of developing the next tree from the residual of all previous trees, develop the next tree from the residual of a sample of previous trees. The effect on the model is similar in that individual components are forced to be more self-sufficient. They observe some reasonably significant gains. As Soren points out, colsample_bytree and colsample_bylevel are analogous to input-layer dropout. DART is available in xgboost already by setting booster="dart"
