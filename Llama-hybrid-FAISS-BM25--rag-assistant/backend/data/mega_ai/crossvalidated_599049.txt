[site]: crossvalidated
[post_id]: 599049
[parent_id]: 599032
[tags]: 
There are actually quite a few ways to examine random effects, but not a lot of ways to test them if you mean inferential tests (I note some exceptions near the end of my answer). Exploring RE's Descriptively I have fit a really basic model with some data in the languageR package in R to show how. First, the packages and the model fit are shown below. Here I have used a crossed random effects design, which uses subjects and items as random intercepts. #### Load Libraries #### library(languageR) library(lmerTest) library(tidyverse) library(performance) #### Fit Model #### fit To check the model metrics of the lme4 fit, we can use the model_performance function from the performance package by running model_performance(fit) . One of the nice things it gives beyond a number of other useful stats is the ICC: # Indices of model performance AIC | AICc | BIC | R2 (cond.) | R2 (marg.) | ICC | RMSE | Sigma -------------------------------------------------------------------------------- 6213.114 | 6213.128 | 6261.957 | 0.377 | 0.225 | 0.195 | 0.342 | 0.347 Here we can see that the ICC is around 19.5% indicating a fair level of clustering, but nothing super high. Running summary(fit) seems to indicate why, as the variation for both subjects and words seems low: Linear mixed model fit by REML. t-tests use Satterthwaite's method [ lmerModLmerTest] Formula: LogRT ~ PC1 + PC2 + PC3 + (1 | Word) + (1 | Subject) Data: beginningReaders REML criterion at convergence: 6199.1 Scaled residuals: Min 1Q Median 3Q Max -5.3367 -0.6301 -0.0247 0.6318 3.9126 Random effects: Groups Name Variance Std.Dev. Word (Intercept) 0.01154 0.1074 Subject (Intercept) 0.01763 0.1328 Residual 0.12014 0.3466 Number of obs: 7923, groups: Word, 184; Subject, 59 Fixed effects: Estimate Std. Error df t value Pr(>|t|) (Intercept) 7.336e+00 1.944e-02 7.611e+01 377.407 The summary is dense, but basically the "Random effects" section shows that subjects and words vary fairly little (less than 1 SD). However, some subjects and some words may vary more than others. We can check with ranef(fit) . This output shows how much the conditional mean shifts with each word and each subject: $Word (Intercept) avontuur -0.0376961757 baden 0.0929130421 balkon 0.0550390452 band -0.0699927051 barsten 0.1364986648 beek -0.0941336459 beker -0.0677617070 beton 0.0198963592 beven -0.0584016778 bieden 0.0720644481 blaffen 0.0666273615 blinken 0.0452859616 bocht -0.0208467019 bonzen 0.1779355838 boodschap 0.0027313764 bord -0.0747432455 broek -0.1352857758 broer 0.0149900742 brok 0.0350749656 brullen -0.0602780645 buit -0.0972509626 bukken 0.1055088293 cent -0.1117035758 deken 0.0644954935 douche 0.0036381350 durven 0.0378583315 dwingen 0.0985062914 echo 0.0441164339 emmer -0.1827732107 flitsen 0.1099284571 fluisteren -0.0402365298 fruit -0.1418218259 gapen 0.0790988060 garage 0.0573048084 giechelen 0.0744790481 gieten 0.0051786877 gillen -0.0720853650 glinsteren 0.1611677965 gloeien -0.0006420434 gluren 0.0569286145 graan -0.0292549369 grap -0.0532858065 grijns 0.0594641835 grijnzen 0.0898645421 grinniken 0.0079788370 groeten 0.0101844190 grommen 0.0275969175 grot -0.0824446830 hijgen -0.0196344803 hijsen -0.0102253868 horizon 0.0651420746 horloge 0.0999756095 insekt 0.1136356311 jagen -0.0790522963 juichen 0.0443482373 kanon 0.0562395943 karton 0.0801699947 karwei 0.1548301850 kerel 0.0598380633 ketel 0.1016535893 kilo -0.1381536047 kin -0.1042770699 klagen 0.0457694174 klant -0.0086262023 knagen 0.0485373649 kneden 0.1201589549 knielen 0.1126815917 knipperen 0.1517693419 knol -0.0174397117 koffer -0.0616477091 koning -0.1281543729 koren 0.1131955273 korst -0.0287838781 kraag -0.0440020299 kreunen -0.0609515083 krijsen 0.1006712741 krimpen 0.0615385705 kudde -0.0508501525 kus -0.1843313504 ladder 0.0222257557 laden -0.0021878554 lawaai -0.0365457444 leunen -0.0605402731 liegen 0.0188475617 lijden 0.1098908845 liter 0.0032587258 loeren -0.0312888887 manier -0.0597143638 matras 0.0594742474 matroos 0.0289956581 melden -0.0823024077 mengen 0.0704723994 metselen 0.0833313563 minuut -0.0474364720 mompelen 0.0518466679 mouw -0.0771313614 mus -0.1219554377 muts -0.0893368820 neef -0.1088691002 ober -0.0386440623 oever 0.0529884979 oom -0.2501263391 paradijs 0.1035461642 parfum 0.1300401079 park -0.1898363453 pet -0.2387002465 piepen -0.0617037204 pijl -0.1524056501 piloot -0.0307178077 plafond 0.0550323655 plein -0.1062308115 plek -0.1071375138 plezier 0.0271274116 plukken 0.0246629318 poes -0.3211252786 poos -0.0604537823 proberen 0.0865032420 raket -0.0305182572 rekenen -0.0678917356 rest -0.0522567305 rij -0.1152876283 rijst 0.0074512884 rillen -0.0195288176 rinkelen 0.1137929926 ruiken -0.1270553529 ruzie -0.0531441298 schamen 0.1394000041 schande 0.1012821240 schelden 0.0380243513 schitteren 0.2030268425 schoot 0.0370187782 schrapen 0.1279871976 sissen 0.0882860501 slikken 0.0997938898 sloot -0.1050037645 smeken 0.0198952857 smijten 0.0746374741 snauwen 0.1000946006 snikken 0.0646164112 snor -0.1365519060 snuiven 0.1266264774 sok -0.1988610956 spijten -0.0127989874 spleet 0.0974313437 sprookje -0.0829790800 spul 0.0727633882 stampen 0.0670943244 staren 0.1351586609 stier -0.0508508015 stinken 0.1052158188 stoep 0.0192434202 stoken 0.1689559126 strekken 0.1158477946 struikelen 0.1168544362 stuiven 0.1212319937 taart -0.1674119915 tante -0.0603503035 teen -0.0710505994 temperatuur 0.2229739230 trots -0.0615712834 trui -0.0825829037 turen 0.0756005171 ui -0.1136609762 vaas -0.2255921528 vacht 0.0115724128 verdriet -0.1118314783 verrassen 0.1253446671 vijver 0.0261143860 villa 0.0273855995 vork -0.0892530467 vuist -0.0905227220 wang -0.0534576374 wapperen 0.0518450719 weven 0.0248082646 wiegen -0.0319488208 worm -0.0828325787 worstelen 0.0929385197 woud -0.0622268625 zeuren -0.0770968651 zuigen -0.0493489334 zwaard -0.0246543439 zwemmen -0.1579047535 zweven 0.0106800811 zwijgen 0.0054364575 $Subject (Intercept) S10 -0.01114527 S12 -0.17835276 S13 -0.07971401 S14 0.16302133 S15 -0.15054170 S16 0.02901146 S18 0.01322766 S2 0.10030362 S20 0.12988077 S21 -0.02441368 S22 0.10534709 S26 -0.23647577 S27 0.17240726 S28 -0.07967623 S29 0.13399079 S3 -0.15511963 S30 0.17107756 S31 -0.04131071 S32 0.19187719 S33 -0.20276061 S34 -0.36079186 S35 -0.01248947 S37 -0.09568015 S39 0.03243001 S40 0.04935140 S43 0.08565865 S46 -0.19972929 S47 -0.01513195 S48 0.03499562 S49 -0.06006614 S51 0.05509955 S52 -0.08016102 S53 -0.10935698 S54 -0.08940870 S57 -0.03362590 S58 0.07610907 S59 -0.07817729 S60 0.03002117 S61 -0.18360230 S62 0.08128662 S63 -0.09115206 S64 0.09495314 S65 -0.04681862 S66 0.23863772 S67 0.01930349 S68 0.03687130 S69 -0.12728725 S7 0.18998541 S70 -0.04493750 S71 0.11866950 S72 0.09710285 S73 0.14082743 S74 -0.11915647 S75 -0.15241258 S76 -0.07439909 S77 0.08911369 S78 0.01982794 S79 0.22601634 S8 0.20748937 with conditional variances for “Word” “Subject” However, this is a very long list, and may be better to just visualize instead. We can do this with the lattice package with the dotplot function, using dotplot(ranef(fit)) . lattice::dotplot(ranef(fit))[1] lattice::dotplot(ranef(fit))[2] Each plot is shown below: This shows how much each word and each subject shifts from the intercept. While here the variation is quite small, you can see where the variation is occurring. Inferential Testing If you are looking for some form of inferential test, this is a hairy subject which stretches the definition of random effects and what they mean in a model. The FAQ by Ben Bolker discusses this in some part with regards to model comparison of random effects. There are also random effects splines in GAMMs that include a default significance test, but what that means is likely not going to be helpful unless you have some very specific purpose for doing this. There is a post here that talks about GLMM and GAMM RE significance testing which illustrates part of the issue with this.
