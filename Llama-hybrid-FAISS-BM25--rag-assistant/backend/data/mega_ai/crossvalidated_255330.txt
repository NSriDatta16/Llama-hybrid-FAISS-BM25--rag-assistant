[site]: crossvalidated
[post_id]: 255330
[parent_id]: 
[tags]: 
What is the difference between manual search and grid search for hyperparameters

I am reading about the hyperparameters optimization for a machine learning model. I am reading "Practical Recommendations for Gradient-Based Training of Deep Architectures" paper. Author speaks about manual search, grid search and random search. What is the difference between Manual serach and grid search. What I understand is in both cases, we define a zone of interest and we select values from it to test our model on validation set. The best values of hyperparameters are choosen by minimizing a criteria, for example, error classification on validation set. May be in a grid search approach, we try more values! Any explanation?
