[site]: crossvalidated
[post_id]: 90016
[parent_id]: 89983
[tags]: 
Note that even if you are implementing multi-class SVM, the one-vs-all strategy is usually applied (or you can use other strategies to achieve the multi-classifier effect), since SVM is binary classifier. The dimension of weight vector is the same as feature dimension. So if you are applying the linear SVM, the weight vector dimension is equal to the input space dimension. For other kernels, original data space is transformed into another high-dimensional space, specifically, if you are applying the RBF kernel, the weight vector dimension can be viewed as infinite. You can search any SVM tutorials online on the topic of the basic binary SVM classifier along with the extended version (such as multi-class SVM, SVR, etc.) . There is also a post on feature space , and a post on interpretation of SVM feature weights that might help. @ogrisel's answer to the 2nd post above gives you a better analysis on one-vs-all strategy on multi-class SVM.
