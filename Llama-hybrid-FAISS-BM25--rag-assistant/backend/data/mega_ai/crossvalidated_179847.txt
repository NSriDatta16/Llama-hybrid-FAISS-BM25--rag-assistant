[site]: crossvalidated
[post_id]: 179847
[parent_id]: 179845
[tags]: 
Since you are working with nested models, a much better approach might be done with plain LASSO. From what I understand, GLMNET concerns estimating a non-linear relationship between several factors and the outcome of interest, which is generally important if there is one or more factors having a complex non-linear relationship with the outcome. With less than 200 observations and nearly half as many features, the idea of estimating this reliably is ludicrous. The missing coefficients in your kitchen sink model is a testament to that. The NA values are a consequence of singularity, when one column or more of the model matrix can be expressed as a linear combination of other columns. Therefore if stepwise model selection is the appropriate means of creating a final predictive model, forward stepwise selection is the only viable solution: and iffy at that. LASSO could be much better. I think you should give that an attempt if this really concerns building a predictive model. Nonetheless, I can't help but observe that these measurements seem to arise from a somewhat sophisticated physical process. Building predictive models has limited importance in fields where processes are not understood. However, if a process is understood well enough to formulate a model (or two or ten) without relying on complicated machine learning techniques, I wholeheartedly advocate abandoning ML methods in favor of --what I call-- fitting a "physical" model. This is much simpler and easier, usually. Just see the R help entry for nls . Physical model(s) generally provides a fantastic means of communicating data to physicists, biologists, or other groups. Finding 4 or 5 physical models, and comparing AIC provides some means of comparing their predictive accuracy.
