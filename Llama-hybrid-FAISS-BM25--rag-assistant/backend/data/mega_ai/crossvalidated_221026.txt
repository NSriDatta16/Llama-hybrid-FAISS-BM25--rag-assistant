[site]: crossvalidated
[post_id]: 221026
[parent_id]: 134599
[tags]: 
Why do you want to use CNNs here? Have you considered other models that actually handle imbalanced data? For example, I've found the following two techniques have worked really well for me: Random Forests w/ SMOTE Boosting : Use a hybrid SMOTE that undersamples the majority class and over-samples the minority class by adjustable percentages. Select these percentages depending on the distribution of your response variable in the training set. Feed this data to your RF model. Always cross-validate/perform grid-search to find the best parameter settings for your RFs. XGBoost w/ hyper-parameter optimisation : Again, cross-validate or perform gird-search to find the best parameter settings for the model. Additionally, xgboost allows you to balance positive and negative class weights using scale_pos_weight . See the parameter documentation for a complete list. I should also add that the data-set I was working on had the same percentage of skew and I was able to obtain Sensitivity score of 0.941 and a Specificity of 0.71 with xgboost , which means the model is predicting the true positives quite accurately and that bodes well for me. (Sorry, I can not leave a comment, not enough reputation and I really wanted to know why you chose CNNs)
