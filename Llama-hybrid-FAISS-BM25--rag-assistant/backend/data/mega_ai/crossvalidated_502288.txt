[site]: crossvalidated
[post_id]: 502288
[parent_id]: 
[tags]: 
How to properly split data for machine learning on small data sets

I'm doing a regression task using machine learning on some small data sets (less than 100) with numeric features. Before training the model, I would like to take 20% of the data as a holdout test set to be excluded from the training process. Currently, I'm choosing the holdout set randomly and I find the choice of the holdout set would significantly influence the performance of the final model (which is as expected). Therefore, I'm wondering what should I do to develop a model which is robust to the change of data splitting method given such small data sets?
