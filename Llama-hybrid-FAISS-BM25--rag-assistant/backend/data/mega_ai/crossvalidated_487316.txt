[site]: crossvalidated
[post_id]: 487316
[parent_id]: 
[tags]: 
Bayesian inference of stochastically evolving model parameters

I have a question related to self-calibration in radio interferometry, but I will try to phrase it as generic as possible. I have a set of data points $$D = \{ d_{0, t_0}, d_{1, t_0}, \cdots, d_{M, t_0}, d_{0, t_1}, d_{1, t_1}, \cdots, d_{M, t_1}, \cdots, d_{0, t_n}, d_{1, t_n}, ... d_{M, t_n} \},$$ taken at different time intervals $$t = 0, 1, \cdots, n$$ to which I want to fit a model. For each time interval I have $N$ model parameters $\theta = \{\theta_{0, t_0}, \theta_{1, t_0}, ..., \theta_{N, t_0} \}$ and $M = N ( N - 1 ) / 2$ data points. I have generated some noisy simulated data from my model so that the model parameters evolve with time in a stochastic manner (which is close to real observations; see Figure 1 for the evolution of my simulated model parameters) and my aim is to infer those parameters. Due to SNR restrictions, I can not infer the model parameters in every single time interval, so instead what I am doing is to group together data points taken e.g. at 5 consecutive time intervals and minimize the likelihood of my model given the data to find the average $\bar{\theta}_{k, t^{'}_0}$ , $(k = 0, 1, ..., N)$ for $t_0 and so on. In this way I infer the average set of $N$ model parameters for each binned up subset of my data, independently (seems to be working fine). Just to note, in order to infer my model parameters I am using a gradient descent algorithm. However, my approach does not take advantage of the fact that the evolution of the model parameters is a stochastic process, which means $\theta_{k, t_{n+1}}$ is not independent from $\theta_{k, t_{n}}$ . I am wondering if I can solve for all the model parameters simultaneously and introduce Gaussian priors so that the prior for the k'th model parameter at $t_n$ is centered at $\theta_{k, t_{n - 1}}$ . In this case would the expression to minimize look something like this, \begin{equation} \label{eq:self_calibration} P({\theta} | d) = \prod_{n=0} \left( L(d_n | {\theta_n}) \prod_{k=1} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{\frac{(\theta_{k, t_n} - \theta_{k, t_{n-1}})^2}{\sigma^2}} \right) \end{equation} where $d_n = \{ d_{0, t_n}, d_{1, t_n}, ... d_{M, t_n} \}$ , $\theta_n = \{\theta_{0, t_n}, \theta_{1, t_n}, ..., \theta_{N, t_n} \}$ and $\sigma$ will be fixed to some value. Does my problem fall into a particular category of bayesian statistics problems, so I can read up more about this?
