[site]: crossvalidated
[post_id]: 96861
[parent_id]: 45731
[tags]: 
The biggest problem is that regression trees (and algorithms based on them like random forests) predict piecewise constant functions, giving a constant value for inputs falling under each leaf. This means that when extrapolating outside their training domain, they just predict the same value as they would for the nearest point at which they had training data. @mbq is correct that there are specialized tools for learning time series that would probably be better than general machine learning techniques. However, random forests are particularly bad for this example, and there other general ML techniques would probably perform much better than what you are seeing. SVMs with nonlinear kernels are one option that comes to mind. Since your function has periodic structure, this also suggests working the frequency domain, using Fourier components or wavelets.
