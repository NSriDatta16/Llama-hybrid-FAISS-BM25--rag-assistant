[site]: crossvalidated
[post_id]: 172801
[parent_id]: 172785
[tags]: 
1.Did I get that right? As far as I understood, OR and elasticity both indicate how much the probability to observe the dependent variable changes if the variable is present or not. Let's go back to the very basic definitions of odds/odds ratios and elasticity. An odds is the defined as the probability of an event occurring divided by the probability of that event not occurring, i.e.: $Odds = \frac{Pr}{1-Pr}$ An odds ratio is therefore the ratio of two odds , so it is technically not correct to say that it indicates the relative probability of the dependent variable changing in the presence of the variable (a ratio of two probabilities is commonly known as a risk ratio). The technically correct interpretation is to use "odds," but odds are not really intuitive or straightforward for lay people, so a common way of interpreting odds ratios in the epidemiology literature is to use "likely." For example, if the OR for the dichotomous variable $Female$ is 1.2, then you would interpret it as "Females are 1.2 times more likely than males to have the disease" or "the odds of disease for females is 1.2 times that of males." Odds ratios are commonly used in public health and the medical literature. Elasticity is a common measure in economics and comes from economic theory. The basic definition of elasticity is the percent change in one variable corresponding to the percent change in another variable (Train, 2009). That is: $\epsilon=\frac{\% \Delta X}{\% \Delta Y}$ If you were fitting a regression model where the outcome is quantifiable (by which I mean you can fit an OLS or Poisson model), the interpretation is straightforward. For example, a 1% increase in price corresponds to a 0.2% decrease in doctor visits. In discrete choice models, the interpretation is not that straightforward, because we are dealing with likelihoods, instead of something more tangible. In a logistic regression output (for example, output from Stata's margins, eyex(*) postestimation commands), a straightforward interpretation of elasticity would be the percent change in probability of the outcome corresponding to a 1 percent change in the covariate of interest. For instance, if your output says that the elasticity of income was 0.122, the interpretation would be "a 1 % increase in income is associated with a 0.122% increase in probability of blablabla." Note that both OR and elasticity show you the direction and magnitude of the effect under examination, and they are both measures of relative changes, rather than discrete changes. A third way of quantifying effect size also popular in economics, the marginal effect, measures discrete changes in predicted probability. That is, if variable $Female$ has a marginal effect of 0.302, the interpretation is that females are 30.2 percentage points more likely than males to have the disease. 2. Would you suggest me to use only one of the measures or both? If only one: which one? It depends on your discipline. Use what the people in your field or your intended audience are familiar with, as they are both correct measures of effect. Do not use the measure with which your intended audience is not familiar. I dabble in both epidemiology and economics (field is public health/health policy) and have worked with both epidemiologists and economists at university, and none of the epidemiologists I worked with had heard of elasticity until they started working with me. On the other hand, my old econometrics professor really hated odds ratios ("it doesn't make sense") and exclusively used marginal effects and elasticities. 3. Also general thoughts about odds ratio vs. elasticities will help me! Doesn't have to be in a discrete choice context. A parting note, although I probably shouldn't be dishing out this advice since it borders on academic dishonesty, is that sometimes people choose one over the other if it makes their results look "favorable." For example, the table below contains the same result from a simple logistic regression of using a certain health service on income using 4 different measures: the $\beta$ coefficient, OR, elasticity $\epsilon$, and the marginal effect (ME). The important thing to note is that all of these measures came from the same logistic regression model, conveying the same information in different ways. $$\begin{array}{|c|c|c|c|} \hline & \beta & \text{OR} & \epsilon &\text{ME}\\ \hline \text{Income (USD)} & .226 & 1.25 &.009 & .036\\ \hline \end{array}$$ Of all the measures presented, one may be tempted to present the OR, because it has the largest effect size. That is, a .009% increase in probability or a 3.6 percentage point increase in probability of using a service are not as impressive-sounding as having someone be 1.25 times more likely to use a service as their income increases.
