[site]: crossvalidated
[post_id]: 361245
[parent_id]: 
[tags]: 
Poor regression results of neural networks on 2d benchmark data (compared to spline interpolation)

I try to understand for which regression tasks neural networks might be useful. One benchmark for me is to reproduce the ability of scipy.interpolate.griddata : Regression of the 2d function $$ x(1-x)\cos(4\pi x) \sin^2(4\pi y^2). $$ However, this seems to be hard for neural networks: Source code: https://nbviewer.jupyter.org/github/cknoll/demo-material/blob/master/compare_regression_mlp_vs_spline.ipynb Questions: Am I doing something wrong, e.g. in terms of meta parameters? Is this task not suited for neural networks? Would it be better to try TensorFlow or pytorch instead of scikit.learn?
