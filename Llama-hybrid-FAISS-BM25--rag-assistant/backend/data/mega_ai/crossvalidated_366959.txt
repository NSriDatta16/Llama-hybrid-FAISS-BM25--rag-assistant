[site]: crossvalidated
[post_id]: 366959
[parent_id]: 366880
[tags]: 
What a marvelous problem. Your instructor (with his towering intellect) has given you quite a gem to work on. If you add and subtract $E[Y\mid X]$ to $Y$, then you can write $$ \{Y- E[Y \mid X]\} + E[Y|X] = Y \tag{1}. $$ To see the connection with the Pythagorean Theorem, think of this equation as $$ A + B = C, $$ where $A = \{Y- E[Y \mid X]\}$, $B =E[Y|X]$ and $C = Y$. This notation might be familiar if you were thinking of $A$ , $B$ and $C$ as vectors, where $A$ is the flat vector on the bottom of the right triangle, $B$ is the vertical piece, and $C$ is the hypotenuse. The Pythagorean theorem for vectors says, that as long as $A$ and $B$ are orthogonal , we have the length of $A$ squared plus the length of $B$ squared equals the length of $C$ squared. How can random variables be orthogonal, and how do we take the length of them? @KDG has the right idea: the squared length of a random vector is the average of its square, so square both sides (1), and then take the average on both sides, and you will arrive at the result. The orthogonal idea has to deal with why $$ E\left[\{Y- E[Y \mid X]\} E[Y|X] \right] = E\left[A B \right] = 0. $$ This would solve the problem by making that cross term have mean zero. Also, it would help you solve it from the second line of your work because it shows $2 E[{E[(Y|X)^2}] - 2E[Y*E[Y|X]] = 0$, and so you're left with $E[Y^2]$. Perhaps your (terrific, magnificent, amazing, etc.) instructor worked this out in class by showing the covariance between these two pieces is $0$. Perhaps it's on slide 14 of the notes from section 5.3. Also, I'm sure if you asked him, he would tell you he's very glad to see his students working very hard on their homework.
