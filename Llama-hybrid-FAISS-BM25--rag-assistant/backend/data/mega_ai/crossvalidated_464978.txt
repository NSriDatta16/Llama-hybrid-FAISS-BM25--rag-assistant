[site]: crossvalidated
[post_id]: 464978
[parent_id]: 
[tags]: 
Predicting outputs for new samples in Bayesian linear regression

This is my first question on this forum. I just got started with Bayesian statistics. While I do understand the motivations behind Bayesian methods, I am a little unclear on what the predictions even mean. Consider a standard regression problem of predicting the price of a house given its area in square feet. Assume the optimal parameters (slope and intercept) of the model have been found. The price of any new house (x_new) is just the number - {intercept + slope * x_new}. In Bayesian linear regression, we work with the so-called posterior predictive distribution (abbreviated PPD). But what is the PPD anyway? Is it a probability density function (pdf) with some parameters like mean and (co)variance? If so, how do I obtain a single value of the house price from this density function? Should I just take the mean of this distribution or are there sophisticated techniques available? Is it a real number, given by the equation - intercept + slope * x_new? If so, a. Are intercept and slope sampled from the posterior distribution of slope and intercept? b. Or are the posterior mean values of slope and intercept used for computing the price of the new house?
