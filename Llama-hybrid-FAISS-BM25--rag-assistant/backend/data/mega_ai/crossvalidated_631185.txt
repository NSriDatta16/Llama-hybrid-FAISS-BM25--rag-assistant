[site]: crossvalidated
[post_id]: 631185
[parent_id]: 
[tags]: 
Good training/test results, but very poor performance in inference as the stream data is coming

I am interested in the audio classification problem. After labeling the audio recordings I have in Praat software environment, I extract the MFCC features from each labeled frame and create an SVM classifier model from random 80%-20% separated data set. The results are quite good on the 20% separated test data, the test accuracy is around 90%, while the 5-fold cross-validation accuracy on the training data is around 90%, and the model hyperparameters were selected by optimizing the them with cross validation accuracy on training data. So far everything is perfect. The problem starts with records that the model has never seen before. The interval results over the whole recording, which I split into frames & windows, are very bad. I also use a post-processing algorithm that combines the probability values of consequtive frames, but the model returns high classification results on very irrelevant points. If the performance on single label test results is so high (both training and test), why are the inference (data is coming as stream) results so irrelevant? The records I use for inference are very similar in content to the records I use in training/test. Am I having this problem because MFCC does not carry temporal information in real time processing? Do you have any suggestions? Thank you!
