[site]: crossvalidated
[post_id]: 562861
[parent_id]: 562805
[tags]: 
Exploratory factor analysis (EFA) is chock-full of decision points. I have posted a guide to these at http://yellowbrickstats.com/documents/Factor%20Analysis%20Decision%20Guide.pdf : A. Decide how to treat missing data B. Assess data suitability for factor analysis C. Choose an extraction method D. Pick a rotation method E. Decide how many factors to extract F. Decide which items to keep in the analysis G. Choose a way of displaying results Your wording suggests that you have allowed software defaults to make a lot of those decisions for you. I recommend that you document here whatever you can about your code and the decisions you deliberately made (the “specs” you chose). To conduct EFA on 24 input variables using only 180 observations means that you have sparse data with which to estimate many relationships. I’m not saying this approach is out of the question, but it should be helpful to reduce the number of inputs, ideally on theoretical grounds. Variables that on their face seem unrelated to any other group of variables, or that seem almost completely redundant with other individual ones, would be best dropped. With N=180, your solution(s) would inspire more confidence if the inputs were reduced to perhaps 15. But then, can you describe the audience for this analysis, and what they prioritize? For choosing the best number of factors to extract, currently the favored methods don’t include the Kaiser-Guttman rule. It is wickedly parodied in Preacher, K. J., & MacCallum, R. C. (2003). Repairing Tom Swift's electric factor analysis machine. Understanding Statistics, 2, 13-32, http://www.quantpsy.org/pubs/preacher_maccallum_2003.pdf . It's further discredited in Braeken, J., & van Assen, M. A. L. M. (2017). An empirical Kaiser criterion. Psychological Methods, 22(3), 450-466. http://dx.doi.org/10.1037/met0000074 . Nor is the scree test among those currently favored. Instead, parallel analysis, the minimum average partial correlation test, and the empirical Kaiser criterion are preferred. I recommend looking into more of the above-listed aspects of the EFA, and thinking through your results after more iterations, before you proceed to CFA, if you do at all. And then if you do, that you cross-validate to assess the robustness of your CFA solution. Not with simple split-half cross-validation, since an N of 90 will be almost definitely too small for the task at hand. Your results for CFI and TLI do not sound necessarily “very good” to me. You may want to look further into benchmarks for such indicators. Finally, I would not say definitely Yes or No on the use of Cronbach's alpha to aid in factor-retention decisions. There are too many other aspects of the process that I would recommend examining further.
