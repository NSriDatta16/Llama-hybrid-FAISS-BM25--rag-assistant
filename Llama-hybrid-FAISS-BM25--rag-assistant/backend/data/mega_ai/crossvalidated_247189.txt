[site]: crossvalidated
[post_id]: 247189
[parent_id]: 232821
[tags]: 
This is an interesting question, with different issues: MCMC algorithms do not always recycle the computation of the posterior density at all proposed values, but some variance reduction techniques like Rao-Blackwellisation do. For instance, in a 1996 Biometrika paper with George Casella, we propose to use all simulated values, $\theta_i$ $(i=1,\ldots,T)$, accepted or not, by introducing weights $\omega_i$ that turn the average$$\sum_{i=1}^T \omega_ih(\theta_i)\big/\sum_{i=1}^T \omega_i$$into an almost unbiased estimator. (The almost being due to the normalisation by the sum of the weights.) MCMC is often used on problems of large (parameter) dimension. Proposing an approximation to the whole posterior based on the observed density values at some parameter values is quite a challenge, including the issue of the normalising constant mentioned in Tim's answer and comments. One can imagine an approach that is a mix of non-parametric kernel estimation (as in e.g. krigging ) and regression, but the experts I discussed with about this solution [a few years ago] were quite skeptical. The issue is that the resulting estimator remains non-parametric and hence "enjoys" non-parametric convergence speeds that are slower than Monte Carlo convergence speeds, the worse the larger the dimension. Another potential use of the availability of the posterior values $\pi(\theta|\mathcal{D})$ is to weight each simulated value by its associated posterior, as in $$\frac{1}{T}\sum_{t=1}^T h(\theta_t) \pi(\theta_t|\mathcal{D})$$ Unfortunately, this creates a bias as the simulated values are already simulated from the posterior: $$\mathbb{E}[h(\theta_t) \pi(\theta_t|\mathcal{D})]=\int h(\theta) h(\theta_t) \pi(\theta_t|\mathcal{D})^2\text{d}\theta$$ Even without a normalisation issue, those simulations should thus be targeting $\pi(\theta|\mathcal{D})^{1/2}$ and use a weight proportional to $\pi(\theta|\mathcal{D})^{1/2}$ but I do not know of results advocating this switch of target. As you mention in the comments, this is connected with tempering in that all simulations produced within a simulated tempering cycle can be recycled for Monte Carlo (integration) purposes this way. A numerical issue, however, is to handle several importance functions of the form $\pi(\theta)^{1/T}$ with missing normalising constants.
