[site]: crossvalidated
[post_id]: 7257
[parent_id]: 
[tags]: 
Learning weights in a Boltzmann machine

I'm trying to understand how Boltzmann machines work, but I'm not quite sure how weights are learned, and haven't been able to find a clear description. Is the following correct? (Also, pointers to any good Boltzmann machine explanations would also be great.) We have a set of visible units (e.g., corresponding to black/white pixels in an image) and a set of hidden units. Weights are initialized somehow (e.g., uniformly from [-0.5, 0.5]), and then we alternate between the following two phases until some stopping rule is reached: Clamped phase - In this phase, all the values of the visible units are fixed, so we only update the states of the hidden units (according to the Boltzmann stochastic activation rule). We update until the network has reached equilibrium. Once we reach equilibrium, we continue updating $N$ more times (for some predefined $N$), keeping track of the average of $x_i x_j$ (where $x_i, x_j$ are the states of nodes $i$ and $j$). After those $N$ equilibrium updates, we update $w_ij = w_ij + \frac{1}{C} Average(x_i x_j)$, where $C$ is some learning rate. (Or, instead of doing a batch update at the end, do we update after we equilibrium step?) Free phase - In this phase, the states of all units are updated. Once we reach equilibrium, we similarly continue updating N' more times, but instead of adding correlations at the end, we subtract: $w_{ij} = w_{ij} - \frac{1}{C} Average(x_i x_j)$. So my main questions are: Whenever we're in the clamped phase, do we reset the visible units to one of the patterns we want to learn (with some frequency that represents the importance of that pattern), or do we leave the visible units in the state they were in at the end of the free phase? Do we do a batch update of the weights at the end of each phase, or update the weights at each equilibrium step in the phase? (Or, is either one fine?)
