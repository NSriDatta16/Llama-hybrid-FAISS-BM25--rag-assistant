[site]: crossvalidated
[post_id]: 637086
[parent_id]: 637084
[tags]: 
Let $g(p) = \log\left(\dfrac{p}{1-p}\right)$ . Then it sounds like you want to model: $$ g\left(\mathbb E[Y\vert X]\right) = X\beta $$ and estimate $\beta$ as $$\hat\beta = \underset{\hat\beta_0}{\arg\max}\left\{ \sum_i\left[ y_i\log\left(\hat p_i\right) + \left(1 - y_i\right)\log\left(1 - \hat p_i\right) \right]\bigg\vert \hat p_i = g^{-1}\left( \hat\beta_0^TX_i\right) \right\}$$ This is logistic regression when the $y_i\in\left\{0,1\right\}$ , and the estimation $\hat\beta$ is maximum likelihood estimation that gives nice properties for the coefficient point estimates, confidence intervals, and hypothesis tests. You can shoehorn your problem in this kind of model, sure, and you might even get good performance. However, I would hesitate to call it a logistic regression when you lack a binomial-distributed outcome. A term you might use to describe your approach is that you are using an extremum estimator , in this case, optimizing the usual binomial likelihood despite the fact that you definitely do not have a binomial-distributed outcome (you know this with certainty because you do not have integer outcomes). I have my doubts that this is the best approach to your problem and that you need to shoehorn your data into the wrong kind of model when more appropriate models seem to be out there (e.g., explicitly model the ordinal variable, such as with a proportional odds ordinal model), but you won't really know unless you try it.
