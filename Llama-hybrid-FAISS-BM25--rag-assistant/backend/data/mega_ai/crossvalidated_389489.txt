[site]: crossvalidated
[post_id]: 389489
[parent_id]: 389463
[tags]: 
Confidence intervals arise from frequentist probability models. A probability is defined in terms of an experiment that can be repeated infinitely often. For example, we say that a coin is fair if it shows Heads in half of its tosses over the long run. If you have a random sample $X_1, X_2, \dots, X_{10}$ from a normal population with mean $\mu$ and standard deviation $\sigma,$ then one can show that the statistic $$T = \frac{\bar X - \mu}{S/\sqrt{10}} \sim \mathsf{T}(\text{df}= 9),$$ where $\bar X$ is the sample mean, $S$ is the sample standard deviation, and $\mathsf{T}$ stands for Student's t distribution. Then we have $$P(-2.262 This is purely a probability statement. According to the frequentist interpretation of probability, it means that if we do many such 10-observation experiments, the $T$ -statistic will lie between -2.262 and +2.262 in 95% of the cases. With a little algebra the last probability statement is seen to be equivalent to $$P\left(\bar X - 2.262\frac{S}{\sqrt{n}} This amounts to giving a random interval $$\left(\bar X - 2.262\frac{S}{\sqrt{n}},\; \bar X + 2.262\frac{S}{\sqrt{n}}\right)$$ which will 'cover' the unknown population mean $\mu$ for 95% of the 10-observation experiments over the long run. Some people object to using the word 'probability' to describe the last statement. On any one occasion the random interval may include $\mu$ or not. (They say, "Either it covers or it doesn't, there's no probability about it.") So they prefer to use the word 'confidence' instead of 'probability'. [Perhaps this change in terminology would not be necessary, if everyone kept the frequentist definition of probability in mind throughout the discussion. If you're playing American roulette at a well-regulated casino, you don't know whether you you will win on any one spin of the wheel, but you do know you have a larger chance of winning if you bet on Red (18 chances in 38) than if you bet on only the number 10 (1 chance in 38). With a 95% confidence interval, you have 95 in 100 chances of 'winning'.] Even though we don't know for sure whether the 'confidence interval' contains $\mu$ or not for any one sample of size 10, we do know that the procedure by which the interval was obtained will give an interval that covers $\mu$ for 95% of the samples over the long run. Note: In Bayesian probability modeling, one begins with a prior probability distribution. Then this distribution can be combined with information from any one sample to provide a 'probability interval' to describe the experiment at hand. It takes some reading and some thought to understand the philosophical differences between frequentist and Bayesian models.
