[site]: datascience
[post_id]: 37964
[parent_id]: 37962
[tags]: 
I guess the best way to understand it is to read its paper called A generalized feedforward neural network architecture for classification and regression . This article presents a new generalized feedforward neural network (GFNN) architecture for pattern classification and regression. The GFNN architecture uses as the basic computing unit a generalized shunting neuron (GSN) model, which includes as special cases the perceptron and the shunting inhibitory neuron. GSNs are capable of forming complex, nonlinear decision boundaries. This allows the GFNN architecture to easily learn some complex pattern classification problems. In this article the GFNNs are applied to several benchmark classification problems, and their performance is compared to the performances of SIANNs and multilayer perceptrons. Experimental results show that a single GSN can outperform both the SIANN and MLP networks. I have to add this point that the paper is so much old. People usually use Relu nonlinearity these days. Also take a look at here .
