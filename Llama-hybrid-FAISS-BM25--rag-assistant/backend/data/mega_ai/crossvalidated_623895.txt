[site]: crossvalidated
[post_id]: 623895
[parent_id]: 623894
[tags]: 
The aim of a train/test split is to estimate true model performance. To do this in an unbiased way, the test data needs to be independent of the training data. If rows are independent, then a random split like train_test_split() will achieve this. However, if the rows show additional structure like groups (multiple rows per patient/client/visitor etc.), or temporal dependence, then you need an other way to do the splits, e.g., via Scikit-Learn's GroupShuffleSplit() for grouped splits, TimeSeriesSplit() for time series, or PredefinedSplit() for custom splits. Check Scikit-Learn for an overview of the splitter classes. Edit The larger the data, the more stable the estimated performance. With only 150 observations, variance will be very high, and you might switch to nested/repeated cross-validation, or the method suggested by Frank in the comments. It stays important to respect row structure in these options.
