[site]: crossvalidated
[post_id]: 594051
[parent_id]: 594034
[tags]: 
Use nested CV in the following way: in the inner loop, you optimize both algorithms and their hyperparameters, i.e. A (incl. α) vs. B (incl β) Basically, what your "without nesting" approach does. This will give you a readily trained model, i.e. A with some optimal α or B with optimal β the outer loop gets you two important internal validation (or rather, verification) results: is the obtained optimum stable (i.e., is one algorithm consistently preferred, and with reasonably stable hyperparameter)? an estimate of generalization performance which both your approaches lack Keep in mind, though: it is not necessarily a sensible assumption that one algorithm should outperform another. E.g., if LDA works well, there should be no surprise in finding that logistic regression does so, too. Given that your dataset is small, the corresponding uncertainty on your performance estimate may be the limiting factor for the optimization. Make sure you keep an eye on that (and do use proper scoring rules for optimization)
