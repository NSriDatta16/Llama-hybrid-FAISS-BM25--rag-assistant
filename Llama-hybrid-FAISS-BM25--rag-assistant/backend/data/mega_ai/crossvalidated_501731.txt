[site]: crossvalidated
[post_id]: 501731
[parent_id]: 
[tags]: 
Large Mismatch between Validation and Test Set Performance

I have a time-series dataset, which is split into the following sections: First 50% purely for training Next 40% is for validation, split into 20-folds Last 10% is purely for testing This is a balanced binary classification problem, and I am using XGBoost. The problem is that there is a poor correlation between validation performance and test-set performance. For example, Model A has a 56% accuracy on validation sets, and 57% accuracy on test sets. That's good. I wanted to improve the model, so I made Model B. I added some variables, re-tuned the hyperparameters and achieved an accuracy of 58.5% with Model B on the validation set. Then, I see that Model B has an abysmal 46% accuracy on the test set. Why could this be happening? How could I try to fix this?
