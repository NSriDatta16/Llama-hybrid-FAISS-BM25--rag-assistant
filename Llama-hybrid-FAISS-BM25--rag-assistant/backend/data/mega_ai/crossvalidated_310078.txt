[site]: crossvalidated
[post_id]: 310078
[parent_id]: 
[tags]: 
Residual network: why is each block learning residual error with respect to identity mapping?

In original version of neural network, it learns H(x) from input x, and in the residual network, it is said that learning is improved by learning only residual error with respect to identity mapping, which is F(x)=H(x)-x. Can anyone explain why this will improve learning? What if H(x) significantly deviates from identity mapping? Thanks!
