[site]: datascience
[post_id]: 109888
[parent_id]: 
[tags]: 
When linear regression is really a good model to be used?

By definition of linear regression model : If we note $Y$ the real random variable to be explained (endogenous variable, dependent or response) and $X$ the explanatory variable or fixed effect (exogenous). the linear regression model amounts to assuming that, on average, $E(Y)$ , is an affine function of $X$ . $$E(Y) = f(X) = β_0 + β_1X$$ and we write $$Y = β_0 + β_1X + ε (*)$$ with $ε$ following the normal law $N(0,s)$ . Our main goal now is to find the parameters $$(β_0, β_1)$$ using the method of least squares. My question comes from the remark that we use the observations of $Y$ , $Y_i$ (which are random), to estimate the relationship that should model the expectation of $E(Y)$ as a linea function of $X$ . I explain this clearly with the following example: Following the previous definition, I implemented the following code in Python import matplotlib.pyplot as plt import pandas as pd import numpy as np import random from sklearn.linear_model import LinearRegression W = np.random.normal(0,1.5,200) X = np.array([i for i in range(200)]) Y = 0.5 + 0.001*X + W X = X.reshape(-1,1) Y = Y.reshape(-1,1) regressor = LinearRegression() regressor.fit(X, Y) print('Slope : {}'.format(regressor.coef_[0][0])) print('Intercept : {}'.format(regressor.intercept_[0])) I get the following results by running the script two times : for the first time Slope : -0.0014194386100520823 Intercept : 0.594949722904278 In second time Slope : 0.00037356086526345897 Intercept : 0.6948322302347023 As you see, we obtain different values for the slope and the intercept between both tests and the in each case the values obtained are not close to the expected values 0.001 and 0.5 respectively, eventhough the response variable $Y$ is generated according to the theoritical relationship (*). My question is two folds : When the results of the linear regression model are considered to be reliable ? unfortunately it was not the case in this situation where I judged that it will allow for the best modeling for the relationship between X and Y. Is there a different experimental setup when the results of the tests will match or would be close to the expected values ? In other words, how can I improve the previous results ? I see that by increasing the number of observations from 200 to 1000000 the results improve. However it seem to me not reasonable to expect that an experiment need to be repeated 1000000 times for us to be able to make good estimations for the parameters. Thanks in advance for your help.
