[site]: crossvalidated
[post_id]: 27096
[parent_id]: 24664
[tags]: 
Yes, there is a bias. For example, assume your classificator agrees with the expert 80% of the time. Now, there are several options, here are the two extremes: your model is better because the 20% where it does not agree is where the experts are wrong -> your performance is underestimated OR the 20% where you disagree are all cases where the experts are right -> your performance is overestimated. You can find more info by searching for "imperfect gold standard". There are some nice bayesian methods availabe, but I am not familiar enough with them to recommend any. It might also more of a "multiple reader" problem, especially if your experts disagree with each other. And, yes, your model will suffer if you train it with partly wrong class labels. It will try to emulate the flawed experts. I don't know whether any particular method is particular resistant, I think a classificator that outputs a class probability could perform somewhat because you can correct somewhat for a expert bias toward one class by adjusting the cutoff. But that's just my intuition talking.
