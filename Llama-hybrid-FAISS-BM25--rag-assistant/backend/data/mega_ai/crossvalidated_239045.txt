[site]: crossvalidated
[post_id]: 239045
[parent_id]: 
[tags]: 
Is there a reasonable way to impose a prior within a likelihood-based model?

I have been using GAM (mgcv's gam() ) to perform a fairly complex and computationally intensive analysis - I have millions of observations and dozens of terms including 2-D tensor product splines. It gets excellent results for the most part, but some predictions differ an excessive amount from prior expectations. (I have a specific model whose predictions can be used as a prior, and the deviations are being measured relative to this "respected baseline" model.) This could be taken as a cue to use a more Bayesian approach, but the modeling already takes many hours to complete, bam() doesn't help, and I would like to avoid switching to a method like MCMC which I assume is much more computationally intensive. Instead, I'm wondering if it's possible to impose a prior within the existing fitting framework, or something with similar computational demands to what I am now using. For example, drawing on the interpretation of conjugate priors as adding pseudo-observations, could it be reasonable to add some amount of data that matches my prior, and fit to the expanded dataset? If not, what other possibilities might I consider?
