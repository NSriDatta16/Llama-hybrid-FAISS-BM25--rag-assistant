[site]: crossvalidated
[post_id]: 395593
[parent_id]: 395586
[tags]: 
It is possible indeed. As you are looking for a bayesian approach, you may want to read about "maximum a posteriori" (MAP) which is essentially the whay you suggest in your question. Basic idea: find the values of the parameters $w_1, w_2, w_3, w_4$ which maximize $P(w_1, w_2, w_3, w_4 | x, y)$ where $x$ and $y$ are your measured variables. From Bayes rule: $P(w_1, w_2, w_3, w_4 | x, y) = P(x, y | w_1, w_2, w_3, w_4) P(w_1, w_2, w_3, w_4) / P(x,y)$ . You may ignore here the normalization factor $P(x,y)$ . Now you may choose - as you said - some prior $P(w_1, w_2, w_3, w_4) $ and also find the likelihood function $P(x, y | w_1, w_2, w_3, w_4)$ either because you know how your measured variables depend on the parameters, or because you assume some appropiate model for that relationship. Afterwards, you select the values for $w_i$ for maximizing, and this set of parameters is the MAP solution for your problem.
