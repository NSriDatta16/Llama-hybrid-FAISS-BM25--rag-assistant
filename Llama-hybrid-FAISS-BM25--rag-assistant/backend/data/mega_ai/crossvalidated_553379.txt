[site]: crossvalidated
[post_id]: 553379
[parent_id]: 553289
[tags]: 
At any given point in the game, you're $3$ or fewer "perfect flips" away from winning. For example, suppose you've flipped the following sequence so far: $$ HTTHHHTTTTTTH $$ You haven't won yet, but you could win in two more flips if those two flips are $TH$ . In other words, your last flip was $H$ so you have made "one flip" worth of progress toward your goal. Since you mentioned Markov Chains, let's describe the "state" of the game by how much progress you have made toward the desired sequence $HTH$ . At every point in the game, your progress is either $0$ , $1$ , or $2$ --if it reaches $3$ , then you have won. So we'll label the states $0$ , $1$ , $2$ . (And if you want, you can say that there's an "absorbing state" called "state $3$ ".) You start out in state $0$ , of course. You want to know the expected number of flips, from the starting point, state $0$ . Let $E_i$ denote the expected number of flips, starting from state $i$ . At state $0$ , what can happen? You can either flip $H$ , and move to state $1$ , or you flip $T$ and remain in state $0$ . But either way, your "flip counter" goes up by $1$ . So: $$ E_0 = p (1 + E_1) + (1-p)(1 + E_0), $$ where $p = P(H)$ , or equivalently $$ E_0 = 1 + p E_1 + (1-p) E_0. $$ The " $1+$ " comes from incrementing your "flip counter". At state $1$ , you want $T$ , not $H$ . But if you do get an $H$ , at least you don't go back to the beginning--you still have an $H$ that you can build on next time. So: $$ E_1 = 1 + p E_1 + (1-p) E_2. $$ At state $2$ , you either flip $H$ and win, or you flip $T$ and go all the way back to the beginning. $$ E_2 = 1 + (1-p) E_0. $$ Now solve the three linear equations for the three unknowns. In particular you want $E_0$ . I get $$ E_0 = \left( \frac{1}{p} \right) \left( \frac{1}{p} + \frac{1}{1-p} + 1 \right), $$ which for $p=1/20$ gives $E_0 = 441 + 1/19 \approx 441.0526$ . (So the mean is not $413$ . In my own simulations I do get results around $441$ on average, at least if I do around $10^5$ or $10^6$ trials.) In case you are interested, our three linear equations come from the Law of Total Expectation . This is really the same as the approach in Stephan Kolassa's answer , but it is a little more efficient because we don't need as many states. For example, there is no real difference between $TTT$ and $HTT$ --either way, you're back at the beginning. So we can "collapse" those sequences together, instead of treating them as separate states. Simulation code (two ways, sorry for using Python instead of R): # Python 3 import random def one_trial(p=0.05): # p = P(Heads) state = 0 # states are 0, 1, 2, representing the progress made so far flip_count = 0 # number of flips so far while True: flip_count += 1 if state == 0: # empty state state = random.random() = p # state 1 (H) if flip H, state 2 (HT) if flip T else: # state 2, 'HT' if random.random()
