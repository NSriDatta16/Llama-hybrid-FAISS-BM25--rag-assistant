[site]: stackoverflow
[post_id]: 715895
[parent_id]: 
[tags]: 
How can I write a caching HTTP proxy in Perl?

I intend to write a simple HTTP proxy in Perl using the HTTP::Proxy module. I'm clear with the very basic task of how to create a proxy and basic filters and stuff. But what I cannot understand is how to manually force-serve a file through cache. Basically, the scenario is this that I run this proxy in computer A. The user on computer B accesses web uses this proxy. Now, this proxy will just act as a pass through for all B's requests, until he requests a particular URL (a file, say http://abc.com/file.zip ). I need to intercept this request, and instead of allowing him to download the actual file.zip, give him an already downloaded file that I manually kept on computer A. Also, note that I might not have a web server running on computer A, so I can't just redirect the url, I need to serve it from cache. Any pointers for this would be appreciated. Thanks Edit: Some more info. I started using HTTP::Daemon and LWP::UserAgent in combination instead of HTTP::Proxy So far, I intercept all requests successfully, and then I search the headers for the url. If the particular filename is not there, I just pass the request to actual destination using LWP:UserAgent (simple_request) and return the response to original sender using send_response. If I find the filename, I don't further forward the request, instead I'm trying to serve my particular file using "send_file_response" method. The problem is that all other requests are working fine and comp B is able to surf the net, but when it tries to download this file, it just keeps waiting for a response. About using squid, It is not an option for me to install squid on these machines.
