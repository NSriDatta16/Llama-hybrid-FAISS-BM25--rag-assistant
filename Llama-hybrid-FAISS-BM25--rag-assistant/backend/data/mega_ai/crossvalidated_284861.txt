[site]: crossvalidated
[post_id]: 284861
[parent_id]: 
[tags]: 
Do the Determinants of Covariance and Correlation Matrices and/or Their Inverses Have Useful Interpretations?

While learning to calculate covariance and correlation matrices and their inverses in VB and T-SQL a few years ago, I learned that the various entries have interesting properties that can make them useful in the right data mining scenarios. One obvious example is the presence of variances on the diagonals of covariance matrices; some less obvious examples that I have yet to use, but could come in handy at some point, are the variance inflation factors in inverse correlation matrices and partial correlations in inverse covariance matrices. One thing I have yet to see directly addressed in the literature, however, is how to interpret the determinants of these matrices. Since determinants are frequently calculated for other types of matrices, I expected to find a slew of information on them, but I've turned up very little in casual searches of both the StackExchange forums and the rest of the Internet. Most of the mentions I have encountered revolve around using the determinants as a single step in the process of calculating other statistical tests and algorithms, such as Principle Components Analysis (PCA) and one of Hotellingâ€™s tests; none directly addresses how to interpret these determinants, on their own. Is there a practical reason why they're not discussed often in the literature on data mining? More importantly, do they provide any useful information in a stand-alone fashion and if so, how could I interpret the determinants of each? I realize that determinants are a type of signed volume induced by a linear transformation, so I suspect that the determinants of these particular determinants might signify some kind of volumetric measure of covariance or correlation etc. over an entire set, or something to that effect (as opposed to ordinary covariance and correlation, which are between two attributes or variables). That also begs the question of what kind of volume their inverses would represent. I'm not familiar enough with the topic or the heavy matrix math involved to speculate further, but I am capable of coding all four types of matrices and their determinants. My question is not pressing, but in the long run I will have to make decisions on whether or not it's worthwhile to regularly include these matrices and their determinants in my exploratory data mining processes. It's cheaper to just calculate the covariance and correlation in a one-on-one, bivariate manner in these particular languages, but I'll go the extra mile and implement determinant calculations if I can derive some deeper insights that justify the expense in terms of programming resources. Thanks in advance.
