[site]: datascience
[post_id]: 55510
[parent_id]: 41680
[tags]: 
You can see I have set up a basic pipeline here using GridSearchCV, tf-idf, Logistic Regression and OneVsRestClassifier. In the param_grid, you can set 'clf__estimator__C' instead of just 'C' import numpy as np from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.multiclass import OneVsRestClassifier from sklearn.linear_model import LogisticRegression from sklearn.model_selection import GridSearchCV from sklearn.pipeline import Pipeline tfidf_vectorizer = TfidfVectorizer(smooth_idf=True) log_reg_clf = OneVsRestClassifier( estimator=LogisticRegression( intercept_scaling=1, class_weight='balanced', random_state=0 ) ) # Create regularization hyperparameter space C = np.logspace(0, 4, 10) param_grid = [{ 'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)], 'vect__max_features': (None, 5000, 10000, 50000), 'vect__norm': ['l1','l2'], 'clf__estimator__C': C, 'clf__estimator__penalty': ['l1','l2'] }] log_reg_clf_tfidf = Pipeline([ ('vect', tfidf_vectorizer), ('clf', log_reg_clf) ]) print(log_reg_clf_tfidf.get_params().keys()) gs_logReg_tfidf = GridSearchCV( log_reg_clf_tfidf, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1 ) gs_logReg_tfidf.fit(X_train, y_train) print("The best parameters: \n", gs_logReg_tfidf.best_params_) print("The best score: \n", gs_logReg_tfidf.best_score_) df_test_predicted_idf = gs_logReg_tfidf.predict(X_test)
