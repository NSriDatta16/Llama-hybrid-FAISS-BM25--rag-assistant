[site]: crossvalidated
[post_id]: 621416
[parent_id]: 
[tags]: 
When do numerical transforms need sample-weighting before applying linear regression

Just wondering if anyone knows of any good resources for sample-weighting in numerical transformations. That is with the intent of using the transformed data in a linear regression model I work with times-series data where we weight linear regression models for recency. i.e older data has a lower weight This is done using the sample_weight parameter in sklearn LinearRegression In preprocessing, if we apply scaling e.g using mean normalization, we use the same sample weights as we use for the regression. This is directly supported by the sklearn StandardScaler However there are other transformations we can apply in the model pipeline before we do scaling/model fitting Intuitively I feel like at least some of these should be using sample weights in the same way as the scaler/regression-model. For example - If we want to use a yeo-johnson transformer. This transformer effectively tries to transform our data to have a gaussian shape. Clearly weighting the data can have an impact on how the yeo-johnson transformer transforms our data. However the implementations of yeo-johnson that i've seen from scipy and feature-engine do not support sample weights. So I'm not sure if there's a good reason that it's been left out or if they just haven't got round to implementing
