[site]: stackoverflow
[post_id]: 661956
[parent_id]: 621344
[tags]: 
No reputation system is secure, without real life verification. If anonymous people can be invited then it can always be gamed, with sufficient effort and false identities. Your aim should be to increase the cost of such gaming above the potential gain, which will depend on what your system gets used for. The main cost you can use to inhibit power gains is forcing users to contribute positively reviewed contributions before you increase their standing. How you do this, and how you make it difficult for them to leverage existing identities to falsely rate as positive the contributions of new identities they are trying to give power to, is the nuts and bolts of the system; and should make use of an existing user base to spot and penalise spurious false positives. You can make use of game theory by rewarding people for being in the majority. So if A accuses B of wrong-rating, it is highlighted and lots of people get to vote on it. Those who cast their mojo on the side of the vote that ends up winning, get it back and increase in reputation for reliability (it is worth having more than one type of reputation), while those in the minority, lose a triangle number of mojo (one the first time, 2 the next, 3 the next, 6 the next, 10 the next, and so on)
