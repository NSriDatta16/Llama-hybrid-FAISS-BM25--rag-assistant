[site]: crossvalidated
[post_id]: 210432
[parent_id]: 210403
[tags]: 
The definition of a distribution as assigning probabilities to each possible event works for discrete distribution, but becomes trickier for continuous distributions, where e.g. any number on the real line could be the outcome. Very often when talking about distributions, we think of them as having fixed parameters such as a binomial distribution having two parameters: firstly, the number of observations and secondly a probability $\pi$ of a single observation being an event. Typical parametric statistical models describe how the parameter(s) of a distribution depend on certain things such as factors (a variable that has discrete values) and covariates (continuous variables). For example, if in a normal distribution you assume that the mean can be described by some fixed number (an "intercept") and some number (a "regression coefficient") times the value of a covariate, you obtain a linear regression model with a normally distributed error term. For a binomial distribution, one commonly used model ("logistic regression") is to assume that the logit of the probability $\pi$ of an event ($\pi/(1-\pi)$) can be described by a regression equation such as $\text{intercept}+\beta_1 \text{covariate}_1+\ldots$. Similarly, for a Poisson distribution a common model is to assume this for the logarithm of the rate parameter ("Poisson regression").
