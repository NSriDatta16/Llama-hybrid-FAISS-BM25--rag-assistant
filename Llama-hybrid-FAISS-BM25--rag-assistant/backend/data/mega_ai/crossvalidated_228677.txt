[site]: crossvalidated
[post_id]: 228677
[parent_id]: 182112
[tags]: 
Have you trained some network with the setting you have mentioned? I have not yet, but if we think in some function like $y=\sqrt{x}$ or $y=sin^{-1}(x); x\in [0,2\pi ]$, these are simple functions, however if you want to approximate them, complex values should be supported by the learned transformation $x\mapsto f(x) = y$, i.e. in order to approximate functions like the mentioned ones, the network's architecture must be endowed with complex valued basis funtions 1 . Otherwise, the imaginary part of the image of $f(x)$ could be lost. It is seemed to the case of approximating an injective function, where more than a $x$ corresponds to a $y$, e.g. $y = f(x) = x^2$. Then try to approximate $f^{-1}(y) = x$. I hope this helps. Complex valued neural networks
