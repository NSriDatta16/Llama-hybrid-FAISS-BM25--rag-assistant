[site]: crossvalidated
[post_id]: 523022
[parent_id]: 523007
[tags]: 
If the coin toss going wrong is just a random thing that has nothing to do with what the result of the coin toss would have been (had nothing gone wrong), then ignoring the result of this particular toss is the easiest. Pretending that we are completely certain or that we only add a downscaled weight to the second shape parameter (options 2 and 3) ignores the possibility of the toss could have ended up as heads (i.e. it's not quite right). Adding 0.3 and 0.7 is the right thing to do, if you truly believe that there was a 30:70 probability that the coin would have come up heads vs. tails. However, note you need to believe this no matter how unfair the coin would be in truth. Perhaps, it only looks like that conditional on the coin being fair? Let's look at an extreme example: You have observed 99 heads and 0 tails A coin toss goes wrong and you feel like that was 30% likely to be heads and 70% tails. With option 4, your belief about the proportion of heads before this 100th toss was a 95% credible interval from 0.994 to 0.9997. After this toss it's 95% CrI from 0.95 to 0.998. Before this toss, what the probability that the proportion is below what is now your lower CrI limit was less than $2 \times 10^{-22}$ , but now it's 0.025. You may question whether that seems quite right, but it's indeed the right update to your belief, if you really think that toss would have landed tails up with 70% probability and heads-up with 30% probability. Another issue with option 4 is that if you keep having such "failed" coin tosses and they all favor tails over heads (in your judgement) by 70:30, then you eventually converge to believing in a probability of the coin coming up tails being 70%. Again, as above this may be the right update. An alternative model of what is going on is that you think that if this is a fair coin, then what you saw was increasing the probability of this toss ending up tails from 50% to 70% (=increasing the log-odds from 0 to log(0.7)-log(0.3)=0.8472979). So, in that case your belief about the coin overall influences what you believe the outcome of this coin toss was. In fact, the more you learn, your opinion on this toss will change as more data comes in in the future. In that case, some simple conjugate updating rule will not work. I feat you'll have to write down an explicit model and do MCMC sampling for it, I fear. That could look like this: Observed coin tosses follow $Y_i \sim \text{Binary}(\pi)$ Messed up tosses also follow $Z_i \sim \text{Binary}(\pi)$ for the latent (but unobserved) outcome they would have had We only observe that $ P(Z_i = 1)$ is $\text{logit}^{-1}(\text{logit}(\pi)-0.847)$ . That's actually surprisingly hard to code up in Stan (my normal preferred MCMC sampler) due to the discrete latent variable, but presumably this is possible to deal with, but it's definitely a bit messy.
