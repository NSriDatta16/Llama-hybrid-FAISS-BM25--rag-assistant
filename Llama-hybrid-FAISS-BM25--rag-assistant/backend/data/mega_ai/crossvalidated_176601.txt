[site]: crossvalidated
[post_id]: 176601
[parent_id]: 
[tags]: 
How to deal with unbalanced data and large dataset on low budget?

If we have a dataset with 5:1 Ratio and 500.000 observations we can randomly sample the majority class getting in this case 100.0000 minority class and 100.000 majority class? I'm wondering this because I wanna test non-linear kernels SVM and Neural Network, but don't work well with large-scale datasets because of complexity. (I want to select the best model)
