[site]: stackoverflow
[post_id]: 3101341
[parent_id]: 3097658
[tags]: 
Not sure if I'm following what you're describing, but it sounds like you need to do the following: In the context of a search, represent different types of entities in a common way There are potentially large numbers of entities returned in a result set Only need to provide further depth when individual entities are accessed This sounds like an ideal use for Solr . Solr is the open-source search framework built on top of Lucene . It provides access over HTTP to a Lucene-based search index, using XML as the payload basis. It is REST-oriented, speaks JSON as well, so it's language-agnostic. Most implementations of Solr run behind-the-scenes, with access to results served up behind a website's search results page. Your requirements might actually be a great fit for exposing access to a Solr server's query directly. All the elements of working with the results are already handled -- paging, filtering, sorting, etc. All the logistics work that you really don't want to do yourself. As the implementor, your real work is determining what goes in your search index. The index could be structured to hold the common elements of your variant entities, and the search speed would be blazingly fast. Upon retrieval of a given resultset, your application could retrieve deeper details of an entity from its original source (if you didn't want to push the entire entity into the search index, which is another possibility.)
