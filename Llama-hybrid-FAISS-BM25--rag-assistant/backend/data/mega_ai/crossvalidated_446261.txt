[site]: crossvalidated
[post_id]: 446261
[parent_id]: 446250
[tags]: 
$P(\theta)$ and $P(y)$ are priors; you can easily apply the same intuition you have for $P(y|\theta)$ by pretending they are conditionals $P(y|Z)$ and $P(\theta|Z)$ where Z is a latent variable you don't care about - if you describe $P(y|\theta)$ is a surface, they, too are surfaces. The 3D cube you've shown assumes that $y$ and $\theta$ are flat surfaces, and they can be - but since they can be functions of another variable, they too can be warped. Geometrically, this would push the joint density curves up or down, depending on whether the warping produces a 'hill' or a 'sinkhole', and since the elevation of the curve represents probability, make the corresponding interval of values accordingly more or less likely. Conditioning on the variable values corresponds to taking a slice of the cube cut along the axis representing that variable, e.g. $p(y,\theta|y=4)$ picks and isolates one of the colored curve graphs - in this case, the one whose endpoint crosses $y$ at 4 (I believe it's the first red curve). Now, something like the probability $p(\theta=0.4)$ is indeed a bit arbitrary. The prior probability of the parameters depends... more or less on how much reason you have to favor some values over others. This is both a weakness and a strength. A bad prior may warp your results, and it's not something trivially verifiable. You can use a uniform prior to represent total ignorance, but sometimes a prior too far from the actual value is a problem. If you make a strong assumption and you're wrong , you will throw out perfectly correct conclusions as unlikely. Your reasoning is only as strong as your model. On the flip side, it represents the modularity of the Bayesian updating. Your priors in one experiment may be your posteriors from a previous one, and if your high-level assumptions are correct (e.g. you don't suddenly get negative counts for something you thought was Binomial), the updates will asymptotically update to the true value.
