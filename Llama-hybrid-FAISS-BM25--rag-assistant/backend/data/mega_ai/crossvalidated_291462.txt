[site]: crossvalidated
[post_id]: 291462
[parent_id]: 291451
[tags]: 
my opinion is that max&mean pooling is nothing to do with the type of features, but with translation invariance. Imagine learning to recognise an 'A' vs 'B' (no variation in A's and in B's pixels). First in a fixed position in the image. This can be done by a logistic regression (1 neuron): the weights end up being a template of the difference A - B. Now what happens if you train to recognise on different locations in the image. You cannot do this with logistic regression, sweeping over the image (ie approximating a convolutional layer with one filter) and labelling all sweeps of the image A or B as appropriate, because learning from the different positions interferes - effectively you try to learn the average of A-B as A/B are passed across your filter - but this is just a blur. with max pooling learning is only performed on the location of max activation (which is hopefully centred on the letter). I am not so sure about mean pooling - I would imagine that more learning (ie weight adjustment ) is done at the max activation location and that avoids the blurring)... I would encourage you to just implement such a simple network with 2 classes and 1 filter for convolutional layer, then max/mean pooling and 1 output node and inspect the weights/performance.
