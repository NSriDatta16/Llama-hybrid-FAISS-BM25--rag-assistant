[site]: crossvalidated
[post_id]: 489359
[parent_id]: 
[tags]: 
Association between Current state/action and the far future reward

How the Agent make the association between the current $Q_t(s_t,a_t)$ and a far future reward that by nature of my environment we get reward at least after 10-15 time steps from the action taken. If the rewards are collected in Replay Buffer and sampled at random then its probably gonna be broken, else if online training is used what part of the $Q$ update will consider the future reward ? Edit: I have noticed another similar question Delayed Rewards in Reinforcement Learning . Yet, but it had fixed delay period, here the delay is stochastic and reward may not occur.
