[site]: crossvalidated
[post_id]: 614416
[parent_id]: 614399
[tags]: 
For instance, I run a logistic regression in males to obtain the OR for death and age and then I run the logistic regression for females to obtain the OR, and then I compare the two ORs using test for interaction. That is not the "test for interaction" that the page you link describes. The test there is based on two nested models, not two separate models for males and females. One model includes predictors individually (e.g., ~ age + sex ) and the other including the interaction between them (often coded ~ age*sex in R, which expands to ~ age + sex + age:sex , with age:sex the interaction term). The two nested models are then compared by a likelihood-ratio test. The "signficance" of the coefficients reported for a single model with interactions is typically evaluated instead by a t -test or Wald test. There's nothing wrong in principle with that, as in the limit of large sample sizes the results converge to those of the likelihood-ratio test. There nevertheless can be some confusion about lower-level coefficients in such models, even with lower-level interaction coefficients when the model includes higher-level interactions, as their values depend on the coding of interacting predictors. The Anova() function in the R car package can test all coefficients associated with a predictor in a joint t -test or Wald test. That overcomes those difficulties in interpreting the individual coefficients. So the difference between the properly constructed "interaction test" based on two models and the properly constructed test of interaction coefficients in a single model is the difference between the likelihood-ratio test used in the first approach and the t -test or Wald test used in the second approach. This UCLA web page explains how the tests typically reported for models fitted by maximum-likelihood methods differ.
