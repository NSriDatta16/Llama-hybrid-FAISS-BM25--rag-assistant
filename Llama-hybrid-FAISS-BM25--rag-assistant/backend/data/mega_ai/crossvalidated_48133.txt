[site]: crossvalidated
[post_id]: 48133
[parent_id]: 
[tags]: 
Sum standard deviation vs standard error

I'm having difficulty in determining what exactly the difference is between the 2, especially when given an exercise and I have to choose which of the 2 to use. These is how my text book describes them: Sum standard deviation Given is a population with a normally distributed random variable $X$. When you have a sample $n$ from this population the population is: $X_{sum} = X_1 + X_2 ... + X_n$ with $\mu_{Xsum} = n \times \mu_x$ and $\sigma_{Xsum} = \sqrt{n} \times \sigma_x$. Standard error When you have a normally distributed random variable $X$ with mean $\mu_X$ and standard deviation $\sigma_X$ and sample length $n$, the sample mean $\bar{X}$ is normally distributed with $\mu_{\bar{x}} = \mu_X$ and $\sigma_{\bar{x}} = \dfrac{\sigma_X}{\sqrt{n}}$ These 2 are awefully similair to me to the point I can't at all decide which to use where. Here are the problems where I discovered I couldn't: Problem 1 A filling machine fills bottles of lemonade. The amount is normally distributed with $\mu = 102 \space cl$. $\sigma$ = $1.93\space cl$. Calculate the chance that out of 12 bottles the average volume is $100 \space cl$. The problem itself is easy, however the troublesome part is what to choose for the standard deviation of the sample. Here they use $\dfrac{1.93}{\sqrt{12}} $ which I can live with, until I encountered the second problem. Problem 2 A tea company puts 20 teabags in one package. The weight of a teabag is normally distributed with $\mu = 5.3 \space g$ and $\sigma = 0.5 \space g.$ Calculate the chance that a package weighs less than 100 grams. Here I thought they'd also use $\dfrac{0.5}{\sqrt{20}}$, but instead they use $\sqrt{20} \times 0.5$. Can someone clear up the confusion?
