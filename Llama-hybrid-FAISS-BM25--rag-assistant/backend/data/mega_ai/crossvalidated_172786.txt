[site]: crossvalidated
[post_id]: 172786
[parent_id]: 
[tags]: 
Is it possible to construct a hypothesis test for the existence of a mean of a symmetric distribution?

In practice, we often assume that the process we are examining has a mean, and so statistics involving averages are defined. As pure conjecture, I was wondering if one can construct a hypothesis test for the existence of a mean. This seemed a bit too broad, so how about the more limited case where the data are iid observations of a symmetric distribution? Here's what I've tried so far, and where I got stuck: Assume: $E[X_i]=\mu \in (-\infty,\infty)\;\textrm{and} \;X_i \sim F(x_i;\mu)$ Then: $$\bar{X}_n := \frac{\sum_{i=1}^n X_i}{n} \xrightarrow{wp1} \mu\; \textrm{by SLLN}$$ We also know that the distribution of $\bar{X}_n$ will converge to a stable distribution $f(x; \alpha,\beta,c,\mu)$, where $\beta=0,\alpha>1$ (to ensure it is both symmetric and has a mean), thus: $$\bar{X}_n \xrightarrow{d} f(x;\alpha,0,c,\mu)$$ I didn't find this very helpful, because there are still too many free parameters. Therefore, I tried another adjustment: Let $Y_n=X_{n}-\bar{X}_{n-1},\; n>1$ then: $$\lim_{n\to \infty} E[Y_n] = E[X_n] - E[\bar{X}_{n-1}] = \mu - \lim_{n\to \infty} E[\bar{X}_{n-1}] = \mu-\mu = 0 $$ Where the third expression is justified by observing that $E[\bar{X}_k]$ is a constant function in $k$: $$E[\bar{X}_k] = \frac{1}{k}\sum_{i=1}^k E[X_i] = \mu \;\forall k\implies \lim_{k\to\infty} E[\bar{X}_k] = \mu$$ So, we can now say that: $$Y_n \xrightarrow{d} f(y;\alpha,0,c,0)$$ Issue What I really want it so find a series of transformations of $Y_n$ that allow me to get a sequence of random variables $G_n$ such that: $$G_n \xrightarrow{d} f(g;\alpha,0,1,0)$$ Then, I want to construct an asymptotically correct hypothesis test from an observation of $G_n$: $$H_0: \alpha > 1;\; H_a: \alpha\leq 1$$ So we have the test: $$T(a;R\subset \mathbb{R})=1 \implies a \notin R,$$ $$T= 0\;o/w$$ Where $a=G_n$, and we define $R:=R_n$ such that $E_{\alpha>1}[T(G_n;R_n)]\leq P(\textrm{Type I error})$, where we have some pre-specified Type I error rate. Thoughts so far I don't know how to find such a sequence, but it appears that some work has been done on direct inference on $\alpha$. See here . I think that a reasonable test would be as follows: Partition the sample into $K$ groups. Let $Y_{i,k}:= X_{i,k} - \bar{X}$ be the mean corrected values using the grand mean. For each $k \in K$ calculate the partition sample mean $\bar{Y}_k$ Assume that $\bar{Y}_{k}$ are observations from an $\alpha-$stable distribution with $\beta=\mu=0$ Estimate $\alpha$ using one of the methods listed here and approx. (1-p)%-confidence interval $I_p$. If $\alpha Not sure if there area any issues with this though.
