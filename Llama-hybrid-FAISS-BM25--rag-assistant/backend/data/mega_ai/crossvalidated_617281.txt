[site]: crossvalidated
[post_id]: 617281
[parent_id]: 
[tags]: 
Exact steps for rolling window CV evaluation or sliding window CV evaluation for SARIMA

So far I have using this process: 1)split data into training and test 2)do model selection(p,d,q, P,D,Q,etc) using training data(in this case, I used autoarima) from pmdarima import auto_arima arima_model=auto_arima(x_train,start_p=1, start_q=1, d=1, test='adf', max_p=10, max_q=10,trace=True,seasonal=True) Doing the CV : I am using the whole data set, with hyperparameters found in step 2. the starting window is the training set from step 1: I train the model, forecast h steps, calculate metrics, then slide/expand the window(depending on rolling vs sliding), forecast/evaluate. repeat until the end. from pmdarima.model_selection import RollingForecastCV from statsmodels.tsa.arima.model import ARIMA cv2 = RollingForecastCV(step=1, h=5,initial =window_size) cv_generator2 = cv2.split(d1) rmse2=[] mae2=[] for i in range(0,iterations): a=next(cv_generator2) model = ARIMA(d1.iloc[a[0]], order=(3,1,3)) model_fit = model.fit() yt_forecasted = model_fit.forecast(steps=5) rmse2.append(np.sqrt(mean_squared_error(d1.iloc[a[1]].to_numpy().flatten(), yt_forecasted))) mae2.append(mean_absolute_error(d1.iloc[a[1]].to_numpy().flatten(), yt_forecasted)) average the metric somehow( in this case I'm just taking a simple average). However I have been discussing with Bing Chat and they claim that the model selection with autoarima should be done in each iteration of the loop:" The auto_arima function is used within the for loop in the example code to select the best ARIMA model for each training set. This allows the model to adapt to changes in the data over time. If the auto_arima function was used before the for loop, it would only select a single ARIMA model based on the first training set. This model may not be the best fit for subsequent training sets. Using the SARIMAX function within the for loop allows us to refit the selected ARIMA model to each training set. This ensures that the model is updated with the most recent data and can make accurate predictions for each test set." Is this a valid method, and if so, is it better than the steps I've been using? In fact, are the steps I'm using valid?
