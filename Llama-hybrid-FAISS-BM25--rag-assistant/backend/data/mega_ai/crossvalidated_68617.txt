[site]: crossvalidated
[post_id]: 68617
[parent_id]: 68558
[tags]: 
I think they are modelling each pixel as a mixture of gaussians - this is a model of the background see eg opencv http://docs.opencv.org/modules/video/doc/motion_analysis_and_object_tracking.html BackgroundSubtractorMOGÂ¶ An improved adaptive background mixture model for real-time tracking with shadow detection, Proc. 2nd European Workshop on Advanced Video-Based Surveillance Systems, 2001: http://personal.ee.surrey.ac.uk/Personal/R.Bowden/publications/avbs01/avbs01.pdf My simplified understanding: you model each pixel (separately) as a MOG. Take 1 gaussian case- for each pixel you calculate running average, and standard deviation. So now you calculate z-score of intensity value wrt your gaussian model - if its an outlier you declare "rat" so previously you were marking X[i,j,t+1]-X[i,j,t]>threshold ="rat" instead (X[i,j,t+1]-mean[i,j])/stddev[i,j] > threshold ="rat" [and more complicated with real mixture of gaussians] To clarify- what is being built is a statistical model of a "background" pixel. The current method can be interpreted as assuming each pixel has constant intensity: taking difference (in time) identifies the foreground "objects". Next level up, we model background pixel values as normally distributed: we estimate the mean and standard deviation of each pixel by a running average calculation. This basically allows us to ignore "typical variations" - ie areas which are constantly changing pixel values are ignored (eg leaves on tree?) - you need a bigger change there than in areas of low "typical variation". Finally, Mixture of Gaussians allows you cope with more complicated "typical patterns of variation".
