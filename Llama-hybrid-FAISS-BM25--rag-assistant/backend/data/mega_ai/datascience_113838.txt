[site]: datascience
[post_id]: 113838
[parent_id]: 113809
[tags]: 
Potential solutions are a linear or a Random Forest regressors. Here is a code example, with data generated like yours: from sklearn.ensemble import RandomForestRegressor from sklearn.datasets import make_regression from sklearn.linear_model import LinearRegression #%% X, y = make_regression(n_samples=100, n_features=1, n_targets=3, n_informative=1, random_state=0, shuffle=False) print(X) print(y) #%% model = LinearRegression() # fit model model.fit(X, y) # make a prediction row = [0.21947749] yhat = model.predict([row]) # summarize prediction print(yhat[0]) model = RandomForestRegressor() # fit model model.fit(X, y) # make a prediction row = [0.21947749] yhat = model.predict([row]) # summarize prediction print(yhat[0]) If the linear regression is not good enough, you can also try with a Logistic Regression instead: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html More information about Random Forest Regressor: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=random+forest+regressor#sklearn.ensemble.RandomForestRegressor See also: https://machinelearningmastery.com/multi-output-regression-models-with-python/
