[site]: crossvalidated
[post_id]: 349939
[parent_id]: 349810
[tags]: 
Given the lumpiness of the residuals, no response transformation in a model fitted using lm is going to overcome that. Your attempted logit transformation appeared to lessen the problem, but only because you discarded all the 0s and 1s, thus undoubtedly biasing the estimates. From here, it seems that the logit may indeed be an effective modeling choice, but not the way you are going about it. And you mention $N_e$ several times as if we know what it is, and don't explain it. I'm guessing that your response values are proportions of the form $x/N_e$, where $x$ is some count of a binary outcome, and that $N_e$ is the number of outcomes total for each observation. If that is the case, and under a model that says these outcomes are independent, I think a logistic regression model is more appropriate. It would be fitted using the glm function; something like: mod This does incorporate the logit transformation, in the sense that the logit is the default link function for a binomial model. Once you settle on a model, you should use the emmeans package for post-hoc comparisons, rather than lsmeans , which is being deprecated.
