[site]: crossvalidated
[post_id]: 100260
[parent_id]: 100020
[tags]: 
Interesting question. The trick to this is that, in order to do multiple imputation, you need more than just a predictive model (which could/would be easy to obtain in, say, a machine learning approach). We'll call these models simulating models, since they're not quite probability models. The combined aspect of feature selection (big $p$) and training a simulating model makes me think that a Bayesian approach is the best. That also means that there's not a clear approach to this. To me the best approach would have the following approach: Identify all missingness patterns For each pattern, use a Bayesian feature selection approach to assign posterior weights to complete cases in the data. Randomly sample complete cases iteratively to generate complete data frames.
