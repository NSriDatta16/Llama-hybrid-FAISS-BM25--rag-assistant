[site]: crossvalidated
[post_id]: 233532
[parent_id]: 233512
[tags]: 
I'll copy my answer from the very related question How few training examples is too few when training a neural network? (any update will be performed there): It really depends on your dataset, and network architecture. One rule of thumb I have read (e.g., in (2)) was a few thousand samples per class for the neural network to start to perform very well. In practice, people try and see. It's not rare to find studies showing decent results with a training set smaller than 1000 samples. (2) Cireşan, Dan C., Ueli Meier, and Jürgen Schmidhuber. "Transfer learning for Latin and Chinese characters with deep neural networks." In The 2012 International Joint Conference on Neural Networks (IJCNN), pp. 1-6. IEEE, 2012. https://scholar.google.com/scholar?cluster=7452424507909578812&hl=en&as_sdt=0,22 ; http://people.idsia.ch/~ciresan/data/ijcnn2012_v9.pdf : For classification tasks with a few thousand samples per class , the benefit of (unsupervised or supervised) pretraining is not easy to demonstrate.
