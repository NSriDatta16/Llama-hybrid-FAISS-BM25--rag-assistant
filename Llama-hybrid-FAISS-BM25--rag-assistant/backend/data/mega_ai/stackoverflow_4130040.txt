[site]: stackoverflow
[post_id]: 4130040
[parent_id]: 4128355
[tags]: 
I have not faced such issue before, but I have some theories about better speed . When system persist data as 40-byte characters and there is a index on it, the index would be as short as enough to distinguish the exactly record poisition of data. For example: 0101101.... => 010(3-byte index) 0111111.... => 011(3-byte index) In another way, when system persist data as 8-byte(Int64) integer and there is a index on it, the index should be exactly 8 bytes per record. In generic database theory, the less storage used, the more query performance gained. If your data is much enough that database need all of the characters(40-byte character) to index the record, the size of index would be 40-byte on some records. And the 8-byte integer index, as explained, still stay in 8 bytes however data grown. There is a precondition in above theory: the matched data should only occupy as a small part of all. There is a significant factor to concern for effort of index maintenance: You need 20 indexes(logically) to speed up the 20 Int32's strategy. There is only one index, indeed, needed for 80-character strategy and for single Int64 strategy. Let's explain if the index doesn't work, which means the database system execute query using full-table-scan(FTS) strategy. We assume the 40-byte(character) data is persisted as 40 bytes per record, every page in SQL Server can hold 8K * 1024 / 40 = 204 records. For 8-byte(Int64) data with 8 bytes per record, every page in SQL Server can hold 8K * 1024 / 8 = 1024 records. If you have 20000 records, database need 20000 / 204 = 99 I/O's to perform FTS, and 20000 / 1024 = 20 I/O's for the other one. The less I/O's needed, the more performance gained.
