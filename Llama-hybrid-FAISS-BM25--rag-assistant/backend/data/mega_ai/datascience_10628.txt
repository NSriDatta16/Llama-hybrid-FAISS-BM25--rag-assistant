[site]: datascience
[post_id]: 10628
[parent_id]: 
[tags]: 
Questions regarding deep learning?

I have questions regarding this Normalized weights and Initial inputs video on Udacity course Deep Learning In this video the lecturer talks about variables that go into Big-loss function should have zero mean and equal variances. I canâ€™t figure about which variables the lecturer is talking about. Are they weights and biases or are they soft-max function and labels in the Big-loss function? And how would zero mean and equal variance help in optimization? The other question I have is, in the video the lecturer talks about weight initialization randomly using Gaussian distribution, I cannot understand how can we initialize weights using Gaussian distribution with zero mean and standard deviation sigma? And where optimizer will move the point (initialized weight), up or down to find the local minima? So can you recommend me a book that I should study before taking this course, so that problems like these don't occur?
