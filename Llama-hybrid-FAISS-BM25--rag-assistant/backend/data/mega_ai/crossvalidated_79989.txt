[site]: crossvalidated
[post_id]: 79989
[parent_id]: 79986
[tags]: 
(This could have been a comment but gets a bit too long). The "final precision score" seems vaguely defined here. If you just had three independent experiments trying to measure the same underlying parameter (let's call it "truthness"), you could just pool your results and work out the overall score of $\frac{\sum{TP}}{\sum{TP + FP}}$. But in fact it looks like you want to compare three independent experiments that are measuring different underlying parameters - the truthness as measured by rule 1, by rule 2 and rule 3. There's no statistical way of judging between the three rules - perhaps rule 1 is the best measure and it's a really bad machine learning method, perhaps rule 3 and 2 are and it's good. You need some extra (non-statistical) information to judge which of the rules is more useful for you.
