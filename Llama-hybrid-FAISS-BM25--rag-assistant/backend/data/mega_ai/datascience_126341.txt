[site]: datascience
[post_id]: 126341
[parent_id]: 
[tags]: 
Feature importance using random forest vs. SHAP

I recently came across SHAP while looking for feature-importance methods. To use SHAP, first a model needs to be created, and then based on the predictions made by the model, SHAP values are calculated. If I use a random forest model and then calculate the SHAP values, how much is the role of the model accuracy? If the model accuracy is not very good (50-60%), can SHAP values be considered reliable? Or if the model accuracy is good (>90%), why SHAP is used if random forest can provide me the feature importance? Could someone explain the role of model accuracy while considering SHAP for determining feature importance?
