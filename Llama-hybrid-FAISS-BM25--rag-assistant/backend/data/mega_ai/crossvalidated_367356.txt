[site]: crossvalidated
[post_id]: 367356
[parent_id]: 
[tags]: 
Why is it difficult to learn a single kernel that performs well at all positions in the convolutional feature map?

I am reading Deep Learning book by Ian Goodfellow, in which they wrote (in chapter 9, section 9.5) that: " ... MATLAB refers to this as full convolution, in which enough zeros are added for every pixel to be visited k times in each direction, resulting in an output image of width m + k âˆ’ 1 . In this case, the output pixels near the border are a function of fewer pixels than the output pixels near the center. This can make it difficult to learn a single kernel that performs well at all positions in the convolutional feature map." From these lines, I understand that the output pixels near border are a function of fewer input pixels (because of added zero padding) but I do not understand how it becomes difficult to learn a single kernel using full convolution
