[site]: crossvalidated
[post_id]: 556182
[parent_id]: 556038
[tags]: 
I think that what Breiman refers to as "algorithmic models" would roughly correspond to what statisticians would recognise as non-parametric methods --- i.e., methods that do not assume an underlying parametric model for the data. Likewise, what he refers to as a "stochastic data model" would roughly correspond to what statisticians would recognise as parametric-models --- i.e., models that assume an underlying probability distribution within a restricted class parameterised by a relatively small number of parameters. The examples given on the first page of the paper (linear regression, logistic regresion, Cox model) are of this type. Brieman's argument is essentially that statisticians rely on parametric models that often do not conform to the underlying processes generating the data. He discusses this in Section 5 of the paper, where he notes that "If the model is a poor emulation of nature, the conclusions maybe wrong." One might argue that this criticism is overbroad, since statisticians using parametric models can use diagnostic testing to check if their model assumptions are contradicted by the observed data (and then form a different model or use non-parametric methods if the present model is no good). On this point, Brieman is of the view that this is not done with sufficient regularity. He states that "A few decades ago, the commitment to data models was such that even simple precautions such as residual analysis or goodness-of-fit tests were not used. The belief in the infallibility of data models was almost religious." (p. 202) If I may offer an analysis of Brieman's views here, I think it is certainly fair to point out that analysts using parametric models do not always do their due diligence by looking at diagnostic plots and tests. I think it is also fair to say that analysts sometimes make inferences from models that are heavily affected by untested model assumptions, and which are not robust to changes in assumptions (e.g., making inferences about tail probabilities in parametric regression models). I don't think it is statisticians who are primarily making these errors, but evidently Brieman does. If you do proper diagnostic testing of a parametric model, and are careful with the kind of inferences you make, this significantly blunts the critique made by Brieman, since there is then an empirical test of the model assumptions affecting the inferences. Many "machine learning" models like the random forest model can be regarded as non-parametric statistical methods. Guys like Breiman have done a great service in developing these models. I'm not convinced that this is a separate field to what statisticians have always considered as the broad class of non-parametric methods.
