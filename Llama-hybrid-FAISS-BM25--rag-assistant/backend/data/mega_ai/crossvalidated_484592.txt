[site]: crossvalidated
[post_id]: 484592
[parent_id]: 
[tags]: 
BOW features classifying better than complex models like BERT

I am doing a document classification task and I find that using simple BOW features with a random forest provide better results than using complex models like BERT or ELECTRA even after doing some parameter tunning. What could be the reasons behind this? Many of the documents I need to classify lack continuous text so maybe single terms are enough to figure out what class they belong to. I am also dealing with a highly unbalanced dataset but still the difference is so big I am wondering if maybe there is something I am missing here. I would have assumed BERT and pretrained NLP models would at least match a simple BOW representation. In what general cases do you think a BOW model could outscore BERT or similar deep NN models? Maybe I can get some tips to inspect the data.
