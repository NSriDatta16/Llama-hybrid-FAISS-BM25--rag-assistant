[site]: stackoverflow
[post_id]: 724414
[parent_id]: 724349
[tags]: 
That seems like a rather difficult thing to measure, because you can't really isolate a single process to run by itself. In fact, if you tried to do so you'd run into difficulty defining what constitutes a "single process" - is it just the userspace code that belongs to that program? Or do you include the kernel code executed on behalf of the program as well? What if the OS optimizes kernel code so that similar requests from different programs are handled together, using a nearly constant amount of energy? Then you couldn't even separate out the energy usage by program. In a case like this, my inclination would be to measure the expectation value, essentially the average amount of energy used by the application. Ideally you'd start with a large number of systems, all identical except that half of them have the application running and half of them don't. Let each of the systems run under whatever operating conditions you want to test under (same conditions for all devices, of course, except for the fact that half of them are running the app and half are not), and either measure the rate of energy consumption using the standard API, or let the batteries run out and measure how long it takes each unit to drain its battery. Then compare the average result from the devices that were running the app vs. the average result from those that weren't, and you can figure out how much the program increases the power consumption of the computer.
