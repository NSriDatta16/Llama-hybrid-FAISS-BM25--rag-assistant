[site]: datascience
[post_id]: 124316
[parent_id]: 
[tags]: 
Numerical issue with softmax regression implementation on MNIST

I'm having numpy numerical issues with my implementation of softmax regression/multiclass logistic regression on the MNIST dataset. The numpy exp and log numerical issue goes away when I divide the x values by 255 (normalization). I'm confident that I'm correctly implementing the lost and gradient functions. I tried writing my softmax as np.exp(z - max(z)) / np.sum(np.exp(z - max(z)), axis = 1, keepdims=True) but it was still giving errors in with np.log dividing by 0 in cross-entropy error. Is there something I'm missing that is causing the softmax regression to fail when running MNIST data with x values ranging from 0 to 255 but works on x values ranging from with 0 to 1 My code is: import numpy as np from urllib.request import urlopen import gzip #[['http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'], # ['http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']]: def getMNISTXData(url): streamed_file = urlopen(url) with gzip.GzipFile(fileobj=streamed_file) as f: # first 4 bytes is a magic number magic_number = int.from_bytes(f.read(4), 'big') # second 4 bytes is the number of images image_count = int.from_bytes(f.read(4), 'big') # third 4 bytes is the row count row_count = int.from_bytes(f.read(4), 'big') # fourth 4 bytes is the column count column_count = int.from_bytes(f.read(4), 'big') # rest is the image pixel data, each pixel is stored as an unsigned byte # pixel values are 0 to 255 image_data = f.read() #reshape the values to between 0 and 1 instead of 0 to 255 #divide by 255 is done for numerical stability, otherwise numpy exp will overflow images = np.frombuffer(image_data, dtype=np.uint8).reshape((image_count, row_count * column_count)) return images def getMNISTYData(url): streamed_file = urlopen(url) with gzip.GzipFile(fileobj=streamed_file) as f: # first 4 bytes is a magic number magic_number = int.from_bytes(f.read(4), 'big') # second 4 bytes is the number of labels label_count = int.from_bytes(f.read(4), 'big') # rest is the label data, each label is stored as unsigned byte # label values are 0 to 9 label_data = f.read() labels = np.frombuffer(label_data, dtype=np.uint8).reshape((label_count, 1)) return labels x_train_url = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz' y_train_url = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz' x_train = getMNISTXData(x_train_url) y_train = getMNISTYData(y_train_url) print(x_train.shape) print(y_train.shape) import matplotlib.pyplot as plt plt.imshow(x_train[1].reshape((28,28)), cmap='gray_r') plt.show() x_test_url = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz' y_test_url = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz' x_test = getMNISTXData(x_test_url) y_test = getMNISTYData(y_test_url) print(x_test.shape) print(y_test.shape) import matplotlib.pyplot as plt plt.imshow(x_test[0].reshape((28,28)), cmap='gray_r') plt.show() #Indicator fuction #returns array with index y being 1 and 0 for all other def indicatorFunc(y, size = 10): indicatorArray = np.zeros(size, dtype=np.uint8) indicatorArray[y] = 1 return indicatorArray #Gets the 1{yi = k} vector for each y, final result is matrix. #each row is the 1{yi = k} def oneHotEncodeMatrix(y_data): OHTResult = np.zeros((len(y_data), 10)) for index in range(len(y_data)): OHTResult[index] = indicatorFunc(y_data[index]) return OHTResult #gets the WX+b value def calcZ(x_data, weight, bias): return np.dot(x_data, weight) + bias #calculates softmax for values for each xi def softmaxMatrix(z): #numerator is the exp(wx+b) for each class for each data #denom is the sum of exp(wx+b) #dividing them we get softmax for each class in for each x return np.exp(z - np.max(z), dtype=np.float128) / np.sum(np.exp(z - np.max(z), dtype=np.float128), axis = 1, keepdims = True, dtype=np.float128) #calculates the gradient of W and b used for gradient Descent def calculateNLossGradient(x, error): #first element of the tuple is the gradient of weight: Summation i=1 to n 1/n * xi(P(yi=k|xi,w,b) - 1{yi = k}) #second element is the gradient of bias: Summation i=1 to n 1/n * (P(yi=k|xi,w,b) - 1{yi = k}) return (1/x.shape[0] * np.dot(x.T, error), 1/x.shape[0] * np.sum(error, axis = 0, dtype=np.float128)) def calculateNCrossEntropyLoss(yOneHotEnc, softmax, z): #calculates the cross entropy loss for current weight and bias on training data #return np.mean(-np.sum(yOneHotEnc * np.log(softmax, dtype=np.float128), axis = 1, dtype=np.float128), dtype=np.float128) return np.mean(-np.log(np.sum(yOneHotEnc * softmax, axis = 1, dtype=np.float128), dtype=np.float128)) def MulticlassLRGradientDescent(x_data, y_data, learning_rate = 0.5, min_tolerance = 0.6): #create weight and softmax values modelWeight = np.zeros((784,10), dtype=np.float128) modelBias = np.zeros(10, dtype=np.float128) yOHE = oneHotEncodeMatrix(y_data) zVal = calcZ(x_data, modelWeight, modelBias) softmaxVal = softmaxMatrix(zVal) errVal = softmaxVal - yOHE #calculate initial Cross entropy loss lossValue = calculateNCrossEntropyLoss(yOHE, softmaxVal, zVal) print('Starting Fitting Model') #loop until min_tolerance is reached on cross entropy loss while (lossValue > min_tolerance): print(lossValue) #gets gradient for weight and bias weightGradient, biasGradient = calculateNLossGradient(x_data, errVal) #update weight and bias modelWeight -= learning_rate * weightGradient modelBias -= learning_rate * biasGradient #calculates softmax for next iter zVal = calcZ(x_data, modelWeight, modelBias) softmaxVal = softmaxMatrix(zVal) errVal = softmaxVal - yOHE #calculates new loss on updated weight and bias lossValue = calculateNCrossEntropyLoss(yOHE, softmaxVal, zVal) return (lossValue, modelWeight, modelBias) #predicts the integer based on 28x28 MNIST data def predict(x_data, weight, bias): zVal = calcZ(x_data, weight, bias) softmaxVal = softmaxMatrix(zVal) return np.argmax(softmaxVal, axis=1) #calculates the correct prediction rate of the model def calculatePredictError(y_data, predictOutput): correctNum = 0 for index in range(len(y_data)): if y_data[index] == predictOutput[index]: correctNum += 1 return correctNum / len(y_data) #doing some test print(MulticlassLRGradientDescent(x_train, y_train)) result = MulticlassLRGradientDescent(x_train, y_train) print(calculatePredictError(predict(x_test, result[1], result[2]), y_test))
