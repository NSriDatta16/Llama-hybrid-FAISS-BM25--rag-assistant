[site]: crossvalidated
[post_id]: 262554
[parent_id]: 
[tags]: 
Why averaging stochastic gradient descent not always used?

In some references equation (20) people tend to average or normalize the back propagated error by the number of examples in the mini-batch before updating the weights. while in other references is not the case. I never averaged this error. Is there any explanation why it is used or not ?
