[site]: crossvalidated
[post_id]: 259360
[parent_id]: 
[tags]: 
Which assumptions about the variance need to hold to apply a closed-form analytic solution of Bayesian updating?

I am working on an application where I use Recursive Bayesian updating to incorporate new information into an estimate of a parameter that follows a normal distribution. I assume a conjugate prior. This process is mathematically equivalent to the Kalman filter. The Kalman filter provides a posterior mean and a posterior variance of the estimate of the mean. The application I am using this for has no further requirements than those of a Kalman filter. The arithmetic used follows the derivation as shown here: http://www2.bcs.rochester.edu/sites/jacobslab/cheat_sheet/bayes_Normal_Normal.pdf However, I got confused from the section on Conjugate priors on the Wikipedia page. In the table on continuous distributions the entry “normal - μ and σ2 - Assuming exchangeability” provides an derivation of σ2 that is required prior to calculating a posterior μ. My problem in understanding is which variance this refers to. Does this refer to the posterior variance of the data or the variance of the posterior mean? Any non-technical explanation would be very much appreciated! Many thanks :)
