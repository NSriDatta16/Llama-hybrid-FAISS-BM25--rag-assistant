[site]: crossvalidated
[post_id]: 397413
[parent_id]: 397392
[tags]: 
You seem to ask how to use just one package in either Python or in R to do all the three tasks. This can be done in a "pipeline", in which you need to do some "pre-processing" to handle the missing values before you fit the model. You can get the model fitting the training data in either Python or R. In Python, you can use "sklearn": from sklearn.preprocessing import Imputer from sklearn.linear_model import LogisticRegression imp = Imputer(missing_values='NaN', strategy='mean', axis=0) mlg = LogisticRegression(multi_class='multinomial', penalty='l2') model = Pipeline([('imputation', imp), ('multilogit', mlg)]) In R, you can use "caret": library(caret) model As you say, xgboost (gradient boosted trees) is also robust to missing values. You can use the "xgboost" module/library in either Python or R to give it a try.
