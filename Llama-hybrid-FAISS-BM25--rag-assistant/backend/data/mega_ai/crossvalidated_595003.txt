[site]: crossvalidated
[post_id]: 595003
[parent_id]: 594677
[tags]: 
I will outline my comment as an answer. First, some clarification. In Bayesian statistics, there is no notion of "standard error" in the context of trying to conduct inference on a statistic. The standard error of an estimator is the standard deviation of the estimator's sampling distribution. A sampling distribution relies on the notion of repeated random sampling - a frequentist interpretation of probability. Rather, what you want is the posterior distribution of the differences in parameters - specifically the posterior distribution of $W := \text{P(success A)} - \text{P(success B)}$ . Once you have the distribution of W, you can describe its qualities in whatever capacity you wish (credible intervals, i.e. quantiles, highest density intervals, etc.) and you can get point estimates by reporting the mean, median, etc. In theory, you can derive W by thinking about the distribution of W = X - Y, where X and Y are independent Beta random variables. This might give you some distribution in closed form, if you can work out the math. A much easier way to do this is described in the comments - use Monte Carlo simulation. If you randomly sample an arbitrarily large number of realizations from each posterior/beta distribution (say 10000 each), and simply take the difference between these two arrays, you will have obtained 10000 realizations of W! From here, you can get a Monte Carlo estimate of whatever quantity you wish to conduct inference on W - mean, median, ... using empirical estimators. In the comments, you stated concerns regarding the "standard error decreasing for a large nunber of random realizations". This is Monte Carlo error - the error that you obtain by approximating some statistic of W with samples from W (as opposed to using math to work out the distribution and/or quantities of W directly). This is error that is unrelated to what is implied by your data or prior beliefs, but rather the "cost" of using simulation. Luckily, as you already noticed, the error goes to 0 for a large number of random samples, so as long as you simulate a large number of realizations, this error will be negligible. To see this: take the mean of W, derived via. simulation, and compare it to the mean difference that you have already calculated in your code. What you should find is that your Monte Carlo estimate for the mean of W approaches the estimate that you explicitly calculated in closed form for a progressively larger number of samples.
