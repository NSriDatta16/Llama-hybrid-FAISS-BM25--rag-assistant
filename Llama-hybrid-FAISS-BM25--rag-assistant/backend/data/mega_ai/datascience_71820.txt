[site]: datascience
[post_id]: 71820
[parent_id]: 
[tags]: 
Why -logD trick in GANs training work?

When training the generator, we want to minimize log(1 - D(G(z))) (this has a form of log (1-x)). Using graph calculator we plot and see that the slope of this function is very small at first, thus giving handicaps for G when training in early stages. To solve this, we have to equalize the "minimize log(1 - D(G(z)))" to minimize -log(D(G(z))) (-log x). Using the graph plotter again, we can see the gradient at the early steps is much more stronger. However, in this graphs plotted, the x value is increasing, while our data is images. Can someone explain the intuition or clarify this point for me? I can still dont understand why inverting to -log(D(G(z))) helps Generator learn faster and better. The plots of two functions:
