[site]: crossvalidated
[post_id]: 76726
[parent_id]: 76693
[tags]: 
Another possibility are neural networks, if you use the cross-entropy as the cost functional with sigmoidal output units. That will provide you with the estimates you are looking for. Neural networks, as well as logistic regression, are discriminative classifiers, meaning that they attempt to maximize the conditional distribution on the training data. Asymptotically, in the limit of infinite samples, both estimates approach the same limit. You shall find a detailed analysis on this very question in this paper . The takeaway idea is that even though the generative model has a higher asymptotic error, it may approach this asymptotic error much faster than the discriminative model. Hence, which one to take, depends on your problem, data at hand and your particular requirements. Last, considering the estimates of the conditional probabilities as an absolute score on which to base decisions (if that is what you are after) does not make much sense in general. What is important is to consider, given a concrete sample, the best candidates classes output by the classifier and compare the associated probabilities. If the different between the best two scores is high, it means that the classifier is very confident about his answer (not necessarily right).
