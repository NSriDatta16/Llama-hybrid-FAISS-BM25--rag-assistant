[site]: crossvalidated
[post_id]: 558910
[parent_id]: 558900
[tags]: 
Having a Hessian that must be updated every time the guess at parameter estimates $\beta$ changes is a necessary requirement for achieving excellent calibration (i.e., the weighted in iteratively reweighted least squares ). Multinomial logistic regression is built for prediction, and I suspect that your stated goal of classification would be better replaced with a goal of prediction, i.e., getting predicted probabilities of class membership. Using ordinary Newton-Raphson iteration to solve for the maximum likelihood estimate of $\beta$ converges very fast, often in only 5 iterations (5 passes at the data). So I'm not sure how much it is worth to develop shortcuts.
