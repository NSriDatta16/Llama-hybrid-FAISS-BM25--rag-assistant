[site]: crossvalidated
[post_id]: 601513
[parent_id]: 601465
[tags]: 
The limit theorem is 'central' The central limit theorem (CLT) has a central role in all of statistics. That is why it is called central ! It is not specific to frequentist or Bayesian statistics. Note the early (and possibly first ever) use of the term 'central limit theorem' by George Pólya who used it in the article "Über den zentralen Grenzwertsatz der Wahrscheinlichkeitsrechnung und das Momentenproblem" Das Auftreten der Gaußschen Wahrscheinlichkeitsdichte $e^{-x^2}$ bei wiederholten Versuchen, bei Messungsfehlern, die aus der Zusammensetsung von sehr vielen und sehr kleinen Elementarfehlern resultieren, bei Diffusionafurgängen usw. ist bekanntlich aus einem und demselben Grenzwertsatz zu erklären, der in der Wahrscheinlichkeitsrechnung ein zentralen Rolle spielt . emphasis is mine. The principle behind the limit is applied whenever we use a normal distribution The CLT describes the tendency of sums of variables to approach a normal distribution and that is independent from how you would wish to analyse the variables, whether it is frequentist or Bayesian. Such sums occur anyware. It is arguable that whenever a normal distribution is used, then it is indirectly an application of the central limit theorem. A normal distribution does not occur as an atomic distribution. There is nothing inherently normal distributed and when a normal distribution 'occurs' then it is always due to some process that sums several smaller variables (e.g like a Galton board where a ball is hitting multiple times a pin before ending up in a bin). And such sums can be approximated by a normal distribution. The use of the normal distribution can have other motivations. For instance, it is the maximum entropy distribution for a given mean and variance. But in that case, it still indirectly relates to the CLT as we can see a maximum entropy distribution as arrising from many random operations that preserve some parameters (like in the case of the normal distribution, the mean and variance are preserved). When we add up many variables with a given mean and variance, then the resulting distribution is likely gonna be something with a high entropy, ie something close to the normal distribution. The CLT is such a general principle that the question is like asking "what is the role of 'integration' in Bayesian statistics". Or fill in any other trivial process in place of CLT. Practical application of CLT It might be that in practice one observes a tendency for textbooks or statisticians/fields to often apply a particular technique, frequentist or Bayesian, and use relatively more or less often a normal approximation. But, that is in principle not related to those fields. In practice a particular technique might be preferred. For instance when approximating intervals, then one can use a normal distribution as approximation, but that is not a neccesity. One can also use a Monte Carlo simulation to estimate the distribution or sometimes there is a formula for the exact distribution. Possibly Bayesian approaches use the normal approximation less often because they are in a situation where they use Monte Carlo simulation/sampling already anyway (to find a solution for large intractable models). It can be that in particular fields the models are too complex to apply a normal distribution approximation and that those fields also often apply Bayesian techniques. That doesn't make the role of the CLT is smaller for Bayesian techniques. At least not in principle. There is a large amount of scientists that use nothing much more than simple things like ANOVA, chi-squared tests, ordinary least squares fits, or small variations of it. Those techniques happen to be frequentist and use a normal distribution approximation. Because of that it might seem like frequentist techniques often use the CLT but it doesn't rely on it in principle. Related: How would a bayesian estimate a mean from a large sample? Would you say this is a trade off between frequentist and Bayesian stats?
