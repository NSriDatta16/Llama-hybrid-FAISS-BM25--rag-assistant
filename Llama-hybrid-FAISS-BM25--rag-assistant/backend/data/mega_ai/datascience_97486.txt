[site]: datascience
[post_id]: 97486
[parent_id]: 
[tags]: 
When and how to use StandardScaler with target data for pre-processing

I am trying to figure out when and how to use scikit-learn 's StandardScaler transformer, and how I can apply it to the target variable as well. I've read this post and, while the accepted answer maintains that it is not necessary to standardize the target vector, other answers suggested that it might still be beneficial. So let's assume that I want to go ahead and standardize the target vector. According to the syntax, the fit_transform method of a StandardScaler instance can take both a feature matrix X, and a target vector y for supervised learning problems. However, when I apply it, the method returns only a single array. If I try to unpack two values, like in the code below, I get a "ValueError: too many values to unpack (expected 2)" error: from sklearn.preprocessing import StandardScaler scaler = StandardScaler() X_scaled, y_scaled = scaler.fit_transform(X,y) # X is some feature array, y is the target vector # This code will produce an error message This is consistent with the documentation, which states that the return value is a single output array X_new . Then my question is: why is there an option to add y to the parameters of the method? Does it change the way in which X is standardized? If not, should I use something like the code below?: from sklearn.preprocessing import StandardScaler scaler_X = StandardScaler() scaler_y = StandardScaler() X_scaled = scaler_X.fit_transform(X) y_scaler = scaler_y.fit_transform(y)
