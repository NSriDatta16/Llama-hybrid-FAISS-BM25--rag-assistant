[site]: datascience
[post_id]: 1033
[parent_id]: 1029
[tags]: 
Due to the very Big increase in Big Data (pun intended) and the desire for robust stable scalable applications I actually believe it to be Scala . Spark will inevitably become the main Big Data Machine Learning tool, and it's main API is in Scala. Furthermore you simply cannot build a product with scripting languages like Python and R, one can only experiment with these languages. What Scala brings is a way to BOTH experiment and produce a product. More reasons Think functionally - write faster code and more readable code Scala means the end of the two team development cycle. So better product ownership, more agile cross functional teams, and half as many employees required to make a product as we will no longer need both a "research" team and an engineering team, Data Scientists will be able to do both. This is because Scala is; A production quality language - static typing, but with the flexibility of dynamic typing due to implicits Interoperable with rest of Java world (so Apache Commons Math, Databases, Cassandra, HBase, HDFS, Akka, Storm, many many databases, more spark components (e.g. graphx, SparkStreaming) Step into Spark code easily and understand it, also helps with debugging Scala is awesome: Amazing IDE support due to static typing Property based tests with ScalaCheck - insane unit testing Very concise language Suits mathematicians perfectly (especially Pure Mathematicians) A little more efficient as compiled not interpreted Python Spark API sits on Scala API and therefore will always be behind Scala API Much easier to do Mathematics in Scala as it's a Scalable Language where one can easily define DSLs and due to being so functional Akka - another way other than storm to do High Velocity Pimp my library pattern makes adding methods to Spark RDDs really easy
