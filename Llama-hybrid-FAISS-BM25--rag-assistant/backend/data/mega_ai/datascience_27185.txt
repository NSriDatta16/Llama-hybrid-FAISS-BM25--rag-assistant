[site]: datascience
[post_id]: 27185
[parent_id]: 27169
[tags]: 
You might try extending your approach to include adding random noise to your training data, sometimes called noise injection. By doing this you can theoretically extend the amount of training data you have almost infinitely and avoid over-fitting of a small training sample. An internet search will turn up several papers on the subject, e.g. Whiteout: Gaussian Adaptive Noise Regularization in FeedForward Neural Networks
