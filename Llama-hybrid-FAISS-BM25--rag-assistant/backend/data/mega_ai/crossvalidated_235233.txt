[site]: crossvalidated
[post_id]: 235233
[parent_id]: 235189
[tags]: 
As it has been mentioned already in previous answers, random forest for regression / regression trees doesn't produce expected predictions for data points beyond the scope of training data range because they cannot extrapolate (well). A regression tree consists of a hierarchy of nodes, where each node specifies a test to be carried out on an attribute value and each leaf (terminal) node specifies a rule to calculate a predicted output. In your case the testing observation flow through the trees to leaf nodes stating, e.g., "if x > 335, then y = 15", which are then averaged by random forest. Here is an R script visualizing the situation with both random forest and linear regression. In random forest's case, predictions are constant for testing data points that are either below the lowest training data x-value or above the highest training data x-value. library(datasets) library(randomForest) library(ggplot2) library(ggthemes) # Import mtcars (Motor Trend Car Road Tests) dataset data(mtcars) # Define training data train_data = data.frame( x = mtcars$hp, # Gross horsepower y = mtcars$qsec) # 1/4 mile time # Train random forest model for regression random_forest
