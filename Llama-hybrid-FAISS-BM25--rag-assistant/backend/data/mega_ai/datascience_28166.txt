[site]: datascience
[post_id]: 28166
[parent_id]: 
[tags]: 
How is Kernel Matrix on a distribution defined?

Consider the following words taken from the lecture notes: The Hilbert-Schmidt Independence Criterion (HSIC) measures the dependence of the two random variables $X$ and $Y$. An empirical estimate of the HSIC is proportional to the $trace(KHLH)$, where $K$ is a kernel matrix on $X$, $L$ is a kernel on $Y$, $H$ is a centering matrix with $H_{ij} = δ(i, j) − \frac{1}{n}$. $HSIC(X, Y ) = 0$ if and only if $X$ and $Y$ are independent. The larger $HSIC(X, Y)$, the larger the dependence between $X$ and $Y$. For me the only unclear part of this definition is the "[K] kernel matrix on a distribution [X]" sentence. Can someone explain what it means to apply the kernel on a distribution?
