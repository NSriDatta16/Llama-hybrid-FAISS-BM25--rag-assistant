[site]: crossvalidated
[post_id]: 267342
[parent_id]: 267193
[tags]: 
The usual measure of the size of noise about a nonlinear least squares regression fit is the standard error of the residuals, which is the square root of the variance estimate $$s^2=\hat{\sigma}^2=\frac{1}{n-p}\sum_i (y_i-\hat{y}_i)^2\,.$$ It is an estimate of the population standard deviation of the noise term ($\epsilon$) in the nonlinear regression model $y=f(x;\theta)+\epsilon$. Here $n$ is the number of observations, $p$ the number of free parameters used to define the fitted model, $y_i$ is the $i$-th response value and $\hat{y}_i$ is the $i$-th fitted value. [See, for example equation 9.35 and the immediately preceding equations here ] Many programs or functions for fitting nonlinear regression produce a value for $s$ in their output. For example, here's R output for one of the examples in its help on nonlinear regression: summary(fm1DNase1) Formula: density ~ SSlogis(log(conc), Asym, xmid, scal) Parameters: Estimate Std. Error t value Pr(>|t|) Asym 2.34518 0.07815 30.01 2.17e-13 xmid 1.48309 0.08135 18.23 1.22e-10 scal 1.04146 0.03227 32.27 8.51e-14 --- Residual standard error: 0.01919 on 13 degrees of freedom Number of iterations to convergence: 0 Achieved convergence tolerance: 3.281e-06 The value in the third-last printed line, for "Residual standard error" is just such an estimate. [Unfortunately the online curve_fit documentation is constantly timing out right now, so I can't look up how to get it from scipy's curve_fit for you.] Would I use the same formula if I were to linearize my data and then just do a least-squares fit? Note that the two assumptions (that the noise variance is constant on both the original scale and on the log scale) are never consistent with each other - if one constant variance assumption were true, the other could not be. Your model for the way the noise is spread around the model should actually describe the way the noise behaves. If the noise is relative for the exponential model (i.e. average spread about the curve is constant in percentage terms, so that typical spread at $x$ divided by expected value at $x$ is about the same at each $x$) then it will be constant in absolute terms on the log scale for the linear model. On the other hand, if it's constant (in absolute terms) on the original exponential model then the spread will be smaller at larger $x$-values and larger at smaller $x$-values on the log scale. You can get a poor fit (sometimes quite poor) if you assume constant variance when it's far from correct. Standard errors of parameters will be wrong, and prediction intervals (for new points) will be next to useless. If you applied the formula for $s$ to a situation where the spread of the noise term wasn't almost constant, the value of $s$ would be estimating a sort of weighted average of those changing spreads, but would really only describe the spread at one place. That said, if the 'true' model has constant spread on the log scale, then the usual estimate for it uses the same formula. It's also possible to calculate (at least approximately) the way the spread should go (as a function of the expected value of the model at $x$) after you transform from a constant spread (in what ever direction). If the size of the error is tiny or the values never get near 0, it may not make much appreciable difference -- so
