[site]: crossvalidated
[post_id]: 486597
[parent_id]: 486590
[tags]: 
Since the data are nested, the answer is technically no. 2, and a bit of 3. Straight forward depends on your experience, but here is one approach. This sounds like exactly the right setup for a mixed effect model. Let's work bottom up. For subject $j$ , we assume that the logit of the success rate is $$ \operatorname{logit}(p_j) = \beta_{0,j} $$ Here, we assume no other cpvariates are used to adjust this estimate. Note that the intercept is also indexed by $j$ , meaning each subject gets their own estimate. The next level up the hierarchy is to assume that each intercept comes from some population level distribution $$ \beta_{0,j} \sim \mathcal{N}(B_0, \sigma_B) $$ The population level mean $B_0$ requires estimation. Let's do this in R. library(lme4) library(tidyverse) #Simulate data set.seed(2) n_subs |z|) (Intercept) -1.144 0.207 -5.525 3.3e-08 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Note that the intercept estimate for this model captures our population level mean > confint(model) Computing profile confidence intervals ... 2.5 % 97.5 % .sig01 0.000000 1.0026083 (Intercept) -1.621016 -0.7514589 These intervals are on the log odds scale. If you wanted to test if the population level mean success rate was $p$ , you would look to this confidence interval and determine if $\operatorname{logit}(p)$ was in this interval. I think this is the easiest since its just a model call in R, but perhaps you could also weight each observation by their observed variance and calculate a weighted mean. To obtain a confidence interval for that would be an exercise in the manipulation of random variables and their variances. EDIT: Libraries like rstanarm and brms make Bayesian analysis easy, but I'm fond of writing my own little Stan program. Here is a stan program for a hierarchical beta binomial model. model_code mu; real kappa; vector [n] p; } model{ mu ~ uniform(0,1); kappa ~ cauchy(0,1); p ~ beta_proportion(mu, kappa); for( i in 1:n){ target += binomial_lpmf(y[i] | n_trials[i], p[i] ); } }') Fitting this model to the data I've simulated above results in the following posterior credible interval for the population probability > fit$draws('mu') %>% + posterior::as_draws_df() %>% + tidybayes::spread_draws(mu) %>% + tidybayes::mean_qi() # A tibble: 1 x 6 mu .lower .upper .width .point .interval 1 0.263 0.187 0.350 0.95 mean qi
