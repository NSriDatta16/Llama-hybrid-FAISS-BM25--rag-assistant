[site]: datascience
[post_id]: 71569
[parent_id]: 71536
[tags]: 
A safer method is to use the integer part of the fraction (after truncating) $n_c \approx n^{3 \over 4}$ examples for training, and $n_v \equiv n - n_c$ for validation (a.k.a. testing). If you are doing cross-validation, you could perform that whole train-test split at least $n$ times (preferably $2n$ if you can afford it), recording average validation loss at the end of each cross-validation "fold" (replicate), which is what tensorflow records anyway; see this answer for how to capture it). When using Monte Carlo cross-validation (MCCV) then for each of the $n$ (or $2n$ if resource constraints permit) replicates, one could randomly select (without replacement to make things simpler) $n_c$ examples to use for training and use the remaining $n_v$ examples for validation, without even stratifying the subsets (based on class, for example, if you are doing classification). This is based on a 1993 paper (look at my answer here for more information) by J. Shao in which he proves that $n_c \approx n^{3 \over 4}$ is optimal for linear model selection. At that time, non-linear models such as machine learning (see this answer for yet another discussion on that) were not as popular, but as far as I know (would love to be proven wrong) nobody has taken the time to prove anything similar for what is in popular use today, so this is the best answer I can give you right now. UPDATE: Knowing that GPUs work most efficiently when they are fed a batch sized to be a power of two, I have calculated different ways to split data up into training and validation which would follow Jun Shao's strategy of making the training set size $n_c \approx n^{\frac{3}{4}}$ and where both $n_c$ and $n_v \equiv n - n_c$ are close to powers of two. An interesting note is that for $n = 640$ , $n_c \approx 127$ and therefore $n_v \approx 513$ ; because $127 \approx 2^7$ and $513 \approx 2^9$ I plan to go ahead and use those as my training and validation test sizes whenever I am generating simulated data.
