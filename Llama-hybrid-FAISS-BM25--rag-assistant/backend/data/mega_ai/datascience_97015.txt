[site]: datascience
[post_id]: 97015
[parent_id]: 
[tags]: 
In Keras, how to organize multiple input features using pre-trained embedding mapping?

Let's say the goal is to predict weather given multiple features (temp, humidity) in the past 3 days. weather (y) can be: Sunny, Cloudy, Rainy. Temp (X1) can be : Hot, Cool, Cold. Humidity (X2) can be: Low, Medium, High. Let's say I have a pre-trained embedding dictionary for Temp: temp_dict = {'Hot':[1,0,2], 'Cool':[2,3,0], 'Cold':[5,1,-3]} And also a pre-trained embedding dictionary for Humidity: humidity_dict = {'Low':[3,0,2], 'Medium':[1,3,0], 'High':[6,3,3]} Let's say one dataset is data_x = np.array([ # sample 1 [ # Input features at timestep 1 ['Cold', 'High'], # Input features at timestep 2 ['Hot', 'Low'], # Input features at timestep 3 ['Hot', 'Medium'] ], # sample 2 [ # Input features at timestep 1 ['Cold', 'Medium'], # Input features at timestep 2 ['Cool', 'Low'], # Input features at timestep 3 ['Cool', 'Low'] ] ]) The labels of these two sample points are: data_y = ['Sunny', 'Cloudy'] My question is: how should the embedding matrix look like after using the pre-trained embedding? As you can see the original data_x has the shape of (2,3,2), should the embedding matrix have a shape of (2,3,6)? In that case, would the embedding matrix be the following? embedded_matrix = np.array([ # sample 1 [ # Input features at timestep 1 [5,1,-3, 6,3,3], # Input features at timestep 2 [1,0,2, 3,0,2], # Input features at timestep 3 [1,0,2, 1,3,0] ], # sample 2 [ # Input features at timestep 1 [5,1,-3, 1,3,0], # Input features at timestep 2 [2,3,0, 3,0,2], # Input features at timestep 3 [2,3,0, 3,0,2] ] ]) If this should be the case, how should I formulate a BiLSTM model using Keras? If not, how should the data be preprocessed and how should I formulate a BiLSTM model for it? Any help would be much appreciated.
