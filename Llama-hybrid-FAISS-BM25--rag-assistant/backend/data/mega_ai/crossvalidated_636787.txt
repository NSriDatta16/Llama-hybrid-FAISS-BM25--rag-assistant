[site]: crossvalidated
[post_id]: 636787
[parent_id]: 
[tags]: 
Why is hyper-parameter tuning decreasing training set performance

Setup : I am using hyperopt for xgboost hyper-parameter tuning. In each trial, the corresponding configuration is evaluated with time-series cross-validation (CV). The CV validation performance the only objective for the tuning process (common practice). Facts : The tuning process is effective at increasing the CV validation performance. However, this causes a huge decrease of performance in the training set. With default parameters: training performance: 72.5% validation performance: 60% After hyperopt tuning: training performance:57% validation performance: 62.7% So the tuning process increased validation performance by 2.7%, but cause a significant drop of training performance by 15.5%. Thoughts : I can think of two interpretations: "Good scenario": The original training performance was high due to overfitting noise (72.5%) and the new result (57%) is more realistic and learning actual patterns. Therefore, this removal of noise overfitting increases the performance of the validation set by 2.7%. Therefore, no further action is required. "Bad Scenario": Instead, the model was learning useful patterns from training data (72.5%) but after the tuning process it is forced to under-fit the training set (57%) in order to overfit the validation set (from 60% to 62.7%). Consider also that the training set is several times larger than the validation set. So it seems that the processed "sacrificed" the performance on a huge number of examples in order to get the validation data right. Possible action: instead of using only the CV validation performance as objective for optimization, I could use something like (0.7* CV_validation + 0.3*CV_training). This will force the process to learn to optimize the CV_performance without sacrificing the performance on such a huge number of training examples. Questions: Which scenario do you believe is closer to the truth? Why is it so common to focus entirely on a CV validation performance objective (which may cause hyper-parameter overfitting), and not a combination of CV validation and CV training performance (as I suggested previously)?
