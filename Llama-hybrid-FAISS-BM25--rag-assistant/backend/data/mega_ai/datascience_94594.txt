[site]: datascience
[post_id]: 94594
[parent_id]: 
[tags]: 
Slow keras fit method with 100x100 array, how can I make it faster?

how can I make this training faster ? when I call the fit method on a 100 x 100 matrix goes very slow my model it's a sequential h = self.model.fit( inputs, targets, epochs=epochs, batch_size=16, verbose=1, ) this is my matrix def build(n): mat=np.ones(N*N) return mat.reshape((N,N)) this is the of my Qtraining qt = Qtraining(model, env, n_epoch=200, max_memory=500, data_size=100, name='model100') This is the experience method def get_data(self, data_size=10): env_size = self.memory[0][0].shape[1] # env_state 1d size (1st element of episode) mem_size = len(self.memory) data_size = min(mem_size, data_size) inputs = np.zeros((data_size, env_size)) # metti Nsize righe di 0 , e envSize elementi 0 targets = np.zeros((data_size, self.num_actions))# for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)): env_state, action, reward, next_env_state, game_over = self.memory[j] inputs[i] = env_state # There should be no target values for actions not taken. # Thou shalt not correct actions not taken #deep (quote by Eder Santana) targets[i] = self.predict(env_state) # Q_sa = derived policy = max quality env/action = max_a' Q(s', a') Q_sa = np.max(self.predict(next_env_state)) if game_over: targets[i, action] = reward else: # reward + gamma * max_a' Q(s', a') targets[i, action] = reward + self.discount * Q_sa return inputs, targets using a 50 x 50 matrix I get 2500 cells, and in the construction of the neural network I have a 2500x2500 parameters + 2500 for a total of 6252500. I think that slows down operations. and there are only 3 Danse layers, the last one is size 4 because of the possible actions that are 4. Is it possible to reduce the time of operation by adding more Danse layers? this is my model def build_model(env, **opt): loss = opt.get('loss', 'mse') a = opt.get('alpha', 0.24) model = Sequential() esize = env.maze.size model.add(Dense(esize, input_shape=(esize,))) model.add(LeakyReLU(alpha=a)) model.add(Dense(esize)) model.add(LeakyReLU(alpha=a)) model.add(Dense(num_actions)) model.compile(optimizer='adam', loss='mse') return model
