[site]: stackoverflow
[post_id]: 2158223
[parent_id]: 2052684
[tags]: 
I created a CUDA-based solution based on Carl Smotricz's second algorithm. The code to identify Self Numbers itself is extremely fast -- on my machine it executes in ~45 nanoseconds; this is about 150 x faster than Carl Smotricz's algorithm, which ran in 7 milliseconds on my machine. There is a bottleneck, however, and that seems to be the PCIe interface. It took my code a whopping 43 milliseconds to move the computed data from the graphics card back to RAM. This might be optimizable, and I will look in to this. Still, 45 nanosedons is pretty darn fast. Scary fast, actually, and I added code to my program which runs Carl Smotricz's algorithm and compares the results for accuracy. The results are accurate. Here is the program output (compiled in VS2008 64-bit, Windows7): UPDATE I recompiled this code in release mode with full optimization and using static runtime libraries, with signifigant results. The optimizer seems to have done very well with Carl's algorithm, reducing the runtime from 7 ms to 1 ms. The CUDA implementation sped up as well, from 35 us to 20 us. The memory copy from video card to RAM was unaffected. Program Output: Running on device: 'Quadro NVS 295' Reference Implementation Ran In 15603 ticks (7 ms) Kernel Executed in 40 ms -- Breakdown: [kernel] : 35 us (0.09%) [memcpy] : 40 ms (99.91%) CUDA Implementation Ran In 111889 ticks (51 ms) Compute Slots: 1000448 (1954 blocks X 512 threads) Number of Errors: 0 The code is as follows: file : main.h #pragma once #include #include typedef std::pair sized_ptr; static sized_ptr make_sized_ptr(int* ptr, size_t size) { return make_pair (ptr, size); } __host__ void ComputeSelfNumbers(sized_ptr hostMem, sized_ptr deviceMemory, unsigned const blocks, unsigned const threads); inline std::string format_elapsed(double d) { char buf[256] = {0}; if( d file: main.cpp #define _CRT_SECURE_NO_WARNINGS #include #include "C:\CUDA\include\cuda_runtime.h" #include #include #include using namespace std; #include #include #include #include #include "main.h" int main() { unsigned numVals = 1000000; int* gold = new int[numVals]; memset(gold, 0, sizeof(int)*numVals); LARGE_INTEGER li = {0}, li2 = {0}; QueryPerformanceFrequency(&li); __int64 freq = li.QuadPart; // get cuda properties... cudaDeviceProp cdp = {0}; cudaError_t err = cudaGetDeviceProperties(&cdp, 0); cout file: self.cu #pragma warning( disable : 4231) #include #include #include #include #include #include using namespace std; #include "main.h" __global__ void SelfNum(int * slots) { __shared__ int N; N = (blockIdx.x * blockDim.x) + threadIdx.x; const int numDigits = 10; __shared__ int digits[numDigits]; for( int i = 0, temp = N; i >>(deviceMem.first); LARGE_INTEGER liKernel = {0}; QueryPerformanceCounter(&liKernel); cudaMemcpy(hostMem.first, deviceMem.first, hostMem.second*sizeof(int), cudaMemcpyDeviceToHost); // dont copy the overflow - just throw it away LARGE_INTEGER liMemcpy = {0}; QueryPerformanceCounter(&liMemcpy); // display performance stats double e = double(liMemcpy.QuadPart - liStart.QuadPart)/freq, eKernel = double(liKernel.QuadPart - liStart.QuadPart)/freq, eMemcpy = double(liMemcpy.QuadPart - liKernel.QuadPart)/freq; double pKernel = eKernel/e, pMemcpy = eMemcpy/e; cout UPDATE2: I refactored my CUDA implementation to try to speed it up a bit. I did this by unrolling loops manually, fixing some questionable use of __shared__ memory which might have been an error, and getting rid of some redundancy. The output of my new kernel is: Reference Implementation Ran In 69610 ticks (5 ms) Kernel Executed in 2 ms -- Breakdown: [kernel] : 39 us (1.57%) [memcpy] : 2 ms (98.43%) CUDA Implementation Ran In 62970 ticks (4 ms) Compute Slots: 1000448 (1954 blocks X 512 threads) Number of Errors: 0 The only code I changed is the kernel itself, so that's all I will post here: __global__ void SelfNum(int * slots) { int N = (blockIdx.x * blockDim.x) + threadIdx.x; int s = 0; int temp = N; s += temp - 10 * (temp/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; s += temp - 10 * ((temp/=10)/10) /*temp % 10*/; slots[N+s] = 1; }
