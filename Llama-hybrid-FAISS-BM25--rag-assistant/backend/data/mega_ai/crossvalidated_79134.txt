[site]: crossvalidated
[post_id]: 79134
[parent_id]: 79122
[tags]: 
Kernels can be extended to nearly any kind of data, but the modelling has to be done very carefully. And this is the reason, why many people are scared of it. Its difficult to handle non-understood methods. Its just not enough to apply some gaussian kernels and to perform grid search on the scaling. This critisism is not just related to kernel methods, but to all somewhat mathematical approaches in computer vision, machine learning etc. If you read also "older" [1] papers, you will indeed see that the kernels methods are used for more than 50 years everywhere, where computing is required. So it cannot be that bad. :) However, after a quick look on your links, I could see that Y. Bengio is also working a lot on deep learning, which is also a kind of kernel based regression. I wouldn't try to find a "go-for-all" method, but to select a specific problem and a good-looking paper and rebuild it from scratch in order to get good feeling for problems and benefits of a method. On your way you will have to develop techniques to "debug" the kernel regression/classification/neural networks, which will give you new ideas and force you to solve "unexplained" phenomena. Good luck!
