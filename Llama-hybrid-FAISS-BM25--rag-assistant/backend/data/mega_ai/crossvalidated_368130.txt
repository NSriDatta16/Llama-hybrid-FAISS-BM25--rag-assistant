[site]: crossvalidated
[post_id]: 368130
[parent_id]: 366775
[tags]: 
To be clear, you ran a logistic regression on the data and had positive results showing the treatment was associated with the outcome, right? Let's leave the causation part aside since statistics cannot show causation, that require reasoning. It is unclear whether you ran a multivariate or a univariate model. In any case, as you know, the coefficients you get on a logistic regression represent the change on the log odds (or logit) for one unit change in your predictor, or, in your case the difference in the logit for each treatment compared to the one you chose as the baseline. Therefore, I would expect that there is a strong correlation between the probability of having the outcome with each treatment and the logit of developing the outcome with each treatment. Wouldn't you? Just to illustrate, here is a graph of LOGIT vs. PROBABILITY. In your case, the coefficients would be on the Y axis and represent the change (in that same scale) between one treatment and the other. In my view, that tells you nothing about confounding. If you have true confounding that you did not include in your model, then that change in probability and the change in the log odds may not be because of the treatment at all. If you did run an MV model, then the cofactors that you entered did not explain away the effect of the treatment. But you don't need to test the correlation for that. Statistics is not going to help you design a better causal model. You should try to draw a causal diagram to help you think about the problem. In summary, the logit should be correlated with the probability. As the probability changes, so does the logit. If there are confounders and you add them to the model then the correlation will go down. Having a high correlation could mean either having a true strong relationship between treatment and effect OR having a confounder you did not add to the model.
