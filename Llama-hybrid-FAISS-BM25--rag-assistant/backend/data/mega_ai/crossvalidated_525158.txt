[site]: crossvalidated
[post_id]: 525158
[parent_id]: 
[tags]: 
Effect Sizes in Machine Learning Models

I am working on designing a systematic review & meta-analysis of machine learning techniques in the field of stuttering. One issue that has arisen is that: the currency papers usually trade in with meta-analyses are effect sizes. However, reporting effect sizes within the ML field is not the norm. Indeed, it is questionable what an effect size would be w.r.t. a machine learning model. I wanted to get some advice from some other ML enthusiasts... One approach is to use accuracy as a like-for-like replacement and instead of estimating the effect size of a clinical procedure; one estimates the accuracy of models in a field. This has been used in Lee et al., 2018 , for example. This may work for the ML field but is perhaps a bit misleading in a meta-analysis context. I say misleading for the same reason one doesn't use p -values in the meta-analysis as, we want the size of the effect given the scope of the research question. When researching effect sizes, I came across the odds-ratio effect size which looks superficially similar to a confusion matrix for ML models. The odds ratio of interest could then be specified by the importance in the field: the odds ratio of predicting a stutter when it is a stutter (true positive) versus when it is fluent speech (false positive). However, I have yet to see this when scoping for effect sizes in ML models. Not exactly an effect size, however a model comparator could be used such as BIC or AIC from the log-likelihood. However, this depends on the research reporting exactly how many observations are in a given class in both the training and test set. Also, how this could be used to aggregate models to get an overall estimate of model performance in a field is unclear to me at this stage. Have y'all got any thoughts on the above. Also, do you know of any effect size metrics for ML already existing that I am oblivious to? For the meta-analysis this would have to calculable from the standard information provided in papers such as, accuracy, precision, dataset size, feature input length etc. I look forward to any suggestions and comments, Liam P.S. Project page can be found here for further details.
