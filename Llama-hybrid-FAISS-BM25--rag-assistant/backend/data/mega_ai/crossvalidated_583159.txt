[site]: crossvalidated
[post_id]: 583159
[parent_id]: 583155
[tags]: 
Imputation should be used with care. If you fill in the mean value for any missing one, you simulate knowledge you simply don't have. Consider simply keeping a NA value if your model can deal with it, or try deleting all cases with missing values and see how your model performs then. Select your features only based on the training data. Doing selection first and splitting later leaks data. As Dave writes, class imbalance is usually not a problem, and SMOTE will not solve a non-problem . Doesn't your software do the one-hot encoding by itself? Remember to scale based only on the training data, and then applying this scaling separately to the test data. Scaling all data at once again leaks data. kNN is a hard classifier. I would strongly recommend using a probabilistic classifier instead, especially for rare targets - see here . Finally, you may be interested in How to know that your machine learning problem is hopeless?
