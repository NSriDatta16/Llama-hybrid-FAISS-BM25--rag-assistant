[site]: crossvalidated
[post_id]: 558577
[parent_id]: 558252
[tags]: 
In my answer, I respectfully disagree with the accepted answer. First of all, the fact that ARIMA models do not forecast well in forecasting competitions is not a weakness of ARIMA but is evidence that the stochastic process that produced the time series in question was one other than ARIMA and ARIMA should not have been used in the first place. A time series with nonlinear dependence for example will obviously not be forecasted well by ARIMA but that is hardly a shortcoming of ARIMA. If you simulate a time series from an ARIMA process, then an ARIMA model will do a spectacular job at prediction. If using the wrong tool results in poor performance - this is not evidence that the tool if flawed. Secondly, if ARIMA models are to be faulted for their performance in forecasting then in my opinion a strong case can be made about them doing poorly in long-term forecasting only. They could also be faulted for assuming that the error terms is white noise with a constant variance, which translates into a constant prediction error. But the GARCH family of models can help accommodate time-varying, autocorrelated variance. Another point pertains to the fact that it is trendy to discard old methodologies in favor of new, recently minted methods. In the forecasting competitions the message seems to be that we should discard ARIMA for machine learning methods. But there have been plenty of fads in statistics/econometrics. Check out this article titled "Economists are prone to fads, and the latest is machine learning" . Saying the words "machine learning" in an interview these days might help you get the job, but that is hardly evidence of substance I could organize a forecasting competition where I will select the time series so as to champion any particular family of models - you name it; I could select these time series so that the ARIMA models will do best and the machine learning methods will do poorly If, as whuber points out, the case could be made that there are hardly any real-world phenomena that are driven by ARIMA processes, then a case could be made about the limited applicability of ARIMA. And to me the biggest finding from the forecasting competitions is that combinations of various methods have consistently outperformed (across competitions), on average, any particular method. This seems to support the statement that real time series come from much more complicated processes than those in our arsenal of models (which includes both ARIMA and machine learning models). However, this is an indictment against any individual model type - be it an ARIMA model or a machine learning model. But somehow the conclusion is erroneously translated into machine learning - good; ARIMA - bad.
