[site]: datascience
[post_id]: 113549
[parent_id]: 
[tags]: 
How can I improve my current model to get a higher mAP value? (Stuck at 79~78)

I am facing an issue trying to improve my model for object detection, this is something which I have been facing for quite a few days. I have tried to improve my model by fine tuning and also changed the split to 80-20 (5399 for train, 1499 for val) to include more data for my validation set but still no luck in trying to improve the mAP (mean average precision) value of my model. The model config I have so far: model_4 = Sequential() model_4.add(Conv2D(16, (3, 3), activation='relu', input_shape=(300, 300, 3))) # model_4.add(RandomFlip(mode='horizontal_and_vertical', seed=None)) model_4.add(BatchNormalization()) model_4.add(MaxPool2D(pool_size=(2, 2))) model_4.add(Conv2D(32, (3, 3), activation='relu')) model_4.add(BatchNormalization()) model_4.add(MaxPool2D(pool_size=(2, 2))) model_4.add(Conv2D(64, (3, 3), activation='relu')) model_4.add(BatchNormalization()) model_4.add(MaxPool2D(pool_size=(2, 2))) model_4.add(Conv2D(64, (3, 3), activation='relu')) model_4.add(BatchNormalization()) model_4.add(MaxPool2D(pool_size=(2, 2))) model_4.add(Conv2D(128, (3, 3), activation='relu')) model_4.add(MaxPool2D(pool_size=(2, 2))) model_4.add(Flatten()) model_4.add(Dropout(0.35)) model_4.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.1))) model_4.add(Dropout(0.35)) model_4.add(Dense(4)) model_4.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=[tfr.keras.metrics.MeanAveragePrecisionMetric()]) model_4.summary() My approach is to try and improve as much as I can without a pretrained model/weights. I trianed with batch size as 64, no data augmentation. I was hoping to at least reach 85% or higher but that may be a bit of a stretch for me at this point. My graphs for loss and mAP: I reached a mAP of 79 for my train and val set which is quite close Any help would be appreciated as to how I can go forward into making the model perform better. I am sure there has to be something that is causing a bottleneck in the model performance. Thanks a lot.
