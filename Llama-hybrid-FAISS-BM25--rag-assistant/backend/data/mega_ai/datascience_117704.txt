[site]: datascience
[post_id]: 117704
[parent_id]: 
[tags]: 
How can I detect errors/irregularity in a dataset

I've been working on a pathfinding project using topographic data for my software development course, even though I've never really had calculus lessons. The algorithm works fine by itself, however, after trying to visualize the data to recreate a map, I've noticed that there are chunks of data that are clearly wrong. I believe that it must come from the datasource itself, since those chunks of error are way too regular to be a missinterpretation of the data, with clear squares being drawn on the image, as you can see My question is how can I detect and correct those errors? I have a few ideas like trying to calculate the average elevation of similar looking zones in order to find by how much the data is wrong and use that number to ajust the wrong chunk numbers and have the accurate values. Another was to find the coordinates of the wrong datasets, find the expected elevation on another dataset / a website and then deduct the difference. However I'm scared that those methods are unreliable at best, or would make the data even less accurate at worse. I've been using the dataset from this website
