[site]: crossvalidated
[post_id]: 558039
[parent_id]: 558001
[tags]: 
I think you have hit the infamous scikit learn logistic regression defaults to regularisation of 1. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html https://news.ycombinator.com/item?id=21416702 You can fix your simple problem by setting penalty='none' or C=100 in the constructor. C=100 would be necessary for older versions that defaulted to the liblinear algorithm. # Logistic Regression clf = LogisticRegression().fit(X, y_and) clf.predict(X) # --> array([0, 0, 0, 0) clf = LogisticRegression().fit(X, y_or) clf.predict(X) # --> array([1, 1, 1, 1) #reduce regularisation by setting penalty='none' or inverse regularisation to 100 # Logistic Regression clf = LogisticRegression(penalty='none').fit(X, y_and) clf.predict(X) # --> array([0, 0, 0, 1) clf = LogisticRegression(C=100).fit(X, y_and) clf.predict(X) # --> array([0, 0, 0, 1) clf = LogisticRegression(penalty='none').fit(X, y_or) clf.predict(X) # --> array([0, 1, 1, 1) ```
