[site]: datascience
[post_id]: 124773
[parent_id]: 124763
[tags]: 
Why the test accuracy showing odd patterns ? As @mohottnad mentioned in the comment, it appears your model overfits. It means that it doesn't generalise well and works badly on testing data. I don't know the details of you data, but this strange pattern of accuracy might be explained as follows: after many epochs your model is so overtrained that it return just one class. in epoch 100 this class is A and it covers correctly almost 60% of data in epoch 115 decision threshold changes slightly and the model's guess is B that is correct in +- 1/3 of data and so on, and so on It's my hypothesis you can dissect, your situation probably isn't as simple as I described, but it might be very similar. You can also check if you have an imbalanced dataset that might be an issue. How can I fix this problem? I don't know how complex your variables are, but you have just 3 input variables and you feed them into 64->32->32 neurons. In many cases, it's too much. I would try with a way simpler model like 16->8 neurons or even smaller. Your demend on model complexity is associated with complexity of relationships in your data. Maybe you need just a logistic regression, who knows? It's up to you to experiment and offset it. The value=0.6 in dropout for this data and model also appears to be too high.
