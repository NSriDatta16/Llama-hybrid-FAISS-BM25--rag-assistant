[site]: crossvalidated
[post_id]: 533769
[parent_id]: 533719
[tags]: 
Relaxed LASSO does LASSO (not ridge) in both steps. If it first does LASSO, then ridge, calling this relaxed LASSO seems misleading to me. More importantly, LASSO and AIC are apples and oranges. LASSO is a fitting method while AIC is an information criterion. (E.g. there are works that use AIC instead of cross validation for determining the penalty intensity of LASSO. So you can have both at once if you like.) A better way to phrase this would be a comparison of LASSO with OLS (both being fitting methods) where the former is tuned using cross validation while the latter uses model selection (stepwise? full subset?) based on AIC. To address you question directly, we have to recall the "no free lunch" theorem: there is no prediction method that is the best for all problems. There exist problems for which one method is better and other problems for which another method is better. E.g. in the original LASSO paper, the author shows problems where LASSO beats ridge and vice versa (I think subset selection is included in the comparison there, too, and it gets to beat and be beaten by LASSO and ridge as well). I would not be surprised if the original relaxed LASSO paper contains some similar comparisons. In summary, you have to figure out the best method for each problem without relying on overly broad generalizations. A somewhat related thread is "AIC versus cross validation in time series: the small sample case" .
