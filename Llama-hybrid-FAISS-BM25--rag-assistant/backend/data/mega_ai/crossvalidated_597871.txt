[site]: crossvalidated
[post_id]: 597871
[parent_id]: 585287
[tags]: 
Let's rewind the definitions. Definition $1.$ Let $E$ be a Polish space. Consider $\langle X_t\rangle_{t\in\mathcal I\subset \mathbb R}$ an $E$ -valued stochastic process. It follows the Markov property if $$\mathbf P[X_t\in A\mid \mathcal F_s] = \mathbf P[X_t\in A\mid X_s,]~~~~\forall A\in \mathfrak B(E),~\forall s,t\in \mathcal I\wedge (s\leq t) \tag 1\label 1.$$ Any process following $\eqref 1$ is a Markov Process. With $E$ being countable and $\mathcal I = \mathbb N_0,$ the process becomes discrete Markov chain. $\bullet$ Does the specification of homogeneous and non-homogeneous change the defining property of the Markov process, viz. $\eqref 1?$ Defintion $2.$ $\langle X_n, T_n \rangle_{n\in \mathbb N}$ is a Markov renewal process if $$\mathbf P[ X_{n+1}=j, ~T_{n+1}- T_n\leq t\mid X_0,\ldots, X_n; T_0, \ldots,T_n] = \mathbf P[X_{n+1}=j,~ T_{n+1}- T_n\leq t\mid X_n]\tag 2\label 2.$$ It is assumed that $\langle \mathbf X, T\rangle$ is time-homogeneous i that $$\mathbf P[X_{n+1}=j,~ T_{n+1}- T_n\leq t\mid X_n] := Q(i, j, t)\tag 3$$ being independent of $n.$ Definition $3.$ Define $Y_t := X_n\cdot\mathbb I_{[T_n,~T_{n+1})}(t).$ Then $\langle Y_t\rangle$ is the semi-Markov process associated with $\langle X, T\rangle.$ $\bullet$ Markov property holds for $Y_t$ only at epochs $T_n.$ $\bullet$ The distribution of the sojourn time $T_{ij}$ can be anything. $\bullet$ If $Q(i,j, t) = p_{ij}[1-e^{-\lambda(i)t}],$ then only the semi-Markov process becomes a time-homogeneous Markov process. $\langle Y_t\rangle$ is a Markov process. Therefore, a Markov process has the Markov property at all times. A semi-Markov process has the Markov property only at epochs. Addition of non-homogeneity doesn't make a drastic distinction. As aptly remarked here : In effect a semi Markov process can have whatever transition probability dependence on time you like, whereas in a non-homogeneous Markov chain you will still always have the probability of a transition from $i$ to $j$ in $[t,t+h]$ being $q_{ij}(t)h+o(h). $ At the end of the day, it is always the case of whether the Markov property $\eqref 1$ has been followed throughout or only at some instances. References: $\rm [I]$ Introduction to Stochastic Processes, Erhan Ã‡inlar, Dover Publications, $2013,$ chapter $10,$ p. $314.$ $\rm [II]$ Stochastic Processes, J. Medhi, New Academic Science Limited, $2012,$ chapter $7,$ p. $299.$
