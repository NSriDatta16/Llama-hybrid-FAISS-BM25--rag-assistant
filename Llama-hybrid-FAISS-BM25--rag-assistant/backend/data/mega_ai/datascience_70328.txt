[site]: datascience
[post_id]: 70328
[parent_id]: 70326
[tags]: 
The choice is mostly about your specific task: what do you need/want to do? Many-to-one (single values) models have lower error, on average, since the quality of outputs decreases the more further in time you're trying to predict. Many-to-one (multiple values) sometimes is required by the task though. An alternative could be to employ a Many-to-one (single values) as a (multiple values) version: you train a model as (single), then you use it iteratively to predict multiple steps. I personally experimented with all these architectures, and I have to say this doesn't always improves performance. Based on my experience, Many-to-many models have better performances. For example, I had to implement a very large time series forecasting model (with 2 steps ahead prediction). The best model was returning the same input sequence, but shifted forward in time of two steps. It appeared that the model was better at keeping the predicted values more coherent with previous input values. It was a seq2seq RNN with LSTM layers. EDIT: The Loss doesn't strictly depend on the version, each of the Losses discussed could be applied to any of the architectures mentioned. A problem for multiple outputs would be that your model assigns the same importance to all the steps in prediction. This is something you can fix with a custom MSE Loss, in which predictions far away in the future get discounted by some factor in the 0-1 range. In that way your model would attribute greater importance to short-range accuracy. Let me know if that's helpful.
