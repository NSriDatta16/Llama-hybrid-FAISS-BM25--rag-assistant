[site]: crossvalidated
[post_id]: 145266
[parent_id]: 
[tags]: 
How much prediction accuracy of SVM (or other ML models) depend on the way features are encoded?

Suppose that for a given ML problem, we have a feature which car the person possesses. We can encode this information in one of the following ways: Assign an id to each of the car. Make a column 'CAR_POSSESSED' and put feature id as value. Make columns for each of the car and put 0 or 1 according to whether that car is possessed by the considered sample or not. Columns will be like "BMW_POSSESSED", "AUDI_POSSESSED". In my experiments the 2nd way performed much better than 1st one, when tried with SVM. How does the encoding way affects the model learning, and are there some resources in which affect of encoding has been studied? Or do we need to do hit and trials to check where it performs best?
