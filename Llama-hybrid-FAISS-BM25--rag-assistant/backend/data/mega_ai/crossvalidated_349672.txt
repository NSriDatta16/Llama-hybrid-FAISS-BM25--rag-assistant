[site]: crossvalidated
[post_id]: 349672
[parent_id]: 348787
[tags]: 
The main reason is inappropriate data preprocessing . People tend to assume they can just dump the data into a black box algorithm and get out clusters. That does not work. Because clustering is unsupervised, it is much more sensitive than many supervised approaches. Before using any of the clustering algorithms, you first need to understand what they do, in particular of what the data needs to be like. In particular, the methods are very sensitive to data scaling. Neither not using scaling, nor automatic normalization, is usually appropriate. As a user of clustering, you need to first carefully select, scale, and weight all features. A single bad attribute (such as a record ID) can spoil everything. It gets most problematic if you have nonlinear variables, mixed types, and attributes of different kind. In supervised learning, e.g., a SVM can learn much of the feature selection and linear scaling. But without labels, we can't do this in clustering.
