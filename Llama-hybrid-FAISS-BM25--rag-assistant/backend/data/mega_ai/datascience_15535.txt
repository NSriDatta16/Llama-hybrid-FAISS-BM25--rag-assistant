[site]: datascience
[post_id]: 15535
[parent_id]: 
[tags]: 
Convolutional Neural Network overfitting

I built a CNN to learn to classify EEG data (only about 4000 training examples, 2 classes, 50-50 class balance). Each training example is 64x512, with 5 channels each Ive tried to keep the network as simple/small as possible for testing: ConvLayer (4 filters) MaxPool Dropout 50% Fully connected (50 neurons) Dropout 50% Softmax Im also using weight decay (L2 reg, lambda = 0.001) The problem is no matter how I play with the filter parameters (size, stride, number) my network keeps overfitting. It fits the training data 100%, but no matter what I do I can't get the test accuracy over 65%. Why is such a small network overfitting? I thought it was a sample size issue, but I've read a number of research papers on EEG and BCI and they occasionally have even smaller sample sizes than I do What else can be done to regularize a CNN?
