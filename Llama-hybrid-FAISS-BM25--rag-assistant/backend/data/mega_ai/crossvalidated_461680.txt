[site]: crossvalidated
[post_id]: 461680
[parent_id]: 461586
[tags]: 
Below is a short explanation. If you have questions, I am happy to elaborate or go into further detail. Linear Regression: The use of t-tests is linear regression comes from the distribution of normally distributed error terms: $y_i=X_i'\beta + \epsilon_i$ where $\epsilon_i \sim N(0,1)$ iid. It follows that $\frac{\hat{\beta_j}-\beta_{j0}}{se(\hat{\beta_j})} \sim t(N-K),$ where $N$ is the sample size and $K$ is the length of the vector $\beta$ . Note that the default in most regression software packages test the hypothesis that $\hat{\beta_j}=0$ , i.e. setting $\beta_{j0}$ equal to zero. Logistic Regression: Logistic regression assumes errors follow the logistic distribution. Consequently, the term $\frac{\hat{\beta_j}-\beta_{j0}}{se(\hat{\beta_j})}$ does not follow a t-distribution. Instead, we can use the Wald test, which relies on asymptotic normality as is implied by the Central Limit Theorem.
