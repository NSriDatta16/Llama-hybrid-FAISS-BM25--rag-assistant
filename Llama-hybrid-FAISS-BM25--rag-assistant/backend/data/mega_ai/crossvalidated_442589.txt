[site]: crossvalidated
[post_id]: 442589
[parent_id]: 442588
[tags]: 
It seems that you do nested cv to evaluate the performances of each split but I don't see any sort of averaging to come up with a final estimate. I'm assuming you average accuracies found for each outer split. More importantly, it won't probably matter how large your hyper-parameter search space is because RandomizedSearchCV has only n_iter=5 iterations, which means you randomly sample only $5$ combinations from a total of $6\times8\times4\times5\times4 = 3840$ combinations. When you sample only $5$ of these, it's highly probable that you end up with a bad set of hyper-parameters since the search space is not spanned well. You may want to use a smaller space with broader steps, and then re-search around promising areas at finer resolution. Or, you may also want to try Bayesian HPO implemented in skopt ( BayesSearchCV class), which is typically more efficient than complete grid search and surely better from random search.
