[site]: crossvalidated
[post_id]: 204334
[parent_id]: 203984
[tags]: 
This is an excellent and deep question. While traditional textbooks (like mine ) tend to promote Bayes factors as equivalent to posterior probabilities of the null and alternative hypotheses or of two models under comparison, which is formally correct as detailed in the following extract from my Bayesian Choice , I now tend to think that the Bayes factor per se should not be used for decision-making but rather as a measure of relative evidence of one model versus the other. For instance, using $\mathfrak{B}^\pi_{01}(x)=1$ as the dividing line between null and alternative (or between model a and model b) does not strike me as a natural choice. Furthermore, I do not think the 0-1 loss advocated by Neyman and Pearson and later adopted by almost everyone is making much sense and brings any support to the decisional interpretation of the Bayes factor. My current perspective on the Bayes factor is more in a prior or posterior predictive mode where the behaviour of $\mathfrak{B}^\pi_{01}(x)$ is assessed under both models, in order to calibrate the observed value $\mathfrak{B}^\pi_{01}(x)$ against both prior or posterior distributions of $\mathfrak{B}^\pi_{01}(x)$. This gets us away from the decisional perspective. [From The Bayesian Choice , 2007, Section 5.2.2, page 227] From a decision-theoretic point of view the Bayes factor is only a one-to-one transform of the posterior probability, but this notion came out to be considered on its own ground in Bayesian testing. The Bayes factor is the ratio of the posterior probabilities of the null and the alternative hypothesis over the ratio of the prior probabilities of the null and the alternative hypothesis, i.e., $$ \mathfrak{B}^\pi_{01}(x) = {\mathbb{P}(\theta \in \Theta_ 0\mid x) \over \mathbb{P}(\theta \in \Theta_1\mid x)} \bigg/ {\pi(\theta \in \Theta_ 0) \over \pi(\theta \in \Theta_ 1)}. $$ This ratio evaluates the modification of the odds of $\Theta_0$ against $\Theta_1$ due to the observation(s) and can naturally be compared to $1$, although an exact comparison scale can only be based upon a loss function. The Bayes factor is, from a Bayesian decision-theoretic point of view, completely equivalent to the posterior probability of the null hypothesis as $H_0$ is accepted when $$ B^\pi_{01} (x) \ge {a_1\over a_0} \big/ {\rho_0 \over \rho_1} = {a_1\rho_1 \over a_0\rho_0}, $$ where $$ \begin{align*} \rho_0 &= \pi(\theta\in\Theta_0) \quad \hbox{ and } \nonumber\\ \rho_1 &= \pi(\theta\in\Theta_1)\\ &=1-\rho_0. \end{align*} $$ and where $a_0$ and $a_1$ are the penalties for wrongly selecting the alternative and null hypotheses or the models $\mathfrak{M}_0$ and $\mathfrak{M}_1$. respectively, in Neyman-Pearson formulation: $$ \mathfrak{L}(\theta, \varphi) = \begin{cases} 0 &\text{if $\varphi=\mathbb{I}_{\Theta_0}(\theta)$,} \cr a_0 &\text{if $\theta\in\Theta_0$ and $\varphi=0$,} \cr a_1 &\text{if $\theta\not\in\Theta_0$ and $\varphi=1$,}\cr\end{cases} $$
