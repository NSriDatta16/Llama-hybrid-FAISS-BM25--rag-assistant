[site]: crossvalidated
[post_id]: 303783
[parent_id]: 303739
[tags]: 
For what it's worth, I remember some specific results about convergence of the filtering covariance matrix (not mean) and convergence of the Kalman gain matrix. However, I think these are only true for specific models. For example, in section 2.3 of Bayesian Forecasting and Dynamic Models , the authors show these types of convergence for the random walk plus noise model. I also remember that these authors also deal with evaluating out-of-sample forecast performance by evaluating their forecast distributions at the out-of-sample data. High (log-)densities are good, while low ones are bad. This stuff is very much akin to Bayes Factors and prior prediction distributions. Under certain assumptions, I am sure you can invoke a limiting argument to justify convergence of these logged quantities to some entropy-based quantity.
