[site]: crossvalidated
[post_id]: 350599
[parent_id]: 194425
[tags]: 
Since this looks like self-study I will only give some ideas. First notation. $p$ is the probability that a child pays with a quarter( maybe $p=1/2$ was intended?). Let $X_i$ be the number of quarters the cashier has after child $i$ has paid, $X_0=2 k$. Then, $X_0, X_1, X_2, \dotsc, X_{2n}$ is a Markov chain. To assure that this is defined at all times, we postulate that if the cashier has no quarters left, he pais preliminary with a "debt certificate" and count that a a negative quarter. So we are interested in the probability that $$ \min(X_0, X_1, \dotsc, X_{2n}) \ge 0 $$ If we now reformulate, declaring $-1$ to be an absorbing state, and stop the chain if it is absorbed, then we are interested in the probability that the chain is never absorbed (before or at time $2n$). Some post which might be of help is Given two absorbing Markov chains, what is the probability that one will terminate before the other? , Expected number of times you spent in a state of an absorbing markov chain, given the eventual absorbing state
