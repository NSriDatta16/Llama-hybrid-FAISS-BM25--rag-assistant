[site]: crossvalidated
[post_id]: 103632
[parent_id]: 103624
[tags]: 
You have one big problem with the F-test for equality of variance, and two problems with naive testing for equality of variance in time series: 1) it's very sensitive to deviations from normality. This means that often things like Levene or Browne-Forsythe type tests (along with several others) are suggested instead. 2) The usual variance tests assume independence. You would seem generally unlikely to have it with time series. 3) if your time series are changing over time, a more rapidly varying mean (stronger trend) will look like a larger variance. You may misdiagnose one as the other. A potentially more suitable approach would model the series appropriately to estimate trend and time dependence and possible change in mean at the intervention - as well as model the potential change in variance at the intervention. A suitable test of change in variance would reduce to testing the parameter describing the change in variance at the intervention. Edit: The idea would be to write a time series model describing the series, including any effects on mean and variance (say) at the intervention. The model for the variance of the error term would presumably be along the lines that it's $\sigma^2$ before the intervention and $\kappa\sigma^2$ after. Such a model might be fit by ML, say. A test of $\kappa=1$ would then be a test for a change in variance. Your idea of fitting ARMA before and after and comparing some estimate of variance that way has merit, but you don't seem to be anticipating a change in time-dependence across the intervention. (Or did I misunderstand? If so, that might slightly complicate the potential advice, because error variance and series variance would no longer be directly related across the change.) Another edit: perhaps your F-test approach can be made more robust to non-normality. If you fit your ARMA model before and after the intervention, the estimates of the error terms can be resampled (with replacement), and pseudo-samples generated from those. You can then build up a bootstrap CI for the ratio of variances, which if it excluded 1 would suggest that the variances differed. Bootstrap resampling would stay within the two parts (by which I mean a pseudo-error on one side of the intervention would come from sampling the residuals on that same side). Alternatively you could do something more like a randomization test on the residuals from the model: sampling without replacement across the divide, but now you'd treat the generated variance ratios as the null distribution of a test statistic, and see where your original sample ratio fell in the distribution. Finally, you might fit your ARMA model and perform a Levene or Browne-Forsythe test on the residuals from the model (for two groups, before and after), which avoids the lack of robustness of the F-test.
