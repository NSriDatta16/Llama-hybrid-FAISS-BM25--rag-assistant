[site]: crossvalidated
[post_id]: 497262
[parent_id]: 491523
[tags]: 
Since $$p(x|\mu,\lambda,\nu)=\int_0^\infty \varphi(x|\mu,(\lambda\eta)^{-1})\gamma(\eta|\nu/2,\nu/2)\,\text d\eta$$ the observed likelihood writes \begin{align}\prod_{i=1}^n p(x|\mu,\lambda,\nu)&=\prod_{i=1}^n\int_0^\infty \varphi(x_i|\mu,(\lambda\eta)^{-1})\gamma(\eta|\nu/2,\nu/2)\,\text d\eta\tag{1}\\ &=\prod_{i=1}^n\int_0^\infty \varphi(x_i|\mu,(\lambda\eta_i)^{-1})\gamma(\eta_i|\nu/2,\nu/2)\,\text d\eta_i\\ &=\int_{\mathbb R_+^n}\prod_{i=1}^n \varphi(x_i|\mu,(\lambda\eta_i)^{-1})\gamma(\eta_i|\nu/2,\nu/2)\,\text d\boldsymbol\eta \end{align} since $\eta$ is a dummy symbol in each of the $n$ integrals in (1), which can be written as $\eta_i$ for the $i$ -th integral. Thus the complete likelihood can be chosen as $$\prod_{i=1}^n \varphi(x_i|\mu,(\lambda\eta_i)^{-1})\gamma(\eta_i|\nu/2,\nu/2)$$ About the second question, it is counter-productive to see $\eta$ in a Bayesian light as a parameter with a Gamma prior since $\eta$ varies with the observation, which is issued from the marginal ( $\eta$ integrated out) and not the conditional on $\eta$ , as demonstrated above. An $n$ sample $(x_1,\ldots,x_n)$ comes with an $n$ latent sample $(\eta_1,\ldots,\eta_n)$ . Contrary to a Bayesian sample, it is not possible to learn about $\eta_i$ from the sample.
