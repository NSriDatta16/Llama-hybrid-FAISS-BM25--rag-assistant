[site]: datascience
[post_id]: 100649
[parent_id]: 
[tags]: 
What are the “training error” and “test error” used in deep learning papers?

I have heard of the terms "training" and "test error" in the context of classification quite often, but I am not sure I know what they mean. This article writes: Training Error : We get the by calculating the classification error of a model on the same data the model was trained on (just like the example above). But what is the "classification error of a model"? Is it $100\% - \text{train_accuracy}$ or is it the loss? This does not get clear to me, I'm afraid. Edit : The paper Deep Residual Learning for Image Recognition has in Figure 6 on page 8 some plots for the training and test error and in table 6 concrete values for them. How do I get them when training a ResNet, for example?
