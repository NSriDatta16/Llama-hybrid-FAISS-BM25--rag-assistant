[site]: datascience
[post_id]: 31030
[parent_id]: 31025
[tags]: 
An easy way to run different versions of multiple frameworks alongside each other is to use Docker . With Docker, you can create a new "Container", kind of a light-weight virtual machine, for each project. Docker handles all hardware abstraction and separates the different Frameworks. Note : To use the GPU within a Docker container, you need to install Nvidia-Docker , as a "normal" Docker installation can not share the GPU with a container. In your example, you could have a Docker container for Digits, and a separate one for TensorFlow - then the two frameworks will be completely isolated from each other. This approach comes with multiple advantages: You can run the same container on a different machine without installing e.g. TensorFlow - all you need is (Nvidia-)Docker. You can easily use different (TensorFlow) versions for different projects, as each project gets it's own container which is separated from the system. Containers can use different CUDA versions, e.g. CUDA 8 for Digits and CUDA 9 for TensorFlow. There are pre-built containers for almost all existing deep learning frameworks. Nvidia even provides some GPU-optimized containers with their free NGC (Nvidia GPU Cloud) service.
