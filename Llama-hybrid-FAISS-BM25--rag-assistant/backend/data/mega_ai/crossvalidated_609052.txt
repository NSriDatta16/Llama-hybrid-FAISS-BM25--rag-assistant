[site]: crossvalidated
[post_id]: 609052
[parent_id]: 
[tags]: 
How to apply the central limit theorem on higher order moments?

If I have a set of $N$ independent samples from a probability distribution $P(X)$ , $X_i\sim P(X)$ , then I know from the central limit theorem (assuming the distribution is well behaved) that the moments of the sample distribution $\overline{X^k}\equiv \frac{1}{N}\sum_i X_i^k$ , will each individually be normally distributed, and there are useful formulas I can use for the sample error. But how can I talk about the joint distribution $P(\overline{X^k},\overline{X^{\ell}})$ ? Specifically I care about the joint distribution of the second and fourth sample moments, $P(\overline{X^2},\overline{X^{4}})$ . From quick numerical experiments and naive intuition, I would guess that this joint distribution should be a multivariate Gaussian under some set of conditions. But I also see problems with that, because inequalities like $(\overline{X^2})^2\le\overline{X^4}$ are satisfied. There is also the fact that even if two distributions $P(A)$ and $P(B)$ are normal, it doesn't have to be the case that $P(A,B)$ is normal. In practice this question arises because I have a time series of data from a Markov chain with $0\leq X_i\leq 1$ (so I have to use the Markov chain central limit theorem), and I care about estimating the quantity $f(\mathbb{E}[X^2],\mathbb{E}[X^4])$ . There are lots of other ways to estimate the error on the quantity $f$ , but I think it would be useful to understand the generic situation above.
