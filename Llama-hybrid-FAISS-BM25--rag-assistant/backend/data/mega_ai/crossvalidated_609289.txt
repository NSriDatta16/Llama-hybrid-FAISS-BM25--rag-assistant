[site]: crossvalidated
[post_id]: 609289
[parent_id]: 
[tags]: 
Identifiability of models on RKHS

I have just started learning about using reproducing kernel hilbert spaces for regularisation in machine learning. I am looking for some examples of reproducing kernels that produce identifiable and non identifiable models of the following form: $$ Y_i \sim \text{EF}(\mu_i,\phi),~g(\mu_i) = \gamma + f(x_i), f \in \mathcal H_k $$ where EF here some an exponential family distribution, $x_i \in \mathbb{R}^p$ and $\mathcal H_k$ is a RKHS with reproducing kernel $k(x,x')$ . We consider only $\mathcal H_k \subset \{ f \colon \mathbb{R}^p \to \mathbb{R} \}$ . I would like examples of kernels for which this model is identifiable, and those under which it isnâ€™t. My understanding is that the model is identifiable if each distinct set of $(\gamma,\phi, f)$ corresponds to different exponential family distributions EF. Is this correct? If so, I am then unsure about what restrictions need to be on $f$ such that our model is identifiable. More generally, I have seen that if we have $f \in \mathcal C^2(x)$ (twice differentiable functions) then our model isn't identifiable, because we have $g(\mu_i) = \gamma + f(x_i) = (\gamma - c) + (f(x_i) + c)$ and $(f(x) + c) \in \mathcal C^2(x)$ . This makes sense to me, but I am unclear about how we can then make this model identifiable by changing the properties of $f$ , or rather by restricting the domain on which $f$ exists. I am also unsure how to implement these domain restrictions by using different kernels to define our RKHS. Any help / examples of reproducing kernels would be appreciated.
