[site]: crossvalidated
[post_id]: 555034
[parent_id]: 
[tags]: 
Disagreeing significance tests for an Ordinal Logistic Regression

I calculated both confidence interval and p-value on the same model using R, and the two tests of significance disagreed with one another. I am comparing how 3 groups differ in terms of an ordinal variable, once a separate numeric predictor was taken into account. The model indicated that group was a significant predictor, and when I graphed the probabilities, I noticed that two of the groups were very similar, so I created a subset of the data only containing these groups to see if group was still a statistically significant predictor. The p-value indicated that it was not (p=0.64), but the confidence interval indicated that it was a significant predictor (CI 2.5% = 0.68, CI 95% = 1.28). I'm not sure where to go from here. I did a couple of other tests (which make a few extra assumptions and so aren't ideal), and all of them indicated non-significance. I've been using confidence intervals for this entire project, so suddenly switching to p-values is a bit jarring and I would prefer not to turn to tests & models that are less ideal. I wish to know why this happened, what it means, and, if possible, whether this is due to a mistake in my code. here's the code for the model & statistical tests I used: library(MASS) #model DvS ```
