[site]: crossvalidated
[post_id]: 325220
[parent_id]: 325012
[tags]: 
For your specific case , I would point out that the Student's t includes the normal distribution as a limiting case (df -> inf). Thus, the two are nested and not really different likelihoods. Because of that, I don't really see a need for model selection - you can just fit the Student's t and interpret the df value as proximity to normality. If you are super concerned about overfitting, add a regularization (hyper)prior on the df parameter. Note that it may be useful to reparameterize the df parameter in the Student's t, see, e.g. Augustynczik et al. (2017) Forest Ecology and Management, 401, 192-206 . In general : yes, you can compare different likelihoods with ICs such as AIC or WAIC, with exceptions. These exceptions are probably the thought underlying the quoted paragraph, but I admit that the text is sufficiently vague to create confusion. Generally, different likelihoods are comparable (note, btw., that the use of deviance in the text is a bit confusing because deviance is often defined as the difference to a saturated model, but here only means log L). However, there are a number of exceptions. Some common situations are Changes of the # of data points Changing the scale of the response variable (e.g. doing a log transformation on y), see here Changing the codomain of the probability distribution, e.g. comparing continuous with discrete distributions I think 1 is trivial (and easy to correct for). For 2,3 consider that p(D|M, parameters) is a pdf for D, thus changing the scale or codomain will change the integral and thus the normalized density. See also related questions on CV, e.g. here . Another problem could be that you use a stats software that doesn't use properly normalized likelihood values (usually the normalization is not important, so a programmer might be tempted to drop it), but I don't think that's common.
