[site]: datascience
[post_id]: 43991
[parent_id]: 43689
[tags]: 
As far as I know, kernel methods cannot deal with categorical variables (don't now whether it is the case). In addition, you will have to use indirect methods to evaluate the variable importance. This could work, although I havent tested it yet: Giam, X., Olden, J.D., 2015. A new R2-based metric to shed greater insight on variable importance in artificial neural networks. Ecol. Modell. 313, 307–313. http://dx.doi.org/10.1016/j.ecolmodel.2015.06.034 I would definitively go for a tree-based approach. Since you already know that there are correlated variables, I would advocate for conditional Random Forests (which solve many drawbacks of the standard random forests implementation). Check: Strobl, C., Hothorn, Zeileis, A., 2009. Party on! R J. 1 (2), 14–17. And references therein. At least in R there are complementary packages ( https://cran.r-project.org/web/packages/pdp/index.html ) that allow plotting the impact of each predictor variable over the target variable (house prices). That complements the variable importance ranking pretty well. Good luck.
