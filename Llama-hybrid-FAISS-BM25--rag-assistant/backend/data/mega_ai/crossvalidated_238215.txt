[site]: crossvalidated
[post_id]: 238215
[parent_id]: 
[tags]: 
Standard errors different from sqrt of covariance matrix diagonal elements in scipy.odr

I'm writing a code to fit some data (with x_errors and y_errors) to a model with three parameters a , b and c , using the ODR method with scipy.odr . The fitting procedure is good enough, however I find that the standard errors on the estimated parameters out.sd_beta are different from the sqrt of the diagonal elements of the covariance matrix out.cov_beta by more than a factor of 2.4 (e.g. 0.0206 vs 0.00883 for the parameter a ). A Monte Carlo simulation (w/ 100k realizations) shows that the square root of variance of the parameters is very close to the one extracted from the covariance matrix, and both are similar to the average of the standard error in the MC simulation: √Var(a) ~ 0.00853 , Mean(a_sd) ~ 0.00854 , √Cov(a,a) ~ 0.00883 . I originally thought that the standard errors where just the sqrt of the diagonal elements of the covariance matrix, but they are clearly not the same value here. What the standard errors represent then? Am I missing something? I tried looking at the ODRPACK user manual but I didn't find anything. Also, there should be any reason why the standard errors are so different in the original fit and in the MC simulation? It may be useful to write down how I did the simulation. First, I took the x values (w/ x-errors) from the data, which represent the bins of a distribution. Then I computed the probability in the bin as the value of the distribution in those points (with the fitted parameters) times the bin size (x[i+1]-x[i-1])/2 . I could have used the analytical integral for that, but it should be roughly the same. Then I assigned the residual probability (1-sum(p[i]) (of the order of 10^-10) to a token bin far away in the tail, and I used np.random.choice to draw N=400k points (original number of points that I binned). At this point it's just a matter of counting the occurrence of each bin in the resulting array, computing poissonian errors, normalizing and discarding the token bin. Then fit, save the results, and take another draw (100k times).
