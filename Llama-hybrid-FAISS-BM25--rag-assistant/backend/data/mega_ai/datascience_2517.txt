[site]: datascience
[post_id]: 2517
[parent_id]: 2486
[tags]: 
Dimension reduction (like PCA) is an excellent way to visualize the results of classification on a high-dimensional feature space. The simplest approach is to project the features to some low-d (usually 2-d) space and plot them. Then either project the decision boundary onto the space and plot it as well, or simply color/label the points according to their predicted class. You can even use, say, shape to represent ground-truth class, and color to represent predicted class. This is true for any categorical classifier, but here's an SVM-specific example: http://www.ece.umn.edu/users/cherkass/predictive_learning/Resources/Visualization%20and%20Interpretation%20of%20SVM%20Classifiers.pdf In particular, see figures 1a and 2a.
