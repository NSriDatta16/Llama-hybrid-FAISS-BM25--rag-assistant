[site]: crossvalidated
[post_id]: 568485
[parent_id]: 
[tags]: 
Logistic regression of 'true model' has bias

I'm trying to train a logistic regression on simulated data. I have n=1000 simulations for the following variables: binary proxy variable proxy = rbinom(n, 1, 0.5) x1 thats affected by proxy: x1 A random effect variable: xr binary response y l pr yt This is the distribution of pr , that is used to generate the binary yt . It is unbalanced in this case case 1: I created a data frame that contains x1, xr, pr, yt , split it into train/test. Train dataset contains x1, xr, yt to fit model1 = glm(yt ~ x1 + xr, data = train1, family = "binomial") . After that, I did test_prob = predict(model1, data.frame(test_data), type="response") in which test_data contains 2 columns: x1 and xr . Finally, I calculated bias y_bias . case 2: I tried another model: model2 = glm(yt ~ proxy + x1 + xr, data = train2, family = "binomial") . In this case train contains proxy, x1, xr, yt . I used model2 to predict yt in steps similar to case 1. I assume model1 is the true model with around 0 bias because yt is generated by x1 and xr and we are using the same two variables to predict yt. However, the bias of model2 is smaller then model1. I'm wondering if this is normal, or I did something wrong?
