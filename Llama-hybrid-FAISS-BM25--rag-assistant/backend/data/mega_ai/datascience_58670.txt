[site]: datascience
[post_id]: 58670
[parent_id]: 
[tags]: 
Specifying number of threads using XGBoost.train

When using the xgboost.train() function, all the threads are used. I would like to use a specific amount. Unfortunately, this function does not accept the parameters nthread nor n_jobs . How can I control the number of threads being used? Thanks. // Edit It seems that I found a solution. In contrast with the method, how one provides the nthread (or n_jobs) parameter to XGBClassifier of XGBRegressor, by adding this parameter directly to the brackets as xgb.XGBRegressor(nthread=n) then as indicated on xgboost document (page 46), I added an additional parameter parameters["nthread"] = number_of_threads to the parameters (a dictionary) I am using. After testing with different numbers, the number of threads being used reported in htop was the same as the number_of_threads parameter provided. Can anyone confirm this to be the right method?
