[site]: crossvalidated
[post_id]: 240172
[parent_id]: 
[tags]: 
What method can be used to evaluate distribution from observations given by their bounds (ranges)?

A standard problem of statistics is to evaluate statistical properties (mean, variance, probability distribution) from a set of numerical observations. However, in some cases instead of having numerical observations we have ranges for the observer number. For example, we know that value is between 1.3 and 3.5, or that the value is larger than 5.7. How such observations have to be treated? I remember that there as a Wikipedia article about that but I cannot find it. ADDED I would like to find the answer in the context of machine learning. Actually my problem is less general than the described above. I have tow types of observations: (1) exact numeric values and (2) observations with known lower bound (for example I know that the values has to be not smaller than 3.7). I need to use the given observations in a training. As far as I remember some iterative procedure has to be used. We train the model using the lower bounds as the target. Then we use the training model to predict and then we do the next iteration in which we use the prediction as target. But I do not remember how exactly it should be done and what is the intuition behind this iterative procedure.
