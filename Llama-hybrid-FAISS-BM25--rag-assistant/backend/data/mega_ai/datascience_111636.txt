[site]: datascience
[post_id]: 111636
[parent_id]: 
[tags]: 
When to prioritize accuracy over precision?

I am working on a simple SVM project for the prediction of hepatitis c. I got my dataset from kaggle. When dealing with null values, I tried two ways, firstly by dropping data with null values, second by filling null values with mean. The above is the result of the first method. I obtained a fairly high accuracy value, as well as a high precision value for blood donors (healthy people).However, the accuracy value of fibrosis, hepatitis, and suspect is 0. I know this because there are only a few datasets for these three categories, and some of them have null values, so they have to be dropped. Next is if I replace the null value with the mean of the column. I get a slightly lower accuracy value, but still get precision on fibrosis and hepatitis. I want to know, is it more important to get high accuracy from dropping data, or precision from using mean values?
