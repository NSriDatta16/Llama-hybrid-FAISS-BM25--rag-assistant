[site]: datascience
[post_id]: 16640
[parent_id]: 
[tags]: 
How to improve the binary classification model for text (News Articles) of Recurrent Neural Net with word emmbeding?

I am trying to do binary classification of news articles using Recurrent Neural Net with word embedding. Following are the parameters of the model: Data: 8000 labelled news articles (Sports:Non-sports::15:85) Parameters: embedding size = 128 vocabulary size = 100000 No. of LSTM cell in each layer = 128 No. of hidden layers = 2 batch size = 16 epochs = 10000 Result: AUC on training set = 0.60 AUC on testing set = 0.55 As the both training and testing error is high model is underfitting and require more data. So I have couple of doubts here: What would be the optimum data size required? Can we change the parameters to improve AUC. By decreasing, embedding size or No. of neurons we can minimize degree of freedom.
