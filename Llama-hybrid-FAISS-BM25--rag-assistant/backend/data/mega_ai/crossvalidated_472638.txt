[site]: crossvalidated
[post_id]: 472638
[parent_id]: 
[tags]: 
sample complexity vs training cost (time complexity)

I have a question about the complexities. Consider two regression problems A, B and assume that A has lower sample complexity than B. A and B share the same target function but the loses are slightly different, so the sample complexity are different. If I train a neural network (or any kind of suitable learner) to solve A and B with everything fixed (including sample size), and assume my dataset is large enough to solve both A and B. In this setting, can I expect more efficient training for the problem A? I mean, I want to say that the number of iterations needed to achieve certain accuracy is lower in case of A than in B since the sample complexity is lower. Is this statement true?? Any kind of references would be helpful! I'm kind of new to this field :D
