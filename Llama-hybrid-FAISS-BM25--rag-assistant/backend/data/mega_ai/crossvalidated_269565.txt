[site]: crossvalidated
[post_id]: 269565
[parent_id]: 205867
[tags]: 
If your training and test data are drawn from the same distribution, shuffled etc, then training and test error for unseen minibatches, prior to training on those minibatches, should on average be identical. If they are not, then one of those assumptions is being violated, ie: your training and test data are not drawn from the same distributions, and/or you didnt shuffle the data Note that you have to be a bit careful about shuffling your data, its not always applicable, eg if you have time series: your test data should be drawn from a time period after the time periods from which all of the training data were drawn. But now the distributions are not the same (probably change gradually over time), which violates assumption 1, above, and would hence give rise to what you are seeing.
