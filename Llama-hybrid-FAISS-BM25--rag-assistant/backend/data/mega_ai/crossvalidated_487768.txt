[site]: crossvalidated
[post_id]: 487768
[parent_id]: 482906
[tags]: 
It is untrue. The MAB setting can be interpreted as a one-state MDP (thus a MAB is stateless). In MAB you are given a set of K distributions (whose structure is usually known while the mean of the distribution is unknown). The goal in MAB is either to identify the arm with the highest mean (best arm) with the smallest number of arm pulls or to maximize the cumulative regret. An MDP is much more complex: the action you choose determines a new state in which you could have completely different distributions (and best arms). In MAB you are always in the same state).
