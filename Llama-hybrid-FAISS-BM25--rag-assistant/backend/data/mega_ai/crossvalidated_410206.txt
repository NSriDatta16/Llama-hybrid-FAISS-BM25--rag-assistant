[site]: crossvalidated
[post_id]: 410206
[parent_id]: 410118
[tags]: 
The general procedure of K fold Cross Validtion (CV) is: Shuffle Dataset Hold out some part of it ( $~20\%$ ) whic will serve as your unbiased Test Set. Select a set of hyper-parameters. Divide the rest of your data into $K$ -parts. Use one part as validation set, rest as train set. Your Validation performance (of given hyper-parameters) is determined/evaluated as the average of choosing each one of $K$ sets as CV set once (mathematically $\sum_KP(set^{(k)}) *(Performance) = \sum_K \frac{1}{K}*(Performance)$ (since randomly chosen). Speaking in layman terms, assume you have a question bank and you have to report to others about your knowledge. You set out a certain number of questions as test (do not touch it except at the end). The rest you divide in $K$ parts and use one $(K-1)$ sets of question to train your knowledge (see both the question and answer) and the last one set to Validate your knowledge (solve questions, do not see answer), you do this for all sets choosing each time one set as the validation set. And finally, you take the test on the test set and report your knowledge.
