[site]: datascience
[post_id]: 64887
[parent_id]: 
[tags]: 
Question regarding: Vectorization Math of Backpropagation in a Neural Network

Formula: These are the formula I use for backpropagation from Brilliant : Question: If we consider a Neural Network with the structure (3,2) : And we would start calculating the derivative (for 1 trainings example), we would have a (2,1) matrix for the error term. Since $\hat{y} - y$ is a (2,1) matrix and $g_0'(a_1^m)$ is also a (2,1) matrix and we multiplicate them element-wise with each other. If we know want to proceed and calculate the partial derivative with respect to w we would need to multiply $\delta$ which is a (2,1) matrix with $o_i$ which is (3,1) a matrix which is not possible. So what to do? :/
