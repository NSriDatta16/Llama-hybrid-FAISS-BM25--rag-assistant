[site]: crossvalidated
[post_id]: 326970
[parent_id]: 
[tags]: 
Function maximisation using non-linear regression

I'm working on a function maximisation problem, witch is related to a non-linear regression problem. The problem is as follows: The target variable is $y$ and is continuous. The data set consists of some features $x_1,\dots,x_N$, $y$ and a parameter $p$, which is a continuous and bounded. The parameter $p$ is a feature that I can tune for new samples. The objective is to, given a new data point (i.e., a set of fetaures $x_1, \dots, x_N$), find the parameter $p$ that will yield maximum $y$. This is problem is somehow similar to some reinforcement learning problems. New data points are being sampled at constant time intervals, for each new data point ($x_1, \dots, x_N$) I get to decide a parameter $p$ and then I get a feedback $y$. For each new data point, I want to decide the best $p$ so that $y$ is maximized. My approach to solve this problem is as follows: Use non-linear regression techniques to estimate $y$ as a function of $p$ and $x_1, \dots, x_N$ (i.e, regression-$y$). Evaluate regression-$y$ over all possible (well just a subset using global optimization techinques) values of $p$ in order to find the one that yields higher $y$. Construct a second data set with $x_1, \dots, x_N$ and $p^*$, where $p^*$ is the parameter that yielded higher $y$ in regression-$y$. Use another non-linear regression to estimate $p^*$ as a function of $x_1, \dots, x_N$ (i.e., regression-$p$). Use the regression-$p$ to estimate the best $p$ for each new data point. I'm wondering if I could use another procedure that estimates the best $p^*$.
