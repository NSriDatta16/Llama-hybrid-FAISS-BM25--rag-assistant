[site]: datascience
[post_id]: 128153
[parent_id]: 128112
[tags]: 
There is not enough context in this question to assess why SMOTE is performing poorly across your test set. However, if you are using an XGBoost classification model, there is the option to train the model to penalise errors on the minor class more heavily. This would mean that creating synthetic data using SMOTE would not be necessary. Suppose that an XGBoost model is being used to train on y_train and x_train data as below: import xgboost as xgb xgb_model = xgb.XGBClassifier(learning_rate=0.001, max_depth = 1, n_estimators = 100, scale_pos_weight=3) xgb_model.fit(x_train, y_train) Note that the higher the value of the scale_pos_weight parameter - the more severely the model will penalise errors on the minor class. In the above example, it is set to 3 - but one can experiment to find the value at which model accuracy is sufficient. As an aside, when dealing with imbalanced classes - one should also pay attention to precision vs. recall, as maximising accuracy may not necessarily be the best option. Let's take an example. Suppose we have a dataset where 90% of customers buying a service from a company do not cancel their subscription, but 10% of them do. If the aim of the model is to predict if a customer will cancel, then a 90% accuracy is useless as it tells us nothing about the 10% that do cancel. In this regard, one would be looking for a high recall score - i.e. we want to maximise true positives and minimise false negatives. Precision = ((TP)/(TP + FP)) Recall = ((TP)/(TP + FN)) where TP = True Positive, FP = False Positive, FN = False Negative In a situation where we would prefer to minimise false positives - e.g. configuring a spam filter so that it does not falsely mark important e-mails as spam - then we would look to maximise precision . In this regard, I would recommend experimenting with the sensitivity of the scale_pos_weight parameter using just the original data (without SMOTE) and see what the results are like. However, depending on the data you are working with - ensure that you are also paying attention to precision and recall figures, as f1-score accuracy on its own does not tell the whole story.
