[site]: datascience
[post_id]: 81442
[parent_id]: 81438
[tags]: 
If you set epsilon decay to 0.999 you will need $$ \epsilon_{max} \cdot \epsilon_{decay}^x = \epsilon_{min} \\ 1 \cdot 0.999^x = 0.01 \\ x \approx 4603 $$ 4603 episodes to reach minimum epsilon. After 91 episodes you will reach $$ \epsilon_{current} = \epsilon_{max} \cdot \epsilon_{decay}^{episodes} = 1 \cdot 0.999^{91} \approx 0.913 $$ which is exactly what you can see in your plot. It's not a problem but remember that this model still makes over 91% moves randomly. Average reward should not decrease over time. It can mean a few things for example error in dqn algorithm or too high learning rate in your model. The best way to debug is to start with as simple environment as possible and let your model learn to play it and only then increase the difficulty.
