[site]: stackoverflow
[post_id]: 4351593
[parent_id]: 4350725
[tags]: 
If I understand you: You will implement each bloom filter as a bitmap of size N. You assume a hash function which uniformly distributes the elements. If you have ~1000 elements, you would size the bloom filter bitset size so only some tolerable load factor of them are set, perhaps average 1 in 8 to keep the set intersection false positive rate low. Nevertheless you may always get some false positives. For example with bloom filter set intersection, you may get some false positives when set1 = { e1 } and set2 = { e2 } , e1 != e2 , that set1 intersect set2 = { } but bf(set1) interesect bf(set2) <> {} . Note you will never get false negatives -- if bf(set1) intersect bf(set2) = {} then necessarily set1 intersect set2 = {} . I think your algorithm should form BFs for both R and W, then intersect them as many bits at a time as possible, as shown in variant 2 below. Quick hack, rusty C: const unsigned N = 1024 * 8; const unsigned BPW = 8 * sizeof ulong; typedef unsigned long ulong; typedef struct BF { ulong bits[N/BPW]; } BF; unsigned hash(ulong e) { return foo(e) % N; } void clear(BF* pbf) { memset(pbf->bits, 0, sizeof(pbf->bits)); } void add(BF* pbf, ulong e) { unsigned h = hash(e); bf.bits[h/BPW] |= 1 >(h%BPW)) & 1; } bool intersect(BF* pbfResult, BF* pbf1, BF* pbf2) { bool empty = TRUE; for (unsigned i = 0; i bits[i] = pbf1->bits[i] & pbf2->bits[i]) != 0) empty = FALSE; return !empty; } void intersectRW(unsigned nr, ulong* r, unsigned nw, ulong* w) { BF bfR, bfW, bfIntesection; unsigned i; clear(&bfR); for (i = 0; i Expected runtime? Each invocation initializes 3 BFs of 1 KB e.g. 128 ulongs, and these smallish bitmaps sit on the TOS and should easily fit into L1$, and at any rate have great spatial locality; adds 100-1000 elements to bfR e.g. ~1000 inlined invocations of add, some bit shifts and stores; hit tests 100-1000 elements of bfR e.g. ~1000 inlined invocations of hit, some bit shifts, masks, tests; or variant 2, performs elementwise ANDs on just ~128 pairs of ulongs (Note of course all the / and % in the code above are optimized into shifts and masks.) In total this might be some tens of thousands of instructions and a few thousand L1 or L2 cache hits; with a 2 GHz cycle time machine, I would be surprised if this takes more than a few ms once warmed up. As for hash functions, you didn't tell us about the distribution of these 64-bit elements. If they are already well distributed, you can just fold the 64-bits down to 16-bits with a couple of shifts, xors, and a mask. * Today's curious fact -- MS VC++ 4.0's fine grained 'minimal rebuild' feature (http://msdn.microsoft.com/en-us/library/kfz8ad09(VS.80).aspx) depends upon bloom filters galore -- but we had never heard of bloom filters at the time. Rather, we thought we had invented a novel set with probablistic-membership-test data structure... * What do you think? Happy hacking! Wait, I forgot to mention: Overkill, but you can speed up the clear and the intersect operation using vector SIMD instructions (e.g. SSE). You may be able to take advantage of other properties of the data. For example, if there is any similarity between each invocation's R and W arrays, you may be able to turn the brute force algorithm into an incremental algorithm, athough you might have to use counting bloom filters. Depending upon the load factor and the repetitiveness of the elements themselves, you may not need to clear the bitmaps each iteration. You only need to clear them when you finally get a non-empty intersection (then rerun the add()s and the intersect().) Your problem size doesn't need it here, but if you had millions of elements, you could divide the input R and W lists into sublists, hand them out to multiple cores, build private copies of BFs for R and W, then fold (OR) the BF(R)s and BF(W)s together.
