[site]: stackoverflow
[post_id]: 4056302
[parent_id]: 4056144
[tags]: 
It is bad manners to download the DTD from w3.org every time you need to validate a document. Their servers are under crushingly heavy load and it is very expensive for them to pay for all the bandwidth, servers, and IT workers to manage it all. It has always been bad form to download the DTD excessively (per operation), and until recently W3 has been relying on the politeness of software developers and vendors to write their programs in such a way as to not download the DTD per-operation. However, this reliance on good manners is no longer working. Recently W3 has been taking matters into its own hands by blocking DTD downloads based on User Agent matching rules, as well as other blocking rules like IP-based blocking for particularly bad offenders. Since this announcement, they have felt free to introduce new blocking rules as they see necessary, based on e.g. observing traffic trends. It is not unreasonable to think that a recent update to their blocking rules may have affected your software. Very recently I believe they started blocking DTD downloads with very broad User Agent string matching: Internet Explorer user agents, Java user agents, and .NET user agents, to name a few. You should download the DTD just once, and have your validator reference the DTD from local disk, or at least host the DTD using your own server and bandwidth. All parsers worth a darn have features to help re-map "DTD namespace" to "physical DTD location." Many XML utilities have the ability to use an XML catalog to map URIs for external resources to a locally-cached copy of the files. For some additional information on configuring XML applications to use a catalog, see Norman Walsh's Caching in with Resolvers article or Catalog support in libxml , and don't forget to use Google for more information! Also note others have recently started encountering problems with w3.org, DTDs, .NET and IE.
