[site]: crossvalidated
[post_id]: 189956
[parent_id]: 189906
[tags]: 
In machine learning, model error on the training data is meaningless , period. It is not a limitation nor overfitting, merely a consequence of the fact that methods are built just to perform well on unseen data. In case of RF "train set error" is expected to be near zero because RF uses not-pruned decision trees, hence naturally looks suspicious; yet in case of other algorithms you can expect strange biases and unexpected behaviours as well. OOB is neither some kind of "training set error which looks good", but a result of an internal cross-validation; it should be also rather used as a diagnostic, and, if compared, compared with results of cross-validation of other approaches.
