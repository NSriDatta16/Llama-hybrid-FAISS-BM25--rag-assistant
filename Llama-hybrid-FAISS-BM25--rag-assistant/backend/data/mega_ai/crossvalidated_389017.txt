[site]: crossvalidated
[post_id]: 389017
[parent_id]: 
[tags]: 
Perplexity calculation in variational neural topic models

I'm looking at this 2016 paper from Miao et al. https://arxiv.org/abs/1511.06038 where they use a variational autoencoder for topic modelling. To evaluate the effectiveness of their model, they use perplexity, defined as $exp(-\frac{1}{N}\Sigma^{N}_n\frac{1}{L_n}\log p(X_n))$ . Where $N$ is number of documents, $L_n$ is number of words in document $n$ , and $p(X_n)$ is the probability of observing document $X_n$ (calculated by taking the product of the per-word probabilities in the document $X_n$ . The authors say that: Since $\log p(X)$ is intractable in the NVDM, we use the variational lower bound (which is an upper bound on perplexity) to compute the perplexity following Mnih & Gregor (2014). In their github implementation here: https://github.com/ysmiao/nvdm , The perplexity calculations are coming from the sum of reconstruction loss terms: $E_{q(h|X_n)}[\log p(X_n|h)]$ in place of $\log p(X_n)$ , where $E_{q(h|X_n)}[\log p(X_n|h)]$ is approximated with samples from the posterior approximation $q(h|X_n)$ . My question is: why is this a reasonable approximation - and why is it guaranteed to be an upper bound on perplexity? Any insight here would be much appreciated.
