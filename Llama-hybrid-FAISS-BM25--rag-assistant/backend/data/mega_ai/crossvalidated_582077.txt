[site]: crossvalidated
[post_id]: 582077
[parent_id]: 
[tags]: 
Logistic regression outputs equal coefficients, std error and t values for every categorical variable after creating dummies. Why is that?

I have a dataframe with 700 rows and for each row I have dummy variables. The dataframe looks like this 0 1 2 3 1 1 0 0 0 2 0 0 0 1 3 0 1 0 0 4 1 0 0 0 ..... This is my X . As the target variable I have a floating number between 5.5 and 10, this is my y . I then fit a linear regression on this data. X2 = sm.add_constant(X) est = sm.OLS(y, X2) est2 = est.fit() est2.summary() This outputs the following table: https://gyazo.com/adb010b46cabc785168f0235aa967379 Why are all the values equal? Does this mean there is no predictive power in the data?
