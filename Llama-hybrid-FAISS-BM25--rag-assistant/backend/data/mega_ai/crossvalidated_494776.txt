[site]: crossvalidated
[post_id]: 494776
[parent_id]: 411235
[tags]: 
Within Continual Learning, there are three main problem paradigms : Task-Incremental Learning (where we want the model to solve multiple distinct tasks) Class-Incremental Learning (where we want the model to solve a classification problem, while being presented with additional classes in each new task) Domain-Incremental Learning (where we want the model to answer the same question, but the underlying distribution of the data changes with each task). Permuted MNIST 1 is designed to present an example of the latter problem, where the question (and output labels) are the same: "Is this an image of a 0, 1, 2, 3, ... or 9?" but the underlying distribution of the input data differs with each task. Note however that Permuted NIST has been criticised 2 for not providing a realistic example of an evaluation setting for a Continual Learning model (i.e. there is little to no similarity between the tasks). A more natural example may be, you have a model designed to classify images of cats and dogs based on headshot photos taken face on indoors. You receive new data for nominally the same task (classify pictures of cats and dogs), but the images are from a different distribution where a subset of learnable features are hypothesized to be shared (e.g. colour of animals, facial features etc), e.g: photos of the animals in profile photos of different species of cat and dog photos in a different context (park vs indoors) Permuted MNIST was originally proposed in An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks (2015), and has since been adopted as a common test of Domain-IL performance in Continual Learning (e.g. Three scenarios for continual learning ): To test this kind of learning problem, we designed a simple pair of tasks, where the tasks are the same, but with different ways of formatting the input. Specifically, we used MNIST classification, but with a different permutation of the pixels for the old task and the new task. Both tasks thus benefit from having concepts like penstroke detectors, or the concept of penstrokes being combined to form digits. However, the meaning of any individual pixel is different. The net must learn to associate new collections of pixels to penstrokes, without significantly disrupting the old higher level concepts, or erasing the old connections between pixels and penstrokes. Towards Robust Evaluations of Continual Learning (2019): Cross-task resemblances Input data from later tasks must resemble old tasks enough that they at least sometimes result in confident predictions of old classes, early in training. The widely used Permuted MNIST (see ยง4.2.1) which violates this...
