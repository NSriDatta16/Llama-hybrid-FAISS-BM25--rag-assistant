[site]: datascience
[post_id]: 65639
[parent_id]: 65636
[tags]: 
Very brief answer (no way to go into details here): Aparently the two calls produce different tables containing slightly different statistics. AIC and BIC compare nested models. So if you have some model and you add or remove some variables (for instance), you may compare AIC, BIC. There is no universal "okay" range in terms of overall figures. Even with a low(er) AIC, BIC, you can have a "bad" model. So AIC, BIC really is about comparing "similar" models against each other. There are robust standard errors, which are computed in a different way than "normal" standard errors. I think this indicates that "normal" standard errors are calculated. Not really. The pseudo R-squ. may give you some idea about model fit, but it is a little different from "normal" R-squared and I don't find it too useful. The value of the coefficient is not directly related to significance (small values can be significant and vice versa). Significance is calculated from standard errors/t-/z-statistics . Note that your coefficients are log-odds (NOT marginal effects). In case you want to obtain marginal effects, you need to look for some package (like "margins" in R/Stata) or you do this by hand. Overall I recommend to have a good read about logistic regression since you seem to be uncertain about basic concepts.
