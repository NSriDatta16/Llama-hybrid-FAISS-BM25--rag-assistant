[site]: crossvalidated
[post_id]: 358729
[parent_id]: 
[tags]: 
Difference between Hartigan & Wong Algo to Lloyd's algorithm in K-means clustering

In the iterations of Hartigan and Wong Algo of K-Means clustering, If the centroid is updated in the last step, for each data point included, the within- cluster sum of squares for each data point if included in another cluster is calculated. If one of the cluster sum of squares is smaller than the current one, the data point( case) would be assigned to new cluster. My question is- How is it different from Llyod's algorithm? In Lloyd's new data points will be assigned to new cluster if distance from its(new cluster) lesser that current one. I am wondering how is it possible for a data point to have higher distance from another cluster( new cluster) but lesser squared distance from same another cluster( new cluster) ? paper I referred- https://core.ac.uk/download/pdf/27210461.pdf I think it is sth to do with number of data points in a cluster, but I could't related it to any example where a data point falls in different clusters in both the algos. Can some please explain on it?
