[site]: crossvalidated
[post_id]: 237411
[parent_id]: 143206
[tags]: 
I don't fully understand your formulas, but you definitely should normalize your inputs; otherwise you will run into convergence and performance issues in training your neural networks. If you want to scale inputs and observational data to the scale [0,1], you can use the following: $$ \underline y_{norm} = (\underline y - y_{min})/(y_{max}-y_{min}) $$ To perform the inverse transformation, just invert that formula. $$ \underline y = \underline y_{norm}(y_{max}-y_{min})+ y_{min} $$ You can also scale to [-1,1] if you replace $$(\underline y - y_{min})$$ with $$(\underline y - \bar y)$$ in the first equation. Not sure which language you work in, but here is an example in R for scaling the data. http://datascienceplus.com/fitting-neural-network-in-r/ Hope that helps!
