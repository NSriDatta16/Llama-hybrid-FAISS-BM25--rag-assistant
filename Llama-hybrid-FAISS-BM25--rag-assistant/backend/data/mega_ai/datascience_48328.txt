[site]: datascience
[post_id]: 48328
[parent_id]: 
[tags]: 
How to set kernel size (height and width) for 1D convolution layer in CNN Keras R API for doc2vec input?

I am using a doc2vec matrix (6000,1024) as feature space to input in a classification model which can categorise each document(sentence in my case) into one of the two classes (A,B). My feature space has 1024 features for each of the 6000 sentence in the dataset. So basically each row of doc2Vec matrix represents a feature vector for that sentence. I am trying to use this single matrix as input to a 1D CNN. Usually, the input to CNNs for NLP tasks have one matrix per sentence, hence the batch size is equal to the number of sentence. Whereas my situation is slightly different, I have one matrix as described above. So basically I want the filters to have kernels (of various widths) which slide across just one sentence vector, as opposed to usually kernels which slide across a group of words (i.e slide across multiple word vectors at a time with a height greater than 1). However, I am finding it difficult to set the parameter values to the following layers in keras API for R layer_input(shape = 1024, batch_shape = c(6000,1024), dtype = 'float64', name = 'input1') does this input layer represent what I want it to represent, if not what should it look like otherwise? and not sure how to set the parameter values for layer_conv1d(filters = , kernel_size = ). I am not sure how to give kernel_size list of values which represent (height = 1 and width = n) where n is an integer greater than 1. So in summary I am expecting CNN to select a feature space (6000*n) from an original feature space(6000*1024) and I would column bind it with another feature space to feed it to fully connected layers in the CNN architecture.
