t they do not correlate with cancer. These features may be working against one's model, making it more difficult to obtain optimal results. This problem is up to the data miner to solve, and there is no universal solution. The first step any data miner should take is to explore the data, in an attempt to gain an understanding of how it can be used to solve the problem. One must first understand what the data means, and what they are trying to discover before they can decide if anything must be removed from the data set. Then they can create or use a feature selection or dimensionality reduction algorithm to remove samples or features from the data set if they deem it necessary. One example of such methods is the interquartile range method, used to remove outliers in a data set by calculating the standard deviation of a feature or occurrence. Distance function When a measure such as a Euclidean distance is defined using many coordinates, there is little difference in the distances between different pairs of points. One way to illustrate the "vastness" of high-dimensional Euclidean space is to compare the proportion of an inscribed hypersphere with radius r {\displaystyle r} and dimension d {\displaystyle d} , to that of a hypercube with edges of length 2 r . {\displaystyle 2r.} The volume of such a sphere is 2 r d π d / 2 d Γ ( d / 2 ) {\displaystyle {\frac {2r^{d}\pi ^{d/2}}{d\;\Gamma (d/2)}}} , where Γ {\displaystyle \Gamma } is the gamma function, while the volume of the cube is ( 2 r ) d {\displaystyle (2r)^{d}} . As the dimension d {\displaystyle d} of the space increases, the hypersphere becomes an insignificant volume relative to that of the hypercube. This can clearly be seen by comparing the proportions as the dimension d {\displaystyle d} goes to infinity: V h y p e r s p h e r e V h y p e r c u b e = π d / 2 d 2 d − 1 Γ ( d / 2 ) → 0 {\displaystyle {\frac {V_{\mathrm {hypersphere} }}{V_{\mathrm {hypercube} }}}={\frac {\pi ^{d/2}}{d2^{d-1}\Gamma (d/2)}}\rightarrow 0} as d → ∞ {\displaystyle d\rightarrow \infty } . Furthermore, the distance between the center and the corners is r d {\displaystyle r{\sqrt {d}}} , which increases without bound for fixed r. In this sense when points are uniformly generated in a high-dimensional hypercube, almost all points are much farther than r {\displaystyle r} units away from the center. In high dimensions, the volume of the d-dimensional unit hypercube (with coordinates of the vertices ± 1 {\displaystyle \pm 1} ) is concentrated near a sphere with the radius d / 3 {\displaystyle {\sqrt {d}}/{\sqrt {3}}} for large dimension d. Indeed, for each coordinate x i {\displaystyle x_{i}} the average value of x i 2 {\displaystyle x_{i}^{2}} in the cube is ⟨ x i 2 ⟩ = 1 2 ∫ − 1 1 x 2 d x = 1 3 {\displaystyle \left\langle x_{i}^{2}\right\rangle ={\frac {1}{2}}\int _{-1}^{1}x^{2}dx={\frac {1}{3}}} . The variance of x i 2 {\displaystyle x_{i}^{2}} for uniform distribution in the cube is 1 2 ∫ − 1 1 x 4 d x − ⟨ x i 2 ⟩ 2 = 4 45 {\displaystyle {\frac {1}{2}}\int _{-1}^{1}x^{4}dx-\left\langle x_{i}^{2}\right\rangle ^{2}={\frac {4}{45}}} Therefore, the squared distance from the origin, r 2 = ∑ i x i 2 {\textstyle r^{2}=\sum _{i}x_{i}^{2}} has the average value d/3 and variance 4d/45. For large d, distribution of r 2 / d {\displaystyle r^{2}/d} is close to the normal distribution with the mean 1/3 and the standard deviation 2 / 45 d {\displaystyle 2/{\sqrt {45d}}} according to the central limit theorem. Thus, when uniformly generating points in high dimensions, both the "middle" of the hypercube, and the corners are empty, and all the volume is concentrated near the surface of a sphere of "intermediate" radius d / 3 {\textstyle {\sqrt {d/3}}} . This also helps to understand the chi-squared distribution. Indeed, the (non-central) chi-squared distribution associated to a random point in the interval [-1, 1] is the same as the distribution of the length-squared of a random point in the d-cube. By the law 