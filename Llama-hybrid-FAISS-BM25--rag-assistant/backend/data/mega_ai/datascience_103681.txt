[site]: datascience
[post_id]: 103681
[parent_id]: 103679
[tags]: 
Yes. The optimizer and loss the are not part of serving inference. Once you finish training, tensorflow will save the entire graph (i.e. architecture + weights). Then, you just need to load the graph (with its weights) and provide the input for serving i.e. the feature vectors. Once the graph is loaded it is just a function f(x) where x is the feature vector and f is the function of the graph. There is no use for the loss at this stage as the optimization process is over. There are several ways you can provide tensorflow graph with features. One common option is with GRPC, where you feed the model with features that are organized as google protobuf structure. You can't change loss or optimizer for the inference part, as they are only relevant to the training and optimization.
