[site]: crossvalidated
[post_id]: 394741
[parent_id]: 394722
[tags]: 
Does Batch Normalization Introduce non linearity into the Neural Network? Well $f(\{x\}) = \frac{\{x\}-\mu(\{x\})}{std{(\{x\})}}$ is definitely not a linear function. Does Batch Normalization help the network in any way other than keeping the weights alive? I think you probably mean that it keeps the gradients alive, not the weights. The answer to this is yes, it also acts as regularization.
