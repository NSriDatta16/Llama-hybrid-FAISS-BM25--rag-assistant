[site]: crossvalidated
[post_id]: 522345
[parent_id]: 
[tags]: 
RNN Sequence Prediction - Am I Introducing Leakage?

I am training an LSTM for sequence prediction where the targets are either 0 or 1 and I am currently using a sequence length of $20$ . I have done extensive feature engineering so I have 61 input features of length $20$ , used to make 1-step forecasts (i.e. predict either $0$ or $1$ at $T = 21$ ). Initially I removed the targets from the training data and results were poor but I recently introduced them to the training data and now achieve surprisingly high accuracy for such a task (60%+). My question is, am I introducing data leakage? In theory it doesn't seem an issue because I am using the data at time steps from $T = 1, ..., 20$ to predict if the value at $T = 21$ is either $0$ or $1$ . However, the high results have me suspicious that the LSTM is maybe remembering the targets and overfitting because the targets are in the train data. I think of this as a time series prediction problem where the values at time $t$ are thought of as a linear combination of previous values, hence my logic it should be fine. What do you all think?
