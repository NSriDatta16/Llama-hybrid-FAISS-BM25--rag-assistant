[site]: crossvalidated
[post_id]: 85866
[parent_id]: 
[tags]: 
Why does nobody use the Bayesian multinomial Naive Bayes classifier?

So in (unsupervised) text modeling, Latent Dirichlet Allocation (LDA) is a Bayesian version of Probabilistic Latent Semantic Analysis (PLSA). Essentially, LDA = PLSA + Dirichlet prior over its parameters. My understanding is that LDA is now the reference algorithm and is implemented in various packages, while PLSA should not be used anymore. But in (supervised) text categorization, we could do exactly the same thing for the multinomial Naive Bayes classifier and put a Dirichlet prior over the parameters. But I don't think I have ever seen anyone do that, and the "point estimate" version of multinomial Naive Bayes seems to be the version implemented in most packages. Is there any reason for that?
