[site]: crossvalidated
[post_id]: 11077
[parent_id]: 10167
[tags]: 
The following are just a few points: If you have departure from normality then bootstrapping is often a good idea. You mention using "1000" replicates. Increasing the number of replicates increases computational time and accuracy. Thus, sometimes when first setting up your model, you'll set the number of replicates at a level that is relatively quick to run. However, for your final model that you report, you may want to push up the number of replicates to 10,000 or more. If the departure of your data from normality is mild, then coefficient and model fit tests that assume normality are often a reasonable approximation. In particular when you have a big sample, as is often the case with structural equation modelling, assumption tests that perform a significant test with the null hypothesis as normality often are overly sensitive for the purpose of deciding whether to persist with methods that assume normality. I would pay more attention to the actual indices of non-normality like skewness and kurtosis values (or if your intuition is sufficiently trained, check out histograms of the variables). If the departure from normality is mild, I would expect that both standard and bootstrapped approaches should yield similar results. Showing that your results are robust to such analytic decisions may provide you with greater confidence in your results.
