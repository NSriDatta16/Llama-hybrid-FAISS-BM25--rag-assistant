[site]: crossvalidated
[post_id]: 342371
[parent_id]: 
[tags]: 
can a word embedding encode two concepts in an order?

This question is from a homework in the Sequence Models course taught by Andrew Ng on Coursera (this is not related to a homework problem per se, just for general edification). See the screenshot below where the homework was describing cosine similarity. I was a little confused about the example to the right, where "France - Paris" and "Rome - Italy" were taken to be nearly opposites because one is country-city and the other is city-country. Can an embedding really encode two different concepts with an "ordering" like this, or is this just a very contrived example?
