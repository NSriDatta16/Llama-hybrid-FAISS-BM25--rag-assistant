[site]: crossvalidated
[post_id]: 320062
[parent_id]: 
[tags]: 
Difference between logistic regression models for classification problems

In various papers, I had often seen the logistic regression model for classification problems written in two forms. $$p(y =\pm1|\mathbf{x},\mathbf{w}) = \sigma(y\mathbf{w}^{T}\mathbf{x}) = \frac{1}{1+\exp(-y\mathbf{w}^T\mathbf{x})} \tag 1$$ and $$p(y =1|\mathbf{x},\mathbf{w}) = \sigma(\mathbf{w}^{T}\mathbf{x}) = \frac{1}{1+\exp(-\mathbf{w}^T\mathbf{x})} \tag 2$$ The first form has the label being multiplied to the dot product of $\mathbf{w}$ and $\mathbf{x}$ and the second doesn't. Are both the forms are equivalent? If not, how do they differ? References: Minka, T.P. (2003). Algorithms for maximum likelihood logistic regression ( pdf ) Abu-El-Haija, S. Derivation of logistic regression ( pdf )
