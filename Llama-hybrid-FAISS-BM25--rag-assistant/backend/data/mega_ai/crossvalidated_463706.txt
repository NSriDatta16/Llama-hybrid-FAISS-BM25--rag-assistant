[site]: crossvalidated
[post_id]: 463706
[parent_id]: 
[tags]: 
Are Neural Networks Mixture Models?

To my understanding, Gaussian Mixture models are a set of parameterized gaussian distributions that collectively describe an entire, aggregate distribution. ^ from McGonagle et al Also to my understanding, in a neural network classifier with 1 hidden layer, you have a mixture of functions (sigmoids, relus, etc) that are aggregated into a function that produces a high value for things that belong to a given class (cars, planes, etc) ^ a neural network with 5 sigmoid hidden nodes So my question is: do neural networks fall in the general domain of mixture models? If so, why are they never referred to as such? If not, how come? Is it because they don't use probability distributions per se (even though a sigmoid looks a lot like the cumulative density function of a gaussian) Just curious; thanks for any advice
