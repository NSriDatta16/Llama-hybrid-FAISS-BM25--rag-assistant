[site]: crossvalidated
[post_id]: 340239
[parent_id]: 319923
[tags]: 
This is just a hunch (I'm pretty new to ML and computer science) but I would say it is related to how the tensors are actually processed in the computer architecture (Particularly GPU architecture). For example I believe that it is recommended to have mini-batch sizes related to powers of 2: "Some kinds of hardware achieve better runtime with speciÔ¨Åc sizes of arrays. Especially when using GPUs, it is common for power of 2 batch sizes to offer better runtime. Typical power of 2 batch sizes range from 32 to 256, with 16 sometimes being attempted for large models." - Deep Learning book by Goodfellow et al.
