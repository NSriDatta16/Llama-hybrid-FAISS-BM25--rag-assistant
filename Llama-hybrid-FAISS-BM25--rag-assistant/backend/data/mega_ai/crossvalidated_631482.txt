[site]: crossvalidated
[post_id]: 631482
[parent_id]: 532215
[tags]: 
From a machine learning standpoint, you may not touch your test set until the last step of your analyses where you measure your performance . Your two-phased training is a clear example of information leakage . I believe you can combine both models into a single framework where you "ignore" your random effects in the regularization part of your loss function. This is already supported in glmnet . Note: Posted links are not necessarily the best reference. They are simply my first Google hits.
