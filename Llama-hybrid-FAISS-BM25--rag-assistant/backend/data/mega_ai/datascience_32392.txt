[site]: datascience
[post_id]: 32392
[parent_id]: 
[tags]: 
GAN to generate a custom image does not work

I have been training a GAN in the cloud for some time now. I use Google's free credit. My laptop with a CPU doesn't seem to be up to the task. The image I want to generate is this. Even though the number of epochs is about 15000 I don't get anything close to the original. This is the main code. I don't claim to fully understand the deep layers. It took a few days to even write this code. The rest of the code is boilerplate to train. There is no compilation error and I look at the images using TensorBoard. The output from the generator is (1024,1024) images. Should this be the same as my original which is a (299,299) images. Should I calculate using formulas how each layer transforms the image to understand it better ? How do I fix this ? I have mixed and matched API's just to create a working example assuming that doesn't create any problem. X = tf.placeholder(tf.float32, shape=[None, 299, 299, 1], name='X') Z = tf.placeholder(dtype=tf.float32, shape=(None, 100), name='Z') is_training = tf.placeholder(dtype=tf.bool,name='is_training') keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob') keep_prob_value = 0.6 def generator(z,reuse=False, keep_prob=keep_prob_value,is_training=is_training): with tf.variable_scope('generator',reuse=reuse): linear = tf.layers.dense(z, 1024 * 8 * 8) linear = tf.contrib.layers.batch_norm(linear, is_training=is_training,decay=0.88) conv = tf.reshape(linear, (-1, 128, 128, 8)) out = tf.layers.conv2d_transpose(conv, 64,kernel_size=4,strides=2, padding='SAME') out = tf.layers.dropout(out, keep_prob) out = tf.contrib.layers.batch_norm(out, is_training=is_training,decay=0.88) out = tf.nn.leaky_relu(out) out = tf.layers.conv2d_transpose(out, 32,kernel_size=4,strides=2, padding='SAME') out = tf.layers.dropout(out, keep_prob) out = tf.contrib.layers.batch_norm(out, is_training=is_training,decay=0.88) out = tf.layers.conv2d_transpose(out, 1,kernel_size=4,strides=2, padding='SAME') out = tf.layers.dropout(out, keep_prob) out = tf.contrib.layers.batch_norm(out, is_training=is_training,decay=0.88) print( out.get_shape()) out = tf.nn.leaky_relu(out) tf.nn.tanh(out) return out def discriminator(x,reuse=False, keep_prob=keep_prob_value): with tf.variable_scope('discriminator',reuse=reuse): out = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], padding='SAME') out = tf.layers.dropout(out, keep_prob) out = tf.nn.leaky_relu(out) out = tf.layers.max_pooling2d(out, pool_size=[2, 2],padding='SAME', strides=2) out = tf.layers.conv2d(out, filters=64, kernel_size=[3, 3], padding='SAME') out = tf.layers.dropout(out, keep_prob) out = tf.nn.leaky_relu(out) out = tf.layers.max_pooling2d(out, pool_size=[2, 2],padding='SAME', strides=2) out = tf.layers.dense(out, units=256, activation=tf.nn.leaky_relu) out = tf.layers.dense(out, units=1, activation=tf.nn.sigmoid) return out GeneratedImage = generator(Z) DxL = discriminator(X) DgL = discriminator(GeneratedImage, reuse=True)
