[site]: stackoverflow
[post_id]: 5143009
[parent_id]: 5130808
[tags]: 
My interpretation of your question: Given two very long, noisy time series, find a shift of one that matches large 'bumps' in one signal to large bumps in the other signal. My suggestion: interpolate the data so it's uniformly spaced, rectify and smooth the data (assuming the phase of the fast oscillations is uninteresting), and do a one-point-at-a-time cross correlation (assuming a small shift will line up the data). import numpy from scipy.ndimage import gaussian_filter """ sig1 and sig 2 are assumed to be large, 1D numpy arrays sig1 is sampled at times t1, sig2 is sampled at times t2 t_start, t_end, is your desired sampling interval t_len is your desired number of measurements """ t = numpy.linspace(t_start, t_end, t_len) sig1 = numpy.interp(t, t1, sig1) sig2 = numpy.interp(t, t2, sig2) #Now sig1 and sig2 are sampled at the same points. """ Rectify and smooth, so 'peaks' will stand out. This makes big assumptions about your data; these assumptions seem true-ish based on your plots. """ sigma = 10 #Tune this parameter to get the right smoothing sig1, sig2 = abs(sig1), abs(sig2) sig1, sig2 = gaussian_filter(sig1, sigma), gaussian_filter(sig2, sigma) """ Now sig1 and sig2 should look smoothly varying, with humps at each 'event'. Hopefully we can search a small range of shifts to find the maximum of the cross-correlation. This assumes your data are *nearly* lined up already. """ max_xc = 0 best_shift = 0 for shift in range(-10, 10): #Tune this search range xc = (numpy.roll(sig1, shift) * sig2).sum() if xc > max_xc: max_xc = xc best_shift = shift print 'Best shift:', best_shift """ If best_shift is at the edges of your search range, you should expand the search range. """
