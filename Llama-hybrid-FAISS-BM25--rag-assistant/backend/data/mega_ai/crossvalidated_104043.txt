[site]: crossvalidated
[post_id]: 104043
[parent_id]: 
[tags]: 
How to deal with outlier in the experiment

My question is related to this one . I'm working on an experiment involving transferring data between different locations all over the world via the Internet. As the Internet can be busy, sometimes it takes longer to transfer the same amount of data than the other times. The difference can be significant, e.g. for the 1mb of data, it normally takes 2 seconds to transfer, but occasionally (around 1 out of 20 times), it can take up to 20 seconds or more. I am comparing different setups for the same problem. For each one, I perform multiple times and get the average result, i.e. time to solve the problem. However, as outlier can happen at one setup but not on another, my comparison is affected. So, at the moment, for each setup, I perform M times but only get the average of N of the smallest results (N So, my question is whether my method is acceptable and if it makes my paper less reliable. I'm also interested in how experimental outlier is handled in general. I'm working in CS but answers from other fields are welcome.
