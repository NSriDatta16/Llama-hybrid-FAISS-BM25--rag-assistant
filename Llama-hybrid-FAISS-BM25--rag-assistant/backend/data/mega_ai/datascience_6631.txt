[site]: datascience
[post_id]: 6631
[parent_id]: 
[tags]: 
Alignment of square nonorientable images/data

Another post where I don't know enough terminology to describe things efficiently. For the comments, please suggest some tags and keywords I can add to this post to make it better. Say I have a 2D data structure where 'orientation' doesn't matter. The examples I ran into: The state of a 2048 game. In terms of symmetry groups this would be D 4 / D 8 , except that an operation doesn't yield an identical state, it just yields another state that has the same solution. Images of plankton or galaxies (without background). Somewhat similar to above except that any rotation (not just 90 o ) yields an equally valid image (and one might take scale into account, but let's forget about that). In both cases I've wanted to transform all these equivalent states/images to remove all but one of the equivalent images. To illustrate with two that worked: I can use image moments M 10 and M 01 to transform horizontally and vertically mirrored equivalent data. E.g. apply horizontal mirroring iff it makes M 10 bigger. This would transform a 2048 state and it's horizontal mirror image to the same state. I can use the eigenvector of the covariance matrix which has the largest eigenvalue as the orientation. Then I can rotate the image to align this eigenvector with some predetermined axis (e.g. horizontally). That still leaves a lot of operations though (diagonal mirroring, rotations around the center, inversion). And these operations do not commute (D 8 is non-Abelian). Is there any comprehensive approach? The reason I want to do this is to help machine learning methods by removing variance that isn't actually meaningful. Hopefully that makes sure they don't have to learn these equivalences, so possibly need less train data (and time).
