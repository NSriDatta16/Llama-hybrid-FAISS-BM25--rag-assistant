[site]: crossvalidated
[post_id]: 277795
[parent_id]: 
[tags]: 
Matching moments in Gaussian Mixtures

Consider $$q^{\backslash n}(\theta) = \mathcal{N}(\theta | m^{\backslash n},v^{\backslash n}I)$$ and $$f_n(\theta) = (1-w)\mathcal{N}(x_n | \theta,I) + w\mathcal{N}(x_n|0,aI)$$ Then let $$\hat{P}(\theta) = q^{\backslash n}(\theta)f_n(\theta) = (1-w)\mathcal{N}(x_n | m^{\backslash n},(v^{\backslash n}+1)I)\mathcal{N}(\theta | \mu, \Sigma) + w\mathcal{N}(x_n|0,aI)\mathcal{N}(\theta | m^{\backslash n},v^{\backslash n}I)$$ where $$\mu = \frac{1}{v^{\backslash n}+1}m^{\backslash n} + \frac{v^{\backslash n}}{v^{\backslash n}+1}x_n$$ and $$\Sigma = \frac{v^{\backslash n}}{v^{\backslash n}+1}I$$ This problem is in the Exercise 10.39 of Pattern Recognition and Machine Learning (by Chris Bishop). Let $P(\theta) = \frac{1}{Z_n}\hat{P}(\theta)$ where $Z_n$ is the partition function. I wonder how we obtained the mean of $\theta$ (equation 10.244 in the book), which is $$\mathrm{E}_{p(\theta)}[\theta] = m^{\backslash n} + v^{\backslash n}\nabla_{m^{\backslash n}}\ln Z_n.$$
