[site]: datascience
[post_id]: 67298
[parent_id]: 
[tags]: 
Q learning for blackjack, reward function?

I am currently learning reinforcement learning and am have built a blackjack game. There is an obvious reward at the end of the game (payout), however some actions do not directly lead to rewards (hitting on a count of 5), which should be encouraged, even if the end result is negative (loosing the hand). My question is what should the reward be for those actions ? I could hard code a positive reward (fraction of the reward for winning the hand) for hits which do not lead to busting, but it feels like I am not approaching the problem correctly. Also, when I assign a reward for a win (after the hand is over), I update the q-value corresponding to the last action/state pair, which seems suboptimal, as this action may not have directly lead to the win. Another option I thought is to assign the same end reward to all of the action/state pairs in the sequence, however, some actions (like hitting on count Note: My end goal is to use deep-RL with an LSTM, but I am starting with q-learning.
