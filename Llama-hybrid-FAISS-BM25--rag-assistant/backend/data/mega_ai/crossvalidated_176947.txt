[site]: crossvalidated
[post_id]: 176947
[parent_id]: 
[tags]: 
Setting random seed for neural network

I'm training a neural network for a particular problem which can be predicted with 100% accuracy. However, the problem is that results tend to vary between 99% and 100% even if I train 10 different networks and take the average. I was reading around and found that it was due to random weights initialized every time the program ran. Is it okay to set the random seed to 1 and then train 10 different networks and take the average? This will result in less variation and easy model selection.
