[site]: crossvalidated
[post_id]: 117199
[parent_id]: 114385
[tags]: 
All of these architectures can be interpreted as a neural network. The main difference between AutoEncoder and Convolutional Network is the level of network hardwiring. Convolutional Nets are pretty much hardwired. Convolution operation is pretty much local in image domain, meaning much more sparsity in the number of connections in neural network view. Pooling(subsampling) operation in image domain is also a hardwired set of neural connections in neural domain. Such topological constraints on network structure. Given such constraints, training of CNN learns best weights for this convolution operation (In practice there are multiple filters). CNNs are usually used for image and speech tasks where convolutional constraints are a good assumption. In contrast, Autoencoders almost specify nothing about the topology of the network. They are much more general. The idea is to find good neural transformation to reconstruct the input. They are composed of encoder (projects the input to hidden layer) and decoder (reprojects hidden layer to output). The hidden layer learns a set of latent features or latent factors. Linear autoencoders span the same subspace with PCA. Given a dataset, they learn number of basis to explain the underlying pattern of the data. RBMs are also a neural network. But interpretation of the network is totally different. RBMs interpret the network as not a feedforward, but a bipartite graph where the idea is to learn joint probability distribution of hidden and input variables. They are viewed as a graphical model. Remember that both AutoEncoder and CNN learns a deterministic function. RBMs, on the other hand, is generative model. It can generate samples from learned hidden representations. There are different algorithms to train RBMs. However, at the end of the day, after learning RBMs, you can use its network weights to interpret it as a feedforward network.
