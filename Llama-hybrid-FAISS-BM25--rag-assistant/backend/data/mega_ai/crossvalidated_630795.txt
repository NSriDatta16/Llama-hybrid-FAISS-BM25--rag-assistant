[site]: crossvalidated
[post_id]: 630795
[parent_id]: 630787
[tags]: 
Does this mean that given a matched design, one cannot use simple statistics such as a T-test/Anova to compare the different outcome groups, since such methods do not allow for adjusting for the matching factors? Well, a twin design is the perfect example of a matched design not requiring adjustment for the matching factor! In matching - which mind you is different from a case control study - we often adjust for a matching factor for two reasons. Residual confounding - in quasiexperimental designs, we might create "blocks" by age intervals of 10 or 5 years, but as you know a 69 year old is different from a 60 year old by quite a bit. Prognostic value - blocking can remove confounding, but it does not stratify the effect estimates, you can still adjust for the factor and significantly reduce the residual standard error. In fact, a blocked design can increase the residual standard error relative to simple random sampling because you oversample heterogeneous groups! None of any of this applies if there's undetected interactions between factors! A case control study is not a matched study, you're not forced to select a number of cases equal to a number of controls to ensure valid design or inference. You can sample controls in a ratio of 1:1, 2:1, 10:1, or in any fashion as long as it doesn't depend on the covariates at all . The power of logistic regression is that the effect estimate, the odds ratio, does not depend on the background frequency of the event and is thus consistent with measurements from longitudinal studies (i.e. where outcome dependent sampling has not occurred). Add to that, in the situation where the event is rare, the odds ratio approximates the risk ratio in a prospective design (another term for a study where outcome dependent sampling has not occurred). Matching in case control designs still begs for adjustment due to the same reasons above.
