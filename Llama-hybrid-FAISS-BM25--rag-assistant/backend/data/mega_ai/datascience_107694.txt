[site]: datascience
[post_id]: 107694
[parent_id]: 15236
[tags]: 
While I am somewhat hesitant to answer, given that I consider myself a beginner, I think I have something to offer so will do my best. I’ve been working my way up the learning curve for the past year and a half and have built my own Feed Forward Fully Connected and Convolutional network solver so not an absolute beginner. OK, so here’s my input to the question. While it is true that CNNs offer some translation invariance, the issue the OP is facing will not be addressed properly by simply feeding a big image with a dog somewhere in the image when the CNN was trained on closely cropped images. The OPs intuition is correct, there is a preprocessing stage. This is about the extent of my knowledge and am also on a course to learn about these techniques. Look up R-CNN (Regions with CNN Features) networks. There are various techniques, one is called segmentation. The image is segmented into smaller sections and various computer vision techniques such as HOG (histogram of gradients) are used to make a “weak” estimation about weather the section is a Region of Interest (ROI), i.e. contains an object of interest. Each of these regions is passed to a trained CNN to determine weather an object it is trained on is in the image. Apparently, the original R-CNN network would pass on average 2000 ROIs to find one object. Faster R-CNN made improvements.
