[site]: datascience
[post_id]: 65491
[parent_id]: 14914
[tags]: 
There seem to be two central issues: The errors increased after you transformed the variables using PCA - PCA creates components from the predictors, and has no relation to the target. This is important because the component describing most of the variance data (the top component of PCA) may not be a great predictor. Chances are if you are using that component, your model might be worse off and you will see an overall increase in error. I would suggest using some other method, like Random Forest or GBM, to find the variable importance of the components wrt to the predictor variable. Training error is greater than validation error - Either your model is underfitting to the data or your validation data has some easy example wrt the model. For the first case, maybe drop the regularization on your linear regression. For the second case, use cross-fold validation to get better error estimates.
