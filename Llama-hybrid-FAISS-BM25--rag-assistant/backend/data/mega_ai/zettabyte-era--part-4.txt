aling with large data-flow in the Zettabyte Era, in 2008 Cisco unveiled a new router, the Aggregation Services Router (ASR) 9000, which at the time was supposed to be able to offer six times the speed of comparable routers. In one second the ASR 9000 router would, in theory, be able to process and distribute 1.2 million hours of DVD traffic. In 2011, with the coming of the Zettabyte Era, Cisco had continued work on the ASR 9000 in that it would now be able to handle 96 terabytes a second, up significantly from 6.4 terabytes a second the ASR 9000 could handle in 2008. Data centers Energy consumption Data centers attempt to accommodate the ever-growing rate at which data is produced, distributed, and stored. Data centers are large facilities used by enterprises to store immense datasets on servers. In 2014 it was estimated that in the U.S. alone there were roughly 3 million data centers, ranging from small centers located in office buildings to large complexes of their own. Increasingly, data centers are storing more data than end-user devices. By 2020 it is predicted that 61% of total data will be stored via cloud applications (data centers) in contrast to 2010 when 62% of data storage was on end-user devices. An increase in data centers for data storage coincides with an increase in energy consumption by data centers. In 2014, data centers in the U.S. accounted for roughly 1.8% of total electricity consumption which equates to 70 billion kWh. Between 2010 and 2014 an increase of 4% was attributed to electricity consumption by data centers, this upward trend of 4% is predicted to continue through 2014–2020. In 2011, energy consumption from all data centers equated to roughly 1.1% to 1.5% of total global energy consumption. Information and communication technologies, including data centers, are responsible for creating large quantities of CO2 emissions. Google's green initiatives The energy used by data centers is not only to power their servers. In fact, most data centers use about half of their energy costs on non-computing energy such as cooling and power conversion. Google's data centers have been able to reduce non-computing costs to 12%. Furthermore, as of 2016, Google uses its artificial intelligence unit, DeepMind, to manage the amount of electricity used for cooling their data centers, which results in a cost reduction of roughly 40% after the implementation of DeepMind. Google claims that its data centers use 50% less energy than ordinary data centers. According to Google's Senior Vice President of Technical Infrastructure, Urs Hölzle, Google's data centers (as well as their offices) will have reached 100% renewable energy for their global operations by the end of 2017. Google plans to accomplish this milestone by buying enough wind and solar electricity to account for all the electricity their operations consume globally. The reason for these green-initiatives is to address climate change and Google's carbon footprint. Furthermore, these green-initiatives have become cheaper, with the cost of wind energy lowering by 60% and solar energy coming down 80%. In order to improve a data center's energy efficiency, reduce costs and lower the impact on the environment, Google provides 5 of the best practices for data centers to implement: Measure the Power Usage Effectiveness (PUE), a ratio used by the industry to measure the energy used for non-computing functions, to track a data center's energy use. Using well-designed containment methods, try to stop cold and hot air from mixing. Also, use backing plates for empty spots on the rack and eliminate hot spots. Keep the aisle temperatures cold for energy savings. Use free cooling methods to cool data centers, including a large thermal reservoir or evaporating water. Eliminate as many power conversion steps as possible to lower power distribution losses. The Open Compute Project In 2010, Facebook launched a new data center designed in such a way that allowed it to be 38% more ef