[site]: crossvalidated
[post_id]: 251748
[parent_id]: 251450
[tags]: 
On the issue of model priors: It is usually impossible to assign a specific prior to each of the $2^p=K$ models, where $p$ is the number of predictors. A conventional way to go about this problem is to elicit a non-informative prior to the models as it is hard to know anything specific about the model space. However, if you are certain about the probability inclusion of some variables then it is possible to convey this information in the set up. The idea is to decentralise prior mass such that the MCMC can discover the majority of all good models. An example of a conventional set up for the model prior is as follows: $\textrm{for}\quad M_k\in\mathcal{M} \quad \textrm{let} \quad M_k\sim{}Bin(p,\phi)\quad \textrm{where} \quad \phi\sim{}Beta(a,b) $ By letting $a=1$ you get $b=\frac{p-\mathbb{E}(M_k)}{\mathbb{E}(M_k)}$, thus one has only to specify the expected prior models size, although one wants this expectation to carry as little influence as possible. You can use a tessellation model prior and a ridge prior for the coefficients if your design matrix is singular, that way you'll avoid centring prior mass around bad models, making it easier for the MCMC to discover good models.
