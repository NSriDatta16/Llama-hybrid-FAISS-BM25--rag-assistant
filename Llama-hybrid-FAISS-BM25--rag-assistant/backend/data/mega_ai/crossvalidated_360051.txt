[site]: crossvalidated
[post_id]: 360051
[parent_id]: 
[tags]: 
Why don't GAN generators vastly overfit?

It seems that, if the GAN generator is simply mapping noise to a value which should be as indistinguishable as possible for the discriminator from the real data, the generator could simply learn to map all noise to a single (or perhaps a handful) of real examples. For instance, in the image classification task, what stops a GAN generator from ignoring (through close-to-zero weights) the noise it receives and then mapping to a single image of a "9" every time?
