[site]: crossvalidated
[post_id]: 327897
[parent_id]: 327864
[tags]: 
One classic method for linking text documents uses cosine similarity on TF-IDF features. A simple way to extend this would be to use Doc2Vec or similar document embeddings instead of TF-IDF - cosine similarity of word/document embeddings captures semantic similarity (some people might point out that word embeddings aren't technically deep learning, but I think that author might find these methods useful). Second approach is to try to learn distance function that corresponds to item dissimilarity. This is analogous to record linkage method that uses TF-IDF features (use of distance function is analogous to cosine similarity in this model). Siamese networks can be used to learn such distance functions. They are essentially networks that given two examples return their similarity/dissimilarity. "Siamese" comes from the use of shared weights for hidden layers (they encode both inputs in the same way). Here you can see an example talk on using Siamese Networks for similar task. If you want to read further on Siamese Networks I encourage you to look up One Shot Learning, which is somewhat similar to record linkage.
