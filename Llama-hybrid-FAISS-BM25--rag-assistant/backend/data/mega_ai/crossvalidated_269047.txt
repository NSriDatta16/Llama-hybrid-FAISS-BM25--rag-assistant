[site]: crossvalidated
[post_id]: 269047
[parent_id]: 269032
[tags]: 
The practice of using the scores of the PCA model (the lower-dimensional variables you can get from PCA) is known as Principal Component Regression (PCR). One shortcoming of PCR is that the transformation matrix that converts the data from its original form to an orthogonal space (the loadings), from which you can select a small number of relevant ones to reduce the dimensonality, is that these loadings are estimated to maximize the variance of the new, orthogonal variables. This ignores the relationship between these variables and the response in your regression problem. Here is a description of how to perform PCR in R. An alternative is to use Partial Least Squares (PLS). This procedure searches for loadings that give you a dataset of orthogonal variables that are also highly correlated with the response. In a nutshell, you get dimensionality reduction and the latent variables you pick are usually more powerful predictors of your response than the variables from PCR. There is a PLS package for R, though it has limited functionality. Both PLS and PCA can create problems of interpretation since they transform your original data into new variables. If you are not comfortable interpreting these transformations and have many variables, you could try a variable selection procedure. LASSO is quite popular. One method that I have found useful recently while working with high-dimensional data where I want flexibility and interpretability is MARS, which is implemented in the R package earth . This method will perform variable selection for you, and the results are interpretable almost like in linear regression. However, the models it fits are flexible since they are piecewise linear, which may be too unconstrained for your problem.
