[site]: datascience
[post_id]: 56465
[parent_id]: 
[tags]: 
How to determine which type of layer one should use?

Considering the SRGAN, I found it amazingly difficult to find logic on how this architecture was thought. The first two layers are input layer and 2d convolution layer, whose choice is pretty simple to understand since we want to detect features to scale them. But after, there are what is called "residual blocks" containing PReLU layers, element-wise sum layers, batch normalization layers, and convolution layers... Moreover, another element-wise sum is done after these residual blocks plus some batch normalization and convolution again. How did the author think to use all these types of layers, in this particular order, and what logic does bind these layers? In order to be able to think myself to new architectures and to understand simpler existing ones.
