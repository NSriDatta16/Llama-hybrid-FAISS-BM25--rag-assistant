[site]: crossvalidated
[post_id]: 178199
[parent_id]: 
[tags]: 
Posterior of the linear regression model with g-Prior

Assume a linear model of the form $$Y=X\beta+\epsilon$$ where $\epsilon$ has a multivariate Normal distribution with mean $0_N$ and covariance matrix $\sigma^2 I_N$ . I would like to perform simple of Bayesian inference and using a natural conjugate g -prior for $\beta$ conditional on $h=\sigma^{-2}$ : $$\beta|h \sim N(\underline{\beta},h^{-1}g(X'X)^{-1})\text{ , where } g>0$$ and $$h \sim G(\underline{s}^{-2},\underline{v}).$$ From standard textbooks (e.g. those publicly available slides from Luc Bauwens, p. 115) it is clear that the marginal posterior distribution of $\beta$ is an $N$ -variate $t$ -distribution with parameters (given T observations and letting $\underline{v},\underline{s}\rightarrow0$ ): $$\beta|y \sim t(\overline{\beta},\overline{s^2}\overline{V},T)$$ where $$\overline{\beta}=\frac{1}{1+g}\underline{\beta}+\frac{g}{1+g}{\beta}_\text{OLS}$$ and $$\overline{V}=\frac{g}{1+g}(X'X)^{-1}.$$ However, I do fail in finding an appropriate representation of $\overline{s^2}$ , given $\underline{\beta}\neq0$ . The representation should be $$\overline{s^2}=\frac{1}{T}\left( (Y-X\beta_\text{OLS})'(Y-X\beta_\text{OLS})+\frac{1}{g}(\beta_\text{OLS}-\underline{\beta})'X'X(\beta_\text{OLS}-\underline{\beta})\right)$$ . Can anyone give me a more comprehensive representation of $\overline{s^2}$ that helps me to understand the impact of the chosen prior mean $\underline{\beta}$ onto the posterior variance? I appreciate every comment or idea, thank you=)
