[site]: datascience
[post_id]: 16118
[parent_id]: 16117
[tags]: 
Here is a pretty solid notebook for you to compare with (their random forest yielded 0.98): https://www.kaggle.com/startupsci/titanic/titanic-data-science-solutions/notebook Have you tried adjusting the number of estimators in your random forest model? It looks like you are using 10, but more should help improve the model. Try 100. I get a result which seems good to me (on the training set) the trained model performs bad on the test set Don't base your results on the training set. Your test set is how you assess your model.
