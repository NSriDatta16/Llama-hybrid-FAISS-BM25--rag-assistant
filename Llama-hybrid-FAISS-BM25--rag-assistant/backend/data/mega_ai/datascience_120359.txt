[site]: datascience
[post_id]: 120359
[parent_id]: 
[tags]: 
I used SMOTE-ENN to balance my dataset and it improved the performance metrics, but how can I be sure it's not overfitting?

The models were evaluated using 10-fold cross validation. foldCount = StratifiedKFold(10, shuffle=True, random_state=1) The models in question are XGBoost. xgb = XGBClassifier(verbosity=2, random_state=0, n_estimators=100, max_depth=10, learning_rate=0.35, gpu_id=0, tree_method='gpu_hist', predictor='gpu_predictor') The shape of the dataset is (117k, 34) after preprocessing and feature selection. The dataset was balanced using imblearn's SMOTEENN. from imblearn.combine import SMOTEENN smote_enn = SMOTEENN(random_state=42, sampling_strategy = 'not majority') X_normalized, y = smote_enn.fit_resample(X_normalized, y) Data Before Balancing + Model Performance Data After Balancing (with SMOTE-ENN) + Model Performance
