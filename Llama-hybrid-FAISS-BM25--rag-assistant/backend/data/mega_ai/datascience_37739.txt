[site]: datascience
[post_id]: 37739
[parent_id]: 
[tags]: 
How to choose dimensionality of the Dense layer in LSTM?

I have a task of multi-label text classification. My dataset has 1369 classes: # data shape print(X_train.shape) print(X_test.shape) print(Y_train.shape) print(Y_test.shape) (54629, 500) (23413, 500) (54629, 1369) (23413, 1369) For this task, I've decided to use LSTM NN with the next parameters: # define model maxlen = 400 inp = Input(shape=(maxlen, )) embed_size = 128 x = Embedding(max_features, embed_size)(inp) x = LSTM(60, return_sequences=True,name='lstm_layer')(x) x = GlobalMaxPool1D()(x) x = Dropout(0.1)(x) x = Dense(2000, activation="relu")(x) x = Dropout(0.1)(x) x = Dense(1369, activation="sigmoid")(x) model = Model(inputs=inp, outputs=x) model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'] batch_size = 32 epochs = 2 model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1) Question : Are there any scientific methods for determining Dense and LSTM dimensionality (in my example, LSTM dimension=60 , I Dense dimension=2000 , and II Dense dimension=1369 )? If there are no scientific methods, maybe there are some heuristics or tips on how to do this with data with similar dimension. I randomly chose these parameters. I would like to improve the accuracy of the model and correctly approach to solving similar problems.
