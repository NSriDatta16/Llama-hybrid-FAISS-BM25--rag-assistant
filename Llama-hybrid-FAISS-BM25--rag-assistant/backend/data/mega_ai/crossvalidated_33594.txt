[site]: crossvalidated
[post_id]: 33594
[parent_id]: 
[tags]: 
Combining correlated measurements - negative weights

I'm trying to get the analysis of this (I hope) simple case correct in my head. Lets say I measure the same thing two different ways, on the same set of data. Call these measurements $y_1$ and $y_2$. They have Gaussian errors $s_1$ and $s_2$. But since they are measured on common data, they have a correlation coefficient $\rho$. Say $\rho$ is measured with a toy monte carlo or similar, though I don't think that matters. Just to make sure we are on the same page, this will generate a co-variance matrix that has $s_1^2$ and $\rho s_1s_2$ on the top row, and $\rho s_1 s_2$ and $s_2^2$ along the bottom row. It is easy to calculate a weighted average, $ \bar y$. Under certain circumstances it is possible to find that $y$ is outside the range $y_1, y_2$. This happens, in particular, when $\rho >\frac {s_1}{s_2}$. Since these measurements are on the same data, and are measuring the same thing, this is just not possible. In short, "opps." I must have messed up my measurements of $s_1, s_2$, or $\rho$. I feel comfortable with this. :-) Now, lets say I do exactly as above, but now I take it to the next level and measure a number of systematic errors associated with each method. Say, for the sake of argument, that the systematic errors for method 1 are not correlated with any of the systematic errors for method 2. After thinking about this for a while... well, I'm not entirely sure what to think. Do I have such a neat test to see if I've made a mistake anymore? I actually think I must, as you might imagine that I have systematic errors but they are vanishingly small. So, I can do something like decrease $\rho$ - because they now have uncorrelated error (the systematic error) and then re-run the test. This is pretty straight forward, I think: I use $\rho$ to split the statistical error into a correlated and uncorrelated part, add the uncorrelated parts in quad with the systematic errors, and then re-calculate $\rho$. But does the test still make sense? I fear I'm missing a fundamental concept here or I'd be able to determine what was going on. Things in my current problem domain get arbitrarily complex. I have to combine measurements of the same thing in uncorrelated data sets, but with substantial correlated systematic errors. The procedure I describe just above for adjusting $\rho$ applies here just as well (the statistical error is uncorrelated, but some of the systematic errors will be), but here it seems incorrect. Another clue to my missing fundamental concept. :-) I'd appreciate some help getting my thinking straight.
