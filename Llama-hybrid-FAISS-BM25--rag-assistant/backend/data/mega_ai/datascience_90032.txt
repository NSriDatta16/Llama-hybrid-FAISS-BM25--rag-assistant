[site]: datascience
[post_id]: 90032
[parent_id]: 90005
[tags]: 
I don't know ludwig or even "parallel CNN" but there's a clear problem: this is not a confusion matrix, this is a heat map. A confusion matrix shows the number of instances for every combination of predicted/true label. It's for categorical labels, you could indeed obtain TP/FP/FN/TN classification status from it. A heatmap is for numerical values, as can be seen from the scale on the right side. It's very likely that this heatmap is made of the probabilities of the labels for every instance, rather than the labels themselves (also the choice of colours is unusual but this doesn't matter). The good news is that it appears that most instances which have 0 or 1 as true label are correctly predicted (high value for 1,1 and 0,0). The bad news is that there's an issue in the labels themselves: apparently a large number of instances (at least a third I think) don't have any label and are considered 'UNKNOWN'. And apparently the system just considers these 'UNKNOWN' instances as a third class, so your labels are not binary actually. It manages to recognize this class quite well, but it's probably an issue you should investigate.
