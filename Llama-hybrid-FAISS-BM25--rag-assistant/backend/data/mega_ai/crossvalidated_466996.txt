[site]: crossvalidated
[post_id]: 466996
[parent_id]: 
[tags]: 
On projected gradient descent and inequality constraints

Consider the optimization problem \begin{equation} \min_{x\in\mathbb{R}^n} \quad f(x) \end{equation} using the gradient descent, we can iteratively solve this problem \begin{equation} x^{k+1} = x^k-\eta\nabla f(x^k) \end{equation} Adding a constraint on the problem, \begin{align} \min_{x}& \quad f(x)\\ \text{subject to}& \quad x \in C \end{align} we can use projected gradient descent to solve the problem \begin{equation} y^{k+1} = x^k-\eta\nabla f(x^k) \end{equation} \begin{equation} \DeclareMathOperator*{\argmin}{arg min} x^{k+1} = \argmin_{x\in C} \frac{1}{2}\|y^{k+1}-x\| \end{equation} Question: I was wondering how can I use this to solve the following constrained problem with inequality constraint \begin{align} \min_{x}& \quad f(x)\\ \text{subject to}& \quad G(x) \leq 0 \end{align} Note: I can not solve this by writing in the form of Lagrangian function. The reason is that this is an optimization for a neural network (where $f(x)$ is the loss function and $x$ is the weights of the network) and I'm not able to find the Lagrangian multiplier using this method. About my constraint: The network outputs a graph. The constraint imposes the idea that the sum of weights of edges connected to each node should not exceed the predicted value for that node. e.g. in a molecular graph, sum of the bond orders (for covalent bonds connected to an atom) should not exceed the valency of that atom. It is not immediately clear for me how to attempt finding a feasible set for model parameter based on this constraint. Even pointing to such literature would be much appreciated.
