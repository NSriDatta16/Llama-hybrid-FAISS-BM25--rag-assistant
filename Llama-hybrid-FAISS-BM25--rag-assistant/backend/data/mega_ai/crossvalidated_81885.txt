[site]: crossvalidated
[post_id]: 81885
[parent_id]: 
[tags]: 
How would re-weighting American Community Survey diversity data affect its margins of error?

Background: My organization currently compares its workforce diversity statistics (ex. % persons with disabilities, % women, % veterans) to the total labor force availability for those groups based on the American Community Survey (a surveying project by the US Census Bureau). This is an inaccurate benchmark, because we have a very specific set of jobs that have different demographics than the labor force as a whole. Say, for example, that my organization is mostly engineers. Engineering is only about 20% women in my state. If we compare ourselves to the total labor force benchmark, which is more like of 50% women, it results in panic that “we only have 20% women, this is a disaster!” when really, 20% is what we should be expecting because that’s what the labor landscape looks like. My goal: What I would like to do is take the American Community Survey occupation data (by diversity category) and re-weight it based on the composition of jobs in my business. Here is a sample data set for Social and Community Service workers . I want to add these job codes listed together (because our crosswalk is to job groups, not to specific job codes), then I want to weight that benchmark based on the number of people we have in that category (ex. our 3,000 Social and Community Service workers), then I want to do the same to all the other job groups, add those numbers together, and divide by our total number of workers. This would give me a new re-weighted diversity measure (ex. from 6% persons with a disability to 2% persons with a disability). My questions: How do I fit margins of error to this final rolled up benchmark? I do not have the raw census data set (obviously), but you can view margins of error for each number in the link that I provided by toggling the “Estimate” field to "Margin of Error" at the top of the table. My other co-workers who are working with this data fully intend to ignore the margins of error, but I am worried that we are creating a statistically meaningless benchmark for ourselves. Is this data even still usable after the manipulation described above?
