[site]: crossvalidated
[post_id]: 448900
[parent_id]: 
[tags]: 
Problems with using Gibbs Sampling for Bayesian DAGs

Assume we want to sample from the variables of Bayesian belief network, which is a Directed Acyclic Graph (DAG), where we observe some of the variables, and do not observe the others. We can usually do Gibbs sampling since the probability of a variable conditional on the others can be easily computed. However, I am asked: When is using Gibbs sampling to simulate from a DAG given the observed values at a subset of nodes is not appropriate? Can you see the reason? I believe this has to be something about the convergence of Markov chain, but I can't see why. Is it because when we know some of the variables it can result in the underlying Markov chain not to be stable? We know that the limit exists when the underlying chain is aperiodic, so maybe when we fix some observed variables we have periods. One explanation I have is: suppose a variable has many parent nodes, and no child. It will take too much time for this node to change its state since at each step we change only one variable and this will have too little effect considering that this node has a lot of parent nodes...
