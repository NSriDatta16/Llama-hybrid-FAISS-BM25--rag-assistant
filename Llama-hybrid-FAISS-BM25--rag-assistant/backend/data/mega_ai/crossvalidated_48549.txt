[site]: crossvalidated
[post_id]: 48549
[parent_id]: 48547
[tags]: 
In my experience, when the neural network ends up with all zeros at the output, it is likely that the rails are being saturated. That is that the common sigmoid function processing element will only swing to 0 or +1 limits and if the input happens to be far outside of the linear input sensitivity threshold range, it will force the sigmoid to stick at one of the output levels. You could check if all of the inputs are limited to a small range (say -1 to 1) or force them to be limited by using a transformation, such as a scaling or normalization of data. And do not use raw price, but an approximately stationary transformation such as log returns. There is a simple tutorial on this blog , but keep in mind it is using Weka, a java based GUI.
