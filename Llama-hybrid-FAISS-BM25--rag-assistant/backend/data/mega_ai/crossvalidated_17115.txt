[site]: crossvalidated
[post_id]: 17115
[parent_id]: 17106
[tags]: 
By definition, an inefficient estimator will have larger risk for quadratic losses. Under some additional assumptions and simplifications, I suppose one might equate larger risk with inadmissibility, which would imply there is no need ever to use inefficient estimators, because there are uniformly superior estimators available. Better accounts of frequentist inference eschew such assumptions and focus on admissibility, leaving it to the user to choose an appropriate loss function and compare risk functions among the available admissible estimators. This unifies frequentist and Bayesian theory (there's nothing in the frequentist theory that precludes adopting a prior probability and in fact many admissible procedures have been discovered by doing precisely that) and allows for minimax estimation as well. As a practical matter, as you surely know, one can equate loss of efficiency with cost of data collection: to achieve a given power in a study where the variance of the estimator scales like $1/n$, a reduction in efficiency by a factor $t \lt 1$ typically requires collecting $1/t$ times as much data. For example, the statistician who can find an estimator that is twice as efficient as one proposed by a client has ( caeteris paribus ) just halved the cost of the client's data collection. There are subtleties involving asymptotic efficient estimators. For example, an AEE can be inefficient for all finite values of $n$. But I hope your question isn't bearing on this issue.
