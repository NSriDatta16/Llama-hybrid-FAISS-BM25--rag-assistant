[site]: crossvalidated
[post_id]: 465982
[parent_id]: 
[tags]: 
Gradient in Convolutional Layer

I have a convolutional neural network that operates on $4$ -tensors. I'm trying to calculate the gradient w.r.t. the 4-dimensional filter, i.e. $\frac{\partial E}{\partial f}$ , given the gradient w.r.t. the following layer, $\frac{\partial E}{\partial y}$ . The dimensional compatibility is as follows: $$x\,(N, H, W, C_{\text{in}}) \,\ast\, f\,(F_h, F_w, C_{\text{in}}, C_{\text{out}}) \rightarrow y\,(N, \frac{H-F_h}{S},\,\frac{W-F_w}{S}, C_{\text{out}}),$$ where $N$ is the batch size. I was getting a bit caught up in the tensor notation and summation for $\frac{\partial E}{\partial f}$ , so I decided to tackle it by dimensional analysis - I had read that all boils down to another convolution between $x$ and $\frac{\partial E}{\partial y}$ . If you want some concrete values for the dimensions, here they are: $$(64, 28, 28, 1) \ast (3, 3, 1, 2) \rightarrow (64, 26, 26, 2)$$ What I ended up with was this: $$x^T\,(1, 28, 28, 64)\,\ast\,\frac{\partial E}{\partial y_{2103}}\,(26, 26, 64, 2) \rightarrow f_{2103}\,(1, 3, 3, 2)$$ This does give the right dimensions, but it doesnt seem to generalise to strided convolutions. Could someone please guide me towards a solution here?
