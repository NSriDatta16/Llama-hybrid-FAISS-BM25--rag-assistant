[site]: datascience
[post_id]: 8660
[parent_id]: 
[tags]: 
Transforming AutoEncoders

I've just read Geoff Hinton's paper on transforming autoencoders Hinton, Krizhevsky and Wang: Transforming Auto-encoders . In Artificial Neural Networks and Machine Learning, 2011. and would quite like to play around with something like this. But having read it I couldn't get enough detail from the paper on how I might actually implement it. Does anyone know how the mapping between input pixels to capsules should work? What exactly should be happening in the recognition units? How it should be trained? Is it just standard back prop between every connection? Even better would be a link to some source code for this or something similar.
