[site]: crossvalidated
[post_id]: 580939
[parent_id]: 580320
[tags]: 
It is typical practice that the sample size is considered (implicitly) to be a known constant unless we specify the contrary in the analysis . This practice saves time by alleviating the need to specify that the sample size is known, which is true in the vast majority of statistical applications. You can of course proceed on the basis that $n$ is also an unknown parameter in the model. In this latter case your log-likelihood function would be: $$\ell_{\mathbf{x}_n}(n,\theta) = \log {n \choose T(\mathbf{x}_n)} + T(\mathbf{x}_n) \log(\theta) + (n-T(\mathbf{x}_n)) \log(1-\theta),$$ and the minimal sufficient statistic is indeed $(n,T(\mathbf{x}_n))$ (so the statistic $T(\mathbf{x}_n)$ is not sufficient in this case). (Note: I do not agree with the comment by Xi'an asserting that $n$ must be the outcome of a random variable to be included as part of the sufficient statistic; the concept of sufficiency is a classical concept, and in that domain the notion of an "unknown constant" is perfectly valid. There is no need to create a Bayesian model that specifies a distribution for $n$ in order for it to be part of the sufficient statistic.)
