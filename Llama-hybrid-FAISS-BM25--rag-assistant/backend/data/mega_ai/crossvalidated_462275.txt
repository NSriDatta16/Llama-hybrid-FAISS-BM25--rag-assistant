[site]: crossvalidated
[post_id]: 462275
[parent_id]: 462245
[tags]: 
Given your assumption of having an exponential trend, you can apply the logarithm to your data. Doing so, you transform your time series into having a linear trend, which is much easier to model. I provide a simple example in Python below. In this case your time series is $X_t=f(t)+\epsilon_t$ , where $f(t)$ is your trend and $\epsilon_t \sim \mathcal{N}(0,1)$ . You think that your trend is exponential, so this function will have the form $a e^{b (t -c)}$ for some constants $a,b,c\in \mathbb{R}$ that you don't know. import numpy as np import matplotlib.pyplot as plt t = np.linspace(0, 10) a = 2 b = 0.5 c = 2 f = lambda t: a * np.exp(b * (t - c)) epsilon_t = np.random.randn(len(time)) X_t = f(t) + epsilon_t plt.plot(t, X_t, label='Original time series') plt.legend() plt.show() # Compute trend trend_coeff = np.polyfit(t, np.log(X_t), deg=1) trend = lambda t: trend_coeff[0] * t + trend_coeff[1] plt.plot(t, np.log(X_t), label='Log time series') plt.plot(t, trend(t), linestyle='dashed', label='Trend') plt.legend() plt.show() And if you are courious, you can note that the theoretical value of the coefficients is $[b, \log a - bc]$ , which is relatively close to the [0.529, -0.538] of our fitting considering that our time series is noisy.
