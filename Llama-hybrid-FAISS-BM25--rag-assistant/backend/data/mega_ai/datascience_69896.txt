[site]: datascience
[post_id]: 69896
[parent_id]: 
[tags]: 
MAPE over 100% after normalization of dataset

I try to forecast power demand for next 24 hours. Years 2017 and 2018 are my training set, 2019 is test set. I use multistep vanilla LSTM . In first step I used original data with any preparation and I get MAPE score about 7,5%. Then I read some article about doing the same thing in Matlab and they use to types of normalization of dataset: First one $$ P_n(d,h)=\frac{P(d,h)}{max_‚Å°P} $$ Second one $$ P_n(d,h)=\frac{((P(d,h)-mean(P(d)))}{std(P(d))} $$ When I use first one Make drop to 3,5% and in article second one gets even better scores. But when I use it my forecast was very wrong with MAPE 130% and very big errors. I don't find in internet anyone with the same problem. I tried using MinMax scaler but MAPE was around 20%. I think it have something with very small values because when modified second normalization to have every value greater than zero MAPE drop to 78%. this is my neural network def build_model(train, n_input): # prepare data train_x, train_y = to_supervised(train, n_input) # define parameters verbose, epochs, batch_size = 2, 100, 72 n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1] # define model model = Sequential() model.add(LSTM(400, activation='relu', input_shape=(n_timesteps, n_features),return_sequences=True)) model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features))) model.add(Dense(100, activation='relu')) model.add(Dense(100, activation='relu')) model.add(Dense(n_outputs)) model.compile(loss='mse', optimizer='RMSprop') # fit network model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose) return model this is link to my Colab colab this is normalization #first one load_norm=data['load'].max() data2=data.copy()/data['load'].max() #second one import datetime def no_trend(x): mean=x.mean() std=x.std() return (x-mean)/std def no_trend_transform(data): index_range=data.copy() index_range=index_range.resample('D').mean() index_range.reset_index(inplace=True) index_range['index']=index_range['index'].apply(lambda x: x.strftime("%Y-%m-%d")) for i in index_range['index']: data[i]=no_trend(data[i]) return data.dropna() data2=no_trend_transform(data.copy()) Dataset dataset Do you have any idea what is a problem? I tried this that a set with other types of LSTM and MLP and I have the same problem.
