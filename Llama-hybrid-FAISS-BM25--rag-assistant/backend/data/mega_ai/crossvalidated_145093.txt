[site]: crossvalidated
[post_id]: 145093
[parent_id]: 144272
[tags]: 
Since the value of $\phi_2$ is twice that of $\phi_1$, all the distances in $\phi_2$-space are twice as big as the distances in $\phi_1$-space. This means that the margin (which is roughly the "thickness" of the separating hyperplane that the SVM learns) is twice as big also. We can show this with an even simpler pair of kernel functions, $\phi_1(x, y) = (x, y)$ and $\phi_2(x) = (2x, 2y)$--the principle is exactly the same as with the pair of kernels you suggested. If you have a dataset with positive points at $(0,0), (0,1)$ and negative points at $(1,0), (1,1)$, then using $\phi_1$ you'll learn the following SVM: On the other hand, $\phi_2$ multiplies each coordinate by 2 relative to $\phi_1$, so you learn the following hyperplane instead: As you can see, because all distances are inflated by a factor of 2, the margin is greater as well. Appendix: R code for plots do.plot
