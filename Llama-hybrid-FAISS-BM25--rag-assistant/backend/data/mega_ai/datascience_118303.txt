[site]: datascience
[post_id]: 118303
[parent_id]: 
[tags]: 
Grad-CAM for CNNs with GAP layer

I'm new to deep learning, so maybe this is a silly question... Do any adjustments need to be made for applying Grad-CAM on CNNs that use a Global Average Pooling (GAP) layer right before fully connected ones? I understand that the GAP layer aggregates the activations of an intermediate layer in order to produce a compact representation of the image, removing information regarding the features location. Is this an obstacle to grad-cam backpropagation? I imagine that for a CNN that uses, for example, a Max Pooling layer followed by a Flatten layer, o Grad-CAM is capable of retriving the exact location of the relevant features. I'm sorry if it is a silly doubt, but I couldn't find the answer for it anywhere. Thanks in advance!
