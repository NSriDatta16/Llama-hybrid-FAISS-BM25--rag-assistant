[site]: datascience
[post_id]: 123328
[parent_id]: 
[tags]: 
How did Andrej Karpathy make the LSTM output byte values for sampling Shakespeare?

I'm wondering how continuous output values of deep learning networks are converted to byte values or other discrete values for that sake. For example here: In his famous article The Unreasonable Effectiveness of Recurrent Neural Networks , Andrej samples Shakespeare texts using an LSTM. An LSTM's output consists of sigmoid outputs multiplied by tanh outputs: ( Understanding LSTM Networks, Christopher Olah, 2015 ) These values are always in the interval [-1, 1], so their product (and hence the output of the LSTM) is also in this interval. How are these values converted to byte values {0, 1, 2, 3, ..., 255}?
