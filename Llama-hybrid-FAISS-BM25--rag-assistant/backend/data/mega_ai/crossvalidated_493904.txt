[site]: crossvalidated
[post_id]: 493904
[parent_id]: 493898
[tags]: 
Is my strategy of forward selecting the features according to the mean CV AUC OK here? Since you are using Python you should be aware of Recursive Feature Selection CV which in essence is doing what you are, but this gives you the advantage of working with pipelines Is it OK to keep the LASSO regularization (which also select feature), in the loop? This is ok since with the feature selection you are pointing to the combination of features that "optimize" the metric, whereas L1 regularization is punishing the non-significant features for the specific model If yes for the second question, as you see, I fixed the LASSO parameter C to 4 according to a grid search done before this process, with all 23 features (which sounds not really appropriated)... Have you an idea on how to optimize the C parameter of the LASSO inside this process instead of before with all features? You can use LogisticRegressionCV which will optimize the regularization parameter via cross-validation for you at each fit stage. This is a working example using a dummy dataset of how this should be used: from sklearn.linear_model import LogisticRegressionCV from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.feature_selection import RFECV from sklearn.model_selection import train_test_split from sklearn.datasets import load_breast_cancer X, y = load_breast_cancer(return_X_y= True) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42) scoring = "roc_auc" model = Pipeline([("scaler", StandardScaler()), ("model",RFECV(estimator = LogisticRegressionCV(max_iter = 10000,class_weight="balanced", scoring= scoring, random_state= 42) ,scoring = scoring))]).fit(X_train, y_train) model.score(X_test, y_test) Note that as per 1st question both, the feature selection and C parameter are to optimize roc auc. You can test by yourself that when modifying this, i.e changing the metric on any of the two processes, the scoring will decrease (ej. optimizing the metric for feature selection as accuracy and roc auc for C in logistic regression model)
