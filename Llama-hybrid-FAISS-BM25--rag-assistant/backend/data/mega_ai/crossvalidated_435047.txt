[site]: crossvalidated
[post_id]: 435047
[parent_id]: 
[tags]: 
Selection bias estimation in feedback loops

I'm trying to design a feedback loop for improving logistic regression model over time, it consists of following steps: a user submits text for analysis; back-end system (model) runs multilabel logistic regression (among N labels) and choose M labels that have met threshold; labels are shown to the user and user can do 3 things with each prediction: agree/disagree and do nothing data then stored and used as a training set for improving models (with the initial weight used from the previous model) This schema introduces selection bias and response bias: selection bias - training data distribution doesn't represent the original distribution response bias - users might agree to some labels more likely than to another; So given this scheme, is there a way to take into account those biases and make updates to the model with normalized weights? Or is there any other technique that would be useful in this scenario?
