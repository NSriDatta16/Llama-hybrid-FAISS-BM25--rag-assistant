[site]: crossvalidated
[post_id]: 283046
[parent_id]: 283028
[tags]: 
Unless the objective of your survey is finding out about lying behaviours, adding any "audits" or lie detectors is a really bad idea. It is okay to ask knowledge questions, but do not encourage lying behaviour. Avoid formulating weak questions, even if they are meant to be "audits". In your second example, the attentive respondent will follow exactly your advice and disagree because that's what you've asked for. In the first example, the last option does not make any sense at all, for that would leave no time for anything but ... In addition, you receive a "controlled" garbage response, now what? ignore the response in your study: very dangerous strategy. As soon as the proportion becomes significant, the study is no less flawed than without the "audit". impute it with a more plausible value, sure, but how? If you don't know what causes the bad item response, it is very difficult to impute it without introducing another bias; disclose it in your study: the preferable option, but hopefully the phenomenon is rare enough to avoid the readers from concluding the problem was the survey itself; Therefore, the only viable solution consists in studying your topic well and eventually come up with a set of good questions. Test the questionnaire before-hand on a few subjects (e.g. a sample of 10-20) and then learn from that test run to revise the questionnaire accordingly. Seek feedback from peers who ran similar surveys as well. Finally, run your full data collection. Should any weird significant response phenomenon arise, you should always ask yourself: what characterizes those people who provided the bad answers? If there's a pattern, you can resort to imputation; could the formulation of the question and the response items be improved? is the topic overly sensitive? May this lead a certain subsample not to respond at all to either question or survey? is the questionnaire too long? is the survey addressed to the right audience? how to ensure that those who respond are actually from the population you are studying? who did not respond to the survey and what are the potential reasons? is the sample design and the collection mode appropriate? Never assume that the questionnaire and the survey design would not introduce bias.
