[site]: datascience
[post_id]: 124819
[parent_id]: 
[tags]: 
How to selectively train a deep model based on the unavailability of a subset of the feature set

I am creating a deep learning binary classification model. Each sample in the dataset contains two mutually exclusive feature sets X and Y. Feature set X is present in all samples; however, there are around 45% of the total samples wherein values for feature set Y is unavailable. Feature values in Y are binary in nature. I want my model to be such that during inference if the test sample doesn't contain values for feature set Y, then the inference should be done only on feature set X. In case if values for Y are available, inference shall be based on both X and Y. I am using PyTorch Lightning framework for model architecture design and development. As per my understanding, one approach I can follow is to "fill in" some default values for the features in Y in case they are absent and train the model. But, what values to fill? Should it be 0 or 1 or any other like -1, etc. Another approach might be to create a binary feature named isYPresent (for example). It will be 0 if Y is absent and 1 if present. Does there exist a technique which can handle this scenario during model training (and later during inference) based conditionally on the value of this new feature?
