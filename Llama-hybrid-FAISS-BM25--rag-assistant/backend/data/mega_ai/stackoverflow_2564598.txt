[site]: stackoverflow
[post_id]: 2564598
[parent_id]: 2561513
[tags]: 
For most SVM implementations, training time can increase dramatically with larger values of C. To get a sense of how training time in a reasonably good implementation of SMO scales with C, take a look at the log-scale line for libSVM in the graph below. SVM training time vs. C - From Sentelle et al.'s A Fast Revised Simplex Method for SVM Training . alt text http://dmcer.net/StackOverflowImages/svm_scaling.png You probably have two easy ways and one not so easy way to make things faster. Let's start with the easy stuff. First, you could try loosening your convergence criteria . A strict criteria like epsilon = 0.001 will take much longer to train, while typically resulting in a model that is no better than a looser criteria like epsilon = 0.01. Second, you should try to profile your code to see if there are any obvious bottlenecks. The not so easy fix, would be to switch to a different optimization algorithm (e.g., SVM-RSQP from Sentelle et al.'s paper above). But, if you have a working implementation of SMO, you should probably only really do that as a last resort.
