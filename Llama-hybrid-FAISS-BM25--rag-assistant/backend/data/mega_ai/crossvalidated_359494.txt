[site]: crossvalidated
[post_id]: 359494
[parent_id]: 359449
[tags]: 
In principle , you could certainly use Gibbs sampling or Metropolis Hasting to take draws from the posterior of a state space model. There is nothing about these models that invalidates the theory that justifies either of these methods. In practice , it's my understanding that this is a bad idea. In short, the number of samples required would be unreasonable for even a moderate sized problem. In particular, note that there is a very strong relation between the relatively small number of parameters and very large number of hidden states. This means that conditional on the current values of the hidden states , the posterior of the parameters is very, very tight. Likewise, for a given hidden state, conditional on the other hidden states + parameters, the posterior is very tight. However, that doesn't mean the joint distribution itself is very tight. This can lead to very bad behavior for Gibbs sampling or Metropolis Hasting. For example, if we just update one parameter/state at a time, all the parameters/states will barely budge at each update, yet the marginal distributions will be very wide. This will require an unreasonable number of samples to get a reasonable approximation of the posterior. We can try to sample more efficiently with something like a block updater, but this comes with it's own set of problems. For example, if we do something like an adaptive block updater then non-normality will make sampling very inefficient, actually getting a reasonable estimate of the posterior covariance matrix is a chicken/egg problem, computational costs grows cubicly, etc. This is the motivation for using PMCMC: we can propose an update for the parameters and then approximate integration over all the possible states. Thus, we can sample from the marginal distribution of the parameters much more efficiently...and conditional on the parameters, we can draw samples from the state space more efficiently as well. I'm not so certain how well Stan handles state space models. Presumably, because it uses HMC and updates all the parameters simultaneously, it will have more efficient sampling per iteration than say Metropolis Hasting or Gibbs, but I think it may still face many of the same problems? I'm curious to hear if others have had a positive or negative experience with Stan and state space models.
