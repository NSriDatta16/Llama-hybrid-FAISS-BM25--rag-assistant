[site]: crossvalidated
[post_id]: 362143
[parent_id]: 359771
[tags]: 
But, i rarely noticed anyone doing it for deep learning projects. Is there a specific reason for not using Dimensionality reduction techniques in deep learning? That depends on the aims of these projects. For example for projects/papers dealing with representation learning it's pretty common: Reducing the Dimensionality of Data with Neural Networks Semantic Hashing Vector Representations of Words from Tensorflow documentation On the other hand, if you have a supervised problem and you're primarily interested in some metric, then you're less likely to incline what are the features network actually learned.
