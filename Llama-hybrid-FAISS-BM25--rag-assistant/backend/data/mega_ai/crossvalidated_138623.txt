[site]: crossvalidated
[post_id]: 138623
[parent_id]: 138426
[tags]: 
If your sample size is 9, then multiple regression is a real strain. Think that even with two predictors $X_1, X_2$ and a response variable $Y$, you are estimating three parameters (constants to be estimated) $\beta_0, \beta_1, \beta_2$ in a function like $\beta_0 + \beta_1 X_1 + \beta_2 X_2$. Loosely, but genuinely, you don't have much information to do that. Many statistical accounts advise as rules of thumb having many more data points per parameter than that. Consider also the fact that two distinct points define a straight line uniquely, so that $Y = \beta_0 + \beta_1 X_1$ could always be fitted exactly with two such data points, regardless of whether the model makes scientific or practical sense or would be turn out to be a good approximation for a much larger dataset. This can be extended to three distinct points in a three-dimensional space being enough to fit a plane uniquely: that is the case $\beta_0 + \beta_1 X_1 + \beta_2 X_2$ again. You can get intuition for this case by holding three fingers of two hands in the air and imagining a plane through them. It can then be extended more generally to fitting a linear regression function in any space. That becomes impossible for most of us to visualise, but the algebra generalises to your being able to fit at most 8 predictors to 9 data points, but such a perfect fit would be spurious and totally sensitive to any quirks in a dataset. Much of the point of fitting any regression is that the data points all have a vote and there is limited democracy insofar as points extreme in some sense will be often countered by others. (Often, but not always....) This is just a matter of geometry, but statistically it can be worse, even much worse. If your predictors are correlated with each other, as they usually will be (it's hard to imagine datasets in which relevant variables are related to the response but unrelated to each other, unless that is a consequence of an experimental set-up), then it is difficult enough in general to work out the underlying relationship reliably. It's harder still to do that with very small samples. This problem goes under various names, including multicollinearity. Examples could be imagined in which it works fine, but usually the experience will be similar to yours. The $P$-values are a health warning that you do not have a sample size large enough to do what you are trying. So, what to do? Try to get more data if you can. That's easy to say, but it's really important to realise that it's the only good solution. There is no statistical or Hogwarts spell to fit complicated models well to very small datasets. But naturally, this may not be practical for all kinds of simple reasons. Be very cautious, and in particular don't fit anything that you can't support graphically. This is always good advice, but it is more than usually true with a model fitted to few data points for which programs may solemnly produce outrageous nonsense. As a rule of thumb, try at most two predictors. (Using a model just to predict makes no difference here; an untrustworthy model is untrustworthy regardless of your motive.)
