[site]: crossvalidated
[post_id]: 497062
[parent_id]: 497051
[tags]: 
The most common situation I'm familiar with is fitting any kind of Bayesian (regression) model to data. It's usually very easy to write down the likelihood (=sampling distribution of the data for given parameter values), as well as some prior distributions for the model parameters. The posterior distribution is proportional to their product, but it is usually not possible to get a closed form solution for the denominator (that denominator requires integrating out all model parameters when you may have dozens or hundreds of model parameters). Thus, outside some very, very specific circumstances, there will be no closed form posterior distribution, which one could analytically summarize, available for Bayesian models. However, doing MCMC sampling is usually very feasible. The homepage of one popular MCMC sampler (Stan) has a list of case studies that illustrate use cases of MCMC sampling. Even for something simple like the baseball batting rates example, try getting the results they produce without MCMC sampling, I assure you that will be tough. I'm not 100% sure that in that case it's not perhaps possible, but in the more complex examples it definitely will be impossible.
