[site]: crossvalidated
[post_id]: 622674
[parent_id]: 
[tags]: 
Bayesian inference on model parameters from summary statistics alone

Consider quantities $y_1,y_2,\dots,y_p$ , for the $j$ th of which we have $n_j$ measurements $y_{1j},y_{2j},\dots,y_{n_jj}$ . Unfortunately, I do not have access to the raw data $y_{ij}$ -- only to the reported sample mean $\bar{y}_j$ , sample variance $s_j^2$ , and sample size $n_j$ for each $j$ . Suppose further that $y_{ij}\sim\mathcal{N}(\mu_j,\sigma_j^2)$ , where $\mu_j=f_j(\vec{\theta})$ is a deterministic but complicated (non-invertible, non-differentiable) and computationally expensive function of latent parameters $\vec{\theta}$ on which I want to do inference. I have several ideas about how to proceed, and I would like some advice about their relative merits. One option would be to model $$ \bar{y}_j\mid\vec{\theta},\sigma_j,n_j\sim\mathcal{N}(f_j(\vec{\theta}),\sigma_j^2/n_j)\\ s_j^2\mid\vec{\theta},\sigma_j,n_j\sim\frac{\sigma_j^2}{n_j-1}\chi_{n_j-1}^2. $$ After obtaining a joint posterior over $(\vec{\theta},\vec{\sigma})$ , I would marginalize out $\vec{\sigma}$ to obtain a posterior over $\vec{\theta}$ alone. However, since I would be treating $\vec{\sigma}$ as nuisance parameters anyway, another option might be to take $$ \bar{y}_j\mid\vec{\theta},s_j,n_j\sim f_j(\vec{\theta})+\frac{s_j}{\sqrt{n_j}}t_{n_j-1}, $$ thus reducing the dimensionality of the problem by forgoing inference on $\vec\sigma$ . This is potentially advantageous because the cost of evaluating $f(\vec{\theta})$ is going to necessitate the use of methods which may struggle with simultaneous inference over many parameters. Is this approach strictly equivalent to the previous one? My first two approaches implicitly assume that the $y_j$ (and thus the corresponding sample means $\bar{y}_j$ ) are uncorrelated. I am not sure that this can be justified from the experimental design alone. I could instead take $\vec{y}\sim\mathcal{N}_p(\vec{\mu},\Sigma)$ so that $\vec{\bar{y}}\mid\vec{\theta},\tilde{\Sigma},\vec{n}\sim\mathcal{N}_p(\vec{f}(\vec{\theta}),\tilde{\Sigma})$ , but then I would need to include the off-diagonal components of $\tilde\Sigma$ as nuisance parameters in addition to the on-diagonal ones. (I am unsure what distribution $\vec{s}\mid\vec{\theta},\tilde\Sigma,\vec{n}$ would have in this case.) Yet my intuition is that this is unnecessary if for no other reason than that the data I actually have, namely $\bar{y}_j$ and $s_j^2$ , estimate (in a classical sense) the means $\mu_j=f_j(\vec\theta)$ and on-diagonal components $\tilde\Sigma_{jj}$ , respectively, and should therefore be essentially un-informative as to the off-diagonal components of $\tilde\Sigma$ . Is this sound justification for taking $\tilde\Sigma$ to be a priori diagonal? Many thanks!
