[site]: crossvalidated
[post_id]: 106391
[parent_id]: 106073
[tags]: 
This is a power calculation that can only be achieved via simulation. Assuming that you are fine with the simulation components of the analysis up to simulating correlated binary outcomes, I will attempt to address that deficiency. It is usually reasonable to simulate correlated categorical outcomes using a random effect in the linear component of the fitted model. For instance, if you're an R user, this might look something like: npers The major caveat with, say, risk prediction from repeated measures designs is the following: the fitted values from fixed effects in a conditional (mixed) model predict outcomes in a person whose random effect is exactly zero. Remember random effects arise from millions of unmeasured prognostic factors. If you actually measured all those factors, there would actually be no need for random effects because repeated measures would be conditionally independent from one another since you've controlled for every possible level of variation within and between persons. However, and I think this is a somewhat unexplored principle, I think you can get better risk prediction from marginalizing the distribution of conditional fitted risk values according to the estimated distribution of the random effect. This is technically a better approximation to whatever the actual risk is relative to the GEE. The GEE estimates the logit of the average whereas a marginalized mixed model would give you the average of the logit. Jensen's inequality gives us that the average of the logit is not the logit of the average. Which is right? Remember, it's the particular individuals' random effect which is unknown. Hence you are averaging up a bunch of possible logits to estimate their risk. We showed something similar with missing data and risk prediction before.
