[site]: crossvalidated
[post_id]: 289111
[parent_id]: 
[tags]: 
Text classification: Lost in the world of Deep learning, NB, LSTM and CNN

Imagine I have a large text document, I want to be able to highlight some parts of the document if they belong to a category I've specified. I'm trying to figure out what's the best machine learning approach to do that. Currently I'm using a simple Naive Bayes algorithm, but I've heard results can be improved with LSTM or Convolutional Neural Networks. I'm trying hard to understand all these concepts, but I would like to make sure of a few things before spending too much time on it: Can LSTM be applied to a "small" training set. I mean, In my training set, I will only have 100 sentences for each category I want to train . Can CNN be a better option? Or maybe LSTM can be applied to CNN? I've heard deep learning needs millions of data to be effective. I'm really far away from this, but LSTM seems to belong to the deep learning family. Does it mean that LSTM can't be applied to my problem? In a nutshell, what would be the best approach to do text classification with a small training set of 100 sentences / 30 categories (3000 sentences in total) If I decide to build a better training set, (1000 sentences/ 30 categories) would the approach be different?
