[site]: crossvalidated
[post_id]: 204667
[parent_id]: 
[tags]: 
Cross Validation - purpose, need and utility

The question might sound like an old one but I haven't got satisfactory answers for a number of questions I have about CV. I looked at several questions on CV here , here , here and here and yet things aren't very clear to me. So I will post a few questions which are related and hopefuly will help me (and other people) understand CV better. Say I use K-fold CV for a learner (say linear regression). In the process, I learn K different sets of regression parameters. For each set of params, I know the error on the corresponding validation set. Now what do I do? Which of those K sets of learned params should I select? Do I retain the params set which gave the least error? Or should I now learn a new model with all training data together (in which case, why did I do CV in the first place)? Does CV help avoid overfitting? Is this true in all cases or is it true only for specific type of learners (like Decision trees)? How does CV avoid overfitting if the above is true in general for any learner? Is CV needed only for small datasets or also for large datasets (think big data scale)? If the purpose of CV is to get a better estimate of the prediction error (and assuming we have a large test set), why shouldn't we just use a fixed training set, and a number of disjoint test subsets, averaging the errors across all test subsets?
