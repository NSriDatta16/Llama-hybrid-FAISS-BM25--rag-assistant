[site]: stackoverflow
[post_id]: 4325333
[parent_id]: 
[tags]: 
touchesbegan with multiple UIImageView detects incorrect UIImageView

I'm having a problem with touch detection on iPad. I subclassed the UIImageView like this: @interface MyUIImageView : UIImageView { BOOL _dragActive; CGPoint originalLocation; } @end @implementation MyUIImageView - (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event { _dragActive = YES; originalLocation = self.center; } - (void)touchesMoved:(NSSet *)touches withEvent:(UIEvent *)event { if (_dragActive) { UITouch* touch = [touches anyObject]; self.center = [touch locationInView:self.superview]; } } - (void)touchesEnded:(NSSet *)touches withEvent:(UIEvent *)event { if (_dragActive) { self.center = originalLocation; } _dragActive = NO; } - (void)touchesCancelled:(NSSet *)touches withEvent:(UIEvent *)event { if (_dragActive) { self.center = originalLocation; } _dragActive = NO; } @end I have multiple ImageView(MyUIImageView) controls on the controller view side by side but my touchesBegan is only being called for the front most although they are separated on the controller view. Looks like there is an invisible "detection layer" that spawns beyond the ImageViews. When I click and drag an ImageView the one that get dragged is the one that is to the left or to the right depending on which one is in front. If I change the z axis then the behavior repeats but on the images that are on front.
