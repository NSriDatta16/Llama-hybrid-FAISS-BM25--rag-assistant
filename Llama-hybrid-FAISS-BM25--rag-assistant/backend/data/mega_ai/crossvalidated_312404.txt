[site]: crossvalidated
[post_id]: 312404
[parent_id]: 
[tags]: 
General strategy for tuning a ML algorithm

I am a bit confused about the general strategy to adopt for the set up of a ML learning algorithm, in the case for example of a neural network, and I have not been able to find resources (books or articles) to answer my questions. Let us consider a neural network where the variables that are tunable are the numbers of layers, the sizes of the layers and the connections between layers (for example relu, sigmoid, pooling, convolutions...) and that I have a training set, a validation set and a test set. From what I have understood about the subject, a general strategy could be the following: I choose a neural network architecture (as described above) and I train my neural network, in the sense that with an iterative method (like gradient descent), weights (biases included) are iteratively computed in order to minimize the discrepancy (in some given norm) between the actual values $y_{train}$ and the output given by the neural network $\hat y_{train}$. Then, at each iteration, I use the validation set to compute the discrepancy between the actual values $y_{val}$ and the output given by the neural network $\hat y_{val}$. So my questions are: 1) Should I tune the parameters (number of layers, sizes of layers, type of connections) in order to minimize the error between $y_{val}$ and $\hat y_{val}$ ? 2) Isn't doing 1) considered data snooping ? 3) If I pursue the strategy described in 1), suppose I obtain after tuning the neural network a very low error between $y_{val}$ and $\hat y_{val}$. Then I use the test set to compute the error between $y_{test}$ and $\hat y_{test}$ and find out that the error is larger than the validation error. So what should I do ? Change the parameters of the neural network ? I suppose that would be again data snooping and/or that it would limit the further ability of the neural network to make correct predictions of new data ? And how much larger with respect to the validation set error is the test set error considered too large ? 4) More generally, could someone describe the strategy that is generally accepted in the ML/DL community to tune the parameters of a neural network in the case described above (in the sense where I can tune the number of layers, the sizes of layers, the type of connections and I have training, validation and test sets) ?
