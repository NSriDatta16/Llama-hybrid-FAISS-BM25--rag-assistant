[site]: crossvalidated
[post_id]: 205866
[parent_id]: 
[tags]: 
The Harris recurrence of a stepping-out slice-sampling-within-Gibbs MCMC

I want to use a multistage version of the MCMC here . That is, I want to use a Gibbs sampler to draw from a general joint distribution $p(x_1, x_2, x_3, \ldots)$ with a Gibbs step for each full conditional $p(x_i | \ldots x_{i - 1}, x_{i + 1}, \ldots)$, where I use Neal's (2003) stepping-out slice sampler to draw from each full conditional. (For each index $i$, sample $p(x_i | \ldots, x_{i - 1}, x_{i + 1}, \ldots)$ by first sampling auxiliary variable $u_i$ from $p(u_i | \ldots, x_{i - 1}, x_i, x_{i + 1}, \ldots)$ and then $x_i$ from $p(x_i | u_i, x_1, \ldots x_{i - 1}, x_{i + 1}, \ldots)$). Edit 4/7/16 I'm assuming a variant of slice sampling that does not necessarily sample from $p(x_i | u_i, x_1, \ldots x_{i - 1}, x_{i + 1}, \ldots)$ in a direct fashion. This full conditional is a uniform density on some "slice" $S$ of the $x_i$ component of the state space. Rather than calculate $S$ using an optimization, Neal proposed stepping-out and shrinkage procedures to draw an approximate sample of $x_i$ (Figures 3 and 5 of the 2003 paper). End edit 4/7/16 Question: when is this Markov chain Harris recurrent? Harris recurrence would in some sense ensure eventual convergence to the stationary distribution from any starting state, and it would also give us useful ergodic theorems such as the MCMC analogue of the strong law of large numbers ( Robert and Casella (2004) ). From Roberts and Rosenthal (2006) , we know Metropolis-within-Gibbs algorithm is Harris recurrent if the chain will eventually move in every coordinate direction with probability 1. I want the same thing to be true for slice-samping-within-Gibbs, but I cannot find a discussion of this specific point.
