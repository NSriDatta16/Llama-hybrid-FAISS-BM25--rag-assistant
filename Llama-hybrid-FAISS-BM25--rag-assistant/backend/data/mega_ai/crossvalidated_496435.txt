[site]: crossvalidated
[post_id]: 496435
[parent_id]: 383756
[tags]: 
I would recommend not performing feature selection with SVMs if you are interested in generalisation performance. The SVM approximately implements a bound on the generalisation that is independent of the number of features. However, as soon as you try to optimise the kernel (or equivalently select features), then all of the theory underpinning the bound is violated and the bound no longer holds. It is easy to over-fit feature selection criteria, and this can make performance much worse. See, for example, my answer here . If you are interested in finding the most important features as an end in itself (rather than to improve performance) then I would recommend using a model that has feature selection built in, such as the LASSO or LARS. I can strongly recommend the paper of Guyon and Elisseeff for guidance on the use of feature selection (and some of the potential pitfalls).
