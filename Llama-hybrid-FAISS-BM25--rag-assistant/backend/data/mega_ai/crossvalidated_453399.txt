[site]: crossvalidated
[post_id]: 453399
[parent_id]: 
[tags]: 
Regularising yearly prevalence estimates using hierarchical model (time series)

Say I'm attempting to get the best possible estimates for the prevalence of drug use in the US in each of the past 5 years. I could build a model with either a Bayesian logistic regression model with either a time index or time trend variable included. However, each of these approaches seems sub-optimal to me: Yearly estimates using the time index model doesn't give use any information from the underlying time trend, so it invariably overfits. Yearly estimates from the time trend model ignores idiosyncratic differences in prevalence from year to year, so invariably underfits. Is there a way to use some sort of hierarchical multi-level model where what we essentially do is set the prior of the coefficients associated with each year to what would be expected if prevalence followed a linear trend over time. That way, yearly estimates could be regularised towards the linear trend. Is there anything inherently wrong with this approach? And, would simply including both a time trend and time index in the same model accomplish the same task? Models Time Index used_drugs ~ binomial(1,p), logit(p) = a[year], a[year] ~ normal(0,1.5) #Note: numbers are just examples of priors Time Trend used_drugs ~ binomial(1,p), logit(p) = a + b*year, a ~ normal(0,1.5), b ~ normal(0,0.5) Time Index and Time Trend (non-hierarchical) used_drugs ~ binomial(1,p), logit(p) = a[year] + b*year, a[year] ~ normal(0,1.5), b ~ normal(0,0.5) Time Index and Time Trend (hierarchical) Note: I'm not sure if this is correct. used_drugs ~ binomial(1,p), logit(p) = a[year], a[year] ~ normal(mu,sigma), mu = a + b*year, a ~ normal(0.1.5) b ~ normal(0,0.5)
