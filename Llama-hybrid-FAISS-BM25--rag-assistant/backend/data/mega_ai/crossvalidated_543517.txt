[site]: crossvalidated
[post_id]: 543517
[parent_id]: 133501
[tags]: 
The approach makes sense to me. I would be careful though with the interpretation of the "probability" that some machine learning algorithms produce. The logistic regression directly models the probabilities. If correctly specified, then the output can be interpreted as "probability". Neural nets are similar; they can be seen as logistic regression with highly complex feature extraction. I am not sure about the tree-based methods. As far as I know, there is no consensus if we can interpret the "scores" of methods like the random forest as "probabilities". As you said, the scores indicate the fraction of trees that judged the positive. The trees are samples from possible models, whereas what we want is samples from trials. I find no clear link between them. As a result, I personally see the scores from the random forest just as scores. The higher the score, the larger the probability. Perhaps they are a monotonic transformation of probabilities, but not necessarily equal. That said, I would be happy if someone could correct me if my interpretation is wrong.
