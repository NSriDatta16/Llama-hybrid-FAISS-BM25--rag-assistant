[site]: crossvalidated
[post_id]: 532257
[parent_id]: 532189
[tags]: 
We can back out the answer with a little auxiliary information about the covariates. Your linear model is probably something like $$E[y \vert x, z] = \hat y= \hat \alpha + \hat \beta \cdot x +\hat \delta \cdot z.$$ What is the change in the expected value of $y$ associated with 1 unit change with $x$ ? We can easily get that from the derivative: $$\frac{\Delta \hat y}{\Delta x} =\hat \beta.$$ We can then turn that into an elasticity: $$\epsilon =\frac{100\cdot\frac{\Delta \hat y}{\hat y}}{100 \cdot \frac{\Delta x}{x} }= \frac{\% \Delta \hat y}{\% \Delta x}= \hat \beta \cdot \frac{x}{\hat y}=\frac{\partial \hat y} {\partial x} \cdot \frac{x}{\hat y}.$$ In other words, to get an elasticity, we just need to multiply the regression coefficient on $x$ by the value of $x$ itself over the prediction of $y$ . Note that this is a function of the covariates and can vary across observations. We need some way to summarize the individual elasticities. There are several ways to put this into practice, but the most common is to take the average in the sample: $$\bar \epsilon =\frac{1}{N} \sum_{i=1}^N \hat \beta \cdot \frac{x_i}{\hat y_i}.$$ Some software can do this for us, which makes the calculation of the standard errors much easier. Here's an example in Stata: . sysuse auto, clear (1978 automobile data) . regress price mpg foreign Source | SS df MS Number of obs = 74 -------------+---------------------------------- F(2, 71) = 14.07 Model | 180261702 2 90130850.8 Prob > F = 0.0000 Residual | 454803695 71 6405685.84 R-squared = 0.2838 -------------+---------------------------------- Adj R-squared = 0.2637 Total | 635065396 73 8699525.97 Root MSE = 2530.9 ------------------------------------------------------------------------------ price | Coefficient Std. err. t P>|t| [95% conf. interval] -------------+---------------------------------------------------------------- mpg | -294.1955 55.69172 -5.28 0.000 -405.2417 -183.1494 foreign | 1767.292 700.158 2.52 0.014 371.2169 3163.368 _cons | 11905.42 1158.634 10.28 0.000 9595.164 14215.67 ------------------------------------------------------------------------------ . /* canned */ . margins, eyex(mpg) Average marginal effects Number of obs = 74 Model VCE: OLS Expression: Linear prediction, predict() ey/ex wrt: mpg ------------------------------------------------------------------------------ | Delta-method | ey/ex std. err. t P>|t| [95% conf. interval] -------------+---------------------------------------------------------------- mpg | -1.238224 .3721885 -3.33 0.001 -1.980347 -.4961013 ------------------------------------------------------------------------------ . /* by hand */ . predict yhat, xb . generate elasticity = -294.1955 *(mpg/yhat) . summarize elasticity Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- elasticity | 74 -1.238224 1.060581 -7.488722 -.4215304 This means that a 1% increase in mpg is associated with 1.2% decrease in price. If we don't have the raw data, but have some summary statistics on the covariates and the coefficients, we can plug those into the first formula instead of averaging. The answers won't match exactly but are usually reasonably close.
