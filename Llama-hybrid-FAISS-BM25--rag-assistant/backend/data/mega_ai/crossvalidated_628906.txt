[site]: crossvalidated
[post_id]: 628906
[parent_id]: 
[tags]: 
XGBoost Calibration for weighted loss function

I am currently using XGBoost (in R ) to perform multiclass classification. I am using merror=eval_metric and my objective is multi:softprob , so that I can get predicted probabilities for each class. I also have a vector of weights for each of the observations I'm using. I've plotted a calibration curve for each class (basically using a One vs. Rest approach, as that is what's done by CalibratedClassifierCV for multiclass classification). As expected by the nature of XGBoost, the distribution always looks bimodal with modes very close to 0 and 1. I would like to calibrate my model but I am unsure how this can be done (preferably in R). I don't mind using a One vs. Rest approach as I understand that's what's done in Python and it's probably the simplest approach out there. My question is how this can be done given that the calibration process is apparently using the Brier score as objective. Does my choice of loss function affect things and how can I account for my observation weights in the calibration process? Any suggestions would be very helpful!
