[site]: crossvalidated
[post_id]: 135771
[parent_id]: 135767
[tags]: 
I won't be answering list items in your question. Partly because it is SAS specific (I don't use SAS). My answer is a sort of general precaution. Using variables of different type to cluster cases isn't particularly good idea. Because it is unclear how to weight such different variables. Should a continuous feature be weighted equally as a 10-class nominal one? Or weighted 9 times greater because there is 9 dummy variables hiding behind that nominal one? Or weight should be somehow estimated to be in-between (for example based on comparing variance of the one with enthropy of the other)? Also, attributes of different character naturally call for different distance measure. Euclidean or Manhattan distance are good for scale (interval) variables but using them with binary variables is questionnable. Binary features with "asymmetric" meaning (present vs absent) usually require such coefficients as Jaccard or Ochiai, while Dice coefficient is better for nominal (dichotomous or polytomous converted into dummy) features. It is possible to use popular composite similarity measures like Gower , of course. One should note, however, that Gower is only for hierarchical cluster analysis, and hierarchical clustering is poorly suited for large amount of objects, both practically and theoretically ( 1 , 2 ). And Gower isn't euclidean or metric distance, it is improper to use hierarchical methods like Ward of centroid with it (may use average, complete, single linkage methods). Finally, it relatively tedious task to investigate/interpret how the clusters erected by the analysis differ in regards to every feature constituting Gower measure, due to their different nature. Of course, you could work-out a plan to do clustring by subsamples if your overall sample is so large, and then to combine results somehow (various ways are possible) to arrive at a common result, but is quite a hard work. In SPSS, there exist TwoStep cluster analysis that can efficiently cluster huge amount of objects and also can process interval and nominal variables together. It has also some options to advice the number of clusters and to track down outliers. However it doesn't process ordinal or binary data so far and it has its assumptions; it is not a panacea. (You may search on this site for two-step cluster if you wish.) Clustering based on mixed-type data is purely a heuristic idea and lacks mathematical or esthetical merit behind it. There exist a nonlinear transformation in statistical anlysis, called optimal scaling which can convert categorical types of variable into quantitative interval one, but it must have a goal function to "optimize" the transformation for. Theoretically, it could be used for cluster analysis (like it is used with PCA and other dimensionality reduction techniques) but I haven't seen it used so nor tried to use so myself, for now.
