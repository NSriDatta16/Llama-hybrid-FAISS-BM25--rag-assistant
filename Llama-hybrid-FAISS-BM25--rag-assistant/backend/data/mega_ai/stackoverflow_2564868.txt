[site]: stackoverflow
[post_id]: 2564868
[parent_id]: 2563773
[tags]: 
In terms of memory consumption, numpy arrays are more compact than Python tuples. A numpy array uses a single contiguous block of memory. All elements of the numpy array must be of a declared type (e.g. 32-bit or 64-bit float.) A Python tuple does not necessarily use a contiguous block of memory, and the elements of the tuple can be arbitrary Python objects, which generally consume more memory than numpy numeric types. So this issue is a hands-down win for numpy, (assuming the elements of the array can be stored as a numpy numeric type). On the issue of speed, I think the choice boils down to the question, "Can you vectorize your code?" That is, can you express your calculations as operations done on entire arrays element-wise. If the code can be vectorized, then numpy will most likely be faster than Python tuples. (The only case I could imagine where it might not be, is if you had many very small tuples. In this case the overhead of forming the numpy arrays and one-time cost of importing numpy might drown-out the benefit of vectorization.) An example of code that could not be vectorized would be if your calculation involved looking at, say, the first complex number in an array z , doing a calculation which produces an integer index idx , then retrieving z[idx] , doing a calculation on that number, which produces the next index idx2 , then retrieving z[idx2] , etc. This type of calculation might not be vectorizable. In this case, you might as well use Python tuples, since you won't be able to leverage numpy's strength. I wouldn't worry about the speed of accessing the real/imaginary parts of a complex number. My guess is the issue of vectorization will most likely determine which method is faster. (Though, by the way, numpy can transform an array of complex numbers to their real parts simply by striding over the complex array, skipping every other float, and viewing the result as floats. Moreover, the syntax is dead simple: If z is a complex numpy array, then z.real is the real parts as a float numpy array. This should be far faster than the pure Python approach of using a list comprehension of attribute lookups: [z.real for z in zlist] .) Just out of curiosity, what is your reason for porting the C++ code to Python?
