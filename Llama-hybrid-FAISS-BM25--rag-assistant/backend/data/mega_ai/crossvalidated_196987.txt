[site]: crossvalidated
[post_id]: 196987
[parent_id]: 
[tags]: 
How to do dimensionality reduction on a huge data set?

I am working with fMRI data of ~1000 subject. Each subject has a feature vector of ~150 million dimension. So I can only keep the feature vectors of ~10 subjects in memory. What are some algorithms that would enable me to do feature selection/ dimensionality reduction, assuming that I can only keep a fraction of the samples in memory at once?
