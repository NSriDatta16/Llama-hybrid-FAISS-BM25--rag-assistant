[site]: datascience
[post_id]: 41482
[parent_id]: 
[tags]: 
Loss is bad, but accuracy increases?

I have a multicategorial classification problem for images. There are 5 (imbalanced) classes for which i use different class weights. In general there are only a few training images per class: ~56-238 To classify them, I use a neural network with much data augmentation. I have a validation set with the same distribution as the train set (but it only has about 30% of the images per class). The resulting loss / accuracy graphs look a bit weird (edit: the second graph contains the term "Test Loss", but it is the "Validation Loss"): I'm not sure how I can interpret these two images: The validation accuracy cleary increases, but the validation loss doesn't change too much. Can anyone help me with the interpretetion of these graphs? Thank you very much
