[site]: crossvalidated
[post_id]: 642993
[parent_id]: 642794
[tags]: 
Statistics is more than about sampling. Statistics is about making a conclusion - extracting meaning - from incomplete information. If you simply repeat the information you are provided, then statistics isn't being used. If you summarize, interpret, or express it differently, then you are using Statistics. When you take the average of a set of test scores by a student, what is it you are doing? Is it merely the mechanical sum of test scores divided by the count? No, not really: nobody would care about the average of a set of test scores if it was an arbitrary mechanical operation. If it was an arbitrary mechanical operation, why not divide it by 3.14? Or multiply each test score by its test score number, add that up, then divide by the number of test scores squared? Both of these contain about the same amount of information about the original test scores, but aren't something you are doing. It is the properties of the average that you care about. Often you'll implicitly use the linear average to try to describe what score the student would do get given more testing on the same subject, usually with some validity. And many people don't even consider the spectrum of averages - geometric, logarithmic, the p-family, etc - that often have the very same properties that the linear average has. They just use the linear average out of habit. Even a test score - 70/100 say - is a fraction of the tested material the student understood. A student with a consistently high test score you presume has a grasp of the material, while one with a consistently low test score you presume does not. You could imaging a better mechanism for evaluating understanding of material; factor analysis, for example, could be used on a set of tests to determine which students lack understanding of which topics, and even to get a measure of how well the course teaches a given topic by correlating the score in a topic with other scores. As a concrete example of this, a psychology professor once used this to figure out which questions they had failed to teach the class (questions whose answer was highly uncorrelated with higher marks), based off of the idea if the answer wasn't correlated with studying the material it was a teaching failure. They had a cut off, and reduced the denominator of their exams by their failed questions (they became "bonus questions" implicitly), then sought to improve the next iteration of instruction and examination. All of these tools produce a signal, and part of Statistics is understanding if that signal is spurious. Like, if you want to know if blue jelly beans are tastier to your class. You blind taste test, and ask your subjects to rate how tasty each of a bunch of jelly beans are. The thing is, the rating someone gives a jelly bean will contain "how tasty" information plus other information you don't care about, like the mood of the student, if the student's clothing itches, the order they tasted the jelly bean, etc. You can attempt to measure the magnitude of this "random factor" by looking at the distribution of ratings. If there is a large random factor, you'd usually get more variation in sample values. So the degree to which the blue jelly beans got a higher taste score needs to be compared to the amount of variance in the signal in an attempt to determine if the higher (or lower) taste score of the jelly bean is from the jelly bean itself, or uncontrolled external random factors. All of this applies to how you use information about your students test scores. If you want to simply state what they are and don't interpret them, you are fine. But if you even take an average, or compare two subpopulation averages against each other, and don't want to be deceptive, you should use Statistical tools to determine if what you are highlighting is just noise or it is a meaningful signal. You are doing this manipulation to produce a story (even if an implicit one), and without statistical tools that story will quite likely be untrue. It is really easy to lie with numbers by accident.
