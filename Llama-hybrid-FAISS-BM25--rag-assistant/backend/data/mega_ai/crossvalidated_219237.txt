[site]: crossvalidated
[post_id]: 219237
[parent_id]: 172381
[tags]: 
I think that the cut-off of 0.5 is related to the historical factor analysis tradition of requiring a standardized loading of |0.3| (where loadings can range from -1 to 1). To see this, first transform the discrimination value into the standardized loading form with the formula $$f = \frac{a}{\sqrt{(1 + a^2)}} $$ where $a = \alpha / 1.702$ because of the scaling of the logistic metric compare to the normal ogive. In this case, $\alpha = .5$, therefore the standardized loading is $f = 0.2818$, or approximately 0.3. This matches very closely to the standardized loading cut-off, and is probably the reason why Baker adopted it. Note that in the same spirit of traditional factor analysis cut-off, this criteria is rather arbitrary and should generally be discouraged. You should be more interested in the meaning of the item to understand if this value is reasonable and contributes some amount of information to your test (indeed, some low discriminating items even have some use at the beginning stages of a computerized adaptive test), and also be mindful of the sampling variability via estimates such as the standard error.
