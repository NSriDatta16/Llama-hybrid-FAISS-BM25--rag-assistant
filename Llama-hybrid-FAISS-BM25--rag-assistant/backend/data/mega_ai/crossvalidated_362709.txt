[site]: crossvalidated
[post_id]: 362709
[parent_id]: 362703
[tags]: 
I would not call any of those metrics (adjusted $R^2$, AIC, BIC) estimations of the testing error, but they are intended to perform a similar function, and all of them can be informative. Nothing will be as unbiased as using an actual testing set, of course. To get something that takes a form that is more similar to testing error, I would suggest using cross validation and looking at the average of the cross validation error across each folds. One option in R is the caret package, which lets you do cross validation multiple times and average across of them (e.g. 5-fold CV 3 times, so it's training/testing 15 regressions).
