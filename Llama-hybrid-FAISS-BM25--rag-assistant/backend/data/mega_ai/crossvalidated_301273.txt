[site]: crossvalidated
[post_id]: 301273
[parent_id]: 233852
[tags]: 
You'll have to describe your problem a bit more But generally speaking, once you have "dense" vectors using an embedding method like Word2Vec, go ahead and use them as you would for any general input. Neural Nets (and Deep Learning architectures, as well as ML algorithms in general) simply try their best to match one vector (i.e. an ordered series of numbers; INPUT) to another (LABELS). Once you are done with training, use the "inverse" Word2Vec operation if you want to convert that dense vector to one-hot encoded vector i.e. actual words
