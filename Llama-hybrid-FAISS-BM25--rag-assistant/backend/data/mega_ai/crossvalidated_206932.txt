[site]: crossvalidated
[post_id]: 206932
[parent_id]: 
[tags]: 
Deep Learning on a weird dataset

I'm currently learning Deep learning and I'm trying to create a dnn on a dataset with difficult data to learn. There is a lot of continous attributes and there seem to be little to no difference between classes. I added noise to the datas and it seems to make my accuracy better, but I still cannot go over 55%. I also tried different activations (tanh, relu) and optimizer (RMSProp, Adam). My next idea is to use an encoder,but I don't really know how to use it on my datas. I was wondering if there is other thing that I could do to get somewhat near 75-80%. The dataset is WineQuality ( https://archive.ics.uci.edu/ml/datasets/Wine+Quality ) There is 11 attributes and 10 classes (from 1 to 10) Using Keras, I tried the following where x_train is 11 attributes. : model = Sequential() model.add(Dense(6, input_dim=(len(x_train[0])), init='uniform')) model.add(Activation('tanh')) model.add(GaussianNoise(0.01)) model.add(Dense(8, init='uniform')) model.add(Activation('tanh')) model.add(Dense(nb_classes, init='uniform')) model.add(Activation('softmax')) After 200 epochs, I only have loss: 1.0930 - acc: 0.5151 Thanks!
