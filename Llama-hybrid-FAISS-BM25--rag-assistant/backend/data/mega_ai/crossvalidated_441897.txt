[site]: crossvalidated
[post_id]: 441897
[parent_id]: 441892
[tags]: 
Let's look at three possible models: \begin{align} \mathrm{logit}(y) &= \beta_0 + \beta_1\cdot \mathrm{hours} + \beta_2\cdot \mathrm{course} + \beta_{3}\cdot \mathrm{hours}\times\mathrm{course}\tag{1} \\ \mathrm{logit}(y) &= \beta_0 + \beta_1\cdot \mathrm{hours} + \beta_2\cdot \mathrm{course}\tag{2}\\ \mathrm{logit}(y) &= \beta_0 + \beta_1\cdot \mathrm{hours} \tag{3} \end{align} where $\mathrm{hours}$ is a continuous variable and $\mathrm{course}$ is a dummy variable for one of the two courses. Model $(1)$ allows for the relationship between hours and probability of success to have i) different intercepts and ii) different slopes (i.e. non-parallel slopes). Model $(2)$ allow for the relationship between hours and probability of success to have different intercepts. Model $(3)$ assumes that the relationship between hours and probability of success is identical for both courses. We can use a likelihood ratio test to check each simpler model agains the more complex one. Here is an example using R with simulated data. The simulation assumes that $\beta_{3} = 0$ , i.e. that the lines are parallel. Specifically, I used model $(2)$ with $\beta_{0} = -65/7$ , $\beta_{1} = 5/21$ and $\beta_{3} = 9/10$ : n The likelihood ratio test comparing model $(1)$ vs. $(2)$ is: Model 1: y ~ hours + course Model 2: y ~ hours * course Resid. Df Resid. Dev Df Deviance Pr(>Chi) 1 997 442.24 2 996 440.05 1 2.1889 0.139 As expected, there is little evidence suggesting that the model containing an interaction (i.e. non-parallel lines) is warranted. Now let's compare model $(2)$ with $(3)$ : Model 1: y ~ hours Model 2: y ~ hours + course Resid. Df Resid. Dev Df Deviance Pr(>Chi) 1 998 458.20 2 997 442.24 1 15.959 6.474e-05 *** There is a lot of evidence suggesting that different intercepts are warranted (i.e. parallel slopes but one is higher than the other). Hence, we would assume that the overall probability of success is different for the two courses. This is of course expected, because we simulated it with an odds ratio of $2.46$ . The odds ratio in the simulated data is: summary(mod_2) Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -9.6567 0.6842 -14.114 Hence, the estimated odds ratio for course 2 vs. course 1 is $\exp(0.9837) = 2.67$ . We would interpret this as follows: "The odds of succeeding for participants using course 2 were 2.67 times higher than the odds of participants using course 1". To make it even clearer, we could calculate and compare the average probability of succeeding for both course types using emmeans : library(emmeans) emmeans(mod_2, "course", transform = "response") course prob SE df asymp.LCL asymp.UCL course1 0.121 0.0231 Inf 0.0754 0.166 course2 0.268 0.0360 Inf 0.1979 0.339 Confidence level used: 0.95 On average, the probability of success is $0.121$ for participants of course 1 and $0.268$ for participants of course 2. This corresponds to an odds ratio of $2.67$ . Here is a plot of the three models on the probability scale: An on the log-odds scale:
