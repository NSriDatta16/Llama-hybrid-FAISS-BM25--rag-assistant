[site]: crossvalidated
[post_id]: 268171
[parent_id]: 268126
[tags]: 
You'll almost certainly want to look at reliability engineering and predictions for thorough analyses of survival times. Within that, there are a few distributions which get used often: The Weibull (or "bathtub") distribution is the most complex. It accounts for three types of failure modes, which dominate at different ages: infant mortality (where defective parts break early on), induced failures (where parts break randomly throughout the life of the system), and wear out (where parts break down from use). As used, it has a PDF which looks like "\__/". For some electronics especially, you might hear about "burn in" times, which means those parts have already been operated through the "\" part of the curve, and early failures have been screened out (ideally). Unfortunately, Weibull analysis breaks down fast if your parts aren't homogeneous (including use environment!) or if you are using them at different time scales (e.g. if some parts go directly into use, and other parts go into storage first, the "random failure" rate is going to be significantly different, due to blending two measurements of time (operating hours vs. use hours). Normal distributions are almost always wrong. Every normal distribution has negative values, no reliability distribution does. They can sometimes be a useful approximation, but the times when that's true, you're almost always looking at a log-normal anyway, so you may as well just use the right distribution. Log-normal distributions are correctly used when you have some sort of wear-out and negligible random failures, and in no other circumstances! Like the Normal distribution, they're flexible enough that you can force them to fit most data; you need to resist that urge and check that the circumstances make sense. Finally, the exponential distribution is the real workhorse. You often don't know how old parts are (for example, when parts aren't serialized and have different times when they entered into service), so any memory-based distribution is out. Additionally, many parts have a wearout time that is so arbitrarily long that it's either completely dominated by induced failures or outside the useful time-frame of the analysis. So while it may not be as perfect a model as other distributions, it just doesn't care about things which trip them up. If you have an MTTF (population time/failure count), you have an exponential distribution. On top of that, you don't need any physical understanding of your system. You can do exponential estimates just based on observed part MTTFs (assuming a large enough sample), and they come out pretty dang close. It's also resilient to causes: if every other month, someone gets bored and plays croquet with some part until it breaks, exponential accounts for that (it rolls into the MTTF). Exponential is also simple enough that you can do back-of-the-envelope calculations for availability of redundant systems and such, which significantly increases its usefulness.
