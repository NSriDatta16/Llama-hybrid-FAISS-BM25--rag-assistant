[site]: stackoverflow
[post_id]: 1944755
[parent_id]: 1944599
[tags]: 
I've had my fair share of creating crawlers with Java using Lucene and in fact I've answered to a related question before about the actual creation process and structure of a web crawler here . This isn't directly applicable to your question but I do think it's worth mentioning here. Anyway, I have to agree with Stephen C , you're better off with pure Java or pure perl solution instead of a mix of both, however my opinion is based on the fact that they're completely different from each other and hammering two ( or more ) different mindsets together isn't usually the most optimal thing one could do. What you described also got me thinking on improving my own crawler ( the one I reference in my other answer I linked in the first paragraph ), mainly the part about the actual crawling pattern. While I do believe it will take significantly more time to develop a way to manually instruct a Java application to crawl some URL in a specific pattern as the same would take in perl, doing that in Java would eventually lead up to a lot more usable piece of software with all sorts interesting small features which wouldn't be a pain to maintain. On the other hand, the scripting side of Java is a bit meh, there is a scripting API but since scripting is about loosely defining what you want to do and Java can be annoyingly strict at times, it's not as flexible as one would hope. To really give an opinion, I think you should minimize the part of programming language which is harder to maintain. I don't know which one it is for you but I'd assume perl. Basically commit to one of the languages and use it to its full extent, don't use the other language as a shortcut.
