[site]: crossvalidated
[post_id]: 241001
[parent_id]: 
[tags]: 
Deep Learning: Use L2 and Dropout Regularization Simultaneously?

Is there a theoretical basis against using both L2 and Dropout regularization simultaneously for training a deep neural network? They are both related but could they be complementary if used together?
