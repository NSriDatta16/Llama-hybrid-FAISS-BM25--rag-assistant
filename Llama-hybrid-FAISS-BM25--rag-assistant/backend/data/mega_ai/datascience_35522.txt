[site]: datascience
[post_id]: 35522
[parent_id]: 29197
[tags]: 
If you haven't figured out what's going on already then you could try a couple of things. 1) Since you mentioned that your input values are very small, you could try normalizing them. I agree that very small (in your case, really small) values might mess up the weight updation. When you do, make sure you normalize first and then do training-testing split 2) Can you tell me how your loss looks during training? Do you see overfitting? If you do, did you use dropout? Did you try L2 regularization on the weights? (only use them on weights, not on biases) There could be a million things going on and a lot of room for improvement may be there in the network, but I need to have a look at how your loss decreases as the training proceeds. Also, you need to elaborate on how bad your results look? (I assume that your training is quite successful but your testing error is high?). Also , if you're not bound to use CNN, did you try out with an ANN with a few hidden layers and see how that model does?
