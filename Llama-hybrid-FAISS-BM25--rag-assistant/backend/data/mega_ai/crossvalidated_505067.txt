[site]: crossvalidated
[post_id]: 505067
[parent_id]: 
[tags]: 
How to Evaluate model's r-square after inverting from logarithmic

I stacked with question about inverting the r-square( r² ) model value after taking log1p() . My baseline LinearRegression model and Random Forest evaluations: Model algorithm RMSE r² MAE Random Forest 104.0874 0.9410 38.8811 LinearRegression 271.7991 0.5977 164.7908 I tried to take log1p() on y for new LinearRegression model: y_train_log = np.log1p(np.clip(y_train.copy(), 0, None)) y_valid_log = np.log1p(np.clip(y_valid.copy(), 0, None)) regr = linear_model.LinearRegression() regr.fit(X_train, y_train_log) predicts = regr.predict(X_valid) ... Results: Model algorithm RMSE r² MAE LinearRegression after log 0.866856 0.8143277 0.684246 So I am sure, I need to take expm1() on predicts and y_valid_log and only them compute RMSE and MAE in roder to compare it to previous models, so I did it: Model algorithm RMSE r² MAE LinearRegression after log 877.3852 0.8143277 156.3328 But what about r-square( r² ) ? Should I also take expm1() and only then scoring r-square( r² ) ?
