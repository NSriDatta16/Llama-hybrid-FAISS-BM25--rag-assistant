[site]: crossvalidated
[post_id]: 620438
[parent_id]: 
[tags]: 
How is OpenAI embedding obtained

There is OpenAI embedding API https://platform.openai.com/docs/guides/embeddings . How is this embedding related to the GPT3.5 transformer model architecture? Is it the vectors learned from the input embeddings part, which is the summation of word embedding and position embedding, at the end of model training? Is LLM optimized for inference task different from those LLM used for extracting embeddings? I have a large domain corpus. Is there anyway to update the word/sentence/document embedding obtained from OpenAI embedding API based on my own domain corpus? There may be some words in my corpus that are close to each other but far from each other in OpenAI embedding space. Any tutorials or guidance will be helpful.
