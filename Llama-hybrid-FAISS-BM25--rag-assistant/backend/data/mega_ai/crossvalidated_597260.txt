[site]: crossvalidated
[post_id]: 597260
[parent_id]: 596723
[tags]: 
Context Let us start with the linear regression model most people are familiar with: $$ Y_i = \beta_0 + \beta_1{X_1}_i + \beta_2{X_2}_i + \beta_3{X_3}_i + \epsilon_i $$ Here each $X_{ji}$ variable corresponds to the $j$ -covariate value for the $i$ -subject. For instance, we can assume: $X_1$ is ' sex '. A dichotomous categorical variable that takes values 1 = 'Female' and 0 = 'Male'. $X_2$ is ' weight ', but measured in tons. $X_3$ is ' height ', measured in centimeters. And let $Y$ be our outcome of interest, which can be ' hours of organized sports per week '. Trivially, if they do not take part in organized sports, the value of this variable will be 0. For instance, let us assume that our first participant ( $i = 1$ ) is "Julia". Julia is a female, she weights 0.07 tons (70 kg) and is 175 centimeters tall. She does 2.5 hours of organized sports per week. Which means that $Y_1 = 2.5; X_{11} = 1; X_{21} = 0.07$ and $X_{31} = 175$ . Then, for Julia, the model results in the following equation: $$ 2.5 = \beta_0 + \beta_1 + \beta_20.07 + \beta_3 175 + \epsilon_1 $$ Questions Normality You mention: None of the variables are normally distributed Note that this is a very common misunderstanding, that makes its way even into books, and that is addressed in multiple questions in this site (such as here and here ). What the (Gaussian with identity link generalized) linear model assumes is that the variation around the conditional mean of $Y$ given all covariates $\boldsymbol{X}$ , that is, the distribution of the $\epsilon_i$ terms, follows a normal distribution. Regression coefficients You must have heard that regression coefficient represent the amount of change in the outcome $Y$ for a one-unit change in the corresponding covariate $X_j$ (holding the other covariates constant). This definition corresponds to that of a partial derivative : $$ \frac{\partial Y}{\partial X_2} = \beta_2 $$ As you see, the definition does not exclude any range of values for the variables involved. However, there are two issues that can come up with having different scales. First, as you could have imagined, having weight in tons is not convenient. Most likely the $\beta$ coefficient will be very small, and it becomes cumbersome to interpret. Second and partially related to this point, having numbers that are too large or too close to zero can bring computational or numerical instability issues. These issues are not related to the theory of the model, but the fact that we use computers to estimate our models. Generalized Linear Models Lastly, we have seen these properties for a linear (in coefficients) model. The only thing that a generalized linear model does is to change the distributional family for the error term (e.g. to a binomial distribution) and add a transformation to the (expected value of the) outcome (or, equivalently, to the linear predictor itself). There is no requirement of distributions for the covariates, nor restrictions on the range of the values they can take. For example, say we will change our outcome $Y$ to represent whether someone does more than 2 hours of organized sports per week or not. The outcome is now binary, so we will fit a GLM with a binomial error distribution (which is not present since we took the expected value) and a logit transformation of the expected value. This is better known as a logistic regression: $$ \ln\left(\frac{\mathbb{E}[Y_i|\boldsymbol{X}_i]}{1 - \mathbb{E}[Y_i|\boldsymbol{X}_i]}\right) = \beta_0 + \beta_1{X_1}_i + \beta_2{X_2}_i + \beta_3{X_3}_i $$
