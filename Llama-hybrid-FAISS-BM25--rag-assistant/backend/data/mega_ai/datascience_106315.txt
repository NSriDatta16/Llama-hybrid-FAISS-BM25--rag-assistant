[site]: datascience
[post_id]: 106315
[parent_id]: 106308
[tags]: 
If your model type allows for incremental learning as neural nets do, you can train new examples from previously fitted models to save on fit time. This is known as online learning. If your model does not support this, you could implement a “decayed conveyor belt” strategy on your data where you sample and train with the last n datapoints with more probability than the old ones. In this case, I would make sure a chunk of the train data is the same between any two or all model versions as a way to influence a constant learned behavior. Beware that training like this may make the model sensitive to seasonality patterns and biased towards process drifts even if your data is not a time series, so you may need to account for this when sampling, normalizing or evaluating the models.
