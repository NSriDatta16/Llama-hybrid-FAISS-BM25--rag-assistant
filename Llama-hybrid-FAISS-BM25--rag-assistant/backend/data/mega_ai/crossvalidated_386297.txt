[site]: crossvalidated
[post_id]: 386297
[parent_id]: 386267
[tags]: 
In addition to the points raised by @Michael M, we have to look at what exactly we mean by "outperform". One purpose of many statistical analyses is prediction. For this, I think RF might always be better than linear regression (I'm not sure about that, but it seems to be so, more knowledgeable users can bring up exceptions and details, Michael mentions one possibility; and, in a comment, @whuber mentions another). But sometimes prediction is only part of our aim and sometimes it isn't even a part. Another goal of many analyses is explanation. Linear and logistic regression results explain the relationships among the independent and dependent variables in ways that may add to knowledge - or that may indicate some problem in the data or something to look into or whatnot. In his wonderful book Statistics as Principled Argument Robert Abelson talks about another reason why regression might be better: It can be part of a principled argument in ways that would be difficult for random forests.
