[site]: datascience
[post_id]: 121432
[parent_id]: 84350
[tags]: 
Vanishing gradient as explained in the Xavier Glorot paper "Understanding the difficulty of training deep feedforward neural networks" can be seen as a shift of the mean of the gradient to lower values with small standard deviations when considering each layers from the output to the input. There is no specific threashold to measure the vanishing gradient since it depends on you data, loss, network, etc. Only monitoring the mean- and std- of the gradient on each layer during multiple training epochs can help to make you own interpretation.
