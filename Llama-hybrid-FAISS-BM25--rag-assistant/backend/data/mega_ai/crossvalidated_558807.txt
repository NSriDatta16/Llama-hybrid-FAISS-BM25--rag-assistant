[site]: crossvalidated
[post_id]: 558807
[parent_id]: 558790
[tags]: 
One exponential observation. Suppose you buy an electronic device that is advertised to have an exponential lifetime averaging 60 months (5 years). It turns out that yours dies at two months. You would feel cheated. In statistical terminology you might test $H_0: \mu = 60$ against $H_a: \mu You could reject $H_9$ at the 5% level. If $X\sim\mathsf{Exp}(\mathrm{rate}=1/60),$ then $P(X \le 2) = 0.033.$ [Using R:] pexp(2, 1/60) [1] 0.0327839 Without the jargon of hypothesis testing, you might say that if the true average lifetime were 60 months, then the 'probability' of such a short lifetime for your device is $0.033,$ which is unreasonably small. Alternatively, you might say that you had 'confidence' that the device would last longer than two months. In ordinary English, there isn't much difference between the words probability and confidence. If you knew about the frequentist definition of probability, you might say, "If $\mu=60,$ then only three or four people out of 100 would have such bad fortune." But you might choose to dwell mainly on your own situation, without reference to an imaginary group of 100 other people. Of course, there is no way for you to know the true mean lifetime for sure, but you could reasonably feel that it's not actually 60 months. Random sample from an exponential population. Now suppose that ten people buy this device and that their average failure times were $\bar X_{10}.$ Then one has the relationship $$\frac{\bar X_{10}}{\mu} \sim \mathsf{Gamma}(\mathsf{shape}=10, \mathsf{rate}=10),$$ which can be 'pivoted' to give the probability statement $$P\left(\frac{\bar X}{U} \le \mu \le \frac{\bar X}{L}\right) = 0.95,$$ where $L$ and $U$ cut probability $0.025$ from the lower and upper tails, respectively, of $\mathsf{Gamma}(10,10).$ For example. if a random sample of size ten from an exponential population has $\bar X_{10} = 22.3,$ then a 95% 'confidence' interval for $\mu$ is $(13.1, 40.5).$ 22.3/qgamma(c(.975,.025), 10, 10) [1] 13.05254 46.50301 As long as we have no data at hand or we do not know the true value of $\mu,$ the displayed equation is a straightforward probability statement. But as soon as you have data, some people begin to fret that depending on $\bar X$ and $\mu$ the statement between parentheses (in the display above) is either true or false. To make peace with such people, there seems to be an agreement that it is OK to use the word 'confidence' for that expression, but to avoid the word 'probability'. Somehow, these people feel that the 'probability' has collapsed to become meaningless. Never mind that the true value of $\mu$ will never be precisely revealed in any practical situation. I feel that exactly the same quibble might be made concerning the probability statement earlier $P(X \le 2) = P(X\le 2\,|\,\mu)$ about your purchase of one electronic device. But somehow, that probability statement gets a free pass, possibly because we have previously speculated about a value of $\mu.$ So we don't need to call that a 'confidence' statement. What to tell students and clients? It's OK to say, "There's 95% probability/ chance/ confidence that this random interval includes the unknown true value of $\mu."$ But in writing, your life will be simpler if you use the customary (diplomatic) word confidence . [Sometimes, even that is not enough to avoid controversy. There are contradictor and deeply-held views about the meaning(s) of frequentist confidence intervals. (See comments.)] Notes: (1) In a Bayesian context, a prior distribution along with the likelihood function of data lead to a posterior probability distribution from which a Bayesian 'probability' or 'credible' interval is determined. Then quibbles about the applicability of the interval estimate to the current investigation disappear. (2) The German philosopher Schopenhauer once said, "Philosophy is the systematic abuse of a terminology established just for that purpose." [my translation]. The quibble about the use of words 'probability' and 'confidence' may put frequentist statistical inference in a similar position.
