[site]: crossvalidated
[post_id]: 267847
[parent_id]: 
[tags]: 
Motivation for average log-likelihood

In maximum likelihood estimation, I sometimes see the average likelihood function $\frac{1}{N}\mathcal{L}(\theta, x)$ used over the likelihood. Since maximum likelihood estimation optimises over the parameters $\theta$, I dont see the motivation for averaging, since it doesnt change the maximim of $\mathcal{L}(\theta, x)$. Can someone give me some intuition for why we might want to divide by $N$?
