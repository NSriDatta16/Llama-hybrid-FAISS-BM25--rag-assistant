[site]: crossvalidated
[post_id]: 220485
[parent_id]: 
[tags]: 
Sample dependency in Neural Net Training cross-validation

I've created a Monte Carlo simulation that randomly divides my data into "test" and "training"-Samples and then trains a neural network. The ratio of 0 and 1 (19.62%) Category is stabilized on sampling. My results show a highly fluctuating model accuracy ( min =0.6452, M =0.7792, max =0.8925). What could be possible reasons for this effect and how should I choose a test/train/model for my discussion?
