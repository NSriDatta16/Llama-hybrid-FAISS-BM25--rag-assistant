[site]: crossvalidated
[post_id]: 352430
[parent_id]: 
[tags]: 
What is the meaning of the average value of all word vectors in the sentence?

Today I saw a sentiment analysis article here . There is one piece hard to understand: Next we have to build word vectors for input text in order to average the value of all word vectors in the tweet using the following function: #Build word vector for training set by using the average value of all word vectors in the tweet, then scale def buildWordVector(text, size): vec = np.zeros(size).reshape((1, size)) count = 0. for word in text: try: vec += imdb_w2v[word].reshape((1, size)) count += 1. except KeyError: continue if count != 0: vec /= count return vec Scaling moves our data set is part of the process of standardization where we move our dataset into a gaussian distribution with a mean of zero, meaning that values above the mean will be positive, and those below the mean will be negative. Many ML models require scaled datasets to perform effectively, especially those with many features (like text classifiers). He just add up all word vectors in the sentence(tweet), divide by word count, turning to a new vector for training. As I know, a word vector is a hidden layer's parameters. So the average value of those hidden layer's parameters, what's the meaning it present and why it can be used for training?
