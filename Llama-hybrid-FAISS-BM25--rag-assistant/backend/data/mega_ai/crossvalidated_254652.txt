[site]: crossvalidated
[post_id]: 254652
[parent_id]: 
[tags]: 
Feature normalization training dataset

I'm trying to understand logistic regression by training a classifier on the MNIST dataset (a list of hand written digits represented as a list of pixel intensities). I read about feature normalization ( https://en.m.wikipedia.org/wiki/Feature_scaling ) but I'm not sure how to apply it to my problem on hand. The training data looks like this: P1, P2, P3, ... P748 0, 0, 180, ... 240 0, 50, 150, ... 0 0, 0, 0, ... 108 So each row describes a separate image, and each column represents the same pixel (P1 is the pixel in the upper left corner of the image, P2 is the next pixel to the right, etc.) Question 1 When normalizing the data, do I normalize each instance (where min and max refer to the values within that row) or do I normalize each feature across the entire training dataset (where min and max of P1 refers to the values within every last training example - potentially many dozens of thousands of values)? Question 2 After the classifier is trained with normalized data, what do I do with a new data sample that I want to run through the classifier? Do I normalize every feature against each other (where min and max refer to values across P1 - P748 within a single instance)?
