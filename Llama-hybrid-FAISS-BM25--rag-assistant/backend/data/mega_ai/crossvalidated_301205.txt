[site]: crossvalidated
[post_id]: 301205
[parent_id]: 
[tags]: 
Accuracy on deep learning model

Every epoch I'm logging the accuracy of a deep learning method on the test set. These are the results so far. The whole run is 150 epochs 0,33.6057 1,38.0719 2,62.037 3,66.3943 4,64.6514 5,44.4989 6,44.2266 7,59.5861 8,45.7516 9,47.7124 10,49.6732 11,48.5839 12,45.8606 13,50.1089 14,52.3965 15,56.7538 16,53.3769 17,51.6885 18,57.7342 19,58.6601 20,57.0806 21,59.3682 22,41.7756 23,42.1024 24,58.9869 25,57.5163 26,57.4619 27,58.4423 The value after the comma is the accuracy percentage. Is this a normal behavior or are the changes in accuracy too big and inconsistent? What general things can I further explore to improve on the results? Edit to add more information: It is a semi-supervised model Labeled data size for training: 7408 Unlabeled data size for training: 46077 Test data size: 1836 Mini-batch size: 100 Layers: [3000, 4000, 2500, 1000, 500, 250, 2] Activation: lrelu for hidden layers and softmax output layer Learning rate: Testing both 0.01 and 0.02. Both behave similarly as far as I can see. Decay after 15th epoch It is an implementation of this model with some few changes: https://github.com/rinuboney/ladder EDIT 2: Actually learning rate 0.01 seems to be behaving more estable
