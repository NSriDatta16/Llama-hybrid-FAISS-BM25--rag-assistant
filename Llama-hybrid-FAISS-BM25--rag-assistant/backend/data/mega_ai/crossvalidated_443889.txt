[site]: crossvalidated
[post_id]: 443889
[parent_id]: 
[tags]: 
Using label encoder on a categorical feature that we want to embed

I have a dataset with feature that have very high cardinality, doing one-hot encoding is not an option because of memory limitations, so I am currently label encoding this feature and then I feed that to a tensorflow embedding layer, then I train my whole network. Is it okay to use label encoder this way ? (I know that usually we shouldn't use it for features, but I feel like here the labels are only used as lookup for the embedding layer) How does the embedding layer learn the embedding, I couldn't find anywhere on google a clear explanation on how the computation for creating the embeddings is done.
