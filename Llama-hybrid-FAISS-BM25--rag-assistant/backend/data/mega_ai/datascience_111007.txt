[site]: datascience
[post_id]: 111007
[parent_id]: 
[tags]: 
How to solve this ValueError: Dimensions must be equal

I'm trying to train an autoencoder model with colored image samples but I got this error ValueError: Dimensions must be equal, but are 476 and 480 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_4/conv2d_28/BiasAdd, IteratorGetNext:1)' with input shapes: [?,476,476,1], [?,480,480,3]. although i have checked the dimensions of the test and training sets all are (480,480,3) from matplotlib import image,pyplot import cv2 IMG_HEIGHT=480 IMG_WIDTH=480 def prepro_resize(input_img): oimg= cv2.imread( input_img, cv2.COLOR_BGR2RGB) return cv2.resize(oimg, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA) x_train_ = [(prepro_resize(x_train[i])).astype('float32')/255.0 for i in range(len(x_train))] x_test_ = [(prepro_resize(x_test[i])).astype('float32')/255.0 for i in range(len(x_test))] the code for adding noise is noise = augmenters.SaltAndPepper(0.1) seq_object = augmenters.Sequential([noise]) train_x_n = seq_object.augment_images(x_train_ * 255) / 255 val_x_n = seq_object.augment_images(x_test_ * 255) / 255 all of the above line of codes work propertly but the previosly mentioned error occures on running model fit history = model.fit(x_train_,train_x_n, epochs=10, batch_size=128) i've assured that all of the samples and noise images are colored of shape(480,480,3)
