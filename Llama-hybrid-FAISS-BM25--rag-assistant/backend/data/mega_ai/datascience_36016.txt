[site]: datascience
[post_id]: 36016
[parent_id]: 
[tags]: 
KL divergence for time-series prediction

I am training a model to predict time series data. I would like the residuals of the model to be approximately normally distributed, as this is convenient for making probabilistic statements. The model I'm considering works as follows, with i/o scaled to into the same range: Batch of observations ↴ Batch of inputs ⟶ Batch of outputs ⟶ Batch of residuals ⟶ Bins The model is then trained using KL divergence so that the bins approximate a (discrete) normal distribution on the batch. What I'm having trouble with is the binning part. I need a layer where the activation of each node is roughly the proportion of samples in the batch that are in each bin. That is to say, if there are 100 samples in the batch and 15 of them result in a residual between -0.1 and 0.1 , then the activation of the the " [-0.1,0.1] neuron" should be close to 0.15 .
