[site]: crossvalidated
[post_id]: 227025
[parent_id]: 226992
[tags]: 
Dropping the incomplete cases, called ''complete case analysis'' almost always leads to biased and inefficient estimates. This can only be avoided under very stringent assumptions namely when the missing is completely at random (missing completely at random or MCAR): see this link for details. This is because you lose information that is available in the incomplete cases. Replacing the missing values by other another value, the so-called ''single value imputation method'', has similar shortcomings. If e.g. you replace the missing value by the average, then the ''overall'' average will remain OK, but the variability of the data (standard error) will be underestimated. The state of the art methods are (1) maximum likelihood estimation and (2) multiple imputation methods. If your estimates are obtained by maximum likelihood using all (complete and incomplete) cases then under less stringent assumptions (missing at random or MAR, see link supra) you will get unbiased and efficient estimates. This is because under certain assumptions (MAR) the likelihood function is not impacted by the missingness (see link supra for details). Multiple imputation replaces a missing value with more than one alternative (see link for the details) and then ''averages out'' the results. It also leads to less biased and efficient estimates when the missings are MAR. This is because the imputation by multiple values ''re-introduces'' additional variability compared with imputation by only one value (see link supra for details).
