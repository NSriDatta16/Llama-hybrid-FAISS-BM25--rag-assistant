[site]: crossvalidated
[post_id]: 420172
[parent_id]: 222584
[tags]: 
TL;DR We can say that, when we move from RNN to LSTM (Long Short-Term Memory), we are introducing more & more controlling knobs, which control the flow and mixing of Inputs as per trained Weights. And thus, bringing in more flexibility in controlling the outputs. So, LSTM gives us the most Control-ability and thus, Better Results. But also comes with more Complexity and Operating Cost. Reference [ NOTE ]: GRU is better than LSTM as it is easy to modify and doesn't need memory units, therefore, faster to train than LSTM and give as per performance. Actually, the key difference comes out to be more than that: Long-short term (LSTM) perceptrons are made up using the momentum and gradient descent algorithms. This image demonstrates the difference between them:
