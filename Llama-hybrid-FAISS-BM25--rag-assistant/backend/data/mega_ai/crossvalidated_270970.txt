[site]: crossvalidated
[post_id]: 270970
[parent_id]: 241082
[tags]: 
The issue with performing inference after model selection is that you are selecting the most predictive variables and then performing inference as if they were selected independently of the data. It is possible to show that refitting the regression model after doing model selection with the lasso (or any other model selection method!) may lead to $\sqrt{n}$ -biased estimates (which is one reason why a simple Gaussian approximation will often fail for confidence intervals) Fortunately, there has been much progress in recent years in developing inference methods that account for post-selection. Some relevant references for your case are: Exact post-selection inference, with application to the lasso and, Post-selection inference for l1-penalized likelihood models by Jonathan Taylor and Robert Tibshirani, Stanford University . The techniques discussed in these references are implemented in the R package selectiveInference- selectiveInference: Tools for Post-Selection Inference | CRAN . The selectiveInference package should produce the valid confidence intervals you need.
