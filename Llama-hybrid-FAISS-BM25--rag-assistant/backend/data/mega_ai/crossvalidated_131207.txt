[site]: crossvalidated
[post_id]: 131207
[parent_id]: 
[tags]: 
Bayes Linear regression- logarithmic transformation of prior distribution of the variance

I have a Bayesian version of a linear regression with 3 covariates. The model is given by \begin{align*} Y\sim N(\mu,\tau)\end{align*} \begin{align*} \mu=\alpha + \sum\beta_{i}x_{i}\end{align*} where $Y=log(Y)$ and $\beta_{i}$ has the following flat priors \begin{align*} \alpha \sim N(0,0.00001)\end{align*} \begin{align*} \beta_{1} \sim N(0,0.00001)\end{align*} \begin{align*} \beta_{2} \sim N(0,0.00001)\end{align*} \begin{align*} \beta_{3} \sim N(0,0.00001)\end{align*} \begin{align*}\tau \sim \Gamma(\alpha=0.001,\beta=0.001)\end{align*} Hence if $\tau$ has a gamma distribution as prior and keeping in mind that $\frac{1}{\tau}$ = $\sigma^{2}$, $\sigma^{2}$ must have an inverse gamma distribution as prior. 1) How do I show that $\sigma^2$ has a inverse gamma distribution as a prior? 2) From the above, how do I derive the prior distribution of $log(\sigma^{2})$? (Essentially, this question is about using change of variable, it is not related to estimation. We have a random variable $\sigma^{2}$ which has an inverse gamma distribution and we want to find the density function of $log(\sigma^{2})$ which is a function of $\sigma^{2}$).
