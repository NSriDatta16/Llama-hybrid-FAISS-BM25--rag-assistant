[site]: crossvalidated
[post_id]: 333571
[parent_id]: 333493
[tags]: 
Q1. Proof Given $\mathbf A$ that is square or tall, we want to maximize $\operatorname{tr}(\mathbf A^\top \mathbf X)$ subject to $\mathbf X^\top \mathbf X=\mathbf I$. Let us denote by $\mathbf A = \mathbf{USV}^\top=\mathbf{\tilde U}\mathbf{\tilde S}\mathbf V^\top$ the "thin" and the "full" SVD of $\mathbf A$. Now we have: \begin{align} \operatorname{tr}(\mathbf X^\top \mathbf A) &= \operatorname{tr}(\mathbf X^\top \mathbf {\tilde U}\mathbf {\tilde S}\mathbf V^\top) = \operatorname{tr}(\mathbf {\tilde S} \mathbf V^\top\mathbf X^\top\mathbf{\tilde U}) \\&= \operatorname{tr}(\mathbf{\tilde S} \mathbf P) = \sum s_i P_{ii} \le \sum s_i = \operatorname{tr}(\mathbf S). \end{align} Here what I called $\mathbf P$ is a matrix with orthonormal rows as can be verified directly: $$\mathbf P\mathbf P^\top = \mathbf V^\top\mathbf X^\top\mathbf{\tilde U} \mathbf{\tilde U}^\top \mathbf X \mathbf V = \mathbf I.$$ So $\mathbf P$ must have all its elements not larger than one. It follows that the whole expression is not larger than the sum of singular values. Using $\mathbf X = \mathbf{UV}^\top$ yields exactly this value of the trace, hence it is the optimum. QED. (This proof can be found e.g. in Gower & Dijksterhuis, Procrustes Problems , section 5.1. The proof is a little less confusing when $\mathbf A$ is square because then the thin and the full SVDs coincide.) Q2. How is it called? Very similar problems have been studied in several different areas. I found three (!). FIRST, there is orthogonal Procrustes problem : given $\mathbf A$ and $\mathbf B$, find orthogonal matrix $\boldsymbol\Omega$ minimizing $\|\mathbf A - \mathbf B\boldsymbol\Omega\|^2$. Writing it as $$\|\mathbf A - \mathbf B\boldsymbol\Omega\|^2 = \|\mathbf A\|^2 + \|\mathbf B\|^2 - 2\operatorname{tr}(\mathbf{AB}^\top\boldsymbol\Omega),$$ we see that the solution is given by the SVD of $\mathbf{AB}^\top$. A related problem is minimizing $\|\mathbf A - \mathbf B\boldsymbol\Omega\|^2$ when $\boldsymbol\Omega$ is not square and has orthonormal rows . It has exactly the same solution. Actually, my problem can be seen as exactly this one when $\mathbf B=\mathbf I$. However, when $\boldsymbol\Omega$ is not square and has orthonormal columns , the problem does not have a closed-form solution (see Procrustes Problems referenced above.) SECOND, there is an orthogonalization problem: given $\mathbf A=\mathbf{USV}^\top$, find a square matrix $\boldsymbol\Omega$ that would make $\mathbf A\boldsymbol\Omega$ have orthonormal columns such that $\|\mathbf A - \mathbf A\boldsymbol\Omega\|^2$ were minimal. We already saw that the best $\mathbf A\boldsymbol\Omega$ is $\mathbf{UV}^\top$, and in order to achieve that $\boldsymbol\Omega$ should be equal to $\mathbf V\mathbf S^{-1}\mathbf V^\top = \mathbf C^{-1/2}$ where $\mathbf C = \mathbf A^\top\mathbf A$. This is apparently known in physical chemistry as Löwdin's symmetric orthogonalization! According to Mayer, 2002, On Löwdin's method of symmetric orthogonalization , Löwdin's symmetric orthogonalization scheme is well known to everybody working in quantum chemistry. It was introduced in 1950 [1] as a tool for transforming the generalized eigenvalue problem obtained in overlapping basis sets to an equivalent “standard” eigenvalue problem valid in an auxiliary orthogonal basis. (Many of us call the latter simply the “Löwdin basis.”) [...] In 1957 Carlson and Keller proved [2] that the symmetrically orthogonalized (or simply “Löwdin-orthogonalized”) orbitals have a remarkable property: among all the possible orthonormal functions, the symmetrically orthogonalized ones are the closest in the least-squares sense to the original nonorthogonal functions. THIRD, there is a problem of whitening: given centered $\mathbf A=\mathbf{USV}^\top$, find a square matrix $\boldsymbol\Omega$ that would make $\mathbf A\boldsymbol\Omega$ have uncorrelated columns with unit variance such that $\|\mathbf A - \mathbf A\boldsymbol\Omega\|^2$ were minimal. This of course differs from symmetric orthogonalization only by a constant, and the solution is $\boldsymbol\Omega = \mathbf C^{-1/2}$ where $\mathbf C = \mathbf A^\top\mathbf A/n$ is the corresponding covariance matrix. This is called ZCA whitening. See my own answer in What is the difference between ZCA whitening and PCA whitening? and e.g. Kessy et al., 2018, Optimal Whitening and Decorrelation .
