[site]: crossvalidated
[post_id]: 289051
[parent_id]: 
[tags]: 
Estimating error from an autocorrelated random walk

Hello Cross Validated, I am trying to simulate autocorrelated, lognormal values such that their SD matches that of an existing time series. I plan to generate these values using the following function: $$ X_t=\rho X_{t−1}+ \sqrt {1-\rho^2} \varphi $$ where $ \varphi \sim N(0,\sigma^2)$ I have an observed time series from which I would like to estimate $ \sigma^2 $, given a fixed $\rho $. I'm not sure if I can do this mathematically, or if I should just fit the observed time series to the above model, and am overthinking the whole thing. My end goal is to simulate an autocorrelated time series that has similar error structure to the existing one. Is there an equation out there in time series world for $ \sigma^2 $, based on $X_t$, $X_{t−1}$ and $\rho $? Thank you in advance for your help.
