[site]: datascience
[post_id]: 53225
[parent_id]: 
[tags]: 
Why does the logistic regression cost function need to be the negative of log?

I am going through this course. The professor is talking about the logistic regression cost function: $$ P(y|x) = \hat y^y (1- \hat y)^{(1-y)} $$ Taking log on both sides provides: $$ \begin{align} log[P(y|x)] &= log[\hat y^y (1- \hat y)^{(1-y)}]\\ &= - L(\hat y,y) \end{align} $$ Why does the logistic regression cost function need to be the negative of log?
