[site]: crossvalidated
[post_id]: 576355
[parent_id]: 
[tags]: 
Showing that the given critical value (?) gives a test with significance level 0.05

So I have a maths problem that I'm struggling to understand... The original language isn't English, but I have done my best to translate the necessary background information into English. Assume that we have observed the following values: 0.50, -0.15, 2.82, 0.68, 0.19, 1.23, -1.65, 2.38, -0.49, 1.59, 0.66, -0.12, 1.20, 1.08, 0.82 from a sample $X_1, X_2,...,X_{15}$ where $X\sim N(\mu,1)$ for $i=1,2,...,15$ and $\mu$ is an unknown parameter. We are interested in the following two hypotheses: $H_0:\mu=0\\ H_1:\mu=0.5$ Let $W=\frac{1}{15}(X_1,X_2,...,X_{15})$ be the average of the sample, and for $c>0$ observe the test that accepts the null hypothesis if $W\leq c$ . For the following, we will test the null hypothesis $H_0$ at a significance level $\alpha=0.05$ . What I need help with: How do I show that $c=0.4247$ gives a test with a significance level of $\alpha=0.05$ ? My initial thought was to check if the area under the graph for the normal distribution with mean 0 and variance 1 was 0.05 to the right of the critical value, but I got 0.34 instead (thought the critical value looked a bit off when I drew the graph...). I don't know what I've overlooked. My best guess is that my "critical value" isn't actually the critical value.
