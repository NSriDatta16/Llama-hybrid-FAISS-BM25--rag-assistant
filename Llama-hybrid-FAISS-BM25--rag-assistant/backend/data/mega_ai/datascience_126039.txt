[site]: datascience
[post_id]: 126039
[parent_id]: 
[tags]: 
How to do feature selection correctly in xgboost for time series forecasting after obtaining a good predictive model?

I have a very large dataset (~7 million rows) for which I have extracted ~500 features during feature engineering phase. I have trained an XGBoost which has a fairly good predictive capability (based on the metrics on the test set by cross-validation for time series). Now I would like to reduce the number of input variables to the model to speed up the training, but I don't know what method to use or how to select them. (When exploring the weight, gain and coverage values, I see that some variables with high weight have very low gain. Which method to choose? Are there others?)
