[site]: crossvalidated
[post_id]: 111051
[parent_id]: 
[tags]: 
Learned production test

To validate the acoustic performance of a product, we are using hand-engineered features and thresholds. Everytime a new hardware problem arises we have to at least tweak a parameter and at worst add a new feature with its own parameters. We now have tens of thousands of records, with some labeled, and I'm thinking it might good to switch to a completely learned test to just have to add new labeled data when new faults are detected or even better ask for labeling when something unusual is detected. Background The speaker plays a sine sweep of 1 sec recorded by several microphones. Here's what its magnitude looks like in the frequency domain: If the speaker were perfect, we would have only the first ramp, but this one is already fairly good. Here are just a few examples of the kind problems that occur: a badly glued wire that resonates at a particular frequency a huge harmonic distortion, on a particular range or everywhere an engineer who decides to replace a drop of glue by a screw (rather low) external noises: an operator who sneezes while another one relates its week-end, a machine running etc. Possible difficulties an extremely low false negative rate compute power and memory are scarce resources since the test is run by the product itself Questions First of all, do you think we should stick with our current approach ? I can't really afford to ask for a few weeks of work on this path if that's a dead end. I'm thinking about treating the subject as being an image classification problem. Would you treat the whole records at once or slice them in peaces (since things like harmonic distortion have the same "shape" whatever the frequency) ? I'd like an excuse to play with Boltzmann machines and deep neural networks, do you have the feeling that it's not a good direction to go ? Maybe I'm in the wrong place to ask such an open and non-technical question...
