[site]: crossvalidated
[post_id]: 300761
[parent_id]: 
[tags]: 
Understanding the connection between 2 ways to write a logistic regression model

I'm currently enrolled in a regression models course through Coursera and am having trouble conceptually understanding logistic regression. I've attached a picture of "where" I'm having trouble. Linear vs logistic regression Linear $$ RW_i = b_0 + b_1RS_i + e_i $$ or $$ E[RW_i|RS_i, b_0,b_1] = b_0+b_1RS $$ Logistic $$ {\rm Pr}(RW_i|RS_i,b_0,b_1) = \frac{\exp(b_0+b_1RS)}{1+\exp(b_0+b_1RS)} $$ or $$ \log\bigg(\frac{{\rm Pr}(RW_i|RS_i,b_0,b_1)}{1-{\rm Pr}(RW_i|RS_i,b_0,b_1)}\bigg) = b_0+b_1RS $$ In this particular example, the lecture is about modeling Bernoulli outcomes. I understand that when modeling binary data in a linear fashion, the expected value of the outcome is the probability of said outcome (first two formulas in the picture). What I'm having trouble with is where the second two formulas came from and how they can be interchanged (in the lecture, he says if we "invert/work with" [the 3rd formula] it can be rewritten as the 4th formula) I'd like to know the connection between the last two equations and how they should be interpreted.
