[site]: datascience
[post_id]: 124020
[parent_id]: 
[tags]: 
How can we use a transfomer model with new data if we still don't have the output?

Transformer models are trained using inputs and outputs. They are both embedded and encoded and used to train multi-head attention mechanisms... But how can we use a transformer model to predict new data? We won't have any "output" to feed the model yet. For example you use English and Spanish text to create a dictionary. But when you want to translate new English text you don't know the translation yet.
