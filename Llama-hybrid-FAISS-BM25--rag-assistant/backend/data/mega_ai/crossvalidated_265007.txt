[site]: crossvalidated
[post_id]: 265007
[parent_id]: 262776
[tags]: 
Your idea of features is actually correct, I implemented a RL agent that learns to play Pac-Man: in a small environment it can use classic RL algorithms and actually store a Q table for each possible state/action tuple, but as you said when the space becomes larger it becomes intractable. In this case, I used features like the presence if ghosts or food nearby as an inout of a neural network, and I was able to train it to win every game. Radial Basis functions allow you to extend, in a sense, your input to a ML algorithm or a NN, if used on the input data as a kernel, to apply the "kernel trick". In this way you can exploit non linear aspects of the I put data to classify with non linear boundaries. A similar concept is thus applied in the field of RL, using the state input data.
