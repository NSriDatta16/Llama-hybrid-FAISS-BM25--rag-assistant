[site]: crossvalidated
[post_id]: 55891
[parent_id]: 55888
[tags]: 
Edit: I assume you mean the conditional mean of the errors is zero. Imagine if the errors had a common nonzero mean - $\mu_\varepsilon$, say, and you fitted a least square model. What would happen? It would be absorbed by the constant, and the residuals would on average be zero. So you can't test whether the residuals have a common mean that's not zero. What you can check is whether the residuals (and by implication the errors that they estimate) have constant mean; on average they're still zero, but conditionally they may have means some distance from zero. The usual way to check that is a plot of residuals against the predictor(s), or if there are more than a couple of predictors, at least against fitted values. Here's the first diagnostic plot of the ones R will give by default when you plot the result of a regression: plot(lm(dist~speed,data=cars)) It has a loess smooth superimposed, but without the curve you can still discern that the points tend to sit above the zero line at each end and perhaps below it in the middle. You can immediately see that the linearity assumption is somewhat suspect, and that perhaps some curved relationship is present.
