[site]: crossvalidated
[post_id]: 263564
[parent_id]: 
[tags]: 
Overfitting in object detection?

I've heard different definitions of overfitting. One of them is "if the training error continues to decrease but testing error begins to increase at some point, it is overfitting". The other, "if the training mAP is way higher than testing mAP it is overfitting". I've even seen a definition saying "test score Which one of them actually applies specifically to object detection? I encountered a situation where both my train mAP and test mAP increases (test mAP - very slightly, sometimes fluctuate a little but no downward trend). But the difference between the two can increase by quite a bit i.e. train mAP is increasing at a faster rate than test mAP is. I've sometimes seen a big difference of around 20%. Should I train for more epochs until I begin to see a downward trend in test mAP? Will there always be such a trend? Could I adjust any parameters such as learning rate so that I can see this trend faster? *note: mAP values are averaged across a 5-fold CV Sample of my mAP values (mAP vs iterations):
