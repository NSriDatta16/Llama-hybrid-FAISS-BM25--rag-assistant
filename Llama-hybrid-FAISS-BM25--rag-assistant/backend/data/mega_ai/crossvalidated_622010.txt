[site]: crossvalidated
[post_id]: 622010
[parent_id]: 621971
[tags]: 
Here is a consistent estimator based on method of moments. Suppose \begin{align} X &\sim N(\mu,\sigma^2)\\ Y &=\max(U,X)\\ p &=P[Y>U]\\ q &=E[Y-U]\\ r &=E[(Y-U)Y] \end{align} where we estimate $p,q,r$ from averages of the data in the problem. Those variables are defined by integrals, and the integrals lead to an equation which we can solve numerically for $\mu$ : $$\sqrt{\frac{r-q\mu}{2\pi p}}\,\exp\left(\frac{-p(\mu-U)^2}{2(r-q\mu)}\right)=q-p(\mu-U).$$ This equation has the following interpretation: Let $s=\sqrt{(r-q\mu)/p}$ , which is equal to $\sigma$ if we have the exact values for $\mu,p,q,r$ . Let $Z\sim N(\mu,s)$ . Then $$f_Z(U) = \frac{q - p(\mu-U)}{s^2}.$$ Example : Suppose we use this procedure with 100 standard normal variables with a left cutoff at $u=1$ . Simulating this 1000 times, I found estimated means that are only slightly biased, averaging around -0.006 with a standard deviation around 0.3. The accuracy is even better for lower cutoffs. roots = c() for(i in 1:100000){ u = 1 x = rnorm(100) y = pmax(x,u) p = mean(y>u) q = mean(y-u) r = mean((y-u)*y) f = function(mu){ s2 = max(0,(r-q*mu)/p) ex = exp(-(u-mu)^2/(2*s2)) return(sqrt(s2/(2*pi)) * ex - (q-p*(mu-u))) } if(f(-r/q)>0) root = r/q else root = uniroot(f, c(-r/q, r/q))$root roots = c(roots, root) } hist(roots) c(mean(roots), sd(roots))
