[site]: crossvalidated
[post_id]: 601562
[parent_id]: 
[tags]: 
How to handle physically meaningless values in sampling?

I'm working on stochastic optimization for optimal energy dispatch, where the uncertainty of photovoltaic power output should be considered with monte carlo sampling and scenario reduction technique. In most literature I've read, the power output uncertainty of the photovoltaic module $P_{PV}$ is usually considered as the sum of some prediction value from a machine learning model $P$ and the prediction error $\varepsilon$ . $$ P_{PV} = P + \varepsilon $$ The papers usually consider $P$ as a constant and $\varepsilon$ as a random parameter that is normally distributed $\varepsilon \sim N(0, \sigma)$ . From the physical point of view, it is clear that the power output of the photovoltaic must exceed zero (otherwise it consumes energy instead of making it), and it must be lower than its maximum capacity $P_{max}$ . $$ 0 \le P_{PV} \le P_{max} $$ However, it's quite obvious that during the monte carlo sampling, it's very likely to have a sampled error $\varepsilon$ that is either very small or very large, making the $P_{PV}$ smaller than zero or larger than its maximum capacity. Some papers just setting these values to either 0 or $P_{max}$ , which will change the distribution of the $\varepsilon$ according to my understanding. How to handle these physically meaningless values during monte carlo sampling?
