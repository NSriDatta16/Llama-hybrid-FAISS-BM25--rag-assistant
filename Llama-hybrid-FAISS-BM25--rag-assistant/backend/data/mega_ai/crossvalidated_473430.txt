[site]: crossvalidated
[post_id]: 473430
[parent_id]: 473426
[tags]: 
If w is vector of weights of features, how it can be transposed? Isn't that same like doing just w * w ? If you view a column vector as a $k \times 1$ matrix and a row vector as a $1 \times k$ matrix, then the meaning of a transpose should be obvious because it corresponds to the usual usage in linear algebra and matrix arithmetic. The notation w * w is ambiguous. Do you mean dot product or element-wise product? If two vectors are multiplied, result is vector again. This is not what the logistic cost function says. The logistic cost function uses dot products. Suppose $a$ and $b$ are two vectors of length $k$ . Their dot product is given by $$ a \cdot b = a ^\top b=\sum_{i=1}^{k} a_i b_i = a_1b_1 + a_2b_2 + \cdots +a_kb_k. $$ This result is a scalar because the products of scalars are scalars and the sums of scalars are scalars. Does it mean that all 'outer' (exp, log, sum) operations are done on vectors? No, the result of a dot product is scalar. How do we can minimize function when output is vector? You don't need to minimize a vector because the result of the logistic regression cost function is a scalar. You use ordinary scalar minimization.
