[site]: crossvalidated
[post_id]: 593997
[parent_id]: 593990
[tags]: 
This is speculation, since your comments mention that you do not have access to the training performance, but with poor out-of-sample performance by fancy models, this sounds like a classic case of overfitting. Yes, a model like a random forest allows much more flexibility in the modeling than a vanilla logistic regression, but this runs the risk of fitting the model to coincidences in your data (noise) instead of genuine trends (signal). In the extreme, think about playing connect-the-dots. When you go and apply this overfitted model to new data, the predictions have little to do with the true trend, and your predictive accuracy is poor. Balancing the ability to fit complicated trends while guarding against overfitting is really the key to doing good machine learning work.
