[site]: crossvalidated
[post_id]: 283463
[parent_id]: 283268
[tags]: 
I assume that your cross validation is implemented correctly the first glance at your code does not exhibit anything weird. I also assume that you use svmlight without modifications and it works correctly. The only thing that can cause your problems can be the improper selection of parameters. Please check this: https://en.wikipedia.org/wiki/Support_vector_machine#Parameter_selection as well as the documentation of SVM light. Try multiple combinations. I have not seen your data, but my intuition is that: They are not separable and in combination with that... ...the parameters cause something like majority voting. If the training set has majority of positives, it results into all positives in the test set. My advice: Evaluate different values of parameters. Plot the data in some dimensions to see if there is any change to reach separability. Try different classifier such as k-neighbors as a reference. Also available in C++ easily: http://docs.opencv.org/3.1.0/de/d63/kmeans_8cpp-example.html
