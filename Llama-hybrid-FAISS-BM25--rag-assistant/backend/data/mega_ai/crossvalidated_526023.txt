[site]: crossvalidated
[post_id]: 526023
[parent_id]: 305804
[tags]: 
A paper was recently published out of Stanford (2021) that describes how to account for dependence between our data folds. The TLDR is: We use nested cross validation to develop a systematically biased model. This provides an estimate of bias inherent to our data splits. We subtract the bias from a regular CV model, creating unbiased confidence intervals with "proper" coverage. These concepts generalize to any loss function. While the technique is still pretty new, I created a quick writeup of the paper if you want more details (but don't want to read the paper). Paper Info (in case the link dies): Name: Cross-validation: what does it estimate and how well does it do it? Authors: Stephen Bates, Trevor Hastie, and Robert Tibshirani Year: 2021
