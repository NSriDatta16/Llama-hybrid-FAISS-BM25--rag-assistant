[site]: crossvalidated
[post_id]: 253954
[parent_id]: 
[tags]: 
Problems understanding "equivariance to translation" example in deep learning book by Goodfellow et al

I am trying to understand the following part about equivariance to translation from the deep learning book by Goodfellow, Bengio and Courville (chapter 9.2, page 338-339): To say a function is equivariant means that if the input changes, the output changes in the same way. Specifically, a function $f(x)$ is equivariant to a function $g$ if $f(g(x)) = g(f(x))$. In the case of convolution, if we let $g$ be any function that translates the input, i.e., shifts it, then the convolution function is equivariant to $g$. For example, let $I$ be a function giving image brightness at integer coordinates. Let g be a function mapping one image function to another image function, such that $I' = g(I)$ is the image function with $I'(x, y) = I(x âˆ’ 1, y)$. This shifts every pixel of $I$ one unit to the right. If we apply this transformation to $I$, then apply convolution, the result will be the same as if we applied convolution to $I'$, then applied the transformation $g$ to the output. My questions concerns the last sentence. The first part, i.e. "If we apply this transformation to $I$, then apply convolution" corresponds to $f(g(x))$. However, the second part of the sentence does not make sense. $I' = g(I)$. Consequently, applying convolution to $I'$ gives $f(g(x))$. If we now apply $g$ again, we are left with $g(f(g(x)))$. Am I making a mistake? Or is the last $I'$ supposed to be a $I$?
