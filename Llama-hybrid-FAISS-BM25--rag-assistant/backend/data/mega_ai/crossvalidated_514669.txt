[site]: crossvalidated
[post_id]: 514669
[parent_id]: 488019
[tags]: 
Neural networks, including DNNs, don't by themselves suffer from high variance any more than other machine learning algorithms. It is just that we find it easier to start the training with more complex networks and control for variance by the techniques you mentioned, than to start with simpler (less expressive) networks and gradually increase their complexity. By observing the network behaviour during training you can already get hints regarding simplification. If you'd start with a simpler network, you'd be tapping in the dark how to augment it.
