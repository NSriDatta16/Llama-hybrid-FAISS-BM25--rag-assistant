[site]: crossvalidated
[post_id]: 265940
[parent_id]: 
[tags]: 
XGBoost - Weights in classifcation tree 0 or 1?

I've read the paper on the XGBoost algorithm and one thing is not quite clear to me. The regularization term is defined as below where $w_{j}$ corresponds to the weight in end node $j$. For the regression case this would be the predicted value in the end node and for the classification case this would be either a $0$ or a $1$ I would suspect. Then the regularization term seems intuitive to me in the case of regression for penalizing large predictions however in the classification case it wouldn't add much as the $w_{j}$'s will always be a $0$ or a $1$ right?
