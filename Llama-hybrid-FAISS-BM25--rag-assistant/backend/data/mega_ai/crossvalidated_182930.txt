[site]: crossvalidated
[post_id]: 182930
[parent_id]: 
[tags]: 
How does one run K-fold validation for algorithms that are trained via gradient descent?

I am trying to choose the model that generalizes the most (using k-fold cross validation), however, my model is trained using gradient descent. I am concerned about this because I am not sure how I am suppose to choose the step size (nor the number of iterations) for each split of the k-fold validation. Recall that k-fold validation splits the data into k pieces and trains the model with k-1 pieces and tests/validates with the remaining piece. Then one estimates the generalization of the model by taking the average of the k different validation costs that we obtained. One picks the model with the lowest estimated generalization (i.e. lowest average cross validation). The worry that I have is that since each split of the data is different, that a fixed step size will not yield good training and it wasn't actually the model's fault that it didn't perform well, but that the real issue was that the step size wasn't set correctly for the current model and current split of the data (i.e. the issue is with the optimization procedure rather than the model in question). Therefore, I was wondering, if there was a way to choose the step size so that this wouldn't be the case? One way that I thought of solving this (automatically), was to actually make the model incorporate the step size as part of the model (i.e. we choose the step size as part of the model). We call a new model $M_{new}$ a tuple as old model together with the step size; $M_{new}= (M_{old},\eta_{\theta} )$. Now we just do the standard k-fold validation on this. The issue that I had with doing this is that including an additional parameter to do cross validation can potentially yield better results but it can also be very expensive to include this additional parameter. Specially because this new parameter might need discretization which is hard to choose well (issues like, what is a big enough step size, how far away the step sizes should be, what range to consider, etc are hard to choose). This procedure would probably solve the variation in models, because as we vary models we vary step sizes, but within each estimation of the generalization, it is still susceptible to being negatively affected by each split of the data (since the step size isn't varied across splits within the k-fold validation itself). What I am actually doing is the following heuristic: First I train my model using batch gradient descent on the whole data and look at how many iterations and which step size it needs for it to settle down in some local minimum. I do this to get a sense of how small the step size has to be when it includes every split of the data and to see how many iterations it needs to converge in the worst case. This is done manually/visually by inspecting how the cost on the (regularized) training error changes. I also inspect the plots of the parameters changes, to make sure that those also converge (settling down). After that, I fix both my number of iterations and my step size and proceed to do k-fold validation (unfortunately, I also run several different initializations, to avoid the same local minima's). This heuristic might work, but, it obviously doesn't scale because it requires human intervention. Is there a way to solve this issue? I'd hope there was some sort of heuristic/procedure that people use, because in practice, people do use models like Convolutional Neural Nets or standard Neural Nets, which are trained with (stochastic) gradient descent. I assume people don't blindly do stuff with these models and actually do good practices like cross validation to choose whatever parameters have to be chosen via cross validation.
