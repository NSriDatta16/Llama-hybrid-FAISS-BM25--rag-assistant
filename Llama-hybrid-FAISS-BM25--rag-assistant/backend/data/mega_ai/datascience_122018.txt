[site]: datascience
[post_id]: 122018
[parent_id]: 
[tags]: 
Which preprocessing is the correct way to forecast time-series data using LSTM?

I just started to study time-series forecasting using RNN. I have a few months of time series data that was an hour unit. The data is a kind of percentage value of my little experiment and no other correlated information this. It is simple 1-D array info. I would like to forecast the future condition of this. Many tutorials and web info introduced direct training and forecasting the time series data without any data pre-processing. But for the RNN (or ML and DL), I think we should consider the data's condition that is stationary or not. My data is totally random condition which is stationary data (no seasonality, no trend). For example, the US stock prediction tutorial showed super great accuracy forecasting performance according to many LSTM tutorials. [If this really works and is true, then all ML developers will be rich.] And, Some of them didn't emphasize and note a kind of the data pre-processing such as non-stationary to stationary something like that. According to my short knowledge, I think the non-stationary data such as stock price (will have trend) should be converted as a stationary format through differencing or some other steps. and I think this is a correct prediction as a view of theoretical sense even if the accuracy is not high. So my point is, I'm a bit confused about whether that really is no need for any preprocessing to treat stationary or not. For my case, I applied differencing step ( $t_n - t_{n-1}$ )to my time-series data in order to remove the trend or some periodic situation. Is my understanding not correct? Why do time-series forecasting tutorials not introduced data stationarity?
