[site]: crossvalidated
[post_id]: 423121
[parent_id]: 
[tags]: 
Parameter estimation by averaging over all high-likelihood possibilities?

I am refereeing a chemistry paper. The authors are trying to interpret some experimental data by comparison with numerical simulations. They have run many simulations using different combinations of input parameters. They want to estimate what input parameters produce output that best corresponds to the experimental data. The scheme they have come up with is to: Find the simulation whose output is closest to the experimental data and calculate its likelihood. (They calculate the likelihood using a Normal distribution based on the sum of square errors between the simulation output and the experimental result.) Select all simulations with a likelihood greater than 95% of the likelihood of the most likely simulation. Take the (unweighted) mean and standard deviation of those likely simulations, and report those values. To me this sounds like a bad approach, and there are many better ways to do it (for example, Bayesian parameter inference). A simple drawback I would see is if two simulations had very similar input values. Then these simulations would be "double-counted". Is there justification for using this approach? Is it "really bad" or just "kind of bad", or is it actually OK?
