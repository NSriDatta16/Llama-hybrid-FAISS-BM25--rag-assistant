[site]: datascience
[post_id]: 25352
[parent_id]: 
[tags]: 
How should classification be done for a very small data set?

I am looking at data from the London Data Store based on social characteristics between London boroughs. Since there are only about 30 London boroughs, the data sets I am looking at are naturally very small. For example, I might be fitting regression/correlations to a plot of about 30 points. What are appropriate ways to conduct classification on such small data sets, and why? 'Why' is important. I was thinking of something like SVM, or Naive Bayes. Or regression if the data is continuous. What are very inappropriate ways to conduct classification here?
