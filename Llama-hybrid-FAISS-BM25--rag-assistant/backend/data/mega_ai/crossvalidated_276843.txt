[site]: crossvalidated
[post_id]: 276843
[parent_id]: 
[tags]: 
Using low coverage predictors in models?

The conventional wisdom I run up against is to drop predictors with low coverage without given them much consideration. By low coverage predictors : I meant predictors whose values are mostly missing. So, say we have values for only 1% or say 0.1% of the exemplars. To me one -- I would tend to think -- that the low coverage predictors might have a high degree of leverage in say a boosting learner. Does this line of argument hold any water -- if it does, is there a method one can employ to make such a case.
