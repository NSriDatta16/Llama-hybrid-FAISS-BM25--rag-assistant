[site]: crossvalidated
[post_id]: 614891
[parent_id]: 
[tags]: 
How to calculate the variance of the weighted sum of two stationary time series with autocorrelation?

I have two stationary time series $X(t)$ and $Y(t)$ that I know are correlated to each other but they also each have autocorrelations. Each has a credible interval band for each time series at every time $t$ defined by their respective means $\mu_x(t)$ and $\mu_y(t)$ and standard deviations $\sigma_x(t)$ and $\sigma_y(t)$ (I could assume normality if I have to but do not for the time being). My goal is to describe the time series $Z(t)$ defined as the following weighted sum: $Z(t):=aX(t)+bY(t)$ where $a\in \mathbb{R}$ , $b\in \mathbb{R}$ . In other words, $X(t)-Y(t)$ is the result of $a=1,b=-1$ and the simple mean $\frac{X(t)+Y(t)}{2}$ is the result of $a=0.5,b=0.5$ etc... The mean (e.g. the point estimate at time $t$ ) is very straight forward because it is a mean of means: $\mu_z(t)=a\mu_x(t)+b\mu_y(t)$ In order to find $\sigma_z(t)$ I need the square root of the following identity: $\mathbb{V}(aX(t)+bY(t))=a^2\sigma_x(t)^2+b^2\sigma_y(t)^2 + 2\rho_{x,y}\sigma_x(t)\sigma_y(t)$ However, I know the auto-correlations in $X(t)$ and $Y(t)$ can inflate the estimate of the needed Pearson's correlation $\rho_{x,y}$ (spurious correlation and all that) despite my time series being stationary. I want to emphasize that I am not interested (at this point) in merely finding the important lags by prewhitening $X(t)$ and $Y(t)$ in a cross-correlation analysis. I also do not believe that transfer functions are appropriate here because it would be a stretch to assume that $X(t)$ influences $Y(t)$ but $Y(t)$ does not influence $X(t)$ . I need a reasonable estimate $\hat{\rho}_{x,y}$ for lag=0 simply to define the uncertainty of my time series $Z(t)$ . My questions are: Provided my time series are long enough and I was ok with a brute force solution, can I simply take the correlation of the thinned time series (like one would do with MCMC) such that I remove elements that are so close as to be in the range of autocorrelations? Hyndman's fable package in R handles a similar situation where quantile forecasts are combined while compensating for correlations in the errors. I looked at the package implementation and it seems it takes the correlation of the de-autocorrelated residuals in the above formula. This would be great if I could simply fit separate ARMAs (or ARIMA for non-stationary series) to both $X(t)$ and $Y(t)$ and take the correlation of the residuals! However, in Hyndman's situation the ARMA model's are fit to the same time series and the correlation of the residual terms of the two different models are applied to the forecast values to eventually produce quantiles. Furthermore, my Applied Time Series notes from grad school explicitly says that calculating cross-correlations on pre-whitened time series can identify correlations significantly different than zero but the pre-whitening interferes with the magnitude of the linear association. So which is it? Can I fit ARMA models and calculate the correlation of the residuals for $\hat{\rho}_{x,y}$ ? Does it make a difference if I find the ARMA for $X(t)$ , filter $Y(t)$ with those coefficients and take the correlation of the residuals (this is typically how prewhitening is usually applied from what I can tell)? Practical context for my questions This setup would be extremely useful if I had a time series of the reproductive number $R_t$ (average # of people each person infects in a viral outbreak) for the country and also for the locality. They are obviously correlated. I might like to know if the difference between the locality's $R_t$ and the national $R_t$ is different than 0 in a statistically significant way because this identifies patterns in spatial heterogeneity. I also might like to take the average of $R_t$ 's from different viral variants weighted by the percentage of each variant in the population.
