[site]: crossvalidated
[post_id]: 144745
[parent_id]: 
[tags]: 
Is this an appropriate method to test for seasonal effects in suicide count data?

I have 17 years (1995 to 2011) of death certificate data related to suicide deaths for a state in the U.S. There is a lot of mythology out there about suicides and the months/seasons, much of it contradictory, and of the literature I've reviewed, I do not get a clear sense of methods used or confidence in results. So I've set out to see if I can determine whether suicides are more or less likely to occur in any given month within my data set. All of my analyses are done in R. The total number of suicides in the data is 13,909. If you look at the year with the fewest suicides, they occur on 309/365 days (85%). If you look at the year with the most suicides, they occur on 339/365 days (93%). So there are a fair number of days each year without suicides. However, when aggregated across all 17 years, there are suicides on every day of the year, including February 29 (although only 5 when the average is 38). Simply adding up the number of suicides on each day of the year doesn't indicate a clear seasonality (to my eye). Aggregated at the monthly level, average suicides per month range from: (m=65, sd=7.4, to m=72, sd=11.1) My first approach was to aggregate the data set by month for all years and do a chi-square test after computing the expected probabilities for the null hypothesis, that there was no systematic variance in suicide counts by month. I computed the probabilities for each month taking into account the number of days (and adjusting February for leap years). The chi-square results indicated no significant variation by month: # So does the sample match expected values? chisq.test(monthDat$suicideCounts, p=monthlyProb) # Yes, X-squared = 12.7048, df = 11, p-value = 0.3131 The image below indicates total counts per month. The horizontal red lines are positioned at the expected values for February, 30 day months, and 31 day months respectively. Consistent with the chi-square test, no month is outside the 95% confidence interval for expected counts. I thought I was done until I started to investigate time series data. As I imagine many people do, I started with the non-parametric seasonal decomposition method using the stl function in the stats package. To create the time series data, I started with the aggregated monthly data: suicideByMonthTs Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 1995 62 47 55 74 71 70 67 69 61 76 68 68 1996 64 69 68 53 72 73 62 63 64 72 55 61 1997 71 61 64 63 60 64 67 50 48 49 59 72 1998 67 54 72 69 78 45 59 53 48 65 64 44 1999 69 64 65 58 73 83 70 73 58 75 71 58 2000 60 54 67 59 54 69 62 60 58 61 68 56 2001 67 60 54 57 51 61 67 63 55 70 54 55 2002 65 68 65 72 79 72 64 70 59 66 63 66 2003 69 50 59 67 73 77 64 66 71 68 59 69 2004 68 61 66 62 69 84 73 62 71 64 59 70 2005 67 53 76 65 77 68 65 60 68 71 60 79 2006 65 54 65 68 69 68 81 64 69 71 67 67 2007 77 63 61 78 73 69 92 68 72 61 65 77 2008 67 73 81 73 66 63 96 71 75 74 81 63 2009 80 68 76 65 82 69 74 88 80 86 78 76 2010 80 77 82 80 77 70 81 89 91 82 71 73 2011 93 64 87 75 101 89 87 78 106 84 64 71 And then performed the stl() decomposition # Seasonal decomposition suicideByMonthFit At this point I became concerned because it appears to me that there is both a seasonal component and a trend. After much internet research I decided to follow the instructions of Rob Hyndman and George Athana­sopou­los as laid out in their on-line text "Forecasting: principles and practice", specifically to apply a seasonal ARIMA model. I used adf.test() and kpss.test() to assess for stationarity and got conflicting results. They both rejected the null hypothesis (noting that they test the opposite hypothesis). adfResults I then used the algorithm in the book to see if I could determine the amount of differencing that needed to be done for both the trend and season. I ended with nd = 1, ns = 0. I then ran auto.arima , which chose a model that had both a trend and a seasonal component along with a "drift" type constant. # Extract the best model, it takes time as I've turned off the shortcuts (results differ with it on) bestFit > summary(bestFit) Series: suicideByMonthFromMonthTs ARIMA(0,1,1)(1,0,1)[12] with drift Coefficients: ma1 sar1 sma1 drift -0.9299 0.8930 -0.7728 0.0921 s.e. 0.0278 0.1123 0.1621 0.0700 sigma^2 estimated as 64.95: log likelihood=-709.55 AIC=1429.1 AICc=1429.4 BIC=1445.67 Training set error measures: ME RMSE MAE MPE MAPE MASE ACF1 Training set 0.2753657 8.01942 6.32144 -1.045278 9.512259 0.707026 0.03813434 Finally, I looked at the residuals from the fit and if I understand this correctly, since all values are within the threshold limits, they are behaving like white noise and thus the model is fairly reasonable. I ran a portmanteau test as described in the text, which had a p value well above 0.05, but I'm not sure that I have the parameters correct. Acf(residuals(bestFit)) Box.test(residuals(bestFit), lag=12, fitdf=4, type="Ljung") Box-Ljung test data: residuals(bestFit) X-squared = 7.5201, df = 8, p-value = 0.4817 Having gone back and read the chapter on arima modeling again, I realize now that auto.arima did choose to model trend and season. And I'm also realizing that forecasting is not specifically the analysis I should probably be doing. I want to know if a specific month (or more generally time of year) should be flagged as a high risk month. It seems that the tools in the forecasting literature are highly pertinent, but perhaps not the best for my question. Any and all input is much appreciated. I'm posting a link to a csv file that contains the daily counts. The file looks like this: head(suicideByDay) date year month day_of_month t count 1 1995-01-01 1995 01 01 1 2 2 1995-01-03 1995 01 03 2 1 3 1995-01-04 1995 01 04 3 3 4 1995-01-05 1995 01 05 4 2 5 1995-01-06 1995 01 06 5 3 6 1995-01-07 1995 01 07 6 2 daily_suicide_data.csv Count is the number of suicides that happened on that day. "t" is a numeric sequence from 1 to the total number of days in the table (5533). I've taken note of comments below and thought about two things related to modeling suicide and seasons. First, with respect to my question, months are simply proxies for marking change of season, I am not interested in wether or not a particular month is different from others (that of course is an interesting question, but it's not what I set out to investigate). Hence, I think it makes sense to equalize the months by simply using the first 28 days of all months. When you do this, you get a slightly worse fit, which I am interpreting as more evidence towards a lack of seasonality. In the output below, the first fit is a reproduction from an answer below using months with their true number of days, followed by a data set suicideByShortMonth in which suicide counts were computed from the first 28 days of all months. I'm interested in what people think about wether or not this adjustment is a good idea, not necessary, or harmful? > summary(seasonFit) Call: glm(formula = count ~ t + days_in_month + cos(2 * pi * t/12) + sin(2 * pi * t/12), family = "poisson", data = suicideByMonth) Deviance Residuals: Min 1Q Median 3Q Max -2.4782 -0.7095 -0.0544 0.6471 3.2236 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) 2.8662459 0.3382020 8.475 summary(shortSeasonFit) Call: glm(formula = shortMonthCount ~ t + cos(2 * pi * t/12) + sin(2 * pi * t/12), family = "poisson", data = suicideByShortMonth) Deviance Residuals: Min 1Q Median 3Q Max -3.2414 -0.7588 -0.0710 0.7170 3.3074 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) 4.0022084 0.0182211 219.647 The second thing I've looked into more is the issue of using month as a proxy for season. Perhaps a better indicator of season is the number of daylight hours an area receives. This data comes from a northern state that has substantial variation in daylight. Below is a graph of the daylight from the year 2002. When I use this data rather than month of the year, the effect is still significant, but the effect is very, very small. The residual deviance is much larger than the models above. If daylight hours is a better model for seasons, and the fit is not as good, is this more evidence of very small seasonal effect? > summary(daylightFit) Call: glm(formula = aggregatedDailyCount ~ t + daylightMinutes, family = "poisson", data = aggregatedDailyNoLeap) Deviance Residuals: Min 1Q Median 3Q Max -3.0003 -0.6684 -0.0407 0.5930 3.8269 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) 3.545e+00 4.759e-02 74.493 I'm posting the daylight hours in case anyone wants to play around with this. Note, this is not a leap year, so if you want to put in the minutes for the leap years, either extrapolate or retrieve the data. state.daylight.2002.csv [ Edit to add plot from deleted answer (hopefully rnso doesn't mind me moving the plot in the deleted answer up here to the question. svannoy, if you don't want this added after all, you can revert it)]
