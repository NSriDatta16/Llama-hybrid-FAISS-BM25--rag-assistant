[site]: crossvalidated
[post_id]: 79876
[parent_id]: 79871
[tags]: 
Yes, the way in which medical and social researchers use statistics has a number of problems. Significance testing is probably inappropriate in the vast majority of cases and in my opinion has possibly led to stagnation of these fields. I have come to think that instead of just seeing if two averages are different, the researchers should be focused on describing the distribution of the results in search of subgroups, estimating parameters, and guessing mathematical models that may explain the data generating process at the individual level. My personal guess would be that well over 50% of the conclusions drawn in the literature are false or at least only true for an extremely narrow set of conditions that will never be reproduced exactly again. Highly recommended reading: Meehl, P.E. (1967). Theory-testing in psychology and physics: A methodological paradox . Philosophy of Science , 34 :103-115. There is empirical evidence of serious problems as well: Recently researchers from Amgen have claimed they could replicate 5/52 results from "landmark studies". Researchers from Bayer reported slightly better success in attempting to validate new drug targets, replicating 19/67 results . An effort by John Ioannidis to reproduce data on the presence of sex difference for various diseases reported replicating 1/432 results . Edit: To clarify a bit. I do not think significance testing the difference between groups is bad in and of itself, it can clearly provide information on what may be worth investigating further. It is just that it provides so little information in comparison with the alternatives so should always be done in conjunction. The real world result has been that all focus goes on the significance test. This is at the expense of the other approaches to analyzing data mentioned, and it is lack of the others that I believe has stagnated medical research.
