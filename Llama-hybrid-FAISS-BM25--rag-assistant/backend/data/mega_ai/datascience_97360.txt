[site]: datascience
[post_id]: 97360
[parent_id]: 97356
[tags]: 
In fact, the classification algorithms generally need a numeric value to be able to classify correctly. You can use Random Forest using a function that would replace NaNs by a mean value or an outlier value. In your case, it could be -1 or -5, but you can use the general mean value so that it would reduce the variability for NaN values in the classification process. from __future__ import print_function import numpy as np from sklearn.ensemble import RandomForestClassifier from sklearn.impute import SimpleImputer X_train = [[1,4,5,3,5,1,8,5,1,0, NA, 6],.... Y_train = [lung,... X_test_1 = ... # Option 1: Create our imputer to replace missing values with the mean e.g. imp = SimpleImputer(missing_values=np.nan, strategy='mean') imp = imp.fit(X_train) X_train_imp = imp.transform(X_train) #Option 2:Or replace by an outlier value X_train_imp = X_train.nan_to_num(-5) # Then train the classifier clf = RandomForestClassifier(n_estimators=10) clf = clf.fit(X_train_imp, Y_train) #Option 1: X_test_imp = imp.transform(X_test_1) #Or Option 2 X_test_imp = X_test_1.nan_to_num(-5) #Result: print(X_test_1, '->', clf.predict(X_test_imp)) Initial source code: https://stackoverflow.com/questions/30317119/classifiers-in-scikit-learn-that-handle-nan-null
