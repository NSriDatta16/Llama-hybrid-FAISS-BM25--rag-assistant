[site]: crossvalidated
[post_id]: 472514
[parent_id]: 
[tags]: 
Why is my validation loss always larger than my epoch loss

I am training a CNN and it seems no that matter what I do my validation loss is always much greater than my training loss. To my understanding, this should mean my model is always overfitting my data set. INFORMATION: My model is built in Keras running on tensorflow=1.14. My model is a binary cross-entropy. I Have a data set of about 2500 tagged photos. My tensor board:
