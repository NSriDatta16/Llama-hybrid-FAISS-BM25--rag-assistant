[site]: crossvalidated
[post_id]: 552562
[parent_id]: 
[tags]: 
Understanding the Tweedie Distribution

I am trying to better understand the basic details and properties about the Tweedie Probability Distribution. The Tweedie Probability Distribution is a bimodal probability distribution function which is useful for capturing shapes and patterns in datasets having a high level of "over dispersion" (i.e. many zeros, also called zero-inflated). Here are some examples of the Tweedie Probability Distribution Function: I am trying to better understand the general form of the Tweedie Probability Distribution Function. In general, a Tweedie Distribution is said to be a sum of an "M" number of Gamma Distributions - where "M" itself is a random variable from a Poisson Distribution. According to Wikipedia, the Tweedie Probability Distribution Function (for a random variable "Y") can be written as follows: From the above statement, it would appear that the Tweedie Probability Distribution Function is parametrized by "alpha", "p" and "sigma^2" (i.e. since "thetha" is a function of "p" and "sigma^2"). I spent some time trying to understand this, but I still have the following questions: 1) I noticed that there is a "z" term in the Tweedie Probability Distribution Function - I assume that this actually refers to the original random variable "Y", and that replacing "Y" with "z" is just a common tradition when writing integrals. Is this correct? (e.g. "dz" is effectively "dy"?) 2) In the Tweedie Probability Distribution Function, what exactly is "v-lambda"? The Wikipedia page states that "v-lambda" refers to a "sigma finite measure" - but I am not sure what this means. In practice (e.g. when modelling real world data using the Tweedie Distribution), does this "v-lambda" term "drop out" of the Probability Distribution Function? Is writing "v-lambda" simply a mathematical "formality" ? Or does "v-lambda" actually refer to some physical term? 3) If you have some observations (e.g. heights of basketball players) X : X1, X2...XN, and you decide that these observations likely originated from a Tweedie Probability Distribution Function. Given these observations, how do you calculate "alpha", "p" and "sigma^2" (e.g. are there formulas for the Maximum Likelihood Estimates of these parameters) ? If you assume that X: X1, X2...XN come from a Tweedie Probability Distribution Function - how do you calculate the "mean" ( E(X) ) and the "variance" ( Var(X) ) of X? (I have a feeling that you obviously just can't use the same formulas for mean and variance based on a normal probability distribution) 4) Are there any standard methods to (numerically) integrate the Tweedie Probability Distribution? For example, the main R package for the Tweedie Distribution ( https://cran.r-project.org/web/packages/tweedie/tweedie.pdf ) uses the "saddle point approximation" method to compute densities : > library(tweedie) > power mu phi y fy plot(y, fy, type = "l", lwd = 2, ylab = "Density") > > f.saddle lines( y, f.saddle, col = 2 ) > legend("topright", col = c(1, 2), lwd = c(2, 1), legend = c("Actual", "Saddlepoint") ) > > hist( rtweedie( 1000, power = 1.2, mu = 1, phi = 1) ) In practice, could MCMC be used to evaluate samples from a Tweedie Probability Distribution Function? Can someone please help me clarify these points? Thanks! References: https://en.wikipedia.org/wiki/Tweedie_distribution https://converged.yt/papers/dsm-paper-AppendixD.pdf Note: I have also seen the Tweedie Probability Distribution expressed as a sum of infinite series: And this sum of the infinite series itself is approximated using Stirling's Formula and Fourier Inversion (e.g. https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.449.2161&rep=rep1&type=pdf ).
