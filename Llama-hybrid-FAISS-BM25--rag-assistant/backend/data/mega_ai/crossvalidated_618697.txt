[site]: crossvalidated
[post_id]: 618697
[parent_id]: 616582
[tags]: 
From LIMA: Less Is More for Alignment (2023) by Chunting Zhou et al.: These results strongly suggest that almost all knowledge in large language models is learned during pretraining , and only limited instruction tuning data is necessary to teach models to produce high quality output. Remains prolonged pre-training and adding information in the prompt, as Ggjj11 suggested.
