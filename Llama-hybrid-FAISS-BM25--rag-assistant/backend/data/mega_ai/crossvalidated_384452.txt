[site]: crossvalidated
[post_id]: 384452
[parent_id]: 384446
[tags]: 
It can be shown that by using sufficiently large sample sizes for the MC approximation, a lower bound to the marginal log-likelihood is tightened. While this estimator is hence biased, in can serve the same practical purposes. It was shown in [1] that $$ \log p(x) \ge \mathcal{L}_{K+1} \ge \mathcal{L}_{K} $$ for $\mathcal{L}_K = \mathbb E_{z_1, \ldots, z_K \sim q^K} \left[\log \frac{1}{K} \sum_{k=1}^K \frac{p(x, z_k)}{q(z_k)}\right]$ , where $q^K \equiv \underbrace{q \otimes q \otimes \cdots \otimes q}_{K times}$ . This also holds for $q(z) = p(z)$ . [1] Burda, Yuri, Roger Grosse, and Ruslan Salakhutdinov. "Importance weighted autoencoders." arXiv preprint arXiv:1509.00519 (2015).
