[site]: stackoverflow
[post_id]: 3055609
[parent_id]: 3052511
[tags]: 
Your best (but, admittedly, least guaranteed) method is to drive user behaviour to try and have them format the data in a standardised and easily parsed format. Even just having one or two easy main formats to try and encourage them to convert to would be an excellent step and reduce the amount of error correction/formatting required. Beyond that, I would suggest that creating Regular Expressions, and functions behind those RegExps to standardise the data you are going to use would be a solution. I have run a few RegExps against the test data you have provided, but am having trouble creating a bulletproof solution in that regard (it may be that you will need to have a few different patterns to pick up each combination). I have even tried parsing some of the test data provided through the Google Geocoding API (which is, normally, quite a resilient system, allowing for plain text addressing, as well as multiple Lat/Long formats), but, no joy. The more standard the data coming in, the easier to create accurate information coming out. Maybe integrating a map (Google Maps or otherwise) into the input phase would allow for you to validate the input more accurately.
