[site]: crossvalidated
[post_id]: 361485
[parent_id]: 
[tags]: 
Why update SARSA with S'A' at all if the goal is a less aggressive exploitation policy?

Why is it that we update the Q values using S' and A' and not the maximum as in Q-learning? If the goal is to have a less aggressive exploitation policy, why don't we simply use an epsilon greedy action policy with a small/decaying epsilon, e.g. 0.1? That would make the program quite conservative as well. What's the advantage of updating using S'A' as opposed to using the optimal action?
