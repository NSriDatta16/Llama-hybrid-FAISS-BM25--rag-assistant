[site]: datascience
[post_id]: 55057
[parent_id]: 55009
[tags]: 
[This answer is based on my limited knowledge, please don't hesitate to edit or propose improvements in the comments] Actually I think it's a bit misleading to say that algorithms can be affected by class imbalance, because it's not exactly the algorithm which is affected it's the evaluation method (I mean "evaluation" in a broad sense including the loss function used by the algorithm during training). Some algorithms may be closely related to a particular loss function or internal optimization strategy, so by association such algorithms have the same weaknesses. A simple way to see that class imbalance issues completely depend on the evaluation method is to compare micro-average performance with macro-average over the classes in a case where 99% of the instances belong to the same class: micro-average gives the same weight to every instance, so a model which assigns the majority class will look as if it performs very well. macro-average gives the same weight to every class, so assigning the majority class won't work better than random. So technically the problem of class imbalance could (should?) be seen as a design choice between maximizing the number of instances correctly classified (default evaluation) and any other alternative, for example giving equal weight to every class. But of course it's not practical nor common to design a specific evaluation measure or loss function specific to every problem.
