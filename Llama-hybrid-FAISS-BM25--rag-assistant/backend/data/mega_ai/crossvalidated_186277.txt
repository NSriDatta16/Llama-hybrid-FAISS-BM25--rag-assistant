[site]: crossvalidated
[post_id]: 186277
[parent_id]: 
[tags]: 
How to use PCA in regression?

I'm currently reading in the Applied Predictive Modeling book about PCA for dimensionality reduction. I've read the following: If the predictive relationship between the predictors and response is not connected to the predictorsâ€™ variability, then the derived PCs will not provide a suitable relationship with the response. In this case, a supervised technique, like PLS, will derive components while simultaneously considering the corresponding response. I don't understand the meaning of this. Could somebody explain this in better words or in an example (when to use PLS instead of PCA)? How can I decide in a real dataset if I should use PCA or PLS? Predictors is the same as features. Second, I'm using Matlab and I'm a bit unsure about the transformation. Let's assume that $X$ is my data matrix where the rows are the data points and the columns are the features (predictors). In Matlab the function call is [coeff,score,latent,tsquared,explained,mu] = pca(X) Should I now use coeff or score instead of X or should I do X*coeff or X*score ? I also don't understand what the difference is between coeff and score .
