[site]: datascience
[post_id]: 23058
[parent_id]: 19357
[tags]: 
I think that heavily depends on the nature of your data (categorical/continuous). I'd start with simple methods first. Those come to my mind: You can compare distribution of each variable either by using quantiles or any statistical test to see whether they are significantly different You could also count occurrence of each label/category and compare them I'd also try to employ any sort of distance measure. For example you could calculate mahalanobis distance and look for big changes Or something really simple - just an absolute difference between new and old data, set a threshold and everything exceeding the threshold will be reported You can also put in place some multidimensional techniques - like correlation matrix, principal components, clustering etc. and look for changes If none of these are suitable, then there is whole branch of stats/ML models specialized for anomaly detection. SVM, t-SNE, Isolation forests, Peer Group Analysis , Break Point Analysis , Time series (where you would look for outliers outside trends). Those methods have the advantage that they are sort of white-box, so you can tell why someone is an outlier. Should this not be the thing you want, others suggested ANN approaches, which will also work.
