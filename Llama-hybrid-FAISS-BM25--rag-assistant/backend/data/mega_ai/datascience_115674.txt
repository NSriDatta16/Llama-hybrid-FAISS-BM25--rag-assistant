[site]: datascience
[post_id]: 115674
[parent_id]: 115658
[tags]: 
Your question: how poor is the CART ensemble (random forest or GBM) at finding an exact perfect line of split? Answering: Each tree can be considered a piecewise constant fit of the surface. The inputs for the trees are trained on a random subset of both the columns and the rows, so no two trees are fed the same information. This leads to the trees having a bootstrap-style distribution of split locations. For the RF, the trees are aggregated for continuous domain outputs using an error weighted mean sum. For the Boosted Machine (series ensemble) the target is a weighted error of the previous ensemble. This means that over time it gets closer and closer to exact. What it means : If you were trying to use a random-forest to approximate a cube, all else being equal, you are likely to get a 12th power spheroid. If you were trying using a GBM it might be a 120th power spheroid. In the limit of many samples, many compute, big model, it could be said to approach to within a bound of error, which a mathematician would love. It can get very very close. The problem is that there is "no perfect system". All universal approximators are approximators. As always, we are mechanics at the garage and there is no perfect tool. We need to have a wide variety of tools that we understand sufficiently well to apply to the problem.
