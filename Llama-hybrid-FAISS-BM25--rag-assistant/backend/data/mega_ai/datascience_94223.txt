[site]: datascience
[post_id]: 94223
[parent_id]: 34357
[tags]: 
I think the shortest answer can be this slide from Jake Vanderplas' PyCon 2017 Keynote (and it's a great talk which can be a longer answer): Thus most people don't prefer Pandas per se, they prefer (rapidly growing) Python Data Stack and Python ecosystem encompassing it. Scientist may go mostly with high-level domain packages, data engineers with ML packages, and when either of the two groups have something actionable from their interactive JupyterLab sessions, software engineers may use another packages to add HTTP API and describe deployment to move it into production. And all with the same language and ecosystem! SQL (even with all what commercial RDBMS vendors eager to sell you) is nowhere near such capability. Pandas underpins some these use cases, and in turn relies on lower layers of the stack (e.g. NumPy). Could Python DBAPI and SQL be a replacement that would keep the rest intact? Parity, as such, is well covered in Pandas' Comparison with SQL . SELECT total_bill, tip, smoker, time FROM tips LIMIT 5 -- vs -- df[["total_bill", "tip", "smoker", "time"]].head(5) or SELECT day, AVG(tip), COUNT(*) FROM tips GROUP BY day -- vs -- df.groupby("day").agg({"tip": np.mean, "day": np.size}) The same intent expressed in different ways (declarative DSL vs API in a high-level general purpose imperative language that mimics the DSL). From the perspective of familiarity to different roles (SQL is around for almost 50 years actually and doesn't seem to loose its relevance, and is known beyond software engineering) and expressiveness, I'd say SQL wins. But if you look from a broader application maintenance and operation perspective, SQL has a number of problems it brings along: new attack surface RDBMS SQL dialect differences another software system to manage in case of client-server RDBMS real-world (analytical) SQL maintenance as strings (e.g. composition, re-usability, comprehensibility) ORM as a solution for above, but bringing a bag of own problems In my opinion not dragging these problems into a fundamental component of a stack is a smart pragmatic decision. Instead you have a fast in-memory table with idiomatic (i.e. mostly counter-intuitive) high-level imperative API, which covers most of use cases. And interestingly enough there is Blaze which runs on top of SQL (via SQLAlchemy) and provides Pandas-like interface, which probably means that the latter is becoming the standard API for tabular data manipulation for data analysis. That said it doesn't mean there aren't niche use cases in data analysis which can be solve in SQL alone. One example that I can give is ad-hoc exploratory data visualisation in tools like sqliteviz (in-browser SQLite with full Ploty's array of scientific visualisation) and sqlitebrowser (regular SQLite with simplistic visualisation capability). It's a breeze tweaking the result set (e.g. filtering, type conversion, adding computed columns, etc.) for the visualisation in SQL (not to mention how much easier are mid-complexity visualisations done in a GUI, comparing to much more idiomatic Matplotlib's API). Update There's a very interesting project from Dutch CWI, called DuckDB . It's an open-source embedded analytical (columnar, vectorised, MVCC) database that tries to address the SQL mismatch for the most typical data science workflow. Basically to eliminate the need for re-inventing (poor man's in-memory) databases by data scientists, by removing all friction for reusing useful parts that the database field has accumulate for over than 50 years. For instance, you can completely install it with pip install duckdb (and it has wheels so you most likely don't need a compiler), you can save/load Pandas dataframes directly to the database, execute SQL with it on Pandas dataframes directly (i.e. zero-copy at least for numeric types), it has own query composition mechanisms and more. First 15 minutes of this talk, DuckDB â€“ The SQLite for Analytics , one of the authors, Mark Raasveldt, explains how DuckDB addresses the problem. Practical SQL for Data Analysis -- What you can do without Pandas gives a lot of advanced PostgreSQL examples of how to data analysis in SQL from from cleaning, sampling and splitting datasets to binning, pivots and calculating linear regression.
