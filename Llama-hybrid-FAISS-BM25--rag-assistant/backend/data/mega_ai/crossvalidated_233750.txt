[site]: crossvalidated
[post_id]: 233750
[parent_id]: 233581
[tags]: 
You worte If $p(X)$ is Gaussian, I can easily pull a sample from there, but then do I put this sample into the likelihood function? If that's the case I'm evaluating a probability value at a particular point, and not actually "taking a sample I think you misunderstand the concept of conditional probability, when we sample from the prior and plug the sampled value into the likelihood , we do not evaluate a probability value at a particular point we just get a conditional distribution given the sampled value from the prior. Suppose that the target distribution is the joint probability distribution of two variables, a discrete variable $\delta \in \{1,2,3\}$ and a continuous variable $\theta \in \mathbb{R}$ then the target density will be defined as : 01-The discrete part of this density is : $$ \{Pr(\delta =1), Pr(\delta = 2), Pr( \delta= 3)\} = (.45, .10, .45)$$ 02- The continuous part of this density is $$P(\theta|\delta) = dnorm(\theta,\mu_{\delta},\sigma_{\delta })$$ , where $(\mu_1,\mu_2,\mu_3) = (âˆ’3, 0, 3)$ and $(\sigma^2_1,\sigma^2_2,\sigma^2_3) = (1/3, 1/3, 1/3) $ . This is a mixture of three normal densities and a plot of the exact marginal density of , $p(\theta) =\sum p(\theta|\delta)p(\delta)$ will be like that that can be done using the following code in R :` mu Now it is very easy to obtain independent Monte Carlo samples from the joint distribution of $(\delta,\theta)$ First, a value of $\delta$ is sampled from its marginal distribution, then the value is plugged into $p(\theta|\delta)$ from which a value of $\theta$ is sampled (Note the sampled pair $(\delta,\theta)$ represents a sample from the joint distribution $p(\delta,\theta)=p(\delta)p(\theta|\delta)$ ) then the empirical distribution of the $\theta$ samples provides an approximation to the marginal distribution $p(\theta) =\sum p(\theta|\delta)p(\delta)$ . Now a histogram of 1,000 Monte Carlo -values generated in this way or in other words the empirical distribution of the Monte Carlo samples looks like $p(\theta)$ . set.seed(1) S For more details see A First Course in Bayesian Statistical Methods the book provides also a very good comparison between MC and MCMC Chapter 6 section "Introduction to MCMC diagnostics ". `
