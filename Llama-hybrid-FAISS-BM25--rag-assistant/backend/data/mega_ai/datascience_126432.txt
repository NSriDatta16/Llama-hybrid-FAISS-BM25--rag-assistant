[site]: datascience
[post_id]: 126432
[parent_id]: 
[tags]: 
Hyperparameter tuning

Jane trains three different classifiers: Logistic Regression, Decision Tree, and Support Vector Machines on the training set. Each classifier has one hyper-parameter (regularisation parameter, depth-of-tree, etc) that needs to set, so she chooses a set of 10 reasonable values for each and performs a sweep over those values (retraining the classifier each time) and chooses the value that gives the best performance on the test set. She then reports performance for the three classifiers with their best hyper-parameter settings on the test dataset. Is there a problem with her approach? I think the answer regards some problems related to overfitting ,isn't it?
