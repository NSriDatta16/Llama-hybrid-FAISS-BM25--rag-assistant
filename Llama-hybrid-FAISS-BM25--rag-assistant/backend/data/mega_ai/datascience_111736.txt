[site]: datascience
[post_id]: 111736
[parent_id]: 
[tags]: 
ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(880,) and logits.shape=(16, 3)

This is my multiclass neural network model. # We declared a function for creating a model. def build_model1_two_hidden_layers(): model = Sequential() # Input layer => input_shape must be explicitly designated model.add(Dense(16, input_shape = (normed_train_data.shape[1],))) # Output layer => output dimension = 1 since it is a regression problem model.add(Dense(3, activation='softmax')) # Activation: sigmoid, softmax, tanh, relu, LeakyReLU. # Optimizer: SGD, Adam, RMSProp, etc. # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers learning_rate = 0.0001 optimizer1 = optimizers.Adam(learning_rate) model.compile( optimizer=optimizer1, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'] ) return model Currently, I am not adding any hidden layer , just want to test the model withou hidden layers first.However , I have an assumption that the model recognize my output layer as hidden layer. This is my sample data input. SEX AGE MENTAL DIS HISTORY SUIC HISTORY LIVING ECONOMIC SUIC RISK ANXIETY STATE ANXIETY TRAIT 0.510342 2.133002 -0.605015 -0.645996 0.417973 0.429160 -1.533806 -1.690477 -1.867256 This is my error ValueError: labels.shape must equal logits.shape except for the last dimension. Received: labels.shape=(880,) and logits.shape=(16, 3) I think 880 is my size of dataset and 16 is the perceptrons for the input layer and 3 is the perceptron for output layer. How to rectify this error?
