[site]: crossvalidated
[post_id]: 132934
[parent_id]: 132924
[tags]: 
I'm not sure why your particular dataset got that particular result since the data is not available, but there's a reason logistic regression calculations "blow up": complete separation. If your interaction term creates a region of values where there are no expected events then the denominator of the chi-square calculation will go to zero and the statistic will go to infinity. Chi-square for tables is the sum of squared (observed-expected) divided by "expected". The fitted odds ratio would also be some number divided by zero or something very small and that might drive the odds ratio to very large or infinite values. Firth's penalized method is supposed to reduce the chances of this happening but you should also notice that some of your coefficients and standard errors have also "blown up". If you calculate odds ratios by exponentiation of values of 10 or 20, you get effective representations of numerical infinity. So it's not Firth's method that is at fault, but rather idiosyncrasies in your particular model applied to your data. You can often see teh cause of this by using tabular displays where the row is the event in question and the columns are the predictors. Supposedly the likelihood ratio tests are still valid in this case. You might also to consider exact methods.
