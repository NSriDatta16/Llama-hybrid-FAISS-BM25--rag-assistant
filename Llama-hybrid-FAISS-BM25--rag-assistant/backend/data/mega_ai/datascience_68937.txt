[site]: datascience
[post_id]: 68937
[parent_id]: 
[tags]: 
Making outputs of sub-models the inputs of other models LSTM

I'm trying to create a neural network that is composed of different sub-models. Each sub-model have their own inputs, which some of them can be shared between the sub-models. For example, sub-model 1 could be something like this: S1 = Input(shape=(1,50),name="Stats") S2 = LSTM(300,return_sequences = True)(S1) S3 = Dropout(0.5)(S2) S4 = LSTM(200,return_sequences = False)(S3) S5 = Dropout(0.5)(S4) S6 = Dense(100,kernel_initializer='uniform',activation='relu')(S5) S7 = Dense(1,kernel_initializer='uniform',activation='relu')(S6) And then, the output of this sub-model I want it to go as an input of a hidden layer. The thing is that the hidden layer I'm trying to do is also with LSTM and I read in some forums that using keras concatenate can do this. So, it would go like this: merge = concatenate([S7,A7,B7,...],name="conca") At last, I tried to gave this merge object to a new model that would be treated as a "hidden layer". It would go like this: hidden_1_1 = Input(shape=(1,6),name="Hidden_Layer_1")(merge) hidden_1_2 = LSTM(300,return_sequences = True)(hidden_1_1) hidden_1_3 = Dropout(0.5)(hidden_1_2) hidden_1_4 = LSTM(200,return_sequences = False)(hidden_1_3) hidden_1_5 = Dropout(0.5)(hidden_1_4) hidden_1_6 = Dense(100,kernel_initializer='uniform',activation='relu')(hidden_1_5) hidden_1_7 = Dense(1,kernel_initializer='uniform',activation='relu')(hidden_1_6) And I'm getting this error: TypeError: 'Tensor' object is not callable . So...how can I make that the outputs of the sub-models to be the inputs of the other models? In an image, what I'm trying to do is something like this, but the thing is that instead of a neuron, each neuron would be a model. Thank you in advance!
