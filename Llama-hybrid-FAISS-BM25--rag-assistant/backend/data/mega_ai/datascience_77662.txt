[site]: datascience
[post_id]: 77662
[parent_id]: 
[tags]: 
Why cant I overfit this dataset with my neural network?

I have read that given a model is complex enough and I train for enough epochs, my model should at some point overfit the dataset. However I implemented a simple neural network in keras and my validation set loss seems to never go up: import tensorflow as tf from tensorflow import keras import numpy as np import random from sklearn import datasets, preprocessing import matplotlib.pyplot as plt # import and scale dataset = datasets.load_boston() X = dataset.data y = dataset.target X = preprocessing.scale(X) y = y.reshape((y.shape[0], 1)) # shuffle shuffle_indices = list(range(X.shape[0])) random.shuffle(shuffle_indices) X = X[shuffle_indices] y = y[shuffle_indices] # tain-validation split X_train, y_train = X[:int(X.shape[0] * 0.7)], y[:int(X.shape[0] * 0.7)] X_val, y_val = X[int(X.shape[0] * 0.7):], y[int(X.shape[0] * 0.7):] # define and fit model model = keras.Sequential([keras.layers.Dense(X.shape[1], use_bias=True, activation="sigmoid"), keras.layers.Dense(128, use_bias=True, activation="sigmoid"), keras.layers.Dense(128, use_bias=True, activation="sigmoid"), keras.layers.Dense(128, use_bias=True, activation="sigmoid"), keras.layers.Dense(128, use_bias=True, activation="sigmoid"), keras.layers.Dense(128, use_bias=True, activation="sigmoid"), keras.layers.Dense(128, use_bias=True, activation="sigmoid"), keras.layers.Dense(y.shape[1]) ]) model.compile(optimizer=tf.keras.optimizers.SGD( learning_rate=0.0001 ), loss='MeanSquaredError') model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, verbose=1) # plot data plt.plot(range(1, len(model.history.history['loss']) + 1), model.history.history['loss'], label='Train Set Cost') plt.plot(range(1, len(model.history.history['val_loss']) + 1), model.history.history['val_loss'], label='Validation Set Cost') plt.xlabel("epoch") plt.ylabel("loss") plt.legend() plt.show() The model is a simple dense neural network with Mean Squared Error as its loss function and gradient descent as it's optimizer. I tried to make the network deeper, but the validation loss only keeps decreasing until it stops at one point.
