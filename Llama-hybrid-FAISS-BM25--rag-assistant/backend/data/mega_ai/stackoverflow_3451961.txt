[site]: stackoverflow
[post_id]: 3451961
[parent_id]: 3451861
[tags]: 
The most efficient way, if you don't need much state stored, is to do just what you hinted: create a Markov chain. Associated with each state is an array of probabilities of exit to the next state. This gives you complete control over the process and is pretty compact. (Note that you use it by generating a random number from 0 to 1 and doing a binary search on the cumulative probabililties.) An alternative, fuzzier approach is to maintain a set of probabilities and a set of biases. If you have a bias term like launcher_bias = 0.8*launcher_bias + 0.2*(1.0 - (last_item == launcher)) rocket_bias = 0.8*rocket_bias + 0.2*(last_item == launcher) and you weight your probabilities with these values (and then renormalize the whole set to 1, or equivalently if the total probability of all items ends up at 0.7 or somesuch, you pick values from 0 to 0.7) you will find that as you get excess launchers the probability of getting more will drop. But, at the same time, you'll increase the chance of getting rockets. Basically, you'll have some exponentially decaying weighting factor that prejudices you against launchers if you've had one recently.
