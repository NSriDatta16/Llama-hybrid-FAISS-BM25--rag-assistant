[site]: crossvalidated
[post_id]: 354420
[parent_id]: 152882
[tags]: 
Illustrating the Bias - Variance Tradeoff using a toy example As @Matthew Drury points out, in realistic situations you don't get to see the last graph, but the following toy example may provide visual interpretation and intuition to those who find it helpful. Dataset and assumptions Consider the dataset which consists of i.i.d. samples from $Y$ a random variable defined as $Y = sin(\pi x - 0.5) + \epsilon$ where $\epsilon \sim Uniform(-0.5,0.5)$ , or in other words $Y = f(x) + \epsilon$ Note that $x$ is not a random variable hence the variance of $Y$ is $Var(Y) = Var(\epsilon) = \frac{1}{12}$ We will be fitting a linear, polynomial regression model to this dataset of the form $ \hat f(x) = \beta_0 + \beta_1x + \beta_1 x^2 + ... + \beta_px^p$ . Fitting various polynomials models Intuitively, you would expect a straight line curve to perform badly as the dataset is clearly non linear. Similarly, fitting a very high order polynomial might be excessive. This intuition is reflected in the graph below which shows the various models and their corresponding Mean Square Error for train and test data. The above graph works for a single train / test split but how do we know whether it generalizes? Estimating the expected train and test MSE Here we have many options, but one approach is to randomly split the data between train / test - fit the model on the given split, and repeat this experiment many times. The resulting MSE can be plotted and the average is an estimate of the expected error. It is interesting to see that the test MSE fluctuates wildly for different train / test splits of the data. But taking the average on a sufficiently large number of experiments gives us better confidence. Note the gray dotted line that shows the variance of $Y$ computed at the beginning. It appears that on average the test MSE is never below this value Bias - Variance Decomposition As explained here the MSE can be broken down into 3 main components: $$E[ (Y - \hat f)^2 ] = \sigma^2_\epsilon + Bias^2[\hat f] + Var[\hat f]$$ $$E[ (Y - \hat f)^2 ] = \sigma^2_\epsilon + \left[ f - E[\hat f] \right]^2 + E\left[ \hat f - E[ \hat f] \right]^2$$ Where in our toy case: $f$ is known from the initial dataset $\sigma^2_\epsilon $ is known from the uniform distribution of $\epsilon$ $E[\hat f]$ can be computed as above $\hat f$ corresponds to a lightly colored line $E\left[ \hat f - E[ \hat f] \right]^2$ can be estimated by taking the average Giving the following relation Note: the graph above uses the training data to fit the model and then calculates the MSE on train + test .
