[site]: datascience
[post_id]: 88447
[parent_id]: 
[tags]: 
Which metric to use for evaluating a rating system

I have a system which gives a star rating of the quality of work(on scale of 1-5, 1 being extremely poor and 5 being exceptionally good). An expert labelled a test set with their ratings of quality of work. The data is imbalanced in the 5 classes(1,2,3,4,5), very few samples for Extremely poor and Exceptionally good ratings. Is there a metric which can take into account consideration that if system rated extremely poor quality work as very good or exceptionally good, it should be penalised more, as compared to when it rated an extremely poor rating as poor or average? And again due to imbalanced class distribution, straightforward accuracy is not the best measure. Any suggestions for metric?
