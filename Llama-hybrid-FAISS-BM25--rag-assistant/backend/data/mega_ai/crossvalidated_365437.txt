[site]: crossvalidated
[post_id]: 365437
[parent_id]: 
[tags]: 
What are advantages of random forests vs using bagging with other classifiers?

I'm studying Random Forests, but after reviewing the methods I got the following line of reasoning: I feel like the big advantage of random forests happens in the bagging process where nearly uncorrelated predictions are created due to the random features, producing predictions with low variance. On the other hand, this method doesn't require your classification method to be a decision tree. If other classification algorithms (LDA, QDA, logistic regression, etc) usually perform better than decision trees, why would I choose to use decision trees as my classifier? Random forests seem a lot more popular than bagging with other classifiers (it even got its own name) but I don't see any particular reason why.
