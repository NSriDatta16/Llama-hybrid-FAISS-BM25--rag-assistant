[site]: datascience
[post_id]: 67576
[parent_id]: 
[tags]: 
What does linearly decreasing training and accuracy loss means?

I am trying to train an LSTM autoencoder for sentence embeddings:- Embedding size = 600 LSTM Hidden size = 600 Vocab Len = 3972 Number of LSTM layers = 1 Bidirectional = True Here the architecture of the encoder is:- Embedding layer mapping 3972 nodes to 600 LSTM taking the whole sequence and giving output and state of shape (2*num_layers, 600) This output and state is then used to set state and hidden state of a decoder, whose architecture is:- Embedding layer mapping 3972 nodes to 600 LSTM taking the whole sequence and giving output and state of shape (2*num_layers, 600) Softmax(linear_layer mapping 600 to 3972) I have tried many different architectures and most have been just an overfitting failure. Although, training the model with this config, here is the loss vs epoch and accuracy vs epoch : This article , although says that if the training loss and validation loss are decreasing linearly then the model is underfitting. Still, there is some confusion as the same article says that it is underfitting coz of :- 1) The model complexity is not able to learn the data and the model should be increased in complexity(increase the layers/nodes per layer) 2) The training is stopped prematurely. My concern is:- 1) the loss graph is not linear exactly, so is it underfitting? if it is, then, 2) Should I continue training or should I change the architecture?
