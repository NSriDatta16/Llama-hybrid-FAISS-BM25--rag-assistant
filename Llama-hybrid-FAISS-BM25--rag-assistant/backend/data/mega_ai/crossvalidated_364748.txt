[site]: crossvalidated
[post_id]: 364748
[parent_id]: 
[tags]: 
When training a neural network to determine appropriate number of epochs should you look at validation loss or validation objective loss?

I'm currently training a basic feedforward neural network for a binary classification task. For the loss function I'm currently using logloss, but the actual objective that I'm looking to improve on is ROC AUC. I understand that you typically look for where validation loss diverges from the training loss. However, in this case while the validation loss (logloss) has diverged, the validation AUC value keeps on improving.
