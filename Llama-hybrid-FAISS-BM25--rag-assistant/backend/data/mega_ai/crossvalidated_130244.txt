[site]: crossvalidated
[post_id]: 130244
[parent_id]: 130207
[tags]: 
You might try a more general non linear dimensionality reduction manifold learning method like locally linear embedding, laplacian eigenmaps or t-SNE. It is perfectly possible for there to be a lower dimensional subspace (manifold) in your data in a way that leaves 0 correlation between the N-basis dimensions. For example a circle of points about the origin or wave form as seen here . PCA won't pick this up but other methods will. Looking at such methods is especially interesting and common for visualization and exploratory data analysis. For use within a classifier or other model you'll need to restrict yourself to the methods that can be fit on training and applied on test which excludes lots of these methods. If this is your main interest you should also look into methods for unsupervised pretraining and (supervised) feature engineering.
