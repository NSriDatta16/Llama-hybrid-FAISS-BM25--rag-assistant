[site]: crossvalidated
[post_id]: 100932
[parent_id]: 100926
[tags]: 
To test for interaction / moderation (basically synonymous), first add brand commitment as a predictor in your linear model, then multiply brand commitment by review valence, and add the product to the model too. It is important to have both the main effects in the model when including their interaction, and you may want to center the variables before multiplying them to handle nonessential multicollinearity (I've read in places that this is not much of a solution though, and haven't got a better one offhand). Brand commitment is ordinal though, so ANOVA is not appropriate (I wonder if review valence might be ordinal too) – it wastes information by ignoring the order of ranks. There are a few options to consider here: If you think the three brand commitment items measure the same latent construct... ...and you have a lot of data and motivation to do things right, you can estimate a latent continuous construct with a rating scale model à la item response theory, then add the latent factor as a single continuous predictor. This will allow control of measurement error. ...and you want to go the quick and dirty route, you can adopt the usual classical test theory assumptions, take the average or sum of the three items' Likert ratings, and enter this as a single continuous predictor. This assumes measurement error balances out, but it may not. If you think the three brand commitment items measure different constructs, or want to estimate their relationships separately for some other reason (and are prepared to tangle with potential multicollinearity problems)... Penalized regression (see " Continuous dependent variable with ordinal independent variable ") works well for ordinal predictors. It may give you a bit of a headache to have 8 dummy coefficients for each of your three brand commitment items though. Nine response options per item might be enough to justify treating responses as continuous, especially if their frequencies aren't distributed too bizarrely. See my discussion of Bollen and Barb (1981) here – basically, with more than five response options, binning continuous data into ordinal groups doesn't attenuate correlations too awfully much (i.e., less than 10%), so the logic is that data collected as ordinal ought to be continuous enough with > 5 ranks. Interactions will be tougher to interpret with this method. You'll end up with products of all your dummy coefficients, which will probably make for some terrifying output. AFAIK, you can test the overall significance of these interactions with an F -test comparing the model with all these interactions to the nested model without all of them, which will produce relatively succinct output...but IMO, it's still a lot more daunting than having an interaction between a single continuous variable and one other categorical factor with three levels. Even without the F -test, that's only two product terms (one for each dummy code of the discrete variable). Another issue to consider is the reference distribution for your response variable. Purchase probability sounds binary, in which case you'd want to use logistic regression, but if you have actual percentages that you're modeling instead of just did / not purchase ( 0 / 1 , or some such codes), you might want to go with beta regression, or maybe even a nonparametric model.
