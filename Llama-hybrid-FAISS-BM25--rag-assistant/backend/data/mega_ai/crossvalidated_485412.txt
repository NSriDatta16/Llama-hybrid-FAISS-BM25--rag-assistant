[site]: crossvalidated
[post_id]: 485412
[parent_id]: 
[tags]: 
Correlation of Two Continuous Variables as a Function of the Exponential Decay of a Third Continuous Variable

I'm trying to model the Pearson correlation coefficient ( $\rho$ ) of some time-invariant value (average annual rainfall in this example) as a function of separation distance between two locations. I expect correlation to be high if the locations are close but decay to zero for large separations. I have a dataset of average rainfall at each location and by taking all pairwise combinations of locations I can generate a dataset with columns: average annual rainfall at location 1 ( $x_1$ ) average annual rainfall at location 2 ( $x_2$ ) distance between locations 1 and 2 ( $d$ ) By binning this dataset by distance and plotting the correlation coefficient within each bin I can visually confirm that the correlation coefficient follows an approximately exponential decay from some finite value at $d = 0$ , decaying to zero at large $d$ . I would like to fit a model of the form: $$\rho = \rho_0e^{-d/d_0}$$ Is there a way to go about this that allows fitting of one model to all the data (as opposed to binning the data into subsets)? I understand the general principle that one can use an interaction term in a regression model to capture the correlation but have been unable to apply it to this problem. The general form of this problem seems like one that would occur commonly but I've not been able to find reference to it in my searching.
