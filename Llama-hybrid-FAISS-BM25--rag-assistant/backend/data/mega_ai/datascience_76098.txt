[site]: datascience
[post_id]: 76098
[parent_id]: 76096
[tags]: 
First you should define a metric that suits the problem $R^2$ in your case. Do a correct cross-validation and train test splits. And then choose in the cross validation which option has the best results for your model (imputing missing or xgboost no imputing). This way you are doing an empirical experiment and selecting the best result. Probably you want to have a look to sklearn pipeline to do that.
