[site]: crossvalidated
[post_id]: 624380
[parent_id]: 
[tags]: 
Getting a Many to One LSTM/MLP to overfit

I have a dataset of 20 thousand horses. For each horse, I have its 10 last historical races (finishing time, position, track name, distance etc. for 41 features) and am trying to predict its finishing time in its next race (i.e. its current race.) To do so, I am using an LSTM as a feature selector for a horse's historical races, into a feed-forward network whose first layer is additionally comprised of features pertinent to the race being predicted (track name, distance, starting position etc. for 27 features) I am aiming to get within 0.1 MAE (mean) since for a given race, finishing times typically differ by 0.05-0.1. To begin with, I am simply trying to overfit my model to validate my data, pipeline and model's capacity. I have done so in the past with CNNs successfully. However, I can't seem to be able to converge to less than ~0.3 MAE. This indicates that the model has learned patterns in the data - but I am aiming to overfit as close to 0 MAE on the train set as possible. import torch import torch.nn as nn from torch.utils.data import Dataset, DataLoader import random import torch.optim as optim from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error import random from torch.utils.tensorboard import SummaryWriter writer = SummaryWriter(log_dir='./logs') ## CREATE DATASETS AND DATA LOADERS class RaceDataset(Dataset): def __init__(self, data): self.hist_race_features = data['hist_race_features'] self.current_race_features = data['current_race_features'] self.targets = data['targets'] self.indices = list(range(len(self.targets))) random.shuffle(self.indices) def __len__(self): return len(self.targets) def __getitem__(self, idx): shuffled_idx = self.indices[idx] hist_race = torch.tensor(self.hist_race_features[shuffled_idx], dtype=torch.float32) # torch.Size([10, 41]) current_race = torch.tensor(self.current_race_features[shuffled_idx], dtype=torch.float32) # torch.Size([27]) target = torch.tensor(self.targets[shuffled_idx], dtype=torch.float32) # torch.Size([1]) return {'hist_race_features': hist_race, 'current_race_features': current_race, 'targets': target} batch_size = 64 train_dataset = RaceDataset(train_data) test_dataset = RaceDataset(test_data) train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True) ## DEFINE MODEL AND HYPERPARAMS class CompositeModel(nn.Module): def __init__(self, seq_input_size, cur_input_size, lstm_hidden_size, lstm_num_layers, ff_hidden_size): super(CompositeModel, self).__init__() self.lstm = nn.LSTM(seq_input_size, lstm_hidden_size, lstm_num_layers, batch_first=True) self.ff = nn.Sequential( nn.Linear(lstm_hidden_size + cur_input_size, ff_hidden_size), nn.ReLU(), nn.Linear(ff_hidden_size, ff_hidden_size), nn.ReLU(), nn.Linear(ff_hidden_size, ff_hidden_size), nn.ReLU(), nn.Linear(ff_hidden_size, ff_hidden_size), nn.ReLU(), nn.Linear(ff_hidden_size, ff_hidden_size), nn.ReLU(), nn.Linear(ff_hidden_size, 1) ) def forward(self, historical_data, current_data): lstm_output, _ = self.lstm(historical_data) lstm_last_output = lstm_output[:, -1, :] combined_features = torch.cat([lstm_last_output, current_data], dim=1) predicted_time = self.ff(combined_features) return predicted_time seq_input_size = 41 # Feature per historical race cur_input_size = 27 # Features for the race getting predicted lstm_hidden_size = 1024 lstm_num_layers = 5 lstm_dropout = 0.0 ff_hidden_size = 512 attention_size = 32 model = CompositeModel(seq_input_size, cur_input_size, lstm_hidden_size, lstm_num_layers, ff_hidden_size, attention_size) learning_rate = 0.001 num_epochs = 10000 criterion = nn.MSELoss() optimizer = optim.Adam(model.parameters(), lr=learning_rate) device = torch.device("cuda" if torch.cuda.is_available() else "cpu") model.to(device) # TRAIN MODEL best_test_loss = float("inf") counter = 0 for epoch in range(num_epochs): model.train() # Train on batches train_losses = [] train_targets = [] train_outputs = [] for batch in train_data_loader: hist_race_features = batch["hist_race_features"].to(device) current_race_features = batch["current_race_features"].to(device) targets = batch["targets"].to(device) optimizer.zero_grad() outputs = model(hist_race_features, current_race_features) loss = criterion(outputs, targets) loss.backward() optimizer.step() train_losses.append(loss.item()) train_targets += list(targets.cpu().numpy().flatten()) train_outputs += list(outputs.detach().cpu().numpy().flatten()) # Evaluate training metrics avg_train_loss = sum(train_losses) / len(train_losses) train_rmse = mean_squared_error(train_targets, train_outputs, squared=False) train_mean_ae = mean_absolute_error(train_targets, train_outputs) train_median_ae = median_absolute_error(train_targets, train_outputs) model.eval() # Test on batches test_losses = [] test_targets = [] test_outputs = [] with torch.no_grad(): for batch in test_data_loader: hist_race_features = batch["hist_race_features"].to(device) current_race_features = batch["current_race_features"].to(device) targets = batch["targets"].to(device) outputs = model(hist_race_features, current_race_features) test_loss = criterion(outputs, targets) test_losses.append(test_loss.item()) test_targets += list(targets.cpu().numpy().flatten()) test_outputs += list(outputs.cpu().numpy().flatten()) # Evaluate testing metrics avg_test_loss = sum(test_losses) / len(test_losses) test_rmse = mean_squared_error(test_targets, test_outputs, squared=False) test_mean_ae = mean_absolute_error(test_targets, test_outputs) test_median_ae = median_absolute_error(test_targets, test_outputs) # Write logs writer.add_scalars('Average Loss', {"train": avg_train_loss, "test": avg_test_loss}, epoch) writer.add_scalars('Root Mean Squared Error', {"train": train_rmse, "test": test_rmse}, epoch) writer.add_scalars('Mean Absolute Error', {"train": train_mean_ae, "test": test_mean_ae}, epoch) writer.add_scalars('Median Absolute Error', {"train": train_median_ae, "test": test_median_ae}, epoch) My guess is that this model should be powerful enough to overfit the train dataset but it doesn't. I have tried more complex models with out success also. The below results are after about 40min of training on an RTX 2060. Am I missing something? Is there a bug in my pipeline? Or is it just more difficult than I anticipated to get something to overfit?
