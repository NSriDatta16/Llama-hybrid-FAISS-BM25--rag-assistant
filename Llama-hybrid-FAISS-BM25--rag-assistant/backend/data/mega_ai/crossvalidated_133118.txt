[site]: crossvalidated
[post_id]: 133118
[parent_id]: 
[tags]: 
Linear regression - is a model "useless" if $R^2$ is very small?

Given a complex output which depends on many underlying factors, I am given 3 explanatory variables and about 10K data points and the task to assess their impact on the output. The OLS model is very weak - it has an $R^2$ of about 0.7%. There are clear deviations from normality and the Cook's plot shows numerous outliers. However the estimates of the coefficients for the explanatory variables show up as highly significant (95% confidence). EDIT: Based on a few helpful comments, I have pinned the question down further to: Is the t-test of the coefficients enough to guarantee that the results of the model can be trusted (i.e. are not spurious) despite the high variance of the dependent variable and low $R^2$? I consider the model as useful not if it shows a good fit, or if it has a good predictive power, but if we were to test the relationship between the dependent and independent variables in an experimental setting, increasing the independent variables would show on average the same effect on the dependent variable as estimated by the model. As a side-note, to deal with the non-normality and the outliers I ran a robust regression and I calculated the coefficient distribution using a non-parametric bootstrap with the bootstrap sample size chosen to be 80% of the total sample size. The estimated coefficients are quite similar.
