[site]: crossvalidated
[post_id]: 164417
[parent_id]: 50786
[tags]: 
I see a few possibilities. You could bin the response into a few arbitrary categories and use a classification tree If the counts are typically very low, 0, 0, 0, 1, 0, 3, 0, 2, you could treat each integer count as a class and again use a classification tree (probably not your case). In these cases, it's going to be harder to get a high variance explained type metric as opposed to continuous regression. If the counts are not typically low and there is a lot of variation, I'd just go for it with a regression tree. Using poisson regression over linear regression, for instance, is only gravy when it comes to getting a good linear predictor. If you're not seeing good predictive power with the random forest, then I doubt a fancier model that specifically accommodates count data is going to do a lot for you. Update (2020-12-11) Since writing this answer, a Kaggle contest (the M5 competition) showed me a situation where using Poisson loss in a LightGBM framework did really well for retail sales data with low counts. I don't know how much better it did than mean squared error but many of the public notebooks were using it, and it was an easy switch. I don't think my second bullet is a very good idea but I'll leave it up.
