[site]: crossvalidated
[post_id]: 547752
[parent_id]: 
[tags]: 
Questions about validation loss in deep learning

I believe the formula for calculating validation loss is $J=\frac{1}{N}\sum^N_i f(\hat y_i, y_i)$ where $N$ is the number of the data and $f$ is the loss function. However, some people calculate validation loss as $J=\frac{1}{M}\sum f(\hat y, y)$ where $M$ is the number of an epoch. What is the difference between them? Let's say we compare two models for the same task (e.g. hyperparameter search). The first model which has a smaller batch size than the other will get small validation loss because of the second formula. Then how do I compare the different models with different batch sizes? Should I use different metrics such as F1 score or accuracy rather than validation loss?
