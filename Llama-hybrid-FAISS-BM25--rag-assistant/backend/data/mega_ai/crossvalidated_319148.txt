[site]: crossvalidated
[post_id]: 319148
[parent_id]: 319024
[tags]: 
Cooks distance shows how much the whole regression model would change if $(x_i, y_i)$ is removed. I am not quite clear what you mean by "hat value". Do you mean $e_i = y_i - \hat{y}_i$, or $h_{ii}$ in the hat matrix $H$ (i.e. leverage )? Either way they are different from cooks distance. Note that cooks distance takes the form $$D_i = \frac{e_{i}^{2}}{s^{2} p}\left[\frac{h_{ii}}{(1-h_{ii})^2}\right]$$, so it's related to both residual $e_i$ and leverage $h_{ii}$. Large $D_i$ could be due to large $e_i$ or $h_{ii}$, or both. Possible reasons for large residual $e_i$: $y_i$ far from fitted value (possibly outlier) large leverage $h_{ii}$: $x_i$ far from other $x_{j}$'s (influential point due to the value of $x$)
