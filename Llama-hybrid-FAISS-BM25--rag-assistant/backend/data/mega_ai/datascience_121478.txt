[site]: datascience
[post_id]: 121478
[parent_id]: 121475
[tags]: 
The issue is not with the imbalance per se. The issue is that your categories are not particularly separable on the available data (or they are but you are not modeling the correct relationship, e.g., needing a quadratic term yet lacking one). When imbalanced categories are easy to distinguish, performance is high. For instance, I see a lot more Honda cars than Ferrari cars (imbalanced classes). Nonetheless, I do not strugle to distinguish between the two, beause they look so different. $^{\dagger}$ In this case, the class imbalance is not an issue, and it is easy to identify the correct car manufacturer just about every time. On the other hand, I see these two "identical" twins about equally often (no imbalance), and I struggle to tell them apart, since they look so similar. In this case, despite the lack of imbalance, I mix up their names all the time and struggle to distinguish between them. Two Cross Validated links are worth reading. How to know that your machine learning problem is hopeless? The gist here is that some problems are just hard, such as hoping to predict the toss of a fair coin. Are unbalanced datasets problematic, and (how) does oversampling (purport to) help? The gist here is that imbalanced problems are not so inherently different from balanced problems. $^{\dagger}$ I am reminded of a quote from the movie My Cousin Vinny , which is a possible spoiler. They are discussing if getaway vehicles could be mistaken for each other: "One was the Corvette, which could never be confused with the Buick Skylark."
