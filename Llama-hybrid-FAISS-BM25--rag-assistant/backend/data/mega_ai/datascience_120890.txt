[site]: datascience
[post_id]: 120890
[parent_id]: 120532
[tags]: 
That code is a combination of raw Python and the Pandas library. It might be more useful to use the Hugging Face library which is designed for this task. Something like: # Load imbd dataset from datasets import load_dataset imdb = load_dataset("imdb") # Load T5 specific tokenizer from transformers import T5Tokenizer tokenizer = T5Tokenizer.from_pretrained('t5-small', model_max_length=512) # Apply T5 specific tokenizer to the imdb dataset def preprocess_function(examples): return tokenizer(examples["text"], truncation=True) tokenized_imdb = imdb.map(preprocess_function, batched=True)
