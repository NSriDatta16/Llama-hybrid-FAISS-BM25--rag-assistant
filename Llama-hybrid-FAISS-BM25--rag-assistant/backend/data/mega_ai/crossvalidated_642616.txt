[site]: crossvalidated
[post_id]: 642616
[parent_id]: 
[tags]: 
How to use propensity scores in real examples

I am trying to understand how to use propensity score matching in a real world example (e.g. case control study). Step 1: Based on what I understand, I think a Logistic Regression is first used to estimate the Propensity Scores: $$P(T=1|X=x) = \frac{e^{(\beta_0 + \beta_1x)}}{1+e^{(\beta_0 + \beta_1x)}}$$ $T$ is the treatment assignment $X$ is the vector of covariates $\beta_0$ and $\beta_1$ are the parameters to be estimated Step 2: From here, we then use some matching algorithm (e.g. nearest neighbors) to match each individual in the case group ( $i$ ) to a similar individual within the control group ( $j$ ) based on their estimated propensity scores: $$d_{i,j} = \arg\min_{j \in C} |p_i - p_j|$$ Step 3: Finally, we use a conditional likelihood which takes into consideration the treatment, matching and propensity scores (unadjusted model, effect of covariates are only included in propensity score matching, not in the later model ... but this optional I think). We are modelling the treatment effect in matched patients: For outcome for the treated individual in pair $i$ as $Y_{1i}$ and the outcome for the control individual in pair $i$ as $Y_{0i}$ . The treatment effect for pair $i$ is then $Y_{1i} - Y_{0i}$ . The regression model for the treatment effect could be written as: $$Y_{1i} - Y_{0i} = \alpha + \gamma P_i + \epsilon_i$$ $Y_{1i} - Y_{0i}$ is the treatment effect for pair $i$ $P_i$ is the average propensity score for pair $i$ $\alpha$ and $\gamma$ are parameters to be estimated $\epsilon_i$ is the error term for pair $i$ For $n$ matched patient pairs, the likelihood becomes: $$L(\alpha, \gamma|\Delta Y, P) = \prod_{i=1}^{n} f(\Delta Y_i|\alpha, \gamma, P_i)$$ where $\Delta Y_i = Y_{1i} - Y_{0i}$ is the treatment effect for pair $i$ , and $f(\Delta Y_i|\alpha, \gamma, P_i)$ is the conditional probability density function of $\Delta Y_i$ given $P_i$ . Is this the correct understanding? Example: For a logistic regression example - (assuming Steps 1 and 2 have already been completed, here is how Step 3 would look (assume 4 patients, 2 pairs : Patient 1 and Patient 2, Patient 3 and Patient 4) : Patient 1: Treated ( $T_1 = 1$ ), Propensity Score $P_1 = 0.6$ , Outcome $Y_{11} = 1$ Patient 2: Control ( $T_2 = 0$ ), Propensity Score $P_2 = 0.5$ , Outcome $Y_{02} = 0$ Patient 3: Treated ( $T_3 = 1$ ), Propensity Score $P_3 = 0.7$ , Outcome $Y_{13} = 0$ Patient 4: Control ( $T_4 = 0$ ), Propensity Score $P_4 = 0.7$ , Outcome $Y_{04} = 1$ The treatment effect for each pair is $Y_{11} - Y_{02}$ for Pair 1 and $Y_{13} - Y_{04}$ for Pair 2. The regression model for the treatment effect is: $$Y_{1i} - Y_{0i} = \alpha + \gamma P_i + \epsilon_i$$ where $P_i$ is the average propensity score for pair $i$ , and $\epsilon_i$ is the error term for pair $i$ . The likelihood for these two matched pairs would be: $$L(\alpha, \gamma|\Delta Y, P) = f(\Delta Y_1|\alpha, \gamma, P_1) \times f(\Delta Y_2|\alpha, \gamma, P_2)$$ where $\Delta Y_i = Y_{1i} - Y_{0i}$ is the treatment effect for pair $i$ , and $f(\Delta Y_i|\alpha, \gamma, P_i)$ is the conditional probability density function of $\Delta Y_i$ given $P_i$ . For a logistic regression model for the outcome, each term in the product would be a Bernoulli probability: $$f(\Delta Y_i|\alpha, \gamma, P_i) = [P(\Delta Y_i=1|\alpha, \gamma, P_i)]^{\Delta Y_i} [1-P(\Delta Y_i=1|\alpha, \gamma, P_i)]^{1-\Delta Y_i}$$ where $P(\Delta Y_i=1|\alpha, \gamma, P_i)$ is the predicted probability of the treatment effect being 1, given by the logistic function: $$P(\Delta Y_i=1|\alpha, \gamma, P_i) = \frac{e^{(\alpha + \gamma P_i)}}{1+e^{(\alpha + \gamma P_i)}}$$
