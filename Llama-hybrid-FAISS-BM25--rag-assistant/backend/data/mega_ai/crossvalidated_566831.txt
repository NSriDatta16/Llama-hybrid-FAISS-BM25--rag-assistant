[site]: crossvalidated
[post_id]: 566831
[parent_id]: 566826
[tags]: 
Bayesian optimization (BO) is a recipe to tell how you should explore the hyper-parameter (HP) space. So, you'll be using your validation set as before, but exploring the space in the direction that BO suggests. This is typically useful when you have a lot of HPs to tune and it's computationally expensive (or impossible) to try them all. Grid search explores the HP space in an ordered manner; random search just randomly picks some HP values but BO selects the next HPs to try based on how much information it'd gain from trying that HPs with your model. It's much more economic for a large and high dimensional HP space.
