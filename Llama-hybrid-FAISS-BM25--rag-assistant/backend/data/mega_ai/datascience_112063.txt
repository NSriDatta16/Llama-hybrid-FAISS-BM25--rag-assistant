[site]: datascience
[post_id]: 112063
[parent_id]: 
[tags]: 
Parameters for training a sentence-similarity model using Bert?

I have a list of sentences : sentences = ["Missing Plate", "Plate not found"] I am trying to find the most similar sentences in the list by using Transformers model with Huggingface embedding . I am able to find the similar sentences but the model is still not able to identify the difference between : "Message ID exists" "Message ID doesn't exist" [Note: I am trying to find the similarity by using the Cosine similarity from pytorch] Can you suggest me ways to hyperparameter tune my model so that the model can weigh in more on the negative words and consider them opposite? I found the list of parameters that can be tuned but not sure what the best parameters would be Thanks!
