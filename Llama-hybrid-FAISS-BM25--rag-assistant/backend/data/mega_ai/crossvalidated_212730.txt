[site]: crossvalidated
[post_id]: 212730
[parent_id]: 
[tags]: 
How would you represent this one-vs-all SVM accuracy?

I have a set on one-vs-all SVMs. Let's say I have three classes. I want to show FAR and FRR from the system, but I appear to get getting very large FRR values and very little FAR values. This is because I use a positive test set from the genuine class as positive test data and the positive data from all other classes as negative test data for a test. This means that I get an equal number of FAR and FRR values. If a genuine sample is falsely rejected then it means another SVM will falsely accept it in another test for another user. This gives the same FAR and FRR values. But it means the FAR and FRR percentages are EXTREMELY different. The negative dataset can be up to 100 times bigger than the positive set. This means that, if we have n false rejections (and consequently false acceptances) then we have n/pos_data_size FRR and n/(pos_data_size*100) FAR! I would like to nicely represent the error rates. But this seems to be very difficult to do! Is there a way that would work in this case?
