[site]: crossvalidated
[post_id]: 259135
[parent_id]: 259121
[tags]: 
Thanks for the clarification. If you want to take the uncertainty about your initial data-based estimate into account, then I think this is what the math looks like. Let $q$ be the true probability of success. You have gathered some data $D$ generated by a Binomial process with this success rate. In this data, you observed $N$ successes. From this, you can work out the following posterior distribution (assuming you have no prior beliefs about $q$): $$ p\left(q\mid D\right)\propto Binomial(N,q) $$ This gives you the probability (up to a constant of Normalization), given your data, that $q$ has a certain value. You can reduce this distribution to a point-estimate $\hat{q}$, for example by taking the value of $q$ with the highest probability under the distribution. Supposing you have no prior assumptions about $q$, this corresponds to the maximum likelihood estimate (MLE), which is given by the rate of successes in your sample (in your case: $\hat{q}_{ML}=0.95$). If you now want to predict the number of successes $M$ in a new dataset, you could condition on your point estimate $\hat{q}$, and compute the probability $p(M|\hat{q})=Binomial(M,\hat{q})$. However, you indicate that you want to take on board your uncertainty about $q$, which means you want to account for every possible value of $q$, and its probability, when making your prediction of the number of successes $M$ in a new dataset. Your prediction should therefore be based on the following distribution, in which you marginalize over your belief about $q$ given the data: $$ p(M\mid D)=\int{p\left(M\mid q\right)p\left(q\mid D\right)\mathrm{d}q} $$ From this distribution, you can then read off an estimate for $M$ and a confidence interval around that estimate. The integral over $q$ might be difficult to work out analytically (and note that you'd also have to work out the Normalization constant that I left out in the definition of $p\left(q\mid D\right)$). However, you could approximate it using MCMC sampling methods, or by using the Normal approximation of the Binomial distribution (in this case, the integral boils down to a convolution of Gaussians, for which there are standard results you can use).
