[site]: datascience
[post_id]: 4861
[parent_id]: 4845
[tags]: 
While reading blogs and papers is helpful to identify the latest and greatest, having a solid foundation helps a lot, too. But I assume you already have gone over Manning's great (and free in e-book form) book on IR, right? http://nlp.stanford.edu/IR-book/ It contains information on creating your own thesaurus from your document collection to solve synonymy problems, LSA for polysemy, etc.. As for similarity measures, you will see there that Okapi BM25 (Robertson et al.) is considered superior to cosine similarity (but more expensive to implement and run). Regarding the current state of the art, there was a small emergence of Bayesian Network-based classifiers in the early nineties (starting with Turtle & Croft), but that went quiet for a while. However, right now, using BNs for IR is again finding some revival, particularly in biomedical IR. In that respect, I think most ongoing work is directed towards using Bayesian models incl. topic models and deep learning for word-sense disambiguation (WSD) and semantic similarity. Here is a pointer to a recent paper with good references on the topic. http://arxiv.org/abs/1412.6629
