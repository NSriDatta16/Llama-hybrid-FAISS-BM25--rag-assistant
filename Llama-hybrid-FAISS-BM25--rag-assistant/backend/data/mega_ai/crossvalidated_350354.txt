[site]: crossvalidated
[post_id]: 350354
[parent_id]: 
[tags]: 
Is there a test error metric that takes into account variance of the data?

In standard machine learning applications, models are often evaluated based on metrics like RMSE or Deviance. I was wondering if there is a similar metric tailored towards meta-analyses that takes into account not just the value of a data point, but its variance as well? So deviations between the model and the data are penalized less for data points with low variance compared to those with higher variance.
