[site]: crossvalidated
[post_id]: 146215
[parent_id]: 146214
[tags]: 
Random forest is not not just a bunch of trees -- each of them is built on a different resample of objects (i.e. it is a bagging ensemble) and optimisation of splits is clipped to $m$ randomly selected attributes. Both procedures are applied mainly to reduce the correlation of individual trees and thus make voting work, and in context of a single tree they actually hurt its accuracy. Also, you have set max_depth of a decision tree to 1, which makes it a dumb single-split model rather than a decision tree. This way you got unrealistically bad accuracies in both cases.
