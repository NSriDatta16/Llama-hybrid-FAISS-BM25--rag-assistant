[site]: crossvalidated
[post_id]: 434158
[parent_id]: 
[tags]: 
When regularizing based on an informative prior, how to give model a little more freedom to partially reject regulariziation

I am new here I hope this question is appropriate. I am modelling a spatial domain, whereby I have repeated measures at n locations. I make a bayesian linear model at each n locations based on about 6 temporal repeated measure points. I think the predicted data $y_n$ is fairly noisy, but hard to know theoretically what the noise level is, as the emperical estimate of $\sigma_{yn}$ would presumably include both model misspecification plus measurement error. Therefore, I regularize the parameter of interest: (the slopes) $\beta_n$ by a spatial process. The assumption here is that the slope values should be similar to nearby locations. And that closer locations should be even more similar. There are common sense reasons why this might be the case, but also some (potentially drastic) deviations in nearby $\beta_n$ are to be expected. Here is a Kruschke diagram of my model. So my question is: What are my options to allow my model a little bit more flexibility to express small scale or local deviations? Things I've thought of: 1.) One of the great benefits of Bayes is that you throw in all your uncertainties and estimate a joint posterior. Therefore, maybe I am giving my model the enough freedom to partially reject regularization, it is just choosing not to. I have given it my prior assumptions and the posterior is the answer. Maybe I should not want less regularization. 2.) Allowing $\sigma_n$ the noise of the spatial process be larger along diagnol of covariance matrix. I haven't been able to estimate a posterior for this parameter (I get an internal pymc3 error when I try. Furthermore, all posteriors of hyperparameters are difficult to estimate!). So I have been setting $\sigma_n$ to small scalar values. A posterior estimate of this might be a great improvement though eh? 3.) setting $\sigma_{yn}$ (The uncertainty of predicted variable) to be smaller, thereby relying on a more independent regression at each location $n$ . My data are normalized so $\sigma_{yn}'s$ should be 1 without the linear model. But with the linear model I only see a small reduction of $\sigma_{yn} \sim N(0.9,.1)$ . Setting a scalar value to the combined measurement error plus model specification seems less than ideal. As I suspect both of these are fairly moderate in size. Maybe incorporate a measurement error layer? I have seen this done in McElreath's Statistical Rethinking: $y_{obs_i} ∼ Normal(y_{true_i} , y_{se_i} ) $ $y_{true_i} ∼ Normal(μ_i , σ_i)$ I suppose this might cause more shrinkage not less. But might be useful. 4.) Adding an additional spatial process to the linear model to account for smaller scale fluctuations. Haven't thought this one through well. Any thoughts, comments, questions would be appreciated! Thanks
