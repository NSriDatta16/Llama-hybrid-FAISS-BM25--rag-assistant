[site]: crossvalidated
[post_id]: 580201
[parent_id]: 
[tags]: 
Compromise between ranked and kernel-based estimate of empirical distribution (for estimating likelihood of single value)

Setup I have: About fifty values $x_1,…,x_n$ sampled from the same but unknown distribution $X$ . I have no useful theoretical insight on the nature of that distribution. Empirically, the distribution is considerably prone to outliers (heavy tail). A single value $y$ for which I would like to estimate the probability $p$ that it was sampled from the above distribution. Several iterations of the same scenario, but with the distribution of $X$ varying (including its general form). Using a subset of the data with a known ground truth, these allow for a benchmark my choices (the details of which go beyond the scope of this question). Since I have several iterations, any solution must work automatically. For example, I cannot prune outliers by hand (not that I would consider this a particularly good approach). What I considered so far I know that my problem boils down to estimating the CDF of $X$ . I can then obtain a one-sided $p=\text{CDF}(y)$ and from this it’s straightforward to get a two-sided $p$ . I see three general ways to do that: Just rank all values with $r_y$ being the rank of $y$ . Then I can compute: $\text{CDF}(y) = \frac{r_y+1}{n+1}$ (for low $y$ ). Create a kernel-density estimator $K$ and use its CDF. (I have means to obtain a reasonable estimate of the kernel width.) Assume normality (or some other parametric distribution), fit its parameters and use the resulting CDF. Now, a rank-based approach (1) is not overly sensitive to outliers, however it’s too radical in not making a distinction between close and extreme outliers. The kernel-based approach (2) is overly sensitive to outliers (at least for a Gaussian kernel and any reasonable kernel width). Using some parametric distribution (3) is far out and cannot handle outliers at all. My benchmark results support this. Now, the best way forward for me seemed to just mix the ranked- and kernel-based approach, i.e., average their CDFs (possibly with a weight). My benchmark confirms this and yields a higher performance than for the unmixed approaches. This is reasonably robust with respect to the mixing ratio: Anything between roughly 3:7 and 7:3 (kernel to ranked) yields the same good result. Questions My mixing approach feels awkwardly arbitrary, although I have a benchmark that at least somewhat supports it. Is there any reasonable argument or reference for the mixing approach? Is there any approach that is similar in nature (and might perform even better)? Is there another relevant approach that I am missing?
