[site]: crossvalidated
[post_id]: 257328
[parent_id]: 
[tags]: 
Why is boosting less likely to overfit?

I've been learning about machine learning boosting methods (e.g., ADA boost, gradient boost) and the information sources mentioned that boosting tree methods are less likely to overfit than other machine learning methods. Why would that be the case? Since boosting overweights inputs that were not predicted correctly, it seems like it could easily end up fitting the noise and overfitting the data, but I must be misunderstanding something.
