[site]: crossvalidated
[post_id]: 313174
[parent_id]: 
[tags]: 
How do I train an LSTM for text generation?

Say I have a long text. How do I feed this into my RNN/LSTM for text generation. What I am doing at the moment is taking the first 10 characters. Working out the loss. Altering the weights. Then moving one character forwards and doing the same with the next (overlapping) 10 characters. I don't think this is working since the error does not seem to be going down. Instead it seems to be cycling. i.e. for each set of 10 characters the weights are adjusted but that doesn't necessarily mean the weights for all 10-characters substrings are moving in the same direction! I can only get it to converge if the length of my roll-out is bigger than the sample text I am feeding it. My model is a 2-layer GRUcell RNN. Input, hidden and output layers are vectors of size 33 which gives lower case characters plus some symbols.
