[site]: crossvalidated
[post_id]: 81858
[parent_id]: 
[tags]: 
Studying whether a policy had an effect outside the normal fluctuations in a time series, with time series cross sectional data

I'd really appreciate a point in the right direction of what models I should study, and the best modelling approach to evaluate a sentencing policy. I certainly am not asking for a full solution, but it would save me a huge amount of time if I knew where to start. I have experience of time series models with economic time series (including concepts like nonstationarity and cointegration), but no experience at all with time series cross sectional data. Background Sentence lengths vary through time for many reasons such as changes in judicial attitudes, changes in the severity of offending coming before courts, public perceptions of sentencing etc. One important reason why sentencing levels change is the release of new/revised sentencing guidelines, which are documents that advise judges on appropriate sentence lengths. I would like to study whether a new sentencing guideline had an effect on sentence lengths. That is, following the release of a sentencing guideline, did sentencing lengths change more than is consistent with the normal month to month fluctuations in sentencing that happen irrespective of changes to guidelines? Dataset I have a dataset that records, for each sentence passed, the sentence length, the date of sentence but also lots of additional information that can be used as controls, such as the aggravating and mitigating factors present in each case. The dataset runs from a year before the guideline was introduced to around a year after its introduction. For any particular offence, I may have around 5,000 records a year (total n=10,000). I also have data that may allow me to control for some common shocks which may hit the system, such as a change in judicial attitudes. e.g., if judges become more penal. This may be possible by using data on average sentence lengths for offences not affected by new sentencing guidelines (the guideline of interest in on assault, but I also have data on, say, burglary). As far as I can tell, charts of average sentence lengths appear almost nonstationary - they wander up and down but do not seem drawn to any long run average or trend . Intuition tells me sentence lengths cannot wander indefinitely up or down. However, over the time horizons I'm studying, it may be reasonable to assume they can wander without bounds. Attempts so far I have grouped sentences into months and calculated in each month average sentence lengths. I have then estimated simple ARDL models. This allows me to generate a forecast of the time series beginning just prior to the introduction of the new guideline. I can also plot error bands around this forecast to generate a 'fan chart'. If the outturn of average sentence lengths strays outside the 5th and 95th percentiles of the forecast, then I conclude that the sentencing guidelines probably had an effect. I have included average sentence lengths for other offences (e.g. burglary) in these models in the hope that this captures some of the common shocks hitting the system (e.g. a general increase in penality). However, as yet, I haven't included the controls I have for the aggravating and mitigating factors in each case, because I don't know how to best combine this cross sectional data with the time series data. By doing so, I would hope to "narrow" the level of uncertainty reflected in the fan chart because I would effectively be explaining away some of the sources of variability in sentencing. I would therefore have greater power in distinguishing whether the new guideline had an affect. I feel like a way forward may be to run cross sectional regressions of the aggravating and mitigating factors on sentence length, save the residuals, and use the monthly averages of the residuals rather than average sentence lengths in the time series work. There must be a 'best way' to do this kind of thing, but I'm unsure of what models are most appropriate. Any ideas or help is greatly appreciated - thank you. Apologies for such a lengthy question. Robin
