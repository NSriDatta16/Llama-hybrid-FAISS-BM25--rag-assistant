[site]: datascience
[post_id]: 99766
[parent_id]: 99754
[tags]: 
There could be an overfitting issue indeed. Models shouldn't constantly increase their accuracy with additional trainings, and it could result as a bad generalization, i.e. a failure in classifying new combinations. I don't know if your model uses neural networks, but if it is so, there are several functions to forget/reset a small part of the trained neurons, so that it avoids overfitting in new trainings. The Dropout function is the most common one, but you could have similar functions in error calculation functions like the Adam Optimization . If there is no such functions in your model, a solution could to restart from scratch the training including the new data. If the result is similar to model A, it could confirm that model B and C were overfitting. Finally, overfitting results highly depends on data, Model C could also be correct without overfitting, more details would be necessary to check this out. But generally speaking if you are around 90% or more, you are in an overfitting scenario.
