[site]: datascience
[post_id]: 120888
[parent_id]: 
[tags]: 
Using transformer to predict permutation of tokens based on encoded input

i am trying to implement a transformer based agent for a tile placing board game, and i was thinking about this kind of architecture: Src input is embedded board, with an empty block (for example 10x10 with a 3x3 block missing, so 3*3=9 tiles to be placed) Target tokens are the tiles to be placed. The transformers somehow outputs something that can be interpreted as a permutation of these tokens to fill the empty block. Is there an architecture that is made / proefficient in making those kinds of predictions (not just tokens but a permutation of the target tokens)? Or do you see a better way to approach this type of situation ? (i am pretty new to this)
