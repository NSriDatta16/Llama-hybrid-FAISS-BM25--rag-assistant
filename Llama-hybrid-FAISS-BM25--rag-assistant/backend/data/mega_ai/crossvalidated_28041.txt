[site]: crossvalidated
[post_id]: 28041
[parent_id]: 
[tags]: 
Pros/cons of estimating parameters for missing observations?

Some people are playing a game online. Every time a person plays, a new game board is generated randomly. On generation of a new board, the player can also choose a special weapon. (The choice of weapon does not affect the board generation.) Over time, observed data are like this: player weapon win 3 5 0 # player 3 used weapon 5 and lost 4 2 1 # player 4 used weapon 2 and won 8 1 1 # player 8 used no weapon and won To find out if some players are better with some weapons, and others with other weapons, I've modeled this as a Bayesian logistic regression: $logit(Pr(Win=1)) = \alpha_{p,w}$ $\alpha_{p,w} \sim N(\mu_{w},\sigma^2)$ So, $\mu_w$ is the effect of weapon $w$ across all players, and $\alpha_{p,w}$ is the effect of player $p$ with weapon $w$. Because this is a Bayesian model, the prior for $\alpha_{p,w}$ is $\mu_w$, so in theory, I can estimate $\alpha_{p,w}$ for all combinations of $p$ and $w$ even if some players never use some weapons. (JAGS will do this with nested for loops over players and weapons, for example.) But is that a bad idea? Also, is there a special name for this kind of model? P.S. Please edit the title and tags if you can make it clearer.
