[site]: datascience
[post_id]: 24255
[parent_id]: 
[tags]: 
Why study properties with infinitesimal change?

I read about analysis on local properties of neural networks. Some of them study the impact of "infinitesimal" change to an input. Like in Percy Liang's paper Understanding Black-box Predictions via Influence Functions. They have neat formalization with these properties but I don't really get the point. My questions are: How local is local? Or maybe how small is "infinitesimal". I get the idea that this is related to some derivative and stuff. But these results are applied to some changes that are not that small from my perspective, like a change of 0.1 in pixel value ranging from 0 to 1. Why is this considered correct? From my understanding, if the derivative does not change much, it can be applied to a larger area. But is this the case in neural networks? It would be great if I can get some references on this topic. Since I don't really have much background in ml theory and serious math stuff. Other pointers that may help me understand these topics are also appreciated. Thank you for the help in advance.
