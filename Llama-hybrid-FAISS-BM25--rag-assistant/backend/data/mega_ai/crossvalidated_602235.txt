[site]: crossvalidated
[post_id]: 602235
[parent_id]: 161709
[tags]: 
This seems to be a misinterpretation of extending $R^2$ to more complicated situations than the usual in-sample OLS linear regression. In particular, the "propotion of variance explained" interpretation of $R^2$ is the exception, not the rule. As is derived in the link, that definition only applies when $\overset{N}{\underset{i=1}{\sum}}\left[ \left( y_i - \hat y_i \right)\left( \hat y_i - \bar y \right) \right] = 0$ , which is not the case in a random forest regression. library(randomForest) set.seed(2023) N Indeed, the documentation gives this quantity as: $$ 1-\left( \dfrac{ \text{MSE} }{ \text{var}\left(y\right) } \right) = 1-\left( \dfrac{ \dfrac{1}{N}\overset{N}{\underset{i=1}{\sum}}\left( y_i - \hat y_i \right)^2 }{ \dfrac{1}{N}\overset{N}{\underset{i=1}{\sum}}\left( y_i - \bar y \right)^2 } \right) = 1-\left( \dfrac{ \overset{N}{\underset{i=1}{\sum}}\left( y_i - \hat y_i \right)^2 }{ \overset{N}{\underset{i=1}{\sum}}\left( y_i - \bar y \right)^2 } \right) $$ The third of the three expressions is a common definition of $R^2$ , so the linked information about $R^2$ applies. This does not mean that such a value is worthless, however. Indeed, I have lots of thoughts on an $R^2$ -style performance metric in complicated settings.
