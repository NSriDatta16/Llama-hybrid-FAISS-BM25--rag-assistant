[site]: crossvalidated
[post_id]: 109179
[parent_id]: 109177
[tags]: 
Some options: Do not use accuracy alone as a metric. That way, we would get 98% accuracy with everything classified as the majority class, which would not mean anything. Precision & Recall might be a better one. You could try using a Cost sensitive classifier through which you can state the cost of misclassification of the different classes. Use an SVM but penalize one of the classes which can be done using LibSVM boost the number of minority class training examples by artificially creating new samples from the existing samples. resample the set, to have a proportional number of samples in both the classes (probably not an option in your case)
