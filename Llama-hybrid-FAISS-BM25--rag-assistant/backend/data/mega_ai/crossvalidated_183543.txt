[site]: crossvalidated
[post_id]: 183543
[parent_id]: 
[tags]: 
Issues with Importance sampling for flat prior

I am trying to draw Bayesian inference via importance sampling for a parameter $\xi$ attached with an (unbounded) flat prior. This seems problematic as this is clearly not a probability measure but rather a measure with mass infinity. Under a $t$-distributed likelihood with known $\sigma^2 $ and $\nu$ I obtain $$\log \mathcal{L}(y|\xi)=\frac{-\nu-1}{2}\sum_{t=1}^{T}\log\left(1+\frac{(y_t-\xi)^2}{\nu\sigma^2}\right)$$ Is this the kernel of a known probability distribution in $\xi_i$? As I doubt so, I am searching for a importance density that helps me computing sensible weights. For example, if I chose $\xi_i \sim N(\mu,\sigma_\xi ^2)$ as importance density, my weights will look like $$w_i=\exp\left(\log\{\mathcal{L}(y|\xi_i)\}+\frac{1}{2\sigma_\xi ^2}(\xi_i-\mu)^2\right).$$ Simulating gives me an extremely high number of weights being equal to $0$. How can I overcome this problem? **Remark: I updated the notation due to a mistake. **
