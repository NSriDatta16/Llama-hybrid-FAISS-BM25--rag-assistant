[site]: crossvalidated
[post_id]: 81680
[parent_id]: 
[tags]: 
Training Restricted Boltzmann Machines with Bias Units

I have written some code that basically does the following:- 1: creates a matrix of binary features and a matrix of scaled features ( in the range 0 to 1 ) 2: RBM trains separately on each of the above features matrices to get weight matrices 3: horizontally stacks a random row vector for bias unit weights and the two weight matrices from step 2 to create a single, initial input layer to hidden layer weight matrix 4: matrix multiplies the input features by the matrix from step 3 and feeds forward through the logistic function hidden layer to create a hidden layer output 5: RBM trains on the hidden layer output from step 4 to get a weight matrix 6: horizontally stacks a random row vector for hidden layer bias unit weights and the weight matrix from step 5 to create a single, initial hidden layer to Softmax weight matrix 7: uses the initial weight matrices from steps 3 and 6 instead of random initialisation for backpropagation training of a Feedforward neural network However, I am now wondering whether it's wise/correct to exclude the weights of the bias units from the RBM training?
