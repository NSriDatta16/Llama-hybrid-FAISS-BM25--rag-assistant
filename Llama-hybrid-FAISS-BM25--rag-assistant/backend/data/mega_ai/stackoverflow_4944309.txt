[site]: stackoverflow
[post_id]: 4944309
[parent_id]: 4944179
[tags]: 
There is no single way of reading and parsing any type of file that is fastest all the time. However, you might want to build a Ragel grammar for CSVs; those tend to be pretty fast. You can adapt it to your specific type of CSV (comma-separated, ; -separated, numbers only, etc.) and perhaps skip over any data that you're not going to use. I've had good experience with dataset-specific SQL parsers that could skip over much of their input (database dumps). Reading in bulk might be a good idea, but you should measure on actual data whether it it's really faster than stdio -buffering. Using binary I/O might speed things up a bit on Windows, but then you need to handle newlines somewhere else.
