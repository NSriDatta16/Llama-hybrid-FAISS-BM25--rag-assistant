[site]: crossvalidated
[post_id]: 524502
[parent_id]: 
[tags]: 
How to practically forecast a time series in a Bayesian framework

can someone explains me how bayesian time series forecasting practically work? Let me use the model on which I am working as example. It is a dynamic Poisson model or INGARCH(1,1) model \begin{equation} Y_t \sim Pois(\lambda_t) \\ \text{with} \qquad \lambda_t = \mu + \alpha Y_{t-1} + \beta \lambda_{t-1} \end{equation} In short, this model assumes that the data follows a Poisson whose mean/variance $\lambda_t$ changes over time in a way similar to an ARMA(1,1). I have estimated the parameters of this model (and their distributions) using a MCMC algorithm since the posterior it is not tracatble. What I want to know is how I can predict future distributions for multiple step-ahead. I would also like to know which is the so-called predictive distribution in a context like this. I have tried it in the following way: For time $t+1$ : I randomly choose values for $\mu, \alpha, \beta$ from the sample obtained from the MCMC algorithm I use this values to compute $\lambda_{t+1}$ * I draw from a $Pois(\lambda_{t+1})$ I repeat step 1-2-3 many times For time $t+2$ : I randomly choose values for $\mu, \alpha, \beta$ from the sample obtained from the MCMC algorithm I randomly choose $\lambda_{t+1}$ from the sample obtained for time $t+1$ I use this values to compute $\lambda_{t+2}$ I draw from a $Pois(\lambda_{t+2})$ I repeat step 1-2-3-4 many times However, I am not confident on the correctness of this procedure. Thanks a lot for your help. I recover $\lambda_{t}$ in this way: for (i in 1:LastObservation) { if (i==1) { lambda[i] = mu+ alpha * InitialValueY + beta * InitialValueLambda } else { lambda[i] = mu + alpha * Y[i-1] + beta * lambda[i-1] } } #in this case lambda_t is lambda[LastObservation]
