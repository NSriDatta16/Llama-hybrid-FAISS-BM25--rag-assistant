[site]: crossvalidated
[post_id]: 619310
[parent_id]: 619265
[tags]: 
You can certainly take a set of 1000 observations from a Cauchy distribution, and they will have a finite mean and finite variance > x mean(x) [1] -0.7734487 > var(x) [1] 435.5169 If you want a Central Limit Theorem, though, you care about the distribution over different samples of size 1000 from the distribution > x mean(x) [1] 0.1649075 > var(x) [1] 481.9081 These have different finite means and variances. The question is whether the distribution of the mean, across these samples, is Normal. It isn't. lots.of.means So, what's happening? Most of the time, as you add observations to a Cauchy distribution, the sample average moves a little bit towards the centre of the distribution. But sometimes you get a really big observation that kicks the sample mean away from the centre of the distribution x If you take a sample of size 1000, most of the time you get a reasonable value, but occasionally there has been a big jump just before $n=1000$ and you get an outlier. This never stops happening, no matter how large $n$ is, and that's what we mean when we say say the Cauchy distribution doesn't satisfy a central limit theorem or even a law of large numbers. If you look at the variance of samples it's a bit different vars Again, the variance mostly goes down as if it's trying to converge to a 'true value', but keeps getting kicked up. Here, the jumps get bigger and bigger as $n$ increases, so the sample variance tends to get bigger and bigger -- it diverges to infinity. So, that's how you can get infinite variance and no mean and no asymptotic normality even though most individual values from a Cauchy distribution look perfectly reasonable. There are enough outliers to mess things up, enough so that you don't get the mean converging no matter how many observations you take.
