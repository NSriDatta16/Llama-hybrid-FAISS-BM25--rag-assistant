[site]: datascience
[post_id]: 115390
[parent_id]: 115333
[tags]: 
There are various ways to deal with this kind of data, but I think you could consider it as a multivariate time series problem. First because you have a time logic in every column that could be learned by a model to detect patterns in a sequential way. Then because there could be correlations between values that could improve the results. That's why I suggest to do some correlation map between features to know better the data. https://seaborn.pydata.org/examples/many_pairwise_correlations.html Then, it seems that you want to "optimize" omega, which makes me think more about an optimization algorithm like Reinforcement Learning or Genetic Algorithm. The simplest one is the Genetic Algorithm. It would explore thousands of random data to find an optimum, and the results are usually very good compared to human ones. Here are some useful links to implement it: https://pypi.org/project/geneticalgorithm/#:~:text=geneticalgorithm%20is%20a%20Python%20library,algorithm%20(GA)%20in%20Python . https://medium.com/analytics-vidhya/creating-genetic-algorithms-with-python-187d79f27c0a https://bobrupakroy.medium.com/auto-time-series-411453a78562
