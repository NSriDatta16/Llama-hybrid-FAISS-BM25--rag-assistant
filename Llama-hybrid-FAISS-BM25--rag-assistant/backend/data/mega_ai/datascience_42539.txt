[site]: datascience
[post_id]: 42539
[parent_id]: 42139
[tags]: 
I am wrong. ELMo also use the output of LSTM for context-dependent representation. The output only from word embedding is the context-independent representation. Why the representation is useful? I think it is because, it is learning the difference between words and the representation is not the real meaning for the word.
