[site]: crossvalidated
[post_id]: 496222
[parent_id]: 444303
[tags]: 
As a matter of fact, Spearman's rank correlation coefficient may for some data be more informative (and less misleading) than a simple linear regression . The crucial difference between Spearman's rank correlation coefficient and linear regression is that the former can detect non-linear associations , while linear regression cannot and may even lead to false conclusions. First of all, you confused some statements about linear regression and causality here. Linear regression can explain the association between a dependent variable and some independent explanatory variables, it says nothing about causality. Causality is much harder to measure and can only rigorously be established by conducting a controlled experiment (it is however possible to measure a weaker concept of causality through time-based effect observations, based on the assumption that the cause must be observed before its effect, or through methods such as non-parametric regression discontinuity design). More in detail, while it is true that the linear regression function is based on linear correlation (similar to Pearson's correlation coefficient), they are not the same. A (scalar-valued) linear regression model assumes that: $y_i = \alpha + \beta * x_i + \epsilon_i$ where $y_i$ , the dependent variable to be explained or predicted, may for example be the (numerical) GPA of student $i$ . Then, $x_i$ is the independent or explanatory variable, e.g., the number of hours of studying the student spent during last semester, which helps explain the GPA. $\alpha$ is the intercept term, giving the average GPA level without using $x_i$ as an explanatory variable and $\epsilon_i$ is the error term. Now the assumption in plain-vanilla linear regression is that this error term $\epsilon_i$ is independently and identically distributed (i.i.d) with mean zero. Often it is wrongly assumed that the dependent variable $y_i$ should be normally distributed, which is not required in linear regression. So, if your data is actually non-linearly related, i.e. if $\beta$ (the increase in average GPA per additional hour of studying) in the regression does not stay constant but depends on the level of $x_i$ (say $\beta = 0.5$ for $x , but $\beta = 2$ for $x >= 10$ ), then linear regression analysis is misleading. In our example this could, e.g., be the case if an effort of less than 10 hours of studying does not result in a good enough understanding of the subject at hand to raise a student's GPA by more than 0.5 per additional hour of studying on average. However, an effort of a total of more than 10 hours put in is associated with a significant increase of GPA per additional hour of studying on average. This is exactly where Spearman's rank correlation coefficient would give more accurate results than Pearson's correlation coefficient or linear regression , since Spearman's rank correlation coefficient is non-parametric and does not assume a linear relation.
