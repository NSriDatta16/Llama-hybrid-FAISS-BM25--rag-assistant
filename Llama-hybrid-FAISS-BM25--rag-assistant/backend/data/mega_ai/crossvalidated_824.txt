[site]: crossvalidated
[post_id]: 824
[parent_id]: 672
[tags]: 
Bayes' theorem is a relatively simple, but fundamental result of probability theory that allows for the calculation of certain conditional probabilities. Conditional probabilities are just those probabilities that reflect the influence of one event on the probability of another. Simply put, in its most famous form, it states that the probability of a hypothesis given new data ( P(H|D) ; called the posterior probability) is equal to the following equation: the probability of the observed data given the hypothesis ( P(D|H) ; called the conditional probability), times the probability of the theory being true prior to new evidence ( P(H) ; called the prior probability of H), divided by the probability of seeing that data, period ( P(D ); called the marginal probability of D). Formally, the equation looks like this: The significance of Bayes theorem is largely due to its proper use being a point of contention between schools of thought on probability. To a subjective Bayesian (that interprets probability as being subjective degrees of belief) Bayes' theorem provides the cornerstone for theory testing, theory selection and other practices, by plugging their subjective probability judgments into the equation, and running with it. To a frequentist (that interprets probability as limiting relative frequencies ), this use of Bayes' theorem is an abuse, and they strive to instead use meaningful (non-subjective) priors (as do objective Bayesians under yet another interpretation of probability).
