[site]: crossvalidated
[post_id]: 613704
[parent_id]: 
[tags]: 
Create weight for tokens with BERT models

I am fine-tuning CamemBERT model for text classification. I have a lot of domain specific words and a small dataset (10k sentences with 70 labels) and when I added tokens, it didn't help the model to perform better (probably because of my small dataset). When adding tokens with the add_tokens function, can we instantiate the weight embedding of the new tokens (like with CBOW embedding)?
