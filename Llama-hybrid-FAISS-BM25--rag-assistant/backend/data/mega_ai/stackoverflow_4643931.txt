[site]: stackoverflow
[post_id]: 4643931
[parent_id]: 4643536
[tags]: 
I hope you don't mind I took the liberty of modifying your code to something that I would more likely write. from itertools import izip def filetxt(): # keeps track of word count for each word. word_freq = {} # list of words which we've found word_list = [] # mapping from word -> index in word_list word_map = {} lvl1 = [] lvl2 = [] total_t = 0 users = 0 text = [] ####### You should replace this with a glob (see: glob module) for l in range(0,500): # Open File try: with open("C:/Twitter/json/user_" + str(l) + ".json", "r") as f: text_f = json.load(f) users = users + 1 # in this file there are multiple tweets so add the text # for each one. for t in text_f.itervalues(): text.append(t) ## CHECK THIS except IOError: pass total_t = len(text) # Filter occ = 0 import string for s in text: a = re.findall(r'(RT)',s) b = re.findall(r'(@)',s) occ += len(a) + len(b) s = s.encode('utf-8') out = s.translate(string.maketrans("",""), string.punctuation) # make a list of words that are in the text s words = s.lower().split(None) for word in word_list: # try/except is quicker when we expect not to miss # and it will be rare for us not to have # a word in our list already. try: word_freq[word] += 1 except KeyError: # we've never seen this word before so add it to our list word_freq[word] = 1 word_map[word] = len(word_list) word_list.append(word) # little trick to get each word and the word that follows for curword, nextword in zip(words, words[1:]): lvl1.append(word_map[curword]) lvl2.append(word_map[nextword]) What is is going to do is give you the following. lvl1 will give you a list of numbers corresponding to words in word_list . so word_list[lvl1[0]] will be the first word in the first tweet you processed. lvl2[0] will be index of the word that follows the lvl1[0] so you can say, world_list[lvl2[0]] is the word that follows word_list[lvl1[0]] . This code basically maintains word_map , word_list and word_freq as it builds this. Please note that the way you were doing this before, specifically the way you were creating W2N will not work properly. Dictionaries do not maintain order. Ordered dictionaries are coming in 3.1 but just forget about it for now. Basically when you were doing word_freq.keys() it was changing every time you added a new word so there was no consistency. See this example, >>> x = dict() >>> x[5] = 2 >>> x {5: 2} >>> x[1] = 24 >>> x {1: 24, 5: 2} >>> x[10] = 14 >>> x {1: 24, 10: 14, 5: 2} >>> So 5 used to be the 2nd one, but now it's the 3rd. I also updated it to use a 0 index instead of 1 index. I don't know why you were using range(1, len(...)+1) rather than just range(len(...)) . Regardless, you should get away from thinking about for loops in the traditional sense of C/C++/Java where you do loops over numbers. You should consider that unless you need an index number then you don't need it. Rule of Thumb: if you need an index, you probably need the element at that index and you should be using enumerate anyways. LINK Hope this helps...
