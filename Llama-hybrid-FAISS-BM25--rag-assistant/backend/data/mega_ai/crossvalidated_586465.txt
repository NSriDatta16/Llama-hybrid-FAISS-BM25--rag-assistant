[site]: crossvalidated
[post_id]: 586465
[parent_id]: 586459
[tags]: 
The reason you are unable to reproduce the coefficients in your example problem is that the data generating model you coded doesn't correspond to the model you fit. Replacing the line Y with Y and running the rest does recover (close to) the true values. The former creates a strict threshold at .5, above which all Y s are 1 and below which all are 0. This is not included in your optimization. The fact that you have a binary outcome doesn't mean anything; you can still use the linear probability model with constrained least squares as you did to compute the coefficients. That said, if you want to do constrained logistic regression, you can use CVXR , which is a general purpose optimization engine, to specify a logistic regression model with constraints, as follows: library(CVXR) beta = 0)) result This relies on maximizing the log likelihood assuming a binomial family and logistic link. This is not a quadratic optimization problem because the objective function is not quadratic. Including these constraints is not useful for this problem because the resulting predictions are already bound between 0 and 1 so the coefficients can be of any value, and you will not be able to recover the data-generating coefficients you specified unless you change them to have a logistic form, e.g., Y
