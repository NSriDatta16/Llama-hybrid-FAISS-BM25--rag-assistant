[site]: crossvalidated
[post_id]: 299579
[parent_id]: 
[tags]: 
Intuition behind neural networks

I'm really interested in understanding the intuition behind multilayer perceptrons and neural networks. I'm following the Caltech video which is excellent https://www.youtube.com/watch?v=Ih5Mr93E-2c More specifically it goes through an example at 30 mins in where a circle classifier is approximated by intersections of straight lines. More specifically consider the lines $l1: y-x=1$, $l2: y-x=-1$, $l3: y+x=1$, and $l4: y+x=-1$ Now suppose that i split each space into 2 depending on whether a co-ordinate point is above the line or not call these regions $h_{i}$ and $\overline{h}_{i}$ respectively. Then i know i want to classify positive if i'm in the square intersection of all 4-lines and so if the variable $\overline{h}_{1}h_{2}\overline{h}_{3}h_{4}$ evaluates to true. They didn't go through this in the lecture but how would i represent this in a neural network like they did at around 27 mins in for the XOR problem? Any help would be appreciated i really want to try and get a feel for breaking these problems down.
