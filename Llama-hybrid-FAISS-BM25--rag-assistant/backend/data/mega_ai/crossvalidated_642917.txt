[site]: crossvalidated
[post_id]: 642917
[parent_id]: 614740
[tags]: 
The problem with the binomial test is that you are treating the estimated proportion 0.105 among the old products as known, while it is estimated. Also, how you have calculated the test is in error, because 12 is a percent, while you have used is at the number of errors. A correct test would be binom.test(7, 60, p=0.105, alternative="greater") Exact binomial test data: 7 and 60 number of successes = 7, number of trials = 60, p-value = 0.4443 alternative hypothesis: true probability of success is greater than 0.105 95 percent confidence interval: 0.05605488 1.00000000 sample estimates: probability of success 0.1166667 The chi-squared test is not really appropriate, since it tests a different hypothesis, and in principle could reject because of differences among the old, and not differences between old and new. Let us try: with(mydata, chisq.test( cbind(nerror, Total-nerror))) Pearson's Chi-squared test data: cbind(nerror, Total - nerror) X-squared = 2.1033, df = 7, p-value = 0.9539 (see code below for definitions). We could avoid these by collapsing the first 7 rows of the table: ctable ctable Total nerror 1 305 33 8 60 7 > chisq.test(ctable) Pearson's Chi-squared test with Yates' continuity correction data: ctable X-squared = 1.6109e-30, df = 1, p-value = 1 But what I would prefer is first doing a logistic regression, and then define a contrast and testing the contrast. With R code: mod0 > car:::linearHypothesis(mod0, hypothesis.matrix= c(rep(1/7, 7), -1), coef.=coef(mod0), vcov.=vcov(mod0)) Error in linearHypothesis.default(model, ...) : residual df = 0 So we do it by hand: c This computes an approximate z-test of the hypothesis that the average of coefficients for the old products (7) is equal to the coefficient for the new. It is not significant at any conventional level. Code for reading the data: textdata
