[site]: crossvalidated
[post_id]: 223312
[parent_id]: 190287
[tags]: 
I suggest you determine if/how to handle "concept drift" and what kind of inference you need on streaming (big?) data. There are a number of excellent papers but this one from Prof David Blei is among the top few. "The Population Posterior and Bayesian Inference on Streams" https://arxiv.org/pdf/1507.05253.pdf The abstract gives good hints about how this relates to "standard probabilistic modeling approaches": Many modern data analysis problems involve inferences from streaming data. However, streaming data is not easily amenable to the standard probabilistic modeling approaches, which assume that we condition on finite data. We develop population variational Bayes, a new approach for using Bayesian modeling to analyze streams of data. It approximates a new type of distribution, the population posterior, which combines the notion of a population distribution of the data with Bayesian inference in a probabilistic model. We study our method with latent Dirichlet allocation and Dirichlet process mixtures on several large-scale data sets. A few others "A Comparison on How Statistical Tests Deal with Concept Drifts" http://worldcomp-proceedings.com/proc/p2012/ICA2334.pdf "A SURVEY OF CLASSIFICATION METHODS IN DATA STREAMS " http://charuaggarwal.net/streambook.pdf "[Charu C. Aggarwal] A Survey of Stream Classification Algorithms" http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.675.1122&rep=rep1&type=pdf Since this is not really a full answer I will wait for feedback before going further in this direction.
