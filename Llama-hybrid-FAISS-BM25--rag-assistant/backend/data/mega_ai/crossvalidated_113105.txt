[site]: crossvalidated
[post_id]: 113105
[parent_id]: 
[tags]: 
Understanding a measure of convergence of MCMC simulations

I am trying to better understand better the Gelman/Rubin measure of convergence of MCMCs. The method starts off by defining two quantities: $B$ and $W$. $B$ is said to be the between chain variance (as typically $m$ chains are run in parallel), and $W$ is the average within chain variance. I understand $W$ - it is merely the average of all the variances in each of the individual chains. $B$, at first glance, appears to measure the average deviation across all chains of their average from the overall mean. However, $B$ is multiplied by $n$ - the sample size - which I don't quite understand. Texts say that this is because there are $n$ points in each chain, however, I was hoping someone could provide a little intuition here? Further, $W$ is combined with $B$ in a weighted average, with $W$'s weight being $(n-1)/n$, and $B$'s weight simply being $(1/n)$. This is then typically divided by $W$, and the square root taken. If $B$ equals $W$ I can see that this ratio is then $1$. However, I don't see how this ratio ever gets far away from $1$ for moderately large sample sizes. It must be the case that $B>>W$, part of which I can understand if the chains are initially overdispersed. Still, the fact that $B$ is multiplied by $(1/n)$, makes it look like this part of the weighted average should disappear at a fast rate, even if $B$ is large. Basically, I think my question could be condensed into the following 'Why is this measure of convergence reasonable? Given that as $n$ gets large, ceteris paribus, the role played by the between chain variance appears to become smaller.'
