[site]: crossvalidated
[post_id]: 183820
[parent_id]: 183819
[tags]: 
Learning rate is used to ensure convergence. A one line explanation against high learning rate would be: The answer might overshoot the optimal point There is a concept called momentum in neural network, which has almost the same application as that of the learning rate. Initially, it would be better to explore more. So, a low momentum and high learning rate would be advisable. Gradually, the momentum can be increased and the learning rate can be decreased for ensuring convergence.
