[site]: crossvalidated
[post_id]: 562645
[parent_id]: 546965
[tags]: 
Aggregation then do a paired-t doesn't make sense for variance reduction and may result in large variance and biased std error. A linear regression or post-stratification might be appropriate. Let's make some fake data. library(tidyverse) library(furrr) options(future.globals.maxSize = 1073741824) get_estimates % rowwise() %>% mutate(y = list(rbinom(strat_cnt, 1, strat_y))) %>% unnest(y) %>% dplyr::select(strat, y) %>% mutate(trt = if_else(runif(nrow(.)) > 0.5, 1, 0)) # random assign to A/B df_agg % group_by(strat) %>% summarise( n = n(), n0 = sum(trt), n1 = sum(1 - trt), s = n0 * n1 / n, # strat variance y0 = sum(y * trt), y1 = sum(y * (1 - trt)), strat_diff = y1 / n1 - y0 / n0, .groups = 'drop' ) df_agg %>% summarise( # non_aggregate non_aggregate = sum(y1) / sum(n1) - sum(y0) / sum(n0), # agg_avg: aggregate by strat then average without weight agg_avg = mean(strat_diff), # post_strat: aggregate by strat then weight by strat proportion weight_diff = weighted.mean(strat_diff, n), # ols regression/ancova: if strat is categorical, then ols estimate equal to weight by strat variance # lm(y ~ trt + strat, df)$coefficients['trt'] ols_diff = weighted.mean(strat_diff, s) ) } plan(multisession, workers = 4) SIM_CNT % pivot_longer( cols = c('non_aggregate', 'agg_avg', 'weight_diff', 'ols_diff'), names_to = 'key', values_to = 'value' ) %>% # filter(key == 'avg_day_diff') %>% ggplot() + geom_freqpoly(aes(value, color = key), bins = 100) + labs( x = 'diff', y = '', color = '', title = 'aggregation then do a paired-t result in large variance')
