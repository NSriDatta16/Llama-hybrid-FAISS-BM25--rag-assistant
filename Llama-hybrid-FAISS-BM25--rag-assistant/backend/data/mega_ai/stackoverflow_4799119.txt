[site]: stackoverflow
[post_id]: 4799119
[parent_id]: 
[tags]: 
OpenGL application fades when texturing an object

I have an application that animates a person traversing the halls of a spaceship. I have also created an OpenGL DLL that the application links to. The purpose of this OpenGL DLL is to intercept specific calls, and then do something when these calls are intercepted. The main call that i am concerned about intercepting is wglSwapBuffer ( i think thats the name ). In this call, i render a 3D object ( half sphere or half cylinder ) and specify texture coordinates for each vertex. I then capture the output of the framebuffer, and use it to texture the contents of the sphere using glCopyTexImage2D, or something like that. After i do all that stuff, my dll the calls the real dll and the real swapbuffer method is called. When i place my dll in the same folder as the application, I get what i expect, a dome with graphics textured onto it. What i did not expect is that the screen fades constently. What i mean by that is that everything looks the way its supposed to, and then over a second interval, the screen will fade to be completly black, and then it will come back to being normal. This repeats with an average frequency of about a second, sometimes its faster, sometimes its slower, it seems to depend on hard the processor is working. Any ideas?
