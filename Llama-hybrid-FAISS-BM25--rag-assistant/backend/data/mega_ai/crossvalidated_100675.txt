[site]: crossvalidated
[post_id]: 100675
[parent_id]: 100673
[tags]: 
(Almost) Everything can be expressed as a linear model, if you don't restrict it to a finite number of parameters. This is the basis of functional analysis and kernel regression (as in SVMs with kernels). For instance, Fourier series - you can produce an infinite sine/cosine series, where the amplitude of the wave of each frequency gets a learned coefficient, and you can learn (almost) any function (any function whose square is integrable - which is a very weak condition). Kernel machines, and functional analysis, are a wonderful idea, and make the world seem very beautiful - virtually everything is linear! See http://en.wikipedia.org/wiki/Kernel_methods The classic statistical probabilistic reference is Grace Wahba's Spline Models for Observational Data .
