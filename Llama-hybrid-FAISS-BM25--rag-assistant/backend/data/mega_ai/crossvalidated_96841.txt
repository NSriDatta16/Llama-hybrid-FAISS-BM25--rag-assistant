[site]: crossvalidated
[post_id]: 96841
[parent_id]: 96720
[tags]: 
chisq.test(table(d$p,d$y)) This command is not computing the chi-square test you think. Notice that the table command is going to create a contingency table of the two vectors and perform a chi-square test of independence. As an example of what the table command is doing, check out the 2 by 2 table created below table( c("Y", "Y", "N", "N"), c(1,1,1,0)) 0 1 N 1 1 Y 0 2 I don't think there is any function that will give you a chi-squared statistic of the form $\sum (O_i - P_i)^2/P_i$ because this does not correspond to a chi-squared test I am aware of! If you are trying to perform a test of goodness of fit, you might want to check out the Hosmer-Lemeshow goodness of fit test. In looking through the residuals function, it appears you stumbled upon the formula for Pearson residuals, but the motivation for these residuals is not for the purpose of performing a Pearson chi-squared test! Notice that since your data are bernoulli (binomial with $N=1$), $E(Y_i)=p_i$ and $Var(Y_i)=p_i(1-p_i)$. Thus, the Pearson residuals are equivalent to standardizing $Y_i$ by its estimated mean and variance. See Residuals from glm model with log link function for a discussion of what the Pearson residuals are typically used for. However, in this case of binary logistic regression, it's impossible to misspecify the relationship between the mean and variance of a bernoulli random variable. Thus the Pearson residuals won't help to diagnose overdispersion because it's impossible to have overdispersion in a binary logistic regression. It is possible, however, to have overdispersion in a binomial logistic regression where $Y_i \sim binomial(N, p_i)$ and $N>1$.
