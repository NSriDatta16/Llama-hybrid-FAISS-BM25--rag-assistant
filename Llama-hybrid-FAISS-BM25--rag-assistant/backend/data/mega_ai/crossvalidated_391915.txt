[site]: crossvalidated
[post_id]: 391915
[parent_id]: 
[tags]: 
"Return values" of univariate logistic regression

I read an interesting article on an approach to calibrate probabilistic classifiers ( Kull et al. 2017, "Beyond sigmoids: How to obtain well-calibrated probabilities from binary classifiers with beta calibration" ) and stumbled across a formulation that is unclear to me. In the second step of algorithm 1 the authors write $$(a,c) \leftarrow \mathrm{fit\: univariate\: logistic \:regression \: to \: predict \: y_{train}\: from\: \mathbf{s}'}$$ which left me confused. In my understanding this assigns the "return values" of the logistic regression fit to the variables $a$ and $c$ . While the authors state that this approach to acquire these two parameters for their function makes it possible to use any implementation of logistic regression, these usually only either return a model object or the coefficients of the model (which should amount to the same). On page 8, section 3.1, the authors introduce the parameters $a,b,c$ and in proposition 1 they show that the likelihood ratio of the logistic model is equal to that of their parameterization of the used beta distribution, which is supposed to show that fitting a logistic model to acquire the parameters is sufficient - however they don't seem to write a word about the formulation above besides Hence, we can use logistic calibration (i.e. univariate logistic regression) to fit the beta[a=b] calibration maps, as shown in Algorithm 1. Maybe this is just too trivial for the authors to write more explicitly, can someone explain to me what exactly the authors assign to $a$ and $c$ here? Edit: for completeness sake, here's a screenshot of algorithm 1 from the paper
