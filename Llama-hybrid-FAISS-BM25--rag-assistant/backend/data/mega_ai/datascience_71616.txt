[site]: datascience
[post_id]: 71616
[parent_id]: 
[tags]: 
low error, high CV(RMSE)?

I am comparing 2 neural network models. I have used the model to make predictions on unseen data. One model returns an error of 20.9% for y1, 36.6% for y2, 4.53% for y3 on unseen data, and a CV(RMSE) of 19.3. The other returns an error of 15.5% for y1, 33.8% for y2 and 4.83% for y3 on unseen data, and a CV(RMSE) of 31.5. I'm struggling to interpret the results. A lower CV(RMSE) is better, yet why do I get a much higher error on unseen data?
