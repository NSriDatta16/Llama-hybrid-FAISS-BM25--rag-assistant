[site]: datascience
[post_id]: 55153
[parent_id]: 55140
[tags]: 
What momentum does is to average out the derivatives in different directions in parameter space so that the directions that oscillate much will be close to zero, but for the parameters that do not oscillate this would not be the case - averaging will not vanish. On the other hand RMSprop works as a dampener in all directions: larger the derivatives, larger the dampening rate. This means that the fast oscillatory modes with large derivatives will be dampened more. The learning in slow directions which you want to keep may also be dampened, but the rate will be smaller. You can find more details on RMSprop and their combination Adam on the following Coursera course: https://www.coursera.org/learn/deep-neural-network/lecture/y0m1f/gradient-descent-with-momentum
