[site]: crossvalidated
[post_id]: 431992
[parent_id]: 187335
[tags]: 
At this time, stochastic gradient based methods are almost always the algorithm of choice for deep learning. This means that data comes in as batches, gradients are computed and parameters are updated. This means you can also compute the loss over the data as each batch is selected. Under this framework, there are two ways in how the loss is computed that I can think of which can lead to this phenomenon that the training error is greater than the validation error. Below, I show that Keras does, in fact, appear to compute the in-sample errors in these ways. 1.) Training error is averaged over whole epoch, rather all at once at the end of the epoch, but validation error is only at end of epoch. As we sample our training data to compute gradients, we might as well compute the loss over them as well. But since the validation data is not used during the computation of gradients, we may decide to only compute the loss after the end of the epoch. Under this framework, the validation error has the benefit of being fully updated, while the training error includes error calculations with fewer updates. Of course, asymptotically this effect should generally disappear, since the effect on the validation error of one epoch typically flattens out. 2.) Training error is computed before batch update is done. In a stochastic gradient based method, there's some noise the gradient. While one is climbing a hill, there's a high probability that one is decreasing global loss computed over all training samples. However, when one gets very close to the mode, the update direction will be negative with respect to the samples in your batch. But since we are bouncing around a mode, this means on average we must be choosing a direction that is positive with respect to the samples out of batch. Now, if we are about to update with respect to the samples in a given batch, that means they have been pushed around by potentially many batch updates that they were not included in, by computing their loss before the update, this is when the stochastic methods have pushed the parameters the most in favor of the other samples in your dataset, thus giving us a small upward bias in the expected loss. Note that while asymptotically, the effect of (1) goes away, (2) does not! Below I show that Keras appears to do both (1) and (2). (1) Showing that metrics are averaged over each batch in epoch, rather than all at once at the end. Notice the HUGE difference in in-sample accuracy vs val_accuracy favoring val_accuracy at the very first epoch. This is because some of in-sample error computed with very few batch updates. >>> model.fit(Xtrn, Xtrn, epochs = 3, batch_size = 100, ... validation_data = (Xtst, Xtst)) Train on 46580 samples, validate on 1000 samples Epoch 1/3 46580/46580 [==============================] - 8s 176us/sample - loss: 0.2320 - accuracy: 0.9216 - val_loss: 0.1581 - val_accuracy: 0.9636 Epoch 2/3 46580/46580 [==============================] - 8s 165us/sample - loss: 0.1487 - accuracy: 0.9662 - val_loss: 0.1545 - val_accuracy: 0.9677 Epoch 3/3 46580/46580 [==============================] - 8s 165us/sample - loss: 0.1471 - accuracy: 0.9687 - val_loss: 0.1424 - val_accuracy: 0.9699 (2) Showing error is computed before update for each batch. Note that for epoch 1, when we use batch_size = nRows (i.e., all data in one batch), the in-sample error is about 0.5 (random guessing) for epoch 1, yet the validation error is 0.82. Therefore, the in-sample error was computed before the batch update, while the validation error was computed after the batch update. >>> model.fit(Xtrn, Xtrn, epochs = 3, batch_size = nRows, ... validation_data = (Xtst, Xtst)) Train on 46580 samples, validate on 1000 samples Epoch 1/3 46580/46580 [==============================] - 9s 201us/sample - loss: 0.7126 - accuracy: 0.5088 - val_loss: 0.5779 - val_accuracy: 0.8191 Epoch 2/3 46580/46580 [==============================] - 6s 136us/sample - loss: 0.5770 - accuracy: 0.8211 - val_loss: 0.4940 - val_accuracy: 0.8249 Epoch 3/3 46580/46580 [==============================] - 6s 120us/sample - loss: 0.4921 - accuracy: 0.8268 - val_loss: 0.4502 - val_accuracy: 0.8249 Small note about the code above: an auto-encoder was built, hence why the input ( Xtrn ) is the same as the output ( Xtrn ).
