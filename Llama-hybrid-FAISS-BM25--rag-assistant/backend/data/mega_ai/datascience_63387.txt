[site]: datascience
[post_id]: 63387
[parent_id]: 63341
[tags]: 
To add to the other answer, If you want just to make predictions, all your data is training data and you can make predictions for data that you have not seen. You do not need to split your data into two parts. The splitting is hence only useful to evaluate the performance of link prediction methods. Your drawing above does not reflect a standard machine learning pipeline. Unbiased estimates of performance can be computed only in the following manner: from the train data you construct a model (which here would be two parts; the network embedding and the binary classifier such as logistic regression), from which you can make predictions. You evaluate the predictions on the ground truth that was withheld from the learning process, which is the test set. Hence, the pipeline would be: Left-hand side: Train network -> Network embedding -> LR model -> Predictions Right-hand side: Test network -> Evaluation Cross link from land-hand side ‘Predictions’ directly to right-hand side ‘Evaluation’. So, the predictions are made from the model (for example logistic regression which is in turn based on a network embedding), which is learned on the training data. This is true not just in this link prediction setting but generally for any machine-learning model evaluation setting. As an additional remark, there is no way to align network embeddings learned on the train and the test network, so an approach including a new embedding on the test set would not make sense. Hope fully this clarifies the setting?
