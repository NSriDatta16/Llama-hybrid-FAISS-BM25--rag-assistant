[site]: crossvalidated
[post_id]: 61140
[parent_id]: 61085
[tags]: 
R often does not scale well to large data. You may need to move on to more efficient implementations. There are plenty of choices around. But of course, there probably are also various R packages that could help you a bit further. Also, it pays off to stop thinking in matrixes . What you are working with is a graph . 1 is an edge, and 0 is not. An easy way to accelerate computing the similarities here is to cleverly exploit the similarity. This btw. is pretty much the benefits you get by processing the data in "column form" in Hadoop, for example. When you realize that cosine similarity consists of three components: product of A and B, length of A and length of B, you will notice that two parts are independent of the other vector, and the third part has the squared sparsity, this will drastically reduce the computations needed for a cosine similarity "matrix" (again, stop seeing it as a matrix) The streamlining then is: Compute the length of each single vector, for normalization (i.e. compute $|A|$) For each attribute (!) send a message to each pair of non-zero entries. If you have $0.01$ of non-zero values in each of $c$ columns, this will be just $O(0.0001 * c * n^2)$ messages. Count the number of messages received for each pair, this is $A\cdot B$, divide by $|A|$ and $|B|$. Alternatively: Standardize each vector to length $|A|=1$ (your matrix will no longer be binary!) For each attribute (!) send a message with the product of the two values to each pair of non-zero entries. If you have $0.01$ of non-zero values in each of $c$ columns, this will be just $O(0.0001 * c * n^2)$ messages. Sum the messages received for each pair, this is the cosine similarity. (No division necessary, as $|A|=|B|=1$) And definitely think about how to store and organize your data in memory. Here, fast data access and manipulation is 90% of the cost, the actual computations are trivial. Don't let R do it automatically, because that probably means it is doing it wrong...
