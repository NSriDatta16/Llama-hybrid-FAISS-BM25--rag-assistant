[site]: crossvalidated
[post_id]: 495446
[parent_id]: 495252
[tags]: 
You could do the oversampling outside/before the cross validation iff you keep track of the "origin" of the synthetic samples and treat them so that no data leak occurs. This would be an additional constraint similar to e.g. a stratification constraint. This is possible e.g. by doing a cross validation on the real-sample basis and inside the cross validation add only those synthetic data to the train (test) data where the original cases are both in the training (test) set. For testing, I'd anyways at least keep track of what results were obtained with real data and what with synthetic data. OTOH, there is the question whether this is worth while, and whether the oversampling isn't only curing a symptom that actually points to deeper problems (for which more appropriate direct solutions are available): Are unbalanced datasets problematic, and (how) does oversampling (purport to) help? When is unbalanced data really a problem in Machine Learning? Class imbalance in Supervised Machine Learning What is the root cause of the class imbalance problem?
