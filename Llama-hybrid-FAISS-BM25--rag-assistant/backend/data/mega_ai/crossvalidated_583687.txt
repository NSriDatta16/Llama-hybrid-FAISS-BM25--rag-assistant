[site]: crossvalidated
[post_id]: 583687
[parent_id]: 583662
[tags]: 
I suspect that there is nothing wrong with the degrees-of-freedom (DF) estimates. If you have 100 participants each having 40 headlines to evaluate, you have 4000 observations. The DF used to evaluate those interaction terms should represent the number of observations minus the DF used up for other aspects of the model. What seems more likely in your lmer() model is that you have "statistically significant" effects with your interaction terms that aren't practically significant, given the magnitude of the Accuracy effect. Practical and statistical significance aren't the same thing, particularly with large sample sizes. That said, you should be paying attention to why the binomial model isn't converging. The lmer() model is seldom appropriate for binary outcomes and might give you probabilities below 0 or above 1. You don't say what the problem is, but logistic regression can run into perfect separation . It's also possible that the default solver or number of iterations weren't adequate for the size and nature of your data set. The above explanation of interaction effects that "are not interpretable when looking the visualized data" would still hold.
