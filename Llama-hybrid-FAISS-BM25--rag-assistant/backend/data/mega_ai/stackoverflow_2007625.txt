[site]: stackoverflow
[post_id]: 2007625
[parent_id]: 2007575
[tags]: 
That's a very vague question. You say you look for indexing, but you can't look at indexing in isolation. You have to look at the queries that are being run, the execution plans, the indexes that are being used and how they are being used. The Profiler tool can help a great deal in determining which queries are inefficient. Aside from that - make sure a maintenance plan is set up. You should be updating statistics and defragmenting/rebuilding indexes at least once a week in a heavy transactional database. If you have the infrastructure, look at your file and filegroup settings. You should try to put tables and/or indexes that are large and frequently used on different physical drives, if possible. If you have any very large tables, you might think of partitioning them. If you're still having performance problems, denormalization can sometimes help - but it all depends on the situation. I'm going to stop there - don't want this answer to become the world's most random list of SQL performance tips. I recommend you be more specific about where you think the performance issues are, and tell us a bit more about the database (size, current indexing strategy, transaction frequency, any large reports you need to generate, etc.)
