[site]: crossvalidated
[post_id]: 164246
[parent_id]: 164048
[tags]: 
The answer by @Sycorax is fantastic. In addition to those fully described aspects of the problem related to model fit, there is another reason not to pursue a multi-step process such as running random forests, lasso, or elastic net to "learn" which features to feed to traditional regression. Ordinary regression would not know about the penalization that properly went on during the development of the random forest or the other methods, and would fit unpenalized effects that are badly biased to appear too strong in predicting $Y$ . This would be no different than running stepwise variable selection and reporting the final model without taking into account how it arrived.
