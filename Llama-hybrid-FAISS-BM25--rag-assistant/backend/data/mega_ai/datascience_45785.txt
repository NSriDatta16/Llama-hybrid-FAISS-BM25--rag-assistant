[site]: datascience
[post_id]: 45785
[parent_id]: 
[tags]: 
Training deep CNN with noisy dataset

I am training a Mask RCNN model with a train dataset that has been generated from some simple computer vision operations (color thresholding) and some morphological filtering. The train set captures around 2387 instances over 1157 images and there is only one class. The validation dataset is human annotated with 1381 instances over 410 images. I estimate the data pollution rate in the train set to be around 40%. The model appears to be training well, albeit very slowly as indicated by the always decreasing val_loss. However a strange thing happens with the training loss; at every drop in learning rate, the loss increases significantly (see below). Can anyone provide insight or references as to why: The model trains so slowly The training loss increases while the val loss decreases Any tips on better training models with noisy train datasets. Parameters: L2 loss on Conv2D layers: 1e-4 / size(kernel) Optimisation strategy: Nadam optimiser, LR 1e-3, scheduled to divide by 10 on plateau (patience 50) Training from scratch
