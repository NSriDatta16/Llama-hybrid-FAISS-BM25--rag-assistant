[site]: crossvalidated
[post_id]: 547708
[parent_id]: 
[tags]: 
How to derive local variational close form for logistic regression, analytically

In Prof Bishop's book, Pattern Recognition and Machine Learning, Chapter 10, on local variational inference for logistic regression, page 501, equation 10.161 has been derived, from differentiating EM objective, which is $$ \xi_{new}^2 = \phi_n^\mathsf{T}(S_n + m_n m_n^\mathsf{T})\phi_n. $$ In 2 paragraphs later, it has been said that "An alternative approach to obtaining re-estimation equations for $\xi$ is to note that in the integral over w in the definition (10.159) of the lower bound $L(\xi)$ , the integrand has a Gaussian-like form and so the integral can be evaluated analytically. Having evaluated the integral, we can then differentiate with respect to $\xi_n$ . It turns out that this gives rise to exactly the same re-estimation equations as does the EM Exercise 10.34 approach given by (10.163)." However, when I tried the alternative route, I didn't reach this equation. Is there any source that derived the above equation analytically? or Can anyone derive it here? Edit: Adding objective function : Assuming $p(w)\sim \mathcal{N}(0,\alpha I)$ , from (10.153, 10.154) we have: $$ h(w, \xi)p(w) = exp\{\sum_n w^\mathsf{T} \phi_n( t_n-1/2) -\xi_n/2-w^\mathsf{T}(2\lambda(\xi_n)\phi_n\phi_n^\mathsf{T}+\alpha I)w+\lambda(\xi_n)\xi_n^2+ln(\xi_n)\} $$ . For the next operations, I'm not sure what is correct to bring it here.
