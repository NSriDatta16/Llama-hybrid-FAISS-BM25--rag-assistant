[site]: crossvalidated
[post_id]: 26367
[parent_id]: 26360
[tags]: 
I think you have to set up this problem using Markov Chains theory, are you familiar with it? The system you are considering is a discrete system which can be in any of the (n+1) states { [0], [1], [2], ... ,[n] } where [j] is the state with j red balls. The system starts from the state [0] and evolves over time with a transition matrix, (probability of going from state i to state j) $T_{ij}=\frac{n-i}{n}$ if j=i+i $T_{ij}=\frac{i}{n}$ if j=i $T_{ij}=0$ otherwise Now this Markov chain is stationary and you know the initial distribution (which is a delta function peaked on the state [0]) You can get the distribution at a future time k (in this case you are interested in time k, which means after k steps) by multiplying the transition matrix by itself k times and then multiplying the result times the initial distribution $p_k=T^k p_0$ where $p_k$ is the vector of probabilities (indexed by the state) at time k and $p_0$ is the vector of probabilities at time 0 (delta function at 0). Now, since the product fo a matrix ($T^k$) times a vector ($p_0$) which has a 1 at the first element and 0 everywhere else (your delta function) is just the first column of the matrix and since you are interested in the probability of $d$ red balls then what you are looking for is the matrix element $(T^k)_{d+1,0}$ I've put d+1 because we take [0] balls to be the first element. So all you have to do is to do the matrix product and look for that element. Possibly, since the matrix is nearly diagonal, you will find that you can calculate it analytically, give it a go
