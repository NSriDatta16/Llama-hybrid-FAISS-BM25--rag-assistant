[site]: crossvalidated
[post_id]: 408333
[parent_id]: 
[tags]: 
a model for multiclass classification with varying number of classes

I've been searching for a model that can take as input an arbitrary number of feature vectors. As in the title, wanted to build a model that would be able to pick the best candidate from a set. For each record the size of a set could differ (so the number of classes would differ as well). Since NLP deals with sets of arbitrary length, my first attempt was to use something like RNN but I wanted it to be insensitive to order. I'm aware of bidirectional RNNs. I've also found a 'bag of words' implementation in rnn and ffn. bag of words implementation in RNN neural bag of words model An example (an artificial one) We've got a number of movies. For each movie we've got a set of reviews (the number of reviews varies). Only one of them is positive, the rest is negative. Of course, one could create a model for each individual review but one can do better. The idea is that the information from the other reviews might significantly improve the model. Zero padding won't probably do the trick, the number of reviews varies greatly. Update & a possible solution There's a well known paper about rankNET , where the authors use shared weights across the network for a learn-to-rank problem (check out Siamese networks ). One could use the idea (shared weights) to build a model for the multiclass classification I've described above. While I was not able to implement it in keras, it is quite easy to derive the backpropagation algo for these kinds of networks. It's easy to teach the network, even if there are different sizes of input vectors for every record. I'm still unsure how it will perform though.
