[site]: datascience
[post_id]: 56601
[parent_id]: 
[tags]: 
Do CNN convolution and pooling layers get backpropogated?

I can't find a simple answer to this by Googling which leads me to think the answer is no, but I want to be sure... In a feed forward network, all of the layers of weights get backpropogated, but what happens in a convolutional neural network on the backprop step? Is it only the feedforward part of the network (after the convolution and pooling layers) that gets backpropped? Which would mean that the convolutional layers are a form of static feature extraction...
