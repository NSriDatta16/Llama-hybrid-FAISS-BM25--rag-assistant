[site]: crossvalidated
[post_id]: 265890
[parent_id]: 265871
[tags]: 
Imagine yourself to be in a situation where you're doing many similar tests, in a set of circumstances where some fraction of the nulls are true. Indeed, let's model it using a super-simple urn-type model; in the urn, there are numbered balls each corresponding to an experiment you might choose to do, some of which have the null true and some which have the null false. Call the proportion of true nulls in the urn $t$. To further simplify the idea, let us assume the power for those false nulls is constant (at $(1-\beta)$, since $\beta$ is the usual symbol for the type II error rate). You choose some experiments from our urn ($n$ of them, say) "at random", perform them and reject or fail to reject their hypothesis. We can assume that the total number of experiments in the urn ($M$, say) is large enough that it doesn't make a difference that this is sampling without replacement (i.e. we'd be happy to approximate this as a binomial if need be), and both $n$ and $M$ are large enough that we can discuss what happens on average as if they're what we experience. What proportion of your rejections will be "correct"? Expected total number of rejections: $nt\alpha+n(1-t)(1-\beta)$ Expected total number of correct rejections: $n(1-t)(1-\beta)$ Overall proportion of times a rejection was actually the right decision: $\frac{(1-t)(1-\beta)}{t\alpha+(1-t)(1-\beta)}$ Overall proportion of times a rejection was an error: $\frac{t\alpha}{t\alpha+(1-t)(1-\beta)}$ For the proportion of correct rejections to be more than a small number you need to avoid the situation where $(1-t)(1-\beta)\ll t\alpha$ Since in our setup a substantial fraction of nulls are true, if $1-\beta$ is not substantially larger than $\alpha$ (i.e. if you don't have fairly high power), a lot of our rejections are mistakes! So when your sample size is small (and hence power is low), if a reasonable fraction of our nulls were true, we'd often be making an error when we reject. The situation isn't much better if almost all our nulls are strictly false -- while most of our rejections will be correct (trivially, since tiny effects are still strictly false), if the power isn't high, a substantial fraction of those rejections will be "in the wrong direction" - we'll conclude the null is false quite often because by chance the sample turned out to be on the wrong side (this may be one argument to use one sided tests - when one sided tests make sense - to at least avoid rejections that make no sense if large sample sizes are hard to get). We can see that small sample sizes can certainly be a problem. [This proportion of incorrect rejections is called the false discovery rate ] If you have a notion of likely effect size you're in a better position to judge what an adequate sample size might be. With large anticipated effects, a rejection with a small sample size would not necessarily be a major concern.
