[site]: datascience
[post_id]: 9845
[parent_id]: 9818
[tags]: 
I've posted this link on Reddit and got a lot of feedback. Some have posted their answers here, others didn't. This answer should sum the reddit post up. (I made it community wiki, so that I don't get points for it) Auto-Encoding Variational Bayes is a combination of a Bayes Network and a neural network. The paper Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference seems to go in the same direction. Dropout: A Simple Way to Prevent Neural Networks from Overfitting is an example where Bayesian neural networks outperform their dropout approach (see section 6.4 "Comparison with Bayesian Neural Networks") Human-level concept learning through probabilistic program induction is a paper "on a Bayesian net network that does one-shot classification that way outperformed neural networks" (according to trashacount12345 - I didn't check that by now). Yann LeCun wrote a Google+ post in which he argues that neural networks and probabilisitc graphical models are not orthogonal concepts.
