[site]: crossvalidated
[post_id]: 264638
[parent_id]: 264436
[tags]: 
It seems that bootstrapping, as suggested by @Tim in comments, might be a good way to proceed. Even if your statistical software doesn't directly support bootstrapping it's not to hard to roll your own. For example, say you have all data for each individual in a single row (species; 3 treatment types; starting and ending length, width, and height; block ID) and you have 304 rows. You set up an index vector of length 304, and for each bootstrap fill it with a random sample with replacement from the integers from 1 to 304. You then take those indexed rows from your full data set for 304 rows total (with some original rows omitted, some taken once, and others 2 or more times). Then do your analysis and store the regression coefficients. Do this 999 times. For each regression coefficient, average the 999 results; then put its values for the 999 repetitions in rank order; the 25th and 975th in order set the 95% confidence limits. Unless your analysis depends heavily on having a balanced design, this should suffice. This will not work if there is an underlying Cauchy problem, but I'm not convinced that you have this problem with your data set. The Cauchy problem comes from trying to take a ratio of 2 random variables in which you run a risk of dividing by zero or by numbers close to zero. Although this can be a serious issue in the types of economic time series addressed by @DaveHarris in the documents linked from his answer, in your case the lengths, widths and heights are all positive and far from zero so you don't seem to be in that situation. Raw differences between start and finish, or logs of start/finish ratios, should be sufficiently well behaved that you can analyze your data with the bootstrap, which is a well respected way to deal with your type of situation when you can't count on normal distributions of the data of interest.
