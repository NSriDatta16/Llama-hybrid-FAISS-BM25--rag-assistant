[site]: crossvalidated
[post_id]: 508350
[parent_id]: 508347
[tags]: 
The word "convincing" is not standard statistical wording, but rather subjective. You may have a lecturer who taught you how to use it, but that would be their personal usage really. Some people use specific different wordings depending on the test or confidence level, i.e., "there's some evidence that a mean is not 0" if it is rejected at 5% or - equivalently - it isn't in the 95% confidence interval (CI), "strong evidence" at 1%/99% etc. Probably you were taught to use "convincing" for a certain level, but that's not a standard. What can be said is that the CI is a set of parameter values that are all compatible with the data (at the given level). So for example if the CI is (10,15), surely there can't be "convincing evidence" that the mean is 12, because it might well be 13 or 10.2 or 14.8. Same if the CI is (0.5,0.6), the true mean can well be 0.52, so this doesn't give you evidence that it's >0.55. However, means lower 0.3 would, at level 95%, not be compatible with the data, so yes, one can say there's evidence (with whatever additional word your lecturer would like to use) that the true mean is larger than 0.3. "Significant" would normally refer to significance tests, however there is a mathematical correspondence between tests and CIs, so if the 95% CI is (0.5,0.6), this also means that a standard 5% test of the null hypothesis mean=0.3 would be rejected, so the mean is significantly different from 0.3. However we've got to be careful not to put too much trust in words. For example, if you compute 100 CIs at level 95%, chances are on average 5 of them will not include the true value, so one shouldn't say every single one provides "convincing" or "enough" evidence - one shouldn't be too convinced that they all cover the true value. And then all this is based on model assumptions which in reality are not normally true (one may wonder whether a "true" mean that is not directly observable even exists), and then there's more than one way to test the same hypothesis and different tests may give you different results. Sorry for making things even more confusing but you've got to accept, indeed, statistics is difficult (and asking questions like you do is a good start).
