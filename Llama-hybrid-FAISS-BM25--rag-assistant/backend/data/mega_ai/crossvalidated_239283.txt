[site]: crossvalidated
[post_id]: 239283
[parent_id]: 239246
[tags]: 
In Bayesian estimation one views the parameter as a random variable and bases estimates on its posterior distribution given the data. However, there is no single, "correct" way to get an estimate from a posterior distribution, so one common approach is to take the mode of the posterior distribution. This is sort of the Bayesian analog of maximum likelihood. Another approach is to take the mean of the posterior, as one does when using the squared error loss function. So to answer your question, the idea of taking the most likely value of the parameter is just one approach to doing Bayesian estimation and is not necessarily something that needs proving.
