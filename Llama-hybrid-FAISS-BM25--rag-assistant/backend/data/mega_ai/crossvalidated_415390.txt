[site]: crossvalidated
[post_id]: 415390
[parent_id]: 
[tags]: 
Bayesian Hyperparameter Optimization. What makes it "bayesian"?

I'm using some bayesian hyperparameter optimization. I know how they works . They always calculate the next values of the hyperparameter dependent on the result of former evaluations. But what makes them bayesian? I know the bayesian theorem is: p(A|B) = (P(B|A) * P(A)) / P(B) What is the connection between this formula an the process of bayesian hyperparameter optimization? Is it just that the probability of a hyperparameter value depends on condition (former evaluations) we consider as relevant for the event? Thanks for helping!
