[site]: crossvalidated
[post_id]: 525480
[parent_id]: 525093
[tags]: 
In the results from both fit1 and fit0 , the coefficients (in the non-exponentiated scale), their standard errors, and the statistics calculated from their ratios are identical. So the pooling of point estimates and standard errors agrees between pool() and your method. What's different is the degrees of freedom used to evaluate the significance of the statistics. In your evaluation of fit0 you used a Z-test, or equivalently a t-test with infinite degrees of freedom, to evaluate whether the average coefficient values differ from 0. That is the limiting case if there were no error introduced by imputation and a very large number of degrees of freedom in the complete-data analysis. Yet there is some error being introduced by the imputation. At the other extreme, if all the error is introduced by imputation, you only have 5 imputations (the default) among which to average, providing 4 degrees of freedom in a t-test to distinguish those mean coefficient estimates from 0. On that basis, the test statistics for age and t5 would have p-values of 0.053 and 0.041, respectively. The proper calculation of the degrees of freedom, $\nu$ , for multiple imputation is explained in Stef van Buuren's Flexible Imputation of Missing Data book online. That calculation takes into account the number of imputations and the variability introduced by the imputation. When pool() estimated the degrees of freedom, it only got 0.50 and 0.44 for age and t5 , respectively, as shown in summary(fit1) . The reported p-values are consistent with the reported test statistics and t-distributions having those degrees of freedom. There thus might be an error in the calculation of degrees of freedom because you started with a coxme model. By default, the pool() function tries to get the complete-data degrees of freedom (typically, the number of cases minus the number of fitted coefficients) from the models themselves. The degrees of freedom easily extracted from the coxme objects (e.g. fit$analyses[[4]]$df ) are very small and probably aren't what's appropriate for calculating the degrees of freedom for multiple imputation. The pool() function allows for a dfcom argument where you can specify the degrees of freedom in the complete-data analysis. Provide a reasonable value for that argument in your call to pool() * and you should be OK. My guess is that the results will be much closer to your estimates based on the Z-test. *I'm not sure how many degrees of freedom to associate with the fixed-effect estimates in a coxme model. With 113 events in this case, 2 fixed coefficients, and a single random effect based on 19 clusters, something on the order of 100 would probably be OK.
