[site]: crossvalidated
[post_id]: 630614
[parent_id]: 
[tags]: 
How to measure the difference between two distributions of the same family?

Kullback-Leibler divergence seems to be a frequently used "metric" to measure the difference between probability distributions, regardless of their respective families. However, I would like to measure the difference between the parameters of two distributions of the same family (multivariate normal). Is there an appropriate metric for this? Would mean squared error between their means and covariance matrices suffice? Additionally, as this is part of a recreational deep learning project, I would prefer the metric to be differentiable.
