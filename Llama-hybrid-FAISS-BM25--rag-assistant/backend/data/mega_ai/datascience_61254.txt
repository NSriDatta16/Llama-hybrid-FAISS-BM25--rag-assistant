[site]: datascience
[post_id]: 61254
[parent_id]: 
[tags]: 
LSTM to predict Sin(x) from x

I would like to pass a series of values $x_1, x_2...$ as input to the model to predict $y_1 = sin(x_1), y_2 = sin(x_2)...$ -I created dataset: $x=[0.1,0.2,...]$ and $y=[sin(0.1),sin(0.2),...]$ -I normalize x in $[0,1]$ (not y because it has range $[-1,+1]$ . -I split x and y in: x_train/y_train, x_val/y_val, x_test/y_test -I pass x_train and y_train to fit model lstm it doesn't even work for the training set. (Maybe for the test set it cannot work because x_test is out of range of x_train?) I set time_steps = 70 because I need to set more than a sin period, I think I tried to fit for more than 20 epochs but the train/validation loss not changed.. import sys import os import numpy as np import math import pandas as pd from matplotlib import pyplot as plt from sklearn.preprocessing import MinMaxScaler from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error from keras.models import Sequential, load_model from keras.layers import LSTM, Dense, Flatten, Dropout from keras.callbacks import EarlyStopping, ModelCheckpoint from keras import backend as K K.clear_session() # hyper-parametri params = { "batch_size": 20, "epochs": 20, "time_steps": 70, } OUTPUT_PATH = "..." TIME_STEPS = params["time_steps"] BATCH_SIZE = params["batch_size"] n_periods = 20 n_points = int(2*math.pi*n_periods)*10+1 x = np.linspace(0, int(2*math.pi*n_periods), n_points) y = np.zeros(n_points) for i in range(0, n_points): y[i] += math.sin(x[i]) x = (x - np.min(x))/np.ptp(x) #normalize def create_timeseries(arr1, arr2): # build univariate time series dim_0 = len(arr1) - TIME_STEPS x = np.zeros((dim_0, TIME_STEPS)) y = np.zeros((dim_0,)) for i in range(dim_0): x[i] = arr1[i:TIME_STEPS+i] #TIME_STEPS+i non compreso y[i] = arr2[TIME_STEPS+i-1] #print(x[i], y[i]) print("length of time-series i/o",x.shape,y.shape) return x, y def adjust_dataset(mat, batch_size): # eliminates the excess dataset portion no_samples_to_drop = mat.shape[0] % batch_size if(no_samples_to_drop > 0): return mat[:-no_samples_to_drop] else: return mat x_ts, y_ts = create_timeseries(x, y) # reshape da [samples, timesteps] in [samples, timesteps, features] n_features = 1 x_ts = x_ts.reshape((x_ts.shape[0], x_ts.shape[1], n_features)) len_train = int(len(x_ts)*80/100) len_val = int(len(x_ts)*10/100) #DATASET DI TRAINING 80% x_train = x_ts[0:len_train,:,:] y_train = y_ts[0:len_train] #DATASET DI VALIDATION 10% x_val = x_ts[len_train:len_train+len_val,:,:] y_val = y_ts[len_train:len_train+len_val] #DATASET DI TEST 10% x_test = x_ts[len_train+len_val:,:,:] y_test = y_ts[len_train+len_val:] x_train = adjust_dataset(x_train, BATCH_SIZE) y_train = adjust_dataset(y_train, BATCH_SIZE) x_val = adjust_dataset(x_val, BATCH_SIZE) y_val = adjust_dataset(y_val, BATCH_SIZE) x_test = adjust_dataset(x_test, BATCH_SIZE) y_test = adjust_dataset(y_test, BATCH_SIZE) print(x_train.shape, y_train.shape) print(x_val.shape, y_val.shape) print(x_test.shape, y_test.shape) def create_model(): model = Sequential() model.add(LSTM(30, input_shape=(TIME_STEPS, x_train.shape[2]), return_sequences=True)) model.add(LSTM(30, input_shape=(TIME_STEPS, x_train.shape[2]))) model.add(Dense(1)) model.compile(optimizer='adam', loss='mse') return model model = create_model() model.summary() history = model.fit(x_train, y_train, epochs=params["epochs"], verbose=2, batch_size=BATCH_SIZE, shuffle=False,validation_data=(x_val, y_val)) Results: Test set MSE: 0.49853
