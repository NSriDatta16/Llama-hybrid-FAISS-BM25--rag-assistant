[site]: crossvalidated
[post_id]: 137790
[parent_id]: 137786
[tags]: 
If your professor said that, they were wrong. The estimated betas ($\hat\beta_1$) in logistic regression are on the scale of the linear predictor. That is, they are changes in log odds . Exponentiating them (i.e., $\exp(\hat\beta_1)$) converts them from additive changes in log odds to multiplicative changes in odds. In other words, you are right, the odds would decrease (increase) by a factor of $\exp(\hat\beta_1)$. This follows from the definition of logarithms and exponentiation. When the odds are divided by $1+\rm odds$ (not $1-\rm odds$), then you will get a predicted probability. In addition, your professor's expressions seem to be missing the intercept, $\hat\beta_0$, unless it was suppressed (a bad idea). That is, the predicted probability of 'success' ($Y=1$) at a particular point, $X=x_i$, is $\exp(\beta_0 + \beta_ix_i)/(1+\exp(\beta_0 + \beta_ix_i))$. This seems to be confused on multiple levels; that may be a bad sign.
