[site]: datascience
[post_id]: 96281
[parent_id]: 
[tags]: 
Preprocess multi-sample time series data: encode each sample separately or in aggregate?

Let's say I have 3 dense sequences of uniform length. Should I fit a scaler on them separately or together? import numpy as np from sklearn.preprocessing import StandardScaler arr = np.array([ [ [1.1],[2.2],[3.3] ], [ [1.2],[2.3],[3.4] ], [ [4.0],[5.0],[6.0] ] ]) SS = StandardScaler() Separately: SS.fit_transform(arr[0]) SS.fit_transform(arr[1]) SS.fit_transform(arr[2]) Or together? tall_2d = np.concatenate((arr[0],arr[1],arr[2])) SS.fit(tall_2d) SS.transform(arr[0]) SS.transform(arr[1]) SS.transform(arr[2]) I suppose I would be performing interpolation on each sequence separately, so should I encode and detect outliers separately too?
