[site]: datascience
[post_id]: 32843
[parent_id]: 16729
[tags]: 
Why can't the input be a vector of all those values, so that I can decide to multiply them if I want, or apply another function from the vector space to the reals, and then apply the activation function on that real value? You CAN implement that in Keras , using a custom Lambda layer, see this . So assume that you have a feedforward neural network with 2 layers, which are fully connected. In Keras this means that you have 2 Dense layers sequentially. Each node of each layer performs a sum of its inputs and thereafter applies the activation function. If you wish to multiply the outputs of the first layer and then feed their products to the next Dense layer, you just need to insert a Lambda layer in between. The new Lambda layer shall multiply -or do whatever you want with- the outputs of the first layer and then feed the result in the other Dense layer. Any implementation I have seen does not allow this, and if I wanted to do it, it seem I would have to implement my whole neural network architecture by myself without the possibility of using Theano, Keras or other libraries Essentially, you just need to write only your custom Lambda layer and model.add() it in between any two layers of interest :)
