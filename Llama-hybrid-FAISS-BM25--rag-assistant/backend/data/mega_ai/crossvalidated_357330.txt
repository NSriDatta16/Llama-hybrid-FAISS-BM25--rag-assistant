[site]: crossvalidated
[post_id]: 357330
[parent_id]: 
[tags]: 
Why we train the generative model "indirectly" in GAN(generative adversarial networks)?

In the simple GAN here , I noticed when we train the generator, we are not directly training it by mapping the noise input (length 100 vector) to an image (28*28 matrix). Instead, the author is using the whole GAN and disable the discriminator to train the Generator (see below). # Train discriminator discriminator.trainable = True dloss = discriminator.train_on_batch(X, yDis) # Train generator noise = np.random.normal(0, 1, size=[batchSize, randomDim]) yGen = np.ones(batchSize) discriminator.trainable = False gloss = gan.train_on_batch(noise, yGen) Could anyone tell me why? Can we directly train generator by doing length 100 vector input and 28*28 output, like sequence to sequence model?
