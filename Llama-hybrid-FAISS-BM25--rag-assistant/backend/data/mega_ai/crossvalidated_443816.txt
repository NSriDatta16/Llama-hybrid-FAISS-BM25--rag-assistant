[site]: crossvalidated
[post_id]: 443816
[parent_id]: 443814
[tags]: 
I don't think that would be possible without substantial changes as it would require the slope of the hyper-plane to be different on either side of the decision boundary (in which case it would no longer be a hyper-plane). However, you could get a similar result by using a different slack penalty (usually the C hyper-parameter) for positive and negative patterns. Many SVM solvers support this as it can be used to compensate for unequal false-positive and false-negative costs or for situations where the class frequencies in the training set are different from those encountered in operation. Mrs Marsupial and I wrote a paper on this some years back, but there were several other papers that published similar results around that time. G. C. Cawley and N. L. C. Talbot, Manipulation of prior probabilities in support vector classification, In Proceedings of the IEEE/INNS International Joint Conference on Neural Networks (IJCNN-2001), pp. 2433-2438, Washington, D.C., U.S.A., July 15-19 2001. ( pdf )
