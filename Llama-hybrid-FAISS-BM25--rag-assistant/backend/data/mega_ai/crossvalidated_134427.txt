[site]: crossvalidated
[post_id]: 134427
[parent_id]: 
[tags]: 
In practice, why do we convert categorical class labels to integers for classification

This might be a naive question, but I am wondering why we (or maybe it's just me) are converting categorical class labels to integers before we feed them to a classifier in a software package such as Python's scikit-learn ML library? Let's take the simple Iris dataset, why do we convert the class labels from "Setosa", "Virginica", and "Versicolor" to e.g., 0, 1, and 2? This question came up when I was collaboratively working on a project and one of my colleagues didn't use a label encoder to convert the class labels from strings to integer. It worked (she was using scikit-learn); I intuitively "corrected" it (inserted a label encoder) and she asked me why: Well, I really had no good answer to that other than "most machine learning algorithms work better this way" (this is something I read sometime ago somewhere). Now that I thought about it: What is the rationale behind it? Since in typical classification tasks class labels are nominal, not ordinal variables, is it computational efficiency (storing and processing less "data")?
