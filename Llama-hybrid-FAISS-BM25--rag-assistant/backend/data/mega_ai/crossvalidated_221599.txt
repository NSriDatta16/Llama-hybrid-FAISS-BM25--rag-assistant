[site]: crossvalidated
[post_id]: 221599
[parent_id]: 127073
[tags]: 
Your fitted model is best viewed as a function that consumes data points and returns predictions, this is the fitted function in its greatest generality. For example, in linear regression, the fitted model can be expressed as a vector of estimated model coefficients $(\beta_0, \beta_1, \ldots, \beta_n)$, and the fitted function is $$ f(x) = \beta_0 + \beta_1 x_1 + \cdots + \beta_n x_n $$ For a boosted tree model, the fitted function is $$ f(x) = g\left( \sum_i T_i(x) \right) $$ where $T_i$ are the individual weak learners (trees in most implementations), and $g$ is a link function. In your example, $g$ converts the predictions from a log-odd to a probability. Usually in an R package you can evaluate the fitted function by calling predict . You can evaluate the fitted function on your training data points, these are the fitted values in your second plot. Your first plots are commonly called partial dependency plots . Generally, the full form of the fitted function is very high dimensional, and cannot be completely visualized by the human imagination. To alleviate this dimensionality problem, partial dependency plots average out the effects of all the variables in the model except one, and plots the average fitted value with respect to the one variable that is left over. It is also possible to make two-dimensional partial dependency plots, which look like a surface, you can see an example here .
