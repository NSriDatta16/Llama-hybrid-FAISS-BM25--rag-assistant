[site]: crossvalidated
[post_id]: 178128
[parent_id]: 178120
[tags]: 
Of course not. Random forests are known for being capable to separate even very complex classes with nonlinear decision boundary, for which one will think about SVM with some kernel ( http://scikit-learn.org/stable/modules/ensemble.html ) Also ( deep ) autoencoders are not always based on kernel computations but they are nonlinear. Typically, it's very difficult to find this non-linear equivalent in the input space from the beginning, although, of course, when you know some hidden magic behind you data you can build much simpler classifiers ( and in general you are even obliged to do some investigation of your data prior to solving classification task ) However, to my experience, when you build very strong classifiers for image processing tasks, all really good results are thanks to deep architectures, which are kernel-based under the hood ( and these kernels are learnable! )
