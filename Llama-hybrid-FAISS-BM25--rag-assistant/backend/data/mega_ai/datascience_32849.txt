[site]: datascience
[post_id]: 32849
[parent_id]: 
[tags]: 
Why do we need the sigmoid function in logistic regression?

What is the purpose of the logistic sigmoid function as it is used in logistic regression? Why does it need to be part of the hypothesis function h(x) ? As I understand it, the logistic sigmoid function gives the probability that a certain input vector x is contained within a class C1 for a label y. In the binary-class case, it seems that if h(x) >= 0,5, we say that x belongs to one class, otherwise it belongs to the other. In the logistic regression model, our hypothesis function h(x) is of the form g(p^T * x), where p is the parameter vector (p^T is the transpose) and g is the sigmoid function. Since the y-intercept of the logistic sigmoid is 0.5, saying that h(x) >= 0.5 is the same as saying p^T * x >= 0. What I'm getting at is why do we need the logistic sigmoid function at all to define some threshold for separating the classes? Why not just let the hypothesis function be of the form h(x) = p^T * x, and claim that y = 1 if p^T * x >= 0? Why complicate things unnecessarily with the logistic sigmoid?
