[site]: datascience
[post_id]: 36387
[parent_id]: 36344
[tags]: 
Spectral clustering usually is spectral embedding, followed by k-means in the spectral domain. So yes, it also uses k-means. But not on the original coordinates, but on an embedding that roughly captures connectivity. Instead of minimizing squared errors in the input domain, it minimizes squared errors on the ability to reconstruct neighbors. That is often better. The main reason why spectral clustering is not too popular is because it is slow (usually involves building a O(n²) affinity matrix, and finding the eigenvectors can be up to O(n³) time) and you still need to rely on the original distances/similarities to build the input graph before embedding. Most of the difficulty of clustering is in handling the data to get reliable distances/similarities...
