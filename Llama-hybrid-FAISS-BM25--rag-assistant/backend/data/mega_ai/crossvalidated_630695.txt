[site]: crossvalidated
[post_id]: 630695
[parent_id]: 
[tags]: 
How does Dempster-Shafer Theory of Evidence relate to Deep Learning?

I am reading this article and it has the following phrase - "Dempster-Shafer Theory of Evidence assigns belief masses a set of classes (unlike assigning a probability to a single class) ". However, I am not able to understand this concept. Why would one typically assign a probability to a class in the first place. Also, why is Dempster-Shafer's technique better? Finally, why does the sum of belief masses and uncertainty sum to 1? Based on my reading , this is what D-S Theory does - "In this formalism a degree of belief (also referred to as a mass) is represented as a belief function rather than a Bayesian probability distribution.". I also read this article but it didn't help me.
