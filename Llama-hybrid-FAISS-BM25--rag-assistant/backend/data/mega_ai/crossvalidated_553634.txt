[site]: crossvalidated
[post_id]: 553634
[parent_id]: 
[tags]: 
understanding normalisations in StyleGan2 and on general

I was looking through labml's implementation of StyleGan2, and came across two normalisations: in the DiscriminatorBlock : "Scaling factor $\frac{1}{\sqrt 2}$ after adding the residual" self.scale = 1 / math.sqrt(2) in the PathLengthPenalty : "Calculate (g(w)â‹…y) and normalize by the square root of image size. This is scaling is not mentioned in the paper but was present in their implementation." output = (x * y).sum() / math.sqrt(image_size) as noted, there is no explanation for the necessity of them in the original paper, nor in labml's explanations - which raises the following questions: why are those normalisations needed? why those specific normalisations where chosen, in each case? how one would generally know which normalisations to choose in a deep learning project? I would appreciate any helpful tips, ideas and insights on this matter. thanks.
