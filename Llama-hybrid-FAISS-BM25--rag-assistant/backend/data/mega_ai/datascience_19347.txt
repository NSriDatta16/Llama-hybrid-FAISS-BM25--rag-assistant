[site]: datascience
[post_id]: 19347
[parent_id]: 19268
[tags]: 
Start each model with default parameters,use the evaluation metric to record error of each algorithm with default parameter. For majority of classification modeling AUC metrics gives the better results read here . Not necessary that all features are important, do the feature selection. You can get the important features using random forest/xgboost algorithms, try to remove the least important features and check if evaluation score is improving. . Now you think of tuning the parameters and yes each model have different parameters. Most common parameter is alpha(learning rate), to start with you can hand tuned alpha with values in range 0.0001 to 10 read here . You can use more sophisticated methods to tuned parameters such Randomized and Grid search read here . Feature wights is way to tell your model that which is most/least important feature. You can get the idea of feature weights from the feature importance I explained at the top.
