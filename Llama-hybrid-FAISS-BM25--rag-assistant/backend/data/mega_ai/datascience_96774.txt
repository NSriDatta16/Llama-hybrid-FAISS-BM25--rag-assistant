[site]: datascience
[post_id]: 96774
[parent_id]: 
[tags]: 
Using on-demand features in machine learning

I have 6 input features $[m1,m2,m3,m4,m5,m6]$ . I am trying to build a model that can predict the value of all 6 of these values using $[m1,m2,m3]$ . However, I have the option of asking for another feature from $[m4,m5,m6]$ on a per-prediction basis. Obviously, I want to choose the feature that improves my predictive performance, based on the values of $[m1,m2,m3]$ . How would I go about doing this, and is there a name for this form of problem? The naive option would obviously be to work out which of $[m4,m5,m6]$ improves performance most in my training set and always use it, but I would prefer a method that makes use of my known $[m1,m2,m3]$ to identify which of the $[m4,m5,m6]$ would be best in this case. The closest method I could find was 'active learning', which takes new labels. I get the impression I could maybe use bayesian optimization but I'm unsure how to proceed.
