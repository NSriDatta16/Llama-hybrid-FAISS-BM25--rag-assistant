[site]: crossvalidated
[post_id]: 613345
[parent_id]: 613332
[tags]: 
In principle, the (or at least one) right way to do this is clear (see e.g. this question & answer ), but this is also time-consuming, which I assume is why it's usually not done: Do multiple imputation, build model separately on each of the multiple imputations (of course being careful to impute after training-validation-test-splitting ), if new data has no missing data then the overall prediction is the average of the predictions from each of these models (e.g. see example here). If the new data has missing values, then you need ideally should impute them coherently. I.e. create as many multiple imputations and use the implicit parameter values as used in the original multiple imputation for each imputation - that's easiest, if you did your multiple imputation explicitly with a Bayesian model fit using MCMC, a bit less easy for some imputation packages that abstract this away (and don't offer this option - which I think illustrates that mostly people building tools for multiple imputation think of inference on a fixed dataset, rather than about prediction). Of course, it's not necessary to fit models separately for each imputation, although that's a common approach see e.g. the discussion in BDA3 starting from page 449 (esp. from 452 onwards, see also Zhou, X. and Reiter, J.P., 2010. A note on Bayesian inference after multiple imputation . The American Statistician, 64(2), pp.159-163.). E.g. in Bayesian MCMC samplers, there's approaches that jointly look at the likelihood over all imputations. Alternatively, I'd guess you could do things like picking a different imputation randomly for each tree (or even for each node split) in tree-based algorithms (like random forest or gradient boosted decision trees), but I've never seen that implemented.
