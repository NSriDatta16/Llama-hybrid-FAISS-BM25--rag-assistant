[site]: datascience
[post_id]: 105044
[parent_id]: 
[tags]: 
Interpreting XGBoost's results (when they span between [0,0.5])

I would like to classify sentences into one of two different categories. I trained a XGBoost model over a search grid with k-folds cross-validation. My data represents sentences, and features represent entities that were extracted from each sentence and their sums (the entities actually come from five different models, so I added five other variables for their sums). Eventually, when predicting on the test set, I get the following distribution of probabilities: which I am having trouble interpreting. A few points: The predictions distribution looks almost the same for the train set as well (I don't have a validation set since I have trained the model using folds). I trained another model, logistic regression with a similar process, with cross-validation and different extents of l2 regularization, and got a very similar plot. The code I used is attached below. Using a calibration layer did not help. I understand the results as that the data contains many sentences that clearly belong to class 0, where the other ones are similar to the ones from class number 1. In that regard, the features that I have can't separate between the classes correctly. On the other side, and at this point, I am ok if that is the case since I spent hours trying to understand what is wrong with my model, maybe I have a problem with my code and I did not train both the XGB and the logistic regressions correctly.. from scipy import stats from xgboost import XGBClassifier from sklearn.model_selection import RandomizedSearchCV, KFold from sklearn.metrics import f1_score, accuracy_score from copy import deepcopy X = deepcopy(X_train_) y = deepcopy(y_train_) clf_xgb = XGBClassifier(objective = 'binary:logistic') param_dist = {'n_estimators': stats.randint(150, 600), 'learning_rate': stats.uniform(0.01, 0.5), 'tree_method': ['gpu_hist'], 'subsample': stats.uniform(0.3, 0.7), 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'colsample_bytree': stats.uniform(0.5, 0.45), 'min_child_weight': [1, 2, 3, 4, 5, 6, 7] } clf = RandomizedSearchCV(clf_xgb, param_distributions = param_dist, n_iter = 50, scoring = 'accuracy', error_score = 0, verbose = 10, n_jobs = -1) numFolds = 5 folds = KFold(n_splits = numFolds, shuffle = True) estimators = [] results = np.zeros(len(X)) score = 0.0 for train_index, test_index in folds.split(X): X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:] y_train, y_test = y.iloc[train_index].values.ravel(), y.iloc[test_index].values.ravel() clf.fit(X_train, y_train) estimators.append(clf.best_estimator_) results[test_index] = clf.predict(X_test) score += accuracy_score(y_test, results[test_index]) score /= numFolds
