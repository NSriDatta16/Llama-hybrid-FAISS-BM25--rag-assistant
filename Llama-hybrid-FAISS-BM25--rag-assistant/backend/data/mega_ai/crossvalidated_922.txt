[site]: crossvalidated
[post_id]: 922
[parent_id]: 886
[tags]: 
I don't think there is a fundamental idea around parameter estimation in Machine Learning. The ML crowd will happily maximize the likelihood or the posterior, as long as the algorithms are efficient and predict "accurately". The focus is on computation, and results from statistics are widely used. If you're looking for fundamental ideas in general, then in computational learning theory, PAC is central; in statistical learning theory, structural risk miniminization ; and there are other areas (for example, see the Prediction Science post by John Langford). On bridging statistics/ML, the divide seems exagerrated. I liked gappy's answer to the "Two Cultures" question.
