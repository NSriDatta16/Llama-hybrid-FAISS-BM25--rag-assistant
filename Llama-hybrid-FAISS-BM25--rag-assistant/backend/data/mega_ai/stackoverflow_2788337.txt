[site]: stackoverflow
[post_id]: 2788337
[parent_id]: 2788300
[tags]: 
The software can handle it, can your server? Well, it depends . Are you just archiving it? Sure get a hundred billion rows, it doesn't care, the performance problems come in then you're querying the data. The larger it gets, the more space you need in terms of total storage and for operations (deletes, rollback segments, etc) on that data, preferably in memory but on a fast tempdb drive if not. What matters more to a SQL server than processor on large data sets (though processor certainly affects the time it takes, not the threshold of query/data it can handle) is memory and space (both HD and RAM since it'll overflow to TempDB for large operations), this is speaking in terms of capacity . For performance you need disk IO, memory and processor power all together. The short answer to can it handle it yes , provided you have enough space. Does it handle it fast enough ? That's depends on what kind of queries you're running and how much performance matters. One last thing, don't forget to take a look at other questions here on optimizing large tables .
