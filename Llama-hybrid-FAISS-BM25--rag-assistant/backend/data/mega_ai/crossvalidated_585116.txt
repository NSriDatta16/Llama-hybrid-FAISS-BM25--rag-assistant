[site]: crossvalidated
[post_id]: 585116
[parent_id]: 584027
[tags]: 
I have written some keras code with a single RNN cell and a dense layer to capture the following two patterns which is similar to the two patterns above. However, the distribution of magnitudes of high vehicles and low vehicles that are drawn from a categorical distribution below are not being represented in the test output. Categorical Random Variable, x = {0,1,2} and p(x) = {0.6,0.3,0.1} low vehicles = 1 + x , every 4 hours high vehicles = 6 + x , every 8 hours I managed to get the results like the following with this code from copyreg import pickle import numpy as np import tensorflow as tf import matplotlib.pyplot as plt import tensorflow.keras as keras import sys #### for reproduclvle resutls from numpy.random import seed seed(1) import tensorflow tensorflow.random.set_seed(2) n_steps = 12 batch_size = 32 lay1_state_size = 64 lay2_state_size = 0 dense_state_size = 1 num_epochs = 25 horizon = 24 loss_function_type = 'sparse_categorical_crossentropy or mse or rmse' num_layers = 1 optimizer_type = 'Adam' metrics = 'rmse' # spikes at regrular interval dem = np.load('const_dem_2_freq_stoch.npy') dem_len = len(dem) def gen_batch(dem, batch_size, n_steps): n = n_steps + 1 raw_x = dem[:-1] data_length = len(raw_x) num_of_win = data_length - n - 1 # 1382 windows batch_partition_length = num_of_win // batch_size # 172 batches #print('batch_partition_length',batch_partition_length) data_x = [] j=0 for i in range(batch_partition_length): windows_x = [] k=0 while(k The data generation code is given below from copyreg import pickle import numpy as np import tensorflow as tf import matplotlib.pyplot as plt import tensorflow.keras as keras dem_len = 1240 def categorical(p): return (p.cumsum(-1) >= np.random.uniform(size=p.shape[:-1])[..., None]).argmax(-1) p = np.array([0.6, 0.3, 0.1]) def dem_hr(hr, lo_veh, hi_veh,len): dem_hrs = np.array([]) for i in range(10000): #d = np.random.randint(lo_veh,hi_veh) d = lo_veh + categorical(p) z = np.array([0]*(hr-1)) dem_hrs = np.append(dem_hrs, d) dem_hrs = np.append(dem_hrs, z) dem_hrs = dem_hrs[:len] return dem_hrs def gen_data(len): dzero = np.zeros(len) # for hr,lo_veh, hi_veh in zip([4, 8],[1, 6],[3,9]): # d = dem_hr(hr, lo_veh, hi_veh,len) # dem = dem + d # dem = np.array(dem,dtype=np.float32) d4 = dem_hr(4, 1, 3,len) d8 = dem_hr(8, 6, 9,len) dall = dzero + d8 dsub = dall - d4 dem = np.where(dsub>=0,d8,d4) # plt.plot(dem) # plt.plot(d4) # plt.plot(d8) # plt.show() return dem dem = gen_data(len=dem_len) np.save('const_dem_2_freq_stoch_cat',dem) plt.plot(dem) plt.show() I think incresing the number of steps may help to capture the distribution of magnitudes at different periods. Does increasing the layers also help to capture the magnitude distribution?
