[site]: crossvalidated
[post_id]: 272218
[parent_id]: 
[tags]: 
How to determine how many runs are needed for a Monte Carlo simulation?

I have been reading a lot of references online, but people seem to have different sorts of equations to determine the required number of runs. This formula was the one I obtained from an article and I am wondering if this is indeed the right one. Also, how can I use this formula? Edit: I will use the Monte Carlo simulation to generate random numbers from a normal distribution. These random numbers will be used to represent demand as the random variates. The model of interest is an inventory model where demand will be the variable to be simulated. The properties of the demand is that it is normally distributed, mean is non-stationary over time, independent and not correlated, and stochastic over a time horizon. I performed a linear program using MATLAB, however, the solution of the problem is deterministic by nature--meaning it will always give the same "optimum" value for the specified parameter settings. What I want to achieve is to incorporate randomness into the system by using a Monte Carlo simulation which will test my model for robustness when different "real" demands are incorporated. I would say a 95-98% accuracy would be good, but it is completely arbitrary because I do not really have anything to base it on. Below is my code for the generation of the "real" demand values. Where: n= number of runs; average(i)=mean of demand; a(i)=standard deviation of demand; CV=coefficient of variation; sim_d="real" demand values; This is the flowchart of the process to further explain the procedure (click to see)
