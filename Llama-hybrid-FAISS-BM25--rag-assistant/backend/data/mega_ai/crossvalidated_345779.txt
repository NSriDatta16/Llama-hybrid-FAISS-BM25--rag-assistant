[site]: crossvalidated
[post_id]: 345779
[parent_id]: 
[tags]: 
How should Training Data for Fully ConvNets look like?

I've been working with CNNs recently. For a new task, I need to predict objects in an image pixelwise. Fully ConvNets seem to be the way to go. I read the original paper (Long et al., 2014) and a few blogs about FCNs so far. Though, I have some trouble understanding how to setup my training data. From what I've read, each image in the sample data can be (in opposition to CNNs) of arbitrary size, is that correct? To setup the training data, I have to create a second "image" of an image, which should act as a mask for the object to be trained. May this mask-image contain more than one object and also different types (classes) of objects? Thanks in advance. Please let me know, if I need to add more information.
