[site]: crossvalidated
[post_id]: 617573
[parent_id]: 
[tags]: 
T-test fails as sample size increases. Is there a solution?

Please consider the Table below Item Sample Mean Sample count, n Sample Standard Deviation Standard Error SD/sqrt(n) Unit A 95.9461 PSI n=430 3.8397 0.185166776 Unit B 94.488 PSI n=25 2.5344 0.50688 Now when I want to show if these two tests are significantly different from each other. $$ \frac{94.488 - 95.9461}{ \sqrt{0.50688^2+0.185166776^2}} \approx -2.7 $$ Now according to this Website these two units are significantly different!? Even if I have the true standard deviation (in this case its probably similar). I would still get similar results. Dividing by the sample count completely destroys any kind of SE, as you can see: as n approaches infinity, SE approaches 0. You could make any two averages significantly different from each other with a large enough sample size, simply because you are dividing by a smaller and smaller number. Intuitively, I don' think there is any difference. Suggestion 1 : I don't think this addresses the problem I am getting at. When doing a Z-test, we would be using standard deviation, but with a t-test, or in this case, we divide by n. This doesn't make sense to me, we should inherently have a larger SE with a sample than compared to a population because we don't have as many data points. Edit: for those asking for the formula from the website. If the Z-statistic is less than 2, the two samples are the same. If the Z-statistic is between 2.0 and 2.5, the two samples are marginally different If the Z-statistic is between 2.5 and 3.0, the two samples are significantly different If the Z-statistic is more then 3.0, the two samples are highly signficantly different $$ Z = \frac{\bar{X_1}-\bar{X_2}}{\sqrt{\sigma^{2}_{x_1}+\sigma^{2}_{x_2}}} $$ Edit: To further clarify, below is a histogram of my tests. How can we possibly look at these two distributions and say that they are significantly different? Especially when, I only have 25 samples for one!
