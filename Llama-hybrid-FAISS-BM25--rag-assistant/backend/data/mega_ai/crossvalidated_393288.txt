[site]: crossvalidated
[post_id]: 393288
[parent_id]: 
[tags]: 
Learning useful semantic representations of data

Training a neural network on its final task (e.g. classification) right from the beginning is not always the best way to go. I'd like to make a short list of recognized methods of motivating a NN to learn useful representations of data. This is in my opinion closely related to preventing shortcuts in learning ("person A is the one with ear piercing"). Siamese and Triplet Networks Autoencoders self-supervised learning with interesting synthetic target and loss matching high-res small patches of pictures with low-res whole pictures solving jigsaw puzzles (everything from keras blog so far) Confusing Domains What else?
