[site]: datascience
[post_id]: 41407
[parent_id]: 
[tags]: 
Sentiment Analysis Naive Bayes vs Logistic Regression

I am doing some sentiment analysis on Twitter data, and I wanted to compare a Naive Bayes Classifier and a Logistic Regression classifier as to if their performance is affected by spell checking the data. Feature extractor is a simple bag of words, and the spelling correction algorithm is an edit distance python package. Now for Logistic Regression, after spell checking, the accuracy drops by 1% and the False Positives and False negatives numbers are raised by around 20. I expected the same performance from Naive Bayes, thinking that it might have to do with the training step, where probably some words are mis-corrected and the testing phase is affected. But it actually got a better percentage by 2% and more True positives and True negatives (but also more False Negatives). Is the nature of the algorithms(generative/ discriminative) the reason behind it? Or is it something I am missing, because I can't wrap my head around it at the moment. (they both use the same training and test data, the same pre-processing procedure and the same spelling correction algorithm). Thanks for any help!! a (total) noob.
