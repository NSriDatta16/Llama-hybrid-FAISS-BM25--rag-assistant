[site]: crossvalidated
[post_id]: 637230
[parent_id]: 637217
[tags]: 
Let $a_j$ be the probability of predicting the class $j$ . Generically this is a sum $$a_j = \sum_i P(j|i) p_i$$ where $p_i$ is the probability of producing the class $i$ in the sample. For the case of null predictive power, $$a_j=P(j|*) \sum_i p_i= P(j|*)$$ So the elements in the $i,j$ entry of the confusion matrix, that usually are $P(j|i)p_i$ , can be written in this case as just $a_j p_i$ . For such matrix it is elementary to prove that the values of precision and reall for a class $k$ are respectively $$Precision(k)=p_k$$ and $$Recall(k)=a_k$$ The total precision and total recall will be 1, the averaged precision and recall will be $1/n$ , and the weighted averages will be $\sum_k p_k^2$ and $\sum_k p_k a_k$ respectively. Usually if one finds a pure random class label where nothing can be predicted except the distribution of probability, the best approach is to predict always argmax( $[p_0 .. p_n]$ ). Then recall is 1 for the max value and the weigthed average recall is the best one you can get. But other metrics are not so easy to optimize. For instance consider F1, you would get $$ F1(k) = {2 p_k a_k \over p_k + a_k} $$ And the weigthed average $$ \bar{F1} =2 \sum_k {p_k^2 a_k \over p_k + a_k} $$
