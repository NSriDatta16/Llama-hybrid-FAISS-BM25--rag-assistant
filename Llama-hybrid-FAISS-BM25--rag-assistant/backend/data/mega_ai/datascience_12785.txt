[site]: datascience
[post_id]: 12785
[parent_id]: 
[tags]: 
How would one use a network trained on CIFAR-10 to find things in a photo?

There are a million and one examples and tutorials on how to train up a neural network on the sample sets like the MNIST data and the CIFAR-10 data, but how does one go from the toy examples of recognising 200x200 clips each containing a single centred object to a real problem like finding CIFAR-10 category objects (the dog and the cat below) within a picture, like I presume Google does for their photo annotation. Can someone describe how one might approach this leap from the classroom to the real world?
