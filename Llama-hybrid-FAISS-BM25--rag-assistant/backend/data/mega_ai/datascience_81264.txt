[site]: datascience
[post_id]: 81264
[parent_id]: 81247
[tags]: 
This kind of problem can be modelled in two different ways, which I call time-of-event and time-to-event. The first is what you have tried out so far, and illustrated in your picture. Time-of-event Feed in the entire time-series, and use as target the time of the event. Target can be encoded as the second from start of series, a percentage of the duration of entire series etc. Advantages: Simple. Standard regression setup. Disadvantages: Time-series might be very long, difficult for model to learn. Few instances in training set. 1 per time series. Single prediction for one whole series, no distribution of values Time-to-event Divide the time-series into multiple overlapping analysis windows. For each window, compute the distance (in time) to the event of interest, and use this as the target. The target can be expressed in seconds, or number of time-steps. Note that it may be positive (in future, relative to window) or negative (in the past, relative to the window). At training time, the simplest setup is to treat each such analysis-window,time-target pair is treated as independent instances. At prediction time each individual analysis window then passed through the model. Prediction for each individual window then has to be aggregated to give a single prediction. In the simplest case this can be just the mean or median. More advanced cases would for example weight predictions based on their time. Advantages: Multiplies the number of training instances in dataset Model input has lower data complexity. Since only seeing section of time Can get predictions in real-time/streaming fashion Get multiple predictions, forming a kind of distribution Disadvantages Adds another function block, aggregating of windowed predictions into a single prediction Adds additional hyper-parameters. Window length, overlap, aggregation method Overlap means that model runs many times on each data point. Might increase compute time for predictions The window length can be quite short relative to entire time series. Ex a 15 minute series with 60 second windows using 5 second forwarding between each window (91.66% overlap). That would give 15min*60s/5s = 180 instances per series. Or the window length can be quite close to the entire time series. Ex a 15 minute series with 10 minute windows and 1 minute forwarding between each window (90% overlap). Giving 15min/1min = 15 instances per series. What works best here is highly problem and data dependent. The use of multiple analysis windows like this is effectively a data augmentation technique (time-shift). Since it is applied also at prediction time, it is also an example of Test-Time Augmentation (TTA). Models I would always recommend starting with a non-time series model as a baseline. Summarize the features inside each window (mean,std,(max-min) of each variable), and use Linear Regression, Random Forest to see how it performs. This gives an indication of the complexity of the problem. And is super-fast to do some initial hyper-parameters scans on (for example on window length). And you should plot these features/predictions as part of Exploratory Data Analysis / Error Analysis! After that I would try a simple LSTM / GRU model, or maybe a 1D CNN.
