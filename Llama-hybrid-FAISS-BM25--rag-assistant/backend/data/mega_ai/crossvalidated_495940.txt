[site]: crossvalidated
[post_id]: 495940
[parent_id]: 495921
[tags]: 
You can do the regression the same way as you do the classification. You have some input features (either hand-crafted: n -grams, word frequencies; or from a neural network) and then, instead of a classifier, you do regression. By that I mean, that you do a linear projection into a scalar and compute the loss as a mean square error and propagate it back to the model (or update the model in a different way if it is not a neural network). Sometimes, it is better to cast the problem as a classification problem (presumably because classification provides stronger training signal than regression). In that case, you can split the target values into several bucketsâ€”some reasonable intervals that evenly cover the target values. You can then either take the most probable interval or estimate the target values as an expected value from the model: $\sum_I p_I c_I$ where $c_I$ is the center of the interval $I$ and $p_I$ is the probability assigned to interval $I$ by the model.
