[site]: crossvalidated
[post_id]: 463885
[parent_id]: 463783
[tags]: 
This is a fairly common problem for Bayesian statistics where the posterior distribution $$p(\theta|x)=\dfrac{f(x|\theta)\pi(\theta)}{\int_\Theta > f(x|\theta)\pi(\theta)\,\text{d}\theta}=\dfrac{f(x|\theta)\pi(\theta)}{m(x)}$$ most often involves an intractable normalising constant $m(x)$ . One of my answers to earlier questions on that topic lists a range of solutions, based on simulation. A book-length entry is found in Chen, Shao and Ibrahim (2001) . Reverting to the question and its notations, i f the only available material is provided by the sample $$\mathfrak S = \{x_i\}_{i=1}^n \sim \xi$$ with no further access to simulation , contrary to the previous answer , a range of solutions can be found by a reverse version of the importance sampling method, namely that, for any density function $\alpha(\cdot)$ [with the same support as $f(\cdot)$ , at most], the following general identity holds: $$\mathbb{E}_\xi\left[\frac{\alpha(X)}{f(X)}\right]=\int_{\mathfrak X} \dfrac{\alpha(x)}{f(x)}\,\xi(x)\,\text{d}x=\int_{\mathfrak X} \dfrac{\alpha(x)}{f(x)}\dfrac{f(x)}{c}\,\text{d}x=\int_{\mathfrak X} \dfrac{\alpha(x)}{c}\,\text{d}x=\frac{1}{c}$$ Therefore, the estimate $$\frac{1}{n}\sum_{i=1}^n \dfrac{\alpha(x_i)}{f(x_i)}\qquad x_i\sim\xi(x)$$ is an unbiased and convergent estimator of $1/c$ , whatever $\alpha(\cdot)$ is. The only caution in choosing this $\alpha(\cdot)$ density is to ensure that the estimator has a finite variance, for otherwise the outcome is completely untrustworthy .
