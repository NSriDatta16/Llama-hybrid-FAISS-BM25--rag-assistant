[site]: crossvalidated
[post_id]: 450049
[parent_id]: 
[tags]: 
What does it mean to predict "with a constant" in a decision tree?

I'm new to this exchange and ML. Below is a snippet (hopefully it's enough context) from The Elements of Statistical Learning by Hastie, Tibshirani, Friedman: We first split the space into two regions, and model the response by the mean of $Y$ in each region. We choose the variable and split-point to achieve the best fit. Then one or both of these regions are split into two more regions, and this process is continued, until some stopping rule is applied. For example, in the top right panel of Figure 9.2, we first split at $X_1 = t_1$ . Then the region $X_1 â‰¤ t_1$ is split at $X_2 = t_2$ and the region $X_1 > t_1$ is split at $X_1 = t_3$ . Finally, the region $X_1 > t_3$ is split at $X_2 = t_4$ . The result of this process is a partition into the five regions $R_1,R_2, . . . ,R_5$ shown in the figure. The corresponding regression model predicts $Y$ with a constant $c_m$ in region $R_m$ , that is, $$ \hat{f}(X)=\sum_{}^{} c_m I\{(X_1, X_2) \in R_m \} $$ As far as I can tell, $I\{ \}$ was not defined in any of the sentences or sections above, so being new to ML as well, I don't get what that function is. Also, what does "predict Y with a constant" mean? Please explain at an intro level; I've just began ML and our course goes ridiculously fast so despite the notation, I don't really know what's going on. For now I'm assuming $I$ is what we call the binary function, where it's 1 if true and 0 if false but then I'm not sure what it means for $(X_1,X_2)$ to be in $R_m$
