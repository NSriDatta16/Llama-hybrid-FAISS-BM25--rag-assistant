[site]: crossvalidated
[post_id]: 348380
[parent_id]: 
[tags]: 
R/Stata Can I include a categorical variable in a Logistic regression when one of its values perfectly predicts one of the outcomes?

Suppose I have the following data df = data.table('y'= c(1,1,1,1,1,1,1,0,0,0,0), 'x' = c(1,1,1,1,1,1,1,1,1,0,0)) where x = 0 perfectly predicts y = 0. I thought this means that I can't include x as a regressor, but R apparently has no problem with this logitcontrol = list(maxit = 100) logitmodel But Stata would drop the last two observations because x==0 perfectly predicts y==0, and then it would drop x because all that's left is x==1. Intuitively, I think Stata's solution makes sense, but how come R doesn't have a problem producing a result in this case? Also, in general, does it make mathematical sense to include a variable like x where one of the values of x perfectly predicts a value of the dependent variable? My intuition is 'no', but I'm not sure... BTW, it doesn't make a difference if I add in another regressor say z.
