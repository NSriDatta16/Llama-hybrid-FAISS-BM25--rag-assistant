[site]: crossvalidated
[post_id]: 521529
[parent_id]: 379879
[tags]: 
In theory, RF can approximate arbitrary functions that involve multiple input features using branches in the trees it builds. However, with limited training data (always the case in practice), it can matter a lot how conveniently the data are set-up for RF. I.e. it's ideal if it needs to only make a few cuts along as few dimensions as possible. See e.g. this answer to another question (it was about tree boosting, but the same answer applies to RF). Another thing that usually gains you a lot is representing high-cardinality categorical features well (e.g. using embeddings or target encoding) - RF is not really good at dealing with categorical features with many levels (if you just one-hot-encode them). I.e. in practice you will want to pre-processing and feature engineering, and would expect it to improve RF performance. How much it helps depends on how good the un-processed data were as features to start off with vs. how much it can be improved.
