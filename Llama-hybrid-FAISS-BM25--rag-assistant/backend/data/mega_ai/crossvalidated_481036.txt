[site]: crossvalidated
[post_id]: 481036
[parent_id]: 481033
[tags]: 
If you have the prior distribution $\mathsf{Beta}(\alpha_0, \beta_0)$ for Success probability $\theta$ and binomial likelihood $\theta^x(1-\theta)^{n-x},$ corresponding to $x$ Successes in $n$ Bernoulli trials, then by Bayes' Theorem you have the posterior distribution is $\mathsf{Beta}(\alpha_n = \alpha_0 + x,\; \beta_n = \beta_0 + n - x),$ which has posterior mean $E(\theta) = \frac{\alpha_n}{\alpha_n+\beta_n}.$ According to Bayes' Theorem, POSTERIOR = PRIOR $\times$ LIKELIHOOD: $$h(\theta|x) = f(\theta) \times g(x|\theta)\propto\theta^{\alpha_n+1}(1-\theta)^{\beta_n+1}$$ $$\propto \theta^{\alpha_0+1}(1-\theta)^{\beta_0+1} \times \theta^x(1-\theta)^{n-x},$$ where $\propto$ (read as "proportional to") acknowledges that we have omitted normalization constants to write 'kernels' of densities instead of densities. We recognize $\theta^{\alpha_n+1}(1-\theta)^{\beta_n+1}$ as the kernel of $\mathsf{Beta}(\alpha_n,\beta_n).$ If I understand your data correctly, you observed $x = 447$ days of use out of $n = 700.$ Also, it seems you are to assume that car use is equally likely on all days, that days of use are independent within any one subject, and that subjects use cars independently of one another. These assumptions are required if we are to have 700 independent trials, each with the same Success probability $\theta.$ d = 0:7; f=c(1,5,3,15,20,25,31,0); sum(d*f) [1] 447 So if you begin with a flat prior $\mathsf{Unif}(0,1)\equiv\mathsf{Beta}(1,1),$ then your posterior distribution is $\mathsf{Beta}(448,554).$ Your posterior mean is $E(\theta) = \frac{448}{1002}$ and a 95% Bayesian posterior probability interval ('credible' interval) for $\theta$ is $(0.416, 0.478).$ qbeta(c(.025, .975), 448, 554) [1] 0.4164427 0.4779689 Note: For various theoretical and technical reasons, some Bayesian statisticians prefer to use the Jeffries prior $\mathsf{Beta}(.5,.5)$ as a non-informative prior distribution, instead of the uniform prior $\mathsf{Beta}(1,1).$
