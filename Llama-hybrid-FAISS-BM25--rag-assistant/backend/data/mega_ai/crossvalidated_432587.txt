[site]: crossvalidated
[post_id]: 432587
[parent_id]: 417194
[tags]: 
Confidence intervals are frequentists tools. From a frequentist point of view, there is no such thing as confidence on the parameter. There is only one true parameter $\lambda$ which specifies your random process. This random process generates a sequence of data. Frequentists say that in other realities, the same process has generated different sequences of data. You can weight each reality with a probability. Then, you can add the weights of "realities" which have the same average. It gives you the probability of an average, i.e. the weight of realities which have this average. The CLT tells you that the probability distribution over these averages of sequences tends to be a gaussian with a mean equals to the mean of your random process and a shriking variance as the size of the sequence grows. Confidence Intervals are tools for finite sequences. Yet, with the CLT, we understand that your $P\left(X_{\mathrm{obs}} ; \lambda\right) \geq \alpha$ does not make sense : the probability that a (almost) gaussian to take one specific value is (almost) zero. A finite probability $\alpha$ (or $1-\alpha$ ) can only be obtained by considering an interval of value. Hence, CIs weight the realities which have an average which deviates by a certain quantity from the mean of your distribution. This is why we have $P\left(x \leq X_{\mathrm{obs}} ; \lambda\right) \geq \alpha$ . For poisson process, the mean is your parameter $\lambda$ . The average is an empirical estimate of this $\lambda$ . CIs quantify how likely is the deviation between the two. CIs involve the size of the sample $N$ , the probability threshold $1 - \alpha$ , and the deviation $\Delta = \hat{\lambda} - \lambda$ . For a given probability $1 - \alpha$ and a sample size $N$ , you can find the corresponding ""maximal"" deviation (e.g. in the link I sent you). In fine, it meant : "there is a fraction $1-\alpha$ of "realities" for which the empirical mean is at most at a $\Delta$ distance of the true parameter $\lambda$ . Hence, there is no maximum on parameter (again, there is only one parameter) in confidence intervals. I think you may be interested by Credible Intervals which is the Bayesian equivalent (there is only one reality with true data, and multiple more or less credible generating processes). The two are often very similar in shape but differs in nature/ philosophical perspective.
