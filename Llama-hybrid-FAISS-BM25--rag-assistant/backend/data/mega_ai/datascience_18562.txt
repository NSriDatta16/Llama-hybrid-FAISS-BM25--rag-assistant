[site]: datascience
[post_id]: 18562
[parent_id]: 
[tags]: 
Does the input data representation matter while training CNN for speech recognition?

I am currently doing pattern recognition on spectograms of audio files using convolutional neural networks. The spectograms are made using matplotlib cm.jet colormaps. Problem with this color map is that it auto ranges its colors based on the min and max value of the input it is given. so an example: Spectrograms of two different version of audio file. One with static filter output, and the other with delta filter outputs. RGB values show no difference in ranges for both delta and normal, but the db, scale shows a big difference. My input consist of one column of the static and one column of delta, or a matrix (40,2,3), but since these ranges are very different kinda make me suspect that this would not work very well. Am I right or wrong?
