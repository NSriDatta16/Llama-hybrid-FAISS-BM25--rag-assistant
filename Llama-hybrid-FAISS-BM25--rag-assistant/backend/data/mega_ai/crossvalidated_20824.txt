[site]: crossvalidated
[post_id]: 20824
[parent_id]: 20786
[tags]: 
Yes, compressed sensing can be used for data mining when the data are sparse. For example, see Calderbank et al. Compressed Learning . The intuition is that if the data are sparse then one can perfectly reconstruct the data w.h.p from its randomly projected representation, provided that the projection dimension, $k$, satisfies $k \in \mathcal{O}(\|\Phi(x)\|_0 \text{log}\ d)$, where $d$ is the data dimension, and $\|\Phi(x)\|_0$ is the number of non-zero entries in the sparse representation of the data. It follows that w.h.p no information was lost by carrying out the random projection. However, one can do much better. For example, classification is a considerably simpler task than perfect signal reconstruction and so one can give guarantees for randomly projected classifiers with no sparsity requirement on the data and which require only that the projection dimension is logarithmic in the number of classes. For example, see our KDD paper from 2010: Durrant and Kaban. Compressed Fisher Linear Discriminant Analysis . It is also not necessary for data to be sparse in order to carry out regression in the randomly projected domain, for example see this NIPS 2009 paper: Mailard and Munos. Compressed Least-Squares Regression There is quite a sizeable literature on machine learning with randomly projected data and on compressed learning. Chasing down the references in the papers I've cited above should give you a good start if you want to look deeper.
