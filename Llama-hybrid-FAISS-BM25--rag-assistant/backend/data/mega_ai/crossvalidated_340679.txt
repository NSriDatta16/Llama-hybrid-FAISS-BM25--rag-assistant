[site]: crossvalidated
[post_id]: 340679
[parent_id]: 340355
[tags]: 
The importance of a feature-variable depends on the distributiuon of all the other feature-variables used, for the classification problem at hand. Generally, when changing a feature-value $x_i$ can cause the pattern or feature vector ${\bf {\it x}}$ to become assigned a different class label, then that feature-value is of importance: Feature-value $x_i$ is said to have potential influence for the classification of feature vector ${\bf {\it x}}$. Feature-values that have potential influence for a large number of (different) pattern vectors, they are important ones for the classification task at hand. A wrapper-approach to feature assessment involves removing each feature-variable, one-by-one, and compute the resulting decrease in classification performance. Hence, with $n$ feature variables, you need to train $n$ different classifiers, each with one less feature (basically, a 'leave-one-out' approach). See the analysis of this problem in: [M. Egmont-Petersen, J.L. Talmon, A. Hasman, A.W. Ambergen. "Assessing the importance of features for multi-layer perceptrons," Neural Networks, Vol. 11, No. 4, pp. 623-635, 1998].
