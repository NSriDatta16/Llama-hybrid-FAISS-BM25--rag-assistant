[site]: crossvalidated
[post_id]: 560794
[parent_id]: 560769
[tags]: 
$P(y|x, w)$ is not the model likelihood. it is a point wise prediction. In logistic regression it is the sigmoid over the logits $wx +b$ . if $p_i = P(y_i|x_i, w)$ Then the likelihood of this single point is: $p_i^{y_i} * (1-p_i)^{1-y_i}$ $P(D|w)$ is a notation for the model likelihood for the entire dataset. In the logistic regression setup we usually use log loss or cross entropy which is the negative log likelihood, which is basically the sum of the log likelihood of each point (i.e. sum over $log(p_i^{y_i} * (1-p_i)^{1-y_i})$ )
