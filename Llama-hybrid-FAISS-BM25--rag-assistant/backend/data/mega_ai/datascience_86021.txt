[site]: datascience
[post_id]: 86021
[parent_id]: 19346
[tags]: 
It is the layer weights that are learnt. Layer weights will be the same for all sentences. So every sentence is 'transformed' using these hardcoded weights to give out a single word context which best represents the meaning of that entire sentence. If you think of it that way, then in every NN, the layer weights are hardcoded, nonetheless they do a good job of transforming different values of input This does not mean that the output word representing the sentence is the same for all sentences. Second point - the context vector here is slightly different from the context vector we associate with Attention mechanism (weighted sum of all states). The semantics are slightly different Lastly - Yes it is possible that this way to determine 'context' is not the most optimum way. Nonetheless when the paper came out it did present a refreshing point of view. More importantly the paper was not much about attention in itself - but more about classification of large corpus of documents using Attention
