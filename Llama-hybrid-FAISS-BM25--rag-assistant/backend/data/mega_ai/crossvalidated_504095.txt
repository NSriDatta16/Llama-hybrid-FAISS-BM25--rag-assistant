[site]: crossvalidated
[post_id]: 504095
[parent_id]: 504062
[tags]: 
Not necessarily. These parameters control how "complex" or "overfit" the model can be. If your model is too simple or too complex , misclassification will increase. There is some sweet spot of parameters for your data and problem, which you should try to find experimentally by measuring misclassification rate on a holdout set (a random sample of your data that is excluded from the SVM). This article has nice visualizations for an RBF SVM showing what an underfit or overfit model looks like, but the concept is similar for any kernel. (I think sigma works opposite from gamma, where a bigger sigma regularizes, i.e., makes the model less complex).
