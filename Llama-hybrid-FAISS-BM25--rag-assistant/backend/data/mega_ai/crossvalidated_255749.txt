[site]: crossvalidated
[post_id]: 255749
[parent_id]: 
[tags]: 
How can I compute the expected value of the mean of a subset of one variable given the mean of a subset of another variable in a correlated dataset?

I have a dataset with three variables: "Category", "X", and "Y". "Category" can be one of 5 different values: say A, B, C, D, E. I know that X and Y are correlated (say their correlation coefficient is 0.4). I can compute mean(X) , mean(Y) for the entire data set, as well as mean(X | Category = A) , mean(X | Category = B) , etc. Say I have a situation as follows: mean(X) = 0.7 mean(Y) = 0.8 mean(X | Category=A) = 0.5 mean(Y | Category=A) = 0.65 Now clearly, the average X and Y are both lower in the "A" category. What I'd like to know is, assuming that Y influences X (via their correlation), how much better/worse is the X in category A, given that the Y is on average worse as well ? Intuitively, if I see the following: mean(X) = 0.7 mean(Y) = 0.8 mean(X | Category=A) = 0.5 mean(Y | Category=A) = 0.5 Then I could say that X is better in the subset of category A, because given the lower Y value, I would expect the X to be lower as well, but it is in fact higher. Similarly, given: mean(X) = 0.7 mean(Y) = 0.8 mean(X | Category=A) = 0.65 mean(Y | Category=A) = 0.8 I could intuitively say the X is worse by comparison, because the expected mean is 0.7 yet the actual mean was 0.65. How do I quantify this? I suspect the correlation may be enough, but I am unsure how to proceed. In other words, I want to know how to compute something like: What would the expected mean(X | category=A) be given that the mean(Y) is v, the mean(Y | Category=A) is w, and assuming that X | category=A has the same distribution/"behavior"/relation to Y as X itself? My earlier question is an attempt to figure out a tool I could use do this, but I'm not sure if it's the right approach.
