[site]: crossvalidated
[post_id]: 416164
[parent_id]: 
[tags]: 
Integrate out (covariance) matrix in Normal-Wishart distribution

In Gelman's Bayesian Data Analysis Chapter 3.6, he introduces the multivariate normal with unknown mean and variance, with the priors $\Sigma\sim \text{Inv-Wishart}_{\nu_0}(\Lambda_0^{-1})$ $\mu\rvert \Sigma \sim N(\mu_0, \Sigma/\kappa_0)$ and the joint prior $p(\mu, \Sigma)\propto \lvert \Sigma\rvert^{-((\nu_0+d)/2+1)}\exp\Big(-\frac{1}{2}\text{tr}(\Lambda_0\Sigma^{-1})-\frac{\kappa_0}{2}(\mu-\mu_0)'\Sigma^{-1}(\mu-\mu_0)\Big)$ Gelman then states that the (posterior) marginal is multivariate $t$ without elaboration. In a paper that I found (A Bayes Approach for Combining Correlated Estimates - Seymour Geisser), Geisser had the following steps, also without elaboration (notations, parameterisation and context are different from Gelman, but a similar integration step is involved). $p(\mu, \Sigma^{-1})\propto \Big\lvert \Sigma^{-1}\Big\rvert ^{(n-d-1)/2}\exp\Big(-\frac{1}{2}\text{tr}\Big(\Sigma^{-1}\sum_{j=1}^n (\mathbf{x}_j-\mu\mathbf{e})(\mathbf{x}_j-\mu\mathbf{e})'\Big)\Big)$ Integrating out $\Sigma^{-1}$ yields $p(\mu)\propto \Big\lvert \sum_{j=1}^n(\mathbf{x}_j-\mu\mathbf{e})(\mathbf{x}_j-\mu\mathbf{e})'\Big\rvert ^{-n/2}$ The result can be further massaged to yield the $t$ density, but my question is specifically on the integration step only. The result $p(\mu)$ looks simple but I'm not sure how it's carried out. Question: How do I obtain the marginal distribution of $p(\mu)$ by integrating out $\Sigma$ ? Any references to similar matrix integrations will be great. Thank you in advance!
