[site]: crossvalidated
[post_id]: 233694
[parent_id]: 233581
[tags]: 
Note that you have a sample, i.e. the data, and you want to find the credibility of an unknown parameter, below I explain a special kind of MC nemely MCMC, markov Chain Monte Carlo. Maybe it's good to make the notation a bit more explicit, and for simplicity take the one-dimensional case (this is only for simplicity, it also works in the multi-dimensional case). You say that your likelihood is Gaussian just as well as your prior. If we take the one-dimensional case then our goal it to estimate one parameter, e.g. the unkown mean $\mu$. The posterior is then $P(\mu|_D) \propto P(D|_\mu) p(\mu)$ Now in MCMC (Monte Carlo Markov Chain), you start from an initial value $\mu=x_1$ and make a proposal move $x_2$, in order to decide whether the proposal will be accepted, you should evaluate the posterior at $x_1$ and at $x_2$. So you have to compute $ P(D|_\mu=x_1) p(\mu=x_1)$ (and the same for $x_2$). The prior is known (you have chosen it yourself), so you can evaluate it at $x_1$. The likelihood $P(D|_\mu=x_1)$ at $x_1$ is also knwown ; you know it is gaussian and (in the one dimensional case) only the mean is unknown but you say that you want to evaluate it at $\mu=x_1$ so you have the mean and you can compute the value for $P(D|_\mu=x_1)$ (the data $D$ is also known of course). Similar for $X_2$. So it is the 'Gaussian formula'' where you plug in $\mu=x_1$ and $X=D$ ($\sigma$ is known because we assumed the one dimensional case for simplicity, so only one parameter, $\mu$ is unknown, but you evaluate at $\mu=x_1$, so that's solved). So we can compute (up to a constant) $\pi_1=P(\mu=x_1|_D)$ and $\pi_2=P(\mu=x_2|_D)$. Remember that $x_2$ was only a proposal move. This proposal is accepted if $\pi_2$ > $\pi_1$ , if $\pi_2 \le \pi_1$ then the move is accepted with a probablity $\frac{\pi_2}{\pi_1}$ (P.S. a symmetric transition kernel is assumed). If the move is accepted then move to $x_2$ else stay at $x_1$ and next generate the next proposal, ... This algorithm is constructed such that the so-called ''balance equations'' are fulfilled, and that is suffcient for the chain to converge to the posterior ''in the end''. Summary: if you can't sample from the posterior directly, then construct a markov chain that has the posterior as limiting distribution and use this Markov chain to ' walk to' that limiting distribution. The algorithm supra defines such a markov chain using a special case of the Metropolis-Hastings procedure. [[Note, if your data is a sample with multiple elements, then you take a product of likelihoods, assuming independence). ]]
