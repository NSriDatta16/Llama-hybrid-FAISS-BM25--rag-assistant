[site]: crossvalidated
[post_id]: 312143
[parent_id]: 312132
[tags]: 
I concluded that this is a case of high bias (underfitting). This can be checked. Suppose you train your dataset on increasing-sized chunks of your data, and test on some fixed-sized chunk you left out, then plot the train and test errors as a plot of the size of the train chunks. High bias will appear as the error decreasing to some level and staying there. High variance might appear as a large gap between the train and test errors. If this indeed looks like high bias, you could try random forests, for example, which might find interaction patterns between the features (binary or otherwise). You might find XGBoost , in particular, convenient for use.
