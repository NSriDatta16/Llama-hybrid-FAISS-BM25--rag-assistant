[site]: datascience
[post_id]: 73498
[parent_id]: 
[tags]: 
why does Scikit Learn's Power Transform always transform the data to zero standard deviation?

all of my input features are positive. Whenever I tried to apply PowerTransformer with box-cox method, the lambdas are s.t. the transformed values have zero variance. i.e. the features become constants I even tried with randomly generated log normal data and it still transform the data into zero variance. I do understand that mathematically, finding the lambda s.t. the standard deviation is the smallest, would mean the distribution would be the most normal-like. But when the standard deviation is zero, then what's the point of using it? p.s. so one of the values of lambda I get by using PowerTranformer is -4.78 If you apply it into the box-cox equation for lambda != 0.0, then for any input feature y values, you technically get the same values. i.e. (100^(-4.78)-1.0)/(-4.78) is technically equals to (500^(-4.78)-1.0)/(-4.78)
