[site]: crossvalidated
[post_id]: 192633
[parent_id]: 181264
[tags]: 
Since the weights are not initialized properly and groups of neurons end up in the same local minima, according to their (similar) initialization. To overcome this, you could use dropout / drop connect to break symmetry. Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. R. (2012). Improving neural networks by preventing co-adaptation of feature detectors.
