[site]: crossvalidated
[post_id]: 506220
[parent_id]: 505696
[tags]: 
Have you run your model on a simple dataset like MNIST to verify it's implemented correctly? In an WGAN-GP, the generator loss is typically not meaningful, and the discriminator loss is an approximation of the negative wasserstein distance between the generator distribution and real distribution. Of course, this only works if the discriminator is powerful enough, and you train it enough (usually several iterations per generator iteration). Otherwise, the discriminator loss is pretty meaningless. When it's working properly, the discriminator loss should start from 0, rapidly drop to some negative number, and then slowly work it's way back to 0, (which means the generator and true distribution are getting closer).
