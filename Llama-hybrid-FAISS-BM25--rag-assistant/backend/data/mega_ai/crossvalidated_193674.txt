[site]: crossvalidated
[post_id]: 193674
[parent_id]: 
[tags]: 
How to build a decision tree with a constraint on sensitivity?

I am trying to develop a classification model on a sample of people which will discriminate between "Type A" and "Not-Type A" people. Due to external factors, the minimum sensitivity for this classification--that is, the minimum probability that person will be classified as Type A given that they actually are Type A--must be greater than or equal to 95%. Given these constraints, I already performed an ROC analysis by fitting my class variable on the available covariates using logistic regression, subsequently using the predicted probabilities as a classifier (i.e.: p-hat>=threshold means "type A", otherwise "Not-Type-A"). The ROC curve from this method looks roughly like this: Basically, my discrimination function works very, very well for high specificity and (relatively) low sensitivity, but performance (i.e., the distance between the ROC curve and the diagonal line) becomes progressively worse as one moves to other extreme of high sensitivity/low specificity. Initially, this was OK because in an ROC analysis, I can take the point that performs "best" between [0.95,1] sensitivity and use the corresponding threshold for the predicted probabilities to classify my sample--the discriminant isn't optimal, but it's as optimal as it can be given my constraints. The problem is, my end user doesn't want to use the logit formula to calculate predicted probabilities and compare that to a threshold. They need to be able to discriminate classes "in the field" without using a calculator, so they want a decision tree instead. I can build a decision tree with recursive partition methods. The results are uncannily similar to what they would be if I was able to use the "optimal" point in the ROC curve--if you average up the mis-classification rates in the terminal nodes, the decision tree results in a specificity of 97.6%, and a sensitivity of 49.5%. However, I don't need a perfectly optimal classifier, I need a classifier that's as optimal as possible given a required sensitivity greater than 95%. I have no idea how to modify the recursive partitioning algorithm to apply this constraint, and I can't find any literature on the subject. Is it even possible? Is there some other method for constructing a decision tree that will converge on a tree with the required sensitivity?
