[site]: crossvalidated
[post_id]: 617154
[parent_id]: 616872
[tags]: 
Ultimately, if you have the same reasonably large number of events and the underlying parametric model is adequate, the distribution of coefficient estimates from repeated sampling of the underlying distribution should be close to the multivariate normal distribution from the original fit. There's no need to put this in the $\log T = \alpha + W$ accelerated failure time format. Once you have fixed shape and rate parameters in the form expected by pgamma() and rgamma() , just sample directly from rgamma() for event-time simulations. With your shape and rate values from the fit to the lung data set, to mimic the 165 events in that data set and overlay onto the Kaplan-Meier curve: plot(survfit(Surv(time, status) ~ 1, data = lung)) newGammaData Repeat the last 3 lines as often as you'd like. To compare against the variability of coefficient estimates from the original model, sample from the bivariate normal distribution of the coefficients as they are reported by flexsurvreg() , exponentiate (as you do) to get values that are expected by pgamma() , then add lines as you show. Try the following: newCoef and repeat both code lines as often as you would like. Direct comparison of covariances among fits to simulated data and covariance matrix of coefficient estimates To illustrate how well the asymptotically bivariate normal distribution of coefficient estimates corresponds to what you find by multiple fits to data drawn from the modeled survival distribution, get the gamma fit to the original data (with 165 events), then combine fit results from 200 samples (of 165 uncensored simulated event times each) from the modeled gamma fit. ## fit lung data library(flexsurv) lungGammaFit That illustrates the first paragraph of the answer: the variability among fits to multiple samples from the gamma-distribution fit to the lung data is essentially what you would get from the original variance-covariance matrix of coefficient estimates, if the number of events is the same.
