[site]: datascience
[post_id]: 61383
[parent_id]: 54764
[tags]: 
In "Transformer model", during the training, all the predictions are computed in one step. That's one of its strength points. It is during inference that the target sentence is generated sequentially invoking a beam search (usually with a small beam width). During training (emphasizing on training) just use target word indexes as inputs to the decoder, you just need to trim the index of token from end of target sequence.
