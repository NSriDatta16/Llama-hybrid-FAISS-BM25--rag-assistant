[site]: crossvalidated
[post_id]: 323491
[parent_id]: 235413
[tags]: 
In layman's terms, the within variance is the variance within each dataset on the parameters being estimated, whereas the between variance is the variance across datasets in those parameters. In other words, what gets called the within variance in multiple imputation is just regular old error variance in analyses without multiple imputation (i.e. analyses on a single dataset). You can think of this as just the noise in your model. The between variance is how much your estimates change one imputation to another --- it's what gets added to your analysis by imputing more than one dataset. Toy example To illustrate, consider a simple dataset, where we want to run a linear regression where X1 and X2 predict Y. First, we generate the data: set.seed(24601) # generate random X1 and X2, and generate Y based on them X1 Here's the data (note the missing values present): > round(my_df, 2) Y X1 X2 1 0.56 -0.26 -0.58 2 0.08 0.58 -0.25 3 -1.31 0.47 NA 4 -0.51 NA -0.25 5 1.01 -0.27 1.33 6 0.22 NA -0.44 7 -0.54 0.26 NA 8 0.25 -0.26 -0.70 9 -0.38 -1.23 0.01 10 -0.83 NA NA Now we'll make three different datasets, each time imputing values in for the missing ones on X1 and X2. Because we'll used a probabilistic imputation (rather than a deterministic one), the values will be a little different for each dataset we impute. library(Amelia) # an R package for multiple imputation imputed_data If you look at the imputed datasets, you'll see they differ in value for the observations that were missing (output truncated for readability): > round(imputed_data$imputations$imp1, 2) Y X1 X2 1 0.56 -0.26 -0.58 2 0.08 0.58 -0.25 3 -1.31 0.47 -2.01 4 -0.51 -0.53 -0.25 ... > round(imputed_data$imputations$imp2, 2) Y X1 X2 1 0.56 -0.26 -0.58 2 0.08 0.58 -0.25 3 -1.31 0.47 -3.07 4 -0.51 0.10 -0.25 ... If we run the regression in each dataset, we'll get slightly different results because of those differences in the imputed values (output edited for readability): m1 summary(m1) ... Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 0.1897 0.2018 0.940 0.3784 X1 0.1427 0.3433 0.416 0.6901 X2 0.6809 0.2231 3.051 0.0185 * --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 0.4947 on 7 degrees of freedom Multiple R-squared: 0.606, Adjusted R-squared: 0.4935 F-statistic: 5.384 on 2 and 7 DF, p-value: 0.03839 > summary(m2) ... Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 0.2369 0.1814 1.306 0.2329 X1 0.1601 0.3293 0.486 0.6416 X2 0.4839 0.1399 3.460 0.0106 * --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 0.4548 on 7 degrees of freedom Multiple R-squared: 0.6671, Adjusted R-squared: 0.5719 F-statistic: 7.012 on 2 and 7 DF, p-value: 0.0213 > summary(m3) ... Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -0.1121 0.2386 -0.470 0.653 X1 -0.3529 0.4672 -0.755 0.475 X2 0.2467 0.4406 0.560 0.593 Residual standard error: 0.7348 on 7 degrees of freedom Multiple R-squared: 0.1308, Adjusted R-squared: -0.1176 F-statistic: 0.5266 on 2 and 7 DF, p-value: 0.6123 In the above results, you can see that each model has variance around its estimates (the standard errors for each regression coefficient). To get an estimate of the within variance for the effect of X1, you could average all of the SEs for X1 across the three models (and likewise for X2). To get an estimate of the between variance, you'd want to look at how much the coefficients for X1 and X2 vary across the three imputations. This is exactly what is often done to calculate SEs for multiple imputation[1]: You average the SEs from each of the datasets to get the "within" variance, and then measure the variability in the coefficients across datasets to get the "between" variance, and combine them together into a single estimate that reflects both the natural noise in the data and the uncertainty due to the "guessing" done to fill in missing data during the multiple imputation process. [1] more specifically, this is a brief description of Rubin's rules from his 1987 book Multiple Imputation for Nonresponse in Surveys )
