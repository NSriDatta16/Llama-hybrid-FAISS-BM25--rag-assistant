[site]: crossvalidated
[post_id]: 317904
[parent_id]: 317902
[tags]: 
This could really be answered by taking a course in Monte Carlo simulation, which goes into this topic in depth. Here's a good set of slides that cover common approaches to generating samples from specific distributions. There are also more complicated approaches like Markov Chain Monte Carlo and copula methods for very complicated distributions with dependence and other behavior. This is a well studied area that should not be hard to remedy, especially if you've been able to handle measure theory. This is simple stuff in comparison. Now, mathematically, why do these methods work? At their heart they depend on the ability to generate a sequence of real-valued numbers $X_i$ in the interval $[0,1]$ such that $$\lim_{n \to \infty} \frac{|\{i: X_i \in (a,b), i\leq n\}|}{n} = b-a$$ In addition, we demand that $|COV(X_i,X_j)| \approx 0, \forall i\neq j$ There are a ton more mathematically stringent tests that such sequences must pass to demonstrate statistical randomness (see here , and here ). "Random numbers" are actually *pseudo-*random numbers -- they are deterministically created but are statistically indistinguishable from iid observations from a uniform distribution (up to some enormous lag). Using the pseudo-random numbers, we can generate sequences of numbers in a range like $[0,1]$ and then use various transforms and algorithms to turn these into all the other types of random variables and processes we use. Why $[0,1]$? Well, as someone who knows measure theory, you know that $P(\Omega)=1, P(\emptyset)=0, 1\geq P(X|X\subset \Omega) \geq 0$, so drawing random samples on this range allows you to sample the probability measure's range.
