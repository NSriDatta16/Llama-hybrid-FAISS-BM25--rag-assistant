[site]: crossvalidated
[post_id]: 336390
[parent_id]: 125604
[tags]: 
I would also suggest looking at recurrent neural networks for their natural application to sequence data. Check out this tensorflow tutorial on machine translation for ideas about network specification: https://www.tensorflow.org/tutorials/seq2seq . Also this nice explanation on Long Shirt Term Memory (LSTM) RNNs: http://colah.github.io/posts/2015-08-Understanding-LSTMs/ . I'm not sure there is a "better" way to encode the data, but there are definitely more compressed ways, such as packing multiple binary variables into a byte. There is also chas game representation, and the related universal sequence mapping (USM) which encodes lengths of sequences into pairs of 32 or 64 bit floats or ints (essential just bit packing on the quaternary code), both of which have been used recently for NNs on DNA sequences.
