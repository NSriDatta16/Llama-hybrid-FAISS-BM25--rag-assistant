[site]: crossvalidated
[post_id]: 291542
[parent_id]: 
[tags]: 
Do we need shuffle the entries before training gbdt by xgboost?

For example, the first 10 samples are taken from patient 1, the next 8 samples are taken from patient 2 and the next 12 samples are taken from patient 3 etc... Using the samples as trainset within its original order will make our gbdt classification model's performance weaker ? Should we shuffle it before training ?
