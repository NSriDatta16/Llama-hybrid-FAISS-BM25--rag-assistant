[site]: crossvalidated
[post_id]: 29233
[parent_id]: 29201
[tags]: 
One thought is that you should've mentioned the regularity conditions for asymptotic normality of the estimates and the $\chi^2$ performance of the likelihood ratio test statistic. These conditions include, informally speaking, the true parameter being in the interior of the parameter space; the log-likelihood really affording Taylor series expansion; i.i.d. data; conditions to interchange some of the derivatives and the integrals/expectations (some sort of uniform boundedness); and such. See http://www.stat.unc.edu/postscript/rs/ISI89.pdf and http://www.jstor.org/stable/2346086 concerning violations of these conditions. (The simplest example is estimation when the support depends on the parameter value, e.g., $U[0,\theta]$. The MLE $\hat\theta_n=x_{(n)}$ is not asymptotically normal, and an estimator that has a greater asymptotic efficiency in terms of MSE can be constructed.) These are worthy papers to read if you are serious about statistical theory, and many courses on asymptotics do not really wander off far enough into this elephant's graveyard of ML elegance. Another thought is that may be they really did want you to mention both Wald and score tests. Buse (1982) provides a wonderful review of the relation between the three tests.
