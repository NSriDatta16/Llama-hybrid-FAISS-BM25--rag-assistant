[site]: crossvalidated
[post_id]: 493749
[parent_id]: 493738
[tags]: 
I will describe how a statistician interprets count data. With a tiny bit of practice you can do it, too. The basic analysis When cases arise randomly and independently, the times of their occurrences are reasonably accurately modeled with a Poisson process. This implies that the number of cases appearing in any predetermined interval has a Poisson distribution. The only thing we need to remember about that is that its variance equals its expectation. In less technical jargon, this means that the amount by which the value is likely to differ from the average (its standard error ) is proportional to the square root of the average. (See Why is the square root transformation recommended for count data? for an explanation and discussion of the square root and some related transformations of count data.) In practice, we estimate the average by using the observed value. Thus, The standard error of a count of independent events with equal expected rates of occurrence is the square root of the count. (Various modifications of this rule exist for really small counts, especially counts of zero, but that shouldn't be an issue in the present application.) In the case of Vatican City, a rate of 33,666 cases per million corresponds to $$\frac{33666}{10^6} \times 802 = 27$$ cases. The square root of $27$ is $5$ (we usually don't need to worry about additional significant figures for this kind of analysis, which is usually done mentally and approximately). Equivalently, this standard error is $\sqrt{27}$ cases out of $802$ people, equivalent to $6500$ per million. We are therefore justified in stating The Vatican City case rate is $33666\pm 6500$ per million. This shows how silly it is to quote five significant figures for the rate. It is better to acknowledge the large standard error by limiting the sig figs, as in The observed Vatican City case rate is $34000 \pm 6500$ per million. (Do not make the mistake of just taking the square root of the rate! In this example, the square root of 33,666 is only 183, which is far too small. For estimating standard errors square roots apply to counts, not rates. ) A good rule of thumb is to use one additional significant digit when reporting the standard error, as I did here (the case rate was rounded to the nearest thousand and its SE was rounded to the nearest 100). A slightly more nuanced analysis Cases are not independent: people catch them from other people and because human beings do not dart about the world like atoms in a vial of hot gas, cases occur in clusters. This violates the independence assumption. What really happens, then, is that the effective count should be somewhere between the number of cases and the number of distinct clusters. We cannot know the latter: but surely it is smaller (perhaps far smaller) than the number of cases. Thus, The square root rule gives a lower bound on the standard error when the events are (positively) correlated. You can sometimes estimate how to adjust the standard error. For instance, if you guess that cases occur in clusters of ten or so, then you should multiply the standard error by the square root of ten. Generally, The standard error of a count of positively correlated events is, very roughly, the square root of the count times the square root of a typical cluster size. This approximation arises by assuming all cases in a cluster are perfectly correlated and otherwise the cases in any two different clusters are independent. If we suspect the Vatican City cases are clustered, then in the most extreme case it is a single cluster: the count is $1,$ its square root is $1,$ and the standard error therefore is one whole cluster: namely, about $27$ people. If you want to be cautious about not exaggerating the reliability of the numbers, then, you might think of this Vatican City rate as being somewhere between just above zero and likely less than 70,000 per million ( $1\pm 1$ clusters of $27$ of out a population of $802$ ).
