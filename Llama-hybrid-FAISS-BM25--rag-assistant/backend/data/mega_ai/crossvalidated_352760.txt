[site]: crossvalidated
[post_id]: 352760
[parent_id]: 266267
[tags]: 
Late to the party, but here is my answer anyway, and it is "Yes", one should always be concerned about the collinearity, regardless of the model/method being linear or not, or the main task being prediction or classification. Assume a number of linearly correlated covariates/features present in the data set and Random Forest as the method. Obviously, random selection per node may pick only (or mostly) collinear features which may/will result in a poor split, and this can happen repeatedly, thus negatively affecting the performance. Now, the collinear features may be less informative of the outcome than the other (non-collinear) features and as such they should be considered for elimination from the feature set anyway. However, assume that the features are ranked high in the 'feature importance' list produced by RF. As such they would be kept in the data set unnecessarily increasing the dimensionality. So, in practice, I'd always, as an exploratory step (out of many related) check the pairwise association of the features, including linear correlation.
