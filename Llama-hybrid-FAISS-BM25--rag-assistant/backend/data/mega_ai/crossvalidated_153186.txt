[site]: crossvalidated
[post_id]: 153186
[parent_id]: 153068
[tags]: 
If you distrust your original 937 observations so much, you should be very cautious before you use those data for any purpose. I assume that you have thought that issue through and have nevertheless decided to use those untrustworthy observations to obtain a rough estimate of the number of re-tests you have to perform in order to get an adequately precise final model based on later, technically sound observations. If you are keeping the same set of covariates in each of your new models based on subsets of the original observations, the fact that you have a linear model means that your work is essentially already done. Each coefficient standard error reported in your model with all 937 cases essentially contains a factor close to inversely proportional to the square root of the number of cases. If you analyze subsets with 100 cases each, your coefficients in the subset models will have about $\sqrt{\frac{937}{100}}$ higher standard errors, about a factor of 3. You certainly can test this by doing 1000 models based on samples of 100 from the original data if you wish. Examine the standard deviations of the point estimates of each of the regression coefficients among the 1000 models. That tells you how much different models based on 100 cases each are likely to differ, which is what you apparently care about. The average value of each coefficient among the 1000 models should be close to the value from your original model. I don't see a need to combine the standard errors of the models separately. If you do choose to do so, you should, for each regression coefficient, square the standard errors to obtain variances, average those variances among the 1000 models, and then take the square root of the average variance. The pooled standard error obtained that way should be pretty similar to the standard deviation of the point estimate obtained as in the previous paragraph. Often when someone speaks of "training" a model there is some variable selection involved to obtain the final set of covariates. If that was the case in the development of your original model, you also need to consider the reproducibility of the covariate-selection process itself. In that case, keeping the same set of covariates for all of your sub-sample models might not be a good way to proceed.
