[site]: crossvalidated
[post_id]: 151467
[parent_id]: 
[tags]: 
Choosing right range for data while using scikit-learn

I have a dataset with 1175 examples and 21 features which are in the range of [-1, +1], and two class labels 1 and 0. As I read in the most of the resources, it is good to have data in the range of [-1, +1] or [0, 1]. So I thought I don't need any preprocessing. But when I run SVM and decision tree classifiers from scikit-learn. I got 100% accuracy using cross-validation with 10 folds. Afterwards, I tried to multiply the data by 10, 100, 1000 etc. Every time I increase the number, I get less accuracy. For example I got 91% for multiplying with 100. On the other hand, the decision tree classifier stays the same for all multiplications.
