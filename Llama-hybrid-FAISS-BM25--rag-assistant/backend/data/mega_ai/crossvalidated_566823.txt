[site]: crossvalidated
[post_id]: 566823
[parent_id]: 566786
[tags]: 
You could treat the NaNs as unlabelled data and use a semi-supervised learning algorithm, but as @Tim (+1) suggests, labelling them as positive is likely to bias the results. Unless you know the mechanism generating the NaNs, the best you can do is likely to be to ignore the labels entirely and just use the attribute vector. There are semi-supervised versions of logistic regression and the SVM. Note that imbalance generally is not an inherent problem. If ignoring the minority class is unacceptable, it probably means your application has unequal misclassification costs, and you just need to take them into account (e.g. for the SVM by having different slack penalties for positive and negative patterns). But considering misclassification costs is something we should be doing anyway, and the imbalance does not affect the solution to the cost-sensitive learning problem. Just a thought, as it is a spam dataset, it could be that the negative examples are emails that were caught by the spam filter, but labelled by the user as ham, and the positive examples could be labelled as spam by the user. The NaN ones may be emails that were caught by a spam filter, but were not checked by the user?
