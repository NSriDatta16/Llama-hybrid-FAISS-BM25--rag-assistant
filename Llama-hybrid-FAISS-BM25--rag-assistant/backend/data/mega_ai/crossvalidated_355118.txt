[site]: crossvalidated
[post_id]: 355118
[parent_id]: 
[tags]: 
For deep learning, does the statement "batch size should be no more than 32" make sense from Yann LeCun?

Does batch size over 100 is really meaningless, as I see some paper related to Deep Reinforcement Learning, there always have some batch size over 100. In addition, if batch size should really be no more than 32, does it mean that high-performance GPU is useless?
