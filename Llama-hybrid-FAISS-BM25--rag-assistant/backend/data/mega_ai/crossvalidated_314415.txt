[site]: crossvalidated
[post_id]: 314415
[parent_id]: 
[tags]: 
Estimating the average error of a random distribution

I'm not very familiar with statistical terms, so sorry if I messed up with some namings. If I have a data set with names and ages. Example: Tom 12 Jenny 14 Joe 15 Kate 14 And I have a the following choices of ages: [11, 12, 13, 14, 15, 16] Let's say I don't know the age of each person, I have a task to calculate the average error in age difference, if I randomly assign an age to a person by choosing one of the ages above. So let's take an example, I randomly chose an age for each person: Tom 13 Jenny 16 Joe 11 Kate 13 So for tom I have 1 year in difference from the real age, 2 for Jenny.... So the average error in age difference from the real age would be: (1 + 2 + 4 + 1)/4 = 2 I don't know how to think about it in a more general way. What can I use to get the average error in a large dataset if I chose random ages from a list? Extra info: The purpose of this task is that, I am creating a machine learning algorithm that predict the age of each person based on other data, and I want to compare the results with the results of a random distribution of age. To see if my prediction gives better results (less average error) than just a random pick Hope my question made sense.
