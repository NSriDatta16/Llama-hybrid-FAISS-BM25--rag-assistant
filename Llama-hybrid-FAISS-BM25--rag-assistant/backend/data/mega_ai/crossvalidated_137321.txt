[site]: crossvalidated
[post_id]: 137321
[parent_id]: 137166
[tags]: 
Your objective can be accomplished with a bit of calculus and algebra. First suppose that you have the probability density/mass function for $S$ , call it $f(s)$ . Given the parameter $a$ then let's write the conditional density of $S$ as $$ f(s|a). $$ Suppose you also have the density of $a$ , which we'll write as $g(a)$ . Then the joint density of $(s,a)$ is just the product $f(s|a)g(a)$ . Thus the marginal density of $s$ will be $$ f(s) = \int f(s|a) g(a) da $$ (If $a$ is discrete, then replace the integration with a summation over the support of $a$ .) This process of multiplying together conditional with marginal and integrating is an extremely common operation in Bayesian statistics, hence the link to the other question. The object you are in interested in, in Bayesian statistics, could be called a prior predictive distribution . If instead you have joint distribution functions, then it still holds that the joint distribution function $F(a, s) = F(s|a) F(a).$ Now you don't need to any integration. Instead, the marginal distribution function for $s$ is just $$ F(\infty, s) $$ or whatever the maximum value that $A$ may obtain is.
