[site]: crossvalidated
[post_id]: 517848
[parent_id]: 
[tags]: 
Sequential Bayesian Linear Regression with Diagonal Covariance

The standard update rules for a sequential Bayesian linear regression are well-known (heck, they're even on wikipedia: https://en.wikipedia.org/wiki/Bayesian_linear_regression ). However, in large dimensional models with N features, this requires updating and storing an NxN (O(N^2)) matrix which can become prohibitive in terms of latency. Please see our Github repo for a quick write-up: https://github.com/KoyoteScience/BayesianLinearRegressor At the same time, it is often desirable to have “dumber” model for large-dimensional systems, since such systems are more likely to overfit anyways. And a very obvious choice would be a linear regression but while forcing a diagonal covariance matrix. (NB: We may not “diagonalize” the covariance between the intercept and the coefficients, since that would be far too restrictive, and in this case, the covariance matrix would be a three-wide diagonal matrix and maintain the same order complexity scaling.) It would seem, at first, that you could just remove the off-diagonal elements of the covariance matrix during the update steps, and convert the matrix multiplications into element-wise multiplications, with large computer cost savings. It would also remove the need to tune an L2 regularization constant, since a large goal of that regularization is to remove the large coefficients learned with co-linear independent variables, which goes away if we assume that those variables are already linearly independent of each other. However, while you can gain reasonable estimates for the coefficients this way, the updates to the sum of residual squares go hay-wire, and it will grow huge or go negative even. Which brings us to the question: Are there closed form update rules to perform a sequential Bayesian linear regression with a forced diagonal covariance matrix between the model parameters (excluding the intercept)?
