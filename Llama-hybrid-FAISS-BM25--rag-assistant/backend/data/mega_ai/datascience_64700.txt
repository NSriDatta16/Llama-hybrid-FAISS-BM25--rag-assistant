[site]: datascience
[post_id]: 64700
[parent_id]: 
[tags]: 
Ram usage of model keep increasing when training to previously trained model

Update It keep increasing when i load the saved model like this. return tf.keras.models.load_model("models/min__1576172002.model") and i am saving model using agent.model.save(f'models/min__{int(time.time())}.model') I declare my model as model = Sequential() model.add(Dense(6,activation='relu',input_shape=(4,))) model.add(Dropout(0.2)) # model.add(Flatten()) model.add(Dense(5,activation='relu')) model.add(Dropout(0.2)) # model.add(Flatten()) model.add(Dense(5,activation='relu')) model.add(Dropout(0.2)) model.add(Dense(2,activation='softmax')) model.compile(loss="mse", optimizer=Adam(learning_rate=0.001), metrics=['accuracy']) Then its working ok. But after some time as it was not showing results, I use model = Sequential() model.add(Dense(6,activation='relu',input_shape=(4,))) model.add(Dropout(0.2)) # model.add(Flatten()) model.add(Dense(5,activation='relu')) model.add(Dropout(0.2)) # model.add(Flatten()) model.add(Dense(5,activation='relu')) model.add(Dropout(0.2)) model.add(Dense(5,activation='relu')) model.add(Dropout(0.2)) model.add(Dense(2,activation='softmax')) model.compile(loss="mse", optimizer=Adam(learning_rate=0.001), metrics=['accuracy']) I added only one more layer. But now. I see RAM usage of computer. It is keep increasing and not stopping. If i pause training then RAM will also pause at that point and when i continue training then RAM will increase and it took 32GB of RAM (and still increasing )and previous model with one less layer took only 6GB of RAM
