[site]: datascience
[post_id]: 102918
[parent_id]: 102883
[tags]: 
Your problem has 3 main sections as below: Text data (function description) as input. Looks like a multi-label & multi-class classification problem There is hierarchy/dependency between the two classifiers (Parent and sub category) Based on this information, I would suggest you have a look at BERT/transformers based multi-label & multi-class classification work This could be a helper blog: https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a . This will help you set up first two points from above.This itself could give you decent performance. Now for the 3rd Part(dependency between 2 classifiers): I would think about concatenating output of first classifier(dense layer) with BERT's CLS output(768 dim vector) and using this as input for your second classifier. For the loss function, just use cross-entropy for each classifier and add them for final loss. You can backpropagate from this loss (this allows you to think about doing a weighted average also if you like). But during training, you might want to think a little bit about teacher forcing, if your model is not learning properly.
