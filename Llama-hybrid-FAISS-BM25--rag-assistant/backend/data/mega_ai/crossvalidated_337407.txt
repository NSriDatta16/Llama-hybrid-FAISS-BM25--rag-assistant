[site]: crossvalidated
[post_id]: 337407
[parent_id]: 
[tags]: 
LinearSVC gives nonintuitive (bad) boundaries

I'm going through chapter 5 (SVM) in Geron's book "Hands on Machine Learning" (ipynb link). The task is to classify the Iris Dataset. The code: import numpy as np import matplotlib.pyplot as plt from sklearn import datasets from sklearn.linear_model import SGDClassifier from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.svm import LinearSVC, SVC iris = datasets.load_iris() # The petal len + width: X = iris["data"][:, (2, 3)] y = iris["target"].astype(np.float64) svm_clf = Pipeline([ ("scaler", StandardScaler()), # ("linear_svc", SVC(1, "linear")) ("linear_svc", LinearSVC(C=1, loss="hinge")) # ("linear_svc", SGDClassifier(alpha=0.001, loss="hinge")) ]) svm_clf.fit(X, y) x0, x1 = np.meshgrid( np.linspace(0, 8, 200).reshape(-1, 1), np.linspace(0, 3, 200).reshape(-1, 1) ) X_new = np.c_[x0.ravel(), x1.ravel()] y_predict = svm_clf.predict(X_new) zz = y_predict.reshape(x0.shape) plt.contourf(x0, x1, zz) plt.plot(X[y == 2, 0], X[y == 2, 1], "g^", label="Iris-Virginica") plt.plot(X[y == 1, 0], X[y == 1, 1], "bs", label="Iris-Versicolor") plt.plot(X[y == 0, 0], X[y == 0, 1], "yo", label="Iris-Setosa") plt.show() Produces: My question: I expected the yellow and blue dots to be separated better. I thought the SVM classifier would put the boundary right in the middle between the two clusters. When I use the SVC classifier instead of LinearSVC (commented in the above code). I get what I expected: So: How come the boundary is so bad in the LinearSVC classifier?
