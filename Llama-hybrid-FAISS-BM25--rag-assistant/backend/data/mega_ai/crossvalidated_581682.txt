[site]: crossvalidated
[post_id]: 581682
[parent_id]: 581679
[tags]: 
I think the confusion arises because the premise of your question is flawed. In particular, as I understand it, you seem to think there is a discrepancy because you seem to be intuiting a notion that the minimum sample size calculation and the two-sample two-tailed proportion test are somehow supposed to be "inverses" of one another. This intuition (if it's the intuition that you really had) is false, and defining concepts more precisely might help see why. When you are doing a sample size calculation, the precise question you are asking is as follows: " If the data are generated such that group $A$ has population proportion $p_A$ while group $B$ has population proportion $p_B$ , and assuming I collect data in proportion $\kappa$ , how large does my sample need to be so that I have a probability $\beta$ of rejecting that the two samples have the same mean at the $\alpha$ significance level?" The key point to notice is that in order to reject with a high probability like $\beta=0.8$ , the mean of the sampling distribution needs to be more than $q_{1-\alpha/2}$ standard errors away from 0. This is because when you draw from actual data, you will sometimes (in fact, roughly half the time!) get "unlucky" and draw data where the difference between the sample proportions are closer together than the population proportions. As a result, you need your sample size to be big enough so that even most of the time when you're unlucky in this way, your standard errors are sufficiently low so that you will still be far enough away from equality that your statistical test would reject the null that the two proportions are equal. Now consider the two-proportion test. The question that the test is asking is " if my data happened to be such that a fraction, $p_A$ , of the data in group $A$ was positive and a fraction $p_B$ of group $B$ was positive, and sample sizes are $n_A, n_B$ respectively, what is the probability that such an extreme deviation occurred under the null hypothesis that in the population, the two samples came from the same population, with the same underlying variance." Hopefully, stating the definitions of these two calculations has made it clear that the two calculations are not "opposites" or "inverses" of one another, so there is no reason why plugging the outputs from one calculations into the inputs for another should return back the inputs from the original calculation. In your specific case, the intuition for why is that in order to have an 80% chance of getting statistical significance, you need to give yourself enough "wiggle room" so that even if the difference in proportions in sample happens to less than the population (which it will in practice half of the time, just from sampling variation), it is still a sufficiently large difference most of the time that you will still reject at significance level 5%. The fact that you are giving yourself this wiggle room means in the average case (which is what you plugged into your two-sample proportion test as inputs), you should be comfortably rejecting the null hypothesis. If you were teetering right on the edge, like in your proposal, you would only find statistical significance 50% of the time (in the 50% of cases where just by dumb luck, the difference in proportions is less than the population mean, you would fail to reject), which is far less than the 80% you would have wanted.
