[site]: crossvalidated
[post_id]: 601184
[parent_id]: 
[tags]: 
Should a CNN generalize to arbitrary positions in the data?

I have trained a CNN on one dimensional data that is the power spectral density (PSD) of a $N$ different classes of signals ( $N=4$ ). Each of the $N$ signals has a different spectral shape (not shown here). For illustrative purposes, the plots shown below are from the same signal class. The idea is to treat this as an image classification problem. The model performs exceptionally well when the training data has all the examples centered around the same frequency (i.e., within a few hundred Hertz): The CNN fails to properly classify new examples that are outside the frequency range of the training data: Model Details and Assumptions: The CNN model is implemented in PyTorch using the following layers: model = nn.Sequential( nn.Conv1d(in_channels=1, out_channels=64, kernel_size=128, stride=1, padding=1), nn.ReLU(), nn.MaxPool1d(kernel_size=16, stride=2), nn.Dropout(p=0.25), nn.Flatten(), nn.Linear(257664, n_classes) ) The optimizer is torch.optim.Adam . Batch size has been varied from 8 to 128, epochs varied from 10 to 50. The input data is normalized to $[0,1]$ . Training examples varied from [2000, 8000], where 20% are used for validation and 20% are used for test. I have also tried adding additional convolutional layers, varying the kernal sizes, neurons, layers, etc. Questions: Shouldn't the CNN model generalize such that new examples that are not within the same frequency range (i.e., centered around the middle) should be identified as the correct class? Are there other steps I need to take, whether in the model or training data?
