[site]: datascience
[post_id]: 64636
[parent_id]: 64630
[tags]: 
you need to use OneHotEncoder() for you independent variables (X), and LabelEncoder() for your dependent variable (y). If you want to reduce the number of dummy variables (output of OneHotEncoder) you can remove one dummy variable for each category. For example, for a categorical variable, Gender , you will have Gender_Female and Gender_Male ; but only one is required. Gender_Female=0 means Male . So you need to use drop='first' for OneHotEncoder(). However, when you use this feature, you have to use handle_unknown='error' (the latest version has a limitation than you can't use handle_unknown='ignore'). I highly recommend you to read this article Choosing the right Encoding method-Label vs OneHot Encoder . The other possible way to reduce the number of variables, but I don't recommend', is using feature selection methods, SelectKBest(). However, I don't believe it works for non-linear problems as I haven't got good results in my problems. You can read here more 1.13. Feature selection A better solution may be dimensionality reduction methods, e.g. PCA, to reduce the number of apparent variables and make your modelling computationally lighter and faster; but you know that you may lose some accuracy when you use this method. Read here 6.5. Unsupervised dimensionality reduction
