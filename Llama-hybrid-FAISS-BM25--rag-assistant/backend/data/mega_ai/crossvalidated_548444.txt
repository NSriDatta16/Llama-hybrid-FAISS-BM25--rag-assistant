[site]: crossvalidated
[post_id]: 548444
[parent_id]: 548421
[tags]: 
I think when you're instructor introduces more-time series modeling methods you will get a better intuition for the problems with your models in general. There are a few points to be made about the limitations of your models: Autocorrelation. Simply put, when you have auto-correlated data, linear models simply aren't appropriate. They are ALL biased, because they assume no autocorrelation. Overfit. Overfit cannot always be detected just by looking at a model. This is one of the reasons we often hold out some data for validation by training on some data and then testing it against held-out data. This allows us to detect overfit. So, you're right, there isn't a perfect quantitative way per se to detect overfit, because by definition overfit is related to the true distribution across the population, which you haven't observed. Polynomials. In general higher-order (e.g. 3-5) polynomials are discouraged in most fields because they are postulating that there is some underlying mechanism that has a high order function. This simply doesn't happen very often outside of physics. In other words, this is a theoretical objection, not a empirical objection. Unless you can substantively justify the use of a high-order polynomial, it will always be viewed as skeptical. And, with validation data, you would most likely see this is the case. Another way to think about this: you stated: "I would say that at least I should try to create a model that fits the data in sample well." I disagree with this statement. I think the goal of a statistical model is to explain the data sample well. If we cared only about pure predictive power, then most likely you would be better off with a machine learning algorithm like random forest, SVM etc. You use statistical models to understand, not just predict.
