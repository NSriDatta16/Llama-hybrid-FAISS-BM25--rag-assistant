[site]: datascience
[post_id]: 48076
[parent_id]: 
[tags]: 
My question is about dependency between hidden states for Back Propagation Through Time in RNN

In one video lecture, professor Ali Ghodsi of University of Waterloo says that the first node of S(t)(hidden state of RNN at time t) has an effect only on the first node of S(t+1)(hidden state of RNN at time t+1), the second node of S(t) has an effect only on the second node of S(t+1), and so on. I do not see how that is correct cause the weight matrix W connecting the state at one time step to the state at the next time step is (p,p) dimensional which means each node of S(t) is connected to every node of S(t+1). What I have come to understand from various blogs on the internet about RNN is that nodes in the hidden state of some time step are connected to every node in the hidden state corresponding to the next time step which is contradictory to what professor Ghodsi is stating in the lecture. What I want to clarify is whether the hidden nodes in RNN are usually connected in the same way as fully connected networks throughout the temporal dimension, or are they connected elementwise as the professor says. I am providing a link to the video https://www.youtube.com/watch?v=AvyhbrQptHk&t=1704s where the claim is made a 43:02. I had posted this question on StackOverflow, but that doesn't seem to be the correct platform for such topics. I am new to this site. So, please be a little patient if you do not like the format of the question and let me know how I can improve the quality of my question. Thanks in advance.
