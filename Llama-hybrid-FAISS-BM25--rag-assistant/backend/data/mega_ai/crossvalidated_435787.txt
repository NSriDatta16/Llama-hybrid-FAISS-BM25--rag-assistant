[site]: crossvalidated
[post_id]: 435787
[parent_id]: 435634
[tags]: 
Stepwise model selection, particularly forward stepwise, is not very reliable. This page provides much general discussion. With Cox models the problem is even worse than for ordinary linear regression. In ordinary linear regression there is no bias if you omit a predictor that is uncorrelated to the predictors you include. In other types of regressions like logistic regression or Cox proportional hazard regressions, however, if you omit a predictor that is associated with outcome your estimates of the coefficients for the included predictors are inherently biased. There is a wonderful analytic illustration for probit models on this page ; the principle applies to Cox models too. So both inter-correlations of predictor values and omission of predictors associated with outcome pose problems for Cox regressions. The coefficient for a predictor considered separately from all the other predictors can be very unreliable. My guess is that your "statistically insignificant variable" is actually associated with outcome, as you suspected from the beginning. As a single predictor, though, its coefficient was biased to a low and "statistically insignificant" value because other predictors associated with outcome were omitted. For unpenalized regressions (that is, not using LASSO, ridge, elastic net, etc.) a useful approach is to see how many predictors you can reasonably expect to handle without overfitting. For Cox models, that's on the order of 1 predictor for every 15 events. Within that limit, try to include all predictors that might reasonably be associated with outcome, based on your knowledge of the subject matter, and add in candidate predictors for any specific hypotheses you want to test. Then validate the model-building process with bootstrapping or cross-validation. Frank Harrell's course notes provide a valuable resource for further study of regression modeling in general and Cox models in particular.
