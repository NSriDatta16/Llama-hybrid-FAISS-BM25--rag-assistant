[site]: crossvalidated
[post_id]: 504624
[parent_id]: 
[tags]: 
Expected value of subset of variables in Bayesian setting

Assume we have $N$ random variables $X_1, \ldots, X_N$ with known (posterior) distributions that are easy to sample from. For simplicity, assume that I am interested in the expected value of the ten largest of these random variables. There will be some uncertainty surrounding this expected value as there is uncertainty with respect to the rank of a given $X_i$ in case the distributions of $X_1, \ldots, X_N$ overlap. I want to use simulation based methods. My approach is to simulate $M$ samples from the distributions of $X_1, \ldots, X_N$ , where in each iteration, I construct a binary indicator of length $N$ indicating whether random variable $i$ is within the set of the ten largest samples or not. Averaging over these $M$ draws gives me the probability that random variable $i$ is member of the top ten group. Denote this probability as $\pi_i$ . Define a binary random variable that indicates membership in the top ten group as $S_i$ . $S_i$ follows a Bernoulli distribution s.t. $S_i \sim Ber(\pi_i)$ . In a second step, I draw $L$ samples from the distribution of $S_i$ and from the distributions of $X_1, \ldots, X_N$ . Given a draw of $S_i$ , I can select the top ten out of the samples of $X_1, \ldots, X_N$ in each iteration and average the respective samples within the top ten group. I save this average, so the result after $L$ iterations will be the distribution of the average outcome within the top ten group, taking into account all relevant sources of uncertainty. My questions are: Is this simulation approach valid in general? From a Bayesian perspective, is this simulation valid or do I need to treat additional quantities (e.g. $S_i$ or $\pi_i$ ) as random variables that need a prior?
