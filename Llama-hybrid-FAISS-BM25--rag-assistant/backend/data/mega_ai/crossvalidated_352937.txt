[site]: crossvalidated
[post_id]: 352937
[parent_id]: 352795
[tags]: 
This matter has been discussed in the literature a fair bit. See Ho, Imai, King, & Stuart (2007) and Kang & Schafer (2007) for some good intuitions on why you might prefer matching over regression. One important benefit of matching, especially pair matching, is that one does not need to make a functional form assumptions about the relationship between the confounder and the outcome. For example, if that relationship (conditional on treatment) was not well approximated by a simple regression model, bias would remain in the effect estimate using regression but not using matching. Of course, this is a bit of a straw man because it's possible to skillfully estimate a flexible regression model that accounts for nonlinearities. It's also possible to perform a sophisticated match that protects against unmeasured confounding. Matching may also be preferred in the case of many confounders because it's harder to model the relationships of all of them with the outcome, but it may be possible to match on them. Matching can protect against extrapolation from a region of covariate overlap between your two groups. This is discussed by Ho et al. (2007). Matching can protect you from capitalizing on chance due to readjusting a regression model after examining the effect estimates. Matching provides access to estimands not available with regression (e.g., the average treatment effect on the treated). Matching estimates marginal effects, which cannot be so easily estimated with logistic regression. On the other hand, regression is optimally efficient, doesn't require you to throw away units, and allows you to estimate conditional effects and interactions.
