[site]: crossvalidated
[post_id]: 281179
[parent_id]: 281177
[tags]: 
An autoregressive time series is one where each observation depends on the one(s) before that. For instance, an AR(1) series is one where $y_t=\phi y_{t-1}+\epsilon_t$ for an AR parameter $\phi$ and noise $\epsilon_t$. AR models are a special case of ARIMA models . If your time series tends to stay at a certain level for a longer while, this usually indicates autoregressive behavior. If $y_{t-1}$ is far away from the median and $y_t$ depends on $y_{t-1}$ autoregressively with $\phi>0$, then $y_t$ will likely also be far away from the median, in the same direction as $y_{t-1}$. Below are a few examples (with R code) for AR(1) series, for different values of the autoregressive parameter $\phi$. Note how the bottom series for $\phi=0.99$ displays markedly strong persistence. library(forecast) nn If you want to follow up on this, there are many textbooks on time series out there - just be sure you find one with an emphasis on ARIMA models, not so much exponential smoothing. This chapter in an online textbook may be a good start. In your particular example, you could fit AR(1) models to each time series and see how different the estimated coefficients are, and even calculate significance if you are so inclined. Or fit more general AR($p$) models, but those are harder to interpret and compare.
