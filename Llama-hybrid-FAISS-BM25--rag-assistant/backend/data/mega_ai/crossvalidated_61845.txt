[site]: crossvalidated
[post_id]: 61845
[parent_id]: 
[tags]: 
Large scale Cox regression with R (Big Data)

I am trying to run a Cox regression on a sample 2,000,000 row dataset as follows using only R. This is a direct translation of a PHREG in SAS. The sample is representative of the structure of the original dataset. ## library(survival) ### Replace 100000 by 2,000,000 test The main challenge is in the compute time for the original dataset (2m rows). As far as I understand, in SAS this could take up to 1 day, ... but at least it finishes. Running the example with only 100,000 observations take only 9 seconds. Thereafter the time increases almost quadratically for every 100,000 increment in the number of observations. I have not found any means to parallelize the operation (e.g., we can leverage a 48-core machine if this was possible) Neither biglm nor any package from Revolution Analytics is available for Cox regression, and so I cannot leverage those. Is there a means to represent this in terms of a logistic regression (for which there are packages in Revolution) or if there are any other alternatives to this problem? I know that they are fundamentally different, but it's the closest I can assume as a possibility given the circumstances.
