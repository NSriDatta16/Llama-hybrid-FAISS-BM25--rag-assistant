[site]: datascience
[post_id]: 31334
[parent_id]: 31329
[tags]: 
Whether or not padding is ppropriate really depends on the entire structure of your dataset, how relevant the different variables/columns are and also the type of model you want to run at the end. Padding would be used, whereby you would have to fix the length of each sample (either to the length of the longest sample, or to a fixed length - longer samples would be trimmed or filtered somehow to fit into that length). Variables that are strings can be padded with empty strings, variables with number can be padded with zeros. There are however many other ways to pad, e.g. using the average of a numerical variable, or even model-based padding, padding with values that "make most sense" for filling gaps in that specific sample. Getting deep into it like that might more generally be called imputation, instead of padding - it is common in time series data, where gaps aren't always at one end of a sample. Below I outline one approach to padding or standardizing the length of each sample. It it not specifically padding. As you did not mention a programming language, I will give and code snippet in Python , but the same is easily achievable in other languages such as R and Julia . The Approach Based on the two examples you provide, it seems each example would be a calendar day, on which there are a variable number of observations. There are also columns that are strings, and others are strings of numbers (e.g. column 5 in sample 2). In time-series analysis in general, it is desirable to have a continuous frequency of data. That means have one day give one input. So my approach would be to make your data into a form that resembles a single input for each of the variables (i.e. columns) of each sample. This is general approach, and you will have to try things out or do more research on how this would look in reality for your specific data at large. Timestamps I would use these as a kind of index, like the index in a Pandas DataFrame . One row = one timestamp. Multiple variables are then different columns. Dealing with strings I will assume that your dataset has a finite number of possible strings in each column. For example, that column 4 (holding names ), will always hold a name from a given set. One could perform set(table2['column 4']) to see which values there are (removing duplicates). Or even: # Gather a single list containing all strings in column 4 of all samples all_names = [] [] # list comprehension to loop # Check how many strings there are from collections import Counter counter = Counter(table2['column4']) print(len(counter)) # see how many unique values exist print(counter) # see how many times each string appears print(counter.most_common(5)) # see the most common 5 strings Now assuming this shows there is a finite number (more than likely the case), You could look into using a sparse representation of each sample (that means for each day). For example, if all the words in the entire dataset were: ['hi', 'hello', 'wasup', 'yo', 'bonjour'] (duplicates removed), then for one single sample with column 4 holding e.g. ['hi', 'hello', 'yo', 'hi'] , your sparse representation for this sample would be: [2, 1, 0, 1, 0] , because the sample has two 'hi', one 'hello', zero 'wasup' and so on. This sparse representation would then be your single input for column 4 for the timestamp (that single sample). It might be worth looking into something like the DictVectorizer and CountVectorizer from Scikit-Learn. Dealing with number columns As I mentioned right at the beginning, you could pad these to a chosen length, perhaps matching the length of the string based representation above (or not!), depending on your final model. You can then pad the inputs with a value that makes sense for your model (see the kind of options I mentioned at the beginning of my answer). This should land you with, once again, a single vector for the given day, containing the information in the numerical column.
