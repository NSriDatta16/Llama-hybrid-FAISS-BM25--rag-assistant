[site]: datascience
[post_id]: 56701
[parent_id]: 56695
[tags]: 
If you want to use arbitrary length input and outputs, there are two common options: train a single model for each length or use a recurrent neural network (RNN) architecture. A non-RNN neural network cannot handle arbitrary length because the shape of the weights depend on the length of the input. From your example, it seems like you want to keep different copies of weights based on the length. You could do that, but in theory, it is the same as training separate models. The weights from one length will only be updated by inputs of the same length, so why not save yourself the hassle and have separate models? Although RNNs are typically used for natural language processing and understanding, it does not mean they cannot be used to solve other deep learning problems. Specifically for your problem, you should use a many-to-many architecture. Source: http://karpathy.github.io/2015/05/21/rnn-effectiveness/ In Keras, you can use the LSTM layer and set the parameter return_sequences to True, which will return an output the same length as your input sequence. Documentation here: https://keras.io/layers/recurrent/#lstm .
