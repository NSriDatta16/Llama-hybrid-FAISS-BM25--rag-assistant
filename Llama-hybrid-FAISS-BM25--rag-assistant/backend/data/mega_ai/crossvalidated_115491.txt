[site]: crossvalidated
[post_id]: 115491
[parent_id]: 115355
[tags]: 
In the absence of subject matter knowledge, overinclusion of variables is generally better than underinclusion, and there is little reason to do model selection to build a PS. What is more important is to build a flexible model. My default approach is to spline every continuous variable and to not look at $P$-values for variables in the PS, i.e., I use a flexible additive logistic regression model. There are many advantages of covariate adjustment using the logit PS. I typically spline the logit of PS to include as a multiple degree of freedom adjustment variable, after doing due diligence regarding non-overlap regions. See http://www.citeulike.org/user/harrelfe/article/13340175 and http://www.citeulike.org/user/harrelfe/article/13265389 and more articles in http://www.citeulike.org/user/harrelfe/tag/propensity-score . You have to be sure to also include as separate covariates the likely strong predictors of $Y$ as PS is just for bias adjustment, not for capturing outcome heterogeneity. I am dubious of any matching method that results in discarding matchable observations or that is highly dependent on dataset order. Discarded observations have a lot to say about how covariate effects should be estimated.
