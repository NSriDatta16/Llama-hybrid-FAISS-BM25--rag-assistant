[site]: crossvalidated
[post_id]: 366824
[parent_id]: 142873
[tags]: 
You should ask yourself what were you trying to achieve with your modeling approach. As you correctly said "how far from true solution am I" is a good starting point (notice this is also true for classification, we only get into specifics when we run into dichotomization, usually in more CS oriented machine learning, such as trees or SVMs). So, let's measure it, shall we? If $x_i$ is the truth and $\hat x_i$ your model output, for sample $i$ , here's the error: $$\epsilon_i = x_i - \hat x_i$$ You could measure the mean error $\sum_i \epsilon_i$ , but it turns out that, doing that, positive and negative errors cancel, giving you no way to know how good your model actually performs! So, what people do in general, is to use these measures: Squared error: $$\text{SE}=\sum_i^n \epsilon_i^2$$ Mean squared error: $$\text{MSE}=1/n \times \text{SE}$$ Root mean squared error: $$\text{RMSE}=\sqrt{\text{MSE}}$$ Relative mean squared error (do not confuse this for the RMSE, root mean squared error): $$\text{rMSE}={n-1\over n}{{\sum_i^n \epsilon_i^2}\over {\sum_i^n (x_i - \mathbb E(x))^2}}= {\text{MSE} \over Var(x)}$$ $\text{R}^2$ : $$\text{R}^2=1 - \text{rMSE}$$ Absolute error: $$\text{AE}=\sum_i^n \sqrt{\epsilon_i^2}=\sum_i^n |{\epsilon_i}|$$ Mean absolute error: $$\text{MAE}=1/n \times \text{AE}$$ And many, many others. You can find them around on the site (see for example How to interpret error measures? ).
