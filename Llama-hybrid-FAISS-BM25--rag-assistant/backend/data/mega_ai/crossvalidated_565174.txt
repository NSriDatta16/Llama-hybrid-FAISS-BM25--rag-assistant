[site]: crossvalidated
[post_id]: 565174
[parent_id]: 565151
[tags]: 
The additional output nodes will not help, if there are no training examples to go with it. When you train a neural network with a softmax activation function in the final layer, the output nodes can be interpreted as a probability distribution over the classes. Training a neural network by any form of gradient descent with a cross-entropy loss will attempt to maximize the probability of the observed class. In other words, the ideal output is all of the probability mass on 'cat' if the training image is a cat, and all of the probability mass on 'dog' if it's a dog. There's nothing in here to encourage putting any probability mass on the 'other' class, because you don't provide training examples of it. The network will learn to push the probability of that class down toward 0, regardless of whether the provided image is a dog or cat. This means it won't predict 'other' at test time. Sure, I made some assumptions in there. But the general statement holds, even for other loss functions or training regimens.
