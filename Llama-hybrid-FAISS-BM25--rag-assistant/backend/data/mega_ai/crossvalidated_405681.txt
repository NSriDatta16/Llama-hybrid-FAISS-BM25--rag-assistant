[site]: crossvalidated
[post_id]: 405681
[parent_id]: 405674
[tags]: 
This seems a problem easily solved by additive risk models. Create the regressor 1/n and estimate the additive risk model relating 1/n to the outcome $y$ , you will obtain maximum likelihood estimates of $a$ and $b$ . This is one of a general class of "binomial models" which are among a general class of "generalized linear models". The most famous example in this class is logistic regression which attributes to the outcome outcome a binomial variance, i.e. that the variance is equal to the mean times one minus the mean, and that the mean response is related to the predictors through a "logit link". $$\log \left( \text{Pr}(Y|X) / (1-\text{Pr}(Y|X)) \right) = X^T\beta$$ . However one can maintain the binomial variance attribute and vary the link. In particular, additive risk uses the identity function as the "link": $$\text{Pr}(Y|X) = X^T\beta$$ which in 1-dimension is exactly the linear model you express above. Estimation is done through maximum likelihood and Fisher Scoring in most default software. In R, for instance, the "call" is glm(y ~ x, family=binomial(link="identity") . In fact, there are some antiquated warnings in the ?glm help file about not fitting such a model. But these dismiss the importance of additive risk models and of using alternative fitting strategies (there is ample discussion on that topic through this SE).
