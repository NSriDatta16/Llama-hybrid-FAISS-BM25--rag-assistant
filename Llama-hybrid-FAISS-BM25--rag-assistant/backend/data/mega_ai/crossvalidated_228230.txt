[site]: crossvalidated
[post_id]: 228230
[parent_id]: 228213
[tags]: 
The cost function gives you a metric for how "good" your predictor is: the lower the cost, the better your predictor. So your target while training a predictor is to minimise the cost function (ideally, you would want it to be zero). This is what machine learning algorithms do: optimise the parameters of the predictor in order to minimise the cost function. If you didn't have a handy cost function like the (squared) sum of errors, you would not know how well your predictor is doing. To give a simple example: assuming you are training a predictor $P$, first with the vector of coefficients $\omega_1$ and then with $\omega_2$, getting as result the following error vectors: $e_1 = [1, -0.2, 3, 5]$ $e_2 = [0, 9, -2.3, 7]$ Just by looking at the error vectors, how would you decide whether parameters $\omega_1$ or $\omega_2$ are better? In contrast, if you calculate a cost function on each vector (for instance, the squared sum of errors), you obtain $cost_1 = \displaystyle\sum_{i=1}^{4} e_{1i}^2 = 35.04$ $cost_2 = \displaystyle\sum_{i=1}^{4} e_{2i}^2 = 135.29$ Like this, it is immediately obvious that the error vector $e_2$ is indicative of a higher error, since the cost function is higher. So you would know that using the coefficients $\omega_1$ for $P$ is the better choice.
