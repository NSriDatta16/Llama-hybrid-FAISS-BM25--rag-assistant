[site]: crossvalidated
[post_id]: 153425
[parent_id]: 110981
[tags]: 
When using AdaBoost (and most other machine learning algorithms, such as Support Vector Machines), it is important to calibrate prediction scores. One popular method is Isotonic Regression, which I recommend for most machine learning tasks. If you pass the prediction scores from your AdaBoost model through an Isotonic Regression you'll find that it provides calibrated probabilities that range from near zero to near one. In fact, you should do this with all of the models you have mentioned before combining them in an ensemble model. Sci-kit learn provides an Isotonic Regression function, as well as a new CalibratedClassifierCV function which will allow you to calibrate your prediction scores using cross-validation rather than holding out a separate calibration set from your training sample. To learn more, check out these papers; http://www.cs.cornell.edu/~caruana/niculescu.scldbst.crc.rev4.pdf http://ijcai.org/papers13/Papers/IJCAI13-286.pdf
