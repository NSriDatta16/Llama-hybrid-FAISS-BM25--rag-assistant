[site]: crossvalidated
[post_id]: 114654
[parent_id]: 114610
[tags]: 
Let me describe what I see as soon as I look at it: If we're interested in the conditional distribution of $y$ (which if often where interest focuses if we see $x$ as IV and $y$ as DV), then for $x\leq 0.5$ the conditional distribution of $Y|x$ appears bimodal with an upper group (between about 70 and 125, with mean a bit below 100) and a lower group (between 0 and about 70, with mean around 30 or so). Within each modal group, the relationship with $x$ is nearly flat. (See red and blue lines below drawn roughly where I guess some rough sense of location to be) Then by looking at where those two groups are more or less dense in $X$, we can go on to say more: For $x>0.5$ the upper group disappears completely, which makes the overall mean of $x$ fall, and below about 0.2, the lower group is much less dense than above it, making the overall average higher. Between these two effects, it induces an apparent negative (but nonlinear) relationship between the two, as $E(Y|X=x)$ seems to be decreasing against $x$ but with a broad, mostly flat region in the center. (See purple dashed line) No doubt it would be important to know what $Y$ and $X$ were, because then it might be clearer why the conditional distribution for $Y$ might be bimodal over much of its range (indeed, it might even become clear that there are indeed two groups, whose distributions in $X$ induce the apparent decreasing relationship in $Y|x$). This what I saw based on purely "by-eye" inspection. With a bit of playing around in something like a basic image manipulation program (like the one I drew the lines with) we could start to figure out some more accurate numbers. If we digitize the data (which is pretty simple with decent tools, if sometimes a little tedious to get right), then we can undertake more sophisticated analyses of that sort of impression. This kind of exploratory analysis can lead to some important questions (sometimes ones that surprise the person who has the data but has only shown a plot), but we must take some care over the extent to which our models are chosen by such inspections - if we apply models chosen on the basis of the appearance of a plot and then estimate those models on the same data, we'll tend to encounter the same problems we get when we use more formal model-selection and estimation on the same data. [This is not to deny the importance of exploratory analysis at all - it's just we must be careful of the consequences of doing it without regard to how we go about it. ] Response to Russ' comments: [later edit: To clarify -- I broadly agree with Russ' criticisms taken as a general precaution, and there's certainly some possibility I've seen more than is really there. I plan to come back and edit these into a more extensive commentary on spurious patterns we commonly identify by eye and ways we might start to avoid the worst of that. I believe I'll also be able to add some justification about why I think it's probably not just spurious in this specific case (e.g. via a regressogram or 0-order kernel smooth, though of course, absent more data to test against, there's only so far that can go; for example, if our sample is unrepresentative, even resampling only gets us so far.] I completely agree we have a tendency to see spurious patterns; it's a point I make frequently both here and elsewhere. One thing I suggest, for example, when looking at residual plots or Q-Q plots is to generate many plots where the situation is known (both as things should be and where assumptions don't hold) to get a clear idea how much pattern should be ignored. Here's an example where a Q-Q plot is placed among 24 others (which satisfy the assumptions), in order for us to see how unusual the plot is. This kind of exercise is important because it helps us avoid fooling ourselves by interpreting every little wiggle, most of which will be simple noise. I often point out that if you can change an impression by covering a few points, we may be relying on an impression generated by nothing more than noise. [However, when it's apparent from many points rather than few, it's harder to maintain that it's not there.] The displays in whuber's answer supports my impression, the Gaussian blur plot seems to pick up the same tendency to bimodality in $Y$. When we don't have more data to check, we can at least look at whether the impression tends to survive resampling (bootstrap the bivariate distribution and see if it's nearly always still present), or other manipulations where the impression shouldn't be apparent if it's simple noise. 1) Here's one way to see if the apparent bimodality is more than just skewness plus noise - does it show up in a kernel density estimate? Is it still visible if we plot kernel density estimates under a variety of transformations? Here I transform it toward greater symmetry, at 85% of default bandwidth (since we're trying to identify a relatively small mode, and the default bandwidth is not optimized for that task): The plots are $Y$, $\sqrt{Y}$ and $\log(Y)$. The vertical lines are at $68$, $\sqrt{68}$ and $\log(68)$. The bimodality is diminished, but still quite visible. Since it's very clear in the original KDE it seems to confirm it's there - and the second and third plots suggest its at least somewhat robust to transformation. 2) Here's another basic way to see if it's more than just "noise": Step 1: perform clustering on Y Step 2: Split into two groups on $X$, and cluster the two groups separately, and see if it's quite similar. If there's nothing going on the two halves shouldn't be expected to split all that much alike. The points with dots were clustered differently from the "all in one set" cluster in the previous plot. I'll do some more later, but it seems like perhaps there really might be a horizontal "split" near that position. I'm going to try a regressogram or Nadaraya-Watson estimator (both being local estimates of the regression function, $E(Y|x)$). I haven't generated either yet, but we'll see how they go. I'd probably exclude the very ends where there's little data. 3) Edit: Here's the regressogram, for bins of width 0.1 (excluding the very ends, as I suggested earlier): This is entirely consistent with the original impression I had of the plot; it doesn't prove my reasoning was correct, but my conclusions arrived at the same result the regressogram does. If what I saw in the plot - and the resulting reasoning - was spurious, I probably should not have succeeded at discerning $E(Y|x)$ like this. (Next thing to try would be a Nadayara-Watson estimator. Then I might see how it goes under resampling if I have time.) 4) Later edit: Nadarya-Watson, Gaussian kernel, bandwidth 0.15: Again, this is surprisingly consistent with my initial impression. Here's The NW estimators based on ten bootstrap resamples: The broad pattern is there, though a couple of the resamples don't as clearly follow the description based on the whole of the data. We see that the case of the level of the left is less certain than on the right - the level of noise (partly from few observations, partly from the wide spread) is such that it's less easy to claim the mean is really higher at the left than at the center. My overall impression is that I probably wasn't simply fooling myself, because the various aspects stand up moderately well to a variety of challenges (smoothing, transformation, splitting into subgroups, resampling) that would tend to obscure them if they were simply noise. On the other hand, the indications are that the effects, while broadly consistent with my initial impression, are relatively weak, and it may be too much to claim any real change in expectation moving from the left side to the center.
