[site]: crossvalidated
[post_id]: 627747
[parent_id]: 574409
[tags]: 
As stated here , the L(G,D) you cite above is not a loss, rather it should be called an objective. The negative of L(G,D) can be called a 'loss'. Perhaps this is one source of confusion. In fact, in the GAN paper , the objective is called a value function, V(G,D). Additionally, given the objective, $\mathbb{E}_{x\sim\ p_r(x)}[log[D(x)] + \mathbb{E}_{x\sim\ p_g(x)}[log1 - D(x)]]$ , you can see that it reaches a maximum value of 0 when D(x)=1 (correctly) for all real samples and D(x)=0 (correctly) for all fake samples produced by the Generator; when the Discriminator is wrong the objective decreases to negative values. Hence the objective is maximized while training the Discriminator to output the correct class. On the other hand, the Generator wants to get better and fool the Discriminator to output the wrong class (D(x)=1) for the fake samples and hence we train the Generator to get better by minimizing the objective, i.e., pushing it to values less than zero.
