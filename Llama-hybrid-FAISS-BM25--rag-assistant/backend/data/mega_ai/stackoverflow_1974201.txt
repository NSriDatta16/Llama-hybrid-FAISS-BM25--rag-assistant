[site]: stackoverflow
[post_id]: 1974201
[parent_id]: 1974006
[tags]: 
I think you can calculate your gradient using the same approach used in image border detection (which is a gradient calculus). If your histogram is in a vector you can calculate an approximation of the gradient as*: for each point in the histogram compute gradient[x] = (hist[x+1] - hist[x]) This is a very simple way to do it, but I'm not sure if is the most accurate. approximation because you are working with discrete data instead of continuous Edited : Other operators will may emphasize small differences (small gradients will became more emphasized). Roberts algorithm derives from the derivative calculus: lim delta -> 0 = f(x + delta) - f(x) / delta delta tends infinitely to 0 (in order to avoid 0 division) but is never zero. As in computer's memory this is impossible, the smallest we can get of delta is 1 (because 1 is the smallest distance from to points in an image (or histogram)). Substituting lim delta -> 0 to lim delta -> 1 we get f(x + 1) - f(x) / 1 = f(x + 1) - f(x) => vet[x+1] - vet[x]
