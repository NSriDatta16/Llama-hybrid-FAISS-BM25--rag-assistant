[site]: crossvalidated
[post_id]: 493435
[parent_id]: 
[tags]: 
What are the applications, where different multi-label classification performance evaluation metrics should be used?

There are numerous multi-label classification performance evaluation metrics, namely hamming loss, accuracy (or Jaccard-index), subset accuracy (or exact match), example-based (precision, recall, f1-score), micro (precision, recall, f1-score), macro (precision, recall, f1-score), coverage, one-error, average-precision, AUC, ranking loss. I wish to know the different applications of multi-label classification, where these different performance evaluation metrics should be used. I searched a lot; however, unable to find an article that mentioned one-to-one correspondence between performance evaluation metrics and applications of multi-label classification, i.e., ranking loss is ideal for recommendation system (this is just an example).
