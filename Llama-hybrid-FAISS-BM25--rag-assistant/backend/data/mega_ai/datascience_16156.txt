[site]: datascience
[post_id]: 16156
[parent_id]: 
[tags]: 
Compare probability estimates of two classifiers

Consider two binary classifiers A and B. Suppose that both A and B are predicting the same target, but that A is trained on a subset of the data for which a different set of features is available than for B. Suppose further that A and B output probability esitmates and that for a set of mixed input types (some with features that A can accept, others for B) I need to rank them by probability of being positive. Perhaps (and this is completely fabricated) I'm trying to predict early mortality of lions and tigers in a zoo. Different features are available for early lion mortality than for early tiger mortality. However, I ultimately will need to order all of the big cats, (among both lions AND tigers) by likelihood of early mortality. My ideas so far: Train a meta-estimator that accepts the input type (belonging to A or B) and the scores from A and B. I'm thinking xgboost or another tree-based regressor. Attempt to directly and monotonically transform the probability estimates from A and B so as to 'bring them into alignment' in such a way as to maximize the cross-validated AUC. This seems to be similar to the first option. Other information: In my actual application there is class imbalance, and the class imbalance varies between A type datapoints and B type datapoints. Precision TPR/(TPR+FPR) is most important in a business context.
