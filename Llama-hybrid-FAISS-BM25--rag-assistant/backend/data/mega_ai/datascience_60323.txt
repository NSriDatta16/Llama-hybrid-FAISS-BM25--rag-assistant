[site]: datascience
[post_id]: 60323
[parent_id]: 
[tags]: 
Difference of sklearns accuracy_score() to the commonly accepted Accuracy metric

I am trying to evaluate the accuracy of a multiclass classification setting and I'm wondering why the sklearn implementation of the accuracy score deviates from the commenly agreed on accuracy score: $\frac{TP+TN}{TP+TN+FP+FN}$ For sklearn the sklearn.metrics.accuracy_score is defined as follows( https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score ): $\texttt{accuracy}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} 1(\hat{y}_i = y_i)$ This seems like its completly neglecting the true negatives of the classification. Example: Predicted 1 2 3 Actual 1 5 2 0 2 8 6 2 3 3 4 12 And here the TP,TN,FP and FN: TP TN FP FN 1 5 24 11 2 2 6 20 6 10 3 12 21 2 7 SUM 23 65 19 19 In the "standard" average score I would calculate: $\frac{23+65}{23+65+19+19}=0,698$ In the sklearn implementation however it would be: $\frac{1}{42}*23= 0,548$ Why is this different? And is the other metric somewhere mentioned in the literature, I couldn't find anything so far.
