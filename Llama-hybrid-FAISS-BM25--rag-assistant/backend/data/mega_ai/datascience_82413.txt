[site]: datascience
[post_id]: 82413
[parent_id]: 82404
[tags]: 
The ISL description is of gradient boosting (regression, with mse as the loss function), not of AdaBoost. There, $\lambda$ is constant, not weights for each tree. Since each tree is fitted to the residuals, we need to add the results to better approximate the true values, not average. However, the title question is still an interesting one. It does seem probably mostly arbitrary , but at least some testing has been done, see e.g. "Experiments with AdaBoost.RT, an Improved Boosting Scheme for Regression" by Shrestha and Solomatine.
