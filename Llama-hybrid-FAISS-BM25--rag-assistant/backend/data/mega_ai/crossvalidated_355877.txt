[site]: crossvalidated
[post_id]: 355877
[parent_id]: 355853
[tags]: 
In addition to the chi-squared test as described in @astel's answer, you could also do this by simulation. For $j = 1,\dots, N$ where $N$ is a big number (say $10000$) I'll simulate $$ X_{ij} \stackrel{\text{iid}}\sim \text{Multinomial}(35, (1/5, \dots, 1/5)) $$ for $i = 1,\dots,112$. Each $X_{ij}$ represents a single grid with 35 cells made of 5 colors. I'm simulating these with each color having equal probability because I want to see what I'd expect under the null distribution, which in this case is exactly that, i.e. $p_0 = (1/5,\dots,1/5)$. From this I'll obtain $$ T_j = \frac 1{112}\sum_{i=1}^{112} X_{ij} $$ so for each simulated data set of 112 35-cell grids, I'll get a single quintuple $T_j$ giving the average number of each color that appeared in the 112 grids. You are concerned that your observed average, I'll call it $t$, is suspiciously far from the expected value under the null of $(7,7,7,7,7)$. I can therefore use my simulations to exactly test this: let $\mu_0 = (7,7,7,7,7)$, and for each $T_j$, compute $$ D_j = \|T_j - \mu_0\| = \sqrt{\sum_{k=1}^5 (T_{jk} - 7)^2} $$ (I'm using "$D$" to stand for "distance"). Thus I'll get $N$ simulated values of the Euclidean distance of the average number of each color from the expected number $\mu_0$ under the null hypothesis. I can then compute $d = \|t - \mu_0\|$ and see how that compares. I did this in R and here's the result: The red line is your observed value of this statistic. Just as a quick check, this value is $$ \sqrt{(7.053571 - 7)^2 + (7.098214 - 7)^2 +(6.633929 - 7)^2 +(7.223214 - 7)^2 +(6.991071 - 7)^2} \approx 0.443 $$ just as shown in the figure. And that is a completely typical result under the null distribution so I don't see any evidence that your observed $t$ is suspiciously far from the expected one in terms of the Euclidean norm. Here's the code to do this: g There are tons of other things you could do here, like consider different norms, look at each coordinate by itself, or try more analytical methods such as the chi-squared test suggested in @astel's answer. But I like simulation because it's nice and simple, and I find it easier to do simulation-based approaches when I'm trying to reason about a problem that I don't know how to solve in advance. As for your concern about sample size, you need to be more clear about what you want to detect. If you say that you want to detect any difference, then there is a sample size sufficient to do that with high probability but it could be astronomical. Suppose in truth the probability of a purple square is not $0.2$ as it would be under $H_0$ but instead is $0.1999999$. As $n\to\infty$ you will eventually reject with high probability but the required sample size is going to be enormous. The point of this is to say that when you ask "is the sample size big enough", the only real answer is "for what?". To emphasize this point, I did another simulation. I'm allowing $n$ to vary so I'll be simulating $X_{ij}^{(n)}$ and I'll get $N$ $D_j^{(n)}$ for each $n$ under consideration. I'll take $\Delta^{(n)} = E(D_j^{(n)})$, and for each $n$ I'll obtain a 95% quantile-based confidence interval for $\Delta^{(n)}$ via my simulation. I did this for $n = 50,100,150,\dots,900,950,1000$ so you can see how the confidence interval at 95% changes as $n$ increases. Again, the red line is your observed value. So for the particular $t$ you observed, even though with $n=112$ we saw no evidence of there being a meaningful deviation, we'd start rejecting this once $n \approx 400$. But the point of this is that that's not the right way to look at this. If this is a real situation you know the probabilities aren't EXACTLY $(1/5,\dots,1/5)$. Instead, you want to make sure you reject when the difference is big enough to matter, which requires using domain knowledge to decide what "big enough to matter" means here. Here's the code for that plot: nseq
