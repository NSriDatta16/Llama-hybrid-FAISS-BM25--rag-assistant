[site]: crossvalidated
[post_id]: 230093
[parent_id]: 229634
[tags]: 
I'm going to use a different notation to that you used in your question for this answer. We say $X_n$ (for $n >= 0$) is a markov chain with initial distribution $\lambda$ and transition matrix $P$ if for all $n >= 0$ and states $i_0, i_1, ..., i_{n+1}$ if the two conditions below are met: (i) $P(X_0 = i_0) = \lambda_{i_0}$, which is the initial state distribution (ii) $P(X_{n+1} = i_{n+1} | X_0 = i_0, ... , X_n = i_n) = P(X_{n+1} = i_{n+1} | X_n = i_n) = P_{i_n i_{n+1}}$ where $P_{i_n i_{n+1}}$ is the transition from state $i_n$ to $i_{n+1}$. With regards to predicting probabilities of future states, you refer to both probabilities and states with the same notation. But I think I understand what you mean. If you knew the initial state distribution, and wanted to predict the probabilities of future distributions, you wouldn't really have an iterative function. If you look at the probability $P(X_0 = i_0, X_1 = i_1, ... , X_n = i_n)$ you are asking the question "what is the probability that I start in $i_0$ at time $0$, and then moved to $i_1$ ... then finish in $i_{n}$ at time $n$?". You would then get: $= P(X_0 = i_0)P(X_1 = i_1 | P(X_0 = i_0)...P(X_n = i_n | X_{n-1} = i_{n-1})$ $= \lambda_{i_0}P_{i_0 i_1}...P_{i_{n-1}i_n}$ (The proof of the above can be found here on page 2: http://www.statslab.cam.ac.uk/~rrw1/markov/M.pdf ) You would use the initial distribution only when you are working with $X_0$ in the sense that you wouldn't need to use it if you are finding a conditional probability. Now if you knew $x_0$ and $x_k$, which I interpret at $X_0$ and $X_k$ I assume you want to know the answer to $P(X_k = i_k | X_0 = i_0 )$. Because you are only specifying one condition, that the chain starts at a certain state at $X_0$, there are many paths to get to its final destination at time $k$. So you would have to calculate the probability for every path (e.g. $\lambda_{i_0}P_{i_0 i_4}P_{i_4 i_3}.... P_{i_{k-1} i_k}$) and sum them up, this post might explain it better: Checking whether a given formula is correct for a homogeneous Markov chain . A shorter calculation would just be to look at the transition from $i_0$ to $i_k$ on the calculated transition matrix $\lambda_{i_0} P_{i_0 i_n}^{(k)}$. Finally for references: 'Introduction to Stochastic Modelling' by Howard Taylor and Samuel Karlin is a great book which I am reading now. Chapter 3 focuses on these issues you are dealing with.
