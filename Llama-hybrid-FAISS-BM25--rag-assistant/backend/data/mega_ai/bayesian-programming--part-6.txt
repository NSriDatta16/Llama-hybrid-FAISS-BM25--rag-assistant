the system is in state S t {\displaystyle S^{t}} ; on an initial state at time 0 {\displaystyle 0} : P ( S 0 ∧ O 0 ) {\displaystyle P(S^{0}\wedge O^{0})} . Parametrical forms The parametrical forms are not constrained and different choices lead to different well-known models: see Kalman filters and Hidden Markov models just below. Question The typical question for such models is P ( S t + k ∣ O 0 ∧ ⋯ ∧ O t ) {\displaystyle P\left(S^{t+k}\mid O^{0}\wedge \cdots \wedge O^{t}\right)} : what is the probability distribution for the state at time t + k {\displaystyle t+k} knowing the observations from instant 0 {\displaystyle 0} to t {\displaystyle t} ? The most common case is Bayesian filtering where k = 0 {\displaystyle k=0} , which searches for the present state, knowing past observations. However, it is also possible ( k > 0 ) {\displaystyle (k>0)} , to extrapolate a future state from past observations, or to do smoothing ( k < 0 ) {\displaystyle (k<0)} , to recover a past state from observations made either before or after that instant. More complicated questions may also be asked as shown below in the HMM section. Bayesian filters ( k = 0 ) {\displaystyle (k=0)} have a very interesting recursive property, which contributes greatly to their attractiveness. P ( S t | O 0 ∧ ⋯ ∧ O t ) {\displaystyle P\left(S^{t}|O^{0}\wedge \cdots \wedge O^{t}\right)} may be computed simply from P ( S t − 1 ∣ O 0 ∧ ⋯ ∧ O t − 1 ) {\displaystyle P\left(S^{t-1}\mid O^{0}\wedge \cdots \wedge O^{t-1}\right)} with the following formula: P ( S t | O 0 ∧ ⋯ ∧ O t ) = P ( O t | S t ) × ∑ S t − 1 [ P ( S t | S t − 1 ) × P ( S t − 1 | O 0 ∧ ⋯ ∧ O t − 1 ) ] {\displaystyle {\begin{array}{ll}&P\left(S^{t}|O^{0}\wedge \cdots \wedge O^{t}\right)\\=&P\left(O^{t}|S^{t}\right)\times \sum _{S^{t-1}}\left[P\left(S^{t}|S^{t-1}\right)\times P\left(S^{t-1}|O^{0}\wedge \cdots \wedge O^{t-1}\right)\right]\end{array}}} Another interesting point of view for this equation is to consider that there are two phases: a prediction phase and an estimation phase: During the prediction phase, the state is predicted using the dynamic model and the estimation of the state at the previous moment: P ( S t | O 0 ∧ ⋯ ∧ O t − 1 ) = ∑ S t − 1 [ P ( S t | S t − 1 ) × P ( S t − 1 | O 0 ∧ ⋯ ∧ O t − 1 ) ] {\displaystyle {\begin{array}{ll}&P\left(S^{t}|O^{0}\wedge \cdots \wedge O^{t-1}\right)\\=&\sum _{S^{t-1}}\left[P\left(S^{t}|S^{t-1}\right)\times P\left(S^{t-1}|O^{0}\wedge \cdots \wedge O^{t-1}\right)\right]\end{array}}} During the estimation phase, the prediction is either confirmed or invalidated using the last observation: P ( S t ∣ O 0 ∧ ⋯ ∧ O t ) = P ( O t ∣ S t ) × P ( S t | O 0 ∧ ⋯ ∧ O t − 1 ) {\displaystyle {\begin{aligned}&P\left(S^{t}\mid O^{0}\wedge \cdots \wedge O^{t}\right)\\={}&P\left(O^{t}\mid S^{t}\right)\times P\left(S^{t}|O^{0}\wedge \cdots \wedge O^{t-1}\right)\end{aligned}}} Bayesian program P r { D s { S p ( π ) { V a : S 0 , ⋯ , S T , O 0 , ⋯ , O T D c : { P ( S 0 ∧ ⋯ ∧ S T ∧ O 0 ∧ ⋯ ∧ O T | π ) = P ( S 0 ∧ O 0 ) × ∏ t = 1 T [ P ( S t | S t − 1 ) × P ( O t | S t ) ] F o : { P ( S 0 ∧ O 0 ) P ( S t | S t − 1 ) P ( O t | S t ) I d Q u : { P ( S t + k | O 0 ∧ ⋯ ∧ O t ) ( k = 0 ) ≡ Filtering ( k > 0 ) ≡ Prediction ( k < 0 ) ≡ Smoothing {\displaystyle Pr{\begin{cases}Ds{\begin{cases}Sp(\pi ){\begin{cases}Va:\\S^{0},\cdots ,S^{T},O^{0},\cdots ,O^{T}\\Dc:\\{\begin{cases}&P\left(S^{0}\wedge \cdots \wedge S^{T}\wedge O^{0}\wedge \cdots \wedge O^{T}|\pi \right)\\=&P\left(S^{0}\wedge O^{0}\right)\times \prod _{t=1}^{T}\left[P\left(S^{t}|S^{t-1}\right)\times P\left(O^{t}|S^{t}\right)\right]\end{cases}}\\Fo:\\{\begin{cases}P\left(S^{0}\wedge O^{0}\right)\\P\left(S^{t}|S^{t-1}\right)\\P\left(O^{t}|S^{t}\right)\end{cases}}\end{cases}}\\Id\end{cases}}\\Qu:\\{\begin{cases}{\begin{array}{l}P\left(S^{t+k}|O^{0}\wedge \cdots \wedge O^{t}\right)\\\left(k=0\right)\equiv {\text{Filtering}}\\\left(k>0\right)\equiv {\text{Prediction}}\\\left(k<0\right)\equiv {\text{Smoothing}}\end{array}}\end{case