[site]: crossvalidated
[post_id]: 289172
[parent_id]: 
[tags]: 
Half-half cross-validation with logistic regression: is there a rule of thumb for whether resampling is needed?

I need to perform a logistic regression. The paper "Cross-Validation for Selecting a Model Selection Procedure" ( pdf ) seems to suggest that the best method for feature selection is repeated-sample (they perform 400 repetitions) half-half cross-validation (CV), and for model evaluation is leave-one-out CV. However, I have a very large dataset (63 thousand observations). I have read that the larger the dataset, the less we should worry about overfitting. Thus, my questions are: Can I just be satisfied with performing half-half CV once? Is there a rule of thumb linking the dataset's size with the number of repetitions or, more generally, the complexity of the model-selection (and possibly of the validation) procedure? I suspect that if such a rule of thumb exists, in the case of logistic regression it should take not only the global sample size, but also the minimum number between events and non-events into account (as it is the case with the number of parameters that makes sense to include in a logistic regression). Edit: Thanks Harshit for your reply. The reason why I want to compare different models is not that I want to drop the variables that have a coefficient very near to zero, but that I want to choose among different versions of the same variables, i.e.: whether including a continuous variable as it is or as a binary variable (using the median as cut-off), and which version of categorical variables to include (i.e., whether grouping variables in just 2 categories or more). Thus I don't think Lasso regression makes sense in my case.
