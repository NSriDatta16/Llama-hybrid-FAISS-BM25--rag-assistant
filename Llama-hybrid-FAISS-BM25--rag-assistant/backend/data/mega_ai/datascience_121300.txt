[site]: datascience
[post_id]: 121300
[parent_id]: 
[tags]: 
Unsupervised SimCSE not Learning Good Representations

I'm using the unsupervised SimCSE approach to train a semantic embedding model on a corpus of tag documents. That is, ordered lists of tags concatenated into white-space seperated strings. I use a pretrained language model on the same corpus. It seems that the cosine loss reduces very quickly and then fluctates somewhat randomly. Looking at the cosine similarity across the batch early on in the training procedure, it seems that the problem just isn't that hard. Diagonals should be similar and everything else should be different and that is the case from very early in the training procedure. My corpus is too different from standard benchmarks to use downstream tasks to evaluate the effectiveness of the embeddings on downstream tasks unfortuantely, so I need to rely on training/evaluation loss and eyeballing the model similarities for evaluation. It seems to me that the model is just trivially solving the semantic embedding task because batch samples aren't similar enough to need to learn appropriate contrastive representations. Does anyone have any experience with this behaviour and what might be causing the problem?
