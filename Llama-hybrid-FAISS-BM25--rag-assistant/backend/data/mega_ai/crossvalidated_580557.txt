[site]: crossvalidated
[post_id]: 580557
[parent_id]: 
[tags]: 
How to do deal with varying performance across a wide range of parameters?

We are working on a recommendation system. Our data comes from varying sources that make it natural to train a model for each source. Now we come to the crux. For each of the data sources we get varying performance for the used model: random forest, ridge regression, association rule mining, xgboost the hyperparameters of the chosen model: alpha, number of estimators etc. parameters for how the data is fed into the model like: window size or relearn interval Unfortunately there seems to be no combination that works best for all our data sources. In the end this forces us to train with all combinations for each data source to get the best performance. Now we are wondering if there is a way out of this computational mess. Edit: The reason why a different model for every source seems reasonable, is that the different sources lead to mostly non-overlapping feature sets and recommendation options.
