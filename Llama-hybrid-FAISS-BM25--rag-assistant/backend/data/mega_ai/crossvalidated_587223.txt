[site]: crossvalidated
[post_id]: 587223
[parent_id]: 587134
[tags]: 
This method of generating train/test splits is very similar to cross-validation, so you shouldn't have problems with overfitting - in fact one of the reasons it was used was to help prevent overfitting. One benefit over cross-validation is that the size of the test set is not dictated by the number of test folds. Which is useful in this case as it meant the authors could generate the same number of train/test splits for all the datasets used in the evaluation, even when there are fewer cases in the dataset than the required number of test folds. The main draw-back is the one you've already mentioned - it requires more computing resources than (for example) a single train/test split. As for the number of splits to use, "The Great Time Series Classification Bake Off" you reference used 100 splits. Other more recent papers proposing time series classifiers, such as Tan et al. "MultiRocket: multiple pooling operators and transformations for fast and effective time series classification" , have used 30 splits.
