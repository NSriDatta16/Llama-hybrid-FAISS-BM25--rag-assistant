[site]: crossvalidated
[post_id]: 354374
[parent_id]: 354305
[tags]: 
First, I would make boxplots of the six groups, all in the same figure, to get a preliminary view. Below are such boxplots for fake data (simulated in R): Classes 1-3 have average GPA 4.0 with SD .25; Classes 4-6 have average GPA 3.5 with SD .30. The differences in means and the differences in SDs both show fairly clearly. If this analysis of class GPAs is just for your own personal curiosity, you might stop here. x = c(rnorm(99, 4, .25), rnorm(99, 3.5, .3)) g = as.factor(rep(1:6, each=33)) boxplot(x ~ g, col="skyblue2", pch=19, ylab="GPA", xlab="Class") Second, in almost any textbook that gives serious treatment to one-factor ANOVA you will find several tests to see if group variances are equal. Tests for equality of variance are notoriously of low power (not always finding real differences). You can try one of them to see what it finds. For normal data, the Bartlett test is a popular choice. For the fake data generated above, the null hypothesis that all groups come from populations with one common variance is rejected, P-value 0.001. You could use two-sample tests (perhaps var.test ) to see which specific groups have different variances. bartlett.test(x, g) Bartlett test of homogeneity of variances data: x and g Bartlett's K-squared = 20.038, df = 5, p-value = 0.001229 Finally, even if variances are not equal, you can still test whether the groups have equal means. You could use a 'Welch' one-way ANOVA test that uses approximation similar to those of the Welch 'separate-variances' two-sample t test. With 30ish students in each group, this test should work well. (I would probably use it in preference to a standard one-way ANOVA with groups as large as 30, even if the Bartlett test detected no differences among variances. But apparently there have not yet been enough simulation studies on the performance of this test to say mine is a general accepted view.) In R, the procedure oneway.test performs this test. It clearly finds significant differences among groups: oneway.test(x ~ g) One-way analysis of means (not assuming equal variances) data: x and g F = 33.377, num df = 5.000, denom df = 89.084, p-value One of several ways to make paired comparisons to see where the significant differences lie is the R procedure pairwise . Not surprisingly, it finds no significant differences among groups 1-3, and none among groups 4-6, but does find 1-3 to differ significantly from 4-6. pairwise.t.test(x, g) Pairwise comparisons using t tests with pooled SD data: x and g 1 2 3 4 5 2 1 - - - - 3 1 1 - - - 4 3.2e-09 3.4e-10 6.6e-10 - - 5 2.4e-10 2.4e-11 4.7e-11 1 - 6 2.6e-10 2.7e-11 5.1e-11 1 1 P value adjustment method: holm Note: My main purpose has been to give you some clue what is available. For technical details, you can google to find very many R documentation and help pages.
