[site]: datascience
[post_id]: 12147
[parent_id]: 
[tags]: 
Gradient Boosted Trees or Neural Networks Using Model Averaging?

I am working on a certain insurance claims related data-set to classify newly acquired customers as either claim or non-claim . The basic problem with the training set is the extremely large imbalance in claim and non-claim profiles, with the claims amounting to just ~ 0.26% of the training set. Also, most claims are concentrated largely towards the final few years (data is sorted by date). On applying Logistic Regression or even Random Forests, to train on 70% of the data, the test results were well below satisfactory. I've been looking at alternate models and I came across this blog post . A particular line that got my attention is: GBM is better than rf_t. In the paper, the best classifier for two-class data sets was avNNet_t, with 83.0% accuracy Although, no real clarification was given as to why that was. Can someone help me open this "blackbox"? Which model really works (in the case described above) and why ?
