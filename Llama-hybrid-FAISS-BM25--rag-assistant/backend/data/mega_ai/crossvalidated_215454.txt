[site]: crossvalidated
[post_id]: 215454
[parent_id]: 
[tags]: 
CNN. Why convolution and composition?

About convolution: prof. Brad Osgood said during the course EE-261 said that we can not fully "visualize" convolution. E.g. https://see.stanford.edu/materials/lsoftaee261/book-fall-07.pdf , p.105: "Now, tell the truth, do you really think you could just flip and drag and figure out what the convolution looks like of that thing with some other thing?" p.99: "What is Convolution, Really? There’s not a single answer to that question." "In brief, we’ll get to know the convolution by seeing it in action: Convolution is what convolution does." Via this I want to emphasize that: even from computational point of view - convolution is understandable operation, but from more deep point of view it is not. It isn't obvious how to design kernel even for 1D signals. About composition: For a long time mathematicians and physicist use superposition approach to analyze difficult thing via summ of elementary terms, e.g.: Taylor series Fourier Series Total acceleration of the point is proportional to the sum of forces in point Structure of solution of system of linear algebraic equation and ordinary differential equation I mean tha "sum" is very fundamental thing. Instead of using sum computer scientists decide to use compoistion for model neural network. But beside chain rule for differentiation there are (at least known for me) no useful equation for analyze g(f(x)). I can describe it via similar sentence as for convolution even from computational point of view - convolution is understandable operation, but from more deep point of view it is not. Question: So my point is in that such structure lead to not understanable model for humans. I want to understand why this two not so obvious operations have been choosen as building blocks in this field.
