[site]: crossvalidated
[post_id]: 636646
[parent_id]: 440595
[tags]: 
WHY? A troubling point with t-SNE is that it does not give a functional relationship between the high-dimension space and the reduced-dimension space, limiting the usefulness of t-SNE. For instance, if you want to reduce the dimension of a predictive model, when you go to predict on new data, you do not have a way to do so. This is in contrast to, say, PCA (Principal Components Analysis), where you can apply the eigenvectors from some training data to extract features from new data (either for out-of-sample testing or on entirely new data being predicted in production). Consequently, t-SNE is at its most useful when you just want to visualize high-dimensional data, hence the emphasis on reducing to the two dimensions where our vision operates. You can’t visualize data in $80$ or $100$ dimensions, and you can’t do much beyond visualize with the t-SNE results, so I wonder why one would bother to reduce to a dimension where visualization is not feasible. An alternative to t-SNE that does allow you to apply the transformation to new data is UMAP: Universal Manifold Approximation and Projection.
