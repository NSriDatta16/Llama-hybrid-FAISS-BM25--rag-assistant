[site]: crossvalidated
[post_id]: 130798
[parent_id]: 130775
[tags]: 
1) rarely do people only want to estimate. Usually inference - CIs, PIs, tests - is the aim, or at least part of it (even if sometimes it's done relatively informally) 2) Things like the Gauss Markov theorem isn't necessarily much help -- if the distribution is sufficiently far from normal, a linear estimator is not much use. There's no point in getting the BLUE if no linear estimator is very good. 3) things like sandwich estimators involve a large number of implicit parameters. It may still be okay if you have a lot of data, but many times people don't. 4) Prediction intervals rely on the conditional distribution's shape including having a good handle on the variance at the observation - you can't quite so easily wave the details away with a PI. 5) things like bootstrapping are often handy for very large samples. They sometimes struggle in small samples -- and even in moderately sized samples, frequently we find that the actual coverage properties are nothing like advertized. Which is to say -- few things are the sort of panacea people would like them to be. All of those things have their place, and there are certainly plenty of cases where (say) normality is not required, and where estimation and inference (tests and CIs) can reasonably be done without necessarily needing normality, constant variance and so on. One thing that often seems to be forgotten is other parametric assumptions that could be made instead. Often people know enough about a situation to make a fairly decent parametric assumption (e.g. say... that the conditional response will tend to be right skew with s.d. pretty much proportional to mean might lead us to consider say a gamma or lognormal model); often this may deal with both the heteroskedasticity and the non-normality in one go. A very useful tool is simulation -- with that we can examine the properties of our tools in situations very like those it appears our data may have arisen from, and so either use them in the comforting knowledge that they have good properties in those cases (or, sometimes, see that they don't work as well as we might hope).
