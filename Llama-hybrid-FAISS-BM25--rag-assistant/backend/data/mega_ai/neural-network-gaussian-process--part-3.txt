{\displaystyle y^{l}} . The covariance or kernel of this Gaussian process depends on the weight and bias variances σ w 2 {\displaystyle \sigma _{w}^{2}} and σ b 2 {\displaystyle \sigma _{b}^{2}} , as well as the second moment matrix K l {\displaystyle K^{l}} of the preceding activations y l {\displaystyle y^{l}} , z i l ∣ y l ∼ G P ( 0 , σ w 2 K l + σ b 2 ) K l ( x , x ′ ) = 1 n l ∑ i y i l ( x ) y i l ( x ′ ) {\displaystyle {\begin{aligned}z_{i}^{l}\mid y^{l}&\sim {\mathcal {GP}}\left(0,\sigma _{w}^{2}K^{l}+\sigma _{b}^{2}\right)\\K^{l}(x,x')&={\frac {1}{n^{l}}}\sum _{i}y_{i}^{l}(x)y_{i}^{l}(x')\end{aligned}}} The effect of the weight scale σ w 2 {\displaystyle \sigma _{w}^{2}} is to rescale the contribution to the covariance matrix from K l {\displaystyle K^{l}} , while the bias is shared for all inputs, and so σ b 2 {\displaystyle \sigma _{b}^{2}} makes the z i l {\displaystyle z_{i}^{l}} for different datapoints more similar and makes the covariance matrix more like a constant matrix. z l | K l {\displaystyle z^{l}|K^{l}} is a Gaussian process The pre-activations z l {\displaystyle z^{l}} only depend on y l {\displaystyle y^{l}} through its second moment matrix K l {\displaystyle K^{l}} . Because of this, we can say that z l {\displaystyle z^{l}} is a Gaussian process conditioned on K l {\displaystyle K^{l}} , rather than conditioned on y l {\displaystyle y^{l}} , z i l ∣ K l ∼ G P ( 0 , σ w 2 K l + σ b 2 ) . {\displaystyle {\begin{aligned}z_{i}^{l}\mid K^{l}&\sim {\mathcal {GP}}\left(0,\sigma _{w}^{2}K^{l}+\sigma _{b}^{2}\right).\end{aligned}}} As layer width n l → ∞ {\displaystyle n^{l}\rightarrow \infty } , K l ∣ K l − 1 {\displaystyle K^{l}\mid K^{l-1}} becomes deterministic As previously defined, K l {\displaystyle K^{l}} is the second moment matrix of y l {\displaystyle y^{l}} . Since y l {\displaystyle y^{l}} is the activation vector after applying the nonlinearity ϕ {\displaystyle \phi } , it can be replaced by ϕ ( z l − 1 ) {\displaystyle \phi \left(z^{l-1}\right)} , resulting in a modified equation expressing K l {\displaystyle K^{l}} for l > 0 {\displaystyle l>0} in terms of z l − 1 {\displaystyle z^{l-1}} , K l ( x , x ′ ) = 1 n l ∑ i ϕ ( z i l − 1 ( x ) ) ϕ ( z i l − 1 ( x ′ ) ) . {\displaystyle {\begin{aligned}K^{l}(x,x')&={\frac {1}{n^{l}}}\sum _{i}\phi \left(z_{i}^{l-1}(x)\right)\phi \left(z_{i}^{l-1}(x')\right).\end{aligned}}} We have already determined that z l − 1 | K l − 1 {\displaystyle z^{l-1}|K^{l-1}} is a Gaussian process. This means that the sum defining K l {\displaystyle K^{l}} is an average over n l {\displaystyle n^{l}} samples from a Gaussian process which is a function of K l − 1 {\displaystyle K^{l-1}} , { z i l − 1 ( x ) , z i l − 1 ( x ′ ) } ∼ G P ( 0 , σ w 2 K l − 1 + σ b 2 ) . {\displaystyle {\begin{aligned}\left\{z_{i}^{l-1}(x),z_{i}^{l-1}(x')\right\}&\sim {\mathcal {GP}}\left(0,\sigma _{w}^{2}K^{l-1}+\sigma _{b}^{2}\right).\end{aligned}}} As the layer width n l {\displaystyle n^{l}} goes to infinity, this average over n l {\displaystyle n^{l}} samples from the Gaussian process can be replaced with an integral over the Gaussian process: lim n l → ∞ K l ( x , x ′ ) = ∫ d z d z ′ ϕ ( z ) ϕ ( z ′ ) N ( [ z z ′ ] ; 0 , σ w 2 [ K l − 1 ( x , x ) K l − 1 ( x , x ′ ) K l − 1 ( x ′ , x ) K l − 1 ( x ′ , x ′ ) ] + σ b 2 ) {\displaystyle {\begin{aligned}\lim _{n^{l}\rightarrow \infty }K^{l}(x,x')&=\int dz\,dz'\,\phi (z)\,\phi (z')\,{\mathcal {N}}\left(\left[{\begin{array}{c}z\\z'\end{array}}\right];0,\sigma _{w}^{2}\left[{\begin{array}{cc}K^{l-1}(x,x)&K^{l-1}(x,x')\\K^{l-1}(x',x)&K^{l-1}(x',x')\end{array}}\right]+\sigma _{b}^{2}\right)\end{aligned}}} So, in the infinite width limit the second moment matrix K l {\displaystyle K^{l}} for each pair of inputs x {\displaystyle x} and x ′ {\displaystyle x'} can be expressed as an integral over a 2d Gaussian, of the product of ϕ ( z ) {\displaystyle \phi (z)} and ϕ ( z ′ ) {\displaystyle \phi (z')} . There are a number of situations where this has been 