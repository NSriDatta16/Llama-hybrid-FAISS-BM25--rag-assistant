[site]: crossvalidated
[post_id]: 593543
[parent_id]: 593516
[tags]: 
The main problem here is that the observations within each subject are not independent. Thus the standard errors of your estimates of the parameters of your model will tend to be too narrow. A well respected way to "take care of" repeated measures in models fit by maximum likelihood is to keep the same point estimates of coefficients but take the clustering of observations within subjects into account. One way this is done is by calculating a robust, "sandwich" version of the coefficient covariance matrix. The survreg() function of the R survival package provides a cluster argument through which you can specify which observations come from which individuals to get a robust coefficient covariance matrix. That function can accept Surv() values as outcomes that cover all the types of censoring that you have, and provides your "loglogistic" distribution family as an option. An alternative cluster implementation that might work immediately would be to use the tools of the sandwich package on the object returned by the fitdistcen() function and a specification of subject identifiers in a cluster argument. I don't know if the sandwich tools will work on that type of model object, however. Another approach is cluster bootstrapping . Instead of repeated sampling with replacement from the individual observations as in standard bootstrapping, you resample with replacement from the subjects , keeping all of each selected subject's individual observations in as many copies as the individual is represented in the bootstrap sample. That mimics the process of repeated sampling of subjects from the underlying population. You model each cluster-bootstrap sample as you did the full data set, keeping the corresponding coefficient covariance matrix returned by the vcov() function from the fitdistcen object. Do a few hundred such samples, and report the average of the coefficient covariance matrices. That represents the estimated error due to differences among the individuals in the population rather than the covariances weighted toward within-individual distributions returned in your original model. Fitting a fully parametric random-effects model to this type of censored data is beyond my intellectual PTT. If that's what you want, I suspect that you will be best served by Bayesian modeling. The brms package allows for censored outcomes via its addition-terms . Section 25.4 of this document illustrates how to handle censored data in brms .
