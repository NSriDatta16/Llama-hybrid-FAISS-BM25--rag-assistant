[site]: stackoverflow
[post_id]: 5410523
[parent_id]: 5410345
[tags]: 
For profiling you can add quite a few options to the app when you run it. Firstly you can add "+RTS -sstderr". This gives you the broad stats that you described so I guess you already know this! 1,835,837,744 bytes allocated in the heap 328,944,448 bytes copied during GC 2,908,728 bytes maximum residency (25 sample(s)) 142,056 bytes maximum slop 9 MB total memory in use (1 MB lost due to fragmentation) Generation 0: 3483 collections, 0 parallel, 1.54s, 1.54s elapsed Generation 1: 25 collections, 0 parallel, 0.09s, 0.07s elapsed INIT time 0.00s ( 0.00s elapsed) MUT time 3.04s ( 3.13s elapsed) GC time 1.63s ( 1.61s elapsed) RP time 0.00s ( 0.00s elapsed) PROF time 0.00s ( 0.00s elapsed) EXIT time 0.00s ( 0.00s elapsed) Total time 4.67s ( 4.74s elapsed) %GC time 34.9% (34.0% elapsed) Alloc rate 603,893,994 bytes per MUT second Productivity 65.1% of total user, 64.2% of total elapsed As you can see from the example output above, I write some pretty bad Haskell. You can delve into this more with some additional options and improve things. -prof - Enables profiling -caf-all - Constant Applicative form for all top-level items (constant costs, one for each module.) -auto-all - Cost-centre analysis for every top-level function Once you get the profiling information out, you can print out pretty pictures like the one below ( hp2ps ). This shows allocation rates. As you can see from below it's pretty simple to find the function that's doing too much work. Whilst this doesn't give per type information, it does help isolate what's happening. I found Real World Haskell to be tremendously useful.
