[site]: crossvalidated
[post_id]: 122094
[parent_id]: 
[tags]: 
Does the central limit theorem apply to these probability density functions?

Let's say you have n uniform random variables from 0 to 1. The distribution of the average of these variables approaches normal with increasing n according to the central limit theorem. What if however, instead of all the variables being random, one of them was guaranteed to be 0, and one of them was guaranteed to be 1. This would arise in the following case: Let's say you have n=7 randomly generated numbers from 0 to 1 and they are, from smallest to largest, [.1419 .1576 .4854 .8003 .9572 .9649 .9706]. If you were to subtract the smallest number from all of the numbers and then divide all the numbers by the new maximum you would end up with [0 .0189 .4145 .7945 .9838 .9931 1]. In this way you have a set of n numbers where n-2 of them are random and the other two are guaranteed to be 0 and 1. I would like to know whether the central limit theorem still applies to numbers generated in this way. By visual inspection using MATLAB, it actually appears to approach normal quicker than when the numbers are all random, but I would like a mathematical reason as to why, especially considering that the central limit theorem states that all the numbers must be random.
