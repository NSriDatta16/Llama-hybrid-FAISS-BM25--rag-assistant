[site]: crossvalidated
[post_id]: 379136
[parent_id]: 377693
[tags]: 
Variable importance is not straightforward in linear regression since variables might be correlated. However, its a good practice to do the following when preparing your data for training models: Ensure all variables representing the same quantities are in the same units (all distance in meters, weights in grams, or as per the scale suitable to the problem) Scale all variables to zero mean and unit standard deviation Determining the importance of variables in linear regression A popular approach to determine variable importance for linear regression models is to decompose the $R^2$ into contributions attributed to each variable. Refer to the document describing the PMD method (Feldman, 2005) . Another popular approach is averaging over orderings (LMG, 1980). The LMG works like this: Find the semi-partial correlation of each predictor in the model, e.g. for variable a we have: $SS_a/SS_{total}$ . It implies how much would $R^2$ increase if variable $a$ were added to the model. Calculate this value for each variable for each order in which the variable gets introduced into the model, i.e. { $a,b,c$ } ; { $b,a,c$ } ; { $b,c,a$ } Find the average of the semi-partial correlations for each of these orders. This is the average over orderings. The R package relaimpo implements 6 different metrics for assessing relative importance of variables in the linear regression model, including averaging over orderings of regressors and pmvd. relaimpo also gives bootstrap confidence intervals. References: Relative importance of Linear Regressors in R Relative Importance and Value, Barry Feldman (PMD method)
