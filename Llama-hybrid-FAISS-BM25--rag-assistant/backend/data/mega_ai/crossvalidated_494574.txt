[site]: crossvalidated
[post_id]: 494574
[parent_id]: 
[tags]: 
Clarification for $\beta = {\{\beta_{10},\beta_1}\} $ when fitting logistic regression and the number of classes is k=2

I was learning from Elements of statistics p.120 under section 4.4.1 Fitting Logistics Regression Models The log likelihood function was given as $l(\beta) = \sum_{i=1}^N {y_i\log p(x_i;\beta) + (1-y_i)log(1-p(x_i;\beta))}$ Here $$\beta = {\{\beta_{10},\beta_1}\} \qquad (1)$$ and we assume that the vector of inputs $x_i$ includes the constant term 1 to accommodate the intercept. Please my question is : Assuming we have only two inputs $X$ = $X_1$ + $X_2$ and adding the intercept or constant term ( $X_0)$ that contains only 1's, we will have $X$ = $X_1 + X_2 + X_0$ . When we find $\beta$ using linear regression, it will be a vector in $R^3$ or the vector will contain three elements i.e $\beta = \{ b_1,b_2,b_3 \}$ How did they get $\beta_{10}$ in $(1)$ and also I want to know if $\beta_{10}$ and $\beta_1$ in $(1)$ are scalars or their vectors
