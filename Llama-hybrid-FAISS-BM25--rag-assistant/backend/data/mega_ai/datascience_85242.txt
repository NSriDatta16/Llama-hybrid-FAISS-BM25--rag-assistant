[site]: datascience
[post_id]: 85242
[parent_id]: 
[tags]: 
Different feature importance results between DNN, Random Forests and Gradient Boosted Decision Trees

I've been modeling metabolite data with 3 different regressor models. I get similar results from running feature importance with Random Forest model and Gradient Boosted Decision Trees (where I used the scikit-learn built-in feature importance), but with Deep Neural Networks I get very different results (used permutation feature importance). I also ran PCA, and PCA gave me similar results to DNN! Is this normal? Could both of them be accurate still? I have quite a large amount of initial features.
