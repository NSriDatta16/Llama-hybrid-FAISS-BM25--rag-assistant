[site]: stackoverflow
[post_id]: 5321035
[parent_id]: 5319861
[tags]: 
How about separating traversal from any other processing? Perhaps create a work queue ( MailboxProcessor is a good starting point) and, as the tree is traversed, enqueue additional work for background processing. It doesn't solve the parallel traversal problem (which seems tricky to get right for all cases) but with additional processing relegated to the background, it should go pretty quickly. You can experiment with the number of background workers until you find a good degree of parallelism. This all assumes the amount of work to be done for each node is non-trivial. EDIT Here's some code. I'm sure it can be improved. I had to hammer it out pretty quickly. But this shows the basic concept. It only has one "background worker," i.e., the MailboxProcessor . I'll leave updating it to use multiple workers to the imagination. type Msg = | Work of 'a | Done of 'b type MapTransformer(f) = let results = ResizeArray() let m = MailboxProcessor.Start(fun payload -> let rec loop() = async { let! msg = payload.Receive() match msg with | Work work -> results.Add(f work) return! loop() | Done (channel : AsyncReplyChannel ) -> channel.Reply(results :> seq ) } loop()) member this.Enqueue(item) = m.Post(Work item) member this.Results = m.PostAndReply(fun c -> Done c) let uberMap tree = let m = MapTransformer(fun x -> x + 1) tree |> List.iter (fun x -> m.Enqueue(x)) m.Results uberMap [1; 2; 3] //outputs [2; 3; 4]
