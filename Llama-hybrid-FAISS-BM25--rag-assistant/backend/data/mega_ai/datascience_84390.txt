[site]: datascience
[post_id]: 84390
[parent_id]: 84388
[tags]: 
From the structure you have outlined it looks like you're going for a dense fully-connected neural network. A general rule of thumb for practitioners on this topic is that increasing the size of a single hidden layer is more likely to yield a more performant network than adding successive layers. This is obviously not true in all cases - but as you are experimenting with architectures it is more useful to start by increasing the size of your one hidden layer before you jump to two of even three. See this for more details. I would recommend removing one of those hidden layers and increasing the number of nodes on the remaining. Something else to note: if you are looking at image data you might consider using convolutional layers. These are much more appropriate for problems with data that are spatially related (images etc..). If you do decide to go with this approach the previous advice does not apply as it relates only to simple dense multilayer perceptrons. Instead review this .
