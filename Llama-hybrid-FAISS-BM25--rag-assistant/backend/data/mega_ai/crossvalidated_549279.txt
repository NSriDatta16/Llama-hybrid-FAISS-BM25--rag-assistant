[site]: crossvalidated
[post_id]: 549279
[parent_id]: 549278
[tags]: 
I think this could be done using the parametric bootstrap. Since you have a model for the expected number of points, and you make assumptions about the distribution of those points, you can essentially simulate new data. The approach is as follows (I'll demonstrate using some R code). You have your data that you used to fit your model: # Simulating some data to use. nteams = 50 x = rnorm(nteams) lambda = 100*exp(-0.25*x) y = rpois(nteams, lambda) fit=glm(y~x, family = poisson()) From your model, for each team, you can predict the expected number of points: predicted_lambda = predict(fit, type='response') Do the following 1000 times: For each team, simulate a poisson random variable using the expected points from your model. nsims = 1000 # Store simulations here sim_results = matrix(rep(0, nteams*nsims), nrow = nsims) for(i in 1:nsims){ #Simulate new data based on the fit sim_results[i, ] = rpois(nteams, predicted_lambda) } For each simulation you just did, order each team from first to last for(i in 1:nsims){ # This is equivalent to argsort in something like numpy sim_results[i, ] = sort(sim_results[i,], index.return=T)$ix } You now have 1000 simulations of the ordering of each teams. All you have to do now is count the rankings each column. For example, here is the probability that one of my simulated teams winds up in the indicated spot sim_results[, 1] %>% table %>% prop.table() 3 6 7 8 12 14 19 20 25 28 35 39 43 50 0.012 0.025 0.036 0.012 0.010 0.019 0.117 0.054 0.030 0.002 0.123 0.003 0.556 0.001 In practice, you should also simulate the coefficients from their sampling distribution and use them to generate new predictions in each simulation step. I've spoken a little about this in this answer . The best approach, however, would be to use a Bayesian poisson regression (assuming the model is well specified) because you can integrate over all the uncertainty in the model.
