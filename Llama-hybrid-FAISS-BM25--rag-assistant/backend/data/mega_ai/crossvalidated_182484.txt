[site]: crossvalidated
[post_id]: 182484
[parent_id]: 179774
[tags]: 
Just for the sake of completeness I'm posting my working solution here (just the raw prototype, nothing beautified so far) import org.apache.spark.mllib.linalg.{ Vector, Vectors } import org.apache.spark.mllib.regression.LabeledPoint import org.apache.spark.mllib.classification.{ SVMModel, SVMWithSGD } import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics import org.apache.spark.mllib.tree.RandomForest import org.apache.spark.mllib.util.MLUtils var rdd = sc.textFile("/Users/romeokienzler/Documents/proj/eoc/ielsg26ALLsept_2015_IBM.csv") rdd.cache() val headerAndRows = rdd.map(line => line.split(",").map(_.trim)) val header = headerAndRows.first val data = headerAndRows.filter(_(0) != header(0)) //val maps = data.map(splits => header.zip(splits))O //val result = maps.filter(map => map("user") != "me") //convert date to number //convert % to number //convert . to zero //convert csv to array //convert empty strings to 0 //var matrix = rdd.map(s => s.replaceAll("/","")).map(s => //s.replaceAll("%","")).map(s => s.replace('.','0')).map(s => s.split(',')).map(a //=> a.map(e => if (e.length==0) "0" else e)) var matrix = data.map(a => a.map(s => s.replaceAll("/", "")).map(s => s.replaceAll("%", "")).map(s => s.replace('.', '0')).map(s => s.split(',')).map(a => a.map(e => if (e.length == 0) "0" else e))) //var matrix = data.map(s => s.replaceAll("/","")).map(s => //s.replaceAll("%","")).map(s => s.replace('.','0')).map(s => s.split(',')).map(a //=> a.map(e => if (e.length==0) "0" else e)) //convert double matrix to mllib matrix var matrixMLLib = matrix.map(a => a.map(aa => aa(0))).filter(a => a.length == 90).map(a => a.map(e => e.toDouble)).map(a => new LabeledPoint(a(83), Vectors.dense((a.slice(0, 83) ++ a.slice(84, a.length))))) //var matrixMLLib = matrix.map(a => a.map(e => e.toDouble)).filter(a=> //a.length==89).map(a => new //LabeledPoint(a(1),Vectors.dense((a.slice(2,a.length))))) val splits = matrixMLLib.randomSplit(Array(0.6, 0.2,0.2)) val (trainingData, testData, validationData) = (splits(0), splits(1),splits(2)) // Train a RandomForest model. // Empty categoricalFeaturesInfo indicates all features are continuous. val numClassesList = 2 :: 3 :: 4 :: 5 :: 6 :: 7 :: 8 :: 9 :: 10 :: Nil val categoricalFeaturesInfo = Map[Int, Int]() val numTreesList = 3 :: 5 :: 10 :: 30 :: 50 :: 70 :: 100 :: 150 :: Nil // Use more in practice. val featureSubsetStrategyList = "auto" :: "all" :: "sqrt" :: "log2" :: "onethird" :: Nil // Let the algorithm choose. val impurityList = "gini" :: "entropy" :: Nil val maxDepthList = 3 :: 5 :: 10 :: 15 :: 20 :: 25 :: 30 :: Nil val maxBinsList = 2 :: 5 :: 10 :: 15 :: 20 :: 25 :: 30 :: Nil var parametersAndScore: List[(Double, Int, Int, String, String, Int, Int)] = Nil for (numTrees val prediction = model.predict(point.features) (point.label, prediction) } val testErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / testData.count() println("Test Error = " + (testErr, numClasses, numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins)) parametersAndScore = (testErr, numClasses, numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins) :: parametersAndScore } } } } } } val optimalParameters = parametersAndScore.sortBy(_._1).sortBy(_._3).head //(0.0,3,10,auto,gini,3,2) val model = RandomForest.trainClassifier(trainingData, optimalParameters._2, categoricalFeaturesInfo ,optimalParameters._3, optimalParameters._4, optimalParameters._5,optimalParameters._6,optimalParameters._7) // Evaluate model on test instances and compute test error val labelAndPreds = validationData.map { point => val prediction = model.predict(point.features) (point.label, prediction) } val validationErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / validationData.count() println("Validation Error = " + validationErr) println("Learned classification forest model:\n" + model.toDebugString)
