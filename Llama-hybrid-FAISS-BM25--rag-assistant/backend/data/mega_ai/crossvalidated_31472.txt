[site]: crossvalidated
[post_id]: 31472
[parent_id]: 31462
[tags]: 
There is a distinction between feature selection, feature extraction, and dimensionality reduction. Feature selection: Choosing m of n features where, m Feature extraction: May include feature selection but can also be generative.It can create new feature dimensions based on existing features. Normally the set of generated and selected features, m, will be of a smaller size than the original feature set, n. Though potentially the new features might be used to enhance the available set of features. Normally m = n is possible. Dimensionality Reduction: Any method by which a set of data with n features is represented by m features, where m Depending upon the number of output nodes chosen for the Neural Network, they are fully capable of effecting dimensionality reduction. Consider a multi-layer neural network with N input neurons with each layer having one less neurons than the previous layer: layer sizes -> {N, N-1, N-2, ..., 1 }. Taking the outputs of any layer offers a reduced dimensionality representation of the input space in a set of transformed features, even to the limit of representing the input space in a single dimension. As your question was not about the primary goal of the Neural Networks but only about how they might be used for dimensionality reduction, as we have shown here it is certainly feasible that Neural Networks are capable of dimensionality reduction. The features you get with such a reduction, like those obtained with Principal Component Analysis, are not a selection of the original features but a transformation of those features and may not have a real physical interpretation. For example consider a feature comprised of ... 0.34 Age + 0.17 Height + 0.03 Eye Color + 0.2 Make of car owned. You may find the best performance for any given application may combine elements of feature selection and feature extraction, but this will only be revealed empirically.
