[site]: datascience
[post_id]: 55848
[parent_id]: 30692
[tags]: 
I would like to know what kind of neural network is suitable for this task? A convolutional autoencoder is a good thing to try, but there is a minor issue with it for this type of problem: the latent representation has often lost spatial awareness (especially if FC layers were used at the end of the encoder). For a task like this, a pixel $p_{ij}$ in the input is likely to be far more related (and useful) to the corresponding (same position) pixel $\widehat{p}_{ij}$ in the output, compared to some other, far away pixel $p_{\ell k}$ in the input. For this reason, I'd suggest using a U-net architecture , as this preserves spatial localities throughout the network. References: Long et al, Fully Convolutional Networks for Semantic Segmentation Ronneberger et al, U-Net: Convolutional Networks for Biomedical Image Segmentation And what kind of loss function is suitable? A good starting point is the standard mean $L_1$ or $L_2$ loss over the output image. Since your images are not natural images, I hesitate to recommend perceptual losses , but they could work as well. Without more details about your architecture and data, I'm afraid I cannot say much more than these though.
