[site]: crossvalidated
[post_id]: 311636
[parent_id]: 311559
[tags]: 
As pointed out by the comments and by Glen's answer , the OP is mistaken in the impression that improper priors cannot be handled analytically. Any perusal of a Bayesian textbook [like mine!] would dispel this impression. For instance, take a Normal mean problem with $x\sim\mathcal{N}(\theta,1)$ and the unknown mean $\theta$ endowed with the flat prior $\pi(\theta)=c$ for an arbitrary constant $c$. The posterior distribution is easily derived as $\theta|x\sim\mathcal{N}(x,1)$. The only relevant point in the question is whether or not software handle improper priors differently and in particular spotting whether or not the posterior does not exist . The answer is that most of the methods and software do not. Monte Carlo methods are equipped for dealing with un-normalised densities and miss the possible occurrence of an infinite integral. MCMC methods similarly use the un-normalised densities as entries and process them in acceptance probabilities with the same danger . This even includes the Gibbs sampler, which may rely on well-defined conditional distributions that have no joint probability distribution. A very simple illustration comes from Casella's & George's Gibbs for Kids : \begin{align*} \eta|\theta&\sim\mathcal{E}(\theta)\\ \theta|\eta&\sim\mathcal{E}(\eta)\\ \end{align*} has no proper stationary measure. One of the first papers by Alan Gelfand and Adrian Smith actually contains a Gibbs sampler for a random effect model with an improper Jeffreys prior that suffers from this major drawback. This is presumably one reason why the early BUGS (Bayes using Gibbs sampling) software has a prohibition of improper priors. (While advocating replacing these improper priors by proper priors with huge variances is questionable!) Stan certainly allows for improper priors.
