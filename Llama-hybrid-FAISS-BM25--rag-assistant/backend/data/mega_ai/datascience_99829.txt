[site]: datascience
[post_id]: 99829
[parent_id]: 99827
[tags]: 
In the this link , the author describes that the difference between model transparency and explainability (ie interpretability) lie in their approaches to solving the black box problem in AI. Transparency solves this by the use of simple models, such as linear regression, that are well-known and use easy to follow steps. Whereas interpretability solves this problem by trying to gain insights into the black box using statistical methods. The most popular statistical method is the Local Interpretable Model-Agnostic Explanations framework (LIME). This is where, quote, "LIME essentially runs the model in a parameter space close to the prediction to understand how each feature impacted the results of the model." This framework was suggested and further explained in this paper that also came with a python package called LIME . Using the above framework to answer your second question, Deep Neural Networks can be made explainable (ie interpretable ) without necessarily being transparent.
