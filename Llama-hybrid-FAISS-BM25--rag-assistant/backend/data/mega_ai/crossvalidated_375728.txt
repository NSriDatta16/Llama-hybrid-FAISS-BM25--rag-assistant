[site]: crossvalidated
[post_id]: 375728
[parent_id]: 374949
[tags]: 
The purpose of cross-validation is to have a statistically sound estimate of how well can a specific model perform for the specific problem (and dataset). It is not clear what are the 10 datasets you mention in your question. Note that it is considered a good practice to shuffle your data before splitting it for cross-validation. Yes - you need to repeat the procedure of train (on (k-1) folds) and test (on 1 fold) k times. Then you average the error over the test folds. The resulting error can be used to compare among different models (for example different types of regression, or different hyperparameters' values). After you choose a specific model (e.g., based on the cross-validation results), you can train it on the entire dataset and this model can be used for production.
