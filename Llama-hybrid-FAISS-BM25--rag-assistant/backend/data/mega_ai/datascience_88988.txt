[site]: datascience
[post_id]: 88988
[parent_id]: 88973
[tags]: 
There is no universal loss value result that you can or should achieve. Beside your model it will heavily depend on the data that you have. What is good or bad result is subjective and depends on your use-case. It's a very broad question how to improve the result of a neural network and you should be more specific but some ideas that can work generally: Preprocess your data differently (i.e. use TF-IDF or use text as a sequence) Collect more data (neural networks usually prefer that, also your test set seems small) Use different optimizer (i.e. Adam) Use different architecture (i.e. some RNN) Use different algorithm (i.e. XGBoost) Use BatchNormalization Use some callback that modifies your learning rate Tune your parameters
