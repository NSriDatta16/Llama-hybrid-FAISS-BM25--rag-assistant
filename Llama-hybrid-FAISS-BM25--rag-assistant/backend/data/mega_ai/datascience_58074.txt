[site]: datascience
[post_id]: 58074
[parent_id]: 58070
[tags]: 
You are correct in your general understanding of bidirectional recurrent neural networks, they do utilize information from both the past and the future. However, they are not usually used for predicting the future. Instead they are mostly used for tasks like: Speech Recognition, Translation and Handwritten-Recognition. For these uses, the "prediction", or more generally the output of the model, is based on a global-scale (a big chunk of text like a full sentence or a paragraph), while the bidirectional behavior works on a local-scale (single words). In simple terms, when we want our model to predict the meaning of a full sentence. We need it to understand the meaning of the specific words composing it. But in order to do that, we use the words that come before (past) and after (future) each specific word.
