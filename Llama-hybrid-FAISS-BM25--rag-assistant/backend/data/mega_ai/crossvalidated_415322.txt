[site]: crossvalidated
[post_id]: 415322
[parent_id]: 415317
[tags]: 
the original system, i.e. Lorenz equation, is too sensitive to the perturbation,which can cause the random behaviour and the difficulty of prediction. While you shouldn't expect any single sample from your trained model to match the ground truth (given the sensitivity to perturbation), you would expect the model to assign high likelihood to all ground truth data (if trained with MLE of course). For example, (and this is true of not only ML models but also humans), while you can't expect to accurately predict a long trajectory, given some starting point, you can expect that if you sample a sequence from your model, conditioned on that same start point, that you would retrieve some plausible looking sequence. More precisely, given a sequence from Lorenz attractor: $y_{1} \cdots > y_{N}$ , can we get the probability of $p(y_{1}, ..., y_{N})$ based on a neural network? Yes, the typical way is with $P(y) = \prod_i p(y_i | y_{ , where $p(y_i|y_{ is typically modeled by an RNN whose $i$ th output is the mean (and sometimes also log variance) of a normal distribution.
