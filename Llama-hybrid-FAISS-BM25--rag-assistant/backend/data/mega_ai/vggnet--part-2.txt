} means a down-sampling layer by 2x2 maxpooling with stride 2. Training The original VGG models were implemented in a version of C++ Caffe, modified for multi-GPU training and evaluation with data parallelism. On a system equipped with 4 NVIDIA Titan Black GPUs, training a single net took 2â€“3 weeks depending on the architecture. == References ==