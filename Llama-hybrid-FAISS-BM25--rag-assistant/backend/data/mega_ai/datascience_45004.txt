[site]: datascience
[post_id]: 45004
[parent_id]: 
[tags]: 
Time of trainig vs time of prediction, which one is used during classification algorithms comparison?

I need to use many algorithms for making a binary classification, such as Logistic regression, SVM, XGBoost, CatBoost, ... I get an interesting improvement but All of those algorithms (except LR) take a very long time for training data. So I need to know if I must indicate training time in my comparison or it is doesn't need to be indicated and predicting time is enough ?? And how many time tuning parameters and fitting training should be done in a real application? does it done each time we insert a new row on data?
