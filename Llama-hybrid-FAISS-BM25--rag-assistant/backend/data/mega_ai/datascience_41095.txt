[site]: datascience
[post_id]: 41095
[parent_id]: 40958
[tags]: 
I am sorry to say that I am not aware of a simple "rule of thump", as this varies a lot according to the nature of the problem. But below you can find some guidelines you can use to determine the "optimal" number of features for your problem. First of all, you should use some dimensionality reduction in order to reduce the number of columns that you are going to use as input. Dimensionality reduction techniques are separated in 2 categories: Feature transformation and feature selection. Feature transformation techniques restructure the feature-space and produce a new set of features based on the old ones. A very popularly used technique for dimensionality reduction is Principal Component Analysis (pca) that uses some orthogonal transformation in order to produce a set of linearly non-correlated variables based on the initial set of variables. Feature selection techniques actually select the features with the highest "importance"/influence on the output variable, from the set of existing features. Some popular techniques are Fisher score (actually assigns weights to the features based on some "importance" criteria), Recursive Feature Elimination (usually provides quite good results when combined with SVM classifier) etc. The following material might help you select dimensionality reduction/feature selection approach. A review article for feature selection for classification A quite good summary of dimensionality reduction techniques Now, the next step after selecting the right method and the right classification algorithm is to find out which is the optimal number of features for your problem. A good idea would be to redo the classification recursively every time adding one extra feature and observe the Classification Error. Given that the feature selection technique will work well, you are expected to observe something like this: The blue dotted line shows the point where the Classification Error of the validation set gets its minimum value. This point indicates the optimal number of features for your problem. After this, the error of the validation set starts increasing while the training set error keeps decreasing - which is an indication of overfitting. (most probably the curves that you will get from your real data will not be that smooth, there might be some fluctuations and the pattern will be less clear - but more or less this will be the general pattern) Keep in mind that after the optimal number of features is determined, a separate test set should be used to evaluate the final model (since you used the validation set for calculating one of the model's parameters you cannot also use it for the evaluation).
