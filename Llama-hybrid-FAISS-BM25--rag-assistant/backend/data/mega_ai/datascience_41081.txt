[site]: datascience
[post_id]: 41081
[parent_id]: 41077
[tags]: 
As you know, you can basically reduce the number of features by choosing best discriminant ones. If you used scikit-learn vectorizers like TF-IDF, they have the parameter max_features which chooses $n$ best features for you. But my point is something else: All BoW models which I guess you used are unsupervised. I strongly recommend that you use mutual information between features and targets (you may also search "Supervised TF-IDF" to get more insight) and choose your best features more effectively. At the end you need to choose $n$ neurons as input layer but with this way you may be able to get the most out of less number of features. If you are familiar with autoencoders, they are also a pretty strong way to reduce the number of features effectively. Hope it helps!
