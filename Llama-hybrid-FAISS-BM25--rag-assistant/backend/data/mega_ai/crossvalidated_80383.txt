[site]: crossvalidated
[post_id]: 80383
[parent_id]: 80376
[tags]: 
As it happens, runtime is not an issue for this problem. Consider the following implementation using Rcpp with completely non-optimized (by me) C++ code: library(inline) library(Rcpp) src Benchmarking this results in runtimes averaging about 0.2 seconds: > library(microbenchmark) > x y microbenchmark(foo(x,y), times=10) Unit: milliseconds expr min lq median uq max neval foo(x, y) 203.3502 204.1472 211.3426 230.9456 264.8911 10 And, just to show there's something in the output matrix: > y[1:5,1:5] [,1] [,2] [,3] [,4] [,5] [1,] 1.098348178 -0.04432606 -0.02573213 -0.01627862 0.007647209 [2,] -0.044326056 0.93672643 0.02166652 -0.03514427 0.050381680 [3,] -0.025732132 0.02166652 1.03743968 -0.03125105 0.024817283 [4,] -0.016278624 -0.03514427 -0.03125105 1.00030357 -0.016148363 [5,] 0.007647209 0.05038168 0.02481728 -0.01614836 0.942497665 I'm running on an Intel i7 920 CPU clocked at 2.79 GHz, 64 bit Ubuntu, 6GB memory. As a consequence, I wouldn't bother to do it in parallel, unless you're interested in the parallelization of this particular matrix operation in its own right. (Note also that this implementation will alter the input matrix x , thanks to the pass-by-reference semantics of NumericMatrix and the statement A(k,i) -= sum; ).
