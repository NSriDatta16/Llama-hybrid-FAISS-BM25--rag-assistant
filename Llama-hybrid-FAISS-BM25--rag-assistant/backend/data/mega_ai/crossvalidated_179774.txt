[site]: crossvalidated
[post_id]: 179774
[parent_id]: 
[tags]: 
Poor performing prediction, what algorithm shall I use? n=126 p=116 - ApacheSpark

I got a data set from a hospital from the PET/CT lab on oncology data (which I'm very unfortunately not allowed to share). n is 126 with 116 features. There is one target variable called death which I have to predict. I've written two small ApacheSpark applications in Scala - one using SVM w/ SGD and one using Decision Trees. On SVM I get an ROC of 0.5 and on Decision Trees I get 0.42 error rate. My question is if there is a chance with that small number of examples do to any useful prediction and if so if you can give me some advice on how to proceed. Below there is my code for Decision Trees: import org.apache.spark.mllib.linalg.{Vector, Vectors} import org.apache.spark.mllib.regression.LabeledPoint import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD} import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics import org.apache.spark.mllib.tree.DecisionTree import org.apache.spark.mllib.tree.model.DecisionTreeModel import org.apache.spark.mllib.util.MLUtils var rdd = sc.textFile("/Users/romeokienzler/Documents/proj/eoc/Workbook1.csv") //convert date to number //convert % to number //convert . to zero //convert csv to array //convert empty strings to 0 var matrix = rdd.map(s => s.replaceAll("/","")).map(s => s.replaceAll("%","")).map(s => s.replace('.','0')).map(s => s.split(',')).map(a => a.map(e => if (e.length==0) "0" else e)) //convert double matrix to mllib matrix var matrixMLLib = matrix.map(a => a.map(e => e.toDouble)).filter(a=> a.length==89).map(a => new LabeledPoint(a(1),Vectors.dense((a.slice(2,a.length))))) // Split data into training (60%) and test (40%). val splits = matrixMLLib.randomSplit(Array(0.6, 0.4), seed = 11L) val (trainingData, testData) = (splits(0), splits(1)) // Train a DecisionTree model. // Empty categoricalFeaturesInfo indicates all features are continuous. val numClasses = 2 val categoricalFeaturesInfo = Map[Int, Int]() val impurity = "gini" val maxDepth = 5 val maxBins = 32 val model = DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo, impurity, maxDepth, maxBins) // Evaluate model on test instances and compute test error val labelAndPreds = testData.map { point => val prediction = model.predict(point.features) (point.label, prediction) } val testErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / testData.count() println("Test Error = " + testErr) println("Learned classification tree model:\n" + model.toDebugString) // Save and load model model.save(sc, "myModelPath") val sameModel = DecisionTreeModel.load(sc, "myModelPath") Support Vector Machine: import org.apache.spark.mllib.linalg.{Vector, Vectors} import org.apache.spark.mllib.regression.LabeledPoint import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD} import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics var rdd = sc.textFile("/user/root/romeo/eoc/data.csv") //convert date to number //convert % to number //convert . to zero //convert csv to array //convert empty strings to 0 var matrix = rdd.map(s => s.replaceAll("/","")).map(s => s.replaceAll("%","")).map(s => s.replace('.','0')).map(s => s.split(',')).map(a => a.map(e => if (e.length==0) "0" else e)) //convert double matrix to mllib matrix var matrixMLLib = matrix.map(a => a.map(e => e.toDouble)).filter(a=> a.length==89).map(a => new LabeledPoint(a(1),Vectors.dense((a.slice(2,a.length))))) // Split data into training (60%) and test (40%). val splits = matrixMLLib.randomSplit(Array(0.9, 0.1), seed = 11L) val training = splits(0) val test = splits(1) val numIterations = 1000 val model = SVMWithSGD.train(training, numIterations) // Compute raw scores on the test set. val scoreAndLabels = test.map { point => val score = model.predict(point.features) (score, point.label) } // Get evaluation metrics. val metrics = new BinaryClassificationMetrics(scoreAndLabels) val auROC = metrics.areaUnderROC() println("Area under ROC = " + auROC) Thanks a lot in advance!
