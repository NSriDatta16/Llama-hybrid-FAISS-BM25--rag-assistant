[site]: datascience
[post_id]: 84907
[parent_id]: 
[tags]: 
Binary + Neutral Classification

I have a dataset of posts for sentiment analysis that are labelled with -1 (negative), 1 (positive) or 0 (neutral). So I wonder how should I deal with that. These are my ideas: make a multiclass classifier : I tried with a random forest, and the results are pretty correct; however, I have a certain amount of negatives in positives and vice versa; I would've preferred the error to rather be in neutral. make a binary classifier, but when predicting, if the probabilities are too balanced, return neutral. However, it seems to me that I don't use the neutral data - isn't it a waste of data? Maybe using a OneVsAll will be better? make a perceptron/neural network with an tanh neuron at the output; but I don't know what good loss function could be used here. Do you know if there is any of those that is theoretically/practically better?
