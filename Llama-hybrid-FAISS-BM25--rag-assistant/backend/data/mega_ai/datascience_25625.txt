[site]: datascience
[post_id]: 25625
[parent_id]: 14064
[tags]: 
Implementing this with a recurrent neural network is not that difficult. My suggestion is close to what you already suggested but instead of sampling different points in time I would just broadcast your target over all time steps. If there are a total of N time steps, and we want to predict on steps t=1 to t=N-1, our X is a matrix of shape [N-1, k] with k the number of features. Y is a sequence of shape [N-1] with all the values being equal to EventN. This is similar to what you actually want to achieve, namely at every time step you want to predict the final value. Your loss function will be calculated over all time steps and backpropagated through time. It's possible that you might want to weigh your function as a function of the time step, maybe later predictions are more or less important, you'll need to do some analysis on this. Another recommendation would be to add some feature of time in your feature explicitly, that might help the network.
