[site]: crossvalidated
[post_id]: 267899
[parent_id]: 
[tags]: 
Why do we care about the noise in the target variables when building machine learning models?

When building linear regression problem, we assume that we have a noise or erros in the target variables that we measured. I have two questions about that If I want to build a machine learning model. I think that we mustn't care about the errors in the data. Because simply, it is not my problem. This is the problem of customers/researchers who are measuring the data. I mean their job to decrease the noise using Digital Signals Processing or any other tools. From my point of view, we have a lot of problems in this field and we do not need more. Secondly, we don't separate this field from other fields. Thirdly, I think by modeling the noise in the target variables, we are just telling people that ML field is a tool to solve problems from A to Z regardless of where the data came from. Of course, there is a reason to build that noise, but I can't find it. Can you give me a practical example where we should model the noise, otherwise our machine learning system will fail? I found that the origin of this is based on Errors-in-variables models . However, I want to understand the reason from machine learning prospective.
