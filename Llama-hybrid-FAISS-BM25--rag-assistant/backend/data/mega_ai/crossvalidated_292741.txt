[site]: crossvalidated
[post_id]: 292741
[parent_id]: 
[tags]: 
How to avoid local minimum in recurrent neural network

I have trained a recurent neural network on tensirflow so there is no need t initialize my paraemters,it will be done automatically into the tf.dynamic_rnn so when i train my model ,i don't get right predictions all the time.I mean when i compile my code,i get sometimes good predictions but sometimes my model fail so i think this is due to the fact that gradient descent is sometimes stuck on a local minimum so what can i do , i did the tf.train.AdamOPtimizer(0.01).minimize(loss) .what is the best optimizer that avoids local minimum
