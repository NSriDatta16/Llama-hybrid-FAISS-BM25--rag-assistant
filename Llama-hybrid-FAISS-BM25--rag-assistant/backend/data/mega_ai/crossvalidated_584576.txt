[site]: crossvalidated
[post_id]: 584576
[parent_id]: 584564
[tags]: 
You don't have to. It's true that Naive Bayesian assumes the features are independent conditioned on the class label. But it's OK to make wrong assumptions, because any model is just a set of assumptions after all, one can't be sure if all of the assumptions fits the reality. So, as long as adding the feature results in a better model selection criteria, such as BIC, then you should do it. As it said "all models are wrong, some are useful"
