[site]: crossvalidated
[post_id]: 551540
[parent_id]: 
[tags]: 
Truncate tweets for text classification

I have a binary classification tweet dataset with statistics as follows average tweet length is 600.1 words max tweet length is 3900 words min tweet length is 40 I'm trying to classify the tweet using pre-trained BERT So, to work with bert, I chose the maximum sequence length as 128 i.e.. each tweet token length is fixed to 128 tokens So I'm truncating the data to 128 tokens and the performance of the bert model is almost 98% acc But my question is that each tweet is very large but we are truncating to small tweet still the model is giving very good accuracy. I'm unable to understand how it is working fine
