[site]: crossvalidated
[post_id]: 390463
[parent_id]: 372096
[tags]: 
I ended building an auto encoder, which is a neural network with the following structure. The input are the values of each timeseries, the output the same values. So this neural network tries to reconstruct the timeseries after passing through a hidden layer with only a couple of neurons (the autoencoder I build had only three neurons in the middle hidden layer). Training this neural network is really simple with Keras / Tensorflow (you can find some inspiration here: https://blog.keras.io/building-autoencoders-in-keras.html ). When the neural network is trained, you simple pass through all the timeseries and record the values of the hidden neurons for each timeseries. This is your feature matrix! To illustrate that this works really well, take a look at the following image. For a couple of timeseries (the occurrence of a given name in the Netherlands for each year), I used these the features to find names with a similar timeseries. You see that it effectively selects similar names, although it did not use the full timeseries (42 values) but only the 3 features.
