[site]: crossvalidated
[post_id]: 113311
[parent_id]: 
[tags]: 
Which post-hoc comparison to use and why

Hopefully this is now a much clearer picture of the question I want to answer: For each of 60 different plans I ran 35 simulation replications of my Agent Based Model (ABM) simulation. Then for each simulation replication of each plan, I generated a score ($\geq0$), so that I ended up with 35 scores for each of the 60 plans. I now want to find the best plan which I define as the plan with the smallest mean score. Of course I can compute the mean score for each one of the 60 plans, and I can rank each plan according to the mean score. At this point how do I test whether the 1st ranked mean score is statistically significantly different to the 2nd ranked score. And if I find it is not, how do I test whether the first two ranked mean scores are statistically significantly different to the 3rd ranked score, and so forth. Eventually I would like to end up with a set of plans (although the set can contain only one plan) for which I can state that the set of plans are equally best (as far as being statistically significantly the same). This is what I was considering doing: For each plan I compute the mean score and then select the 5 plans with the 5 smallest scores. I then use the Kruskal-Wallis H-Test to determine if any of the 5 means are significantly different (since my samples do not satisfy the normality or homoscedasticity assumptions of ANOVA ). If the p-value returned by the test is less than my significance level $\alpha$ then I know that at least one of the means is different and want to test for which one this is (are). At this point I need to use a post-hoc comparison test but am unsure as to which one I should use and why.
