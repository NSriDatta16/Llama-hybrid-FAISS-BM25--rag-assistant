[site]: datascience
[post_id]: 93796
[parent_id]: 86624
[tags]: 
The variation in performance gains you are seeing from reduction precision might be due to different frameworks using different types. Even after downcasting data types, some operations will automatically upcast types. You mention using both Pandas and TensorFlow / Keras. Mixing frameworks might result in unwanted recasting of data types. It is better to use a single framework to avoid recasting. There is no software (e.g., language, library, or model) agnostic answer. Hardware utilization is software-specific. In order to get the gains from reduced precision, the same software stack should be throughout the entire modeling process. The software should be designed for the specific chip (e.g., CPU, GPU, or TPU).
