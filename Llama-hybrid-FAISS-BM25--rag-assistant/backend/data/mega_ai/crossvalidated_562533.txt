[site]: crossvalidated
[post_id]: 562533
[parent_id]: 562454
[tags]: 
Player skill might approximately be a single linear quantity (of course, some players might play better with some deck-set-up they like best, some particular decks might only be suitable for more skilled players etc.). So, one could argue that you can use a logistic regression type of set-up that is something like this: $$\text{logit} P(\text{player #1 wins}| \text{deck #1}, \text{deck #2} ) = \beta_0 + \text{skill}_1 - \text{skill}_2 + f(\text{deck #1}, \text{deck #2}).$$ I.e. there's some fixed effect of the first player (e.g. whoever plays a card first) winning all else being equal, there is an effect of the difference in skill and there is some complicated function that involves the decks. More generally, this could of course all be some complicated function of player characteristics and deck characteristics. I wonder whether - given enough data on played games - this could be approached using a neural network. Decks could be input as a collection of items (= the cards) and be dealt with using a transformer type of architecture with an attention mechanism (the idea is that unless one uses positional encodings transformers are invariant to order - which does not really exist in a deck when we do not know which way it will be shuffled) followed by some fully connected layers, while players could be put into 1-dimensional embedding layers (which use the same embeddings whether the same player is player #1 or #2) with these embeddings going straight to the output layer and one would use a sigmoid activation function. Of course, this all pre-supposes a large database of played games where the player and deck information are available. Or you can go crazy and use reinforcement learning to train agents and create games (in fact, such agents would presumably have a good internal representations of the value of decks that would be helpful for the task you describe).
