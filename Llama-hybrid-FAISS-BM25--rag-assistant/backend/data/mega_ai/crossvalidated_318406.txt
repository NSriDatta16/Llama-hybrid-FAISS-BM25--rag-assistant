[site]: crossvalidated
[post_id]: 318406
[parent_id]: 
[tags]: 
How to test for significant difference in multilevel data?

I work with a multilevel data set like the one below. Scenario Group individual Measurement 1 1 1 555 2 1 2 525 .. ... ... ... 10 1 10 565 11 2 1 1250 12 2 2 1300 ... ... ... ... 20 2 10 1199 ... ... ... ... 2000 200 10 345 The groups are problems to be solved and the individuals are different configurations (i.e., different settings of parameter values) of a single algorithm. The measurements represent the performance value of running an algorithm with configuration a on problem b . Lower values are better. In a second experiment all scenarios an run again, but now the algorithm has a slightly modified implementation that I expect to result in better performance measurements. So what I have is the following Scenario Group individual Measurement 1 Measurement 2 1 1 1 555 515 2 1 2 525 520 .. ... ... ... ... 10 1 10 565 555 11 2 1 1250 1248 12 2 2 1300 1296 ... ... ... ... ... 20 2 10 1199 1120 ... ... ... ... ... 2000 200 10 345 296 I would like to test whether the measurements between the two experiments significantly differ to indicate that the modification led to better performance results (i.e, lower values). So I'm not really interested in individual scenarios, but on average for the entire data set I would like to know whether measurement 2 is significantly better than measurement 1. What test could I use that takes into account the multilevel data structure?
