[site]: crossvalidated
[post_id]: 272482
[parent_id]: 
[tags]: 
Normalization - which is better?

So say I want the user to type the first 5 letters of a word he or she is thinking about; I want the neural network to output the remaining letters in the word. However, should I: Convert the 5-letter string to binary ( A=01000001 , B=01000010 , etc.) This means that I will have 5 * 8 = 40 input neurons Or should I: Link letters to numbers ( A=1 , B=2 , etc.) Divide this number by ALPHABET_LENGTH=26 (normalize) Resulting in A~0.04 , B~0.08 , etc. Meaning I will only have 5x1 input neurons The same would count for the output of course! However, what is more effective? Which normalization will have a more positive effect on the neural-network training (through backpropagation and genetic algorithms, both). And are there any papers on this?
