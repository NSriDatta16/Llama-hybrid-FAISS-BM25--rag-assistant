[site]: crossvalidated
[post_id]: 446642
[parent_id]: 446416
[tags]: 
BART is a regression method, just like generalized linear models (e.g., linear or logistic regression), decision trees, or many other machine learning methods. BART has a few advantages for causal inference that distinguish it from other methods. First, because the tuning parameters correspond to Bayesian priors, each predicted value has a posterior distribution, from which credible intervals can be directly computed. Although for some regression methods there is theory for how to construct valid confidence intervals, the general advice for g-computation is to bootstrap, which does not always work with machine learning-based methods. There is some evidence that the credible intervals from BART do not reach nominal confidence levels, especially for the ATT, but there are ways to improve coverage. Note that confidence intervals can also be estimated for treatment effects estimated using other machine learning methods by using targeted minimum loss-based estimation (TMLE). Second, BART is extremely flexible and is able to account for nonlinearities and interactions without overfitting due to the Bayesian priors. In addition, the default tuning parameters are effective in many cases. This is in contrast with generalized linear models, which involve a fairly strict parametric structure, and decision trees, which can easily overfit, may not capture smoothness very well, and require a procedure to set the tuning parameters. Third, it's possible to incorporate substantive information into the priors, for example, on which variables to perform a split or for which variables the treatment effect should vary. This is less possible with some other methods that use fully data-driven splitting criteria and variable selection. BART's potential is still being explored, but its growing popularity in causal inference is due at least partly to its performance in causal inference competitions, such as that described by Dorie et al. (2019), which details many of the points I've brought up here. Conceptually, BART does just what many other regression methods do, as you have identified, but some of its unique characteristics make it particularly well suited for causal inference. Dorie, V., Hill, J., Shalit, U., Scott, M., & Cervone, D. (2019). Automated versus do-it-yourself methods for causal inference: Lessons learned from a data analysis competition. Statistical Science, 34(1), 43â€“68. https://doi.org/10.1214/18-STS667
