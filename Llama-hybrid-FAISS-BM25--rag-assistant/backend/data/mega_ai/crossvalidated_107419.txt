[site]: crossvalidated
[post_id]: 107419
[parent_id]: 106318
[tags]: 
dfife's answer is good though it may be informative to re-read Breiman's description of how random forests can handle missing values in the training data while trying to predict a variable without missing values: http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#missing1 Another approach I've had good luck with to predict or get importance scores from data sets with missing values with out imputing is three way splitting which splits the missing value onto a third branch at each node. This is particularly useful if the fact something is NA may actually be informative (ie in a survey where a question being left blank may be significant). This method originates (to my knowledge) in Timo Erkkila's rf-ace: https://code.google.com/p/rf-ace/ and can also be found in my implementation, CloudForest: https://github.com/ryanbressler/CloudForest . rf-ace has a (difficult to build) r-package, cloudforest doesn't yet but is faster and more memory efficient and can also handle missing values via a bias correction without three way splitting or imputation as in some variants of CART. If you have missing values in the thing you are trying to predict you may want to look into methods for semi supervised learning. If you want an unsupervised method for imputing missing values while you aren't trying to predict thing you could start with nearest neighbor imputation or impute to the variable mean or mode (as Breiman suggests to initialize his method for RF imputation).
