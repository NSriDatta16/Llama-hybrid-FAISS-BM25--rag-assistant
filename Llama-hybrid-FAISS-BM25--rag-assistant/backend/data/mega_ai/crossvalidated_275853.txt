[site]: crossvalidated
[post_id]: 275853
[parent_id]: 275840
[tags]: 
Question 1: Logistic regression should certainly work here: you have a binary outcome (booked or not) and you have 40 predictors. You could consider adding quadratic terms (squaring all your continuous variables and adding them as extra predictors) or interaction terms (multiplying your predictors with each other). If you feel like testing other methodologies and your focus is on creating a good prediction model, you could look into, e.g., support vector machines, decision trees, random forests. I would suggest the caret package for R ( http://topepo.github.io/caret/index.html ) for this. However, this will be some extra work but performance might increase. Also, some of these models might be harder to interpret. If you are really just looking into finding the predictors, logistic regression is already a good choice. Question 2: p-values give good indications for individual variables but, as you said, as soon as you have correlating predictors in a model, they are harder to interpret. If you are looking into building a good prediction model: I would evaluate models by their performance in a cross-validation (not sure whether SPSS can do that?). Take something like 70% of your dataset and test multiple combinations of variables in a cross-validation. You can evaluate your models using different metrics: Area under the ROC-cure (AUC) for discrimination, mean-squared error for minimizing the prediction error, etc. Choose a metric and take the model with the best metric, test it on the 30% of 'unused' data - this is the estimate of how your final model performs. On top of that, you can choose to use penalized logistic regression (logistic LASSO, elastic net) to select predictors for you (again, extra work to learn this but it might save you plenty of time in the future). In that case you would have to tune the penalization parameters in the cross-validation instead of trying different combinations of predictors.
