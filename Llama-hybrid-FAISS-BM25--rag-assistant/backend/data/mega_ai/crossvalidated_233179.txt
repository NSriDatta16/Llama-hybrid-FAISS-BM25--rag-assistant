[site]: crossvalidated
[post_id]: 233179
[parent_id]: 233178
[tags]: 
Classification trees require sometimes ten times the sample size of logistic regression, and you will be quite disappointed in the stability of the tree. Bootstrap the process for a few resamples and you will see the tree topology change quite a bit. Simplicity in single trees is more of an illusion than a reality. Trees seem simple when you select one tree from many competitors that are very difficult to choose from. In addition you have chosen a discontinuous improper accuracy scoring rule which is optimized by bogus predictions, i.e., optimized by using the wrong model for the data. Lack of significance is not a reason to change methods. Instead consider data reduction masked to $Y$, or use penalized maximum likelihood estimation to deal with your relatively small sample size.
