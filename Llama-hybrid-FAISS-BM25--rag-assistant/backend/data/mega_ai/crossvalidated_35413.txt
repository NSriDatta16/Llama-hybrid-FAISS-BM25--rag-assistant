[site]: crossvalidated
[post_id]: 35413
[parent_id]: 35395
[tags]: 
Many of the linkage distances are computed on a set of pairwise distances. Then this works just fine with a distance matrix. So most of the time, while the intuition is to have a "handle", what is being done is more a statistical approach. E.g. single-linkage is the minimum distance, and average linkage is the mean distance taken from the submatrix connecting the two clusters. Note that for efficiency, you will often want to avoid computing the distance matrix (which needs $O(n^2)$ memory) in the first place. I guess the main reason why this is frequently been done is because it allows you to easily plug in other distances, hierarchical clustering is sensible for tiny data sets only in the first place (the naive algorithm has $O(n^3)$ run time!) and because the operation of computing pairwise distances is available as a highly optimized native C operation, which is significantly faster than anything done in the R interpreter. As for your question on computing a distance on the rows/cols in the distance matrix: I don't think this is a very sensible measure. As each entry is a distance , it corresponds to a RMSE of distance similarity of two objects. I.e. "the object is as far to all other objects as the other". But there are some related methods used for high dimensional data, that choose a number of reference objects (but not the whole database!) and judge object similarity by how similar the distances to these reference points are. So sometimes, this seems to work quite well; but I wouldn't choose the whole data set as reference objects; after all you want to keep dimensionality low (and one reference object ~ one dimension!) and get below $O(n^2)$ runtime. With this approach, you need the full distance matrix, which is a lot of (possibly redundant) computations and memory.
