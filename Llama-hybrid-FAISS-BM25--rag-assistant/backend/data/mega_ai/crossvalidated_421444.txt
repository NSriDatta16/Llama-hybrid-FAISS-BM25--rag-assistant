[site]: crossvalidated
[post_id]: 421444
[parent_id]: 421336
[tags]: 
Q1 In words your model TrapRate3 ~ Site + s(PT36, k = 5, m = 2, bs = "tp") + s(PT36, by = Site, k = 5, bs = "tp", m = 1) + s(Year, bs = "tp", k = 5) posits that the response can be decomposed into a fixed Site effect; each Site has it's own mean, an average smooth effect of PT36 over all levels of Site , a separate Site -specific smooth effect of PT36 which measures the deviation from the average smooth for the $j$ th level of Site , and a smooth effect of sample Year The site-specific "difference" smooths are really estimating an entirely separate smooth for each level of Site ; there is no shared information here and that implies that you are focused on this specific set of sites as you model can't generalise to other Site s. These smooths are also centred, which is why we require something in the model to account for the potentially different mean response values for each level of Site . This model isn't saying that the population smooth effect of PT36 , $f(\mathsf{PT36})$ , applies to all unmeasured sites, sensu a random slope model in classical mixed effects modelling. However, it would be your best estimate of the effect of PT36 on the response for some unmeasured new Site . Whether you can use your model to predict the response at this unmeasured Site in another matter; you won't have an estimate for the mean response at any site because of the fixed effects Site term in the model. One motivation for this model is that it can be more parsimonious than TrapRate3 ~ Site + s(PT36, by = Site, k = 5, bs = "tp") + s(Year, bs = "tp", k = 5) if all or most of the $f_{\mathrm{Site}}(\mathsf{PT36})$ have a very similar shape; why estimate 11 very similar smooth functions when you can estimate a single average function and 11, potentially simpler "difference" functions? But, having said that, one of the ways of thinking about a random effect if that the effects are penalized towards some average effect; in a random intercept, the random effects are shrunk toward the overall intercept in the model, random slopes are shrunk towards the average or population "slope" in the model. Here, the estimated smooth effects for each Site are shrunk towards the average smooth effect but not with regard to the overall model intercept - the model includes fixed effect of Site . So, if it walks like a duck and quacks like one too... Q2 Which you choose will depend entirely on how you hypothesise the Year effect to vary between Sites ? If all Sites have largely been exposed to the same environment then one might expect a single common smooth effect of Year , so use + s(year) only. If you hypothesise that each of the 11 sites has experienced it's own, different, set of temporal events not related to Temperature, then + s(year, by = Site) would be warranted. If, however, you think that each site has experienced roughly the same set of temporally-ordered events or forcing but with some Site -specific idiosyncrasies, then you could use the + s(Year) + s(Year, by = Site, m = 1) form. We can't answer that question for you I'm afraid. Q3 The outputs in the summary are analogues of the $t$ tests of the null hypothesis that $\hat{\beta}_i = 0$ for the $i$ th coefficient in the model. The difference here is that the null hypothesis assumes that the estimated function $\hat{f}_{\mathrm{Site}}(\mathsf{PT36}) = 0$ , i.e. is a constant function. Is the estimated function and hence are the data consistent with this assumption? Because of the way this smooth effect is penalized — m=1 means a first derivative penalty penalising deviation from a flat or constant function — and the way you've set this model up, there isn't anything in this model summary that you can point to that says PT36 has a significant effect on the response for this particular site. You couldn't do this, nor might one philosophically want to do so, if you'd estimate a random slope for each site about some population effect of PT36 in a mixed effects model. Here you would most likely need to predict the response for each level of Site , whilst holding Year at the average Year , over the range of PT36 and plot the estimated values and the classic 95% point-wise confidence interval ( $\pm$ 2 $\times$ SE( $\hat{y}))$ and then look to see if the response varies over the range of PT36 and with what level of uncertainty. (Note this 95% interval has an across-the-function interpretation, not the usual 95% pointwise interpretation as it is really a Bayesian credible interval given improper priors on the smoothness parameters). Q4 I've already touched on this but these two specifications are different: y ~ Site + s(x, by = Site) estimates a separate mean for each level of Site ; there's no shrinkage towards the overall model intercept in the coefficients implied by how Site enters the model (by default the coefficients for Site are parameterised into differences from the model intercept), whereas with y ~ s(x, by = Site) + s(Site, bs = "re") the Site specific means are shrunk towards the overall model intercept (they're shrunk towards zero but then we add on the model intercept to get each Site s mean). Q5 You could use AIC but you do have to be sure that the model is fully penalised if you are using REML. You can switch to estimating via ML if you aren't sure to do the selection and then refit the chosen model using REML to get the best estimates for the smoothness parameters. AIC is an estimator of the leave-one-out (IIRC) MSE of the model so your selection if using it is based on prediction error. Instead, you could embrace the world of penalties and use select = TRUE in your gam() code, which will put a separate penalty on any unpenalized term in the bases of the smooth function in the model (not the Site fixed effect, you'd need to do something else to penalize that, see paraPen argument). This extra penalty can shrink a term entirely out of the model — i.e. do model selection for you — whilst taking into account your uncertainty about whether and which covariates were related to the response; the summary() output will account for this extra uncertainty.
