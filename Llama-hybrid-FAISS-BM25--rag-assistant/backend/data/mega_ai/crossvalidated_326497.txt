[site]: crossvalidated
[post_id]: 326497
[parent_id]: 
[tags]: 
Classification problems - is there a concept of coefficients in SVM, Decision Trees, and NN?

I'm currently exploring the field of machine learning, and am pretty new to it. I'm familiar with the concept of regression and the idea of weights/coefficients for each variable to understand the importance of that variable in the model. In the case of SVM, NN, and decision trees, is there a way to get an idea of which variables are most important? or have the most weight? Or is it not digestible in the same way that people interpret regression? Like say I have a class I am trying to label 1 or 0 (does this person drive), and there are two other variables (the age, and the education of the person). In a regression, I can assign a coefficient to age and education to understand the predictive power of the the variables. If I do a decision tree, whatever variable I split at the top implies that that has the most importance because that divides the dataset I have by the most. But is there like some form of coefficient to that or how do I interpret a metric in the case of classifying via SVM, NN, and Decision Trees? Also, is there a way in sklearn (python) to easily get the 'coefficients' of a classifier?
