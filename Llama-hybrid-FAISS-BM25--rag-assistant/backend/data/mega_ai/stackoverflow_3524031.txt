[site]: stackoverflow
[post_id]: 3524031
[parent_id]: 
[tags]: 
Google crawler finds robots.txt, but can't download it

Can anyone tell me what's wrong with this robots.txt? http://bizup.cloudapp.net/robots.txt The following is the error I get in Google Webmaster Tools: Sitemap errors and warnings Line Status Details Errors - Network unreachable: robots.txt unreachable We were unable to crawl your Sitemap because we found a robots.txt file at the root of your site but were unable to download it. Please ensure that it is accessible or remove it completely. Actually the link above is the mapping of a route that goes an action Robots. That action gets the file from the storage and returns the content as text/plain. Google says that they can't download the file. Is it because of that?
