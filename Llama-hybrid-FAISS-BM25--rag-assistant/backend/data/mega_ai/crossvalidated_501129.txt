[site]: crossvalidated
[post_id]: 501129
[parent_id]: 
[tags]: 
Maximum Likelihood Estimator and finding parameters

I think I understand the process of determining a Maximum Likelihood Estimator as being similar to the machine learning process of Gradient Descent for Linear Regression in that GD for LR results in a set of parameters that minimizes Least Squares Error and results in the best fitting regression line. Finding the MLE results in determining a set of parameters that also most closely fits the data. Is this analogy appropriate?
