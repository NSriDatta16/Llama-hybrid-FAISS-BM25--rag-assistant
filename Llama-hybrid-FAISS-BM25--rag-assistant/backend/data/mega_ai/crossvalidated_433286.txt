[site]: crossvalidated
[post_id]: 433286
[parent_id]: 
[tags]: 
When does multi-task learning make more sense than multi-label classification?

As part of writing a book on machine learning, I am creating an extreme multi-label stack overflow question tagger for thousands of tags with varying numbers of training examples and I’ve approached it as a multi-label classification problem after balancing the data as much as possible. This works out to some number of the most frequent labels and I am using weak supervision to generate additional training labels for infrequent tags. Snorkel, the software involved for labeling, doesn’t support multi-label learning so the data must be split into subsets for each label anyway, so I’ve thought about approaching this as a multi-task problem. So my TDLR question is: when building a network classifier, when does one use multi-label learning and when does one use multi-task learning? Is the essential difference in this case the number of labeled records for each output?
