[site]: crossvalidated
[post_id]: 446213
[parent_id]: 262794
[tags]: 
Why does a decision tree have low bias & high variance? Does it depend on whether the tree is shallow or deep? Or can we say this irrespective of the depth/levels of the tree? Why is bias low & variance high? Please explain intuitively and mathematically. Bias vs Variance More Bias = error from the model being more simpler (does not fit the data very well) More Variance = error from the model being more complex (fits the data too well, and learns the noise in addition to the inherent patterns in the data) Everything is relative I want to start by saying that everything is relative. Decision Tree in general has low bias and high variance that let's say random forests. Similarly, a shallower tree would have higher bias and lower variance that the same tree with higher depth. Comparing variance of decision trees and random forests Now with that ironed out, let's think why decision trees would be worse in variance (higher variance and lower bias) than let's say random forests. The way a decision tree algorithm works is that the data is split again and again as we go down in the tree, so the actual predictions would be made by fewer and fewer data points. Compared to that, random forests aggregate the decisions of multiple trees, and that too, less-correlated trees through randomization, hence the model generalizes better (=> performs more reliably across different datasets = lower variance). Similarly, we are making more simplifying assumptions on random forests to consult only a subset of data and features to fit a single tree, hence higher bias. BTW, similary, a tree with lower height = less reliant on fewer data points generalizes better and and has less variance compared to a deep tree.
