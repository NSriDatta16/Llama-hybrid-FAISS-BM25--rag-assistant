[site]: crossvalidated
[post_id]: 597318
[parent_id]: 597306
[tags]: 
Accuracy is not the best metric. It is also impossible to interpret it without further details about your data. I have no access to your data, but I found a similar Kaggle dataset where 85% of the athletes did not get a medal while 15% did. If your data is similar, this would mean that if you predicted: "no medal" for everybody you already get 85% accuracy. To judge the performance, you need some benchmarks. Do you know any other results obtained using this or a similar dataset? How does your compare to theirs? You also would like to have an internal benchmark, i.e. compare the model to some trivial model (e.g. predict the most frequent class for everyone). Without this, no metric can be interpreted. The $k$ hyperparameter controls how many nearest neighbors you are averaging to make a prediction. Larger $k$ plays a role in regularization : with small $k$ you are likely to overfit, with large $k$ underfit. With $k=N$ (sample size) you are making the same prediction every time. Did you check if the result is not due to the fact that with increasing $k$ you are simply starting to make constant predictions? Maybe in this case this starts happening pretty fast.
