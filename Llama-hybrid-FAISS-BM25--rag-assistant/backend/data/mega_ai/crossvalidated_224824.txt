[site]: crossvalidated
[post_id]: 224824
[parent_id]: 224816
[tags]: 
Just like you calculate cosine similarity Random Forests can be used for unsupervised learning. These unsupervised Random Forests output similarity matrices based on proximity. The only caveat is that the Random Forest similarity is based on whole data, i.e. it's not pairwise calculated, you must give it the whole data for it to learn the similarity, as it's based on the number of times two given observations ended on the same leaf in the trees. In other words, this means that you'd need to recalculate the whole proximity matrix for all data every time a new observation is added. To read about unsupervised Random Forests, I recommend this small description on Leo Breiman and Adele Cutler site (the inventors of Random Forests). Even wikipedia includes a section on unsupervised learning with random forests .
