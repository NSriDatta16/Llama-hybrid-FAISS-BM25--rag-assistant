[site]: crossvalidated
[post_id]: 371956
[parent_id]: 
[tags]: 
How state aggregation in reinforcement learning works?

I am watching Prediction with linear approximation video course in the RL class by prof. Sutton. He presented state aggregation approach on a random walk problem. It seems that this approach just aggregates the value function of different states. However, I thought that this approach aggregates states and therefore, their value functions are aggregated, too. Can someone explain how this approach works? Is discretization of a continuous space the same as state aggregation? If yes, in discretization, states are aggregated at first and therefore, value functions are then aggregated.
