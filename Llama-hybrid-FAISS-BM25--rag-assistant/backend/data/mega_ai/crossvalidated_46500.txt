[site]: crossvalidated
[post_id]: 46500
[parent_id]: 
[tags]: 
Dealing with dependant data when estimating probability of an event happening

I have 10 years worth of data from 1970 to 1980 (40 quarters). For each quarter I have five measurements M1, M2, M3, M4 and M5. TWIST: Although the data I have is on individual patient level, the outcome variable (T) is common to all patients during epidemic times. For example, all patients tend to have their target flags set to 1 (positive) in quarters Q19, Q20 and Q21 as well as in quarters Q33, Q34, Q35, Q36, Q37, Q38, Q39 and Q40. The reason for this is because patients are flagged with 1 even if they have mild conditions of a particular disease and they all tend to have it during epidemic times. The common target variable makes me think that I should aggregate my measurements on from individual to population level and then estimate probability of widespread disease occurring. However, that means that I’m “losing” information i.e. I’m ignoring potentially relevant information on an individual level. My “gut feeling” is that I shouldn’t be aggregating and averaging my data. On the other side if I use a simple logistic regression model and treat my data as if it was independent (which it clearly isn’t) I’ll probably get biased estimates. My ultimate goal is to be able to (given individual measurements) calculate the probability for that particular individual of being ill.
