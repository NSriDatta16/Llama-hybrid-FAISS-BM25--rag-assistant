[site]: crossvalidated
[post_id]: 554321
[parent_id]: 554317
[tags]: 
Yes. There are few proposed measures of calibration, but the most widely circulated is the so called Hosmer-Lemeshow statistic. At a 10,000 view, this test works by binning a risk model into deciles, and then calculating the expected event frequency versus the observed event frequency within each decile. The "x"-axis here is the average predicted risk for each of the 10 deciles, and the "y"-axis is the corresponding proportion of events in each decile. Ideally the curve lies on a straight line. And the deviations follow a binomial probability model. The choice of 10 bins is due to Hosmer and Lemeshow, but can easily be taken to be more, and can be chosen with non-empirical (i.e. quantile) thresholds. Then you get into some of the known measures of risk stratification tables. However all of these are problematic. To me, a more intuitive measure of calibration is the Brier score. This is just the MSE. Brier pointed out this is a valid and useful measure even when the data are binary, and it favors closer predictions on the absolute risk scale which is favorable for many reasons! I started the Wiki for the HL test long ago, yet it appears to be in severe disarray. https://en.wikipedia.org/wiki/Hosmer%E2%80%93Lemeshow_test
