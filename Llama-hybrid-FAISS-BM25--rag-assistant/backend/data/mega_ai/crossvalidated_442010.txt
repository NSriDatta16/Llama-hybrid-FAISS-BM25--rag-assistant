[site]: crossvalidated
[post_id]: 442010
[parent_id]: 321094
[tags]: 
First of all, permit me to elucidate a couple of terms to find the common ground: $\delta(x)$ - decision rule $\gamma(\theta, \delta(x))$ - the loss function $R(\theta, \delta) = \mathbb{E}_{x} [R(\theta, \delta(x))]$ - the risk function $r(\delta) = \mathbb{E}_{\theta}[R(\theta, \delta(x))]=\mathbb{E}_{\theta}(\mathbb{E}_{x} [R(\theta, \delta(x))])$ - the Bayes risk Thus, every decision rule is characterised by a single number and Bayesian decision rule is defined as a minimizer of $r(\delta)$ . Keeping things simple, let us consider the following case: $$ H_0:\ \theta = \theta_0\\ H_1:\ \theta = \theta_1 $$ where $\theta_0\ne\theta_1$ . Hence: $$ \delta(x)\in\{d_0,d_1\} $$ Now we need to define the loss function: $$ \begin{cases} \gamma(\theta_0, d_0) = 0\\ \gamma(\theta_0, d_1) = 1 \end{cases} \qquad \begin{cases} \gamma(\theta_1, d_0) = 1\\ \gamma(\theta_1, d_1) = 0 \end{cases} $$ Now, we set the things up to derive Maximum a Posteriori. Given a prior probability $\pi(\theta)$ , let us evaluate a posterior probability $\pi(\theta|x)$ . Directly applying Bayes' theorem: $$ \pi(\theta|x) = \cfrac{L(x, \theta)\pi(\theta)}{\int L(x, \theta)\pi(\theta)d\theta} $$ The Bayes risk: $$ \begin{align} r(\delta) &= \mathbb{E}_{\theta, x} \gamma(\theta, \delta(x))\\ &=\mathbb{E}_{\theta} \left[\mathbb{E}_{x}\left[\gamma(\theta, \delta(x))|\theta \right]\right]\\ &=\mathbb{E}_{x} \left[\mathbb{E}_{\theta}\left[\gamma(\theta, \delta(x))|x \right]\right]\\ &=\int f(x) \mathbb{E}_{\theta}\left[\gamma(\theta, \delta(x))|x \right] dx \tag{1} \end{align} $$ In our case: $$ \mathbb{E}_{\theta}\left[\gamma(\theta, \delta)|x \right] = \sum_{i=0}^{1} \gamma(\theta_i, \delta) \pi(\theta_i|x) \tag{2} $$ If you are given an $x \in \Omega$ value, you need to make a decision in favour of $H_0$ ( $\delta(x) = d_0$ ) or $H_1$ ( $\delta(x) = d_1$ ). Then: $$ \delta(x) = d_0: \qquad (2)=\mathbb{E}_{\theta}\left[\gamma(\theta, d_0)|x \right]=1\cdot\pi(\theta_1|x) \tag{3} $$ $$ \delta(x) = d_1: \qquad (2)=\mathbb{E}_{\theta}\left[\gamma(\theta, d_1)|x \right]=1\cdot\pi(\theta_0|x) \tag{4} $$ Recall, that the purpose is to minimize the Bayes risk (1), which reduces to minimization of (2) and finally to comparison of (3) and (4). For example, if: $$ \pi(\theta_1|x) > \pi(\theta_0|x) \Rightarrow \delta(x) = d_1 $$ That is exactly Maximum a Posteriori. Hope this helps.
