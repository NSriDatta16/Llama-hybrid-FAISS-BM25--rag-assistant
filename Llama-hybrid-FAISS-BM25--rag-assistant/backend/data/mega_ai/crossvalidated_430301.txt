[site]: crossvalidated
[post_id]: 430301
[parent_id]: 
[tags]: 
How is it possible for a VAE decoder to reconstruct n different classes while being limited to much lower k dimensions?

How is this even possible for the VAE Autoencoder to reconstruct n different classes while being limited to k dimensions in the bottleneck layer (k . For an example, I created a simple MLP-VAE with embedding size of only 2 and used the MNIST dataset which has 10 classes. To my astonishment, the model could easily reconstruct all classes with different latent varible values. This is very puzzling to me! Aren't the mean and std s that are created in encoder's part which are as large as the embedding size, supposed to specify each classes valid values? That is for example, all the variables that can create a 1, will have this mean and this std ! while the values needed to create 2's have that mean and that std ! etc) and basically the network uses these mean / std s to form separated regions, to sample from and create new digits later on? What is happening here? Why should this even work? How and where do all these digits come from then? They cant be coming from only two means, two stds!? can they?
