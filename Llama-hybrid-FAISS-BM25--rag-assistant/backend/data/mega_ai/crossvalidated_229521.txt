[site]: crossvalidated
[post_id]: 229521
[parent_id]: 
[tags]: 
Election fraud detection: the statistics of Quick Count

I’m reading the book Quick Count and Election Observation (chapter 5). I’m interested in understanding the statistics used in Quick Counts. Quick Counts is a methodology for verifying official election results by counting (in parallel to the official counting) the vote counts of some polling places. The Quick Count works as follows: A certain sample size $n$ is decided before hand, and the expected margin error is computed as well. In the election day, $n$ of the polling places are sampled at random. The results of each sampled polling place (number of votes for each candidate) are reported and summed up. In order to check if the elections are flaw or not, the results of the sampling are compared to the official results. (Note that the sampling unit is not voters but polling places, that is, aggregation of voters). The proportion of votes is modeled as a binomial distribution with parameter $p$. The objective is to sample that binomial distribution, and estimate $p$ and find the confidence interval such that $p \in \hat{p} \pm \epsilon$, were $\hat{p}$ is the sample mean and $\epsilon$ the margin error. Usually, $\epsilon\in [0,1]$ is a design parameter (given by the user) and one has to find the smallest sample size $n$ (number of polling places) such that the margin error is smaller than $\epsilon$. The problem is similar to that of sampling a binomial distribution, but the samples are not independent since they votes are sampled in bulks (one for each polling place sampled). My concerns are regarding how the margin error and sample size are computed. According to the book linked above: First they compute the number of voters that should be sampled. $n_{v} =\frac{p(1-p)}{\frac{{\epsilon}^2}{z^2}+\frac{p(1-p)}{N}}$, where $N$ is the total population of potential voters, and $z$ is the z-score of a normal distribution at the desired confidence level. $p$ is usually set to $0.5$ (maximum variance of the binomial distribution). (see example in page 73, and explanation in page 72) The number of polling places to sample $n$ is determined by $n=\frac{n_{v}}{\text{average number of voters per polling palce}}$. The real margin error is computed (see page 66 and 77) $\epsilon_{r}=z\frac{s}{\sqrt{n}}$, where $s$ is the heterogeneity (i.e., the square root of the variance). Q1: Why do they compute two margin errors $\epsilon$ and $\epsilon_{r}$. I understand that only $\epsilon_{r}$, the margin error that is computed with the number of polling places, is correct. Do you think that is done this way in order to have an idea of the best-case margin error? Q2: Why not compute the sample size of polling place directly with $\epsilon$? ($n=z^2\frac{p(1-p)}{\epsilon^2}$) Polling places have different number of votes. In order to compute the expected proportion of votes for a candidate. There are two options (the book does not specify which one to use) Sum up the votes in all sampled polling places and compute the proportion. This would give to each vote the same weight in the proportion estimation. However, polling places with less votes will have less weight, and I’m afraid that the way to compute the margin error, $\epsilon_{r}$ is not correct for this case. Q3: how would you compute the margin error in this case? Compute the proportion of votes for each sampled polling place, average those proportions. This would give each polling place the same weight, but different weight to each vote. In this case I think that $\epsilon_{r}$ is computed correctly, but I think it does not make sense to give more weight to votes in polling places with few votes. Q4: Which option would you use to compute the expected proportion of votes 1) or 2).
