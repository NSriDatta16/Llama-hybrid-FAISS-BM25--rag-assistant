[site]: crossvalidated
[post_id]: 74388
[parent_id]: 74042
[tags]: 
This is one of the generalizations of classification that are tackled in semi-supervised learning. If you have a measurement of certainty you can use approaches that allow weighting of training instances. The higher the certainty, the larger the corresponding instance weight. Examples of such approaches include instance-weighted SVM and logistic regression. I'm sure weka has implementations of these algorithms. If all else fails, sample multiple instances from the instances with high certainty. You can use this approach for traditional SVM or LR. Example: SVM If I am not mistaken, weka has interfaces to LIBSVM . LIBSVM allows you to solve class-weighted SVM in all its releases, and instance-weighted SVM in special versions of each release. I'm going to assume weka does not support the latter (which is what you need). Class weighted SVM minimizes the following objective function: $$ \min_{\mathbf{w},\xi} \|\mathbf{w}\|^2 + {\color{blue}C_{pos}} \sum_{i \in \mathcal{P}} \xi_i + {\color{blue}C_{neg}} \sum_{i \in \mathcal{N}} \xi_i, $$ with $\mathbf{w}$ the separating hyperplane in feature space, $\xi$ the slack variables (which model training misclassification) and $\mathcal{P}$ and $\mathcal{N}$ the set of support vectors belonging to the positive and negative class, respectively. Using the weights $C_{pos}$ and $C_{neg}$ you can assign different misclassification penalties between classes. Based on your question, it seems like you would ideally want to use 6 different weights (2 classes $\times$ 3 levels of certainty). You can achieve this for many approaches by duplicating samples of the points with high certainty. For example, in terms of SVM, using the same data instance twice yields an identical solution to doubling its associated $C$ value. This is a very easy way to assign high misclassification penalties to certain data instances. You can follow the same approach for logistic regression.
