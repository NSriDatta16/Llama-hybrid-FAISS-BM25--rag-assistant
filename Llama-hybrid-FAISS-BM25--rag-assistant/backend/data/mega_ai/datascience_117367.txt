[site]: datascience
[post_id]: 117367
[parent_id]: 
[tags]: 
Is there any benefit to using cross validation from the XGBoost library over sklearn when tuning hyperparameters?

The XGBoost library has its own implementation of cross validation through xgboost.cv() . It looks like it requires data be stored as a DMatrix . Instead of using xgboost.cv() , I could use XGBoost's sklearn API to perform cross validation using sklearn with GridSearchCV() or RandomizedGridCV , or cross_validate() . If I use the sklearn implementations of cross validation, I could use pandas.DataFrame 's and familar sklearn functions/classes. I have two questions: Are there any important differences between performing cross validation using XGBoost directly and using sklearn? Is xgboost.cv() optimized in some way that the sklearn cross validation functions are not? I understand there are some superficial difference in how to train the models. Is there any benefit to using DMatrix over pandas.DataFrames? It looks like in older versions of XGBoost, you couldn't use pandas.DataFrames.
