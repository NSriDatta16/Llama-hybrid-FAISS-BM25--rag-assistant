[site]: crossvalidated
[post_id]: 586822
[parent_id]: 586821
[tags]: 
The default caret approach is form = 'corr' , in which the square of the correlation coefficient between predicted and observed is calculated. This prevents any possible negative $R^2$ values. 'form = traditional' is 1 - (the sum of squared differences between the true value and the prediction / sum of squared differences between the observed value and the mean of all values). This theoretically allows for negative values, if the model predictions are on average worse than just predicting the average value. In your case, you have a very strong correlation in your plot, but the precise values on the X- and Y-axes are very different because you added 1 to all 'predicted' values in the simulation. This makes the predictions very bad, which can be easily seen if we replot this with better axis limits and add a 1:1 line indicating where predictions and observations would be identical: This large deviation from the diagonal is a bias that makes the model predictions worse than just predicting the mean (based on mean squared error, or really any criterion in this case) even though the predictions are highly correlated with the observed values . This is a weird situation but I have encountered models with negative $R^2$ with real data, though not because of such a simple bias/offset. So I personally prefer the 'traditional' calculation and believe it provides a more accurate picture of model performance. Visualisation always communicates a more complete picture than a summary statistic, though, so I would still recommend examining a plot of predicted vs. observed. You might be interested in these related threads: Is $R^2$ useful or dangerous? What does negative R-squared mean? Manually calculated $R^2$ doesn't match up with randomForest() $R^2$ for testing new data Also note that the function you are using is deprecated, use postResample instead.
