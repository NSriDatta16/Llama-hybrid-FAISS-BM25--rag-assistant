[site]: datascience
[post_id]: 128391
[parent_id]: 
[tags]: 
In reinforcement learning, why learn Q rather than V?

Why do we learn the action-value function $Q(s,a)$ rather than the (just state) value function $V(s)$ ? At least for deterministic environments? $V$ is much smaller than $Q$ , and they are trivially relatedâ€”just scan over all possible actions and simulate to the next states to arrive at the $Q$ (which is what the Q learning algo must do anyway). I.e. $Q(s,a)=V(s')$ where $s'$ is the next state from $s$ after doing $a$ . So why not just learn the $V$ s? Is the main reason because of stochastic environments? Related: What is the Q function and what is the V function in reinforcement learning?
