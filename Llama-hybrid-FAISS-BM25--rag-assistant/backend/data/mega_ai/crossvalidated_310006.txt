[site]: crossvalidated
[post_id]: 310006
[parent_id]: 310005
[tags]: 
Duplicates: for an SVM it is actually only important if you are using a soft-margin SVM. A hard-margin SVM is required to perfectly separate your training data, so it doesn't matter how many duplicates and such there are (the downside being, the algorithm fails if it cannot perfectly classify your data). For a soft-margin SVM, it is allowed to ignore a few samples in constructing the decision boundary (how many is dependent on a hyperparameter) -- if there are multiple points at the same location it would have to ignore all of them or none of them, effectively pushing the algorithm to find a solution that correctly classifies the duplicated point. So, if duplication is something that naturally arises in your data it is a good thing, but a hard-margin SVM would not -- algorithmically -- notice it. If an example is present in both sets then you should definitely take it out of one, assuming you (a) know they are identical in advance and (b) you also know which set to take it out of. Otherwise a soft-margin SVM should be reasonably robust to them (see 1), but too many will make your results heavily hyperparameter-dependent. With regards to class imbalance see the answer here: class imbalance in SVMs
