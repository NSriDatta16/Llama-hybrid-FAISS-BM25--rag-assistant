[site]: crossvalidated
[post_id]: 8829
[parent_id]: 8808
[tags]: 
So you have a density of: $$p(X_i|\theta)=\frac{1}{2\theta}\;\;\;\; X_i\in[-\theta,\theta]$$ Now this is what is called a scale density, and $\theta$ is a scale parameter, just like the standard deviation in a normal distribution. Now to do a Bayesian CI you require a prior distribution for $\theta$. Because $\theta$ is a scale parameter, the prior describing complete initial ignorance is given by: $$p(\theta|\theta_L,\theta_U) = \frac{1}{\theta [log(\frac{\theta_U}{\theta_L})]} \;\;\; \theta\in[\theta_L,\theta_U]$$ In your comment, you state that "the improper prior is to be used" so this means that you take the upper limit $\theta_U\rightarrow \infty$ and the lower limit $\theta_L\rightarrow 0$. But this is in principle, to be done at the end of the calculation, and not at the start. This is to ensure that you don't have an "infinity" floating around in your results, making them arbitrary. If the limit does not exist, then "probability theory" is "telling you" that the actual bounds are important to your conclusion. I assume you want to work this out for yourself, so the remainder just goes: calculate the posterior (Note: I have used $s$ as a dummy variable to indicate that the denominator is independent of $\theta$). $$p(\theta|D,\theta_L,\theta_U)=\frac{p(\theta|\theta_L,\theta_U)\prod_{i=1}^{n}p(X_i|\theta)}{\int_{\theta_L}^{\theta_U}p(s|\theta_L,\theta_U)\prod_{i=1}^{n}p(X_i|s)ds}$$ Calculate calculate the lower bound $C_L$ and upper bound $C_U$ such that there is a $100(1-\alpha)$% probability that $C_L This should give you enough of the "machinery" to go and solve the problem. However, if you need more details, I can post them.
