[site]: datascience
[post_id]: 24797
[parent_id]: 
[tags]: 
Should I use harmonic mean for averaging metrics in repeat runs of classifier evaluation?

I am testing an LSA classifier with a randomised set of test-cases, picked from a larger set using under-sampling (to balance the classes). I am performing parametric sweeps to examine the behaviour of the classifier under different hyperparameters. I noticed early on that the results have a margin of error, making the performance fine-tuning difficult. So I implemented an averaging technique which simply runs the same parametric scenario N times with different random test-cases and averages the results - using arithmetic mean. (I believe this qualifies as cross-validation.) This works well and certainly smooths out the performance charts, so I can see the parameter change effects more clearly. However, I recently learned about the harmonic mean, and now I suspect I should be using it for this purpose - because I am averaging a rate? I think it probably doesn't matter for looking at one parameter sweep chart (it's relative to itself), but it probably will matter when I come to compare different classifiers (absolute comparison of scores). Note: I am not talking about using harmonic mean to produce F1 scores from TPR, FPR etc. I am only talking about using it to average these performance metrics over multiple repeats of the entire test process. e.g. These charts show "confusion matrix" scores when sweeping a param. The first chart shows a single run. It looks like there might be a performance sweet-spot at k=70 but I'm pretty sure this is just noise due to the random selection of the test-cases (and the limited number I have). This is the same test run 10 times on different test-cases. (You can see the apparent minimum has gone, the results are smoother and even the ACd trend line is flat. This shows this range of k param isn't affecting performance.) This is averaged by arithmetic mean, I'm wondering if harmonic mean is more correct.
