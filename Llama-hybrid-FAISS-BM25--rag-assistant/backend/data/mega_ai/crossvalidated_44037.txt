[site]: crossvalidated
[post_id]: 44037
[parent_id]: 44019
[tags]: 
My advisor and I wrote an algorithm called k -information gain nearest neighbors, which I think will be helpful for you. One of the basic differences between our approach and that of typical knn is that we use mutual information as the distance metric--that is, after training, the class of a new document is determined by the k most similar documents, in the information theoretic sense. Here's the paper describing for text classification: Ambert & Cohen, 2011 , but people have used it for other applications as well.
