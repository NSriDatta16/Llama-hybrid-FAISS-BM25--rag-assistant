[site]: crossvalidated
[post_id]: 247371
[parent_id]: 
[tags]: 
Accuracy of confidence intervals using gradient descent linear regression

I'm trying to build a regression model and I'd like to analyze the impact of each feature with confidence intervals, but because I'm working with big data I'm forced to use a distributed machine learning package. I'm providing a step size and a # of iterations, so GD is trying to find the minimum but I have no way of knowing if it actually gets there or not. It looks like I could use bootstrap to estimate standard errors, but even so, would they mean anything because of the aforementioned convergence questions? If not, what are some other options for evaluating feature impact?
