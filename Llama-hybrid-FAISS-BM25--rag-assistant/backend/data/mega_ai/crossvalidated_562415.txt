[site]: crossvalidated
[post_id]: 562415
[parent_id]: 562413
[tags]: 
Moving-average models are always weakly stationary because they are finite linear combinations of a white noise sequence for which the first two moments are time invariant. For example, consider the $MA(1)$ model $$r_{t}=c_{0}+a_{t}-\theta_{1}a_{t-1} \quad \text{or} \quad r_{t}=c_{0}+(1-\theta_{1}B)a_{t}$$ Taking expectation of the model, we have $$\mathbb{E}(r_{t})=c_{0}$$ which is time invariant of MA(1). Taking the variance we have : $$Var(r_{t})=\sigma_{a}^2+\theta_{1}^2\sigma_{a}^2 = (1+\theta_{1}^2)\sigma_{a}^2.$$ where we use the fact that $a_t$ and $a_{t−1}$ are uncorrelated. Again, $Var(r_t)$ is time invariant. Your question and the previous statement applies to general $MA(q)$ models, and we obtain two general properties. First, the constant term of an $MA$ model is the mean of the series [i.e., $\mathbb{E}(r_{t})=c_{0}$ ]. And second in general, the variance of an $MA(q)$ model is: $$Var(r_{t})=(1+\theta_{1}^2+\theta_{2}^2 \dots +\theta_{q}^2)\sigma_{a}^2.$$ Edit This $ΜΑ(4)$ model is from Hamilton's book "Time Series Analysis" page 50.I have added the $a$ term in the example.Hope that answers your question. # MA(4) :Y_t= e_t - 0.6e_t-1,_ 1 + 0.3e_t- 2 - 0.5e_t-3 + 0.5e_t-4 n_samples = 100 θ1 = -0.6 θ2 = 0.3 θ3 = -0.5 θ4 = 0.5 μ = 5 α = 0.01 y = ε = np.random.normal(0,1,size=n_samples) for t in range(n_samples): y[t] = μ +α*t +ε[t] + θ1*ε[t-1] + θ2*ε[t-2] + θ3*ε[t-3] + θ4*ε[t-4] from statsmodels.graphics import tsaplots fig = tsaplots.plot_acf(y, lags=12)
