[site]: crossvalidated
[post_id]: 27661
[parent_id]: 27647
[tags]: 
Calculating moments is often a good place to start when looking at the shape of the data. For example the normalized first moment Sum(t*n)/Sum(n) might be all you need here. That is, because you multiple by time, it gives more weight to the values that take longer time, and higher order moments would give even more weight to tail. Sum(t*n)/Sum(n) is, of course, just the average time, but thinking in terms of moments gives the obvious next step of using higher order moments in determining the shape. Here's a graph: and the code to generate it: import matplotlib.pyplot as plt import numpy as np t = np.linspace(0, 1., 200) def f(a): f0 = np.exp(-a*(t-.1)) i = np.searchsorted(t, .1) f0[:i] = 1 return 200*f0 data = [f(a) for a in (10, 20, 30, 40)] def process(t, f): moment0 = sum(f) moment1 = sum(t*f) moment2 = sum(t*t*f) moment3 = sum(t*t*t*f) v1 = moment1/moment0 v2 = moment2/moment0 v3 = moment3/moment0 plt.plot(t, f) s = "%.2f %.4f %.5f" % (v1, v2, v3) return s vals = [] for d in data: val = process(t, d) vals.append(val) plt.legend(vals) plt.show() alternate: An variant on this approach is that since you have a bunch of data, most of it from good disks, you could calculate your average distribution, and then look at the difference between this and each individual distribution, and then process this difference. Final update: OK, so maybe you need 4th order moments to get something really clear. Why? Consider some rough estimates of the 3rd order for the B drive, and compare the first elements contribution to the a point on the tail (6*16**5)*(.017**3)=31 to (4*16**1)*(.283**3)=1.5 There are a lot more points in the tail, but maybe 100s, not thousands, so maybe these don't add up well enough. If you use 4th order, these become (6*16**5)*(.017**4)=.52 and (4*16**1)*(.283**4)=.41 , but again there are a lot more in the tail, so these should add up to something very distinct.
