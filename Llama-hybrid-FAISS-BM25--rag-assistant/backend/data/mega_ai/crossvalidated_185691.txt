[site]: crossvalidated
[post_id]: 185691
[parent_id]: 185688
[tags]: 
In that case (small sample), you should probably try a leave-one-out cross-validation. Using a single validation sample implies a big variance on the estimation of the performance of your model. Therefore, the results are not reliable and the decision tree is better than the random forest happens by pure chance. Leave-one-out cross-validation consists in dropping one variable and use the model train on the $n-1$ variables. Then you observe the difference between the predicted and the actual value of the remaining element. You performance will be evaluated on 59 elements, and not on 9 elements.
