[site]: datascience
[post_id]: 82180
[parent_id]: 
[tags]: 
Generative chatbots with BERT pretrained vectors

Most places seem to train generative chatbots with one hot encoded vectors. See here for example, and even the official tutorial on pytorch . But using one hot encoded vectors are undoubtedly the worst performing method. No tutorial seems to provide this using BERT vectors. Why hasn't chatbots been built with BERT vectors? Are BERT vectors are not meant to be used this way?
