[site]: crossvalidated
[post_id]: 167377
[parent_id]: 167259
[tags]: 
The short answer is that for classifier networks, an output activation is normally used that restricts $h_\theta(x)$ to the open interval (0, 1), so you never end up computing these $\log(0)$ values. Read on for details! This loss is known as the categorical cross-entropy . It measures the difference between the true distribution over labels, and the distribution generated by the neural network. This loss is usually used (instead of the mean-squared error) for a classifier network because it has nice gradient properties . Often, in a network used for classification in this way, the output layer uses a softmax activation to get the final $h_\theta(x)$ value: $$ g(\vec{z}) = \frac{\exp(\vec{z})}{\sum_i\exp(z_i)}. $$ This has several benefits: it normalizes the output values to sum to 1, it bounds the output values in practice to the open interval (0, 1). To generate a 0, for instance, the pre-activation input on a unit would have to be a negative number large enough to cause exp(x) to overflow to 0. Likewise, to generate a 1 output, the outputs of all other units would have to be zero, which is nearly impossible for the same reason. So it's basically safe to compute $\log(h_\theta(x))$ and $\log(1 - h_\theta(x))$ in the cross-entropy loss because in practice the $h_\theta(x)$ values are limited to the open interval (0, 1).
