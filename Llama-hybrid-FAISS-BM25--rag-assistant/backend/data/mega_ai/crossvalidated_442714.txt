[site]: crossvalidated
[post_id]: 442714
[parent_id]: 
[tags]: 
Why does thinning work in Bayesian inference?

In Bayesian inference, one needs to determine the posterior distribution of the parameters from the prior distribution and the likelihood of the data. As this computation might not be possible analytically, simulation methods may be required. In MCMC (Markov Chain Monte Carlo) algorithms, a Markov chain is generated, whose limit distribution is the desired posterior distribution. In practice, it might be difficult to assess whether convergence has been achieved. When you stop a Markov chain at a finite step, you do not have independent realizations, as each generated point depends on the previous ones. The thing is that, as the chain advances, such dependence will be lower and lower, and at infinity you would obtain independent realizations from the posterior. Thus, let us assume that we have stopped the Markov chain at a finite step, and that the sample obtained has significant autocorrelation yet. We do not have independent draws from the posterior distribution. Thinning consists in picking separated points from the sample, at each $k$ -th step. As we are separating the points from the Markov chain, the dependence becomes smaller and we achieve some sort of independent sample. But what I do not understand about this procedure is that, although we have an (approximately) independent sample, we are not still simulating from the posterior distribution; otherwise the whole sample would have present independence. So in my view, thinning gives more independence, which is certainly necessary to approximate statistics via Monte Carlo simulation and the law of large numbers. But it does not accelerate the encounter with the posterior distribution. At least, I do not know any mathematical evidence about the latter fact. So, actually, we have gained nothing (apart from less storage and memory demand). Any insight on this issue would be appreciated.
