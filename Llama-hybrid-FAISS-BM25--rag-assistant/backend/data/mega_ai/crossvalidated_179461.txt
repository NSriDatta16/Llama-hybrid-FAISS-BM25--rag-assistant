[site]: crossvalidated
[post_id]: 179461
[parent_id]: 
[tags]: 
how does one compute expectations for non-linear functions

I am continuing my struggles with approximate Bayesian inference methods. I have a fundamental doubt about how to compute certain expectations that arise during variational bayes, for example. So, my joint model is written as: $$ p(Y|W, \beta, X) = \prod_{i=1}^{N} p(y_i|x_i, w_i, \beta) p(w_i)p(\beta) $$ Here $W$ and $\beta$ are the model parameters and $W= \{w_i, w_2, w_3....w_i\}$ and i is the i-th observation. $y_i$ is the i-th output variable and $x_i$ is the corresponding input. So I have applied Variational Bayes and and factorized my model parameters according to the mean field approximation as $Q(W, \beta) = Q(W)Q(\beta)$. So, now if I want the posterior distribution over $Q(W)$, I have to take the expectation wrt to the $Q(\beta)$. So, looking at each $w_i$ in the first instance, I have: $$ p(y_i, w_i, \beta| x_i) = p(y_i|x_i, w_i, \beta) p(w_i)p(\beta) $$ Consequently, $$ \log Q(w_i) = E_{\beta}[\log p(y_i|x_i, w_i, \beta) + \log p(w_i) + \log p(\beta)] $$ where $E[\beta]$ represents the expectation wrt to $Q(\beta)$ Taking constant terms out: $$ \log Q(w_i) = E_{\beta}[\log p(y_i|x_i, w_i, \beta) + \log p(w_i)] + C $$ My problem now is that the first term is modeled using a Gaussian distribution but the parameters $\beta$ are connects $y_i$ and $x_i$ through a non-linear transformation function. So, in the end I end up with having to compute integral of the expression of the form: $$ E_{\beta}[y-T(x)]^T[y-T(x)]\big] $$ Assuming $Q(\beta)$ takes some known form, how may I proceed to compute this expectation given that $T$ can be any arbitrary function?
