[site]: crossvalidated
[post_id]: 317334
[parent_id]: 316962
[tags]: 
There are several issues here. In particular, there seem to be some confusions about how to simulate a standard logistic regression. Briefly, you don't add noise around... the probability "signal" . As a result of the way you did this, there is a huge amount of variability in the resulting 'binomial'(-esque) data, way more than there should be. Here are the probabilities in your dataset: plot(flips[,1]/rowSums(flips)) If those .4+ observations end up on one side or the other, they will act as 'outliers' (they aren't really) and drive a type 1 error in a model that doesn't take into account the fact that these data aren't really binomial. Here is a version that uses a simple hack to allow the model to detect and account for overdispersion: set.seed(5082) pval This is the model summary from the last iteration. Note that the dispersion is estimated to be $\approx 12\times$ what it should be for a true binomial: s # Call: # glm(formula = flips ~ yrandom, family = "quasibinomial") # # Deviance Residuals: # Min 1Q Median 3Q Max # -5.167 -2.925 -1.111 1.101 8.110 # # Coefficients: # Estimate Std. Error t value Pr(>|t|) # (Intercept) -1.96910 0.14942 -13.178 Here is another version, where I fit the same model that you do, but just generate the data without the added noise around the signal. (Note that code that is otherwise the same is omitted for brevity.) set.seed(541713) ... pactual
