[site]: crossvalidated
[post_id]: 600247
[parent_id]: 
[tags]: 
L2 regularisation in DNN context

could you explain me in DNN (deep neural networks) context the meaning of "m" and "w" in the following formula (L2 regularization)? Cost function = Loss + Lambda/2m * sum||w||(exp[2]) I know that m is the number of data points while w the weight. This in a "regression context". I'm a little bit confused to figure it out in the context of DNN. Thank you in advance
