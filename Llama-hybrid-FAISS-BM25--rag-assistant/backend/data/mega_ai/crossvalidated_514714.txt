[site]: crossvalidated
[post_id]: 514714
[parent_id]: 514688
[tags]: 
Not quite the same but Bayes Linear (BL) Statistics tells us how to do bayesian analysis if we only specify means and variances (and covariances). I.e. we are only making limited statements about our beliefs. It is also advantageous over a "full" bayesian analysis in the sense that it is entirely tractable and therefore much faster than computational bayesian methods. If you specify $\theta \in [a,b]$ then under a BL framework you might say $E(\theta) = m = 0.5(a+b)$ (the mid point). You would also then need to specify the variance. You might say that $m + k \times var(\theta) = b$ . A sensible choice would be $k=3$ by Pukelshiems $3\sigma$ rule. You can then perform BL updates in light of data which give you an updated mean and variance of $\theta$ . This isn't the same as a posterior distribution but is a pair of posterior moments. Essentially, you don't get as much information as a full bayes analysis but that's because you're not putting as much in
