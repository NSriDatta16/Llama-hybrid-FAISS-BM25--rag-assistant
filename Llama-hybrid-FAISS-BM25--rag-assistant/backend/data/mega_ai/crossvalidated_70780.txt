[site]: crossvalidated
[post_id]: 70780
[parent_id]: 70566
[tags]: 
Arguably, Bayesian logistic/probit regression would be better if you had informative prior, or if there was perfect or quasi-perfect separation or if you wanted to fit a hierarchical model. If you have an informative prior, then use it. And nothing better than use it in a Bayesian approach. If there is perfect separation, a good prior (even if only weakly informative) may help you to deal with this problem . Last, but not least, I think Bayes excels with hierarchical models. And yet, I'd still favor a Bayesian approach even if none of the above is true. And for one simple reason: It's easier to interpret Bayesian results than frequentist ones. As it is known, it's hard to correctly compute standard errors for interaction terms in logistic/probit regression. However, it's quite easy to compute the uncertainty of interaction terms with a Bayesian approach. See the chosen answer to this question of mine about interaction terms in logistic regression. Also, with Bayes you can use posterior predictive checks to check the fit of your model, a great bonus!
