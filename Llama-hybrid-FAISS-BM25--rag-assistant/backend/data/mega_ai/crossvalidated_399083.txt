[site]: crossvalidated
[post_id]: 399083
[parent_id]: 398974
[tags]: 
Well, $p_z(E(x))$ doesn't seem to be the best metric as it can be maximized with with a encoder network which disregards the standard normal prior and always outputs 0 (or some very small values close to 0, so that the decoder can do its job). More broadly , when comparing VAEs to other generative models (RBMs, PixelRNN, PixelCNN, GLOW, NICE, many GAN variants, etc) which don't have any autoencoder structure and don't have any concept of "reconstruction loss" or "likelihood of the encoding of a data point", it doesn't make sense to use either of those measures. You can only really rely on 1. the subjective quality of the generated samples, and 2. likelihood of the model (although GANs don't allow this, and with VAEs it can be hard)
