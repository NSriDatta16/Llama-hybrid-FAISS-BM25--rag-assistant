[site]: crossvalidated
[post_id]: 114800
[parent_id]: 114719
[tags]: 
Well, in Machine Learning the thing called Cross Validation is performed pretty often for purpose of model testing (test if that type of a model with these hyper-parameters - like number of degrees of freedom or whatever - fits your problem) - you split your data several times into train and test data sets, then run optimization over training set and compute whatever quality over tests data. The most confidential way is to run so called "QxT-fold cross validation". The pseudocode could could like: cv_values = [] for t in range(T): split = randomsplit(data, number_of_parst = Q) for test_id in range(Q): model.fit(split[:test_id] + split[test_id + 1:] # test on everything excepting test_id cv_values.append(model.test(split[test_id])) cv_values.mean() # whatever
