[site]: crossvalidated
[post_id]: 463879
[parent_id]: 
[tags]: 
Can the elliptical slice sampler be used to infer kernel hyperparameters for GP Regression?

Context Suppose I have some sample points $X$ , and responses, $\mathbf{y}$ . I wish infer the mechanism by which $\mathbf{y}$ is generated from $X$ using a Gaussian Process (GP) as a prior distribution, i.e., I assume $\mathbf{y}$ can be modelled as a draw from a GP: $p(\mathbf{y}|X, \theta) = \mathcal{N}(\mathbf{y}; m(X), K(X, X | \theta))$ where $m$ is a function describing the prior mean, $k$ is a covariance kernel which designates the covariance between each of the points in $X$ , and $\theta$ is a vector of hyperparameters which tune the behaviour of the kernel. Supposing I fix (choose) $m$ and $k$ , I am required to infer suitable values of the hyperparameters, $\theta$ , given the likelihood function defined above and the data. In other words, this is a canonical GP regression problem. One way of doing this is via Markov-Chain Monte-Carlo, in which case we sample from something that is (hopefully) proportional to: $p(\theta | X, \mathbf{y}) \propto p(\mathbf{y} | X, \theta) p(\theta)$ Which can be accomplished using (for example) Hamiltonian Monte-Carlo (HMC). I'll add for reference that I've had no (relevant) issues implementing or using HMC to accomplish the above. Question One alternative to HMC I have seen mentioned for performing MCMC for GP models is Murray et. al. 's elliptical slice sampler (ESS), though after studying the paper I am a little unsure how the algorithm might be used to sample the kernel hyperparameters, $\theta$ . In particular, if I look at open source implementations (such as the python version here ), the algorithm appears to accept and propose parameter vectors of dimension equivalent to the latent function one assumes is Gaussian distributed: that is, the algorithm appears to propose latent functions drawn from a fixed covariance matrix, and not samples of the kernel hyperparameters. Is it possible to use ESS to sample kernel hyperparameters for the type of canonical GP regression problems described above (presumably via extra operations after sampling the latent function), or do I misunderstand the purpose of the algorithm?
