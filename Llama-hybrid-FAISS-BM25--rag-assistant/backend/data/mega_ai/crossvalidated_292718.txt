[site]: crossvalidated
[post_id]: 292718
[parent_id]: 
[tags]: 
Test Accuracy for Unbalanced Dataset

I have a binary, highly unbalanced dataset with a ratio of 1:20 between the two classes. Now to account for this, I have constructed mini-batches with equal ratio between the two classes, in order to artificially balance the ratio. My current algorithm samples the underlying classes and feeds that into the neural network followed with back-propagation. Questions: 1) With regards to my test-set, I'm just wondering should my test-set be randomly selected (results in a very fuzzy graph) or should I keep my test-set constant (as in without random sampling of the entire test set)? 2) What are the shortcomings between each approach & which is more valid?
