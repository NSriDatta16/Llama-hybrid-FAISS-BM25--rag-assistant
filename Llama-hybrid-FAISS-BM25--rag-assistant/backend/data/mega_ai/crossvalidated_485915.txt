[site]: crossvalidated
[post_id]: 485915
[parent_id]: 
[tags]: 
Why does increasing K increase bias and reduce variance

I get confused when it comes to KNN, why exactly does increasing K increase bias and reduce variance Correct me if Iâ€™m wrong My knowledge, suppose we have a regression problem If k=1 and our nearest neighbor has a value of 5, that means our bias is zero right , our predicted value will be 5, bias=5-5, For variance if a different data set was used and the value was 7, our variance would be 2,(high variance) If k=3 and have values of 4,5,6 our value would be the average And bias would be sum of each of our individual values minus the average And variance , if a different data set Witt values 4,6,7, average would be 5.667 and variance would be 0.6666( low variance)
