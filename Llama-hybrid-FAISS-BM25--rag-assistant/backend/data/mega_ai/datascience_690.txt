[site]: datascience
[post_id]: 690
[parent_id]: 683
[tags]: 
Train 2 generative models, one for each dataset (spam only, spam plus ham), that will give you the probability that a datapoint is drawn from the same probability distribution of the training data. Assign emails as spam or ham based on which model gives you the highest probability of the document arising from the training data used to train it. Example generative models are RBM's, autoencoders (in that case, which model has the lowest reconstruction error). There are likely some bayesian generative models also that will assign a probability to a data point based on some training data. The best option though would be to take time to curate a second dataset containing only ham. That will give you higher classification accuracy. Assuming a lower proportion of spam to ham emails, that should not be too hard. You can even use Mechanical Turk if you lack the time or resources (or interns \ graduates students or other cheap labor).
