[site]: crossvalidated
[post_id]: 426903
[parent_id]: 426900
[tags]: 
No, that is needlessly restrictive. There are a large range of interpretable models including not just (as Frans Rodenburg says) linear models, generalized linear models and generalized additive models, but also machine learning methods used for regression. I include random forests, gradient boosted machines, neural networks, and more. Just because you don't get coefficients out of machine learning models that are similar to those from linear regressions does not mean that their workings cannot be understood. It just takes a bit more work. To understand why, I'd recommend reading this question: Obtaining knowledge from a random forest . What it shows is how you can approach making almost any machine learning model interpretable.
