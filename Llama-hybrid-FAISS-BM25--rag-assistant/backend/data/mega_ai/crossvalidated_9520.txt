[site]: crossvalidated
[post_id]: 9520
[parent_id]: 4473
[tags]: 
You use the example "January, February, and March", and I hope that's more for illustration and it isn't literally all the data you have. For monthly data, you really should have 3+ years of data, and places like the Census Bureau won't touch a monthly series with less than 7 years of data. Also, you don't mention exactly what data you have for each month, but it really makes a difference. Simply taking a single sales number for each month and fitting a straight line through them (lm) isn't really much of a model. It might give you an idea of the overall trend, but not realistic predictions. If you have monthly data on other factors that are primary drivers of sales, it might work. Then, as chl says, if you want to have an idea if your approach will work, you need to look at the residuals ( resid (lm_model) ) with commands like acf and qqnorm to see if the errors from your model are basically random -- which is what lm assumes -- or if they have a pattern to them, in which case your model is missing something important. Obviously, the ultimate test is how well your model predicts on data that it has not seen, over the long run, but with small amounts of data or the wrong data you can fool yourself with an initial lucky "prediction" and really get embarrassed down the road when the data and approach inevitably fail. Usual models for univariate time series (such as monthly sales figures and no other data) would involve more complicated models that take some experience to fit, such as arima or the forecast package.
