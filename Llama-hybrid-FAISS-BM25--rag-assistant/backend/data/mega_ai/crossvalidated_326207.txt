[site]: crossvalidated
[post_id]: 326207
[parent_id]: 326198
[tags]: 
1) Should XGBClassifier and XGBRegressor always be used for classification and regression respectively? Basically yes, but some would argue that logistic regression is in fact a regression problem , not classification, where we predict probabilities . You can call predicting probabilities "soft classification", but this is about a naming convention. 2) Why does objective ='reg:linear' option even exist for XGBClassifier? Shouldn't it be only available in XGBRegressor? Logistic regression uses logistic loss function , but no one prohibits you from minimizing squared loss, i.e. squared difference between predicted probabilities and the target zeros and ones. As far as I understand from the documentation, this is what XGBoost will do if you use the 'reg:linear' parameter in here. See also the What is the difference between linear regression and logistic regression? thread. 3) Is "explained variance" the best metric for regression model evaluation? or perhaps RMSE? There is no such a thing as "the best metric", if there was, we would be using it for all the problems and didn't have multiple metrics. Metric is problem specific.
