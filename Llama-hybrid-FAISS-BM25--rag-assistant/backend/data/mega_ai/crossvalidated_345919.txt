[site]: crossvalidated
[post_id]: 345919
[parent_id]: 345737
[tags]: 
At this point in time, its not well-understood when and why certain regularization methods succeed and fail. In fact, its not understood at all why deep learning works in the first place. Considering the fact that a sufficiently deep neural net can memorize most well-behaved training data perfectly, there are considerably more wrong solutions than there are right for any particular deep net. Regularization, broadly speaking, is an attempt to limit the expressivity of models for these "wrong" solutions - where "wrong" is defined by heuristics we think are important for a particular domain . But often it is difficult to define the heuristic such that you don't lose the "right" expressivity with it. A great example of this is L2 penalties. Very few methods that would be considered a form of regularization are generally applicable to all application areas of ML. Vision, NLP, and structured prediction problems all have their own cookbook of regularization techniques that have been demonstrated to be effective experimentally for those particular domains. But even within those domains, these techniques are only effective under certain circumstances. For example, batch normalization on deep residual networks appears to make dropout redundant, despite the fact that both have been shown to independently improve generalization. On a separate note, I think the term regularization is so broad that it makes it difficult to understand anything about it. Considering the fact that convolutions restrict the parameter space exponentially with respect to pixels, you could consider the convolutional neural network a form of regularization on the vanilla neural net.
