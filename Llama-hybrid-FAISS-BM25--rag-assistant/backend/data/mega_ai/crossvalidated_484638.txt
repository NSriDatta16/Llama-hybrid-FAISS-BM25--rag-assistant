[site]: crossvalidated
[post_id]: 484638
[parent_id]: 484590
[tags]: 
Letting the coordinates of $p$ points be $\beta_i,$ $i=1,\ldots, p,$ the signed distances with noise are $$y_{ij} = \beta_i - \beta_j + \epsilon_{ij}=\mathbf{x}_{ij}\beta + \epsilon_{ij}$$ with iid Normal errors $\epsilon_{ij}$ and model matrix $x_{ij,k} = \delta_{ik}-\delta_{jk}.$ Not all $p$ coefficients are identifiable, however, because the distances don't determine the location. But if we arbitrarily fix one of the coefficients, say $\beta_1=0,$ we can estimate all the other locations relative to this one. This is an Ordinary Least Squares (OLS) problem and so can be solved with the usual OLS machinery. To illustrate, I generated four random points at locations 1.9 11.6 5.6 9.3 The model matrix $X = (x_{ij, k})$ (with its first column, for $\beta_1,$ omitted) is Point Interval 2 3 4 1-2 1 . . 1-3 . 1 . 1-4 . . 1 2-3 -1 1 . 2-4 -1 . 1 3-4 . -1 1 For instance, the first row in this matrix says the distance between points 1 and 2 equals $(1,0,0) (\beta_2,\beta_3,\beta_4)^\prime = \beta_2 = \beta_2-\beta_1$ (because, implicitly, $\beta_1=0$ ). The last row says the distance between points 3 and 4 is $-\beta_3 + \beta_4.$ The least squares estimates, compared to the locations, are good: 2 3 4 True location 9.8 3.8 7.5 Estimate 9.8 3.1 7.8 (Notice that "true location" is relative to the first point at 1.9 .) As another illustration, I created 400 random points (at typical inter-point distances of $3$ ) and measured their $400(399)/2=159\,600$ distances with Gaussian noise of unit standard deviation (which is a fairly large fraction of these distances, making this a stringent test). Rather than print out the results, it's better to graph the $399$ coefficient estimates! You can see it works very well. The reason is that we have $399$ measurements associated with each point, so the imprecision in each estimate should be about $1/\sqrt{399}\approx 0.05,$ or about $1.7\%$ of the average nearest-neighbor distance. The imprecision is about twice that because these measurements are not independent. The software fit this model (of $159\,600$ observations and $399$ variables) in a couple of seconds. I used a sparse matrix for $X$ to save RAM. This is the complete R code for generating the examples and figures. (Change n to n for the figures.) The estimates are stored in the vector b . noisy_dist = function(x, sigma=1){ out
