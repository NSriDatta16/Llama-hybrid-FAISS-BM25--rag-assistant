[site]: datascience
[post_id]: 36995
[parent_id]: 
[tags]: 
Is it a good idea to normalize the outputs of a Neural Network for Regression, when the different outputs vary in magnitude?

I understood that it is not necessary to scale the output of a neural Network when I predict a single value via regression. Is it necessary do normalize the Outputs of my neural Network if I have multiple outputs that vary in magnitudes between 10^-2 and 10^4? My intuition would tell me that the loss function might ignore the smaller values and only focus on the values of a bigger magnitude.
