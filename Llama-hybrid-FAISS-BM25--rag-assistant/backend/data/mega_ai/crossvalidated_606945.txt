[site]: crossvalidated
[post_id]: 606945
[parent_id]: 606828
[tags]: 
If the treatment impacts only a tiny fraction of users, you should analyze just the impacted subset because even a large effect on a small set of users could be diluted until it becomes statistically undetectable. In other words, your analysis sample should include only users eligible for personalization. One way to think of this is that personalization changes the experience for the 1700 users but not the 483K. If you average the effect for the entire population of users, you are mixing the effect for 1700 with 483K zeros. Instead, you should randomly split the 1700 personalization-eligible users in half. The first group should be sent the personalized e-mail, and the second the unpersonalized e-mail (or perhaps nothing, depending on what you actually plan to do). The analysis would compare the mean outcomes between the two groups. Since personalization is costly, you may want to make the null that the average/total effect is greater or equal to the average/total cost of personalization rather than zero. More broadly, this approach is called "triggering" and can improve the sensitivity (statistical power) of the test. The tradeoff is that the estimated effect does not apply to your total user base, just the folks eligible for this particular personalization. A good reference is Chapter 20 of Kohavi, Tang, and Xu's Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing
