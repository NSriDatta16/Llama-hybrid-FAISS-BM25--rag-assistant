[site]: crossvalidated
[post_id]: 107874
[parent_id]: 
[tags]: 
How to deal with a skewed class in binary classification having many features?

I am doing data analysis in the mobile ad targeting domain. I have around 18 features and for a combination of these features, the result is either True or False (1/0) depending on whether the impression was clicked or not. The problem here is that the output class is highly skewed . Click though rate is around 0.4% . (i.e value is 1 only 4 out 1000 times). I have a data set of 2 million rows and I am using 90% as train set and 10% as test set. I have used logistic regression from sckit-learn package in python . Now after training my model I get all values for test set as 0. Please tell me what the problem could be and what should I do to solve it? P.S. : I have tried increasing my data set size and also reducing the number of features(even to just one feature). If I see the probability of each class(0/1) in the test set, I get around 0.002 - 0.005 for a 1. Thanks
