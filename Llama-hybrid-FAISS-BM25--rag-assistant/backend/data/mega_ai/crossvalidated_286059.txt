[site]: crossvalidated
[post_id]: 286059
[parent_id]: 286049
[tags]: 
Oh, how I dislike the language used in the Wikipedia article. Bayes factors can have problems that do not exist for posterior probabilities, even though Bayes factors could be seen as a function of posterior probabilities. Bayesian methods never use less information than non-Bayesian methods, but they may use as much and may have precisely the same outcome under very careful sets of assumptions. I am going to try and answer this in light of three papers and a book. They are: Jeffreys, William and Berger, James. Sharpening Ockham's Razor On A Bayesian Strop. Technical Report 91-44C. Purdue University Wetzels, Ruud, et al. Statistical Evidence in Experimental Psychology: An Empirical Comparison Using 855 t-tests. Perspectives on Psychological Science. 6(3) 291â€“298 The third is by Abraham Wald that discusses his complete class theorem, but I am not at a place where I can look up a bibliography for it. The fourth is a book: COX, R. T., The Algebra of Probable Inference, Johns Hopkins University Press, Baltimore, MD, (1961). The first thing to understand is that from the Complete Class Theorem, Bayesian methods cannot be stochastically dominated, but the Bayesian method can stochastically dominate a non-Bayesian method. A Bayesian method can never be less accurate, but it can be more accurate. This alone can reduce type I errors. The difference is generally in the presence of prior information. In the presence of real prior knowledge, a Bayesian solution will dominate all others. It is rare not to have some real knowledge. While there may be a desire to feign ignorance so as to minimize bias, it is rare to be truly ignorant. The second issue comes from Wetzels' paper. They compare 855 published t-test to their Bayesian result and found that in many cases the Bayesian solution was not significant or even supported the null. The added structure of non-Bayesian methods makes it more likely that a finding will be seen as significant. While, of course, it isn't known which hypotheses are really true and false, the impact is systemic and not idiosyncratic. Given the high false discovery rate in psychology found in other papers, it would tend to support the Bayesian method. Wetzels found that simply using stricter rules would not help in setting a cutoff for $\alpha$. The math did not improve because higher cutoffs trigger higher sample sizes for power and this just shifted the problem, but did not solve it. Finally, axiom systems such as Cox's assign probabilities to each hypothesis, something that non-Bayesian methods do not do. Indeed, no number is assigned to any hypothesis, just the to the probability of seeing the data if the null is true. In Frequentist methods, the acceptance or rejection of the null is an all-or-nothing situation. The cut-off is arbitrary. There is no similar situation forced in Bayesian methods. This allows more information into the Bayesian method by marginalizing over the parameter space as the exact parameter values are not of interest. Non-Bayesian methods only consider the point expectation based on the data. If type I error exists in a Frequentist model, then a sample statistic is as extreme or more extreme than would be expected under the null to some degree of confidence. If that same statistic exists in a Bayesian model, there may be some of the posterior density that lies outside the false alternative. Likewise, other parameters in the model may be influencing the hypothesis of the parameter of interest. It may be that under some density locations of the other parameters, the false alternative would not be taken. Bayes factors average over the nuisance parameter space, instead of using point estimates. This gets more information in the Bayes factor than the Frequentist solution, or at least can get more in it. The likelihood ratio can be thought of as the ratio of the best case for one hypothesis versus the best case for the other hypothesis. The Bayes factor is the average density in one region versus the average density in another region. The Bayes factor will tend to be more conservative in rejecting a true null.
