[site]: crossvalidated
[post_id]: 552563
[parent_id]: 552459
[tags]: 
Your code looks technically correct to me (it's hard to give a deeper answer without a reproducible example). Per my comments, I do not believe type.measure = 'class' is appropriate; default or mse would be a better choice. It is always hard to say whether your ML algorithm has detected all the structure there is in your data: How to know that your machine learning problem is hopeless? There may be nothing more to find here, so the best prediction is essentially guessing - or there may be something left. It's always good to talk to the domain experts. Perhaps you are already sending out (personalized?) reminders, coupons or promotions - can you include these in your model? The typical reaction is to use a more complex model. I do not subscribe to this automatic response, but you do have a decent-sized data set, so you might want to look at models that provide a little more flexibility. For instance, there may be interactions between your predictors, and a logistic regression will not capture these unless they are explicitly modeled. There are simple implementations of GBMs or Random Forests out there, and if interpretability is not high on your list of requirements, you can probably easily modify your code to try one of these models. In a comment, you ask how to apply proper scoring rules to your problem. Note that your logistic regression (with type = 'response' ) outputs predicted probabilities $\hat{p}_i$ of the $i$ -th instance to belong to the target class, i.e., to lead to a purchase. So you conversely have a predicted probability $1-\hat{p}_i$ that the $i$ -th instance is not a purchase. In your test set, you know whether it was or was not a purchase - so any prediction with a high $\hat{p}_i$ for a purchase (and a low $\hat{p}_i$ for a non-purchase) is a good one. The most common proper scoring rules are the Brier score $$ B = -\sum_{i\text{ purchase}} \hat{p}_i^2 - \sum_{i\text{ non-purchase}} (1-\hat{p}_i)^2$$ and the log score $$ L = -\sum_{i\text{ purchase}} \log \hat{p}_i - \sum_{i\text{ non-purchase}} \log(1-\hat{p}_i).$$ In both cases, lower is better. (There is also the opposite convention, dropping the minus signs; then higher is better.) The tag wiki contains more information and pointers to literature. Of particular interest may be Why is LogLoss preferred over other proper scoring rules? Incidentally, here is a problem: if you take decisions based on your model output (sending one of two different types of email) and then use the result to evaluate your model, you have introduced a confounder. This problem of course applies regardless of what evaluation measure you use. There is no remedy that completely satisfies me, but it is good to keep this complication in mind. See How to avoid selection bias while updating lead scoring (predictive) model with new data .
