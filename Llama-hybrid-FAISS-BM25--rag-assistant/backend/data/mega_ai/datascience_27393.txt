[site]: datascience
[post_id]: 27393
[parent_id]: 
[tags]: 
matching results with sklearn average_precision_score

I have written a (convenience) class for binary classification in python which takes several models and compares their ROCs, AvPrecisions, and creates several charts (distribution of scores, accuracy/sensitivity/specificity, ROC, PR, etc.). A key difference that I am observing is in the computation of average precision. For some examples, using average_precision_score(true labels, prob score) I get a value which is 0.1% to 0.2% more than the average precision computed as xaxs,yaxs = df['sens'].values[::-1],df['ppv'].values[::-1] ap = yaxs[:-1]*(xaxs[1:]-xaxs[:-1]) or equivalently xaxs,yaxs = df['sens'].values,df['ppv'].values tmp = yaxs[1:]*(xaxs[:-1]-xaxs[1:]) I do the same for AUC and that matches to second place of decimal. Based on the formula given here the above calculation seems to be correct. In the figure shown, the values computed by scikit-learn are 0.8977 and 0.8722. Whereas the values compute by the numpy code above are 0.895 and 0.8697. I am using 10,001 thresholds between 0 and 1 so I would think that the bumps in the left corner of the chart should be adequately captured. I would welcome input on how to change my calculation to match the one from skl. Thx.
