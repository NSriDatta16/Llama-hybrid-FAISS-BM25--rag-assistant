[site]: crossvalidated
[post_id]: 378273
[parent_id]: 
[tags]: 
How do I prove: the posterier is proportional to the product of the prior distribution and the likelihood function?

In the book of pattern recognition and machine learning equation (1.66) says: Using Bayesâ€™ theorem, the posterior distribution $\bf{w}$ for is proportional to the product of the prior distribution and the likelihood function. $$ p(\bf{w}|\bf{x},\bf{t}, \alpha, \beta) \propto p(\bf{t}|\bf{w},\bf{x}, \beta) p(\alpha|\bf{w}) $$ I do know that Bayes's theorem is $P(A,B)=P(A|B)P(B)=P(B|A)P(A)$ but I don't quite know how to derive this so many variable case. Besides, what is the proportion constant, why the remaining is a constant?
