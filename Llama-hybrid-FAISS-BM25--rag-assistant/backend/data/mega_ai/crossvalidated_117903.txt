[site]: crossvalidated
[post_id]: 117903
[parent_id]: 
[tags]: 
How can I improve my sklearn logistic regression model

My objective is to classify sentences into useful (denote in boolean as 1) and not useful (denote in boolean as 0) categories. I have about 525 features where 300 features are the most frequent and important keywords after removing stopwords and the rest are domain names. The total number of documents I have is 793. I manually labelled the classes as useful and not useful and I have about 93 useful and the rest (700) as not useful. Below is the result of my logistic regression with the parameter values: model = LogisticRegression(penalty='l1') X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0) model = model.fit(X, y) Based on the results i got, it seems that the regression is doing a very bad job at classifying sentences as useful with really bad precision, recall and 1-score. How can i improve the accuracy? Note, as shown above, i already am implementing L1 regularization.
