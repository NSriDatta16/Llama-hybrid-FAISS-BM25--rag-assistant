[site]: crossvalidated
[post_id]: 193021
[parent_id]: 141017
[tags]: 
I thought that the response from Ben Kuhn was pragmatic and insightful. Now my own background includes in text classification, expert systems, clustering and security. Given this background, I would like to think that I might have something to add to the conversation. But the previous statements by Ben Kuhn highlight that straightforward approaches could produce many false positives. IT staff, when faced with many false positives, typically "tune out" because they simply do not have the time to chase false positives all the time. So what to do? Certainly logs with attacks in them could be helpful but then we have a catch-22 unless companies somehow share attack data. While some Silicon Valley start-ups might be pursuing such threat sharing, what else might we do? One possible approach is to create a simulation of the network and then find a way to generate attacks against the simulation. That is, suppose we create a simulation where the black hats (also simulated) are not known in advance to the white hats. Given these attacks, we can then attempt to create algorithms that should discover these attacks. If the black hats operate independently of the white hats, then we have a real battle that will play out. If the attackers break into the system, or are undetected, then the white hats have, to some degree, failed. One could even have an incentive structure when the security analysts on the black hat team are rewarded for their successes (breeches or undiscovered attacks). Similarly, the group comprising the white hats are rewarded for stopping breeches and/or detecting attacks. There is nothing perfect about this arrangement. Obviously real black hats might exceed the talents of the "friendly" black hat team. Nonetheless, as person who has a fair amount of data analysis, it seems to me that it is very hard to quantify the success of white hats without a better understanding of the black hats. Bottom line is this. If we can't know what real black hats are doing, the next best thing is friendly black hats. I also have a rather unusual idea. Suppose in addition to the friendly black hats and the white hats, there is a gray hat team. What does it mean to be a grey hat? The idea is simple. Grey hats are permitted to look at what the friendly black hats are doing and the white hats. But why? Suppose that the friendly black hats launch attacks using approaches A, B and C, and the white hats never discover any of these three approaches. Well, the grey hats are empowered to look at what both the friendly black hats are doing as well as the white hats are doing, and they try to consider what principles might be used to discover these undetected attacks. If the grey hat finds such principles, the grey hat team can then share these principles with the white hat team without describing the exact attacks in detail. The hope is that these "hints" provided by the grey hat team give the white hat team a push in the right direction without revealing too much. In retrospect, I apologize if my response is really not about specific techniques. Obviously my response is not about specific techniques. But in my experience, a lot of problems in machine learning - including those in security - often fail because the data is inadequate. This approach, using white hats, grey hats and black hats, might help produce the data that would allow a security company (or IT staff) to not only quantify the effectiveness of their defenses, but provide an organizational structure that pushes the white hat team to progressively improved their defenses and their monitoring. I really don't have any idea if the approach I am suggesting is original. I have never heard of grey hats, but I actually think that the role of grey hats could be critical to pushing the white team forward, without revealing too much. Note: my use of the term "grey hat" here is not standard. See http://www.howtogeek.com/157460/hacker-hat-colors-explained-black-hats-white-hats-and-gray-hats/ . So some other term, perhaps "striped hat" should be used instead. But still the idea remains the same: a striped hat can help mediate between the work of friendly black hats and defenders (white hats), so that certain ideas and hints can be judiciously shared with the white hats.
