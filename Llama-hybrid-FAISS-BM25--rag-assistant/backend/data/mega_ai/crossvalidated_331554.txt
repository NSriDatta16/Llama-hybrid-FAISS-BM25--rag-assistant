[site]: crossvalidated
[post_id]: 331554
[parent_id]: 
[tags]: 
How can machine learning be applied to generate a similarity measure for fuzzy matching?

Consider the problem of performing a fuzzy join between two datasets $J$ and $K$. The standard approach requires a similarity measure $S: D \times D \rightarrow \mathbb{R}$. A full join of $J$ and $K$ is performed and the similarity measure is evaluated on each of the resulting records, and only records that score above a certain threshold are kept. Usually the similarity measure is just a string similarity metric like the Levenshtein distance. The records I'm working with, though, have several features of various types (strings, categorical variables, even geographic locations), and while those features may have . I also have some labeled data to train on, so I've approached this as a classification problem. For each record in the cross join, I construct features and then train a classifier on those features with the response variable being whether to record was kept or rejected. This has given decent but not great results. With that set up, here are my questions: Is the classification framing a good way to approach this? Are there any papers/resources about using machine learning to construct a similarity metric? Are there alternative approaches to this problem that I should consider?
