[site]: crossvalidated
[post_id]: 167630
[parent_id]: 
[tags]: 
Training on time series data with a small number of examples

The data I have is collected from 16 smartphones - it's made up of discrete readings from various sensors (eg. accelerometer in 3 axes, intensity of sound in various frequencies etc.), at regular intervals. About half of the 16 (owners of the smartphones) are healthy, and the other half is sick, and the objective is to train a classifier to tell them apart. The readings from every sensor are in effect a long (many hundreds of hours) time series. I've divided the time series into 5-minute-long "time windows" such that every instance (/example) represents data from all sensors during a particular 5 minutes interval, and every feature is the average across that interval of the readings from a particular sensor. The problem I face now is that although I have many different instances, many of them will either be highly correlated, or that training on them as is will overfit horribly because the learner will train to recognize the 8 sick individuals instead of the underlying evidence for the existence of disease (by identifying the similarities that must exist across time intervals that originate from the same individual). I've considered using random forests, but I reckon that because of the inherent similarity between instances bagging won't actually help here. Another alternative I've considered in that respect is to train every weak learner on one interval from every patient (16 examples in all per tree) instead of bagging, but I'm worried the trees will be too shallow. Could anyone point me in a useful direction? (I work in Python, in case you mean to give reference to specific tools or packages.)
