[site]: crossvalidated
[post_id]: 72078
[parent_id]: 72068
[tags]: 
Let me clarify a couple of things. Fist of all, when you use Naive-Bayes to calculate the probability $P(\text{label}|\text{doc_word})$, you have to change that relation into something you know. In this case, the natural route is to use Bayes' theorem that states the following: $$P(\text{label}|\text{doc_word}) = \displaystyle \frac{P(\text{doc_word}|\text{label})P(\text{label})}{P(\text{doc_word})}$$ Usually, you can disregard the denominator because it only provides a normalization factor, which is usually not needed. As you said, there are issues regarding the calculation of $P(\text{doc_word}|\text{label})$ when you don't have a word assigned to a given label, so the whole expression would be zero. However, there is an easy fix. You can pretend that words not assigned to a given label are actually seen once. Therefore, the maximum likelihood estimate, that is, the good old frequentist view of probability, is calculate as: $$P_{Lap}(\text{word}|\text{label}) =\frac{ C(\text{word}) + 1}{N + d}$$ where $C(\text{word})$ is the number of times a given word appears assigned in a label, $N$ is the total number of words in your corpus and $d$ is a correction factor that accounts for the number of extra words you are considering in the corpus. This trick has a serious drawback. As you should expect, there are a fairly large number of words you may encounter in a document that are not assigned to any label, so you are allocating a tiny bit of probability to those words and subtracting the same tiny bit to the words in your corpus. Therefore, a large chunk of the probability space will be been given to unseen words, and that is quite unsatisfactory. That is why there have been proposal to remedy this issue. One of them is the Lidstone smoothing, in which we add a fraction $\lambda$ instead of $1$: $$P_{Lid}(\text{word}|\text{label}) =\frac{ C(\text{word}) + \lambda}{N + d\lambda}$$ An even better estimate of the frequency of a word is the Good-Turing estimator, so I encourage you to give it a read. Depending on your particular application, you may want to try more sophisticated smoothing procedures, but this is really the low-hanging fruit.
