[site]: datascience
[post_id]: 102469
[parent_id]: 102465
[tags]: 
It depends on the type of data. Looks like you have a multiclass classification problem, but is it a balanced or imbalanced dataset? Binary classification dataset can work with almost all kinds of algo's but multiclass classification does not. For example Logistic Regression does not work well with multiclass classification. Popular algorithms that can be used for multi-class classification include: k-Nearest Neighbors. Decision Trees. Naive Bayes. Random Forest. Gradient Boosting. Algorithms that are designed for binary classification can be adapted for use for multi-class problems. This involves using a strategy of fitting multiple binary classification models for each class vs. all other classes(called one-vs-rest) or one model for each pair of classes (called one-vs-one). One-vs-Rest: Fit one binary classification model for each class vs. all other classes. One-vs-One: Fit one binary classification model for each pair of classes. Binary classification algorithms that can use these strategies for multi-class classification include: Logistic Regression. Support Vector Machine. For metrics you have to be careful. You can use accuracy when the dataset is balanced but using the same for imbalanced would be catastrophic. For example you have binary classification with the 2 output classes having frequency 10% and 90%. If you choose accuracy as a metric you would get abnormally high value and you would think your model works good. But it is misleading as your model will predict the majority class most of the time, even when the real output is from the minority class. So it would be wise to use the F1 score (which is nothing but a combination od precision and recall) for imbalanced dataset.
