[site]: datascience
[post_id]: 114687
[parent_id]: 
[tags]: 
Bertopic with embedding: unable to use find_topic

I've used BERTopic with success for the following tasks: get topics, visualise (topics, barcharts, documents ...) and DTM (extended to get area plot with considerable success). However, I am unable to use the find_topics() function (There are a few others I'm struggling with, which I'll post as new questions so as not to conflate this one). I get an error message indicating that I'm using embedding (which is true). # Prepare embeddings using default 'sentence embedding' sentence_model = SentenceTransformer("all-MiniLM-L6-v2") embeddings = sentence_model.encode(docs_bert, show_progress_bar=True) Trying to solve that, I have tried to instantiate a new model without embedding model_ngram_embed2 = BERTopic(embedding_model=embeddings) but it then throws an error: ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all() I need to instantiate before I can fit_transform the model to my doc (text corpus), after which I would then be able to find_topics(). How do I go about that? What should be done? Regarding find_topics(), I've read allowing precomputed embeddings in bertopic.find_topics() issue NB: Python 3.8.8 | IPython 7.31.1 | BERTopic 0.11.0
