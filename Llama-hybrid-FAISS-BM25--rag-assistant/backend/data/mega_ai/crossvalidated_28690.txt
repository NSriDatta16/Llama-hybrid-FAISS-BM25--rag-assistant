[site]: crossvalidated
[post_id]: 28690
[parent_id]: 
[tags]: 
Why use a beta distribution on the Bernoulli parameter for hierarchical logistic regression?

I'm currently reading Kruschke's excellent "Doing Bayesian Data Analysis" book. However, the chapter on hierarchical logistic regression (Chapter 20) is somewhat confusing. Figure 20.2 describes a hierarchical logistic regression where the Bernoulli parameter is defined as a the linear function on the coefficients transformed through a sigmoid function. This seems to be the way hierarchical logistic regression is posed in most of the examples I've seen in other sources online as well. For instance - http://polisci2.ucsd.edu/cfariss/code/SIMlogit02.bug However, when the predictors are nominal, he adds a layer in the hierarchy - the Bernoulli parameter is now drawn from a beta distribution (Figure 20.5) with parameters determined by mu and kappa, where mu is the sigmoid transformation of the linear function of coefficients, and kappa uses a gamma prior. This seems reasonable and analogous to the coin-flipping example from chapter 9, but I don't see what having nominal predictors has to do with adding a beta distribution. Why wouldn't one do this in the case of metric predictors and why was the beta distribution added for the nominal predictors? EDIT: Clarification on the models I'm referring to. First, a logistic regression model with metric predictors (no beta prior). This is similar to other examples of hierarchical logistic regression, such as the bugs example above: $$ y_i \sim \operatorname{Bernoulli}(\mu_i) \\ \mu_i = \operatorname{sig}(\beta_0 + \sum_j \beta_j x_{ji} ) \\ \beta_0 \sim N(M_0, T_0) \\ \beta_j \sim N(M_\beta, T_\beta) \\ $$ Then the example with nominal predictors. Here's where I don't quite understand the role of the "lower" level of the hierarchy (incorporating the logistic outcome into a beta prior for a binomial) and why it should be different than the metric example. $$ z_i \sim \operatorname{Bin}(\theta_i, N) \\ \theta_i \sim \operatorname{Beta}(a_j, b_j) \\ a_j = \mu_j \kappa \\ b_j = (1- \mu_j) \kappa \\ \kappa \sim \Gamma(S_\kappa, R_\kappa) \\ \mu_j = \operatorname{sig}(\beta_0 + \sum_j \beta_j x_{ji} ) \\ \beta_0 \sim N(M_0, T_0) \\ \beta_j \sim N(0, \tau_\beta) \\ \tau_\beta = 1/\sigma_{\beta}^2 \\ \sigma_{\beta}^2 \sim \operatorname{folded t} (T_t, DF) $$
