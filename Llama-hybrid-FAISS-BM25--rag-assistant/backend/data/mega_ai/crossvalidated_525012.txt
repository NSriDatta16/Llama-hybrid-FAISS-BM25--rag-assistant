[site]: crossvalidated
[post_id]: 525012
[parent_id]: 
[tags]: 
Knowing when to stop with spatial point thinning -- is an approach with Clark-Evans test valid?

I need a random sample of presence points from the species' area to use in distribution modeling. I have an excessive amount of spatially clustered presence records, so I use minimum nearest neighbor distance-based spatial thinning with R package spThin . I created a list of thinned datasets based on a vector of minimum NND values ranging from 10 to 500 km with a step of 10 km. To check if the distribution of points in each thinned set can be considered random, I used Clark-Evans' two-sided test with Cumulative Distribution Function (cdf) edge correction and 99 replicates Monte-Carlo based p-value estimation ( spatstat package). I get the following distribution of p-values: As I see it, the random pattern "likeliood" distribution is sort of unimodal. Two main questions are the following: 1. Is this workflow acceptable? (I do not mean "flawless" -- there is likely no ideal solution for that problem, as usulal.) 2. If so, based on the graph, what distance is a reasonable choice for modeling? As there is a lot of uncertainty in both occurrence data and range estimation, I thought I could arbitrarily choose one value from the peak region of the graph. However, it would be nice to preserve as many points as it is reasonable to. Here is how the actual point distributions look. The three graphs are made with (upper to lower) minimum NND = 130, 180 and 280 km (on the graph, that is "first p > .05", "first p ~= 1" and "average between first and last p > .05", respectively). I would appreciate any advice with the reasonable choice of NND value from the experienced statisticians.
