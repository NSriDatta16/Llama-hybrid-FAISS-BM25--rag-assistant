[site]: crossvalidated
[post_id]: 425037
[parent_id]: 
[tags]: 
Mode-collapse problem in GAN: How to grasp the full entropy of the distribution we want to model in GAN

In pix2pix GAN paper( https://arxiv.org/abs/1611.07004 ), authors found that the noise vector and the dropout are not efficient in grasping the full entropy of the data distribution we want to model. The model learns during the training in a manner to ignore the noise provided by the noise vector and the dropout adds only minor stochasticity in the output. What is the right method to grasp the full entropy of the data distribution we want to model?
