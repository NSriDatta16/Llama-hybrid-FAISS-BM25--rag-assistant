[site]: crossvalidated
[post_id]: 534584
[parent_id]: 529824
[tags]: 
I'm about to do something ... possibly dumb. Here is your image with some "annotations": In the top-slice the predicted is about the same as the mean of the measured. There is lots of hand-waving to be had: it is a skewed slice so the right side is sparse, what is a bin-size, etcetera. The point here is that the CART, the "atom" of both the RandomForest and GradientBoostedMachine performs "averaging" over the leaf for the predictor output. This means the prediction is going to try very hard to be inside of the training data. How "inside" it is depends on the data and the model parameters. See also: some crazy dude making sketches about Random Forests .
