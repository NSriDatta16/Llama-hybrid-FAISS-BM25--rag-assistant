[site]: crossvalidated
[post_id]: 231588
[parent_id]: 
[tags]: 
Bivariate time series VAR models always show serial correlation

I am looking at a VAR model for two sets of time series data, the LIBOR interest rate and the Federal Funds rate for a particular time from Quand. If you install the "Quandl" package anyone can run this code. Differencing the data does not make a difference, and they are not normally distributed as seen with a Jarque-Bera test. My question is more conceptual. Why does this bivariate series show low $p$-values of the serial correlation test no matter what the lag for VAR? library(Quandl) library(fpp) library(vars) library(tseries) Libor=Quandl("FRED/CADONTD156N",collapse = "weekly") FederalFunds=Quandl("FRED/DFF",start_date="2001-01-02", end_date="2013-05-31",collapse="weekly") Libor.ts=ts(Libor[,2]) # Reverse the data in the time series object. Libor.ts[]=rev(Libor.ts) FederalFunds.ts=ts(FederalFunds[,2]) FederalFunds.ts[]=rev(FederalFunds.ts) combined_data The output of the graph is The output of lags$selection lags$selection AIC(n) HQ(n) SC(n) FPE(n) 11 10 9 11 I used the SC lag suggestion as 9, but then brute forced it. No matter what the lag, from 1, all the way to 50, very small p values. Here is the test for lag 9, supposedly the best. The best Portmanteau test (the highest p-value is) Portmanteau Test (asymptotic) data: Residuals of VAR object var9 Chi-squared = 30.57, df = 4, p-value = 3.746e-06
