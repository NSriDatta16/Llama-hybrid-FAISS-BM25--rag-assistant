[site]: crossvalidated
[post_id]: 364943
[parent_id]: 364925
[tags]: 
Well, if you can't assume randomness of data points in the set i.e. you assume the values are correlated with the order of the points in the set - you could make sample by uniformly taking the points (every n-th , where n = |P| / |s| ; P is population, s is sample), but I would use the k-fold cross-validation technique (because I had the same dilemma as you and solved it by adopting this highly regarded validation technique): The k-fold cross-validation provides fair accuracy estimation, using entire data set - when data insufficiency prevents separation of training and test data sets. The data is partitioned into k folds (exclusive, no data points shared among the folds), equal in size. Then, the validation is performed in k iterations, having different combination of k-1 training subsets and one test subset. Once all iterations are finished, the average values of the effectiveness measures (F1-score) are computed. Data points are distributed among folds randomly . Btw. the Support Vector Machine is designed for binary (2-class) classification, it is not an option. [1] C. Cortes, V. Vapnik, Support-Vector Networks, Mach. Learn. 20 (1995) 273â€“297. doi:10.1023/A:1022627411411.
