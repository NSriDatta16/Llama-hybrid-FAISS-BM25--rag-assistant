[site]: crossvalidated
[post_id]: 370272
[parent_id]: 
[tags]: 
"Denoising" autoencoder with distortions other than Gaussian noise

I watched some talks by Yoshua Bengio, where he often refers to denoising auto-encoders (AE) as a powerful method to learn (unsupervised) representations on an input space ( e.g. here ). The idea as far as I have understood it, is that the valid input only lives on a manifold of much smaller dimension than the complete input space. E.g. if we use bitmap representations of 1000px, then the complete input space is the $\mathbb{R}^{1000}$ . But if we just use letters and numbers as inputs, this data may only use a much lower dimension, let's say something comparable to the $\mathbb{R}^{50}$ . Thus, the first layers of the AE just learn a non-linear projection of the $\mathbb{R}^{1000}$ to the $\mathbb{R}^{50}$ . Now by adding (Gaussian) noise to the input during training, the performance is increased. The interpretation is straightforward, the noise offsets the data away from the manifold, and the AE learns to return this corrupted data back to the manifold ( here ). My main question is if adding Gaussian noise is really the only kind of distortion that we should consider when training denoising AE. For humans, it is easily possible to reconstruct the original letter, even if it is rotated or upside down. Could we train an AE to also project upside down or rotated versions of the same letter to the same point on the manifold? But rotated and upside down versions of the same letter are really far away in the original input space under e.g. $L^2$ norm, whereas the same image with added Gaussian noise is quite close. Would an AE still be able to learn this much more complex task of mapping such different inputs to the same manifold. While NNs can be universal approximators in general, such a mapping may require too many neurons or training time. Also, to be an AE, the network must have a bottleneck, which violates the universal approximation assumptions.
