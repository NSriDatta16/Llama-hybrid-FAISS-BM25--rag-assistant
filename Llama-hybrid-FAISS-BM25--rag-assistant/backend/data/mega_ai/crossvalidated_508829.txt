[site]: crossvalidated
[post_id]: 508829
[parent_id]: 508818
[tags]: 
When you say I've got covariates X and Y , do you really mean that you have a response variable Y and a set of predictor variables X ? Your examples cover a lot of ground, so you might benefit from keeping things simple to begin with. "Just for fun" is relative and the more complex the question, the more time it requires someone to spend answering it. (There are generally no guarantees that a question will be answered on this forum, I would think.) For the sake of simplicity, I will assume that the observations collected on X and Y are actually independent (which would most likely NOT be the case for the data in your first example). I will also assume that we only have a single predictor variable X . With such data and the stated assumptions in place, one flexible approach you could use to model both the conditional mean and conditional variance of Y given X would involve the use of so-called GAMLSS models, aka Generalized Additive Models for Location, Scale and Shape. See https://www.gamlss.com . If we can further assume that the conditional distribution of Y given X is Normal, we would in effect deal with a special case of the above type of model: Additive Model for Location and Scale. In R, this model could be specified like this: library(gamlss) model Here, the function NO2() defines the normal distribution, a two parameter distribution, with mean equal to mu and variance equal to sigma. The function pb() is a P-spline smoother which will allow for the possibility that the effect of X on the conditional mean and the conditional variance of Y given X is potentially nonlinear. The potential nonlinearity of the effects is captured in a nonparametric fashion. The data will help reveal the underlying shape of these effects - you will not have to guess what complicated forms these effects might have. (There are other types of smoothers available, such as cubic splines cs().) For more, see http://www.gamlss.com/wp-content/uploads/2013/01/gamlss-manual.pdf and https://www.gamlss.com/wp-content/uploads/2019/10/Practicals-Bilbao.pdf . Of course, if the data collected on X and Y are not independent (e.g., X and Y are daily time series), you would need to change your modelling framework. Dependence complicates things! I think one important consideration is whether the conditional variance of Y given X is of primary interest or just a nuisance. If it is just a nuisance, trying to get an explicit model for it - let alone the best possible model - might be overkill. If you can assume that X has a linear effect on the conditional mean of Y given X , then you might get away with using some type of Huber-White correction of the standard error of your estimated linear effect of X on the conditional mean of Y given X . In other words, you can fit a model for the conditional mean of Y given X which assumes constant variability of the Y values at each X value but then correct the standard errors to make your inference on the linear effect of X on the conditional mean of Y given X robust to the presence of non-constant variability.
