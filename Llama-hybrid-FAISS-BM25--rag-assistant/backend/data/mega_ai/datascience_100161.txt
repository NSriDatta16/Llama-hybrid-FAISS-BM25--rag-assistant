[site]: datascience
[post_id]: 100161
[parent_id]: 100089
[tags]: 
Personally I find Victor Lavrenko's explanation of underfitting and overfitting the most intuitive and concise definition: This definition is very useful for at least these two points: This is not always an easy task to measure model's complexity ( check ) as presented in most of the diagrams that explain this concept You avoid the pitfall of comparing the same model's metrics in train and test set as described here : ...We can identify if a machine learning model has overfit by first evaluating the model on the training dataset and then evaluating the same model on a holdout test dataset. If the performance of the model on the training dataset is significantly better than the performance on the test dataset, then the model may have overfit the training dataset.... This situation is not clearly defined since there is no a "standard" difference between train and test error that can guarantee that your model is overfitting, so there is no such thing as significantly better on the test set (as far as I know) But of course I'm not saying that you should no care about training vs testing error.
