[site]: crossvalidated
[post_id]: 439327
[parent_id]: 
[tags]: 
Why is local-m Attention differentiable?

In this paper ( https://arxiv.org/pdf/1508.04025.pdf ) local attention is introduced. With local-m attention, we compute the attention vector over the source hidden states within a window around the fixed center $p_t$ . This is the same as 'multiplying' the source state sequence with a $rect$ -function. And the $rect$ -function is not differentiable, however, the authors claim that their model is. How is this possible? If this is the case, then why don't we implement hard attention ( https://arxiv.org/pdf/1502.03044.pdf ) the same way: predict the position $p_t$ with a feed-forward net, instead of sampling, and then just use a window of size 1. This way we can use normal backpropagation and don't need reinforcement learning.
