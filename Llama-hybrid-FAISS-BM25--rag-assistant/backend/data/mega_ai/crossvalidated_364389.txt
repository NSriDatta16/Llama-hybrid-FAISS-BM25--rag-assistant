[site]: crossvalidated
[post_id]: 364389
[parent_id]: 
[tags]: 
Extracting latent vectors from autoencoder similar to SVD

I have read that there is an equivalency between a linear autoencoder and performing SVD. SVD can be used in collaborative filtering, for example, factorization of a user-movies matrix $\mathbf{M}$ can generate $\mathbf{U}$ and $\mathbf{V}$, which represent latent user and movie features, respectively. We currently use this technique to generate user features (e.g. $\mathbf{U}$) which are then used to build other machine learning models. Looking at the architecture of an autoencoder, it seems to me the "bottleneck" is where the latent features must lie, but it is not clear to me that you can separate out the $\mathbf{U}$ and $\mathbf{V}$ in the same way that is done with SVD. Am I correct about this? Would appreciate any comments and especially references to material covering these theoretical details.
