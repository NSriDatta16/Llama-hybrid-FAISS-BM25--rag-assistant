[site]: datascience
[post_id]: 22173
[parent_id]: 
[tags]: 
Why not use more than 3 hidden layers for MNIST classification?

Many works use 2-hidden-layer neural networks for classifying MNIST handwritten digits sets. To improve accuracy, other techniques (dropout, ReLU.. etc) have been used without increasing the number of hidden layers. Is there any reason not to use more than three hidden layers? for example, overfitting?
