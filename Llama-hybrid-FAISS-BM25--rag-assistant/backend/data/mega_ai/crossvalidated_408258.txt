[site]: crossvalidated
[post_id]: 408258
[parent_id]: 408240
[tags]: 
This problem is from Bertsekas by the way; and to be precise since the limits are not shown in the image: $$f_X(x)=\begin{cases}1/2, & 0\leq x First of all if you're OK with the statement in the solution that $E[X|Y]$ takes values $2$ and $1/2$ with probability $1/2$ , then you're left with a new random variable, $Z=E[X|Y]$ , where you're asked the variance of it, $\operatorname{var}(Z)$ , in which you can execute the standard way of calculating the variance, as also pointed out by @StubbornAtom in the comments. Let's derive $E[X|Y]$ . First of all, it is a function of $Y$ , and there are two cases at most because we have only two $Y$ values. So, we'll calculate $E[X|Y=1]$ and $E[X|Y=2]$ . We can analytically find $f_{X|Y=1}(x)$ and find the expectation, but a simpler approach would be using the given plot. If $Y$ is $1$ , then $X$ is uniform in $[0,1]$ , which gives $E[X|Y=1]=1/2$ . If $Y=2$ , $X$ is uniform in $[1,3]$ , which gives $E[X|Y=2]=2$ . Edit : After you added your bullet points: 1) PDF of $X$ is not in any standard form, e.g. uniform, exponential, normal etc. But, when we condition on $Y$ , it's partitioned into two simpler (i.e. uniform PDFs) pieces: $f_{X|Y=1}(x)$ and $f_{X|Y=2}(x)$ . We can directly use uniform PDF's pre-calculated statistics. You first need to understand that these two PDFs are uniform as a checkpoint. 2) $E[X|Y]$ is a random variable because it depends on $Y$ . It doesn't depend on $X$ , because $x$ is integrated out: $$E[X|Y]=\int_{\mathcal{X}} xf_{X|Y}(x)dx$$ Similarly, $E[X]$ is constant, $E[X|Y,Z,T]$ depends on $Y,Z,T$ etc. 3) Typical definition of variance is $\operatorname{var}(Z)=E[(Z-E[Z])^2]$ ; and here $Z=E[X|Y]$ . Also, in your definition, you're confusing $\operatorname{var}(E[X|Y])$ with $\operatorname{var}(X|Y)$ : $$\operatorname{var}(E[X|Y])\neq E[X^2|Y]-E[X|Y]^2 = \operatorname{var}(X|Y)$$
