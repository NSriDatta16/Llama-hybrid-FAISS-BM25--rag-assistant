[site]: datascience
[post_id]: 62663
[parent_id]: 
[tags]: 
Time series forecasting produce same values with different training data

I'm developing a python program which predict daily timeseries values. Each daily timeseries contains 288 values (a record every 5 minutes). The main idea is to train a LSTM model with 7 days data and predict the next day. After the prediction, train again the model with the last 7 days (so the one just predicted and discarding the first one). In order to do this, I have implemented the following code: for idx in range(len(self.test)): graph = tf.Graph() with tf.Session(graph=graph): history = [x for x in self.train] # prepare data train_x, train_y = to_supervised(self.train, self.n_input, self.n_output) self.fit_model(train_x, train_y) # make the prediction yhat_sequence = self.forecast(history, self.n_input) real_sequence = self.test[idx, :].reshape(-1, len(self.test[idx, :])) real_sequence = self.scaler_test.inverse_transform(real_sequence) yhat_sequence = yhat_sequence.reshape(-1, len(yhat_sequence)) yhat_sequence = self.scaler_train.inverse_transform(yhat_sequence) # add real sequence to history history.append(self.test[idx, :]) # add real sequence to train last_day_scaled = np.array([self.test[idx, :]]) self.train = np.concatenate((self.train, last_day_scaled)) # remove first day from train in order to have always one week of training self.train = self.train[1:, :] # reset model in order to train it again self.model.reset_states() self.model = None Here the fit_model function: def fit_model(self, train_x, train_y): # define parameters verbose, epochs, batch_size = 1, 100, 128 # reshape trains ... n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1] if self.model is None: print("Create model") self.model = Sequential() self.model.add(LSTM(100, input_shape=(n_timesteps, n_features))) self.model.add(LeakyReLU(alpha=0.1)) self.model.add(RepeatVector(n_outputs)) self.model.add(LSTM(100, return_sequences=True)) self.model.add(LeakyReLU(alpha=0.1)) self.model.add(TimeDistributed(Dense(100))) self.model.add(LeakyReLU(alpha=0.1)) self.model.add(TimeDistributed(Dense(1))) self.model.compile(loss='mse', optimizer='adam') # fit network self.model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose) This codes works without errors, but predictions done training after training are very similar to each other even if training data change. Pictures below are three different days (blu real data and green prediction) I've try to increase epochs, neurons, add DroupsOut and to increase number of training days Is there something wrong with my code? How can I improve my prediction training after training?
