[site]: crossvalidated
[post_id]: 167025
[parent_id]: 
[tags]: 
10-fold cross validation for forecasting time series with explanatory data ?

I saw that the question was asked some years ago here , but I wasn't satisfied with the answers so I'm asking it again. Is there some theoretical foundations about not doing k-fold cross validation with time series ? I've read that it makes more sense to not use forward looking data to predict past data, but if you expect the dependencies to have evolved with time, you should have modelled it so this is not shoking to mix all the data for tuning the algorithm, and use the end of the window for testing (for aesthetic purposes and plots). Plus most of approaches don't take into account the time dependency so it seems artificial to use the rolling windows (local methodes use distances between regressors in the sense of the metric, not in a timely way). I was working with this paper that doesn't even evoke the question. The only point I would underline is that if you use lags and regressors and lags of regressors, the observations of the training test would be correlated which may be problematic for some methods more than others, right ?
