[site]: datascience
[post_id]: 63636
[parent_id]: 63459
[tags]: 
Use nlp.pipe() to process texts in larger batches, which is much faster, especially for a lot of short texts: for doc in nlp.pipe(sent_list): # averaged doc vector print(doc.vector) # token vectors print([token.vector for token in doc])
