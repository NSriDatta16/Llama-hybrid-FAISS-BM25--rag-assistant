[site]: datascience
[post_id]: 49755
[parent_id]: 49746
[tags]: 
I think you are tackling 2 different problems here: Imbalanced dataset Hyperparameter optimization for XGBoost There are many techniques for dealing with Imbalanced datasets, one of it could be adding higher weights to your small class or another way could be resampling your data giving more chance to the small class. For XGBoost I suggest fixing the learning rate so that the early stopping number of trees goes to around 300 and then dealing with the number of trees and the min child weight first, those are the most important parameters.
