[site]: crossvalidated
[post_id]: 612364
[parent_id]: 
[tags]: 
How to determine effective sample size when sampling averaged samples?

I have a sampling process like the following: Randomly select psus from one stage with equal probability Use all ssus of each psu selected for estimation. Each ssu is associated with a statistic from an aggregate of sub-units So for example we want to estimate a statistic about the number of insect per trees in orchards: Let's say we sample 10 counties as our psus. All the farms from those counties are our ssus. We then have aggregate statistics from each farm about the number of insects per tree, where the farms have different number of trees. We don't have individual observations for each tree, just the aggregate statistics. Because our statistic relies on the number of trees, which we don't have observations on directly, in a sense trees is our sampling unit. So we might think of our effective sample size as being based on the design effect on measuring the variance of insects per tree. However, that is tricky. We only have one observation: the statistic for each farm. But farms may have wildly differently number of trees that contribute to the aggregate total. Would it make sense to think of there being one observation for each tree, where each tree within each farm is assumed to have the same rate of insects per tree? Since we do not have any sub-information from each farm, I'm not sure how else to structure my data for standard error estimate and analysis.
