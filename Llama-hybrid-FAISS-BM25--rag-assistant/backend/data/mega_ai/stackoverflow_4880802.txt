[site]: stackoverflow
[post_id]: 4880802
[parent_id]: 4880566
[tags]: 
Well, Facebook's architecture is highly scalable, and they have a lot of "front doors" to data requests, and some real muscle behind that to crunch data effectively. The first question is, how many concurrent users is this app supposed to handle? SELECT TOP 25 ... FROM Activity WHERE Activity.Date ) Low hundreds, think about a replication server to separate non-realtime or less often-used tasks, or simply to load-balance. High hundreds, start thinking of a server cluster with distributed tables and bulk transaction shipping. More than that and you're beyond my expertise on enterprise architecture. Your first steps in any case: Profile your DB. See the queries produced by each action the user can take, and look critically at whether that query is the most efficient way to do the job. Refactor cursor-based operations; you DO NOT WANT these in any operation expected to execute quickly because they short-circuit a lot of the muscle the SQL engine can give you in crunching numbers. Identify criteria most often used to filter/retrieve results, especially with equality, and make those clustered primary keys. A clustered key will cause the server to arrange data with the same criteria on the same pages of data for faster retrieval of data likely to be retrieved in blocks. Be careful, though; too many indices will reduce performance. If the query looks good, and it's executed against a well-indexed schema, but it's still slow, consider refactoring the query into a table-valued function or stored procedure. Those are precompiled, and a query plan pre-engineered, saving you that overhead on a common DB call. They also require less information to be sent over the network. Cache the results of some of the more expensive queries, especially data shared by several pages and/or data unlikely to change quickly, in a session store or other in-memory repository on the webserver side. You'll need a lot of memory available in your webserver. Still not enough? Throw some more hardware muscle into the DB server computer. Consider a distributed model; most major DBMSes can work in a cluster environment. How you structure that model depends on your schema and the operations performed; most often, separating data by geographic region works well, even for a giant like Facebook. While you're doing all this, you can make the UI more responsive by incorporating asynchronous technologies like AJAX; the frame of your page can load and display in the browser while the DB server's still churning, then the data can follow asynchronously and be rendered into the page in a delayed fashion.
