ate not only webpages, but also videos and audio files on the internet. 2010s The past decade witnessed neural machine translation (NMT) methods replace statistical machine translation. The term neural machine translation was coined by Bahdanau et al and Sutskever et al who also published the first research regarding this topic in 2014. Neural networks only needed a fraction of the memory needed by statistical models and whole sentences could be modeled in an integrated manner. The first large scale NMT was launched by Baidu in 2015, followed by Google Neural Machine Translation (GNMT) in 2016. This was followed by other translation services like DeepL Translator and the adoption of NMT technology in older translation services like Microsoft translator. Neural networks use a single end to end neural network architecture known as sequence to sequence (seq2seq) which uses two recurrent neural networks (RNN). An encoder RNN and a decoder RNN. Encoder RNN uses encoding vectors on the source sentence and the decoder RNN generates the target sentence based on the previous encoding vector. Further advancements in the attention layer, transformation and back propagation techniques have made NMTs flexible and adopted in most machine translation, summarization and chatbot technologies. See also History of natural language processing ALPAC report Computer-assisted translation Lighthill report Machine translation Notes References Hutchins, J. (2005). "Milestones in machine translation â€“ No.6: Bar-Hillel and the nonfeasibility of FAHQT]" (PDF). Archived from the original (PDF) on 29 January 2019. Retrieved 9 March 2012. Van Slype, Georges (1983). Better translation for better communication. Paris: Pergamon Press. ISBN 978-0-08-030534-9. Further reading Hutchins, W. John (1986). Machine Translation: past, present, future. Ellis Horwood series in computers and their applications. Chichester: Ellis Horwood. ISBN 978-0-470-20313-2.