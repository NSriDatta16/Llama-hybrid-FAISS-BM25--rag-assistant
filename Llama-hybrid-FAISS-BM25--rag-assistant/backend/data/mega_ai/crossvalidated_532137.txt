[site]: crossvalidated
[post_id]: 532137
[parent_id]: 532126
[tags]: 
Depending on the model, the randomness of a sample can be difficult to verify. In the case where the data consist only of $0$ 's and $1$ 's, one might look at the lengths of runs. For example, if $0$ 's and $1$ 's are equally likely, then runs of $0$ 's ought to be of average length $2$ and the same for runs of $1$ 's. In particular, in a random sequence of twenty $0$ 's and $1$ 's where the two outcomes are equally likely, we would not be surprised to to see: 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 while we would be surprised to see runs of length five and six as in 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 But you say you don't have access to original data. For instances in which you do have original data, you might want to look at pages on this site and online that discuss 'runs tests' for randomness. Testing proprotions. In your case, it seems you don't have access to the original data, but a summary of how many $1$ 's and how many $0$ 's were observed. Then it is not possible to test for randomness, but it is easy to check whether a particular proportion of $1$ 's seen in a sample of size $n$ is likely to have resulted, sampling from a population with a particular probability of $1$ 's. It would be unusual for the sample proportion to be exactly equal to the population probability, but the two numbers should not be extremely different. Example: Suppose the population probability of ones is $p = 0.4$ and we observe $X = 387$ ones in a sample of size $n$ from the population, so that the sample estimate of $p$ is $\hat p = x/n = 387/1000 = 0.387.$ We could formulate the null hypothesis $H_0: p = 0.4$ and the alternative $H_a: p \ne 0.4.$ Then under the null hypothesis $X \sim \mathsf{Binom}(n=1000, p=0.4).$ We could use an exact binomial test in R to test $H_0$ against $H_a$ at the 5% level of significance. binom.test(x=387, n=1000, p=0.4) Exact binomial test data: 387 and 1000 number of successes = 387, number of trials = 1000, p-value = 0.4198 alternative hypothesis: true probability of success is not equal to 0.4 95 percent confidence interval: 0.3566826 0.4179848 sample estimates: probability of success 0.387 If $H_0$ is true, then the P-value $0.4198$ is the probability of a more extreme outcome than the observed $X = 387.$ In R, where pbinom is a binomial CDF, this can be computed directly, as follows. S = pbinom(387, 1000, 0.4); S [1] 0.210093 # P(X = 413) S + L [1] 0.4197529 # P(More extreme) Because the P-value $0.4198 > 0.05 = 5\%,$ we do not reject $H_0$ at the 5% level of significance. That is, the observed value $X = 387$ is not surprisingly different from the 'expected' value $400.$ The figure below shows the PDF of the null distribution $\mathsf{Binom}(n=1000, p=0.5).$ Total heights of bars outside the red vertical lines represent the P-value of the test. R code for figure above. hdr = "PDF of BINOM(1000, 0.4)" x = 350:450; PDF = dbinom(x, 1000, .4) plot(x, PDF, type="h", col="blue", lwd=2, main=hdr) abline(h = 0, col="green2") abline(v = 387.5, col="red") abline(v = 412.5, col="red", lty="dashed") By contrast, if we happened to observe $X = 435$ or $X = 362,$ these values would lead to P-values below 5%, and we would reject $H_0: p = 0.4.$ Here are the exact P-values that would result from these outcomes according to binom.test . [We use $ -notation to show just the two P-values, instead of the complete output as above.] binom.test(x=435, n=1000, .4) $p.val [1] 0.02589798 binom.test(x=362, n=1000, .4)$ p.val [1] 0.01416038
