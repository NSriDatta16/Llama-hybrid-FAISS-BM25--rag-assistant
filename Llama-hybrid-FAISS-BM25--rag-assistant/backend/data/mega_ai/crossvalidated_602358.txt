[site]: crossvalidated
[post_id]: 602358
[parent_id]: 598561
[tags]: 
ML Models usually accept inputs with fixed number of features: If model was trained on 10 features, it is impossible to provide a point where only 7 features are defined. SHAP operates on a different coalition of features, so to compute a feature importance (SHAP value) for feature f1, it checks what model predicts if only f1 defined, if (f1, f2) are defined, (f1, f3) and so on, (see how Shapley Values are defined for more information). As I mentioned for ML models absent features still must be defined somehow. zero, NaN or any other values can used for example, but such values may produce out-of-distribution samples: if the model have never seen zero for a feature it may go crazy. To cope with that a masker/background dataset can be used. Suppose there is a point $x$ , and we need to evaluate model on features $f_1, f_2$ , and "ignore" features $f_3, f_4$ . To do that the absent features are substituted with every points from the masker dataset, and we have a new dataset $D$ with the same size as masker dataset where $f_1, f_2$ features are always the same and equal $x$ , and $f_3, f_4$ equal to masker dataset. Then we evaluate model on $D$ and take the average. I think is a good idea to cross-validate it on training (masker) dataset, for training dataset it depends if local or global Shapley values should be obtained If "final" is a global shapley values -- average shapley values for different point is a standard solution.
