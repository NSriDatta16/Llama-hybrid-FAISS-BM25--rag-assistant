[site]: crossvalidated
[post_id]: 142117
[parent_id]: 141984
[tags]: 
Just to get the ball rolling, I'll start with a possible (but probably not optimal) answer. You could use a bag of words representation with stop-words (frequently used non-informative words such as "the") removed and compute L1 distance between documents. Probably even better would be to use binary vectors that simply indicate whether a word is included and use hamming distance. You could other vectors to incorporates your additional information. For instance, suppose you additionally have price and weight. For two items define $w_1, w_2$ to be there respective bag-of-words vectors, and $v_1, v_2$ to be vectors containing (price, weight). You could define the distance between (w1, v1) and (w2,v2) as $$ d_{Hamming}(w1, w2) + \alpha \cdot d_{L^1}(v1, v2) $$ $\alpha$ gives you a way of controlling the relative strength of description-paragraph features versus non-description-paragraph features. I'm sure there are better ways to go about this and that people in this community will know them, but this is a start.
