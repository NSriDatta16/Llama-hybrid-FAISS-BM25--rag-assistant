[site]: datascience
[post_id]: 96961
[parent_id]: 
[tags]: 
Low accuracy of trained model when dataset contains 10^5 observations and 128 features using "Statistic and machine learning toolbox" of Matlab

The entrys are real numbers (each row is a channel output, where blocklength n= 128). The accuracy is approx. 50%. The labels contain elements of the set {0,1}. The dataset is balanced. For smaller blocklength (n= 32 and 50000 observations) the accuracy is approx. 90%. In this case, fine and cosine KNN perform the best. For the case where n = 128, feature selection does not increase the accuracy. I have tried several samples. Is there any hope to get a better accuracy? Is the value range a problem? I assume that a bigger sample size would help but it would lead to high computational complexity. I used the proposed Matlabcode to select featuers: %--------------------------------------------------------------------------- %savedata is a 10^5 x 128 matrix, savedata_m is a 10^5 x1 vector with % entries of 0's and 1's. rng(1); % For reproducibility cvp = cvpartition(savedata_m,'holdout',20000); Xtrain = savedata(cvp.training,:); ytrain = savedata_m(cvp.training,:); Xtest = savedata(cvp.test,:); ytest = savedata_m(cvp.test,:); nca = fscnca(Xtrain,ytrain,'FitMethod','none'); L = loss(nca,Xtest,ytest) nca = fscnca(Xtrain,ytrain,'FitMethod','exact','Lambda',0,... 'Solver','sgd','Standardize',true); L = loss(nca,Xtest,ytest) cvp = cvpartition(ytrain,'kfold',5); numvalidsets = cvp.NumTestSets; n = length(ytrain); lambdavals = linspace(0,20,20)/n; lossvals = zeros(length(lambdavals),numvalidsets); for i = 1:length(lambdavals) for k = 1:numvalidsets Xt = Xtrain(cvp.training(k),:); yt = ytrain(cvp.training(k),:); Xvalid = Xtrain(cvp.test(k),:); yvalid = ytrain(cvp.test(k),:); nca = fscnca(Xt,yt,'FitMethod','exact', ... 'Solver','sgd','Lambda',lambdavals(i), ... 'IterationLimit',30,'GradientTolerance',1e-4, ... 'Standardize',true); lossvals(i,k) = loss(nca,Xvalid,yvalid,'LossFunction','classiferror'); end end meanloss = mean(lossvals,2); figure() plot(lambdavals,meanloss,'ro-') xlabel('Lambda') ylabel('Loss (MSE)') grid on [~,idx] = min(meanloss); bestlambda = lambdavals(idx) % Find the best lambda value bestloss = meanloss(idx) %Fit the nca model on all data using best lambda and plot the feature weights nca = fscnca(Xtrain,ytrain,'FitMethod','exact','Solver','sgd',... 'Lambda',bestlambda,'Standardize',true,'Verbose',1); figure() plot(nca.FeatureWeights,'ro') xlabel('Feature index') ylabel('Feature weight') grid on %tol = 0.5; tol = 0.0001; selidx = find(nca.FeatureWeights > tol*max(1,max(nca.FeatureWeights))) L = loss(nca,Xtest,ytest) %Classify observations using the selected features features = Xtrain(:,selidx); classificationKNN = fitcknn(... features, ... ytrain, ... 'Distance', 'Euclidean', ... 'Exponent', [], ... 'NumNeighbors', 1, ... 'DistanceWeight', 'Equal', ... 'Standardize', true, ... 'ClassNames', [1; 2]); L = loss(classificationKNN,Xtest(:,selidx),ytest) %--------------------------------------------------------------_ Furthermore, I used sequencial feature selection. Code: c = cvpartition(savedata_m,'k',10); opts = statset('Display','iter'); %Model= fitcecoc(XT,yT,'Learners','knn') fun = @(XT,yT,Xt,yt)loss(fitcecoc(XT,yT,'Learners','knn'),Xt,yt); [fs,history] = sequentialfs(fun,savedata,savedata_m,'cv',c,'options',opts) %-------------------------------------------------------------------------- I get the following. sequencialFeatureSelection Start forward sequential feature selection: Initial columns included: none Columns that can not be included: none Step 1, added column 15, criterion value 9.8064e-05 Final columns included: 15 fs = 1×128 logical array Columns 1 through 42 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Columns 43 through 84 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Columns 85 through 126 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Columns 127 through 128 0 0 history = struct with fields: In: [1×128 logical] Crit: 9.8064e-05
