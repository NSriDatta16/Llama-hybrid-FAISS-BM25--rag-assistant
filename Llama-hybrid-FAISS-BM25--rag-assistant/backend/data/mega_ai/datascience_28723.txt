[site]: datascience
[post_id]: 28723
[parent_id]: 28446
[tags]: 
There is this very cool idea in a paper by Ryabko[1] which is not yet very well known. This is called the telescope distance $D_H$. To make a valid assessment about two time series, just looking at the data is not enough. You need to compare the underlying stochastic process that generates them, i.e. you want to compare two probability distributions. And the telescope distance is precisely a metric on the space of probability distributions. It goes like this (kind of formidable to the uninitiated). For a set of functions $\mathbf{H} = (\mathcal{H_1, H_2, \ldots})$, the telescope distance is defined as $$D_{\mathbf{H}}(P, Q) \equiv \sum_{k=1}^{\infty} w_k \sup_{h \in \mathcal{H_k}} | E_P [h(X_1,\ldots,X_k)] - E_Q [h(Y_1, \ldots,Y_k)]|$$ where $P,Q$ are the distribution that generates $X$ and $Y$ respectively, and $w_k$ are some exponentially decaying weights (see the paper for details). You don't know $P$ and $Q$; all you got are the time series. It turns out you could use the following empirical quantity $\hat{D}$ to estimate the true telescope distance, $$ \small \hat{D}_{\mathbf{H}}(X_{1:n}, Y_{1:m}) \equiv \sum_{k=1}^{min(m,n)} w_k \sup_{h \in \mathcal{H_k}} \big|\frac{1}{n-k+1} \sum_{i=1}^{n-k+1} h(X_{i:i+k-1})- \frac{1}{m-k+1} \sum_{i=1}^{m-k+1} h(Y_{i:i+k-1}) \big| $$ where $X_{1:n}$ and $Y_{1:m}$ are your observed time series. Notice the nice thing about this metric is, the two time series don't have to be equal in length. Now, everything seems to be fine except that you notice you need the $h(\ldots)$? And it's not just one function, but a sequence of functions. The cool idea is that these $h(\ldots)$s could be modeled as a binary-classifier well known in machine learning. For example, one could use SVM for these $h$ to discriminate between a subsequence $X$ and a subsequence of $Y$. Once you've trained these binary classifiers, and there are $min(n,m)$ of them, you run them through the subsequences of the same length of $X$ and $Y$, sum them up and you're done. [1]Ryabko, D., & Mary, J. (2013). A binary-classification-based metric between time-series distributions and its use in statistical and learning problems. The Journal of Machine Learning Research, 14(1), 2837-2856.
