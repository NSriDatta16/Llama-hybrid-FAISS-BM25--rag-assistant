[site]: crossvalidated
[post_id]: 195502
[parent_id]: 
[tags]: 
RNN classification without sequence maximum length?

I'd like to use RNN for binary classification. One example of such task is sentiment analysis, where embedding of words from a sample are fed into network one by one. But all implementations I have found do define maximal length of a sample and crop or pad samples to this length. Why is this necessary? I thought the very purpose of RNN was to deal with variable length samples, because if we know sample length beforehand, simple convolutional network can deal with it. There will be more weights, but they will be easier to train.
