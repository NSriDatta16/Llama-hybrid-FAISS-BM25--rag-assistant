[site]: crossvalidated
[post_id]: 269586
[parent_id]: 269538
[tags]: 
You can estimate $K$ using method of moments estimator $$ \frac{k}{n} \approx \frac{K}{N} \implies \frac{N}{n} k $$ or maximum likelihood estimator as described by Zhang (2009): $$ \frac{N-1}{n} k $$ for derivation and further details check the following paper: Zhang, H. (2009). A note about maximum likelihood estimator in hypergeometric distribution. Comunicaciones en Estad√≠stica, 2(2), 169-174. On another hand, it you want to define a distribution of $k$ white balls, drawn without replacement from the urn containing $N$ balls in total, while treating the total number of white balls $K$ as unknown, i.e. as a random variable, then you can define such problem in terms of Bayesian model, with beta-binomial prior (in fact a conjugate prior ) for $K$ (as described by Fink, 1997 and Dyer and Pierce, 1993): $$ k \sim \mathcal{H}(N,K,n) \\ K \sim \mathcal{BB}(N, \alpha, \beta) $$ what follows to a beta-binomial posterior predictive distribution of $k$ parametrized by $N$ , $\alpha' = \alpha + k$ and $\beta' = \beta + N-k$ , and the posterior distribution of $K$ is $$ f(K\mid k,N,\alpha,\beta) = {N-n \choose K-k} \frac{\Gamma(\alpha+K)\,\Gamma(\beta+N-k)\,\Gamma(\alpha+\beta+n)}{\Gamma(\alpha+k)\,\Gamma(\beta+n-k)\,\Gamma(\alpha+\beta+N)} $$ If you want to assume that $K$ can be anything in the $[k, N-n+k]$ range, you can use uniform $\alpha=\beta=1$ prior. For further details check: Dyer, D. and Pierce, R.L. (1993). On the Choice of the Prior Distribution in Hypergeometric Sampling. Communications in Statistics - Theory and Methods, 22(8), 2125-2146. You may also be interested in reading about capture-recapture method where you are interested in finding $N$ , since it is closely related and follows the same logic.
