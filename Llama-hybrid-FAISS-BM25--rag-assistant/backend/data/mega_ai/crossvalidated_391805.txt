[site]: crossvalidated
[post_id]: 391805
[parent_id]: 161642
[tags]: 
Just to give a more clear understanding, I have explained each terminology with examples Multiclass classification/(One-Vs-One and One-Vs-ALL) : Classification task with >2 classes! Assumption is that each sample is assigned to one and only one label E.g. MNIST E.g. a set of images of fruits which may be oranges, apples, or pears. Last layer activation function would be softmax- softmax activation function generalizes the logistic activation function to C classes rather than just two classes. ( single label to single example ) Eg saying each image is either pedestrians or car or detect stop signs! Eg.saying each image is either of the numbers between 0-9(MNIST)! Or you can use 4 different logistic regression classifers- each neuron in the last layer has sigmoid activation function (extension of one-vs-all method!)! Multilabel classification : This Classification task assigns a set of target labels to each sample. E.g. Building a classifier for a self-driving car that would need to detect several different things such as pedestrians, detect other cars, detect stop signs in an image!. E.g. A document could have multiple topics! Loss function used would be "logLoss" Multioutput regression/ Multitarget regression/multidimensional linear regression : This task assigns a sample to a set of target values! E.g.predicting several properties for each data-point, such as wind direction and magnitude at a certain location Last layer activation should be linear Loss function used would be "MSE" Now let's comes to the difference between multi-task learning(one subset is a multilabel classification or multioutput regression) and multiclass classification problem! : Multi-class classification : You are assigning a single label (could be multiple labels such as MNIST problem) to the input image as explained above. Multi-task learning (one subset of it is multi-label classification) You're asking for each picture, does it have a pedestrian, or a car a stop-sign or traffic-light, and multiple objects could appear in the same image (one image can have multiple labels!). In other words, If you train a neural network to minimize this cost function (Log loss) you are carrying out multi-task learning because what you're doing is building a single neural network that is looking at each image and basically solving four different classification problems. It's trying to tell you does each image have each of these four objects in it?. Or you could achieve it by just training four separate neural networks instead of train one network to do four things! Note : But if some of the earlier features in the neural network can be shared between these different types of objects, then you find that training one NN to do four things, results in better performance than training four completely separate neural networks to do the four tasks separately. That's the power of Multi-task learning ! To put everything into perspective, Multi-task learning will make more sense when you have the below requirements: Training on a set of tasks that could benefit from having shared lower-level features! If the amount of data you have for each task is quite similar! @RockTheStar, I think your transfer learning suggestion isn't correct ! What you are trying to say & have similar(but weak) meaning for transfer learning, I will try to explain with the help of an example. Suppose you have 100 different tasks and you have 1000 train examples for each! If you build you separate NN for classifying each class you won't do much good! due to a limited number of training example (1000) but if you build a single network for solving 100 different, let's say classification problem then, you have (1000*1000)(Million instead of just 1000 for each separate task) training examples that can provide some knowledge that helps every other task among these 100 tasks. This is a big boost! Can train a big enough NN to do well on all the tasks!
