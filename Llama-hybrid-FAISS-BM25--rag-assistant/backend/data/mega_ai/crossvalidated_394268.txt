[site]: crossvalidated
[post_id]: 394268
[parent_id]: 
[tags]: 
What are reasonable decisions to make when performing logistic regression along with validation?

I'm not really a statistician but, in the words of Scarlet O'Hara in Gone with the Wind, "have always depended on the kindness of strangers.‚Äù I have a data matrix corresponding to 20 trials with 15 predictors each. Ten trials correspond to "true" and the remaining to "false." I'd like to perform a logistic regression. When I use all 15 predictors, Matlab gives me a warning that the data is linearly separable. Q1: Is this an indication that perhaps I'm trying to overfit? I then used PCA and experimented with reducing the dimension. Of course the p-values corresponding to the regression coefficients varied considerably. Q2: How much weight should I place on these p-values? Q3: I was hoping to perform some sort of cross-validation, perhaps "leave-one-out." Should I focus more on the validation and not worry as much about the p-values? Q4: When using "leave-one-out," what sort of cutoff do I use to decide whether the data point retained for training purposes is correctly classified. For example, if have a "true" data point and the probability of it being true as estimated from my model is at least .5, is that sufficient to conclude correct classification?
