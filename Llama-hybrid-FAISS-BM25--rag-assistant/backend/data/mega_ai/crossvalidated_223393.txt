[site]: crossvalidated
[post_id]: 223393
[parent_id]: 223370
[tags]: 
I would think that any algorithm that can prove it reaches a global error minimum (linear/logistic regression, support vector machines) should stay the same, except for maybe a few trailing decimal places. Models that do not make this guarantee that could get stuck in a local minimum, like neural networks or random forests, will probably differ from training session to training session.
