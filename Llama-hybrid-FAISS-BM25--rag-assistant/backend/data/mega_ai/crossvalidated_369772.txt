[site]: crossvalidated
[post_id]: 369772
[parent_id]: 
[tags]: 
Survival Analysis on recurrent behavior time series predictor

We are trying to build a credit model to predict the default time (or finally closed the loans as censored). The predictor is a high-dimension time series of current observed previous payment behavior. We hope to find some signal of default and default time. I am wondering which structure of the model approach should I use? A. Only observations when next loan application. There is one observation for each next loan, the response is the next loan default time or closed time with censored. Predictors are last 3-month payment behavior time series and its other feature engineering metrics. Advantage: The structure is clear and easy. Disadvantage: It seems it can only be used for application scorecard, but can not find early signal indicators for live loan becoming worse risk during the duration terms for monitoring. B. Rolling overlap observations for each month during the whole loan life. The response will be the remaining life time for each observation. The predictors will be the last 3-month time series and its feature engineering. Advantage: 1. It works for live loan monitoring. Lots of machine learning papers or NLP papers using such structure, so lots of example to review. Disadvantage: 1. It assume independent for each lag observation. (if I put applicants' other generic variables in it, it may partially solve the problem) Longer duration loans have more observations. Sort of bias. E.g. A patient smoked 10 times per day at the beginning time series, then get serious sick, then he changed into smocked 1 time per day as time series. Finally he died after 3 months. The model will think a 10 per day time series is related to a long survival time, while a once per day time series, or an improving time series (from 10 to 1) is related to a short survival time. (The credit risk model may suffer from such problem less series, because a good behavior of payment will definitely improve a longer survival time results in short term) C. Survival analysis with time-varying covariates. Advantages: It seems theoretically more correct? (I still not understand all the calculation details yet, please correct me if it is not suitable or not) Disadvantages: Most of the examples are based on Cox models. I want a parametric model which is easily predict the exact time and easier to embedded to machine learning techniques. D. Longitudinal analysis on survival analysis. Advantage: It seems theoretically correct? Disadvantage: It consider the changing signal as random effect and cares more about the accurate calibration of fixed effect based on the variance of random effect. But actually I want to find our the signal pattern of the changing signal. Which approach is more correct or more feasible in practice? Or there are other approaches more correct. Or any of the statement above is wrong, please correct me. Or just some other advice or suggestion, feel free to discuss together. Thank you.
