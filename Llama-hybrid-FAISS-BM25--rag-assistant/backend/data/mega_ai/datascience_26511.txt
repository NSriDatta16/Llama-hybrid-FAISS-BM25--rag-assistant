[site]: datascience
[post_id]: 26511
[parent_id]: 
[tags]: 
How would you describe the trade-off between model interpretability and model prediction power in layman's terms?

I know it depends on the data and question asked but imagine a scenario that for a given dataset you could either go for a fairly complex nonlinear model (hard to interpret though) giving you a better prediction power perhaps because the model may see the nonlinearities present in the data, or have a simple model (perhaps a linear model or something) with less prediction power but easier to interpret. Here is a very good post discussing ideas on how to interpret machine learning models. Industries, while being very cautious, are slowly becoming more interested in adopting more complex models! Still they want to know the trade-off clearly? A data scientist perhaps is the one sitting between data team and decision-makers, and often need to be able to explain these stuffs in layman's terms. I am trying to brainstorm here to see what analogy you would come up with to describe such trade-off to a non-technical person?
