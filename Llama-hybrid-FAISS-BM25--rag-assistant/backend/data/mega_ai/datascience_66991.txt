[site]: datascience
[post_id]: 66991
[parent_id]: 66787
[tags]: 
As pointed by Sean Owen, this is probably linked to correlation in the input variables. Concerning LIME : you can read here : https://christophm.github.io/interpretable-ml-book/lime.html (paragraph 5.7) why a correlation between inputs could pose problem, more specifically due to an implementation problem. (gaussian sampling ignore features correlation). Shapley values are designed to take correlation into account by construction (more specifically trough the symetry condition, hinting that the more variables are similar the more they will have a similar effect). However, as stated in https://arxiv.org/abs/1705.07874 (paragraph 4.2), SHAP rely on the independence of input to approximate Shapley values. So both techniques you used are subject to caution when used on data with important correlations.
