[site]: datascience
[post_id]: 86251
[parent_id]: 
[tags]: 
outliers in time series

I have a data set like the following where the rows are dates and the columns are values recorded by different sensors on those dates. Before working with the data for the purpose of predicting it, I would like to remove the anomalies. Standard deviation The first thing I found on the internet was to get data out of the standard deviation so working with this, I've come up with things like this. I search a little more in interet I have read that it is not a good method when the data does not follow a normal distribution. So I did a shapiro test for normality and the H0 hypothesis was rejected, my data doesn't look like a Guassian But if I plot a histogram, the data looks like half a bell. IQR in some sites I read about the IQR method which is based on ordering the data, so I went to test it too, and with a value of n of 1.5 it gave me results equal to the standard deviation tsmoothie At this point I was quite confused and I found this library and this link I thought maybe it was a better way than the above and tried to test it too. But I ran into the problem that it has many methods and I honestly don't know which one to use. PCA + IQR I kept looking on the internet and I found this link that left me more confused, it is a case similar to mine where there are several time series of various sensors. But after applying pca and iqr the following are anomalous points For me, this sensor has a normal behavior, but it marks many anomalous points, and in sensors with points with high values, it does not mark them as anomalous So in this context, what would be the best approach to detect the anomalous points before working with the data? What do you get used to doing?
