[site]: crossvalidated
[post_id]: 129039
[parent_id]: 129030
[tags]: 
For general and parametric approaches to feature selection , the following introductory paper might be helpful: http://machinelearning.wustl.edu/mlpapers/paper_files/GuyonE03.pdf . Another paper presents a rather comprehensive overview of both parametric and non-parametric techniques: http://www.psb.ugent.be/~yvsae/pdf/fssreview_Bioinformatics_2007_23_19_2507.pdf . Earlier and more general (fundamental) papers on feature selection in machine learning include http://www.aaai.org/Papers/Symposia/Fall/1994/FS-94-02/FS94-02-034.pdf and http://sci2s.ugr.es/keel/pdf/specific/articulo/Blum_Selection_1997.pdf . In regard to non-parametric approaches, in particular, for dimensionality reduction , I would recommend you to consider popular methods, such as principal component analysis (PCA) ( http://en.wikipedia.org/wiki/Principal_component_analysis ) and exploratory factor analysis (EFA) (see http://en.wikipedia.org/wiki/Factor_analysis and http://en.wikipedia.org/wiki/Exploratory_factor_analysis ). Usually, EFA is preferable to PCA , when researchers are interested in discovering latent structure of data (then latent variables are usually called factors ).
