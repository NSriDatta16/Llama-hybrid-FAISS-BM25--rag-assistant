[site]: datascience
[post_id]: 111061
[parent_id]: 111038
[tags]: 
Here are some proposal. I would need to see the code to be more specific. Did you randomize your data and split to train and validation parts? Have you applied any dropout to your learning process? Did you normalize the data? It seems that your model use quite different set of data, having them randomly organized could solve your issue. On the other hand, a 10% drop out could often avoid overfitting issues because it resets a part of neural network weights. Lack of normalization could also block the neurons to specific ranges of data and explain bad results in the validation dataset.
