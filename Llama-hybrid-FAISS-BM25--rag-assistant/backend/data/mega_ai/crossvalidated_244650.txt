[site]: crossvalidated
[post_id]: 244650
[parent_id]: 
[tags]: 
Cross-validation tuning

I'm using Caret to perform some analyses, but even after reading some books and the caret manual I still have some theoretical doubts. Below the code I'm using. #-- Partition of to original data into test and training #-- A two column df, response and predictor. part The questions that I have are: Shouldn't I repeat this several times to get an average of the predicted output of the test data? In this case I just have a response and a predictor, when doing the training, the final model is just a regular linear model fit or is it tuned (which is the reason for CV). Finally, in the case of having more than one predictor B1 and B2 , the tuning made in the train function means that the final model may be one of these: y = B1 + B2 , y = B1 x B2 , y = B1 , y = B2 Is this the real meaning of tuning of the model or I'm totally misunderstanding this.
