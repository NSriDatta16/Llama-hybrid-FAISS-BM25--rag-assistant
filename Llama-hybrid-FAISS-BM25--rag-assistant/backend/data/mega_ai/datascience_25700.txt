[site]: datascience
[post_id]: 25700
[parent_id]: 
[tags]: 
How differential semi-gradient Sarsa updates estimated average reward?

I cannot understand the way how algorithm Differential Semi-gradient Sarsa updates its estimated average reward $\bar{R}$. The algorithm I am looking at is from Sutton's text book Reinforcement Learning:An Introduction , section 10.3. Why does not update $\bar{R}$ using the reward $R$ got at current step like $\bar{R} = (1-\beta)\bar{R}+\beta*R$ ? Since based on definition, $\bar{R}$ is the estimated average reward. I cannot understand the reason why the updating is like this: $\bar{R} = \bar{R}+\beta*\delta$, where $\delta$ is just the TD error. Why using TD error to update the average reward? The following figure shows the algorithm.
