} ^{th}} location. Then the cost associated in joining the spring between i t h {\displaystyle \mathbf {i} ^{th}} and the j t h {\displaystyle \mathbf {j} ^{th}} point can be given by S ( p i , p j ) = S ( p i − p j ) {\displaystyle S(\mathbf {p} _{i},\,\mathbf {p} _{j})=S(\mathbf {p} _{i}-\mathbf {p} _{j})} . Hence the total cost associated in placing l {\displaystyle l} components at locations P l {\displaystyle \mathbf {P} _{l}} is given by S ( P l ) = ∑ i = 1 l ∑ j = 1 i s i j ( p i , p j ) {\displaystyle S(\mathbf {P} _{l})=\displaystyle \sum _{i=1}^{l}\;\displaystyle \sum _{j=1}^{i}\;\mathbf {s} _{ij}(\mathbf {p} _{i},\,\mathbf {p} _{j})} The above equation simply represents the spring model used to describe body pose. To estimate pose from images, cost or energy function must be minimized. This energy function consists of two terms. The first is related to how each component matches the image data and the second deals with how much the oriented (deformed) parts match, thus accounting for articulation along with object detection. The part models, also known as pictorial structures, are of one of the basic models on which other efficient models are built by slight modification. One such example is the flexible mixture model which reduces the database of hundreds or thousands of deformed parts by exploiting the notion of local rigidity. Articulated model with quaternion The kinematic skeleton is constructed by a tree-structured chain. Each rigid body segment has its local coordinate system that can be transformed to the world coordinate system via a 4×4 transformation matrix T l {\displaystyle T_{l}} , T l = T par ⁡ ( l ) R l , {\displaystyle T_{l}=T_{\operatorname {par} (l)}R_{l},} where R l {\displaystyle R_{l}} denotes the local transformation from body segment S l {\displaystyle S_{l}} to its parent par ⁡ ( S l ) {\displaystyle \operatorname {par} (S_{l})} . Each joint in the body has 3 degrees of freedom (DoF) rotation. Given a transformation matrix T l {\displaystyle T_{l}} , the joint position at the T-pose can be transferred to its corresponding position in the world coordination. In many works, the 3D joint rotation is expressed as a normalized quaternion [ x , y , z , w ] {\displaystyle [x,y,z,w]} due to its continuity that can facilitate gradient-based optimization in the parameter estimation. Deep learning based models Since about 2016, deep learning has emerged as the dominant method for performing accurate articulated body pose estimation. Rather than building an explicit model for the parts as above, the appearances of the joints and relationships between the joints of the body are learned from large training sets. Models generally focus on extracting the 2D positions of joints (keypoints), the 3D positions of joints, or the 3D shape of the body from either a single or multiple images. Supervised 2D joint positions The first deep learning models that emerged focused on extracting the 2D positions of human joints in an image. Such models take in an image and pass it through a convolutional neural network to obtain a series of heatmaps (one for each joint) which take on high values where joints are detected. When there are multiple people per image, two main techniques have emerged for grouping joints within each person. In the first, "bottom-up" approach, the neural network is trained to also generate "part affinity fields" which indicate the location of limbs. Using these fields, joints can be grouped limb by limb by solving a series of assignment problems. In the second, "top-down" approach, an additional network is used to first detect people in the image and then the pose estimation network is applied to each image. 3D joint positions With the advent of multiple datasets with human pose annotated in multiple views, models which detect 3D joint positions became more popular. These again fell into two categories In the first, a neural network is used to detect 2D joint positions from each view and these det