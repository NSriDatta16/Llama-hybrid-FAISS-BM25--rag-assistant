[site]: crossvalidated
[post_id]: 509042
[parent_id]: 481783
[tags]: 
The importance-weighted empirical risk is an unbiased estimator for the risk with respect to the target distribution, for any N. But it's difficult to say anything about the minimizer of the importance-weighted empirical risk for finite sample sizes. Let's abstract this a bit: Let F be a functional (i.e. takes in a function f and returns a number). Let G be random functional such that E[G(f)] = F(f) for every function f. In the IWERM scenario, F(f) is the expected error of f with respect to the target distribution, and G(f) is the importance weighted empirical error of f on the training sample. You're basically asking whether we have: E[ argmin_f G(f) ] = argmin_f F(f), where f ranges over some set of functions (in your example, affine functions). I don't see any reason for this to be true. One reason you would expect this to be false in the machine learning setting is overfitting. If we don't have a lot of data and we're fitting using a very expressive space of functions (e.g. neural networks or high degree polynomials), we may fit the data very well but perform terribly on new data. This will happen whether or not we're importance sampling. (I don't think this is what's happening in your simulation.) Here's the paper I originally referenced, just for the record. " Learning Bounds for Importance Weighting " by Cortes et al.
