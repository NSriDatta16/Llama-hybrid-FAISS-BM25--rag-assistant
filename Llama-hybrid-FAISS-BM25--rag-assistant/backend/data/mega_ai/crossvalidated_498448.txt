[site]: crossvalidated
[post_id]: 498448
[parent_id]: 498434
[tags]: 
If you have a simple neural network which separates some data $\{x_i\}$ , and it has a fully connected first layer with weight matrix $W$ , and then you apply some invertible linear transform $x' = Ax$ to the data, then $Wx = WA^{-1}x'$ , which is to say that if you use the weights $WA^{-1}$ on the transformed data, you'll get the same outputs.
