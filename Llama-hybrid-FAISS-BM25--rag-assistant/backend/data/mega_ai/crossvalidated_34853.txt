[site]: crossvalidated
[post_id]: 34853
[parent_id]: 33867
[tags]: 
Yes, it's converging, but difficult to see (or measure programmatically) from the first plot. You can try averaged SGD, where you use the average of the usual noisy SGD-trained parameters as the true model parameters. See Xu, 2011, " Towards Optimal One Pass Large Scale Learning with Averaged Stochastic Gradient Descent ." The averaged parameters should converge faster, and it should make your plots look much smoother.
