[site]: datascience
[post_id]: 65370
[parent_id]: 54947
[tags]: 
1) when the variable follows the non normal distribution you can use different transformation to make it normal, if variable follows the skewed distribution(either positive or negative) you can use log transformation to make it normal. 2) and 3) Instead of removing the outlier always go through outlier capping method, it will help to improve the performance of the model. 4) In machine learning some algorithm need to scale the data before go to modeling. for ex. cluster Analysis, Principal component Analysis(PCA). we can use scaling when the some values of the variable is too high as compare to the values of the other variable. (1,2,3,56,900,100,34,22,9) while using such type of algorithm always go to scaling instead of transformation.
