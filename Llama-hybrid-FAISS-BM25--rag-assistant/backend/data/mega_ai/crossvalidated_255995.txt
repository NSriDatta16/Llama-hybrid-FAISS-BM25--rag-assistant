[site]: crossvalidated
[post_id]: 255995
[parent_id]: 
[tags]: 
Neural network terminology "minimize"

In the TensorFlow documentation, it appears that the optimizer method "minimize" just takes a single step in the direction of the gradient (rather than doing this repeatedly until a local minimum is found). Is that terminology standard in machine learning? For example, the DDPG algorithm given in this paper contains the phrase "Update critic by minimizing the loss...". Does this actually mean "Take a single step in the direction of the negative loss gradient..."?
