[site]: datascience
[post_id]: 43216
[parent_id]: 
[tags]: 
Hyperas LSTM configuration assignment error

I have been working on my trivial keras lstm model trying to implement Hyperas with the following code that gives me an error I cannot resolve. I have just been experimenting around with Hyperas and it would be great to get this to work. My code in one file looks as follows: from keras.preprocessing import sequence from keras.models import Sequential from keras.layers import Dense, Embedding, Dropout, Activation from keras.layers import LSTM from keras.datasets import imdb from pandas import DataFrame from sklearn.preprocessing import MinMaxScaler from matplotlib import pyplot import h5py from keras.callbacks import TensorBoard from numpy import * from hyperas import optim from hyperas.distributions import choice, uniform from hyperopt import Trials, STATUS_OK, tpe from configuration.data_loader import * def data(): # normalise features scaler = MinMaxScaler(feature_range=(0, 1)) X_train_df , y_train_df , X_val_df , y_val_df , X_test_df , y_test_df = load_saved_datasets() X_train_df = scaler.fit_transform(X_train_df.get_values()) X_val_df = scaler.fit_transform(X_val_df.get_values()) y_train_df = y_train_df.get_values() y_val_df = y_val_df.get_values() X_train = X_train_df y_train = y_train_df X_val = X_val_df y_val = y_val_df return (X_train, y_train, X_val, y_val) def model(X_train, y_train, X_val, y_val): """ :param X_train: SCALED :param y_train: :param X_val: SCALED :param y_val: :return: """ X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1])) X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1])) model = Sequential() # Layer 1 model.add(LSTM({{uniform(4,70)}}, input_shape=(X_train.shape[1],X_train.shape[2]))) model.add(Activation({{choice(['tanh', 'relu'])}})) model.add(Dropout({{uniform(0, 1)}})) # If we choose 'four', add an additional fourth layer if {{choice(['two', 'three'])}} == 'two': # Layer 2 model.add(LSTM({{uniform(4,100)}}, input_shape=(X_train.shape[1],X_train.shape[2]))) model.add(Activation({{choice(['tanh', 'relu'])}})) model.add(Dropout({{uniform(0, 1)}})) model.add(Dense(1)) model.add(Activation({{choice(['softmax', 'relu', 'tanh'])}})) model.compile(loss='rmse', metrics=['accuracy'], optimizer={{choice(['rmsprop', 'adam', 'sgd'])}}) result = model.fit(X_train, y_train, batch_size={{choice([64, 128])}}, epochs=2, verbose=2, validation_data=(X_val, y_val)) #get the highest validation accuracy of the training epochs validation_acc = amax(result.history['val_acc']) print('Best validation acc of epoch:', validation_acc) return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model} def hyperas_main(): trials = Trials() best_run, best_model = optim.minimize(data=data, model=model, algo=tpe.suggest, max_evals=20, trials=trials) X_train, Y_train, X_test, Y_test = data() print("Evaluation of best performing model:") print(best_model.evaluate(X_test, Y_test)) print("Best performing model chosen hyper-parameters:") print(best_run) # print("Evalutation of best performing model:") # # print(best_model.evaluate(X_val, y_val)) # print("Best performing model chosen hyper-parameters:") # print(best_run) Where the function load_saved_datasets() simply loads my sets with pandas. However, the error output looks as follows: >>> Hyperas search space: def get_space(): return { 'LSTM': hp.uniform('LSTM', 4,70), 'Activation': hp.choice('Activation', ['tanh', 'relu']), 'Dropout': hp.uniform('Dropout', 0, 1), 'Dropout_1': hp.choice('Dropout_1', ['two', 'three']), 'LSTM_1': hp.uniform('LSTM_1', 4,100), 'Activation_1': hp.choice('Activation_1', ['tanh', 'relu']), 'Dropout_2': hp.uniform('Dropout_2', 0, 1), 'Activation_2': hp.choice('Activation_2', ['softmax', 'relu', 'tanh']), 'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']), 'batch_size': hp.choice('batch_size', [64, 128]), } >>> Data 1: 2: 3: # normalise features 4: scaler = MinMaxScaler(feature_range=(0, 1)) 5: 6: X_train_df , y_train_df , X_val_df , y_val_df , X_test_df , y_test_df = load_saved_datasets() 7: 8: X_train_df = scaler.fit_transform(X_train_df.get_values()) 9: X_val_df = scaler.fit_transform(X_val_df.get_values()) 10: 11: y_train_df = y_train_df.get_values() 12: y_val_df = y_val_df.get_values() 13: 14: X_train = X_train_df 15: y_train = y_train_df 16: X_val = X_val_df 17: y_val = y_val_df 18: 19: 20: 21: >>> Resulting replaced keras model: 1: def keras_fmin_fnct(space): 2: 3: """ 4: 5: :param X_train: SCALED 6: :param y_train: 7: :param X_val: SCALED 8: :param y_val: 9: :return: 10: """ 11: 12: X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1])) 13: X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1])) 14: 15: 16: model = Sequential() 17: 18: # Layer 1 19: model.add(LSTM(space['LSTM'], 20: input_shape=(X_train.shape[1],X_train.shape[2]))) 21: model.add(Activation(space['Activation'])) 22: model.add(Dropout(space['Dropout'])) 23: 24: # If we choose 'four', add an additional fourth layer 25: if space['Dropout_1'] == 'two': 26: # Layer 2 27: model.add(LSTM(space['LSTM_1'], 28: input_shape=(X_train.shape[1],X_train.shape[2]))) 29: model.add(Activation(space['Activation_1'])) 30: model.add(Dropout(space['Dropout_2'])) 31: 32: 33: model.add(Dense(1)) 34: model.add(Activation(space['Activation_2'])) 35: 36: model.compile(loss='rmse', metrics=['accuracy'], 37: optimizer=space['optimizer']) 38: 39: result = model.fit(X_train, y_train, 40: batch_size=space['batch_size'], 41: epochs=2, 42: verbose=2, 43: validation_data=(X_val, y_val)) 44: 45: #get the highest validation accuracy of the training epochs 46: validation_acc = amax(result.history['val_acc']) 47: print('Best validation acc of epoch:', validation_acc) 48: return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model} 49: Traceback (most recent call last): File "C:/Users/user/Desktop/AI/Backend/src/main.py", line 40, in lstm_training.hyperas_main() File "C:\Users\user\Desktop\AI\Backend\src\training\lstm_training.py", line 94, in hyperas_main trials=trials) File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperas\optim.py", line 67, in minimize verbose=verbose) File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperas\optim.py", line 133, in base_minimizer return_argmin=True), File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperopt\fmin.py", line 307, in fmin return_argmin=return_argmin, File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperopt\base.py", line 635, in fmin return_argmin=return_argmin) File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperopt\fmin.py", line 320, in fmin rval.exhaust() File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperopt\fmin.py", line 199, in exhaust self.run(self.max_evals - n_done, block_until_done=self.async) File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperopt\fmin.py", line 173, in run self.serial_evaluate() File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperopt\fmin.py", line 92, in serial_evaluate result = self.domain.evaluate(spec, ctrl) File "C:\Users\user\Anaconda3\envs\AI\lib\site-packages\hyperopt\base.py", line 840, in evaluate rval = self.fn(pyll_rval) File "C:\Users\user\Desktop\AI\Backend\src\temp_model.py", line 110, in keras_fmin_fnct UnboundLocalError: local variable 'X_train' referenced before assignment Where do I reference X_train before use? Is this due to naming conventions? Does the problem lie maybe with a computational graph? Any help is appreciated.
