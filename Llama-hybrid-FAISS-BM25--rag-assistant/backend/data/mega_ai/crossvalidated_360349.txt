[site]: crossvalidated
[post_id]: 360349
[parent_id]: 360261
[tags]: 
@jessica Data reduction for categorical variables is an interesting concept. Let's first discuss what is Data Reduction (DR)? Often in literature and research DR is equated with dimensionality reduction . DR is broadly of two types, Feature Selection (FS) and Feature Extraction (FE) . Note, there exists a major difference between the two. While a given FS method will focus on reducing the original set of features into a subset that explains the maximum variance. The FS method will maintain the original feature set. In short, it will NOT transform the original features or variables BUT will only derive those features or variables that explain the maximum variance. There exists both supervised and unsupervised FS techniques that aim to work with labelled or unlabeled datasets. Some FS methods are Information Gain Relief , Chi Squares , Fisher Score . Whereas a FE method will focus on transforming the original set of features into a subset that explains the maximum variance. The FS method will NOT maintain the original feature set. In short, it will transform the original features or variables and replace them with transformed variables. A well known FE method is Principal Component Analysis (PCA) . Note, PCA will orthogonally transform the original features into a subset of Principal Components (PCs) . Also note, mapping the PCs to the original set of variables is hard . Besides PCA will work only for continuous variables. If you want to conduct FE on categorical variables, I suggest use Multiple Correspondence Analysis (MCA) . Other FE methods are Linear Discriminant Analysis (LDA) and Cannonical Correlation Analysis (CCA) . With this brief discussion, lets focus on the R package . Try the FactoMineR package. Recently, I asked a similar question on StackOverflow. I invite you to read the discussion .
