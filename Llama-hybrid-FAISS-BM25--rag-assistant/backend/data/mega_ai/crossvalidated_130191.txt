[site]: crossvalidated
[post_id]: 130191
[parent_id]: 
[tags]: 
Proof of optimality of mean squared loss

Suppose I am building a predictor for $y = f_w(x) + noise$ using some framework with parameters $w$ (linear regression, neural networks, etc.) given a number of training examples $\{(x_i,y_i)\}$. I recall reading that finding the best $w$ in the sense of minimising the quadratic loss: $L(y, f_w(x)) = \sum_i (y_i - f_w(x_i))^2$ has the interpretation that that the learnt function $f_w(x)$ is such that $f_w(x) = E[y|x]$, assuming $(x,y)$ are drawn from some distribution $p(x,y)$. I also recall reading that finding the best $w$ in the sense of minimising the absolute value loss: $L(y, f_w(x)) = \sum_i |y_i - f_w(x_i)|$ has the interpretation that $f_w(x) = Conditional Median(y|x)$, assuming $(x,y)$ are drawn from some distribution $p(x,y)$. (Please correct me if I am wrong.) I'd like to know under what assumptions are the above statements valid? Are there some assumptions on the noise distribution? Should $p(x,y)$ take a particular form? Could you cite some formal references on this specific subject? It would be great if you could link to papers discussing the interpretation and proofs of other loss functions such as the log-loss, margin loss, etc.
