[site]: datascience
[post_id]: 124343
[parent_id]: 124318
[tags]: 
The neural network's weights are updated to reduce the difference between the predicted Q-value $Q(s,a;Î¸)$ and the target Q-value $y$ . Since we're only interested in the action that was actually taken, the gradient for actions not taken is zero, and they do not affect the update. This selective updating means that the neural network learns the value of the action that was chosen, without interfering with the values of other actions. Your loss is dependent only on actions that the agent selected. Since the loss only depends on the Q-value for the action that was actually taken, the partial derivatives (gradients) of the loss with respect to the Q-values of the other actions are zero. This is why the parameters of the network are only updated in relation to the action that was actually taken and the Q-values for the other actions remain unchanged for this particular training instance.
