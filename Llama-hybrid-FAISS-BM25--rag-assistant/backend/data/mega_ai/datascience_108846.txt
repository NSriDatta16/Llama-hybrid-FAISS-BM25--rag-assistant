[site]: datascience
[post_id]: 108846
[parent_id]: 108726
[tags]: 
Something seems unclear or maybe I didn't get it. Please comment if my answer is not precise enough. A recommender engine is not limited to its training data when it comes to query. The unfairness shows up if the pool of available items to be recommended is different for those 2 engines. Example : I train language models for calculating the similarity between a search query and the title of all websites on the web. Training data would be the text dataset based on which I tune my language model. Small dataset results in "bad" training so in query time, it may not work well as it did not cover the whole language distribution in training phase. BUT IT STILL GIVES A SET OF ANSWERS FOR THE QUERY! This is the point I concern you are mistaking. Recommender engines can be compared as long as the set of queries and item pool are fixed. Then the one trained on small data works poor in compare to the one which was trained on larger amount of data. For this comparison you "need" labeled data i.e. for a set of known queries you need to know the first $n$ item to be recommended or ranks of first $n$ item or some other kind of label. But you certainly need labelled data and when you have it, the comparison will be valid. For evaluation metrics, please have a look at this answer .
