[site]: datascience
[post_id]: 55037
[parent_id]: 55013
[tags]: 
You should take into account that the size of the images in the Keras example is as little as 28x28 and that they are grayscale images (i.e.a single channel), so if you want to actually compress the information you don't have much margin to increase the number of channels in the convolutional layers. The architecture of the encoder in normal autoencoders (with input images of larger sizes and in color) resembles the typical convolutional network meant for classification, where the width and height and progressively reduced and the number of channels increases, and there is a final flattening operation to express the information into a single dense vector.
