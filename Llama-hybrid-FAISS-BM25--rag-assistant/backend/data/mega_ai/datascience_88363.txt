[site]: datascience
[post_id]: 88363
[parent_id]: 
[tags]: 
How to compare hyperparameter tuning in R and Python

I tried random forest in both R (Caret) and Python (Scikit-learn), but the results differ drastically. Pearson correlation between predicted value and actual value was 0.2 in python whereas 0.8 in R. I suspect that is because of hyperparameter tuning difference and wanted to check detail settings in R and python. Since I manually designated hyperparameters in Python explicitly, I know hyperparameter values in Python, but in R I am not sure which corresponding hyperparameters were used. In R, it only shows mtry was chosen as 46 and number of trees were 500. In python, however, there were many more hyperparameters such as maximum number of levels in tree(max_depth), minimum number of samples required to split a node (min_samples_split), minimum number of samples required at each leaf node. Etc which I couldn’t find in R. Are there hidden default settings for the values in R or R doesn’t consider hyperparameters other than mtry and number of trees? If so, why? I tried to search such information but there was no information available. Below are the links that I referred to. https://arxiv.org/pdf/1804.03515.pdf https://topepo.github.io/caret/train-models-by-tag.html#random-forest
