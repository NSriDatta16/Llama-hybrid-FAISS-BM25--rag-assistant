[site]: datascience
[post_id]: 25882
[parent_id]: 
[tags]: 
Train a multi-output neural network to learn subset of "valid" response combinations

I'm working on extending a model of human immediate serial recall task performance, originally described in this paper . This model takes a sequence of items, such as digits or phonemes, stores them as they are presented, and then repeats the sequence back in order. Their model uses one-hot encoding and decoding to describe items to be remembered and recalled (such as digits or phonemes) as atomic units in memory. I'd like to adapt this model to describe items as collections of features instead. For example, rather than encoding the phoneme /b/ as a unique element in a one-hot vector, I'd like to model it as a combination of phoneme features (e.g. voiced = true, manner = stop, place = labial), with each input and output corresponding to one feature. Similarly, rather than modeling the digit "one" as a unique element in a one-hot vector, I'd like to model it as an input sequence of the phonemes (e.g. [w,^,n]). This formulation of the problem naturally leads to a set of possible model outputs that is larger than the set of items that occur in the training set. However, the models I've trained so far do not appear to have learned this structure in the data set. When the model produces an incorrect phoneme, it produces phoneme features combinations that do not occur in the training set at about a chance rate. Similarly, the model does not seem to learn the transition probabilities between phonemes within a word, and instead its incorrect responses seem unrelated across sequential phonemes. Restated, the model doesn't seem to learn to exploit the set of phonemes or words that are in the training data, and instead seem to "brute-force" the recall task by remembering every input as a sequence of phoneme features. Therefore, my question is if there are specific model structures or optimizers designed to exploit this cross-output and cross-time information to learn that some output patterns are "valid" (occur within the training set) or "invalid" (never occur within the training set)? I don't know if this is a problem that has been previously addressed, or whether I'm using the correct terminology, so any guidance would be appreciated. To date, I've tried a vanilla recurrent layer with a set of dense one-hot output layers to represent the output features. I've tried adding a softmax-activation dense layer before and after the recurrent layer, but this seemed to impair the model ability to store sequences. For optimizers, I have tried SGD, Adagrad, and Adam optimizers, with Adam generally giving the best results. Replacing the vanilla recurrent layer with LSTM or GRU units has improved the model ability to recall item sequences, but doesn't address the "invalid" response rate. I've been using Keras to implement the model.
