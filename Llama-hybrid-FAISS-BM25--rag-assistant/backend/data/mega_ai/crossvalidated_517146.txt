[site]: crossvalidated
[post_id]: 517146
[parent_id]: 
[tags]: 
How to compare a Linear Regression’s Coefficients with the Coefficients for its Subgroups using Standard Error?

Assume a linear regression model has been made of an item’s overall utility value, and elements like durability and color availability have statistically significant coefficients in the overall value equation. The overall value equation was derived from 300 surveys - 160 men and 140 women. While gender was not considered to be a factor in the value equation, it’s potential influence is being assessed after the overall equation was created. That creates six variables in a table: Durability - Y, with standard error Z. Durability (Men) - M, with standard error N. Durability (Women) - W, with standard error X. So, if given the Durability coefficient and standard error for the 300 surveys, and again for just the 160 men and 140 women, what findings can be derived? I get what the question’s asking, as there are interesting insights to report on: Did one gender associate high value to Durability and the other gender gave it low value? Did one gender consistently rate Durability, while the other gender had a broader range of opinions? What I don’t have is the statistical strength to find do the math behind this analysis. My plan was to make graphs of the three normal distributions and see how much they visually overlap. What’s the better way? Follow-up: What if it wasn’t gender? What if the post-analysis segmentation had 4+ buckets like ‘Durability by Region of Country’? That means whatever math test I use, I assume I have to compare the variable to the average and not the variables to one another. (This is my first post, so apologies in advance if I’m not following some etiquette, or left some key info out. Thank you!)
