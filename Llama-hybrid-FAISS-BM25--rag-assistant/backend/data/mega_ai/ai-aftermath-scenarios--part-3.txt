ithout traditional monetary exchange. However, this technological approach to communist goals faces several challenges. The transition period could create new forms of inequality between those who control AI systems and those who do not. Additionally, questions remain about how to ensure equitable access to advanced technologies and prevent the concentration of AI capabilities among a small elite, which could lead to new forms of class division rather than the classless society envisioned by communist theory. Benevolent dictator In this scenario, postulate that a superintelligent artificial intelligence takes control of society, but acts in a beneficial way. Its programmers, despite being on a deadline, solved quasi-philosophical problems that had seemed to some intractable, and created an AI with the following goal: to use its superintelligence to figure out what human utopia looks like by analyzing human behavior, human brains, and human genes; and then, to implement that utopia. The AI arrives at a subtle and complex definition of human flourishing. Valuing diversity, and recognizing that different people have different preferences, the AI divides Earth into different sectors. Harming others, making weapons, evading surveillance, or trying to create a rival superintelligence are globally banned; apart from that, each sector is free to make its own laws; for example, a religious person might choose to live in the "pious sector" corresponding to his religion, where the appropriate religious rules are strictly enforced. In all sectors, disease, poverty, crime, hangovers, addiction, and all other involuntary suffering have been eliminated. Many sectors boast advanced architecture and spectacle that "make typical sci-fi visions pale in comparison". Life is an "all-inclusive pleasure cruise", as if it were "Christmas 365 days a year". After spending an intense week in the knowledge sector learning about the ultimate laws of physics that the AI has discovered, you might decide to cut loose in the hedonistic sector over the weekend and then relax for a few days at the beach resort in the wildlife sector. Still, many people are dissatisfied, Tegmark writes. Humans have no freedom in shaping their collective destiny. Some want the freedom to have as many children as they want. Others resent surveillance by the AI, or chafe at bans on weaponry and on creating further superintelligence machines. Others may come to regret the choices they have made, or find their lives feel hollow and superficial. Bostrom argues that an AI's code of ethics should ideally improve in certain ways on current norms of moral behavior, in the same way that we regard current morality to be superior to the morality of earlier eras of slavery. In contrast, Ernest Davis of New York University this approach is too dangerous, stating "I feel safer in the hands of a superintelligence who is guided by 2014 morality, or for that matter by 1700 morality, than in the hands of one that decides to consider the question for itself." Gatekeeper AI In "Gatekeeper" AI scenarios, the AI can act to prevent rival superintelligences from being created, but otherwise errs on the side of allowing humans to create their own destiny. Ben Goertzel of OpenCog has advocated a "Nanny AI" scenario where the AI additionally takes some responsibility for preventing humans from destroying themselves, for example by slowing down technological progress to give time for society to advance in a more thoughtful and deliberate manner. In a third scenario, a superintelligent "Protector" AI gives humans the illusion of control, by hiding or erasing all knowledge of its existence, but works behind the scenes to guarantee positive outcomes. In all three scenarios, while humanity gains more control (or at least the illusion of control), humanity ends up progressing more slowly than it would if the AI were unrestricted in its willingness to rain down all the benefits and unintended consequences of its a