[site]: datascience
[post_id]: 88972
[parent_id]: 88967
[tags]: 
Three separate models (one per channel) will easily learn to predict the >channel category, but it will never output r0g1b2 and r2g3b0 classes in 64 class model because it have never seen these classes. How to overcome this problem? The only way to solve this problem is to use channels (one for each skin damage type) for each pixel, and treat it as a regression rather than a classification. In other words, use a multi output regression. For your output, use a convolutional layer that gives the same number of rows and columns as the input, but 4 channels (one for each skin damage type). Your ground truth (y_true) should be an array the same width and height as your input, but with 4 channels (one for each skin damage type) with each holding the severity rating of that pixel for the corresponding skin damage type. Your loss function could be something used for regression such as MAE (mean absolute error). This is because a classification will output 0 for classes it has never seen samples of since that is what minimizes the loss . A regression, on the other hand, will treat the target variable as continuous, and even if it hasn't seen examples of all severity levels of Type A skin damage (for example), it can still output them. You could then choose thresholds to classify the outputs into the corresponding labels. Ex. for each output 0.5 is 1, >1.5 is 2, >2.5 is 3, >3.5 is 4 so [0.1, 1.6, 0.7, 5] means {A: 0, B: 2, C: 1, D: 4} This is also more useful and easier to interpret in a clinical context as the severity is ordinal rather than just categorical, so a doctor would be better off knowing that a particular mild case (for example) had a prediction of 1.4 rather than 0.6, because they both correspond to a mild prediction but a 1.4 is closer to moderate and may be treated differently than a 0.6 This is an interesting problem from a learning and research perspective, but I develop deep learning based prognosis and diagnosis models using medical images at a big pharma/life sciences company and can tell you that a dataset of 200 images for a task this complex will be insufficient for decent performance or reliable results. multi-fold training/validation/testing AND some slight image augmentation will be necessary, but probably still insufficient.
