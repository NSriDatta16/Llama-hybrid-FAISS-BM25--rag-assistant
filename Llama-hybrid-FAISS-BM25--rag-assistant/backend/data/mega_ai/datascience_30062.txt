[site]: datascience
[post_id]: 30062
[parent_id]: 30061
[tags]: 
You can build a dictionary of character sequences (words) and for each instance of text you will count the occurrence of these words. You can either use groupings of characters n-grams or words them selves using bag-of-words . n-grams n-grams is a feature extraction technique for language based data. It segments the Strings such that roots of words can be found, ignoring verb endings, pluralities etc... The segmentation works as follows: The String: Hello World 2-gram: "He", "el", "ll", "lo", "o ", " W", "Wo", "or", "rl", "ld" 3-gram: "Hel", "ell", "llo", "lo ", "o W", " Wo", "Wor", "orl", "rld" 4-gram: "Hell", "ello", "llo ", "lo W", "o Wo", " Wor", "Worl", "orld" Thus in your example, if we use 4-grams, truncations of the word Hello would appear to be the same. And this similarity would be captured by your features. Bag-of-words Bag-of-Words builds a dictionary of the words it has seen during the training phase. Then using the word the frequency of each word in the example a vector is created. This can then be used with any standard machine learning technique.
