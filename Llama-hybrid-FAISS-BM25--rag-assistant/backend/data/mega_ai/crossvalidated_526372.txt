[site]: crossvalidated
[post_id]: 526372
[parent_id]: 526361
[tags]: 
I'll assume binary classification throughout. Multiclass or multilabel, and multioutput regression, may change things a bit more. Gradient boosted trees don't have significant differences between regression and classification: everything is the same except the loss function whose derivatives are used as targets for the individual trees Neural networks have more of a structural difference: everything is the same except for the activation of the final layer and the loss function applied to that layer and then backpropagated. Random forests show perhaps the greatest difference. The individual trees are constructed slightly differently, using a different splitting criterion. Then the predictions are aggregated differently: for regression, it's just the mean; for classification, it can be the mode of the trees' hard classifications (to obtain a hard classifier), or the mean of the trees' hard classifications, or the mean of the trees' soft classifications.
