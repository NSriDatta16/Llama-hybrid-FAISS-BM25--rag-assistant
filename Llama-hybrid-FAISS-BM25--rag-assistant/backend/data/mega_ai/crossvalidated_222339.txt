[site]: crossvalidated
[post_id]: 222339
[parent_id]: 222325
[tags]: 
Assume team A has a probability p of winning each game, independent across games. If team A is to win the best of 7 series, it must have at some point already won 3 games and wins the next game. At such time as team A has won 3 games and will win the next game, team B must have won either 0, 1, 2, or 3 games. A judicious application of the negative binomial addresses all these possibilities, and yields an expression in terms of p for the probability that team A wins the series. The result is that for p = 0.5, the probability that team A wins the series is (drum roll, Smitty) 0.5. If p = 0.7, the probability that team A wins the series is 0.873964. I will make you actually do the calculation to get the answer for p = 0.6. Alternatively, the problem can be readily, if somewhat laboriously, formulated using a bivariate discrete time time-homogeneous Markov Chain, with separate absorbing states for team A has won 4 games, and team B has won 4 games. Starting from a state of no games yet played, the 7th power of the one-step transition matrix can be calculated, and the "no games yet played" to "team A wins absorbing state" entry of this 7th power matrix provides the probability that team A wins the series. The advantage of this approach is that by expanding the state space and/or adjusting entries in the one-step transition matrix, it is easier to relax a number of assumptions in order to make the calculation better match the real world.
