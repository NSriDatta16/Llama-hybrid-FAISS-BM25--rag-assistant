[site]: crossvalidated
[post_id]: 244704
[parent_id]: 244665
[tags]: 
To answer your question, let's first put things into proper terms: I have a dataset consisting of ~20000 lines and 8 columns. It is a mixture of binary and float data You have a dataset with ~20,000 observations, or instances, and 8 variables. These variables are of mixed types: numeric/continuous, and categorical/discrete. one binary variable is the important one and I want to create a model to predict the other variables based on this binary. One of your binary variables is the classification (i.e. yes/no, positive/negative) that you are ultimately interested in. This is your response . You want to model the rest of your data as regarding that variable, so that (1) given the other seven variables, you can predict the classification of this instance, and (2) given the classification of an instance, you can perhaps make assumptions about average values for the other variables. These other variables are your predictors . This is a basic outline of a binary classification problem. What confuses me is the mix of binary and float data in order to select the best method. There are many different classifiers. The question that you need to consider for each is: how does this method handle continuous data, and how does this method handle categorical data? Most classifiers have no problem with continuous data. Even decision trees, which intuitively work best with categorical variables, can smoothly implement 'under the hood' mechanisms to handle continuous variables. So the real question is: how does this algorithm handle categorical variables? Logistic regression, a simple binary classifier, can handle your categorical data by creating 'dummy variables' for each category. A dummy variable is also called an indicator variable, and it takes on the value of either 1 or 0 to indicate the presence of a specific categorical value. For example, suppose you have a categorical variable, Gender. The values for this variable can be male, or female. A dummy variable for this can be Male. If the value of Gender is indeed male, then this dummy Male variable will have the value 1. Otherwise, it will be 0. By using dummy variables, categorical values can easily be represented and modeled in logistic regression. While it's important for you to understand how dummy variables work, most statistical software and languages provide 'assistance' for this. In python, for example, you can use pandas's get_dummies function to create those dummy variables for you. Here is a great tutorial demonstrating logistic regression in python, that specifically explores the usage of dummy variables. http://blog.yhat.com/posts/logistic-regression-python-rodeo.html Good luck!
