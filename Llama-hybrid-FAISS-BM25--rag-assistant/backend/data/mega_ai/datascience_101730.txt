[site]: datascience
[post_id]: 101730
[parent_id]: 
[tags]: 
How to run hdbscan clustering faster?

I'm using hdbscan to cluster embedding output from BERT, which took in a data file of >150k chat messages. The embedding process took a little over 4 minutes, but as of this writing the hdbscan clustering process has taken > 1 hour and there's no end in sight. What also seems weird to me is when I look at the system resource consumption (I'm on Windows 10), the script I'm running is only taking up 7% of CPU (i9-10850K) and 1.2GB of memory (out of 128GB). So I have a few questions, Why is this not consuming more system resources? Is there some way for me to parallelize this? Lastly here's the code FYI. data = parseMessages('raw-data-150k-new-delim.txt', 'รฐ') model = SentenceTransformer('paraphrase-MiniLM-L6-v2') embeddings = model.encode(data, show_progress_bar=True, convert_to_tensor=True) clusters = hdbscan.HDBSCAN( min_cluster_size=15, min_samples=15, metric='euclidean', cluster_selection_method='eom').fit(embeddings) Thanks!!
