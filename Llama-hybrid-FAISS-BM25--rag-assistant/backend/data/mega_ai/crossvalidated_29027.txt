[site]: crossvalidated
[post_id]: 29027
[parent_id]: 28993
[tags]: 
The Bayesian way of doing this loses no information: Your variable $X$ is categorically distributed with probability vector $\mathbf p$. The conjugate prior of the categorical distribution is the Dirichlet distribution, so let $\mathbf p$ be Dirichlet-distributed with shape parameter vector $\boldsymbol\phi$. With every observation, you update $\boldsymbol\phi$ by incrementing the realized component. You can then check to see if your maximum likelihood probability $\mathbf p^\star$ is within 0.01 of the true probability by integrating the ball with radius 0.01 centered at $\mathbf p^\star$.
