[site]: crossvalidated
[post_id]: 47058
[parent_id]: 
[tags]: 
Importance of variables in logistic regression

I am probably dealing with a problem that has probably been solved a hundred times before, but I'm not sure where to find the answer. When using logistic regression, given many features $x_1,...,x_n$ and trying to predict a binary categorical value $y$, I am interested in selecting a subset of the features which predicts $y$ well. Is there a procedure similar to the lasso that can be used? (I have only seen the lasso used for linear regression.) Is looking at the coefficients of the fitted model indicative of the importance of the different features? Edit - Clarifications After Seeing Some of the Answers: When I refer to the magnitude of the fitted coefficients, I mean those which are fitted to normalized (mean 0 and variance 1) features. Otherwise, as @probabilityislogic pointed out, 1000x would appear less important than x. I am not interested in simply finding the best k-subset (as @Davide was offering), but rather weigh the importance of different features relative to each other. For example, one feature might be "age", and the other feature "age>30". Their incremental importance might be little, but both may be important.
