[site]: datascience
[post_id]: 117806
[parent_id]: 117724
[tags]: 
The most common approach is to write custom preprocessing steps to standardize the names, examples include tokenizing, stemming, and lower casing. After extensive preprocessing, the resulting tokens can be mapped to existing vector embeddings. One useful example is a model trained on Common Crawl, such as FastText .
