[site]: crossvalidated
[post_id]: 62066
[parent_id]: 
[tags]: 
Backtesting/cross-validation for time-series and prediction intervals

Suppose I carry out the following exercise with my trusty statistics software: Fit some time-series model to the data $y_1,\dots,y_t$ and calculate $\hat{y}_{t+1}$, the fore­cast of the next obser­va­tion, and the error $e_{t+1}^*=y_{t+1}-\hat{y}_{t+1}$ for that fore­cast observation. Repeat the previous step for $t=m,\dots,n-1$ where $m$ is the min­i­mum num­ber of obser­va­tions needed for fit­ting my model. I plot the distribution of the errors $e_{m+1}^*,\dots,e_{n}^*$ or calculate its percentiles What relationship does that distribution have to the analytical prediction interval for $\hat y_{t+1}$? My intuition is that the distribution of the errors from this iterative CV process does not tell you very much about the variability of the prediction from the forecast made using the final version of the model. As the model is trained on more data, the errors will tend to decline with each step. So the large errors will be from early versions of the model and the small errors will come from the later versions. The final version of the model is more like the small-error late version, so it makes no sense to consider the early large errors as coming from that final model's error distribution. Even if there's no improvement in the model as it is fed more data, many time series model produce analytical prediction intervals. That will tell you if the difference in the actual and the prediction you observe is an outlier or not.
