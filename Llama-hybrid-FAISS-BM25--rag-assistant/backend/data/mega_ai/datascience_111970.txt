[site]: datascience
[post_id]: 111970
[parent_id]: 111951
[tags]: 
You can use a Bayesian model to evaluate the confidence of your predictions. You can then use the confidence to specifically acquire more data where you model is less confident. When training a normal / frequentistic machine learning model you only get one value back for every prediction you do (This is usually the mean or median of the Bayesian model). This does not incorporate the confidence of this value. Note, that in a classification problem you can't use the raw prediction value as a guide, because it does not represent any concept of confidence nor is the function linear or steady. I would also not use any normal evaluation metrics (mean squared error, area under the curve) as they are prone to overfitting. I guess the difference of these metrics between the training and test data could be an indicator, but again it does not represent any concept of confidence. A Bayesian machine learning models returns more information with which you can evaluate the confidence of the prediction. Known and unknown unknowns Ideally your Bayesian model distinguishes between known unknowns and unknown unknowns. Known unknowns lie in the non-determinism of your data. E.g. you can't predict the outcome of a coin throw and some dogs vs. cats are indistinguishable. Unknown unknowns come from the incompleteness of your knowledge. The model hasn't seen all examples, which are out there. There still could be some data out there which surprises your model. If you are using Tensorflow you can use TensorFlow Probability for this. Here is great talk with an accompanied blog post to get you started on the topic. It also explains the concept of known and unknown unknown in more detail, but beware you probably need to watch/read it multiple times. For other machine learning frameworks similar extensions exist. Bayesian bootstrap A very cheap way to build Bayesian model is to use a Bayesian bootstrap (I wouldn't recommend the normal bootstrap method as it can produce bad results for small datasets). However, this only considers unknown unknowns. Here is a good talk about the usefulness of a Bayesian bootstrap in general. It's from the author of R package to do this. A similar package for Python exists, but it is not as well maintained, but the core bits for training a Bayesian machine learning model work. I checked them and contributed to the library a while ago. The code to do this is also very short so you can even implement it yourself. Basically you train many models (an ensemble) with different weights for the data points. The output of this ensemble of frequentistic models is an ensemble of predictions. The closer the predictions are together (the smaller the variance) the more confident is the model about the prediction. With this technique you can also identify data points where the model is not very confident and especially ask for more example of those when acquiring more data. This is called active learning. You can listen to this podcast and explore this demo to learn more. Some ideas As for predicting how much the new data will improve you model, I have a few ideas, but have not tested them: You could train on smaller subsets of your data and plot the rising confidence levels over the size of the dataset. However, this would only work if you pull in new data randomly. When specifically choosing good new data points you would probably need to simulate this with your current dataset. There are probably many papers out there in the active learning space.
