[site]: crossvalidated
[post_id]: 374670
[parent_id]: 
[tags]: 
Why wider range for a feature in Machine learning affects training?

I was reading through the Google Machine learning crash course and I can't digest the below point: If a feature set consists of multiple features, then feature scaling provides the following benefits: Helps the model learn appropriate weights for each feature. Without feature scaling, the model will pay too much attention to the features having a wider range. Could anyone explain with an example of how the model will pay too much attention (How?) to the features having a wider range. ?
