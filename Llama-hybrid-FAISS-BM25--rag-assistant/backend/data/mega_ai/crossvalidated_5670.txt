[site]: crossvalidated
[post_id]: 5670
[parent_id]: 5619
[tags]: 
I see no obvious reason not to do so. As far as I know, we usually make a distinction between two kind of effect size (ES) measures for qualifying the strength of an observed association: ES based on $d$ (difference of means) and ES based on $r$ (correlation). The latter includes Pearson's $r$, but also Spearman's $\rho$, Kendall's $\tau$, or the multiple correlation coefficient. As for their interpretation, I think it mainly depends on the field you are working in: A correlation of .20 would certainly not be interpreted in the same way in psychological vs. software engineering studies. Don't forget that Cohen's three-way classification--small, medium, large--was based on behavioral data, as discussed in Kraemer et al. (2003), p. 1526. In their Table 1, they made no distinction about the different types of ES measures belonging to the $r$ family. There have by no way an absolute meaning and should be interpreted with reference to established results or literature review. I would like to add some other references that provide useful reviews of common ES measures and their interpretation. References Helena C. Kraemer, George A. Morgan, Nancy L. Leech, Jeffrey A. Gliner, Jerry J. Vaske, and Robert J. Harmon (2003). Measures of Clinical Significance . J Am Acad Child Adolesc Psychiatry , 42(12), 1524-1529. Christopher J. Ferguson (2009). An Effect Size Primer: A Guide for Clinicians and Researchers . Professional Psychology: Research and Practice , 40(5), 532-538. Edward F. Fern and Kent B. Monroe (1996). Effect-Size Estimates: Issues and Problems in Interpretation . Journal of Consumer Research , 23, 89-105. Daniel J. Denis (2003). Alternatives to Null Hypothesis Significance Testing . Theory and Science , 4(1). Paul D. Ellis (2010). The Essential Guide to Effect Sizes . Cambridge University Press. -- just browsed the TOC
