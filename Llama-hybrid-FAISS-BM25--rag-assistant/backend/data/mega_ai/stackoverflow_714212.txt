[site]: stackoverflow
[post_id]: 714212
[parent_id]: 597483
[tags]: 
Benchmarking a runtime environment as complex as the JVM is hard. Even excluding the JIT and GC, you've got a big heap, memory layout and cache variation between runs. One thing that helps with Jython is simply running the benchmark more than once in a single VM session: once to warm up the JIT and one or more times you measure individually. I've done a lot of Jython benchmarking, and unfortunately it often takes 10-50 attempts to achieve a reasonable time You can use some JVM flags to observe GC and JIT behavior to get some idea how long the warmup period should be, though obviously you shouldn't benchmark with the debugging flags turned on. For example: % ./jython -J-XX:+PrintCompilation -J-verbose:gc 1 java.lang.String::hashCode (60 bytes) 2 java.lang.String::charAt (33 bytes) 3 java.lang.String::lastIndexOf (156 bytes) 4 java.lang.String::indexOf (151 bytes) [GC 1984K->286K(7616K), 0.0031513 secs] If you do all this, and use the HotSpot Server VM, you'll find Jython slightly faster than CPython on pystone, but this is in no way representative of Jython performance in general. The Jython developers are paying much more attention to correctness than performance for the 2.5 release; over the next year or so with a 2.6/2.7/3.0 release performance will be more emphasized. You can see a few of the pain points by looking at some microbenchmarks (originally derived from PyPy) I run.
