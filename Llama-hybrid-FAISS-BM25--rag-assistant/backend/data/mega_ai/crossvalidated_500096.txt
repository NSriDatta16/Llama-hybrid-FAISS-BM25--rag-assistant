[site]: crossvalidated
[post_id]: 500096
[parent_id]: 123124
[tags]: 
Following Will's comment. This article (www0.cs.ucl.ac.uk/staff/W.Langdon/roc) has some good points under the heading "Choosing the Operating Point". picking the point closest to the top left corner of a ROC curve equates to choosing the operating point such that TPR = TNR, i.e. false positives are equally bad as false negatives. â€“ Will Nov 13 at 15:57. Using iscost line from the link www0.cs.ucl.ac.uk/staff/W.Langdon/roc. Using these concept: alpha = cost_false_positive = cost of a false positive (false alarm) beta = cost_false_negative = cost of missing a positive (false negative) p = proportion of positive cases Then the average expected cost of classification at point x,y in the ROC space is C = (1-p) alpha x + p beta (1-y). To find the best threshold you have to minimize C so : best_threshold = argmin ( (1-p) alpha x + p beta (1-y) ). This seams to works.I am open to suggestion or remarks. Here is the code. In needs to have binary_thresholds, fp_rate, recall. Here fp_rate and recall is of the shape (num_thresholds, 1) or (num_thresholds, num_classes). def find_best_binary_auc_threshold(binary_thresholds, fp_rate, recall, proportion_positive_case: float = 0.5, cost_false_positive: float = 0.5, cost_false_negative: float = 0.5, argmin_axis: int = 0): isocost_lines = cost_false_positive * (1 - proportion_positive_case) * fp_rate + cost_false_negative * proportion_positive_case * (1 - recall) best_indexes = np.argmin(isocost_lines, axis=argmin_axis) best_thresholds = binary_thresholds[best_indexes.tolist()] return best_thresholds, best_indexes
