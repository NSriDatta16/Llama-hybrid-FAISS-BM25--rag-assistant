[site]: crossvalidated
[post_id]: 529484
[parent_id]: 
[tags]: 
How to train a linear regression if the number of sample features is variable (time series) (in sklearn)

Let's assume for the samples $\{(x_i,y_i)\},$ the $dim\ x_i$ is variable, e.g. a time series $x_i = (x_{i1},\cdot,x_{iT_i}).$ Then how do we train a linear regression for such samples? Especially how do we deal with such case in sklearn ? Currently I naively fixed a length $l$ (usually the maximal length of $x_i$ in samples), then add $0$ for the length of sample being short than $l;$ or cut off for the length of sample being longer than $l$ (test sample). Since I never used the deep learning library, do you have any example for the code of LSTM ï¼Ÿ I think such input samples must be very common in LSTM. Another way I think is interpolate/extrapolate each time series (sample) to get a continuous curve. Then fix some common synthetic time points to obtain a synthetic time series for each sample. Then the training is based on those synthetic time series with same length. Update: If we train a time series prediction (no label) like ARMA, then it is easy to use a moving window to obtain the equal length data. However if it is a Supervised learning, The samples are something like: $$\{(x_1^1,x_1^2,x_1^3),y_1\},\{(x_2^1,x_2^2),y_2\},\{(x_3^1,x_3^2,x_3^3,x_3^4,),y_3\},\cdots$$ Then even for RNN or LSTM, how to deal with it? It seems Keras also demands the equal length on $x.$
