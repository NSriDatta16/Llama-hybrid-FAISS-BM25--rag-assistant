[site]: crossvalidated
[post_id]: 526001
[parent_id]: 
[tags]: 
What is an appropriate way to address this problem?

I have the following problem: Given long texts (around 15K words each), and five values associated with each one of them (the famous big5 traits), predict, for a new text, its big5 values based on the available training data. An example training row looks like this: big5_openness | big5_conscientiousness | big5_extraversion | big5_agreeableness | big5_neuroticism | input_text Each big5 value is an integer between 0 and 100. Assume the input_text is in english, but it contains many weird symbols (codes for emojis, for example) My idea is the following: Use a sentence encoder to transform each text into a vector. This becomes a regression problem - fit the encoded texts (vectors, that are represented as a matrix X ) and the y values (these are the big5 values, that are of shape (1, 5) ) into a regressor and predict for new input. The limitations: The texts are huge - I am using bert to encode sentences ( https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens ), but it considers only the first 500 tokens, which is not sophisticated enough. I have tried Longformer , but it is extremely slow and it also has token limitation: 4096. Predict all 5 values at the same time - I am using xgb.XGBRegressor to predict only 1 value at a time. I would like to use some model that can predict all values at once (because there could be a correlation between them and it would probably be more accurate if the model predicts them at once) I have implemented my ideas and, using RMSE as error metric, I have average 21 error (RMSE) for predicting only the first big5 value: openness. Dimensions of my input: X_train: (16378, 768) y_train: (16378,) X_validate: (1820, 768) y_validate: (1820,) NOTE! The y-s only contain one value, because I am running only on the first big5 value. Do you have any ideas how to approach this problem to achieve better accuracy, speed, what would be a good structure of the whole pipeline to approach this problem?
