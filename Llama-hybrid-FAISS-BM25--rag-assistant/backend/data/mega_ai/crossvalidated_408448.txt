[site]: crossvalidated
[post_id]: 408448
[parent_id]: 
[tags]: 
Running two MCMC chains in parallel while minimizing Kullback-Leibler divergence between both sample distributions

I want to sample from a distribution $p(X)$ with $X \in R^n$ . However, I can only evaluate the likelihoods of $Z = AX$ and $Z = BX$ with $A,B \in R^{m \times n}$ and $m = n-1$ . Now my idea is to run two Markov Chain Monte Carlo samplers in parallel while minimizing the Kullback-Leibler divergence of the sample-approximated distributions of both chains. I was thinking of some kind of autoregressive proposal distribution that becomes tighter when the approximated distribution of a chain is wider than that of the other chain (and vice versa). Is this feasible? Does anyone know an existing algorithm that does something similar? I would be very happy about any expert opinion on that.
