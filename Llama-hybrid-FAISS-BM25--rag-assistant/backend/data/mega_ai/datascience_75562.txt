[site]: datascience
[post_id]: 75562
[parent_id]: 61009
[tags]: 
If we treated NER as a classification/prediction problem, how would we handle name entities that weren't in training corpus? The goal of a NER Tagger is to learn patterns in language that can be used to classify words (or more generally, tokens), given a pre-specified set of classes. These classes are defined before training and remain fixed. Classes such as: PERSON , DATETIME , ORGANIZATION , ... you name it. A good NER Tagger will learn the structure of a language and recognize that "Fyonair is from Fuabalada land." follows some linguistic rules and regularities, and that from these regularities (learned autonomously during training) the classifier can attribute Fyonair class PERSON and to Fuabalada the class LOCATION . How would our model identify it if it wasn't included in billions of corpus and tokens? In fact, Deep Learning models tend to work better than others with very large datasets (the so called "big data"). On small datasets they are not extremely useful. Can unsupervised learning achieve this task? NER tagging is a supervised task. You need a training set of labeled examples to train a model for that. However, there is some unsupervised work one can do to slightly improve the performance of models. There is this useful paragraph that I took from Geron's book : Suppose you want to tackle a complex task for which you don't have much labeled training data [...] If you can gather plenty of unlabeled training data, you can try to use it to train an unsupervised model, such as an autoencoder or a generative adversarial network [...] Then you can reuse the lower layers of the autoencoder or the lower layers of the GAN's discriminator, add the output layer for your task on top, and fine tune the final network using supervised learning (i.e. the label training examples). It is this technique that Geoffrey Hinton and his team used in 2006 and which led to the revival of neural network and the success of Deep Learning. [ p. 349, 2nd edition. ] (Best book on Machine Learning ever, IMHO.) This unsupervised pretraining is the only way to use unsupervised models for NER that I can think of. Good luck with your task!
