[site]: crossvalidated
[post_id]: 580300
[parent_id]: 580280
[tags]: 
To add a little to @Bj√∂rn's answer, when the model selection criterion is noisy (or there is a random element to the classifier) grid search (or random search) actually makes more sense than some more elegant or more efficient model selection procedures, such as gradient descent or Nelder-Mead simplex, where the randomness may affect the termination criterion for the optimisation algorithm (they generally stop when the improvement in performance or the "gradient" is small). Randomness in the construction of a classifier is not ideal, so minimising it by e.g. using lots of trees is a good idea. One problem is that the noisyness of the classifier construction may make it easier to over-fit the model selection criteria if the "randomness" of a particular classifier just happens to suit the sampling variation in the validation set (or cross-validation) error.
