[site]: crossvalidated
[post_id]: 134332
[parent_id]: 
[tags]: 
Unclear what to make of test results

I'm attempting to classify e-mails using Mallet and an SVM. Below are some test-results, but I'm not sure what to make of them. The test-set is the most recent e-mails found per project. The training-set is the most recent e-mails that come after that So a value of 10/100 on the axis means: 10 most recent e-mails as test 100 most recent e-mails as training, skipping the first 10 In the end a trained classifier will need to make predictions on a new incoming e-mail about which project it most likely belongs to. The reason I sort the data by time is that I'd like to use only the most relevant data for training. This is because the topics in mails change over time and a very old e-mail might not add any useful information. Data I'm using as tokens (they're stored as a graph database): e-mail addresses found in header (to, from, cc, bcc) words and e-mail addresses found in subject and message body F2-scores per project as a function of test-size / train-size Fraction of instances that have the correct label as their best predicted label: Some questions I have: Does a horizontal line in the graph mean that adding new information does not matter? Is it true that I should use as large a training set as possible? Not every project has the same amount of e-mails, so after a while one project will have a larger training set than another. Does this matter? Any other insights I might be oblivious to?
