[site]: datascience
[post_id]: 5675
[parent_id]: 5639
[tags]: 
I would suggest playing around with this in either R or Python using Scikit Learn . The text will take a bit of playing with, but is pretty straightforward to normalize and turn into a feature set. I suggest applying TFIDF to normalize each text document against the entire corpus. You will then have lots of text features that you can join with your metadata features to do novelty detection. Scikit-Learn and it's excellent User Guide are a great resource for getting started in this arena as are Mahout (Java based) and the book Mahout In Action . There are also countless packages in R to accomplish this. One thing to note is that you seem to suggest specific ways that you want to detect fraud. This type of hunch based machine learning is known as applying heuristics and tends to perform worse than pure machine learning methods. You should just focus on using novelty detection algorithms or possibly anomaly detection algorithms and let the statistics find the fraud rather than trying to apply your own intuition.
