[site]: crossvalidated
[post_id]: 458814
[parent_id]: 92157
[tags]: 
I want to start of by thanking @amoeba says Reinstate Monica & ttnphns for their contributions that have greatly helped me! I'm so grateful in fact, I'd want to buy them a drink or be able to return the favor somehow. The only thing I'm going to add to their reply is my python implementation of drawing these Decision boundaries, I think it'll help others, theory and insight is great, but some understand better through code. The code below is useful for visualization, I have used LDA for dimensionality reduction (10 000 dim to 2D) for 3 classes. The framework is sklearn. Only the code to plot the DB is written below, if you're interested in the training part of the classifier, sci-kit learn's documentation is VERY good. The code below assumes you have projected your training data to 2D and you have computed their means. x_min, x_max = plt.xlim() # xplot = np.linspace(x_min, x_max, 100) #to plot the whole lines and find the intersection #x_l1 and x_l2 to only plot the relevant part of the lines [found the intersection by first plotting the data] x_l1 = np.linspace(x_min, 0.272, 100) x_l2 = np.linspace(0.272, x_max, 100) cov = lda1_2features.covariance_ prec_m = np.linalg.inv(cov) line1 = np.dot(prec_m, (mu1[0]-mu1[1]).T)#mu1 contains the coordinates of all the # classes [in this example 3 classes) midpoint1 = (mu1[1]+mu1[0])/2 plt.plot(midpoint1[0], midpoint1[1], 'p', color='magenta', markersize=10, markeredgecolor='grey') rico1 = -line1[0]/line1[1] cte1 = midpoint1[1]-(rico1)*midpoint1[0] # plt.plot(xplot, (rico1*xplot)+cte1, '--b') plt.plot(x_l1, (rico1*x_l1)+cte1, '--b') line2 = np.dot(prec_m, (mu1[0]-mu1[2]).T) midpoint2 = (mu1[2]+mu1[0])/2 plt.plot(midpoint2[0], midpoint2[1], 'p', color='magenta', markersize=10, markeredgecolor='grey') rico2 = -line2[0]/line2[1] cte2 = midpoint2[1]-(rico2)*midpoint2[0] # plt.plot(xplot, (rico2*xplot)+cte2, '--r') plt.plot(x_l2, (rico2*x_l2)+cte2, '--r') line3 = np.dot(prec_m, (mu1[1]-mu1[2]).T) midpoint3 = (mu1[2]+mu1[1])/2 plt.plot(midpoint3[0], midpoint3[1], 'p', color='magenta', markersize=10, markeredgecolor='grey') rico3 = -line3[0]/line3[1] cte3 = midpoint3[1]-(rico3)*midpoint3[0] # plt.plot(xplot, (rico3*xplot)+cte3, '--g') plt.plot(x_l1, (rico3*x_l1)+cte3, '--g') plt.show() 2D subspace of classifier I with Decision boundaries, class centers(yellow star), cov_ellispses and midpoints(pentagons) plotted in one figure using matplotlib] Sources; scikit_lda_qda scikit_lda
