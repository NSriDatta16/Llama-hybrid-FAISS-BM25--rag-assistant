[site]: crossvalidated
[post_id]: 493069
[parent_id]: 493037
[tags]: 
To sum up my comments, EFA suffers from two main drawbacks in this context: It doesn't incorporate the design effect (repeated measures, which implies a specific variance-covariance matrix); There's no way to tell whether one model is better than the other: There's no real goodness-of-fit measure in EFA. If you are only interested in scale reliability, then computing the intraclass correlation (with its associated 95% confidence interval) should be enough. This won't, however, take into account measurement error unless you correct for it, as suggested by William Revelle on his Personality Project . If the factor structure matters, the proper way to analyze such data would be to use some Structural Equation Model (or CFA under the umbrella of the multilevel factor analysis ) since this allows to account for repeated measures. One of the benefit of this approach is that you can directly use the factor scores (i.e., accounting for incorporate measurement error) for further processing at no cost (regression, comparison of means, etc.). In response to comments, the above suggestion assumes that items (item content + response options) are constant in your scale, i.e. items do not vary from one administration to the other (like, e.g., when using different images which all relate to the same category, and subjects are asked to rate them). If, on the contrary, the pre-post scores aren't necessarily related on a per subject basis (or they are simply be anti-correlated), you're probably more interested in demonstrating that the interitem correlation matrix is comparable between the two administrations (since this will account for the intra-individual high/low balance), that item loadings are close one each other, and that the scale has adequate internal consistency (Cronbach alpha or other related indices). Since EFA is mainly concerned with factor structure and interitem correlation, it's probably the best way to go. It will be harder to work directly with raw or factor scores, unless you standardize them (using reverse scoring or other kind of absolute transformation) so that they remain comparable from one administration to the other, but analyzing the observed correlation matrix (between items, for all subjects) using classical data analysis techniques (PCA, MCA or cluster analysis) should be enough.
