[site]: crossvalidated
[post_id]: 207515
[parent_id]: 207509
[tags]: 
In short, no. There's a "no free lunch theorem" in machine learning that there's no a-priori distinction in machine learning algorithms. The best technique is usually to try a wide diversity of algorithms on your dataset, and pick the one that seems to give the best out-of-sample error. scikit-learn contains great functions for doing this. I suggest you try a random forest first. Those often give pretty good results on real-world, tabular data.
