, industrial automation) and fundamental issues (e.g. AI classification, security, certifiability, socio-technical systems, ethics). On the other hand, it provides an overview of the central terms in the field of AI and its environment across a wide range of interest groups and information sources. In total, the document covers 116 standardisation needs and provides six central recommendations for action. G7 On 30 October 2023, members of the G7 subscribe to eleven guiding principles for the design, production and implementation of advanced artificial intelligence systems, as well as a voluntary Code of Conduct for artificial intelligence developers in the context of the Hiroshima Process. The agreement receives the applause of Ursula von der Leyen who finds in it the principles of the AI Directive, then being finalized. New guidelines also aim to establish a coordinated global effort towards the responsible development and use of advanced AI systems. While non-binding, the G7 governments encourage organizations to voluntarily adopt the guidelines, which emphasize a risk-based approach across the AI lifecycle—from pre-deployment risk assessment to post-deployment incident reporting and mitigation. The AIP&CoC also highlight the importance of AI system security, internal adversarial testing ('red teaming'), public transparency about capabilities and limitations, and governance procedures that include privacy safeguards and content authentication tools. The guidelines additionally promote AI innovation directed at solving global challenges such as climate change and public health, and call for advancing international technical standards. Looking ahead, the G7 intends to further refine their principles and Code of Conduct in collaboration with other organizations like the OECD, GPAI, and broader stakeholders. Areas of broader development include more clrsnrt AI terminology (e.g., "advanced AI systems"), the setting of risk benchmarks, and mechanisms for cross-border information sharing on potential AI risks. Despite general alignment on AI safety, analysts have noted that differing regulatory philosophies—such as the EU's prescriptive AI Act versus the U.S.'s sector-specific approach—may challenge global regulatory harmonization. Israel On October 30, 2022, pursuant to government resolution 212 of August 2021, the Israeli Ministry of Innovation, Science and Technology released its "Principles of Policy, Regulation and Ethics in AI" white paper for public consultation. By December 2023, the Ministry of Innovation and the Ministry of Justice published a joint AI regulation and ethics policy paper, outlining several AI ethical principles and a set of recommendations including opting for sector-based regulation, a risk-based approach, preference for "soft" regulatory tools and maintaining consistency with existing global regulatory approaches to AI. In December 2023, Israel unveiled its first comprehensive national AI policy, which was jointly developed through a collaboration between ministerial and stakeholder consultation. In general, the new policy outlines ethical principles aligned with current OECD guidelines and recommends a sector-based, risk-driven regulatory framework, which focuses on areas like transparency and accountability. The policy proposes the creation of a national AI Policy Coordination Center to support regulators, and further developing the tools necessary for responsible AI deployment. In addition, alongside 56 other nations, to domestic policy development, Israel signed the world's first binding international treaty on artificial intelligence in March 2024. The specific treaty, led by the Council of Europe, has obliged signatories to ensure current AI systems uphold democratic values, human rights, and the rule of law. Italy In October 2023, the Italian privacy authority approved a regulation that provides three principles for therapeutic decisions taken by automated systems: transparency of decision-making 