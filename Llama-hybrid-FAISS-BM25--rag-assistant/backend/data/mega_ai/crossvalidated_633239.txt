[site]: crossvalidated
[post_id]: 633239
[parent_id]: 633028
[tags]: 
Start with the intercept. As you have chosen sum/deviation coding, that is a type of average outcome over all levels of the predictors: "the mean of means of the dependent variable at each level of the categorical variable," as this UCLA web page puts it. You have two such categorical variables, so the intercept is the estimate at the average over all levels of both of them. With logistic regression, this is in a log-odds scale. The main effect of condition With an interaction between task and condition , the association of one with outcome depends on the value of the other. With sum/deviation contrasts, the "main effect" coefficient for any level of one of those 2 predictors is the associated difference (here, a log-odds difference) from the intercept ("grand-mean" outcome), evaluated at the "grand mean" over the levels of the other. Is that really of interest by itself, without considering the significant interaction between task and condition ? What might be of more interest is the overall association between condition and outcome, taking all of its levels and interactions into account, sometimes called a "chunk test." A UCLA web page on logistic regression illustrates that with the wald.test() function of the R aod package . If you work within the rms package (highly recommended if you are going to do a lot of regression analysis), its anova() function (unlike that of base R statistics) provides that type of test. What about condition d ? With 4 levels of condition you only get 3 coefficients. The intercept ("grand mean") includes the effect associated with the 4th level. If you know the "grand mean" over all 4 levels and the differences of the other 3 levels from the grand mean (their individual coefficients under sum/deviation coding), it's simple algebra to get the point estimate of the 4th level, condition d . For confidence intervals around that estimate, however, you need to know the variance-covariance matrix of the coefficient estimates. That's not included in this model summary, although it's included in the model and accessible via the vcov() function. Post-modeling tools like those provided by the emmeans package can perform such calculations for you. These tools take the choice of predictor coding into account, so that you can typically just use the default R dummy/treatment coding for categorical predictors.* The interaction between task and condition Two-way interaction coefficients represent additional differences beyond what you would otherwise predict, based on the intercept and the individual coefficients for those specific levels of the predictors. I find it easier to think through those interactions with dummy/treatment coding. You can get outcome predictions for any combinations of predictor values, taking all coefficients into account, with post-modeling tools like those in the emmeans and rms packages. *The only situation I can think of where categorical-variable coding matters is when you perform so-called "Type III ANOVA" tests on a model; dummy/treatment contrasts don't work then. But you probably shouldn't be doing those tests anyway; see the help page for the Anova() function in the R car package .
