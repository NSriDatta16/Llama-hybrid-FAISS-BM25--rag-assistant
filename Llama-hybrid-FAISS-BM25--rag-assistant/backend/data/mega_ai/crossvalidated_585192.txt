[site]: crossvalidated
[post_id]: 585192
[parent_id]: 
[tags]: 
Difference Between GLM predict Output in R vs. GLM predict Output in Python (statsmodels) Logistic Regression

I am just working on trying to port some R script to Python. I am fairly new to the Python language. I have been going through the R script and converting it. But there is a part that is stumping me, where I ran a logistic regression in statsmodels GLM, but when I use the predict method afterwards, the results I am getting from statsmodels is not comparable to what I get running R. I just need some help in figuring out how Python is running, to lead to the differences. To make it easier for reproducibility, I will include both my R and Python scripts. I will post my R scripts first, followed by the Python along with the data. # R Script # the dataframe dfR = data.frame('DV' = c(1, 1, 0, 0, 1, 0, 1, 0, 0, 1), 'IV1' = c(3.58517, 2.07391, 0.55865, 1.08131, 0.15004, 2.9959, 1.29169, 1.50527, 0.81436, -1.90697), 'IV2' = c(3.73935, 0.53802, 1.73509, 3.01428, 2.7058, 1.97086, 3.98669, 2.67305, 3.18234, 1.39142), 'IV3' = c(0.8255, 4.8461, 4.3388, 2.565, 5.6754, 5.4174, 7.666, -0.1009, 0.4374, 3.6268) ) print(dfR) Y $v P u Z Below is the Python code, it follows the R code exactly, with just minor variations to be consistent with how Python outputs stuff # Python Code import pandas as pd import numpy as np from sklearn.preprocessing import StandardScaler from numpy import linalg import statsmodels.api as sm import statsmodels.formula.api as smf # the dataframe dfP = pd.DataFrame( {'DV': [1, 1, 0, 0, 1, 0, 1, 0, 0, 1], 'IV1': [3.58517, 2.07391, 0.55865, 1.08131, 0.15004, 2.9959, 1.29169, 1.50527, 0.81436, -1.90697], 'IV2': [3.73935, 0.53802, 1.73509, 3.01428, 2.7058, 1.97086, 3.98669, 2.67305, 3.18234, 1.39142], 'IV3': [0.8255, 4.8461, 4.3388, 2.565, 5.6754, 5.4174, 7.666, -0.1009, 0.4374, 3.6268] } ) print(dfP) Y = dfP.iloc[:, 0] X = dfP.iloc[:, 1:] XS = StandardScaler().fit_transform(X) P, _, Q = np.linalg.svd(XS, full_matrices=False) Z = P @ Q ZS = StandardScaler().fit_transform(Z) Lambda = linalg.inv(ZS.T @ ZS) @ ZS.T @ XS dfZS = pd.DataFrame(ZS, columns=X.columns) dfXY = pd.concat([Y, dfZS], axis=1) ZS_columns = list(dfXY.iloc[:, 1:].columns) ZS2_columns = ' + '.join(str(i) for i in ZS_columns) formula = 'Y ~ {}'.format(ZS2_columns) mod = smf.glm(formula=formula, data=dfXY, family=sm.families.Binomial()).fit() print(mod.summary()) b = mod.params[1:] # **where there is a difference between R and Python** LpredY = mod.predict(dfP) print(LpredY) The only part that is not consistent with the output from R is the LpredY variable. Just need some assistance in figuring out the discrepancies.
