[site]: datascience
[post_id]: 63993
[parent_id]: 
[tags]: 
Detect blur image using ssdmobilenet and tensorflowlite

I have clear images of cards vs blurry images of card. My task is to capture photo when the image is not blurry, as you can see from the description I need this code to run in real time on android device. I have done some background reserarch on this topic 'Identify blurry image'. And found out few interesting solutions. Apply opencv transforms such as laplace or sobel filter. The blurry image will have less edges. And then using techniques such as SVM to find out which image has less edges Use other opencv transforms similar to sobel to get edges of images and then find image with less edges. Although these transforms produce good output. They are badly slow. I need something which has speed similar to tflite object detection using android. Taking this logic in my mind my obvious step was to annotate images 1500(blurred cards) vs 1500(non blurry cards) and retrain ssdmobilenet model using tensorflow object detection api. My dataset (clear) (blur) However when I exported the trained model to android I completely messy output, it appears as though the model has not learned anything from the data. My question is Is this problem solvable using object detection api as I mentioned above ? if yes where am I going wrong ? If no what are the fastest alternatives to detect blur in real time
