[site]: crossvalidated
[post_id]: 51189
[parent_id]: 
[tags]: 
Data whitening for improving regression

My Data: $X_i= \{0.4;~7;~1,000;0;~0.8;~1;~0;~40;~0.7;~1;~0;~89,100\},~Y_i=345$ The training set size is $\approx35, 000$. $Y$ is the dependent variable and the task is to estimate its value (regression). I normalized the $X$ data by scaling them and then applying a sigmoid function. I did the same with $Y$. I tried using a neural network with 3 layers: 1st input(neurons=number of features), 2nd - hidden=20 neurons, 3rd - output=1 neuron; each layer has sigmoid function), learning rate=0.9, momentum=0.5, I also tried using SVM(kernel="radial") and glm(family="gaussian") models, but nothing performed well. I applied a whitening procedure (to remove correlations) to $X,Y$ together as one matrix (by chance). And as the result the StdErr was less than 1%. So, the question is: in my test data I have only $X$ and usually whitening is applied only to $X$ (inputs). Is it possible to apply results from previous whitening to a new dataset (without known $Y$)? Why did I get so much improvement?
