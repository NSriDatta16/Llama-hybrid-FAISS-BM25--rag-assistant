[site]: crossvalidated
[post_id]: 585742
[parent_id]: 
[tags]: 
Guidelines for using NMS before calculating mAP for object detectors

I am having a hard time understanding how to use Non-Max Suppression (NMS) when trying to evaluate an object detection model, especially when paired with trying to calculate metrics like the mean Average Precision (mAP). For example, I trained an EfficientDet model to find and classify objects into three categories. Now I want to evaluate said model and calculate the mAP. I know there are different standards/meanings of mAP but regardless of the flavor of mAP , it seems like I first need to perform NMS to prune down overlapping detections of the same class. To do this, I have to provide the NMS process an IoU threshold (and in some cases you can also provide a score threshold at this step). How do I know if the IoU threshold picked at the NMS step is optimal without iterating on the IoU threshold twice, once for NMS and once for the mAP calculation? Should I set the score threshold at this step to 0? Moreover, the NMS process is used to prune away overlapping bounding boxes belonging to the same class, but I need to handle overlapping boxes from different classes right? Once again I need to make a decision for what constitutes too high of an IoU and I think keep the box whose score is highest. I could just use some guidance for how the evaluation process is meant to go.
