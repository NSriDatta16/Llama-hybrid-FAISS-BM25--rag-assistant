[site]: crossvalidated
[post_id]: 428256
[parent_id]: 428235
[tags]: 
The best approach, particularly with a Cox or logistic regression, is to use a multiple regression model that includes all relevant predictors . In Cox or logistic regression, in addition to the issue of correlations among predictors that concerns you, omitting a predictor related to outcome can lead to bias in estimates of the coefficients for the predictors you include, even if the omitted predictor is uncorrelated to the included predictors; see the answer by Harrell on the page linked above. So given the way that you have structured the analysis, your Model 4 is the most reliable way to start. That is, "intensity of task" is the only predictor significantly associated with outcome of the 3 you are considering (when other covariates are also taken into account). Your tests of multiple nested models is instructive, as in your case it pretty much replicated what you found with Model 4, but it wouldn't be considered the most reliable way to proceed in general. For example, what one tests with the standard R anova() function is whether the second predictor adds significant information about outcome after what was provided for by the first predictor has been accounted for. In cases with predictors that are less distinct in their relationships with outcome than your 3 seem to be, that might not work well and lead you to make a false-negative finding. Furthermore, as that multiple nested models process involves multiple tests on the same data you should be correcting for multiple comparisons , which would make it harder to find truly significant predictors. Note that there are other ways to perform analysis of variance that do not depend on the order of entry of predictors into the analysis; see this page for discussion of different types of ANOVA. For example, consider the anova() function that acts on objects created with the rms package . In your case without interactions and no multi-level categorical predictors the results would be those you got with Model 4, but in more complicated models that latter version of anova() gives more useful results that take all levels of a categorical predictor and interactions involving any predictor into account. Finally, it seems that you have taken a continuous measure of profitability and broken that apart into dichotomous measures of "success" or "failure." Binning continuous predictors is generally a bad idea . So although your model to this point seems to rule out predictors other than "intensity of task" as significant, I wonder whether having continuous measures of "success" and "failure" probabilities might yet show them also to have significant relationships with outcome. My answer does not address the issue of your use of time-varying covariates, mentioned in the title but not discussed within the question itself. Note that some types of time-varying covariates can lead to misleading conclusions related to survivorship bias . Be very careful with time-varying covariates.
