[site]: datascience
[post_id]: 24584
[parent_id]: 24579
[tags]: 
I suspect the problem is the fact that your input data values are very high. You're trying to map the input variable $x \in (0,100)$ to $y = x+1$ in your code, but neural networks work best when the data has much lower values. A good strategy is to normalise the data before training so that each feature has zero mean and unit variance. Try scaling your data down like so (I've also changed the code that originally generates the inputs to make it more efficient in numpy): # Instantiating Neural Network x = np.random.randint(0, 100, size=100).reshape(100,1) y = x + 1 # normalize data to have zero mean and unit variance x_normalized = (x - x.mean()) / x.std() y_normalized = (y - y.mean()) / y.std() Train your network with x_normalized and y_normalized instead of x and y . Then, during testing, you normalize your input data like above, and you can scale your predictions back up to the original scale by rearranging the above formula. # generate test data & normalize using train data mean&std test = np.random.randint(0, 100, size=100).reshape(100,1) test_x_normalized = (test - x.mean()) / x.std() # input to network to get normalized outputs test_y_normalized = NN.forward(test_x_normalized) # rescale normalized outputs to original 0-100 scale test_y = (test_y_normalized * y.std()) + y.mean() print("TEST INPUT:", test, sep = '\n', end = '\n\n') print(test_y, end = '\n\n')
