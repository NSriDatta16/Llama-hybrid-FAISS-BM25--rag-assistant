[site]: crossvalidated
[post_id]: 468756
[parent_id]: 
[tags]: 
Why do R and SPSS give different SEs (complex survey with weights)?

My colleague and I are working with complex survey data (i.e., with weights). He is doing the analysis in SPSS, and I am trying to double-check his work, but I use R. We have a binary explanatory variable and a binary outcome, and we'd like to estimate the association (odds ratio, OR), using logistic regression. Eventually we will do multivariable analysis, but we are first trouble-shooting univariate results (1 binary explanatory variable). We've noticed that the point estimates (coefficients and ORs, i.e., exp(beta)) from the two softwares are identical, but standard errors (SE) and confidence intervals differ. For example, using the same variable definitions, he gets the following logistic regression OR and CI, using SPSS: 1.885 (1.611 â€“ 2.206) B=0.634, SE=0.080 [full SPSS outputs included at bottom of this post] And I get, using R (svyglm): 1.885457 (1.407309 - 2.52606) B=0.63417, SE=0.14923 [full R outputs included at bottom of this post] In other words, the SEs and CIs in SPSS are larger than those estimate in R. Any ideas why this is the case? We're wondering if we've made an error or if the softwares actually calculate the SEs in different ways. Thank you for any help! SPSS syntax: WEIGHT BY New_Weight. DATASET ACTIVATE DataSet1. SAVE OUTFILE= '/Users/jd/datafilec3.sav' /COMPRESSED. LOGISTIC REGRESSION VARIABLES SRMH /METHOD=ENTER sexual_orientation /CONTRAST (sexual_orientation)=Indicator(1) /PRINT=CI(95) /CRITERIA=PIN(0.05) POUT(0.10) ITERATE(20) CUT(0.5). SPSS outputs: R syntax: > summary(svyglm(srmh.r ~ as.factor(so.r), design=joshunsvy, family=binomial)) R outputs: Call: svyglm(formula = srmh.r ~ as.factor(so.r), design = joshunsvy, family = binomial) Survey design: svydesign(id = ~1, weights = ~WTS_M, data = joshun) Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -2.75422 0.02257 -122.06
