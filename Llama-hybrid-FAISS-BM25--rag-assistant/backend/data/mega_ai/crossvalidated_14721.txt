[site]: crossvalidated
[post_id]: 14721
[parent_id]: 
[tags]: 
How is the bayesian framework better in interpretation when we usually use uninformative or subjective priors?

It is often argued that the bayesian framework has a big advantage in interpretation (over frequentist), because it computes the probability of a parameter given the data - $p(\theta|x)$ instead of $p(x|\theta)$ as in the frequentist framework. So far so good. But, the whole equation it is based on: $p(\theta|x) = {p(x|\theta) . p(\theta) \over p(x)}$ looks to me little suspicious for 2 reasons: In many papers, usualy uninformative priors (uniform distributions) are used and then just $p(\theta|x) = p(x|\theta)$, so bayesians get the same result as frequentists get - so how is then bayesian framework better in interpretation, when bayesian posterior and frequentists likelihood are the same distributions? It just yields the same result. When using informative priors, you get different results, but the bayesian is affected by the subjective prior, so the whole $p(\theta|x)$ has the subjective tinge too. In other words, the whole argument of $p(\theta|x)$ being better in interpretation than $p(x|\theta)$ builds on a presumption that $p(\theta)$ is kind of "real", which normally is not, it is just a starting point we somehow choose to make the MCMC run, a presumption, but it is not a description of reality (it can't be defined I think). So how can we argue that bayesian is better in interpretation?
