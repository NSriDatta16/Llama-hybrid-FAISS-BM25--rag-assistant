[site]: crossvalidated
[post_id]: 437238
[parent_id]: 436519
[tags]: 
To properly answer your question regarding automatic model differences requires a little bit of history https://autobox.com/pdfs/econometrics.pdf to explain some different approaches to ARIMA model identification. Model identification has and always will be an iterative process much like peeling an onion where clues are found and followed and possibly discarded culminating in a possibly useful model . Box and Jenkins in 1968 suggested this approach and https://autobox.com/pdfs/ARIMA%20FLOW%20CHART.pdf reflects a modification/update of this where additional/possible model complexity is found out in an exploratory mode . Think of the EDA approach of J. Tukey but in a time series context. My first attempt in my disseration topic in 1968 was to do a one pass brute-force approach of trying a family of possible models to determine the best model via minimizing the error variance. In this regard Auto.arima was based upon an early piece of my software called AUTOBJ (which is the forerunner of AUTOBOX which I have helped to develop) while using a relative of the error variance the AIC to suggest the "best model". Neil Polhemus , a friend of mine , the founder of Statgraphics was also aware of AUTOBJ and decided to use what was then a promising model identification tool call the Extended Autocorrelation (EACF or ECF With regard to ARMA time series, what exactly is eacf (extended auto-correlation function)? ) as the basis for his approach. The EACF failed to detect either latent deterministic structure of the need for error variance remedies and is no longer a tool of choice. What you have are two different approaches ( two pieces of software) to model identification , neither of which deal with the effect of possible latent deterministic structure (like level/step shifts or local time trends) and complications dealing with error variance structure (like power transforms or GLS). Visually and analytically your selected time series has error variance issues (higher variability at higher levels) and a level shift. A simple ar(1) model in a log transform yields one possible pulse. Neither of your selected tools of choice deal with this opportunity space. The residuals from the model I suggest are free of structure. A series can be non-stationary in the mean. There are (at least) two different ways to remedy this .. 1) to difference ... 2) to Demean ie. adjust for one or more level/step shifts or local time trends . In closing your series ( although monthly) exhibits no provable seasonality. Incorporating unwarranted seasonal differencing INJECTS structure which needs a counter-balancing seasonal component to provide a remedy. I developed a useful model ( 1 level shift needed to deal with non-stationarity (period 58) and a simple ar(1) component ) here with Gaussian Noise (here) which provided the following Actual & forecast graph here with wide limits due to the need for a log transform (N.B. how the error variance is smaller at lower levels of the original series ) . These forecasts look nothing like any of your three candidate models. Also note that there is no seasonality in the original data , the model and the errors from the model . Tools that assume seasonal structure ..thus injecting seasonality into the residuals and then incorporating seasonal structure to counter-balance that had been erroneously injected should be critically examined. The appropriate model is approximately a random-walk (.956 is nearly 1.0 ) with a positive drift (1.48) in logarithms.
