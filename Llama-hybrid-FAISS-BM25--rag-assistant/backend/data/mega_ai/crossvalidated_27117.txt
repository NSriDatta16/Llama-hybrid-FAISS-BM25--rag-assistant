[site]: crossvalidated
[post_id]: 27117
[parent_id]: 27050
[tags]: 
I don't understand why you have two $\lambda$ values. In all the logistic regression I've encountered, there is only one $\lambda$ value, and you try different values of $\lambda$ to minimize the cost $J$. I also took the machine learning class you reference, and my Octave code looked like this. J = 1/m * sum(-y' * log(sigmoid(X*theta)) - (1-y)'*log(1-sigmoid(X*theta))); J += lambda/(2*m) * sum(theta(2:theta_len,:).^2); Note that lambda should be a scalar value in this implementation. This is the math equivalent of the above Octave statement. $J(\theta) = \frac{1}{m}\sum\limits_{i=1}^m[y^{(i)}log(h_{\theta}(x^{(i)})) - (1-y^{(i)})log(1-h_{\theta}(x^{(i)}))] + \frac{\lambda}{2m}\sum\limits_{j=1}^n\theta^{2}_{j}$
