[site]: crossvalidated
[post_id]: 411562
[parent_id]: 
[tags]: 
AdaBoost learning rate calculation

I saw the following in a Random Forrest calculation. My understanding of logarithms is not intuitive, I always have to look them up. It was asked: Calculate this decision tree’s weight in the ensemble the weight of this tree = learning rate * log( (1 — e) / e) It was in middle of an Adaboost tutorial. My question is why is this equation with the log chosen? What special properties does it have that makes a good constant for the learning rate? Basic Ensemble Learning (Random Forest, AdaBoost, Gradient Boosting)- Step by Step Explained Under the section Adaboost.
