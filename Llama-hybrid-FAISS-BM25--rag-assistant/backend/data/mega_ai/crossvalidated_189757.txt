[site]: crossvalidated
[post_id]: 189757
[parent_id]: 
[tags]: 
The variety of problems with Cox's Theorem

So I've been trying to understand Cox's Theorem and the problems surrounding it. There's so much information on this topic that I've become confused as to the exact state of the theorem. I've gathered there are three main issues, and I'll just ask my questions as I move along. My main references are K. Van Horn, A Guide to Cox's Theorem, 2003 and A. Terenin & D. Draper, Rigorizing and Extending the Cox-Jaynes Derivation of Probability, 2015 . The assumption that a plausibility of A given B can always be represented by a real number. This assumes universal comparability between propositions, which some find unwarranted. I know Jaynes (Probability Theory as Extended Logic, 2003, Appendix A) argues for universal comparability, though I'm not entirely sure that his argument is sufficient. The second issue with this assumption is that representing belief in proposition $(A|B)$ as a real number, says nothing about our doubt of $(A|B)$; $(\neg A|B)$. This objection is often raised in the context of belief-function theory (which I'm not really familiar with) (G. Shafer, A Mathematical Theory of Evidence, 1976) . Cox later postulates that a function $S$ exists such that $(\neg A|B) = S(A|B)$, which seems to show that we can express doubt in terms of belief. For that reason, I don't really understand the objection. Next, the objection is raised that one-dimensional representations of plausibility can't adequately represent ignorance. Jaynes seems to deal with this using maximum entropy methods (Information Theory and Statistical Mechanics I & II, 1957) and prior transformation groups (Prior Transformations, 1968) . From what I gathered this solution is not considered sufficient by many. Are there any specific objections? Finally, Van Horn mentions: Another motivation for two-dimensional theories has been the perception that proper application of Bayesian methods requires knowledge of the ‘‘true’’ probabilities, which are viewed as physical properties. This can lead to theories in which one represents uncertainty as a convex set of probability distributions [20]. Jaynes dismisses such concerns about ‘‘true,’’ physical probabilities as examples of the ‘‘Mind Projection Fallacy’’ [21], yet even the Jaynesian viewpoint admits certain states of information that are mathematically equivalent to being uncertain about some ‘‘physical’’ probability. Bayesians deal with uncertain ‘‘physical’’ probabilities by reasoning about the probabilities of various physical probability values. This brings us back to the previous concern, representation of ignorance, and hence this second motivation for considering a two-dimensional theory reduces to the first. [20] : H.E. Kyburg, Bayesian and Non-Bayesian Evidential Updating, 1985 [21] : E.T. Jaynes, Probability Theory as Logic, 1989 I'm not entirely sure why knowledge of ``true'' probabilities is necessary for proper application of Bayesian methods. Is this just the matter of devising a proper prior? Halpern (A Counterexample to Theorems of Cox and Fine, 1999; Revisiting Cox's Theorem, 1999) has claimed to have constructed a counterexample to Cox's Theorem. Snow (The Reasonableness of Possibility from the Perspective of Cox, 2001) disagrees, saying that Cox implicitly made an assumption that negates the counterexample. Paris (The Uncertain Reasoner's Companion, 1994) seems to formalise this assumption, but the consequence is that the Cox-Jaynes probability function cannot have a finite domain. Halpern considers this problematic, since it may not be natural to postulate an infinite proposition space. Snow and Van Horn each have their own arguments against Halpern's objection. Van Horn (A Guide to Cox's Theorem, 2003, p.12-13) remarks that even if we restrict ourselves to a finite number of propositions $(A|B)$, there can still be an infinite number of plausibility values if we don't restrict ourselves to a finite number of information states for that domain. Snow (On the Correctness and Reasonableness of Cox's Theorem for Finite Domains, 1998, section 4) gives examples of situations where an infinite domain is required to give sensible answers. Terenin & Draper (Rigorizing and Extending the Cox-Jaynes Derivation of Probability, 2015, p.8) claim Van Horn's approach is difficult to evaluate formally since it lacks rigor. They do however, remark that: Jaynes (2003) makes an important distinction between expressions of information that are ontological (e.g., ''there is noise in the room") describing the world as it is and those that are epistemological (e.g., ''the room is noisy") describing Your information about the world. There is no contradiction in assuming a finite number of world states (ontology), which is certainly true in some problems, and using an uncountably infinite number of propositions to describe Your uncertainty about those world states (epistemology); the latter is a modeling choice that we (and many other Bayesian statisticians) and to be extremely useful. Which seems to in spirit agree with Van Horn, if I'm interpreting everything correctly. I haven't seen anyone claim fault in Snow's position, though Jaynes (2003) notes: It is very important to note that our Consistency Theorems have been established only for probabilities assigned on finite sets of propositions. In principle, every problem must start with such finite-set probabilities; extension to [countably] infinite sets is permitted only when this is the result of a well-defined and well-behaved limiting process from a finite set. Which I'm not sure contradicts Snow, but at least questions the naturalness of infinite domains yet again. S. Arnborg and G. Sjödin (Bayes Rules in Finite Models, 2000) show that Paris' assumption is not necessary to justify the theorem. They replace his assumption with weaker ones, and prove Cox' Theorem for finite domains. However, their method does not work for infinite domains, which seems somewhat problematic considering Snow's claim that infiniteness of the domain is natural. Finally, Terenin and Draper claim to formalise Cox-Jaynes for uncountably infinite domains (2015, p.7), though I'm not sure whether this means infinite propositions, or just infinite plausibilities (in the information state sense of Van Horn, the epistemological sense of Jaynes, and/or the reasonable results sense of Snow). In short, there seems to be a lot of disagreement here. It might be that I am misinterpreting statements though, so I would like for someone more knowledgeable to confirm. Lastly, there seems to be a problem with countable additivity, which only Terenin and Draper mention. Indeed, it seems most of their motivation is to add countable additivity to the Cox-Jaynes approach. I don't quite understand why countable additivity is necessary (though I suppose it may have something to do with wanting the domain to be (un)countably infinite as previously seen). To summarise: Is Jaynes' argument for universal comparability considered sufficient? What is the problem with one-dimensional theory not saying anything about doubt? What are the problems with Jaynes' argument for objective priors and representing ignorance? What is the trouble concerning Jaynes' argument about the Mind Projection Fallacy? Is there a concensus regarding the finite-/(un)countably-infinite-ness of the domains in the Cox-Jaynes approach? If not, what are the exact problems? What is the deal with countable additivity in the Cox-Jaynes approach?
