[site]: datascience
[post_id]: 33368
[parent_id]: 
[tags]: 
Unintuitive results when Expanding Binary Classification to Multiclass

I have aproblem where I need to predict when a Truck arrives to pickup something. Say we have formulated that a binary classification model, where 0: The truck coming for pickup today 1:The truck comes for pickup sometime in the future after today. Next, it was decided to expand the 2 class problem to a three class one, as follows: 0: The truck coming for pickup today, 1: The truck comes for pickup tomorrow 3: The Truck comes for pickup sometime in the future after tomorrow. So, the 0-class remains as it is. A Random Forest (ranger in R) model was applied in both situations and the results compared. SInce the 0-class remains as is, we would expect the number of 0-predictions to be close from both models. But that is not the case: there is about a 30% difference in the number of 0-class predictions in the two models, which I find unintuitive. Is this behavior not really as unintuitive or is somethign wrong?
