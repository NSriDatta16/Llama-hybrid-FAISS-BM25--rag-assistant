[site]: crossvalidated
[post_id]: 429250
[parent_id]: 
[tags]: 
Why is having low variance important in offline policy evaluation of reinforcement learning?

Intuitively, I understand that having an unbiased estimate of a policy is important because being biased just means that our estimate is distant from the truth value. However, I don't understand clearly why having lower variance is important. Is that because, in offline policy evaluation, we can have only 'one' estimate with a stream of data, we don't know if it is because of variance or bias when our estimate is far from the truth value? Basically, variance acts like bias. Also, if that is the case, why having variance is preferable to having bias? Thank you in advance!
