[site]: datascience
[post_id]: 81727
[parent_id]: 
[tags]: 
What would be the target input for Transformer Decoder during test phase?

The Transformer Decoder takes in two inputs, the encoder's output, and the target sequence. How the target is fed into the decoder has been provided in this answer I am having confusion about what the target sequence will be when the trained model is evaluated?. Is it that we start with a tag for the first timestep and loop through the transformer decoder for each timestep like in RNN's? It would be helpful if someone can clarify this for me.
