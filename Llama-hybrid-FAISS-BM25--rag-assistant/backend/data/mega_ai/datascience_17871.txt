[site]: datascience
[post_id]: 17871
[parent_id]: 
[tags]: 
Injecting random values as one input feature for feature selection results in a odd beaviour

I am trying to find a cutoff value, in the feature importance space to eliminate spurious features. So I am injecting a completely random generated feature (as one of the input features) and I cut the features that are scoring below the value of the random feature in the importance ranking. But once I removed the features, the performance drop. I don't understand what is happening. I checked this behavior in a gradient boost and in a random forest. Someone has a clue of what is happening?
