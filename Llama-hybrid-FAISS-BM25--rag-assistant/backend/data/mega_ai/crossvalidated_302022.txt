[site]: crossvalidated
[post_id]: 302022
[parent_id]: 301968
[tags]: 
That is because in the first example of digit recognition , they do not use the CNN structure. Rather, they use the simple MLP with one hidden layer with the below code. def baseline_model(): # create model model = Sequential() model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu')) model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax')) # Compile model model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) return model As a result, MLP with 784-784-10 nodes are created. When using the CNN structure in the following example, they reshape the X data into (n, 28, 28, 1). # load data (X_train, y_train), (X_test, y_test) = mnist.load_data() # reshape to be [samples][pixels][width][height] X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32') X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32') In short, as there are two examples using different model structures in digit recognition example, two data shapes are employed as a result. In general, it could be said that 1D-shaped flattened data are used as inputs for fully-connected layers (e.g., MLPs) and 2D-shaped rectangular data are used for convolutional and pooling layers.
