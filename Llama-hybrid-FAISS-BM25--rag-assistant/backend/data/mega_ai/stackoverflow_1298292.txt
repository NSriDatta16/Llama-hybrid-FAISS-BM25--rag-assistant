[site]: stackoverflow
[post_id]: 1298292
[parent_id]: 1160720
[tags]: 
My company have been logging some structured traffic info straight into a MySQL log database. This database is replicated downstream to another database. All analytics run off the final database replication. Our site sustain quite a bit of traffic. So far, it doesn't seem to have any major problems. However, our IT department have some growing concerns regarding to the scalability of the current setup and is suggesting that we offload the log info onto "proper" log-files. The log-files will then be reinserted back into the same downstream database tables. Which brings me to this question. :) Here are some of pros and cons that I see regarding to the subject of log-files vs log-db (relational): log-files are fast, reliable, and scalable (At least I have heard Yahoo! makes heavy uses of log files for their click tracking analytics). log-files are easy for sys-admin to maintain. log-files can be very flexible since you can write almost anything to it. log-files requires heavy parsing and potentially a map-reduced type of setup for data-extraction. log-db structures are a lot closer to your application, making some feature's turn around time a lot shorter. This can be a blessing or a curse. Probably a curse in the long run since you'll most likely end up with a highly coupled application and analytic code base. log-db can reduce logging noises and redundancies since log-files are insert only where as log-db gives you the ability to do update and associated-insert (normalization if you dare). log-db can be fast and scalable too if you go with database partitioning and/or multi-log databases (rejoin data via downstream replications) I think some stress tests on the log database are needed in my situation. This way at least I know how much headroom I have. Recently, I've been looking into some key-value / document-based databases like Redis, Tokyo Cabinet, and MongoDB. These fast inserting databases can potentially be the sweet spot since they provide persistence, high (write) throughputs, and querying capabilities to varying degrees. They can make the data-extraction process much simpler than parsing and map-reducing through gigs of log files. In the long run, I believe it is crucial to have a robust analytics data warehouse. Freeing application data from analytic data and vice versa can be a big WIN. Lastly, I would just like to point out there are many similar / closely related questions here on StackOverflow in case you want to broaden your discussion. Storage of many log files Is writing server log files to a database a good idea? Using a SQL Server for application logging. Pros/Cons? Fast Search in Logs Separate production database for logging You Log to Your DB, Where Do You Log When Your DB is Down? Edit: rsyslog looks very interesting. It gives you the ability to write directly to MySQL. If you are using Ruby, you should have a look at the logging gem. It provides multi-target logging capabilities. It's really nice.
