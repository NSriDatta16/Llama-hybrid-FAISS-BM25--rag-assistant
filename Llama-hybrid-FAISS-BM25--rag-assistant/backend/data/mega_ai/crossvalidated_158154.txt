[site]: crossvalidated
[post_id]: 158154
[parent_id]: 158149
[tags]: 
Hope this helps: Single output node in theoretical concept is possible, as long as you know what is the CUTOFF of the value. For example, let say you want to use 1-layer ANN to build a logic gate , you can use different set of weights to construct an AND gate, and OR gate. And there is only one output node in each ANN (like the dog example you give). Here it's the OR gate (h(X) is a sigmoid function, which introduce non-linearity to the neural network. The non-linearity is important because that how makes you question 3 possible---using three layers to solve non-linear classification problem): Here it's the AND gate: IMPORTANT!: Usually now what people do in neural network is that they introduce a softamx layer (i.e., logistic regression) in the LAST layer of neural network. Why this is done because let's say you want to have classify 4 animals (cow, cat, dog, chicken), you use softmax last layer and you can OBTAIN 4 PROBABILITIES for being cow, cat, dog, or chicken. Then ANN will calssify your input based on the HIGHEST probability. For example, given your input, the output probabilities are: cow--0.1, cat--0.1,dog--0.1, chicken--0.7. thus, the ANN will classify your input image as chicken. Let's consider the network in the figure below. It is a ANN with k-layers, as defined as L1,L2,...Lk. The input layer is the first layer, i.e., L1, and the output layer is Lk (we want to classify red dot or blue plus). When you do backpropagation, your delta(error) will be calculated in layer Lk, and it is propagate back to previous layers (started from L(k-1) back to L1). So, the weights, W(1)...,W(k1-1), can be updated. Therefore, in fact, ALL your weights are updated in this case. In your question, you are saying the weight, W(1), will not be updated, right? I have not seen this before. Can you provide a link where you see it and I can try to explain to you. The claim is a big claim :). People have proven that using 1 hidden-layer can make the ANN to do a non-linear classifier, such as making an XNOR gate. That is, using 3 layers (input, hidden, output) can solve both linear and non-linear problem. But that does not mean "using only 3 layers" can solve all the non-linear problems. The current research finding is: to solve difficult classification problem, such as classifying 1000 objects, you need to use DEEP arhitecture. That is, using more than 1 hidden layer (sometime can be more than 10) to build a deep neural network to do classification. I hope my answer can give you some insight. You questions cover a board range of concepts in ANN. And it is difficult to explain all here. Please do not hesitate to let me know if you have any questions, and I will try to respond when I see them. :) Good luck.
