[site]: crossvalidated
[post_id]: 151395
[parent_id]: 
[tags]: 
Question regarding form of a cost function while training a model

I am beginner in Machine Learning and I am very interested in modelling, simulation and all this jazz :) One of the basic idea I learned so far is the use Cost Function and its minimization in order to train models based on existing data. In my understanding, Cost Function of any form provides an error measure between real and simulated data and, at particular stage of training, how accurate a model is. I have come across a formula: $$J(\Theta)=\frac{1}{2}\sum_{m=1}^n\big(y^{(i)}-\Theta^{\text{T}}x^{(i)}\big)^2$$ I believe the expression squared inside brackets is expression of an error. I was always asking myself why we tend to use the error squared. How about applying absolute value or power to 4, etc. I found an explanation based on probabilistic interpretation which describes error to be normally distributed with mean 0. It's fine to understand it but from this point onward authors usually skip the in-between process and tend to give the final result. So basically I still haven't fully understood it :/ I found that if we assume that error is normally distributed, that is $$\varepsilon^{(i)} \sim \mathcal{N}(0,\sigma^2)$$ its probability is expressed by Gaussian Distribution: $$\text{P}(\varepsilon^{(i)})=\frac{1}{\sqrt{2\pi}\sigma}\exp{\Bigg(-\frac{\big(\varepsilon^{(i)}\big)^2}{2\sigma^2}\Bigg)}$$ Now, how is it related to the cost function? I was digging more and found out that data are also expressed by normal distribution? Is it because of the assumption of error being normally distributed ? I also found an equation below, where $y^{(i)}$ denotes real data and $\Theta^{\text{T}}x^{(i)}$ is a hypothesis. I believe models are fitted based on data and given hypothesis--here linear equation. The model's features are denoted by $x$ whereas parameters by $\Theta$: $$y^{(i)}|x^{(i)};\Theta \sim \mathcal{N}(\Theta^{\text{T}}x, \sigma^2)$$ It is then followed by equation: $$\text{P}(y^{(i)}|x^{(i)};\Theta)=\frac{1}{\sqrt{2\pi}\sigma}\exp{\Bigg(-\frac{\big(y^{(i)}-\Theta^{\text{T}}x^{(i)}\big)^2}{2\sigma^2}\Bigg)}$$ I can see the term $(y^{(i)}-\Theta^{\text{T}}x^{(i)})$ which is the same in Cost Function and the equation above. So reassuming, does the normal distribution of error incline the normal distribution of data and therefore the use of aforementioned form of the Cost Function ? If error was not normally distributed, would that form of Cost Function be wrong?
