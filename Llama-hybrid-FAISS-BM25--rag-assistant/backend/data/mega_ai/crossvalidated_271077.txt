[site]: crossvalidated
[post_id]: 271077
[parent_id]: 
[tags]: 
From unevenly spaced values, a normal distribution that sums to the mean

I have input data that is $N$ items and each has several properties, one of which is called, say, $P$. Their values of $P$ are unevenly spaced between 0 and 1, and may even repeat between items. For example, suppose $N=8$ and the list of values for $P$ looks like this: $$[0.1, 0.2, 0.2, 0.3, 0.4, 0.5, 0.8, 0.9]$$ (Recall, even though 0.2 appears twice in that list, they correspond to different items that differ in other properties). From these items, I want to draw $M$ samples, and $M >> N$ so naturally there will be repeated draws of the same item. Let's say $M=100$. But, crucially, I want the distribution of $P$ among the drawn samples $M$ to be approximately normal, having a specific target mean $\mu_P$ and standard deviation $\sigma_P$ value. To again pick a specific example, let's say I want $\mu_P = 0.33$ and $\sigma_P = 0.2$. Keep in mind that these are my targeted values of $\mu$ and $\sigma$, they are NOT the natural mean and stdev of the original list of values $P$. Here's what I've figured out so far: In the simpler case where the values of $P$ are spaced out evenly between 0 and 1 with no repeat values, this would be relatively straightforward. I would compute the Gaussian equation with $\mu = 0.33$ and $\sigma = 0.2$ for each value of $P$. Then, since $P$ spans a finite range and $\mu$ is not in the dead center of it, I would also need to cut off any $P$ values above $\mu+(\mu-P_{min})$, or 0.66 in this case - otherwise, the higher the $\sigma$, the higher the error that would be introduced by drawing from the extreme right-tail values when there are no correspondingly extreme left-tail values to draw from. (If $\mu$ were instead in the upper half of the range of $P$, I would do the same cutoff on the left tail instead). Then I would normalize the resulting values so that they sum to 100, and draw that many times from each. In other words, the number of times $m$ to draw item $i$ would be: $$g_i = (e^{-(P_i-\mu_P)^2/2\sigma_P^2} )/ \sqrt{2\pi\sigma_P^2}$$ $$g_i(P_i>0.66) = 0$$ $$m_i = 100\frac{g_i}{\sum{g_i}}$$ Obviously we will have to round these to integers and so we won't hit our target $\mu$ exactly, but the higher the number of draws $M$ gets, the closer we'll get. That's fine. Again, that all works (I've tested it in Python) if they were spaced out evenly in $P$ and there were no repeats. If we add repeated $P$ values into the mix, it's not so hard: for item $i$, if its value of $P_i$ repeats twice, I just divide each one's number-of-times-to-draw $m_i$ by 2 so that that value of $P$ doesn't get oversampled. But what if it's not quite an exact repeat but rather two very very close values, or in general, what if $P$ is not evenly spaced? Or what if there is both uneven spacing and repeat values, as in the very first example list of $P$ values I gave? I'm trying to come up with a more universal solution, and not sure where to go. I am doing this in Python, so if a solution isn't particularly elegant or analytical, that's okay (i.e. numerical/programming approaches are okay). Any tips would be appreciated! Feel free to point me to further reading, I searched quite a bit to no avail but I may be using the wrong search terms. Edit: This is different from flagged possible duplicate " How to simulate data that satisfy specific constraints such as having specific mean and standard deviation? ." While I found that question a very interesting read, unless I'm misunderstanding it, it seems that that question is focused on generating new, simulated data that matches a certain constraint of $\mu$ and $\sigma$. In my case here, I am stuck with my $N$ items and their corresponding $P$ values. They are real items and I can't make new ones up, nor can I change the value of their property $P$. From these items, I need to determine how many times to pick each item $i$ such that my final dataset, in aggregate, has (close to) the desired $\mu$ and $\sigma$. Edit2: Commenter @whuber has asked for more information on the problem I'm trying to solve. The problem I am trying to solve is this: I have a set of $N$ blocks of simulated material (which in my post I generically called "items"). Each block has various properties that I can measure - thermal conductivity, electrical conductivity, porosity, etc. I specified bounds of 0 to 1 for simplicity in this example, but the span could be different - either way there is a finite span. I want to choose some number $M>>N$ of these blocks (and I'm allowed to pick the same one more than once) such that taken in aggregate, their porosity averages out to appx. some value $\mu$, but among the blocks' various values of porosity there is approximately a standard deviation of $\sigma$.
