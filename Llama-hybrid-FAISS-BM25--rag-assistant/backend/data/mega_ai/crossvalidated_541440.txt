[site]: crossvalidated
[post_id]: 541440
[parent_id]: 
[tags]: 
Conceptual question - is it correct to use categorical variables such as day, month, year as a fixed sequence input in LSTM?

I am working on a problem where I have to try to predict the dependent variable (continuous) every hour based on hourly temperature (the single continuous variable in predictor space), along with 4 categorical variables, i.e., an hour of the day, day of the week, month, and year (as shown below). I am planning to encode the categorical variables as embeddings. |Dependent variable|Temperature|hour|day|month|year| |--|--|--|--|--|--| |15.6|30|0|20|March|1994| |23.7|11|1|6|April|1992| . . . and so on My question is, in an LSTM model, creating fixed-length sequences of temperature (my continuous variable) makes sense, but I don't find it convincing to create the fixed length of days, months, or years to feed in the LSTM cell. After all, when I create embeddings to represent the categorical variables of constant size vectors, in a fixed-length of 4, the day, month, and the year categorical features and hence the embeddings will be the same. So how does it contribute towards model learning? Is it correct to create sequences of date and time based categorical data?
