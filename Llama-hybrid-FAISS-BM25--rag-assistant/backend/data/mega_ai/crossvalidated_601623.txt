[site]: crossvalidated
[post_id]: 601623
[parent_id]: 
[tags]: 
What is the reason of setting a gap between the end of the train set and the beginning of the test set?

When splitting train/test data sets there is an option to set a gap between them. For example, given a series of 100 days, we can split as follows: train = 80, gap = 1, test = 19. In the materials I'm learning, however, there isn't a clear explanation why to do or not to do so, and how to determine the gap length. I can guess that leaving a gap may be helpful in addressing overfitting, but would appreciate if you can point me to a reference. EDIT: For further clarification, I'm working with time series data cross-validation. For example, this gap setting can be found in sklearn.model_selection.TimeSeriesSplit . According to the user's guide : sklearn.model_selection.TimeSeriesSplit(n_splits=5, *, max_train_size=None, test_size=None, gap=0) in which gap is the number of samples to exclude from the end of each train set before the test set.
