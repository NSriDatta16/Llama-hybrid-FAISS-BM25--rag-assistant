[site]: crossvalidated
[post_id]: 555048
[parent_id]: 554853
[tags]: 
I would do the following: Pick a logistic regression Run your model and return the coefficients for each feature Transform the coefficients using: exp(beta) = transformed coefficient value (you need to do this because you have a underlying logit assumption) Sort your transformed coefficients If you have not normalized your features before, then you need to multiply the coefficient with its standard deviation Now to get comparable results for the different classes you would need to normalize the coefficients (or coefficients * std. dev.) by dividing by the class priors (so by the share of the classes--> by .5 if you have two equally big classes). This gives you a table of how important the features are in relation to the different classes you have in your data set. The next steps can be done if you also want to try to optimize your model performance: 7) Remove all features with a pvalue > .1 8) This is optional and might not always be a good idea, but you could: From significant features remove least important features step by step and observe impact on your prediction accuracy (better to use something like ROC AUC) 9) You want as few features as possible with the best possible performance 10) To get features importance for your reduced set of features go through step (2) to (6)
