[site]: datascience
[post_id]: 19348
[parent_id]: 
[tags]: 
Creating a dataset for benchmarking of timeseries preprocessing capabilities

I have been tasked with comparing the capabilities of different startups offering AI-assisted data preprocessing. Due to legal reasons I cannot offer company data for the benchmarking, not even simulated using the same structures and patterns, which means that I either create a dataset with not-company-related simulated data myself or find one on the internet. To clarify things, by data I mean timeseries. Some simple examples of what I would expect: centering/aligning the timeseries using e.g. cross-correlation, denoising them, finding out correlations, outlier detection, etc. Are there any (free) datasets designed to be hard to preprocess the data? I could not find any adequate. If not, what is the best way of constructing an own challenging, simulated dataset for this purpose? The purpose of the preprocessing step is to clean the timeseries data before it is fed into a neural network in order to be classified and tagged.
