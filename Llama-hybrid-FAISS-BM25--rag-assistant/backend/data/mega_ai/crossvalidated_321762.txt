[site]: crossvalidated
[post_id]: 321762
[parent_id]: 
[tags]: 
When do MAP inference and full Bayesian Inference give the same solution and why?

I'm struggling to grasp some concepts regarding bayesian learning theory. As I understand it one can classify a dataset by finding a posterior distribution and simply selecting a $w$ in $f(x) = w^TX$ that maximises the density of the posterior distribution. I believe that I read somewhere that this gives the same solution as Full Bayesian inference in the case of Gaussian Process regression but not necessarily in general. Why is this the case? Why might this relation not hold true except in the case of GP regression? Thanks.
