[site]: crossvalidated
[post_id]: 350445
[parent_id]: 
[tags]: 
Binary logistic regression: Interpreting odds ratio vs. comparing predictive probabilities

Consider the following logistic regression: set.seed(1839) n Which produces: Estimate Std. Error z value Pr(>|z|) (Intercept) -1.172720 0.2244242 -5.225463 1.737202e-07 x 2.490961 0.3421728 7.279833 3.342331e-13 During my time in academia, I would report this as an OR of 12.07 (because exp(coef(mod)[[2]]) ) and say that "people with an x score of 1 are 12 times as likely then people with an x score of 0 to have a positive outcome on y" (where we assume that 1 is a positive outcome for y). Now that I'm in industry and working with clients more, people like to see raw percentage point increases. Which we can approximate from comparing the predicted values for people where x = 0 and x = 1: > inv_logit(coef(mod)[[1]]) [1] 0.2363636 > inv_logit(sum(coef(mod))) [1] 0.7888889 So we could show predicted probabilities (usually shown as percentages for ease to the reader) as 78.9% when x = 1 and 23.6% when x = 0. This is a difference of 55.3 percentage points. However, when we take those two predicted probabilities and divide them by one another, we don't get "12 times as likely." Instead, we get: > inv_logit(sum(coef(mod))) / inv_logit(coef(mod)[[1]]) [1] 3.337607 Which is 3.34 times, not 12.07. Now, I know that what I'm doing is: $p(y = 1 | x = 1) \over p(y = 1 | x = 0)$ Whereas the odds ratio is doing: $p(y = 1 | x = 1) \over 1 - p(y = 1 | x = 1)$ Which aren't the same, because inv_logit(coef(mod)[[1]]) + inv_logit(sum(coef(mod))) is greater than 1 (as it usually is). I feel as if I am missing something basic here, but can't quite place it. Can anyone tell me where I'm going wrong in my interpretation here? Or perhaps I'm interpreting the odds ratio incorrectly? How do I reconcile these differences?
