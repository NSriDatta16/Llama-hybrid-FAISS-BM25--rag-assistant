[site]: datascience
[post_id]: 11905
[parent_id]: 11665
[tags]: 
If you'd like to keep things straight and simple for a start, you may want to view this as a standard categorial classification problem. As a second step, you use multi-step-Prediction, as @eulerleibniz suggested. To render this approach feasible, you only predict the label for the next second (not for five) as a first step. You may use a random forest or gradient boosted trees algorithm. Both need little parameter tuning, are reasonably well-behaved, and implementations are widely available (e.g., in Python and R). You can have a go at your problem with these algorithms. In a second step, you then repeat the whole thing, and combine your input data with the prediction just generated to predict the next label. And so forth, until you've got the next five labels. If you're just a little bit lucky, the results are already good enough. If not, at least they provide a benchmark for more laborious approaches like RNN.
