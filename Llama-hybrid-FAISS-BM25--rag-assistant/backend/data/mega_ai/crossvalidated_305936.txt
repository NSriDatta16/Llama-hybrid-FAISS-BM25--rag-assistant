[site]: crossvalidated
[post_id]: 305936
[parent_id]: 305125
[tags]: 
My professor said that when one fixes the value of the parameter, and then watch the posterior distribution after 0, 1, 2, ... observations, the result is a Markov chain. (I.e. it is not even an analogy, but an exact correspondence in some sense.) They also said that, however, for i.i.d. observations, the above scenario often does not satisfy the requirements for convergence to a stationary distribution. Therefore, the Bayesian update process is in some sense not really analogous to Monte Carlo Markov chains which are always set up/rigged so that they converge to a stationary distribution (the posterior in the Bayesian update process after one update). My professor gave me the following example to illustrate their point: Suppose $X_1, \dots, X_n \sim Bern(\theta)$ and with a $Beta(\alpha,\beta)$ prior on $\theta$ . The posterior after $n$ updates, with $S_n := \sum_{i=1}^n X_i$ is distributed as $Beta(\alpha + S_n, \beta + n - S_n)$ . Writing $(\alpha_n, \beta_n) = (\alpha_n + S_n, \beta + n - S_n)$ , then the Bayesian update process gives a Markov chain on the state space $(\alpha_n, \beta_n)$ , with transition kernel $Q(\alpha_{n+1}, \beta_{n+1}|\alpha_n, \beta_n)$ such that: $$Q(\alpha_n +1, \beta_n|\alpha_n, \beta_n) = \theta $$ $$Q(\alpha_n, \beta_n + 1|\alpha_n, \beta_n) = 1 -\theta $$ Since $\alpha_n + \beta_n$ always increases by $1$ , this Markov chain cannot have a stationary distribution. But we do have that $\dfrac{\alpha_n}{(\alpha_n + \beta_n)} \to \theta$ , so that the posterior distribution will asymptotically concentrate around $\theta$ . If the prior satisfies Cromwell's rule , then by the argument found here , for the true value $\theta_0$ and any other value $\theta_1$ , we have that $$\dfrac{\lambda(\theta_0 | X_1, \dots, X_n )}{\lambda(\theta_1 | X_1, \dots, X_n)} \to \infty $$
