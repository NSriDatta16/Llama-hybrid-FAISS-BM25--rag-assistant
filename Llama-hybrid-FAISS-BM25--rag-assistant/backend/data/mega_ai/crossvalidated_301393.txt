[site]: crossvalidated
[post_id]: 301393
[parent_id]: 
[tags]: 
How can a machine learning model learn from feedback about its performance? (i.e. telling it if it was correct/incorrect in its predictions)

I have a machine learning model, and it predicts the labels for a previously unseen data set. If I go through and mark each generated label as correct or incorrect, how can I use this new information to tune the weights on my model? I'm not sure what the correct phrase for adding such a feedback loop into the model is called.
