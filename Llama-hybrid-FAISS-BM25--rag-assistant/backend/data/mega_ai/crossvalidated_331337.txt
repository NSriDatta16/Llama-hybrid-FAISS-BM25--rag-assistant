[site]: crossvalidated
[post_id]: 331337
[parent_id]: 331068
[tags]: 
You can only use the validation set once. After that, you are already over-fitting, as you say. CV is less susceptible to overfitting, simply because more splits, but it will still overfit . The more splits, the more data, and the fewer hyper-parameter values you choose, the less you will overfit. As far as theoretical results, Bengio's group came out with a paper recently, related to training deep networks, which is fairly related to what you are asking, https://arxiv.org/abs/1710.05468 "Generalization in Deep Learning", Kawaguchi, Kaelbling, Bengio, 2018. "In practical deep learning, we typically adopt the trainingâ€“validation paradigm, usually with a held-out validation set. We then search over hypothesis spaces by changing architectures (and other hyper-parameters) to obtain low validation error. In this view, we can conjecture the reason why deep learning can sometimes generalize well as follows: it is partially because we can obtain a good model via search using a validation dataset. Indeed, as an example, Remark 6 states that if validation error is small, it is guaranteed to generalize well, regardless of its capacity, Rademacher complexity, stability, robustness, and flat minima."
