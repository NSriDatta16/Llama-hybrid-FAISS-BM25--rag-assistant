[site]: datascience
[post_id]: 25425
[parent_id]: 
[tags]: 
speech accent recognition data augmentation and training

I am using a Kaggle dataset to learn more about using sound with Deep Learning. I have extracted the mfcc features using this cool library - librosa. However, I want to try feature extraction using CNN's and then train on LSTM. (Any advice here would be good, if I am on the right track) Should I just put the raw wav file into CNN or should I do some data augmentation before that? Link to the dataset
