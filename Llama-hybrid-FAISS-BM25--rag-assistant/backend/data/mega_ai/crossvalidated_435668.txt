[site]: crossvalidated
[post_id]: 435668
[parent_id]: 
[tags]: 
What would a reversed Inception v3 block look like for a convolutional autoencoder, specifically in the decoder block?

(I've been using Keras but if this is possible in PyTorch I'd be willing to switch my project.) I've been working with convolutional autoencoders and they look promising for my use case. One thing that I'm trying to experiment with is with implementing a set of parallel feature extractors like those found in Inception v3 modules. However, because the module takes an input and then builds several parallel tensors from that one input, and then concatenates the parallel tensor output I don't know how that would work in reverse, or if that is even logically possible? Has anyone seen this done anywhere?
