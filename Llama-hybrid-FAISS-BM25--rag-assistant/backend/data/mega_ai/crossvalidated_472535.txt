[site]: crossvalidated
[post_id]: 472535
[parent_id]: 
[tags]: 
Mean of non-central Poisson deviance distribution is lower than that of the associated central distribution

We have observed some strange behaviour regarding distributions of Poisson deviance statistics. In short, we find for certain Poisson parameters, that the non-central deviances are smaller than the central deviances, completely contrary to intuition. More detail below: Background We are using Poisson deviance to analyze the results of radiation detection simulations. Specifically, we have two models $\boldsymbol{\lambda}_0$ and $\boldsymbol{\lambda}_1$ that can give rise to a vector $\boldsymbol{n}$ of counts at each measurement, e.g., $$ \boldsymbol{n} \sim \text{Poisson}(\boldsymbol{\lambda}_{0}). $$ We are interested in finding how often a measurement $\boldsymbol{n}$ drawn from the alternate model $\boldsymbol{\lambda}_1$ "looks like" it was drawn from the null model $\boldsymbol{\lambda}_0$ . To accomplish this, we use the Poisson deviance $$ D(\boldsymbol{n} | \boldsymbol{\lambda}) = 2 \left[ \boldsymbol{n} \log(\boldsymbol{n}) - \boldsymbol{n} \log(\boldsymbol{\lambda}) + \boldsymbol{\lambda - \boldsymbol{n}} \right] $$ and consider two different distributions of deviance statistics. First, we consider the deviance $D(\boldsymbol{n}_0 | \boldsymbol{\lambda}_0)$ between the null model $\boldsymbol{\lambda}_0$ and a sample $\boldsymbol{n}_0$ drawn from it. Then, we consider the "non-central" deviance $D(\boldsymbol{n}_1 | \boldsymbol{\lambda}_0)$ between a sample $\boldsymbol{n}_1$ of the alternate model $\boldsymbol{\lambda}_1$ computed assuming that $\boldsymbol{\lambda}_0$ was the true model. The distributions of these $D$ statistics can be Monte Carlo simulated, or approximated analytically via shifted Gamma distributions. We can then define a decision rule for deciding $\boldsymbol{\hat{\lambda}} = \boldsymbol{\lambda}_0$ vs $\boldsymbol{\lambda}_1$ , and subsequently compute the false negative probability that $\boldsymbol{n}$ "looks like" it was drawn from the null model $\boldsymbol{\lambda}_0$ when really it was generated from the alternate model $\boldsymbol{\lambda}_1$ . Problem The problem we see is that occasionally, the distribution of the non-central deviances $D(\boldsymbol{n}_1 | \boldsymbol{\lambda}_0)$ is below that of the central deviances $D(\boldsymbol{n}_0 | \boldsymbol{\lambda}_0)$ . For instance, consider a simple model with $N = 10^5$ measurements and constant Poisson rates $$ \boldsymbol{\lambda}_0 = 2.80 \cdot \vec{1}_N $$ $$ \boldsymbol{\lambda}_1 = 2.82 \cdot \vec{1}_N $$ where $\vec{1}_N$ denotes a vector of $1$ 's of length $N$ . Our results for the central (blue) and non-central (orange) deviances are shown in the figure below. The non-central deviance distribution is lower than the central one, leading to a strange false negative probability of ${>}0.5$ . Intuitively, we would expect that the deviances from the correct model $\boldsymbol{\lambda}_0$ computed using the incorrect model $\boldsymbol{\lambda}_1$ should be larger than those computed using the correct $\boldsymbol{\lambda}_0$ . Or at least, that this should be true on average. If we write out the difference in means $$ \Delta \equiv \mathbb{E}[D(\boldsymbol{n}_1 | \boldsymbol{\lambda}_0)] - \mathbb{E}[D(\boldsymbol{n}_0 | \boldsymbol{\lambda}_0)] $$ $$ \Delta = 2 \sum_i \mathbb{E}[\lambda_{0i} - n\log\lambda_{0i} + n\log n -n | \lambda_{1i}] - 2 \sum_i \mathbb{E}[\lambda_{0i} - n\log\lambda_{0i} + n\log n -n | \lambda_{0i}] $$ $$ \Delta = 2 \sum_i (\lambda_{0i} - \lambda_{1i} + \lambda_{0i}\log \lambda_{0i} - \lambda_{1i} \log \lambda_{0i} + \mathbb{E}[n\log n | \lambda_{1i}] - \mathbb{E}[n\log n | \lambda_{0i}] ) $$ we would intuitively expect this never to be negative. However, as our example shows, this is not always the case. In fact this problem seems to arise under two conditions: The two model-predicted count vectors are similar across most measurements: $\lambda_{0i} \simeq \lambda_{1i}$ . The model-predicted counts are small on average: $\lambda_i \lesssim 10$ . Distillation down to a single measurement To simplify, let us model a scenario with a single measurement: $N=1$ . We will explore the behaviour of $\Delta$ in the two above conditions where $\lambda_0 \simeq \lambda_1 \lesssim 10$ . If we plot the difference in means $\Delta$ as a function of $\lambda_0$ and $\lambda_1$ , we obtain the following figures: The regions in teal are where the difference in means $\Delta$ is positive, and the regions in dark blue are where it is negative. Zooming in on the upper dark blue region: The red line in the second figure is where $\lambda_0 = \lambda_1$ . We find that the two regions are connected, with a boundary at $\lambda_0 = \lambda_1 \equiv B \simeq 1.338$ . In addition, there is a vertical asymptote at $V \simeq 0.5049$ . So it seems that contrary to our intuition, this effect is real. The mean of the non-central Poisson deviance distribution can be lower than that of its associated central distribution , even in the simple case of $N=1$ measurements. In other words, the wrong model matches the data better than the correct model. Is there an intuitive explanation for why this occurs, and for the $\lambda_0$ and $\lambda_1$ that it does? Or perhaps does the Poisson deviance formalism break down in these regimes? Any insight here would be appreciated.
