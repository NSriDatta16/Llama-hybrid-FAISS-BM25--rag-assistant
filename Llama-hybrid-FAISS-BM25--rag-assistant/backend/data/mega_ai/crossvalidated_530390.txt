[site]: crossvalidated
[post_id]: 530390
[parent_id]: 
[tags]: 
Sequential update of Posterior distribution of a Correlated Gaussian distribution

Consider the following problem of sequentially estimating ( in a Bayesian setting ) the means of the two Gaussian distributions $\mathcal{N}(\mu_1,\sigma_0^2)$ and $\mathcal{N}(\mu_2,\sigma_0^2)$ which have the same known variance $\sigma_0^2$ and have a known correlation $\rho$ . Using conjugate priors, at any given time $t$ , we have prior probabilities for the means as $\mu_1 \sim \mathcal{N}(\theta_1(t),\sigma_1^2(t))$ , $\mu_2 \sim \mathcal{N}(\theta_2(t),\sigma_2^2(t))$ . We observe a unidimensional sample $x(t)$ from one of the two distributions and we update the parameters of our prior probabilities as follows: WLOG, assume that $x(t)$ comes from the first distribution i.e. $x(t) = x_1(t)$ . The update equations are given by \begin{align} \theta_{1}(t+1)&=\frac{\sigma_{1}^{2}(t) x_{1}(t)+\sigma_{0}^{2} \theta_{1}(t)}{\sigma_{1}^{2}(t)+\sigma_{0}^{2}} \qquad \text{(1)}\\ \sigma_{1}^{2}(t+1)&=\frac{\sigma_{1}^{2}(t) \sigma_{0}^{2}}{\sigma_{1}^{2}(t)+\sigma_{0}^{2}} \qquad \text{(2)}\\ \theta_{2}(t+1)&=\theta_{2}(t)+ \underbrace{\rho \sigma_1(t) \sigma_2(t)}_{\rho - term} \frac{x_{1}(t)-\theta_{1}(t)}{\sigma_{1}^{2}(t)+\sigma_{0}^{2}} \qquad \text{(3)}\\ \sigma_{2}^{2}(t+1)&=\sigma_{2}^{2}(t)-\frac{\sigma_{1,2}^{2}}{\sigma_{1}^{2}(t)+\sigma_{0}^{2}} \qquad \text{(4)} \end{align} The above update equations follow from straightforward application of conjugate priors . Here is my question - Let $S = \{1,2,2,1,2,1, \dots, 1\}$ be an arbitrary binary sequence of length of T which determines the distribution from which we observe the sample. E.g. $S(3) = 2$ which says that $x(3) = x_2(3)$ i.e. at the third time instance, I get the sample from distribution 2. So, based on $S$ , I get the samples from one of the distributions at each $t$ . I want to determine if the sequence of updates $\theta_1(t)$ and $\theta_2(t)$ converge to $\mu_1$ and $\mu_2$ respectively. Here is what I know: I made some simplifying assumptions such as $\theta_1(0)=\theta_2(0)=0 ;\sigma_1(0)=\sigma_2(0)=\sigma_0=1 $ and proceed ahead: For $\rho = 0$ : If the correlation $\rho$ was zero, samples from one distribution are not going to effect the updates in the $\theta$ parameters of the other distribution because the $\rho - term$ would be zero in equation 3. So, we can repeat the process of sampling the unidimensional observations $x(t)$ for large enough times so that we get enough samples from both the distributions and then, say that both $\theta_1(t)$ and $\theta_2(t)$ asymptotically converge to $\mu_1$ and $\mu_2$ , respectively. We can also comment on the rates of convergence using SLLN, etc. For $\rho \ne 0$ : However, I am not sure any such results of asymptotic convergence exist for $\rho \ne 0$ . My intuition is that using the additional information of correlation should help in tighter bounds/faster convergence. However, I am clueless in this case, because both $\theta_1$ and $\theta_2$ get updated at every $t$ . Any pointers to prior literature and your thoughts are welcome.
