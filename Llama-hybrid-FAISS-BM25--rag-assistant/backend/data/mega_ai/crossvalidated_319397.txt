[site]: crossvalidated
[post_id]: 319397
[parent_id]: 
[tags]: 
Learning "concept embeddings" as opposed to word embeddings - modifying word2vec's objective

I want to capture relationships between high-level concepts, as opposed to just between words, using word2vec or similar approach. What would be a promising way to achieve that? I was thinking of modifying the objective function to use something else that word co-occurrence counts, is there any better approach? A bit of background: at present, I'm using Siamese LSTMs to classify whether a title-reference pair from a systematic review is relevant. Currently, the inputs are word vectors generated using fastText.
