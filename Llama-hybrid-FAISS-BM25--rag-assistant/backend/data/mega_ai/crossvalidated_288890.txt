[site]: crossvalidated
[post_id]: 288890
[parent_id]: 288676
[tags]: 
Suppose you are counting radioactive samples that have been pipetted into counting tubes and the decays counted. Since the error of counting is itself Poisson, but the pipetting has a long tailed error, you select the median value of three duplicate samples as the least likely to have a wild pipetting error. Suppose you send identical gold ore samples to three laboratories to extract gold. You choose the laboratory that isolates the most gold from the samples you sent. Suppose you test three samples of a fixed dose of drug X, from three different manufactures, for mercury contamination. You choose to buy pills from the company whose pill has the least amount mercury in it. So, well now, does not the criterion for selection depend on the motive for selecting? Plausibility is not undefined. Consider the scientific method, e.g., see this which is, in effect, that we try to disprove everything, and only when we fail to disprove a hypothesis, despite having demonstrated that competing hypotheses are unlikely, we are still only left with a less easily proven implausible explanation than we had before testing it. No matter how many times we demonstrate plausibility we do not validate our hypothesis. However, our confidence increases as a result of multiple negative results, especially if our testing extends to testing theretofore unsuspected implications of a new hypothesis. Sometime thereafter we promote a plausible explanation to the status of a theory. Consistency of input data is sometimes referred to as a plausibility check , but what we are referring to would be the application of plausibility logic (Schlechta K. Completeness and incompleteness for plausibility logic. Journal of Logic, Language and Information. 1996;5:177-92.) in a statistical context. Now the answer given by @kodiologist below is a good one, with the exception that I would remove the "sort of" from the description and just state that plausibility is essentially Bayesian reasoning. A typical statistical test shows that something is either implausible or not implausible. This extends to hypothesis testing and outlier testing. The banking industry has an interest in stress testing which invokes quantifying "the (im) plausbility of a realisation by its Mahalanobis distance from the mean of the distribution," where Mahalanobis distance is the $n$ -space normalized L $_2$ norm. Although this is unlikely to be optimal for $n$ -space minimization, it is nevertheless a good starting point.
