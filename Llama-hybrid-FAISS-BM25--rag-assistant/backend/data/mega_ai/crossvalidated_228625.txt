[site]: crossvalidated
[post_id]: 228625
[parent_id]: 
[tags]: 
heteroskedasticity and out-of-sample predictions

My model is an OLS with a single independent variable on cross-sectional data (n=3500). The relation is linear and there's a very good fit and there are no outliers, but the residuals' variance increases as x increases, clearly visible as a fan-shape in a residual-versus-predicted plot, so there's an issue with heteroskedasticity (which the Breusch-Pagan test confirms). The residuals' variance seems to be normally distributed and indeed symmetric above and below any value of x. I then calculated robust standard errors. This model has two objectives: To predict y for out-of-sample values of x. That's why transforming the variables to reduce heteroskedasticity won't help much: I'll have to de-transform the results back to their original units and the variance in the errors will return. To convey the message that in this model specification there is heteroskedasticity with a specific pattern that as x increases, the variance in the errors increases too, making predictions of high value x's less reliable but within a certain calculable range (i.e. confidence intervals). My questions are: can I use robust standard errors to calculate confidence intervals for out-of-sample x's? I'd like to plot the in-sample and out-of-sample variables together with the regression line and 95% confidence intervals obtained through robust standard errors. Is there any special issue to be aware of, or can they be plotted just like regular CIs? Just out of curiosity I also tried bootstrapped standard errors, which came out remarkably similar to the robust standard errors. Is there any reason to prefer one over the other? Is there any other way to deal with heteroskedasticity in a case like this without introducing another independent variable? I hope these questions make sense, if not please bear with me as I'm quite new at this and I'd like to learn why. Thank you!
