[site]: datascience
[post_id]: 57799
[parent_id]: 
[tags]: 
Neural net only works for small datasets

I have a neural network that attempts to solve some regression problem. The network works fine when the dataset has a small number of training examples, lets say 20. It overfits of course, but the training loss decreases to 0 which is what I want right now. However, when I take my entire dataset, which has 5000 training examples in it, the loss plateaus at around 375. It won't decrease to zero, no matter how many hidden layers and neurons and activations I add. I tried everything. What does this mean? Why does this happen and how can I fix it? Is it plausible that it's simply not possible to train a model that fits the training data?
