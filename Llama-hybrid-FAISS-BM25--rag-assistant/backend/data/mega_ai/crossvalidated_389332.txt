[site]: crossvalidated
[post_id]: 389332
[parent_id]: 389233
[tags]: 
This is clearly a mistake in the Eigenproblems in Pattern Recognition . Good catch. This is not a PLS objective, for the reasons you gave yourself. This does indeed work for CCA (see section 4.2.2 in the same Chapter), but does not work for PLS. Now you may ask: if this objective does not work, then how can one formulate PLS in terms of minimizing squared error? There is probably no natural way to do it. I have never seen it in the literature. E.g. a pretty comprehensive (but very dense and hard to follow) paper by Torre A Least-Squares Framework for Component Analysis does not mention PLS. I have not seen it elsewhere either. That said, last year I realized that for univariate $\mathbf y$ , OLS (analogue of CCA in this case), ridge regression, PLS, and PCA, all can be very neatly united in one least-squares framework: see my answer to The limit of "unit-variance" ridge regression estimator when $\lambda\to\infty$ . I've been wondering if perhaps the multivariate case can also be formulated like that, but I did not manage to work it out so far.
