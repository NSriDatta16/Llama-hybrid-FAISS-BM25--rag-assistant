[site]: crossvalidated
[post_id]: 519659
[parent_id]: 
[tags]: 
Random forest final stage: Consider the training dataset or the entire dataset?

I trained and tuned a random forest classifier using cross validation and train-test split, as in 70% training dataset (which is then cross validated 5 splits, 6 times) and 30% test dataset. With the CV I managed to get the best hyper-parameters and with the test dataset I obtained the performance score. This link suggests that after everything is ready, one should then refit/retrain the model with the same configuration as before but on the entire dataset now (not the training dataset anymore). However, I wonder if this wouldn't mess with the hyper-parameters that were defined before specifically for the training data. Also, I wonder if this would not somehow change the nature of the model (as it would most likely start getting 100% accuracy in the entire dataset). This is particularly important for me because I need to use the model on another similar dataset to predict synthetic values. How do you guys usually proceed?
