[site]: crossvalidated
[post_id]: 573931
[parent_id]: 
[tags]: 
Covariance of Least Squares Estimators

I am trying to solve the problem shown below: To solve (a), I defined the sum of squared errors $f(\hat{\beta}) = \sum_{k = 1}^{n} (y_k - \hat{\beta})^2$ . This allows us to identify the least-squares estimate of $\hat{\beta}$ : $$-2 \sum_{k = 1}^{n} (y_k - \hat{\beta}) = f'(\hat{\beta}) = 0 \implies \hat{\beta} = \frac{1}{n} \sum_{k = 1}^{n} y_k.$$ This makes sense as one $\hat{\beta}$ is simply the average of all observations. However, I don't know if my interpretation of (b) is correct. Is it essentially asking us to apply the formula $$Cov(\hat{\beta}^{(1)}, \hat{\beta}^{(2)}) = \frac{\sum_{k = 1}^{n-1} (u_k - \hat{\beta}^{(1)})(v_k - \hat{\beta}^{(2)})}{n-1}$$ where $(u_k) = (y_2, \dots, y_n)$ and $(v_k) = (y_1, y_3, \dots, y_n)$ ?
