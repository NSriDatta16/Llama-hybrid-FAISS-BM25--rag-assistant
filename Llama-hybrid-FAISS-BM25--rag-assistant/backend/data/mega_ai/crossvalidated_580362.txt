[site]: crossvalidated
[post_id]: 580362
[parent_id]: 
[tags]: 
Lagged variables, data leakage and machine learning

I am reading a paper that fits a random forest (RF) to some data that is grouped by company and quarter. In the data engineering stage, the authors include 'lagged' variables of many of the explanatory variables to feed the RF. My question: By lagging the variables, aren't we inducing a 'data leakage' problem? (They computed the lags before splitting into train/test) For instance, for a company-quarter combination that is in the TRAINING set and already has the info for a different_quarter-same_company combination that is in the TEST set, could we potentially lead to overly optimistic results because of the 'leakage'? Thank you for your thoughts!
