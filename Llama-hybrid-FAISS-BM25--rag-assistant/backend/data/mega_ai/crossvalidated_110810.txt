[site]: crossvalidated
[post_id]: 110810
[parent_id]: 110809
[tags]: 
Simulating results for this process is sometimes called a "stick-breaking" process: we start with a 1-unit stick and break it into two pieces. For this example, we call the first piece "Democrats" and set it aside. Then we break the second piece into two pieces and call the first piece "Republicans," and we are left with the third (and in this example, final) piece, which we call "Greens" (or "Libertarians," or whatever). The length of each piece of stick corresponds to the probability of the respective party winning the seat. At every point, we only have a total of 1 unit of stick -- the stick is simply allocated into smaller pieces -- so the law of total probability is respected. The distribution of lengths of the pieces of the stick is often characterized as a Dirichlet distribution , which is a generalization of the beta distribution into an arbitrary number of outcomes: the beta distribution is the same as a Dirichlet distribution for two possible outcomes. You might wonder why one doesn't simply use several normal models, either one for each party, or even $k-1$ for each of $k$ parties. The answer is that the normal distribution has support over the whole real line, which means it would predict with positive probability $\Pr(\text{Democrats win})$ for each of $\{-10, 10, 100, \pi\}$, none of which are valid probabilities. However, one might use normal models if the probability of winning is transformed in some way. A common transformation which takes values on a unit interval to the real line is the logistic transformation $\text{logit}(x)=\log(x)-\log(1-x)$ which is identical to the log of the odds. This does have support over the entire real line, so perhaps a normal model would be acceptable. But if you've put your data on a real line, then literally any distribution on the real line is reasonable prima facie -- a question you might need to consider is how heavy the tails are. A normal distribution has very light tails, while a Cauchy distribution is notoriously pathological, and a Student's t -distribution with more then 1 degree of freedom is a compromise between those two extremes.
