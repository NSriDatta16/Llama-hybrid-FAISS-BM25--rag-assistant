[site]: crossvalidated
[post_id]: 234860
[parent_id]: 
[tags]: 
Is there a general term for when one trains with more information than when one uses his trained model?

I'm interested in training a neural network on 1xN size inputs, but actually only using 1xM inputs for when I use my learned model. 1 Specifically speaking, I'm interested in training some model for a Poker Bot. I was hoping to train the model on data that has ALL hands revealed. Obviously, one can only play poker with only his hand visible. I'm having trouble doing my own research/learning on this idea since it's fairly long to describe. Is there a proper term for what I'm trying to do?
