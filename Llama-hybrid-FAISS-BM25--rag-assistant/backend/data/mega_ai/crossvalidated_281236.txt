[site]: crossvalidated
[post_id]: 281236
[parent_id]: 
[tags]: 
ARIMA time trend analysis using R and SPSS and poor datasets: opposite signs for the Moving Average part

I want to study a time series using ARIMA. To understand what is the best ARIMA model, I use the function Arima (dataset, order, seasonal) from the package forecast in R . You can see dataset I am trying to analyse below. TEST Using Arima(TEST, c = order(0,1,1), seasonal = FALSE) in R , I obtained the following results: Series: TEST ARIMA(0,1,1) Coefficients: ma1 -0.2155 s.e. 0.1741 sigma^2 estimated as 3.221e-08: log likelihood=274.33 AIC=-544.67 AICc=-544.33 BIC=-541.39 However, if I try to load the same dataset in SPSS , via Analyze > Forecasting > Create Traditional Models... and I select ARIMA(0,1,1) , my results are different and, in particular, the sign of my ma1 is opposite, i.e. ma1 = .215 SE = .163 I am a newbie in time trend analysis, and I performed these calculations for multiple datasets, some of them very poor. Initially, I associated my sign differences to the low quality of the dataset, however I am not sure if this could be the case also in this situation, given that the dataset does not seem so bad to justify radically difference results using different programs and, consequently, different algorithms. I also tried to compare the plots obtained from R and from SPSS , and at first glance the seem identical. Finally, I did some tests also looking at the autoregressive part, and I did not notice a similar phenomenon of sign inversion. For example, if I use the same dataset and an ARIMA (1,1,0) I get the following results in R Coefficients: ar1 -0.1549 s.e. 0.1580 sigma^2 estimated as 3.26e-08: log likelihood=274.11 AIC=-544.23 AICc=-543.89 BIC=-540.95 and in SPSS ar1 = -.155 s.e. = .165 What could be the reason for this difference? And which results should I trust?
