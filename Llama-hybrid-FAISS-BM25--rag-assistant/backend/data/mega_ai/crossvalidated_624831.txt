[site]: crossvalidated
[post_id]: 624831
[parent_id]: 
[tags]: 
Purpose of distribution "over" a variable notation

The deep learning book (Goodfellow, Bengio, and Courville, 2016)'s notation section says $\mathcal{N}(\mathbf{x}; \mathbf{\mu}, \mathbf{\Sigma})$ represents a normal distribution over $\mathbf{x}$ , which I thought was just a shorthand for specifying the dimensions or for referencing a distribution without needing to write $\mathbf{x} \sim \mathcal{N}(\mathbf{\mu}, \mathbf{\Sigma})$ . However, I see it used in the paper Denoising Diffusion Probabilistic Models (Ho et al., 2020 at NeurIPS) in the form $$p_θ(x_{t−1}|x_t) := N (x_{t−1}; \mu_θ(x_t, t), \Sigma_θ(x_t, t))$$ where the dimensionality isn't in question, and the normal distribution isn't over the marginal $x_{t-1}$ , rather the conditional $x_{t-1} \mid x_t$ . I'm wondering what the $x_{t-1}$ in the $N(x_{t-1}; ...)$ notation actually means.
