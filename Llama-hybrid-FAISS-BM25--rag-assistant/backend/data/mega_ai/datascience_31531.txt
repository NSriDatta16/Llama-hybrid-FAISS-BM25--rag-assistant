[site]: datascience
[post_id]: 31531
[parent_id]: 
[tags]: 
Is machine learning a viable tool to map accent from speech onto text/syllables?

I'm quite new to coding and even newer to machine learning, so please excuse if this is a stupid question to ask. The project I am thinking about building is a program that helps correct pitch accent (the changes in high and low in between syllables) by analyzing speech from user input. So let's say we have a random word I want to analyze, what I give to the Program is the representation of the audio (see further down) and a count for how many syllables the audio contains. As an output I want to know for each Syllable if it is either High or Low. Let's do an example for the English word Animal . Pitch is the blue line As an input I give the number of syllables (3) and a representation of the audio. As an output I want to see the Syllables mapped onto either High or Low, for the example "animal" [High, Low, Low/ 1,0,0] for "malaria" (4 syllables) I'd want [LLLH/0,0,0,1]. . In order to do this I plan to train a Neural Network (Since with those the difference in speaking pace apperently doesn't need to be controlled for) and preprocess my audio with mel frequency cepstral coefficients in order to represent the features present in human speech. (I also thought about preprocessing to represent just the pitch but i am not sure if I might take away too many features then). As mentioned earlier as an output I want the representation of where in the word the changes in hight occur. My training data consists of 50000 recordings of various pitch-accent-patterns over words, the recordings themselves are labeled with the pattern and the word they represent. Does this seem doable with a Neural Network or machine learning in general? How do I get the Syllable Count to be weighted so much that the output is directly related to the high and low of each syllable? Do you have any ideas/tips/suggestions in general?
