[site]: crossvalidated
[post_id]: 307032
[parent_id]: 
[tags]: 
how to encode classes so that they reflect sequential correlation between them

I have a time series that I want to predict (using Neural Network, but is not important). On top of using the info at previous values ($t-1$, $t-2$, ...etc) I want to use another variable: the hour of the day . Stupid Method One way would be to map: $00:00 \rightarrow 0 $ $01:00 \rightarrow 1$ .... and so on. So I woul have $24$ classes $\{0,1,2,..., 23\}$. However there is a problem: $23$ and $0$ are close, but at the same time this is not reflected here. second method: one hot encoding? Another way would be to create vectors with $24$ entries where all the elements are zero, apart from the class that we are looking at. This is equivalent to creating dummy variables. For instance: $00:00 \rightarrow [1,0,0,0,....,0]$ $01:00 \rightarrow [0,1,0,0,...,0]$ ...and so on. However there is a problem: this doesn not reflect correlation at all! Other Method I was thinking of using some cyclic structure, for instance $sin$, $cos$ or maybe polar coordinates? I haven't found the solution yet, but this is my progress: Map the class labels of the stupid method to $[0,1]$, by normalizing them Scale them to be in the range from $0$ to $2\pi$. Use $cos$ or $sin$ on them. This method doesn't quite work, but I can see some light.. Any ideas?
