[site]: crossvalidated
[post_id]: 114735
[parent_id]: 114663
[tags]: 
Even with a non-informative prior, Bayesian inference is different from frequentist approaches. For example, consider estimating the probability $\theta$ that a coin will turn up heads. Take a uniform prior on $\theta$. If we observe a single flip, and it is heads, the Bayesian predictive probability that the next flip will be heads is 2/3. A maximum-likelihood approach would say the probability is 1. If you want the derivation of this result, read Bayesian inference, entropy, and the multinomial distribution . I have written several papers on exactly this topic. If you want more examples, check out: Pathologies of Orthodox Statistics , Inferring a Gaussian distribution and Bayesian inference of a uniform distribution .
