[site]: crossvalidated
[post_id]: 615637
[parent_id]: 
[tags]: 
Spark Pipeline - Chain Regressors Together

I'm running this on databricks, using python, spark, pipeline, mlflow, etc. Can use whichever library I need to though I have a simple Linear Regression script. I separately have a Random Forest script. The data set has 10 features and 1 label to predict. All columns are normalized doubles. assembler = VectorAssembler(inputCols=in_cols, outputCols='features') rf = RandomForestRegressor(labelCol='label') #lr = LinearRegression(labelCol='label', featuresCol='features') evaluator = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName='r2') stages = [assebler, rf] pipeline = Pipeline(stages=stages) cv = CrossValidator(estimator=pipeline, evaluator=evaluator, numFolds=3, seed=42..) cv.fit(train).transform(test) How can I have the random forest output be a vector and feed its output into the linear regression and have the model fit. Similar to how a neural network layer's output would be the input to the next layer. I'm aware this isn't really the ideal model, but want to know how it can be done
