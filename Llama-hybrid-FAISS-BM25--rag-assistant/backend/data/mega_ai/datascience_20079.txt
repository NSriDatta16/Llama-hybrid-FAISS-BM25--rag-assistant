[site]: datascience
[post_id]: 20079
[parent_id]: 
[tags]: 
wrong output for neural network written from scratch

I am trying to write a complete neural network from scratch. However, the results are not very encouraging. My prediction output shows one for one single row only in the 3 class classifier. I will post my code and then I will talk about the problem in the output. #labels or classes #1=iris-setosa #2=iris-versicolor #0=iris-virginica #features #sepallength #sepalwidth #petallengthcm #petalwidth import pandas as pd import matplotlib.pyplot as plt import csv import numpy as np df=pd.read_csv('Iris.csv') df.convert_objects(convert_numeric=True) df.fillna(0,inplace=True) df.drop(['Id'],1,inplace=True) #function to convert three labels into values 0,1,2 def handle_non_numericaldata(df): columns=df.columns.values for column in columns: text_digit_vals={} def convert_to_int(val): return text_digit_vals[val] if df[column].dtype!=np.int64 and df[column].dtype!=np.float: column_contents=df[column].values.tolist() unique_elements=set(column_contents) x=0 for unique in unique_elements: if unique not in text_digit_vals: text_digit_vals[unique]=x x+=1 df[column]=list(map(convert_to_int,df[column])) return(df) handle_non_numericaldata(df) x=np.array(df.drop(['Species'],1).astype(float)) c=np.array(df['Species']) n_values=(np.max(c)+1) #to make the vector one hot encode y=(np.eye(n_values)[c]) (np.shape((y))) m1=np.size(c) theta=np.ones(shape=(4,21)) theta2=np.ones(shape=(21,3)) #no of examples "m" #learning rate alpha alpha=0.05 #regularization parameter lamda=0.05 for i in range(1,5000): z1=np.dot(x,theta) sigma=1/(1+np.exp(-z1)) #activation layer 2. a2=sigma z2=np.dot(a2,theta2) probs=np.exp(z2) softmax=probs/np.sum(probs,axis=1,keepdims=True) delta3=softmax delta3=delta3-y A2=np.transpose(a2) dw2 = (A2).dot(delta3) W2=np.transpose(theta2) delta2=delta3.dot(W2)*sigma*(1-sigma) X2=np.transpose(x) dw1=np.dot(X2,delta2) dw2=dw2-lamda*theta2 dw1=dw1-lamda*theta theta =theta -alpha* dw1 theta2= theta2-alpha * dw2 final1=x.dot(theta) sigma=1/(1+np.exp(-final1)) z2=sigma.dot(theta2) exp_scores=np.exp(z2) probs=exp_scores/np.sum(exp_scores,axis=1,keepdims=True) a=np.zeros_like(probs) a[np.arange(len(a)),a.argmax(1)]=1 print(a) The output according to me, as I have written this, all the output probabilities are same hence it cannot classify properly.output should be 'a' array with 50 1's in the first row, 50 in the second, and 50 in the third. But all the ones are in first row. I have been meddling with this since last three days. Please help me figure out mistake I have made in writing this neural network.
