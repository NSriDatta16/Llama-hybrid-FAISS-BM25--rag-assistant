[site]: crossvalidated
[post_id]: 479532
[parent_id]: 479520
[tags]: 
You are not using gsem , so you don't have an eta. So let's step back and think about what you are trying to do. You have $E[\ln y|x]$ , but you want to calculate $E[y|x]$ . Exponentiating the predicted values from the log model will not provide unbiased estimates of $E[y|x]$ , as $$E[y_i|x_i] = \exp(x_i'\beta) \cdot E[\exp(u_i)].$$ If $u \stackrel{iid}{\sim} N[0,\sigma^2]$ , then $E[\exp(u)] = \exp(0.5 \cdot \sigma^2)$ . That quantity may be estimated by replacing $\sigma^2$ with its consistent estimate $s^2$ . You have that from etregress and you also have its variance, so you should be good. I believe the first one below is the equivalent of what you want: . webuse nhanes2f, clear . qui svyset psuid [pweight=finalwgt], strata(stratid) . qui svy: etregress loglead i.female i.diabetes, treat(diabetes = weight age height i.female) // coefl . margins, expression(exp(predict(xb))*exp((exp(_b[/:lnsigma]))^2/2)) Predictive margins Number of strata = 31 Number of obs = 4,940 Number of PSUs = 62 Population size = 56,316,764 Model VCE : Linearized Design df = 31 Expression : exp(predict(xb))*exp((exp(_b[/:lnsigma]))^2/2) ------------------------------------------------------------------------------ | Delta-method | Margin Std. Err. t P>|t| [95% Conf. Interval] -------------+---------------------------------------------------------------- _cons | 14.39444 .2534461 56.79 0.000 13.87753 14.91134 ------------------------------------------------------------------------------ . di "E[exp(u)] = " exp((exp(_b[/:lnsigma]))^2/2) E[exp(u)] = 1.073898 . sum lead Variable | Obs Mean Std. Dev. Min Max -------------+--------------------------------------------------------- lead | 4,942 14.32032 6.167695 2 80 This makes strong assumptions. You can also try using another version of the correction that makes fewer distributional assumptions (just homoscedastic iid). Here it really makes no difference: . /* This assumes homoscedastic iid errors (Duan's "smearing" re-transformation) */ . predict double ln_yhat, xb (2 missing values generated) . gen double expuhat = exp(ln_yhat - loglead) (5,397 missing values generated) . quietly sum expuhat . di "E[exp(u)] = " r(mean) E[exp(u)] = 1.0780898 . gen double yhat_duan = exp(ln_yhat)*r(mean) (2 missing values generated) . sum lead yhat_duan if e(sample) Variable | Obs Mean Std. Dev. Min Max -------------+--------------------------------------------------------- lead | 4,940 14.32287 6.167599 2 80 yhat_duan | 4,940 14.48996 2.728553 11.81736 21.2051 The actual mean is \$14.32, Duan's method gives you \$14.49 and the original method gives you \$14.39. It might make sense to take two (or more) averages: one for the treated observations and one for untreated if you have reasons to believe there's heteroskedasticity across the two groups, but homoskedasticity within them. You could also go it by gender, etc. This lets you relax homoskedasticity assumption a bit. Unfortunately, I don't know of a way to do this with margins that takes the variance from the estimation of the residuals into account. Usually this kind of re-transformation adjustments makes the predictions line up better on average, but it does not ensure that predictions for individual cases are particularly good. You can see evidence of that in the range (or if you plot a histogram of the actuals and the predictions).
