[site]: crossvalidated
[post_id]: 444970
[parent_id]: 444960
[tags]: 
This is mode collapse . Fairly classic failure mode of generative models. See, the generator doesn't have to be good, it just has to be good enough . If the whole model has reached a local minimum and, for whatever reason, cannot break on through to another, lower minimum, then it will just settle for its best shot. The why is a big, broad and open problem. In your case, it seems like the GAN Discriminator got very good at... discriminating, in the classes of digits that it could learn, but it's overspecialized. This explains high resolution in some classes, but junk or nothing elsewhere.In more extreme cases, your model might collapse to averaging over all pixels into a wonky, 8-ish shaped figure. Note that MNIST 1, 7 and 9 are basically all variations on a theme of straight line with a horizontal part on top. Your discriminator most likely learned to reject everything with high pixel values outside a vertical-ish region around the center as fakes, with some leeway for the very edges on the horizontal axis. Since there's multiple reasons for failure, there's multiple approaches you can try to throw at it. First thing to try would likely be to beef up the discriminator in terms of sheer layer size/number. Another is that the generator might be what's underpowered - it's good at doing high-res on local scale, but garbage on encoding high-level variance coherently. If you're using a regular dense network, might be worth giving CNNs a shot instead - or even something more exotic like graph networks, and/or hybridizing with VAEs - but note that VAEs are by no means immune from the exact same problem - I'm battling it in one right this moment, in fact.
