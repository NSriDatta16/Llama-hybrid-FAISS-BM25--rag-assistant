[site]: crossvalidated
[post_id]: 641127
[parent_id]: 
[tags]: 
Non constant Feature Importance

I have a financial dataset which has 10 years worth of data. The aim is to build a regressor capable of predicting next year sales. So, if I want to predict sales for 2024, I could use data from 2023, 2022, 2021, and so on... If I use all my features, I'm able to get a decent model, but with some feature selection/engineering, I believe we can have much better model, because some of my features are very noisy. So, I was trying to apply MDA (Mean Decrease accuracy) and analyze feature importance for a Random Forest, but the big thing is, the feature importance keeps varying a lot from year to year, so its really hard to select which features are noise and which are not. For instance, for 2023 the inflation is a very important feature, but back in 2018 it was not that important and was only adding noise. I thought about adding more features or trying to differentiate my features in order to have something more stable, but no success yet. So my question is, what are the best ways to tackle this? Thanks for reading!
