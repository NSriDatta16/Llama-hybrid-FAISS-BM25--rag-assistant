[site]: crossvalidated
[post_id]: 532022
[parent_id]: 
[tags]: 
Maximum likelihood function for time series model

Given Linear Regression model $$ y_i =\beta_0 + \beta_1 x_i + \epsilon_i $$ where $\epsilon_i \sim N(0,\sigma ^2)$ , joint density will be > $\prod f(\epsilon_i)$ since they're all independent. However, in other models like AR , MA they are dependant on the previous value. AR Model $ x_t= \sum_{j=1}^p \phi x_{t-j} + \omega$ where $\omega \sim N(0,\sigma^2)$ . I know we will use the rule of $p(y|x)=p(x,y)/p(x)$ to get the joint density, but I can't get my head around how to can do it recursively. I have read this paper "http://mayoral.iae-csic.org/timeseries_insead/handout3_armaestimation_irfs_arch.pdf" and i have some questions : $X2|(X1=x1) \sim N(c+\phi x1,\sigma^2)$ => i know mean and variane for x1 , but not sure how did they get this conditional distrubtion? then they mentioned that the joint distribution for $x1 , x2 ,x3$ $f x3 ,x2 ,x1 = fx3|x2,x1 * fx2|x1 * fx1$ this makes since , but then they mentioned that over $t$ observation the equation will be $fx_T , x_{T-1} .. x_1 = fx_1 * _{t=2} ^ T fx_t|x_{t-1}$ again not sure how this adds up !
