[site]: datascience
[post_id]: 36256
[parent_id]: 36238
[tags]: 
The predictions are based on what you feed in as training outputs and the activation function. For example, with 0-1 input and a sigmoid activation function for the output with a binary crossentropy loss, you would get the probability of a 1. Depending on the cost of getting the decision wrong in either direction you can then decide on how you deal with these probabilities (e.g. predict category "1", if the probability is >0.5 or perhaps already when it's >0.1). From what you describe, you had 0-1 input and presumably assumed a linear activation for your output layer (perhaps with a mean-squared-error loss?). This means, you assumed a regression problem, where the output is directly a predicted number (that can be any real number from in $(-\infty, \infty$). I'd assume that was not what you intended and you might want what I mentioned in the first paragraph instead.
