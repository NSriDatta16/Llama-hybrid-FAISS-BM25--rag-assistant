ts, as well as transnational government and non-government organizations to ensure AI is ethically applied. AI ethics work is structured by personal values and professional commitments, and involves constructing contextual meaning through data and algorithms. Therefore, AI ethics work needs to be incentivized. Intergovernmental initiatives The European Commission has a High-Level Expert Group on Artificial Intelligence. On 8 April 2019, this published its "Ethics Guidelines for Trustworthy Artificial Intelligence". The European Commission also has a Robotics and Artificial Intelligence Innovation and Excellence unit, which published a white paper on excellence and trust in artificial intelligence innovation on 19 February 2020. The European Commission also proposed the Artificial Intelligence Act, which came into force on 1 August 2024, with provisions that shall come into operation gradually over time. The OECD established an OECD AI Policy Observatory. In 2021, UNESCO adopted the Recommendation on the Ethics of Artificial Intelligence, the first global standard on the ethics of AI. Governmental initiatives In the United States the Obama administration put together a Roadmap for AI Policy. The Obama Administration released two prominent white papers on the future and impact of AI. In 2019 the White House through an executive memo known as the "American AI Initiative" instructed NIST (the National Institute of Standards and Technology) to begin work on Federal Engagement of AI Standards (February 2019). In January 2020, in the United States, the Trump Administration released a draft executive order issued by the Office of Management and Budget (OMB) on "Guidance for Regulation of Artificial Intelligence Applications" ("OMB AI Memorandum"). The order emphasizes the need to invest in AI applications, boost public trust in AI, reduce barriers for usage of AI, and keep American AI technology competitive in a global market. There is a nod to the need for privacy concerns, but no further detail on enforcement. The advances of American AI technology seems to be the focus and priority. Additionally, federal entities are even encouraged to use the order to circumnavigate any state laws and regulations that a market might see as too onerous to fulfill. The Artificial Intelligence Research, Innovation, and Accountability Act of 2024 was a proposed bipartisan bill introduced by U.S. Senator John Thune that would require websites to disclose the use of AI systems in handling interactions with users and regulate the transparency of "high-impact AI systems" by requiring that annual design and safety plans be submitted to the National Institute of Standards and Technology for oversight based on pre-defined assessment criteria. The Computing Community Consortium (CCC) weighed in with a 100-plus page draft report â€“ A 20-Year Community Roadmap for Artificial Intelligence Research in the US The Center for Security and Emerging Technology advises US policymakers on the security implications of emerging technologies such as AI. In Russia, the first-ever Russian "Codex of ethics of artificial intelligence" for business was signed in 2021. It was driven by Analytical Center for the Government of the Russian Federation together with major commercial and academic institutions such as Sberbank, Yandex, Rosatom, Higher School of Economics, Moscow Institute of Physics and Technology, ITMO University, Nanosemantics, Rostelecom, CIAN and others. Academic initiatives Multiple research institutes at the University of Oxford have centrally focused on AI ethics. The Future of Humanity Institute focused on AI safety and the governance of AI before shuttering in 2024. The Institute for Ethics in AI, directed by John Tasioulas, whose primary goal, among others, is to promote AI ethics as a field proper in comparison to related applied ethics fields. The Oxford Internet Institute, directed by Luciano Floridi, focuses on the ethics of near-term AI technologies and I