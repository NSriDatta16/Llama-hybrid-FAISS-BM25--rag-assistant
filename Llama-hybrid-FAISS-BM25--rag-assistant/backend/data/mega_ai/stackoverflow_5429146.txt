[site]: stackoverflow
[post_id]: 5429146
[parent_id]: 5429039
[tags]: 
Regardless of the data structure you're going to use, your memory consumption is never going to drop below the memory required to store all your data. Have you calculated how much memory it is required to store one instance class object? Your huffman encoding is a space-saving optimization, which means that you are eliminating a lot of duplicated data within your class objects yourself. This has nothing to do with the data structure you use to hold your data. This depends on how your data itself is structured so that you can take advantage of different space-saving strategies (of which huffman encoding is one out of many possibilities, suitable for eliminating common prefixes and the data structure used to store it is a tree). Now, back to your question. Without optimizing your data (i.e. objects), there are things you can watch out to improve memory usage efficiency. Are all our objects of similar size? Did you simply run a loop, allocate memory on-the-fly, then insert them into a list, like this: foreach (var obj in collection) { myList.Add(new myObject(obj)); } In that case, your list object is constantly being expanded. And if there is not enough free memory at the end to expand the list, .NET will allocate a new, larger piece of memory and copies the original array to the new memory. Essentially you end up with two pieces of memory -- the original one, and the new expanded one (now holding the list). Do this many many many times (as you obviously need to for GB's of data), and you are looking at a LOT of fragmented memory spaces. You'll be better off just allocating enough memory for the entire list at one go. As an afternote, I can't help but wondering: how in the world are you going to search this HUGE list to find something you need? Shouldn't you be using something like a binary tree or a hash-table to aid in your searching? Maybe you are just reading in all the data, perform some processing on all of them, then writing them back out...
