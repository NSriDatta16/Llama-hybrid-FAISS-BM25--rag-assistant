[site]: crossvalidated
[post_id]: 226973
[parent_id]: 
[tags]: 
Comparing variability between conditions

Lets say I measure peoples reaction time across 2 manipulations (condition 1 and condition 2) within subjects (i.e. the same participant completes both conditions). My prediction is the RT measure in condition 2 is significantly more variable than it is in condition 1 A bit more detail about my setup...each person completes 5 trials per condition. Within each trial, they are pressing a button in response to a stimulus. They do this 20 times each trial, and I take the average of the 20, which is their mean reaction time for that trial. Over the course of the experiment, this means I would get 5 mean reaction times per condition (1 for each trial). I then average over these 5 to get a mean RT for that person, for that condition. Repeat for the second condition. Ultimately, I end up with 2 numbers per participant (1 for each condition) which is the mean of (mean) RTs across all the sub trials. I want to see whether the variability of mean RT scores is greater in one condition vs. the other across all of my participants. Here is an example of my data layout: What would be the correct way to test this? Could it simply be an F test, with the Fvalue tested being var(1)/var(2)? Could Levene's test be used for this? Given that condition is a within subjects factor, should I be averaging the sub trials the way that I am? Because if I calculate variance of condition 1, thats the variance across all participants, rather than for the individual subject. So I feel like I'm actually losing the benefit of using a within subjects/repeated measures design by doing this. The reason for doing it this way is due to concerns about violating independence if multiple rows correspond to the same subject
