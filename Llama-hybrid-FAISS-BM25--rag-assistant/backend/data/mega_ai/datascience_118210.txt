[site]: datascience
[post_id]: 118210
[parent_id]: 
[tags]: 
Predicting a next word from a sentence of a different lenght than seen in training

I am building a custom Decoder-only transformer model, which is being trained on the task of Next Word Prediction. The training procedure is analogous to that of chat GPT models - the input to the model is a sentence of length K (say K=30) and the target is this sentence shifted one to the right, e.g.: "I would like a cup of" - input "would like a cup of tea" - output If I train my model on sentences of a specified lenght, say K=30, how will it perform in inference mode when it is provided much shorter sentences, say of length 3?
