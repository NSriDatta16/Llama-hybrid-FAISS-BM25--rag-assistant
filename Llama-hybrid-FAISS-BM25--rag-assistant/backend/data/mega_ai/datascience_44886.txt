[site]: datascience
[post_id]: 44886
[parent_id]: 44884
[tags]: 
Before exploring more sophisticated tools like Spark or Dask, one option would be to read the data in chunks instead of loading the whole file. For example, if you are using pandas the read_csv method accepts chunksize argument. The main idea is that often what you need to do is reduce each chunk down to something much smaller with only the parts you need (some average/count/sum etc.. of some classes) and store a series/array/dict etc accordingly.
