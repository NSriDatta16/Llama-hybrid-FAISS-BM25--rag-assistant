[site]: crossvalidated
[post_id]: 53324
[parent_id]: 
[tags]: 
Spotting trends in time based data

I have a dataset which I need to spot trends in. The actual data refers to operation calls which take a certain amount of time to complete. My client wants to know which operation calls are improving and which are deteriorating over a time period. Each operation call has an entry for each day which shows the average time that call took to return. Date Call Avg duration ----------------------------------- 18/03/2013 Call 1 123ms 19/03/2013 Call 1 156ms 20/03/2013 Call 1 198ms 21/03/2013 Call 1 99ms My current implementation uses (CurrentDayAvgDuration - PrevDayAvgDuration) / âˆš(CurrentDayAvgDuration + PrevDayAvgDuration) for each day and then takes the average of that value over all days but I'm not too sure if the value is relevant. That formula is one I found and plugged in just to try. My question is, how can I calculate a single value per operation call which can be used in comparison with all of the other operation calls to determine which are trending upwards (deteriorating) and which are trending downwards (improving)?
