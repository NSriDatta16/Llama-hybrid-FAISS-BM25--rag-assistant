[site]: crossvalidated
[post_id]: 563321
[parent_id]: 552697
[tags]: 
My difficulties came from the settings/context of the text. Since the text explains what $\mathcal R_k$ are at the beginning of this section (in this paragraph, but not shown in the excerpt), I had thought that classification $\mathcal R_1, \mathcal R_2$ is pre-defined before calculating equation (1.78), and that then we assign $\mathbf x$ to class $\mathcal C_1$ or $\mathcal C_2$ freely, with this assignment being the variable of the minimization problem. It turns out that the classification of whether $\mathbf x$ belongs to $\mathcal R_1$ or $\mathcal R_2$ is unknown before equation (1.78). The underlined sentence actually defines a classification rule. Then, we can prove that this rule achieves a smaller $p$ (mistake) than any other arbitrary classification. The proof is easy (as suggested by the starting word "Clearly"), but I still need to clarify the settings a little bit here: the assumed condition $p({\mathbf x},\mathcal C_1)>p({\mathbf x},\mathcal C_2)$ is pre-defined before calculating equation (1.78). It holds no matter how we assign $\mathbf x$ . So, in the optimal assignment stated in the underlined text, $\mathbf x$ should be assigned to the first integral, i.e., $\mathcal R_1$ , because $p({\mathbf x},\mathcal C_2)$ is smaller. In another arbitrary classification in which $\mathbf x\in\mathcal R_2$ , we should look at the second integral in equation (1.78), where the term in the summation is $p(\mathbf x,\mathcal C_1)$ . From the given condition $p(\mathbf x,\mathcal C_1)>p(\mathbf x,\mathcal C_2)$ , this would result in a larger $p$ (mistake). Note that the assignment of an $\mathbf x$ can be either of the two classes with a probability. At first, I had thought the assignment is deterministic (white or black), which also caused my difficulty in understanding the text.
