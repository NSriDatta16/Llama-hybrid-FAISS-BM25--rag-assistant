[site]: datascience
[post_id]: 102988
[parent_id]: 
[tags]: 
Is the explained variance a good metric for autoencoders?

I want to evaluate how an autoencoder will perform on my data. Now, I can do this with the mean squared error of the decoded data compared to the original data, and this is fine when comparing this autoencoder with other autoencoders, but I was wondering. Wouldn't evaluating the explained variance as seen here be a better metric for evaluating it? That way I could, not only have a more intuitive understanding of how much of the data my autoencoder is learning but also compare it with other dimensionality reduction techniques like PCA and NMF. Is this metric appropriate for this scenario?
