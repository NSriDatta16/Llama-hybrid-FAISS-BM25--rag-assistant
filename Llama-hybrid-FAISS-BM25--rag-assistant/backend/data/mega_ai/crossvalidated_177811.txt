[site]: crossvalidated
[post_id]: 177811
[parent_id]: 
[tags]: 
Is this alternative method to Metropolis-Hastings salvageable? What is it called?

For my application, I need to calculate an integral over a specific distribution. This distribution is obtained by Bayesian inference - the density at $\Theta$ is proportional to $P(\Theta)f(\Theta)$, for a Gaussian prior $P(\Theta)$ and known function $f$ giving the probability of the data given parameters $\Theta$. My understanding is that Metropolis-Hastings is the go-to method for this case, but I've been trying to implement an alternative method which is more intuitive to me, and potentially might converge faster. But I've been having some problems with it, and I wondered if they can be resolved, and how to seek more information. The initial idea is to simply sample particles from the prior $P$, give each particle a weight proportional to $f$, and calculate a weighted average of my desired feature. But if the data indicates parameters which are unlikely according to the prior, this method will require a prohibitive amount of particles, since we will so rarely generate a particle of meaningful weight. So the modification is to have an estimate $Q$ for the posterior distribution (assuming a multivariate Gaussian is adequate for my application), sample from it, and give each particle $\Theta$ a weight of $f(\Theta)\frac{P(\Theta)}{Q(\Theta)}$. This should, if I'm not mistaken, give the correct result on average; and this modification fared well in my tests on toy datasets that exhibit the phenomenon of posterior distribution significantly different from the prior. My problem is that this method performed poorly on mundane datasets. I'm fairly certain this is because some of the generated particles will be outliers (according to $Q$). The correction of dividing by the density of $Q$ gives these particles a huge weight, so at any moment the weighted average can be jerked towards whatever are the values of a generated outlier. So, this brings me back to the titular questions. Can this be fixed, and does this method have a name? I've considering using a uniform $Q$ instead of Gaussian, but if I choose its support too narrow, I will miss out on meaningful regions of the probability space, and if it's too wide, most particles will be wasted on areas outside the meaningful region (and I suspect that any width will be either too narrow or too wide, especially in high dimensions). I've also considered simply ignoring outliers, or maybe limiting their weight, but that seems wrong.
