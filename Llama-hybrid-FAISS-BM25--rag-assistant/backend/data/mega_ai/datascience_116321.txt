[site]: datascience
[post_id]: 116321
[parent_id]: 
[tags]: 
Are There set in stones rules for EDA?

so I'm doing my first Data Science project and I'm having doubts in EDA and data preprocessing. There are several preprocess that I want to do, these are: dealing outliers dealing with missing values, i want to use mean value dealing with imbalanced data removing features that have low correlation towards the target variable (if exist) dealing with highly correlated features but I'm having doubt on which should i do first and which one should i do later. for example, if i deal with outliers first, then impute the missing value with mean, it will certainly yield a different result than if i impute missing value with mean then dealing with the outliers. I searched across the internet, and no one seems to give a throughout guide on this process. Also, is it true that its best practice to split the data first, then do preprocess on training set? if that's so, then why i often found people to standardize the test set?
