[site]: crossvalidated
[post_id]: 312951
[parent_id]: 
[tags]: 
Machine Learning algorithm where variable importance depends on the value of other variables

I am designing an algorithm that can detect cheating in a game of chess. I have a database of players who have been flagged by moderators as cheating, along with a number of game-level characteristics such as move times and move accuracy (as determined by a chess engine) for both black and white. Let's specify a simple regression: cheatflag ~ whiteMoveTime + blackMoveTime + whiteMoveAccuracy + blackMoveAccuracy Let's say cheatflag is a factor-level variable that is 0 if no cheater, 1 if white is the cheater, 2 if black is the cheater. The issue is that the predictive value of variables like whiteMoveTime and whiteMoveAccuracy depends crucially on who is doing the cheating. If white is cheating, those variables should have different coefficients than if black is doing the cheating. As far as I know, running most blackbox algorithms will derive coefficients that average across all the cases of cheating without understanding the hierarchical nature of the variables. This problem has a Bayesian flavor with some kind of conditional assumption -- if black is cheating, then these variables matter; if white is cheating, these variables matter, and so on. I know I could run two separate machine learning models, one for white cheaters and one for black cheaters, but I feel that that throws out very useful information that a single ML model would be able to capture. How can I deal with this issue?
