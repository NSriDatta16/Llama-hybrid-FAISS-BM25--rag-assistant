[site]: datascience
[post_id]: 17765
[parent_id]: 17629
[tags]: 
A suggestion I give is to change the layers of CNN. You have 3 CNN layers, all sequentially added acting on the same shape and outputting the same output shape with same filter size. What you can try is to change the filter size and using multiple filter sizes to catch different features of different sizes. For this, try this model: main_input = Input(shape=input_shape, name="main input") flattened_outputs = [] for i in filter_sizes: conv_filter_i = Convolution1D(no_of_filters, i, border_mode='same', activation='relu', W_constraint=maxnorm(3))(main_input) pooling_i = MaxPooling1D(pool_length=2)(conv_filter_i) flattened_i = Flatten()(pooling_i) flattened_outputs.append(flattened_i) merged_conv_outputs = merge(flattened_outputs, mode="concat") softmax = Dense(output_shape, activation="softmax")(merged_conv_outputs) model = Model(input=main_input, output=softmax) model.compile(loss='mean_squared_error',optimizer=optimizer_mode) Note: change the dimensions as necessary. Apart from this, I suggest you to use Dropout layer. It helps a lot according to my personal experience. Also, do use adam optimizer. Experiment with various pooling mechanisms. Remember that there is a lot of experimentation that has to go on, so try various other parameters and filter sizees too.
