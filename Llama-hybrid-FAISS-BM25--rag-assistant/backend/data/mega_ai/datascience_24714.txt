[site]: datascience
[post_id]: 24714
[parent_id]: 24689
[tags]: 
Weight Initialization Weights can be initialized by either setting them all to zero. Or by setting them randomly using a Gaussian distribution centered at 0 with a variance similar to the values of your input features. Is every initialization going to give you the same results? No. Neural networks (NNs) converge to a local minimum. Thus, different initialization of the weights will cause the loss function to be minimized to a different value. If you are unhappy with your results you can always do random restarts with different weight initialization.
