[site]: stackoverflow
[post_id]: 5411089
[parent_id]: 5410811
[tags]: 
That size puts you in the VLDB territory (very large databases). Things are fundamentally different at that altitude. Your question cannot be answered without the full requirements of the responsibilities of your application. You need to design for performance with respect to what your application should DO with the data. My advice is to get someone onboard who have previous experience, or you are close to 100% guaranteed to fail. If you go with Oracle, it provides several types of partitioning that you will want to use very carefully. You need partitions for administrative purposes (moving data, building indexes, recovering data) as well as for query performance: Range partitioning, for example by a date range List partitioning, for storing slices of data say country-wise ('SE', 'US', 'GB') Hash partitioning. Stores your data in one of the partitions based on a hash function Or any combination of the above Also, you need someone who knows how to build and configure a monster machine with truly awesome I/O throughput. You need more than 1GB/s, which isn't very cheap when you also need to store 200 TB. Actually, if those 200 TB are table data only, you will need to double or triple that to be able to create indexes, aggregate tables, backups etc. Sorry I couldn't give you a solution ready for use, but I wanted to make sure you understand that you are not just building an above average sized database. It is massive!
