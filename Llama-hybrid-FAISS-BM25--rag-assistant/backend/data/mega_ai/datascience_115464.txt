[site]: datascience
[post_id]: 115464
[parent_id]: 115455
[tags]: 
Arima and LSTM are very different and there could be some tips to improve results. Have you tried relative values instead of raw values? For instance: #Raw values: raw=[1200, 1300, 1250, 1370] #Relative (or differential) values: diff=[+100,-50,+120] Sometimes, raw values like 1400 could alter the results for ARIMA and LSTM differently. On the other hand, LSTM could have bad predictions with noisy data. Some smoothing could improve results, but it depends on the kind of data. Finally, are you trying to forecast 30 days in a single shot? Most predictions focus on 1-day forecast and set their precision on the sequential results from one day to another on the 30 days of validation data. If your aim is to get accurate long-term forecasting, ARIMA and LSTM might not be the best solutions (overall ARIMA), because they have their own structural limitations. This could explain also why LSTM results have a gap with real results: some intern mechanisms have limited memory and wrongly predict important decreases or decreases of values. The shape result of LSTM seems correct, but there is a small shift in Y of 10 because it initially predicted a smaller decrease. LSTM is quite difficult to understand: all I can say is that weights are connected to each other and peaks are more difficult to predict because of those dependencies. I recommend reading the initial paper, it's very interesting: https://www.researchgate.net/publication/13853244_Long_Short-term_Memory My advice is to lose accuracy by grouping values (ex: make a prediction of weeks instead of days) or use long-term models like those ones: https://towardsdatascience.com/extreme-event-forecasting-with-lstm-autoencoders-297492485037 https://thuijskens.github.io/2016/08/03/time-series-forecasting/ https://arxiv.org/pdf/2210.08244.pdf
