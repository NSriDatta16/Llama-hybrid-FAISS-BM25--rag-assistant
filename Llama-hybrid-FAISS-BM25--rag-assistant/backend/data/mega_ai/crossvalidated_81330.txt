[site]: crossvalidated
[post_id]: 81330
[parent_id]: 81328
[tags]: 
Here are a few quick Google hits... PAC-Bayes Analysis: Background and Applications Probably Approximately Correct Learning and Vapnik-Chervonenkis Dimension Probably approximately correct learning on Wikipedia Overview of the Probably Approximately Correct (PAC) Learning Framework From this last one, a quote: A more refined, Bayesian extension of the PAC model is explored in [26]. Using the Bayesian approach involves assuming a prior distribution over possible target concepts as well as training instances. Given these distributions, the average error of the hypothesis as a function of training sample size, and even as a function of the particular training sample, can be defined. Also, $1 - \delta$ confidence intervals like those in the PAC model can be defined as well. [26] $=$ W. Buntine, A Theory of Learning Classification Rules . PhD thesis, University of Technology, Sydney, 1990.
