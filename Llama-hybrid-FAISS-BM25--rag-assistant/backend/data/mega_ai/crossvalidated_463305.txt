[site]: crossvalidated
[post_id]: 463305
[parent_id]: 
[tags]: 
Interpretation of y-axis in partial dependence plot

First off, I know there are many questions on this site similar to this one. I've read them, and have not been able to find a solution. In Elements of Statistical Learning , the following figure shows partial dependence plots for California Housing Data: The text defines partial dependence of $f(X)$ on $X_S$ as $f_S(X_S) = E_{X_C}f(X_S, X_C)$ , the marginal average of $f$ . I'm wondering how to interpret the y-axis of these plots. Based on the definition, I would expect the y-axis to be the housing price, as the given x-axis variables vary, while accounting for the averages of all other variables. But that can't be the case, because the y-axis has negative values, and all values are in the range -1 to 2. The scikit-learn documentation shows how to make the plots here: https://scikit-learn.org/stable/auto_examples/inspection/plot_partial_dependence.html#sphx-glr-auto-examples-inspection-plot-partial-dependence-py . Other questions have asked specifically about the implementation in R for classification, which uses a logit, and explains the negative values. But I'm wondering about the regression case, as described in Elements .
