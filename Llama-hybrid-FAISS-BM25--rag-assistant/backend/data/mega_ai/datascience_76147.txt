[site]: datascience
[post_id]: 76147
[parent_id]: 76133
[tags]: 
Transformer based architectures are some of the most popular in NLP right now. You can check this blog post for more information: https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html Other than performance, one major advantage of transformers is that operations can be parallelized, making it much faster than RNNs/LSTMs.
