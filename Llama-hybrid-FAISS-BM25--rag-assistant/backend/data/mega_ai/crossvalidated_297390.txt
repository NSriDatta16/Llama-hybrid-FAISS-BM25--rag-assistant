[site]: crossvalidated
[post_id]: 297390
[parent_id]: 297380
[tags]: 
Not being able to know what solution generalizes best is an issue, but it shouldn't deter us from otherwise using a good solution. Humans themselves often do not known what generalizes best (consider, for example, competing unifying theories of physics), but that doesn't cause us too many problems. It has been shown that it is extremely rare for training to fail because of local minimums. Most of the local minimums in a deep neural network are close in value to the global minimum, so this is not an issue. source But the broader answer is that you can talk all day about nonconvexity and model selection, and people will still use neural networks simply because they work better than anything else (at least on things like image classification). Of course there are also people arguing that we shouldn't get too focused on CNNs like the community was focused on SVMs a few decades ago, and instead keep looking for the next big thing. In particular, I think I remember Hinton regretting the effectiveness of CNNs as something which might hinder research. related post
