[site]: crossvalidated
[post_id]: 185318
[parent_id]: 185311
[tags]: 
What you are actually doing with the two-step process you've outlined is sampling from the joint distribution $p(x_{new}, \mu \thinspace | \thinspace x_1, \dots, x_n)$, then ignoring the sampled values of $\mu$. It's not altogether intuitive, but, by ignoring the sampled values of $\mu$, you are integrating over it. A simple example may make this clear. Consider sampling from $p_X(x \thinspace | \thinspace y) = 1/y \thinspace \text{I}(0,y)$, uniform over $(0,y)$, and $p_Y(y) = 1$, uniform over $(0,1)$. You should be able to see, intuitively, what $\int_0^1p_X(x \thinspace | \thinspace y)p_Y(y)dy$ will look like. We construct some simple, horribly inefficient, R code (written this way for expository purposes) to generate the samples: samples samples is clearly a random sample from the joint distribution of $x$ and $y$. We ignore the $y$ values and construct a histogram of only the $x$ values, which looks like: which hopefully matches your intuition. If you think carefully about it, you will see that the samples of $x$ do not depend upon any particular value of $y$. Instead, they depend (collectively) on a sample of values of $y$. This is why ignoring the $y$ values is equivalent to integrating out $y$, at least from a random number generation perspective. On the other hand, consider what happens if you average. You'll get just one number from your Monte Carlo run, namely, the average of the $x_{new}$ samples. This isn't what you want (in your case)!
