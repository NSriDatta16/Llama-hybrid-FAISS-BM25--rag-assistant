[site]: crossvalidated
[post_id]: 299177
[parent_id]: 299062
[tags]: 
You should pay attention to measures of your models' performance on the test data set. I think that your question stems from confusion over the purpose of the training, validation and test sets. Two related questions on this site you might look at are What is the difference between test set and validation set and Difference between training, test and holdout set data mining model building . For the specifics of your question, it suffices to run through the purpose of each data set. Training Data Set : this is the data set that you use to build your model. In this case SVM, RF, LR or k-NN. We don't simply accept this model, however, because it may be underfitted or overfitted to the training data set. Validation Data Set : this is the data set that you use to select model parameters. Different models have different parameters that might need to be tuned (such a the 'k' in k-NN or the number of trees in RF) and the validation data set is used to choose select the best values for these parameters. Unfortunately, this means that this data is used to train/select the model and performance on the validation data set can't be used to judge the quality of the model for the same reasons that performance on the training data set couldn't be used. Test Data Set : this is the data set that you use to judge the quality of your model. It has not been seen at any step of the training or model selection process and should provide a good test of your model's ability to capture the relevant patterns in the data while also generalizing to unseen examples. To summarize: the test data set does not act as a reassurance, it acts as your evaluation. It is the first time that your model is faced with data that has not been used to train/select the model and it is how you are able to judge your model's performance.
