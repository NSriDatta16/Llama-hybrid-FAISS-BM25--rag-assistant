[site]: crossvalidated
[post_id]: 248336
[parent_id]: 
[tags]: 
Expected test error

According to Deep Learning (Ian Goodfellow and Yoshua Bengio and Aaron Courville,p.111, available online): 1.Assume that train and test set are indentically distributed(IID assumption). 2.Then: ''We sample the training set, then use it to choose the parameters to reduce training set error, then sample the test set. Under this process, the expected test error is greater than or equal to the expected value of training error" Could you provide me with mathematical proof of this statement?
