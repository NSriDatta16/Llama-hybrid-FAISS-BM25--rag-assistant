[site]: crossvalidated
[post_id]: 287312
[parent_id]: 287307
[tags]: 
Yes, I suspect your model is useless. From your description, I get that your variables are not fully detrended. They probably all have unit roots (Breush Pagan test, White test) and are not truly stationary. And, your solution of adding a trend variable results in a model that has numerous specification issues. First thing you may need to do is fully detrend your variables. One popular method is to compute the % change in the variable from one period to another. Another method is to compute the First Difference in Natual Log from one period to another. Both those variables transformations will result in typically fully detrended variables that are truly stationary and do not have a unit root. When you deal with fully detrended variables instead of non-stationary nominal variables, you will notice that the R Square of your regression drops markedly. Also, the statistical significance of your independent variables may drop a lot too. But, such a model is real and well specified. The residuals of such models are typically well behaved (stationary enough, not too autocorrelated, not too heteroskedastic). Meanwhile, your original model with nominal time series variables that are not detrended may very well have an R Square close to 1. Some of the variables will likely be multicollinear as you indicated. And, residuals will be too highly autocorrelated (Durbin Watson score often under 1.2). This is a classic "spurious" regression as Clive Granger (original paper on the subject) would say whereby you have a regression with a very high R Square that has no real meaning. The relationships are illusory and are simply driven by the fact that any nominal time series over time does grow. But, it does not mean that two such variables have any meaningful relationship.
