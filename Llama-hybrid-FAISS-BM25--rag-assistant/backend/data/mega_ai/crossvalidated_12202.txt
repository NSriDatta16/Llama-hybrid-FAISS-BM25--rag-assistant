[site]: crossvalidated
[post_id]: 12202
[parent_id]: 12200
[tags]: 
A common technique before applying PCA is to subtract the mean from the samples. If you don't do it, the first eigenvector will be the mean. I'm not sure whether you have done it but let me talk about it. If we speak in MATLAB code: this is clear, clf clc %% Let us draw a line scale = 1; x = scale .* (1:0.25:5); y = 1/2*x + 1; %% and add some noise y = y + rand(size(y)); %% plot and see subplot(1,2,1), plot(x, y, '*k') axis equal %% Put the data in columns and see what SVD gives A = [x;y]; [U, S, V] = svd(A); hold on plot([mean(x)-U(1,1)*S(1,1) mean(x)+U(1,1)*S(1,1)], ... [mean(y)-U(2,1)*S(1,1) mean(y)+U(2,1)*S(1,1)], ... ':k'); plot([mean(x)-U(1,2)*S(2,2) mean(x)+U(1,2)*S(2,2)], ... [mean(y)-U(2,2)*S(2,2) mean(y)+U(2,2)*S(2,2)], ... '-.k'); title('The left singular vectors found directly') %% Now, subtract the mean and see its effect A(1,:) = A(1,:) - mean(A(1,:)); A(2,:) = A(2,:) - mean(A(2,:)); [U, S, V] = svd(A); subplot(1,2,2) plot(x, y, '*k') axis equal hold on plot([mean(x)-U(1,1)*S(1,1) mean(x)+U(1,1)*S(1,1)], ... [mean(y)-U(2,1)*S(1,1) mean(y)+U(2,1)*S(1,1)], ... ':k'); plot([mean(x)-U(1,2)*S(2,2) mean(x)+U(1,2)*S(2,2)], ... [mean(y)-U(2,2)*S(2,2) mean(y)+U(2,2)*S(2,2)], ... '-.k'); title('The left singular vectors found after subtracting mean') As can be seen from the figure, I think you should subtract the mean from the data if you want to analyze the (co)variance better. Then the values will not be between 10-100 and 0.1-1, but their mean will all be zero. The variances will be found as the eigenvalues (or square of the singular values ). The found eigenvectors are not affected by the scale of a dimension for the case when we subtract the mean as much as the case when we do not. For instance, I've tested and observed the following that tells subtracting the mean might matter for your case. So the problem may result not from the variance but from the translation difference. % scale = 0.5, without subtracting mean U = -0.5504 -0.8349 -0.8349 0.5504 % scale = 0.5, with subtracting mean U = -0.8311 -0.5561 -0.5561 0.8311 % scale = 1, without subtracting mean U = -0.7327 -0.6806 -0.6806 0.7327 % scale = 1, with subtracting mean U = -0.8464 -0.5325 -0.5325 0.8464 % scale = 100, without subtracting mean U = -0.8930 -0.4501 -0.4501 0.8930 % scale = 100, with subtracting mean U = -0.8943 -0.4474 -0.4474 0.8943
