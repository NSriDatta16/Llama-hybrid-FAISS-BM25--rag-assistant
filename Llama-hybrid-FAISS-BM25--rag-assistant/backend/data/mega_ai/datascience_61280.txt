[site]: datascience
[post_id]: 61280
[parent_id]: 41175
[tags]: 
Disclaimer: I will try to answer the question but promote Image Augmentation Library Albumentations , which may collaborators and I develop in free time and which we believe is the best image augmentation library at the market :) There are many ways to augment the image data. Spatial transforms: Crops, Flips, Transpose, Elastic transform, ShiftScaleRotate, etc. Pixel level transforms: BrightnessContrast, Gamma, shifts in RGB space, shifts in HSV space, JpegCompression, weather transforms (say add rain to the image), etc. Which transformations to use and what parameters to choose is art, rather than science. Those transformations that do not change data distribution: must-have. Those that change: may work may not. If you have a lot of experience they will, if not; they will make models weaker :) Spatial transformations: If your target is invariant to horizontal flips, say you need to classify dogs versus cats or perform segmentation on a street view imagery - horizontal flips should be used. If you work with satellite imagery, horizontal or vertical flips, transpose, and rotations are good choices. For some medical imagery, you may add elastic, and grid transforms. Another standard spatial transform is RandomResizedCrop and ShiftScaleROtate. It helps to deal with the fact that your objects may have different sizes. In your street view imagery, you may have a pedestrian in front of you, or far from the camera => you may zoom in / zoom out from an image and crop a piece that fits your network input. As long as your parameters for zoom are not too extreme, it serves as a good regularizer and improves the quality of your models. Color Transforms These are trickier. They solidly move you away from your original data distribution, but in many (but not all) situations, it adds value. I would recommend trying to play with the parameters of your transform and check if the transformed image looks more or less natural. One day I was working on a Kaggle competition for which applications of the JpegCompression with different strength was a must-have. Blog post with the solution. It may happen that for the problem that you are facing some similar not widely used transform may be essential. But it not the end of the story. For many problems, we know that your train and test data have different distributions. Ex: Data is split by the city, and you train on the data collected in Moscow and predict on the data from Paris. Your train comes from one hospital and test set from the other. Or you want extra confidence that your models will be more robust when the distribution changes in the production pipeline. In these cases, you can go hardcore and augment your images in a bizarre, non-realistic way. But this is an advanced technique. It is widely used to win Deep Learning Challenges and beat existing State Of The Art. For most problems, you may safely use flips, crops, ShiftScaleRotate, BrightNessContrast, and focus on other parts of your Deep Learning pipeline. In the Albumentations library, we prepared a list of the jupyter notebooks that show how to apply transforms on your images. Examples on the applications of albumentations to images, masks, bounding boxes, keypoints, weather transforms and multiple targets problems. Feel free to check and submit an issue if something is not clear :)
