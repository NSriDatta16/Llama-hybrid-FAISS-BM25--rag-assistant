[site]: crossvalidated
[post_id]: 601433
[parent_id]: 575367
[tags]: 
Observe that the output of adfuller(B) shows 40 as the number of observations although the length of the original series is 41. In order to test for the unit root, the Dickey-Fuller test represents time series as an auto-regressive process of the first order and transforms it via differencing: $$ \Delta y_t = \gamma y_{t-1} + \varepsilon_t $$ where $\Delta y_t$ is the first-order difference with respect to $y_t$ , $y_{t-1}$ is the previous value, and $\varepsilon_t$ is the white noise. Since the original time series is differenced, the number of observations is reduced by 1. The Augmented Dickey-Fuller test is just an extension of the Dickey-Fuller test which allows representing the first-order difference as an autoregressive process (by including the lags of itself), and thus account for autocorrelation. $$ \Delta y_{t} = \gamma y_{t-1} + \delta_1 \Delta y_{t-1} + ... + \delta_{p-1} \Delta y_{t-p+1} + \varepsilon_t $$ where $p$ is the order of the original autoregressive process. The value of usedlag in the output of the function adfuller() represents the number of additional lagged differences in the equation above: if it's 0, then no additional lags are included, and the model is fit as in the original Dickey-Fuller test. In your example adfuller(A) used 7 lags and thus reduced the number of the differenced values to 33 (40 minus 7). The statsmodels' implementation of adfuller() by default selects the best fit among the models with different number of lagged differences starting with 0, and up to the number specified in the maxlag parameter according to the Akaike information criterion. This can be overridden though by setting autolag as None , and specifying a certain number in maxlag which will be then used as $(p-1)$ .
