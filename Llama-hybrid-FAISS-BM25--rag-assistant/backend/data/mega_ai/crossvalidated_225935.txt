[site]: crossvalidated
[post_id]: 225935
[parent_id]: 225843
[tags]: 
You don't have to get predicted categories from a logistic regression model. It can be fine stay with predicted probabilities. If you do get predicted categories, you should not use that information to do anything other than say 'this observation is best classified into this category'. For example, you should not use 'accuracy' / percent correct to select a model. Having said those things, $.50$ is rarely going to be the optimal cutoff for classifying observations. To get an intuitive sense of how this could happen, imagine that you had $N=100$ with $99$ observations in the positive category. A simple, intercept-only model could easily have $49$ false negatives when you use $.50$ as your cutoff. On the other hand, if you just called everything positive, you would have $1$ false positive, but $99\%$ correct. More generally, logistic regression is trying to fit the true probability positive for observations as a function of explanatory variables. It is not trying to maximize accuracy by centering predicted probabilities around the $.50$ cutoff. If your sample isn't $50\%$ positive, there is just no reason $.50$ would maximize the percent correct.
