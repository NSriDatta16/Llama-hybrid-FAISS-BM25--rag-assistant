[site]: crossvalidated
[post_id]: 610245
[parent_id]: 
[tags]: 
Combined Shapley Values for Probability Models

Using Python I have created two separate XGBoost probability models. From these two models, I compute a final value by multiplying the outputs (probabilities) together to give a probability of both events happening at the same time. I would like to be able to explain the output of the final value using Shapley values computed using the shap library ( https://shap-lrjball.readthedocs.io/en/latest/index.html ). Previously I have attempted to use shap.KernelExplainer to explain the output function. This works, but I have found this to be very slow when I use enough of my dataset to create an accurate background for the explainer. I have the shap.Explainer for both of the individual models which work quickly. I am attempting to find a way to use the shap values of the individual models to create the final shap values, but am struggling to do so. For example: Model_1 Probability = 0.5, Feature_1 Contribution = 0.3, Feature_2 Contribution = 0.2 Model_2 Probability = 0.2, Feature_1 Contribution = 0.05, Feature_2 Contribution = 0.15 Computed Probability = 0.1, Feature_1 Contribution = ?, Feature_2 Contribution = ? Is there a formula to determine the contributions of the individual features to the computed probability?
