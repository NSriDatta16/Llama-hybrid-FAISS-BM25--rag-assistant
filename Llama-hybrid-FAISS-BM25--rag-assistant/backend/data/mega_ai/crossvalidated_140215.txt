[site]: crossvalidated
[post_id]: 140215
[parent_id]: 
[tags]: 
why boosting method is sensitive to outliers

I found many articles that state that boosting methods are sensitive to outliers, but no article explaining why. In my experience outliers are bad for any machine learning algorithm, but why are boosting methods singled out as particularly sensitive? How would the following algorithms to rank in terms of sensitivity to outliers: boost-tree, random forest, neural network, SVM, and simple regression methods such as logistic regression?
