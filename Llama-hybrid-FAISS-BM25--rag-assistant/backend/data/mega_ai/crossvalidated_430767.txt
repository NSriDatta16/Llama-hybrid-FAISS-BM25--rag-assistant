[site]: crossvalidated
[post_id]: 430767
[parent_id]: 430762
[tags]: 
Markov models are used when you believe there is a dependence between the current state and the immediately prior state. In your example, if you believe that playing tennis on day $t-1$ makes it more or less likely that you will play tennis on day $t$ a Markov model can help. The simplest type of Markov model is the Markov Chain where the system is completely observable and the current state only depends on the prior state. In this type of model the weather would not effect your probability of playing tennis on day $t$ , the only thing that matters is if you played tennis on day $t-1$ . What is more likely to be useful for your problem is something like a Hidden Markov Model where there is a hidden state (which may include factors like weather) which effect the observed state of your system (playing tennis). If on the other hand you have no reason to believe that your state on the day prior has an impact on the state on the current day, then Markov models won't help. The reason for using a time series type model is because you believe the time points are not independent from one another (i.e. the IID assumptions of most traditional models are broken). If this is not the case then it shouldn't matter what day your data points come from (e.g. if you shuffled around your time stamps you would lose no information). In this scenario, other methods like decision trees or SVMs will be of better use.
