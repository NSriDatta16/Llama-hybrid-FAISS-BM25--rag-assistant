[site]: datascience
[post_id]: 64592
[parent_id]: 
[tags]: 
Explanation behind the calculation of accuracy in deep learning model

I am trying to model an image segmentation problem using convolutional neural network. I came across code in Github which I am not able to understand the meaning of following lines of codes for calculation of accuracy - def new_test(loaders,model,criterion,use_cuda): for batch_idx, (data,target) in enumerate(loaders): output = model(data) ###Accuracy _, predicted = torch.max(output.data, 1) total_train += target.nelement() correct_train += predicted.eq(target.data).sum().item() model(data) outputs a tensor of shape B * N * H * W B = Batch Size N = Number of segmentated classes H,W = Height,Width of an image
