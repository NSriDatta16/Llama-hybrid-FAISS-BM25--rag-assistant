[site]: datascience
[post_id]: 104350
[parent_id]: 104344
[tags]: 
Multinomial logistic regression, supported in SKLearn in Python and VGAM in R, extends binary logistic regression in a way very similar to how softmax in deep learning extends sigmoid. Instead of considering the response variable as binomial, as logistic regression does, multinomial logistic regression considers the response variable to be multinomial (stunning, I know). The regression coefficients then get fitted using the usual method of maximum likelihood estimation (equivalent to minimizing crossentropy loss), and the model returns the probabilities of each category, same as logistic regression. The usual machine learning methods have multiclass extensions, however: SVM, random forest, k-nearest neighbors, shallow neural networks, etc. You certainly donâ€™t have to jump straight to deep learning.
