[site]: crossvalidated
[post_id]: 174648
[parent_id]: 
[tags]: 
Dimensionality reduction for narrow, tall matrices

I have a matrix with three columns and a lot of rows. The first two columns contain integers N1 and N2. N1 is always {0,1,2,3}, but N2 can vary from let's say -50 to 50. It's always the same N1s, but usually a different set of N2s. Finally, the third column is a real number, let's call it R. It monotonically increases with both N1 and N2. I have a bunch of these matrices. I want to pull out the smallest amount of numbers needed to reconstruct the matrix within some error tolerance (so that I can then compare the numbers of different matrices and use them for prediction). It's common in my field to regress R linearly with N2 for each N1 and pull out the slope. However, there is a substantial amount of information lost with this procedure since they are not strictly linear. Is there a more principled procedure to do something like this?
