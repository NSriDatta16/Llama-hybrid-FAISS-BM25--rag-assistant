[site]: crossvalidated
[post_id]: 564782
[parent_id]: 
[tags]: 
Adding predictors to an intercept-only model

I'm currently testing out a logistic regression model I plan to use to analyse the results of an experiment I'm yet to conduct. I'm running it in R. My experiment is going to measure whether animals recognise, and therefore choose, a rewarding option (e.g. a blue versus red box, in which only one contains food). The animals will have had a "training" trial to expose them to this option, and then their responses will be recorded in a "test" trial. I first want to test whether they choose this option more often than would be expected by chance. I therefore start with an intercept-only model as follows: model = glm(choice ~ 1, family = "binomial", data = df) This seems to work fine. But I am confused about adding predictor variables to this model. For example, because the side the rewarding option is presented on in the test trial compared to the training trial may have an effect on choice, I have added a predictor called "sideSame", which has two levels: 0 for no/different and 1 for yes/same. I'm running different simulations of the data for different potential outcomes. One simulation I am looking at considered that animals choose the rewarding option in the test trial only when it is on the same side as in the training trial . Code: model2 = glm(choice ~ 1 + sideSame, family = "binomial", data = df) So the summary coefficients are: Intercept: Estimate of roughly 0, P > 0.05 SideSame: Strongly positive estimate, P The intercept is now the probability of animals choosing the rewarding option when the rewarding option is presented on a different side. As expected, it is saying that animals do not choose this option more than can be expected by chance when it is presented on a different side. My issue is that I'm not totally sure how to interpret this. It seems to me to be an interaction (because whether or not they go for a rewarding option - which is, in a way, a treatment even though it is not written as an explanatory variable - depends on which side it's presented on. It also seems to be doing the same thing as including an interaction term does if I included another predictor: if I added, say, animal age (adult or juvenile), the interaction term would tell me how much to add on to the coefficient for "juvenile (sideDifferent)" when the side for juveniles is "Same", in the same way that sideSame alone in the model above is telling me how much to add on to the intercept of sideDifferent when the side is "Same". I'm also considering a few other predictors but worry that I might struggle with their interpretation, so I want to be sure this is the right way to model my data. I know an alternative would be to code whether animals choose the LEFT or RIGHT option and include whether the rewarding option was on the left or right as a predictor (as well as different/same), but then including other variables would only tell me about their effect on choice of left or right, which is meaningless, so I think I would have to fit them all as interaction terms. This doesn't seem like a better approach, but I'm unsure. The bottom line is that I need to be able to say definitively whether animals are able to recognise the rewarding option, while also considering potential confounds. Is it appropriate to model my data in this way?
