[site]: crossvalidated
[post_id]: 454544
[parent_id]: 
[tags]: 
Why transform uniform random variables to standard normal random variables?

I have come across a few studies on the topic of forecasting. let $X_t = Y_t|D_{t - 1}$ , where $\{Y_t: t = 1,2,3, \dots\}$ is the series to be forecast one step ahead and where $D_t$ represents all data available to the forecaster up to and including time $t$ . in a system closed to external information $D_t = \{D_0, y_i,\dots, y_t\}$ then $X_t$ will have a forecast distribution functions $F_t, t = 1,2,3,\dots$ given by our model. Suppose $F_t$ is continuous it follows immediately that when our model is correct. $$ U_t = F_t(X_t) $$ with $U_t$ independent uniform [0,1] random variables and $$ V_t = \Phi^{-1}(U_t) $$ are independent normal random variables with $\mathcal{N}(0,1)$ distribution, where $\Phi$ is the standard normal cdf. My question is, why not just do test on the uniform random variables $U_t$ ? rather than transforming and doing normality checks on $V_t$ The above is taken from Smith (1985) Smith, J Q (1985) Diagnostic Checks of Non-standard Time Series Models. Journal of Forecasting. 4 , pg 283-291
