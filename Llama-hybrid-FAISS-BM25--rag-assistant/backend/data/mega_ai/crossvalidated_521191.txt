[site]: crossvalidated
[post_id]: 521191
[parent_id]: 
[tags]: 
How does the pooled output from the output layer in a BERT model reference back to the actual text?

I was wondering if someone can refer to me a source or describe to me how to interpret the 768 sequence of numbers that are derived from the output layer of the BERT Model. Like, what do they mean and is there away to reference them back to the actual text? Like if I have -0.856645 in the 768 sequence, what does this mean? Overall, I'm trying to understand the meaning behind the 768 sequence and how it ties back to the text itself.
