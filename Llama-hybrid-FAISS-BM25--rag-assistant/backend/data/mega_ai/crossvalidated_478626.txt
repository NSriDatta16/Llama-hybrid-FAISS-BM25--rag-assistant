[site]: crossvalidated
[post_id]: 478626
[parent_id]: 476941
[tags]: 
First, you need to know what is the optimal coding , then anything else will be an equivalent or less efficient coding. A sufficient condition for designing an optimal coding is knowing the (exact) true probability, $p(x)$ , for every data, $x$ , in the target system. In practice, we only have access to an estimation, $q(x)$ , of the true probability. As there is always error in estimation, there might be some $x_1$ and $x_2$ such that the $p(x_1) > p(x_2)$ but $q(x_1) . This means that your coding allocates a smaller code to $x_2$ than the code that is allocated to $x_1$ . For example, if you use $p(x)$ then $x_1$ might be coded as 01 and $x_2$ as 011 . But if you use $q(x)$ then $x_1$ is coded as 011 and $x_2$ as 01 . Now, when you are using the system in practice, you need to send more of $x_1$ than $x_2$ and in average you are sending more bits than if you knew the $p(x$ ). So, this KL difference will gives you a hint that , on average, how much more bits your system is consuming. As it's written in the famous book Elements of Information Theory : "If we knew the true distribution $p$ of the random variable, we could construct a code with average description length $H(p)$ . If, instead, we used the code for a distribution $q$ , we would need $H(p)+ D(p||q)$ bits on the average to describe the random variable."
