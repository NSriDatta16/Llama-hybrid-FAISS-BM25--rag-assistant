[site]: crossvalidated
[post_id]: 25821
[parent_id]: 25791
[tags]: 
A regular Bayesian model has the form $p(\theta |y) \propto p(\theta)p(y|\theta)$. Essentially the posterior is proportional to the product of the likelihood and the prior. Hierarchical models put priors on the prior (called a hyperprior) $p(\theta |y) \propto p(y|\theta)p(\theta |\lambda)p(\lambda)$. We can do this as often as we want. See Gelman's " Bayesian Data Analysis " for a good explanation.
