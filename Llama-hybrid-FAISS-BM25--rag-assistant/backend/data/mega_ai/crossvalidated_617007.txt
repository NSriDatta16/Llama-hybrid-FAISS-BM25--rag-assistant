[site]: crossvalidated
[post_id]: 617007
[parent_id]: 
[tags]: 
Distribution of Weighted Sample Variance

Say we have $N$ independent Gaussian variables $X_i$ , each drawn from a mean-zero Gaussian with variance $\sigma_i^2$ , where in this case I assume I know the $\sigma_i^2$ . Define the weighted average as $$ \bar{X} = w \sum_i^N X_i / \sigma_i^2, \ \ w = \left(\sum_i^N \sigma^{-2}_i\right)^{-1}. $$ Then define the weighted sample variance as $$ S^2 = w \sum_i^N (X_i - \bar{X})^2 / \sigma_i^2 $$ In the case that all variances are equal, so that $\sigma_i^2 = \sigma_2$ , this is of course just the standard un-weighted sample variance. Now, the expectation of $S^2$ is simply $w(N-1)$ , where the $(N-1)$ comes about in the same way that we get it in the non-weighted case. We can then consider the quantity $\gamma = S^2 / \langle S^2 \rangle$ to be a "normalized" weighted variance with expectation unity. I'd like to know the distribution of $\gamma$ . In the case that all variances are equal, $\gamma$ can be written $$ \gamma = \frac{N}{N-1} \sum_i^N (Y_i - \bar{Y})^2, $$ where $Y = X/\sigma$ is a standard normally distributed variable. According to this MathWorld article , this ends up having the distribution $$ f(\gamma) = \frac{\beta^\beta}{\Gamma(\beta)} \gamma^{\beta-1} e^{-\beta \gamma}, $$ with $\beta = (N-1)/2$ . This is just a Gamma distribution. But what about the case in which $\sigma_i^2$ can vary for different $i$ ? Having run several simulations, it seems that the distribution of $\gamma$ is precisely the same as in the unweighted case, and thus depends only on $N$ . I have only two problems with this: I can't prove it. Intuitively, I would expect that if I had say $N=100$ , but of those variables, only one had low variance, and the rest had "enormously" high variance, then the distribution should be approximately the same as having $N=1$ . However, the distribution knows nothing about the variances involved, and only about the total number of observations. Most likely my intuition just needs to be sharpened here -- does anyone have a good explanation? EDIT I'm adding some code and a plot here to show the simulation I did: So, here's the simulation code: def simulate(variance: np.ndarray, size=100000): nd = len(variance) w = 1/np.sum(1/variance) Z = np.random.normal(size=(size, nd)) first_term = np.sum(Z**2, axis=1) second_term = np.sum(Z / np.sqrt(variance), axis=1)**2 * w return (first_term - second_term) / (nd - 1) Then, I made a plot where I used three different variance vectors: (i) all ones, (ii) all ones except one at $10^{-5}$ , and (iii) half ones, half $10^{-5}$ . Code for making the plot: N = 100 plt.figure(figsize=(10, 6)) sim_gamma_ones = simulate(np.ones(N)) lopsided_var = np.ones(N) lopsided_var[0] /= 1e5 # very small variance for just one observation sim_gamma_single_good = simulate(lopsided_var) half_var = np.ones(N) half_var[:N//2] /= 1e5 # very small variance for just one observation sim_gamma_half_good = simulate(half_var) plt.hist(sim_gamma_ones, bins=150, histtype='step', label='unweighted', density=True) plt.hist(sim_gamma_single_good, bins=150, histtype='step', label='one reliable obs', density=True) plt.hist(sim_gamma_half_good, bins=150, histtype='step', label='half reliable', density=True) x = np.linspace(0, 5, 500) plt.plot(x, gamma.pdf(x, a=(N-1)/2, scale=2/(N-1)), color='k', lw=1, label='Gamma distribution') plt.title(f"N={N}") plt.legend() The plots:
