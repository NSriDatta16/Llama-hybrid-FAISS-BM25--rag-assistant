[site]: crossvalidated
[post_id]: 345765
[parent_id]: 
[tags]: 
How to handle machine learning inputs that should be considered as a set of vectors, but whose interpretation is order invariant (order agnostic set)

Basically wondering best practices for input modeling and ML algorithm type(s) for inputs that essentially model samples that are a bag/set of "sub-objects", so order does not matter. Think of the kind of 2D input vector that would normally go into an RNN, but in this case the order of the 2nd-degree vectors in the input vector should not affect output. Trying to model a classification problem where there are some number of records R1,...,Rn each with a uniform set of features f1,...,fm in a bag/set that should evaluate the same regardless of the order that the items R1,...,Rn are observed/pulled from the bag. All of the records are related to / interact with each other, but they may also affect the output individually (in terms of relations, think of a simple transitive closure graph with self loops). Eg. say records R are personnel profiles, Ri.fj are features about each person Ri, and the output y is whether some group R1,...,Rn would make a "good" team. A team may not be "good" because either a single person Ri is just bad or there would be some bad interactions between two are more members. My question is, is there some common design pattern for dealing with this (relatively new to machine learning)? I was either going to represent this kind of input as 1) a single big vector of features where a single sample is of the form [R1.f1,...,R1.fm,...,Ri.f1,...,Ri.fm,...,Rn.f1,...,Rn.fm] and feed into something like a simple DNN or DRF (accounting for the fact that order of each set of features does not really matter by creating all permutations of that row as extra samples to train on (treating each [Ri.f1, ..., Ri.fm] subrow as a element for permutation)). Maybe ordering the "subvectors" by alpha order based on feature Ri.f1 for all input vectors and having that just be the way data was always feed to the algorithm would be better than generating artificial permutations? Or 2) break them up into groups , so a single sample looks like like [[R1.f1,...,R1.fm],...,[Ri.f1,...,Ri.fm],...,[Rn.f1,...,Rn.fm]] and feed into an RNN (the problem here seeming to be that it is not order agnostic ; perhaps a CNN would work well here?). Again, is there some common design pattern for dealing with this? Any advice would be appreciated. ---------- Updates ** Adding this extra info in response to some comments discussion: In the "teams" example, they may be of arbitrary size, but can be simplified by only accounting for the first x members. My actual use case is more like looking at line items on a receipt and trying to predict a single outcome associated with that receipt.
