[site]: datascience
[post_id]: 48533
[parent_id]: 
[tags]: 
Why use Variational Autoencoders VAE instead of Autoencoders AE in Anomaly Detection?

I have read many papers that recommend using Variational Autoencoders over Autoencoders since they have a more probabilistic approach and the ability to use KL divergence on the latent dimension. But when trying to test both networks I find that the variability of the output in Variational Autoencoders is reducing the accuracy of the network and I am getting better results when using Autoencoders . I am still working on very simple data and training my network on normal images that do not have any augmentation or changing background. Does the performance of Variational Autoencoders increase with harder data or is there any other reason to choose it over Autoencoders ? Or do Autoencoders perform better in anomaly detection ?
