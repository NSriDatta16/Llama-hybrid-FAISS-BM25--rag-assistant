[site]: crossvalidated
[post_id]: 575851
[parent_id]: 575751
[tags]: 
Usually, it does introduce more parameters. The original definition of attention (by Bahdanau et al. ) defines attention energies as a single-layer NN computation: $$e_i = v^T \tanh \left( Wq + Uk_i + b \right)$$ where $q$ is the query and $K=(k_1, \ldots,k_n)$ are the keys (using the later terminology of Attention is all you need), $v$ , $W$ and $U$ are learnable parameters. The energies are later normalized using softmax and the resulting distribution is used to compute the context vector, i.e., a weighted average of some values. When you assume, you can directly compare the keys and the query, you can compute the energies as $e_i = q^Tk_i$ with a single dot product. In that case, you indeed do not introduce further parameters to the model. However, this ofter works poorly, so there is a linear projection before the dot product (e.g., in the splitting the attention heads in the Transformers) to make the keys and queries commensurable, which, however, means additional hyperparamters.
