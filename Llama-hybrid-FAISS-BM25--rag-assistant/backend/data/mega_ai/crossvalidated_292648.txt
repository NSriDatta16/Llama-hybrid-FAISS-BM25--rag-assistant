[site]: crossvalidated
[post_id]: 292648
[parent_id]: 
[tags]: 
Mining text with small datasets

I'm interning in an auditing company and have audit reports that require categorising. I have been using simple text mining + classification techniques in R ( DocumentTermMatrix in tm package, SVM via e1071 package, etc.) to help. Unfortunately it is laborious to manually categorise the issues to create the train data, but as of now I have about 50+ samples categorised into about 7 categories. A shockingly small number, I know. What then is the best way to continue? Is 50 too small a size for training data? I have about 150 reports that requires categorising. The reports are each roughly about 900 - 2000 chars (1-2 pages) long (hence laborious to manually categorize).
