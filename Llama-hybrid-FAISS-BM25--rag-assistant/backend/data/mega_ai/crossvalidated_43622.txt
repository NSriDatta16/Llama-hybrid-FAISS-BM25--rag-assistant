[site]: crossvalidated
[post_id]: 43622
[parent_id]: 
[tags]: 
A "Gambler's Loss function"?

What is a good loss function for a predictive model used by gamblers? I've been reading a bit about loss functions recently. I've always just went with MSE (e.g., for a couple of neural network projects) and didn't ask questions. I didn't realize exactly how arbitrary MSE actually is. And speaking of this, could somebody explain a simple practical situation where MSE can be derived as the "correct" loss function? Anyway, I came across Log-Loss (which is the same as cross entropy) and am interested because I'm curious about some probabilistic models. I understand how one derives this loss function from information theory, but when we talk about probabilities, we're often involved in some form of gambling on an outcome. It's not clear to me that efficient transmission of information translates to the type of utility one is usually looking for in a predictive/probabilistic model. If, for example, I had a model that was meant to predict the winner of the 2012 US presidential election, and I had used this to move money around on a future's market like Intrade, how might I determine a loss function for my prediction - assuming I'm able to continue making bets as the market fluctuates? Same type of thing should apply for any market where I am able to make handicapped bets on the occurrence of some event. Or is this really regret, and is regret completely different than a loss function?
