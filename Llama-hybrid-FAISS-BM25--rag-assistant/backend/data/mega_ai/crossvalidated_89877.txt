[site]: crossvalidated
[post_id]: 89877
[parent_id]: 
[tags]: 
'Uniformization'?

I am looking for a better term for what I call ' uniformification ', where I change data to make it more close to uniformly distributed. I am doing a project in which I try to make the output of a neural network uniformly distributed over the output space. Let's call the neural network $f(x | \theta)$, where $\theta$ contains the weights and other tunable parameters. What I do is to change the parameters of the network $\theta$ such that the output is closer to a uniform distribution. You could say I am making the output more uniform by modifying the function $f(x|\theta)$. How would I call this process? I was thinking of the term ' uniformification ', but it sounds kind of weird. What could be a better term for this? Or is there already a term for this in the literature? PS : in no case will I use a transformation on either $x$, $\theta$ or on the output $f(x|\theta)$ in order to make the output more uniform. I am only adjusting the weights $\theta$ in order to achieve that. Edit : According to this post on the suffixes -ise, -ate and -ify , the term should actually be ' uniformization '.
