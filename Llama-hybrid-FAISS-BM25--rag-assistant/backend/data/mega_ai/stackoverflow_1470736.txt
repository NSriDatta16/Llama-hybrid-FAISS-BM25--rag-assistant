[site]: stackoverflow
[post_id]: 1470736
[parent_id]: 1467336
[tags]: 
Try explaining exactly what you want to do? And what you've tried? What error message did you get? You're not very clear... What libraries have you tried? If you're not aggressive, there are no restrictions in downloading WM content. I've never heard of any restrictions. Some User-Agents are banned from editing to avoid stupid spamming, but really, I've never heard of downloading restrictions. If you are trying to scrape a massive amount of images, downloading them through Commons, you're doing it wrong (tm). If you are trying to get a few images, anywhere from 10 to 200, you should be able to write a decent tool in a few lines of code, provided that you are respecting the throttling requirement: when the API tells you to slow down, if you don't do it, sysadmins are likely to kick you out. If you need a complete image dump, (we're talking of a few TBs) try asking on wikitech-l . We had torrents available when there were less images, now it's more complicated, but still doable . About bot accounts. How deep have you looked in the system? You need a bot account for fast, unsupervised edits. Bot privileges also open a few facilities such as increased query sizes. But remember: bot account? it's simply an augmented user-account. Have you tried running anything with a classical account?
