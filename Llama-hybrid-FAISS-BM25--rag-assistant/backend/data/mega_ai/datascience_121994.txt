[site]: datascience
[post_id]: 121994
[parent_id]: 
[tags]: 
RFECV giving same test scores for every feature size

I am trying to reduce the feature space of my training dataset down from the 16000 it currently is before engaging in Random Forest Classification. Initially I removed all features in less that 5% of samples (leaving me with the 16000) and I am trying to further reduce this by RFECV. To do this am am using the following: from sklearn.model_selection import StratifiedKFold from sklearn.linear_model import LogisticRegression from sklearn.feature_selection import RFECV selector = LogisticRegression(penalty = 'l1', solver='liblinear') cv = StratifiedKFold(n_splits = 5) rfecv = RFECV(estimator = selector, step = 2, cv = cv, scoring = 'accuracy', min_features_to_select = 1, n_jobs = 8) rfecv.fit(train_16S, train_16S_labels) However the rfecv.cv_results_["mean_test_score"] are all the same: I have previously seen the problem reported here and the solutions was to use no penalty but but from reading around using penalty = 'l1' and solver='liblinear' is common for this problem?
