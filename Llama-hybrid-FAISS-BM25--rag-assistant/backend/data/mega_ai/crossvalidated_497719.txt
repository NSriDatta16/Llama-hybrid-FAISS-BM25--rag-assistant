[site]: crossvalidated
[post_id]: 497719
[parent_id]: 
[tags]: 
Does the Bernstein–von Mises theorem imply convergence in distribution between a Bayesian estimator and the MLE analogue?

Does the Bernstein–von Mises theorem imply convergence in distribution between a Bayesian estimator and its MLE analogue? Say I have \begin{equation*} \begin{aligned} & \mu \sim N(m, s^2) \\ & Y_1, ..., Y_n \overset{iid}{\sim} N(\mu, \sigma^2) \end{aligned} \end{equation*} with known $\sigma^2$ the posterior for $\mu$ is \begin{equation*} \begin{aligned} & \mu|Y_1, ..., Y_n \sim N(\hat{m}, \hat{s}^2) \\ & \hat{m} = \frac{\frac{1}{s^2}m + \frac{n}{\sigma^2}\bar{Y}}{\frac{1}{s^2}\frac{n}{\sigma^2}} \\ & \hat{s}^2 = \left( \frac{1}{2^2} + \frac{n}{\sigma^2} \right)^{-1} \end{aligned} \end{equation*} where we write $\bar{Y} = \frac{1}{n} \sum_{i=1}^{n} Y_i$ Once I have shown the conditions for B-VM hold (MLE consistent, finite-dimensional, well-specified, smooth, existence of tests) does the Bayesian estimator then converge in distribution to the normal centered about the MLE? Is it implied their variance is equal or is there another step before?
