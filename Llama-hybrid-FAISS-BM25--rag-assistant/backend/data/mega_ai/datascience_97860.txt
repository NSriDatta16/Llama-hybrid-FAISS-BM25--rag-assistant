[site]: datascience
[post_id]: 97860
[parent_id]: 
[tags]: 
Semantic Segmentation: Data formats

I am new to semantic segmentation and have a lot of problems with the things you do not see in tutorials: How the data should "look" at any given step. Currently, I have a U-Net which is supposed to do a binary segmentation of aerial images into trees/other land cover (more classes are planned in case this is working). Problem: The training process runs for a while, accuracy goes up to 1 (which is conspicuous in itself) and the trained model predicts just 0 everywhere, no matter the input image. I have read that data format, namely whether the color values are Int8 , float32 , etc. can be an issue. However, I do not know what the format should be, so I do not know if this is the problem. At the moment, my mask images are of type float32 with dimentsions (batchsize, 256, 256, 1). Is this how it should be, or should the masks e.g. be Int8 ? Could this be a reason why the results are terrible at the moment? The training images are (batchsize, 256, 256, 4) (RGBa images) also in float32 . Model predictions are one-hot encoded (output layer of shape (batchsize, 256, 256, 2) for the 2 classes which I currently use). My implementation of the CNN is using tf.keras . Please comment if further information is required to find out what is wrong. Edit: About 30% of the area is class "trees" (= 0), the rest is class "other" (= 1). I tried to upload a TensorBoard here (had some trouble making it work, unfortunately it had no Name when it was uploaded). This is the Python output: 256/256 [==============================] - 121s 434ms/step - loss: 0.8407 - updated_mean_io_u: 0.3848 - accuracy: 0.0039 - val_loss: 0.6496 - val_updated_mean_io_u: 0.3762 - val_accuracy: 0.0000e+00 Epoch 2/5 256/256 [==============================] - 108s 424ms/step - loss: 0.6294 - updated_mean_io_u: 0.3823 - accuracy: 0.0000e+00 - val_loss: 0.6159 - val_updated_mean_io_u: 0.3791 - val_accuracy: 0.0000e+00 Epoch 3/5 256/256 [==============================] - 109s 425ms/step - loss: 0.6007 - updated_mean_io_u: 0.3829 - accuracy: 0.0000e+00 - val_loss: 0.5971 - val_updated_mean_io_u: 0.3757 - val_accuracy: 0.0000e+00 Epoch 4/5 256/256 [==============================] - 109s 428ms/step - loss: 0.5826 - updated_mean_io_u: 0.3437 - accuracy: 0.4609 - val_loss: 0.5815 - val_updated_mean_io_u: 0.1231 - val_accuracy: 1.0000 Epoch 5/5 256/256 [==============================] - 110s 431ms/step - loss: 0.5695 - updated_mean_io_u: 0.1178 - accuracy: 1.0000 - val_loss: 0.5746 - val_updated_mean_io_u: 0.1247 - val_accuracy: 1.0000 ...rather strange "jumps" in accuracy between 0 and 1; model predicts only "0" which isn't even the larger class...
