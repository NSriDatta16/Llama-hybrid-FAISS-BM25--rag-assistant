[site]: datascience
[post_id]: 67673
[parent_id]: 
[tags]: 
Transfer Learning Question: Extending the Functionality of a Multipose-Estimation Machine Learning Model?

I have experimented with a number of different machine learning models used for pose estimation. Most of them output a heatmap and offsets for the detected person(s) in the image. I really like the performance/accuracy of the multipose estimation model here . What I would like to do next is to create a model similar to this one, except it should label each pose of the person(s) detected. There are multiple different implementations caffe/pytorch/tensorflow to choose from. I've thought about how to approach this and I have thought of a few different ways: Create a completely new machine learning model and use the labeled output of the pose estimation model to train it. Change or add layers to the machine learning model to change the output. (Not sure how this is done) Ditch the pose estimate model and train a new model to directly estimate using raw images/labels of cropped people. This would rely on another method to detect each person. I want to take the path of least resistance here but I also care about the time it takes to gather/process data, and most importantly the accuracy/performance of the model. Are there any experienced Machine Learning/Data Scientists who answer the following? Which approach should I take? advantages/disadvantages Which machine learning library offers the functions to do this. My assumption is that option 1 or 2 would be more accurate than option 3. Am I correct?
