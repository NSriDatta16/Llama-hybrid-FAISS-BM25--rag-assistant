[site]: datascience
[post_id]: 110940
[parent_id]: 79727
[tags]: 
Knowledge graph (KG) is a different structure then Graph Neural Network (GNN). Both are indeed graphs but where KG differs is that it is not a Machine learning (ML) model, its just a way to "represent" relation between entities using an edge (predicate) while GNN is ML model that it learns the structure of the graph (neighbors and neighbor of neighbors) while training. This is why KG embedding is shallow in a sense that it could be merely an embedding of nodes obtained from either word embeddings such as Word2Vec or other methods such as TransE , not accounting much for multi-hop context. Whereas GNN is indeed aimed at learning/encoding multi-hop context such as information about neighbors and neighbor of neighbors, into node embeddings, hence they are more rigorous then KG embeddings. How should we choose which approach if we want to get embeddings? As I mentioned KG is merely representing a caterogical entity, such as "cat" with a relation such as "feral", while GNN is an ML model, (not just representing relations between entities). So depending upon the problem, you can choose one or the other.
