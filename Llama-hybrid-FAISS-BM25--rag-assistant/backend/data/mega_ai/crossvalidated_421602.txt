[site]: crossvalidated
[post_id]: 421602
[parent_id]: 421574
[tags]: 
The answer and comments above basically nail it. Here are a couple comments to add a couple thoughts. Any machine learning algorithm will be sensitive to changes in the data (or the task at hand). From a matrix perspective, if it expects for example the first ten columns to represent the left side of the license plat, and now you rotate the plate, those first 10 columns now might represent the "top" or the "bottom" of the license plate... so it wouldn't be fair to say NNs/DL are not good, since you're evaluating them using a moving target. So better to train a model for the task it will be used on, rather than hypothetical variants. If you will be expecting rotations as inputs, then that should be part of your training of the model, otherwise, maybe not as useful. The reason why NNs and DL tend to be powerful is they have the ability to extract the signal and summarize complex, local relationships between features in an image via built-in functionality in their architecture (e.g., convolution layers or auto-encoders). That does not mean that they're bullet-proof, but for image-recognition tasks they offer probably the most powerful toolkit for it at the expense of computation time, understanding how to design and optimize their architecture, etc.. Hope this helps!
