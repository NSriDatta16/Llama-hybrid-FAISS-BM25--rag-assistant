[site]: crossvalidated
[post_id]: 52871
[parent_id]: 36006
[tags]: 
As a researcher in Bioplausible Machine Learning, I strongly agree that "no model is correct but some are useful", and in fact models and formalisms have the strong failing as used by authors who talk about optimization of the problem, when what they are doing is optimizing a model, i.e. exploring its parameter space and finding a local or hopefully global optimum. This is not in general an optimum for the real problem. While the originator of a model normally uses the correct terminology, and exposes all the assumptions, most users gloss over the assumptions, which most often are known not to hold, and also use less precise language about "learning" and "optimization" and "parameterization". I think this optimal parameterization of a model is what people would mean in Machine Learning, particularly in supervised Machine Learning, although I can't say I've heard "learn a model" a lot - but it does occur, and whereas the person trains the model, the computer learns the parameters of the model. Even in unsupervised learning the "learning" is most often simply parameterization of a model, and hopefully "learning a model" is thus optimal parameterization of a model (although often different ways of searching the parameter space find different solutions even though they can be proven to optimize the same thing). I would indeed rather use "training a model" for this purpose rather than personifying the computer and creating the ambiguity between discovering a new model and parameterizing an old one. In fact, most of my research is about learning the model in terms of discovering a better model, or a more computationally and cognitively/biologically/ecologically plausible model.
