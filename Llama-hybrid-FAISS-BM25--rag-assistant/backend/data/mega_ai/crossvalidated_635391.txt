[site]: crossvalidated
[post_id]: 635391
[parent_id]: 164963
[tags]: 
This issue is sometimes known as 'interpretational confounding' (Burt, 1976). The problem is that the model does not distinguish between structural and measurement parameters so simply optimises over all parameters. Thus, if an item is more closely related to a different latent variable than the average of other items on the factor, then the loading of that item on its latent variable will increase to improve the fit of the model. This means that the latent variables are partly defined by indicators from other scales in the model, and when a new scale is added the interpretation of the latent variables changes. In the case of the question, adding (or removing) var4 resulted in the interpretation of (at least) var3 changing, which meant a different amount of its variance was predicted by var2. This is a serious issue that it is important to do something about. It may be possible to overcome by allowing correlated residuals fairly liberally (so these relationships don't spread through the latent variables) but this is far from perfect. A relatively easy way to deal with the issue simply forces the measurement parameters to match the values in CFAs (by fixing them in the model specification). The coolest method, though, is to allow item residuals to correlate with all other latent variables and then constrain these in some way. If the sum of squares of item residual correlations with external factors is minimised (for each factor combination) then the measurement parameters equal what they would have been in a CFA (Nagy et al., 2017). This method does get out of hand when there are lots of items or factors and is complicated so simply fixing parameters is usually the best method from a pragmatic point of view. http://journals.sagepub.com/doi/10.1177/004912417600500101 http://dx.doi.org/10.1080/00220973.2016.1260524
