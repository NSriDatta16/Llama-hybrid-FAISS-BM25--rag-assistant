[site]: datascience
[post_id]: 82236
[parent_id]: 
[tags]: 
One Neural network with multiple outputs or multiple neural networks with a single output?

I an building a feed forward deep learning model using tabular data. The inputs are numeric features or categorical features (represented with embeddings). The outputs are the same number of numeric input features. Is there any known research or models out there which verifies that using a single model with multiple outputs would be better/worse than multiple models, each with a single output? In essence, with N observations and M outputs, a single model minimizes: $$ \frac{1}{N}\sum_n^N\sum_m^M \left(y_m^{(n)} - \hat{y}_m^{(n)} \right)^2 $$ while multiple models with single output, each minimize: $$ \frac{1}{N}\sum_n^N \left(y_m^{(n)} - \hat{y}_m^{(n)} \right)^2 $$ For a single value of $m$ . Any reason one would be preferred over the other, or do I just have to try and see for myself?
