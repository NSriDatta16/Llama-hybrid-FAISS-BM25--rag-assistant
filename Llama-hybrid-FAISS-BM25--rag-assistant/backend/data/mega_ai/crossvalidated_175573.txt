[site]: crossvalidated
[post_id]: 175573
[parent_id]: 175382
[tags]: 
The purpose of PCA is to reduce the dimensionality of your data, in part to reduce the number of parameters and therefore the variance of your predictor. I think you are applying PCA to the transpose of the matrix you want to apply it to, because your result should be $700 \times n$ for some $n$ that you choose. I am not familiar with the matlab implementation. That being said what you should be doing with PCA and SVM is, Normalize Data: Center and scale your data. The transformation, $C$, that centers and scales your data should be stored in some fashion. "Train" PCA: PCA learns a variance maximizing linear transformation onto a lower dimensional space. Learn this transformation, and then apply it to your training data. This transformation, $B$, should be stored in some fashion. "Train" SVM: As you were already doing train SVM on your reduced data. The predictor $A$ should be stored in some fashion. Classifying new data point, $x$, is then as easy as $A \circ B \circ C(x)$.
