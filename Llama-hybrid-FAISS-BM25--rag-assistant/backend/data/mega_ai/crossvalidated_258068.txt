[site]: crossvalidated
[post_id]: 258068
[parent_id]: 257721
[tags]: 
Basically you need some sequence learner (on word level), e.g. CRF or RNN, that either outputs a tag or a "null" symbol at each word, where the tag would represent a type of class you want and "null" would mean still inside the last tag. Given appropriately tagged training data you can then just treat it as a supervised classification problem. Take for example: Account: SugarHigh Inc Qty: 1,000 Tons Sugar Date: 9 - 15 July From: NY To: IL The corresponding labeling would be: ACCOUNT 0 0 QUANTITY 0 0 PRODUCT DATE 0 0 0 0 FROM 0 TO 0 Of course the textual labels are representing numbers as given by a softmax layer, e.g. ACCOUNT = 1. I published a paper nearly ten years ago about something very similar for parsing bibliographical meta-data with probabilistic finite state transducers. It could help to illuminate the overall problem, although I'd rather use something like LSTMs nowadays. See here: https://pdfs.semanticscholar.org/61d5/37dffd719ee98bd6871564d924dd38c9a075.pdf
