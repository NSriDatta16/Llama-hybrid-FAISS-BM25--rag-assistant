[site]: datascience
[post_id]: 401
[parent_id]: 382
[tags]: 
I like a multiple step strategy: Write clean easy to understand code, as opposed to short-tricky code. I know statisticians like tricky code, but spotting problems in tricky code is dangerous. ( I am mentioning this because a supervisor of mine was fond of undocumented 500 lines python scrips - have fun debugging that mess and I have seen that pattern a lot, especially from people who are not from an IT background) Break down your code in smaller functions, which can be tested and evaluated in smaller stes. Look for connected elements, e.g. the number of cases with condition X is Y - so this query MUST return Y. Most often this is more complex, but doable. When you are running your script the first time, test it with a small subsample and carefully check if everything is in order. While I like unit tests in IT, bugs in statistics scripts are often so pronounced that they are easily visible doing a carefully check. Or they are methodical errors, which are probably never caught by unit tests. That should suffice to ensure a clean "one - off " job. But for a time series as you seem to have, I would add that you should check for values out of range, impossible combinations etc. For me, most scripts that have reached step 4 are probably bug free - and they will stay that way unless something changes. And most often, the data are changing - and that is something which should be checked for every run. Writing code for that can be time consuming and annoying, but it beats subtle errors due to data entry errors.
