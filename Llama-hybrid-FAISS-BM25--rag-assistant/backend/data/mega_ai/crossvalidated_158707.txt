[site]: crossvalidated
[post_id]: 158707
[parent_id]: 158705
[tags]: 
It means you're over-fitting the training data without assessing the generalization error using e.g. cross-validation. You can avoid using cross validation when using random forests because of the way it estimates the out-of-bag (OOB) error as it goes. However, once you use those OOB prediction residuals as the inputs to the second random forest model in your pipeline this is no longer true. In order to get an estimate of the generalization error you need to think about this two stage process as components of a new model that needs to be assessed via cross validation. Build your model on a training sample then assess its accuracy on a test set and I guarantee your results will not look as good. Another way to look at this is see what happens is instead of stopping at 2 random forest models you now built a third model to predict the residuals of the second. You'll get an even better result. Chain enough of these together and you'll predict the test set perfectly.
