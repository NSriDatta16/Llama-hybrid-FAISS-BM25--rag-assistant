[site]: crossvalidated
[post_id]: 387993
[parent_id]: 
[tags]: 
What kind of impact do autoencoders have on final model performance when compared to models trained only on supervised data?

For example, say we have two datasets, a labeled set (I will call it df_labeled) of nrows=200k and an unlabeled dataset (df_unlabeled) of nrows=800k and we want to build a binary classifier. I clearly, have the option of building my model only using df_labeled but I want to take advantage of having df_unlabeled since the data is gathered from closely related sources. To give further context to my problem, I am working with spending data for consumers on different products which are binned broadly into different categories like Food, Travel, Education, Health, etc. At present I am training on data from a specific category to predict on future behavior within that category. But as you can imagine consumers are not constrained to one particular category and make purchase across category, so there might be additional correlation to learn if the complete data set is taken into account. I want to make a generic model using the complete dataset to predict on future behavior of consumers in a specific category and without having to compromise a lot on performance. I am thinking of using an autoencoder to learn the correlations in the complete dataset (without the category tag) and then run a further training step using h2o.deeplearning on data labeled with specific categories. Do models built using this approach perform better than models just trained on df_labeled data ? I am looking for some advice on this approach before embarking on it full throttle.
