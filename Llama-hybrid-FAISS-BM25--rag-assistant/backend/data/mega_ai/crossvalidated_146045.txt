[site]: crossvalidated
[post_id]: 146045
[parent_id]: 146037
[tags]: 
This has been answered before but I will try to include a very simple explanation which can hopefully get you on the right track. A logit regression model, linking the probability of a dependent variable $y$ to some vector of independent variables $X$ is written as follows $$Pr(y=1) = \Lambda(X\beta)$$ where $\Lambda()$ represents a logistic c.d.f. The marginal effect can be though of as the impact a change in some variable $x_j$ has on the response probability $Pr(y=1)$ and can be written as. $$\frac{\partial Pr(y=1)}{\partial x_j} = \beta_j \lambda(X\beta) $$ where $\lambda$ is the p.d.f of a logistic function (the first derivative of $\Lambda$ w.r.t its argument) Notice that for different values of X, you get a different values of $\lambda(XB)$, giving you different marginal effects. To calculate the average marginal effect, you take the average of the logistic p.d.f for all the values of X in your sample and multiply it by your coefficient $\beta_j$. $$\frac{\partial Pr(y=1)}{\partial x_j} = \beta_j E[\lambda(X\beta)] $$ Aside Note: This is different than the marginal effect at the average.
