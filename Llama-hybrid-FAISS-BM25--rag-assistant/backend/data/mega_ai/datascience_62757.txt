[site]: datascience
[post_id]: 62757
[parent_id]: 61988
[tags]: 
If the last layer of your output has no activation (e.g. a linear layer, a convolution), then its range is unbounded. Supervised training may lead the network to learn the appropriate output range. This does not seem to be the case with your GAN. When you need the output of the generator to be constrained to a specific range of value, the safest approach is to simply force it by having the last layer use an activation function that does so by construction. As you need the output to be in $[0, 1]$ , an appropriate activation function for the last layer of the generator would be a Sigmod .
