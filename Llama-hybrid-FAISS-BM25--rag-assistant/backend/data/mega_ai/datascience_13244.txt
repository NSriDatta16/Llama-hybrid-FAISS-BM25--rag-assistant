[site]: datascience
[post_id]: 13244
[parent_id]: 
[tags]: 
Neural Net for regression task on images only learning mean of training data

I'm trying to train neural networks to extract parameters out of input data. In particular determining the width, height and color of bricks (see attached pictures as example inputs). I've already tried CNNs operating on the raw images and NNs operating on extracted features ( 2 describing edges and a color histogram ). Both approaches seem to learn the mean of the training data. The color is mostly gray and the width and height between the two extremes. The output does not depend on the input as the NN always outputs the "same" values (only very small fluctuations). As I'm operating on generated data I have a perfect correlation between input and desired output and infinite training data. The used loss function is mean squared error (also tried the absolute error). Can someone explain why this is happening or how to avoid this training behavior? I'm using the library tiny-cnn . My current approach (using features) uses 5 fully connected layers, decreasing layer size from 1200 to 17(amount of parameters). net (1200, 600) (600, 300) (300, 150) (150, 60) (60, 17); I've test several CNN structures, always ending in 2 fully connected layers. I tried different kernel sizes from 3 to 11. This is one of the last I tried: net (100, 100, 5, 3, 4) (96, 96, 4, 2) (48, 48, 7, 4, 8) (42, 42, 8, 2) (21, 21, 7, 8, 16) (15, 15, 16, 3) (5, 5, 5, 16, 32) (32, 64) (64, size); 5-conv, average, 7-conv, average, 7-conv, average(3x3), 5-conv, full, full I've mainly used RMSProp and adagrad with standard learning rates but also tried higher and lower rates. Example inputs:
