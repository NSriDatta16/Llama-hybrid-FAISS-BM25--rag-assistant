[site]: crossvalidated
[post_id]: 603333
[parent_id]: 
[tags]: 
Does Propensity Score theorem invalidate linear regression?

The propensity score theorem in Causal Inference implies that $E[T|X]=E[T|p(X)]$ , i.e. it is sufficient to control for the propensity score to retrieve the average causal effect. Then, we can use a linear regression which only controls for $p(X)$ , and not all confounders $X$ to retrieve the Average Causal Effect. This implies a regression equation of the form $$Y=\beta_0+\beta_1T+\beta_2p(X)+\varepsilon$$ However, since $p(X)$ is almost always a non-linear function of $X$ (clearly in a logistic regression, even in an LPM we have to restrict probabilities to between 0 and 1 which introduces non-linearities). If we used regression adjustment instead, our model would be of the form $$Y=\delta_0+\delta_1T+\sum_{k=1}^K \gamma_k x_k+\eta $$ This is clearly linear in $X$ and otherwise has the same form has the propensity score regression. As I understand this, this has two consequences: Linear Regression can never retrieve the ACE To retrieve the ACE in a regression without the propensity score, we need a partially linear model, whose non-linear term includes all confounders $X$ (and, coincidentally, which approximates the propensity score $p(X)$ ). Are these consequences correct? Does this pose a problem for regression adjustment, or do we simply (as usual in OLS) argue that linear regression retrieves the best linear approximation to the (partially) non-linear model involving the propensity score?
