[site]: datascience
[post_id]: 535
[parent_id]: 527
[tags]: 
As I understood, Document 1 and Document 2 may have different number of keys. And you wand to get final similarity evaluation between 0 and 1. If so, I would propose following algorithm: Sum of max. vals is equal to 0. Select maximum value from doc-doc matrix and add it to Sum of max. vals. Remove row and column with maximum value from the matrix. Repeat steps 2-3 until rows or columns are ended. Denominate Sum of max. vals by average number of key words in two texts. Final estimation would be equal to 1, if both documents have identical length, and every word from Doc 1 has equivalent in Doc 2. You haven't mentioned software, you are using, but here is R example of function, computing such similarity (it takes object of class matrix as input): eval.sim In python - import numpy as np def score_matrix(sim_matrix): similarity = 0 denominator = sum(sim_matrix.shape) / 2 for i in range(min(sim_matrix.shape)): x, y = np.where(sim_matrix == np.max(sim_matrix))[0][0], np.where(sim_matrix == np.max(sim_matrix))[1][0] similarity += sim_matrix[x, y] sim_matrix = np.delete(sim_matrix,(x),axis=0) sim_matrix = np.delete(sim_matrix,(y),axis=1) return similarity / denominator
