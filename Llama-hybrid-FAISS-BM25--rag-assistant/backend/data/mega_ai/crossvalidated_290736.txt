[site]: crossvalidated
[post_id]: 290736
[parent_id]: 
[tags]: 
Random Forest Dataset Variability

I am going to implement a Random Forest Regressor and remember reading somewhere, that the datasets for learning should be as diferent as possible for a good pretiction. (Unfortunately I can not find that source text anymore, Neither after a search in the web I can not find support for this assumption) Therefore I would run a L1-Norm distance measure on my feature matrix for all datasets and dismiss those with a too low value. Resulting in these Questions: Can anyone support the assumption of using high variability between the datasets? If yes, is there a suggestion on a more suitable way than the L1-Norm? Suggestions for python implementation, better than numpy's linalg norm? EDIT: In the case of the trainingset below I would only dismiss v1 or v4. V marks a dataset (=5 counts) holding 8 features each.
