 as a science or philosophical topic has been a common theme in science fiction literature and films. One film that could be argued to be ingrained in pop culture that depicts the dystopian future use of robotic AI is The Matrix, depicting a future where humans and conscious sentient AI struggle for control of planet Earth, resulting in the destruction of most of the human race. An animated film based on The Matrix, the Animatrix, focused heavily on the potential ethical issues and insecurities between humans and robots. The movie is broken into short stories. Animatrix's animated shorts are also named after Isaac Asimov's fictional stories. Another facet of roboethics is specifically concerned with the treatment of robots by humans, and has been explored in numerous films and television shows. One such example is Star Trek: The Next Generation, which has a humanoid android, named Data, as one of its main characters. For the most part, he is trusted with mission-critical work, but his ability to fit in with the other living beings is often in question. More recently, the movie Ex Machina and the TV show Westworld have taken on these ethical questions quite directly by depicting hyper-realistic robots that humans treat as inconsequential commodities. The questions surrounding the treatment of engineered beings has also been key component of Blade Runner for over 50 years. Films like Her have even distilled the human relationship with robots even further by removing the physical aspect and focusing on emotions. Although not a part of roboethics per se, the ethical behavior of robots themselves has also been a joining issue in roboethics in popular culture. The Terminator series focuses on robots run by a conscious AI program with no restraint on the termination of its enemies. This series has the same archetype as The Matrix series, where robots have taken control. Another famous pop culture case of AI with defective morality is HAL 9000 in the Space Odyssey series, where HAL (a computer with advanced AI capabilities who monitors and assists humans on a spacecraft) kills humans on board to ensure the success of the assigned mission after his own life is threatened. Killer robots Lethal Autonomous Weapon Systems (LAWS), often called "killer robots", are theoretically able to target and fire without human supervision or interference. In 2014, the Convention on Conventional Weapons (CCW) held two meetings. The first was the Meeting of Experts on Lethal Autonomous Weapons Systems. This meeting was about the special mandate on LAWS and intrigued intense discussion. National delegations and many non-governmental organizations(NGOs) expressed their opinions on the matter. Numerous NGOs and certain states such as Pakistan and Cuba are calling for a preventive prohibition of LAWS. They proposed opinions based on deontological and consequentialist reasoning. On the deontological side, certain philosophers such as Peter Asaro and Robert Sparrow, most NGOs, and the Vatican argue that granting too much rights to machine violates human dignity, and that people have the "right not to be killed by a machine". To support their standpoint, they repeatedly cite the Martens Clause. At the end of the meeting, the most important consequentialist objection was that LAWS wouldn't be able to respect international humanitarian law (IHL), as believed by NGOs, many researchers, and several states (Pakistan, Austria, Egypt, Mexico). According to the International Committee of the Red Cross (ICRC), "there is no doubt that the development and use of autonomous weapon systems in armed conflict is governed by international humanitarian law." States recognize this: those who participated in the first UN Expert Meeting in May 2014 recognized respect for IHL as an essential condition for the implementation of LAWS. With diverse predictions, certain states believe LAWS will be unable to meet this criterion, while others underline the difficulty of adjudicating at t