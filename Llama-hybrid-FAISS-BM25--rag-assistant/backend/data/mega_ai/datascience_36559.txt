[site]: datascience
[post_id]: 36559
[parent_id]: 36551
[tags]: 
Passing directly the output of the softmax is also common (among the few textual GANs out there), e.g. see the improved Wasserstein GANs (WGAN-GP) . With hard Gumbel-softmax (+ straight-through estimator), you pass one-hot encoded vectors, which is the same as what you have with real data. If you pass the output of the softmax, the discriminator should be able to more easily tell apart real data (one hot) from fake data (non-one hot). That being said, in my opinion neither of the two approaches seems very promising nowadays. There seems to be far more REINFORCE-based textual GANs.
