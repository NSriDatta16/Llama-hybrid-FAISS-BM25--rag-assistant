[site]: crossvalidated
[post_id]: 390740
[parent_id]: 390674
[tags]: 
The main thing to be careful of in predictive time series models is to avoid leaks from the future. The classic example is where you calculate the moving average or slope centered on the current point. This will include N points to the left and right, and the points to the right are from the future. You won't have those points when your model is actually going to be used. So you need to think exactly what information your model will have at the point you want to make a prediction and not build your model on any other data. (That's why people use trailing statistics, though moving averages never really make sense, even if you use the less-wrong trailing version.) In answer to your comment, I am uncomfortable with your proposed method for several reasons, but first let me say that I think your instinct on this is probably good: you don't want to come up with an ad hoc method for formalizing what you see in time series as you look at them. None of this "Well, if I subtract the 3rd, 5th, and 7th values from the average and take the largest...", and that's a good instinct. But your method introduces other complications that worry me: You’ll probably end up using a regression method which is thrown off by outliers. In that case a single spike point can cause it to calculate a misleading slope. Do you understand regression and it’s disgnostics? Are you going to grab the slope and intercept coefficients without looking at their “statistical significance”? If not, what will you do if they are not significant? If you do understand regression diagnostics, do you know how they can be inaccurate (overly optimistic) when applied to time series, and how to correct for that? Calculating trends by regression is trotting out machinery that is often more complex than people realize and yet not as powerful as State Space approaches, for example, that could give you direct answers. That’s why I’m encouraging you to think of other features that might be simpler and more directly address your actual targets. Are you sure that there really are up and down segments? From what you say there's no overall trend or any seasonality, so the series is basically wandering around. Depending on the autocorrelation, this can make series that look like noise or that look like something's going on. But it really isn't. Using a complex tool like regression could fool you into thinking what you're seeing must be real, when it might just be noise. If you're using R, try: plot (arima.sim (n=50, list (ar=c(0.882)))) several times in a row. You'll see fascinating patterns, but... On the other hand, if you are rigorous with training and testing and avoiding future leaks, you can certainly try the regression slope method and not care that much if it’s an approved idea or not: the proof is in the predicting. If it predicts well — and you’re not messing something up to fool yourself about your out-of-sample accuracy — it’s good enough. You might not be able to reverse-engineer your model for goodvexplanations of why, but if that’s not your concern, no need to worry. (And it might be slow to deploy on a large scale, but that’s another matter.) Pre-edit continuation of answer: Also, we love to calculate trends by throwing a set of data into a OLS regression. But is that actually necessary? Is the trend in this case just the first value in the window subtracted from the last? Or do you care about the number of positive point-to-point deltas versus negative deltas instead? Last, you can't just use an OLS regression naively on a time series. Time series are autocorrelated, which violates an assumption of OLS. (The main effect is that your diagnostics are too optimistic and you think your slope is statistically different from 0 and it's not.) Not to mention that time series have seasonal effects. That's why there's old-school ARIMA. (A more modern approach is State Space, also known as Kalman, but that's probably too far afield for your simple application, hence my question about whether you even really need to do regressions at all.)
