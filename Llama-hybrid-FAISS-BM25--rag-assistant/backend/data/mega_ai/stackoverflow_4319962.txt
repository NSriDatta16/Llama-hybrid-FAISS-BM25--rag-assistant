[site]: stackoverflow
[post_id]: 4319962
[parent_id]: 
[tags]: 
Comparing Value of one list inside Gigantic Two Dimen list in python, Fastest way?

I want to compare if value of one list exist in value of other list.They are huge (50k + items, from database). EDIT: I also want to mark the record which is duplicated as duplicate=True and keep them in the table for later refrence. here how the lists are: n_emails=[db_id,checksum for id,checksum in search_results] #I want to compare checksum if exist inside same list or other list and retrieve id (db_id , if exist) #example : n_emails= [[1,'CAFEBABE010'],[2,'bfeafe3df1ds],[3,'deadbeef101'],[5,'CAFEBABE010']] #in this case i want to retrive id 1 and 5 coz they are same checksum for m in n_emails: dups=_getdups(n_emails,m[1],m[0]) n_dups=[casesdb.duplicates.insert( **dup ) for dup in dups] if n_dups: print "Dupe Found" casesdb(casesdb.email_data.id == m[0]).update(duplicated=True) def _getdups(old_lst,em_md5,em_id): dups=[] for old in old_lst: if em_md5==old[0] and old[1]!=em_id: dups.append(dict(org_id=old[1],md5hash=old[0],dupID=em_id,)) return dups But it seems too long and in larger list (50k vs 50k records+) It ran for over 5000 seconds and never done , seems never ending loop? The server i running have 4 GB of ram and 4 cores. Obviously i am doing something wrong. Please help .. thanks a lot! SOLVED: Dict Index Mapping is way a lot faster! (When mysql table is not indexed, plese note i have not test against indexed table). Its 20 secs vs 30 miliseconds = 20*1000 / 30 = 666 Times! LOL
