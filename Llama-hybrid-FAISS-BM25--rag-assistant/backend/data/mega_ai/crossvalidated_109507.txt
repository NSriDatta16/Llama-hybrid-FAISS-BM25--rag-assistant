[site]: crossvalidated
[post_id]: 109507
[parent_id]: 
[tags]: 
Feature Selection using (low) MCC

I have approximately 1200 input parameters that I am trying to whittle down with the following rough process: 1) Fit rbf SVM with n = 1200 parameters and calculate Matthews Correlation Coefficient(cross validation with 10 partitions) 2) Fit linear SVM, find the lowest weight (absolute value) parameter 3) Fit rbf SVM with n-1 parameters, compare the average MCC and delete the parameter IF my MCC is the same or better Unfortunately, I didn't have high predictive power in the first place. With all 1200 parameters, the MCC of the rbf SVM was around 0.018. And deleting just one parameter significantly lowered the MCC, sometimes to 0.0. I'd like some help interpreting these two things: 1) Why should there be a significant difference in predictive power when I use 1200 parameters versus 1200-1 parameters? 2) What does an MCC of around 0.018 mean? Is it all noise? So there is no true predictive power? And as a last question: Is comparing the MCC not the best approach? Perhaps I can use ROC, but I don't know why one would be preferred over the other. What else would you suggest and why? Any other comments about my procedure would be appreciated!
