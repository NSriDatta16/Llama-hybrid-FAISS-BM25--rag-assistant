[site]: crossvalidated
[post_id]: 483581
[parent_id]: 483496
[tags]: 
First, it's always important to start with knowledge of the subject matter. Second, selection based on "univariate"* models can be particularly misleading with logistic regression, as it is prone to omitted-variable bias in a way that can diminish your chance of finding true associations of predictors with outcome. Unlike with least-squares regression, the omitted predictors don't even need to be associated with the included predictors to get bias with logistic regression. That's also true for survival modeling. So it's better to avoid that selection process. How to proceed beyond that depends on the purpose of the modeling. If your primary interest is in prediction, consider a modeling approach that uses as many predictors as possible while avoiding overfitting. If you for example use ridge regression, with cross-validation to choose the penalty based on minimizing deviance (log-loss), there is no such thing as "too many predictors." All predictors are kept, with regression coefficient magnitudes diminished to avoid overfitting. Or you could use elastic net to cut down some on the number of predictors while avoiding overfitting. If you need a more focused approach, follow the recommendations in Frank Harrell's course notes or book . They provide ways to deal with such situations via a combination of methods, cutting down on the number of predictors included without leading to bias in the final model. For example, multiple predictors representing essentially the same phenomenon might be combined into a single predictor. If there is a particular variable like a treatment in which you are interested, and you wish to check its relationship with outcome while adjusting for other factors, you could consider a hybrid of the above approaches: penalizing the factors you want to adjust for with ridge while keeping the treatment variable unpenalized. This paper illustrates that approach, and discusses others. I take that to mean single-predictor models. It's often preferred to use "univariate" and "multivariate" to refer to the number of response/outcome variables, not the number of predictors, although that preference isn't universal.
