[site]: crossvalidated
[post_id]: 460036
[parent_id]: 459956
[tags]: 
On your first question: Why does the chosen level of the CI play out such that the very same percentage of CIs will contain the mean of the population? This is not always the correct interpretation, so I present more on the underlying varying concepts associated with confidence intervals. To quote from Wikipedia : The confidence interval can be expressed in terms of samples (or repeated samples): "Were this procedure to be repeated on numerous samples, the fraction of calculated confidence intervals (which would differ for each sample) that encompass the true population parameter would tend toward 90%."[2] The confidence interval can be expressed in terms of a single sample: "There is a 90% probability that the calculated confidence interval from some future experiment encompasses the true value of the population parameter." Note this is a probability statement about the confidence interval, not the population parameter...Here the experimenter sets out the way in which they intend to calculate a confidence interval and to know, before they do the actual experiment, that the interval they will end up calculating has a particular chance of covering the true but unknown value.[4] This is very similar to the "repeated sample" interpretation above, except that it avoids relying on considering hypothetical repeats of a sampling procedure that may not be repeatable in any meaningful sense. The explanation of a confidence interval can amount to something like: "The confidence interval represents values for the population parameter for which the difference between the parameter and the observed estimate is not statistically significant at the 10% level".[7] In fact, this relates to one particular way in which a confidence interval may be constructed. In each of the above, the following applies: If the true value of the parameter lies outside the 90% confidence interval, then a sampling event has occurred (namely, obtaining a point estimate of the parameter at least this far from the true parameter value) which had a probability of 10% (or less) of happening by chance. Also, some important points covered under misunderstanding, to quote further: Misunderstandings A 95% confidence level does not mean that for a given realized interval there is a 95% probability that the population parameter lies within the interval (i.e., a 95% probability that the interval covers the population parameter).[13] According to the strict frequentist interpretation, once an interval is calculated, this interval either covers the parameter value or it does not; it is no longer a matter of probability. The 95% probability relates to the reliability of the estimation procedure, not to a specific calculated interval.[14] Note, there is also Bayesian inference in the form of so-called credible intervals. Per Wikipedia again : Confidence intervals correspond to a chosen rule for determining the confidence bounds, where this rule is essentially determined before any data are obtained, or before an experiment is done. The rule is defined such that over all possible datasets that might be obtained, there is a high probability ("high" is specifically quantified) that the interval determined by the rule will include the true value of the quantity under consideration. The Bayesian approach appears to offer intervals that can, subject to acceptance of an interpretation of "probability" as Bayesian probability, be interpreted as meaning that the specific interval calculated from a given dataset has a particular probability of including the true value, conditional on the data and other information available. The confidence interval approach does not allow this since in this formulation and at this same stage, both the bounds of the interval and the true values are fixed values, and there is no randomness involved. On the other hand, the Bayesian approach is only as valid as the prior probability used in the computation, whereas the confidence interval does not depend on assumptions about the prior probability. To answer your larger question, "why not just make use of the distribution of the sample means, which is much more likely to be normal than any one individual sample", you are actually right if the samples are from a uniform distribution. In fact, an approximate way to generate random normal deviates is to average 12 deviates from a uniform distribution. However, a more efficient path is to employ a transformation (employing, for example, a Box-Cox power transformation, see discussion here ) is induce normality and not lose so many degrees of freedom. If the data has percentage errors, a log transform is recommended.
