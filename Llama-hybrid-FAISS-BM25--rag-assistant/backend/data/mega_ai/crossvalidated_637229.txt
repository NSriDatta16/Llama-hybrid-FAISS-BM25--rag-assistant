[site]: crossvalidated
[post_id]: 637229
[parent_id]: 
[tags]: 
Question on a paper which talks about stacking several fully connected layers of 2 neural networks

So to preface, my knowledge on neural networks is very limited, and I've had a very difficult time trying to comprehend the details of this paper . My background is in maths, and I've created a continous wavelet CNN and the LSTM model, however I'm confused as to what I'm using in Equation 15 and 16. It looks to be just a sigmoid function, where I concatenate the 2 arrays (I assume I extend the $m_{i,j,t}$ array here), and then create a training function to estimate the weights and biases, but it feels like I'm skipping something important. If it is the case that I'm simply using the sigmoid function, I plan on using this section on Wikipedia to create the NN and train as the paper recommends, however some clarification would be great. As I said, my knowledge on neural networks is pretty rudimentary, so I'm basically making educated guesses here.
