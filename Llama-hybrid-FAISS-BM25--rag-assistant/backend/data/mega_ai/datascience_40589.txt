[site]: datascience
[post_id]: 40589
[parent_id]: 
[tags]: 
Standardizing Vegas odds for a randomForest

I'm sorry I don't have reproducible code, but I have a pretty specific question that I can't find an answer to. I'm using randomForest to project NBA statistics. Vegas-odds are incredibly useful because it's provides the wisdom of the crowd. Intuitively I feel like they need to be standardized for analysis, but maybe randomForest is good enough. The reason why I feel it needs to be standardized is because it's disjoint. If a team has a moneyline of -125, that means that you must pay \$125 to win \$100 (payout of \$225). If a team has a betting line of +110, that means you need to bet \$100 to win \$110 (payout of \$210). Therefore, it's disjoint in that there would never be scores in (-100, 100) since +100 or -100 are both even odds. With that said, would you recommend reshaping the vector in some way so that the random forest can learn "better"? E.g. -125 is a (125/(100 + 125) 55.6% chance of winning and a +110 is a (100/110+100) 47.6% chance of winning. Would changing the moneylines to percentages help performance? I know the only surefire way to check would be to run models, but I really don't have time for it at the moment, and this question will help me to determine in general if/when standardizing is necessary.
