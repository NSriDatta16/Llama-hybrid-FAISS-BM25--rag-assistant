[site]: crossvalidated
[post_id]: 518928
[parent_id]: 518760
[tags]: 
Rationale for a paired design Dependent data actually provide a superior design for inferring conditional effects, such as change from baseline. While SES, demographics, etc. comprise the "standard" adjustments for non-conditional analyses, you are at an advantage with the design and model you are considering. Models for dependent data With clustered data, paired data specifically, variables for adjustment are classified as either within-cluster or between-cluster. Conditional models for paired binary outcomes include McNemar's Test , a univariate procedure, and conditional logistic regression , the multivariate and imbalanced-cluster analogue. This is a conditional likelihood procedure. With conditional models, between-cluster confounders -- variables that do not vary within individuals in a cluster -- are handled by "conditioning" and cannot be adjusted for. You can compare this to a paired T-test: since the test simply subtracts the value between pairs, any expected effect of between-cluster variables is subtracted off. Mixed-effects logistic regression , where a random intercept is included for each cluster, is a profile likelihood method and is less efficient and more difficult to fit and interpret. It may be biased too. (I will follow-up this question separately). This is a profile likelihood procedure -- when using most off-the-shelf solvers for these models. If there is an interest in understanding the unconditional effect of these variables, one can present an analysis of " pairs-as-individuals " where models for independent data are used in spite of the inherent design. This is a pseudo-likelihood procedure. Testing interaction A variable is an effect modifier, or a modifier, if the expected difference varies significantly depending on the value of the modifier. If there is an interest in understanding the possible interaction between one of the between-cluster variables and the pre-post indicator, you can explore this one of several ways: Adjust for the interaction term in the pairs-as-individuals analysis or in the mixed effects model analysis Fit McNemar's test for each stratum or an appropriate categorization of the modifier, and compare the 1- $\alpha$ confidence intervals for the conditional odds ratio Fit a conditional logistic regression with the pre-post indicator, and the product of the pre-post indicator and the modifier. Note: unlike linear models where one must adjust for the lower level terms, conditional logistic regression handles the lower-level effect of the modifier by conditioning on its outcome. Typically because post-hoc interaction testing is a sensitivity analysis, and requires a lot of power, and because it's an inverted hypothesis test (the null of no-interaction is a "favorable" outcome for reporting the primary hypothesis), the alpha-level of interaction tests are typically set to 0.1 or even higher depending how imbalanced the modifier term is.
