[site]: crossvalidated
[post_id]: 538611
[parent_id]: 
[tags]: 
Less data for one feature than other features in a regression?

Say you have a 10 timeseries features, where 9 of them have 10 years of data and 1 of the features has 5 years of data. In this scenario, more data would lead to better estimates of the true coefficient for the 9 variables, so it would be advantageous to use the variable to predict. However, the exclusion of one variable is not desirable. Are there any methods to estimate coefficients of regressions based on different amounts of data? Filling the missing data with zeros would not lead to better estimates. One method I thought of that is not great is to predict based on 9 features and use that prediction as a feature with the feature with 5 years of data. I feel like some sort of bayesian method may be suitable. A similar idea can apply for covariance matrix estimations. For example, you want to compute the covariance between a number of stock returns. However, they IPO at different times so you do not have the same amount of data for each stock. Does anyone know what this problem is called, or have any information on it or solutions?
