[site]: stackoverflow
[post_id]: 5175351
[parent_id]: 5166716
[tags]: 
In order to achieve an asymptotical performance of O(n) (as the hand-coded solution does), you could use the Aggregate function like in series.Skip(period-1).Aggregate( new { Result = new SortedList (), Working = List (series.Take(period-1).Select(item => item.Value)) }, (list, item)=>{ list.Working.Add(item.Value); list.Result.Add(item.Key, list.Working.Average()); list.Working.RemoveAt(0); return list; } ).Result; The accumulated value (implemented as anonymous type) contains two fields: Result contains the result list build up so far. Working contains the last period-1 elements. The aggregate function adds the current value to the Working list, builds the current average and adds it to the result and then removes the first (i.e. oldest) value from the working list. The "seed" (i.e. the starting value for the accumulation) is build by putting the first period-1 elements into Working and initializing Result to an empty list. Consequently tha aggregation starts with element period (by skipping (period-1) elements at the beginning) In functional programming this is a typical usage pattern for the aggretate (or fold ) function, btw. Two remarks: The solution is not "functionally" clean in that the same list objects ( Working and Result ) are reused in every step. I'm not sure if that might cause problems if some future compilers try to parallellize the Aggregate function automatically (on the other hand I'm also not sure, if that's possible after all...). A purely functional solution should "create" new lists at every step. Also note that C# lacks powerful list expressions. In some hypothetical Python-C#-mixed pseudocode one could write the aggregation function like (list, item)=> new { Result = list.Result + [(item.Key, (list.Working+[item.Value]).Average())], Working=list.Working[1::]+[item.Value] } which would be a bit more elegant in my humble opinion :)
