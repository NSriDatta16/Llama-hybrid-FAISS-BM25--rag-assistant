[site]: crossvalidated
[post_id]: 447336
[parent_id]: 
[tags]: 
Differences between ML Type I, and ML Type II, and full Bayesian inference?

Can someone please point me to a good note (or tutorial) that explains the difference between the three common types of statistical inference techniques: (a) ML Type I estimation, (b) ML Type II estimation, and (c) full Bayesian inference? A simple example using a linear regression model $y=X \beta + \eta$ (where $\eta$ is normally distributed) would suffice for understanding. Update : A reference to ML Type I and Type II estimation can be found in this book Machine Learning: A Bayesian and optimization perspective by Sergios Theodoridis on pages 592 and 600. Note that, in this book these two estimators have been referred to as the MAP Type I and Type II estimators.
