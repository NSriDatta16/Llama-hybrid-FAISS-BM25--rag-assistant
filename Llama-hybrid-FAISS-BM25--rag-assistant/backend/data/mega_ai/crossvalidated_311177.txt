[site]: crossvalidated
[post_id]: 311177
[parent_id]: 
[tags]: 
Estimation of AR($p$) model by `lm` versus `arima` in R: different results

I'm in the middle of reading a book Forecasting: Principles and Practice and simultaneously trying to code "by hand" all the things, for better understanding. I've found something that I cannot explain: Given a time-series generated by AR(2) process, I try to model it as linear regression problem Judging from what I've read so far- it should be perfectly possible to find matching coefficients using both methods. Unfortunately, I get different results. Question is why? AR(p) model is described by the equation: $$ y_t = \epsilon_t + \phi_1y_{t-1} + \phi_2y_{t-2} + ... + \phi_py_{t-p} $$ I've lagged time-series by 1 and 2 and created classical dataframe with three columns: current x t-1 x t-2 x and performed regression. R code example below: library(xts) x Results are quite different: #Regression results Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 0.08173 0.11102 0.736 0.463 x.lag1 0.54860 0.10082 5.441 4.11e-07 *** x.lag2 0.15724 0.09883 1.591 0.115 # Arima results ar1 ar2 intercept 0.5919 0.1645 0.5572 s.e. 0.0983 0.1009 0.4268 Coefficients are similar, although slightly different. Questions: why is it so? Is it this random error component included in every observation in AR(p) process? how could I model ARMA process with differencing (non-stationary) using regression? Should I fit regression model to differenced-and-lagged time series just like that?
