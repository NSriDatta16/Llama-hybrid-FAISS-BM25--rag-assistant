[site]: crossvalidated
[post_id]: 400046
[parent_id]: 400003
[tags]: 
In some circumstances, many would recommend that you use random sampling with replacement instead of trying to generate separate train, validation, and test sets. Unless you have several thousands of cases, the hard 3-way split is going to limit your power because (1) you will not be using all the information in the data to develop the model, and (2) your final test set may have too few cases to give you a precise test of model performance. Furthermore, there's a danger that your apparent results will depend too much on the vagaries of the one specific data-set split that you performed to start. A better approach to model development, particularly with less than several thousands of cases, can be to develop a model based on your entire data set (taking advantage of all the data that you have) and then to test the model-building performance with multiple (e.g., hundreds) of samples taken with replacement from your full original data set and of the same size at that data set: bootstrap samples. You repeat your model-building process on each of the bootstrapped samples, and then test the performance of each model on the full original data set. The idea is that the relation of each of the bootstrap samples to your original data set is similar to the relation of your original data set to the underlying population as a whole. So the average performance (e.g., in terms of bias) of the models based on the bootstrapped samples and applied to the whole data set provides an estimate of how well the model based on your whole data set would apply to the underlying population of interest. See this page and its links for more details.
