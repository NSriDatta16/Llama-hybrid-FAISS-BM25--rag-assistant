[site]: crossvalidated
[post_id]: 38906
[parent_id]: 38894
[tags]: 
[Updated with the extra question 1] Question 1 Note that in EM typically the clusters are modeled not just by a mean and a variance, but by a mean vector and a covariance matrix . Initial parameter values are usually to use the identity matrix as covariance matrix, and a random vector as initial mean. Similar to k-means, it does pay off to carefully choose initial values (e.g. by running on a sample first, or e.g. k-means++). You can use k-means++ to obtain initial centers for EM! For updating, you assign objects "fuzzy" to all the clusters, relative to their densities (i.e. normalize by the density sum, so the assignments always total to 1 for each object!), then you compute the weighted average and weighted covariance matrix for each cluster. It's actually really simple. You might even want to avoid keeping the NxK matrix in memory. Look up "estimating multivariate gaussian mixture" for details. Question 2 Well, you can obviously do this incrementally. The means (and thus the covariances) can be updated online quite well. However: the results probably will not be as good, unless you have good starting points. So it makes sense to at least do these iterations on a reasonably sized initial sample. computing the inverse matrix is a fairly expensive operation that you do not want to do once per element So at least you should do a batch-window type of approach (to reduce the number of matrix inversions you need to compute; i'm not aware of an incremental update to the inverse matrix); maybe repeating on each batch until convergence (to improve quality).
