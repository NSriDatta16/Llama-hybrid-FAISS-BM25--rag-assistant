[site]: crossvalidated
[post_id]: 504017
[parent_id]: 504012
[tags]: 
Any neural network trained on a crossentropy loss function performs categorical prediction, but the raw (trained) model output is a probability distribution (after normalization, possibly softmax). Outputting a distribution is a hallmark of probabilistic methods. The model doesn't make a prediction, per se, but you can think of the model return as prediction distribution. This is the theoretical basis for using crossentropy functions for training models. The prediction comes from taking the choice that maximizes the probability of being correct according to the distribution. To obtain a single prediction from the model for use in an application, we guess the most-likely prediction according to the distribution we got from the neural network model. Any distinction is a result of the method used to define the model and the mathematical optimization method used to solve it.
