[site]: crossvalidated
[post_id]: 110018
[parent_id]: 109122
[tags]: 
As often in regression, there are several ways to proceed, but the most straightforward one is probably given by the moving-average approach. That is, you assume a linear (linear-in-the-parameters) relationship between your target $y_t$ ( change_in_rank ) and your regressand $x_t$ ( change_in_goodness ) given by $$ y_t = \sum_{i=1}^p \beta_{t-k} \, x_{t-k} $$ Here, the input-parameter $p$ determines the maximum lag-time. Next, you fit your model using some seleted data of the form $(x_{j-1}, \ldots, x_{j-p}; y_j)$ where $j\in \{1,\ldots, N_\text{data}\}$, e.g. by using standard least-squares regression. Finally, you can use the result either to forecast (in this case more flexible models like neural networks might be doing better), or to interprete the result using the fitted parameters $\boldsymbol \beta$ (--in interpretability, almost nothing beats linear models). If that model is not flexible enough, you can extend it to higher dimensions and more general functions $f(x_{t-1}, \ldots, f_{t-p})$, and also to autoregressive-moving-average models where you further include some previous regression results $y_j$ for $j
