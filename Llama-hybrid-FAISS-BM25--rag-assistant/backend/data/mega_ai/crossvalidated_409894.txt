[site]: crossvalidated
[post_id]: 409894
[parent_id]: 268925
[tags]: 
I reworked on the Keras MNIST example and changed the fully connected layer at the output with a 1x1 convolution layer. I got the same accuracy as the model with fully connected layers at the output. # convert class vectors to binary class matrices y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) visible = Input(shape=(28, 28, 1)) layer = Conv2D(32, (3,3), activation='relu')(visible) layer = Conv2D(32, (3,3), activation='relu')(layer) layer = MaxPooling2D(pool_size=(2, 2))(layer) layer = Dropout(0.25)(layer) layer = Conv2D(64, (3,3), activation='relu')(layer) layer = Conv2D(64, (3,3), activation='relu')(layer) layer = MaxPooling2D(pool_size=(2, 2))(layer) layer = Dropout(0.25)(layer) layer = Conv2D(128, (3,3), activation='relu')(layer) layer = Conv2D(128, (1,1), activation='relu')(layer) out_dense = Conv2D(num_classes, (1,1), activation='softmax')(layer) out_dense = GlobalAveragePooling2D()(out_dense) model = Model(inputs=visible, outputs=out_dense) model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])
