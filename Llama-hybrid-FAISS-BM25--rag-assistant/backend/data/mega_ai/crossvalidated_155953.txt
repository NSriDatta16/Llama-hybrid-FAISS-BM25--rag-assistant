[site]: crossvalidated
[post_id]: 155953
[parent_id]: 
[tags]: 
Bad matches - what to do? Data variability. Internal vs External Validity.

I have a treatment group of around 5,000 observations and a control group of 6,000. I will be estimating a difference-in-differences model and I have created a matched sample for this analysis. After matching with replacement, my groups are reduced to around 4,800 observations in each group (I'm only looking for one match per treated observation). I have 8 variables I'm interested in the groups being comparable with respect to. Before matching, the difference in means across the groups are very different (all significantly different at 1% level). After matching, 4 variables remain significantly different at the 1% level. Is there anything I can do about this? I've tried matching on covariates and on propensity scores and I can't seem to get better results. Could it just be my data has too much variance across the groups? EDIT: I have continued reading on this topic. The closest I have found to an answer is provided by Roberts and Whited (2012) in their study of endogeneity in empirical corporate finance. They say that one approach is to remove the bad matches from the sample, i.e., exclude any treatment-control pairs for whom the distance in covariates/propensity scores is too large. Clearly, this is a pretty ad hoc solution. I'm tempted to proceed with the poorly matched sample in entirety, since the trade-off between internal and external validity from hand-picking the sample seems too high. I have found that the poorly matched groups have common pre-trends, does this validate my strategy somewhat?
