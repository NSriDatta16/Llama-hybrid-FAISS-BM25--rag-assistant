[site]: crossvalidated
[post_id]: 251510
[parent_id]: 145086
[tags]: 
So the first part of question: Do data scientists need to know information theory ? I thought the answer is no until very recently. The reason I changed my mind is one crucial component: noise. Many machine learning models (both stochastic or not) use noise as part of their encoding and transformation process and in many of these models, you need to infer the probability which the noise affected after decoding the transformed output of the model. I think that this is a core part of information theory. Not only that, in deep learning, KL divergence is a very important measure used that also comes from Information Theory. Second part of the question: I think the best source is David MacKay's Information Theory, Inference and Learning Algorithms . He starts with Information Theory and takes those ideas into both inference and even neural networks. The Pdf is free on Dave's website and the lectures are online which are great
