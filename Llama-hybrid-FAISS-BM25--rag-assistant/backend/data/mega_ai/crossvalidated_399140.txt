[site]: crossvalidated
[post_id]: 399140
[parent_id]: 
[tags]: 
Examples of features construction for linear methods in Reinforcement Learning

I am referring to page 210 of of Sutton and Barto book on Reinforcement Learning available here: book Linear function approximation for state-value functions are of the form $$\hat{v}(s,\mathbf{w}) = \mathbf{w}^T \mathbf{x}(s) =\sum_{i=1}^d w_ix_i(s)$$ Accordingly, linear function approximation for action-value functions are of the form $$\hat{q}(s,a,\mathbf{w}) = \mathbf{w}^T \mathbf{x}(s,a) =\sum_{i=1}^d w_ix_i(s,a)$$ The functions $x_i(s)$ or $x_i(s,a)$ are called features of the state $s$ (or of the state-action couple $s,a$ . While I have found plenty of examples on how to choose features of the states, I haven't been able to find many references in the literature on how to choose features for state-action couples, and most of them are based on choosing features of the state $x_i(s)$ and then building the vector $\mathbf{x}(s,a)$ by simply assigning the state features in different slots of the feature vector, leaving other component at zero. To give an example, suppose we have only two actions $a_1,a_2$ available for each state $s$ . Then, given the features vector for the state $\mathbf{x}(s)$ , the features vector for the state-action couples becomes $$\mathbf{x}(s,a_1)= \left[\begin{align} &\mathbf{x}(s)\\ &\mathbf{0} \end{align}\right] $$ $$\mathbf{x}(s,a_2)= \left[\begin{align} &\mathbf{0}\\ &\mathbf{x}(s) \end{align}\right] $$ My question is then: can anybody help me to find references to different specifications of how to choose features for state-action couples?
