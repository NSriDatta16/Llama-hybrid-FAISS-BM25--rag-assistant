[site]: crossvalidated
[post_id]: 108345
[parent_id]: 
[tags]: 
Is hold-out validation a better approximation of "getting new data" than k-fold CV?

I've been rethinking an answer I gave to a question a couple weeks ago Hold-out cross-validation produces a single test set that can be used repeatedly for demonstration. We all seem to agree that this is in many ways a negative feature, since the one held-out set could turn out to be non-representative through randomness. Moreover, you could end up overfitting to the test data in the same way you can overfit to the training data. However, it seems to me that the static nature of a held-out sample is a better approximation of "getting more data" than k-fold CV, and avoids the issue of averaging across folds. I can't, however, come up with any statistical basis for this feeling I have. Is there any logic in my intuition? For instance, what I have in mind for an upcoming project is first using hold-out validation to build and test a model, then as a validation step re-drawing the hold-out set several times to show that my estimates of prediction error (on the test set) are robust to sampling error in the test set. Is this a bad idea for any reason? This question was asked before but never received an answer.
