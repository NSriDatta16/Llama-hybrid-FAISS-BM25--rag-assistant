[site]: crossvalidated
[post_id]: 397611
[parent_id]: 
[tags]: 
Neural Networks Perceptrons and MLPs

While studying as a newbie about Neural Networks I started as everyone from the basics (perceptrons, MLPs) then how backpropagation works before dive in to harder deep learning concepts. Now, I am trying to solve exercices (theoretical and practical) in order to practice and I have two questions. 1) I read that the Perceptron (single neuron) relates to a logistic regression classifier in particular, a (binary) logistic regression classifier is the same as a (single neuron) Perceptron with a sigmoid activation function. Is it true? How can I prove it? any link/example with examples etc. 2) A Multi-layer NN without activation function is equivalent to applying a linear transformation to the input data. Can someome explain me why this is true? an example?
