[site]: crossvalidated
[post_id]: 519219
[parent_id]: 
[tags]: 
Why do parameters go untested in Machine Learning?

I finished up a machine learning (ML) course a while back. Everything was as an optimization problem. No matter what predictive challenge you face in ML, you're generally minimizing some objective (i.e., cost) function. In so doing, you come up with "optimal" parameters that satisfy the equation you're working with (e.g., gradient descent and linear regression where MSE is the objective function you minimize). Is it the case with all machine learning models that, when you find the optimal parameters that minimize your objective function, you are also, almost by definition, finding the same statistically significant coefficients you would otherwise discover if you were to attack the problem from a stats perspective where the focus is on tests of statistical significance? Let's define "stats perspective" as running a model in R and adding or deleting new variables based on their statistical significance or degree to which they change AIC .
