[site]: crossvalidated
[post_id]: 111899
[parent_id]: 43942
[tags]: 
Most of the papers you'll find on the subject will deal with matrices where the ratings are on a scale [0,5]. In the context of the Netflix Prize for example, matrices have discrete ratings from 1 to 5 (+ the missing values). That's why the squared error is the most spread cost function. Some other error measures such as the Kullback-Leibler divergence can be seen. Another problem that can occur with standard matrix factorization is that some of the elements of the matrices U and V may be negative (particularly during the first steps). That's a reason why you wouldn't use the log-loss here as your cost function. However, if you're talking about Non-negative Matrix Factorization you should be able to use the log-loss as your cost function. You are in a similar case than Logistic Regression where log-loss is used as the cost function: your observed values are 0's and 1's and you predict a number (probability) between 0 and 1.
