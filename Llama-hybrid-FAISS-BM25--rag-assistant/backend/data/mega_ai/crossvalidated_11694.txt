[site]: crossvalidated
[post_id]: 11694
[parent_id]: 11691
[tags]: 
I have just started using clustering algorithms recently, so hopefully someone more knowledgeable can provide a more complete answer, but here are some thoughts: 'Meaningful', as I'm sure you're aware, is very subjective. So whether the clustering is good enough is completely dependent upon why you need to cluster in the first place. If you're trying to predict group membership, it's likely that any clustering will do better than chance (and no worse), so the results should be meaningful to some degree. If you want to know how reliable this clustering is, you need some metric to compare it to. If you have a set of entities with known memberships, you can use discriminant analysis to see how good the predictions were. If you don't have a set of entities with known memberships, you'll have to know what variance is typical of clusters in your field. Physical attributes of entities with rigid categories are likely to have much lower in-group variance than psychometric data on humans, but that doesn't necessarily make the clustering 'worse'. Your second question alludes to 'What value of k should I choose?' Again, there's no hard answer here. In the absence of any a priori set of categories, you probably want to minimize the number of clusters while also minimizing the average cluster variance. A simple approach might be to plot 'number of clusters' vs 'average cluster variance', and look for the "elbow"-- where adding more clusters does not have a significant impact on your cluster variance. I wouldn't say the results from k-means is meaningless if it cannot be visualized, but it's certainly appealing when the clusters are visually apparent. This, again, just leads back to the question: why do you need to do clustering, and how reliable do you need to be? Ultimately, this is a question that you need to answer based on how you will use the data.
