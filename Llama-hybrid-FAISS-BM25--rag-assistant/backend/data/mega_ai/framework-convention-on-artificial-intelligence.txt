The Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law (also called Framework Convention on Artificial Intelligence or AI convention) is an international treaty on artificial intelligence. It was adopted under the auspices of the Council of Europe (CoE) and signed on 5 September 2024. The treaty aims to ensure that the development and use of AI technologies align with fundamental human rights, democratic values, and the rule of law, addressing risks such as misinformation, algorithmic discrimination, and threats to public institutions. More than 50 countries, including the EU member states, have endorsed the Framework Convention on Artificial Intelligence. Background The development of the Framework Convention on AI emerged in response to growing concerns over the ethical, legal, and societal impacts of artificial intelligence. The Council of Europe, which has historically played a key role in setting human rights standards across Europe, initiated discussions on AI governance in 2020, leading to the drafting of a binding legal framework. The process of creating the Framework Convention began in 2019 with the ad hoc Committee on Artificial Intelligence (CAHAI) assessing the feasibility of the instrument. In 2022, the Committee on Artificial Intelligence (CAI) took over the process, drafting and negotiating the text of the Convention. The treaty is designed to complement existing international human rights instruments, including the European Convention on Human Rights and the Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data. Structure and content The Convention establishes fundamental principles for AI governance, including transparency, accountability, non-discrimination, and human rights protection through eight chapters and 26 articles. Adopted in 2024, this landmark treaty addresses AI governance through seven core principles and detailed implementation mechanisms. It mandates risk and impact assessments to mitigate potential harms and provides safeguards such as the right to challenge AI-driven decisions. It applies to public authorities and private entities acting on their behalf but excludes national security and defense activities. Implementation is overseen by a Conference of the Parties, ensuring compliance and international cooperation. Activities within the AI system lifecycle must adhere to seven fundamental principles, ensuring compliance with human rights, democracy, and the rule of law. The treaty also establishes remedies, procedural rights and safeguards, and risk and impact management requirements to promote accountability, transparency, and responsible AI development. The treaty consists of five chapters. Chapter I contains general provisions. Chapter II states the general obligation to protect human rights and the integrity of democratic processes and respect of the rule of law. The main principles and rights are contained in Chapter III, which consists of Articles 6 to 13. Chapter IV (Articles 14 to 15) sets up the legal remedies. Chapter V states the risk and impact management framework. Chapter VI facilitates the implementation criteria of the treaty. Chapter VII sets the co-operation and oversight mechanisms. Chapter VIII contains various concluding clauses. Article 1 declares the objectives of the treaty, to ensure that activities within the lifecycle of artificial intelligence systems are fully consistent with human rights, democracy and the rule of law. Entry into force The treaty will enter into force on the first day of the month following the expiration of a period of three months after the date on which five ratification made by five countries, including three member states of the Council of Europe. Competing approaches While the CoE's AI Convention represents a multilateral effort to regulate AI through a human rights-based approach, alternative frameworks have also been proposed. One notable example is