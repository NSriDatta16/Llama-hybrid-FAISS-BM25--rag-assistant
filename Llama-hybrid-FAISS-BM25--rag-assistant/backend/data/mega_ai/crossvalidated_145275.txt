[site]: crossvalidated
[post_id]: 145275
[parent_id]: 145266
[tags]: 
To answer the question in the title: performance heavily depends on the vectorization scheme, that is on what your features are (e.g. feature engineering) and how they are normalized (they should at least be on comparable scales). It also depends tremendously on how well your kernel function aligns with the realities of your application domain. Your first vectorization makes no sense as there is no structure in it to learn for an SVM. You have to encode your data in a way that actually contains information. You must realize that methods like SVM work on the concept of distance. If you have an ordinal column with 'feature ids', there is no distance defined in that dimension, and hence it is pretty much useless for learning purposes. Your second method works much better because you implicitly added a lot of information by defining dimensions that describe the brand of a car.
