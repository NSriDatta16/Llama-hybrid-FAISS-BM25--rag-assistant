[site]: datascience
[post_id]: 39648
[parent_id]: 
[tags]: 
ValueError: Numpy arrays that you are passing to your model is not the size the model expected

I am trying to perform concatenation on the Bidirectinal LSTM layer. I have my model defined like this: embedding_layer=Embedding(words,300,input_length=trainDataVecs.shape[1],weights=[embedding_matrix]) LSTM_word_1 = Bidirectional(LSTM(80, activation='tanh', dropout_W = 0.25, dropout_U = 0.25,return_sequences=True)) model1 = Input(shape=(trainDataVecs.shape[1],),dtype='int32') embedded_sequences1=embedding_layer(model1) lstm_word_out_1 = LSTM_word_1(embedded_sequences1) LSTM_word_2 = Bidirectional(LSTM(80, activation='tanh', dropout_W = 0.25, dropout_U = 0.25,return_sequences=True)) model2 = Input(shape=(trainDataVecs.shape[1],),dtype='int32') embedded_sequences2=embedding_layer(model2) lstm_word_out_2 = LSTM_word_2(embedded_sequences2) conc=concatenate([MaxPooling1D()(lstm_word_out_1),AveragePooling1D()(lstm_word_out_2)]) outp = Dense(classes_num, activation='sigmoid')(conc) model=Model(input=[model1,model2],output=outp) I am fitting like this: history=model.fit(trainDataVecs,Y_train,shuffle=True,batch_size=512,epochs=10,validation_data=(valDataVecs,valid_Y)) But I am getting the error like: ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays PS: The training and validation vectors are arrays. But still I am getting the error. I think it might be because of the model definition but I am not sure.
