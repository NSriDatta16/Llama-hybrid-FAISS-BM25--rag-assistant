[site]: datascience
[post_id]: 123839
[parent_id]: 123832
[tags]: 
I've typically seen (and used) approach B, but at a finer level of granularity - generate embeddings for a set of documents at the chunk level, store the embeddings in a vector database, and then take each query, generate embedding, and use the query embedding to find the top n most similar results in the vector dB.
