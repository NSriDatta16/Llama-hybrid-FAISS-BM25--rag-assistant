[site]: datascience
[post_id]: 73161
[parent_id]: 73151
[tags]: 
One solution could be to: Get sentence embeddings from FastText Compute Euclidean Distance between the consecutive sentences If the distance between the consecutive sentences is close to 1, then, you may say the two sentences are talking about different topics. See here how to compute sentence embeddings for the English language: https://github.com/facebookresearch/fastText/blob/5b5943c118b0ec5fb9cd8d20587de2b2d3966dfe/python/fasttext_module/fasttext/FastText.py#L127 fasttext.util.download_model('en', if_exists='ignore') # English ft = fasttext.load_model('cc.en.300.bin') fasttext.util.reduce_model(ft, 20) def get_fasttext_sentence_embedding(sentence, ft): if pd.isna(sentence): return np.zeros(20) return ft.get_sentence_vector(sentence) Then, compute the euclidian distance between fast text embeddings of consecutive sentences. The same can be done using LDA (topic model), but, that would require a lot of text to model the topics.
