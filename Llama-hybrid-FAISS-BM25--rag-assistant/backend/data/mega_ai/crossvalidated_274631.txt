[site]: crossvalidated
[post_id]: 274631
[parent_id]: 274626
[tags]: 
Caveat: I'm not an expert in this field. If the theoretical distribution of sample impulse response function (IRF) is Gaussian (that is, at every time point the distribution of errors is Gaussian) then 1.96 standard errors covers about 95.0% of the distribution of the sample IRF, and 2 standard errors covers about 95.4% of the distribution of the sample IRF. As Michael Chernick pointed out in the comments, this is "close enough" that people use ±2 standard errors to mean "95% theoretical coverage". Note that the IRF for a typical Vector Autoregression model is asymptotically Gaussian [1]. If you imagine testing, at every time point, the hypothesis that the IRF is zero against the alternative that the IRF is nonzero, and if you assume that the test statistic has a Gaussian distribution, then a theoretical 95% confidence interval is equivalent to the 95% theoretical coverage interval described above. So under a typical set of assumptions, they're more or less the same. But there are several ways to compute a confidence interval for an impulse response function [2], including simulation-based methods. These could in principle lead to a 95% confidence interval that does not line up with the theoretical Gaussian 95% coverage interval. [1] Cf. lecture notes by Luca Gambetti, http://pareto.uab.es/lgambetti/VAR_Forecasting.pdf , citing: Hamilton, James D., 1994, Time Series Analysis, Princeton University Press. [2] Griffiths, William and Lütkepohl, Helmut. (1990). Confidence intervals for impulse response functions: a comparison of asymptotic theory and simulation approaches. https://www.une.edu.au/__data/assets/pdf_file/0018/20484/emetwp42.pdf .
