[site]: crossvalidated
[post_id]: 639735
[parent_id]: 639289
[tags]: 
Would bootstrapping the test set and evaluating many times You do not need to bootstrap the test set. Your test set already contains multiple observations and you evaluate an error for each of them individually, giving you a distribution of errors. Based on that distribution of errors you can analyse a confidence interval for the average error. If the error is a binary value, like in classification, then you can compute the average directly from the number of false and correct errors by using one of many methods to compute the confidence interval for a binomial distributed proportion . In this case bootstrapping would be unnecessary. If the error is a scalar, then you can use a normal distribution approximation, which may work well even when your original distribution is not normal distributed, because the mean of a sample approaches a normal distribution (not if the distribution has problematic tails, but an empirical distribution doesn't often have this, and with problematic tails a bootstrap will not be accurate either). Alternatively you can bootstrap the distribution of errors (but not the test set directly) to compute how a potential distribution of means of errors would look like.
