[site]: crossvalidated
[post_id]: 38249
[parent_id]: 
[tags]: 
Generalizing Add-one/Laplacian Smoothing

Let us assume we are estimating a proportion or rate of "hits". If we have $h$ hits and $m$ misses, the obvious estimator is $\dfrac{h}{h + m}$ In order to avoid unreasonable estimations of $0$ or $1$ when our sample size is small, we can do some (Add-1/Laplacian) smoothing: $\dfrac{h+1}{h+m+2}$ I have read that this has a Bayesian interpretation of having a 50/50 prior over the hit-rate. A couple ideas about generalizing this spring to mind, but I'm uncertain as to the theory. Level of confidence If I'm very confident that the hit rates are 50/50, I could add $2$ instead of $1$ to the hits and misses. Or if I'm less confident, I could add $1/2$. What doesn't immediately make sense to me though is what the Bayesian interpretation (if any) is. Isn't the prior just $p = 0.5$, and that's that? Or is there a natural way to represent concentration? If so, what level of concentration does the Laplacian add-one smoothing correspond to? If not, why doesn't this variable-confidence scheme make sense? Different prior probabilities Instead of a uniform prior, we could have some other prior over the hit rate. To accomplish this, we could add some number to the hits and some number to the misses such that the proportion worked out. However, I don't immediately know how to parameterize it. For instance, if I have a prior of 1/4, should I add $0.5$ and $1.5$ to the hits and misses, or should I add $1$ and $3$? This ties into the previous question about level of confidence. I'd like to parameterize this so I can change the prior probability without altering the confidence (if such a concept makes sense).
