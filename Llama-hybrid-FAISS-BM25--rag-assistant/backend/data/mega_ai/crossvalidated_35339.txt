[site]: crossvalidated
[post_id]: 35339
[parent_id]: 35336
[tags]: 
While this dataset may be "large" by MRI standards, it's nowhere near big enough to cause problems in R. Using random data of these dimensions, and the default settings, on a fairly average machine (MacBook Air, late 2011), I was able to run R's randomForest in 37 seconds, and svm (from the e1071 package) in 6 seconds. In general, R should be able to cope with datasets about one to three orders of magnitude larger than what you're currently working with, depending on the specific task you're trying to accomplish. If you do run into trouble, you may find that using a 64-bit version of R will help. This question on Stack Overflow also lists some tips and tricks for dealing with larger datasets.
