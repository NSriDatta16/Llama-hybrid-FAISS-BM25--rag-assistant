[site]: crossvalidated
[post_id]: 201368
[parent_id]: 201367
[tags]: 
I am guessing that your data will be much larger. If you are interested in using Python then for Neural Networks (NN) you can look into the library you mentioned tensorFlow but I also recommend looking into theano and lasange . There are however many different algorithms that I would suggest for this type of classification based off of personal experience. There is an extension of gradient boosting machines library in both Python and R called xgboost . This particular library is very powerful and is responsible for a lot of winning algorithms on Kaggle. Finally, I think you will find a fairly good classification in both the RandomForestClassifier and ExtraTressClassifier found in the sklearn.ensemble modules in python. In general, these algorithms perform fairly well and are also robust to things like missing values and outliers. Note Just to add a little more to this, another way to create a more powerful classifier would be to run all of the different algorithms mentioned above and take a majority vote of the classification.
