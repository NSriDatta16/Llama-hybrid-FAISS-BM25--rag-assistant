[site]: crossvalidated
[post_id]: 295264
[parent_id]: 
[tags]: 
Checking cross-validation accuracy using regression

I want to empirically check cross-validation accuracy. That is, I am trying to check and better understand bias and variance in the estimation of error by varying the $K$s in K-Fold. For this purpose I need the real error of the model. My idea is to use this function: $$y(x) = \log{x}\sin{x} + 1/10N(0, 2\log(1+x)) + 2\cos{x}$$ to generate a random sample $D$ and then use cross-validation techniques for this sample $D$ and a regression model (simply a polynomial of degree $10$) to estimate the error. Then I could compare this to the error obtained by using the model to a very large sample generated from the function above. I would do this because for example neural networks are computationally expensive. Is this approach reasonable?
