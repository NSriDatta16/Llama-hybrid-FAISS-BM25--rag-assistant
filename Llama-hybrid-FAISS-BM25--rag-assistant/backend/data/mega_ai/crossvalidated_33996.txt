[site]: crossvalidated
[post_id]: 33996
[parent_id]: 
[tags]: 
How to know the stochastic gradient descent is converging when the objective function is expensive to compute

How can I know if the stochastic gradient descent algorithm is converging. I cannot plot my objective function and take its average for lets say every 1000 iterations to see the trend. My objective function itself is huge, so it takes lot of time to compute the objective function itself. In this situation, how to determine if the algorithm is converging. I know what the parameter values should be. But I see the algorithm is fluctuating around a value which is smaller than the actual one. My function has a global maxima. So it should reach that maxima isn't it? The function is concave
