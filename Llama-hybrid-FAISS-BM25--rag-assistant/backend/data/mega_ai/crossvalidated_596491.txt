[site]: crossvalidated
[post_id]: 596491
[parent_id]: 596481
[tags]: 
"Detecting heteroscedasticity" is a kind of magical thinking. As you might expect, there's only one way that variance can be homoscedastic in a sample, but there are infinite ways it may be heteroscedastic. The assumption that heteroscedasticity would be apparent in measured covariates is tenuous enough. More realistically, there are exogenous trends that don't show up in the covariates but do impact analyses. Add the issue of calibrating an actual hypothesis test and identifying a suitable number of subgroups, it quickly slips out of hand. Consider the large sample size dilemma - at large enough $N$ virtually every assumption-based test fails, but this barely precludes the value of the analysis. Essentially, you punish yourself for having good data. I often find I can simulate data with a known failure of assumptions yet with standard parametric models, I obtain reasonable precise estimates, well conserved interval estimates, and powerful and well calibrated tests. Does this mean one should not assess their assumptions? Clearly not. But somehow in the statistics pedagogy, "assessing assumptions" has been equated to conducting tests, which apropos of nothing we can't rely on those $p$ -values at all. Infinitely more valuable are the residual plots - residual versus covariate, and residual versus fitted, residual versus leverage, and so on. Correlation between sites or over time can be compared using the ICC or variograms (note: correlation functionally is similar to heteroscedasticity). On the chance that variance does depend on any such feature, a visual or quantitative summary should suffice. I've never had to report the actual results in the form of a statistical test for any published research manuscript. If the goal of model fitting is inference rather than prediction, the robust variance estimate, also called Huber White or Sandwich variance errors, provide accurate 95% CIs and p-values even in the presence of heteroscedasticity, at barely any impact to power. I would say that this issue has been almost completely resolved as a consequence of these error estimators. In stata, you enter , robust=TRUE . In R, using the sandwich and lmtest package, you can enter waldtest with vcov=VCOVHC to obtain robust errors.
