[site]: crossvalidated
[post_id]: 592598
[parent_id]: 592587
[tags]: 
More generally (ignoring the specifics of the problem), decision trees (and related algorithms like gradient boosted decision trees, random forest etc.) will make predictions for numeric feature values outside of the range of feature values seen at training. The splits for branches of the tree are usually done as "variable #1 = X" (whether it's =, or doesn't really matter) and such splits are only done at values that lie within the range of values seen during training, so any value higher than values seen during training will essentially be treated like the highest value seen during training. Similarly, the a value lower than the lowest value seen during training will be treated like the lowest value seen during training. In other words, no matter how far outside the range of values seen during training, the predictions will no longer change beyond the highest (or lowest) feature value seen during training. This has also been summarized as "decision trees don't extrapolate", which is to say that even if there is e.g. a blatantly obvious linear relationship of feature to outcome, a decision tree will not continue to extrapolate it, but rather "stay flat with its predictions". In contrast, other models (e.g. linear regression, neural networks etc.) will "happily" extrapolate patterns beyond the training data. Of course, this may often be a very, very wrong thing to do. In general, extrapolation beyond the training data involves a lot of assumptions and is usually best done if one truly understands the underlying data generating process instead of modeling it empirically. An example where it is to some extent possible is e.g. predicting drug concentrations for individuals that are much larger or smaller than those in early clinical trials of a drug from pharmacokinetic model (that tends to model the process of absorption, distribution and excretion of a drug taking into account some characteristics of patients). If one does not have such a situation, then perhaps we sometimes need to predict something, but should then be much more cautious about relying on the prediction.
