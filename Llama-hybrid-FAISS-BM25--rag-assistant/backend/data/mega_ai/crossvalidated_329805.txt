[site]: crossvalidated
[post_id]: 329805
[parent_id]: 
[tags]: 
Random sequence and uniform distribution? Is this always the case?

(Short version) Is this always the case that a truly generated random sequence (of whole numbers) conforms to (or at least expected to conform to) a uniform distribution? (Long version) The most general property of a random sequence that I usually found is that its " unpredictability " . Although it is intuitive, I've found no further clarification of "unpredictability" during my search. Afterward, I found a more specific property of a random sequence that reads : Each of the ten digits 0 through 9 will occur about 1/10 of the time in a (uniform) sequence of random digits. Each pair of two successive digits should occur about 1/100 of the time, and so on. Yet if we take a truly random sequence of a million digits, it will not always have exactly 100,000 zeros, 100,000 ones, etc. In fact, chances of this are quite slim; a sequence of such sequences will have this character on the average . Another argument that I found supporting the aforementioned characteristic is that of this page , which states: One definition of randomness implies that the number of heads equals the number of tails. With an unbiased coin, there should, on average, be 50 heads in 100 flips. According to statistical theory, the number of heads will equal the number of tails only in an infinite series of flips. Well, it seems that all of them implicitly or explicitly agree that a random sequence of numbers would conform to a uniform distribution (correct me if you find I took them wrong) Here is my problem: ( Consider a sequence s contains numbers in a fixed set of basis numbers b ) -In the first place, I agree that it is so true that if the next upcoming digit of a truly randomly generated sequence can be any number in a fixed basis set b , which equal probability to appear for each of number in the set (uniformly distributed) then the next coming digit of the sequence is unpredictable and hence nothing happens to conflict with my thoughts. -For a while, however, I started to wonder if we adopt that s was randomly generated so, the time that every number in the set b appear in s would converge to a constant C (i.e. C = Length_of_sequence / Size_of_ b due to the uniform distribution ) when the length of the sequence approaches infinity.That said, there exists a constrain on the times that each number in the basis set b appear in the sequence s , they much be equal to each other (or expected to be). To this end, is s called randomly generated anymore? While there is a "pattern" on the time each number comes to appear in s . Intuitively, I believe that some sort of so-called "degree-of-freedom" was lost. We can somehow be able to have strong belief to the next number X in b to come next in s because X hasn't appeared frequently enough in s before compared to another numbers? My question is: Why do people mostly define the notion of randomness by uniform distribution? Is it always correct/sufficient to resort to uniform distribution to guarantee "randomness"? Why don't we condition the randomness on another basis? I also found a question that conceptually resembles to my question but was phrased in a difference manner. All of your ideas and thoughts are welcomed. Thank you for reading.
