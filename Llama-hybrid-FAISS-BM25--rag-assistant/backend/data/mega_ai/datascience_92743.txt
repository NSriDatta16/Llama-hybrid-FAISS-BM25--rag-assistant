[site]: datascience
[post_id]: 92743
[parent_id]: 92740
[tags]: 
Those vector relations are not exact. Rest assured that king - queen â‰  man - woman . What we do is finding the closest vectors to the result of king - man + woman . One of the closest vectors is queen . Nevertheless, when we try the "parallelogram approach" to verify word relations, in most cases, the closest vector is the original one. The fact that we disregard the original word as a sensible result is due to the original implementation of word2vec, as shown in the study Fair is Better than Sensational: Man is to Doctor as Woman is to Doctor . This implementation quirk is actually one of the sources of gender bias attributed to word embeddings. There are other articles studying the limitations of the analogies based on word embeddings, like this and this . That being said, there are also studies of the relationships that can be found in word representation spaces, like this one , which studies different types of relationships, e.g. class-inclussion, part-whole, attributes, etc. You may find the main figure of the article interesting:
