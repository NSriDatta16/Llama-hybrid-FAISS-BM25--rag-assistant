[site]: stackoverflow
[post_id]: 1193833
[parent_id]: 382186
[tags]: 
at college we had this book which I still find extremely useful: Conte, de Boor; elementary numerical analysis; Mc Grow Hill. The relevant paragraph is 6.2: Data Fitting. example code comes in FORTRAN, and the listings are not very readable either, but the explanations are deep and clear at the same time. you end up understanding what you are doing, not just doing it (as is my experience of Numerical Recipes). I usually start with Numerical Recipes but for things like this I quickly have to grab Conte-de Boor. maybe better posting some code... it's a bit stripped down, but the most relevant parts are there. it relies on numpy, obviously! def Tn(n, x): if n==0: return 1.0 elif n==1: return float(x) else: return (2.0 * x * Tn(n - 1, x)) - Tn(n - 2, x) class ChebyshevFit: def __init__(self): self.Tn = Memoize(Tn) def fit(self, data, degree=None): """fit the data by a 'minimal squares' linear combination of chebyshev polinomials. cfr: Conte, de Boor; elementary numerical analysis; Mc Grow Hill (6.2: Data Fitting) """ if degree is None: degree = 5 data = sorted(data) self.range = start, end = (min(data)[0], max(data)[0]) self.halfwidth = (end - start) / 2.0 vec_x = [(x - start - self.halfwidth)/self.halfwidth for (x, y) in data] vec_f = [y for (x, y) in data] mat_phi = [numpy.array([self.Tn(i, x) for x in vec_x]) for i in range(degree+1)] mat_A = numpy.inner(mat_phi, mat_phi) vec_b = numpy.inner(vec_f, mat_phi) self.coefficients = numpy.linalg.solve(mat_A, vec_b) self.degree = degree def evaluate(self, x): """use Clenshaw algorithm http://en.wikipedia.org/wiki/Clenshaw_algorithm """ x = (x-self.range[0]-self.halfwidth) / self.halfwidth b_2 = float(self.coefficients[self.degree]) b_1 = 2 * x * b_2 + float(self.coefficients[self.degree - 1]) for i in range(2, self.degree): b_1, b_2 = 2.0 * x * b_1 + self.coefficients[self.degree - i] - b_2, b_1 else: b_0 = x*b_1 + self.coefficients[0] - b_2 return b_0
