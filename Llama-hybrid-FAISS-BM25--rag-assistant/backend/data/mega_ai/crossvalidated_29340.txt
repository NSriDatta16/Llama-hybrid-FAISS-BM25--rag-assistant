[site]: crossvalidated
[post_id]: 29340
[parent_id]: 29325
[tags]: 
The differences have been settled by DocBuckets and Pardis, but I want to add one way to compare their performance not mentioned. Linear regression is usually solved by minimizing the least squares error of the model to the data, therefore large errors are penalized quadratically. Logistic regression is just the opposite. Using the logistic loss function causes large errors to be penalized to an asymptotically constant. Consider linear regression on a categorical {0,1} outcomes to see why this is a problem. If your model predicts the outcome is 38 when truth is 1, you've lost nothing. Linear regression would try to reduce that 38, logistic wouldn't (as much).
