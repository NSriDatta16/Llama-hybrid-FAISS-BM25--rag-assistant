[site]: crossvalidated
[post_id]: 495083
[parent_id]: 
[tags]: 
Posterior of a Normal distribution

I have a problem obtaining a posterior of a normal multivariate distribution. The problem is as follows: Assuming $ \mathbf{X} \sim N_p (\boldsymbol{\mu}, \boldsymbol{\Sigma}) $ , known $\boldsymbol{\Sigma}$ , I am interested in estimating a posterior for $\boldsymbol{\mu}$ . Assuming $\boldsymbol{\mu} \sim N_p(\boldsymbol{\mu}_0, \boldsymbol{\Sigma}_0)$ (conjugate prior), we have that for a sample $\mathbf{X}_1, \cdots, \mathbf{X}_n$ of $\mathbf{X} $ , $$\pi(\boldsymbol{\mu}|\mathbf{X}) \sim N(\boldsymbol{\mu}^*, \boldsymbol{\Sigma}^*),$$ on what, $\boldsymbol{\mu}^* = ( \boldsymbol{\Sigma}_0^{-1} + n\boldsymbol{\Sigma}^{-1} )^{-1}( \boldsymbol{\Sigma}_0^{-1} \boldsymbol{\mu}_0 + n\boldsymbol{\Sigma}^{-1}\bar{\mathbf{x}} )$ e $\boldsymbol{\Sigma}^* = (\boldsymbol{\Sigma}_0^{-1} + n\boldsymbol{\Sigma}^{-1})^{-1}$ . enter link description here However, by simulating this process I am getting some results that I cannot understand. Considering the case $p = 2$ . For $\boldsymbol{\Sigma} = \begin{pmatrix} 10 & 7.668116 \\ 7.668116 & 12 \end{pmatrix}$ , when simulating $10000$ observations of the vector $\mathbf{X}$ , and obtaining the posteriori mean vector $\mathbf{X}$ , I get some results that I cannot understand. Considering it a priori for $\boldsymbol{\mu} \sim N_2\left( \begin{pmatrix} 25\\ 50 \end{pmatrix}, \begin{pmatrix} 1000 & 0\\ 0 & 1000 \end{pmatrix} \right)$ , I made a function in R to return the values of the parameters of the posterior library(mvtnorm) paramPosteriorMu = function(X, Sigma, mu0, Sigma0){ n = nrow(X) SigmaStar = solve( solve(Sigma0) + n*solve(Sigma) ) muStar = SigmaStar %*% ( solve(Sigma0)%*%mu0 + n*solve(Sigma)%*%colMeans(X) ) return(list(mu = muStar, Sigma = SigmaStar)) } #observed data: Sigma = matrix(c(10, 7.668116, 7.668116, 12), nc = 2) X = rmvnorm(10000, mean = c(5, 2), sigma = Sigma) #prior: mu0 = c(25,50) Sigma0 = matrix(c(1000, 0, 0, 1000), nc = 2) #posterior: paramPosteriorMu(X, Sigma, mu0, Sigma0) In my R I'm getting an answer $Sigma [,1] [,2] [1,] 0.0009999984 0.0007668099 [2,] 0.0007668099 0.0011999980 One question, I am not a specialist in Bayesian inference, why are the sigma values so close to zero? The Wikipedia, where I got the result about a posteriori, says that "mean was estimated from observations with total precision (sum of all individual precisions) ${\displaystyle {\boldsymbol {\Sigma }}_{0}^{-1}}$ and with sample mean ${\displaystyle {\boldsymbol {\mu }}_{0}}$ " Is there a misunderstanding in the implementation? Or some error in my understanding? Thanks in advance!
