[site]: crossvalidated
[post_id]: 430332
[parent_id]: 430327
[tags]: 
Adapted from a related answer of mine : Bagging is an important feature of random forests (though not exclusive to them). Every tree in the random forest is fitted to only 2/3 of the data points in the dataset, randomly selected. And so every data point is used for fitting by only 2/3 of the trees in the forest. The 'bag' represents the points that were used for fitting a tree; OOB points are therefore the remaining 1/3 of points that were not used for fitting it. OOB predictions for a specific data point are generated by using only the 1/3 of the trees that do not have that data point in them to make the predictions. This provides a more unbiased estimate of the prediction error of the random forest for that data point. This process is repeated for all data points to generate OOB predictions for every point in the dataset. For the same reasons, I would expect OOB proximity estimation to be less biased and more reliable than 'in-bag' estimation.
