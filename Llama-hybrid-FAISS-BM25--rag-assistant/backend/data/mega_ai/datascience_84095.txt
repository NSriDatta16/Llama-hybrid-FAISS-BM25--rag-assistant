[site]: datascience
[post_id]: 84095
[parent_id]: 84087
[tags]: 
It looks like the inverse reinforcement learning problem defined by Stuart Russell as Given measurements of an agent’s behaviour over time, in a variety of circumstances. measurements of the sensory inputs to that agent; a model of the physical environment (including the agent’s body). Determine the reward function that the agent is optimizing. It is particularly difficult in your case because you only have observations of a tiny subset of the actual state of a customer and the environment. I don't think it is solvable without being able to actively explore the actions or without really strong assumptions or a model of the dynamics. If you can assume that the historical supervisors did their best to help their clients to return to work, your task simplifies to: given the historical actions up to a given point, predict the next historical action. Even with this simpler problem, you still have to be careful with conditioning, the possible non-stationarity in time, choosing a good model (perhaps similar to what you tried), etc.
