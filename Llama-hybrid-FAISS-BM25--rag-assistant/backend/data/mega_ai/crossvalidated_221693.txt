[site]: crossvalidated
[post_id]: 221693
[parent_id]: 220672
[tags]: 
The answer from @FrankHarrell, and associated comments from him and @NickCox, answer the question admirably. I would add that the implicit focus on the shape of raw distributions of predictors and outcome variables is misplaced; in linear modeling, what's important is linearity of relations of predictors to outcome and the distribution of residuals. I also wish to add information on two articles cited in the original question that might explain some sources of the difficulty sensed by the OP. It's important to evaluate articles critically, not just accept them because they happen to have been published. The cited paper on misuses of log transformations by Feng et al rightly notes some abuses that are possible with log transformations, but tends to leave the impression that log transformations should be avoided rather than used intelligently. For example, the paper says: using transformations in general and log transformation in particular can be quite problematic in practice to achieve desired objectives with alleged difficulties noted such as: there is no one-to-one relation between the original mean and the mean of the log-transformed data...it is not conceptually sensible to compare the variability of the data with its transformed counterpart ... comparing the means of two samples is not the same as comparing the means of their transformed versions and concluding: rather than trying to find an appropriate distribution and/or transformation to fit the data, one may consider abandoning this classic paradigm altogether... I don't see that the alleged difficulties noted in that paper provide reasons to avoid informed use of logarithmic or other transformations. Others have noted more serious deficiencies in that paper. Bland, Altman and Rohlf wrote a direct response, In defence of logarithmic transformations . The full response is apparently behind a paywall, but I believe the following quotes would constitute fair use: They do not illustrate their article with any real data, however, and appear largely to ignore the context in which log transformations are applied...They also quote out of context the people they criticise...Feng et al. also say ‘Although well-defined statistically, the quantity Exp(E(log X)) has no intuitive and biological interpretation.’ We find no problem in intuition concerning it. Although the expression looks complicated, it is simply the geometric mean. Bland, Altman and Rohlf conclude: Log transformation is a valuable tool in the analysis of biological and clinical data. We do not think anyone should be discouraged from using it by this ill-argued and misleading paper. The paper that "advises to use ANOVA to test the differences among raw fold differences (FD) in immunoblotting" deals nicely with some of the technical difficulties in performing densitometry of what are called "western blots" (difficulties of which I am painfully aware), yet the almost off-hand suggestion at the end of the paper to "Determine the average FD and associated P values for the biological replicates by importing the FD from step (2) above into a statistical analysis software package such a PRISM or Analyze IT" does not seem to have received very critical review. (It also does not rule out the possibility of log-transforming the FD values in the statistical analysis.) A suggestion to use raw FD actually contradicts the idea presented earlier in that paper that this analysis is "a very similar methodology to qPCR," or the quantitative polymerase chain reaction. Statistical analysis of qPCR is best done on the values of "cycles to threshold" or $C_t$ values. These $C_t$ values have direct $\log_2$ relations to the original amounts of the nucleic-acid sequence being analyzed. Of further note in nucleic-acid quantification, the MA plot widely used in microarray analysis is a Bland-Altman plot on logarithmic transformations of expression data. When errors are proportional to values of interest, the logarithmic transformation can make lots of sense.
