[site]: crossvalidated
[post_id]: 615825
[parent_id]: 
[tags]: 
How can I use the features embedding from wav2vec model?

I learned how to get the embedding features from wav2vec from this question but I have some questions. What is the difference between using those fixed embedding features in a downstream task and fine-tuning the model? I know that I can use the fixed embedding features with text(for example: BERT) but Does the same thing apply for audio data and wav2vec? The resulting embeddings are long sequences of vectors(for example: the sequence length is 1676 for a 30 second audio file). What is the best way to shorten that sequence assuming that my data have audio files with different length?
