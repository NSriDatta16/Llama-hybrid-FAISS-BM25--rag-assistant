[site]: crossvalidated
[post_id]: 608372
[parent_id]: 
[tags]: 
Very balanced dataset and a multiclass classification problem, no context behind the inputs. Which evaluation metric to use?

I have constructed a simple neural network model, for a classification problem, with 10 target classes where an input (with some number of features) is to be classified to only one of the 10 classes. The input data that I am provided with is just features as numbers (and their target classes) - there is no context behind it, so nothing like "vitals of cancer patients" where certain incorrect classifications would need to be punished more than others. The final layer activation function is the softmax function, and the Loss function used is categorical cross entropy. Also, the number of occurrences of each class are very similar to one another. It is very much a balanced dataset. The evaluation metrics I currently consider are: The loss function itself: categorical cross entropy. Accuracy score (because of course) Confusion matrix So my question is: Which evaluation metric is the most appropriate to use given no context whatsoever - just raw numbers and balanced classes? To add on to this question - say we were adding contexts behind the data provided, which type of contexts would warrant using each of these metrics. What would be the common use cases and drawbacks of these metrics? Are there alternate metrics that are advisable to look at for this class of problems (classification problem with multiple classes)?
