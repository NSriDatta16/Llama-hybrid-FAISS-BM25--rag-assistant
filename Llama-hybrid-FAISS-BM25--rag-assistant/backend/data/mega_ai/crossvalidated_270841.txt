[site]: crossvalidated
[post_id]: 270841
[parent_id]: 270704
[tags]: 
Let's see. Multi-label classification is the problem of assigning multiple labels (categories) to each input sample. The classical example is blog posts and tags. Say you want to train an algorithm to try and figure out what tags a StackOverflow (SO) question will be assigned by its author, given only its title and body. You algorithm needs to provide multiple outputs for each input sample. So, for instance, you want your algorithm to be able to assign all tags it thinks that SO question would have in real life. Can you think of a dead simple way to do that using regular machine learning tools? You probably have come up with what's called Binary Relevance . It's an obvious way to transform the problem so that you can use regular ML tools. You just train a binary classifier for each tag individually and, for each classifier that returns True , you assign that tag to that input sample. This is the binary relevance method (note that this is also called OvR (one versus rest) in toolkits such as scikit-learn). Binary relevance is a problem transformation method because it's equivalent to transforming a single input sample with 4 tags into 4 separate input samples, one for each tag. After transforming the problem like this, you can use any single-label machine learning algorithm. This is different from algorithm adaptation methods , where you don't just transform the dataset and then use any old single-label ML algorithm. These are algorithms specifically tailored for multi-label classification; these are multi-label adaptations for many popular algorithms such as neural nets, kNN, random forests, etc. All Stackexchange forums (like this one) have public datasets which are good ways to train multi-label algorithms.
