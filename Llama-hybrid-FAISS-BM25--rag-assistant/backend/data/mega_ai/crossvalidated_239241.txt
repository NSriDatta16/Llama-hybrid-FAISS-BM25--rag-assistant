[site]: crossvalidated
[post_id]: 239241
[parent_id]: 239217
[tags]: 
In general, artificially biasing the sampling of parts of the train set (either directly, by weighting, or by synthesis), is problematic. Virtually every classifier also learns the a-priori label distribution. In Naive Bayes this can be seen very directly. In other techniques (e.g., logistic regression, classification trees, etc.), this appears too indirectly. The cases where oversampling/overweighting makes sense, are different: The Wikipedia entry , for example, states The usual reason for oversampling is to correct for a bias in the original dataset. One scenario where it is useful is when training a classifier using labelled training data from a biased source, since labelled training data is valuable but often comes from un-representative sources. and sites as an example a sample where ~67% are male, whereas they are known to compose ~50% of the population. A different case where overweighting (possibly by oversampling) is when the missclassification penalties are unequal. Two things to note when dealing with highly imbalanced data: When tuning parameters (using the train set), it might be important to use stratified cross validation . It pays to ensure that the train set and test set are prepared by a stratified split as well. For highly-imbalanced data, you might also need to make the test set larger than you usually do, in order to reduce test noise.
