[site]: crossvalidated
[post_id]: 312074
[parent_id]: 
[tags]: 
How to model 100% success probability for one group only in multi-factor model with a Bernoulli variable?

I am currently trying to do a Bayesian analysis of a data set from an experiment I conducted. The setup was something like this: Five participants Three tests, where each test is whether there is a distinguishable difference between two items Each participant was given each test six times; whether they got it correct was recorded as 0/1 I would like a posterior for the probability of success for each participant as well as for each test (also for each participant on each test, but this is a simple extension). Each trial is a Bernoulli variable (success/fail). I model the success probability of a trial for a given person $p$ and a given test $t$ as $p\left(t,p\right)=\operatorname{logistic}\left(\mu_{t,s}\right)$ where $\mu_{t,s}=\mu_0 + \delta_t + \delta_s$, and now I want to estimate $\mu_0$, $\delta_t$, and $\delta_s$. Each of these variables gets a zero-centred Normal prior, with standard deviation of 5. I'm doing this all in PyMC3. The problem I'm running into is that for test 2, all participants successfully identified the correct item all six times. In order to accurately model this, we would want to set $\delta_{t=2}=\infty$. In practice, I end up getting very large values for all parameters, instead of just the one. While annoying, this makes sense: the model cannot actually model a success probability of 1, and with the normal priors, at some point increasing other parameters than $\delta_{t=2}$ becomes better than further increasing $\delta_{t=2}$. My question is this: this model seems to be a poor choice of model for the data, as it can't accurately represent it with finite parameters. So what is the right way to model this? Practically, I've tried a few things to get it to work anyway, but they break in PyMC3 for reasons I don't fully understand: Setting a flat prior on $\delta_{t=2}$ Using a custom link function, $f\left(\mu_{ab,s}\right)=\min\left(1,\max\left(0,\frac{\mu_{ab,s}+1}{2}\right)\right)$ I also tried putting a scale parameter inside the logistic function, which helped somewhat, but still resulted in skewed estimates. I've also considered adding noise to the data, by duplicating the data (e.g.) a hundred times and then just flipping one result for that particular perfect-success trial only, but haven't tried this. This, along with the things I tried above, I feel are hacksâ€”the model should be able to model the perfect success without needing them. Of course, if there's no "right way" to model this, I can resort to whatever hack is best.
