[site]: crossvalidated
[post_id]: 620935
[parent_id]: 620881
[tags]: 
In theory , no. Because the mutual information between the target and the features decreases or stays the same when you take out features. The following rule in information theory describes this: $$I(Y; X_1, X_2) = I(Y; X_1) + I(Y; X_2|X_1)\longrightarrow I(Y;X_1,X_2)\geq I(Y; X_1)$$ But, in practice, yes . No model or algorithm is perfect and they may work better with less features. Part of the reason is the algorithm or the implementation itself, and the other part is the limited capability of us doing hyper-parameter tuning. For example, in the case of random forests, note that the best hyper parameters may change with respect to number of features, e.g. the tree depth. The search space is combinatorially large and usually it is difficult to exhaust. Finally, there is the effect of stochasticity in the process. Another point is that you are selecting the features that the algorithm thinks important. So, it's a feedback cycle and may not work well always. The same could have been done in a simple algorithm like logistic regression and could result in poor performance. Is it worth looking for a subset of features in the base feature set, or is it already the best set by default? The short answer is Yes, but only if you suspect that your algorithm is not working well with that set of features.
