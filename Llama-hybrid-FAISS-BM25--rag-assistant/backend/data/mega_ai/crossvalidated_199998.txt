[site]: crossvalidated
[post_id]: 199998
[parent_id]: 104531
[tags]: 
I tend not to use classification accuracy as a model selection criterion because it is discrete and a small change in lambda can produce a larger change in the error rate. I find that Allen's PRESS (i.e. the cross-validation estimate of the sum of squares error) works well for setting lambda in classification problems. It also has a certain symmetry to it, if we use least squares for fitting the ridge regression model, then using it for tuning lambda as well ought to be reasonable. As it is a classification task, a regularised logistic regression model might be a better option, with lambda chosen to minimise the cross-validated negative log-likelihood.
