[site]: crossvalidated
[post_id]: 575032
[parent_id]: 
[tags]: 
What is the error of the mean of data that have uncertainty values attached to them?

Given a set of $n$ values, the error associated with their average will be $$\text{standard deviation}/\sqrt{n}.$$ But if the values themselves have an uncertainty attached to them, such as $100\pm 1,$ $110 \pm 1, \ldots$ is the previous formula correct?
