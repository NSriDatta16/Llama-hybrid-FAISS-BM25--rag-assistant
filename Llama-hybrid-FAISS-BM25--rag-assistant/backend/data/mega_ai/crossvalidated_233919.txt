[site]: crossvalidated
[post_id]: 233919
[parent_id]: 
[tags]: 
Do I have to normalize the input vector for RNN if it only consists of 0 and 1?

Yan LeCun's paper " Efficient Backprop " indicates that the average of each input variable over training set should be close to zero. If the input variables are all categorical variables and encoded by one hot encoding. In this case the averages are certainly not zero. So do I need to normalize this kind of vectors?
