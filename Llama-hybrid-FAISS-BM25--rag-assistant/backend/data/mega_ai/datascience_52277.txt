[site]: datascience
[post_id]: 52277
[parent_id]: 18258
[tags]: 
Here is an example of why you would want to do it (and approximately how). I have 3 predictive models of housing prices: linear, gradient boosting, neural network. I want to blend them into a weighted average and find the best weights. I run linear regression, and I get a solution with weights like -3.1, 2.5, 1.5, and some intercept. So what I do instead of using sklearn is: blendlasso = LassoCV(alphas=np.logspace(-6, -3, 7), max_iter=100000, cv=5, fit_intercept=False, positive=True) And I get positive weights that sum (very close) to 1. In my example, I want the alpha that works best out-of-sample so I use LassoCV with cross-validation. The sklearn docs state that you shouldn't set alpha to 0 for numerical reasons, however, you can also use straight Lasso() and set the alpha parameter as low as you can get away with to get a reasonable answer.
