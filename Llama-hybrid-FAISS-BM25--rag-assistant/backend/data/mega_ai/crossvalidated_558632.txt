[site]: crossvalidated
[post_id]: 558632
[parent_id]: 558610
[tags]: 
Most forms of approximation in machine learning also lead to generalisation - the ability to give better-than-guesswork estimates for a target variable when presented with a previously unseen example. Outside of RL, using a training dataset with a neural network or other function approximator, achieving this generalisation is the most common goal when training. This is the reason for cross-validation and test datasets, in order to measure how well the model has learned to generalise. Deep RL, when exploring a very large state/action space, relies on this generalisation effect in order to learn effectively. It can still be hard for an approximator to generalise well in board games where a very small difference in state can lead to radically different results. Hence self-playing learning systems like AlphaZero use complex architectures and significant compute resources to gain large amounts of experience (millions of games) in a small amount of time. This still falls far short of brute-forcing all possible states (by many orders of magnitude), so does still heavily rely on generalisation.
