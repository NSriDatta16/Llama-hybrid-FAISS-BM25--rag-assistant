[site]: crossvalidated
[post_id]: 544559
[parent_id]: 544548
[tags]: 
One method for regression is MDN, mixture density network. The idea is to model the output of the network as mixture of gaussians. i.e. Instead of outputting a single number each time, the network output is several numbers describe the gaussian distribution for example: output $\mu$ , $\sigma$ of the normal distribution. Then your goal is to maximize the average log likelihood (i.e. your loss is the negative log likelihood). In this case for each prediction you will get different $\sigma$ that will describe the confidence in the prediction. You can read more about it here: https://towardsdatascience.com/a-hitchhikers-guide-to-mixture-density-networks-76b435826cca Another method which is good both for regression and for classification is bayesian neural network. The basic idea here, is to model the weights as normal distribution, instead of simple numbers.These weights will describe the posterior distribution. Then in order to get the confidence you sample from the posterior weights and calculate the standard deviation of the results.
