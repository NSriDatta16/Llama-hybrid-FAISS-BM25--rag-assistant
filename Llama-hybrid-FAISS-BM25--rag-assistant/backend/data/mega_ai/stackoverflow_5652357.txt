[site]: stackoverflow
[post_id]: 5652357
[parent_id]: 
[tags]: 
References for data normalization

What are the best practices on normalizing data (not sure if that is the right term) for NNs and other machine learning algorithms? What I mean is how you represent data to the NN/algo. For instance, how do you represent a store code? Store 555 isn't greater or less than 554, it is just a classification. Do NNs/algo models just filter that out on their own or do you need to prod them into making a classification rather mathematical distinction? Thanks for any help in directing me to appropriate information. I am obviously new to this. EDIT : Thanks to everyone for the answers. I have been digging through quite a few data mining books and while I have found a few that spend a chapter or two on the topic of data pre-processing I am a little surprised at how most gloss over it entirely. Thanks again.
