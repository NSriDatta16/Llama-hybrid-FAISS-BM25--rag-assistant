[site]: crossvalidated
[post_id]: 496280
[parent_id]: 493393
[tags]: 
After examining the problem more I convinced myself that the official way to do it is the right way. My objection was originally that doing regression against {0, 1} could result in jagged results. But actually, that's the basis for logistics regression! Isotonic regression is not fundamentally different in that sense. Here's a bad drawing to explain why this is okay In the same way, neither logistic regression, nor isotonic regression will have any problem with regressing to a set containing just 0s and 1s. As for why my first graph looks "jagged" As a commenter made me realise, it's just an artifact of uniform binning combined with the fact that the dataset is imbalanced towards 0.95. Some bins just happened to have a 1 point in them and that point was predicted wrong even after calibration. So really, me trying to use bucketed rates instead of the actual target values is just a way of interfering with the intended function of isotonic regression. In fact, it turns out that the roc_auc score is still better for the "official" recalibration method vs my proposed one.
