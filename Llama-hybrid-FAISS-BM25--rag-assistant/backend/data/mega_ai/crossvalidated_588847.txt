[site]: crossvalidated
[post_id]: 588847
[parent_id]: 
[tags]: 
Einstein notation $-$ or another $-$ to denote constraints in high dimensional ILP problems

When discussing marginal sums of arrays in 3 dimensions or more, is it customary in the statistical and/or data science communities to use the Einstein summation convention? Is some other form preferred? The context is an integer linear programming (ILP) optimization problem where the decision variables are $X\in\mathbb{R}^{I \times J \times K}$ and $z \in \mathbb{R}^I$ , and the constraints involve marginal sums on $X$ . Should I (may I?) use $$ \begin{matrix} \min ~~~ &C^{ijk}X_{ijk} + \tau^i z_i & \\ \text{s.t.} &1^{ijk} X_{ijk} &= 10 \\ & 1^kX_{ijk} 1_j &\preccurlyeq 10z \\ & 1^{ik}X_{ijk} &\succcurlyeq \bf{1}_J \end{matrix} $$ Is there some other "standard" way to say this? I'm trying to avoid $\sum_{ijk}X_{ijk}=10$ as I am writing a spec for software that eschews loops and summations in factor of matrix and inner products. I am just looking for a generally-accepted notation for inner product-like constructs/marginalizations for higher dimensional arrays. Follow-up: It is perhaps obvious that any 3-dimensional-or-higher array (3rd order tensor or higher) can be serialized into a regular 2D array (by concatenating the 2nd and all subsequent layers/levels of the array on to the side or bottom of the top layer/level), so for all practical purposes, e.g., writing technical specifications, the 2D matrix notation is sufficient.
