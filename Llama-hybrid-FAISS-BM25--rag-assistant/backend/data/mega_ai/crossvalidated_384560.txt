[site]: crossvalidated
[post_id]: 384560
[parent_id]: 81986
[tags]: 
The standard deviation represents dispersion due to random processes. Specifically, many physical measurements which are expected to be due to the sum of many independent processes have normal (bell curve) distributions. The normal probability distribution is given by: $ \Large Y = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{\left(x-\mu\right)^2}{2\sigma^2}} $ Where $Y$ is the probability of getting a value $x$ given a mean $\mu$ and $\sigma$ â€¦the standard deviation! In other words, the standard deviation is a term that arises out of independent random variables being summed together. So, I disagree with some of the answers given here - standard deviation isn't just an alternative to mean deviation which "happens to be more convenient for later calculations". Standard deviation is the right way to model dispersion for normally distributed phenomena. If you look at the equation, you can see the standard deviation more heavily weights larger deviations from the mean. Intuitively, you can think of the mean deviation as measuring the actual average deviation from the mean, whereas the standard deviation accounts for a bell shaped aka "normal" distribution around the mean. So if your data is normally distributed, the standard deviation tells you that if you sample more values, ~68% of them will be found within one standard deviation around the mean. On the other hand, if you have a single random variable, the distribution might look like a rectangle, with an equal probability of values appearing anywhere within a range. In this case, the mean deviation might be more appropriate. TL;DR if you have data that are due to many underlying random processes or which you simply know to be distributed normally, use standard deviation function.
