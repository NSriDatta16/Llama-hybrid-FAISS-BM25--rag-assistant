[site]: crossvalidated
[post_id]: 597980
[parent_id]: 
[tags]: 
How to sample data such that sample attribute means optimally match arbitrary target attribute means?

I have a very large dataset D (>100 million samples) with attribute/feature set F ( S such that the mean error between the feature averages of S ( Fs ) and some given array of target feature values ( Ft ) is minimized. We do not have any other information about the target data (its distribution, variances etc.), so we are free to make any assumptions. Also, while we would like S to be as large as possible, small sizes are also acceptable (lowest at about 10000 samples). I have tried the following approaches so far: Fit target values belong to specific distribution (Normal, Poisson etc.). Get the corresponding PDF values for each point in D . Get probabilities by multiplying the values for each feature for each point. Do weighted sampling on the probability set. Get distance (cosine/Manhattan) between the target vector and each point in D . Transform output to interpret as probabilities. Carry out weighted sampling. I have also been looking into MCMC sampling but not sure how to go about fitting it to this specific problem. What could be some potential approaches that could work well?
