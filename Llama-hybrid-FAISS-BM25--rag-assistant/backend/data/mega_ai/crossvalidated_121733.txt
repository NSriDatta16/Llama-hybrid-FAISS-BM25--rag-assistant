[site]: crossvalidated
[post_id]: 121733
[parent_id]: 
[tags]: 
why pretraining for convolutional neural networks

Usually Back propagation NN has the problem of vanishing gradients. I found that Convolutional NN (CNN) some how get rid of this vanishing gradient problems (why?). Also in some papers some pretraining approaches have been discussed for CNN. Could somebody explain to me the following? the resons for pretraining in CNN and what are the problems/limitations with CNN? any relavent papers talking about the limitation of CNN?
