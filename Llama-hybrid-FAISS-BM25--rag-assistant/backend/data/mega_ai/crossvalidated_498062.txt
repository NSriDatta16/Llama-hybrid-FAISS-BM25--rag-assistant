[site]: crossvalidated
[post_id]: 498062
[parent_id]: 
[tags]: 
Variable Selection : Removing Linear Dependency by SVD using the Condition number and then eliminating the variable causing multicollinearity

I am trying to perform regression with over 5000 feature variables(X) and I would like to eliminate multicollinearity. Incremental VIF computation is expensive. Incremental PCA works but I might lose out on an independent variable that has good correlation with my Y variable. I would like to get back a truncated version of my feature variable matrix. Is there a way to do this in python ?
