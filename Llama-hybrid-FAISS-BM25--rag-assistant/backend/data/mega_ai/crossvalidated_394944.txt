[site]: crossvalidated
[post_id]: 394944
[parent_id]: 379744
[tags]: 
LIME creates a surrogate model locally around the unit whose prediction you wish to understand. Thus it is inherently local. Shapley values 'decompose' the final prediction into the contribution of each attribute - this is what some mean by 'consistent' (the values add up to the actual prediction of the true model, and this is not something you get with LIME). But to actually get the shapley values, some decision must be made about what to do/how to handle the values of the attributes 'left out', which is how the values are arrived at. In this decision, there is some choice which could change the interpretation. If I 'leave out' an attribute, do I average all the possibilities? Do choose some 'baseline'? in a nutshell: Shapley values actually tell you, in an additive way, how you got your score, but there is some choice about the 'starting point' (i.e. the decision about omitted attributes). LIME simply tells you, in a local sense, what is the most important attribute around the data point of interest.
