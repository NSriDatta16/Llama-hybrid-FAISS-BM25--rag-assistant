implistic and easily overlooked assumptions, such as the categorization of individuals into pre-defined social groups. Other delicate aspects are, e.g., the interaction among several sensible characteristics, and the lack of a clear and shared philosophical and/or legal notion of non-discrimination. Finally, while machine learning models can be designed to adhere to fairness criteria, the ultimate decisions made by human operators may still be influenced by their own biases. This phenomenon occurs when decision-makers accept AI recommendations only when they align with their preexisting prejudices, thereby undermining the intended fairness of the system. Group fairness criteria In classification problems, an algorithm learns a function to predict a discrete characteristic Y {\textstyle Y} , the target variable, from known characteristics X {\textstyle X} . We model A {\textstyle A} as a discrete random variable which encodes some characteristics contained or implicitly encoded in X {\textstyle X} that we consider as sensitive characteristics (gender, ethnicity, sexual orientation, etc.). We finally denote by R {\textstyle R} the prediction of the classifier. Now let us define three main criteria to evaluate if a given classifier is fair, that is if its predictions are not influenced by some of these sensitive variables. Independence We say the random variables ( R , A ) {\textstyle (R,A)} satisfy independence if the sensitive characteristics A {\textstyle A} are statistically independent of the prediction R {\textstyle R} , and we write R ⊥ A . {\displaystyle R\bot A.} We can also express this notion with the following formula: P ( R = r | A = a ) = P ( R = r | A = b ) ∀ r ∈ R ∀ a , b ∈ A {\displaystyle P(R=r\ |\ A=a)=P(R=r\ |\ A=b)\quad \forall r\in R\quad \forall a,b\in A} This means that the classification rate for each target classes is equal for people belonging to different groups with respect to sensitive characteristics A {\displaystyle A} . Yet another equivalent expression for independence can be given using the concept of mutual information between random variables, defined as I ( X , Y ) = H ( X ) + H ( Y ) − H ( X , Y ) {\displaystyle I(X,Y)=H(X)+H(Y)-H(X,Y)} In this formula, H ( X ) {\textstyle H(X)} is the entropy of the random variable X {\displaystyle X} . Then ( R , A ) {\textstyle (R,A)} satisfy independence if I ( R , A ) = 0 {\textstyle I(R,A)=0} . A possible relaxation of the independence definition include introducing a positive slack ϵ > 0 {\textstyle \epsilon >0} and is given by the formula: P ( R = r | A = a ) ≥ P ( R = r | A = b ) − ϵ ∀ r ∈ R ∀ a , b ∈ A {\displaystyle P(R=r\ |\ A=a)\geq P(R=r\ |\ A=b)-\epsilon \quad \forall r\in R\quad \forall a,b\in A} Finally, another possible relaxation is to require I ( R , A ) ≤ ϵ {\textstyle I(R,A)\leq \epsilon } . Separation We say the random variables ( R , A , Y ) {\textstyle (R,A,Y)} satisfy separation if the sensitive characteristics A {\textstyle A} are statistically independent of the prediction R {\textstyle R} given the target value Y {\textstyle Y} , and we write R ⊥ A | Y . {\displaystyle R\bot A\ |\ Y.} We can also express this notion with the following formula: P ( R = r | Y = q , A = a ) = P ( R = r | Y = q , A = b ) ∀ r ∈ R q ∈ Y ∀ a , b ∈ A {\displaystyle P(R=r\ |\ Y=q,A=a)=P(R=r\ |\ Y=q,A=b)\quad \forall r\in R\quad q\in Y\quad \forall a,b\in A} This means that all the dependence of the decision R {\displaystyle R} on the sensitive attribute A {\displaystyle A} must be justified by the actual dependence of the true target variable Y {\displaystyle Y} . Another equivalent expression, in the case of a binary target rate, is that the true positive rate and the false positive rate are equal (and therefore the false negative rate and the true negative rate are equal) for every value of the sensitive characteristics: P ( R = 1 | Y = 1 , A = a ) = P ( R = 1 | Y = 1 , A = b ) ∀ a , b ∈ A {\displaystyle P(R=1\ |\ Y=1,A=a)=P(R=1\ |\ Y=1,A=b)\quad \foral