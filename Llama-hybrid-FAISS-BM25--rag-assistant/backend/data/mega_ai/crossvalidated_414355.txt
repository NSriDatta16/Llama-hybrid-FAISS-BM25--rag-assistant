[site]: crossvalidated
[post_id]: 414355
[parent_id]: 412402
[tags]: 
As Brale mentions, it's actually a function from states to a distribution over the set of actions. Because the domain and range of this function are usually discrete, The state is very often continuous in many control problems where you have continuous joint angles and pose, etc. The action space is also often continuous in those cases, since you can often choose to apply any amount of torque within some limits. therefore this function do not have the usual properties when it comes to functions, such as continuity, differentiability, Lipischitzness, smoothness, etc. Therefore there is nothing general that we can say about this function, am I correct? Often, for continuous spaces, $\pi(s) = \mathcal{N}(f(s;\theta), \sigma^2)$ where $f(s;\theta)$ is a learned function approximator. You can actually say that $f$ is continuous, and subdifferentiable, if it is implemented as a neural network $f$ is Lipschitz if there is a bound on the absolute value of the weights in $\theta$ , alternatively you can enforce this with a weight regularization penalty a la WGAN-GP. The expert here usually being a human, so this expert policy is literally a function that models how the human brain works or react to a highly complicated environment. I am pretty sure there is no closed form description of such an object. There is virtually nothing we can ever say about this function either. That's true, but usually there is no need to make any such assumptions. Is there any way or any existing literature that attempts to make the concept of a policy less abstract? What is the simplest policy that you can have for a non-trivial scenario? A simple but powerful class of policies might be parameterized as $\pi(s) = \mathcal{N}(\theta^T \phi(s), \sigma^2)$ where $\phi$ is a set of basis functions.
