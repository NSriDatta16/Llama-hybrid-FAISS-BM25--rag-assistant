[site]: datascience
[post_id]: 38444
[parent_id]: 
[tags]: 
What parameters should be searched with grid search

In neural networks exist the parameters lr, error, iterations. I used this Library in my code: trainer.train(trainingSet, { rate: getParametersAnn(tipo,parametros).lr,//0.003 iterations: 20000, error:getParametersAnn(tipo,parametros).error,//0.005 shuffle: true, log: 10, cost: synaptic.Trainer.cost.CROSS_ENTROPY, it is recommended that lr be too small to settle in the solution what parameters should be searched with grid search? or should I use the default parameters of the library? with this parameters rate: 0.001, iterations: 2000, error: 0.1, shuffle: true, log: 1, cost: synaptic.Trainer.cost.CROSS_ENTROPY the result is: iterations 1 error 0.5826960676804478 rate 0.001 iterations 2 error 0.24274412100103793 rate 0.001 iterations 3 error -0.1024786307448624 rate 0.001 iterations 1 error 0.5714651392530429 rate 0.001 iterations 2 error 0.30301059323863505 rate 0.001 iterations 3 error 0.062228013069539526 rate 0.001 . . .etc. and with rate: 0.1, iterations: 20, error: 0.1, shuffle: true, log: 1, cost: synaptic.Trainer.cost.CROSS_ENTROPY iterations 1 error -7.352525710025565 rate 0.1 iterations 1 error -11.137117275284693 rate 0.1 iterations 1 error -8.64864011321306 rate 0.1 iterations 1 error -11.165450848337727 rate 0.1 iterations 1 error -11.087407126740619 rate 0.1 iterations 1 error -11.157093359867917 rate 0.1 iterations 1 error -11.139330057051765 rate 0.1 iterations 1 error -11.111847588899709 rate 0.1 see the iterations of the second example, it does not advance because, how should the iterations be?
