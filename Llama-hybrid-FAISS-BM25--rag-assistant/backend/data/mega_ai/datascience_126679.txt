[site]: datascience
[post_id]: 126679
[parent_id]: 
[tags]: 
Multinomial Logistic Regression sensitive to choice of Encoding

I am using the following LogisticRegression model using sklearn. The task requires to select one label from multi-labels, so if I provide a, b the output could be d etc: from sklearn.linear_model import LogisticRegression multi_class_prediction_model = LogisticRegression(solver='newton-cg', multi_class='multinomial') x_train=[['a','b'],[...]] y_train=[['d'],[...]] x_train.applymap(encodings) y_train.applymap(encodings) encodings={'a':1,'b':2,'c':3,'d':4...} multi_class_prediction_model.fit(x_train, y_train) I encoded the labels manually to numeric integers as above. However, the prediction seems to be sensitive to numeric values of encodings! So if I change it following: encodings={'a':100,'b':200,'c':300,'d':400...} Then the prediction changes drastically. Is this methodology correct?
