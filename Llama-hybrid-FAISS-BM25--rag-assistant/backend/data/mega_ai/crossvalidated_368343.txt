[site]: crossvalidated
[post_id]: 368343
[parent_id]: 367248
[tags]: 
There is no inconsistency. The first ( left-most ) numbers reflect the predictions of the classifier used (here this classifier is a random forest (*)). The second ( central ) numbers reflect the average influence of that particular feature value in the final predictions. These two sets of numbers should indeed convey similar information but they do not need to be exactly the same. In particular, the first numbers come from our (potentially highly sophisticated) full model that encapsulates the associations across all the features in our training sample. The second numbers encapsulate the behaviour of the linear model used by LIME in the neighbourhood of the sample-point we trying to explain. (Notice that LIME usually does not employ all the available features when making an explanation, we usually set the num_features to be smaller than the total number of available features.) For the example shown, the predicted probability of that particular mushroom being poisonous is $1$ . The second numbers suggest that, given the training data available, having odor=foul would increase on average the predicted probability of that mushroom being poisonous by $0.26$ and similarly, having gill-size=broad would decrease on average the predicted probability by $0.13$ . That does not necessitate that the overall predicted probability from the full classifier is the sum of these average changes - thus there is no inconsistency. :) (*)While the blog-post link provided does not show the source of that image, the full notebook where this picture is taken from, can be found here . This how I know that the underlying full model is an RF.
