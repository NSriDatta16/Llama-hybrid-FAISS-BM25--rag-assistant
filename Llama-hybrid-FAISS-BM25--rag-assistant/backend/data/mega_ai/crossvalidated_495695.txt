[site]: crossvalidated
[post_id]: 495695
[parent_id]: 
[tags]: 
How is possible to obtain similar RMSEs but very different Bias between two predictor models?

I'm comparing the results of two predictors models, CNN convolutional neural network and WRF weather numerical model, against a ground truth (Merra). WRF-Merra is the weather numerical model vs Merra reanalysis. CNN-Merra is the convolutional neural network vs Merra reanalysis. I'm running the model for different times after the initialization and for each of them I have reasonable RMSE and Correlation coefficient results but very different Bias. Here an example for the 18 hrs after the initialization: rmse cnn-merra: 41.59755336876574 rmse wrf-merra: 44.698412696954215 bias cnn-merra: -17.23248780747778 bias wrf-merra: 7.743057069935867 corr_wrf_merra: 0.9643024072814607 corr_cnn_merra: 0.972817697637590 Here for 24hrs after the initialization: rmse_cnn-merra: 60.866766881390106 rmse_wrf-merra: 47.321850472005345 bias_cnn-merra: -34.66534693047336 bias_wrf-merra: 6.556152471130599 corr_wrf_merra: 0.9604825847469841 corr_cnn_merra: 0.9688442121379363 Here how I computed the quantities with python (same for wrf_merra quantities): RMSE rmse_cnn_merra =sqrt(mean_squared_error(merra,cnn)) Bias bias_cnn_merra =np.average(cnn - actual) Corr coeff. corr_cnn_merra=np.corrcoef(cnn, merra)[1,0] I would like to show you an example of the plots of cnn,wrf and merra for all the timesteps about the 24hrs after the initialization. How is possible to have cnn-merra bias so negative? Where should I look first to explore this problem? I'm supposing that there is something wrong in the model but how can the RMSE seem reasonable? This is my first approach with comparing results with different metrics so it's highly possible that my questions derive from a lack of theory. Thanks
