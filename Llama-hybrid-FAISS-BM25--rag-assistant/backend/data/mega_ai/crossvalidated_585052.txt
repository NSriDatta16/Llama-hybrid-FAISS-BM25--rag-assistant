[site]: crossvalidated
[post_id]: 585052
[parent_id]: 
[tags]: 
CycleGAN cycle loss

I was reading the paper of CycleGAN and I was trying to implement it. However, my models does not converge to any good solution whatsoever, and since I've checked the implementation many times, I think that the problem is on how I understood the algorithm. Specifically, I have some doubts on how the "cycle" is trained. At the moment, the gradient wrt one generator (let's say real to segmented), is composed $$L_{disc}^{segm} + L_{rec}^{real \; to \; segm} + + L_{rec}^{segm \; to \; real}$$ However, I'm not too sure about the middle part. In particular, we use the second generator to ensure that the generation is not too far from the initial one, however the gradient wrt the loss, of the other direction, should not influence this right? Example: $G_1$ = real to segmented $G_2$ = segmented to real If we want to compute the loss wrt $G_1$ , we should care only of the reconstruction of it's input to the real domain, right? However, as explained in the paper (formula with the 3 loss), seems that also the second generator that is used to go back to the original domain is optimized to that that reconstruction is better. However, this lead to the fact that a generator has to become better at both: generating images from one domain to the other reconstruct the other generator output to the initial image I think this might be the problem that is causing my GAN not to converge, do you agree?
