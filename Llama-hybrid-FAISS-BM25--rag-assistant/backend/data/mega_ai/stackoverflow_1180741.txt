[site]: stackoverflow
[post_id]: 1180741
[parent_id]: 1173356
[tags]: 
Hey Shinyfish, I understand the impulse to want a formula...and I'll promise you that any general formula will be provably wrong outside of a narrow context. Consider someone who tells you that every requirement should have N tests associated with it. Now consider a few sample requirements, e.g. The username field requires a minimum of 6 alphanumeric characters, vs. The dosage calculator will correctly calculate the patient's dose of Danger-o-medicine, based on their age, gender, body weight. Both are possible requirements. The first is relatively straightforward and fairly low stakes. The second has many potential points of failure, and if it succeeds in many cases but fails in a few seemingly random ones, it'll kill someone. Anyone who tells you to count your requirements and then multiply by something is deluded or selling snake oil. Similarly, saying that UAT will take 1/Nth the coding time /may/ be a useful heuristic within some business context, but the value for N will vary wildly between, say, a startup making blogging software and developing the next version of Photoshop. For that matter, what /you/ mean by UAT (and what your unit and system testing does(n't) cover) likely varies dramatically from what the folks advising you mean by the same terms. Here's rule of thumb that I might use to estimate how much time testing'll take: First, to the extent that it's possible, consider similar projects within your organization. How many person/days of testing did they get? Were stakeholders happy with how thoroughly the product was tested? How do you expect this new project to be similar/different from previous ones? How experienced/skilled are the testers you'll be getting, compared to previous projects? How well will they understand this project at the outset, compared to previous projects? Of course, sometimes you don't have relevant previous projects to compare to. If you don't...know that your estimate will have a much larger margin of error. I can't speak for you, but 98.% of the developers (testers, coders, etc.) that I've worked with chronically underestimate. If that's true for you, try to compensate accordingly. Perhaps most importantly, try to understand how accurate your estimate is (or isn't) and then set stakeholders' expectations accordingly. Providing an illusion of certainty rarely helps anyone. Best of luck!
