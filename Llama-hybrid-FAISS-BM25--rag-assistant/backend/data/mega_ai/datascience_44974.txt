[site]: datascience
[post_id]: 44974
[parent_id]: 44971
[tags]: 
As the number of epochs increase the error goes down and the neural network has less to learn from the given data. The learning rate also decreases towards the end which makes the calculations of the gradients and weight updates numerically unstable. These are some of the reasons that contribute to slow learning. You can have a look here Quora for more details where Ian Goodfellow has answered a similar question.
