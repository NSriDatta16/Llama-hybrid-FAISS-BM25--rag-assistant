[site]: datascience
[post_id]: 123814
[parent_id]: 
[tags]: 
Generating synthetic labeled data (sampling from p(x,y))

I'm working on a toy problem. Consider a dataset that consists of 1-D vectors (waveforms) that contain noise, except for one prominent spike. Denote the waveform by $\vec{x}$ , and let the coordinate of the spike be the scalar $y$ . So for each waveform $\vec{x}$ , the corresponding label is the location of the spike $y$ . Suppose I want to sample from this distribution $p_{\vec{X},Y}(\vec{x},y)$ in order to create new data -- in my case, to accomplish the sampling I'm experimenting with using variational auto encoders and also de-noising diffusion probabilistic architectures (Markov hierarchical VAEs, similar to stable diffusion). The problem I'm running into is how to encode the scalar label $y$ along side the waveform $\vec{x}$ . My initial attempts have been to simply copy $y$ a number of times into a 1-D vector $\vec{y}$ which has similar length to $\vec{x}$ , and then concatenate $\vec{x}$ and $\vec{y}$ into a new vector $\vec{xy}$ , and then have my models try to create synthetic samples $\vec{xy}'$ resembling $\vec{xy}$ . Then to recover $\vec{x}$ and $y$ , I can split $\vec{xy}'$ to get $\vec{x}'$ and $\vec{y}'$ and set $y' = mean(\vec{y}')$ . However, this approach has not proved reliable. I've spent some time trying to find literature addressing this problem, but to no avail. Does anyone have any suggestions on how I could implement a better approach, or at least point me in a good direction? For context, here is an example of an $\vec{x}$ , where $y=180$ . Once I scale $y$ to be in $[0,1]$ , and then concatenate $\vec{x}$ and $\vec{y}$ , I get a vector that looks like this:
