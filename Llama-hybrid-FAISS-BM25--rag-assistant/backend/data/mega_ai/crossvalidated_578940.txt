[site]: crossvalidated
[post_id]: 578940
[parent_id]: 
[tags]: 
Can I adjust the Wasserstein GAN loss function for my particular data?

I am working on building Generative Adversarial Networks for the purpose of generating synthetic flight data. The GAN will be trained on actual time-series flight data in the form of a (n,m,9) array where n is the number of flights, m is the number of time samples, and each column is a state variable: [ $V$ , $\alpha$ , $\beta$ , $p$ , $q$ , $r$ , $\phi$ , $\theta$ , $\psi$ ]. So far I have been exploring WGANs using gradient penalty. I have already implemented these architectures in TensorFlow. But I am interested in adding another penalty to the loss function. Since there are also mathematical relationships between some of these variables, I was wanting to check the mathematical consistency of the generated variables, and any discrepancy could be used to increase the loss. My thought is that it would increase the quality of the generator output. There is a paper with the title " Data Augmentation for Intelligent Contingency Management Using Generative Adversarial Neural Networks " published by NASA that implements this, but on GANs, not on WGANs. Since the WGAN's loss function is key to how it generally has better convergence than vanilla GANs, would altering the WGAN loss function affect the convergence properties? Thanks
