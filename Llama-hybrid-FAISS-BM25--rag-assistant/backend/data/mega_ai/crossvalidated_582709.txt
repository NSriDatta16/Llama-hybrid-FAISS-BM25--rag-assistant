[site]: crossvalidated
[post_id]: 582709
[parent_id]: 582231
[tags]: 
The double descent phenomenon is seen in the test loss, not the training loss. Double descent, as described by Belkin et al. in "Reconciling modern machine learning and the bias-variance trade-off" is observed as model complexity (essentially the number of model parameters) increases. When the model has fewer parameters than training samples, it follows the familiar bias/variance trade-off curve as the model size is increased. The test error reaches a peak when it reaches what Nakkiran et al.'s "Deep double descent: where bigger models and more data hurt" describes as the interpolation point, which is when the training error drops to ~0. This is about when the number of parameters equals the number of samples, but things like dropout and regularisation can reduce the effective number of parameters. After the interpolation point, counterintuitively, increasing the model size reduces the test loss. So to detect this form of double descent, you need to run a series of tests increasing the model complexity and track the test and training loss from each model. However, Nakkiran et al. also found that when the model size is around the interpolation point, the change in test loss when increasing the number of training epochs also shows evidence of double descent. But this doesn't apply to all models. If the model isn't large enough to reach the interpolation point, double descent won't be seen in the test loss, no matter how long the model is trained. This form of double descent can be detected by tracking the test and training loss every few epochs. If at some point the training loss is close to zero and the test loss is decreasing you know you've passed the interpolation point and are in the second descent.
