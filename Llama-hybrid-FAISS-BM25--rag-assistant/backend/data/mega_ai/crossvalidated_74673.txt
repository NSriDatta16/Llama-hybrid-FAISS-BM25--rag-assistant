[site]: crossvalidated
[post_id]: 74673
[parent_id]: 73966
[tags]: 
You can do this with the lm and associated functions, but you need to be a little careful about how you construct your weights. Here's an example / walkthrough. Note that the weights are normalized so that the average weight = 1. I'll follow with what happens if they aren't normalized. I've deleted a lot of the less relevant printout associated with various functions. x summary(unwtd_lm |t|) (Intercept) 0.04238 0.031 --- x 1.03071 0.03268 31.539 summary(wtd_lm |t|) (Intercept) 0.03436 0.03227 1.065 0.287 x 1.03869 0.03295 31.524 You can see that with this much data we don't have much difference between the two estimates, but there is some. Now for your question. It's not clear whether you want the distance in standard errors where the standard errors are for fitted values or for prediction, so I'll show both. Let us say we are doing this for the value $x = 1$ and the target value (green dot) $y = 1.1$): > y_eval wtd_pred # Distance relative to predictive std. error > (y_eval-wtd_pred$fit[1]) / sqrt(wtd_pred$se.fit^2 + wtd_pred$residual.scale^2) [1] 0.02639818 > > # Distance relative to fitted std. error > (y_eval-wtd_pred$fit[1]) / wtd_pred$se.fit [1] 0.5945089 where I've deleted the warning message associated with predictive confidence intervals and weighted model fits. Now I'll show you how to do the residual variance calculation. First, if your weights aren't normalized, you will have problems: > wts summary(wtd_lm |t|) (Intercept) 0.03436 0.03227 1.065 0.287 x 1.03869 0.03295 31.524 predict(wtd_lm, newdata=data.frame(x=1), interval="prediction") fit lwr upr 1 1.073049 -0.2461643 2.392262 Note how that residual standard error has gone way down and the prediction confidence interval has really changed, but the coefficient estimates themselves have not. This is because the calculation for the residual s.e. divides by the residual degrees of freedom (998 in this case) without regard for the scale of the weights. Here's the calculation, mostly lifted from the interior of summary.lm : w which you can see matches the residual s.e. in the previous printout. Here's how you ought to do this calculation if you find yourself in a position where you need to do it by hand, so to speak: > rss_w sqrt(rss_w / wtd_lm$df) [1] 1.019937 However, normalizing the weights up front takes care of the need to divide by mean(w) and the various lm -related calculations come out correctly without any further manual intervention.
