[site]: crossvalidated
[post_id]: 305327
[parent_id]: 
[tags]: 
Derivation of local linear embedding

Might be a trivial question, but how do I solve for the following constrained optimization problem that appeared in local linear embedding? $$\min_{w_1,\cdots,w_k} \|x-\sum_{i=1}^k w_i x_i\|^2 \text{ s.t. } \sum_{i=1}^k w_i = 1$$ , where $x$ and $x_i$'s are given $p\times 1$ vectors. I tried the following: \begin{align} \|x - \sum w_i x_i\|^2 &= \|\sum w_i (x - x_i)\|^2\\ &=\left(\sum w_i (x - x_i)^T \right)\left( \sum w_i (x-x_i)\right)\\ &= \sum_{i,j} w_i w_j (x - x_i)^T (x - x_j) \\ &= w^T A w \end{align} , where $i$-th entry of column vector $w$ is just $w_i$, and $A_{ij} = (x - x_i)^T ( x - x_j)$. Take derivative with respect to $w$, I got $$2Aw = 0$$ , which tells me that $w \in \text{ker}(A)$. But how do I get a more explicit expression? I have read this notes but the derivation on page 10 does not make sense to me. For example, the writer says "we define the local covariance matrix" but then wrote $C_{jk} = (x - \eta_j)\cdot (x - \eta_k)$. First I don't think the dimension matches. Second, so is $C_{jk}$ is matrix or an entry in the matrix?
