[site]: datascience
[post_id]: 52464
[parent_id]: 
[tags]: 
Random Forest application with 40+ Predictor Variables

I am using R package randomForest to build a Random Forest model for classification. Ultimately, I need to choose one of five programs for a group of individuals based on historical data. The final variable that is being predicted is a categorical "1, 2, 3, 4, or 5" variable. I need to incorporate 30-40 variables--their importance will also be analyzed-- to reach a decision for each individual. I have no problem training a model, initially. Below is a sample data set being trained with R's randomForest package. I am running up-to-date versions of both the package and RStudio. set.seed(101) train My question is : Once I have a model trained, tested, and cross-validated, how do I actually apply new data to this model? Is it viable to use that many variables-- all categorical, some binary --for this?
