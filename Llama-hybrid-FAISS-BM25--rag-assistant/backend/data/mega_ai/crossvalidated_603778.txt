[site]: crossvalidated
[post_id]: 603778
[parent_id]: 603765
[tags]: 
NOTE: the following solution is written based on the first version of the question where there was only two populations and two kinds of tests. But the approach holds for any other number of populations and tests. Suppose $y$ is your response variable of whether the diagnosis is correct or not (so a binary variable). Then you can use a logistic regression model as: $$y_{i} \sim Bernoulli(p_{k[i],j[i]})$$ where $p_{k,j}$ is the probability of correct diagnosis in population $k$ (k=1,2) and for test $j$ (j = A, B). So in total you will have four different probabilities of correct diagnosis for each combination of $Population \times Test$ . Then you can compare these probabilities. I'll show how this simple model can be fit in R both in a frequentist way using the glm() function and also in a Bayesian way using the R2jags package. First, the glm approach: library(boot) # Package contains the logit transform # ------ Simulating some data # synthetic successful diagnosis rates for each combination pop1_testA = 0.8 pop2_testA = 0.75 pop1_testB = 0.3 pop2_testB = 0.25 set.seed(123) df = data.frame(population = c(rep("1",500) ,rep("2",500)), test = as.factor(c(rep('A',250),rep('B',250),rep('A',250),rep('B',250))), correct_diagnosis = c(rbernoulli(250, p = pop1_testA), rbernoulli(250, p = pop1_testB), rbernoulli(250, p = pop2_testA), rbernoulli(250, p = pop2_testB))) glm.fit = glm(correct_diagnosis ~ population*test -population -test - 1, data = df, family = binomial(link = 'logit')) summary(glm.fit) inv.logit(coef(glm.fit)) # To see the values in the original scale And here are the results: > summary(glm.fit) Coefficients: Estimate Std. Error z value Pr(>|z|) population1:testA 1.6883 0.1743 9.686 inv.logit(coef(glm.fit)) population1:testA population2:testA population1:testB population2:testB 0.844 0.772 0.296 0.224 Now let's fit the model in a Bayesian way using R2jags. library(R2jags) model_code $correct_diagnosis), pop = as.numeric(df$ population), test = as.numeric(df$test)) # Choose the parameters to watch model_parameters Results of the Bayesian model: > print(model_run) mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff p[1,1] 0.791 0.026 0.739 0.773 0.792 0.808 0.840 1.001 2800 p[2,1] 0.727 0.026 0.675 0.709 0.727 0.745 0.778 1.001 2700 p[1,2] 0.317 0.029 0.261 0.297 0.317 0.336 0.375 1.002 1500 p[2,2] 0.270 0.029 0.214 0.249 0.269 0.290 0.328 1.001 3000 An important perk of the Bayesian approach that you don't get using the frequentist approach is that now you can calculate probabilities of each of the rates being greater than the other one (and other probabilities like being greater than zero and etc). For example, let's calculate the probability of the test A being more effective in population A than in population B: $$\pi_{1,1} = P(correct \ diagnosis | pop = 1, test = A)$$ $$\pi_{2,1} = P(correct \ diagnosis | pop = 2, test = A)$$ $$P(\pi_{1,1} > \pi_{2,1}) = ?$$ This is how you can simply calculate the probability in question using the posterior samples of the Bayesian model: probs = model_run $BUGSoutput$ sims.list$p mean(probs[,1,1] > probs[,2,1]) [1] 0.9573333 And the answer is roughly 96%.
