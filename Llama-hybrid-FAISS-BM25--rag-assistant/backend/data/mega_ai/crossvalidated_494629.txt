[site]: crossvalidated
[post_id]: 494629
[parent_id]: 
[tags]: 
policy gradient sampling stationary state distribution

Currently learning about the policy gradient theorem for reinforcement learning . The final derivation for the policy gradient simplifies to $$E_{\pi}[Q^{\pi}(s,a)\nabla_{\theta}ln\,\pi_{\theta}(a|s)]$$ where $E_{\pi}$ is equivalent to $E_{s \sim d^{\pi},a \sim \pi_{\theta}}$ . Sampling $a \sim \pi$ is straightforward. My question is how do we sample from the stationary state distribution $s \sim d^{\pi}$ for the current policy $\pi_{\theta}$ ?
