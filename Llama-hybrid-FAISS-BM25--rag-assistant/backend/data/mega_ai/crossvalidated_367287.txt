[site]: crossvalidated
[post_id]: 367287
[parent_id]: 
[tags]: 
Comparing two models of recurrent neural networks for predicting time series

I'd like to train a RNN to predict a time series (The data set is composed of sequences of cell cycle division times). Iv'e seen two models that seem appropriate. Presented here is my understanding for how they work. In the first, each training sequence is of some length $n$ and the goal of the model is to predict the sequence $\delta$ time steps into the future. So the target for each sequence would be that same sequence shifted $\delta$ time steps into the future. Then at test time, the input is some seed sequence $x$ , and the output is $x'$ , the prediction of $x$ shifted $\delta$ time steps into the future. We can then feed $x'$ into the model and get $x''$ , and so on, generating a prediction of $x$ 's future for an arbitrary length. In the second model, at training time the target of any time step $t$ , call it $y^{ }$ , is fed into the hidden state of the next time step $h^{ }$ and at test time, instead of passing the real target $y^{ }$ . we pass the predicted output $\hat{y}^{ }$ , again, enabling us to generate a future prediction of an arbitrary length. The more I think about it, the more it seems that really, the second model is actually a special case of the first with $\delta=1$ . Is this observation correct? If not, what is the difference and when should I use each one? Are there other RNN architectures that may be relevant? Here is a sketch of how these models should look (unrolled)
