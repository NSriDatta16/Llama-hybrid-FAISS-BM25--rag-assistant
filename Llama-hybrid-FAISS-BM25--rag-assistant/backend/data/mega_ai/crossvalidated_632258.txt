[site]: crossvalidated
[post_id]: 632258
[parent_id]: 
[tags]: 
Measure alignement between continuous and binary variables

I am trying to compare different evaluation metrics to assess performance of LLM-based solutions. To do so, I was planning to compute different metrics values (continuous outcome) and compare these values with a human judgement (binary outcome - correct or not correct). Consider the example: question = "Who is the author of Harry Potter?" answer = "J.K. Rowling" generated_answer = "The author of Harry is Joanne Rowling" Suppose you have 2 different functions that compute a continuous score: Precision (word-based) Cosine similarity between 2 embeddings (answer and generated_answer) From the 2 functions above, suppose we get these scores: precision = 1/7 = 0.1428 cosine = 0.8 For that same example, we have a binary value coming from a human judgement that indicates the generated answer is correct. correctness = 1 Suppose we have this for $n$ examples, it means we have $n$ continuous values for precision and $n$ continuous values for cosine . We also have $n$ binary values for correctness . I was thinking to using correlations (Spearman or Kendall) between each of these metrics and the correctness to determine which one is more aligned with it. However, that means I have to measure a correlation between continuous and binary values, which I am not sure is valid. My goal is to get a sense of which evaluation function is more aligned with the human judgement. Any thoughts?
