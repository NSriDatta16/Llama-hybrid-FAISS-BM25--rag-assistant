[site]: crossvalidated
[post_id]: 393445
[parent_id]: 
[tags]: 
Global sensitivity Morris method - choice of delta and normalisation of the elementary effects

I have few questions regarding the Morris method (as decribed e.g. in Campolongo, Cariboni, Saltelli, Environmental Modelling & Software 22, 2007 or Wenthworth et al. J. Uncertainty Quantification 2016) a global sensitivity method. I describe it below in some details as it is not very widely known. Method definition It uses the notation of the elemenatry effects defined as follows $$d_i(q) = \frac{f(q_1,\dots,q_{i-1},q_i+\Delta,q_{i+1},\dots,q_p)-f(q)}{\Delta} = \frac{f(q+e_i)-f(q)}{\Delta}$$ where $\Delta$ is the step size chosen from the set $\Delta \in \{ \frac1{l-1}, \dots, 1-\frac1{l-1} \}$ . Note that it assumes parameters mapped to $[0, 1]^p$ . Constructed in this way, $d_i$ quantifies the approximate, large scale, local sensitivity of the model response relative to the i th parameter. The following settings are recommended: $l$ should be even and $\Delta = \frac{l}{2(l-1)}$ which should garantee equal probability sampling from the distribution. $$d_i^k(q) = \frac{f(q^k+\Delta e_i)-f(q^k)}{\Delta}$$ is the elementary effect associated with $i$ th parameter and k th sample. With $r$ sample points per parameter, the Morris indices for the parameter $q_i$ are $$\mu_i^* = \frac1{r}\sum_{k=1}^{r} |d_i^k|, $$ $$\sigma_i^2 = \frac1{r-1} \sum_{k=1}^{r}(d_i^r - \mu)^2, \mbox{where } \mu = \frac1{r}\sum_{k=1}^{r} d_i^k.$$ The mean quantifies the individual effect of the input on output, whereas the variance incorporates variability due to parameter interactions. Ranking of the parameters is done using $\sqrt{\mu_i^{*2} + \sigma_i^2}$ . Screening algorithm (Wentworth et al. 2016) Create a $(p+1)p$ matrix $A$ with ones in the lower triangle such that $$A = \begin{bmatrix} 0 & 0 & \dots & 0 \\ 1 & 0 & \dots & 0 \\ \dots & & \ddots & \\ 1 & 1 & \dots & 1 \end{bmatrix}$$ Choose the step size $\Delta$ as above equal $\frac{l}{2(l-1)}$ . Select starting vector $q^* \in \mathbb{R}^{1\times p}$ . Construct a $p\times p$ diagonal matrix $D^*$ , whose entries are randomly chosed from $\{ -1,1\}$ . Calculate the sampling matrix $$ A_s = J_{p+1,1}q^* + \frac\Delta2 [(2A - J_{p+1,p})D^* + J_{p+1,p}]P^*,$$ where $J_{i,j}$ is a $i\times j$ matrix with all ones and $P^*$ is a permutation of the identity matrix. For parameters defined not in unit hypercube, i.e. $q\in[l_i,u_i]$ for $i=1,\dots,p$ , take $l=[l_1,l_2,\dots,l_p]$ and $u=[u_1,u_2,\dots,u_p]$ . The sampling matrix is then scaled to match the range of parameters $$ C=J_{p+1,1}l + A_s(D(u-l)), \;\;\;\;\;\; (*)$$ where $D(u−l)$ is a diagonal matrix with entries $u−l$ . Compute the elementary effects for $i=1,\dots,p.$ Let $C_k$ denote the $k$ th row of $C$ . Then $$ d_i = \frac{f(C_m) - f(C_n)}{\Delta}, \;\;\;\;\;\; (**)$$ where $m$ and $n$ denote the indices such that $m$ th row and $n$ th row differ in the $i$ th entry. Repeat steps 1-7 for $r$ samples. The Morris statistics, $\mu_i^*$ and $\sigma_i^2$ , are calculated as described in the Method section by taking the average of the local elementary effect. Note 1 from the author: denominator of (**) in step 7 is $\Delta$ for all $q_i, i = 1,\dots, p$ . The elementary effects must be computed using the scaled step size, even though model responses are computed at the parameter values, which are mapped using (*). Note 2: Wentworth et al. and others suggest $l=20$ and $r=50$ . Discussion/Questions I have trouble to see why $\Delta$ is choosen to be $\frac{l}{2(l-1)}$ , which for $p=20$ is equal $10/19$ . When selecting $q^*$ as in point 3 of the algorithm, the $q_i$ of interest has to be selected from the set $\{0,1/(l-1),2/(l-1),...,1-\Delta\}$ (according to original Morris 1991 paper, otherwise it might be that after adding delta its value is larger then 1.). I.e. $q_i$ will assume values from 0 to 9/19. Question 1: Why not simply generate sequence between 0 and 1 with elements equidistantly spaced with step $\frac{1}{(l-1)}$ ? It would be analog to the above scenario. Question 2: Would it make better sense to calculate, instead of an elemenatry effect, a local normalized sensitivity index similar to how it is done in the Matlab SimBiology toolbox, see the 'full' normalization case (of course with $\Delta$ instead of differentials $\partial x$ or $\partial k$ and without the time dependency): https://uk.mathworks.com/help/simbio/ref/normalization.html It would have the advantage that it is dimensionless compared to the elementary effects.
