[site]: crossvalidated
[post_id]: 479186
[parent_id]: 
[tags]: 
Neural network written from scratch learns much slower than PyTorch

I wrote a program from scratch using numpy for the feeding forward and backprogation of a network. I tested it against a program written using PyTorch with the same architecture and the network from scartch is around 200 times slower. What reasons do you think could cause this, and how much slower or faster would you expect a well written program from scratch to be compared to using PyTorch. The architecture of the network is a 2 stacked GRU followed by a MLP; the optimiser is Adam; and mini-batch learning is implemented in both.
