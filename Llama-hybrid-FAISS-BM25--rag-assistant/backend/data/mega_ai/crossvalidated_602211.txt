[site]: crossvalidated
[post_id]: 602211
[parent_id]: 501720
[tags]: 
P-values are used as a measure of effect size all the time. The simplest way to express effect sizes are The raw or absolute effect sizes, like a difference between means. Some alternatives to express ( relative ) effect sizes are Cohen's D, which expresses effect size relative to the pooled population variances t-statistic, which expresses effect size relative to the variance of the sample means. And also p-values, which are a way to express the effect size relative to the statistical probability when some null hypothesis is true. Depending on the application one or the other may be preferred. In publications you may often see that multiple values are reported. For instance you could something like: Our study found that participants who drank coffee had a statistically significant increase in productivity, with a mean effect size of $0.8$ ( $t_{df=23}=3.2$ , $p = 0.002$ ), proving once and for all that caffeine is the real workhorse in your cup of joe. (The content of the quote is fantasy and any resemblance to real studies are purely conincidence. I had chat-gpt make that quote for me) Note that these relative ways of expressing effect sizes do not always coincidence. For a given absolute effect size you can have different statistics and p-values depending on the sample sizes and estimated variances. The same p-value may occur with large and small effect sizes. The same effect size may occur with large and small p-values. The p-value is not a measure of the absolute effect size.
