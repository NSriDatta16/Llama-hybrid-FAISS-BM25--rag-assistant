[site]: crossvalidated
[post_id]: 521716
[parent_id]: 
[tags]: 
Linear kernel SVM performs well on non-linear separable data

I am working on an exercise for my course in SVMs. We are given a 2D-dataset and we are supposed to construct a SVM model that classifies the data as good as possible. When I plot the training set it is clear that the data is not linearly separable. I then constructed a LS-SVM model with linear kernel, where I tune the parameters to obtain optimal performance, and went on to plot the ROC-curve of this model on the test set. The area under the ROC-curve is very close to 1, meaning that the model is almost a perfect classifier. What is the intuition behind this? FYI: I obtain similar results for polynomial and RBF kernels.
