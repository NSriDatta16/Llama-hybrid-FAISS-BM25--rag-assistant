[site]: datascience
[post_id]: 10903
[parent_id]: 10877
[tags]: 
You can do this in pandas since your data set is small. For "big" data that does not fit in memory you would want to use a database; PostgreSQL with the PostGIS extension would be ideal, since it handles the nearest neighbor part, which is the most challenging aspect. Here are some sample queries, in python. Show me the Globs where average of each Glob in file Efficiency is greater than 50% import pandas efficiency = pandas.read_csv('efficiency.csv', sep=',', index_col=0) structure = pandas.read_csv('structure.cv', sep=',', index_col=0) efficiency[efficiency.mean(1) > 0.5] Sort the Structure list descending on Run3, then ascending on Run2. structure.sort_values(by=["Run3", "Run2"], ascending=[False, True]) I'm not sure how you're defining the distance so I am unable to demonstrate the last part.
