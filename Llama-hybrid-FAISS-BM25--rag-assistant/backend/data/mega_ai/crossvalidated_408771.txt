[site]: crossvalidated
[post_id]: 408771
[parent_id]: 
[tags]: 
Reinforcement Learning: what does "γ-just" mean in advantage function estimation?

In "HIGH-DIMENSIONAL CONTINUOUS CONTROL USING GENERALIZED ADVANTAGE ESTIMATION" by Schulman et al. ( https://arxiv.org/abs/1506.02438 ) the advantage estimator, under certain conditions, is claimed to be "γ-just", where γ is the discount factor. What does it mean? Thanks EDIT: If i interpreted correctly the Definition 1 in the mentioned paper, it means that an estimator is γ-just if it is an exact estimator of the discounted version of A. Is it correct? This being said, I still don't understand the subscripts of the estimator At. Why did the authors write 0:∞ ? The estimate (as well as the real value of A) should depend only on the trajectory to go. What am I missing?
