[site]: crossvalidated
[post_id]: 451458
[parent_id]: 451451
[tags]: 
One key point, the conditional Normal distribution is what matters for ANOVA. In other words, if you had $Y_{ijk} = \mu + \beta_i + \beta_j + \beta_k (+\mbox{interactions?}) + \epsilon$ it's the distribution of the error term $\epsilon$ that matters. As a statistical reviewer, I have had people try to fob me off with arguments about Normal approximations. I do know they might be accepted by non-statistical reviewers. But I can see all kind of good reasons for using POLR (proportional odds logistic regression). For example, what if the difference between ticking 5 and 4 is very different from the difference between 1 and 2. I know the effect sizes are in log odds ratios which is weird for most people, but they are very comparable linear models. Instead of $\mu$ above you have a vector of cutpoints, but then you get $\beta$ values which indicate the change in log odds for the difference between level 1 and level 2 in each of your factors. I know there are a few more assumptions to check, but I really think the advantages outweigh the time you have to invest in figuring it out.
