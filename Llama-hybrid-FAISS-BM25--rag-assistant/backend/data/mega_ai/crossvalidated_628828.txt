[site]: crossvalidated
[post_id]: 628828
[parent_id]: 
[tags]: 
Can expected variance of GLM be expressed through gradients under non-cannonical link functions?

In GLMs (generalized linear models), one can typically obtain an estimate of the expected variance of the response variable given the predictors as a transformation of the same parameter that defines the mean. Per the paper: JÃ¸rgensen, Bent. "Exponential dispersion models." Journal of the Royal Statistical Society: Series B (Methodological) 49.2 (1987): 127-145. When using a canonical link function, the inverse of the expected variance van be expressed as the derivative of the inverse link function w.r.t. the mean: $$ V(\mu)^{-1} = \frac{\partial \tau^{-1}(\mu)}{\partial \mu} $$ So for example, for a logistic regression model, where $$ P(y = 1|x) = \frac{\exp(x)}{\exp(x)+1} = \mu = p $$ the variance is known to be: $$ V(y|x) = p (1 - p) $$ the link is the logit function $$ g(p) = \log \frac{p}{1 - p} $$ And the expected variance can be calculated through it as $$ V(y|x) = \frac{1}{\frac{\partial g(p)}{\partial p}} $$ $$ p = \frac{\exp(x)}{\exp(x)+1} $$ without any apriori knowledge that $var(p) = p (1 - p)$ However, if one were to switch to a non-cannonical link function, such as probit, where $$ g(p) = \Phi^{-1}(p) $$ the relationship would no longer hold. Now, my question is, given knowledge about the link function, inverse link function, and probability distribution $P(y|x)$ or $P(y|g(x))$ , can the expected variance be expressed in terms of those functions plus their derivatives?
