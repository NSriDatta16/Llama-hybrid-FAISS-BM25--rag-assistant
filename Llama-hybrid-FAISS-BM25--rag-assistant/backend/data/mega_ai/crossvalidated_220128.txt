[site]: crossvalidated
[post_id]: 220128
[parent_id]: 220127
[tags]: 
I'll first remark that conventional PCA is not so well adapted to categorical features (such as whether or not an organism has wings). The reason is that the principal components are generally nontrivial linear combinations of the input features, and it's not always clear what that should mean. For instance the first principal component could be composed of something like $45\%$ "has wings", $30\%$ "feathered", and $25\%$ "6 legs" (these percentages can be computed from the first eigenvector). It would be difficult to use this to eliminate a feature because secretly the "right" features are "has wings and feathers" (birds) and "has wings and six legs" (insects). With enough data some sort of PCA can surface this insight, but it's not always obvious in practice. That said, there is some work in this direction; a good buzzword is Multiple correspondence analysis . The more general problem that you're considering is feature selection , and there are many good approaches for eliminating redundancy in features subject to certain constraints; given that you're not working with an astronomical number of observations, mRMR might be good for your problem.
