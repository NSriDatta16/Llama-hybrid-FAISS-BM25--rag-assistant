[site]: crossvalidated
[post_id]: 126147
[parent_id]: 104582
[tags]: 
Regresssion trees require far greater sample sizes than predominantly additive regression models, and make far more stringent assumptions for continuous variables (piecewise flatness with identifiable cutpoints). Note that if you use an improper accuracy scoring rule to compare two methods (e.g., "classification" accuracy) you will get highly misleading results. Single regression trees are not stable and do not have competitive $R^2$, hence the popularity of tree-averaging-type methods such as random forests.
