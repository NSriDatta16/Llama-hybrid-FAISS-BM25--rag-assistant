[site]: crossvalidated
[post_id]: 574458
[parent_id]: 574185
[tags]: 
If you transform your images to all have the same background, you are removing noise from your data. This means a model trained on these transformed images may be more accurate on other images transformed in the same way . You would need to transform your test images as well - and include this transformation in the ML pipeline, if you intend to use this model in an application. If you don't, the model is likely to get confused by the background and would probably perform worse than a model trained on the original images would perform. If you want to try this, you could use object detection techniques (for an into to these, see Jason Brownlee's "A Gentle Introduction to Object Recognition With Deep Learning" ) to detect the skin, then mask out the rest of the image.
