[site]: crossvalidated
[post_id]: 555949
[parent_id]: 
[tags]: 
How to interpret the feature importances for 'eli5.show_weights()' for regression?

I am trying to understand how the interpret the values yielded by eli5's show_weights variable after feature importance. I have used this for several regression models, e.g. multiple linear regression, Support Vector Regression, Decision Tree Regression and Random Forest Regression. I am using it to interpret the importance of features for all these models. This is my code for the Random Forest Regression: from sklearn.model_selection import RepeatedKFold import eli5 from eli5.sklearn import PermutationImportance from eli5 import show_prediction, show_weights Xfeature_names = X.columns regressor = RandomForestRegressor(n_estimators = 100, random_state = 0) # K-fold cross validation with permutation testing cv = RepeatedKFold(n_splits=6, n_repeats=100, random_state=1) perm = PermutationImportance(regressor, cv = cv) perm.fit(X,y) show_weights(perm, feature_names = X.columns.tolist()) I then receive this output: As I read from the eli5 documentation, what show_weights does is Return an explanation of estimator parameters (weights) as an IPython.display.HTML object. from https://eli5.readthedocs.io/en/latest/autodocs/eli5.html I read previously that this is an improvement in model performance as measured by r2, but I was not able to find this on the eli5 documentation. So my question is, how do I interpret the feature weights meaningfully? Could I state based on this table that e.g. Max span improved model performance as measured by r2 by 0.11 (sd = 0.32), and was therefore the most important contributor to model performance? Or is there a better way to meaningfully and transparently report the results from the permutation importance testing?
