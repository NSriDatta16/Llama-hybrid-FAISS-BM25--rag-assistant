[site]: crossvalidated
[post_id]: 196606
[parent_id]: 
[tags]: 
If all components of a hierarchical model have not converged, can we say that any parameters have truly converged?

I'm working with a hierarchical regression model of the following form similar to that presented in Peter D. Hoff's book, A First Course in Bayesian Statistical Methods: $\boldsymbol{Y}_j \sim \text{multivariate normal}(\boldsymbol{X}_j\boldsymbol{\beta}_j,\sigma^2\boldsymbol{I}) \\ \boldsymbol{\beta}_1,...\boldsymbol{\beta}_m \sim \text{multivariate normal}(\boldsymbol{\theta},\boldsymbol{\Sigma}) \\ \boldsymbol{\theta} \sim \text{multivariate normal}(\boldsymbol{\mu}_0, \boldsymbol{\Omega}_0) \\ \boldsymbol{\Sigma} \sim \text{inverse-Wishart}(\eta_0,\boldsymbol{\text{S}}_0^{-1}) \\ \sigma^2 \sim \text{inverse-gamma}(\nu_0/2,\nu_0\sigma_0^2/2)$ After 100000 repetitions, when I look at the $\beta$ coefficients, the $\theta$ coefficients and $\sigma^2$, they appear to have converged. However, when I see the $\Sigma$ matrix, it appears that it has not converged. My question is, can I really say that the other components of the model have truly converged, especially since each conditional distribution depends on the other parameters? Should I trust the results until all of the parameters have converged? Thanks!
