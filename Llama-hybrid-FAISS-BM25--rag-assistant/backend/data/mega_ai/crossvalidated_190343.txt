[site]: crossvalidated
[post_id]: 190343
[parent_id]: 
[tags]: 
Hierarchical Weibull model: choice of parameterization

I am experimenting with fitting a Bayesian hierarchical model using right-censored and Weibull distributed time-to-first-event data. However, I have some issues that might be related to the Weibull-parameterization (in terms of shape and 1/scale) that I have chosen. I wanted to allow a reasonable amount of flexibility of the distribution parameters in each experiment (each with multiple observations, some of which have an event observed and some of which are right-censored), so my first try was to have a bivariate normal random effect on the log-shape parameter and the log(1/scale) parameter for each experiment. In my first test, I used a bivariate normal prior with mean 0 and covariance matrix of $1000 \times \bf{I}_{2\times2}$ for the mean of the random effect, while for the covariance matrix of the random effect I used an inverse Wishart prior with 2 degrees of freedom and $100 \times \bf{I}_{2\times2}$ as the scale matrix. It turned out that my software (I used PROC MCMC in SAS) did not seem to sample very efficiently (i.e. high autocorrelation and poor mixing despite strong thinning and runtime of 3 hours) on a set of test data I generated. In the test data I had 12 exerimental units with around 200 observations each, generated using exponentially distributed failure times with around 1/4 to 3/4 of non-censored event times, which I assumed should be a relatively nice scenario. I wonder whether part of the problem is the way in which I have parameterized the Weibull distribution (in terms of shape and 1/scale). I seem to recall that I read somewhere that the parameter estimation with the Weibull distribution can be difficult and that reparameterizations help. I assume I read that in the context of maximum-likelihood estimation, but did assume that the same might be true for MCMC sampling. I am not really wedded to this particular parameterization, so I would really like to hear whether anyone is aware of other parameterizations generally working much better (or at least under some circumstances).
