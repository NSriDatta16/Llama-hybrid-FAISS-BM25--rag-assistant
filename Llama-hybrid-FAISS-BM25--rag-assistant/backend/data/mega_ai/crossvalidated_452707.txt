[site]: crossvalidated
[post_id]: 452707
[parent_id]: 452209
[tags]: 
Samplers are algorithms used to generate observations from a probability density (or distribution) function. Two examples are algorithms that rely on the Inverse Transform Method and Accept-Reject methods . On the other hand, an estimator is an approximation of an often unknown quantity. Monte Carlo methods refer to a family of algorithms used to obtain these estimations. Monte Carlo methods have the characteristic that they rely on samples from probability distributions to obtain these approximations. This is where the two concepts connect. Markov Chain Monte Carlo (MCMC) methods combine these two ideas to generate samples and estimate quantities of interest with these samples. Metropolis-Hastings is one of many MCMC algorithms. For example, if your quantity of interest is the mean of a posterior distribution, this usually means you have to solve an integral. In higher dimensions, solving the integral is often very difficult or even impossible to solve analytically. The idea of MCMC methods is to simulate a sample from the posterior distribution, and then estimate the integral needed to calculate the mean using the average of the sample. For a friendly introduction to these concepts, I think Introducing Monte Carlo Methods with R by Robert & Casella is a great reference.
