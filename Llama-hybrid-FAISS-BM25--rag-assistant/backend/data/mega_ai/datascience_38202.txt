[site]: datascience
[post_id]: 38202
[parent_id]: 38199
[tags]: 
I'm not convinced 24% accuracy is very poor, depending on what your dataset looks like. Your baseline accuracy is in the realm of 3.5% with 28 classes. But let's assume you want to do better. CNNs for images use 2-d convolution filters, because there is an expectation that pixels that are close together should be processed together. I guess you could use a 2-d convolution on the 90x59 matrix, but it isn't clear to me that we should be looking for information across "close" sensors. Perhaps you can use some sort of "tall" 2-d convolution, so that you capture information across all sensors in the same time span. You may want to try training a model on each channel and ensembling them instead, as you mention. If you do this, I guess you could use a 1-d convolution to process each channel, but I don't really see why you would. Is there a reason you feel the need to use CNNs? There are very likely more appropriate models specific to processing time-series data.
