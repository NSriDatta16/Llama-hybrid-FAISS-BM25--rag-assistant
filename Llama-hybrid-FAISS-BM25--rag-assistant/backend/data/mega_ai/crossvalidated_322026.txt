[site]: crossvalidated
[post_id]: 322026
[parent_id]: 322020
[tags]: 
It's something similar to the change of variable trick in integration. The two expressions in the text clearly indicate you to consider substituting $r - s$ with $m$. The details are spelled out as follows. For simplicity, let's denote the summand $e^{-i(r - s)v}\gamma(r - s)$ by a bivariate function $K(r, s)$, whose domain is the set of $N \times N$ grid points $\{1, 2, \ldots, N\} \times \{1, 2, \ldots, N\}$. On the other hand, note that $K(r, s)$ is completely determined by the coordinate differences $m := r - s$, therefore may also be denoted by $\tilde{K}(m)$. The challenge is to express the double sum $S := \sum_{r = 1}^N \sum_{s = 1}^N K(r, s)$ in terms of the new summing index $m$. I will illustrate this transformation process in matrix form as follows. In terms of $(r, s)$, we are effectively summing over the matrix (think the row corresponds to $r$ and the column corresponds to $s$): \begin{align} \begin{bmatrix} K(1, 1) & K(1, 2) & \cdots & K(1, N) \\ K(2, 1) & K(2, 2) & \cdots & K(2, N) \\ \vdots & \vdots & \ddots & \vdots \\ K(N, 1) & K(N, 2) & \cdots & K(N, N) \end{bmatrix}. \tag{1} \end{align} As stated before, since $K(r, s) = \tilde{K}(r - s) = \tilde{K}(m)$, matrix $(1)$ is equal to \begin{align} \begin{bmatrix} \tilde{K}(0) & \tilde{K}(-1) & \cdots & \tilde{K}(1 - N) \\ \tilde{K}(1) & \tilde{K}(0) & \cdots & \tilde{K}(2 - N) \\ \vdots & \vdots & \ddots & \vdots \\ \tilde{K}(N - 1) & \tilde{K}(N - 2) & \cdots & \tilde{K}(0) \end{bmatrix}. \tag{2} \end{align} The entries in matrix $(2)$ can be summed over diagonally. For example, there are $N$ terms $\tilde{K}(0)$ lie on the main diagonal line, which corresponds to $m = 0$. There are $N - 1$ terms of $\tilde{K}(-1)$ and $\tilde{K}(1)$ lie on the first off-diagonal line of the upper triangle and that of the lower triangle, which correspond to $m = -1$ and $m = 1$, respectively. In general, on the $m$-th off-diagonal line of the upper triangle, there are $N - m$ terms of $\tilde{K}(-m)$, while on the $m$-th off-diagonal line of the lower triangle, there are $N - m$ terms of $\tilde{K}(m)$. Summing all the $N^2$ terms of $\tilde{K}(\cdot)$ in this way, we obtain \begin{align} S = & \sum_{\text{upper triangle}} \tilde{K}(\cdot) + \sum_{\text{diagonal}}\tilde{K}(\cdot) + \sum_{\text{lower triangle}}\tilde{K}(\cdot) \\ = & \sum_{m = 1}^{N - 1} (N - m)\tilde{K}(-m) + N\tilde{K}(0) + \sum_{m = 1}^{N - 1}(N - m)\tilde{K}(m) \\ = & \sum_{|m| This completes the proof. For your second question, to show $f_N(\cdot)I_{(-\pi, \pi]}(\cdot)$ is a density function, since $f_N(v) \geq 0$ for all $v \in (-\pi, \pi]$, it suffices to show that $$\int_{-\pi}^{\pi}f_N(v) dv = 1.$$ By the identity we just proved, together with the linearity of the integral, $$\int_{-\pi}^{\pi} f_N(v) dv = \frac{1}{2\pi N}\sum_{|m| It is easy to show (also well-known as the orthogonality of Fourier basis) that \begin{align} \int_{-\pi}^{\pi} e^{imv} dv = \begin{cases} 0 & m \neq 0, \\ 2\pi & m = 0. \end{cases} \end{align} Combining this with the fact $\gamma(0) = 1$, it follows that $\int_{-\pi}^{\pi} f_N(v) dv = 1$. PS: I found your question is more about pure mathematical derivation, which may be more appropriate to be asked at Mathematics Stack Exchange. Indeed, this time series book you are reading is written in a very rigorous way.
