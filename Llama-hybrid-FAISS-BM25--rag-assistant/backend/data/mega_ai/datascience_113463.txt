[site]: datascience
[post_id]: 113463
[parent_id]: 
[tags]: 
Error when predicting breast cancer using logistic regression

Summarize the problem : Received an error 1 # predict the test dataset ----> 2 yhat = model.predict(X_test) File c:\Users\nwm2\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:425, in LinearClassifierMixin.predict(self, X) 411 def predict(self, X): 412 """ 413 Predict class labels for samples in X. 414 (...) 423 Vector containing the class labels for each sample. 424 """ --> 425 scores = self.decision_function(X) 426 if len(scores.shape) == 1: 427 indices = (scores > 0).astype(int) File c:\Users\nwm2\Anaconda3\lib\site-packages\sklearn\linear_model\_base.py:407, in LinearClassifierMixin.decision_function(self, X) 387 """ 388 Predict confidence scores for samples. 389 (...) 403 this class would be predicted. 404 """ ... 118 ) 119 # for object dtype data, we only check for NaNs (GH-13254) 120 elif X.dtype == np.dtype("object") and not allow_nan: "ValueError: Input contains NaN, infinity or a value too large for dtype('float64')." Provide details and any research : Converting breast cancer dataset - categorical data into numbers using feature-engine. Seems to work up to - yhat = model.predict(X_test) with above error. I've tried checking for nans in my dataset but there's none. Here's the code # load libraries from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score from sklearn.model_selection import train_test_split from sklearn.preprocessing import LabelEncoder from feature_engine.encoding import OrdinalEncoder import pandas as pd from sklearn.metrics import mean_absolute_error from sklearn.metrics import r2_score # load dataset df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv', header=None) df.head() # assign labels to features names = ['Age', 'Menopause', 'Tumor-Size', 'Inv-Nodes', 'Node-Caps', 'Deg-Malig', 'Breast', 'Breast-Quad', 'Irradiat', 'Class'] df.columns = names # use a loop to determine which features are categorical and which are numerical for name in names: if name != 'Class': if df[name].dtype == 'object': print(name, 'is categorical') else: print(name, 'is numerical') # print out the number of categorical features print('Number of categorical features:', len(df.select_dtypes(include=['object']))) # print out the number of numerical features print('Number of numerical features:', len(df.select_dtypes(include=['number']))) # use train test split method from scikit-learn library to seperate dataset into 70% training and 30% test X_train, X_test, y_train, y_test = train_test_split(df.drop(['Class'], axis=1), df['Class'], test_size=0.3, random_state=1) # use feature_engine method Ordinal Encoder to convert categorical features to ordinal encoder = OrdinalEncoder(encoding_method='arbitrary') #fit the data to the model encoder.fit(X_train) # use transform to encode the categories to numbers X_train = encoder.transform(X_train) X_test = encoder.transform(X_test) #check for nans in X_test print(X_test.isnull().sum()) # Ordinal encode target variable y label_encoder = LabelEncoder() label_encoder.fit(y_train) y_train = label_encoder.transform(y_train) y_test = label_encoder.transform(y_test) # check for any nans print(df.isnull().sum()) # use logistic regression method from scikit-learn library to predict malignancy model = LogisticRegression() # fit the model to the training dataset model.fit(X_train, y_train) print(X_test.isnull().sum()) X_test = X_test.fillna(X_test.mean()) X_test.isnull().sum() # predict the test dataset - error happens here! yhat = model.predict(X_test)** # print out accuracy score using accuracy_score method from scikit-learn library accuracy_score = accuracy_score(y_test, yhat) print('Accuracy: %.2f' % (accuracy_score * 100)) ```
