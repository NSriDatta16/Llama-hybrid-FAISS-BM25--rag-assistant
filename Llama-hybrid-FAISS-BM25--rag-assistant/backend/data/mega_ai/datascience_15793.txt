[site]: datascience
[post_id]: 15793
[parent_id]: 15784
[tags]: 
When you look at the vectors that word2vec generates - negative words may have unique features but can be treated just like positive words. That is to say, as far as the NN is concerned - these are just similar words. You may have to construct "concept vectors" on top of the word vectors to do what you would like to do. Your parts of speech tagging should automatically mark negating words as ADV. You can then train on these adverbs in conjunction to your verbs as a positive or negative output. Here's an example using spacy:- import spacy nlp = spacy.load('en') # this can take a while sample_text = u'Do not go.' parsed_text = nlp(sample_text) token_text = [token.orth_ for token in parsed_text] token_pos = [token.pos_ for token in parsed_text] At this point token_text will be a list of your words and token_pos will be the POS tagging:- Do - VERB not - ADV go - VERB . - PUNCT As you can see, "not" is tagged as ADV here. You can now feed this tagged output (or a better parse tree) into a second network to train for a negative or positive output. Hope this helps.
