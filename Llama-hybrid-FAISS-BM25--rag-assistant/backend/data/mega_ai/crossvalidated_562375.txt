[site]: crossvalidated
[post_id]: 562375
[parent_id]: 562363
[tags]: 
This is a very broad question, because the applications vary a lot. There are short series and there are long series. There are series with strong signal and weak noise and there are the opposite. Machine learning methods are likely to do well with long series and strong signal. Classical time series methods may do better with short series and weak signal. (But that applies more generally than just to time series.) Makridakis "Interview about M4, Foresight" (2018) talks about this. He says machine learning methods underperform classical time series models, but the machine learning community does not accept this: Our conclusions were quite straightforward: the forecasting accuracy of all ML methods was inferior to that of statistical ones. Not only that, but the accuracy of the Na√Øve 2 benchmark was better than half the ML methods. We were excited by the results, and sent the paper to the journal Neural Networks. We got back a letter from them saying that other studies have proven the superiority of ML methods, so our results could not be right. The paper was rejected without even a peer review! We then wrote at least 10 letters to the editor asking about the studies purporting to show the superiority of ML. Against all academic tradition, we received no response. Nothing. And our own search of statistical data bases, including Google Scholar and Scopus, found no studies proving the superiority of ML methods. See also Makridakis et al. "Statistical and Machine Learning forecasting methods: Concerns and ways forward" (2018). It says that traditional statistical time series models consistently dominate the machine learning methods in forecasting monthly data. (However, the authors might not be entirely fair to the ML methods. To keep computational costs manageable, the latter are not tuned all that thoroughly. In practice it should be possible to tune them more, given sufficient computational resources.) However, that was 2018. In the M5 competition (2020), a machine learning method won. It was a method that in a sense aggregated classical time series models/forecasts. (Though it may not be obvious from the description linked above, it was discussed as such rather clearly in a Forecasting Impact podcast; cannot remember which episode, though; perhaps the one with Rob Hyndman.) It was based on them, yet it was able to improve over them just a bit, and that was sufficient to win the competition. If the M competitions are any guide, it seems machine learning has caught up just recently with the classical time series methods. Even if they actually employ the classical time series methods under the hood, machine learning methods are now able to beat them in some instances.
