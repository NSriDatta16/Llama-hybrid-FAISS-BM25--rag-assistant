[site]: crossvalidated
[post_id]: 414339
[parent_id]: 310687
[tags]: 
I think the above answer is correct, but let me just explain some of the intuition for this problem, which helps us generalize it to a broader scope of models. First we'll assume that $N = M$ , for notational convenience. This assumption allows us to assume that the training set and test set are drawn from the same distribution. Let $L(m, y)$ be the loss of the model $m$ on a data set $y$ . Let $\mathcal{M}$ be the set of all models (not necessarily linear). Now define $m_x$ to be a model which optimizes the loss on data set $x$ , that is, $L(m_x, x) \le L(m, x)$ for all models $m \in \mathcal{M}$ . Let the data set $x$ and the data set $y$ be drawn independently from a distribution $\mathcal{D}$ . The LHS in the original problem represents the average value of $L(m_x, x)$ whereas the RHS represents the average value of $L(m_x, y)$ . This is hard to compare; it's possible for $L(m_x, x)$ to be larger than $L(m_x, y)$ because $y$ might just be an "easier" dataset than $x$ . However, we can see that the average value of $L(m_x, y)$ is the same as the average value of $L(m_y, x)$ because $x$ and $y$ are independent. Now, the comparison is easy. The average value of $L(m_x, x)$ is less than or equal to the average value of $L(m_y, x)$ because $L(m_x, x)$ is always less than $L(m_y, x)$ , and we may conclude.
