[site]: crossvalidated
[post_id]: 497685
[parent_id]: 
[tags]: 
Bootstrapping CIs for model predictions: bootstrap model parameters or mean difference in model predictions?

I am calculating the average incremental effect of a disease on number of health care visits. To calculate this effect, I am estimating a model for number of visits as a function of the disease (a binary 0/1 variable) and several covariates. I then use this model to make two predictions of number of visits using a simulated data set: one prediction where the disease variable is manipulated to be as if everyone had the disease (disease variable set to 1 for everyone and predictions averaged) and one prediction as if no one had the disease (disease variable set to 0 for everyone and predictions averaged). The difference in the two average predictions is the average incremental effect of the disease that I am interested in. In my experience, this approach is called recycled predictions. To quantify uncertainty in this estimate, I would like to bootstrap a 95% CI around it. If I estimate the model using my original data (which has a mix of disease == 0 and disease == 1) and then bootstrap just the mean difference, I get the same point estimate but a different SE/95% CI than if I bootstrap the model coefficients using the original data and then take the difference of the predictions from my simulated data. Which approach is correct? library(tidyverse) library(boot) # data disease $disease == 0, ], type = "response")) mean_disease1 disease == 1, ], type = "response")) mean_diff $disease == 0, ], type = "response")) mean_disease1 disease == 1, ], type = "response")) mean_diff ```
