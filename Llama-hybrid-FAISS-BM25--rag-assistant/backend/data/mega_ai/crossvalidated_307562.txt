[site]: crossvalidated
[post_id]: 307562
[parent_id]: 307546
[tags]: 
If you have tested your model on an unseen test set and then did not tune again to improve results on the said test set, assuming that the test set is large enough then you will have a bias-free estimation of the error. When you apply your model to other unseen test sets, that come from the same data distribution , you can expect to have a similar performance. About the confidence in your prediction, the output a classifier is usually a score, not a label. For example, in a neural network, the output is the probability of an instance belonging to a class. You can work with this information instead of the predicted labels. Regarding semi-supervised learning, you could use the Expectation-Maximization algorithm to take advantage of the unlabeled data. In this algorithm, you repeatedly predict labels for the unlabeled data and then use the predicted labels to train a new model. Under some particular conditions, this actually improves performance on unseen data.
