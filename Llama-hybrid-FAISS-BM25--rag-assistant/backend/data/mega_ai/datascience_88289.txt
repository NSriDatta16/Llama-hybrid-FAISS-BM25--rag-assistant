[site]: datascience
[post_id]: 88289
[parent_id]: 
[tags]: 
Denoising Prior to Image Classification

From what I have read, Denoising during preprocessing for image classification tasks seems to be a bit controversial. While on one hand it might improve classification accuracy, the computational complexity seems to discourage a lot of people. Rather I've seen a lot of claims, but hardly anything I can call concrete evidence, which argue that noise "would not matter" for a sufficiently deep neural network. That being said, assuming that I have decided to perform some kind of Denoising on my data, prior to classification, I'd like to ask what are some good practices? I've recently gotten into auto-encoders (and their potential in denoising) and I've seen models which either derive features from encodings (in deeper layers) or concatenate encoded features on top of the original data. So essentially, one approach is to embed the "denoiser" into the classification network itself. Are there any other techniques I can look into? I'm asking in general, so feel free to answer on any other ML models which aren't neural network-based. Thanks in advance
