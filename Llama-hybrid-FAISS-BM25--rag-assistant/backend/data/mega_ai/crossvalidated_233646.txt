[site]: crossvalidated
[post_id]: 233646
[parent_id]: 233597
[tags]: 
Try to put the quality measure into the data, not in the model. You have to make an assumption though, and that is that you need to guess at the distribution of your data points, I'll try to explain below. I believe the following pragmatic approach will deliver workable results: assuming a Gaussian distribution for your ratings, the recipe would be as follows: For each of your measurements, you determine a parameter $\sigma=\mu\sqrt{\nu}/\nu$, where $\mu$ is the mean rating and $\nu$ is the accompanying vote count. For each measurement, you generate a large number $N$ of random numbers from the normal distribution that has mean $\mu$ and standard deviation $\sigma$. The effect is that your rating of 4.5 with only 1 vote is now represented in your data with a rather large variety, whereas the rating of 2 with 10 votes, has a much smaller variety of 0.6. Feed the augmented data to your algorithms where all data points have the same weight. Edit: On the the value of $\sigma$ The $\sigma$ value has its roots in Poissonian statistics, where the variation on a count is equal to the count itself. In your case the vote count. Edit: On the "boundedness" of your distribution If you do as the recipe above suggests, your augmented data will include mean ratings that are not valid values, i.e. less than 1 and more than 5 (or 10). You could keep those values and merely truncate the predictions of your models. There is an alternative described here . That will improve the mathematical foundation of your analysis. However, I doubt it will matter significantly in practice.
