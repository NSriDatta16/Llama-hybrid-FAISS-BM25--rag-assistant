[site]: crossvalidated
[post_id]: 346863
[parent_id]: 344914
[tags]: 
You say "I want to estimate distribution". But you don't have enough data to estimate this distribution. In this case, you have to make simplifying prior assumptions. You say that prediction $\hat{Y}(A)$ of a model is uncertain: that is, the real growh potential $Y(A)$ might be different by $\varepsilon=Y(A)-\hat{Y}(A)$. Conditional distribution $P(\varepsilon|A)$ is what you are trying to estimate. Having this distribution, you can predict distribution of difference $Y(A)-Y(B)=x$ as convolution $p(x) \sim \int p(z|A)p(z-x|B)dz$. This already requires assumption that different trees are independent of each other, but this assumption is weak enough. Now the stronger assumtptions which can make it as simple as possible: assume $P(\varepsilon|A)$ is normal - then it will be easy to integrate it. For many natural proccesses, this assumption is realistic assume $P(\varepsilon|A)$ does not depend on $A$ at all - then you have only to estimate two parameters, its mean and variance. If your data is limimted, this is enough. assume your model is on average unbiased (most of them are on IID data), then you have to estimate only variance of $\varepsilon$ . If you think that the model is biased, you can estimate the bias as well, but in the distribution of difference it will cancel out. This variance should ideally be estimated out-of-the-train-sample. Cross validation is ideal for this, but if you can fit the model only once (why?), then you can split your 200 trees into train and test sets e.g. of 140 and 60 trees, fit the model on the first set, and estimate variance of the error on the second one. Let it be $\sigma^2$ Now when you have your $P(\varepsilon)\sim\mathcal{N}(0, \sigma^2)$, you can show that distribution of difference is also normal, $P(Y(A)-Y(B))\sim\mathcal{N}(\hat{Y}(A)-\hat{Y}(B), 2\sigma^2)$. Voila! If you feel that the homoschedasticity assumption ($Var(\varepsilon|A)=\sigma^2$ is too strong, you have to somehow estimate this variance. It can be done non-parametrically (e.g. with bootstrap), but you say it is not an option. In this case, you can come up with a simple parametric model for $\sigma(A)$ - for example, $\sigma(A)=\alpha+\beta\hat{Y}(A)$, or $\sigma(A)=\alpha\hat{Y}(A)^\beta$. Then you can estimate parameters of this model instead of estimating a single $\sigma$. If you still believe that $(\hat{Y}(A)-Y(A))\sim\mathcal{N}(0, \sigma(A)$), then $Y(A)-Y(B)$ has the same mean as before and variance $\sigma^2(A)+\sigma^2(B)$ and is still normal.
