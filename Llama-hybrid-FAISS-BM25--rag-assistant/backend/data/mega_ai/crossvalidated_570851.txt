[site]: crossvalidated
[post_id]: 570851
[parent_id]: 
[tags]: 
Feature selection with RandomForest and then retrain RandomForest using the selected features

I am trying to classify patients into 2 different groups using a random forest. The features correspond to the gene expression of individual patients. This means, that I have around 20.000 features (20.000 genes were measured) and 120 observations (patients). I am wondering, if it would make sense to pre-select genes, for example based on how much they vary across patients and then use this subset, of for example 3000 genes to train the actual RandomForest. I am unsure about this, because from what I have read, RandomForest basically automatically evaluates the importance of features and drops unnecessary ones. Another question I had was, how you would proceed if you want to predict the class of a patient using for example only the 10 most informative genes (returned by a first run of the RandomForest using all genes). Should I re-train the Classifier using only the 10 features as an input or is it possible to use my trained Classifier (trained using all genes) and only provide it with the 10 features that I am interested in (I am using scikit-learn for the implementation). Any help or comments are much appreciated! Cheers!
