[site]: crossvalidated
[post_id]: 501649
[parent_id]: 
[tags]: 
Fluctuating Validation Loss and Accuracy while training Convolutional Neural Network

I am training a convolutional neural network with 3 layers to classify cancer cell images into one of the 2 classes. I am using ReLU activations to introduce non linearity and batchnorm / dropout per layer for regularization. I have 2340 images per class in my training set and 200 images per class in validation set (Both sets have perfectly balanced classes). Even after enough regularization, it seems my model is still overfitting. What could be other possible reasons for fluctuating validation loss and accuracy? Should I try a lower learning rate? (current lr = 0.001). What can I do to solve this issue?
