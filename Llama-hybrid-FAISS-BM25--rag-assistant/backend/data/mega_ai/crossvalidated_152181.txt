[site]: crossvalidated
[post_id]: 152181
[parent_id]: 
[tags]: 
What does improper learning mean in the context of statistical learning theory and machine learning?

I was reading the following paper and it talked about improper learning. I wasn't 100% what it rigorously meant but they do mention: I am not sure what "representation independent" means, but as far as I am concerned, the learning algorithm is allowed to choose functions that might not be exactly within the restriction of the concept class $C$ that it is trying to learn. i.e. it might be trying to learn some specific type of function from samples (say trying to learn a half-space $\mathcal{H}_{n,k}$) but we allow it to choose functions of not that type, with the restriction that its error is not very far from the best of the original class in consideration. I guess the intuition is more or less clear, but was wondering if this interpretation is correct and whether there is a more precise/rigorous way to define what improper learning is.
