[site]: crossvalidated
[post_id]: 221474
[parent_id]: 
[tags]: 
Two ways of optimize the same function

i m reading actually this tutorial about deepLearning and in particurlar about Logistic Regression. http://deeplearning.net/tutorial/logreg.html#logreg I don't get why it first says to optimize logistic regression taking the max Probability and after using the Log loss function ? Sorry you can explain me the point where him will use the Argmax and where Will use the Loss ? you would not need only 1 of this 2 ?
