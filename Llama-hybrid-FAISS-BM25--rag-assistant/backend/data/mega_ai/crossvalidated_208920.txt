[site]: crossvalidated
[post_id]: 208920
[parent_id]: 208571
[tags]: 
The purpose of incomplete principal components regression is to accomplish data reduction in an unbiased way by not using $Y$ in a disorganized way to select the model's independent variables. That means that the model must include principal components $1, 2, \dots, k$ where $k$ can be chosen using AIC. It is not appropriate to pick and choose which PCs to include in a purely stepwise way. Also the output of the lrm function defines how to interpret the intercepts. You have misinterpreted them. They correspond to cumulative probabilities. Once you take care of those problems you can interpret the signs of coefficients in the usual way. lrm states the model such that if $\beta$ is positive, increasing $X$ is associated with increasing $Y$. You can run plot(anova(fit)) to get a rough idea of ranking of predictive discrimination. But the data are not capable of reliably telling you the ranking of variable importance, which would be exposed by bootstrap confidence intervals on importance ranks (type ?anova.rms for more information on this).
