[site]: crossvalidated
[post_id]: 113032
[parent_id]: 
[tags]: 
ks.test and ks.boot - exact p-values and ties

I am confused by the behaviour of ks.test (package stat) a) in the presence of ties and b) if one-sided while doing a two-sample test. Documentation: "Exact p-values are not available for the two-sample case if one-sided or in the presence of ties." I ask if black (experiment) and red (control) follow the same distribution function without knowing the underlying distribution function. In my hands exact p-values are computed if one-sided and in the presence of ties (according to the warning message). But two-sided the p-value is just If interested you may download the data as .Rda (length of the vector ~ 9000): https://www.dropbox.com/s/xl29jvpurkbwqpm/black.Rda?dl=0 https://www.dropbox.com/s/5biptm1xet36v3v/red.Rda?dl=0 Example: ks.test (black, red) Two-sample Kolmogorov-Smirnov test data: black and red D = 0.0731, p-value I tried ks.boot (package "Matching") that claims to work for two.sample tests with ties and "provides correct coverage even when the distributions being compared are not entirely continuous." Same story. I get exact p-values for one-sided conditions only. For instanche: ks.boot (black, red, alternative="l") $ks.boot.pvalue [1] 0.001 $ks Two-sample Kolmogorov-Smirnov test data: Tr and Co D^- = 0.0275, p-value = 0.0005651 alternative hypothesis: the CDF of x lies below that of y $nboots [1] 1000 attr(,"class") [1] "ks.boot" Did I missunderstand the sentence "exact p-values are not available for the two-sample case if one-sided or in the presence of ties?" I thought the sense was: No exact p-value if one-sided or ... Are the p-values of ks.test (two.sample, one sided) "correct"? In terms of delivering exact p-values ks.boot was not superior. Can anybody please comment on this? Thanks Hermann @Roland My problem: "Exact p-values are not available for the two-sample case if one-sided or in the presence of ties" (ks.test). Maybe I was confused by the term "exact" that is defined by (statistic) methods. But I get "precise" (in the sense of a precise number) p-values for the one-sided but not for the two-sided test ... ks.test (black, red, alternative="g")$p.value # one-sided [1] 1.235537e-23 # precise p-value Warnmeldung: In ks.test(black, red, alternative = "g") : im Falle von Bindungen sind die p-Werte approximativ ks.test(black, red)$p.value # two.sided [1] 0 # Is this precise? The most "precise" p-value (ks.test, two.sided) ... ks.test (black, red) Two-sample Kolmogorov-Smirnov test data: black and red D = 0.0731, p-value I was confused a p-value of 0 is reported if there is a p.value But this does not explain the different behaviour according to the reported p-values. I get a "precise" (approximative) p.value for one-sided but not for two-sided ... Due to statistical reasons? Further, I dont get an "precise" p-value for the two.sided ks.boot neither (that should be "exact"). It is ks.boot (black, red) $ks.boot.pvalue [1] 0 # no ks.boot.pvalue reported $ks Two-sample Kolmogorov-Smirnov test data: Tr and Co D = 0.0731, p-value Are "precise" p-values (ks.boot) only reported for one.sided conditions? Thanks Hermann
