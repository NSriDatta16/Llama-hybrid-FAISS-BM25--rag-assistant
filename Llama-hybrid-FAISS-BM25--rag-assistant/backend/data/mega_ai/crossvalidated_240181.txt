[site]: crossvalidated
[post_id]: 240181
[parent_id]: 240179
[tags]: 
To begin with, as you state, the suggested alternative throws away information about the sizes. So, for example, say the ordinal variable takes values in $\{0, 1, 2, 3, 4, 5\}$. Furthermore, say there were 1,000,000 samples with 2 as the independent value, where the dependent value tended to be 0. 1,000,000 samples with 3 as the independent value, where the dependent value tended to be 1. A single value each for ${0, 1}$ as the independent variable, where the dependent value was 1. A single value each for ${4, 5}$ as the independent variable, where the dependent value was 0. A linear predictor (at least an unweighted one) over the aggregation for each value of the independent variable, would not recognize that that the linear function should be ascending, which doesn't make sense when considering the problem. Another thing to note is that there's a fundamental difference between logistic regression and linear regression over the aggregates. Logistic regression, finds a classification with a linear boundary between the two classes. Linear regression over the aggregates finds the best fit mapping an increase in the independent variable to a linear increase in the probability of obtaining a specific class in the dependent variable. These two things are not the same. In fact, if the point is to find the significance of a linear boundary (which is what logistic regression does), it can be found more directly. Say the ordinal variable takes a small number $m$ of values. For each of the possible $m - 1$ possible threshold values for $t$, divide the dependent variable into two sets depending on whether the corresponding independent variable is below or above $t$, and run a Mann-Whitney test . For the best threshold, say the significance of the Mann-Whitney test was $\alpha$. Using the Bonferroni correction justification , you can claim the significance is at least $\frac{\alpha}{m - 1}$.
