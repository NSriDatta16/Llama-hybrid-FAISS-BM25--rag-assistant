[site]: crossvalidated
[post_id]: 317447
[parent_id]: 317446
[tags]: 
$y_{score}$ is the continuous output of your classifier. In this case it sounds like the CNN is outputting a softmax, so it's just the value of the softmax at the class you are interested in. I think there's some confusion. The ROC curve represents a continuum of thresholds. It makes no sense to request an ROC curve for a single threshold, because that just corresponds to a single point in ROC space (TP,FP). On the other hand, the AUC is independent of threshold: it's the probability (with respect to your data distribution) that a positive class will rank above a negative class. This is the same regardless of threshold, since it references ground truth positive and negative, as opposed to predicted. If you want to examine the TP,FP rates of each threshold, then you can make the call: fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score) which will return vectors of false positive rates, true positive rates and corresponding thresholds.
