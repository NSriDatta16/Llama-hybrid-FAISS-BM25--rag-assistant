[site]: crossvalidated
[post_id]: 281786
[parent_id]: 281644
[tags]: 
I agree with your colleague. Fitting MLE's to each experiment will always yield a likelihood greater than or equal to the model with a common probability of heads, so you need to account for this somehow. You are comparing models with different sized parameter spaces. You have 2 parameters to fit in the first one, and only 1 in the second. Therefore, you need to account for the inevitable increase in likelihood gained by the extra degrees of freedom. There are a few common approaches: AIC BIC Penalized likelihood (in general) Bayesian inference with a prior over the two options. Of course, what if $p_1 = p_2 + \epsilon, \; |\epsilon|\ll p_2$ You are ruling out this possibility in your approach, but you may not care. Whether or not it is "correct" depends on how sensitive you want your test to be. The nice thing about (4) is you automatically get $\Lambda$ due to the fact that Bayesian inference works with probabilities.
