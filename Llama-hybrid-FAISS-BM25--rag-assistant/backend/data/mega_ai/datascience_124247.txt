[site]: datascience
[post_id]: 124247
[parent_id]: 
[tags]: 
How Can I Train a Real-World-Ready Classifier with Limited Real Data and Abundant Open-Source Data?

I am trying to train a text classifier with open-source data to generalize on the real user traffic (henceforth "real data"). However, even though I have many annotated open-source data, I have only a few hundred real data. I know the best way to generalize to the user traffic is by training a model with such data. However, given the scarcity of real data, it does not make sense to do so (I am aware that this may be possible with LLMs like LLaMA2, but I hope to work with BERT-like small models). My idea is to train a model using open-source data (without training on the real data) that performs well on the real data, likely through some sort of regularization or constrained optimization on the real data. However, I am not sure what options I have. Could anyone provide me with some pointers? Thank you!
