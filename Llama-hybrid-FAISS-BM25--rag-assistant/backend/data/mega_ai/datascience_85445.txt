[site]: datascience
[post_id]: 85445
[parent_id]: 85338
[tags]: 
I've used such a method to remove tokenized words in a TFIDF NLP transformer that were very infrequent. In my case these words were mostly spelling mistakes or random characters that I didn't want to track as features. Basically you can run numpy.count_nonzero on every column & if it returns a number that's less than some threshold (say 1 or 2) you can run pandas.DataFrame.drop on that column.
