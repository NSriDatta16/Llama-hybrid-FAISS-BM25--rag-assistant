[site]: crossvalidated
[post_id]: 297181
[parent_id]: 297165
[tags]: 
You are calculating V(s) and your loss function using the data in slightly different ways. Most importantly your loss function sums loss once per sample transition, whilst V(s) is using the transitions in more complex ratios. By using the sample transitions to build an MDP and resolve V(s), you will on average have trajectories visiting state 1 always, state 2 $\frac{1}{3}$ of the time, and state 5 $\frac{1}{2}$ of the time. These ratios need to form part of your loss calculation, because if this were a sampled supervised learning dataset, then they would occur with that frequency - if you do this you should find that the values you calculate do indeed minimise a weighted MSE. More concretely, for a fair comparison between your loss calculation from samples and the state values you have estimated, you should define total loss as: $$L = \sum_{i=i}^{N} \frac{\rho_{MDP}(s_i)}{\rho_{N}(s_i)} (V(s_i) - (V(s'_i)+r_i))^2$$ Where $\rho_{MDP}(s_i)$ is the expected frequency of steps that start in state $S$ resulting from your MDP reconstruction to calculate $V(s_i)$, and $\rho_{N}(s_i)$ is the observed frequency of that start state in the sample set. This formula will tend towards the MSE loss that you were expecting to see, as you take larger, more representative sample sizes.
