[site]: crossvalidated
[post_id]: 558503
[parent_id]: 
[tags]: 
Does bootstrapping artificially create significance?

I'm trying to calculate a p-value for two samples and am having some issues understanding the role bootstrapping might play. The data I have comes from an MRMC study: Five readers took a five-hundred question test creating five accuracy scores to form sample 1. Some time later, the same five readers took the same test, but this time with a suggested answer list. The five accuracy scores on the test the second time form sample 2. My understanding is that a paired t-test would be the way to evaluate if the difference in average accuracy between the two conditions was significant or not. (Although I have heard that perhaps doing something like a repeated measures ANOVA might be better?)enter code here My question is that sample 1 and sample 2 only give me 1 value for difference in average accuracy. I could bootstrap with replacement to get more samples, but this seems like it would artificially create significance? For example, if I bootstrapped 10M times over the data I have the average difference of these paired samples would be pretty much the difference in the average of sample 1 and sample 2. Is there a best practice for using bootstrapping with the paired t-test or should I be looking to use some other methodology entirely?
