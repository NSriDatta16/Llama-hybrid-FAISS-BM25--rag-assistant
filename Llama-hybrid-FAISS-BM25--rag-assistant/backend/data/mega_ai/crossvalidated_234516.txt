[site]: crossvalidated
[post_id]: 234516
[parent_id]: 234396
[tags]: 
The paper On the Learnability of the Uncomputable showes that machine learning is not estimating programs in a very surprising direction. It shows how to pac learn the halting problem . The halting problem is not computable, and therefore there is no program that can compute it. The way to learn it is simple - take a large enough sample of programs that halt. Compute a threshold high enough so most programs halt before it. When having to classify a new sample run it until the threshold and see if it halts. I think that this paper shouldn't be interpreted as showing that we can learn what we cannot compute. Instead, in alerts on the problem in the PAC framework. We assume that if we have samples, we can learn. In the case of the halting problem, we cannot get such samples (in general). Without extra knowledge we won't know which of the programs will eventually halt so we can run time until they end. In the other direction, formal treatment of machine learning usually assume that the concept belong to some hypothesis set of a mathematical nature. Usually most concept discussed belong to much simpler hypothesis classes than programs. The reason to that is that we have negative results about the learnability for already when the concept is less complex than a program. For examples see " Cryptographic limitations on learning boolean formulae and finite automata "
