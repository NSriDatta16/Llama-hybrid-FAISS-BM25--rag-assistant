[site]: crossvalidated
[post_id]: 578453
[parent_id]: 
[tags]: 
How to show that adding more data improve a model quality?

I am working on a project for university and I would like to demonstrate that adding more rows to the same model (linear regressions for instance or other types of models) increase the model quality. By quality I mean it would overfit less, and generalize better. For the first dataset I have around 180 rows, while the second dataset contains around 1400 rows (additional rows were generated through various methods and are similar up to 70% to the initial dataset). When I train a simple linear regression model (with OLS). I get better results on the smaller model than the second with more data. I was thinking that the error was smaller because there was less rows (computing average error for 180 rows will probably give a lower error than computing it for 1400 rows). Although the second model with more data is theoretically better, how I can measure its quality ? (I tried using AIC and BIC but they are much lower in the model with less data).
