[site]: crossvalidated
[post_id]: 504336
[parent_id]: 504325
[tags]: 
"Is this normal?" I don't use this software, and I'm not sure what you mean by "normal," but nothing jumps out at me. A few thoughts: Asymptotic distributions of MLE estimates have a variance term that is the reciprocal of the Fisher Information. This means, roughly, that you get wider confidence intervals when the likelihood surface is "flatter" or "less pinched" on average. This has connections with how identifiable a model is. In other words, not all SSMs are created equally. I always think about how much I could pare down a model by removing a parameter or two, and if that would make a difference. I'm not sure how you're calculating these intervals, but it's all just food for thought. Asymptotics only apply when your data set is large enough. Your data might not be large enough to justify these kind of confidence intervals. In this case, I'd recommend either collecting more data, or transforming the parameter space so that MLE distributions become more normal. You could start off by estimating $\log \sigma^2$ or $\log \sigma$ instead of $\sigma^2$ . If you exponentiate that parameter estimate, that would give you the estimate of $\sigma^2$ , by the invariance principle. This would also free you from having to specify lower bounds for your algorithm. You're talking about percentage errors, which seems like you're interested in estimating $\sigma^2/ \mu$ . You can do this with standard MLE theory, as well, using the invariance property again, and getting confidence intervals using the delta method, etc. Try plotting profile log-likelihoods. Hold one of the three parameters fixed, simulate only one data set, and see if this surface looks flat at the top.
