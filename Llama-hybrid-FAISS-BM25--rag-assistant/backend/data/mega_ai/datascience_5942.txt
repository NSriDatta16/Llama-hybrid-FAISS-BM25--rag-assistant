[site]: datascience
[post_id]: 5942
[parent_id]: 5875
[tags]: 
You can perform logistic regression (if your dependent variable has two classes) that penalizes based on the L1 norm. You can choose the correct sparsity parameter (typically $\lambda$) that chooses how strongly to seek sparsity based on cross-validation. The model will force many non-informative features to be 0. This is a form of feature selection. See here: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
