[site]: crossvalidated
[post_id]: 637264
[parent_id]: 
[tags]: 
Relation between gini coefficient/accuracy ratio and roc_auc_score when there are many identical predictions

I have been working on ranking metrics related to various estimators lately, and cam a across a curious phenomenon related to the Gini-coefficient which I would like to understand better. I will start with some Python-snippets to illustrate the context and phenomenon. Let us say way have a set of predictions and a set of targets related to a binary classifier (i'll just generate junk-data here since my question is purely related to the metrics): import random target=[random.randint(0,1) for _ in range(0,100)] pred=[random.uniform(0,1) for _ in range(0,100)] Using the implementation below (taken from https://www.kaggle.com/code/batzner/gini-coefficient-an-intuitive-explanation ) def gini(actual, pred, cmpcol = 0, sortcol = 1): assert( len(actual) == len(pred) ) all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float) all = all[ np.lexsort((all[:,2], -1*all[:,1])) ] totalLosses = all[:,0].sum() giniSum = all[:,0].cumsum().sum() / totalLosses giniSum -= (len(actual) + 1) / 2. return giniSum / len(actual) def gini_normalized(a, p): return gini(a, p) / gini(a, a) we easily verify the classical result that from sklearn.metrics import roc_auc_score >>> roc_auc_score(target,pred)*2-1 0.1347402597402596 >>> gini_normalized(target,pred) 0.13474025974025977 This conforms to known theory. However, when a significant number of our predictions are identical - but correspond to different targets - it appears that we no longer have the correspondence above. Rather it appears that the roc_auc_score becomes equals to the average of the normalized gini over all possible ways to permute pred and target in such a way that pred will be sorted in ascending order by our permutation. Let my illustrate by a few examples >>> gini_normalized([0,0,1],[0.1,0.9,0.9]) 0.0 >>> gini_normalized([0,1,0],[0.1,0.9,0.9]) 1.0 >>> roc_auc_score([0,1,0],[0.1,0.9,0.9])*2-1 0.5 >>> gini_normalized([0,1,0,1,0,0],[0.5,0.7,0.1,0.9,0.9,0.9]) 0.5 >>> gini_normalized([0,1,0,0,1,0],[0.5,0.7,0.1,0.9,0.9,0.9]) 0.25 >>> gini_normalized([0,1,0,0,0,1],[0.5,0.7,0.1,0.9,0.9,0.9]) 0.0 >>> roc_auc_score([0,1,0,0,1,0],[0.5,0.7,0.1,0.9,0.9,0.9])*2-1 0.25 >>> roc_auc_score([0,1,0,1,0,0],[0.5,0.7,0.1,0.9,0.9,0.9])*2-1 0.25 >>> roc_auc_score([0,1,0,0,0,1],[0.5,0.7,0.1,0.9,0.9,0.9])*2-1 0.25 In light of these observations I would be very interested in hearing any answers/thoughts related to the following questions: Is my hypothesis correct, that is does it hold in general that the roc_auc_score is equal to the average of the gini-coefficients where we average over ways to sort pred? If this is correct that how do we define the gini-coefficient in this case ? Which way of sorting do we use, or is the gini coefficient in fact defined as the average ? Similarly I would be curious to know how we define the cumulative accuracy profile and the accuracy ratio in the situation where there are several possible ways to sort (the accuracy ratio appears to just be an alternative definition of the gini coefficient). Does anybody know of a reference (or even better a derivation) of the above relationsship - if turns out to be correct?
