[site]: crossvalidated
[post_id]: 360880
[parent_id]: 
[tags]: 
ML for optimizing manufacturing tool programming

I work with some folks who program a rather complex tool that uses a pair of motion systems and a controllable light source to do some material processing. In general it does a pretty good job by just programming it "directly", as in ask it to draw a rectangle 20 units by 30 units with radiused corners of 5 units. It does OK but if you are to get the maximum performance out of the machine, we have found that there are many "tricks" that we can do to make it work better. You do multiple passes, vary power, cut shapes slightly different sizes, you reprogram the motion parameters, in order to get a machine that was +/- 2 units to one that is +/- 0.2 units. So the team working on this has rules of thumb and preferred alogorithms that they have come up with. I can't help but want to use some form of machine learning for this application, but based on my limited experience it seems like a genetic algorithm will be best to solve this based on work I did in school years ago. To scale the problem I can see perhaps 10-15 variables driving this with a range of 2-10 "states" each. This state space has millions of states and I can test about 1000/day. Is the path on this GA or should I be looking at other (newer) tools?
