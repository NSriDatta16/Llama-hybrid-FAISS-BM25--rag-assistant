[site]: datascience
[post_id]: 106993
[parent_id]: 106987
[tags]: 
It all depends on the data variability. If the time series are too variable between each other in terms of raw values, you might not see any meaningful cluster. That's why you will want to transform the data to make the times series more comparable. A first step would be to have relative values instead of absolute values if you want to detect behavioral patterns. Then, it is always recommended to normalize data. Without normalization, the gaussian functions behind the t-SNE algorithm would not segregate the small and the big values the same way and it could lead to more variability (= no clear cluster). In addition to that, if the variability is too high in terms of raw value, it could be interesting to apply a log, but be aware that there would be precision loss, which is generally not critical as you only want to visualize data in a lower dimension. Finally, if the time series are too long (100 could be the case), and T-SNE can't detect visible similarities between sensors, you should simplify the data by applying mean values between 2 or more consecutive values. Please keep in mind that t-SNE is mainly usefull when you have many variables (ex: comparing 50 engines having 9 sensors with 100 values each, and you want to lower those 9 sensors to 2 dimensions) that you want to visualize to detect similarities or differences. My last advice is to start with one important sensor first before considering more sensors. As soon as you reach interesting result with one sensor, you can increase complexity with more sensors. Alternatively, you can apply UMAP: it has the benefit to make correlations between clusters, no normalization is needed, but the result might be worse than t-SNE between individual points in the lower dimension. A correlation study between sensors can be interesting: some sensors with no or low correlation, or too noisy, could be discarded. In conclusion, data preprocessing is crucial and depends on the algorithm you use, but always start with smaller datasets that you can evaluate the result quality, before considering the whole datasets.
