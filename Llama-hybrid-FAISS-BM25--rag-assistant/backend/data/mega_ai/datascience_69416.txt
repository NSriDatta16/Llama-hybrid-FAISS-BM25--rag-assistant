[site]: datascience
[post_id]: 69416
[parent_id]: 69411
[tags]: 
You should at least try pre-trained embedding vectors. TfidVectorizer is particularly sensitive to out-of-vocabulary words, which are likely to appear if you're trying transfer learning to a new domain. The GloVe embeddings [1] have a dictionary of 400k vectors, unless you're working with documents from a technical domain they should provide some improvement. Also, consider to perform some extra feature engineering, words by themselves do not provide much information. Why not trying adding n-grams & dependencies extraction, entity recognition, etc. as preprocessing steps? [1] http://nlp.stanford.edu/projects/glove/
