[site]: crossvalidated
[post_id]: 85842
[parent_id]: 85835
[tags]: 
1) Your question requests for clarification removed - it's now dealt with in the question ]> Any additional information you can give about what you're trying to find out may help. 2) The Signed Rank Test The Wilcoxon signed rank test assumes symmetry under the null, and its really only a test for the median when that symmetry holds (it's actually a test for the median of pairwise averages, but with symmetry, the population quantity that converges to - the pseudo-median - will coincide with the population median). You don't have symmetry. A sign test actually is a test for medians and doesn't assume symmetry. But if you want your inference to be about means that doesn't help you. 3) Skewness and the t-test Your risk isn't just a type II error. High skewness affects the type I error rate, and can produce a biased test (that is, a test with power lower than $\alpha$ when $H_0$ is false). So you aren't doing the test at the significance level you think you are, for starters. 4) Other suggestions (a) Your data are skew, so the obvious thing to do is use a model for skewed data. This is easily accomplished by a simple GLM of the form $E(y)=\mu$ (e.g. in R, a model fitted with the formula y~1 ). GLMs give a variety of possible skewed models, and are explicitly models for the mean. The obvious first choice is gamma-family, but there are others if that's not suitable (inverse Gaussian is more skew, for example) Here's an example, done in R. The data: 0.8347 0.9837 0.8740 0.8471 0.8251 1.0461 0.7796 0.8302 0.9559 0.7557 0.8850 0.8695 0.9451 0.8436 0.8216 0.8431 0.7182 0.8753 0.7793 0.7483 First, here's what the data look like (this is a kernel density estimate with a rugplot): Now for the hypothesis test that the mean is 1, done via GLM (some output omitted): > summary(glm(y~1,family=Gamma(link="identity"))) Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 0.85305 0.01835 46.49 Then the t-statistic we want would be (0.85305-1)/0.01835 = -8.008 (the values used in that calculation come from the line labelled "(Intercept)", and the null hypothesis) You can even do it all directly in GLM through use of an offset: > mu0=rep(1,length(y)) > summary(glm(y~1+offset(mu0),family=Gamma(link="identity"))) Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -0.14695 0.01835 -8.01 1.65e-07 *** (Dispersion parameter for Gamma family taken to be 0.009251426) Null deviance: 0.17154 on 19 degrees of freedom Residual deviance: 0.17154 on 19 degrees of freedom And now the t-value and the p-value for the test are right there in the output. (in this case, the data are not actually gamma distributed, but it's pretty close, and the test should give excellent results.) (b) Perhaps a resampling-based test, such as seeing whether a bootstrap confidence interval for the mean includes 1. bootmean=replicate(10000,mean(sample(y,20,replace=TRUE))) # bootstrap plot(density(bootmean),xlim=c(0.76,1)) # draw a smoothed density, include 1 on axis rug(bootmean,col=8) # mark bootstrapped mean values in gray rug(quantile(bootmean,p=c(.025,.975)),col=2,lwd=2) # mark on 95% CI limits in red abline(v=1,lty=2,col="green3") # draw H0 value Here's the plot: Clearly, the null is rejected here as well.
