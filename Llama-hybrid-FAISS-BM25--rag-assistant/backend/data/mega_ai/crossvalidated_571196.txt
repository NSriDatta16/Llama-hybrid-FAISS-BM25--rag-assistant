[site]: crossvalidated
[post_id]: 571196
[parent_id]: 
[tags]: 
My random forrest regressor was overfitting so I tried to use randomsearchcv but I still got a worse result, what should I change?

I tried to fix my overfitting with randomized search cross-validation. These are my params: I set 100 estimators but that is irrelevant for the overfitting. I read log2 was best for regressors somewhere. I am not sure about max depth being correct I found that number somewhere on stack exchange saying it was good. I set 5,8 and 3,6 because in min_samples_split and min_samples_leaf as I saw online that the larger they were the closest they would be to overfitting but ofcourse the lower they are the more they will underfit so is this what I should change? In terms of performance, this one is worse compared to the time I did not use cross-validation. When I used random forest regressor (n=100) with default settings it also behaved badly (has a negative r^2 score) with the validation data but at least with the training data, it has an r^2 score of 60. I know I shouldn't test it with training data but I used it as proof of overfitting. This code I have below neither performs well(has a negative r^2 score) on the validation data nor on the training data, i.e this is proof for me it is under-fitted. What should I do to fix this? import sklearn from sklearn.ensemble import RandomForestRegressor import numpy as np from sklearn.model_selection import RandomizedSearchCV from sklearn.utils import shuffle #[32..features]: x=(1474277, 34) y=(1474277, 1) X, Y = shuffle(x, y, random_state=0) print("x=",np.shape(X)," y;",np.shape(Y)) # Number of trees in random forest n_estimators = [100] # Number of features to consider at every split max_features = ['log2'] # Maximum number of levels in tree max_depth = [5,6,7,8] # Minimum number of samples required to split a node min_samples_split = [5, 8] # Minimum number of samples required at each leaf node min_samples_leaf = [3, 6] # Method of selecting samples for training each tree bootstrap = [True] # Create the random grid random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap} print(random_grid) rf = RandomForestRegressor() Reg = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 16,n_jobs=-1, random_state=42) print("done") print(Reg.best_params_) output of Reg.best_params: {'n_estimators': 100, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 8, 'bootstrap': True}
