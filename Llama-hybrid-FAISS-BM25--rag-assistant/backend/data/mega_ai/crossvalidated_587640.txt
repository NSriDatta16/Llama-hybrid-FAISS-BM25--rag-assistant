[site]: crossvalidated
[post_id]: 587640
[parent_id]: 
[tags]: 
modeling time between calls with exponential distribution

I've read that time between calls (in a call center) can be modeled with exponential distribution. My question is this: the shape of the exponential distribution has a decreasing nature. Suppose that there are 6 calls at average in an hour. In this case, according to my intuition, the highest probability for the next call to happen (after a call) should be 10 minutes. Any time smaller than 10 minutes should have a lower probability compared to 10 minutes. So, the shape of the distribution should not be decreasing but should be something like achieving its highest value around 10. I would be glad if you point out what is wrong in my reasoning.
