[site]: crossvalidated
[post_id]: 459298
[parent_id]: 
[tags]: 
How to generalize shrinkage to fully-bayesian models?

I've got a time series that I'm modelling as an exponential; growth rate, with the rate following a logistic distribution: $$ y_t = e^{x_t r_t} $$ where $$ r_t = \frac{L}{1-e^{-k(x_t-x_0)}} $$ I've got priors on $L$ , $k$ , and $x_0$ , and they're distributed $\beta$ , $\Gamma_1$ , and $\Gamma_2$ , respectively. I fit the model using Metropolis-Hastings/MCMC. I get a good fit to observed data. Here's the problem: when I try to validate it by holding out a few most recent days of data to see how well it does predictively, it becomes apparent that I'm overfitting horribly. If I were doing this in a frequentist context, I'd just do a gridsearch over the parameters using look-forward cross validation. But that doesn't work for two reasons: I need credible intervals By definition, my problem is non-stationary. So, how do I control the bias/variance tradeoff in a bayesian context? I had an idea that I could add a criterion in the MH algorithm that requires a proposed position to fit both the past (training) set and the future (holdout set). But that feels like polluting the training set with the testing set. I'd appreciate ideas and references if this is a standard/solved problem.
