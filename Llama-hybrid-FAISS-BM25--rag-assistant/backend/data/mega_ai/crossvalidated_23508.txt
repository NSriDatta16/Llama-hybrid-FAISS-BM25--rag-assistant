[site]: crossvalidated
[post_id]: 23508
[parent_id]: 23507
[tags]: 
(This really is a real question I'm facing and the ML StackExchange site going live was pretty much perfect timing: I'd done a few days of book reading and online research and was about to start implementing. Here are my results. Although they aren't rigorous I think they do answer my own question. I shall leave the question open for now in-case anyone has any useful input, has tried something similar, or have some useful references.) Okay over the past couple of days I've coded this up. The code is not very efficient - lots of collection creation & copying, but the object of the exercise was to see if it would work, and how well it works. I am splitting my data randomly into two lists: training data, and test data. I am running the test data through the conventional Maximum Entropy POS Tagger; and my new MEMM tagger. Hence they see the same test data, allowing direct comparisons - due to the randomness in the data being chosen, I see some variation between tests (typically about 0.2-0.4%). First test uses an MEMM tagger with a single stage (ie. a true Markov Chain). This consistently performed better than the simple ME tagger by about 0.1-0.25%. Next I tried the two stage approach which seems like it should be more correct. However the results were even more marginal. Often the results would be identical, occasionally it would be slightly inferior, but probably a majority of times it was slightly better (so +/-0.05%). The MEMM tagger is slow. Okay I haven't applied any optimizations, but the 1 stage (true Markov Chain) is N times slower (where N = Number of labels) because this is the number of paths which are transferred between each step. The 2 stage implementation is N*N slower (because of the greater number of paths transferred). Although optimizations might improve things, I this is probably too slow for most practical applications. One thing I am trying is to apply a lower probability limit to the paths. Ie. the Viterbi paths are pruned during each iteration with all paths below a certain probability (currently Log(total path P) Why do we not see any improvement? I think this is primarily due to the way POS tags behave and the Maximum Entropy model. Although the model takes features based on the previous two tags, the immediate previous tag is much more important compared to the one before it. Intuitively this would make sense for the English language (eg. an adjective is usually followed by a noun or an another adjective but this doesn't really depend on what was before the adjective).
