[site]: crossvalidated
[post_id]: 604428
[parent_id]: 604421
[tags]: 
If you want to use the decoder as a generative model, you can theoretically input random vectors and force it to generate an image (this is what the generator in a GAN does). But that would cause, in the best case, that the model will only work for specific random vectors. If you just not use the encoder you're basically generating 2 random vectors which output two different images. What happens if you take 2 very similar images in the training set, the same image rotated by 1 degree for example, and randomly generate two random vectors that are very far apart? Also think of the inverse case where you generate 2 infinitesimally close random vectors, but force them to generate very different images ( a white plane over blue skies and a black sheep in a green meadow). You are basically forcing the generative model to learn contradictory information and therefore hurting performance. The clever solution for that was the encoder. It allows the model to automatically constrain the random vectors so that similar inputs generate similar random vectors, thus allowing the decoder to learn much better. It also makes the latent space continuous so that for every random vector you get a pretty valid output. Hope it helps somewhat.
