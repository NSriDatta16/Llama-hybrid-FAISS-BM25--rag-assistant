[site]: crossvalidated
[post_id]: 192033
[parent_id]: 
[tags]: 
Understanding "we lose degrees of freedom in product deviations"?

I'm having a tricky time understanding the statement: we lose $n−1$ [degrees of freedom] by computing the product deviations [in $cov(x,y)$] I'm not necessarily looking for an overview of degrees of freedom, just an explicit pointer to grasp this claim. It comes from here. Full quote: You may be perplexed that we average the product deviations [in $cov(x,y)$] by dividing by $n−1$ rather than $n$. The best explanation is that in the probability model discussed below, the sample covariance is an unbiased estimator of the distribution covariance. However, the mode of averaging can also be understood in terms of degrees of freedom , as was done for sample variance. Initially, we have $2n$ degrees of freedom in the bivariate data. We lose two by computing the sample means $m(x)$ and $m(y)$. Of the remaining $2n−2$ degrees of freedom, we lose $n−1$ by computing the product deviations. Thus, we are left with $n−1$ degrees of freedom total. Thanks, if you can rephrase the claim to help with understanding?
