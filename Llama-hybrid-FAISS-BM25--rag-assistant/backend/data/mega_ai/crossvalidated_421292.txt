[site]: crossvalidated
[post_id]: 421292
[parent_id]: 
[tags]: 
James Stein Estimator for more than one Sample

I have a hard time understanding the James-Stein Estimator. I show you how I tried to comprehend it by using a python example. I take a normally distributed random vector with mean $(0.1, 0.2, 0.3, 0.15, 0.11, 0.87)$ and variance 1 for each vector component. Then I sample 20 data points and with these, I calculate the average for each vecor component, which is the maximum likelihood estimate. For the James Stein estimator, I use the formula mystein=(1-((len(mymean)-2)/(myMLE**2).sum()))*myMLE If the sample size, as in the example below, only rarely in 1000 simulation steps, the James-Stein estimator outperforms the Maximum Likelihood estimator. If I sample only 1 datapoint as in most examples I found, it does. I might fundamentally misunderstand something, but I don't know what. import numpy as np check = [] for i in range (0, 1000): np.random.seed(i) mymean = [0.1, 0.2, 0.3, 0.15, 0.11, 0.87] cov = [[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]] a, b, c, d, e, f = np.random.multivariate_normal(mymean, cov, 20).T myX=np.array([a,b,c,d,e,f]) myMLE=myX.mean(axis=1) mystein=(1-((len(mymean)-2)/(myMLE**2).sum()))*myMLE err_y=((myMLE-mymean)**2).sum() err_js=((mystein-mymean)**2).sum() check.append((err_js
