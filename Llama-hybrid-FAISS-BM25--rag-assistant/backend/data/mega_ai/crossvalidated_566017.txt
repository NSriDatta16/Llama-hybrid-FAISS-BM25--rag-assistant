[site]: crossvalidated
[post_id]: 566017
[parent_id]: 
[tags]: 
How to combine stratified sampling and avoid common driver in both training & test set - R Cross-Validation

I want to build a random forest or gradient boosting model on very heterogeneous data using cross-validation in R. Due to data heterogeneity and dependency between the observation (the same subject ID can be found multiple time in the observations), I am looking to use an algorithm that split the dataset into a training and testing set using stratified sampling (to minimize bias) and also that force same subject ID to fall within the one split set only (to avoid common driver in both dataset). Anyone knows how I can achieve that or that have alternative solution to achieve the same purpose? FYI, I'm using the caret R package. Thanks, John
