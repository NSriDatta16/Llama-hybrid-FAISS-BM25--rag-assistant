[site]: crossvalidated
[post_id]: 358921
[parent_id]: 358632
[tags]: 
RNN architectures are good at remembering previous time-steps along a sequence, because of the loops nature, allows information to persist. That's why if your data has temporal dependency it is a good approach to use them rather than using only dense layers which does not address these issues. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop [1]. If I understood correctly your dataset consist on a scalar number for each day for the last 100 days, right? I suggest then that your input data should has a shape of: [Batch_size, sequence_length, features] Where in your case features will be 1 and sequence_length is a parameter that will allow you to process the temporal dependence. On your specific problem would be: how much do you want to remember for your forecast prediction? 5 days? 100 days? This eventually is a hyperparameter that you will have to find. [1] http://colah.github.io/posts/2015-08-Understanding-LSTMs/
