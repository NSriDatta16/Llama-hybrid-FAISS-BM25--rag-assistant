[site]: crossvalidated
[post_id]: 502510
[parent_id]: 502301
[tags]: 
I seriously doubt the correctness of Zadrozny's conclusion. Her argument is not supported by any formal deliberations and only by one artificial example. So I can only try to interpret her logic. To answer your questions: How does the constraint that all examples in the training set are classified correctly imply that sample selection bias will not systematically affect the output of the optimisation? It does not, by itself. Zadrozny seems to consider it in combination with the maximum margin property of the SVMs, which implies that only the points on the margin determine the boundary. The logic is apparently that the selection bias in the vicinity of the class boundary is more-or-less constant, equally affecting both classes, and thus doesn't affect the boundary (much). In my opinion, this is a bold statement that calls for a formal proof. Furthermore, why is it necessary to assume that the selection probability is greater than zero for all $x$ ? It is not necessary , but, following Zadrozny's logic, should be sufficient : If all points have a non-zero probability to be selected, then the margin points also have a chance of being selected. On the other hand, if the selection probability is zero for $x$ around the true boundary, those points cannot be selected and the estimated class boundary will differ significantly from the true one. Again, I am not convinced and would prefer seeing a formal proof.
