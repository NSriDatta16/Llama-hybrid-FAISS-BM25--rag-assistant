[site]: crossvalidated
[post_id]: 460035
[parent_id]: 460008
[tags]: 
The procedure you've just described boils down to the sampling from a naive Bayes model of the underlying variables (features and labels). Thus, it is valid in the sense of having the described statistical properties with respect to the different frequencies of occurrences. However, I do wonder what the very first question is you try to answer here. Since you are talking about the creation of a training set, it seems(!) as if you head for some predictive model, which, for a given user, predicts the label from its features. If that's the case, then why taking a detour through the creation of a training set with naive Bayes properties, when you can directly construct a naive Bayes model(!) based on the statistical properties you already have? Every quantitiy you need for defining the probabilities of a naive Bayes Bayesian network is in place.
