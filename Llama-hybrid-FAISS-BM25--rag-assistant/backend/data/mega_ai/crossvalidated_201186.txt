[site]: crossvalidated
[post_id]: 201186
[parent_id]: 
[tags]: 
Bayes factor (B) vs p-values: sensitive (H0/H1) vs insensitive data

The question of a beginner in Bayesian stats. As far as I understand, it is claimed (e.g. Dienes 2014) that B-based inference allows us to either confidently reject/accept the null, OR declare the data to be inconclusive/insensitive based on conventional cut-off values for B; while a value of p>.05 can never really distinguish between the null being true and the data just not being sensitive enough. However, I don't really understand how analysing the data in terms of B gives us more confidence in rejecting/accepting H0 vs declaring the data to be inconclusive. How are the conventions for B (e.g. data is insensitive if B is between 1/3 and 3) any less arbitrary than if one were to define similar "inconclusiveness" conventions also for p-values, such as declaring as inconclusive data that gives p-values only a bit above alpha (e.g. between 0.05 and 0.10), i.e. essentially playing with the false-discovery (Type I error) rate? Also, can one really always drive B out of the "insensitive range" (e.g. 1/3 to 3) simply by making the data less insensitive i.e. by collecting more data i.e. by increasing N? I understand this is alright to do with B-based stats but not with p-based stats, although I don't understand why - assume you initially find the data to be insensitive using B-values, then add more data, then are able to reject/accept H0 - say you then added even more data, and this leads to a new B-value whereby the opposite conclusion is drawn about H0. How is that acceptable/good practice?
