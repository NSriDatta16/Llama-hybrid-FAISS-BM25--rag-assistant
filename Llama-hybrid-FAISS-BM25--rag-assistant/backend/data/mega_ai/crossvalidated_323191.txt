[site]: crossvalidated
[post_id]: 323191
[parent_id]: 
[tags]: 
Adding data to change SVM classification

I have worked with SVMs in the past and I consider myself quite familiar with their main aspects. But an answer in here surprised me quite a bit. The original poster asked for a simple case of separating 4 2-d points in 2 classes: points were: [ 0,0 ], [ 0,1 ], [ 1,0 ], [ 1,1 ] and labels were: [ -1, -1, -1, 1 ] . The problem was that with the default parameters and linear model it did not separate the data correctly. A proposed method was to add more data to the dataset. The funny thing is that the data added was just an exact replicate of the original 4 points. 5 times to be precise. So, the data became: [ 0,0 ], [ 0,1 ], [ 1,0 ], [ 1,1 ], [ 0,0 ], [ 0,1 ], [ 1,0 ], [ 1,1 ], [ 0,0 ], [ 0,1 ], [ 1,0 ], [ 1,1 ], [ 0,0 ], [ 0,1 ], [ 1,0 ], [ 1,1 ], [ 0,0 ], [ 0,1 ], [ 1,0 ], [ 1,1 ] with the corresponding labels also quintupled. My question is whether should this work in SVM in general. I found it wrong (as a solution) as I consider adding data that does not provide new discrimination values could not affect the result. In this implementation it does affect it though. So, is this consistent with theory or is it an implementation issue? What am I missing here? P.S. The implementation is in python, sklearn.svm to be precise if it's of any concern.
