[site]: datascience
[post_id]: 86418
[parent_id]: 66732
[tags]: 
Sometimes, when you have important categories in your population it is best to split the data set by catégories and train different model on them. This might be some way to go if you really have different populations and different associated behaviour. This might be helpful to avoid some category imbalance problems. However this might not be practical as you would have to tune multiple models. Regarding xgboost, it is designated to handle important data sets rapidly. It’s usually not desirable to try to influence the learning process to choose what feature it will pick first. If you have one feature that it should pick first because of expert knowledge but it doesn’t : look what feature are above in term of importance and if there might be a problem with them. try to improve your feature with feature engineering.
