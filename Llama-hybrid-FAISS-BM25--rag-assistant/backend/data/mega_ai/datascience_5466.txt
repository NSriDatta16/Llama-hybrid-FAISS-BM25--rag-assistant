[site]: datascience
[post_id]: 5466
[parent_id]: 778
[tags]: 
I've been using Anaconda Python 3.4 and Pandas to search 10M row database to match 20K of login credentials. Takes about a minute. The pandas internals make great use of memory. That said, truly big data requires a processing architecture matched to the problem. Pandas is just the glue (logic) in this equation, and other tools can do this as well. R, Scala, Haskell, SAS, etc. can replicate some of the logic - perhaps just enough to answer questions faster. But python makes a good (best?) general-purpose tool. You can run R code in python, as well as most other languages. Although interpretive, there are high performance techniques and tools such as pypy that can make python run almost as fast as benchmark tools with only slightly more effort. And python has many libraries that do just about everything - see above list. If you are asking if you should learn and use python, my answer is yes Articles indicate that python is used more than R among people who use both. But few data science problems are solved by a single tool. It may become your go-to tool, but its only that - a tool. And just as no sane person builds a house with just a hammer, no sane Data Scientist uses just one tool.
