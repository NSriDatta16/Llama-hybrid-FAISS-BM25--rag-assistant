[site]: crossvalidated
[post_id]: 83397
[parent_id]: 83303
[tags]: 
and the above is what we do in Bayesian inference for parametric models, right? The book is using Bayesian model averaging, which is the same for parametric models or any other Bayesian method, given that you have posterior over your parameters. Now I have a noise-free training data set It doesn't need to be 'noise-free'. See later pages. HOWEVER, that's not what the book does! I mean, after specifying the prior p(f), it doesn't compute the likelihood and posterior, but just go straight forward to the predictive prediction. See this: https://people.cs.umass.edu/~wallach/talks/gp_intro.pdf I believe, in page 17 we have the prior, and later the likelihood. I believe if you write the derivations, and find the posterior, and then average over the posterior for prediction (like in the weight-space view) it will result in the same equations as in page 19 for mean and covariance.
