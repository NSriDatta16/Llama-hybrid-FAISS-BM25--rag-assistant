[site]: crossvalidated
[post_id]: 498758
[parent_id]: 
[tags]: 
Multiple line decision boundary in neural networks

I understand that in a neural network with no hidden layers where the output is the sigmoid function applied to a weighted sum of the inputs that the decision boundary will be a line. I do not understand how when we have for example two hidden units why the decision boundary becomes two lines. For the decision boundary to be two lines this implies that the decision boundary is not even a function of the two inputs however I feel like we should be able to work backwards to get a decision boundary that is a function of the inputs. Can someone help work me through the math so that I can see that the decision boundary for a neural network with two hidden units is actually two lines?
