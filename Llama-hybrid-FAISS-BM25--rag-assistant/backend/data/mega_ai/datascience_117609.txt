[site]: datascience
[post_id]: 117609
[parent_id]: 
[tags]: 
Why to Train Q-function in Reinforcement Learning?

I am recently learning RL. I see most algorithms are to estimate the Q function. I would like to know why not simply train a model that takes current states as input and outputs actions. Take ANN for example. Perhaps we can record the action taken and calculate discounted awards for every iteration, and let the optimizer adjust weight of the ANN model. Is this impossible? Why or Why is fitting the Q function better?
