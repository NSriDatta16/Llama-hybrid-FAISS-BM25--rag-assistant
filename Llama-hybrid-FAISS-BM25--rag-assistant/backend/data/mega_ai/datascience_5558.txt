[site]: datascience
[post_id]: 5558
[parent_id]: 
[tags]: 
Finding frequencies in a noisy, "uneven" dataset

I'm working on a problem where frequency analysis applies (decomposition of a signal into frequencies, that is), but it's noisy and the samples are unevenly spaced. Specifically: given a list of items purchased at a bar/restaurant, try to estimate the number of guests on the check based on distinct "frequencies" of purchase. The logic is that if there are N guests on a check, then it's reasonable to see N frequencies of drinks being purchased, one person buying every 10 minutes, another every 15, etc. (Plenty of other properties of the check should be included, but here I'm focusing specifically on estimating distinct frequencies). So more formally: given a noisy, unevenly spaced time series, find the smallest number of frequencies which reproduce the signal while minimizing the error (... for some sensible definition of how to minimize both the error and the number of frequencies simultaneously). This is more a machine learning problem than signal processing. I realize it's also an open question, but can anyone point me in the right direction? Is there a particular method or algorithm that applies here?
