[site]: crossvalidated
[post_id]: 576524
[parent_id]: 347918
[tags]: 
Firstly, I completely understand the temptation to do this. You want your model assumptions to be defensible and your model to be valid out-of-sample. The issue is: this is not Bayesian inference. This is regularization using Bayes theorem. That isn't "good" or "bad." The answer to your titular question is yes absolutely. The only thing I would say is that there are probably better regularization methods that would be easier and equally valid under cross-validation. Bayesian priors are not validated, they are solicited. A prior reflects your preexisting beliefs. If you have to validate it, you didn't believe it in the first place and therefore it is not a genuine prior in the true sense of the term. The related technique of using secondary data sources to generate a prior that has been brought up is what is refereed to as "empirical" Bayes method, using a second separate date set to generate a prior. This works well for hierarchical models and for situations in which you have empirical prior knowledge you can call on. I don't see how this makes sense if you are taking one data set and splitting it into two specifically for that purpose. It begs the question why not perform inference on the whole data set with a subjective prior? If you're going to infer your prior from a subset of the data using Bayesian inference, that requires a non-empirical prior which you could just use on the entire data set (in other words, you're just splitting Bayesian inference into two unnecessary steps). If you are not using Bayesian inference to generate a prior, then you don't really believe in using Bayesian inference to solve your given problem in the first place. In that case, just use the method you really believe in on the entire data set. TLDR: if you don't have a prior belief you feel comfortable using, don't use Bayesian inference; just skip to the method you would use to generate the prior and use it across the board.
