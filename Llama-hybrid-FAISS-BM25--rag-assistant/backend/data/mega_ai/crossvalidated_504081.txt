[site]: crossvalidated
[post_id]: 504081
[parent_id]: 
[tags]: 
Is using more data in an analysis of variance inherently better?

I have a large data set (~50000 rows) with each row representing one hour of data. I want to know if more tags are detected based on equipment model used. The data represents 90 sites (each site recording a different number of hours), with 30 sites using each type of equipment model. Would it be better to run a model with all 50000 data points (the response variable being detections) or to group the data by site and run my analysis with the average hourly detections per site (the response variable being hits/hour)? And if the later is the case, how do I account for the different number of hours of detection per site?
