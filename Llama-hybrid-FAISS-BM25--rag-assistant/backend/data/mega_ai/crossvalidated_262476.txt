[site]: crossvalidated
[post_id]: 262476
[parent_id]: 
[tags]: 
How can LDA classification accuracy be higher when using fewer linear discriminants?

I'm trying to reduce a dataset with LDA . I expect that on reduced dataset (i.e. with fewer linear discriminants retained) I will have less classification accuracy. However, depending on the random seed, sometimes the reduced version is giving me higher accuracy. # N=1000, p=50, 10 out of 50 are informative, 20 classes X, y = make_classification(1000, 50, n_informative=10, n_classes=20) X1, X2, y1, y2 = train_test_split(X, y) lda = LDA() lda.fit(X1, y1) predicted = lda.predict(X2) full_accuracy = accuracy_score(y2, predicted) reduction = LDA(n_components=5) X1red = reduction.fit_transform(X1, y1) X2red = reduction.transform(X2) lda.fit(X1red, y1) predicted = lda.predict(X2red) reduced_accuracy = accuracy_score(predicted, y2) print full_accuracy, reduced_accuracy, reduced_accuracy/full_accuracy # prints 0.132 0.16 1.21212121212 Do you know why after dimensionality reduction I have higher accuracy?
