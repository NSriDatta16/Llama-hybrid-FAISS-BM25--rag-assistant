[site]: crossvalidated
[post_id]: 505628
[parent_id]: 
[tags]: 
Calculating the Fisher information matrix for implementing a policy-gradient algorithm

I am having difficulty implementing a reinforcement learning algorithm using a policy gradient approach, where the agent is a neural network. More specifically, I am having trouble calculating the 'natural gradient' which is the 'vanilla gradient' multiplied by the inverse of the Fisher information matrix. First, the vanilla gradient $g_{\rm van}$ is given by: $$ g_{\rm van} = E \left [ \sum_t R_t \frac{\partial }{\partial \theta} \log \pi_\theta(a_t|s_t) \right], $$ where $E$ denotes the expectation value (according to the policy $Ï€_\theta(a_t|s_t)$ ) and $R_t$ the return collected for the particular action sequence of actions and observations of the environment. The variables $\theta$ here are the weights and biases of the neural network (the agent in this problem), which consists of an input layer, two invisible layers, and an output layer (793, 300, 300, 21). The natural gradient is then defined as: $$ g_{\rm nat} = F^{-1} g_{\rm van}, $$ where $F$ is the Fisher Information matrix given by: $$ F = E \left [ \left( \frac{\partial}{\partial \theta} \log \pi_\theta(a|s) \right) \left( \frac{\partial}{\partial \theta} \log \pi_\theta(a|s) \right) ^T \right]. $$ I am having difficulty understanding this last formula. What are the dimensions on which the transpose of the second term in the bracket is being taken? My confusion here is that the gradient operation in this formula will generate an object of the same shape as the neural network I am using. And the parameters of the neural net are not a simple matrix but a set of three weight matrices $W_i$ and three bias vectors $b_i$ . So how does one go about taking the transpose of that?
