[site]: datascience
[post_id]: 51002
[parent_id]: 
[tags]: 
Neural Network learning in datasets that lie in small intervals

I am trying to use Keras to learn a Neural Network that predicts the function $f(x)=\frac{x^2}{2}$ . The network offers good performance when I try to learn the function over the intervals $[-10,10]$ and other similarly big intervals, but when I try to learn the function over $[-0.001,0.001]$ , the neural network simply outputs the same value every time, or something extremely close to it when making a prediction. Does anyone have any idea why that is? I am currently trying out 3 hidden layers with the relu activation function, a dataset of size 10000, and 10 epochs.
