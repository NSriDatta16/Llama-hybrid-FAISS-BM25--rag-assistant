[site]: crossvalidated
[post_id]: 603269
[parent_id]: 
[tags]: 
Why does mean-centering in a univariate logistic regression change p-values?

I have a very simple logistic model with a single continuous independent variable and a two-category dependent variable. When I mean-center the IV, the p-value of the coefficient changes significantly, and I'm not sure why. Example code snippet that reproduces the effect: import statsmodels.api as sm import numpy as np x = [5, 5, 6, 6, 5, 6] y = [1, 1, 1, 1, 2, 2] xc = x - np.mean(x) lr1 = sm.MNLogit(y, x) model = lr1.fit() lr2 = sm.MNLogit(y, xc) model2 = lr2.fit() print(model.pvalues) print(model2.pvalues) 0.423 1. Shouldn't the significance level of the coefficient not depend on the predictor variable's scale? All I can find from other threads is that centering will change the significance of interaction effects, but that's not applicable here. I'm also wondering which of the two results I should ultimately use to determine if there is a significant relationship between the two variables. Intuitively, the model with centered input seems "more" correct, given that in this data set there is no relationship at all.
