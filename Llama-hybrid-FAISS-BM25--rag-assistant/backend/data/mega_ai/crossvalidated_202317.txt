[site]: crossvalidated
[post_id]: 202317
[parent_id]: 202310
[tags]: 
As indicated by the name, burn-in is there to stabilise the chain towards its stationary regime, so the burn-in step should not be considered for performance evaluations like acceptance rate goals. However I want to warn you about the notion that 10⁴ simulations is large or poor in a generic sense. It will all depend on the type of target $f$ and the type of proposal $q$ you use in your algorithm. Even an acceptance rate of $23$\% may be misleading. For instance, assume you observe $x\sim\mathcal{N}(\theta^2,1/5)$ with a prior $\theta\sim\mathcal{N}(0,1)$. The posterior on $\theta$ is bimodal with modes near $\pm\sqrt{x}$, but running the basic Metropolis-Hastings code below target=function(x,y){ dnorm(x,0,1,log=TRUE)+dnorm(x*x,y,.2,log=TRUE)} T=1e5 y=pi mch=rep(rnorm(1),T) ace=0 for (t in 2:T){ mch[t]=pop=rnorm(1,mch[t-1],.3) if (log(runif(1))>target(pop,y)-target(mch[t-1],y)) mch[t]=mch[t-1] ace=ace+(mch[t]==pop) } produces an acceptance rate of > ace/T [1] 0.22921 and an output with a single mode In case you cannot reproduce the output with the above R code, here is the trace of a thinned MCMC based on 10⁵ iterations (with no burn-in)
