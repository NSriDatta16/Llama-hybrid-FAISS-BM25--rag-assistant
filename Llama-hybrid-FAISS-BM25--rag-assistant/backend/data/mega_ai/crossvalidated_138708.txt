[site]: crossvalidated
[post_id]: 138708
[parent_id]: 138281
[tags]: 
You are unclear on whether you are interested in the correlation structure of the outcome variables, or if you just want to handle polytomous data in a coherent way. I will assume the latter since it is more fundamental to the problem. Since you have an ordered categorical outcome variable (grade), the easiest and most intuitive solution is probably proportional-odds logistic regression. This avoids having to impose an explicit continuous mapping (which often involves making an assumption, e.g. linearity, or doing a hack). The concept is poorly explained on the wikipedia page http://en.wikipedia.org/wiki/Ordered_logit and further reading is available in Agresti's Categorical Data Analysis (note, it is NOT in Introduction to Categorical Data Analysis which is basically a slimmed-down version of the former), or on http://www.stat.uchicago.edu/~pmcc/reports/prop_odds.pdf It is implemented in R as the function polr() in the library MASS. You can type 'library(MASS)' followed by '?polr' for help. A quick explanation would not go amiss. Note that logistic regression is basically defined by the model $\mathrm{logit}(pr(Y=1\,\big|\,X=x))=\beta_0+\sum_i^p \beta_i x_i$ under the usual assumptions of conditional independence. Instead, let's take this model and say $$\mathrm{logit}(pr(\mathrm{Grade}>F\,\big|\,X=x))=\beta_{0F}+\sum_i^p \beta_i x_i.$$ This is equivalent to defining $Y=\chi(\mathrm{Grade}>F)$ and doing logistic regression. Now we'll continue and consider the conditional probability $$\mathrm{logit}(pr(\mathrm{Grade}>D\,\big|\,\mathrm{Grade}>F,X=x))=\beta_{0D}+\sum_i^p \beta_i x_i.$$ This means that the contribution of the explanatory variables (i.e. $\beta_i$) stays the same, but since $\big|\beta_{0D}\big| Obviously, repeating this for $pr(\mathrm{Grade}>C\,\big|\,\mathrm{Grade}>D, X=x)$ and so on will specify the model completely. In the end, you have four intercepts ($\beta_{0F},\beta_{0D},\beta_{0C},\beta_{0B}$) instead of just one ($\beta_0$). Intuitively, a student's "quality", plus a random unobserved factor, must be high enough to overcome the hurdle of getting a C. The proportional odds logistic regression model basically says that it's probability $\mathrm{invlogit}(-\beta_{0D})$ to get from a $D$ to a $C$, no matter what quality $x$ one has. This is the assumption. Details are in the University of Chicago link above.
