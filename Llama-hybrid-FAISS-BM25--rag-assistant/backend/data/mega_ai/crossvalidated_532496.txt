[site]: crossvalidated
[post_id]: 532496
[parent_id]: 532489
[tags]: 
For using a z-test for proportion here, is the idea to look at "Patient was prescribed drug at least once in time period" vs. "Patient was not prescribed drug at least once in time period"? If so, that's a reasonable thing to look at, as long as the time periods are equally long and as long as intervals between prescriptions don't cause trouble (worst case: yearly renewal and all doctors try to do it in January, because budget is available, or other weird effects like that; best case: pretty much random prescription times renewed at substantially shorter intervals than your time periods of interest). However, comparing that using a two-sample test seems wrong, because you'll presumably have a lot of patients occuring in both time periods. I.e. these could be looked at as paired proportions, which you can analyze in a number of ways. For example, you can look at this as a contingency table of "prescibed in summer" vs. "prescribed in winter" and methods for contingency tables - there are extensions if you only have data for some patients in one season. You can also use a random effects logistic regression with a random patient effect, e.g. in R this would look like this: library(lme4) glmer(y ~ (1|patient) + season, family = binomial) The nice thing about the logistic regression is that it extends sensibly to the setting with multiple types of prescriptions e.g. by adding a prescription type by season interaction and allowing the patient random effect to vary by prescription type, e.g. like this: glmer(y ~ 0 + (prescription_type|patient) + season + prescription_type + season*prescription_type, family = binomial) You could then look at the season by prescription type interaction (and its p-value) and apply multiplicity corrections as needed. You can also adjust for other variables, if that makes sense. Perhaps taking a Bayesian perspective and embedding the possibility for diverging effects inside a hierarchical model (see e.g. these comments by Frank Harrell or e.g. the horseshoe prior, which let's you encode your a-priori belief about likely number of meaningful interactions could be an approach). If there are additional things going on beyond seasonality (e.g., as you mention, COVID-19, or a general long-term trend for more prescriptions, or the average person in your database having gotten a bit older etc.), these will confound any of the simple ways of looking at this, no matter whether you look at aggregated numbers or individual counts. Especially if you look across many years, you can try to adjust for such effects (e.g. by having a "this time period is during the COVID-19 pandemic"-effect with interactions to specific prescriptions in the model), but this is why it's hard to causally attribute differences in prescriptions to a causal effect of it being a particular season (as opposed to something else that happened at the same time). In that sense the models I describe above are perhaps more descriptive. You may also have the issue that within the same person, many chronic drugs may be taken for a long time once initiated, so having them in the first time interval for some patients likely means that more people (the original ones plus some more) will take them in the second time interval. If your conclusion changes when you take summer first or winter first, then this is a sign this might be going on (another argument for looking at multiple years).
