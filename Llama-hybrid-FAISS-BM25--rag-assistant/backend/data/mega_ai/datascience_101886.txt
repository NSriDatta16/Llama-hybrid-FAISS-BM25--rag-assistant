[site]: datascience
[post_id]: 101886
[parent_id]: 94205
[tags]: 
Just for fun, run this for long generative output. Here is some code to put at the end. Also, you may want to change it to n-tuples or ngrams. This is a nice toy language model! output_str = [] with torch.no_grad(): context = ngrams[0][0][:] # Getting context and target index's context_idxs = torch.tensor([word_to_ix2[w] for w in context], dtype=torch.long) output_txt = context for i in range(30): context = context[1:]+[vocab[ixp]] output_txt+=[vocab[ixp]] #print(vocab[ixp],end=' ') context_idxs = torch.tensor([word_to_ix2[w] for w in context], dtype=torch.long) log_preds = model(context_idxs) ixp=torch.multinomial(np.exp(log_preds),1) #ixp=torch.argmax(log_preds) " ".join(output_txt)
