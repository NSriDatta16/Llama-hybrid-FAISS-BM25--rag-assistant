[site]: datascience
[post_id]: 88276
[parent_id]: 88267
[tags]: 
Since CNNs are translation invariant, aren't the translational shifts from keras useless as those shifts will not result in new images per say? Invariance to translation means that if we translate the inputs the CNN will still be able to detect the class to which the input belongs. Translational Invariance is a result of the pooling operation. In pooling operation, we replace the output of the convnet at a certain location with a summary statistic of the nearby outputs such a maximum in case of Max Pooling. As in the case of max-pooling, we replace the output with the max, so even though we adjust the input slightly, it will not impact the values of most pooled outputs. The major issue with max pooling is that the network fails to learn the spatial relation between different features , and thus will give a false positive if all features are present in the wrong position with respect to one another. This happens for Cases like Image Segmentation where we require position. So, Data Augmentation comes in handy to handle heavy distortion in images and make the model more robust to these distortion when we have less images. Reference: Translation Invariance
