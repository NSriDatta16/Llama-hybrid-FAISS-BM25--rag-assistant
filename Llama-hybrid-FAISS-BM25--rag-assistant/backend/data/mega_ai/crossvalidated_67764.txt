[site]: crossvalidated
[post_id]: 67764
[parent_id]: 
[tags]: 
Is the expected value a valid decision-making method in a very short term?

This might be related to game theory more than statistics, but I decided to ask this question here. Let's assume you're offered a lottery. There are a hundred balls in a bowl: 99 white balls and one red ball. You are allowed to pick one ball at random (obviously without seeing what color it is). If the ball you picked is red, you win \$100. However, if you pick a white ball, you lose \$1. The expected value of the lottery is .99* (-\$1) + .01 * \$100 = \$.01. This suggests that you should play the lottery, since it allows you to win one cent on average. The expected value in this case means that if you play the lottery an infinite amount of times, you'll average a gain of one cent per game. However, what if you're only allowed to play the lottery once or twice or three times? Is the expected value still a viable decision-making device in such a scenario? Thank you for your responses.
