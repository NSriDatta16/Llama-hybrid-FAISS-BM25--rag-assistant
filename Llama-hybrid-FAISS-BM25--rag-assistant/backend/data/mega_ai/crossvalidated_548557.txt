[site]: crossvalidated
[post_id]: 548557
[parent_id]: 
[tags]: 
Why doesn't test error increase for a high number of boosting iterations? Figure 10.13 of The Elements of Statistical Learning

My question refers to the figure 10.13 of The Elements of Statistical Learning . Test error decreases monotonically with the increase in tree iterations. However, I don't understand why the test error does not raise for the high number of iterations. In the figure below the test error increases for the more complex model. EDIT: The boosting algorithm combines the output of weak learners (often trees) to produce strong predictions. $$ f_{M}(x) = \sum_{m=1}^{M}f_{m}(x;\theta_{m}) $$ where M is a tunable hyperparameter that controls trade off between bias/variance. In the section 10.14.1 of The Elements of Statistical Learning the gradient boosting model was fit to California Housing data. In the figure 10.13 the average absolute error for training and testing data is decreasing monotonically with the number of boosting iterations (M). This is what authors write: The test error is seen to decrease monotonically with increasing M, more rapidly during the early stages and then leveling off to being nearly constant as iterations increase. Thus, the choice of a particular value of M is not critical, as long as it is not too small So, I think authors claim that even for a big number of iterations M the test error will level off. However, shouldn't the test error rise for the very complex model (indicated by a high number of M)?
