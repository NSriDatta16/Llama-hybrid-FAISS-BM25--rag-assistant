[site]: crossvalidated
[post_id]: 355452
[parent_id]: 355440
[tags]: 
This doesn't sound like a good fit to reinforcement learning for me. RL algorithms have to learn how their actions affect the world, what the payoffs for your actions are, and how to do long-term "credit assignment," etc., none of which are aspects of your problem. Instead I'd recommend something like: learn a regression model from the state to the reward. Then take your action if the reward estimate is positive. This is (maybe) better than just training a classifier, because it gets stronger signal in cases where it should really really be positive. You might prefer to design a loss with harsher penalties when you make the wrong choice, though.
