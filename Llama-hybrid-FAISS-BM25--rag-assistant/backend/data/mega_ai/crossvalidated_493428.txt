[site]: crossvalidated
[post_id]: 493428
[parent_id]: 
[tags]: 
Estimating the binomial distribution parameter $p$ for rare events

Suppose we have an extremely large collection of red balls and green balls. If we let $R$ and $G$ be the events of drawing a red ball and drawing a green ball, respectively, and if we let $\Pr(R)=p$ then $\Pr(G)=1-p$ . We also assume that the vast majority of the balls in our collection are green, implying $p . We would like to estimate $p$ using the following experiment: sample from the collection 3 times by selecting 20 balls each time. Then starting with the uninformed prior distribution of $p$ as Beta $(1,1)$ we update the prior by Bayesian updating after each sample and compute the expected value of $p$ after completing the 3 samples. So suppose we sample and get 20 green balls for each of the 3 samples. The final update of the prior distribution of $p$ is Beta $(1,61)$ and the expected value of $p$ is $E(p)=\frac{1}{62}\approx 0.01613$ . This seems to be a very high estimate and I think the problem is that I am starting the updating with an uninformed prior despite the fact that I know $p . Is there a way to justify a more informed prior in order to get a stronger conclusion? For example, if I believe that $p\le 0.01$ start with the informed prior Beta $(2,100)$ , my update for $p$ will be distributed as Beta $(2,160)$ and $E(p) = \frac{1}{81}>0.01$ ! That makes no sense to me. Any help would be appreciated.
