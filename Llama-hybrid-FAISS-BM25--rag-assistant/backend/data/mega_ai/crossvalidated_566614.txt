[site]: crossvalidated
[post_id]: 566614
[parent_id]: 566593
[tags]: 
Good afternoon! You have provided a good link in your post. It shows that you need predict(model) Why? Because it's Out Of Bag forecast (the OOB score is calculated using only a subset of decision trees not containing the OOB sample in their training dataset), as far as I know, so it's similar to cross-validation. Using predict(model, newdata=train) you will make predictions using train data and model trained on that data, which seems confusing and may provide unrealistically high model performance. I personally would pay attention to model performance on test, because model was fitted on train so it 'knows' train and will perform on train better. Is R-squared the metric you really want to work with? It just indicates the percentage of target variable variance explained by model. Since ML models are used for forecasting, the most concern is about (surprisingly!) the accuracy of forecast. So for regression problem people usually use RMSE, MAPE etc. which describe better the average error of forecast.
