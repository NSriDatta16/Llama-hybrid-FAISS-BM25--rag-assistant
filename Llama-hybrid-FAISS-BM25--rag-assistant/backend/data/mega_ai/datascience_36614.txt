[site]: datascience
[post_id]: 36614
[parent_id]: 
[tags]: 
Autoencoder ambivalent about order of input data?

The problem I'm working to solve is this: Given a musician's prerecorded free-form playing. I want to analyze each of the individual notes to determine how "in-rhythm" it is. See the graph in the screenshot. The dark shading represents the beat intervals between every note in the vicinity of the one in question (plus or minus say, 10,000 ms) and every other in that vicinity. From this you are able to see peaks where common beat intervals lie and you can begin to deduce the length of a standard quarter note beat, etc. The light thin lines represent the intervals between the note in question and those in the local vicinity. When I say I want to know how "in-rhythm" this note is, what I mean is, "how close are these lines to their nearest peak?" It's basically a problem of cluster analysis. So, given a set of numbers (represented by the thin lines in the graph) how close are they as a set to the center of their respective clusters? It strikes me that this could be a good machine learning problem, so I've been attempting to approach it from that direction. I was thinking a simple autoencoder would be suitable for the task. The input would be lists of numbers representing these beat intervals, but one thing I'm not sure about is this: There's no telling how many of which peak/cluster any given note's beat intervals might belong to, so is there a way to keep the neural net ambivalent about the order in the list it finds these numbers? I don't want it determining that a certain note was more out of rhythm simply because it was missing an interval from a large cluster, etc. It seems to me that order would probably always matter, so I'm at a bit of an impasse with my understanding. Am I right about this? Do you see some other solution?
