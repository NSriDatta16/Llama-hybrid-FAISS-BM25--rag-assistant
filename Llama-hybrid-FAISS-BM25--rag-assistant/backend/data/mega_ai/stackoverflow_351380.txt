[site]: stackoverflow
[post_id]: 351380
[parent_id]: 
[tags]: 
What are the problems associated with serving pages with Content: application/xhtml+xml

Starting recently, some of my new web pages (XHTML 1.1) are setup to do a regex of the request header Accept and send the right HTTP response headers if the user agent accepts XML (Firefox and Safari do). IE (or any other browser that doesn't accept it) will just get the plain text/html content type. Will Google bot (or any other search bot) have any problems with this? Is there any negatives to my approach I have looked over? Would you think this header sniffer would have much effect on performance?
