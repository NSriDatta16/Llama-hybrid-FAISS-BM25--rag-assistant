[site]: crossvalidated
[post_id]: 207105
[parent_id]: 
[tags]: 
Topic Modeling Dataset for Code Verification

I am trying to write up a Gibbs sampling Latent Dirichlet Allocation function for myself in R , and wanted to run it on a dataset where the true classification of topics to documents and words is "known". Is there a known uncomplicated dataset I can use to ensure my implementation is ok? For example journal article abstracts that lie in 3 distinct fields, which are already pre-classified. I understand this might be difficult since many documents can be classified differently, but often artificial datasets are constructed for purposes of model validation. I have tried the cora.documents in lda R package, but do not know what the true classification is there. I have also searched through papers on LDA and looked through examples, but all of them seem to be real data examples. I have also tried simulating data , but it is unclear to be whether the prior generative process should align with the posterior decisions. Intuitively, I think not, so working with simulated data for Bayesian settings as this don't seem viable. (I understand this question might be off topic on CV, but seems relevant to me)
