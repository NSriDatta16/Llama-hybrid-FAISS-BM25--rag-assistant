[site]: crossvalidated
[post_id]: 275057
[parent_id]: 136526
[tags]: 
The images you present are the same as those here: link . The following is some code, translated to R with some adjustments, to work through this. The RF selected (2 trees) is not acceptable. This is not apples-to-apples, so any of the authors' assertions about "entropy" can be mis-informative. First we get the data: #reproducibility set.seed(136526) #I like to use question number as random seed #libraries library(data.table) #to read the url library(randomForest) #to have randomForests library(miscTools) #column medians #main program #get data wine_df = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv") #conver to frame wine_df Next we find the right size of random forest for it. max_trees Now we can look at how many elements should be in the ensemble: #make friendly for boxplot err_frame And it gives us this, which I then manually draw blue and black lines on in a version of midangle-skree heuristic to get a "decent" ensemble size of 30. It is two tangent lines from the slope: one at highest slope, one at right end of domain. We make a ray from intersection of those tangent lines to the slope-line along the mid-angle. The next highest point after the intersection informs tree-count. Now that we have a decent random forest we can look at errors. First we compute the error. # make "final" model my_rf_fin The first plots to start with are basic EDA plots including the 4-plot of error. #EDA on error par(mfrow = n2mfrow(4) ) #run seq plot(fit_err, type="l") grid() #lag plot plot(fit_err[2:length(fit_err)],fit_err[1:(length(fit_err)-1)] ) abline(a = 0,b=1, col="Green", lwd=2) grid() #histogram hist(fit_err,breaks = 128, main = "") grid() #normal quantile qqnorm(fit_err, main = "") grid() par(mfrow = c(1,1)) Which yields: The error is reasonably well behaved. It is narrow tailed. There is a non-Gaussian set of samples on the right side of the lag plot. The central part of the distribution looks triangular. It isn't Gaussian, but it wasn't expected to be. This is a discrete level output modeled as continuous. Here is a variability plot of actual vs. predicted, and of error vs. predicted. If systematically over-predicts the poorest class as better than rated, and under-predicts the highest class as poorer than rated. This random forest is less poorly constructed, and likely is a healthier function approximator. Next steps : make the boundary plot like yours on the first 2 principle components. Notes on the code : I'm not a big scikit.learn guy, so I am going to misunderstand parts of what they are doing. Standard disclaimers apply. Two trees in an ensemble is a contradiction in terms like "one man army". The random forest is no "one man army" because it would be CART as a non-weak learner. The author did a disservice to an ensemble learner by selecting 2 elements as the ensemble size. The big joy of a random forest is you can add ensemble elements. Never (ever) accept a random forest smaller than 20 trees. Double-check any forest smaller than 50 trees. The author has no split between training/validation or test. They use all the data to fit the learners. A better way is to split into those groups then determine the ensemble parameters, then make the model with the combined train/valid data. I don't see that here. Author does not specify whether the "y" is discretized or continuous. This means the RF might be living in regression instead of classification.
