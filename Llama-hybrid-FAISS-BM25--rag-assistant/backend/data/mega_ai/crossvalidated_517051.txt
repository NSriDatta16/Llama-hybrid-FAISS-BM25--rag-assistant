[site]: crossvalidated
[post_id]: 517051
[parent_id]: 
[tags]: 
Markov Chains - Can we set the Initial distribution as $X_{1}$ instead of $X_{0}$ to calculate a non-conditional probability?

Had a small question when I was going through Ross â€“ Probability Models. Given a discrete-time Markov chain $\{X_{n}: n=1,2,3 \ldots\}$ with a state space $\mathcal{S} = \{0,1\}$ , and an initial distribution $P(X_{0} = 0) = \alpha = 1 - P(X_{0} = 1)$ , we can write the unconditional distribution of $X_{n}$ as: $P(X_{n} = k) = \sum_{i\in \mathcal{s}} P(X_{n} = k | X_{0} = i)P(X_{0} = i)$ Assuming we calculate the distribution of $X_{1}$ from a given transition probability matrix and the given distribution of $X_{0}$ , can we write: $P(X_{n+1} = k) = \sum_{i\in \mathcal{s}} P(X_{n+1} = k | X_{1} = i)P(X_{1} = i)$ . Here, all I do is change the initial distribution from $X_{0}$ to $X_{1}$ . Is this allowed?
