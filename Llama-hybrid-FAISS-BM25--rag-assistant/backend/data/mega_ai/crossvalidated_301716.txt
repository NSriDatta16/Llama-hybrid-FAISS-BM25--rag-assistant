[site]: crossvalidated
[post_id]: 301716
[parent_id]: 301694
[tags]: 
I would approach the problem in the following way. Cluster the accounts so that the state is (account cluster, state of the account) Construct the transition matrices with de data you have available. Use Dynamic programming to find the optimal policy. Force the sales representatives to follow the actions of Q-learning. So that it implements the optimal policy found by dynamic programming most of the time and takes a random action from time to time (greedy exploration) Q-Learning will be start gathering more data and modifing the best policy. Step 1. Would help reduce the dimensionality of the problem. It will be useful with new accounts, since you would be able to use the best policy found in other accounts. Steps 2. and 3. would use the data you have to construct the best static policy so far. This will make the Q-learning have a better start. Steps 4. and 5. would help you balance the tradeoff between gathering data to construct the optimal policy and actually helping the sales representatives gathering more money.
