[site]: datascience
[post_id]: 128195
[parent_id]: 
[tags]: 
Best practice for classification of parts of a sound file based on content

I have a collection of raw recordings. I also have a text file for each recording with the starts and ends of subparts of interest from the original recording. I want to train a model to classify parts of interest in future sound files. My intuition says that I should aim to train a BERT-like encoder to classify parts of the sound file, like when training a NER. However, since the relevant sub-parts of a recording are relevant due to their content, I am wondering whether I should first try to convert the recording into text. Is my intuition correct? Are there any models for handling audio files?
