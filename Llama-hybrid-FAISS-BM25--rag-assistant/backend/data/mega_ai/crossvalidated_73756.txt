[site]: crossvalidated
[post_id]: 73756
[parent_id]: 
[tags]: 
Sample from Wishart distribution with inverse Scale matrix

I tried to model precision matrix in a hierarchical Bayesian setup with Wishart prior given d.f. and inverse scale matrix, and matrix normal likelihood, since it's a conjugate prior, my posterior on the precision matrix $K$ ends up in the form: $$ K \sim \text{Wishart}(\text{df}, \Lambda^{-1}) $$ Since the dimension of $\Lambda$ is quite big, I do not wish to take the inverse of the matrix and use the built-in sampler. I looked at the source code for Matlab's wishrnd , they used Bartlett decomposition for large dimensions (81+n), which should also work for smaller dimensions albeit its inefficiency. snips of the code: [n,m] = size(Lambda); [d,p] = cholcov(Lambda,1); % Otherwise use the Smith & Hocking procedure d = eye(size(d)) / d; % Load diagonal elements with square root of chi-square variates a = diag(sqrt(chi2rnd(df-(0:n-1)))); % Load upper triangle with independent normal (0, 1) variates a(itriu(n)) = randn(n*(n-1)/2,1); % Desired matrix is D'(A'A)D x = a(:,1:size(d,1))*d; a = x' * x; % --------- get indices of upper triangle of p-by-p matrix function d=itriu(p) d=ones(p*(p-1)/2,1); d(1+cumsum(0:p-2))=p+1:-1:3; d = cumsum(d); In order to accommodate my needs,i.e. inputing degrees of freedom $df$ and the inverse scale matrix $\Lambda$ I added d = d \ eye(size(d)) after the second line, so that I would have the inverse of the cholesky decomp of the inverse scale matrix, in others words, the cholesky decomp of the scale matrix. Then everything should be okay from there ( I hoped). I tested this by firstly generating a 3 by 3 positive definite matrix: >> test = rand(190, 3); Lambda = test'*test; >> Lambda Lambda = 62.7642 46.4970 45.6662 46.4970 61.9178 45.4114 45.6662 45.4114 59.1070b Setting $df = 6$, 100,000 randoms samples were generated and the empirical mean is compare with the first moment of the distribution >> df = 6; >> sam = 0; for loop = 1:100000 sam = sam + mywishrnd(Lambda,df); end >> sam/100000 ans = 0.0956 -0.1069 -0.0689 -0.1069 0.3380 -0.0286 -0.0689 -0.0286 0.3872 >> inv(Lambda)*df ans = 0.2647 -0.1118 -0.1187 -0.1118 0.2692 -0.1205 -0.1187 -0.1205 0.2857 There is quite a big differences in some entries of the results, but I don't see anything wrong with this theoretically. Is it possibly due to numerical error? Could someone enlighten me on this problem?
