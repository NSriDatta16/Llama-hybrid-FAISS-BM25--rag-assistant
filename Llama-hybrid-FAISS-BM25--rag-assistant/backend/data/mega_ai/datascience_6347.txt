[site]: datascience
[post_id]: 6347
[parent_id]: 6331
[tags]: 
The best choice for storage technologies will depend largely on how much data (in terms of bytes) you expect to accumulate over the lifetime of your project, so the first thing i would do is try to get some sample data, or make some educated guesses (e.g. how many bytes does 1 temperature recording take up X how many change events am I expecting per day X how many temperature sensors X how many days worth of data you want to store and analyse over time). Once you have a rough idea of how much data you need to store and analyse, you can use that to start narrowing down your choices. There's no right answer, and others may disagree, but I would suggest that if you're dealing with anything less than terabytes of data, you don't need hadoop (I noticed that's a tag in your question) - hadoop is not really a data storage solution (although it does have it's own file system called HDFS or just DFS), it's more of a framework for processing and transforming huge quantities of data. Also if you don't have thousands of events per second to record, you probably don't need NoSQL solutions either. For storage of structured data, given that you've never really done data analysis before, SQL databases are probably the way to go if you have gigabytes or less, and SQL will be easier and more useful to learn - it's mature, been around for ages and is still the go-to standard in most industries, so there are plenty of learning resources . Maybe try out MySQL Community Edition server (free, open source) as a start, I would also recommend the MySQL Workbench to help you get started (a bunch of GUI tools you can use to mess around with SQL when learning) PS I don't know anything about capturing signals from sensors, so maybe there are more appropriate technologies which I'm not aware of!
