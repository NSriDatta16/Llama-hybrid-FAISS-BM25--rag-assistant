[site]: crossvalidated
[post_id]: 469453
[parent_id]: 
[tags]: 
XGBoost classification of panel/longitudinal data observations

I have a dataset of several firm quarters for a 10 year period (around 400 firms and around 30 observations per firm). For each quarter, there are a number of annualized financial ratios, which are used as features (around 40). Each quarter is associated with a binary label regarding a specific event happening or not in the following fiscal year. These events rarely occur, so my dataset is highly imbalanced. My main goal is to predict the probability of this event happening in the following year based on these ratios. As such, I would like to be able to train based on financial quarters from the past (e.g 2008 to 2015) and classify quarter observations from 2017 (in order to find if this event occurs in 2018). As of now, I'm trying to train an XGBoost classifier, just using the financial data from observations (no time or firm variables), but my results are somewhat disappointing. The time effects are irrelevant in my problem, but I'm afraid firm-specific effects may corrupt the data classification of observations since data samples of neighbor observations or firm observations are correlated. Is there a better way to adapt an algorithm like XGBoost, that works well on imbalanced data, to a problem like this? I tried some suggested approaches, such as training a classifier for each firm, but this approach does not translate over well to my problem since in a lot of firms the event I'm trying to predict does not occur. I also tried including dummies for each firm in my XGBoost model, but it doesn't seem to improve my detection results, and the one-hot encoding method dramatically the number of features, as I have more than 400 firms. Thanks in advance.
