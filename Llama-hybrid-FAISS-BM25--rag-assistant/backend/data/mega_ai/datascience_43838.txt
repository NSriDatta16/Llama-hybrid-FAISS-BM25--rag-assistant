[site]: datascience
[post_id]: 43838
[parent_id]: 43071
[tags]: 
At this point of time, if I had to start a project from scratch and I had to choose between Hadoop and Spark, I would certainly choose Spark over Hadoop. There are several reasons for this: Spark is more efficient than Hadoop given the fact that processing in Spark is in-memory whereas Hadoop requires to store intermediate results in disk. Spark provides dozens of different operations and it is not constrained to just Hadoop's map-reduce.| However, I still think that there is value in learning Hadoop before trying to learn Spark, even if it is at a high level. These are some reasons: You may came across some legacy applications/systems based on Hadoop technologies It provides a gentle introduction to some of the concepts used in Spark Spark is sometimes used in combination with some technologies in the Hadoop ecosystem, like Hive and HDFS (Spark does not incorporate a way of storing data, but it can fetch data from multiple sources, including HDFS, and a Spark cluster with HDFS based data storage is a usual combination).
