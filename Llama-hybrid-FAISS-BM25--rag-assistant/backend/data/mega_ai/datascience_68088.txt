[site]: datascience
[post_id]: 68088
[parent_id]: 26980
[tags]: 
XGBoost is not naturally calibrated in probabilities. You need to use something like: objective = "binary:logistic" to make sure that the model's output can be interpreted as a probability. Otherwise you may only get scores, that can only be used to rank instances. As most performance metrics can be calculated on scores, it is a common mistake to use what look like probabilities (associated with good performance metrics) instead of 'real' probabilities. AS for model instability (here in the sense that a slight change in explanatory variable change the prediction a lot), you need to recheck your whole calibration process : variable selection, train / test partitionning, hyper-parameter-tuning / cross validation, performance metrics used, to ensure that your model is not over-fitting.
