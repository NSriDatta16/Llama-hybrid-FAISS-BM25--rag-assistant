[site]: crossvalidated
[post_id]: 210504
[parent_id]: 210227
[tags]: 
Interesting problem! If I understand correctly you need to assess the quality of both models and take the one that works best: with better predictive power. Unless you have more games, the results will not be very generalizable. I assume that you have G games. You need to define a metric to compare the 2 models. When looking at binary outcome entropy (or log-loss) is usually an excellent metric. Then you can modify it to fit your purpose. The metric to score a model is always very subjective and especially in your case, you can define many. Here are a few examples: Average Entropy (or log-loss) of the probability in the last 10 minutes. In that case, you are measuring how well a model predict "just" before the true answer is known: $$ Error = \frac{1}{G}\sum_{g=1}^{g=G}{\frac{1}{10}\sum_{i=40-10}^{i=40}{[y_g*log(p_{i}^{g})+(1-y_g)*log((1-p_{i}^{g}))]}} $$ Average Entropy (or log-loss) of the probability with exponential loss. In that case, you are measuring how well a model predict "just" before the true answer is known: $$ Error = \frac{1}{G}\sum_{g=1}^{g=G}{\frac{1}{\sum_{i=1}^{i=M}{e^{i-M}}}\sum_{i=1}^{i=M}{e^{i-M} [y_g*log(p_{i}^{g})+(1-y_g)*log((1-p_{i}^{g}))]}} $$ With $y_g$ being the outcome of the game (0/1). If you think that the beginning or the middle of the game is more important than you can adjust those function as required. Hope this help.
