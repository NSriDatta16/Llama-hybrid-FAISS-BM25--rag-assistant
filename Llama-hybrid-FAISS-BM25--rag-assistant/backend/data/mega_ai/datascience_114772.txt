[site]: datascience
[post_id]: 114772
[parent_id]: 
[tags]: 
What is the best way for me to classify this audio data?

I have a set of audio data. I would like to classify each audio file based on a half-second of data from a give time period. The audio data is given as counts as a function of time $s(t)$ . Right now each datum looks like: | 1024 values of $s(t)$ | 1024 values of $\dot{s}(t)$ | 1024 values of $\hat{s}(t)$ | 1024 values of $\dot{\hat{s}}(t)$ | label | where dots indicate a time derivative and hats indicate some signal processing operations I perform on the raw signal. I found some success running on 1,000 such data points with sklearn 's gradient boosting classifier. I have two beginner questions: The only preprocessing I'm doing is converting the class names to numeric values. I know that ML methods tend to work better when data is scaled to be zero-mean and unit variance. Is doing no preprocessing valid? Or is there a better way to handle the intial data? Are there other types of classifiers that would be especially well-suited to this type of data? From my limited understanding, a benefit of my current approach is that it can be interpreted. In principle, I could examine the values of $s(t),~\dot{s}(t),~\hat{s}(t)$ and $\dot{\hat{s}}(t)$ for new audio files and determine what my classifier would call it. I think I would like to stick to methods like this, but if there is typically a substantial trade-off in accuracy compared to e.g. a 1D CNN, I would prefer something accurate.
