[site]: crossvalidated
[post_id]: 275922
[parent_id]: 
[tags]: 
Does Langevin MCMC with decreasing step size require Metropolis-Hastings?

We want to sample from the distribution $P(\theta \mid X)$, which we only know up to a multiplicative constant. In Langvin MCMC, our Markov Chain is $$ \theta_{t+1} = \theta_t + \frac{\epsilon_t}{2}\left ( \nabla P(\theta_t) + \sum_{i = 1}^n \nabla P(x_i \mid \theta_t) \right ) + \sqrt{\epsilon_t}\mu, $$ where $\mu \sim N(0,I)$ and $\epsilon_t$ is the stepsize. This is a discrete time approximation of the continuous time process $$ \frac{d \theta_t}{d t} = \frac{1}{2}\nabla P(\theta_t \mid X) + \xi(t). $$ where $\xi(t)$ is the time derivative of Brownian motion. If $\epsilon_t$ is a constant, then for the distribution to converge to the posterior we need to adjust each step with Metropolis-Hastings. However if $\epsilon_t$ is decreasing (with some assumptions such as $\sum_{t = 1}^\infty \epsilon_t = \infty$ and $\sum_{t = 1}^\infty \epsilon_t^2 My reason for asking is that there has been a lot of work on Langvin MCMC with stochastic gradients and it is not clear to me if all the error is due just to the estimate of the gradients or the discretization of the continuous time Markov Chain with even with decreasing stepsize.
