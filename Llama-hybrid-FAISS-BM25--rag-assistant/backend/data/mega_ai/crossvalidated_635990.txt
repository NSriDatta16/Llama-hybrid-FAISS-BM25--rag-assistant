[site]: crossvalidated
[post_id]: 635990
[parent_id]: 
[tags]: 
Imputing missing values in CPUE time-series data with varying effort

I have a dataset witch consists of several years fish counts in a trap that is used to catch downstream migrating individuals. The trap is usually emptied daily, but sometimes the interval is longer (2-6 days). I refer to this interval between sampling as "trapping period". I expect that all of the fish moving downstream are caught and none manage to escape the trap. Example data: Day Count nDays Env1 Env2 1 1 1 5.6 1.2 2 3 1 5.5 1.3 4 11 2 5.8 1.9 5 7 1 6.0 1.8 6 23 1 6.2 1.9 8 43 2 6.3 1.9 9 31 1 6.5 1.5 10 11 1 7.1 1.2 12 7 2 7.5 0.9 15 5 3 7.7 0.8 Day = Number of the day from the start of trapping season; Count = Number of eels in the trap in Day n; nDays = Length of the trapping period (i.e. the "effort"); Env1, Env2, ... = Mean of the environmental variables during the trapping period. I am interested in how the different environmental variables such as discharge, temperature, barometric pressure etc. affect the daily counts of caught fish. I thought of just using the mean of the environmental variables during the trapping period in a set of candidate models to explain the CPUE (Catch Per Unit Effort,i.e. Count/nDays) without regarding to the temporal aspect of the data, including the trapping period (the effort) as an offset. This proved to be quite a good approach in the sense that the models performed well, but completely disregarded the temporal autocorrelation between the counts that seems quite possible from visually inspecting the data and also makes biological sense. So I have been trying to find a way to analyze this as a time series data. So my question is: What would be the best way for me to impute the missing counts for the catch periods lasting more than 1 day and what caveats do you see in this approach I should be aware of?
