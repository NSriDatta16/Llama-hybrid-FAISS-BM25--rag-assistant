[site]: crossvalidated
[post_id]: 590710
[parent_id]: 
[tags]: 
When the sample mean converges to the population mean, does the probability that the sample mean is equal to the population mean tend to 0?

Let $y_1, y_2, \ldots , y_N$ be arbitrary real numbers and suppose a process of simple random sampling without replacement that selects $n$ out of $N$ elements. Then suppose that these $N$ elements are embedded in an asymptotic regime, indexed by $h \in \mathbb{N}$ , whereby (1) the original set of $N$ real elements is copied $h âˆ’ 1$ times, (2) within each of the $h$ copies, exactly $n$ units are selected under simple random sampling without replacement and (3) the $h$ copies are then collected into a single population with $Nh$ total units and $nh$ sampled units. Denote the sample mean under simple random sampling without replacement for each $h \in \mathbb{N}$ by \begin{align*} \hat{\bar{y}}_h = (1/nh) \sum \limits_{i = 1}^{Nh} S_{h,i} y_{h,i}, \end{align*} where $S_{h,i}$ is an indicator variable equal to $1$ if $y_{h,i}$ is included in the sample and $0$ if not. For each $h$ , there are $\binom{Nh}{nh}$ possible samples, the collection of which is denoted by $\mathcal{S}_h$ . The vector $\mathbf{s}_h = \begin{bmatrix} s_{h,1} & \ldots & s_{h,N} \end{bmatrix}^{\top}$ is an element from the set $\mathcal{S}_h$ . This asymptotic regime implies that (1) The average outcome, $\bar{y}_h = (1/Nh) \sum \limits_{i = 1}^{Nh} y_{h,i}$ is equal to $\bar{y}$ , which is fixed over all $h \in \mathbb{N}$ ; (2) $\max \limits_{1 \leq i \leq Nh} \left(y_{h,i} - \bar{y}_{Nh}\right)^2$ is fixed over all $h \in \mathbb{N}$ , which implies that $\lim \limits_{h \to \infty} \max \limits_{1 \leq i \leq Nh} \left(y_{h,i} - \bar{y}_{Nh}\right)^2 / Nh = 0$ ; and (3) the proportion of sampled units, $p_h \in (0, 1)$ , is fixed at $p \in (0, 1)$ over all $h \in \mathbb{N}$ . These three conditions suffice for the almost sure convergence of the sample mean to the population's mean, i.e., \begin{align*} \hat{\bar{y}}_h \xrightarrow{\textrm{a.s.}} \bar{y}. \end{align*} I interpret this convergence statement as meaning, in essence, that, with a large enough $Nh$ , the sample mean, $\bar{y}_h$ , will always lie (i.e., with probability $1$ ) in the interval $(\bar{y} - \varepsilon, \bar{y} + \varepsilon)$ , where $\varepsilon$ is an arbitrarily small constant greater than $0$ . My question is whether either of the two conditions hold: \begin{align*} \lim \limits_{h \to \infty} \left(\dfrac{1}{\left\lvert \mathcal{S}_h \right \rvert}\right)\sum \limits_{\mathbf{s}_h \in \mathcal{S}_h} \mathbb{1}\left\{\hat{\bar{y}}_h = \bar{y}\right\} & > 0 \text{ or } \\ \lim \limits_{h \to \infty} \int_{\bar{y}^* \in \mathcal{Y}} \left(\dfrac{1}{\left\lvert \mathcal{S}_h \right \rvert}\right)\sum \limits_{\mathbf{s}_h \in \mathcal{S}_h} \mathbb{1}\left\{\hat{\bar{y}}_h = \bar{y}^*\right\} \, d \, \bar{y}^*& > 0, \end{align*} where $\mathcal{Y} = \left\{ \bar{y}^*: \left\lvert \bar{y} - \bar{y}^* \right\rvert . In other words, although the sample mean will, as $h \to \infty$ , lie within a narrow interval around the population mean, $\bar{y}$ , could the probability that the sample mean is exactly equal to $\bar{y}$ tend to $0$ as $h \to \infty$ ? Or is this probability always bounded away from $0$ in the limit? It seems like this probability would not always be bounded away from $0$ , but I am having difficulty constructing a counterexample that satisfies the three conditions above. I would be greatly indebted to anyone who can give a simple example that satisfies the three conditions above, but where the probability that the sample mean is equal to the true limiting mean tends to $0$ . It seems that one way to do this would be to given an example in which the sample mean produces unique values for every $h \in \mathbb{N}$ , which would imply that, at best, $\Pr\left(\hat{\bar{y}}_h = \bar{y}\right) = \left(\dfrac{1}{\left\lvert \mathcal{S}_h \right \rvert}\right)$ . Since $\lim \limits_{h \to \infty} \dfrac{1}{\left\lvert \mathcal{S}_h \right \rvert} = 0$ , then $\Pr\left(\hat{\bar{y}}_h = \bar{y}\right)$ would also tend to $0$ . However, I am having difficulty constructing such an example that satisfies the three aforementioned conditions. Finally, if indeed the probability is not always bounded away from 0 as $h \to \infty$ , are there additional (ideally mild) conditions one could impose on the infinite triangular array to ensure that the probability is always bounded away from 0?
