[site]: crossvalidated
[post_id]: 405397
[parent_id]: 
[tags]: 
Why does boosting accuracy change when run multiple times?

I have a set of 380 observations with 30 predictor variables and one response variable. I have determined using other methods (bagging and random forest) that there is a set of 7 variables that are most important for prediction. I'm using the boosting function from the adabag package, and have set a constant random number seed. However, when I run the same command again, I get a different prediction accuracy. Here is a sample code that reproduces the behaviour: library(MASS) library(adabag) set.seed(42) data("birthwt") # Example data birthwt $race race) birthwt $smoke smoke) birthwt $low low) N Notably the accuracy varies by several percentage points on each iteration of the commands, and does so seemingly randomly. I'm uncertain whether this is a "problem" as such or intended behaviour. Why does this happen?
