[site]: datascience
[post_id]: 40583
[parent_id]: 
[tags]: 
Extracting Useful features from large convolutional layers

I have been training a convolutional neural network on emotion detection. Now, I would like to extract features for my data to train an LSTM layer. In my case, the top convolutional layers in the network has the following dimensions: [None, 4, 4, 512] and [None, 4, 4, 1024] . Therefore, this will give a total of 8192 and 16384 dimensional vectors. This is too large to train an LSTM layer. Therefore, I would like to know what is the best possible way to reduce the dimensionality of this vector? In other words, should I apply global average pooling to the conv layer after obtaining the activation or any other dimensionality reduction technique? In this case, my features will be a vector of 512 or 1024 dimensions, which makes sense. Any help is much appreciated!!
