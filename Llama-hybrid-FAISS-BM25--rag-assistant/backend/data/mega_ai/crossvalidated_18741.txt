[site]: crossvalidated
[post_id]: 18741
[parent_id]: 18451
[tags]: 
One simple approach would be as follows. For the two preference questions, take the absolute difference between the two respondent's responses, giving two variables, say z1 and z2, instead of four. For the importance questions, I might create a score that combines the two responses. If the responses were, say, (1,1), I'd give a 1, a (1,2) or (2,1) gets a 2, a (1,3) or (3,1) gets a 3, a (2,3) or (3,2) gets a 4, and a (3,3) gets a 5. Let's call that the "importance score." An alternative would be just to use max(response), giving 3 categories instead of 5, but I think the 5 category version is better. I'd now create ten variables, x1 - x10 (for concreteness), all with default values of zero. For those observations with an importance score for the first question = 1, x1 = z1. If the importance score for the second question also = 1, x2 = z2. For those observations with an importance score for the first question = 2, x3 = z1 and if the importance score for the second question = 2, x4 = z2, and so on. For each observation, exactly one of x1, x3, x5, x7, x9 != 0, and similarly for x2, x4, x6, x8, x10. Having done all that, I'd run a logistic regression with the binary outcome as the target variable and x1 - x10 as the regressors. More sophisticated versions of this might create more importance scores by allowing male and female respondent's importance to be treated differently, e.g, a (1,2) != a (2,1), where we've ordered the responses by sex. One shortfall of this model is that you might have multiple observations of the same person, which would mean the "errors", loosely speaking, are not independent across observations. However, with a lot of people in the sample, I'd probably just ignore this, for a first pass, or construct a sample where there were no duplicates. Another shortfall is that it is plausible that as importance increases, the effect of a given difference between preferences on p(fail) would also increase, which implies a relationship between the coefficients of (x1, x3, x5, x7, x9) and also between the coefficients of (x2, x4, x6, x8, x10). (Probably not a complete ordering, as it's not a priori clear to me how a (2,2) importance score relates to a (1,3) importance score.) However, we have not imposed that in the model. I'd probably ignore that at first, and see if I'm surprised by the results. The advantage of this approach is it imposes no assumption about the functional form of the relationship between "importance" and the difference between preference responses. This contradicts the previous shortfall comment, but I think the lack of a functional form being imposed is likely more beneficial than the related failure to take into account the expected relationships between coefficients.
