[site]: crossvalidated
[post_id]: 522802
[parent_id]: 477049
[tags]: 
The classical view of machine learning is that there is a bias-variance tradeoff and such a corresponding "sweet spot" between under-fitting and over-fitting. However, modern deep architectures can continue improving in test performance even after reaching very low or zero training risk and entering the "over-parameterized regime". This is explored in the paper Reconciling modern machine learning practice and the bias-variance trade-off by Belkin-Hsu-Ma-Mandal 2018 ( https://arxiv.org/abs/1812.11118 ).
