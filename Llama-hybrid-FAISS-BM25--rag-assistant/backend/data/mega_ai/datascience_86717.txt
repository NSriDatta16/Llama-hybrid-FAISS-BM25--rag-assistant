[site]: datascience
[post_id]: 86717
[parent_id]: 86706
[tags]: 
You could use some statistical method to rank these feature sets, such as extracting in each features set a discriminative score per feature ( kolmogorov smirnof , mutual information , ...) and then take the mean, the median, the p95, ... But , depending on the classifier that will be used, this score may be useless, because some classifiers act as features selectors (decision trees, neural networks, ...) and others don't (Gaussian NB, kNN,...). Example If you have 10 features in your 500 that are really good to discriminate your classification and the other 490 that do not contain information. Using a decision tree based classifier will lead to good performance as probably only the 10 features will be used. kNN in the other hand will lead to bad performance... However, your features set score would remain the same.
