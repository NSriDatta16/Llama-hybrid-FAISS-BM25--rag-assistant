[site]: crossvalidated
[post_id]: 503747
[parent_id]: 
[tags]: 
What do we want to measure when training agents?

When training RL agents, there are a lot of heuristics that come into play, (I believe due to stochasticity, specificity of problems and so on). However, I have seen in several papers measures that people (almost) always measure when training RL agents to see if it is actually learning. I will list those and I would like to know more important measures to look at when training or some rules of thumb/sanity checks that experienced people have encountered. Average Reward ( over x number of episodes ) Loss function (usually in Deep RL) # of actions (in grid world examples) Plots of the policy (violin plots) Somebody have more to add?
