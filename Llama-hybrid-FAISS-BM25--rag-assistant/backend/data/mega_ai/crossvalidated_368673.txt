[site]: crossvalidated
[post_id]: 368673
[parent_id]: 341
[tags]: 
Imbalanced class sizes are both a theoretical and practical problem with KNN which has been characterized in machine learning literature since at least 2003. This is particularly vexing when some classes have a low occurrence in your primary dataset (ex: fraud detection, disease screening, spam filtering). A google scholar search 1 shows several papers describing the issue and strategies for mitigating it by customizing the KNN algorithm: weighting neighbors by the inverse of their class size converts neighbor counts into the fraction of each class that falls in your K nearest neighbors weighting neighbors by their distances using a radius-based rule for gathering neighbors instead of the K nearest ones (often implemented in KNN packages) I've also found these two blogs helpful for general background on imbalanced class sizes. https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/ https://elitedatascience.com/imbalanced-classes
