[site]: datascience
[post_id]: 100319
[parent_id]: 
[tags]: 
Improving the accuracy of a binary categorization neural network

I'm currently working on an algorithm to replicate how human beings perceive gender from the voice. I have 11,000 voice clips - all of which appear to sound 100% male or 100% female, so the algorithm should theoretically be able to reach 100% accuracy. However, mine is stuck at around 93% on validation datasets and no number of nodes or hidden layers seems to change this. I also have a pretty exhaustive set of 70 variables (e.g. pitch, formant frequencies, HNR, etc.) so it's unclear to me whether I'm missing some variables or just putting them together the wrong way. These are all normalized by their means and stdevs too. The core of my script looks like this: # Set up the model model = Sequential() # Add the first layer and second layers model.add(Dense(500, activation='relu', input_shape = (n_cols,))) model.add(Dense(500, activation='relu')) # Add the output layer model.add(Dense(2, activation='sigmoid')) sgd = SGD(learning_rate=0.01) # Compile the model model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) # Define early_stopping_monitor early_stopping_monitor = EarlyStopping(patience=15) # Fit the model model.fit(predictors, target, epochs=150, validation_split=0.2, callbacks=[early_stopping_monitor]) I just wondered if anyone had any tips on how to make this perform better? Different activation functions, losses, optimizers? Am I missing any tricks which particularly help binary classification too? (Because all the voice samples sound either obviously male or obviously female, I'm considering this a binary classification problem until I start adding androgynous voices.) Is an N of 11,000 enough for this kind of neural network too?
