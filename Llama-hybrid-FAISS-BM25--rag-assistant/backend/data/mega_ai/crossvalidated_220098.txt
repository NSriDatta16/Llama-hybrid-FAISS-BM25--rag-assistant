[site]: crossvalidated
[post_id]: 220098
[parent_id]: 215577
[tags]: 
The short answer is no: the DIC comparison is not valid between these models applied to fundamentally different datasets. The slightly longer answer is that DIC (like all likelihood-based methods of model comparison such as AIC) is based partly on the -2 * log likelihood of the model - as you add more data points this likelihood will decrease, so the DIC will increase (for a fixed number of effective parameters) regardless of how well the model 'fits' in the general sense. So in your case, the 'stringent' approach would be expected to give a lower DIC purely on the basis of having fewer observations to fit to than the 'relaxed' approach model. If you wanted to persuade yourself of this, you could simulate a number of datasets of different N, and then fit the exact same model to these and look at the relationship between DIC and N. The second part of the following question is somewhat related to yours and the answer may also help you: Comparing AIC among models with different amounts of data You could potentially use non-likelihood based model selection techniques, such as posterior predictive p-values or leave one out cross validation, to see if there was evidence for the 'less certain' datapoints having worse fit to the model. However, I would be very reluctant to combine averages calculated using a different number of datapoints within the same model from a theoretical point of view, as this would likely break assumptions of homoscedasticity. It would probably be better to fit something like a hierarchical model of the individually observed temperatures with a random effect of individual. Regarding the last part of your question - it depends what you mean. Experimental balance will certainly affect the fit of the model, in that a better balanced study design will give less uncertainty in results. This would be expected to increase the diagnostic power of DIC to differentiate between candidate models (fit to the same data). If you mean 'would a well balanced study have a better DIC than an equivalent but unbalanced study' then the answer is that the DIC would not be comparable, as the datasets are by definition not the same.
