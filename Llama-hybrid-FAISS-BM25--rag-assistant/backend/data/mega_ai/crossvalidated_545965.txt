[site]: crossvalidated
[post_id]: 545965
[parent_id]: 
[tags]: 
Bayesian analysis used merely as a computational tool?

I have sometimes seen some statisticians used bayesian analysis and related techniques such as MCMC simply as a tool when a frequentist approach is not satisfying, typically for example when the maximum likelihood estimator is hard to find or takes too much time to compute. In these case they focus only on the definition of the model and estimation (by MCMC for example) and barely on the choice prior distributions (from what I've seen). I guess they use flat distributions by default but the particular choice of a prior is never discussed, maybe because of the large number of parameters the model may have and the difficulty to assign a meaningful prior distribution to each one of them. Is it something usual to switch to a bayesian analysis and use it merely a as computational counterpart of a frequentist approach when the latter performs poorly? My feeling is that bayesian and frequentist are very distinct statistical framework (at least that's what my teachers taught me!) and using one or another shouldn't be justified simply by computational purposes and moreover the choice of the prior distributions should at least be carefully made. I know this is not really a statistical question but I just would like to know what pure bayesians think about this kind of use of bayesian analysis. Sorry in advance if it does not fit this site.
