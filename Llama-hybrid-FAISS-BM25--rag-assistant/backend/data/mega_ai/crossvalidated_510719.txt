[site]: crossvalidated
[post_id]: 510719
[parent_id]: 
[tags]: 
Evaluate clustering accuracy based on an adjacency/similarity/connection matrix

Description In the classification tasks, the classification accuracy is computed by accuracy=n_correct/n_total For example, if I have three samples, and the ground truth labels are [0,1,0] and the predicted labels are [0,1,1] , then the accuracy will be 2/3=0.667 . In clustering, since label names do not matter that we only care about the relationships among samples, I wonder if there is a connection-matrix-based method that is commonly used in the machine learning world. import numpy as np def custom_accuracy(expected, pred): # ignore diagonal elements return (np.sum(expected == pred) - expected.shape[0]) / (expected.size - expected.shape[0]) def generate_connection_matrix(labels): labels = labels.flatten() left_matrix = np.repeat(labels.reshape(-1, 1), len(labels), axis=1) return np.equal(left_matrix, labels).astype(np.float32) y_true = np.array([0, 10, 13, 4, 1, 5, 7, 3, 6, 12, 9, 8, 2, 9, 15, 3, 9, 10, 11, 14]).astype(np.int64) y_pred=np.array([12, 10, 14, 6, 15, 9, 5, 3, 5, 5, 8, 13, 9, 4, 9, 7, 0, 11, 1, 2]).astype(np.int64) acc = custom_accuracy(generate_connection_matrix(y_true), generate_connection_matrix(y_pred)) print(acc) The output shows 0.9421052631578948 Problem So far the connection matrix version seems reasonable, however, when I compare it to the best-permutation one, I get a confusing result. I compute all permutations of y_pred and find the following permutation is the best compared to y_true . If I use the same evaluation method in the classification, I have import numpy as np from sklearn.metrics import accuracy_score y_true = np.array([0, 10, 13, 4, 1, 5, 7, 3, 6, 12, 9, 8, 2, 9, 15, 3, 9, 10, 11, 14]).astype(np.int64) y_best=np.array([0, 10, 13, 4, 1, 5, 6, 3, 6, 6, 12, 8, 5, 15, 5, 2, 9, 7, 11, 14]).astype(np.int64) print(accuracy_score(y_true,y_best)) The output shows 0.6 Now my question is: which result should I trust? 0.94 or 0.6?
