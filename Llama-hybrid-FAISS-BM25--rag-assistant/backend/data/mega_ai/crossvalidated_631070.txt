[site]: crossvalidated
[post_id]: 631070
[parent_id]: 
[tags]: 
Classification error when estimating population size of rare phenomena

I need to understand how a particular statistical challenge has been formally recognised or is commonly described in literature, and what the best academic resources are that discuss it. Here's the problem: consider you need to detect a rare phenomenon and in classifying the whole population (no need to sample) to detect it you want to consider the effects of different hypothetical rates of classification error. To illustrate assume the following hypothetical reality: total population ( N ) = 1 million rare phenonon of interest is present in 1 in 1,000 of the population ( P ) and absent in the remaining 999,000 ( A ) A 100% accurate classification would therefore yield 1,000 true positives and 999,000 true negatives. But we cannot assume our classification is perfect. But let's assume our false negatives are relatively few (certainly having a negligible effect on the estimate for A ). The real problem is the effect that even a tiny rate of false positive classification will have on estimation of P , since if just 1 in 1,000 of A observations are misclassified the estimate for P is doubled. Grateful for any insight community can offer for how this has been formalised and where I can find more information. It feels like the domain of Bayesian statistics which I'm not very expert in.
