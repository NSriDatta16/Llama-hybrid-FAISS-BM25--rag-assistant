[site]: crossvalidated
[post_id]: 386646
[parent_id]: 
[tags]: 
How can I create a meaningful weighting for RMSE?

Background I should start off by saying I am not a mathematician and please excuse simple/stupid mistakes! The goal of my exercise is to find the “best-fitting” model for the purpose of prediction. However, there are a couple of caveats: I am only interested in predicting over the upper quartile of the response points; under-predicting the value of the response is MUCH worse than over-predicting, and; I have three specific values I wish to calculate – lets say 90, 99 and 99.99. In this case I am working with support vector machines (SVMs) which my previous investigations have shown to be the best performing models out of a wide range of possible model types. For this particular exercise the array of possible models are SVMs with the same formula but different tuning parameters. This is an example of some analogous data: df To these ends @missuse has written some code to use leave-one-out cross-validation over the upper quartile of time points. At each iteration of the cross-validation I am currently calculating a weighted root mean square error (wRMSE), where I have made a simple (read crude) alteration which penalises model under-prediction 3× as harshly as over-predictions. Here is the wRMSE function which I am feeding into the caret::train function: wRMSESummary $obs - data$ pred) Res[Res And here is the code I am using to carry out LOOCV over the upper range of the response which @missuse wrote: `#Creating folds for upper quartile LOO-CV df %>% mutate(id = row_number()) %>% #create a column called id which will hold the row numbers filter(TrtTime >= unname(summary(df$Response)[5])) %>% #subset data frame according to your description split(.$id) %>% #split the data frame into lists by id (row number) map(~ .x %>% select(id) %>% #clean up so it works with indexOut argument in trainControl unlist %>% unname) -> dfFolds #Turning test sets into training sets dfFolds and finally the code for feeding both these into the caret::train function via caret::traincontrol : #Fitting traincontrol dfcontrol Problem I want to find a less arbitrary value than just multiplying the error of under-predictions by 3. Hopefully one that gives me some idea of the chance my model is under-predicting (if possible). By multiplying by a scalar as I outlined above, I believe (please correct me if I am wrong) that I will have diminishing returns as the value of the scalar increases- i.e. the PE will tend towards a particular model as the scalar increases. Or put another way the point estimates that I am interested in calculating (see point 3 in the background) will converge as my scalar tends towards infinity. If so, I was wondering if it would be possible to calculate the receiver-operator curve (ROC) that would characterise the loss in change and from here work out the area under the curve (AUC) which could in turn be used to determine what the optimal scalar would be, by say trying to account for 95% of the change in the fitted values across the upper quartile. Does that even make sense? This is really out of my comfort zone but any guidance would be greatly appreciated! I am completely open to alternative ideas and really looking for critiques as to whether or not this makes sense! If it does, would anybody be able to show me how I might go about determining this optimal value, preferably in R .
