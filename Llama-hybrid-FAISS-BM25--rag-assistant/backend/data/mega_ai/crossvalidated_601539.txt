[site]: crossvalidated
[post_id]: 601539
[parent_id]: 601529
[tags]: 
In general, it is hard to say what constitutes a good score. I have seen papers in top journals that have $R^2 . At the same time, it might be the case for a different problem that $R^2=0.9$ is nothing worth celebrating. An advantage that $R^2$ has over other measures of performance is that it inherently gives some kind of comparison to a baseline model; if you can’t beat the baseline model, your model isn’t helping. This corresponds to $R^2\le 0$ , with equality denoting the exact same performance as the baseline model. Thus, as long as you get $R^2>0$ , you’re doing something useful in terms of predictive ability. At the very least, you are performing better than a reasonable baseline model. How much better than $0$ you need to be is going to depend on the problem and how others have performed. If you get the best value anyone has ever gotten, that sounds like good news! If you beat the baseline model but fall short of what most others can achieve, there is room to improve. As with any machine learning task, watch out for overfitting.
