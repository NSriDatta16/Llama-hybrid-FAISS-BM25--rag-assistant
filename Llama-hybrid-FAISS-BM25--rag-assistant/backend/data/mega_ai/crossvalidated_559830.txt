[site]: crossvalidated
[post_id]: 559830
[parent_id]: 
[tags]: 
Is there a consensus on bad practice when doing model comparison in deep learning?

Lately I've been thinking about how to maintain the Equity property when Benchmarking DL for research. On Wikipedia , Equity property is defined as "All systems should be fairly compared." There are two things regard "fairness" that I understand: Keep the experiment condition the same for every model. (this is easy) The experiment condition should not be bias in favor of any single model. (this is the tricky part) So, when comparing between two or more promising DL models, how do I know the techniques I'm using (weight decay, shuffling data at every epoch, choice of optimizers, etc) does not bias the benchmark result for any model? I could not find any document discussing about this. Hopefully somebody could make it clearer for me, or provide some references. Thank you all very much.
