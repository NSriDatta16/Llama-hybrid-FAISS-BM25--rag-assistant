[site]: crossvalidated
[post_id]: 438358
[parent_id]: 438352
[tags]: 
I mostly check if it has a 21th century approach or a 20th century approach. Some indications include does it pay inordinate attention to topics that had their day, like the Durbin-Watson test, simultaneous equations etc. further red flags include too much attention being paid to fixed regressors, exact finite-sample results in toy settings, no attention to things that are routine nowadays like Eicker-White standard errors somewhat similarly, does it mechanically go through "violations of the classical assumptions" in the sense of "if you find heteroskedasticity, do GLS", "if you find serial correlation, do Cochrane-Orcutt" etc. - there is nothing wrong with any of these techniques, but it is rare in practice to have that these issues occur in isolation. (To be fair, it is much easier to explain what not to do than what to do.) does it pay attention to numerical implementation, i.e., how to actually carry out an empirical analysis using software, preferably one that allows for easy reproducibility, such as R or Stata? especially in undergraduate level texts, does it include interesting empirical applications rather than artificial samples which can be fed into a calculator to illustrate computation of some statistic by hand last but not least, is it typeset properly?
