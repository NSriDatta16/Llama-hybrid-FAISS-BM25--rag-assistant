[site]: crossvalidated
[post_id]: 162083
[parent_id]: 162063
[tags]: 
Further to my comments, here's a worked example where we try to infer $a$ and $c$ on the basis of a sample of observed $x$ and $y$ pairs and the belief that the data is generated in the way you describe. I'll use R and JAGS in this example. First make the data in R: set.seed(1234) c Sample some $x$s according to an exponential dist with rate $a$ x and for each x, sample a y from an exponential dist with rate $c/x$ y Bundle it into a data.frame dd and define a Bayesian model by specifying a data generating process for $x$ and $y$ and priors for unknown $a$ and $c$ in the form of an R function for R2jags to work with mod Now load the interface to JAGS library(R2jags) # requires JAGS to be installed first and compile a sampler that will sample from the posterior for this model jmod An initial round of sampling is actually sufficient (convergence statistic is here Rhat ) so we look what the sampler has come up with jmod 3 chains, each with 2000 iterations (first 1000 discarded) n.sims = 3000 iterations saved mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff a 1.011 0.101 0.824 0.943 1.010 1.076 1.219 1.001 3000 c 1.954 0.194 1.592 1.819 1.948 2.079 2.351 1.001 3000 The marginal posterior means of $a$ and $b$ are 1.011 and 1.954 respectively with quantiles as shown above, etc. In this case not too far from their true values of 1 and 2. You can also summarise the joint posterior in any way you like from the samples themselves, but this shows the general approach.
