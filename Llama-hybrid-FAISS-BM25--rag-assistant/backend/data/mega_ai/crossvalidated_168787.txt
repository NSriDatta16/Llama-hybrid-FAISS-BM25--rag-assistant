[site]: crossvalidated
[post_id]: 168787
[parent_id]: 168724
[tags]: 
In order to be able to answer the question about whether n or n+1 represents the 'right' number of regressors, you need to establish a way to test your fit. The main risk in using too many regressors (features) is overfitting. The only way to establish this is by testing the regressor against Out of Sample data. To achieve this, you will need to split your dataset into a training and testing subset. "Fit" each model on the training dataset and test the fitted regressor against the test dataset. Whichever model exhibits the best score (e.g., the means of establishing best fit, in your case Root Mean Squared Error) will be the most appropriate given the data. There are more formal ways to control overfitting. For example, there is a whole body of machine learning regressors called "Ridge Regressors" and "Lasso Regressors" which explicitly control for complexity. Utilizing them requires a bit more refinement. See the following for more info: http://scikit-learn.org/stable/modules/linear_model.html
