[site]: datascience
[post_id]: 36985
[parent_id]: 
[tags]: 
Tensorflow deep learning Weird Accuracy

I want to build a model to classify images of a dataset( ASL signs alphabet ). The dataset is in a folder where each sub-folder contains the images of a class and the name of the class is the name the sub-folder. Each image is 200x200. I wrote two scripts. The first one to transform the dataset to TFrecords. Here it is : import glob import numpy as np from random import shuffle import cv2 from tqdm import tqdm import tensorflow as tf #dataset file dataset_file=glob.glob("dataset/asl_alphabet_train/*") features_add=[] labels=[] classes_names=[] img_size=100 #getting the addess of each image and its label and the name of each class #the label will be the same as the index of the corresponding classe name : classes_names(label[i]) is the name of the classes of the image i for i,f in enumerate(dataset_file): classes_names.append(f[27:]) # the name of the subfolders is the name of the class subfolder_paths=glob.glob(f+"/*") for j,sub_f in enumerate(subfolder_paths): labels.append(i) # the label is the same for all the images in the subfolder features_add.append(sub_f) features_add=np.asarray(features_add) labels=np.asarray(labels) classes_names=np.asarray(classes_names) # shuffle the data tmp=list(zip(features_add, labels)) shuffle(tmp) features_add, labels=zip(*tmp) #Divide the data into 70% train, 20% validation and 10% test train_add=features_add[0:int(0.7*len(features_add))] train_labels=labels[0:int(0.7*len(features_add))] val_add=features_add[int(0.7*len(features_add)):int(0.9*len(features_add))] val_labels=labels[int(0.7*len(features_add)):int(0.9*len(features_add))] test_add=features_add[int(0.9*len(features_add)):] test_labels=labels[int(0.9*len(features_add)):] def read_image(add): #read an image #no need to resize, all the images in this dataset are 200x200 #cv2 images in BGR, it doesn't really matter for our netword img= cv2.imread(add) img = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_CUBIC) img=img.astype(np.float32)#/255 #img = np.asarray(img) return img def _int64_feature(value): #convert value to int64 using tf.train.Int64List and creature a feature using tf.train.Feature return tf.train.Feature(int64_list=tf.train.Int64List(value=[value])) def _bytes_feature(value): #convert value to bytes using tf.train.BytesList and creature a feature using tf.train.Feature return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value])) def TFrecord_write(features_add,labes, name): # data->FeatureSet->Example protocol-> Serialized Example -> tfRecord with tf.python_io.TFRecordWriter("TFrecords/"+name+".tfrecords") as writer: # the TFwriter writer print("writing the "+name+" TFrecord") for i,add in enumerate(tqdm(features_add)): img_raw=read_image(add) height=img_raw.shape[0] width=img_raw.shape[1] depth=img_raw.shape[2] img_raw=img_raw.tostring()# convert each image to bytes example= tf.train.Example( features=tf.train.Features( feature={ 'label': _int64_feature(int(labels[i])), 'img_raw': _bytes_feature(tf.compat.as_bytes(img_raw)) })) writer.write(example.SerializeToString()) #write the record TFrecord_write(train_add,train_labels,"train") TFrecord_write(val_add,val_labels,"val") TFrecord_write(test_add,test_labels,"test") And the second script is where I read the TFrecords, define the model and train it, and the evaluate it. Here It's : import numpy as np import tensorflow as tf import cv2 from PIL import Image import glob import sys import math batch_size = 3 img_size = 100 classes_names = [] dataset_file = glob.glob("dataset/asl_alphabet_train/*") for f in dataset_file: classes_names.append(f[27:]) # the name of the subfolders is the name of the class num_classes = len(classes_names) def parser(record): # a parsing function to parse the tfrecords keys_to_features = { "img_raw": tf.FixedLenFeature([], tf.string), "label": tf.FixedLenFeature([], tf.int64) } parsed = tf.parse_single_example(record, keys_to_features) # parsing one example from the example buffer from the tfrecord using the keys image = tf.decode_raw(parsed["img_raw"], tf.float32) # decoding ( bytes -> tf.float32) image= tf.cast(image, tf.float32) image = tf.reshape(image, shape=[img_size, img_size, 3]) # reshaping images label = parsed["label"] # casting labels to int32 label = tf.one_hot(indices=label, depth=num_classes) # transform to one hot encoding # with tf.Session() as session: # print(session.run(label)) return image, label def input_fn(filenames, train_bool=True): # from tfrecord to iterable data dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=40) # instantiantion of an object from class TFRecordDataset dataset = dataset.map(parser) # maps a function to the dataset if train_bool: #dataset = dataset.shuffle(buffer_size=2048) repeat = 1 # if in training mode allow reading data infinitely else: repeat = 1 # if in validation or test allow max 1 read dataset = dataset.repeat(repeat) dataset = dataset.batch(batch_size) # define bach size # iterator= dataset.make_one_shot_iterator()# making the iterator # images_batch, labels_batch=iterator.get_next()# getting the data # x= {'image': images_batch} # y= labels_batch return dataset # x, y def train_input_fn(): return input_fn(filenames=["TFrecords/train.tfrecords"]) def val_input_fn(): return input_fn(filenames=["TFrecords/val.tfrecords"],train_bool=False) def test_input_fn(): return input_fn(filenames=["TFrecords/test.tfrecords"]) def conv_layer_max2pool(Input, num_output_channels, conv_filter_size,conv_strides, pool_filter_size, pool_strides): # a function to create convulional layers, parameters are : # num_output_channels : number of the output filters # conv_filters_size: size of the convolution filter it should be a 2-D tuple # conv-strides: strides of the convolution. It's assumes that the strides over the height are the same as over the width # pool_filter_strides: as the conv_filter_size but for the pooling filter # pool_strides: as the conv_strides but for the pooling filter_shape= [conv_filter_size[0], conv_filter_size[1], Input.get_shape().as_list()[3], num_output_channels] #creating the shape of the filter to create the weights of the convolution W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.01)) #creating the weights conv= tf.nn.conv2d(Input, W, [1,conv_strides,conv_strides,1], padding="SAME") # creating the convolutional layer bias=tf.Variable(tf.zeros([num_output_channels])) # creating the biasis conv=tf.nn.bias_add(conv, bias) conv=tf.nn.relu(conv) #max pooling conv=tf.nn.max_pool(conv, [1, pool_filter_size[0], pool_filter_size[1], 1],[1, pool_strides, pool_strides, 1], padding="SAME") return conv def model_fn(X, keep_prob): conv1=conv_layer_max2pool(X,num_output_channels=64, conv_filter_size=(5,5), conv_strides=2, pool_filter_size=(2,2), pool_strides=2) conv1= tf.nn.dropout(conv1, keep_prob) conv2=conv_layer_max2pool(conv1,num_output_channels=128, conv_filter_size=(3,3), conv_strides=2, pool_filter_size=(2,2), pool_strides=2) conv2= tf.nn.dropout(conv2, keep_prob) # conv3 = conv_layer_max2pool(conv2, num_output_channels=128, conv_filter_size=(3, 3), conv_strides=2, # pool_filter_size=(2, 2), pool_strides=2) # # conv4 = conv_layer_max2pool(conv3, num_output_channels=128, conv_filter_size=(2, 2), conv_strides=2, # pool_filter_size=(2, 2), pool_strides=2) flat_layer= tf.layers.flatten(conv2) #FC layers dense1=tf.layers.dense(flat_layer, 256, activation=tf.nn.relu) dense2=tf.layers.dense(dense1, 128, activation=tf.nn.relu) dense3=tf.layers.dense(dense2, 64, activation=tf.nn.relu) #output layer output=tf.layers.dense(dense3, num_classes) return output #Remove previous weights, bias, inputs... tf.reset_default_graph() # place holdes for features, labels and keep_prob x=tf.placeholder(tf.float32, [None, img_size, img_size, 3] , name="X") y=tf.placeholder(tf.int64, [None, num_classes], name="y") keep_prob=tf.placeholder(tf.float32, name="keep_prob") #logits logits= tf.identity(model_fn(x, keep_prob), name="logits") # loss= loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( labels=y, logits=logits)) #optimizer optimizer=tf.train.AdamOptimizer().minimize(loss) #Accuracy pred=tf.equal(tf.argmax(logits,1),tf.argmax(y,1)) accuracy=tf.reduce_mean(tf.cast(pred,tf.float32), name="accuracy") train_dataset= train_input_fn() train_iterator=train_dataset.make_initializable_iterator() features, labels= train_iterator.get_next() valid_dataset=val_input_fn() valid_iterator=valid_dataset.make_initializable_iterator() valid_features, valid_labels=valid_iterator.get_next() save_model_path="Model/model0/" epochs= 10 keep_probability=0.5 with tf.Session() as sess: sess.run(tf.global_variables_initializer()) #num_images=train_input_fn().get_shape().as_list[0] #training_cycle for epoch in range(epochs): #for _ in range(math.ceil(num_images/batch_size)): sess.run(train_iterator.initializer) sess.run(valid_iterator.initializer) count=0 while True : try: count += 1 img_batch, label_batch= sess.run([features,labels]) # print([classes_names[i] for i in label_batch]) # #input() # for i,test in enumerate(img_batch): # #print(label_batch)#classes_names[label_batch[1]]) # test2 = Image.fromarray(img_batch[i].astype('uint8'), 'RGB') # test2.show(test2) # input() # print("next batch") sess.run(optimizer, feed_dict={x: img_batch, y: label_batch, keep_prob: keep_probability}) #print("batch number :", count) except tf.errors.OutOfRangeError: break print('Epoch {:>2}: '.format(epoch+1),end='') l = sess.run(loss, feed_dict={x: img_batch, y: label_batch, keep_prob: 1.0}) count=0 valid_accuracy=0 while True : try: valid_img_batch, valid_label_batch = sess.run([valid_features, valid_labels]) valid_accuracy+=sess.run(accuracy, feed_dict={x: valid_img_batch, y:valid_label_batch, keep_prob:1.0}) except tf.errors.OutOfRangeError: break count+=1 valid_accuracy=valid_accuracy/count print("The loss is : {0}, and the Validation Accuracy is: {1}".format(l, valid_accuracy)) saver=tf.train.Saver() saver_path=saver.save(sess,save_model_path) The problem is , no matter how I change the model, no matter how I change the batch_size or even change the optimizer, and no matter how long I run the training I get always the same accuracy : arround 3%. I still can't figure it out why. Can you help? Thank you
