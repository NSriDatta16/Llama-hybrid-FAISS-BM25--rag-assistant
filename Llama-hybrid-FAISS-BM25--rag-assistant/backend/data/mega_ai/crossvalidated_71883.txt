[site]: crossvalidated
[post_id]: 71883
[parent_id]: 71863
[tags]: 
Note that to prove the answer, you really only need to show that $$E \Big[ -2 \big(Y - E(Y|X)\big) \big(E(Y|X) - g(X)\big) \Big] = 0$$ As for which expectation to take, you take it conditionally, otherwise the term $$\arg \min_{g(X)} E\Big[\big(Y - g(X)\big)^2\Big]$$ Doesn't make sense, as $g(X)$ is a random variable if $E$ is $E_{XY}$ and not $E_{Y|X}$. Show you should really write $E\Big[\big(Y - g(X)\big)^2|X\Big]$ or $E_{Y|X}\Big[\big(Y - g(X)\big)^2\Big]$ to make this clear. Now given this clarification, the term $\big(E(Y|X) - g(X)\big)$ is a constant, and can be pulled outside the expecation, and you have: $$-2\big(E(Y|X) - g(X)\big)E \Big[ \big(Y - E(Y|X)\big)|X\Big]=-2\big(E(Y|X) - g(X)\big)\Big[ E(Y|X) - E\big[E(Y|X)|X\big]\Big]=-2\big(E(Y|X) - g(X)\big)\Big[ E(Y|X) - E(Y|X)\Big]=0$$ Hence you can write the objective function as: $$E_{Y|X}\Big[\big(Y - g(X)\big)^2\Big]=E_{Y|X}\Big[\big(Y - E_{Y|X}(Y|X)\big)^2\Big]+\big(E_{Y|X}(Y|X) - g(X)\big)^2$$ The minimiser is obvious from here. Note that if you were to average over $X$ as well, then a very similar argument can be used to show: $$E_{X}\Big[\big(E(Y|X) - g(X)\big)^2\Big]=E_{X}\Big[\big(E_{Y|X}(Y|X) - E_X\big[E_{Y|X}(Y|X)\big]\big)^2\Big]+\Big(E_{X}\big[E_{Y|X}(Y|X)\big] - E_X\big[g(X)\big]\Big)^2$$ This shows that if you set $g(X)=E_{Y|X}(Y|X)$ for each $X$, then you also have a minimiser over this function as well. So in some sense it doesn't really matter whether $E$ is $E_{YX}$ or $E_{Y|X}$.
