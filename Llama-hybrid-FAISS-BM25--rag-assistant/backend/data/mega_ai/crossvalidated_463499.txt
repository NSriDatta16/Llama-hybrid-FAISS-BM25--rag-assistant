[site]: crossvalidated
[post_id]: 463499
[parent_id]: 
[tags]: 
Machine learning (KNeighborsRegressor) Train score = 1

I'm trying to understand the outcome of this model. What I don't understand is why the score train is always one. I understand that this type of behavior is due to overfitting. However, I have already modified several hyper parameters and I have not been able to modify this behavior. I am using 16 features and a dataset divided into 12,000 training data and 3,000 test data. The code that I'm using to validate my model is : model_KNR = KNeighborsRegressor(metric = 'manhattan', n_neighbors = 3, weights = 'distance', leaf_size = 1,n_jobs=-1,algorithm = 'ball_tree') model_KNR.fit(x_train, y_train) y_pred_KNR = model_KNR.predict(x_test) error_KNR, error_original = compute_error(y_pred_KNR, y_real, y_test) N, train_score, val_score = learning_curve(model_KNR, x_train, y_train, train_sizes = np.linspace(.01,1,10), cv=cv, scoring='r2',n_jobs=-1) plt.plot(N,train_score.mean(axis=1), label = 'train') plt.plot(N, val_score.mean(axis=1), label = 'validation') plt.xlabel('Train sizes') plt.legend() plt.grid(True) print("Average error :%.2f"%np.mean(error_KNR),"m") print("Quality of prediction :%.2f"%r2_score(y_pred_KNR, y_test)) print("") The result is : Accuracy :0.94 (+/- 0.01) Average error :0.22 m Quality of prediction :0.94 Do you have any recommendations?
