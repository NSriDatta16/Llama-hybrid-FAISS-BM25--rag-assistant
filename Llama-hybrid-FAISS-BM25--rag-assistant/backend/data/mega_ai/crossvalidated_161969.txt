[site]: crossvalidated
[post_id]: 161969
[parent_id]: 161967
[tags]: 
Intuitively, a bias means that in average your estimate is off by some amount from the true value of the parameter. In application to residuals you have to understand that they are estimates of errors. In a model like this $$y=X\beta+\varepsilon$$ The last term is an error, and it's not observable. We can estimate the errors, and this estimate called residuals $\hat\varepsilon$. The bias in relation to residuals could mean that in average your residuals are off by some amount from errors: $$E[\hat\varepsilon]\ne 0$$ here, I assumed that errors are zero in average. Usually, in the context of the regression the bias is considered for parameter estimates $\hat\beta$, not the residuals. Note, that in the linear regression we usually include the intercept, thus, by construction, we make $$E[\hat\varepsilon|X]= 0$$
