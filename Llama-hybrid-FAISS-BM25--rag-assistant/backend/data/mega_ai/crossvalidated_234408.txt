[site]: crossvalidated
[post_id]: 234408
[parent_id]: 233200
[tags]: 
First, the runtimes are so different (about a factor ten) that there is hardly any need of a formal test! But there is still much of interest to say ... You say you have a paired comparison, since the implementations were tested with different datasets (same datasets for each implementation, making it paired). But then, for some of the datasets, you did multiple (five) runs, making it an independent samples comparison within the paired comparison! Maybe simply those independent runs should be averaged. Now note that formal hypothesis tests for paired comparisons typically are based on models such as $$ y_{i,1} = \mu + \epsilon_{i,1} \\ y_{i,2} = \mu + \Delta +\epsilon_{i,2} $$ where the $\epsilon$'s have some distribution we do not bother to specify, and $\Delta$ is the difference between treatments. That is, the tests depend on the asumption that the expected difference between treatments on the pairs are constant over the different experimental conditions indexed by $i$. That cannot be the case here, since runtimes would be expected to be (close to) proportional when input dataset size varies. That could be treated by a regression model, or more simply by analyzing logarithms! I leave that for you to see.
