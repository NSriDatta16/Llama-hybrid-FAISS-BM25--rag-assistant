[site]: crossvalidated
[post_id]: 320690
[parent_id]: 320675
[tags]: 
There is no theoretical basis for logistic regression (in general as a choice vs. another model). Two things are arbitrary: summing the influences of each variables, each influence being proportional to the variable (linear predictor) the sigmoid link (logit) The first assumption is similar to linear regression: a simple model that is very useful and often matches observations sufficiently well to make something of it. The second assumption can't be justified either. It is similar to the assumption of normality of the noise in linear regression. Interestingly many other link functions produce very similar results: Difference between logit and probit models . It is however interesting that logistic regression is equivalent to maximum entropy (in the case of binary/multinomial outcomes and independent observations), and that maximum entropy was stated as a principle by Jaynes in the 50s. I think people realized the two are equivalent much later (early 2000s as far as I known).
