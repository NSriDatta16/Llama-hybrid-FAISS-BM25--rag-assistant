[site]: crossvalidated
[post_id]: 240568
[parent_id]: 
[tags]: 
Correction for family-wise error when performing comparisons for several subgroups

I am unsure how to do the correction for family-wise error rate in my experimental design. The design is the following: I performed a classification task with five different algorithms in two different training scenarios for 30 different data sets. Furthermore, each data set is subdivided into two groups (holidays vs. normal days) for which I want to perform comparisons of methods separately in addition to the comparison on the whole data set. Originally, my idea was the following: For each research question, I perform a Friedman test and then post-hoc tests for pairwise comparison of methods. These post-hoc tests are corrected for multiple comparison in sense of comparing five methods pairwise by using Shaffer's correction. My research questions are e. g. the following: Are there differences between the methods in training scenario 1 for holidays? However, I then noted that I am testing a lot of research question essentially on the same data. I am not sure whether I should do another correction step and if so, how I should do that. For example, I could just count the total number of research questions (2 training scenarios and for each the whole data sets, only holidays and only normal days are considered --> 6 research questions), and then perform a Bonferroni or Bonferroni-Holm correction on the p-values from the already corrected pairwise comparisons of methods. However, I do not know whether this is reasonable. I am thankful for any suggestions on how to perform significant test in the given design. However, I would like to restrict the attention to non-parametric tests as I strongly think that my data is not suitable for parametric methods.
