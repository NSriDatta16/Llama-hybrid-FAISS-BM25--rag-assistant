[site]: crossvalidated
[post_id]: 304258
[parent_id]: 304242
[tags]: 
Indeed, CNNs typically use same-size input. If you take a closer at step 3 in that blog posting: Pad each sentence to the maximum sentence length, which turns out to be 59. We append special tokens to all other sentences to make them 59 words. Padding sentences to the same length is useful because it allows us to efficiently batch our data since each example in a batch must be of the same length. You will see they are using fixed size input there as well. For text processing in general, it is common to preprocess your data with word-embeddings. Methods such as tf-idf, word2vec and doc2vec take your words/text and provide fixed size numerical input.
