[site]: crossvalidated
[post_id]: 71689
[parent_id]: 71670
[tags]: 
In a regression setting you can actually test whether the simple aggregation is the correct choice. Suppose you have monthly data $Y_t$ and daily data $X_\tau$ (with the fixed $m$ days in a month). Suppose you are interested in a regression: $$Y_t=\alpha+\beta \bar X_t +u_t, (1)$$ where $$\bar X_t=\frac{1}{m}\sum_{h=0}^{m-1}X_{tm-h}.$$ Here we assume that for each month $t$ the daily observations are $X_{30(t-1)+1},...,X_{30t}$. In this case we assumed that each day has the same weight, which clearly is a restriction. So we can assume that more general model holds: $$Y_t=\alpha+\beta \bar X_{t}^{(w)} +u_t,(2)$$ with $$X_t^{(w)}=\sum_{h=1}^{m-1}w_hX_{tm-h}.$$ There are a lot of articles which explore different possible choices of $w_h$. Usually it is assumed that $w_h=g(h,\alpha)$, for some function $g$ which depends on parameters $\alpha$. This type of regression model is called MIDAS (MIxed DAta Sampling) regression. Model (2) nests the model (1) so it is possible to test the hypothesis that $w_h=\frac{1}{m}$. One such test is proposed in this article (I am one of the authors, sorry for the shameless plug, also I wrote an R package midasr for estimating and testing MIDAS regressions where this test is implemented). In a non-regression setting there are results which show that aggregation can change the properties of the time series. For example if you aggregate AR(1) processes which have short term memory (the correlation between two observations of the time series quickly dies off when the distance between them is increased), you can get a process with long term memory. So to sum up the answer is that validity of application of statistics on aggregated data is a statistical question. Depending on the model you can construct a hypothesis whether it is a valid application or not.
