[site]: crossvalidated
[post_id]: 443299
[parent_id]: 442644
[tags]: 
There are several different types of architectures you could consider to solve this problem. You chose a solution fully based on CNN's, which is reasonable, but another apparent choice would be to use something like LSTM-CNN's. For the sake of simplicity let's stay with a full CNN-based effort. You will require 3d convolutions. Look . In this case, your array would be five dimensional, e.g. [sample_number, time_step, x, y, channel]. Yet, convolutions are performed over the three middle dimensions; time being treated just as the spatial dimensions. At this point, your case is a bit special due to the future availability of two channels, while the third one is missing. A straight forward approach would be to extract samples of 52 timesteps. Modify then the last step by discarding* channel 1, and instead using this channel's information as the last timestep as target variable. *Discarding, most elegantly, would be some masking operation, yet masking in CNN's generally stirs discussion. Google might yield some workarounds, or see discussions like this . The common man's masking, which I would recommend as a baseline for your case, would be to just replace the channel's value by some constant (e.g. 0). There are yet some questions remaining: For how long do you have reliably the "future data" of the two channels? If you have it in advance for quite a period, you should consider utilizing more of these time steps. Is data of these two other channels really this reliable? Are you sure you are allowed to provide this data, and that it makes sense from a prediction perspective? Take well care when validating your approach. You generally will predict one step in advance with this baseline method. You then do one step and include the generated information to predict t+2. This requires a very conservative approach when doing a clean validation. Good Luck.
