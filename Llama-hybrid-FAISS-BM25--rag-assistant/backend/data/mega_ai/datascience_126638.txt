[site]: datascience
[post_id]: 126638
[parent_id]: 
[tags]: 
Bad metrics results by strong class imbalance in Credit card classification

Hi i'm currently in the process of writing my bachelor's thesis and stuck at a some steps. I've developed a few ML-Model (XGBoost, (Balanced) Random Forest, ElasticNet,...) on an extreme imbalanced data set (only about 0.2% of the data set belong to positive class). Almost all of my models have the same performance for the metrics that i chose: ROC AUC 0.77-0.80 Recall for positive class: 0.80-0.88 PR AUC: 0.04 - 0.06 Precision for positive class: 0.01-0.02 Matthews Correlation Coefficient (MCC): 0.13-0.15 Brier Score: 0.11-0.13 I'm quite stressed out that the metrics which are normally sensitive to imbalance in data set are really bad. I have tried some sampling methods including some variations of SMOTE, Undersampling (for which i even implemented a cross-validation script to find out what undersampling rate would be the best) and even tried implementing class weights, but the results don't seem the get better.. If anyone has any suggestion it would mean the world to me! Also one Background information: the model should be a Classifier for credits and there are only two classes: good and bad credits. I've read in some forums that it's ok to have this kind of results if the Recall is more important and false positive (which is normally high due to the imbalance) is not so "expensive". But classifying good credits as bad credits is in fact, bad? Thank you for reading and i would appreciate all the help!!! ----------------------------------------------------------------- P.s: I have also want to try out some new metrics for this imbalanced classification problem. The suggested metrics are: Kappa; weighted-averaged Accuracy, F1-Score; macro-averaged Accuracy, F1-Score. If anyone has a suggestion for metrics that I could use, I'd also appreciate it!
