[site]: datascience
[post_id]: 102493
[parent_id]: 102489
[tags]: 
Decision Tree, KNN, & Random Forest (Methods that are suitable for overlapping data) This statement is false. All those methods are good when the decision surface (separating surface) has a highly nonlinear form. They act as a non-parametric local approximation - all parameters are not in fact parameters of the decision function but are meta parameters of the model. When the decision separator is linear then it is to be expected logistic regression to perform better. To see if your data is linearly separable it is not enough to see pairwise scatter plots. Imagine to clouds of points, one nested inside another. If they are round, no matter how you project them in any pairwise axes they will look overlapped.
