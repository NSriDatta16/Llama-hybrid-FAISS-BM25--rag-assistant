[site]: datascience
[post_id]: 6797
[parent_id]: 
[tags]: 
Tune hyperparameters for cost-sensitive classification

I have an unbalanced data set with about 8% of negative examples. The goal is to minimize false negatives given a cost matrix. It seems like SVM (with radial kernel) and random forest work best. How should I tune hyperparameters in this setting? My suggestion: separate data into train/validation set, use probabilistic output together with cost matrix to assign predicted classes, tune hyperparameters to maximize accuracy . How can I increase performance? Currently I use random forest with nodesize=1 and mtry=5 which gives about 97% accuracy.
