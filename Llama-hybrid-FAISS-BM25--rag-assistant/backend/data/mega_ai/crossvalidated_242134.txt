[site]: crossvalidated
[post_id]: 242134
[parent_id]: 
[tags]: 
KL divergence for a hierarchical prior structure e.g. Linear Regression

For a Linear Regression $\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \epsilon$ with $\epsilon \sim \mathcal{N}(0, \sigma^2\mathbb{I})$, suppose the prior set on $\beta_k$ is $\sim \mathcal{N}(0, l_k)$ and prior on $l_k$ is $\mathbb{G}(\alpha_k, \beta_k)$ which is a Gamma Distribution. Suppose the approximate posterior on $\beta_k$ is $q(\beta_k)$ and that of $l_k$ is $q(l_k)$ then if the KL divergence from $q$ to $p$ i.e. $KL(q||p)$ is to be computed then what is the recommended steps? This is required in Variational Bayesian Inference. I have attempted like this... $KL(q||p) = \displaystyle \prod_{k = 1}^P \int_{\beta_k, l_k} q(\beta_k) q(l_k) \log \frac{p(\beta_k|l_k) p(l_k)}{q(\beta_k) q(l_k)} d\beta_k dl_k $ $ \displaystyle \int_{\beta_k, l_k} q(\beta_k) q(l_k) \log \frac{p(\beta_k|l_k) p(l_k)}{q(\beta_k) q(l_k)} d\beta_k dl_k\\ = \displaystyle \int_{ l_k} \left[ q(l_k)\left\{\int_{\beta_k} q(\beta_k)\log q(\beta_k|l_k)p(l_k) d\beta_k\right\} - \log q(l_k)\right] dl_k - \int_{\beta_k} q(\beta_k) \log q(\beta_k) d\beta_k$ After this how to proceed? Can anybody help me? Thanks in advance.
