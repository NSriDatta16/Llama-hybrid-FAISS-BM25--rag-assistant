[site]: crossvalidated
[post_id]: 50769
[parent_id]: 50738
[tags]: 
Flagging outlier is not a subject-matter decision but a statistical one. Outliers have a precise, objective definition: they are observations that do not follow the pattern of the majority of the data. Such observations need to be set apart at the onset of any analysis simply because their distance from the bulk of the data ensures that they will exert a disproportionate pull on any model fitted by maximum likelihood. Furthermore, detecting outliers is a statistical procedure with a well defined objective and whose efficacy can be measured . It is also important to point out that no matter how they are identified (whether according to an algorithm or simply through faith in someone else's wild guesses) the outlyingness of a group of suspect observations can be assessed simply by measuring their influence on a non-robust fit: outliers are by definition observations that have an abnormal leverage (or 'pull') over the coefficients obtained from an LS/ML fit. In other words, outliers are observations whose removal from the sample should severely impact the LS/ML fit. I have added more explanation of this in my answer to a related question . In any case, the rule you cite for detecting outliers is flawed. To see why, just notice that the sum of the squared z-scores always sum to a constant (n-1), regardless of whether your data contains outliers or not. For the precise problem you have I explained at length in previous answer how adjusted boxplots could be used to identify outliers when the observations of interest are suspected to have a skewed distribution. As pointed out by Placidia I suspect you are not providing us with all the elements for it is indeed strange to be doing data mining on univariate datasets. Regardless, I advise you to have a look at a modern book on outlier detection methods. I warmly recommend Maronna R. A., Martin R. D. and Yohai V. J. (2006). Robust Statistics: Theory and Methods. Wiley, New York.
