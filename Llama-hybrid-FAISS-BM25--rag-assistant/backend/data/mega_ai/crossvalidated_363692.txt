[site]: crossvalidated
[post_id]: 363692
[parent_id]: 363441
[tags]: 
Following my comment above, if $X$ is our confirmed symptoms (as binary present/absent variables) and $Y$ is our diagnosis (as one-hot vector/categorical variable), the $Z$ is our untested/unconfirmed systems (also as binary variables). The simplest model would be multi-logistic regression such that $E[Y|X,Z]=\mathop{\mathrm{softmax}}(f([X,Z],\theta))$ , but we could choose our estimator to be any function $f$ such as a neural network. Here $[X,Z]$ is sample-wise concatenation. To fit this model, we use the likelihood that $$\mathcal{L}(Y|X,Z)=\sum_i \mathrm{Cat}(Y=y_i|\theta,x_i,z_i)$$ For the frequentist solution, we use EM algorithm and any associated shortcuts or heuristics (a discussion of which is outside the scope of this post). Once we have our estimator for $\theta$ we can find the most likely $z$ given $x$ and/or $y$ and check for those symptoms with a value of 1. A Bayesian approach would instead generate many samples of both $\theta$ and $Z$ given the above likelihood and reasonable priors. We would then take the expectations $E[Z|X=x, Y=y]$ and/or $E[Z|X=x]$ over all values of $\theta$ . It might be worth it to use variational Bayes however if your training data is particularly large. You could then choose to check for symptoms with highest expectation (highest marginal probability). Updating our diagnosis/prediction is simply running our updated vector through the model, which should take only a few microseconds depending on the model. Updating the model itself, however, requires refitting and is therefore only recommendable after collecting a substantial number of new examples. Finally, as your model incorporates more computer-aided diagnoses, you also might want to maintain that your model isn't substantially different from a human expert and you could probably use a discriminator from adversarial networks for that purpose.
