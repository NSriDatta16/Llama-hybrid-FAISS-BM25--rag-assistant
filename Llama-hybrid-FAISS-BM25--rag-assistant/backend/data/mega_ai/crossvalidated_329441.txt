[site]: crossvalidated
[post_id]: 329441
[parent_id]: 
[tags]: 
Correcting log-bias in the output of an XGB

I have previously worked with GAMs, where I was trying to do regression on a log-transformed variable. The log-transformation introduced a negative bias in the average of the predicted variable, and I corrected for this by multiplying each of the predictions $\exp(\hat y)$ by the factor $$\langle \exp( \delta \hat y) \rangle$$ where $\delta \hat y$ was the residuals from the GAM. Now I am using XGB, and trying to do regression on a log-transformed variable $y$ once again. The predictions $\hat y$ satisfy $$ \frac{\sum_i \hat y_i}{\sum_i y_i} = 0.999 $$ so overall it looks good. However, when I exp -transform the variables I get $$ \frac{\sum_i \exp(\hat y_i)}{\sum_i \exp(y_i)} = 0.861 $$ which is considerably worse. I suspect that this is due to the negative bias. Is there a way to correct for the bias in the XGB as in a GAM/GLM?
