[site]: stackoverflow
[post_id]: 2527637
[parent_id]: 2510218
[tags]: 
Using zc.blist can bring good results after all, and setting the "cache_size" option when creating the DB controls the size of the data that will remain in the RAM. The size of used RAM can grow bigger if you don't do "transaction.commit" often enough. By defining a large cache_size and doing transaction.commit often, the last accessed buckets of the blist will stay in the RAM, giving you fast access to them, and the amount of used RAM won't grow too much. Packing is very expensive though, but if you have a large harddisk, you don't have to do it that often anyway. Here is some code to try yourself. Run "top" at the background and change cache_size to see how it affects the amount of used RAM. import time import os import glob from ZODB import DB from ZODB.FileStorage import FileStorage import transaction from zc.blist import BList print('STARTING') random = open('/dev/urandom', 'rb') def test_list(my_list, loops = 1000, element_size = 100): print('testing list') start = time.time() for loop in xrange(loops): my_list.append(random.read(element_size)) print('appending %s elements took %.4f seconds' % (loops, time.time() - start)) start = time.time() length = len(my_list) print('length calculated in %.4f seconds' % (time.time() - start,)) start = time.time() for loop in xrange(loops): my_list.insert(length / 2, random.read(element_size)) print('inserting %s elements took %.4f seconds' % (loops, time.time() - start)) start = time.time() for loop in xrange(loops): my_list[loop] = my_list[loop][1:] + my_list[loop][0] print('modifying %s elements took %.4f seconds' % (loops, time.time() - start)) start = time.time() for loop in xrange(loops): del my_list[0] print('removing %s elements took %.4f seconds' % (loops, time.time() - start)) start = time.time() transaction.commit() print('committing all above took %.4f seconds' % (time.time() - start,)) del my_list[:loops] transaction.commit() start = time.time() pack() print('packing after removing %s elements took %.4f seconds' % (loops, time.time() - start)) for filename in glob.glob('database.db*'): try: os.unlink(filename) except OSError: pass db = DB(FileStorage('database.db'), cache_size = 2000) def pack(): db.pack() root = db.open().root() root['my_list'] = BList() print('inserting initial data to blist') for loop in xrange(10): root['my_list'].extend(random.read(100) for x in xrange(100000)) transaction.commit() transaction.commit() test_list(root['my_list'])
