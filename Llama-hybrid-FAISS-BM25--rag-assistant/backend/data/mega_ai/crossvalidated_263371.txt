[site]: crossvalidated
[post_id]: 263371
[parent_id]: 246862
[tags]: 
One of the approach is here: http://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html Maybe you can create two RNNs(I never tried this, it just come in my mind): First RNN will look on the series and learn the state. Then you can copy the state to the next rnn which will try to do the stuff you need. You learn both of them end-to-end.
