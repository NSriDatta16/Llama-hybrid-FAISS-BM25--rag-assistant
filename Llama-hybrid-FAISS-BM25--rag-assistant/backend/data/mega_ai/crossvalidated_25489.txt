[site]: crossvalidated
[post_id]: 25489
[parent_id]: 25482
[tags]: 
Your thinking is good. John Tukey recommended binning by halves: split the data into upper and lower halves, then split those halves, then split the extreme halves recursively. Compared to equal-width binning, this allows visual inspection of tail behavior without devoting too many graphical elements to the bulk of the data (in the middle). Here is an example (using R) of Tukey's approach. (It's not exactly the same: he implemented mletter a little differently.) First, let's create some predictions and some outcomes that conform to those predictions: set.seed(17) prediction The plot is not very informative, because all the actual values are, of course, either $0$ (did not occur) or $1$ (did occur). (It appears as the background of gray open circles in the first figure below.) This plot needs smoothing. To do so, we bin the data. Function mletter does the splitting-by-halves. Its first argument r is an array of ranks between 1 and n (the second argument). It returns unique (numeric) identifiers for each bin: mletter n lower[i] Using this, we bin both the predictions and the outcomes and average each within each bin. Along the way, we compute bin populations: classes To symbolize the plot effectively we should make the symbol areas proportional to bin counts. It can be helpful to vary the symbol colors a little, too, whence: binprop With these in hand, we now enhance the preceding plot: abline(0,1, lty=1, col="Gray") # Reference curve points(x,y, pch=19, cex = 3 * sqrt(binprop), col=colors) # Solid colored circles points(x,y, pch=1, cex = 3 * sqrt(binprop)) # Circle outlines As an example of a poor prediction, let's change the data: set.seed(17) prediction Repeating the analysis produces this plot in which the deviations are clear: This model tends to be overoptimistic (average outcome for predictions in the 50% to 90% range are too low). In the few cases where the prediction is low (less than 30%), the model is too pessimistic.
