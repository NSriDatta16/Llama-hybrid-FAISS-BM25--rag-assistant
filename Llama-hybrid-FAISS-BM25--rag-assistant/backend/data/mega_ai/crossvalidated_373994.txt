[site]: crossvalidated
[post_id]: 373994
[parent_id]: 340462
[tags]: 
The term control comes from dynamical systems theory, specifically, optimal control. As Richard Sutton writes in the 1.7 Early History of Reinforcement Learning section of his book [1] Connections between optimal control and dynamic programming, on the one hand, and learning, on the other, were slow to be recognized. We cannot be sure about what accounted for this separation, but its main cause was likely the separation between the disciplines involved and their different goals. He even goes on to write We consider all of the work in optimal control also to be, in a sense, work in reinforcement learning. We define a reinforcement learning method as any effective way of solving reinforcement learning problems, and it is now clear that these problems are closely related to optimal control problems, particularly stochastic optimal control problems such as those formulated as MDPs. Accordingly, we must consider the solution methods of optimal control, such as dynamic programming, also to be reinforcement learning methods. Prediction is described as the computation of $v_\pi(s)$ and $q_\pi(s, a)$ for a fixed arbitrary policy $\pi$ , where $v_\pi(s)$ is the value of a state $s$ under policy $\pi$ , given a set of episodes obtained by following $\pi$ and passing through $s$ . $q_\pi(s, a)$ is the action-value for a state-action pair $(s, a)$ . It's the expected return when starting in state $s$ , taking action $a$ , and thereafter following policy $\pi$ . Control is described as approximating optimal policies. When doing control, one maintains both an approximate policy and an approximate value function. The value function is repeatedly altered to more closely approximate the value function for the current policy, and the policy is repeatedly improved with respect to the current value function. This is the idea of generalised policy iteration (GPI). See 5.1 Monte Carlo Control in [1]. [1] Reinforcement Learning: An Introduction, by Richard S. Sutton and Andrew G. Barto
