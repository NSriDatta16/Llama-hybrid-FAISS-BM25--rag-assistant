[site]: crossvalidated
[post_id]: 162308
[parent_id]: 
[tags]: 
multidimensional inputs, outputs and backpropagation

Let's say I have a neural network in matrix form. Inputs, hidden layer nodes and outputs are represented by row vectors, while the weights are matrices of the sizes [outputRows; inputRows]. Now, let's say I'd like to handle multiple inputs and outputs without having to iterate through columns of row vectors. For output calculation, this should work out without any trouble, as there will just be additional columns after vector multiplication. But for training with multiple input-output value pairs, up to now I relied on iterating through the columns. I couldn't find really meaningful resources regarding backpropagation on multimensional inputs/outputs. Is it possible and/or advisable?
