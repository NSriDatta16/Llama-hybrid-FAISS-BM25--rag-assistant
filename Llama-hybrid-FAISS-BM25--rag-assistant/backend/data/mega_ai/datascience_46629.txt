[site]: datascience
[post_id]: 46629
[parent_id]: 35921
[tags]: 
The previously selected good answer is true in the sense that CNN and RNN where the bests choices the last few years for NLP (combined with unsupervised methods like word2vec, glove or wordpiece). But recent works use the attention neural network called the Transformer. See Attention Is All You Need and BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding . These model now achieves state of the art performance in many NLP tasks.
