[site]: datascience
[post_id]: 93592
[parent_id]: 93526
[tags]: 
First reading the question I thought this is very easy and I started searching and trying out some libraries (i.e. nltk, and spacy). Here are my attempts and clearly showing that none of them works. I was thinking that these libraries will generate a parsing tree or a context-free grammar to detect sentences, but they are splitting based on a certain characters such as periods or commas. So the other solution is to learn a classifier that learns the boundaries of sentences. A simple solution can be to use random forest classifier or SVM to serve as a binary classification task for each token. But the missing part is the data to train the model on and what to consider as labels (a BIO tagging scheme is a good idea here). I include two papers here that can be a good starting point for you to first read their methodology and use the datasets they are mentioning to do the task. Du, Jinhua, Yan Huang, and Karo Moilanen. "AIG Investments. AI at the FinSBD task: Sentence boundary detection through sequence labelling and BERT fine-tuning." Proceedings of the First Workshop on Financial Technology and Natural Language Processing. 2019. Rudrapal, Dwijen, et al. "Sentence boundary detection for social media text." (2015).
