[site]: crossvalidated
[post_id]: 526872
[parent_id]: 526862
[tags]: 
Most MCMC algorithms do require the posterior density to be available up to a normalising constant, which means the likelihood $\ell(\theta_t|x)$ to be available as well in the sense that it can be computed for the actual data $x$ and an arbitrary value of the parameter $\theta$ . For instance, the Metropolis-Hastings algorithm makes a proposal $$\theta'\sim q(\theta|\theta_t)$$ and takes $\theta_{t+1}=\theta'$ with probability $$1 \wedge \dfrac{\pi(\theta')\ell(\theta'|x)q(\theta_t|\theta')}{\pi(\theta_t)\ell(\theta_t|x)q(\theta'|\theta_t)}$$ When the Metropolis-Hastings ratio is larger than one (1) the proposed value is accepted with probability $1$ . The decision to accept (or to move) is therefore based on the value of the target density at the proposed and current values of the parameter. This usually depends in particular on the values of the likelihood function at the proposed and current values of the parameter. Concerning the "ugliness" of the likelihood function, by which I assume a complex or costly function, provided the values of the likelihood function at the proposed and current values of the parameter can be computed in a reasonable time, this does not matter. Situations when the values of the likelihood function at the proposed and current values of the parameter need not be computed include the Gibbs sampler, which does not require an acceptance step specific choices of the proposal $q(\cdot|\cdot)$ so that the ratio $$\dfrac{\pi(\theta')\ell(\theta'|x)q(\theta_t|\theta')}{\pi(\theta_t)\ell(\theta_t|x)q(\theta'|\theta_t)}$$ does not require the full computation of the values of the likelihood function at the proposed and current values of the parameter (as for instance in Murray et al., 2012 , resolution of doubly intractable problems) replacements of the likelihood function with an unbiased estimator as in latent variable models (as in pseudo-marginal algorithms ).
