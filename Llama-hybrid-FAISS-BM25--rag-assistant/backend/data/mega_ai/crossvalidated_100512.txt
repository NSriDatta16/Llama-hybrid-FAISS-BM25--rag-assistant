[site]: crossvalidated
[post_id]: 100512
[parent_id]: 
[tags]: 
How to appropriately represent certain outliers

I am working with a dataset representing a material's 'Range of Coverage', or, a calculated amount of time it is expected to stay in stock. This calculation is based on a material's usage during a period of time. So far, my values have been less than 150; however, I am running into an issue during periods with no material usage as they shoot the calculation up to 99,999. When I analyze this data in my statistical software, the extreme, essentially meaningless, values of these outliers greatly affect my test results. Can anyone recommend a way to 'dilute' these outliers due to their value but at the same time utilize their presence as a statistical measure? In other words, I do not want to completely remove them because their presence is significant but since the value of each observation is being analyzed, what other options do I have to test this dataset? Here is an example dataset which includes both cases - a ROC value of '0' as well as a ROC value of '99,999'. Since these values represent the approximate number of inventory days-on-hand, '0' makes sense but '99,999' does not. Feb-13 - 99,999 Mar-13 - 0 Apr-13 - 34 May-13 - 0 Jun-13 - 99,999 Jul-13 - 44 Aug-13 - 18 Sep-13 - 99,999 Thank you all! MCC
