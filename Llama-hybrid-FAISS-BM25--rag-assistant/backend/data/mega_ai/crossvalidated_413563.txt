[site]: crossvalidated
[post_id]: 413563
[parent_id]: 
[tags]: 
Details of binary logistic regression, estimating $P(Y=1|X)$

I am trying to understand logistic regression, but most sources I have found tend to leave the actual computational step as sort of a "black box", like using r glm(y~x,...) which obscures the underlying compuation. As an exercise, I want to write my own routine for doing (binary) logistic regression which requires me knowing the details. For binary outcomes $Y$ , and some predictor data $X$ , we attempt to model the conditional probability $$ p(X) = P(Y=1|X) = \frac{1}{1+ e^-{\beta X}} $$ and the corresponding linear model $$\mathcal{l} = \text{log}\bigg( \frac{p}{1-p} \bigg) = \beta X$$ How do we now proceed in practice to compute $\beta$ ? In my understanding we have something like a linear system, so that for $n$ measurements & $k$ predictive variables $$l_1 = \beta_0 + \beta_1x_{11} + ... +\beta_k x_{1k}$$ $$l_2 = \beta_0 + \beta_1x_{21} + ... +\beta_k x_{21}$$ $$$$ $$l_n = \beta_0 + \beta_1x_{n1} + ... +\beta_k x_{nk}$$ which could then be solved using standard methods (such as SGD for an appropriate cost function). But how do we compute/estimate the values in $l_i$ ? The observed value of $P(Y=1|X)$ would simply be the scalar $p* = \frac{\sum_{i=1}^n y_i}{n}$ for each row, meaning that the system to be solved would be $$ \text{log}(\frac{p*}{1-p*})\times(1,1,....,1)^T = \beta X$$ Is this correct? I have been testing with the following r code: set.seed(1234) x which gives the coefficients estimates for $\beta$ > fit$coefficients (Intercept) x -2.2261215 0.1651474 > fit2$coefficients (Intercept) x -2.219647e+00 -5.338566e-16 which differ noticably in the estimates of the $x$ coefficent. I thought this may be becuse of the different optimization methods used in the glm() vs lm() methods, but is my understand of the modelling procedure correct?
