[site]: datascience
[post_id]: 118194
[parent_id]: 
[tags]: 
Large change in validation loss, small change in training loss

I'm training a multi-task, multi-label neural network. I am attempting to tune the architecture and am having some trouble interpreting the learning curves. Particularly, when I look at the learning curves for the best performing architectures, the training loss is quite small after the first epoch and decreases very gradually. The validation loss starts very large and decreases much more rapidly than the training loss. There are two things I don't understand. 1) How does a small change in training loss result in a large change in validation loss? 2) Are these curves indicative of over or underfitting? EDIT: I made a mistake in the training loss calculation which makes these learning curves irrelevant
