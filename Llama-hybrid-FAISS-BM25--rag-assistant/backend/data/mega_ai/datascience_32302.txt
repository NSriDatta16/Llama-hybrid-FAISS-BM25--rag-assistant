[site]: datascience
[post_id]: 32302
[parent_id]: 31958
[tags]: 
My suggestion would be a sequence classification approach using Deep Learning, in particular Recurrent Neural Networks , which are proven to be powerful in text processing. For fast prototyping, you should use the Keras API (with Tensorflow backend). In short: Label your dataset (2 classes: vacancies or not-vacancies) Embed every word in your dataset into a vector of integers, using the Embedding layer of Keras Find the "X" most common words in your dataset, where "X" depends on the size of your dataset Constrain your dataset to include only those words and remove the rest Pad or truncate the sequences to have the same length using keras.preprocessing.sequence.pad_sequences() Train an LSTM-RNN on your labeled dataset (simply by inserting a LSTM layer in Keras) and then test it Extra tips for improvement: use a Dropout layer to decrease the variance of your model and also try improving it by combining it with a Convolutional Neural Network (CNN) to exploit spatial relations in the data. This can be easily implemented if you insert a Conv1D layer before the LSTM layer. An excellent reference that I have found online is this .
