[site]: crossvalidated
[post_id]: 601913
[parent_id]: 280665
[tags]: 
This answer focuses not on stability, but on a different related issue that I have not seen addressed in the answers/comments above. There is "conventional wisdom" about LOOCV having higher variance, e.g. quoted from ESL in the question above. This conventional wisdom makes sense to me only if CV with different fold sizes were estimating the same thing. But if the full dataset size $n$ is fixed, then 5-fold CV is estimating MSE for models trained on $n\times4/5$ cases, while 10-fold CV is estimating MSE for models trained on $n\times9/10$ cases, and so on. These are different targets of estimation, so there's no reason to expect a simple relationship between their estimates' variances. Instead, what would happen if we think about using CV to estimate MSE for a fixed training set size ? I modified @JakeWestfall's R code (linked in the question) to carry out 2-fold, 5-fold, 10-fold, and LOOCV with a fixed training set size. I chose to use $n_{train}=36$ to allow for integer sample sizes, so that the full dataset sizes were: $n=72=36\times2/(2-1)$ for 2-fold $n=45=36\times5/(5-1)$ for 5-fold $n=40=36\times10/(10-1)$ for 10-fold $n=37=36\times37/(37-1)$ for LOOCV In other words, for each rep of the simulation: Generate a new dataset of size $n=72$ Carry out 2-fold CV on this full dataset Take just the first 45 cases of the full dataset, and carry out 5-fold CV (so that we have five instances of [training on 36 cases and testing on 9 cases] from among the same 45 cases each time ) Similarly for 10-fold on the first 40 cases of the full dataset Similarly for LOOCV on the first 37 cases of the full dataset Results from 10,000 reps: ## k = 2 k = 5 k = 10 k = n ## mean 1.122 1.123 1.123 1.123 ## variance 0.052 0.068 0.073 0.077 Unsurprisingly, the means are all the same. These are all unbiased estimators of the MSE for models with $n_{train}=36$ . But now that $n_{train}$ is fixed, the variance of $\hat{MSE}$ increases with k. This, to me, matches the intuition from ESL and others. For each rep of the simulation: 2-fold CV is almost the average of 2 independent estimates of $\hat{MSE}$ . (Well, not quite. It's the average of $\hat{MSE}$ over two independent $\hat f(x)$ , but there is dependence between training and test sets.) Meanwhile, LOOCV is almost just a single estimate of $\hat{MSE}$ . (It's the average of $\hat{MSE}$ over $n$ estimates of $\hat f(x)$ , but these $n$ fitted models are so correlated as to be nearly identical, unless there are major outliers.) By this intuition, LOOCV should have higher variance than 2-fold CV; and 5- or 10-fold should be somewhere in between... if they are all trying to estimate the same thing . And indeed, the simulation supports this intuition. Back to the OP's question, and as a contrast to @XavierBourretSicotte's answer: when $n_{train}$ is fixed, "LOOCV has higher variance" does not require instability. Of course, this does not tell us what value of k to choose in the standard situation where $n$ is fixed and $n_{train}$ varies with k! But I hope it helps to illustrate (1) where the "LOOCV has higher variance" intuition came from, and (2) why that intuition breaks down in the standard situation.
