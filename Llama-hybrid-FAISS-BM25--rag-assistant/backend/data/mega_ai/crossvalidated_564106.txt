[site]: crossvalidated
[post_id]: 564106
[parent_id]: 563741
[tags]: 
First, note that for a fixed seed $s$ , you would not have a random output from the simulator, but always the same output, so the covariance $S$ would be zero. So I will remove the dependence of $S$ on $s$ . Also, I will subsume $n$ into $\phi$ , so that we are left with just the parameter vector $\phi$ and the covariance $S$ of the simulator only depends on $\phi$ : $S = S(\phi)$ . The likelihood of given data D for a model $M(\phi)$ , which is completely described by the parameters $\phi$ , is by definition the probability of $D$ under this model : $$ logL(D | \phi) := \log p(D| M(\phi)). $$ So the covariance that you have to use in the formula for $logL$ is the covariance $S(\phi)$ of the model $M(\phi)$ : fitting a model with MLE means you presume that the data $D$ is generated by your model $M(\phi)$ and then you find the $\phi$ that maximizes the belonging probability; you don't fit a model on data that you presume has been created by another model. Now your model, which is the simulator $M(\phi)$ , is Gaussian with both the mean $\mu(\phi)$ and the variance $S(\phi)$ being functions of $\phi$ . The log-likelihood that you want to maximize is: $$ logL(D|\phi) = -\frac{1}{2} \big\langle(D - \mu(\phi)), \: S(\phi) (D - \mu(\phi))\big\rangle. $$ Note that $\Sigma$ is not entering into your model. Since the model is a complex simulator, I presume that the functions $\mu(\phi)$ and $S(\phi)$ are not known. Thus, if you wanted to find the MLE estimation of $\phi$ , you would have to resort to numerical optimization. However, if you want the posterior of $\phi$ , since you mentioned in the OP that you want to sample $\phi$ ), you need to devise an appropriate prior $p_{prior}(\phi)$ for $\phi$ , compute the unnormalized posterior (define $L := exp(logL)$ ): $$ p_{post}(\phi) \propto L(D|\phi) p_{prior}(\phi), $$ and then sample from that, e.g. with some MCMC method. Without any more information, it is impossible to say whether this is more or less appropriate than any of those many ABC methods.
