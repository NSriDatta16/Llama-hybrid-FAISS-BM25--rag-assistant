[site]: datascience
[post_id]: 18305
[parent_id]: 18280
[tags]: 
This was going to be a comment but it grew to an answer. I think there should be some clarification because the question itself is not specifically about visualization but checking the "integrity" of the features. PCA will work for make a generalization of the dataset as a whole. It is a very standard starting point for exploring data. If the first 2 components do show a clear separation, this is a pretty solid indication that at least some projection of your data can well represent your classes. So, short answer is yes . If the first 2 components don't show separation, that does not mean that the features are necessarily bad, it just means that the first two components do not explain the majority of the variability in the dataset. Feature selection is used to check the integrity/importance/value of individual features and how they affect the model. You can use random forest gini importance to rank your features or lasso regularization to with cross-validation to find out how individual features are weighted in a log. reg. model (this does require a little more work as the weightings are not necessarily an exact measurement of variable importance). Feature selection and cross-validation are the most direct ways of determining feature integrity. PCA is mostly a good first pass and helpful visualization.
