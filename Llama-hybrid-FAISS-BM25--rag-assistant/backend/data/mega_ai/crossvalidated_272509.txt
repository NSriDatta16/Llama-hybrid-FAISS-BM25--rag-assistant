[site]: crossvalidated
[post_id]: 272509
[parent_id]: 272385
[tags]: 
The proof is given in the Mother of All Random Generation Books, Devroye's Non-uniform Random Variate Generation , on p.211 (and it is a very elegant one!): Theorem 2.3 (Sukhatme, 1937) If we define $E_{(0)}=0$ then the normalised exponential spacings $$(n-i+1)(E_{(i)}-E_{(i-1)})$$ derived from the order statistics $E_{(1)}\le\ldots\le E_{(n)}$ of an i.i.d. exponential sample of size $n$ are themselves i.i.d. exponential variables Proof. Since \begin{align*} \sum_{i=1}^n e_i &= \sum_{i=1}^n e_{(i)} =\sum_{i=1}^n \sum_{j=1}^i(e_{(j)}-e_{(j-1)})\\ &=\sum_{j=1}^n \sum_{i=j}^n(e_{(j)}-e_{(j-1)}) =\sum_{j=1}^n (n-j+1)(e_{(j)}-e_{(j-1)}) \end{align*} the joint density of the order statistic $(E_{(1)},\ldots,E_{(n)})$ writes as $$f(\mathbf{e})=n!\,\exp\left\{-\sum_{i=1}^ne_{(i)}\right\}=n!\,\exp\left\{-\sum_{i=1}^n (n-i+1)(e_{(i)}-e_{(i-1)})\right\}$$ Setting $Y_i=(E_{(i)}-E_{(i-1)})$, the change of variables from $(E_{(1)},\ldots,E_{(n)})$ to $(Y_1,\ldots,Y_n)$ has a constant Jacobian [incidentally equal to $1/n!$ but this does not need to be computed] and hence the density of $(Y_1,\ldots,Y_n)$ is proportional to $$\exp\left\{-\sum_{i=1}^n y_i \right\}$$ which establishes the result. Q.E.D. An alternative suggested to me by GÃ©rard Letac is to check that $$(E_{(1)},\ldots,E_{(n)})$$has the same distribution as$$\left(\frac{E_1}{n},\frac{E_1}{n}+\frac{E_2}{n-1},\ldots,\frac{E_1}{n}+\frac{E_2}{n-1}+\ldots+\frac{E_n}{1}\right)$$ (by virtue of the memoryless property), which makes the derivation of $$\sum_{k=1}^n(E_k-E_{(1)})\sim \sum_{k=1}^{n-1}E_k$$ straightforward.
