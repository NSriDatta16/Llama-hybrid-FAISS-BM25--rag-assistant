[site]: crossvalidated
[post_id]: 413321
[parent_id]: 
[tags]: 
Early loss stop and strategies to select best model

Run config: BERT_MODEL_HUB = "https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1" BATCH_SIZE = 32 LEARNING_RATE = 2e-5 NUM_TRAIN_EPOCHS = 2.0 WARMUP_PROPORTION = 0.1 SAVE_CHECKPOINTS_STEPS = 500 Training set: Class1 0.301805 Class2 0.197109 Class3 0.139705 Class4 0.130531 Class5 0.083358 Class6 0.067785 Class7 0.065793 Class8 0.013913 Class1 10000 Class2 6531 Class3 4629 Class4 4325 Class5 2762 Class6 2246 Class7 2180 Class8 461 This is the plot of the loss on the training set itself: Options I'm looking at now: Modifying training parameters above Introduce the Validation Loss / Other metrics at each step / n steps. Early stopping based on no loss decrease on training set Automatically selecting the best model from the checkpoints (saving best checkpoint as I go along training) Would benefit from some word of advice. EDIT: I have been using the 1000 checkpoint (loss 1.9151e-3) to predict on my validation set, but I get the same nonsensical "one class only" predictions.
