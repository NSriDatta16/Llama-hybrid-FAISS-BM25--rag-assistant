[site]: crossvalidated
[post_id]: 173126
[parent_id]: 171646
[tags]: 
I think you don't have a clear concept of what a neural network does. The output nodes are mapped to the hidden layer (in this case) by a separate vector of weights for every node, thus the matrix-nature of the algorithm. The fact that one node is pulling the weights in its favor does not contradict that the other are doing the same with ITS RELEVANT mappings (its own vector of weights). That's what makes difficult to visualize the concept of weight optimization/gradient descent, because it is happening in a (probably high) number of different dimensions, while we are used to understand only three spatial ones. Hope to have helped.
