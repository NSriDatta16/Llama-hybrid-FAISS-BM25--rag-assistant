[site]: crossvalidated
[post_id]: 311337
[parent_id]: 
[tags]: 
Algorithms for solving combinatorial complexity problems in machine learning?

Many machine learning problems have combinatorial complexity . For example, in part-of-speech (POS) tagging in NLP, the goal is to predict one of possible $T$ tags for every word in a sentence of length $n$, i.e. we want to compute \begin{equation} \arg \max_{t_1,...,t_n} p(t_1, ..., t_n, w_1, ..., w_n) \end{equation} There are $O(T^n)$ possible tag sequences. One approach to solving this problem is to factor the joint distribution as a Hidden Markov Model (HMM), learn its parameters (e.g. using an EM algorithm) and apply dynamic programming (Viterbi algorithm) to find the optimum sequence of tags: \begin{equation} \pi[i, t] = max_{t^{\prime}}\{\pi[i-1, t^{\prime}] + \log P(t|t^{\prime}) + \log p(w_i|t)\} \end{equation} where $\pi[i,t]$ is the Viterbi recurusion table of size $O(nT)$. Since the max operation above is over $T$ possible tags for each entry in the table of size $n\times T$, the time complexity of the Viterbi decoding is $O(nT^2)$. Thus, we just reduced the original problem of exponential complexity to polynomial time complexity using dynamic programming . I'm interested in examples of algorithms that could be used to reduce a combinatorial problem to polynomial time in the area of machine learning.
