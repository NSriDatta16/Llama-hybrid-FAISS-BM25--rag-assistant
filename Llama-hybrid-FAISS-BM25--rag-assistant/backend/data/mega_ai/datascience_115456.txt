[site]: datascience
[post_id]: 115456
[parent_id]: 115453
[tags]: 
Large pretrained language models are empirically useful. They are empirically useful at prediction for established NLP benchmarks and novel tasks. Since this class of models is the best currently available at prediction across this spectrum, there is no need for "prefiltering steps" and does not matter if the models have memorized previously seen answers.
