[site]: datascience
[post_id]: 15969
[parent_id]: 15960
[tags]: 
It depends: Some algorithms would benefit from near duplicates (such as kNN), while some of them use the outliers of clusters to build their rules on (such as SVM). In my experience it is very important that you understand how your data is structured and what concept you are actually trying to learn, before you settle on a downsampling method. I recently ran into a problem in which I wanted to predict a certain behavior in time, but local dependecies (spacially as in x,y) kept throwing the algorithm in local optima. Downsampling maximizing distibution over x,y actually increased performance of almost all trained models.
