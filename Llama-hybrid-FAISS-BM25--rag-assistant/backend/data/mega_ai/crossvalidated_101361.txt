[site]: crossvalidated
[post_id]: 101361
[parent_id]: 101358
[tags]: 
It sounds like you are reading about statistical models . Such models include: A deterministic part (i.e. something that looks like an algebraic relationship; e.g. a line like $y = a + bx$ is a deterministic relationship where $y$ is determined by a linear function of $x$); and A random part (i.e. something, like noise, that is more or less unknowable... or only knowable in an aggregate sense, like a normal distribution, or some other distribution.). The random part may be called 'noise' or 'error' or something else, depending on the conventions of talking about statistics in a particular discipline. The difference between an observation and the mean of all observations (e.g. $X_{i} - \bar{X}$) is often termed error . In a moving average ($q$) model—e.g. $y_{t} = \mu + \varepsilon_{t} + \theta_{1}\varepsilon_{t-1} + \theta_{2}\varepsilon_{t-2} + \dots + \theta_{q}\varepsilon_{t-q}$—you are explaining $y$ as determined by some mean $\mu$ plus some amount of noise (i.e. a random quantity), plus some amount ($\theta_{1}$) of noise ($\varepsilon_{t-1}$) from last time ($t-1$), plus some (possibly different) amounts of noises to $t-q$ times ago. I do not know the history of who made the MA(q) model up. Some jerk? Some awesome person? No idea. I am not gonna post an excel spreadsheet, but it's not too hard to apply. Suppose the contribution of noise at time $t$ is inversely proportional to how long ago the noise happened. Then $\theta_{1} = 1$, $\theta_{2} = 1/2$, $\dots$, and $\theta_{q} = 1/q$, and the MA(q=3) is: $y_{t} = \mu + \varepsilon_{t} + \varepsilon_{t-1} + \frac{1}{2}\varepsilon_{t-2} + \frac{1}{3}\varepsilon_{t-3}$ Estimating this model is trickier than with a straight up least squares regression... but that's the basic idea of it.
