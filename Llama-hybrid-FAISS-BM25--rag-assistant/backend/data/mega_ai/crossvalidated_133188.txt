[site]: crossvalidated
[post_id]: 133188
[parent_id]: 132726
[tags]: 
To first address the title question: In effect that depends on implementation details. A more specialized implementation may well be faster. Because BEST uses $t$ distributions for data, I don't think there's are simple summary statistics for the mean or variance parameters (this contradicts what I was suggesting in comments earlier). So each of those calculations will be at least O(n) (every new $\nu$ would require a recalculation of likelihood / conditional distributions across the whole sample). This might be why it's slow. -- Here's one example of how to tackle a straight/simple ('drop in') "Bayesian t-test", in this case framed as a regression-on-a-dummy problem that should be about as fast as a single simulation-step of MCMC. Take the set-up here and following the derivation further down , where in this case $\beta$ can be regarded as $(\mu_1,\delta)$, where $\delta$ is the difference in means ($\delta = \mu_2-\mu_1$) and $X$ is a column of 1's and a column, $g$, which is the 0-1 indicator for membership in the second group. Then the posteriors given there can be computed once (no actual matrix inversion is required, I think, but even if it was, it's only 2x2). We can integrate $\sigma^2$ out of the posterior for $\beta$ to get a marginal for $\beta$. Indeed, it looks like you could integrate $\mu_1$ out, then $\sigma^2$ and get what appears to be a closed form (I think $t$-distributed) posterior for $\delta$ alone involving no simulation at all. It doesn't have to be done as a regression of course -- you can do the same calculations more directly. [I set it up that way because the calculations are largely already done for you.] Some slightly more complicated cases can still be done along similar lines. Further complications may be easier done using MCMC -- but in at least some of those cases the calculation can be kept to simple summary statistics which should still result in fast iterations. (If that's still too slow, you might be able to get somewhere via Laplace approximation. There are a number of other possibilities)
