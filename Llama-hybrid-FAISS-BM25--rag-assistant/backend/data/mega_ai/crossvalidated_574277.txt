[site]: crossvalidated
[post_id]: 574277
[parent_id]: 
[tags]: 
Evaluating a survival analysis model against a binary classifier

I'm new to survival analysis and looking to use it to help a telcom company better identify clients at risk of churning. Their current model predicts risk of churning in time windows (1month, 2months, etc) with a GBoost binary classifier, so by using survival analysis I'm hoping to provide a richer continuous risk function (or values) for their clients across time. I've read some articles and tutorials online, and began experimenting with the Cox Proportional Hazards model, but I have some questions on how can I fairly compare both model's performance. They mainly use the lift score, so I was thinking about using the same metric on the risk scores from the Cox model. However, since the survival model wasn't trained on discrete time windows, I don't know how I could do this comparison using the lift score (or other metric). Do you guys have any suggestion on how I can achieve this? Note: In case it help, I'll leave here how I compute the event and duration target features for my dataset: where client_join is the date of when the client joined a service, snapshot is the date when all the current covariates were recorded, study_period is the end of the study period (for my analysis im considering 12 months), so basically any churn event before this date is considered a positive event (event=1), negative otherwise (event=0). For a given snapshot, there can't be churn events before the snapshot. Churn1 and Churn2 are from two different clients!
