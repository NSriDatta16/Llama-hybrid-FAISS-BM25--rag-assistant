[site]: crossvalidated
[post_id]: 134368
[parent_id]: 
[tags]: 
Are there any contemporary uses of jackknifing?

The question: Bootstrapping is superior to jackknifing; however, I am wondering if there are instances where jackknifing is the only or at least a viable option for characterizing uncertainty from parameter estimates. Also, in practical situations how biased/inaccurate is jackknifing relative to bootstrapping, and can jackknife results provide preliminary insight before a more complicated bootstrap is developed? Some context: A friend is using a black-box machine learning algorithm ( MaxEnt ) to classify geographic data that is "presence only" or "positives only." General model assessment is usually done using cross-validation and ROC curves. However, she is using the output of the model to derive a single numeric description of the model output and would like a confidence interval around that number; Jackknifing appears to be a reasonable way to characterize uncertainty around this value. Bootstrapping does not appear relevant because each data point is a unique location on a map that cannot be re-sampled with replacement. The modeling program itself might be able to ultimately provide what she needs; however, I am interested in general if/when jackknifing can be useful.
