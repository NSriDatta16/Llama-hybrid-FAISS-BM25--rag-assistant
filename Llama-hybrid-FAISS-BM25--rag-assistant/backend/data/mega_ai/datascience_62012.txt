[site]: datascience
[post_id]: 62012
[parent_id]: 
[tags]: 
A generalized quadratic loss for deep neural network for multi-class classification

I'm evaluating the possibility to introduce a new loss for the subject described above. Let $l$ be the number of examples, $q$ the number of classes, $p_{i,r}$ the $r$ classifier output on example $i$ and $y_{i,r}$ the binary indicator (0 or 1) if class label $r$ is the correct classification for the observation on pattern $i$ . It would be: $\sum_{i=1}^{l} \sum_{j=1}^{l} (\sum_{r=1}^{q} y_{i,r} log(p_{i,r})) S_{i,j} (\sum_{r=1}^{q} y_{j,r} log(p_{j,r}))$ where the cross entropy loss is used and c.e. losses are correlated by a similarity matrix S positive semi definite. There is any method to write this custom loss on a software framework for deep learning (e.g.: TensorFlow) and have a backtracking algorithm that is based on it?
