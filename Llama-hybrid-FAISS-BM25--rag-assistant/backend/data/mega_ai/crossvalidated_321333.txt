[site]: crossvalidated
[post_id]: 321333
[parent_id]: 
[tags]: 
Log Loss function in scikit-learn returns different values

I have been trying to wrap my head around the log loss function for model evaluation. I understand how the value is calculated after doing the math by hand. In the python module sklearn.metrics the log_loss function returns two different values depending on the order of the input lables. from sklearn.metrics import log_loss y_pred = [[ 0.1 , 0.9 ], [ 0.9 , 0.1 ], [ 0.8 , 0.2 ], [ 0.35, 0.65]] log_loss(["ham", "spam", "spam", "ham"], y_pred) 1.8161075557302173 log_loss(["spam", "ham", "ham", "spam"], y_pred) 0.21616187468057912 What is the correct proceedure? I would have thought that the output for both would be the same. When tackling a real machine learning problem, how will I know which metric is the correct one? PS. Apologies if this question should have been posted in stack-overflow
