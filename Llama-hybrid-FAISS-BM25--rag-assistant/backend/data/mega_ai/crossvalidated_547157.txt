[site]: crossvalidated
[post_id]: 547157
[parent_id]: 547088
[tags]: 
Yes, this is true. $q$ is chosen here from a specific family of functions, parametrized by the intercept and slope of the logistic regression. Any binary probabilistic classification model would work well. The best method would depend on the nature of $p$ , so the more methods you try, the better it would be. Usually, one of the following methods works well enough: logistic regression / neural networks (multilayer perceptron, in your case) / gradient boosting with small decision trees / KNN. Bayesian methods can work with any of these frameworks as a way of regularizing (= assigning priors to) them. I don't know about methods of direct evaluation of entropy, and I think that it is perfectly OK to evaluate it using the entropy of q , given that q itself is well calibrated.
