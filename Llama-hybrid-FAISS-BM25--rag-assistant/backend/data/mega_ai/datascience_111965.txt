[site]: datascience
[post_id]: 111965
[parent_id]: 111951
[tags]: 
You can make experiments using only a subset of the data you already have. Suppose you machine learning should estimate some underlying unknown probability distribution from a given sample. If your probability distribution happens to be a Gaussian normal you only need to estimate the mean and variance but if the probability distribution is more complicated this problem can be a lot harder, especially if you don't have much a priori information on what the distribution could look like. Of couse, the bigger your sample of training data, the better your estimation. But how much better would your estimate be if you could double your training data? Train your model with half or a quarter of the data you have and then try to get a feel for how much the model improves with each increase in the size of the training data.
