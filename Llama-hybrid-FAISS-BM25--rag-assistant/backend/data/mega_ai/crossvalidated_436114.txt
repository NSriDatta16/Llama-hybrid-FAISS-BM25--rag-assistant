[site]: crossvalidated
[post_id]: 436114
[parent_id]: 
[tags]: 
Interpreting hamming loss for multilabel classification

I have a multi label - multi class classifier that aims to predict the top 3 selling products out of 11 possible for a given day. Using scikit learn's OneVSRest with XgBoost as an estimator, the model gets a hamming loss of 0.25. Im not familiar with HL, I have mainly done binary classification with roc_auc in the past. Is this an okay score and how can I describe the effectiveness of the model? does it mean that the model predicts 0,25 * 11 = 2,75 labels wrong on average?
