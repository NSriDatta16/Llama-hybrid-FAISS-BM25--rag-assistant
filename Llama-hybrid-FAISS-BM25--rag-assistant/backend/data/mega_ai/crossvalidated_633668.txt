[site]: crossvalidated
[post_id]: 633668
[parent_id]: 
[tags]: 
Outlier detection on a measurement stream. Decision theoretic, Bayesian approaches?

I have a stream of real valued measurements $x_1, x_2, \dotsc$ that I expect to be, for the most part, normal distributed with some unknown mean $\mu > 0$ and unknown variance $\sigma^2$ . However, once in a while I have an outlier that is so much larger than $\mu$ that it is unlikely to come from the same distribution, and I want to detect these outliers. I also allow for the possibility that $\mu$ and $\sigma^2$ may vary (very) slowly over time (hence the windowed approach below). I have a heuristic solution that works as follows. At step $n$ , estimate the mean $\mu$ and variance $\sigma^2$ of the normal distribution over the $M$ latest measurements $X_n = (x_{n-M+1}, x_{n-M+2}, \dotsc, x_n)$ , for some appropriate window length $M$ . I use standard sample mean and sample variance estimators for this. Then use these estimates, say $\hat \mu_n$ and $\hat \sigma_n^2$ , to compute the log likelihood $$y_n = \ln p(X_n | \hat \mu_n, \hat \sigma_n^2)$$ over the same window. Now, if $x_n$ is one of the rare outliers, then the data $X_n$ will be poorly fit by a gaussian hypothesis, and hence $y_n$ will be significantly smaller than $y_{n-1}$ . I use something like a simple threshold to detect this, and discard $x_n$ as an outlier. (I also discard it from the measurement stream, so that it is not included in upcoming parameter estimates.) The above seems to work fine, but I would prefer something with more precise underpinnings. I have tried to formulate it as a decision theory problem. Basically, I consider the observations to be divided into two classes $C_1 = \text{"normal"}$ and $C_2 = \text{"outlier"}$ . Then the optimal decision rule (in the sense of fewest misclassifications) is the one that assigns $x$ to $C_1$ if $p(C_1 | x) > p(C_2 | x)$ (see for example Bishop's PRML, section 1.5.1). There are two issues with that approach here though: I am trying to infer $p(x | C_1)$ and classify observations simultaneously, but the classification affects the inference, leading to a circularity issue. I have no model of $p(x | C_2)$ , so I cannot use Bayes' rule to evaluate $p(C_1 | x)$ and $p(C_2 | x)$ . I only know that $\mathrm E[x | C_2] > \mathrm E[x | C_1] = \mu$ , and that the prior $p(C_2)$ is small. If $x$ were a discrete variable, then I could have used $p(x | C_2) = 1 - p(x | C_1)$ to overcome the second issue, but alas. I have also considered a fully Bayesian treatment, with some prior $p(\mu_1, \sigma_1^2, \mu_2, \sigma_2^2)$ for the parameters of the two classes (now supposing that $p(x |C_2)$ is gaussian as well). The prior could, in principle, encode the requirement $\mu_1 , and I think we could (again in principle) integrate over the parameters, conditioned on the data, to obtain $p(x_n \in C_1 | X_n)$ . In reality, however, I suspect this will be difficult. What standard approaches are there to this sort of problem? Can any of my ideas be salvaged? What would you suggest? Ideally I would like to keep it simple.
