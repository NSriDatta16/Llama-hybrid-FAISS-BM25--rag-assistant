[site]: crossvalidated
[post_id]: 235162
[parent_id]: 
[tags]: 
Fitting a Known Function with a Feedforward Neural Network

Given the following known function $$ f(x, t) = e^{-t}\|x\|_2 - 1, $$ where $x \in R^2$ and $t \in R$, I would like to fit it with a neural network by sampling pairs of the form $\{(x,t),f(x,t)\}$ according to some distribution (uniform in this case). I would like the approximation to be good in $-5 \le \|x\|_\infty \le 5$ and $0 \le t \le 2.5$. Unless I am mistaken, I believe this function is continuous so it should be approximated arbitrarily well by a single layer NN. To check how well the fit is doing, I grid the $x$-dimension and the $t$-dimension and compute exact values. So far, I have been trying to fit a neural net and I can't seem to reduce the error below ~0.1 for all the time "t" slices, which is really bad, given that around $t=1.5$ most of the values of $f(x,t)$ in the domain of x specified above are roughly between -1 and 0, so an error of 0.1 I believe is quite large. I am using tensorflow. I've tried NNs of 3-5-1,3-10-1,3-20-1,3-100-1,3-200-1 neurons. I have also used deeper networks, but I'd like to stay shallow if possible. I've tried Gradient Descent, GD with Momentum and AgaGrad. The first two barely help, Adagrad does well in the beginning and then it performs more and more poorly. I have tried tanh and ReLu for my activations. They don't seem to make much of a difference.. Any help, suggestions, papers or information that could help me out would be greatly appreciated.
