[site]: crossvalidated
[post_id]: 421927
[parent_id]: 
[tags]: 
Neural Networks input data normalization and centering

I'm learning Neural Networks and I grasped the algebra behind them. I'm now interested in understanding how normalization and centering of the input data affect them. In my personal learning project (Regression with NN) I've transformed my input variables to a range between 0 and 1 using the following function: normalize The NN model fits well and has an acceptable out-of-sample prediction error. However, I read in other questions that scaling the inputs to have mean 0 and a variance of 1 is advised for NN. I don't fully understand: how this transformation works better for NN against the min-max normalization between 0 and 1. how can I assess which transformation to apply in my data?
