[site]: crossvalidated
[post_id]: 531558
[parent_id]: 
[tags]: 
Why do we need to exploit when training an agent in reinforcement learning?

I have been studying reinforcement learning lately for a robotic project but I have been confused about one thing in particular. When the agent is learning during the training phase, why is it important that the agent exploits rather than explores? My idea is that since it's learning, it should be free to explore different policies and not restrict it to any degree of exploitation. This way, each step will certainly be investigated and every combination of steps in an episode will be traversed. Isn't it better this way or am I missing an important piece of the puzzle?
