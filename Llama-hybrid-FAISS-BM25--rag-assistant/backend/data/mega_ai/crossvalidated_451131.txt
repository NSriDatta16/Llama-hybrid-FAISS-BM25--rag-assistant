[site]: crossvalidated
[post_id]: 451131
[parent_id]: 451128
[tags]: 
I am suggesting a general solution for any model that you can also use to neural networks as well. Unfortunately, I am not a R user. So, I cannot ensure that the R functions for R below really work. You may select features considering the importance of the features for out of sample prediction. In this context, I suggest two very interesting and general methods that you can use: 1) Permutation importance : The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled Solution in R : Permutation importance in R 2) Shap values : It is not an easy concept since it is based in game theory, but it shows the importance of each feature. Solution in R : Shap values in R
