[site]: datascience
[post_id]: 85561
[parent_id]: 
[tags]: 
Is padding the right way to allow your model to make prediction with test sequences of shorter lengths?

Say I have a RNN-lstm encoder-decoder model trained on fixed timesteps (no padding when training, all sequences are treated as if having the same lengths). My testing criteria requires me to provide input sequences with lengths shorter than the fixed length on which my model was trained. In this case, if I want to use model.predict() to make predictions, I would have to pad the test sequences in order to provide arrays with the same dimensions (which is required by the model.predict() method). I am wondering if it's ok to just stick to model.predict() and pad the shorter sequences if I want to make predictions with shorter test sequences?
