[site]: crossvalidated
[post_id]: 630954
[parent_id]: 
[tags]: 
Definition of recurrent stochastic process, in general

This interesting question: Recurrence definition for a Markov chain gives the definition of a recurrent state for some discrete process. I was wondering, in the case of a continuous (time) process, what is the correct way to define a state $y$ as recurrent? In that case, would the (first) sum become an integral? I imagine that I might consider the probability of a "continuous" union of events, but how would I actually represent that? What about the very general case where we consider a stochastic process of any nature (discrete and continuous, mixed, etc.)? Is there a general name for the class of processes where all the (interesting) states considered are recurrent?
