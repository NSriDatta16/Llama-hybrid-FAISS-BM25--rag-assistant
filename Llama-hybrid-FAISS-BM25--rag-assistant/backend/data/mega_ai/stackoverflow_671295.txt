[site]: stackoverflow
[post_id]: 671295
[parent_id]: 671260
[tags]: 
One user image ~ 100kb, so let have 10 000 users in database, each user will have in average 5 images, so we will have 5 terabytes DB, and each image output will be executed via a DB and this extra DB traffic will reduce the general DB server perfomance. ... you may use the DB cluster to avoid this, but suppose it is expensive User report about error on live database, (on test - all works correctly), how would you create dump an unpack it on developers machine? How much time it will take? In one moment you can decide to put images on some CDN, what will be the changes in your source code?
