[site]: crossvalidated
[post_id]: 315007
[parent_id]: 
[tags]: 
Estimation and Elimination of both Trend and Seasonality with a Moving Average Filter

In the book «Introduction to Time Series and Forecasting», by Brockwell and Davis, the authors state in section 1.5.2.1 (3rd edition) something which I summarise below. Sample: $\{x_1,..., x_n\}$. We first estimate the trend by applying a Moving Average Filter (MAF) chosen specially to eliminate seasonality and to dampen the noise. If the period $d$ is even, i.e. $d=2q$, then $$\hat m_t=\frac{0.5x_{t-q}+x_{t-q+1}+...+x_{t+q-1}+0.5x_{t+q}}{2q}$$ If period is odd, then use the simple MAF: $$\hat m_t=\frac{\sum_{j=-q}^{q}x_{t+q}}{2q+1}$$ Why does the first estimation eliminate seasonality? Is it because it considers the terms $x_{t-q},x_{t+q}$? Afterwards, the authors also state something as: After deseasonalizing the data, we reestimate the trend from the deseasonalized data. This reestimation is done in order to have a parametric form for the trend that can be extrapolated for the purposes of prediction and simulation. In what precise way is the trend reestimation helpful for the purposes of prediction and simulation? and why not just use the 1st trend estimation? Any help would be appreciated.
