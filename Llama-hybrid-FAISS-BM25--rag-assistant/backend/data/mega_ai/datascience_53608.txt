[site]: datascience
[post_id]: 53608
[parent_id]: 53563
[tags]: 
In Grid Search, Random Search , we trained different independent model i.e. irrespective of the outcome of previous models and later evaluate all these independent models. We have another automatic technique for hyper-parameter optimization, known as Bayesian HyperOpt. It took the references of previous model and try to identify the best new set of hyper param and trained a new model. This two step process gets repeated, until we get the desired results. You can get many online references for complete implementation. Although I could not find any approach for batch by batch, I thought its worth to mention Bayesian approach.
