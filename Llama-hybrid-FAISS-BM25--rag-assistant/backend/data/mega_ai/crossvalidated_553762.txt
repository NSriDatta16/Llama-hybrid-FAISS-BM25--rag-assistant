[site]: crossvalidated
[post_id]: 553762
[parent_id]: 
[tags]: 
How is it possible to have $P(A|B \cup C)$ lower than both $P(A|B)$ and $P(A|C)$?

Let's say we investigate disease probability given two symptoms. Thus we have 3 variables: A) has disease B) has symptom 1 C) has symptom 2 We have following data: Now we want to see which symptom makes probability of disease higher. First we calculate probability of disease when having symptom 1. We can easily calculate that conditional probability P(A|B) = 2/3 as there are three cases of symptom 1 and two cases of disease when having symptom 1 . We do the same for symptom 2. As there are three cases of symptom 2 and two cases of disease when having symptom 2 the conditional probability P(A|C) = 2/3 Now we want to get some reference value, which would tell us what is overall probability of disease when having at least one symptom. So we calculate P(A|BâˆªC) = 1/2 as there are 4 cases with at least one symptom, and in 2 of them disease is also present. However, how can we explain the fact, that having symptom 1 without consideration of symptom 2 (and vice versa) leads to higher probability of disease, than having at least one these symptoms? If there would be 50 symptoms in dataset and we need to tell which of them makes the probability of disease lower than case has random set of symptoms we could not do that, as the reference value (which I would intuitively expect to be ~average) is actually the lowest one? How should I define the reference general probability that random combinations of symptoms leads to disease? One way that I tried would be to calculate this reference, would be to multiply each row where disease is present with number of present symptoms in that row and then divide sum of this by total sum of symptoms, followingly: Thus I get 4/6 = 2/3 . Is this approach correct? If yes, is it called somehow?
