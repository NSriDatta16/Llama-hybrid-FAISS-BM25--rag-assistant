[site]: crossvalidated
[post_id]: 397822
[parent_id]: 397556
[tags]: 
Hm, benchmarking neural networks is tricky for many reasons a) they are typically used on datasets where you would not apply traditional methods because the latter (off-the-shelf methods) would not perform well there (i.e., you would apply CNNs directly to images instead of some sort of landmark features extracted from images; you would apply RNNs to raw text data -- or word embeddings at the least -- instead of bag-of-word models) b) there are many, many more architectural settings and tuning parameters to consider A recent study that comes to mind, although particular to a dataset, which I wouldn't consider ideal for DL -- and they only used a simple MLP model -- would be Koutsoukas A, Monaghan KJ, Li X, Huan J: Deep-learning: investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data. Journal of Cheminformatics 2017, 9. For some benchmarks regarding CNN architectures, for example, consider Canziani, Alfredo, Adam Paszke, and Eugenio Culurciello. "An analysis of deep neural network models for practical applications." arXiv preprint arXiv:1605.07678 (2016).
