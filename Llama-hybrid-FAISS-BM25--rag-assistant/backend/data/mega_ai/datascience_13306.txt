[site]: datascience
[post_id]: 13306
[parent_id]: 
[tags]: 
Fit Decision Tree to Gradient Boosted Trees for Interpretability

I was wondering if there is literature on or someone could explain how to fit a decision tree to a gradient boosted trees classifier in order to derive more interpretable results. This is apparently the approach that Turi uses in their explain function which outputs something like this: Turi's explain function: from their page here . I know that for random forests you can average the contribution of each feature in every tree as seen in the TreeInterpreter python package, but this seems to be a different method since it is focused on exact splits and one decision tree. Does anyone know anything more about this method for interpreting gradient boosted trees?
