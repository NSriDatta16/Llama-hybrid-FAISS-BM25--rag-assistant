[site]: datascience
[post_id]: 122042
[parent_id]: 
[tags]: 
Inverse reinforcement learning with trajectories only

Inverse reinforcement learning (IRL) is a task that can learn a reward from other agent behaviour. Most IRL paradigms assume that dynamics of environment is known, that is the transition probability and agent's policy are given. However, in my problem, the transition probability and specific policy of the agents are unknown and the only thing I have is a bounch of sample trajectories consisted by state and action sequences. So how can I do IRL on such task ? So far, the only example is the typical linear IRL discussed by AY.Ng ( Algorithms for Inverse Reinforcement Learning ). However, the solution seems not elegant because we still need to define a set of policies as benchmark, which is not deterministic. Is there any unified framework to do IRL task with sampled trajectories only ? Non-parametric method might be a better solution.
