[site]: crossvalidated
[post_id]: 642600
[parent_id]: 642511
[tags]: 
You can use results from K-means to explore cluster validity using other methods, based on different distance methods. Firstly, I would recommend looking at the effect of various feature transformations (normalization, mean-zero standardization, and percentiles) on cluster validity. That is, transform feature values first, then run K-means, then generate your plot. There are also a number of different estimators one can use for cluster validity, such as Davies-Bouldin index, Dunn's index, Silhouette distance, Hubert's $\Gamma$ statistic, etc. In the plots below, I show the average object to cluster distance as a function of $k$ using 4 distance metrics (Euclidean, Manhattan, Chebychev, Canberra) for the raw, normalized, and mean-zero standardized feature values. You can see that when feature values are standardized, the Canberra distance shows are very distinct knee at $k=3$ , and so does Chebychev.
