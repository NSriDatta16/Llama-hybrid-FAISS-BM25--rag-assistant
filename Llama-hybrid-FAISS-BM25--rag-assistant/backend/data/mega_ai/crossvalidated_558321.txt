[site]: crossvalidated
[post_id]: 558321
[parent_id]: 345147
[tags]: 
You should use the output from margins (though possibly modified or augmented). This really depends on the question you are trying to answer by running this probit. Your question lacks that info, so I will tell you what Stata calculated and give some suggestions about what I might do in your shoes. The output of margins in an average marginal effect of mino, which in this case corresponds to $$AME_{mino}(obrat,delinq) = \frac{1}{N} \sum_{i=1}^{N} \left[\Pr(approve_i \vert mino_i = 1, obrat_i,delinq_i)- \Pr(approve_i \vert mino_i = 0, obrat_i,delinq_i) \right]$$ In other words, this means you predict the outcome as if everyone had mino set to one, then predict as if everyone had a mino of zero take the difference between (1) and (2) calculate the mean of those differences in the estimation sample All other variables are set to observed values rather than counterfactual ones, and you are averaging across observations with different changes in probability (since they have different covariates). There are some more details on the math relating probabilities and coefficients here . In your case, you have a drop in the expected probability of approval of 13 percentage points (-.13 on a [0,1] scale) associated with everyone having a mino of 1 versus a mino of zero. This is very much statistically different from zero. The interactions in non-linear models are hard to interpret on their own because of the reasons outlined in Ai and Norton's 2003 EL paper , and because they are not on the probability scale. Personally, since you have one covariate that is continuous and two that are discrete, I would also do something like this: margins delinq, dydx(mino) at(obrat = (a(b)c)) marginsplot where a(b)c is a numlist with reasonable values of obrat. This will give you the effect of mino for various combinations delinq and obrat. Averaging can obfuscate some interesting patterns. Here's an example of that where the effect of foreign origin has a positive effect on good car mileage, but there are some important differences for expensive cars that are light versus heavy: Here the effect of foreign tapers off at zero for heavy cars once price gets to ~\$5K, but becomes negative for expensive light cars at around $6K. On average, since most cars are actually cheaper than 6K, the average marginal effect is positive and insignificant. Here's the code that generated the graph above: . sysuse auto, clear (1978 automobile data) . generate high_mpg = mpg>22 . generate heavy = weight>3200 . label define heavy 0 "Light Cars" 1 "Heavy Cars" . label values heavy heavy . probit high_mpg (i.foreign i.heavy)##c.price, nolog Probit regression Number of obs = 74 LR chi2(5) = 44.83 Prob > chi2 = 0.0000 Log likelihood = -25.556805 Pseudo R2 = 0.4673 --------------------------------------------------------------------------------- high_mpg | Coefficient Std. err. z P>|z| [95% conf. interval] ----------------+---------------------------------------------------------------- foreign | Foreign | 4.133345 2.521531 1.64 0.101 -.8087655 9.075455 | heavy | Heavy Cars | 2.271217 4.352434 0.52 0.602 -6.259398 10.80183 price | .0004709 .0005511 0.85 0.393 -.0006092 .0015509 | foreign#c.price | Foreign | -.0007594 .0005716 -1.33 0.184 -.0018797 .0003609 | heavy#c.price | Heavy Cars | -.0009399 .0009511 -0.99 0.323 -.0028041 .0009242 | _cons | -1.75037 2.311541 -0.76 0.449 -6.280908 2.780168 --------------------------------------------------------------------------------- Note: 3 failures and 0 successes completely determined. . margins heavy, dydx(foreign) at(price = (3e3(1e3)1e4)) Conditional marginal effects Number of obs = 74 Model VCE: OIM Expression: Pr(high_mpg), predict() dy/dx wrt: 1.foreign 1._at: price = 3000 2._at: price = 4000 3._at: price = 5000 4._at: price = 6000 5._at: price = 7000 6._at: price = 8000 7._at: price = 9000 8._at: price = 10000 ------------------------------------------------------------------------------- | Delta-method | dy/dx std. err. z P>|z| [95% conf. interval] --------------+---------------------------------------------------------------- 0.foreign | (base outcome) --------------+---------------------------------------------------------------- 1.foreign | _at#heavy | 1#Light Cars | .5676583 .27756 2.05 0.041 .0236508 1.111666 1#Heavy Cars | .6459791 .2322063 2.78 0.005 .1908631 1.101095 2#Light Cars | .337514 .1553374 2.17 0.030 .0330583 .6419697 2#Heavy Cars | .3099325 .275026 1.13 0.260 -.2291085 .8489736 3#Light Cars | .0994343 .2089884 0.48 0.634 -.3101753 .509044 3#Heavy Cars | .0343267 .0932036 0.37 0.713 -.1483489 .2170024 4#Light Cars | -.1160091 .2589875 -0.45 0.654 -.6236153 .391597 4#Heavy Cars | -.007607 .0234016 -0.33 0.745 -.0534732 .0382592 5#Light Cars | -.2970767 .2291851 -1.30 0.195 -.7462713 .1521179 5#Heavy Cars | -.002826 .0157615 -0.18 0.858 -.033718 .0280661 6#Light Cars | -.4482997 .196322 -2.28 0.022 -.8330838 -.0635156 6#Heavy Cars | -.0006149 .0055651 -0.11 0.912 -.0115223 .0102925 7#Light Cars | -.5781679 .2068051 -2.80 0.005 -.9834984 -.1728373 7#Heavy Cars | -.0001074 .001419 -0.08 0.940 -.0028886 .0026738 8#Light Cars | -.6906892 .2266041 -3.05 0.002 -1.134825 -.2465533 8#Heavy Cars | -.0000152 .0002754 -0.06 0.956 -.000555 .0005245 ------------------------------------------------------------------------------- Note: dy/dx for factor levels is the discrete change from the base level. . marginsplot Variables that uniquely identify margins: price heavy . margins, dydx(foreign) Average marginal effects Number of obs = 74 Model VCE: OIM Expression: Pr(high_mpg), predict() dy/dx wrt: 1.foreign ------------------------------------------------------------------------------ | Delta-method | dy/dx std. err. z P>|z| [95% conf. interval] -------------+---------------------------------------------------------------- foreign | Foreign | .0756642 .0995296 0.76 0.447 -.1194101 .2707386 ------------------------------------------------------------------------------ Note: dy/dx for factor levels is the discrete change from the base level.
