[site]: crossvalidated
[post_id]: 377026
[parent_id]: 377014
[tags]: 
It's not a problem, at least not from an algorithmic point of view, if you just set $y = 101$ (or some arbitrary number $> 100$ ) for those observations where all you know is that $y > 100$ . RF / GBM can split their tree nodes on, say, $y \leq 100$ to branch off all of those observations should such appear to be a useful split. Naturally this won't be as good as if you had all the $y$ values, as you won't be able to split a node on, for example, $y \leq 125$ , but that's not an algorithm issue, it's a data issue, and there's not much you can do about that other than perhaps try to impute the censored $y$ values using other methods - which might just make things worse if the imputation isn't accurate enough. Consider the following trivial XGBoost example, where we first run with uncensored features, then with one feature mildly censored: library(xgboost) x which generates the following results: [1] train-rmse:10.668740 test-rmse:10.320863 [101] train-rmse:10.279332 test-rmse:10.096274 [201] train-rmse:10.025436 test-rmse:9.976359 [301] train-rmse:9.836189 test-rmse:9.899672 [401] train-rmse:9.688129 test-rmse:9.846857 [501] train-rmse:9.568161 test-rmse:9.817383 [601] train-rmse:9.454921 test-rmse:9.796544 [701] train-rmse:9.346735 test-rmse:9.784290 [801] train-rmse:9.244619 test-rmse:9.774979 [901] train-rmse:9.149431 test-rmse:9.770299 [1000] train-rmse:9.057386 test-rmse:9.769593 Now for the censored version, where we substitute $1$ for all values of x[,10] that are $> 1$ : x_censored The results are: [1] train-rmse:10.668740 test-rmse:10.320863 [101] train-rmse:10.279332 test-rmse:10.096274 [201] train-rmse:10.025436 test-rmse:9.976359 [301] train-rmse:9.837773 test-rmse:9.900777 [401] train-rmse:9.688486 test-rmse:9.848269 [501] train-rmse:9.568610 test-rmse:9.822435 [601] train-rmse:9.454171 test-rmse:9.803899 [701] train-rmse:9.347045 test-rmse:9.790157 [801] train-rmse:9.243943 test-rmse:9.781143 [901] train-rmse:9.148064 test-rmse:9.775464 [1000] train-rmse:9.054367 test-rmse:9.776827 As you can see, the results are not really significantly different, but that's because the censoring was limited to one out of 10 features and only occurred in about 16% of the cases. The fundamental learning, though, is that it doesn't break these types of algorithms if you have to use censored data.
