[site]: datascience
[post_id]: 103737
[parent_id]: 
[tags]: 
Extracting linear trends from a dataset

Consider a sensor measurement f that varies with both temperature T and the properties of the fluid being measured. The temperature changes through each day and the fluid properties can be assumed to vary less frequently. If I cross plot the data in Excel then by eye I can very easily draw a straight line through some points and translate that line horizontally and "voila" that same line fits through other clusters of plots. So if that line has slope -1/a then all I need to do instead of plotting f versus time I actually plot f + a T versus time I get a curve which does not have the temperature dependence and is now indicative of fluid property. Cool. So my question is how to automate this extraction of a . My plan today is to set objective function as the L1 norm of the derivative of the time series and minimize over a as that might give a time series of many points with almost zero derivative and a few jump discontinuities where it decides the fluid has changed [as opposed to an L2 that would smear everything out]. But my thoughts are that this feature extraction is likely already covered in some text book somewhere and what I am really missing is the better vocabulary to look it up :-) Any suggestions? Thanks
