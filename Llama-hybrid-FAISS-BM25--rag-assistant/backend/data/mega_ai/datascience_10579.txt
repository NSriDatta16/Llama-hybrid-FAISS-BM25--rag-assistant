[site]: datascience
[post_id]: 10579
[parent_id]: 10558
[tags]: 
If you're interested more generally in speech understanding or speech-to-text, some approaches to natural language parsing and speech-to-text use recurrent neural networks or Hidden Markov processes for learning, as well as a number of signal-processing algorithms to extract more data from the input stream that just raw audio. Keep in mind people have spent their whole careers on this work, so it's not a good problem to just pick up and run with unless you're a MS/PhD candidate looking for a capstone/dissertation project. Here's the iconic paper from Bell Labs that inspired a lot of the DFA/HMM solutions. I've yet to find a paper that does a good job of explaining how to actually implement the RNN style solutions, but here's one in case you're interested. It's likely that Alexa uses some combination of these methods, but I doubt you're going to get any good answer out of anyone here. After all, it's an important Amazon project and it's not like their engineers are going to come on Stack Overflow and start giving away trade secrets.
