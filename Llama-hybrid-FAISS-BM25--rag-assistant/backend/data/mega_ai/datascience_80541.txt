[site]: datascience
[post_id]: 80541
[parent_id]: 
[tags]: 
How to combine two different embeddings in the best way possible?

I have two models which are giving two books embedding Ml_model_a => book1_embedding [ 1, 200 ] Ml_model_b => book2_embedding [ 1, 200 ] I am building a third model which will take these two different embeddings to tell me which book to choose. Now my final layer is the classification between 0,1 ( which book to choose ). How to learn these embeddings best way possible to classify better? What I have tried yet : If I am averaging those embeddings and then sending to one model, then embeddings are losing a lot of information, so I am using concatenation method. But it's not classifying well, Is there any other model, a technique I could use to enhance the capability of learning to book embedding and predict which book to take?
