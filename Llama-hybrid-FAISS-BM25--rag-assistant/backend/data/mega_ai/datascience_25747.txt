[site]: datascience
[post_id]: 25747
[parent_id]: 25745
[tags]: 
Depending on your algorithm, it may have different interpretations. Suppose you are using SVM with kernels , it means your input data is exactly between two data points with different classes or if you are using linear kernels in SVM it means that your data is on the separator line . If you are using Neural Networks , this is the Probability of each class . In such cases there maybe different explanations for this phenomenon. Suppose that you are trying to classify images of green and purple cats! and suppose that you have two same cats with both colors, then your classifier may output this result Another interpretation may also exist. suppose that you have unbalanced data-set for your two classes. suppose that there are same feature vectors of both classes. in such cases, the distribution of your samples overlap. A class which has more data samples would be the winner and will occupy the space much more than the class with less samples. In such cases, if you get 50 percent as the output, You can not tell that both classes have same expectations. If I want to clarify this more, I would do that with this example. Suppose that you have a car classifier for distinguishing between white and blue cars. during training you had 100 images of blue car and 20 images of white car . During recall phase , if for an arbitrary image you have 50 percent for each class, you can never say that the image has same probability to be each one at all .
