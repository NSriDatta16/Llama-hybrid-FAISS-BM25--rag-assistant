[site]: datascience
[post_id]: 122908
[parent_id]: 89799
[tags]: 
Cross-validation for time series is a very complex topic. My impression is that there is no final consensus on what the best approach is. For a quick reference, you can e.g. consult this thesis or the documentation related to the tscv library . If you are dealing with an autoregressive problem, where independent variable and target coincide, I think the issue is slightly easier than the general case, though. The way I see it, in the case of a neural network model, of the necessity for i.i.d. data boils down to using the mean gradient value over a batch. If your windows are not i.i.d., such mean will obviously be a biased estimator of the true gradient. Other than that, at prediction stage the process is purely deterministic. That is, 'past' or 'future' doesn't matter if you use a trained model to predict $t$ +1 given the previous ( $t-N$ .., $t$ ) timesteps. As a pre-emptive answer, one can imagine to flip the time series and re-fit, and the accuracy of the prediction should not be affected by the causality ( assuming the causality dependency can be reversed ). It also helps thinking of the time series in terms of its Fourier transform. That one is actually free from the time dependency, and nobody would argue that you can use a FFT for drawing samples at any timestep $t$ along the sequence. So yes, in practice the points are causally connected, but from the point of view of the analysis, this caveat is only used in the creation of the windows and in the minimization step. Again, this is only my interpretation and I stress that I only sustain it in the case of autoregressive tasks, using NNs, where there train/test windows do not overlap. I am open to other point of views, please leave me a comment if I overlooked some concept.
