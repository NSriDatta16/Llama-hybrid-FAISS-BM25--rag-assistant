[site]: crossvalidated
[post_id]: 467984
[parent_id]: 
[tags]: 
sparsity assumption in Bayesian linear regression

I have a simple question. Is the assumption of sparsity only useful when p > n , that is when you have a large number of features compared to observation. When I use a Uniform prior, I can see that a lot of coefficients (that held be zero) are not estimated to be zero. I was wondering if a sparsity assumption might help alleviate this problem. However, re-running with a sparse Laplace prior does not shrink the coefficients as much as I would have hoped. I am re-running with more mass on 0 for the Laplace prior, but not sure if in the regime of n >> p this will be useful. Any suggestions/comments will be very much appreciated. Thanks!
