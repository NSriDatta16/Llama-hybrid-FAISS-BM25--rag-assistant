[site]: stackoverflow
[post_id]: 4771872
[parent_id]: 4771506
[tags]: 
This is a difficult problem, and the root of the difficulty is in capturing the order in which the updates arrive. If the updates already have an associated (fine grained) timestamp, then the solution is fairly straight-forward: Define a Value class that hold the actual value and a timestamp. It needs a synchronized setIfNewer(ActualValue v, Timestamp t) which updates the actual value if the supplied timestamp is more recent. Define the map as ConcurrentHashMap . Use putIfAbsent to put values into the map. If the putIfAbsent() returns a non-null value, use setIfNewer(...) to update it. Note that this only works if the map updates can keep up in the long term ; i.e. average data rate is not too high to cope with. If the updates do not have an associated timestamp, then you've got a problem. If you are having difficulty keeping up with the updates, then you will have difficulty adding an timestamp to the updates that accurately reflects the arrival time. And that means that there is a risk that updates will be (in effect) reordered. (If this is the case then I don't think the problem is solvable ... without changing the problem; see below.) Some things that might work: Do some profiling / performance analysis to figure out where the bottleneck really is. It might not be in doing the map updates at all. (After all ConcurrentHashMap is designed to be highly scalable.) If there is strong affinity between the threads and the key values, then you could try 1) de-duping the updates in each thread using a per-thread LRU map, or 2) use a per-thread counter instead of a timestamp. You could try partitioning the map based on the keyspace. You could try adding more processors and/or more memory ... depending on what your profiling and monitoring are reporting. You could try partitioning the entire application based on the keyspace. If the real problem is that the application cannot keep up, this may be the only possible approach.
