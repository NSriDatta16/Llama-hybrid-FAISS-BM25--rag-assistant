[site]: crossvalidated
[post_id]: 623299
[parent_id]: 
[tags]: 
How to create representative training, validation, and test sets when working with time series data?

In my application, I am working with a relatively long time series of daily market index percentage returns (many years) and am trying to model the dependence structure of the returns from a pure time series perspective (if there is any) and analyse the probabilistic properties of the residuals after any dependence is removed or the original return series if there is no dependence between days. Technically, this is a univariate time series taking values in $(-1, \infty)$ . I have employed the commonly used framework of splitting my data into train, validation, and test sets such that chronological ordering is respected to evaluate my models and create hypotheses. Specifically, I want to make sure that I'm paying attention to extreme values of my time series, say returns with with magnitude greater than or equal to 0.07. I'd like to make each of these disjoint subsets of my whole time series representative of my larger sample, especially as it pertains to each subset having a similar percent of extreme returns. I'm trying to do this so I have enough data to create hypotheses and also enough unseen data to see if these hypotheses hold out-of-sample. Let's assume there are 20 days in the whole time series of 25000 days where the return has absolute value greater than or equal to 0.07. Additionally let's say that half of these extreme values lie within the first 5000 days. The problem I run into is that these extreme days are not evenly spread across time meaning that I run into a tradeoff between having my subsets be representative of the larger sample and having sufficient data in my training set so as to be able to learn from this data independent of the extreme days as I would like to analyze "typical" days as well. Any input or references on this would be greatly appreciated, thanks!
