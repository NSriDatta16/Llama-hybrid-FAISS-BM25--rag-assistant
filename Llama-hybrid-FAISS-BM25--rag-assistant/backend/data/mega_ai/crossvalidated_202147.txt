[site]: crossvalidated
[post_id]: 202147
[parent_id]: 202121
[tags]: 
Approaches that naively select model terms based on some p-values or some AIC cut-offs (either in a multivariate model via some kind of stepwise or other selection or by looking at lots of univariate models) lead to extremely problematic fits that may fit the particular dataset well, but will otherwise not be useful. Models constructed in such a fashion tend to wrongly identify variables as relevant that are not (while not identifying truly relevant variables - if we assume the used model is some reasonable approximation to nature, in which some variables are relevant and some are not) and have poor predictive properties on new datasets. Nevertheless such approaches are still often used and one can even occasionally get such work published in some well-respected journals, but are quite thoroughly discredited in the statistical community. There are a lot of more appropriate approaches, e.g. bootstrapping naive model building approaches, cross-validation, random forests, model averaging, variable selection priors etc. that should be used instead.
