[site]: crossvalidated
[post_id]: 476499
[parent_id]: 
[tags]: 
One-sided test for AUC (area under the curve for ROC)

I am trying to determine the power of testing the AUC of a diagnostic test with continuous score against a one-sided alternative. I was thinking I could just use the confidence intervals produced by ci.auc from the R package pROC . By checking whether the lower limit of the confidence interval is larger than my value hypothesized under H0, the test should have 2.5% type I error rate. However, my simulation does not really adhere to these principles. Although true coverage rate is approximately 95% for AUC values smaller than around 0.9, the type I error rate for the one-sided test is in many cases much larger than the anticipated 2.5%. In fact, it seems to be much closer to the type I error rate for the two-sided test , i.e. 5%. Code follows. I am sorry for the quite naive code. I hope, it's comprehensible. library(pROC) auc_non_inferior auc_noninferior)/length(lower.limit) true.value.in.CI To give an example result of the function: set.seed(16) auc_non_inferior(n1=100, n2=100, auc_h1=0.75, auc_noninferior=0.75, nsim=1e4) > $`Mean AUC` > [1] 0.7495468 # this is as expected, since auc_h1=0.75 > $`Power of Non-Inferiority test` > [1] 0.0381 # here I expected 0.025 > $coverage > [1] 0.9437 # close to expected 95% Are the confidence intervals for the AUC not meant to equally spend type I error probability on both sides, i.e. values being larger and smaller? If so, why? And how can I do a one-sided test for AUC then? Or is something else wrong with this simulation?
