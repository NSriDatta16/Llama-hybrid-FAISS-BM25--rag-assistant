[site]: crossvalidated
[post_id]: 44002
[parent_id]: 43996
[tags]: 
Here's my take on the issue: SVMs are a very elegant way to do classification. There's some nice theory, some beautiful math, they generalize well, and they're not too slow either. Try to use them for regression though, and it gets messy. Here's a resource on SVM regression. Notice the extra parameters to twiddle and the in depth discussion about optimization algorithms. Gaussian Process Regression has a lot of the same kernelly math, and it works great for regression. Again, the very elegant, and it's not too slow. Try to use them for classification, and it starts feeling pretty kludgy. Here's a chapter from the GP book on regression. Here's a chapter on classification, for comparison. Notice that you end up with some complicated approximations or an iterative method. One nice thing about using GPs for classification, though, is that it gives you a predictive distribution, rather than a simple yes/no classification.
