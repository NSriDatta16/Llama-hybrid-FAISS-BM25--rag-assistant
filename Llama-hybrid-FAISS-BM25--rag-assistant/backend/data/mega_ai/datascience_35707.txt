[site]: datascience
[post_id]: 35707
[parent_id]: 
[tags]: 
Minimizing an upper bound of objective function

In many machine learning problems, you often have an objective function (e.g., cost, loss, error) that you want to minimize. Instead of directly minimizing this objective function, I sometimes see papers that derive the upper bound of the objective function, and then minimize the upper bound version instead. The reason for this seems to be that the original objective cannot be obtained by the data we have at hand, or just hard to minimize for some reasons. My question is, does it make sense to minimize the upper bound? Are there guarantees that they lead to the same solution? My concern is that the minimizer can obviously become different in the two cases. If this is the case, do we know how close the two can be? Are there good textbooks or papers that explain these issues? Thank you very much for your help!
