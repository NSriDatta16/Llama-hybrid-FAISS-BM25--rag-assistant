[site]: crossvalidated
[post_id]: 174733
[parent_id]: 173724
[tags]: 
It helps to think about the underlying meaning of the scores that result from each approach. Denote the binary user-item scores as $X_{hi}$ for user $h=1,...,H$ on item $i=1,...,I$ and the item-attribute scores as $T_{ia}$ for item $i=1,...,I$ and attribute $a=1,...,A$. First consider using the dot product (without normalization). The score on attribute $a$ for user $i$ is $\sum_{i=1}^I X_{hi} T_{ia}$, which is the sum of the scores on attribute $a$ for all items purchased by user $h$. The scores on the $A$ attributes will be correlated because they are driven in part by the number of items purchased by user $h$. library(corrplot) # randomly generate strictly positive matrices item_attributes Next consider taking the L1 norm of the user-item scores (but leaving the item-attribute scores as is): item_attributes_l1 The score on attribute $a$ for user $i$ would then be mean of the scores on attribute $a$ across all items purchased by user $h$: $\frac{1}{n_a} \sum_{i=1}^I X_{hi} T_{ia}$, where $n_a = \sum_{i=1}^I X_{hi}$ is the number of items purchased. Taking the mean rather than the sum removes the correlation driven by the number of items purchased. Next consider taking the L2 norm of the user-item scores (again, leaving the item-attribute scores as is): item_attributes_l2 The L2 norm of a set of $i$ binary items is $\sqrt{\sum_{i=1}^I X_{hi}^2} = \sqrt{\sum_{i=1}^I X_{hi}} = \sqrt{n_a}$, and so the score on attribute $a$ for user $i$ would then be $\sqrt{n_a}$ times the mean of the scores on attribute $a$ across all items puchased by user $h$: $\frac{1}{\sqrt{n_a}} \sum_{i=1}^I X_{hi} T_{ia}$. The scores on the $A$ attributes will still be correlated because they are all driven in part by $\sqrt{n_a}$. Of these three options, it seems to me that taking the L1 norm on items (i.e., averaging the item-attribute scores instead of summing them) produces the most interpretable results. If total number of items purchased is of interest, then you can always calculate this and include it as a further predictor. How best to norm the item-attribute scores seems to me to be an entirely separate question. Note that taking the L1 norm of the item-attribute scores amounts to assigning each item a "portion" of the total amount of an attribute, which might or might not make sense depending on context. Rather than taking the L2 norm, it might make more intuitive sense to re-scale the item-attribute scores to have mean 0 and SD 1, i.e., item_attributes_Z
