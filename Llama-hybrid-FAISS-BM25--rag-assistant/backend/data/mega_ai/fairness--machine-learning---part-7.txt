 , − } ∀ a , b ∈ A {\displaystyle P(R=+\ |\ Y=y,A=a)=P(R=+\ |\ Y=y,A=b)\quad y\in \{+,-\}\quad \forall a,b\in A} Conditional use accuracy equality. A classifier satisfies this definition if the subjects in the protected and unprotected groups have equal PPV and equal NPV, satisfying the formula: P ( Y = y | R = y , A = a ) = P ( Y = y | R = y , A = b ) y ∈ { + , − } ∀ a , b ∈ A {\displaystyle P(Y=y\ |\ R=y,A=a)=P(Y=y\ |\ R=y,A=b)\quad y\in \{+,-\}\quad \forall a,b\in A} Overall accuracy equality. A classifier satisfies this definition if the subject in the protected and unprotected groups have equal prediction accuracy, that is, the probability of a subject from one class to be assigned to it. This is, if it satisfies the following formula: P ( R = Y | A = a ) = P ( R = Y | A = b ) ∀ a , b ∈ A {\displaystyle P(R=Y\ |\ A=a)=P(R=Y\ |\ A=b)\quad \forall a,b\in A} Treatment equality. A classifier satisfies this definition if the subjects in the protected and unprotected groups have an equal ratio of FN and FP, satisfying the formula: F N A = a F P A = a = F N A = b F P A = b {\displaystyle {\frac {FN_{A=a}}{FP_{A=a}}}={\frac {FN_{A=b}}{FP_{A=b}}}} Definitions based on predicted probabilities and actual outcome These definitions are based in the actual outcome Y {\textstyle Y} and the predicted probability score S {\textstyle S} . Test-fairness, also known as calibration or matching conditional frequencies. A classifier satisfies this definition if individuals with the same predicted probability score S {\textstyle S} have the same probability of being classified in the positive class when they belong to either the protected or the unprotected group: P ( Y = + | S = s , A = a ) = P ( Y = + | S = s , A = b ) ∀ s ∈ S ∀ a , b ∈ A {\displaystyle P(Y=+\ |\ S=s,A=a)=P(Y=+\ |\ S=s,A=b)\quad \forall s\in S\quad \forall a,b\in A} Well-calibration is an extension of the previous definition. It states that when individuals inside or outside the protected group have the same predicted probability score S {\textstyle S} they must have the same probability of being classified in the positive class, and this probability must be equal to S {\textstyle S} : P ( Y = + | S = s , A = a ) = P ( Y = + | S = s , A = b ) = s ∀ s ∈ S ∀ a , b ∈ A {\displaystyle P(Y=+\ |\ S=s,A=a)=P(Y=+\ |\ S=s,A=b)=s\quad \forall s\in S\quad \forall a,b\in A} Balance for positive class. A classifier satisfies this definition if the subjects constituting the positive class from both protected and unprotected groups have equal average predicted probability score S {\textstyle S} . This means that the expected value of probability score for the protected and unprotected groups with positive actual outcome Y {\textstyle Y} is the same, satisfying the formula: E ( S | Y = + , A = a ) = E ( S | Y = + , A = b ) ∀ a , b ∈ A {\displaystyle E(S\ |\ Y=+,A=a)=E(S\ |\ Y=+,A=b)\quad \forall a,b\in A} Balance for negative class. A classifier satisfies this definition if the subjects constituting the negative class from both protected and unprotected groups have equal average predicted probability score S {\textstyle S} . This means that the expected value of probability score for the protected and unprotected groups with negative actual outcome Y {\textstyle Y} is the same, satisfying the formula: E ( S | Y = − , A = a ) = E ( S | Y = − , A = b ) ∀ a , b ∈ A {\displaystyle E(S\ |\ Y=-,A=a)=E(S\ |\ Y=-,A=b)\quad \forall a,b\in A} Equal confusion fairness With respect to confusion matrices, independence, separation, and sufficiency require the respective quantities listed below to not have statistically significant difference across sensitive characteristics. Independence: (TP + FP) / (TP + FP + FN + TN) (i.e., P ( Y ^ = 1 ) {\displaystyle P({\hat {Y}}=1)} ). Separation: TN / (TN + FP) and TP / (TP + FN) (i.e., specificity P ( Y ^ = 0 ∣ Y = 0 ) {\displaystyle P({\hat {Y}}=0\mid Y=0)} and recall P ( Y ^ = 1 ∣ Y = 1 ) {\displaystyle P({\hat {Y}}=1\mid Y=1)} ). Sufficiency: TP / (TP + FP) and 