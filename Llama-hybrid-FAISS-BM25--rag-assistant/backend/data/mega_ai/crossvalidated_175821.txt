[site]: crossvalidated
[post_id]: 175821
[parent_id]: 175776
[tags]: 
I also frequently find that Random Forests outperform other classifiers, and that they can even outperform combinations of other classifiers. Random Forests are simply good . It's hard to answer what specifically is the issue in your particular instance. One thing that could have an impact could be correlated regressors. SVM and logistic regression have a hard time with correlated predictors, as can AdaBoost , depending on which underlying weak learner is used. Random Forests, through "feature bagging" (selecting a small subset of predictors in building each separate tree) mitigates the effect of correlated regressors. If this really is the underlying issue, you could look at dimension reduction techniques like PCA before feeding the transformed data to your SVM and logistic regression.
