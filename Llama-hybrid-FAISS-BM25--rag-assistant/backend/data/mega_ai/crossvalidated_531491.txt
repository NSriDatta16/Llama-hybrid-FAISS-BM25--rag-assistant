[site]: crossvalidated
[post_id]: 531491
[parent_id]: 
[tags]: 
Can a neural network nodes "underweight" or "overweight" themselves?

I was under an impression that artificial intelligence is modelled after organic intelligence. Under the context of organic intelligence, it seems that some individuals are capable of getting caught with the condition of learned helplessness towards their own judgments after exposing to repeated trauma or failures. I'm curious if such "psychology" could ever influence an AI. Suppose that a node repeatedly fails at producing results relative to other nodes from its layer, would a node underweight itself similarly to how a pessimist underweights their own achievements? How long does it take for a node to correct its bias, and is there a situation where they can never correct their bias after "learning helplessness" no matter the amount of fair and normally distributed data was input again to train the neural network? A similar context also applies to "learned arrogance" where nodes overweight themselves permanently after exposing to a series of hotstreaks.
