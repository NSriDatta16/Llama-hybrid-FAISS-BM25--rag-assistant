[site]: datascience
[post_id]: 24251
[parent_id]: 24223
[tags]: 
This is where Word Embedding play an amazing role. If you want to solve the problem you have at hand with Natural Language Processing approach, what you can do is learn vector representations for these documents and store them with the labels i.e tags for that text. You can then use the similarity of vector representations between documents, to predict the tags. This way, your computation is not intensive at all and you can keep retraining as and when you get more data.
