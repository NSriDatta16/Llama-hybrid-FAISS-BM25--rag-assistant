[site]: stackoverflow
[post_id]: 3895868
[parent_id]: 3885489
[tags]: 
This seems to be a recurring question - e.g. #3396055 It most probably isn't a unit-test, because they should be fast (and independent). So running them all isn't a big drag. I can see where this might help in short-circuiting integration/regression runs to save time. If this is a major need for you, I'd tag the setup tests with [Core] or some such attribute. I then proceed to write a build script which has two tasks Taskn : run all tests in X,Y,Z dlls marked with tag [Core] Taskn+1 depends on Taskn: run all tests in X,Y,Z dlls excluding those marked with tag [Core] (Taskn+1 shouldn't run if Taskn didn't succeed.) It isn't a perfect solution - e.g. it would just bail out if any one [Core] test failed. But I guess you should be fixing the Core ones instead of proceeding with Non-Core tests.
