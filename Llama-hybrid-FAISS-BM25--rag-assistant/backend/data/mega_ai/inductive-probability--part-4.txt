ce has played a key role in probability theory. It says that if N statements are symmetric so that one condition cannot be preferred over another then all statements are equally probable. Taken seriously, in evaluating probability this principle leads to contradictions. Suppose there are 3 bags of gold in the distance and one is asked to select one. Then because of the distance one cannot see the bag sizes. You estimate using the principle of indifference that each bag has equal amounts of gold, and each bag has one third of the gold. Now, while one of us is not looking, the other takes one of the bags and divide it into 3 bags. Now there are 5 bags of gold. The principle of indifference now says each bag has one fifth of the gold. A bag that was estimated to have one third of the gold is now estimated to have one fifth of the gold. Taken as a value associated with the bag the values are different therefore contradictory. But taken as an estimate given under a particular scenario, both values are separate estimates given under different circumstances and there is no reason to believe they are equal. Estimates of prior probabilities are particularly suspect. Estimates will be constructed that do not follow any consistent frequency distribution. For this reason prior probabilities are considered as estimates of probabilities rather than probabilities. A full theoretical treatment would associate with each probability, The statement Prior knowledge Prior probabilities The estimation procedure used to give the probability. Combining probability approaches Inductive probability combines two different approaches to probability. Probability and information Probability and frequency Each approach gives a slightly different viewpoint. Information theory is used in relating probabilities to quantities of information. This approach is often used in giving estimates of prior probabilities. Frequentist probability defines probabilities as objective statements about how often an event occurs. This approach may be stretched by defining the trials to be over possible worlds. Statements about possible worlds define events. Probability and information Whereas logic represents only two values; true and false as the values of statement, probability associates a number in [0,1] to each statement. If the probability of a statement is 0, the statement is false. If the probability of a statement is 1 the statement is true. In considering some data as a string of bits the prior probabilities for a sequence of 1s and 0s, the probability of 1 and 0 is equal. Therefore, each extra bit halves the probability of a sequence of bits. This leads to the conclusion that, P ( x ) = 2 − L ( x ) {\displaystyle P(x)=2^{-L(x)}} Where P ( x ) {\displaystyle P(x)} is the probability of the string of bits x {\displaystyle x} and L ( x ) {\displaystyle L(x)} is its length. The prior probability of any statement is calculated from the number of bits needed to state it. See also information theory. Combining information Two statements A {\displaystyle A} and B {\displaystyle B} may be represented by two separate encodings. Then the length of the encoding is, L ( A ∧ B ) = L ( A ) + L ( B ) {\displaystyle L(A\land B)=L(A)+L(B)} or in terms of probability, P ( A ∧ B ) = P ( A ) P ( B ) {\displaystyle P(A\land B)=P(A)P(B)} But this law is not always true because there may be a shorter method of encoding B {\displaystyle B} if we assume A {\displaystyle A} . So the above probability law applies only if A {\displaystyle A} and B {\displaystyle B} are "independent". The internal language of information The primary use of the information approach to probability is to provide estimates of the complexity of statements. Recall that Occam's razor states that "All things being equal, the simplest theory is the most likely to be correct". In order to apply this rule, first there needs to be a definition of what "simplest" means. Information theory defines simplest to mean having the s