[site]: crossvalidated
[post_id]: 283748
[parent_id]: 
[tags]: 
How to correctly interpret the likelihood function of a Markov Chain, $P_{\theta}(X_1, ..., X_T)$ vs $P(X_1, ..., X_T|\theta)$?

Suppose $ \{ X_i \}_{i=1}^{T}$ are states of a markov chain and let $P_{\theta}(X_1, ..., X_T)$ be the probability of observing the path when $\theta$ is the true parameter value (a.k.a. the likelihood function for $\theta$). Using the definition of conditional probability, we know $$ P_{\theta}(X_1, ..., X_T) = P_{\theta}(X_T | X_{T-1}, ..., X_1) \cdot P_{\theta}(X_1, ..., X_{T-1})$$ Since this is a markov chain, we know that $P_{\theta}(X_T | X_{T-1}, ..., X_1) = P_{\theta}(X_T | X_{T-1} )$, so this simplifies this to $$ P_{\theta}(X_1, ..., X_T) = P_{\theta}(X_T | X_{T-1}) \cdot P_{\theta}(X_1, ..., X_{T-1})$$ Then, the likelihood function is then: $$ P_{\theta}(X_1, ..., X_T) = \prod_{i=1}^{T} P_{\theta}(X_i | X_{i-1} ) $$ where $X_0$ is to be interpreted as the initial state of the process. My question is how the above analysis works if we use the different notation of $$P(X_1, ..., X_T|\theta)$$ being the likelihood function for $\theta$ instead. Then, won't be end up with: $$ P(X_1, ..., X_T|\theta) = P(X_T | X_{T-1}, ..., X_1, \theta) \cdot P(X_1, ..., X_{T-1}|\theta)$$ ? Then, we will have: $$ P(X_1, ..., X_T|\theta) = P(X_T | X_{T-1}, ..., X_1, \theta) \cdots P(Y_1|Y_0,\theta) $$ But, I am not sure how to find $P(Y_1|Y_0,\theta)$ since it now has $\theta$ in the conditional part? In other words, if we were to treat the likelihood as a conditional probability distribution, do we now have a different problem of trying to find the joint distribution of the states and $\theta$? What is the correct notation for using the conditional distribution notation for the likelihood?
