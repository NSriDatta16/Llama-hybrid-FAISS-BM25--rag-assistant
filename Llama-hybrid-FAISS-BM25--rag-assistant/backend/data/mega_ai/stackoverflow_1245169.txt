[site]: stackoverflow
[post_id]: 1245169
[parent_id]: 1241758
[tags]: 
"I plan to do operations on that data (eg. sum, difference, averages etc.) as well including generation of say another column based on computations on the input." This is the standard use case for a data warehouse star-schema design. Buy Kimball's The Data Warehouse Toolkit. Read (and understand) the star schema before doing anything else. "What is the best way to store the data and manipulate? " A Star Schema. You can implement this as flat files (CSV is fine) or RDBMS. If you use flat files, you write simple loops to do the math. If you use an RDBMS you write simple SQL and simple loops. "My main concern is speed/performance as the number of datasets grows" Nothing is as fast as a flat file. Period. RDBMS is slower. The RDBMS value proposition stems from SQL being a relatively simple way to specify SELECT SUM(), COUNT() FROM fact JOIN dimension WHERE filter GROUP BY dimension attribute . Python isn't as terse as SQL, but it's just as fast and just as flexible. Python competes against SQL. "pitfalls/gotchas that I should be aware of?" DB design. If you don't get the star schema and how to separate facts from dimensions, all approaches are doomed. Once you separate facts from dimensions, all approaches are approximately equal. "What are the reasons why one should be chosen over another?" RDBMS slow and flexible. Flat files fast and (sometimes) less flexible. Python levels the playing field. "Are there any potential speed/performance pitfalls/boosts that I need to be aware of before I start that could influence the design?" Star Schema: central fact table surrounded by dimension tables. Nothing beats it. "Is there any project or framework out there to help with this type of task?" Not really.
