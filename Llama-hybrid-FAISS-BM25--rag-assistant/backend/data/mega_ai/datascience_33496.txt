[site]: datascience
[post_id]: 33496
[parent_id]: 33493
[tags]: 
Yes, it is typical to have some persistent representation of the model that is uploaded, and yes, it is typically very big as a file/files. Using pickle is one way to do it, commonly used with scikit-learn , for example. Deep learning frameworks typically have their own formats, but nothing stops you from using pickle with them as well, except that it is more complicated and less efficient as an approach. I'm not sure I understand the second part of the question, but if you want to modify your model online, nothing stops you from creating a new pickle. It is advisable that you run a new training as a separate batch process in the background, to avoid blocking your site or web service, especially if your web application server is single-threaded. Furthermore, you need to be wary of utilisation of server resources, so you would be better off running batch updates like that in low-traffic periods. This could be on over the weekend, or if your user base is predominantly regional, at night or on public holidays.
