[site]: datascience
[post_id]: 33001
[parent_id]: 32986
[tags]: 
An approach would be to sort out all the words in your data according to how often they appear, i.e. their "frequency". After that, pick the "X" most frequent words in your dataset to use them for the classification of your dataset. Assuming that you are working with Python and Keras, you should use the Embedding layer. For more details about how to use that layer, check this . Shortly, what this layer does is that it maps the input to a high dimensional vector domain. A word is converted to a real-valued vector and word similarity is evaluated by the "closeness" of two word-vectors in the high-dimensional vector space. Also make sure that your dataset consists of texts of fixed-length, by truncating long sequences or zero-padding short ones. After all this is done, you can train a recurrent neural network with LSTM neurons as a text classifier. LSTMs have been proven very successful in text processing due to their inherent memory. A hands-on Python/Keras tutorial that demonstrates all the above can be found here , I am sure it will be of high help :)
