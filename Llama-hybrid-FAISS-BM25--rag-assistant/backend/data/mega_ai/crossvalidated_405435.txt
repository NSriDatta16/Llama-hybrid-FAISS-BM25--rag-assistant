[site]: crossvalidated
[post_id]: 405435
[parent_id]: 404691
[tags]: 
People seem to have an assortment of pretty rigid practices. I'll just comment that I think ANOVA F tests are kind of overrated. They can be useful for deciding what model is suitable for a dataset; but they do not help much, in my opinion, for doing any meaningful inference. In particular, if you have fitted a two-way factorial model including interaction, and the residual diagnostics look good, I don't see anything wrong with proceeding to do post hoc means and comparisons without even looking at the ANOVA table. Appropriate multiplicity adjustments should be used, and I think it's important to look at the means themselves, not just the pairwise differences -- both from a subject-matter perspectives -- and probably plot them as well. I am a lot more comfortable with what is described in the preceding paragraph than I am with some analysis where rigid rules and "significance" criteria are applied, but no diagnostic plots or descriptive plots are examined. I see this kind of routinized method way, way too often. Not only do I think that little is lost by ignoring ANOVA tables, it is possible that something will be gained. For example, suppose that in skipping the ANOVA and plotting the means, we observe an interaction that would be of scientific interest (but for which there is insufficient data to achieve the magical "P potentially important that could be investigated in further experimentation. A devoted user of ANOVA tables may summarily throw the interaction out of the model, hence never having the opportunity to notice this potentially important result. Remember, just because something isn't "statistically significant," that doesn't prove it isn't there; it just means you don't have enough data to be sure it isn't part of the noise.
