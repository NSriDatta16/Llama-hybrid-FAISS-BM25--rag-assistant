[site]: crossvalidated
[post_id]: 448732
[parent_id]: 
[tags]: 
Calculating marginal likelihoods for coin flip with/without prior beta distribution

I was given a problem where I need to "compare a simple and complex model by computing the marginal likelihoods " for a coin flip. There were $4$ coin flips, $\{d_1, d_2, d_3, d_4\}$ . The "simple" model is the hypothesis that it is a fair coin, and $P(H) = 0.5$ . The "complex" hypothesis is $P(H) = \theta$ with prior $Beta(\theta|2,2)$ . I was also given that the formula for marginal likelihood is $p(D|M) = \int_\theta p(D|\theta, M)p(\theta|M)d\theta$ . A follow up question I am given is to decide which of these models provides a better account of the data $\{d_1, d_2, d_3, d_4\} = \{H, H, T, H\}$ . What I have so far: I will call the "simple" model $M_1$ and the "complex" one $M_2$ . My intuition tells me that the marginal likelihood for the simple model is simply $p(D|M_1) = 0.5$ , but I am not sure how to show mathematical calculation of this. For the "complex" model, I am not sure how to proceed. My guess is that $p(\theta|M_2) = \beta(\theta|2,2) = \frac{\Gamma(2+2)}{\Gamma(2)\Gamma(2)}\theta^{2-1}(1-\theta)^{2-1} = 6\theta(1-\theta)$ , but I am not sure what $p(D|\theta, M_2)$ would be. For the follow up question, my understanding is that I have to compute the maximum likelihoods and then compute the Bayesian Factor as $\frac{p(D|M_1)}{p(D|M_2)}$ .
