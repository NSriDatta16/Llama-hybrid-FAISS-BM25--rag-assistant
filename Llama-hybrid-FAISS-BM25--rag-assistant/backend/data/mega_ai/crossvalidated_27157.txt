[site]: crossvalidated
[post_id]: 27157
[parent_id]: 27146
[tags]: 
Extrapolating a linear regression on a time series, where time is one of the independent variables in the regression. A linear regression may approximate a time series on a short time scale, and may be useful in an analysis, but extrapolating a straight line is foolish. (Time is infinite and ever-increasing.) EDIT: In response to naught101's question about "foolish", my answer may be wrong but it seems to me that most real-world phenomenon don't increase or decrease continuously forever. Most processes having limiting factors: people stop growing in height as they age, stocks don't always go up, populations cannot go negative, you can't fill your house with a billion puppies, etc. Time, unlike most independent variables that come to mind, has infinite support, so you really can imagine your linear model predicting Apple's stock price 10 years from now because 10 years from now will surely exist. (Whereas you wouldn't extrapolate a height-weight regression to predict the weight of 20-meter-tall adult males: they don't and won't exist.) In addition, time series often have cyclical or pseudo-cyclical components, or random walk components. As IrishStat mentions in his answer, you need to consider seasonality (sometimes seasonalities at multiple time scales), level shifts (which will do strange things to linear regressions that don't account for them), etc. A linear regression that ignores cycles will fit over a short-term, but be highly misleading if you extrapolate it. Of course, you can get into trouble whenever you extrapolate, time-series or not. But it seems to me that we too often see someone throw a time series (crimes, stock prices, etc) into Excel, drop a FORECAST or LINEST on it and predict the future via essentially a straight line, as if stock prices would rise continuously (or decline continuously, including going negative).
