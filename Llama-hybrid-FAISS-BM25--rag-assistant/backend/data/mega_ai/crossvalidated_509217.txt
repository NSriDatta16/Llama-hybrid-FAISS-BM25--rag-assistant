[site]: crossvalidated
[post_id]: 509217
[parent_id]: 509208
[tags]: 
Let's suppose we could simply observe the joint distribution of $\Pr(Y,X,Z)$ . We don't have to estimate anything. We can calculate anything we want from this joint distribution. Our assumptions about how the outcome is determined (a causal model) say the treatment effect, $E[Y_{X=1} - Y_{X=0}]$ isn't equal to $E[Y|X=1] - E[Y|X=0]$ . There's a confounding variable, $Z$ , that contaminates the association of $Y$ and $X$ so that it doesn't just reflect $X$ affecting the value of $Y$ . But it also says that $E[Y_{X=1} - Y_{X=0}|Z=z]$ , the treatment effect for units where $Z$ equals $z$ , equals $E[Y|X=1, Z=z] - E[Y|X=0, Z=z]$ . If we look at units where $Z$ is held constant, the association between $X$ and $Y$ does come about because $X$ affects $Y$ . So, what we want to do is calculate $E[Y|X=1, Z=z] - E[Y|X=0, Z=z]$ . One thing that is annoying is that the treatment effect can vary with $z$ now. We need to either consider many different treatment effects, one corresponding to every value taken by $Z$ , or average them with $\Pr(Z)$ . Now let's return to reality. We can't observe $\Pr(Y,X,Z)$ , we have to estimate it. And typically, we estimate the conditional expectations directly, with regressions. Your alternative does exactly that. The average marginal effect of your logistic regression is an estimate of $\sum_z (E[Y|X=1, Z=z] - E[Y|X=0, Z=z]) \Pr(Z=z)$ where $E[Y|X=x, Z=z]$ is modelled as $\frac{1}{1 + \exp{(-\alpha - \beta x - \gamma z)}}$ and $\Pr(Z=z)$ as the frequency with which $Z=z$ occurs in your sample. Propensity scores matching is primarily a way of controlling for $Z$ (conditioning on it in the regression) when $Z$ has many components. It turns out that conditioning on the propensity score $p(Z)$ , a scalar, is as good, for some purposes, as conditioning on $Z$ even when it's a vector. It's as good for rendering the potential outcomes $Y_{X=1}$ and $Y_{X=0}$ independent from $X$ when conditioning on it. This is why propensity scores work. Long story short: Yes, the two approaches should give similar results And if $Z$ is one-dimensional, there is, as far as I know, no reason to use propensity scores. You can easily use $Z$ directly. Even if $Z$ has many components, you can just all add them to a regression and this is a still a more widely used control strategy than propensity scores.
