[site]: crossvalidated
[post_id]: 447444
[parent_id]: 442563
[tags]: 
The usual for of evaluating a regressor in machine learning is by evaluating the error on a different dataset from the one used in training. I will assume that your sentence "All algorithms are trained and evaluated on the exact same dataset." mean that there are 2 different data sets, one for training and one for testing, and they are the same for both regressors (XGBoost and NN for example). If you are using only one dataset for both training and testing (which is the usual for people that use linear regression and talks about Q-Q plots of residuals) please DON'T. Split your single dataset into say, 80% training and 20% testing. The distributions of the residuals (which in machine learning are similar to errors - more on this below) of the testing set are irrelevant. There is no assumption that errors/residuals for the regressor are normal, so Q-Q plot are irrelevant. And so on. The main difference between residuals and errors is that error are always positive - from a prediction point of view, predicting an y that is 5 above or below the correct value is equally wrong. There are two usual transformations from residuals to error - the MSE and MAE referred by user11852 - MSE takes the square of the residuals and MAE takes the absolute value. Now you have to sets of measures of ERRORS (be it MAE or MSE or others) and you want the regressor with least mean or median error. Errors are seldom normally distributed, so a non-parametric test is the more canonical approach, but if you have thousand of data points in your test data set, then the central limit theorem as referred by Demetri Pananos apply, so you can use a parametric test. Finally, there is an important point. The two sets of error measures (for each regressor) are PAIRED - that is each measure in one set has a correspondent measure on the other set. So you should use a paired test for that. To summarize: a) use 2 data sets, b) compute the error from the residuals - use the square transform - it is more frequently used, c) choose the regressor with least median error and d) if you want to argue that the one you choose is "really" (or significantly) better that the other one, then use the Wilcoxon signed rank test (the paired version of the Wilcoxon rank-sum)
