[site]: crossvalidated
[post_id]: 203792
[parent_id]: 
[tags]: 
Replacing ridge regression with Bayesian MCMC

I have a ridge regression model $ y = \beta_1 x_1 + \beta_2 x_2 + ...$ The $x$s are highly collinear but are all physically relevant, hence use of ridge regression. And am considering replacing it with Bayesian MCMC estimation to allow use of a more complex model $ y = \delta^{x_0} ( \beta_1 x_1^{\gamma_1} + \beta_2 x_2^{\gamma_2} + ... )$ where $x_0$ is another predictor and $\gamma, \delta$ more coefficients. Both models have a sensible physical interpretation. Is this a sensible thing to do? If so, I presume the ridge penalty metaparameter $\lambda$ is replaced by variance on priors for $\beta$. How would I choose the priors? In the ridge regression $\lambda$ was chosen by generalized cross-validation. In the Bayesian model, is GCV still appropriate for choice of $\lambda$? Is it appropriate for choice of the ordinary parameters $\beta, \gamma, \delta$ as well? If so should I estimate $\beta,\gamma,\delta,\lambda$ together or should I run some nested models where $\lambda$ is deferred to the outer loop? To be clear, the overarching aim is good out-of-set prediction. I have never used a Bayesian model before so if this is 101 stuff I apologise, please point me at the right resources!
