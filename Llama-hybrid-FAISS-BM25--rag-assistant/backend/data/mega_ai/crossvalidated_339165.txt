[site]: crossvalidated
[post_id]: 339165
[parent_id]: 
[tags]: 
Standard Deviation of a Proportion

It's easy to explain why the standard deviation of a data set is computed the way it is. If you can compute an average, it is, in some sense simply an average deviation of each score from the mean for all scores (yes, I know that average deviation and standard deviation are not the same thing). The standard deviation of a proportion is harder to understand intuitively. Why would you multiply p times (1-p)? What's up with that? Is it analogous to the idea of average deviation, that is so apparent in the standard deviation formula used for a set of scores? If so, how?
