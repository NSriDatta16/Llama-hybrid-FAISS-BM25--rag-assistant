[site]: crossvalidated
[post_id]: 179191
[parent_id]: 179104
[tags]: 
I agree that some sort of dimension reduction approach of your features makes sense. Standard PCA was developed for finding linear combinations of continuously scaled features based on symmetric matrices and wouldn't be appropriate for your many 0,1 features. When faced with matrices of categorical data that are not symmetric, sparsely populated or potentially nonlinear, SVD-based factorization methods are a much better, more robust approach. Correspondence analysis is one SVD method for finding low dimensional, "PCA-like" solutions based on categorical features but there are many others. One recent paper by Chen and Xie uses a probabilistic, robust Cauchy model rooted in SVD decomposition designed to capture nonlinear, sparse and extreme valued information... http://arxiv.org/abs/1412.6506 Bayesian Tensor Regression , an approach developed by David Dunson at Duke is kind of the state-of-the-art for massive, multiway contingency table analysis. But it's not clear that this would be a useful approach for your needs since, if the prior responder is right that you have "many irrelevant features", it takes the dimensionality as fixed as in genome analysis. You should be aware that the approach exists. http://www.researchgate.net/profile/David_Dunson/publications Once you have reduced the dimensionality and scored your employees, then there are many clustering algorithms available for use. K-means is the granddaddy of them all but has the limitation of always finding spherically-shaped clusters, even when there really aren't any real groupings to the data. But it works pretty well. K-medians would be another option. Agglomerative methods will find differently shaped cluster segments and can be based on similarities between the dimensions. But there are almost as many clustering algorithms as there are variable selection algorithms -- both are areas where every statistician and their brother has an approach and/or a working paper.
