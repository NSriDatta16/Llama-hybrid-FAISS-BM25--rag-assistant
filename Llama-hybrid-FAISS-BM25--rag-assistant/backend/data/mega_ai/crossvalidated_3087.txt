[site]: crossvalidated
[post_id]: 3087
[parent_id]: 3082
[tags]: 
It is broken, although if you perform enough shuffles it can be an excellent approximation (as the previous answers have indicated). Just to get a handle on what's going on, consider how often your algorithm will generate shuffles of a $k$ element array in which the first element is fixed, $k \ge 2$ . When permutations are generated with equal probability, this should happen $1/k$ of the time. Let $p_n$ be the relative frequency of this occurrence after $n$ shuffles with your algorithm. Let's be generous, too, and suppose you are actually selecting distinct pairs of indexes uniformly at random for your shuffles, so that each pair is selected with probability $1/{k \choose 2}$ = $2/\left( k (k-1) \right)$ . (This means there are no "trivial" shuffles wasted. On the other hand, it totally breaks your algorithm for a two-element array, because you alternate between fixing the two elements and swapping them, so if you stop after a predetermined number of steps, there is no randomness to the outcome whatsoever!) This frequency satisfies a simple recurrence, because the first element is found in its original place after $n+1$ shuffles in two disjoint ways. One is that it was fixed after $n$ shuffles and the next shuffle does not move the first element. The other is that it was moved after $n$ shuffles but the $n+1^{st}$ shuffle moves it back. The chance of not moving the first element equals ${k-1 \choose 2}/{k \choose 2}$ = $(k-2)/k$ , whereas the chance of moving the first element back equals $1/{k \choose 2}$ = $2/\left( k (k-1) \right)$ . Whence: $$p_0 =1$$ because the first element starts out in its rightful place; $$p_{n+1} = \frac{k-2}{k} p_n + \frac{2}{k(k-1)} \left( 1 - p_n \right).$$ The solution is $$p_n = 1/k + \left( \frac{k-3}{k-1} \right) ^n \frac{k-1}{k}.$$ Subtracting $1/k$ , we see that the frequency is wrong by $\left( \frac{k-3}{k-1} \right) ^n \frac{k-1}{k}$ . For large $k$ and $n$ , a good approximation is $\frac{k-1}{k} \exp(-\frac{2n}{k-1})$ . This shows that the error in this particular frequency will decrease exponentially with the number of swaps relative to the size of the array ( $n/k$ ), indicating it will be difficult to detect with large arrays if you have made a relatively large number of swaps--but the error is always there. It is difficult to provide a comprehensive analysis of the errors in all frequencies. It's likely they will behave like this one, though, which shows that at a minimum you would need $n$ (the number of swaps) to be large enough to make the error acceptably small. An approximate solution is $$n \gt \frac{1}{2} \left(1 - (k-1) \log(\epsilon) \right)$$ where $\epsilon$ should be very small compared to $1/k$ . This implies $n$ should be several times $k$ for even crude approximations ( i.e. , where $\epsilon$ is on the order of $0.01$ times $1/k$ or so.) All this begs the question: why would you choose to use an algorithm that is not quite (but only approximately) correct, employs exactly the same techniques as another algorithm that is provably correct, and yet which requires more computation? Edit Thilo's comment is apt (and I was hoping nobody would point this out, so I could be spared this extra work!). Let me explain the logic. If you make sure to generate actual swaps each time, you're utterly screwed. The problem I pointed out for the case $k=2$ extends to all arrays. Only half of all the possible permutations can be obtained by applying an even number of swaps; the other half is obtained by applying an odd number of swaps. Thus, in this situation, you can never generate anywhere near a uniform distribution of permutations (but there are so many possible ones that a simulation study for any sizable $k$ will be unable to detect the problem). That's really bad. Therefore it is wise to generate swaps at random by generating the two positions independently at random. This means there is a $1/k$ chance each time of swapping an element with itself; that is, of doing nothing. This process effectively slows down the algorithm a little bit: after $n$ steps, we expect only about $\frac{k-1}{k} N \lt N$ true swaps to have occurred. Notice that the size of the error decreases monotonically with the number of distinct swaps. Therefore, conducting fewer swaps on average also increases the error, on average. But this is a price you should be willing to pay in order to overcome the problem described in the first bullet. Consequently, my error estimate is conservatively low, approximately by a factor of $(k-1)/k$ . I also wanted to point out an interesting apparent exception: a close look at the error formula suggests that there is no error in the case $k=3$ . This is not a mistake: it is correct. However, here I have examined only one statistic related to the uniform distribution of permutations. The fact that the algorithm can reproduce this one statistic when $k=3$ (namely, getting the right frequency of permutations that fix any given position) does not guarantee the permutations have indeed been distributed uniformly. Indeed, after $2n$ actual swaps, the only possible permutations that can be generated are $(123)$ , $(321)$ , and the identity. Only the latter fixes any given position, so indeed exactly one-third of the permutations fix a position. But half the permutations are missing! In the other case, after $2n+1$ actual swaps, the only possible permutations are $(12)$ , $(23)$ , and $(13)$ . Again, exactly one of these will fix any given position, so again we obtain the correct frequency of permutations fixing that position, but again we obtain only half of the possible permutations. This little example helps reveal the main strands of the argument: by being "generous" we conservatively underestimate the error rate for one particular statistic. Because that error rate is nonzero for all $k \ge 4$ , we see that the algorithm is broken. Furthermore, by analyzing the decay in the error rate for this statistic we establish a lower bound on the number of iterations of the algorithm needed to have any hope at all of approximating a uniform distribution of permutations.
