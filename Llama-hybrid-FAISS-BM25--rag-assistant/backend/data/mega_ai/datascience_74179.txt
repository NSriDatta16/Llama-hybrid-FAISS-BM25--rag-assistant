[site]: datascience
[post_id]: 74179
[parent_id]: 74009
[tags]: 
To be clear, here, time-series classification refers to forecasting discrete values. In another context, time-series classification could refer to predicting a single class for the entire time-series (i.e. heart disease vs healthy heart). Thanks @mloning for pointing this out. When it comes to forecasting discrete outputs, models are trained to predict the next value based on the previous ones, which means that The input is the historical data up to timestamp t (in your scenario, the data up to week = 201904 ) The output is the value at timestamp t + 1 ( y when week = 201905 ) If you want to predict more than 1 value into the future , you should perform predictions in a recurrent way, i.e.: use data up to t to predict t + 1 add your prediction to your data use data up to t + 1 (where t + 1 is your own prediction) to predict t + 2 and so on How far into the future you want to look is called the horizon . And you are free to use as big of a horizon as you like. Of course, since every new step into the future is based on guesses and not actual data, it is expected that the further you look, the worse your predictions will become. Which makes perfect sense. That's why it's easier to predict what the weather will be like tomorrow than in 7 days. Splitting data into training and testing is not very different than for a normal classification problem. The only constraint is that your test data should only contain data "in the future" compared to the training data. Here is a good blog about it: https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8 should I train the model for each time series independently? Short answer: try both approaches and see which one works best Long answer: All of this depends on whether you believe that each time-series represent a different "process" or "pattern". It could be that a single model could make good predictions for either time-series. It could also be that both time-series represent different processes and therefore, it might be wiser to train different models for each. Think about it like a weather forecast. I could have time-series data for a bunch of cities. I could train a model specific to each city, but it might also help to train a model using data from all cities so that it can capture generic weather patterns. This can help if all of a sudden, I need to predict the weather for a new city I didn't know about. Since I didn't know about it, I don't have a model specifically for it, so I would need to reuse one, which ideally should be general enough.
