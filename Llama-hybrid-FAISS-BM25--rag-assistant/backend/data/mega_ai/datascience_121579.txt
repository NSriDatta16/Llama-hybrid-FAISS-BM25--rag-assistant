[site]: datascience
[post_id]: 121579
[parent_id]: 121577
[tags]: 
The results you are receving may be affected by variance. When you evaluate the model on the 30% of the data, you will have low bias but more variance. The imbalance of the target should not be a problem as long as you stratify your split. Alternatives to consider: Use the out of bag score of random forest, that is the score in the samples that are excluded during bootstrap. That will give you a good approximation of the performance on the test and they will be approximately 30% of the train data always so it will be more fair evaluation. Create learning curves Evaluate the model performance as a function of sample size, so you can see if the model actually benefits from adding more data to the training set. Hope it helps!
