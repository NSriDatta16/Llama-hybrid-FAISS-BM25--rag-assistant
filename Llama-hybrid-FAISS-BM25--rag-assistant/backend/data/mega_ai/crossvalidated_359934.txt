[site]: crossvalidated
[post_id]: 359934
[parent_id]: 359932
[tags]: 
Q1: It seems here $y_k=a_k$, in PRML around eq 5.18 In the regression case, we can view the network as having an output activation function that is the identity, so that $y_k = a_k$ Q2: In the discussion on P242 there's only one layer with no activation function, actually the author didn't call it a neural network but a "simple linear model" Consider first a simple linear model in which the outputs $y_k$ are linear combinations of the input variables $x_i$
