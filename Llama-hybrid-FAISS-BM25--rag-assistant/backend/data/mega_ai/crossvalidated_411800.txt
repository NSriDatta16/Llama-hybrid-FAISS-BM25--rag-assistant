[site]: crossvalidated
[post_id]: 411800
[parent_id]: 411754
[tags]: 
I think the model should learn two things: time series behaviour and some general rules from the data for each state, i.e. if you have the following data: day | state | rainfall 1 | CA | 10 2 | CA | 25 3 | CA | 0 1 | WA | 100 2 | WA | 90 3 | WA | 80 then an example for those two rules would be It will rain roughly the same amount as the day before In southern states it rains much less In order to make it learn rules of the first time you need to transform the data into the following format day | state | rainfall | rainfallBefore 1 | CA | 10 | NA 2 | CA | 25 | 10 3 | CA | 0 | 25 1 | WA | 100 | NA 2 | WA | 90 | 100 3 | WA | 80 | 90 This essentially covers the time series part because all the models that people usually use when they say 'time series' is ARIMA or so which is basically one very special instance (not necessarily the best one) of a very normal regression with the transformed table as above (containing lagged variables). However, one can use many different models: https://www.r-bloggers.com/timeseries-forecasting-using-extreme-gradient-boosting/ . In order to make it learn about the second part (i.e. "surfing the wave of right now" features) you need to join in as much information as possible about the states that could be related to rainfall. One possibility that would it make easy for a model to learn a rule as given above would be to insert the lat/lon coordinates of the middle point of each state. Then the model yould learn the rule: The bigger the latitude the more south the state is, hence, the less rain I should expect. So: transform the data table and introduce lagged features introduce many state rain relation features take any regression model and let it run on this training set with rainfall as a target variable
