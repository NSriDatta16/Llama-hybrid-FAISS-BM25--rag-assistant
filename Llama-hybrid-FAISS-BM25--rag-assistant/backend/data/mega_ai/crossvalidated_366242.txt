[site]: crossvalidated
[post_id]: 366242
[parent_id]: 
[tags]: 
Describing relative performance of models on the basis on log-loss / cross-entropy

Suppose I train classification algorithms on a given dataset with three model specifications: A, B, and C. On validation data, model A has an average log-loss of 1.0, model B has a log-loss of 0.75, and model C has a log-loss of 0.5. I would like a way to describe the relative performance of these three models which has some kind of quantitative interpretation. For example, is the absolute difference in log-loss a meaningful quantity? Does it make sense to say that model B is 0.25 better than model A? What about the percent difference? Is model B 25% better than model A? Is C "as much better" than B as B is than A? As an example, if I were comparing models on the basis of AIC, I know that the absolute difference in AIC is a quantity with a meaningful interpretation (i.e., it is related to the relative probabilities that the model specifications are correct), whereas the percent change in AIC is not a meaningful quantity.
