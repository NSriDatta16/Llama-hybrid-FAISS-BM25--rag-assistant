[site]: crossvalidated
[post_id]: 95627
[parent_id]: 95621
[tags]: 
To select the important variables (features) in your dataset, you could perform variable clustering. In variable clustering, the correlation between the variables is of interest (you want to cluster variables that are highly correlated with each other). This R package may provide more insight into how it works and will actually implement a method for you to use. One way of performing variable clustering that may provide some intuition into your problem is to perform PCA on your data and then cluster variables that are grouped together by the PCA loadings. In a sense, this is what the methods in that package do. Intuitively, one could say that they are highly correlated with the same dimension of the PCA subspace and therefore with each other - thus they should be clustered. Note that before performing PCA and other similar procedures, one should standardize the variables. In the comments below, you express that this approach may not be automatic enough for your specific situation. You claim that you need to run variable selection on multiple datasets and aggregate the findings. An alternative with a more automatic selection could be to use sparse PCA (PCA-based methods should probably be acceptable since the variable clustering also uses PCA). You will need to select a level of "sparsity" (how many variables to exclude). If you can run Matlab, the simplest thing would probably be to use the package by Karl Sjorstrand and run spca using soft thresholding (see example in the function) to select the level of sparsity automatically. Do this for all of your subsets and then aggregate the results in a logical way (one could be to exclude variables that are always excluded, or excluded in almost all datasets). If you do not have Matlab, you can run spca in R using the elasticnet package, though I do not think it will automatically determine the sparsity parameters. You may find another R package that does though.
