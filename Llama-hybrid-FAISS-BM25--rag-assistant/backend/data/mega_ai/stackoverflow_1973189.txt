[site]: stackoverflow
[post_id]: 1973189
[parent_id]: 
[tags]: 
optimizing with IEEE floating point - guaranteed mathematical identities?

I am having some trouble with IEEE floating point rules preventing compiler optimizations that seem obvious. For example, char foo(float x) { if (x == x) return 1; else return 0; } cannot be optimized to just return 1 because NaN == NaN is false. Okay, fine, I guess. However, I want to write such that the optimizer can actually fix stuff up for me. Are there mathematical identities that hold for all floats? For example, I would be willing to write !(x - x) if it meant the compiler could assume that it held all the time (though that also isn't the case). I see some reference to such identities on the web, for example here , but I haven't found any organized information, including in a light scan of the IEEE 754 standard. It'd also be fine if I could get the optimizer to assume isnormal(x) without generating additional code (in gcc or clang). Clearly I'm not actually going to write (x == x) in my source code, but I have a function that's designed for inlining. The function may be declared as foo(float x, float y), but often x is 0, or y is 0, or x and y are both z, etc. The floats represent onscreen geometric coordinates. These are all cases where if I were coding by hand without use of the function I'd never distinguish between 0 and (x - x), I'd just hand-optimize stupid stuff away. So, I really don't care about the IEEE rules in what the compiler does after inlining my function, and I'd just as soon have the compiler ignore them. Rounding differences are also not very important since we're basically doing onscreen drawing. I don't think -ffast-math is an option for me, because the function appears in a header file, and it is not appropriate that the .c files that use the function compile with -ffast-math.
