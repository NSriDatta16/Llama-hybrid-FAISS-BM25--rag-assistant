[site]: crossvalidated
[post_id]: 351997
[parent_id]: 
[tags]: 
Filling replay memory randomly at the beginning or not?

I have a question about the correct way of implementing replay memory for a DQN. Assuming the the maximum size of memory is $N$, what do we need to do if the batch size is $K$? 1) Fill the memory just by choosing $N$ random actions, without updating the neural network. Then, take batch of samples with size $K$,... 2) When we add each experience to the memory, update the neural network with a batch of size $\min \{K, \text{current size of memory} \}$ and do not wait for the memory to get filled completely. Does this really matter? Thanks,
