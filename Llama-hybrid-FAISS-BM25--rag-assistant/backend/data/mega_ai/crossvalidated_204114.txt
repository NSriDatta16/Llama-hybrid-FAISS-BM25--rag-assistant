[site]: crossvalidated
[post_id]: 204114
[parent_id]: 
[tags]: 
Deep Neural Network weight initialization

Given difficult learning task (e.g high dimensionality, inherent data complexity) Deep Neural Networks become hard to train. To ease many of the problems one might: Normalize && handpick quality data choose a different training algorithm (e.g RMSprop instead of Gradient Descent) pick a steeper gradient Cost function (e.g Cross Entropy instead of MSE) Use different network structure (e.g Convolution layers instead of Feedforward) I have heard that there are clever ways to initialize better weights. For example you can choose the magnitude better: Glorot and Bengio (2010) for sigmoid units: sample a Uniform(-r, r) with $r = \sqrt{\frac{6}{N_{in} + N_{out}}}$ or hyperbolic tangent units: sample a Uniform(-r, r) with $r =4 \sqrt{\frac{6}{N_{in} + N_{out}}}$ Is there any consistent way of initializing the weights better?
