[site]: crossvalidated
[post_id]: 444673
[parent_id]: 
[tags]: 
Comparing Regression Coefficients from a "log-log" to an Alternative De-meaning Procedure

Consider two regression models: $log(y_i) = \log(x_i)\alpha + \epsilon_i \,\,\,\,\,$ (Model 1), $log(y_i) = (\frac{x_i}{\overline{x}})\beta + \varepsilon_i \,\,\,\,\,\,\,\,$ (Model 2), where $\overline{x}$ is the sample average of $x_i$ . Both of these models transform the variable $x_i$ , the first with a log, the second by dividing by the sample average. In short, why aren't $\alpha$ and $\beta$ equal? I am confused because, it is my understanding that: $\alpha = \frac{\partial \log(y)}{\partial \log(x)} = \frac{\partial \log(y)}{\partial y}\frac{\partial y}{\partial x} \frac{\partial x}{\partial \log(x)} = \frac{\partial y}{\partial x}\frac{x}{y}$ and $\beta = \frac{\partial \log(y)}{\partial (\frac{x_i}{\overline{x}})} = \frac{\partial \log(y)}{\partial y}\frac{\partial y}{\partial x} \frac{\partial x}{\partial (\frac{x_i}{\overline{x}})} = \frac{\partial y}{\partial x}\frac{x}{y}$ However, in simulations, these two regression coefficients do not exactly equal each other. Is there an approximation going on somewhere in my definitions that I am ignoring? Is there some kind of small-sample bias that is relevant in practice that is missed here?
