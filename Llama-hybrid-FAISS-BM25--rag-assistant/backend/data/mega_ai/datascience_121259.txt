[site]: datascience
[post_id]: 121259
[parent_id]: 
[tags]: 
Resizing layer in adversarial GAN

A lot of questions have already been asked regarding resizing layer in sequential models but I couldn't find any that could solve my specific architecture. I am creating an adversarial GAN. First an image (of size 224 224 3) is input and sent through a generator that outputs a generated image of the same size. This image is then given to a discriminator and a target network (VGG16) that both expect an input of 224 224 3. Here is my current code: def __init__(self): # input image dimensions inputs = Input(shape=(224, 224, 3)) optimizer_g = Adam(0.0002) optimizer_d = SGD(0.01) # Build generator outputs = self.build_generator(inputs) self.G = Model(inputs, outputs) self.G._name = 'Generator' # self.G.summary() # Build discriminator and train it outputs = self.build_discriminator(self.G(inputs)) self.D = Model(inputs, outputs) self.D.compile(loss=tensorflow.keras.losses.binary_crossentropy, optimizer=optimizer_d, metrics=[self.custom_acc]) self.D._name = 'Discriminator' # self.D.summary() # We use VGG16 trained with ImageNet dataset. self.target = VGG16(weights='imagenet') self.target.trainable = False # Build GAN: stack generator, discriminator and target img = (self.G(inputs) / 2 + 0.5) * 255 # image's pixels will be between [0, 255] ## Image is now preprocessed before being fed to VGG16 self.stacked = Model(inputs=inputs, outputs=[self.G(inputs), self.D(self.G(inputs)), self.target(preprocess_input(img))]) self.stacked.compile(loss=[self.generator_loss, tensorflow.keras.losses.binary_crossentropy, tensorflow.keras.losses.categorical_crossentropy], optimizer=optimizer_g) self.stacked.summary() The problem I have now, is that I need to make this network work with any image size . It means that the generator will take an image 600 800 3 for instance, output a 600 800 3 and then this image needs to be resized to (224 224 3) in order to be fed to the discriminator and VGG16. (I can't change the input of the discriminator or VGG16, the output of the generator needs to be resized in between). I have tried many ways to add a resizing layer after the generator with Resizing(), Reshape() or even tf.image.resize() but I couldn't make them fit in my network. I am not sure if I should add a new Model() after the generator or if I should change the input of build_discriminator() and self.D = Model(inputs, outputs) Could anyone enlighten me on this matter and explain to me how I could interconnect all those models with a resizing process in between? Thanks in advance ! PS: I didn't paste the code of the generator and discriminator but if you need to see their code, they have been taken from that github https://github.com/niharikajainn/adv_gan_keras/blob/master/adv_gan.py .
