[site]: crossvalidated
[post_id]: 296183
[parent_id]: 295781
[tags]: 
The comments and answers are very helpful in terms of addressing the OP's explicitly stated 'simple question' regarding an appropriate modeling framework but, unless I'm missing something, none of them provide direction about how to evaluate the relative (not relevant) importance of features in the resulting model(s). This concern was articulated both in the title as well as the very first sentence of this question. So, my reading is that the OP really has two questions: the first is manifest and has already been answered, while the second was not explicitly stated, is therefore latent and remains unanswered. This response will attempt to address this second, latent question. Many heuristics for evaluating relative importance of features have been proposed in the literature. Ulrike Gromping's papers and R module -- RELAIMPO -- are probably the single best source for both a thorough literature review as well as evaluatory software (RELAIMPO stands for 'relative importance of regressors', e.g., see here ... https://prof.beuth-hochschule.de/groemping/software/relaimpo/ ). Some heuristics involve adding up the values of metrics output from the model and then repercentaging to create a relative ranking of features that sum up to 1 (or 100%). For example, one widely used method is to standardize continuous regressors onto a unit scale (mean=0, std dev=1) followed by evaluating, repercentaging and ranking the absolute values of the resulting beta coefficients from the model. Another related method is not to standardize features but to sum up the F- or t-test values (the absolute values in the case of the t) output from the model and repercentaging those. The logic of this latter approach is that the beta coefficients are expressed in the units or scale of the underlying, unstandardized feature while the F- and t-values are standardized metrics. Both of these approaches are limited by two assumptions: first, that a single pass at the data can be fully informative about the behavior of the model and, second, that one of the four types of estimable functions is correct -- usually the type 3 assumption of independence of the regressors (e.g., see this SAS document, Four Types of Estimable Functions , https://support.sas.com/documentation/cdl/en/statug/63347/HTML/default/viewer.htm#introglmest_toc.htm ). Workarounds concerning the first assumption of reliance on a single pass at the data leverage iterative and approximating tools such as the bootstrap-, jackknife- or random forest-type algorithms to obtain more precise and robust 'central tendencies' wrt model parameters. Second, rotation through the four different approaches to estimating functions can be employed as an additional control on these central tendencies. See Gromping's papers for greater detail about how these latter methodologies are to be employed. Personally, I like the iterative and approximating approaches as they enable a type of empirical 'simulation' of differing data landscapes , enabling more robust estimates. And while I can see the value in rolling through the four types of estimable functions insofar as it is exhaustive and thorough, it still seems like unnecessary overkill from a purely computational and resource utilization perspective. Given that, the key questions become ones of evaluating the asymptotic accuracy and performance of both the iterative, approximating algorithms as well as inclusion of tests for the four types of functions . Chen and Xie's paper, A Split-and-Conquer Approach for Analyzing Extraordinarily Large Data , addresses the statistical question of the accuracy of these iterative algorithms and concludes that they are, for the most part, delivering quite comparably accurate results (see here ... http://www3.stat.sinica.edu.tw/sstest/oldpdf/A24n49.pdf ). Regarding the second concern with adding the four types of functions , my own comparison of RELAIMPO-based relative importance with methods that do not test for the four types suggests that there is little to be gained from their addition.
