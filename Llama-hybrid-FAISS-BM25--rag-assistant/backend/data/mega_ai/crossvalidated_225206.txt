[site]: crossvalidated
[post_id]: 225206
[parent_id]: 161030
[tags]: 
In one-dimensional case $x_j$ is an average of its neighbors plus a zero-mean Gaussian with a non-zero variance $\sigma^2$ $x_j=\frac{1}{2}(x_{j-1}+x_{j+1})+\epsilon_j = \frac{1}{2}(x_{j-1}+x_{j+1})+\mathcal{N}(0, \sigma^2)$ Thus $p(x_j) = \mathcal{N}(x_j|\mu, \sigma^2) \propto \exp(\frac{1}{2\sigma^2}(x_j-\mu)^2)$ where $\mu=\frac{1}{2}(x_{j-1}+x_{j+1})$ Now, if we define a vectors $\mathbf{L}=\frac{1}{2}[-1,2,-1]^T$ and $\mathbf{x} = [x_{j-1}, x_j, x_{j+1}]$ we can calculate their inner product as: $\mathbf{Lx} = \frac{1}{2}(-x_{j-1} + 2x_j -x_{j+1}) = x_j - \frac{1}{2}(x_{j-1}+x_{j+1}) = x_j - \mu$ This allows us to rewrite $p(x_j)$ as $p(x_j) \propto \exp(\frac{1}{2\sigma^2}||\mathbf{Lx}||^2) = \exp(\frac{1}{2\sigma^2}\mathbf{x}^T\mathbf{L}^T\mathbf{Lx}) = \exp(\frac{1}{2}\mathbf{x}^T\Sigma^{-1} \mathbf{x})$ So we see that $p(x_j) = \mathcal{N}(\mathbf{x}|0, \Sigma)$, where $\Sigma = (\frac{1}{\sigma^2}\mathbf{L}^T\mathbf{L})^{-1}$ In n-dimensions we just change definition of $\mathbf{L}$ to (4.77) and we can write $p(\mathbf{x}) = \mathcal{N}(\mathbf{x}|0, (\frac{1}{\sigma^2}\mathbf{L}^T\mathbf{L})^{-1})$
