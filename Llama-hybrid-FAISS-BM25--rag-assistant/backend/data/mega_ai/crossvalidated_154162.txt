[site]: crossvalidated
[post_id]: 154162
[parent_id]: 139495
[tags]: 
If I understand your pseudo-code correctly, I don't see where the stacking model is being tested in the cross validation loop. I would expect to see something like model4 = fitmodel4(model1, model2, model3, train) y4 = predict(model4, test) Similar to how the base models' hyper-parameters are being tuned using cross validation prediction error (e.g. neural network's number of nodes, regression's independent variables and potential transformations), there would also be tuning of the stacking model's hyper-parameters in the cross validation loop As for your questions: Yes, the final base learners are fit using the entire training data Yes. The stacking model would use the outputs from the final base learners. Over fitting is related to model complexity and not training on more data.
