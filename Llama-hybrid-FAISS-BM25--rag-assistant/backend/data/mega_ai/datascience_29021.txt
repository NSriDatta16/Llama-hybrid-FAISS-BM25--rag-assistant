[site]: datascience
[post_id]: 29021
[parent_id]: 
[tags]: 
Concrete Dropout for Recurrent Neural Networks (Keras)

I would like to use the Concrete Dropout Framework from GAL in application to recurrent neural networks. There is a great paper about it and the implementation can be found on the website (Thank you so much Yarin!): https://github.com/yaringal/ConcreteDropout He implements a Keras Layer called Concrete Dropout, which can be applied to arbitrairy layers. Nevertheless all his examples are feed forward networks, so here is my question: Can I use it in a straight forward manner to regularize RNNs? Example Code in Keras for this would be: model.add(ConcreteDropout(GRU(32)))
