[site]: datascience
[post_id]: 26569
[parent_id]: 
[tags]: 
How can we decompose generalization gap as done in the paper "Generalization in Deep Learning"?

I am reading a recent paper " Generalization in Deep Learning " and I am unable to understand a step. In this step, they first take neural network as a direct acyclic graph(DAG) and described output of neural network as follows, and then they decomposed generalization gap as follows, without any explanation. Here z is, Can someone explain this or point me towards the right direction.
