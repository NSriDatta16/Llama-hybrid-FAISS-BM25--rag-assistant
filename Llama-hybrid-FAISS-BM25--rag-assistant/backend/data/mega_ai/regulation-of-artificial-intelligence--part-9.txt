eared unintended legal implications, especially for vulnerable groups such as patients and migrants. The risk category "general-purpose AI" was added to the AI Act to account for versatile models like ChatGPT, which did not fit the application-based regulation framework. Unlike for other risk categories, general-purpose AI models can be regulated based on their capabilities, not just their uses. Weaker general-purpose AI models are subject transparency requirements, while those considered to pose "systemic risks" (notably those trained using computational capabilities exceeding 1025 FLOPS) must also undergo a thorough evaluation process. A subsequent version of the AI Act was finally adopted in May 2024. The AI Act will be progressively enforced. Recognition of emotions and real-time remote biometric identification will be prohibited, with some exemptions, such as for law enforcement. The European Union's AI Act has created a regulatory framework with significant global implications. This legislation introduces a risk-based approach to categorizing AI systems, focusing on high-risk applications like healthcare, education, and public safety. It requires organizations to ensure transparency, data governance, and human oversight in their AI solutions. While this aims to foster ethical AI use, the stringent requirements could increase overhead and compliance costs, delaying certain AI designs and deployments. Observers have expressed concerns about the multiplication of legislative proposals under the von der Leyen Commission. The speed of the legislative initiatives is partially led by political ambitions of the EU and could put at risk the digital rights of the European citizens, including rights to privacy, especially in the face of uncertain guarantees of data protection through cyber security. Among the stated guiding principles in the variety of legislative proposals in the area of AI under the von der Leyen Commission are the objectives of strategic autonomy and the concept of digital sovereignty. On May 29, 2024, the European Court of Auditors published a report stating that EU measures were not well coordinated with those of EU countries; that the monitoring of investments was not systematic; and that stronger governance was needed. The EU's Artificial Intelligence Act (Regulation (EU) 2024/1689) entered into force on 1 August 2024, creating a risk-based legal framework for AI systems, including special provisions for general-purpose AI models enforceable by 2 August 2025. Finland Finland has appointed a working group to evaluate what national legislation is required by the EU Artificial intelligence Act, and to prepare a legislative proposal on its national implementation. The working group began its evaluation on April 29, 2024, and is expected to conclude by June 30, 2026. Germany In November 2020, DIN, DKE and the German Federal Ministry for Economic Affairs and Energy published the first edition of the "German Standardization Roadmap for Artificial Intelligence" (NRM KI) and presented it to the public at the Digital Summit of the Federal Government of Germany. NRM KI describes requirements to future regulations and standards in the context of AI. The implementation of the recommendations for action is intended to help to strengthen the German economy and science in the international competition in the field of artificial intelligence and create innovation-friendly conditions for this emerging technology. The first edition is a 200-page long document written by 300 experts. The second edition of the NRM KI was published to coincide with the German government's Digital Summit on December 9, 2022. DIN coordinated more than 570 participating experts from a wide range of fields from science, industry, civil society and the public sector. The second edition is a 450-page long document. On the one hand, NRM KI covers the focus topics in terms of applications (e.g. medicine, mobility, energy & environment, financial services