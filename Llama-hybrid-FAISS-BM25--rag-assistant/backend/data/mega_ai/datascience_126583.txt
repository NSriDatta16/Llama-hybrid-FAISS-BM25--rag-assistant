[site]: datascience
[post_id]: 126583
[parent_id]: 126565
[tags]: 
The simple answer might be that we want our model to be the best in a real-world application . Because of that, in most cases we don't care about training loss as it's not a good sample of real-world data (due to the possible overfitting) and validation loss is - validation data are not directly known by the model. On the other hand, a huge gap between training and validation loss is a disturbing phenomenon and might testify against the quality of the model. If you want to incorporate training loss into your HO, still there might be approaches when it would be beneficial. It might be a plus in Bayesian Optimization - you can read more about that in this well-cited work .
