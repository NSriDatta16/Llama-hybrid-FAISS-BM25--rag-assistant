[site]: datascience
[post_id]: 67047
[parent_id]: 
[tags]: 
Loss being outputed as nan in keras RNN

Since the first Epoch of the RNN, the loss value is being outputted as nan. Epoch 1/100 9787/9787 [==============================] - 22s 2ms/step - loss: nan I have normalized the data. ..., [9.78344703e-01], [1.00000000e+00], [9.94293976e-01]]]) Example of my X_train (float64 of size (9787,60,1)) - array([6.59848480e-04, 6.98212803e-04, 6.90540626e-04, ..., 1.00000000e+00, 9.94293976e-01, 9.95909540e-01]) Example of my y_train (float64 of size (9787,)) My RNN: # Initialising the RNN regressor = Sequential() # Adding the first LSTM layer and some Dropout regularisation regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1))) regressor.add(Dropout(0.2)) # Adding a second LSTM layer and some Dropout regularisation regressor.add(LSTM(units = 50, return_sequences = True)) regressor.add(Dropout(0.2)) # Adding a third LSTM layer and some Dropout regularisation regressor.add(LSTM(units = 50, return_sequences = True)) regressor.add(Dropout(0.2)) # Adding a fourth LSTM layer and some Dropout regularisation regressor.add(LSTM(units = 50)) regressor.add(Dropout(0.2)) # Adding the output layer regressor.add(Dense(units = 1)) # Compiling the RNN regressor.compile(optimizer = 'adam', loss = 'mean_squared_error') # Fitting the RNN to the Training set regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)
