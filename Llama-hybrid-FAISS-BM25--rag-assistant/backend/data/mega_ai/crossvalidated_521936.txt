[site]: crossvalidated
[post_id]: 521936
[parent_id]: 
[tags]: 
Backprop absolute value of matrix

I'm learning neural networks and can't wrap my head around how to do backprop on a model proposed by my professor. Say a weight matrix $A$ in some layer of the model is used to compute intermediate outputs: $$ y = |A|x, $$ where $|A|$ means taking the element-wise absolute values of $A$ . How would I do backprop through this layer?
