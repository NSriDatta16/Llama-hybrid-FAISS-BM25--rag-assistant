[site]: crossvalidated
[post_id]: 325962
[parent_id]: 325940
[tags]: 
You can find an explanation in the original paper here: https://arxiv.org/abs/1603.02754 By default, XGBOOST will create a forest with exactly num_boost_round trees. The algorithm relies on gradient boosting, meaning that each tree is trained one-at-a-time. Training on the current tree stops if either the max_depth has been reached or if additional splits do not significantly raise accuracy.
