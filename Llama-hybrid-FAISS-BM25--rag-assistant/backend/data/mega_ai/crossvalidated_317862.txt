[site]: crossvalidated
[post_id]: 317862
[parent_id]: 
[tags]: 
How can an ensemble perform worse than all but one of its constituents?

I came across a very unusual situation: I trained 5 deep nets on a problem. 4 of the 5 had excellent in- and out-of-sample accuracy. I trained a classifier on the probability outputs of the 5 deep nets to predict the label. (I tried XGBoost, linear methods, random forests, and even random kitchen sinks.) The final classifier performs worse than the 4 "good" base classifiers. Even when I remove the one "bad" base classifier, the final ensemble still performs worse than any individual base classifier. Any ideas what could be going on here? EDIT: the final ensemble's in-sample accuracy is 100%. I think this is clearly a problem of overfitting, but it seems odd it could actually perform worse . I wonder if data augmentation would get me anywhere? EDIT2: Using SMOTE to generate new samples of my 5-dimension vectors right before the last step got some lift, but it still isn't on par with the original base classifiers.
