[site]: crossvalidated
[post_id]: 437565
[parent_id]: 437563
[tags]: 
You cannot just throw regularization at a problem and assume it must improve the model. Ridge is about on par with unregularized here. My suspicion then would be that the price is heavily non -linearly dependent on features, and when the other regularizers start aggressively chomping at the weights of some of the less powerful but valid predictors, you lose some information. That said, this is guesswork based on very little data. It might not even be the fault of the model - it might, for example, be a bug in the feature engineering workflow. One thing to do would be to preprocess some dataset with the same features in the same way and see if the pattern sticks. Another would be to swap out the code doing the preprocessing for some library that does the same thing in its own way.
