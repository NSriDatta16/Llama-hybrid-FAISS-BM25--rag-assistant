[site]: datascience
[post_id]: 115024
[parent_id]: 
[tags]: 
Dialogue history encoding for multi-turn dialogues using Seq2seq

In single-turn dialogue seq2seq models where the goal is to produce a good answer y to a query x, sentences are usually encoded such that x is fed to the encoder, while the decoder is only given a "START" token and the output from the encoder. Often, attention is incorporated into the decoding step by eg concatening the decoder output at time t with the encoder output and performing attention on the resulting vector: attention(y_t, encoder_{out}). What are common ways to encode multi-turn dialogues? The idea here is that the model can be queried k times (where k is the number of turns in the dialogue) for one conversation and has to keep track of the dialogue context throughout to generate coherent responses. A simplistic way to do it would be to simply concatenate the dialogue history over all turns and feed it to the encoder, but I am unsure whether different RNNs (eg LSTMs or GRUs) can handle longer sequences and still maintain a high feature quality.
