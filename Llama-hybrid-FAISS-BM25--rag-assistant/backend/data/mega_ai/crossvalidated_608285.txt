[site]: crossvalidated
[post_id]: 608285
[parent_id]: 
[tags]: 
statistics linking McFadden's $R^2$ to the relationship between two binary variables, akin to correlation (Copula with Bernoulli margins?)

My goal is to create a visualization of the strength of the McFadden's $R^2$ of a (multinomial) logistic regression, where McFadden's $R^2$ is $1-\dfrac{LL(M_1)}{LL(M_0)}$ , involving the ratio of the log-likelihood of the fitted model ( $M_1$ ) to that if an intercept-only model ( $M_0$ ), analogous to $R^2$ in linear regression. If this were a linear regression, a good way to visualize the strength of the $R^2$ would be to plot the predicted and true values. For a multinomial logistic regression, this seems problematic. My idea is to simulate $2\times2$ data that will have a particular McFadden's $R^2$ . Then I will put the counts in an array (confusion matrix of sorts). Then I will plot a $2\times2$ grid with the four squares colored (probably in greyscale) according to their counts. If there are dramatically different colors, that would signal high predictive performance, while colors that are hard to distinguish would indicate more pedestrian performance. I can simulate $2\times2$ data quite easily. set.seed(2023) N However, I do not have any obvious way to control the relationship between x and y in terms of the McFadden's $R^2$ . What is the statistics of this relationship? Can it come through some kind of copula between the marginal Bernoulli distributions? I don't know what I want to do with my visualization, but I want to figure out how to make it so I can figure out how useful it is.
