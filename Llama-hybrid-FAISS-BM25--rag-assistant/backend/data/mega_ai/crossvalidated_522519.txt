[site]: crossvalidated
[post_id]: 522519
[parent_id]: 
[tags]: 
Statistical significance test for 5-fold cross validation on a single dataset

I have used stratified 5-fold cross validation to generate five data folds to compare several (N) deep learning models on a single dataset. Now, I have the fold-wise test accuracies for all of the models as shown below: Algo Fold Accuracy 1 fold1 83.15 1 fold2 83.28 1 fold3 83.53 1 fold4 85.93 1 fold5 86.23 2 fold1 81.18 2 fold2 82.09 2 fold3 80.54 2 fold4 83.23 2 fold5 83.83 3 fold1 81.74 3 fold2 84.18 3 fold3 83.83 3 fold4 84.13 3 fold5 86.83 ----------------- Which statistical test is suitable for assessing the difference among model performances? I've used Friedman test followed by a post-hoc analysis based on the Wilcoxon-Holm method as described here but it shows "Sample size too small for normal approximation." warning and there is no significant difference among all the models. Is it beneficial to do a pairwise McNemar's test after summing up all the contingency metrics from different folds, I mean Cochran's Q test followed by McNemar? Any suggestions will be highly appreciated.
