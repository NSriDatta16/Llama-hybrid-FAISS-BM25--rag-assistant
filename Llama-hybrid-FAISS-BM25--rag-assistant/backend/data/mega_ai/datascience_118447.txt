[site]: datascience
[post_id]: 118447
[parent_id]: 
[tags]: 
Can I use a fitted polynomial regression to make reverse predictions?

I want to start off by acknowledging that this may be a dumb-sounding question to someone with more machine learning experience to me, so please go easy. Here is the background. I am currently an undergraduate assisting with research/development on a ML-driven robotic chemistry system for synthesizing silver nanocrystals. Currently we have a huge, very old, and undocumented Python codebase that manages the robot and implements various ML techniques for predicting properties of nanocrystals given the concentrations of the reagents used for their synthesis. Right now we are using multiple polynomial regression to predict the maximum absorbance wavelength of a nanocrystal using a set of varying reagent concentrations as input attributes. We want to develop a new functionality to make this prediction in the reverse direction, or, given a target maximum absorbance wavelength we want to predict the reagent concentrations which should be used in the reaction. Because of the messy and delicate state of the code and some time constraints, we can't do the easy solution of making a new multi-target model. Here is a sample of the code we're using to implement to regression: from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression poly_regressor = PolynomialFeatures(degree=6) X_poly = poly_regressor.fit_transform(X) poly_reg_model = LinearRegression() poly_reg_model.fit(X_poly, y) Here X is usually 2-3 features depending on the experiment. The degree is always fixed at 6. Is there any was I could use the fitted poly_reg_model or any parameter data stored within it to make a sort of "reverse model" that would predict values of X given y ? I know that this is a messy and possibly bad approach but my hand is being forced. Thanks!
