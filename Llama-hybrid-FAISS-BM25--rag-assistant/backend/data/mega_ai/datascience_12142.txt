[site]: datascience
[post_id]: 12142
[parent_id]: 12128
[tags]: 
I cannot recommend highly enough this online book on neural networks. The tricky part about neural networks is the stuff you mentioned -- what value to use for the learning rate, what topology to use for the network, etc etc -- we call these things hyperparameters to distinguish from parameters which are estimated by the optimization process. This big section of the aforementioned book covers exactly that. I don't know if you'll find what you want though. The reason is because there is no silver bullet.
