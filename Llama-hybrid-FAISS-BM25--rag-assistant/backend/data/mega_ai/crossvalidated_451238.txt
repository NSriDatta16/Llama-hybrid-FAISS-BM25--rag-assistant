[site]: crossvalidated
[post_id]: 451238
[parent_id]: 451211
[tags]: 
We do care but usually either the issue is taken care of, or we're not making a specific distributional assumption with which we could apply those considerations. Many of the usual estimators for commonly used parametric models are either fully efficient under the usual distributional assumptions for that model or asymptotically efficient under those model assumptions. Unless we're dealing with fairly small sample sizes, there's nothing to do. Consider generalized linear models as an obvious example. We often don't have a fully explicit parametric distributional model. We might use a robust procedure, or we might be looking at some convenient estimator along with a bootstrap for dealing with bias and estimating standard error. Without an explicit distribution to even start looking at sufficiency or completeness for, there's nothing to do. (Consider that there may be little point in finding an efficient estimator for a model you're sure will be wrong... what might make more sense would be finding one that does reasonably well in some kind of neighborhood of an approximate model. A good part of the theory for robustness takes a particular sense of the word "neighborhood" when considering a question like this.) In the comments below Nick Cox points out that " deviations from the ideal -- are often perfectly tolerable "; this is certainly the case. Box wrote " Remember that all models are wrong; the practical question is how wrong do they have to be to not be useful ." To me this is a pretty central issue, but I'd add "and in what particular ways" after "how wrong". It's important to understand the behavior of the tools we use away from the situation they're best at; when do they perform quite well, when do they perform badly (and hopefully what else might do at least as well in a similar range of circumstances). We need to keep in mind that statistical tools like tests, estimates and intervals all have several senses in which we expect them to 'perform' (e.g. significance level and power, bias and variance, interval width and coverage); for example, there's often a tendency to focus very hard on significance level on tests without paying attention to power. These issues are less clean-cut than looking at completeness or sufficiency, and we don't have a nice array of "neat" theorems to use. In many cases we may need to use coarser but simpler tools - like simulation - to get much of a sense of what may happen. [In some situations it helps to understand something of the tools of robustness to have clues about what things it might make sense to simulate. It's good to have a sense of what it takes to make something go completely off the rails. I've seen people report that a test has "good robustness to skewness" while simulating nothing more extreme than an exponential distribution, for example, and only examining type I error rate.]
