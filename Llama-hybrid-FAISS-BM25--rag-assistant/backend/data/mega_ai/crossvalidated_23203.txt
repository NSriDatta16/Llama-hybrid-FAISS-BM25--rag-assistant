[site]: crossvalidated
[post_id]: 23203
[parent_id]: 23193
[tags]: 
The idea is nice, but the main problem with averaging is that it works (i.e. removes noise so that you get the essence) only if you average the very similar representation of an exactly the same entity. To get it clear, imagine that you perform your process on a watermelon -- for a human, the word "watermelon" works for a full watermelon as well as for a halved watermelon or even a slice of watermelon, but you won't (even in an idealized world free of practical obstacles) find an algorithm which would manage to align them, and in return you'll get a sphere of a hue somewhere between brown and yellow. Things get worse with less obvious terms -- for instance "house" actually means more less "a building which is/might be used by a small, preferably related group of people for living". This way the act of recognizing it on a picture involves a huge dose of imagination and may greatly depend on culture and environment -- this way you'll end up aligning igloo, mediterranean villa and yurt, which is again obviously impossible. Thus, I think you should rather think of clustering pictures filed under certain subjects and analyzing centroids. The topic is ultra broad, but some directions for start -- extracting interesting object from a picture (to scale it) is called ROI detection ; for aligning you should start from keypoint recognition ; similarity/classification can be usually done without explicit alignment via transformation-independent image features -- for instance PHOW/G or SIFT to name the basic ones.
