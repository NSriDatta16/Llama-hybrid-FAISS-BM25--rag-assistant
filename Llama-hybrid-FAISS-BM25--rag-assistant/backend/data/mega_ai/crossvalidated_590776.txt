[site]: crossvalidated
[post_id]: 590776
[parent_id]: 50561
[tags]: 
Setup Actually you can now get the ICC fairly easy from the model using the performance package. You can also get the alpha coefficient quickly with the psych package. Here below I load the requisite libraries for my example: #### Load Libraries #### library(lmerTest) library(performance) library(psych) library(tidyverse) The dataset I will use for the ICC example comes from cake dataset of the nlme package, which measures breakage angles from different cakes. Since this data doesn't have multiple-item scales from what I recall, I've used the BFI dataset from the psych package separately for that example. You can inspect the data below: #### Load Datasets #### cake ICC Example From there I can fit a mixed model with the cake dataset and get the ICC from the saved model: #### Run Model #### model Which gives me this quick output: # Intraclass Correlation Coefficient Adjusted ICC: 0.671 Unadjusted ICC: 0.581 Reliability Example You don't need to fit a mixed model to get the reliability coefficients and the previous example didn't have multiple item scales from what I recall, so from here I use the BFI data. Since I'm not interested in clumping all the items together, I will only select the A items from the BFI dataset, then run the reliability function on it directly: #### Check Only A Items #### a.items % select(contains("A"), -age, -education) #### Run Reliability #### reliability(a.items) # reliability measures From there I get a host of reliability metrics, but you can see alpha listed among them: Measures of reliability reliability(keys = a.items) omega_h alpha omega.tot Uni r.fit fa.fit max.split All_items 0.64 0.71 0.75 0.89 0.9 0.99 0.75 min.split mean.r med.r n.items All_items 0.62 0.33 0.34 5 For the alpha CI, you can also directly use the alpha function, which only brings back alpha metrics. I specify it explicitly here because sometimes it gives an error otherwise with specific packages loaded: a.items %>% psych::alpha() Which gives me what I want: Some items ( A1 ) were negatively correlated with the total scale and probably should be reversed. To do this, run the function again with the 'check.keys=TRUE' option Reliability analysis Call: psych::alpha(x = .) raw_alpha std.alpha G6(smc) average_r S/N ase mean sd 0.43 0.46 0.53 0.15 0.85 0.016 4.2 0.74 median_r 0.32 95% confidence boundaries lower alpha upper Feldt 0.4 0.43 0.46 Duhachek 0.4 0.43 0.46 Reliability if an item is dropped: raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r A1 0.72 0.73 0.67 0.398 2.64 0.0087 0.0065 A2 0.28 0.30 0.39 0.097 0.43 0.0219 0.1098 A3 0.18 0.21 0.31 0.061 0.26 0.0249 0.1015 A4 0.25 0.31 0.44 0.099 0.44 0.0229 0.1607 A5 0.21 0.24 0.36 0.072 0.31 0.0238 0.1311 med.r A1 0.376 A2 0.081 A3 0.081 A4 0.105 A5 0.095 Item statistics n raw.r std.r r.cor r.drop mean sd A1 2784 0.066 0.024 -0.39 -0.31 2.4 1.4 A2 2773 0.630 0.666 0.58 0.37 4.8 1.2 A3 2774 0.724 0.742 0.72 0.48 4.6 1.3 A4 2781 0.686 0.661 0.50 0.37 4.7 1.5 A5 2784 0.700 0.719 0.64 0.45 4.6 1.3 Non missing response frequency for each item 1 2 3 4 5 6 miss A1 0.33 0.29 0.14 0.12 0.08 0.03 0.01 A2 0.02 0.05 0.05 0.20 0.37 0.31 0.01 A3 0.03 0.06 0.07 0.20 0.36 0.27 0.01 A4 0.05 0.08 0.07 0.16 0.24 0.41 0.01 A5 0.02 0.07 0.09 0.22 0.35 0.25 0.01
