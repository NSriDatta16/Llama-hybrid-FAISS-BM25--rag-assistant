[site]: datascience
[post_id]: 45052
[parent_id]: 
[tags]: 
Any heuristic for minimal DCGAN latent space dimension?

I am highly interested in approaching minimal latent space dimension (as many other may be) for DCGANs or autoencoders. In this example of DCGAN on the MNIST dataset, the person uses a 100-dimensionnal latent space. Since the dataset is made of 10 distinct classes it is reasonable to assume a lower bound of 10 for the minimal DCGAN latent space. But what about examples with no distinct classes such as the latest face generation by Nvidia? If no heuristic exist, is there some way that could minimize the amount of time spent tuning the parameter?
