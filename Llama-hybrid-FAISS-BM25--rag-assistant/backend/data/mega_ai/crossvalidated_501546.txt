[site]: crossvalidated
[post_id]: 501546
[parent_id]: 500685
[tags]: 
Your concern is warranted. XGBoost treats missing values by first splitting the feature without considering missings, then sending the missings down whichever path is more appropriate. So it very likely will end up learning the predictiveness of your missing tests. Not all tree models work this way. See: How do decision tree learning algorithms deal with missing values (under the hood) Meaning of Surrogate Split In particular, using C4.5 with its approach of splitting rows missing the feature across both children with appropriate weights should work quite well. Otherwise, you'll need to either drop or impute. Imputation should also be done with care: simply imputing the mean will still allow a tree to isolate that value. Something based on other features (including @EdM's suggestion for multiple imputation, but also e.g. KNN imputation) will reduce that effect.
