[site]: datascience
[post_id]: 86778
[parent_id]: 
[tags]: 
How data are prepared during training, testing and in production?

Most of real world datasets have features with missing values. Replacing missing values with an appropriate value such as its mean, is considered as a good step in feature engineering. Some times we also standardize/normalize feature columns before feeding it to train an model. Before modelling we also split our dataset to training and testing sets. My first query is how do we do feature engineering in this splitted dataset? Do we use a global mean of the unsplitted features to replace the missing value of those features in both training and testing set or should we use local means of those sets? Like the above question how do we do normalization to a train, test dataset? The last but an important question, in productions we mostly get feature values one at a time (think a row of features), how do we feature engineer such data rows?
