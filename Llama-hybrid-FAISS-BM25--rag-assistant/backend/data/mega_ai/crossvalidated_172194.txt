[site]: crossvalidated
[post_id]: 172194
[parent_id]: 171853
[tags]: 
I think about three main possibilities. The first one is a multiple regression model with C2 as a function of C1 and other predictor variables. The second one is the difference score (C2-C1 seems most natural to me) as a function of C1 and other predictor variables. The third is test score as the dependent variable, and using a mixed models to account for the paired nature of the data. In this form, C1 and C2 are combined in the long format, so that each individual has two rows, one with the value of C1 as the score, and one with the value of C2. They should then also have a categorical variable with the categories C1 or C2 indicating the source of the outcome variable for each row. So the first possibility is a standard multiple regression. You will then model C2 as a function of C1: lm (C2 ~ C1 + x1 + ... + x7) The predictor variables will indicate how each predictor affects the mean of C2, regardless of the value of C1. You may think that certain predictors will influence the way that C1 affects C2. For example, perhaps a good C1 score is associated with an even better C2 score in women, but there is no such relationship in men. Then you need to include interaction effects between C1 and the predictor variables: lm (C2 ~ C1 * x1 + ... + C1 * x7) And you may of course also include interactions between predictors. You may also have a non-linear relationship between C1 and C2, and you can test this by including polynomials of C1 in the model and then comparing the models: lm (C2 ~ C1 + I(C1*C1) + x1 + ... + x7) lm (C2 ~ C1 + I(C1*C1) + I(C1*C1*C1) + x1 + ... + x7) There are also other techniques for modeling non-linearity. The second approach, with using the difference score, was not recommended in the answer to your previous question. I haven't used this approach, but I can see some problems with it and no obvious advantages. The third approach is using mixed models. The data should be organized this way: subject score test x1 x2 x3 ... 1 145 C1 3 2 0 1 172 C2 3 2 0 2 142 C1 0 14 2 2 154 C2 0 14 2 Etc. In this approach, you'll model score as a function of test type (C1/C2) and predictor variables, and you'll allow each individual to have their own baseline score and also, if you want to, their individual effect of test type (C1/C2) on the score. First the random effects section: library(lme4) library(lmerTest) lmer (score ~ fixed effects + (1|subject)) Here we take into account that the observations are paired, and every subject will have their own baseline score level on both tests. lmer (score ~ fixed effects + (type|subject)) Now we added a different slope per individual, so that each individual will have their own effect of type (C1 vs C2) on the score. And we can now add fixed effects: lmer (score ~ type + x1 + ... + x7 + (type|subject)) But now we're only modeling the score, and you're mainly interested in the effect of predictor variables on the difference between C1 and C2 if I understand you correctly. We then have to model this by using interactions between type and predictor variables: lmer (score ~ type * x1 + ... + type * x7 + (type|subject)) Interactions between other predictor variables can of course be added as well. I think this starts to look like a full model. There are many parameters that must be estimated in this model: 2*7 (for all x's and interaction with type) and 1 for type, and then intercept, standard deviation and the two random effects for subject. 20 in total if I'm not mistaken. This might be compared to 17 parameters in the multiple regression model with all interactions between x's and C1. But this model has twice the number of observations. Which method is preferable is up to you, and you can create many models and compare them to see which seems to be the best (using anova, AIC etc). Good luck!
