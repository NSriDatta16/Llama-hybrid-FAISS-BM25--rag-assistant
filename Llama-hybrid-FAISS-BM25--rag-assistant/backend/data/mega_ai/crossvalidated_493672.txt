[site]: crossvalidated
[post_id]: 493672
[parent_id]: 
[tags]: 
Model evidence and Bayesian model selection

I'm reading some course notes on Bayesian statistics and in one of the slides entitled 'model evidence' it writes: $$p(y|m)=\int{p(y,\theta|m)d\theta}=\int{p(y|\theta,m)p(\theta | m)d\theta}$$ "Because we have marginalised over $\theta$ the evidence is also known as the marginal likelihood." I have two issues here. I don't understand how does $p(y,\theta|m)$ become $p(y|\theta,m)p(\theta | m)$ . Is this derived from the multiplication rule of dependent events $P(A,B)=P(A|B)P(B)=P(B|A)P(A)$ ? If so - I don't see how. What is this linked to "we have marginalized over theta"? What does $m$ really stand for? I know what it's just supposed to stand for but it's just beyond my comprehension. How is it related to model parameters?
