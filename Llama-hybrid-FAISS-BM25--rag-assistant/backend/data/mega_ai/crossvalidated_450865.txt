[site]: crossvalidated
[post_id]: 450865
[parent_id]: 
[tags]: 
In Bayesian inference, why is p(D) sometimes called "the evidence"?

Bayes's Theorem states that $p(H|D) = \frac{p(D|H)}{p(D)}p(H)$ where H is the hypothesis and D is the new data. It can also be written as $posterior = \frac{likelihood}{evidence} * prior $ p(D) is sometimes called the "marginal likelihood", because it is the likelihood of the data regardless of whether the hypothesis (or anything else) is true or not, and is sometimes referred to as the "normalising constant". But why is it sometimes called "the evidence"?
