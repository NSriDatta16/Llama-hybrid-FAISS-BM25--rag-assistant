[site]: crossvalidated
[post_id]: 619078
[parent_id]: 618728
[tags]: 
There is a lot to say here and I think it would helpful for frankly everyone to read the Reckless Guide to P-values from Michael J. Lew, in which he explains the nature of significance and hypothesis testing very well: https://link.springer.com/content/pdf/10.1007/164_2019_286.pdf?pdf=inline%20link Also I think that you are confusing significance and confidence as statistics terminology: $\alpha$ significance is a property of data $x$ relative to a hypothesis $H$ , namely $P(X \text{ "more extreme than" }x|H) , while $1-\alpha$ confidence is the property of a region (e.g. an interval) of hypothetical parameter values, such that each value outside of it would fail an $\alpha$ significance test given your data $x$ . Simple math answers to your questions What is that new confidence? Is it as simple as $1âˆ’(0.00001^2)$ ? Under the Null-hypothesis the two samples are independent and so the probabilities multiply, making it a legitimate $0.00001^2$ significance test. If I am going to run 2 identical experiments, how is that different to just running the first t-test with twice as much data? I'll have a lot more to say about this in the 2nd part of the answer but for now: Given the large sample sizes and assuming constant variance we take the t-statistics in the two datasets as $T_1, T_2\sim\mathcal N(0,1)$ under the Null-hypothesis. Now in the combined data the standard error is smaller by a factor of $\sqrt 2$ while the difference of means is just the average of the differences of means in the two subsets. So $$ T_{combined} = \frac{T_1 + T_2}{2}\cdot\sqrt{2} $$ Now we have two (two sided) $\alpha^2$ significance tests: $|T_1| > \Phi^{-1}(1-\alpha/2) \text{ and }|T_2| > \Phi^{-1}(1-\alpha/2)$ $|T_{combined}| > \Phi^{-1}(1-\alpha^2/2)$ . Plugging in $\alpha = 10^{-5}$ we find that $T_1, T_2$ have to be bigger than $4.42$ for 1. and the mean of $T_1, T_2$ has to be bigger than $4.57$ to pass 2. So both being $4.5$ fulfills 1 but not 2, while one being $4$ the other $6$ works only for 2. The 2nd Test would have higher power under the assumptions of a t-test making it the standard. Can I get the same level of confidence on the "longer experiment" just by changing the threshold? How do I calculate what that threshold would be? Not really a math-question, but in the Fisher-approach you would report your p-value as precise as would make sense, while in the Neymann-Pearson-approach to hypothesis testing it is completely unacceptable to change the significance levels (really the critical values) after the fact. Again i implore you to read the link posted at the top. Serious considerations From what you are writing the probability of your results coming from purely random noise is basically zero, however there are an awful lot things that are neither purely random noise nor interesting scientific results, which often means that a 2nd round of data collection ends up very much non identical to the 1st one ( https://en.wikipedia.org/wiki/Replication_crisis ). Measurement error: A loose plug disproved the general theory of relativity with like $|t| > 6$ in 2011: https://en.wikipedia.org/wiki/Faster-than-light_neutrino_anomaly#Measurement_errors Unmeasured confounding: Maybe your circuit picks up thunder storms and there were more thunder storms while you were measuring state A then while measuring state B. Inconsistent effect: Maybe the difference between states is that A picks up on thunder storms but B doesn't. You won't measure a difference when the weather is sunny. Issues in the statistical analysis like: implicit multiple comparison reinforcing random patterns during data cleaning violations of assumptions, e.g. non-constant variance between states ... Repeating your experiment is much more about reducing theses sources of error than about lowering the significance level, which really only deals with purely random noise.
