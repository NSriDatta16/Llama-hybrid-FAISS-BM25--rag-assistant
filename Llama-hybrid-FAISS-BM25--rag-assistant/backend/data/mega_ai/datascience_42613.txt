[site]: datascience
[post_id]: 42613
[parent_id]: 42606
[tags]: 
1 It seems to me that you have very few data points... Your are using Deep Learning, which is a data hungry technique and 315 points are a really small data-set... 2 This is a toy example , where does your data come from? If you created it (for example, a sine) the problem may be easy... I expect you are not trying to forecast a random walk: in time series, looking only at the MAE is not always the best idea. In a random walk, you may be forecasting a sample with the same value as the previous one, and the error still becomes small... Try to plot the true curves and the predicted ones... 3 For the first epochs, the validation accuracy is higher than the one in training. This is quite weird... It may happen if your model is using dropout and you are not disabling it in the validation stage. 4 Once again, having the same accuracy in train and test set is not a bad symptom. You have to evaluate your results with respect to your data, your model, your training technique and so on... Comments: Mos of the times I encountered that the problem with a Deep Learning model comes from a bad data handling procedure (data gathering, data cleaning, data splitting, data processing and so on) and with misleading interpretations of the results, and not from the model itself. Please don not take it wrong, I'm not saying is necessary your case...
