[site]: crossvalidated
[post_id]: 300292
[parent_id]: 300291
[tags]: 
Your data set has the following characteristics and consequences: Not to many data points (100 * 3), so the method should work well on small datasets Only a subset of the features may be used to predict the outcome, so you search for a sparse model You want to interpret your model after learning it. Finite, discrete outcome variable so model should be able to handle classification task You do not mention it, but often it is best to start simple so the model should be simple and fast. Starting simple is key to figure out if and how you want to improve. Based on these I would suggest regularized logistic regression. Examples are: Logistic regression with L2-norm. This minimizes the sum of the squared weights (besides the prediction errors), i.e. close to zero is good enough. Logistic regression with L1-norm. This minimizes the sum of the weights (besides the prediction error), i.e. most weights are exactly zero. Both models can implemented with LogisticRegression . Note the penalty parameter that specifies the regularization (i.e. norm). Also check LogisticRegressionCV that can optimize the regularization strength for you.
