[site]: crossvalidated
[post_id]: 552588
[parent_id]: 552582
[tags]: 
Usually it is a bad idea to reinvent the wheel, so if you need this to solve an applied problem, it would be wise to find already existing solution. It's not exactly the same, but you may be interested in learning more about concepts such as active learning , or human-in-the-loop in machine learning if you consider non-automated solutions as well. The problem of actively sampling the data is often treated as multi-armed bandit problem in discrete case, or Bayesian optimization ( Frazier, 2018 ) in general, with methods such as Gaussian processes for continuous cases. TL;DR those algorithms learn the distribution of the data and can help you to make a decision what kind of data is most promising to sample. Such approaches were used in clinical trials ( Giovagnoli, 2021 , Takahashi and Suzuki, 2010 for some reviews) and other scenarios. If I understand correctly, in your second scenario you want to discard the data. Why would you do that? Throwing out valid data is almost never a good idea, especially if it is expensive to obtain. If you're sampling randomly this should not be a problem. Having unbalanced data is often not a problem . If it is, you can always use an algorithm less susceptible to it, use survey weights to adjust for it, etc.
