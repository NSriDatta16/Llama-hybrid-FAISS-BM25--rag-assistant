[site]: crossvalidated
[post_id]: 102759
[parent_id]: 
[tags]: 
Differences between logistic regression and perceptrons

As I understand, a perceptron/single-layer artificial neural network with a logistic sigmoid activation function is the same model as logistic regression. Both models are given by the equation: $F(x) = \frac{1}{1-e^{-\beta X}}$ The perceptron learning algorithm is online and error-driven, whereas the parameters for logistic regression could be learned using a variety of batch algorithms, including gradient descent and Limited-memory BFGS, or an online algorithm, like stochastic gradient descent. Are there any other differences between logistic regression and a sigmoid perceptron? Should the results of a logistic regressor trained with stochastic gradient descent be expected to be similar to the perceptron?
