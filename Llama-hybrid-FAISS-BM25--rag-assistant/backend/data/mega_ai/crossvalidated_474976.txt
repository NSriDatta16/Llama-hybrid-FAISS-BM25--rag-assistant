[site]: crossvalidated
[post_id]: 474976
[parent_id]: 474962
[tags]: 
My answer is since one cannot in practice even confirm the long term accuracy of a simple regression model, one should only expect a likely diminishing probability of successful forecasting. Now, to attempt to quantify the latter diminishing probability of accuracy, in the classic regression scenario, a simple approach is to obtain a very long history and tabulate the declining accuracy of a best-fitting model, from some selected (at random) short time period, and apply it to the longer historical series. Repeat for various selected periods. As regression theory supplies a probabilistic prediction as well, it may be meaningful to compare the accuracy by assessing # of time frames in the future where it becomes evident that the model has failed based on history. This gives one a contextually based quantitative estimate (and perhaps meaningful insight) on how likely the latest time period based model may behave going forward. However, this is still questionable as have driving forces producing change remained even stationary? Perhaps yes, if physical laws of nature are driving processes, but otherwise, not likely. Now, with respect to machine learning, good news, no need to divide up your database. The not so good news, get a related time series of much longer (essentially older) data, and perform my suggest analysis and use it as a guide to avoid proclaiming excessive expected forecasting accuracy.
