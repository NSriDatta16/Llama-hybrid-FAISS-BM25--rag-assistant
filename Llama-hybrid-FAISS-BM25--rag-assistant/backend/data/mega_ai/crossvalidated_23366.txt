[site]: crossvalidated
[post_id]: 23366
[parent_id]: 23365
[tags]: 
I don't know whether there are recent approaches to the problem, but I think I know why John Platt solved the problem in this kind of unsatisfactory way. Many machine learning algorithms can be written as regularizer plus loss function. For example, ridge regression would be $\lambda ||w||^2 + \sum_i (y_i - w^\top x_i)^2$. The minimizer of this is equivalent to the MAP of a Gaussian prior on $w$ and a Gaussian likelihood (just take an exp around the whole expression and put a minus in front). The SVM objective function looks similar. The squared norm regularizer stays the same, but the loss function is replaced by the hinge loss. The problem is now that the exp of the hinge loss does not correspond to a proper likelihood. Maybe there are approaches to change it, in order to make it into one, but then the question is whether it would still be called SVM. Edit: One thing one could always do is bagging. One could train $n$ SVMs on different parts of the dataset and then simply count the fraction of positive/negative voting SVMs at testing stage. However, this is not specific to SVMs, of course.
