[site]: crossvalidated
[post_id]: 360122
[parent_id]: 185464
[tags]: 
I am no expert in this matter but I think in your case it has to do with the model you chose yourself. If 10k is already a small size for a neural network, aren't the fold sub-samples way to little for a dataset with 300-400 features and a min of 20 and max of 250 neurons? Probably your neural network is not able to learn anything from the fold datasets, while the full training dataset maybe just about enough to notice a difference? I can't find a concrete paper but there's a lot of literature on-line discussing how the complexity of the problem defines the optimal training dataset size. Here 's an oline blog that cites some good papers.
