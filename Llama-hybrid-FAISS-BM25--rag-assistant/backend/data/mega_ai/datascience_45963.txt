[site]: datascience
[post_id]: 45963
[parent_id]: 
[tags]: 
How to train continuous/soft classification model?

The classic classification problem is like finding the function $F:\mathbb{R}^n\mapsto \{0,1\}$ . The label set will be [Apple,Banana,Banana,...,Apple]. What if I want to train a function $F:\mathbb{R}\mapsto[0,1]$ ? My samples could be something like "this sample has 80% probability to be Apple and 20% to be Banana". It seems a multi-output neural network works, as we can apply the softmax loss with cross entropy loss. What about random forest or other algorithms? I have tried some common algorithms in scikit-learn without any luck. For example, this code: import numpy as np from sklearn.ensemble import RandomForestClassifier N_FEATURES = 10 N_SAMPLES = 1000 N_CLASSES = 2 train_x = np.random.rand(N_SAMPLES, N_FEATURES) train_y = np.random.rand(N_SAMPLES, N_CLASSES) train_y = np.apply_along_axis(lambda x: x/x.sum(), 1, train_y) model = RandomForestClassifier(n_estimators=10).fit(train_x, train_y) Yields a ValueError: Unknown label type: 'continuous-multioutput' .
