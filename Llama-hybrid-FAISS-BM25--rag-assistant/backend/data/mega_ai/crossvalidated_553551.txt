[site]: crossvalidated
[post_id]: 553551
[parent_id]: 
[tags]: 
How to confirm (for reviewers) that possible nuisance variables have not affected my experimental outcome?

We are undergoing review on an auditory perception experiment. We purposely used naturalistic stimuli, which differ in various acoustic features. To deal with this natural variability, we produced 8 different versions of each stimulus and counterbalanced them across participants (n > 250). Meaning that each participant heard each auditory stimulus, but the experimental manipulations performed on that stimulus varied according to the participant's experimental condition. The stimuli were also heard in a different order across the participant groups. Finally, each stimulus ID was also included as a random intercept in the GLMM modelling (the model failed to converge when we tried to include the stimulus ID as a slope with regards to the fixed effects). There are a total of 20,000+ observations (binary correct/incorrect response variable). From our perspective, we would expect that these natural stimuli differ, and it is a degree of experimental control we have knowingly forfeited to enhance ecological validity. One of the reviewers is adamant that we show that possible "nuisance" acoustic features have not swayed our results and the editor has gone with them, although it isn't totally clear from their comments whether they are fully aware of the counter-balancing and shuffling we performed (although we did report it in the manuscript). We are happy to appease, but there are quite a few possible variables to look at, some of which are probably related to one another. The study is on a relatively new topic with many unknowns, so we don't have good theoretical reasons to expect some features will influence participants more than others, however. In summary, the goal is to show that our experimental manipulations still produce the effects we predicted (as they seem to have, robustly), even after taking these extra features into account. I have been Googling PCA, factor analysis, and saw the MATLAB documentation on feature selection using NCA . I tried out the NCA approach, including all the possible predictor terms as well as random effect terms, and it basically confirmed what I expected from visualising the data: the experimental manipulation variables had the largest feature weights, and there are some non-zero, but less highly weighted "nuisance" variables, and then about an equal number of zero-weighted "nuisance" variables. But I couldn't find any representative papers from my field that made use of this technique, so it might just cause me more trouble with the review process. I am trying to figure out how to throw this unplanned acoustic analysis into our paper in a scientifically transparent way with some level of "significance" to appease the reviewer/editor, but I'm not sure which route is best. Would it be valid (and potentially more straight-forward) to simply report a post hoc GLMM that includes every single possible predictor variable, and show that the experimental effects of interest have held?
