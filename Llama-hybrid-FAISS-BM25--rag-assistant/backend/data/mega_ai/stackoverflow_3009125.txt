[site]: stackoverflow
[post_id]: 3009125
[parent_id]: 3003781
[tags]: 
One solution is to have a second table to use for detecting clashes, and populate that with a trigger. Using the schema you added into the question: CREATE TABLE medicinal_product_date_map( aic_code char(9) NOT NULL, applicable_date date NOT NULL, UNIQUE(aic_code, applicable_date)); (note: this is the second attempt due to misreading your requirement the first time round. hope it's right this time). Some functions to maintain this table: CREATE FUNCTION add_medicinal_product_date_range(aic_code_in char(9), start_date date, end_date date) RETURNS void STRICT VOLATILE LANGUAGE sql AS $$ INSERT INTO medicinal_product_date_map SELECT $1, $2 + offset FROM generate_series(0, $3 - $2) $$; CREATE FUNCTION clr_medicinal_product_date_range(aic_code_in char(9), start_date date, end_date date) RETURNS void STRICT VOLATILE LANGUAGE sql AS $$ DELETE FROM medicinal_product_date_map WHERE aic_code = $1 AND applicable_date BETWEEN $2 AND $3 $$; And populate the table first time with: SELECT count(add_medicinal_product_date_range(aic_code, vs, ve)) FROM medicinal_products; Now create triggers to populate the date map after changes to medicinal_products: after insert calls add_, after update calls clr_ (old values) and add_ (new values), after delete calls clr_. CREATE FUNCTION sync_medicinal_product_date_map() RETURNS trigger LANGUAGE plpgsql AS $$ BEGIN IF TG_OP = 'UPDATE' OR TG_OP = 'DELETE' THEN PERFORM clr_medicinal_product_date_range(OLD.aic_code, OLD.vs, OLD.ve); END IF; IF TG_OP = 'UPDATE' OR TG_OP = 'INSERT' THEN PERFORM add_medicinal_product_date_range(NEW.aic_code, NEW.vs, NEW.ve); END IF; RETURN NULL; END; $$; CREATE TRIGGER sync_date_map AFTER INSERT OR UPDATE OR DELETE ON medicinal_products FOR EACH ROW EXECUTE PROCEDURE sync_medicinal_product_date_map(); The uniqueness constraint on medicinal_product_date_map will trap any products being added with the same code on the same day: steve@steve@[local] =# INSERT INTO medicinal_products VALUES ('1','A','2010-01-01','2010-04-01'); INSERT 0 1 steve@steve@[local] =# INSERT INTO medicinal_products VALUES ('1','A','2010-03-01','2010-06-01'); ERROR: duplicate key value violates unique constraint "medicinal_product_date_map_aic_code_applicable_date_key" DETAIL: Key (aic_code, applicable_date)=(1 , 2010-03-01) already exists. CONTEXT: SQL function "add_medicinal_product_date_range" statement 1 SQL statement "SELECT add_medicinal_product_date_range(NEW.aic_code, NEW.vs, NEW.ve)" PL/pgSQL function "sync_medicinal_product_date_map" line 6 at PERFORM This depends on the values being checked for having a discrete space- which is why I asked about dates vs timestamps. Although timestamps are, technically, discrete since Postgresql only stores microsecond-resolution, adding an entry to the map table for every microsecond the product is applicable for is not practical. Having said that, you could probably also get away with something better than a full-table scan to check for overlapping timestamp intervals, with some trickery on looking for only the first interval not after or not before... however, for easy discrete spaces I prefer this approach which IME can also be handy for other things too (e.g. reports that need to quickly find which products are applicable on a certain day). I also like this approach because it feels right to leverage the database's uniqueness-constraint mechanism this way. Also, I feel it will be more reliable in the context of concurrent updates to the master table: without locking the table against concurrent updates, it would be possible for a validation trigger to see no conflict and allow inserts in two concurrent sessions, that are then seen to conflict when both transaction's effects are visible.
