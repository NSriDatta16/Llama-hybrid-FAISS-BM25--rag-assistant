[site]: crossvalidated
[post_id]: 93748
[parent_id]: 
[tags]: 
Augmented Dickey Fuller output conflicting in Stata

I am required to perform unit root testing on a given time series. The output obtained in Stata is somewhat confusing me. To the best of my knowledge I am obtaining two conflicting results, Stata indicating that the time series fits a unit root process while also seemingly saying that the coefficient is significantly different from zero, hence contradicting the idea that the time series indeed follows a unit root process. This is the output obtained in Stata: . dfuller series3, noconstant regress lags(0) Dickey-Fuller test for unit root Number of obs = 48 ---------- Interpolated Dickey-Fuller --------- Test 1% Critical 5% Critical 10% Critical Statistic Value Value Value ------------------------------------------------------------------------------ Z(t) 8.943 -2.623 -1.950 -1.609 ------------------------------------------------------------------------------ D.series3 | Coef. Std. Err. t P>|t| [95% Conf. Interval] -------------+---------------------------------------------------------------- series3 | L1. | .1314633 .0147005 8.94 0.000 .1018897 .1610369 ----------------------------------------------------------------------------- Clearly the test statistic is indicating that the null hypothesis is accepted and hence the time series fits a unit root process. However, the p-value obtained for L1 is 0.000 indicating that it is significantly different from zero (0.1314633 cannot be treated as being 0). I read somewhere that this might be related to the Augmented Dickey Fuller test itself; however, I cannot seem to find this link again. I also ran the Augmented Dickey Fuller test using lags as well as the Philips-Perron test and obtained similar results. Would anyone have any idea why the ADF is giving such results and what might be the cause of this anomaly?
