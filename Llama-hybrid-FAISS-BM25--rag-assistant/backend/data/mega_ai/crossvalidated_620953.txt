[site]: crossvalidated
[post_id]: 620953
[parent_id]: 
[tags]: 
What can you do with quantified uncertainty in latent variable time-series models?

Uncertainty quantification in latent variable models is a topic I am interested in, but I am struggling to grasp the difference between what you can do with quantified parameter uncertainty and quantified uncertainty in the latent state. This is particularly ambiguous to me in applications involving time-series models (such as SSMs). Given a sequential latent model with posterior belief $p(z_t|x_{1:T}; \theta)$ and transition probability $p(z_t|z_{t-1}; \phi)$ , our goal is to estimate these distributions (e.g. using variational inference) to be able to both extract the underlying causal explanations for observed data and make predictions about the future. I understand that estimating these distributions give us the uncertainty in the latent state (e.g. the variance in the posterior), and that by using Bayesian methods to find $p(\theta|z, x)$ we can quantify uncertainty in the fitted parameters, but what do these quantities actually help us do regarding making predictions about future timesteps, and what's the difference between what we can do with each of them?
