[site]: crossvalidated
[post_id]: 600309
[parent_id]: 555971
[tags]: 
Your calculation doesn't reproduce the p-value correctly because by default logistf uses Firth's penalized maximum likelihood to fit the logistic regression and the penalty is a function of the predictors. In effect, the full model and the reduced model are penalized differently. The penalized likelihood is: $$ \begin{aligned} \log L^*(\beta) = \log L(\beta) + \frac{1}{2}\log\det I(\beta) \end{aligned} $$ where $I(\beta)$ is the Fisher information matrix. (The second term â€” the penalty â€” is the term which @Mark points out in a comment.) The coefficients $\beta$ are estimated iteratively and, given the current value for the probabilities of success $\widehat{p}$ , the information matrix is calculated as: $$ \begin{aligned} I(\widehat{\beta}) = X^\top\operatorname{diag}\left\{\widehat{p}(1-\widehat{p}\right\}X \end{aligned} $$ Note that the penalty is a function of the fitted probabilities $\widehat{p}$ as well as the model matrix $X$ . So when you drop a predictor, you change the penalty term as well. Let's use your example to demonstrate the issue. Note: I drop dia from the full model; otherwise the data is completely separable. With this change, we can fit the model case ~ oc + vic + vicl + vis + age with and without penalization. For more about complete separation, see How to deal with perfect separation in logistic regression? . full.model $loglik, reduced.model = reduced.model$ loglik, null.model = null.model$loglik ) #> full null #> full.model -136.6498 -157.3390 #> reduced.model -140.8798 -158.3699 #> null.model -162.6972 -162.6972 We get three different values for the null log-likelihood! That's because the three models â€” the full model, the restricted model (without age ) and the explicit null model â€” are all penalized to a different degree by Firth's method. data.frame( pvalue.logistf = full.model$prob["age"], pvalue.byhand = 1 - pchisq(2 * (full.model$loglik[1] - reduced.model$loglik[1]), df = 1) ) #> pvalue.logistf pvalue.byhand #> age 0.01055201 0.003630392 Now let's turn off penalization by setting firth = FALSE and refit the same three models. full.model Reassuringly, we get the same value for the null log-likelihood in the second column because the models are fitted with the standard maximum likelihood method. There is no penalty. rbind( full.model = full.model$loglik, reduced.model = reduced.model$loglik, null.model = null.model$loglik ) #> full null #> full.model -143.1338 -164.7384 #> reduced.model -146.5363 -164.7384 #> null.model -164.7384 -164.7384 And now the calculation "by hand" does reproduce the p-value for the age predictor. data.frame( pvalue.logistf = full.model$prob["age"], pvalue.byhand = 1 - pchisq(2 * (full.model$loglik[1] - reduced.model$loglik[1]), df = 1) ) #> pvalue.logistf pvalue.byhand #> age 0.009090372 0.009090372
