[site]: crossvalidated
[post_id]: 147950
[parent_id]: 142057
[tags]: 
With a normally distributed response a simple way to do this is to run it as a 'flat' / one-way ANOVA. Then you would run a-priori orthogonal contrasts: {A~B vs. ~AB}, and then {A~B&~AB vs. AB}. I gather these may be binomial, so you could do the analogous thing with logistic regression, or even a set of chi-squared analyses. Here is an example walkthrough using your data, with R: d = data.frame(s=c(5 ,8, 15), f=250-c(5 ,8, 15), treat=c("AnB", "nAB", "AB")) summary(glm(cbind(s,f)~treat, family=binomial, d)) # ... # Coefficients: # Estimate Std. Error z value Pr(>|z|) # (Intercept) -2.7515 0.2663 -10.332 Note that the p-values listed with the coefficients are Wald tests, and that with multiple categories (as here with three), they do not quite tell you if the conditions differ, but only if the indexed condition differs from the reference condition. To test whether there are differences amongst the three conditions, I have performed likelihood ratio tests using the null and residual deviances and degrees of freedom. By conventional criteria, the treatments do not quite differ significantly. summary(glm(cbind(s,f)~treat, family=binomial, d[-3,])) # ... # Coefficients: # Estimate Std. Error z value Pr(>|z|) # (Intercept) -3.8918 0.4518 -8.615 (In this case, you could use the Wald test, but I ran a likelihood ratio test for consistency.) There is not enough evidence to conclude the $A\neg B$ and $\neg AB$ conditions differ. summary(glm(cbind(s,f)~I(treat=="AB"), family=binomial, d)) # ... # Coefficients: # Estimate Std. Error z value Pr(>|z|) # (Intercept) -3.6233 0.2810 -12.893 The data are not consistent with the assumption that $AB$ is the same as $A\neg B\cup\neg AB$.
