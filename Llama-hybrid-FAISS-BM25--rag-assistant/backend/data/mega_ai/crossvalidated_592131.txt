[site]: crossvalidated
[post_id]: 592131
[parent_id]: 
[tags]: 
Bayesian optimal loss functions - Are linear regression and logistic regression equivalent?

According to this page , the square & logistic loss functions are "bayes consistent": A Bayes consistent loss function allows us to find the Bayes optimal decision function ${\displaystyle f_{\phi }^{*}}$ by directly minimizing the expected risk and without having to explicitly model the probability density functions. If my understanding is correct, this means that: if it was possible to minimize the expected risk, minimizing the square loss and the logistic loss would both return the same function (the Bayes optimal classifier, which is optimal for the accuracy metric). in practice, we can only minimize the empirical loss, not the expected loss. Does this suggest an equivalence between linear regression and logistic regression? That both would return the optimal classification function if the training set is big enough?
