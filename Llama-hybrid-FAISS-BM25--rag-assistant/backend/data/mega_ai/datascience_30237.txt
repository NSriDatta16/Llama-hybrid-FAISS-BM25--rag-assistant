[site]: datascience
[post_id]: 30237
[parent_id]: 
[tags]: 
Does L1 regularization always generate a sparse solution?

Following is a plot in Bishop's Pattern Recognition and Machine Learning explaining why $L_1$ regularization would lead to sparse solution, and I understand that in this case $w_1$ would be automatically constrained to be 0. However, it seems to me that it is not always true that the corner point is closest to the optimal unconstrained solution. For instance, if the optimal unconstrained solution is at the red cross, then there exists some point on the side that is closer to the red cross than corner points. In this case, do we still have sparse solutions?
