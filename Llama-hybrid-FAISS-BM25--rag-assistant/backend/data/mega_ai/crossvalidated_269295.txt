[site]: crossvalidated
[post_id]: 269295
[parent_id]: 
[tags]: 
Using SVM regression model without cross-validation and parameter optimization

I am working on a regression model of quite complicated dataset. Dataset is heterogenous in the sense that it contains elements of significantly different properties. I am using $\epsilon$ type regression with radial basis kernel (RBF) (libsvm implementation). When I arbitarily set parameter C (~$200$) and leave the rest of parameters with default values I get really good regression outcome (using testing set, which was previously unseen by the model). However when I try to optimize the parameters ($C$, and RBF $\gamma$) I get quite lousy results. For example using grid search with k-fold cross-validation with respect to minimizing mean square error or max error or maximizing $R^2$ on learning dataset, leads to squared correlation coefficient $R^2$ against testing data about 0.5, whereas for arbitrarily chosen parameters I get $R^2$ about 0.9. Actually this is the first time I have such phenomenon occur, and I am tempted to interpret this as a result of the data charachteristic, and state that the possible model overtraining leads to improvement of the regression results. I really need hints on this. How to interpret such behaviour, what methodology can I use to find the optimal parameters, what optimization criterion function etc.?
