[site]: crossvalidated
[post_id]: 401863
[parent_id]: 401860
[tags]: 
I think if you plotted the average loss for each epoch, instead of the average loss for each minibatch, you'd see that your loss is basically flat, indicating that the network is not improving from one epoch to the next. If the quality of model predictions doesn't change over time, and the inputs always appear in the same order, then you'd expect to see this kind of pattern. So what's happening here is (1) the network isn't getting better at making predictions and (2) the inputs are always in the same order. This will give a periodic appearance to the plot, because the same predictions are being made at the same relative position, over and over again. Some suggestions on how to improve the network can be found here: What should I do when my neural network doesn't learn?
