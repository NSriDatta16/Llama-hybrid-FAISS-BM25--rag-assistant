[site]: crossvalidated
[post_id]: 295192
[parent_id]: 194142
[tags]: 
One more idea about dimensionality reduction in the context of 1x1 filters: Take for example an 4096x8x8 fc7 layer from FCN. What happens if the next layer (call it fc8) is 2048x8x8 with filter size 1? fc7 is very deep inside the network, each of its 4096 features is semantically rich, but each neuron (e.g. input image is 250x250x3) has a large receptive field. In other words, if a neuron is very active, we know that somewhere in its semantic field there's a corresponding feature present. Take for example a left-uppermost neuron in fc8 with a 1x1 filter. It connects to all 4096 neurons/features only in the same receptive field (upper-left corner of the image), each of which is activated by a single feature. Some (let's same 500) of them are very active. If the resulting neuron is also very active, it means it probably learnt to identify 1 or more features in this receptive field. After you've done this 2048 times for left-uppermost neurons in fc8, quite a few of them (e.g. 250) will be very active, meaning they 'collected' features from the same receptive field through fc7, and many very likely more than one. If you keep reducing the dimensionality, a decreasing number of neurons will be learning an increasing number of features from the same receptive field. And since spatial parameters 8x8 remain the same, we do not change the 'view' of each neuron, thus do not decrease the spatial coarseness. You may want to have a look at 'Fully Convolutional Networks' by Long, Shelhamer and Darrel.
