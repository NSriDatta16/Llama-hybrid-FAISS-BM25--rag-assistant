[site]: datascience
[post_id]: 13740
[parent_id]: 
[tags]: 
How to train neural networks with large sized data sets?

I have a dataset size of ~500000 with input dimension 46. I am trying to use Pybrain to train the network but the training is extremely slow for the whole dataset. Using batches of 50000 data points, each batch takes more than 2 hours for training. What are caveats of optimizing the network design so that the training is faster?
