[site]: datascience
[post_id]: 48428
[parent_id]: 
[tags]: 
Reverse engineering on Xgboost model

I am doing experiments on https://www.physionet.org/challenge/2017/sources/ submission. I like one of the submission code, which use Xgboost to train the classifier. Training data is in .mat file which I converted to CSV file for training. In the below code, I have a pre-trained model xgb.bin , with which I can test any input signal. But I want to train the model using different data and create my own training model. Here, is the code which predicts the class name for a given input ECG file: def predict(data): #data = io.loadmat(path)['val'][0] from numpy import genfromtxt data = genfromtxt('testdata/val.csv', delimiter=',') features_noise = np.zeros((5, )) snr, rr_num, var, fr, fr2 = find_noise_features(data) features_noise[0] = snr features_noise[1] = rr_num features_noise[2] = var features_noise[3] = fr features_noise[4] = fr2 features = extract_basic_features(data, 30000) features = np.hstack((features, features_noise.reshape(1, -1))) mean_ = np.array([15.96300284066109753667, 0.00412371298595770857, 38811.34497233365254942328, 0.48050717744965593115, 0.14397582347542958736]) scale_ = np.array([4.22917401559752281770, 0.00093664880988427878, 62350.76443798459513345733, 0.15396567666240373873, 0.07085474966801086349]) features_noise -= mean_ features_noise /= scale_ prediction = 0 if features_noise[0] 6.0: prediction = 3 if features_noise[3] > 3.0: prediction = 3 if features_noise[4] I could create dfeatures for all training data which is in the CSV file. (I am reading each CSV individually and calculating feature. Is it correct?) Now once I have defaulters for all training ECG files, I want to create a xgboost model. But I donâ€™t have any clue for that. Any suggestion highly appreciated.
