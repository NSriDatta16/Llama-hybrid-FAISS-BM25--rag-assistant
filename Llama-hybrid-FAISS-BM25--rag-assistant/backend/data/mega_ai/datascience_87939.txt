[site]: datascience
[post_id]: 87939
[parent_id]: 87935
[tags]: 
Doing it is easy. Simply create a mapping between your 11 values and embeddings of any size. Choosing the values for the embeddings is typically done through training a neural network that embeddings are part of. You could use dimensionality reduction techniques like PCA for instance as an alternative. Now, embeddings only make sense if they represent a feature of dimensionality $D$ with embeddings of dimensionality between 1 and $D-1$ . So in your case, I don't know how much you will benefit from the dimensionality reduction itself. You may experience benefits of replacing sparse with dense features, but this needs to be empirically tested.
