[site]: datascience
[post_id]: 89143
[parent_id]: 
[tags]: 
Machine Learning algorithms and Cross Validation, the best practice

I'm new in Machine Learning, and I'm studying the main concepts behind algorithms from the mathematical point of view. I'm also trying to start implementing some algorithms for regression purposes using sklearn library. I would like to summarize the main steps in ML and provide the question: I understand the dataset, clean and prepare, identifying a set of suitable algorithms for such dataset. Train the algorithms and see the performances, choosing the best one. Hyperparameter tuning of the best performing algorithm using Random or Grid Search with cross-validation between 5-10 I have the best parameters for training the algorithm, I train the algorithm with such params. Now the question that arises for which I am not clear what to do. May I consider to train the algorithm with the best parameters also performing the cross-validation? or Have I to train the algorithm without the cross-validation? In short, The model puts into production is the model trained with cross-validation (for instance using KFold for training in step 4) or the model trained without (step 4)?
