[site]: datascience
[post_id]: 23481
[parent_id]: 
[tags]: 
What is the point of tensors in CNNs? Why not simply reshape the data into matrices?

Take the following tensor: $$ \left[\begin{array}{cc} a & b & c\\ d & e & f\\ g & h & i\\ \end{array}\right] $$ $$ \left[\begin{array}{cc} j & k & l\\ o & n & m\\ p & q & r\\ \end{array}\right] $$ Where each matrix represents a channel. This could be reshaped fairly easily into a vector: $$ [a,d,g,b,e,h,c,f,i,j,o,p,k,n,q,l,m,r] $$ And then concatenated row-wise with other vectorized tensors to form a typical flat-file dataset of dimension $N \times P$, where $N$ is the number of training samples and $P$ is the product of the tensor dimensions. Rather than futzing with a convolutional layer, one could simply constrain ones weights to be zero in the subsequent layer. If $X$ is a flat $N\times P$ dataset of concatenated vectorized tensors, then the convolutional weights would form a sparse matrix, with the first two columns of a $P \times 4$ convolutional "layer" being $2\times 2\times 2$ filter being $$ \left[\begin{array}{c} w 0\\ w0\\ 00\\ ww\\ ww\\ 00\\ 0w\\0w\\00\\w0\\ w0\\00\\ww\\ww\\0w\\0w\\0w\\00 \end{array}\right] $$ This seems to me more intuitive than the tensor formulation, and could be computed fairly simply using sparse matrix packages. Perhaps it is partly matter of taste. But I'm curious: is there anything special about the tensor paradigm -- either mathematically or computationally -- that is superior to the flattened representation? I understand that computers convert matrix algebra to for-loops "under the hood", but doesn't the advent of the GPU make such explicit looping irrelevant?
