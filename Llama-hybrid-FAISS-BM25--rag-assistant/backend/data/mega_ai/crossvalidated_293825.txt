[site]: crossvalidated
[post_id]: 293825
[parent_id]: 
[tags]: 
Biasing a trained neural network to a specified category for unexpected inputs

I have been using a neural network to classify an object as either 'good' or 'defective' (2 classes). It seems to be doing a decent job of it except in certain unforeseen/unexpected scenarios. For example, in the above image, 'good' objects are shown in green, and the 'defective' ones are in Red. The second last row has a large object formed by the merger of many objects. Ideally, it should be 'Red', instead the trained network classifies it as 'Good (Green)'. The reason is that such an object was never seen during the training phase. Also, see the left most object in the first row from the top. It should also be 'Red'; but, because it has features never seen during the training, the network classifies it as 'good'. This has been a general trend so far where all such unknown shapes are classified as 'good' with very high classification score. Now, there could be many such unexpected scenarios with unnatural shapes (see image below). so, it is not possible to create a training set to train a network. I would instead like to create a network where such unknown shapes would by default be classified to 'defective (Red)' category, or to any other fixed class category of my choice. I use binary objects for training, so the features are statistical in nature (area, diameter, form factor, convexity etc..). Any suggestions as to how can I accomplish this?
