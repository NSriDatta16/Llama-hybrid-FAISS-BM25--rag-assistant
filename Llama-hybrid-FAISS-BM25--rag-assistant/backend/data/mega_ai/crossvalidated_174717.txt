[site]: crossvalidated
[post_id]: 174717
[parent_id]: 174708
[tags]: 
The two answers are equivalent. I personally would think of it as average error instead of the sum. But remember that gradient descent has a parameter called the learning rate, and that only a portion of the gradient of the error is subtracted. So whether the error is defined as total of average can be compensated by changing the learning rate.
