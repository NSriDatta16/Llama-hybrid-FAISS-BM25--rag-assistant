[site]: crossvalidated
[post_id]: 143477
[parent_id]: 
[tags]: 
How to use information about likelihood of classes in a classifier?

General question: How can information about the likelihood of classes be used to improve a classifier? Suppose that the probability of each class is known quite precisely (from a very large sample), but the number of observations which include both the features and the class is much smaller. It seems intuitively that the probability of a class affects how confident we can be about the predictive power of features associated with that class. The probability of a class may be quite different in the samples for which we have features than in the population at large, either because of sampling bias or because of variation due to small sample size; using the accurate probabilities may help. Specific question: My classes are related pairs of categorical values, where the probability of some kinds of pairs is much less than expected from multiplying the probabilities of the individual values. I have a lot of data (millions of samples) about the probability of each class/pair (without features), and a little bit of data (hundreds of samples) with features that I am trying to build a SVM classifier from. Toy example with two observations in each pair which are either A or B, and two features which are almost perfectly predictive: population probabilities from huge sample: A,A 78% B,B 20% A,B 1% B,A 1% data for SVM: 0,0 A,A (80 times) 1,1 B,B (20 times) 0,1 A,B 1,0 B,A Naive SVM of course predicts A,B from 0,1. It seems to me the correct prediction for 0,1 considering the population from which this data is drawn may be A,A because A is more common, and the A,B pair is rare. Even if 0 is predictive for A and 1 is predictive for B (which they seem to be in this case - we don't have a single sample that would suggest otherwise), then if we see 0,1 it still may be quite unlikely to be A,B because of what is known about the population. The fact that we have seen a 0 in 0,1 implies that there was an A, which strongly implies that there wasn't a B. (Presumably if the classifier had more samples, a few of them would be 0,1 A,A or even 1,1 A,A which would show that 1's are not perfectly predictive in this case, and in fact the probability of 0,1 A,A is higher than 0,1 A,B. But the probability of this kind of counter-example not appearing in the data by chance, even if it was more common than 0,1 A,B, is pretty significant given the small sample size.)
