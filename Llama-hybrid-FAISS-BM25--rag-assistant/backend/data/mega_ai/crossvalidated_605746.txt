[site]: crossvalidated
[post_id]: 605746
[parent_id]: 
[tags]: 
Is multinomial logistic regression symmetric?

Simple linear regression is symmetric in the sense that, if I regress $Y$ on $X$ or $X$ on $Y$ , I get the same $R^2$ and result from the overall $F$ -test. set.seed(2023) N summary(Ly) Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -3.5268 -0.6544 -0.0301 0.6608 3.1812 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 0.0146774 0.0308043 0.476 0.634 x 0.0004153 0.0305085 0.014 0.989 Residual standard error: 0.9738 on 998 degrees of freedom Multiple R-squared: 1.857e-07, Adjusted R-squared: -0.001002 F-statistic: 0.0001853 on 1 and 998 DF, p-value: 0.9891 > summary(Lx) Call: lm(formula = x ~ y) Residuals: Min 1Q Median 3Q Max -3.2220 -0.7032 -0.0229 0.6861 4.5979 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -0.0239849 0.0319559 -0.751 0.453 y 0.0004471 0.0328434 0.014 0.989 Residual standard error: 1.01 on 998 degrees of freedom Multiple R-squared: 1.857e-07, Adjusted R-squared: -0.001002 F-statistic: 0.0001853 on 1 and 998 DF, p-value: 0.9891 Assuming two categorical variables, $X$ and $Y$ , I can fit a multinomial logistic regression using either as the feature to predict the other. I can also calculate $R^2_{McFadden}$ for each model and overall likelihood ratio tests. In a simulation, it seems to matter which variable is the feature. However, I wonder if this is just a numerical issue. Does the math say these are the same? library(nnet) library(lmtest) # Simulate data # set.seed(2023) N $value MNLL0 value R2_McFadden R2_McFadden [1] 0.03431655 > > # G-test (“lr” means likelihood ratio) > # > lmtest::lrtest(L1, L0) Likelihood ratio test Model 1: y ~ x Model 2: y ~ 1 #Df LogLik Df Chisq Pr(>Chisq) 1 290 -3267.9 2 29 -3384.1 -261 232.26 0.8994 However, when I flip the variables, the numbers change slightly. L2 $value MNLL3 value R2_McFadden R2_McFadden [1] 0.05055947 > > lmtest::lrtest(L2, L3) Likelihood ratio test Model 1: x ~ y Model 2: x ~ 1 #Df LogLik Df Chisq Pr(>Chisq) 1 270 -2180.7 2 9 -2296.8 -261 232.26 0.8994 EDIT I thought both the $R^2_{McFadden}$ and the p-value differed, but it's only $R^2_{McFadden}$ . That strikes me as the weirdest possibility of them all: a change to the value that quantifies relationship strength ( $R^2_{McFadden}$ ) yet no change to the p-value testing that relationship.
