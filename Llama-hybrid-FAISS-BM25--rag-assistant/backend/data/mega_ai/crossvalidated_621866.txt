[site]: crossvalidated
[post_id]: 621866
[parent_id]: 
[tags]: 
Implementing a collaborative filtering model for recommending items to new users and how to evaluate it

I have some data for a collaborative filtering problem, which can be represented in a user-item interaction matrix. The data consists of 20 million orders, where there are 15000 different items, and we only now if an item was bought or not (implicit data) for each order. It is also important to note that the data is really sparse, where smaller oders of size 2, 3 and 4 are the most common (orders of size 1 were removed). I want to use this data to recommend items to users that have already added some items to their digital shopping cart but havent payed yet. The data is anonymized, so each “user” in the interaction matrix is just an order by an unknown user, and each of the new orders will also be treated as new «users» (user data can’t be saved). I have had a look at the matrix factorisation libraries LightFM and Implicit, but both of them seem to just be able to give recommendation to users that were in the training data, and that you have to train the model again for each new user you want to give recommendations to. I tried to get around this be doing item based CF with the item embeddings from LightFM, but this method just recommends similar items to the items that are in the cart, not complementary items (i.e. if a user has added bread and peanutbutter to their cart I dont want other types of bread or peanutbutter to be recommended, but rather items like jam or milk). The best model I have implemented so far is just using a co-occurence matrix for each item to find the items that co-occures the most times with all the items in the users cart. Another method I have considered is to use a neural network for «learning matrix factorisation» by training it on the recommendations from LightFM. I have also heard that it is possible to use variational autoencoders for this problem, is that something I should consider? It is important to note that models with slow inference is not well suited for this problem, because recommendations must be given quickly. I also have some more data that I haven’t used yet because I wanted to try the standard collaborative filtering methods first. This data is timestamps for each order and category data for each item (like which section in the store the item belongs to). I see that LightFM can utilize data like this, are there other methods or libraries that can do well with this kind of data? Another problem I have thought about is how I should evaluate different models. I have considered just using precision and recall at k, but since the data is really sparse most of the results will just be 0 if not k is set to be really big. Is it better to treat this like a ranking problem and do leave-one-out evaluation (or more than one for the larger orders) with some ranking metric instead? I have some experience with ML and NLP, but I have never worked with recommendation systems before, so any guidance is appreciated.
