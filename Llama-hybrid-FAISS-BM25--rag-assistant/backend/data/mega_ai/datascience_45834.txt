[site]: datascience
[post_id]: 45834
[parent_id]: 
[tags]: 
LSTM - Forecasting usage (real world)

I see that LSTM is very powerful reconstructing time series it was fed with, but my issue is: => Can LSTM predict future values without requiring real (training/testing) data? My objective is simple: Modelling a univariate time series to predict itself. ARIMA, SARIMA and Holt Winters were used, but Machine Learning (using LSTM) approach for forecasting seems fake in practice. Am I wrong about my point? My dataset is a 2 years duration series observed daily. I've evaluated initially 1.5 year as training set, defined by trainingX (a rolling window of 180 days duration) and trainingY (a rolling window of 30 days duration). I have tried: - A single LSTM layer with 30 units, returning sequences - A single LSTM layer varing of 1 unit to 1024 units and a dense layer with 30 units - Stacked LSTM with 2 to 4 layers with 1 to 1024 layers and a dense layer with 30 units - All of them were modified by sigmoid, relu and tanh activation functions Besides, Using a rolling window prediction, a method that releases the first "L" values of the trainingX set and append the first "L" prediction values at the end of the same trainingX set, I get random predictions converging to a constant or to zero. The training and predict batch were varied of 1 to 250. Have anyone experienced a reconstructed (lagged) output time series when wanting a forecasting output?
