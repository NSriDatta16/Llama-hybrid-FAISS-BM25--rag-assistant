[site]: crossvalidated
[post_id]: 41704
[parent_id]: 
[tags]: 
How and why do normalization and feature scaling work?

I see that lots of machine learning algorithms work better with mean cancellation and covariance equalization. For example, Neural Networks tend to converge faster, and K-Means generally gives better clustering with pre-processed features. I do not see the intuition behind these pre-processing steps lead to improved performance. Can someone explain this me?
