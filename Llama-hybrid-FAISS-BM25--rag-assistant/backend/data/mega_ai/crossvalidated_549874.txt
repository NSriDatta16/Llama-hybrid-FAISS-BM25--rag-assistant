[site]: crossvalidated
[post_id]: 549874
[parent_id]: 549866
[tags]: 
First off, don't use accuracy, which is a seriously misleading evaluation measure . Instead, use probabilistic classifications, and evaluate these using proper scoring rules . You can easily combine probabilistic classifications. If your three models yield predicted probabilities $\hat{p}_1, \hat{p}_2$ and $\hat{p}_3$ for a new instance to belong to the target class, simply take the average of the $\hat{p}_i$ as the combined probabilistic prediction. If your models differ on some proper scoring rule, then you can use a weighting based on these scores. Or you could even run a logistic regression of your target on the in-sample probabilistic classifications of your three models. Note, however, that any attempt to estimate weights for combinations will introduce additional variance, and the end result may well be worse than if you had used a simple unweighted average (e.g., Claeskens et al., 2016 ).
