[site]: crossvalidated
[post_id]: 50458
[parent_id]: 50447
[tags]: 
To add a little extra information to @gung's excellent coverage of the linear case, in the higher order polynomial case there are several ways you could do it either exactly or approximately (but pretty much as accurately as you need). First, note that the degrees of freedom for the polynomial (or indeed of any fitted function) must be at least as large as the number of "known" points. If the degrees of freedom are equal, you don't need the data at all, since the curve is completely determined. If there are more 'known' points you can't solve it (unless they all lie on exactly the same polynomial of the specified degree in which case any suitably-sized subset will suffice). From here on, I'll just talk about when the polynomial has more d.f. than the known points (such as a cubic - with 4df - and three known points, so that the cubic is neither overdetermined by known points nor completely determined by them). 1) "the curve must pass through this point" is a linear constraint on the parameters, resulting in constrained estimation or constrained least squares (though both terms can include other things than linear constraints, such as positivity constraints). You can incorporate linear constraints by either (a) recasting the parameterization to implicitly include each constraint resulting in a lower order model. (b) using standard tools that can incorporate linear constraints on the parameters of a least squares fit. (usually via something like the formula given at the above link) 2) Another way is via weighted regression. If you give the known points sufficiently large weight, you can get essentially the same fit as in (1). This is often readily implemented, can be substantially quicker than reparameterizing, and can be done in packages that don't offer constrained fitting. All of @gung's caveats apply
