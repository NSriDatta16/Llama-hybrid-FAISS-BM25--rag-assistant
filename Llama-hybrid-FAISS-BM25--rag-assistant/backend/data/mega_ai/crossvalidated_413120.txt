[site]: crossvalidated
[post_id]: 413120
[parent_id]: 413117
[tags]: 
I guess the only thing I am aware of that does this are (dense) embeddings in real vector spaces." Exactly, they get the best of both worlds: A fixed vector length and an ability to represent as many concepts as desired. While indexing with discrete values for each word will loose the advantage of fixed vector lengths, which is useful for many things. In particular many ML models require fixed vector sizes. While just indexing with real numbers doesn't have this problem at all. Yes, the indexing scheme you propose has another problem: words can be close in meaning to two others words, even though those 2 words are not close. For example: The word "mother" is close to both "queen" and "father", but "queen" and "father" are not (as) close to each other. If you use an indexing scheme, then the only way you can have the word "mother" be close to both "queen" and "father" at the same time is if "queen" and "father" are also close to each other. A dense vector embedding would allow "mother" to be close to "father" along one dimension and close to "queen" along a different dimension, while still keeping "queen" and "father" far apart from each other.
