[site]: crossvalidated
[post_id]: 348307
[parent_id]: 
[tags]: 
SVM: Maximal number of components kernel PCA versus linear PCA

I'm comparing the Support Vector Machines (SVM) formulation of linear PCA with kernel PCA. I know that in linear PCA, the maximum number of principal components is equal to the dimension of the input space. For kernel PCA, therefore, I expect the maximum number of principal components to be equal to the dimension of the projection of the input space into higher dimensional space (which is often implicit by just using the Kernel function). I don't find any confirmation on this somewhere online. Moreover, in my notes of a lecture I've followed, I've noted somewhere that the maximal number of principal components of kernel PCA is the number of observations in the dataset. Does anyone have a formal understanding of how this works or can advice a resource online? Does the number of principal components depend on the dual/primal formulation? Thanks a lot for some advice on this!
