[site]: crossvalidated
[post_id]: 200445
[parent_id]: 
[tags]: 
Machine learning: intuition behind perceptron learning algorithm

Given features $x_1...x_n$, weights $w_1...w_n$, calculated output $y = W^T \cdot X$, and actual output $\hat{y}$, the perceptron learning algorithm changes the weights after each iteration as follows: $$\Delta z_i = \text{learningRate} \cdot (\hat{y} - y) \cdot x_i$$ I understand why we multiply by $(\hat{y} - y)$: we want to change the weight to push the calculated output closer to the actual output. Similarly, the sign of $x_i$ has to be taken into account: if $x_i$ is negative, the weight should be shifted in the opposite direction than if it is positive. Question: What I don't understand is why multiply by the value $x_i$, rather than just its sign? We multiply by the value of $(\hat{y} - y)$ to produce a larger change when the deviation is large, but why produce a larger change when $x_i$ is big in magnitude? We are already multiplying $z_i$ and $x_i$, so $x_i$ being large is taken into account. It seems that when multiplying $\Delta z_i$ by $x_i$ will cause $x_i$ to be squared in the calculation of $\hat{y}$, causing features with large magnitudes to be overrepresented.
