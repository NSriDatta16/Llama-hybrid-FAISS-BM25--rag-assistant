[site]: crossvalidated
[post_id]: 315708
[parent_id]: 
[tags]: 
Neural Network: Why can't I overfit?

I have a (feed-forward single layer) neural network with which I try to predict an environment-related variable from two financial variables (regression). I use the "train" function from the caret package. I use the nnet() algorithm in the caret package. I have two continuous predictors, and 420 data points. For theoretical understanding, I try to purposely overfit my model; to my understanding, this should normally work with every dataset, e.g. bei increasing the "size" (i.e. the number of hidden units). However, increasing the size of hidden units drastically does not lead to overfitting. Thus, is it wrong to assume that you can overfit every neural network by increasing "size"? Which other variable could lead to an overfitting instead? grid
