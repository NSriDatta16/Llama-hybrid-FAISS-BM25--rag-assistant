[site]: crossvalidated
[post_id]: 343843
[parent_id]: 
[tags]: 
Proper way to assess median failure distance in the presence of censoring

I would like to measure the median distance at which a material fails when it is stretched. At first pass, this sounds trivial and there is a simple version of this by which I pull a material until it fails and then record the failure distance. I can then simply take the median or do a 1-dimensional fit to the data assuming a distribution and calculate the median from the fit parameters of the distribution. There is a second version of the study by which I can stretch the material to a range and then relax the material and then stretch to a longer distance repeatedly until it finally fails. The analysis of this is not different than what was described earlier. However, there could be some situations where the failure happens at a longer distance than earlier stretches but shorter than the current target stretch. In this case, I feel like taking the failure distance is not completely faithful as the previous stretch was longer than the current distance and it had not failed at that point. I feel as though for this specific case, I should consider treating the longest stretch as a censored data value and ignore the actual failure distance. Ultimately, I feel as though I could record the stretch distance as a function of time and each time point where there is no failure, should inform the final result in something like a logistic regression approach. Although I feel as though all of this information would be great to include there are a number of issues with this. The first is the sampling frequency of the distance measurement seems to be completely arbitrary and ultimately I would have many orders of magnitude of data in an unfailed state with only a few (on the order of 10s) of data in the failed state. Before I dig into this I wanted to ask the community which of these approaches is the preferred method. I feel that something near the second method is the optimal as it does not suffer from the sampling rate issue and the strongly unbalanced data but seems to address the issue of "missed" failures through the censoring approach. What is the best way for me to approach this measurement? Thanks for any input on this.
