[site]: crossvalidated
[post_id]: 78171
[parent_id]: 24371
[tags]: 
The original post is unclear on what is the measure that you want to compare after the n days of the experiment. The first alternative is that you want to decide which technique (A or B) will give you the best performance (on average) for the next day. That is, on average which of A and B will give you better returns FOR THE NEXT DAY. A second alternative is which of A and B will give you (on average) the better return AFTER N DAYS. The two measures differ on the number of days you have to run the experiment to be sure of your answer. a) Let us take the first metric - return for the next day. You ran the experiment for N days, and at the beginning of the each day both A and B make their decision and you measure their performance at the end of the day. For each day both methods have the same information and the same budget, so you can pair each day of the experiment. So you would use a paired t-test (if N is large enough and the distribution of returns mildly normal- usually > 30) or a wilcoxon signed-rank test (if N is not that large or if the distributions are very non-normal). If the resulting p-value is low enough, you will know which has better daily average return. The only possible issue is that statistical tests assume that the samples are independently drawn from the population, but returns on following days are very likely not independent. So there is room for trouble here. But I believe that although stock prices or other time series data are very likely correlated form one time to the next one, from the experiment point of view, each return data is independent since at each day both A and B where allowed to make their choices. And you are measuring how good are the choices each method makes. b) If you want the average return after N days, if you run the experiment for N days you only get a single data point for each method, and thus you do not have much evidence that one is better than the other. You would have to repeat this experiment M times (and calculate the N days average return for each method). Again repeat the tests above for the set of M pairs of data, and you are done. But there is a problem here - I believe you cannot overlap too much the intervals of N days of each experiment. On the limit, one could do the following. day 1 - A and B select stocks day 2 - same day 3 - same .... day N - same, but also measure the return for the N days starting at day 1 day N+1 - same, also measure the return for the N days starting at day 2 day N+2 - same, also measure the return for the N days starting at day 3 thus after N+M days you would have your M data pairs. But here the assumption of independence is clearly violated. The return for the first N days starting at day 1 is VERY correlated with the return of the N days starting at day 2, and so on. So the data is not interdependent, and thus the test is meaningless. So in this case the safe thing to do is to use totally non-overlapping intervals of N days to make the measures.
