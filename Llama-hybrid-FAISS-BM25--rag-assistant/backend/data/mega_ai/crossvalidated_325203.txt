[site]: crossvalidated
[post_id]: 325203
[parent_id]: 325008
[tags]: 
First a few technical things: You can use an offset in xgboost for Poisson regression, by setting the base_margin value in the xgb.DMatrix object. You will not get the same results with your above code as if you use the base_margin term. (You get the same results in a GLM, but this is not a GLM. I think the weight term in xgboost means something different.) For your question: Sum of predictions will not equal sum of observations after a small number of rounds for several reasons: Xgboost is regularizing predictions in the nodes (shrinking them toward 0). This will happen by default Xgboost is scaling predictions from each tree (by a positive number less than 1). This will happen by default Xgboost is randomly sampling rows every round, not fitting on the whole data set. I think this will not happen by default. Some other behaviors. Basically: It is not true that fitting one round in xgboost is the same as fitting a basic decision tree in the usual way.
