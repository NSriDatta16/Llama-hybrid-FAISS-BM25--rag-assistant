[site]: crossvalidated
[post_id]: 29820
[parent_id]: 29781
[tags]: 
In case you use gradient descent to fit your model, standardizing covariates may speed up convergence (because when you have unscaled covariates, the corresponding parameters may inappropriately dominate the gradient). To illustrate this, some R code: > objective optim(c(10,10), objective, method="BFGS")$counts #returns the number of times the function and its gradient had to be evaluated until convergence function gradient 12 3 > objective2 optim(c(10,10), objective2, method="BFGS")$counts function gradient 19 10 > optim(c(10,1), objective2, method="BFGS")$counts #scaling of initial parameters doesn't get you back to original performance function gradient 12 8 Also, for some applications of SVMs, scaling may improve predictive performance: Feature scaling in support vector data description .
