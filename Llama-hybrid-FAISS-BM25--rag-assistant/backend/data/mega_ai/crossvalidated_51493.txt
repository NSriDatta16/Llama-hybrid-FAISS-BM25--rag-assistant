[site]: crossvalidated
[post_id]: 51493
[parent_id]: 
[tags]: 
Normalizing constant irrelevant in Bayes theorem?

I've been reviewing Bayesian literature in an attempt to utilize Bayesian inference for hypothesis testing when I have very well established priors, but there's one thing I cannot get my head around: Why is the normalizing constant unimportant in determining the posterior when using MCMC methods? I understand that the evidence does not depend upon the parameters due to integration, but how is your posterior a valid probability distribution if it does not integrate to one (which as I understand it is the function of the normalizing constant)? If it isn't a valid probability distribution (since it is merely proportional to likelihood X prior), then how is it useful? I really need someone to explain this to me as if I were a 7 year old, or possibly a chimp of some sort because I'm having a terrible time understanding it.
