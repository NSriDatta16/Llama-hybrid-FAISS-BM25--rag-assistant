[site]: crossvalidated
[post_id]: 351216
[parent_id]: 
[tags]: 
Aren't my iterations needed to train NN for XOR with MSE < 0.001 too high?

I use a neural network which consists of: input layer (2 neurons) hidden layer (2 neurons, 2 biases) output layer (1 neuron, 1 bias) The weights and biases are random initialized from range [-1, 1] . I use learning rate of 1 (if it's either 0.01 , 0.1 , 0.2 , 0.5 , 0.7 or 2 the NN converges in more iterations), sigmoid as activation function and stochastic gradient descent as a learning algorithm. If the MSE is less than 0.001, the output for XOR is like: [0, 0] -> 0.031 [0, 1] -> 0.971 [1, 0] -> 0.971 [1, 1] -> 0.030 And if the MSE is less than 0.0001, the output is: [0, 0] -> 0.009 [0, 1] -> 0.991 [1, 0] -> 0.991 [1, 1] -> 0.008 So when I train the NN to get the MSE When I train it to get the MSE Thus, my questions are: Is the MSE Aren't the iterations too high? I mean, what's the average number of iterations it should take? Is it normal that it's sometimes even unable to get these small errors or it takes for e.g. MSE Thanks in advance.
