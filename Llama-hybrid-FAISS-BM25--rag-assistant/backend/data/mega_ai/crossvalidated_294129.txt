[site]: crossvalidated
[post_id]: 294129
[parent_id]: 294126
[tags]: 
There are indeed various options. I think normalizing with respect to the whole dataset is the best, but in practice using the mean and variance of a given mini-batch works well with less computation. If you are training GANs, you should use virtual batch normalization which prevents intra-batch correlation. During test time it is preferable to normalize with respect to the whole test set.
