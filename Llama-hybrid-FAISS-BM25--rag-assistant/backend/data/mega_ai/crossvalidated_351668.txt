[site]: crossvalidated
[post_id]: 351668
[parent_id]: 
[tags]: 
Deriving Autocorrelation Structure for Binary Markov Chain

I'm trying to derive the autocorrelation structure of a Binary Markov Chain with \begin{align} Pr(s_t=1 | s_{t-1}=1) &= q \\ Pr(s_t=0 | s_{t-1}=1) &= 1-q \\ Pr(s_t=0 | s_{t-1}=0) &= p \\ Pr(s_t=1 | s_{t-1}=0) &= (1 - p) \end{align} By a binary markov chain I mean a process that, conditional on the last observation, is independent of the past observations: $E(s_t | s_{t-1}, s_{t-2}, ..., s_0) = E(s_t | s_{t-1})$. I can easily find the undonditional mean and the variance. Let $Pr(s_t = 1) = z$. Then: \begin{align} z &= Pr(s_t=1 | s_{t-1} = 0) Pr(s_{t-1} = 0) + Pr(s_t=1 | s_{t-1} = 1) Pr(s_{t-1} = 1) \\ z &= (1-p)(1-z) + qz \\ z &= \frac{1-p}{2-q-p} \end{align} Then the variance is just $\gamma_0 = z (1-z)$. Now I need to find the other autocorrelations $\frac{\gamma_j}{\gamma_0}$ For the first one $\frac{\gamma_1}{\gamma_0} = \frac{Cov(s_t, s_{t-j})}{\gamma_0} = \frac{E(s_t s_{t-1}) - E(s_t)E(s_{t-1})}{z(1-z)}$ After a bit of manipulations using law of iterated expectations I get $\frac{\gamma_1}{\gamma_0} = \frac{q - z}{1-z} = \frac{(2-q-p)q - 1 + p}{1 - q}$. This formula seems not intuitive to me and, more importantly, I tried to calculate for higher order $j>1$ and I can not find any standard. I thought I would be able to find a general formula $\frac{\gamma_j}{\gamma_0} = f(q, p, j)$. After some google searching I could not find any expressions. Is there any nice trick to find the autocorrelation function for a binary markov chain? Thanks.
