[site]: crossvalidated
[post_id]: 344158
[parent_id]: 
[tags]: 
How much higher accuracy of train than test is enough to consider the model overfitted?

Considering a dataset of 920 samples with 40 features in a binary classification problem. The dataset is the heart disease dataset publicly available here. I preprocessed the dataset discarding those features which contains >50% missing data. Those which contains The models considered are: Linear SVM, RBF SVM, Logistic Regression, KNN , Decision Tree , Random Forest I tuned the parameters using RandomSearchCV: > Model: SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear', max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False) > Model: SVC(C=10000.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf', max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False) > Model: LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False) > Model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=65, p=2, weights='uniform') > Model: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=10, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='random') > Model: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', max_depth=30, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=4, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False) I got the following scores (mean +/- std) in a 10-CV: It surprises me that the training accuracy and F-score is higher (specially in random forest) than the test one. Besides I computed bagging algorithms by the same methodology (tuning the number of estimators with RandomSearchCV and having the base_estimator the previous models considered): Model: BaggingClassifier(base_estimator=SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear', max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False), bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0, n_estimators=200, n_jobs=1, oob_score=False, random_state=36, verbose=0, warm_start=False) Model: BaggingClassifier(base_estimator=SVC(C=10000.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf', max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False), bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0, n_estimators=100, n_jobs=1, oob_score=False, random_state=37, verbose=0, warm_start=False) Model: BaggingClassifier(base_estimator=LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0, n_estimators=100, n_jobs=1, oob_score=False, random_state=38, verbose=0, warm_start=False) Model: BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=65, p=2, weights='uniform'), bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0, n_estimators=100, n_jobs=1, oob_score=False, random_state=38, verbose=0, warm_start=False) Model: BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=10, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='random'), bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0, n_estimators=500, n_jobs=1, oob_score=False, random_state=34, verbose=0, warm_start=False) Model: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', max_depth=30, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=4, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False) I got the following scores (mean +/- std) in a 10-CV: It also surprises me that there is no so much improvement from single algorithms to bagged algorithms. On the other hand I also tried AdaBoost with Decision Tree and Logistic Regression (same tuning of n_estimators and learning rate with Random SearchCV: Model: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False), learning_rate=10, n_estimators=600, random_state=38) Model: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=10, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='random'), learning_rate=0.01, n_estimators=200, random_state=34) I also got the following scores: Reading about ensembles methods one may believe that its accuracy improves from single models, however for logistic regression even worsen (just a bit) but still, for Decision Trees it does not really improved that much What could have happened? Am I overfitting?
