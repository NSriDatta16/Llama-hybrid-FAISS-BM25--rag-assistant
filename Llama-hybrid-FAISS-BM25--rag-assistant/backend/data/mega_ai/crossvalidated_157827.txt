[site]: crossvalidated
[post_id]: 157827
[parent_id]: 
[tags]: 
Understanding the different formulations for SVM

I've been working with kernlab for more than a year now, but I always stickied to the vanilla cost ( C-svc ) formulation for classification. Of course, kernlab includes some other formulations. In the manual , some classification formulations are briefly cited. I'm quite familiar with vanilla Cost svms. For example, I know very well the C-svc and have a vague idea what encompasses a native multi-class formulation and I do understand the principles of nu-svc . Could someone please shed some light on these different formulations and how they compare, if applicable, to C-svc ? Information of different considerations made, robustness, sparseness, sensitivity to high dimensionality or class imbalances would be greatly useful. C-svc : C (Cost) classification nu-svc : $\nu$ (nSV) classification C-bsvc : bound-constraint SVM classification spoc-svc Crammer-Singer native multi-class kbb-svc Weston-Watkins native multi-class
