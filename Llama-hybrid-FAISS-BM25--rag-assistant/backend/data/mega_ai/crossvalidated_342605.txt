[site]: crossvalidated
[post_id]: 342605
[parent_id]: 
[tags]: 
How to use Bayesian Evidence to Compare Models

I'm exploring how to use Bayesian Estimation to compare models, and need to compare with a way to implement it. So far I just found this article is easier to understand, but I'm still not sure how to implement. If you go to page 20 "Model comparison using the Bayesian evidence". We just need to calculate this for each model and compare: $$P(M_1|D)=\frac{P(D|M_1)P(M_1)}{\sum_iP(D|M_i)P(M_i)}$$ Also as the author mentioned, " $P(M)$ is the model prior probability. If we have no reason to favour one model over another, then we just set all of these to be equal". $P(D|M_i)$ is the evidence and "The important point is that the evidence is a normalized PDF over the data". These raised me 2 questions: $P(M_i)$ can be equal for all the models, it means I can set them all as 1 or the sum of them should be 1? If evidence $P(D|M_i)$ is normalized pdf, it should be a distribution, right? Then how can I convert a normalized pdf to a value? What confuses me most is, imagine I have features X, ground truth y, and predicted classes y_pred. How can I calculate $P(D|M_i)$ for each model? Is that possible to give me some suggestions with a simple example with features X, ground truth y, and predicted classes y_pred ? If you can do that in python or R, it's even better.
