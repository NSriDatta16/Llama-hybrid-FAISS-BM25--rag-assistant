[site]: stackoverflow
[post_id]: 1609844
[parent_id]: 1596020
[tags]: 
This is what I ultimately did - it was enough for our use for now, and with some simple benchmarking, I feel OK about it. We'll be watching to see how it does in production before we expose the results to our customers. The components: class EventsController true end end This is called from an ajax call in the site layout... var list = ''; $$('div.item').each(function(item) { list += item.id + ','; }); { :controller => :events, :action => :create}, :with => "'ids=' + list" ) %> Then I made a rake task to import these rows of comma delimited ids into the db. This is run the following day: desc "Calculate impressions" task :count_impressions => :environment do date = ENV['DATE'] || (Date.today - 1).to_s # defaults to yesterday (yyyy-mm-dd) file = File.new("log/impressions/#{date}.log", "r") item_impressions = {} while (line = file.gets) ids_string = line.split(' ')[1] next unless ids_string ids = ids_string.split(',') ids.each {|i| item_impressions[i] ||= 0; item_impressions[i] += 1 } end item_impressions.keys.each do |id| ActiveRecord::Base.connection.execute "insert into item_stats(item_id, impression_count, collected_on) values('#{id}',#{item_impressions[id]},'#{date}')", 'Insert Item Stats' end file.close end One thing to note - the logger variable is declared in the controller action - not in environment.rb as you would normally do with a logger. I benchmarked this - 10000 writes took about 20 seconds. Averaging about 2 milliseconds a write. With the file name in the envirnment.rb, it took about 14 seconds. We made this trade-off so we could dynamically determine the file name - an easy way to switch files at midnight. Our main concern at this point - we have no idea how many different items will be counted per day - ie. we don't know how long the tail is. This will determine how many rows are added to the db each day. We expect we'll need to limit how far back we keep daily reports and will role up results even further at that point.
