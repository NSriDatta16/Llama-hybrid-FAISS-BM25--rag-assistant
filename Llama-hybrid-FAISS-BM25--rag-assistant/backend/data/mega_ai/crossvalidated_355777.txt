[site]: crossvalidated
[post_id]: 355777
[parent_id]: 355722
[tags]: 
There are a couple of approaches to your situation. You are trying to regress a binary response on a two way interaction. If you have no continuous variables you would like to throw in, then one option is to perform a linear regression. If you understand the linear regression model, then this solution will be easier for you. It will also give the same predictions as the logistic regression model as long as the regressor remains the two-way interaction. You would reshape your data thus: Pair Cnt1 Gene Tissue Weights A1:B1 1 A T1 23 A1:B1 0 A T1 201 A1:B1 1 B T1 43 A1:B1 0 B T1 565 Hence each current row becomes two rows and a weights variable represents the number of individuals satisfying that condition, so frequency weights. Then you can perform your linear regression model (this alternative shape for the data also works for logistic regression). Your coefficients will be on the probability scale and signify differences in probabilities. Your syntax could be: lm(Cnt1 ~ Gene * Tissue, data = x, weights = Weights) Personally, I prefer: lm(Cnt1 ~ 0 + Gene + Gene : Tissue, data = x, weights = Weights) # this tells me the proportion for each gene at T1, the baseline then # how T2 and T3 differ from this baseline for each gene If your model will expand to include continuous predictors, or you may drop the interaction between both factors, then a logistic model remains a good bet. With continuous predictors or no interaction between both factors, a linear model may predict garbage probabilities (outside of 0 and 1) and then the model may be both biased (incorrect coefficients) and inconsistent (situation not helped by large sample size). If you stick with the logistic model. Since you are intent on modeling pr(Cnt1), then your syntax should be: # cbind(success, failure) glm(cbind(Cnt1, Cnt2) ~ Gene * Tissue, family = binomial, data = x) # default link for binomial is logit The linear model component here, made up of your coefficients, is not on the probability scale but on the logit or log odds scale. Your intercept should be the negative of what you currently have. And that will be a huge number since it's on the log odds scale. (Remember you are modeling 1/0 data not 23/635 data). I think this answer does a good job of explaining how to work with logistic regression coefficients. Finally, about the anova function, see ?anova.glm for details. This is actually analysis of deviance (deviance being bad) which is how we typically compare generalized linear models. What it does is it looks as the reduction in deviance as each term in your formula gets added to the model, so like a test for each new term during forward entry. The reduction for the interaction, being the last term added to the model, works like an omnibus test for all the terms representing the interaction. If the reduction is not statistically significant, some investigators may choose to simplify the model by dropping the interaction.
