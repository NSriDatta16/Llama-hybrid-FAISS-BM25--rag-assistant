[site]: crossvalidated
[post_id]: 503185
[parent_id]: 502781
[tags]: 
This is because the inference (estimation of the hidden states) made by the viterbi function optimizes another criterion than the posterior function. With $\pmb{X}$ the vector of hidden random variables and $\pmb{Y}$ the vector of observed random variables, viterbi gives you the Maximum A Posteriori (MAP) estimate defined by: $$ \hat{\pmb{x}}^{MAP} = \mathrm{argmax}_{\pmb{x}}p(\pmb{X}=\pmb{x}|\pmb{Y}=\pmb{y}). $$ On the other hand, posterior gives you the estimate of each marginal probability. If you take locally the argument maximum of this posterior probabilities you will find differences with the MAP estimate. The corresponding sequence you have infered is sometimes called marginal MAP or Maximum Posterior Mode (MPM). It is then defined by, $\forall n\in\{1,\dots,N\}$ : $$ \hat{x}_n^{MPM}=\mathrm{argmax}_{x_n}p(X_n=x_n|\pmb{Y}=\pmb{y}). $$ If you want to learn more, you can search for elements on Bayesian decision theory .
