[site]: crossvalidated
[post_id]: 611166
[parent_id]: 549153
[tags]: 
The ROC curve measures how well the model can distinguish between the two categories: the higher the AUC score, the better the ability to distinguish (at least a bit loosely speaking). This comes from the fact that the ROCAUC is related to running a two-sample Wilcoxon Mann-Whitney U test on the continuous predictions made by your model , such as predicted probabilities or log-odds of a logistic regression. You can get the test statistic for the hypothesis test from knowing the AUC and the number of members of each category. Then you can get a viable p-value. There are other ways to test if your categories have different distributions of the features, but this seems totally legitimate to me. If the model struggles to distinguish between the categories, then you get a low AUC close to $0.5$ and a high p-value, as you should. If the features provide valuable information for distinguishing between the categories, model performance will be strong, leading to a high AUC and a small p-value. For this particular use case, you might need more than just a small improvement over baseline (AUC $=0.5$ ) performance to warrant clinical use. The specific predicted probabilities might be of use there, and you can run tests directly on those (such as a test of a full logistic regression against the intercept-only model nested within it).
