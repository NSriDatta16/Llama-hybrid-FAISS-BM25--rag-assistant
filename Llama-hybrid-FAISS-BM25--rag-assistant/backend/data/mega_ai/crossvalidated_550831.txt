[site]: crossvalidated
[post_id]: 550831
[parent_id]: 
[tags]: 
D&D Probability question: why am I wrong?

In Dungeons and Dragons, the primary die used for success or failure is the D20, or 20 sided die. A 1 is a critical failure, and a 20 is a critical success. When one has advantage, one rolls 2 dice and takes the higher of the 2 rolls. Recently, we had a game where a character rolled 6 critical successes over the course of 18 rolls, some with advantage and some without. The odds of a critical success by itself are 1 in 20 (p1), the odds with advantage are 39 in 400 (p2). What are the odds of 6 over the course of 18 rolls? I modelled it as 18 choose 6 / pn^6. This yielded 1 in 3500 for p1 and 1 in 62 for p2. I also wrote a simulation, and got significantly different results, but in the ballpark. I rolled a billion simulations and the results converged to about 1/6300 for p1 and 1/220 for p2. I repeated this several times with essentially no change. Where did I go wrong? I would really like to know why these 2 methods don't yield similar results.
