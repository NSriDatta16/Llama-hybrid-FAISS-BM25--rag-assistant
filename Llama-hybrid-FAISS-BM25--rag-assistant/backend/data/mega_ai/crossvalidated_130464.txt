[site]: crossvalidated
[post_id]: 130464
[parent_id]: 
[tags]: 
Computation of the entropy of marginals?

I have implemented this paper: Efficient graph-based semi-supervised learning of structured tagging models In the last sentence of the section 4.2, the authors have mentioned another possible way of combining the token marginals. The exact sentence is: Other ways of combining the token marginals, such as using weights derived from the entropies of marginals , might be worth investigating. I am not sure how to compute the entropies of marginals which is mentioned here. EDIT: A summary of related parts of the paper: In this paper, the authors attempt to use a kNN similarity graph as a constraint for training a conditional random fields model in a semi-supervised manner. In section 4.1 of the paper the authors mention how token marginals are computed using the parameters of a base model. Here in this paper the tokens are the occurrences of n-grams, types on the other hand, are the n-grams themselves. In section 4.2, the authors want to assign a probability to the types themselves rather than their occurrences (tokens). Therefore, they choose the simplest method, that is to average the probability of all of the tokens in the training data. In the last sentence of this section, the aforementioned sentence is said. They suggest an alternative way of combining the token probabilities in order to assign the type probabilities.
