[site]: crossvalidated
[post_id]: 186097
[parent_id]: 
[tags]: 
Is this the state of art regression methodology?

I've been following Kaggle competitions for a long time and I come to realize that many winning strategies involve using at least one of the "big threes": bagging, boosting and stacking. For regressions, rather than focusing on building one best possible regression model, building multiple regression models such as (Generalized) linear regression, random forest, KNN, NN, and SVM regression models and blending the results into one in a reasonable way seems to out-perform each individual method a lot of times. Of course, a solid understanding of each method is the key and an intuitive story can be told based on a linear regression model, but I'm wondering if this has become the state of art methodology in order to achieve the best possible results.
