[site]: crossvalidated
[post_id]: 388045
[parent_id]: 387993
[tags]: 
In general, one would hope that an autoencoder will create a very useful low dimensional representation of data (an embedding) that summarizes the data in a very usuable way without losing important details. If it does that really well, then it is often much more efficient to build models on small supervised tasks with the embeddings as your input (see e.g. Word2vec). However, an autoencoder may learn to encode a lot of information irrelevant to your task at hand and may discard subtle information that is crucial for your task (but where omitting it does not get penalized enough by the loss function used to construct the autoencoder - at least relative to how much unlabeled data you have). This is particularly of concern, if the unlabeled data is of limited size so that you can realistically only create a relatively small dimensional embedding space (insufficient unlabeled training data to create something more complex). This is less of a concern, if you have an enormous amount of unlabeled data and much, much less labeled data (e.g. for NLP every Twitter message ever vs. a few hundred or thousand tickets posted in a customer support portal). In that case, you can create a sufficiently complex embedding that captures so much subtle detail that it becomes a lot less likely that you loose anything important for your task of interest by using the embedding to represent your data. The other concern is, that the usefulness of an embedding it also depends on whether what is "interesting" in your labelled data is at all present in your unlabeled data. If the unlabeled data is from a similar data source, then this reduces the concern, while if the types of data are just completely different (e.g. using an autoencoder to create an embedding for temperature patterns in your living room and then running the brightness of the sun through the autoencoder to get embeddings to predict sunflares is probably a bad idea), the gap between what the autoencoder encodes into an embedding and what is really going on in your data may be too huge for this to be useful. In your case, I'd speculate that it is unclear and needs to be tried. It may depend on whether the two datasets are very similar and whether your task of interest relies a lot on "obvious" features needed for an autoencoder. Thus, you probably have to just try it both ways and compare the performance on a validation set not used for training.
