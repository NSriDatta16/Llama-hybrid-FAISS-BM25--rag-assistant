[site]: crossvalidated
[post_id]: 484636
[parent_id]: 
[tags]: 
How do the decision boundaries of logistic regression and support vector machines compare?

I'm not so much interested in implementation details, just how the decision boundaries of the trained models would compare. The answer depends on regularization, kernel used and so on, so lets say both have pretty good, practical implementations. Are the decision boundaries always very similar? Can the decision boundaries be very different? Does the dimension of the data affect the answer? Is there ever a reason to choose one over the other, besides efficiency?
