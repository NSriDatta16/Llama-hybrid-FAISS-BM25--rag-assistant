[site]: crossvalidated
[post_id]: 311380
[parent_id]: 311375
[tags]: 
In the first paper you mention, k-means is used to learn filter (convolutional) layers in the network. The difference between what they are doing and vanilla k-means clustering, is that in this case: the points are randomly extracted image patches and the centroids are the filters that will be used to encode images. but this learns redundant filters, so they combine this with a kind of sparse dictionary encoding to eliminate the redundant filters. Note that the actual task that the algorithm performs classification, not clustering, so in my opinion it's really more of a semi-supervised method rather a unsupervised method. I think the second link is much closer in spirit to what you are after. I'm sure it's possible to do clustering using CNNs but do consider that they are not the right model for every problem. If you are a subject matter expert in this area where these measurement are taken, can I suggest labelling in the data? It's possible to achieve good results fine-tuning a CNN with only 100-150 elements per class, if you can find a good base model. I know there has been a bunch of work on 1-D CNNs for ECG data (as mentioned in your links) so perhaps start transfer learning from one of those models. If you have less data, I think CNNs are probably not the right tool, maybe consider Gaussian processes.
