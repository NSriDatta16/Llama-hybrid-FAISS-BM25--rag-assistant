[site]: datascience
[post_id]: 49251
[parent_id]: 
[tags]: 
New images always predict one label

I have trained a SVM for image classification using RGB histogram as features and a couple of other ones. These are my feature and label sizes: STATUS] feature vector size (11244, 525) [STATUS] training Labels (11244,) [STATUS] training labels encoded... [STATUS] feature vector normalized... [STATUS] target labels: [0 0 0 ... 1 1 1] [STATUS] target labels shape: (11244,) I am using sklearn's train_test_split with ratio of 0.15 for test. Following is the classification report(100% recall and precision on test). This is weird!! Tuning hyper-parameters for precision Best parameters set found on development set: {'C': 1, 'kernel': 'linear'} Grid scores on development set: 0.991 (+/-0.005) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'} 0.852 (+/-0.003) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'} 0.993 (+/-0.003) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'} 0.991 (+/-0.005) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'} 0.999 (+/-0.002) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'} 0.993 (+/-0.003) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'} 1.000 (+/-0.000) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'} 0.999 (+/-0.002) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'} 1.000 (+/-0.000) for {'C': 1, 'kernel': 'linear'} 1.000 (+/-0.000) for {'C': 10, 'kernel': 'linear'} 1.000 (+/-0.000) for {'C': 100, 'kernel': 'linear'} 1.000 (+/-0.000) for {'C': 1000, 'kernel': 'linear'} Detailed classification report: The model is trained on the full development set. The scores are computed on the full evaluation set. precision recall f1-score support 0 1.00 1.00 1.00 574 1 1.00 1.00 1.00 1113 micro avg 1.00 1.00 1.00 1687 macro avg 1.00 1.00 1.00 1687 weighted avg 1.00 1.00 1.00 1687 # Tuning hyper-parameters for recall Best parameters set found on development set: {'C': 1, 'kernel': 'linear'} Grid scores on development set: 0.986 (+/-0.006) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'} 0.633 (+/-0.009) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'} 0.988 (+/-0.005) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'} 0.986 (+/-0.006) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'} 0.998 (+/-0.003) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'} 0.988 (+/-0.005) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'} 1.000 (+/-0.001) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'} 0.998 (+/-0.003) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'} 1.000 (+/-0.000) for {'C': 1, 'kernel': 'linear'} 1.000 (+/-0.001) for {'C': 10, 'kernel': 'linear'} 1.000 (+/-0.001) for {'C': 100, 'kernel': 'linear'} 1.000 (+/-0.001) for {'C': 1000, 'kernel': 'linear'} Detailed classification report: The model is trained on the full development set. The scores are computed on the full evaluation set. precision recall f1-score support 0 1.00 1.00 1.00 574 1 1.00 1.00 1.00 1113 micro avg 1.00 1.00 1.00 1687 macro avg 1.00 1.00 1.00 1687 weighted avg 1.00 1.00 1.00 1687 BUT, on new images(sampled from same distribution), I am not getting even a single classification right. What could be going wrong?
