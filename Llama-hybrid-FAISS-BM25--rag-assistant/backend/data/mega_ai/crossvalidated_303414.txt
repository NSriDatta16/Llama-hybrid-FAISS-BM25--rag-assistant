[site]: crossvalidated
[post_id]: 303414
[parent_id]: 303403
[tags]: 
Is it because for certain estimators, in order to prove they are unbiased, Depending on your definition of bias, no. If you are using the usual statistical definition, then this is not why we invoke this assumption. The assumption is used for identification of the effect, that is, it's used to say that it's possible to estimate what you want to estimate with observational data (considering infinite samples). It says nothing about statistical properties of specific estimators under finite samples. Of course, if what you want to estimate is not identified, then all estimators will be biased for this causal quantity, by definition. But you can still have identification of the causal quantity with finite sample biases. More specifically, unconfoundedness (also called conditional ignorability, selection on observables etc) is usually invoked when you want to identify the average treatment effect with an observational quantity such as a traditional difference in means. The average treatment effect is usually defined as: $$ \tau = E[Y_i(1) - Y_i(0) ] $$ To simplify the derivation, let's also define the conditional average treatment effect: $$ \tau(X) = E[Y_i(1) - Y_i(0) |X_i] $$ You never get to observe any of thoses quantities, because you only observe $Y_i(1)$ for those who were treated and $Y_i(0)$ for those who were not treated. However if $\{Y_i(1), Y_i(0)\} \perp T|X$, you can rewrite $\tau(X)$ as: $$ \begin{align} \tau(X) &= E[Y_i(1) - Y_i(0) |X_i]\\ &= E[Y_i(1)|X] - E[Y_i(0) |X_i]\\ &= E[Y_i(1)|T_i =1, X_i] - E[Y_i(0) |T_i = 0, X_i]\\ &= E[Y_i|T_i =1, X_i] - E[Y_i | T_i = 0, X_i]\\ &= \tau(X)_{diff} \end{align} $$ And this last quantity you do observe. So you can identify the average treatment effect $\tau$ with $\tau(X)_{diff}$ taking the expectation over $X$: $$ \tau = E[Y_i(1) - Y_i(0) ] = \int_X E[Y_i(1) - Y_i(0) |X]dP(X) =\int_X\tau(X)_{diff}dP(X) \\ $$ Notice that this assumption is sufficient for identifying the average treatment effect, but it's not necessary . Also, implicit in our derivation is the assumption of common support of $X$ between the treated and control units. Notice we did not talk about any specific estimator here. You could estimate those quantities in several ways. For identification, this estimator has to be consistent, but it could still have finite sample bias. Maybe the simplest example you could think of is a penalized estimator for $E[Y_i|T_i, X_i]$, which would probably be biased in finite samples but still consistent (under other assumptions, such as correct specification etc).
