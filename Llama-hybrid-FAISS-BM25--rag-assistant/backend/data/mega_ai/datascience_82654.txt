[site]: datascience
[post_id]: 82654
[parent_id]: 
[tags]: 
Is Keras LSTM the right choice?

My Keras LSTM NN improves to a val_loss of around 0.005 when training with 75% of my 4000-s long time series. I've ran the GridSearchCV to tune the hyperparameters but when I try to predict the remaining 25% of the series I get unsatisfactory results. The predictions lose quality in its very first points. The data is MinMax-scaled and I haven't bothered re-scaling yet since it wouldn't matter for now. Does it mean the LSTM is not adequate for my case? Is there anything else I could try? My time series comes from a dynamic FEM simulation with time step of 0.1 s, ie, two (or even more) consecutive points are very similar. To avoid redundant data I filtered the series to work with steps of 1 s. I've also tried to use tensorflow.keras.preprocessing.sequence.TimeseriesGenerator but it starts training the NN for a few moments and then complains about the dimensions of the input (I'm trying to solve the issue on StackOverflow, but any help would be greatly appreciated). Regardless, I really don't see why this function would be important since my series is already in a y=f(x) kind of structure.
