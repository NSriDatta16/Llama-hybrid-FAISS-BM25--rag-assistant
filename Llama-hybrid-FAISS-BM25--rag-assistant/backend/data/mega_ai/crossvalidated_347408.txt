[site]: crossvalidated
[post_id]: 347408
[parent_id]: 
[tags]: 
Using several logistic regression models to calculate probability

I have a feedforward ANN with a single output neuron that I use sigmoid activation on to predict true/false. I want to obtain a percentage likelihood of the true or false outcome, but when I do the appropriate reverse-engineering on the output neuron I can see that it distributes my probabilities much closer to the threshold (0.5) than I would expect and so the probability it gives me from this one output isn't very useful. My domain space / input parameters are such that rather than there being one very obvious global minima (ie "best answer") to my problem, I suspect if one were able to visualize the multi-dimensional graph of parameters vs error that there are lots of fairly similar local minima depending on the initial seed etc. So my question is this - is it a reasonable approach to train, say, 100 models that are not perfectly overlapping in their answers (ie have all found different local minima), and use the number of models that predicted true or false as the probability of the outcome? Or is that crazy talk and is there is a well-known solution to what I'm trying to do?
