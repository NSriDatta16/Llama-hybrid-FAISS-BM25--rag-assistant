[site]: stackoverflow
[post_id]: 2917136
[parent_id]: 1951066
[tags]: 
Gestures are typically finger movements on the Android’s touch-sensitive screen that are processed using the android.gesture package. The most common gesture is a simple “tap”, which is like a “mouse click” on a PC. This particular gesture is also detectable via the View.OnClickListener interface. The next most common gesture is a “drag” (like dragging with a mouse on a PC) which you do when you first turn on your Android and drag the lock slider to unlock your Android. But these are the simplest examples, as the gestures package will report full finger movement sequences and allow your application to detect, for example, if a gesture follows a curved arc, if the movement is clockwise or counterclockwise and if the movement was a slow “drag” or a quick “flick”. Your application will have to be able to convert the X/Y location and timestamps to figure out what the movements are. You might use such motions for moving, dragging and spinning virtual objects, either for selection, or for a game. At the next level of sophistication, the SDK includes a sample app, GestureBuilder (“Gestures Builder”), that you can install and run on your emulator or Android that will create a “library” of gestures. When your app gets a gesture, it can pass it to the GestureLibrary class, which will determine if the gesture matches one of the gestures in your library. You might have a “flick clockwise” gesture, for example. There is no character recognition, yet, but that’s an obvious evolution for the future of Android gestures. More detailed information is on Android developer website, in the article, “ Gestures ”.
