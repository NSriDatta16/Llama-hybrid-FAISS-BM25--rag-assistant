[site]: crossvalidated
[post_id]: 233887
[parent_id]: 
[tags]: 
How to train a machine learning classifier on arrays of different length?

I am tinkering over this problem quite for a bit and might just need a little push in the right direction. Consider sequences of tuples $A_m = \left( (x_i,a_i)\right)_{i\in\{1,\dots,m\}} $ and $B_n = \left( (x_j,b_j)\right)_{j\in\{1,\dots,n\}}$ They can be different lengths and assume that all the $A_k $ are labeled 1 and the $B_l$ are labeled 0. We also write $\mathscr{A} = (A_s)_{s\in \{1,\dots, \alpha \}}$ and $\mathscr{B}=(B_t)_{t\in \{1,\dots, \beta \}}$. Question: For any subset of unlabeled $\mathscr{A}$ and $\mathscr{B}$ create a sparse classifier that can label the $A_k$ and $B_l$ correctly. I have been thinking on using a plain logistic regression $$\log\left(1+\exp\left(-yw^T\hat{x}\right)\right)+\lambda R(w)$$ where $y$ is the label, $\hat{x}$ the argument, $w$ the weight and the Regulation term. Now for I was thinking in adjusting the $(a_i)$ and $(b_j)$ by trimming them to the minimum or extending the missing $a_i$ or $b_j$ with zeros and put them into the Loss function above. But this seems to me rather brute. I feel there is something I missed. I am working with apache sparks Mllib and it has a nice LogisticRegressionWithLBFGS class that can handle most of this. I was also considering looking into the cross validation methods but it the documentations was very unintuitive to me. When I understand this correctly this problem is similar to the problem of having words in different lengths where the alphabet is much bigger- lets just say $a_i,b_j\in \mathbb{R}$. and we know that some words are labeled as 1 or zero. In my case the words might be $10^5$ letters long. So the question that I am asking is: What did I miss? And how would a machine learning expert handle this problem - considering a implementation?
