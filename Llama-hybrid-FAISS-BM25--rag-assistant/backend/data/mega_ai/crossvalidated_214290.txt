[site]: crossvalidated
[post_id]: 214290
[parent_id]: 213464
[tags]: 
The only place where one can safely ignored iid is in undergraduate statistics and machine learning courses. You have written that: one can work around the i.i.d. assumption and obtain robust results. Actually the results will usually stay the same, it is rather the inferences that one can draw that will change... This is only true if the functional form of the models is assumed to be basically correct. But, such an assumption is even less plausible than iid. There are at least two ways in which iid is critically important in terms of applied modeling: It is an explicit assumption in most statistical inference, as you note in your question. In most real-world modeling, at some stage we need to use inference to test the specification, such as during variable selection and model comparison. So, while each particular model fit may be OK despite iid violations, you can end up choosing the wrong model anyway. I find that thinking through violations of iid is a useful way to think about the data generating mechanism, which in turn helps me think about the appropriate specification of a model a priori. Two examples: If the data is clustered, this is a violation of iid. A remedy to this may be a mixture model. The inference I will draw from a mixture models is generally completely different to that which I draw from OLS. Non-linear relationships between the dependent and independent variables often show up when inspecting residuals as a part of investigating iid. Of course, in pretty much ever model that I have ever built, I have failed in my quest to reduce the distribution of the residuals to anything close to a truly normal distribution. But, nevertheless, I always gain a lot by trying really, really, hard to do it.
