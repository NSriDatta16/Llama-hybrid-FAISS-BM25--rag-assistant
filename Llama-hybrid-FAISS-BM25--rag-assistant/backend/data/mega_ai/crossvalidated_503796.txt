[site]: crossvalidated
[post_id]: 503796
[parent_id]: 503789
[tags]: 
Tough to say without more details of the problem, but here are some thoughts: Yes, I agree the first approach is overfitting. Yes, I agree that you have plenty of observations for just about any application. I would let model 2 run for more epochs just to confirm it is also overfitting. Maybe there was a weird local min, the val loss is still improving at the end, it's possible it needed more time. I would try different batch sizes, different dropout rates (although 0.5 is pretty high), and a longer, skinnier architecture, like 5-10 layers of 32 nodes or something. If this runs slowly, you could definitely downsample. Also try smaller batches. Again, this will slow it down, so you could downsample. Lastly, I'd want to clarify why you are using CNNs at all. Usually 2D CNNs are used on images, is that what you have? Your data shape almost looks like 3x3 pixel images with 7 channels, which I'm guessing is not quite right. With only 3x3 channels, a fully connecting thing might make more sense. I think you are effectively doing that since you are flattening a convolution that is covering your entire 'image'. Hope that helps some, and good luck!
