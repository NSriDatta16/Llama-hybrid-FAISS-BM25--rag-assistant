[site]: datascience
[post_id]: 32421
[parent_id]: 
[tags]: 
How to preserve levels with Z-score?

I normalize time series data using a sliding window to be fed into a Neural Net. I normalize each window independently using Z-score. (Because on the entire dataset proven to be useless. Because on later on batch level is random due to shuffling.) Z-score normalize data as a pattern, as a deviation from the mean measured in the portion of the standard deviation. I apply the function on every time window (and not on batch). It would return the same for: Window: [1, 5, 2] Mean: 2.66 STDev: 2.081 Result[-0.800, 1.120, -0.320] Window: [10, 50, 20] Mean 26.66 STDev: 20.81 Result[-0.800, 1.120, -0320] This is not desired. The magnitude of the input carries information that is useful and I need to preserve it while applying normalization benefits. My best idea is: Z-Score(i) / (1 / Mean(Window(n))) Where (i) is the item in Window(n) and (n) represents the Nth sliding window This results an output that keeps the magnitude: [-2.135, 2.890, -0.854] [-21.35, 29.89, -8.540] This output keeps the Z-score benefits while preserves the magnitude. Can you help me out if this a fair approach?
