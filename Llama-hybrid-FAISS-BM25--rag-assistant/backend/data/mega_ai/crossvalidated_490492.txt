[site]: crossvalidated
[post_id]: 490492
[parent_id]: 490490
[tags]: 
The updated data is presumably more correct, so it appears like a model fitted to the updated data is likely closer to the true data generating process, as well. So I would use the new model. Then again, large changes in the forecast (note that different models may give forecasts that are not very different, at least at short horizons) would be a cause for concern. So I would at least take a look at the differences in the forecasts from the two models. If two (or more) models are so equally reasonable that small changes in the data may make auto.arima() jump from one model to the other, it may also be worthwhile to use both models, by averaging the forecasts. As long as the order of integration is the same, you can also compare AICs and potentially use the AICs in a weighting scheme (e.g., Kolassa, 2011, IJF - sorry for the self-promotion). Note, however, that investing a lot of time in finding "optimal" weights may not help a lot ( Claeskens et al., 2016, IJF ). Finally, if you have the time, you could also disable some of the computational shortcuts that auto.arima() takes, which may give you yet other models to play with, by setting stepwise=FALSE and/or approximation=FALSE .
