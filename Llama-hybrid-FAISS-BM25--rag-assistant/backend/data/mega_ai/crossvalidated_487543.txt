[site]: crossvalidated
[post_id]: 487543
[parent_id]: 487539
[tags]: 
Mostly you split your dataset into train and test data. Train data is used for training and optimization, test data for a final check as a last step to verify your models quality. The latter you don't touch at all until the last step! When optimizing hyperparameters such as the number of neurons per layer you could split train data again into train and validation data (hold-out) by random. This could have two extreme results: The model performs very well. The model performs very badly. How do you know if it's case 1 or 2? Or something in between? You simple don't know. So how would you judge the performance (e.g. accuracy of 95%)? You can't judge it and be sure that performances will remain on this level for "real data" (test data). Therefore you do k-fold CV. You create k splits of the train data into train and validation data and validate all of these splits. Easy case: Lets say you have k = 3 and you have two models m1 and m2 (50 neurons, 100 neurons). You split your training data 3 times, which results in 3 combinations of train and validation data. You train and validate both models m1 and m2 with all of these combinations. M1: acc1 = 0.92, acc2 = 0.87, acc3 = 0.8 M2: acc1 = 0.98, acc2 = 0.85, acc3 = 0.91 Based on these results you can judge if m1 or m2 performs better. To do so, you calculate the mean of the accuracy for each model, so: M1: acc_mean = 0.863 M2: acc_mean = 0.913 In this case, m2 has the better overall performance on all k splits. Now forget about all the models you have trained. All you take away is: You have found out, that 100 neurons perform better! So you take your original train data and train a model (m2 with 100 neurons) with it. Finally you can test it with your test data. The difference between your results with hold-out set and k-fold CV is based on choice of the data. In other words, it is not representative for performance of your model. You can try to generate 3 different hold-out sets and you will see, that some perform better then others. Hope that helps to understand the idea of k-fold CV and interpreting the results. I suggest you to deeply understand the principles of machine learning / deep learning before moving over to early stopping and other optimization methods, otherwise you just use some techniques without knowing how they work and what their restrictions are.
