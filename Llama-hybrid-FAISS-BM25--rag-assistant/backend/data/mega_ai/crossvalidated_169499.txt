[site]: crossvalidated
[post_id]: 169499
[parent_id]: 
[tags]: 
Heteroscedasticity in machine learning predictions

I am using a machine learning method (PLS) to predict a continuous variable, which currently does a pretty good job, with reasonable RMSE etc. However, the residuals exhibit heteroscedasticity, where the error variance increases along with the dependent variable. I come from an econometrics background where it is emphasised that heteroscedasticity in residuals implies that the predictions obtained are non-optimal (intuitively there is some information that is being that could be incorporated into a model to improve the prediction). In econometrics, if we want to improve the performance of models we use weighted least squares, or other related methods to take into account this facet of the data. How should I approach this in machine learning? In particular in PLS (in the package Caret ), if you have any knowledge of this? Best, Ben
