[site]: crossvalidated
[post_id]: 462476
[parent_id]: 
[tags]: 
Why do model learn better on the same data copied few times?

I've faced something I can't understand. I am working with ANN, model is pretty simple, only few dense layers. As an input I have 8 columns with standarised values, problem is supervised learning, regression. For now I have X_train of shape (37160, 8). I've tried training model, but it didn't perform well: Later on I was working with my data and I messed up something with indexes while merging dataframes. It created copies of my data on my original file. At first I didn't notice that now my X_train has shape of (185800â€¬, 8) and I started fitting model. It was exactly the same model as above, as well as data, just the same rows copied few times. I realised something is wrong due to higher time for each epoch, however I didn't stop it and this is the result: I am newcomer to data science, just exploring basics and maybe it is a dumb question and the answer is silly, but can someone explain me what and why happened? Why the second model is learning better?
