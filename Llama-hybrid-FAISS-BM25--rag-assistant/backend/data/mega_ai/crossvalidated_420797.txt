[site]: crossvalidated
[post_id]: 420797
[parent_id]: 419458
[tags]: 
The approach: fully-convolutional generative models You could try using a fully-convolutional generative model such as a Variational Autoencoder , which has been used for many image generation tasks . Variational Autoencoders (VAEs) are made of an encoder network which compresses an image to a lower-dimensional Gaussian representation and a decoder network which reconstructs the original image. If you feed noise into the decoder network directly you can generate images. An Example Since a convolutional filter can be applied to an image of any size, fully-convolutional models can take in arbitrary images and will produce images with output sizes which are a constant fraction (or constant multiple) of the input image size. To use an absurdly very simple example, imagine you trained a VAE with an encoder made of one convolutional layer and a decoder made of one transposed convolutional layer (each with stride 2). If you generated noise of size MxN and fed it into the decoder half of your VAE, you would get an output of size 2Mx2N. Producing even smoother outputs This method along wouldn't produce quite smooth (for instance, the model described would only produce even-width/even-height images). If you care about having every single possible pixel dimension you could add an extra convolutional layer at the end with stride 1 (stride 1 will keep the image output size about the same as the input) and pad your image appropriately before passing it into the layer so the output has the desired size. I couldn't find any papers using a model like this for the type of image generation task you described, but fully convolutional models have been used successfully for semantic segmentation of variable-sized images .
