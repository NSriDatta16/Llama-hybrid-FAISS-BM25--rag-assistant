[site]: crossvalidated
[post_id]: 424119
[parent_id]: 
[tags]: 
Is there a fundamental difference between artificial neural networks and "other" supervised machine learning models

I would like to link three of these resources, present my understanding of what I read, and pose the question if my understanding is approximately correct Is Machine Learning glorified curve fitting Difference between supervised machine learning and design of experiments? How useful is Turing completeness? are neural nets turing complete? Reading the linked resources and assuming that the answers and comments are correct, I gather that (I quote myself, including bad spelling: this post is heavely edited, the initial content is in the history) From a certain, very abstract viewpoint, a supervised machine learning problem is an optimization problem. You try to maximize some "measure of good-ness" or minize some measure of "bad-ness". The way you formulate the problem defines, in a way, the "machine learning model". There might be different ways how you solve the optimization problem ("train the model"). is not wrong . [A] Question 1: is [A] correct? If [A] is correct, than in that sense, f.ex. a CNN (or ANNs in generall) is not different from a SVM or a Random Forest. [B] Question 2: Is [B] a reasonalbe conclusion? However, there exists proof that 1) FFN are universal approximators 2) RNNs are Turing complete I've read (unfortunately, I can't find the resource anymore) that it is possible to approximate Random Forest (and I would assume SVMs, ...) with certain kind of ANNs, but not the other way round. So in that sense the concept of ANN is more generall than SVMs or Random Forests (I'm struggling with the language a lot here...) [C] Question 3: Is [C] correct?
