[site]: datascience
[post_id]: 73114
[parent_id]: 
[tags]: 
How can I fix regression model interpretation of feature?

I'm building a regression model to predict the values of a feature $Y$ given a set of other features $X_{1}, X_{2}, X_{3}..X_{n}$ . Onde of these other features, let's say $X_1$ , is known to be inversely proportional to $Y$ based on domain's knowledge. The problem is my model is interpreting his coefficient as positive, letting it directly proportional to $Y$ . I've tried plenty of different models to verify if I could get better interpretation, such as OLS, Linear Regression, and Logistic Regression, but every model I tried failed to interpret the $X_1$ coefficient. What can I do to get a regression that better reflects the real-world behavior of this coefficient?
