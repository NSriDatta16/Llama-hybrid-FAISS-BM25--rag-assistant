[site]: crossvalidated
[post_id]: 368122
[parent_id]: 
[tags]: 
Discouraged by simple Bayesian Question

My university is testing an intro Machine Learning (ML) course for us undergrads, and having been interested in ML since the beginning to understand what it was, I jumped at the chance to take it. But being someone who has not been back in school for a long time and much busier than I was in my first years long ago, I am finding that I need more info and examples than the class in its current form has. I am struggling to figure out what the attached question is asking. I am searching online for help with this particular topic, but I am also finding that everyone seems to have their own way of phrasing similar questions in such a way that I am finding it hard to link the info. My understanding from stats way back when is that $p(x|\omega_1)$ is stating the probability of $x$ given $\omega_1$ for $0\le x \le 2$ and zero other wise. Same obviously if given $\omega_2$ . If I understand, the priors are the probability of $\omega_1$ and $\omega_2$ which are somehow obtained. And honestly that is as far as I am really comprehending. I am not sure what (a) and (b) are truly asking for or how to get them. If anyone is able to help me with some pointed info on the topic it would be greatly appreciated.
