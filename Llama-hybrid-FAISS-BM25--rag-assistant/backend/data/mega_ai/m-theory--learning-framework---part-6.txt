that it consists of simple and complex cells. This idea was originally proposed by Hubel and Wiesel. M-theory employs this idea. Simple cells compute dot products of an image and transformations of templates ⟨ I , g i t k ⟩ {\displaystyle \langle I,g_{i}t^{k}\rangle } for i = 1 , … , | G | {\displaystyle i=1,\ldots ,|G|} ( | G | {\displaystyle |G|} is a number of simple cells). Complex cells are responsible for pooling and computing empirical histograms or statistical moments of it. The following formula for constructing histogram can be computed by neurons: 1 | G | ∑ i = 1 | G | σ ( ⟨ I , g i t k ⟩ + n Δ ) , {\displaystyle {\frac {1}{|G|}}\sum _{i=1}^{|G|}\sigma (\langle I,g_{i}t^{k}\rangle +n\Delta ),} where σ {\displaystyle \sigma } is a smooth version of step function, Δ {\displaystyle \Delta } is the width of a histogram bin, and n {\displaystyle n} is the number of the bin. Applications Applications to computer vision In authors applied M-theory to unconstrained face recognition in natural photographs. Unlike the DAR (detection, alignment, and recognition) method, which handles clutter by detecting objects and cropping closely around them so that very little background remains, this approach accomplishes detection and alignment implicitly by storing transformations of training images (templates) rather than explicitly detecting and aligning or cropping faces at test time. This system is built according to the principles of a recent theory of invariance in hierarchical networks and can evade the clutter problem generally problematic for feedforward systems. The resulting end-to-end system achieves a drastic improvement in the state of the art on this end-to-end task, reaching the same level of performance as the best systems operating on aligned, closely cropped images (no outside training data). It also performs well on two newer datasets, similar to LFW, but more difficult: significantly jittered (misaligned) version of LFW and SUFR-W (for example, the model's accuracy in the LFW "unaligned & no outside data used" category is 87.55±1.41% compared to state-of-the-art APEM (adaptive probabilistic elastic matching): 81.70±1.78%). The theory was also applied to a range of recognition tasks: from invariant single object recognition in clutter to multiclass categorization problems on publicly available data sets (CalTech5, CalTech101, MIT-CBCL) and complex (street) scene understanding tasks that requires the recognition of both shape-based as well as texture-based objects (on StreetScenes data set). The approach performs really well: It has the capability of learning from only a few training examples and was shown to outperform several more complex state-of-the-art systems constellation models, the hierarchical SVM-based face-detection system. A key element in the approach is a new set of scale and position-tolerant feature detectors, which are biologically plausible and agree quantitatively with the tuning properties of cells along the ventral stream of visual cortex. These features are adaptive to the training set, though we also show that a universal feature set, learned from a set of natural images unrelated to any categorization task, likewise achieves good performance. Applications to speech recognition This theory can also be extended for the speech recognition domain. As an example, in an extension of a theory for unsupervised learning of invariant visual representations to the auditory domain and empirically evaluated its validity for voiced speech sound classification was proposed. Authors empirically demonstrated that a single-layer, phone-level representation, extracted from base speech features, improves segment classification accuracy and decreases the number of training examples in comparison with standard spectral and cepstral features for an acoustic classification task on TIMIT dataset. == References ==