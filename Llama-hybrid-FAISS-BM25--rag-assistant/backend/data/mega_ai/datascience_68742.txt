[site]: datascience
[post_id]: 68742
[parent_id]: 68725
[tags]: 
One way to approach this is to increase model capacity and see if/when your LSTM is able to learn the train data. In this first step it is ok to overfit (also see this recent question and answer for this approach) since you can add regularization/decrease model capacity later. These are the parameters I would tweak: find a good learning rate along a log-scale (try at least 0.1, 0.01 and 0.0001) increase the number of LSTM layers, e.g. to 5 increase the hidden dimension, e.g. to 1024 slightly increase the embedding dimension, e.g. to 300 If training this model takes too long, tune the learning rate based on your current model and then make the other adjustments. However, I suggest to not make the other adjustments in smaller steps or one by one as that can take a lot of time.
