[site]: crossvalidated
[post_id]: 611305
[parent_id]: 610044
[tags]: 
If you are getting $R^2 , then I assume you are calculating according to: $$ R^2=1-\left(\dfrac{ \overset{N}{\underset{i=1}{\sum}}\left( y_i-\hat y_i \right)^2 }{ \overset{N}{\underset{i=1}{\sum}}\left( y_i-\bar y \right)^2 }\right) $$ This is how sklearn.metrics.r2_score does the calculation, for instance. In that case, you are right that $R^2 is possible, but this is because the above equation need not be related to $\left(\text{corr}\left(y, \hat y\right)\right)^2$ like it is in OLS linear regression with an intercept. Even in such a setting, the relationship breaks down if you go to out-of-sample predictions like I suspect are of interest to someone working on neural networks. Consequently, $\sqrt{1-\left(\dfrac{ \overset{N}{\underset{i=1}{\sum}}\left( y_i-\hat y_i \right)^2 }{ \overset{N}{\underset{i=1}{\sum}}\left( y_i-\bar y \right)^2 }\right)}$ does not seem like a valuable statistic to calculate, even if the value is a real number. The only value might be to know this statistic is imaginary, since that flags situations where performance is poor (worse than the baseline of predicting $\bar y$ every time), but we would already know that from getting $R^2 . Since there are multiple featuress in your neural network, or at least one feature that nonlinearly predicts the outcome, there is not even a connection between $\sqrt{R^2}$ and the correlation between the feature and target like there is in simple linear regression. (I actually do not see much value in calculating $\sqrt{R^2}$ in linear regression, especially if there are multiple features.) Thus, I would not worry about getting imaginary square roots of $R^2 . If someone demands to know the correlation: Part of your job is to tell people when they have misconceptions. If someone is demanding to know a meaningless statistic or a statistic that does not mean what they think it means, your should be addressing the questions they should have asked. (It is easy to be a jerk about this, so don't be.) It is easy to calculate $\text{corr}\left(y, \hat y\right)$ if someone insists on it. It might be that this value is high, perhaps even one, despite $y$ being quite different from $\hat y$ , such as $y = (1, 2, 3)$ and $\hat y = (101, 102, 103)$ or $\hat y = (101, 201, 301)$ . Again, it is on you to explain why a high correlation between predicted and actual values can hide major issues with performance and to do assessments that expose such such issues.
