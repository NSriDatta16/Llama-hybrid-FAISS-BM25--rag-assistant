[site]: crossvalidated
[post_id]: 321818
[parent_id]: 246837
[tags]: 
I would suggest the following approach: First of all, it is important to define what is your criterion. Is it accuracy? Is it to maximize recall and to assure that the precision is at least 80%? This decision may be dependent on your context. For example, if you want to detect cancer, you want to focus on recall because it is dangerous to omit a potential patient. Divide the data you have into training, validation, and test sets. If you data set is sufficiently large, you do not have to go for cross-validation. For each possible combination of variables, you can train the model on training data, tune with validation data, and finally compare on test data. Then, you know which variables are more relevant. Some important notes: The feature selection can be understood also as a hyper parameter optimization. Thus, you can optimize not just the selection of features, but also e.g. number of neurons in neural network or number of trees in random forests. One efficient way how to select the features is regularization that works well not just for logistic regression, but also for neural networks. The lasso can help. Without splitting into training a test sets, the results can be confusing and blind trying of different subsets shall be avoided. Sometimes, it may be helpful to see what features have a direct or indirect influence on the prediction. For this purpose, (i) Bayesian networks or (ii) careful treatment of multicolinearity can be considered. A relevant reading is also here: http://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf
