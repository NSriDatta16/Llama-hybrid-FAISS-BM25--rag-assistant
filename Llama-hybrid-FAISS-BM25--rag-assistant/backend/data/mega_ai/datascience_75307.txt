[site]: datascience
[post_id]: 75307
[parent_id]: 74967
[tags]: 
The issue is in your sampling procedure. The purpose of a VAE is to train a neural network, the decoder, that takes samples $z$ from a normal distribution $p(z)$ and maps them to images $x$ such that the images follow the original image distribution $p(x)$ . The encoder's job is essentially to facillitate the training of the decoder, but for sampling it is not needed. What you do is that you sample an image with random pixel values, which has nothing to do with the original image distribution $p(x)$ , and map it to the latent space. The encoder is trained to map images to the latent space, not noise, hence the encoding is way off. Since the images with the normaly distributed values in the pixels are probably all similarly "wrong" compared to $p(x)$ , they get mapped to a similar domain in the latent space and hence produce similar outputs. For generation of new samples you only need the decoder, so instead of sampling images with normally distributed pixel values, sample normally distributed vectors in 256 dimensions and pass those through the decoder only. Side note: it seems a bit odd to me that you do not use fully-connected layers with non-linearities in the end of the encoder / beginning of decoder. If it works with only a linear mapping from the last feature map to the latent space, then it's fine, but intuitively I would have assumed that there should be at least one fully-connected layer with non-linear activation. But again, if it works then don't worry.
