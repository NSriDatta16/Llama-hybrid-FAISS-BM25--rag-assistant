[site]: crossvalidated
[post_id]: 380190
[parent_id]: 379318
[tags]: 
I think more the validation loss diverging at 500 epochs in the plot you have is more noticeable than the validation accuracy plateauing. I would recommend reducing the number of hidden units and see if it changes anything, in case you have not tried this already. I would set my first objective to reach similar loss and accuracy on train and validation and then try to improve both together. If none of these helped, I would check the train/validation split. Are you shuffling the data? Another reason for the performance above could be different distribution of training and validation sets. Edit (based on new results): I think this is a better start now. Usually the dropout values I have seen are .2-.5. 0.95 seems to much. If a lower dropout overfits, reduce the hidden units to 100. Here is what I might approach this. Fix the # of epochs to maybe 100, then reduce the hidden units so that after 100 epochs you get the same accuracy on training and validation, although this might be as low as 65%. This is what I call a good start. From here, I'll try these maybe: Start increasing the hidden units. (We know this start overfitting from your data, so go to option 2.) Add more layers, starting with few hidden units. Maybe 10 or so at each layer. Try other forms of RNNs like GRU. Tweak the # of observations, lower values may not have enough information, higher values might be tough to run, taking more time and still not capturing the long-term dependencies. If you are dealing with time-series data, not sequences like text, try applying pre-processing techniques like spectrogram and see if that helps. Take a look at Attention layers. See if you can leverage those with your model.
