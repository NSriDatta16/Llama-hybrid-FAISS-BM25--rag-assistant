[site]: crossvalidated
[post_id]: 335123
[parent_id]: 
[tags]: 
Classification - only one support vector possible?

Suppose we have a set of $n > 1$ data points in $\mathbb{R}^2$ labeled either positive or negative. This set is linearly separable. Suppose that I'm searching for a the largest margin hyperplane of this set by using a SVM classifier. It is possible to find such a data set that would result in having only one support vector? If no, what is the proof that the number of support vector must be at least 2?
