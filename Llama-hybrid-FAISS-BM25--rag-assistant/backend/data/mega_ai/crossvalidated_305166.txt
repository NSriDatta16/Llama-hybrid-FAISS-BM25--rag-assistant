[site]: crossvalidated
[post_id]: 305166
[parent_id]: 
[tags]: 
General question regarding probability distribution in machine learning

This question is in similar spirit to Probability distribution in data mining I am going through some material online, and the source says that given a set of training data and labels $\{(x_n,y_n)\}$, $n = 1, \ldots, N$, we make the assumption that: $x_n$ is generated by some "distribution" $P(x)$, or written as $x \sim P(x)$ How is the probability distribution related to cumulative density function, probability mass function or probability density function? It is assumed that such probability distribution is unknown. But can we have an idea as to how complex or simple such probability distribution could be? What is the use/utility of such unknown probability distribution? For example, at any moment we can measure a number of features about our body, say temperature, heart rate, rate of breathing, etc. Let $x_n$ be a vector that captures all these variables, then it could possibly be generated by some extremely high dimensional probability distribution (joint probability, mixed random variables, non-independent, non-zero correlation, covariance, mean, variance, etc.). We couldn't model such a probability distribution it even if we tried, so what benefit does it bring to us by making such an assumption? Would it be correct to say that training data $x_n$ are equivalent to random variable evaluated at some outcome of an underlying event space? If so, what is the event space?
