[site]: crossvalidated
[post_id]: 172647
[parent_id]: 172638
[tags]: 
This approach definitely does corrupt the model. The output of logistic regression is meant to convey the probability of an event given some configuration of independent variables. Explicitly removing large amounts of data because of the value of the dependent variable will definitely harm this aspect of the model's output. It sounds like your goal is to classify as opposed to using these probabilities, so if the skew is leading to two many false negatives, you should produce an ROC curve and determine if there is some threshold which produces an acceptable amount of false positives/negatives. The problem that you discuss has been studied greatly and is often referred to as one-class classification . When the vast majority of the data is "normal" and the goal is to detect "anomalies" (for example flight malfunction) there are many methods which essentially focus on understanding normality as opposed to understanding anomaly.
