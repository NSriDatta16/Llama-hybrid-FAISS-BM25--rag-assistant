[site]: crossvalidated
[post_id]: 168959
[parent_id]: 
[tags]: 
Constant-output Markov chain in time-series prediction

Suppose a Markov chain with two discrete states $A$ and $B$. The probability of moving from $A$ to $B$ is $0.1$ and the probability of moving from $A$ to $A$ is $0.9$. Similarly, $B$ to $B$ has probability $0.9$ and $B$ to $A$ probability $0.1$. Suppose the Markov chain describes a time-series where transitions from $A$ to $B$ and from $B$ to $A$ are something one would like to predict. Given the current state, the best prediction of the next state is the most probable next state . With the described Markov chain, it would be the best to predict $A$ or $B$ constantly, depending on the where the process started. This fails to be useful in predicting occurrences from $A$ to $B$ or vice versa, which is interesting. What should I conclude? That making predictions in such system is not possible? Or is the reasoning flawed with respect to best prediction of the next state is the most probable next state I asked the question https://stats.stackexchange.com/questions/168892/how-are-markov-chains-used-for-time-series-forecasting previously. This is related to that but not equal. Are Markov chain always not good for time-series prediction?
