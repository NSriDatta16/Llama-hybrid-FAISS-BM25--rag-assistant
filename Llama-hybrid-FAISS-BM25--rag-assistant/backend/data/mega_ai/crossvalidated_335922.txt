[site]: crossvalidated
[post_id]: 335922
[parent_id]: 275358
[tags]: 
Why is increasing non-linearity desired? Simply put: the more 'non-linear' our decision function, the more complex decisions it can make. In many cases this is desired because the decision function we are modeling with the neural network is unlikely to have a linear relationship with the input. Having more neurons in the layers with ReLU, a non-linear activation function, means that the output of the network should have a non-linear relationship with the input. 'Input' in this case is going to be the convoluted image segments. What effect does it have on the overall performance of the model? It depends on the problem. Considering CNNs: if the relationship between the class you want to predict and, in this case, convoluted image segments, is 'non-linear' then the performance of the network will improve if the fully connected layers (decision function) have non-linear activation functions (like ReLU). Stacking more layers will also increase your non-linearity.
