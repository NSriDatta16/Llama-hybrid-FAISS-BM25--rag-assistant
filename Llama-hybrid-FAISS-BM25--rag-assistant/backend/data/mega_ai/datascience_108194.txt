[site]: datascience
[post_id]: 108194
[parent_id]: 
[tags]: 
How to collect a computer vision dataset?

Context: my team is researching some plant-growth patterns using object detection models. We have collected a small set of images (a few thousand) and ran some simple experiments. The results were encouraging, so now we want to do some serious data collection (tens of thousands of images), but before doing so, we would like to have (create?) some "collection protocol", such as: defining the resolution of the images, times of day, weather, etc. For example, since our application will only run during daylight, we won't collect nighttime images. And since we cannot control the weather, we want to ensure that we have training data with different conditions, such as rain, fog, etc. Although (we think) our "collection protocol" is reasonable, it is still an ad-hoc product. We would feel better about doing such extensive data collection if we had some sort of "formal guideline", you know? I have read multiple papers discussing how datasets are made, but they usually focus on "how the data was labeled" and not on "how the data was collected". Can you guys suggest some peer-reviewed papers that discuss the data collection process itself? We hope to avoid non-obvious pitfalls that we have not considered. Thanks in advance.
