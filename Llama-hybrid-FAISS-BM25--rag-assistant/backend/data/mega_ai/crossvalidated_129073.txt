[site]: crossvalidated
[post_id]: 129073
[parent_id]: 126952
[tags]: 
Optimal control methods attempt to minimize a loss or error function just like neural networks (e.g. $E_j$ for each example $j$). However optimal control is about controlling a system to follow a reference trajectory, e.g. a path for a robot to follow or a specific signal to be generated, in some state space and the error function penalizes deviations from this trajectory (we will also frequently, though not necessarily, penalize controls that are too large by some metric). When training a neural network we do not always have a specific trajectory (i.e. sequence) of interest. Recurrent Neural Network are used for problems wherein we do have a desired trajectory, e.g. a path for a robot to follow or a specific signal to be generated. In such cases one needs a large number of example trajectories. The net could then be trained to output the controls required to move the system between a given start state and goal state. The trained network would then, hypothetically, be able to generalize to previously unseen start-goal state pairs. In training the network we are penalizing the deviation between the desired control and the correct control at each time step $t$ or the sum overall deviations, i.e. $Ej = \sum_t E_{j,t}$ where $E_{j,t}$ indicates the error for the deviation of the system at time step $t$ of trajectory $j$, which is the loss function we are optimizing in optimal control problems.
