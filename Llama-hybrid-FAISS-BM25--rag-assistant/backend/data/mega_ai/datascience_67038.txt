[site]: datascience
[post_id]: 67038
[parent_id]: 
[tags]: 
What is the difference between step size and learning rate in machine learning?

I am using TensorFlow to implement some basic ML code in Python. I was wondering if anyone could give me a short explanation of the meaning of and difference between step size and learning rate in the following functions. I used tf.train.GradientDescentOptimizer() to set the parameter learning rate and linear_regressor.train() to set the number of steps. I've been looking through the documentation on tensorflow.org for these functions but I still do not have a complete grasp of the meaning of these parameters. Thank you and let me know if there is any more info I can provide. (I posted this on Stack Overflow before I knew there was a Data Science forum board too, sorry)
