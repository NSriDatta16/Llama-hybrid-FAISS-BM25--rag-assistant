[site]: crossvalidated
[post_id]: 626048
[parent_id]: 625968
[tags]: 
I am not sure I completely understand your setup, especially regards the feature names. In all of your datasets features are traceable? That is, the 3rd column, for example, will mean the same? Regarding the Type of Feature Selection Method to use There is no one best option that will always win against others. Some relay on statistical assumptions and information theory (CMIM, for example), other on distance (SURF and its variants). Another important distinction would be the paradigm by which you do the feature selection. One might require you to run a model of some sort ( embedded methods ), other will look at the features themselves regardless of a model ( filter methods ) and also you have the method you were referring to, of forward/backward elimination. Each of the paradigm might be preferable under some circumstances. For example, iteratively running models might be very computationally expensive and time demanding, and it also may prone to overfit. Also, if your final model is XGBoost , for example, it would make no sense to use a logistic regression for the feature selection stage. How to Evaluate Your Feature Selection Method Basically, as you assess yourself on any choice of hyper-parameter combination, on the validation set. You can treat the FS stage as another hyper-parameter to choose, where you want to find the combination that maximizes your performance on the validation set. The only caveat, is again, computation power and time constraint. For a set of features, maybe the best hyperparameters combination would be x while for another set of features combination z would be the best, therefore it is tempting to search for a best combination of hyperparameters under every combination of features, but as you might see already, it is impractical. Therefore, what is being done in most of the companies I am familiar with, is (1) look for a best feature combination; then (2) hyperparameter tuning. For more information about feature selection, I kindly point you to the following introduction here . When focusing on Accuracy Alone This a somewhat unrelated question. Should you be looking at accuracy alone? Is your data balanced? Does the threshold matter? Do you have the same utility from true positive and true negative? I feel like it is a bit beyond the scope of the feature selection problem, as you want to choose features that maximize your KPI of choice.
