[site]: datascience
[post_id]: 27422
[parent_id]: 
[tags]: 
Which dissimilarity/similarity measure use after a dimension reduction ( PCA / AutoEncoder / ... )?

Each problem required its own similarity/dissimilarity measure. Imagine we are dealing with dataset composed with vector of real. I suppose that we mostly use the euclidean distance especially in low dimension. Unfortunately we often have to deal with huge dimensional dataset and we apply divers dimension reduction techniques to make the problem easier to solve. I will be happy to know your opinion about different similarity/dissimilarity measure you use after made a dimensionality reduction and how they impact classification/regression/clustering metrics. Is it better to use euclidean distance after a PCA or another distance measure ? Why ? And if i prefer to use AutoEncoder to reduce my dataset dimensions, does it exists a special one that guaranty to offer better results with a specific similiarity/dissimilarity measure ? Does it exist a dimensionality reduction technique that is optimal with a particular distance metrics an which is bounded in $O(n.log(n))$ in time ?
