[site]: stackoverflow
[post_id]: 2397508
[parent_id]: 2397474
[tags]: 
In the Linux kernel it is well explained (from those included): Deflate (gzip) - Fast, worst compression bzip2 - Slow, middle compression lzma - Very slow compression, fast decompression (however slower than gzip), best compression I haven't use others, so it is hard to say, but speeds of algorithms may depend largely on architecture. For example, there are studies that data compression on the HDD speeds the I/O, as the processor is so much faster than the disk that it is worth it. However, it depends largely on the size of bottlenecks. Similarly, one algorithm may use memory extensively, which may or may not cause problems (12 MiB -- is it a lot or very small? On embedded systems it is a lot; on a modern x86 it is tiny fragment of memory).
