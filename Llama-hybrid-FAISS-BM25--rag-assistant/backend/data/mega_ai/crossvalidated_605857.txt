[site]: crossvalidated
[post_id]: 605857
[parent_id]: 605778
[tags]: 
This is a variation of the Coupon Collector problem, extensively discussed on this site . However, the algorithm proposed for this variation is based on the Principle of Inclusion-Exclusion, which is numerically instable (because it involves cancellation of relatively large sums and differences). So, here I offer a solution more amenable to computation. You posit a situation in which a random sample of size $8$ is obtained without replacement from a population of $n=13$ substances. After obtaining $N$ such samples independently, we are interested in how many of the substances have not yet been sampled. This can be viewed as a Markov chain defined on the number of substances not yet sampled. After the first sample, there will be $k = 13 - 8$ unsampled substances. After sampling independently for awhile, suppose there remain $j\le k$ unsampled substances. The next sample will include $j^\prime \le j$ of them with probability $$p(j,j^\prime) = \frac{\binom{j}{j-j^\prime}\binom{n-j}{n-k - (j-j^\prime)}}{\binom{n}{n-k}}.$$ The transition matrix for this chain is $P = p(j,j^\prime).$ We only need to consider the transitions after the initial sample, for which $k \ge j \ge j^\prime \ge 0.$ Here it is (rounded to six digits). 0 1 2 3 4 5 0 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1 0.615385 0.384615 0.000000 0.000000 0.000000 0.000000 2 0.358974 0.512821 0.128205 0.000000 0.000000 0.000000 3 0.195804 0.489510 0.279720 0.034965 0.000000 0.000000 4 0.097902 0.391608 0.391608 0.111888 0.006993 0.000000 5 0.043512 0.271950 0.435120 0.217560 0.031080 0.000777 The row headings designate $j$ while the column headings are $j^\prime.$ Each row gives the probability distribution of the number of unsampled substances after the next sample is taken. We begin at the bottom row, with $j=k=5,$ because that is the state we are in after the first sample. It shows, for instance, there is a 0.043512 (4.5%) chance of completing your collection on the very next sample. But, at the other extreme, there's a 0.000777 chance that the next sample will pick up the same $n-k = 8$ substances in the first sample. And so on. The rules of matrix multiplication (which Excel can do, by the way) imply that the probability distribution after $N$ samples is found on the bottom row of the matrix $P^{N-1} = (P)(P)\cdots(P).$ More simply, the distribution designated by the bottom row becomes, after the next sample, the distribution designated by the bottom row multiplied by $P.$ That gives an efficient algorithm. Much more can be said by analyzing $P,$ but this should suffice. An effective algorithm in pseudocode is the following. It shows you how large $N$ must be in order to attain a chance $q$ of sampling all the substances. Input n, k, q Compute P Set PN = Vector of k zeros followed by a 1 For N = 1 to Infinity If PN(1) >= q Then Break Set PN = PN * P Next N Return N As an example, when run with $n=13,$ $k=5,$ and $q=0.95,$ this returns $N=6.$ Here's the $N-1 = 5$ power of the transition matrix (with rounded values to make it easier to read): 0 1 2 3 4 5 0 1.0000000 0.0000000 0.0000000 0e+00 0 0 1 0.9915835 0.0084165 0.0000000 0e+00 0 0 2 0.9832016 0.0167638 0.0000346 0e+00 0 0 3 0.9748543 0.0250419 0.0001038 1e-07 0 0 4 0.9665415 0.0332511 0.0002072 2e-07 0 0 5 0.9582632 0.0413915 0.0003448 5e-07 0 0 You can see the value 0.9582... in the $(5,0)$ position is just barely above the target of $q = 0.95.$ The bottom row is what you will find in the variable PN after the for loop is exited. As a bonus, the next entry 0.0413... tells you the chance of missing exactly one substance and the following ones tell you the chances of missing exactly two substances, and so on. You can see there's virtually no risk of missing more than one. You could generalize your question by asking how large $N$ needs to be to limit the risk of missing more than $j$ substances: all you need to do is compare the sum of the first $j+1$ entries in PN to your threshold q in the test inside the loop. Here is an R implementation of the algorithm. It begins with the function Transition to compute $P.$ This function employs the logarithms of the binomial coefficients to handle potentially large values of $n$ (which otherwise could overflow). I tested it with values of $n$ exceeding 10,000 and $k=5000.$ This is where almost all the work is done: the main loop takes no time at all in comparison.f As a final check, when run with $n=424,$ $k=424-5=419,$ and $q = 0.90,$ the result is $N=700$ with a chance of $0.900239...,$ exactly as found in the thread I referenced at the outset. Transition = q) break PN
