[site]: crossvalidated
[post_id]: 80712
[parent_id]: 80698
[tags]: 
The problems in your question can be divided into two types: Unsupervised learning: class labels are unknown Example algorithms include k-means, k-nearest-neighbour, mixture model, hierarchical clustering, etc. Supervised learning: class labels are known for at least a subset of the cases, and the algorithm is expected to generalize patterns it learned in the training data instead to predict classes or perform regression on new cases. Classification algorithms include SVM, neural nets (logstic, softmax), etc. Regression algorithms include neural nets (with real-valued outputs), linear regression, nonlinear regression etc. For unsupervised clustering specifically, there is no gold-standard measure of performance. (There is, however, a large number of measures that examine properties such as between-cluster distance, within-cluster distance, stability, association with domain-specific variables.) Therefore, practitioners may try a few algorithms and present the consensus clusters (i.e. consensus clustering), or they may choose the one that reveals 'interesting' patterns that are worthy of further investigation. For supervised classification/regressions, it is well known that given a sufficiently large amount of data, all the algorithms may perform similarly, provided that each is properly parameterized and tuned. Where the algorithms differ is in how fast they converge to the optimum accuracy (e.g. sensitivity, specificity, precision, recall). Given that data is often limiting, it may be worthwhile to identify the algorithm with superior performance using your limited data. Sometimes, your data may even be so limiting that all the algorithms you try have poor accuracy, suggesting that information contained in data is insufficient for accurate classification/regression (e.g. predicting long-term stock market prices using the price history). In order to test the performance of the algorithm properly, you need to set up cross-validation correctly so that your results are not confounded by algorithms fitting spurious noise in the training data (i.e. overfitting). You might find Andrew Ng's free online course helpful: http://www.ml-class.org
