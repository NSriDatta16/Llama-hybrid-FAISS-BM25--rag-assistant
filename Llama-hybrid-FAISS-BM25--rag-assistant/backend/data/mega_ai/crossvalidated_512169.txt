[site]: crossvalidated
[post_id]: 512169
[parent_id]: 
[tags]: 
Number of units in fully connected layers

I would like to build a fully-connected network for classifying three classes. As input I have two feature sets. One feature set with 100 features and another feature set with 1000 features. The input features consists of temporal and frequency features from smartphone accelerometer and gyroscope readings. The three classes correspond to three activity patterns. I thought about designing the neural network as follows: input: 100 features layer 1: 50 units batch normalization relu activation dropout layer 2: 25 units batch normalization relu activation dropout layer 3: 13 units batch normalization relu activation dropout output: 3 classes input: 1000 features layer 1: 500 units batch normalization relu activation dropout layer 2: 250 units batch normalization relu activation dropout layer 3: 125 units batch normalization relu activation dropout output: 3 classes Does this design make sense or is it better to have the units constant in each layer or even growing the number of units for a start?
