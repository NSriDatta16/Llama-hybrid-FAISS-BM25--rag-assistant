[site]: crossvalidated
[post_id]: 468923
[parent_id]: 468849
[tags]: 
Suppose your DGP is $s_{ij}=k_i+d_j+\varepsilon_{ij}$ , and $\varepsilon_{ij}\sim(0,\sigma^2)$ . Your variables are answers to questions $j$ and the observations are students $i$ . So, we could write this as: $$s_j(i)=k(i)+d_j+\varepsilon_j(i)$$ Let's look at means: $$\bar s_j=E[s_j(i)]=\bar k+d_j$$ Now we can seethe effect of demeaning: $$s'_j(i)=s_j(i)-\bar s_j=k(i)+d_j+\varepsilon_j(i)-(\bar k+d_j)=k'(i)+\varepsilon_j(i)$$ where $k'(i)=k(i)-\bar k$ With this DGP, you accomplished your objective, eliminated question difficulty, that is not interesting to you. It was important that this DGP had no difficulty in the error term. However, my experience tells me that maybe $\varepsilon_j(i)\sim(0,\sigma^2(d_j,k_i))$ . In which case de-meaning above will not work. The reason is that when we plug this into PCA, it effectively handles the covariance matrix: $$C=cov[s'_j,s'_k]=cov[\varepsilon_j,\varepsilon_k]$$
