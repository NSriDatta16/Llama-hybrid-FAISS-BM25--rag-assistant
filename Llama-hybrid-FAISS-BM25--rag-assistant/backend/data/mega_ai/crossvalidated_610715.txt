[site]: crossvalidated
[post_id]: 610715
[parent_id]: 610712
[tags]: 
This is what happens when you overfit the training data. Your model identifies idiosyncratic characteristics of the training data that are specific to that data sample but don't generalize to other data samples. So what seems to be excellent performance on the training data does not carry over to new data. An Introduction to Statistical Learning discusses overfitting and how to minimize it throughout the text. Considerations specific to neural networks are in Chapter 10. In outline, to minimize overfitting you can either have the network learn more slowly or penalize the model's parameters. Also, consider whether a single train/test split is the best way to evaluate your modeling. In other contexts Frank Harrell recommends resampling-based validation of the modeling process unless you have tens of thousands of cases. I suspect that similar considerations apply to this type of image classification, although I don't have much experience with it.
