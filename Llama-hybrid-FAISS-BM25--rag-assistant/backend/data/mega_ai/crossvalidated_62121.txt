[site]: crossvalidated
[post_id]: 62121
[parent_id]: 59472
[tags]: 
It seems an off-the-cuff blog post has run wild here, so please afford me the opportunity to respond. [Edited shortly after original post] In recreating my results, it looks like there are potentially two pieces missing. Firstly, the standard deviation measure must also assume a zero mean for the distribution (so the square-root of the mean of squared daily distance measures). Secondly, the sensitivity of the similarity measure is going to be based on the moving averages used and the length of the measurement period. Extending the data from 5/15/2013 to 6/18/2013 changed the measure from -9% to -17% with the 20 DMA model. [/Edit] I don't quite know why Placidia seemed to so aggressively attack my understanding of time-series; nowhere in my post do I present this alternative measure as a legitimate, mathematically sound model. Perhaps I should have more concretely not stated it as such. She is absolutely correct in her definitions of spectral decomposition, linear correlation, and autocorrelation. I was not shooting for a lagged cross-correlation function (if I was, I would have used it). I do not contest that the model I presented is mathematically unsound. But there is a big difference between mathematically accurate and pragmatically useful. I could have differenced the two models and tried to fit an ARMA(p,q) model. But what are p and q? Then we have to start talking AIC and BIC to find the most parsimonious, but statistically significant model. Then I have to worry whether I can assume the relationship will remain stationary long enough that I can continue to use this model going forward. In this particular case, that solution was overkill. I am a big believer that simple and intuitive is more robust than complicated -- even if complicated is more purely mathematically accurate. My intention was not to say that the measure I was playing with was better , but simply, in my case, potentially more useful for what I was trying to capture. She says that having a zero mean is important and you should difference to get there. This is absolutely, mathematically true. Looking at financial data, however, we see that long-term, daily return distributions tend to have a very near-zero mean return -- so the point is moot. In the short-term, however, securities can exhibit statistically significant trends. By assuming a zero mean, rather than differencing out to a zero mean, we incorporate this trend within our data and therefore our correlation measure. A quick and dirty trick, but it works for us because we know we're doing it. I can appreciate she doesn't like it. It's non-pristine mathematics. It's messy. It has warts and bumps and doesn't fit in the right, rigid boxes. But it is pragmatic for me as a quick measure that helps incorporate the short-term, statistically-significant trends that can occur in financial returns, into a simple, quick, off-the-cuff similarity measure.
