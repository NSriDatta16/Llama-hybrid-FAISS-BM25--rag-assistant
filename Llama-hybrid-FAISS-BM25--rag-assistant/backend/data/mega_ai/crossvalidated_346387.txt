[site]: crossvalidated
[post_id]: 346387
[parent_id]: 
[tags]: 
Why does enforcing a prior distribution create semantic latent variables in variational autoencoders?

Variational autoencoders create latent variables that have a known distribution (e.g., Gaussian with zero mean and unit variance), and so do adversarial autoencoders. I understand why this turns the autoencoder into a generative model, but somehow this also causes the latent variables to have semantic meaning. For example, when "walking in latent space" of an encoder trained on face images, one of the coordinates of the latent vector might gradually transition the generated images from male to female, and another coordinate might gradually change the age, another might affect the appearance of sunglasses. What is the theoretical explanation for this?
