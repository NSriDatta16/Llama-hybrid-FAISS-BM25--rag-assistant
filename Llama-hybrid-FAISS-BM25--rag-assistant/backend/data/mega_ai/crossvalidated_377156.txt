[site]: crossvalidated
[post_id]: 377156
[parent_id]: 376766
[tags]: 
Encoder part can reduce size of the image by 100 and decoder part will increase it back by 100. It doesn't matter what will be the size of the image as long as decoder makes reverses operations compare to the encoder. Convolutional parameters are shared across the image, so it doesn't matter what's the height and width of the image. Also, just because you can propagate images through the network it doesn't mean that you will get reasonable answer for any image. If you propagate one image through the network and get nearly perfect segmentation, but increasing area for the same image by large factor, let's say 1000, will destroy this effect only because objects in the up-scaled image are so large compare to the average representation of the same objects in the training that it won't be able to capture them with fixed set of the convolutional layers.
