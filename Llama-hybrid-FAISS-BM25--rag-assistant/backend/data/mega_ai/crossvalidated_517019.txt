[site]: crossvalidated
[post_id]: 517019
[parent_id]: 
[tags]: 
What does it mean for a Markov CHAIN to be recurrent (not just a state)?

There are many resources offering equivalent definitions of recurrence for a state in a Markov Chain - for example, state $x$ is recurrent if, starting in state $x$ you will eventually return to state $x$ almost surely. However, I have been asked to show that a certain Markov Chain is recurrent. Half an hour of Google searching has not been able to answer whether this means existence of a recurrent state, or that all states are recurrent. So I put it to the community - what does it mean for a Markov Chain to be recurrent?
