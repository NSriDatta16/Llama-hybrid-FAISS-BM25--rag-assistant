[site]: crossvalidated
[post_id]: 591586
[parent_id]: 591578
[tags]: 
An example of an article that defines it is "Honest Confidence Regions for Nonparametric Regression" by Ker-Chau Li (1989). Here the word "honest" refers to the requirement that the minimum coverage probability over a rich class of (nonparametric) regression functions should be no less than the nominal confidence level Confidence intervals can 'fail' to be honest when they are not exact computations, and are instead estimates. An example of how it can go 'wrong' are the different methods to compute a confidence intervals for a binomial proportion . The Clopper-Pearson is always covering at least the given percentage, no matter what the true proportion parameter is. Other intervals, like Wald interval or Jeffreys interval don't (at least not when you condition on the parameter). The image below gives an example where the coverage probability is given as function of the true parameter for the case of a sample from a binomial distribution with n=100 (From this question Revisiting the Rule of Three ) In the case of the Wald interval the 'mistakes' are introduced because it is an approximation. In the case of Jeffreys' interval the 'mistake' is because the interval is actually a credible interval and doesn't even try to be a confidence interval by design.
