[site]: crossvalidated
[post_id]: 374949
[parent_id]: 
[tags]: 
Questions about performing k-fold cross validation for the first time

I am learning how to perform K-fold CV and I have a few questions about the method. This is an excerpt from the website: https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f . In K Fold cross validation, the data is divided into k subsets. Now the holdout method is repeated k times, such that each time, one of the k subsets is used as the test set/ validation set and the other k-1 subsets are put together to form a training set. The error estimation is averaged over all k trials to get total effectiveness of our model. As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set. Interchanging the training and test sets also adds to the effectiveness of this method. As a general rule and empirical evidence, K = 5 or 10 is generally preferred, but nothingâ€™s fixed and it can take any value. Notice that the much of the explanation done here is about the error itself. Let's say that I am performing a linear regression on sets of data. (This is the model I want to have.) Additionally I have 10 sets of data where I fit a model on. If I decide to have $k = 5$ (from this text), I will have 2 sets of data per $k$ . So I can fit a model on these 2 sets, and test the data with the other sets and record their errors. My question: So I will need to repeat this procedure with other sets of data (so that each $k$ will become a validation set exactly once), what happens to my model? Which model do I choose? Insights please.
