[site]: crossvalidated
[post_id]: 246139
[parent_id]: 246122
[tags]: 
Some machine learning algortihms (kNN, tree based algorithms including random forests, naive Bayes, graph based algorithms with label propagation etc.) can handle multi class classification inherently. They also output probability estimates for each record to belong to each of the classes. Usually, you would assign only the most probable class per record. In your case, you can assign the k most probable classes. Or you could assign as many classes as there are above a certain probability threshold. This allows you to do your multi-class, multi-label classification while running the algorithm only once and not 12 times. It is better o have one binary column per class (and maybe also keep the columns per class with the classification probabilities). Having one column with a varying number of data concatenated is a mess in programming, avoid it. It is not very clear from your post if this is supervised learning. Do you have the correct label(s) per record? The imagenet data-set is for example tested with multiple labels per record even though there is only one correct label. If the correct label is among the top 5 predicted, this counts as a correct classification. If you have multiple corretc labels per record, it will be more complicated to measure the classification performance comparing them to multiple estimated labels.
