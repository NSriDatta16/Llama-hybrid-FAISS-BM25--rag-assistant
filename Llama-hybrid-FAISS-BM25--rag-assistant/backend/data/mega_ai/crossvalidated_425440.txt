[site]: crossvalidated
[post_id]: 425440
[parent_id]: 
[tags]: 
Discrete Regression with Neural Networks

I'm currently building a neural network(NN) for regression on a dataset that came from a lab experiment, each sample was ran against a sensor 10 times, yielding 39 independent variables having the same dependent variable. The database is then made of 120 lines coming from 12 samples, repeated 10 times each, and each sample has the same value for the dependent variable. Given that, I first split the database into two parts having the same proportion of samples. (Forgive, please, the code below, I didn't know how to better implement it) import pandas as pd import random from sklearn.neural_network import MLPRegressor from sklearn.model_selection import validation_curve train_set = pd.DataFrame(columns=base.columns) for samp in base.sample.unique(): samples = random.sample(list(np.arange(1,11)), k=7) int1 = base[(base.sample==samp) & (base.sample.isin(samples))] train_set = pd.concat([train_set,int1]) train_out_set = train_set['Target'] train_in_set = train_set.drop('Target, axis =1) The test set was just what was left from the original base minus the train. Manually done. At first, I tried fitting the data into a three-neuron one hidden layer network with the variables having the fewest outliers: nn = MLPRegressor((3), activation= 'logistic', solver = 'sgd', max_iter = 2000, alpha = 0, random_state =9 ) nn.fit(train_in_set.loc[:,few_outliers], train_out_set) nn.score(test_in_set.loc[:,few_outliers], test_out_set) For which I received and R² of -0.06 for both sets. Given the low score even for the train set, I thought the NN was underfitting, hence I use validation_curve for assessing various sizes of the one hidden layer, but this using using all independent variables: nn3 = MLPRegressor((3), activation= 'logistic', solver = 'sgd', max_iter = 2000, alpha = 0, random_state = 9 ) train_score, val_score = validation_curve(nn3, train_in_set, train_out_set, 'hidden_layer_sizes', range(3,26), cv =3, scoring='r2') mts = train_score.mean(axis=1) mvs = val_score.mean(axis=1) For which I got I tried doing the same last step which the other parameters of the network, namely, the activation function, the random_state and none gave me a minimal satisfactory value(R² of 0.5). I was wondering if the problem could be with the CV step, since I can't control which of the sample go into which fold and hence causing low R² scores or am I approaching the whole thing from the wrong side ? P.S.: I thought of maybe using MLPClassifer , but the idea of NN was enabling us at the lab to estimate the target variable of new samples sometimes without the need to prior classification.
