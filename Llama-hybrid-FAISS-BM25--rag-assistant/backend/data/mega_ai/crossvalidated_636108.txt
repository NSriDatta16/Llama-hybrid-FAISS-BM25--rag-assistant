[site]: crossvalidated
[post_id]: 636108
[parent_id]: 611583
[tags]: 
Here are some additional thoughts. If treated as a time series decomposition problem, your data may be thought symbolically as Y= 'Trend/PiecewiseLinear' + Outlier + error . Apparently, numerous ways are possible to do the inference and detect the associated changepoints, most likely with inconsistent results among statistical methods. Let me use a Bayesian time series analysis package Rbeast I developed (more info available at https://github.com/zhaokg/Rbeast ) to demonstrate this decomposition. In R, first make a simulated signal with a two-piece trend (the first segment is a flat line and the second segment is a linear line) plus three outlier-type changes. set.seed(123) # the 1st seg is flat and the 2nd segment is linear y = c( (1:50)*0, 1:50 ) + rnorm(100)*2 # Add artificial dips/spikes at three isolated points to mimic outlier-type changepoints y[30] = y[30]+20 y[69] = y[69]-20 y[70] = y[70]+20 plot(y, type='l') Then, run the time series decomposition to estimate the trend (i.e., piecewise linear model) and outlier components, together with possible changepoints. library(Rbeast) out = beast(y, season='none', hasOutlier=TRUE) plot(out) where the prob(tcp) subplot shows the probability of changepoint occurrence over time in the trend component and the single peak indicates that there is just one possible changepoint, and the outlier subplot shows the outlier component. The three salient outliers are detected but apparently there is a model overfitting because some other smaller extreme values also have decent probabilities of being outlier-type changepoints. This may be not that useful for your specific applications, but hopefully it at least provides some alternative perspectives.
