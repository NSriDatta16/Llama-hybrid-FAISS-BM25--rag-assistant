[site]: crossvalidated
[post_id]: 163110
[parent_id]: 37993
[tags]: 
I concur regarding the usefulness of a boostrapped t-test. I would also recommend, as a comparison, a look at the Bayesian method offered by Kruschke at http://www.indiana.edu/~kruschke/BEST/BEST.pdf . In general, questions of "How many subjects?" can't be answered unless you have in hand an idea of what a significant effect size would be in terms of the problem being solved. That is, and for instance, if the test were a hypothetical study regarding the efficacy of a new drug, the effect size might be the minimum size needed to justify the new drug compared to old for the U.S. Food and Drug Administration. What's odd in this and many other discussions is the wholesale willingness to posit that some data just have some theoretical distribution, like being Gaussian. First, we don't need to posit, we can check, even with small samples. Second, why posit any specific theoretical distribution at all? Why not just take the data as an empirical distribution unto itself? Sure, in the case of small sample sizes, positing that the data come from some distribution is highly useful for analysis. But, to paraphrase Bradley Efron, in doing so you've just made up an infinite amount of data. Sometimes that can be okay if your problem is appropriate. Some times it isn't.
