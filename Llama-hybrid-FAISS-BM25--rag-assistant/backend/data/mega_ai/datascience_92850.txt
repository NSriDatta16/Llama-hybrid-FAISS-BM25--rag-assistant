[site]: datascience
[post_id]: 92850
[parent_id]: 92837
[tags]: 
Suppose you have a question like: "How does car weight affect miles per gallon (mpg)?" Load and plot the "car data". In the first plot you can clearly see that there is a (more or less) linear relation between $weight$ and $mpg$ . Now you can ask: is there a difference in time? You can add a "dummy" for the years $\leq$ 1975 to flag this years ( $=1$ if true $=0$ otherwise). When you plot the data for the two periods of time ( $\leq$ 1975 vs. $>$ 1975), you can see that there is quite a difference. library(ISLR) library(dplyr) # Car dara df = ISLR::Auto df = df %>% select(weight,mpg,year) summary(df) # Dummy encoding "time" df $y70_75 = ifelse(df$ year $weight,df$ mpg,xlab="Weight", ylab="MPG", ylim=c(10,50)) # Plot with "time dummy" plot(df $weight[df$ y70_75==1],df $mpg[df$ y70_75==1],xlab="Weight", ylab="MPG", col="red", ylim=c(10,50)) points(df $weight[df$ y70_75==0],df $mpg[df$ y70_75==0]) Now we can plug this into a linear regression, essentially fitting one linear line for the black dots and one linear line for the red dots (indicated by the dummy). The model looks like $$ mpg = \beta_0 + \beta_1 weight + \beta_3 dummy_{70-75} + u$$ # Regression reg = lm(mpg~weight,data=df) summary(reg) # Regression with time dummy reg2 = lm(mpg~weight+y70_75,data=df) summary(reg2) Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 46.325718 0.689669 67.17 For the years $\leq$ 1975, the estimated $mpg$ would be $43.3 - 4.53 * 1 - 0.007 * weight$ , for the remaining years ( $>$ 1975), the estimated effect would be $43.3 - 4.53 * 0 - 0.007 * weight$ . Adding a dummy here simply augments the intercept term conditional on the dummy. Here this would be a different intercept term conditional on time as defined by the dummy. We can say that (on average) $mpg$ for the years $\leq$ 1975 was lower than in later years. Or in other words, for a given $weight$ , $mpg$ was about -4.5 units lower in $\leq$ 1975 compared to later years. When you have a lot of dummies, you can end up with more variables (columns) than observations (rows) which is a "high dimensional" problem. This is - for instance - the case when you dummy encode text as a "bag of words". In this case you need to use regularization in linear models (e.g. Lasso/Ridge).
