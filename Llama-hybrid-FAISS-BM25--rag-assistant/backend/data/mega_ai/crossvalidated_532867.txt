[site]: crossvalidated
[post_id]: 532867
[parent_id]: 393708
[tags]: 
Can they be used? Yes. Autoencoders (AE) are dimensionality reduction techniques. One could formulate a mapping from missing data series to full series, in 1-D, $\mathbb{R}^{m} \rightarrow \mathbb{R}^{n}$ , where $m , $m-n$ missing time-points. This is the conceptual idea. However, training vanilla AE may not be possible without introducing any prior knowledge from low-dimensional (missing data) set, that's why people introduce "pairing" AE with other techniques, such as Gaussian Process for the lower dimensional series $x_{t}$ , to full latent series $z_{t}$ . A sketch of the formulation in this case will look like $$ p_{\theta}(z_{t}|x_{t}) = \mathcal{N}(g_{\theta}(x_{t}), \sigma^{2}\bf{I}))$$ where the inference is to find $\theta$ parameters. AE replaces function $g$ . See GP-VAE: Deep Probabilistic Time Series Imputation . If so, which is the major modification I need to make to the architecture, in order to get a performing implementation for my use case? The core issue is not only selecting appropriate architecture but formulation of the problem. which other Deep Learning or AI model are suitable for missing data imputation with multivariate time series? GANs are also utilised in the literature.
