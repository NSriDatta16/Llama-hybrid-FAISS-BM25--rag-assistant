[site]: datascience
[post_id]: 113810
[parent_id]: 
[tags]: 
How to use a `lr_scheduler` when you don't known how many training steps to do?

I am trying to fine-tune a BERT model, but instead of doing it a fix number of training step, I want to use a stalling policy and allow it to run until the model stalls for N evaluations. However, I was previously using the transformers.get_linear_schedule_with_warmup , which requires an explicit number of training steps. Is there any other learning rate scheduler that I should use for this task?
