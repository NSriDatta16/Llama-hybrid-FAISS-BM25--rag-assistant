[site]: crossvalidated
[post_id]: 60621
[parent_id]: 
[tags]: 
Understanding the two-stage choice paradigm

In Manski - The structure of random utility models the following example is proposed: Consider the alternative set space a = $(\alpha,\beta,\gamma)$ with the attribute representation: $X = \begin{bmatrix} & \alpha & \beta & \gamma & \cr x_1 & 1 & 1 & 2 \cr x_2 & 0.5 & -0.5 & -1 \end{bmatrix}$ . The individuals/decision-makers $\sigma$ and $\tau$ are characterized by the attributes: $S = \begin{bmatrix} \sigma & \tau \cr 1 & 0 \end{bmatrix}$ . Finally the function $w(x,s)$ which defines the utility of the utility maximizing agents $\sigma$ and $\tau$ is given by $w(x,s) = x_1 + x_2\cdot s$ . The aim is to compute the probabilities: $P_t(a\in^c C)$ which is the probability that a decision-maker $t\in T$ will choose the alternative $a$ from a possible choice set $C$ . By the definition of the alternative space a one can think of $C$ as any non-empty subset of any particular order of the alternatives $\alpha, \beta$ and $\gamma$ . Hence there will be quite a few possible choice sets $C$ from which a decision-maker can choose. Manski denotes the choice set space, the set of all possible non-empty subsets $C$ , with $\Gamma$ and $T$ represents the population of all possible decision-makers. To calculate $P_t(a\in^c C)$ additional information is given. The joint distribution $M_{\Gamma T}((C,t))$ of possible choice sets $C$ and the decision-makers $t$ is given by: $M_{\Gamma T}((\alpha,\beta,\gamma),\sigma) = \frac{2}{36}$ for each of the six ordered choice sets whose elements are $\alpha,\beta$ and $\gamma$ $M_{\Gamma T}((\alpha,\beta),\sigma) = \frac{1}{12}$ for each of the two ordered choice sets whose elements are $\alpha$ and $\beta$ $M_{\Gamma T}((\alpha,\beta,\gamma),\tau) = \frac{1}{36}$ for each of the six ordered choice sets whose elements are $\alpha,\beta$ and $\gamma$ $M_{\Gamma T}((\alpha,\beta),\tau) = \frac{2}{12}$ for each of the two ordered choice sets whose elements are $\alpha$ and $\beta$ To calculate the probabilities $P_t(a\in^c C)$ for the case that the information of $x_2$ is not observed we first need to calculate the vector $W_{Ct}$ which contains the utilities for the alternatives contained in $C$ for a decision-maker $t$ . In this case this will yield: $\bar W_{(\alpha,\beta,\gamma),\sigma} = \begin{pmatrix} 1.5\\ 0.5\\ 1\end{pmatrix}$ and $\bar W_{(\alpha,\beta,\gamma),\tau} = \begin{pmatrix} 1\\ 1\\ 2\end{pmatrix}$ For the calculation of the probability $P_t(a\in^c C)$ Manski gives the following two formulas: $(1) \ P(\bar W_{Ct} | r_{Co},s_{to}) = \frac{ \sum_{ (\tilde C, \tilde t):r_{\tilde Co} = r_{Co}, s_{\tilde to} = s_{to}, W_{\tilde C\tilde t} = \bar W_{Ct} } M_{\Gamma T}((\tilde C,\tilde t))}{\sum_{ (\tilde C, \tilde t):r_{\tilde Co} = r_{Co}, s_{\tilde to} = s_{to}} M_{\Gamma T}((\tilde C,\tilde t))}$ $(2) \ P_t(a\in^c C) = \sum_{\bar W_{Ct}:\bar w_{at}\ge \bar w_{\tilde at}, \tilde a\in C}P(\bar W_{Ct} | r_{Co},s_{to})$ So clearly in order to calculate $P_t(a\in^c C)$ we need to calculate (1) first. This is done by summation over $M_{\Gamma T}((\tilde C,\tilde t))$ for all possible choice problems $(\tilde C,\tilde t)$ for particular values of $r_{\tilde Co},s_{\tilde to}$ and $W_{\tilde C\tilde t}$ namely $r_{Co},s_{to}$ and $\bar W_{Ct}$ . To do that we need to consider the definition of $r_{Co}$ and $s_{to}$ . Manski proposes that $X$ and $S$ are split up into observable and non-observable parts like $X = [X_o,X_u]$ and $S = [S_o,S_u]$ where the "o" donates the observable, and "u" the non observable part. Now we can write $X_o$ as $X_0 = (x_{ao}, \forall \ a\in $ a ). The definition of $r_{Co}$ is now given by $r_{Co} = (x_{ao}, \forall \ a\in C)$ . So the only difference between $X_o$ and $r_{co}$ is the set on which $x_{ao}$ is defined on, since $r_{Co}$ considers all possible choice-sets $C$ , $X_o$ only defines $x_{ao}$ on the alternative space a . Now my dilemma: Since I need to calculate (1) in order to calculate (2), I need to sum up the joint probabilities $M_{\Gamma T}((\tilde C, \tilde t))$ over possible values of $r_{Co}, s_{to}$ and $\bar W_{Ct}$ . Since the value of $s_{to}$ is given by the integers $1$ or $0$ and $\bar W_{Ct}$ is just one possible utility-vector depending on which choice-set $C$ we are currently looking on, I only need to figure out what $r_{Co}$ actually is. The definition is quite clear but for this example I'm not quite sure. Since $x_2$ is not observed I thought of $r_{Co}$ as a vector of the observed outcomes of $x_1$ , i.e., $r_{Co} = (1.5,0.5,1)$ for $C = (\alpha,\beta,\gamma)$ . But if I consider $r_{Co}$ in this way the calculation will not work since (1) will always be 1 and the sum in (2) can get larger then 1 which is of course not possible. I'm stuck with this problem a couple of days now and any help will be much appreciated!
