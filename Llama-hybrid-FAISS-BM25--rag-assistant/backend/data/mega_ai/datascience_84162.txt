[site]: datascience
[post_id]: 84162
[parent_id]: 
[tags]: 
How to quantify ‘compute cost’ of training of xgboost model?

I want to quantify compute cost of hyper-parameter search for xgboost model. One way can be to measure training time with one particular hyper parameter configuration chosen for training and use it as proxy for compute cost. Can we quantify compute cost based on hyper parameters of this model depending upon value of hyper parameters chosen e.g., analytical expression based on max depth, num of estimators, min child weight, gamma etc or can you suggest some other way to quantify this compute cost? I want to measure for each particular hyper parameters chosen for training on same set of data what will be the model performance and compute cost!
