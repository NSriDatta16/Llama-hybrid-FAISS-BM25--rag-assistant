[site]: crossvalidated
[post_id]: 512011
[parent_id]: 512008
[tags]: 
This is a consequence of Jensen's Inequality . You want $E[y|x]$ , but exponentiating the predicted value(s) from the log model will not provide unbiased estimates of $E[y|x]$ , as $$E[y_i|x_i] = \exp(x'\beta) \cdot E[\exp(u_i)]$$ and the second term is omitted in your calculation. If the error term $u \sim N[0,\sigma^2]$ , then $E[\exp(u)] = \exp(\frac{1}{2}\sigma^2)$ . That quantity may be estimated by replacing $\sigma^2$ with its consistent estimate $s^2$ from the regression model. Alternatively, Duan (1983) shows that for $iid$ errors (which need not be Normal), $$E[\exp(u)] = \frac{1}{N} \sum_i \exp(e_i),$$ where $e_i$ are the residuals. I've implemented Duan's Smearing Transformation below. Essentially, you need to multiply the exponentiated mean by the average of the exponentiated residuals: library(tidyverse) test $fitted.values))*mean(exp(m$ residuals)) mean(test$salary) This will work even if you have covariates in the model, though you will have to tweak the calculation a bit since the predictions will now vary across observations: mean(exp(m $fitted.values)*exp(m$ residuals)) This second version should also work in your intercept-only example.
