[site]: crossvalidated
[post_id]: 393959
[parent_id]: 393776
[tags]: 
One problem could be using a different metric for evaluating test performance than training. SVM is optimizing empirical missclassification error that tries to minimize the absolute number of correct classifications, regardless what are the proportions in each class, whereas F1 could be penalizing more the errors in the less prevalent class (based on quick look at F1). When optimizing on the natural proportion, the classifier is biased to the prevalent class (because of optimizing the empirical error) and F1 decreases because of that. Your goal seems to be give more importance to less prevalent class. I suggest define the train objective that reflect your goals and evaluate both train and test based on same metric . Adjusting training proportions is one way for achieving that (in this case, you should see improvement in the natural test evaluated with a more balanced metric. Have you checked confusion matrices?). Another is to weight the samples, so that you are able to use all training set.
