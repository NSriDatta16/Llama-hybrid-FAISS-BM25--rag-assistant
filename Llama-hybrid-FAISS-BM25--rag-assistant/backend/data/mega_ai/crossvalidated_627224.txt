[site]: crossvalidated
[post_id]: 627224
[parent_id]: 
[tags]: 
Is it normal to have a sharp increase in validation error when using 10% of the data instead of something like 20-30%?

Scenario: I'm training a relatively simple neural network to classify pairs of tabular datapoints (~150k), lets say drugs and diseases, whether they are related (positive) or not (negative). As I only have a list of related pairs, I first split my data to train and test sets. Then, for each pair in my train set, I randomly sample a disease for each drug in a manner that the new pairs are not present in the training set, and the training set only, so to avoid data leak. This negative sampling is also done in the test set, but there the new negative pairs are checked against both the train and the test sets. Result is, around 300k pairs with 50/50 positive-negative split. Additionally, the features of the pairs are standardized, but once again, the test set is standardized with the mean and variance of the train set to avoid data leak. Problem: The model performed quite good with a 0.7/0.3 train-test split, but when I tried 0.9/0.1 its performance dropped off sharply. I've run it multiple times, it isn't just a result of an accidental bad split. Moreover, the training errors remained about the same in both splits. Is this a normal phenomenon? Or is there something I did wrong? Edit: Training the very same model for 10 epochs 0.6/0.4 split (even better performing than the 0.7/0.3) train_loss=0.3715, train_accuracy=0.8456, train_auroc=0.9147, train_auprc=0.9089 test_loss=0.3803, test_accuracy=0.8374, test_auroc=0.9099, test_auprc=0.9139 0.9/0.1 split train_loss=0.3343, train_accuracy=0.8620, train_auroc=0.9311, train_auprc=0.9310 test_loss=0.4557, test_accuracy=0.7943, test_auroc=0.8779, test_auprc=0.8837 There are batch norm and dropout layers in the network to improve generalization.
