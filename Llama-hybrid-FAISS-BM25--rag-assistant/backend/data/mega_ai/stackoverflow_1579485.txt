[site]: stackoverflow
[post_id]: 1579485
[parent_id]: 1565347
[tags]: 
I worked out the following solution: Using an XPath query on the XHTML source code (I took the print-version, because it is shorter, but it also works on the normal version). //html/body//div[@id='bodyContent']/p[1] This works on German and on English Wikipedia and I haven't found an article where it doesn't output the first paragraph. The solution is also quite fast, I also thought of only taking the first x characters of the XHTML, but this would render the XHTML invalid. If someone is searching for the Java code, here it is then: private static DocumentBuilderFactory dbf; static { dbf = DocumentBuilderFactory.newInstance(); dbf.setAttribute("http://apache.org/xml/features/nonvalidating/load-external-dtd", false); } private static XPathFactory xpathf = XPathFactory.newInstance(); private static String xexpr = "//html/body//div[@id='bodyContent']/p[1]"; private static String getPlainSummary(String url) { try { // Open Wikipage URL u = new URL(url); URLConnection uc = u.openConnection(); uc.setRequestProperty("User-Agent", "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.1) Gecko/20090616 Firefox/3.5"); InputStream uio = uc.getInputStream(); InputSource src = new InputSource(uio); // Construct Builder DocumentBuilder builder = dbf.newDocumentBuilder(); Document docXML = builder.parse(src); // Apply XPath XPath xpath = xpathf.newXPath(); XPathExpression xpathe = xpath.compile(xexpr); String s = xpathe.evaluate(docXML); // Return Attribute if (s.length() == 0) { return null; } else { return s; } } catch (IOException ioe) { logger.error("Cant get XML", ioe); return null; } catch (ParserConfigurationException pce) { logger.error("Cant get DocumentBuilder", pce); return null; } catch (SAXException se) { logger.error("Cant parse XML", se); return null; } catch (XPathExpressionException xpee) { logger.error("Cant parse XPATH", xpee); return null; } } Use it by calling getPlainSummary("http://de.wikipedia.org/wiki/Uma_Thurman");
