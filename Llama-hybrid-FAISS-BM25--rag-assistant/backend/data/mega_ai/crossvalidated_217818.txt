[site]: crossvalidated
[post_id]: 217818
[parent_id]: 
[tags]: 
Comparing neuron "jitter" values across trials

I'm asking this question on the statistics forum because I'm wondering a bit about drawing appropriate conclusions supported by statistics from skewed data (if it belongs on another area of stack exchange, I'll be happy to move it there). I'm working with a neuron model and attempting to understand spike timing and reliability across trials. The outline of the model is that I have a neuron whose voltage fluctuations from two sources: input from other neurons which basically increase or decrease the voltage of my neuron of interest as Poisson spikes (i.e. 80% of neurons increase my neuron's voltage and 20% decrease it, but they decrease the voltage by 4x the amount of the ones that increase in order to maintain some balance), and intrinsic noise in the neuron. The goal is to understand how these sources of noise affect the mean time til the first spike (i.e. the voltage of my neuron reaches a certain value) and the trial-to-trial variability of the first spiking times. A paper I'm looking at defines the mean latency (ML) as follows: $$ML = \left = \frac{1}{N}\sum_{i=1}^n t_i$$ where $t_i$ is the first spike time of the $i^{th}$ realization. The "jitter" is defined as follows: $$J = \sqrt{\left - \left ^2}$$ I have my program set up so that I can create a histogram of first spike times, and then I can tell it to give me the mean spike time and the standard deviation of the values. However, the distribution of spike times is heavily skewed so I'm a bit wary of the conclusions I can draw from this (i.e. what parameters have effects on the first spike timing). I classified the simulations into categories: high noise vs low noise and high frequency vs low frequency (frequency refers to the rate at which the neuron receives input from other neurons) The numbers are as follows: High Noise/Low Freq => mean = 22.176, std = 21.127, median = 15.2 High Noise/High Freq => mean = 21.053, std = 20.9007, median = 15.15 Low Noise/Low Freq => mean = 71.4946, std = 78.2021, median = 47.53 Low Noise/High Freq => mean = 67.809, std = 68.659, median = 46.85 I also ran the simulations without any background neurons (so just the neuron of interest + intrinsic noise) and received the following: High Noise => mean = 21.59, std = 20.536, median = 15.4 Low Noise => mean = 72.471, std = 76.597, median = 45.875 I would like to know what conclusions I can reasonably draw about the effects of intrinsic noise and the effects of other neurons providing voltage input into my neuron of interest (and that I'm not inferring anything I shouldn't be). For example, it seems like the higher the intrinsic noise, the smaller the time it takes on average for a neuron to spike. It also seems like the intrinsic noise lowers the trial-to-trial variability (i.e. the jitter), but the skewness of the data makes me wonder how accurate that is since the coefficient of variation is close to $1$ for practically all cases. For example, if the mean in the first case at 20 and the std was 20 whereas in the latter case if the mean were 10,000,000,000 and the std was 80, it has a higher std but clearly the latter is a lot more stable from trial-to-trial. So I'm unsure what I can say about noise affecting jitter, and also what affect intrinsic noise has on the shape of the tail of the distribution. As for the frequency of neural input into my neuron of interest, it looks like the neuron decrease a little bit the time it takes to fire when it receives more and more input, but the time that it drops is quite small relative to changes in the intrinsic noise level. Thus, the data seems to suggest like intrinsic noise is actually an important feature for inducing quick and reliable spike timing, and that input from other neurons can also induce quicker and more reliable spike timing but not by as much as intrinsic noise levels do. This seems quite counterintuitive biologically because I would expect a neuron to fire as a result of spikes received from other neurons. While intrinsic noise can cause neurons to fire spontaneously, I'm surprised to see it doing so in such a well-behaved manner (i.e. low jitter), although as I stated before, I'm not sure if I can reasonably say that. Thus my question is: What conclusions are reasonable to make about the effects of intrinsic noise and firing frequencies on the trial-to-trial variability of first neural spike times based upon the data simulated? (I'm trying to focus more on what simulations are necessary to run to fill in missing pieces of the data rather than run so many simulations that I have a ton of data but only some of it is useful -- e.g. for medium noise, I'd rather focus on a few different frequency levels rather than try it for 30 different ones if the data is going to behave similarly).
