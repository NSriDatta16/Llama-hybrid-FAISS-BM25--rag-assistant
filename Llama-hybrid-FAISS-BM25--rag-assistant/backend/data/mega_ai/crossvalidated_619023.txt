[site]: crossvalidated
[post_id]: 619023
[parent_id]: 
[tags]: 
Why do popular ML and statistical packages simply ignore classical estimation and detection algorithms for statistical signal processing?

For those who had a hard time to study and understand classical estimation and detection algorithms, and unfortunately realized that these algorithms are simply ignored by many packages that have the same focus, e.g., scikit-learn, scipy, Keras/tensorflow, etc... Just to list some of such "classical estimation and detection algorithms": Detection : Minimax Neyman-Peason Generalized likelihood ratio test (GLRT) Estimation : BLUE (Best Linear Unbiased Estimator) Method of moments (MoM) Kalman filtering Such a classic detector as the Neyman Pearson detector cannot be found in any of these packages. Hence, my unique way out is to implement my own codes or, at most, compare my codes with a random low-rated package that is used by almost nobody. On the other hand, algorithms from fields such as statistical machine learning, pattern recognition, and deep learning are readily implemented. For instance, My unique goal is to understand why these methods aren't implemented in popular packages. I wonder whether such methods are worth it, after all.
