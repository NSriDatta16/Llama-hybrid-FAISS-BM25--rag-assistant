[site]: crossvalidated
[post_id]: 606235
[parent_id]: 
[tags]: 
Can this approach be used for machine learning using train-test split?

So let's say I have a dataset with 1000 samples, 20 cols. Regression problem. I use train-test split, say 80-20% I create a Model, lets say Random Forest. I use gridsearchCV to find the best model that gives me highest R^2 for the same. Now, imagine this is a kaggle competition, that gives us a result or a score on a different test set when we submit our predictions. Now, IF I use the same parameters that gridsearchCV gave, but train the model on the entire training data , and use that to test the unseen data, should I get better results? Or should it be the same? My assumption is that, by feeding more data, and having the same parameters, I'll only generalise the model more, which should be good, and will lead to a minute increase or decrease in the kaggle score. Please do give your opinions about it. Thanks!
