[site]: crossvalidated
[post_id]: 477184
[parent_id]: 477148
[tags]: 
First, you need to distinguish between 'association' and 'correlation'. Suppose you have $k$ levels of a factor that represent a categorical variable (parenting style) and test scores that seek to give useful numerical measurements of some aspect of parenting. If a one-way ANOVA using this categorical variable and this numerical variable, gives significant results, then you have significant association between the two variables. Now suppose that the $k$ levels of the factor are numerical values, and the response variable is numerical. (Perhaps the factor involves different amounts of irrigation and the response variable is yield per acre of a crop.) Then it makes sense to find the Pearson correlation between measured amounts of water and crop yields. This sample correlation may be far enough from $0$ to be statistically significant. In your problem, suppose it makes sense to view the $k$ different parenting styles on an ordinal scale. (Maybe different amounts of time spent with a child, different levels of strictness in adhering to family rules, etc.) Then it would make sense to find the Spearman correlation between ordinal style and a numerical test score. (Spearman correlation looks at ranks and ordinal data can be ranked.) In this case of ordinal styles and numerical test scores, you may have a significant result from an ANOVA and also a Spearman correlation significantly different from $0.$ But it is possible for ANOVA to be significant and Spearman correlation not significant, for ANOVA not to be significant and Spearman correlation significant, or neither to be significant. ANOVA and Spearman correlation use different formulas and need not agree as to significance. In particular, an association that is detected by ANOVA need not be detected by Spearman sample correlation $r_S.$ Here are fake data to illustrate ANOVA and Spearman correlation. (Sampling and computations in R.) set.seed(2020) x1 = rnorm(50, 100, 10) x2 = rnorm(50, 105, 10) x3 = rnorm(50, 110, 10) x4 = rnorm(50, 115, 10) x = c(x1,x2,x3,x4) g = rep(1:4, each=50) par(mfrow=c(2,1)) stripchart(x~g, ylim=c(.5,4.5), pch="|") boxplot(x~g, horizontal=T, col="skyblue2") par(mfrow=c(1,1)) The Spearman correlation depends on the order of numbering of the four parenting styles. As numbered first below, test scores tend to increase as styles run from 1 through 4, as seen in the stripcharts and boxplots above. cor(x, g, meth="s") [1] 0.3687901 # Order 1-2-3-4, Higher r.S g2 = rep(c(1,4,3,2), each=50) cor(x, g2, meth="s") [1] 0.07459459 # Order 1-4-3-2, Lower r.S The results of the ANOVA are the same for ANY ordering of the four parenting styles. (ANOVA pays no attention to the order of listing of the $k=4$ levels of the factor variable.) oneway.test(x ~ g) One-way analysis of means (not assuming equal variances) data: x and g F = 11.35, num df = 3.00, denom df = 108.74, p-value = 1.554e-06 oneway.test(x ~ g2)$p.val [1] 1.553761e-06
