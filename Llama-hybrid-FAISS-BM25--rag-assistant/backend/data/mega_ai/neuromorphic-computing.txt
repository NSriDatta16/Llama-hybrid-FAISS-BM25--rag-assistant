Neuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain. A neuromorphic computer/chip is any device that uses physical artificial neurons to do computations. In recent times, the term neuromorphic has been used to describe analog, digital, mixed-mode analog/digital VLSI, and software systems that implement models of neural systems (for perception, motor control, or multisensory integration). Recent advances have even discovered ways to detect sound at different wavelengths through liquid solutions of chemical systems. An article published by AI researchers at Los Alamos National Laboratory states that, "neuromorphic computing, the next generation of AI, will be smaller, faster, and more efficient than the human brain." A key aspect of neuromorphic engineering is understanding how the morphology of individual neurons, circuits, applications, and overall architectures creates desirable computations, affects how information is represented, influences robustness to damage, incorporates learning and development, adapts to local change (plasticity), and facilitates evolutionary change. Neuromorphic engineering is an interdisciplinary subject that takes inspiration from biology, physics, mathematics, computer science, and electronic engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors, and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems. One of the first applications for neuromorphic engineering was proposed by Carver Mead in the late 1980s. Neurological inspiration Neuromorphic engineering is for now set apart by the inspiration it takes from what is known about the structure and operations of the brain. Neuromorphic engineering translates what we know about the brain's function into computer systems. Work has mostly focused on replicating the analog nature of biological computation and the role of neurons in cognition. The biological processes of neurons and their synapses are dauntingly complex, and thus very difficult to artificially simulate. A key feature of biological brains is that all of the processing in neurons uses analog chemical signals. This makes it hard to replicate brains in computers because the current generation of computers is completely digital. However, the characteristics of these chemical signals can be abstracted into mathematical functions that closely capture the essence of the neuron's operations. The goal of neuromorphic computing is not to perfectly mimic the brain and all of its functions, but instead to extract what is known of its structure and operations to be used in a practical computing system. No neuromorphic system will claim nor attempt to reproduce every element of neurons and synapses, but all adhere to the idea that computation is highly distributed throughout a series of small computing elements analogous to a neuron. While this sentiment is standard, researchers chase this goal with different methods. Anatomical neural wiring diagrams that are being imaged by electron microscopy and functional neural connection maps that could be potentially obtained via intracellular recording at scale can be used to better inspire, if not exactly mimicked, neuromorphic computing systems with more details. Implementation The implementation of neuromorphic computing on the hardware level can be realized by oxide-based memristors, spintronic memories, threshold switches, transistors, among others. The implementation details overlap with the concepts of artificial immune systems. Training software-based neuromorphic systems of spiking neural networks can be achieved using error backpropagation, e.g. using Python-based frameworks such as snnTorch, or using canonical learning rules from the biological learning literature, e.g. using BindsNet. Examples As early as 2006, researchers at Georgia Tech published a field programm