[site]: crossvalidated
[post_id]: 605804
[parent_id]: 
[tags]: 
Numerical Stability of Transformer Training

I am trying to train a Transformer for sequence model, specifically for time series denoising. I have observed that the loss function (MSE) has been significantly improved during the evaluation which theoretically has not activated the weight of the model from the very beginning. However, after several epochs (1 or 2) the evaluation can pull the loss into infinity. My question is 1) what happened during the evaluation? I am quite sure I have not called the optimizer.step() and loss.backward(). 2) Is there any method to fix such numerical instability?
