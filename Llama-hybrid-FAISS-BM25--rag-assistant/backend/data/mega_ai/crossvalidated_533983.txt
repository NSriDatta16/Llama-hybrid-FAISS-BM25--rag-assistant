[site]: crossvalidated
[post_id]: 533983
[parent_id]: 
[tags]: 
Is there any reason to use LIME now that shap is available?

The context: explaining a binary classifier XGBoost model. If we say that we are limited to the LIME and Shapley Additive Explanation aka "shap" package, is there any reason to use LIME? My impression is that LIME is a flawed, half-solution to the problem of explaining machine learning models, that may have been "better than nothing" a few years ago, but has now been superseded Lundberg's shap package/methodology. Which addresses the shortcomings of LIME. Can anyone think of reasons to use LIME?
