[site]: crossvalidated
[post_id]: 412048
[parent_id]: 
[tags]: 
Neural network outputs extreme probabilities

I currently have two scenarios that I'm unable to understand: A multi-class neural network classifier: this model's final softmax layer outputs very extreme "probabilities" for each class for the samples - very often just 0 or 1, instead of something less extreme (like say 0.8 or 0.2 or whatever). A multi-label neural network classifier that has much the same problem of outputting extreme 0/1 scores, albeit with a sigmoid last layer. Any idea of what might be going wrong? If this is overfitting -- I'm using quite a bit of dropout too but that didn't help either. How can I remedy this? Thank you!
