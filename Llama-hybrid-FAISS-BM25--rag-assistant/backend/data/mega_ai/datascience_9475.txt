[site]: datascience
[post_id]: 9475
[parent_id]: 8428
[tags]: 
I'm somewhat new to the topic as well, but I think what you are looking for is an autoencoder. I have only used it in the h2o deeplearning package, but it seems to work well. The idea behind an auto-encoder is to begin with your inputs, encode down to less nodes (two is nice for visual representation), then decode back to your original outputs (ass accurately as possible). If the auto-encoder can decode back to an accurate representation of your inputs, then there was sufficient important information withheld in those two nodes. You can then plot the features that those two nodes held in a two-dimensional plot that would be analogous to a bounded PCA plot. Also - the auto-encoder is not constrained to linearity like the PCA is. Below is a quick snippet of some code, hope it helps. library(h2o) localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, min_mem_size = "3g", max_mem_size = "4g", nthreads = -1) dat_h2o
