[site]: crossvalidated
[post_id]: 95820
[parent_id]: 
[tags]: 
How to interpret basis function that yields vector in machine learning algorithm?

I'm struggling to understand what $\phi(x_{N+1})$ is in this excerpt of an algorithm (namely Linear Bayesian Regression embedded in other algorithm): $c_i = \gamma_i / \sum^L_{j} \gamma_j$ $V_i^{N+1} = ((V_i^N)^{-1}+\beta \phi(x_{N+1})^Tc_i \phi(x_{N+1}))^{-1}$ $\theta_i^{N+1} =V_i ^ {N+1} ((V_i^N)^{-1}\theta_i^N+\beta \phi(x_{N+1})^Tc_i r)$ The authors say: "...where $\phi(x_i)$ denotes the feature vector of $x_i$ (...) The choice of $\phi(x)$ depends on the task. In our experiments however, a Gaussian basis function where the center is given by the augmented state $x_i$ proved to be a good choice" I know what a Gaussian basis function is, but how does it yield a vector? I think that users with statistics and machine learning background will probably understand right away what $\phi(x)$ is here, but let me know if you need more context.
