[site]: stackoverflow
[post_id]: 69305
[parent_id]: 69115
[tags]: 
Changing ofs = *pChar >> 4; pszHex[0] = pHex[ofs]; pszHex[1] = pHex[*pChar-(ofs*16)]; to int upper = *pChar >> 4; int lower = *pChar & 0x0f; pszHex[0] = pHex[upper]; pszHex[1] = pHex[lower]; results in roughly 5% speedup. Writing the result two bytes at time as suggested by Robert results in about 18% speedup. The code changes to: _result.resize(_len*2); short* pszHex = (short*) &_result[0]; const unsigned char* pEnd = _pArray + _len; const char* pHex = _hex2asciiU_value; for(const unsigned char* pChar = _pArray; pChar != pEnd; pChar++, ++pszHex ) { *pszHex = bytes_to_chars[*pChar]; } Required initialization: short short_table[256]; for (int i = 0; i > 4]; pc[1] = _hex2asciiU_value[i & 0x0f]; } Doing it 2 bytes at a time or 4 bytes at a time will probably result in even greater speedups, as pointed out by Allan Wind , but then it gets trickier when you have to deal with the odd characters. If you're feeling adventurous, you might try to adapt Duff's device to do this. Results are on an Intel Core Duo 2 processor and gcc -O3 . Always measure that you actually get faster results — a pessimization pretending to be an optimization is less than worthless. Always test that you get the correct results — a bug pretending to be an optimization is downright dangerous. And always keep in mind the tradeoff between speed and readability — life is too short for anyone to maintain unreadable code. ( Obligatory reference to coding for the violent psychopath who knows where you live .)
