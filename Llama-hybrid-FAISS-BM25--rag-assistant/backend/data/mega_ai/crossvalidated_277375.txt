[site]: crossvalidated
[post_id]: 277375
[parent_id]: 
[tags]: 
Machine learning on short time series with multiple observations at one point in time

I have a time series which is short i.e it has only 7 points (7 months) where the data is measured(Margin), it has many multi level categorical attributes and one numerical attribute called Total_Margin. Also, there are multiple measurements for every point per subscriber. I want to use machine learning to train a model on 6 months of data to try and predict the 7th month. I have thought hard about this problem and came up with a technique to sort of deconstruct this time series into one row for every subscriber where all the data for every subscriber is flattened into one row. A simplified version of the flattening for just one subscriber can be seen here: I have some questions regarding the problem I have, I apologise if they appear uneducated but I don't have a background in statistics. What would such a time series be called? (literature) examples forecasting such a time series with or without machine learning in literature? Is my flattening process a valid approach? if yes what would it be called, I think its loosely based on target based encoding but I'm not sure as i was unable to find something on it. I think I introduce collinearity among predictors with my method? would that be accurate.
