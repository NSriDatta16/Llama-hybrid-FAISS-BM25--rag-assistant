[site]: crossvalidated
[post_id]: 189412
[parent_id]: 189384
[tags]: 
It depends. There are a bunch of ways to define the "average" response. The answer here is based on the unweighted average across groups; with this simple, artificial example it doesn't make any difference, but in other cases you might want to take a population-weighted average. n.b. there are several reasons the following is not quite right, although it's not an unreasonable start for consistency, we ought to be taking the mean / combining the standard errors on the linear predictor (link) scale, not the response scale the answer below essentially treats the groups as fixed effects. We know more about the distribution (at least the assumed distribution) of the conditional modes ... but it means there are a lot of possible definitions I will update when I get a chance, but it's still a slightly useful answer Repeating data generation for my convenience ... library("dplyr") ## for data_frame set.seed(0) means = rnorm(5, mean=0, sd=2) df = data_frame(group = as.factor(rep(1:5, each=100)), x = rep(seq(-3,3, length.out =100), 5), y=as.numeric(dnorm(x, mean=means[group]) > 0.4*runif(10))) #Fit model library(mgcv) gam_model = gam(y ~ te(x, group, bs=c("ts", "re")), data=df, family = binomial) gam_avg = gam(y ~ s(x), data=df, family = binomial) Tweak prediction step a tiny bit to retain se in the results (it would be nice to write a broom::augment() method for this case ...) #Predict pfun Generate mean predictions by averaging at each value of x; construct confidence intervals by adding "in quadrature" (i.e. sqrt(sum(x^2)) ) (I don't know why c() is necessary, but it seems to be). sumquad % group_by(x) %>% summarise(response=mean(c(response)), se=sumquad(se)) %>% mutate(lwr=response-2*se,upr=response+2*se) Now visualize: library("ggplot2"); theme_set(theme_bw()) gg1
