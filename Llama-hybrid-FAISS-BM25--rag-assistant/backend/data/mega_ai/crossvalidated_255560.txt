[site]: crossvalidated
[post_id]: 255560
[parent_id]: 255548
[tags]: 
Your independent processes are not correlated! If $X_t$ and $Y_t$ are independent random walks: A correlation coefficient unconditional on time does not exist. (Don't talk about $\operatorname{Corr}(X, Y)$.) For any time $t$, $\operatorname{Corr}(X_t, Y_t)$ is indeed 0. But sample statistics based upon time-series averages will not converge to anything! The sample correlation coefficient you calculated based upon averaging multiple observations over time is meaningless. Intuitively, you might guess (incorrectly) that: Independence between two processes $\{X_t\}$ and $\{Y_t\}$ implies they have zero correlation. (For two random walks, $\operatorname{Corr}(X, Y)$ doesn't exist.) The time series, sample correlation $\hat{\rho}_{XY}$ (i.e. the correlation coefficient calculated using time-series, sample statistics such as $\hat{\mu_X} = \frac{1}{T} \sum_{\tau = 1}^T X_\tau$) will converge on the population correlation coefficient $\rho_{XY}$ as $T \rightarrow \infty$. The problem is that neither of these statements are true for random walks! (They are true for better behaved processes.) For non-stationary processes: You can talk about the correlation between processes $\{X_t\}$ and $\{Y_t\}$ at any two particular points of time (eg. $\operatorname{Corr}(X_2, Y_3)$ is a perfectly sensible statement.) But it doesn't make sense to talk about correlation between the two series unconditional on time! $\operatorname{Corr}(X, Y)$ does not have a well-defined meaning. The problems in the case of a random walk? For a random walk, unconditional population moments (i.e. which don't depend on time $t$), such as $\operatorname{E}[X]$, don't exist. (In some loose sense, they are infinite.) Similarly, the unconditional correlation coefficient $\rho_{XY}$ between two independent random walks isn't zero; it in fact doesn't exist! The assumptions of ergodic theorems don't apply and various time-series averages (eg. $\frac{1}{T} \sum_\tau X_\tau$) don't converge towards anything as $T \rightarrow \infty$. For a stationary sequence, the time series average will eventually converge on the mean that's unconditional on time. But for a non-stationary sequence, there is no mean that's unconditional on time! If you have various observations of two independent random walks over time (eg. $X_1$, $X_2$, etc... and $Y_1$, $Y_2$, ....) and you calculate the sample correlation coefficient, you will get a number between $-1$ and $1$. But it won't be an approximation of the population correlation coefficient (which doesn't exist). Instead, $\hat{\rho}_{XY}(T)$ (calculated using time-series averages from $t=1$ to $t=T$) is going to basically be a random variable (taking values in $[-1, 1]$) which reflects the two particular paths the random walks took by chance (i.e. the paths defined by the draw $\omega$ drawn from sample space $\Omega$.) Speaking extremely loosely (and imprecisely): If both $X_t$ and $Y_t$ happened to wander off in the same direction, you'll detect a spurious positive relationship. If $X_t$ and $Y_t$ wandered off in different directions, you'll detect a spurious negative relationship. If $X_t$ and $Y_t$ happened to wander across each other enough, you'll detect a near zero relationship. You can Google more about this with the terms spurious regression random walk . A random walk isn't stationary and taking averages over time $t$ won't converge on what you would get by taking iid draws $\omega$ from in sample space $\Omega$. As mentioned in the comments above, you can take first differences $\Delta x_t = x_t - x_{t-1}$ and for a random walk, that process $\{\Delta x_t\}$ is stationary. Big picture idea: Multiple observations over time IS NOT the same as multiple draws from a sample space! Recall that a discrete time stochastic process $\{ X_t \}$ is a function of both time ($t \in \mathbb{N}$) and a sample space $\Omega$. For averages over time $t$ to converge towards expectations over a sample space $\Omega$, you need stationarity and ergodicity . This is a core issue in much time-series analysis. And a random-walk isn't a stationary process. Connection to WHuber's answer: If you can take averages across multiple simulations (i.e. take multiple draws from $\Omega$) instead of being forced to take averages across time $t$, a number of your issues disappear. You can of course define $\hat{\rho}_{XY}(t)$ as the sample correlation coefficient computed on $X_1\ldots X_t$ and $Y_1 \ldots Y_t$ and this will also be a stochastic process. You can define some random variable $Z_t$ as: $$Z_t = |\hat{\rho}_{XY}(t)|$$ For two random walks starting at $0$ with $\mathcal{N}(0,1)$ increments, it's easy to find $E[Z_{10000}]$ by simulation (i.e. taking multiple draws from $\Omega$.) Below, I ran a simulation of 10,000 calculations of a sample Pearson correlation coefficient. Each time I: Simulated two 10,000 length random walks (with normally distributed increments draw from $\mathcal{N}(0,1)$). Calculated the sample correlation coefficient between them. Below is a histogram showing the empirical distribution over the 10000 calculated correlation coefficients. You can clearly observe that the random variable $\hat{\rho}_{XY}(10000)$ can be all over the place in the interval $[-1, 1]$. For two fixed paths of $X$ and $Y$, the sample correlation coefficient doesn't converge to anything as the length of the time series increases. On the other hand, for a particular time (eg. $t=10,000$), the sample correlation coefficient is a random variable with a finite mean etc... If I take the absolute value and compute the mean over all the simulations, I calculate approximately .42. I'm not sure why you want to do this or why this is at all meaningful??, but of course you can. Code: for i=1:10000 X = randn(10000,2); Y = cumsum(X); z(i) = corr(Y(:,1), Y(:,2)); end; histogram(z,20); mean(abs(z))
