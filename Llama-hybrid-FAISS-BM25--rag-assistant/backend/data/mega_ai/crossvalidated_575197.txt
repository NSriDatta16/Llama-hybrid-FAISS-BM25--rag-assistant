[site]: crossvalidated
[post_id]: 575197
[parent_id]: 575185
[tags]: 
Don't be surprised that Pearson correlation coefficients aren't greatly affected by log or square-root or square or similar simple monotonic transformations of $X$ in your case. The rank orders aren't affected by the transformation, meaning that non-parametric correlations aren't affected. In terms of the Pearson correlation : $$\rho_{X,Y}=\frac{\operatorname{E}[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X\sigma_Y} $$ when $X$ is transformed and $Y$ isn't, it's a matter of how much the transformation of $X$ moves values above and below the mean in the transformed scale, relative to the corresponding change in $\sigma_X$ . The net effect can be very small. The sample Pearson correlation is biased and not robust , further complicating attempts at intuition in practice. Consider the following bivariate normal data in R; you need to have the mvtnorm package available: set.seed(303) norm2 $y y ## get roughly into reported ranges of values plot(y~x,data=norm2) ## not shown, similar to cloud in the plot from the question, no outlier with(norm2,cor(y,x)) # [1] -0.5559027 with(norm2,cor(y,x^2)) # [1] -0.5400946 with(norm2,cor(y,log(x))) # [1] -0.5426008 with(norm2,cor(y,sqrt(x))) # [1] -0.5546897 If you don't have a solid theoretical reason for a particular transformation, it's often good to let the data suggest the functional form of the relationship by modeling the continuous predictor variable with a regression spline . Also, see the discussion on: Is normality testing 'essentially useless'? I would worry more about the potential high-leverage point noted by @dipetkov, but you need to apply your knowledge of the subject matter.
