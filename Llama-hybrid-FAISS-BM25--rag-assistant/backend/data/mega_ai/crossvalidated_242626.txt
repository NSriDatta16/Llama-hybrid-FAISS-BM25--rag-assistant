[site]: crossvalidated
[post_id]: 242626
[parent_id]: 242615
[tags]: 
This latter case is very common in, for example, logistic regression. In this case, you are correct that the model is the same in either case. It also shows up in linear regression, where the usual loss is $$ \mathit{loss}(w) = \lVert y - (X w + b) \rVert^2 $$ (with $y \in \mathbb R^N$ the vector of labels, $X \in \mathbb R^{N \times d}$ the feature matrix, $w \in \mathbb R^d$ the weights and $b \in \mathbb R$ the offset). Scaling still matters, though: If you're regularizing the loss, e.g. in ridge regression $$ \mathit{loss}(w) = \lVert y - (X w + b) \rVert^2 + \lambda \lVert w \rVert^2 .$$ Here if you change the relative scales of $X$, equally rescaling $w$ will change your loss by changing the $\lVert w \rVert^2$ term. If you're solving with iterative methods like gradient descent, poor feature scaling leads to poor conditioning of the problem, which can make your gradient descent much slower. In interpretation of the model weights $w$. (If your data is standardized, it's fairly reasonable to interpret the features with the largest model weights as the most important; you certainly can't do that if the scales of the features vary widely.)
