[site]: crossvalidated
[post_id]: 162353
[parent_id]: 
[tags]: 
What measure of training error to report for Random Forests?

I'm currently fitting random forests for a classification problem using the randomForest package in R, and am unsure about how to report training error for these models. My training error is close to 0% when I compute it using predictions that I get with the command: predict(model, data=X_train) where X_train is the training data. In an answer to a related question , I read that one should use the out-of-bag (OOB) training error as the training error metric for random forests. This quantity is computed from predictions obtained with the command: predict(model) In this case, the OOB training error is much closer to the mean 10-CV test error, which is 11%. I am wondering: Is it generally accepted to report OOB training error as the training error measure for random forests? Is it true that the traditional measure of training error is artificially low? If the traditional measure of training error is artificially low, then what two measures can I compare to check if the RF is overfitting?
