[site]: datascience
[post_id]: 120944
[parent_id]: 115429
[tags]: 
I don't see FLAN-T5 in the list as well as the other T5 variants, so my guess is that all T5 variants got conflated into T5. Since fine-tuning (eg, FLAN-T5) has become very important in language models, this likely explains T5's recent resurgence according to the plot in the question details.
