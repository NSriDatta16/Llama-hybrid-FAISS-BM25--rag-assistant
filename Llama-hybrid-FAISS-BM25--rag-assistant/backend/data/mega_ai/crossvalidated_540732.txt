[site]: crossvalidated
[post_id]: 540732
[parent_id]: 540522
[tags]: 
1:1 propensity score matching without replacement is not generally unbiased; it works only when there are many more control units than treated units and when there is good overlap between the treatment groups. There are a few things that could possibly be going on here that I'll attempt to address. Let's consider your analysis of the Dropbox CSV file. Starting with nearest neighbor matching on the propensity score: > mod_match summary(mod_match, improvement = FALSE) Call: matchit(formula = Z ~ C1 + C2 + C3 + Cp, data = imf.meta_nomiss, method = "nearest") Summary of Balance for All Data: Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max distance 0.7011 0.2248 1.8304 1.2078 0.3973 0.6309 C1 105.1623 94.4411 0.2145 1.0402 0.0620 0.0961 C2 612.5812 409.4929 1.1874 0.9812 0.2965 0.4356 C3 -200.4626 -200.5272 0.0013 0.9718 0.0063 0.0176 Cp 0.7255 0.3189 0.9112 . 0.4066 0.4066 Summary of Balance for Matched Data: Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max Std. Pair Dist. distance 0.7011 0.2934 1.5668 1.2203 0.3127 0.5714 1.5668 C1 105.1623 98.1299 0.1407 1.0524 0.0411 0.0710 1.1167 C2 612.5812 464.6477 0.8649 1.2906 0.2179 0.3556 1.1090 C3 -200.4626 -200.9724 0.0103 0.9481 0.0093 0.0248 1.1554 Cp 0.7255 0.4006 0.7281 . 0.3249 0.3249 1.0761 Sample Sizes: Control Treated All 3424 2576 Matched 2576 2576 Unmatched 848 0 Discarded 0 0 We can notice a few things here. First, the data are very imbalanced. There are large standardized mean differences and KS statistics (eCDF max) for C2 and Cp. Let's take a look at the distribution of C2 before and after matching: There are areas of non-overlap in the treated distribution, which means nearest neighbor matching without a caliper will fundamentally be unable to achieve balance, yielding bias in the effect estimate. Looking at this plot, there is no hope in accurately estimating the ATT using matching without a caliper. Supplying a caliper (e.g., caliper = .05 ) restricts the analysis to the area of overlap and allows us to achieve balance and accurately recover the treatment effect (the treatment effect seems to be constant so the average treatment effect in the caliper-matched sample is equal to the ATE and ATT, though this is rarely true in real data). > #Caliper matching > mod_match summary(mod_match, un = FALSE) Call: matchit(formula = Z ~ C1 + C2 + C3 + Cp, data = imf.meta_nomiss, method = "nearest", caliper = 0.05) Summary of Balance for Matched Data: Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max Std. Pair Dist. distance 0.4874 0.4785 0.0344 1.0574 0.0065 0.0317 0.0345 C1 100.2388 101.6385 -0.0280 0.9981 0.0076 0.0246 1.1019 C2 521.3383 520.3469 0.0058 1.0987 0.0045 0.0167 0.8306 C3 -200.0333 -201.4824 0.0293 0.9590 0.0112 0.0281 1.1515 Cp 0.5805 0.5558 0.0552 . 0.0246 0.0246 0.8712 Sample Sizes: Control Treated All 3424 2576 Matched 1137 1137 Unmatched 2287 1439 Discarded 0 0 > lm_treat1 lmtest::coeftest(lm_treat1, vcov. = sandwich::vcovCL, cluster = ~subclass) t test of coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -55.8991 1.7003 -32.8756 Why didn't CEM provide the right answer? CEM, like caliper matching, restricts the analysis to an area of common support, so it should recover the effect correctly. You analyzed the matched data incorrectly. The MatchIt vignette on estimating effects explains how to estimate effects after CEM; you must include the weights in the effect estimation. When we do this, we find an estimate with a confidence interval that contains 5, indicating that CEM is successful. > lm_treat1 lmtest::coeftest(lm_treat1, vcov. = sandwich::vcovCL, cluster = ~subclass) t test of coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -62.3837 3.0945 -20.1594 Let's move on to the analysis of the data you simulated with the code in your question. Examining the balance of the covariates before matching, we see that the covariates are mostly balanced except for V1, which has an extreme imbalance. But more important is that the numbers of treated and control units are very close together, with a few more treated units than control units. This is not a situation in which nearest neighbor matching without replacement will succeed. Barely any matching is taking place; the matched sample is almost identical to the unmatched sample. If you instead use matching with replacement (i.e., replace = TRUE ), balance is achieved and the effect estimate is correct. (To keep this answer from getting too long I'll let this be an exercise for the reader.) I think your attempts to analyze these data suffered from a few problems: 1) You applied a blunt instrument instead of using the method most appropriate for the data, 2) You did not assess balance to see if your method was working, and 3) You analyzed the data incorrectly. Matching is a method that requires care and nuance; its strength is that you can tailor the method to incorporate substantive information about the subject matter and build trust in the reader that you have eliminated all bias due to confounding by the measured covariates. In order to realize these benefits, though, you have to do the matching in line with best practices as described in the MatchIt vignettes. It is critical to use the matching method most appropriate for the data at hand (described in the "Matching Methods" MatchIt vignette ), ensure you have achieved balance after matching (described in the "Assessing Balance" MatchIt vignette ), and estimated the effect correctly (described in the "Estimating Effects" MatchIt vignette ). Hopefully taking a closer look at these documents will provide some clarity.
