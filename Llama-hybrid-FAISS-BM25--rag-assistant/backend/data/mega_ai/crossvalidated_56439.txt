[site]: crossvalidated
[post_id]: 56439
[parent_id]: 56435
[tags]: 
There are many ways to approach this problem. One simple and flexible approach is as follows: 1) Come up with a way of computing a coefficient c for each user, such that this coefficient should usually be bigger if your hypothesis is true than if not. For example, you could use c = sum_{feature in {Extrov, Dep, Res}} (how much likes feature)(favorite character has feature - least favorite character has feature). Designing this coefficient is up to you. The important thing is that you expect this coefficient to be big when your hypothesis is true. 2) Then compute the average of this coefficient over your data. 3) The question you now need to answer is: Is the coefficient you got above unusually big? You can do this with a permutation test. Specifically, permute all the answers to the three questions (i.e., for each question individually, reassign all the answers to this question to new people) and then re-compute your coefficient. Do this repeatedly. If the coefficient you got in part (2) is bigger than 97.5 of the coefficients you get by permuting your data, then you may be able to report a significant effect.
