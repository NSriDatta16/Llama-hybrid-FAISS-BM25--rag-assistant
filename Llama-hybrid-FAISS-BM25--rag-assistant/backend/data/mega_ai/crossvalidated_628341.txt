[site]: crossvalidated
[post_id]: 628341
[parent_id]: 
[tags]: 
Quantifying error in derived parameter from approximate solution to Laplace's equation

I am solving the Laplace equation $\nabla^2 u = 0$ on a 2D equispaced grid (spacing $ h $ ) with boundary conditions $ u(x=0) = 1 $ and $ u(x=L) = 0 $ . My solver is approximate, yielding a solution $ u_{\text{approx}} $ with local errors at each grid point. I derive a parameter $ M $ from $ u_{\text{approx}} $ as follows: Take a slice at $ x = x_i $ (yielding $ N $ points in an $ N \times N $ grid), Compute the numerical derivative $ \frac{du}{dx} = \frac{u_{i+1,j} - u_{i,j}}{h} $ for each point in the slice, Sum these derivatives to obtain $ M = \sum_{j=1}^N \left(\frac{du}{dx}\right) $ . I aim to quantify the error in $ M $ when compared to the case with the exact solution $ u_{\text{correct}} $ (yielding $ M_{\text{exact}} $ and $ M_{\text{approx}} $ ). Although the simplified problem suggests a linear profile for $ u $ from $ x=0 $ to $ x=L $ , my actual problem is more complex with a non-trivial domain, making $ u_{\text{correct}} $ unknown. A potential starting point could be the known residual of the PDE, $ \nabla^2 u_{\text{approx}} \neq 0 $ , at each grid point. I seek guidance on how to quantify the error in $M$ , leveraging the PDE residual or any other method that could provide insight into this error. Any suggestions or references to relevant methodologies would be highly appreciated.
