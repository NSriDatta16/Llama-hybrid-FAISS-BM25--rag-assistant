[site]: crossvalidated
[post_id]: 562058
[parent_id]: 
[tags]: 
Random forests confidence intervals and prediction

This is a short simulation to check the coverage, when used as predictive intervals , of the random forest confidence intervals introduced in the paper: S. Wager, T. Hastie and B. Efron. Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife . Journal of Machine Learning Research, 15, pp 1625-1651 (2014) The data is simulated from the process described in Section 4.3 of J. Friedman. Multivariate Adaptive Regression Splines . Annals of Statistics. 19(1), pp 1-67 (1991) There are six independent predictors $X_1,\dots,X_6$ , each of them with $\text{U}[0,1]$ distribution, and an independent random variable $\epsilon$ having a $\text{N}(0,1)$ distribution. The response variable is defined as $$ Y = 10 \sin (\pi X_1 X_2) + 20 (X_3 -1/2)^2 + 10 X_4 + 5 X_5 + \epsilon. $$ friedman We generate a training sample of size 1.000 and a test sample of size 100.000. set.seed(42) n $se Upper se mean((Lower $y) & (test$ y We set a nominal coverage of 95% , but the simulation results in a coverage of approximately 20.2% . The question is about the low effective predictive coverage obtained in this simulation. Notes: We're computing the $1-\alpha$ level confidence intervals as described in their footnote (page 3): $\hat{y}\pm z_\alpha \hat{\sigma}$ . As pointed by usÎµr11852 in the comments below, the effective coverage decreases as we increase the number of trees in the forest. Examples: num.trees = 50 => effective coverage = 0.94855 num.trees = 100 => effective coverage = 0.76876 num.trees = 150 => effective coverage = 0.68959 num.trees = 200 => effective coverage = 0.56038 num.trees = 250 => effective coverage = 0.55393 num.trees = 300 => effective coverage = 0.32304 num.trees = 350 => effective coverage = 0.55413 num.trees = 400 => effective coverage = 0.26372 num.trees = 450 => effective coverage = 0.26232 num.trees = 500 => effective coverage = 0.23139
