[site]: datascience
[post_id]: 23666
[parent_id]: 
[tags]: 
How many features to sample using Random Forests

The Wikipedia page which quotes "The Elements of Statistical Learning" says: Typically, for a classification problem with $p$ features, $\lfloor \sqrt{p}\rfloor$ features are used in each split. I understand that this is a fairly good educated guess and it was probably confirmed by empirical evidence, but are there other reasons why one would pick the square root? Is there a statistical phenomenon happening there? Does this somehow help decrease the variance of the errors? Is this the same for regression and classification?
