[site]: crossvalidated
[post_id]: 143930
[parent_id]: 
[tags]: 
How to calculate Fisher criterion weights?

I am studying pattern recognition and machine learning, and I ran into the following question. Consider a two-class classification problem with equal prior class probability $$P(D_1)=P(D_2)= \frac{1}{2}$$ and the distribution of instances in each classes given by $$ p(x|D_1)= {\cal N} \left( \begin{bmatrix} 0 \\0 \end{bmatrix}, \begin{bmatrix} 2 & 0 \\ 0 & 1 \end{bmatrix} \right),$$ $$ p(x|D_2)= {\cal N} \left( \begin{bmatrix} 4 \\ 4 \end{bmatrix}, \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \right).$$ How to calculate Fisher criterion weights? Update 2: The calculated weight provided by my book is: $W=\begin{bmatrix} \frac{-4}{3} \\ \frac{-2}{9} \end{bmatrix}$. Update 3: As hinted by @xeon, I understand that I should determine the projection line for the Fisherâ€™s discriminant. Update 4: Let $W$ be the direction of the projection line, then the Fisher linear discriminant method finds that the best $W$ is the one for which the criterion function is maximized. The remaining challenge is how can we get numerically $W$ vector?
