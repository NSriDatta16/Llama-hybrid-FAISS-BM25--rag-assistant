[site]: crossvalidated
[post_id]: 85677
[parent_id]: 85572
[tags]: 
Quick Intuitive Solution The best approach is to accept any offer exceeding a threshold $t$ to be determined. The expected value of such offers is $(1+t)/2$ while the expected waiting time before such an offer is seen is $1/(1-t)$ , which is multiplied by the daily cost $c$ . Thus we must find $t$ that maximizes the net $e(t) = (1+t)/2 - c/(1-t).$ The optimum threshold (answering the question) is $$t^{*}(c) = \max\{0, 1-\sqrt{2c}\}$$ with expected net value $$e(t^{*})=t^{*} + (t^{*}-1)^2/2 = \max\{1/2, 1-\sqrt{2c} + c\}$$ which ranges from $1/2$ (when $c\ge 1/2$ ) to $1$ (when $c=0$ ). The strategy depends on $c$ as suggested in the question, but the number of days within which the cost will exceed $1$ (equal approximately to $1/c$ ) is irrelevant to the decision strategy and therefore should play no role in the solution, either. (In the real world, one might conclude after awhile that the advertising is worthless and withdraw the house for sale on that basis--but such considerations are not part of this simplified model.) Rigorous Demonstration When confronted with an offer of $x$ your options are to accept it (which is worth $x$ ) or to wait a day, when (a) you will earn $-c$ and (b) will receive the value of a random offer $X$ with distribution $F$ (which is always uniform). That expected value is independent of whatever happened in the past. Your decision procedure therefore does not vary over time and consequently can be represented as a function $$d:[0,1]\to\{\text{accept}, \text{reject}\}$$ where $d(x)$ stipulates what to do upon receiving offer $x$ . Equivalently, an optimal decision procedure amounts to a decomposition of the possible values of $x$ into two sets, $A = d^{-1}(\text{accept})$ and $R = d^{-1}(\text{reject}),$ where the offer is accepted if and only if $x\in A.$ If we accept an offer $x$ then we would certainly accept any better offer $y\gt x$ , making it clear that every element of $R$ is less than every element of $A$ . Therefore an optimal decision procedure amounts to choosing a threshold $t = \sup(R) = \inf(A)$ once and for all; an offer $x$ is accepted if and only if $x\ge t.$ Because the optimal choice (between acceptance and rejection) is always the one worth more, the value $v(x)$ of an offer $x$ is $x$ if $x\ge t$ and otherwise is the expected value of the sale ( $e$ ) minus the cost of prolonging the sale a day ( $c$ ). Whence, breaking the calculation of the expectation into two disjoint cases according to the decision options, $$e = \mathbb{E}(v(X)) = \mathbb{E}(X | X \ge t)\Pr(X \ge t) + \mathbb{E}(e - c | X \lt t)\Pr(X \lt t).$$ Taking expectations with respect the uniform distribution of $X$ , $$e = (1-t^2)/2 + t(e-c)$$ with unique solution $$e(t) = \frac{1/2 - c t - t^2/2}{1-t}$$ (equalling the value of $(1+t)/2 - c/(1-t)$ found intuitively.) The $t$ in $[0,1]$ which maximizes this expectation $e(t)$ is $t^{*}(c) = 1 - \sqrt{2 c}$ provided $0 \le c \le 1/2$ and otherwise it equals $0$ . In the former case $e^{*} = e(t^{*}) = 1 - \sqrt{2 c} + c$ and in the latter case $e^{*}=1/2$ (because we will pick the first offer we see, which has an expectation of $1/2$ ). The optimal threshold for $c = 0.1$ is $t^{*} = 1 - \sqrt{0.2} \approx 0.553,$ with expected value $e^{*} = 1 - \sqrt{0.2} + 0.1 \approx 0.653.$ This makes sense intuitively: by accepting only offers greater than $0.553$ , we would hope to receive something in the middle of $[0.553, 1]$ on average, or about $0.78$ . We would, however, expect to wait a little more than a day on average before seeing such an offer, thereby costing us a little more than $0.10$ If one pays up front for each day of advertising, $c$ is added to $e^{*}$ but the optimal solution is not changed (except when $c\gt 1$ , in which case it obviously is optimal not to advertise at all). Now $e^{*} = t^{*},$ which is an interesting result: the optimal threshold equals the expected value of the sale.
