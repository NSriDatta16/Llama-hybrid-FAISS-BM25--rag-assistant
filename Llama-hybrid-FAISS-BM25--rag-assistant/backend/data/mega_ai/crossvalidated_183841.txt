[site]: crossvalidated
[post_id]: 183841
[parent_id]: 183204
[tags]: 
As pointed out by @Randel in the comments, the RE-EM tree approach by Sela and Simonoff (2012, Machine Learning , 86 (2), 169-207, doi:10.1007/s10994-011-5258-3 ) and the MERT approach by Hajjem, Bellavance, Larocque (2011, Statistics and Probability Letters , 81 , 451-459, doi:10.1016/j.spl.2010.12.003 ) are rather similar. Both iterate between adjusting for random effects (= correlated observations) and fitting a regression tree like CART. Thus, the result is a regression tree as you get from CART (i.e., with just a predicted constant in each leaf of the tree) but adjusted for a global random effect (e.g., a random intercept for a cluster to adjust for within-cluster correlations). Therefore, the original motivation of these trees (and corresponding forests) is really to obtain regression trees for clustered data. However, they can also be used for regression diagnostics as pointed out by Simonoff (2013, Statistical Modelling , 13 (5-6), 459-480, doi:10.1177/1471082X13494612 ). We recently proposed an extension of RE-EM tree/MERT that can also include more complicated models in each node of the tree (e.g., a treatment effect) and is applicable not only to continuous responses but also binary or cout data ( Fokkema et al., 2015 ).
