[site]: crossvalidated
[post_id]: 614307
[parent_id]: 
[tags]: 
Underestimation of residual variance in a hierarchical model

I'm trying to fit a simple hierarchical model using simulated data. The model is $$y_{ij} \sim N(\mu_i, \sigma^2)$$ $$\mu_i \sim N(\mu, \tau^2)$$ The log joint distribution of parameters and data is: $$\log p(\boldsymbol y, \mu,\tau,\sigma,\boldsymbol \mu) = \sum_{i=1}^m \log f(\mu_i;\mu,\tau) + \sum_{i=1}^m\sum_{j=1}^{n_i} \log f(y_{ij};\mu_i,\sigma)$$ where $f$ is the univariate normal pdf, and I have $m$ groups, with $n_i$ observations from group $i$ . It's my understanding that typically when fitting these kinds of models, you would do it in two stages: integrate out the $\mu_i$ to get the likelihood of the data, maximise it to estimate $\mu, \sigma, \tau$ , then fix them maximise the full log joint, with $\mu, \sigma, \tau$ fixed, to estimate the random effects $\mu_i$ You can also estimate the parameters using MCMC. The thing I'm trying to do is just find the MAP estimate by directly optimising the log joint in one go. I'm finding that the first two approaches agree with each other using simulated data, in the sense that the point estimates I get from the two-stage empirical Bayes approach are practically identical to the posterior modes I get from sampling and the coverage of the confidence intervals I construct using the Fisher information is good and it all matches up with the posterior distributions I get from sampling. If I just maximise the log joint directly, I end up underestimating the residual variance $\sigma^2$ and the CIs I construct for the random effects $\mu_i$ are too narrow. However, the log joint is larger when I optimise everything at once rather than using the two-stage approach, so I don't think it's just that my optimiser is converging to a worse local maximum. I don't understand why this is the case. The parameters found by the optimiser should be the mode of the posterior, and they should be the parameters that maximise the log joint (at least away from the boundary of $\tau=0$ ), right? So how am I finding "wrong" parameters with higher log joint than the posterior mode? EDIT : Another framing of this question is "when and how can MAP estimates differ from the modes of the marginal posteriors I obtain from sampling, assuming both (appear to) have converged, and how does this relate to hierarchical models in particular?"
