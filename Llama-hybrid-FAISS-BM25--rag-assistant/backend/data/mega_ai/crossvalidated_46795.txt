[site]: crossvalidated
[post_id]: 46795
[parent_id]: 46519
[tags]: 
If you show the confidence interval as well as the value of the statistic, then there is no problem with giving as many significant figures as you wish, as in that case a large number of significant figures does not imply spurious precision as the confidence interval gives an indication of the likely actual precision (a credible interval would be better). It is then essentially a matter of making the table neat, concise and readable, so essentially there is unlikely to be a simple rule that suits all occasions. Replicability is important in scientific studies, so ideally it should be possible to reproduce the results to any number of siginifcant figures (whether they are of practical significance or not). Rounding to a small number of significant figures could reduce confidence in a replication of a study as errors could be masked by the rounding of the results, so there is a possible downside to rounding in some circumstances. Another reason not to round too far is that it can make it impossible for others to extend your study without actually repeating it. For instance I might publish a paper that compares various machine learning algorithms using the Friedman test, which depends on the rankings of the different algorithms on a set of benchmark datasets. If the statistics for individual classifiers on each dataset are given to a number of significant figures depending on their standard errors, this will undoubtedly create many apparent ties in the rankings. This means that (i) a reader/reviewer of the paper will be unable to replicate the Friedman test from the results given in the paper and (ii) someone else would then be unable to evaluate their algorithm on the benchmark datasets and use the Friedman test to put it into the context of the results from my study. Generally using sufficient signfiicant figures to avoid introducing spurious ties doesn't cause a problem for the reader.
