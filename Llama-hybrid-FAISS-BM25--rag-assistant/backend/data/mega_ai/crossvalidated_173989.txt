[site]: crossvalidated
[post_id]: 173989
[parent_id]: 
[tags]: 
When to use LDA over GMM for clustering?

I have a dataset containing user activity with 168 dimensions, where I want to extract clusters using unsupervised learning. It is not obvious to me whether to use a topic modelling approach in Latent Dirichlet allocation (LDA) or Gaussian Mixture Models (GMM), which is more of a Bayesian approach. In that regard I have 2 related questions: What is the main differentiator between the two methods? I know the basics of the two models, but I am curious about what really sets one apart from the other. Can something in the problem/data tell me whether one model is a better fit? If I apply both methods to my data, how can I compare the results to see which method is better? Update The 168 users activity variables are counts of an activity, thereby holding positive discrete values. There is no maximum value, but roughly 90% of the variables attain values in the interval $[0,3]$. It might make sense simply model all of these activity variables as binary variables describing whether it is zero or non-zero, but we do not yet know enough about the problem to determine that. The main thing we are looking for are insights into the different clusters of user activity.
