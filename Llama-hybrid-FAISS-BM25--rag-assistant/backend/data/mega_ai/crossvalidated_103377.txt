[site]: crossvalidated
[post_id]: 103377
[parent_id]: 23157
[tags]: 
I work with the text classification problem, and for the classification I am using decision tree classifiers(ID3, Random forests etc). So I can give you an example that is related to text classification. In classification we are going to deal with the different words as the attributes, and you can reduce the features using information gain threshold and once you have all the reduced features with you, it will follow the procedure that I have mentioned below. While building the decision tree, it will start with the attribute having the highest information gain, and now there are more than one words/attributes with the same information gain value. So for text classification, it will check in the alphabetical order. For example: for root node there are two words with highest information gain ("Good" with IG=0.5, and "Awesome" with IG=0.5), "Awesome" will be selected as the root node. Hope this will help to solve the doubt. It will be great if you can download the machine learning package called "Weka" and try out the decision tree classifier with your own dataset. As the beautiful thing is, after the classification process it will allow you to see the decision tree created. ID3, Random Tree and Random forest of Weka uses Information gain for splitting of nodes.
