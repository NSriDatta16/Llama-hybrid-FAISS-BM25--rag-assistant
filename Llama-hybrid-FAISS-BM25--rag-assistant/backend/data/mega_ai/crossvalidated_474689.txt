[site]: crossvalidated
[post_id]: 474689
[parent_id]: 246089
[tags]: 
Predictors, dummy variables, or features are important in predictive modeling as they help capture genuine patterns in a data set and therefore make a better prediction since a model having a certain behavior will likely continue to have a certain behavior. And feature engineering helps capture this behavior. Now for statistical inference based on your definition, you can already assess to an extent the relationship between predictor and response variable using exploratory analysis like scatterplots, correlation plots, correlograms, seasonal plots, lag plots. And further, strengthen your assessment by removing/adding the predictor from the features and evaluating the prediction. So, feature engineering I would say is a crucial step in predictive modeling, and secondary in drawing statistical inference (since there are other methods to assess the relationship between available variables, looking into the historic data)
