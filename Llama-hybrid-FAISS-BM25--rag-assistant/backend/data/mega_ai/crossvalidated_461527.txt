[site]: crossvalidated
[post_id]: 461527
[parent_id]: 
[tags]: 
What would we call a hypothesis test that decreases in power as the sample size increases?

In any given situation there is almost always more than one hypothesis test available. We use characteristics such as uniformly most powerful or locally most powerful, or being unbiased, to distinguish between tests and choose the best one. I've stumbled upon an informal test that enjoys the following characteristic: as the sample size increases, the power decreases and the size increases. It is the so-called direct test used in some expert elicitation settings. An example follows. Ask an expert for estimates and 90% coverage intervals for $n$ parameters of interest, and compare the claimed coverage 0.9 with the actual coverage (say, x/n). If they are identical then the expert is well calibrated. If they are not, then the expert is not well calibrated. So in the case of n = 10 and 90% intervals, the null hypothesis that "the expert is not well calibrated" is rejected when the number of true values occurring within the experts intervals is in the rejection region, namely 9. In the case of n = 100 and 90% intervals, the null hypothesis that "the expert is not well calibrated" is rejected when the random variable which is the number of true values occurring within the experts intervals is in the rejection region, namely 90. Asymptotically, the power is zero and the size is 1. So, all else equal, we prefer to test with a smaller sample size. This seems statistically distasteful to me but I'm unaware of any rules that preclude it from being used in a given situation. Is there a name for such a characteristic? Lacking alternatives I lean towards "asymptotically powerless" but it's not clear that that is sufficient reason to reject it in low-sample settings.
