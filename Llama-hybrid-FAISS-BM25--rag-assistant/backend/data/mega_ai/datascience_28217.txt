[site]: datascience
[post_id]: 28217
[parent_id]: 25336
[tags]: 
I would suggest to have a look at fasttext , it will learn word embeddings for you from your corpus (advantage over word2vec embedding is that it learns representations based on character ngrams, so if a word is there, but its plural is not, it will still have a similar representation) and then in the supervised learning mode it uses something very simple like regression for classification, provided you have examples of labelled data. I tried it with trivial 20newsgroups and it works well for distinct categories. Maybe not a production-friendly solution (it's in c++, but can be stretched to python, albeit not without pain), but can give an idea. Given the nature of the algorithm, it's quick, compared to nets.
