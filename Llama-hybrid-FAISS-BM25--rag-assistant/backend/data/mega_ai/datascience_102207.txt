[site]: datascience
[post_id]: 102207
[parent_id]: 99912
[tags]: 
Combining training and validation data as training data before evaluating test data should be okay. Think of the step that uses validation data as part of the training process, then you will see that it is okay. The purpose is to get an accurate estimate of how the model will perform on unseen data. If you can afford it, a better estimate can be obtained by doing k-fold cross-validation, e.g. for k = 5: Divide all available data into 5 folds (200 images in each) For each fold, do the following: Treat that fold as the test set Split the remaining data (800 images) into training and development/validation data Complete the training process and measure performance on the test set Average the performance across the 5 folds to get a better estimate of performance on unseen data.
