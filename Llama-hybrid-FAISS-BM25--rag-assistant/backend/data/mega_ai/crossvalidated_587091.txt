[site]: crossvalidated
[post_id]: 587091
[parent_id]: 
[tags]: 
negative binomial regression and a coding scheme for non-linear data

I have a count variable nlongfix of number of long eye fixations on stimulus during a trial, which I'm modeling with a difficulty (of the task) variable dims . Because nlongfix is overdispersed, I'm reading that I should use a negative binomial regression. The nlongfix variable is one measure among many others in an experiment, and from regressions of the other (non-count) variables I have a pretty good idea that the responses are generally in line with theory, in that difficulty increases (for simplification, let's say) cognitive processing until a certain threshold, after which cognitive processing decreases notably or levels out, so it doesn't increase anymore with difficulty. For the other variables, I have used the coding scheme 1 from here to test models where the first variable codes the dims to increase linearly until the threshold and stay level after that, and the second variable stays level first and increases afterwards. Long eye fixations are related to cognitive processing as well, so nlongfix should follow this same pattern, and from simply plotting the averages for each difficulty level, it does seem to be the case, but I need statistical evidence. (Note that even though the graph might look like simply linear, very similar graphs with other variables have shown that this coded scheme, with a threshold at dims = 6 or 8, has had a much better fit than simply linear models. But at least it's clear it's not exponential.) A simple negative binomial regression is not suitable, because when I plot the predicted values, they increase exponentially instead of leveling out after the threshold. But I'm hesitating to use the coding scheme, because then both of the piecewise slopes would be exponential individually, which doesn't seem right. I've thought about a regular linear mixed model, but is this ok due to the coding scheme, even if the data is count? I've thought about converting the variable to a percentage of total fixations, but this doesn't change the predicted values from being exponential. I'm completely unfamiliar with non-linear models. The current nb-model in R: > nlongfix_lin_order % glmer.nb(nlongfix ~ dims + trialcount + (dims|ID), data = .) > summary(nlongfix_lin_order) Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod'] Family: Negative Binomial(2.8649) ( log ) Formula: nlongfix ~ dims + trialcount + (dims | ID) Data: . Control: glmerControl(optimizer = "bobyqa") AIC BIC logLik deviance df.resid 30452.8 30499.3 -15219.4 30438.8 5625 Scaled residuals: Min 1Q Median 3Q Max -1.5204 -0.7387 -0.2439 0.4781 11.6452 Random effects: Groups Name Variance Std.Dev. Corr ID (Intercept) 0.312018 0.55859 dims 0.001602 0.04002 0.20 Number of obs: 5632, groups: ID, 47 Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept) 1.4173892 0.0869937 16.29 The model also uses trialcount as a predictor because the experiment had many trials and there is a fatigue effect, and (dims|ID) as random effects due to individual differences. The coding scheme has essentially replaced the dims with (climb + level) term in regressions for non-count variables. Also, I'm interested in what to do about the warning about rescaling, but that's secondary because this is most likely not the model to use. What would be a correct way to deal with this? Is nonlinear modeling the only choice or can I use the coding scheme somehow with a nb-mmodel? If nonlinear is the way to go, can someone give me tips how to proceed?
