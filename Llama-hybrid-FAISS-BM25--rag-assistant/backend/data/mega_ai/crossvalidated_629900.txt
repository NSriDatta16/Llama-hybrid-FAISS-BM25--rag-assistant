[site]: crossvalidated
[post_id]: 629900
[parent_id]: 
[tags]: 
Hypothesis testing - Newbie blockers - Update and more

Brief : I'm from manufacturing industry, a processing machine in our production line used to do pressing, polishing and QA one after the other. Now we have a new machine that will perform these at the same time. Ideally the new machine will produce units in less time than the old machine. I want to prove that time taken by new machine is significantly less than old machine. Null hypothesis - There is no significance difference in time taken by both machines to produce one unit. Alternate hypothesis - Time taken by new machine is less than old machine. Initial Plan : I initially planned on performing bootstrapping to identify the population distribution. Assuming the data was normally distributed from bootstrap, I planned on Two sample t-test, else Mann Whitney U-test. There is also some extreme outliers ~2% in a data of 50K or more records. I thought of removing these outliers completely as they are less than 5%. Questions : My problems are, (1) during research I came across normality test (Shapiro-Wilk) which I though might help to statistically confirm the normality. (2) Then I ran into proportion tests for sample size, which is also being recommended. (3) Then came across (winsorized mean), for replacing outliers with non-outliers. With just a regular (trust me, am not over researching) research, I'm flooded with over information, which is quite confusing. What should be the ideal framework for my use case. What would you all recommend that I do, correct or refer??? I planned on performing all the steps I as per my plan. But, now having second thoughts if that will be correct. Any advice, feedback, corrections will be really helpful. Update: Thank you all so much for inputs. I was able to research and decide the trade-offs. Let me summarize what I've done and require your suggestions and input again for a particular blocker in sample size. Data 1 size = 10 million records Data 2 size = 1 million records population distribution (for both) = log normal distribution: right skewed. It almost looks like needle and a reallllyyyyyy long tail. S.D and variance for both populations are different. Outlier - used IQR method (Q1 - 1.35 * IQR and Q3 + 1.35 * IQR) to trim outliers. Converted data to log 10 and achieved normal distribution performed two sample t-test with n=30 and 5% alpha, rejected the null hypothesis. New blocker: I read two books (Practical statistics for Data scientists by Peter Bruce and Andrew Bruce and Statistics by Robert S Witte and John S Witte) and Data camp course to learn hypothesis test. In all of them, they had always assumed sample size, likewise I just assumed a sample size of 30 and performed the test. Now I ran into (Power analysis) and other tools to calculate the sample size. My doubt is Is it necessary to calculate the sample size? What other essentials like these am I missing out on (I've included every step of my test process above)? Any recommended steps/procedures/tests that you would suggest before I start the hypothesis test?
