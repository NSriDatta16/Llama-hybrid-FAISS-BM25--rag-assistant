[site]: crossvalidated
[post_id]: 4153
[parent_id]: 3911
[tags]: 
I think the premise of this question is flawed because it denies the distinction between the uncertain and the known . Describing a coin flip provides a good analogy. Before the coin is flipped, the outcome is uncertain; afterwards, it is no longer "hypothetical." Confusing this fait accompli with the actual situation we wish to understand (the behavior of the coin, or decisions that are to be made as a result of its outcome) essentially denies a role for probability in understanding the world. This contrast is thrown in sharp relief within an experimental or regulatory arena. In such cases the scientist or the regulator know they will be faced with situations whose outcomes, at any time beforehand, are unknown, yet they must make important determinations such as how to design the experiment or establish the criteria to use in determining compliance with regulations (for drug testing, workplace safety, environmental standards, and so on). These people and the institutions for which they work need methods and knowledge of the probabilistic characteristics of those methods in order to develop optimal and defensible strategies, such as good experimental designs and fair decision procedures that err as little as possible. Confidence intervals, despite their classically poor justification, fit into this decision-theoretic framework. When a method of constructing a random interval has a combination of good properties, such as assuring a minimal expected coverage of the interval and minimizing the expected length of the interval--both of them a priori properties, not a posteriori ones--then over a long career of using that method we can minimize the costs associated with the actions that are indicated by that method.
