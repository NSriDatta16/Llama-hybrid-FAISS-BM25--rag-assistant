[site]: datascience
[post_id]: 60518
[parent_id]: 60487
[tags]: 
There could be a couple of possible reasons: One reason could be the Adam optimizer is a combination of several other optimization techniques (e.g., momentum and running average of gradient squares). The combination of those techniques works well on multi-label text classification. Another reason could be that multi-label text classification is a sparse problem. The Adam optimizer in TensorFlow has a sparse implementation .
