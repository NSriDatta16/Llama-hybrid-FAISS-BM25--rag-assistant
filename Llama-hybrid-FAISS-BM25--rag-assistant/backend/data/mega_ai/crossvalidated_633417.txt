[site]: crossvalidated
[post_id]: 633417
[parent_id]: 
[tags]: 
Evaluating and comparing forecasting methods through errors in multi dimensional time series data

I have a fairly complicated problem and I would like some advice on how to properly assess the results. I have a series of 12 connected 'zones' that have a specific numerical value at any given point in time, either negative or positive. I have some forecasted values for each zone and I have some realised values. The data are discrete time series of hourly resolution, one value per hour and run over a two year period The forecasted values of the zones can change depending on 2 tunable parameters but the realised results always remain the same as I'm working with historical data. Lets say I modify one of the parameters of the algorithm and get some newly forecasted values that effectively give me a different error (difference between the forecasted and the realised values), what would be the best way to compare the new result to the original forecasted values? So far, this is what I have thought of and tried, my issue though, is that I don't know how one would normally make what could be considered a rigorous assessment where many different values are used for the parameters: 1. Compare the zone-wise, absolute difference in errors between the two scenarios, this can be represented as two distributions or directly compared/subtract one value from the other. I thought about making a tally table to count the number of instances when method 1 was better than method 2 and evaluating that way but it has the drawback that the size of the errors is lost 2. Aggregate, average and compare the values over various different resolutions (daily, monthly, yearly etc.) This was just to simplify the amount of data that was being compared, though this would lose some degree of information The most important point to consider though is that there are four scenarios that give, what I would call, two important features that I would like to encode in the result from a single metric if possible. Feature one; the absolute size of the error Feature two; the relative size of the error compared to the value of the zone at a give n time. Example: Scenario 1: lets say for a given zone at a given time we have a value of 1000 and an error of one, its easy to properly assess this error. It is a small error and is a small percentage of the zones value at that point in time and not very significant. Scenario 2: A zone has a small value, lets say 5, and a small error lets say 4, then this is a very large percentage of the value of the zone even though it is what could be considered a small error. Scenario 3: a zone has a large value, 12000 but also a large error of 200, conversley as a percentage of the zones value is is small even though the error is rather large. I also thought about scaling the datasets but then the errors would scale too and not solve the problem of their relative significance. I also though about setting threshholds of what a significant error is and using that as a flag in the results but this brings in a degree of human influence I would rather avoid having. I hope the problem is clear. Does anyone have any good suggestions?
