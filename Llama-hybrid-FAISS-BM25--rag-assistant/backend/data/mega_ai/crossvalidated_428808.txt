[site]: crossvalidated
[post_id]: 428808
[parent_id]: 428663
[tags]: 
Yes, it works perfectly for the case of classification because we use the deviance residuals. Deviance residuals are directly related with the contribution each point has to the overall likelihood score. The deviance residuals are commonly used to check the model fit at each observation for generalized linear models; a gradient boosting machine is no different (see Elements of Statistical Learning, Hastie et al. (2009) Ch. 10.2 " Boosting Fits an Additive Model " for the relation between boosting and additive models). When dealing with a binary classification task, we often assume that we are concerned with a binomial distribution. Because the outcome variable has only two possible types it naturally extends to classification tasks and to binomial (or binary) logistic regression. Basing our boosting procedure to the binomial likelihood and the subsequent residuals allows us to directly move from standard regression tasks to classification tasks; CV.SE as a short but to-the-point exposition on the relation between deviance residuals and binomial (log)-likelihood here .
