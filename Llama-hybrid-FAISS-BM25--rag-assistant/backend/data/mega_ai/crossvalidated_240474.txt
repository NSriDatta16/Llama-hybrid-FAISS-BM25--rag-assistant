[site]: crossvalidated
[post_id]: 240474
[parent_id]: 
[tags]: 
Sequence to Label Model

I have a dataset with me where the input is a sequence and output is just some labels. (No sequence in that) What is the best model to train that kind of dataset..? I was using seq2seq model. But the results were very low. Then I used multi-label svm with (1,7) ngrams. The result were better than seq2seq model. But not very good. Can someone specify a better model..? Thank You!! EDIT 1 Input is actually a set of sequences. When I was using svm , the set was flatten and considered as a one sequence. In seq2seq model, the sequences were separated with a special symbol to identify that it is a different sequence. EDIT 2 Input sequence does not have a finite length. An example is given below. Say I have input vocab: AAA, BBB, CCC, DDD, EEE output vocab: 111, 222, 333, 444 ----Input Sequence----------------------Output (Order does not matter)-- AAA, BBB, DDD 111, 333 AAA, DDD, BBB 222, 333 DDD, BBB, AAA, CCC 111, 444, 222 BBB, DDD, CCC, AAA 333
