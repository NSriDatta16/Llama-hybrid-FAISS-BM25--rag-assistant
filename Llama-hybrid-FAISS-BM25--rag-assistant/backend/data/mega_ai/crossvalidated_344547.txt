[site]: crossvalidated
[post_id]: 344547
[parent_id]: 344544
[tags]: 
If the mean of group B was larger than the mean of group A then a statement that participants in group B performed better on average than participants of group A is naturally correct. However, is the difference in performance likely to reflect an underlying difference in performance ability or just an accident of random sampling? (The samples are random, aren't they?) A relatively large P-value says that the difference is not very extreme relative to the statistical expectations of the model applied. That would be consistent with the accident of random sampling option, but it would also be consistent with the possibility that your sample is small relative to the size needed to expose an effect small relative to the variability. It may also mean that the statistical model is inappropriate. A P-value greater than 0.05 implies that the null hypothesised values of the parameter of interest (presumably zero in this case) lies within a 95% confidence interval. If zero is not within the 90% confidence interval then the P-value must be greater than 0.1. The hypothesis that the effect size is zero must be rejected when the observed P-value is greater than the pre-determined critical value (0.05 or 0.1 for you, but I can't tell which) if you are intent on obtaining the long term false positive error rate implied by that critical value. However, you may well not want that. The type of response to or report of data depends on the analytical and experimental purpose, and you have not told us about them. Now, can a confidence interval be interpreted as you suggest? Not really, but probably well enough for your purposes. See this for the full glory of interpretation of confidence intervals: How to interpret confidence interval of the difference in means in one sample T-test?
