[site]: crossvalidated
[post_id]: 286296
[parent_id]: 285995
[tags]: 
I would say that yes, it depends on the classifier. It's feature engineering and in my opinion the choice of the categorical encoding is kind of like the choice of hyperparameters : you have to cross-validate which one seems to be working the best and with which algorithm. Just so you know, you can use one-hot encoding or label encoding (integer from 1 to 20) but you can also use other encodings, some listed here : https://github.com/scikit-learn-contrib/categorical-encoding Another notable point is that you can also learn a representation of your categorical variable in a higher dimension (not only one number but a vector of d numbers). This is often called "embeddings" and is famously known for words (word2vec) but can be used for any categorical variable. Hope it helps a bit
