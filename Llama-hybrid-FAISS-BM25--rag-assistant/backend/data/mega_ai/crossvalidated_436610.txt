[site]: crossvalidated
[post_id]: 436610
[parent_id]: 300588
[tags]: 
You may be experiencing exploding gradient problem, especially if you're using recurrent neural networks for approximation. If that's the case lowering learning rate, discount factor, or lowering gradients either by gradient clipping or gradient scaling should help.
