[site]: crossvalidated
[post_id]: 429145
[parent_id]: 406586
[tags]: 
You probably have figured this out by now but I'll just add an answer here for completeness (and for anyone else that gets confused) I haven't read the book but it seems to me that you're confusing a modeled environment (is that the official name?) with a model free environment. In a modeled environment, you don't need to explore because you already have the dynamics of the system. In this case you simply apply the algorithm to EVERY state against EVERY action. In your case let's just say you start with the random policy of going left everywhere. it looks like this: s1, s2, s3, s4, s5, s6 5, first workout the value as per policy, let's make gamma 1 because it's way too early in the morning. You get: s1, s2, s3, s4, s5, s6 5, 5, 5, 5, 5, 20 now apply policy improvement, in this iteration the only thing interesting that's gonna happen is at s5. The guy sitting at s5 looks to the left, looks to the right and decides right is better (20 over 5, or.... officially the "max of all actions"), and improves the policy. All other states stays the same for now (they all get 5 at either side). The new policy now becomes: s1, s2, s3, s4, s5, s6 5, , 20 Iteration 2: evaluate value as per policy s1, s2, s3, s4, s5, s6 5, 5, 5, 5, 20, 20 Iteration 2: policy improvement (s4 changes his mind and goes right, everyone else stays the same). New policy now becomes: s1, s2, s3, s4, s5, s6 5, , ->, 20 and so on, until everyone eventually goes to the right.... and policy stabalises. You now drop a guy at s3 and he will go right. In a model freeeeed environment, and pretty much in all real world cases. You don't get the model and you have to just explore. In this case you're right, you need to introduce some kind of exploratiion term, so that the agent will try new options every now and then. In your case the agent only sees a black tunnel to his left, and a black tunnel to his right, he tries left and gets 5. He keeps on going left, and if he's just greedy he'll just go left forever, but if you introduce a chance for him to explore, he'll travel down the right tunnel a few times eventually to see what's going on, and he will figure out the right side is better.
