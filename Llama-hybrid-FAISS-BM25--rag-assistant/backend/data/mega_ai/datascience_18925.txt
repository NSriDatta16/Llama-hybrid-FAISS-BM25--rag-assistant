[site]: datascience
[post_id]: 18925
[parent_id]: 18913
[tags]: 
Typical things to look for when training neural networks: Learning Curve: a plot of the error on the validation set X size of training set. The error must decrease as the network is trained, so if you see fluctuations or an increase something is wrong. Learning Rate: the learning rate influences the convergence of gradient descent. A small learning rate will make the model overfit the data while a big one may make it underfit. Precision: of the classified examples in the training set, how many did the network got right, or more precisely, how many did it classify as expected? Recall: of all the positive examples, in your case the paid ones, how many did it classify as paid ? If you notice the performance of the network is bad you may: Add other features that make the model fit the data better - for example add average family income to the features Get more training examples Some papers suggest deeper networks are able to catch subtleties about the model they are trying to fit, so experimenting with the network architecture is an option.
