[site]: crossvalidated
[post_id]: 16710
[parent_id]: 
[tags]: 
Does standardising independent variables reduce collinearity?

I've come across a very good text on Bayes/MCMC. IT suggests that a standardisation of your independent variables will make an MCMC (Metropolis) algorithm more efficient, but also that it may reduce (multi)collinearity. Can that be true? Is this something I should be doing as standard .(Sorry). Kruschke 2011, Doing Bayesian Data Analysis. (AP) edit: for example > data(longley) > cor.test(longley$Unemployed, longley$Armed.Forces) Pearson's product-moment correlation data: longley$Unemployed and longley$Armed.Forces t = -0.6745, df = 14, p-value = 0.5109 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: -0.6187113 0.3489766 sample estimates: cor -0.1774206 > standardise cor.test(standardise(longley$Unemployed), standardise(longley$Armed.Forces)) Pearson's product-moment correlation data: standardise(longley$Unemployed) and standardise(longley$Armed.Forces) t = -0.6745, df = 14, p-value = 0.5109 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: -0.6187113 0.3489766 sample estimates: cor -0.1774206 This hasn't reduced the correlation or therefore the albeit limited linear dependence of vectors. What's going on? R
