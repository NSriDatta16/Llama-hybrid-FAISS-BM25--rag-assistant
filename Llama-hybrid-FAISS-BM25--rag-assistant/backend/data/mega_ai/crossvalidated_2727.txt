[site]: crossvalidated
[post_id]: 2727
[parent_id]: 2717
[tags]: 
One way to highlight clusters on your distance matrix is by way of Multidimensional scaling . When projecting individuals (here what you call your nodes) in an 2D-space, it provides a comparable solution to PCA. This is unsupervised, so you won't be able to specify a priori the number of clusters, but I think it may help to quickly summarize a given distance or similarity matrix. Here is what you would get with your data: tmp I added a small jittering on the x and y coordinates to allow distinguishing cases. Replace tmp by 1-tmp if you'd prefer working with dissimilarities, but this yields essentially the same picture. However, here is the hierarchical clustering solution, with single agglomeration criteria: plot(hclust(dist(1-tmp), method="single")) You might further refine the selection of clusters based on the dendrogram, or more robust methods, see e.g. this related question: What stop-criteria for agglomerative hierarchical clustering are used in practice?
