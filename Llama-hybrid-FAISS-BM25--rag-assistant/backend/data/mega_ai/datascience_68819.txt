[site]: datascience
[post_id]: 68819
[parent_id]: 60192
[tags]: 
Normalization rescales features to [0,1]. The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. For machine learning, every dataset does not require normalization. It is required only when features have different ranges. For example, consider a data set containing two features, age, and income. Where age ranges from 0–100, while income ranges from 0–100,000 and higher. Income is about 1,000 times larger than age. So, these two features are in very different ranges. When we do further analysis, like multivariate linear regression, for example, the attributed income will intrinsically influence the result more due to its larger value. But this doesn’t necessarily mean it is more important as a predictor. So we normalize the data to bring all the variables to the same range. Normalization is a good technique to use when you do not know the distribution of your data or when you know the distribution is not Gaussian (a bell curve). Normalization is useful when your data has varying scales and the algorithm you are using does not make assumptions about the distribution of your data, such as k-nearest neighbors and artificial neural networks. Regularization is a feature scaling technique that is intended to solve the problem of overfitting. By adding an extra part to the loss function, the parameters in learning algorithms are more likely to converge to smaller values, which can significantly reduce overfitting. Regularization significantly reduces the variance of the model, without substantially increases its bias. One of the major goals during the training of your machine learning model is to avoiding overfitting. The model will have a low accuracy if it is overfitting the dataset. This happens because your model is trying too hard to capture the noise in your training dataset. By noise we mean the data points that don’t really represent the true properties of your data, but rather randomness. Learning such data points, makes your model more flexible, but it does so at the risk of overfitting to model.
