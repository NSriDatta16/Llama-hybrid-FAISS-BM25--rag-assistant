[site]: datascience
[post_id]: 122570
[parent_id]: 
[tags]: 
Reinforcement learning with PPO - tips and tricks

I am trying to use PPO where the agent has to maneuver around an obstacle towards the target while respecting the spatial boundaries. While the agent learns to respect spatial boundaries it never learns to get around the obstacle to the other side and seems to get stuck on some local minima. I have tried the following : mu (mean) output with a given standard deviation decay, mu and variance/covariance outputs (where variance is a nn parameter in torch and in other setting as a network similar to mu). In addition I have also tried beta distribution. The hyperparameters were tuned using Optuna for each architecture. Have tried different reward functions but no avail, What am I missing?
