[site]: crossvalidated
[post_id]: 7103
[parent_id]: 
[tags]: 
Compression theory, practice, for time series with values in a space of distributions (say of a real random variable)

Example of problem: Part of our research team is working on providing operationally wind power forecast. Usually, since there are different time scalse that interest forecast user, a forecast is issued every 15 min (it has even happened that 5 seconds was requirer) for every 15 minutes ahead up to serveral days. Obviously when you contract with a wind farm owner he has many wind farms, can be 10 or even 1000 wind farms depending of who you are working with. It is likelly that this number is going to be bigger in the near future. Now if the forecast user wants not only the point forecast but the forecast of 100 intesreting quantile (i.e. the whole marginal distribution) and if he wants you to store everything in a data base year after year, then you start tinking ..... ok that makes a lot of data. I'm not an international meteorological institute and cannot afford that. Edit (according to @whuber's comment): to make it critical it can be tough of with a 5 second time frame. But anyway this is not meant to be the question, just an example (people coule provide other examples) My question is : is there a compression theory/best practice for time series of distributions (i.e function of time with values in a space of distribution). I agree that you could work quantile by quantile and apply simple compression algorithm dedicated to signals (could be based on wavelet) but I am searhing for something more dedicated. For example if you know everything is well approximated by gaussians, the quantile by quantile approach would be stupid ! Edit (according to @whuber's comment): The question is really how to integrate the temporal dimension in a compression scheme, hence nI don't want to make a choice of a subset of quantiles that would be the same for ALL time. The remark with gaussian is not dedicated to the example, it is an example to illustrate a case when very good compression is required. An other trivial remark (from the theoretical side) would be: imagine you have a very complicated distribution that cannot be summarized with few quantiles and that you observe it for 1000 successive times. It would be sad to store it for each of these times.
