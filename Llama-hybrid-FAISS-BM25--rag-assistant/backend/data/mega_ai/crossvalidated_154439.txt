[site]: crossvalidated
[post_id]: 154439
[parent_id]: 
[tags]: 
General assumptions about functions in machine learning

In the article "A few useful things to know about machine learning" ( ungated pdf ), I found the following quote: In fact, the general assumptions, like smoothness, similar examples have similar classes, limited dependencies, limited complexity, are often enough to do very well, and this is part of the reason why machine learning has been so successful. I understand the assumption that similar examples should be able to have similar classes. I am guessing "limited dependencies" means that the optimization function only depends on a finite number of variables, "limited complexity" means that the problem's complexity is limited, and "smoothness" means the optimization function is smooth in some sense. Are those guesses right? Can someone clarify these for me?
