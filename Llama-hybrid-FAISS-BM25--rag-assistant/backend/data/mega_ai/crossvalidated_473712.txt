[site]: crossvalidated
[post_id]: 473712
[parent_id]: 473710
[tags]: 
I think that's correct. Take a look at section 7.3 The Biasâ€“Variance Decomposition of Elements of Statistical Learning, Eqs. (7.13) and (7.14), which are formulated for ridge regression, but I believe the idea extends to unregularized OLS. In the unconstrained optimization problem, I believe $f(X)$ is the true function, the same one you noted as not necessarily being linear. You can see that the averaged squared bias is decomposed into a model bias and estimation bias term. I believe the estimation bias is zero for OLS if the Gauss-Markov assumptions are satisfied. The model bias is the bias induced by your linear model applied to data from possibly a non-linear function. I think the term "bias" is sometimes ambiguously/loosely used. Consider https://en.wikipedia.org/wiki/Bias_of_an_estimator . The second sentence states "An estimator or decision rule with zero bias is called unbiased." I think "zero bias" here means "zero estimation bias" (Using ESL terminology), but not zero model bias. I'm not 100% sure on this, so hopefully someone more experienced/knowledgeable than I am on this can comment.
