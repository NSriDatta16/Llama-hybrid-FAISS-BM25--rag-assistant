[site]: stackoverflow
[post_id]: 2168657
[parent_id]: 2168603
[tags]: 
DeMorgan's Law allows you to state a string of logical operations in different ways. It applies to logic and set theory, where in set theory you use complement for not, intersection for and, and union for or. DeMorgan's Law allows you to simplify a logical expression, performing an operation that is rather similar to the distributive property of multiplication. So, if you have the following in a C-like language if !(x || y || z) { /* do something */ } It is logically equivalent to: if (!x && !y && !z) It also works like so: if !(x && !y && z) turns into if (!x || y || !z) And you can, of course, go in reverse. The equivalence of these statements is easy to see using something called a truth table. In a truth table, you simply lay out your variables (x, y, z) and list all the combinations of inputs for these variables. You then have columns for each predicate, or logical expression, and you determine for the given inputs, the value of the expression. Any university curriculum for computer science, computer engineering, or electrical engineering will likely drive you bonkers with the number and size of truth tables you must construct. So why learn them? I think the biggest reason in computing is that it can improve readability of larger logical expressions. Some people don't like using logical not ! in front of expressions, as they think it can confuse someone if they miss it. The impact of using DeMorgan's Law on the gate level of chips is useful, however, because certain gate types are faster, cheaper, or you're already using a whole integrated circuit for them so you can reduce the number of chip packages required for the outcome.
