[site]: datascience
[post_id]: 97613
[parent_id]: 
[tags]: 
Training set and test set size

How to correctly approach the generation of a training/test set? I am doing several experiments testing the generalization ability of my neural network model, so my test set is different from my training set in all experiments (for example, in one experiment the structure of sentences is the same between the training set and the test set, but in the training set I use one set of words and in the test set I use another set of words). So my question is: to be able to compare accuracy between experiments, do I have to maintain a similar size of training set/test set between the experiments? Should I only make sure that the size of the training set is always similar or the size of the test set? In one experiment I have a dataset of size 29160 that I generate for training and in other experiments I have bigger datasets that I generate for training (sometimes of size 122472), so should I use the whole dataset in that first experiment and draw a sample of around 30000 examples from other bigger datasets in other experiments to use as a training set?
