[site]: crossvalidated
[post_id]: 550021
[parent_id]: 
[tags]: 
Why would random forest outperform a well tuned gradient boosted regression model?

When comparing CART, rf and gbm in a model with 11 explanatory variables and about 12,000 observations rf outperforms CART (not surprising) AND gbm (surprising). Apart from the difficulty in adequately tuning gbm, are there specific reasons why rf would perform better than gbm?
