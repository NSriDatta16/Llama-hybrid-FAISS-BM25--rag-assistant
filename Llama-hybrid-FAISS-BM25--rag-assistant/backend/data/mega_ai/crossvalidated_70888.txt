[site]: crossvalidated
[post_id]: 70888
[parent_id]: 70820
[tags]: 
A different way to answer your question is the following sequential thinking that I would like to illustrate with a simple example: 1) Whats the null hypothesis related to the question of interest? E.g. in US, the average income is $6000 per month. 2) How can we measure the deviance from the null hypothesis based on available data? First try: $T =$ Average income. The further away from 6000, the less plausible the null hypothesis is and the more we should reject it. 3) Find the distribution of $T$ if the null hypothesis is true. This "null distribution" is the basis for the test decision. In our example, if the sample is large, the Central Limit Theorem tells us that $T$ is approximately normally distributed with mean 6000 and standard deviation $\sigma/\sqrt{n}$, where $\sigma$ is the true standard deviation of the income in US. We know $n$ and $\sigma$ can be estimated by the sample standard deviation $\hat \sigma$. Principally, we could now lean back and use this result to find test decisions. However, because we statisticians are nice, we usually try to modify the test statistic to keep the null distribution free of as much data dependent information as possible. In our simple example, we could use $$ T' = (T-6000)/(\hat \sigma/\sqrt{n}) $$ instead of $T$. This modified test statistic $T'$ is always approximately standard normal if the null hypothesis is true. No matter the sample size, the hypothesised mean and the standard deviation, the test decision is always based on the same critical values (like $\pm 1.96$). This is the famous one-sample Z-test.
