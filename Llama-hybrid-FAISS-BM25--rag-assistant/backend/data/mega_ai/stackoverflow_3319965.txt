[site]: stackoverflow
[post_id]: 3319965
[parent_id]: 3317537
[tags]: 
Asking for the cost of a single malloc is the wrong question. Usual performance degradation factors are: Size of working set (how many bytes you are "touching" within e.g. a second) Memory fragmentation (how long does it take malloc to find a suitable block, and how much will this increase working set size) From my experience, when you have to expect many nodes of that size (>~ 100K...Millions), these things do matter. Custom Allocator Of course, if you can tune your algorithm to use less memory, or less nodes, do so. However, instead of letting the allocation cost concern leak into your solution, isolate it in a custom allocator. The simplest choice for that would be overloading new for your class, this means your solution code is not affected. Which allocator depends a bit on the needs of the algorithm. For frequently allocating and freeing same-sized blocks, a fixed-size pool is the canonical choice. An arena allocator can perform even better if you have many allocations and very few deletes (i.e. you can afford to not release the memory that was freed). However, the deciding factor between the two is usually locality of reference. If there's anything you can do to boost that, you can win big time.
