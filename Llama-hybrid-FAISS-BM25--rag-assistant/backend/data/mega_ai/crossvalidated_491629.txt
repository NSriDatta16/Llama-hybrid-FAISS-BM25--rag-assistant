[site]: crossvalidated
[post_id]: 491629
[parent_id]: 
[tags]: 
Fully connected Recurrent Neural Network: question about full connectivity

Here is the picture of RNN It's said, that hidden layer is fully connected(dash dots). But I don't understand why? For example I don't understand why the one from $a_3$ to $a_1$ exists. I thought information transfers from hidden state $a_{t-1}$ to $a_{t}$ and not other way around. Maybe I am confused by terminology. Can you explain me?
