[site]: stackoverflow
[post_id]: 1651178
[parent_id]: 1650721
[tags]: 
A good way to reduce scalability of your data tier is to interact with it on a procedural basis. (Fetch row..process... update a row, repeat) This can be done within a stored procedure by use of cursors or within an application (fetch a row, process, update a row) .. The result (poor performance) is the same. When people say they want to do processing in their application it sometimes implies a procedural interaction. Sometimes its necessary to treat data procedurally however from my experience developers with limited database experience will tend to design systems in a way that do not leverage the strenght of the platform because they are not comfortable thinking in terms of set based solutions. This can lead to severe performance issues. For example to add 1 to a count field of all rows in a table the following is all thats needed: UPDATE table SET cnt = cnt + 1 The procedural treatment of the same is likely to be orders of magnitude slower in execution and developers can easily overlook concurrency issues that make their process inconsistant. For example this kind of code is inconsistant given the avaliable read isolation levels of many RDMBS platforms. SELECT id,cnt FROM table ... foreach row ... UPDATE table SET cnt = row.cnt+1 WHERE id=row.id ... I think just in terms of abstraction and ease of servicing a running environment utilizing stored procedures can be a useful tool. Procedure plan cache and reduced number of network round trips in high latency environments can also have significant performance advantages. It is also true that trying to be too clever or work very complex problems in the RDBMS's half-baked procedural language can easily become a recipe for disaster.
