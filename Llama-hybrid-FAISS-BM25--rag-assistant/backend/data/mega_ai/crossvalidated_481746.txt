[site]: crossvalidated
[post_id]: 481746
[parent_id]: 
[tags]: 
is this graph of loss function or input data distribution?

I have been looking at the Batch normalization and got confused. https://www.google.com/search?q=how+to+draw+non+convex+optimization+loss+function+in+graph&newwindow=1&tbm=isch&source=iu&ictx=1&fir=p9jTQ-nE7iJyfM%252CVwHlY7V21gHQFM%252C_&vet=1&usg=AI4_-kQQK_-BeVyvG8Co4iKdUS4oB9rzxQ&sa=X&ved=2ahUKEwjApZaGjIbrAhVkFqYKHf-aCUAQ9QEwAnoECAoQBQ&biw=2077&bih=1065#imgrc=En2uJKnp9l7i7M I saw the this kind of non convex or convex graph when you learning the deep learning. then 1. is this graph of loss function? 2.How they graph this because we do not know the entire loss function graph. 3. is normalizing change the graph of loss function? 4. for batch normalization. is it same thing as normalizing the input data. between deep learning layers? then it also change the loss function graph?
