[site]: crossvalidated
[post_id]: 551046
[parent_id]: 
[tags]: 
L1 regularization for feature selection in neural net

In statistics, a lasso regression do some feature selection (or reduce the dimensionality of the problem). This is a very efficient technique as both the prediction and the feature selection use the same loss function. It is a "one step" optimization (as opposed to "two steps" where a preselection is done using a feature selection technique and a prediction is done then). I would like to apply to NN a similar idea to lasso, if my first layer contains activation functions with L1 regularizations, I should be able to look at the weights and select the features that are the most relevant. The general idea is to reduce the size of my input in production, if I train with 5000 features, I would like to use only the most relevant (max 50 features) in production (and achieve this selection using my neural network as it is linked to my prediction). Any thought? Or recommendations on how to achieve this?
