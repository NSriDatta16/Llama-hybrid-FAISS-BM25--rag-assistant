[site]: crossvalidated
[post_id]: 31038
[parent_id]: 31036
[tags]: 
Consistency of an estimator means that as the sample size gets large the estimate gets closer and closer to the true value of the parameter. Unbiasedness is a finite sample property that is not affected by increasing sample size. An estimate is unbiased if its expected value equals the true parameter value. This will be true for all sample sizes and is exact whereas consistency is asymptotic and only is approximately equal and not exact. To say that an estimator is unbiased means that if you took many samples of size $n$ and computed the estimate each time the average of all these estimates would be close to the true parameter value and will get closer as the number of times you do this increases. The sample mean is both consistent and unbiased. The sample estimate of standard deviation is biased but consistent. Update following the discussion in the comments with @cardinal and @Macro: As described below there are apparently pathological cases where the variance does not have to go to 0 for the estimator to be strongly consistent and the bias doesn't even have to go to 0 either.
