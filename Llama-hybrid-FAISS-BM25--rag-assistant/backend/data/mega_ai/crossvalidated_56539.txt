[site]: crossvalidated
[post_id]: 56539
[parent_id]: 56525
[tags]: 
Sometimes the maximum likelihood estimate for a variance component is zero. Or more generally, sometimes a given algorithm for getting approximate MLEs will return zero. This happens when, for example, your fixed effects happen to be able to fit all the members of a group perfectly, and no variance is left over. This is mainly an issue when the sample size is small relative to the number of groups. Doug Bates, the author of the lme4 package, discusses this on page 11 of his book/manual on R-Forge . He calls it a "degenerate" model, and says it's equivalent to if you didn't include that random effect at all. The model is still valid, but you may have reasons not to trust its estimates, as discussed below. Andrew Gelman and a bunch of collaborators discuss the issue in more depth here . They think that pure maximum likelihood's tendency to return zeros in this case can cause a number of problems (discussed on page 2). They suggest weakly bumping the expected variance of the random effects up slightly to make it return nonzero estimates. These adjusted estimates can be more stable, and may be more consistent with a researcher's prior knowledge about the problem. This approach will also tend to give better standard errors. While the approach they suggest is Bayesian, they show that it has good frequency properties as well. One of the authors, Vincent Dorie, has an R package that extends lme4 using their suggested method here .
