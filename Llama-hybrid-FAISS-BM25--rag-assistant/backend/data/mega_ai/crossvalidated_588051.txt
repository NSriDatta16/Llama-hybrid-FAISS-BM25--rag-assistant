[site]: crossvalidated
[post_id]: 588051
[parent_id]: 587900
[tags]: 
A full specification of the prior would require to also specify prior probabilities for the models. Let's say we have only ${\cal M}_\text{fair}$ and ${\cal M}_\text{loaded}$ . Let's further say you assign a prior probability of $\frac{1}{2}$ to both of these, and a uniform over ${\cal M}_\text{loaded}$ . What this means is that a priori you expect there is a very substantial probability (0.5) that the coin is exactly fair, whereas you assign a very low probability to $\theta$ being, say, between 0.45 and 0.55 (namely $0.5·0.1=0.05$ ). This means that as long as your number of tosses is rather low, an observed relative frequency close to 0.5 will confirm the possibility that the true value is exactly 0.5, rather than favouring a model that allows it between 0.45 and 0.55 with nonzero but small probability, even if in fact the observed relative frequency is something like 0.47. If the true probability is 0.47, for a low number of observations, Bayes (with choices as indicated) may favour ${\cal M}_\text{fair}$ over ${\cal M}_\text{loaded}$ for this reason, however if the number of observations is large enough, also Bayes will at some point see that the observed relative frequency is so incompatible with ${\cal M}_\text{fair}$ that it'll start favouring ${\cal M}_\text{loaded}$ . This is all as it should be, if you realise that your prior assignment gave $\theta=0.5$ a strong advantage over " $\theta\neq 0.5$ but close". If this is backed up by reliable prior knowledge, fair enough. If you just choose your priors for the two models as ½ each because you don't know better, well this is what you get. You're free to change your prior assignments; you don't have to give ½ to ${\cal M}_\text{fair}$ , and neither do you have to choose the prior as uniform within ${\cal M}_\text{loaded}$ . In a realistic situation in which you think there's a large probability for $\theta=0.5$ , usually you would also expect $\theta$ rather close to 0.5 in case of ${\cal M}_\text{loaded}$ , and your prior within ${\cal M}_\text{loaded}$ should reflect that, with the effect that Bayes can already see that $\theta$ may not be equal to 0.5 but still close at a lower sample size. The effect that $\theta=0.5$ gets a strong advantage may be seen as implicit penalty for the more complex model, and as such may be seen as welcome. However it isn't really clear on which grounds then the prior for ${\cal M}_\text{fair}$ should be chosen as 0.5 rather than 0.3, or 0.6, or whatever. All these imply some kind of penalty, but there isn't really a rationale apart from understanding the underlying situation that could tell you what exactly the penalty should be. Furthermore it may be argued that this is an "un-Bayesian" consideration, as it is often not about what you believe the truth is or even how to predict future observations (which is what according to standard Bayesian philosophy the prior should be about), but rather it favours simpler models because it supposedly would be nice to have a simpler model (and people are scared of "overfitting"), so if the true $\theta$ is 0.508, you may be happy to select a model that has it at 0.5, even though a true Bayesian should not be happy about this. Regarding comparing ${\cal M}_\text{mildly loaded}$ with ${\cal M}_\text{loaded}$ , I think this is not a well defined model selection problem, as both can be true at the same time with positive probability ( ${\cal M}_\text{loaded}$ gives probability 0 to ${\cal M}_\text{fair}$ being true, so arguably these two won't be true at the same time). Any assignment of prior probabilities within ${\cal M}_\text{mildly loaded}$ and ${\cal M}_\text{loaded}$ plus probabilities for these two models can be emulated by a suitably chosen prior within ${\cal M}_\text{loaded}$ alone, without even introducing ${\cal M}_\text{mildly loaded}$ , which means that "the probability of ${\cal M}_\text{mildly loaded}$ being true as opposed to ${\cal M}_\text{loaded}$ " is not identifiable and not meaningful. (A valid probability model is defined in this way, fair enough, so it is not forbidden to start like this, but if you look at quantities like the posterior probability of ${\cal M}_\text{loaded}$ , this won't have an interpretation that is useful for model selection). So I wouldn't introduce ${\cal M}_\text{mildly loaded}$ in the first place, but rather handle all $\theta\neq \frac{1}{2}$ by suitable prior choice within ${\cal M}_\text{loaded}$ , which gives you a posterior that can be interpreted in a straightforward manner. The same thing can of course be said regarding $ {\cal M}_\text{head-loaded}$ etc. PS: I can imagine a situation in which the introduction of both ${\cal M}_\text{loaded}$ and ${\cal M}_\text{mildly loaded}$ and probabilities for both of them are meaningful, which is if you have information that there are two possibilities how your coin might have been constructed (maybe you want to guess which company did it), and for one you know that it operates according to ${\cal M}_\text{loaded}$ , the other one according to ${\cal M}_\text{mildly loaded}$ . You also then need to assume the priors within both of these. This will give you a well defined posterior probability for the source of your coin. This, however, is not a typical situation in model selection. In model selection, there is only $\theta$ , and ${\cal M}_\text{loaded}$ and ${\cal M}_\text{mildly loaded}$ are just thought constructs. This particularly means that even if you knew that the true $\theta=0.4$ , you do not know whether this was generated from ${\cal M}_\text{loaded}$ or ${\cal M}_\text{mildly loaded}$ , and the data do not contain information that could help to distinguish these (all information to distinguish these comes from the prior choices). This is what I mean by stating above that posterior probabilities for these are not identifiable and not meaningful.
