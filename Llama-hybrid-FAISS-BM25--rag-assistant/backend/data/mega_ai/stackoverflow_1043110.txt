[site]: stackoverflow
[post_id]: 1043110
[parent_id]: 1041585
[tags]: 
Since you care most about run length, you could generate random run lengths instead of random bits, so as to give them the exact distribution you want. The mean run length in random binary data is of course 4 (sum of n/(2^(n-1))), and the mode average 1. Here are some random bits (I swear this is a single run, I didn't pick a value to make my point): 0111111011111110110001000101111001100000000111001010101101001000 See there's a run length of 8 in there. This is not especially surprising, since run length 8 should occur roughly every 256 bits and I've generated 64 bits. If this doesn't "look random" to you because of excessive run lengths, then generate run lengths with whatever distribution you want. In pseudocode: loop get a random number output that many 1 bits get a random number output that many 0 bits endloop You'd probably want to discard some initial data from the stream, or randomise the first bit, to avoid the problem that as it stands, the first bit is always 1. The probability of the Nth bit being 1 depends on how you "get a random number", but for anything that achieves "shortish but not too short" run lengths it will soon be as close to 50% as makes no difference. For instance "get a random number" might do this: get a uniformly-distributed random number n from 1 to 81 if n is between 1 and 54, return 1 if n is between 55 and 72, return 2 if n is between 72 and 78, return 3 if n is between 79 and 80, return 4 return 5 The idea is that the probability of a run of length N is one third the probability of a run of length N-1, instead of one half. This will give much shorter average run lengths, and a longest run of 5, and would therefore "look more random" to you. Of course it would not "look random" to anyone used to dealing with sequences of coin tosses, because they'd think the runs were too short. You'd also be able to tell very easily with statistical tests that the value of digit N is correlated with the value of digit N-1. This code uses at least log(81) = 6.34 "random bits" to generate on average 1.44 bits of output, so is slower than just generating uniformly-distributed bits. But it shouldn't be much more than about 7/1.44 = 5 times slower, and a LFSR is pretty fast to start with.
