[site]: crossvalidated
[post_id]: 129935
[parent_id]: 
[tags]: 
Generating text data for training for doing named entity recognition and extraction

I'm trying to build an algorithm for doing named entity extraction. It goes like this. There is a large set of text documents [communications], from which specific information has to be extracted. The information to be extracted is date, process names, terms like price, percentages, organization names, etc. It looks like standard nlp problem. But one problem is documents can vary in size and format. It can range from one line to text plus tables or couple of paragraphs with other discussions. My idea is that, if I build a multi-label classifier, with large enough data set, and classify documents, where each class represents particular type of document, for each type of which, there will be specific named entity and information extraction codes. In the situation I'm right now, it's not possible for me to gain access to real data. I've only a few samples documents. My question is this - Is my approach okay? Currently, I'm using python+nltk library. To train classifier, as I don't have large data set, I'm thinking of generating test data, by writing random text generator, based on the sample emails I have. If I do like this, won't I be fooling my classifier? Is there a fundamental problem with this approach? What should I do, as I don't have access to real data? Any pointers will be helpful. Thank you!!
