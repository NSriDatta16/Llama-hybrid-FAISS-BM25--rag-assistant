[site]: crossvalidated
[post_id]: 297990
[parent_id]: 
[tags]: 
Applying the Shapiro Wilk test to a large number of numeric variables to test for normality

I am working with data from a cellular network and I have 5000+ variables (cells in the network) and for each of these variables I have measurements of noise levels. Each variable has 175 samples and the data is continuous in nature but has been sampled every 15 mins. This is my dataset, 175 x 5000+ values all measuring the same metric, noise levels in dBm. Since this data is timeseries data, I was looking at the Hurst exponent to explain the long term memory for each of the variables (5000+). I then plotted the distribution of the H values and the graph in green is the outcome. As you can see below the distribution of H values is approximately normal. It has been suggested to me in conversation that since the Hurst exponent is approximately normally distributed then the underlying data is also normally distributed. But I know from working with the data that for each variable the distribution is right skewed rather than normally distributed. I would like to either prove or disprove this statement and I am looking for a procedure to test this. I came across this paper where the authors had randomly generated a couple of hundred time series and the Hurst distribution of these couple of Hundred time series were also normally distributed. So I guess I wanted to disprove the belief that the underlying data was also normal. I hope what I am trying to do is a bit clearer.
