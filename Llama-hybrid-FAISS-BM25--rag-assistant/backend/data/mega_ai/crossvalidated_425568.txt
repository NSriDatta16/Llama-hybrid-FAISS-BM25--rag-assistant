[site]: crossvalidated
[post_id]: 425568
[parent_id]: 
[tags]: 
Weird sample variance when creating a lognromal sample with pre-defined mean and variance

I have been working with lognormal distributions as a proposal distribution for some MCMC routines which require the proposal distribution to have some pre-defined sample mean and variance, $m$ and $v$ , respectively. Considering that I'm using scipy.stat.lognorm to generate a sample from the proposal distribution, I have to define $\mu$ and $\sigma^2$ , parameters of the underlying normal distribution. I've determined $\mu$ and $\sigma^2$ using the relation: \begin{equation} \mu=\ln\left(\frac{m}{\sqrt{1+\frac{v}{m^2}}}\right), \qquad \sigma^2=\ln\left(1+\frac{v}{m^2}\right) \end{equation} This have worked fine when $m \geq 1$ , however when $m the variance of the generated sample becomes smaller than it was supposed to be ( $v$ ) and I am not sure why. As an example, running the code bellow def get_underlying_normal_params(m, v): m2 = m * m nrm_mean = np.log(m2 / np.sqrt(v + m2)) nrm_var = np.log((v + m2) / m2) return nrm_mean, nrm_var lognrm_mean = 1e-5 lognrm_var = 10 norm_mean, norm_var = get_underlying_normal_params(lognrm_mean, \ lognrm_var) sample = [lognorm.rvs(scale=np.exp(norm_mean), s=np.sqrt(norm_var)) \ for _ in range(50000)] print("Sample mean: ", statistics.mean(sample)) print("Sample variance: ", statistics.variance(sample)) the produced output is: Sample mean: 1.3404377964314877e-06 Sample variance: 5.009857166696648e-09 We can see then, that the created sample has variance ~5e-9, far from the desired variance, 10. If however, I run the same code setting lognrm_mean = 1 , the output is: Sample mean: 1.0077730236251317 Sample variance: 9.250922743416222 And now the sample variance is actually close to the desired variance. Why was I able to pre-determine the variance of the sample on the second case but not on the first case? Am I doing something conceptually wrong? Edit explaining why this is not a duplicate of this other question : in my question I ask if there is something wrong in the procedure I used to create a lognormal with a pre-determined sample mean and variance. There could be a conceptual problem that I am missing or even a procedural problem, concerning for instance floating point erors; I am specifically interested in the behaviour of the sample variance. The other question asks the relation between parameters of a lognormal distribution (associated to an underlying normal distribution) and its mean and variance. Of course this relates to this question, however that is not the question I am asking and, moreover, I have given "formulas" for this relation in my question.
