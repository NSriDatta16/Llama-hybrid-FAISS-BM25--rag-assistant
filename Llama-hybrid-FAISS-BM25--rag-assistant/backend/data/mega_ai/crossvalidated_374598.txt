[site]: crossvalidated
[post_id]: 374598
[parent_id]: 
[tags]: 
Can some one explain me what is difference between Markov process and Markov Decision Process

Markov Process : A stochastic process has Markov property if conditional probability distribution of future states of process depends only upon present state and not on the sequence of events that preceded. Markov Decision Process: A Markov decision process (MDP) is a discrete time stochastic control process. It provides a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker. Asper my understanding Markov Decision Process is just a framework for Markov Process or there is something else I am missing. One more question is it says it as Stochastic control process meaning it is not completely random and Markov Process is completely random . Can someone help me with this
