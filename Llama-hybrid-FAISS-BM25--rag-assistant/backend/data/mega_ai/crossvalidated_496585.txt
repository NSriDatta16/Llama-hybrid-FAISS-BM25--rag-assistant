[site]: crossvalidated
[post_id]: 496585
[parent_id]: 496539
[tags]: 
adding more variables to a linear model doesn't imply better estimates of the true parameters This is not just estimating variables, but also variable selection. When you only subselect That is why the error decreases when you are choosing a larger size for the subset. Because more coefficients, which are likely coefficients from the true model, are being estimated (instead of left equal to zero). The decrease of the error goes a bit further than $k=10$ because of the high correlation between the variables. The strongest improvement happens before k=10. But with $k=10$ you are not there yet, and you are gonna select occasionally the wrong coefficients from the true model. In addition, the additional variables may have some regularizing effect . Note that after some point, around $k=16$ , the error goes up when adding more variables. Reproduction of the graph In the R-code at the end I am trying to reproduce the graph for the forward stepwise case. (this is also the question here: Recreating figure from Elements of Statistical Learning ) I can make the figure look similar But, I needed to make some adjustment to the generation, using $\beta \sim N(1,0.4)$ instead of $\beta \sim N(0,0.4)$ (and still I do not get the same as the figure which starts at 0.95 and drops down to 0.65, while the MSE computed with the code here is much lower instead). Still, the shape is qualitatively the same. The error in this graph is not so much due to bias: I wanted to split the mean square error into bias and variance (by computing the coefficient's mean error and variance of the error). However, the bias is very low! This is due to the high correlation between the parameters. When you have a subset with only 1 parameter, then the selected parameter in that subset will compensate for the missing parameters (it can do so because it is highly correlated). The amount that the other parameters are too low will be more or less the amount that the selected parameter will be too high. So on average a parameter will be more or less as much too high as too low. The graph above is made with a correlation 0.15 instead of 0.85. In addition, I used a fixed $X$ and $\beta$ (Otherwise the bias would average to zero, more explained about that further). Distribution of the error of the parameter estimate Below you see how the error in the parameter estimate $\hat\beta_1- \beta_1$ is distributed as a function of the subset size. This makes it easier to see why the change in the mean square error behaves like it does. Note the following features There is a single peak for small subset sizes. This is because the parameter is often not included in the subset and the estimate $\hat\beta$ will be zero making the error $\hat\beta - \beta$ equal to $-\beta$ . This peak decreases in size as the subset size increases and the probability for the parameter to be included increases. There is a more or less Gaussian distributed component that increases in size when the single peak decreases in size. This is the error when the parameter is included in the subset. For small subset sizes the error in this component is not centered around zero. The reason is that the parameter needs to compensate for the ommission of the other parameter (to which it is highly correlated). This makes that a computation of the bias is actually very low. It is the variance that is high. The example above is for fixed $\beta$ and $X$ . If you would change the $\beta$ for each simulation then the bias would be every time different. If you then compute the bias as $\mathbb{E}(\hat \beta - \beta)$ then you get very close to zero. library(MASS) ### function to do stepforward regression ### adding variables with best increase in RSS stepforward $coefficients[-1] } else { coef[step_order[1:l]] coefficients[] } error[l,]
