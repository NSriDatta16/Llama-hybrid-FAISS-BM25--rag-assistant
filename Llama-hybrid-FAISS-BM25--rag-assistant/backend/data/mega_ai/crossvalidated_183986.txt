[site]: crossvalidated
[post_id]: 183986
[parent_id]: 
[tags]: 
Derivation of OLS Variance

I stumbled over a rather simple result of OLS regression which is $$ Var[\hat\beta] = \sigma^2(X^TX)^{-1} $$ where $\sigma$ is the variance of the error term $u$ and $X$ is the regressor matrix. I first just accepted the proof in my textbook but now I am thinking that it either uses sloppy notation or I am missing something. $\hat\beta$ is the estimated and $\beta$ is the true parameter (assuming unbiasedness). It states that \begin{align} Var[\hat\beta] &= E[(\hat\beta - \beta)(\hat\beta-\beta)^T] \\ &= E[(X^TX)^{-1}X^Tuu^TX(X^TX)^{-1}] \\ &= (X^TX)^{-1}X^T E[uu^T] X(X^TX)^{-1} \end{align} but $X$ was only assumed to be exogenous and not non-stochastic. Under this assumption I think $X$ cannot be dragged outside the expectation operator. Momentarily, I think that it should be $Var[\hat\beta|X]$ to make sense. Is that the case? My web research couldn't clarify this. I only found similar derivations to the above without further explainations.
