[site]: crossvalidated
[post_id]: 479791
[parent_id]: 479781
[tags]: 
We are not simply using the hypothesis from linear regression. And we plug it into the sigmoid function to convert into a new hypothesis for a couple of reasons! Before we start we must know that the Logistic Regression Model is applied to Classification Problems. Classification can be of two types: (1) Binary- (1 or 0), (True or False), (Yes or No) etc. (2) Multiclass- (1, 2, 3 or 4) etc. Ans:- Now we substitute this hypothesis into the sigmoid function because: Logistic Regression Model wants 0 This is where Probability comes into the picture. The Hypothesis hθ(x) = P(y=1|x;θ) Here hθ(x) = estimated probability that y=1 on input x. That is the sigmoid function directly provides us with this probability, as it has a range of [0,1] just like probability has [0,1] in mathematics. The reason why we don't use Linear Regression for Classification: For example- We want to predict a tumour is Malignant or Benign using one feature-x: Tumor size and we want to predict y: Malignant(1) or Benign(0). We can threshold the classifier output of hθ(x) at 0.5 as follows: If hθ(x) >= 0.5, predict 'y=1' If hθ(x) But if we apply this same technique with more training data: it may predict wrong. it may predict y>1 or y
