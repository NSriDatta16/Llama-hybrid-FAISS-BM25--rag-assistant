[site]: crossvalidated
[post_id]: 552044
[parent_id]: 
[tags]: 
How can I use projections (components) from multiple correspondence analysis in subsequent regression analysis, similar to PCA

I am trying to reduce the dimension of a matrix of several hundred binary/indicator/boolean variables, and then use the reduced components in subsequent regression modeling. For continuous variables, this would look typically involve using PCA on the covariance matrix, projecting the data onto some subset of the eigenvectors, and using these resulting components in a regression model, effectively reducing the number of parameters estimated while retaining most of the information in the data. For a set of binary variables, correlation is not well-defined. Multiple correspondence analysis can be used instead. We take a Burt matrix, and apply MCA to it. I think I understand the math behind correspondence analysis, but what I cannot figure out is how to project the data down onto some subset of eigenvectors. That is, how are the components created in MCA for use in a regression analysis? So, if I have $K$ binary variables, how do I get the closest $K-d, d\geq 1$ dimensional approximation to the data, for integers $d$ in the same way I would with PCA? Or, with MCA is this not the idea?
