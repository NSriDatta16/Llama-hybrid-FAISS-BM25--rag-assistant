[site]: crossvalidated
[post_id]: 45541
[parent_id]: 45532
[tags]: 
I am a little off topic because I just offer you an other example of this kind of behavior, but hopefully this is extreme enough to help you understanding it. So my point is that when a factor associated with a trait is frequent, it can be a terrible predictor, even if the association is strong. Here is R code for an hypothetic case/control study. First, generate y and x : runif(1) y Then run a logistic regression: > summary(glm(y ~ x, family=binomial(link=logit))) Deviance Residuals: Min 1Q Median 3Q Max -1.4916 -0.2747 0.3091 0.8929 2.5674 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -3.2581 0.7203 -4.523 6.08e-06 *** x1 3.9719 0.7415 5.357 8.48e-08 *** The $\beta_1$ value is huge, isn’t it? And the $p$-value is tiny. Don’t pay attention to the intercept, this is a case/control study. As huge as $\beta_1$ is, $x_1$ is a terrible predictor: of course, 99% out of the cases ($y=1$) have $x=1$, but still 50% of controls have $x=1$. So if you use $x=1$ to predict $y=1$, you will misclassify 50% of the controls (and if the trait $y=1$ is rare, near to 50% of the population). You can modify this example to get the reverse behavior (correctly classifying controls but missing many cases), etc. You will even get a terrible behavior is all categories like this : runif(1) y Let's go: > summary(glm(y ~ x, family=binomial(link=logit))) Deviance Residuals: Min 1Q Median 3Q Max -1.54527 -0.85630 -0.00329 0.84972 1.53697 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -0.8145 0.2157 -3.775 0.00016 *** x1 1.6474 0.3072 5.363 8.2e-08 *** The $\beta$ is still quite large, but you can’t classify with this variable... PS See also this paper (in Genetics)
