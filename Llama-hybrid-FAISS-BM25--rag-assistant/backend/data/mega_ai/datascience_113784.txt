[site]: datascience
[post_id]: 113784
[parent_id]: 
[tags]: 
Practical application of denoising autoencoders

I have been reading into autoencoders for the purpose of denoising data. In the examples i found (eg. [ 1 , 2 , 3 ], which are the first few google results) they have the following input/output: Input layer: The original data with some artificial noise added Output layer: The original data (noiseless) I fail to see the practical application of this setup as it seems to require noiseless data to begin with. If we already have noisy data, then add even more noise to the input, wont the the network learn to remove the artificial noise, but not the original noise? Is a better approach to not add noise, but to just use a standard autoencoder where input/output are the same? It likely still will have some denoising properties as noise is random and therefore hard/impossible to represent in a lower dimensionality, while the patterns in the data are not. Therefore the noise might get lost in the embedding layer.
