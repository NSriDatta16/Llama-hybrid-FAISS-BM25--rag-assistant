[site]: datascience
[post_id]: 13358
[parent_id]: 
[tags]: 
PCA algorithm problems - Python

I have implemented PCA algorithm and I understood it very well but still I have some questions. My code is below and it's very simple implementation. import numpy as np x = np.loadtxt('CCPP', delimiter=',') row, column = x.shape # Mean normalization for i in range(column): x[:,i] = (x[:,i] - x[:,i].mean()) / (x[:,i].max() - x[:,i].min()) sigma = x.transpose().dot(x) / row u, s, v = np.linalg.svd(sigma, 0) z = x.dot(u[:,:3]) ## new features new_x = z.dot(u[:,:3].transpose()) ##reconstruction First Question As you can see above my sigma variable is x.transpose().dot(x) / row It's giving to me an nxn matrix (n is number of features). But sigma's formula is $$\Sigma = \frac{1}{n} \sum_{i=1}^n x^{(i)} {x^{(i)}}^T$$ Why there is a summation symbol in formula? I mean, if I use this sigma formulation then sigma is going to be a number, not a matrix. I have to get nxn matrix, right? So is my sigma implementation correct? or am I missing something about the formula? Second Question When we are reconstructing X (at the bottom in the code), should new_x equal to my first X? I mean, I reduced dimension of the data set, then I reconstructed it, original dataset and reconstructed dataset must be the same, right? This is my second question. Third Question This one is easy. Should I use data compression for each of my dataset which has 1000, 100000 or more features? I mean, can I always use it? Is it a good choice to use it every time?
