[site]: crossvalidated
[post_id]: 588898
[parent_id]: 486676
[tags]: 
In general terms, you have error that shrinks the more data you collect (or disappears if you have infinite data) and error that remains independent of how much data you collect. The first is called random error or variable error in your case. The second one is called systematic error or constant error in your case. For example, let's say I want to know the average height of men and women in a classroom. I can pick only a few men and women at random, and use their (sample) average height to infer about the classroom average height. This is random errorâ€”if I pick the whole classroom I will have no zero random error. Now imagine that I am not actually measuring them but just asking them to self-report height. Assume that men will inflate their self-reported height. This error will remain even if I ask the whole classroom. We will be extremely precisely wrong. As you see, systematic errors (usually called biases) are huge validity threats to our inferences. Yet most of the efforts to account for error will restrict themselves only to sampling error. For random error we can estimate our precision (e.g. by means of confidence intervals). For most systematic errors or biases, we have not even a guess about their magnitude or direction. Thus, sensitivity or bias analyses are an essential part of research. Further reading: Greenland, S., & Rafi, Z. (2019). To aid scientific inference, emphasize unconditional descriptions of statistics. arXiv preprint arXiv:1909.08583. Greenland, S. (2005). Multiple-bias modeling for observational studies (with discussion). Journal of the Royal Statistical Society, Series A, 168, 267-306.
