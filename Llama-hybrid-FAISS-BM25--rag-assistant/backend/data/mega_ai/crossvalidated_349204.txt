[site]: crossvalidated
[post_id]: 349204
[parent_id]: 349155
[tags]: 
My intuition about this phenomenon is connected to the complexity of the model to be learned. A deep neural network can indeed approximate any function in theory , but the dimension of the parameter space can be really large, like in the millions. So, actually finding a good neural network is really difficult. I like to think about feature engineering as giving a head start to the algorithm, providing it some extra information regarding the data representation which is good enough in some sense. Of course, this is not a formal explanation, this question might be really hard to answer with scientific rigor.
