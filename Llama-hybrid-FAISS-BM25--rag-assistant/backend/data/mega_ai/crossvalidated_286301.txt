[site]: crossvalidated
[post_id]: 286301
[parent_id]: 
[tags]: 
Is my better score with a different machine learning model statistically significant?

I have a question concerning the p-value and how you can say that this selection of features is better than that other one. To make things simple let's assume that I'm working on the spam classification problem. I've tested two different ways to do my feature engineering : OPTION 1 = bag of words Accuracy : 90% OPTION 2 = tf-idf Accuracy : 91% Those results seem pretty close with an edge for tf-idf. However this could be caused by the random seed, the dataset I trained my algorithm on, the dataset I tested my data on etc. My question is : can I say that OPTION2 is better than OPTION1 ? I looked on Wikipedia for information on statistical significance and null hypothesis and from what I've understood I need to compute the probabilty of my test happening if OPTION2 is better than OPTION1 (H0) How can I do this ? And there seems to be a lot of controversy around the p-value (how do you set the threshold ? the fact that it is mistaken with the probability of the null hypothesis being true etc) so in the end am I not better off running my algorithm different times with different random seeds and on different parts of the dataset and do some sort of average on those values ?
