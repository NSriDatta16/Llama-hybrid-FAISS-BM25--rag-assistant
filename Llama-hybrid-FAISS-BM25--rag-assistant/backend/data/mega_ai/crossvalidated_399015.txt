[site]: crossvalidated
[post_id]: 399015
[parent_id]: 
[tags]: 
Should one track the loss or accuracy of a neural network when training it?

Should one track a model's progress using its loss or its accuracy? I ask this because sometimes the loss at a epoch is higher than that at previous epochs (which is a bad thing) but so is the accuracy at that epoch (which is a good thing). So should one prefer models with lower loss or those with higher accuracy. Here, both the loss and accuracy refer to that on the validation set (that are calculated after each epoch). The reason why I think that lower loss is better is that the model is setup to essentially minimize the loss and not to maximize the accuracy. Lower loss, to me, means that the model is in a better region of the error surface that we are trying to minimize (and I feel that a higher accuracy does not necessarily reflect that because the accuracy has nothing to do with this surface) and hence a model with lower loss might be able to generalize better. On the other hand, from a practical viewpoint, we are in almost all cases really interested in the accuracy and as such the loss has no significant meaning.
