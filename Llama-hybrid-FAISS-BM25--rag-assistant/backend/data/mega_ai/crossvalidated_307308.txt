[site]: crossvalidated
[post_id]: 307308
[parent_id]: 307302
[tags]: 
I think the question is difficult to answer in the abstract but for what it is worth here are some thoughts: The data you are feeding the might not be the 'perfect' dataset for that particular algorithm. For example, I could estimate the parameters of a linear regression model (i.e., $Y=X\beta + \epsilon$) using stochastic gradient descent. If the data is inconsistent with my assumption (e.g., the data points are randomly scattered around then the fit is likely to be poor with a small dataset. In your context, it is possible that the neural network approach may be getting too many 'disparate' data points which are wildly different in some sense (e.g., if we are trying to recover handwritten digits then it gets images of handwritten digits written in different colors, with different writing instruments etc.). Thus, with a small dataset the fit is poor but as you increase the dataset size, more training samples become available and the fit improves as one might expect. The only circumstance when I imagine the fit would be good with a small dataset would be when we have a well-behaved dataset in the sense that there is a strong pattern that can be recovered easily by our model. For example, we feed the neural network handwritten digits all written in black with about the same font size by the same type of writing instrument and so on. In such a situation, I would imagine that a small dataset might be sufficient and a sufficiently complex neural network might actually fit the data perfectly as the pattern in the data is too strong relative to the noise present.
