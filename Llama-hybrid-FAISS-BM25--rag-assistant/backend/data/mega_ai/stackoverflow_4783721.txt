[site]: stackoverflow
[post_id]: 4783721
[parent_id]: 4783081
[tags]: 
The two notions are orthogonal. You can have worst case asymptotics . If f(n) denotes the worst case time taken by a given algorithm with input n , you can have eg. f(n) = O(n^3) or other asymptotic upper bounds of the worst case time complexity. Likewise, you can have g(n) = O(n^2 log n) where g(n) is the average time taken by the same algorithm with (say) uniformly distributed (random) inputs of size n . Or you can have h(n) = O(n) where h(n) is the average time taken by the same algorithm with particularly distributed random inputs of size n (eg. almost sorted sequences for a sorting algorithm). Asymptotic notation is a "measure". You have to specify what you want to count: worst case, best case, average, etc. Sometimes, you are interested in stating asymptotic lower bounds of (say) the worst case complexity. Then you write f(n) = Omega(n^2) to state that in the worst case, the complexity is at least n^2 . The big-Omega notation is opposite to big-O: f = Omega(g) if and only if g = O(f) .
