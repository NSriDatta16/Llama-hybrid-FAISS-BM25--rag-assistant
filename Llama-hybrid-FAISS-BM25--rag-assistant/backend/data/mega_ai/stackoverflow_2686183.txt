[site]: stackoverflow
[post_id]: 2686183
[parent_id]: 1766461
[tags]: 
Some problems could be solved by a recurrent neural network. For example, it is good for calculating parity over a sequence of inputs. The recurrent neural network for calculating parity would have just one input feature. The bits could be fed into it over time. Its output is also fed back to the hidden layer. That allows to learn the parity with just two hidden units. A normal feed-forward two-layer neural network would require 2**sequence_length hidden units to represent the parity. This limitation holds for any architecture with just 2 layers (e.g., SVM).
