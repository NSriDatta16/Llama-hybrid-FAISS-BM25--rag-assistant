[site]: crossvalidated
[post_id]: 424973
[parent_id]: 424970
[tags]: 
Autoencoders do not differ from any other kind of neural network applied to images (e.g. convolutional neural networks ). Images are stored on computers on many formats, one of the popular ones is to have the image splited to three layers, for the red, green, and blue channels, where the final color that you see is the combination of the values from the three layers. When working with such data, neural networks usually also keep the information stored in three layers, for each basic color. This happens in dense, convolutional, and any other kind of layer. Same applies to autoencoders, that are defined in terms on the same building blocks as any other kind of neural network. Moreover, even if you flattened the layers, there is no reason why network should loose any information. If they are able to learn spatial relations, smiles, letters, digits, animal shapes, shoe shapes, and a lot of other kind of things, I see no reason why color should be any special.
