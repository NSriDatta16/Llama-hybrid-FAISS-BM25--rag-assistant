[site]: crossvalidated
[post_id]: 350692
[parent_id]: 350678
[tags]: 
Should i normalize my numerical data values before feeding to any type of autoencoder? If they are int and float values do I still have to normalize? Normalizing data often improves the model because it amounts to pre-conditioning the inputs so that optimization proceeds more smoothly. Which activation function should I use in autoencoder? Some article and research paper says "sigmoid" and some says "relu"? Use the one that works best for your problem. ReLUs are gaining popularity because they alleviate some problems with sigmoids units. See What are the advantages of ReLU over sigmoid function in deep neural networks? for some more information. Should I use dropout in each layer? That depends on what you want your model to do and what qualities you want it to have. Autoencoders that include dropout are often called "denoising autoencoders" because they use dropout to randomly corrupt the input, with the goal of producing a network that is more robust to noise. This tutorial has more information .
