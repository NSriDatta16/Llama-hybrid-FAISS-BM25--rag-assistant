[site]: crossvalidated
[post_id]: 583849
[parent_id]: 
[tags]: 
Is using an approximation technique to estimate the parameter under a known posterior distribution necessary?

Let $X_i \sim \text{IID Poisson}(\theta)$ for $i=1,2,...,n.$ The MLE of $\theta$ is written as $$\hat{\theta}_\text{MLE}=\bar{x}.$$ Suppose $\theta$ has a probability density function (pdf) $p(\theta) \propto \theta^{-1/2}$ , which is Jeffrey's prior. The resulting posterior distribution is $\theta|\mathbf{x} \sim \text{Gamma}(\sum_{i=1}^{n} x_i +\frac{1}{2},\frac{1}{n})$ . Under quadratic loss, it can be shown that the (minimum risk) Bayes estimator is $$\hat{\theta}_\text{Bayes} = \bar{x}+\frac{1}{2n}.$$ Now, knowing the Bayes estimator in this scenario, if I were to compare the performances of the MLE and the Bayes estimator in terms of bias, can I simply simulate data from Poisson with parameter $\theta_0$ and estimate using $\hat{\theta}_\text{MLE}$ and $\hat{\theta}_\text{Bayes}$ directly? Then, repeat for say, $1000$ iterations and check the means of the estimated values of $\hat{\theta}$ ? Alternatively, should I use some sort of approximation techniques such as MCMC?
