[site]: crossvalidated
[post_id]: 369746
[parent_id]: 
[tags]: 
Can we improve a model by dropping unimportant features

I have a Random Forest Model which, after using StringIndexer and HotEncoder, has got around 1300 features. I calculated the importance of all these features and I found out that more than 500 features have got 0 importance in the final model. Will I improve my model by dropping this feature before the training or will I end up just with a model faster to train? Since those unimportant features are mostly features generated by the hotencoder for categories which almost never appear (those which belong to the "long tail" of the dataset) I was considering as an option to group them into a new feature named "other" before start the training the model.
