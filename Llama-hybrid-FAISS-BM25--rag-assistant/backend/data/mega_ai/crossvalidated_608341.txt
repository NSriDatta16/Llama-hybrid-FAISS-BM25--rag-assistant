[site]: crossvalidated
[post_id]: 608341
[parent_id]: 
[tags]: 
How to find/understand magnitude of difference (meta-analysis reports Hedge's g)

I'm reading a meta-analysis about how well cognitive-behavioral therapy (CBT) works for treating depression in adults. The study uses a statistic called Hedge's g to measure the treatment's effectiveness. I'm learning about this statistic for the first time, and as I understand it, it's inversely proportional to the weighted average of standard deviations in compared groups. So if people in these groups are much more similar to themselves than is the case in the general population (I presume they have depression, which would correspond to being on the left tail of well-being (I assume a depression score corresponds to well-being/happiness on the low end sufficiently well that you can sort of translate between these in your mind, at least as a first approximation)), a relatively small change might result in a big Hedge's g. This would suggest that a Hedge's g = 0.53 might mean that even if the change is significant in terms of improving depression, when you look at the results in terms of a change in well-being, the change is pretty small. (i.e. a common outcome could be that you might not as depressed, but you'd still be relatively sad). I think the above is complicated by the fact that measures of depression are not sensitive to changes such that the improvement goes above the "not depressed" threshold - you can't have a score lower than 0 (no symptoms). I doubt that given Hedge's g = 0.53 this would change my analysis very much, because unless a big portion of patients had low scores to begin with, moving 0.53 standard deviations shouldn't get them close to 0 symptoms I think. My questions: is my reasoning right? is there a way to find what was the difference in absolute terms or at least some proxies to have an idea how big are the improvements in practical terms?
