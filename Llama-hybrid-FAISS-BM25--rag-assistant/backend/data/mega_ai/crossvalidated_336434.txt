[site]: crossvalidated
[post_id]: 336434
[parent_id]: 332746
[tags]: 
Whenever the same participants contribute information to multiple estimates (whether it be multiple estimates of the measure over time, multiple effects for different measures, or both), the sampling errors of the estimates are correlated and that should be accounted for by computing the covariances. In addition, one can account for possible dependency in the underlying true effects by fitting a multilevel/multivariate model. That just means that we include random effects, such that the true effects are allowed to be correlated in some form. An example analysis of this is provided here . A somewhat less common case arises when we have multiple estimates that are clustered within some higher level grouping variable, but the estimates within the groups are based on different sets of participants. In that case, the sampling errors are independent, but there may still be correlation among the underlying true effects. So, we then again want to add random effects that reflect this. An example analysis of this is provided here . As was mentioned in the comments, this type of analysis/model is only appropriate when the sampling errors are uncorrelated. A common problem with the first case (where sampling errors are correlated) is that the information needed to compute the covariances is not available. Some work has been done to examine whether we can ignore the covariances (i.e., assuming that they are 0) as long as we still allow the underlying true effects to be correlated (again, by adding appropriate random effects to the model). When doing that, the correlations among the sampling errors get subsumed into the correlation among the true effects. Using the example here , you can try this out: library(metafor) dat Model res1 allows sampling errors to be correlated (the V matrix includes the covariances). In model res2 , we use diag(V) , so only the diagonal of the V matrix is used. As you will find, the correlation among the true outcomes is 0.6088 in res1 and 0.7752 in res2 . Since we (incorrectly) assume that the covariances among the sampling errors are zero in res2 , the model tries to compensate for this by increasing the correlation among the underlying true effects. Model res2 can work okay for making inferences about the fixed effects (i.e., for testing and constructing confidence intervals for the estimated average effects). But we know that the model is misspecified, so it isn't ideal. A possible remedy is to use cluster-robust inference methods after having fitted a model like res2 . For the example above, this would be: robust(res2, cluster=dat$trial) The cluster-robust inference approach tries to "fix up" the standard errors of the estimates of the fixed effects. You will see in the example that the SEs are quite a bit larger now. Asymptotically (i.e., when the number of clusters gets large), this approach should provide appropriate SEs (but that's unlikely to be the case in this example, since there are only 5 studies).
