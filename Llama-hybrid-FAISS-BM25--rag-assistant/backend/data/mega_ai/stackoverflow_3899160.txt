[site]: stackoverflow
[post_id]: 3899160
[parent_id]: 3899097
[tags]: 
There's a chapter in Introduction to Algorithms devoted to finding two closest points in two-dimensional space in O(n*logn) time. You can check it out on google books . In fact, I suggest it for everyone as the way they apply divide-and-conquer technique to this problem is very simple, elegant and impressive. Although it can't be extended directly to your problem (as constant 7 would be replaced with 2^101 - 1 ), it should be just fine for most datasets. So, if you have reasonably random input, it will give you O(n*logn*m) complexity where n is the number of points and m is the number of dimensions. edit That's all assuming you have Euclidian space. I.e., length of vector v is sqrt(v0^2 + v1^2 + v2^2 + ...) . If you can choose metric, however, there could be other options to optimize the algorithm.
