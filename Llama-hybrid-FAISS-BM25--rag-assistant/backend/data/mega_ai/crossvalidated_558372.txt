[site]: crossvalidated
[post_id]: 558372
[parent_id]: 558316
[tags]: 
Exploding gradient is also an issue when vanilla RNN trying to learn the long-term dependency in the context. This phenomenon is related to the largest singular value $\lambda_1$ of weight matrix $W_h$ as well as $\frac{1}{\gamma}$ , a term depends on activation function $\sigma$ and dimensionality, see 'On the difficulty of training recurrent neural networks' for further references.
