[site]: crossvalidated
[post_id]: 497797
[parent_id]: 497252
[tags]: 
To some extent, it depends on how well each of these ideas performs. Of course, it's pretty expensive and time consuming to do predictions with the different approaches, wait some months and then find out whether a model worked. And this gets even messier, when you aim to intervene based on the predictions. So, the next best thing is to cut your data in time: e.g. predict based on everything we knew before 1 January 2015 vs. what happened in 2015, predict based on everything we knew before 17 April 2016 vs. what happened in 2016, or whatever corresponding splits make sense. Ideally, you would want to see that are model performs consistently across cuts (plus minus a bit of noise and taking into account that the later you do the cut, the more training data you have - unless you actually want to discard very old training data, which may be a serious consideration). As you suggest, I would expect that taking into account timeframes will matter. E.g. number of logins a user ever made is likely not that great a predictor, because it confounds two different types of information: how much the user logs in and how long they have been around. So, instead things like number of log-ins per year of being a user, log-ins in the last 2 week, last 12 weeks, last half-year etc. are alternatives that sound like things one should investigate (and there are probably other ways of creating features of this type). It also sounds plausible to look at the relative change in recent (whatever that means e.g. last month?) number of logins vs. how many the user usually (whatever that means) does. In principle, a model like xgboost is capable of figuring out interactions (e.g. when a user is on the platform for a long time, a large number of logins means something different than for a user that's been there a short-time), but it tends to be much, much more efficient to provide a feature that captures a human understanding. Additionally, xgboost cannot really extrapolate, unless you give it features that help it extrapolate: What I mean is that the training data has no user with >10 years membership and no user with >1000 logins, then when get new data that has 15 years membership and 15000 logins, it will actually treat it just like 10 years membership with 1000 logins - in contrast, there might be existing users with >1000 logins/year (assuming that this is a sensible way of looking at the data), which the model could base predictions on (we can argue whether the model should do that and you need to think about that).
