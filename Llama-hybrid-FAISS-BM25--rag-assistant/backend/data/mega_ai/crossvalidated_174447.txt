[site]: crossvalidated
[post_id]: 174447
[parent_id]: 174344
[tags]: 
As @glen_b pointed out, likelihood is not an inverse probability, as $\theta$ is not a random variable. However, you are correct in that it is a measure of evidential support. One caveat is that, unlike probability, it is not an absolute measure of support (a likelihood of 1, 10, or 1000 has no intrinsic meaning), but a relative measure of support. Generally, this is encoded by forming the likelihood ratio (LR): $$ LR(\theta):= \frac{L(\theta;x)}{L(\theta_{MLE};x)}$$ Which will always be between 0 and 1. This is an improvement over the unnormalized likelihood, but we still aren't quite there. It turns out that, for example, a $LR=0.15$ is not by itself a useful measure either, since its interpretation depends on the dimension of $\theta$. If $\theta$ is a scalar, then $P(LR However, it can also be used as a purely subjective measure of what we consider "plausible" parameter given the data (read:evidence). Under this non-probabilistic interpretation, we would say that any scalar $\theta$ that resulted in $LR can , but then your inferences at a higher dimension will not be compatible with inferences at a lower dimension. This is a subtle point. A good article on this was written by one of the strongest proponents of likelihood inference (JK Lindsey). See here. ). Essentially, compatible inference can be implemented by raising the scalar likelihood cutoff to the number of dimensions of the vector parameter. For example, if our parameter dimension is 2, then a cutoff that would be compatible with $0.15$ would be $0.15^2$. The above is a very abridged description of modern likelihood. I think your confusion is shown by the following statement you made: Given that Graham is using an umbrella, there is a 20% chance that it is raining. This is actually not what a 20% likelihood would tell you. What you stated above is a Bayesian posterior probability : $P(\textrm{Raining}|\textrm{Umbrella})$, what the likelihood it saying is quite the opposite: $$L(\textrm{Raining}|\textrm{Umbrella}) = P(\textrm{Umbrella}|\textrm{Raining})$$ As you correctly pointed out, a prior probability (and a normalizing constant) is required to turn a likelihood into a probability.
