[site]: stackoverflow
[post_id]: 4828378
[parent_id]: 4827503
[tags]: 
Even if the number of active objects would be much larger, say 1 million, you can still use a relatively small hash map, for example a map of size 10000. Each element of the map points to a linked list of IDs. These lists are searched using simple linear searrch. If the hash function is well chosen, the IDs will be distributed evenly (or close to that) over the 10000 entries in the hash map. Thus each entry of the hash table will contain about 100 IDs. Linear searching such a list takes 50 comparisona on average. In one of my apps the number of symbols was around 1000. I used just simple linear search. Performance analysis showed that 90% of CPU time was spent in the table lookup. Next I made a hash table of just 32 entries -> CPU load of the table lookup dropped to below 4%. Problem solved. Enlarging the hash table would have no noticeable impact on speed (less than 4%) so I left it at the size of 32. Conclusion: you can use a hash table that is smaller than the number of elements. This requires an average number of comparisons of (Total number of IDs / size of hash table / 2) Choose the hash table size large enough to reduce CPU time for table lookup to a low fraction of total CPU time.
