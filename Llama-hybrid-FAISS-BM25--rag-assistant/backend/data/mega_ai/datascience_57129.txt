[site]: datascience
[post_id]: 57129
[parent_id]: 
[tags]: 
CART algorithm (Classification and regression trees) question

We fit a full classification tree model $T_k$ of given depth $k$ to data using the CART algorithm, and prune the tree by finding $E(k, \alpha) = min_{T\subset Tk} Err(T) + \alpha |T|$ . Here, $Err(T)$ is the training error of a tree $T$ on the training data, $|T|$ is the number of leaves in $T$ and $\alpha$ is a given parameter. Which of the following is sometimes false ? $\color{blue}{(a) E(k+ 1,0) \geq E (k,0)}$ (b) $E(k+ 1,0) \leq E(k,0)$ (c) $E(k+ \alpha+1) \geq E(k,\alpha)$ (d) All three statements above are always true $\color{blue}{Explanation:}$ By supplying the depths $k$ and $k + 1$ , the Cart algorithm will return us with a tree of depth $k, T,$ and a tree of depth $k + 1, \widetilde {T}$ . It is important to note that $T$ and $\widetilde {T}$ share the same first $k - 1 $ levels. Now the pruning starts, any possible pruning of $T$ can be achieved by pruning $\widetilde {T}$ , but not vise versa. Therefore $E(k, \alpha) \geq E(k + 1, \alpha)$ for any $\alpha \in R_+.$$ See Lecture 7. So this is taken from an exam I just did. I'd like to know if there are any instances same as in the image where the CART algorithm could use a negative alpha and thus encourage a larger tree? Or does the algorithm state that alpha must be a non negative integer at all times?
