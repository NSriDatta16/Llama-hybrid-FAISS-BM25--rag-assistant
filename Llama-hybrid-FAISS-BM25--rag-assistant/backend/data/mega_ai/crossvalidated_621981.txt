[site]: crossvalidated
[post_id]: 621981
[parent_id]: 621974
[tags]: 
Must it produce a valid inference? No! In the simulation below, I generate a sample of size $10$ that serves as the data. Then I generate synthetic data, based on the mean and variance from the sample. I combine the data and the synthetic data and calculate a confidence interval for the combination. I also calculate a confidence interval for the original data. set.seed(2023) N mu){ contained[i] mu){ contained_regular[i] The confidence intervals from the real data contain the true parameter value in about the desired $95\%$ of cases ( $95.11\%$ ). However, augmenting the data with synthetic data leads to the confidence intervals containing the true value in only $13.94\%$ of cases. That is, you think you’re calculating a $95\%$ confidence interval but actually get a $13.93\%$ confidence interval. Ouch! What’s happening is that the synthetic data are generated to be similar to the data, not the data-generating process. Each time data are generated, they are generated using the estimated mean and variance, which are not the true mean and variance. This drags the synthetic data away from the true population of interest, distorting the statistical inference. I hope this demonstrates potential dangers of using synthetic data. Philosophically, I do not see much of a difference between using synthetic data in frequentist methods and using an informative prior in Bayesian methods, and Bayesian methods can be very powerful, but if you pick a bad prior (or a bad way of generating synthetic data), you can wind up in trouble. EDIT Amazingly, the story doesn’t even get much better for N and S . I would have though that the estimated mean and variance would be so close to their true values with a sample size of 10000 , but they appear not to be close enough to give confidence intervals that function as they should.
