[site]: crossvalidated
[post_id]: 332089
[parent_id]: 
[tags]: 
Numerical gradient checking (best practices)

I've implemented a neural network and am using numerical gradient checking to validate the back-propagation algorithm is working correctly. I'm using the standard method to calculate the numerical gradient: $f'(x) \approx \frac{J(\theta + \epsilon) - J(\theta - \epsilon)}{2 \epsilon}$ where $\epsilon = 10^{-4}$, and norm(gradients - numericalGradients)/norm(gradients + numericalGradients) to check back-propagation is operating correctly. I'm currently checking throughout training for testing purposes and I think that it is functioning correctly, however, as the network approaches its solution the gradients become very small and I think this is why the check fails. So my question is what are the best practices for when to perform gradient checking? Once at the start only, only when the minimum gradients are N times bigger than epsilon? #!/usr/bin/python import numpy as np import matplotlib.pyplot as plt class NeuralNet: GRAD_CHECK_THRESH = 10e-8 GRAD_CHECK_ITER = 9999999 EPSILSON = 10e-4 def __init__(self, _maxIter=250, _nHidden=3): # Set hyperparameters self.maxIter = _maxIter self.nHidden = _nHidden self.learningRate = np.linspace(0.5, 0.05, self.maxIter) self.momentum = 0.5 self.enNesterov = False # Nesterov accelerated gradient (https://arxiv.org/pdf/1212.0901v2.pdf) self.cost = [] self.gradDiff = [] self.minGrad = [] self.dW1 = 0 self.dW2 = 0 def initNet(self, _nInput, _nOutput): self.nInput = _nInput self.nOutput = _nOutput self.W1 = np.random.rand(self.nInput, self.nHidden)/100 self.W2 = np.random.rand(self.nHidden, self.nOutput)/100 def train(self, X, y): # Initialise network structure self.initNet(X.shape[1], y.shape[1]) # Train - full batch for m in range(self.maxIter): # Check gradient descent is operating as expected if m
