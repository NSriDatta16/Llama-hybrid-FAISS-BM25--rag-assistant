[site]: datascience
[post_id]: 58339
[parent_id]: 58337
[tags]: 
One way to do that is to customize the formula to update weights. Normally, the formula is something like this: weight = weight - learning_rate * error You can change it to: weight = max(0, weight - learning_rate * error) This will perform well or not? I have no idea. We can't say much about the guaranteed performance of neural network models in general. However, if by good results, you mean a model with all positive weights, I believe this one will qualify.
