[site]: crossvalidated
[post_id]: 612477
[parent_id]: 
[tags]: 
Linear process, how is $X_t$ well-defined?

Def . Let $ \theta \in \mathbb{R}^{\mathbb{Z}}$ be a sequence of real-numbers such that $ \sum_{j \in \mathbb{Z}} | \theta_j | and $\{W_t\}$ be a white noise with variance $\gamma$ . Then a time series $\{X_t\}$ is a linear porcess if it can be represented as $$ X_t = \sum_{j\in \mathbb{Z}} \theta_j W_{t-j}.$$ Using the criterion for mean-square convergence, if $S = \sum_{j \in \mathbb{Z}} | \theta_j |$ , then for any $ t \in \mathbb{Z}$ , $$ E(X_t^2) = E(\sum_{j\in \mathbb{Z}} \theta_j W_{t-j}) \leq \bigg(\sum_{j \in \mathbb{Z}} | \theta_j | \sqrt{E(W_{t-j})}\bigg)^2 \stackrel{?}{=} S^2 \gamma.$$ Im failing to see why the last equality holds. Should not $ \sum_{j \in \mathbb{Z}} E(W_{t-j}) = \infty$ anyways, if $\gamma â‰  0$ ?
