[site]: datascience
[post_id]: 28691
[parent_id]: 
[tags]: 
Gradient descent and partial derivatives

I'm on the first chapter of Nielsen's book on neural networks . He gives an example of a gradient descent and that change in function $C(v_1,v_2)$ is described by this formula: $$\begin{eqnarray}\Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +\frac{\partial C}{\partial v_2} \Delta v_2\tag{7}\end{eqnarray}$$ Though I'm familiar with partial derivatives, i'm confused about how you would compute partial derivatives of this function. Could someone give an example please?
