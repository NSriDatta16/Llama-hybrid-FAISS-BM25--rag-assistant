[site]: crossvalidated
[post_id]: 314625
[parent_id]: 
[tags]: 
binomial distribution "flower", ratios vs direct

I am working with a set of data that is very similar to the binomial distribution. It is closely simulated by a random binomial variable. In the real data, there is reason to believe there are predictor variables that account for differences in the binomial probability. The goal is to determine those predictors effect on that binomial probability. Think about this case as a rare random event. However, it is presumed that is not completely random. There are environmental factors that increase the possibility of that event. I'm sure that people in the insurance industry work with data like this. What I have is county level data and population counts (X in these charts) and event counts (Y in these charts) and I also have other potential predictor variables. This code simulates the data. binom.prob=0.01 set.seed(8) x=1:20000 y=sapply(x,function(x) sum(rbinom(x,1,binom.prob))) plot(x,y,col=rgb(1,0,0,0.5),pch='.',main='binomial distribution');grid() plot(x,y/x,col=rgb(1,0,0,1),pch='.',main='binomial distribution ratio');grid() Since this is a binomial problem, logistic regression (glm binomial) handles this data set. Coded either way as: summary(glm(I(y/x)~x,data.frame(x=x),family=binomial,weights=x)) summary(glm(cbind(x-y,y)~x,data.frame(x=x),family=binomial)) But for other machine learning techniques that are not set up explicitly for binomial distributions, I believe reason for exploring the data as a ratio rather than as the X sample population and the Y events, is that if one tries to learn simply the direct values then one just automatically gets a high r squared and little is discovered. But if I am trying to predict the ratio then this effectively cancels out the population size and allows me to focus on those variables that truly affect the binomial probability. (summary(lm(y~x)))$r.squared #obviously high r squared, returns 0.97 (summary(lm(I(y/x)~x)))$r.squared #obviously low r squared, returns 0.00001977375 Is there a better way to predict the contributing factors to the binomial distribution? Or am I over thinking this and I should really just use logistic regression. I found that I had to exclude those records that had a small sample population size in order to get good results or use weighting based on the population counts. I think it has to do with the Heteroscedasticity of the data. Is there a way of using the records from the small populations without weighting (besides logistic)? From an artistic point of view, plotting the ratios of the binomial distribution causes a flower to appear. Has a mathematician named this graph? d=expand.grid(num=0:50,dem=1:50) d=d[d$num
