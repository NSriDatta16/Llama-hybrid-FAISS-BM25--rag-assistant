[site]: crossvalidated
[post_id]: 487452
[parent_id]: 
[tags]: 
When should an embedding layer be used? How big should an embedding be?

I am currently in the process of learning about seq2seq autoencoders for a task involving sentence embedding (samples are sentences, with words represented as integers in a vocab of size $n$ ). In the different tutorials and examples I have viewed I have noticed some authors use an embedding layer after the input layer while others do not. Now I understand what embedding layers are and roughly how they work, but I can not seem to figure out when one should use an embedding layer - specifically in the context of my task. My best guess is that embedding layers simply make the representation of the data easier for the network to work with, transforming a large vocab of $n$ words as integers into fixed sized float vectors. However I do not really have any evidence to back this up other than intuition. So are there any rules of thumb as to when embedding layer after a network's input layer? If so, are there any good rules of thumb for what embedding size to choose in proportion to the vocabulary size? If it matters, I am referring to the Embedding layer in Tensorflow 2 / Keras.
