[site]: stackoverflow
[post_id]: 3589550
[parent_id]: 3589479
[tags]: 
25k requests per second you need to scale out (even at 25k per minute, 25k per second is actually a huge load and you'll need many a servers to handle it). You must have a park of WWW service servers, each dumping the request into a local storage (a queue). You can't have the WWW farm talk straight inot the back end, it will die because of contention (lock exclusion due to client requests attempting to insert/update in the same spot in the database). The WWW service just dumps the requests locally, and then returns the HTTP response and continues. From the mid tier WWW servers these requests have to be aggregated and loaded into the central servers. This loading has to be reliable, easily configurable, and quite fast. Don't fall for the trap of 'I'll just write a copy utility myself with retry logic', that road is paved with bodies. A good candidate for this local storage is a SQL Server Express instance and a good candidate for the aggregation and loading is Service Broker. I know this architecture works because I've done projects that use it, see High Volume Contiguos Real Time Audit and ETL . And I know of projects that use this architecture to scale it ( really high, see March Madness on Demand or Real Time Analytics with SQL Server 2008 R2 StreamInsight about how the Silverlight media streaming runtime intelligence is collected (the emphasys on both links is on different technologies, but sinc eI happen to know that project quite well I know how they collect the data from the WWW web-services to their back end).
