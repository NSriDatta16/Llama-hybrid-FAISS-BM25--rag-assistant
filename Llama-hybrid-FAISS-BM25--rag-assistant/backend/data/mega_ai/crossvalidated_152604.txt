[site]: crossvalidated
[post_id]: 152604
[parent_id]: 
[tags]: 
Are these logical variables for predicting among train/test sets?

I'm wondering if the following makes sense for a model. I have a training and a test set. I want to predict whether a website visitor is a bot or a human, based on several visits. The data has been classified, so in the training set I know whether they are humans or bots. There is 63% of overlap in the IP-addresses of the training and test set. I also know that an IP address is not purely decisive whether someone is a bot or human. I'm thinking to take the average of the bot outcome of the ip-address, not taking into account the row itself for the training as a feature: ip bot feature 1 1 0.5 # (avg of 0 & 1, excluding a bot=1) 1 1 0.5 # (avg of 0 & 1, excluding a bot=1) 1 0 1 # (avg of 1 & 1, excluding a bot=0) 2 1 0.5 # (avg of 0 & 1, excluding a bot=1) 2 0 1 # (avg of 1 & 1, excluding a bot=0) 2 1 0.5 # (avg of 0 & 1, excluding a bot=1) For the test, it can then just use the average of "bot" outcome per IP-address in the training set (or the global average if no ip does not occur in training), and a dummy variable for being in the test or not. Does this make sense?
