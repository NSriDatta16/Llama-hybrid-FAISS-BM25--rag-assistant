ic awards, in recognition of his work. Lattices and big data sets The technique of fuzzy concept lattices is increasingly used in programming for the formatting, relating and analysis of fuzzy data sets. Concept formalization According to the computer scientist Andrei Popescu at Middlesex University London, a concept can be operationally defined to consist of: an intent, which is a description or specification stated in a language, an extent, which is the collection of all the objects to which the description refers, a context, which is stated by: (i) the universe of all possible objects within the scope of the concept, (ii) the universe of all possible attributes of objects, and (iii) the logical definition of the relation whereby an object possesses an attribute. Once the context is defined, we can specify relationships of sets of objects with sets of attributes which they do, or do not share. Fuzzy concept lattice Whether an object belongs to a concept, and whether an object does, or does not have an attribute, can often be a matter of degree. Thus, for example, "many attributes are fuzzy rather than crisp". To overcome this issue, a numerical value is assigned to each attribute along a scale, and the results are placed in a table which links each assigned object-value within the given range to a numerical value (a score) denoting a given degree of applicability. This is the basic idea of a "fuzzy concept lattice", which can also be graphed; different fuzzy concept lattices can be connected to each other as well (for example, in "fuzzy conceptual clustering" techniques used to group data, originally invented by Enrique H. Ruspini). Fuzzy concept lattices are a useful programming tool for the exploratory analysis of big data, for example in cases where sets of linked behavioural responses are broadly similar, but can nevertheless vary in important ways, within certain limits. It can help to find out what the structure and dimensions are, of a behaviour that occurs with an important but limited amount of variation in a large population. Big data Coding with fuzzy lattices can be useful, for instance, in the psephological analysis of big data about voter behaviour, where researchers want to explore the characteristics and associations involved in "somewhat vague" opinions; gradations in voter attitudes; and variability in voter behaviour (or personal characteristics) within a set of parameters. The basic programming techniques for this kind of fuzzy concept mapping and deep learning are by now well-established and big data analytics had a strong influence on the US elections of 2016. A US study concluded in 2015 that for 20% of undecided voters, Google's secret search algorithm had the power to change the way they voted. Very large quantities of data can now be explored using computers with fuzzy logic programming and open-source architectures such as Apache Hadoop, Apache Spark, and MongoDB. One author claimed in 2016 that it is now possible to obtain, link and analyze "400 data points" for each voter in a population, using Oracle systems (a "data point" is a number linked to one or more categories, which represents a characteristic). However, NBC News reported in 2016 that the Anglo-American firm Cambridge Analytica which profiled voters for Donald Trump (Steve Bannon was a board member) did not have 400, but 4,000 data points for each of 230 million US adults. Cambridge Analytica's own website claimed that "up to 5,000 data points" were collected for each of 220 million Americans, a data set of more than 1 trillion bits of formatted data. The Guardian later claimed that Cambridge Analytica in fact had, according to its own company information, "up to 7,000 data points" on 240 million American voters. Harvard University Professor Latanya Sweeney calculated, that if a U.S. company knows just your date of birth, your ZIP code and sex, the company has an 87% chance to identify you by name â€“ simply by using linked data sets from