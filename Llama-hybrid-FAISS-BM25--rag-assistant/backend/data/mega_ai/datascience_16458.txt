[site]: datascience
[post_id]: 16458
[parent_id]: 
[tags]: 
Tips for retraining convolutional neural networks given a drastically different loss surface

For the image dataset I am working with, I need to use B&W version of images (otherwise, I would need to build a network to give false colors to a set of my images, since they have an overpowering color tint). I am attempting to retrain VGG's bottom layers (including the last convolution block) in order to perform this task, but am running into the problem that by rephrasing the space in which the input operates in (and thus also completely changing the loss surface) it is a difficult task to retrain these layers. I've experimented with learning rates from everywhere from 0.01 to 100 (using different decay schedules for each) with no success. Does anyone have any tips with retraining networks for significantly different loss surfaces? Should I ditch my efforts and attempt to train a new network end-to-end (my dataset isn't too large, so this is quite prone to overfitting if I am to use deep learning)? Are there networks built for B&W images that I could instead retrain?
