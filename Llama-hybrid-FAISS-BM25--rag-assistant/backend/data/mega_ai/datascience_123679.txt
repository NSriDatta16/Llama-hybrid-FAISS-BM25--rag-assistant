[site]: datascience
[post_id]: 123679
[parent_id]: 
[tags]: 
One-Hot encoded variables dominates importance among other variables

I am currently training some machine learning models to predict the 28-day compressive strength of cement, a continuous real-valued variable. The available dataset comprises samples from three distinct types of cement. To account for this, I've introduced two one-hot encoded variables to indicate the specific type of cement associated with each sample. Upon fitting a linear regression model and analyzing the coefficients, I noticed that the the one-hot encoded variables presented the highest magnitude among all variables. Additionally, when employing a basic shallow decision tree, the resulting tree structure revealed that the one-hot encoded variables were the most informative. Surprisingly, when I removed these variables, the results given by evaluation metrics worsen. The results also worsen when training models individually for each type of cement in separate datasets.. Similar worsening in results occurred when training models individually on separate datasets for each cement type. Here are statistical summaries for the target variable per cement type: Cement type 1: Mean - 36.672927, Standard Deviation - 1.097930, Number of Samples - 611 Cement type 2: Mean - 47.470623, Standard Deviation - 1.181711, Number of Samples - 421 Cement type 3: Mean - 45.534391, Standard Deviation - 1.604127, Number of Samples - 234 From a domain knowledge perspective, regulatory standards dictate that cement type 1 should have a minimum value of at least 32, type 2 a minimum of 40, and type 3 a minimum of 34. Is it possible that the prominence of these one-hot encoded variables over others stems from the low variability in the target variable per cement type? Additionally, could this be influenced by the possibility that the other variables may exhibit non-linear relationships with the target variable that cannot be captured by the linear model? Might these factors constrain the model's predictions even more restricted to the range of values of the training set, potentially leading to misleading results?
