[site]: crossvalidated
[post_id]: 598924
[parent_id]: 
[tags]: 
Is my model actually overfitting?

I'm working for the first time on my own with a convolutional neural network, and I'm kind of stuck with the same results since the very beginning. My model is built with Pytorch and it has the following structure: Convolutional layer 1 -> Convolutional layer 2 -> Convolutional layer 3 -> MLP (input-hidden-output) I'm trying to use this model for a binary classification task. I have a dataset of 2482 images and as far as I know (from some code that I found) my model has 7010 trainable parameters. Since this size is not enough for training the model from scratch, I'm performing data augmentation in the train split (I'm splitting 90-10%) obtaining 46554 images, which I think it should be enough for a decent training. The problem I'm facing is, with that setup my validation accuracy is not increasing. Moreover, after a few epochs it decreases. Training accuracy increases, so it looks like overfitting but, is this really overfitting? Is a model with 7010 parameters able to overfit a dataset with 46554 images? Any comment/link/reference is appreciated. Thanks in advance
