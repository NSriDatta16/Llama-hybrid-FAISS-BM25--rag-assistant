[site]: crossvalidated
[post_id]: 608729
[parent_id]: 590587
[tags]: 
The evaluation metric you described is similar to the concept of "Cumulative Gain" (CG) in Information Retrieval. CG measures the quality of a ranked list of items by summing up the relevance scores of the items in the list. In your example, the true top k items have a cumulative gain of 19, and the predicted top k items have a cumulative gain of 17 and 16 for the first and second predictions, respectively. By dividing the predicted cumulative gain by the true cumulative gain, you can get a value that indicates the effectiveness of the prediction. It's worth noting that there are several variants of CG, such as Normalized Cumulative Gain (NCG), Discounted Cumulative Gain (DCG), and Normalized Discounted Cumulative Gain (NDCG). These variants differ in how they weight the relevance scores of the items in the list, but the basic idea is the same. I hope this helps! Let me know if you have any other questions.
