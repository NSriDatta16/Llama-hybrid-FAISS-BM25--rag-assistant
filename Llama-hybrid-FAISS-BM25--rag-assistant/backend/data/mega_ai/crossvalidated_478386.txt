[site]: crossvalidated
[post_id]: 478386
[parent_id]: 
[tags]: 
simulation of logistic regression sensitivity to prior probability: Brier score vs accuracy

I wrote a simulation in R that compares performance of a logistic regression as I vary the prior probability of the two classes. The gist is that I do a simulation of data that generates nearly balanced classes and then fit a logistic regression. Then I generate a new response variable, with the original predictors. Next, I take only a fraction of the new data, according to the specified class imbalance, which ranges from $5\%$ being in class $0$ to $95\%$ being in class $0$ . I use my original logistic regression model, trained on balanced classes, to predict both the accuracy (threshold of $0.5$ ) and the Brier score, which is a proper scoring rule. My stance is that the proper scoring rule should be much less sensitive to the class imbalance, and the results show this. However, this feels like cheating! Are these even on the same scale, or have I done something like compare the variance of human heights in feet and dog heights in miles? At the same time, there are no units on either accuracy or Brier score What would be the right way to make this comparison about variability in order to show the lack of sensitivity the proper scoring rule has to the prior probability? (I eventually want to do something like this with a more sophisticated machine learning model, but logistic regression is easy to simulate.) # Taken from: https://stats.stackexchange.com/a/46525/247274 set.seed(2020) N $y == 0) idx1 y == 1) # Subset # select0
