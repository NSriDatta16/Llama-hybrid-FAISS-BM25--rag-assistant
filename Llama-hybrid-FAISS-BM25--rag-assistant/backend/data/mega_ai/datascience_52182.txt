[site]: datascience
[post_id]: 52182
[parent_id]: 52167
[tags]: 
Basically, you need to know about the unsupervised learning tasks in NLP. For this, we mostly vectorize the input sentences using an embedding matrix. Text Summarization: Text Summarization not based on Neural Networks is used in a number of systems. These systems vectorize the input and then rank the sentences using a ranking algorithm ( like TextRank ) and cosine similarity based on their importance. The most important sentences are then given as output. You can read more here . Similarity between two documents: If you have a powerful document vectorizer like Doc2Vec , then the vectors of similar documents are similar to each other with some score. This score can be derived using cosine similarity. A technology blog will have a higher score of similarity with a computer science based blog rather than a holiday/tourism blog. Such systems are useful in many use cases. Clustering algorithms have also been applied here. Sentiment Analysis is not an unsupervised learning task. It is a classification task: For training a sentiment analysis model, you need a dataset which consists of text and its corresponding sentiment ( categorical or binary ). Such a model could not be achieved through clustering or ranking methods. But, yes, these models use word embedding like the other models. Some links which describe the basic tasks categorized under NLP: https://natural-language-understanding.fandom.com/wiki/List_of_natural_language_processing_tasks https://www.analyticsvidhya.com/blog/2017/10/essential-nlp-guide-data-scientists-top-10-nlp-tasks/ “Deep Learning for NLP: An Overview of Recent Trends” by Elvis https://link.medium.com/iItIayc0NW https://blog.algorithmia.com/introduction-natural-language-processing-nlp/
