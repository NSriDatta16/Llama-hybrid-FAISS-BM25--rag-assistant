[site]: datascience
[post_id]: 124787
[parent_id]: 
[tags]: 
Training with few samples, dropping training loss but constant validation loss

I am training a resnet50-based model using transfer learning. My dataset has 10 classes and about 10 occurrences per class, so it is very small. The training loss is decreasing steadily to 0.07 for 100 epochs, but when I validate it on data from another dataset the validation loss is almost constant, approximately 0.7Â±0.1. The test data comes from another dataset that I cannot use for training, it has the same classes present but occurrences of multiple classes in the same file, in contrast to the training data, where each file has only one class. Could this be the reason of the poor performance with the validation data? I would expect that if I train with files with one class per file, the model learns to recognize multiple classes in one file as well. I am new to deep learning, so this is a bit fuzzy for me and I would be happy to get some expert advice.
