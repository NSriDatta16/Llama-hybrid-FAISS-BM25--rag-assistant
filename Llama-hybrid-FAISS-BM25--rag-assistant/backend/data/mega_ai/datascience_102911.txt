[site]: datascience
[post_id]: 102911
[parent_id]: 
[tags]: 
Multiple models have extreme differences during evaluation

My dataset has about 100k entries, 6 features, and the label is simple binary classification (about 65% zeros, 35% ones). When I train my dataset on different models: random forest, decision tree, extra trees, k-nearest neighbors, logistic regression, sgd, dense neural networks, etc, the evaluations differ GREATLY from model to model. tree classifiers: about 80% for both accuracy and precision k-nearest neighbors: 56% accuracy and 36% precision. linear svm: 65% accuracy and 0 positives guessed sgd : 63% accuracy and 2 true positives + 4 false positives I don't understand the difference in such disparity. Can someone explain why that happens? Am I doing something wrong? Also cannot find an answer to my question, so please link if someone asked it already Would really appreciate the help!
