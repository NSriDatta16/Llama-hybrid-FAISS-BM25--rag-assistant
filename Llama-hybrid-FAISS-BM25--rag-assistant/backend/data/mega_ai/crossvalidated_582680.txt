[site]: crossvalidated
[post_id]: 582680
[parent_id]: 123619
[tags]: 
if you use SVM , you can assign param class_weight=balanced => weights will be taken into consideration by classifier when training (look sklearn docs) if you want to make threshold different than 0.5. => you can move threshold - THE WAY: if you think false positives are worse than false negatives - you can take this into consideration in costs in the code OR on the stage of decision-making [NB use predict_proba for newly predicted sample & compare it with threshold you decided - e.g. estimator.predict_proba() P.S. but also take a look here Are unbalanced datasets problematic AND here - Is threshold moving unnecessary in balanced classification problem
