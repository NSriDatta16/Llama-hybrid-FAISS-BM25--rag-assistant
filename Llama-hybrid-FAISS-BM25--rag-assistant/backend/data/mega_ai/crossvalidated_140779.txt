[site]: crossvalidated
[post_id]: 140779
[parent_id]: 
[tags]: 
How best to identify candidate error-prone independent variables

I am working on some blood flow data, obtained through doppler. The resulting dataset is a time series, in which each row consists of the following variables: timestamp vessel cross sectional area (double precision float, $A_{vessel}$) beam incidence angle (double precision float) blood velocity (double precision float, $V_{blood}$) blood flow (double precision float, calculated as $\dot{Q}_{blood}=V_{blood}*A_{vessel}$ ) My problem is that flow values, even when corrected for the angle of incidence, yield unrealistically high values. How can I quantify the role of each independent variable participating in the blood flow variability, since I suspect this would be a good way of detecting the culprit variable? Would a spearman correlation be a suitable test? And could someone please tell me if the below reasoning seems correct? Or am I doing this wrong? I tried to eyeball the distributions, which after removing the ouliers using $Z_{score} From those graphs, I suspect an imprecision in blood velocity measurements, since the flow distribution closely follows the velocity distribution. Furthermore, the velocity distribution seems to still have a lot of outliers on the upside, as I suspect by looking at its boxplot. Angle also seems to have a lot of outliers, but since its distribution is closer to a gaussian shape, I infer it has less of a chance to be the problem. Finally, the imprecision in measurements seems systematic, as can be suspected by looking at the following graph (the cumulative sum of flow is linear, and its derivative is flat)
