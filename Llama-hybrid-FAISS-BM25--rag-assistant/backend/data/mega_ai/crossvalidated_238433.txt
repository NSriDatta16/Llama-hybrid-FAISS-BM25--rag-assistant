[site]: crossvalidated
[post_id]: 238433
[parent_id]: 
[tags]: 
Grid tuning CV: Full blown vs limited

I am doing grid based parameter search using CV for my XGBoost model in R. Code is for reference but question below is lot generic: opt1 0)/nrow(base_data))) opt2 0)/nrow(base_data))) searchGridSubCol I ran my model for nrounds = 500 but time taken when using grid combinations in (unexpectedly) non-linearly growing. So I want to cut time for grid search. I found 500 is good limit for grid search in my case, as most cases model overfitting start before 500 iterations. So this is full blown CV . However to save time I want to just run each combination for say 100 or 200 iterations and compare (this I am calling limited CV ). What is shortcoming of limited CV Vs full blown CV for grid search; apart from not be able to get statistically sound estimate for RMSE (in my case). Can optimal parameters of limited CV can be different than full blown CV if yes then why? In other words is it always necessary to run till overfitting is detected when doing hyperparameter tuning?
