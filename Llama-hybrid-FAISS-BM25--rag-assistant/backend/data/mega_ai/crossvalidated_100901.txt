[site]: crossvalidated
[post_id]: 100901
[parent_id]: 100728
[tags]: 
For the Stata commands in this answer let me collect your variables in a local: local xlist sse01 wartosc_sr_trw_per_capita zatr_przem_bud podm_gosp_na_10tys_ludn proc_ludn_wiek_prod ludnosc_na_km2 So now you can always call all the variables with `xlist' 1) There are two commands that you can use after your fixed effects regression. xttest2 performs a Breusch-Pagan LM test with the null hypothesis of no dependence between the residuals. This is a test for contemporaneous correlation. Not rejecting the null means that the test did not detect any cross-sectional dependence in your residuals. xttest3 performs a modified version of the Wald test for groupwise heteroscedasticity. The null hypothesis is homoscedasticity. You can install both commands by typing ssc instal xttest2 and ssc instal xttest3 . If you detect correlations between your residuals you can correct for this with the robust option: xtreg st_bezr 'xlist', fe robust To test for autocorrelation you can apply a Lagrange Multiplier test via xtserial : xtserial st_bezr 'xlist' The null hypothesis is no serial correlation. To correct for both serial correlation and heteroscedasticity you can use the cluster option with your id variable: xtreg st_bezr 'xlist', fe cluster(id) 2) For the normality test for the residuals: you can obtain the residuals via the predict command predict res, e after your fixed effects regression. For visual inspection you can use: kdensity res, normal (plots the distribution of the residuals and compares it to a normal) pnorm res (plots a standardized normal probability plot) qnorm res (plots the quantiles of the residuals against the quantiles of a normal distribution) With pnorm you can see if there is non-normality in the middle of the distribution and qnorm shows you any non-normality in the tails. A formal test can be obtained by swilk res . The null hypothesis is that the residuals are normally distributed. Generally, non-normality is not a too big concern but it matters for inference. You can again correct for this with the robust option. 3) Having corr(u_i, Xb) = -0.9961 means that the fixed effects are strongly correlated with your explanatory variables, so you did well by controlling for these fixed effects. A strong correlation of this type usually indicates that pooled OLS or random effects will not be suitable for your purpose because both of these models assume that the correlation between $u_i$ and $X\beta$ is zero. 4) Generally yes but it depends what you want to estimate or how you can treat your data, i.e. whether your variables are random variables or not. Here is an excellent explanation for the difference between mixed effects and panel data models by @mpiktas which will surely help you.
