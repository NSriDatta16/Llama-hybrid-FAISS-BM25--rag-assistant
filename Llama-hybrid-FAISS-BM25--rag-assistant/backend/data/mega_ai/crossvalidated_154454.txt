[site]: crossvalidated
[post_id]: 154454
[parent_id]: 154415
[tags]: 
PCA and CFA are highly subjective techniques with many heuristics, options and rules of thumb. For instance, there is no test for choosing between oblique and orthogonal rotations. It's simply a matter of analyst preference that can have significant downstream implications as a function of the choice made. For another, one commonly applied rule of thumb is that the component eigenvalues should have a minimum value of 1.0, the logic being that any preserved component should contribute at least as much to the overall variance as a single variable. For your data, this would give only two components, not three. The next thing is that OLS PCA is not scale invariant. You state that you "normalized" your data, including removing some outliers. There may be a problem with terminology here but, for me, "normalizing" refers to mean centering only where "standardizing" refers to transforming the data into an orthonormal basis function that is mean centered with a standard deviation of one. If you only mean centered your data, then your results would be erroneous in OLS PCA. The other thing is that removing outliers is always a bad idea. There's simply too much information in these outliers to warrant deleting them. Not to mention that deleting a first pass of outliers typically creates a new round of outliers, and so on, producing a fruitless, pointless infinite series of outlier deletions. 20th c statistical techniques such as Winsorizing, trimming and the whole boatload of techniques involving grooming data to a more "normal" PDF is really dumb. Use robust techniques instead.
