[site]: datascience
[post_id]: 31109
[parent_id]: 
[tags]: 
Ratio between embedded vector dimensions and vocabulary size

Using Embedding layer in Keras on a fairly small vocabulary (~300), I am looking at how to choose the output of this layer (dense vector) when given a 300 dimension vector. I think that the embedded vector need to have a minimum length to be able to map a given vocabulary.
