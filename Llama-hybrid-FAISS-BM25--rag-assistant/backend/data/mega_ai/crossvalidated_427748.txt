[site]: crossvalidated
[post_id]: 427748
[parent_id]: 
[tags]: 
What does it mean when someone says they have sparse labels?

I'm going through the Hands-On Machine Learning book with Scikit-Learn and TF by Aurelion Geron and I've come across the notion of choosing a specific loss function due to the data having sparse labels. The specific quote is This code requires some explanation. First, we use the "sparse_categorical_crossentropy" loss because we have sparse labels (i.e., for each instance, there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. If instead we had one target probability per class for each instance (such as one-hot vectors, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need to use the "categorical_crossentropy" loss instead. The thing is this is different than my understanding of a sparse vector where most of the values are 0. So what are sparse labels?
