[site]: crossvalidated
[post_id]: 124857
[parent_id]: 
[tags]: 
Implementation of Bayes posterior predictive check

I have a question concerning the implementation of a bayes posterior predictive check. Let us assume i have this model (implementation is in R and jags): model { for( i in 1 : N ) { y[i] ~ dlnorm( mu , 1/sig^2 ) } sig ~ dunif( 0.01 , 1000 ) mu ~ dnorm( 0,1E-6 ) } I want to estimate the parameters of a lognormal distribution given some data $y$. For the both parameters of the lognormal i use an uninformative prior distribution. I carry out the mcmc sampling using (code is form the book "Doing bayesian data analysis"): parameters = c("mu" , "sig") adaptSteps = 1000 burnInSteps = 1000 nChains = 3 numSavedSteps=30000 thinSteps=1 nPerChain = ceiling( ( numSavedSteps * thinSteps ) / nChains ) # Create, initialize, and adapt the model: jagsModel = jags.model( "model.txt" , data=datalist , n.chains=nChains , n.adapt=adaptSteps ) # Burn-in: cat( "Burning in the MCMC chain...\n" ) update( jagsModel , n.iter=burnInSteps ) # The saved MCMC chain: cat( "Sampling final MCMC chain...\n" ) codaSamples = coda.samples( jagsModel , variable.names=parameters , n.iter=nPerChain , thin=thinSteps ) mcmcChain = as.matrix( codaSamples ) chainLength = NROW(mcmcChain) mu Now i want to check, how exact my model fits the dataset. According to Gleman (2003, P.162), i have $L$ simulations from the posterior density of the parameters mu and sig. For each of the $L$ parameters i simulated a new dataset and calculate the test statistic with this new dataset and the original dataset and compare the results. My algorithm looks like this: result = t(log(y),mu[i]) } The function $t$ is the test statistic and checks if the model is adequate except for the extreme tails. It is defined like this: $$T(y,m) = |y_{x_1} - m | - |y_{x_2} - m|$$ where $x_1$ and $x_2$ are chosen to represent approximately 90 and 10 percent of the distribution (see Gelman 2003, P.165). Is this the right approach? If yes, would it be enough to use the parameter values in the highest density interval only? I am fairly new to bayesian statistics so i am unsure if i understood the whole procedure. And is there a better test statistic? I know that my data will be approximately lognormal. But at least in the lower tails there will be a lot of noise (the data are diameter distributions of particles recorded continuously by an optical sensor with limited resolution). In future the algorithm should run from time to time during the recording and send a notification when there is a huge deviation from the lognormal model. Thanks for the help! Here is the complete source modelstring = " model { for( i in 1 : N ) { y[i] ~ dlnorm( mu , 1/sig^2 ) } sig ~ dunif( 0.01 , 1000 ) mu ~ dnorm( 0,1E-6 ) } " # close quote for modelstring writeLines(modelstring,con="model.txt") y = t(log(y),mu[i]) } t Reference: 2003 "Bayesian Data Analysis", Andrew Gelman et. al
