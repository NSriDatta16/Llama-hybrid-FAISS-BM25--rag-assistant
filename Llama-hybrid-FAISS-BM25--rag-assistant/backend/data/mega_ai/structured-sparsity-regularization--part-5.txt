ch define hypothesis spaces. Finite dictionaries can be used to define specific kernels, as will be shown. Assume for this example that rather than only one dictionary, several finite dictionaries are considered. For simplicity, the case in which there are only two dictionaries A = { a j : X → R , j = 1 , . . . , p } {\displaystyle A=\{a_{j}:X\rightarrow \mathbb {R} ,j=1,...,p\}} and B = { b t : X → R , t = 1 , . . . , q } {\displaystyle B=\{b_{t}:X\rightarrow \mathbb {R} ,t=1,...,q\}} where q {\displaystyle q} and p {\displaystyle p} are integers, will be considered. The atoms in A {\displaystyle A} as well as the atoms in B {\displaystyle B} are assumed to be linearly independent. Let D = { d k : X → R , k = 1 , . . . , p + q } = A ∪ B {\displaystyle D=\{d_{k}:X\rightarrow \mathbb {R} ,k=1,...,p+q\}=A\cup B} be the union of the two dictionaries. Consider the linear space of functions H {\displaystyle H} given by linear combinations of the form f ( x ) = ∑ i = 1 p + q w j d j ( x ) = ∑ j = 1 p w A j a j ( x ) + ∑ t = 1 q w B t b t ( x ) , x ∈ X {\displaystyle f(x)=\sum _{i=1}^{p+q}{w^{j}d_{j}(x)}=\sum _{j=1}^{p}{w_{A}^{j}a_{j}(x)}+\sum _{t=1}^{q}{w_{B}^{t}b_{t}(x)},x\in X} for some coefficient vectors w A ∈ R p , w B ∈ R q {\displaystyle w_{A}\in \mathbb {R} ^{p},w_{B}\in \mathbb {R} ^{q}} , where w = ( w A , w B ) {\displaystyle w=(w_{A},w_{B})} . Assume the atoms in D {\displaystyle D} to still be linearly independent, or equivalently, that the map w = ( w A , w B ) ↦ f {\displaystyle w=(w_{A},w_{B})\mapsto f} is one to one. The functions in the space H {\displaystyle H} can be seen as the sums of two components, one in the space H A {\displaystyle H_{A}} , the linear combinations of atoms in A {\displaystyle A} and one in H B {\displaystyle H_{B}} , the linear combinations of the atoms in B {\displaystyle B} . One choice of norm on this space is | | f | | = | | w A | | + | | w B | | {\displaystyle ||f||=||w_{A}||+||w_{B}||} . Note that we can now view H {\displaystyle H} as a function space in which H A {\displaystyle H_{A}} , H B {\displaystyle H_{B}} are subspaces. In view of the linear independence assumption, H {\displaystyle H} can be identified with R p + q {\displaystyle \mathbb {R} ^{p+q}} and H A , H B {\displaystyle H_{A},H_{B}} with R p , R q {\displaystyle \mathbb {R} ^{p},\mathbb {R} ^{q}} respectively. The norm mentioned above can be seen as the group norm in H {\displaystyle H} associated to the subspaces H A {\displaystyle H_{A}} , H B {\displaystyle H_{B}} , providing a connection to structured sparsity regularization. Here, H A {\displaystyle H_{A}} , H B {\displaystyle H_{B}} and H {\displaystyle H} can be seen to be the reproducing kernel Hilbert spaces with corresponding feature maps Φ A : X → R p {\displaystyle \Phi _{A}:X\rightarrow \mathbb {R} ^{p}} , given by Φ A ( x ) = ( a 1 ( x ) , . . . , a p ( x ) ) {\displaystyle \Phi _{A}(x)=(a_{1}(x),...,a_{p}(x))} , Φ B : X → R q {\displaystyle \Phi _{B}:X\rightarrow \mathbb {R} ^{q}} , given by Φ B ( x ) = ( b 1 ( x ) , . . . , b q ( x ) ) {\displaystyle \Phi _{B}(x)=(b_{1}(x),...,b_{q}(x))} , and Φ : X → R p + q {\displaystyle \Phi :X\rightarrow \mathbb {R} ^{p+q}} , given by the concatenation of Φ A , Φ B {\displaystyle \Phi _{A},\Phi _{B}} , respectively. In the structured sparsity regularization approach to this scenario, the relevant groups of variables which the group norms consider correspond to the subspaces H A {\displaystyle H_{A}} and H B {\displaystyle H_{B}} . This approach promotes setting the groups of coefficients corresponding to these subspaces to zero as opposed to only individual coefficients, promoting sparse multiple kernel learning. The above reasoning directly generalizes to any finite number of dictionaries, or feature maps. It can be extended to feature maps inducing infinite dimensional hypothesis spaces. When Sparse Multiple Kernel Learning is useful Considering sparse multiple kernel learning is useful in several situations in