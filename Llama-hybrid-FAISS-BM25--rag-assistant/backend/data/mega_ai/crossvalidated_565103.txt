[site]: crossvalidated
[post_id]: 565103
[parent_id]: 219619
[tags]: 
overfitting will happen if one searches for a model hard enough , unless one imposes restrictions on model complexity, period I guess the simple answer is yes , if the search space (complexity of considered model class(es)) is large enough). If data is the new oil , then note that oil is usually burnt during use. Consider training a gazillion of random forests by tuning the random seed. One of them will by chance be optimal on the test set. Cross validation won't change this result in the end. More recently, the "double decent" was discovered, see for example [1] and the review [2]. There is a whole new regime for overparametrized models that interpolate the training data . In this regime, the notion of overfitting is not adequate anymore. If a model is very much overparametrized, it may (or may not) have a better statistical risk (generalization error) than the optimal point in the classical bias-variance-trade-off regime. [1] Belkin, Hsu, Xu "Two Models of Double Descent for Weak Features" 2020, https://epubs.siam.org/doi/10.1137/20M1336072 [2] Dar, Muthukumar, Baraniuk "A Farewell to the Bias-Variance Tradeoff? An Overview of the Theory of Overparameterized Machine Learning" 2021, https://arxiv.org/abs/2109.02355
