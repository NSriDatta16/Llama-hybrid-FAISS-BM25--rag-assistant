[site]: crossvalidated
[post_id]: 86390
[parent_id]: 86378
[tags]: 
Do I understand correctly: PCA calculates $p$ scores $\mathbf T^{(n \times p)}$ from data $mathbf X^{(n \times m)}$ using the transpose of the loadings $\mathbf P^{(p \times m)}$: $\mathbf T = \mathbf X \mathbf P^T$ then the OLS calculates some $Y^{(n \times 1)}$ using coefficients $\beta^{(p \times 1)}$: $Y = \mathbf T \beta$, together: $Y = \mathbf X \mathbf P^T \beta = \mathbf X \mathbf B$ with $\mathbf B^{(m \times 1)} = \mathbf P^T \beta$ And now you want to have some indication of the variance of $\mathbf B$? First of all, in order to get confidence intervals for $\mathbf B$ you need to consider both the PCA and the regression. Calculating confidence intervals for $\beta$ alone doesn't make sense: PCA is not a projection that is unique, i.e. the axes can flip without notice. In addition for your PCR model, in the $p$-dimensional space of the retained PCs you can also have rotations which do not affect the predictions if $\beta$ changes accordingly. I suspect that not taking care of these equivalence rules (= restrictions/contraints) is what causes the $\pm \infty$ range in @whuber's comment. I think of this as: what happens to my model if I acquire a new data set and fit a new model. The models can be equivalent (having the same $\mathbf B$), but different loadings $\mathbf P$ and regression coefficients $\beta$. Now I have no idea how to get confidence intervals for the PCA, and then how to combine these two given the equvalence contraints. I usually go a much easier way: I bootstrap $\mathbf B$ during a resampling (out-of-bootstrap) validation. (So far I don't need confidence intervals for $\mathbf B$, for my purposes the distribution of observed $\mathbf B$s over the bootstrapping is good enough - I need "hard numbers" only on the predictive power)
