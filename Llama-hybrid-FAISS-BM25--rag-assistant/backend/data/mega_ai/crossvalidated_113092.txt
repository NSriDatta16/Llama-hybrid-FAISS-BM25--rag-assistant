[site]: crossvalidated
[post_id]: 113092
[parent_id]: 
[tags]: 
In Bayesian hypothesis testing, do the prior model probabilities have to be equal?

The posterior odds is the product of the Bayes factor and prior odds: $\frac{p(M_1|data)}{p(M_2|data)}=\frac{p(data|M_1)}{p(data|M_2)}\times\frac{p(M_1)}{p(M_2)}$. I was under the impression that the prior model odds could be specified as anything by the analyst, but then I read a passage in a psychology paper, Myung and Pitt (1997, p. 84) which states, p(M1) represents the probability that the model M1 is a true description of the events under study before data are collected. For real-world problems, this probability may not exist, or not be known even if it does. We assume equal model priors; that is, p(M1)/p(M2). This assumption is often made by researchers in Bayesian model selection...and is an unavoidable simplification of a problem for which there is not as yet a satisfactory solution. An implication of the assumption is that model selection is based solely on the Bayes factor. The decision to ignore model priors does not undermine use of the Bayesian approach. It appears that they are stating that specifying equal prior probabilities is necessary (i.e., "unavoidable"), but this seems contrary to other things I have read and the structure of the equation above. So must the prior odds be set to 1? Myung, I. J., & Pitt, M. A. (1997). Applying Occamâ€™s razor in modeling cognition: A Bayesian approach. Psychonomic Bulletin & Review , 4 , p. 79-95.
