[site]: crossvalidated
[post_id]: 562740
[parent_id]: 
[tags]: 
Conflicting omnibus results for a mixed-effects model

I am attempting to get omnibus tests of interactions with a multicategorical variable ("strategy") in mixed-effects models. When running this in lmerTest::lmer , I noticed that the results from car::Anova and anova.lmerTest differed in ways that suggest different conclusions (i.e., an effect that was nonsignificant with Anova was significant with anova ). Given that I am receiving different results from these functions, I am unsure what is most appropriate for this situation. I expect small variations, especially using Ward chi-squared tests compared to an F test with Kenward-Roger or Satterthwaite degrees of freedom. However, the differences I am seeing are larger than I'd expect and suggest different conclusions. Here is the summary of the model: For context: Data comes from an intensive longitudinal (ecological momentary assessment) study where individuals completed surveys over several days Group is a person-level factor Strategy is a multicategorical factor and repeated within survey (every row is a strategy per survey per day per person) The main variable of interest is the autoregressive slope of negative affect > summary(model) Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest'] Formula: na.t2 ~ group * strategy * na + (na | id/day) Data: ema_long_refnone_std REML criterion at convergence: 5237.9 Scaled residuals: Min 1Q Median 3Q Max -4.9441 -0.4330 -0.1505 0.2386 7.2226 Random effects: Groups Name Variance Std.Dev. Corr day:id (Intercept) 0.034712 0.18631 na 0.039280 0.19819 0.88 id (Intercept) 0.225537 0.47491 na 0.006272 0.07919 -0.50 Residual 0.354287 0.59522 Number of obs: 2599, groups: day:id, 503; id, 103 Fixed effects: Estimate Std. Error df t value Pr(>|t|) (Intercept) -0.24685 0.07160 75.18233 -3.447 0.00093 *** groupSZ 0.53314 0.10524 77.90156 5.066 2.66e-06 *** strategyreappraising 0.10582 0.10326 2398.36079 1.025 0.30558 strategysharing 0.07288 0.12775 2390.80108 0.570 0.56841 strategyattention 0.09886 0.10047 2397.50742 0.984 0.32524 strategyavoiding 0.11431 0.15337 2357.23408 0.745 0.45617 strategyhiding -0.17877 0.17337 2362.62142 -1.031 0.30260 na 0.22424 0.04090 89.46584 5.482 3.84e-07 *** groupSZ:strategyreappraising -0.17355 0.13489 2419.49560 -1.287 0.19837 groupSZ:strategysharing -0.13001 0.15574 2432.98603 -0.835 0.40392 groupSZ:strategyattention -0.18011 0.13435 2420.15624 -1.341 0.18017 groupSZ:strategyavoiding -0.20555 0.17882 2369.30664 -1.149 0.25048 groupSZ:strategyhiding 0.17198 0.25925 2326.81740 0.663 0.50716 groupSZ:na 0.07377 0.05566 90.68751 1.326 0.18833 strategyreappraising:na -0.17487 0.12249 2060.50288 -1.428 0.15353 strategysharing:na -0.38368 0.12249 1990.48877 -3.132 0.00176 ** strategyattention:na -0.17019 0.12635 2201.69278 -1.347 0.17812 strategyavoiding:na -0.19486 0.15403 2253.50623 -1.265 0.20598 strategyhiding:na -0.15712 0.21971 2282.06633 -0.715 0.47460 groupSZ:strategyreappraising:na 0.15704 0.13987 2167.65742 1.123 0.26167 groupSZ:strategysharing:na 0.32126 0.13994 2094.83522 2.296 0.02179 * groupSZ:strategyattention:na 0.03436 0.14744 2273.55364 0.233 0.81576 groupSZ:strategyavoiding:na 0.12592 0.16818 2279.34457 0.749 0.45410 groupSZ:strategyhiding:na 0.07480 0.26795 2298.17673 0.279 0.78015 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 and the omnibus tests: > # Anova Wald > Anova(model, type = "III") Analysis of Deviance Table (Type III Wald chisquare tests) Response: na.t2 Chisq Df Pr(>Chisq) (Intercept) 11.8848 1 0.0005659 *** group 25.6659 1 4.059e-07 *** strategy 3.7701 5 0.5829610 na 30.0546 1 4.200e-08 *** group:strategy 4.7006 5 0.4535018 group:na 1.7570 1 0.1850037 strategy:na 11.8744 5 0.0365499 * group:strategy:na 5.8978 5 0.3162926 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 > # Anova Kenward-Roger > Anova(model, type = "III", test.statistic = "F") Analysis of Deviance Table (Type III Wald F tests with Kenward-Roger df) Response: na.t2 F Df Df.res Pr(>F) (Intercept) 11.8073 1 99.84 0.0008612 *** group 25.5020 1 105.01 1.871e-06 *** strategy 0.7499 5 2344.18 0.5860915 na 28.6949 1 76.67 8.590e-07 *** group:strategy 0.9312 5 2363.35 0.4594962 group:na 1.6853 1 75.60 0.1981660 strategy:na 2.3227 5 2165.96 0.0408497 * group:strategy:na 1.1599 5 2237.36 0.3266031 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 > # anova Satterthwaite (lmerTest default) > anova(model, type = "III") Type III Analysis of Variance Table with Satterthwaite's method Sum Sq Mean Sq NumDF DenDF F value Pr(>F) group 4.4889 4.4889 1 153.09 12.6701 0.0004952 *** strategy 0.2425 0.0485 5 2305.85 0.1369 0.9837937 na 3.8407 3.8407 1 395.87 10.8408 0.0010821 ** group:strategy 1.6654 0.3331 5 2305.85 0.9401 0.4537256 group:na 1.8069 1.8069 1 395.87 5.1002 0.0244674 * strategy:na 4.8255 0.9651 5 2165.85 2.7241 0.0184565 * group:strategy:na 2.0895 0.4179 5 2165.85 1.1796 0.3166858 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 > # anova Kenward-Roger > anova(model, type = "III", ddf = "Kenward-Roger") Type III Analysis of Variance Table with Kenward-Roger's method Sum Sq Mean Sq NumDF DenDF F value Pr(>F) group 4.4554 4.4554 1 206.38 12.5756 0.0004836 *** strategy 0.2409 0.0482 5 2363.35 0.1360 0.9840286 na 3.7434 3.7434 1 321.57 10.5659 0.0012739 ** group:strategy 1.6496 0.3299 5 2363.35 0.9312 0.4594962 group:na 1.7611 1.7611 1 321.57 4.9708 0.0264686 * strategy:na 4.7321 0.9464 5 2237.36 2.6711 0.0205179 * group:strategy:na 2.0548 0.4110 5 2237.36 1.1599 0.3266031 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 While most results are consistent, the group:na interaction is different in anova.lmerTest compared to car::Anova in both cases for each. One thing that sticks out to me is that the residual/denominator degrees of freedom are comparable for omnibus tests of only categorical variables but are very different for na and group:na . Any thoughts on what might be driving this or which test would be most appropriate to report/act on?
