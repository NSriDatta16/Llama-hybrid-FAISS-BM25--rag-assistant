[site]: crossvalidated
[post_id]: 271091
[parent_id]: 268874
[tags]: 
Philosophically, two basic approaches present themselves here. One approach is to seek off-the-shelf models that (supposedly) enable you to 'extract' or 'derive' knowledge from your data. I would identify that approach with inductivism . Karl Popper famously called induction "a myth," and I share his view. Inductivism remains, however, the dominant epistemology in the (clinical) medical sciences at this time. Its spirit is nowhere more vividly represented than in the field of 'data science', the basic premise of which (it seems to me) is that data are like underground ore deposits to be 'mined', and that for this we need only to employ the right 'earth-moving equipment' (i.e., techniques or methods ). An alternative spirit is that of 'Strong Inference' described in a famous essay by Platt [1,2]. Here, the focus is on building and testing theories . Notwithstanding the strong 'inductivist' leanings of many Bayesians, I think Bayesian methods (as distinct from 'Bayesian ism ') make a very suitable basis for pursuing strong inference. If you are interested, I would be glad to assist you in pursuing that course. Presently, your simulation code generates data having the formal appearance of the sort of data you might collect, but not their informational content . To achieve the latter, you would need to write in some equations (models) of a data generating process ( DGP ) describing what might be going on 'beneath the surface' in your data. If you could add such equations, I would propose to show you how to implement your model in JAGS , a fully declarative Bayesian modeling tool that has the lovely property of letting you run the very same model both 'forwards' (from given parameters to simulated data) and 'backwards' (from measured data to inference about unknown parameters). This approach would – as its first and perhaps most important benefit – enable you to check whether various theories you might consider (as expressed in your models of the DGP) would yield to exploration in different regimes of sample size . If your actual sample sizes are of the order of the $N=50$ individuals of your simulation (split across 5 categorical disease sub-types, no less), then I would not hold out great hopes of learning anything new that isn't already 'obvious' to clinicians treating these types of cancer. But this approach would let you demonstrate such an intuition objectively, at least. Platt JR. Strong Inference: Certain systematic methods of scientific thinking may produce much more rapid progress than others. Science. 1964;146(3642):347-353. doi:10.1126/science.146.3642.347 . Fudge DS. Fifty years of J. R. Platt’s strong inference. Journal of Experimental Biology. 2014;217(8):1202-1204. doi:10.1242/jeb.104976 .
