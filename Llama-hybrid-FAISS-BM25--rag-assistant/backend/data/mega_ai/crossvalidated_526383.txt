[site]: crossvalidated
[post_id]: 526383
[parent_id]: 
[tags]: 
When should a problem be approached as a sequential one?

I am working on a problem with a dataset of the form $(x_j,t_i,y_{i,j} )_{(j,i) \in J \times I}$ where $y_{i,j}$ is the output label. Think of progression of illness over time or weather conditions over an area. The labelling is done on new features $x$ that are not in the training set, and no initial $y$ is provided for this $x$ . Here $x_j$ does not vary over time, so the only variable to vary sequentially is time itself. So, I don't see any benefit in using RNN/transformers/LSTM over non-sequential ANN architectures. In the weather example above I can try to approach this problem by thinking of it as a generalized interpolation $f(x_n,\prod y_{i,j},t_i) = y_{i,n}$ , and I can try to generalize this to the illness example. In that case it may make sense for me to use sequential ANN architectures like RNN's. However, I have been specifically asked not to do this. Obviously, I can try both and pick the one that works the best, but I would still like to know if there's a theoretical construct that can help in picking which approach is the better, or even the most likely better, one. I have tried to modify the various stochastic versions of well-posedness of problems. However, so far I have not found a satisfactory formulation of an argument despite my intuition saying that it should work; Especially since another part of my intuition says that using an RNN cannot hurt either (it just doesn't confer any benefits over other ANN's)
