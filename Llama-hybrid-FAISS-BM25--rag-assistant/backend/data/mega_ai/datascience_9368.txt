[site]: datascience
[post_id]: 9368
[parent_id]: 9364
[tags]: 
Whenever I work with xgboost I often make my own homebrew parameter search but you can do it with the caret package as well like KrisP just mentioned. Caret See this answer on Cross Validated for a thorough explanation on how to use the caret package for hyperparameter search on xgboost. How to tune hyperparameters of xgboost trees? Custom Grid Search I often begin with a few assumptions based on Owen Zhang 's slides on tips for data science P. 14 Here you can see that you'll mostly need to tune row sampling, column sampling and maybe maximum tree depth. This is how I do a custom row sampling and column sampling search for a problem I am working on at the moment: searchGridSubCol And combined with some ggplot2 magic using the results of that apply function you can plot a graphical representation of the search. In this plot lighter colors represent lower error and each block represents a unique combination of column sampling and row sampling. So if you want to perform an additional search of say eta (or tree depth) you will end up with one of these plots for each eta parameters tested. I see you have a different evaluation metric (RMPSE), just plug that in the cross validation function and you'll get the desired result. Besides that I wouldn't worry too much about fine tuning the other parameters because doing so won't improve performance too much, at least not so much compared to spending more time engineering features or cleaning the data. Others Random search and Bayesian parameter selection are also possible but I haven't made/found an implementation of them yet. Here is a good primer on bayesian Optimization of hyperparameters by Max Kuhn creator of caret. http://blog.revolutionanalytics.com/2016/06/bayesian-optimization-of-machine-learning-models.html
