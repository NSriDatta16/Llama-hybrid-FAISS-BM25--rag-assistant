[site]: crossvalidated
[post_id]: 419372
[parent_id]: 
[tags]: 
Random Forest Underperforms Median on Training Set for Toy Regression Problem

I have found that random forests is failing on a toy regression problem. My prior impression of random forests is that it is very robust, so I expected that, on the training set, it should always outperform the median (predicting the median response for all inputs, which I take to be a notable benchmark for any regression problem). However, for some simple random data, I have found this to not be the case. Specifically, in R: set.seed(77) features = data.frame( a=rnorm(4200), b=rnorm(4200)) response = rnorm(4200) mean( ( response - median(response))^2 ) rf.sim setting maxnodes = 1 helps more than anything so far, but it still underperforms slightly. I have read that random forests is resistant to overfitting, so maybe this partially explains the results. What is the reason that random forest cannot beat the median here, and is there some tuning that would allow it to do so? Also, pursuant to that, what are the options for increasing overfitting in this situation?
