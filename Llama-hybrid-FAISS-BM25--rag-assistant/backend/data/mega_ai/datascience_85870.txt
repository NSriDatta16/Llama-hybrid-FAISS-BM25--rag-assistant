[site]: datascience
[post_id]: 85870
[parent_id]: 85813
[tags]: 
There are two main problems - You have one Feature which is correlated ( multi-collinearity) to all the others. If you are trying to solve using " closed-form solution ", the following will happen $y = w_0 + w_1X_1 + w_2X_2 + w_3X_3$ $w_0$ is the $y$ intercept and to complete the matrix form 1= $X_0$ . Hence, $y = w_0X_0 + w_1X_1 + w_2X_2 + w_3X_3$ Solution for $w$ is $(X^{T}X)^{-1}X^{T}y$ So, X must be an Invertible Matrix. But, If the model contains dummy variables for all values, then the encoded columns would add up (row-wise) to the intercept ( $X_0$ here)(See below table) and this linear combination would prevent the matrix inverse from being computed (as it is singular). \begin{array} {|r|r|} \hline X_0 & X1 &X2 &X3 \\ \hline 1 &1 &0 &0 \\ \hline 1 &0 &1 &0 \\ \hline 1 &0 &0 &1 \\ \hline \end{array} why my model got successfully trained at all since if the article is to be believed, the transposition error should have prevented it from being successfully trained. Valid question! Aurelien Geron(Author of " Hands-On Machine Learning " has answered Here . - The LinearRegression(Scikit-Learn) class actually performs SVD decomposition, it does not directly try to compute the inverse of X.T.dot(X). The singular values of X are available in the singular_ instance variable, and the rank of X is available as rank_ On Performance In a practically large dataset, a closed-form solution is not preferred. May use an Iterative approach algorithm i.e. Gradient-Descent Multi-collinearity too, will not impact the performance but Interpretability of Features. Coeff changes depending upon which dummy is removed - This is obvious as each dummy is now a Feature with a different level of contribution (based on data) . The only thing that is sure is their effect together and one-less is the same. The inconsistent result you are getting should be due to some other issue. Dummy-variable Trap I have never heard of this term except " Udemy course A-Z ML ". So I don't think that there is any special meaning of the word "trap" if you understand the points( i.e. Singularity, Multi-collinearity, and Interpretability) separately References - www.feat.engineering - Sec#5.1 Sebastian Raschka stats.stackexchange
