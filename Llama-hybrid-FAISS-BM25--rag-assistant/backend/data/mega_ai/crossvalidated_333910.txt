[site]: crossvalidated
[post_id]: 333910
[parent_id]: 
[tags]: 
R-Square Change in a Multivariate Regression

I am investigating whether the predictive validity of the Big Five personality traits can be improved by controlling for sources of self-report error (e.g. memory, interpretation biases, ect.). I am specifically interested in identifying the confounding variables with the strongest effects. To ensure that I am testing general differences in predictive validity, I would like to consider three outcome variables simultaneously (a,b,c), known to correlate strongly with two of the Big Five traits (Neuroticism and Extraversion) Thus, I conducted several hierarchical multivariate regressions in the following form: BaseModel Confound.1.Model anova(BaseModel,Confound.1.Model) Confound.2.Model anova(BaseModel,Confound.1.Model) Now, both of the ANOVAs tell me that the confounds explain incremental variance in the set of outcomes, over and above personality. However, I do not know how much more variance is explained -- that is to say, the R-Square change metric is not provided, as it normally would be in a multiple regression with one outcome variable. Is there some valid way to calculate the R-square change for a multivariate regression? (e.g. averaging the R-square changes for the individual outcomes). Is there some other statistic that is better suited for my question? Thank you for your time.
