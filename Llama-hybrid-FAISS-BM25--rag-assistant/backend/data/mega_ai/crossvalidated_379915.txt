[site]: crossvalidated
[post_id]: 379915
[parent_id]: 
[tags]: 
Test Set Probabilities and Accuracy

Say we've got a logistic regression model $M$ used as a classifier in a binary case. Now we take a test set $\tau=\{(x_1,y_1),...,(x_n,y_n)\}$ , each test sample is assigned with $\hat{\pi}_i=P(y_i=1|x_i)$ and then, assuming naive threshold of 0.5, a prediction is made: $\hat{y}_i=\left\{\begin{matrix}1 & \hat{\pi}_i\geq 0.5\\ 0 & \hat{\pi}_i . We can then $M$ 's discuss accuracy rate as $\frac{1}{n}\sum_{i}{I\{\hat{y}_i=y_i\}}$ or maybe its certainty rate $\frac{1}{n}\sum_{i}{max(\hat{\pi}_i,1-\hat{\pi}_i)}$ . Wherever I've looked, a logistic regression classifier is assessed either by information criteria or by cross-validation, both eventually relating to the degree of fit to the train dataset. It might look a total stranger's question, but are there are known methods using accuracy or certainty? it might be just me missing this info somehow.
