[site]: datascience
[post_id]: 115210
[parent_id]: 
[tags]: 
What if many different models reach the same maximum metrics

I am talking about trying different algorithms, different parameters, different stacking configurations that all improve upon previous baselines, and yet a lot of them have exactly the same values on several metrics and by extension, the confusion matrix. What can this mean? I have five possible explanations: Is it overfitting (it does indeed improve upon baselines but it does not generalize all to well to the unknown data)? Is this the limit of the specific model (ie. you can't reach any further than this using machine learning) or are the falsely classified samples simply extremely difficult? Is there something wrong with the data (the models could achieve better results but there are wrong labels on the test set so while the algorithms actually predict the correct thing, the evaluation shows it as mistaken)? Is the model so extremely robust? Am I simply cherry-picking and it is just coincidence? I compared tens or even hundreds of models that had varying results but I focus on the better ones that achieved similar results. It's just a hunch at this point so I don't want to go into more details, I am just curious about what you think about whether or not the things I stated are possible, or it is something else entirely.
