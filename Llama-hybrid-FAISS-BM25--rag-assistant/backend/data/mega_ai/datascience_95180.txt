[site]: datascience
[post_id]: 95180
[parent_id]: 
[tags]: 
LSTM for regression in time and space

I am trying to implement my first LSTM for a supervised regression problem. The data is in the following format: every row has month, day and hour in three separate columns, other 10 predictive features and one output. Of those 10 predictive features, two are the coordinates in space where the output value was measured. Since the space was modeled as a 6 x 8 grid, there are 48 combinations, and hence 48 rows for every time step. The number of rows is therefore: 365 (days/year) * 24 (hours/day) * 48 (points in space/hour). I have already solved the problem using a simple fully-connected neural network, but I have been asked to compare it with other models including LSTM. The problem is that I don't understand if I have to rearrange the data, and what the input sizes that I should use for the problem are. I need one prediction for every point in space, for every hour of every day of every month. I would like to implement this in Keras/Tensorflow. EDIT : to clarify, I am confused on how to implement this as a time-series problem because, for every point in time, I have 48 rows (one per grid point in space), instead of having one row per point in time. I could technically pivot wider, but this would lose any information about the x- and y- coordinates, which means that I could not extrapolate with other information.
