[site]: crossvalidated
[post_id]: 173068
[parent_id]: 
[tags]: 
Am I understanding differences between Bayesian and frequentist inference correctly?

Given a sequence of independent experiments, each having as its outcome either success or failure, the probability of success being some number p between 0 and 1 : A Bayesian would consider the results of the k experiments $X_1, X_2, ..., X_k$ fixed while p would be random, then assume a prior distribution on p and then come up with a posterior distribution for p given the results of the k experiments. Using a distribution for p, a Bayesian would use credible intervals . A frequentist would consider p a fixed value but the results of the k experiments $X_1, X_2, ..., X_k$ random and would try to come up with a maximum likelihood estimate. A frequentist would use confidence intervals . Hypothesis testing : A frequentist would use normal approximation to come up with a p-value to see if there is any reason to reject a null hypothesis $H_0$ in favor of an alternative hypothesis $H_1$. For a frequentist, $P(H_0), P(H_1) \in \{0,1\}$ A Bayesian would assign a prior probability to $H_0$ and compute a posterior probability $P(H_0 | k)$. A Bayesian would not absolutely choose between $H_0$ and $H_1$. Rather a Bayesian would be more inclined to $H_0$ if $P(H_0 | k) > 1 - P(H_0 | k) = P(H_1 | k)$ Regression: Given regression model $ g(E(Y)) = \beta_0 + \beta_1 X_1 + ... + \beta_k X_k $ A frequentist would consider $\beta_i$'s and other parameters to be fixed and would use MLE or OLS. A Bayesian would consider $\beta_i$'s and other parameters to be random, assign them prior distributions and then come up with posterior distributions for $\beta_i$'s and other parameters given the y's and X. Anything wrong? Anything I missed?
