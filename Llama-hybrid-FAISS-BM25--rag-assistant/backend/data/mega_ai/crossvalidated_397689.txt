[site]: crossvalidated
[post_id]: 397689
[parent_id]: 397680
[tags]: 
Besides images (also including things like Go or chess, where basically the board state gets represented as an image with different channel for different pieces and past positions), audio data, video, sequences (e.g. ECG signals or other wearable sensors) and natural language processing/translation (in a sense also sequences [of words]), I would think that situations that lend themselves to representations with embeddings (that e.g. represent the characteristics of individuals, items, words etc.) are often also very promising. These things include e.g. collaborative filtering (e.g. movie or book recommendations based on what other "similar people" have liked). Additionally, situations where multi-target learning and/or transfer learning is possible, which can be very promising when data are limited. If there are enough data another attractive situation is situations with extensive data, where I have seen neural networks coming up with better features (at least that is what I assumed was the reason for why neural networks sometimes outperform other methods with tabular data) on its own than what e.g. xgboost or RF produces.
