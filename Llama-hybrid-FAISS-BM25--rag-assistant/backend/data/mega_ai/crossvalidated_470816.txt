[site]: crossvalidated
[post_id]: 470816
[parent_id]: 
[tags]: 
Approximating a distribution of functions instead of a single function?

It is easy for a neural network to learn to approximate an analytic function such as f(x) = x^2 or f(x) = x^2 + 1 . I am struggling to learn a parametrized version of that (ie. f(x) = ax^2 + bx + c ). Given a context of 1000 x and f(x) pairs uniformly sampled from a quadratic with random a , b , c , I want to provide a target x_t and have the network predict f(x_t) . My architecture is below. input_1 is the context vector which consists of 1000 x and f(x) pairs. input_2 is x_t , the position of the point I want to predict. dense_6 is a linear layer with one neuron, supposed to represent f(x_t) . To train, I have generated 100 random quadratics. For each quadratic, I generate 100 training examples. A training example consists of a random context (the 1000 points fed to the first network), and a random target. However, I am unable to get this to work at all no matter what I do. The validation loss barely decreases. It either memorizes the training set and overfits or underfits. Any ideas on how I can achieve this? What should I try?
