[site]: crossvalidated
[post_id]: 491971
[parent_id]: 
[tags]: 
Modelling random samples in terms of probability spaces

This question relates to this and this . When one is modelling the process of (independent) random sampling, it seems to go like this: you start out with a probability space $(\Omega,\mathcal{F},P)$ , then you consider $n$ i.i.d. random variables $X_1,\dots,X_n: \Omega \to \mathbb{R}$ . Then, a sample is the image of $\omega \in \Omega$ under $(X_1,\dots,X_n)$ , that is, $(x_1,\dots,x_n) = (X_1,\dots,X_n)(\omega)$ . This doesn't make intuitive sense to me. As a silly example, if $\Omega$ is a set of people and we wish to estimate their average height, we don't test the height of the same individual using $n$ "different" rulers; instead, we measure the height of $n$ people with the same ruler. I think there might be an equivalent and more intuitive approach. Instead of considering $n$ random variables, we could consider the product space $(\Omega^n, \mathcal{F}^n,P^n)$ and a random variable $X = X_1$ (as above), which induces $X^n: \Omega^n \to \mathbb{R}^n$ . Since $X_1,\dots,X_n$ are i.i.d. it follows that the pushforward measures induced by $(X_1,\dots,X_n)$ and $X^n$ are the same. In fact, for $B_1,\dots,B_n \in \mathcal{B}$ (borel sets) we have $$(X_1,\dots,X_n)^{-1}[B_1 \times \cdots \times B_n] = X_1^{-1}[B_1] \cap \cdots \cap X_n^{-1}[B_n]$$ and $$(X^n)^{-1}[B_1 \times \cdots \times B_n] = X^{-1}[B_1] \times \cdots \times X^{-1}[B_n]$$ . From independence and the construction of the product space we have \begin{align*} P((X_1,\dots,X_n)^{-1}[B_1 \times \cdots \times B_n]) &= P(X_1^{-1}[B_1] \cap \cdots \cap X_n^{-1}[B_n]) \\ &= P(X_1^{-1}[B_1]) \cdots P(X_n^{-1}[B_n]) \\ &= P(X^{-1}[B_1] \times \cdots \times X^{-1}[B_n]) \\ &= P((X^n)^{-1}[B_1 \times \cdots \times B_n]). \end{align*} Since the pushfoward measures coincide in "basic" borel sets in $\mathbb{R}^n$ they are the same. In that second construction a random sample would be an element of the form $(x_1,\dots,x_n)=(X(\omega_1),\dots,X(\omega_n))$ . My question is, then, If both constructions are equivalent (I might have made a mistake in my reasoning), why is the first one preferred?
