[site]: crossvalidated
[post_id]: 55831
[parent_id]: 55827
[tags]: 
If I understand you, what you are doing is out-of-sample testing. And to avoid data-leakage, you do not want to include the data target_data in the inference on nu . A more appropriate way to handle this is to do the following: nu = mc.Gamma('nu', 3, 2) fit_obs = mc.NoncentralT('fit', fitmean, fitprec, nu, value=fit_data, observed=True) N = target_data.shape[0] predictive_obs = mc.NoncentralT('predictive', mean, prec, nu, size=N ) This way, you get a new variable predictive_obs , which is a distribution of possible realizations of the test data, given the training-data-fitted nu variable. (I made predictive_obs size N so it returns samples of equal size of the testing data set). From this, we can compare how likely we are, given the fitted nu , to see the target dataset. For example, if your predictive samples, provided in mcmc.trace("predictive") , have very very fat tails, and your observed target data has thin tails, perhaps the fit is not correct. See here for some examples of goodness-of-fit visualizations. Using a deterministic wrapper, like your edit, still adds that data to the inference. I'll demonstrate: Instead of an informative prior, like the Gamma you chose, I'm going to use a non-informative prior (a Uniform), just so there is no bias and the conclusion is clear: Using the code: nu = mc.Uniform( 'nu', 0,40) fit_data = np.random.randn( 500 ) We should see the posterior of nu away from 0, as the data is from a Normal (which is a Student-T with a large nu .) This is without any "testing data" included. We see this posterior on nu : We add heavy tailed data to be the testing_data , target_data = np.array( [-10., -5., 6., 8.] ) #very unlikely values, would promote small nu If we add your deterministic fix_nu variable, and the target_data def fix_nu( nu = nu ): return nu test_obs = mc.NoncentralT('test_obs', 0, 1, nu, value=target_data, observed=True) and running the same as above, we get: I should make it clear: this plot is the previous inference and the new inference. The large difference in the distributions implies the testing_data has been included in the inference. I think what you want to do is possible. Even if the means (and prec) are very different, so long as the assumption (which should be tested) that $\nu$ are equal, something like the following is totally valid: nu = mc.Gamma('nu', 3, 2) fit_obsA = mc.NoncentralT('fitA', fitmeanA, fitprecA, nu, value=fit_dataA, observed=True) fit_obsB = mc.NoncentralT('fitB', fitmeanB, fitprecB, nu, value=fit_dataB, observed=True) will perform inference on nu , (again, stressing under the assumption the nu are the same in the two groups).
