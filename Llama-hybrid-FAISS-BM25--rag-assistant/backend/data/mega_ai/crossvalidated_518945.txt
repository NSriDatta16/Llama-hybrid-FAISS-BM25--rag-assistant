[site]: crossvalidated
[post_id]: 518945
[parent_id]: 
[tags]: 
Why can't I classify my data perfectly on this simple problem using a NN?

I have a set of observations made of 10 features, each of these features being a real number in the interval (0,2). Say I wanted to train a simple neural network to classify whether the average of those features is above or below 1.0. Unless I'm missing something, it should be enough with a two-layer network with one neuron on each layer. The activation functions would be a linear one (i.e. no activation function) on the first layer and a sigmoid on the output layer. An example of a NN with this architecture that would work is one that calculates the average on the first layer (i.e. all weights = 0.1 and bias=0) and asseses whether that is above or below 1.0 in the second layer (i.e. weight = 1.0 and bias = -1.0). When I implement this using TensorFlow (see code below), I obviously get a very high accuracy quite quickly, but never get to 100% accuracy... I would like some help to understand conceptually why this is the case. I don't see why the backppropagation algorithm does not reach a set of optimal weights (may be this is related with the loss function I'm using, which has local minmums?). Also I would like to know whether a 100% accuracy is achievable if I use different activations and/or loss function. Thanks! import numpy as np import tensorflow as tf import matplotlib.pyplot as plt X = [np.random.random(10)*2.0 for _ in range(10000)] X = np.array(X) y = X.mean(axis=1) >= 1.0 y = y.astype('int') train_ratio = 0.8 train_len = int(X.shape[0]*0.8) X_train, X_test = X[:train_len,:], X[train_len:,:] y_train, y_test = y[:train_len], y[train_len:] def create_classifier(lr = 0.001): classifier = tf.keras.Sequential() classifier.add(tf.keras.layers.Dense(units=1)) classifier.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))#, input_shape=input_shape)) optimizer = tf.keras.optimizers.Adam(learning_rate=lr) metrics=[tf.keras.metrics.BinaryAccuracy()], classifier.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=metrics) return classifier classifier = create_classifier(lr = 0.1) history = classifier.fit(X_train, y_train, batch_size=1000, validation_split=0.1, epochs=2000)
