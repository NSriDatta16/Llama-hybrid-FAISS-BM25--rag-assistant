[site]: crossvalidated
[post_id]: 443148
[parent_id]: 
[tags]: 
How to design high quality encoder-decoder pairs for images?

In many of todays deep models for image processing you can find some sort of encoder-decoder structure, in the simplest form it is an Autoencoder, whenever we want to introduce some kind of bottleneck. In my own experiments even in their simplest form (e.g. strided convolutions in the encoder, transposed convolutions in the decoder) they will produce quite blurry outputs or just with a general lack of detail. I noticed that adding a e.g. a discriminator can help with the sharpness but that can also introduce other artifacts. While I am aware that in practice you will lose some quality, I have also seen results that have a lot better quality output images, though rarely with public source code or sufficiently detailed descriptions of their architecture. Similarly when you add (long) skip connections (like in u-net type networks) you do immediately get better results in terms of autoencoding, but then you basically circumvent the bottleneck that we need in many applications. So how do you design an encoder-decoder pair with a bottle neck that still allows for high quality reconstructions? What losses should be used?
