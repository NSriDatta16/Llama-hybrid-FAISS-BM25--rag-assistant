[site]: crossvalidated
[post_id]: 200438
[parent_id]: 199148
[tags]: 
I don't have sufficient privileges to be able to write comments, so I will just provide my input/observations here as an answer. In my experience, Support Vector Classifiers (SVC) tend to be either at par or outperform the other methods when the binary classes are balanced. For unbalanced classes, SVC tends to perform poorly. I don't often deal with multiclass problems, but I have seen some good results with SVC for multiclass problems as well. Another thing I've noticed is that the curse of dimentionality doesn't seem to affect SVC as much as other modeling techniques. In other words, as I add more terms in the model, the other techniques start performing poorly on the test (or, holdout) set as compared to the training set. But not so much when I use SVC. Because of this reason, if model parsimony is not your priority, then SVC may be a better option as you can throw in a lot of terms without as much over-fitting as the other methods. One of the issues I have with SVC is that it doesn't implicitly provide a measure (like predicted probability) to be able to rank order the observations. You could use Platt Scaling (implemented in sklearn.svm package in Python), but I have seen some inconsistencies. (I can share the details if anyone's interested.) Not sure if this really answers your question, but these are my observations. Hope that helps.
