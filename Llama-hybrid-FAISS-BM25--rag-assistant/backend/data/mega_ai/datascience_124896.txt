[site]: datascience
[post_id]: 124896
[parent_id]: 124864
[tags]: 
This is a very common scenario, to overcome this you can use one hot encoding for your categorical variable - sklearn.preprocessing.OneHotEncoder One hot encoding will ensure that it gets all the categories from your training data and will encode the testing data categories according to the train data. Since your test data has new categories , it will ignore the encoding of the new categories in the test data. from sklearn.preprocessing import OneHotEncoder import pandas as pd x_train=pd.DataFrame({"Categorical Variable": ["a", "b","c","d","e","f","g"]}) x_test = pd.DataFrame({"Categorical Variable": ["a","b","c","d","e","f","h","l","m","n"]}) transformer = OneHotEncoder(handle_unknown = 'ignore') ##handle_unknown plays the role of ignoring the new values in the test data transformer.fit(x_train) print(transformer.transform(x_train).toarray()) Here you can observe that there are only 7 one hot encoded variables; since train_data has a total of 7 categories [[1. 0. 0. 0. 0. 0. 0.] [0. 1. 0. 0. 0. 0. 0.] [0. 0. 1. 0. 0. 0. 0.] [0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0.] [0. 0. 0. 0. 0. 1. 0.] [0. 0. 0. 0. 0. 0. 1.]] print(transformer.categories_) [array(['a', 'b', 'c', 'd', 'e', 'f', 'g'], dtype=object)] print(transformer.get_feature_names()) ['x0_a' 'x0_b' 'x0_c' 'x0_d' 'x0_e' 'x0_f' 'x0_g'] print(transformer.transform(x_test).toarray()) Here you can observe that the test data has also 7 categories as it comes from the training set and encoder ignores h,l,m,n [[1. 0. 0. 0. 0. 0. 0.] [0. 1. 0. 0. 0. 0. 0.] [0. 0. 1. 0. 0. 0. 0.] [0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0.] [0. 0. 0. 0. 0. 1. 0.] [0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0.]]
