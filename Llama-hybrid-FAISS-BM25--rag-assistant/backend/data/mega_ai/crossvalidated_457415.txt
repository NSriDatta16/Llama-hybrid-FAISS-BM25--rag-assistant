[site]: crossvalidated
[post_id]: 457415
[parent_id]: 
[tags]: 
Desirable properties of datasets and models for benchmarking Bayesian posterior inference algorithms

Are there canonical datasets for benchmarking the performance of posterior inference algorithms? For example in machine learning literature, the MNIST dataset ( and others ) is often used in benchmarking optizmation algorithms. If this question does not fit the community guidelines, here's an alternate question: Which properties are desirable in a dataset and model for a comprehensive assessment of Bayesian posterior inference algorithms? An example of a desirable property of a dataset and model might be the presence of multiple modes separated by large regions of low density in the posterior. Another example is a high dimensional problem that has been solved. Looks like StRD MCMC Dataset had a promising start, but the datasets are very small and dated. Another example is the collection of oddly-shaped, 2-dimensional posterior distributions seen in this HMC visualization application . Are there any known datasets/models with properties exhibited in this example but in higher dimensions? Even better if it has known expected values. Seems like a similar discussion took place: performance benchmarks for MCMC (@lacerbi).
