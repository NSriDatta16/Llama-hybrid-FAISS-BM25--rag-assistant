[site]: crossvalidated
[post_id]: 475322
[parent_id]: 
[tags]: 
Preprocessing data for the learning step

I am currently reading "Human level control through deep reinforcement learning" and I came across the algorithm in the paper. I am confused because the algorithm uses a different notation or I must be missing something. In the paper under Algorithm 1: deep Q-learning with experience replay. , it says Store transition $(\phi_t, a_t, r_t, \phi_{t+1})$ in $D$ $\phi_{t+1} = \phi(s_{t+1}) = \phi(s_t, a_t, x_{t+1})$ where $x_{t+1}$ is the image (frame which is returned by the gym). So... $a_t$ is not only used in the preprocessing but also in saving in the buffer. So this algorithm actually says: Store transition $(\phi(s_{t-1}, a_{t-1}, x_{t}), a_t, r_t, \phi(s_t, a_t, x_{t+1}))$ in $D$ Why use it in the preprocessing though. Isn't the preprocessing only used for the frame/image? [edit] A fellow student has pointed out that the preprocessing is used for frames only, as described in The function $w$ from algorithm 1 described below applies this preprocessing to the $m$ most recent frames and stacks them to produce the input to the Q-function, in which $m = 4$ , although the algorithm is robust to different values of $m$ (for example, $3$ or $5$ ). This is still confusing because of the notation of $s_{t+1} = s_t, a_t, x_{t+1}$ Link to the paper: http://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf
