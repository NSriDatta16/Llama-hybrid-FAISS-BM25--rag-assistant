[site]: crossvalidated
[post_id]: 429268
[parent_id]: 355109
[tags]: 
From my reading, I thought this statement is true asymptotically, i.e. for large sample size, and if one uses an uninformative prior. A simple numerical example would seem to confirm this - the 90% profile maximum likelihood intervals and 90% credible intervals of a ML binomial GLM and Bayesian binomial GLM are indeed virtually identical for n=1000 , though the discrepancy would become larger for small n : # simulate some data set.seed(123) n = 1000 # sample size x1 = rnorm(n) # two continuous covariates x2 = rnorm(n) z = 0.1 + 2*x1 + 3*x2 # predicted values on logit scale y = rbinom(n,1,plogis(z)) # bernoulli response variable d = data.frame(y=y, x1=x1, x2=x2) # fit a regular GLM and calculate 90% confidence intervals glmfit = glm(y ~ x1 + x2, family = "binomial", data = d) library(MASS) # coefficients and 90% profile confidence intervals : round(cbind(coef(glmfit), confint(glmfit, level=0.9)), 2) # 5 % 95 % # (Intercept) 0.00 -0.18 0.17 # x1 2.04 1.77 2.34 # x2 3.42 3.05 3.81 # fit a Bayesian GLM using rstanarm library(rstanarm) t_prior = student_t(df = 3, location = 0, scale = 100) # we set scale to large value to specify an uninformative prior bfit1 = stan_glm(y ~ x1 + x2, data = d, family = binomial(link = "logit"), prior = t_prior, prior_intercept = t_prior, chains = 1, cores = 4, seed = 123, iter = 10000) # coefficients and 90% credible intervals : round(cbind(coef(bfit1), posterior_interval(bfit1, prob = 0.9)), 2) # 5% 95% # (Intercept) -0.01 -0.18 0.17 # x1 2.06 1.79 2.37 # x2 3.45 3.07 3.85 # fit a Bayesian GLM using brms library(brms) priors = c( prior(student_t(3, 0, 100), class = "Intercept"), prior(student_t(3, 0, 100), class = "b") ) bfit2 = brm( y ~ x1 + x2, data = d, prior = priors, family = "bernoulli", seed = 123 ) # coefficients and 90% credible intervals : summary(bfit2, prob=0.9) # Population-Level Effects: # Estimate Est.Error l-90% CI u-90% CI Eff.Sample Rhat # Intercept -0.01 0.11 -0.18 0.18 2595 1.00 # x1 2.06 0.17 1.79 2.35 2492 1.00 # x2 3.45 0.23 3.07 3.83 2594 1.00 # fit a Bayesian GLM using arm library(arm) # we set prior.scale to Inf to specify an uninformative prior bfit3 = bayesglm(y ~ x1 + x2, family = "binomial", data = d, prior.scale = Inf) sims = coef(sim(bfit3, n.sims=1000000)) # coefficients and 90% credible intervals : round(cbind(coef(bfit3), t(apply(sims, 2, function (col) quantile(col,c(.05, .95))))),2) # 5% 95% # (Intercept) 0.00 -0.18 0.17 # x1 2.04 1.76 2.33 # x2 3.42 3.03 3.80 As you can see, in the example above, for n=1000 , the 90% profile confidence intervals of a binomial GLM are virtually identical to the 90% credible intervals of a Bayesian binomial GLM (the difference is also within the bounds of using different seeds and different nrs of iterations in the bayesian fits, and an exact equivalence can also not be obtained since specifying a 100% uninformative prior is also not possible with rstanarm or brms ).
