[site]: crossvalidated
[post_id]: 337303
[parent_id]: 301478
[tags]: 
Part of the difference comes down to conditioning, the difference between pre-data probabilities and post-data probabilities. Before you do your single experiment (before you obtain your sample), you know that there is a 95% chance that the 95% CI will contain the true mean (this is the definition of a 95% CI). However, after you obtain your sample, you are in a different state of knowledge: you have not learned the true mean, but you have seen a particular sample of data, which may give you some new knowledge and which can affect your probability calculations. Analogously, before you draw a card, you know that there is a 25% chance that the card will be a club. Now to make the analogy work, you cannot learn the true suit of the card when you draw it (because likewise the true mean is always hidden from you). But you may learn something new from drawing the card, for instance the color of the suit. Let's say that you draw the card, and through some mechanism (it doesn't matter for the point), you learn that the card is from a black suit. This changes your probability: from prior information, you know that clubs are black, and that half the cards are from black suits, so now you know that the card has a 50% chance of being a club. If, on the other hand, you discovered a red card, from your prior information you know that clubs are not red, so you would now know that there is a 0% chance of your card being a club. Both these probabilities are consistent with a 25% chance of a club before drawing the card. If you were to ignore your prior information, or if you were not told that the card was black, you would still have a 25% chance of being correct. However, you can do better if you take advantage of your prior information. There are many examples of this with real CIs, where seeing the data gives a coverage probability that is different from the CI %. This classic example (halfway down the post) of a "misleading" CI from David McKay may help. A similar example is given by Berger . To continue with your example of heights of people: lets say that you know that your population under study is from the Netherlands, which has the tallest average height of any country in the world (about $1.84 \pm 0.02$ m). However, lets say your sample has a 95% CI of $1.7 \pm 0.02$ m. Do you still think there is a 95% probability that the true population mean lies in that interval? I would say that, based on the prior knowledge, your specific sample was a stochastic fluke and anomalously low. In other words, the probability is much less than 95% that the true mean lies in your calculated CI. Note, before you obtained your sample, and calculated your specific CI, your chance of obtaining a CI that encompassed the true mean was 95%. Afterwards, if you use no prior information, and assume that all mean heights are equally probable a priori , then you could , if you wanted, make a Bayesian statement that there is 95% probability that your interval contains the true mean. But realize that such a statement does not follow from the definition of a CI, and that it crucially depends on a particular assumed prior for the mean. It also depends on your normality assumption, as most frequentist CIs cannot be re-interpreted in a Bayesian manner so easily.
