[site]: datascience
[post_id]: 10932
[parent_id]: 
[tags]: 
Difference between AlphaGo's policy network and value network

I was reading a high level summary about Google's AlphaGo , and I came across the terms "policy network" and "value network". At a high level, I understand that the policy network is used to suggest moves and the value network is used to, "Reduce the depth of the search tree [and estimate] the winner in each position in place of searching all the way to the end of the game." These two networks seem redundant to me. What is the policy network doing if it's not using the value network to prune its policies? It seems pretty clear that the value network is a deep learning neural network; is the policy network just a theoretical abstraction and not an actual neural network? The target variable for the value network seems to be win/loss. Is there a target variable for the policy network; if so, what is it? What is the policy network trying to optimize? The full pdf of Google's paper, published in Nature, can be found here .
