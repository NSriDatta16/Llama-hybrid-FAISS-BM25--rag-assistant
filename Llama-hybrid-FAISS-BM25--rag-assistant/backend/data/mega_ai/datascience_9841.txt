[site]: datascience
[post_id]: 9841
[parent_id]: 9823
[tags]: 
An embedding layer turns positive integers (indexes) into dense vectors of fixed size. For instance, [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]] . This representation conversion is learned automatically with the embedding layer in Keras (see the documentation ). However, it seems that your data does not need any such embedding layer to perform a conversion. Having an unnecessary embedding layer is likely why you cannot get your LSTM to work properly. If that is the case then you should simply remove the embedding layer. The first layer in your network should then have the input_shape argument added with information on the dimensions of your data (see examples ). Note that you can add this argument to any layer - it will not be present in the documentation for any specific layer. By the way, hyperparameters are often tuned using random search or Bayesian optimization. I would use RMSProp and focus on tuning batch size (sizes like 32, 64, 128, 256 and 512), gradient clipping (on the interval 0.1-10) and dropout (on the interval of 0.1-0.6). The specifics of course depend on your data and model architecture.
