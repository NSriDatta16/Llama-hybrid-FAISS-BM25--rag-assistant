[site]: datascience
[post_id]: 64283
[parent_id]: 64278
[tags]: 
This is a frequently asked question because of its confusing nature. So let me try to shed a little light on this. Channels come from "media". Looking at broadcast technology behind TVs you have mulitple channels for different information that gets broadcasted to your TV. For example an image might consist of only three channels that contain information on how much Red, Green or Blue each pixel in an image is. Mapping this to a CNN you would have an RGB image with three channels. An image however can be interpreted as different things as well. For example you could take information from an image how cyan, magenta, yellow or black something is. This would mean your CMYK image would be analyzed by four channels (each colour being one channel). In CNNs this means that each of your filters gets applied to each of your channels. Why? Because it might be that your filters get different information from each of the channels. And maybe they converge to different filters after each learning step as well.
