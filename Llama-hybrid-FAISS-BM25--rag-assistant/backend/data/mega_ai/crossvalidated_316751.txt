[site]: crossvalidated
[post_id]: 316751
[parent_id]: 
[tags]: 
Understanding covariance in Bayesian regression model

I am confused about when to model covariance in a Bayesian regression. Here's what I am trying to model. I have a dataset which has scores for a set of students who did a set of practice exam problems. Each question is from a set of question-type Q. Questions are shuffled so that subsequent questions could come from a different question-type . I want to look at pairs of questions from different question types and model how the type of previous question affect the score of the current question. I want to model something like the following: $y_{s,t} \sim a_{s} + b_{q(t)} + \alpha * b_{q(t-1)}$ Here $y_{s,t}$ is student $s$'s score for the current question. $a_{s}$ is a dummy indicator for student $s$. $q(t)$ is the type of the current question and $q(t-1)$ is the type of the previous question where $q(t) \neq q(t-1)$. $b$'s are random coefficients for each question type $q$. $\alpha$ is the quantity I am interested in. My question is, when I model this as a Bayesian regression model, is it correct to model $b$ as $b \sim Normal(0,\sigma_{b})$ or should I include a covariance for this? I have read that when modeling multiple group level coefficients in multi-level models, we need to model covariance between the coefficients (e.g., covariance between group level random slope and intercept). But in this case the $b$'s are just one coefficients per each question type and consider two of the question type when modeling one observation. So it is confusing for me whether it is enough to have just a variance parameter or if I should include covaraince for modeling the parameter $b$. Any conceptual explanation would be very helpful to understand this.
