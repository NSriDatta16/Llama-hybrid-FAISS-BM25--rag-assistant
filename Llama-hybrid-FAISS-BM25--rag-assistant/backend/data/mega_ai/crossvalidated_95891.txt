[site]: crossvalidated
[post_id]: 95891
[parent_id]: 
[tags]: 
If you know a factor is significant, what is a reason why R might think it's not?

I'm running a logistic regression model where anecdotally I expected age to be a very large factor. If you see from the charts I made in Excel before running the model through R, this is how the support lines up by age: Looks pretty significant. Though when I run the model, as you can see below, age is the only thing that's not significant -- which was very surprising: > attach(mydata) > > # Define variables > > Y X > # Logit model coefficients > > logit > summary(logit) Call: glm(formula = Y ~ X, family = binomial(link = "logit"), na.action = na.exclude) Deviance Residuals: Min 1Q Median 3Q Max -2.1019 -0.7609 0.5231 0.7101 2.3965 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) 4.013446 0.440962 9.102 My only guess on this is that the previous support scores (both 0-100 numerical values) I'm using may have already taken age into account, and the model doesn't want to count it twice. Though, to compare, region and county are just two different ways of cutting up the geography -- and those both seem significant. Can somebody let me know what you would think if your model told you that age wasn't significant when in clearly is? Trying to figure out if there's a way of thinking about it that I'm missing or if something in my code is wrong. Thanks! -- EDIT Pairs plot added to show correlation (despite some factors being categorical): pairs(~sex + region + age + supportscore1 + supportscore2 + county, data=mydata)
