[site]: crossvalidated
[post_id]: 265961
[parent_id]: 265779
[tags]: 
Normalizing your input is generally a good idea in order to achieve a well-defined problem. If you don't normalize, your training might be very slow or might end up in a local minimum. The intuitive explanation is that if you have a variable with very large variables, the change in weights from back-propagation will be very different than for any other (smaller) variables. The variables don't necessarily need to fall between 0 and 1, in fact it is generally recommended to normalize with a mean of 1 and a standard deviation of 1. Your approach should also work however. The above is only about simple normalization/rescaling. If you have very noisy or assymetrical data, you might also consider transformation to make your input more smooth. See also this . In theory the neural network should be able to handle most of the alinearity in your data though, provided you use non-linear activation functions.
