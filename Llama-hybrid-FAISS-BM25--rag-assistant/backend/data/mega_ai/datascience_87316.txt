[site]: datascience
[post_id]: 87316
[parent_id]: 87308
[tags]: 
This is a good example of what is usually called "data leakage" -- you are bleeding information from your test set back to your model set. A certain amount of this is inevitable, and it's why (especially for deep learning) problems data scientists often split up data sets into training, validation, and holdout sets. The validation/testing set is used to do the kind of parsimonious model tuning you're talking about before assessing the accuracy with a final holdout set. Incidentally, it sounds like you're right that the elevation might be a feature that overfits. One way to solve that without totally losing the information value from actual elevation would be to transform the feature into bins, which will likely include multiple observations in each.
