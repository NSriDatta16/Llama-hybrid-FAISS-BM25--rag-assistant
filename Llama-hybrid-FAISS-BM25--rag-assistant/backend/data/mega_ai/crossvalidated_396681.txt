[site]: crossvalidated
[post_id]: 396681
[parent_id]: 162294
[tags]: 
The excellent book Regression Methods in Biostatistics: Linear, Logistic, Survival, and Repeated Measures Models have a treatment of power analysis for logistic regression, with some simple useful (approximate) formulas, very possibly the formulas used by GPower referred in another answer (in section 5.7.) If those approximations are not good enough, probably simulation will be needed. Two-sided testing of $H_0\colon \beta_j=0$ (log-odds scale) versus $H_1\colon \beta_j=\beta_j^a$ with level $\alpha$ and power $\gamma$ , standard deviation of predictor $x_j$ is $\sigma_{x_j}$ , $p$ the marginal prevalence of the outcome and $\rho_j^2$ is the multiple correlation of $x_j$ with all the other predictors (this is the R-squared reported by a linear multiple regression of $X_j$ as response on all the other predictors, and do not involve the response in the logistic regression at all.) The minimum sample size is then $$ n=\frac{(z_{1-\alpha/2}+z_\gamma)^2}{(\beta_j^a \sigma_{x_j})^2 p(1-p) (1-\rho_j^2)} $$ where $z_{1-\alpha/2}$ and $z_\gamma$ are quantiles of the standard normal distribution corresponding to level and power. Note the use in this formula of the variance inflation factor $\text{vif}_j=\frac1{1-\rho_j^2}$ . A graph showing minimum sample size as function of alternative coefficient $\beta_j^a$ : For completeness some related formulas from the same source: If sample size $n$ is decided then power is $$ \gamma=1-\Phi\left(z_{1-\alpha/2}-|\beta_j^a| \sigma_x\sqrt{np(1-p)(1-\rho_j^2)}\right)$$ where $\Phi$ is the standard normal cumulative distribution function. The minimum detectable effect (on log-odds scale) is $$ \pm \beta_j^a = \frac{z_{1-\alpha/2}+z_\gamma}{\sigma_{x_j}\sqrt{np(1-p)(1-\rho_j^2)}} $$ The references given for this approximate formulas is A SIMPLE METHOD OF SAMPLE SIZE CALCULATION FOR LINEAR AND LOGISTIC REGRESSION which in turn for much of the theory refers to Sample Size for Logistic Regression With Small Response Probability which bases its result on approximations to the Fisher information matrix, so this is really based on normal approximations. It is known that normal approximations can be bad for logistic regression, so the results from this formulas should probably be checked by simulation. Code in R: min_n A simple test: min_n(beta_a=0.2, sigma_x=1, p=0.5, R2=0.5) [1] 1570 Code for the plot: ypos
