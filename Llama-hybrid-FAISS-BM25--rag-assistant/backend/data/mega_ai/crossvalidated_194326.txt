[site]: crossvalidated
[post_id]: 194326
[parent_id]: 194314
[tags]: 
You are mixing various ideas. Logistic regression uses the logistic function to translate the unrestricted linear predictor to a restricted $[0,1]$ space. This function must be monotonic. The $X$s on the other hand can include complex functions. Regularization is better called penalized maximum likelihood estimation because its purpose nowadays is to avoid overfitting and no so much to regularize (make variables less correlated). You can use penalized MLE with logistic models even if all the $X$s affect the linear predictor (log odds that $Y=1$) linearly. Note that penalization = shrinkage. If you have multiple terms representing one predictor (say using a regression spline), penalization will make the resulting fitted transformation more flat. Targeted penalization (e.g., penalizing only the nonlinear components) will make it more simple but still possibly steep.
