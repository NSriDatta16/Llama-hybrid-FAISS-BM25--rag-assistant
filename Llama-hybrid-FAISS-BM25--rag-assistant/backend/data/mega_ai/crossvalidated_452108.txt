[site]: crossvalidated
[post_id]: 452108
[parent_id]: 
[tags]: 
Steps in gradient boosting algorithm

Can some one please explain the 3rd step 2(c) in the below gradient boosting algorithm. I was under the impression, that the 2(c) computation is nothing but the mean of the corresponding terminal node (average of all the target values in the node- average of $r_{im}$ , since $r_{im}$ is the target). What parameter of GBM does gradient descent update after calculating gradient of loss function? Also, isn't $f_{m-1}(x_i)$ assigned to $\gamma$ (a constant, in step 1) ? Not sure, why we are adding $f_{m-1}(x_i)$ to $\gamma$ which is like $2*\gamma$ in 2(c). Why are we using $f_{m-1}(x_i)$ and $\gamma$ and $L$ , instead of mean of $r_{im}$ of the node, in step 2(c)
