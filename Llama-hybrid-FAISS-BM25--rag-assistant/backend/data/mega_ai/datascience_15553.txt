[site]: datascience
[post_id]: 15553
[parent_id]: 
[tags]: 
How to compare the performance of feature selection methods?

There are several feature selection / variable selection approaches (see for example Guyon & Elisseeff, 2003 ; Liu et al., 2010 ): filter methods (e.g., correlation-based, entropy-based, random forest importance based), wrapper methods (e.g., forward-search, hill-climbing search), and embedded methods where the feature selection is part of the model learning. Many published algorithms are also implemented in the machine learning tools like R, Python, etc. What would be an appropriate method to compare different feature selection algorithms and to select the best method for a given problem / dataset? A further question would be, whether there are any metrics known that measure the performance of feature selection algorithms?
