[site]: datascience
[post_id]: 61303
[parent_id]: 61299
[tags]: 
Since you're seeing probabilities concentrated near 0 and 1 (as is expected in gradient boosting), make sure you're not using Platt calibration; isotonic calibration is a better choice, or if you're willing to depart sklearn, beta calibration sounds promising. Keep in mind that all these calibration methods should use a separate training set. Also, have a look at calibration plots (which might show that Platt is unsuitable, and would also indicate whether the next paragraph is a possibility). There's also a (slight) possibility that these scores are actually well-calibrated: e.g. if the data was generated in two clusters, and each cluster's points choose classes uniformly with probabilities close to 0 in one cluster and close to 1 in the other cluster, then "the right" answers are these probabilities, with the tree finding those clusters. One approach to obtain "more regularly distributed probabilities" without actually calibrating them would be to make your model more conservative, using fewer trees and/or lower learning rate, more regularization, etc. but this risks hurting the model's performance.
