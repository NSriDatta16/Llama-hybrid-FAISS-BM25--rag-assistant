[site]: crossvalidated
[post_id]: 95880
[parent_id]: 
[tags]: 
NBA Points Per Game

I have a database with many thousands of entries of box scores. Each box score has a player name, date played, points scored, minutes played, and some other stats like rebounds, assists, etc. I want to use this information to find out how the frequency of points per game varies by each half a point difference. I'm not sure I'm stating the problem exactly, so here is an example. So let's say we're looking at Kevin Durant, his average and median points per game for this season is 31. So let's say the next game he plays, he's gonna get above 31 points 50% of the time, and below 31 points 50% of the time (and disregard all cases where he hits exactly 31). How often will he get above 30.5 points? How often will he get above 31.5 points? Or rather, how do I use my database to figure this out? If I just check historical games with Kevin Durant and see how often he went over 31.5 as opposed to 31 as opposed to 29.5 the sample size won't be large enough. And if I select 5,000 random box scores with the criteria "select box score where points scored was between 29 and 33", I believe I will seriously bias the distribution and won't be able to learn from it. Thoughts?
