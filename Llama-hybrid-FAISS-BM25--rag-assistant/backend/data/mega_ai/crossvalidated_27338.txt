[site]: crossvalidated
[post_id]: 27338
[parent_id]: 27313
[tags]: 
We are working with data like this for a major fast food franchise. The series represents the demand for tacos in 15 minute intervals for the last 5 years (180,000 observations) . This series can be treated by building 96 separate models (4x24) for each 15 minute interval a daily model reflecting overall trends,level shifts,holiday effects etc in daily values. By integrating the impact of daily values and their history on each of the 96 models and then reconciling, we are able to accurately predict both the demand for 15 minute intervals and the daily totals. The reason you think the acf is significant is as Rob points out due to the sample size since the standard error of the acf is equal to 1/sqrt(N). @Luna As you correctly point out in your comment one loses the connection between the different time slices BUT one gains the impact of activity over days/weeks/months while being able to detect changes in daily effects , while discovering the impact of particualr days of the month etc.. We like you had studied the "one-time series approach" using semi-hourly electricity demand data only to conclude that we were getting FALSE CONCLUSIONS due to the size/length of the data. In general one could have 96 equations with X eXogenous series . This would be called a Vector ARIMA problem and would be unwieldy as outlier /inliers cpuld distort parameter estimates. Standard errors would be microscopic in size due to large N . We have found ways to incorporate daily trends directly into each of the 96 equations
