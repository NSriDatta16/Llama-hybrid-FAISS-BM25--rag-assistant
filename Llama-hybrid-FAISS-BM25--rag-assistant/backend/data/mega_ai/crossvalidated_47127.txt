[site]: crossvalidated
[post_id]: 47127
[parent_id]: 47090
[tags]: 
Increasing training size does not neccessarily help the classifier and rather, may lead to a degradation in the generalization ability. Regarding your own experiment, the factor of such unexpected degradation in performance given the increase in the training size could be one of the following: 1- Randomness: Simply, if you run the experiment again, you may see a different result from the one you have. This is only if the classifier is using any random approach in training. 2- Parameter Optimization: For example, in SVM, while increasing the training size, if the data is not linearly separable, you may need to increase the values of the slack variables (@Douglas). This parameter optimization helps in accounting for any new training point that violates the linear separability of the space. 3- Overfitting: Training some classifiers for longer time or using extra training points, may lead to a good performance on the training data but a worse one on the testing part. This is because your classifier could be so much fitting the training points to an extent in which it is difficult for to predict new points of different characteristics. 4- Experiment Design: It would be more indicative to run the experiment you have more than once on different parts of the data ( cross-validation ) and report the scores. In this case, we will have a MEAN accuracy value and an STDEV which would be more realistic indicators of the observation you have. My advise for you is to run the same expariment again within the same setting. If you get a different result, then, you check the random part in your code. Then, even if you get the same result, use cross-validation. Finally, you may tune some of the parameters of the SVM.
