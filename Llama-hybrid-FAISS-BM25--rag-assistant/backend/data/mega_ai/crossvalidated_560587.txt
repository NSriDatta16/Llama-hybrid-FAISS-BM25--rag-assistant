[site]: crossvalidated
[post_id]: 560587
[parent_id]: 
[tags]: 
Why does a Decision Tree algorithm outperform the Random Forest Algorithm in certain cases?

Currently I write my master thesis that deals with the binary prediction of university dropouts (dropout - yes/no). In the thesis, I compare the performance of three different classification algorithms (K-nearest Neighbor, Decision Tree, Random Forest) during three different periods (t0, t1, t2). I use the following variables for the prediciton at each period: t0: age, gender, final high school grade, desired graduation (Bachelor/Master), study subject at the university t1: age, gender, final high school grade, desired graduation (Bachelor/Master), study subject at the university, average grade after the first semester, number of failed courses after the first semester t2: age, gender, final high school grade, desired graduation (Bachelor/Master), study subject at the university, average grade after the first semester, number of failed courses after the first semester, average grade after the seond semester, number of failed courses after the second semester For the prediciton of the university dropouts, I use the R package "caret". For the algorithms, I use the following methods: K-nearest Neighbor: "knn" Decision Tree: "rpart" Random Forest: "ranger" Overall, I get the following results for each period: t0: t1: t2: Graphical Representation of the results: Overall, I don't understand a few results and I hope that you could help me out: Why does the Decision Tree algorithm sometimes outperform the Random Forest algorithm? I thought that a Random Forest is generally better than a Decision Tree Algorithm because it basically combines several decision trees. Therefore, I assumed its performance would always be at least as good as the performance of a decision tree algorithm. However, the decision tree algorithm sometimes outperforms the random forest algorithm in my results (e.g. Decision Tree has a higher precision at t0 and a higher recall at t2) Why do all algorithms show similar results? Most of the time, they have values that are very close to each other. Only some outliers can be detected, but they are also not that large (highest difference is about 0.14). I assumed that the Random Forest would outperform the other two algorithms to some extent because its functionality is more complex. The only explanation I have is that I performed a hyperparameter tuning for the K-nearest Neighbor algorithm but not for the Random Forest algorithm. Why do the evaluation metrics rise most of the time at t1, but fall at t2? I expected that the evaluation metrics would rise over time because more explanatory variables are added to the models. I only have two guesses for that result: First, the distirbution of the target variable changes over time (t0: ~38% dropout, t1: ~33% dropout, t2 ~23% dropout). Second, I assume that the evaluation metrics falls at t2 because of the correlation of some variables (e.g. grade after first semester + grade after second semester). Maybe some of you can help me to answer these questions. Unfortunately, I'm a beginner at this topic and I don't have much knowledge about it. Every help is really appreciated.
