[site]: crossvalidated
[post_id]: 597413
[parent_id]: 41274
[tags]: 
The standard way to do this is to take the transition probability matrix for the Markov chain and raise it to the appropriate power. Since the process starts at state zero its final state will be in the range $-N \leqslant X_n \leqslant N$ so you can do this using a transition probability matrix with $2N+1$ states. This matrix has the form: $$\mathbf{P}_N = [p_{i,j} | -N \leqslant i,j \leqslant N],$$ where $p_{i,j}$ are the relevant transition probabilities. The relevant transition probabilities after $N$ steps are the elements of the matrix $\mathbb{P}_N^N$ . If we start at state zero then the probability of being in state $x$ after $N$ steps is given by the element $\mathbb{P}_N^N[0, x]$ . Implementation in R: We can implement your problem in R by programming a function to compute the relevant probability for ending in state x starting from the zero state. For general application we can program a function transition.prob to compute this probability. $^\dagger$ transition.prob = 1) { for (k in 1:N) { PN Using $N=10$ , $l=3$ , $p=\tfrac{1}{3}$ and $x=4$ we can use this function to compute the $N$ -step transition probability. The output shows that the transition probability is $\mathbf{P}_N^N[0, 4] = 0.078125$ . transition.prob(N = 10, l = 3, prob = 1/3, x = 4) [1] 0.078125 $^\dagger$ Note that the above code is illustrative only and is not the most efficient way to program for large values of N . For illustrative purposes I am using a fairly simple way to take matrix powers here and not trying to make it efficient using eigen-decomposition. The code also does not include checks to enforce sensible inputs.
