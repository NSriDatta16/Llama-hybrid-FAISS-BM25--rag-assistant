[site]: crossvalidated
[post_id]: 21774
[parent_id]: 21768
[tags]: 
Assuming a fixed effects model, with that number of records I would be amazed if you had a "textbook" normal probability plot. In my experience, analysis with large datasets, and certainly when they hit around 10K observations, have these types of issues. Have you: tested for outliers or influential points, e.g. with Cook's d ? compared the results of your various regressions with a measure like AIC or BIC ? If you're using R, you can use anova() to compare the models (if you've saved the models as an object) to see which one is best. do you have hetereoscedasticity in the residuals, if you compare a plot of fits against them? This is a little difficult to answer without actually seeing your normal probability plot, and the rest of the information from the points I list above. Update based on comments below: Sometimes you just can't get a better result from your data. I would simply include the residuals plot with your report/presentation as well as the other information so that people can judge your results for themselves. You've put some effort into improving the model - you should mention this and the impacts it had in your report/presentation as well. On your question about a better approach, one analyses the data one has in order to test a hypothesis. You say you have months of data, does that mean you have a time series, in which case would a time series analysis be more appropriate than a regression? Can you update your question with: the research question you have what your outcome/dependent variable is what your data are the model that you analysed (you can just copy and paste out of your model statement in your software) 2nd update: More questions/thoughts: you've used an average sales volume for a half hour period, is your dependent variable ( gallons ) for that matched half hour period on the day of interest? So you've got rows that all represent half-hour gallons , which you've linked to the preceding 4 week average for that day/half hour? for the variance in price from competitors, does that relate to the half hour gallons or have you done a 4 week average for that? given that day of the week probably influences sales, have you thought of adding in either a "weekend" indicator, or a "day of week" set of 6 indicators to your model? Because you've only got a 4-week average, you shouldn't need to worry too much about seasonality. 3rd update: I had assumed a volume product like petrol for point 3 above, but maybe you are looking at beverages so there may be a different "day" or "time of day" effect for that, e.g. lunch time sales, "movies" sales. Also, if your gallons measure is sequential, there may be autocorrelation which I don't think you would notice in any plots because you simply have so much data, and most plots I have seen demonstrating this for students normally have 100, or even only 10 plots so that people can see the autocorrelation easily. As noted at the end of that page, you should do the Durbin-Watson test for autocorrelation . The only situation I think of where gallons has a lower probably of occurring is if your gallons dates and times have been randomly sampled, because this should break any autocorrelation effect. Sorry to hit you with another test, but the computer will calculate it really fast.
