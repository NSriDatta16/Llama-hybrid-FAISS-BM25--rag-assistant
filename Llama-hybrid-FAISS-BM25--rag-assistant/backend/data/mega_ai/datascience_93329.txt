[site]: datascience
[post_id]: 93329
[parent_id]: 
[tags]: 
Can there be in-active neuron in output layer

I am new to deep learning, and was studying about it. I know that input from input layer is multiplied with weights and then added with bias. And output of this is passed to a activation function of a neuron in hidden layer. Suppose if we use 'Relu' as activation function and our weighted sum is less than 0, then that particular neuron will not be activated right! So similar to that what if some neuron in output layer have some value and that value is not accepted by a particular activation function means the value is below the threshold for that activation function, so will that particular neuron remain in-active.
