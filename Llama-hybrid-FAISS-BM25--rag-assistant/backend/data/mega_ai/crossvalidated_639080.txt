[site]: crossvalidated
[post_id]: 639080
[parent_id]: 638912
[tags]: 
TLDR. The bimodality is due to label switching. Just as a two-component normal mixture has a bimodal posterior, so does the this mixture of two sigmoid components: swapping the a/b and c/d parameter pairs (so the "first" component has parameters c/d and the "second" one parameters a/b) results in the same likelihood. One solution is to impose an ordering constraint. See also this in-depth tutorial by Michael Betancourt: Identifying Bayesian Mixture Models . I found this question interesting. So in writing an answer I proceed to considerably modify the simulation and to completely ignore the model specified by the OP. Nevertheless, I do fit a non-linear Bayesian model for the sum of two sigmoid components and the model converges reasonably well. So hopefully my answer is useful to the OP. The simulation Without loss of generality, I scale the time $X$ and the outcome $Y$ to the [0, 1] range. I also parametrize the sigmoid curve as a location-scale family: instead of $\operatorname{sigmoid}(ax + b)$ I use $\operatorname{sigmoid}((x - \text{loc}) / \text{scale})$ . Here are some examples of one- and two-sigmoid growth curves. For $\operatorname{sigmoid}((x-\text{loc})/\text{scale})$ , the location parameter is the $x$ value at which the function is equal to 0.5 and the scale parameter determines the steepness at $x = \text{loc}$ . Caveat: I suspect it is intended that the growth process starts at $(X=0, Y=0)$ and ends at $(X=1, Y=1)$ . However, the sigmoid function is defined on the real line and its return value might be greater than 0 at $x=0$ and less than 1 at $x=1$ . To constrain the sigmoid to start at ≈ 0 and end at ≈ 1 for $x\in[0,1]$ we have to make the function steep enough. This implies that location and scale are correlated; the closer the location is to the boundary (0 or 1), the stronger the correlation. I don't explicitly model the correlation between location and scale. As long as the location is within the interior — say between 0.1 and 0.9 — both parameters seems to be reliably estimated. The model I write a Stan model for a mixture of two sigmoid components and I fit the model twice, first to simulated experimental data and then to simulated control data. Aside: Little information is lost in fitting two smaller models to half of the data rather than one big to all of the data. Even in the OP's original formulation, the two groups have their own sigmoid parameters and the only shared parameter is the measurement error, $\sigma$ , which is negligible in this simulation. An important part of this Stan model is that the two location parameters are ordered: loc1 . This constraint breaks the symmetry between the two equally valid orderings of the two locations and thus removes one mode of the bimodal posterior. I use Stan's handy ordered vector type. parameters { ordered[2] locations; real scale1; real scale2; } transformed parameters { real loc1 = locations[1]; real loc2 = locations[2]; // inv_logit() is the sigmoid function. real mu = ( 0.5 * inv_logit((X - loc1) / scale1) + 0.5 * inv_logit((X - loc2) / scale2) ); } Note: The R code to reproduce the analysis, together with the complete Stan model, is attached at the end. And here is a summary the results. First, the posterior growth curves (in red) under the two conditions, Experimental and Control. Also shown (in light grey) is the simulated data. And finally the summaries of the two fitted models: # Experimental group #> variable mean median sd mad q5 q95 rhat ess_bulk #> 1 loc1 0.200 0.200 0.0143 0.0143 0.177 0.225 1.00 1911. #> 2 loc2 0.800 0.800 0.0141 0.0142 0.777 0.823 1.00 2537. #> 3 scale1 0.0495 0.0495 0.00142 0.00136 0.0471 0.0519 1.00 2792. #> 4 scale2 0.0508 0.0508 0.00148 0.00149 0.0484 0.0533 1.01 3219. #> 5 sigma 0.00956 0.00956 0.000178 0.000180 0.00928 0.00987 0.999 2136. # Control group #> variable mean median sd mad q5 q95 rhat ess_bulk #> 1 loc1 0.191 0.191 0.0123 0.0123 0.171 0.210 1.00 2535. #> 2 loc2 0.207 0.207 0.0115 0.0110 0.188 0.227 1.00 2515. #> 3 scale1 0.0492 0.0492 0.00232 0.00237 0.0454 0.0530 1.07 38.0 #> 4 scale2 0.0481 0.0481 0.00226 0.00234 0.0446 0.0519 1.07 34.0 #> 5 sigma 0.00992 0.00992 0.000193 0.000190 0.00961 0.0102 1.00 2490. The fit to the Experimental data is great while there are some issues with the fit to the Control data (two Rhat's of 1.07). Maybe this can be improved with stronger priors? Or even better — for modeling the simulated data at least — is to fit a single sigmoid component for Control. library("truncnorm") library("tidybayes") library("posterior") library("cmdstanr") library("tidyverse") set.seed(1234) # sigmoid = inverse logit = plogis sigmoid % expand( nesting(Curve, Group, a, b, c, d), Time = seq(0, 1, length = 31) ) %>% mutate( Ey = growth_curve(Time, a, b, c, d), Y = rnorm(n(), mean = Ey, sd = 0.01) ) # sim_df % filter(Group == "Control") sim_df % filter(Group == "Treatment") sim_data $Curve), Y = sim_df$ Y, X = sim_df $Time, I = sim_df$ Curve, A = distinct(sim_df, Curve, a, b, c, d) $a, B = distinct(sim_df, Curve, a, b, c, d)$ b, C = distinct(sim_df, Curve, a, b, c, d) $c, D = distinct(sim_df, Curve, a, b, c, d)$ d ) code scale1; real scale2; vector[K] nlp_a; vector[K] nlp_c; vector [K] nlp_b; vector [K] nlp_d; real sigma; // dispersion parameter } transformed parameters { real loc1 = locations[1]; real loc2 = locations[2]; vector[N] mu = ( 0.5 * inv_logit((X - nlp_a[I]) ./ nlp_b[I]) + 0.5 * inv_logit((X - nlp_c[I]) ./ nlp_d[I]) ); } model { nlp_a ~ normal(loc1, 0.1); nlp_c ~ normal(loc2, 0.1); nlp_b ~ normal(scale1, 0.01); nlp_d ~ normal(scale2, 0.01); sigma ~ normal(0, 1); Y ~ normal(mu, sigma); } " model $sample( data = sim_data, init = list(init, init), chains = 2, parallel_chains = 2 ) fit$ diagnostic_summary() draws % expand( nesting(.chain, .iteration, .draw, loc1, scale1, loc2, scale2), Time = seq(0, 1, length = 31) ) %>% mutate( Y = growth_curve(Time, loc1, scale1, loc2, scale2) ) %>% ggplot( aes(x = Time, y = Y) ) + geom_line( aes(Time, Y, group = interaction(Group, Curve)), alpha = 0.1, data = sim_df ) + stat_lineribbon(color = "#67000D") + scale_fill_brewer(palette = "Reds") + theme( legend.position = "none" )
