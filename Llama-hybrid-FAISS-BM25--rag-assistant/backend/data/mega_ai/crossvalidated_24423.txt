[site]: crossvalidated
[post_id]: 24423
[parent_id]: 24344
[tags]: 
Forgive the lack of measure theory and abuses of notation in the below... Since this is Bayesian inference, there must be some prior on the unknown in the problem, which in this case is the distribution of $X_1$, an infinite-dimensional parameter taking values in the set of distributions on $[0, 1]$ (call it $\pi$). The data distribution $S_k|\pi$ converges to a normal distribution, so if $k$ is large enough ( Berry-Esseen theorem ) we can just slap in that normal as an approximation. Furthermore, if the approximation is accurate the only aspect of the prior $p(\pi)$ that matters in practical terms is the induced prior on $(\text{E}_\pi(X_1),\text{Var}_\pi(X_1))=(\mu,\sigma^2)$. Now we do standard Bayesian prediction and put in the approximate densities. ($S_n$ is subject to the same approximation as $S_k$.) $p(S_n|S_k) = \int p(\pi|S_k)p(S_n|\pi,S_k)d\pi$ $p(S_n|S_k) = \int \frac{p(\pi)p(S_k|\pi)}{p(S_k)}p(S_n|\pi,S_k)d\pi$ $p(S_n|S_k) \approx \frac{\int p(\mu,\sigma^2)\text{N}(S_k|k\mu,k\sigma^2)\text{N}(S_n|(n-k)\mu + S_k, (n-k)\sigma^2) d(\mu,\sigma^2)}{\int p(\mu,\sigma^2)\text{N}(S_k|k\mu,k\sigma^2) d(\mu,\sigma^2)}$ For the limits of the integral, $\mu \in [0, 1]$, obviously; I think $\sigma^2 \in [0,\frac{1}{4}]$? Added later: no, $\sigma^2 \in [0,\mu(1-\mu)].$ This is nice -- the allowed values of $\sigma^2$ depend on $\mu$, so info in the data about $\mu$ is relevant to $\sigma^2$ too.
