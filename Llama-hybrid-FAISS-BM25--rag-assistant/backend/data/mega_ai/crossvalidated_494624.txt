[site]: crossvalidated
[post_id]: 494624
[parent_id]: 494388
[tags]: 
While many neural network architectures -- including those commonly used in object detection -- can deal with inputs of variable size, it's typically desireable to resize inputs to the same size to improve computational efficiency via "batching", since the workload can be more effectively parallelized. In object classification, the aspect ratio isn't that important to determining what an object is -- other than some pathological examples (for example, classifying ovals versus circlse). However in object detection, the objective often includes outputting the precise bounding box of the object, and it does matter what the aspect ratio is there -- you could imagine humans always have a width-height ratio of rougly 1:4, and the network might learn this fact as long as the aspect ratio is kept consistent.
