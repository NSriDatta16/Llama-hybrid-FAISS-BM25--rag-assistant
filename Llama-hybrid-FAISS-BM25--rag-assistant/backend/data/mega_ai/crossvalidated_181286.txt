[site]: crossvalidated
[post_id]: 181286
[parent_id]: 
[tags]: 
Proper approach to Gamma-distributed data prediction with measurement errors in outliers

My task is to predict Gamma-distributed data with a large number of extreme-valued outliers caused by measurement error (i.e. the machine that records the values intermittently malfunctions). My objective is to minimize Mean Absolute Error of the data as recorded by the machine -- meaning errors in predicting the "bad data" that these extreme outliers are considered just as much of a failure as if they were errors in predicting the "good data". All that matters is the Mean Absolute Error that the model produces on test data. Taking a very large sample, I can illustrate the distribution of the outcome in my data in the following ways: Density Plot Descriptive Statistics > summary(train.raw$Expected) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.01 0.51 1.43 17.15 4.06 33020.00 Note: Don't be confused by the fact that the outcome is called "expected". It's not an Expected Value in a statistical sense. It's what machine recorded as the outcome. Fitting of the Gamma distribution by maximum likelihood Parameters : estimate Std. Error shape 0.27855894 1.226094e-04 rate 0.01623498 1.408218e-05 Loglikelihood: -18048793 AIC: 36097590 BIC: 36097618 Correlation matrix: shape rate shape 1.0000000 0.5042223 rate 0.5042223 1.0000000 So, both the proportion, range, and variation of the outliers is pretty extreme here. I am not sure how to proceed. I could exclude outliers from my training data, left-censoring the data to a certain range (i.e. 0 to 20, 0 to 60, or 0 to 150, depending on my methodological choices for detecting outliers), though even then the remaining data still follows a Gamma distribution. Density Plot with Outliers (Y > 115) Removed However, when I do that, there are large absolute errors with test data, when one of the extreme values are encountered. On the otherhand, I can try to fit a model without removing the outliers. The primary problem here is that there's basically 0 correlation between predictor data and "bad" outcome data, thus the model (be it random forest, GLM, or anything else) is very unstable. I want to confirm that I should try to remove outliers / "bad" data from the training data and I could use guidance on finding the split between the natural ("real") high values in the long tail of the Gamma distribution and the measurement error ("bad") extreme values. Based on the subject matter, we only know that the maximal "real" values could be anywhere between 20 and 115. I am also open to suggestions on the best algorithm or model for use in this analysis, given the distribution and large size of the data.
