[site]: crossvalidated
[post_id]: 424201
[parent_id]: 424170
[tags]: 
Loss : Discrepancy between the response of superviser and learning machine for a given input x (Vapnik, 2000, p. 19). Different for regression, classficiation.. risk functional : Probability of "error" of the learning machine (Vapnik, 2000, p. 20). As described by @resnet this is replaced by empirical risk empirical risk functional , i.e., the frequency of "error" (Vapnik, 2000, p. 20). Error : Usually, it is used to describe the error of your ML algorithm (train error, test error, and so on) . Vapnik seems to be a bit inconsistent with usual usage of error. However, error is also not a very technical term. Note: Empirical risk is only the test error (not train error). Cost is used in ML terminology to describe the cost for miss-classification of an example (e.g., soft-margin SVM) - compared to the value that is added to the loss function from the regularization term. The "cost" parameter allows to balance between higher regularization error vs. miss-classification "cost" of the complete error term. The cost parameter is a very SVM specific term. For other ML algorithms it is often called the regularization parameter. Note: Cost function is not very specifically defined in literature see @resnet comment below. @resnet: "The term cost function is more general. It's like objective function but defined for minimization (whereas the objective function can either be defined as an maximization, in case of reward, or minimization)"
