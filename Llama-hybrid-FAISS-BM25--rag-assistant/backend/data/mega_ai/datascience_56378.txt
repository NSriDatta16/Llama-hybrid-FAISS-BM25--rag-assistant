[site]: datascience
[post_id]: 56378
[parent_id]: 54260
[tags]: 
Should i convert it back to a data frame? why not? Most of the sklearn transformers like LabelBinarizer outputs numpy array (it is one of design principal of scikit learn) so it is easier to work with ndarray in pipelines. Unless you absolutely need some features of panda it is good idea to work with ndarray what is the best practice to merge X with my 1 numerical feature now ? I would suggest to use Pipeline with FeatureUnion. FeatureUnion will run each pipeline in parallel and combine results of all the pipelines. Please look at example code below class DataFrameSelector(TransformerMixin, BaseEstimator): def __init__(self, include=None, exclude=None): self.include = include self.exclude = exclude def fit(self, X, y=None): return self def transform(self, X, y=None): """ Returns only attributes listed in %include parameter if it is not None else return all attributes except listed in %exclude parameter """ if self.include: return X[self.include].copy() else: return X.drop(self.exclude, axis=1) """Wrapper for LabelBinarizer as it only takes one parameter for fit and transform methods and is not working with pipeline""" class LblBinarizer(TransformerMixin, BaseEstimator): def __init__(self): self.binarizer = LabelBinarizer() def fit(self, X, y=None): return self.binarizer.fit(X) def transform(self,X,y=None): return self.binarizer.transform(X) cat_pipeline = Pipeline( [ ("select categorical features", prepare_data.DataFrameSelector(include=["ocean_proximity"])), ("Binarize categorical features", LblBinarizer()) ]) num_pipeline = Pipeline( [ ("select numerical features", prepare_data.DataFrameSelector(exclude=["ocean_proximity"])) ]) full_pipeline = FeatureUnion(transformer_list=[ ("num pipeline", num_pipeline), ("cat pipeline", cat_pipeline) ]) prepared_data = full_pipeline.fit_transform(housing_features)
