[site]: crossvalidated
[post_id]: 253559
[parent_id]: 244173
[tags]: 
You can view the task as multi-label classification , and use the typical metrics for multi-label classification, e.g. excerpt from {2}: Wikipedia also has a section on Statistics and evaluation metrics for Multi-label classification . But keep in mind that term extraction is a bit different, as explained in {1}: Despite these first evaluation experiences, no comprehensive and global framework has yet been proposed for computational terminology as there exist for many other NLP fields. Beside economic factors, it seems that evaluating terminology acquisition raises some specific intrinsic difficulties. [...] As mentioned above, traditional metrics of precision and recall are not appropriate for term extraction evaluation. One problem is that term relevance is a gradual rather than a binary notion and that one cannot expect all extractors or terminologists to deliver ranked list of terms. This led us to stem relevance on a terminological distance. A second problem is that no terminological standard can be considered as a stable and unique gold standard. FYI Getting the accuracy for multi-label prediction in scikit-learn References: {1} Nazarenko, Adeline, and Haifa Zargayouna. "Evaluating term extraction." In International Conference Recent Advances in Natural Language Processing (RANLP'09), pp. 299-304. 2009. https://scholar.google.com/scholar?cluster=10075060291670172889&hl=en&as_sdt=0,22 ; http://anthology.aclweb.org/R/R09/R09-1.pdf#page=323 ; https://pdfs.semanticscholar.org/a953/001b2be9b73574418ba42f8f48017629e11e.pdf {2} Tsoumakas, Grigorios, and Ioannis Katakis. " Multi-label classification: An overview. " Dept. of Informatics, Aristotle University of Thessaloniki, Greece (2006).
