[site]: crossvalidated
[post_id]: 370003
[parent_id]: 369952
[tags]: 
The issue is complicated because your model is logistic. Under normal circumstances such as in a linear regression, most things you say would apply. Focusing on the linear model, I say most because adding variables should not increase random intercept variance even if the variables are mediocre predictors. The random intercept variance can go up very slightly but it shouldn't be by much. But with logistic regression, the case is not necessarily so. I'll make some claims then explain why at the end. If you add variables that explain the outcome better to a multilevel logistic regression, the variance of the random intercept will increase. However, if that variable also accounts for the differences between the embarks, then the random intercept variance may decrease. If that variable in no way accounts for any differences between embarks but explains the outcome better, the variance of the random intercept will definitely go up. An example is a variable that you have centered using the mean of each embark on that variable such that it doesn't vary across embarks. This is because the error variance is fixed to $\pi^2/3$, such that any improvements to the model will reflect in increased random intercept variance, unless such improvements simultaneously explain differences between embarks thus reducing the random intercept variance. I hope this makes some sense. Replying to your comments about the ICC. Since you are using R, check out the MuMIn package which has an R-squared glmm function. This should allow you to calculate $R^2$ as defined by Nakagawa and Schielzeth http://dx.doi.org/10.1111/j.2041-210x.2012.00261.x Theirs is a relatively simple approach that takes the different sources of variance into consideration (fixed effects, random effects, logistic error) so that one can compare across models with varying fixed effects.
