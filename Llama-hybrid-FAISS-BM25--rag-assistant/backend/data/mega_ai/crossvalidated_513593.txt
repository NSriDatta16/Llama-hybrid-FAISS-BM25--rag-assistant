[site]: crossvalidated
[post_id]: 513593
[parent_id]: 500596
[tags]: 
Really, there is a lot of things that you can do: Make sure that you have sufficiently detailed data . I have had a quick look at the rules of the game you suggest , and I have learned that It matters what cards have actually been played, not only the cards that are in the deck. The timing of cards played matters. One can use a model that includes absolute or relative times in predicting outcome. You can use a gaussian model if you believe that a card may be useful only within a certain time interval during the game, or a logistic model if you believe that the card is only useful in the beginning or only at the end of a game. The order in which the cards are played matters. The problem is that even for 8 cards there are 8! = 40320 different orders to play them. Perhaps for the beginning it makes sense to take note of the order of each pair of cards, as well as how far from one another they typically appear. You may want to perform embedding on decks to determine what decks win more. I would proceed as follows: Represent each deck as n-dimensional vector, where each element is the number of cards of a particular type in the deck Perform a local embedding such as t-sne to project that data onto a 2D plot. You may need to play around with the embedding parameter until you get nice results Color each point by the average winrate of that precise deck. Visually look for clusters of high winrate, and identify what decks they are Similar to the above, try clustering Filter out only the decks that have high winrate As before, represent them as vectors Perform clustering , e.g. kmeans to obtain clusters of decks that have most similar cards. You may need to play around with the exact clustering method and distance function until you find one that fits naturally to your data For each cluster, display cards in that cluster, sorted by frequency of use
