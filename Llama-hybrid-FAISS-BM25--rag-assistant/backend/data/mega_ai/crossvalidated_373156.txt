[site]: crossvalidated
[post_id]: 373156
[parent_id]: 
[tags]: 
Bayesian linear regression (predictive distribution)

I'm studying a book about Gaussian processes in machine learning, and I do not know how to exactly compute the predictive distribution. In this question: Understanding the predictive distribution in gaussian linear regression said it is like $(1)$ , but I found in Bishop's Pattern Recognition and ML that this predictive distribution is like $(2)$ : \begin{align} f_*\mid x_*,\, X,\, y\quad &\to\quad \mathcal{N}(\sigma_n^{-2}x^T_* A^{-1}Xy,\; \hspace{13mm} x_*^T A^{-1}x_*) \tag{1} \\ f_*\mid x_*,\, X,\, y\quad &\to\quad \mathcal{N}(\sigma_n^{-2}x^T_* A^{-1}Xy,\; \sigma_n^2 I + x_*^T A^{-1}x_*) \tag{2} \end{align} (That is, with a different variance.) What happened? Why are they not equal?
