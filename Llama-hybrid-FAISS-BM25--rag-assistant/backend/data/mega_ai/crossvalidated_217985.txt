[site]: crossvalidated
[post_id]: 217985
[parent_id]: 217736
[tags]: 
For artificial neural networks (the kind employed in machine learning) there is no "dimensionality". As @user20160 notes, convolution nets are often presented in 2D to help us understand the operations of the network, but there is no position in space for any of the units, just connections to different parts of an image. In the website you link to, the neural network has a connectivity rule that is defined by unit-to-unit hop distances, meaning that there is an implicit 3D spatial location for each unit. To answer your question: I don't think there are any packages in R for this type of architecture (I haven't done an exhaustive search though). But, the NEURON or Brian simulation environments could potentially let you do it with simple integrate-and-fire units. As well, implementing it in R or python wouldn't be that hard - just define a point in space for each neuron and set a connectivity rule based on distance. I would note: whether such a design is useful is an open question. We see some patterns of connectivity the depend on distance in the real brain (see e.g. this paper ), so there may be a good reason to do it. As far as I know, though, no one has ever actually demonstrated a good reason from a machine learning perspective.
