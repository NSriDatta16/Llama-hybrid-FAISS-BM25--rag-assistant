[site]: crossvalidated
[post_id]: 551336
[parent_id]: 
[tags]: 
How can be normalized value from logistic function used to determine probability of binary classifier outcome?

I would like to discuss chapter that comes from Foreign-Exchange-Rate Forecasting With Artificial Neural Networks . This chapter (see screenshot) describes a binary classifier made from neural network output values (this case predicts binary output). I understand meaning of these formulas but what I do not understand is equation 12.4 in the sense how can be normalized value $g_i^+(x)$ used as a probability value for positive outcome and $1 - g_i^-(x)$ for negative outcome prediction? Q: How is strong connection between predicted value from neural network and probability of predicted binary outcome? Edit1: @mhdadk: I am aware of this work with probability in binary output, my question was more about how relevant is the normalization with the sigmoid logical function itself to produce confidence / probability measure (probability density). I'm thinking that, for example, if the input to normalization function is in the interval approx. $(-\infty, -5)$ or $(5,+\infty)$ will basically still be normalized to the value of 1 (simply and figuratively speaking). With respect to sigmoid function everything except values from the interval $(-5,5)$ will be "truncated" to the value very near of 1. And outside the interval $(-5,5)$ there is infinitely more values than inside this interval. How does the probability, after conversion to the normalized value $(0,1)$ , is significant in this manner?
