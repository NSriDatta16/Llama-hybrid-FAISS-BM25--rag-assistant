[site]: crossvalidated
[post_id]: 507644
[parent_id]: 507591
[tags]: 
So @wprime gave a part of the answer. Indeed, we want to set return_sequences=True because we don't just want the final prediction for each sequence, we want all the predictions along the way as well. By then reshaping the input correctly ( [batches, timesteps, features] ) we get a very good result. This is minimal working example: import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' from keras.models import Sequential from keras.layers import Dense from keras.layers import LSTM import keras import numpy as np # Generate dataset input = np.random.randint(0, 10, size=(2000,)) # Output is average of i-2, i-1 and i output = []; output.append(input[0]) # does not work for i = 0; output.append((input[0] + input[1]) / 2) # does not work for i = 1 for i in range(2, len(input)): output.append((input[i-2] + input[i-1] + input[i]) / 3) # for all i > 1 output = np.asarray(output); # Normalize to range 0-1 input = input / 10; output = output / 10; # Split into train/valid with 50/50 ratio split = int(input.shape[0] * 0.5) x_train = input[:split]; x_valid = input[split:]; y_train = output[:split]; y_valid = output[split:]; # Reshape input into [batch, timesteps, features] x_train = np.reshape(x_train, (1,x_train.shape[0], 1)) x_valid = np.reshape(x_valid, (1,x_valid.shape[0], 1)) y_train = np.reshape(y_train, (1,y_train.shape[0], 1)) y_valid = np.reshape(y_valid, (1,y_valid.shape[0], 1)) # Create and train LSTM network model = Sequential() model.add(LSTM(4, input_shape=(1000, 1),return_sequences=True)) model.add(Dense(1, activation='linear')) model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.1)) model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=400, batch_size=1, verbose=2) # Validate the results predictions = np.squeeze(model.predict(x_valid)) * 10; y_valid = np.squeeze(y_valid) * 10 print(predictions[50:55]) print(y_valid[50:55]) ```
