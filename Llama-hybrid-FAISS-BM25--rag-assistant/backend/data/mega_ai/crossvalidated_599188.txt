[site]: crossvalidated
[post_id]: 599188
[parent_id]: 
[tags]: 
How does the decoder predict directly the image in VAEs?

I am reading the VAEs paper Auto-Encoding Variational Bayes . In their loss function: they define reconstruction loss (second RHS term) as the expected value of the log p(x|z) wrt to the posterior of the prior. I understand that this expectation is the midpoint of the function because the posterior of the prior is a Gaussian. However, how is it possible to directly regress the mean with an MLP? In the encoder an MLP is used to return mean and variance for a Gaussian however in the decoder the MLP directly gives you the sample from p(x|z). Also is there any intuition why with just a sample from p(z) is enough to compute the expectation?
