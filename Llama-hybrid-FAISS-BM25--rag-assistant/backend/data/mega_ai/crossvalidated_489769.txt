[site]: crossvalidated
[post_id]: 489769
[parent_id]: 
[tags]: 
Accuracy measure for model which sometimes produces no prediction

I have a model which produces no output for some inputs. What's a reasonable way to measure the performance of the model against a data set, taking the "missing output" into consideration? And is there a sane way to compare this performance to a model with a continuous output? For example... The model I have is a classifier of the form: IF input between 0 and 10 THEN true ELSE if input between 11 and 20 THEN false This model will produce no classification for inputs below 0 or above 20. This is by design: the induction process has decided this range of inputs is the predictable part of the problem. To compute something like accuracy, I could treat "no output" as just being "wrong" (neither a true positive or true negative). But this doesn't seem right: I feel like I'm missing a bunch of ways to approach this situation. Compare this to a logistic regression model, where I have the probability of some classification, and presumably a threshold for true/false classifications. In this case, ROC AUC might be commonly used. Is there any sane way to compare a logistic regression model to one which produces no output for some inputs? Pointers much appreciated: I don't even have the right language to describe this situation.
