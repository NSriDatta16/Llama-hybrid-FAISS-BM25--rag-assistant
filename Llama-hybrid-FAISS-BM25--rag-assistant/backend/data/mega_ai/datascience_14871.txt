[site]: datascience
[post_id]: 14871
[parent_id]: 
[tags]: 
Spark MLLib - how to re-use TF-IDF model

I am using spark ml IDF estimator/model (TF-IDF) to convert text features into vectors before passing it to the classification algorithm. Here's the process: Datasets: Full sample data (labeled) Training (labeled) Test (labeled) Unseen (non-labeled) This is my current workflow: Fit IDF model (idf-1) on full Sample data Apply(Transform) idf-1 on full sample data Split data set into Training and Test data Fit ML model on Training data Apply(Transform) model on Test data Apply(Transform) idf-1 on Unseen data Apply(Transform) model on Unseen data I read somewhere that I should split my data into training and test BEFORE fitting IDF model; Fit IDF only on training data and then use the same transformer to transform training and test data. Why would you do that? What exactly do IDF learn during the fitting process that it can reuse to transform any new dataset. Perhaps, idea is to keep same value for |D| and DF|t, D| while use new TF|t, D| ? Also, how often I will Fit (not transform) IDF model against new unseen data? let say my model is ready for prediction. I made n prediction using same IDF and Classifier model. After that I want to retrain model as I have new data now. Should I also retrain IDF then?
