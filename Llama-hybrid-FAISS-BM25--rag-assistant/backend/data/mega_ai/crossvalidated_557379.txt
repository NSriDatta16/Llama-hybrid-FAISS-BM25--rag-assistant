[site]: crossvalidated
[post_id]: 557379
[parent_id]: 49671
[tags]: 
Bjorn's answer suggests a frequentist confidence procedure cannot handle sparse data, nor can it incorporate historical data. To illustrate this Bjorn provides the TGN1412 example, (see e.g. pages 2 and 92 to 94 here or Senn, S. (2008). Lessons from TGN1412 and TARGET: Implications for observational studies and meta-analysis. Pharmaceutical Statistics, 7(4):294â€“301. ), where 6 out of 6 patients with an adverse event on a test drug compared with 0 out of 2 placebo patients with an event. Using only the data provided above (while assuming equal exposure for all subjects and that a subject can experience only 1 event of interest), the figure below depicts confidence curves (one-sided p-values) testing hypotheses regarding the population-level adverse event rate $p$ for the active and placebo treatments. It also identifies the one-sided 97.5% confidence limits. This is formed by inverting the CDF of a binomial distribution based on the $\hat{p}_{pbo}=0$ and $\hat{p}_{act}=1$ point estimates. The estimated rate ratio is $\hat{p}_{pbo}/\hat{p}_{act}=0$ and a conservative upper 97.5% confidence limit is the ratio of the individual confidence limits, $0.84/0.54=1.56$ . Notice the point and interval estimate $0(0,1.56)$ for the rate ratio is not $0(-\infty,\infty)$ . This figure also shows Bayesian posterior densities (credible intervals of all levels) for the adverse event rate for each treatment based on an arbitrary uniform prior in each group. As estimators the posterior means are biased towards 0.5, which is evidenced by the observed point estimates. Also to note is the upper credible limit for the placebo event rate is noticeably shorter than the confidence limit. This credible limit may not have good coverage probability in repeated experiments, calling into question whether we should feel confident in its performance for this experimental result. Based on $100,000$ Monte Carlo simulations the two-sided equal-tailed $95\%$ credible interval for the incidence rate ratio is $(0.0096, 0.85)$ . Viewing the prior as a user-defined weight function that smooths the likelihood, the posterior densities can be seen as approximate p-value functions. The choice of interpreting a credible interval comes down to what one wants to measure using probability, the experimenter or the experiment. Based on these data and a uniform prior distribution, a strict posterior decision rule would lead one to conclude the unknown fixed true rate ratio is smaller than $1$ . Both methods can incorporate relevant historical data. Encoding the historical and current data through the likelihood, it is not clear what arbitrary user-defined weight function (prior) one should choose when smoothing the likelihood to construct the posterior intervals. Addendum : Per Bjorn's request we can also look at the scenario where both groups have zero observed events. Just as before the credible intervals are worrisomely shorter than the confidence intervals, and the posterior means are the result of biased estimators. The challenge now is to construct a point and interval estimate for the incidence rate ratio. The maximum likelihood estimate is $\frac{\hat{p}_{pbo}}{\hat{p}_{act}}=\frac{0}{0}$ , which we could define to be equal to $1$ . However, to construct conservative upper and lower confidence limits as before would produce values of the form $\frac{c}{0}$ . The Bayesian analysis of the rate ratio avoids this trouble because of the uniform prior distributions for each rate. This is equivalent to incorporating hypothetical experimental evidence by considering the scenario where each treatment group had recruited $2$ additional subjects, and $1$ subject in each group experienced the event of interest. This of course does not match the actual observed experiment, but it does provide conservative point estimates (conservative in the sense that the adverse event rate is not under estimated). This same examination of hypothetical experimental evidence can be performed by referencing the exact binomial sampling distribution, which is presented in the figure below. Under this hypothetical scenario, a conservative $95\%$ confidence interval can be constructed by using the ratios of confidence limits for the individual rates, producing $\bigg(\frac{\hat{p}^L_{pbo}}{\hat{p}^U_{act}},\frac{\hat{p}^U_{pbo}}{\hat{p}^L_{act}}\bigg)=\Big(\frac{0.006}{0.53},\frac{0.81}{0.003}\Big)=(0.011,270)$ . Another approach would be to invert the cumulative distribution function for the maximum likelihood estimator of the rate ratio while profiling the nuisance parameter $p_{act}$ . Based on $100,000$ Monte Carlo simulations, the two-sided equal-tailed $95\%$ credible interval for the rate ratio is $(0.068, 68.25)$ . If we instead investigate the difference in incidence rates then no hypothetical experimental evidence is needed when constructing confidence limits based on the binomial CDF. If a subject can experience more than 1 event or we have varying exposure for each subject (or both) then a Poisson or Negative Binomial model should be used instead. Treating fixed population-level parameters as random variables gives the appearance that more uncertainty is being accounted for, but often leads to credible limits (approximate confidence limits) that are too short.
