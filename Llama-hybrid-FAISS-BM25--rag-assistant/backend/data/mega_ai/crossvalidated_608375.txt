[site]: crossvalidated
[post_id]: 608375
[parent_id]: 608372
[tags]: 
The trouble with accuracy is that your model does not predict discrete classes. The neural network outputs values on a continuum that have a (granted, weak) interpretation as the probabilities of class membership. (I say it is weak because neural networks tend to lack probability calibration . That is, when they predict a probability of $p$ , the event does not happen with probability $p$ .) Consequently, your model has $0\%$ accuracy. Every prediction is at least a little bit incorrect. In order to get a positive accuracy score or a confusion matrix, you need to convert those continuous predictions into discrete categories, and this requires you to know the consequences of making incorrect decisions. I would argue that, if you do not know the consequences of the discrete decisions, you have no business making those decisions. All you should be doing is making accurate probability predictions. While you might be able to get an accurate model, even a high accuracy score could mislead someone into thinking your model does not make crucial mistakes. Mixing up two classes might be particularly disastrous, so much so that a user is willing to make sacrifices elsewhere (even leading to a less accurate model overall) in order to minimize how often such a mistake is made. The standard way to assess the probability predictions is through the crossentropy loss (“log loss” in some circles, much of Cross Validated being one such circle), which you can normalize using McFadden’s $R^2$ . Brier score, which you can normalize using Efron’s $R^2$ , could be a useful measure, too. Related Links Why is accuracy not the best measure for assessing classification models? Academic reference on the drawbacks of accuracy, F1 score, sensitivity and/or specificity Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules Classification vs. Prediction
