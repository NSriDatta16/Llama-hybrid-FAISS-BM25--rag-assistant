[site]: datascience
[post_id]: 116465
[parent_id]: 116415
[tags]: 
This is a GOOD question. Say you have taken a pre-trained CNN model and then fine-tuned it on your data. The model is productionized and works well for a few weeks but now you observe a drift. The ideal option is to fine-tune with the (old+incremental data) since you anyway used pre-trained models to start out with. The fine-tuning is usually a much shorter process and can be repeated again and again with new data. You could also look at the option of down-sampling old data and giving more importance to new data that has come in in past few weeks and fine-tune on this combination. You need not worry of catastrophic forgetting when you are fine-tuning data this way. To be safer, you can freeze most of the layers of the original network and only fine-tune the outermost layers. This way you are not tampering too much with the model and minimally tuning it. The articles you are referring to are not the right ones in the current situation. You should look at industry papers on incremental learning for CNN models and run thru' some of those for more detailed analysis. For eg: https://www.mdpi.com/2079-9292/10/16/1879 https://arxiv.org/abs/1712.02719 https://pdfs.semanticscholar.org/8f21/c99d8257c79baf22c211ed17a2224574b524.pdf Based on the actual situation at ground the strategies need to be chosen according. To repeat, if you are merely using a pre-trained model and fine-tuning it with your data which is what most practitioners do, then it is always better to just fine-tune the entire thing again instead of taking an incremental approach as fine-tuning in general does not take too much time. You can downsample the old data in case the new samples are limited or look at ways to increase the gradient update weightage for the new samples.
