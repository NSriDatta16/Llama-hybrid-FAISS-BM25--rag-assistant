[site]: datascience
[post_id]: 47234
[parent_id]: 
[tags]: 
Learning image embddings for clustering based on custom distance metric

I have a large dataset of images, and i can calculate their distance to oneanother. I will at a later point recieve new images where i can not determine their distances to the ones in my training set(or anyone else for that matter). My idea was to cluster these images, and then infer similar features for the new images, as those in the same cluster. I tried using the vgg16, vgg19, and resnet50 to encode the images and then use DBSCAN to cluster. It worked decently, however from my experience, DBSCAN does not work optimally in such a high dimensional space. I found this on here Another way is to learn an embedding that optimizes your similarity metric using a neural network and just cluster that But i am not sure what is meant here, how exactly should i train the network, in my mind i would have to define a loss function that punishes bad encodings. I though of simply taking the square distance between the calculated distance, and the distance in the encoded space, however i feel like there are multiple issues with that. I am most comfortable with keras, so if anybody know a repo or something along those lines, i would be grateful aswell!
