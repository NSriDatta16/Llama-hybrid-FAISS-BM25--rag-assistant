ke use of the function of V(x,y,t) as a video sequence where t is the time dimension, x and y are the pixel location variables. e.g. V(1,2,3) is the pixel intensity at (1,2) pixel location of the image at t = 3 in the video sequence. Using frame differencing A motion detection algorithm begins with the segmentation part where foreground or moving objects are segmented from the background. The simplest way to implement this is to take an image as background and take the frames obtained at the time t, denoted by I(t) to compare with the background image denoted by B. Here using simple arithmetic calculations, we can segment out the objects simply by using image subtraction technique of computer vision meaning for each pixels in I(t), take the pixel value denoted by P[I(t)] and subtract it with the corresponding pixels at the same position on the background image denoted as P[B]. In mathematical equation, it is written as: P [ F ( t ) ] = P [ I ( t ) ] − P [ B ] {\displaystyle P[F(t)]=P[I(t)]-P[B]} The background is assumed to be the frame at time t. This difference image would only show some intensity for the pixel locations which have changed in the two frames. Though we have seemingly removed the background, this approach will only work for cases where all foreground pixels are moving, and all background pixels are static. A threshold "Threshold" is put on this difference image to improve the subtraction (see Image thresholding): | P [ F ( t ) ] − P [ F ( t + 1 ) ] | > T h r e s h o l d {\displaystyle |P[F(t)]-P[F(t+1)]|>\mathrm {Threshold} } This means that the difference image's pixels' intensities are 'thresholded' or filtered on the basis of value of Threshold. The accuracy of this approach is dependent on speed of movement in the scene. Faster movements may require higher thresholds. Mean filter For calculating the image containing only the background, a series of preceding images are averaged. For calculating the background image at the instant t: B ( x , y , t ) = 1 N ∑ i = 1 N V ( x , y , t − i ) {\displaystyle B(x,y,t)={1 \over N}\sum _{i=1}^{N}V(x,y,t-i)} where N is the number of preceding images taken for averaging. This averaging refers to averaging corresponding pixels in the given images. N would depend on the video speed (number of images per second in the video) and the amount of movement in the video. After calculating the background B(x,y,t) we can then subtract it from the image V(x,y,t) at time t = t and threshold it. Thus the foreground is: | V ( x , y , t ) − B ( x , y , t ) | > T h {\displaystyle |V(x,y,t)-B(x,y,t)|>\mathrm {Th} } where Th is a threshold value. Similarly, we can also use median instead of mean in the above calculation of B(x,y,t). Usage of global and time-independent thresholds (same Th value for all pixels in the image) may limit the accuracy of the above two approaches. Running Gaussian average For this method, Wren et al. propose fitting a Gaussian probabilistic density function (pdf) on the most recent n {\displaystyle n} frames. In order to avoid fitting the pdf from scratch at each new frame time t {\displaystyle t} , a running (or on-line cumulative) average is computed. The pdf of every pixel is characterized by mean μ t {\displaystyle \mu _{t}} and variance σ t 2 {\displaystyle \sigma _{t}^{2}} . The following is a possible initial condition (assuming that initially every pixel is background): μ 0 = I 0 {\displaystyle \mu _{0}=I_{0}} σ 0 2 = ⟨ some default value ⟩ {\displaystyle \sigma _{0}^{2}=\langle {\text{some default value}}\rangle } where I t {\displaystyle I_{t}} is the value of the pixel's intensity at time t {\displaystyle t} . In order to initialize variance, we can, for example, use the variance in x and y from a small window around each pixel. Note that background may change over time (e.g. due to illumination changes or non-static background objects). To accommodate for that change, at every frame t {\displaystyle t} , every pixel's mean and variance must be updated