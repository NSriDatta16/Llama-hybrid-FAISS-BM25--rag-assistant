[site]: crossvalidated
[post_id]: 229111
[parent_id]: 
[tags]: 
Improving the speed of XGBoost CV

My data set has around 5 mil rows. I intend to use xgb,cv to find optimal no of tress and then use caret wrapper or my own custom hyper-parameter tuning function. XGBoost's in-built cv itself is taking a long time. I guess other functions will take even more time. Previsouly I worked on smaller data sets. XGboost ran very fast and smooth. so far I have tried doing CV by converting training data frame to sparse matrix, dcgMatrix and several other matrix types. Still it's taking lot of time. Last resort is to make a validation set and try to use that set for parameter tuning. theoretically this is more sound idea, but I have never tried it so little unsure about this. what are few ways to deal with large data sets?
