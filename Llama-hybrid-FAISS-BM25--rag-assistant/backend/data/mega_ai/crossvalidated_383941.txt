[site]: crossvalidated
[post_id]: 383941
[parent_id]: 383699
[tags]: 
You can always check the convergence of an algorithm by increasing the number of iterations or tuning the convergence criterion to be more precise. This rarely helps anything. We are usually more interested in whether the algorithm converged to a local extremum rather than the global one. A way to check that is by permuting the starting conditions for whatever solver you have: they should all lead to the same optimum. Another possibility is that the algorithm diverges rather than converges. This is usually evidenced by ludicrous estimates: but it seems to be worth repeating: you have to actually look at the output of whatever estimate you have and ask if it makes sense. Sometimes, there are certain smoothness conditions at the global maximum (or minimum) that need to hold for the solution to be unique. A singular Hessian or expected information will evidence some violation along these lines. For MCMC routines, varying the seed, the number of iterations, and the length of burn in sometimes has an impact on estimates. Can anything more be said in general, without knowing what algorithm you're using? Not really.
