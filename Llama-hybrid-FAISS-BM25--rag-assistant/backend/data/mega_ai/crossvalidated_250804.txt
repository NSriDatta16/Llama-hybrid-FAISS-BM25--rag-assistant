[site]: crossvalidated
[post_id]: 250804
[parent_id]: 234763
[tags]: 
In my experience with logistic regression where $n >> p$, using $L_1$ or $L_2$ regularization on the coefficients has little to no effect on inference. Variables that are selected by $L_1$ will usually have enormous $z$-scores - suggesting they remain in any final model. Furthermore, post-selection inference, or interpretation of $p$-values after performing variable selection, is a difficult and active research field. Since you seem to have ample data, regularization only complicates things. Instead, standard logistic regression with careful consideration of domain knowledge, collinearity, variable transformations, and quadratic/interaction terms will go a very long way. And since you have so much data, using data splitting techniques can give you further confidence in this (labor intensive) process.
