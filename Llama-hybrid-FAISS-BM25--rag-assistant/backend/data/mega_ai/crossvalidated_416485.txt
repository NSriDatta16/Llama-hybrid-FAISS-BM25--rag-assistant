[site]: crossvalidated
[post_id]: 416485
[parent_id]: 151478
[tags]: 
You predict a class if it is given maximum probability by the estimated model. So when some classes are not predicted that is simply because the model never gave them maximum probability. That might just be correct, and not necessary a reason for concern. So I disagree with the answer by @Nitin, proposing oversampling. You might say: but they did occur in the data . Yes, but it might have been rare occurrences! never really the most probable outcome given the predictors in the model. You didn't give us a context, what your classes represent in the "real world". You have very unbalanced classes. That might be because some classes really are uncommon in your population, or it might be some problems with data collection. You didn't tell us. But it is difficult to see that over (or under)-sampling can achieve anything that cannot be achieved using weights. Even more important, you are using (ordinal) logistic regression, which is not a classifier, see Why isn't Logistic Regression called Logistic Classification? . Logistic regression gives you estimated probabilities for class membership, and instead of just looking at the maximum predicted probability, you could compare the predicted probabilities with the population proportions. Or even pass to use some proper scoring rule . See Using proper scoring rule to determine class membership from logistic regression or Is accuracy an improper scoring rule in a binary classification setting? . About the use of over/under-sampling, our community member @Frank Harrell have on this site (and elsewhere) commented against its use, see Downsampling vs upsampling on the significance of the predictors in logistic regression and https://www.fharrell.com/post/class-damage/ .
