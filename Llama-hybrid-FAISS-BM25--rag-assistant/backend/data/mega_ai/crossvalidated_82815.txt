[site]: crossvalidated
[post_id]: 82815
[parent_id]: 
[tags]: 
data normalisation problems

I am pretty new in machine learning and hence facing a lot of confusion in data normalisation concepts. Someone pls clarify the following doubts : 1) While normalising a data matrix of m-samples x n-features, the normalisation should be done along m-samples or along the n-features i.e we normalise each row or each column here ? 2) We should normalise all the data together or normalisation should be done separately for each class. 3) Suppose I have a vector of 2-samples x n-features as shown class_1 0.4432 27.19 0.6733 0.0828 0.4134 -0.6662 0.3381 0.0552 0.0 -0.01167 0.0 0.0 0.0 0.00056 0.0 0.0 0.03111 0.05778 0.01333 0.0 -0.02722 -0.02333 0.0 0.00222 -0.02722 0.0 0.0 0.0 10100 10010 11000 10100 10100 11000 11000 10001 11000 10001 10001 10100 10001 10001 10001 class_2 0.7647 16.1073 0.7867 -0.2414 -0.2264 -0.8025 0.8649 -0.3524 -0.01944 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.04611 0.0 -0.01944 0.03556 -0.02722 0.03111 0.0 0.0 0.0 0.0 0.0 10010 10100 11000 10010 10001 10100 10010 10001 10001 11000 10001 10001 10001 11000 10001 How to normalise in this case as you can see that the first few features have float values but there are some which are encoded binary features ( the 00110 types are some position informations) . If we normalise what will happend to such information ? 4) The training and testing data should be separated after normalisation or before normalisation and then normalised ? 5) What about the user sample ? once I train and prepare my classifier the user give a SINGLE input of 1-sample x n-features ? It is quite obvious that the values for each feature will differ in magnitude greatly as compared to normalised data used in training and testing. How to handle this thing ?
