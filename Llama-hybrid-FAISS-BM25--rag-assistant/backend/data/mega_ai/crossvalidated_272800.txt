[site]: crossvalidated
[post_id]: 272800
[parent_id]: 
[tags]: 
CNN accuracy very low, what is wrong with this script?

I'm building an image recognition system that classifies cars from 10 different models. The input data is a folder with 100 images for each model. I am having difficulties because the model stagnates at 16% accuracy when tries to predict the test set. My question is: are there any major pitfalls in my script that are causing the model to work so bad? I modified a script that I found online for a CNN and that is the model that I use: from scipy import misc import numpy as np import tensorflow as tf import matplotlib.pyplot as plt from datetime import datetime from scipy.signal import convolve2d from scipy.io import loadmat from sklearn.utils import shuffle import os def y2indicator(y): N = len(y) ind = np.zeros((N, 10)) for i in xrange(N): ind[i, y[i]] = 1 return ind def error_rate(p, t): return np.mean(p != t) def convpool(X, W, b): # just assume pool size is (2,2) because we need to augment it with 1s conv_out = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME') conv_out = tf.nn.bias_add(conv_out, b) pool_out = tf.nn.max_pool(conv_out, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') return tf.nn.relu(pool_out) def init_filter(shape, poolsz): w = np.random.randn(*shape) / np.sqrt( np.prod(shape[:-1]) + shape[-1]*np.prod(shape[:-2] / np.prod(poolsz) )) return w.astype(np.float32) img_folder = 'cars' makes = [d for d in os.listdir(img_folder) if os.path.isdir(os.path.join(img_folder, d))] # index for model classification i = -1 # dict to put X & y data of all images into it data = {'X': [], 'y': []} for make in makes: make_path = os.path.join(img_folder, make) models = [d for d in os.listdir(make_path) if os.path.isdir(os.path.join(make_path, d))] for model in models: i += 1 model_path = os.path.join(img_folder, make, model) jpegs = [img for img in os.listdir(os.path.join(img_folder, make, model)) if 'jpg' in img] for j, jpg in enumerate(jpegs): if j -1: test_cost = session.run(cost, feed_dict={X: Xtest, T: Ytest_ind}) prediction = session.run( predict_op, feed_dict={X: Xtest}) err = error_rate(prediction, Ytest) print "Cost / err at iteration i=%d: %.3f / %.3f" % (i, test_cost, err) LL.append(test_cost) print "Elapsed time:", (datetime.now() - t0) Thanks for your help and sorry for the ignorance!
