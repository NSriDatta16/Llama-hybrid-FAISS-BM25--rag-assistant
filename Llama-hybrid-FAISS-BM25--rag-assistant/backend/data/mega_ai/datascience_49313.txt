[site]: datascience
[post_id]: 49313
[parent_id]: 
[tags]: 
How does BERT deal with catastrophic forgetting?

In the ULMFit paper authors propose a strategy of gradual unfreezing in order to deal with catastrophic forgetting. That is, when the model starts be fine-tuned according to a downstream task, there is the danger of forgetting information on lower layers. Although Google's BERT is also a pre-trained language model, which makes use of fine-tuning for downstream tasks, authors don't mention this phenomenon. Why is that the case? Is BERT immune to it? Or does it deal with this in another way?
