[site]: datascience
[post_id]: 123503
[parent_id]: 
[tags]: 
Tensorflow diagram for attention mechanism

I was reading the tutorial from tensorflow on the transformer model , however, when they explain the transformer model, they display such a picture : which I don't understand. What do the ingoing arrow and outgoing arrow mean? What do the bold vertical line and the normal horizontal lines mean? Why is there just one array for (key,value)?
