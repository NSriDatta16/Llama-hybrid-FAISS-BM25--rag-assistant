[site]: datascience
[post_id]: 108330
[parent_id]: 108324
[tags]: 
This is not how it works: If the ML model is Bayesian, for example Naive Bayes, then the prior probability is already factored in the predicted probability. It has been calculated on the training set. If it's not a Bayesian model, then the way the predicted probability is calculated is different and "complete", i.e. it's not meant to be modified. For example in a decision tree the probability depends on how many instances have a particular label in a particular branch of the tree in the training set. Again, it wouldn't make sense to multiply this predicted probability by some external global prior. The main principle in supervised ML is that anything which needs to be learned by the model should be obtained by the model itself from the training set. If some additional information is added, it's likely that there's something wrong with the method. Btw you're right that multiplying all the predicted posterior probabilities by some external prior would also mess up the probabilistic interpretation, since the probabilities across classes would not sum to 1 anymore.
