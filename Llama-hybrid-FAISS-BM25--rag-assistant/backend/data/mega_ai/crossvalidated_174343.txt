[site]: crossvalidated
[post_id]: 174343
[parent_id]: 
[tags]: 
Using a classifier's test error as a model evaluation metric for another model

I have a multi-class multi-label (MCML) dataset, built from a model I do not trust (assume I am right for distrusting it). Say I have 1000 patients with 14 feature scores, and 5 possible target labels - of which each patient can qualify for greater than or equal to one of those labels. X = 14 features: {x1, x2, ..., x14} Y = 5 target labels: {y1, y2, y3, y4, y5} Because I do not trust the model, I do not trust all of the labels the model I am examining, outputs. I want to perform an experiment, where I evaluate the reasonability of a model built from the dataset I distrust, but with one of the target labels in the label set deleted . I will thus have 5 experiments, where I delete only one of the target labels from the set {y1, y2, y3, y4, y5}. For example: Expt 1: X = {x1,x2,...x14}, Y={y2,y3,y4,y5} Expt 2: X = {x1,x2,...x14}, Y={y1,y3,y4,y5} Expt 3: X = {x1,x2,...x14}, Y={y1,y2,y4,y5} Expt 4: X = {x1,x2,...x14}, Y={y1,y2,y3,y5} Expt 5: X = {x1,x2,...x14}, Y={y1,y2,y3,y4} To evaluate each model, I compare how well a multi class multi label learner was able to learn the dataset (i.e, using various evaluation metrics for multi-label learners). Is it reasonable to use a machine learning classifier to judge the reasonability of a partial of a given model, compared to other partial models? As long as the target score vector's dimensionality is the same, I see no reason why this would be illogical. Also, is this a roundabout way of doing this? Perhaps there is a statistical technique that examines partial models built from a multi-class multi-label dataset which can tell me which labels are not informative?
