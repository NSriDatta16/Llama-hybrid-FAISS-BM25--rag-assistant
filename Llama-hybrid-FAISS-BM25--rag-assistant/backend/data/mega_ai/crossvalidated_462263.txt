[site]: crossvalidated
[post_id]: 462263
[parent_id]: 
[tags]: 
Construction of prior in Bayesian Statistics

I was trying to read this book on Bayesian Statistic and have I have trouble understanding the part in orange in the bottom image: I think I get what is defined in equation (3.9) and how having $R = X-AX$ could give us $X-AX \sim \pi_{mod.error}(r)$ but I don't get how we can have the prior distribution of $x$ from that, maybe knowing what is "hidden" behind proportional term could help. Source : (Calvetti and E. Somersalo, Introduction to Bayesian Scientific Computing , Springer, 2007) It is actually a type of issue I encountered several times in this type of examples ( like in interpolation noise-free data ) and I never know how to deal with those cases when we have an $Ax=R$ and we want to express the prior of $x$ given that the distribution of $R$ and the value of $A$ are known. I think the example above is quite representative. Any advice on how I could understand that?
