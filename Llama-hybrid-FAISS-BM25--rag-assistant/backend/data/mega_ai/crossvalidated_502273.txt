[site]: crossvalidated
[post_id]: 502273
[parent_id]: 502266
[tags]: 
Since this was too long for a comment, I will post it as an answer, though perhaps not a proper answer. As far as I understand, by using PCA you will lose the connection to the original variables. What you end up with are new features that best explain the total variance. Each of these new features is a linear combination of the original variables. CR_i and CC_i are measuring how much each of these new features are contributing to the variance. Maybe they are doing something like looking at the weights of each of the original variables in the linear combinations that give PC1, PC2 and so on. There are not enough details to know I guess. By the way, your toy example is not a good use case for PCA. After rescaling and centering, the data columns are nearly i.i.d. draws from a standard normal. All these variables will be nearly orthogonal, hence PCA will just give you the coordinate axes more or less (all the components will contribute equally to the variance as well and they are aligned with the original variables roughly). In fact, in the large-sample limit, the PCs would not be individually identifiable.
