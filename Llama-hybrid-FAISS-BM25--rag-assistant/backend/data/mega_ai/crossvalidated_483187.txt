[site]: crossvalidated
[post_id]: 483187
[parent_id]: 
[tags]: 
Difference between Log Transformation and Standardization

Is there any difference between the log transformation and standardization of data before subjecting the data to a machine learning algorithm (say k-means clustering)? It looks like a common approach in preprocessing for clustering algorithms is to first un-skew the data through the log transformation and then perform standardization. My question is, don't both of these methods achieve the same effect when it comes to un-skewing the data? That is, both seem to transform the data into a normal distribution. I do understand that standardization forces zero mean and unit variance but is it really required to perform both these methods on a single dataset? So where do these two preprocessing techniques differ?
