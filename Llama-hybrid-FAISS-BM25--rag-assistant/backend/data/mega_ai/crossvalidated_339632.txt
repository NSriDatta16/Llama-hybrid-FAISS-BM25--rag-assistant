[site]: crossvalidated
[post_id]: 339632
[parent_id]: 338923
[tags]: 
So, after trying many input and parameter tweaks, I came to a conclusion that LSTM cannot long dependencies until it gets long enough vector of past time series values. In my experiments a so-so good quality of forecast could be obtained after feeding the net with 64 lags, which span over the seasonalities in the model. Another thing is that minibatches are a bad idea if they were sampled randomly. In the realization of neural networks I played with I made it work with 100% of examples passed in iteration. That way I ensured that all examples come in time-wise sequences. Also it is worth mentioning that the LSTM result compared poorly against a linear benchmarking model. If you think I am wrong, give me good counter arguments.
