[site]: crossvalidated
[post_id]: 154902
[parent_id]: 
[tags]: 
Difference between SAS and R results - Nonlinear Regression

Hoping someone can assist with this rather niche question. I have a routine built in R for analysing depreciation curves, which is fit according to a logistic model with an additional additive intercept term. model = wrapnls(formula = outcome~ 1/(1 + exp(b*age-a))+c, data = data, start = c(a = 0,b= .01 ,c= 0), upper = c(a=100,b=100)) I fit this using nlmrt, as the Jacobian is probably poorly conditioned for some of the groups. Using nlmrt I achieve good results which exhibit satisfactory predictive power. Conversely, when using proc Nlin in SAS, I get a strange effect where the intercept term (c and I for the R and SAS code respectively) effectively tries to dominate, blowing up close to the average of the dataset, while the exponential terms become very small. In reality, the intercept should simply set the lower bound for the terminal value on the asset. SAS code looks as follows; PROC NLIN DATA = Model_Data METHOD = MARQUARDT; PARMS A = 0, B = 0 I=0; BOUNDS A Can anyone help me understand these different behaviours, and maybe give me some advice on how to get SAS to more faithfully reproduce the results from R?
