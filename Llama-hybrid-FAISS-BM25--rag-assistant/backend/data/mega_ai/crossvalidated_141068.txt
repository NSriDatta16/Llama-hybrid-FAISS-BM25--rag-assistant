[site]: crossvalidated
[post_id]: 141068
[parent_id]: 140925
[tags]: 
I think this is a common confusion among new students of statistics that OP is experiencing. At least I had a hard time wrapping my head around it. The difficult concept is that of the sampling distribution of an estimator. In order to explain sampling distributions of regression parameters teachers often explain by saying "if we drew a large number of samples of size n from the population of interest and performed regressions on the individual samples then our estimates obtained from our regressions would, in expectation (on average), equal the true population parameter. By using the central limit theorem we can construct confidence intervals for the parameters. Etc." This is not what people do in actual studies, it is just a thought experiment to illustrate that our estimates of $\beta$, or whatever other parameter we are looking for, come from a sampling distribution and that these estimates will vary, in a certain way described nicely by the central limit theorem, around the true parameter we are looking for. In actual studies data is almost always "pooled", meaning we use all the observations we have at the same time.
