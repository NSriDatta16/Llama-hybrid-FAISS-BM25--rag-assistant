[site]: crossvalidated
[post_id]: 534797
[parent_id]: 
[tags]: 
Does it make sense to find confidence intervals for neural networks?

I was trying to figure out at best the differences between confidence intervals , prediction intervals , credible intervals as tools to take into account uncertainty associated to predictions on unseen data. I've noticed that, when we look, for example, at Linear Regression , several studies propose to compute confidence intervals to quantify the uncertainty linked to the model parameters of regression ( $\beta_0, \beta_1 \, : y_i = \beta_1x_i + \beta_0$ ). So for example, in this case we find an interval such that at a certain confidence , e.g. $95\%$ the parameters $\beta_0$ or $\beta_1$ will lie in that interval. When it comes to other approaches like Neural Networks or Gradient Boosting , I have never encountered a similar approach to predict uncertainty associated to predictions but instead I've seen people running an Ensemble of models in order to come up with a distribution of the outputs and quantifying the uncertainty by taking the mean and standard deviation of outputs distribution. So what is the difference here? This is not of course the same as considering confidence intervals, as we are now considering distributions over outputs and not over the parameters of the model.. Is this other approach related to prediction intervals or credible intervals ? And why should we choose one thing instead of the other? Many thanks for your help, James
