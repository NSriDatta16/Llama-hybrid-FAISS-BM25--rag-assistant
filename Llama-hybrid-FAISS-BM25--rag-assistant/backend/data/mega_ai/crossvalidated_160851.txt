[site]: crossvalidated
[post_id]: 160851
[parent_id]: 160847
[tags]: 
There's an infinite amount of types regressions you could perform. Some examples that come to mind Logistic Regression Support Vector Regression Random Forest Regression and so on... On top of that, you can transform the input variables. This could involve taking the log, normalizing them, replacing the values with quantiles, the possibilities are endless. So how do you choose? One approach is to try many different models and see which one has the lowest error on a test set. But as you multiply the different models, one might just beat the others on the test set through sheer luck. The best is to think about the nature of your data and the form you expect the answer to take. Do you think the effects are additive? Then linear models might work well. Do you think there are complex, nonlinear interaction between your variables? Consider kernel methods or neural nets. Do you think the outcome is really determined by clusters and subclusters of the population? Then random forests might work best. You can try this cheat-sheet from sklearn but really the best is to think about your problem and what the regressions actually do.
