[site]: crossvalidated
[post_id]: 551477
[parent_id]: 
[tags]: 
Inverse of a noisy derivative

I have a series of samples (x(t), y(t)) , where both are noisy and with (assumed) iid errors (sx(t), sy(t)) . I need to measure a function z(x',y) = y(t) / x'(t) . However, because the true x'(t) is close to zero, the noise causes x_meas to jump up and down across 0, and therefore z_meas jumps up and down across 0 and up to infinity, because some values are extremely close to 0. Averaging the final result is basically worthless because of the infinities. So where is the statistically best (least biased, etc) place to apply smoothing? Ideally, I know what x(t) is supposed to be as the dependent variable, although there are open-loop errors so I can't treat that with an absolute. But it might still be the best place to apply a smoothing function (I've been using an SG filter, because it has less of a temporal offset and handles the corners when x(t) turns around). Is it better to filter x and then take the derivative there, or filter x' ? (Or are those effectively the same thing? And as a secondary question, if I wanted to preserve the errors for propagation, is there something I should do? Handling error for a running average is tricky. ... Side note: whatever I do, z(t) becomes pathological when going from x' > 0 to x' . In theory z(x',y) shouldn't change at that corner, but it totally does. Edit: on the shapes of the curves. x(t) is either going to be a relatively slowly varying sine wave or sawtooth. In theory, x'(t) = +/- k where k is a constant. y is going to be a rough rectangle, where it is y =~ x'(t) * (c + f(x,t)) . where c is a second constant and f(x,t) is an even more slowly varying function that is going to be roughly linear in x . The reason y is a distorted rectangle is that when x' jumps from + to -, the sign of y is going to flip.
