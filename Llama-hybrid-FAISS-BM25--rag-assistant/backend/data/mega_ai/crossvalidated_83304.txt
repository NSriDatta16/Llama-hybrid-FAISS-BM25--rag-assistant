[site]: crossvalidated
[post_id]: 83304
[parent_id]: 83283
[tags]: 
The derivation from the binomial distribution might gain you some insight. We have a binomial random variable; $$ p(x) = {n \choose x} p^x (1-p)^{n-x}$$ This can alternatively be computed recursively; $$ p(x) = \frac{(n-x+1)p}{x(1-p)}p(x-1)$$ If you keep the initial condition; $$ p(0) = (1-p)^n $$ Now let us assume that $n$ is large and $p$ is small but the average success of $p(x)$ is constant $(np = \lambda)$ . Then we can do the following; $$ P( X = i ) = {n \choose i} p^x (1-p)^{n-x} $$ We use that $p = \lambda / n$ . $$ P( X = i ) = \frac{n!}{(n-i)!i!} \left(\frac{\lambda}{n}\right)^i \left(1-\frac{\lambda}{n}\right)^{n-i} $$ We switch some variables around and evaluate; $$ P( X = i ) = \frac{n(n-1)(n-2)\cdots(n-i+1)}{n^i} \frac{\lambda^i}{i!} \frac{(1-\frac{\lambda}{n})^n}{(1-\frac{\lambda}{n})^i} $$ From calculus we know that $ \lim_{n\to\infty} (1 + x/n)^n = e^x $ . We also know that $[n(n-1)(n-2)\cdots(n-i+1)]/n^i \approx 1 $ because both the top and bottom are polynomials of degree $i$ . This leads to the conclusion that as $ n \to \infty$ : $$ P(X=i) \to \frac{ e^{-\lambda}{\lambda^i}}{i!} $$ You can then verify that $E(X) = \lambda$ and $\operatorname{Var}(X) = \lambda$ via the definition. We know that the binomial distribution approximates the normal under the conditions of the De Moivre-Laplace Theorem as long as you correct for the continuity, which is why $P(X\le x)$ is replaced by $P(X\le x+0.5)$ .
