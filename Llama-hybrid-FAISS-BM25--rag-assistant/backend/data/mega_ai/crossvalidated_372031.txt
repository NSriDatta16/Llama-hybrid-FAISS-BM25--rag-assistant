[site]: crossvalidated
[post_id]: 372031
[parent_id]: 
[tags]: 
Different results for stratified cross validation and train test split for CNN

I am trying to develop an image classifier using conventional neural networks. Now I was looking at evaluating the model using 10-fold cross validation and through repeated train test splitting (hold out partitioning). When I do repeated hold out partitioning, I get an average error of 1.5%, and for stratified cross validation, I get error of more than 10%. Just was wondering how this was happening? The code is as given below # X is the image feature input which is of size (4571, 91, 91) which represents 4571 images each of size 91x91. # y is the vector of labels # Repeated hold out partitioning y_c = to_categorical(y) for i in range(10): X_train, X_test, y_train, y_test = train_test_split(X, y_c, test_size=0.1, stratify = y_c) X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify = y_train) # reshape to be [samples][pixels][width][height] X_train = X_train.reshape(X_train.shape[0], 91, 91, 1).astype('float32') X_test = X_test.reshape(X_test.shape[0], 91, 91, 1).astype('float32') X_val = X_val.reshape(X_val.shape[0], 91, 91, 1).astype('float32') # create model model = Sequential() model.add(Conv2D(32, (5, 5), input_shape=(91, 91, 1), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.2)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dense(2, activation='sigmoid')) # Compile model model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=40, batch_size=8, verbose=1) # Final evaluation of the model scores = model.evaluate(X_test, y_test, verbose=0) print("CNN Error: %.2f%%" % (100-scores[1]*100)) // # X is the image feature input which is of size (4571, 91, 91) which represents 4571 images each of size 91x91. # y is the vector of labels # Stratified cross validation skf = StratifiedKFold(n_splits=10, random_state=42) skf.get_n_splits(X, y) print(skf) conf_mat = np.zeros(shape=(2,2)) for train_index, test_index in skf.split(X, y): # print("TRAIN:", train_index, "TEST:", test_index) X_train, X_test = X[train_index], X[test_index] y_train, y_test = y_c[train_index], y_c[test_index] X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify = y_train) # reshape to be [samples][pixels][width][height] X_train = X_train.reshape(X_train.shape[0], 91, 91, 1).astype('float32') X_test = X_test.reshape(X_test.shape[0], 91, 91, 1).astype('float32') X_val = X_val.reshape(X_val.shape[0], 91, 91, 1).astype('float32') # create model model = Sequential() model.add(Conv2D(32, (5, 5), input_shape=(91, 91, 1), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.2)) model.add(Flatten()) model.add(Dense(128, activation='relu')) model.add(Dense(2, activation='sigmoid')) # Compile model model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=40, batch_size=8, verbose=1) # Final evaluation of the model scores = model.evaluate(X_test, y_test, verbose=0) print("CNN Error: %.2f%%" % (100-scores[1]*100)) X is the image feature input which is of size (4571, 91, 91) which represents 4571 images each of size 91x91. y is the label vector of size(4571, )
