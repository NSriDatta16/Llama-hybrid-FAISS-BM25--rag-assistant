[site]: crossvalidated
[post_id]: 539096
[parent_id]: 
[tags]: 
How to create an ML training dataset from unevenly spaced multivariate timeseries?

I have a time series dataset with multiple features X_n from which I want to predict an output y. However, both the x and y values are unevenly spaced and were sometimes collected at different frequencies. For example, let's say the temperature variable is collected 3 times a day while the oxygen saturation is only collected once a day and then the output (harvest weight) is collected once every two days. In addition sometimes the data was just not collected and so there will be a lot of values missing. What is the best practice in modelling these kind of datasets? Should I do a very basic linear interpolation between all the data points and then supply the most granular frequency with interpolated values to the model? Or is it best practice to stick to the less granular values and lose all the information from the higher frequency data? The intention is to create a dataset over which I will use sliding windows to feed into a variety of ML forecasting models (gaussian processes, LSTM, CNNs, symbolic regression etc) Any help would be much appreciated!
