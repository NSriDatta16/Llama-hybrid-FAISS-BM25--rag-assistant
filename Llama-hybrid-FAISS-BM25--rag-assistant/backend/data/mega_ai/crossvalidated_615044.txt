[site]: crossvalidated
[post_id]: 615044
[parent_id]: 
[tags]: 
Accounting for edge cases without training on the test set

I'm fine-tuning a large language model to predict binary sentiment, where a false negative is far more costly for my use case than a false positive. I've used weighted cross-entropy to account for this, and when I evaluated my model on the test set, there were a few cases in the test set that were unacceptable misclassifications. I then decided to re-train the model by manually imputing those edge cases to my training data, and it no longer made that mistake. However, I know it is poor form to "train on the test set", which is to an extent what I'm doing. How else am I supposed to account for this specific edge case not being misclassified?
