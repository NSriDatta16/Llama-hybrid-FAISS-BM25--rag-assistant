[site]: datascience
[post_id]: 123225
[parent_id]: 
[tags]: 
Recall and Precision ML models

I use decision trees for a binary classification. To evaluate the model, I use K-fold cross-validation, where k = 10. When I run the model n times, I get a relatively constant accuracy across all folds, for each run, with an average accuracy of about 0.85 (note that I have not yet tune the hyperparameters). However, my values for Recall and Precision show some (significant) deviations. Please note that my random state = None and shuffle = 10. If I change my random state to 100, the results are constant (as it performs the same split/uses the same set). But what I would like to know... are these discrepancies not too high? and is it perhaps due to my data set (which is quite limited, with a total of 2500 data points). Recall run 1 : class 0 is 0.84 / class 1 is 0.87 run 2 : class 0 is 0.77 / class 1 is 0.99 run 3 : class 0 is 0.76 / class 1 is 1 ....... Precision run 1 : class 0 is 0.85 / class 1 is 0.87 run 2 : class 0 is 0.98 / class 1 is 0.81 run 3: class 0 is 1 / class 1 is 0.83 .......
