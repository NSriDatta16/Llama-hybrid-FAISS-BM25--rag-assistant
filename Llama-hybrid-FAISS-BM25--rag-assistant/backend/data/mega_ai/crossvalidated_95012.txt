[site]: crossvalidated
[post_id]: 95012
[parent_id]: 94974
[tags]: 
It seems to me that, if a value is meaningful, its exact value is meaningful. The p value answers this question: If, in the population from which this sample was randomly drawn, the null hypothesis was true, what is the probability of getting a test statistic at least as extreme as the one we got in the sample? What about this definition makes an exact value meaningless? This is a different question from the ones about extreme values of p. The problem with statements that involve p with many 0's are about how well we can estimate p in the extremes. Since we can't do that very well, it makes no sense to use such precise estimates of p. This is the same reason we don't say that p = 0.0319281010012981 . We don't know those last digits with any confidence. Should our conclusions be different if p I think the problem is with how we typically conclude things about p. We say "significant" or "not significant" based on some arbitrary level. If we use these arbitrary levels, then, yes, our conclusions will be different. But this is not how we should be thinking about these things. We should be looking at the weight of evidence and statistical tests are only part of that evidence. I will (once again) plug Robert Abelson's "MAGIC criteria": Magnitude - how big is the effect? Articulation - how precisely is it stated? Are there lots of exceptions? Generality - to what group does it apply? Interestingness - will people care? Credibility - does it make sense? It is the combination of all of these that matters. Note that Abelson doesn't mention p values at all, although they do come in as a sort of hybrid of magnitude and articulation.
