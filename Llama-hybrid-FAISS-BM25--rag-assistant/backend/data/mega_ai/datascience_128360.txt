[site]: datascience
[post_id]: 128360
[parent_id]: 
[tags]: 
Reduce mode searching behaviour of VAE

I'm applying VAEs to sections genomic data (haplotypic vcf format, so binary variables), with one model being trained on each section. They each have different layer sizes and weights to better fit the sections of data, but share training hyperparametres. Depending on which section I'm applying these methods to, my models sometimes exhibit mode searching behaviour quite heavily. These are PCA plots of my data for 4 sections before and after autoencoding. The base values are represented in grey, and the decoded values in red. So a perfect autoencoding process should have one red dot over each grey dot (I know that isn't the true goal of a VAE). In the two plots on the left, the decoded data quite visibly concentrates in the densest regions of the distribution of the base data, with a "path" of samples between these modes. On the right, the decoded data is much more dispersed throughout the distribution of the base data. To obtain this, I already greatly decreased the weight of the KL divergence within the loss calculations of my VAE models to allow them to "explore" the latent space more, but this seems to not be sufficient to eliminate the mode searching behaviour in all of them. What paths can I explore to try to remedy this mode searching behavious in my VAE models? I am working with keras in Python3, so bonus points if your answer includes methods that work in that environment.
