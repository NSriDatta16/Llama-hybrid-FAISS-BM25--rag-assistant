[site]: datascience
[post_id]: 47134
[parent_id]: 
[tags]: 
Designing a pretrained DNN for image similarity

I am pretty new to deep learning and really hope that you can help me. I want to write a python program that lets me choose an area in a reference image. This subimage of variable size should then be used to search in a database of images. Then the parts of the images with the highest similarity to the reference sub image should be given. However I have big problems with the sizing of the reference and database images. I tried to read into pretrained DNNs (like VGG19) and use the features of a last layer for similarity computation. But these DNNs seem to accept input arrays only in certain resolutions. Should I then rescale the reference image? The database images will most likely be much larger than the reference. Should I then partition all the database images into smaller subsets? Or use a single shot algorithm like YOLO? Since there are so many different algorithms I would be very thankful for every comment or idea. Lasse
