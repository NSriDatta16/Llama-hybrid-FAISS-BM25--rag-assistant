[site]: crossvalidated
[post_id]: 362066
[parent_id]: 
[tags]: 
Keras NN - loss gets stuck at 8.6791

What does it mean when my neural network always gets stuck at the exact number 8.6791 when I use binary-crossentropy loss? Some strange local minimum? It happens regardless of my learning rate, initialization, activation function, regularizer, or choice of optimizer. The only thing that changes it is a change of architecture or a new loss function, which are things I don't want to change...
