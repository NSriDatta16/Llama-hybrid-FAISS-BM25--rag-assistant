[site]: datascience
[post_id]: 128248
[parent_id]: 
[tags]: 
As a result of cross-validation, the difference between the ideal auc values â€‹of the train set and the test set

In the attached figure, the x-axis is the number features of s removed, and the y-axis is the average auc score over 10 CVs. I want to choose the point with the highest score while avoiding overfitting points. While looking for standards for overfitting, I found here that a 10% difference in auc score is 'overfitting' and a 1% difference is 'balanced/good fit'. Then, I realized that if the difference is more than 10% even after cross validation, overfitting can be suspected. However, what is curious is when the score difference is more than 1% and less than 10%. For example, if the difference is 5%, should you suspect overfitting? Or should we suspect overfitting when it is 9%? Or, if it is less than 10%, do we not need to suspect overfitting?
