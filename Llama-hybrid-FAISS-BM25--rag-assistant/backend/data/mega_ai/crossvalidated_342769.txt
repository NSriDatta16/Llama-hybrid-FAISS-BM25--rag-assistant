[site]: crossvalidated
[post_id]: 342769
[parent_id]: 
[tags]: 
Stabilizing variance and dependence of data on its mean

I am reading Practical Machine Learning with Python , about feature engineering, section Statistical Transformations . This sections starts with the following lines Letâ€™s look at a different strategy of feature engineering on numerical data by using statistical or mathematical transformations. In this section, we will look at the Log transform as well as the Box-Cox transform. Both of these transform functions belong to the Power Transform family of functions. These functions are typically used to create monotonic data transformations, but their main significance is that they help in stabilizing variance, adhering closely to the normal distribution and making the data independent of the mean based on its distribution. I have two questions, and since they are similar I am asking in a single post. Q1: I know what variance is but I don't understand what "stabilizing variance" is. How do we determine if a variance is "stable" or not? Any explanation with an example or reference would be helpful. Q2: What does it mean for data being "independent of the mean"? Isn't the mean a function of (numeric) data, and so it is mean that depends on data? I can't imagine how data can depend on its mean.
