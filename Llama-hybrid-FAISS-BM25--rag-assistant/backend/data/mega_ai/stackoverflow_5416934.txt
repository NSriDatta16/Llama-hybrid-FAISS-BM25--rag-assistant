[site]: stackoverflow
[post_id]: 5416934
[parent_id]: 
[tags]: 
C++ file operations cause "crash" on embedded Linux

I'm in a embedded led measuring system project now. It uses ARM & linux, and has 64M memory and 1G storage. When measuring, it's supposed to write data to a .csv file. I did it this way: Create/open a file before measurement begins In the measuring loop, when data is ready, put it into the file, then go to next measuring When user stop the measurement, the file will be closed But, when I add this feature, the program keep running several hours, then the machine won't respond to anything ( measuring stopped, UI still display but doesn't respond to any action, etc.). And the csv file is about 15MB. While without this feature, the machine can work well all day. I've thought about this, maybe It's because the memory is used up. With such a small memory, is it possible to keep writing a file? Or should I close it every time I finished writing data? (In that case, I will have to open/close the file very frequently, it will cause our system to be slow, what is not glad to see) Apologize for my poor English, maybe someone can understand it and give me some help. God is lighting your path, thank you all! ps: I do believe the file operations itself is correct. the code like this: std::ofstream out_put; out_put.open(filePath, std::ofstream::out | std::ofstream::trunc); while(!userStoped()){ doSomeMesuring(); for(int itemIndex = 0; itemIndex mdata.item[itemIndex].mvalue mdata.item[itemIndex].judge
