[site]: datascience
[post_id]: 15930
[parent_id]: 
[tags]: 
Xgboost (classification problem) feature importance per input not for the model

I have trained a xgboost model for a classification problem. I'm able to get the feature importance for the model as below. http://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/ But I would like to get feature importance per input. Basically, one input may give me a output probability 0.9, another one input may give me a output probability 0.1. I want to know because which features (with values) give me a probability 0.9? which features (with values) give me a probability 0.1? How can I approach that? Is there a package for this?
