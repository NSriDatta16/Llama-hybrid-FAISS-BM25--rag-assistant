[site]: stackoverflow
[post_id]: 3078989
[parent_id]: 3078502
[tags]: 
As background you may note bechmarks such as specmarks . Compared with your scenario there is significantly more processing, but you will see that your 30,000 req/sec is a comparatively high, but not insanely high, figure. You may also find Joines et al useful. (Disclaimer: they're colleagues.) In your scenario I would expect in descending order of cost: Database retrieval Network activity reading and returning requests Simple processing You're not doing complex processing (Eg. graphic rendering or rocket-science type math). So first guess: if your dictionary were a database then then the cost of doing a query is going to dominate everything else. Traditionally, when we hit bottlenecks in the Web/App server tier we scale by adding more instances, but if the database is the bottleneck that's more of a problem. So one direction: what performance can you expect from a database engine does 30k tps seem feasible? Your first observation: cache stuff is a commonly used stategy. Here you have (presumably) random hits across the whole dictionary, hence caching recent asnwers in itself is probably not going to help, unless ... can you cache the whole thing? 50,000,000 * (100 + overhead) == ?? On a 64bit JVM on a 64bit OS maybe it fits? If not (and as the data gets really big, then probably not) then we need to scale. Hence a strategy of slicing the cache may be used. Have (for example) 4 servers, serving A-F, G-M, N-P, T-Z respectively (and, note, 4 separate caches or 4 separate databases). Have a dispatcher directing the requests.
