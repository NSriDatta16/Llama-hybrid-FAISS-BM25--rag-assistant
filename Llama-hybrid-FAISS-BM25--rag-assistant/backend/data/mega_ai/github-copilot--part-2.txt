ks. After accomplishing the request, it tags the user for code review. It is essentially an asynchronous version of agent mode. Reception Since Copilot's release, there have been concerns with its security and educational impact, as well as licensing controversy surrounding the code it produces. With the nature of large language models relying on massive datasets scraped from public sources, this makes it difficult to ensure that the data used for training is fully accurate, unbiased, and ethically sourced. Including Copilot, which is based off of large language models, is no different. Copilot will generate code derived from vast datasets that may include copyrighted or insecure examples. According to a study in December 2021, Copilot was given 89 scenarios that could replicate a MITRE CWE to auto-fill, creating a total of 1689 programs, in which 40% of code auto-filled by Copilot was deemed vulnerable. Licensing controversy While GitHub CEO Nat Friedman stated in June 2021 that "training ML systems on public data is fair use", a class-action lawsuit filed in November 2022 called this "pure speculation", asserting that "no Court has considered the question of whether 'training ML systems on public data is fair use.'" The lawsuit from Joseph Saveri Law Firm, LLP challenges the legality of Copilot on several claims, ranging from breach of contract with GitHub's users, to breach of privacy under the CCPA for sharing PII. GitHub admits that a small proportion of the tool's output may be copied verbatim, which has led to fears that the output code is insufficiently transformative to be classified as fair use and may infringe on the copyright of the original owner. In June 2022, the Software Freedom Conservancy announced it would end all uses of GitHub in its own projects, accusing Copilot of ignoring code licenses used in training data. In a customer-support message, GitHub stated that "training machine learning models on publicly available data is considered fair use across the machine learning community", but the class action lawsuit called this "false" and additionally noted that "regardless of this concept's level of acceptance in 'the machine learning community,' under Federal law, it is illegal". Privacy concerns The Copilot service is cloud-based and requires continuous communication with the GitHub Copilot servers. This opaque architecture has fueled concerns over telemetry and data mining of individual keystrokes. In late 2022 GitHub Copilot has been accused of emitting Quake game source code, with no author attribution or license. See also ChatGPT Tabnine Devstral Cursor (code editor) Devin AI Generative AI Microsoft Copilot Code completion Vibe coding References External links Official website