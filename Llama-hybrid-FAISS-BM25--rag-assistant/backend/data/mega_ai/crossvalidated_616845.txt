[site]: crossvalidated
[post_id]: 616845
[parent_id]: 
[tags]: 
Multi-class classification, KBestFeatures, different scores best for different labels - intelligent way to approach?

So I have a dataset with about 6x features as I have samples, which are balanced across 8 classes. I set out to figure out which features are important for each label. I've been approaching this using Logistic Regression in the multinomial setting. Initially I had used all ~300 features but knew there was strong colinearity in some of the features, and opted to combine them using some correlation cut off - this reduced things to ~150 features, but I'm still in a bind as it comes to 'feature importance'. I'm currently using Nested Cross validation - an inner loop which tunes the C hyperparameter, and an outer loop for testing. After integrating a 'KBestFeatures' module into the pipeline, I noticed different 'KBestFeatures' are better for different classes - for example, lets say 30 features allows for reliable classification of Class 1, while all 150 features makes for strong classification of Class 6 while bringing Class 1 much closer to chance. I feel a bit overwhelmed with all this. The whole reason I'd set up the nested CV was to avoiding the kind of tinkering I'm doing. Is there some more straight forward approach for arriving at the minimal feature set for each class I'm looking to identify? I also haven't gotten to the point of doing significance testing which will obviously be important. I've been looking for ISL and ESL and nothing is quite hitting me as the natural approach to this problem, outside of perhaps training individual models 'manually', but that seems wrong as well... Any tips would be great.
