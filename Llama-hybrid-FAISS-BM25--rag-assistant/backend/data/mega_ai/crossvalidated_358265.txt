[site]: crossvalidated
[post_id]: 358265
[parent_id]: 358214
[tags]: 
To some degree, the first two come for free with language modeling. In language modeling, we attempt to maximize $E[P(X_{1..T})]$ where $X_{1..T}$ is a sequence of words sampled from our dataset, and $P(X_{1..T})$ is our model. Usually we factor $P(X_{1..T})$ as: $$P(X_{1..T}) = \prod_{t=0}^T P_\theta(x_t|x_{ Sentence completion: given the start of a sentence $x_{1..k}$ simply sample $X_k \sim P_\theta(x_k|x_{ Semantic classification: simply check using a standard parser whether the sentence is syntactically valid. If it is, then you can say the next word is semantically valid if $\frac{P_\theta(x_k = X_k|x_{
