[site]: crossvalidated
[post_id]: 240432
[parent_id]: 240426
[tags]: 
First off, you can do dimensionality reduction of features independent of any particular prediction problem, i.e. representation learning . In the context of prediction problems, sparsity-promoting regularization can be used to automatically perform feature selection . This is commonly accomplished using $L_1$ penalties such as LASSO for linear regression (and also in deep learning ). ($L_1$ regularization is also used in representation learning, such as sparse coding and sparse autoencoders ).
