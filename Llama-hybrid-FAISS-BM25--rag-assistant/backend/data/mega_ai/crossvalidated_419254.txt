[site]: crossvalidated
[post_id]: 419254
[parent_id]: 
[tags]: 
Posterior distribution from piecewise likelihood

Consider a hierarchical Bayesian model for analysing data from an inhomogeneous Poisson process that we observe in discrete time. Let $Y_i, i = 1,...,n$ , be the number of events occurring in the time interval $[i−1,i]$ and assume that $P(Y_i=y_i | \lambda,\theta,k) = \begin{cases} \frac{\lambda^{y_i}}{y_i!}e^{-\lambda} & \text{for } i ≤ k \\ \frac{\theta^{y_i}}{y_i!}e^{-\theta} & \text{for } i > k \end{cases}$ where $k$ is an integer value. In other words, the intensity of the process is $\lambda$ before time k and $\theta$ after time k. Derive the posterior density of the unknown parameters given the observed data f(θ, λ, k|y1, . . . , yn) $f(\theta,\lambda,k|y_1,...,y_n)$ . The proposed solution: The posterior density is: $f(\theta,\lambda,k|y_1,...,y_n)\propto f(\lambda)f(\theta)f(k)f(y_i,...,y_n|\theta,\lambda,k)$ = $f(\lambda)f(\theta)f(k)\prod_{i=1}^{k}\frac{\lambda^{y_i}}{y_i!}e^{-\lambda}\prod_{i=k+1}^{n}\frac{\theta^{y_i}}{y_i!}e^{-\theta}$ On the last line of the solution: Where do the two iterated products ( $\prod_{i=1}^{k}...\prod_{i=k+1}^{n}...$ ) come from? In my intuition, the posterior $f(y_i,...,y_n|\theta,\lambda,k)$ should be a product of n factors, each being a y-distribution i.e. $P(Y_i=y_i | \lambda,\theta,k)$ . Why does it suffice to include k factors from the first distribution and n-k factors from the second? I understand that Bayes's rule is involved here, but I can't seem to get the steps right. Nevermind, I figured it out. I was thinking of each Y_i as one event that may occur at different times. It should be thought of as the number of events happening for one time interval $i$ .
