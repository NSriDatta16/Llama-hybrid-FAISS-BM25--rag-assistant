[site]: crossvalidated
[post_id]: 544680
[parent_id]: 544651
[tags]: 
I find it hard to think of scenarios, where predictions with random effects set to zero are of interest (there are of course inference situations for contrasts and comparisons where the random effects are irrelevant/cancel out). If there is variation and unexplained differences between random effects levels, why would we ignore that when making predictions? For unseen random effects levels, this implies assuming an added random effect that follows the overall random effects distribution. There's some scenarios, where ignoring the random effects (seeing them to zero) is okay. But, if so, it's only okay, because it results in the same answer as having the random effect. One example would be if we want point predictions for new random effects levels from a linear (mixed effects) model with normally distributed random effects and are not interested in prediction intervals. However, for something like mixed effects logistic regression this is not the same thing. Perhaps someone else can think of some scenarios where we'd want to set random effects to zero, but I can't (outside of hypothetical "if only we could eliminate this variability"-scenarios).
