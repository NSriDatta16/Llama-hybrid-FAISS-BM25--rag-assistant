[site]: datascience
[post_id]: 111717
[parent_id]: 
[tags]: 
How is uncertainty evaluated for results obtained via machine learning techniques?

As machine learning (in its various forms) grows ever more ubiquitous in the sciences, it becomes important to establish logical and systematic ways to interpret machine learning results. While modern ML techniques have shown themselves to be capable of competing with or even exceeding the accuracy of more "classical" techniques, the numerical result obtained in any data analysis is only half of the story. There are established and well formalized (mathematically) ways to evaluate uncertainties in results obtained via classical methods. How are uncertainties evaluated in a machine learning result? For example, it is (at least notionally) relatively straight forward to estimate uncertainties for fit parameters in something like a classical regression analysis. I can make some measurements, fit them to some equation, estimate some physical parameter, and e.g. estimate its uncertainty with rules following from the Gaussian error approximation. How might one determine the uncertainty in the same parameter as estimated by some machine learning algorithm? I recognize that this likely differs with the specifics of the problem at hand and the algorithm used. Unfortunately, a simple Google search turns up mostly "hand-wavy" explanations, and I can't seem to turn up a sufficiently understandable scientific paper discussing an ML result with an in-depth discussion of uncertainty estimation.
