[site]: crossvalidated
[post_id]: 561182
[parent_id]: 
[tags]: 
Why the constraint always holds in soft margin SVM?

In the soft margin SVM, the loss minimization function is given as - Subject to $y_i(w^Tx_i + b) \geq 1 - \varepsilon_i$ and $\varepsilon_i \geq 0$ The 2nd constraint will always be true for any value of $x_i$ , $y_i(w^Tx_i + b) \geq 1 - \varepsilon_i$ and $\varepsilon = 1-(y_i(w^tx_i + b))$ So, for misclassified points, the constraint will be, $y_i(w^Tx_i + b) \geq 1 - (1 - (y_i(w^Tx_i + b)))$ which will be, $y_i(w^Tx_i + b) \geq (y_i(w^Tx_i + b))$ This means the constraint always holds. So, what is the point of using the constraint?
