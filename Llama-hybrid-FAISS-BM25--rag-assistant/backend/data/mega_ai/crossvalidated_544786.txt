[site]: crossvalidated
[post_id]: 544786
[parent_id]: 
[tags]: 
SVM random sampling permutation for imbalanced data: class & score weighted vs non weighted

I have been running the dataset of 2 classes with imbalanced numbers with python. Class one is 61, and class two is 66. When I built up the SVM model and did the random sampling permutation (monte-carlo-permutation), the middle of the permutated distribution matched perfectly at the chance level of 50% for non-weighted code (above picture), but it is not for class & score weighted code (below picture). The black dotted line indicates chance level (50%) and the green dotted line indicates the actual model's score. And here is related code for both situations: ## Code without weighted class and score #SVC setting svc_rbf = SVC(kernel='rbf', gamma=grid.best_params_["gamma"], C=grid.best_params_["C"]) #permutation score, permutation_scores, pvalue = permutation_test_score(svc_rbf, HAPPE_PCA, HAPPE_target, cv=cv, n_permutations=10000, n_jobs=-1, verbose = 0) ## Code with class and score weighted #SVC setting svc_rbf = SVC(kernel='rbf',class_weight="balanced", gamma=grid.best_params_["gamma"], C=grid.best_params_["C"]) # permutation score, permutation_scores, pvalue = permutation_test_score(svc_rbf, HAPPE_PCA, HAPPE_target, cv=cv, scoring='f1_weighted', n_permutations=10000, n_jobs=-1, verbose=0) I used gridsearch to find the best-fitted parameter. HAPPE_PCA is input data (EEG frequency powers) and HAPPE_target is classes of 1(n=61) and 2(n=66). I think the weight corrected score might influence the shiting of the center for the weighted results. However, I need expert's help to find related reference articles or relevant discussions. Thank you for reading my question. Regards, Forgot to say that I used Leave-n-out for cross-validation (cv).
