[site]: crossvalidated
[post_id]: 228637
[parent_id]: 228636
[tags]: 
Lets take the issue in hand step by step. First training and test data creation. For this you need to do stratified sampling just to get proper representation of both behaviors in both parts. You can do so in data.table by: train_ind Now to treat imbalance you have many ways in RF: Put higher penalty of misclassification for rarer classes. Increase penalty even more with sample weight. Due to presence of first two options in neat way I like Python scikit-learn RF more. However if you want to do it in R then I would suggest you to use caret and use appropriate RF version where these options are available (choose from http://topepo.github.io/caret/Random_Forest.html ). I have dealt with even more skewed class in my project and based on my experience I like xgboost (gbm is there but its slow) much more to deal with such problem.
