[site]: crossvalidated
[post_id]: 471506
[parent_id]: 
[tags]: 
Detection Function in Distance Sampling, R

I'm fitting detection functions on whale data using the ds function in Distance package in R. I am having difficulty choosing the best detection function to then use in a density surface model. I first fit three simple models: Hazard Rate (no adjustment terms), Half Normal (no adjustments) and Uniform (cosine adjustment). The uniform and half normal both give similar estimates of abundance in the 150 mark, compared to hazard rate which estimates at the 250 mark. Hazard rate comes out with the lowest AIC value, indicating best model fit. However, once i start adding covariates (for example seastate or cluster size), the hazard rate model starts predicting much higher values (some reaching abundance of 1,000) again, also showing a lower AIC, and therefore indicating best model. However, when plotted, they just don't look right. Example below: Whilst I know this particular example, the CV surrounding Hazard rate with area as covariate is particularly high (~50%, therefore best not to use it even with a lower AIC), I am having similar issues with other detection functions for different years. When fitting covariates with hazard rate, I get lower AIC but graphs looking much worse (like the one attached here) than half normal, and an average PA of 0.2 (surely that's not great?) One other thing I have noticed is that my data has evidence of spiked data towards zero. One way around this is fitting the detection function to distinct bin widths. For example, specifiyng unequal bins, 0-100, 100-200, 200-300, 300-600, 600-900, etc. This gives me a lower AIC but is this good practice? I hope this makes sense, Thanks for your help
