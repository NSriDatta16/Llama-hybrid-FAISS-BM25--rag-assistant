[site]: crossvalidated
[post_id]: 381896
[parent_id]: 
[tags]: 
Instrumental variable analysis: ivreg (R) vs. naive estimation

Short version of my question: Is it true that the naive, 2-step instrumental variable approach overestimates the standard errors (I expected an underestimation)? Long version: I am working with an instrumental variable approach with an instrumental variable X, an exposure Y and a dependent variable Z which are all continuous variables. I would like to use a 2-stage estimation approach, i.e., I first estimate $Y \sim X$ , then predict $\hat{Y}$ using the estimated model and finally fit $Z\sim \hat{Y}.$ I have read that the standard errors are not correct if I naively use this 2-step procedure (and ignore the uncertainty on $\hat{Y}$ ) and I am aware that there are R-functions (for example ivreg from the AER package) which can correct for that. When I simulate data, I get the correct confidence interval coverage with ivreg. I am trying to understand the implications of using the naive 2-step procedure compared to the ivreg-function: from my intuition, the naive procedure should underestimate the standard errors because we ignore the uncertainty in the exposure variable. However, in simulations, it seems as if we get wider confidence intervals with the naive method than with ivreg (coverage of confidence intervals close to 1). I am wondering if the overestimation of the standard errors with the naive approach is correct or if I made a mistake? Are you aware of any publication covering this feature in detail? Here is some R-code for the calculation (I am aware that this is just one example, but I get the same pattern in multiple iterations): library(AER) # generate datasets set.seed(123456) N This leads to: Confidence interval naive estimation: 0.98780224 1.02405510 Confidence interval ivreg: 0.993337964 1.01851938 So the confidence intervals for the naive approach appear wider than for ivreg. Thanks in advance for your help!
