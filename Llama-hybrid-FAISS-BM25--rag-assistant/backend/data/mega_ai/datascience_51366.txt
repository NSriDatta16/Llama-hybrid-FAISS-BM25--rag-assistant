[site]: datascience
[post_id]: 51366
[parent_id]: 51354
[tags]: 
I have implemented your model to the astonishment, there is a very minute error that is hard to notice. The way, I was able to get better accuracy is by changing the optimizer to "SGD" or "ADAM". As you have used "ADADELTA" which is an extension of "ADAGRAD" optimizer. In "ADAGRAD" has good performs on sparse data & while training a large scale neural network. Its monotonic learning rate usually proves too aggressive, stops learning too early. Refer to this link for understanding on optimizers
