[site]: datascience
[post_id]: 47045
[parent_id]: 46918
[tags]: 
Do you want your agent to perform illegal actions at any given time or not at all? One way to avoid illegal actions is to use a mask over your 144 action vector (so the action indices are preserved) when you calculate the softmax probabilities. Then you sample actions according to the masked probabilities. First you need to determine which actions are illegal at a given step which should depend on the dynamics of the game. One example are the algorithms used to learn to play the mini-missions in StarCraft II. In order to enforce your agent to act with the minimum amount of steps you should introduce a small penalty (lets say for example -0.01) so your agent will try to optimize also this part of the reward. For winning the game question, there is no answer to that. This depends on many factors, I name few here: how appropriate is the agent's architecture given the game, reward sparsity, types of observations (images, non-vector data), data p reprocessing, inputs to your agent, amount of exploration etc. There is no guarantee that if you use the X type of method will solve your task (except if your task has already been solved with a specific type of learner). You could possibly name the game/task you want to solve.
