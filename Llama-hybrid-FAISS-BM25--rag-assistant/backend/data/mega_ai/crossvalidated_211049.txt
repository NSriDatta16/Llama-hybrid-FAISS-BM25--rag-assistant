[site]: crossvalidated
[post_id]: 211049
[parent_id]: 
[tags]: 
Regression and posterior

Let $y_i$ follow $\operatorname{Bin}(n_i,p_i)$ and for $p_i$ we consider the logit quadratic model: $$\log\frac{p_i}{1-p_i}=\beta_0+\beta_1A_i+\beta_2(A_i-\operatorname{mean}A)^2$$ where $A_i$ is AGE_i during the $i$th time. It is part of example 9.3 from the book Bayesian Computation With R , but with a twist in the regression formula. The question is: If the regression vector is $\beta=(\beta_0,\beta_1,\beta_2)$ has a uniform noninformative prior write an R code to compute the logarithm of the posterior density of $\beta$. Question: How is the posterior density is computed without R? Attempt: $$p(y_i|p_I)={n_i\choose y_i}p_i^{y_i}(1-p_i)^{n_i-y_i}=\operatorname{Beta}(y_i+1,n_i-y_i+1)$$ and the prior is $$p(p_i)\propto 1 \,.$$ Then $$p(p_i|y_i)\propto p(y_i|p_i)p(p_i)=\operatorname{Beta}(y_i+1,n_i-y_i+1)$$ Is this correct? I think there is something missing because I did not use the vector $\beta$. EDIT: I found that $$p(y|\beta)=\displaystyle\prod_{i=1}^n{n_i\choose y_i}\left(\frac{e^{n_i}}{1+e^{n_i}}\right)^{y_i}\left(\frac{1}{1+e^{n_i}}\right)^{n_i-y_i}$$ So then if we multiply it by 1 to get the posterior we get : $$p(\beta|y)=\displaystyle\prod_{i=1}^n{n_i\choose y_i}\left(\frac{e^{n_i}}{1+e^{n_i}}\right)^{y_i}\left(\frac{1}{1+e^{n_i}}\right)^{n_i-y_i}$$ What can I do after that? Is this proportional to something better?
