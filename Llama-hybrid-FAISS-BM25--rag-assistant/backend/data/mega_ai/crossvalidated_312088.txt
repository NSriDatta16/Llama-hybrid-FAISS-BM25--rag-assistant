[site]: crossvalidated
[post_id]: 312088
[parent_id]: 311880
[tags]: 
I would generally use all the data available even if some is noisy, unless some of it was obviously nonsense. Should I include obstructed annotations in my training set? Yes, include obstructed images even though they are more challenging. Should I include annotations that I cannot make out myself due to lighting conditions? If you believe the annotations are still accurate then yes. Is it bad if, inside the image set, I have unlabelled examples of wrenches? I.e. will this confuse my network? Having unlabelled positive examples is called label noise and it'll make object recognition harder. If possible try to fix unlabelled examples by adding the missing annotations. But I would still include these labels, especially if you think this will be a feature of the dataset where you wish to apply this. Should I augment the training set by performing rotations, even if I only expect to see horizontally aligned rectangular plates? I am unsure if this is best here, but I am inclined to think it wouldn't hurt. That said you can start with the usual augmentation methods such as horizontal flips, random crops, and adding some noise by Gaussian blurring or playing with hue or saturation. If you are not getting the performance you are after then consider more intensive data augmentation such as rotations and other affine transformations. One of the intuitions about data augmentation is that it helps prevent overfitting by letting the neural network learn from a wider set of spatial statistics, this is relevant given your small dataset. Also consider adapting your preprocessing step to do further augmentation.
