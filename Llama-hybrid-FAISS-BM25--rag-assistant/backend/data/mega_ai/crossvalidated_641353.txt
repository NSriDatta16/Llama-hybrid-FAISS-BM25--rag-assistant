[site]: crossvalidated
[post_id]: 641353
[parent_id]: 641338
[tags]: 
There are two separate issues in your question. Prediction intervals: no, narrower intervals are usually not better. After all, we are aiming at a specified coverage. If your PI has the correct coverage, making it narrower will make it lose this. We typically don't want this. We typically evaluate central PIs using the Winkler score , which balances calibration (i.e., coverage) and sharpness (i.e., interval width). Testing predictive accuracy. Forecasters still quite often only report accuracy KPIs, without formally testing them between methods. If they do test in an NHST framework, they need to account for multiple forecasting methods evaluated on multiple time series . The current standard is the MCB test ( Koning et al., 2005 ). I believe that you could, for instance, apply this to Winkler scores as above. This earlier thread may be useful: How can I determine that a forecast is significantly more accurate than another one? (time series)
