[site]: datascience
[post_id]: 90236
[parent_id]: 90234
[tags]: 
The problem is that you are not using BERT's tokenizer properly. Instead of using BERT's tokenizer to actually tokenize the input text, you are splitting the text in tokens yourself, in your token_list and then requesting the tokenizer to give you the IDs of those tokens. However, if you provide tokens that are not part of the BERT subword vocabulary, it will not be able to handle them. You must not do this. Instead, you should let the tokenizer tokenize the text and then ask for the token IDs, e.g.: tokens_list = tokenizer.tokenize('Where are you going?') Remember, nevertheless, that BERT uses subword tokenization , so it will split the input text so that it can be represented with the subwords in its vocabulary.
