[site]: stackoverflow
[post_id]: 2076439
[parent_id]: 2027252
[tags]: 
There are a HUGE number of good approaches to this problem, and the method you ultimately should use will depend on the type of data you're dealing with (i.e., how it's distributed, dimensionality of the data points, possibly overlapping clusters, robustness to outliers, etc.). As was said, the first thing to try would be k-means clustering. You might also want to have a look at a simple variant called k-medoids (a.k.a. Partitioning Around Medoids (PAM)) which is more robust to outliers than k-means. One thing to note about both k-means and k-medoids is the existence of the parameter k (the number of clusters). If you won't know the number of clusters a priori , there are a variety of techniques to select k automatically (cross-validation, silhouette score, etc.); see Cluster Analysis and Finite Mixture Models for a more comprehensive list of cluster analysis implementations in R . My personal favorite clustering technique would be a Gaussian Mixture Model (GMM). I commonly use a good implementation of GMMs via an R package called MCLUST which identifies the number of clusters automatically using the Bayesian Information Criterion . Once you select a method to identify cluster membership (i.e., which data points are grouped together into sets), you can then average them or do with the data as you will.
