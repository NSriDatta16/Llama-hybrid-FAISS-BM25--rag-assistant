[site]: crossvalidated
[post_id]: 529869
[parent_id]: 
[tags]: 
Find a representative samples from an estimated distribution by KDE

I served a Neural Network model trained on a huge (timeseries) dataset. In production, I would like to monitor the newly received data and check if there is a drift in the features using K-S testing. To run the test, I am required to provide a reference data of the training dataset. Using the complete dataset isn't an option as the data is highly dimensional and has millions of rows. So I need to find the best representative samples of the training set. The features are continuous and don't follow a specific distribution. For example, if a feature is normally distributed, I would use the Mean and Standard deviation to build the distribution and use it as a reference data for the drift algorithm instead of loading the complete feature. Some solutions I found are: The authors of this paper suggest to use Dimensionality Reduction techniques to lower the dimensionality of the reference data to a fixed representation by using Untrained or Trained Autoencoder. Then, run the K-S test on the latent code. Brute force: Use Reservoir Sampling to sample from the training data. Then, keep sampling until the Jensen-Shannon Divergence distance between the sampling distribution and training distribution is within a threshold. Are there better approaches to find a representative samples for an estimated distribution? Please bear with me as I am a fellow software engineer who has fair knowledge in statistics.
