[site]: crossvalidated
[post_id]: 629200
[parent_id]: 629193
[tags]: 
Yes and no. If you don't shuffle the data, it's no longer $k$ -fold cross-validation. Using $k$ -fold CV is really only justifiable if we can reasonably treat the dataset as a random sample from the population that you want to generalize to. Then we can use $k$ -fold CV to estimate the average performance of models like yours across new random training sets. See Bates et al 2023, "Cross-Validation: What Does It Estimate and How Well Does It Do It?" ): ...it estimates the average [performance] of models fit on other unseen training sets [of size $n \times (k-1)/k$ ] drawn from the same population If you don't shuffle, CV's training sets aren't random, and your CV performance estimates might be biased by however the dataset's rows were ordered. So I don't think there is a separate name for " $k$ -fold CV but without shuffling," because it isn't really a useful technique. If your data are meaningfully ordered by time, not a random sample, then you should use one of the CV variants specifically designed for time series data. See for example the answers to this post , which also explains why you should not just do the " $k$ -fold CV but without shuffling" proposed in your question. A better simple approach, mentioned in those answers, is what's sometimes called "rolling-origin-calibration evaluation": see for example p.8 of Yi et al. (2018) or this section of Rob Hyndman's book Forecasting: Principles and Practice, 2nd ed. . (On the Wikipedia page you cited earlier, Wikipedia refers to "rolling cross validation," citing a paywalled article that distinguishes "rolling-origin-calibration" CV, "rolling-window" CV, and a few other variants. Although it's paywalled, the Yi et al. (2018) article on arXiv illustrates these variants.) These are all still variants of CV; they are just not the same as the default version of $k$ -fold CV. If your data were sampled in some other structured way -- not a simple random sample but also not a time series -- then you should modify CV to ensure that your training sets mimic the sampling design of interest. Examples include grouped data, complex survey designs, spatial sampling, etc. See section 2 of this answer to another post for details and examples.
