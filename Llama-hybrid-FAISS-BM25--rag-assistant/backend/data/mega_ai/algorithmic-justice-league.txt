The Algorithmic Justice League (AJL) is a digital advocacy non-profit organization based in Cambridge, Massachusetts. Founded in 2016 by computer scientist Joy Buolamwini, the AJL uses research, artwork, and policy advocacy to increase societal awareness regarding the use of artificial intelligence (AI) in society and the harms and biases that AI can pose to society. The AJL has engaged in a variety of open online seminars, media appearances, and tech advocacy initiatives to communicate information about bias in AI systems and promote industry and government action to mitigate against the creation and deployment of biased AI systems. In 2021, Fast Company named AJL as one of the 10 most innovative AI companies in the world. History Buolamwini founded the Algorithmic Justice League in 2016 as a graduate student in the MIT Media Lab. While experimenting with facial detection software in her research, she found that the software could not detect her "highly melanated" face until she donned a white mask. After this incident, Buolamwini became inspired to found AJL to draw public attention to the existence of bias in artificial intelligence and the threat it can poses to civil rights. Early AJL campaigns focused primarily on bias in face recognition software; recent campaigns have dealt more broadly with questions of equitability and accountability in AI, including algorithmic bias, algorithmic decision-making, algorithmic governance, and algorithmic auditing. Additionally there is a community of other organizations working towards similar goals, including Data and Society, Data for Black Lives, the Distributed Artificial Intelligence Research Institute (DAIR), and Fight for the Future. Notable work Facial recognition AJL founder Buolamwini collaborated with AI ethicist Timnit Gebru to release a 2018 study on racial and gender bias in facial recognition algorithms used by commercial systems from Microsoft, IBM, and Face++. Their research, entitled "Gender Shades", determined that machine learning models released by IBM and Microsoft were less accurate when analyzing dark-skinned and feminine faces compared to performance on light-skinned and masculine faces. The "Gender Shades" paper was accompanied by the launch of the Safe Face Pledge, an initiative designed with the Georgetown Center on Privacy & Technology that urged technology organizations and governments to prohibit lethal use of facial recognition technologies. The Gender Shades project and subsequent advocacy undertaken by AJL and similar groups led multiple tech companies, including Amazon and IBM, to address biases in the development of their algorithms and even temporarily ban the use of their products by police in 2020. Buolamwini and AJL were featured in the 2020 Netflix documentary Coded Bias, which premiered at the Sundance Film Festival. This documentary focused on the AJL's research and advocacy efforts to spread awareness of algorithmic bias in facial recognition systems. A research collaboration involving AJL released a white paper in May 2020 calling for the creation of a new United States federal government office to regulate the development and deployment of facial recognition technologies. The white paper proposed that creating a new federal government office for this area would help reduce the risks of mass surveillance and bias posed by facial recognition technologies towards vulnerable populations. Bias in speech recognition The AJL has run initiatives to increase public awareness of algorithmic bias and inequities in the performance of AI systems for speech and language modeling across gender and racial populations. The AJL's work in this space centers on highlighting gender and racial disparities in the performance of commercial speech recognition and natural language processing systems, which have been shown to underperform on racial minorities and reinforced gender stereotypes. In March 2020, AJL released a spoken word artistic piece, titled Voicing E