[site]: crossvalidated
[post_id]: 563375
[parent_id]: 
[tags]: 
Show that the autocovariance matrix is positive definite

I've been working through the textbook Time Series Analysis and its Applications (R. H. Shumway & D. S. Stoffer 2ed). The topic I'm looking at is forecasting using ARMA models. The below assumes that $\mathbb{E}(x_{n+m}^n)=0$ First, we want a one-step-ahead prediction using the best linear predictor of the form $$x_{n+1}^n = \phi_{n1}x_n+\phi_{n2}x_{n-1}+...+\phi_{nn}x_1$$ Using the property that the best linear predictor is found by solving $$\mathbb{E}[(x_{n+m}-x_{n+m}^n)x_k]=0, \enspace\enspace\enspace k=0,1,...,n$$ We can determine the coefficients as the ones that satisfy: $$\mathbb{E}[(x_{n+1}-\sum\limits_{j = 1}^n\phi_{nj}x_{n+1-j})x_{n+1-k}]=0, \enspace\enspace\enspace k=0,1,...,n$$ or, we can write $$\sum\limits_{j = 1}^n\phi_{nj}\gamma(k-j)=\gamma(k),\enspace\enspace\enspace k=1,...,n$$ We can represent this in matrix form as $$\Gamma_n\phi_n=\gamma_n$$ Now, a question in the book asks to prove that $\Gamma_n$ is positive definite, assuming we know that $\sigma_w^2>0$ and $\gamma(h)\rightarrow0\enspace as\enspace h\rightarrow\infty$ . I wasn't able to figure this out independently so I have been working through a proof provided to me. I don't want to go into the details of the proof without having to, as there is only one detail that I'm not following. It is that we can write $$\Gamma_n=QDQ'$$ where $Q$ is unitary, that is, $QQ'=I_n$ , and $D=diag(\lambda_1,...,\lambda_r)$ , where the $\lambda_i's$ are the positive eigenvalues of $\Gamma_n$ . I understand, from linear algebra, given that $\Gamma_n$ is symmetric (which it is due to stationarity) we can write it in this form. What I don't understand is why the eigenvalues are positive. All proofs that I've seen for showing that a symmetric matrix has positive eigenvalues either assume positive definiteness or decompose the matrix into something like $A = LL^T$ . I've tried QR-decomposition and LU-decomposition without any luck.
