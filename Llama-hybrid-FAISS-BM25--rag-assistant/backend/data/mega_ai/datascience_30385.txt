[site]: datascience
[post_id]: 30385
[parent_id]: 
[tags]: 
Error in training a merged model in Keras

I attempted to merge a VGG-16 and ResNet-50 model in Keras to benefit from the combined feature representations toward a binary classification task. I was successful in building and saving the merged model. However, while training, I am getting an error. Here is my code: #load libraries import numpy as np from keras import applications from keras.layers import GlobalAveragePooling2D, Dense from keras.layers import Concatenate from keras.preprocessing.image import ImageDataGenerator from sklearn.metrics import log_loss from keras.models import Model from keras.optimizers import SGD from sklearn.metrics import roc_curve, auc from sklearn.metrics import classification_report,confusion_matrix,accuracy_score import matplotlib.pyplot as plt from sklearn.preprocessing import label_binarize from evaluation import plot_confusion_matrix from keras.models import load_model from scipy import interp from itertools import cycle ############################################################################### #image dimensions and loading img_width, img_height = 1024,1024 train_data_dir = 'china_whole/train' validation_data_dir = 'china_whole/test' epochs = 30 batch_size = 2 num_classes= 2 ############################################################################### ''' Building a merge of two models''' base_model1 = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width,img_height,3)) #get the model summary base_model1.summary() #addind the top layers x1 = base_model1.output x1 = GlobalAveragePooling2D()(x1) #analogous to flatten() model1 = Model(inputs=base_model1.input, outputs=x1) model1.summary() #load the second model ######################################################## base_model2 = applications.ResNet50(weights='imagenet', include_top=False, input_shape=(img_width,img_height,3)) #get the model summary base_model2.summary() #addind the top layers x2 = base_model2.output x2 = GlobalAveragePooling2D()(x2) #analogous to flatten() model2 = Model(inputs=base_model2.input, outputs=x2) model2.summary() ############################################################################### '''merge the models''' mergedOut = Concatenate()([model1.output,model2.output]) #this is concatenating the two GAP layers #add a new dense layer and softmax out=Dense(2048, activation='relu')(mergedOut) out = Dense(num_classes, activation='softmax', name='predictions')(out) #create the new model with three branches and one dense layer model = Model(inputs=[model1.input,model2.input], outputs=out) model.summary() #fix the optimizer sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True) #the values are computed by a randomized gird search method #compile the gpu model model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) ############################################################################### #declaring image data generators train_datagen = ImageDataGenerator(rotation_range=2.0,rescale=1./255) test_datagen = ImageDataGenerator(rescale=1./255) train_generator = train_datagen.flow_from_directory( train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical') validation_generator = test_datagen.flow_from_directory( validation_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical', shuffle=False) nb_train_samples = len(train_generator.filenames) nb_validation_samples = len(validation_generator.filenames) #check the class indices train_generator.class_indices validation_generator.class_indices ############################################################################### #start training model.fit_generator( train_generator, steps_per_epoch=nb_train_samples // batch_size, epochs=epochs, validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size,verbose=1, workers=1) The error when running model.fit_generator was: Traceback (most recent call last): File " ", line 6, in validation_steps=nb_validation_samples // batch_size,verbose=1, workers=1) File "C:\ProgramData\Anaconda3\lib\site-packages\keras\legacy\interfaces.py", line 91, in wrapper return func(*args, **kwargs) File "C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py", line 2224, in fit_generator class_weight=class_weight) File "C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py", line 1877, in train_on_batch class_weight=class_weight) File "C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py", line 1476, in _standardize_user_data exception_prefix='input') File "C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py", line 86, in _standardize_input_data str(len(data)) + ' arrays: ' + str(data)[:200] + '...') ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[[0.17478053, 0.17478053, 0.17478053], [0.17482202, 0.17482202, 0.17482202], [0.17394349, 0.17394349, 0.17394349], ..., [0.15611881, 0.15611881, 0.15611881... How can i resolve this issue in the code?
