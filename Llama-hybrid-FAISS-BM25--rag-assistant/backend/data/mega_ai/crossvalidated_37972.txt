[site]: crossvalidated
[post_id]: 37972
[parent_id]: 37967
[tags]: 
You are right. The loss you optimize when training a neural network is basically the sum over your some function of the rows in your training set. That loss acts as a proxy called the "empirical distribution" for the true underlying distribution which you do not have access to. However, it might not hurt: if you have lots of data (since you generate it) you can train a really large network. In the limit, you have an infinitely large network with infinite training data - and the network can just remember all inputs and thus predict them perfectly. This sounds rather theoretical, but I have had cases where some kind of fixing the empirical distribution to somewhat resemble the true distribution more (because of prior knowedge) have not helped at all. Actually, the error on held out test data was roughly the same for both training sets. So if it hurts your specific training problem depends on the data and the problem.
