[site]: crossvalidated
[post_id]: 587558
[parent_id]: 587517
[tags]: 
The answer depends on how you obtain the autocorrelation estimates. Case 1: Autocorrelation estimated from only training data. In this case, there cannot be any data leakage because the autocorrelation function is only derived from information that is available during training. It does not matter if, e.g., the autocorrelation function "indicates" that the next 10 values will be similar to the last training data point, because this "indication" is only based on information that was available during training, and may in fact be totally wrong. For example, the time series below has high autocorrelation and we can "leverage" the autocorrelation information of the training part to come up with various predictions. However, these predictions have nothing to do with the test data, as seen below. It turns out that the autocorrelation function tells us which data are likely to come next, given the training data but not which data really come next. There is no information leakage. Case 2: Autocorrelation estimated from all data (or across several train/test splits). In this case there certainly is an information leak. Since the autocorrelation function is based on information derived from the test set, we can plug in the last few data points of the training set to obtain optimal estimates for the test set. For example, we could obtain the following prediction (using overfitting) which is a clear case of data leakage.
