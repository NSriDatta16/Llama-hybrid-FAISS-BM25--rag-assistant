[site]: crossvalidated
[post_id]: 643626
[parent_id]: 643612
[tags]: 
TLDR : This looks like the expected amount of overfitting. IMHO it's not worth being too concerned with unless you have reason to believe it's going to cause big issues with whatever the use case for the model is (i.e. false positive could cause heavy costs). AUC-ROC can be interpreted as $P(\hat y_1 > \hat y_0 | y_1 =1, y_0=0)$ . From this definition, we can see that the metric is not very sensitive to "overconfidence" (i.e predicting $p = 0.99$ when really $p = 0.9$ ). Logistic loss, on the other hand, can be very sensitive to overconfidence. For example, if you predict $P(y_i = 1) = 1$ but observe $y_i = 0$ , your LogLoss is unbounded! So given the relatively small difference to AUC-ROC and moderately large difference in LogLoss, you should suspect that your model is likely to be over confident. This is pretty common for most ML methods and as long as it's not ruining model performance, you live with it. If you want to keep basically the same predictions but fix the overconfidence (i.e. nudge the predictions of $p = 0.99$ back down to $p = 0.9$ ), this can be done pretty easily by recalibrating your predictions . Note that recalibration will not change the rank order of predictions, but will help give you predicted probabilities you can have more confidence in; items with prediction of $p = 0.99$ should now be true 99% of the time instead of 90% if you used the uncalibrated model. If you think the overfitting is so bad that the model is not properly leveraging the features, then you need to go back to the drawing board and think about how to improve the model (feature engineering, regularization etc).
