[site]: crossvalidated
[post_id]: 564561
[parent_id]: 564548
[tags]: 
There are many ways how you could normalize error metric, for example, you could divide it by a known constant that serves as a benchmark. What you are suggesting is similar to relative absolute error $$ \mathrm{ RAE} = \frac{ \sum^N_{i=1} | \hat{\theta}_i - \theta_i | } { \sum^N_{i=1} | \overline{\theta} - \theta_i | } $$ but notice two differences: RAE normalized by the distance from the average, rather than sum. In such a case, you compare to a benchmark. With comparing to sum the error would be get smaller as sample size would grow and generally the values may be trickier to interpret than you assume. What if the true values sum to zero? It is totally possible, you just need to have the data with mean equal to zero for that. If they sum to small value you have the same problem as with MAPE. Every "relative" error metric has some edge cases where it can give strange results or be hard to interpret, that is one of the reasons why people often prefer unnormalized metrics like means absolute error, or mean squared error, etc.
