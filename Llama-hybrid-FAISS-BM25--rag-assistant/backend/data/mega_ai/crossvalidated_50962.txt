[site]: crossvalidated
[post_id]: 50962
[parent_id]: 50932
[tags]: 
BGreene's answer is a good one, but I would just add that it might make even more sense to go from PCA to the more closely related LDA classifier, which is Latent Dirichlet Allocation. As the name implies, it's a latent variable technique, like PCA. It's trending highly in the classification literature (I'm using it myself right now) particularly in text mining and unstructured data. Using PCA then Fischer's LDA is statistically valid ceteris paribus, but it's not necessarily a good idea. Though I and plenty of other people do use linear discriminate in some contexts because it's so quick and easy, in most applications it's not a very statistically efficient or practically effective choice. As a classifier it often performs particularlly poorly; I usually run and rank many classifiers for any algorithm I'm building and linear discriminate is usually at the bottom of the list. It's poor performance may be the reason for needing PCA to reduce dimensional, but I would just choose a single, more appropriate classifier.
