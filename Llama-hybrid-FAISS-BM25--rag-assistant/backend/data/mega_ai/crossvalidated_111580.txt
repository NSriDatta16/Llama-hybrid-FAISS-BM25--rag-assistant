[site]: crossvalidated
[post_id]: 111580
[parent_id]: 
[tags]: 
Tuning paramaters SVM, DT, k-NN, NN

I'm trying to compare the predictive strenght of four different algorithms: support vector machines k-NN decision trees neural networks I've got a few questions concerning the parameter tuning: Some papers like [1]state that k-nearest neighbour does not need parameter tuning, don't you need to decide what k will be? If you want to tune the parameters of SVM (gridsearch) and NN (different hidden neurons), on what data set do you do that if you plan on using tenfold cross-validation? If you're using your data set with tenfold, isn't there any data left to use to validate your parameters? [1] Xiao, W., Qian, Z., & Fei, Q. (2006). A comparative study of data mining methods in consumer loans credit scoring management. Journal of Systems Science and Systems Engineering, 419-435.
