[site]: crossvalidated
[post_id]: 297529
[parent_id]: 
[tags]: 
combining text and non-text features in a classification model

I am new to ML, so please interpret this question accordingly... I am not sure if this is a common issue or not, or if I am thinking about this the right way. Here is what I am trying to do: I have a bunch of text fragments which I want to classify into certain topics. The text fragments are the titles of support tickets, so for example the title "My laptop is broken, please help" might get classified into the Hardware category, and the title "I would like a refund for my July bill" might get classified into the Finance category. So far this is straightforward. However, I have a lot of metadata that would probably be useful to include in my model. For example I know how long somebody has been a customer w/ the company, which could be one feature. I know the age of each customer, which could be another feature. Etc. What I'm not sure is, what is the best way to combine these metadata features with the text features? For the text features I am using something like tf-idf, so I'll have one feature for each word in the vocabulary, and the feature list will be very long since the vocabulary is large. I suppose I could manually append these metadata features to the end of the vocabulary, but it seems a little ridiculous to append 10 features to a feature vector 100k features long. And I'm not sure if it would work right. FWIW I am using scikit-learn, but I'm not sure if it has any functionality that would help here.
