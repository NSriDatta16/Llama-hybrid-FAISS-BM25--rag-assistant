[site]: crossvalidated
[post_id]: 583500
[parent_id]: 583496
[tags]: 
If you were going for prediction, I would have suggested some regularization approach. In a context of Null Hypothesis Significance Testing (NHST), you may want to look at the collinearity diagnostics of Belsley, Kuh and Welsch. In contrast to VIF, they also reveal which groups of predictors are closely associated. This makes deciding how to "thin out" your predictor set much more focused. The disadvantage is that BKW is quite a bit more complicated. And I don't know how well it works with 2000 predictors. Alternatively, you could use a dimension reduction technique like PCA and run your logistic regression on the first few principal components. The disadvantage here is that you get the p values of the principal components, not of your original data. Finally, NHST really presupposes you have predefined hypotheses in the context of a planned experiment. If you really want to feed in 2000 predictors and assess whether any coefficient is nonzero, perhaps you should go back to the planning stage and plan your experimental controls more carefully.
