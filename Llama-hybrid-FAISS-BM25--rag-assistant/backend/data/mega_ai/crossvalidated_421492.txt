[site]: crossvalidated
[post_id]: 421492
[parent_id]: 421488
[tags]: 
Can I regard equation 7 as the numerator in equation 2, where mu and c are z (the latent variables?) Yes, because they said that $z = \{\mu, c\}$ and equation 8 as the denominator in equation 2? Yes. For equation 7, Is it some chain rule of the joint? Yes. And in equation 8, are they simply just marginalizing out each xi, and taking the product of each sample assuming they're i.i.d? They are marginalizing the $\mu$ using the integral and $c$ with the sum. Not the $x$ . The integral and sum are the tools to "sum over" all possible values of that thing - so that then it falls out of the $p(\mu, c, x)$ and it becomes just $p(x)$ :-) For equation 7, Is it some chain rule of the joint? And in equation 8, are they simply just marginalizing out each xi, and taking the product of each sample assuming they're i.i.d? Well, they say that $\mu$ is latent, so it is not given, it is unknown, and thus so is $\sigma$ . And bayesian hierarchical models are so cool because you don't have to choose - the proper value of a hyperparameter will be found by the fitting procedure :-) Either MCMC, MAP or some other method. It will be much slower, but it will work. I've seen, in some particular models, that there can be ways to approximate the hyperparameters by some rule of thumb to speed up the whole process and getting almost the same result. But in general, you want to estimate the optimal hyperparameter value and bayesian models do allow that :-)
