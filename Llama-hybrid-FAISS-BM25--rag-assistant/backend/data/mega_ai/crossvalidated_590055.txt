[site]: crossvalidated
[post_id]: 590055
[parent_id]: 
[tags]: 
Calculation of Sensitivity of the Outputs to the Inputs over Time in RNN

Alex Graves, author of Supervised Sequence Labelling with Recurrent Neural Networks, described how sensitivity of an output to the inputs is calculated as follows: /* The delta terms refer to the partial derivative of the loss with respect to variables of interest. δtk := ∂L/∂ytk. ytk: the k-th output at time t */ First, all output delta terms are set to zero except some δtk, corresponding to the time t and output k we are interested to. This term is set equal to its own activation during the forward pass, i.e. δtk = ytk. The backward pass is then carried out as usual, and the resulting delta terms at the input layer correspond to the sensitivity of the output to the inputs over time. I find it confusing. Shouldn't the derivative be proportional to instantaneous rate of change of the output instead of the instantaneous value of the output? In my opinion, δtk should be set to 1 instead. What do you think, my friends? Here is a link to the digital version of the book. You can find the sensitivity stuff on page 23.
