[site]: crossvalidated
[post_id]: 421328
[parent_id]: 421310
[tags]: 
Yes, this is possible. Consider a binary classification problem with real-valued (1d) inputs and class labels '0' and '1'. A linear classifier will find a decision boundary that separates the input space into two halves. In the 1d case, this is simply a threshold. Points will be assigned label '0' on one side of the boundary and label '1' on the other side. For example: 0 0 0 0 0 | 1 1 1 1 If the data fit this pattern, then a linear classifier is a good option. A non-linear classifier (e.g. random forest or kernelized SVM) is more appropriate when data from each class are distributed in multiple, interleaved regions, and can't be separated by a single threshold. For example: 0 0 0 0 | 1 11 11 1 | 0 0 0 0 0 0
