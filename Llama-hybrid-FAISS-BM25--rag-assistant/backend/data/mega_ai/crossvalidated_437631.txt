[site]: crossvalidated
[post_id]: 437631
[parent_id]: 437497
[tags]: 
A key difference which I failed to appreciate: the MA model predictions of $x_t$ include $\epsilon_{t-1}$ in its computation whereas the AR model only predicts based on $x_{t-1}$ without (explicit) regard as to whether the prediction at $t-1$ was under- or over-estimating $x_{t-1}$ . Fleshing out what @user1587692 highlighted, the MA model averages across innovations ( $\epsilon$ , i.e., the "novelty" that the MA model failed to catch, even with its lag(1) component). The AR model, on the other hand, average previous observations (residuals, i.e., $x$ when $\mu = 0$ ) without splitting the time-series part and innovation part. To make this super clear, I made a small dataset with $\mu = 0$ , $\beta_1 = 0.5$ and $\beta_2 = 0.2$ (latter only used for MA(2) and AR(2)). Here, $x$ is called "observed" and $\epsilon$ is called "MA(1) error". The yellow cells are "helpers", typed in to make the predictions work for observation $x_1$ . To me, this also gives a better intuition why: The covariance between $x_t$ back until $x_{t-order}$ is positive and zero further back. This is due to the i.i.d. residuals (innovations on top of the non-i.i.d. autocorrelation) that contribute within the averaging window but has, by definition of being white noise, no information about $x_t$ further back. AR models have (positive or negative) autocorrelations further back. This is just the time-series autocorrelation (dampened by the i.i.d. innovations on top). Why AR and MA can be viewed as re-parameterizations of each other. No information is added or removed in either model. However, you cannot transform one to the other at any particular time ( $t$ , column in the table above) - you need to look further back to make an estimate. That's why you need a high order AR to estimate a low-order MA. It takes a lot of $x$ to estimate $\epsilon$ if you can't model it directly. Similarly, it takes a high order MA to estimate a low-order AR if you don't model $x$ directly (condition it out).
