[site]: crossvalidated
[post_id]: 321156
[parent_id]: 
[tags]: 
Bias and Variance, Overfitting and Underfitting

I am trying to understand the concept of bias and variance and their relationship with overfitting and underfitting. Right now my understanding of bias and variance is as follows.(The following argument is not rigorous, so I apologize for that) Suppose there is a function $f:\mathcal{X}\to\mathbb{R}$, and we are given a training set $\mathcal{D}=\{(x_i,y_i):1\le i\le m\}$, i.e., we know $y_i=f(x_i)$ for $1\le i\le m$, and that $(x_i,y_i)$ in $\mathcal{D}$ are sampled from the same distribution $P(x,y)$. We use the training set $\mathcal{D}$ to obtain a model $\hat{f_{\mathcal{D}}}$. (a) The bias and variance of the learning algorithm is then the bias and variance of the estimator $\hat{f_{\mathcal{D}}}(\hat{x})$ on an unseen example $\hat{x}$, respectively. Is this correct? (b) The bias of $\hat{f_{\mathcal{D}}}(\hat{x})$ on an unseen example $\hat{x}$ is defined to be $\mathbb{E}[\hat{f_{\mathcal{D}}}(\hat{x})-f(\hat{x})]$, where the expectation is taken across all possible training sets $\mathcal{D}$. In other words, we repeat the procedure of sampling the training set $\mathcal{D}$ from $P(x,y)$, and then obtaining a function $\hat{f_{\mathcal{D}}}$ for each such $\mathcal{D}$. We then compute the average $\hat{f_{\mathcal{D}}}(\hat{x})-f(\hat{x})$. Is this a correct interpretation of bias? Different $\mathcal{D}$s can give different $\hat{f_{\mathcal{D}}}(\hat{x})$, and the variance of $\hat{f_{\mathcal{D}}}(\hat{x})$ measures the expected deviation of $\hat{f_{\mathcal{D}}}(\hat{x})$'s from the expected value of $\hat{f_{\mathcal{D}}}(\hat{x})$. Am I correct? (c) I read that as the model capacity increases, the bias decreases and the variance increases. Although I could understand this somewhat intuitively, I don't quite understand this when I think in terms of the definition of bias. If the model capacity increases, then it is prone to over-fitting. So the learned model does worse on the unseen example $\hat{x}$. In other words, $\hat{f_{\mathcal{D}}}(\hat{x})$ is not very close to $f(\hat{x})$ on an unseen example $\hat{x}$. This will be true if we repeat the procedure for different samples of training set $\mathcal{D}$. Then why is the average error, which is the bias $\mathbb{E}[\hat{f_D}(\hat{x})-f(\hat{x})]$, low? Is it because the positive deviations and negative deviations balance each other to give a low bias? (d) (very important) Can you explain why high capacity means low bias and high variance (and low capacity means high bias and low variance) using part (b)?
