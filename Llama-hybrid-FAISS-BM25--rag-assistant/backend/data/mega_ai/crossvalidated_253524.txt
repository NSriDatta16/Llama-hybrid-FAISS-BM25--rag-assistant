[site]: crossvalidated
[post_id]: 253524
[parent_id]: 
[tags]: 
How to choose the discount value in a Markov Decision Process?

I reproduced a trivial game found in an Udacity course to experiment Markov Decision Process. I was really surprised to see I found different results. After some research, I saw the discount value I used is very important. When I choose a discount of 0.5, I got different results but with a discount of 0.999, the results are the same (and the solution is optimal). My question is: how to choose the discount value? In this example, we have an optimal solution with a discount value who is almost 1 but is it the case every time? If you want to reproduce the experiment, here is the (Python) code I created: import numpy as np import mdptoolbox rewar = -0.04 T = np.array([ # 0 1 2 3 4 5 6 7 8 9 10 11 [ [0.9, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1, 0.8, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.1, 0.8, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.8, 0.1, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.1, 0.0, 0.1], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.1, 0.1]], # 0 1 2 3 4 5 6 7 8 9 10 11 [ [0.1, 0.8, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.2, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.1, 0.8, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.1, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.8, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.8, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.1, 0.8], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.9]], # 0 1 2 3 4 5 6 7 8 9 10 11 [ [0.1, 0.1, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1, 0.8, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.0, 0.8, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.1, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.8, 0.1, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.8, 0.1], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.9]], # 0 1 2 3 4 5 6 7 8 9 10 11 [ [0.9, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.8, 0.1, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.1, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.2, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.8, 0.1, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.8, 0.1]] ]) R = np.array([ # 0 1 2 3 4 5 6 7 8 9 10 11 [ [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, 1.00, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, -1.00, rewar, rewar, rewar, rewar], [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, -1.00, rewar, rewar, rewar, rewar]], # 0 1 2 3 4 5 6 7 8 9 10 11 [ [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, 1.00, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, -1.00, rewar, rewar, rewar, rewar], [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, -1.00, rewar, rewar, rewar, rewar]], # 0 1 2 3 4 5 6 7 8 9 10 11 [ [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, 1.00, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, -1.00, rewar, rewar, rewar, rewar], [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, -1.00, rewar, rewar, rewar, rewar]], # 0 1 2 3 4 5 6 7 8 9 10 11 [ [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, 1.00, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, -1.00, rewar, rewar, rewar, rewar], [ 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar, rewar], [rewar, rewar, rewar, rewar, rewar, rewar, rewar, -1.00, rewar, rewar, rewar, rewar]] ]) discount = 0.1 pi = mdptoolbox.mdp.PolicyIteration(T, R, discount, eval_type=1) pi.run() print(pi.policy)
