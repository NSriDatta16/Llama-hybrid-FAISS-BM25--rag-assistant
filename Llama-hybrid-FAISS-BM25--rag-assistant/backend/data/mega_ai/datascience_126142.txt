[site]: datascience
[post_id]: 126142
[parent_id]: 
[tags]: 
The using of golden dataset in Augmented SBERT Training

I use the training strategy of Augmented SBERT (Domain-Transfer) . In the code example they use the golden-dataset (STSb) for the training evaluator. Here two code snippets of the example of sentence-transformers : Get data and split them gold_samples = [] dev_samples = [] test_samples = [] with gzip.open(sts_dataset_path, 'rt', encoding='utf8') as fIn: reader = csv.DictReader(fIn, delimiter='\t', quoting=csv.QUOTE_NONE) for row in reader: score = float(row['score']) / 5.0 # Normalize score to range 0 ... 1 if row['split'] == 'dev': dev_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score)) elif row['split'] == 'test': test_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score)) else: #As we want to get symmetric scores, i.e. CrossEncoder(A,B) = CrossEncoder(B,A), we pass both combinations to the train set gold_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score)) gold_samples.append(InputExample(texts=[row['sentence2'], row['sentence1']], label=score)) Initialize evaluator and fit model logging.info("Read STSbenchmark dev dataset") evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev') # Configure the training. warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up logging.info("Warmup-steps: {}".format(warmup_steps)) # Train the bi-encoder model bi_encoder.fit(train_objectives=[(train_dataloader, train_loss)], evaluator=evaluator, epochs=num_epochs, evaluation_steps=1000, warmup_steps=warmup_steps, output_path=bi_encoder_path ) First Question: Why is the golden-dataset used for the evaluation, if the model fits on the silver-dataset? Further, the test_sample from the golden dataset is used for the final analysis: # load the stored augmented-sbert model bi_encoder = SentenceTransformer(bi_encoder_path) test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test') test_evaluator(bi_encoder, output_path=bi_encoder_path) Second Question: Why is the test_sample based on the golden-dataset? Why is the test_sample not based on the silver dataset?
