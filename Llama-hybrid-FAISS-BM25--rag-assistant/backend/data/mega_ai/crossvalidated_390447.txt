[site]: crossvalidated
[post_id]: 390447
[parent_id]: 
[tags]: 
Using a priori knowledge in a classification task

I'm working on a classification task, related with text classification, where texts to be classified are requests for technical support, and the classes are technical guys which issues can be assigned to. I have about 10 different classes. Data, i.e requests for support, are quite noisy (as one should expect), and the overall performance of the classifier I was able to train was poor - about 42% of correct classification. So, I decided to try a different approach. Since I know for sure that each class (i.e, the technician) can possibily belong only to a "superclass" A or to another superclass "B"(i.e there are only two distinct technical teams) I tried to train a first classifier to discriminate between A and B superclasses, and a second classifier to use to predict which class a text belongs, given its predicted superclass. This way, the overall performance reached by combining of two classifiers is reasonably good. Despite the results, I wonder if using one's a priori knowledge of a given domain should be considerate 'cheating' or it's a normal - and accepted - practice in the field of Machine Learning. What's your opinion about ?
