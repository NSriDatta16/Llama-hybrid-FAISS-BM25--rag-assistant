[site]: datascience
[post_id]: 35478
[parent_id]: 35476
[tags]: 
The RMSE is a measure for how "wrong" a regression model's predictions are on average, and is mostly useful as a relative metric for determining which of a set of models is best. If you want an absolute baseline against which to compare any given model you can always compute the standard deviation of your target, which is the RMSE of a model which predicts the average value of $y$ for every observation. I would also argue that for something like housing prices a more meaningful error measure is root mean square logarithmic error, which is the RMSE after taking the log of $y$ (or $y + 1$ if $y$ contains zeros) and the predicted values. The reason for this is that we're interested in errors as proportions of our target (an error of \$50,000 is much more serious for a \$100,000 house compared to a \$1,000,000 house), and taking logs is the way to adjust for this. Also be sure to focus on test or cross validation error, else you will always choose your most overfit model.
