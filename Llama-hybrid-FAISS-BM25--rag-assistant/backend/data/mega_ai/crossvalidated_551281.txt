[site]: crossvalidated
[post_id]: 551281
[parent_id]: 
[tags]: 
Great variance in prediction quality using different trainings of the same LSTM on the same data

I'm taking very first steps building a prediction model for time-series data using LSTM (and deep learning in general). A natural and motivating direction is stocks prices predictions. TL;DR When training the same network multiple times on the very same input data I get extremely different prediction results. I understand and expect differences (due to different randomness), but I witness things like this: with with Mean absolute error: 3.95 / Mean squared error: 30.39 vs. with with Mean absolute error: 19.07 / Mean squared error: 637.35. Note that these two are the results of two different runs of the same code given the same training data. See below more details. Questions Why? What are the reason to witnessing such significant differences? One training round yields good predictions and the other one merely suggests that the model was able to learn something about the trends. What's next? What should I do next? What terms should I focus on and study and investigate? More details The code I'm using is mostly based on what I found in how to develop lstm models for time series forecasting by Jason Brownlee. Steps I started with 10 years of daily (adjusted) closing price of \$FB stock. I noticed the same behavior also with \$AMZN and other large cap stocks. Next I build training chunks with 50 steps each. def split_sequence(sequence, n_steps): X, y = list(), list() for i in range(len(sequence)): # find the end of this pattern end_ix = i + n_steps # check if we are beyond the sequence if end_ix > len(sequence)-1: break # gather input and output parts of the pattern seq_x, seq_y = sequence[i:end_ix], sequence[end_ix] X.append(seq_x) y.append(seq_y) return array(X), array(y) I kept 30% of the preprocessed data for validation. Lastly, I built the model: model = Sequential() model.add(LSTM(50, activation=keras.activations.relu, input_shape=(n_steps, n_features))) model.add(Dense(1)) model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='mse') model.fit(X_train, y_train, epochs=200, verbose=1, callbacks=[tensorboard_callback]) Complete notebook is available here . I will be happy to add more details in case you think I missed something and most importantly, I would love to get your feedback what should I investigate next. Thanks in advance!
