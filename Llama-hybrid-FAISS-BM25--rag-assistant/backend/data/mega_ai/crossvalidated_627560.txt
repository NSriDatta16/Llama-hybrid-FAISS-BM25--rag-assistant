[site]: crossvalidated
[post_id]: 627560
[parent_id]: 
[tags]: 
An ARMA model with white noise errors, that are ARCH? (How is that possible?)

First my assumption was that ARMA models take only the autocorrelation of the time series into consideration but not of the error terms (wrong!). But this assumption is wrong! As the within ARMA models the autocorrelation of the implicit error terms (approx trough the residuals) disappear. An ARMA model with autocorrelated error terms would be miss-specified. E.g. within ARMA-ARCH or ARMA-GARCH models the observed variables have ARMA white noise errors, but they are ARCH . Therefore, they are dependent, within higher moments. I do not really understand the last part of it. Tried to explain myself it mathematically but do not really find a solution. Can someone explain me how that is possible? Update: Thank you for your answer @Richard. I guess I somehow forgot what the MA term means again. So just to be clear on the MA part again: As the MA is a linear combination of the past white noise terms and is useful to explain the serial correlation in residuals in isolation (but only if they are white noise). Often using the MA model we can explain serial correlation in short lags but the problem is that volatility clustering and long-memory effects stay. So now in (G)ARCH models, the variance is allowed to be serially correlated and also be dependent on past lags. Apart from that all stays the same. So in the ARMA model they residuals can be dependent but they need to be white noise. In ARCH/GARCH the residuals can also be dependent but they do not need to be white noise (heteroskedastic, volatility clustering). Is that right? Side question about definitions: variance/error terms: if I talk about the theoretical model residuals: after fitting a specific model --> if we test a hypothesis we test on the error terms/variance not on the residuals?
