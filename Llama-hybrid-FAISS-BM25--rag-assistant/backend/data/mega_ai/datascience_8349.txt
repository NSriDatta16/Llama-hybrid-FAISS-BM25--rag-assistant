[site]: datascience
[post_id]: 8349
[parent_id]: 
[tags]: 
Classification of vector sequences

My dataset is comprised of vector sequences. Each vector has 50 real-valued dimensions. The number of vectors in a sequence range from 3-5 to 10-15. In other words, the length of a sequence is not fixed. Some fair amount of the sequences (not vectors!) are annotated with a class label. My task is to learn a classifier that given a sequence of vectors, the class label for the whole sequence is computed. I cannot tell the exact nature of the data but the nature of sequences is not temporal. Nevertheless, a vector $x_i$ cannot be interchanged with a vector $x_j$ without changing the label ($i \neq j$). In other words, the order of vectors is important. The vectors themselves are comparable, for example it makes sense to compute a dot product and use this similarity value. My question is: what are the tools/algorithms that can help to classify such data? UPDATE: The data has such a property that one or very few vectors influence strongly the class label. POSSIBLE SOLUTION: After some research it looks like the Recurrent Neural Networks (RNN) fit the bill pretty naturally. The overarching idea is to pick a context size $k$, concatenate word vectors, do max pooling and feed that through classical NN. At each possible context window position in a sentence, a feature vector is built. The final feature vector is built using max pooling for example. The backpropagation is done to adjust the network's parameters. I already got some positive results (GPU is a must).
