[site]: crossvalidated
[post_id]: 561842
[parent_id]: 
[tags]: 
Why are raw data analyzed rather than the probability distribution the data are sampled from?

QQ plots and other methods to analyze probability distributions seem to require input of the raw data itself rather than the probability distribution that the data sample. Why is that the case, even if an empirical distribution can be generated? (I am not a mathematician, so I might be wording or thinking about that a little strangely.) I also would like to know how I can get around this particular issue for my particular problem. I posted this yesterday, but I'm amending this today to hopefully be clearer: EDIT: A colleague calculated the number of aggregates of particles, averaged over time. These aggregates have a particular size. My understanding is that this amounts essentially to many time series -- one for each size of aggregate. Then, my colleague calculated the histogram of counts vs. size of aggregate. All I have is the histogram, but following this post, and my reading, I think I should actually be using the time series data in verifying the distribution, and so on. However, it seems that typically one time series is analyzed to get a distribution, but that is not the case here. I don't know how to analyze all of these many time series in the manner described by some of the responses, to do things like maximum likelihood estimation, and so on. Can somebody help clear up my thinking on this?
