[site]: crossvalidated
[post_id]: 466942
[parent_id]: 466114
[tags]: 
This seems a really interesting discussion and it is maybe nice to point another feature of regularization. Why regularization reduces the risk of overfitting? At a first look could sound strange to talk about overfitting for such a simple model (simple linear regression). However, I think the point the example wants to emphasize is the impact of the regularization on the leverage . Suppose we have a rigde regression (what follows can be generalized to more exotic problems) $$ \hat{y} = X \hat{\beta} = X (X'X + k I)^{-1} X' = H y $$ where $H$ is the hat matrix, $X$ is the model matrix ( $n \times p$ ) and $I$ is a regularization matrix shrinking the values of $\beta$ . The leverage is equal to the diagonal elements of the matrix $H$ (let's indicate them as $h_{ii}$ ). This is true for the simple regression model as well as for the regularized one (and for any regularized estimator for what matters). But what is the impact of the regularization on the leverage exactly? If we compute the SVD of $X = UDV'$ , can be shown that the ridge leverage is equal to $$ h_{ii} = \sum_{j = 1}^{p} \frac{\lambda_{j}}{\lambda_{j} + k} u^{2}_{ij} $$ with $\lambda_{j}$ equal to the $j$ th eigenvalue of $X'X$ , $u_{ij}\lambda^{1/2}_{j}$ is the proj. of the $i$ th row of $X$ onto the $j$ th principal axis, and $\mbox{tr}(H) = \sum h_{ii}$ measures the effective degrees of freedom. From the formula above we can deduce that for $k > 0$ For each observation, the ridge regression leverage is smaller w.r.t. the LS leverage The leverage decreases monotonically as $k$ increases The rate of decrease of the leverage depends on the position of the single $X$ -row (the rows in the direction of the principal axis with larger eigenvalues experience a smaller leverage reduction effect). Going back to the example, In my opinion, the author just wants to stress the fact that the regularized line is not pulled down by the blue point around 20K as much as the non-regularized one when the red dots in the same surroundings are taken out (this in light of point 1&3 above). This prevents 'overfitting' (wich we can read here as high influence ) and ensures better results also for unseen data. I hope my answer adds something interesting to this nice discussion.
