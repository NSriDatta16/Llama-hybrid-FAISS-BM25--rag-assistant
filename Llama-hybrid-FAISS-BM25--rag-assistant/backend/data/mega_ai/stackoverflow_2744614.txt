[site]: stackoverflow
[post_id]: 2744614
[parent_id]: 2743586
[tags]: 
EDIT: MathWorks give advice on this problem . You can view memory usage with the commands system_dependent memstats and system_dependent dumpmem (as well as simply memory , as noted by Jonas). The command pack (which in effect defragments your workspace) may also come in useful. If you are dealing with objects containing > 10 million or so values, then memory can easily become an issue. Throwing hardware at the problem (i.e. buying more RAM) may be an option, but there is a limit to what you can achieve. The way I suggest you approach recoding things to make them more memory efficient is: See if there are any variables you don't need to allocate. A classic example of this is when a function returns a value of the same size as it's input. function x = XPlus1(x) x = x + 1; end is more memory efficient than function y = XPlus1(x) y = x + 1; end Next, try and split your problem down into small chunks. At the simplest level, this may involve performing an operation on rows instead of a whole matrix, or on individual elements instead of a vector. (The cost of looping is less than the cost of it not running at all due to memory contraints.) Then you have to reconstruct your answer from the pieces. This step is essentially the philosophy behing map-reduce, so as a bonus, your code will be more easily parallelizable.
