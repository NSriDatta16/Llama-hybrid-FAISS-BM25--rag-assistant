[site]: crossvalidated
[post_id]: 349458
[parent_id]: 
[tags]: 
Correlation attenuation: Question about Spearman’s correction

Correlation attenuation: Question about Spearman’s correction Disclaimer: I’m not a statistician, so please don’t be surprised about ignorance and/or outrageously stupid faults in reasoning. But do let me know, please! I’m interested in the expected attenuation of a hypothesized correlation by imperfect measures. My motivation is to take this into account for power calculations. For a hypothesized correlation $r_{xy}$ between two properties, what is the expected observed correlation $r_{x’y’}$ between two imperfect measures of these properties? The imperfectness of these measures is given by their validity ( $r_{x’x}$ and $r_{y’y}$ ; their correlation with the property they aim to measure), which in turn can be estimated by their re-test reliabilities ( $r_{x'_1x'_2}$ and $r_{y'_1y'_2}$ ; which really are upper bounds of their validity). Running some simulations I stumbled upon a simple pattern: $r_{x’y’} = r_{xy} \times r_{x'x} \times r_{y'y}$ which – I thought – surely has been described before. Googleing a bit, I hit on Spearman’s ‘disattenuation’ ( https://en.wikipedia.org/wiki/Correction_for_attenuation , https://www.jstor.org/stable/1412159 ). As far as I see, this is looking at the same thing from the opposite end. Spearman was interested in estimating $r_{xy}$ from $r_{x’y’}$ , by correcting for the attenuation effect of $r_{x'_1x'_2}$ and $r_{y'_1y'_2}$ . My problem is that his equation is different from my results: $r_{xy} = \frac{r_{x’y’}}{\sqrt{r_{x'_1x'_2}\times r_{y'_1y'_2}}}$ which implies $r_{x’y’} = r_{xy} \times \sqrt{r_{x'_1x'_2}\times r_{y'_1y'_2}}$ Basically, the effect of attenuation in my simulations is the square of that given by Spearman. So I went back and double-checked that my simulations do what I thought they would do. Checking the properties of the simulated data, everything seems to be in order: the simulated ‘true’ values $x$ and $y$ correlate with $r_{xy}$ ; the measurements $x’$ correlate with $x$ by $r_{xx}$ , $y’$ and $y$ correlate by $r_{yy}$ . However, $r_{x’y’}$ is equal to $r_{xy}$ attenuated by the product of $r_{x’x}$ and $r_{y’y}$ , rather than the square root of that product. Thinking about this discrepancy, I also noticed that Spearman’s attenuation formula goes against my intuition. Take the simplest case: Two properties that are perfectly correlated ( $r_{xy} = 1$ ), a perfect measure of the criterion ( $r_{yy} = 1$ ) and a measure of the predictor that has limited reliability ( $r_{xx} ). For this case, my simulations would suggest $r_{x’y’}= 1\times 1 \times r_{x'x} = r_{x'x}$ , whereas Spearman would predict $r_{x’y’} = 1 \times \sqrt{1\times r_{x'_1x'_2}} = \sqrt{r_{x'_1x'_2}}$ . I don’t understand how Spearman’s solution makes sense. It implies that the observed correlation of $x’$ with $y’$ will be higher than the correlation of $x’$ with itself ( $r_{x'_1x'_2}$ ). How can that possibly be true? It seems obvious to me, that if $r_{x'_1x'_2}$ is the only limiting factor for $r_{x’y’}$ (because everything else is perfectly correlated), $r_{x’y’}$ should be equal to $r_{x'_1x'_2}$ . So, where do I go wrong? How does the square root in Spearman’s equation make sense? What could explain this discrepancy between his equation and the simulation results?
