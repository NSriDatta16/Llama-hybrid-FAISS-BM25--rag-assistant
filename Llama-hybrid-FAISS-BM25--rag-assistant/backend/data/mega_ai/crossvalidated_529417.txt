[site]: crossvalidated
[post_id]: 529417
[parent_id]: 
[tags]: 
Computing $\frac{\partial}{\partial W} || t_n -W^T \phi (x_n) ||^2$

In Ch 3.1.5 of Pattern Recognition and Machine Learning how do we take the derivative wrt $W$ of 3.33: $$ln(p(T|X,W,\beta))=\frac{NK}{2}ln(\frac{\beta}{2\pi}) - \frac{\beta}{2}\sum_{n=1}^N || t_n -W^T \phi (x_n)||^2$$ I attempted to use the chain rule, but I think it might be easier for example to use differentials. I computed: $$\frac{\partial}{\partial W}ln(p(T|X,W,\beta))=- \frac{\beta}{2}\sum_{n=1}^N \frac{\partial}{\partial W}(t_n -W^T \phi (x_n))^T(t_n -W^T \phi (x_n)) $$ $$=- \frac{\beta}{2}\sum_{n=1}^N \frac{\partial}{\partial (t_n-W^T \phi (x_n))}(t_n -W^T \phi (x_n))^T(t_n -W^T \phi (x_n))\frac{\partial}{\partial W} (t_n-W^T \phi (x_n)) $$ $$=- \beta\sum_{n=1}^N (t_n -W^T \phi (x_n))\frac{\partial}{\partial W} (t_n-W^T \phi (x_n)) $$ where I used $$\frac{\partial (x^Tx)}{\partial x}=2x$$ but I'm not sure how to compute the derivative: $$\frac{\partial}{\partial W} (t_n-W^T \phi (x_n))$$
