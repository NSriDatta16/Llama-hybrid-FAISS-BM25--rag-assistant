[site]: crossvalidated
[post_id]: 452916
[parent_id]: 452590
[tags]: 
In the case of a Bernoulli response you are looking to model the change in the probability $p = f(x;\eta)$ as a function of your predictors. You can just make a special model for doing this, and that is fine, but suppose you want to use some general technique, such as say a linear model? The immediate problem you hit is that they are going to give you predictions for some inputs that lie outside (0,1) that is allowed for p. You can fix this! All you need to do is put a transform on your model, we need some function that will map $(-\infty, \infty)$ on to $(0,1)$ . Let's use the Normal CDF $\Theta(z)$ : $p = \Theta(f(x;\eta))$ That's it! We have discovered GLM, we have solved our problem. You can now go out and get your data and fit your model using maximum likelihood. For any trial parameter value $\eta$ you can calculate the predictor $p$ for each data point, and calculate the total likelihood for your sample and off you go. But... that isn't a "canonical" GLM. In fact this example is Probit regression. The canonical form for handling binomial data would be to use Logistic regression, and it is about finding canonical form that the exponential family stuff is all about. The reasons to prefer canonical form are subtle, and not always compelling. However if you use the canonical link function, then some of the mathematics of fitting is simplified as are another of derived results. An excellent answer on the difference between Probit and Logistic this can be found here, and the idea carries forward to any canonical vs non-canonical link: https://stats.stackexchange.com/q/30909
