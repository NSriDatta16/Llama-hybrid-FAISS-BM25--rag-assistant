[site]: datascience
[post_id]: 117892
[parent_id]: 
[tags]: 
model interaction between words for a sentiment analysis task

I am wondering what is the most appropriate way to model the interaction between two words/variables in a language model for a sentiment analysis task. For example, in the following dataset: You didn't solve my problem,NEU I never made that purchase,NEU You never solve my problems,NEG The words "solve" and "never", in isolation, doesn't have a negative sentiment. But, when they appear together, they do. Formally speaking: assuming we have a feature «solve» that takes the value 0 when the word «solve» is absent, and 1 when the word is present, and another feature «never» with the same logic: the difference in the probability of Y=NEG between «solve»=0 and «solve»=1 is different when «never»=0 and «never»=1. But a basic logistic regression (using, for example, sklearn ), wouldn't be able to handle this kind of situation (it doesn't add interaction terms).
