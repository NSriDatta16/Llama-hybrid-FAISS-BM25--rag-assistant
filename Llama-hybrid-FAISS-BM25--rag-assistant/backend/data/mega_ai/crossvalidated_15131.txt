[site]: crossvalidated
[post_id]: 15131
[parent_id]: 
[tags]: 
Are there differences in Bayesian and frequentist approaches to EDA?

Very simply put: Are there any differences in Bayesian and Frequentist approaches to Exploratory Data Analysis? I know of no inherent biases in EDA methods as a histogram is a histogram, a scatterplot is a scatterplot, etc., nor have I found examples of differences in how EDA is taught or presented (ignoring a particularly theoretical paper by A. Gelman). Finally, I looked at CRAN, the arbiter of all things applied: I haven't found packages tailored to a Bayesian approach. However, I thought CV might have a few people who could shed a light on this. Why should there be differences? For starters: When identifying appropriate prior distributions, shouldn't one investigate this visually? When summarizing data and suggesting whether to use a frequentist or Bayesian model, shouldn't the EDA suggest which direction to go? The two approaches have very clear differences on how to handle mixture models. Identifying that a sample likely comes from a mixture of populations is challenging and directly related to the methodology used to estimate the mixture parameters. Both approaches incorporate stochastic models and the selection of model is driven by understanding the data. More complex data or more complex models necessitates more time in EDA. With such distinctions between stochastic models or generating processes, there are differences in EDA activities, so shouldn't there be distinctions arising from different stochastic approaches? Note 1: I'm not concerned with the philosophies of either "camp" - I only want to address any gaps in my EDA toolkit and methods.
