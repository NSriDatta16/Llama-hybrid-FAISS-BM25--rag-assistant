[site]: crossvalidated
[post_id]: 324858
[parent_id]: 324843
[tags]: 
This post: How to produce a pretty plot of the results of k-means cluster analysis? goes over some suggestions on how to visualize clustering results. Although the post and examples are given in R, you can find equivalent packages in python. Some of the main suggestions with the python equivalent packages: Performing PCA to reduce the number of dimensions you are dealing with and taking the first 2 or 3 principal components for visualization. Note that if you do go with this method, taking the first 2 or 3 will only be useful if the majority of the variance is accounted for by your first 2 or 3 principal components (see explained_variance_ on the sklearn PCA page ) Performing a Silhouette analysis. This analysis gives you an idea of the separation between your samples in each cluster and could be used to figure out how "good" your clusters are (i.e. are the samples within the cluster far apart, close together, close to the decision boundary). This analysis can be performed after PCA or without, but the resulting visualization are pair-plots (i.e. 2D plots looking at pairs of your features). Looking at pair plots for 15 attributes (105 plots) is a little cumbersome, so I would suggest first performing PCA to see if you can reduce the number of dimensions you are working with. Here an sklearn example of a Silhouette analysis
