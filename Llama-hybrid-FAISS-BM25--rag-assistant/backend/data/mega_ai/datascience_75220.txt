[site]: datascience
[post_id]: 75220
[parent_id]: 75217
[tags]: 
What you are referring to is called a multi-input model and can be esaily built in most deel learning frameworks. The idea is to have both types of data as separate inputs, then use specific layers depending their types (recurrent layers to sequence data, CNN to images, and so on...) to later on concatenate them together. If you can use Keras, there is the functional Api which is specialy well suited for the task at hand. An example of code (based the example given in the documentation) for your problem could be: from keras.layers import Input, Embedding, LSTM, Dense, merge from keras.models import Model # headline input: meant to receive sequences of 100 integers, between 1 and 10000. # note that we can name any layer by passing it a "name" argument. main_input = Input(shape=(100,), dtype='int32', name='main_input') # this embedding layer will encode the input sequence # into a sequence of dense 512-dimensional vectors. x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input) # a LSTM will transform the vector sequence into a single vector, # containing information about the entire sequence lstm_out = LSTM(32)(x) #At this point, we feed into the model our auxiliary input data by concatenating it with the LSTM output: auxiliary_input = Input(shape=(5,), name='aux_input') x = merge([lstm_out, auxiliary_input], mode='concat') # we stack a deep fully-connected network on top x = Dense(64, activation='relu')(x) x = Dense(64, activation='relu')(x) x = Dense(64, activation='relu')(x) # and finally we add the main logistic regression layer main_output = Dense(1, activation='sigmoid', name='main_output')(x) #This defines a model with two inputss: model = Model(input=[main_input, auxiliary_input], output=main_output) #Then compite and train model.compile(optimizer='rmsprop', loss='binary_crossentropy') model.fit([headline_data, additional_data], labels, nb_epoch=50, batch_size=32) In your case, the dynamic data would be the headline_input and your static data the auxiliary_input . The model will take both, apply the recurrent layer to the former and concatenate them to pass the union through the dense layers. Of course, many of these parameters will depend on your data, but at least this example will give you an idea on how to build such model. There is also this interesting project conditionall RNN which is also meant for this purposes. Worth taking a look.
