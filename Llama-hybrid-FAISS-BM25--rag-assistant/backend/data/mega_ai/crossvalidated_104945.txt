[site]: crossvalidated
[post_id]: 104945
[parent_id]: 104928
[tags]: 
This is just an interaction. You want to model the effect of being treated vs. not being treated on the outcome. But the effect of being treated is, coarsely, a function of how the treatment was administered. Let's say you were going to use logistic regression (which you probably should). Call $T=1$ when treated and $T=0$ otherwise, and $\operatorname{Pr}(Y=1)=p$ where $Y$ is your binary outcome. You're asserting that $$ \log\left(\frac{p}{1-p}\right)\equiv\operatorname{logit}\left(p\right)=\alpha+\beta T $$ That is, you're saying that when someone is treated, the log odds of $Y$, for that someone, increase by $\beta$. But you also want to say that, given $T=1$, the log odds of $Y$ will also vary with respect to treatment intensity $S$. The easiest way to incorporate this is to say $$ \operatorname{logit}\left(p\right)=\alpha+\beta T+\gamma ST $$ That is, $Y|T=1$ varies linearly with $S$. The fact that $S$ is "unobserved" when $T=0$ doesn't matter because it would get multiplied by zero anyway. Importantly, this model is just one step of algebra away from $$ \operatorname{logit}\left(p\right)=\alpha+(\beta + \gamma S)T $$ which, again, is mathematically equivalent but also reveals a different interpretation: the coefficient on $T$ itself is a function of $S$. Interpreting this in terms of log odds is easy, because the effect is linear. But translating those log odds back to probabilities is somewhat more complicated. There is also an issue with statistical significance, in that p-values can be different depending on whether you're talking about log odds or raw probabilities. There's a thorough, if somewhat dense, walkthrough of these issue here , demonstrated in Stata. Finally, you will often hear that you should never include interaction terms in a regression without also including the "main effects." That prescription obviously doesn't apply here.
