[site]: crossvalidated
[post_id]: 76905
[parent_id]: 76896
[tags]: 
I would recommend using LibSVM which you can call from Matlab , it is generally much faster and better. As for the parameters: you need to optimize both of these by splitting your data in three pieces and testing different values on a part of the data. Basically you would procede as follows (fractions are just a choice): Split off 1/3 training data Split off 1/3 validation data Split off 1/3 testing data You would train the SVM using a set of parameters on the training data and test it on the validation data and repeat this procedure for different parameters. Once an optimal parameter set is found, you then train on both the training and validation data (put them together) and evaluate your model on the testing data. As for the parameter testing, this is usually done in a 'grid search' with a procedure called 'cross-validation' (see also the part about k-fold cross-validation here ). One more thing: if you were to use a linear kernel, things would probably go much faster. The kernel itself is much faster to evaluate and you would only need to optimize one parameter (the box constraint) instead of two (the box constraint and the sigma bandwidth). That being said, I have worked with dimensions much larger than yours in a matter of seconds using LibSVM. All of this and more is als explained in 'A Practical Guide to Support Vector Classication' , which I strongly recommend you read before starting to use SVMs.
