[site]: crossvalidated
[post_id]: 131210
[parent_id]: 131199
[tags]: 
I'm puzzled by your question. I know you say you understand fixed vs. random effects, but perhaps you don't understand them in the same way I do. I've posted a rather extended excerpt from an in-press book chapter here which explains my view (rather pragmatic, fairly closely aligned with Andrew Gelman's). More directly answering the question: it doesn't (IMO) make any sense to include the main effects of socioeconomic variables such as income as random. If you had more than one measurement of income per individual, you could include individual as a grouping variable and allow the effects of income on the response (whatever it is) to vary across individuals. Race seems to make most sense as a fixed effect, and it's unlikely that you're going to be able to measure an individual under the effects of more than one race, but you might (e.g.) be able to characterize random variation in the effects of race across different countries. You could treat it as a random effect (i.e. model differences among races as being drawn from a Normal distribution), but it's likely to be impractical because you probably won't have enough different races in your data set, and it would be hard for me to come up with a good conceptual argument for this either ... "area of living" make sense as a grouping variable, which could certainly be a reasonable random effect (i.e. the intercept would vary across living areas). Individual would probably be nested within area, unless individuals move between areas over the time scale of your study. your situation seems to be a case where you have some random variation across individuals, but you also have individual-level covariates. Adding these individual-level covariates (race, income, etc.) to the model will account for some of the among-individual variability (and is probably a good idea). It may add clarity to distinguish among grouping variables (which must be categorical), which represent the groups across which things vary, and effects , which are the differences in some parameter/effect (usually the intercept, but could be the effects of income/education/whatever) across the levels of some grouping variable. update : I will take the liberty of giving some counterpoint to your My understanding of random effects: factors that are randomly selected from a population; Maybe, it depends on your philosophical outlook. This is required in the classical frequentist paradigm, but I would relax it somewhat by asking whether it's reasonable to treat the effects as being random draws from some hypothetical population. (The classic examples here are (1) exhaustive sampling (what if you have measurements for every neighborhood in the city, or every region/province/state in a country? Can you still treat them as random draws from some superpopulation? and (2) time periods measured sequentially (e.g. years 2002-2012). In both of these cases I would say it makes pragmatic sense to model them using random effects.) levels of the factor is of little interest; not necessarily. I don't think the idea that random effects must be nuisance variables holds up in practice. For example, in animal-breeding analyses one may be very interested in knowing the breeding value (BLUP) of a particular animal. (The so-called level of focus does have some implications for how one compares models.) variables are unobserved factors. I'm not sure what this one means. You know what neighborhood each observation comes from, right? How is that "unobserved"? (If you suspected clustering in your data based on unobserved factors you would need to fit a discrete mixture model .) If you mean that you don't know why neighborhoods are different, I don't think that matters here. So take neighborhood as an example. It is my variable of main interest, the levels are important. I use mixed models and verify that a great deal of variance lies within it. The only reason I can think of not to use neighborhood as a random effect would be if you had only measured a small number (say
