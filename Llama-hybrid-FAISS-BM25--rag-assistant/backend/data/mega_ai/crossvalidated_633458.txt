[site]: crossvalidated
[post_id]: 633458
[parent_id]: 
[tags]: 
Purpose of expressing data in principal components

I have a rough understanding of the outline PCA. Given $n$ samples of $m$ -dimensional data: $\vec{x}_1, \vec{x}_2, \dots, \vec{x}_n$ , PCA aims to find an appropriate orthonormal basis called principal components $\vec{p}_1, \vec{p}_2, \dots, \vec{p}_m$ to re-express the original data. I don't get how it is useful to express data in terms of principal components $\vec{p}_1, \vec{p}_2, \dots, \vec{p}_m$ . What can we do with these newly projected data? I want to know the details of how data analysis would be carried out once principal components are found. Here is one concrete example: Imagine we are given a large box of various kinds of apples and we need to find the best way to divide apples into groups. Suppose we have $n=30$ apples. For each apple, we measure $m=5$ numerical quantities: how red it is, diameter, height, bitterness, and sweetness. All of these data will be encoded into $m$ -dimensional vectors: $\vec{x}_1, \vec{x}_2, \dots, \vec{x}_n$ . Then we find the principal components of this data set which will be $\vec{p}_1, \vec{p}_2, \dots, \vec{p}_m$ . After rewriting the original data in terms of these principal components, how are we going to start classifying $n$ apples? One possible way I can think of is to put apples with $\vec{p}_1$ coefficient that dominates coefficients of the rest of components $\vec{p}_2, \dots, \vec{p}_n$ into one category, and put apples with $\vec{p}_2$ coefficient that dominates coefficients of the rest of components into another...?
