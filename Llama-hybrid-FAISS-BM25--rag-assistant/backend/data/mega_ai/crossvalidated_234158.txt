[site]: crossvalidated
[post_id]: 234158
[parent_id]: 233548
[tags]: 
Is hyperparameter tuning on sample of dataset a bad idea? A: Yes, because you risk overfitting (the hyperparameters) on that specific test set resulting from your chosen train-test split. Do I limit my classification accuracy? A: Yes, but common machine learning wisdom is: with your optimal hyperparameters, say $\lambda^*$, refit your model(s) on the whole dataset and make that model your final model for new, unseen, future cases. Do I avoid using all the prediction power that my dataset can offer by tuning only on a subset? A: see previous answer. If such a harm of performance is happening is it somehow limited by some factor? A: idem. I measure my accuracy using 10-fold cross as I use to also evaluate the parameters A: Note that this is different from what is asked in the title. 10-fold CV iterates over 10 test-train splits to arrive at an "unbiased" (less-biased) estimate of generalizability (measured in this case by accuracy). 10-fold CV exactly addresses the issue I talk about in the first answer. the prediction accuracy I get from training on my whole dataset A: this is an "in-sample" measure that could be optimistically biased. But don't forget that you have many cases and relatively few features, so that this optimism bias may not be an issue. Machine learning nugget: "the best regularizer is more data." [cont'd], is always really close to the evaluation I get when tuning the parameters for the best set of parameters. A: see previous answer. Look at the hyperparameter plots: does tuning decrease error and by how much? From what you are saying, the tuning is not doing much. You could test this as follows. Take a 70%-30% train-test split. Compare predictive performance of: an untuned model trained on the train set, a 10-fold-CV tuned model trained on the train set. Let both models predict the test set. If performance is very close, then tuning is not doing much. If performance is different in favor of the tuned model, then continue with the tuning approach.
