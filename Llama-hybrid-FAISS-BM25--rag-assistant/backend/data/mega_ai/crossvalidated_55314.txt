[site]: crossvalidated
[post_id]: 55314
[parent_id]: 55136
[tags]: 
I think the crucial point about the "statistical significance" of your results is the implicit assumption, that the years are independent samples of one population. But over 20 years, the temperature-dependent use of electricty may change quite a lot. As really you have a time series of 20 summers, you'd need to look into general trends as well as into seasonal effects, and patterns within the summmers. you can shuffle your data at two or three different levels: within the years (which tells you something about the general relation between electricity use and hot summers) or between the years, i.e. use another year's temperatures with the electricity data. You are talking about time series. Do you generate temperature patterns within the years (e.g. heat wave, considering a lag between temperature and electricity)? If so, you can shuffle those features as well. If you derive your RMSE only from out-of-sample predictions, you have an out-of-bootstrap estimate. Not .632 because you do not mix in training-set residuals. Neither would .632 bootstrap be recommended if you have a situation where overfitting can occur. There is also the .632+ bootstrap, which tries to estimate the amount of overfitting, and then adjusts the amount of training set error that is mixed into the estimate. Personally, I prefer to stay with the completely independent test set, i.e. pure out-of-bootstrap. If I need to measure overfitting, I do that separately, and prefer to report it separately.
