[site]: crossvalidated
[post_id]: 630384
[parent_id]: 627057
[tags]: 
Interesting question! @christoph hanck has treated a lot of stuff here. In your edit, you ask a question: why does the average of $e_i^2$ , with iid $e_i\sim(0,\sigma_i^2)$ converge? Here I provide an answer to this question. First we have \begin{align} \frac 1n \sum_i e_i^2 &= \frac 1n \sum_i (e_i^2-\sigma_i^2) + \frac 1n \sum_i \sigma_i^2 \end{align} Let's look at the first term. Given the indepence assumed on $e_i$ , $z_i=e_i^2-\sigma_i^2$ is also indepndent and has a zero mean. Therefore as long as you have a moment of $2+\delta$ for $e_i$ , the result (that $\frac 1n \sum_i e_i^2$ converges) would follow. For simplicity, however, let's assume finite fourth moments for $e_i$ such that we could invoke elementary results here; for some real $a>0$ , we have \begin{align} \Pr\left(|\bar z|>a\right)&\leq \frac{var(\bar z)}{a^2}\\ &= \frac{1}{n^2a^2}\sum_ivar(z_i)\\ &\leq \frac{1}{n^2a^2}nc\\ &=\frac c{a^2}n^{-1}\end{align} for some constant c. This in turn implies that $\frac 1n \sum_i (e_i^2-\sigma_i^2) \overset{p}{\to}0$ . Therefore, $$\frac 1n \sum_i e_i^2\overset{p}{\to} \lim_{n\to \infty}\frac 1n \sum_i \sigma_i^2.$$ Note, however, that in a regression framework and when the focus is the OLS estimators, one focuses often on the standard errors of the OLS estimator and that would be slightly different.
