[site]: crossvalidated
[post_id]: 24427
[parent_id]: 24405
[tags]: 
Interpreting the intercept You can think of logistic regression as giving you a posterior probability of being a '1'. The intercept represents a prior on categories derived from the dataset: specifically, it is the empirical estimate of log(p(Y=1)/p(Y=0), by itself when the model has only an intercept, for the cases in the 'reference' classes when there are categorical covariates, and for cases when the covariates are at 0 more generally (but less interpretably). So your strongly negative number is probably telling you that '1's are rare among the cases in your sample characterised by having all covariates at 0. Again, there may be no observations there, so it's not worth worrying about the intercept value. This discussion is fairly clear. Because of this handy separation of concerns among the parameters, you can correct for category imbalance by training on a better balanced sample and only adjusting the intercept . See King and Zeng for a thorough discussion.
