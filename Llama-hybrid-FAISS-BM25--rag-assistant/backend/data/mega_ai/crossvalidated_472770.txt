[site]: crossvalidated
[post_id]: 472770
[parent_id]: 461026
[tags]: 
There are a lot of questions here, so I'll first give an overview, and then explain a bit more. You have 4 tests you're asking about: Hausman test, Sargan test, a Wald test of exogeneity, and a Hansen J Test. To fix some notation, let $Z$ be a vector of instruments, and consider $Y = \beta_1 X_1 + \beta_2 X_2 + e$ , where $X_1$ are exogenous variables you include in the model, and $X_2$ are endogenous, and you wish to use $Z$ instruments for $X_2$ . Sometimes I will use $X = (X_1,X_2)$ as well. In what follows, I will describe each test, and then provide intuition and an approach. I may stray from my notation during the intuition parts, but tried to stick to it during the approach parts. Before beginning, the TL;DR is that Wald and Hausmann test for exogeneity of $X$ (assuming exogeneity of $Z$ ), and Hansen's J and Sargan test for exogeneity of $Z$ (assuming you have more instruments than endogenous variables). Wald and Hausmann are very similar, but Wald is often better than Hausmann, and Sargan is a simpler version of Hansen's J used with TSLS (Hansen's J is used with IV-GMM). Since Hausman and the Sargan test different things, it makes sense you get different results. Here's an explanation of what each test basically does: Wald test of exogeneity : You assume that the instruments $Z$ satisfy exogeneity, and you test if $X_2$ may actually be exogenous. Intuition: You have a valid instrument $Z$ (this assumption is key) for some variable $X$ , and the first stage basically fits $X = \hat{\alpha} Z + \hat{e}$ , and intuitively, in TSLS, we replace $X$ with $\hat{\alpha}Z$ in the second stage, which is the part of $X$ that is predicted by $Z$ . Now what's $\hat{e}$ ? Well it's the part of $X$ that is unexplained by $Z$ . If we ran a regression of $Y$ on $\hat{e}$ . and find $\hat{e}$ has no effect on $Y$ , then the part of $X$ that explains $Y$ is basically accounted for by $\hat{\alpha}Z$ , but since $Z$ is exogenous by assumption, then $X$ 's effect on $Y$ is a combination of the $Z$ fitted part and the $Z$ unfitted part, but we just found out that the unfitted part does not matter, and so $X$ is actually exogenous for all intents and purposes: the only part of it that matters is the part explained by $Z$ , and $Z$ itself is exogenous, so $X$ must be exogenous. In such a case, you don't have to use IV and can just run OLS, which is more efficient. Approach: we run the regression $Y = \delta_1 X + \delta_2\text{resid}(X_2) + \epsilon$ , where $\text{resid}(X_2)$ are the residuals from the first stage regression of $X_2$ on $Z$ . Then the exogeneity test is a Wald test that $\delta_2 = 0$ (ie jointly testing that all coefficients in the vector $\delta_2$ are $0$ ). Rejecting the test means that $X_2$ is not exogenous. Hausman's test for endogeneity : This test is very similar to the above Wald test, and should be quite similar (I think exactly the same) under homoscedasticity. It is not used because we don't want to necessarily impose such an assumption, and because it involves a generalized inversion of a matrix that is often hard to calculate numerically. So we instead use a Wald test as above. Intuition: Same as Wald test above. Approach: First get first stage of TSLS and get the residuals $r$ . Then run a regression $Y = \beta X + \delta r$ and test if $\delta = 0$ . If significantly different, $(X_1,X_2)$ is not exogenous, and you should use TSLS, otherwise you can use the more efficient OLS. Note that unlike Wald test, the first stage and residuals are for all $(X_1,X_2)$ using $(X_1,Z)$ , not just $X_2$ . Hansen's J : If we have more instruments than endogenous variables, i.e. $dim(Z) > dim(X_2)$ , then we can test if all instruments are exogenous assuming that at least one of them is exogenous. Intuition: If $dim(Z) > dim(X_2)$ , we have more instruments than we need, and so we can actually use some of them for testing purposes instead of using them for estimation. I'm not super sure how to give an intuitive explanation here, but basically if we have more instruments then needed, TSLS will use all these instruments to build a set of instruments of $dim(X_2)$ , and so I can take the residuals of TSLS from using this 'reduced' set of instruments, and then run a regression of these residuals (denoted $r_{TSLS}$ ) on $Z$ . If $dim(Z) = dim(X_2)$ , then by construction the coefficient of such a regression will be $0$ , i.e. $r_{TSLS} = \hat{\alpha}Z$ will always result in $\hat{\alpha} = 0$ , and so we don't learn anything. In contrast, if $dim(Z) > dim(X_2)$ , then this need not be the case, but if the instruments truly were exogenous, then it should still be $0$ . This is what we are testing here. Approach: This is really used with IV-GMM, which is not what you are doing, so I don't know how much you want to know about this. As I'll next explain, the Sargan test is basically the simplified version of this test used with TSLS (the analogy is typically as follows: IV is to GMM as Sargan's test is to Hansen's J test). Sargan : Very similar to Hansen's J. We use it to test exogeneity of instruments assuming one is at least exogenous, when we have more instruments than $X_2$ endogenous variables. It is popular when performing TSLS. Following on comment below, it seems that Hausmann's test for overidentification, as defined by OP as in Section 15.5 of Wooldridge's Introductory Econometrics, is also defined as this test. Intuition: Same as Hansen's J. Approach: If we assume homoskedasticity, the Sargan's test is a special case of Hansen's J test. We first run TSLS with all instruments, and get the residuals, and then regress these on the instruments. The sample size times $R^2$ of this regression is approximately $\chi^2$ with number of excess instruments as degrees of freedom.
