[site]: datascience
[post_id]: 94807
[parent_id]: 94784
[tags]: 
There are probably many variants but here are two simple approches: Using pretrained word embeddings, you can calculate the semantic similarity between two words. For example you could use cosine to measure the similarity between the vector of a target word (e.g. "calm") and every word in the set (e.g. "cloud"). Then the mean across words in the set gives how much the set is associated to the target, and you can pick the target which has the max similarity. Using WordNet to directly obtain a semantic distance/similarity between words. The method is similar to the one above. Note that there are many improvements that can be done to these basic ideas, for example you could use a predefined set of words related to "calm" instead of just the word "calm" (you can get the most similar words from WordNet for instance). There also many options for the aggregation across the set of words.
