[site]: datascience
[post_id]: 19697
[parent_id]: 
[tags]: 
scale_pos_weight Xgboost

My question is rather simple what does the parameter scale_pos_weight in xgboost do? I know typically it should be $\frac{sum(negative cases)}{sum(positive cases)}$. Does it oversample the minority class by that ratio or does it undersample the majority class by inverse of that ratio? Or something else? Also I would like to know if during cross validation in xgbcv, does the sampling happen on the test part of the cross-validation also or only the train part is affected by scale_pos_weight? Because i've heard that sampling should never be applied to test as it gives over-optimistic results.
