[site]: stackoverflow
[post_id]: 228052
[parent_id]: 227994
[tags]: 
You probably want to process this piecewise in some way. (I assume queries are a lot more complicated that you showed?) In that case, you'd want try one of these: Write your stored procedure to iterate over results. (Might still lock while processing.) Repeatedly select the N first hits, eg LIMIT 100 and process those. Divide work by scanning regions of the table separately, using something like WHERE M Run the "midnight job" more often. Seriously, running stuff like this every 5 mins instead can work wonders, especially if work increases non-linearly. (If not, you could still just get the work spread out over the hours of the day.) In Postgres, I've had some success using conditional indices. They work magic by applying an index if certain conditions are met. This means that you can keep the many 'resolved' and the few unresolved rows in the same table, but still get that special index over just the unresolved ones. Ymmv. Should be pointed out that this is where using databases gets interesting . You need to pay close attention to your indices and use EXPLAIN on your queries a lot. (Oh, and remember, interesting is a good thing in your hobbies, but not at work.)
