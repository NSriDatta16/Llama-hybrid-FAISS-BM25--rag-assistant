[site]: crossvalidated
[post_id]: 458667
[parent_id]: 458648
[tags]: 
When you do cross-validation, you check your model on data that the model did not see during the training process. By doing so, you penalize the model for picking up on mere coincidences in the training data, the most extreme example of which is memorizing the training data (connect the dots). You are correct that more parameters should mean a better fit, but thatâ€™s on training data. When you go to unseen data in cross-validation, the expectation (maybe more like hope) is that there will be an improvement in fit on unseen data up to a point, and then the additional parameters will cause the model to overfit. That sweet spot right before the overfitting begins is the parameter count you would use. There are subtleties in developing a good machine learning model, but that is the gist and why your book uses cross validation to find the optimal number of parameters. It is finding the sweet spot in performance on the unseen data.
