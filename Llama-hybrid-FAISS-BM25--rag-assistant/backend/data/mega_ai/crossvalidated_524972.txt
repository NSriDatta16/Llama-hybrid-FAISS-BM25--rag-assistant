[site]: crossvalidated
[post_id]: 524972
[parent_id]: 
[tags]: 
Testing for statistically signifiant differences between a sample of humans and an automated system on a single task

I'm trying to determine the appropriate method to test if there is a significant statistical difference between the performance of a group of users performing a task manually versus the same task being completed automatically. For example, suppose I'm testing a suggested spell correction interface (think red squiggles under words identified by the system as misspelled) versus auto correction. Assume that in the former case, all $n$ users are given an identical passage of text that they must proof read and make changes to (with the help of the red squiggles). By comparison, the fully automated version requires no human at all: the same text given to the humans is given to the auto corrector and it goes through and makes changes. Now suppose I'm measuring accuracy of the resulting text (let's not worry exactly how that's measured, but assume it's continuous) and that's the thing I want to compare between the manual and automatic methods. This will result in a distribution of accuracy scores across the human proofreaders (assume this follows a normal distribution). I'm not sure how to treat the accuracy score of the automated system. So first question: should it be treated as a single measure, or should it be paired with each of the $n$ manual scores? If the former, how should I test for a statistically significant difference between the two conditions? If the latter case, a paired t-test seems wrong because the automatic proofer's distribution isn't normal (err, is that correct?) nor are the variances of the two groups the same (some variance $\sigma^2$ for humans and a variance of 0 for the automatic proofer). Would a randomization test be a better fit since it doesn't have these restrictions? This is all focused on a single text sample; if I were to expand this to consider $m$ text samples, it becomes a lot simpler. The manual condition would result in a distribution of average accuracy (across humans), one average per text, and the automatic condition would be a distribution of scores, one per text.
