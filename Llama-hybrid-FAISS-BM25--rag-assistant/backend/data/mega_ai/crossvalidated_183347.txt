[site]: crossvalidated
[post_id]: 183347
[parent_id]: 
[tags]: 
Distinguish long and short term fluctuations in time series

I have a sequence of events $(e_1,e_2,\dotsc,e_n)$, and each event $(e_i)$ is described by two features $(t_i,F1,F2)$, where $t_i$ is the time of capturing the event. The events $(e_i)$ are captured every second for 10 hours. An example of the events is as follows: { (1,10,5), (2,10,4), (3,10,8), (4,10,0), (5,11,5), (6,11,5), (7,11,19), ... } where the first element is $t$ (the time in seconds), the second element is $F1$ and the third element is $F3$. My question : what is the statistical model that can tell whether $F1$ or $F2$ are long or short term fluctuations? Or if $F1$ or $F2$ have long- or-short variations based on the dataset?
