[site]: crossvalidated
[post_id]: 390170
[parent_id]: 390165
[tags]: 
The layers are a hierarchy to begin with: each layer is fed the outputs of the previous layer and hence works with whatever processing prior layers have done. (There are skip layers and such, but I'm talking in general.) That doesn't guarantee that the physical hierarchy will map to a logical hierarchy by which we humans pedagogically decompose images, but it does provide an intuitive starting point for how it might. In addition we structure the inputs and outputs in a way that pushes the organization options in certain directions. Inputs are pixels and outputs are essentially sets of dummy variables indicating "it's a car", "it's a truck", "it's a traffic light". (I'm really simplifying here.) This constrains the network and the level of processing of the original pixels that each layer would have access to. The input is vague and low-level, while the output is specific and high-level: If I tell you an image has brown pixels it barely narrows what the image might contain, but if I tell you the image is a bear in a mountain stream it eliminates a lot of candidate images. So it's not guaranteed that it works like the idealized description people give, and I've read papers that give hints that it does not exactly work that way. But at the Big Picture level, the intuition about processing and access to processed data -- which is based on a physical hierarchy in the network itself -- makes a logical hierarchy seem likely. In some sense it's more about the constraints we build in when designing a network rather than the actual ingredients. On the flip side, it's good that you're realizing that to some degree the idealized description is taking how we logically think of the task and believing that the machine must somehow reason in like manner, which is not a priori guaranteed.
