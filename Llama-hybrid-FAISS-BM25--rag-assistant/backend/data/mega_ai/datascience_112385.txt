[site]: datascience
[post_id]: 112385
[parent_id]: 
[tags]: 
What does this statement relative to neural network weight initialization mean?

"The same value in all the parameters makes all the neurons have the same effect on the input, which causes the gradient with respect to all the weights is the same and, therefore, the parameters always change in the same way." Taken from my course.
