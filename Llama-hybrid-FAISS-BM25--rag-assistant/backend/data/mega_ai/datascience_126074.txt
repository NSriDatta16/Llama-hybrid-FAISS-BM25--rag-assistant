[site]: datascience
[post_id]: 126074
[parent_id]: 
[tags]: 
Why I'm getting a negative R2 score with Random Forest Regressor?

I'm trying to predict some variables for MOF's (from a scientific paper) using the Random Forest model in Phyton, but the value of R2 is negative (different from the paper, which was positive). I actually don't know if the problem is with my dataset (that involves assigning numerical values to strings), or with my code. The original dataset is literature dataset and my version is "Dados editados 3" The Dataset link: https://docs.google.com/spreadsheets/d/17r-hxcuuzEFdfsqcAdHe_9iIp1d51IvL/edit?usp=sharing&ouid=111702212107777597741&rtpof=true&sd=true I tried to review the code multiples times, though I don't know what I'm doing wrong, because the RF model is a very robust one. Also, I'm removing all Nan values of the dataset with a funcition to detect and remove outliers. The code: import pandas as pd from sklearn.model_selection import train_test_split from sklearn.model_selection import GridSearchCV from sklearn.preprocessing import MinMaxScaler from sklearn.ensemble import RandomForestRegressor from sklearn import preprocessing from sklearn import metrics import numpy as np import seaborn as sns import matplotlib.pyplot as plt import warnings warnings.filterwarnings('ignore') from google.colab import drive drive.mount('/content/drive', force_remount= True) df = pd.read_excel(r'/content/drive/My Drive/Projeto ML/Dados ML.xlsx', sheet_name = "Dados editados 3") print(df.shape) df = df.drop(columns = ['Enzyme loading', 'Immobilisation yield', 'Activity retention'] ) df.replace('-', np.NaN, inplace = True) df = df.dropna() print(df.shape) #Modified function def get_outliers(l): #if you keep 0.1 and 0.75 then pretty much no outliers will be filtered #q1 is 0.25 quantile and q3 is 0.75 quantile q1 = l.quantile(0.25) q3 = l.quantile(0.75) iqr = q3-q1 fenceLow = q1 - 1.5 * iqr fenceHigh = q3 + 1.5 * iqr return [~(i>=fenceLow and i Any suggestion about the code or the dataset itself?
