[site]: crossvalidated
[post_id]: 550725
[parent_id]: 
[tags]: 
Theoretical Details of the MCMC Algorithm

I am trying to better understand the theoretical details of the MCMC Algorithm. In particular, I am trying to better understand why "satisfying the detailed balance condition will result in the Markov Chain converging to the target distribution p(x)"? Part 1 - Summary of the MCMC Algorithm : Below, I have written my understanding of the MCMC Algorithm - here is a visual process I drew ( p(x) is the target distribution and q(x) is the proposal distribution): Assume you start with a target distribution p(x) that you are unable to sample directly. With the right choice of a "transition kernel" and almost any proposal distribution q(x) that spans the same "support" as the target distribution (I still haven't understood why the choice for the proposal distribution is so liberal) - you can now draw samples from the target distribution and calculate the probabilities of these samples belonging to the target distribution. I tried to represent a continuous state Markov Chain for two points X and Y - and show that the distribution of these continuous states would resemble the target distribution. Part 2 - General Notes about Markov Chains: In general, a Markov Chain describes the probability of transitioning to some state, given that you are currently in some other state. The "Markov Property" tells us that the probability of transitioning to some state only depends on the current state. This can be written as follows: For a Markov Chain, the Limiting Distribution can be defined as the long term probability of being in any of the states within the Markov Chain. This can be defined using the transition matrix and the initial probabilities. For a discrete Markov Chain, the limiting distribution is a vector of probabilities (this limiting distribution is also a stationary distribution ): A Markov Chain is said to be " irreducible " if the Markov Chain can go from any state to any state. Below, the Markov Chain in "A" is irreducible but the Markov Chain in "B" is not irreducible (this property is useful for understanding that in theory, the Markov Chain will be able to sample any region of the target probability distribution function, regardless of the current position of the Markov Chain): Part 3 - Balance Condition: The Balance Condition of a Markov Chain is defined as the following condition : If the Balance Condition of a Markov Chain is satisfied, then the Markov Chain will converge to a unique and stationary distribution. (I think this means that the limiting distribution of the transition kernel itself is p(x), i.e. the target distribution?) Part 4 - A Special Choice of the Transition Kernel: In a Discrete Markov Chain, a transition matrix is used to describe the probabilities of transitioning between any two states within the Markov Chain. In a Continuous Markov Chain, a transition kernel is used to describe the probabilities of transitioning between states. To satisfy the Detailed Balance Condition , a special choice of the transition kernel is chosen (this special transition kernel incorporates the probabilities of accepting or rejecting samples from the proposal distribution - but I am not sure why the original Metropolis-Hastings Algorithm uses these acceptance/rejection definitions) : Part 5 - "Proof" of the Special Transition Kernel Satisfying the Detailed Balanced Condition Below, we can show that the choice of our special kernel satisfies the Detailed Balance Condition: I have spent some time and have learned a lot more than I knew before about MCMC Sampling Algorithms (e.g. Metropolis-Hastings) - but I still have trouble understanding the following point: We have shown that our choice of transition kernel satisfies the Detailed Balanced Condition, thus the Markov Chain we are using (to generate candidates from the proposal distribution and then evaluate the target function at these candidates) will have a unique and stationary distribution. But why should this stationary distribution of the Markov Chain converge to the distribution of the target function? I still can not understand the logic behind this - can someone please help me understand this? Thanks! References: https://similarweb.engineering/mcmc/
