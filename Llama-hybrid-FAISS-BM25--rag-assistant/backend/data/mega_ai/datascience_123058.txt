[site]: datascience
[post_id]: 123058
[parent_id]: 123053
[tags]: 
Although LLM's like GPT-3 and LLAMA have gain public attention due to marketing, BERT is the foundation of all Large Language Models being open-source and the first one to base on transformer architecture. Also BERT's bidirectional context-aware embeddings allowed it to capture rich contextual information from both left and right contexts of a word. This property made BERT versatile and effective across a wide range of NLP tasks. These are the reasons why in researchers use BERT instead of other LLMs
