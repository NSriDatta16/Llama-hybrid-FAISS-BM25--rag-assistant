[site]: crossvalidated
[post_id]: 351864
[parent_id]: 351856
[tags]: 
The idea is this. You have a set of data input pairs (x, y), or tuples, as I will call them (in the simplest case). You want to (for example) predict y - or something about y - based on knowing the x it goes with. You split it into a learning group and a test group. Now you could be trying to 'teach' any number of approaches or algos. It could be a neural network; it could be an SVM; it could also be old-fashioned regression. However the mechanism works, you feed it x's and tell it if it's prediction is wrong (or how wrong it is). The goal is for the algo to find a 'best' way to predict the y from any x. Then you test in on the test data to make sure it really does predict (the big risk being overfitting of the training data). # Broadly speaking, there are two kinds of algos. Ones like regression don't really, in my mind, involve 'machine learning'. It's just applying standardized math to solve a known optimization problem (least squares). But if you have a neural net it is a different beast, because the net does change and evolve to move toward it's best possible algo given the net design.
