[site]: crossvalidated
[post_id]: 345018
[parent_id]: 288694
[tags]: 
Sampling simply means to draw a sample from a probability distribution. For example, you can draw a sample from a Gaussian distribution. When you draw one sample, it tells you nothing about the distribution. But after you draw lots of samples, their values should follow the distribution. RBM is a stochastic neural network, meaning that the values of every neuron follow certain probability distributions. When you have the p(v, h), theoretically you can draw samples of pair value (v, h) from the distribution. But it does not make much sense to do that, because that is almost useless. On the other hand, it is useful to know the distribution of p(h|v) and p(v|h), because then you can sample h given v. It means, when you have an observed value v, you can compute the probability distribution of the hidden value h, i.e., p(h|v). Once you have the distribution, you can sample the value of h, and vice verse. This is important, because then you can use value h to represent v (together with the weights and biases). That means, you can reconstruct v from h, and you can use h for any learning or computations in place of v. It also means you can pretrain a layer of network with RBM unsupervisedly, while still extracting the useful features.
