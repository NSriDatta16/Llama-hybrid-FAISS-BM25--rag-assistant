[site]: crossvalidated
[post_id]: 524179
[parent_id]: 201747
[tags]: 
One of the practical reasons why we use weak learners is that we don't need to care about issues like this. In many cases ensembling many weak learners is just enough to achieve good performance. Weak learners are simple by design, we don't usually tune them. You are correct, if you wanted to tune them, this becomes a complicated optimization problem. If you really want to do this, one thing that could make things easier is to use a more clever optimization algorithm than grid search, for example Bayesian optimization that "cleverly" explores the parameter space.
