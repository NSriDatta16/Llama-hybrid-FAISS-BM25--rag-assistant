[site]: crossvalidated
[post_id]: 576777
[parent_id]: 
[tags]: 
Diversity between classifiers in ensemble learning

According to Wikipedia, Ensemble of models tends to yield better results when there is a significant diversity among the models. Many ensemble methods, therefore, seek to promote diversity among the models they combine. Using a variety of strong learning algorithms has been shown to be more effective than using techniques that attempt to dumb-down the models in order to promote diversity. I have two questions please regarding this paragraph: Could you please explain the meaning of diversity with simple example? In ensemble classifier, do we combine (using for example, majority voting) weak classifiers or strong classifiers, or a combination of both weak and strong classifiers?
