[site]: crossvalidated
[post_id]: 306266
[parent_id]: 
[tags]: 
Data Dredging or valid?

Hi Cross Validated community, I have been reading answers posted previously on the topic of automated model selection and whether it is data dredging. This has led me to doubting the validity of my current approach. My question is: am I data dredging or dangerously using automated model selection? Here is the process. I have 40 nucleiotide variations and calculating a risk score to then use a logistic regression to predict cases and controls of a trait. I want to find the 'most important' subset, say 10 variations that perform as well the 40. My dataset of individuals is 1000. 1. I split the dataset into two subsets A (N=850) and B (N=150). B is used for testing after finding one or more models. Start a list called best_variations. 2. Shuffle A, then split into A_train (75%) and A_valid (25%). 4. Using the previous best_variations, and the current cycle's variation, calculate the risk score. 5. Fit the risk score logistic regression using A_train. 6. Calculate AUROC with A_valid (not using the labels). 7. Repeat 2 to 4 100 times to compute the average AUC for variation. 8. Compare the average AUROC to the previous best AUROC. 9. if larger, keep, after iterating through the 40 variations keep the maximum AUROC found, and put append the variation to a list of best variations. 10. Repeat 2-8, increasing the number of variations included at each cycle. 11. Result: smaller list of the variations that maximize AUROC. 12. Using the best variations, compare the accuracy and ROC to other models with set B, the test set, which has not been seen by the automated process. Thanks for any input! Hopefully I can answer any clarification questions.
