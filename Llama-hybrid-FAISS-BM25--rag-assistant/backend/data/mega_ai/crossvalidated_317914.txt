[site]: crossvalidated
[post_id]: 317914
[parent_id]: 43436
[tags]: 
The Difference Let's do a small thought experiment with regards to regression. Let's make this simple regression: $y = \beta_0 + \beta_1 x$ We can apply solve for the best possible weights and linear algebra states that the best weights can be found via: $\beta^* = [\beta_0, \beta_1]^T = (X'X)^{-1} X'y$ Now imagine that we run the regression with a small dataset and with a large dataset. I think it should be safe to argue that we are much more certain that our estimate $\beta^*$ is sensible when we have 1000 points of data opposed to if we only have 10 points of data. Because $\beta^*$ is a single datapoint and not a distribution, we cannot quantify our certainty with it. This is where and why bayesians interpret $\beta$ differently. Bayesians look at $\beta$ and think that depending on the dataset, we can be more or less certain about it. If this feels very confusing, you may appreciate this blogpost where the difference is mentioned in more detail. [Disclaimer, this blogposts are written by myself] The Benefit Now we will assume that we've learned our $\beta^*$ and this is a distribution instead of a mere number. You'll notice that our prediction now becomes stochastic. $\beta_0 + \beta_1 x_i \to \hat{y_i} $ Our prediction $y_i$ is now a distribution too. This means that we have confidence bounds on our prediction. If you care about the uncertainty of your prediction, this is a very very nice thing.
