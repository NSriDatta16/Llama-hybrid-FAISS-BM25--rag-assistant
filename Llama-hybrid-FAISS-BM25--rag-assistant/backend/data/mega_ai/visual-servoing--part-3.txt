 popularly called portioned approach partitions the visual (or image) Jacobian into motions (both rotations and translations) relating X and Y axes and motions related to the Z axis. outlines the technique, to break out columns of the visual Jacobian that correspond to the Z axis translation and rotation (namely, the third and sixth columns). The partitioned approach is shown to handle the Chaumette Conundrum discussed in. This technique requires a good depth estimate in order to function properly. outlines a hybrid approach where the servoing task is split into two, namely main and secondary. The main task is keep the features of interest within the field of view. While the secondary task is to mark a fixation point and use it as a reference to bring the camera to the desired pose. The technique does need a depth estimate from an off-line procedure. The paper discusses two examples for which depth estimates are obtained from robot odometry and by assuming that all features are on a plane. The secondary task is achieved by using the notion of parallax. The features that are tracked are chosen by an initialization performed on the first frame, which are typically points. carries out a discussion on two aspects of visual servoing, feature modeling and model-based tracking. Primary assumption made is that the 3D model of the object is available. The authors highlights the notion that ideal features should be chosen such that the DOF of motion can be decoupled by linear relation. The authors also introduce an estimate of the target velocity into the interaction matrix to improve tracking performance. The results are compared to well known servoing techniques even when occlusions occur. Various features used and their impacts on visual servoing This section discusses the work done in the field of visual servoing. We try to track the various techniques in the use of features. Most of the work has used image points as visual features. The formulation of the interaction matrix in assumes points in the image are used to represent the target. There has some body of work that deviates from the use of points and use feature regions, lines, image moments and moment invariants. In, the authors discuss an affine based tracking of image features. The image features are chosen based on a discrepancy measure, which is based on the deformation that the features undergo. The features used were texture patches. One of key points of the paper was that it highlighted the need to look at features for improving visual servoing. In the authors look into choice of image features (the same question was also discussed in in the context of tracking). The effect of the choice of image features on the control law is discussed with respect to just the depth axis. Authors consider the distance between feature points and the area of an object as features. These features are used in the control law with slightly different forms to highlight the effects on performance. It was noted that better performance was achieved when the servo error was proportional to the change in depth axis. provides one of the early discussions of the use of moments. The authors provide a new formulation of the interaction matrix using the velocity of the moments in the image, albeit complicated. Even though the moments are used, the moments are of the small change in the location of contour points with the use of Green’s theorem. The paper also tries to determine the set of features (on a plane) to for a 6 DOF robot. In discusses the use of image moments to formulate the visual Jacobian. This formulation allows for decoupling of the DOF based on type of moments chosen. The simple case of this formulation is notionally similar to the 2-1/2- D servoing. The time variation of the moments (m˙ij) are determined using the motion between two images and Greens Theorem. The relation between m˙ij and the velocity screw (v) is given as m˙_ij = L_m_ij v. This technique avoids camera calibration by