[site]: crossvalidated
[post_id]: 517820
[parent_id]: 
[tags]: 
Meaning of θj in equation for partial derivative of MSE

The equation to find the partial derivative of a cost function with respect to a parameter θj is given in the book Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow : $$ \frac{\partial}{\partial \theta_j}\operatorname{MSE}({\boldsymbol{\theta}}) = \frac{2}{m} \sum_{i=1}^m \left(\boldsymbol{\theta}^\intercal \boldsymbol{x}^{(i)} - y^{(i)}\right)x_j^{(i)} $$ m = number of instances in the dataset x = input vector for the prediction y = label for the input vector Is $\theta_j$ in the equation a unique combination of bias and weights which is reflected in the vector $\boldsymbol{\theta}$ in the equation? Or is it a single parameter inside a vector?
