[site]: crossvalidated
[post_id]: 542070
[parent_id]: 
[tags]: 
Derivation of expected value in REINFORCE policy gradient

This is a derivation in the book "Reinforcement Learning, an Introduction, 2ed" for the REINFORCE algorithm. By definition $q_\pi(s,a)=\mathbb{E}[G_t|S_t=s,A_t=a]$ . I don't understand how the inner expectation vanish when going from line 2 to line 3. Why the following is true? $$\mathbb{E}\left[\mathbb{E}[G_t|S,A]\frac{\nabla\pi(A_t|S_t)}{\pi(A_t|S_t)}\right]= \mathbb{E}\left[G_t\frac{\nabla\pi(A_t|S_t)}{\pi(A_t|S_t)}\right]$$ This question was made in another stack but in one step of the accepted answer it is assumed that the conditional expectation is wrt $S_t=s$ (a specific value of $S_t$ ) and not $S_t$ which is a random variable. Derivation of Monte Carlo Policy Gradient for REINFORCE
