[site]: crossvalidated
[post_id]: 349961
[parent_id]: 
[tags]: 
How does probabilistic ML "handle uncertainty"?

I have heard professors and others say that probabilistic machine learning is useful because it can model or handle uncertainty. I'm not sure what is meant by this. To give an authoritative source, David MacKay writes in his book on inference (p. 531): Probabilistic modelling also handles uncertainty in a natural manner. It offers a unique prescription, marginalization, for incorporating uncertainty about parameters into predictions... What is meant by this? How does this handle uncertainty? A comparison to a non-probabilistic model would be appreciated.
