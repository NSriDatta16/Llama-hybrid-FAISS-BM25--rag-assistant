[site]: crossvalidated
[post_id]: 147258
[parent_id]: 
[tags]: 
Expectation of squared error

In machine learning, we let $X$ be a real-valued input vector and $Y$ be a real number output, with joint distribution $P(X,Y)$. We are looking for a function $f(X)$ for predicting $Y$ given the values of $X$. In most of machine learning problems, we give penalty for each time that the prediction is wrong. The loss function is defined as follows: $L(Y,f(X))=(Y-f(X))^2$. The expected square prediction error is given as: $$EPE(f) = E(Y-f(X))^2 = \displaystyle\int [y-f(x)]^2P(dx,dy). $$ The book I'm reading says: By conditioning on $X$, we can write EPE as $EPE(f) = E_XE_{Y|X}((Y-f(X))^2|X)$, and eventually getting a solution that is $f(x) = E(Y|X=x)$. I'm not sure I follow what happened in these steps. Please help me with the derivation. Thanks
