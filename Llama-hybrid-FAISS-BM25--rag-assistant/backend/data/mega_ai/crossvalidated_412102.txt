[site]: crossvalidated
[post_id]: 412102
[parent_id]: 412098
[tags]: 
You can drop the uncommon words, but this would lead to losing information. There's a number of better approaches: As mentioned in comments, you can group the uncommon words in the "other" category. You can use feature hashing , where multiple words would share same encodings. Another approach is to assign unique labels to a subset of most popular words, and for all the other words you would split them to n-grams and encode the n-grams. This is done by some deep learning algorithms, and probably makes sense for those that look at sequences, rather than bag-of-words . Notice that the above approaches work also for words that were not present in the training set, but appear on prediction time.
