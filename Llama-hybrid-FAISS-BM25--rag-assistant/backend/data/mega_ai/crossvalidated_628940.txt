[site]: crossvalidated
[post_id]: 628940
[parent_id]: 
[tags]: 
How should I test whether simultaneous residuals from two models of the same time series are independent?

Suppose I have two different models, with comparable goodness of fit but very different structure, that I have fit to the same time series. For both, the residuals pass various tests of normality. How would I test whether the simultaneous residual vector observations are independent of each other? The correlation between the residual vectors is very small. The question I am really trying to get at is whether the average of the forecasts of the two models is likely to be better than the individual model forecasts. For the historic (training) data the averaged model fits better than either individual model, but I donâ€™t think I can assume this result extends to forecasts. All I can think of to do is slice off the last thirty or forty observations for testing, using only the remaining observations for training. But what I really have is not two models, but about 40 models. My current belief is that the largest subset of those models for which the residuals are mutually independent should be averaged. So I want to do pairwise independence tests on the residuals for all of them, in order to identify the models which should be included in the averaged model. My hope is that I can get away with such pairwise testing if I use the right test, rather than needing to test every subset, which become infeasible quickly as the number of models rises. Would it enough to test pairwise correlations rather than pairwise independence?
