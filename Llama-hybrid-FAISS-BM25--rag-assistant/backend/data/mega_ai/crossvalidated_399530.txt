[site]: crossvalidated
[post_id]: 399530
[parent_id]: 399430
[tags]: 
The 0/1 encoding of male/female doesn't by itself put more weight on females versus males; it's not really different from having a value of 0 versus 1 (or 1 versus 2) in a continuous predictor. It's just a difference of 1 unit in the predictor value. As @Tim rightly points out, for many machine learning approaches normalization is not required and there is no issue about weighting. There is, however, a potential problem when your modeling method requires all predictors to be on the same scale. Examples are principal-components analysis (PCA) and penalized linear approaches like LASSO, ridge, or their hybrid elastic net. The default, in some implementations at least, is to normalize all predictors including the categorical predictors. That's where you can have difficulties. If you don't normalize the categorical predictors, are they on the same scales as the continuous predictors, as your penalization method implicitly assumes? If you do normalize 2-level predictors like male/female, the normalized values can depend heavily on the class frequencies in your sample. So normalization of predictors having class imbalance can alter weighting. For multi-level categorical predictors the issue is even more vexing as the choice of the reference level can affect the normalized values. This page goes into more detail. There is no one-size-fits-all solution to this issue in PCA and penalized regression; intelligent application of your subject-matter knowledge might be best.
