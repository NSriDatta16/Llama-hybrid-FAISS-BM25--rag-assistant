[site]: crossvalidated
[post_id]: 297607
[parent_id]: 210056
[tags]: 
The essence of a neural network is the graph. While graphs may be part of math, their concepts are as old as relationship itself and pre-date it. If it were necessary for learning to be complex, then brains probably wouldn't have evolved at all, for the probability of ordered complexity is too improbable. So, then, one must ask: what is the simplest machine that can learn? But, of course, that begs the epistemological question: what is learning? Learning is the juxtaposition of two novel states, forming a memory. And there you have the basis of AI: memory.
