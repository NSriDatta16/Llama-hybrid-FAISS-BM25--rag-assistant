[site]: crossvalidated
[post_id]: 563652
[parent_id]: 563649
[tags]: 
You have a model R = f(CP, F1, ..., Fn) + eR, where R is the revenue CP is the conversion probability F1, ..., Fn are further features f is the function describing the model eR is some noise. Furthermore, you have a second model for the conversion probability CP: CP = g(G1, ..., Gm) + eCP, where CP is the conversion probability G1, ..., Gm are the features you use to predict CP g is the function describing the model for CP eCP is some noise. Now, everything depends on how you choose the functions f and g, what learnable parameters and hyperparameters you give them, and what you presume for the distribution of the noises. This describes a simple Bayesian network (BN), and there are several learning algorithms for BNs varying in complexity, e.g. the EM algorithm. And there will be no a priori degradation of the quality of the final prediction.
