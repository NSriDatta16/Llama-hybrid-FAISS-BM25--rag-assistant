[site]: crossvalidated
[post_id]: 366059
[parent_id]: 
[tags]: 
Meaning of different softmax notations in papers

I was wondering if the different notations of the softmax input mean different things especially about the size of the output. For example, in the paper Pointer Networks , it sometimes state the input of the softmax with the subscript j, and in another equation, it removed the subscript Does the one with the subscript j imply that we produce a distribution over the elements of each ui and the one without the j subscript mean a distribution over all the ui vectors? I thought it could be a typo, but it happened again in another paper Reinforcement Learning for Solving the Vehicle Routing Problem . Here:
