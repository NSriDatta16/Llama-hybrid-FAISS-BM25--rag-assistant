[site]: crossvalidated
[post_id]: 82933
[parent_id]: 82924
[tags]: 
Those are good questions. Linear support vector machines look for the linearly-separating hyperplane in your data. The characteristics of that plane have a lot to do with the number of features in your classification problem, as well as the approach you're using to model the features (e.g., binary or term frequency/inverse document frequency, also known as tf-idf). It might help you to brush up on some SVM fundamentals. To this end, i've found " A Practical Guide to Support Vector Machine Classification " to be an outstanding reference. That said, SVM does use all the features you give it, but it is not necessarily equally influenced by all features. For example, in text classification, which tends to involve millions of features, it has been my experience that less-informative features, such as the presence or absence of a very common word, does not have as much influence as a less-common word that tends to be associated with one particular class.
