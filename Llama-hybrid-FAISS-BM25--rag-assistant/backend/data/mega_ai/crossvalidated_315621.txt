[site]: crossvalidated
[post_id]: 315621
[parent_id]: 315604
[tags]: 
I agree that the wording they chose was poor. What they are trying to get at, I think, is that there is more than one way to be wrong. Their point is that the test is not right 95% of then time: maybe 95% of the people who get a 'positive' for the test have the disease, but maybe 10% of the people who get a negative also have it. Then, on average, if 20 out of 100 people have the disease, and 100 people take the test, 27% will get a positive result, but only 19% have the disease. This is a real problem. In the early days of HIV, the number of people infected was quite small ( Part of this is just what I will call 'bookeeping' on true positives, false positives, true negatives, and false negatives - which also must take into account the relative frequency of the issue. In olden times, this basic theory was developed by Pearson during WWII (see 'Detection Theory': https://en.wikipedia.org/wiki/Detection_theory ) The author is also trying to introduce the dichotomy between Bayesian and frequentist stats. Frequentist is what we are mostly taught and involves the standard test (t-tests, etc.). It relies on the data being all we look at. Bayesian stats, on the other hand, looks at the data we have in light of prior data or even thoughts. There is lots written on the differences but given they raised polling data it is worth noting some historical (and recent) failures of polling due to this split. Have you ever wondered why they can declare a U.S. state resuls in the race for president by exit polls with only 2% of the vote in? It is because we know, from prior years, exactly what happened in each county. If a Democrat has won the county by a 10-20% margin in the last 20 elections, a Bayesian pollster looks at a 2% lead by the Democrat as a very strong likelihood of his or her winning. But a 2% lead by the Democrat in a county that has always voted Republican is a weaker case - yet, in both cases, the lead is 2%. We are 'informed' by prior information , in Bayesian-speak. The UK Brexit vote had this problem: no one had voted on this issue before. The frequentist polling got it wrong.
