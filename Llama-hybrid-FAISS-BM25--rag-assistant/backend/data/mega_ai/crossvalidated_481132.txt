[site]: crossvalidated
[post_id]: 481132
[parent_id]: 480978
[tags]: 
You could fit a binomial regression (a logistic regression where the data is a count of successes over a count of trials). This would allow you to infer how the probability that a test in an article is erroneous changes given the meta-data of the article. This generalizes modeling a single yes/no if the article contains at least one erroneous test, thus preventing you from throwing away information. Further it allows you to reasonably compare articles that contain different amounts of tests, and to control for whether the number of tests changes the probability of a test having an error. You could pair such a model with a model that represents the distribution of total number of tests featured in an article given the meta data (e.g. a Poisson or negative-binomial regression). This could provide even more insights. A word of caution: your inferences should be taken with a grain of salt, as your data sounds observational in nature (versus experimental). This is fine, its just important avoid pitfalls like overfitting to data, misinterpreting noise for signal, etc.
