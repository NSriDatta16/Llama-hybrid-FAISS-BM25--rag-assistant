[site]: crossvalidated
[post_id]: 89521
[parent_id]: 
[tags]: 
Binomial count data - use glmer, lmer or just average it all?

I'm new to both mixed-effects models and R, so please excuse me if this is a bit of a silly question! I'm struggling with choosing the best method to analyse my data for a speech perception study, and would appreciate some help! Some info about the data: In the study, participants listen to sentences in different accents and embedded in different noise levels, and then repeat what they understand. So for each sentence there is the number of words correctly repeated, and the total number of words in each sentence. I'm trying to figure out how to analyse this data in a mixed-effect model. I thought a binomial glmer would be best, as it's count data, but I had no idea if I was doing this right (particularly specifying the proportion of words correctly repeated), so I tried the same model (without interactions) in glmer and lmer. glmer: mixed.glmer lmer: all.lmer Then I compared the models: > Df AIC BIC logLik deviance Chisq Chi Df Pr(>Chisq) > all.glmer 6 13441.2 13480.1 -6714.6 13429.2 > all.lmer 7 2564.6 2610.0 -1275.3 2550.6 10879 1 Which seems to suggest that the lmer model is a much better fit, but surely the data isn't being modelled well by linear methods? Then, a colleague suggested that I average across all noise levels for each accent (so I can treat the data using linear methods), giving only three data points per participant. So I tried this model, which seems to be a much better fit than either of the above models with all of the data: average.m1 AIC BIC logLik deviance > -102.1759 -93.1426 56.0880 -112.1759 However, this seems to be throwing away a lot of data (particularly now that the noise factor has disappeared), even if the model does fit better - I thought the whole point of mixed models was to avoid doing the averaging step, like I'd need to for an ANOVA. This seems like very much like the easy way out of this problem! So my questions are: Should I bother trying to fit a model to the whole dataset, or go with the easy way and average it? Am I right to think that for the whole data set, the lmer model is a better fit than the glmer model, or is this like comparing apples and oranges? If I do use the gmler model, am I specifying the DV correctly? It should be the proportion of correct responses (i.e.: Correct/Max). I'm finding it very, very hard to find instructions that I can actually understand! Any help would be highly appreciated!
