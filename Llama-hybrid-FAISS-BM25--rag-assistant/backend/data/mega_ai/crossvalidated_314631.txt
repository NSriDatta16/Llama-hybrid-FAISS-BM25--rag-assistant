[site]: crossvalidated
[post_id]: 314631
[parent_id]: 314618
[tags]: 
You certainly can do that. Since they are linear models, you are essentially averaging the predicted values from 10 linear models fit to slightly different slices of your training data. You could imagine doing the same thing with bootstrap samples, and you'd have a linear-regression forest (but without the predictor subsampling that makes random forest work so well). In the end, you get a crude sort of regularization out of the procedure. The averaging lowers your model variance, but only to a point since there are only ten models and they are going to be quite correlated. In practice, you have better options in penalized regularization methods. These achieve the same ends, and give you more precise control over the variance reduction of the model.
