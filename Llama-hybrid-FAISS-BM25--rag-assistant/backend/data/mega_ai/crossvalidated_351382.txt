[site]: crossvalidated
[post_id]: 351382
[parent_id]: 57906
[tags]: 
If this were me, I would formulate this as a Bayesian problem, like Xi'an said, so that confidence (well, credible) intervals fall out naturally. Since the mixture component means are random variables, the posterior distribution will tell you everything you need to know about your estimated parameters, beyond just point estimates and confidence intervals. While it's true that standard Bayesian methods like MCMC will perform poorly on mixture model data due to lack of identifiability and a highly multimodal posterior, you can mitigate this computationally (like by using Potentials in PyMC3) or by switching to Variational Inference, which is not only better suited to this problem but will also give you back a distribution for each parameter.
