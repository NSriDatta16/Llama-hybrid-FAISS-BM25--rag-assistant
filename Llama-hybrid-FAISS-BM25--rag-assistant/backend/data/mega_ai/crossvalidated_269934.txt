[site]: crossvalidated
[post_id]: 269934
[parent_id]: 
[tags]: 
Function approximation using multilayer perceptron (neural network)

I've been asked to solve a problem for a project. I'm working on Python or R. I need to approximate a function with multiplayer perceptron (neural network). The function is: $y= 2\text{cos}(x)+4$ on the interval $[0,10]$. After reading a lot about perceptron and neural network for the approximation of functions, I found a code that helped me a lot and my program is based on this code. Here is the code (with comments) I use to approximate my function followed by questions and examples : # Create vector of random data between 0 and 10, lenght 50 x Few questions 1) In the example I found, we generate 50 points (vector x), but why 50 ? If I use 20 or 1000 results can vary. 2) How to fix the number of neurons to use ? I just try with a lot of different numbers but I don’t have rule. 3) How to fix the number of iteration the neural network use (maxit=40 here) ? Should I use other parameters of nnet ? I'm a bit lost 4) I have 1 hidden layer as I see that most of approximate function case use only one but I dont really know why. 5) When I create vector « x1 » I dont know how to fix the number of element I want (here 100 but what if I choose 20 or 1000) 6) When I run my code, results are changing, sometimes the approximation is quite precise and sometimes It’s just not good from a certain points of the curve and I dont really know why. I'm also interested by this method on python but it seems more complicated to implement Example 1 : a good approximation (not bad) green line : approximated function with neural network (multilayer perceptron) dark line: our function (2*cos(x)+4) dots are generated points from the function (y) that we use to build the model Example 2 : a bad approximation (with the same code)
