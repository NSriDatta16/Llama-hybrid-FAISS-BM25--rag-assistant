[site]: crossvalidated
[post_id]: 48634
[parent_id]: 48374
[tags]: 
The longpower package implements the sample size calculations in Liu and Liang (1997) and Diggle et al (2002). The documentation has example code. Here's one, using the lmmpower() function: > require(longpower) > require(lme4) > fm1 lmmpower(fm1, pct.change = 0.30, t = seq(0,9,1), power = 0.80) Power for longitudinal linear model with random slope (Edland, 2009) n = 68.46972 delta = 3.140186 sig2.s = 35.07153 sig2.e = 654.941 sig.level = 0.05 t = 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 power = 0.8 alternative = two.sided delta.CI = 2.231288, 4.049084 Days = 10.46729 Days CI = 7.437625, 13.496947 n.CI = 41.18089, 135.61202 Also check the liu.liang.linear.power() which " performs the sample size calculation for a linear mixed model" Liu, G., & Liang, K. Y. (1997). Sample size calculations for studies with correlated observations. Biometrics, 53(3), 937-47. Diggle PJ, Heagerty PJ, Liang K, Zeger SL. Analysis of longitudinal data. Second Edition. Oxford. Statistical Science Serires. 2002 Edit: Another way is to "correct" for the effect of clustering. In an ordinary linear model each observation is independent, but in the presence of clustering observations are not independent which can be thought of as having fewer independent observations - the effective sample size is smaller. This loss of effectiveness is known as the design effect : $$ DE = 1 +(m-1)\rho$$ where $m$ is the average cluster size and $\rho$ is the intraclass correlation coefficient (variance partition coefficient). So the sample size obtained through a calculation that ignores clustering is inflated by $DE$ to obtain a sample size that allows for clustering.
