[site]: crossvalidated
[post_id]: 517264
[parent_id]: 
[tags]: 
How does a transformer network's attention mechanism determine what to pay attention to?

The paper Attention is All You Need describes the transformer network which uses a "multi-head attention mechanism". The basic intuition behind this mechanism is that it weighs other tokens in a sequence by how much they are expected to influence the value of a token at some position. There are several high-level things I don't understand about it though and every article I read about them is either too technical or too hand-wavy for my experience level. These are the things I am trying to understand: Are the attention weights based solely on position of the tokens? Are the attention weights calculated using the vectors in the sequence? If so, which vectors are used? How is the attention mechanism trained? What are the inputs it received during training?
