[site]: stackoverflow
[post_id]: 2977557
[parent_id]: 2940369
[tags]: 
The process usually goes like this: You have some labeled data instances which you want to use to train a classifier, so that it can predict the class of new unlabeled instances. Using your classifier of choice (neural networks, bayes net, SVM, etc...) we build a model with your training data as input. At this point, you usually would like to evaluate the performance of the model before deploying it. So using a previously unused subset of the data (test set), we compare the model classification for these instances against that of the actual class. A good way to summarize these results is by a confusion matrix which shows how each class of instances is predicted. For binary classification tasks, the convention is to assign one class as positive, and the other as negative. Thus from the confusion matrix, the percentage of positive instances that are correctly classified as positive is know as the True Positive (TP) rate. The other definitions follows the same convention...
