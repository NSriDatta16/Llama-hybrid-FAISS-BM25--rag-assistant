[site]: crossvalidated
[post_id]: 531523
[parent_id]: 531491
[tags]: 
AI is not necessary modeled after organic intelligence. There are subfields within AI and computational neuroscience or cognitive science, that are interested in creating biologically plausible algorihms, but this is more of an exception than a rule. In some fields, people create computational models of various behaviours or cognitive processes in order to study these processes, but not for the sake of improving AI. In this case it is possible that some group have computational models of learned helplessness. "Learned helplessness" of a node is not the same as learned helplessness of an individual and I don't thing these effect would be related. What would a not do with respect to other nodes depends on an learning algorithm. In a Hebbian style "wire together, fire together" learning, if a node fails to produce results relative to other nodes, it would get deweighted or maybe even pruned out of a network. In a more traditional gradient based optimization, a node will be adjusted based on it's error gradient regardless of what other nodes in a layer do. There might be a regularization parameter imposed on the layer which might take into account activations of other neurons, but this might also have an effect in either direction.
