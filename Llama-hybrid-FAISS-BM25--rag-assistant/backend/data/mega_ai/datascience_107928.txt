[site]: datascience
[post_id]: 107928
[parent_id]: 
[tags]: 
Usefulness of intercept in layman terms - ELI5

I am working on a binary classification problem with 1000 rows and 10 features. While I did use random forest for classification, I also used LIME to explain the predictions of the random forest. However, I came across something like below Intercept 0.7932393836062923 Prediction_local [0.71440155] Right: 0.6854552819361831 Lime computes prediction_local based on below formula exp.local_exp = exp.intercept[1] + sum([weight[1] for weight in exp.local_exp[1]]) 0.714401551296631 #returned this value (matches with `Prediction_Local`) So, my question is a) When individual features contributes very less to the prediction, how can I convince the business regarding huge intercept value? what is the use of intercept? If business asks why is intercept value high, how can I explain the reasoning behind it? b) I understand that intercept helps us to capture all linear patterns (which a model with no intercept cannot capture) but how does it acquire it's value? If you are asked to explain the use of intercept to model predictions, how would you explain that to a ordinary layman? c) In above LIME explanation, we can see that major contribution of local prediction came from intercept . So, am trying to understand how does it get its value and how to interpret and translate its usefulness for business stakeholders? I understand intercept is a constant when X=0. So, what does that mean? How is it useful? As you can see in the above example, despite my input variable coefficients being very low, it still predicts the class/outcome correctly because of the high intercept value. But as you know this intercept value doesn't come from our input variables. So, how do we explain the reasoning of this intercept value with a simple explanation to business users? This question is also raised because am having trouble in explaining intercept to business users without mathematical terms
