[site]: crossvalidated
[post_id]: 101488
[parent_id]: 101471
[tags]: 
If the dataset you have is representative of the real distribution of the class labels then the fact that labels are imbalanced should be incorporated in your predictions. Also not using data while you have them is rather unadvised. So one solution would be instead of sampling the majority class to try oversampling the minority. In classifiers like SVMs the solution is straight forward by assigning different weights to each class label. In Bayesian approaches you have different priors per class. Also, check out the answers here: Training a decision tree against unbalanced data
