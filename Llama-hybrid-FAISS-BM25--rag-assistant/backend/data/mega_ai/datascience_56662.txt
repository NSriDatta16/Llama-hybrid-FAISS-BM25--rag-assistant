[site]: datascience
[post_id]: 56662
[parent_id]: 55359
[tags]: 
Label flipping is a training technique where one selectively manipulates the labels in order to make the model more robust against label noise and associated attacks - the specifics depend a lot on the nature of the noise. Label flipping bears no benefit only under the assumption that all labels are (and will always be) correct and that no adversaries exist. In cases where noise tolerance is desirable, training with label flipping is beneficial. Label smoothing is a regularization technique (and then some) aimed at improving model performance. Its effect takes place irrespective of label correctness. From 1 Adversarial Perturbations of Deep Neural Networks , 2016 : Without label smoothing, a softmax classifier is trained to make infinitely confident predictions on the training set. This encourages the model to learn large weights and strong responses. When values are pushed outside the areas where training data concentrates, the model makes even more extreme predictions when extrapolating linearly. Label smoothing penalizes the model for making overly confident predictions on the training set, forcing it to learn either a more non-linear function or a linear function with smaller slope. Extrapolations by the label-smoothed model are consequently less extreme. From Regularizing Neural Networks by Penalizing Confident Output Distributions , 2017 : Confident predictions correspond to output distributions that have low entropy. A network is over-confident when it places all probability on a single class in the training set, which is often a symptom of overfitting. The confidence penalty constitutes a regularization term that prevents these peaked distributions, leading to better generalization. As a result of label smoothing, the model becomes more robust in general. Its increased ability to deal with incorrect labels is just part of the overall improvement. However, one cannot claim that the effects of label smoothing are purely beneficial. From When Does Label Smoothing Help? , 2019 : Despite having a positive effect on generalization and calibration, label smoothing can hurt distillation. We explain this effect in terms of erasure of information. With label smoothing, the model is encouraged to treat each incorrect class as equally probable. With hard targets, less structure is enforced in later representations, enabling more logit variation across predicted class and/or across examples. This can be quantified by estimating mutual information between input example and output logit and, as we have shown, label smoothing reduces mutual information.
