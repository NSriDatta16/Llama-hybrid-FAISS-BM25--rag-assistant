[site]: crossvalidated
[post_id]: 533858
[parent_id]: 
[tags]: 
Is Fractional Differencing still important when using a LSTM model?

In his seminal book "Advances in Financial Machine Learning", Dr. Marcos Lopez de Prado describes the importance of using fractional differencing to preserve memory while keeping stationary. But in deep neural networks, some models like LSTM, Transformers, and even CNN, can retain memory. In these models, when providing a sufficiently large interval to the network, is it still useful to apply Fractional Differencing? Can I get away with just using price returns and a long interval, say 128 days?
