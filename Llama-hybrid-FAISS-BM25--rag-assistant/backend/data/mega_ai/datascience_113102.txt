[site]: datascience
[post_id]: 113102
[parent_id]: 
[tags]: 
'NoneType' object has no attribute 'get_shape' in standard AdamOptimizer Initialization

I'm trying to construct a basic neural network in TensorFlow by following an example in Hands-On Machine Learning by Aurelian. The following code n_inputs = 4 n_hidden = 4 n_outputs = 1 initializer = tf.contrib.layers.variance_scaling_initializer() learning_rate = 0.01 X = tf.placeholder(tf.float32, shape=[None, n_inputs]) hidden = tf.layers.dense(X, n_hidden, activation=tf.nn.elu, kernel_initializer=initializer) logits = tf.layers.dense(hidden, n_outputs, kernel_initializer=initializer) outputs = tf.nn.sigmoid(logits) p_left_and_right = tf.concat(axis=1, values=[outputs, 1-outputs]) action = tf.multinomial(tf.log(p_left_and_right), num_samples=1) y = 1. - tf.to_float(action) cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits( labels=y, logits=logits) print("cross_entropy: ", cross_entropy) optimizer = tf.train.AdamOptimizer(learning_rate) grads_and_vars = optimizer.compute_gradients(cross_entropy) gradients = [grad for grad, variable in grads_and_vars] gradient_placeholders = [] grads_and_vars_feed = [] print("grads_and_vars:", grads_and_vars) for grad, variable in grads_and_vars: gradient_placeholder = tf.placeholder(tf.float32, shape=grad.get_shape()) gradient_placeholders.append(gradient_placeholder) grads_and_vars_feed.append((gradient_placeholder, variable)) training_op = optimizer.apply_gradients(grads_and_vars_feed) init = tf.global_variables_initializer() saver = tf.train.Saver() produces the error cross_entropy: Tensor("logistic_loss_15:0", shape=(3, 1), dtype=float32) grads_and_vars: [(None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), (None, ), ( , ), ( , ), ( , ), ( , )] --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in () 27 print("grads_and_vars:", grads_and_vars) 28 for grad, variable in grads_and_vars: ---> 29 gradient_placeholder = tf.placeholder(tf.float32, shape=grad.get_shape()) 30 gradient_placeholders.append(gradient_placeholder) 31 grads_and_vars_feed.append((gradient_placeholder, variable)) AttributeError: 'NoneType' object has no attribute 'get_shape' My best guess was that this had to do with passing in None for the first dimension of shape , but changing that into a number does nothing for the error. What is the cause of this? Also, I'm relatively new to TensorFlow and this type of neural network, so don't be afraid to dumb things down. ;D Thanks!
