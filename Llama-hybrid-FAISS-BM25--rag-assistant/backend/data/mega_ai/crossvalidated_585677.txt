[site]: crossvalidated
[post_id]: 585677
[parent_id]: 
[tags]: 
Transforming input features for ANN

I usually normalise my input variables for linear models (i.e. apply a log transformation, or rank-based inverse normal transformation). One of the reasons I like using tree based methods like Random Forests and XGBoosts is that I do not need to transform the input features (when using these algorithms for classification). I know that it is important to scale input features for neural networks (i.e. subtract values by the mean and divide by the standard deviation), but is there a need ensure input features are approximately normal when using neural networks for classification (like I would for linear models)?
