[site]: crossvalidated
[post_id]: 362038
[parent_id]: 
[tags]: 
Adverserial Verification of an XGboost Classifier

This paper proposes an algorithmic framework, predictor-verifier training, to train neural networks that are verifiable, i.e., networks that provably satisfy some desired input-output properties. The key idea is to simultaneously train two networks: a predictor network that performs the task at hand, e.g., predicting labels given inputs, and a verifier network that computes a bound on how well the predictor satisfies the properties being verified. My question is: How much if these techniques are generalizable to a generic classifier such as an XGboost (it's the ML algorithm of choice in my company for which I'd like to try the idea of adverserial model validation). Would appreciate any reference to a relevant work on the XGboost case.
