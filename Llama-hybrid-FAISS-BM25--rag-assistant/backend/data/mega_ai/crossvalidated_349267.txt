[site]: crossvalidated
[post_id]: 349267
[parent_id]: 347727
[tags]: 
Often a significance test is performed for the null hypothesis against an alternative hypothesis . This is when one-tailed versus two-tailed make a difference. For p-values this (two or one sided) does not matter! The point is that you select a criterium that only occurs a fraction $\alpha$ of the time when the null hypothesis is true. This is either two small pieces of both tails, or one big piece of one tail, or something else. Type I error rate is not different for one or two sided tests. On the other hand, for the power it matters . If your alternative hypothesis is asymmetric, then you'd wish to focus the criterium to reject the null hypothesis only on this tail/end; such that when the alternative hypothesis is true then you are less likely to not reject ("accept") the null hypothesis. If your alternative hypothesis is symmetric (you don't care to place more or less power on one specific side), and deflection/effect on both sides is equally expected (or just unknown/uninformed), then it is more powerful to use a two-sided test (you are not loosing 50% power for the tail that you are not testing and where you will make many type II errors). Type II error rate is different for one and two sided tests and depending on the alternative hypothesis as well. It is becoming more a bit like a Bayesian concept now when we start involving preconceptions about whether or not we expect an effect to fall on one side or on both sides, and when we wish to use a test (to see if we can falsify a null-hypothesis) to 'confirm' or make more probable something like an effect.
