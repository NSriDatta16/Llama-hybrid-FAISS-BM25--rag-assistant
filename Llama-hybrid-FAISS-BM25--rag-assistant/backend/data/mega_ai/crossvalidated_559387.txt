[site]: crossvalidated
[post_id]: 559387
[parent_id]: 
[tags]: 
Is the idea of "Zeno's Paradox" indirectly assumed in every statistical model?

I have more of a philosophical question : Is the idea of "Zeno's Paradox" indirectly assumed in every statistical model? In philosophy, there is an old concept first attributed to the Ancient Greek philosopher Zeno of Elea called "Zeno's Paradox". As I understand, this actually includes several similar paradoxes - each one of them being loosely related to the other. In short, they can be summarized as such: In other words - if a man running a 10 KM race, he first needs to run the first kilometer. Before he can the first kilometer, he must first run the first meter - and before he can run the first meter, he must first run centimeter. And of course, before he can run the first centimeter, he must run the first millimeter - and this is an endless cycle. But by this logic - shouldn't the runner (paradoxically) be stuck in the same position forever, since he has infinite denominations of a meter to complete? I have always wondered if this above paradox is implicitly assumed in statistical modelling - for example, if you take the decision boundary "learned" by any statistical model (e.g. random forest): Do we assume that if the covariate values of some data point (e.g. the black point in the second picture) are "so infinitesimally close" to another "neighboring" data point - Zeno's Paradox would "ensure" that the response value for both of these data points must be the same (i.e. "immobilize them")? For example, the points (0.543, 0.677, "Orange") and (0.543331, 0.677771, "Orange") are so similar - they "must" share the same response value? On the other hand, both of these points might suffer from the "Omitted Variable Bias" (OVB), and actually have differing values of other variables which make them different. Similarly, if two neighboring data points are "too close" (e.g. Euclidean Distance) to one another, do we assume that they are in essence the same point? I know on one hand this is a silly question, and on the other hand it's strikingly evident - but is this idea of "Zeno's Paradox" in the background of every statistical model, and thereby we have reasons to believe that Zeno's Paradox is fundamentally engrained within the nature of physical objects and phenomena and the universe itself? If the measurements of one data point infinitesimally digress away from the measurements of another data point - are they still the same data point? For example, is the likelihood of "infinitesimally different observations" the same? Using the R programming language, I showed an example where the likelihood of observing similar points is calculated (using the " dnorm() " function) given a Normal Distribution with Mean = 11 and Standard Deviation = 0.1 *: In the end, is Zeno's Paradox something so universally evident, that nature (and data produced from nature) can not escape this paradox? If two data points are very close to each other, do statistical models treat them as basically identical? *** Note**: I can provide the R code for this graph if someone is interested
