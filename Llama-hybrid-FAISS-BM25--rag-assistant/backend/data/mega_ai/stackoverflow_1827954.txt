[site]: stackoverflow
[post_id]: 1827954
[parent_id]: 
[tags]: 
Finding out how when google last crawled

I'd like to find out how current google's cached copy of a large set of pages is. I think I need to look in the logs for IP's, check to find user-agent "googlebot", then export a list that says each page and when it was last visited. I imagine this could be a cron job that runs weekly. If this is right, how would I write the script? If this is wrong, what would be a better way?
