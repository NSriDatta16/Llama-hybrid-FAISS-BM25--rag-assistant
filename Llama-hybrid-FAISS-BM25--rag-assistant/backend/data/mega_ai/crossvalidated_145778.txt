[site]: crossvalidated
[post_id]: 145778
[parent_id]: 
[tags]: 
Data-driven, high-dimensional feature selection strategies

I am working on a biomedical/healthcare data science problem. I have a dataset of 600 samples, ~6000 variables and class label as "positive" or "negative". I want to perform feature selection on this high-dimensional data. I want to know what are the best strategies to find which feature is most contributing here. Typically, I design a binary classifier (SVM, NB, RF or ANN) and then use information gain or RandomForest to assess the feature importance. Here, my variable space is ten-times more than my instances - hence am not comfortable with this approach. Is there any better strategy to reduce the feature space in a data-driven way?
