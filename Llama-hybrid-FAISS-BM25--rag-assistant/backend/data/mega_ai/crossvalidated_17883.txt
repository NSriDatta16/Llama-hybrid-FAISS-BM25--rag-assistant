[site]: crossvalidated
[post_id]: 17883
[parent_id]: 17877
[tags]: 
p*, the threshold below which we would reject the null hypothesis, is normally written as $\alpha$, and is known as the false-positive rate. A "false-positive" error is the error of rejecting the null hypothesis when it is actually true, and is also called a "Type-I" error. However, the interpretation of $\alpha$ must be performed with some care; as this is a frequentist test, it means that if you repeatedly performed the test a large number of times where the null hypothesis is true, the test would reject the null hypothesis a proportion $\alpha$ of the time. However this does not mean that the probability of having rejected a true null hypothesis in any particular instance of the trial is $\alpha$. No frequentist statistical test can do this, as it as particular events do not have a long run frequency and hence you cannot assign a frequentist probability to them. However, I think in this case, as you are repeatedly testing models, it is a bit like a quality control study, so the frequentist approach reasonable, and $\alpha$ is a reasonable answer to the question, because you are looking for the error rate of the statstical testing procedure , rather than the outcome of a particular test. If you are interested in the probability of having rejected the null hypothesis incorrectly in a given instance of the test, then you will need a Bayesian approach.
