[site]: crossvalidated
[post_id]: 364522
[parent_id]: 
[tags]: 
Validation set for early stopping

I learnt about validation for early stopping by taking the course , and I have several questions. Question about validation for early stopping: We split the dataset $D$ into a training set $G$ and a test set $T$. The training set $G$ is then split into a validation set $V$ and a smaller training set $G^-$. The trained model on $G^-$ is called $g^-$. The idea of early stopping with a validation set is 'to get a better estimate $\Bbb E_{val}(g^-)$ of a worse quantity $\Bbb E_{out}(g^-)$'. My question is after we get a satisfying $\Bbb E_{val}(g^-)$ thus stop training, do we simply forget about the validation set and calculate the $\Bbb E_{out}(g^-)$ on the test set? Question about cross-validation for early stopping: I learnt that CV can also be used for early stopping. The key is to treat the training iteration as a hyperparameter, so we just perform a grid search for this hyperparameter with CV as we usually do. At the end of the day, the training iteration that yields the smallest averaged validation error will be chosen. Do we actually do this in practice? I think this approach is costly.
