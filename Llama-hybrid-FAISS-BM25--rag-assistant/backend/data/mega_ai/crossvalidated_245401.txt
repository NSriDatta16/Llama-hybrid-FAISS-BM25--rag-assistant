[site]: crossvalidated
[post_id]: 245401
[parent_id]: 
[tags]: 
"normalising" scores for performance

First time poster, have had a browse of the open question forum but cant find an answer to my problem... I dont know if "normalising" is the correct term here... so be gentle... :-) I am required to generate a "score" for a team of managers, based around a list of different criteria. Each criteria ultimately gives a reasonably convenient score that can be expressed as a % So far so good. I had thought I could take an average of the % and be done. Key issue / problem for me here is that, of a total of 8 or so criteria, not all come in to play for each manager. So, for managers with less criteria in play, any low scores have a greater impact than for managers with more criteria in play. For example: Manager a criteria 1: 100% Criteria 2: 100% Criteria 3: 75% Criteria 4: 100% Average score: 93.75% Manager b criteria 1: 100% Criteria 2: 100% Criteria 3: 75% Criteria 4: n/a Average score: 91.66% Ultimately meaning, manager b is more negatively impacted for making the same error. This scoring system will be used to generate bonus scores - and its a hugely contentious topic. What options do I have for correcting this without giving "manager b" a free 100% for criteria 4? Thanks in advance!
