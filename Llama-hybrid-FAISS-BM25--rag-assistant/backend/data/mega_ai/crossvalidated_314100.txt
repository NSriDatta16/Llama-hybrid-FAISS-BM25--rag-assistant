[site]: crossvalidated
[post_id]: 314100
[parent_id]: 
[tags]: 
How can I calculate the SD of a Gaussian obtained from sampling a binomial distribution

I need to simulate some antibody labeling scenarios. To keep it non-field specific, I'll talk in terms of fruit instead of nanobodies though. Let's say I have an infinite supply of fruit. 70% of this supply are apples. If I now sample this population an infinite amount of times, with a sample size of 24, I should get 24*0.7 apples on average in my samples. The distribution of fruit in these samples can (I think) be represented with a Gaussian distribution. My question is, is it possible to calculate the standard deviation of this distribution from only these two parameters? I think it should be, but have no idea how to do it. Cheers!
