[site]: datascience
[post_id]: 88183
[parent_id]: 88164
[tags]: 
The ROC-AUC curves are used to find the best threshold that optimizes True Positive Rate vs False Positive Rate . Using it in a K-Fold cross-validation is a good practice to determine the best threshold to use. Then, your final test is here to validate that you did not overfit on some hyperparameters, including this threshold. So ROC-AUC must not be used again in final test . You should compare the results of your final test with the same threshold used in your cross-validation. Hope it helps. Note on threshold (EDIT): The threshold to optimize could be the threshold to use in a binary classification problem that outputs probabilities (for instance, output of a sigmoid or a logistic regression). In that case, various threshold settings gives various the model's predictions ( FPR , TPR ), and so is built the ROC curve. You could read further on sklearn guide page .
