[site]: crossvalidated
[post_id]: 240629
[parent_id]: 239873
[tags]: 
A common approach to dimensionality reduction is to perform Principal Components Analysis (PCA) . Let's say you have some vector $\mathbf{x}$. Instead of a basis $\mathbf{u}_1 = \begin{bmatrix} 1 \\ 0 \\ 0 \\ \cdots \end{bmatrix}$, $\mathbf{u}_2 = \begin{bmatrix} 0 \\ 1 \\ 0 \\ \cdots \end{bmatrix}$, etc..., the idea is to find a new basis : $\hat{\mathbf{u}}_1, \hat{\mathbf{u}}_2, \ldots$ such that the first dimension captures the most variation, the second dimension captures the second most etc... For example, I've seen this done with liquidity in finance. People have a sense of what liquidity is, but there's no single measure (or even clean definition). One approach to building a single, rough measure from multiple liquidity measures is to perform PCA and call the first principal component a proxy for liquidity. How reasonable this approach is depends on what you're trying to do and the specific problem at hand. In some sense, this is related to lossy compression: it can work surprisingly well, but if you try to approximate an image or song with too low a dimension space, what you get may not resemble the original for any practical purpose.
