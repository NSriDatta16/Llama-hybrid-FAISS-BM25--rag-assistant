annot be the solution to the scalability problem ... The problem is that programmers introduce too many hidden assumptions in the robot's code. The proposed solutions are to have the agent exploit the inherent physics of its environment, to exploit the constraints of its niche, and to have agent morphology based on parsimony and the principle of Redundancy. Redundancy reflects the desire for the error-correction of signals afforded by duplicating like channels. Additionally, it reflects the desire to exploit the associations between sensory modalities. (See redundant modalities). In terms of design, this implies that redundancy should be introduced with respect not only to one sensory modality but to several. It has been suggested that the fusion and transfer of knowledge between modalities can be the basis of reducing the size of the sense data taken from the real world. This again addresses the scalability problem. Principle of parallel, loosely-coupled processes: An alternative to hierarchical methods of knowledge and action selection. This design principle differs most importantly from the Sense-Think-Act cycle of traditional AI. Since it does not involve this famous cycle, it is not affected by the frame problem. Principle of sensory-motor coordination: Ideally, internal mechanisms in an agent should give rise to things like memory and choice-making in an emergent fashion, rather than being prescriptively programmed from the beginning. These kinds of things are allowed to emerge as the agent interacts with the environment. The motto is, build fewer assumptions into the agent's controller now, so that learning can be more robust and idiosyncratic in the future. Principle of ecological balance: This is more a theory than a principle, but its implications are widespread. Its claim is that the internal processing of an agent cannot be made more complex unless there is a corresponding increase in complexity of the motors, limbs, and sensors of the agent. In other words, the extra complexity added to the brain of a simple robot will not create any discernible change in its behavior. The robot's morphology must already contain the complexity in itself to allow enough "breathing room" for more internal processing to develop. Value principle: This was the architecture developed in the Darwin III robot of Gerald Edelman. It relies heavily on connectionism. Critical responses Traditionalist response to local environment claim A traditionalist may argue that objects may be used to aid in cognitive processes, but this does not mean they are part of a cognitive system. Eyeglasses are used to aid in the visual process, but to say they are a part of a larger system would completely redefine what is meant by a visual system. However, supporters of the embodied approach could make the case that if objects in the environment play the functional role of mental states, then the items themselves should not be counted among the mental states. Lars Ludwig explores mind extension further outlining its role in technology. He proposes a cognitive theory of 'extended artificial memory', which represents a theoretical update and extension of the memory theories of Richard Semon. See also References Further reading Braitenberg, Valentino (1986). Vehicles: Experiments in Synthetic Psychology. Cambridge, MA: The MIT Press. ISBN 0-262-52112-1 Brooks, Rodney A. (1999). Cambrian Intelligence: The Early History of the New AI. Cambridge, MA: The MIT Press. ISBN 0-262-52263-2 Edelman, G. Wider than the Sky (Yale University Press, 2004) ISBN 0-300-10229-1 Fowler, C., Rubin, P. E., Remez, R. E., & Turvey, M. T. (1980). Implications for speech production of a general theory of action. In B. Butterworth (Ed.), Language Production, Vol. I: Speech and Talk (pp. 373â€“420). New York: Academic Press. ISBN 0-12-147501-8 Lenneberg, Eric H. (1967). Biological Foundations of Language. John Wiley & Sons. ISBN 0-471-52626-6 Pfeifer, R. and Bongard J. C., How the body shapes 