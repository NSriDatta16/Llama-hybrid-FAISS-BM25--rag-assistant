[site]: datascience
[post_id]: 120803
[parent_id]: 
[tags]: 
How to Fine-Tune Multilingual Translational Transformer Models

I'm trying to fine-tune facebook/nllb-200-distteled-600M model on my english to arabic dataset, but the results are so bad I'm expecting there should be something wrong with defining the model and tokenizer, or maybe preprocessing the data. My code the following: from transformers import AutoTokenizer, AutoModelForSeq2SeqLM import pandas as pd tokenizer = AutoTokenizer.from_pretrained("facebook/nllb-200-distilled-600M") model = AutoModelForSeq2SeqLM.from_pretrained("facebook/nllb-200-distilled-600M") dff = pd.read_csv('/content/data.csv') """ # Formatting Data """ source = dff['eng_Latn'].values.tolist() target = dff['arb_Arab'].values.tolist() from sklearn.model_selection import train_test_split max = 512 X_train, X_val, y_train, y_val = train_test_split(source, target, test_size=0.2) X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=max, return_tensors="pt") y_train_tokenized = tokenizer(y_train, padding=True, truncation=True, max_length=max, return_tensors="pt") X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=max, return_tensors="pt") y_val_tokenized = tokenizer(y_val, padding=True, truncation=True, max_length=max, return_tensors="pt") import torch class ForDataset(torch.utils.data.Dataset): def __init__(self, inputs, targets): self.inputs = inputs self.targets = targets def __len__(self): return len(self.targets) def __getitem__(self, index): input_ids = torch.tensor(self.inputs["input_ids"][index]).squeeze() target_ids = torch.tensor(self.targets["input_ids"][index]).squeeze() return {"input_ids": input_ids, "labels": target_ids} train_dataset = ForDataset(X_train_tokenized, y_train_tokenized) test_dataset = ForDataset(X_val_tokenized, y_val_tokenized) from transformers import DataCollatorForSeq2Seq data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors="pt") """# Metrics""" import evaluate metric = evaluate.load("sacrebleu") import numpy as np def postprocess_text(preds, labels): preds = [pred.strip() for pred in preds] labels = [[label.strip()] for label in labels] return preds, labels def compute_metrics(eval_preds): preds, labels = eval_preds if isinstance(preds, tuple): preds = preds[0] decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True) labels = np.where(labels != -100, labels, tokenizer.pad_token_id) decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True) decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels) result = metric.compute(predictions=decoded_preds, references=decoded_labels) result = {"bleu": result["score"]} prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds] result["gen_len"] = np.mean(prediction_lens) result = {k: round(v, 4) for k, v in result.items()} return result """# Training""" from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer training_args = Seq2SeqTrainingArguments( output_dir="mymodel", evaluation_strategy="epoch", save_strategy = 'epoch', learning_rate=2e-5, per_device_train_batch_size=16, per_device_eval_batch_size=16, weight_decay=0.01, save_total_limit=3, num_train_epochs=20, predict_with_generate=True, load_best_model_at_end=True ) trainer = Seq2SeqTrainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=test_dataset, tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics, ) trainer.train() """ # Testing """ trainer.save_model('finalmodel') from transformers import pipeline mymodel = AutoModelForSeq2SeqLM.from_pretrained("./finalmodel") translator = pipeline ('translation' , model = mymodel, tokenizer=tokenizer, src_lang = 'eng_Latn', tgt_lang= 'arb_Arab') print (translator('suddenly, we were attacked ')) I previously trained the helsinki model using huggingface autotrain tool on smaller data and I got better results. is it the data or the training process? Does the tokenizer and model know which language I'm using based on the columns names, or do I need to define that? P.S. I'm new to NLP, so, much of my code is copied.
