[site]: stackoverflow
[post_id]: 747315
[parent_id]: 745190
[tags]: 
Paul. There's two parts to your question. First, why are writes slow? When you say you have large databases, you may want to clarify that with some numbers. The Microsoft teams have demonstrated multi-terabyte loads in less than an hour, but of course they're using high-end gear and specialized data warehousing techniques. I've been involved with data warehousing teams that regularly loaded so much data overnight that the transaction log drives had to be over a terabyte just to handle the quick bursts, but not a terabyte per hour. To find out why writes are slow, you'll want to compare your load methods to data warehousing techniques. For example, have you tried using staging tables? Table partitioning? Data and log files on different arrays? If you're not sure where to start, check out my Perfmon tutorial to measure your system looking for bottlenecks: http://www.brentozar.com/archive/2006/12/dba-101-using-perfmon-for-sql-performance-tuning/ Second, how do you scale out? You asked how to set up multiple database servers so that one handles the bulk load while others handle reads and some writes. I would heavily, heavily caution against taking the multiple-servers-for-writes approach because it gets a lot more complicated quickly, but using multiple servers for reads is not uncommon. The easiest way to do it is with log shipping: every X minutes, the primary server takes a transaction log backup and then that log backup is applied to the read-only reporting server. There's some catches with this - the data is a little behind, and the restore process has to kick all connections out of the database to apply the restore. This can be a perfectly acceptable solution for things like data warehouses, where the end users want to keep running their own reports while the new day's data loads. You can simply not do transaction log restores while the data warehouse is loading, and the users can maintain connections the whole time. To help find out what solution is right for you, consider adding the following to your question: The size of your database (GB/TB in size, # of millions of rows in the largest table that's having the writes) The size of your server & storage (a box with 10 drives has different solutions available than a box hooked up to a SAN) The method of loading data (is it single-record inserts, are you using bulk load, are you using table partitioning, etc)
