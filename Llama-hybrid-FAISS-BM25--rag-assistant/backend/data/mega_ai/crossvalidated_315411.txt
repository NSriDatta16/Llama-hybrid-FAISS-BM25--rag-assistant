[site]: crossvalidated
[post_id]: 315411
[parent_id]: 315402
[tags]: 
One can consider multi-layer perceptron (MLP) to be a subset of deep neural networks (DNN), but are often used interchangeably in literature. The assumption that perceptrons are named based on their learning rule is incorrect. The classical "perceptron update rule" is one of the ways that can be used to train it. The early rejection of neural networks was because of this very reason, as the perceptron update rule was prone to vanishing and exploding gradients, making it impossible to train networks with more than a layer. The use of back-propagation in training networks led to using alternate squashing activation functions such as tanh and sigmoid . So, to answer the questions, the question is. Is a "multi-layer perceptron" the same thing as a "deep neural network"? MLP is subset of DNN. While DNN can have loops and MLP are always feed-forward, i.e., A multi layer perceptrons (MLP)is a finite acyclic graph why is this terminology used? A lot of the terminologies used in the literature of science has got to do with trends of the time and has caught on. How broad is this terminology? Would one use the term "multi-layered perceptron" when referring to, for example, Inception net? How about for a recurrent network using LSTM modules used in NLP? So, yes inception, convolutional network, resnet etc are all MLP because there is no cycle between connections. Even if there is a shortcut connections skipping layers, as long as it is in forward direction, it can be called a multilayer perceptron. But, LSTMs, or Vanilla RNNs etc have cyclic connections, hence cannot be called MLPs but are a subset of DNN. This is my understanding of things. Please correct me if I am wrong. Reference Links: https://cs.stackexchange.com/questions/53521/what-is-difference-between-multilayer-perceptron-and-multilayer-neural-network https://en.wikipedia.org/wiki/Multilayer_perceptron https://en.wikipedia.org/wiki/Perceptron http://ml.informatik.uni-freiburg.de/former/_media/teaching/ss10/05_mlps.printer.pdf
