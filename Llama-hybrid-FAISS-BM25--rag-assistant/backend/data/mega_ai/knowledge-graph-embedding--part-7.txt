 dimension d × 3 {\displaystyle d\times 3} without reshaping and passes it to series of convolutional filter of size 1 × 3 {\displaystyle 1\times 3} . This result feeds a dense layer with only one neuron that produces the final score. The single final neuron makes this architecture as a binary classifier in which the fact could be true or false. A difference with ConvE is that the dimensionality of the entities is not changed. Capsule neural networks This family of models uses capsule neural networks to create a more stable representation that is able to recognize a feature in the input without losing spatial information. The network is composed of convolutional layers, but they are organized in capsules, and the overall result of a capsule is sent to a higher-capsule decided by a dynamic process routine. CapsE: CapsE implements a capsule network to model a fact ( h , r , t ) {\displaystyle (h,r,t)} . As in ConvKB, each triple element is concatenated to build a matrix [ h ; r ; t ] {\displaystyle {\ce {[h;{\mathcal {r}};t]}}} and is used to feed to a convolutional layer to extract the convolutional features. These features are then redirected to a capsule to produce a continuous vector, more the vector is long, more the fact is true. Recurrent neural networks This class of models leverages the use of recurrent neural network. The advantage of this architecture is to memorize a sequence of fact, rather than just elaborate single events. RSN: During the embedding procedure is commonly assumed that, similar entities has similar relations. In practice, this type of information is not leveraged, because the embedding is computed just on the undergoing fact rather than a history of facts. Recurrent skipping networks (RSN) uses a recurrent neural network to learn relational path using a random walk sampling. Model performance The machine learning task for knowledge graph embedding that is more often used to evaluate the embedding accuracy of the models is the link prediction. Rossi et al. produced an extensive benchmark of the models, but also other surveys produces similar results. The benchmark involves five datasets FB15k, WN18, FB15k-237, WN18RR, and YAGO3-10. More recently, it has been discussed that these datasets are far away from real-world applications, and other datasets should be integrated as a standard benchmark. Libraries KGE on GitHub MEI-KGE on GitHub Pykg2vec on GitHub DGL-KE on GitHub PyKEEN on GitHub TorchKGE on GitHub AmpliGraph on GitHub OpenKE on GitHub scikit-kge on GitHub Fast-TransX on GitHub MEIM-KGE on GitHub DICEE on GitHub See also Knowledge graph Embedding Machine learning Knowledge base Knowledge extraction Statistical relational learning Representation learning Graph embedding References External links Open Graph Benchmark - Stanford WordNet - Princeton