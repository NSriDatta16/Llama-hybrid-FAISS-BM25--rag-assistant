[site]: crossvalidated
[post_id]: 347548
[parent_id]: 
[tags]: 
Trending time series data normalization for Deep Learning

I'm replicating following article Financial Time Series Prediction using Deep Learning and I'm stuck with data normalization. In chapter 5.1 in the second paragraph in the last sentense the authors claims "Each input sequence was filtered by five taps long, moving uniform averaging, and then normalized by reducing the mean, and dividing by its standard deviation" I have several questions, specifically under section [5.1] on page 10 : 1) What do they mean by " Each input sequence was filtered by five taps long, moving uniform averaging "? I do not understand this completely 2) "...then normalized by reducing the mean, and dividing by its standard deviation" . How do they normalize nonstationary trending price data? They train an ANN with SPY ETF minute prices on 2001-2013 time period and use 60 lags to predict price trends, so how do they compute mean and std? I guess they compute mean and std for each sample that is on 60 lags and then normalize each sample sequence individually. If this's the way they do it then how to normalize test data?
