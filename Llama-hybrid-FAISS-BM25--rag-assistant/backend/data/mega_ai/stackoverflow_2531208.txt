[site]: stackoverflow
[post_id]: 2531208
[parent_id]: 2478921
[tags]: 
To make sure your package are not messing up with the same files, you could just create an empty file called just like the filename but with another extension (like mydata.csv.being_processes ) and make sure your Data Flow Task is running only on files that don't have such file. This acts as a lock. Of course you could change the way you're scheduling your jobs but often - when we encounter such an issue - it's because we got no leverage on those things :)
