[site]: crossvalidated
[post_id]: 422257
[parent_id]: 422225
[tags]: 
To simplify the discussion here, suppose you have $k = 3$ groups instead of six groups. If subjects are assigned at random into the three groups, then you would expect the 'Before' scores to be about the same in the three groups. Even so, you might want to test for that as you begin the study. Suppose the numbers of subjects in the three groups are 50, 60, and 55, respectively. Here are data based on three equal population means, generated in R. I denote the 'Before' scores by $X_{ij}$ 's ( $i$ for group, $j$ for subject within group). x1 = rnorm(50, 100, 15) x2 = rnorm(60, 100, 15) x3 = rnorm(55, 100, 15) mean(x2); mean(x2); mean(x3) [1] 98.5924 [1] 98.5924 [1] 99.94643 Do 'Before' score differ among groups? The sample means differ slightly, but not significantly, among the three groups. A Welch one-way ANOVA confirms this; the P-value is about 0.75: x = c(x1,x2,x3) g = as.factor(rep(1:3, times=c(50,60,55))) oneway.test(x ~ g) One-way analysis of means (not assuming equal variances) data: x and g F = 0.2891, num df = 2.00, denom df = 105.11, p-value = 0.7495 Do Improvement scores differ among Groups? Next, when you have the After scores, it makes sense to ask whether the treatment had affected the three groups in different ways. You can use the differences After - Before to explore that: I denote the 'After' scores by $Y_{ij}$ 's, and the differences as $D_{ij} = Y_{ij} - X_{ij}.$ My data have some distinct differences among the three average differences $\bar D_i$ 's d1 = rnorm(50, 2, 2); d2 = rnorm(60, 5, 2); d3 = rnorm(55, 6, 3) mean(d1); mean(d2); mean(d3) [1] 1.942013 [1] 5.131513 [1] 6.266347 On the boxplot below the three means $\bar D_i,\, i = 1,2,3,$ are shown as red dots (nearly the same as the three medians). Notches in the sides of the boxes are nonparametric confidence intervals (CIs), calibrated for comparing two groups at a time. Nonoverlapping CIs may indicate significant differences. boxplot(d ~ g, notch=T, col="skyblue2", pch=19) d.avg = c(mean(d1), mean(d2), mean(d3)) points(1:3, d.avg, pch=19, col="red") A one-way ANOVA, on the differences, shows that the treatment had (highly) significantly varying effects on different groups The P-value is near $0.$ oneway.test(d ~ g) One-way analysis of means (not assuming equal variances) data: d and g F = 51.843, num df = 2.00, denom df = 100.25, p-value = 3.476e-16 Ad hoc tests can be used to explore the pattern of differences among groups. It is safe to assume Groups 1 and 3 differ. We use Welch two-sample t tests to compare Group 1 with Group2 and Group 2 with Group 3. t.test(d1, d2) $p.val [1] 4.245742e-14 t.test(d2, d3)$ p.val [1] 0.01958676 In order to avoid 'false discovery' doing several tests on the same data, it is best to use the Bonferroni method , which requires somewhat lower P-values in order to claim significance. There is no problem declaring significance above. But if you are going to compare groups with adjacent mean improvements among six Groups, you should not claim significance unless P-values are below about 1%. You could do a one-way ANOVA on the 'After` scores, but it seems to me that your primary focus should be on average improvement scores $(\bar D_1 =1.94, \bar D_2= 5.13, \bar D_3 = 6.27).$ Possible one-sample test. Because the smallest improvement was in Group 1, you may want to do a formal one-sample t test on the $D_{1j}$ 's to see if improvements there are significantly different from 0. The test confirms that they are. t.test(d1) One Sample t-test data: d1 t = 6.821, df = 49, p-value = 1.256e-08 alternative hypothesis: true mean is not equal to 0 95 percent confidence interval: 1.369861 2.514164 sample estimates: mean of x 1.942013 Notes: (1) If you do the last test (for Group 1 improvement) using $X_{1j},$ and $Y_{1j}$ (instead of $D_{1j})$ , then be sure to do a 'paired' t test. (2) Of course your real data may differ in important ways from my fake data created just for illustration. If difficulties arise as you analyze your data, please leave a Comment, and maybe someone can help. (3) You briefly mentioned the possibility of a 3-way ANOVA. That would be possible, but not entirely straightforward. The three factors would be Group (1, 2, ..., 6), Time (Before, After), and Subject ( $j = 1, 2, \dots, n_i).$ You would have to make sure subjects are 'random' and 'nested within treatments'. Also, you might find that 'After' scores are more variable than 'Before' scores. If so, you would have to diagnose what difficulty that is causing. Given your stated objectives I don't think these complications are worth the trouble.
