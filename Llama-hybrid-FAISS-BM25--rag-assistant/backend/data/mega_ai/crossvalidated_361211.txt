[site]: crossvalidated
[post_id]: 361211
[parent_id]: 361197
[tags]: 
Yes, you do have to save the old state a second time, or however many times you reject a proposal. As you say, Metropolis-Hastings is a Markov chain Monte Carlo (MCMC) method. Given some distribution of interest $\pi$ (in your case $\pi(z)\propto f(z)\mathbf{1}_{z\in B}$), you simulate a Markov chain that is designed to have $\pi$ as its invariant distribution. That is, $\pi$ is the limiting distribution of the chain. Eventually, if you run the chain long enough, the draws in the chain are statistically indistinguishable from draws sampled from $\pi$. A feature of the MH algorithm is that sometimes you reject proposals, so the chain will contain duplicates. And the possibility of duplicates is part of the algorithm . A sampling scheme where you generate a MH chain and then discard any duplicates will not necessarily have the desired statistical properties. $\pi$ may not be the invariant distribution any longer.
