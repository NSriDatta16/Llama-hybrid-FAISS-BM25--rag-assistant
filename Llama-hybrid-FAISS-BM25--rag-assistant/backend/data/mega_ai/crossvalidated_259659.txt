[site]: crossvalidated
[post_id]: 259659
[parent_id]: 
[tags]: 
Proper loss function

I'm working with a dataset dealing with product sales in a supermarket. I'm using a large neural network (with large I mean I have many inputs compared to the number of training instances) to forecast the sales, but I would like to reduce the input dimension, using an autoencoder . Let me describe the input data for one product (in my network I forecast $m$ products alltogether and I have input data associated to each one of them): $0/1$ flag, but $0$ for most training istances, indicating stockout, basically if $1$ the product is not available and the number of sales for that product on that day will be $0$. count data $X \in \big\{0,1,\dots,m\big\}$, but 0 for most training istances, representing the number of promotions active on that product that day. Real number representing the product price, but $X_i \in {x_1,x_2,..,x_k}$ i.e. it assumes at most k different values over the training period for almost all products. As I said before, I have these 3 inputs multiplied by $m$ number of products, so $3m$ inputs. I want to reduce the size of the input, by using an autoencoder. This means that my inputs are also my outputs and I would like to encode my input in a lower dimensional space and then decode it and reconstruct it. If I accomplish that I would be able to reduce the size of my forecasting network . Now, I don't have a clue about which loss measure I should use for such data and I kindly ask for your help . One idea I had was to transform the 2 categorical(ordinal) inputs into $k$ dummy variables (where $k$ is the number of levels), in that case it's like a multilabel classification problem, so that I would use a binary crossentropy loss function and sigmoids on the output layer.
