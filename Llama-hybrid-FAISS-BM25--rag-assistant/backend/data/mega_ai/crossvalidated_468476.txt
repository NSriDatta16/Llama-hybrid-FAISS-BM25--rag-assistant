[site]: crossvalidated
[post_id]: 468476
[parent_id]: 468475
[tags]: 
K,Q and V are representations of encoder and decoder states and vary according to problem. The weight matrices correspond to the linear transformation of the states.They are trained as a part of the whole neural network block. This blog might be helpful. https://medium.com/lsc-psd/introduction-of-self-attention-layer-in-transformer-fc7bff63f3bc
