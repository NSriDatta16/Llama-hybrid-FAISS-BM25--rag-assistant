[site]: crossvalidated
[post_id]: 572713
[parent_id]: 
[tags]: 
influence of bayesian priors: rjags and categorical variables

I am a bad statistician and new using Bayesian tools, and I am learning how to make regressions with rjags . While toying, I came across a situation I do not fully understand, and I would need some help from the community. the example: library(data.table) library(ggplot2) library(rjags) library(magrittr) global_slope % rbindlist() It creates a dataset with a classical Simpson paradox: ggplot(df,aes(x,y,color = as.factor(ID)))+ geom_point() I can use mixed effect regression, but in a first step I just wanted to perform a regression adjusted for the ID categorical variable: lm(y ~ x + ID,data = df) %>% summary() lm(formula = y ~ x + ID, data = df) Residuals: Min 1Q Median 3Q Max -3.1638 -0.7172 -0.0060 0.6544 2.9827 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 3.32405 0.16884 19.687 Now I want to do the same with rjags . I do the following: model_code $ID_num, y = df$ y, x = df$x) model This does not give the expected results: 1. Empirical mean and standard deviation for each variable, plus standard error of the mean: Mean SD Naive SE Time-series SE alpha 2.38553 0.20216 0.0045205 0.023001 bID[1] 0.00000 0.00000 0.0000000 0.000000 bID[2] 4.94015 0.05910 0.0013216 0.003490 bID[3] 2.45937 0.22747 0.0050864 0.009988 bID[4] 4.42102 0.24729 0.0055295 0.012415 bID[5] -1.11753 0.27499 0.0061490 0.022423 bID[6] 3.17433 0.23565 0.0052692 0.011053 bID[7] 0.09581 0.24132 0.0053960 0.014685 bID[8] 3.90678 0.25029 0.0055967 0.012346 bID[9] 0.71809 0.23663 0.0052912 0.012584 bID[10] 1.66045 0.23142 0.0051747 0.011332 beta 0.33399 0.02955 0.0006607 0.003277 sigma 1.31688 0.04148 0.0009275 0.001146 I realized that it was because the prior I gave for the categorical variable ID is too narrow. If I replace bID[j] ~ dunif(-5,5) by bID[j] ~ dunif(-100,100) in the JAGS model, then I find results similar to those of the frequentist lm : 1. Empirical mean and standard deviation for each variable, plus standard error of the mean: Mean SD Naive SE Time-series SE alpha 3.292 0.16957 0.0037918 0.0194214 bID[1] 0.000 0.00000 0.0000000 0.0000000 bID[2] 17.622 0.66571 0.0148857 0.2021913 bID[3] 8.805 0.35826 0.0080109 0.0892269 bID[4] 15.123 0.57542 0.0128667 0.1739097 bID[5] -2.025 0.22548 0.0050420 0.0194497 bID[6] 10.969 0.43419 0.0097089 0.1219498 bID[7] 2.107 0.21089 0.0047156 0.0170001 bID[8] 13.156 0.51186 0.0114454 0.1450026 bID[9] 4.165 0.24613 0.0055036 0.0381072 bID[10] 6.545 0.29735 0.0066490 0.0548702 beta -0.972 0.07282 0.0016284 0.0193806 sigma 1.027 0.03268 0.0007307 0.0009942 So the question: I was expecting that even if the priors are wrong or too narrow (my bID[j] ~ dunif(-5,5) ), the model would at the end converge to the expected solution if it has enough iterations, as each step posterior distribution os based on the data. But it seems it does not. The MCMC seems to have converged (to the wrong result), and increasing the number of burning does not alter the result. Why is that ? Do the priors constrain the possible results whatever the number of iterations ? Or is there a kind of local minima reached before the actual true result ?
