[site]: datascience
[post_id]: 26372
[parent_id]: 26371
[tags]: 
In general, it's never a bad idea to use logistic regression as a first stab at a classification problem. If it doesn't work great, it at least gives you a baseline. Random forest would probably work well here as well. Generally, random forests aren't considered very interpretable, but they're actually pretty interpretable if you're interested in understanding the decision process for a single prediction , which it sounds like would be sufficient for your needs here (i.e., the model can tell you a student is likely to perform a certain way because of their behavior on specific tests). A random forest will probably also handle missing data better, which might be useful to you since I'm guessing not all students took the same tests. Another option you can try here which handles null data extremely well and would also be simple for inference, is naive bayes.
