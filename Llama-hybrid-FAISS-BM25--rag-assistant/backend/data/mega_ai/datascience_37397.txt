[site]: datascience
[post_id]: 37397
[parent_id]: 30829
[tags]: 
Based on my understanding, this seems to boil down to a multi-class classification problem (each set/sequence of hand gestures eventually corresponding to a word/symbol). An RNN/LSTM/GRU architecture is a great place to start, but will be computationally expensive and rather slow to train. However, whether you absolutely need one or more of these depends on how your data is structured, and whether you can get away with treating your images as a set, rather than a sequence. Here are some potential ideas: Start by setting up a CNN layer for each "RUN_*" folder, along with dropout and/or flattening between each layer. Start by setting up a single long vector representing all stages of the sequence, then add a couple of layers of CNNs, also with dropout and/or flattening . This will take some exploration and tuning on your end to see what works the best, and you will need to choose with evaluation metrics you want to optimize for (e.g. precision/recall) The reason I'm suggesting a CNN is because, in certain cases, CNNs can provide similar performance to a recurrent model, but at a fraction of the cost. Unfortunately, it's tough to tell with little to no information about you data.
