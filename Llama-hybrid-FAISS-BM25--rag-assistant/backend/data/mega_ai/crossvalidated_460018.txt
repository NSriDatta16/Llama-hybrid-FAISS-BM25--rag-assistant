[site]: crossvalidated
[post_id]: 460018
[parent_id]: 
[tags]: 
Keras Neural Network: use loss from one output in the loss of the other output

I would like to use the loss from one of my NN auxiliary outputs as part of the loss for the other output. $L($ total $) = L($ main output $) - \lambda L($ auxiliary output $)$ I am unsure how to access the auxiliary loss when creating a custom loss function, as shown in the "# define custom loss" section in my code: # multi-ouput NN from tensorflow.keras.layers import Input, Dense from tensorflow.keras.models import Model import tensorflow.keras.backend as K import numpy as np # initialize input tensor input = Input(shape=(128,), name='input') # tell Keras the shape of the input per batch # initialize passes encoded_data = Dense(64, activation='relu', name='encoded_data')(input) classified_data = Dense(3, activation='softmax', name='classified_data')(encoded_data) predicted_data = Dense(128, activation='softmax', name='predicted_data')(encoded_data) # define model with one input and two outputs model = Model(inputs=input, outputs=[classified_data, predicted_data]) # define custom loss def custom_loss(layer): # create loss that incorporate loss from classification layer, lambda = 0.1 def loss(y_true,y_pred): return K.mean(K.categorical_crossentropy(y_true, y_pred) - (0.1)*K.categorical_crossentropy(layer), axis=-1) # Return a function return loss # compile the model model.compile(optimizer='adam', loss={'classified_data': 'categorical_crossentropy', 'predicted_data': custom_loss(classified_data)}) Any ideas? I have used this as a guide for creating custom losses of this type, but can't quite get it to work: https://towardsdatascience.com/advanced-keras-constructing-complex-custom-losses-and-metrics-c07ca130a618
