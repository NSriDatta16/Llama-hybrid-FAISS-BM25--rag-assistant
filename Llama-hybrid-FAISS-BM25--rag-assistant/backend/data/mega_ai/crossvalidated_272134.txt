[site]: crossvalidated
[post_id]: 272134
[parent_id]: 272121
[tags]: 
If you read: Validation and updating of predictive logistic regression models: a study on sample size and shrinkage ( pdf ) The same author explains in a little bit of detail. The recalibration approach is to define i linear predictor, $Z$ as $Z = \tilde{\alpha}_{model} + \tilde{\beta}_1 X_1 + ... + \tilde{\beta}_p X_p$ and to use this linear predictor in a regression model: $\hat{Y}_{cal} = \hat{\alpha}_{overall} + \hat{\beta}_{overall}$. If no recalibration is required, $\hat{\alpha}_{overall} = 0 $ and $\hat{\beta}_{overall}$ = 1. If they significantly differ from this case then there is a need to recalibrate the model. Recalibrated regression coefficients can be calculated as $\hat{\beta}_{cal} = \hat{\beta}_{overall} \tilde{\beta}_i$. One could say that the recalibrated model borrows the relative effects (ratios) of the regression coefficients from the model in the training set. The case which you describe in your question arises when $\hat{\beta}_{overall} = 1$, i.e. $\hat{\alpha}_{overall} | \hat{\beta}_{overall}=1$ where the slope is set to unity by entering $Z$ as an offset term to the model. Predicted risks are on average understimated if $\hat{\alpha}_{overall} | \hat{\beta}_{overall}=1>0$ and overestimated if $\hat{\alpha}_{overall} | \hat{\beta}_{overall}=1 Updating of the intercept and fixing $\hat{\beta}_{overall}$ to one is a simple recalibration method that intends to correct calibration at the macro scale, i.e. to make the average predicted probability equal to the observed overall event rate.
