[site]: crossvalidated
[post_id]: 385008
[parent_id]: 
[tags]: 
Difference between averaging and ignoring the partial dependencies?

This question sparks from model interpretation/visualization. To graph the dependency of a function with >2 arguments, one often needs to ignore or average out some arguments. Problem set Hastie, Tibshirani & Friedman (Elements of Statistical Learning, 2001) p.370 define a partial dependence of a mapping $f(X)=f(X_S, X_C)$ to a subset of its arguments $X_S$ by averaging the $X_C$ out: $$\bar{f}_S (X_S)= \mathrm{E}_{X_C} \, f(X_S, X_C)$$ and state explicitly that this function does not describe the effect of $X_S$ on f ignoring the effect of $X_C$ on $f$ , but $\tilde{f}_S$ does: $$ \tilde{f}_S (X_S) = \mathrm{E}( f(X_S, X_C) | X_S) $$ Questions Am I correct in my understanding: The first equation starts with an "existing" function $f(X_S, X_C)$ and then removes the dependency on $X_C$ by averaging over it. The second equation describes the concept of creating an approximating $\tilde{f}_S$ , such that for each "value" of $X_S$ the approximation $\tilde{f}_S$ is close to $f(X_S, X_C)$ . What is the mathematical difference between the two equations? The first expectation integrates only over the $X_C$ dimensions, whereas the second one integrates over all dimensions, right? Is it possible to get an analytical sense of the difference of both? Is it possible to calculate the second equation in practice for some dataset?
