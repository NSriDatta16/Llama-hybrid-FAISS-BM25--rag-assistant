[site]: crossvalidated
[post_id]: 161580
[parent_id]: 161564
[tags]: 
I suggest that you take the first approach. With the second approach, not only you might lose some information, but you can also introduce biases in the dataset by categorizing numerical features. To make the first approach work, you need to pre-process all the features once you create dummy variables, which includes: Centering and scaling Transformation to remove skewness in data Remove highly correlated features Remove features that have near-zero variance To prevent overfitting, you can use penalized logistic regression model.
