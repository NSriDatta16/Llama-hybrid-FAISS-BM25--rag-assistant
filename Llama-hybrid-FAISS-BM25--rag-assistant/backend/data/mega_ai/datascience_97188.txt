[site]: datascience
[post_id]: 97188
[parent_id]: 66207
[tags]: 
Here're my understandings: (1)[CLS] appears at the very beginning of each sentence, it has a fixed embedding and a fix positional embedding, thus this token contains no information itself. (2)However, the output of [CLS] is inferred by all other words in this sentence, so [CLS] contains all information in other words. This makes [CLS] a good representation for sentence-level classification. of course, you may use an average vector, it makes sense, too.
