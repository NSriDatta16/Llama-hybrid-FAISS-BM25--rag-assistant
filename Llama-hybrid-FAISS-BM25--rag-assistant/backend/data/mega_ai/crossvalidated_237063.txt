[site]: crossvalidated
[post_id]: 237063
[parent_id]: 236964
[tags]: 
Don't do this. It's not even a good idea for k-means. Do not assume the clustering is perfect, and also do not assume that it never changes. And you won't be able to react appropriately. For example, consider the data set -5 -2 +2 +5 This will cluster at height 3 into the two clusters $\{-5,-2\}$ and $\{+2,+5\}$. But now a new data point arrives: -5 -2 0 +2 +5 and now the best solution is three clusters, $\{-5\}$, $\{-2,0,+2\}$ and $\{+5\}$. The result has changed completely! Clustering algorithms are fragile, use them with care. Don't even assume they got everything labeled correctly - because they won't. The proper way to use clustering is to study the resulting clusters, derive a hypothesis from that then test and verify this hypothesis. You can then of course check if new data is in accordance with this hypothesis etc., but you really should spell out this pattern. A viable, but also questionable because of above reasons, approach is to train a classifier . You want a robust classifier, because your clustering wasn't perfect; so you really want to avoid overfitting. If you just need something, but quality is not very important, then this is feasible (e.g. when you map image snippets to visual words, you don't need to get every single visual word correct, but you only want to get a sufficiently similar histogram in the end; then such approaches work well enough.)
