[site]: crossvalidated
[post_id]: 590165
[parent_id]: 380212
[tags]: 
I thought I'd update my question with an answer, because I've been successfully using the above technique over the past three years. My process I am training models to find tweets that mention adverse events. Things like floods, fire, earthquakes, shootings, etc. I use document vectors as the basis of the machine learning process. When I create a new category, I first populate the positives of the dataset by a combination of keyword searches (i.e. for the flood category, searching for 'flood' is a good start), randomly generated phrases and manually written phrases that represent the sort of thing I'm looking for. This will result in a smattering of positives amidst the sea of negatives. I train a simple model (either a nn with a low neuron count or even just a glm) on this data. This first model is generally pretty crap. However, once applied to my dataset, it will find true positives at a rate high enough (like maybe one in twenty) that I can scroll through the dataset to assign new positives. I then train a new model with this additional data and use it to find more examples. After a few iterations of this process, I typically have a pretty good model in my hands, and am able to find almost all of the positive examples in the dataset. Further refinement mainly comes in the form of heavily penalising false positives.(in the Flood example above, this would constitute phrases like "a flood of subprime home loans", or "The Flood have to be my least favourite enemy in Halo", or "Pictures from the great flood of 1908".) Once I've done this and other validation steps, I generally have a model ready for production. Lessons Learned In my question I worry about whether there are some hidden positive examples that I never find because the model is never trained to find what it doesn't know about. On reflection I don't think that's an issue. Each model I train will settle on a different set of features to predict the classification, and over time the positives that are 'semantic outliers' mostly get picked up. There are a few other tips I can share, but they're not especially relevant to the original question. For instance, it helps the process to split your dataset up into several smaller datasets, and fully assign each one before moving to the next.
