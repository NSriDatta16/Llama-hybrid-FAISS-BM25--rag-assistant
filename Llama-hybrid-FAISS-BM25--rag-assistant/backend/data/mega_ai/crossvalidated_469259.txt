[site]: crossvalidated
[post_id]: 469259
[parent_id]: 
[tags]: 
How to model non-experimental continuous individual treatment effect on a binary target?

I have historical data of a problem that can be described as: A person represented by features X has to wait T minutes on a queue so she can receive a treatment (which is equal for everyone), and by the end of the treatment (takes a few minutes), we observe the binary outcome of Y . I know for a fact that features contained in X , specially seasonality features (like when she entered the queue), directly influence T , at the same time that X and T also have a direct impact on Y . I also know that X might not contain all the features that influence T , and there's no way to be sure. I also know the "shape" of the effect of T on Y : the probability of Y=1 should decrease as T increases, and saturates at a certain point, like a logistic curve. Now the issues : I need a robust, optimized and validated model that estimates the CATE / ITE , but how can I run hyperparameter search, feature selection or any kind of model selection if I don't know the true effect of T on Y , since I only observe one T per data point, and I also don't know if the selection bias is mitigated? How can I know if my model actually works, comparable to running cross-validation for regular classification/regression problems? And what are the most optimal techniques to be used in this scenario? Stuff that I tried already: I tried making T binary by simply splitting the dataset based on a quantile threshold, and then use meta-learners from the causalml package , and then validate it using metrics like the Area Under the Uplift Curve and Qini Curve , but it doesn't seem ideal and I don't see how these metrics account for selection bias. I also tried fitting some learners from econml package , but most of them are very slow and I couldn't get useful output. And I also used scikit-learn's PolynomialFeatures to add non-linearity and account for heterogeneity (force the interaction of T with X ), and then train a simple logistic regression, which yields a seemingly reasonable result (the shape of the curve generated when varying T is according to my expectations), but it outputs more than 25k features, which makes the training process very slow, especially if using Lasso. PS: This dataset has > 100 features and > 3M rows.
