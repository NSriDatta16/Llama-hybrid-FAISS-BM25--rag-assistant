[site]: datascience
[post_id]: 53772
[parent_id]: 
[tags]: 
Get long answers from BERT

We are using Google BERT for question and answering. We are using vanialla bert-base-uncased as well as squad trained checkpoints. The answers from BERT are very short and crisp. For example, if we ask describe a chatbot, then it will simply return, takes input from user and replies ... Though the answer actually is complete paragraph. Will training BERT on long paragraphs can solve this problem? If yes, any idea from where we can get such a QnA dataset, as it is not possible to create a huge QnA dataset manually. Is there any other tweak which can be done at some BERT layer, so that it starts understanding a long answer? Or is there any other framework or system already have solved this kind of problem, by maybe integrating with some other neural network technique, or by using a pipeline of multiple components?
