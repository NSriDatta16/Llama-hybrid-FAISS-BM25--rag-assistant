[site]: datascience
[post_id]: 102809
[parent_id]: 
[tags]: 
Does One-Hot encoding increase the dimensionality and sparsity of dataset?

There are two ways to convert object datatype into numeric datatype, first is One-Hot encoding and second is simply map the numerical tags to different values. For example for column Age containing three distinct values 'child', 'adult' and 'old', for that column One-Hot encoding is: Age Age_child Age_adult Age_old child 1 0 0 adult 0 1 0 old 0 0 1 Whereas a simple mapping of numerical tags to distinct values might be Age _Age child 1 adult 2 old 3 What I understand One-Hot encoding can increase the number of columns many times. For instance, consider 10 columns and each column having 3 distinct values on average, then the resulting dateset will have 30 columns. Whereas, simple numerical mapping does not change the datasets size (columns) and simply assigns the numerical tags to each distinct value. So the question is, does One-Hot encoding increase the dimensionality and sparsity of complex and large dataset? What is the more appropriate approach for machine or deep learning analyses out of these two? Is there any pros and cons of both?
