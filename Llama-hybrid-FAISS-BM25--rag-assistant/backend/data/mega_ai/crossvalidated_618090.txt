[site]: crossvalidated
[post_id]: 618090
[parent_id]: 617281
[tags]: 
Is this a valid method, and if so, is it better than the steps I've been using? Yes the suggestion by Bing Chat to refit the model each time the window is moved along the time series is correct. As new data is observed and added to the complete dataset the SARIMAX model identified in the first window may no longer be the best fitting. So we refit the model (run auto_arima in your case) before forecasting the next h steps. In fact, are the steps I'm using valid? Broadly speaking, yes the general idea is correct with the correction you mentioned from Bing Chat. Sketch of sliding window cross-validation for time series data. Take first n data points as your training dataset. Fit your model and forecast the next h steps. Calculate the error metric (rmse, mae, mape, wape etc.) and record it. Move the window forward one step; adding the next data point to the training dataset and removing the first one. Refit the model and forecast next h steps. Calculate error metric and record it. Repeat until there is no longer h time-points remaining after the end of the training dataset. Calculate the aggregate error metric (mean, median, percentile etc.)
