[site]: crossvalidated
[post_id]: 409287
[parent_id]: 408615
[tags]: 
I am no expert, but in this situation, I'd might try other dimensionality reduction techniques if those previous ones did not work. There are methods such as KernelPCA , using different kernels, with which you can even construct your own. There are other dimensionality reduction techniques - this link https://towardsdatascience.com/dimensionality-reduction-for-machine-learning-80a46c2ebb7e might give you a start. Did you plot them up in 2-3 dimensions? If you plot up several different techniques, you can see which dimensionality reduction technique might be the most suitable for obtaining your clusters - this assumes that your dataset is not too big. You could possibly go up to 4 dimensions by using a colour scheme for the 4th dimension. Although 2-4 dimensions might not capture enough variance, you often do not want to go into a high space of dimensions with k-means as it suffers from Curse of Dimensionality. Check how much variance you capture and pick a suitable number, but I would definitely not try and cluster in 2125 dimensions.
