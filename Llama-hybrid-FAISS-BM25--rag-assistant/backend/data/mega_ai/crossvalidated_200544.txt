[site]: crossvalidated
[post_id]: 200544
[parent_id]: 200042
[tags]: 
My hunch is that this is because you also have a language model (implicitly) trained which might be helping in your case. I guess you are trying to perform image captioning. Taking a concrete example, an image of a diaper will always typically occur with the image of a baby but not vice versa. Assume that images of only diapers are quite rare but those of only babies are numerous in your dataset and do can be learnt easily. Then captioning "Baby wearing diaper" might be easier than captioning just "Diaper" . Assumption here is that your network is able to recognize a baby well. @jstaker7 If you can post some images on which the network works well and some on which it doesn't it'll be easier to dig deeper
