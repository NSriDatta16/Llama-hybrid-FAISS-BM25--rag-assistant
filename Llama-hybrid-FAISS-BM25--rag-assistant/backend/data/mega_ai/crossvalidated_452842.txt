[site]: crossvalidated
[post_id]: 452842
[parent_id]: 
[tags]: 
Analogy for the process of neural networks

Consider a basic neural network like what you would expect to see in any beginner tutorial or course, and attempts to classify images as either 'cat' or 'no cat'. I have a few questions that I've been unable to find answers for, and would be pretty time-consuming to test for answers, so hoping someone here can help instead. Does the neural network recognize some feature of 'cat-ness' from the images - say the general shape of a cat being two points ears and then a rounded face? If I trained the net entirely on images where a cat was in the left half of the photo, would it be able to recognize a cat when presented with a photo that has the cat on the right side? The activation function is based on the input value of pixels in the image, that is rgb(x, y, z) , does that mean that the neural network would potentially struggle with pictures containing a black cat - since these values would be lower? My current understanding is essentially that the neural network process would be analagous to taking all of the training pictures and laying them on top of each other, and then finding the general distribution of rgb values (i.e. the pixel-wise average rgb value). Then when presented with a new image, we would take this flattened 'map' and overlay it with the new image, and see if it lines up relatively well. If yes, we determine it to be a cat image. Is this correct (for a linear activation function? at all?) How does changing the number of layers affect this analogy? What about changing the activation function?
