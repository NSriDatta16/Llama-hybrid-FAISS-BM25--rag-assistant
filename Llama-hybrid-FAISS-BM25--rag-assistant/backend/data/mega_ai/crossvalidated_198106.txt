[site]: crossvalidated
[post_id]: 198106
[parent_id]: 198098
[tags]: 
Disclaimer: I'm not a statistician, but I'm going to provide a completely contrived example of why what he is doing might have issues: Consider the following measures of deprivation for six small areas (lower is more deprived, so worse). 1, 2, 100, 3, 4, 5 It's clear the ranking is: 6, 5, 1, 4, 3, 2 (1 is best). We are going to group the first three areas in one "super area" and the latter three in another area. The average ranking for the first "super area" is (6+5+1)/3 = 4 . The average ranking for the second area is (4+3+2)/3 = 3 . So by his metric, the second area has a better "score" than the first. However, it's clear that this isn't the case: it's not hard to see that the average measure for the first area is (100+2+1)/3 = 34.333... and the average measure for the second area is (3+4+5)/3 = 4 , and higher is better. So in fact, his "ranking" is misleading. This is because rankings abstract the original measure away, so there is no way of knowing just how different the underlying measures are. Of course, this example is completely contrived, but like Ansombe's Quartet I hope it highlights the issues that could arise when using such an statistic. Does your friend have access to the underlying statistics? Finally, aggregating areas is hard , as gerrymandering shows how easily it can be abused. How is he deciding to do it? Edit: I suppose that is an example of point 5. of DJohnson's answer.
