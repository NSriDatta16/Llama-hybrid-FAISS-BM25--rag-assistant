[site]: datascience
[post_id]: 67113
[parent_id]: 
[tags]: 
What are some best Text Representation techniques in NLP

I've studied about various text representation techniques like : Bag of Words , N-gram data modelling , Tf-idf , word embedding etc. I would like to know which among all the techniques are most efficient when it comes to data modelling or representation for a supervised text classification across a large number of categories. I might have around 40 categories and then around a same number of sub-categories upto 4 levels.
