[site]: datascience
[post_id]: 14789
[parent_id]: 14786
[tags]: 
The reason is you (obviously) cannot feed NaNs to your model, so you absolutely have to clean them up. Looks like the idea here is â€“ by filling them with something other than zeros may help the learning by introducing some excessive information. It would be actually interesting first to run some sort of seq2seq RNN to try to predict NaNs from non-NaNs and then explore how it affects learning rate/accuracy...
