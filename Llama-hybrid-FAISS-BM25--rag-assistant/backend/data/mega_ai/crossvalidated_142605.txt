[site]: crossvalidated
[post_id]: 142605
[parent_id]: 142593
[tags]: 
Perhaps a more intuitive way to look at the definition is to start with a single random variable $X$ taking values on $\bf R$. Without going into technicalities, when can you say you have fully specified the behavior of the random variable? When you know its CDF. Given the CDF, you can obtain every possible statistic: mean, standard deviation, quantiles, etc. If the CDF is a "smooth" function (differentiable over, say, an interval), you can also obtain the probability density (by taking the derivative of the CDF). Note: if the CDF is smooth, the probability that X takes value x, $P(X=x) = 0$, is zero! That's the rationale for using a CDF: because it works for discrete and continuous (and weirder) values of $X$. Now, take a step further and think of a pair of random variables $(X, Y)$, describing the occurrence of a point on the plane. When can you say you know their behaviour? When you know the joint CDF $F(x,y)$, i.e., Probability that $X$ takes values smaller or equal than a number $x$, and $Y$ takes values smaller or equal than $y$. From the joint CDF $F$ you can always get the single (marginal) CDF for $X$ and $Y$. Intuitively, $F_X(X)= F(x, \infty)$, i.e., $P(X\le x)$ and $Y$ taking any value less than infinity. But, the individual CDF of $X$ and $Y$ are not enough to characterize the probability distribution of $(X,Y)$. You can find an example yourself when $X$ and $Y$ are Bernoulli (e.g., they take values Head and Tail). Say you toss one coin and give to $X$ and $Y$ the same value, i.e., the outcome of the toss. The individual CDFs for $X$ and $Y$ are the same $P(X=Head)=P(X=Tail)=1/2$; $P(Y=Head)=P(Y=Tail)=1/2$. The probability that they have the same value is 1, because we defined them to be identical. Now, choose a different definition: you toss a coin for $X$ and a coin for $Y$. The individual distributions are the same as before, but now $P(X=Y)=1/2$! So you really need the joint distribution. The last step is to consider a vector of random variables of arbitrary length: $(X_1, X_2, X_3, \ldots)$. A time series is just a random vector. The index is interpreted as time, so, $X_t$ could be store sales on hour $t$, or the number of clients in line at a store, or the price of a stock at minute $t$. But to describe the behaviour of this vector, you still need the joint CDF (your first question) and not the probability that it takes a specific vector. And the interpretation of the $t$-the element of the vector is usually "what happens of some uncertain event at time $t$.
