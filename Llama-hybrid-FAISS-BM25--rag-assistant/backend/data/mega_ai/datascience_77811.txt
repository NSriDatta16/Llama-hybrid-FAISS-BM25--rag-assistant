[site]: datascience
[post_id]: 77811
[parent_id]: 
[tags]: 
Classification of text articles found in different PDFs

I am trying to figure out the approach to connect articles present in different pages or PDFs. The historical data that I have are: Text Articles (broken down in headlines, body text, body headline and media caption and the PDFs names that they are found). I have gotten this in a XML format and I converted it in a Json file that looks like: { "Headline": "This is a Headline", "Byline": [ "This is another BYLINE" ], "BodyHeadline": [ "and the the body headline" ], "BodyText": [ "This should be a large text paragraph", "another sentence in the body text", "the last sentence in body text" ], "MediaCaption": ["If there is media caption"], "PDF": [ "X11#0001.pdf", "X11#0002.pdf", "X11#0003.pdf" ] } As you see this article is included in three different PDFS. What I would like to do is to build a model that classifies/predicts this article in different PDFs. i.e., to which PDFs is this article connected to. The PDFs are mostly readable and I am using PyMuPDF (aka "fitz") for getting the JSON output. This provides information regarding blocks of texts in PDFs such as font, size, bbox location and text. A sample of one PDF would look like this (I just show 2 blocks but it could contain more): { "PDF": "X11#0001.pdf", "Blocks": [ { "block_bbox": [ -0.5304872064644457, 0.9683844633175651, 0.5304879430798047, 0.9793545233723604 ], "block_idx": 0, "text": [ "a text sentence", "other sentence" ], "font": [ "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro" ], "size": [ 7.0, 7.0 ], "line_bbox": [ [ -0.5304872064644457, 0.9683844633175651, -0.4695114902929961, 0.9793545233723604 ], [ 0.4695122269083551, 0.9683844633175651, 0.5304879430798047, 0.9793545233723604 ] ], { "block_bbox": [ 0.0789473460541895, 0.7554111799458375, 0.41483171058858515, 0.9036320824132956 ], "block_idx": 1, "text": [ "This is a sentence ", "another sentence", "sentence3", "another sentence again", "yes, another sentence", "continue...", "continue...", "continue...", "another text", "almost there ", "final sentence" ], "font": [ "TEOSOK+ScalaSansPro-Bold", "TEOSOK+ScalaSansPro-Bold", "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro", "TEOSOK+ScalaSansPro" ], "size": [ 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0 ], "line_bbox": [ [ 0.0789473460541895, 0.7554111799458375, 0.08266079406682393, 0.7680569142930777 ], [ 0.0790216167143238, 0.7689795537757371, 0.16631733627647055, 0.7816252881229773 ], [ 0.0789473460541895, 0.7825479276056366, 0.3965036438661926, 0.7950850917740988 ], [ 0.0789473460541895, 0.7961163014355362, 0.41483171058858515, 0.8086534656039984 ], [ 0.0789473460541895, 0.8096846752654359, 0.38098440483292206, 0.822221839433898 ], [ 0.0789473460541895, 0.8232530490953355, 0.3889415222598362, 0.8357902132637977 ], [ 0.0789473460541895, 0.8368214229252351, 0.3813557156365535, 0.8493585870936973 ], [ 0.0789473460541895, 0.8503897967551347, 0.41312355623389646, 0.8629269609235968 ], [ 0.0789473460541895, 0.8639581705850342, 0.38012281984518836, 0.8764953347534964 ], [ 0.0789473460541895, 0.8775265444149338, 0.37606483416408437, 0.890063708583396 ], [ 0.0789473460541895, 0.8910949182448334, 0.3819320604922132, 0.9036320824132956 ] ],} Any ideas about how can I approach this problem and in which manner can I structure the data?
