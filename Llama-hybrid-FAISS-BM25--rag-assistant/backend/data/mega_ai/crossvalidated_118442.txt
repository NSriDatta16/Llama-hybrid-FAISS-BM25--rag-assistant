[site]: crossvalidated
[post_id]: 118442
[parent_id]: 
[tags]: 
Does the Gibbs Sampling algorithm guarantee detailed balance?

I have it on supreme authority 1 that Gibbs Sampling is a special case of the Metropolis-Hastings algorithm for Markov Chain Monte Carlo sampling. The MH algorithm always gives a transition probability with the detailed balance property; I expect Gibbs should too. So where in the following simple case have I gone wrong? For target distribution $\pi(x, y)$ on two discrete (for simplicity) variables, the full conditional distributions are: $$ \begin{align} q_1 (x;y) & =\frac{\pi (x,y)}{\sum_z \pi (z,y)} \\ q_2 (y;x) & =\frac{\pi (x,y)}{\sum_z \pi (x,z)} \end{align} $$ As I understand Gibbs Sampling, the transition probability can be written: $$ Prob\{(y_1, y_2) \to (x_1, x_2)\} = q_1(x_1; y_2) q_2(x_2; x_1) $$ The question is, does $$ \pi(y_1,y_2) Prob\{(y_1, y_2) \to (x_1, x_2)\} \overset{?}{=} \pi(x_1,x_2) Prob\{(x_1, x_2) \to (y_1, y_2)\}, $$ but the closest I can get is $$ \begin{align} \pi(y_1,y_2) Prob\{(y_1, y_2) & \to (x_1, x_2)\} \\ & = \pi(y_1, y_2) q_2(x_2; x_1) q_1(x_1; y_2) \\ & = \frac{\pi(x_1, x_2)}{\sum_z \pi(x_1,z)}\frac{\pi(x_1, y_2)}{\sum_z \pi(z, y_2)}\pi (y_1, y_2) \\ & = \pi(x_1, x_2) q_2(y_2; x_1) q_1(y_1; y_2) \end{align} $$ That's subtly different, and does not imply detailed balance. Thanks for any thoughts!
