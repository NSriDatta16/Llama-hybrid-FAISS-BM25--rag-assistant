[site]: datascience
[post_id]: 19486
[parent_id]: 19479
[tags]: 
I think you need to define the process and desired outcome a little more. It sounds like you need to: Define what features you want. Figure out how to extract those features. Figure out how to store those features. Pass that dataset to a ML model for training. I would figure out what exactly you want for #3 in terms of the number and type of data elements and then choose a data storage method only then. Unless you are going to be passing the unstructured documents directly to your model, you don't need MongoDB's capabilities. 10,000 records is small, but since you mentioned you want to calculate some aggregated statistics on your patient-level data, you could likely get by with something as simple as MySQL or SQLite. Spark and Map/Reduce are actually competitors, with Spark stealing MR's spotlight lately. You might need one or the other for feature extraction but they're probably overkill for the rest of the stuff you described.
