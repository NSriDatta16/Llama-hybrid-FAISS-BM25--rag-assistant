[site]: crossvalidated
[post_id]: 409679
[parent_id]: 
[tags]: 
LSTM Autoencoders - architecture

I am a bit confused about the structure of LSTM autoencoders, as far as I know, common way to construct vanilla autoencoders is bottleneck structure, for instance, start with 40 nodes, encode it to 30 then decode it back to 40. When I checked LSTM autoencoders implementations, I saw people are using structures like starting from 40 nodes encode it to 100 nodes to 20 nodes and decode it back to 100 nodes and 40 nodes. Is there specific reason for this construction, if there is can someone explain me the reason? Ps: My aim with autoencoders is to reduce the dimension of time series data Thank you so much
