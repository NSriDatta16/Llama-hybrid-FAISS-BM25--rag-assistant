[site]: crossvalidated
[post_id]: 251645
[parent_id]: 249585
[tags]: 
I suppose you are not interested in only recognizing exactly the same image [1]. Instead, you want to know if an image is extremely similar to one you have already seen, and if so, retrieve that one. Why is that challenging? Let us first take a step back and assume that we were only looking at points in Euclidean space. That would be easy, because we could then check if the Euclidean distance $d(x, y) = \sqrt{\sum_i (x_i - y_i)^2}$ exceeds a threshold $\tau$, which you will tune to match the desired degree of necessary similarity. However, the Euclidean distance is not meaningful for images: in high dimensional space, nearly all points have equal distance to each otherâ€“something commonly referred to as the curse of dimensionality . That is why you need to project the images to some space, where it actually is. The easiest way (from a pragmatic perspective) is to get hold of a state-of-the-art image net classifier and use it as a feature extractor. The activations of the last layer before the classification is done will serve as a feature extractor for that. I.e. $d_f(x, y) = \sqrt{\sum_i (f(x)_i - f(y)_i)^2}$ with $f$ mapping an image to the last layers activations, will give you "meaningful" distances. "Meaningful" here refers to the fact that most humans would agree. There are ways to train these feature extractors from scratch. Convolutional Generative Adversarial Networks or convolutional variational auto-encoders come to my mind. If you want to know more, let me know. [1] If so, use a hash table for fast lookup and then compare.
