[site]: crossvalidated
[post_id]: 627022
[parent_id]: 626376
[tags]: 
Update 4 : I've implemented the new general purpose relative explained variation method. Explanation and examples are here. It would be nice to compare its performance with random permutation-based methods. To perform the comparison, I first wrote an R function which computes the random permutation-based relative explained variation (REV) metric. This metric quantifies the impact of shuffling a given predictor on model performance, indexed by the model linear predictor ( $X\hat{\beta}$ ). rexVar_perm $x draws coefficients set.seed(j) # ensure reproducibility srows Next, I used the MASS package to simulate datasets with different collinearities and compute the corresponding general purpose-based and random permutation-based REVs. Focussing on the simplest case (and to make things easy for myself), each dataset has 2 predictors (v1 and v2) and a continuous outcome (y). library(rms) library(here) library(MASS) library(ggplot2) library(data.table) source("rexVar.R") ## https://github.com/harrelfe/rms/blob/master/R/rexVar.r source("rexVar_perm.R") # write function to generate dataframe with correlated predictors sim_cdata As it turns out and as cautioned by @Michael M and @bgreenwell, when the predictors are strongly collinear (correlation > 0.80 in our example), the random permutation-based REV results become somewhat erratic. In contrast, the general purpose-based REV values decline steadily with increasing collinearity, reflecting the diminishing incremental predictive value that a given predictor has over its (correlated) counterpart. @Michael M and @bgreenwell, given that datasets with collinearities are not a rarity in biomedical research, could you advise on alternative variable importance measures that are used in the machine learning world? gen_rev
