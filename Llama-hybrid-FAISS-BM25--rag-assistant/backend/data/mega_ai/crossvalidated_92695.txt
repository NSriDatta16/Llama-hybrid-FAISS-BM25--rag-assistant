[site]: crossvalidated
[post_id]: 92695
[parent_id]: 
[tags]: 
Neural Network Error Plot Odd Effect

I'm using R to fit a neural network to data generated by the formula $y = x^2 + \frac{\epsilon}{2}$ where $x \sim \mathcal{U}(0, 2)$ and $\epsilon \sim N(0, 1)$ (very simple, right?). The following plot shows the plot of function $x^2$ and the generated data: Now, I take the average error for $10$ runs for a Neural Network model of size $k$ for all $k \in \{1, \ldots, 50\}$ getting the following plot: What I find rather strange is that from ~$10$ to ~$30$ and from ~$40$ to ~$50$ it is $\approx 0$ and stable but from ~$30$ to ~$40$ it is volatile and $>> 0$. I've also tried several other functions getting the same effect. Is that normal? Can you provide an explanation for it? The plot above was generated by the following R code: require(nnet) f
