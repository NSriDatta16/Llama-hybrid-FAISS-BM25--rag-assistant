[site]: crossvalidated
[post_id]: 511140
[parent_id]: 109831
[tags]: 
You should ! If you refer to ensemble of models (also called blending, staging, stacking). Unfortunately, the sense behind ensemble is quite vague. Models themselves based on ensemble (Random Forest...) may not performed better than others (Linear Regression, Neural networks). In his article: Stacked generalization (1992) David H. Wolpert stated: The conclusion is that for almost any real-world generalization problem one should use some version of stacked generalization to minimize the generalization error rate. And this remains true until today. However, these model are harder to tune and ship than a single model. They also have a longer prediction time, since you need the predictions of possibly hundreds of models. And, even though they have better predicitions, the increment in accuracy may not be worth the hassle. After seeing various questions about ensemble learning, I wrote why does model staging work exploring the reasons of their success.
