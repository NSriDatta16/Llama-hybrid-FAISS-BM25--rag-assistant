[site]: crossvalidated
[post_id]: 275856
[parent_id]: 275843
[tags]: 
Calibration isn't exactly the same thing in Bayesian work. The prior is where external data is brought to bear in the problem. If you have some problem where there is substantial knowledge and it is credible to believe that $\mu_x\in[4,5]$ then you would put nearly all your mass in that range. If so much data had accumulated that there was very little meaningful error, such as for the speed of light, then you could condition on a precise value such as $\mu_x=4.6321$. As the posterior contains all the available information regarding the location of the parameters, all future work should be calibrated against your posterior density. This would then be subject to scoring to test the validity of the model and its associated parameters from out of sample data. Calibration on the Bayesian side is tied to model selection and model averaging. As a consequence, the best out-of-sample fit may not be the model selected as the Bayesian mechanism will implicitly consider the possibility your validation set happens to be a non-representative sample.
