[site]: datascience
[post_id]: 56969
[parent_id]: 56954
[tags]: 
Your intuitions are good: in general you need your data to contain all the possible indications (features) which might help find the answer. And your thinking is also correct about creating this "other table": the reason why you need it is because for this problem you need each instance to correspond to a customer. Your original data is not organized by customer, it's organized by meeting. So it makes sense to organize your data with features by customer such as these: days_since_last_visit number_meeting_scheduled number_meetings_attended ... 15 4 2 189 3 1 24 2 2 ... In general it's not recommended to assign scores yourself, because you probably don't know what is the optimal value. For example is a customer better when they schedule 10 meetings and attend 3 or schedule 4 and attend 2? It's usually better to give all the raw values you have to the ML algorithm and let it calculate the best way to use it. An important point to define is: what is a good customer exactly? If you think your scoring is really accurate to define a good customer, you can calculate the score and rank the customers, then you're done: this is a heuristic , because you calculate the answer directly based on your knowledge of the problem. Now assuming you are not so sure and want to use ML: If you can have a sample with labels which say whether a customer is "good" or not, then you have a supervised classification problem: the goal will be to train a model able to predict the class (category) for any customer based on the features. If you have a sample with numeric values indicating "how good" a customer is, then you have a supervised regression problem. Again the goal is to train a model which predicts the value for any customer based on the features. For both cases above I'd suggest you start with simple methods such as decision trees or SVM (both can do classification or regression). The former has the neat advantage that you can manually observe the tree and understand how the classifier works. If you don't have any labeled data, then your only option is unsupervised learning , which usually means some form of clustering: in this case there's no training stage, the algorithm is provided only with the features and it tries to group together the instances which are close to each other. A standard approach for that would be K-means, for example. Note that you're not sure to obtain the groups that you expect in this case.
