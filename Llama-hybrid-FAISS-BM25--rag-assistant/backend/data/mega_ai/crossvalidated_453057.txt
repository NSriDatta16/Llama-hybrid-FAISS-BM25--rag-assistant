[site]: crossvalidated
[post_id]: 453057
[parent_id]: 
[tags]: 
Feature learning: is it possible that AEs are better then VAEs?

I'm trying to use unsupervised feature learning for signal data, and I first experimented with an Autoencoder. I used the learned features at the bottleneck as features for supervised classification, and got satisfactory results. I then changed the architecture to that of a VAE, but I can't reach the same level of performance on supervised tasks as the regular autoencoder. I don't think there's a problem with my VAE code as I just copied it off of GitHub repos (cross-checked it with multiple codes). The mean and STD of the produced latent variables Z do converge to somewhere around 0 and 1 (KLD Loss is far from 0 though). However, it seems that as the KLD decreases, the performance also worsens. It was my intuition that if it can reconstruct the input and decrease the KLD, then it's learning "meaningful" features in the latent space that are continuously getting "precise" (i.e. disentangled), and hence better for supervised tasks. However, this seems not to be the case. Can someone help me understand what's happening? How can I at least achieve the performance of a regular AE through a VAE (my goal is not reconstruction but I want to explore the more-or-less disentangled features that can be learned by a VAE)? Or is this the part where I move on to InfoVAEs as they're supposedly better at learning features?
