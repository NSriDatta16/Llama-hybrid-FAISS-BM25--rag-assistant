[site]: crossvalidated
[post_id]: 602696
[parent_id]: 450749
[tags]: 
I have lately encountered the same question and found that the definition of high-dimensionality is not always used consistently. Therefore, I can relate to your problem. More specifically, does a high-dimensionality of a time series refer to its length, number of variables or both? In the context of the curse of dimensionality, both length and number of variables play a role. Therefore, one would expect that the Euclidean distance is less able to distinguish between time series as the length of the time series increases. Will the euclidean distance perform well if I'd like to cluster my data with k-means? Should I find a way to reduce the dimensionality? In practice - which I can confirm from my own results with the Euclidean distance metric - using the Euclidean distance nevertheless often leads to good results. Possible reasons for this are summarized on slide 5 under this link : Some facts on the "Curse of Dimensionality" (from Houle et al. 2010): Mathematics proven for i.i.d. data only Relevant dimensions make the problem easier Irrelevant dimensions make the problem harder mostly a matter of “signal to noise ratio” Numerical contrast goes away, but ranking still remains meaningful There are other distance metrics, such as DTW, which are likely to result in better performance. But if you apply Euclidean distance because, e.g., you want to emphasize the interpretability of your findings, the Euclidean distance may not be a bad choice.
