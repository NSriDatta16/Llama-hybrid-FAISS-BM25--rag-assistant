[site]: crossvalidated
[post_id]: 632340
[parent_id]: 533286
[tags]: 
It is better to look at this in a more general way. So you have a Bayesian model with a likelihood function $L_x(\theta)$ and a prior $\pi(\theta)$ , say. Then the posterior is proportional to $L_x(\theta) \cdot \pi(\theta)$ . Now you modify the prior by incorporating the knowledge that $\theta$ is positive, so the new prior is $\pi(\theta) \cdot \mathbb{1}_{\theta>0}$ , renormalized by dividing by the probability that $\theta >0$ . Let us write this new prior as $\pi_A(\theta)\propto \pi(\theta)\cdot \mathbb{1}_A(\theta)$ , which is simply the prior $\pi$ restricted to the set $A$ . This gives a new posterior, also restricted to the set $A$ , which is proportional to $$ \pi_A(\theta \mid x) \propto L_x(\theta)\cdot \pi(\theta)\cdot \mathbb{1}_A(\theta) $$ which simply is the old posterior restricted to the set $A$ . So the only thing you need to do is recompute the constant of proportionality. So, in your case, if the posterior without restriction is a normal density, then with the restriction to the positive axis it will be a truncated normal. If you also have a conjugate prior for the variance, then the marginal posterior for the expectation will be a t distribution, the restricted posterior will be a truncated t distribution.
