[site]: crossvalidated
[post_id]: 621525
[parent_id]: 
[tags]: 
How to evaluate whether a method is unbiased in estimating SATE in simulation?

I am trying to understand the concept of sample average treatment effect ( $SATE$ ) over population average treatment effect (PATE). $SATE$ focuses on the effects of treatment in the particular sample we have collected. $PATE$ represents the true treatment effect in the study population. The main question is how we can show one method (e.g., matching + averaged mean difference, regression) is unbiased in estimating this $SATE$ ? Here is the R code generating the sample set.seed(218) n = 1000 x = rnorm(n, 0, 1) ###constant treatment effect ### t = 0.5 ###coefficients for the treatment model ### a0=-2.2 a1=0.5 lin.p=a0+a1*x z = rbinom(n,1,exp(lin.p)/(1+exp(lin.p))) ###coefficients for the potential outcome model ### ### The different errors. SATE will diff from sample to sample### error1=rnorm(n, 0, 1) error2=rnorm(n, 0, 1) y0 = 8 +2*x + error1 y1 = 8 +2*x + t + error2 data = data.frame(x,z,y0,y1, yi = ifelse(z == 1 , y1, y0)) #SATE for this sample (SATE = mean(data $y1 - data$ y0)) Questions: Q1) If the error is the same for $y_1$ and $y_0$ (i.e., error1=error2), then $SATE$ is constant for every individual and thus equal to $PATE$ , right? Q2) In this particular sample of 1000, $SATE=0.4531$ . How can we evaluate whether a method (e.g., matching or regression) is biased or unbiased in estimating $SATE$ ? For $PATE$ , we can simulate many different samples. For $SATE$ , the sample is fixed here. Where can we get that â€œrandomness"? In randomized trial setting, we can reshuffle treatment assignment $z$ in this sample of 1000 observations. Now this is an observational study setting, I doubt it is appropriate. Any suggestion will be appreciated!
