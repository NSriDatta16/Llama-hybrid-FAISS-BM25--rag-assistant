[site]: crossvalidated
[post_id]: 420157
[parent_id]: 
[tags]: 
Specifying separable covariance functions for 2D gaussian process regression

I would like to fit a gaussian process regression with two input variables. But I am not sure how to construct or interpret the covariance function with multiple input dimensions. There are different covariance functions (called kernels in sklearn) that you can choose based on the expected relationship, e.g. you might choose a cyclical covariance function for day of the year predicting temperature as temperature goes up in summer then down in winter and starts again. If we have multiple inputs and we expect them to have different relationships with the response variable how do we include this information in the covariance structure? Do we need to? Toy example Two input variables x and w are used to predict y . y follows a sine relationship with x whereas it follows a quadratic relationship with w . There is noise, denoted e . n = 500 w = pd.Series((np.random.random(n)*5)-2.5) x = pd.Series(20*np.random.random(n)) e = pd.Series(np.random.normal(0,0.5,n)) y = pd.Series(w**2 + np.sin(x) + e) data = pd.concat([w,x,e,y], axis=1) data.columns=["w","x","e","y"] For a 1D case with x I would use the ExpSineSquared() kernel in scikit-learn and the Squared Exponential kernel RBF() for w . This Paper says that to extend covariance functions to multiple inputs: take a covariance function that is the product of one-dimensional covariances over each input. So I believe I would create a covariance functions like so: kernel = RBF() * ExpSineSquared() + WhiteKernel() Hopefully RBF() is looking for a smooth function of y with w , ExpSineSquared() is looking for a periodic function with x , and WhiteKernel() is just their capturing unexplained variance. But as I haven't linked them to specific inputs is it looking for both functions across both inputs? References: 1) Gaussian Processes for Timeseries Modelling, S. Roberts, M. Osborne, M. Ebden, S. Reece, N. Gibson & S. Aigrain .
