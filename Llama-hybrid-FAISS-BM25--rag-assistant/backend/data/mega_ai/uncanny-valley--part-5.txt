 considered as exhibiting the uncanny valley effect can be diverse, involve different sense modalities, and have multiple, possibly overlapping causes. People's cultural heritage may have a considerable influence on how androids are perceived with respect to the uncanny valley. The uncanny valley effect may be generational. Younger generations, more used to computer-generated imagery (CGI), robots, and such, may be less likely to be affected by this hypothesized issue. The uncanny valley effect is simply a specific case of information processing such as categorization and frequency-based effects. In contrast to the assumption that the uncanny valley is based on a heterogeneous group of phenomena, recent arguments have suggested that uncanny valley-like phenomena simply represent the products of information processing such as categorization. Cheetham et al. have argued that the uncanny valley effect can be understood in terms of categorization processes, with a category boundary defining 'the valley'. Extending this argument, Burleigh and Schoenherr suggested that the effects associated with the uncanny valley can be divided into those attributable to the category boundary and individual exemplar frequency. Namely, the negative affective responses attributed to the uncanny valley were simply a result of the frequency of exposure, similar to the mere-exposure effect. By varying the frequency of training items, they were able to demonstrate a dissociation between cognitive uncertainty based on the category boundary and affective uncertainty based on the frequency of training exemplars. In a follow-up study, Schoenherr and Burleigh demonstrated that an instructional manipulation affected categorization accuracy but not ratings of negative affect. Thus, generational effects and cultural artifacts can be accounted for with basic information processing mechanisms. These and related findings have been used to argue that the uncanny valley is merely an artifact of having greater familiarity with members of human categories and does not reflect a unique phenomenon. The uncanny valley effect occurs at any degree of human likeness. Hanson has also stated that uncanny entities may appear anywhere in a spectrum ranging from the abstract (e.g., MIT's robot Lazlo) to the perfectly human (e.g., cosmetically atypical people). Capgras delusion is a relatively rare condition in which the patient believes that people (or, in some cases, things) have been replaced with duplicates. These duplicates are accepted rationally as identical in physical properties, but the irrational belief is held that the "true" entity has been replaced with something else. Some people with Capgras delusion claim that the duplicate is a robot. Ellis and Lewis argue that the delusion arises from an intact system for overt recognition coupled with a damaged system for covert recognition, which results in conflict over an individual being identifiable but not familiar in any emotional sense. This supports the opinion that the uncanny valley effect could occur due to issues of categorical perception that are particular to how the brain processes information. Good design can avoid the uncanny valley effect. David Hanson has criticized Mori's hypothesis that entities having an almost human appearance will necessarily be evaluated negatively. He has shown that the uncanny valley effect could be eliminated by adding neotenous, cartoonish features to entities that had formerly caused an uncanny valley effect. This method incorporates the idea that humans find characteristics appealing when they are reminiscent of the young of our own (as well as many other) species, as used in cartoons. Similar effects If the uncanny valley effect is the result of general cognitive processes, there should be evidence in evolutionary history and cultural artifacts. An effect similar to the uncanny valley was noted by Charles Darwin in 1839: The expression of this [Trigonocephalus] snake's face was