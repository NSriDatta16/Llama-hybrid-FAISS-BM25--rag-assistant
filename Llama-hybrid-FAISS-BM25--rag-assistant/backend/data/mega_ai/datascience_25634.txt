[site]: datascience
[post_id]: 25634
[parent_id]: 18103
[tags]: 
I have the exact same issue with a DNN that I am currently building. Taking my data set and synthesizing new data with a GAN seems like a great idea. But the GAN itself will only learn to output images with the same image variance and standard deviations as was learned in the training set. So your newly generated data will simply represent more permutations of the same sample distribution. This will help your NN train better on the same distribution, therefore it may lead to greater over training.
