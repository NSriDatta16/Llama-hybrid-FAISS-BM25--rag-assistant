[site]: crossvalidated
[post_id]: 124973
[parent_id]: 124960
[tags]: 
In order to verify your back-propagation implementation you could compare your results to that achieved with a know correct back-propagation implementation. I can recommend FANN (fast artificial neutral networks) as a cross platform open source implementation of back-propagation. http://leenissen.dk/fann/wp/ . Though I'm sure the Matlab implimention is also very good if you have access to it. As for training iterations you could use early stopping methods rather than keep varying the number of epochs http://page.mi.fu-berlin.de/prechelt/Biblio/stop_tricks1997.pdf . As for the topology of the network. This question has been asked previously: How to choose the number of hidden layers and nodes in a feedforward neural network? As for the learning rate you might need to do a little trial and error :) Hope this helps.
