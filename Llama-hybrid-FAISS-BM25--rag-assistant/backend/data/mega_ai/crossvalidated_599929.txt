[site]: crossvalidated
[post_id]: 599929
[parent_id]: 599922
[tags]: 
The leverage values are fully determined by the explanatory variables, and since regression analysis imposes no restriction on the explanatory variables, it is not true to say that it is commonly believed that the leverage goes to zero asymptotically. $^\dagger$ To the contrary, asymptotic results in regression analysis generally proceed by showing what happens to the various regression quantities of interest if asymptotic conditions are imposed on the explanatory variables and the resulting leverage values. Typically, the asymptotic results in regression are derived using the "Grenander conditions" (see this related answer ) which mean that $\max h_{ii} \rightarrow 0$ as $n \rightarrow \infty$ , so that no individual data point is "influential" in the limit. This is imposed as a condition of asymptotic theorems relating to other regression quantities. Whether or not the maximum leverage of the data points goes to zero asymptotically depends on how you construct the sequence of explanatory variables that you are using for the asymptotic analysis. It is easy to construct sequences of explanatory variables where the maximum leverage does not go to zero, such that there are always "influential" data points, even in the limit. $^\dagger$ When we go beyond this to model the explanatory variables we usually say that we're doing multivariate analysis rather than regression analysis.
