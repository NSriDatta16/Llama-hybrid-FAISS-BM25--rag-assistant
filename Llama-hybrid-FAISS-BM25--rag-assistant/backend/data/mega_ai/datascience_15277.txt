[site]: datascience
[post_id]: 15277
[parent_id]: 15274
[tags]: 
It depends of the model your training. The data needs to be big enough so that you can subsample (with replacement) the data without loss of F1 score . That is the theory. For Neural network, the rule of thumb is P^2, P being the number of parameters. This is often hard to achieve. In practice, if you have the opportunity to create more data, make some, check the improvement, and if there is, you need more data (for your model, that is)
