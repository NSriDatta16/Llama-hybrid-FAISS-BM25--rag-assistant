[site]: crossvalidated
[post_id]: 163040
[parent_id]: 163034
[tags]: 
What is all this prior, likelihood stuff? That's what makes it Bayesian. The generative model for the data is the same; the difference is that a Bayesian analysis chooses some prior distribution for parameters of interest, and calculates or approximates a posterior distribution, upon which all inference is based. Bayes rule relates the two: The posterior is proportional to likelihood times prior. Intuitively, this prior allows an analyst mathematically to express subject matter expertise or preexisting findings. For instance, the text you reference notes that the prior for $\bf\beta$ is a multivariate normal. Perhaps prior studies suggest a certain range of parameters that can be expressed with certain normal parameters. (With flexibility comes responsibility: One should be able to justify their prior to a skeptical audience.) In more elaborate models, one can use domain expertise to tune certain latent parameters. For example, see the liver example referenced in this answer . Some frequentist models can be related to a Bayesian counterpart with a specific prior, though I'm unsure which corresponds in this case.
