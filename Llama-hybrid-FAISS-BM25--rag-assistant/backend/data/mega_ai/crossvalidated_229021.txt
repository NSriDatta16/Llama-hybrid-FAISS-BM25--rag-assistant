[site]: crossvalidated
[post_id]: 229021
[parent_id]: 229007
[tags]: 
Normality tests are mainly a diagnosis tool. As you already said, you can reject this hypothesis with a large enough sample, but you can also reject equality of means with a large enough sample! You could also have a look at QQ plots in order to check departures from normality. Although the CLT guarantees, under some mild conditions, that the average is approximately normal, the rate of convergence varies for different distributions. Then, you never know whether or not in your case, assuming normality is guaranteed by the CLT. For example, consider the following example where you compare $10,000$ times two samples of size $100$ from a t distribution with 2.01 degrees of freedom with mean 0 and 1 respectively, using a t-test. count=vector() for(i in 1:10000){ x = rt(100,df=2.01) y = 1+rt(100,df=2.01) count[i] = ifelse(t.test(x,y)$p.val So, at the 0.05 level, you only reject $\approx 77\%$ of the times, while the means are clearly different. The reason for this is that the distribution of the sample mean of samples of size 100 from a t distribution with 2.01 degrees of freedom does not look normal: samp.mean = vector() for(i in 1:10000) samp.mean[i] = mean(rt(100,df=2.01)) hist(samp.mean) So, the CLT cannot always save you, while conducting a normality test is a safe way to convince people that you are doing sensible things. If the samples look far from normal, you need to think harder whether or not equality of means will answer your scientific question. You could think of alternative nonparametric tests, such as the Kolmogorov-Smirnov, Mann-Whitnney, Permutation tests, and etcetera. Moreover, if the samples are very large and you also have concerns about the normality assumption, you could even plot kernel density estimators and compare them visually, or more formally using some distance between probability distributions (total variation, for instance).
