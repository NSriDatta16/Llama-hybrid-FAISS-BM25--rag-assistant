[site]: datascience
[post_id]: 66214
[parent_id]: 66198
[tags]: 
PCA and truncate SVD do not differ much, since they are based on the same theory that the eigenvectors with the less eigenvalue are discarded. As mentioned here the difference: TruncatedSVD is very similar to PCA, but differs in that it works on sample matrices directly instead of their covariance matrices. When the columnwise (per-feature) means of are subtracted from the feature values, truncated SVD on the resulting matrix is equivalent to PCA. In practical terms, this means that the TruncatedSVD transformer accepts scipy.sparse matrices without the need to densify them, as densifying may fill up memory even for medium-sized document collections. T-SNE attempts to find the underlying structure of the data by taking into account the neighbors of a sample. By prioritizing the neighbor points gives an advantage when data structure is a manifold. A way to understand the meaning of your figure clusters is described here , using radar charts. From my point of view, what i would say is that The information, which predicts the labels Fraud/not Fraud, is not on a structure manifold The samples seems to be linear separated and and that the main information is given by only two features. If you wanted, you could check how much of the eigenvalues energy is retained when keeping only two features
