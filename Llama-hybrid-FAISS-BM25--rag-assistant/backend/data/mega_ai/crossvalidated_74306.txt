[site]: crossvalidated
[post_id]: 74306
[parent_id]: 
[tags]: 
Is there a better name than "average of the integral"?

I'm testing throttle position sensors (TPS) my business sells and I print the plot of voltage response to the throttle shaft's rotation. A TPS is a rotational sensor with $\approx$ 90° of range and the output is like a potentiometer with full open being 5V (or sensor's input value) and initial opening being some value between 0 and 0.5V. I built a test bench with a PIC32 controller to take a voltage measurement every 0.75° and the black line connects these measurements. One of my products has a tendency to make localized, low amplitude variations away from (and under) the ideal line. This question is about my algorithm for quantifying these localized "dips"; what is a good name or description for the process of measuring the dips? (full explanation follows) In the below picture, the dip occurs at the left third of the plot and is a marginal case whether I would pass or fail this part: So I built a dip detector ( stackoverflow qa about the algorithm ) to quantify my gut feeling. I initially thought I was measuring "area". This graph is based on the printout above and my attempt to explain the algorithm graphically. There is a dip lasting for 13 samples between 17 and 31: Test data goes in an array and I make another array for "rise" from one data point to the next, which I call $deltas$. I use a library to get the average and standard deviation for $deltas$. Analyzing the $deltas$ array is represented in the graph below, where the slope is removed from the above graph. Originally, I thought of this as "normalizing" or "unitizing" the data as the x axis are equal steps and I'm now solely working with the rise between data points. When researching this question, I recalled this is the derivative, $\frac {dy}{dx}$ of the original data. I walk through $deltas$ to find sequences where there are 5 or more adjacent negative values. The blue bars are a series of data points who are below the average of all $deltas$. The values of the blue bars are: $0.7 + 1.2 + 1.3 + 1.4 + 1.8 + 2.5 + 2.9 + 3.0 + 2.5 + 2.0 + 1.5 + 1.0 + 1.2$ They sum to $23$, which represents the area (or the integral). My first thought is "I just integrated the derivative" which should mean I get back the original data, though I'm certain there's a term for this. The green line is the average of these "below average values" found via dividing the area by the length of the dip: $23 \div 13 = 1.77$ During the testing of 100+ parts, I came to decide that dips with my green line average less than $2.6$ are acceptable. Standard deviation calculated across the entire data set wasn't a strict enough test for these dips, as without enough total area, they still fell within the limit I established for good parts. I observationally chose standard deviation of $3.0$ to be the highest I would allow. Setting a cutoff for standard deviation strict enough to fail this part would then be so strict as to fail parts which otherwise appear to have a great plot. I do also have a spike detector which fails the part if any $|deltas - avg| > avg+std dev$. It's been almost 20 years since Calc 1, so please go easy on me, but this feels a lot like when a professor used calculus and the displacement equation to explain how in racing, a competitor with less acceleration who maintains higher corner speed can beat another competitor having greater acceleration to the next turn: going through the previous turn faster, the higher initial speed means the area under his velocity (displacement) is greater. To translate that to my question, I feel like my green line would be like acceleration, the 2nd derivative of the original data. I visited wikipedia to re-read the fundamentals of calculus and the definitions of derivative and integral , learned the proper term for adding up the area under a curve via discreet measurements as Numerical Integration . Much more googling on average of the integral and I'm lead to the topic of nonlinearity and digital signal processing. Averaging the integral seems to be a popular metric for quantifying data . Is there a term for the Average of the Integral? ($1.77$, the green line)? ... or for the process of using it to evaluate data?
