[site]: crossvalidated
[post_id]: 339420
[parent_id]: 336512
[tags]: 
Tree-based methods A group of regression and classification methods built around decision trees. In a decision tree, data is recursively partitioned based on its predictors, and new predictions are generated by averaging data points at the relevant tips ('leaves') of each tree. Weaknesses of standard decision trees (such as overfitting) have been substantially overcome by bagging (in random forests) and boosting (in gradient boosting machines). Includes: CART, C4.5, random forests, gradient boosting trees Advantages: Flexible and relatively easy to interpret (importance scores, partial effects) Support vector machines (SVMs) Originally an algorithm for binary classification that identifies the hyperplane best separating two groups of data points. Subsequent extensions include multiclass SVMs (which work by reducing multiple class problems to a series of 2-class problems) and support vector regression (which uses the hyperplane to predict continuous values) Advantages: Artificial Neural Networks Computing systems whose network structure is inspired by (and theoretically allows for the flexibility of) biological systems. Composed of a net of artificial neurons that can transmit signals to each other in a defined, usually hierarchical structure. Each artificial neuron takes multiple inputs, sums them based on their separate weights, and produces output based on some activation function. The weights of each input are learnt during the network's training process. Neurons are organised in layers that tend to abstract different features of the system they are trained upon. Advantages: Includes: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Deep Learning
