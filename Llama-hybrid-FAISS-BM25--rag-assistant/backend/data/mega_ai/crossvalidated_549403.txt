[site]: crossvalidated
[post_id]: 549403
[parent_id]: 549401
[tags]: 
One reason to use traditional hypothesis testing methods (when they can be used) is that it is computationally efficient to do so compared to bootstrap sampling. Depending upon the number of dimensions in your data, the number of bootstrap samples required to estimate p values (or confidence intervals) can be very large. Central limit theorem is not always applicable. Sure, the average of a large number of i.i.d. random variables will lead to a Normal distribution. The question is what is large . Also, the problem is that it is not just the mean of the population you are interested in; there are other parameters that you want to estimate where CLT is not applicable. Again, we have asymptotic Normality to rescue (I would not go into details here), but it also requires a large sample. Again, what is large . Note that asymptotic Normality requires other technical conditions to hold which do not always hold. Edit: An example where CLT is not applicable is when a time series has long-term persistence which means that autocorrelation dies very slowly. Here the assumption of independence is violated to the extent that CLT is not even approximately valid with thousands of samples. Here again you will have t resort to classic sampling distributions for hypothesis testing. Another point (as detailed nicely by Alexis) is that the hypothesis tests are used for rejecting a plausible explanation (model) of the observed phenomenon. Therefore, hypothesis testing itself will stay relevant whatever method is used to test the hypothesis.
