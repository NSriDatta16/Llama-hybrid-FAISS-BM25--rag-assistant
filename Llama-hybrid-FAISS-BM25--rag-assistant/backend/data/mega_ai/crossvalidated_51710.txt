[site]: crossvalidated
[post_id]: 51710
[parent_id]: 51692
[tags]: 
If you are trying to learn a mapping between people's features to their incomes, then you don't have a binary classification problem, you have a regression problem. You might start experimenting with linear regression, polynomial regression, and if they fail, move to multi-layer perceptron neural networks (with an unbounded output layer activation function) or support vector machine regression. Keep in mind that if your data set comes from a random sample of the population, income will be distributed according to a heavy-tailed distribution (e.g. Pareto), that is, there will be a small, but non-negligible, number of people with an income much higher (orders of magnitude) than the average. This is problematic for typical regression algorithms because it makes the underlying optimization problems "stiff", resulting poor speed or even numerical instability. Furthermore, evaluating the accuracy of your regression algorithms with standard error measures such as mean squared error might be misleading, because the algorithm will typically mispredict these high-income instances (since they will be probably intrinsically difficult to predict given the input features) and these will have a disproportionally high effect on the overall error measure. I suggest you might try to preprocess your data applying a log or a log log transformation to incomes, and then normalize them, and all your numeric input features, to fall approximately within some small interval (e.g. -1..1 or 0..1).
