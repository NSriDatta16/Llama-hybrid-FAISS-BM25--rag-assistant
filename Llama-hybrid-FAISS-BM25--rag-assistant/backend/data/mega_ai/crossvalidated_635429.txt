[site]: crossvalidated
[post_id]: 635429
[parent_id]: 194142
[tags]: 
My one sentence answer would be: 1x1 convolutions allow to learn (sets of) linear combinations of input channels. A more intuitive answer Let's start with a 1x1 convolution on a simple image with only 1 channel (think grayscale image): In this case, a 1x1 convolution simply multiplies each pixel by a coefficient. In a sense it just multiplies the whole image, making it "darker" or "brighter" so to say. This is relatively boring / pointless. Now imagine we have 3 input channels, e.g. red, green, and blue. In this case the 1x1 convolution will actually have 3 coefficients, one for each input channel. The convolution itself multiplies each pixel from the 3 channels with the corresponding coefficient and adds them together. This makes things more interesting: Essentially the 1x1 convolution has turned into a linear combination of the red/green/blue input channels. Learning the 3 filter coefficients via backpropagation is now pretty meaningful: The model will try to come up with a linear combination of the 3 RGB channels in such a way that the resulting image still contains as much information as possible, nice! Taking this to the next step: It may turn out that reducing the input images from 3 channels to just 1 channel simply loses too much information. What about reducing it to 2 output channels instead? This is exactly what 1x1 convolution can do: In general the number of coefficients corresponds to num_input_channels x num_output_channels . So when going from 3 input channels to 2 output channels we have 6 coefficients. We can interpret them as 2 vectors with values for (factor_r, factor_g, factor_b) . In other words, when learning these coefficients, the model will try to find 2 linear combinations of the RGB input channels so that the 2 output images still contain as much information as possible. And from here we can generalize the pattern: Applying a 1x1 convolution with M output channels to N input channels tries to learn the optimal set of M linear combinations of these N input channels. The most common use case for this approach is dimensionality reduction, i.e. typically M is used. Actually, I'm not quite sure if there are many use cases to increasing the dimensionality, because in many cases the network structure that follows the convolutions is capable of creating linear combinations of the inputs by itself. In these cases the result would just be a "linear combination of linear combinations", and having increased the dimensionality would be pointless (unless a non-linearity is applied).
