[site]: datascience
[post_id]: 72540
[parent_id]: 63377
[tags]: 
Its actually a bit more than zachdj wrote. You will propably need several things to reach this point. As he said, changing the style from real life photography to comic can be achieved by mere filters or building own filters (quite hard and not intuitive). Another way is to train a network to detect and adapt a specific style, like cGAN for example, which is able to find common style or patterns between huge, unsorted groups of images and learns to transform one in another. Like that: Actually this can work well, but for that you may need a huge amount of data. Lets say arround 2000 images of people with dresses, and another 2000 of the style you want to adapt... so yeah not that easy to get his hands on .. generally the problem you try to tackle is called Domain adaption, and actually the way you doing it it can also be have addons like supervised or unsupervised. For both ways you need some data and preprocessing like, a neural network that do a segmentation for you like cutting out the background and isolates the person, but for that you need also masks which show the network whats interesting and what not. Check out Pix2Pix , UNET (for simple segmentation tasks) and cycle-GAN for unsorted image to image transformation. Good Luck, stay tuned Later Edit: Even came across that paper , maybe helps you.
