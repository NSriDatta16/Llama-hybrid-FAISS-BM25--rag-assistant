[site]: datascience
[post_id]: 42115
[parent_id]: 
[tags]: 
Finding outliers from multiple files

I am dealing with a very strange problem. I have a lot of files. I need to show which files are similar and which one has exception/outliers using its data. I can show with unsupervised learning using KMeans / DBSCAN or similar ML algorithms for each file. But what would be the approach for such a case? How can I show this record has outliers then group them together? My datasets are multivariate time series
