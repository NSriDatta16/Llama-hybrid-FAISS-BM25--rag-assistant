[site]: crossvalidated
[post_id]: 92312
[parent_id]: 92303
[tags]: 
First off, I think you need to clarify what it is you mean by "disparity". The sum of squared distances is an easy measure, however it is fraught with problems when you consider practical factors. To the human eye, two pictures may look similar and yet have vastly different sum of squared errors. The sum of squared distance measure is extremely sensitive to even the slightest difference between pixels. A great paper that reconciles practical considerations and suggests other measures is this one http://www.mdpi.com/2072-4292/2/3/794 by Dowd and Fennel in Remote Sensing. It is geared towards oceanography/atmospheric sciences, but naturally it has applications to other fields as well. Now for the algorithm that you're looking for: What you wrote doesn't seem quite clear to me, so here's the pseudocode for what I mean. Let $(a,b)$ be the co-ordinate of a pixel in image $A$ with RGB value $(x,y,z)$ and $(a,b)$ be the co-ordinate of a pixel in image $B$ with RGB value $(m,n,p)$. The distance for pixel $(a,b)$ is therefore $(x-m,y-n,z-p)$, and you do a loop to go through all the co-ordinates. To compare image $A$ to image $B$ you have to compare the RGB values of the same co-ordinate. So you pictures have to be of the same size, pixel-wise.
