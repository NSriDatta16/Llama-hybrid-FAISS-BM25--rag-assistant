[site]: crossvalidated
[post_id]: 103230
[parent_id]: 
[tags]: 
How do we interpret model priors if models intersect?

Let $\Theta$ be some parameter space and $\Theta_1,\Theta_2,\dots,\Theta_s \subset \Theta$ be parameter subsets which represent competing models in some model selection procedure. There are no assumptions about containment or disjointness of the $\Theta_i$ made. The fundamental postulate of Bayesian model selection is that posterior probability of model $\Theta_i$ is computed according to Bayes rule $$P(\Theta_i | D) \propto P(\Theta_i) \int_{\Theta_i} L (\theta | D) dQ_i(\theta) $$ where $D$ stands for the data, $L$ the likelihood, $Q_i$ the conditional prior distribution of model $\Theta_i$, and $P(\Theta_i)$ the prior. My question is: What do we mean by the prior probability $P(\Theta_i)$? The prior should express our a priori belief of $\Theta_i$ being the right model in some sense, so one might come up with something like $\text{Prob}(\theta_0 \in \Theta_i)$, where $\theta_0$ is the true parameter generating the data (assuming one for now). However, this definition does not work because the true parameter may well be contained in several models. Another way to ask the question: Assume I know the true parameter $\theta_0$, which prior should I choose? Do we have to let go of the notion of an unknown true parameter? Is modeling with overlapping sets $\Theta_i$ inconsistent?
