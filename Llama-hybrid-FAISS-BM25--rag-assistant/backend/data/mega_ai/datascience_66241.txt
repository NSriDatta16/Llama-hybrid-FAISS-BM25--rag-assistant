[site]: datascience
[post_id]: 66241
[parent_id]: 
[tags]: 
Proper loss function for sequence prediction model with multi-step output

Consider a typical time series (sequence) prediction problem that use previous $k$ step historical features to predict the next step target. We use RNN model as an example. As shown in the picture, { $x_0$ ,..., $x_k$ } is the sequence of historical features used to predict the target $y_{k+1}$ at step $k+1$ . Typical method uses only the final output $\hat{y}_{k+1}$ for training and the corresponding loss will be, for example, mse as $||y_{k+1}-\hat{y}_{k+1}||_2$ . Thus, I have following few questions. Q1: Though { $y_1,...,y_k$ } is known at time step $k$ , will it be better to use last multiple (even all) steps of outputs for prediction than using only the last one $\hat{y}_k$ ? For example, using mse for multiple steps outputs as $$loss=\frac{1}{N+1}\cdot\sum_{n=0}^{N} ||\hat{y}_{k+1-n}-y_{k+1-n}||_2 $$ Q2: How to choose a proper loss function for multiple outputs ? It seems the multi-step mse is not a good choice when the rank between $y$ and $\hat{y}$ is prefered than absolute deviation.
