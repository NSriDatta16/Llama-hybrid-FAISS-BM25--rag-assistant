[site]: datascience
[post_id]: 109416
[parent_id]: 
[tags]: 
Assess overfitting - All model metrics or only specific metric?

I am working on a binary classification using random forest with 977 records with 77:23 class proportion I got the below performance in train and test data (AUC = 81) Train data Test data My metric of interest is F1-score because my dataset is imbalanced. So, based on the above classification report, we can infer that drop in F1-score is not huge between train and test. Am I right to understand that? How much is considered a huge drop? Should I be worried about Precision and Recall values being dropped heavily? I don't assess my model based on precision and recall indvidually. Should I just focus on F1 and conclude whether my model is overfit or not? Or all the metrics should have some decent/gradual drop? If we see 1.00 for any of the metric, is it sure shot way to say that model is overfitting? update - new run screnshot - 7 point drop in f1-score
