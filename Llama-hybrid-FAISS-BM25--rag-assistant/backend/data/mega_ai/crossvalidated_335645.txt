[site]: crossvalidated
[post_id]: 335645
[parent_id]: 335520
[tags]: 
No: building confidence intervals by using extreme values of previous confidence intervals does not work. For example, please take a look here: ( pdf ). The point is that such approach would work if confidence intervals contained the true parameter value with $100\%$ probability since, if two parameters are certainly between $2$ and $4$, then their sum is certainly between $4$ and $8$. But $($considering two variables $X_1$ and $X_2$ with the same variance $SE^2)$ if there is a $95\%$ probability that the interval $(2,4)$ contains the true values of both parameters, then there is no reason for the probability of the $(4,8)$ interval containing the true value to be $95\%$, unless the correlation between the two intervals is $1$ (so that you are basically considering a unique interval and multiplying it by two). For example, if the two quantities are independent, the variance of the sum will be twice the variance of single values, so the standard error of the sum will be given by the SE of single values multiplied by $\sqrt{2}$, so that: $SE (X_1+X_2) = \sqrt{2}*SE$, thus the confidence interval will be shorter than the sum of single confidence intervals. So, if the $Y_i, 1 \leq i \leq n$ have a multivariate normal distribution, you can calculate the variance of $Y=\sum_i^n a_iY_i$ by using variances and covariances. In case of independence of the $Y_i$, you would have that: $SE^2(Y)=\sum_i^n a_i^2 SE^2(Y_i)$, and from that formula you could derive your $SE(Y)$ to build your confidence interval for $Y$ (of course, you should add covariances to your formula, in case they are not null). EDIT 24/03/2018 If your variables are not normally distributed, in case your observations $a_i*Y_i$ are i.i.d. you can still rely on the Central Limit Theorem if the sample is large enough (the sample size required for the CLT to hold depends on how far from Normality your distribution is, but $30$ is usually suggested as a rule of thumb). If you can group your dataset in sets of $30+$ i.i.d. observations, then you would still have an approximate Gaussian distribution if multi-normality holds for the sum of variables in each set (given your quantity $Y$ would be the sum of normally distributed variables). Otherwise you can't assume normality of your sum, unless you assume again multinormality of your $Y_i$'s. Also, you need to know the correlation structure of your variables $Y_1, \dots, Y_n$. For example, if the correlation between all variables is $+1$, or if it is $+1$ for some pairs and $-1$ for others, you would actually have just $1$ observation. The point is: to know the variance of a sum of normally distributed variables (when joint normality holds), you would need to know their covariance matrix. EDIT 25/03/2018 Yes: if both the $X_i$ and the random errors $\epsilon_i$ are jointly independent (and obviously also independence between the $X$’s and the $\epsilon$’s hold, and $Y_i = \alpha_i + \beta_i X_i+\epsilon_i$ $\forall i$ in $(1, \dots, n)$, then you have $Y_i$’s are also jointly independent,thus the same holds for $Z_i=a_i*Y_i$ sequence (since $a_i$ is a sequence of constant values). And yes, I agree with you: at the end of the day you have to check whether you can apply the Lindeberg condition for your $Z_i$ sequence. Again yes, the modified version equally apply to sums or averages (given if Z has a normal distribution, then also W_1=Z/n and W_2=Z*n are normally distributed). As for your covariance matrix, the independence between $X_i$ and $Y_j$, the one between $X_i$ and $X_j$ and the one between $Y_i$ and $Y_j$, imply that their covariances are all zero. Thus, you just have to calculate the covariance of each ($X_i, Y_i$) pair.
