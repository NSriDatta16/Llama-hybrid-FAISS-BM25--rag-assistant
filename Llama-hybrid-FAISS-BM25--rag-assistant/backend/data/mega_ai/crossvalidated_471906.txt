[site]: crossvalidated
[post_id]: 471906
[parent_id]: 
[tags]: 
Does distance from the decision boundary suggest higher confidence that the class prediction is correct using SVM?

Does further distance from the decision boundary threshold suggest higher confidence that the class prediction is correct when using SVM with probability estimates enabled? This is not a question about cross-validation. This is a question about decision boundaries for an existing model. Can prediction confidence be inferred from the distance from the decision boundary? Does the distance actually have any meaning? Does the meaning of the distance change depending on the svm kernel used or the hyper-parameters used? With a binary classification task, the default boundary being 0.5, where probability 0.5 class = +1, would there be any difference in the confidence that a class prediction is correct between probabilities of 0.0 to 0.5 (-1), and 0.5 to 1.0 (+1)?
