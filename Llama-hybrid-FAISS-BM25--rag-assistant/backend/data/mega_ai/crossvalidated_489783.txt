[site]: crossvalidated
[post_id]: 489783
[parent_id]: 486708
[tags]: 
We can treat Machine Learning book by Mitchell (1997) as an authoritative reference on this subject. On p. 67 he defines overfitting Definition: Given a hypothesis space $H$ , a hypothesis $h \in H$ is said to overfit the training data if there exists some alternative hypothesis $h' \in H$ , such that $h$ has smaller error than $h'$ over the training examples, but $h'$ has a smaller error than $h$ over the entire distribution of instances. Say, that you are given a sample of points from a noiseless polynomial function. You are to find the function using the polynomial regression model. You can easily imagine how given small sample, you could find many different solutions that fit the training sample perfectly, though do not fit well the entire distribution. An extreme case would be single datapoint, in such case finding the correct model would be impossible, so the solution would surely not generalize. Someone can argue, that the above example does not fit the definition, since $h$ fits the training data equally well as $h'$ , so this does not satisfy the definition criteria. My counterargument is, that in such case many big enough neural networks can't overfit as well, you just need make them fit the training data perfectly. Another argument, may be that the example misses the point, since overfitting is about model fitting to noise, rather than to signal, hence it does not generalize. First, the definition above does not say anything about the noise. Second, if that would be the case, than we must conclude that the definition does not apply noiseless functions, so there is no answer to this question.
