[site]: crossvalidated
[post_id]: 159201
[parent_id]: 159093
[tags]: 
It is certainly not true that the human brain only uses "a few" convolutional layers. About 1/3 of the primate brain is somehow involved in processing visual information. This diagram, from Felleman and Van Essen is a rough outline of how visual information flows through the monkey brain, beginning in the eyes (RGC at the bottom) and ending up in the hippocampus, a memory area. Each one of these boxes is a anatomically-defined area (more or less), which contains several processing stages (actual layers, in most cases). The diagram itself is 25 years old and if anything, we've learned that there are a few more boxes and a lot more lines. It is true that a lot of the deep learning work is more "vaguely inspired by" the brain than based on some underlying neural truth. "Deep learning" also has the added advantage of sounding a lot sexier than "iterated logistic regression." However, mathematical models of neural networks have also contributed a lot to our understanding of the brain. At one extreme, some models attempt to mimic the known biology and biophysics precisely. These typically include terms for individual ions and their flow. Some even use 3D reconstructions of real neurons to constrain their shape. If this interests you, ModelDB has a large collection of models and the associated publications. Many are implemented using the freely-available NEURON software. There are larger-scale models that attempt to mimic certain behavioral or neurophysiological effects, without worrying too much about the underlying biophysics. Connectionist or Parallel-Distributed-Processing models, which were particularly popular in the late 1980s and 1990s and used models similar to those you might find in a current machine learning application (e.g., no biophysics, simple activation functions and stereotyped connectivity) to explain various psychological processes. These have fallen a little out of vogue, though one wonders if they might make a comeback now that we have more powerful computers and better training strategies. (See edit below!) Finally, there is a lot of work somewhere in the middle which includes some "phenomenology", plus some biological details (e.g., an explicitly inhibitory term with certain properties, but without fitting the exact distribution of chloride channels). A lot of current work fits into this category, e.g., work by Xiao Jing Wang (and many others....) EDIT : Since I wrote this, there's been an explosion of work comparing the (real) visual system to deep neural networks trained on object recognition tasks. There are some surprising similarities. Kernels in the first layers of a neural network are very similar to the kernels/receptive fields in primary visual cortex and subsequent layers resemble the receptive fields in higher visual areas (see work by Nikolaus Kriegeskorte, for example ). Retraining neural networks can cause similar changes to extensive behavioral training (Wenliang and Seitz, 2018) . DNNs and humans sometimes --but not always --make similar patterns of errors too. At the moment, it's still rather unclear whether this reflects similarity between real and artificial neural networks in general, something about images specifically[*], or the tendency for neural networks of all stripes to find patterns, even when they aren't there. Nevertheless, comparing the two has become an increasingly hot area of research and it seems likely that we'll learn something from it. * For example, the representation used in the early visual system/first layers of a CNN is an optimal sparse basis for natural images.
