[site]: datascience
[post_id]: 22418
[parent_id]: 22335
[tags]: 
In the blog posting cited in the question, the discussion is about the fact that the experts who develop machine learning models in finance can't explain to their customers (financiers with no training in machine learning) how the model makes the decisions that it does. This brings out a distinction between models that are black boxes because of information that is truly secret (e.g. the coefficients are encoded in a tamper proof FPGA) and models that are open (in the sense that the coefficients are known) but not comprehensible to a particular audience . This latter kind of "black box" is problematic because customers want to reassure themselves that the model you've constructed has "face validity." With other types of models such as Logistic Regression, it's relatively easy to look at the coefficients and check that they have the expected plus or minus signs- even a mathematically illiterate MBA can understand that.
