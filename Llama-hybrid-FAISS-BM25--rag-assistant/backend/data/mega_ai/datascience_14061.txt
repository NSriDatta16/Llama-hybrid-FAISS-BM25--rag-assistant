[site]: datascience
[post_id]: 14061
[parent_id]: 14002
[tags]: 
What some people do is some kind of 'ordered' k-fold cross validation. (Check here , for instance.) You partition the data into $k$ partitions. Then, you fit the model on the partition 1, test on partition 2, get prediction error. Then, you fit the model on the union of partitions 1 and 2, test on partition 3, get prediction error. So on so forth, then average the prediction errors.
