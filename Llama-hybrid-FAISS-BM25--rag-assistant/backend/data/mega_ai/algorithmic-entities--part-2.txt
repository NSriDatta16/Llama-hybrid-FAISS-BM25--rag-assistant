 agrees with Bayern on the existence of a ‘loophole’ whereby an AI system could “effectively control a LLC and thereby have the functional equivalent of legal personhood”. Bayern's loophole of “entity cross-ownership” would work as follows: (1) Existing person P establishes member-managed LLCs A and B, with identical operating agreements both providing that the entity is controlled by an autonomous system that is not a preexisting legal person; (2) P causes A to be admitted as a member of B and B to be admitted as a member of A; (3) P withdraws from both entities. Unlike the zero member LLC, the entity cross-ownership would not trigger a response by the law for having a memberless entity as what remains are two entities each having one member. In corporations, this sort of situations is often prevented by formal provisions in the statutes (predominantly for voting rights for shares), however, such limitations do not seem to be in place for LLCs as they are more flexible in arranging control and organization. Europe In Europe, certain academics from different countries have started to look at the possibilities in their respective jurisdictions. Bayern et al. (2017) compared the UK, Germany and Switzerland to the findings of Bayern (2016) earlier for the US to see whether such “loopholes” in the law exist there as well to set up an algorithmic entity. Some smaller jurisdiction are going further and adapting their laws for the 21st century technological changes. Guernsey has granted (limited) rights to electronic agents and Malta is currently busy creating a robot citizenship test. While it is unlikely the EU would allow for AI to receive legal personality at this moment, the European Parliament did however request the European Commission in a February 2017 resolution to “creating a specific legal status for robots in the long run, so that at least the most sophisticated autonomous robots could be established as having the status of electronic persons responsible for making good any damage they may cause, and possibly applying electronic personality to cases where robots make autonomous decisions or otherwise interact with third parties independently”. Not all parts of the supranational European bodies agreed as the European Economic and Social Committee gave in its own initiative an opposing opinion given May 2017: “The EESC is opposed to any form of legal status for robots or AI (systems), as this entails an unacceptable risk of moral hazard. Liability law is based on a preventive, behavior-correcting function, which may disappear as soon as the maker no longer bears the liability risk since this is transferred to the robot (or the AI system). There is also a risk of inappropriate use and abuse of this kind of legal status.” In reaction to the European Parliament's request, the European Commission set up a High Level Expert Group to tackle issues and take initiative in a number of subjects relating to automation, robotics and AI. The High Level Expert Group released a draft document for AI ethical guidelines and a document defining AI in December 2018. The document on ethical guidelines was opened for consultation and received extensive feedback. The European Commission is taking a careful approach legislating AI by emphasizing on ethics, but at the same time – as the EU is behind in AI research to the United States and China – focusing on how to narrow the gap with competitors by creating a more inviting regulatory framework for AI research and development. Giving (limited) legal personality to AI or even allow certain forms of algorithmic entities might create an extra edge. == References ==