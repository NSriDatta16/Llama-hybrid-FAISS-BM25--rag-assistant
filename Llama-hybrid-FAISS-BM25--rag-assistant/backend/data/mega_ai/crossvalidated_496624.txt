[site]: crossvalidated
[post_id]: 496624
[parent_id]: 496623
[tags]: 
The Law of Large Numbers concerns the sample average, whereby as the sample size increases, the sample average converges towards the expected value. So in your case you would sample from the distribution and take the mean. Then as you repeat the sampling, each time increasing the sample size, the mean of the samples will approach the expected value. I have often explained this to students with a simple example of rolling a fair 6-sided dice. The expected value is 3.5 obviously. First, note that we can never obtain 3.5 in a single roll. With 1 roll we would obtain any of the 6 possibilities with probability 1/6. As we increase the sample size, the sample mean will approach 3.5. We can show this in R as follows: We will sample from a uniform discrete distribution on the integers 1 to 6, starting with a sample size of 1 and increaseing the sample size to 1000. Each time we will compute the sample mean, and finally we will plot the means vs the sample size: set.seed(15) N
