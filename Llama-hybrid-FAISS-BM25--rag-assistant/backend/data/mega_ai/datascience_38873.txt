[site]: datascience
[post_id]: 38873
[parent_id]: 
[tags]: 
Am I missing something about LSTM?

I have imbalanced data that I pass through a LSTM network. Here is part of my code : weights = class_weight.compute_class_weight('balanced',np.unique(trainY),trainY) print (weights) model = Sequential() model.add(LSTM(64, input_shape=(look_back, trainX.shape[2]), recurrent_dropout=0.3, return_sequences=True)) # model.add(Dropout(0.3)) model.add(LSTM(32, recurrent_dropout=0.3)) model.add(Dense(1, activation='sigmoid')) print (model.summary()) model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy']) model.fit(trainX, trainY, validation_data=(validX, validY), epochs=100, batch_size=16, class_weight=weights, verbose=1 , callbacks=callbacks_list, shuffle=True) Weights are [0.6147541 2.67857143] seeing good imbalance. However, when I print confusion matrices (for each set), I only get 0 predicted. How my data are shaped. Actually, each 2-D sequence in input of a LSTM is of size (time_step, features) right ? Here I use time_step of 1 (and features =22 , don't matter). So that means that's the same as if I took each sample of my time serie one-by-one. When I increase time_step to something like 5, it works slightly better but I still get a too high number of "false 0" (0 is the biggest represented class) though a few-layers-MLP works very well on the same data with class_weight parameter. Am I doing something wrong with LSTM ? Here is how the sequences are built: look_back is the size of the sliding window of instants centered around the current time step that I take and the windows overlap : def create_dataset(feat,targ, look_back=2): semi_window=math.floor(look_back/2) dataX, dataY = [], [] for i in range(semi_window,len(targ)-semi_window): a = feat[i-semi_window:(i+semi_window+1), :] dataX.append(a) dataY.append(targ[i]) return np.array(dataX), np.array(dataY) I am really waiting for help because it seems to give performances under simple MLP for example, while it's made to learn temporal dependencies on time series...
