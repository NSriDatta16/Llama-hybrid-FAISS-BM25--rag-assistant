[site]: crossvalidated
[post_id]: 79391
[parent_id]: 
[tags]: 
Approximate function observed through noise

I have a function $f : [a,b] \rightarrow \mathbb{R}$ that I can observe through some noise, i.e. I can only directly measure $f(x) + \eta$ where $\eta$ is some random noise with mean 0. I have a large number of noisy observations of this function, $f_i$, at different arguments $x_i$. What is a good way to approximate the function for any $x \in [a,b]$? If I had several observations of $f(x_0)$ at the same $x_0$ then I could average over these to estimate the true $f(x_0)$. But while I have a relatively large number of observations, each one is at a different argument $x_i$. What is the best course of action in this case? I have no background in statistics so excuse me if this is a basic question. What I'd like t know is if there's some sane theory to handle these situation (which would be much better than myself coming up with some ad-hoc solution such as moving averages). The names of some methods I could use would be sufficient, I can look up the details. Note: I would like to use the approximated $f$ mainly for things such as optimization and finding zero crossings. My data is similar to this artificially generated dataset (Mathematica code): n = 500; data = {#, Sin[#] + RandomReal[.1 {-1, 1}]} & /@ RandomReal[{0, 2 Pi}, n]; ListPlot[data]
