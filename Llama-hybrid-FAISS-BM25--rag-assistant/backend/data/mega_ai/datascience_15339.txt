[site]: datascience
[post_id]: 15339
[parent_id]: 
[tags]: 
Testing a tensorflow network: in_top_k() replacement for multilabel classification

I've created a neural network in tensorflow. This network is multilabel. Ergo: it tries to predict multiple output labels for one input set, in this case three. Currently I use this code to test how accurate my network is at predicting the three labels: _, indices_1 = tf.nn.top_k(prediction, 3) _, indices_2 = tf.nn.top_k(item_data, 3) correct = tf.equal(indices_1, indices_2) accuracy = tf.reduce_mean(tf.cast(correct, 'float')) percentage = accuracy.eval({champion_data:input_data, item_data:output_data}) That code works fine. The problem is now that I'm trying to create code that tests if the top 3 items it finds in indices_1 are amongst the top 5 images in indices_2. I know tensorflow has an in_top_k() method, but as far as I know that doesn't accept multilabel. Currently I've been trying to compare them using a for loop: _, indices_1 = tf.nn.top_k(prediction, 5) _, indices_2 = tf.nn.top_k(item_data, 3) indices_1 = tf.unpack(tf.transpose(indices_1, (1, 0))) indices_2 = tf.unpack(tf.transpose(indices_2, (1, 0))) correct = [] for element in indices_1: for element_2 in indices_2: if element == element_2: correct.append(True) else: correct.append(False) accuracy = tf.reduce_mean(tf.cast(correct, 'float')) percentage = accuracy.eval({champion_data:input_data, item_data:output_data}) However, that doesn't work. Mainly because I don't have a clue what I'm doing when it comes to tf.unpack and tf.transpose. If I leave the transpose out it gives the following error: ValueError: Cannot infer num from shape (?, 5) If the transpose is in there the code runs but my accuracy is always 0.0. So I have one of two questions: 1) Is there an easy replacement for in_top_k() that accepts multilabel classification that I can use instead of custom writing code? 2) If not 1: what am I doing wrong that results in me getting an accuracy of 0.0?
