[site]: datascience
[post_id]: 79837
[parent_id]: 79787
[tags]: 
If you have 5 layers in your model, your data basically gets transformed 5 times via 5 activation functions. That is not completely true. For dense neural networks (for example), your layers are made by neurons that each has its own activation function (so you'll have more than 5 activation functions). Each neuron transforms your data. Now what is a cell ? A cell is a mathematical function that receives one or more input, does the math, and gives one or more outputs. First some examples: neuron: the result is the output of an activation function applied to the weighted sum of the previous layer convolution cell: passes the result of a convolution kernel multiplied to a relative range of the cells of the immediately previous layer to the next layer a lot of other cell examples in this post Why are they called "cells" ? Because those mathematical function are used in artifical neural networks (ANN) context. Why do they have a name ? Because they work well in (some) ANN, so people share their new mathematical function that helps an ANN to converge given a specific problem.
