[site]: crossvalidated
[post_id]: 501702
[parent_id]: 500949
[tags]: 
I think you're mixing up How to compute or approximately compute $P(X)$ The "generative story" Also, I might be wrong on this, but based on the last paragraph, it sounds like you're confusing $X$ with the entire dataset, whereas the notation in the article you linked uses $X$ to mean just one point in the dataset. $x_i$ are meant to be the individual components of vector $X$ . The two steps you described are one way to compute (1) -- density at some single data point $X$ . As it turns out, this is too inefficient in practice, so people use the "variational lower bound", or "ELBO", to obtain a non stochastic, non exact, but guaranteed lower bound on $P(X)$ . The generative story goes like this: we sample some $z$ from a distribution $p(z)$ , usually standard normal. compute $\mu = f(z;\theta)$ we draw $X$ from $P(X|z)$ -- to be more precise, we draw from a normal distribution with the previously computed mean $\mu$ . Also regarding the last paragraph: you can abstractly think of $z$ as some "blueprint" for the generated data $X$ . According to our generative story, a single $z$ can result in different $X$ , because there's some randomness involved. And it is possible, although extremely unlikely, that a $z$ which usually generates the digit "3" might somehow generate the digit "8", because randomness is involved.
