[site]: crossvalidated
[post_id]: 642968
[parent_id]: 
[tags]: 
Point-level prediction intervals in LightGBM models

I would like to compute prediction intervals for LightGBM at the sample level. In other words, given a certain row to be classified (supervised classification, not regression), what is the upper bound for my prediction, and the lower bound for my prediction, with a 90% certainty. I have thought a bit about possible approaches: Data density-based: ideally, this uncertainty would be linked to how likely it is to find this sample within the training dataset. There are a number of methods to estimate the underlying probability density function for a given sample - but I could not find a way to relate it with a confidence interval output. My only idea would be to use the density estimator to determine what is and isn't an outlier by establishing a 90-percentile range around the density scores - and then getting the performance variation for each group GBM-specific methods: I have read some ideas about how this could be achieved - but none has satisfactory answers. They share doing some computation to the contributions of the trees, but this presumes that each tree is random and somewhat independent of the other (i.e. a random forest), which is not the case for LightGBM. I have two proposals, and I would like to know which sounds more sane Bootstrapping the trees used to make a prediction: the final raw_score outputted by LightGBM is achieved by summing up the tree prediction of each individual tree that makes up the GBM. My assumption is that if we have a large number of trees, we could try sampling some ( without replacement), sum their contributions and we will get a different score. We could do this a large number of times, and we will get a distribution of scores, which we can then get confidence intervals from. Standard deviation of the trees: granted this one is the method presented in one the links, I would like to know your thoughts on whether it makes sense. Each tree can contribute 0 to the score, or a very large amount, so my expectation is to have a quite large standard dev (which will be even larger once we multiply it by 1.6 to get a 90% CI). Moreover, I'm not even sure if we could convert this raw score std to a final score std I would really appreciate your input on this. To me, the bootstrapping method makes sense, but makes me a bit uneasy since we are randomly sampling trees that were not built randomly and complement each other (if we sample trees 0 1 2 and 4 its as if we are getting an output from a model that could never exist, since tree 4 would never be built without doing tree 3 first). OTOH, it sounds good. Bonus question: how does one evaluate the correctness of the provided confidence intervals? How can I determine that one method of CI computation is better than another method?
