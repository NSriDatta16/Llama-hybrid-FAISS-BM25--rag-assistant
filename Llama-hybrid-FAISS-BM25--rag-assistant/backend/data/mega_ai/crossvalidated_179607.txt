[site]: crossvalidated
[post_id]: 179607
[parent_id]: 174856
[tags]: 
Without example prototypes for the additional groups D,E,etc, identifying them as independent clusters may or may not be needed. If the data can be modeled well by something like a gaussian mixture model, a well-fit model may indeed involve identification of these extra groups. However, such methods are largely unsupervised in nature... there is little need or use for the prototypes you have for A,B,C beyond seeding the collection. Another method would be to tune a classification model using your labeled dataset, and then apply it to the unlabeled set to obtain an expected classification. Define a threshold of uncertianty, and use items which do not classify below it to seed a new collection of items - that being your unknown new category. Use these new populations to retrain your classifiers. This method is generally known as the Expectation-Maximization algorithm in K-Means and Gaussian Mixture Models , but the general logic can be implemented using neural networks or random forests as classification engines as well. If you need to identify category structure within that newly-identified category, you will need to use an unsupervised technique such as clustering. The other way to identify the new category is certain "single-class" classifiers whose intention is to identify population outliers. For example, single-class SVMs. I have also experimented with single-class decision trees. However, such methods would not use most of the data you have and I would not expect superior results.
