[site]: crossvalidated
[post_id]: 130065
[parent_id]: 129956
[tags]: 
Computing a joint distribution from conditional distributions in general is very difficult. If the conditional distributions are chosen arbitrarily, a common joint distribution might not even exist. In this case, even showing that the conditional distributions are consistent is generally difficult. One result that might be used for deriving a joint distribution is Brook's lemma , $$ \frac{p(\mathbf{x})}{p(\mathbf{x}')} = \prod_i \frac{p(x_i \mid \mathbf{x}_{ i})}{p(x_i' \mid \mathbf{x}_{ i})},$$ by choosing a fixed state $\mathbf{x}'$, although I have never successfully used it myself for that purpose. For more on that topic, I would look at Julian Besag's work. To prove that Gibbs sampling works, however, it's better to take a different route. If a Markov chain implemented by a sampling algorithm has distribution $p$ as invariant distribution, and is irreducible and aperiodic , then the Markov chain will converge to that distribution (Tierney, 1994) . Gibbs sampling will always leave the joint distribution invariant from which the conditional distributions were derived: Roughly, if $(x_0, y_0) \sim p(x_0, y_0)$ and we sample $x_1 \sim p(x_1 \mid y_0)$, then $$(x_1, y_0) \sim \int p(x_0, y_0) p(x_1 \mid y_0) \, dx_0 = p(x_1 \mid y_0) p(y_0) = p(x_1, y_0).$$ That is, updating $x$ by conditionally sampling does not change the distribution of the sample. However, Gibbs sampling is not always irreducible . While we can always apply it without breaking things (in the sense that if we already have a sample from the desired distribution it will not change the distribution), it depends on the joint distribution whether Gibbs sampling will actually converge to it (a simple sufficient condition for irreducibility is that the density is positive everywhere, $p(\mathbf{x}) > 0$).
