[site]: crossvalidated
[post_id]: 539549
[parent_id]: 
[tags]: 
What is the significance behind having small kernel sizes over having one large kernel size that covers the entire input in a CNN?

I have hardly ever seen anyone cover the entire input image with a filter of the same dimensions. I was wondering why that is the case, and if the performance in say, an image detection application would decrease if someone used kernel size = the size of the input image itself?
