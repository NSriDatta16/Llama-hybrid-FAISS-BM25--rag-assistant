[site]: datascience
[post_id]: 13029
[parent_id]: 
[tags]: 
What are the advantages / disadvantages of off-policy RL vs on-policy RL?

There are various algorithms for reinforcment learning (RL). One way to group them is by "off-policy" and "on-policy". I've heard that SARSA is on-policy, while Q-Learning is off-policy. I think they work as follows: My questions are: How exactly is "on-policy RL" and "off-policy RL" defined? What are the advantages / disadvantages of both?
