[site]: datascience
[post_id]: 412
[parent_id]: 
[tags]: 
How can I transform names in a confidential data set to make it anonymous, but preserve some of the characteristics of the names?

Motivation I work with datasets that contain personally identifiable information (PII) and sometimes need to share part of a dataset with third parties, in a way that doesn't expose PII and subject my employer to liability. Our usual approach here is to withhold data entirely, or in some cases to reduce its resolution; e.g., replacing an exact street address with the corresponding county or census tract. This means that certain types of analysis and processing must be done in-house, even when a third party has resources and expertise more suited to the task. Since the source data is not disclosed, the way we go about this analysis and processing lacks transparency. As a result, any third party's ability to perform QA/QC, adjust parameters or make refinements may be very limited. Anonymizing Confidential Data One task involves identifying individuals by their names, in user-submitted data, while taking into account errors and inconsistencies. A private individual might be recorded in one place as "Dave" and in another as "David," commercial entities can have many different abbreviations, and there are always some typos. I've developed scripts based on a number of criteria that determine when two records with non-identical names represent the same individual, and assign them a common ID. At this point we can make the dataset anonymous by withholding the names and replacing them with this personal ID number. But this means the recipient has almost no information about e.g. the strength of the match. We would prefer to be able to pass along as much information as possible without divulging identity. What Doesn't Work For instance, it would be great to be able to encrypt strings while preserving edit distance. This way, third parties could do some of their own QA/QC, or choose to do further processing on their own, without ever accessing (or being able to potentially reverse-engineer) PII. Perhaps we match strings in-house with edit distance But the only method I am familiar with that does this is ROT13 (more generally, any shift cipher ), which hardly even counts as encryption; it's like writing the names upside down and saying, "Promise you won't flip the paper over?" Another bad solution would be to abbreviate everything. "Ellen Roberts" becomes "ER" and so forth. This is a poor solution because in some cases the initials, in association with public data, will reveal a person's identity, and in other cases it's too ambiguous; "Benjamin Othello Ames" and "Bank of America" will have the same initials, but their names are otherwise dissimilar. So it doesn't do either of the things we want. An inelegant alternative is to introduce additional fields to track certain attributes of the name, e.g.: +-----+----+-------------------+-----------+--------+ | Row | ID | Name | WordChars | Origin | +-----+----+-------------------+-----------+--------+ | 1 | 17 | "AMELIA BEDELIA" | (6, 7) | Eng | +-----+----+-------------------+-----------+--------+ | 2 | 18 | "CHRISTOPH BAUER" | (9, 5) | Ger | +-----+----+-------------------+-----------+--------+ | 3 | 18 | "C J BAUER" | (1, 1, 5) | Ger | +-----+----+-------------------+-----------+--------+ | 4 | 19 | "FRANZ HELLER" | (5, 6) | Ger | +-----+----+-------------------+-----------+--------+ I call this "inelegant" because it requires anticipating which qualities might be interesting and it's relatively coarse. If the names are removed, there's not much you can reasonably conclude about the strength of the match between rows 2 & 3, or about the distance between rows 2 & 4 (i.e., how close they are to matching). Conclusion The goal is to transform strings in such a way that as many useful qualities of the original string are preserved as possible while obscuring the original string. Decryption should be impossible, or so impractical as to be effectively impossible, no matter the size of the data set. In particular, a method that preserves the edit distance between arbitrary strings would be very useful. I've found a couple papers that might be relevant, but they're a bit over my head: Privacy Preserving String Comparisons Based on Levenshtein Distance An Empirical Comparison of Approaches to Approximate String Matching in Private Record Linkage
