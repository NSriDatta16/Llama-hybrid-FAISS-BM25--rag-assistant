[site]: crossvalidated
[post_id]: 168711
[parent_id]: 168689
[tags]: 
I think (this interpretation of) Jaynes' statement is false. In theory of computer science, for example there is lots of effort put into derandomizing randomized algorithms. One (not very CS-y) example is the Miller Rabin algorithm . If you'd like to dig deeper into this, computer science theory stackexchange is the place to go. In computational physics \ science, many times (markov chain) monte carlo is the only way to go for exploring high dimensional probability distributions, where a the cost of using a uniform mesh is exponential in the dimension (integration on the unit cube with a 0.1 mesh costs $\mathcal{O}( 10^{d} )$ for $[0,1]^d$). Finally, in statistics - lets say you want to really know if smoking causes cancer. The simplest solution is to take two groups of people. Force one group to smoke and one to not smoke. Let them live (die?) and see which group outlives the other and by how much. This is a simple randomized experiment. But you can't do it in real life, so you have to use smarter statistical methods.
