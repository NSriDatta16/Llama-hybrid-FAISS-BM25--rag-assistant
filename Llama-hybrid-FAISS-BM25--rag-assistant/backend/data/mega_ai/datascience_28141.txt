[site]: datascience
[post_id]: 28141
[parent_id]: 
[tags]: 
Reusing a portion of a neural network (with shared weights) in Keras

I have a partial neural network with several layers of various types, with weights $\theta$; let's call it $F_{\theta}$; and the dimensions of input and output arrays are the same, implemented in Keras with Tensorflow backend. Within this framework, how do train a model of the form $y = F_{\theta}(F_{\theta}(x))$, or more generally some $n$-th iteration of $F_{\theta}$? In other words, I reuse an entire subset of the neural network, with all the same weights, so the full model is deeper but does not have more parameters than the shallower model.
