[site]: crossvalidated
[post_id]: 377903
[parent_id]: 
[tags]: 
Logistic regression with separation and nested design in R

Data: An item can be in the state 0 or 1 (binary). Each year, it starts in the state 0 and then changes to state 1. I have data of 4 seasons (2010 -2013). Each year I sampled the (same) individuals at different timesteps (depending on the year 20-25 timesteps during 6 months). The individuals are taken from different groups (same for all 4 seasons). I had 3 treatments and each individual of a group had one of these 3 treatments. Each individual each season has a different time of starting its development. For every timestep and every individual I know the time since it has started its development. I am interested in the time since development start at which individuals generally swap from state 0 to state 1 and whether this time differs between treatments and between years. Since shortly after the start of development the individuals are always in the state 0 and a certain time after start of development the individuals are always in state 0, time is in many cases a perfect predictor and leads to separation in the data. Since I am sampling the same individuals over time, I need to exactly reproduce the nested structure of my data in a random term of my model in order to avoid pseudoreplication. In R, I can deal with the pseudoreplication if I use a logistic model with a random structure: (YEAR | TIMESTEP/GROUP/INDIVIDUAL) and a fixed structure (TREATMENT * TIME * YEAR). Due to the separation in the data, such a model will not convert. I can deal with the separation in the data by using models which implement bias-reduction (e.g. Firth) as for example brglm or logistf. In these models I will have to treat everything as fixed effect and I will have the problem of pseudoreplication. With so many datapoints, all the model parameters will turn out to significantly influence the state Y (0/1). Do you know of any way to analyse such data? Are there any R packages that deal with separation and at the same time include random effects? Or is there any (better) way to analyse such data? Or any other way I can avoid pseudoreplication? I am glad for any input.
