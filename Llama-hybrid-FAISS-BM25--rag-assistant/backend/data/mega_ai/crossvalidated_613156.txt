[site]: crossvalidated
[post_id]: 613156
[parent_id]: 613128
[tags]: 
I would say that the "alternative hypothesis" is usually NOT a "proposed hypothesis". You do not define "proposed hypothesis" and it is not a common phrase. Presumably you mean that it is either a statistical hypothesis or it is a scientific hypothesis. They are usually quite different things. A scientific hypothesis usually concerns a something to do with the true state of the real world, whereas a statistical hypothesis concerns only conditions within a statistical model. It is very common for the real world to be more complicated and less well-defined than a statistical model and so inferences regarding a statistical hypothesis will need to be thoughtfully extrapolated to become relevant to a scientific hypothesis. For your example a scientific hypothesis concerning the two drugs in question might be something like 'drug x can be substituted for drug y without any noticeable change in results experienced by the patients'. A relevant statistical hypothesis would be much more restricted along the lines of 'drug x and drug y have similar potencies' or that 'drug x and drug y have similar durations of action' or maybe 'doses of drug x and drug y can be found where they have similar effects'. Of course, the required degree of similarity and the assays used for evaluation of the statistical hypothesis will have to be defined. Apart from the enormous differences in scope of the scientific and potential statistical hypotheses, the first may require several or all of the others to be true. If you want to know if a hypothesis is a statistical hypothesis then if it concerns the value of a parameter within a statistical model or can be restated as being about a parameter value, then it is. Now, the "alternative hypothesis". For the hypothesis testing framework there are two things that are commonly called 'alternative hypotheses'. The first is an arbitrary effect size that is used in the pre-data calculation of test power (usually for sample size determination). That alternative hypothesis is ONLY relevant before the data are in hand. Once you have the data the arbitrarily specified effect size loses its relevance because the observed effect size is known. When you perform the hypothesis test the effective alternative becomes nothing more than 'not the null'. It is a bad mistake to assume that a rejection of the null hypothesis in a hypothesis test leads to the acceptance of the pre-data alternative hypothesis, and it is just about as bad to assume that it leads to the acceptance of the observed effect size as a true hypothesis. Of course, the hypothesis test framework is not the only statistical approach, and I would argue, it is not even the most relevant to the majority of scientific endeavours. If you use a likelihood ratio test then you can compare the data support for two specified parameter values within the statistical model and that means that you can do the same within a Bayesian framework.
