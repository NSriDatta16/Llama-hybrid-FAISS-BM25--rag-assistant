[site]: crossvalidated
[post_id]: 631439
[parent_id]: 631432
[tags]: 
Limited Information Setting aside my grief about Cronbach's alpha for a second (see Flora, 2020 for a full accounting), I would generally advise against ever having just two questions for measuring a latent construct. While it is certainly possible to achieve, there are a number of issues that can arise such as yours with such limited information: With just two items, your variance between items is very limited and thus provides less information/precision about your construct (Eisinga et al., 2013). This becomes magnified when the number of responses is very limited (such as a binary response, see Simms et al., 2019). Coefficient alpha is prone to inflation simply by adding items (because of the formulation of alpha determines this), but that is another story. If you are fitting this to a latent variable modeling framework, this will result in under-identified models (see here ). Because I am more partial to McDonald's omega coefficient, this would be a problem for me if I wanted to get factor loadings to estimate the reliability. How come I get the negative score, and what can I do to correct this? Or, would you recommend a different test altogether, for this data set? It doesn't sound like this was done based on previous research. See what others have done and what has worked first. I would then rerun a pilot using more items and items that in the research are more likely to approximate your latent construct (see Thabane et al., 2010 for a guide on pilot studies). Then based off the results you can tweak that to see what makes the most sense for capturing your latent variable. Then after you can run a full scale study with more participants and measure what this looks like. Edit Christian noted that my concerns about alpha items is not warranted. Remember that the formula for Cronbach's alpha is defined as: $$ a = \frac{k}{k-1}(1-\frac{\sum_{k=1}^k {\sigma^2_{y}}_i}{\sigma_y}) $$ where $k$ is the number of items and $\sigma^2_y$ is the variance of the items. Notice that one increases the alpha ipso facto the inclusion of the $k$ parameter in this formula. To test this, we can run a simple simulation of weakly correlated variables ( $r=.10$ ) and see how the number of items may increase the alpha coefficient. Running a simulation with a substantial number of items for this e.g. $k > 100$ or boots makes this simulation slow, so I just use $k for this simulation, which draws a sample of $n=500$ subjects (to stabilize estimation), and $B=100$ simulations (to include uncertainty). The code: #### Load Libraries #### library(psych) library(MASS) library(tidyverse) set.seed(123) #### Sim Data and Coefficient #### simulate_alpha $total$ raw_alpha) } #### Define Items and Sims #### num_items We can see that even with poor correlations for the items, our alpha coefficient almost necessarily increases until reaching an upper boundary near $a = .90$ . This is despite the fact that the items are tau equivalent, as they should all be close to the same correlation. For a relevant paper which discusses this point, see Kopalle & Lehmann, 1997, which shows that alpha can mask uncorrelated items for this very reason. Notice also that alpha estimation is very unstable with even 5 items, whereas as items increase, the uncertainty in the estimate decreases and becomes more consistent: Note that this simulation is very slow. This specific run took about 3 minutes. One can modify the parameters of this simulation from my script by changing the correlation or the items to see how this is affected over a range of values (strong correlations between items for example basically net very little increase in alpha, which makes sense). As to the commentary about under-identification, from the link I provided: Technically a three item CFA is the minimum number of items for a one factor CFA as this results in a saturated model where the number of free parameters equals to number of elements in the variance-covariance matrix (i.e., the degrees of freedom is zero). Suppose that one of the data collectors accidentally lost part of the survey and we are left with only Items 4 and 5 from the SAQ-8. When there are only two items, you have $2(3)/2 = 3$ elements in the variance covariance matrix. As you can see in the path diagram below, there are in fact five free parameters: two residual variances , two loadings and a factor variance. Even if we used the marker method, which the default, that leaves us with one less parameter, resulting in four free parameters when we only have three to work with. References Eisinga, R., Grotenhuis, M. T., & Pelzer, B. (2013). The reliability of a two-item scale: Pearson, Cronbach, or Spearman-Brown? International Journal of Public Health, 58(4), 637–642. https://doi.org/10.1007/s00038-012-0416-3 Flora, D. B. (2020). Your coefficient alpha is probably wrong, but which coefficient omega is right? A tutorial on using R to obtain better reliability estimates. Advances in Methods and Practices in Psychological Science, 3(4), 484–501. https://doi.org/10.1177/2515245920951747 Kopalle, P. K., & Lehmann, D. R. (1997). Alpha inflation? The impact of eliminating scale items on Cronbach’s alpha. Organizational Behavior and Human Decision Processes, 70(3), 189–197. https://doi.org/10.1006/obhd.1997.2702 Simms, L. J., Zelazny, K., Williams, T. F., & Bernstein, L. (2019). Does the number of response options matter? Psychometric perspectives using personality questionnaire data. Psychological Assessment, 31(4), 557–566. https://doi.org/10.1037/pas0000648 Thabane, L., Ma, J., Chu, R., Cheng, J., Ismaila, A., Rios, L. P., Robson, R., Thabane, M., Giangregorio, L., & Goldsmith, C. H. (2010). A tutorial on pilot studies: The what, why and how. BMC Medical Research Methodology, 10(1), 1. https://doi.org/10.1186/1471-2288-10-1
