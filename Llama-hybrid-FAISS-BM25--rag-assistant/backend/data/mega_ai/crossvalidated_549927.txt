[site]: crossvalidated
[post_id]: 549927
[parent_id]: 549886
[tags]: 
The question is asking about whether the two conditional distributions are sufficient for construction of a joint distribution. Recall that conditional distributions are ratios of a joint and a marginal. So that a ratio of the two will cancel and you'll be left with a ratio of two marginals: $$\sum_{\forall x}\frac{p_A(x|y)}{p_B(y|x)} = \sum_{\forall x}\frac{p_A(x,y)p_B(x)}{p_A(y)p_B(y,x)}$$ Now if we are willing to assume that $ p_A(x,y) \equiv p_B(x,y)$ then these joint distributions cancel and you'll get $$\sum_{\forall x}\frac{p_B(x)}{p_A(y)} = \frac{1}{p_A(y)}.$$ So write $$\frac{p_A(x|y)}{\sum_{\forall x}\frac{p_A(x|y)}{p_B(y|x)}} = p_A(x|y)p_A(y)$$ which is the joint distribution by definition. Note we needed to assume the the joint distributions are the same and that the joint distributions exist, this latter point is crucial for continuous distributions. Also, similar reasoning can get the joint distribution from lab B, just switch the numerator and denominator and sum over $y$ instead of $x$ . This sort of result is often referred to as the Clifford-Hammersley theorem in the MCMC literature.
