fect standard of wins; the algorithm will draw random uncertain conclusions each time. After the j-th round, the correlation of near-perfect play runs: 1 − D D − D ( j + 2 ) ∑ i = 0 j D ( j i + 1 ) V i {\displaystyle {1-D \over D-D^{(j+2)}}\sum _{i=0}^{j}D^{(ji+1)}V_{i}} Where Vi is the outcome (+1 is win, 0 is draw and -1 is loss) and D is the decay factor (average of past values of wins and losses). Below, Mn is the multiplier for the n-th round of the game. Legacy Donald Michie's MENACE proved that a computer could learn from failure and success to become good at a task. It used what would become core principles within the field of machine learning before they had been properly theorised. For example, the combination of how MENACE starts with equal numbers of types of beads in each matchbox, and how these are then selected at random, creates a learning behaviour similar to weight initialisation in modern artificial neural networks. In 1968, Donald Michie and R.A Chambers made another BOXES-based algorithm called GLEE (Game Learning Expectimaxing Engine) which had to learn how to balance a pole on a cart. After the resounding reception of MENACE, Michie was invited to the US Office of Naval Research, where he was commissioned to build a BOXES-running program for an IBM Computer for use at Stanford University. Michie created a simulation program of MENACE on a Pegasus 2 computer with the aid of D. Martin. There have been multiple recreations of MENACE in more recent years, both in its original physical form and as a computer program. Its algorithm was later converged into Christopher Watkin's Q-Learning algorithm. Although not as a functional computer, in examples of demonstration, MENACE has been used as a teaching aid for various neural network classes, including a public demonstration from University College London researcher Matthew Scroggs. A copy of MENACE built by Scroggs was featured in the 2019 Royal Institution Christmas Lectures, and in a 2023 episode of QI XL. MENACE is referenced in Fred Saberhagen's 1963 short story Without A Thought, and Thomas J Ryan's 1977 novel The Adolescence of P-1. In her 2023 book The Future, author Naomi Alderman includes a fictional lecture with a detailed overview of MENACE. See also Hexapawn Reinforcement learning References Sources Michie, D.; Chambers, R. A. (1968), "BOXES: An Experiment in Adaptive Control", Machine Intelligence, Edinburgh, UK: Oliver and Boyd, S2CID 18229198 – via Semantic Scholar, Michie and R. A Chambers' paper on the AI implications of BOXES and MENACE. Russell, David W. (2012), The BOXES Methodology: Black Box Dynamic Control, Springer London, ISBN 978-1849965286, a book on the "Boxes" algorithm employed by MENACE. External links Online simulation of MENACE