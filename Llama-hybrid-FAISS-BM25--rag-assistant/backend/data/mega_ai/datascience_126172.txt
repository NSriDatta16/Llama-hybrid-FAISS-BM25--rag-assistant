[site]: datascience
[post_id]: 126172
[parent_id]: 
[tags]: 
How to find proper context in open book question answering?

I want to make an Open Book Question Answering / Retrieval Augmented Generation system. The major concern here is the proper context selection. There are some fundamental issues related to this. For example, you want to make a chatbot for an E-commerce site. So, you have downloaded the crawl of the whole site and the crawl looks something like this: Product Name: ABC Description: [A moderately large description] Price: $100 Product Name: DEF Description: [A moderately large description] Price: $200 ... Now, you have to chunk the whole corpus and generate embeddings for each of them. The difficulties start from here. You cannot generate embedding for an arbitrarily large text. Also, even if you could do so, it would have a performance hit, as the passage will no longer be anything specific. Now, in the depicted scenario, after chunking there can be thousands of contexts that are very similar although they are referring to different products. Now during conversation, how do you ensure you are fetching the appropriate context for the correct product? As, after chunking the whole crawled data, the chunked passages may not contain any reference to the product at all and for many products, the passages can become almost equivalent. A similar situation happens when you work on documents. Like if you have a PDF content like: An Overview of Machine Learning Techniques ......... SVM [A description of SVM] Working Example [An implementation of it] Pros [Benefit of using this algorithm] Cons [Desccribes when this is not applicable] ......... Neural Network [A description of Neural Network] Working Example [An implementation of it] Pros [Benefit of using this algorithm] Cons [Desccribes when this is not applicable] Let's assume, someone is chatting on a Neural Network topic. Now the user is asking the bot about its pros and cons. Now, there is no guarantee that the Pros and Cons related sections will contain the term "Neural Network" in them. The distance between the section and the last time the term "Neural Network" was mentioned can be so large that they cannot be inside of a single context. How do you handle this case? How do you carry forward the topic information on which the subsequent contexts are talking about? Also, there are some catches. There can be multiple levels of hierarchies (section, subsection, etc.), choosing the higher level can make the context too generalized, and choosing the lower level can make it too specialized. Taking all of them into consideration without hierarchy can be misleading. I have for example tried the PyMuPDF library to parse the headers and bold texts from a PDF. My target is to attach the most recent header to every other chunk where there is no header available. But in reality, you cannot always assume this will work. Even this approach fails in my local testing when I want to apply them to PDFs in the wild. Either the selected topic headers are too large in number or too less in number or they are simply generated as an artifact as people may not follow standard while writing documents, they can use those headers in inappropriate ways. I have been searching through the Internet for weeks, but most of the tutorials are only addressing the happy path, and almost no one is discussing this real issue that will arise when you want to apply it in wild situations. Is there any solution to this problem? Or is there any appropriate data structure to handle this kind of data? Is not Retrieval Augmented Generation applicable to this scenario? Any paper, algorithm, tutorial, or idea relevant to it will be helpful. Thanks.
