[site]: crossvalidated
[post_id]: 83993
[parent_id]: 
[tags]: 
Difference between Random Forest and MART

I just wonder what is the difference between Random Forests and MART (Multiple additive regression trees)? I have read a few articles, e.g.: [1] L. Breiman. Random Forests. Machine Learning 45 (1): 5â€“32, 2001. [2] J.H. Friedman. Greedy function approximation: A gradient boosting machine. Technical Report, IMS Reitz Lecture, Stanford, 1999; see also Annals of Statistics, 2001. ... and a few more. And I understood the basics. Random Forest and MART can be both used for either regression or classification. Random Forest is based on bagging, randomization and voting. While the output of MART is rather a weighted sum of ensamble of boosted regression trees. Therefore, I have a basic idea what the difference is. However, it would help me a lot, if somebody more experienced could wrap it up . And one more particular question: If I do a regression using Random Forest, what kind of tree is used? Is it an ensemble of regression trees? Or if it depends on me, which tree I would choose? Or is it a special kind of tree, specific for Random Forests?
