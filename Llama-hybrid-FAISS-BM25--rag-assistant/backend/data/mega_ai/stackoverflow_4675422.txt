[site]: stackoverflow
[post_id]: 4675422
[parent_id]: 4674906
[tags]: 
Looking at each question in turn Is this a very bad idea? Do you know something better to achieve the same? Its not really clear what you hope to achieve by this. Linux already backs memory used by swap space (so if your data exceeds physical memory, some will be swapped to disk). Are you having problems with running out of address space, or running slowly due to excessive paging? Using an mmap backed store won't really affect either. Would I need to allocate the maximum file size beforehand, and will I require all of this space to be allocated on disk? If so, would mapping to a sparse file help? Yes, you need the file to be as big as the space you are mmaping. You can however start with a small file/mmap and grow the file (and mmap additional pages) later as needed. You can also use a sparse file, so that disk space isn't used until the pages are written to. I don't want to write my own heap allocator. Can I use an existing one? There are heap managers that use mmap-backed storage. I've seen versions of the Doug Lea malloc, and various other bibop allocators that do so. When my program finishes, the mmap'd file will be deleted. This means I don't want any pages to be written to disk unless the kernel will actually remove them from memory. Is there something like a lazy flag to mmap to achieve this, or is this automatic? In this case, you could just use MAP_ANON and not have a file at all. However, this gets back to the first question, as this is essentially duplicating what the system malloc (and new) does. In fact on some OSes (Solaris?) that's exactly what the system malloc does. The main reason I've seen custom mmap-based mallocs in the past is for persistent storage (so the file would remain after the process exits and would be remapped on restart).
