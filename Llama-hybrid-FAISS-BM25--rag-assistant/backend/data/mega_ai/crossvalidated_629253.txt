[site]: crossvalidated
[post_id]: 629253
[parent_id]: 629252
[tags]: 
Let's call the two estimators $\widehat{\beta}_1$ (using the whole sample) and $\widehat{\beta}_1^N$ (the average across the $N$ ) subsamples. If the OLS assumptions are satified then these are both unbiased estimators for $\beta_1$ , so they are equivalent in mean. If the equivalence you have in mind is equivalence in distribution, then again under OLS assumptions we have $\frac{\widehat{\beta}_1-\beta_1}{se(\widehat{\beta}_1)}\overset{d}{\to}\mathcal{N}(0,1)$ and this is also true for the second estimator as long as the dependence between estimators in each subsample is negliglible. The two estimators are not identical, i.e. these are not alegbraically the same. Addendum: Save we have non-random explanatory variables, i.e. $x_i$ 's are deterministic. And say in this model, $y_i=\beta_0+\beta_1 x_i + u_i$ , we have $var(u_i)=\sigma_u^2$ . Then we have \begin{align} var(\hat{\beta}_1)&=\frac{\sigma_u^2}{\sum_{i=1}^{nN}(x_i-\bar x)^2}\\ & = \frac{\sigma_u^2}{\sum_{k=1}^{N}a_k}\\ var(\hat{\beta}_1^N)&=\frac1{N^2}\sum_{k=1}^N\frac{\sigma_u^2}{a_k}, \end{align} where $a_k=\sum_{i=1}^N(x_i^{(k)}-\bar{x^{(k)}})^2$ . Now since $\frac1N\sum\frac1{a_k}\geq\frac{1}{\frac1N\sum a_k}$ , $\hat{\beta}_1$ is more efficient compared to $\beta_1^N$ . If $x$ is random, but has a constant variance and its relationship with $u$ is not varying across the sample (in terms of second moments), then the same result follows.
