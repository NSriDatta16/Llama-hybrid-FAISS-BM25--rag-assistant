[site]: crossvalidated
[post_id]: 222575
[parent_id]: 222574
[tags]: 
the first one called deep-belief network based on the restricted boltzmann machine, where you can train each layer independently from the other and then using the output of this layer to train another layer. while the new method autoencoder allow you to build the same structure from the first time, here you have to know that the weights are just transposed between encode and decode. there is no one is better than other. DBN was old approach before AEN. Try both of them and compare the results
