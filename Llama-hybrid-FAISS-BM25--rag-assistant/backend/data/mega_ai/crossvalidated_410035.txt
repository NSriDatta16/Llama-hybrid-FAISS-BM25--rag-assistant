[site]: crossvalidated
[post_id]: 410035
[parent_id]: 
[tags]: 
Local Significance test for composite anomalies

Suppose I have the following 20 points: dput(dat) c(-0.560475646552213, -0.23017748948328, 1.55870831414912, 0.070508391424576, 0.129287735160946, 1.71506498688328, 0.460916205989202, -1.26506123460653, -0.686852851893526, -0.445661970099958, 1.22408179743946, 0.359813827057364, 0.400771450594052, 0.11068271594512, -0.555841134754075, 1.78691313680308, 0.497850478229239, -1.96661715662964, 0.701355901563686, -0.472791407727934 These 20 data points are anomalies of winds or the annual deviation from the 1981-2010 mean. I extracted this from one grid point in a gridded data set (i.e., in netcdf format). For simplicity, I am only showing one time series. Details I am analyzing extreme heavy rainfall days and to understand the formation mechanism, I have to perform lag compositing. First, I derived the anomalies of the 20 years relative to climatology (daily value minus the climatological value). For example, the 20 years is from 1981-2000 while the climatology is the average from 1981-2010. In each year from 1981-2000, I derived the days exceeding a certain threshold. This is labeled as Lag 0. The day before this is Lag-1 and the day after is Lag +1. This is a common method of compositing. Each lag is the average of 20 points. What I want I would like to test for the LOCAL significance of these anomalies. For example, I want to test the significance of the probability of occurrence of these extreme cases. Like a Monte Carlo simulation. I would like to ask for suggestions for a correct statistical test for this and how should I do the test. I want to use R in performing this test. I'll appreciate any help. Sincerely, Lyndz
