[site]: crossvalidated
[post_id]: 351977
[parent_id]: 351950
[tags]: 
A linear time series is one where, for each data point $X_t$, that data point can be viewed as a linear combination of past or future values or differences. For example, for things that change slowly (the height of a river measured every hour if there isn't a flash flood), next hour's measurement is almost certainly very close to the prior ones, and so on, so you might have a model like this: $$ x_t = .9x_{t-1}+.81X_{t-2}+...+\epsilon_t $$ This generally gives rise to autocorrelation. The danger with autocorrelation is that if you don't adjust for it you get regressions that are too good to be true. Generally, linear time series are modeled as either Autoregressive or Moving Average models, which, combined, become an ARIMA process. See: https://www.stat.tamu.edu/~suhasini/teaching673/linear.pdf A non-linear time series would be a much more complex beast. There are a whole host of tools for getting it right with ARIMA processes. But a non-linear time series could be very messy. You might want to take a look also at GARCH series, where the variance wnaders around.
