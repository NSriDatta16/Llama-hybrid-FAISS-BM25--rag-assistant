[site]: crossvalidated
[post_id]: 483991
[parent_id]: 
[tags]: 
In general, what efficiency is expected from neural networks when the input is irrelevant data?

Is it expected to lie around 50%? Less than this? More? "Irrelevant data" could be anything not related to the targets. For example, it could be random data, or it could be a dataset from problem A paired up with targets taken from an unrelated problem B, etc. I imagine that the inverse question would be equivalent to this one - for which efficiency should I start suspecting that my data are meaningless? Edit: Let's assume a random rate of success around 50% (or anything you may like to define). I think my concern boils down to whether we expect a 50% from the NN, or whether there are known "fake effects". I imagine that overfitting would be one such contribution (edit: but only for the training test).
