[site]: crossvalidated
[post_id]: 452653
[parent_id]: 
[tags]: 
MCMC converges to MAP and stays at same value - what may go wrong?

I am working on a Gibbs sampler which is complex and I would like to avoid giving all the details here. I will focus on the most necessary details. The Gibbs sampler involves parameters and latent variables. The parameters are updated from their full conditional distributions partly using a metropolis step. The latent variables are updated using data augmentation from the full conditional distributions. After some iterations the MCMC seems to move in the right direction and then 'collapses to a degenerate distribution'. Further inspection using the optim function in R to maximize the posterior distribution of the parameters using the most recent update of the latent variables reveals that the parameters' distributions are degenerate at the maximum of their posteriors (MAP). Below a plot demonstrating a chain for one such parameter. In red you see the MAP as described above, and in green the true parameter value which is known because this is a simulation. The parameter shown is updated using a Metropolis step. I have tried to adjust the proposal variance of the Metropolis algorithm, but even very very small values ( $10^{-10}$ ) do not increase the acceptance rate. Can anybody offer an explanation and perhaps a remedy for this? Final note: in the simulation I can also treat the latent variables as known (at their true values) and update only the parameters. Then the problem does not occur. However due to earlier work and code checking I am certain that the full conditionals of the latent variables are correct. To answer @Xi'an's question , the data augmentation is not stuck because it samples new values given the parameters on each Gibbs iteration. However since the last Gibbs parameter draws are always the same there is not a strong change anymore across iterations. The AR1 autocorrelation of data augmentation draws at the end (for constant parameters then) is about 0.87. In addition I added a plot of the most recent data augmentation in comparison to the true values. We see the distributions are quite similar but the augmented values show some heteroscedasticity. Furthermore, there are 5 MH parameters updated at the same time using a MV-normal proposal distribution. There are also 2 prior parameters getting updated (they have hyper-prior distributions).
