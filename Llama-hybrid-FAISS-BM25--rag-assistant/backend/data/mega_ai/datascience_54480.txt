[site]: datascience
[post_id]: 54480
[parent_id]: 
[tags]: 
Acurracy = 0 using tensorflow on tabular data

I am new to machine learning and trying to apply this tutorial to my tabular data. My input is a pandas dataframe containing the features (I encoded the categorical columns as floats) and a pandas series containing the labels, which are ints. This is my code: def df_to_dataset(dataframe, labels, shuffle=True, batch_size=32): ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels)) if shuffle: ds = ds.shuffle(buffer_size=len(dataframe)) ds = ds.batch(batch_size) return ds feature_columns = [] # numeric cols for header in list(X_train): feature_columns.append(feature_column.numeric_column(header)) feature_layer = tf.keras.layers.DenseFeatures(feature_columns) batch_size = 32 train_ds = df_to_dataset(X_train, y_train, batch_size=batch_size) val_ds = df_to_dataset(X_val, y_val, shuffle=False, batch_size=batch_size) test_ds = df_to_dataset(X_test,y_test, shuffle=False, batch_size=batch_size) model = tf.keras.Sequential([ feature_layer, layers.Dense(128, activation='relu'), layers.Dense(128, activation='relu'), layers.Dense(1, activation='sigmoid') ]) model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'],) #run_eagerly=True) model.fit(train_ds, validation_data=val_ds, epochs=5) loss, accuracy = model.evaluate(test_ds) print("Accuracy", accuracy) First of all, when I print the shape of the datasets, all feature shapes are shown as (?,). I looked that up, but it didn't really get, what that meant, so I moved on. When executing the model, I got the following output: W0625 16:28:50.013361 140172694484864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support. .wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.where in 2.0, which has the same broadcast rule as np.where Epoch 1/5 2437/2437 [==============================] - 12s 5ms/step - loss: -368933040.3744 - acc: 0.0000e+00 - val_loss: -1374389959.0878 - val_acc: 0.0000e+00 Epoch 2/5 2437/2437 [==============================] - 11s 4ms/step - loss: -4239125012.7993 - acc: 0.0000e+00 - val_loss: -8055676778.8942 - val_acc: 0.0000e+00 Epoch 3/5 2437/2437 [==============================] - 11s 4ms/step - loss: -14449097654.0468 - acc: 0.0000e+00 - val_loss: -21844830544.8532 - val_acc: 0.0000e+00 Epoch 4/5 2437/2437 [==============================] - 11s 4ms/step - loss: -32560744568.1740 - acc: 0.0000e+00 - val_loss: -44181551604.6596 - val_acc: 0.0000e+00 Epoch 5/5 2437/2437 [==============================] - 11s 4ms/step - loss: -60235093753.8022 - acc: 0.0000e+00 - val_loss: -76823729189.8015 - val_acc: 0.0000e+00 1219/1219 [==============================] - 3s 2ms/step - loss: -78553874677.2896 - acc: 0.0000e+00 Accuracy 0.0 Obviously something is wrong, but I don't even know where to begin debugging this, so any tips are welcome! Edit: the labels I am trying to predict are point scores from 80 to 100. Because of this, I switched from binary_crossentropy to mean_squared error. Now the loss is still very large, but positive and the accuracy is still 0
