[site]: crossvalidated
[post_id]: 514818
[parent_id]: 
[tags]: 
Why is the convergence rate faster for this given approach?

LALR: Theoretical and Experimental validation of Lipschitz Adaptive Learning Rate in Regression and Neural Networks This is a paper that suggests using an adaptive learning rate approach for various optimizers. It calculates the Lipschitz constant for the derivative of the error to the weights and uses its inverse to determine the given timestep's learning rate. The reason I think it's faster is that as the Lipschitz constant returns the maximum value of the derivative of the function with respect to a variable, using it helps us to converge faster as it increases the magnitude of the step that we take towards the lower points in the loss function. Is this inference correct? Is there also an added reason/s for this approach to have a faster convergence rate?
