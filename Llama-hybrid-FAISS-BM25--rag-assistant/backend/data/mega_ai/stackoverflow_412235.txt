[site]: stackoverflow
[post_id]: 412235
[parent_id]: 412019
[tags]: 
You might also consider experimenting with alternative activation functions which are cheaper to evaluate. For example: f(x) = (3x - x**3)/2 (which could be factored as f(x) = x*(3 - x*x)/2 for one less multiplication). This function has odd symmetry, and its derivative is trivial. Using it for a neural network requires normalizing the sum-of-inputs by dividing by the total number of inputs (limiting the domain to [-1..1], which is also range).
