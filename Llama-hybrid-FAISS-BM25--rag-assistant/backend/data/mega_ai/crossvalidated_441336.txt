[site]: crossvalidated
[post_id]: 441336
[parent_id]: 92923
[tags]: 
If you use a logistic regression ensemble learner across your sample models you will overfit to your training data. The reason being, and assuming you are doing a random subsampling or bootstrapping of your negative class, there's no reason one sample model should be chosen over the next. They should all have equal weight in your ensemble. My suggestion would be to simply average across the responses from each of your sample models.
