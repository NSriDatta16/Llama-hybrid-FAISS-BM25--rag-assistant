[site]: crossvalidated
[post_id]: 122423
[parent_id]: 
[tags]: 
Help with understanding statistical measures and Receiver Operating Characteristics

In my machine learning class we just went over statistical measures and plots. We looked at the definitions of True Positive Rate (sensitivity/recall, etc), 1-False Positive Rate (speciicity), Accuracy, and Precision. Defining them as the following True Positive rate (Sensitivity/Recall) = True Positives/(True Positives + False Negatives) 1 - False Positive Rate (specificity) = True Negatives/(True Positives + False NegativeS) Accuracy = (True Positive + True Negative)/(Positives + Negatives) Precision = True Positive/(True Postitive + False Negative) When my professor asked what exactly the True Positive Rate measured many people said "Its the percentage of correctly classified samples). And to each person who replied with this kind of answer he said "sorta" but he never really explained exactly what it was. What does each of these exactly measure and how does it help us examine data? Is there a way one of these is useful for a quantitative measure of uncertainty? We also went over ROC plots and Precision-Recall Plots. He said that since for each run of data we can only get one value for each of these measures we create these plots of True Positive Rate vs False negative Rate and Precision vs Recall by adjusting some sort of threshold (number of true positives??) and then plotting a point when we get to that threshold. What exactly do we adjust the threshold of to generate these two types of plots. As i understand it the plot on the ROC curve with the most area is the best at predicting a sample, is this also true for the precision-recall plots?
