[site]: datascience
[post_id]: 94127
[parent_id]: 94123
[tags]: 
We only use zero padding on the edge of the image to be able to compute our convolution on 'edgy' pixels. It is usually just to keep 'round' values of dimension. For example if your input is 64x64, with strides = 2x2, you'd expect a 32x32 output, but without padding, you would get 31x31. Padding is really not a big deal and you can remove it without having much consequences on your results (at least according to my experience), it's more a reason of 'good looking' dimensions (multiples of 2). To get back to the use of CNN in policy decisions, your agent uses the state value to decide which action to take. CNN is used to transform a 256x256 input into a 30 or 20 output features that is concatenated into the state of the network. So a corresponding state could be [agent_position, agent _speed, features_from_image] instead of [agent_position, agent _speed, image], and then your network / Q algorithm takes its decision from this state. So CNN is a kind of subpart of the network.
