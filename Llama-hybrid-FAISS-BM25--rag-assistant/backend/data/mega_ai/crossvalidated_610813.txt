[site]: crossvalidated
[post_id]: 610813
[parent_id]: 
[tags]: 
How to measure the noise in gradients of deep neural networks

I'm dealing with a problem related to explainable AI. The short version of the issue I have is that I've observed some interesting differences between large and small BERT models and I suspect that noisy gradients are the cause. I know gradients are noisy - Integrated Gradients and SmoothGRAD address the saturation and local instability issues. The problem I have is that I don't know if large models (bert-base-cased) have more noise in their gradients compared to small models (14M parameter BERT model). I'm looking for a way to measure the amount of noise the gradients contain. I tried to find articles that deal with this issue but I didn't find any. Something that's theoretically sound would be great, but at this point, I'm thankful for any ideas.
