[site]: crossvalidated
[post_id]: 80756
[parent_id]: 
[tags]: 
How to calculate number of features based on image resolution?

Just covered Andrew Ng's Non-linear Hypothesis of Neural Netowrks, and we had a multiple choice question for determining number of features for an image of resolution 100x100 of grescale intensities. And the answer was 50 million, $5$ x $10^7$ However, earlier for a 50 x 50 pixel, grey scale image. the number of features is 50x50 (2500) Why would it be $5$ x $10^7$ instead of $10,000$? He does however say including all quadratic terms ($x_ix_j$) as features Suppose you are learning to recognize cars from 100Ã—100 pixel images (grayscale, not RGB). Let the features be pixel intensity values. If you train logistic regression including all the quadratic terms ($x_ix_j$) as features, about how many features will you have? and in the earlier slide regarding the 100x100, that the quadratic features ($x_i$ x $x_j$) = 3 million features, but I still can't put a finger on the connection.
