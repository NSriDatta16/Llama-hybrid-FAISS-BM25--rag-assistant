[site]: crossvalidated
[post_id]: 493994
[parent_id]: 206225
[tags]: 
Train your network to give you probabilistic predictions $\hat{p}_{i1}, \dots, \hat{p}_{i4}$ for membership in your four classes of the $i$ -th instance. Then you can use proper scoring-rules ("scoring rules" in the technical sense; I can't tell whether you are using the term in this sense - take a look at the tag wiki for more info) to assess these. For instance, if the $i$ -th instance turns out to belong to class $j(i)$ , then the logarithmic score would penalize the corresponding predictions by $-\log(\hat{p}_{i,j(i)})$ , and the Brier score would penalize it by $\hat{p}_{i,j(i)}^2$ . In each case, smaller is better. You would average these scores over multiple instances $i$ and prefer models with lower average scores. Once you have well-calibrated probabilistic classifications, you can tune your thresholds for optimality, which will involve not only the predictions, but also the costs of misclassification. See here for more info. That is, you should separate the prediction and the decision aspects of your problem.
