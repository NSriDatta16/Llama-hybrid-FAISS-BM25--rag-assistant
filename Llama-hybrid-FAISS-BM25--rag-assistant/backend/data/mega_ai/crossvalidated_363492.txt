[site]: crossvalidated
[post_id]: 363492
[parent_id]: 
[tags]: 
Efficient approximate marginal inference in variational auto-encoder

In Auto-Encoding Variational Bayes , authors mentioned that they proposed a solution to "Efficient approximate marginal inference of the variable $x$". I read through the paper and appendix, now scratching my head about how we can compute this after optimization of the encoder and decoder: given a particular instance $x^{(i)}$, how to compute (approximately) $p(x^{i})$? The only thing I saw is the "marginal likelihood estimator" in the appendix D. But in authors' own words, "that produces good estimates of the marginal likelihood as long as the dimensionality of the sampled space is low." Another way of phrasing my question, what do we really accomplish after the optimization (training VAEs with some data)?
