[site]: crossvalidated
[post_id]: 249031
[parent_id]: 
[tags]: 
Relation between: Likelihood, conditional probability and failure rate

Crosspost from math.stacksexchange . Though it might fit better here. My question is about the possibility of showing equivalence between the hazard rate, the conditional probability (of failure) and a likelihood function. Dynamics: Consider a coin that has $P(\boldsymbol{H})=p$ and $P(\boldsymbol{T})=1-p$ such that $P(H) + P(T) = 1$. The stochastic process $X(t)$ evolves according to this dynamic over time $t$ resulting in a series of $\boldsymbol{H}$ until at time $T$ it lands on tails $\boldsymbol{T}$ which ends the sequence. Definitions: Consider $T$ a continuous random variable with density $f(t)$ and cumulative density $F(t)$. 1) Hazard rate : $\mu(t)=\frac{f(t)}{1-F(t)}$. Aka. force of mortality, hazard function, failure rate, see wiki . This can be larger than one. 2) Conditional probability of failure: $P(t t)}{P(T>t)}\approx\mu(t)\triangle t$ Showing equivalence between 1) and 2) for $\triangle t\rightarrow0$ is easy. Again, see wiki. 2) is the conditional probability of failure , given that the unit worked up until time $t$. 3) Likelihood function: $\mathcal{L}(\theta|X)$. Where $\theta$ is a parameter ($p$) and $X$ is the data observed (e.g. the series of H). E.g. assuming a fair coin we can write $\mathcal{L}(P(\boldsymbol{H})=0.5|\boldsymbol{HH})=P(\boldsymbol{HH}|P(\boldsymbol{H})=0.5)=0.25$. Or alternatively, $P(\boldsymbol{T}|\boldsymbol{HH})=1-P(\boldsymbol{HH}|P(\boldsymbol{H})=0.5)=0.75.$ Questions: q. 1 ) Am I right in asserting that the likelihood function $\mathcal{L}(\theta|X)$ $is$ the complement to the conditional probability function $P(t Exemplified as $P(\boldsymbol{T}|\boldsymbol{HH})=1-P(\boldsymbol{HH}|P(\boldsymbol{H})=0.5)=0.75.$ q. 1.2 ) If q .1 is true, how is the likelihood function connected to the hazard rate function? Can they be shown to be equivalent? q. 1.3 ) Intuitively, all conditional probabilities are purely multiplicative processes. Can we generally write this as $P(t conditional probability of realising another $\boldsymbol{H}$ decreases, the probability (and thus likelihood?) of realising $\boldsymbol{T}$ increases. q. 2 ) Is it generally true, that if all conditional probablities are purely multiplicative processes of numbers between one and zero, they all decrease with some exponential rate $\lambda$? Consider the cumulative hazard rate : $\varGamma=\int_0^t\mu(u)du=-log(1-F(t))$. See wiki . q. 2.1 ) If q. 2 is correct, and we can express the integral over hazard rate as the negative logarithm to the complement of the cdf $-log(1-F(t)$ (sometimes called the survival function), is this essentially the same as the conditional probability? q. 3 ) How does the above relate to the notion of sojourn time ? One can imagine $N$ states with $N$ different hazard rates. What is this problem generally called and how can I relate it to expected mean sojourn time? Intuitively, states with a high hazard rate will have lower sojorn time. Are these equivalent somehow? q. 4 ) If anyone would care to relate this to a Markov Chain with absorbing states, they are most welcome. Especially I am interested in how the conditinal probability relates to the transition probabilities. I realise these are a lot of questions. Any hints, partial answers or call for clarity is appreciated, thanks!
