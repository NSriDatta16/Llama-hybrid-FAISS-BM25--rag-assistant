[site]: crossvalidated
[post_id]: 401022
[parent_id]: 
[tags]: 
CNN analysis help

http://scs.ryerson.ca/~aharley/vis/conv/ I'm trying to better understand the architecture in this CNN. After reading the paper here: http://scs.ryerson.ca/~aharley/vis/ the author says This network has 1024 nodes on the bottom layer (corresponding to pixels), six 5x5 (stride 1) convolutional filters in the first hidden layer, followed by sixteen 5x5 (stride 1) convolutional filters in the second hidden layer, then three fully-connected layers, with 120 nodes in the first, 100 nodes in the second, and 10 nodes in the third. The convolutional layers are each followed by downsampling layer that does 2x2 max pooling (with stride 2). But I get lost when I start interacting with the network. The first step makes sense, 6 convolution filters pass over the input image and I get 6 results. Then there's pooling to reduce the image size- so we have 6 images each being 14x14 pinxels. Then we have 16 filters. It looks like some of then are connected to all 6 previous images while others are connected to only 3. Why is this the case? Is this a choice by the author to disconnect some filters? To achieve the "multiple images contributing to one node" are the convolution results just summed up? After that, we have pooling and fully connected layers, which make sense to me just fine. So yah, I'm wondering why a hidden convolution layer only takes in a few of the inputs from the previous layer.
