[site]: datascience
[post_id]: 14200
[parent_id]: 14161
[tags]: 
I believe this is the answer: https://github.com/dmlc/xgboost/issues/651 the sklearn api uses n_estimators= 100 as default whereas xgb.train is using n_boost_rounds=10 As both refer to the same parameter this could explain the huge difference.
