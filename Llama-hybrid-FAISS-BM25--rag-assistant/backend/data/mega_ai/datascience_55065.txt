[site]: datascience
[post_id]: 55065
[parent_id]: 55031
[tags]: 
KNN Regressor, per se, does not have a dedicated learning process as it just takes weighted average of the dependent variable of the k-nearest neighbors from your training set of the test datapoint whose dependent variable you have to predict. You can try using Support Vector Regressor or MLP (Neural Network) Regressor offered by scikit-learn and see if the performance has increased with respect to number of test cases where predictions resulted in efficiency > 1. If you are adamant on incorporating this condition in your learning process, you can use Keras and create a custom loss function which returns a high value if your efficiency results in a value greater than 1. Although the training will be sensitive to this value and higher values can shutdown the neurons, resulting in all zeros output. But if you are careful you will be able to get sensible predictions with efficiency def custom_loss(voltage, current, torque, speed): def loss(y_true, y_pred): #your logic here return loss model = Sequential() model.add(Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu')) model.add(Dense(1)) model.compile(loss=custom_loss(input_1, input_2, input_3, input_4), optimizer='adam')
