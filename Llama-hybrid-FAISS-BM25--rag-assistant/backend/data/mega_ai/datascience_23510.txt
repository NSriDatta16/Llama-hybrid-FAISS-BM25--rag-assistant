[site]: datascience
[post_id]: 23510
[parent_id]: 
[tags]: 
Using a White noise image to minimise the loss in a (convolutional) neural network

I'm reading someone else's code , which uses vgg19 to transfer the style of an artist to a 'content' image. I'm wondering why they have put INI_NOISE_RATIO * noise_img + (1. - INI_NOISE_RATIO) * content_img) instead of just noise_img ( INI_NOISE_RATIO=0.7 here). Why use a mix of the noise image and content image as input for the white noise bit in the content loss? The paper https://arxiv.org/pdf/1508.06576.pdf by Gatys et.al doesn't mention the mixing?
