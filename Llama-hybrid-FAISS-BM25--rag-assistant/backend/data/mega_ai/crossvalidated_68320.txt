[site]: crossvalidated
[post_id]: 68320
[parent_id]: 68317
[tags]: 
Regression models are typically set up to model the conditional mean $E(Y|X=x)$, or some function thereof (for logistic regression, you are modeling the logit of $E(Y|X=x) \equiv P(Y=1 | X=x)$). The implication of modeling the conditional mean is that the predictors $X$ are viewed as fixed , not random, so that one makes no assumptions about their distributions. This is in contrast to the outcome $Y$, whose (assumed) distribution plays an important role in determining which model to fit and which assumptions to make. There are, however, some instances where you might want to transform the $X$ value: 1) It is scientific convention to report effect sizes on the transformed scale (e.g., $X$ is temperature in Fahrenheit but it is more usual to report the effect of a one-degree Celsius change on the outcome of interest). 2) The conditional mean (or function thereof) is better described as a linear function of the transformed $X$ than on the original scale (e.g., for linear regression, a straight line fits the scatterplot of $Y$ vs. $\log(X)$ better than one of $Y$ vs. $X$).
