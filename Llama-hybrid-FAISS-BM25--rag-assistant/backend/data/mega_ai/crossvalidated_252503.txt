[site]: crossvalidated
[post_id]: 252503
[parent_id]: 
[tags]: 
logistic regression with 1L penalty

Can anyone tell me why I get the same values at the end for this logistic regression for x1-x3 and x1-x14? There are more variables in there so the outcome should change at least a bit right? x This is the function I used to generate data: GenerateData 3) + (0.3*x3) pi = exp(eta) / ( 1 + exp(eta) ) y = rbinom(1500, 1, pi) # combine data and split into training and test data full = data.frame(y, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14) names(full) = c( "y" , paste( "x" , 1:14 , sep="" ) ) return(full) } source( "GenerateData.R" ) FullData = GenerateData( 1035932 ) train = FullData[ 1:750 , ] test = FullData[ 751:1500 , ]
