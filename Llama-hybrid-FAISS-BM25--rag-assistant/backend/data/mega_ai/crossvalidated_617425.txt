[site]: crossvalidated
[post_id]: 617425
[parent_id]: 
[tags]: 
Python's `acf` and Matlab's `xcorr` apparently give different magnitude (but same pattern) answers for some data

I have an experiment with time series data (spike rates). A Python script calculating their autocorrelation with statsmodels.tsa.stattools.acf was apparently giving different answers than an implementation of equivalent logic in Python, using the same bins and 99 lags in each case. The answers had the same pattern, but different magnitudes. In an effort to understand this, I first generated a random series with three sinusoidal frequencies, computed its autocorrelation in Python, and then loaded this same series and the Python correlation into Matlab, and computed the autocorrelation in Matlab. They looked identical (the Matlab version was symmetrical and needed to be sliced, but otherwise identical). Then I stopped my own code in the debugger. I wrote out a test file with the values of a representative series of rates and its autocorrelation. I loaded these into Matlab. The Matlab version is the same shape, but different magnitude. Is this expected? If so, what are the differences between Python and Matlab that can explain it? The series from my experiment is very sparse compared to the random numbers. I'm a bit befuddled because the magnitude reduction is not consistent across conditions in this experiment, such that Matlab gives a very theoretically interesting result and Python does not. Every graph, code snippet, and link to the text files follow. Edit: I tried a few other implementations of autocorrelation in Python. The autocorr method on a series in Pandas gives the same answer as acf but using NumPy's correlate and normalizing by the value at 0 lag gives the same answer as Matlab, so whatever this difference is, it can be compared between Numpy and Pandas/statstools, which at least have algorithms open to inspection. Edit 2: I'm removing the code from my question because I got a close vote for off-topic because it was about programming. I only included code to try to stave off any claim that this difference might be due to a programming error. Please note that my question is about what in the implementation of these algorithms leads to this difference, and which would be the most appropriate for my data. It is not a programming question. Edit 3: On further investigation, I'm not sure the NumPy and Matlab versions are identical. Closer, but not identical. Here are all the text files.
