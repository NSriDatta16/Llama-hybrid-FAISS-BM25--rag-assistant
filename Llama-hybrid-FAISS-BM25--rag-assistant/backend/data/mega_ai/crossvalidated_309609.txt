[site]: crossvalidated
[post_id]: 309609
[parent_id]: 
[tags]: 
Upper bound using Bayes risk

Bayes' risk is $L^*=0$ for a classification problem. $g_n(x)$ is a classification rule (plug-in) such that $g_n=0$ is $\eta_n(x)\leq 1/2$ and $g_n=1$ otherwise. The function $\eta$ is given by $\eta(x)=\mathbb{E}(Y|X=x)$. Then $\mathbb{P}(g_n(X)\neq Y)\leq 4\mathbb{E}((\eta_n(X)-\eta(X))^2)$ Any hints on how to solve this problem? I see that if $\eta_n\leq 1/2$ then it reduces to show that $\mathbb{P}(0\neq Y)\leq 4\mathbb{E}((\eta_n(X)-\eta(X))^2)$, but how do I get the bayesian risk involved. The right-hand of the inequality looks similar like the bayesian risk for the quadratic loss, but I can't see a way to use it - if it is related to the problem.
