[site]: crossvalidated
[post_id]: 499831
[parent_id]: 
[tags]: 
How Could the Estimates Obtained through OLS and GLS Vary in Their 95% Confidence Interval Values While They Have the Same P-Value?

I am working on an interrupted time series analysis. The data actually meet most of the assumptions of the OLS (the outcome variable is normally distributed, the Beusch-Pagan test of the residuals of the linear regression show homoscedasticity, the Durbin-Watson test shows no auto-correlation). From the OLS model, I found the following results: ---------------------------------------------------------------------------------- | |olsmodel |t|) | |----------------------------------------------------------------------------------- | |(Intercept)|28.68111 [27.92314229, 29.43907888] |0.38088 |75.303 | The OLS model shows that idv1p has no significant effect because the 95% CI includes 0 and the p-value is slightly above 0.05. However, the GLS model I run with ARMA(0, 0) (shown below) has the same p-value as the above but the 95% CI shows significant effect. ---------------------------------------------------------------------------------------------------- glsarma00 |t|) | |(Intercept)|28.68111 [27.93460645, 29.42761472] |0.3808765 |75.30292 |0.0000 | |idv1p |1.141656 [0.01276037, 2.27055146] |0.5759777 |1.98212 |0.0509 | |idv2r |-0.026605 [-0.07530323, 0.02209349] |0.0248466 |-1.07077 |0.2875 | |dv3t |-0.072923 [-0.09944641, -0.04640025] |0.0135324 |-5.38878 |0.0000 | ------------------------------------------------------------------------------------------ | AIC= 288.2094; BIC=300.3635; logLik= -139.1047 -----------------------------------------------------------------------------| How could the discrepancy happen? Which model should I pick?
