[site]: crossvalidated
[post_id]: 171713
[parent_id]: 171707
[tags]: 
To get started I recommend reading the introduction to this book by Stephen Boyd. He is doing a lot of cutting edge research in convex optimization, and is one of the biggest names in the field. Often the issue of "making" your problem convex is reparameterization of the problem formulation. But sometimes the function your are trying to optimize is not convex and thus you can optimize a convex approximation which often agrees on the same global optimum. Still there are functions which are highly non-convex, e.g. deep neural networks, where one needs to resort to other methods, (back propagation). The fact why this subject is important relates to the history of optimization. People managed to solve linear programs, where the simplex method is one of the first widely used methods to solve those kind of problems. Then they started to solve quadratic programs and other kinds of problems, but there was no obvious generalization. What these problems had in common was the convexity. It turns out that you can put the convex optimization problems in a canonical form, which is just a linear program. Thus making it a possibility to attack a huge class of problems. This is the best generalization we have so far, and I do not think we can generalize much further than this. Continues relaxations of discrete problems often also yields problems that are convex. Most basic optimization problems are convex, a lot of statistics rely on convex optimization. In some cases you can get a closed form solution for the optimum (e.g. linear regression), but it is easy to define problems that do not have a closed form solution, (e.g. the lasso). If you are working on such a problem it is nice to have a tool to verify if your objective function is convex and to optimize it. This is possible in the software CVX developed by Boyd and others. This is very nice for prototyping, but if you need faster solvers sometimes you need to exploit the intricacies of the problem that you have to create a solver that works faster. The newton method, the simplex method and others have in common that they are deterministic. They always yield the same results. Genetic algorithms do not give you this guarantee. They usually run much slower and are more suitable for when you have a noisy objective function or potentially a highly multi modal objective function. It is entirely dependent on the problem that you are solving what method you would like to use. Read the introduction to the book and it will take you far!
