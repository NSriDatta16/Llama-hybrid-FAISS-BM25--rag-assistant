[site]: crossvalidated
[post_id]: 366430
[parent_id]: 282987
[tags]: 
Summary Hidden Markov Models (HMMs) are much simpler than Recurrent Neural Networks (RNNs), and rely on strong assumptions which may not always be true. If the assumptions are true then you may see better performance from an HMM since it is less finicky to get working. An RNN may perform better if you have a very large dataset, since the extra complexity can take better advantage of the information in your data. This can be true even if the HMMs assumptions are true in your case. Finally, don't be restricted to only these two models for your sequence task, sometimes simpler regressions (e.g. ARIMA) can win out, and sometimes other complicated approaches such as Convolutional Neural Networks might be the best. (Yes, CNNs can be applied to some kinds of sequence data just like RNNs.) As always, the best way to know which model is best is to make the models and measure performance on a held out test set. Strong Assumptions of HMMs State transitions only depend on the current state, not on anything in the past. This assumption does not hold in a lot of the areas I am familiar with. For example, pretend you are trying to predict for every minute of the day whether a person was awake or asleep from movement data. The chance of someone transitioning from asleep to awake increases the longer the person has been in the asleep state. An RNN could theoretically learn this relationship and exploit it for higher predictive accuracy. You can try to get around this, for example by including the previous state as a feature, or defining composite states, but the added complexity does not always increase an HMM's predictive accuracy, and it definitely doesn't help computation times. You must pre-define the total number of states. Returning to the sleep example, it may appear as if there are only two states we care about. However, even if we only care about predicting awake vs. asleep , our model may benefit from figuring out extra states such as driving, showering, etc. (e.g. showering usually comes right before sleeping). Again, an RNN could theoretically learn such a relationship if showed enough examples of it. Difficulties with RNNs It may seem from the above that RNNs are always superior. I should note, though, that RNNs can be difficult to get working, especially when your dataset is small or your sequences very long. I've personally had troubles getting RNNs to train on some of my data, and I have a suspicion that most published RNN methods/guidelines are tuned to text data. When trying to use RNNs on non-text data I have had to perform a wider hyperparameter search than I care to in order to get good results on my particular datasets. In some cases, I've found the best model for sequential data is actually a UNet style ( https://arxiv.org/pdf/1505.04597.pdf ) Convolutional Neural Network model since it is easier and faster to train, and is able to take the full context of the signal into account.
