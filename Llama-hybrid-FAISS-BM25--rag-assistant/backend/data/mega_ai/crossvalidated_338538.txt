[site]: crossvalidated
[post_id]: 338538
[parent_id]: 
[tags]: 
Why do eligibility traces assign higher values to recently/frequently visited states?

For me the evolution of TD Algorithms looks like this: 1-step TD: problematic with sparse rewards => Inefficient use of experience n-step TD: better than 1-step, but what is the best n? (nobody knows without trying) n-step TD(lambda): combine all n-step returns and build a weighted average over all returns => Q/V function can only be updated at the end of an episode n-step TD(lambda) with eligibility traces: elegibility traces allow the Q/V function to be updated online/on the fly without waiting till an episode is over What I don't understand is why we need an eligibility trace at all? I think we could just ignore the eligibility trace because states which weren't visited frequently will have a small TD error so they won't be updated much anyway. Update rule: $Q(s_t,a_t)=Q(s_t,a_t)+\alpha \delta(s_t,a_t) et(s_t,a_t))$ TD error: $\delta (s_t,a_t)=R_t+ \gamma Q(s_{t+1},a_{t+1})âˆ’Q(s_t,a_t)$
