[site]: crossvalidated
[post_id]: 157718
[parent_id]: 157488
[tags]: 
First, try an optimization method like Adagrad or Adadelta that are more robust to learning rates. Also, make sure your gradient updated are correct (e.g. scipy has a check_grad method). Given that you have these two correct, I would then try to do greedy layer-wise pre-training in the first layers for some epochs. The reason is that your network is very deep and you will need proper initialisation to start training. If you are using Torch7 you can have a look at this and use the ConvNet example as pre-training https://github.com/torch/demos/blob/master/train-autoencoder/train-autoencoder.lua .
