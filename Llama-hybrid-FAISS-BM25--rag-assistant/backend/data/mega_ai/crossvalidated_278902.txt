[site]: crossvalidated
[post_id]: 278902
[parent_id]: 144154
[tags]: 
Disclaimer: I am no expert and I even have never done something with reinforcement learning (yet), so any feedback would be welcome... Here is an answer that adds some tiny mathematical notes to your list and some different thoughts on when to use what. I hope the enumeration is self-explanatory enough: Supervised We have data $\mathcal{D} = \{(\boldsymbol{x}_0,y_0), (\boldsymbol{x}_1,y_1), \ldots, (\boldsymbol{x}_n,y_n)\}$ We look for a model $g$ that minimises some loss/cost measure $L(y_i, g(\boldsymbol{x}_i))$ for all points $0 \leq i We evaluate the model by computing the loss/cost $L$ for the rest of the data ( $l \leq i \leq n$ ) in order to get an idea how well the model generalises We can give examples, but we cannot give an algorithm to get from input to output Setting for classification and regression Unsupervised We have data $\mathcal{D} = \{\boldsymbol{x}_0, \boldsymbol{x}_1, \ldots, \boldsymbol{x}_n\}$ We look for a model $g$ that gives us some insight in our data. We have little to no measures to say whether we did something useful/interesting We have some data, but we have no idea where to start looking for useful/interesting stuff Setting for clustering, dimensionality reduction, finding hidden factors, generative models, etc. Reinforcement We have no data We construct a model $g$ that generates data $\boldsymbol{x}_i$ (often called actions), which can be based on measurements and/or previous actions, in an attempt to maximise some reward measure $R(\boldsymbol{x}_i)$ , which is generally not known to the model (it needs to be learned as well). We evaluate by means of the reward function after it had some time to learn. We have no idea how to do something, but we can say whether it has been done right or wrong This seems especially useful for sequential decision tasks. References: Si, J., Barto, A., Powell, W. and Wunsch, D. (2004) Reinforcement Learning and Its Relationship to Supervised Learning, in Handbook of Learning and Approximate Dynamic Programming, John Wiley & Sons, Inc., Hoboken, NJ, USA. doi: 10.1002/9780470544785.ch2
