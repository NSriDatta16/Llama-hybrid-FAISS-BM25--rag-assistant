[site]: stackoverflow
[post_id]: 2066890
[parent_id]: 
[tags]: 
Efficient File I/O and Conversion of Strings to Floats

I have some gigantic (several gigabyte) ASCII text files that I need to read in line-by-line, convert certain columns to floating point, and do a few simple operations on these numbers. It's pretty straightforward stuff, except that I'm thinking that there has to be a way to speed it up a whole bunch. The program never uses the equivalent of 100% of a CPU core because it spends so much time waiting on I/O. At the same time, it spends enough time doing computations instead of I/O that it only does ~8-10 MB/sec of raw disk I/O. I've seen my hard drive do a lot better than that. Would it likely help to do the I/O and processing in separate threads? If so, what's an efficient way of implementing this? An important issue is what to do with memory allocation for holding each line so that I don't bottleneck on that. Edit: I'm using the D programming language, version 2 standard lib., mostly the higher level functions, for most of this stuff right now. The buffer size used by std.stdio.File is 16 KB.
