[site]: crossvalidated
[post_id]: 541729
[parent_id]: 541677
[tags]: 
Here are a few runs with different values of $p$ and $\sigma$ (in the title of the plots) and $n=100$ realisations for each: The histogram is based on $10^4$ Gibbs steps and the curve is the exact likelihood, renormalised to fit the height of the histogram. Whatever the values of $(p,\sigma)$ the fit is quite acceptable and indicate that the convergence properties of the Gibbs sampler are satisfactory. A random walk Metropolis-Hastings algorithm could be used instead but there is no argument to believe it would do better. Concerning the other questions, The number of MCMC iterations is not directly connected with the sample size $n$ . As $n$ grows, the likelihood gets peakier (around the true value of the parameter) which means it may be be harder to reach, but also that it is smoother (asymptotically Normal) and thus easier to explore. The posterior (equivalent to the likelihood in this case) is found properly, as shown by the pictures.
