[site]: crossvalidated
[post_id]: 598761
[parent_id]: 598748
[tags]: 
It's probably easiest to test such hypotheses on means (average revenue per user) rather than on the totals (sums of revenue in each group). But both are doable since means and totals are closely related: $$\frac{1}{N} \sum_i^N y_i = \bar y \rightarrow \sum_i^N y_i = N \cdot \bar y$$ Here is a Stata example using a dataset of 48 pigs whose weight is observed over nine weeks. We start by loading the data: . #delimit; delimiter now ; . webuse pig, clear; (Longitudinal analysis of pig weights) . xtset id week; Panel variable: id (strongly balanced) Time variable: week, 1 to 9 Delta: 1 unit . xtdescribe; id: 1, 2, ..., 48 n = 48 week: 1, 2, ..., 9 T = 9 Delta(week) = 1 unit Span(week) = 9 periods (id*week uniquely identifies each observation) Distribution of T_i: min 5% 25% 50% 75% 95% max 9 9 9 9 9 9 9 Freq. Percent Cum. | Pattern ---------------------------+----------- 48 100.00 100.00 | 111111111 ---------------------------+----------- 48 100.00 | XXXXXXXXX Now we split the pigs into three groups (24 in A and 12 each in B and C): . set seed 12112022; . splitsample, cluster(id) split(.5 .25 .25) gen(group); . label define group 1 "A" 2 "B" 3 "C"; . label values group group; We will force the B pigs to gain 10% more weight: . generate gain = D1.weight; (48 missing values generated) . replace gain = 1.1*gain if group =="B":group; (96 real changes made) . collapse (sum) gain, by(id group); The last step sums up each pig's weight gain over the 9 weeks. This gets us back to 48 observations/rows. Let's set Group C aside for now, so we only have 36 pigs to work with. We can do the test on totals: . /* (1) Test Two Totals */ > total gain if inlist(group,"A":group,"B":group), over(group); Total estimation Number of obs = 36 -------------------------------------------------------------- | Total Std. err. [95% conf. interval] -------------+------------------------------------------------ c.gain@group | A | 1212.5 25.43 1160.874 1264.126 B | 657.8 22.59203 611.9357 703.6643 -------------------------------------------------------------- Though pigs in B grow faster, there are twice as many pigs in A, so the total is ~1.8 bigger. We can remedy that by scaling the Group B total by 2 as if it had 24 pigs: . test _b[c.gain@1.group] = 2*_b[c.gain@2.group]; ( 1) c.gain@1bn.group - 2*c.gain@2.group = 0 F( 1, 35) = 3.95 Prob > F = 0.0546 This is a two-sided test, but we want the one-sided test that $\Delta \le 0$ against $\Delta > 0$ , so we need to divide the p-value by 2: 0.0546/2 = 0.0273. This can be interpreted as saying that if the pigs grew at the same rate and we adjusted for the unequal group size, we would observe a difference like 1212.5-2*657 = -103.1 kg (or even more negative) only 2.7% of the time. Since seeing such a difference would be unusual under the null, we reject the null as false in favor of the alternative that B is better than A. We can do the same test on the means: . /* Test Two Means */ > ttest gain if inlist(group,"A":group,"B":group), by(group) reverse unpaired unequal; Two-sample t test with unequal variances ------------------------------------------------------------------------------ Group | Obs Mean Std. err. Std. dev. [95% conf. interval] ---------+-------------------------------------------------------------------- B | 12 54.81667 1.88267 6.521759 50.67294 58.96039 A | 24 50.52083 1.059583 5.190877 48.32892 52.71275 ---------+-------------------------------------------------------------------- Combined | 36 51.95278 .9901258 5.940755 49.94272 53.96284 ---------+-------------------------------------------------------------------- diff | 4.295833 2.160361 -.2393633 8.83103 ------------------------------------------------------------------------------ diff = mean(B) - mean(A) t = 1.9885 H0: diff = 0 Satterthwaite's degrees of freedom = 18.199 Ha: diff 0 Pr(T |t|) = 0.0620 Pr(T > t) = 0.0310 Here we get a one-sided p-value of 0.0310 directly, which is close to what we got with the totals above. These commands make slightly different small sample adjustments, but any differences will be much smaller with a bigger sample. You can do the same thing with regression: . /* (2) Test Means Using Two-Group Regression */ > regress gain i.group if inlist(group,"A":group,"B":group), vce(hc2); Linear regression Number of obs = 36 F(1, 34) = 3.95 Prob > F = 0.0549 R-squared = 0.1195 Root MSE = 5.6558 ------------------------------------------------------------------------------ | Robust HC2 gain | Coefficient std. err. t P>|t| [95% conf. interval] -------------+---------------------------------------------------------------- group | B | 4.295833 2.160361 1.99 0.055 -.0945492 8.686216 _cons | 50.52083 1.059583 47.68 0.000 48.3675 52.67417 ------------------------------------------------------------------------------ . test _b[2.group] == 0; ( 1) 2.group = 0 F( 1, 34) = 3.95 Prob > F = 0.0549 Again, we need to divide the p-value by 2. But we can also calculate totals from the regression by multiplying by 24 and 12: . /* (3) Totals From Regression */ > nlcom (A_Total: _b[_cons]*24) (B_Total: (_b[_cons] + _b[2.group])*12), post; A_Total: _b[_cons]*24 B_Total: (_b[_cons] + _b[2.group])*12 ------------------------------------------------------------------------------ gain | Coefficient Std. err. z P>|z| [95% conf. interval] -------------+---------------------------------------------------------------- A_Total | 1212.5 25.43 47.68 0.000 1162.658 1262.342 B_Total | 657.8 22.59203 29.12 0.000 613.5204 702.0796 ------------------------------------------------------------------------------ . test _b[A_Total] == 2*_b[B_Total]; ( 1) A_Total - 2*B_Total = 0 chi2( 1) = 3.95 Prob > chi2 = 0.0468 This is all to say that you can use regression to test many kinds of hypotheses about more than two groups: . /* (4) Three Group Regression */ > regress gain i.group, vce(hc2); Linear regression Number of obs = 48 F(2, 45) = 2.37 Prob > F = 0.1053 R-squared = 0.1146 Root MSE = 5.6343 ------------------------------------------------------------------------------ | Robust HC2 gain | Coefficient std. err. t P>|t| [95% conf. interval] -------------+---------------------------------------------------------------- group | B | 4.295833 2.160361 1.99 0.053 -.0553579 8.647025 C | -.6041667 1.924946 -0.31 0.755 -4.481208 3.272874 | _cons | 50.52083 1.059583 47.68 0.000 48.38672 52.65494 ------------------------------------------------------------------------------ . test 2.group; ( 1) 2.group = 0 F( 1, 45) = 3.95 Prob > F = 0.0529 . test 3.group; ( 1) 3.group = 0 F( 1, 45) = 0.10 Prob > F = 0.7551 . test 2.group == 3.group; ( 1) 2.group - 3.group = 0 F( 1, 45) = 3.92 Prob > F = 0.0539 . test 2.group == 3.group == 0; ( 1) 2.group - 3.group = 0 ( 2) 2.group = 0 F( 2, 45) = 2.37 Prob > F = 0.1053 These are p-values for the two-sided hypotheses that I mentioned in the comments.
