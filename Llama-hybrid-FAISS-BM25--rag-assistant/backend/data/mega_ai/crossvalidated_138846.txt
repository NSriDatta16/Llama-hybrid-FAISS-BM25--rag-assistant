[site]: crossvalidated
[post_id]: 138846
[parent_id]: 118500
[tags]: 
First you need to know the definition of probability graphical model (PGM). Given a graph G, a distribution p. a PGM is a pair (G,p), where p factorizes over G.[^1] The keypoint is where G is a graph , not a factor graph. Well ,I think there is nothing wrong to say factor graphical model (factor graph G, a distribution p) , though there's no such use in literature, because factor graph has redundant information for this definition. The graph's main advantage to representation is I-map property (i.e. conditional independence ). Even so, it is not very fined-grained representation. That's why factor graph or other representations comes in. (e.g. many factor graphs may represent the same Markov Network [^2] ) In UGM case, we usually have three representation : Markov Network, Factor Graph, Log-linear Model. The latter is finer-grained than previous one.[^3] Why inference use factor graph? My opinion is it can represent directed and undirected graphical model. Many inferences are agnostic to both models. it can reveal more finer structure than Markov Network that help the message passing algorithm. [^4] Though I am not very familiar to Belief propagation ,I guess it may like reveal tree structure that is ambiguity (to a clique) in Markov Network. [^1]: Kollar & Friedman 2009 (definition 3.5) [^2]: Murphy 2012 (Figure 22.2) [^3]: Kollar & Friedman 2009 (4.4) [^4]: Murphy 2012 (22.2.3.1) reference: Kollar & Friedman 2009. Probabilistic Graphical Model. Murphy 2012. Machine Learning, a probabilistic perspective.
