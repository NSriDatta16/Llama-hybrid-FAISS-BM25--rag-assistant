[site]: crossvalidated
[post_id]: 355743
[parent_id]: 
[tags]: 
Bayesian regression estimate not matching with true value in simple example

I'm quite new to applying the techniques of Bayesian regression. I was experimenting with a simple example where I was comparing the results of Bayesian with the actual values. In this simple example, I just used univariate linear regression with a normally distributed error term and X that was uniformly sampled Here is the data: data = pd.DataFrame( {"X": np.random.RandomState(42).choice(map(lambda x: float(x)/10000.0, np.arange(10000)), 10000, replace=False)}) data["Y"] = 5 + 3*data["X"] + np.random.RandomState(42).normal(0.0, 0.5, 10000) description: X is a uniform sample drawn from [0,1,2,3...9999]/10000 Y = 5 + 3 * X + N(0,0.5) I used Pymc3 to find the posterior distributions of the intercept and coefficient term. I used a normally distributed prior. The complete code is as follows: import pymc3 as pm import numpy as np import pandas as pd import matplotlib.pyplot as plt data = pd.DataFrame( {"X": np.random.RandomState(42).choice(map(lambda x: float(x)/10000.0, np.arange(10000)), 10000, replace=False)}) data["Y"] = 5 + 3*data["X"] + np.random.RandomState(42).normal(0.0, 0.5, 10000) with pm.Model() as normal_model: # The prior for the data likelihood is a Normal Distribution family = pm.glm.families.Normal() # Creating the model requires a formula and data (and optionally a family) pm.GLM.from_formula("Y~X", data=data, family=family) start = pm.find_MAP() # Perform Markov Chain Monte Carlo sampling letting PyMC3 choose the algorithm trace = pm.sample(5000, start=start,tune =1000, random_seed=42, progressbar=True) pm.traceplot(trace[500:]) plt.show() #Some convergence plots fig, axes = plt.subplots(2, 5, figsize=(14,6)) axes = axes.ravel() for i in range(10): axes[i].hist(beta_trace[500*i:500*(i+1)]) plt.tight_layout() plt.show() z = geweke(trace, intervals=15) print(z[0]['X']) plt.scatter(*(z[0]['X']).T) plt.hlines([-1,1], 0, 3000, linestyles='dotted') plt.xlim(0, 3000) plt.show() In this case the result was quite close to the actual values. Estimates and GWEKE convergence for the X coefficient: However, now I change the X vector to: data = pd.DataFrame( {"X": np.random.RandomState(42).choice(map(lambda x: float(x)/100.0, np.arange(10000)), 10000, replace=False)}) data["Y"] = 5 + 3*data["X"] + np.random.RandomState(42).normal(0.0, 0.5, 10000) description: X is a uniform sample drawn from [0,1,2,3...9999]/100 Y = 5 + 3 * X + N(0,0.5) Notice that I have used float(x)/100.0 instead of float(x)/10000.0. In this case although the intercept term is converging to the actual value, the mode of the coefficient is around 0. Estimates and GWEKE convergence for the X coefficient: I looked at the convergence stats and it seems that the samples are converging in both cases. Is this because the gaussian prior is incorrect and not suitable in the second case? Even if I increase the observations and samples, the X coefficient is nowhere close to the actual one. If the prior is incorrect what could be a good prior in this case Can you please help me understand why results of Bayesian regression coming out to be incorrect? As long as X was uniformly varying between 0-1 it worked fine. Thanks
