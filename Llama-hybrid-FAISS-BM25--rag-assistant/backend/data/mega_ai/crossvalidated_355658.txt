[site]: crossvalidated
[post_id]: 355658
[parent_id]: 354904
[tags]: 
Here is my educated guess what is off ... Suppose you have these simplified data sets X_mc Y_mc 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 X_data Y_date 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 As you can see, the class probabilities for class=0 for x=0 are Based on Y_mc: 0.8 Based on Y_data: 0.2 So: When applying your algorithm, all mc-examples with will be assigned to class 1. Class probability means, that on average for comparable input a certain percentage of the input has class 0, the rest class 1. It is not a winner-takes-it-all mechanism. You can simulate this (Pseudo code !): if (mc.loc[i]['mc_class'] == 0): if y_mc[i][0] > y_data[i][0] and random(0,1) So in my example, y_mc[i][0]-y_data[i][0] is 0.8-0.2=0.6. That means, that on average 60 % of the examples with class 0 will be assigned to class 1. I think this is related to rejection sampling , but this is not my area of expertise.
