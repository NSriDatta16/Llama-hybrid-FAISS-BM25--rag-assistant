[site]: stackoverflow
[post_id]: 192614
[parent_id]: 84820
[tags]: 
First, you have to decide if you're going to build your hierarchy bottom-up or top-down. Bottom-up is called Hierarchical agglomerative clustering. Here's a simple, well-documented algorithm: http://nlp.stanford.edu/IR-book/html/htmledition/hierarchical-agglomerative-clustering-1.html . Distributing a bottom-up algorithm is tricky because each distributed process needs the entire dataset to make choices about appropriate clusters. It also needs a list of clusters at its current level so it doesn't add a data point to more than one cluster at the same level. Top-down hierarchy construction is called Divisive clustering . K-means is one option to decide how to split your hierarchy's nodes. This paper looks at K-means and Principal Direction Divisive Partitioning (PDDP) for node splitting: http://scgroup.hpclab.ceid.upatras.gr/faculty/stratis/Papers/tm07book.pdf . In the end, you just need to split each parent node into relatively well-balanced child nodes. A top-down approach is easier to distribute. After your first node split, each node created can be shipped to a distributed process to be split again and so on... Each distributed process needs only to be aware of the subset of the dataset it is splitting. Only the parent process is aware of the full dataset. In addition, each split could be performed in parallel. Two examples for k-means: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.1882&rep=rep1&type=pdf http://www.ece.northwestern.edu/~wkliao/Kmeans/index.html .
