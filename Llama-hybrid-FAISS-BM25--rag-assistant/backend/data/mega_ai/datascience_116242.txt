[site]: datascience
[post_id]: 116242
[parent_id]: 
[tags]: 
Unable to build a XGBoost classifier that gives good precision and recall on highly imbalanced data

The XGBoost Classifier I built is consistently returning a f1 score of 0 and I am unable to fix this despite experimenting with various hyperparameters. The data is heavily imbalanced and hence I feel the model in trying to maximize accuracy is behaving like this . Even changing the eval_metrics to use "aucpr" had no effect. I have searched on Google quite a bit but am unable to find out how to increase the f1 score as either I get high precision or high recall but not both . Please let me know if I am missing something This is the code I am using. The csv file has 100,000 rows and 2 numeric columns as the feature set and 1 response variable (0 or 1) hence no transformation was carried out . df = pd.read_csv("Output\\SimulatedData.csv") X = df.drop('Response', axis=1) y = df["Response"] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=25) estimator_ = XGBClassifier(objective='binary:logistic', eval_metric='aucpr') estimator_.fit(X_train, y_train) y_pred = estimator_.predict(X_test)
