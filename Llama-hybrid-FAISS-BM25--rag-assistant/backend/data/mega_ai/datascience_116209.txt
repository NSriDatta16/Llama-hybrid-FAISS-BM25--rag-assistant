[site]: datascience
[post_id]: 116209
[parent_id]: 
[tags]: 
Trying to make a visualization for training performance

I am using scikit learn's BayesianRidge model to fit a regression to tabular data of d features and N sample. I have already tested how well my model performs using a repeated kfold cross validation check on the dataset. However, when I do this, I cannot make a visualization of how this model performed because I use scikit learns cross_validate method which only returns an array of the testing scores. This is not ideal for me because I want to know what the model has learned, which in my case is the weight vector, lambda and alpha parameters, and the covariance of the posterior over the weight vector. And I cannot extract this from the cross_validate method (to my knowledge) because I can't extract the fitted models per test. I also had hoped to create a visualization of model performance. I know I get the scores of model performance from the cross_validate method, but a visualization would be preferable. So, I was thinking of training the model on the whole dataset, using scikit learn's BayesianRidge, then obtaining estimates for the labels using the .predict(X) method, where X = whole dataset. Then I could make a one-to-one plot of estimated labels versus observed labels What I am wondering is (1) is there a way to extract the best model from scikit learn's cross_validate method. (2) If there is not, then is it valid to fit a model on the whole dataset then make predictions using the whole dataset to get a feeling for training performance? I only want to do this to get the learned parameters and a visualization. Thanks in advance for the help
