[site]: crossvalidated
[post_id]: 365220
[parent_id]: 
[tags]: 
How to choose suitable Autoencoder (LSTM) architecture?

I am new to Autoencoders and I am a bit confused on which model to try for my situation and what is the difference between all the different models I have seen in tutorials. So, I have a set of time-series of a certain length w , so my input dataset X has a shape (5000,50,1) , where 5000 is the amount of small time-series and w=50 . I have seen the following options: LSTM -> Dense -> Linear Activation. For me it seems that the decoding layer is missing here. Or this would still work? LSTM(64) -> RepeatVector( w ) -> LSTM( w ). This one gives me the error, because it's output seems to be of shape ( None, w, w ), while I would actually expect ( None, w, 1 ), corresponding to the original input. How to fix this problem? Or it is actually supposed to be like that and I just don't understand something about Autoencoders? Here is the code that I used: def create_model(): model = Sequential() model.add(LSTM(64, input_shape=(w,1))) model.add(RepeatVector(w)) model.add(LSTM(w, return_sequences=True)) return model Same architecture but divided into separate Encoder and Decoder model. I haven't tried this because I would prefer just one model. Or is this option also worth trying? Thanks.
