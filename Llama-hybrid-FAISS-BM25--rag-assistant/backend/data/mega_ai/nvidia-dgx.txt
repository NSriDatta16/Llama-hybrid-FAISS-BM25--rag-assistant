The Nvidia DGX (Deep GPU Xceleration) is a series of servers and workstations designed by Nvidia, primarily geared towards enhancing deep learning applications through the use of general-purpose computing on graphics processing units (GPGPU). These systems typically come in a rackmount format featuring high-performance x86 server CPUs on the motherboard. The core feature of a DGX system is its inclusion of 4 to 8 Nvidia Tesla GPU modules, which are housed on an independent system board. These GPUs can be connected either via a version of the SXM socket or a PCIe x16 slot, facilitating flexible integration within the system architecture. To manage the substantial thermal output, DGX units are equipped with heatsinks and fans designed to maintain optimal operating temperatures. This framework makes DGX units suitable for computational tasks associated with artificial intelligence and machine learning models. Models Pascal - Volta DGX-1 DGX-1 servers feature 8 GPUs based on the Pascal or Volta daughter cards with 128 GB of total HBM2 memory, connected by an NVLink mesh network. The DGX-1 was announced on 6 April 2016. All models are based on a dual socket configuration of Intel Xeon E5 CPUs, and are equipped with the following features. 512 GB of DDR4-2133 Dual 10 Gb networking 4 x 1.92 TB SSDs 3200W of combined power supply capability 3U Rackmount Chassis The product line is intended to bridge the gap between GPUs and AI accelerators using specific features for deep learning workloads. The initial Pascal-based DGX-1 delivered 170 teraflops of half precision processing, while the Volta-based upgrade increased this to 960 teraflops. The DGX-1 was first available in only the Pascal-based configuration, with the first generation SXM socket. The later revision of the DGX-1 offered support for first generation Volta cards via the SXM-2 socket. Nvidia offered upgrade kits that allowed users with a Pascal-based DGX-1 to upgrade to a Volta-based DGX-1. The Pascal-based DGX-1 has two variants, one with a 16 core Intel Xeon E5-2698 V3, and one with a 20 core E5-2698 V4. Pricing for the variant equipped with an E5-2698 V4 is unavailable, the Pascal-based DGX-1 with an E5-2698 V3 was priced at launch at $129,000 The Volta-based DGX-1 is equipped with an E5-2698 V4 and was priced at launch at $149,000. DGX Station Designed as a turnkey deskside AI supercomputer, the DGX Station is a tower computer that can function completely independently without typical datacenter infrastructure such as cooling, redundant power, or 19 inch racks. The DGX station was first available with the following specifications. Four Volta-based Tesla V100 accelerators, each with 16 GB of HBM2 memory 480 TFLOPS FP16 Single Intel Xeon E5-2698 v4 256 GB DDR4 4x 1.92 TB SSDs Dual 10 Gb Ethernet The DGX station is water-cooled to better manage the heat of almost 1500W of total system components, this allows it to keep a noise range under 35 dB under load. This, among other features, made this system a compelling purchase for customers without the infrastructure to run rackmount DGX systems, which can be loud, output a lot of heat, and take up a large area. This was Nvidia's first venture into bringing high performance computing deskside, which has since remained a prominent marketing strategy for Nvidia. DGX-2 The Nvidia DGX-2, the successor to the DGX-1, uses sixteen Volta-based V100 32 GB (second generation) cards in a single unit. It was announced on 27 March 2018. The DGX-2 delivers 2 Petaflops with 512 GB of shared memory for tackling massive datasets and uses NVSwitch for high-bandwidth internal communication. DGX-2 has a total of 512 GB of HBM2 memory, a total of 1.5 TB of DDR4. Also present are eight 100 Gbit/s InfiniBand cards and 30.72 TB of SSD storage, all enclosed within a massive 10U rackmount chassis and drawing up to 10 kW under maximum load. The initial price for the DGX-2 was $399,000. The DGX-2 differs from other DGX models in that it contains two separat