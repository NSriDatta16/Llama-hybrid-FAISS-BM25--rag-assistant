[site]: datascience
[post_id]: 86699
[parent_id]: 85389
[tags]: 
Unet was published around 2015 and still regarded as state of the art. Since then different versions of Unet has appeared. Resnet, Squeezenet blocks can be used instead of normal convolutional blocks in Unet. In addition to that, DeepLab currently holds top position in most of the benchmarks. But it is not ideal to train from scratch since the model is too big. Averagely one epoch of DeepLab v3+ (newest edition) takes 10 mins to train in the original implementation in Google Colab. In addition to that, mean IoU increases very slowly, and hence you will have to train for 1000s of epochs. But in Unet, the model is very small and trains very quickly. The best thing about Unet is that it can be trained for even 30 images. I myself have used Unet for 14 images and got very good results.
