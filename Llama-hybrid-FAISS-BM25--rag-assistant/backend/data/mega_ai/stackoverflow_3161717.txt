[site]: stackoverflow
[post_id]: 3161717
[parent_id]: 3161548
[tags]: 
Okay, as all posts say, if you want to make it search engine-friendly then bots can scrape for sure. But you can still do a few things, and it may be affective for 60-70 % scraping bots. Make a checker script like below. If a particular IP address is visiting very fast then after a few visits (5-10) put its IP address + browser information in a file or database. The next step (This would be a background process and running all time or scheduled after a few minutes.) Make one another script that will keep on checking those suspicious IP addresses. Case 1. If the user Agent is of a known search engine like Google, Bing , Yahoo (you can find more information on user agents by googling it). Then you must see http://www.iplists.com/ . This list and try to match patterns. And if it seems like a faked user-agent then ask to fill in a CAPTCHA on the next visit. (You need to research a bit more on bots IP addresses. I know this is achievable and also try whois of the IP address. It can be helpful.) Case 2. No user agent of a search bot: Simply ask to fill in a CAPTCHA on the next visit.
