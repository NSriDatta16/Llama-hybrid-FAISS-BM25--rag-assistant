[site]: crossvalidated
[post_id]: 452601
[parent_id]: 452584
[tags]: 
Yes, in principle your "classical" approaches would catch periodicities and autocorrelations as well. Fitting an AR time series model is not that much different from OLS regressing the actuals on lagged values of the actuals, after all. However: Suppose you run a standard linear regression with day, month and year as predictors. Your regression will not understand that a predictor setting (1, 3, 2020) is very similar to (29, 2, 2020). Yes, the third predictor is identical, but the other two are not, and the difference in the fit will be $28\hat{\beta}_{\text{Day}}+\hat{\beta}_{\text{Month}}$ . Compare this to the difference in the fits for a predictor setting of (28, 2, 2020) versus (29, 2, 2020), which is just $\hat{\beta}_{\text{Day}}$ , although the two pairs of predictor settings are both spaced just one day apart. Also, regression has no idea of autoregression. Of course, you can hand-craft your regression, by including a day counter to account for the first fact above, and lagged values of the outcome to account for autoregression. But this will be a lot of work, and it will actually not be mathematically optimal. Now suppose you look at a decision tree, or possibly a Random Forest. Yes, this should be able to learn interactions between predictors, like the difference between (1, 3, 2020) and (29, 2, 2020) above. However, it will need a lot of data to do so. Much more than if you just used a time series approach. Bottom line: you can either use a specific tool for the job (time series analysis), or adapt other tools (regression with a lot of predictor adaptation), or use very general tools that will then require a lot of data (CARTs and Random Forests).
