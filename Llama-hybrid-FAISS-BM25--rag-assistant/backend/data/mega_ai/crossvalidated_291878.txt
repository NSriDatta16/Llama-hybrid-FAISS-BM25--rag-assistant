[site]: crossvalidated
[post_id]: 291878
[parent_id]: 
[tags]: 
kullback leibler divergence between two nested logistic regression models

I have two logistic nested models $\log\dfrac{p_i}{1-p_i}=\beta_{0}+\beta_1 x_i$ and $\log\dfrac{p_i}{1-p_i}=\beta_{0}$ How can I construct the kullback leibler divergence between two nested logistic regression models? Can I use the estimates of $\beta_0$ and $\beta_1$ to calculate KL divergence between these two logistic models? Is there any reference to the kullback leibler divergence between two GLM models?
