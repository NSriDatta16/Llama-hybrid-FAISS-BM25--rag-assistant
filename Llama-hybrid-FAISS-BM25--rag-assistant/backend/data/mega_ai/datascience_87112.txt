[site]: datascience
[post_id]: 87112
[parent_id]: 87083
[tags]: 
In multi-patient datasets a typical cross validation split is leave-subject-out, check this out: What is difference between leave one subject out and leave one out cross validation Basically, each subject used as test subjects in different folds. Your dataset has a few issues. Firstly, depending on your use case there might or not be data leakage. For example, if it is possible to firstly observe enough time series samples of a subject for training, say the first half, then it's ok to use the second half for testing. Secondly, two of your classes appear on two single subjects. For these two, you can't design an algorithm on based on other subject's data. Thirdly, and more importantly, most classes don't have enough samples. For example, the eat_soup class has only 3 samples. In summary, you should use leave-subject-out but on the classes that appear on a substantial number of subjects and there is enough samples in total.
