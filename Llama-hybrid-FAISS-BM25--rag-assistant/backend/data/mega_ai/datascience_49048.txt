[site]: datascience
[post_id]: 49048
[parent_id]: 
[tags]: 
Why did Logistic regression perform better than svm?

I have a data set of movies and their subtitles.My task is to classify them based on their ratings-[R,NR,PG,PG-13,G]. I have tried different ML algorithms and found that Logistic regression out performed them all, but I am unable to figure out why.My data had more features than observations. SVM- should perform well on high dimensional data and will perform well even the there is class imbalance, but failed to show great results. Naive Bayes-I think Naive Bayes did not perform well because of class imbalance. Random forest-decent performance.but did not out perform logistic regression. I am looking for an explanation as to why did one perform better than the other. Note:The data set is sparse and it has more features/parameters than observations/examples.
