[site]: datascience
[post_id]: 122834
[parent_id]: 
[tags]: 
PySpark Logistic regression model weights are inconsistent between runs

I am training a pyspark logistic regression model using pyspark mllib. I am noticing that the weights are not being consistent in between runs. I have set the random seed in the training script and also am making a deterministic split between training and testing data using TrainValidationSplit . With low number of records i.e., less than 1million input records, the model weights match exactly between runs. But as I increase the volume of the data (to >20M records), I am noticing that the weights are fluctuating. Some of them are zero during one iteration while in other iterations, they have values in the 10^(-3) range. Can anyone help me understand why this could be happening? Note: I am doing a constrained optimization - I am setting lower bounds weights and intercept to be zero and non-negative.
