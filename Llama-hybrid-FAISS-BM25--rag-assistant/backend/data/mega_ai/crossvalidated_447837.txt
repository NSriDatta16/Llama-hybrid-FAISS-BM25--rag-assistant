[site]: crossvalidated
[post_id]: 447837
[parent_id]: 
[tags]: 
High AUC, low f1, SVM threshold for an unbalanced problem

I have a very unbalanced binary classification problem (positive class: 0.2%). I need to evaluate it using f1 of the positive class. Now, I'm doing some baselines using an SVM. What I get is a relatively low f1 (0.61) and a very high AUC (0.98). If I understood it correctly, this means that the classifier correctly ranks my examples, but it uses an operating point that is not optimal. So, my questions are: Is my understanding correct? Is SVM using a threshold of 0.5? Does it make sense (both mathematically and from a ML point of view) to tune this parameter, for example by using cross-validation?
