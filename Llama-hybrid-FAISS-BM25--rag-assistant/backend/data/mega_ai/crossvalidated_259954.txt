[site]: crossvalidated
[post_id]: 259954
[parent_id]: 259950
[tags]: 
No, a neural network is not several consecutive linear transformations. As you note, that would only result in another linear transformation in the end, so why do many instead of one? Actually, a neural network performs several (at least one, but possibly more, depending on the number of hidden layers) nonlinear (e.g. sigmoid) transformations. That is also the difference between a neural network and a linear regression, since the latter uses a linear combination of regressors to approximate the regressand.
