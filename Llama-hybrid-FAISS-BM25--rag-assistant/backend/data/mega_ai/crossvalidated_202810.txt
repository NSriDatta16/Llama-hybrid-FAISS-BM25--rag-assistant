[site]: crossvalidated
[post_id]: 202810
[parent_id]: 202447
[tags]: 
This scientific approach you ask for, I would call some reasonable rules of thumb, here's a list (please edit): If a simple model is good enough, then stay with simple. If you expect noisy data, use regularization and robust methods If your data set is flat (more features than observations) your probably gonna need more regularization If you expect unknown non-linear relationships, then use a non-linear learner(not standard logistic regression) Pick a learner which is likely to fit your data structure well. Resort to outer repeated cross-validation to confirm. +10k observations, RF faster than SVM SVM + One hot encoding may not work well for features with +~5 categories randomFoerst will become slow +~15 categories (consider merging categories or use sklearn implementation or Rborist or extraTrees or xgboost(gradient boosting))
