[site]: crossvalidated
[post_id]: 494109
[parent_id]: 
[tags]: 
Why not use large ($n - [n^{0.75}]$) validation sets in machine learning training loop?

I am seeking feedback in the form of answers to a bold question. Please limit comments to requests for clarification of the question only. There appears to be an influence on machine learning practice from the theory of cross-validation. However, since machine learning training loops do not actually perform cross-validation, but only a single validation to calculate a gradient, why do most machine learning practitioners use a smaller validation data set than the size of their training data for each epoch? Why do we, as a community of practicing statisticians, not advocate instead for the use of Jun Shao's $n^{\frac{3}{4}}$ rule when choosing the machine learning training set size? This would guarantee that a machine learning validation set is never smaller than a training set. I implore you to look at the logo of this web site and ponder how deeply the traditions of $k$ -fold (in particular, 5-fold) cross-validation have influenced the world and our own community. In particular, please observe how the logo seems to reinforce the practice of validating on 1/5 of the data after training on 4/5 (when using 5-fold CV). I propose a better method: train on $n_c \equiv n^{\frac{3}{4}}$ , validate on $n_v \equiv n - n_c$ data points. And do not use cross-validation; use a better approximation of Bayesian inference, such as sequential model-based optimization, instead. If you are training on synthetic data, and/or your data set is so large that you cannot possibly use anywhere close to all of it for training/validation, I suggest training on 128 data points, then validating on 512. This reverses the usual practice of training on 4/5 and validate on 1/5 when applied to a data set of size 640, and has the advantage that each data set is a whole power of two (actually Shao would have suggested training on 127, validating on 513 but this is a big enough step in the right direction that I am willing to compromise, because the $\frac{3}{4}$ exponent was probably not the only one he could have chosen).
