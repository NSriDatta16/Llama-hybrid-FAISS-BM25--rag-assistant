[site]: datascience
[post_id]: 117279
[parent_id]: 97809
[tags]: 
The verbiage used in the Wikipedia article regarding the data set being "normalized" or "standardized" is confusing. Typically in machine learning, normalization of a data set is some sort of scaling of the observations or features before a learning algorithm is applied, e.g., scaling of each feature such that all feature values lie in [0, 1]. Or, the scaling of each observation such that their norms are 1, like the OP mentioned. But that's not what's happening in SVM. If I were to write a detailed article on SVM, instead of saying that the data set is normalized, I'd say something like "without loss of generality." Meaning, if the classes are linearly separable, we can assume without loss of generality that we can find a hyperplane wx - b = 0 such that the value of | wx - b| is 1 for all support vectors. This is because all support vectors are equidistant from the hyperplane, and that distance is proportional to | wx - b|, based on the formula for distance of a point from that hyperplane . The value of | wx - b| is the same for all support vectors. This means we can assign an arbitrary value to | wx - b|, and SVM solution will scale w and b accordingly to arrive at the same hyperplane. By convention, | wx - b| is 1 for all support vectors.
