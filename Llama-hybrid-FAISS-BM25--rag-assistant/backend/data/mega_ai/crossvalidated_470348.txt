[site]: crossvalidated
[post_id]: 470348
[parent_id]: 
[tags]: 
why model perform slighty worst after removing co-related features

I have a classification problem on which I am testing the main classification models like Logistic Regression, SVM, KNN and deep neural networks. I have a feature set of 40. And around 5-6 are highly co-related with value >=.9 or To my surprise, when I am removing these co-related variables, the performance slightly gets bad on test data. Now, as per my theoretical knowledge, removing correlated features should remove noise and this improves performance. Upon, googling I found 1 article which pointed out to drop only those which are not co-related with output result. I tried that too but still not luck. Performance reduces slightly after dropping those features. As I am new to data science, can someone guide me on where I could be understanding or going wrong. P.S : I am not sharing data information or implementation details, as I am interested in first knowing the possibility of this case.
