[site]: datascience
[post_id]: 43935
[parent_id]: 
[tags]: 
Mapping 4 Dimensional array to predicted output text

Iv been studying machine learning but im struggling with some concepts and cant seem to find particular answers to the question of how theoretical data is mapped into non classification categories. To be specific , in the problem I am addressing : I have a 4 dimensional image array with R,G,B and Alpha values. I wish to map those input values to expected output values in JSON to train a model which will automatically parse an image into a JSON command based representation: { "name": "img", "attrs": { "height": "210", "width": "400" }, "childs": [ { "name": "path", "attrs": { "p": "M150 0 L75 200 L225 200 Z" } } ] } The issue is I am struggling to conceptually understand how you can map the byte array input or RGB array input values to the expected JSON output to generate the model as the output is a text based prediction alteration of values rather than a classification of particular pixels with a finite set of results. I know it is possible as I have seen Convolutional neural networks used to map-predict 2 dimensional image data to 3 dimensional model data in OBJ format which is a similar problem to solve however I am uncertain how the mapping from pixel data to expected text based 3D vectors was performed. Can anyone recommend any articles or outline their experience in representing non-classification/finite result output or atleast point me in the direction of which category of problems this falls under as every example of CNN's etc seem to fall into classification output problems such as object identification rather than numerical prediction output.
