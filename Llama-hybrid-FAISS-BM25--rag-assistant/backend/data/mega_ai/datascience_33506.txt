[site]: datascience
[post_id]: 33506
[parent_id]: 33448
[tags]: 
Spectral clustering is a family of algorithms for treating larger datasets with complex-network representations. "Large" means "more than a few thousands of nodes but not gigantic". The slides you've linked to say the mathematical theory was developed since the 1970s for undirected graphs. Extensions exist for directed graphs and undirected graphs (see slide 20/20 in the tutorial you've linked to). For some background, maybe read chapter 11, specifically 11.2 and 11.5 of M.E.J. Newman's Book "Networks". The 11.2 Chapter Title is called "Dividing networks into clusters". Chapter 11.5 is "Spectral [graph] partitioning" - the method from which spectral clustering evolved according to slide 20 in http://ranger.uta.edu/~chqding/Spectral/spectralA.pdf you've linked to. The thick (800 page) book "Networks" is an interdiciplinary introduction, and it is very verbose, and it starts from basics. However the book discusses many other things besides clustering. It is also not online, maybe get it through inter-library loan. I also like the introduction of Andrew Ng's et al's 2002 short Paper "On spectral clustering: Analysis and an algorithm" see " https://ai.stanford.edu/~ang/papers/nips01-spectral.pdf ... Despite the empirical successes, different authors still disagree which eigenvectors to use and how to derive clusters from them [...] also, the analysis of these algorithms [...] focus on simplified algorithms that only use one eigenvector at a time" But this was 2002, a lot might have changed since then.
