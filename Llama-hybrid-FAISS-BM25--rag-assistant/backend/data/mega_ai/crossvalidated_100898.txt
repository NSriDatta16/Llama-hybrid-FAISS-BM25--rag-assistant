[site]: crossvalidated
[post_id]: 100898
[parent_id]: 100891
[tags]: 
Have a look at gensim or scikit-learn . Code from sklearn.feature_extraction.text import TfidfVectorizer from nltk.corpus import stopwords train_set = ["The sky is blue.", "The sun is bright.", "The sun in the sky is bright."] stop_words = stopwords.words('english') transformer = TfidfVectorizer(stop_words=stop_words) transformer.fit_transform(train_set).todense() After fitting the model, you can transform your out of sample documents. transformer.transform(test_set).todense() However , it sounds like what you really want to do given your comments is evaluate the tf-idf of the original documents in terms of the " test_set " as the vocabulary? It's unclear to me what you're after I guess. If that's the case though then something like transformer = TfidfVectorizer(stop_words=stop_words, vocabulary=test_set) transformer.fit_transform(train_set).todense().T Gives you what you want I think.
