[site]: stackoverflow
[post_id]: 1516691
[parent_id]: 1516659
[tags]: 
There's a CLOCKS_PER_SEC macro to help you convert ticks to milliseconds. There are O/S-specific APIs to get high-resolution timers. You can run your program more than once (e.g. a 1000 times) and measure that using a low-resolution timer (e.g. some number of seconds), and then divide that total by the number of times you ran it to get a (higher-resolution) average time.
