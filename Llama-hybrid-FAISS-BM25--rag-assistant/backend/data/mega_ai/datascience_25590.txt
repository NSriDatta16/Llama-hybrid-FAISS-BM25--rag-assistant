[site]: datascience
[post_id]: 25590
[parent_id]: 
[tags]: 
Variable Importance for NN's with Olden's Method

Background: I've built a neural network for predicting categorical outcomes and wanted to test variable importance with the variable importance method proposed by Olden et al. 2004 . Problem: However, I've noticed that the more 'important' variables, i.e., variables with greater absolute value on the output from Olden's algorithm, tend to have far fewer samples in the training set than the 'less important' variables. For example, a variable $x$ with variable importance value 5000 might only have 5 observations in the training set that have $x$ encoded as true (I've used one-hot encoding to encode observations here) whilst variable $y$ with importance value 72 might have 750 observations in the training set that have $y$ encoded as true. Questions Has anybody come across this issue? How would you resolve this? Is it reasonable to say that variable $x$ has more variable importance than variable $y$ , even though it has a much smaller sample size?
