[site]: datascience
[post_id]: 47835
[parent_id]: 46632
[tags]: 
PCA is only suitable for continuous variables, and sensitive to scaling. So don't use it here. Instead, you meat want to look at classic information measures whether some attribute is "correlated" with the clusters. For example Gini, mutual information etc. Similarly, the Elbow method is a bad idea. It never was a good idea in the first place because of scaling... But it's really only suitable for choosing the k in k-means if you do many random restarts and look at the best partitionings found. But even then: there is no mathematical definition of the "elbow". Most of the time, there is no elbow, and people just pick some random k this way because they don't consider this option...nit's probably widely misused. But it certainly must not be used with hierarchical clustering!
