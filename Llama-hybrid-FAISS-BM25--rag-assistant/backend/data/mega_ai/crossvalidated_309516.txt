[site]: crossvalidated
[post_id]: 309516
[parent_id]: 182775
[tags]: 
In https://stackoverflow.com/questions/45649520/explain-with-example-how-embedding-layers-in-keras-works/ I tried to prepare an example using 2 sentences, keras's texts_to_sequences 'This is a text' --> [0 0 1 2 3 4] and embedding layer. Based on How does Keras 'Embedding' layer work? the embedding layer first initialize the embedding vector at random and then uses network optimizer to update it similarly like it would do to any other network layer in keras. [0 0 1 2 3 4] --> [-0.01494285, -0.007915 , 0.01764857], [-0.01494285, -0.007915 , 0.01764857], [-0.03019481, -0.02910612, 0.03518577], [-0.0046863 , 0.04763055, -0.02629668], [ 0.02297204, 0.02146662, 0.03114786], [ 0.01634104, 0.02296363, -0.02348827] Above would be some initial embeding vector for a sentence of (maximum) 6 words and output_dim of 3.
