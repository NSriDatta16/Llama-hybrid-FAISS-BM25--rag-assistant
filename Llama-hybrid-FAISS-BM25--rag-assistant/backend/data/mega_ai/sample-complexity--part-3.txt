than the best possible risk in a larger space. However, by restricting the complexity of the hypothesis space it becomes possible for an algorithm to produce more uniformly consistent functions. This trade-off leads to the concept of regularization. It is a theorem from VC theory that the following three statements are equivalent for a hypothesis space H {\displaystyle {\mathcal {H}}} : H {\displaystyle {\mathcal {H}}} is PAC-learnable. The VC dimension of H {\displaystyle {\mathcal {H}}} is finite. H {\displaystyle {\mathcal {H}}} is a uniform Glivenko-Cantelli class. This gives a way to prove that certain hypothesis spaces are PAC learnable, and by extension, learnable. An example of a PAC-learnable hypothesis space X = R d , Y = { − 1 , 1 } {\displaystyle X=\mathbb {R} ^{d},Y=\{-1,1\}} , and let H {\displaystyle {\mathcal {H}}} be the space of affine functions on X {\displaystyle X} , that is, functions of the form x ↦ ⟨ w , x ⟩ + b {\displaystyle x\mapsto \langle w,x\rangle +b} for some w ∈ R d , b ∈ R {\displaystyle w\in \mathbb {R} ^{d},b\in \mathbb {R} } . This is the linear classification with offset learning problem. Now, four coplanar points in a square cannot be shattered by any affine function, since no affine function can be positive on two diagonally opposite vertices and negative on the remaining two. Thus, the VC dimension of H {\displaystyle {\mathcal {H}}} is d + 1 {\displaystyle d+1} , so it is finite. It follows by the above characterization of PAC-learnable classes that H {\displaystyle {\mathcal {H}}} is PAC-learnable, and by extension, learnable. Sample-complexity bounds Suppose H {\displaystyle {\mathcal {H}}} is a class of binary functions (functions to { 0 , 1 } {\displaystyle \{0,1\}} ). Then, H {\displaystyle {\mathcal {H}}} is ( ϵ , δ ) {\displaystyle (\epsilon ,\delta )} -PAC-learnable with a sample of size: N = O ( V C ( H ) + ln ⁡ 1 δ ϵ ) {\displaystyle N=O{\bigg (}{\frac {VC({\mathcal {H}})+\ln {1 \over \delta }}{\epsilon }}{\bigg )}} where V C ( H ) {\displaystyle VC({\mathcal {H}})} is the VC dimension of H {\displaystyle {\mathcal {H}}} . Moreover, any ( ϵ , δ ) {\displaystyle (\epsilon ,\delta )} -PAC-learning algorithm for H {\displaystyle {\mathcal {H}}} must have sample-complexity: N = Ω ( V C ( H ) + ln ⁡ 1 δ ϵ ) {\displaystyle N=\Omega {\bigg (}{\frac {VC({\mathcal {H}})+\ln {1 \over \delta }}{\epsilon }}{\bigg )}} Thus, the sample-complexity is a linear function of the VC dimension of the hypothesis space. Suppose H {\displaystyle {\mathcal {H}}} is a class of real-valued functions with range in [ 0 , T ] {\displaystyle [0,T]} . Then, H {\displaystyle {\mathcal {H}}} is ( ϵ , δ ) {\displaystyle (\epsilon ,\delta )} -PAC-learnable with a sample of size: N = O ( T 2 P D ( H ) ln ⁡ T ϵ + ln ⁡ 1 δ ϵ 2 ) {\displaystyle N=O{\bigg (}T^{2}{\frac {PD({\mathcal {H}})\ln {T \over \epsilon }+\ln {1 \over \delta }}{\epsilon ^{2}}}{\bigg )}} where P D ( H ) {\displaystyle PD({\mathcal {H}})} is Pollard's pseudo-dimension of H {\displaystyle {\mathcal {H}}} . Other settings In addition to the supervised learning setting, sample complexity is relevant to semi-supervised learning problems including active learning, where the algorithm can ask for labels to specifically chosen inputs in order to reduce the cost of obtaining many labels. The concept of sample complexity also shows up in reinforcement learning, online learning, and unsupervised algorithms, e.g. for dictionary learning. Efficiency in robotics A high sample complexity means that many calculations are needed for running a Monte Carlo tree search. It is equivalent to a model-free brute force search in the state space. In contrast, a high-efficiency algorithm has a low sample complexity. Possible techniques for reducing the sample complexity are metric learning and model-based reinforcement learning. See also Active learning (machine learning) == References ==