[site]: datascience
[post_id]: 98052
[parent_id]: 
[tags]: 
Why is the f1 score of my imbalanced data for a multiclass problem so low?

I am dealing with a multi-class problem and imbalanced data. I am trying to find an algorithm that can predict well each class with python (sklearn and pandas). My dataset contains: 620 rows, 12 columns and is imbalanced: class 0: 47,3% class 1: 10,5% class 2: 9% class 3: 8,6% I tried to upsample the classes 1,2,3 and trained diferent algorithms but the best f1 weighted score is only 58%. I also tried to downsample the class 0 and trained the same algorithms but the best f1 weighted score is 40%. SMOTE method does not work so well. The algorithms that I trained are: K Nearest Neighbors Logistic Regression (solver='sag') Random Forest Adaboost SVM How can I improve the accuracy of my models? Do I need to change the model or to something else regarding the imbalanced dataset?
