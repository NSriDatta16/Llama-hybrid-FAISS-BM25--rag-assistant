[site]: crossvalidated
[post_id]: 380778
[parent_id]: 
[tags]: 
neural network: How Standard Scaler can affect to node weights learning

I and learning about neural network, and i suspect about how effective of our feature scaling for deep model. In my opinion, Standard Scaler can lead to a bad results of neural network. Let look at an example: I have a classification task for a data set with 2 features: A and B. After using Standard Scaler for both features, most of rows in dataset will become 0 ( Mean of Standard Scaler distribution is 0).So if we look at neural network formula for one node of first hidden layer( which is after input layer): A.W1 + B.W2 + B1 = 0*W1 + 0*W2 + B1 = B1 From above equation, if most of our rows are full of 0 values , we can see that when most of rows of our dataset doesn't change our weight of first hidden layer, and bias ( B1 ) is the unique factor to pass over first hidden layer and will be updated after each iteration. So as my conclusion, we shouldn't use Standard Scaler for input of neural network. Does it correct ? And please correct me if i am wrong about my explanation.
