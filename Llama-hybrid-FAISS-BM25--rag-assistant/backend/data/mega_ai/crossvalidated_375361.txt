[site]: crossvalidated
[post_id]: 375361
[parent_id]: 373449
[tags]: 
There are probably many ways to do this, depending on what you use to measure the "density" of each point in the vector space. However, one obvious way to make this comparison would be to use your original vectors to form a kernel density estimator (KDE) over the vector-space and use this estimated density to measure the average "density" of a new set of values in that vector space. Details: Consider the case where you have an original set of $n$ vectors $\mathbb{x}_1,...,\mathbb{x}_n \in \mathbb{R}^m$ that you are using to determine the density in the vector space. Define the KDE as: $$p(\mathbb{x}|\lambda) \equiv \frac{1}{n \lambda} \sum_{i=1}^n K \Big( \frac{\mathbb{x} - \mathbb{x}_i}{\lambda} \Big) \quad \quad \quad \text{for all } \mathbf{x} \in \mathbb{R}^m.$$ The function $K$ is an appropriate density on $\mathbb{R}^n$ with zero mean, and $\lambda$ is a bandwidth parameter. You should be able to estimate the bandwidth parameter from the observed data (via maximum likelihood estimation or using some other method) to get the estimated density function: $$\hat{p}(\mathbb{x}) = p(\mathbb{x}|\hat{\lambda}).$$ You now have an estimated density on the vector space $\mathbb{R}^m$ . For any new set of values in this vector space, you can measure their mean-log-density as: $$\begin{equation} \begin{aligned} \hat{\bar{\ell}}(\mathbf{y}_1,...,\mathbf{y}_N) &\equiv \frac{1}{N} \sum_{k=1}^N \ln \hat{p}(\mathbf{y}_k) \\[6pt] &= \frac{1}{N} \sum_{k=1}^N \Bigg[ \ln \Bigg( \sum_{i=1}^n K \Big( \frac{\mathbb{y}_k - \mathbb{x}_i}{\hat{\lambda}} \Big) \Bigg) - n \ln n - n \ln \hat{\lambda} \Bigg]. \end{aligned} \end{equation}$$ This measure is essentially giving you an estimate of the mean-log-density of the new values, where the density function is estimated from the original observations. For a given set of new values in the vector space, this ought to give you a reasonable measure of how "dense" a region these values occupy. As pointed out in the comments to this answer, there are some difficult issues that arise when you measure distances between vectors in high dimensional spaces. In particular, in high dimensional spaces, most of the "density" of a distribution is not near its mean. The present method is general enough to allow you to choose a density kernel that you think gives an appropriate measure of distance between vectors. When working in a high-dimensional space you will probably want to choose something that has "fat tails" so that it does not heavily penalise distances in a single dimension. In any case, the method allows a choice here.
