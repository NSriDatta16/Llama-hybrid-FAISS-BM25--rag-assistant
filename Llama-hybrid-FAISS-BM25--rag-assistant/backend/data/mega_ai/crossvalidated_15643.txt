[site]: crossvalidated
[post_id]: 15643
[parent_id]: 577
[tags]: 
AIC and BIC are information criteria for comparing models. Each tries to balance model fit and parsimony and each penalizes differently for number of parameters. AIC is Akaike Information Criterion the formula is $$\text{AIC}= 2k - 2\ln(L)$$ where $k$ is number of parameters and $L$ is maximum likelihood; with this formula, smaller is better. (I recall that some programs output the opposite $2\ln(L) - 2k$, but I don't remember the details) BIC is Bayesian Information Criterion, the formula is $$\text{BIC} = k \ln(n) - 2\ln(L)$$ and it favors more parsimonious models than AIC I haven't heard of KIC.
