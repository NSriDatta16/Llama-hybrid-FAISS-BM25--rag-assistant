[site]: crossvalidated
[post_id]: 224157
[parent_id]: 223931
[tags]: 
If your trained model is (very) good, the stratification should be no problem, because the forest classify the observations correctly in spite of the stratification. What is your hardware? If you have several cpus you can use the R-package ranger, this is probably much faster and yields the same results as randomForest. You can also train random forests iteratively on parts of the datasets and at the end put them together. 1 M is not too much, depending on your number and type of features you can easily train a random forest model with 50000 observations There are also other packages like h2o, ... And you can use AWS Amazon, ... Maybe a simpler model than random forest (e.g. simply rule based) but trained on the whole dataset can also provide better results, than using only a part of the data. edit: What you can do, is also to use the strata and sampsize argument (as a vector) in the randomForest package. There you can specify exactly the number of samples you want to have from each of the classes. And in different trees you can get completely different samples as you sample from all observations.
