[site]: crossvalidated
[post_id]: 144288
[parent_id]: 
[tags]: 
Condensing spatial time series data and spatial interpolation

I have spatio-temporal albedo (roughly, the 'reflectivity' of earth's surface) dataset, from NASA's MODIS satellite, for a 130 square kilometer area. The dataset contains raster files in the NetCDF format, with a file for each day, and a grid size of 500 m*500 m. There are a lot of 'NA' values in each file, due to cloud cover, satellite errors etc. Till now, I have simply spatially averaged the albedo data from the dataset to construct a simple time-series. I use this time-series to create a machine-learning based model to predict snow water equivalent. I want to see if there's a way to include the spatial variability in the dataset, in the time-series. I'm also curious to know what would be the best way to spatially interpolate the data. Is there a way I can condense the variability, which might be due to factors such as elevation, aspect and slope of the area, into one or more time-series? I have looked at Principal Component Analysis/Empirical orthogonal functions to do the above. Can such methods be used for spatial averaging? What would be the best way to spatial interpolate, considering the numerous NA value cells? Is there a way to take into account the elevation, and other factors, into the interpolation? Any suggestions would be greatly appreciated. Thanks! Note: I use R for my analysis.
