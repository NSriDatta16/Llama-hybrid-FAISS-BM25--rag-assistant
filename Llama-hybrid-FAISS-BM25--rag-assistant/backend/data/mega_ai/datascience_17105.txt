[site]: datascience
[post_id]: 17105
[parent_id]: 17080
[tags]: 
As I don't have your data, I can only give you some suggestions. 10 epoches may be too few. In my practice, 100+ epoches will be applied. I think 100 epoches will be a good start for you. Assuming your data is fully-prepared, some suggestions of the CNN: The first and the second convolution layers should have ReLU activations, at least not linear activations. Why do your output layer have 11 neurons? There are only 10 digits, right? sparse_categorical_crossentropy is used for sparse input. Your sv_train_labels seems to be a non-sparse array, thus categorical_crossentropy is better. Your 3x3, 4x4, 5x5 convolution layer seems weird, but I can't give you a reason (maybe someone else?). If I were you, I would use 3x3 layer. If you want to print your output shape of your model, try model.summary() . It's awesome! If I were you, I'll try RMSprop rather than Adam . My model if you wanna try: x = Input((28, 28, 1)) y = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(x) y = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(y) y = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(y) y = MaxPooling2D((2, 2))(y) y = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(y) y = MaxPooling2D((2, 2))(y) y = Flatten()(y) y = Dense(1024, activation='relu')(y) digit1 = Dense(10, activation="softmax")(y) digit2 = Dense(10, activation="softmax")(y) digit3 = Dense(10, activation="softmax")(y) digit4 = Dense(10, activation="softmax")(y) digit5 = Dense(10, activation="softmax")(y) model = Model(input=x, output=[digit1, digit2, digit3, digit4, digit5]) model.compile('RMSprop', 'categorical_crossentropy', ['accuracy'])
