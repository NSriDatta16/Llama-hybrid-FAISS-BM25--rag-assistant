[site]: crossvalidated
[post_id]: 311530
[parent_id]: 
[tags]: 
First-layer Visualizations in a neural network

I am reading the lectures on "Convolutional Neural Networks for Visual Recognition", and in this lecture they deal with first layer visualization. As you can see in the figure below- this figure supposed to visualize the weights of the first layer of a (fully connected) neural network. Could someone explain how exactly we get these visualizations from the weight matrix W? For example, if the input is of dimension m, and the first layer is of dimension n, the weight matrix has m*n parameters. How do we transform them into the squares depicted in the figure, and how do we decide to fix the intensities?
