[site]: datascience
[post_id]: 74004
[parent_id]: 73989
[tags]: 
Your dataset is extremely unbalanced, and most of the models would just ignore these 37 samples. After all, failing 0.7% of any test seems to be an extremely good result! There are several ways to address the imbalanced dataset. I suggest two options: (1) Assign a very high penalty on misclassification of positive samples -- your loss function would be weighted L2, (2) Resampling -- when you draw a random row, assign a higher probability to get the positive sample than negative. See, for example, https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets for implementation. And How to deal with class imbalance in a neural network?
