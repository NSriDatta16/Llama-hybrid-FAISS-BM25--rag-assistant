[site]: crossvalidated
[post_id]: 34012
[parent_id]: 
[tags]: 
Why can't a Self Organizing Map to recognize handwriting train to acceptable error rate when number of samples is greater than output neurons?

I have a simple Self organizing map that I have been working on. It has an output neuron for all 26 letters, and when I provide it with 26 samples (one for each letter) it quickly is trained to an error rate below 1%. It is fairly accurate, but when I want to add more samples, one for each output neuron, the lowest possible error rate shoots up to around 37%. Even when I use a decaying learning rate it does this. Even If I add one more sample so that I have 27 instead of 26 the training gets stuck on around 16% error rate. I don't understand why as soon as I have more samples than the number of output neurons I cannot train it properly. I am using the subjective learning method, yet the same happens when I switch over to the additive method. I am still a beginner with neural networks so maybe I am not understanding something properly. Any help would be greatly appreciated!
