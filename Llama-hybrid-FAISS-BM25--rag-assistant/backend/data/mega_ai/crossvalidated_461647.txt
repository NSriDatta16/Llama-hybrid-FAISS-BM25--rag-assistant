[site]: crossvalidated
[post_id]: 461647
[parent_id]: 61610
[tags]: 
Image recognition If you have a black a white image (e.g. MNIST), a typical way to represent the image is an array, so a 2-tensor. If you have a color image, you have one 2-tensor per primary color. $^{\dagger}$ Therefore, you have a 3-tensor. So when you do a convolutional neural network to predict if a color photo is of a dog or a cat, you are inputting a 3-tensor and outputting the category, so $\mathbb{R}^{m\times n \times k} \rightarrow \{\text{dog}=0\text{ , cat}=1\}$ , where $m$ is the number of rows, $n$ is the number of columns, and $k$ is the number of levels (so $k=3$ if you consider the primary colors). If you have video, perhaps you would consider time as adding another order to the tensor to give you a 4-tensor. $^{\dagger}$ This is a typical way to do it but not the only way.
