[site]: crossvalidated
[post_id]: 226076
[parent_id]: 
[tags]: 
Ljung-Box statistic doesn't match to ACF of ARIMAX

I'm afraid I basically missunderstand something in the Ljung-Box-Pierce test. I estimate an ARMAX model with $y$ as seasonal response variable with periodicity in lag 144, and ARMA(3,1) process for modeling the errors, Fourier series in the xreg argument for modeling seasonality (because of long length and multiple wiggly seasonality) and an exogenous variable $x$. The model works almost great for forecast and a $t$-test proves $x$ as significant influence on $y$ as it should be on preliminary considerations. The model is estimated with R and the package forecast in this way: Freg = forecast::fourier(y, K=45) # optimal K estimated with gcv Exo = cbind(Freg, x) fit You see, the forecast (blue lines with grey confidence interval) isn't perfect, but it is a good match in general with estimating the model with $N = 2000$ observations and forecasting $6000$ (red line original time series). Now model diagnostics: A test for white-noise by Bartlett with $H_{0} = \text{"residuals are white-noise"}$ passed with a $p$-value of 0.939. The graphics for serial correlations look OK in my mind (maybe except the PACF in very high lags), as you can see in the graphic below. Now I want to prove the good impression of a well-predicting model with a Ljung-Box-Pierce test. The test is based on the statistic $$ Q = N(N+2) \sum_{t=1}^{h} \frac{1}{N-t} \cdot \tilde{\rho}_{t}^{2} $$ where $N$ is the number of observations (number of residuals here), $h$ is the test lag, $\tilde{\rho}_{t}^{2}$ the correlation of observations (residuals) in lag $t$. The $Q$ statistic follows a $\chi^2$ distribution with $h - 4$ degrees of freedom. The $4$ in $h-4$ comes from the estimation of the ARMA parameters. Because of the long length seasonality I want to check the $p$-values of the Ljung-Box-Pierce for the lags 5 to 288 as Rob J. Hyndman suggests in his blog post "Thoughts on the Ljung-Box test" . p.values = numeric(2*144) for (i in 1:(2*144)){ p.pvalues[i] = Box.test(fit$residuals, lag=(3+1+i), type="Box-Pierce", fitdf=(3+1))$p.value } $p$-values are greater 0.05 for $h \in (5;80)$ but smaller 0.05 for $h \in(81;288)$. Question: How do the results of the Ljung-Box-Pierce test and the plotted ACF match? I thought most test results should have a $p$-value greater than 0.05 as I saw the ACF. Maybe something is wrong with the degrees of freedom, because of the 91 estimated coefficients in the xreg argument? I'm sorry, but I'm not allowed to publish data. EDIT : As advised by @RichardHardy I perform a Breusch-Godfrey-Test in addition to the Ljung-Box-Pierce-Test and create plots showing the p-values to their corresponding lags. You can see, for small lags the Ljung-Box-Pierce test favors the null hypothesis, because of its biased estimation. But essentially both tests converge against a p-value of null for very high lags, eventhough the calculated serial correlation is not higher as in smaller lags. p.values.bgtest = numeric(2*144) for (i in 1:(2*144)){ p.values.bgtest[i] = bgtest(fit$residuals ~ 1, order=i)$p.value }
