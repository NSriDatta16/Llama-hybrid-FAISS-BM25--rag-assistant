[site]: datascience
[post_id]: 114375
[parent_id]: 
[tags]: 
Captum vs GNNExplainer for explainability in Graph Neural Networks

I'm new to Graph Neural Networks and interested in exploring frameworks that allow the identification of nodes/edges that underlie prediction. I came across : (1) a model architecture (GNNExplainer) as well as (2) a tool (Captum) , which both seems to achieve this goal, but I'm not able to appreciate the differences between the two. Does Captum work with all model architectures, including GNNExplainer? Can anyone point me to some pros/cons of each, or distinguish them apart by applications/capabilities?
