[site]: crossvalidated
[post_id]: 449387
[parent_id]: 
[tags]: 
Random Forest in R [set.seed()/parameters/confusion matrix]

So, I have a few questions concerning random Forests (mainly in R): How ntree affects Random Forests in general? Will we get more precise "OOB error" (more trees -> bigger possibility that OOB sample will be part of a test set for more trees -> hence, precise OOB error?)? How set.seed() helps randomness for RFs? When we do sampling with replacement I'm thinking that by using the same seed (ex. set.seed(1234)) we will draw same rows for each forest? That is, if we used first 10 rows on tree_1, in random forest_1 then we will use the same rows in tree_1 of random_forest_2, or random_forest_3 etc. Why changing the order of features “improves” a bit OOB error rate, and overall class.error? (using the same seed) Speaking of R, how is confusion matrix made for Random Forest? Do we first train the model, and then we put all the data points in pre-trained RF so we can obtain TruePositives etc. by counting them. PS. I'm currently using RFs mainly for EDA!
