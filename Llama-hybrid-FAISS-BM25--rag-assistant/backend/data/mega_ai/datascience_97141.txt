[site]: datascience
[post_id]: 97141
[parent_id]: 
[tags]: 
Addressing class imbalance: coefficient in loss vs threshold on confidence

Let's say I am training a neural network for a binary classification task, with classes A and B, which is trained using gradient descent with a cross-entropy loss function. The dataset is imbalanced, and there are twice as many examples of A as there are of B. Therefore, my training would be biased towards class A, and would "try harder" at predicting A, at the expense of class B. There are two potential solutions to this: (1) Add a coefficient in the loss function, which downweights examples of A during gradient calculations. (2) Instead of using a threshold of 0.5 on the network's output to determine the predicted class, change this threshold so that predictions of class A need to be "even more" confident than predictions of class B. These two solutions seems related to be, but also quite different. What is the relationship between these two? Is the coefficient in (1) effectively the same as the threshold in (2)?
