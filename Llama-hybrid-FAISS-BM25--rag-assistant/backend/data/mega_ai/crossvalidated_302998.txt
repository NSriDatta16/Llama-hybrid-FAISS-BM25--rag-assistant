[site]: crossvalidated
[post_id]: 302998
[parent_id]: 302982
[tags]: 
I hope the author of that text is a contributor to this site, because I am about to argue that they make a fundamental error, and I would like it if they were around to defend themselves. And then what we want to do is build a predictive function so that if we get a new individual, we can predict whether they're going to respond to chemotherapy up here, as an orange person, or not respond down here as a green person. This is subtly wrong, this is not what what we want to do. Our goal in such a study is to develop a decision rule that will advise us on how to act when presented with a case. That is, our decision rule should tell us whether we should apply the therapy to a case. This is related, but not equivalent, to prediction of whether they will respond, as I will elaborate on below. The correct procedure for developing such a rule does involve prediction: Develop a model that predicts the probability that an individual will respond to treatment. Use the model, along with an understanding of the benefits and costs of treatment, to develop a decision rule that advises doctors on procedure. In many problems the benefits and costs change quickly in response to our understanding of the situation, or outside influences like legislation, or new technology. If we follow the above procedure, only the decision rule has to adapt to these changes, the modeled probabilities are invariant. They only express our underlying scientific knowledge about the treatment and its affects. This is a separation of concerns , which engineers have long known is a powerful tool in organizing work. It is important that our model predicts probabilities. This is what allows us to incorporate information about the benefits and costs into our decision rule. We can calculate the expected value and costs of treatment for an individual, and balance them according to our goals. If instead, we insist on the model telling us "responds" or "not responds" we have given up our power to make nuanced decisions based on these benefits and costs, and have ceded our ability to adapt to an ever changing landscape. The author falls into this trap. In the picture of overlapping distributions they argue that prediction is difficult because in the regions of large overlap, the model can not meaningfully make a binary yes or no call on "responds to treatment". This is simply the truth about most situations we encounter in life. This is why it is important to base our reasoning on probabilities. Probabilities actually quantify the degree of uncertainty we have in making a yes or no call. In the overlapping distributions, there is no difficulty at all in assigning probabilities to "responds to treatment". It is only when we ignore this reality, and attempt to say with certainty what will happen that issues arise. The authors difficulty is manufactured out of their own incorrect procedure. Another issue that comes up is that, prediction is slightly more challenging than inference. This is not generally the opinion of most literature or the wise people I have discussed these issues with. I wonder if the the author is using some quirky definition of "prediction" and "inference". To me, inference is using modeling to understand the true mechanisms that underlie a phenomena. We want to be able to say things like "increasing the treatment drug by x ccs will lead to an improvement in outcomes by y amount". To do inference, we first need a model that describes the phenomena well (the gold standard would be our ability to use the model to make predictions). We then use the shape of that model to distill understanding about what is going on. In prediction, we don't much care about the model being introspectable. If it is too complicated for us to understand, so be it, as long as its predictions are accurate. Prediction studies loosen some of the constraints we must meet to use a model for inference. The author seems to have it backwards. A most excellent reference that is quite readable and really helped me clarify my thinking on this subject is Shmueli: To Explain or Predict .
