[site]: crossvalidated
[post_id]: 391601
[parent_id]: 388947
[tags]: 
It is true that having the ability to represent more complicated functions is a necessary condition for learning more complex functions. However the goal of the learning process is to select a good function from the set of all functions the learning machine can represent. If that set is large then the problem of learning is intrinsically harder. This is called the curse of dimensionality in the pattern recognition literature. Not only must statistical regularities exist in the data for discriminating among members of a large set of functions but the learning algorithm needs to be powerful enough to exploit such statistical regularities. If the learning machine can represent any arbitrary function and the learning algorithm for the machine is capable of learning any arbitrary function then the learning machine will simply memorize the training data set resulting in essentially a fancy way to implement a lookup table! To prevent memorization and have good generalization performance prior knowledge should be provided to the learning machine that restricts the class of functions the neural net learning machine can learn. Examples of such restrictions are using a linear regression or logistic regression model rather than a nonlinear regression model, having fewer parameters, adding regularization such as L1 or L2. Finally note that having a lot of parameters does not always mean that the function space is unconstrained. There are many thousands of parameters in deep learning neural networks but such learning machines have a very specific and highly constrained hierarchical and convolutional architecture which greatly restricts the class of functions they can represent.
