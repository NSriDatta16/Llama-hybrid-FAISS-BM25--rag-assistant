[site]: crossvalidated
[post_id]: 405494
[parent_id]: 
[tags]: 
textclassification caret(svm): very low accuracy for testset because few words matching with trainingset

I am doing text analysis of tweets with caret ("classif.svm). I have manually classified 1500 documents (consisting of 1-5 tweets). When I tune the parameters it shows me an accuracy of about 80% and kappa of 55%. However, when I apply it to my testset the accuracy drops substantially to 40%. I am not sure why this is the case. But I am thinking that it could be because in my training set I have about 5000 unique words as predictors and in my testset I only have 2700 unique words and 1800 that are also in my trainset. Is there some way to get around this issue? Should I only train the trainset with words from my testset? But for my "really to be predicted" data it contains all the unique words there that are also found in the trainset. Does it make sense in that case to even use a testset (by splitting the traindata in train and test like normal) or is there another possible solution to this? Any pointers are appreciated!
