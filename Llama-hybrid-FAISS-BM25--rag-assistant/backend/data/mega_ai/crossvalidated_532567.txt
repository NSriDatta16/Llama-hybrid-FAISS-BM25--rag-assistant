[site]: crossvalidated
[post_id]: 532567
[parent_id]: 
[tags]: 
Intuition behind Residual Neural Network

ResNet architecture states that instead of learning $H(x)$ function , it learns $f(x)$ which equals $f(x) = H(x) - x$ , my intuition was that instead of learning the function all at once , we just learn the difference between the previous block and the next block. but then I read that the network will try to get $f(x)$ to zero! and now I'm confused again, what's the point of doing that as this means we aren't learning anything?
