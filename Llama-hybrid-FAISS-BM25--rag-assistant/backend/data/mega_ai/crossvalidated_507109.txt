[site]: crossvalidated
[post_id]: 507109
[parent_id]: 462544
[tags]: 
Ok so my attempt to partially answer my own question, given what Xi'an said, and my further understanding: It doesn't matter that the prior distribution is improper - i.e. that it's not a valid distribution. Bayesian's are willing to live with that as long as the posterior is proper. And still it does have some intuition understanding, i.e. $\propto 1$ translates intuitively to "all values are equally likely", or "I have no information has to what value it may take". As one of my professor put it: lack of information is also information . If it's a "location" parameter, then the pdf is of the form $f_\theta(y)=f(y-\theta)$ , i.e. the pdf only depends on the difference between $y$ and the parameter. If I change the parameter, I will get the exact same shape of the distribution, only shifted. So no information on this location parameters, means that I want the prior to be translation invariant, $\pi(\theta) = \pi(\theta-\theta_0) = Const. \Rightarrow \pi(\theta)\propto1$ . Otherwise it would mean I do know something about the parameter, that in certain location it is more/less probable than other. If it's a "scale" parameter, then the pdf is of the form $f_\theta(y)=f(y/\theta)/\theta$ , i.e. if we change the scale of $y$ say to $z=\alpha y$ , then the new pdf will be $f_\theta(z)=f(z/\alpha\theta)/\alpha\theta$ . The pdf only depends on the parameter on the scale $y/\theta$ times a normalizing constant. If we define $u=\ln y \Rightarrow y=e^u$ . The pdf of the new variable is then $f_U(u)=e^uf_Y(e^u/\theta)/\theta=e^{u-\ln \theta}f_Y(e^{u-\ln \theta})$ . I.e. the pdf of the new variable, turned our scale parameter to a location parameter. Because now the new function only depends on the (ln of the) parameter by it's difference to the variable. So like before $\ln \theta \propto 1$ . So for the prior $\theta$ itself: $f(\theta)=f_{\ln \Theta}(\ln \theta)\frac{1}{\theta}\propto 1\cdot\frac{1}{\theta}$
