[site]: datascience
[post_id]: 53936
[parent_id]: 
[tags]: 
Pattern Recognition (Bishop) - Maximum Likelihood

This refers to Chapter 2, section 2.2 (page 75) - Pattern Recognition and Machine Learning, Christopher Bishop. The question is related to calculation of Maximum Likelihood variable: Maximum likelihood is given as: $$p(D|\mu) = \prod_{n=1}^{N}\prod_{k=1}^{K}\mu_{k}^{x_{nk}} = \prod_{k=1}^{K}\mu_{k}^{m_{k}} \tag{2.29}$$ where $m_{k} = \sum_{n}x_{nk}$ $\implies$ #occurrences of event $k$ , $x_k$ , over $n$ trials where, k={1, $\ldots$ ,K} and, n={1, $\ldots$ ,N}. Also, $\mu_{k}$ being probability, and $D$ , the observed data. Author applies Lagrangian multiplier $\lambda$ and take log-likehood of above equation to get: $$\sum_{k=1}^{K}m_{k}ln{\mu_{k}} + \lambda(\sum_{k=1}^{K}\mu_{k} - 1) \tag{2.31}$$ given the (probability) constraint): $$\sum_{k=1}^{K}\mu_{k} = 1$$ Maximization of eqn. 2.31, w.r.t $\mu_{k}$ and equating it to 0, yields: $$ \mu_{k} = -m_{k}/\lambda \tag{2.32}$$ Author substitutes the constraint in eq 2.32 and finally gets: $$ \mu_k^{ML} = \frac{m_k}{N} \tag{2.33} $$ I am losing it in the last step - my (partial/ wrong) derivation of 2.31 w.r.t. $\mu_{k}$ yields : $$ \sum_{k=1}^{K}\frac{m_{k}}{\mu_{k}} + \lambda\cdot K = 0$$ I am not able to understand: Where am I going wrong How to move ahead to get the result (only, if my derivation is correct)
