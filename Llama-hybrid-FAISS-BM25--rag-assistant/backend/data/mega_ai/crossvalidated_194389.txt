[site]: crossvalidated
[post_id]: 194389
[parent_id]: 
[tags]: 
Estimating accurately the mean of an autocorrelated bounded integer time series

I have a bounded integer time series $X_{1:\infty}$ ($1\leq X_k\leq M$), and I want to estimate the mean $$ s = \lim_{L\to\infty} \frac{1}{L}\sum_{k=1}^L X_k. $$ I'm assuming it exists and that $X_k$ converges in distribution to some distribution with mean $\mu$ and variance $\sigma^2$, and $s$ converges to $\mu$. I am estimating it for $X_{1:L}$ as $s_X = L^{-1}\sum X_{1:L}$, and the accuracy of $s_X$ I can estimate using $$ \mathbb{V}[s_X] = \frac{\sigma^2}{L} + \frac{2}{\sigma^2L} \sum_{\tau\geq1} \mathrm{Acf}(\tau)(1-\tau/L), $$ by replacing $\sigma$ and the autocorrelation function $\mathrm{Acf}(\tau)$ with the sample standard deviation and the sample a.c.f.. The asymptotic distribution of $X_k$ seems to be quite unusual, with 75% of values being $\leq 4$, and approximately power-law-like distributed up to the maximum $M\sim10^4$. The mean and s.d. are about 12 and 150. The autocorrelation function seems to decay roughly exponentially as $\mathrm{Acf}(\tau)\sim 2^{-\tau}$ until trailing off at $\mathrm{Acf}(\tau)\approx 10^{-3}$. So with these unusual properties of $X_k$, how well can I expect $s_X$ to estimate the limit, and how can I check how good it is? More importantly, are there some better estimators that I can try ?
