[site]: crossvalidated
[post_id]: 561453
[parent_id]: 
[tags]: 
LSTM RNN always predict the same class

I have following code model_rnn = Sequential() model_rnn.add(SimpleRNN(128, input_shape=(t,X_train_rnn.shape[2],))) model_rnn.add(Dropout(0.3)) model_rnn.add(LSTM(128)) model_rnn.add(Dropout(0.3)) model_rnn.add(Dense(3, activation="softmax")) opt= tf.keras.optimizers.Adam(learning_rate=1e-5) model_rnn.compile(loss = 'sparse_categorical_crossentropy', optimizer = opt, metrics = ["accuracy"]) history_rnn = model_rnn.fit(X_train_rnn,y_train_rnn, epochs=50, batch_size = 16, validation_data= (X_test_rnn, y_test_rnn)) I wanted to classify some financial data from 10 years into 3 classes, but I always get the same class with RNN. I tried different number of epochs, batch_size, learning rate, simpler and complexer model, but nothing worked. I have in the training data about 2000 observations and about 800 in the test data. My classes are balanced. Does anyone have any idea what I could change?
