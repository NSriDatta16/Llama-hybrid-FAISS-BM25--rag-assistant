[site]: crossvalidated
[post_id]: 541722
[parent_id]: 
[tags]: 
Can we use Sigmoid directly in front of Mean Square Error in the linear regression model or MLP?

I know that a sigmoid function in front of the MSE in the logistic regression lets gradient be 0, if the prediction is 1 (no matter what the ground truth is). According to this math, this problem will happen in the linear regression model or multilayer perceptron model as well, right? For example, a linear regression model or MLP (with sigmoid function directly in front of MSE) may output 1, but the ground truth may be 0.5. In this situation, the gradient will be 0 so that the weights of the model will not be updated even though the prediction is wrong. I know that there are other reasons that we would not use sigmoid at the output layer for linear regression. Again, does this mean that we should not put sigmoid function directly in front of the MSE (no matter what kind of model we are using)?
