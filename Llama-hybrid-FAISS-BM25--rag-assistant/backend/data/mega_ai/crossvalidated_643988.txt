[site]: crossvalidated
[post_id]: 643988
[parent_id]: 
[tags]: 
Reproducing figure 15.10 in Elements of statistical Learning

I am really struggling to recreate both figures. I am coding in R. For example for the squared bias my idea is the following: What we are interested in in theory is $ E_X[Bias(f^{(T,X)})] = E_X[f(X) - E_T(f^{(T,X)})] \quad (1) $ Where $f^{(.,.)}$ is our random forest. Now at a fixed $x$ : $ Bias(f^{(T,x)})=f(x)-E_T(f^{(x,T)}) $ Where: $f^{(.,T)}$ is the predictor we built using training data ( T ), $f(x)$ is the formula they gave in the book, $( (\frac{1}{\sqrt{50}})\sum(X_j) , ( X_i \sim N(0,1) $ ). Now since we have 500 training data sets, we can approximate $( E_T(f^{(x,T)}) $ ) at a fixed $x$ , by using the Monte Carlo estimate. (In other words we build 500 predictors with 500 different training sets, compute the prediction for this particular $x$ and average). Name this estimate $P(x)$ . $ Bias_{estimate}(f^{(T,x)})=f(x)-P(x) $ Now we use the testing data (we have 600 such testing data) to approximate the Expected value in (1). So we "output" for our squared bias: $ \frac{1}{600}\sum_{j=1}^{600}[f(x_j)-P(x_j)]^2 $ where the $x_{j}$ are the testing points. I just want to know if my idea is correct and/or if anyone has ever reproduced this figure and could provide some help. Much appreciated!
