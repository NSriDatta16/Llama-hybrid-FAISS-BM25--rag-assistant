[site]: datascience
[post_id]: 1231
[parent_id]: 1229
[tags]: 
Rating bias and scale can easily be accounted for by standardization. The point of using Euclidean similarity metrics in vector space co-embeddings is that it reduces the recommendation problem to one of finding the nearest neighbors, which can be done efficiently both exactly and approximately. What you don't want to do in real-life settings is to have to compare every item/user pair and sort them according to some expensive metric. That just doesn't scale. One trick is to use an approximation to cull the herd to a managable size of tentative recommendations, then to run your expensive ranking on top of that. edit: Microsoft Research is presenting a paper that covers this very topic at RecSys right now: Speeding Up the Xbox Recommender System Using a Euclidean Transformation for Inner-Product Spaces
