[site]: crossvalidated
[post_id]: 560121
[parent_id]: 560119
[tags]: 
You don't choose a model from the folds. K fold cross validation is a means of estimating how using a model like a random forest or a boosted tree would perform on unseen data. You would perform cross validation on all models and select the one with the smallest cross validated loss/error metric. Have you seen https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html If you're doing classification, there may be a trend in the log odds of each class (essentially a trend in the probability of each class). You can try and learn it, there is no way to remove it. You will need to extrapolate that trend when using the model to make predictions. The hope is that the trend continues month to month in between trains of the model.
