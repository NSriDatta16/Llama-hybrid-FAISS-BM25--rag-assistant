[site]: datascience
[post_id]: 26823
[parent_id]: 26821
[tags]: 
The image, and variants of it that are commonly used are for illustrative purposes only. They generally do not represent data that has been extracted from real CNNs. The first "Low-level features" part of the diagram is possibly from a real network (I am not sure in this case, it looks more like a constructed filter, e.g. Sobel, to me). That is because it is feasible and relatively easy to interpret the first layer's filter weights directly as images, and the filters do indeed look like the components that they detect. The "Mid-level features" and "High-level features" in your specific diagram have probably been constructed without using a neural network. They are likely to be an artists impression of what the high level features might be. They may have been sampled from real datasets, then just cropped and arranged into the image. Caveat: I cannot find absolute evidence for the specific image being constructed for illustration only, just I suspect this to be the case. It is possible to extract visualisations of features detected by deeper layers. The two common ways to do this are: Dataset matching. Finding examples in the dataset which trigger a specific neuron to output a high value. This can be isolated to a crop of the original image, because you know the combined sizes of all the filters and pools that occur before layer you are interested in. Optimising the input image. Using gradient ascent, but instead of changing the weights, make a cost function that scores the neuron you want to visualise and keep adjusting the input until You can get more information from resources such as this article on feature visualisation .
