[site]: crossvalidated
[post_id]: 294589
[parent_id]: 294298
[tags]: 
Someone more experienced than me can probably weigh in more usefully, but to me this sounds like a difficult data set to work with. That your data are unpaired, despite a research question that seems based in within-subject differences, could do a lot to mask the actual effect of each treatment. I agree that arbitrarily pairing data is not desirable in this case. Assuming that I understand the data you have correctly, I think that your best bet would be to do unpaired, two-tailed t-tests on the pre- and post-treatment measurements of your variable for each condition. This covers a "did the treatments have any effect?"-style question in a fairly typical way. Comparing between conditions seems a lot iffier to me given what you have described. I'm not clear on how subjects were assigned to different conditions, but when only some subjects have measures for condition c, and without being able to take within-subject variation into account, it's hard to conclude that differences are truly due to the conditions themselves. If comparison across conditions is necessary, I would probably do the t-tests described above and then a na√Øve comparison of the measured pre/post differences for those conditions which met your significance threshold (something like: a1 saw an average difference of 5 measured units from pre to post while c1 saw an average difference of 3 measured units, both significant at alpha=0.05). This may not be the answer you are hoping for, but the quality and nature of data always puts a ceiling on how much that data can tell you. I could easily be making a wrong assumption (or assumptions) about your data and your study design, but with stats it pays to be conservative when in doubt.
