[site]: crossvalidated
[post_id]: 183895
[parent_id]: 
[tags]: 
Why do the authors subtract the median in this measure for adjusted average app rating?

I'm just reading the paper "Is this App Safe? A Large Scale Study on Application Permissions and Risk Signals" by Chia et al. (available here from ntnu.no ). On page 3, they calculate an interesting measure, the adjusted average rating: avgra = (avgr − 3) ∗ log(#rating) avgr is the average rating of an app, and #rating is the total number of ratings for this app. I do understand that they log transform the number of ratings to get rid of the skewness in the data. What I do not understand is why are they subtracting 3 (the median if I interpret their explanation correctly) from the rating? Is it to factor in extreme values with a higher loading? Additionally, a reference I could cite regarding the explanation would of course be even better :)
