[site]: crossvalidated
[post_id]: 577854
[parent_id]: 577846
[tags]: 
There are other theorems in mathematical analysis about converging to decent functions (the Stoneâ€“Weierstrass theorem about polynomials and Carleson's theorem about Fourier series come to mind). However, neural networks decrease the bias more than other regression models by taking to the extreme the idea of nonlinearity and interaction. A neural network with millions of parameters is routine. A generalized linear model with millions of parameters, due to nonlinear basis functions (e.g., polynomials or splines) and their interactions, is not as common. If you put in all of those nonlinear features and their interactions in a generalized linear model, taking it to a similar extreme as a neural network, I would expect similar issues of high variance and low bias. In fact, there is a sense in which a neural network (at least some of them) involves a layer (or multiple layers) of feature extraction and then a generalized linear model on the extracted features. After all, if you draw out the usual "web" of a neural network and cover up everything before the final hidden layer, you wind up with something that looks like a generalized linear model.
