[site]: datascience
[post_id]: 106664
[parent_id]: 
[tags]: 
Comparing the cosine similarities of the same word representations, from two separate models (vector spaces)

I am comparing the cosine similarities of word representations derived from a BERT model and also from a static Word2Vec model. I understand that the vector spaces of the two models are inherently different due to the dimensionality of BERT (768) and Word2Vec (300). Essentially I am trying to find a way to compare the two cosine similarity measurements between the same words but from two different models. I also have a set of user-determined similarity scores between the words, e.g., 'vaccinate' - 'inoculate' = 8.99. I was thinking of using this as a scaling factor for the two similarities so each cosine similarity from the vector space would then be scaled by the same amount. I essentially want to quantitatively compare the cosine similarity scores between two models' representations for the same words. Any help would be appreciated.
