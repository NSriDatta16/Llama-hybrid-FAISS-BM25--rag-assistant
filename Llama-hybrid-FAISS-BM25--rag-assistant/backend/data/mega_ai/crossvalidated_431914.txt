[site]: crossvalidated
[post_id]: 431914
[parent_id]: 431890
[tags]: 
You can check the following paper by Sarah Van Erp et al (2019), who discuss different shrinkage priors (below you can see table from their paper). Those priors vary greatly in their shapes, and so amount of shrinkage they provide. Besides discussing pros and cons of those priors, the authors describe a simulation study, where they compare performance of different priors. The results are mixed, for example, depend on if classical regularization, full Bayesian, or empirical Bayesian approach was used. What is also worth mentioning, is that in many cases the differences between different priors were rather small , with some differences when there was more features then samples. In practice this should not makes that big difference, especially when the sample size is large . Choice would be probably rather subjective, based on how much shrinkage would you expect to be needed. You could also make some simulation study, where you would sample data from the priors † , and check performance of the model on this data, by looking on the difference with ground truth values. In such study you would probably need to compare different amount of "false" features to be zeroed-out by shrinkage. † - i.e. simulate data that is similar to what would you expect to see, assuming that you have reasonable, informative priors to achieve this. Van Erp, S., Oberski, D. L., & Mulder, J. (2019). Shrinkage Priors for Bayesian Penalized Regression. Journal of Mathematical Psychology, 89, 31-50. doi:10.1016/j.jmp.2018.12.004 (preprint and supplement: https://osf.io/bf5up/ )
