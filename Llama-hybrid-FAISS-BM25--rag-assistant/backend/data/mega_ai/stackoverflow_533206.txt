[site]: stackoverflow
[post_id]: 533206
[parent_id]: 532889
[tags]: 
First off, frankly, a polling-type architecture sounds very wrong for real-time request handling. If it is at all possible to forward the requests directly to the application that will be processing them, that would be is infinitely preferable. You're opening yourself up to a whole host of additional problems, and you're limiting even your best-case response times to "a couple seconds", which is abysmal. But. Assuming that you can't do anything about the architecture, queuing the messages for retrieval by the internal app is not the problem. An in-memory queue structure can handle that fine (just limit the size of the queue to a couple thousand and return an error if it fills up). Your real bottleneck is going to be the number of open requests on the Web Service. I just don't see how the specified architecture is going to be able to handle thousands of requests/second if each request has a minimum open time of "a couple seconds". Servers are not designed to keep that many requests open. Those that are capable of processing thousands of requests/second do so by responding to each request in a matter of milliseconds, and then clearing it out. If each request is open for multiple seconds, it's going to plaster your server - requests will queue up and 90% of them will end up timing out, assuming your server itself doesn't crash under the weight.
