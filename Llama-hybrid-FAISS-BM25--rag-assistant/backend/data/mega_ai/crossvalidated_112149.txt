[site]: crossvalidated
[post_id]: 112149
[parent_id]: 112148
[tags]: 
This is the first time I actually answer a question, so do not pin me down on it .. but I do think I can answer your question: If you are indeed only interested in model performance and not in thing like interpretability, random forest is indeed often a very good learning algorithm, but does perform slightly worse in the following cases: 1.) When the dimensionality (number of features) is very high with respect to the number of training samples, in those cases a regularized linear regression or SVM would be better. 2.) In the case there are higher order representations/convolutional structures in the data, like e.g. in computer vision problems. In those computer vision cases a convolutional neural network will outperform a random forest (In general if there is knowledge one can incorporate into the learning that is a better thing). That being said random forest are a very good starting point. One of the person I admire for his Machine Learning skills always starts with learning a random forest and a regularized linear regressor. However, if you want the best possible performance I believe nowadays neural networks aka. Deep Learning is looking like a very attractive approach. More and more winners on data-challenge websites like Kaggle use Deep Learning models for the competition. Another pro of neural networks is that they can handle very large numbers of samples (>10^6 one can train them using stochastic gradient descend, feeding bits of data at a time). Personally I find this a very attractive pro for Deep Learning.
