[site]: crossvalidated
[post_id]: 27577
[parent_id]: 22387
[tags]: 
My answer agrees with the first responder. The central limit theorem tells you that if your statistic is a sum or average it will be approximately normal under certain technical conditions regardless of the distribution of the individual samples. But you are right that sometimes people carry this too far just because it seems convenuent. If your statistic is a ratio and the denominator can be zero or close to it the ratio will be too heavytailed for the normal. Gosset found that even when you sample from a normal distribution a normalized average where the sample standard deviation is used for the normalization constant the distribution is the t distribution with n-1 degrees of freedom when n is the sample size. In his field experiments at the Guiness Brewery he has sample sizes that could be in the range of 5-10. In those cases the t distribution is similar to the standard normal distribution in that it is symmetric about 0 but it has much heavier tails. Note that the t distribution does converge to the standard normal as n gets large. In many cases the distribution you have might be bimodal as it is a mixture of two populations. Some times these distributions can be fit as a mixture of normal distributions. But they certain do not look like a normal distribution. If you look at a basic statistics textbook you will find many parametric continuous and discrete distributions that often come up in inference problems. For discrete data we have the binomial, Poisson, geometric, hypergeometric and negative binomial to name a few. Continous examples include the chi square, lognormal, Cauchy, negative exponential, Weibull and Gumbel.
