[site]: crossvalidated
[post_id]: 161112
[parent_id]: 161096
[tags]: 
I will be answering in terms of a usual CNN that is applied to an image. $x$ is the input i.e. the pixels. A convolutional layer in a CNN works by passing over a filter over the data. Here each filter is denoted by $k$. Therefore $W^k$ is the learnable weights for a single filter and $W$ is the weights for all filters. Each filter also has a bias, $b^k$. The convolution operation for a single filter returns a new 2D matrix $x * W^k$. This is simply an elementwise multiplication of the filter weights with the input. As the filter dimensions is usually smaller than the input dimensions, the filter is passed over different subsections of the data, thus yielding a new 2D matrix (see deeplearning.stanford.edu for an example). When applying multiple filters (as is always the case), a new 3D matrix is created as the filter outputs are stacked on top of each other. $k$ denotes the different convolutional filters.
