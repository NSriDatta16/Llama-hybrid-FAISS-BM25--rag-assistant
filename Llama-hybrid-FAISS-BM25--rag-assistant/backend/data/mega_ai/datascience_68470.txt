[site]: datascience
[post_id]: 68470
[parent_id]: 
[tags]: 
Is it possible to create a neural network with two inputs, with sequential layers?

Is there a natural way, in terms of structure of the layers of a NN, in order to pass 2 inputs vectors to the NN? Example: text authorship identification Input #1 : sentence1 by unknown author encoded, as list of words from a dictionary "The sky is blue" => x1 = [2, 23, 7, 76, 0, 0, 0, ..., 0] (zero-padded to have a length of 1000 items) Input #2 : sentence2 by unknown author, idem "The cat is sleeping" => x2 = [2, 65, 7, 121, 0, 0, 0, ..., 0] Output : y = a single number in [0, 1]. 0 = different authors 1 = same author 0.9 = high probability of same author, etc. Of course I could build the layers like this: Input-size: None, 1000, 2 (x1, x2 stacked into a 1000x2 matrix) CNN ... ... Dense: None, 1 Then I could train with a dataset with 10,000 pairs of sentences of the same author (desired output: 1), and 10,000 pairs of sentences with different authors (desired output: 0). But I don't know if it would work by just stacking x1 and x2 as a 1000x2 matrix. TL;DR: What is the classical approach to build a NN taking 2 inputs and a single number as output which is a similarity index from 0% to 100%? (if possible with Sequential structure)
