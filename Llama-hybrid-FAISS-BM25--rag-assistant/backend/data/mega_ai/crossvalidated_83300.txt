[site]: crossvalidated
[post_id]: 83300
[parent_id]: 83296
[tags]: 
(My answer looks like I am assuming univariate distributions, but the underlying ideas carry over to the case with more variates.) If you had population distributions ($F$, $G$) rather than samples and a point $x_{new}$, you could compare the height of the density (or probability function in the case of discrete random variables) to find the distribution with the greater likelihood of producing the observation. i.e. compare $f(x_{new})$ with $g(x_{new})$. However, you only have samples. With large samples, you could make some assumptions (such as "the original population densities are smooth") and use (say) kernel density estimates* ($\hat f$ and $\hat g$), and then compare heights of those at $x_{new}$ - though of course the estimated probabilities are dependent on things like your choice of bandwidth and kernel, and are subject to random variation (a new sample would result in different relative density estimates at each $x$, though in large random samples they should be looking something like the population densities). * or logspline density estimates, or whatever There are some other things you might do but it will pretty much boil down to 'what are you prepared to assume?' (Or did you want to take a Bayesian approach?)
