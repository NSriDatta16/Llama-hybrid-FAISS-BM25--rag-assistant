[site]: crossvalidated
[post_id]: 379318
[parent_id]: 
[tags]: 
Is this a sign of (bad) local minima encountered by this RNN?

On a binary classification task, I can get perfect performance on the training set, but no matter how strongly I regularize the recurrent neural network (dropout 0.99, L2 weight penalties of 0.01) the generalization performance on a validation set is poor. What strikes me as unusual, is that the accuracy on the validation set always seem to get stuck at the same value of 76%. No matter which architecture or regularization alternative, this is a threshold that my model does not seem to be able to overcome. Can this be a general local minima that is being reached, although the training set performance is pretty much perfect? (loss ~0, accuracy 99%) Below one example of several similar looking ones on training/validation loss and accuracy: Note that a plateau is reached around 0.7, after which the training set performance (blue) jumps while the validation set (red) gets worse again (overfitting). On the network: For the image, a single layer RNN is used, with 100 LSTM units. Targets are binary labels {0,1}, class balanced. Loss function is the softmax_cross_entropy_with_logits, using Adam as optimization algorithm. Network: model = Sequential() model.add(Bidirectional(LSTM(800, return_sequences=False), input_shape=(window_size, num_input))) model.add(Dropout(0.6)) model.add(Dense(2)) model.add(Activation('softmax')) adam = Adam(lr=5e-6, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) model.compile(loss='categorical_crossentropy', optimizer=adam,metrics=['accuracy']) Training with Bidirectional LSTM in Keras. Hidden_Units = 200, Dropout = 0.95
