[site]: datascience
[post_id]: 124993
[parent_id]: 
[tags]: 
Predict best chess move using RNNs

I am trying to do a project with AI: in which during any certain moment of a chess game i can predict, using a RNN trained on a kaggle dataset, the best possible move that i can make. I am having issues with the creation of the model. I have cleaned and preprocessed my dataframe and i got left with this dataset: 0 turns 19629 non-null int64 1 opening_ply 19629 non-null int64 2 winner_black 19629 non-null int64 3 winner_draw 19629 non-null int64 4 winner_white 19629 non-null int64 5 victory_status_draw 19629 non-null int64 6 victory_status_mate 19629 non-null int64 7 victory_status_outoftime 19629 non-null int64 8 victory_status_resign 19629 non-null int64 9 tokenized_moves 19629 non-null object 10 opening_eco_A00 19629 non-null int64 11 opening_eco_A40 19629 non-null int64 12 opening_eco_B00 19629 non-null int64 13 opening_eco_B01 19629 non-null int64 14 opening_eco_B20 19629 non-null int64 15 opening_eco_C00 19629 non-null int64 16 opening_eco_C20 19629 non-null int64 17 opening_eco_C41 19629 non-null int64 18 opening_eco_C50 19629 non-null int64 19 opening_eco_D00 19629 non-null int64 20 opening_eco_Other 19629 non-null int64 I have tokenized and padded my tokenized_moves column and split the data: tokenizer = Tokenizer() tokenizer.fit_on_texts(data['tokenized_moves']) total_words = len(tokenizer.word_index) + 1 sequences = tokenizer.texts_to_sequences(data['tokenized_moves']) padded_sequences = pad_sequences(sequences) X = padded_sequences[:, :-1] y = padded_sequences[:, 1:] y = tf.keras.utils.to_categorical(y, num_classes=total_words) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) I am having issues creating the RNN, when fitting the model it crashes on local and on colab(because i am running out of RAM apparently). I need to be sure i did well and i am just running out of resources, or i did not prepare the model or preprocess the data well. model = Sequential() model.add(Embedding(input_dim=total_words, output_dim=100, input_length=X.shape[1])) model.add(LSTM(100, return_sequences=True)) model.add(Dense(total_words, activation='softmax')) My model summary looks like this: Model: "sequential" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 221, 100) 396200 lstm (LSTM) (None, 221, 100) 80400 dense (Dense) (None, 221, 3962) 400162 ================================================================= Total params: 876762 (3.34 MB) Trainable params: 876762 (3.34 MB) Non-trainable params: 0 (0.00 Byte) I am not sure where am i failing?
