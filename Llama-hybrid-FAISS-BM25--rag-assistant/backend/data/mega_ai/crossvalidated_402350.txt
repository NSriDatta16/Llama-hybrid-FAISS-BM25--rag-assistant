[site]: crossvalidated
[post_id]: 402350
[parent_id]: 
[tags]: 
How to convince people that developed predictive model based on Gradient Boosting Machine (GBM) has enough accuracy?

First of all, I'm not a data scientist. I'm an engineer that wants to use machine learning to do a binary classification based on a data that is extracted from computational modeling. I have four independent variables ( $\textbf{X}$ ) and I have two sets of classes as A and B, which I'm interested to build a predictive model to classify this data by using Gradient Boosting Machine (GBM) and examine its accuracy. I do nested cross validation in order to optimize the trees depth in GBM and then train my model on my training dataset, which gives me 0.99 AUC (Area under the curve of ROC curve). Finally, I have a test dataset that comes from an independent group of researchers, which I didn't use it for training, and I test my predictive model on this test dataset and again measures the test dataset accuracy by calculating area under the curve of test dataset, which gives 0.90 AUC for test dataset. I compared my developed model with literature and it turns out that other researchers that tries to solve similar problem as me on a similar datasets never achieved this level of accuracy for their test dataset. But, I have a really hard time to convince my colleagues and PhD adviser in our department (it's not a data science, mathematics, or statistics department and nobody really has any idea about machine learning as general) that my model has enough accuracy due to my test dataset as well as several comparison with the literature. My question: I wanted to know how can I really convince some people that do not have any experience in data science that my model really works and has enough accuracy? Is this testing against test dataset and comparison to existing literature is enough? Any idea or suggestion is appreciated.
