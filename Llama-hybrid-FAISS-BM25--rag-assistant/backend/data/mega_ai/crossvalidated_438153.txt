[site]: crossvalidated
[post_id]: 438153
[parent_id]: 438137
[tags]: 
In my opinion, your first port of call should be standard binary choice models. The 'silver bullet' in credit risk modelling is logistic regression . However, you can branch out and try generalised linear models with probit and complementary log-log link functions too. The benefits of these 'standard statistical methods' are: 1) Your model is easy to interpret. Model explainability is important in credit risk modelling. 2) You don't need vast amounts of data, as is the case with machine learning models. 3) Over sampling isn't required for standard statistical methods. In fact, over sampling will bias your model. My recommendation is to avoid machine learning methods. Another challenge is variable selection. Unfortunately, step-wise selection procedures are common place in credit risk modelling. These should be avoided all together - see Frank Harrel's objections here . A nice alternative is Bayesian variable selection , or even penalised regressions . Bayesian methods are nice since they let you elicit and incorporate expert knowledge about which variables are, and are not useful.
