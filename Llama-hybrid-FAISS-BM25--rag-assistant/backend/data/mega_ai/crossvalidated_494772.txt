[site]: crossvalidated
[post_id]: 494772
[parent_id]: 494762
[tags]: 
These models -- random forest, xgboost, etc -- are extremely sensitive to the hyper-parameter configurations, so there's no reason to believe that these hyper-parameters will yield good models. For xgboost , the number of trees and the learning rate are two examples of hyper-parameters which require tuning. Both have a strong effect on the model. Also, your score measurements are only applied to the in-sample data (the data used to train the model). Because all models can either exhibit overfitting or under-fitting to the training data, its important to measure performance against a hold-out. If I recall correctly, the score method for all of these models implements accuracy, which is not the best choice of measurement for a classification model. See: Why is accuracy not the best measure for assessing classification models? Also, it's not clear what you wish to achieve by limiting consideration to only 2 features. The procedure used here is not a great way to test inclusion or exclusion of features; for more information about feature selection, see feature-selection .
