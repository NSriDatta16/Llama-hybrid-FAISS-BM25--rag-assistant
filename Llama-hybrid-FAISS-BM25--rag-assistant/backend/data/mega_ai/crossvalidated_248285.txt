[site]: crossvalidated
[post_id]: 248285
[parent_id]: 174762
[tags]: 
In addition to selecting suboptimal actions as steffen mentioned, you can act on the following parameters when training TD-Gammon: number of games TD-Gammon was trained on number of units used in the hidden layer whether to use a 1-ply search, 2-ply search, 3-ply search, etc. which human-engineered feature to use From http://videolectures.net/rldm2015_silver_reinforcement_learning/?q=reinforcement%20learning (David Silver): The neural network that was used (image taken from http://webdocs.cs.ualberta.ca/~sutton/book/ebook/node108.html ):
