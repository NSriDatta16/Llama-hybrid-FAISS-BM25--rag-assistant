[site]: crossvalidated
[post_id]: 497726
[parent_id]: 
[tags]: 
Should prior distribution reflect stationarity assumptions?

In the paper Dynamic Hierarchical Factor Models they present a four-level dynamic factor model and estimate it using a Gibbs sampler. One interesting feature of the model is that the error terms are assumed to be stationary normally distributed autoregressive processes for levels 1, 2, and 3. The authors assign standard normal priors to the autoregressive coefficients, which seems very odd to me. Let's say the level 1 equation has an error term that is a AR(1) process, i.e. $$x_t = \Lambda f_t + e_t, \quad e_t = \phi e_{t-1} + \epsilon_t, \quad \epsilon_t \overset{\text{iid}}{\sim} \mathcal{N} (0, \sigma^2).$$ Question: From what I understand, in order to have a stationary AR(1) process, we'd assume that $|\phi| . Should the prior distribution assigned to $\phi$ reflect this assumption? In other words, should the prior distribution assigned to $\phi$ have support $(-1, 1)$ ? If doing what the authors suggest is okay to do, what justification is there for it being okay to do? UPDATE April 4, 2021: In Bayesian Analysis of AR (1) model the authors state the following: The truncated normal distribution is considered as a prior, to impose stationarity They assigned a truncated normal distribution to the autoregressive coefficient. Now we have an example where the prior distribution reflects the stationarity assumption.
