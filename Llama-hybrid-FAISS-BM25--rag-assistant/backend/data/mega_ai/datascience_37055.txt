[site]: datascience
[post_id]: 37055
[parent_id]: 
[tags]: 
Representing a community as a vector

My setup is this: Suppose I have transactional data over a large period of time. The parties of each transaction are labled, and I use Louvain algorithm for detecting communities (and sub-communities) in each arbitrary timestep (a day, 24 hour period). I also used the labels of the parties and tf-idf to give some literal, summarized description for each community, in each timestep. This has allowed me to manually focus on sereval communities that I find interesting for my specific research, which regulary appear in each timestep (they are somewhat consistent in terms of the nodes that make them up - mostly the same nodes each day). It might also be the case that such a community won't appear at all in some timestep (usaully, it wasn't "consolidated" enough that day, so the Louvain was only able to detect isolated components of it). Based on previous knowledge, I can also label each timestep with some label which is relevant for my research. For example, the labels might be: "Wedding", "Funeral", "Birthday", "Ordinary day". This is crucial: By distinguishing communities that were detected during an ordinary day from those that were detected during a special day, my goal is to recognize what distinguishes them - and eventually use it for a predictive model. Finally, In each timestep, I also computed centrality measures for each node in each community, such as degree but also betweenness and closeness. Given this setup, I realized I'm dealing with kind of a new dataset: The community instances (i.e a specific community in a specific timestep). This has led me to think that representing each community instance as a feature vector will allow me to cluster them together, in an attempt to achieve my goal. There are some direct propeties which can be included in such a vector, such as: number of nodes, number of edges, number of sub-communities, average degree, etc. A less naive vector representation could be as an ordered list of number of nodes in each sub-community (of the parent community instance), and zero's elsewhere. (the vector length is the maximal number of sub-communities found). A more sophisticated method would be to caclulate the variance (and mean) of the centrality measures of the nodes in each community instance, and use that as features. In general, I would like to know if there were any successful study cases based on a similar approach (embedding communities instances as feature vectors), and if so, what features were used? Alternatively, are there any flaws in this kind of approach? or more specifically, in the features I suggested? Any help would be appreciated.
