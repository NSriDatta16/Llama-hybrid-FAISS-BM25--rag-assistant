[site]: datascience
[post_id]: 117716
[parent_id]: 
[tags]: 
How to summarize a long text using GPT-3

What is the best way to summarize a long text that exceeds 4096 token limit (like a podcast transcript for example)? As I understand I need to split the text into chunks to summarize, and then concatenate the results and summarize those. Is there already a popular open-source script to do that? Do I understand correctly that GPT-3 is the best model to do that? I've seen some articles about extractive summarization using BERT but the results were pretty low quality.
