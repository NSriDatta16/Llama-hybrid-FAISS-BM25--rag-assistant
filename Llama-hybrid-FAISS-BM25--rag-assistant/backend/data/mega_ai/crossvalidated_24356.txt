[site]: crossvalidated
[post_id]: 24356
[parent_id]: 24345
[tags]: 
Expanding a bit on @MichaelLew 's answer (which is a good answer): Whether you have to correct for multiple comparisons, and whether family wise error is the best way to do this, have nothing to do with whether a test is parametric or semi-parametric or non-parametric. It has to do with philosophy. Andrew Gelman and his colleagues wrote an excellent paper entitled "Why we (usually) don't have to worry about multiple comparisons". They mostly take a Bayesian approach to this problem (not surprisingly, as Dr. Gelman is one of the leading Bayesians) but I think it is true even in the classical or frequentist framework. In addition to one point made early in Gelman's paper (the null hypothesis is rarely, if ever, strictly true), there are points raised by Jacob Cohen in his book on multiple regression (at least, in an earlier edition, I do not know if this is in the later editions), that it's a good question over what period or set of tests we should adjust - that is what is a "family" in the family wise error? He also says it is a subject on which reasonable people can differ. Finally, although it may be obvious, anything that makes type I error smaller makes type II error larger. Sometimes type I errors are more serious than type II. But not always. Using a fixed p = .05 and power = .80 enshrines the idea that type II errors are 4 times worse than type I errors.
