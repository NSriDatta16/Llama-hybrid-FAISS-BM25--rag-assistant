[site]: crossvalidated
[post_id]: 28364
[parent_id]: 27833
[tags]: 
This problem surfaces in virtually all classification approaches, whether logistic regression, support vector classification, or Naive Bayes classification. There are two intertwined issues: A model trained on an imbalanced dataset may overfit in the sense of acquiring a bias in favour of the majority class. When evaluating this model on a test dataset with the same degree of imbalance, classification accuracy can be a hugely misleading performance measure. The literature on these issues has come up with three solution strategies: You can restore balance on the training set by undersampling the large class or by oversampling the small class, to prevent bias from arising in the first place (see the response by @grotos). Alternatively, you can modify the costs of misclassification to prevent the model from acquiring a bias in the first place. An additional safeguard is to replace the accuracy by the so-called balanced accuracy . It is defined as the arithmetic mean of the class-specific accuracies, $\phi := \frac{1}{2}\left(\pi^+ + \pi^-\right),$ where $\pi^+$ and $\pi^-$ represent the accuracy obtained on positive and negative examples, respectively. If the classifier performs equally well on either class, this term reduces to the conventional accuracy (i.e., the number of correct predictions divided by the total number of predictions). In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to chance (see sketch below which I have taken from my response to a related question ). As detailed in my previous response, I would recommend to consider at least two of the above approaches in conjunction. For example, you could oversample your minority class to prevent your classifier from acquiring a bias in favour the majority class. Following this, when evaluating the performance of your classifier, you could replace the accuracy by the balanced accuracy.
