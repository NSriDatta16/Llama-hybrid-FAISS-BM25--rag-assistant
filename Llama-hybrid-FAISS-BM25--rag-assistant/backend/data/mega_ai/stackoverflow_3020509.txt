[site]: stackoverflow
[post_id]: 3020509
[parent_id]: 3020444
[tags]: 
I wouldn't be concerned about 100 functions. That's very few functions. Global functions and methods are compiled, stored in memory, and indexed in a hash table (save for cached lookups implemented recently). You won't have performance deterioration when calling the functions as the number of functions grows, since accessing the hash table is done, on average, in constant time. However, there will be more overhead parsing the scripts and, if you actually call all those functions, compiling them. This is not really a problem if the you use an opcode cache. There will also be more memory overhead, but typically, memory is not a problem in enterprise grade web servers, where it's more appropriate to try to serve the requests as fast as possible, without caring that much about the memory. There are also stylistic issues. If you have too many global functions, consider whether: You are duplicating code between those functions. Consider refactoring, moving the common code to other function and generalizing the behavior of the functions by adding parameters, where appropriate. You would be better grouping functions that operate on the same data in an class. In the end, worry about this only if you profile your application and find function calls to be a CPU bottleneck and function definitions to be a memory bottleneck.
