[site]: crossvalidated
[post_id]: 549878
[parent_id]: 548058
[tags]: 
Many statistical methods rely on taking the normalized sample mean of the data and comparing it to a critical value under the null hypothesis. For example you might have $H_0:\mu=a$ , and your test statistic is $T=\frac{\bar{X}-a}{\hat{\sigma}/\sqrt{n}}$ $\big(\bar{X}$ = sample mean, $\hat{\sigma}$ = square root of the sample variance $\big)$ , which you then compare to some critical value to reject/fail to reject the null hypothesis. When there is dependence in the data $\hat{\sigma}$ is no longer the correct quantity to use to normalize your test statistic. Instead you would want to use the square root of the long-run variance . Failing to account for this would lead your hypothesis test to have incorrect Type I errors, and more/less power depending on how the long-run variance compares to the variance. With real data, it is likely not the end of the world if you do not take the dependence into account (and use the square root of the sample variance instead of the square root of the long-run variance). With that said, because the type of hypothesis test I have described is so central to statistics, when possible it is a good idea to incorporate dependence into the errors of time series data.
