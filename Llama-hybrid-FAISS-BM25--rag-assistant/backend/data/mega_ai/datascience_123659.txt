[site]: datascience
[post_id]: 123659
[parent_id]: 
[tags]: 
How does supervised fine-tuning work in InstructGPT?

See Figure 2 from the InstructGPT paper : I want to know how Step 1 works. Here is one possible algorithm. Pass the prompt through the model, and compute the negative log of the probability of the first token in the desired output. Update the model weights to minimize this loss. Pass the prompt through the model, followed by the first token from the desired output, and compute the negative log of the probability of the second token in the desired output. Update the model weights. Pass the prompt through the model, followed by the first two tokens from the desired output, and compute the negative log of the probability of the third token in the desired output. Update the model weights. Continue until the model has attempted to predict every token in the desired output, updating the weights after each attempt. After reading the SFT section of the Llama 2 paper , I think this is almost correct. However, instead of updating the weights multiple times, we can run the model on the prompt and the desired output together, to get all the aforementioned negative log results at once. Then, we can sum all these results, and do one weight update to minimize this loss. Is that correct?
