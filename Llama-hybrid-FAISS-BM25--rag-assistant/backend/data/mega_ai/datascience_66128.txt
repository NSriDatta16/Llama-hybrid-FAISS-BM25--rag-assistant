[site]: datascience
[post_id]: 66128
[parent_id]: 66120
[tags]: 
I need a way to supress previous answers. The answer to the question depends on the particular network that you are using. What kind of generative model is it? GAN? Autoencoder? Seq2Seq RNN? Having said that, if your network keeps outputting the same result, this is usually referred to as " mode collapse ", which is typical for GANs. If your network is a GAN, it may be worth exploring the Wasserstein Loss that effectively helps you deal with mode collapse. Generally, a standard path to achieve diversity (and non-repetitive results) in the output of a generative network is to augment your training dataset. Augmentation refers to representing the same data in different ways. In the context of animal pictures, imagine it as providing different pictures of zebras or horses, from different angles or under different light conditions etc. Also make sure that your training dataset is balanced , i.e. all classes are represented equally in the training set, otherwise the result will be biased. If you are using a seq2seq network which generates string names of animals, you usually sample those names character by character. There are different sampling strategies in this case, such as greedy sampling (always the most probable character), multinomial sampling (beam search) which can also have temperature scaling. These strategies yield different results and are worth exploring. A very important metric that enhances the diversity of the output of such a network, is the likelihood of a sampled sequence (or its negative log-likelihood). You want to include this likelihood in your loss function to make sure you "push" the network to sample everything in its reach with equal probability . This is explained nicely in this publication and this publication , which use string representations of molecules that are analogous to your animal names task. If you are using an autoencoder as a generative network, you can combine it with an optimization algorithm, such as particle swarm optimizer, to navigate within its latent space and automatically sample diverse solutions. The key here is the cost function of the optimization algorithm , because inside it you need to penalize repetitive answers. Similar performance can be achieved using reinforcement learning and a likewise penalizing scoring function. I'm not sure if this is because the previous animal names are stored in the short term memory or the synapses for the previous animals are supressed somehow If you are using stateless LSTM units, the memory is reset between independent predictions. If you use stateful LSTM units, previous predictions affect next predictions. I realize that my answer covered many different approaches, however it may provide you with different directions to explore.
