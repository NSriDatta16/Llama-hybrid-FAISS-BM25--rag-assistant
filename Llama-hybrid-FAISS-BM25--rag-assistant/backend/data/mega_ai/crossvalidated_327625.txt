[site]: crossvalidated
[post_id]: 327625
[parent_id]: 
[tags]: 
Why maximum likelihood estimation use the product of pdfs rather than cdfs

I'm learning logistic regression and got confused when I saw the equation of the textbook. I knew that for a continuous distribution, to calculate the probability, the pdf $f(x)$ is meaningless. Instead the cumulative density function $F(x)$ shall be used. Thus, since we're maximizing the probability, shouldn't we use the product of cdf s rather than pdf s on the right side of the MLE equation? Thank you! UPDATE, and further questions: This question brings up an interesting point about why we don't often use the fact that $Y=F(X)\sim U(0,1)$ and then try to minimise the KL divergence between $Y$ and $U$ : $$\text{KL}(Y, U) = \int_0^1 f_y(y) \ln f_y(y) \text{d}y$$ Typically we have easy access to the form of $f$ (the original pdf) but $F$ might be less tractable and $f_Y$ is basically something we would need to estimate using empirical CDFs based on the samples $F(X_i), i=...$ . The question is, are the two formulations (the usual MLE and the KL version above) very different in their results?
