[site]: crossvalidated
[post_id]: 620418
[parent_id]: 620217
[tags]: 
There are different steps to deal with the issue of identifiability. The first one is to make sure that your issue is related to practical identifiability, and not structural identifiability. The latter refers to an intrinsic property of a model, for which different combinations of its parameters would yield exactly the same output. For instance, if the relation between the input $x$ and the output $y$ is $y = (A+B)x$ (with free parameters $A$ and $B$ ), then the model is said to be structurally non-identifiable. The former refers to a property of your experimental setting, in which the parameters of an otherwise structurally identifiable model cannot be accurately determined due to observations being scarce and/or noisy, for instance. Structurally non-identifiable models should be avoided. Different methods exist to assess the structural identifiability of a model, e.g.: Massonis, G., & Villaverde, A. F. (2020). Finding and breaking Lie symmetries: implications for structural identifiability and observability in biological modelling. Symmetry, 12(3), 469. For practical identifiability, it then all depends on your set up: 1st possibility: you have one statistical model, but the possibility to acquire more data. You may be only interested in a specific model, which parameters you try to infer from a set of data, but these said data yield unreliable or inaccurate estimate of the parameters (in the sense that different combinations of parameters will yield the same likelihood). The best step is then to acquire more or more informative data, through processes known as Optimal Experiment Design or Bayesian Active Learning. The points of these methods is to obtain data that will be the most informative about the parameters you are trying to infer and are more likely to lead you to their ground-truth values. The following paper sums up different methods and reviews previous applications: https://arxiv.org/pdf/2201.07539.pdf 2nd possibility: you can choose from different possible models to fit your data, but cannot acquire more data. In this situation, performing model selection will guide you to the candidate model having the best explanatory power while minimizing its risk of overfitting and its number of free parameters (and hence guiding you to a unique set of estimated parameters). Model selection can be performed either o Using cross validation, see chapter 1.6 of the following thesis: https://core.ac.uk/reader/535018070 o Using criteria such as the AIC or the BIC, as described in the following paper: Gontier, C., & Pfister, J. P. (2020). Identifiability of a binomial synapse. Frontiers in computational neuroscience, 14, 558477.
