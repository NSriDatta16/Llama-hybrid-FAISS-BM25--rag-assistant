[site]: crossvalidated
[post_id]: 485452
[parent_id]: 484886
[tags]: 
The way the emmeans support currently works is that it extracts the right stuff for the given model, then passes that to mgcv::predict.gam(..., type = "lpmatrix") . That is done in hopes of supporting the possibility that the model involves smoothers. Theoretically, this should work because: > class(model1) [1] "gamlss" "gam" "glm" "lm" This suggests that model1 inherits from mgcv::gam . However, it apparently doesn't inherit from gam . Actually, it doesn't have all the right slots for lm or glm either, but it is easier to doctor-up. I modified the code so it passes off to the glm support instead, and it now works for this example: > emmeans(model1, "x1") x1 emmean SE df asymp.LCL asymp.UCL a -1.09 0.1031 Inf -1.30 -0.892 b -0.58 0.0917 Inf -0.76 -0.400 Results are averaged over the levels of: x2 Results are given on the log (not the response) scale. Confidence level used: 0.95 As it stands now, it will not work if there are smoothers in the model, but it will work more reliably for other models. And it works as well for alternative modes besides the dafault "mu" mode. This model is not a great demo for that because we only have an intercept for components other than mu ; but we can test that at least: > emmeans(model1, "1", what="sigma") 1 emmean SE df asymp.LCL asymp.UCL overall -0.207 0.0524 Inf -0.31 -0.104 Results are given on the log (not the response) scale. Confidence level used: 0.95 > emmeans(model1, "1", what = "sigma", type = "response") 1 response SE df asymp.LCL asymp.UCL overall 0.813 0.0426 Inf 0.734 0.901 Confidence level used: 0.95 Intervals are back-transformed from the log scale I have uploaded the revised package to the emmeans GitHub repository
