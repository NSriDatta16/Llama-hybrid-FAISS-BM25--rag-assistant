[site]: datascience
[post_id]: 120867
[parent_id]: 
[tags]: 
Performing imputation only on the test set?

I'm working on a medical machine learning problem. The key challenge is working with small datasets with quite a lot of missing data. Experimentally, I've seen complete-case analysis (i.e. dropping all rows with missing data) work quite well on one dataset, and imputation (just average based at the moment) working well on another. I can't really justify true complete-case analysis, as missing data is an inherent part of this data and similar datasets. I was wondering if a middle ground where only complete-cases are used for training the model, but then imputation on the test set (using data from train to avoid data leak) is a valid approach? Is there a name for this approach, or any literature? I've been unable to find any. Is there likely to be a performance advantage doing this vs imputing both train and test? Thanks
