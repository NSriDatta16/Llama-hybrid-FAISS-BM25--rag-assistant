[site]: crossvalidated
[post_id]: 638107
[parent_id]: 
[tags]: 
about bayesian optimization, please help

in machine learning mastery website, i don't understand this paragraph. P(A|B) = P(B|A) * P(A) / P(B) We can simplify this calculation by removing the normalizing value of P(B) and describe the conditional probability as a proportional quantity. This is useful as we are not interested in calculating a specific conditional probability, but instead in optimizing a quantity. * why they said we can remove p(B).and became P(B|A) P(A)??doesnt it will distorted the maximum value? i will give my example, my view might be a little bit distorted . these both example come from same samples: 'EX(1)P(B|A) = 3/4 , p(A)= 1/2 , P(B|A)*P(A)= 3/8 ,[P(B|A)*P(A)]/P(B) = 3/5. EX(2) P(B|A) = 2/4 , P(A) = 1/2 , P(B|A)*P(A) = 2/8 , [P(B|A)*P(A)]/P(B) = 2/3. ' in this example, for [P(B|A)*P(A)]/P(B) we got EX(2) better than EX(1) but when we remove the P(B) the EX(1) is clearly better. am i missing something???
