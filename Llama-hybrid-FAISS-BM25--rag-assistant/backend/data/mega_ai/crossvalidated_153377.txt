[site]: crossvalidated
[post_id]: 153377
[parent_id]: 153363
[tags]: 
Linear regression model can be described as $$ y = f(x) + \varepsilon $$ where you have a fixed part $f(x)$ and random part $\varepsilon$. Instead of single random part, you can have multiple random effects - like in random intercept linear mixed models . Random effects have mean of zero, some variance and are normally distributed. In mixed models random effects are predicted rather then estimated as fixed effects, what makes this kind of models called by some to be "somewhere in between" frequentionist and Bayesian approaches. The "frequentionist" part of such models assumes fixed parameters, while the "Bayesian" part is the random effects (see here for description of differences between Bayesian and freuentionist statistics). So from the estimation viewpoint this distinction makes sense, while in general this is a philosophical debate on the nature of the parameters and statistics in general.
