[site]: datascience
[post_id]: 61157
[parent_id]: 61114
[tags]: 
You should modify the code to produce the confusion matrix itself. But assuming that's impossible for some reason... A bit of linear algebra helps here. @n1k31t4 is right that given only accuracy, precision, and recall, you can't expect to reproduce the confusion matrix: you have three equations in four unknowns, and the equations can be expressed as linear equations (in the unknowns; see below), so there are definitely infinitely many solutions (but made finite by the non-negativity requirement, and in odd cases made few or even unique by the integer requirement). If you happen to also know the total number of samples (or perhaps some other confusion-matrix measurement), you can recover everything. You don't need both P and N as @BenjiAlbert uses (although that produces more pleasing formulas IMO). Below I've done it by putting everything else in terms of $TP$ , but there are sure to be several routes to the answer. From $\text{recall}=\frac{TP}{TP+FN}$ , we get $\frac{1}{\text{recall}} = 1+\frac{FN}{TP}$ and so $FN = (\frac{1}{\text{recall}}-1)TP$ . Similarly, from $\text{precision}=\frac{TP}{TP+FP}$ we obtain $FP = (\frac{1}{\text{precision}}-1)TP$ . Finally, $TN = \text{accuracy}\cdot\text{count} - TP$ , so $$\begin{align*} \text{count} &= TP+TN+FP+FN \\ &= \text{accuracy}\cdot\text{count} + (\frac{1}{\text{precision}}-1)TP + (\frac{1}{\text{recall}}-1)TP, \end{align*} $$ and now you can solve for TP: $$TP = \frac{(1 - \text{accuracy})\cdot(\text{count})}{\frac{1}{\text{precision}}+\frac{1}{\text{recall}}-2}$$ Plugging that back into the above formulas gives the values for all the others.
