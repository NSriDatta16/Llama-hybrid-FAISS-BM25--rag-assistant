[site]: crossvalidated
[post_id]: 465640
[parent_id]: 
[tags]: 
Surprising nonlinear variance-based scale est (bias adj) for Laplace Distribution competes with MLE?

Background: Using the quantile function (inverse cumulative distribution) for the Laplace distribution supplied with uniform random deviates (per the RAND() spreadsheet function), I examined an alternate estimator for comparison purposes for the scale parameter of the Laplace distribution in a spreadsheet setting. I worked with a sample size of 100 and computed the average, variance, and the average of the Least-Absolute deviations (LAD), which to quote again from Wikipedia source: Estimation of parameters Given ${\ N}$ independent and identically distributed samples ${\ x_{1},x_{2},...,x_{N}}$ , the maximum likelihood estimator ${{\hat{\mu}}}$ of ${\mu}$ is the sample median, [4] and the maximum likelihood estimator ${{\hat{b}}}$ of ${b}$ is the Mean Absolute Deviation from the Median. Now, in my spreadsheet, the average of absolute deviation for the random Laplace deviates (which is the MLE estimate) for the scale parameter, performed very well, so in the spirit of one of my recent related questions (see ‘Better than expected bias corrected estimator for scale parameter of Logistic random deviates based on sample standard deviation?’ ), I wanted to compare the relative performance again of the sample variance-based estimator with a derived bias correction factor for the current case of the Laplace distribution. So, I quickly derived an estimator, as to quote: Variance: ${2b^2}$ which similarly results in a bias estimator upon solving for b . This is could be viewed in the context of Generalized Method of Moments (GMM) estimator ( see Wikipedia and also the abstract reference below), which is valid for large sample sizes and usually moments over two. I again ran a 100 simulations, and variance-based scale parameter with a rough correction factor (based on 105 independent runs to ascertain a quick estimate) of 1.02 was employed. Again, shockingly in runs 56 to 44 times, 59 to 41, 55 to 45, ..., the non-linear variance estimator roughly corrected for biased displayed a smaller absolute error when compared to the true scale simulation-based parameter versus the MLE. Of course, further repetition and more work on the bias factor is likely warranted, but does anyone else find the implication of a non-linear sample based-estimator (with a quick bias assessment factor no less) possibly behaving better than the MLE surprising (at least, not for the case of small samples)? A search of the web does produce one related reference, ‘The second-order bias and mean squared error of nonlinear estimators’ , to quote the abstract: Despite the now widespread use of nonlinear estimators, their finite-sample properties have received very little attention in either the statistics or econometrics literature. We partially redress this problem by deriving and examining the second-order bias and mean squared error of a fairly wide class of nonlinear estimators which includes Nonlinear Least Squares, Maximum Likelihood, and many Generalized Method of Moments estimators as special cases. A number of examples are provided. The results from a Monte Carlo exercise demonstrate how the results can be applied for improved inferences. An example of work solving moment equations to assist in the derivation of parameter estimates can be found in this paper 'Moment-based estimation for the shape parameters of the Gamma-Gamma atmospheric turbulence model' .
