[site]: stackoverflow
[post_id]: 3456818
[parent_id]: 
[tags]: 
How does this not make varchar2 inefficient?

Suppose I have a table with a column name varchar(20) , and I store a row with name = "abcdef". INSERT INTO tab(id, name) values(12, 'abcdef'); How is the memory allocation for name done in this case? There are two ways I can think of: a) 20 bytes is allocated but only 6 used. In this case varchar2 does not have any significant advantage over char , in terms of memory allocation. b) Only 6 bytes is allocated. If this is the case, and I addded a couple of more rows after this one, INSERT INTO tab(id, name) values(13, 'yyyy'); INSERT INTO tab(id, name) values(14, 'zzzz'); and then I do a UPDATE, UPDATE tab SET name = 'abcdefghijkl' WHERE id = 12; Where does the DBMS get the extra 6 bytes needed from? There can be a case that the next 6 bytes are not free (if only 6 were allocated initially, next bytes might have been allotted for something else). Is there any other way than shifting the row out to a new place? Even shifting would be a problem in case of index organized tables (it might be okay for heap organized tables).
