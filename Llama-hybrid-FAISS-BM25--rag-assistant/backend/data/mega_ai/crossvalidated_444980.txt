[site]: crossvalidated
[post_id]: 444980
[parent_id]: 444471
[tags]: 
No you don't need to transform before the test. Research has shown that the t-test is quite reliable from departures of normality. In addition, it's appropriate for small sample sizes of e.g. 4, 6, 8, etc. The only thing you wouldn't want is a strong outlier(s), since averages and s.d. are used. For example, the average of the four numbers 1,2,3, and 1000000 is a little above 250000 = 1000006/4. So on the number line, the average of 250000 lies somewhere in outer space a 1/4 of the distance to 1000000, where there happens to be no data. The non-parametric Mann-Whitney or Wilcoxon rank sum test can guard against outlier effects as they are rank-based. The general idea is that if an outlier is present and ranks are used, the average of the ranks 1,2,3,4 for the four values 1,2,3,1000000 is 2.5=10/4 -- which is not precisely what Mann-Whitney does, but is similar with evaluations for ties. The alternative hypothesis for Mann-Whitney is also that the two samples came from different distributions. But you still need some sort of central tendency for non-parametric tests. For the t-test, you also have to know if the s.d. are equal between the two samples. If not, you can make an adjustment to the d.f. ( $\nu=n_1 + n_2-2$ ), or use a Welch test. Another important point is that parametric and non-parametric 2-sample tests for equality of means are for unimodal distributions of data, not multimodal with several large humps or spikes in distributions. Mann-Whitney is also not exactly the same as Wilcoxon rank sum, since there is a slight variation in the numerator of their test statistics. If you look at tail probabilities for the $t$ -distribution (range of $\nu$ ) and standard normal, you'll see that the standard normal pretty much starts to approximate $t$ near samples sizes of $n \sim 120$ . So I would use a Z-test for samples sizes above $n=120$ , and call it a large sample test , and simply say the $t$ is for small samples. Computationally, I like to use Z tests for large samples, since computing tail probabilities for the t-distribution is very expensive when compared with Z-scores tail probabilities.
