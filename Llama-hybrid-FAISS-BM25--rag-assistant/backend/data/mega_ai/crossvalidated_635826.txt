[site]: crossvalidated
[post_id]: 635826
[parent_id]: 451681
[tags]: 
I don't see a reason why we would need some extra definition for the time series situation. The definitions of scoring rules and (strict) propriety do not require any assumption on the dependence between different observations, in particular no i.i.d. assumption. Hence, they are perfectly valid, and also commonly applied, in forecast evaluations based on time series data. To be precise, a scoring rule assigns a score $S(G, y)$ to any pair of probability distribution $G$ and observation $y \in \mathbb{R}^d$ . The distribution $G$ could be anything from the success probability $p \in [0, 1]$ of a binary outcome to a density function on the real numbers. $S$ is proper if $$ \mathbb{E}_{Y \sim F} S(F, Y) \le \mathbb{E}_{Y \sim F} S(G, Y) $$ for all $F, G \in \mathcal{G}$ , where $\mathcal{G}$ is some class of distributions. It is strictly proper if equality of the expectations implies $F=G$ . In other words, the true distribution of the observation minimizes the expected score. There is no dependency assumption involved and we could also rewrite this definition such that no random variable appears, at all. In a time series setting, a forecaster would have some information at time $t-1$ specified by some $\sigma$ -algebra $\mathcal{F}_{t-1}$ and would produce some forecast $G_t$ of the distribution of $Y_t \vert \mathcal{F}_{t-1}$ . To judge whether one forecaster achieves lower expected scores than a competitor, we would estimate the score difference of their predictions $(G_t)$ and $(H_t)$ via $$ \frac{1}{n} \sum_{t=1}^{n} \left( S(G_t, y_t) - S(H_t, y_t) \right) . $$ If the $Y_1, \ldots, Y_n$ are i.i.d. this estimates the expected scores w.r.t. a single $Y$ , i.e. $\mathbb{E} (S(G, Y) - S(H, Y) )$ . For a general time series we need to add assumptions like stationarity or ergodicity to ensure that we estimate something meaningful. Although we then estimate some mixture of expected scores (since the distribution of the $Y_t$ varies), propriety still ensures that high positive or negative values indicate differences in predictive performance. For the definition and more background on proper scoring rules see Gneiting and Raftery (2007). Strictly Proper Scoring Rules, Prediction, and Estimation.
