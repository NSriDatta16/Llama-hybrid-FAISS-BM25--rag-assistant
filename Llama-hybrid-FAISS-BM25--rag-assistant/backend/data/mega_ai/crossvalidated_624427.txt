[site]: crossvalidated
[post_id]: 624427
[parent_id]: 
[tags]: 
Dataset too small for number of predictors

For some context, I'm a PhD candidate that is just trying to finish up their dissertation who has insufficient data for any real meaningful analysis and I'm at a bit of a loss on what to do in my predicament and would like some suggestions/advice on how to move forward. My issue is I have this potentially wonderful dataset of semi-wild animals with associated behavioral, social, environmental, and biological data for most of the individual from birth to death. However, this dataset is just not usable for what I set out to do. I was originally told that there was 74 animals in this dataset and while small I thought it would usable, however, that wasn't the reality of the sample, depending on the response variable under investigation the sample size varies from 33 to 22 data points. The models (MCMC glmm univariate 'animal' models), have 5 to 6 predictor variables, plus 1 random effect. All of my variables are continuous, except for 1 (i.e., sex). For the most part I have good convergence and stability for the MCMC, but the residuals distributions are not normal. I figured out it was a subset of animals that are causing my models to have a non normal distribution (my sample has a small handful of infants that are causing non-normality... most of data points are adults, with a few juvenile/subadults). When I take the the infants out, my residuals are normally distributed, but my sample size also shrinks by 4-5 animals depending on the response variable (samples would be in the 20s and teens). I know my models are already too complex for the sample size, and I have tried to simplify them by binning data and trying to get rid of some predictor variables but those suggestions/models have been shot down by my advisor and some committee members. I gave a suggestion that we just keep the models as is (non-normality) and just be super transparent about all the issues of the model(s) because the question we are trying to answer/shed light on revolves around how the predictor variables affects our response variables throughout growth. My thoughts on this are that the models, more or less, are not great models for the data, even if we can get normality in our residuals our sample size are just too small for them to say anything meaningful (I also recognize my models with a slightly larger sample size also can't say anything meaningful). I feel like whatever way I go, I am in a lose-lose situation. My advisor doesn't like that answer and wants me to find a solution, which to me would be to wait 10-20 years for more data, which I am not about to do. So I would like some advice, given the constraints of the sample size, having to keep all of my variables continuous, not able to reduce the number of predator variables, or have enough time/ability to collect more data, what else can I do?
