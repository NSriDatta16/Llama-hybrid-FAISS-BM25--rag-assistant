[site]: crossvalidated
[post_id]: 21937
[parent_id]: 21933
[tags]: 
Ion, PCA is just a specific case of orthogonal rotation. Let X be your n x p data matrix of n points in p dimensions (axes). To obtain this same cloud of points in a new set of axes somehow rotated in space relatively the old ones, you multiply X by a p x p matrix Q of cosines between the old axes (rows) and new axes (columns): $\bf{XQ=C}$ [1], where C is your new (rotated) coordinates. This formula says that each new dimension is a linear combination of p old dimensions. It also follows that $\bf {X=CQ^{-1}}$ or, since the rotation was orthogonal - $\bf Q$ is orthonormal matrix, - $\bf {X=CQ'}$ [2] which says that each old dimension is a linear combination of p new dimensions. Now, PCA is virtually this rotation; what makes PCA special is that Q is not an arbitrary rotation matrix; it is the matrix of such a rotation so that the sum-of-squares (or variance, if your data had been centered) in the 1st column of C becomes maximal possible: that is, variability along the 1st principal component is maximized. Then, sum-of-squares of in the 2nd C column (2nd principal component) is second maximal. Etc. Each next component is a new axis which takes off less and less of multidimensional variability in the cloud. Hence, lion's share of the variability is accounted for by only few m ( m p ) new axes (principal components). In PCA, Q is called matrix of eigenvectors (these being its columns). If you retain just m first components, by retaining just m first columns in Q , you still can use formula [1] to obtain component scores for the m components - the points' coordinates on these m dimensions. So, whatever is m , each component remains a linear combination of original variables. However, using then formula [2] to obtain p original variables from m components won't give you original variables exactly: each original variable will be a linear combination of m components plus some error term . If you perform linear regression ( without constant term) of each original variable by m components as predictors you will see that regression coefficients you get are the elements of Q .
