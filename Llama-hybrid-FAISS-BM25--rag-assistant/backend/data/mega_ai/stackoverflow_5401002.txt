[site]: stackoverflow
[post_id]: 5401002
[parent_id]: 2854087
[tags]: 
If the point of the game is to encourage the user to speak using pronunciation that is closest to "standard pronunciation" for a given language (e.g. EN-US), then having the user train the recognizer to adapt to the user's particular (unmodified) speech patterns may be counterproductive. You would in part be training the recognizer to be more forgiving of the user's pronunciation lapses. Whether you end up using grammar-based recognition or dictation-based recognition (Eric Brown's post looks very promising), you will probably also want to look into "confidence" scores. These scores are available after a recognition has been performed, and they give a numeric value to how confident the recognizer is that what the user actually said matches what the recognizer thinks the user said. Depending on the recognizer configuration and use case, confidence scores may or may not be meaningful. If you are basing your accuracy score off of the textual representation of the phones/phonemes/pronunciation, a quick and easy way to get an accuracy score would be to use Levenshtein distance, an algorithm for which there are many implementations freely available on the net. A better scoring algorithm might be a resynchronizing diff, with the atomic unit of comparison being single phones. Here are some keywords for MSDN doc hunting: ISpRecoResult -> GetPhrase -> SPPHRASE -> Rule -> SPPHRASERULE -> SREngineConfidence. http://msdn.microsoft.com/en-us/library/ee413319%28v=vs.85%29.aspx http://msdn.microsoft.com/en-us/library/ms720460%28v=VS.85%29.aspx
