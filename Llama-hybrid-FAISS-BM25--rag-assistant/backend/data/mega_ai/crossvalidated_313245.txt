[site]: crossvalidated
[post_id]: 313245
[parent_id]: 313230
[tags]: 
Generative Adversarial Networks consist of a Generator and a Discriminator. It is the Generator that attempts to generate images that should fool the discriminator. (1) Is the ability of the Generator to fool the discriminator specific to the particular discriminator? No, not in theory anyway. Imagine that the generator successfully learns to generate data that is indistinguishable from real data. Then all possible discriminators are out of luck. In this particular case, it was proved by [1] that best a discriminator can do is assign 50% that a point is generated/real. You can think of this as flipping a fair coin. In this sense, the optimal generator can "fool" any Discriminator. However, the authors write the following about their proofs The results of this section are done in a non-parametric setting, e.g. we represent a model with infinite capacity ... In the real world, neither generator nor discriminator has infinite capacity. Typically one uses Neural Networks for both. In this case, if one trained a very good NN generator, it should be able to "fool" most NN discriminators. That said, it seems unlikely that the NN generator would be able to "fool" all NN discriminators. You might be interested in reading about the "inception" score [2]. This is a measure of the quality of the generated images. It is computed using a CNN that is used to discriminate the generated images. [1] https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf [2] https://github.com/hvy/chainer-inception-score
