[site]: datascience
[post_id]: 122350
[parent_id]: 
[tags]: 
How can I improve accuracy of my ensemble (or anywhere in the code where I can increase accuracy)?

I am pretty new to machine learning, so if my code is not good, please bear with me. import pandas as pd import os import seaborn as sns from sklearn.metrics import accuracy_score from sklearn import tree import matplotlib.pyplot as plt from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from sklearn.svm import SVC from sklearn.neighbors import KNeighborsClassifier from sklearn.naive_bayes import GaussianNB import numpy as np from imblearn.combine import SMOTETomek from sklearn.model_selection import GridSearchCV from sklearn.metrics import confusion_matrix from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.svm import SVC from sklearn.ensemble import VotingClassifier from sklearn.pipeline import Pipeline from sklearn.model_selection import cross_val_score from sklearn.model_selection import RepeatedStratifiedKFold from sklearn.model_selection import RandomizedSearchCV !wget -q --show-progress "https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Pioneers/Heart%20Disease/heart.csv" patient_data = pd.read_csv("heart.csv") patient_data = patient_data[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'thalach', 'exang', 'target']] column_names = {'age':'age','sex':'sex','cp':'chest_pain', 'trestbps':'blood_pressure','chol':'cholesterol','fbs':'high_blood_sugar','thalach':'heart_rate','exang':'exercise_pain','target':'disease'} patient_data = patient_data.rename(column_names,axis=1) patient_data['chest_pain'] = (patient_data['chest_pain'] > 0).astype(int) #1 for yes, 0 for no patient_data['disease'] = 1 - patient_data['disease'] #1 for yes, 0 for no patient_data = patient_data[['age', 'blood_pressure', 'heart_rate', 'sex', 'chest_pain', 'exercise_pain', 'disease']] X = patient_data[['chest_pain', 'exercise_pain', 'heart_rate', 'blood_pressure', 'sex', 'age']] #FILL ME IN y = patient_data[['disease']] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) smote_tomek = SMOTETomek(random_state=42) X_res, y_res = smote_tomek.fit_resample(X_train, y_train) reg = LogisticRegression(C=1.623776739188721, penalty='l1', solver='liblinear') tree = DecisionTreeClassifier(criterion='entropy', max_depth=30, max_features='sqrt', min_samples_split=4) rf = RandomForestClassifier(max_depth=4, max_features='auto', min_samples_split=5,n_estimators=41) svc = SVC(kernel = 'poly', C=1000.0, gamma = 0.001) gnb = GaussianNB(var_smoothing = 2.848035868435799e-05) ensemble = VotingClassifier([('cf1', reg), ('cf2', tree), ('cf3', rf), ('cf4', svc), ('cf5', gnb)], voting = 'hard') cross_val_score(ensemble, X_res, y_res).mean() The dataset link is given in the code. The dataset is the Cleveland Clinic Heart Disease Dataset (303 samples), and I'm trying to classify whether or not the person has heart disease or not. I made a ensemble with regression, svm, random forest classifier, decision tree classifier, and gaussian naive bayes models. I also used hyperparameter tuning, but maybe there was something that I missed that could be improved on. I'm getting accuracy from ~ $75\%$ - ~ $84\%$ (maybe it could be higher, but I haven't seen anything higher yet). I was wondering if I could increase this accuracy, whether it is in the ensemble itself, or the data, number of features, etc. I also resampled the data set SMOTETomek from imblearn , and am not sure whether that was a good idea or not. If not, should I use a random over (or under) sampler, or something else? I would also like to know if I am missing any steps in cleaning the data.
