[site]: crossvalidated
[post_id]: 628730
[parent_id]: 321621
[tags]: 
The posterior probabilities come from Bayes Theorem , which is the following given the symbols the author uses: P(E|S)*P(S) P(E|S)*P(S) P(S|E) = ------------- = ----------------------------------- P(E) P(E|S=1)*P(S=1) + P(E|S=0)*P(S=0) On the right, the numerator is the conditional probability of the answer being right or not, E, given whether the student knows or not, S, weighted by the prior. The denominator is the prior probability of E: the probability of getting answer E given the prior distribution. It uses the law of total probability : P(E) isn't given to us directly, but can calculate it because we know all of the P(E|S) combinations and P(S). They represent the probability of state S after (or posterior to ) observing results, in this case just one observation. Conceptually, it gives you an updated estimate of whether the student knows (S=1) or doesn't know (S=0) the material after getting the response to a question. If they get the question right, you're more sure now that they know the material. If they got 2/2 questions right then you'd be even more sure. If they got 4/5 wrong then you'd be pretty sure they don't know the material. Bayes' Theorem makes this quantitative. From the input and output values: prior: knowing Newton's law is 50% yes, 50% no after getting one question right: 94% yes, 6% no after getting one question wrong: 17% yes, 83% no You might be curious why it isn't symmetric: getting the question wrong doesn't mean the percentages are 6% yes, 94% no. The reason is mathematically described by the Bayes Factor . For each result E we can look at the probabilities P(E|S): for E=1, getting it right: P(E=1|S=1) is 0.8, but P(E=1|S=0) is only 0.05. So by 16:1 odds the right answer comes from knowing the material. This is very lopsided, so the posterior probabilities are closer to 100%/0% Note: the 94%/6% result is exactly 16:1 odds! for E=0, getting it wrong: P(E=0|S=1) is 0.2, and P(E=0|S=0) is 0.95. So by about 5:1 odds the wrong answer comes from not knowing the material. Not nearly as lopsided as 16:1 odds, so as a result, the posterior probabilities are farther from 0%/100% Note: 17%/83% is exactly the 02:0.95 odds! The odds work out really nicely in this case because the Bayes Factor equation (derived from Bayes Theorem) is posteriorOdds = bayesFactor * priorOdds , and the prior odds are just P(S=1)/P(S=0) = 1 . So it leaves posteriorOdds = bayesFactor . The Bayes Factors are the ratios like 16:1 above. See this answer for more. IMO it's more helpful than the Wiki link for understanding; the Wiki page is more about the derivation. So in this way, you can conceptually think of the posterior probabilities/odds versus the prior as how different your data was than the prior. In this example, 94%/6% is very different from the prior of 50%/50% so the results are pretty convincing. But I should also note that a prior probability of 0 means P(S|E) = 0 from the formulas no matter what. So there are limits to this intuition. It also illustrates the weakness of Bayesian methods - no amount of data can save you from a sufficiently bad prior!
