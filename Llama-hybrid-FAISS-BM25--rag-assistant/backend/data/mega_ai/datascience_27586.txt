[site]: datascience
[post_id]: 27586
[parent_id]: 
[tags]: 
Is a 100% model accuracy on out-of-sample data overfitting?

I have just completed the machine learning for R course on cognitiveclass.ai and have begun experimenting with randomforests. I have made a model by using the "randomForest" library in R. The model classifies by two classes, good, and bad. I know that when a model is overfit, it performs well on data from its own trainingset but badly on out-of-sample data. To train and test my model I have shuffled and split the complete dataset into 70% for training and 30% for testing. My question: I am getting a 100% accuracy out of the prediction done on the testing set. Is this bad? It seems too good to be true. The objective is waveform recognition on four on each other depending waveforms. The features of the dataset are the cost results of Dynamic Time Warping analysis of waveforms with their target waveform.
