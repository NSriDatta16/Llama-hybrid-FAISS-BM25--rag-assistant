[site]: stackoverflow
[post_id]: 1752651
[parent_id]: 1751031
[tags]: 
In terms of general strategies, webguydan 's strategy has a script looping file and database records and comparing them, backward and forwards. You can do better by leveraging your database more. Note what will and won't be slow here: Database inserts are the fastest database operation. Your slowest operation will probably be reading file system MP3 metadata. Single calls to the file system or to the database are much more expensive than set operations (get a list of files). In particular, the deletion operation that checks hundreds of rows for existence of a file will be quite slow. Strategy 2. Creating a staging table in the database to perform comparisons. Your script reads all the mp3s and inserts them into a staging table, which is an empty copy of mp3 table. You then join to the real table to identify moves, deletes, additions. Strategy 3: Simply replace the entire database table. I suspect that the slow part of this operation will be reading mp3 metadata, not any database operation. Since your process reads all the mp3 metadata anyway to identify changes, just replace the entire sql database at each refresh. I'd start with this approach and optimize if needed. Replacing won't work if you have additional information that you were storing in the mp3 sql database that you couldn't replace from the file system. Strategy 4: Depending on your OS version, extracting mp3 metadata may be slow (or maybe not?) Skip reading slow parts of the file system (metadata?) by reading path,name,update date into your staging table. Simple sql queries can identify files that need to be updated (read mp3 data), deleted from table, or inserted. Other approaches: Note that many operating systems and products already allow database style queries to the data you are talking about. MS Indexing service, for example.
