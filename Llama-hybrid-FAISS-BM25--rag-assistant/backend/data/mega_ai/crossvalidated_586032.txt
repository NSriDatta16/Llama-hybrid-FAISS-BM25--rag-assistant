[site]: crossvalidated
[post_id]: 586032
[parent_id]: 585107
[tags]: 
The integral $ \int Q_\lambda(w) \ln \frac{Q_\lambda(w)}{P(w)} dw $ is by definition an expectation $\mathbb{E} \ln \frac{Q_\lambda(W)}{P(W)}$ where $W$ is a random variable with distribution $Q_\lambda(W)$ . Then the expectation is approximated with Monte Carlo method : $$ \int Q_\lambda(w) \ln \frac{Q_\lambda(w)}{P(w)} dw = \mathbb{E} \ln \frac{Q_\lambda(W)}{P(W)} \approx \frac{1}{N} \sum_{n=1}^N \ln \frac{Q_\lambda(w^{(n)})}{P(w^{(n)})} $$ Where $w^{(1)}, \dots, w^{(N)}$ are independent samples from the $Q_\lambda(w)$ distribution. The bigger the $N$ , the smaller is the approximation error. However, in modern stochastic optimization (especially in deep learning) $N$ is often set to 1, since over many iteration of optimization there will ultimately be many different draws of these random variables, and any high variance of an estimate could be dwarfed with reduction in the learning rate.
