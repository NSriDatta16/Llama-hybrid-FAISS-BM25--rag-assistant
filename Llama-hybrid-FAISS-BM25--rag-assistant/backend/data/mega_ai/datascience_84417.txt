[site]: datascience
[post_id]: 84417
[parent_id]: 84395
[tags]: 
I didn't watch the linked video but based on your explanations: yes, your understanding is correct. A common confusion is to assume that cross-validation is similar to a regular training stage and therefore produces a model. This assumption is wrong: CV includes repeated training/testing for the purpose of evaluating the method/parameters . From this understanding it follows that: for doing model training using k fold CV, we re-train on the entire dataset after the end of the CV loop and that is the final model. Yes, since we want to obtain the final model as accurate as possible so we should use all the data. In this case the CV has been used to calculate a good estimate of the performance. We do not select any model from inside the CV loop if the idea of doing CV training is to check the accuracy of the ML algorithm on the entire dataset. Correct, otherwise there's no point using CV. However, if we have multiple ML algorithms say random forest, neural network, SVM inside the CV loop then we select the algorithm with the highest accuracy. Any case where multiple methods and/or parameters are being evaluated is a bit more complex than the regular case of a single method: evaluating multiple systems is by itself an additional layer of training, in the sense that we select some parameters (typically the best model) based on the data. This means that the selection itself is based on the whole data used in the CV stage, so the CV performance of the best model is akin to a performance obtained on a training set. This is why one needs another test set (or nested CV) in order to obtain the final performance of the model. An intuitive way to understand this is to imagine evaluating say millions of models with CV: the only way to know if the best performance is due to chance or not is to evaluate the corresponding model on some fresh test set. Note: the case of combining the outputs of all the models is a different story, since this boils down to a single meta-model.
