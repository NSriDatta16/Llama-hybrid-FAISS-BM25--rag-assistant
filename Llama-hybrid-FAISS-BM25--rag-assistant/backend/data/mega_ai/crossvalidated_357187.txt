[site]: crossvalidated
[post_id]: 357187
[parent_id]: 
[tags]: 
High complexity random forest always performs best on test data

(I am new to machine learning so please bare with me) I am using Random Forest Regression algorithm but I am seeing interesting results. I randomly split data into validation set, test set, and training set, and I used the Python tool GridSearchCV to tune Random Forest, and no matter how I tune, the most complicated RF had the highest score on both validation and test sets no matter how I tune its complexity mathematically (although training and test accuracy differed by 5 to 7 percent). Could this possibly happen if the problem is simple (simple enough that it can train well using fewer points) and the model is training on huge load of data?
