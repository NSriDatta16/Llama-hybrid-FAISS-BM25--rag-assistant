[site]: crossvalidated
[post_id]: 92568
[parent_id]: 92537
[tags]: 
It depends on what you mean by "better", but for most reasons I can think of, the "Risk Ratio" is the superior measure in terms of better reflecting what most people are looking for, having a slightly easier interpretation, etc. But there are some study types that prevent the calculation of a risk ratio (case-control studies) and logistic regression, which is used to calculate odds ratios, is somewhat easier to do - less likely to end up with weird values or convergence problems. But for most of those cases, people are using the odds ratio as a reasonable approximation of the risk ratio they'd actually like in an ideal world. To expand on gung's question a little bit, to explain this reasoning: In an ideal world, an observational epidemiologist would run nothing but cohort studies. As a field, the "desirable" estimate is a risk - there's a back and forth about whether or not the comparison between groups should be a relative risk or a risk difference, but the core is risk, not odds, and right now the de facto effect estimate is relative risk. But cohorts are super-expensive, especially for rare diseases, so case-control studies exist to make the study of those diseases feasible. You can't estimate a relative risk for those however, but it's a decent approximation for rare diseases, so we accept odds ratios as "close enough".
