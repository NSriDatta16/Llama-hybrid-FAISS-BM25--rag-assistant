[site]: crossvalidated
[post_id]: 73720
[parent_id]: 
[tags]: 
Regression estimate of a non-negative variable

I have to estimate linear weight $\beta$ for regression $Y \sim \mathbf{X}$, where $Y$ are non-negative samples. If I perform vanilla regression (lets assume ridge regression) it will find $\beta$ such that most of estimated $\hat{Y}$ are non-negative. But some of them will be negative. But I need them to be invariably non-negative. In Bayesian framework, it implies I need a prior $\beta$ that is non-negative (ridge assume normal priors). Is there simple way to modify ridge regression to obtain this? Or putting non-negative priors and estimating via MCMC is only solution to it. For further description of problem (why I need estimated $\hat{Y}$ to be positive). My full model is a hierarchical model where there is a variable $Z$ that is a linear model of latent variable $Y$ i.e $Z \sim N(\Theta^T \mathbf{Y}, \sigma^2)$. Observable variable are $Z$ and $X$. I need estimates of $\beta$ and $\theta$. I am currently estimating $\beta$ given Y. Given $\hat{Y}$ I am estimating $\theta$. I am iterating between this 2 steps. If $\hat{Y}$ is negative the problem become unidentifiable.
