h data centers emerging as a dominant force behind the increase. The trend is expected to continue as semiconductor and battery manufacturing plants ramp up operations, further intensifying demand. In 2024, a US public policy group reported that AI and other technologies and industries poised to dominate the global economy are characterized by their high electricity demands. As such, the foundation of US energy strategy and policymaking will be to prioritize the reliable and abundant provision of electricity to support these critical sectors, which are needed to maintain the US economic and technological leadership in the twenty-first century. The rapid proliferation of AI has created unprecedented demand for electrical power, presenting a major obstacle to the sector’s growth. E.g., in Northern Virginia, the largest global hub for AI data centers, the timeline for connecting bigger facilities—those requiring over 100 megawatts of power—to the electrical grid has extended to seven years, highlighting the strain on the energy infrastructure and the challenge of meeting AI’s escalating power needs. Across the United States, utilities are experiencing the most substantial surge in electrical demand in decades. This strain is directly contributing to longer wait times for grid connections, complicating efforts to maintain the country’s technological leadership in AI. The significance of these energy challenges extends beyond logistics. A New York Times editorial emphasized the critical role of energy infrastructure, stating that "Electricity is more than just a utility; it’s the bedrock of the digital era. If the United States truly wants to secure its leadership in A.I., it must equally invest in the energy systems that power it." Globally, the electricity consumption of data centers rose to 460 terawatts in 2022. This would have made data centers the 11th largest electricity consumer in the world, between the nations of Saudi Arabia (371 terawatts) and France (463 terawatts), according to the Organization for Economic Co-operation and Development. Water usage Cooling AI servers can demand large amounts of fresh water which is evaporated in cooling towers. To minimize the use of water required for cooling, centers are adopting a closed-loop system where the water is reused. In a 2025 paper, researchers projected that AI will withdraw between 4.2 – 6.6 billion cubic meters of water in 2027, greater than half of the total water withdrawal of the United Kingdom. The authors estimated that training GPT-3 may have consumed 700,000 liters of water, and that 10–50 medium-length GPT-3 responses consume about 500 mL of fresh water, "depending on when and where it is deployed". One data center that Microsoft had considered building near Phoenix, due to increasing AI usage, was likely to consume up to 56 million gallons of fresh water each year, equivalent to the water footprints of 670 families. Microsoft may have increased water consumption by 34% due to AI, while Google increased its water usage by 20% due to AI. Due to their Iowa data center cluster, Microsoft was responsible for 6% of the freshwater use in a local town. A possible solution for reducing water consumption is to build data centers in colder countries that can offer a natural cooling system. For example, Facebook (now Meta) built a data center in Luleå, northern Sweden, in 2011. Google invested one more billion euros into the expansion of its data centre campus in Hamina in Finland in 2024, for a total of 4.5 billion euros invested in the site which also uses seawater for cooling its servers. E-waste Electronic waste (E-waste) due to production of AI hardware may also contribute to emissions. The rapid growth of AI may also lead to faster deprecation of devices, resulting in hazardous e-waste. Among the 62 million tonnes of e-waste produced in 2022, less than one quarter of the total mass was properly recycled. Worldwide, the annual generation of e-waste is rising by 2.6 m