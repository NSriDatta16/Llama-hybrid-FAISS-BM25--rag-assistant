[site]: crossvalidated
[post_id]: 146361
[parent_id]: 
[tags]: 
Adjusting for the past using OLS regression with single lagged response

There are many fine ways to handle a time series error structure in regression, for example as discussed in Time Series with Autoregressive Error . But consider a panel regression model of the form $$ y_{it} = \alpha + \rho y_{it-1} + \beta x_{it} + \epsilon_{it}, $$ for subjects $i = 1, ..., N$ with $t$ as a single point in time (i.e., one current response and one lagged response are available for every subject $i$). Furthermore, suppose this model is fit with OLS regression, with the intuition being to estimate the impact of $x_{it}$ on $y_{it}$ "adjusted for the past." Clearly if $\rho = 1$, we're modeling $\Delta y_{it}$, which seems fine for OLS regression (depending on the definition of $x_{it}$). So I'm thinking to myself, even if there is an endogeneity problem, how much could it hurt to estimate $\rho$ with OLS rather than set it to one? On the other hand, are there benefits to estimating $\rho$ (with OLS or a more sophisticated procedure) rather than just modeling the change?
