[site]: crossvalidated
[post_id]: 278736
[parent_id]: 278729
[tags]: 
With your corrmat (and to get the same output as SPSS using python's library numpy) I would do >>> eigenvalues = np.linalg.eigvals(corrmat) >>> _eigenvectors = np.linalg.eig(corrmat)[1] >>> eigenvectors = - _eigenvectors * np.sign(np.sum(_eigenvectors, 0)) ^ Note the presence of the minus sign above, which as you surely know, can be reversed without changing the variance that is contained in components . Actually, I flip eigenvectors simply to get the ones given by SPSS. And finally >>> eigenvectors*pow(eigenvalues, .5) [[-0.9405272747183386 0.2912371623961133 -0.1407363781821823 0.0912757427551984 -0.0494647032587364 -0.0021481439731338] [-0.9814331113889905 0.0721992935972806 -0.0785090923649322 -0.1459649895629314 -0.0045603280920887 -0.0639222771731283] [-0.9674737210319674 0.1670238493452638 -0.156248635777037 -0.0559392103161693 0.0185365986221359 0.0906156495368767] [ 0.6556408081143963 -0.0951692221784938 -0.7489613102250138 -0.0103839230577475 -0.0029680173560357 -0.0042744222974036] [-0.979638613927672 -0.0730875114449731 -0.1413705590288849 0.1070180886447224 0.0453366719942605 -0.0383729291014583] [-0.6712266404563406 -0.7406796816331325 0.0119583064943183 -0.0001786453151769 -0.0198064550991169 0.0176940014010874]] This is one way to calculate Factor coordinates in PCA using python . The paper which helped me understanding that is Yoel Haitovsky (1966)'s .
