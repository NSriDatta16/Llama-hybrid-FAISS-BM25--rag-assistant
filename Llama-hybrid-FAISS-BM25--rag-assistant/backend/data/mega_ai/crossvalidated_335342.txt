[site]: crossvalidated
[post_id]: 335342
[parent_id]: 335310
[tags]: 
You have made a slight, but important, mistake in your likelihood function. Let's try constructing it differently, breaking the $T=13,500$-length time period into $13,500$ time periods of length $1$ instead of two time periods of length $T_1$ and $T-T_1$. You can see how that likelihood function will look: $$\mathcal{L}(\lambda_1, \lambda_2, T_1) = {\lambda_1^{N_1} e^{-\lambda_1 T_1} \over \Pi_{t\leq T_1}x_t!}{\lambda_2^{N_2} e^{-\lambda_2 (T-T_1)} \over \Pi_{T_1 where $\lambda_1$ is the per-period arrival rate in $[0,T_1]$, $x_t$ is the total number of arrivals in period $t$, $N_1$ is the total number of arrivals in $[0,T_1]$, etc. The way you have done it implicitly assumes there are two periods, one with rate $\lambda_1T_1$ and one with rate $\lambda_2 (T-T_1)$, but if you examine those expressions carefully, you will see that you are confounding the arrival rates $\lambda_i$ and $T$; you really only have two arrival rates in your likelihood function, rates which are functions of the three parameters $\lambda_1$, $\lambda_2$, and $T$, and two samples, each of size $1$. To see this more clearly, let's rewrite your version of the probability distribution of the data: $$p(N_1,N_2) = {\gamma_1^{N_1}e^{-\gamma_1} \over N_1!}{\gamma_2^{N_2}e^{-\gamma_2} \over N_2!}$$ where $\gamma_1 = \lambda_1\Delta T_1$ and $\gamma_2 = \lambda_2(T-\Delta T_1)$. The first term is the probability of a single observation $N_1$ from a Poisson($\gamma_1$), and the second is the probability of a single observation $N_2$ from a Poisson($\gamma_2$). We can learn about $\gamma_1$ and $\gamma_2$, but not so much about $\lambda_1$, $\lambda_2$, and $T_1$. For example, if the MLEs of $\gamma_1$ and $\gamma_2$ are 1 and 2 respectively, with the maximum likelihood function value $\mathcal{L}(1,2) = 1$, then setting $T=10$, $T_1=5$, $\hat{\lambda}_1 = 0.2$, and $\hat{\lambda}_2 = 0.4$ results in $\mathcal{L}(0.2*5=1, 0.4*5=2) = 1$, and setting $T_1 = 2$, $\hat{\lambda}_1 = 0.5$, and $\hat{\lambda}_2 = 0.25$, results in $\mathcal{L}(0.5*2=1, 0.25*8=2) = 1$, the same as before. Any value of $T_1$ has corresponding values of $\hat{\lambda}_1$ and $\hat{\lambda}_2$ that allow the maximum of the likelihood function to be achieved, so all values of $T_1$ are equally likely and the likelihood function contains no information about $T_1$. (It does contain information about the relationship between $T_1$, $\lambda_1$, and $\lambda_2$, but not about $T_1$ in isolation.) This way makes $T_1$ and $T-T_1$ into two sample sizes, and thereby separates them from the arrival rates per observation. We still have $\lambda_1T_1$ and $\lambda_2(T-T_1)$ in the exponential term because there are $T_1$ periods; taking the product of $T_1$ Poisson distributions results in a term of the form $\exp\{-\lambda T_1\}$ (and, in this case, $\exp\{-\lambda(T-T_1)\}$). On a more intuitive level, by treating each $x_t$ as a sample, we can distinguish between the following two situations. Let $T_1 = 9,000$ and $N_1 = 320$. Now, if there were 20 observations over the first 4500 periods and 300 over the last 4500 periods, that would be extraordinarily unlikely for a Poisson variate, and would weigh very heavily against the hypothesis of a constant rate over the interval, but if there were 155 observations over the first 4500 periods and 165 over the last 4500 periods, that wouldn't be unusual at all. However, if we aggregate all the counts to $N_1 = 320$, we can't distinguish between these two arrangements of the observations, even though all the information is there in the underlying data. It is this information that is being lost by your aggregation of the data into one observation from each of two time periods. We'll show some R code that calculates the profile log likelihood for $T_1$, that is, the log likelihood for $T_1$ given the maximum likelihood estimators for $\lambda_1$ and $\lambda_2$ conditional upon $T_1$. time_stamps T) l1 The resulting plot looks like: You can avoid the discretization into $13,500$ periods by converting the problem to one of estimating the parameters of the two exponential distributions for the inter-arrival times, but you would gain very, very little for a problem of this size by doing so. ETA: Some question has arisen as to why the above code omits the factorials in the denominator. This is because they are functions only of the $x_i$, and, as such, don't change when the input values to the likelihood function change; they are constants, and can be ignored. Consider the log of the likelihood function for a Poisson (which saves me typing relative to the actual problem): $$\log \mathcal{L}(\lambda) = -N\lambda + \log(\lambda)\sum x_i - \sum \log x_i!$$ Let's take the difference for two values of $\lambda$, an operation which occurs inside the deviance / AIC / BIC calculations: $$\log \mathcal{L}(\lambda_1) - \log \mathcal{L}(\lambda_2) = -N(\lambda_1-\lambda_2) + (\log(\lambda_1)-\log(\lambda_2))\sum x_i$$ as the two terms involving $\sum \log x_1!$ cancel out. It should also be clear that the maximum value of $\log \mathcal{L}(\lambda)$ will be achieved at the same value of $\lambda$ regardless of whether the additive term $\sum \log x_i!$ is included or not, and all the slopes and higher level derivatives will also be the same. Thus, performing the calculations with $x!$ adds nothing to our analysis except computational burden. From a Bayesian point of view, consider the following posterior distribution: $$f(\lambda;x) = C{\lambda^xe^{-\lambda} \over x!}p(\lambda)$$ where $p(\lambda)$ is the prior on $\lambda$ and $C$ is the unknown constant of integration required to make $f$ integrate to 1. Let's calculate $C$: $$C = {1 \over {1 \over x!}\int_0^{\infty}\lambda^xe^{-\lambda}p(\lambda)d\lambda} = C'x!$$ Replacing $C$ with $C'x!$ results in: $$f(\lambda;x) = C'\lambda^xe^{-\lambda}p(\lambda)$$ as the terms involving $x!$ cancel out. Note that $C'$ does not change if we leave $1/x!$ out of the denominator of the expression for $C$. This shows that we don't need to include the $x!$ in the first place; it will just be canceled out when calculating the constant of integration anyway, so it adds no value.
