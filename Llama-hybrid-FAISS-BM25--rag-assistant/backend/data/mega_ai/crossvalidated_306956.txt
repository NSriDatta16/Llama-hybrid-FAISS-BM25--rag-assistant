[site]: crossvalidated
[post_id]: 306956
[parent_id]: 
[tags]: 
Implementing a very simple Bayesian Calibration

I want to understand Bayesian calibration. I tried to implement a simple Bayesian calibration by constructing a set of truth data and then comparing my model to that data. My understanding of Bayesian calibration is that I should create a set of prior pdfs. In this case, I created an array for each parameter representing probabilities of different values. I used normal distributions, distributed around the sum of least squares solution to the simulation parameters given the truth data. I updated these distributions with the formula $P(X|D) = P(D|X)\ P(X)$, and I normalized the distribution after each iteration to account for the missing denominator $P(D)$. After I have my distribution, I make by prediction using the expected value, $\int f(x) P(x) dx$. My simple example isn't working. Even when my model is capable of perfectly describing the truth (as it is in the settings I show here), the calibrated parameters are incorrect and scattered. Am I thinking about this correctly? Why am I not getting reasonable pdfs of my uncertain model parameters? import numpy as np import numba as nb from scipy.stats import norm import matplotlib.pyplot as plt from scipy.optimize import minimize as mini np.random.seed = 1 ''' In this problem I have some high-frequency data that I can't represent perfectly with my model. Specifically, the "observed" data is generated as a sum of sin waves with specified amplitudes of frequencies and the model is sum of sin waves with less frequencies to specify. ''' # Each sample is this number of time steps SAMPLE_TIME = 200 # Number of frequencies in the "observed" data NUM_TRUTH_FREUQENCIES = 2 TRUE_FF_COEFS = np.random.uniform(0, 1, NUM_TRUTH_FREUQENCIES) # Create "observed" "truth" Data samples = 100 TRUE_SIGNALS = [] for _ in range(samples): start = np.random.uniform(0, 1e3) sample = [] for t in np.linspace(start, start + 1e4, SAMPLE_TIME): sample.append(np.sin(TRUE_FF_COEFS*t).sum()) TRUE_SIGNALS.append([start, sample]) # Define the low-fidelity model to tune. NUM_LOWFI_FREQ = 2 def lowfi(LOWFI_FREQ, start): signal = [] for t in np.linspace(start, start + 1e4, SAMPLE_TIME): signal.append(np.sin(LOWFI_FREQ * t).sum()) return np.array(signal) ''' "vanilla" tuning: minimize the sum of the square of the errors between the models I could now use these to develop some probabalistic discrepency function between the two models. I use this to create my prior distributions. ''' def vanilla_fitness(lowfi_freqs): err = 0 for signal in TRUE_SIGNALS: err += np.mean(np.array(lowfi(lowfi_freqs, signal[0])) ** 2.) return err con = {'type': 'ineq', 'fun': lambda x: np.min(1-x), 'type': 'ineq', 'fun': lambda x: np.min(x-1)} x = mini(vanilla_fitness, np.ones(NUM_LOWFI_FREQ), method='COBYLA', constraints=con) vanilla_x = x.x plt.plot(lowfi(x.x, TRUE_SIGNALS[0][0]), label='Model') plt.plot(TRUE_SIGNALS[0][1], label='Truth') plt.legend() plt.savefig('Vanilla_Tuning.pdf') plt.clf() ''' Baysian Calibration I define a fitness function for single samples of the signal For every unkown parameter in the low-fidelity model, I create a prior using the known bounds. For each sample, I update the prior according to Bayes rule, P(X) = P(D|X) * P(X) then normalize the probability distribution to account for the missing denomenator. ''' def single_fitness(lowfi_freqs, signal_num): true_signal = TRUE_SIGNALS[signal_num] return np.mean(np.array(lowfi(lowfi_freqs, true_signal[0]) - true_signal[1]))**2 # Create Gaussian priors centered around the some of squares solution x_prior = [] num_probs = 400 lbounds = 0 ubounds = 1 for ii in range(NUM_LOWFI_FREQ): tmp_probs = [] for val in np.linspace(lbounds, ubounds, num_probs): tmp_probs.append(norm.pdf(val, vanilla_x[ii], .5)) # arbitrary sigma tmp_probs = np.array(tmp_probs) / np.sum(tmp_probs) x_prior.append(tmp_probs) # Update the priors using the data x_probs = np.array(x_prior) for sample in range(samples): # p(X) = P(D|X) * P(X) x = mini(single_fitness, np.ones(NUM_LOWFI_FREQ), args=(sample,), method='COBYLA', constraints=con) x_probs *= np.sum(x_probs[x_probs
