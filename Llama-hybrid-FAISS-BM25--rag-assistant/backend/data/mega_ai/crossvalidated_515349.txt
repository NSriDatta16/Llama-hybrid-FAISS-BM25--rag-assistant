[site]: crossvalidated
[post_id]: 515349
[parent_id]: 
[tags]: 
WOE logistic regression model with 61 variables, will it cause overfitting?

I've been working a WOE logistic regression model and the data I have is 2878 observations with 814 variables. I used the elastic net to create a penalized regression model so the overall variables have shrinked to 135 as the following code shows. set.seed(123) list.of.fits results # alpha mse fit.name # 1 0.0 4.695402 alpha0 # 2 0.1 4.832684 alpha0.1 # 3 0.2 4.141357 alpha0.2 # 4 0.3 4.613409 alpha0.3 # 5 0.4 4.712044 alpha0.4 # 6 0.5 4.588790 alpha0.5 # 7 0.6 4.452613 alpha0.6 # 8 0.7 4.489673 alpha0.7 # 9 0.8 4.344234 alpha0.8 # 10 0.9 4.371251 alpha0.9 # 11 1.0 4.765942 alpha1 # alpha0.2 is the best I used the variables that has coefficients over 0 in the elastic net model into the logistic regression. In total, the variables have been reduced to 135. Below I used the formula from the elastic net. vars 0 & rownames(coef(fits))!="(Intercept)"] formula = as.formula( paste( 'Y ~', paste( vars , collapse = '+') ) ) m = glm(formula, data_woe, family = 'binomial') summary(m) Then I used step function to select a formula based on AIC. m_step = step(m, direction="both", trace=FALSE) m = eval(m_step$call) > summary(m) Call: glm(formula = Y ~ income_direct_deposit_woe + amount_desired_woe + residence_length_months_woe + Bankaccountlengthmonths_woe + Salary_woe + ID_FraudRiskScore_woe + NumberofMerchantsAllTime_woe + FPDForABA_woe + FPDForABACount_woe + TotalNumberofLoansDelinquentLastYear_woe + OLNumberofApplications30_woe + OLNumberofMerchants_woe + DistancebetweenHomeZipandIPAddress_woe + ACA_ACH_SATISFACTORY_24M_woe + ACA_ACH_SATISFACTORY_EVER_woe + ACA_TTL_6M_BI_Bad_woe + ACA_TTL_6M_BI_GoodAmt_woe + ACA_OLNumberofApplicationsAllTime_woe + ACA_OLNumberofMerchants_woe + ACA_SFNumberofApplications30_woe + ACA_NumberofMerchantsAllTime_woe + ACA_LL_PD_MERCHANT_6M_woe + ACA_LL_PD_OPEN_6M_woe + ACA_LL_AVG_BAL_woe + TCA_AU21S_woe + TCA_G106S_woe + TCA_BC21S_woe + TCA_OF101S_woe + TCA_OF21S_woe + TCA_FI02S_woe + TCA_FI101S_woe + TCA_FI21S_woe + TCA_FI34S_woe + TCA_G105S_woe + TCA_G416S_woe + TCA_G960S_woe + TCA_G990S_woe + TCA_IN101S_woe + TCA_G208S_woe + TCA_RT09S_woe + TCA_RT34S_woe + TCA_ST02S_woe + TCA_AT09S_woe + TCA_AT104S_woe + TCA_AT57S_woe + TCA_CO04S_woe + TCA_G001B_woe + TCA_G001S_woe + TCA_G051S_woe + TCA_G057S_woe + TCA_G220B_woe + TCA_G235S_woe + TCA_G250C_woe + TCA_G251A_woe + TCA_JT80S_woe + TCA_AUT204_woe + TCA_BKC320_woe + TCA_STD205_woe + TCA_TRV10_woe + EmployerDomainMatch_LastDate_Diff_woe, family = "binomial", data = data_woe) Deviance Residuals: Min 1Q Median 3Q Max -2.49187 -0.49696 -0.23686 -0.08489 3.12302 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -1.75521 0.08546 -20.537 The model I got right now has AUC 0.79 and KS 0.45. But it still has 61 variables in the formula. Is it too much and likely to be overfitting? What should I do to select fewer variables without sacrificing too much in prediction? Thanks,
