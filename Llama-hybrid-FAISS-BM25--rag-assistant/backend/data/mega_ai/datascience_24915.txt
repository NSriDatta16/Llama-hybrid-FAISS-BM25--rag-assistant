[site]: datascience
[post_id]: 24915
[parent_id]: 
[tags]: 
Can you use machine learning to extract the entropy from a hand print reliably?

Let's say that I want to generate a cryptographic key based on my hand (I'm using hands just as an example). What I could do is I scan my hand (so that the friction ridges are apparent) and then use a key derivation algorithm. Problem is that if I want to get the same hash, I have to either store the scan somewhere, or be able to produce the exact same scan , which is not very feasible. What if instead, we use a machine learning algorithm that takes a scan of a human hand and produces some data, subject to the following constraints: If the same human hand is scanned twice, produce the same data If different human hands are scanned, produce different data Additionally, it should be hard to predict valid outputs of the neural net, other than brute force (so an adversary would either need to be able to generate human hand scan images, or just feed in random data). One way I thought of doing this was to scan a bunch of hands multiple times, and then train a neural network in such a way that it is punished if it gives different values for hands from the same person, or if two humans get the same hand. Also, you could have another neural network trying to predict whether something is an output of the first one, and the first network is punished if the second one can do so well. My question is, as this problem been studied before (not necessarily with hands, but producing the same output if two inputs satisfy some equivalence relation).
