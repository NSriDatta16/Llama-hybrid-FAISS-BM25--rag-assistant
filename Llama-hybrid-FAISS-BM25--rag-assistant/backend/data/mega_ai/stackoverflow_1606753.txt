[site]: stackoverflow
[post_id]: 1606753
[parent_id]: 
[tags]: 
Caching table results for better performance... how?

First of all, the website I run is hosted and I don't have access to be able to install anything interesting like memcached. I have several web pages displaying HTML tables. The data for these HTML tables are generated using expensive and complex MySQL queries. I've optimized the queries as far as I can, and put indexes in place to improve performance. The problem is if I have high traffic to my site the MySQL server gets hammered, and struggles. Interestingly - the data within the MySQL tables doesn't change very often. In fact it changes only after a certain 'event' that takes place every few weeks. So what I have done now is this: Save the HTML table once generated to a file When the URL is accessed check the saved file if it exists If the file is older than 1hr, run the query and save a new file, if not output the file This ensures that for the vast majority of requests the page loads very fast, and the data can at most be 1hr old. For my purpose this isn't too bad. What I would really like is to guarantee that if any data changes in the database, the cache file is deleted. This could be done by finding all scripts that do any change queries on the table and adding code to remove the cache file, but it's flimsy as all future changes need to also take care of this mechanism. Is there an elegant way to do this? I don't have anything but vanilla PHP and MySQL (recent versions) - I'd like to play with memcached, but I can't.
