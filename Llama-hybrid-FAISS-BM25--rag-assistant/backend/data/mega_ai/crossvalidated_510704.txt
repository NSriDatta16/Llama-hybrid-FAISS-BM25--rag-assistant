[site]: crossvalidated
[post_id]: 510704
[parent_id]: 
[tags]: 
Choosing the Dirichlet prior in a mixture model

Consider the following mixture model with $K components, $$ f\left(x \mid \theta_{1}, \ldots, \theta_{K}, \pi_{1}, \ldots, \pi_{K}\right)=\sum_{k=1}^K \pi_{k} \varphi\left(x \mid \theta_{k}\right) $$ Here $\theta$ represent probability vectors (the component densities are multinomial). I want to do Bayesian inference and estimation via Gibbs sampling. I use Dirichlet priors for both $\theta$ and $\pi$ , but want them as uninformative as possible. However, it seems that non-informative priors with mixture models should not be used (see e.g. page 2 here ). I also understand it applies to both $\omega$ and $\theta$ . What would be adequate choices for the concentration parameters $\alpha_1,\dots,\alpha_K$ of the Dirichlet distribution for $p(\theta)$ and $p(\omega)$ here? Initially I wanted to impose $\alpha_1=\cdots=\alpha_K=1$ on $p(\theta)$ (and similarly for $\theta$ ) but I am not sure anymore.
