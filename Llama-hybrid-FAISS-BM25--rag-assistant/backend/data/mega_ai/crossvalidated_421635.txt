[site]: crossvalidated
[post_id]: 421635
[parent_id]: 421479
[tags]: 
In linear regression, we can speak about the change in the conditional mean of one variable due to a change in the other variable. That's the closest thing to "causality" we get. (It has the rather amusing consequence that a change in either variable's $z$ -score is associated with a smaller mean change in the other variable's $z$ -score, which, like the twin paradox, is explicable in terms of different variables-held-constant definitions of partial derivatives.) Logistic regression is just linear regression where one variable has been transformed, so we get $y=\sigma(Wx+b)$ instead of $y=Wx+b$ . Thus a change in $X$ "causes" a change in the conditional mean of $\Sigma:=\sigma^{-1}(Y)$ , and vice versa. But this can't be restated in terms of changes in $X$ and $\Bbb EY$ , because nonlinear transformations don't commute with expectations.
