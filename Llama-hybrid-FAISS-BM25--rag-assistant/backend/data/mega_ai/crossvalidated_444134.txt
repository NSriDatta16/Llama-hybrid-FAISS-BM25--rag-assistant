[site]: crossvalidated
[post_id]: 444134
[parent_id]: 
[tags]: 
Why has an attempt to account for seasonality in my data made my machine learning results ridiculous?

I am trying to use machine learning (using linear regression) to predict bandwidth use into the future. I have over 50,000 observations spread across 56 weeks (just over a years data), and I am currently using time (limited to the one year) and number of users (which is growing over time) as X values to predict the Y (bandwidth use). The predictions I received were relatively sensible, except that when I fed X values to predict a Y, and when I would increase the time values, predicted bandwidth would fall slightly (going against intuition and past granular data of my company). I thought this could be due to a seasonal effect (internet use falls in the summer as people go outside and rises again in the winter) so I added binary variables for seasons to my data to account for this (i.e. winter = 1 during December, January, February, spring = 1 during March etc). However once I incorporated these, my predictions became ridiculous; multiplying in various directions by factors of millions from what they should be (e.g. from 12Tb/s to -300000000Tb/s, or -900000000Tb/s). Without seasonality coefficients are: Customers: 0.97 Time: 0.043 With seasonality coefficients are: Customers: 9.7e-01 Time: 6.5e-02 Season binaries: all between -6.3e+10 to -7.3e+10 So I am asking, what could be causing this unintuitive result - why is the model somehow massively overestimating the effect of seasonality? Is the way I tried to incorporate seasonality wrong? am I using the wrong model (linear regression) and thus should I remove my seasonal binaries and change the model? Or is it some other issue? Also if it is impossible to account for seasonal effects with my data, is there some other way to get the time X variable to behave as expected? (Time is accounted for by incrementing each next week of data by a value of 1) Thank you in advance for any help EDIT: SOLVED - Issue was the dummy variable trap. Removing one of the seasonal binaries when feeding data fixed the issue
