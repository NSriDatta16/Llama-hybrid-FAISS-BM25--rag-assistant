[site]: crossvalidated
[post_id]: 452390
[parent_id]: 451419
[tags]: 
Your concerns about the ROUGE score are indeed correct. The hope that is the test data are large and diverse enough, the ROUGE score should on average get a reasonable number. There are several papers that study this problem in detail: Correlation between ROUGE and Human Evaluation of Extractive Meeting Summaries from 2008 shows that there is only a very mild correlation between human opinions on summary quality and ROUGE score when they used only human-written summaries. The correlation with human judgment is much better on machine-generated summaries as shows paper Better Summarization Evaluation with Word Embeddings for ROUGE from 2015. For comparison, the Spearman correlation with the human judgment of machine translation metrics is typically over 0.95 for English.
