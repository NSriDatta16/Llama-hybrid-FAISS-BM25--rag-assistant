[site]: crossvalidated
[post_id]: 568131
[parent_id]: 
[tags]: 
What is the difference between these two types of training?

Suppose that I want to detect if a picture contains a particular logo, for instance the following one. Since template matching would be slow and fail those scaled or resized ones, I decided to train a classifier and I have two ideas: Gather many pictures that contain the logo and many others that don't, and directly train a binary classification model. After gathering the training data in the first step, I combine the logo and every image in the two types of images. For example, I combine(using this online tool ) the logo with an image not containing the logo as follows: and keep the labels. I think they are two types of learning: In the first approach, the model pushes the embeddings/representations of the two kinds of pictures away in the space and hence if I try a different logo, the model would become dull; while in the second approach the model would learn to find the trick: If there exists a pattern somewhere in the picture which has the same shape/pattern as the left part of the picture(where the logo lies), the label should be one. I wonder if the difference is transductive learning vs inductive learning? If not, what is it? Any suggestions would be highly appreciated. Thanks in advance.
