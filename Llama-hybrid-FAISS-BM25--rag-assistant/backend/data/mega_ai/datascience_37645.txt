[site]: datascience
[post_id]: 37645
[parent_id]: 
[tags]: 
In natural language processing, why each feature requires an extra dimension?

I am reading Machine Learning by Example. I am trying to understand natural language processing. The book used Scikit-learn's fetch_20newsgroups data as an example. The book mentioned that the text data in the 20 newsgroups dataset that we downloaded from fetch_20newsgroups data is highly dimensional. I do not understand this statement. It is my understanding that dimension is used to describe axies that an array has. For example, import numpy as np np.random.seed(0) x1 = np.random.randint(10, size=6) print("x1",x1) # 1 dimensions np.random.seed(0) x2 = np.random.randint(10, size=(3,4)) print("x2",x2) # 2 dimensions np.random.seed(0) x3 = np.random.randint(10, size=(3,4,5)) print("x3",x3) #3 dimensions How does no. of axies relates to feature in NLP? Why one feature equals to one dimension? Please explain. Thanks. Below is the code from the book that used to download the data for your reference. from sklearn.datasets import fetch_20newsgroups groups = fetch_20newsgroups()
