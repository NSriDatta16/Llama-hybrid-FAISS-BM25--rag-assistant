[site]: crossvalidated
[post_id]: 459590
[parent_id]: 459501
[tags]: 
The requirement that sample sizes be a certain size to have statistical inference confidence stems from I think the emperical law. And that is as you take more random SAMPLES the average of the MEANS converge to the actual population mean. But I've heard in order to be valid a sample size of greater than 32 is required for all samples. But there are other methods used for small sample sizes. You have to use the correct inferential statistics. But I do not know how sample size converge when the sample sizes are effected. I would think you need more data and there might be some notion of conservation relating error and number of samples, and sample size. Edit after some simple algebra can see that if you have m samples of size n you should get same mean as one sample of size m n. Also it could be true for some random distribution that the error may oh increase its only when very large samples are taken that they have more likely hood of being inside the required intervals. So it seems it could depend actually on the distribution itself. But often you can't know that. Also usually we use sample statistics to infer population statistics, not individual means or cases. Because then it is simple the probability described by the unknown population and we can only guess. Even if were right you can only know something to accuracy the probability distribution alows. But in statistics when we talk about statistics like population mean, we actually can get to the desired accuracy. Also from data perspective using samples we can throw away the data and store sample means. But as for this question I think it is hard to say what this person actually means, it not simple and clear concrete statement. But if he is saying that smaller samples are more accurate, it could be plausible but if any statistics are of use then much larger samples would ultimately be best.
