[site]: crossvalidated
[post_id]: 588868
[parent_id]: 
[tags]: 
Fitting an autoregressive models not using the classical Maximum Likelihood Estimator?

I know for example, one could try the Recurrent Neural Networks approaches. But are there any other options to these? I don't know if the questions is rather absurd. I am thinking of models like either Decision Trees, Gaussian Processes, or any other Machine Learning alternatives. I am wondering if one could do something similar to $VAR(p)$ , Distributed lag models, or $ARIMA(p,d,q)$ using other techniques. Therefore being able to do the functional relationship $Y_{t} \sim f(X_{t-1}, X_{t-2}, Y_{t-1}, Y_{t-2})$ . On other note I would like to know if it is absolutely necessary that the assumptions of the "equidistance" are necessary for the $Y_{t}$ . E.g: there is a very specific behavior that happened and at that moment $Y_{t}, Y_{t-1}, Y_{t-2}$ were studied, but only $Y_{t}$ will be used as response and the similar phenomena happened again n ( $n \in N $ , n can be random) minutes later. Would it be wrong to see it from an auto-regressive perspective? I ask it since if one thinks of the LSTM perspective, the input would be tensor([input_size, 2, 2]) , having 2 features and 2 timesteps. But I am not sure if during the optimization process there is an interaction of the $Y_{t}$ used as output.
