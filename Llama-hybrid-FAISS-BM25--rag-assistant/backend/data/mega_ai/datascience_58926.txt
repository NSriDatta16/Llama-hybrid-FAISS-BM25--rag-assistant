[site]: datascience
[post_id]: 58926
[parent_id]: 58901
[tags]: 
The cross-validation error is calculated using the training set only. Choosing the model that has the lowest cross-validation error is the most likely to be the best model for data that it hasn't yet seen. But it's not necessarily actually the best, so in that sense, strictly speaking, you can say the phrase is wrong. Even if your sample is a properly randomly drawn from the data generating process, it's still a finite sample. Imagine if the data is one-dimensional: Each example is just a number. The average of the training set could, by sheer bad luck, deviate a lot from the average of the data generating process. It's a simplistic example, but the best model on this data is not necessarily the best on any sample from this process.
