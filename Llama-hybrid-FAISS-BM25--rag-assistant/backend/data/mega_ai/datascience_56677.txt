[site]: datascience
[post_id]: 56677
[parent_id]: 56676
[tags]: 
Maybe , but note that this is one of those cases where machine learning is not the answer . There is a tendency to try and shoehorn machine learning into cases where really, bog standard rules-based solutions are faster, simpler and just generally the right choice :P Just because you can, doesn't mean you should Edit : I originally wrote this as "Yes, but note that..." but then started to doubt myself, having never seen it done. I tried it out this afternoon and it's certainly doable: import numpy as np from keras.models import Model from keras.layers import Input, Dense, Dropout from keras.utils import to_categorical from sklearn.model_selection import train_test_split from keras.callbacks import EarlyStopping # Create an input array of 50,000 samples of 20 random numbers each x = np.random.randint(0, 100, size=(50000, 20)) # And a one-hot encoded target denoting the index of the maximum of the inputs y = to_categorical(np.argmax(x, axis=1), num_classes=20) # Split into training and testing datasets x_train, x_test, y_train, y_test = train_test_split(x, y) # Build a network, probaly needlessly complicated since it needs a lot of dropout to # perform even reasonably well. i = Input(shape=(20, )) a = Dense(1024, activation='relu')(i) b = Dense(512, activation='relu')(a) ba = Dropout(0.3)(b) c = Dense(256, activation='relu')(ba) d = Dense(128, activation='relu')(c) o = Dense(20, activation='softmax')(d) model = Model(inputs=i, outputs=o) es = EarlyStopping(monitor='val_loss', patience=3) model.compile(optimizer='adam', loss='categorical_crossentropy') model.fit(x_train, y_train, epochs=15, batch_size=8, validation_data=[x_test, y_test], callbacks=[es]) print(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean()) Output is 0.74576, so it's correctly finding the max 74.5% of the time. I have no doubt that that could be improved, but as I say this is not a usecase I would recommend for ML. EDIT 2 : Actually I re-ran this this morning using sklearn's RandomForestClassifier and it performed significantly better: # instantiation of the arrays is identical rfc = RandomForestClassifier(n_estimators=1000, verbose=1) rfc.fit(x_train, y_train) yhat_proba = rfc.predict_proba(x_test) # We have some annoying transformations to do because this .predict_proba() call returns the data in a weird format of shape (20, 12500, 2). for i in range(len(yhat_proba)): yhat_proba[i] = yhat_proba[i][:, 1] pyhat = np.reshape(np.ravel(yhat_proba), (12500,20), order='F') print(np.where(np.argmax(pyhat, axis=1) == np.argmax(y_test, axis=1), 1, 0).mean()) And the score here is 94.4% of samples with the max correctly identified, which is pretty good indeed.
