[site]: crossvalidated
[post_id]: 48914
[parent_id]: 
[tags]: 
Measuring dispersion of tokens within a text file

I am working on a code analyzer application. It is essentially a piece of software that parses and interprets other programs' code and comes up with various metrics, findings, statistics, and ultimately draws performance warnings and re-engineering proposals. It is still in its infancy and what I am currently doing is parsing source code files for variable declaration, assignment, and references. That part works fine, I am able to accurately extract all variable occurrences, their positions and identify them in one of the three aforementioned categories. My next step is to identify and measure clustering of each variable within the code with the intent of identifying distinct functional areas that can be segregated into its own distinct programmatic block (i.e. a function but not necessarily). So it is kind of a simple attempt at machine learning . The data at my disposal consists of the file length and a hierarchical tree of variables, line numbers at which they occur, and how many times they occur on each line. E.g FOO->5 = 1 FOO->17 = 2 FOO->32 = 1 BAR->6 = 1 BAR->55 = 1 etc. meaning that FOO occurs on lines 5 and 32 once, 17 twice on line 2 (example of a red flag for code smell), BAR once on 6 and 55 each etc. What I want to do is measure dispersion of each variable but across the whole file. The fact it needs to be measured against the whole file is what made me think the simple standard deviation won't do because that measures only the dispersion of distributions within itself, i.e. there is another parameter involved. So if the source code file length is say 500 lines, and there are half a dozen variables scattered in the code block 125-200, with each variable appearing seldom or not at all outside that range, I want my metric to capture that and identify the code block 125-200 as a good candidate for separation into its own unit. Conversely, if a variable is uniformly scattered across the whole file and is kind of ubiquitous, I want to recognize that and designate it as a global variable. My question is: is there a standard statistical formula/measure that would represent the degree of dispersion of the distribution of occurrences across an area (in this case variables in a file), something like a value-added standard deviation?
