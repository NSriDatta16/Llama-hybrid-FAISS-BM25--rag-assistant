[site]: crossvalidated
[post_id]: 61261
[parent_id]: 61235
[tags]: 
This part primarily relates to your first, third and fourth question: There's a fundamental difference between Bayesian statistics and frequentist statistics. Frequentist statistics makes inference about which fixed parameter values are consistent with data viewed as random, usually via the likelihood. You take $\theta$ (some parameter or parameters) as fixed but unknown, and see which ones make the data more likely; it looks at the properties of sampling from some model given the parameters to make inference about where the parameters might be. (A Bayesian might say the frequentist approach is based on 'the frequencies of things that didn't happen') Bayesian statistics looks at the information on parameters in terms of a probability distribution on them, which is updated by data, via the likelihood. Parameters have distributions, so you look at $P(\theta|\underline{x})$. This results in things which often look similar but where the variables in one look "the wrong way around" viewed through the lens of the other way of thinking about it. So, fundamentally they're somewhat different things, and the fact that things that are on the LHS of one are on the RHS of the other is no accident. If you do some work with both, it soon becomes reasonably clear. The second question seems to me to relate simply to a typo. --- the statement "equivalent to the usual frequentist sampling distribution, that is" : I took this to mean that the authors were stating the frequentist sampling distribution. Have I read this wrongly? There's two things going on there - they've expressed something a bit loosely (people do this particular kind of over-loose expression all the time), and I think you're also interpreting it differently from the intent. What exactly does the expression they give mean, then ? Hopefully the discussion below will help clarify the intended sense. If you can provide a reference (pref. online as I don't have good library access) where this expression is derived I would be grateful. It follows right from here: http://en.wikipedia.org/wiki/Bayesian_linear_regression by taking flat priors on $\beta$ and I think a flat prior for $\sigma^2$ as well. The reason is that the posterior is thereby proportional to the likelihood and the intervals generated from the posteriors on the parameters match the frequentist confidence intervals for the parameters. You might find the first few pages here helpful as well.
