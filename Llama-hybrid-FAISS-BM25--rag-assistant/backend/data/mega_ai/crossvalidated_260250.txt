[site]: crossvalidated
[post_id]: 260250
[parent_id]: 259801
[tags]: 
Whenever you have high classification accuracy in spite of ignoring some classes, it means that you have class imbalance. Accuracy can be high while ignoring a minority class. Class imbalance is only a problem if you also have cost imbalance (ignoring very rare but very severe cases is unacceptable but ignoring very rare and yet benign cases is the rational thing to do). Random forests are a relatively complex model. They are only justified if they empirically outperform simpler models like the logistic regression. Perform a baseline comparison and renegotiate the requirements based on that evidence if necessary. I could help you better if you told me the reasoning behind each of the steps in your pipeline. Nevertheless, the following should apply: Be sure to use an adequate performance metric, not accuracy if you have imbalance. This metric could be macro averaged F measure which gives equal weight to each class or could be based on the different misclassification costs if they are known to you. Random forest can output probability estimates (based on the number of trees and the labels they give for a record and the confidence with which each tree gives it's label). You can use those probabilities to adjust the classification cutoff so that it conforms with your misclassification costs. This is easier to do in binary classification, so maybe you can think about first filtering the useless records out and then finding the most interesting records among the news records.
