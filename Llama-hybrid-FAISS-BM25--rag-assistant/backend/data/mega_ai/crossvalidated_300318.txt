[site]: crossvalidated
[post_id]: 300318
[parent_id]: 300254
[tags]: 
Yes a lot, the best way to notice this is by doing a kaggle competition. You will see that a lot of users use the same models (mostly gradient boosting and stacking) but feature engineering and selection is really what can make the difference between a top 5 percent leaderboard score and a top 20%. But you also have to check collinearity of your features, sometimes adding too much features that are correlated can decrease the accuracy of your model. Also you need fine tune your hyper parameters which can give you a significant boost in your model score. After all if your model didnt improve it is likely that the algorithm you used is not suitable for your kind of problem. If an algorithm is popular it doesn't mean that it is suitable for every kind of problem.
