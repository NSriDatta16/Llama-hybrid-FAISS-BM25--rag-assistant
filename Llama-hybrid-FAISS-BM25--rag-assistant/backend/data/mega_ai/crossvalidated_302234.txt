[site]: crossvalidated
[post_id]: 302234
[parent_id]: 302202
[tags]: 
Collinearities are not a problem in all regression techniques, you know... You may want to check out component-based options (e.g. principle component regression or PLS regression) where you can reduce your original independent data to a low rank estimation which can be used for a regression with your dependent data. EDIT: Supposing that you have covariation among your IVs you may get a better regression using a latent variable, which will have higher signal/noise ratio. Moreover, if you perform regression individually you risk losing out on potentially important information on more complex interaction patterns between IV. There may e.g. be systematic differences between something which is captured in one of your IVs, such as men/women disease severity score or number of employees in a company. If the overall variability in your IVs are expected to covary with your DV, then I would just go for a PC-regression. However, if you think that there is greater need to tease out the relevant contributions from the variables to your DV, then I would do a PLS regression. Anyway, when you make these kinds of regressions, make sure to combine modelling with proper validation (hard splits/external validation if you have enough samples, nested cross-validation otherwise. Single n-fold cross-validation as a last option.) When, later, you want to check the contributions from your variables to the regression model, you can examine the variable loadings in the PCA or PLS to draw some inference...
