[site]: crossvalidated
[post_id]: 460896
[parent_id]: 460779
[tags]: 
For choice of $k$ , see Choice of K in K-fold cross-validation Repeating: yes, I definitively recommend at least a few repetitions since this allows you to determine stability (e.g. as standard deviation of predictions for the same test case in different repetitions). If the variation there is negligible, your models are stable, and further repetitions would not change anything. If the variation is substantial, the [surrogate] models are unstable. More repetitions then give a better estimate of the average error of the surrogate models, but that does not necessarily help with estimating generalization error of the model trained on the whole data set since that is likely subject to almost the same instability. Calculating pooled error across residuals from folds and repetitions is not like an out-of-bag error: out-of-bag error would pool/average the predictions for the same case and then calculate one residual (average prediction - refererence) per case.
