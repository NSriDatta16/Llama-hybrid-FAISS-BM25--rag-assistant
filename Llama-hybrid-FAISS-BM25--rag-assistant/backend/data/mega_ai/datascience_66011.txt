[site]: datascience
[post_id]: 66011
[parent_id]: 
[tags]: 
How to vectorize the one hot encoding process?

Sorry for such a weird question - I do not even know if this makes sense, however I thought of this during my intro to Python course at uni and have wondered about it since. So I have some experience with Python for data science, but have never taken a structured course. I am in an intro class, and on the first day we were asked to count how many times a certain name appeared in a list. Obviously the answer I came up with was to initialize a variable to zero then iterate through the list and add one to itself whenever the i'th name in the list was equal to the target name. However, in Andrew Ng's deep learning courses, there is a heavy emphasis on vectorizing our calculations whenever possible. This got me wondering how I could vectorize this task. What I came up with, in an ideal scenario, is to create a vector where each the target name is replaced with 1, and the other names are replaced with 0. Then I could just take the sum of the vector and I would have my answer. The problem with this is the only way I know how to create said vector is to iterate through the original list, defeating the purpose this way of solving the problem. Anyways, while I understand that creating this vector is not exactly one hot encoding, is there any way to vectorize this process? Is one hot encoding done iteratively. If not, are there other examples where basic iterative tasks can be turned into tasks able to be processed in parallel? Sorry if this is a dumb question or does not make any sense - just something I was curious about as a noob to base Python.
