[site]: crossvalidated
[post_id]: 331242
[parent_id]: 331221
[tags]: 
@jbowman has the right answer: XGBoost is a particular implementation of GBM. GBM is an algorithm and you can find the details in Greedy Function Approximation: A Gradient Boosting Machine . XGBoost is an implementation of the GBM, you can configure in the GBM for what base learner to be used. It can be a tree, or stump or other models, even linear model. Here is an example of using a linear model as base learning in XGBoost. How does linear base learner works in boosting? And how does it works in the xgboost library?
