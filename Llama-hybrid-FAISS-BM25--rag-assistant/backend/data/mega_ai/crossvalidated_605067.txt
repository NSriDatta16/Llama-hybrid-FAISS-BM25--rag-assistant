[site]: crossvalidated
[post_id]: 605067
[parent_id]: 
[tags]: 
Classification output from a neural network vs SVM

I have a classification problem which i have run through both a neural network and an SVM. I am interested in the probabilities of all the different classifications rather than just assigning to correct class. The neural network is using a Softmax output and the output probabilities are never very confident. My NN outputs rarely go about 50% while the SVM predicts up to about 90% which is more in line with what i expect for this problem. The NN predictions go in the correct direction but because i am interested in the probabilities rather than just the classification they don't appear to be accurate. I would like to try and improve the NN A few ideas and thoughts i have tried Can i change the loss function cross entropy to decrease the loss in cases where the model is very long. I can't find any standard literature on this. Is softmax really a poor reflection of probability Is the NN underfitted? I don't believe so but are there easy ways to verify. Maybe the SVM is just better suited to this problem!
