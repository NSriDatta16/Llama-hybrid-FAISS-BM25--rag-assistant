[site]: datascience
[post_id]: 112823
[parent_id]: 
[tags]: 
What is the best machine learning technique to fuse two spatial data sets?

I have two data sets, containing points geometry ( X,Y ) and a recorded car exhaust parameter (let's say, RP value), of an area of interest (AOI). The datasets are spatially different, that is, the first data set is along side walk (X1, Y1, RP1) and the second data set (X2,Y2, RP2) is on the road center line (line split into equidistant 2 meters points). The distance between the data along the side walk and the one on road center line is varying, at some locations, it is 3 - 6 meters and at some locations it is > 6 meters (let say, 6 - 20 meters range). This is due to the fact that this distance reflects varying road widths, lengths in a realistic, complex city landscape. With the above data in hand, I want to fuse both data sets, considering the data along the side walk "more reliable" (thus higher weightage?), and compare the fused output with the reference data at limited locations in the AOI, to evaluate the data-fusion performance. What is the best machine learning/data science technique to achieve the above? I am open to exploring several (or the "best candidate") technique(s) in Python, R, Matlab, for example. The focus for me is on the data fusion technique. Ps. It is also possible to obtain information on road widths, lengths, building present or not, etc., if it is deemed "suitable" to include in the data processing.
