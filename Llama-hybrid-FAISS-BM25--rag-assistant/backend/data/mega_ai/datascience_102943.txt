[site]: datascience
[post_id]: 102943
[parent_id]: 102940
[tags]: 
tldr: not really, recall and precision are very similar to sensitivity and specificity. It's just a question of what you divide by what. Sensitivity and specificity are specifically binary classification metrics used to gauge how well a model is at predicting true vs false values. sensitivity is the the percentage of true positives vs all positives, and specificity is the percentage of true negatives vs all negatives. In other words, sensitivity is a measure of how well your do well on one set, and specificity is a measure of how well you do on the other set. That's all well and good for, say, diagnosing an illness, but the concept of "true" and "false" is less relevant in document retrieval. it appears precision and recall are domain specific manifestations of sensitivity and specificity; while the math is very similar, the way the ratios are calculated is slightly different, and its implications are slightly different. While sensitivity and specificity focuses on understanding how well true and false sets are predicted, precision and recall are only focused on describing the performance of true (i.e. relvent) documents. image of precision vs recall image of sensitivity vs specificity in terms of your question, given a query there are only two options: a document can be relevant or it can not. You can compute the precision and recall over various sub classes in your test set, or you can compute it over the entire test set. but I see no logical way to compute memory and recall in a purely multiclassification manner.
