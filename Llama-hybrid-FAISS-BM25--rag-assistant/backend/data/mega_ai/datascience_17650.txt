[site]: datascience
[post_id]: 17650
[parent_id]: 
[tags]: 
Multiple Output Layers in Neural Networks in Deep Q Learning

I am trying to train a computer to play with LEGO bricks (simulated) using DQN. My input is an image with 4 color channels (RGB and depth) and the output of the neural network is the coordinates of the best position where the next brick should be put. Instead of having $m_x * m_y * m_z$ (where $m_k$ is the size of positions along the k axis) different outputs, I want to have 3 output layers, each of which returns the x, y or z coordinates of the best position, so I have only $m_x + m_y + m_z$ outputs. My idea is replacing the fully-connected output layer by three fully-connected output layers, but only have one reward value (labeled value) for three layers. Can I do this? Will the three layers returns different outputs if the reward is same?
