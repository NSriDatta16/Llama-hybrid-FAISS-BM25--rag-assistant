[site]: crossvalidated
[post_id]: 71789
[parent_id]: 71779
[tags]: 
Bagging, boosting, and random forests that have recursive partitioning as the estimator result in a prediction tool that is no longer a tree. That is why these methods have superior predictive accuracy when compared to a single (almost always arbitrary) tree. Recursive partitioning that incorporates cross-validation still results in a tree. In many cases, in order to make the tree cross-validate you have to make it so conservative that it is not competitive with other methods in terms of $R^2$.
