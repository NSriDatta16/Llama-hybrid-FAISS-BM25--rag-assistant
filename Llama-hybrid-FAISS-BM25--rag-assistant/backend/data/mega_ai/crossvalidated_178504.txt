[site]: crossvalidated
[post_id]: 178504
[parent_id]: 
[tags]: 
How to propagate uncertainty into the prediction of a neural network?

I have inputs $x_1\ldots x_n$ that have known $1\sigma$ uncertainties $\epsilon_1 \ldots \epsilon_n$. I am using them to predict outputs $y_1 \ldots y_m$ on a trained neural network. How can I obtain 1$\sigma$ uncertainties on my predictions? My idea is to randomly perturb each input $x_i$ with normal noise having mean 0 and standard deviation $\epsilon_i$ a large number of times (say, 10000), and then take the median and standard deviation of each prediction $y_i$. Does this work? I fear that this only takes into account the "random" error (from the measurements) and not the "systematic" error (from the network), i.e., each prediction inherently has some error to it that is not being considered in this approach. How can I properly obtain $1\sigma$ error bars on my predictions?
