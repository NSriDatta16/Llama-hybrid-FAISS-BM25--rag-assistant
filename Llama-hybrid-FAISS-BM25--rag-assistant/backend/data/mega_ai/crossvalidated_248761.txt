[site]: crossvalidated
[post_id]: 248761
[parent_id]: 247982
[tags]: 
In the simplest case, say $p(y|x,w)$ is a Gaussian distribution centered at $x$, $$p(y|x,w)=\frac{1}{Z}\exp(\langle w, F(x,y)\rangle)=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(y-x)^2}{2\sigma^2})$$ we can interpret the feature function as $F(x,y)=(y-x)^2$, the parameter $w$ is then $-1/2\sigma^2$. There's more than one way to construct the feature functions in this case, we can also let the feature function produce a vector $F(x,y)=(x^2, xy, y^2)$, then setting the parameter $w=(-1/2\sigma^2, 1/\sigma^2, -1/2\sigma^2)$ will give the same result. In the case that $y$ is a categorical variable, consider the logistic regression, $$p(y_k|x,w)=\frac{1}{Z}\exp(\langle w, F(x,y_k)\rangle)=\frac{1}{\sum\exp(w_i\phi)}\exp(w_k\phi)$$ the feature function $F(x,y_k)$ should return a N-dimensional vector with phi being the k-th element and 0 elsewhere so that $\langle w, F(x,y_k)\rangle=w_k\phi$.
