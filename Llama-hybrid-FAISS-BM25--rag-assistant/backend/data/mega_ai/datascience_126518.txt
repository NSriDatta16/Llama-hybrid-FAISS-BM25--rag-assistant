[site]: datascience
[post_id]: 126518
[parent_id]: 
[tags]: 
Designing a data science workflow for a small company

I work at a company with eight employees, and was recently hired as a data/business analyst. The company uses an in-house software to manage online retail sales. There is a huge amount of data available, and I need to design a workflow to capture sales data and business analytics. Currently, most of the company’s data is stored in a combination of a MySQL database and DynamoDB. I would like to design a workflow that queries one or both of these databases to record daily statistics, i.e. sales of groups of products over time, cleans the data, and records it in a new “analytics” database. This new data would then be easier to handle for visualization, modeling, etc. Currently I’m taking a course in AWS Lambda, because it seems like that’s the best way to go to automate my scripts. I’m looking into relational database and NoSQL models, and am leaning towards the latter but I’m unsure. Does anyone have advice on this workflow, ideas on where to start, or resources to consult? This is my first job in the field, so I really appreciate any advice! Tl;dr - I am designing a workflow to query a MySQL database > clean data > record statistics in a new “analytics” database > use cleaned data for visualization
