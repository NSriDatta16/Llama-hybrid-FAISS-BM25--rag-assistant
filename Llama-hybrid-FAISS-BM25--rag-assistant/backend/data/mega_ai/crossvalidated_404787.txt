[site]: crossvalidated
[post_id]: 404787
[parent_id]: 403899
[tags]: 
The trouble is in the case of phoneme segmentation, we often assume that speech is pre-annotated so we may easily extract phonemes to train our HMMs In common speech recognition system segmentation is not really needed. K-means initialization as well as random initialization work well enough. Same in "AMADEUS: A SCALABLE HMM-BASED AUDIO INFORMATION RETRIEVAL SYSTEM" , they use k-means initialization and not segment times. Overall, this straightforward HMM approach is not really meaningful, it was used in speaker segmentation some time ago, but not used anymore. It is better to look on speaker segmentation effort, agglomerative clustering or i-vectors instead of this plain row HMM. Something like LEARNING TO SEGMENT SONGS WITH ORDINAL LINEAR DISCRIMINANT ANALYSIS . Recent work on this from Google is Fully Supervised Speaker Diarization .
