[site]: crossvalidated
[post_id]: 5408
[parent_id]: 4360
[tags]: 
A subjectivist Bayesian argument is practically the only way (from a statistical standpoint) you could go about understanding your intuition , which is--properly speaking--the subject of a psychological investigation, not a statistical one. However, it is patently unfair--and therefore invalid--to use a Bayesian approach to argue that an investigator faked the data. The logic of this is perfectly circular: it comes down to saying "based on my prior beliefs about the outcome, I find your result incredible, and therefore you must have cheated." Such an illogical self-serving argument obviously wouldn't stand up in a courtroom or in a peer review process. Instead, we could take a tip from Ronald Fisher's critique of Mendel's experiments and conduct a formal hypothesis test. Of course it's invalid to test a post hoc hypothesis based on the outcome. But experiments have to be replicated to be believed: that's a tenet of the scientific method. So, having seen one result we think might have been faked, we can formulate an appropriate hypothesis to test future (or additional) results. In this case the critical region would comprise a set of results extremely close to the expectation. For instance, a test at the $\alpha$ = 5% level would view any result between 9,996 and 10,004 as suspect, because (a) this collection is close to our hypothesized "faked" results and (b) under the null hypothesis of no faking (innocent until proven guilty in court!), a result in this range has only a 5% (actually 5.07426%) chance of occurring. Furthermore, we can put this seemingly ad hoc approach in a chi-square context (a la Fisher) simply by squaring the deviation between the observed proportion and the expected proportion, then invoking the Neyman-Pearson lemma in a one-tailed test at the low tail and applying the Normal approximation to the Binomial distribution . Although such a test cannot prove fakery, it can be applied to future reports from that experimenter to assess the credibility of their claims, without making untoward and unsupportable assumptions based on your intuition alone. This is much more fair and rigorous than invoking a Bayesian argument to implicate someone who might be perfectly innocent and just happened to be so unlucky that they got a beautiful experimental result!
