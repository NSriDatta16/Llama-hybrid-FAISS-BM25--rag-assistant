[site]: crossvalidated
[post_id]: 436961
[parent_id]: 55072
[tags]: 
If the training dataset is reasonably balanced and has standardized features, I will take the SVM scores as the measure of confidence in belonging to the respective classes. The so-called calibration methods that convert the scores to probability-like quantities, such as Platt scaling, usually use monotone functions (like logistic function) to map the scores to probabilities. Hence, if you only want to compare the confidence levels of a learned SVM model in a particular test datapoint belonging to possible classes, you can just compare the score values (not their absolute values) given that the training dataset from which the model is learned is fairly balanced and does not have any unusual quirk.
