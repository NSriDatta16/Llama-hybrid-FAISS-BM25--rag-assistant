[site]: crossvalidated
[post_id]: 611921
[parent_id]: 
[tags]: 
Is there a schematic procedure of adding features to models?

I have a XGBoost model that consumes ~150 features for a classification problem. Recently, I have a set of ~30 candidate features. I tried to dump everything in the XGBoost with the same hyper parameters (somehow I did not get improvements when tuning the parameters). The performance looks worse than the original model. I wonder how I should proceed. Is there a schematic procedure to follow when adding new features to a model. Below are a few questions that I have. In general, I wonder why the model performance got worse and whether there is an off-the-shelf procedure to follow. One plausible explanation for the worse performance is that the quality of new features may be bad. Namely, the new features are not indicative enough for the model to predict a correct label. However, theoretically, XGBoost should be "smart" enough to learn that the new features are bad only pick the new features. Why is the model performance degraded in practice? Will correlation among old and new features affect model performance? And how shall we verify that? I checked pairwise Pearson correlation coefficient for linear correlation among features. But there might be nonlinear correlation as well. Should I check mutual information instead? How should I select the best subset of features to add? Is it just a trial-and-error process? What happens if my model is a neural network? Is there anything changed for the above questions?
