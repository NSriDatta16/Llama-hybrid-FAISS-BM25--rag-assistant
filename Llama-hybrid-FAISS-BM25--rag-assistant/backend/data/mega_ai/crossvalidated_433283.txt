[site]: crossvalidated
[post_id]: 433283
[parent_id]: 
[tags]: 
Gaussian Process regression on scikit-learn: good performance on testing data, bad performance on testing data

I wrote a Python script that uses scikit-learn to fit Gaussian Processes to some data. IN SHORT: the problem I am facing is that while the Gaussian Processses seem to learn very well the training dataset, the predictions for the testing dataset are off, and it seems to me there is a problem of normalization behind this. IN DETAIL: my training dataset is a set of 1500 time series. Each time series has 50 time components. The mapping learnt by the Gaussian Processes is between a set of three coordinates x,y,z (which represent the parameters of my model) and one time series. In other words, there is a 1:1 mapping between x,y,z and one time series, and the GPs learn this mapping. The idea is that, by giving to the trained GPs new coordinates, they should be able to give me the predicted time series associated to those coordinates. Here is my code: from __future__ import division import numpy as np from matplotlib import pyplot as plt from sklearn.gaussian_process import GaussianProcessRegressor from sklearn.gaussian_process.kernels import Matern coordinates_training = np.loadtxt(...) # read coordinates training x, y, z from file coordinates_testing = np.loadtxt(..) # read coordinates testing x, y, z from file # z-score of the coordinates for the training and testing data. # Note I am using the mean and std of the training dataset ALSO to normalize the testing dataset mean_coords_training = np.zeros(3) std_coords_training = np.zeros(3) for i in range(3): mean_coords_training[i] = coordinates_training[:, i].mean() std_coords_training[i] = coordinates_training[:, i].std() coordinates_training[:, i] = (coordinates_training[:, i] - mean_coords_training[i])/std_coords_training[i] coordinates_testing[:, i] = (coordinates_testing[:, i] - mean_coords_training[i])/std_coords_training[i] time_series_training = np.loadtxt(...)# reading time series of training data from file number_of_time_components = np.shape(time_series_training)[1] # 100 time components # z_score of the time series mean_time_series_training = np.zeros(number_of_time_components) std_time_series_training = np.zeros(number_of_time_components) for i in range(number_of_time_components): mean_time_series_training[i] = time_series_training[:, i].mean() std_time_series_training[i] = time_series_training[:, i].std() time_series_training[:, i] = (time_series_training[:, i] - mean_time_series_training[i])/std_time_series_training[i] time_series_testing = np.loadtxt(...)# reading test data from file # the number of time components is the same for training and testing dataset # z-score of testing data, again using mean and std of training data for i in range(number_of_time_components): time_series_testing[:, i] = (time_series_testing[:, i] - mean_time_series_training[i])/std_time_series_training[i] # GPs pred_time_series_training = np.zeros((np.shape(time_series_training))) pred_time_series_testing = np.zeros((np.shape(time_series_testing))) # Instantiate a Gaussian Process model kernel = 1.0 * Matern(nu=1.5) gp = GaussianProcessRegressor(kernel=kernel) for i in range(number_of_time_components): print("time component", i) # Fit to data using Maximum Likelihood Estimation of the parameters gp.fit(coordinates_training, time_series_training[:,i]) # Make the prediction on the meshed x-axis (ask for MSE as well) y_pred_train, sigma_train = gp.predict(coordinates_train, return_std=True) y_pred_test, sigma_test = gp.predict(coordinates_test, return_std=True) pred_time_series_training[:,i] = y_pred_train*std_time_series_training[i] + mean_time_series_training[i] pred_time_series_testing[:,i] = y_pred_test*std_time_series_training[i] + mean_time_series_training[i] # plot training fig, ax = plt.subplots(5, figsize=(10,20)) for i in range(5): ax[i].plot(time_series_training[100*i], color='blue', label='Original training') ax[i].plot(pred_time_series_training[100*i], color='black', label='GP predicted - training') # plot testing fig, ax = plt.subplots(5, figsize=(10,20)) for i in range(5): ax[i].plot(features_time_series_testing[100*i], color='blue', label='Original testing') ax[i].plot(pred_time_series_testing[100*i], color='black', label='GP predicted - testing') Here examples of performance on the training data. Here examples of performance on the testing data.
