[site]: datascience
[post_id]: 85063
[parent_id]: 85062
[tags]: 
Yes, you are right. As a result of the extraction of features , new feature representations are created. For example, SIFT and HARR are algorithms to extract the crucial features from the images and create feature representation. CNN does it automatically with the help of convolution layers. In an image, smooth area, edge, corners are considered features that may represent it best. The importance of the smooth area, edge, and corners (there are others too) are normally accepted in ascending order. In a simple CNN, if you can visualize the layers you can see that what it extracts from the image are mainly, corners and edge. It is also able to learn more complex features than we know (or defined). So, as you said, the convolution layers try to create a representation of features by extracting them. Then, this features representations (important information from the image) are used in the let's say prediction process.
