[site]: crossvalidated
[post_id]: 573463
[parent_id]: 
[tags]: 
Can autocorrelation impact joint probability?

This is probably a pretty stupid question... but assume I have two random variables, X1 and X2. I want to look at their dependency (joint probability) at some quantile q. Theoretically, in the independent case, I have: P(X1 > q | X2 > q) = 1 - F(X1) - F(X2) + F(X1)*F(X2) So, if q = 0.005, I have: P(X1 > 0.005 | X2 > 0.005) = 1 - 0.005 - 0.005 + (0.005*0.005) = 0.99 Do this for the entire range of q in [0, 1]. For the (fully) dependent case, I have: P(X1 > q | X2 > q) = 1 - F(X1) - F(X2) + min[F(X1), F(X2)] Thus, for q = 0.005: P(X1 > 0.005 | X2 > 0.005) = 1 - 0.005 - 0.005 + min[0.005, 0.005] = 0.995 This is simply the theoretical case of two fully independent or two fully dependent random variables both exceeding their qth quantile. I figured this would set theoretical bounds for conditional probability... Now, my question is: does the above break down when looking at historical data that may contain autocorrelation, may be non-stationary, etc? If X1 and X2 both have significant autocorrelation, can this theoretically push them above the "maximum bound" set by the fully dependent case? I am looking at two time series and their joint probability of exceeding q is sometimes higher than that of the "fully dependent" case. Please let me know if my question even makes sense.
