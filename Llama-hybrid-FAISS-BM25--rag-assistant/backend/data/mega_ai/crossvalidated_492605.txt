[site]: crossvalidated
[post_id]: 492605
[parent_id]: 129498
[tags]: 
This is an interesting question that has different answers according to the context. I agree with what have answered you before, so here I will focus more on the context. It is normal that you have been confused when looking for McNemar's test interpretation on the Internet. The main reason is that both the historical origin of the test (Genetics), as well as its common use in the medical and social science fields, make its interpretation difficult in the context of machine learning. Here I explain what I have learned so far. First of all, it is important to know that there are two different scenarios in the context of machine learning. The first one is that you are evaluating the quality of your model vs. the reference data (test data or possibly training data). The second scenario is when you are comparing two classification models (algorithms). In the first scenario you would normally look for the p-value of the test to be greater than 0.05. That is, do not reject the null hypothesis that assumes homogeneity of the proportion of misclassified cases for the two class labels. In your confusion matrix above, these proportions are calculated from cells AB and BA. A significant value here would indicate that your algorithm misclassifies one label more than another. In the second scenario you would probably look for the opposite. That is, that the p-value of the test is less than 0.05. This would indicate that the classifiers have different error rates. This is evidence that you can use in conjunction with other indicators such as individual model accuracy to conclude that one is better than another. On your second question, you may have already seen that the accuracy provided by the caret package has nothing to do with McNemar's test. This is because the accuracy measures other information from the confusion matrix (cells AA and BB). Finally, on the third question I agree with what Alexis suggested. In summary: what McNemar's theoretically calls marginal homogeneity is, in the first scenario, the homogeneity of the rate of misclassifying the two class labels. In the second scenario, it refers to the homogeneity of the error rates of the classifiers. I hope that these ideas will give you a better understanding of the results that caret provides.
