swers are updated incrementally. This approach, used by large e-commerce or media sites, has long been used in the Entrez portal of the National Center for Biotechnology Information (NCBI) to precompute similarities between the different items in its large datasets: biological sequences, 3-D protein structures, published-article abstracts, etc. Because "find similar" queries are asked so frequently, the NCBI uses highly parallel hardware to perform nightly recomputation. The recomputation is performed only for new entries in the datasets against each other and against existing entries: the similarity between two existing entries need not be recomputed. Examples of Lazy Learning Methods K-nearest neighbors, which is a special case of instance-based learning. Local regression. Lazy naive Bayes rules, which are extensively used in commercial spam detection software. Here, the spammers keep getting smarter and revising their spamming strategies, and therefore the learning rules must also be continually updated. References Further reading lazy: Lazy Learning for Local Regression, R package with reference manual "The Lazy Learning Package". Archived from the original on 16 February 2012. Webb G.I. (2011) Lazy Learning. In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning. Springer, Boston, MA David W. Aha: Lazy learning. Kluwer Academic Publishers, Norwell 1997, ISBN 0-7923-4584-3. Atkeson, Christopher G.; Moore, Andrew W.; Schaal, Stefan (1 February 1997). "Locally Weighted Learning for Control". Artificial Intelligence Review. 11 (1): 75–113. doi:10.1023/A:1006511328852. S2CID 3694612. Bontempi, Gianluca; Birattari, Mauro; Bersini, Hugues (1999). "Lazy Learning for Local Modeling and Control Design". International Journal of Control. 72 (7): 643–658. Bibcode:1999IJC....72..643B. doi:10.1080/002071799220830. Aha, David W.; Kibler, Dennis; Albert, Marc K. (1 January 1991). "Instance-based learning algorithms". Machine Learning. 6 (1): 37–66. doi:10.1007/BF00153759.