[site]: crossvalidated
[post_id]: 34939
[parent_id]: 
[tags]: 
k-fold cross-validation strategy for large data set in statistical learning

I'm trying to learn the Bayesian network structure from a very large data set, and the R package I used for learning can only handle a very small portion of the data set (~10%) at one time due to the computational limitations. The conventional k-fold cross-validation strategy uses k-1 subsets for training and 1 subset for testing. I want to know if I can use only one random subset for training and another random subset for testing? Is there any better solution?
