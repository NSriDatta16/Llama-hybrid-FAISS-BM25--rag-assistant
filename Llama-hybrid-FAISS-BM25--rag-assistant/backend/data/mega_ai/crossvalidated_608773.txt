[site]: crossvalidated
[post_id]: 608773
[parent_id]: 
[tags]: 
Recurrent neural networks vs. State space models

I'm trying to understand the differences between RNNs and State Space Models (SSMs). I know that SSMs can take on different definitions depending on who you ask, but here I define it as in Learning Latent Dynamics for Planning from Pixels . Although this paper is about a new method, they do compare the graphical models associated with RNNs vs. SSMs: Beneath this diagram they say: " Circles represent stochastic variables and squares deterministic variables. Solid lines denote the generative process and dashed lines the inference model". I understand that RNNs have deterministic states unlike SSMs (as they define them here). However, I often see RNNs visualized by an input/output diagram (unfolded RNN diagram) like so: Ignoring the actions $a_t$ and rewards $r_t$ (the paper is an RL paper), considering $x_t$ to be $o_t$ , and supposing that $y_t$ is a prediction for the next state $h_{t+1}$ , it seems as though the canonical diagram of an RNN is simply the "inference model" of a state space model where the states are deterministic. So can we say that the relationship between RNN and SSMs is that RNNs directly model the "inference model" $p(h_{t+1}|h_t, x_t)$ , while SSMs model the generative model (transition model + observation model) and then "do inference" by computing the necessary posteriors? note : I've been looking over these diagrams for a bit so the differing notation doesn't bother me. However, I'm not sure if it is very annoying as a viewer. If so, please comment and I will try and edit.
