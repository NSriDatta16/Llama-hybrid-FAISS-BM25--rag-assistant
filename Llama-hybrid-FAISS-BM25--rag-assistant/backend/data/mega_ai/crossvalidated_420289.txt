[site]: crossvalidated
[post_id]: 420289
[parent_id]: 
[tags]: 
Different terminologies for ground truth

It's general theory that a supervised learning approach can only get as good an accuracy as the quality of the ground truth. The ground truth is considered the best possible annotation. However, consider the following scenario: I have roughly annotated ground truth and I'm using a neural network to do some segmentation tasks. Then after training, I use the trained network to do prediction on the entire dataset. Then if there are any false positives that turn out to be actually true positives, then we refine the dataset. Can I call this active learning or would this be called bootstrapping or neither? I was told that what I'm calling "roughly annotated ground truth" isn't ground truth at all and I should be using a different terminology. What exactly should I call it if not ground truth?
