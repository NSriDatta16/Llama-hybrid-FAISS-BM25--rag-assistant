[site]: crossvalidated
[post_id]: 430475
[parent_id]: 
[tags]: 
Random forest [R]: why is my OOB RMSE so much smaller than test RMSE?

I'm doing the kaggle challenge on timetravel predictions where the task is to predict the duration (Y) of a uber trip given some information about the start and end coordinates and the time the trip was taken. I'm having trouble reconciling the OOB RMSE $(=485)$ from randomForest output and the test RMSE $(=3233)$ I computed on a test set. Theoretically I think these should be very similar? I did a lot of data cleaning but basically this is how I divided between training (80%, N = 116,000) and test(20%, N = 29,000): set.seed(20191007) trainingset_id = sample(nrow(traveltime_tree_scaled), floor(0.8*nrow(traveltime_tree_scaled))) trainingset_id[1:5] traveltime_tree_scaled_train I also winsortized the training set by capping dependent variable (Y) at its 99th percentile value traveltime_tree_scaled_train_w % dplyr::mutate(depvar = if_else(depvar > quantile(traveltime_tree_scaled_train$depvar, 0.99), quantile(traveltime_tree_scaled_train$depvar, 0.99), depvar)) Then I used random forest to do the prediction using some given variables and some variables that I built traindata = traveltime_tree_scaled_train_w testdata = traveltime_tree_scaled_test continuous_covariates_tree What's surprising is that the model outputs OOB RMSE of sqrt(outputrf$mse[length(outputrf$mse)]) [1] 460.9522 but my test RMSE calculation yielded a much larger number predicted_y I feel like I may be calculating the test RMSE wrong somehow but I check with the function MSE() and got the same number. I also calculated the Mean Absolute Error (MAE) and it is much more aligned with the OOB RMSE provided by random forest mae_rf I also got the same weird results with a Decision Tree where test RMSE = 3300.177 but MAE = 502.4888 . I think in general RMSE should be similar to MAE? What am I doing wrong here???
