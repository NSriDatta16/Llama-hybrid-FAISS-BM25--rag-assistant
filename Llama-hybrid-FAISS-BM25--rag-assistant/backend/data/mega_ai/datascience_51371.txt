[site]: datascience
[post_id]: 51371
[parent_id]: 
[tags]: 
Representing state in Q-Learning

I have a fairly simple game in which I wish to use Q-learning to train an agent, but I have some questions regarding state representation. I'm new to RL so bare with me: If you have a game where you and your enemy each have 3 players, each player has health and a location on a 10 x 10 grid. My understanding is that you would need to enumerate all possible states for this game in order to successfully implement Q-learning. How would this be done? If we forget about health for a second and we look at position alone, we have 6 players, each of which could be in any of the 100 locations so our state space for position alone would be 100^6. This seems like an exceptionally large matrix to be working with, and we haven'y even added a parameter for health. What am I missing? is this the point at which you look for alternative state representations? Some guidance or links to relevant articles would be greatly appreciated. Thanks!
