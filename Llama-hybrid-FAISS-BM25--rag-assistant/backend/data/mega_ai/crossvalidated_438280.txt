[site]: crossvalidated
[post_id]: 438280
[parent_id]: 
[tags]: 
Huge sample sizes, tests, and deviation of assumptions?

I am performing Wilcoxon test (but in theory it can be any) and sometimes my sample sizes are huge. Even a single outlier may cause an extremely low p value. I am not interested in small effects at all, my expected effects are huge. How can I moderate impact of outliers in huge samples? I expect no more than 5 percents of points to be outliers and I can easily downsample to half of the sample size - the power will be enough. Or, in another words, how can I detect only effects of large size? I am well aware of Bayesian ways, but here I need to get a p value in the end (I don't like it either, but that's what's expected from me). In particular situation I was also thinking about simply reflecting all the points around the median and compare these reflected samples (so big or small values will be "balanced" from another side), but it also looks strange. So, typically I compare 2 groups: one of size 10-1000, second is 100 times bigger. The distribution of groups is nothing special: reasonable variance, no guarantees on symmetry or family, equal in both groups if no outliers occur. If the groups are different, they are different by more than 4 SDs so it can be seen visually. However in the larger group there are "outliers". These outliers are relevant to experiment and don't occur due to technical error, however, I can not predict the outliers, I may just explain it after I observe it. So I dont have an informative way to get rid of them. The amount of outliers - I said it is 5 percents - but in most of the cases it is 1 or 2 per thousands of data points, but having such sample sizes, even a single outliers leads to pvalues of 10**-5 and lower. The simulation: pvals I added just 3 outliers which are 2SD from the mean - and you can see, even for Wilcoxon test, which is claimed to be more "robust" to outliers, it breaks. UPD: none of the strategies I suggested in the question worked. UPD2: that's the actual piece of data I am working with. It is microarray data and only God knows how it is distributed. The group for comparison is around 10 dots and is located slightly lower than the median of the depicted distribution (but visually - same cloud of dots). I am interested in visually noticeable difference. There are "outliers" in both directions, but what really kills the analysis - the extreme outliers on top. However I am not sure if it will become much better if I remove only extreme outliers ... Another UPD: I am thinking about this problem in a broader sense. I want to say that my null hypothesis is everything of small effect size. How can I do it using frequentist tests? Bayesian, having family of distributions - easily. Frequentists' way - have no idea.
