[site]: crossvalidated
[post_id]: 113695
[parent_id]: 
[tags]: 
Variation of binary responses between repeated measures

I am bit confused in terms of analyzing my data. I have done an experiment which involves testing of detection systems with controlled footage.The footage has been grouped based on scene properties (or factors). I have about 7 factors and each of the factors has different levels. For example, Distance factor (see below in the data example) has 3 levels (i.e. medium, close,and far), Contrast factor has 9 levels (i.e. 0.1 to 0.2, 0.2 to 0.3) and so on. The analysis of system performance is done based on events that have been correctly detected (e.g. in the table: Event No. 1, 2, 3 and so on). The obtained results have scores of 1 to the correctly detected events and 0 to the un-detected events. To estimate the consistency of experimental results, each event was repeated 10 times (e.g. event was put through the detection system 10 times). There are some small variations on the results between the repeated times - the event was not always detected or un-detected but for some events was varied (e.g. see data table SysA_Response column, which represents the proportion/average of detection for events 1, 2, 3 and so on). I want to find out the most influential scene features (factor levels) that affect the performance of the detection systems. I guess i need to do factorial analysis for binary data but my problem is that my data are now proportions (because of the repeated testing of the same event). Any help in terms even for a bit of direction will be appreciated! Many thanks, Ana
