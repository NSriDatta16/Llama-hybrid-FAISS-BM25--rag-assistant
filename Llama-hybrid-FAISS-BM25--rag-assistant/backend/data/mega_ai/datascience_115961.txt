[site]: datascience
[post_id]: 115961
[parent_id]: 
[tags]: 
Failed to convert a NumPy array to a Tensor (Unsupported object type float) in Python

I am trying to build a MLP with Keras and an error appears. I do not have experience with neural networks so it is difficult for me. When I run the code for the NN after some time it says: 'Failed to convert a NumPy array to a Tensor (Unsupported object type float) in Python' The code I have, including the preprocess of the dataset, is the following: import pandas as pd from tensorflow.keras.utils import get_file pd.set_option('display.max_columns', 6) pd.set_option('display.max_rows', 5) dfs = [] for i in range(1,5): path = './UNSW-NB15_{}.csv'# There are 4 input csv files dfs.append(pd.read_csv(path.format(i), header = None)) all_data = pd.concat(dfs).reset_index(drop=True) # Concat all to a single df # This csv file contains names of all the features df_col = pd.read_csv('./NUSW-NB15_features.csv', encoding='ISO-8859-1') # Making column names lower case, removing spaces df_col['Name'] = df_col['Name'].apply(lambda x: x.strip().replace(' ', '').lower()) # Renaming our dataframe with proper column names all_data.columns = df_col['Name'] # display 5 rows pd.set_option('display.max_columns', 48) pd.set_option('display.max_rows', 21) all_data all_data['attack_cat'] = all_data['attack_cat'].str.strip() all_data['attack_cat'] = all_data['attack_cat'].replace(['Backdoors'], 'Backdoor') all_data.groupby('attack_cat')['attack_cat'].count() all_data["attack_cat"] = all_data["attack_cat"].fillna('Normal') all_data.groupby('attack_cat')['attack_cat'].count() all_data.drop(all_data[all_data['is_ftp_login'] >= 2.0].index, inplace = True) all_data.drop(['srcip', 'sport', 'dstip', 'dsport'],axis=1, inplace=True) df = pd.concat([all_data,pd.get_dummies(all_data['proto'],prefix='proto')],axis=1) df.drop('proto',axis=1, inplace=True) df_2 = pd.concat([df,pd.get_dummies(df['state'],prefix='state')],axis=1) df_2.drop('state',axis=1, inplace=True) df_encoded = pd.concat([df_2,pd.get_dummies(df_2['service'],prefix='service')],axis=1) df_encoded.drop('service',axis=1, inplace=True) df_encoded['ct_flw_http_mthd'] = df_encoded['ct_flw_http_mthd'].fillna(0) df_encoded['is_ftp_login'] = df_encoded['is_ftp_login'].fillna(0) df = pd.DataFrame(df_encoded) temp_cols=df_encoded.columns.tolist() index=df.columns.get_loc("attack_cat") new_cols=temp_cols[0:index] + temp_cols[index+1:] + temp_cols[index:index+1] df=df_encoded[new_cols] df_encoded = df.drop('label', axis=1) x_columns = df_encoded.columns.drop('attack_cat') x = df_encoded[x_columns].values dummies = pd.get_dummies(df['attack_cat']) products = dummies.columns y = dummies.values import numpy as np import tensorflow.keras from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, Activation from sklearn.model_selection import train_test_split from tensorflow.keras.callbacks import EarlyStopping from sklearn import metrics x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.25, random_state=42) model = Sequential() model.add(Dense(10, input_dim= x.shape[1], activation= 'relu')) model.add(Dense(9, activation= 'relu')) model.add(Dense(9,activation= 'relu')) model.add(Dense(y_train.shape[1],activation= 'softmax', kernel_initializer='normal')) model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics= ['accuracy']) monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto', restore_best_weights=True) model.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor],verbose=2, epochs=1000) pred = model.predict(x_test) pred = np.argmax(pred,axis=1) y_compare = np.argmax(y_test,axis=1) score = metrics.accuracy_score(y_compare, pred) print("Accuracy score: {}".format(score)) The dataset i'm using is the UNSW-NB15 (2+ million inputs) The error appears after executing the last block of code (begins at import numpy as np) Thanks for any tip that you can give me to solve the problem. The error appearing after the update provided by Muhammad is the following: ValueError Traceback (most recent call last) Input In [13], in () 18 model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics= ['accuracy']) 19 monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, 20 verbose=1, mode='auto', restore_best_weights=True) ---> 22 model.fit(tf.cast(x_train,dtype=tf.float32),y_train,validation_data=(x_test,y_test), 23 callbacks=[monitor],verbose=2, epochs=1000) 26 pred = model.predict(x_test) 27 pred = np.argmax(pred,axis=1) File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\util\dispatch.py:206, in add_dispatch_support. .wrapper(*args, **kwargs) 204 """Call target, and fall back on dispatchers if there is a TypeError.""" 205 try: --> 206 return target(*args, **kwargs) 207 except (TypeError, ValueError): 208 # Note: convert_to_eager_tensor currently raises a ValueError, not a 209 # TypeError, when given unexpected types. So we need to catch both. 210 result = dispatch(wrapper, args, kwargs) File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\ops\math_ops.py:988, in cast(x, dtype, name) 982 x = ops.IndexedSlices(values_cast, x.indices, x.dense_shape) 983 else: 984 # TODO(josh11b): If x is not already a Tensor, we could return 985 # ops.convert_to_tensor(x, dtype=dtype, ...) here, but that 986 # allows some conversions that cast() can't do, e.g. casting numbers to 987 # strings. --> 988 x = ops.convert_to_tensor(x, name="x") 989 if x.dtype.base_dtype != base_type: 990 x = gen_math_ops.cast(x, base_type, name=name) File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\profiler\trace.py:163, in trace_wrapper. .inner_wrapper. .wrapped(*args, **kwargs) 161 with Trace(trace_name, **trace_kwargs): 162 return func(*args, **kwargs) --> 163 return func(*args, **kwargs) File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\framework\ops.py:1566, in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types) 1561 raise TypeError("convert_to_tensor did not convert to " 1562 "the preferred dtype: %s vs %s " % 1563 (ret.dtype.base_dtype, preferred_dtype.base_dtype)) 1565 if ret is None: -> 1566 ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) 1568 if ret is NotImplemented: 1569 continue File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\framework\tensor_conversion_registry.py:52, in _default_conversion_function(***failed resolving arguments***) 50 def _default_conversion_function(value, dtype, name, as_ref): 51 del as_ref # Unused. ---> 52 return constant_op.constant(value, dtype, name=name) File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\framework\constant_op.py:271, in constant(value, dtype, shape, name) 174 @tf_export("constant", v1=[]) 175 def constant(value, dtype=None, shape=None, name="Const"): 176 """Creates a constant tensor from a tensor-like object. 177 178 Note: All eager `tf.Tensor` values are immutable (in contrast to (...) 269 ValueError: if called on a symbolic tensor. 270 """ --> 271 return _constant_impl(value, dtype, shape, name, verify_shape=False, 272 allow_broadcast=True) File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\framework\constant_op.py:283, in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast) 281 with trace.Trace("tf.constant"): 282 return _constant_eager_impl(ctx, value, dtype, shape, verify_shape) --> 283 return _constant_eager_impl(ctx, value, dtype, shape, verify_shape) 285 g = ops.get_default_graph() 286 tensor_value = attr_value_pb2.AttrValue() File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\framework\constant_op.py:308, in _constant_eager_impl(ctx, value, dtype, shape, verify_shape) 306 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape): 307 """Creates a constant on the current device.""" --> 308 t = convert_to_eager_tensor(value, ctx, dtype) 309 if shape is None: 310 return t File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\framework\constant_op.py:106, in convert_to_eager_tensor(value, ctx, dtype) 104 dtype = dtypes.as_dtype(dtype).as_datatype_enum 105 ctx.ensure_initialized() --> 106 return ops.EagerTensor(value, ctx.device_name, dtype) ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float). Column types : df_encoded.info(verbose=True) Int64Index: 2539861 entries, 0 to 2540046 Data columns (total 205 columns): # Column Dtype --- ------ ----- 0 dur float64 1 sbytes int64 2 dbytes int64 3 sttl int64 4 dttl int64 5 sloss int64 6 dloss int64 7 sload float64 8 dload float64 9 spkts int64 10 dpkts int64 11 swin int64 12 dwin int64 13 stcpb int64 14 dtcpb int64 15 smeansz int64 16 dmeansz int64 17 trans_depth int64 18 res_bdy_len int64 19 sjit float64 20 djit float64 21 stime int64 22 ltime int64 23 sintpkt float64 24 dintpkt float64 25 tcprtt float64 26 synack float64 27 ackdat float64 28 is_sm_ips_ports int64 29 ct_state_ttl int64 30 ct_flw_http_mthd float64 31 is_ftp_login float64 32 ct_ftp_cmd object 33 ct_srv_src int64 34 ct_srv_dst int64 35 ct_dst_ltm int64 36 ct_src_ltm int64 37 ct_src_dport_ltm int64 38 ct_dst_sport_ltm int64 39 ct_dst_src_ltm int64 40 proto_3pc uint8 41 proto_a/n uint8 42 proto_aes-sp3-d uint8 43 proto_any uint8 44 proto_argus uint8 45 proto_aris uint8 46 proto_arp uint8 47 proto_ax.25 uint8 48 proto_bbn-rcc uint8 49 proto_bna uint8 50 proto_br-sat-mon uint8 51 proto_cbt uint8 52 proto_cftp uint8 53 proto_chaos uint8 54 proto_compaq-peer uint8 55 proto_cphb uint8 56 proto_cpnx uint8 57 proto_crtp uint8 58 proto_crudp uint8 59 proto_dcn uint8 60 proto_ddp uint8 61 proto_ddx uint8 62 proto_dgp uint8 63 proto_egp uint8 64 proto_eigrp uint8 65 proto_emcon uint8 66 proto_encap uint8 67 proto_esp uint8 68 proto_etherip uint8 69 proto_fc uint8 70 proto_fire uint8 71 proto_ggp uint8 72 proto_gmtp uint8 73 proto_gre uint8 74 proto_hmp uint8 75 proto_i-nlsp uint8 76 proto_iatp uint8 77 proto_ib uint8 78 proto_icmp uint8 79 proto_idpr uint8 80 proto_idpr-cmtp uint8 81 proto_idrp uint8 82 proto_ifmp uint8 83 proto_igmp uint8 84 proto_igp uint8 85 proto_il uint8 86 proto_ip uint8 87 proto_ipcomp uint8 88 proto_ipcv uint8 89 proto_ipip uint8 90 proto_iplt uint8 91 proto_ipnip uint8 92 proto_ippc uint8 93 proto_ipv6 uint8 94 proto_ipv6-frag uint8 95 proto_ipv6-no uint8 96 proto_ipv6-opts uint8 97 proto_ipv6-route uint8 98 proto_ipx-n-ip uint8 99 proto_irtp uint8 100 proto_isis uint8 101 proto_iso-ip uint8 102 proto_iso-tp4 uint8 103 proto_kryptolan uint8 104 proto_l2tp uint8 105 proto_larp uint8 106 proto_leaf-1 uint8 107 proto_leaf-2 uint8 108 proto_merit-inp uint8 109 proto_mfe-nsp uint8 110 proto_mhrp uint8 111 proto_micp uint8 112 proto_mobile uint8 113 proto_mtp uint8 114 proto_mux uint8 115 proto_narp uint8 116 proto_netblt uint8 117 proto_nsfnet-igp uint8 118 proto_nvp uint8 119 proto_ospf uint8 120 proto_pgm uint8 121 proto_pim uint8 122 proto_pipe uint8 123 proto_pnni uint8 124 proto_pri-enc uint8 125 proto_prm uint8 126 proto_ptp uint8 127 proto_pup uint8 128 proto_pvp uint8 129 proto_qnx uint8 130 proto_rdp uint8 131 proto_rsvp uint8 132 proto_rtp uint8 133 proto_rvd uint8 134 proto_sat-expak uint8 135 proto_sat-mon uint8 136 proto_sccopmce uint8 137 proto_scps uint8 138 proto_sctp uint8 139 proto_sdrp uint8 140 proto_secure-vmtp uint8 141 proto_sep uint8 142 proto_skip uint8 143 proto_sm uint8 144 proto_smp uint8 145 proto_snp uint8 146 proto_sprite-rpc uint8 147 proto_sps uint8 148 proto_srp uint8 149 proto_st2 uint8 150 proto_stp uint8 151 proto_sun-nd uint8 152 proto_swipe uint8 153 proto_tcf uint8 154 proto_tcp uint8 155 proto_tlsp uint8 156 proto_tp++ uint8 157 proto_trunk-1 uint8 158 proto_trunk-2 uint8 159 proto_ttp uint8 160 proto_udp uint8 161 proto_udt uint8 162 proto_unas uint8 163 proto_uti uint8 164 proto_vines uint8 165 proto_visa uint8 166 proto_vmtp uint8 167 proto_vrrp uint8 168 proto_wb-expak uint8 169 proto_wb-mon uint8 170 proto_wsn uint8 171 proto_xnet uint8 172 proto_xns-idp uint8 173 proto_xtp uint8 174 proto_zero uint8 175 state_ACC uint8 176 state_CLO uint8 177 state_CON uint8 178 state_ECO uint8 179 state_ECR uint8 180 state_FIN uint8 181 state_INT uint8 182 state_MAS uint8 183 state_PAR uint8 184 state_REQ uint8 185 state_RST uint8 186 state_TST uint8 187 state_TXD uint8 188 state_URH uint8 189 state_URN uint8 190 state_no uint8 191 service_- uint8 192 service_dhcp uint8 193 service_dns uint8 194 service_ftp uint8 195 service_ftp-data uint8 196 service_http uint8 197 service_irc uint8 198 service_pop3 uint8 199 service_radius uint8 200 service_smtp uint8 201 service_snmp uint8 202 service_ssh uint8 203 service_ssl uint8 204 attack_cat object dtypes: float64(12), int64(27), object(2), uint8(164) memory usage: 1.2+ GB New error after removing ct_ftp_cmd : TypeError Traceback (most recent call last) Input In [17], in () 8 from sklearn import metrics 10 x_cast = tf.cast(x,dtype=tf.float32) ---> 12 x_train, x_test, y_train, y_test = train_test_split( 13 x_cast, y, test_size=0.25, random_state=42) 16 model = Sequential() 17 model.add(Dense(10, input_dim= x.shape[1], activation= 'relu')) File ~\miniconda3\envs\pruebas\lib\site-packages\sklearn\model_selection\_split.py:2443, in train_test_split(test_size, train_size, random_state, shuffle, stratify, *arrays) 2439 cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state) 2441 train, test = next(cv.split(X=arrays[0], y=stratify)) -> 2443 return list( 2444 chain.from_iterable( 2445 (_safe_indexing(a, train), _safe_indexing(a, test)) for a in arrays 2446 ) 2447 ) File ~\miniconda3\envs\pruebas\lib\site-packages\sklearn\model_selection\_split.py:2445, in (.0) 2439 cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state) 2441 train, test = next(cv.split(X=arrays[0], y=stratify)) 2443 return list( 2444 chain.from_iterable( -> 2445 (_safe_indexing(a, train), _safe_indexing(a, test)) for a in arrays 2446 ) 2447 ) File ~\miniconda3\envs\pruebas\lib\site-packages\sklearn\utils\__init__.py:378, in _safe_indexing(X, indices, axis) 376 return _pandas_indexing(X, indices, indices_dtype, axis=axis) 377 elif hasattr(X, "shape"): --> 378 return _array_indexing(X, indices, indices_dtype, axis=axis) 379 else: 380 return _list_indexing(X, indices, indices_dtype) File ~\miniconda3\envs\pruebas\lib\site-packages\sklearn\utils\__init__.py:202, in _array_indexing(array, key, key_dtype, axis) 200 if isinstance(key, tuple): 201 key = list(key) --> 202 return array[key] if axis == 0 else array[:, key] File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\util\dispatch.py:206, in add_dispatch_support. .wrapper(*args, **kwargs) 204 """Call target, and fall back on dispatchers if there is a TypeError.""" 205 try: --> 206 return target(*args, **kwargs) 207 except (TypeError, ValueError): 208 # Note: convert_to_eager_tensor currently raises a ValueError, not a 209 # TypeError, when given unexpected types. So we need to catch both. 210 result = dispatch(wrapper, args, kwargs) File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\ops\array_ops.py:1014, in _slice_helper(tensor, slice_spec, var) 1012 new_axis_mask |= (1 1014 _check_index(s) 1015 begin.append(s) 1016 end.append(s + 1) File ~\miniconda3\envs\pruebas\lib\site-packages\tensorflow\python\ops\array_ops.py:888, in _check_index(idx) 883 dtype = getattr(idx, "dtype", None) 884 if (dtype is None or dtypes.as_dtype(dtype) not in _SUPPORTED_SLICE_DTYPES or 885 idx.shape and len(idx.shape) == 1): 886 # TODO(slebedev): IndexError seems more appropriate here, but it 887 # will break `_slice_helper` contract. --> 888 raise TypeError(_SLICE_TYPE_ERROR + ", got {!r}".format(idx)) TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([ 214948, 2349007, 452929, ..., 2356330, 2229084, 2219110]) ```
