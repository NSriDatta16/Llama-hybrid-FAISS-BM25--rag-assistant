[site]: crossvalidated
[post_id]: 368626
[parent_id]: 368569
[tags]: 
Bagging ( bootstrap aggregating ) is applicable to lots of other algorithms than random forests (of which it is an integral part.) It refers to a variance reduction technique based on randomly sampling from the data with replacement, running whatever estimation algorithm is being used on each sample, and then combining (usually averaging) the results. In a random forest, the estimation algorithm is a tree, so you will have one tree per "bag". In RankLib, there are several algorithms, each of which is run on each "bag". One of these algorithms is the MART algorithm (Multiple Additive Regression Trees), which is an implementation of the Gradient Boosting Machine algorithm. The MART algorithm will create many trees (hence "Multiple") on each bag, hence the need to specify the number of trees per bag. Random Forests itself is another algorithm in RankLib, and the number of trees per bag will be needed to tell the RF algorithm how many trees to build on each of the bagged data sets.
