[site]: crossvalidated
[post_id]: 506489
[parent_id]: 506474
[tags]: 
There are some ways to find/eliminate non-informative features, before performing PCA or other dimensionality reduction methods. 1- Remove highly correlated features: This can be done by calculating pair-correlation and removing one of the features that has high correlation (e.g. >0.95) with the other one. Sample code is here 2- Remove features with a lot of ZEROs : In this case, your threshold may be 1-5% so if a feature has less than 1% of non-zero values (more than 99% zeros), may not be informative. for col in df.columns: percent = 100*sum(df[col]>0)/df.shape[0] if percent 3- Remove features with constant values: This case is also covers method 2 (zeros). You calculate the variance for each column and remove features whose variance is lower than threshold, for instance var for col in df.columns: med = np.median(df[col]) percent = 100*sum(df[col]-med>0)/df.shape[0] if percent
