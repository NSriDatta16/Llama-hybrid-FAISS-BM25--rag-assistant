[site]: crossvalidated
[post_id]: 549722
[parent_id]: 549720
[tags]: 
With so few cases, train/test splits aren't helpful . You then lose power in training the model and precision in testing it. What you've done so far is fine. You could go on to estimate how well the model is likely to work for prediction by repeating the modeling on multiple bootstrap samples of the data and evaluating performance of those models on the full data set. That's an accepted way to evaluate the performance of your modeling process. One caution: "whether they'll return for a follow-up visit" might not be an all-or-none result. If you deliberately restricted consideration to returning during a fixed period of time like 1 year that could be OK, but in general you might also be interested in how soon they return and you might also want to take advantage of information from individuals who haven't yet been followed up for that fixed period of time. For those sorts of things you would need to use a survival model instead of logistic regression.
