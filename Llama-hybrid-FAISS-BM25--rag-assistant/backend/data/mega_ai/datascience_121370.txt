[site]: datascience
[post_id]: 121370
[parent_id]: 121364
[tags]: 
It depends on the task you want to perform. The goal here is to find a way to represent your image as a sequence of embedding vectors representing each patch of the image Once you have obtained an encoded representation of your input image, you can perform image classification adding a classification head (i.e a few linear layers, as shown in the picture). Here's an example image classification with ViT on Huggingface generate new sequences of images or text (e.g adding a GPT decoder which takes the sequence of hidden states and outputs a sequence of tokens for tasks like image captioning, visual question answering ...). Here's an example of image captioning on Huggingface . VQA is quite similar, only requiring to pass to the decoder a representation of the image and the question as text.
