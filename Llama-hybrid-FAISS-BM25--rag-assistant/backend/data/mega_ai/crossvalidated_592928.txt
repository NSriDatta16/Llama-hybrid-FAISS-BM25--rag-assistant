[site]: crossvalidated
[post_id]: 592928
[parent_id]: 592763
[tags]: 
I found a solution for the case where we have 2 repeated noisy observations. It is not hard to spot once you write out the joint probability, use it to write out the conditional probability table in terms of $\beta$ and $\alpha$ . We can show that $P(A\ne B) = 2 \alpha(1-\alpha)$ , then use the quadratic formula to solve for $\alpha$ , and then solve for $\beta$ in terms of $\alpha$ . Joint probability table: $Y=0$ $Y=1$ $P(A)$ $A=0$ $\alpha(1-\beta)$ $(1-\alpha)\beta$ $\alpha(1-\beta) + (1-\alpha)(\beta)$ $A=1$ $(1-\alpha)(1-\beta)$ $\alpha\beta$ $(1-\alpha)(1-\beta)+\alpha\beta$ $P(Y)$ $\alpha(1-\beta) + (1-\alpha)(1-\beta)$ $(1-\alpha)\beta +\alpha\beta$ 1 If you doubt that $P(A=1,Y=1)=\alpha\beta$ , consider $P(A=1,Y=1)=P(A=Y,A=1,Y=1)=P(A=Y,Y=1)=P(A=Y)P(Y=1)$ The last equality seems surprising since it says that $A=Y$ and $Y=1$ are independent. But they are since $P(A=Y)=\alpha$ no matter the value of $Y$ . Conditional probability table: $Y=0$ $Y=1$ $P(A=0|Y)$ $\frac{(1-\alpha)(1-\beta)}{\alpha(1-\beta)+(1-\alpha)(1-\beta)}$ $\frac{(1-\alpha)\beta}{(1-\alpha)\beta+\alpha\beta}$ $P(A=1|Y)$ $\frac{(1-\alpha)(1-\beta)}{\alpha(1-\beta)+(1-\alpha)(1-\beta)}$ $\frac{\alpha\beta}{(1-\alpha)\beta + \alpha\beta}$ Lemma 1: $P(A=1|Y=1)=\alpha$ ; $P(A=0|Y=1)=(1-\alpha)$ Simplifying $P(A=1|Y=1)$ from the conditional probability table, we have: $$\frac{\alpha\beta}{(1-\alpha)\beta + \alpha \beta} = \frac{\alpha\beta}{\beta}=\alpha$$ . Simplifying $P(A=0|Y=1)$ we have: $$\frac{(1-\alpha)\beta}{(1-\alpha)\beta+\alpha\beta}=\frac{1-\alpha}{\alpha+1-\alpha}=1-\alpha$$ Lemma 2: $P(A \ne B) = 2 \alpha(1-\alpha)$ Consider the case $P(A\ne B,Y=1)$ . The other is similar. $$P(A \ne B,Y=1) \\ = P(A\ne B|Y=1)P(Y=1) \\= P(Y=1)(P(A=1,B=0)|Y=1) + P(A=0,B=1|Y=1)) \\= P(Y=1)(P(A=1|Y=1)P(B=0|Y=1)+P(A=0|Y=1)P(B=1|Y=1)) \\ = \beta(\alpha(1-\alpha) + (1-\alpha)\alpha) = 2 \beta \alpha (1-\alpha)$$ since $A$ and $B$ are conditionally independent given Y. Clearly, $P(A\ne B,Y=0) = 2 (1-\beta) \alpha (1 - \alpha)$ . So we can write $$P(A \ne B) = 2 \alpha (1-\alpha)\beta + 2 \alpha (1-\alpha)(1-\beta) = 2\alpha(1-\alpha)(\beta + 1 - \beta) = 2\alpha(1-\alpha)$$ Use the quadratic formula to solve for $\alpha$ . $$2\alpha^2 - 2\alpha + P(A\ne B) = 0 $$ $$ \alpha = \frac{2 \pm \sqrt{4 - 8P(A \ne B)}}{4} $$ Finally use $\alpha$ to solve for $\beta$ Observe that $P(Y=1|A\ne B) = P(Y=1)$ . $$ P(Y=1|A\ne B) = \frac{P(A\ne B | Y=1)P(Y=1)}{P(A \ne B)}$$ $$P(A \ne B | Y=1) = P(A=1,B=0 | Y=1) + P(A=0,B=1|Y=1)$$ $$ = 2 P(A=1,B=0 | Y=1) = 2P(A=1|Y=1)P(B=0|Y=1) = 2P(A=1|Y=1)P(A=0|Y=1) = 2P(A=1|Y=1)(1-P(A=1|Y=1) = $$ $$ \frac{P(A=1,B=1) - \alpha ^2 + 2\alpha -1}{2\alpha - 1} = \beta $$ This is because $$P(A=1,B=1) = P(A=1,B=1,Y=1) + P(A = 1, B = 1, Y = 0)$$ Consider $P(A=1,B=1,Y=1)$ . $$P(A=1,B=1,Y=1)=P(A=1, B=1|Y=1)P(Y=1) = P(A=1|Y=1)P(B=1|Y=1)P(Y=1)=\alpha^2\beta$$ And similarly, $P(A=1,B=1,Y=0) = (1-\alpha)^2(1-\beta)$ . Therefore $$P(A=1,B=1) = \alpha^2\beta + (1-\alpha)^2(1-\beta) = \beta(\alpha ^ 2 -(1-\alpha)^2) + (1-\alpha)^2$$ And therefore $$\beta = \frac{P(A=1,B=1) - (1-\alpha)^2}{\alpha^2 - (1-\alpha)^2}$$ So it's clear that if we can estimate $P(A=1,B=1)$ and $P(A\ne B)$ we have an estimator of $P(Y)$ . The use of the quadratic formula deserves some attention. If $P (A \ne B) > 0.5$ then $\alpha$ is not real. This suggests that $P(A \ne B) by construction. Indeed, $P(A\ne B) > 0.5$ violates the conditional independence of $A$ and $B$ given $Y$ by requiring $A$ and $B$ to be anti-correlated. It is also possible that there are 2 real solutions for $\alpha$ . One will have $\alpha > 0.5$ the other will have $\alpha , but only one of these will give a valid solution for $\beta$ .
