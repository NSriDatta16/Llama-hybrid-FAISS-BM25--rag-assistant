[site]: crossvalidated
[post_id]: 442563
[parent_id]: 
[tags]: 
How to statistically compare machine learning "regression" models?

Let say that I want to compare the performance of XGBoost vs NN, or NN vs NN, or even the same NN at different epochs for a regression task. All algorithms are trained and evaluated on the exact same dataset. My thought is to compare the distribution of the residuals i.e.: set up a hypothesis test such tha $\mu_{xgb} > \mu_{nn}$ , or do a t-test,... Here is an example I was working on ... As you may see, both models are similar, both are non-normally distributed, but NN's have a larger variance. I did not know how to compare, so I selected a paired Wilcoxon Signed-rank test since it does not assume a normal distribution. As expected, p-value was really low that the median of XGBoost is less than the median of NN. I have no idea if this is kosher - but I could not find anything online. Also, I was very surprised of how biased both models are in regions with the most frequent data. In terms of linear regression models - both of them would be considered terrible models. I would think QQ-plots would be a better measure than i.e.: feature importance in the case of XGBoost, if we assume $$y = f(x, w) + \epsilon$$ where $x$ is the input and $w$ are weights in both models.
