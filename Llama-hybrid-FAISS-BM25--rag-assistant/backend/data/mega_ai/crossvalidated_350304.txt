[site]: crossvalidated
[post_id]: 350304
[parent_id]: 
[tags]: 
Using trees for conditioned linear regression

I want to explore using tree methods to condition a linear regression. Let's say the baseline regression is of the form $y = \beta x + \epsilon$. In addition, I have conditioning data, a vector $c \in \mathbb{R}^k$, for every observation $(x, y)$. I want to refine my regression model to be $y = \beta(c) x + \epsilon$. If I think of $\beta$ being piecewise-constant in tree-model like parition, then I want to partition the data based on the conditioner $c$ and then fit a different linear relationship in each partition. For example, for scalar conditioning data, my tree might look like: For observations $(x, c)$, $y = \beta_1 x + \epsilon$ if $c > T$, $y=\beta_2 x+ \epsilon$ else. Is there a well known statistical approach that I can use, especially one with an off-the-shelf method available in say the sklearn or xgboost packages? I have toyed with the idea of fitting the $\beta$s using xgboost by redefining a custom objective function, $\hat{y}_i = \beta_i x$ for the xgboost leaf prediction $\hat{y}_i$ and then minimizing $(\hat{y}_i - y_i)^2$ as usual. Is this meaningful?
