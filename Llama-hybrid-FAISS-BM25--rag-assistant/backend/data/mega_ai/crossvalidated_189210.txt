[site]: crossvalidated
[post_id]: 189210
[parent_id]: 189207
[tags]: 
Yes, multicollinearity definitely can affect variable importances in random forest models. Intuitively, it can be difficult to rank the relative importance of different variables if they have the same or similar underlying effect , which is implied by multicollinearity. That is- if we can access the underlying effect by measuring more than one variable, it's not easy to say which is causing the effect, or if they are mutual symptoms of a third effect. A discussion of this property of random forests (and of regression questions more generally) can be found in the following lecture notes, among other sources: http://www-bcf.usc.edu/~shihs/shih_randomforests.pdf One common way to adjust for this is in the variable selection stage- by selecting one of the multicollinear variables to keep while removing others. This comes, of course, with its own potential issues- by removing potentially partially unique effects.
