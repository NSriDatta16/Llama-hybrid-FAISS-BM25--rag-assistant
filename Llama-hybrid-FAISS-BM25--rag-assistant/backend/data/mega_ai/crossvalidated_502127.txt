[site]: crossvalidated
[post_id]: 502127
[parent_id]: 262519
[tags]: 
As @Carl said, MCMC and nested sampling are quite different. You can use MCMC inside nested sampling to find new points, but in this case it is running on the prior probability distribution and rejects samples where the likelihood is below the current likelihood threshold. So the basic steps are: obtain N live points by sampling directly from the prior identify lowest likelihood value of the live points Lmin, and remove it from the sample (dead point) replace that point by sampling from the prior, but do not accept points below Lmin (likelihood-restricted prior sampling, LRPS) go to 2. I skipped the steps keeping track of the volume shrinkage (the i-th volume is $\exp(-i/N)$ ) and assigning weights to the dead points (the i-th dead point has weight $V_i/N \times L_i$ ). The dead sample give (after normalisation) a weighted posterior distribution. The normalisation is the evidence/marginal likelihood. For the LRPS, you can use rejection sampling methods or MCMC-like step sampling methods. Examples of efficient rejection sampling methods are MultiNest and MLFriends ( animation here ). Examples of efficient step sampling methods include hit-and-run sampling, slice sampling and constrained Hamiltonian Monte Carlo.
