[site]: datascience
[post_id]: 15564
[parent_id]: 10429
[tags]: 
I am hesitant to think of features as bad features. However, there are features more or less useful relative to other features. In general pruning features are seen as a good best practice. Overfitting certainly is a real problem within machine learning. Usually a combination of creating too powerful of a model, not having enough data, and/or having too many features can create an undesirable outcome. Proper partitioning of a dataset can help to adjust the model parameters where warranted helping in a more generalizable model.
