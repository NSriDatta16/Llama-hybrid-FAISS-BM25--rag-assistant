[site]: crossvalidated
[post_id]: 70789
[parent_id]: 70775
[tags]: 
Axis-aligned separator (that is a single-feature threshold). Edit : I think the OP understood the answer but here is a bit more details for other readers as suggested in the comment: the current implementation of decision trees in scikit-learn (and hence ensembles of them like Random Forests) is implemented as a tree of binary decision nodes where each node compares one feature value of the sample to a threshold (learned by minimizing an impurity criterion such as GINI or entropy). The leaves of the trees output the majority class or the mean value of the target variable of the training samples that ended up in that leaf after following the path of binary decisions from the root of the tree. There exists more complex variants of Decision Trees that build decision nodes that consider more than one feature at once (for instance Oblique Trees) but they are currently not implemented in scikit-learn.
