mation needs of professional users as they explore in complex domains. Enterprise Track – Goal: to study search over the data of an organization to complete some task. Last ran on TREC 2008. Entity Track – Goal: to perform entity-related search on Web data. These search tasks (such as finding entities and properties of entities) address common information needs that are not that well modeled as ad hoc document search. Cross-Language Track – Goal: to investigate the ability of retrieval systems to find documents topically regardless of source language. After 1999, this track spun off into CLEF. FedWeb Track – Goal: to select best resources to forward a query to, and merge the results so that most relevant are on the top. Federated Web Search Track – Goal: to investigate techniques for the selection and combination of search results from a large number of real on-line web search services. Filtering Track – Goal: to binarily decide retrieval of new incoming documents given a stable information need. HARD Track – Goal: to achieve High Accuracy Retrieval from Documents by leveraging additional information about the searcher and/or the search context. Interactive Track – Goal: to study user interaction with text retrieval systems. Knowledge Base Acceleration (KBA) Track – Goal: to develop techniques to dramatically improve the efficiency of (human) knowledge base curators by having the system suggest modifications/extensions to the KB based on its monitoring of the data streams, created the KBA streamcorpus, organized by Diffeo. Legal Track – Goal: to develop search technology that meets the needs of lawyers to engage in effective discovery in digital document collections. LiveQA Track – Goal: to generate answers to real questions originating from real users via a live question stream, in real time. Medical Records Track – Goal: to explore methods for searching unstructured information found in patient medical records. Microblog Track – Goal: to examine the nature of real-time information needs and their satisfaction in the context of microblogging environments such as Twitter. Natural language processing Track – Goal: to examine how specific tools developed by computational linguists might improve retrieval. Novelty Track – Goal: to investigate systems' abilities to locate new (i.e., non-redundant) information. OpenSearch Track – Goal: to explore an evaluation paradigm for IR that involves real users of operational search engines. For first year of the track the task was ad hoc Academic Search. Question Answering Track – Goal: to achieve more information retrieval than just document retrieval by answering factoid, list and definition-style questions. Real-Time Summarization Track – Goal: to explore techniques for constructing real-time update summaries from social media streams in response to users' information needs. Robust Retrieval Track – Goal: to focus on individual topic effectiveness. Relevance Feedback Track – Goal: to further deep evaluation of relevance feedback processes. Session Track – Goal: to develop methods for measuring multiple-query sessions where information needs drift or get more or less specific over the session. Spam Track – Goal: to provide a standard evaluation of current and proposed spam filtering approaches. Tasks Track – Goal: to test whether systems can induce the possible tasks users might be trying to accomplish given a query. Temporal Summarization Track – Goal: to develop systems that allow users to efficiently monitor the information associated with an event over time. Terabyte Track – Goal: to investigate whether/how the IR community can scale traditional IR test-collection-based evaluation to significantly large collections. Total Recall Track – Goal: to evaluate methods to achieve very high recall, including methods that include a human assessor in the loop. Video Track – Goal: to research in automatic segmentation, indexing, and content-based retrieval of digital video. In 2003, this track be