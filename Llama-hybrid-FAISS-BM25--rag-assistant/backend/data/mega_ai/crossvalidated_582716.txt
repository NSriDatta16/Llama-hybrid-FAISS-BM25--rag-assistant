[site]: crossvalidated
[post_id]: 582716
[parent_id]: 517173
[tags]: 
(Thanks for the reminder! The answer has been revised to focus more on the originally posted question) I think the paper by Zhou, as recommended above by @Björn, specifically discussed about Bayesian inference after multiple imputation. Recently, I am also applying Bayesian conditional logistic regression after multiple imputation (m = 100) in my PhD project. I mixed the MCMC draws from each imputed dataset, and used them to approximate posterior distribution and calculate point estimate and credible interval. I also combined the MCMC draws within each imputed dataset and plotted the posterior distribution across all the datasets in the same graph, as a way to present the variation in posterior approximation across imputed datasets. @Björn suggested above that treating chains from imputed datasets as separate chains and combine them across datasets. It seems reasonable but also I am a bit unsure. I am wondering if there is any reference supporting this. With this in doubt, as for checking MCMC sampling quality, I checked only for the first imputed dataset (or you could check any other one or multiple datasets) – calculating Rhat and effective sample size, and plotting a trace plot (and there are many other useful metrics and plots). Sorry I am new to the forum so I couldn't reply directly above to @Björn's response.
