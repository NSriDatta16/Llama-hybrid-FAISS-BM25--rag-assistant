[site]: crossvalidated
[post_id]: 112473
[parent_id]: 112414
[tags]: 
You will find answers to your questions if you follow references from the book you quoted. In that book of Wilcox, (second edition Springer) the literature references are on page 167. I will follow with some information from Staudte, Robert G.,Sheather, Simon J.: "Robust Estimation and Testing" (Wiley, 1990) which is maybe the most accessible of the sources cited there. First, the modern techniques referred to by "A major theoretical advance during the 1960s was the derivation of a mathematical technique that leads to a convenient and practical method for estimating the variance of the sample trimmed mean. " is the influence function invented by Hampel. To define this we first needs to introduce some other concepts. Lets assume we have a population characterized by some real-valued measurement. So for each individual (member) of that population, we have a real-valued random variable $X$ with cumulative distribution function $F(x)=P(X \le x)$. This distribution function $F$ characterizes the population, and we are interested in describing some aspects of $F$. This description can be taken as a functional defined on distribution functions $F$, that is, a rule that to each possible distribution functions assigns a description of the population. Lets assume for now that the functional, called $T$, is real-valued, so that to each distribution function $F$ we assign a real number $T(F)$. This is discussed in the cited text around page 14 "Descriptive measures". A few examples: The expectation $\mu(F)=T(F)= \int x \; dF(x) $ where the integral is a Lebesgue-Stieltjes integral, which in the case of an (absolutely) continuous random variable reduces to the integral with respect to the density $f(x)=F'(x)$ (where ' denotes the usual derivative) $\mu(F)=\int f(x) \; dx$ and in the discrete case reduces to summation. The median $m(F) = F^{-1}(1/2)$ The qth quatile $T_q(F) = F^{-1}(q)$ Then we get estimators (on "functional form") by applying the descriptor functional $T$ to the empirical distribution function $$ \hat{F}_n(x) = \frac{\text{number of observations $X_i \le x$ }}{n} $$ Some examples: The arithmetic mean is given by $\mu(\hat{F}_n)=\int x \; d\hat{F}_n(x)=\frac1{n}\sum_{i=1}^n X_i$ The empirical median is given by $m(\hat{F}_n)= \hat{F}_n^{-1}(1/2) More examples in the referenced source! Now we want to describe how the functional $T$ is influenced by some "contamination" of the sample. The idea is that with some smallish probability $\epsilon \gt 0$, we sample the value $x$ in place of a sample from the correct distribution function $F$. Describe the distribution function of the contamination with $\Delta_x$, which is a unit step at $x$. Then the combined distribution function is $(1-\epsilon)F+\epsilon \Delta_x$ wbhich we denote by $F_{\epsilon, x}$. ?How much is this functional $T$ influenced by the contamination? We calculate the difference $$ T(F_{\epsilon,x}) - T(F) $$ Then we divide this difference with $\epsilon$, and take the limit when $\epsilon \downarrow 0$. This gives a kind of derivative, in fact a directional derivative of $T$ at $F$ in the direction given by $F_{\epsilon,x}-F$. Around page 59 in the cited reference there are calculations of this, which is the influence function of $T$ at $F$, $x$, written $IF_{T,F}(x)$. We cite some examples: Influence function of the mean: $IF_{\mu}(x)=x-\mu$. Note that this influence function is unbounded, reflecting the fact that the mean can be arbitrarily much distorted by a single large outlier (at $x$). In comparison, the median have a bounded influence function. You can find it in the reference. Now, it is possible to do some series expansion in analogy to a Taylor expansion! This is ,finally, what makes it possible to find the (approximate) variance of the trimmed (or winsorized) mean by a technique superficially similar to what we can do for the usual arithmetic mean. But it is approximate, not exact, and for justification depends on heavy mathematics which I will not go into here. We can write (under assumptions...) $$ T(\hat{F}_n) = T(F) + \int (IF_{T,F}(x) \; d(F_n-F)(x) + R_n $$ We simplified the empirical distribution function to $F_n$. Here $R_n$ is a remainder term which in many cases satisfies that $\sqrt{n} R_n(x)$ converges in probabilitry to zero (with increasing sample size $n$). This leads to the approximation $$ \sqrt{n} (T(F_n)-T(F)) \approx \frac1{\sqrt{n}} \sum_{i=1}^n IF_{T,F}(X_i) $$ and we can use the central limit theorem as usual to get a normal limit with expectation $$ E_F IF_{T,F}(X) = 0 $$ and variance calculated likewise. This is the representation of Winsorised means as a mean of independent random variables that you ask for.
