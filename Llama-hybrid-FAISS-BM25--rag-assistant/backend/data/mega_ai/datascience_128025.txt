[site]: datascience
[post_id]: 128025
[parent_id]: 
[tags]: 
Why does precision decrease with inceasing threshold?

I've trained a Logistic Regression model using scikit-learns LogisticRegression class. I'm dealing with stock data so it's quite noisy and difficult to predict anything. When graphing threshold vs. precision I can see that there's some degree of correlation but it's quite jagged and ultimately falls off as the threshold surpasses a certain point. I'm wondering, Why is this the case? Any suggestions on how to increase prediction power - better suited model, an alternative metric to base prediction confidence off, better data preprocessing etc. Any input would be greatly appreciated.
