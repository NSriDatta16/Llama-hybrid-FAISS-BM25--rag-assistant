[site]: crossvalidated
[post_id]: 303889
[parent_id]: 303851
[tags]: 
The logistic regression model is defined as $$ \begin{align} \eta &= \boldsymbol{X}\beta \\ E(Y|\boldsymbol{X}) &= \mu = g^{-1}(\eta) \\ Y &\sim \mathcal{B}(\mu) \end{align} $$ where $\eta$ is the linear combination, $g^{-1}$ is the inverse of link function and $\mathcal{B}$ is the Bernoulli distribution that serves as a likelihood function. The "default" choice of link function for logistic regression is the logit function $$ g(z) = \frac{1}{1 + e^{-z}} $$ but in your example you are referring to another choice, the probit function . To estimate the $\beta$ parameters you need to maximize the likelihood function $$ \DeclareMathOperator*{\argmax}{arg\,max} \hat\beta = \argmax_\beta \;\mathcal{B}(g^{-1}(\boldsymbol{X}\beta)) $$ In real-life applications this is usually done using algorithms like iteratively reweighted least squares . However if you want to code the algorithm by-hand to understand how does logistic regression work, you probably should try something simpler like gradient descent, you can find worked example of implementing it in Andrew Ng's Machine Learning course on Coursera.org (it's free). To plot the predictions, you need to use the estimated parameters $\hat\beta$ and the values of $\boldsymbol{X}$ that you want to evaluate it on, next you just plug-in the values into the formula and get the predicted probabilities $\hat\mu$: $$ \hat\mu = g^{-1}(\boldsymbol{X}\beta) $$ If you want to get the predicted values of $Y$, then you would need to decide for a decision rule like "if $\hat\mu > \alpha$ then predict $1$ otherwise predict $0$" for some decision boundary $\alpha$. The "default" choice of $\alpha$ is usually $0.5$, but this does not to have to be the optimal choice.
