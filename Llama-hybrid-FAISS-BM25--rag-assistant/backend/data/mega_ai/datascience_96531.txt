[site]: datascience
[post_id]: 96531
[parent_id]: 96492
[tags]: 
My unconventional answer to your question is that you have stumbled upon something that is usual in machine learning even if it is not usually recognised as such. The fact is that models learn from the data they see and model those data and capture their structure as best as they can (sometimes they capture more structure than desirable or even existent, in other words they capture noise). They cannot learn from unseen data . If it happens that unseen data are simply variations of seen data, then all is (usually) well. Else performance on unseen data on average is not better than random. This is especially true as the models (and the data) get more complex (as are graph networks). A possible remedy is to avoid overfitting your networks so they may generalise better, but this means the training (and validation) performance will necessarily drop. Another remedy is to feed those unseen synthetically generated graphs into your network during training, although I don't think this will eventually address the issue. A third possible remedy is to alter the architecture of the network (eg add more layers, ..).
