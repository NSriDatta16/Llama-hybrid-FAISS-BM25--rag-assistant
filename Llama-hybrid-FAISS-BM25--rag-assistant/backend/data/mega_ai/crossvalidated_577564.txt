[site]: crossvalidated
[post_id]: 577564
[parent_id]: 577556
[tags]: 
Maximizing accuracy (percent of correctly examples) is the same as minimizing error rate (percent of incorrectly classified examples). For a single observation, the loss function for the error rate is always 1 (if the predicted class does not match the label) or 0 (if the predicted class matches the label). Accordingly, the derivative of this function is always 0 except at a negligible set of points where the derivative is infinite. This excludes any gradient-based optimizer from training a model, because the model parameters almost always have an update step size of 0, except for the countable number of times when the step size is infinite. Giving up gradient information is not a good trade, because gradient descent, Newton-Raphson and similar are very effective at finding solutions which also have high accuracies, even though accuracy was not optimized directly. Examples include neural-networks and logistic regression. Not all models are trained with gradient information. One prominent example is tree-induction methods such as random forest (however, not all trees are free of gradients; gradient-boosted trees use gradient information). These tree-based models search for good splits by optimizing some criterion, usually gini impurity, or information gain. While these models aren't optimized using gradient information, they also aren't optimized using accuracy. I suppose hypothetically you could use accuracy as a the split criterion.
