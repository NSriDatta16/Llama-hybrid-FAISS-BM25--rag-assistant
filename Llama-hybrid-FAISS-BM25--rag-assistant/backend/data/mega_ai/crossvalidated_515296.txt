[site]: crossvalidated
[post_id]: 515296
[parent_id]: 515283
[tags]: 
This is an interesting question. There would be a way, but what are you trying to accomplish? Imho this is a little bit nonsense in this specific context. Although we are able to compare e.g. apples with eggs, when standardizing predictors, it is no advantage to be able to compare significance if all are highly significant (it would be some enlightening if they vary in their level, but this depends on the sample size. we are still talking about standardized coefficients) Perhaps we can dig a little deeper: Futher, we also have some disadvantages, and it depends on the scenario, if we can compare anything. Do you want to test which of the predictors is even more significant than the other? If the answer is yes, that is not worth the effort showing in most cases, i dont think that even makes sense. However, if you are willed to look at the alternatives, than look at these approaches: Unstandardized predictors: 1.) Comparing different predictors in their strength (effect size) toward the outcome using unstandardized coefficients: telling us how many units we gain or loose when increasing the predictor by one unit, unstandardized coefficients have the advantage as they are comparable over different sample sizes ( KLINE 2011, p. 23, SINGH 1995, p. 599 f.) In other words, we exactly know, if we raise e.g. the price by one unit, we loose y sales of products, as customers are price sensitive. 2.) Comparing the same predictors in their strength (effect size) toward the outcome This subject gets a little bit more interesting as we also use unstandardized coefficients in the search of invariance . Although Invariance is mostly common to Structural Equation modeling, It is also usable in path analysis which is a smaller brother of SEM, but in its simplest form a multiple regression. Invariance means the search for difference in paths (or factor loadings) between two groups of samples. ( WIDAMAN / REISE 1997, p. 281 ff. and 297) Thus you can compare your predictors for example if a rise in price effects online shoppers customers more than offline shoppers. For this you would also use unstandardized coefficients. Standardized predictors: Do we have a technical correlation? When a user clicks on an ad, then fills out a form, then buys a product, a click, lead, sales chain should always be near perfect collinearity when looking at sums of research objects, with some minor deviation. OLBRICH/BORMANN/HUNDT 2019 (yes, self-promotion) Do our estimators differ in terms of different maximum likelihood estimators: https://users.ugent.be/~yrosseel/lavaan/utrecht2010.pdf slide 4 ff. It is possible to use ML estimators which can deal with non-normally distributed data, how these behave in terms of a normal ML estimator, when looking at your predictors? See also: OLBRICH/BORMANN/HUNDT 2019 Compare your calculated coefficients/predictor against an estimated coefficcient (a variation of the z-test) FAHRMEIR el al . 2007 and JEKEL 2007, p. 162 which leads to critical ratios and ultimately to the comparing of groups I already stated. Arbitrary/Varying/ML: In machine learning we can compare coefficients or predictors against each other in different terms: permutation importance (if we remove a feature from the model, how strong does the error of the model changes, was the feature relevant in terms of accuracy, this approach is model arbitrary, modela gnostic) feature importance (we compare coefficients against each other, but with the respective method, thus if you are using feature importance on a regression you are directly comparing coefficients, this appraoch obviosuly gives different results on the same data set depending on the method, because in logistic regression we would look ad log(odds)) feature vs permutation importance: https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html shap values: We look at the positive/negative contribution in relation to a target: that means we not only know which feature improves accuracy more than another, but we know how strong each feature contributes in a specific direction (ggole for shap library) Compare how your predictors add to supression effects in your model, a little bit off topic but worth noting. In summary: If all predictors are already statistically significant from each other, why bother about how high? Look how they contribute to your target outcome or compare them between groups, maybe you come to the conclusion to even drop a feature, so your model is still accurate but less complex. It seems that i shot with a canona ta bird here, but i believe this is something, which should be stated. Hope it helps. Sources: Singh 1995: Measurement Issues in Cross-National Research Widaman/Reise 1997: Exploring te Measurment Invariance of Psychological Instruments: Application in the Substance Use Domain, in BRYANT/WINDLE/WEST The science of prevention Methodological advances .... (and a lot more) pp. 281-324. Kline 2011, Principles and Practive of Structural Equation Modeling, in: Kenny/Little Methodology in the Social Sciences pp. 19-45. Olbrich, R./Bormann, P. M/Hundt, M. 2019: Analyzing the Click Path Of Affiliate-Marketing Campaigns: Interacting Effects of Affiliates’ Design Parameters With Merchants’ Search-Engine Advertising Fahrmeir et al. 2007: Statistics - The way to data analysis (german), However the quote is only similar to my statement Jekel 2007: Epidemiology, biostatistics, and preventive medicine
