[site]: datascience
[post_id]: 17480
[parent_id]: 
[tags]: 
conceptual question about triplet loss embeddings

A question on the paper Schroff, Kalenichenko and Philbin "FaceNet: A Unified Embedding for Face Recognition and Clustering", 2015. It is my understanding that the input to the CNN is a triplet (hence the name) of three pictures or thumbnails - one picture is the anchor, another one is a picture of the same person as the anchor picture, and the third one is a picture of a different person as the anchor. The output is one 128 to 256 embedding for the anchor picture, so that embeddings of pictures of the same person are closer to such output as are embeddings of pictures of different people. So the input for training, as I understood, is three pictures and careful selection of the embeddings is crucial. But what about testing? I thought the goal is to get the embedding of any one picture - or are three pictures (anchor, same person, different person) also necessary for testing?
