[site]: crossvalidated
[post_id]: 279078
[parent_id]: 278882
[tags]: 
No they can be useful, but it depends on your purpose. Several things spring to mind: Cost-Sensitive Classification: If your evaluation function overweights TPR and underweights FPR, we use $F_\beta$ score with $\beta \gg 1$ . (such as @hxd1011's answer on antifraud) Such a classifier can be really useful in an ensemble . We could have one classifier with normal weights, one that overweights TPR, one that overweights FNR. Then even simple rule-of-three voting, or averaging, will give better AUC than any single best classifier. If each model uses different hyperparameters (or subsampled training-sets, or model architectures), that buys the ensemble some immunity from overfitting. Similarly, for real-time anti-spam, anti-fraud or credit-scoring, it's ok and desirable to use a hierarchy of classifiers. The level-1 classifiers should evaluate really fast (ms) and it's ok to have a high FPR ; any mistakes they make will be caught by more accurate, fully-featured, slower higher-level classifiers or ultimately human reviewers. Obvious example: prevent fake-news headlines from Twitter account takeovers like the 2013 "White House bomb attack kills three" from affecting $billions of trading within ms of posting. It's ok for the level-1 classifier to flag that as positive for spam; let's allow it takes a little while to (automatically) determine the truth/falsehood of sensational-but-unverified news reports.
