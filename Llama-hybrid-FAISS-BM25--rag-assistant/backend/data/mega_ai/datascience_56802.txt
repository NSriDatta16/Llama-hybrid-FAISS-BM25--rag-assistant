[site]: datascience
[post_id]: 56802
[parent_id]: 
[tags]: 
Is RL applied to animal dispersion a valid approach?

I have an agent which has a medium-sized, discrete set of actions $A$ : $10 . The actions can be taken over an infinite horizon of 1 second per timestep $t$ . The world is essentially pictures from a static camera and the states $S$ are the amount of animals detected on the picture (assuming perfect detection for simplicity). We can safely say that $max(S) . Each action $a$ is meant to lower the amount of detections because of dispersion or fear from the animals. The reward is the difference of detections from $s_{-1}$ to $s$ . Admittedly I am only a beginner in RL, so I haven't seen much more than MDP's. I believe that this isn't a Markov problem since the states aren't independent (past actions having an impact on the outcome of the current action). That being said, I'm wondering if there's a specific RL algorithm for this setup or if RL even is the right way to go ?
