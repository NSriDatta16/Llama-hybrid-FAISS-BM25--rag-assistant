[site]: crossvalidated
[post_id]: 586302
[parent_id]: 
[tags]: 
Eckart–Young–Mirsky theorem for $n \gg m$

It has been proven that the best reconstruction error in the $k$ rank matrix estimation problem in terms of Frobenius or $L2$ norm is given by the $k$ -truncated SVD as shown here . I've read in multiple papers and e.g. here that PCA loses consistency for $A \in \mathbb R^{m \times n}$ as $n \gg m$ and alternatives have been proposed as in the link I've provided (Sparse PCA). Does that mean that the Eckart–Young–Mirsky theorem doesn't hold for $n \gg m$ or that the Frobenius or $L2$ norm don't capture this inconsistency and that e.g. sparse PCA has the same or worse norm but better consistency?
