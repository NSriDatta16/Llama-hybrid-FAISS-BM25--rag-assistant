[site]: datascience
[post_id]: 20084
[parent_id]: 
[tags]: 
Extractive text summarization, as a classification problem using deep networks

I understand that this is broad, but I merely require a few pointers. I wish to implement a text summarization system. I have already tried out an abstractive approach, now I am trying an extractive approach. The current extractive approaches out there(Textrank, Lexrank etc) are not giving optimal performance. It was suggested to me that I take it as an unsupervised learning task, using Autoencoders/RBM's or K means or any other unsupervised learning algorithm to classify sentences as important or not. My questions are: Is something like this feasible? (I know that nothing can be said for sure in data science unless tried out, but is it worth the shot?) What kind of features should I feed into the classifier? I already know of word frequency distribution(TF-IDF), sentence position, co-occurance stats, but will these be enough? What additional features should I consider? Or should I consider directly feeding in word vectors? I have done my bit of work on the same and have read several papers, but none of them offer clarity in terms of feature computation, but only explain network architecture. Any form of help will be appreciated, thank you!
