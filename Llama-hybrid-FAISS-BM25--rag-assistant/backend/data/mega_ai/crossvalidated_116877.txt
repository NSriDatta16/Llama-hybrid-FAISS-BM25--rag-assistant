[site]: crossvalidated
[post_id]: 116877
[parent_id]: 96829
[tags]: 
Nope. Nyquist is not blind. It requires an understanding of "the characteristic time" of the system. It then asserts that in order to make a Fourier approximation the sampling time needs to be an integer fraction of that characteristic time. the smallest nontrivial integer fraction is 1/2. In the real (non-theoretic) world, it is often very helpful to account for signal variation, to diagnose system changes, to account for uncertainties in the modeling and environment, to sample much more than the minimum integer subsample of 2. Useful and stable systems tend to sample at the "statistics magic sample numbers" of 5 or 30. That means there are either 5, or 30 measurements between "characteristic minimum" times for the assumed system. All of this presupposes that you know your characteristic time. Statisticians are "trust but verify" folks and this is one reason that they want to uniformly randomly sample a system. The minimum distance is not prescribed. They are not operating in integers multiples fixed steps, but reals. For the Metropolis-Hastings algorithm, it can take 20k or substantially more steps to get clean integration using that random sampling. The discipline around convergence that Bayesian method are going to speak to much more deeper fundamentals than Nyquist. They are going to look like "it depends" but .. it does depend. Nyquist depends too. In the investigation you are likely to find more of why it depends. Best of luck.
