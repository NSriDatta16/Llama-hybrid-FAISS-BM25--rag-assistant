[site]: crossvalidated
[post_id]: 413576
[parent_id]: 
[tags]: 
Bayesian estimation from sum of two random variables

Let's say I have a set of observations $Y=\{Y_1,\ldots,Y_N\}$ where each observation is created as the sum of two random variables, i.e. $Y_i=X_{1,i}+X_{2,i}$ . Also, I know that $X_1 \sim Dist_1(\theta_1)$ and $X_2\sim Dist_2(\theta_2)$ (e.g. $Dist_1(\theta_1)=Normal(\mu,\sigma^2)$ and $Dist_2(\theta_2)=Exponential(\lambda)$ ). Is there a way to estimate the parameters $\theta_1$ and $\theta_2$ based on the observations of only $Y$ ? 1) In order to estimate the parameters, I would need the likelihood function $L(\theta_1,\theta_2;Y)$ , which has to be derived from the individual likelihoods of $Dist_1$ and $Dist_2$ . If I can get an analytical formula for these distributions, I could, of course, use that to get the likelihood by convolution. But what if one of the likelihoods is more complicated. 2) Also, I could draw samples from one of the distribution, then subtract and use this to get the likelihood from the second distribution. But that would mean that I have to draw one additional sample for each $Y_i$ so the computational cost is increased. Is there a better way for this? EDIT : Some clarifications: I assume identifiability in the sense that if we let $Dist_3=Dist_1(\theta_1)+Dist_2(\theta_2)$ be the distribution of $Y$ then for any other pair $\tilde{\theta_1}$ and $\tilde{\theta_2}$ with $\tilde{\theta_1}\neq\theta_1$ and/or $\tilde{\theta_2}\neq\theta_2$ we have $Dist_3\neq Dist_1(\tilde{\theta_1})+Dist_2(\tilde{\theta_2)}$ . Thus, for example if $Dist_1$ and $Dist_2$ were bot normal distribution this would not be identifyable (one could simply set $\tilde{\theta_1}=\theta_2$ and $\tilde{\theta_2}=\theta_1$ ). Therefore, the example with a gaussian and a exponential would be identifyable, e.g. by fitting an ex-gaussian. My question is concerned more with a general how to implement something like this in a Bayesian sampler. The actual distributions I have are much more complicated (resulting from a cognitive model). The papers I looked at usually use numerical integration to calculate the convolution, but I would be grateful for a way to reduce the computational costs.
