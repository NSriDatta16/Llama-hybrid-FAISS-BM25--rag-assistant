[site]: crossvalidated
[post_id]: 532385
[parent_id]: 532384
[tags]: 
I don't agree. It may not make much difference if the values are small, but target variable directly affects the gradient size and can result in wild updates during back-propagation. Also, the behavior under regularization may dramatically change. It'll be harder to increase the weights to compensate for the increase in target variable. On the other hand, note that not all problems demand for mean/std standardization. The target variable might be a probability, and the output activation might be a sigmoid. The above paragraph is intended for general unconstrained regression problems.
