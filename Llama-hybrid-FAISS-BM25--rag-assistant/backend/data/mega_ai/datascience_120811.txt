[site]: datascience
[post_id]: 120811
[parent_id]: 
[tags]: 
Monte Carlo simulation of (potentially) correlated multiple time series

I am seeking help on how to perform Monte Carlo simulations on (potentially) correlated time series. I have a single product (e.g., men's wallets) that are sold out of seven stores in the same city. I have last year's daily sales of wallets for each store. Most days, a store sold zero, some days they sold one, fewer days they sold two... the histogram resembles an exponential distribution. I want to be able to use last year's sales, to simulate the potential combined sales of the seven stores. (Assume no sales growth year on year). I am wary of just sampling each store's daily sales independently and combining them into a new RV, as there may be some correlation, and some seasonality, of the sales. Ideally I'd be able to simulate a range of the combined sales for January 1, a range of the combined sales for January 2, .... a range of the combined sales for December 31; that takes into account potential correlation and seasonality of the sales. Bonus points if you can point me to some R functions that do this. It's important to note that I'm not looking to forecast a time series, but rather understand potential range of the 7 stores' sales in sum, based upon variability in the existing 7 stores' time series of sales.
