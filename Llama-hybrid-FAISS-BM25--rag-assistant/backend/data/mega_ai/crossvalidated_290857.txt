[site]: crossvalidated
[post_id]: 290857
[parent_id]: 243207
[tags]: 
I understand your question and frustration, but I am not sure this is something that could be computed analytically, rather you'd have to determine a good setting empirically for your data, as you do for most hyper parameters, using cross validation as @user2149631 suggested. I've had some success using SelectFPR with Xgboost and the sklearn API to lower the FPR for XGBoost via feature selection instead, then further tuning the scale_pos_weight between 0 and 1.0. O.9 seems to work well but as with anything, YMMV depending on your data. You can also weight each data point individually when sending it to XGboost if you look through their docs. You have to use their API not the sklearn wrapper. That way you can weight one set of data points much higher than the other, and it will impact the boosting algorithm it uses.
