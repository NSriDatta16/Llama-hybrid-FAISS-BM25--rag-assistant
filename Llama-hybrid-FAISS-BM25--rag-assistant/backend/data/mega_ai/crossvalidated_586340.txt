[site]: crossvalidated
[post_id]: 586340
[parent_id]: 
[tags]: 
Using PCA covariance for linear regression

$X$ be a random vector in $\mathbb{R}^p$ and $Y$ a random variable, both with mean zero. Let $\Sigma$ denote their joint covariance matrix: $$ \Sigma = \begin{pmatrix}\Sigma_X & \Sigma_{XY} \\ \Sigma_{YX} & \sigma_Y^2\end{pmatrix} $$ The conditional expectation is given by $$ \mathbb{E}[Y|X] = \Sigma_{YX} \Sigma_X^{-1} X$$ This coincides with ordinary least squares regression when $\Sigma$ is estimated as the sample covariance. Suppose that $\Sigma$ is estimated with some form of shrinkage. That should correspond to regularized linear regression. For example, suppose that $$ \Sigma = (1-\lambda) S + \lambda I $$ where $S$ is sample covariance. Then $$ \hat{\beta} = \left(S_{X} + \frac{\lambda}{1-\lambda}I \right)^{-1} S_{XY}$$ which corresponds to Ridge regression. My question is: what sort of regression do we get if we estimate $\Sigma$ by a low-rank plus scalar: $$ WW' + \sigma^2 I$$
