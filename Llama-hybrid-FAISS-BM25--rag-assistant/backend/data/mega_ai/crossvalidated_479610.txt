[site]: crossvalidated
[post_id]: 479610
[parent_id]: 478179
[tags]: 
The comment of @Dave helped and I went through some lecture. For the benefit of other readers, I am posting here the summary of findings. It is suggested that balancing the classes is not an optimal solution. Instead, I found three alternative ways out that various authors suggest: instead of Accuracy, Precision and Recall, proper scoring rules could be used. Most commonly used are: Brier score and logarithmic score: wikipedia use cost-sensitive learning, associating weights to classes either during or after training pick a classifier that is robust against imbalanced classes. Examples include xgboost, adaboost Those are possible alternatives for balancing the classes for training, which has this fundamental deficiency: the data presented to the trained algoritm is far from reality, so the trained algorithm may not have good result in real (unbalanced) environment.
