[site]: crossvalidated
[post_id]: 439432
[parent_id]: 
[tags]: 
How to update a keras LSTM weights to avoid Concept Drift

I´m trying to update a Keras LSTM to avoid the concept of drift. For that I´m following the approach proposed in this paper [1] on which they compute an anomaly score and they apply it to update the network weights. In the paper they use the L2 norm to compute the anomaly score and then they update the model weights. As it is stated in the paper: RNN Update: The anomaly score is then used to update the network W−1 to obtain W using backpropagation through time (BPTT): W = W−1 − ∇(W−1) where is the learning rate I’m trying to update the LSTM network weights, but although I have seen some improvements in the model performance for forecasting multi-step ahead multi-sensor data I’m not sure if the improvement is because the updates deal with the drift concept or just because the model is refitted with the newest data. Here is an example model: model = tf.keras.Sequential() model.add(tf.keras.layers.LSTM(n_neurons, input_shape=(n_seq, n_features))) model.add(layers.Dense(n_pred_seq * n_features)) model.add(layers.Reshape((n_pred_seq, n_features))) model.compile(optimizer='adam', loss='mse') And here is the way on which I’m updating the model: y_pred = model.predict_on_batch(x_batch) up_y = data_y[i,] a_score = sqrt(mean_squared_error(data_y[i,].flatten(), y_pred[0, :])) w = model.layers[0].get_weights() #Only get weights for LSTM layer for l in range(len(w)): w[l] = w[l] - (w[l]*0.001*a_score) #0.001=learning rate model.layers[0].set_weights(w) model.fit(x_batch, up_y, epochs=1, verbose=1) model.reset_states() I’m wondering if this is the correct way to update the LSTM neural network and how the BPTT is applied after updating the weights. P.D.: I have also seen other methods to detect concept drift such as the ADWIN method from the skmultiflow package but I found this one especially interesting because it also deals with anomalies, updating the model slightly when new data with concept drift comes and almost ignoring the updates when anomalous data comes. [1] Online Anomaly Detection with Concept Drift Adaptation using Recurrent Neural Networks Saurav, S., Malhotra, P., TV, V., Gugulothu, N., Vig, L., Agarwal, P., & Shroff, G. (2018, January). In Proceedings of the ACM India Joint International Conference on Data Science and Management of Data (pp. 78-87). ACM.
