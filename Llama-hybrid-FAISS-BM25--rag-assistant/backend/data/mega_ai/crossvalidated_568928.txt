[site]: crossvalidated
[post_id]: 568928
[parent_id]: 568897
[tags]: 
When the data aren't shuffled, the data are split into two parts along the first axis. Observing a large difference in performance between the shuffled and non-shuffled data indicates that something about how the data X, y are sorted is meaningful in some way. As an example, imagine that your data are sorted by one of the features, and this feature is important for prediction. Without information about that feature in the 25% of the data you've reserved for testing ( test_size=0.25 ), the model can't predict well for those values of the feature. In a comment, OP has clarified that the data are a time series (yearly data). So what's probably happened is that shuffling the data is letting the model use information from the future to predict the past, essentially giving the model precognition. To avoid optimistic bias, you should split the data so that you're always training the model on data from the past and evaluating it on data from the future. Cross-validation for timeseries data with regression Splitting Time Series Data into Train/Test/Validation Sets
