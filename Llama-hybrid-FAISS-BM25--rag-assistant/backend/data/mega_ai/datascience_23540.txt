[site]: datascience
[post_id]: 23540
[parent_id]: 
[tags]: 
Converting a regression problem into a classification problem

I have a regression problem where a neural network has to predict a value from $0$ to $19.999...$. I would like to convert this regression problem into a classification problem with the classes $0, 1, 2, ..., 18, 19$. Therefore I am using a $\mathrm{softmax}$-output layer. Now, if I use a categorical crossentropy-loss, the loss is the same if the network classifies an input as $1$ instead of $14$ and if the input is classified as $13$ instead of $14$. I like to punish the loss more if the predicted value / class is farther away from the true value / class. Is there a better loss function than categorical crossentropy for this use-case?
