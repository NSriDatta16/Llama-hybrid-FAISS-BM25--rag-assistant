[site]: datascience
[post_id]: 47813
[parent_id]: 43873
[tags]: 
Loading the data directly from the preprocessing script to the DW means not storing the results of your processing on storage. Not storing those results on storage may imply: Needing to do the processing again if for some reason the data is needed again, for a new DW or for a new research. Not saving the data as a data sink and so not contributing to a data lake architecture , where data sinks are just saved for future reusing on "unpredicted" situations. From a technical perspective, some tradeoffs are mentioned on the Google BigQuery docs on Streaming data , from which the following could be highlighted: Consistency management, as for errors or duplicates. Waiting time until data is available for copy and export operations Still, it would be great to have more comments about the technical perspective on when to use direct transfer and when to use a file for staging preprocessing results. Thanks
