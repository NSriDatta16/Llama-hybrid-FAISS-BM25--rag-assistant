[site]: crossvalidated
[post_id]: 205272
[parent_id]: 205137
[tags]: 
You'll need to train your model through metaheuristics such as simulated annealing (SA) or genetic algorithms (GA). With SA, you can perturb your weights (add Gaussian noise) after each episode. If the new weights perform better, keep them. Otherwise, there is a probability to keep them or to undo the last perturbation. You can see it in action here . In this case, I've used SA to learn a rule table, so it is not restricted to ANNs. The robot's "satisfaction" is how fast it walks. GA for fixed topology neural networks or other kind of models work similarly to SA, except that you'll work with many candidate solutions simultaneously and there is an additional "crossover" operation over your parameters besides the perturbation (which is called "mutation" here). This has been done, for instance, in Genetic Algorithm VS Air Man . In this case, the "satisfaction" is the difference between the player's and enemy's energy bar. But you can even learn the ANN topology with GAs, and one way of doing that is through the NEAT algorithm . This has been done, for instance, in MarI/O , which @Tim mentioned in his comment.
