[site]: datascience
[post_id]: 121556
[parent_id]: 121538
[tags]: 
Data leakage occurs in cases when you train a model with data that is not available for future testing/inference; or when you use same piece of data for training, and then for validation and/or testing. This short Kaggle article sums it up nicely. If you have a feature (e.g. target_year_x ) that somehow quantifies how much of the target goals are currently at year x achieved, I fear that this could introduce bias in your model, and may technically be data leakage. High values for that feature indicate that the project is close to meeting its goals, and is more likely to meet its target; thus the model would learn (the very obvious thing) that high values for target_year_x are highly predictive for the projects' success. My suggestion is to maybe try multiple models, i.e., one model to predict success in first year, one in second, etc. Or, separate model for separate project phases, if you can somehow logically split the projects. If you try that, be careful not to include features that relate to latter phases for the earlier models (e.g., don't include features that provide information about the projects' second year performance, for the model that predicts in the first year). Or, as the other answer by Brian Spiering suggests, which is also a good option IMO, you might want to consider to frame it as a time series prediction problem if you need multiple chronological predictions per project, rather than a binary classification one.
