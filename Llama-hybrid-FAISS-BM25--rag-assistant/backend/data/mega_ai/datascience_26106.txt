[site]: datascience
[post_id]: 26106
[parent_id]: 26016
[tags]: 
One way to move forward could be: Create a feedforward neural network that, given Y (probably you want to normalise it) predicts the X. So the output of the model (the last layer) would be a set of softmax neurons for each feature. So if the feature 1 (e.g. colour) has 4 options, you will apply the softmax over four neurons, and do the same over each feature. Then your loss function could be the sum (or a linear combination if you prefer) of the cross entropy for each feature.
