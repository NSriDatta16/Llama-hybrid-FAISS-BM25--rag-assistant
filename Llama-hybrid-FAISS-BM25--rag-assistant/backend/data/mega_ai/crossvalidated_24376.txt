[site]: crossvalidated
[post_id]: 24376
[parent_id]: 24348
[tags]: 
If similarity is actually 'bioequivalence', as Georgette explains the concept, then the easiest approach is probably via sampling: Sampling solution The most obvious approach is Bayesian but I can imagine that bootstrapping will work fine too. For this, define a and b to be the bounds for bio equivalence, sample from the posterior of the difference (or bootstrap a distribution for this difference) and compute the proportion of samples that are less than a or greater than b, and draw your conclusions from this proportion accordingly. In a Bayesian interpretation, this proportion is the probability that the samples are not actually equivalent, which you can threshold any way you like to make a decision. (If you're very confident about distributional assumptions then you could use the sampling distribution of the equivalent parameter in a regression model and do the whole thing without sampling via one application of lm and vcov , and two of qnorm .) On Testing The approach above is more an estimation / modeling approach than a testing approach. That's deliberate because I think this makes more sense for your problem. Separate issues arise if you really want to test . By this I mean: do you really want the inside/outside judgement distinction to be asymmetric in the way that specifying a null hypothesis in the Fisherian sense would make it? My bet is that you don't. In passing, I would stay well away from 'Bayesian testing' when it involves point hypotheses or their negations. Sensible priors are hard to find and tend to affect the results, which is just the model's way of saying that the probability that a parameter/difference is exactly x is (both mathematically, and in real life) zero. That said there may be other approaches that avoid this kind of 'problem' and these problems need not necessarily affect some operationalisation of the bioequivalence problem.
