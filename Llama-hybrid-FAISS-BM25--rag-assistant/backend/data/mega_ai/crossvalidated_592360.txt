[site]: crossvalidated
[post_id]: 592360
[parent_id]: 592356
[tags]: 
You can use the p7 probability as an estimate. (or if this estimate is very inaccurate, you can also simply conclude that you do not know enough for an accurate answer and more information should be gathered) If you somehow want to improve this estimate then you need to add information . Either by more measurements or by information based on theory. The latter can be tricky and create bias. Example measurement 1: 100 young men among which 20 got sick estimate $p_7 = 0.2 \,(s.e. 0.04)$ measurement 2: 10 000 old men among which 5 000 got sick. estimate $p_6 = 0.5 \,(s.e. 0.005)$ The estimate $p_6$ is much more accurate, but can you honestly use it to predict the probability for a young man to get sick? By using the $p_6$ figure you added more information, but it might be inaccurate information. You should only use information that makes sense. That is, when you know/assume that it will have a small bias (the acceptable level of 'small' depending on how accurate you desire to be). A related concept is the bias-variance trade-off A typical cases in statistics where bias is added is regularised regression. The 'correctness' of the added bias is determined by training and validating a model during which the amount of bias is optimized based on the perfotmance of the model. Another related concept is Bayesian statistics . It provides a way to update knowledge after acquiring more data. Of course, if there is not a lot of data, then the final quality of the estimate depends a lot on the prior knowledge. You could use the accurate number $p_6$ as prior knowledge, but you would have to reduce the weight that you give to it. How you do this is relatively subjective but in a workflow with increasingly more knowledge and information the subjectivity reduces.
