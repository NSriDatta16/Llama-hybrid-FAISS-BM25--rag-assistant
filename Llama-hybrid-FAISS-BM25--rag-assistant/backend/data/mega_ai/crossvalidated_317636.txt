[site]: crossvalidated
[post_id]: 317636
[parent_id]: 
[tags]: 
Convergence of Q-learning and Sarsa

You can show that both SARSA (TD On-Policy) and Q-learning (TD Off-Policy) converge to a certain state-value function q(s,a). However they don't converge to the same q(s,a). Looking at the following example you can see that SARSA finds a different 'optimal' path than Q-learning. Is SARSA useless then? Which attribute of an algorithm tells me if it will converge to the optimal/shortest path? (biasedness, consistency, variance for n to infinity) My idea An estimator/algorithm can only converge to a constant/static value function when its variance for n to infinity goes to 0. Both SARSA and Q-learning converge thus their variance is 0. They don't converge to the same value because SARSA is biased.
