[site]: datascience
[post_id]: 37753
[parent_id]: 37706
[tags]: 
I think this is one of those topics with the most frustrating answer - it depends . To your questions: How can we handle these data which fall into "unknown" category? There are many ways of doing this. Some are very simple and some are more complex, but they all depend on you understanding your data and what exactly causes the missingness - e.g. is the data missing at random or is there a specific cause driving it? Some techniques to treat missing values (in increasing order of complexity): Exclude all missing values. This may be fine if you have a large amount of data and few missing values (not always the case - you allude to this by mentioning the remaining data set may be imbalanced). Replace / group the missing values with an appropriate value - e.g. replace missing values with the mean of the variable / group missings with the most populous level. Impute missing values using models / equations - e.g. Multivariate Imputation by Chained Equations (MICE). How do we train the model to deal with "unknown" data? This depends on the model or technique you are using. Some techniques deal with missing values well (e.g. xgboost ), while others do not (e.g. R's ranger implementation of random forests). You should take into account the model you are using when deciding on how to treat your missing values. Or do we ignore it? Ignore missing values at your peril! Hope that helps!
