[site]: datascience
[post_id]: 121303
[parent_id]: 121296
[tags]: 
In neural networks, convergence is defined based on the values of the training loss function: if the values of the training loss function follow a descending trend (assuming we are minimizing the loss function, which is the standard), then it converges. If they follow an ascending trend or they are oscillating, then the training is not converging. We have to take into account some nuances: Stochastic Gradient Descent : neural networks are usually trained with batch-oriented stochastic gradient descent or some variation of it, so there is usually some noise in the curve. We should ignore the noise when evaluating convergence. Double descent phenomenon : usually we observe an ascending peak followed by a descending trend (see this ). This is normal and does not preclude convergence. See this exameple: Non-stationary training regimes : while in standard supervised learning we have a stationary training goal, there are other alternatives, like GANs (Generative Adversarial Networks) or reinforcement learning, where we are optimizing against a "moving target". Convergence is more difficult to characterize in those environments. Note: we should not mistake training convergence for overfitting. Overfitting is a situation where the network memorizes too much of the training data (therefore the training loss goes down), but it performs poorly on unseen data (therefore the validation loss goes up). Neural network training convergence strictly refers to how the training loss behaves.
