[site]: crossvalidated
[post_id]: 429521
[parent_id]: 429520
[tags]: 
there's nothing to predict Certainly there is. And your logistic regression outputs probabilistic predictions. Which is a Very Good Thing. So what you need to do is to assess the quality of probabilistic predictions. (Out-of-bag, as always in cross-validation.) The tool to do so is scoring-rules , which map probabilistic predictions and corresponding outcomes to scores. In your case, the simplest approach would be to use the logarithmic scoring rule . Suppose your prediction for a particular instance $i$ to be of class 1 is $\hat{p}_i$ . If the instance in fact is of class 1, the score is $s_i:=\log\hat{p}_i$ . If it is of class 0, $s_i:=\log(1-\hat{p}_i)$ . (It's always the log of the predicted probability for the actual class.) The you just sum over the scores, $S:=\sum_i s_i$ . A higher total score is better. (Some people use the opposite convention and minimize the score, then they work with negative logs.) You may be interested in my answer to Why is accuracy not the best measure for assessing classification models? Or in Classification probability threshold .
