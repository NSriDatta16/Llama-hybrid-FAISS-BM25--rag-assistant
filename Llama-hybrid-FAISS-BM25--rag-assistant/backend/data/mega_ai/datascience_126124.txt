[site]: datascience
[post_id]: 126124
[parent_id]: 126107
[tags]: 
The results seems alright. Your training accuracy could be 99% if trained on enough epochs but it does not mean it is a real indicator on how well it will do on unseen data. Regularization bridges that gap and trains network in such a way that difference between training and test accuracy is reduced. Even though it reduces accuracy of train data, it is generalizing and optimizing in such a way that it does well on unseen data. DO NOT FOCUS ON IMPROVING JUST THE TRAIN ACCURACY! Some of the things you could do to improve the accuracy: hyperparameter tuning(Such as dropout, learning rate, etc) increasing or decreasing the number of layers. More layer would mean more learning capacity but since NN are black box models we don't know how the results are going to be (Number of layers could be used as a hyperparameter for tuning) Try using a different architecture which is SOTA(state of the art) such as ViT(Vision Transformers), ConvNext etc for obtaining best results. Simple model is good as long as your goal is achieved.
