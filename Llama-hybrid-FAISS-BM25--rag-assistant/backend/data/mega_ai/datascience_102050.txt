[site]: datascience
[post_id]: 102050
[parent_id]: 
[tags]: 
confused on "real score" vs "decision value" in classification trees

I'm reading the guide to XGBoost and am confused about the distinction it draws between the scoring systems of decision trees and classification/regression trees. The paragraph I am hung up on is: A CART [classification and regression tree] is a bit different from decision trees, in which the leaf only contains decision values. In CART, a real score is associated with each of the leaves, which gives us richer interpretations that go beyond classification. I am not at all sure what this means. My understanding of regression decision trees is that each leaf has a value which is the mean label for all training examples that get assigned to that leaf (after following the structure of the tree). In a multi-tree model, when predicting a new example we navigate it through each of the trees and then average the values of the leaves it ends up in; this average is the final prediction. My questions are: a) Is my understanding of decision trees correct and b) What is being done differently in the CART trees used by XGBoost and LightGBM? From the drawing just below the quoted paragraph, it seems like each leaf has a 'prediction score,' which gets summed across the tree and then somehow processed into the final regression prediction?
