[site]: crossvalidated
[post_id]: 621161
[parent_id]: 621152
[tags]: 
You seem to be misunderstanding what we mean by "models". Imagine that you are observing a horse race. At one point you say, "Horse number 3 is gonna win!". How did you draw the conclusion? You did not have perfect knowledge about each muscle in each horse taking part in the race, about their breaths and heartbeats, each sand grain on the race track, each thought and feeling of each horse and jockey, each sound and wind blow that could affect the result, etc. Even if you had access to such knowledge, the information would not fit the working memory of your brain. Moreover, even if you had the information and it fitted your working memory, we do not have a perfect understanding of the universe (physics, psychology, physiology, etc) so given the facts we could combine them and make a conclusion about the inevitable result of the race. If we did, we would not do horse racing, because the results would be known and advance and not interesting anymore. What you do when you say "Horse number 3 is gonna win!", is you build a mental model of the race. The model combines a subset of known facts with your understanding of what is going on, and based on the model, you are drawing some conclusions. The model could be as simple as "the horse number 3 always wins", or very complex. When we want to be more rigorous, we are using scientific models of the world. Those models could be physical models , mathematical models , simulation models , etc. What those models have in common is that they simplify and approximate reality, so to enable us to use them to draw conclusions, understand, predict, or simulate something. Statistical models are one of the kinds of such models. They are mathematical representations of the problem that use the data. In your question, you gave examples of linear models such as linear regression or generalized linear models, but there are many more models than linear ones. Also, you seem to be assuming that the statistical model assumes in advance the exact mathematical representation of the problem. That is not the case! For example, a regularized regression could shrink some of the parameters to zeros, effectively removing them from the equation, so the resulting function would make use of a different set of features than we assumed in our model. Polynomial regression, like a neural network, is a universal approximator, so the model assumes that the functional representation of the data could take any form. Logistic regression is the simplest kind of neural network , so even if we agreed with your definition of a model, neural networks would fit the definition. Finally, $k$ NN, random forest, and other machine learning models can be written down as mathematical functions, so they would also be models in the sense of being mathematical functions representing the data. If you prefer, instead of saying that in $$y = f(\mathbf{x})$$ $f$ is a "model", use the word "curve" here. You would be saying that you fitted linear regression "curve" to the data, random forest "curve", neural network "curve", etc. However, we usually call $f$ a (statistical or machine learning) model . You would not benefit much from not using the term though, because it would make it harder to communicate with other people, as each time you would need to explain what you mean in the place where you could use the term "model" which is a usual term for it. Regarding your concerns: Intuitively, in the real-world we do not know what is the relationship between label and data. So why would bother creating a relationship between them? In some cases we do, then we can use models that enable us to be explicit about it, in some cases we don't, so we use things like non-parametric models. In no part of modern machine learning training/validation/testing routine do we require the assumption of a clear relationship between $x_i$ and $y_i$ . It literally does not provide us with any additional information. I don't agree. If you are using some machine learning model, you are making an assumption that there is some relation between $x$ and $y$ . If there is no such relation, your model cannot learn anything, and the only thing it could do is it will overfit the noise or predict something like global average, or most frequent class for all the observations. Moreover, if you can use a model that assumes some specific relation, the model may require way less data to learn. For linear regression, a few hundred samples may be more than enough, while for a neural network thousands may not be enough. In modern deep supervised machine learning, the concept of a model is not even remotely mentioned. For example, it doesn't seem to make sense to say things such as "what's the statistical model of GoogLeNet", or "what's the statistical model of LSTM". I mean, what is the functional form of $m$ and noise assumption on $\epsilon_i$ , $y_i = m(x_i) + \epsilon_i$ for things like DenseNet or U-Net? GoogleNet, LSTM, etc are the models themselves. You incorrectly assume that all models have a simple form like $y = m(x) + \epsilon$ , that is not the case. Unless your question is "Are we forced to use linear models", then the answer is obviously "no", even the old-school statistics do not limit itself only to such models.
