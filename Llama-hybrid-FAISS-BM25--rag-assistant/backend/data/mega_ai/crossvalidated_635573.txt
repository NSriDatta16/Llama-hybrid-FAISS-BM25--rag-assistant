[site]: crossvalidated
[post_id]: 635573
[parent_id]: 530044
[tags]: 
There is a general debate on whether to use max or average pooling or a conv layer (with stride 2) to downsample. I would argue that today using conv layers is most prevalent as it simply works best (though not in every case, it requires more data). For classification often the philosophy is: If we find the pattern, we can classify the object. This philosophy is better captured with max-pooling, as you mostly only care about the strongest occurrence (most features occur only once in some small area), whereas average pooling somehow adds noise as it averages the strongest match with some that are rather weak. However, (i) max-pooling limits learning (gradients are 0 except for the feature with max activation within the pooling area) and (ii) in particular if you use large pooling width (say 5 or more as in resent in the final layer before the linear layer) the idea of features occur only once is not valid as you average across a very large area.
