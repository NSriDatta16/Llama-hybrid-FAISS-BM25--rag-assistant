[site]: crossvalidated
[post_id]: 498122
[parent_id]: 496957
[tags]: 
The number of support vectors is largely determined by the number of training errors you have - any point having non-negative loss is a support vector. Thus, the training error is the minimum number. Note for $\nu$ -SVM, if $\nu$ is "in-range", then $\nu$ represents a bound on the fraction of SVs. It's important to note that $\nu$ can be too small - this is equivalent to $C=\infty$ or $\lambda=0$ in the more standard SVM formulations. Additionally, though, in certain contexts (e.g., High Dimension, Low Sample Size) - you may also experience "piling" whereby there are a large number of support vectors on the margins - see here for example.
