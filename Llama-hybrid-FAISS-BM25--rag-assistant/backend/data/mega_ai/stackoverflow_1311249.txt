[site]: stackoverflow
[post_id]: 1311249
[parent_id]: 1311181
[tags]: 
Naturally separating IIS and SQL server is the first step. Sql server really want to have a complete machine for itself. The second thing that is important is to analyze the application as it runs. Never try to optimize the performance of your application without having real usage data, because you probably just spend time optimizing stuff that rarely gets called. One technique I have used with success in the past is to create a System.Diagnostics.Stopwatch in Request_Begin in the global.asax, then store it in a context variable var sw = new Stopwatch(); sw.Start() HttpContext.Current.Items["stopwatch"] = sw; In Request_End, you obtain the stopwatch agin sw = HttpContext.Current.Items["stopwatch"]; sw.Stop(); Timespan ts = sw.Elapsed; And then write to a log table how long time it took to process the request. Also log the URL (both with and without query string parameters) and all sorts of stuff that will help you to analyze performance. Then you can analyze you application and find which operations take the longest time, which are called the most, etc. That will allow you to see if there is one page that is requested a lot, and it generally takes a long time to complete, that should be a target of optimization, using whatever tools you have for that, both .NET and SQL profilers. Other stuff I also normally log are, IP addresses, and user ID for logged in users. That also gives me an invaluable debbugging tool when errors arise. A reason to put it in a table, as opposed to writing it to a log file is that you can use SQL syntax to filter out, group, calculate average times, etc.
