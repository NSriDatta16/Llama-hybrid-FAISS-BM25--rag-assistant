[site]: stackoverflow
[post_id]: 1255236
[parent_id]: 1254994
[tags]: 
The structure of URLs should take search engine optimization into account. Even if the site is only running internal to an organization, it's probably being crawled by an internal engine or will be at some point in the future. Here are a couple of key points from 2 Google resources I have found useful: Good practices for URL structure from http://www.google.com/webmasters/docs/search-engine-optimization-starter-guide.pdf : Use words in URLs - URLs with words that are relevant to your site's content and structure are friendlier for visitors navigating your site. Visitors remember them better and might be more willing to link to them. Provide one version of a URL to reach a document - To prevent users from linking to one version of a URL and others linking to a different version (this could split the reputation of that content between the URLs), focus on using and referring to one URL in the structure and internal linking of your pages. URL structure from http://www.google.com/support/webmasters/bin/answer.py?answer=76329 : A site's URL structure should be as simple as possible. Consider organizing your content so that URLs are constructed logically and in a manner that is most intelligible to humans (when possible, readable words rather than long ID numbers). Consider using punctuation in your URLs. The URL http://www.example.com/green-dress.html is much more useful to us than http://www.example.com/greendress.html . We recommend that you use hyphens (-) instead of underscores (_) in your URLs. Overly complex URLs, especially those containing multiple parameters, can cause a problems for crawlers by creating unnecessarily high numbers of URLs that point to identical or similar content on your site. As a result, Googlebot may consume much more bandwidth than necessary, or may be unable to completely index all the content on your site.
