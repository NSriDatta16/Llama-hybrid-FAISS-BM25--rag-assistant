[site]: datascience
[post_id]: 8867
[parent_id]: 8087
[tags]: 
It is possible that most of the variance in the dataset exists between input images (or between input and output images). In that case, the most informative principal components serve to separate input examples or to separate the input from the output. If only the less informative PCs describe the variance b/w outputs, it will be harder to distinguish between outputs than it was in the original feature space. That said, PCA in images is rarely all that helpful. In this example I can see it being appealing, but it would probably much more meaningful and memory-friendly to learn a different lower dimensional feature representation. You could try a simple autoencoder, SIFT/SURF features, or haar-like features.
