[site]: datascience
[post_id]: 97913
[parent_id]: 97908
[tags]: 
There is an implementation in Scikit-learn named FeatureAgglomeration , that does exactly what you want but using Agglomerative clustering It simply runs the cluster algorithm in the transposed matrix of X. So in your case you could apply this idea but using Kmeans instead Update: I recently came across a similar problem for dimensionality reduction and I found a Python implementation of an originally SAS procedure named VarClus. According to the package's documentation: This is a Python module to perform variable clustering (varclus) with a hierarchical structure. Varclus is a nice dimension reduction algorithm. Here is a short description: A cluster is chosen for splitting. The chosen cluster is split into two clusters by finding the first two principal components, performing an orthoblique rotation, and assigning each variable to the rotated component with which it has the higher squared correlation. Variables are iteratively reassigned to clusters to maximize the variance accounted for by the cluster components.
