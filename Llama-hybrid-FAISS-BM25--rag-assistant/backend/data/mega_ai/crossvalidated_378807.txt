[site]: crossvalidated
[post_id]: 378807
[parent_id]: 
[tags]: 
How to derive the gradient for SSE cost function in Adaline?

I started learning machine learning and have some troubles in understanding derive rules for the gradient of cost function in particular I can't understand how sum(wjxj) transformed to -xj. I tried to google a detailed breakdown explanation but everywhere the same. I know that it pretty simple for mathematicians for those who hasn't met this for quite long time it's a problem. Could someone explain or/and give links to some resources regarding that. Thanks in advance!
