[site]: crossvalidated
[post_id]: 136094
[parent_id]: 
[tags]: 
Extreme differences in Odds Ratios in Logistic Regression with or without a predictor

I was trying to get an intuition for the interpretation of the coefficients in a logistic regression that was intended to reproduce to some extent that presented in a youtube video ( http://youtu.be/vq-_4kWmzTo ). So I created a fictitious data set reflecting the chances of getting accepted (Accepted: int: 0 0 ... 1 0) into a college as related to SAT scores (int 1136 1347 1504) and family/ethnic background (categories = "red" vs "blue"). fit yielded: OR 2.5 % 97.5 % Backgroundblue 0.7088608 0.5553459 0.9017961 Backgroundred 1.7352941 1.3632702 2.2206569 The interpretation seemed easy: Red applicants have 1.7 times more chances of getting in over the rest; blue applicants were at a disadvantage, and had 7 over 10 odds of getting in. However, the more complete model, fit yielded coefficients for background that are difficult to reconcile or interpret: OR 2.5 % 97.5 % SAT.scores 1.008558e+00 1.006940e+00 1.010297e+00 Backgroundblue 8.730056e-06 8.459031e-07 7.634723e-05 Backgroundred 2.329513e-05 2.426748e-06 1.929259e-04 Can you help point out what I am missing? Thanks to the enlightening answer from Maarten below, I was able to make some progress, and obtain the correct Odds Ratios without and with the SAT confounder: Here is just regressing to Background ("Red" versus "Blue"): fit $OddsRatioBlue = 1 / OddsRatioRed$ ?
