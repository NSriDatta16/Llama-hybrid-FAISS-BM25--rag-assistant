[site]: datascience
[post_id]: 89147
[parent_id]: 88923
[tags]: 
I've finally found a way to forecast values based on predicted values from the earlier observations. As expected, the predictions were rather accurate in the short-term, slightly becoming worse in the long term. It is not so surprising that the future predictions digress over time, as they no longer depend on the actual values. Reflecting on my results and the discussions I had on the topic, here are my take-aways: In real-life cases, the real values can be retrieved and fed into the model at each step of the prediction -be it weekly, daily, or hourly- so that the next step can be predicted with the actual values from the previous step. So, testing the performance based on the actual values from the test set may somewhat reflect the real performance of the model that is maintained regularly. However, for predicting future values in the long term, forecasting, if you will, you need to make either multiple one-step predictions or multi-step predictions that span over the time period you wish to forecast. Making multiple one-step predictions based on the values predicted the model yields plausible results in the short term. As the forecasting period increases, the predictions become less accurate and therefore less fit for the purpose of forecasting. To make multiple one-step predictions and update the input after each prediction, we have to work our way through the dataset one by one, as if we are going through a for-loop over the test set. Not surprisingly, this makes us lose all the computational advantages that matrix operations and mini-batch training provide us. An alternative could be predicting sequences of values, instead of predicting the next value only, say using RNNs with multi-dimensional output with many-to-many or seq-to-seq structure. They are likely to be more difficult to train and less flexible to make predictions for different time periods. An encoder-decoder structure may prove useful for solving this, though I have not implemented it by myself. You can find the code for my function that forecasts the next n_steps based on the last row of the dataset X (time-lag features) and y (target value). To iterate over each row in my dataset, I would set batch_size to 1 and n_features to the number of lagged observations. def forecast(self, X, y, batch_size=1, n_features=1, n_steps=100): predictions = [] X = torch.roll(X, shifts=1, dims=2) X[..., -1, 0] = y.item(0) with torch.no_grad(): self.model.eval() for _ in range(n_steps): X = X.view([batch_size, -1, n_features]).to(device) yhat = self.model(X) yhat = yhat.to(device).detach().numpy() X = torch.roll(X, shifts=1, dims=2) X[..., -1, 0] = yhat.item(0) predictions.append(yhat) return predictions The following line shifts values in the second dimension of the tensor by one so that a tensor [[[x1, x2, x3, ... , xn ]]] becomes [[[xn, x1, x2, ... , x(n-1)]]] . X = torch.roll(X, shifts=1, dims=2) And, the line below selects the first element from the last dimension of the 3d tensor and sets that item to the predicted value stored in the NumPy ndarray (yhat), [[xn+1]] . Then, the new input tensor becomes [[[x(n+1), x1, x2, ... , x(n-1)]]] X[..., -1, 0] = yhat.item(0) I tried to summarize some of the things I would have liked to know back when I started. I hope you'll find it useful. Feel free to comment or reach out to me if you agree or disagree with any of the remarks I made above.
