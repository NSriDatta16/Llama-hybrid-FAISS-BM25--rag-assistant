[site]: crossvalidated
[post_id]: 51184
[parent_id]: 
[tags]: 
Can I adapt a MCMC proposal using a parallel chain?

I am running two MCMC chains (say chain A and chain B) in parallel, using the Metropolis-Hastings algorithm with acceptance probability: $P(accept\ x_t) = \min\{1, f(x_t)/f(x_{t-1})\}$. I would like my proposal distribution to be adaptive, but I know that if I use old values of one chain to choose the proposal (i.e $p(x_t|x_{t-1}) = g(x_1, \dots, x_{t-1})$), I will lose the Markov property (see this post for example), because $p(x_t|x_{t-1}, \dots, x_{1}) \neq p(x_t|x_{t-1})$. So I'm running two chains in parallel (same target distribution), chain A uses a fixed (non adaptive) proposal while chain B is using an adaptive proposal which is a function of the past values of chain A (i.e. $p(x^B_t|x^B_{t-1}) = g(x^A_1, \dots, x^A_{t-1})$). To me it looks like the algorithm is correct, because $p(x^B_t|x^B_{t-1}, \dots, x^B_{1}) = p(x^B_t|x^B_{t-1})$, given that the proposal for B is not using past values of the same. My questions are: 1) Is chain B still Markovian? 2) Even though the two chains have the same target distribution, is using one chain to adapt the other one a good idea? Maybe not because in the initial phase the two chains might be in different area of the parameter space. Thanks!
