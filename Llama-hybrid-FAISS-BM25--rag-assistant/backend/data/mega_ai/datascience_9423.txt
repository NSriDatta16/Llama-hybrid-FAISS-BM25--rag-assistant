[site]: datascience
[post_id]: 9423
[parent_id]: 9397
[tags]: 
I decided to expand a bit on my comment and make a full answer. So the reason why somebody may say that performing the hashing trick can destroy interactions is because it may map different features to the same bucket. But usually it's not a big deal. Note that DictVectorizer doesn't perform the hashing trick: When feature values are strings, this transformer will do a binary one-hot (aka one-of-K) coding: one boolean-valued feature is constructed for each of the possible string values that the feature can take on. For instance, a feature “f” that can take on the values “ham” and “spam” will become two features in the output, one signifying “f=ham”, the other “f=spam”. To do it, you need to use a different vectorizer: HashingVectorizer
