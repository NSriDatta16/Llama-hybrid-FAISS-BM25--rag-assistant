[site]: crossvalidated
[post_id]: 365857
[parent_id]: 365767
[tags]: 
Convexity is an example of "global structure" because it depends on the value of a function everywhere, whereas (sub)differentiability is a aspect of local structure because a function is often differentiable in a limited domain. A nonlocal move is in contrast to the commonly used SGD algorithm which operates by iteratively adding some small delta to a point in parameter space -- each update is "local" in the sense that there are no big jumps. A genetic algorithm which combines and mutates weights from a population would consist of nonlocal moves, since parameters can jump arbitrarily in the space. There has only been very limited success with neural networks with non-SGD based, "nonlocal" algorithms. On the other hand, just by using proper initialization, we have been able to train 10000 layer neural networks .
