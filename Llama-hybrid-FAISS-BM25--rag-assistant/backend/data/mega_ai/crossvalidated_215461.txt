[site]: crossvalidated
[post_id]: 215461
[parent_id]: 
[tags]: 
Tradeoff between Survival probability and detection probability: Mark-recapture

When scientists are using mark-recapture models on an open population model to estimate the survival probability and the recapture probability (also known as "detection"), how can we be sure that the model is estimating the right thing between the two parameters? Let me put an example. Imagine that you sampled a population of individuals like this one (where ch is the capture history and al is the alive matrix): ch = data.frame(x1 = c(0,1,1,0,0), x2 = c(0,0,1,0,1), x3 = c(1,0,1,1,0), x4 = c(0,1,1,0,0)) ch # 1 means that an individual was alive and recorded in the field notebook and 0 that it was not observed when sampling at a particular time (x1-x4) x1 x2 x3 x4 1 0 0 1 0 2 1 0 0 1 3 1 1 1 1 4 0 0 1 0 5 0 1 0 0 al = data.frame(x1 = c(0,1,1,0,0), x2 = c(1,1,1,0,1), x3 = c(1,1,1,1,1), x4 = c(0,1,1,1,0)) al # this matrix shows actually what is going on in the population. That means that you haven't observed some individuals in the ch dataset, but could still be present in the environment. x1 x2 x3 x4 1 0 1 1 0 2 1 1 1 1 3 1 1 1 1 4 0 0 1 1 5 0 1 1 0 Since you never know the "al" dataset, how can you be confident that you are actually separating the two parameters? If you have a perfect detection, you should be able to assess perfectly your survival probability. The less you are certain about the detection probability, the less confident you are with your survival estimation. In other words, I guess that if the capture history was like this one, the parameter estimation would be less interesting. It seems that there is much less information in the capture history. ch1 = data.frame(x1 = c(0,0,1,0,0), x2 = c(0,0,1,0,1), x3 = c(1,0,0,1,0), x4 = c(0,1,0,0,0)) ch1 x1 x2 x3 x4 1 0 0 1 0 2 0 0 0 1 3 1 1 0 0 4 0 0 1 0 5 0 1 0 0 But I know that usually, it's not interesting to do this on small datasets. But the point is still there. Since we don't know "al", how can we estimate our parameters properly? Here are my questions: How can you be confident about the values that you observe? Is there a threshold where, if you have a detection probability low or a survival really low, it's impossible to really assess a value for the parameters? For example, if survival goes under 0.11 (meaning that individuals have a probability 11% to serve for the next event or time x#), is it still possible to compute a detection parameter? Is a Bayesian hierarchical model better at estimating parameters for detectability and survival than a frequentist model? Is there a minimum number, approximately, of individuals needed to compute a mark-recapture model on an open population to find detectability and survival? Since a model needs some false absences in order to estimate detectability, what is the proportion of individuals that is only seen once (e.g. c(0,0,0,1) or c(0,1,0,0), etc.) compared to the individuals that have a false negative (e.g. c(0,1,0,1) or c(1,0,0,1), etc.) before a mark-recapture model is not able to 1. discriminate between detectability and survival, and 2. is giving a value that is usable or interpretable without a loss of confidence in the parameter estimation?
