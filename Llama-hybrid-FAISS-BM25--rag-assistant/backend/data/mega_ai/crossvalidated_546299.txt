[site]: crossvalidated
[post_id]: 546299
[parent_id]: 
[tags]: 
Why does a subset of variables produce a higher AUC value than all variables in a logistic regression?

I have to predict when the soil dries out. The dependent variable is therefore binary (the soil is wet or dry). I have a lot of variables, and I have clustered them together into three main clusters. Weather Vegetation Soil When I run a penalised ridge logistic regression ( glmnet ) for all parameters I get an AUC value of around 0.81. Then I run it for each individual cluster. Weather and vegetation both amount to an AUC of 0.5, while the soil parameter has a AUC of 0.84. How can I get a better prediction of the when the soil dries with a cluster of variables than all variables included? Do the 'non-predictive' variables in the weather and vegetation cluster "drag down" the overall AUC score for the whole model and that is what I see with the higher AUC score for soil alone? Here is the script: library(readr) library(caret) library(tidyverse) library(glmnet) library(ROCR) library(pROC) library(doParallel) registerDoParallel(4, cores = 4) set.seed(123) data % select(V1, V2, ... V25) df.W % select(V1, V2, ... V7) df.V % select(V8, V9, ... V18) df.S % select(V19, V20, ... V25) training.samples $V1 %>% createDataPartition(p = 0.8, list = FALSE) train V1 x.test Sum up the AUC values: Weather: 0.5 Vegetation: 0.5 Soil: 0.84 All: 0.81
