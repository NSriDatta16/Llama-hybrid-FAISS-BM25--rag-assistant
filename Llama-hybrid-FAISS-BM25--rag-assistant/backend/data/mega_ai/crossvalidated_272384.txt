[site]: crossvalidated
[post_id]: 272384
[parent_id]: 272364
[tags]: 
Lets clean up some notation issues first. Let the true value of the parameter be denoted as $\theta$ and a point estimator of $\theta$ be denoted as $\hat{\theta}$. $\pi(k=K)$ denotes the probability that $k=K$. The Frequentist process begins with designing the experiment and creating a null hypothesis. The null can matter if a decision about the parameter needs to be made rather than just an inference that results in an action. To talk about comparing the methods, you really need to state a null hypothesis first because probabilities are always with reference to the null. To make matters simple, let us assert that it is important to us for some reason that $\theta\le{.5}$, which implies that half or less of the tosses will result in an A as the number of tosses goes to infinity. For comparative purposes, we will use the same hypothesis for the Bayesian method. The Frequentist is assuming the coin tosses are "identical," though what that precisely means is a bit of a problem. Fundamentally, the process of tossing the coin is subject to the same forces. The Bayesian does not necessarily make that strong assumption. It is possible that a con man or magician tossed it sometimes, deterministically, and a child tossed it later in a manner similar to "randomness." The Bayesian makes the weaker assumption the model you assert is a fair representation of the events in nature. The Bayesian needs to specify a prior distribution. Since nothing is known about the true location of $\theta$ for the purposes of our exposition, we will use the uniform distribution as our prior distribution. It is important to note that although the uniform distribution grants equal weight to all possible values of $\theta$ the expected value of theta is $$\int_0^1\theta\mathrm{d}\theta=\frac{1}{2}.$$ This bias in the expectation will never go away, though its importance will diminish to zero as the sample size goes to infinity. You asserted that Given a binomial process that generates A or B. After 100 draws, we have 36 Bs. The minium variance unbiased estimator is $\hat{\theta}=.64$. The posterior density function will be $$199697662796638231933820787675(1-\theta)^{36} \theta^{64}.$$ If the Bayesian needed a point estimator for some reason, it would be based upon the cost of being wrong in making the estimate. Because of this, there are an infinite number of points. Nonetheless, there are three very common cost functions, the quadratic, the absolute linear lost and the all-or-nothing cost functions. The three points are the mean, median and mode of the posterior density function and not of the data . The respective value of the Bayesian point estimators will be .637255, .638155 and .64 respectively. The frequentist rejects the null at p For the Frequentist, if the process were repeated the concern is with the null and although there is no updating of the estimator, there is a process of reviewing how frequently the null is rejected. For the Bayesian the location of the estimator is updated with each sampling. You are probably looking for terms like conjugate prior, Polya distribution, beta-binomial, Bernouli trials, Bayesian updating and maximum likelihood.
