[site]: crossvalidated
[post_id]: 184620
[parent_id]: 184617
[tags]: 
No it will not get the same posterior distribution for every possible choice of priors. Different priors lead to different posteriors (remember that the posterior $\alpha$ prior $\cdot$ likelihood) and thus chains from MCMC with different equilibrium distributions. Convergence of MCMC is related to the ensurance that the built samples does not depend on the initial state (i.e. on the initialisation of the algorithm). So given a infinite amount of times, two runs of a same of MCMC (associated the same model, including the prior) both gives random samples from the same stationary law.
