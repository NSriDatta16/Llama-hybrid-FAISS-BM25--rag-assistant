[site]: crossvalidated
[post_id]: 316711
[parent_id]: 316704
[tags]: 
It's hard to say without more detail. But most likely, if you're selecting the correct class by picking the maximal class in your softmax, then the loss can keep going down because you're increasing the correct class probability, but if another class always dominates the correct class, then the answer remains the same. For example if you have two classes with probabilities (0.2,0.8), and if the first one is supposed to be correct, then (0.3,0.7) would reduce the loss, but would not change the percent correct. Looking at your code some more, it looks like you have three layers with 10 hidden units each. You'll most likely need at least 100 hidden units within each layer, so try making them much bigger. Check out Yann Lecun's page on MNIST accuracy here: http://yann.lecun.com/exdb/mnist to compare your neural network with the baselines provided
