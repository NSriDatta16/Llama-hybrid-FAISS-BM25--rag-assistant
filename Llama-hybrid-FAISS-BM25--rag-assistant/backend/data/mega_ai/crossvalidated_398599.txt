[site]: crossvalidated
[post_id]: 398599
[parent_id]: 
[tags]: 
How to calculate the lag of a prediction of a time series?

I am trying to learn a time series (Mackey-Glass) using a neural net. In order to see if there has been success in the learning process, I am looking at the correlations between the predicted and real values. The following table shows these correlations: The correlation between the predicted value and the actual real value real_lag_0 is 0.986. Now comparing the predicted value with the real value shifted backwards by one real_lag_1 yields 0.993. It seems like the highest correlation occurs at lag 1. Compare this source If the lag is 1, then the neural net is worthless? How could I improve the model to obtain the highest correlation for actual values?
