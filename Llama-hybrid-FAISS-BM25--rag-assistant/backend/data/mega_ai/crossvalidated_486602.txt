[site]: crossvalidated
[post_id]: 486602
[parent_id]: 
[tags]: 
How does Prior Variance Affect Discrepancy between MLE and Posterior Expectation

Suppose that $\theta\in R$ is a parameter of interest, $p(\theta)$ is our prior belief regarding $\theta$ , and $\hat \theta$ is the MLE for theta derived from the data $x$ . It is my understanding that because the posterior expectation always lies in between the prior expectation $E[\theta]$ and the MLE $\hat \theta$ , it can be expressed as a weighted average of the two values. Furthermore, it was my understanding that if $w_{prior}=w$ represents the weight given to $E[\theta]$ and $(1-w)$ represents the weight given to $\hat \theta$ , i.e. $E_{\theta|x}[\theta|x]=wE_{\theta}[\theta]+(1-w)\hat \theta$ , then $w$ is inversely related to the variance of $p(\theta)$ . Assuming that my understanding is correct (obviously correct me if not), then as the variance of $p(\theta)$ approaches its upper bound, then $w$ approaches zero. The reason I doubt this statement is that there are prior distributions whose variances are bounded above (i.e. Beta distribution), and I don't know if the corresponding weight may be bounded below by a number larger than zero. Edit: According to @Xi-an's comment, it is not true that the posterior expectation must lie between the prior expectation and the MLE. Could someone provide an example of when this occurs?
