[site]: stackoverflow
[post_id]: 754803
[parent_id]: 750787
[tags]: 
One simple and somewhat inaccurate way to do this would be to decrease the granularity of your data. It might not even be inaccurate, depending on how accurate your x, y measurements are. let's say we have the following data: x y signal_strenth 10.2 5.1 10 10.1 5.3 12 10.3 5.5 8 If we floor the x and y values, we get: x y signal_strenth 10 5 10 10 5 12 10 5 9 Then we can average those values by the floored x and y to show that we have average signal strength in the rectangle (10, 5) to (11, 6). Here's the SQL: select floor(x) as rectangle_xmin, floor(y) as rectangle_ymin, floor(x) + 1 as rectangle_xmax, floor(y) + 1 as rectangle_ymax, avg(signal_strength) as signal_strength from table group by floor(x), floor(y); Now, admittedly, you'd ideally want to group data points by distance from point to point, and this groups them by a maximum distance that varies from 1 and to square_root(2) =~1.44, flooring them into rectangular blocks. So it's less than ideal . But it may work well enough for you, especially if the flooring/grouping is less than the error in your measurement of position. If floor() is not granular enough, you can use floor( x * someweight ) / someweight to adjust it to the granularity you want. And of course you can use ceil() or round() to do the same thing. The whole point is to collapse a bunch of nearby measurements to one "measurement", and then take the average of the collapsed values.
