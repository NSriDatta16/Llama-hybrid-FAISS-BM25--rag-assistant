[site]: crossvalidated
[post_id]: 366886
[parent_id]: 366794
[tags]: 
I wonder what you mean exactly by: checking all my models LINE conditions i.e. what do you mean by "LINE conditions" and how do you check your models? If "check" means "test" or "validate" a model, then you would first need to fit the model, and apply the model to a separate data set (not used during model fit) to evaluate how the model performs. Also, what do you mean by "model", i.e. what distinguishes your model among them and make up the selection measure of the best one? Since you are talking about fitting regression models (as opposed to fitting e.g. a regression model, a decision tree model, a neural network model, ...), I presume the models you want to try differ either... in the set of predictors you use (for instance, you may want to try different transformations of the predictors in your regression fit) whether you use weights for your cases the sub-sample of your full dataset you use to fit the model ...other... Despite the above questions, normally fitting a regression model implies doing predictor selection where you start with a set of K potential predictors of your target variable and use an algorithm to nail down the set of predictors that are actually useful to predict your target. Example of such an algorithm is the stepwise selection process, where out of the K potential predictors that you "show" the regression model with, you end up with k ( https://en.wikipedia.org/wiki/Stepwise_regression (and be ware of its criticism at the bottom) So, "nailing down predictors" in your context to me is selecting a set of those potential K predictors I just mentioned. If not, please better clarify the context in which you are asking this question, i.e. essentially answering what youmean by fitting different models.
