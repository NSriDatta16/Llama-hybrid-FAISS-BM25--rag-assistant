[site]: datascience
[post_id]: 99846
[parent_id]: 
[tags]: 
Predicting probabilities in Neural Networks

I have 1000 number of inputs in a sample each ranging between 0-1 as shown: array([[0.404, 0.417, 0.43 , ..., 0.425, 0.416, 0.404], [0.318, 0.295, 0.321, ..., 0.284, 0.305, 0.323], [0.205, 0.2 , 0.19 , ..., 0.197, 0.203, 0.193], ..., [0.421, 0.44 , 0.456, ..., 0.452, 0.453, 0.432], [0.225, 0.239, 0.218, ..., 0.227, 0.226, 0.243], [0.439, 0.451, 0.427, ..., 0.417, 0.445, 0.47 ]]) and 1000 number of outputs in each sample as the probability distribution as follows: array([[3.58779547e-03, 1.00498472e-04, 1.40697861e-04, ..., 2.09036823e-03, 1.20598167e-03, 2.86420646e-03], [3.38713450e-03, 8.42105263e-05, 1.87134503e-05, ..., 2.08654971e-03, 1.34736842e-03, 2.59181287e-03], [2.80166980e-03, 9.33889932e-06, 9.33889932e-06, ..., 1.04595672e-03, 2.52150282e-03, 2.76431420e-03], ..., [4.77871131e-03, 4.16445430e-05, 1.00000000e-09, ..., 2.91511801e-04, 1.07234698e-03, 2.47785031e-03], [3.39823659e-03, 1.00000000e-09, 1.00000000e-09, ..., 2.31447465e-03, 1.50624541e-03, 2.59000735e-03], [4.37774882e-03, 2.03616224e-05, 1.00000000e-09, ..., 3.15605147e-04, 2.43321388e-03, 2.63683010e-03]]) And I want to predict these probabilities bases on the inputs provided. I treated this as a multi-classification problem with 1000 categories, each having its respective probabilities. But the error is 5.8 (cross-entropy). I am using a NN with 2048 nodes and 3 layers with a 'softmax' activation function. My loss function is 'categorical_crossentropy' and Adam(lr = 0.001) optimizer. early_stopping = callbacks.EarlyStopping( min_delta=0.0001, # minimium amount of change to count as an improvement patience=20, # how many epochs to wait before stopping restore_best_weights=True, ) model = keras.Sequential([ layers.Dense(2048, activation='softmax', input_shape=[1000]), layers.Dense (units = 2048, activation = 'softmax'), layers.Dense (units = 2048, activation = 'softmax'), layers.Dense (units = 1000, activation = 'softmax'), ]) model.compile (keras.optimizers.Adam(lr = 0.001), loss = 'categorical_crossentropy') history = model.fit( x_norm_train, y_train, validation_data=(x_norm_val, y_validation), batch_size=23, epochs=500, callbacks=[early_stopping], # put your callbacks in a list verbose=0, # turn off training log ) I have replaced the perfect 0.0 probability with 1e-9 in the output, which reduces the errors even further, but I am not getting good results yet. Any suggestion would help me a lot. I have recently started ML, and I don't even know how I am using the NN is viable. Please help.
