[site]: crossvalidated
[post_id]: 546370
[parent_id]: 546368
[tags]: 
A common approach is to to approximate the posterior (as oppose of calculating the full posterior). We usually model the posterior with "easy to work with distribution" for example distribution that can be described by finite number of parameters. A common solution is to model the posterior as a normal distribution, and thus for each parameter we only need to find $\mu, \sigma$ . In this case, the prior is also modeled as the standard normal distribution, and the way to learn the (approximated) posterior is via variational inference. Once you learn the posterior you can do prediction by computing the integral of the posterior distribution i.e. weighted average according to the posterior weights. Practically, computing the integral is impossible (as there are infinite values) and thus the average is done by sampling the posterior (in this setup sampling each parameter according its normal distribution.
