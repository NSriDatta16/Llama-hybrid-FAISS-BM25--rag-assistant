[site]: crossvalidated
[post_id]: 281686
[parent_id]: 281678
[tags]: 
t-tests generally compare two means, but there is such a thing called a "one-sample t-test," where someone takes one mean and compares it to just any old constant number. In this case, Bem coded a miss as 0 and a hit as 1 . In this case, the mean is the same thing as the percent correct. From there, he could do a one-sample t-test comparing that mean to .50, representing what you would get by guessing by chance. The d refers to Cohen's d , which is the mean difference divided by the pooled standard deviation. It represents how many standard deviations two means are from one another. In this case, the d represents the mean minus .50 (the constant he compares to), divided by the standard deviation of the scores he measured. This assesses how many standard deviations away from 50% his average hit rate was.
