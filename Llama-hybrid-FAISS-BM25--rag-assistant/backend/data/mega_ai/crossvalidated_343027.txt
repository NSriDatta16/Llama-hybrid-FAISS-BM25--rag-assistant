[site]: crossvalidated
[post_id]: 343027
[parent_id]: 
[tags]: 
What is process in Markov Decision Process?

From all the explanations I have had, I only get what the Markov part of MDP is, not the process part of it. Is it same as the process as used in stochastic processes, gaussian processes or poisson processes? I can't get a Wikipedia link to process and the definitions of MDP or any of the aforementioned processes do not go as "Stochastic process is a process which..." . Maybe examples of generic processes and defining these as special cases would help me understand better.
