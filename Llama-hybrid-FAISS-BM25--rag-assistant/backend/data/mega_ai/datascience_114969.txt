[site]: datascience
[post_id]: 114969
[parent_id]: 114958
[tags]: 
As general points: Multivariate RNN: You can use multiple sequential features as an input to your recurrent layers. Taking pytorch as a reference, you can see that the input of LSTM object is a tensor of shape $(L, H_{in})$ or $(L, N, H_{in})$ for batched, where $L$ is the length of your sequences whereas $H_{in}$ is the number of input features. In this approach, you can leave mapping tokens to a vocabulary as part of the standard procedure of a standard embedding being learnt. You may be able to use a multi-label approach (as opposed to multi-class), if I understand your question correctly. Multimodal learning: If features related to embeddings can be considered static/not evolving over time, you may want to add a second auxiliary port to your network, to specifically model this data type. This second part would consist of a feed-forward network with fully connected layers. The fixed-length vector representations / embeddings at the outputs of your RNN and FFN modules could get concatenated before passed to your classification layer. In this way you allow the model to reason from a joint representation of both data modalities. Hope it helps.
