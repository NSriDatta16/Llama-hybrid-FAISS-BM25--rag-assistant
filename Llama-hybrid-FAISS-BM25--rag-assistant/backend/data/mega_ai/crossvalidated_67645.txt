[site]: crossvalidated
[post_id]: 67645
[parent_id]: 
[tags]: 
Valid way to highlight trends in growing data set

I have a summer research project that I'm currently working on that involves face recognition during a video capture session. I currently have an algorithm that returns a ranking of the closest matching results along with a similarity measurement that indicates how closely the input face image was matched. These similarity measurements are based on a comparison to gallery face images on which the algorithm has been trained. As of right now, the application simply continually captures a frame from the video that contains a face image and then queries the algorithm until we get a top result that meets some similarity threshold that the user can set. However, we would like the application to have a "memory" so that it can capture information about the results that are consistently in the top rankings. For example, consider the case where we have a threshold of 65% and we get the following results(only showing top 3 rankings): Result 1 Jim--62% Mark--61% Jane--53% Result 2 Mark--62% Brian--55% Sarah--52% Result 3 Jane--56% Mark--53% Brian--49% Result 4 Brian--66% Mark--63.5% Sarah--57% The inconsistent top rankings seem to be a result of an idiosyncrasy of the algorithm which requires that the orientation/expression of the face closely match its associated training image. This is a crude example, but hopefully I've relayed the concept. In this situation, we would most likely want 'Mark' to be the label for the face since he is consistently placed in the top rankings, but the returned label for the face would be 'Brian'. The main problem is that if we simply aim for a top result with a similarity that meets our baseline target, we fail to take into account any consistent and relevant trends in the history of results, and that is the problem that I was hoping to get some assistance with. The naive approach that I've come up with is simply to continually compute the average of these similarity values, and simply assign the to the face the label with the highest associated current average. Unfortunately, this approach fails to take into account the ranking of the results, which seems like valuable information. One further thing to note is that we are using an eye detection algorithm to preprocess the images, which sometimes fails. If it does fail, we simply guess the locations of the eyes since they are usually in the same general locations in the detected face. If the eye detection does fail, we'd like those results to have less "weight" than those results for which the eye detection was successful. I'll admit that this is a somewhat new domain to me, so I was hoping someone could suggest to me a good statistical/machine learning technique to tackle this problem.
