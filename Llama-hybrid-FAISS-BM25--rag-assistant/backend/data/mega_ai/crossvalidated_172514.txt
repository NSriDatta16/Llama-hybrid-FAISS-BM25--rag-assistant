[site]: crossvalidated
[post_id]: 172514
[parent_id]: 172439
[tags]: 
It just happened that few days ago I read Marco Cuturi's paper on "Fast Global Alignment Kernels" [1] . The idea is to cast the well-known DTW distances as similarities eligible for use in kernel machines, e.g. SVM. You cannot directly transform DTW distance into similarity and hope it will work (e.g. negative exponential of distance) - you will get non positive definite kernel. The author proposed a novel technique with Global Alignment kernels such that the nice DTW properties are accessible as well as the kernel is positive definite. I have experimented with his code on several standard time-series classification datasets [2] and was pleasantly surprised of the performance. The beauty and power of his approach that it works for multivariate time-series as well. And oh, it works for different length time-series as well. Ten time-series might be too little to train a good classifier. Perhaps getting more examples is possible. The paper, implementations (C, MATLAB and Python) can be found [here] . UPDATE: Author's website has moved. Please use the following link to get paper and implementations [4] .
