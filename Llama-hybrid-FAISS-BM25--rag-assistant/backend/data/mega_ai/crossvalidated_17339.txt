[site]: crossvalidated
[post_id]: 17339
[parent_id]: 
[tags]: 
Guessing the appropriate 'distribution' of an observation to perform some form of sensitivity analysis

I wish to run some simulations on the 'estimates' of an event provided by experts (or historical data if available). For example: The technology manager of company X says that probably 300-1000 computers in the organization (out of say 100,000 in total) have Windows XP that needs to be phased out. Now this is an estimate, he's not sure of the number. Let's take 2 scenarios: It's worth spending time/money to sample and estimate (i.e., value of information is worth the effort) It's not worth the effort to perform any form of sampling and let's go with the estimate. In either case, I wish to 'simulate' this model (with other similar) variables. You may think of it is wanting to run Monte-Carlo Simulations, but I don't want to put a specific solution to the idea, for the sake of discussion. The question is then this - given sampling is done, can you 'guess' the appropriate probability distribution (I think this is doable, if I remember correctly from statistics, not sure though). And if sampling is NOT performed, how best to guess it? Note: If my question is 'fuzzy' I'll surely revise it as I receive some comments/answers to make it more clear. The example above may not be the best one but nevertheless let's go with it for the sake of example. If a better example is suggested, I'll surely add it to the question
