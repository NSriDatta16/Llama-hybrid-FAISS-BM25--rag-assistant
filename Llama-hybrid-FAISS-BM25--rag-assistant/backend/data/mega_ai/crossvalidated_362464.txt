[site]: crossvalidated
[post_id]: 362464
[parent_id]: 
[tags]: 
How does neural network training work, if there are A HUGE number of points that not differentiable?

When I first saw ReLu function, I would not guess it will work in neural network because there is a point that is not differentiable. But it seems works very well on modern neural network. My question is that, if we have a neural network with ReLu everywhere, then there are HUGE number of points that is not differentiable, then how to update the weights when we do not have the gradient at those points?
