[site]: crossvalidated
[post_id]: 304810
[parent_id]: 
[tags]: 
Is a frequentist approach to inference appropriate when working with non-repeatable data?

Jackman (2009) writes on p.xxxi-xxxii: Consider researchers analyzing cross-national data in economics, political science, or sociology, say, using national accounts data from the OECD. [...] one can feed the OECD data to a computer program, and have stan- dard errors and significance tests reported for various statistics (e.g. means, correlations, regressions) as usual. But what do those standard errors mean in this context? He concludes on p.xxxii that "adhering to a frequentist conception of probability in the face of non-repeatable data risks intellectual embarrassment" and is inappropriate. Is this correct? Jackman, S. (2009). Bayesian analysis for the social sciences . John Wiley & Sons.
