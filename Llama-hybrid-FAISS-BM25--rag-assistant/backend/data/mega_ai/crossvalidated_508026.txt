[site]: crossvalidated
[post_id]: 508026
[parent_id]: 
[tags]: 
why do we need to numeric the categorical features in Decision Tree

We know that we usually use one-hot encoding to numeric the categorical feature in Machine Learning (although not advised in tree). There are also many algorithms in Tree models to numeric the categorical feature like CatBoost , LightBGM e.t.c. But why do we need numeric in Tree? It seems the definition of Entropy , Gini impurity are both available for the discrete variables and the decision tree algorithms like ID3 and C4.5 both work for the categorical feature. The only problem seems from the regression tree . Can anyone explain more on this party?
