[site]: crossvalidated
[post_id]: 508876
[parent_id]: 
[tags]: 
Distance measure in word2vec

I am currently learning about word embedding and word2vec, and I am having a hard time understanding how the similarity between words is measured in that representation. I have often read that the cosine distance, ergo the angle between vectors, is used for calculate similarity. I'll illustrate my problem with this example, which shows a simplified representation in the latent word2vec space and discriminates between farm animals and pets: Here the vector for "Dog" has approximately the same direction as the vector for "Cow", thereby they would be classified as very similar in terms of cosine distance. Also, the distance between "Cat, Dog" would be way bigger than ""Cow, Horse", since they are closer to the origin. Considering this example, how is cosine distance a valid distance measure in word2vec?
