[site]: crossvalidated
[post_id]: 503061
[parent_id]: 
[tags]: 
Using counterfactual modeling techniques to assess racial bias in predictive models

My team at a health insurance company is discussing how we might measure racial bias in the various predictive models our company uses to assess future health risk (such as annual medical cost or probability of major surgery). This has jumped to the priority following the recently published article in Science (Obermeyer et al., 2019). One suggestion at assessing bias is to run chi-squared tests on the predicted outcomes among race or ethnicity categories. This seems too simplistic to me - surely we want to control for confounding factors if we want an unbiased estimate of bias(!). This leads to an unusual proposition of conducting a causal inference on predictive model outcomes in order to estimate the average causal effect of race. The same methodology could then be applied to measure model bias in ethnicity, age, gender, etc. Question: Is it a valid approach to use a counterfactual model (i.e., multiple regression, exact matching, propensity score matching, etc.) to measure racial bias in predictive model outcomes by using the same data used to build the predictive model?
