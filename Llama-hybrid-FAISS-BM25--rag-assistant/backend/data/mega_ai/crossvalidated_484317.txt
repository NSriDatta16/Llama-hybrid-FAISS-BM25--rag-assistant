[site]: crossvalidated
[post_id]: 484317
[parent_id]: 
[tags]: 
Why bother doing time series split?

From informal guides to peer-reviewed papers, I find this advice time and time again: you should always split your time series respecting the order of the events. This would make sure you don't break the temporal properties of the data. But machine learning models (at least the basic variants) consider the error of every single data point separately, never being aware that there is some data point before that. In other words, there is no concept of time in the models. Therefore, the training algorithm is never going to make use of any temporal ordering (this can be amended with lagged features). So how does regular random splitting hurt when dealing with time series?
