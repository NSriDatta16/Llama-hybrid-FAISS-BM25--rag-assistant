[site]: crossvalidated
[post_id]: 442823
[parent_id]: 
[tags]: 
Proposal Metropolis distribution for complex Bayesian models

In the book Uncertainty Quantification: Theory, Implementation, and Applications , by R.C. Smith, there is a chapter about Bayesian inference. The likelihood is Gaussian, with error variance $\sigma^2$ that may be constant or random: $Y|q,\sigma^2\sim\prod_{i} \text{Normal}(f_i(q),\sigma^2)$ . Here $Y$ (response) and $q$ are random vectors, and $f_i$ are deterministic functions. The prior distributions are $q\sim\pi(q)$ , $\sigma^2\sim\pi(\sigma^2)$ . The author shows the Metropolis algorithm for the simulation of the posterior distribution, $\pi(q,\sigma^2|d)$ , where $d$ is the data on the response. If you do not have the book, nothing happens, as I will ask the question self-contained. The Metropolis algorithm requires the use of a proposal distribution. Although the Markov chain converges for any proposal distribution, the choice becomes important in terms of convergence rapidity. The author proposes that the proposal distribution be Gaussian, with covariance matrix given by the covariance matrix of the estimator from nonlinear regression (frequentist method). That is, if $J(\theta'|\theta)$ is the proposal distribution, then $J(\theta'|\theta)\sim\text{Gaussian}(\theta,V)$ , where $V=\hat{\sigma}^2(X^T(\hat{q})X(\hat{q}))^{-1}$ , being $\hat{q}$ the maximum likelihood estimator (least-squares fitting), $\hat{\sigma}^2$ the estimated error variance from the nonlinear regression (quotient of mean square error and number of observations minus parameters), and $X$ the Jacobian matrix of the map $\{f_i\}_i$ that defines the model (if it were linear regression, it would just be the matrix of covariates). Hence, this method acts in the spirit of empirical Bayes (the data is employed beyond the likelihood). My question is whether, for complex models, there are other choices of the proposal distribution that work. It seems that the shape of the proposal distribution should be as similar as possible to the unknown posterior distribution. As the asymptotic behavior of the Bayesian estimator is Gaussian with covariance matrix precisely estimated as such $V$ , I wonder if empirical Bayes is "optimal" in this setting.
