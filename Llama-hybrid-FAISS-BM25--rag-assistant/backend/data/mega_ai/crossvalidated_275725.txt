[site]: crossvalidated
[post_id]: 275725
[parent_id]: 
[tags]: 
Suspiciously high shrinkage in random effects logistic regression

Consider the following simple example: library( rms ) library( lme4 ) params $Ns ) ), Res = do.call( c, apply( params, 1, function( x ) c( rep( 0, x[ 1 ]-round( x[ 1 ]*x[ 2 ] ) ), rep( 1, round( x[ 1 ]*x[ 2 ] ) ) ) ) ) ) tapply( SimData$ Res, SimData$ID, mean ) dd I.e. we are giving a fixed effects and a random effects model for the the same, very simple problem (logistic regression, intercept only). This is how the fixed effects model looks like: plot( summary( fitFE ) ) And this is how random effects: dotplot( ranef( fitRE, condVar = TRUE ) ) The shrinkage is not surprising itself, but its extent is. Here is a more direct comparison: xyplot( plogis(fe)~plogis(re), data = data.frame( re = coef( fitRE )$ID[ , 1 ], fe = c( 0, coef( fitFE )[ -1 ] ) + coef( fitFE )[ 1 ] ), abline = c( 0, 1 ) ) The fixed effects estimates range from less then 3% to more than 11, the random effects, however, are between 7.5 and 9.5%. (Inclusion of covariates makes this even more extreme.) I'm no expert in random effects in logistic regression, but from linear regression, I was under the impression that so substantial shrinkage can occur only from very-very small group sizes. Here, however, even the smallest group has almost a hundred observation, and sample sizes go above 500. What is the reason for this? Or am I overlooking something...? EDIT (Jul 28, 2017). As per @Ben Bolker's suggestion, I tried what happens if the response is continuous (so that we remove problems about effective sample size, which is specific for binomial data). The new SimData is therefore SimData $Res, SimData$ ID, mean ), Res2 = tapply( SimData $Res2, SimData$ ID, mean ) ) and the new models are fitFE2 The result with xyplot( fe ~ re, data = data.frame( re = coef( fitRE2 )$ID[ , 1 ], fe = c( 0, coef( fitFE2 )[ -1 ] ) + coef( fitFE2 )[ 1 ] ), abline = c( 0, 1 ) ) is So far so good! However, I decided to perform another check to verify Ben's idea, but the outcome turned out to be pretty bizarre. I decided to check the theory another way: I return to binary outcome, but increase the means so that effective sample sizes get bigger. I simply ran params$means and then retried the original example, here is the result: Despite the minimum (effective) sample size indeed drastically increasing ... > summary(with(SimData,tapply(Res,list(ID), + function(x) min(sum(x==0), sum(x==1))))) Min. 1st Qu. Median Mean 3rd Qu. Max. 33.0 72.5 86.0 100.3 117.5 211.0 ... the shrinkage actually increased ! (Becoming total, with zero variance estimated.)
