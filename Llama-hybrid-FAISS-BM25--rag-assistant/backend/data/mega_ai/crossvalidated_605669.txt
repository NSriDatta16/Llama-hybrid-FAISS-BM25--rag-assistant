[site]: crossvalidated
[post_id]: 605669
[parent_id]: 605539
[tags]: 
Let's consider a strategy that stays in room $A$ until a diamond is found, even if it means all 15 trials are needed, and only switches to room $B$ if a diamond is found and we haven't used up all 15 trials. We are assured of finding the diamond in room $A$ , so the expected value of this strategy ( $V_1$ ) is at least equal to $1$ . In fact, if we find the diamond before the $15^{th}$ trial, there is a nonzero probability that we will also find the diamond in room $B$ in the remaining trials; therefore, $V_1 > 1$ . (We don't need to calculate it exactly for what follows, easy though that may be.) Now let's compare this to a strategy that switches to room $B$ after $k \geq 0$ failures. (Obviously we will always switch to room $B$ after a success.) The expected value $V_2(k)$ of switching is just the probability of finding the diamond in room $B$ : $$V_2(k) = {15-k\over 15} = 1 - {k\over 15} \leq 1 Therefore, it never pays to switch before finding the diamond. To generalize this, let's fix the value of the diamond in room $A$ at $1$ with no loss of generality. We set the value of the diamond in room $B$ equal to $v_B$ and the value of the "extra" diamond at $v_E$ . The expected value of strategy $1$ is equal to the value of the diamond in room $A$ ( $1$ ) plus the probability of finding the diamond in room $B$ times the value of doing so given that we found the diamond in room $A$ . Since, on average, we will require $15/2 = 7.5$ trials to find the diamond in room $A$ , we will have, on average, $7.5$ trials in room $B$ , which gives us a $50\%$ chance of finding the diamond: $$V_1 = 1 + 0.5(v_B + v_E)$$ The value of switching after $k$ failures is: $$V_2(k) = \left(1 - {k \over 15}\right)v_B$$ Obviously this will be maximized at $k=0$ , with associated value $v_B$ . Therefore, we switch immediately if and only if: $$v_B > 1 + 0.5(v_B + v_E)$$ A little algebra leads to a simpler version of this condition: $$v_B > 2 + v_E$$
