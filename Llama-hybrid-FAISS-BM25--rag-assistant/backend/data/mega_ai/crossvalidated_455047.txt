[site]: crossvalidated
[post_id]: 455047
[parent_id]: 455004
[tags]: 
The discount factor $\gamma$ is applied to the scalar sum of future rewards. It changes how much a single measure of future reward will contribute to an update step. The trace decay $\lambda$ is applied to the weight update vector . It changes which weights receive an update, and in which proportion. When updating the trace it must also take into account the discount factor, but the value function update itself uses $\gamma$ but not $\lambda$ . In addition, the upadte step for the eligilibity vector is different to and separate from the value function estimate updates, so it will evolve differently as the agent progresses through the state trajectory on each time step.
