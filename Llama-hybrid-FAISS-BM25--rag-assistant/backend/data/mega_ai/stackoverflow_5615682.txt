[site]: stackoverflow
[post_id]: 5615682
[parent_id]: 
[tags]: 
Make search bots to not crawl a deleted page?

Currently we are using a Kentico CMS for out web site and we used to have a page called pages/page1.aspx. We removed that page but every day the google, bing and yahoo sarch robot tries to read that page. Because the page doesn't exist the CMS throws the following error (in the log) Event URL: /pages/page1.aspx URL referrer: User agent: Mozilla/5.0 (compatible; Yahoo! Slurp; http://help.yahoo.com/help/us/ysearch/slurp) Message: The file '/pages/page1.aspx' does not exist. Stack Trace: at System.Web.UI.Util.CheckVirtualFileExists(VirtualPath virtualPath) // and the rest of the stacktrace When we get too many of these errors the whole site crashes (have to clear .Net temp files and restart app pool). Basically I can go to a page that doesn't exist, hit refresh many times and take the site down. Extremely bad. However, first thing, how can I get the bots to not try to access this page? Thanks in advance.
