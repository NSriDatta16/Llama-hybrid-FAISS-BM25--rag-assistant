[site]: crossvalidated
[post_id]: 80787
[parent_id]: 80748
[tags]: 
The null hypothesis behind backbone methods is [The] normalized weights that correspond to the connections of a certain node of degree k are produced by a random assignment from a uniform distribution. If there aren't any "significant" edges, the null hypothesis holds for the entire graph, i.e., edge weights result from nodal propensities to send and receive ties. Depending on the relationships you're analyzing, the backbone method might not be appropriate. The method works best for networks that are conceptually one-mode weighted networks. Two-mode networks can be projected as a weighted one-mode network, but it often doesn't make sense to do so. Drawing upon your example in the Economist, it doesn't make sense to analyze Senate voting as a one-mode network weighted by the number of shared votes. Voting in the Senate is a signed, two-mode relationship. Senators (i) have relationships to a pieces of legislation (j) and they either abstain from voting (0) or they vote for (+1) or against (-1) the legislation. To transform the network into a weighted one-mode agreement network, then perform a backbone analysis on it would be a severe reduction of data. Some pieces of legislation are more politically divisive and some have more votes than others--backbone methods wouldn't capture these mechanisms. You may want to consider Conditional Uniform Graph (CUG) tests instead of backbone methods. The idea behind these tests is to determine if certain graph-level properties (e.g., clustering, average path length, centralization, homophily) result from chance. The process is as follows: Take measurement f from the observed graph Generate a random graph that controls for certain properties of the observed graph (e.g., size, number of edges, degree distribution, etc) Take measurement f from the random graph Repeat steps 2 and 3 many times (e.g., 1000) to produce a null distribution Compare the observed measurement to the null distribution For two-mode networks, it would make sense to create the random graph by permuting the observed graph (both tnet and statnet in R have routines for permuting two-mode networks). If measurement f requires a one-mode network, the randomization process should be done on the two-mode network before projecting it as a one-mode network.
