[site]: crossvalidated
[post_id]: 120364
[parent_id]: 120329
[tags]: 
The logit is a link function / a transformation of a parameter. It is the logarithm of the odds. If we call the parameter $\pi$, it is defined as follows: $$ {\rm logit}(\pi) = \log\bigg(\frac{\pi}{1-\pi}\bigg) $$ The logistic function is the inverse of the logit. If we have a value, $x$, the logistic is: $$ {\rm logistic}(x) = \frac{e^x}{1+e^x} $$ Thus (using matrix notation where $\boldsymbol X$ is an $N\times p$ matrix and $\boldsymbol\beta$ is a $p\times 1$ vector), logit regression is: $$ \log\bigg(\frac{\pi}{1-\pi}\bigg) = \boldsymbol{X\beta} $$ and logistic regression is: $$ \pi = \frac{e^\boldsymbol{X\beta}}{1+e^\boldsymbol{X\beta}} $$ For more information about these topics, it may help you to read my answer here: Difference between logit and probit models . The odds of an event is the probability of the event divided by the probability of the event not occurring. Exponentiating the logit will give the odds. Likewise, you can get the odds by taking the output of the logistic and dividing it by 1 minus the logistic. That is: $$ {\rm odds} = \exp({\rm logit}(\pi)) = \frac{{\rm logistic}(x)}{1-{\rm logistic}(x)} $$ For more on probabilities and odds, and how logistic regression is related to them, it may help you to read my answer here: Interpretation of simple predictions to odds ratios in logistic regression .
