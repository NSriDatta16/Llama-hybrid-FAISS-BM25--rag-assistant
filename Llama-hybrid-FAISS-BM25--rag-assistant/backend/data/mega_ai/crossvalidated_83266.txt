[site]: crossvalidated
[post_id]: 83266
[parent_id]: 
[tags]: 
Particle filters and loopy belief propagation

I want to implement a loopy belief propagation algorithm for factor graphs with continuous variables and messages represented using particles, that is vectors of samples for an empirical distributions. All the works about particle filters that I have found consider either Markov Random Fields with unary and binary terms only or temporal sequences (Hidden Markov Models). In the case of a general factor graph, one needs to compute expressions like $$ m_{g_p\rightarrow z_q}(z_q)=\int_{z_1}\int_{z_2}\int_{z_3}g_p(z_1,z_2,z_3,z_q) m_{z_1\rightarrow g_p}(z_1)m_{z_2\rightarrow g_p}(z_2)m_{z_3\rightarrow g_p}(z_3) {\rm d}z_1{\rm d}z_2{\rm d}z_3. $$ This is the expression for the message going from the factor node $g_p$ to the variable node $z_q$ where $g_p(z_1,z_2,z_3,z_q)$ is function with known closed for expression and the messages $m_{z_i\rightarrow g_p}(z_i)$ are defined by particle distribution. All the equations I have see have only one of these particle terms; what I would like like to understand is the proper way to extend importance sampling and in general particle/MCMC algorithm to the case where you have products of particles. I know that $m_{z_i\rightarrow g_p}(z_i)$ can be written as a sum of weighted Diracs, however I am not sure about how to compute the products. Any pointers to relevant literature are highly appreciated.
