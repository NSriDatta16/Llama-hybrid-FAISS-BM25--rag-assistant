[site]: crossvalidated
[post_id]: 320514
[parent_id]: 320388
[tags]: 
A neural network is a function approximator, where as an RBM is a probabilistic graphical model. Although the equations may seem superficially similar, it's best not to confuse the two ideas. In a probabilistic model, you have probability distributions on the value of the nodes in your graph. So the equation you wrote above for ANN does make sense in the case of RBMs. In an RBM, the joint distribution over all variables is: $$P(x,h) \propto \exp (b^Tv + a^Th + h^TWv)$$ In the case of binary RBM, if you condition on $x$, you'll end up with $$P(h|x) = \sigma(a+Wx)$$ Obviously, $b$ wouldn't show up in this equation because $x$ is fixed, and $b$ only influences the joint probability through $x$. So even though this equation is very similar to the ANN equation, the interpretation is quite different.
