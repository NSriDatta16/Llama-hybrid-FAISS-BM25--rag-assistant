[site]: crossvalidated
[post_id]: 637600
[parent_id]: 
[tags]: 
AdaBoost in Matlab - Only get 88% accuracy with Fisher's Iris data set while 100% in one layer Neural Network

I have made AdaBoost in Matlab. I get 88% in accuracy when I use Fisher's Iris flower set data. Here is the working example: data = load('fisheriris.mat'); X = data.meas; y = strcmp(data.species,'setosa') * 2 - 1; X_train = X(1:50, :); y_train = y(1:50); X_test = X(101:end, :); y_test = y(101:end); % Adaboost classification with 5 weak classifiers N = 5; [mode, accuracy] = adaboost(X_train, X_test, y_train, y_test, N); fprintf('Accuracy AdaBoost: %.2f%%\n', accuracy * 100); And here is the AdaBoost in Matlab. This will return back a model function [models, accuracy] = adaboost(varargin) % Check if there is any input if(isempty(varargin)) error('Missing inputs') end % Get the train data if(length(varargin) >= 1) X_train = varargin{1}; else error('Missing train data') end % Get the test data if(length(varargin) >= 2) X_test = varargin{2}; else error('Missing test data') end % Get the train labels if(length(varargin) >= 3) y_train = varargin{3}; else error('Missing train labels y') end % Get the test labels if(length(varargin) >= 4) y_test = varargin{4}; else error('Missing test labels y') end % Get the amount of models if(length(varargin) >= 5) N = varargin{5}; else N = size(X_train, 2); end % Fit a model models = train(X_train, y_train, N); % Do prediction y_pred = predict(models, X_test, N); % Find the accuracy accuracy = procent(y_test, y_pred); end function models = train(X, y, N) % Get the size of the data [m, n] = size(X); % Create weights w = ones(m, 1) / m; % Create model models = {}; % Begin the training for i = 1:N % Create a basic weak classifier, we choose a Decision Stump model.polarity = 1; model.feature_idx = []; model.threshold = []; model.alpha = []; % Declare the minimum error of the weak classifier as 1.0 min_error = 1.0; % Iterate by finding the column that the weak classificer separates most for j = 1:n % Cut one row X_column = X(:, j); % Sorting, very important thresholds = unique(X_column); % Iterate the sorted row for threshold = thresholds' % Check which one that is below the threshold p = 1; predictions = ones(m, 1); predictions(X_column > threshold) = -1; % Which ones are missclassified misclassified = w(y == predictions); error = sum(misclassified); % Compte the error if error > 0.5 error = 1 - error; p = -1; end % Update the model if error model.threshold) = -1; end end Result: I get 88% in accuracy with this AdaBoost model settings N = 5 . I trying with an one-layer neural network from MataveID % Neural network - One layer C = 1; lambda = 1; X_train = X([1:20 51:70 101:120], :); y_train = y([1:20 51:70 101:120]); X_test = X([21:50 71:100 121:150], :); y_test = y([21:50 71:100 121:150]); [weight, bias, activation_function] = mi.nn(X_train, y_train, C, lambda); % Validate y_pred = sign(X_test*weight' + bias); accuracy = sum(y_test == y_pred) / length(y_test); fprintf('Accuracy Neural Network: %.2f%%\n', accuracy * 100); And I will get 100% accuracy. Question: Is the AdaBoost algorithm correctly written? I mean...the one layer neural network is just one layer neural network with one activation function sign . AdaBoost is famous for handle nonlinear data perfectly and should be consider if the data is complex.
