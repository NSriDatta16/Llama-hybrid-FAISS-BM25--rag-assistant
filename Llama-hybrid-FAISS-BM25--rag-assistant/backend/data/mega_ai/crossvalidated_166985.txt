[site]: crossvalidated
[post_id]: 166985
[parent_id]: 166928
[tags]: 
In short, no they are not the same. In artificial neural networks as well as real neural networks inside the brain, features can be encoded in multiple ways. It might be helpful to have a concrete example. In biology, the visual system is often used as an example of neural encoding. I feel like it also provides a good illustration of how we could understand feature encoding in artificial networks. A presentation of feature encoding in the visual system can be found here: http://cdn.intechopen.com/pdfs-wm/332.pdf In particular, take a look at figure 3a, which depicts encoding of an oriented edge in the retina. At the level of the input layer, rods and cones in the visual system, an oriented edge (a single feature) would be represented by the activity of a group of neurons. The hidden layer (bipolar cells in the retina) has a somewhat more abstract encoding that may be difficult to conceptualise. At the output layer (ganglion cells) the feature is encoded by the activity of a single neuron. So at different levels of processing features can be encoded in different ways. In this example, the feature is encoded by a population of neurons at the input and by a single neuron at the output. In more complicated examples, the output may also involve activity from a population. So far, we have implicitly assumed that neurons are normally off, and turn on when presented with a preferred stimulus, so that features would be encoded by a population turning on. But it's also possible to have more complicated schemes where features can be encoded in terms of the response amplitude, frequency and/or phase of a single neuron or population of neurons.
