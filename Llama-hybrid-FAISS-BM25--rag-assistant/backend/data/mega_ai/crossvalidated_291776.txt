[site]: crossvalidated
[post_id]: 291776
[parent_id]: 
[tags]: 
Causal Inference Between Linearly Related Measures Using Solomonoff Induction Approximation

Solomonoff Induction is considered the gold standard for machine learning because it can learn causal structure with the minimum error . However its chief component, the Kolmogorov program representing the data being modeled, is incomputable . Therefore approximations of the Kolmogorov program are necessary. When the data is a table ( with each measure a column and each row an object of the population ) and the measures are all linearly related to each other , the Kolmogorov program may be approximated by a directed acyclic graph with each measure a node, such that: measures that are most informative are ancestral to those that are least informative each arc is associated with a weight each node's value is a sum of weighted products plus a bias the complexity of the graph, in bits, is added to the number of bits required to correct for all of the residual errors, thereby approximating the DAG's Kolmogorov Complexity's requisite lossless compression Minimizing the Kolmogorov Complexity approximation of said table then provides the Solomonoff Induction approximation of the causal DAG. What are the techniques for finding this DAG in statistics and or machine learning?
