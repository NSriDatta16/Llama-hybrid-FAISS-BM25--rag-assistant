[site]: crossvalidated
[post_id]: 592612
[parent_id]: 592535
[tags]: 
Wow, professor 1 seems to suffer from a massive reverse Dunning-Kruger effect. In essence, I know a lot about one thing therefore I am an expert in all things. A little humility on his part is required. The problem of course is that: He doesn't understand the model building process. Sure, he has examined it. He's been tested on it. He knows a lot about it, but he doesn't understand it. The point he seems to be making having read through your post is that your model, when trained on data that came from a group, will essentially predict something about the group instead of the individual. This is, of course correct. However, he seems to equivocate this with predicting the mean of the group given some covariates. On average, this is correct and what we do when modelling. However, we can predict 95th percentiles, medians, variance, or any other meaningful statistic for the group. We then apply it to the individual. He seems very smug about the fact that we can't know anything about the individual. And the points he makes are valid. Of course, you can train a model on data that comes from a single individual and make inferences based off of that. Economists do it all the time. There is only 1 U.S. economy after all, and you can design statistical methods to make inferences on that one individual. Usually, you are stuck with time-series type models in those cases, but it can be done. However, even if you don't what about conjoint analysis where you give a subject a battery of choices in a survey. With enough choice pairs, you can generate a rigorous enough sample to make inferences on an individuals behavior. Again your professor doesn't seem very familiar with these actual scientific methods that can work on an individual basis. The question isn't can you predict on an individual, the validity of his argument is based on what is the unit of observation, and he just doesn't seem to have much experience with a wide-breadth of different observational units other than individuals. I won't fault him for this lack of experience but I will fault him for spreading disinformation onto unsuspecting students based on his ignorance. Your professor sneers because the data science isn't "rigorous". What he really means by that isn't that there is no mathematical rigor or that there isn't even empirical rigor, or even statistical rigor. What he means is that the models aren't causal. That seems to be his biggest beef. I'll return to statistical rigor in my next point, but for now let's focus on causality. Causality is hard. And a research method class is all about trying to look for causal relationships. You want to design your experiments so that you can say that A causes B to happen. You don't want to have A and B caused simultaneously by something else, or for B to cause A. You are testing A causes B. That is the point of this class. Never lose sight of that one fact. I think this professor has lost the forest for the trees. He isn't looking at it from that perspective any longer. He's looking at research methods as its own thing that must be protected from encroachment. That's kind of sad, because it means that he has actually given up on scientific curiosity. The root of all scientific curiosity is this question: "What if?". He has closed his mind to the possibilities that these new methods could be useful. What if I could use a random forest in a causal way to do "rigorous" scientific research? What would that take? And thus he has closed entire lines of research into new methods for himself. That's sad. Statistical rigor. These data science models do not fit neatly into his paradigm of statistics. Therefore, they do not exhibit any statistical rigor at all. However, a model like random forest does fit into this paradigm pretty easily, if instead of using mean squared error, you used a normally distributed, maximum likelihood loss (which is equivalent to mean squared error if you hang some additional assumptions on your model) then it becomes statistically meaningful. Same with binary cross-entropy loss, add a couple of assumptions and it all works out. The problem is the parameters of your model become much less meaningful. And that gets back to the causality, what the hell does your model even mean? He seems to want to get to a point where he can say something. Again that is a noble pursuit, but is a correlation really all that bad? Sure, you can make mistakes with correlation, but if you've got an underlying theory, you might be willing to take those risks in your prediction. Here's an example: I want to predict whether or not someone will buy my product. If I know their income, can I spit out a probability that they will make that purchase? Of course, with enough data I can. Why? Because income/wealth effects are real according to theory. So, do I need to spend all that time and energy in proving that to be the case to use it? Of course not. Just utilize the correlation, it might be slightly off but the broad strokes are likely just fine. He also seems to equate uncertainty with bad. Surely, this one is a fine point. Except, every time I get in my car there is uncertainty around whether or not something mechanical will break lose and cause me to crash and die. The truth is, you deal with uncertainty with tolerances. This goes back to his bridge analogy. What is your tolerance for failure? If the first bridge spans a 1000 foot drop over spikey rocks, I am with him, I want a bridge that has been rigorously tested. If the bridge is a 2 foot fall over a small stream with rounded pebbles at the bottom of it. I will be annoyed if the bridge falls apart when I cross it, but it didn't cause too much distress. Tolerances are important and drug discovery is a high stakes, low tolerance environment, whereas, say recommending a skirt to a potential customer is a low stakes, high tolerance environment.
