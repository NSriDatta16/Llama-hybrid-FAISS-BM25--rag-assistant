[site]: datascience
[post_id]: 18829
[parent_id]: 
[tags]: 
Methods for string classifications

I have a list of some 100 millions of strings, each of different length. Examples: nsdgnlnesef ngmrlxkvgrmksefsfnlj rnrfnmsbanana housemgslen assistremovecouch As you can see the strings vary in length and some can include english words, some not, some both words and random characters. All use the characters [a-z]. It is possible to characterise the strings are being humanly created or by a algorithm with a reasonable certainty. Later I aim to also classify between different sub-types of algorithms generating these strings ( multiclass classification ). The 100 millions strings I have are already labeled, based on other analysis. But because this is a very slow task, I will use Machine Learning to try and predict the origin of new strings as we get new data. The methods I have started with are bigrams , Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) . I will eventually also run trigrams. As both time and accuracy are very important factors of the method I eventually choose, I want to make sure I test as many as possible. But since there is a forest of methods, I hope to get some helpful advice here. I imagine methods based on features, such as Random Forest and Support Vector Machine could be useful, but I haven't them used before, and I am not certain if they or other methods could handle 100 millions of strings in an efficient way. Any suggestions for methods to look at are very welcomed.
