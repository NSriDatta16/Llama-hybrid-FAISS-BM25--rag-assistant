[site]: crossvalidated
[post_id]: 377401
[parent_id]: 377397
[tags]: 
Parameters and dependent variables are completely different concepts. Dependent variables are the target that you want to measure as a function of your independent variable. For example, if you have information about a person's height and weight, you might try to make an inference about the person's gender (classification) or age (regression). Parameters are the quantity that you optimize to make better predictions. In a neural network, this is usually the composition of several functions ("layers"). For example, a neural network with one hidden layer predicts the dependent variable using $f(A(f(Bx+c)+d)$ where $x$ is your independent variable (feature vector), and $f$ the activation function and $A, B, c, d$ are all parameters of appropriate shape (dimension). Special cases of neural networks with no hidden layers correspond to different generalized-linear-model s. For example, if the activation $f$ is the softmax function, the result is a logistic regression. If $f$ is the identity function, the result is OLS. The independent and dependent variables are the same: inputs are independent variables, outputs are dependent variables. Hopefully this gives you some intuition to unify regression terminology (independent & dependent variables) with neural network terminology.
