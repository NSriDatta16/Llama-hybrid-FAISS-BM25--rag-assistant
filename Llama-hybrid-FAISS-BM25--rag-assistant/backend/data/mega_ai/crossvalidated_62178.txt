[site]: crossvalidated
[post_id]: 62178
[parent_id]: 62176
[tags]: 
The different hyperplanes are given by optima of their respective objective function. For PCA this will be maximization of retained variance. For SVM, it's the hyperplane with the maximum margin separating two classes. The hyperplanes can differ wildly, since you can construct a data set of two classes which is best separated in the direction of lowest variance. Btw, this is only the case for a linear SVM. If you are using a Kernel, you are not necessarily projecting to an n-1 dimensional space.
