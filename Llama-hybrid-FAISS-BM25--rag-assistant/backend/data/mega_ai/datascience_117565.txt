[site]: datascience
[post_id]: 117565
[parent_id]: 117563
[tags]: 
LSTMs/GRUs have lower computational and memory requirements than transformers. Depending on the case, using an LSTM instead of a Transformer may make sense due to those factors. For instance, using Transformers on mobile devices or embedded devices with CPU and memory limitations is not easy. Also, in machine translation, having a Transformer encoder and an LSTM decoder may not significantly impact the resulting translation quality.
