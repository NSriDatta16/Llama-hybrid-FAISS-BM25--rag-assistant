[site]: crossvalidated
[post_id]: 532063
[parent_id]: 531978
[tags]: 
Then how to deal with such correlated samples? This boils down to how these systems are trained, i.e., sequence-to-sequence training. If we do that, the correlation structure is preserved, such as LSTMs or any RNN's training. machine learning algorithm is not a proper way to deal with the time series? Correlations are encoded in the models such as Gaussian process regression requires covariance matrix i.e., Kernel matrices, these matrices encodes training sample's correlation structure. See Usual covariance functions . The assumption of i.i.d. samples is actually not necessary for the machine learning algorithm? Time-series modelling may not be classified as "vanilla supervised learning". So from statistical learning theory perspective, they are special class of models with added assumptions. So, how time-series model's set up will not justify the argument of i.i.d. samples is actually not necessary for the machine learning algorithm .
