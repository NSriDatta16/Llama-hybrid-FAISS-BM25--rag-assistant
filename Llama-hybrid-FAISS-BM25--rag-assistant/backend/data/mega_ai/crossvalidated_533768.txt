[site]: crossvalidated
[post_id]: 533768
[parent_id]: 533759
[tags]: 
The general field you are alluding to is referred to as density estimation . Various approaches within can be treated across two high level categories: Parametric Approach Maximum likelihood estimators (or Bayesian Estimators) are commonly employed to infer the parameter vector that characterizes the assumed distribution from the data. The key here is "assumed", and it is justifiable only if you have some valid reason to believe that the data at hand can be modeled by a known parametric family of distributions. Non-parametric Approach A histogram is a simple and ubiquitous form of a non-parametric density estimate. Many non-parametric approaches are extensions of the classical histogram, for instance a kernel density estimator. Usually, the much weaker assumption you have to make here is that the underlying density is smooth, e.g. continuously differentiable. This is a good source with examples. Whether parametric or non-parametric, one thing to note is that multivariate densities are usually much harder to estimate, due to the curse of dimensionality . Python's ever-growingly encompassing library scikit-learn has some good coverage on Kernel density estimators. You can find it here . I have only included practical links here. If anything tickles your fancy, Google Scholar: "density estimation" is your friend.
