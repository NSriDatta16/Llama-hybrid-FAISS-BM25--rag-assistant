[site]: crossvalidated
[post_id]: 467590
[parent_id]: 467583
[tags]: 
It depends. You can measure prediction quality by cross-validation and the like, and this doesn't require some assumptions such as normality and linearity. If the assumptions are fulfilled, you are in a better position for achieving a good prediction result, however this is not a theorem and applies sometimes but not always (for example a truly linear system with large variance will yield worse OLS predictions than a slightly nonlinear one with a small variance, at least if the nonlinearity is suitable for linear approximation). However, you may be interested in future prediction in regions in which you currently don't have test data, and then "slight nonlinearity" may play out much worse than you can assess from the data you have. Furthermore, standard estimation of the prediction error with test and training sets still requires independence and identical distribution (given explanatory variables $x$ ) of test and training set, and of both regarding any future observations that you actually want to predict. If this is violated and you don't know how exactly, you cannot assess the prediction error in any reliable way. PS: "If they do matter, then why are they not taken into consideration when we do linear regression in machine learning?" Well, everybody who ignores these things does so at their own peril...
