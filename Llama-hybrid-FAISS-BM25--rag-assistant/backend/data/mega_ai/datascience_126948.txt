[site]: datascience
[post_id]: 126948
[parent_id]: 
[tags]: 
Why is there a difference in Training Accuracy Output, when the training dataset is the same but the validation dataset is different?

I am looking at the output of a multi-class image segmentation deep learning model. I used U-Net to implement this. I am confused about why the training accuracies are different for a different validation dataset when using the same training dataset and exactly the SAME model. Note: The hyperparameters are set as same for both cases. a) Adams optimizer: lr = 0.001 b) batch size = 1 (Yes, I know I will need to use a bigger batch size; this is only a test) c) epoch = 1000 The only difference is a) Augmented uses 48 images for validation b) Pseudo-Augmented use of 2 images for validation. Thank you in advance. The output is shown below.
