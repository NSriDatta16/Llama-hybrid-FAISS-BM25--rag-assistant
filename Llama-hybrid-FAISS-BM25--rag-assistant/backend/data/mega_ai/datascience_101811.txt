[site]: datascience
[post_id]: 101811
[parent_id]: 101801
[tags]: 
In a linear regression, "one hot" encoding (aka "dummies") would introduce a own intercept term for each of the bins while treating the variable as numeric would introduce one (linear) slope coefficient for the bins. Treating the variable as "one hot" in a linear model will be more flexible (and will capture the positive correlation as well) since there is no forced (linear) parameterization. However, in other model types, such as random forest (which is non-parametric), "one hot" will not necessarily work well (or better), i.e. if each single category of the one hot encoded variable has little explanatory power. So treating the variable as numeric (e.g. by median value) may work better in this case. Basically, "one hot" encoding and numeric encoding transports pretty much the same information. The question here seems to be which model type can digest the one or the other encoding better. So if you can afford it, I would suggest trying both (one hot and numeric encoding) in different models.
