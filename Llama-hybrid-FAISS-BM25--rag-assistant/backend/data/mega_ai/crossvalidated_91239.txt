[site]: crossvalidated
[post_id]: 91239
[parent_id]: 
[tags]: 
Autoregressive Markov chain simulation and the likelihood ratio test for Markov property

I am trying to estimate a Markov chain of second order (Markov chain that fulfills $P[X_t|X_{t-1},X_{t-2}]=P[X_t|X_{t-1},X_{t-2},...,X_{t-p}]$) using an AR(2) process. Once I have simulated the chain I want to test the hypothesis of first order Markov property $H_0$ against second order Markov property $H_1$ using the Likelihood ratio test. So far it has worked out OK except that the test resulted in a rejection of the null hypothesis for some estimated parameters of the AR(2) process. Let us start from the beginning: Pick different values for the autocovariation function $\gamma(k)=Cov[X_t,X_{t-k}]$ of the AR(2) process, $\gamma(1), \gamma(2), \gamma(0)$. $\gamma(1)$ and $\gamma(2)$ will be varying from 0.3 to 0.8 (in 0.1 steps) and the variance i.e. $\gamma(0)$ will be set equal to 1 for all combinations. Next we estimate the parameters $a_1,a_2$ and $\sigma^2$ of the AR(2) process using the Yule-Walker equations. Since the Yule-Walker equations do not give us information about the order of the autoregressive process, we then use the Bayesian Information Criterion in order to choose the parameters which fit the model of second order. Once we have the parameters, we manually set a vector of $n$ initial states $X_0=\vec0$ and $X_1=\vec1$ and then simulate for every $n$, $t$ time series steps. We then drop the initial values in order to lose the dependence of the manually set values and take only the last 3 time steps $X_{t-2},X_{t-1},X_{t}$. We discretize our time-series in order to have a Markov chain with discrete state space. Take migration matrices $M_1$ from $X_{t-1}$ to $X_{t}$ and $M_2$ from $(X_{t-2},X_{t-1})$ to $X_t$. Test the hypothesis of first order Markov property against the second order Markov property for the above migration matrices. The likelihood ratio test is asymptotically $\chi^2$ distributed with $m$ degrees of freedom. For the degrees of freedom I have simply taken the difference of estimated parameters (estimated transition probabilities). Is this correct? The problem arises when for some combination of $\gamma(2),\gamma(1)$ the BIC returns a second order but the Likelihood ratio test results in an acceptance of the null hypothesis of Markov first order. For example: $\gamma(1)=0.3, \gamma(2)=0.5$ results in $X_t=0.467X_{t-1}+0.067X_{t-2}+\epsilon_{t}$ with variance $\sigma^2=0.864$. $\gamma(1)=0.4, \gamma(2)=0.6$ results in $X_t=0.563X_{t-1}+0.062X_{t-2}+\epsilon_{t}$ with variance $\sigma^2=0.798$. $\gamma(1)=0.5, \gamma(2)=0.7$ results in $X_t=0.686X_{t-1}+0.002X_{t-2}+\epsilon_{t}$ with variance $\sigma^2=0.714$. $\gamma(1)=0.6, \gamma(2)=0.8$ results in $X_t=0.889X_{t-1}-0.111X_{t-2}+\epsilon_{t}$ with variance $\sigma^2=0.596$. For all the other combinations of of $\gamma(1),\gamma(2)$(with $\gamma(0)=1$) either the hypothesis of first order Markov property was rejected or the Bayesian Information Criterion evaluated it as an AR(1) process instead of AR(2). Note that I am aware that the problem for the above cases is that the $a_2$ parameter is close to $0$ and the variance $\sigma^2$ of the error term is large and therefore the Likelihood ratio test accepts the hypothesis of first order Markov property. My questions are: Am I doing the simulation right? How can i interpret these results? Did the simulation of the AR(2) fail? Did the BIC fail to recognize it as a first order AR process? Why is it always a combination of covariances where the $\gamma(2)-\gamma(1)=0.2$? I hope that my question is clear; if not I will be happy to further elaborate or post the R code. I would appreciate any help, advice or hint. Thanks a lot. Cheers from Vienna!
