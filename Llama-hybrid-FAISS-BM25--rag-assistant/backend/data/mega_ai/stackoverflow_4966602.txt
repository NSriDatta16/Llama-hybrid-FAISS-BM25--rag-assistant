[site]: stackoverflow
[post_id]: 4966602
[parent_id]: 
[tags]: 
How can I get the precision of a decimal in js?

This is probably a super easy thing to solve, but I just can't think of an elegant solution right now. Given the following numbers, how do I find the precision (.0001) of each number. 126.01 1.3450 Update: The number of digits after the decimal. The output from the top two numbers would be. .01 .0001
