[site]: crossvalidated
[post_id]: 482801
[parent_id]: 
[tags]: 
Autoencoder based anomaly detection: how to train AE also with outliers?

Suppose the data without labels, i.e., unsupervised anomaly detection task. The data are multivariate sequences, so the idea is to use LSTM based autoencoder (AE). However, typically AE-s for anomaly detection are trained on "normal" samples only, meaning that they learn the patterns of the normal data and will not be able to reconstruct anomaly correctly, thus the reconstruction error will be high for outliers. BUT, what if the labels are not known, is it possible to use it anyway? The model is expected to be biased, but still, this is an autoencoder and it should filter out the noise in process of encoding, or? They discuss it in this book Outlier Analysis , but nowhere else. Plus, how to preprocess the data for such model? Outliers will bias the mean and variance when scaling to zscore..
