[site]: stackoverflow
[post_id]: 669285
[parent_id]: 646974
[tags]: 
Firstly, remember that Unicode doesn't mean 16 bits. The fact that System.String uses UTF-16 internally is neither here nor there. Unicode characters are abstract - they only gain bit representations through encodings. You say "my storage is a System.String" - if that's the case, you cannot talk about bits and bytes, only Unicode characters. System.String certainly has it's own internal encoding, but (in theory) that could be different. Incidentally, if you believe that the internal representation of System.String is too memory-inefficient for Base64-encoded data, why aren't you also worrying about Latin/Western strings? If you want to store binary data in a System.String, you need a mapping between collections of bits and characters. Option A: There's a pre-made one in the shape of Base64 encoding. As you've pointed out, this encodes six bits of data per character. Option B: If you want to pack more bits per character, then you'll need to make an array (or encoding) of 128, 256, 512, etc Unicode characters, and pack 7, 8, 9, etc bits of data per character. Those characters need to be real Unicode characters. To answer your question simply, yes there is a standard, it's Base64-encoding. Is this a real problem? Do you have perf data to support your idea of not using Base64?
