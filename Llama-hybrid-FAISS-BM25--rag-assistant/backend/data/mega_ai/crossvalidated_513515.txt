[site]: crossvalidated
[post_id]: 513515
[parent_id]: 
[tags]: 
in Financial Machine Learning, what would be the difference of objective function, cost function and loss function definitions?

I'm interested in learning more about differences or special considerations when thinking about loss function, cost function, and objective function in a Financial Machine Learning scenario (e.g. using Neural Net to predict the future value of a financial asset and invest in it). I have read this and this , seems to be an open debate on the distinction of those 3 concepts, those answers include citing well-known researchers and practitioners of ML and AI, I actually found a consistent definition in "Linear Algebra and Optimization for Machine Learning, Aggarwal, Springer, pag 142" ... The goal of the optimization problem is to compute the values of the variables at which the objective function is either maximized or minimized. It is common to use a minimization form of the objective function in machine learning, and the corresponding objective function is often referred to as a loss function . So my question is, what about defining objective functions which to maximize?. Because it appears that a so-called "gain function" could exist in a Financial Machine Learning context but never heard of it. My current thought is: This could exist due to a connection with the concept of "calibration", such a concept exists in the realm of metrology, and is defined roughly as a measure of similarity between a practical (observed) value and a theoretical or desired value. Am I right in thinking that in finance, one could desire for maximizing the performance of a predictive model in terms of similarity with the desired outcome (e.g. daily accuracy adjusted to how much an algorithm loses when it was wrong but also when it was right but there was too much volatility intraday) and therefore using a gain function definition?
