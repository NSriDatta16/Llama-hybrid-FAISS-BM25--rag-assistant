[site]: crossvalidated
[post_id]: 124368
[parent_id]: 124351
[tags]: 
In brief, the autoregressive (AR) terms represents the relationship between $y_t$ and $y_{t-1}$. A simple AR(1) model is: $$ y_t=\phi_1 y_{t-1} + \epsilon_{t-1} $$ In words, if $y_{t-1}$ is large, subsequent $y$'s also tend to be large if $\phi>0$ (although, if $\phi$ is less than 1, then $y$ will tend to gradually collapse back down). In an AR(p) process, this is extended to $p$ lagged $y$ terms. Moving average (MA) terms arise from a model like this: $$ y_t = \theta_1 \epsilon_{t-1} + \epsilon_{t} $$ More generally, an MA(q) process is a moving average of the last $q$ error terms ....with weights equal to $\theta_1 \ldots \theta_q$. A combination of AR and MA models is called an ARMA model. Finally, having differences in the model (the middle term of the ARIMA model specification in R) means that instead of an ARMA model in $y$, the ARMA model describes $y_t-y_{t-1}$. You also referred to sma1 and sar1 terms ... you can extend the ARIMA model even further to also cover seasonal time series, in which case sma1 and sar1 refer to the coefficients of the lagged errors and $y_t$'s at seasonal periods (ie 12 months ago for an annual model). Rob Hyndman's excellent online textbook Forecasting Principles and Practice contains a chapter on ARIMA models that explains the meaning of the terms in far more detail than above. Other (offline) standard references include Applied Time Series Modelling and Forecasting (Harris) and Time Series Analysis (Hamilton).
