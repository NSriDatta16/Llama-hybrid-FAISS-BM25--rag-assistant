[site]: crossvalidated
[post_id]: 220420
[parent_id]: 
[tags]: 
Implementation of PCA using SVD without creating covariance matrix

So I'm currently taking a Machine Learning course and have correctly submitted my implementation of PCA. I used SVD. Here it is Octave. function [U, S] = pca(X) %PCA Run principal component analysis on the dataset X % [U, S, X] = pca(X) computes eigenvectors of the covariance matrix of X % Returns the eigenvectors U, the eigenvalues (on diagonal) in S % % Useful values [m, n] = size(X); % You need to return the following variables correctly. U = zeros(n); S = zeros(n); % ====================== YOUR CODE HERE ====================== % Instructions: You should first compute the covariance matrix. Then, you % should use the "svd" function to compute the eigenvectors % and eigenvalues of the covariance matrix. % % Note: When computing the covariance matrix, remember to divide by m (the % number of examples). % covarianceMatrix = (X' * X) ./ m; [U, S, V] = svd(covarianceMatrix); % ========================================================================= end I thought the point of using SVD in PCA implementations was to improve the computational efficiency and therefore not compute the covariance matrix (which can cause loss of precision). How come I was expected to create the covariance matrix? How can I implement PCA without creating a covariance matrix?
