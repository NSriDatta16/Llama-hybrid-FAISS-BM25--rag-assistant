[site]: crossvalidated
[post_id]: 131296
[parent_id]: 
[tags]: 
Parameter Tying: Using observations of one category to lift estimates of baseline ability

I am trying to model an individuals' ability to perform one of several similar tasks. We would like each individual's performance to reflect three factors: the mean ability of the general population, the general ability of the particular individual, and the individual's facility for each specific task. In particular, we would like the model to allow us to make inferences given limited observations. For example, given an individual, if they perform really well at one of the tasks, but their performance on other tasks is unobserved, the model still ought to infer that that individual should be better than average at the other [unobserved] tasks, i.e., good performance on one task should lift estimates of that individual's baseline ability. Currently, we are using the following hierarchical model: given binary responses $y_i$, categorical input $x_i$ with $M$ levels, $$y_i \sim \textrm{Bern}(\pi_i);\ \ \ \ \ \ \textrm{logit}^{-1}(\pi_i) = \alpha_{g(i)} + \sum_{j=1}^{M-1} \beta_j x_{ij}$$ $$\alpha_{g(i)} \sim \cal{N}(\mu_{\alpha}, \sigma^2_{\alpha});\ \ \ \beta_{g(i),j} \sim \cal{N}(\mu_j, \sigma^2_j)$$ where the hyperparameters have weak priors (normal for the mu's, IG for the sigma's). We have expanded the categorical variable (representing the tasks) into $(M-1)$ indicators, to make sure the model is identifiable; this effectively pegs the individual's performance on the first task as that individual's baseline. The model works quite well, and exhibits the desired behavior mentioned earlier; HOWEVER, the tasks do not equally influence the baseline; in particular, an individual's performance on the task associated with the intercept has a much much much larger effect on our estimate of their baseline ability than any other task. We were hoping someone could offer a suggestion to resolve this difference in behavior. Thanks!
