[site]: crossvalidated
[post_id]: 369928
[parent_id]: 368754
[tags]: 
1) One does not overtrain on the test set - one overtrains on the training set, and that may cause the regressor to generalize poorly, which results in large errors for the test set. This is called overfitting But you claim that the errors for the test set were low, so no problem there. So no, no overfitting . 2) The distribution of the CV results are somewhat strange - as the size of the folds increase, one should expect that the distribution of the CV results approaches a Gaussian, centered around the "correct" MAE, which would be the MAE you obtain for the test set. But your folds are not large. You said that the data set has 200 data, but how many of those are in the test set and how many in the training set - the folds are done only on the training set from what I saw in the code. So the folds are at most 20 data, and that could explain the skewness of the distribution of CV results. It seems that your regressor is making some large mistakes on a few data points, and that was the inspiration for some of the comments asking you about outliers - the few data points for which the regressor is making very wrong predictions. 3) XGBoost and other boosting algorithms tend to overfit the training set (but we discussed that there is no overfit because you think that the results in the test set are good). Boosting learns a regressor on the data, than a new regressosn of the errors of the first one, than a new one on the errors of the previous two, and so on. This tend to create an ensemble regressor that fits very well the training set which may cause poor generalization, which may explain large errors for the test set. In your case you are generating 50 of those regressors (which seems too much given that there is only 200 data) and each regressor will probably no make that many mistakes (given that each regressor is a regressor tree with at most 4 levels deep). The usual way to reduce overfitting on boosting is to a) reduce the number of estimators, and/or b) reduce the maximum depth of the trees. I do not have enough experience on boosting to advice you on whether your values are too high, I would suspect so.
