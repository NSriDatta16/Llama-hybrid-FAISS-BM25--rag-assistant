[site]: datascience
[post_id]: 56053
[parent_id]: 
[tags]: 
Why could my DDQN get significantly worse after beating the game repeatedly?

I've been trying to train a DDQN to play OpenAI Gym's CartPole-v1, but found that although it starts off well and starts getting full score (500) repeatedly (at around 600 episodes in the pic below), it then seems to go off the rails and do worse the more it plays. I'm pretty new to ML so I'm not really sure what could cause this so I'm not sure how to start debugging (I've tried tweaking some of the hyper-parameters, but nothing seems to stop this trend). If it helps, here's the (probably) relevant parts of my agent: def _build_model(self): model = Sequential() model.add(Dense(24, input_dim=self.state_size, activation="relu")) model.add(Dense(24, activation="relu")) model.add(Dense(self.action_size, activation="linear")) model.compile(optimizer=Adam(lr=self.learning_rate), loss="mse") return model def get_action(self, state): # Use random exploration for the current rate. if np.random.rand() And the full notebook is here .
