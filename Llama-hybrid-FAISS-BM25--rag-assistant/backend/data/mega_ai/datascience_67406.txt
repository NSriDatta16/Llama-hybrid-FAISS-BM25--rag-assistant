[site]: datascience
[post_id]: 67406
[parent_id]: 67392
[tags]: 
Assuming that your folders are your classes, you can match any document with the correspondent tag. Then, for every document: 1.- Normalize the text, i.e. remove stop words (unless they make sense), stem and / or lemmatize it (unless it doesn't makes sense). 2.- Vectorize the documents, you can choose TFIDF, BOW, word embeddings etc 3.- Depending on your documents train with an MLP (in case of BOW) or an LSTM in case of words embeddings. When you have a new document, you need to repeat the procedure using the vocabulary you created for the training set. I had a similar use case and was enough to use BOW with a multi layer perceptron, the accuracy was above 95%, but, documents were different for each category and I removed most frequent words because there where to common. Another solution is to perform a topic modeling on documents binding those topics to the category and then training a simple classifier (an MLP or SVM will work)
