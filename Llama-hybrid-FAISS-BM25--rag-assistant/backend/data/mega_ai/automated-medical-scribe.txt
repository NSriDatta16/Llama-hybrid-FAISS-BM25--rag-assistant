Automated medical scribes (also called AI medical scribes, AI scribes, digital scribes, virtual scribes, and ambient AI scribes) are tools that transcribe medical speech, such as patient consultations and dictated clinical notes. These tools produce summaries of consultations as well, aiming to reduce the administrative burden on clinicians and improve efficiency in documentation. Automated medical scribes based on Large Language Models (LLMs, commonly called "AI", short for "artificial intelligence") became increasingly popular in 2024. Healthcare providers using AI scribes generally understand the ethical and legal considerations, and supervise the outputs. The privacy protections of automated medical scribes vary widely. While it is possible to do all the transcription and summarizing locally, with no connection to the internet, most closed-source providers require that data be sent to their own servers, securely processed, and the results sent back. Some retailers use zero-knowledge encryption (meaning that the service provider can't access the data). Select AI scribes do not use patient data to train their AIs, or rent or resell it to third parties. Meanwhile, few providers have published safety or utility data in academic journals, and are actually responsive to requests from medical researchers studying their products. Privacy Some providers unclear about what happens to user data. Some may sell data to third parties. Some explicitly send user data to for-profit tech companies for secondary purposes, which may not be specified. Some require users to sign consents to such reuse of their data. Some ingest user data to train the software, promising to anonymize it; however, deanonymization may be possible (that is, it may become obvious who the patient is). It is intrinsically impossible to prevent an LLM from correlating its inputs; they work by finding similar patterns across very large data sets. Some information on the patient will be known from other sources (for instance, information that they were injured in an incident on a certain day might be available from the news media; information that they attended specific appointment locations at specific times is probably available to their cellphone provider/apps/data brokers; information about when they had a baby is probably implied by their online shopping records; and they might mention lifestyle changes to their doctor and on a forum or blog). The software may correlate such information with the "anonymized" clinical consultation record, and, asked about the named patient, provide information which they only told their doctor privately. Because a patient's record is all about the same patient, it is all unavoidably linked; in very many cases, medical histories are intrinsically identifiable. Depending on how common a condition and what other data is available, K-anonymity may be useless. Differential privacy could theoretically preserve privacy. Data broker companies like Google, Amazon, and Microsoft have produced or bought up medical scribes, some of which use user data for secondary purposes, which has led to antitrust concerns. Transfer of patient records for AI training has, in the past, prompted legal action. Open-source programs typically do all the transcription locally, on the doctor's own computer. Open-source software is widely used in healthcare, with some national public healthcare bodies holding hack days. Encryption Multifactor authentication for access to the data is expected practice. Typically, Diffieâ€“Hellman key exchange is used for encryption; this is the standard method commonly used for things like online banking. This encryption is expensive but not impossible to break; it is not generally considered safe against eavesdroppers with the resources of a nation-state. If content is encrypted between the client and the service provider's remote server (transport cryptography), then the server has an unencrypted copy. This is necessary if the data i