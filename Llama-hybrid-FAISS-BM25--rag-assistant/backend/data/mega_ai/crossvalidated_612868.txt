[site]: crossvalidated
[post_id]: 612868
[parent_id]: 612788
[tags]: 
I think the question here is why/whether the loglikelihood function is asymptotically locally a parabola with its maximum at $\hat\theta$ (and so the likelihood function is locally $\exp(-(\theta-\hat\theta)^2/2)$ .Basically, it's just Taylor series: any smooth function is locally a parabola, and any smooth function with zero derivative at a point is locally a parabola with a max or min at that point. It isn't quite just Taylor series -- we do need the Law of Large Numbers and also the rate of convergence of an average to its expected value to be sure that the terms in the Taylor expansion are of the sizes we need them to be. In this case (and relevant other cases) the log-likelihood function is smooth. By the definition of the MLE, the loglikelihood has a maximum at $\hat\theta$ and the derivative is zero at $\hat\theta$ . Therefore, $$\ell(\theta)=\ell(\hat\theta) + 0\times (\theta-\hat\theta) + \ell''(\hat\theta)(\theta-\hat\theta)^2 +\text{remainder}$$ Since the derivatives of $\ell$ are proportional to $n$ , we need $\theta-\hat\theta= O_p(n^{-1/2}$ to keep the remainder small, but that's the range we're interested in. On that range, $\ell(\hat\theta)-\ell(\theta)$ is asymptotically a parabola centered at $\hat\theta$ , so $\exp(\ell(\theta))$ is asymptotically the same shape as a Gaussian likelihood function.
