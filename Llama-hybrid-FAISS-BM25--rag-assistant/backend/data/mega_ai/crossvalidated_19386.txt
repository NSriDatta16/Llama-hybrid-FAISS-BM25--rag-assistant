[site]: crossvalidated
[post_id]: 19386
[parent_id]: 19385
[tags]: 
Since you're treating your SVMs as an ensemble, you should cross validate them as an ensemble. This could potential mean cross-validating multiple combinations of regularization parameters and assessing out-of-sample accuracy of the combined ensemble. Lets say you have 5 SVMs and you want to test 5 possible regularization parameters. This means you have to cross-validate 25 ensembles, one for each possible parameter combination. For each cross validation compute the accuracy (or precision, or whatever) for the entire ensemble on the multi-class problem. The metric you use is subjective and depends on the issues at hand. Accuracy is a good place to start. Going a little further, many SVM implementations support multi-class problems out of the box. Why not just use one of those, and reduce your problem to cross-validating one SVM?
