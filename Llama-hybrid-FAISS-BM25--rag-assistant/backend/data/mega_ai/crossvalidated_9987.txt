[site]: crossvalidated
[post_id]: 9987
[parent_id]: 
[tags]: 
When does the amount of skew or prevalence of outliers make the median preferable to the mean?

I know that "deviations in the data are devil", and when the distribution is highly skewed, it is better to consider median as average rather than mean, but how to decide these hard-limits. For example: CASE 1: Assume X = 10,20,30,40,50,60,70 In this case, I think that it is better to use mean and that it will give very accurate results. CASE 2: Assume X = 10,20,30,40,50,60,70,7000 In this case, I think that it is better to use median instead of using the mean. CASE 3: Assume X = 10,20,30,400,500,600,700 In this case, I think it is better to use IQR (Inter Quartile Range) But I'm stuck with how to decide these hard-limits i.e. which to use in which condition, in general. I've found a tool working on subjected principle, which takes context-less sample-distribution as input and determines whether mean is close/moderate or against the null-hypothesis. Find References:- http://home.ubalt.edu/ntsbarsh/Business-stat/otherapplets/MeanTest.htm (For Mean Test) http://home.ubalt.edu/ntsbarsh/Business-stat/otherapplets/MediansTest.htm (For Median Test) What I'm really looking is a good answer which states how to derive these conclusions.
