[site]: crossvalidated
[post_id]: 415369
[parent_id]: 414143
[tags]: 
A VAE defines a distribution: $P(x) = \int P(x|z)P(z) dz$ . $P(x|z)$ is often a normal distribution $\mathcal{N}(\mu, \sigma^2)$ whose mean and/or variance are parameterized by a neural network (called the "decoder"). In some cases, we assume a fixed variance $\sigma^2$ , but in other cases we might try to model the variance as well. Of course we always have to output $\mu$ . I want to point out that even in the cases where you don't have two layers, you are still outputting $\mu$ . Simply training with MSE loss is equivalent to maximizing log likelihood under a gaussian with mean $\mu$ (and $\sigma^2$ is implicitly some fixed value which depends on the scaling of the MSE loss term vs the KL loss term). What are advantages/disadvantages of the the two approaches. The advantages of modeling $\sigma^2$ is a slightly more expressive model, and the ability to say that the model is more uncertain about some dimensions than other dimensions. The disadvantages is that it's slightly more work to code, and in most cases people only use the mean of the distribution, so there's no reason to bother. You also have to worry about degenerate optimum -- the model could overfit to a small dataset by perfectly memorizing $\mu$ , and then by setting $\sigma^2 \rightarrow 0$ , leading to negative infinity loss.
