[site]: crossvalidated
[post_id]: 239940
[parent_id]: 
[tags]: 
Is the logistic function the best way to parametrise an averaging parameter?

Consider a model for a quantity $y = f(\mathbf{x})$, where $\mathbf{x}$ is a vector of covariates, and $f$ is some smooth and continuous function. Let $\ell(\mathbf{x})$ denote the loss function for predictions $\hat{y}$ made using this model. Let's say that my function $f$ depends on a new covariate $x_m$, constructed by averaging covariates $x_1$ and $x_2$, such that: $$x_m = m x_1 + (1-m) x_2$$ with $0 \leq m \leq 1$. How should an unconstrained optimisation problem be set up to find the best $m$ with respect to the loss function $\ell(\mathbf{x})$? In an unconstrained optimisation, the parameter $m$ cannot be used directly as a decision variable since there is the possibility that it may be smaller than zero, or greater than one. Because of this, one method would be to use the logistic function to parametrise the values of the averaging parameter, i.e.: $$x_m = \frac{1}{1+e^{-m}} x_1 + (1-\frac{1}{1+e^{-m}}) x_2.$$ Are there any better ways of doing this?
