[site]: crossvalidated
[post_id]: 523180
[parent_id]: 116294
[tags]: 
Not exactly an answer, but a proposal on how one would find the solution. I was thinking about that cluster problem. The test would require sampling from the full dataset and deriving kmeans and seeing if the same kmeans occurs within a distribution (example with clustergram) from various samples (normally kmeans itself produces different kmeans depending on it's starting point. An algorithm that hones in on the same kmeans over multiple iterations like clustergram might be more apt). Just as a mean is derived from samples in statistics. But k means has various proportion sizes for its clusters but the point is do the same means appear within a distribution. But how would one compare the distributions of the various vars in the cluster? Normally coefficients are derived from a covariance matrix (or predictor matrix?) which is based on a given y. This has no y. So im wondering if each cluster could be whitened using zca (or even pca). Something w eigenvalues. Use this to derive some type of meaningful means or coefficients. Else one has a set of means. Then one needs to derive the standard error. The standard error is definately based on the covariance matrix (again substitute pca or zca)? But I'd have to brush up on standard error. I believe standard error is a function of standard deviation but instead of a variance of a sample its a variance of a mean Edit: For statistical significance Use the gap statistic method as discussed here http://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/#at_pco=wnm-1.0&at_si=609664423560aa01&at_ab=per-2&at_pos=0&at_tot=1 I also recommend this article for a discussion of other related measures https://medium.com/@haataa/how-to-measure-clustering-performances-when-there-are-no-ground-truth-db027e9a871c
