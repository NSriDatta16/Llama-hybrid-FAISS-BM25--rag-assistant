[site]: datascience
[post_id]: 108601
[parent_id]: 108595
[tags]: 
I managed to solve it! The core mistake was that scikeras doesn't accept non-numerical input. As such I needed to resort to a workaround by eliminating the text preprocessing steps from my custom build_keras_nn() and transforming them into preprocessing steps. Custom preprocessing steps however need their own classes that inherit from scikit-learn TransformerMixin and BaseEstimator . I created two custom preprocessor classes: one to perform the BERT preprocessing task ( BertPreprocessor ) and the other to perform the BERT encoding task ( BertEncoder ). All scikit-learn-style custom transformers must implement a fit() method alongside the transform() , otherwise they are not integrable to other inbuilt scikit-learn transformers and models. One last change was the rewrite of the input layer in build_keras_nn() . Importantly, BERT transforms words/tokens to a 768-dimensional representation, hence the shape argument of Input layer set to 768. The final full code is as follows: class BertPreprocessor(TransformerMixin, BaseEstimator): def __init__(self, preprocessor_model): super().__init__() self.preprocessor_model = preprocessor_model def fit(self, X, y=None): return self def transform(self, X, y=None): return self.preprocessor_model(X) class BertEncoder(TransformerMixin, BaseEstimator): def __init__(self, encoder_model): super().__init__() self.encoder_model = encoder_model def fit(self, X, y=None): return self def transform(self, X, y=None): return self.encoder_model(X)['pooled_output'] def build_keras_nn(): input_layer = Input(shape=768, name='bert_pooled_output') dropout = Dropout(0.1, name='dropout')(input_layer) classification_output = Dense(1, activation='sigmoid', name='classification_output')(dropout) model = tf.keras.Model(inputs=[input_layer], outputs=[classification_output]) metrics_list = [AUC(name='auc'), BinaryAccuracy(name='accuracy')] model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = metrics_list) return model pipe = Pipeline([ ('preprocess', BertPreprocessor(bert_preprocessor_model)), ('encode', BertEncoder(bert_encoder_model)), ('model', KerasClassifier(build_fn=build_keras_nn, epochs=2)), ]) history = pipe.fit(X_train_, y_train_); ```
