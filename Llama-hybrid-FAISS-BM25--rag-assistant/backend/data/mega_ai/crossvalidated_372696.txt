[site]: crossvalidated
[post_id]: 372696
[parent_id]: 
[tags]: 
Can overfitting be a good thing in some cases?

I know the goal of machine learning is to create generalizable models and therefore overfitting is undesirable. However, I wonder if it could be desirable in some cases. For example, let's say I want to predict if a student will dropout a course, and I want to do this before the end of the course by using a proxy label , their assignment submission status . In this scenario, I would not mind if the model trained on the proxy label overfits and does not generalize well to the unseen data, since I care about only a specific set of users. I wonder if this is a valid way of thinking for this specific scenario. Any ideas?
