re. The recent release of PAI's "Guidelines for AI and Shared Prosperity" on June 7, 2023, outlines a blueprint for the judicious use of AI across various stages, guiding organizations, policymakers, and labor entities. The Fairness, Transparency, and Accountability program, in conjunction with the Inclusive Research & Design program, strives to reshape the AI landscape towards justice and fairness. By exploring the intersections between AI and fundamental human values, the former establishes guidelines for algorithmic equity, explainability, and responsibility. Simultaneously, the latter empowers communities by providing guidelines on co-creating AI solutions, fostering inclusivity throughout the research and design process. The Safety Critical AI program addresses the growing deployment of AI systems in pivotal sectors like medicine, finance, transportation, and social media. With a focus on anticipating and mitigating potential risks, the program brings together partners and stakeholders to develop best practices that span the entire AI research and development lifecycle. Notable initiatives include the establishment of the AI incident Database, formulation of norms for responsible publication, and the creation of the innovative AI learning environment SafeLife. The association is also built of thematic foundations that drive Partnership on AI's focus. Atop the programs mentioned above, Partnership on AI looks to expand upon the social impact of AI, encouraging positive social utility. The organization has highlighted potential benefits of AI within public welfare, education, sustainability, etc. With these specific use cases, Partnership on AI is developing an ethical framework in which to analyze and AI's measure of ethical efficacy. The ethical framework places an emphasis on inclusive participatory practices that enhance equity in AI. Programs and initiatives The Partnership on AI has been involved in several initiatives aimed at promoting the responsible use of AI. One of their key initiatives is the development of a framework for the safe deployment of AI models. This framework guides model providers in developing and deploying AI models in a manner that ensures safety for society and can adapt to evolving capabilities and uses. In collaboration with DeepMind, the Partnership on AI has also launched a study to investigate the high attrition rates among women and minoritized individuals in tech. Recognizing the importance of explainability in AI, the Partnership on AI hosted a one-day, in-person workshop focused on the deployment of "explainable artificial intelligence" (XAI). This event brought together experts from various industries to discuss and explore the concept of XAI. In an effort to support information integrity, the Partnership on AI collaborated with First Draft to investigate effective strategies for addressing deceptive content online. This initiative reflects the organization's methodical approach to identifying and promoting best practices in AI. The Partnership on AI is also creating resources to facilitate effective engagement between AI practitioners and impacted communities. In November 2020, the Partnership on AI announced the AI Incident Database (AIID), a project dedicated to indexing the collective history of harms or near harms realized in the real world by the deployment of artificial intelligence systems. The AIID, which shifted to a new special-purpose independent non-profit in 2022, serves as a valuable resource for understanding and mitigating the potential risks associated with AI. Most recently, PAI conducted the PAI's 2023 Policy Forum. This event, held in London, was a gathering of diverse stakeholders to explore recent trends in AI policy globally and strategies for ensuring AI safety. During the event, the Partnership on AI (PAI) unveiled their "Guidance for Safe Foundation Model Deployment" for public feedback. This guidance, shaped by the Safety Critical AI Steering Committee and 