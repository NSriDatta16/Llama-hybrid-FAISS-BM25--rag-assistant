[site]: crossvalidated
[post_id]: 462265
[parent_id]: 
[tags]: 
tradeoff function for exploration/exploitation in the context of gaussian process bayesian optimisation

First, let's give some context to my issue: consider an objective function $f(x)$ defined over a compact set $D$ , such that there exists $x^*, f(x^*) > f(x) \quad \forall x \in D$ . My goal is to use Bayesian optimization to find $x^*$ , as $f(x)$ is in my application very expensive to compute. I chose to use as a prior model of the objective a Gaussian process, and I chose as an acquisition function the GP-UCB function as defined in this article : $$\alpha_t(x) = \mu_t(x) + \beta^{1/2}_t \sigma_t(x)$$ the $t$ parameter indicates the iteration number of the Bayesian optimization process. My question concerns the parameter $\beta_t$ . For now I define it empirically under the form : $$\beta_t = \gamma_1^{\gamma_2 t}$$ with $\gamma_1>0, 0>\gamma_2>1$ . It allows for exploration in the beginning and more exploitation at each iterations. I would like to redefine it in a way such that it gives some theoretical guarantees on the result of the optimization. For example, the article Gaussian Process Optimization in the Bandit Setting:No Regret and Experimental Design gives a bound over the regret in Theorem 2 and I would like to understand how to use this theorem. More precisely, the theorem gives some condition for the theorem to apply over two constants $a$ and $b$ but it does not precise how to obtain those constants for a given kernel, and I would be interested in knowing how to get those constants. To summarize, I would like a way to define $\beta_t $ such that I have some theoretical guarantee over some quantities in the Bayesian optimization process (regret, distance to the global maximum or others). As I have also found one, I would also like to know how to find the numerical values for a and b in theorem 2 of the preceding article, for a given kernel. I would accept an answer to any of those two issues I'm having.
