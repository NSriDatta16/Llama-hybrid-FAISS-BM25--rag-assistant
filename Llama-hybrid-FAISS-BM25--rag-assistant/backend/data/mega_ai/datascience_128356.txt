[site]: datascience
[post_id]: 128356
[parent_id]: 90459
[tags]: 
I asked this question before starting my PhD in natural language processing, and I think I have a slightly better grasp of the term now. When discussing prompting large language models (LLMs), a shot refers to an example given in the prompt to the model , rather than an example it was trained on. For example, 0-shot prompting is when you just ask an LLM a question; single-shot prompting is when you first show how one question should be answered and then ask a similar question and let the LLM answer it, all within one prompt. I imagine that this terminology was borrowed from earlier training techniques, where, as the previous answer mentions , shots were merely training examples. But I do think the language has changed to differentiate between the two when talking about LLMs. For LLMs, shots are specifically given within a single prompt, so a single example may have multiple shots within it.
