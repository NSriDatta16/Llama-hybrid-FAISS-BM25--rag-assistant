[site]: crossvalidated
[post_id]: 359456
[parent_id]: 
[tags]: 
Interpreting precision and recall graphs

i have a CNN for sentiment analysis whose precision and recall for validation data over 10 training epochs is (average:macro): The dataset contains more positive samples than negatives.I have problem interpreting the results.It seems like it has higher recall and lower precision. One way is to say that since there are so many positive samples, there are more examples that can become false negatives leading to smaller recall and high precision. Or if i try to interpret my own results it can be that since number of positive samples is bigger,the classifier is biased towards positive class in beginning leading to more false positives hence lower Precision and higher recall. How are these graphs interpreted actually? Thanks
