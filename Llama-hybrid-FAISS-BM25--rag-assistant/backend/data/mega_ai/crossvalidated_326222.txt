[site]: crossvalidated
[post_id]: 326222
[parent_id]: 
[tags]: 
Machine learning on non-fixed-length sequential data?

I have a problem which I'd like to apply machine learning (supervised classification) to, however, the data is sequential and each row in the data vector has its own length. This implies that the number of features in each row is non-constant (think time-series data - for example - day-by-day data). So this means that the order of the data has meaning and we simply cannot e.g. pad with zeros to make all rows have equal length, as that would introduce spurious signals which would confuse my classifier. At least that's my current opinion. One possible approach is to use e.g. window functions and simply compute (for each day) running sums of things. But that means I'm losing information on history, since each day would have to be represented as its own row in the matrix in order to make all rows have a fixed number of columns, so I could apply classical ML algorithms. I want to avoid this, as I believe it's a suboptimal approach - but I will listen to any arguments against my opinion. I don't have a lot of experience with neural networks, but I believe there are architectures which support non-fixed-length sequence data, e.g., RNNs? Does anyone have any good links/resources I may consider? I welcome thoughts and suggestions from practitioners on how to approach this modeling problem. Thank you! Regards, M
