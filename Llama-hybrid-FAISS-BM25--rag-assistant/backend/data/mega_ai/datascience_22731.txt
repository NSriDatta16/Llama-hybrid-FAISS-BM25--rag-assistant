[site]: datascience
[post_id]: 22731
[parent_id]: 
[tags]: 
How to preprocess Acoustic Data

I am dealing with acoustic data with very high sampling frequency of 2MHz and want to build a classifier. I was wondering if there are any rules of thumb for preprocessing acoustic data. Is it better to directly use raw data (timesignal) or first to construct spectrograms, and to use these? There are papers, which say raw is better, and there are papers saying spectrograms are better. It somehow seems to me, that authors already had a preferred method, even before writing the paper. I think a real comparison is difficult. I read the paper "Deep Learning and Its Applications to Machine Health Monitoring: A survey" , in which a study of different methods was done. I looked up his references, but authors seemed just to pick raw or spectrograms without explaining. For example, in the paper "End-to-end learning for music audio" from Dieleman spectrograms are preferred. In "Sample-Level deep convolutional neural networks for music auto-tagging using raw waveforms" , they claim their 1D structure is better or at least comparable to 2D architectures. Personally I had better experience with spectrograms.
