[site]: datascience
[post_id]: 123571
[parent_id]: 
[tags]: 
Why do I keep on getting ResourceExhaustedError while training on video data using CONV3D on tensorflow?

I'm encountering a memory allocation problem while training a deep learning model on my computer, which has a Core i9 10th Gen CPU, 64 GB of RAM, and an NVIDIA GTX 1660 Super with 6GB of VRAM. Despite what seems like a well-equipped setup, TensorFlow reports errors related to memory allocation during training. I've tried adjusting the batch size, enabling GPU memory growth, and monitoring system resources, but the issue persists. The dataset isn't exceptionally large, and the model isn't overly complex, so I'm puzzled about the root cause. I'm seeking advice on how to diagnose and resolve this memory allocation issue, as I believe my hardware should be capable of handling the workload. Any insights or suggestions would be greatly appreciated. The exact error message is: ResourceExhaustedError: {{function_node _ wrapped__StatelessRandomUniformV2_device /job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[9345024,62] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2] Note: For those who know I am trying to train video dataset of CASIA B with about 14000 one second videos using 3D Convolution.
