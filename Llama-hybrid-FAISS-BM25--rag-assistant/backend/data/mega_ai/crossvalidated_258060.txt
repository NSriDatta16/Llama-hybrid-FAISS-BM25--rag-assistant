[site]: crossvalidated
[post_id]: 258060
[parent_id]: 257818
[tags]: 
If I interpret the comments correctly, you sample the $x_i$ independently of each other. Denote the random sequence that you sample by $X_1, X_2, \dots$ with realizations in the set $S = \{0, 0.1, \dots 1 \}$. The fact that you use an iid-sample from $S$ amounts to saying that for all $x_i, x_j \in S$, $\mathbb{P}(X_i = x_i | X_j = x_j) = \mathbb{P}(X_i = x_i) = 1/11$. (This is the definition of statistical independence that holds for the sequence $X_1, X_2, \dots$ by assumption of an iid sample from $S$.) Now consider any arbitrary function $f:S \to \mathbb{R}$. As long as the function $f$ has a unique inverse $f^{-1}$ on $S$, it holds that each point in $S$ has a unique point in $\mathbb{R}$ it is associated with. Thus, it holds that the exact same probablity mass is on the event $\{f(X_i) = f(x_i) \}$ as on the event $\{X_i = x_i \}$. In other words, it holds that $\mathbb{P}(f(X_i) = f(x_i)) = \mathbb{P}(X_i = x_i)$! Another way to look upon this is to say that if $f$ has a unique inverse on $S$, sampling at random with replacement from $S$ and then plugging it into $f$ is identical to sampling at random with replacement from $f(S) = \{f(0), f(0.1), \dots f(1) \}$, as there is a one-to-one correspondence between the two procedures. Clearly, the function $f = \sin(x)$ satisfies the condition outlined in the paragraph on $S$. We thus have that the above paragraph can be applied to $f$. Hence, $y_i$ is a sum of two independent random variables, namely $f(X_i)$ and $\epsilon_i$. It follows that $y_i$ and $y_j$ are independent.
