[site]: datascience
[post_id]: 103858
[parent_id]: 103833
[tags]: 
A good option is to use a customized Bert library. Therefore, you would need some custom tokenization to detect some key parterns such as "5.0" using a tokenizer like ByteLevelBPETokenizer. from tokenizers import ByteLevelBPETokenizer import os tokenizer = ByteLevelBPETokenizer() tokenizer.train(your training data) os.mkdir('./your_tokenizer') tokenizer.save_model('your_tokenizer') Then, you could use some sequence classification to know at least the category of the sentence. from transformers import AutoTokenizer, AutoModelForSequenceClassification import torch tokenizer = AutoTokenizer.from_pretrained("your_tokenizer") model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased") Now you could need to finetune your model, but you can try without finetuning it: classes = ["Headphone", "Keyboard"] sequence_0 = "USB keyboard" sequence_1 = "3.5 Headphone white" sequence_2 = "Portuguese keyboard" keyboard = tokenizer(sequence_0, sequence_2, return_tensors="pt") headphone = tokenizer(sequence_0, sequence_1, return_tensors="pt") keyboard_classification_logits = model(**keyboard).logits headphone_classification_logits = model(**headphone).logits keyboard_results = torch.softmax(keyboard_classification_logits, dim=1).tolist()[0] headphone_results = torch.softmax(headphone_classification_logits, dim=1).tolist()[0] # Should be keyboard for i in range(len(classes)): print(f"{classes[i]}: {int(round(keyboard_results[i] * 100))}%") # Should be a headphone for i in range(len(classes)): print(f"{classes[i]}: {int(round(headphone_results[i] * 100))}%") The code is inspired from this site: https://huggingface.co/transformers/task_summary.html With enough data, you should be able to train your model with other languages. The amount depends on the variability of the possible names. Note: you could try afterwards smaller models, as the words' structure is simpler than classic litterature.
