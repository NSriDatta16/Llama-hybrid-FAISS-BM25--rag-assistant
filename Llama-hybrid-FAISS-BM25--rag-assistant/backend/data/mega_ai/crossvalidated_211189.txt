[site]: crossvalidated
[post_id]: 211189
[parent_id]: 
[tags]: 
'undirected' $\epsilon$-greedy action selection

There are two famous/classical ways to select an action under the $\epsilon$-greedy action selection that discusses the trade off between exploration and exploitation. Firs is the Semi-uniform Random Exploration. In this case, the best action is selection with some probability $p$, while a random action is chosen with probability $1-p$. Second is the Boltzmann exploration, whose function is based on the Boltzmann distribution of statistical mechanics $$P(a) = \dfrac{exp(Q(s,a)/T)}{\sum_a exp(Q(s,a)/T)} $$ My question is this: The paper: Bayesian Q Learning by Dearden, Friedman and Russell, calls both these exploration methods 'undirected'. Meaning, there is no exploration-specific knowledge used. I do not understand why it is 'undirected'. Further, the very short explanation they gave is not intuitive, either. Any insights? Any possible reason why this is undirected, and what examples are 'directed'? Thanks
