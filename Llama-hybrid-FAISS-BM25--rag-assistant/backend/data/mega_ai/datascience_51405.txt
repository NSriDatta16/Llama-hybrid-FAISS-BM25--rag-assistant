[site]: datascience
[post_id]: 51405
[parent_id]: 51399
[tags]: 
I'm not sure it is a good problem setting for input to a feed-forward network (especially such a small network with only one activation over 6 neurons). What is there even to predict here if you are just using the day of the week and the month in the year? You could simply take the average for each of the pairwise combinations and use that. If you want to adjust for local trends over your dataset's timespan, then perhaps look int temporal decomposition. For example, you can use the seasonal_decompose method available in the statsmodels package for Python. What this does is to find: a global trend over the range of your data parts of your data that vary on a repeating pattern ( seasonally ), any remaining noise, or residuals not fitting parts 1. and 2. It works by applying convolutions over the data to find a repeating frequency. You can think of it like finding correlations in time, compared to the ConvNets, which look for correlations over pixels in an image, for example. Here is an example, using a dataset taken of total number of international airline passengers over time. I am using the statsmodels package to load this well-known R dataset as a Pandas DataFrame : In [1]: import statsmodels.api as sm In [2]: import matplotlib.pyplot as plt In [3]: ap = sm.datasets.get_rdataset("AirPassengers") # ap = AirPassengers The actual dataframe is stored on the data attribute of ap and has two columns: In [4]: ap.data.columns Out[4]: Index(['time', 'value'], dtype='object') We can see how the data looks, where there is clearly an upward trend as well as a repeating seasonality (more people fly over the summer time): In [5]: ap.data.plot("time", "value"); In [6]: plt.show() Now we can perform the seasonal decomposition of the data ( freq=12 , because the data is monthly): In [7]: decomp = sm.tsa.seasonal_decompose(ap.data.value.values, freq=12) This decomp result has a few attributes, but most helpful is the plot... We can see the nicely separated seasonlity and the trend, along with some noise In [8]: decomp.plot(); In [9]: plt.show() We see it isn't perfect, as the seasonality is best fitted to the middle section, not the start or end phases - the residuals are largest at the beginning and end. You can access each of the values: observed , trend , seasonal , resid and nobs on the decmp object. Now if this analysis helps you discover seasonality, you might want to look into Seasnal ARIMA models (also available in the statsmodels package). Here is a blog post I just found that looks pretty detailed and would help you on this path. If you are doing this excercise to learn about Keras and deep learning, it might be worth looking into LSTM models that are better for time-series analysis. You will also need to re-think how you feed data into the model for training, not to mix up the temporal information or create biases (letting the model cheat).
