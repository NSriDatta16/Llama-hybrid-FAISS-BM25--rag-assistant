[site]: datascience
[post_id]: 115443
[parent_id]: 115438
[tags]: 
If in your problem it only makes sense to compute the result at the very end of the sequence, then the loss can only be computed at the batch containing the end of the sequence. I guess this gets more complicated if each sequence has a different length. However, in many-to-one problems, it normally makes sense to compute the result at every time step. For instance, in time series forecasting or in language modeling, the inputs are the previous time steps and the output is the prediction for the next time step, and it makes sense to generate a result (i.e. a prediction for the next time step) at every time step and therefore compute the loss combining the errors of the outputs at each time step in each batch.
