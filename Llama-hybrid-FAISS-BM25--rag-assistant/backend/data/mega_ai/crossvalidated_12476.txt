[site]: crossvalidated
[post_id]: 12476
[parent_id]: 12461
[tags]: 
The "frequentist" response is to invent a null hypothesis of the form "not B" and then argue against "not B", as in Steffen's response. This is the logical equivalent of making the argument "You are wrong, therefore I must be right". This is the kind of reasoning politician's use (i.e. the other party is bad, therefore we are good). It is quite difficult to deal with more than 1 alternative under this sort of reasoning. This is because that "you are wrong, therefore I am right" argument only makes sense when it is not possible for both to be wrong, which can certainly happen when there is more than one alternative hypothesis. The "Bayesian" response is to simply calculate the probability of the hypothesis that you are interested in testing, conditional on whatever evidence you have. Always this contains prior information, which is simply the assumptions you have made to made your problem well posed (all statistical procedures rely on prior information, Bayesian ones just make them more explicit). It also usually consists of some data, and we have by bayes theorem $$P(H_{0}|DI)=\frac{P(H_{0}|I)P(D|H_{0}I)}{\sum_{k}P(H_{k}|I)P(D|H_{k}I)}$$ This form is independent of what is called the "null" and what is called the "alternative", because you have to calculate exactly the same quantities for every hypothesis that you are going to consider - the prior and the likelihood. This is in a sense, analogous to calculate the "type 1" and "type 2" error rates in Neyman Pearson hypothesis testing, simply because a "type 2" error rate when $H_0$ is the "null" is the same thing as the "type 1" error rate with $H_0$ is the "alternative". It is only the connotations implied by the words "null" and "alternative" which make them seem different. You can show equivalence in the case of the "Neyman Pearson Lemma" when there are two hypothesis, for this is simply the likelihood ratio, which is given at once by taking the odds of the above bayes theorem: $$\frac{P(H_{0}|DI)}{P(H_{1}|DI)}=\frac{P(H_{0}|I)}{P(H_{1}|I)}\times\frac{P(D|H_{0}I)}{P(D|H_{1}I)}=\frac{P(H_{0}|I)}{P(H_{1}|I)}\times\Lambda$$ So the decision problems are the same: accept $H_0$ when $\Lambda > \tilde{\Lambda}$ for some cut-off $\tilde{\Lambda}$, and accept $H_1$ otherwise. Thus, the procedures are basically different rationales for choosing the cut-off value, or decision boundary. "Bayesians" would say it should be the product of the prior odds times the loss ratio $\frac{L_2}{L_1}$ where $L_1$ is the "type 1 error loss" and $L_2$ is the "type 2 error loss". These are losses, not probabilities, which describe the relative severity of making each of the two errors. The frequentist criterion is to minimise the one of the average error rates, type 1 or 2, while keeping the other fixed. But because they lead to the same form of decision boundary, we can always find an equivalent bayesian prior*loss ratio for every frequentist minimised error rate. In short, if you are using the likelihood ratio to test your hypothesis, it does not matter what you call the null hypothesis. Switching the null to the alternative just changes the decision to $\Lambda^{-1} decision , so if there are only two options, then "failing to reject the null" means the same thing as "accepting the null".
