[site]: datascience
[post_id]: 118792
[parent_id]: 
[tags]: 
Time series Classification - is LSTM better than XGBoost?

My question is whether LSTM RNN is a better predictor of a label (note not forecaster) than XGBoost. Thus far I have had moderate success with XGB but I wonder if the tree nature, random start and non sequential elements with time window data is preventing further improvements. I have motion data, accelerometer & gyro data on 3 axis at 60 hz. I am trying to then classify movements from the data. I have created time windows for these shots which are consistent and applied an XGBoost algorithm to this data. All I feed to the algorithm is the time series window - 30Hz for the 6 axis so 180 data points. I have 10,000 events that I have labelled. I have 5 categories which I am trying to classify. Categories 1 & 2 have accuracy of 90%, and these take up the majority of the data. The prediction accuracy of the 3 remaining labels is nowhere near as good, between 30% & 60%. I have tried cutting the data differently to build models which focus on differently elements, I have also raised the weight of the less well predicted events. I have tried creating features and modelling on this instead of the raw data but the accuracy was far worse. I have one last idea for how to cut the data so that there is a better classification, but this requires relabelling a lot of data. I have used LSTM before but this would require relearning from my side and so am not sure about the benefits, nor can I find clear answers on if XGB is inappropriate / LSTM is better for time series classification. Below is an example of how the data looks using one axis on accelerometer data.
