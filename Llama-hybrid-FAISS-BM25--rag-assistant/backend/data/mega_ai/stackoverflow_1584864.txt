[site]: stackoverflow
[post_id]: 1584864
[parent_id]: 
[tags]: 
Grep multi-layered iterable for strings that match (Python)

Say that we have a multilayered iterable with some strings at the "final" level, yes strings are iterable, but I think that you get my meaning: ['something', ('Diff', ('diff', 'udiff'), ('*.diff', '*.patch'), ('text/x-diff', 'text/x-patch')), ('Delphi', ('delphi', 'pas', 'pascal', 'objectpascal'), ('*.pas',), ('text/x-pascal',['lets', 'put one here'], )), ('JavaScript+Mako', ('js+mako', 'javascript+mako'), ('application/x-javascript+mako', 'text/x-javascript+mako', 'text/javascript+mako')), ... ] Is there any convenient way that I could implement a search that would give me the indices of the matching strings? I would like something that would act something like this (where the above list is data ): >>> grep('javascript', data) and it would return [ (2,1,1), (2,2,0), (2,2,1), (2,2,2) ] perhaps. Maybe I'm missing a comparable solution that returns nothing of the sort but can help me find some strings within a multi-layered list of iterables of iterables of .... strings. I wrote a little bit but it was seeming juvenile and inelegant so I thought I would ask here. I guess that I could just keep nesting the exception the way I started here to the number of levels that the function would then support, but I was hoping to get something neat, abstract, pythonic. import re def rgrep(s, data): ''' given a iterable of strings or an iterable of iterables of strings, returns the index/indices of strings that contain the search string. Args:: s - the string that you are searching for data - the iterable of strings or iterable of iterables of strings ''' results = [] expr = re.compile(s) for item in data: try: match = expr.search(item) if match != None: results.append( data.index(item) ) except TypeError: for t in item: try: m = expr.search(t) if m != None: results.append( (list.index(item), item.index(t)) ) except TypeError: ''' you can only go 2 deep! ''' pass return results
