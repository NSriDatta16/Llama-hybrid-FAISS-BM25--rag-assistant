[site]: datascience
[post_id]: 72273
[parent_id]: 72257
[tags]: 
You are trying to map hyponyms (words for specific examples of a thing, e.g. dog) to hypernyms (word’s for a general class of things, e.g. animal). This has probably already been done for you for most of your terms in Wordnet , so that’s the place to start if you want to quickly create a solution e.g. for commercial purposes. If this is something you want/need to create your own solution for, here are three suggestions. You could pick one to use as a baseline and try to improve on it: Because of the way the English language works, you could probably get a long way by discarding everything except the final word within reach training example. You can then take the GloVe embedding of that word and feed it to a small feed forward neural net. You could take a generative pertained language model and feed it a dummy sentence fragment including the phrase you want to classify (e.g. “dog house” —> “a dog house is a type of”), and then train on some embedding of the predicted next word. You could use the [hashing trick]( to embed all your example phrases and then train a linear model from scratch. Never underestimate a linear model! Good luck!
