[site]: datascience
[post_id]: 28294
[parent_id]: 
[tags]: 
Generative adversarial networks for multiple distribution noise removal

I am working on a project where I need to denoise images, and my dataset is composed of a big chunk of pairs . The fact is, I have multiple sources of noise (with labels), e.g. Gaussian noise, salt&pepper, distortion, saturation to name a few. Different noises types are on the same original images, meaning that for each undistorted image, I have one pair for each noise type, which I believe is relevant for training. Thanks to the recent success of GANs for image translation tasks, I was looking into recent architectures and how I can adapt them for my task. The question is: do you think that is possible for a GAN to learn a many-to-one mapping between distributions, i.e. different noise distributions (the many) and the undistorted image distribution (the one) or do I need to train multiple networks for different kinds of noise? Given that I have paired images I was looking into the pix2pix architecture. What about the recent CycleGAN ? Learning the backward mapping function looks a lot tougher if there are multiple distributions, which I guess is why when they release the pre-trained models they indeed have multiple models for multiple tasks.
