[site]: crossvalidated
[post_id]: 200274
[parent_id]: 200272
[tags]: 
If you think about where the result comes from the answer is a bit more clear. Rao-Blackwellization is based on the fact that \begin{align} \text{Var}(T) &= \text{Var}[\text{E}(T \mid S)] + \text{E} [ \text{Var}(T \mid S)] . \end{align} So if you have two sufficient statistics $S_1$ and $S_2$ then $\text{Var}[\text{E}(T \mid S_1)] \text{E} [ \text{Var}(T \mid S_2)]$. This means that, on average, conditioning on $S_1$ causes a smaller decrease in the variance of $T$, or that $S_1$ provides less information about $T$. This is in line with the idea of $S_1$ generating a more "coarse" partitioning of the sample space than $S_2$, which is to say it achieves greater data reduction. In general it does matter what sufficient statistic we're conditioning on. Consider for example that the whole sample is itself a trivial sufficient statistic, but in this case conditioning doesn't actually accomplish anything. What we want are sufficient statistics that summarize the information in the sample, ideally using a single number.
