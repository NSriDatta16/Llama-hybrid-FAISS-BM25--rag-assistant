[site]: crossvalidated
[post_id]: 538602
[parent_id]: 538599
[tags]: 
As noticed by @Dave, it's called state of the art , often abbreviated as SOTA . However always when you hear this phrase keep in mind that people often use it rather loosely. For example, you can find claims in machine learning literature of models being "SOTA" where proper benchmarks (running your model and another model using exactly the same procedure, data preprocessing, etc) were never done. One example is LSTM models commonly considered as "outperformed" by more modern "SOTA" models, where there are empirical results showing that LSTMs can be no worse than the more complicated models.
