[site]: datascience
[post_id]: 56308
[parent_id]: 
[tags]: 
Why do trained RL agents still display stochastic "exploratory" behavior on testing data?

I am training a PPO2 RL model using stable baselines. One thing I found is that a trained agent will still display some stochastic behavior on test data, as shown by the predict method of PPO2; the deterministic flag should be set to True to see deterministic (un-stochastic) behavior. I understand that when training an RL agent, there is some amount of random exploration so that an agent can learn the optimal value-policy network. However, I thought that once an agent was trained, and used to act (predict) on new test data, the model parameters would be used and no exploration would take place. Therefore, when testing, I thought the agents actions and subsequent rewards would be deterministic (once the test data is static). Why is the trained agent exploring on test data / Why is the trained agent still stochastic when predicting test data? To what degree is the trained agent stochastic (will it follow its model predictions 90% of the time and guess the other 10%)?
