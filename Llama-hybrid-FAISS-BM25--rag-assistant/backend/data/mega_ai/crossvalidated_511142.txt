[site]: crossvalidated
[post_id]: 511142
[parent_id]: 
[tags]: 
Maximum Likelihood Estimation of a VAR(p) Process

In LÃ¼tkepohl's New Introduction to Multiple Time Series Analysis Chapter 3, we try to estimate the model parameters via Maximum Likelihood Estimation. We assume that $u=(u_1',\dots,u_T')'\sim \mathcal{N}(0,I_T \otimes \Sigma_u)$ , where the $u_t\sim \mathcal{N}(0,\Sigma_u)$ are the error terms in $$(y_t-\mu)=A_1 (y_{t-1}-\mu)+\cdots+A_p (y_{t-p}-\mu) + u_t.$$ We define $\mu^*:=(\mu',\dots,\mu')'$ ( $T$ stacked $\mu$ vectors), $A:=(A_1,\dots,A_p)$ and $\alpha=vec(A)$ . Via maximum likelihood estimation we get the following estimators: $$\tilde{\mu}=\frac{1}{T}\bigg(I_K - \sum_i \tilde{A}_i\bigg)^{-1}\bigg(\sum_t[y_t-\sum_i \tilde{A}_i y_{t-i}]\bigg),$$ $$\tilde{\alpha}=\big((\tilde{X}\tilde{X}')^{-1}\tilde{X}\otimes I_K\big)\big(y-\tilde{\mu}^*\big),$$ $$\tilde{\Sigma}_u=\frac{1}{T}\big(\tilde{Y}^0 - \tilde{A}\tilde{X}\big)\big(\tilde{Y}^0-\tilde{A}\tilde{X}\big)',$$ where and $\tilde{X}$ and $\tilde{Y}^0$ are estimators of $Y^0:=(y_1-\mu,\dots,y_T-\mu)$ (with $Y^0_t:=(y_1'-\mu',\dots,y_{t-p+1}'-\mu')'$ ) and $X:=(Y_0^0,\dots,Y^0_{T-1})$ , which are obtained by replacing $\mu$ with $\tilde{\mu}$ in $X$ and $Y^0$ . My question: How are $\tilde{A}$ and/or $\tilde{\mu}^*$ estimated?
