[site]: stackoverflow
[post_id]: 679210
[parent_id]: 
[tags]: 
How can I use a dynamically sized texture array with glTexImage2D?

Currently, I'm able to load in a static sized texture which I have created. In this case it's 512 x 512. This code is from the header: #define TEXTURE_WIDTH 512 #define TEXTURE_HEIGHT 512 GLubyte textureArray[TEXTURE_HEIGHT][TEXTURE_WIDTH][4]; Here's the usage of glTexImage2D: glTexImage2D( GL_TEXTURE_2D, 0, GL_RGBA, TEXTURE_WIDTH, TEXTURE_HEIGHT, 0, GL_RGBA, GL_UNSIGNED_BYTE, textureArray); And here's how I'm populating the array (rough example, not exact copy from my code): for (int i = 0; i How do I change that so that there's no need for TEXTURE_WIDTH and TEXTURE_HEIGHT? Perhaps I could use a pointer style array and dynamically allocate the memory... Edit: I think I see the problem, in C++ it can't really be done. The work around as pointed out by Budric is to use a single dimensional array but use all 3 dimensions multiplied to represent what would be the indexes: GLbyte *array = new GLbyte[xMax * yMax * zMax]; And to access, for example x/y/z of 1/2/3, you'd need to do: GLbyte byte = array[1 * 2 * 3]; However, the problem is, I don't think the glTexImage2D function supports this. Can anyone think of a workaround that would work with this OpenGL function? Edit 2: Attention OpenGL developers, this can be overcome by using a single dimensional array of pixels... [0]: column 0 > [1]: row 0 > [2]: channel 0 ... n > [n]: row 1 ... n > [n]: column 1 .. n ... no need to use a 3 dimensional array. In this case I've had to use this work around as 3 dimensional arrays are apparently not strictly possible in C++.
