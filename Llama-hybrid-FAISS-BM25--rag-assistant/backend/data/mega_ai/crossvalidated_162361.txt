[site]: crossvalidated
[post_id]: 162361
[parent_id]: 162359
[tags]: 
If nearly all the failures occur in one group and not in another, the $p$-value will be nearly 0 regardless of how many individuals are in a group. There are many reasons for this. In particular there is small sample bias. For time-to-event analyses, the power is not driven by the total sample size, but the number of failures. No failures, no power, no matter how many participants in the sample. One nice connection between survival analysis approaches is the relationship between the Log Rank test and the Cox Model. Just as the score test for a logistic regression model on a binary indicator gives on the same $p$-value as is obtained from a Pearson chi-square test for $2 \times 2$ contingency tables, the Score test for the Cox Proportional Hazards model gives the same $p$-value as is obtained from the Log Rank test. In essence, they are consistent tests, and will give you the same answers "in the long run". This is important because by fitting a Cox model, you estimate a hazard ratio which allows you to numerically summarize the difference in survival between both groups. Examining the 95% confidence interval from the Cox model would be a nice way to "visualize" the uncertainty in these estimates rather than a very small p-value, I bet what you see is an extremely wide confidence interval. So, yes it's possible to obtain these kinds of "crazy" $p$-values in categorical and survival analyses because of small sample bias. The power of the analysis depends on how many failures are in each group. Summarizing the power would be a useful way, also, to better understand the problem. If you were treating this test in a Fisherian sense, you would have to report the power of the test before presenting the $p$-value. This would calibrate our expectations as to how significant we really expect findings leading to a $p$-value of 0.0001 would be.
