[site]: stackoverflow
[post_id]: 3627457
[parent_id]: 3627396
[tags]: 
Broadly speaking, a char is meant to be the smallest unit of sensible data storage on a machine, but an int is meant to be the "best" size for normal computation (eg. the size of a register). The size of any data type can be expressed as a number of char s, but not necessarily as a number of int s. For example, on Microchip's PIC16, a char is eight bits, an int is 16 bits, and a short long is 24 bits. ( short long would have to be the dumbest type qualifier I have ever encountered.) Note that a char is not necessarily 8 bits, but usually is. Corollary: any time someone claims that it's 8 bits, someone will chime in and name a machine where it isn't.
