[site]: crossvalidated
[post_id]: 272951
[parent_id]: 
[tags]: 
Hawkes-Process for non binary events

I am currently using a univariate Hawkes-process for modeling the behaviour of agents in a social network. For example, the likelihood that a user will tweet in the next period is defined by the intensity $\lambda$ of a Hawkes-Process such as: $\lambda_t = \mu + \sum_{t_i For a counting-process defined $(N(t): t>0)$ with the associated filtration $(\mathcal{F}(t): t>0)$ on $[0, T]$ with $t_1 ... t_N$ the realizations of $(N_t)_{t>0}$ My problem is that I would like to apply the same methodology on non-binary variables, let's say retweet counts for example. If the user as been retweeted 180 times at time $t$ I would that to have a higher impact on my intensity than it has been retweeted only 2 times. To clarify, I am able to have the model for a time-series like this one, for a user that got retweeted at time $t_1$, $t_4$, $t_5$ and $t_7$ on $[0,T]$ for T=8: $[0, 1, 0, 0, 1, 1, 0, 1, 0]$ I would like to have a model that takes into account the fact that simultaneous events occured at a given discrete time, 3 retweets at time $t_1$, 180 retweets at time $t_4$, 2 retweets at time $t_5$ and 90 retweets at time $t_7$ represented by the below sparse vector: $[0, 3, 0, 0, 180, 2, 0, 90, 0]$ The problem with the Hawkes-Process framework as I understand it, is that it only takes binary events into consideration and I don't see how to apply it to my problema. One might actually suggest that 'slicing' my time series of occurring event at a high enough frequency will eventually lead to a binary vector of occurrences. That's true, but since this has to be applied to big data, I can't afford to multiply my data length by 1000 or even more. I don't really need a solution here, even just a paper dealing with such issue might be of great help. Thanks.
