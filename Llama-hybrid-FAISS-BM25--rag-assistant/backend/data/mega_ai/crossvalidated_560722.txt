[site]: crossvalidated
[post_id]: 560722
[parent_id]: 
[tags]: 
"Statistical Models can NOT Predict Data Significantly Different from the Data used to Create them"

Anywhere within the field of statistics, has the following statement ever been formalized mathematically? "Statistical Models can NOT Predict Data Significantly Different from the (Joint Probability Distribution of the) Data used to Create them" Although this is a fairly logical statement, I was curious to know if any mathematical statements have been made regarding the generalization of statistical models to probability distributions differing from the ones used to create them. For example: We can simulate data from a multivariate Normal probability distribution (with a given mean vector and variance-covariance matrix) We can then fit a regression model to this data (we could decide beforehand that one of the variables from the above distribution will be the response variable - if we had wanted, we could have even simulated data from a joint conditional Normal probability distribution, i.e. the probability distribution of the response variable conditioned several covariates) Next, we can simulate several "test" data sets from other multivariate Normal probability distributions, and in each one of these sets we can begin to incrementally alter the entries of the mean vector and variance-covariance matrix of each Normal Distribution. Then, we would have the regression model perform predictions and record the MSE for each one of these training sets. It would not be unreasonable to believe that the test data sets containing mean vectors and variance-covariance matrices with elements "closer" (e.g. in terms of Euclidean Distance) to the original Normal Distribution, will likely have lower MSE compared to the test data sets that are "further away" to to the original Normal Distribution. My Question: Although there exist several "I.I.D" distributional type assumptions for certain statistical models - has the above statement ever been mathematically formalized, i.e. Statistical Models can NOT Predict Data Significantly Different from the (Joint Probability Distribution of the) Data used to Create them? Can someone please comment on this? Thanks! Note: On the Machine Learning side, a similar concept exists called the "Rademacher Complexity" ( https://en.wikipedia.org/wiki/Rademacher_complexity ) which in theory is able to place bounds on the Generalization Error of a Machine Learning model with respect to the probability distribution from which the training data is said to have come from: Thus in theory, the Rademacher Complexity would allow us to know the worst possible performance of a machine learning model conditional on observing any future data. However, in practice, the error bounds derived from the Rademacher Complexity are said to be "too wide" for any tangible use: From the Machine Learning side (e.g. PAC Learnability of Hypotheses Classes), has any statement been made on the generalization of models outside of the joint probability distribution used to build them?
