[site]: datascience
[post_id]: 33622
[parent_id]: 
[tags]: 
Keras: matching logistic regression performance with sequential neural network?

Assume a binary classification problem and a relatively small dataset ($\sim \mathbb{R}^{5000 \times 39}$). By using common ML techniques, starting with logistic regression, I'm able to reach ~0.76-0.79 AUC on the validation sample, depending on the model. So there clearly are some significant signals to be extracted from the model. However, when trying even a simplest sequential neural network, it does not learn at all. I.e., using keras from R: (NB: AFAIK the language shouldn't be a problem, since it's only a wrapper for R) model % layer_dense(units = 48, activation = "sigmoid", input_shape = 39) %>% layer_dense(units = 48, activation = "sigmoid") %>% layer_dense(units = 2, activation = "sigmoid") model %>% compile( optimizer = "rmsprop", loss = "categorical_crossentropy", metrics = c("accuracy") ) history % keras::fit( x_train, y_train, epochs = 500, batch_size = 16, validation_split = 0.7, shuffle = T ) However, whatever number of epochs or batch sizes, the model doesn't learn at all, the validation accuracy corresponds to the distribution of the target variable (predicts all as 1). What am I doing wrong? Shouldn't a small one/two layer NN with sigmoid activations at least reach the performance of logistic regression? Any suggestions of how to at least replicate the logistic regression results? Or maybe I've missed some steps in the code? Would be greateful for any insight!
