[site]: datascience
[post_id]: 37175
[parent_id]: 37174
[tags]: 
Actually, you can solve these types of problems easily with deep learning. For a moment think of a chatbot which can generate answers given questions. If we think as you mentioned each time final softmax layer should predict a probability distribution which is similar to vocabulary size. But this isn't the case. We use a loss function called Noise Contrastive Estimatimation (NCE_LOSS). Here we sample most likely words and use them to compute the softmax layer. Here I will mention Tensorflow like to understand this scenario. TF NCE loss Blog About Candidate Sampling
