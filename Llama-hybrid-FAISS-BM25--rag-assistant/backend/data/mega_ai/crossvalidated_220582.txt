[site]: crossvalidated
[post_id]: 220582
[parent_id]: 
[tags]: 
SVM always gives me (in average) below chances cross validation accuracy with random data

I am running e1071 linear SVM on my neuroimaging data. (by function svm() ) When I was doing permutation tests, I found, in average, the cross validation (CV) accuracies with shuffle labels were always below 50% (chance level) in binary classifications. Then I created very simple datasets with random number and labels. I found the same thing. No matter what kernel (linear/RBF) I used, what cost (C) value I tried, and what CV method (10 fold, leave one out, leave two out) was applied, it is always like this. Sample size is one factor that modulates the situation a bit. I thought when training SVM with totally random data, the CVs should fluctuate at the chance level (50%). Here is my code for this demonstration. Did I do something wrong? I canâ€™t figure out why. library('ggplot2') library('dplyr') library('e1071') # ------------------------- Create training function ------------------------- f_train % group_by(iTest, n) %>% do(data.frame(acc = f_train(.$n))) # ----------------------------------- Plot ----------------------------------- # ggplot(data_test, aes(x = n, y = acc)) + stat_summary(fun.y = "mean", colour = "red", geom = "line") + stat_summary(fun.data = 'mean_sdl', geom = 'ribbon', alpha = 0.2)
