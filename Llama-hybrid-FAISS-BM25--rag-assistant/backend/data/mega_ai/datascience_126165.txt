[site]: datascience
[post_id]: 126165
[parent_id]: 
[tags]: 
In MLP, multiple classes, using batches, For update weights, Would I have to calculate the accumulated error(of all samples) of each output neuron?

In Multilayer Perceptron neural networks, I know that there are two types of training: online training, and batch training, which consists of dividing the samples and updating the weights using the accumulated error. In other neural networks, for example in Adaline, I know that something similar is done to update the weights, for example in this video: https://youtu.be/MTe2qsS56MQ?si=Sky-220_zA15l7T8 In this case, it shows the " total error", from what it seems to me, the weights are only adjusted at the end of each epoch, using the accumulated error (summed, that is, the total error) of the samples. In the example in the video, he used only one output neuron, as it was just one Adaline, and in the way it was done, it seems like it was just a single batch, as he made a sum of the squared errors of each sample and only at the end I updated the weights using this accumulated error as I mentioned above, it was just a batch. But for me it's confusing, because, if I have a Multilayer Perceptron using several classes, how would I update the weights using batches? Would I have to calculate the accumulated error of each neuron? For example, if I divide 10 samples into 2 batches, how would the weights be updated? Would it add up the error of all samples from each batch, and then update the weights (after the current batch)? When using multiple classes, what would this weight update look like? I would have to add the error (that is, obtain the accumulated error) of all output neurons, for example: "total error of class 1", "total error of class 2", "total error of class 3", etc? In MLP with several classes, using batches, For update the weights, Would I have to calculate the accumulated error(of all samples) of each output neuron?
