[site]: datascience
[post_id]: 126921
[parent_id]: 126920
[tags]: 
The training (i.e. model.fit ) of your neural network is NOT deterministic → every time you train the network, the result of the training (i.e. the model) is different. The inference (i.e. model.predict ) of your neural network IS deterministic → every time you request predictions from a specific model you obtain the same result. Your training is not deterministic due to 2 reasons: Weight initialization: layer weights are initialized to random numbers. Data shuffling: data is shuffled randomly when preparing the batches to feed the model. You can train your model multiple times and get the one with best performance on the validation data, but this does not assure you that it will be the best performing on unseen data , which is the important thing when training a model. Nevertheless, it is common to do it. As a piece of advice, I would say that it would be great if you could replicate your own training, should the need arise. For this, you can check how to do it as decribed in the Keras docs , which basically tells you to do as follows: keras.utils.set_random_seed(812) # If using TensorFlow, this will make GPU ops as deterministic as possible, # but it will affect the overall performance, so be mindful of that. tf.config.experimental.enable_op_determinism() Different values for the random seed will give you different trained models. If you want to make your results reproducible, you should store somewhere the random seed that gave you the best results. Finally, note that, while your specific neural network is deterministic at inference time, this does not apply to all neural networks.
