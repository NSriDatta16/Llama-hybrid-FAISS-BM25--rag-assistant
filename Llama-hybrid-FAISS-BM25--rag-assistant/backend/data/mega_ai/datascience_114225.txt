[site]: datascience
[post_id]: 114225
[parent_id]: 114224
[tags]: 
You should not compare your machine learning task with others, particularly when they are overfitting their models (on other tasks). Second, there is no mathematical rule for fixing the number $k$ of base learners (i.e., decision trees in your case). You can use grid search or cross-validation (and the like) using a validation set to optimize $k$ , but if the hypothesis space is enormous you could also use random search (e.g., genetic algorithms). Third, your approach is a good way to estimate $k$ . Moreover, it also depends on the size of training and testing sets.
