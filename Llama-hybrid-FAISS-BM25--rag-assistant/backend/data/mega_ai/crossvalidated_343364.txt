[site]: crossvalidated
[post_id]: 343364
[parent_id]: 343177
[tags]: 
I thought I might make a series of graphs with a different, but stylized problem, to show you why it can be dangerous to go from Frequentist to Bayesian methods and why using summary statistics can create issues. Rather than use your example, which is multidimensional, I am going to cut it down to one dimension with two studies whose size is three observations and three observations. The data I am using is fake. Both samples have been forced to have a median of -1. This matters because it is coming from a simplified density function that I have to commonly work with. The Frequentist density and the Bayesian Likelihood function is $$\frac{1}{\pi}\frac{1}{1+(x-\theta)^2}.$$ This is the Cauchy distribution with unknown median, but with a scale parameter of one. In truncated form, it is seen as the most common case in the stock market, and appears in physics problems with rotating objects such as rocks rolling downhill or in the famous "Gull's Lighthouse Problem." I am using it because the central limit theorem doesn't apply, it lacks sufficient statistics, extreme observations are common, Chebychev's inequality doesn't hold and a whole host of normally workable solutions fall apart. I am using it because it makes for great examples without having to put too much work into the problem. There are two samples. In the first study, the data was $\{-5,-1,4\}$. In the second study, the data was $\{-1.5,-1,-.5\}$. This distribution is nice because highly concentrated samples are common and samples with a massive range are common. The 99.99% confidence interval is normally $\pm{669}\sigma$ rather than the $\pm{3}\sigma$ most are used to. The posterior densities of the two separate studies is As is visually obvious, taking summary statistics from sample one could be incredibly misleading. If you are used to seeing nice, unimodal, well-defined and named densities, then that can quickly go out the door with Bayesian tools. There is no named distribution like it, but you could certainly describe it with summary statistics had you not visually looked at it. Using a summary statistic could be a problem if you are then going to use that to build a new prior. The Frequentist confidence distribution for both samples are the same. Because the scale is known, the only unknown parameter is the median. For a sample size of three, the median is the MVUE. While the Cauchy distribution has no mean or variance, the sampling distribution of the median does. It is less efficient than the maximum likelihood estimator, but it takes me no effort to calculate. For large sample sizes Rothenberg's method is the MVUE and there are medium sample size solutions as well. For the Frequentist distribution, you get Notice that had you used summary statistics you would have gotten the same ones for both samples. The Frequentist distribution doesn't depend much on the data because the scale parameter is known and they have the same medians. So the summary statistics are invariant to the differences in the samples, because of the common median. While you would rightly point out that this is contrived and this wouldn't really happen, the distortion remains. Using language more correct for Bayesian thinking, the Frequentist model is $\Pr(x|\theta)$ rather than $\Pr(\theta|x)$. The Frequentist distribution assumes an infinite repetition of sample size three draws and shows the limiting distribution for the distribution of sample medians. The Bayesian distribution is given $x$ so it depends only on the observed sample and ignores the good or bad properties that this sample may have. Indeed, the sample is unusual for Bayesian methods and so one may be given pause to form a strong inference about it. This is why the posterior is so wide, the sample is unusual. The Frequentist method is controlling for unusual samples, while the Bayesian is not. This creates the perverse case where the added certainty of the scale parameter narrows the Frequentist solution, but widens the Bayesian. The joint posterior is the product of both posteriors and by associativity of multiplication, it does not matter which order you use. Visually, the joint posterior is . It is obvious that had you imposed some simplified distribution on the posteriors and used their summary statistics, you would likely get a different answer. In fact, it could have been a very different answer. If a 70% credible region been used for study one, it would have resulted in a disconnected credible region. The existence of disconnected intervals happens in Bayesian methods sometimes. The graphic of the highest density interval and the lowest density interval for study one is You will notice that the HDR is broken by a sliver of a region which is outside the credible set. While many of these problems commonly disappear in large sets with regression, let me give you an example of a natural difference in how Bayesian and Frequentist methods will handle missing variables differently in regression. Consider a well constructed regression with one missing variable, the weather. Let us assume that customers behave differently on rainy days and sunny days. If that difference is enough there can easily be two Bayesian posterior modes. One mode reflects the sunny behavior, the other the rainy. You don't know why you have two modes. It could be a statistical run or it could be a missing data point, but either your sample is unusual or your model has an omitted variable. The Frequentist solution would average the two states and may put the regression line in a region where no customer behavior actually occurs, but which averages out the two types of behavior. It will also be downward biased. The issues may get caught in the analysis of residuals, particularly if there is a large difference in the true variances, but it may not. It may be one of those weird pictures of residuals that will show up on Cross-validated from time to time. The fact you have two different posteriors from the same data implies that you didn't multiply the two together directly. Either you created a posterior from a Frequentist solution that didn't map one-to-one with the Bayesian posterior, or you created a prior from the summary statistics and the likelihood function wasn't perfectly symmetric, which is common.
