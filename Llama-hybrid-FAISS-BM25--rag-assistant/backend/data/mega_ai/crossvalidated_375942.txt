[site]: crossvalidated
[post_id]: 375942
[parent_id]: 375220
[tags]: 
In my example, it is a binary classification (1 or 0) from a feature list of 150 element, so I expect an equation of y = ax1 + bx2 + ... + zzzx150, or something similar, so I can actually use the model. Your question is ill-posed. The "formula" like $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_k X_k + \varepsilon$ defines linear regression model, where $Y$ is a linear function of the features $X_1,X_2,\dots,X_k$ . There is no such simple formula for other models. For most of the other machine learning models, we also use features to predict $Y$ , so we have something like $Y = f(X)$ , but $f$ is a much more complicated, non-linear function. If you'd like to code the predict(X) method by hand, that returns the outputs matching what XGBoost returns, you'd need to go deeper into the literature and source code of the implementation of the package that you used (since there may be minor differences between the papers and different implementations). Next, you'd need to basically re-write the appropriate XGBoost method yourself. Unless you want to do this "to learn more about inner workings of XGBoost", or you need to translate the code to different language, so that it works on your infrastructure, this isn't something that you should do. Every such implementation has some kind of predict(X) method that already does what you want to achieve, you should find examples in the documentation. For more details on XGBoost, check the tutorial in their documentation or this talk by Tianqi Chen .
