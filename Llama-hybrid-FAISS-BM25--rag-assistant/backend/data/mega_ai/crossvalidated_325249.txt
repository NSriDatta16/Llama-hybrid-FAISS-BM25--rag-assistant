[site]: crossvalidated
[post_id]: 325249
[parent_id]: 181183
[tags]: 
No. In fact, you can think SVM with polynomial kernel is adding all the (high order) interactions between all features. For example, if we have two features $(x_1,x_2)$, SVM with 2nd order polynomial is doing $(x_1^2,x_2^2,x_1x_2)$. SVM is called Kernel Trick, because it is implicitly doing polynomial basis expansion with a lot less computational complexity. Think about 10th order polynomial expansion on 10 features, manually expand it will have $10^{10}$ columns. But using kernel trick, we can easily do it. So, not only interaction has been widely used in other models. In adding to interaction, other models trying to more with feature engineering. Instead of multiplication of two columns, more complicated features are derived.
