[site]: crossvalidated
[post_id]: 623407
[parent_id]: 
[tags]: 
Uncertainty of a distribution of classification results

Let us assume that a classification DNN is trained and dropout or model ensembling has produced n samples of a classification distribution. The two methods which I have seen to quantify uncertainty in such a case are entropy and comparing variation or standard deviation. Both these methods seem flawed to me in respect to getting a measure of the uncertainty of the classification result. Entropy The method to calculate the entropy is (as I have seen it) to take the mean of the probability vectors n and calculate the entropy over this set. This then negates the consideration of the variance and or standard deviation. Not to mention that these probabilities almost certainly do not add up to 1. For example, let's say the average probability of class 1 is 0.8 and class 2 is 0.3. Even if these distributions are highly overlapping, the entropy will be relatively low. One would expect a higher uncertainty for overlapping distributions. Variance / Standard Deviation I precede this by saying that I have not found a formalization of this method and merely being referenced in passing. Merely considering the variance does not consider the mean or the distribution of the n samples. For instance, high variance in the most probable class may not be a problem if all other classes are improbable. It seems to me that the best uncertainty quantification would be some metric which takes into account the overlap of the distributions and has a higher output for overlapping distributions closer to 1 than 0. Does anyone know if there is such a metric or if there is some problem in my interpretation?
