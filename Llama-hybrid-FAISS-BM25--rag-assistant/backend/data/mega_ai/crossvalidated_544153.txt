[site]: crossvalidated
[post_id]: 544153
[parent_id]: 
[tags]: 
Zero Covariance vs Independence of Slope and Intercept Estimators in Linear Models with Least Squares

$\newcommand{\Cov}{\operatorname{Cov}}$ Problem Statement: Under the assumptions of Exercise 11.16, find $\Cov\big(\hat\beta_0,\hat\beta_1\big).$ Use this answer to show that $\hat\beta_0$ and $\hat\beta_1$ are independent if $\displaystyle\sum_{i=1}^n x_i=0.$ [Hint: $\Cov\big(\hat\beta_0,\hat\beta_1\big)= \Cov\big(\overline{Y}-\hat\beta_1\overline{x},\hat\beta_1\big).$ Use Theorem 5.12 and the results of this section.] Note: This is Problem 11.17 in Mathematical Statistics with Applications, 5th Ed., by Wackerly, Mendenhall, and Scheaffer. My Work So Far: The assumptions of Exercise 11.16 are that $Y_1, Y_2,\dots,Y_n$ are independent normal random variables with $E(Y_i)=\beta_0+\beta_1 x_i$ and $V(Y_i)=\sigma^2.$ The first part of this question is largely done for us in the book. That is, it is derived that $$\Cov\big(\hat\beta_0,\hat\beta_1\big) =-\frac{\overline{x}\,\sigma^2}{\displaystyle\sum_{i=1}^n(x_i-\overline{x})^2},$$ where $\operatorname{Var}(Y_i)=\sigma^2.$ Now $\overline{x}=0$ if and only if $\sum_{i=1}^n x_i=0.$ So if the sum is zero, the covariance is zero. However, just because $\hat\beta_0$ and $\hat\beta_1$ are normally distributed and their covariance is zero does not make them independent . That would only be true if they were bivariately normally distributed. My Questions: Is what I'm being asked to show even true? That is, is there something about $\hat\beta_0$ and $\hat\beta_1$ being OLS estimators that makes this result true? Or can I show that they are bivariate normal distributed? Zero covariance does not imply independence in general ; why should it be so in this situation? Note 1: in silverfish's answer to this question , it is mentioned in the paragraph beginning with "These two uncertainties apply independently..." that these two uncertainties "...should be technically independent." But it is not proven there, though it is intuitively explained and I could believe it. Note 2: In this thread , Alecos simply makes the argument that I think the book wants here, but doesn't say anything about why zero covariance implies independence. Note 3: I have reviewed a few other threads related to this, but none of them answers the main question of why zero covariance should imply independence in this situation , when it doesn't in general.
