[site]: datascience
[post_id]: 37157
[parent_id]: 37153
[tags]: 
Try a one-hot encoding of the elements in your training set (H, C, I etc.) and the same for the chemical descriptors ('acid', 'oxalic' etc.). Then try feeding the data to a simple feed-forward neural network, mapping the one-hot encodings of the descriptors as your x_train and x_val to the chemical elements, which are your y_train and y_val . For the encodings, take a look at the Scikit learn encoders. I think such a simple approach may work, as the chemical names are logically named, so any experienced chemist knows exactly which elements to expect in a compound, given its name. Your problem doesn't require further information in the predictions, e.g. the actual chemical makeup, like $CH_3CH_2OH$ (ethanol). Regarding a small amount of data: look into something like K-fold cross validation. Using this, you select some portion of the data to be your validation data, and train the model. You then repeat this process, selection a different portion of the data. This will help make the most of a limited dataset, although it may introduce overfitting because your model will eventually have seen all the data! Here is a schematic of this method: Scikit Learn has a class that implements it for you.
