[site]: datascience
[post_id]: 95154
[parent_id]: 53995
[tags]: 
As well known, machine only identify 0 and 1. Therefore, we, for an instance, "encode" characters and symbols with ASCII codes. 0 & 1 can only code two characters. To make sure the code is unique for all characters, we have to use a series number to code them. The hard ware experienced 8, 16, 32, and 64 bits (now 64 bits is most popular). Similarly, in my understanding, embedding is to convert non-digital inputs in a preset order, like words, videos, images, etc. into vectors. These vectors can be used to machine learning easily. The dimension of metrics depends on the features of objects. Few features would result in low dimension, vice versa. For an instance, we would recommend movies to users. If users have only one feature, let's say UserID, and movies only has one feature, movie name. We can build up a matrix with UserID as row, and movie name as columns. If a user watched some movies, those intersection would be 1, otherwise would be 0. | movie1 | movie2 | movie3 | movie 4 | ... | movie n | user1 | 1 | 0 | 0 | 1 | ... | 0 | user2 | 0 | 0 | 0 | 0 | ... | 1 | ... | ... | ... | ... | ... | ... | ... | userm | 1 | 1 | 0 | 0 | ... | 0 | Above is a m X n matrix. Each row represents one user. Thus, for user1, we have a vector (1 0 0 1 ... 0), user2 (0 0 0 0 ... 1), similarly for the rest of users. If the movie has only name without any further features, it is hard for machine to learn and train. Now, if we arrange the movies from left to right based on the suitable age group, we then can recommend movie2 and 3 to user1. Based on above example, we can classify the movies in different features (let's say t features), like animated cartoon, action movie, war movie, horror movie, etc. We can build a m X n X t matrix. Based on the watch history, machine can classify a user's watched movies into different group and recommend similar movies.
