[site]: crossvalidated
[post_id]: 102998
[parent_id]: 
[tags]: 
Removing attributes with few observations in R

I have roughly 15 variables / attributes characterizing 6k customers in my data set. As they are categorical I have transformed them into 1 attribute for each possible value (1-out-of-K coding). An example could be Region with values "A", "B" and "C", which is transformed into 3 variables: Region_A , Region_B and Region_C . The same goes for other variables such as the Sales Channel . After this transformation I now have around 70 attributes. I would like to examine if there are any significant 2-way interactions between the different variables with regards to a response variable (concerning customer quality ) using logistic regression. For instance, it is interesting to see if there is an interaction between Region_A and Sales Channel 1 . However, there are very many possible interactions and therefore I would like to start by removing some variables, which have very few observations connected to them. An example could be that only 3 customers come from Region_A . More specifically, I would start by removing all attributes that have 5 observations or less connected to them (out of 6k observations). However, I cannot find out how to do that. Thus I have the following questions: Does my thinking make sense? Or should I approach the issue in another way? How do I remove all attributes in a dataset which has fewer than 5 observations connected to them? The values of the variables are always 0 or 1 as the customer is either from Region A (=1) or not from Region A (=0). After removing these variables there should be fewer interactions. However, it would still be quite a large amount. I would therefore also like to only examine interactions with 5 observations or more. I am thinking this could be done using a formula in the logistic regression, but can you help me how I would find the right variables for the formula?
