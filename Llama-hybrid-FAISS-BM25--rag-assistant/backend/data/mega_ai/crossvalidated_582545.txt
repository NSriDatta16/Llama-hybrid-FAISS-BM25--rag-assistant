[site]: crossvalidated
[post_id]: 582545
[parent_id]: 
[tags]: 
Ways to detect noise in multi-class classification training data using text embeddings (BERT)

So I have a dataset with a column of text and and labels (5 different labels) associated with it. The labels describe the potential answer to the type of question being asked in the text column. For example the questions could be "Who wrote The Kite Runner?" or "What is psoriasis?" or "Where is the Brooklyn Bridge?". The label is either "Human", "Entity", "Description", "Location", or "Number." However 10% of labels are mislabeled or incorrectly labeled. What methods should I look at to automatically identify mislabeled/noisy samples? I am thinking something along the lines to do with cosine_similarity using the embedding space of each sentence (768 dimensions). I fine-tuned DistilBERT on the training data, which then generated vector embeddings for each line of text. The model was 96% accurate on the test data (I'm not sure if that can be improved). Still is there any way I can remove/counteract the noisy samples in my data using the embedding vectors?
