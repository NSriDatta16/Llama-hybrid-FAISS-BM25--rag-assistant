[site]: crossvalidated
[post_id]: 446443
[parent_id]: 
[tags]: 
Why is the equation for a single-neuron perceptron decision boundary Wp + b = 0 set to ZERO?

I am learning about artificial neural networks. I understand how the weights determine the slope of the (orthogonal) decision boundary and how the bias shifts that decision boundary, much like a line. What I do not understamd is why the equation is always set to zero?
