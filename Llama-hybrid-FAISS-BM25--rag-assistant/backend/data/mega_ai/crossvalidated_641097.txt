[site]: crossvalidated
[post_id]: 641097
[parent_id]: 
[tags]: 
What is a numerically stable way to generate an exponential distribution that properly yields very large, low-probability values in Excel and C++?

I have sets of sampled data with the following statistics: Because the mean is so close to the min, and because of our understanding of the process that generated the samples, we are treating the samples as exponentially distributed, with lambda = 1/average. I am trying to generate random samples with as similar as possible a distribution as the measured data for use in our simulator, which is in C++. When I mock this up in Excel I find that the max of a batch of samples is never anywhere close to the max of the measured samples. After having read "The Black Swan", by Nasim Taleb, I really don't want to model my process in a way that ignores black swan / long tail events. In Excel I'm using the following math to generate a sample: =-LN(1-RAND())*SAMPLE_MEAN+SAMPLE_MIN as inspired by this page: https://www.ntrand.com/exponential-distribution Note that multiplying by SAMPLE_MEAN is the same is dividing by lambda. The problem is that the max of my synthetic samples is always around 25,000 for a batch of 10,000 samples. Indeed, if I replace RAND() with 0.999999999999999 the generated samples is 85,914.4. This is true for any number of 9's more than about 7. I assume Excel is using double precision floating point and just runs out of precision. I noticed that since 1-RAND() will have the same distribution as RAND() I removed the "1-". This helped somewhat. Now if I replace the RAND() with 0.000000000001 I do get bigger numbers. After a while it uses exponential notation and I can store up to 1E-307, which yields a sample value of 1,758,388, which is the magnitude I'm looking for. However, in practice RAND() doesn't seem to yield numbers that small. In a spreadsheet with 16 million cells calling RAND(), across many attempts the smallest number I've gotten is 0.00000006103030236737080, yielding an exponential sample of 41,577.7. This is way more trials than the actual sample count of the real process that yielded max values of 1-2 million. So is there a more numerically stable way of generating random numbers with an exponential distribution so that I can properly get samples in the millions in Excel and in C++?
