[site]: crossvalidated
[post_id]: 639206
[parent_id]: 
[tags]: 
Why does feature importance decrease for highly correlated variables?

I am investigating the relationship between correlation between features and its impact on their feature importances using sklearn's DecisionTreeClassifier algorithm. I manipulated the correlation of variables using the following function. This takes an existing feature from the dataset (Feature A), and creates a correlated feature (Feature B) which contains similar information with Feature A in addition to some noise: def create_highly_correlated_column(existing_column, correlation_coefficient, seed=0): """Create a highly correlated feature with an existing feature of equal cardinality.""" np.random.seed(seed) noisy_column = existing_column.copy() noise_values = noisy_column.value_counts(normalize=True).index distribution = noisy_column.value_counts(normalize=True).tolist() noisy_column = noisy_column.apply(lambda x: np.random.choice(noise_values, p=distribution) if np.random.rand() >= correlation_coefficient else x) return noisy_column So at correlation = 0, Feature B is essentially pure noise and at correlation = 1, Feature B is an exact duplicate of Feature A. Here is how the above function resembles the Pearson's correlation coefficient between two Features: I then plotted a graph of the function's correlation coefficient vs feature importance of both Feature A and Feature B averaged over multiple RNG seeds. The following diagram shows the importances of Feature A (orange) and Feature B (blue): As Feature B becomes highly correlated (~ >0.8), the feature importance of the Feature A starts to decrease quite a bit. I think the reason is because some splits which were originally determined by Feature A are now determined by Feature B, so the importance has in a way started to shift from Feature A to Feature B (becoming evenly split when the features are multicollinear). However, this cutoff range which appears around 0.8 differs when Feature A is changed. For example, choosing to apply my function on a different Feature A produces a graph where the feature importance is only split when the correlated feature has a correlation value of 0.99. Do different features admit a different degree of correlation before their feature importance begins to decrease? Which factors determine this? Note: Since the results from my plot are averaged over multiple seeds, then the feature importances for Feature B and Feature A are almost identical as correlation coefficient approaches 1.
