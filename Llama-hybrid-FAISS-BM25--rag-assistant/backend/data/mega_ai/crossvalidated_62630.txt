[site]: crossvalidated
[post_id]: 62630
[parent_id]: 62004
[tags]: 
Just to give a worked example of what I am talking about in simple case of a trimodal distribution: rng( 0 ,'twister') %Set seed to 0 %Set your starting hyperparameters Modality = 3; Sigmas = [ 2 1 3]; %Standard Deviations Means = [-5 1 9]; MixCoefs = [.4 .25 .35]; Length = 1000; %Get matrix with individual distributions (non-effective way just for illustr.) X = randn(Length,Modality).*repmat(Sigmas,Length,1)+repmat(Means,Length,1); %Mix the distributions to your MixCoefs to get the final mixture. Y = [ X(1: (Length* MixCoefs(1)),1); X(1: (Length* MixCoefs(2)),2); X(1: (Length* MixCoefs(3)),3) ]; %Uncomment to visually inspect your empirical pdf and check multimodality %ksdensity(Y) %Fit a trimodal to your data fitted_obj3 = gmdistribution.fit(Y, 3); %Fit a bimodal to your data fitted_obj2 = gmdistribution.fit(Y, 2); %Check which if the bimodal fit is better based on AIC fitted_obj2.AIC Clearly more readings will give you a better fit and less readings a worse one (on average at least). I tried to extensively comment the code so it is easier to follow (as a general coding advice don't comment absolutely everything cause comments require maintenance also...). Computationally speaking gmdistribution.fit is using an E-M algorithm to find the solution but I don't think that is an issue for you. Hope this code helps a bit. If you have questions fire away. :)
