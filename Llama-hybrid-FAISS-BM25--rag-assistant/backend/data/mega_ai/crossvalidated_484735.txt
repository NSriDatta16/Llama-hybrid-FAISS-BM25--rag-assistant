[site]: crossvalidated
[post_id]: 484735
[parent_id]: 
[tags]: 
Is matrix $H$ positive definite in TRPO algorithm?

TRPO Taylor expands the objective and constraint to $$ \theta=\mathop{\arg\max}_\theta g^T(\theta-\theta_{\text{old}})\quad\text{s.t.}\quad \frac{1}{2}(\theta-\theta_{\text{old}})^TH(\theta-\theta_{\text{old}})\le\delta $$ where $H$ is the Hessian matrix of KL divergence. The above is solved by the KKT conditions and the conjugate gradient method. However, to use the conjugate gradient method, $H$ should be positive definite. So I wonder whether $H$ can be proved to be positive definite w.r.t. policy parameter $\theta$ . It seems to be difficult because there is a neural network between $\theta$ and probability distribution. If we cannot show that $H$ is positive definite, how can we use CG?
