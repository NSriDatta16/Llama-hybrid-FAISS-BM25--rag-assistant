[site]: crossvalidated
[post_id]: 451577
[parent_id]: 451480
[tags]: 
From computational perspective, 1M data points and 12 features for logistic regression is nothing, i.e., the computer can return results in seconds. try this example in R, and you will see how fast we can fit. d=data.frame(matrix(runif(1e6*12),ncol=12)) d$y=sample(c(0,1),1e6, replace = T) fit = glm(y~.,d,family='binomial') So if your concern is the computation. It is not necessary to do the feature selection. On the other and, if you do feature selection, in most cases, the performance (classification accuracy) will be worse. This is because, intuitively, more information does not hurt, even the feature is completely irrelevant to the label, the algorithm will just set the coefficient to zero. If your focus is classification accuracy instead of interpretability, I would use logistic regression with regularization. See my another answer for details Regularization methods for logistic regression Note that "stepwise regression, is now considered a statistical sin." See this post What are modern, easily used alternatives to stepwise regression?
