[site]: crossvalidated
[post_id]: 618169
[parent_id]: 
[tags]: 
MIxed Model Ordinal Regression Drops Random Intercepts

Please could you help me? I have been trying for quite some time to fit a mixed model with multiple binary and continuous predictors and an ordinal dependent variable. Subject ID defines the random intercepts. I have more than 3053 observations from 176 subjects in two main conditions (dreams and mindwandering; for which I use an interaction). These 176 individuals have different numbers of repetitions for each condition. Some have some observations in one condition but none in the other and viceversa. Either way, the number of observations differ between individuals. I reduced the independent variables due to high multicollinearity (PC1 and PC2 below) and kept the independent variables that have correlations r>0.5. I have tried to run the model using MASS::polr, Ordinal::CLMM, CLMM2, as well as BRMS::brm (the latter now throws strange and not so reproducible errors). this is what the model looks like (polr example) model_clin_PHQ In this “DREAM_MW” is an important condition for which I check interactions, P_ID is the numeric subject ID. Country and GENDER are binary variables and the rest continuous. The other models are defined in a very similar manner to this. My objective is to estimate a reliable model with p-values (I am afraid this is the status quo of this type of research). For this model I get " design appears to be rank-deficient, so dropping some coefs " The output: polr(formula = PHQ_O ~ scale(Word_Count_log) * DREAM_MW + scale(NET_Max_BetwCentr) * DREAM_MW + Gender + scale(NET_Assort) * DREAM_MW + scale(PC1) * DREAM_MW + scale(PC2) * DREAM_MW + scale(NET_Clust_log) * DREAM_MW + scale(AGE) + COUNTRY + (1 | P_ID), data = dat_without_outlier, Hess = TRUE) Coefficients: Value Std. Error t value scale(Word_Count_log) -0.025063 0.04644 -0.53965 DREAM_MWMW 0.164164 0.07362 2.22983 scale(NET_Max_BetwCentr) 0.112437 0.04758 2.36299 Gender -0.184038 0.08433 -2.18226 scale(NET_Assort) -0.042983 0.04784 -0.89842 scale(PC1) -0.251628 0.06049 -4.15990 scale(PC2) -0.035111 0.05233 -0.67090 scale(NET_Clust_log) 0.031515 0.05282 0.59665 scale(AGE) -0.388714 0.03721 -10.44784 COUNTRY -0.434912 0.07259 -5.99123 scale(Word_Count_log):DREAM_MWMW -0.047547 0.07123 -0.66748 DREAM_MWMW:scale(NET_Max_BetwCentr) -0.189531 0.07220 -2.62514 DREAM_MWMW:scale(NET_Assort) 0.187682 0.07542 2.48857 DREAM_MWMW:scale(PC1) 0.138605 0.08696 1.59397 DREAM_MWMW:scale(PC2) 0.004897 0.07379 0.06636 DREAM_MWMW:scale(NET_Clust_log) -0.070019 0.08035 -0.87138 Intercepts: Value Std. Error t value none|mild -0.9443 0.1052 -8.9725 mild|moderate 0.9379 0.1062 8.8319 moderate|moderate-severe 2.8388 0.1303 21.7899 moderate-severe|severe 3.4833 0.1519 22.9272 scale(Word_Count_log) -0.0250629 0.0464430 -0.5396 0.589439 DREAM_MWMW 0.1641637 0.0736215 2.2298 0.025758 * scale(NET_Max_BetwCentr) 0.1124366 0.0475822 2.3630 0.018128 * Gender -0.1840378 0.0843336 -2.1823 0.029090 * scale(NET_Assort) -0.0429829 0.0478429 -0.8984 0.368963 scale(PC1) -0.2516276 0.0604888 -4.1599 3.184e-05 *** scale(PC2) -0.0351112 0.0523344 -0.6709 0.502283 scale(NET_Clust_log) 0.0315150 0.0528204 0.5966 0.550744 scale(AGE) -0.3887137 0.0372052 -10.4478 Of note is that there is no estimate of the intercepts in the coefficients. In fact, Even if I remove all predictors and use only 1|P_ID I still get the same warning. Thus I am inclined to believe that the intercepts is what is causing the model to be rank deficient. Would you trust this model even though the random intercepts have been dropped? When I run the model with CLMM I get Cumulative Link Mixed Model fitted with the Laplace approximation formula: PHQ_O ~ scale(Word_Count_log) * DREAM_MW + scale(NET_Max_BetwCentr) * DREAM_MW + scale(NET_Assort) * DREAM_MW + scale(PC1) * DREAM_MW + scale(PC2) * DREAM_MW + scale(NET_Clust_log) * DREAM_MW + scale(AGE) + COUNTRY + Gender + (1 | P_ID) data: dat_without_outlier Random effects: Groups Name Variance Std.Dev. P_ID (Intercept) 14242 119.3 Number of groups: P_ID 176 Coefficients: Estimate Std. Error z value Pr(>|z|) scale(Word_Count_log) 0.0006250 1.0554870 0.001 1.000 DREAM_MWMW 0.0078514 1.6572566 0.005 0.996 scale(NET_Max_BetwCentr) -0.0039393 1.0790258 -0.004 0.997 scale(NET_Assort) -0.0554854 1.0835674 -0.051 0.959 scale(PC1) -0.1251549 1.3783526 -0.091 0.928 scale(PC2) 0.0334129 1.1994965 0.028 0.978 scale(NET_Clust_log) 0.0452586 1.1606962 0.039 0.969 scale(AGE) -0.6171506 1.1746190 -0.525 0.599 COUNTRY -0.6033784 2.2255824 -0.271 0.786 Gender 1.5192000 2.2200040 0.684 0.494 scale(Word_Count_log):DREAM_MWMW -0.0008618 1.5325793 -0.001 1.000 DREAM_MWMW:scale(NET_Max_BetwCentr) -0.0259943 1.6040602 -0.016 0.987 DREAM_MWMW:scale(NET_Assort) 0.1917768 1.6785488 0.114 0.909 DREAM_MWMW:scale(PC1) 0.0550844 1.9661386 0.028 0.978 DREAM_MWMW:scale(PC2) -0.0819698 1.6194986 -0.051 0.960 DREAM_MWMW:scale(NET_Clust_log) -0.0825658 1.7257390 -0.048 0.962 Threshold coefficients: Estimate Std. Error z value mild|moderate 17.963 3.552 5.057 moderate|severe 42.162 4.003 10.533 Here there are no significant variables (note I have not tested assumptions for this), thus in contradiction with all the other models. Still no intercept. With CLMM2 instead I get a rank deficient warning. Warning: **design appears to be rank-deficient, so dropping some coefs** Call: clm2(location = PHQ_O ~ scale(Word_Count_log) * DREAM_MW + scale(NET_Max_BetwCentr) * DREAM_MW + scale(NET_Assort) * DREAM_MW + scale(PC1) * DREAM_MW + scale(PC2) * DREAM_MW + scale(NET_Clust_log) * DREAM_MW + scale(AGE) + COUNTRY + Gender + (1 | P_ID), data = dat_without_outlier) Location coefficients: Estimate Std. Error z value Pr(>|z|) scale(Word_Count_log) 0.0274 0.0620 0.4428 0.65788451 DREAM_MWMW 0.1717 0.1017 1.6886 0.09130061 scale(NET_Max_BetwCentr) 0.0462 0.0642 0.7187 0.47230257 scale(NET_Assort) -0.1091 0.0672 -1.6243 0.10432032 scale(PC1) -0.2310 0.0877 -2.6342 0.00843454 scale(PC2) 0.0980 0.0739 1.3262 0.18478429 scale(NET_Clust_log) 0.0712 0.0714 0.9971 0.31874001 scale(AGE) -0.5953 0.0523 -11.3840 Still no intercept but at least similar results to POLR An alternative is to run the model with averaged values per each participant (thus removing the need to have random effects defined but also reducing statistical power [?]). Here I get no errors but completely different results which is quite discouraging. Why might this be? Would you trust these results given the difference between the approaches? Call: polr(formula = PHQ_O ~ Word_Count_log_Dream + Word_Count_log_MW + NET_Max_BetwCentr_Dream + NET_Max_BetwCentr_MW + NET_Assort_Dream + NET_Assort_MW + PC1_Dream + PC1_MW + PC2_Dream + PC2_MW + NET_Clust_log_Dream + NET_Clust_log_MW + COUNTRY, data = dat_NoRand, control = c(maxit = 1e+05, trace = 0), na.action = na.omit, Hess = TRUE) Coefficients: Value Std. Error t value Word_Count_log_Dream 0.03329 0.1833 0.18168 Word_Count_log_MW -0.07240 0.1861 -0.38902 NET_Max_BetwCentr_Dream 0.41708 0.1977 2.11004 NET_Max_BetwCentr_MW -0.23394 0.1716 -1.36330 NET_Assort_Dream -0.16045 0.2109 -0.76074 NET_Assort_MW 0.27102 0.2042 1.32698 PC1_Dream -0.25567 0.2189 -1.16774 PC1_MW -0.28361 0.2539 -1.11694 PC2_Dream -0.10281 0.1839 -0.55896 PC2_MW 0.05536 0.1848 0.29953 NET_Clust_log_Dream 0.07895 0.1941 0.40665 NET_Clust_log_MW 0.01616 0.2192 0.07374 COUNTRY -0.51941 0.3505 -1.48187 Intercepts: Value Std. Error t value none|mild -0.9049 0.2985 -3.0314 mild|moderate 0.8907 0.2980 2.9888 moderate|moderate-severe 2.9225 0.4413 6.6228 moderate-severe|severe 3.5130 0.5483 6.4068 Residual Deviance: 346.9475 AIC: 380.9475 (28 observations deleted due to missingness) z test of coefficients: Estimate Std. Error z value Pr(>|z|) Word_Count_log_Dream 0.033294 0.183256 0.1817 0.855834 Word_Count_log_MW -0.072396 0.186099 -0.3890 0.697262 NET_Max_BetwCentr_Dream 0.417075 0.197663 2.1100 0.034855 * NET_Max_BetwCentr_MW -0.233942 0.171599 -1.3633 0.172788 NET_Assort_Dream -0.160454 0.210918 -0.7607 0.446811 NET_Assort_MW 0.271018 0.204237 1.3270 0.184517 PC1_Dream -0.255674 0.218948 -1.1677 0.242911 PC1_MW -0.283614 0.253921 -1.1169 0.264021 PC2_Dream -0.102809 0.183928 -0.5590 0.576188 PC2_MW 0.055363 0.184831 0.2995 0.764532 NET_Clust_log_Dream 0.078948 0.194145 0.4066 0.684267 NET_Clust_log_MW 0.016160 0.219169 0.0737 0.941221 COUNTRY -0.519406 0.350507 -1.4819 0.138374 none|mild -0.904885 0.298503 -3.0314 0.002434 ** mild|moderate 0.890692 0.298015 2.9888 0.002801 ** moderate|moderate-severe 2.922522 0.441279 6.6228 3.523e-11 *** moderate-severe|severe 3.513019 0.548324 6.4068 1.486e-10 *** --- My question is can I trust any of these models (in particular, I would like to use a mixed model)? Secondly, what could I do to improve the situation? What would you do? Any suggestions welcome. I am quite unsure of how to define the Bayesian prior so I have not tried this. All the best Thank you.
