[site]: crossvalidated
[post_id]: 269528
[parent_id]: 269306
[tags]: 
The 14th page is not about PLS, it is about PCA since it refers to decomposition of $X$ alone by carrying out singular value decomposition which is an efficient way to obtain eigenvalues($D$) and eigenvectors($V$) of $\operatorname{cov}(X)$). So in PCA case, the orthogonality of $P$ is correct. In PLS, however, the only property of $X$ loadings is each vector in $P$ matrix has unit length ($||p_i||$ = 1) whereas $W$ is orthogonal. In fact, the addition of $W$ is to ensure the orthagonality of $X$ scores($T$) and it is one of the main differences between PLS NIPALS and PCA NIPALS. Thus, as said in comments, $P$ and $W$ are not the same matrices. As a small note I prefer SIMPLS algorithm which is faster and it provides a single vector for regression and makes interpretation a lot easier unlike NIPALS with multiple vectors each corresponding to deflated $X$ which is, in my opinion, quite counter-intuitive and hard to interpret. The properties of PLS factors obtained by NIPALS algorithm can be found in this article: Geladi, Paul, and Bruce R. Kowalski. "Partial least-squares regression: a tutorial." Analytica chimica acta 185 (1986): 1-17.
