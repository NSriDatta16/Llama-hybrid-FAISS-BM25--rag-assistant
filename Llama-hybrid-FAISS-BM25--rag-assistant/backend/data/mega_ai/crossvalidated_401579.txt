[site]: crossvalidated
[post_id]: 401579
[parent_id]: 317065
[tags]: 
Short answer: This is quite a subtle issue relating to the interaction of marginal and conditional independence. The outcomes of the Roulette wheel are conditionally independent (conditional on the underlying distribution of outcomes) but they are marginally positively correlated when you do not condition on the underlying distribution. Your friend is essentially correct, though he might not be explaining this distinction properly. Full answer: This exact issue has been discussed in detail in a series of academic papers on binomial and multinomial prediction in Bayesian analysis (see O'Neill and Puza 2005 ; O'Neill 2012 ; O'Neill 2015 ). Those papers examine models where there is an exchangeable sequence of outcomes , which leads to the IID statistical model. Most importantly, the observable outcomes in the model are independent and identically distributed conditional on the underlying distribution (or equivalently, its indexing parameters), but this does not mean they are marginally independent. As discussed in detail in O'Neill (2009) , when we examine the marginal distribution of the observable values from an exchangeable sequence (i.e., not conditional on knowledge of their underlying distribution), we see that there is no longer independence between the observable outcomes, and indeed, these generally have positive correlation. Theorem 2 of that paper is reproduced here in slightly different language. Consider an exchangeable sequence $X_1,X_2,X_3,...$ . From the representation theorem, the values of the sequence are IID conditional on the underlying distribution $F_X$ (which we will take to be indexed by a parameter $\theta$ ). Define the conditional mean and variance as: $$\mu(\theta) \equiv \mathbb{E}(X_i|\theta) \quad \quad \quad \sigma^2(\theta) \equiv \mathbb{V}(X_i|\theta).$$ For all $i \neq j$ we have: $$\begin{equation} \begin{aligned} \mathbb{Cov}(X_i,X_j) &= \mathbb{E}(X_i X_j) - \mathbb{E}(X_i) \mathbb{E}(X_j) \\[6pt] &= \mathbb{E}(\mathbb{E}(X_i X_j|\theta)) - \mathbb{E}(\mathbb{E}(X_i|\theta)) \mathbb{E}(\mathbb{E}(X_j|\theta)) \\[6pt] &= \mathbb{E}(\mu(\theta)^2) - \mathbb{E}(\mu(\theta))^2 \\[6pt] &= \mathbb{V}(\mu(\theta)) \geqslant 0, \\[6pt] \end{aligned} \end{equation}$$ and: $$\mathbb{Corr}(X_i,X_j) = \frac{\mathbb{Cov}(X_i,X_j)}{\mathbb{V}(X_i)} = \frac{\mathbb{V}(\mu(\theta))}{\mathbb{V}(\mu(\theta)) + \mathbb{E}(\sigma^2(\theta))} \geqslant 0.$$ (Unless $\mu(\theta)$ is almost surely constant, these inequalities are strict.) This marginal probability result reflects the fact that observed outcomes give information on the underlying distribution, which alters our beliefs in such a way that we believe that future outcomes are likely to be the same or similar to observed values. This all occurs explicitly in Bayesian analysis, but in the context of frequentist analysis it is a bit trickier, since frequentists never make probability statements that are not conditional on the underlying parameters. The cited paper discusses this issue in detail, and notes that in this context there is no explicit correlation, but there is a form of pseudo-correlation that arises under the frequentist paradigm. If you would like to learn more about this issue, I recommend reading those papers as a starting point. Application of this situation to gambling games and the gambler's fallacy is discussed in detail. In regard to Roulette, your friend is correct that, if there is any non-zero probability of "bias" in the wheel, then ---looking at the marginal distribution of the outcomes--- the outcomes are positively correlated (and hence are used to predict each other). It is also correct that the outcomes remain conditionally independent, given knowledge of the underlying distribution (and hence the underlying "bias" of the wheel).
