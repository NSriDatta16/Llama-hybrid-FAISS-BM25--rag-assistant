[site]: crossvalidated
[post_id]: 584572
[parent_id]: 584567
[tags]: 
Importance sampling returns an unbiased estimate of the expectation of interest, $E$ say, for all valid importance densities $q$ . The choice of $q$ is driven by (i) the possibility to simulate from $q$ , (ii) the ability to compute the importance ratio $f(\cdot)p_z(\cdot)/q(\cdot)$ , and (iii) a reduced variance ${}^\star$ of the Monte Carlo estimate , $$\widehat E = \frac{1}{n}\sum_{i=1}^n f(z_i) \frac{p_z(z_i)}{q(z_i)}\qquad z_i\stackrel{\text{iid}}{\sim} q\tag{1}$$ which means $q(\cdot)$ must be as similar as possible to $|f(\cdot)|p_z(\cdot)$ , which formally is the optimal choice , albeit of no use since it requires the value of $E$ . Avoiding the kernel of $f$ , i.e., the region of the space $\mathfrak X$ where $$f(z)=0$$ is a good thing for estimating $E$ , because this reduces the variance (e.g., in not producing a random number of zeroes in the Monte Carlo estimate), while not inducing bias. In other words, since $$\int f(z)p_z(z)\,\text dz=\int f(z)\mathbb I_{f(z)\ne 0}p_z(z)\,\text dz+\underbrace{\int f(z)\mathbb I_{f(z)=0}p_z(z)\,\text dz}_{\text{equal to }0}$$ using a random variable to approximate the second term is creating unnecessary noise. For instance, take the ideal case of an arbitrary density $q(\cdot)$ that is positive everywhere and consider $q^+(\cdot)$ , its truncation to the support of $f(\cdot)$ , i.e., $$q^+(x) = \dfrac{q(x)\mathbb I_{f(x)\ne 0}}{\int q(z)\mathbb I_{f(z)\ne 0}\text dz}\stackrel{\text{def}}{=}\dfrac{q(x)\mathbb I_{f(x)\ne 0}}{\mathfrak Q(f(X)\ne 0)}$$ as an alternative (valid) importance density. (I assume for comparison sake that $\mathfrak Q(f(X)\ne 0)>0$ can be computed exactly.) The importance Monte Carlo estimator associated with $q^+(\cdot)$ then writes as $$\frac{1}{n}\sum_{i=1}^n f(z_i) \frac{p_z(z_i)}{q^+(z_i)}\qquad z_i\stackrel{\text{iid}}{\sim} q^+$$ which can be rewritten as $$\frac{\mathfrak Q(f(X)\ne 0)}{n}\sum_{i=1}^n f(z_i) \frac{p_z(z_i)}{q(z_i)}\qquad z_i\stackrel{\text{iid}}{\sim} q^+\tag{2}$$ to compare with (1), which also writes as $$\frac{M}{n}\frac{1}{M}\sum_{i=1}^M f(z_i) \frac{p_z(z_i)}{q(z_i)}\qquad z_i\stackrel{\text{iid}}{\sim} q^+$$ where $$M\sim\mathcal Bin(n,\mathfrak Q(f(X)\ne 0))$$ is the random number of simulations $z_i$ from $q$ (out of $n$ ) such that $f(z_i)\ne 0$ , which are then simulations from $q^+$ . One can spot two sources of additional variability in (1), against (2): The random ratio $\frac{M}{n}$ has expectation $\mathfrak Q(f(X)>0)$ and variance $$\mathfrak Q(f(X)\ne 0)\mathfrak Q(f(X)=0)/n$$ (1) is based on less simulated random variables than (2), meaning that the variance of the empirical average is $n/M$ times larger for (1), compared with (2). ${}^\star$ It is important to remind readers that some importance functions $q$ lead to infinite variance solutions for pairs $(f,p_z)$ .
