[site]: crossvalidated
[post_id]: 582722
[parent_id]: 
[tags]: 
Bayesian inference, likelihood on positive data

Suppose I have a parameter $\theta$ , that I know is positive, and some data $(x_1,x_2,\dots,x_n)$ on noisy realisations of the $\theta$ . I then assume a prior with positive support on $\theta$ (lognormal for example). How important is it to assume a positive likelihood on $x|\theta$ as well, or is it reasonable to assume something like a Gaussian likelihood (which can be negative)? I ask this because the posterior of $\theta$ will have positive support regardless of what the likelihood is because the prior has positive support, so I don't really have to worry about the posterior of $\theta$ having probability on negative values. On the other hand, the data should in principle be always positive as well (since it represents measurements of $\theta$ with noise). In real life practical applications what do people usually do in situations like this (any examples would be much appreciated).
