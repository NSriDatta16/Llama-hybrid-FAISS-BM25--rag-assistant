[site]: crossvalidated
[post_id]: 324107
[parent_id]: 
[tags]: 
Python: Factor Analysis VS Autoencoder(keras) - Should their values be close

I'm trying to compare FactorAnalysis with AutoEncoders. My understanding is that AutoEncoders should be able to capture more of the the "non-linearity" of the data. My guess is that the loadings(FA._components) should somewhat match weights of the hidden layer of the keras autoencoder ? (just a better value) ? Am I completely wrong in thinking that - or is there something wrong with my coding setup I've setup the code to have a number of 2 FACTORS(loading) and thus set the hidden-layer's number of neurons also to 2. from keras.layers import Input, Dense from keras.models import Model import numpy as np from sklearn.decomposition import FactorAnalysis from collections import defaultdict # this is the size of our encoded representations encoding_dim = 3 x_train=np.array([[2,-1,3],[2.5,-1.5,3.3],[2.2,-1.2,3.6]]) inl= Input(shape=(3,)) encoded = Dense(2, activation='relu')(inl) decoded = Dense(3)(encoded) # this model maps an input to its reconstruction autoencoder = Model(inl, decoded) autoencoder.compile(optimizer='adadelta', loss='mse') autoencoder.fit(x_train, x_train, epochs=3000, batch_size=3) #print(autoencoder.predict(x_train)) print("\nWeights of Hidden Layer ~= Should it be the same as FA-Loadings'ish ?\n") print(autoencoder.layers[2].get_weights()[0]) fm = FactorAnalysis(n_components=2,max_iter=150).fit(x_train) print("\nFA-Loadings ~= Should it be the same as Autoencoders-weights'ish ?\n") print(fm.components_)
