[site]: crossvalidated
[post_id]: 582596
[parent_id]: 
[tags]: 
Emotion classifier: overfitting the training dataset

I'm working on a binary classification model over the RAVDESS dataset with a CNN model. These are the performances on the train and validation set and these are the performance on the test set for the unbalanced class distribution, the metrics that I need to check are recall, fscore, and precision. This is the class distribution but I'm trying so many different setups of the same CNN, and this is something like the best result. I still decreased the size of the CNN and used augmentation tecniques. Question: What can I do to decrease the overfitting on training data and get the validation error closer to the training error? My training dataset shape is (8144, 323, 1) and this is the model model = tf.keras.models.Sequential() model.add(tf.keras.layers.Conv1D(256, 8, padding='same', input_shape=(X_train.shape[1], 1))) model.add(tf.keras.layers.Activation('relu')) model.add(tf.keras.layers.Conv1D(256, 8, padding='same')) model.add(tf.keras.layers.BatchNormalization()) model.add(tf.keras.layers.Activation('relu')) model.add(tf.keras.layers.Dropout(0.25)) model.add(tf.keras.layers.MaxPooling1D(pool_size=(8))) model.add(tf.keras.layers.Conv1D(128, 8, padding='same')) model.add(tf.keras.layers.Activation('relu')) model.add(tf.keras.layers.Conv1D(128, 8, padding='same')) model.add(tf.keras.layers.Activation('relu')) model.add(tf.keras.layers.Conv1D(128, 8, padding='same')) model.add(tf.keras.layers.Activation('relu')) model.add(tf.keras.layers.Conv1D(128, 8, padding='same')) model.add(tf.keras.layers.BatchNormalization()) model.add(tf.keras.layers.Activation('relu')) model.add(tf.keras.layers.Dropout(0.25)) model.add(tf.keras.layers.MaxPooling1D(pool_size=(8))) model.add(tf.keras.layers.Conv1D(64, 8, padding='same')) model.add(tf.keras.layers.Activation('relu')) model.add(tf.keras.layers.Conv1D(64, 8, padding='same')) model.add(tf.keras.layers.Activation('relu')) model.add(tf.keras.layers.Flatten()) model.add(tf.keras.layers.Dense(2, activation="softmax")) opt = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.0, decay=0.0, nesterov=False) loss = tf.keras.losses.BinaryCrossentropy() model.summary() model.compile(loss=loss, optimizer=opt, metrics=['accuracy', fscore, precision, recall]) while I'm using some TensorFlow callback such as EarlyStopping and ReduceLROnPlateau
