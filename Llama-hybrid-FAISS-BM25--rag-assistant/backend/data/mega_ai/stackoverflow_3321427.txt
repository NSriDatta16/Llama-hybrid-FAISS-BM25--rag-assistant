[site]: stackoverflow
[post_id]: 3321427
[parent_id]: 3321308
[tags]: 
What you are seeing is the difference between sample variance and population variance and nothing to do with floating point precision or the accuracy of C#'s floating point implementation. You are calculating population variance. Excel and that web site are calculating sample variance. Var and VarP are distinct calculations and you do need to be careful about which one you are using. (unfortunately people often refer to them as if they are interchangeable when they are not. The same is true for standard deviation) Sample variance for your data is 1.56562E-06, population variance is 1.53492394804015E-06. From some code posted on codeproject awhile back: Variance in a sample public static double Variance(this IEnumerable source) { double avg = source.Average(); double d = source.Aggregate(0.0, (total, next) => total += Math.Pow(next - avg, 2)); return d / (source.Count() - 1); } Variance in a population public static double VarianceP(this IEnumerable source) { double avg = source.Average(); double d = source.Aggregate(0.0, (total, next) => total += Math.Pow(next - avg, 2)); return d / source.Count(); }
