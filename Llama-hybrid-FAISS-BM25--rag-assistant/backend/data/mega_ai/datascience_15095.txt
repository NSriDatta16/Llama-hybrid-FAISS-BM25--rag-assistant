[site]: datascience
[post_id]: 15095
[parent_id]: 15091
[tags]: 
Sum-pooling, which is of course just a scaled version of mean pooling, has been proposed for the task of content-based image retrieval (CBIR). To my best knowledge, the first paper for this was the following, and has (according to Google Scholar) gathered 35 citations over its first year of being published: 1 A. Babenko and V. Lempitsky: "Aggregating Deep Convolutional Features for Image Retrieval". In IEEE International Conference on Computer Vision (ICCV) , Dec. 2015, pp. 1269-1277. DOI: 10.1109/ICCV.2015.150 . arXiv: 1510.07493 . A very short explanation of image retrieval: For large-scale image retrieval, a new query image has to be compared to a database of thousands of images to find the most similar image. While previous work has achieved this by matching SIFT descriptors, recently CNN-based descriptors have become the state-of-the-art 2 . The basic idea when using CNNs for image retrieval is, to use a network which is pre-trained (usually on a classification task, such as ILSVRC) and use the output of a layer as the descriptor vector 3,4 . Different papers propose using either one of the FC layers or one of the Conv layers as the descriptor. As the outputs of these layers are very large - too large to use as a "compact" descriptor of an image - the usual approach is to reduce the dimensionality to something in the range of 32 to 1024. This is usually done by L2-normalization → PCA Whitening → L2-normalization 1,3,4 . Now finally, I get to the sum-pooling part: Babenko and Lempitsky 1 show that sum-pooling leads to a better retrieval performance than max-pooling, when the dimensionality of the resulting descriptor is reduced using PCA and Whitening. Their SPoC (Sum-Pooling of Convolutions) method outperforms other pooling/embedding methods, such as max-pooling, Fisher vectors and triangular embedding. Final words: more recent work (ICLR 2016) proposes the so-called R-MAC descriptor 5 , which is the regional maximum activations of convolutions, i.e. they use a set of regions at different scales, calculate the feature vector for each region using max-pooling, and finally sum up all these regional feature vectors. This again improves over the sum-pooling proposed in 1 . Still it has a kind of sum-pooling over the different regions in it. Footnotes & References 2 If required, I can add a few citations to show this, just comment below. 3 A.S. Razavian, H. Azizpour, J. Sullivan, and S. Carlsson, "CNN Features Off-the-Shelf: An Astounding Baseline for Recognition", in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops , Jun. 2014, pp. 512–519. DOI: 10.1109/CVPRW.2014.131 . arXiv: 1403.6382 . 4 A. Babenko, A. Slesarev, A. Chigorin, and V. Lempitsky, "Neural Codes for Image Retrieval", in European Conference on Computer Vision (ECCV) , Sep. 2014, pp. 584–599. DOI: 10.1007/978-3-319-10590-1_38 . arXiv: 1404.1777 . 5 G. Tolias, R. Sicre, and H. Jégou, "Particular object retrieval with integral max-pooling of CNN activations", in International Conference on Learning Representations (ICLR) , Oct. 2016, pp. 1–11. arXiv: 1511.05879 .
