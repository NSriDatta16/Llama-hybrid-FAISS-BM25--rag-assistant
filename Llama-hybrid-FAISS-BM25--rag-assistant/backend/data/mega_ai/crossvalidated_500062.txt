[site]: crossvalidated
[post_id]: 500062
[parent_id]: 500053
[tags]: 
Interesting thread! I'll chime in for the fun of it. lme() When you formulate your lme() model, you are implicitly assuming that your output variable is a continuous random variable. For example, output could be a variable such as body weight , which in principle could take any value within a plausible range of values. The lme() model you stated would be interpreted with this assumption of a continuous output variable in mind: library(nlme) model The model will tell you how the expected value of the output variable depends on condition for a typical participant (i.e., a participant with a random intercept equal to 0). Because R uses dummy coding for the predictor condition , it will encode the effect of condition by including two dummy variables in the model. If your condition predictor has 3 levels, denoted as 0, 1 and 2, R will treat the first of these levels as the reference condition and define the dummy variables that will help you compare the remaining non-reference conditions to the reference one. Specifically, the two dummy variables will be defined as: condition1 = 1 if condition is equal to 1 and 0 else and condition2 = 1 if condition is equal to 1 and 0 else Note that these dummy variables are NOT physically added to your dataset; they are however used by R when it fits the model as if they were included. When you interpret the summary of your lme() model, you will see R report the expected value of the output variable for the reference condition (i.e., condition 0) for the typical subject: look for it in the fixed effects portion of your summary, at the intersection of the Intercept row and the Estimate column. R will also report the difference in the expected values of the output variable between condition 1 and condition 0: look for it at the intersection of the condition1 row and the Estimate column. The difference in the expected values of the output variable between condition 2 condition 0 will be found at the intersection of the condition2 row and the Estimate column. If you parametrize the model like this (i.e., if you force R to fit a model without a fixed intercept): library(nlme) model this will prompt R to report the expected values of the output variable for the typical subject for all 3 conditions (rather than the expected value for condition 0 and the differences in expected values between conditions 2 and 3, respectively, and condition 0). In other words, expect to see something like this in your model output: Fixed effects: Estimate Std. Error z value Pr(>|z|) condition0 40.03 condition1 40.03 + (-39.63) condition2 40.33 + (-37.07) glmer() If your output variable is binary, you need to formulate your glmer() model using a binomial family and a logit link. For example, output could be a variable such as whether or not the study subject is overweight (where 1 = overweight, 0 = not overweight). A binary variable can only take 2 values: 1 or 0. This type of glmer() model is called a mixed effects binary logistic regression model and can be fitted like this in R: library(lme4) model The model will investigate how the log-odds that the output variable takes the value 1 rather than 0 for a typical participant (i.e., a participant with a random intercept equal to 0) depends on condition.
