[site]: datascience
[post_id]: 113649
[parent_id]: 
[tags]: 
Is it a good idea to test the robustness of a Neural Network on a linear relation?

Just to give you more context, I'm currently working on a finance project relying on neural network. I'm principally using Neural Network to achieve regression task. So my neural network aims to predict a non-linear convex relationship between input and output. model = keras.models.Sequential() model.add(keras.layers.Dense(n_units, activation='relu')) model.add(keras.layers.Dense(1)) model.compile(loss="mse", optimizer=tf.keras.optimizers.Adamax(learning_rate=learning_rate)) My supervisor told me to test the performance of my neural network on a linear relationship. ( I give as inputs the same regressors and as an output something which is a linear function of the regressors ). I don't really see how this could be pertinent, especially that my neural network is more likely to overfit my linear relation. Even if I perform a hyperparameters optimization to make my neural net works well on the linear relationship, I'm not sure it will work fine when I use it again for the non-linear. I'm really getting lost. Can anyone please advise me on a way I could make my neural net works well on both tasks? ( Or is it utopic to expect that from the neural net ). Thanks.
