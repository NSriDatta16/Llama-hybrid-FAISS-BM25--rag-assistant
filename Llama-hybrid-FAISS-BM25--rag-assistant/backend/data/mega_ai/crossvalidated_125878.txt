[site]: crossvalidated
[post_id]: 125878
[parent_id]: 
[tags]: 
likelihood in bayesian linear regression

I was going through the derivation for the likelihood of Bayesian linear regression http://en.wikipedia.org/wiki/Bayesian_linear_regression#Posterior_distribution I did not understand this step where the author explains the Conjugate prior distribution. $(\mathbf{y} - \mathbf{X}\boldsymbol{\beta})^T$ $(\mathbf{y} - \mathbf{X}\boldsymbol{\beta})$ = $(\mathbf{y} - \mathbf{X}\boldsymbol{\hat\beta})^T$ $(\mathbf{y} - \mathbf{X}\boldsymbol{\hat\beta})$ + $(\mathbf{\beta} -\mathbf{\hat\beta})^T$$(\mathbf{X}^T \mathbf{X})$$(\mathbf{\beta} -\mathbf{\hat\beta})$ Need help breaking this down.
