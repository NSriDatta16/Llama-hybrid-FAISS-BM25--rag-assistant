[site]: datascience
[post_id]: 11880
[parent_id]: 
[tags]: 
Which, if any, machine learning algorithms are accepted as being a good tradeoff between explainability and prediction?

Machine learning texts describing algorithms such as gradient boosting machines or neural networks often comment that these models are good at prediction, but this comes at the price of a loss of explainability or interpretability. Conversely, single decision trees and classical regression models are labelled as good at explanation, but giving a (relatively) poor prediction accuracy compared to more sophisticated models such as random forests or SVMs. Are there machine learning models commonly accepted as representing a good tradeoff between the two? Is there are any literature enumerating the characteristics of algorithms which allow them to be explainable? (This question was previously asked on cross-validated)
