[site]: crossvalidated
[post_id]: 250763
[parent_id]: 
[tags]: 
Deep Q Network for Uncontrolled Environment

I was wondering what modifications should be done to DeepMind's DQN algorithm if we are faced with an environment that is not modified by the agent's actions. Meaning that if we were in state s and took action a, we don't always go to the same new state s'. Like in trading for example. When you enter a trade, you don't shape the environment. Any suggestions or references are much appreciated.
