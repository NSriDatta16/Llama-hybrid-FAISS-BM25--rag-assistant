[site]: crossvalidated
[post_id]: 472348
[parent_id]: 315872
[tags]: 
I just ran across this question because I was wondering the same thing. I think I have it figured out, however. The misclassification error is a test/outsample error when using a 0/1 loss function, conditional on the used data set/model (with a given threshold). It averages out this error over all X and Y, even those not in the data set. In the spirit of cross validation, we are, however, almost always interested in the expected test error, which averages over the distribution of test data sets. The misclassification error you see as output of, for example, the plot of the cv.glmnet, is averaged out for every model you could employ with a varying threshold for every 'dataset' in the cross-validation procedure.
