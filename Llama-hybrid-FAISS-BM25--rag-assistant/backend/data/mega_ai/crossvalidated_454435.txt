[site]: crossvalidated
[post_id]: 454435
[parent_id]: 454432
[tags]: 
In the notation of $x \in \mathbb{R}^n$ , $n$ usually means number of 'predictors' or 'features' in machine learning context*. For example, in IRIS data set , we have 4 features, so, we can say, each data point is a 4 dimensional point, and we can write $x \in \mathbb{R}^4$ . *well, this is not completely true, because usually we add 1 intercept column to data. The reason we need such notation is that, in many cases, say linear model, we will learn a parameter/weights $\beta$ also in (or related to) $w \in \mathbb{R}^n$ . For example, if we want build a linear model without intercept on IRIS data, the data matrix $X_{m \times n}$ can be $150 \times 4$ , where we have 150 points, and 4 features. And the weights we are fitting is $4 \times 1$ . The model is $X\beta$ , and the output will be $150\times 1$ . Note that, people also use $X_{n\times p}$ to represent data matrix, in that case, $n$ will be number of data and $p$ will be number of features.
