[site]: crossvalidated
[post_id]: 320154
[parent_id]: 
[tags]: 
When not to use cross validation?

As I read through the site most answers suggest that cross validation should be done in machine learning algorithms. However as I was reading through the book "Understanding Machine Learning" I saw there is an exercise that sometimes it's better not to use cross validation. I'm really confused. When training algorithm on the whole data is better than cross-validation? Does it happen in real data-sets? Let $H_1,...,H_k$ be k hypothesis classes. Suppose you are given $m$ i.i.d. training examples and you would like to learn the class $H=\cup^k_{i=1}H_i$ . Consider two alternative approaches: Learn $H$ on the $m$ examples using the ERM rule Divide the m examples into a training set of size $(1−\alpha)m$ and a validation set of size $\alpha m$ , for some $\alpha\in(0,1)$ . Then, apply the approach of model selection using validation. That is, ﬁrst train each class $H_i$ on the $(1−\alpha)m$ training examples using the ERM rule with respect to $H_i$ ,and let $\hat{h}_1,\ldots,\hat{h}_k$ be the resulting hypotheses. Second, apply the ERM rule with respect to the ﬁnite class { $\hat{h}_1,\ldots,\hat{h}_k$ } on the $\alpha m$ validation examples. Describe scenarios in which the ﬁrst method is better than the second and vice versa. Image of the quastion .
