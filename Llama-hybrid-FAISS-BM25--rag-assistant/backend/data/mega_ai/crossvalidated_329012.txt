[site]: crossvalidated
[post_id]: 329012
[parent_id]: 201352
[tags]: 
You use the residuals to estimate the distribution of the error. https://en.wikipedia.org/wiki/Errors_and_residuals , but these are different things. Errors are what the 'true' model includes as randomness Residuals are the differences that you 'observe' between a model fit and a measurement. The residuals do not resemble the errors. When you fit a model then you will fit to the model plus the error terms. This means that the fitting has a tendency to fit a part of the error terms, in addition to the model, and this will in effect, on average, decrease the residuals in relation to the true errors. The more parameters the model has (the more degrees of freedom the model has to fit, cover up, the partial error terms) the less the residuals will resemble the true distribution of the error. So the expression $\frac{\sum r_i^2}{n-2}$ refers to $r_i$ as 'residual' terms, but wishes to express some idea of variance in the 'error' terms and in order to do this it need to include the ' $n-2$ ' instead of the ' $n$ ' term because the residual terms have a slight bias. Related questions for intuition about the $n-p$ factor in ordinary linear regression Why don't standard estimation methods consider the distribution of the residual? the residuals can be considered as a projection of the errors $\mathbf{r} = \left(\mathbf{I}-\mathbf{A}(\mathbf{A}^t\mathbf{A})^{-1}\mathbf{A}^t\right) \mathbf{n}$ Why are the residuals in $\mathbb{R}^{n-p}$? We can consider the variance of the observation to be split up into two orthogonal spaces, one with dimensions $p$ and the other with dimension $n-p$ .
