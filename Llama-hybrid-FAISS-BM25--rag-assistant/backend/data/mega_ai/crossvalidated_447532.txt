[site]: crossvalidated
[post_id]: 447532
[parent_id]: 
[tags]: 
Bayesian Bootstrap interpretation

I am using Bayesian Bootstrap for some analysis. Given dataset $X=\{x_1, \dots, x_N\}$ , we generate bootstrapped samples $X_1,\dots, X_K$ by sampling from the $X$ , with replacement. In classical bootstrap, the weights are equal, that is, each data $x_n$ in $X$ has $\pi_n=1/N$ probability of being present in $X_k$ . In a Bayesian variant, these probabilities $\pi_n$ are sampled from a non-informative, flat Dirichlet distribution $$ \pi_n\sim p(\pi|X)=\mathcal{D}ir(\pi;\alpha) $$ where hyperparameter $\alpha$ is $[1,\dots, 1]\in R^N$ . Then I use these samples to find the distribution over some statistic $\phi$ of each sample $X_k$ . Now my questions are as follows: In the literature, for the classical case, the distribution of $\phi$ is referred to as sampling distribution of $\phi$ . In the Bayesian case, however, it is called posterior of $\phi$ . According to Bayes rule, I can say $$ p(\pi|X)\propto p(X|\pi)p(\pi) $$ Now I don't understand how the introduction of a prior over sampling weights makes the distribution of $\phi$ a posterior ? In the classical case, what does it mean to say that the underlying assumption is that distribution of the data is the distribution of the population ? What is population referring to here?
