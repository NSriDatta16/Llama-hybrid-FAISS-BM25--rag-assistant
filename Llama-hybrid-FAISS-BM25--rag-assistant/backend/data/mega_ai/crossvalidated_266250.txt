[site]: crossvalidated
[post_id]: 266250
[parent_id]: 265980
[tags]: 
I think using MLE here may give you misleading conclusions. You know that some outcome in $\mathcal{K}$ has occured and you want to compute and maximise the likelihood $L(\mathbf{p})=P(k\in\mathcal{K})$. For example, suppose the experiment is stopped when $k_0=1$ events in the category 0 has occured and the number of events in the other categories were any $$ k\in \mathcal{K}=\{(10,0,0,0),(0,0,0,10)\} $$ This tells you that $\mathbf{p}$ must be either quite close to $\mathbf{p}=(1/11,10/11,0,0,0\}$ or $\mathbf{p}=(1/11,0,0,0,10/11\}$ and this will appear as two optima in $L(\mathbf p)$ close to these values. You may be better off doing Bayesian inference, perhaps with a Dirichlet prior on $\mathbf{p}$. The resulting posterior would then be a Dirichlet mixture with components associated with each element in $\mathcal{K}$.
