[site]: crossvalidated
[post_id]: 345604
[parent_id]: 
[tags]: 
"beta_given" column in the h2o.glm beta_constraints

What does the "beta_given" column do in the h2o.glm beta_constraints parameter? h2o is an open source library for machine learning algorithms. There are several online examples on how to install the library on different systems, and on how to apply it. The developer's site for h2o offers a summary description of algorithms; and there is at least one published publication Practical Machine Learning with h2o . The description for generalized linear models can be found in the page for h2o.glm . In that page, one can find the following explanation of the parameter beta_constraints : beta_constraints : Specify a dataset to use beta constraints. The selected frame is used to constrain the coefficient vector to provide upper and lower bounds. The dataset must contain a names column with valid coefficient names. There is a page for beta_constraints which adds detail on the structure of the dataset: it must have columns: 'names', 'lower_bounds', 'upper_bounds', 'beta_given', 'beta_start', 'rho', 'mean', and 'std_dev'. 'Names' is mandatory, most of the rest are optional. The page contains succinct explanations on each column. 'names', 'lower_bounds', 'upper_bounds' contain information similar to the analogous parameters in R's glmnet function , albeit in different format. The explanation for beta_given reads: beta_given : (optional) Specifies the given solution. This works as a base in proximal penalty. I suspect that h2o.glm minimizes: $$ -{\rm loglikelihood} + \lambda(\alpha\|\beta\|_1 + (1-\alpha)\|\beta\|_2^2) + \frac{1}{2\rho}\|\beta - \text{beta_given}\|_2^2 $$ over the model parameter vector $\beta$, subject to lower and upper bound constraints. The parameters $\lambda$ and $\alpha$ are fixed in the optimization over $\beta$, with values taken from a grid search set. The factor involving $\rho$ might be $\frac{\rho}{2}$ instead of $\frac{2}{\rho}$. The page makes reference to Proximal Algorithms by Boyd et al. , in which the term with the $\ell_2$ norm is multiplied by $1/(2\lambda)$ (the use of $\lambda$ there is not the same as in h2o.glm ). The formula above is clearer than the description of 'beta_given' in the help, or if not clearer, at least less ambiguous, and certainly succinct, which makes me doubt it is correct, thus my question. Being an open source library, it is possible to look at the code and answer the question. I have not attempted to do that. I have limited myself to online searches.
