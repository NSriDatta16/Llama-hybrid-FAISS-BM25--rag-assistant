[site]: stackoverflow
[post_id]: 4353715
[parent_id]: 
[tags]: 
classical AI, ontology, machine learning, bayesian

I'm starting to study machine learning and bayesian inference applied to computer vision and affective computing. If I understand right, there is a big discussion between classical IA, ontology, semantic web researchers and machine learning and bayesian guys I think it is usually referred as strong AI vs weak AI related also to philosophical issues like functional psychology (brain as black box set) and cognitive psychology (theory of mind, mirror neuron), but this is not the point in a programming forum like this. I'd like to understand the differences between the two points of view. Ideally, answers will reference examples and academic papers where one approach get good results and the other fails. I am also interested in the historical trends: why approaches fell out of favour and a newer approaches began to rise up. For example, I know that Bayesian inference is computationally intractable, problem in NP, and that's why for a long time probabilistic models was not favoured in information technology world. However, they've began to rise up in econometrics.
