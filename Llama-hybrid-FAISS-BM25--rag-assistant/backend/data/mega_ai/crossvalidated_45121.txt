[site]: crossvalidated
[post_id]: 45121
[parent_id]: 
[tags]: 
choosing an initial state and finding multiple sample points in MCMC?

In a discrete-time Markov chain, having constructed the transition distributions, the initial distribution should not affect the limiting distribution (when it exists) in theory. So in MCMC, how to choose the initial state should not affect that the distribution of $X_n$ will converges to the target distribution. But I wonder if the initial state can really be arbitrarily chosen? Is there some consideration for picking the initial state? If we want to get multiple sample points from the same discrete-time Markov chain, which one is better: Starting from a state, after sufficiently long time, all sample points will be kept. Starting from a state, after sufficiently long time, the first sample point will be kept. Then start over again from a state, after sufficiently long time, the second sample point will be kept. So on for the third, fourth, ..., sample points. I saw in a note uses the second way, and the initial state is fixed over all runs that start over. I am not sure what benefits can using the same or different initial state bring? Thanks!
