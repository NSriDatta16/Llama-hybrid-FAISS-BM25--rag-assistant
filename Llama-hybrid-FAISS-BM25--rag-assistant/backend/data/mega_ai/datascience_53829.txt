[site]: datascience
[post_id]: 53829
[parent_id]: 43436
[tags]: 
I'm an old man who likes simple things :D So I would try a few more basic options for the level 2 model: majority voting (it hardly gets simpler than that!) linear regression single decision tree SVM Apart from the fact that I'm old, there are two reasons why these could be useful: smaller risk of overfitting: If the level 2 model is too complex it tends to overfit, and in my experience there's a high price to pay for that in terms of performance at level 2 when stacking learners. scrutiny: one can easily investigate what happens in the combination of predictions.
