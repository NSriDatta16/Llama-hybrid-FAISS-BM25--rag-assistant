[site]: crossvalidated
[post_id]: 130622
[parent_id]: 
[tags]: 
method/metric of comparing two random samples and their impact

I have the following problem. Given a set S of N=100000 data elements (time series data from solar observations) I need to extract a random sample R of size n=20 and then for each element in S compute the minimum distance to the points in R. That minimum distance is declared to be the rank of the element. The problem is that the N data is not available all from the beginning but it is processed in parallel, in a distributed fashion, being available only partitions of M=8000 elements. I was thinking to generate a random sample for each partition and compute the ranks per partition, but then the ranks won't have the same meaning when compared across partitions since the partitions have different random samples (a point with rank=0.2 in a partition is not the same with a point with rank=0.2 in other partition). Do you have any idea of how can be unified the ranks globally, after they are computed locally, per partition? Is any way of comparing how similar 2 random samples are? Based on that, can we derive a metric to measure the impact of one random sample on a rank? The final goal is to unify all ranks and to have a correct global rank instead of partition based rank. Any ideas would be highly appreciated.
