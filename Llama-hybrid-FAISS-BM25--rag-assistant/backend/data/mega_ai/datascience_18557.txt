[site]: datascience
[post_id]: 18557
[parent_id]: 
[tags]: 
Is there a way to measure the "sharpness" of a decision boundary of a CNN?

It is commonly seen as something bad if the decision boundary of a neural network is too sharp, meaning if slight changes in the input change the class prediction completely. Given a trained CNN, is it possible to measure / calculate the "sharpness" of its decision boundaries? Did somebody do that already?
