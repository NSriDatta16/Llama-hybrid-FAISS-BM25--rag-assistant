[site]: crossvalidated
[post_id]: 422112
[parent_id]: 
[tags]: 
How to learn embeddings from lists of data?

My objective is to learn an embedding for translate sentences from one language to another. The problem is that my data looks like this: Lang_1 Lang_2 --------------------------------------------------------------- token_1 token_2 ... Token_3 | [['Token_1', 'Token_2', 'Token_3',...,'Token_n'], .... ['Token_1', 'Token_2', 'Token_3',...,'Token_n']] --------------------------------------------------------------- ... | ..... | --------------------------------------------------------------- token_1 token_2 ... Token_3 | [['Token_1', 'Token_2', 'Token_3',...,'Token_n'], .... ['Token_1', 'Token_2', 'Token_3',...,'Token_n']] So what I would like to do is to use some sort of seq2seq and train it over those pairs. Then, extract the final state vector layer, and use it as an embedding. The problem is that I do not know how to use Lang_2 column. Because if I flat that column I will lose the order of the token sentences of col Lang_2 which i think might help for my prediction embedding. What alternatives do I have here in order to not lose the order and learn a good embedding from the pairs?
