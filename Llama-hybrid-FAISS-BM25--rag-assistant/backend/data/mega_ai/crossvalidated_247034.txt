[site]: crossvalidated
[post_id]: 247034
[parent_id]: 247008
[tags]: 
Your model $y\propto Sex$ is simple but the variable $Sex$ does not explain most of the variance in $y$. In fact, a large p value for the $\beta_1$ coefficient simply indicates that there is a coefficient $\beta_1$ that given the appropriate value will change in the same direction as $y$. This change explains very little of the variance in $y$ as a function of $Sex$. If you add just another continuous variable the effect size should be even greater as the fitting now occurs over the range of values of the other variable. Keep in mind that when you regress on only one categorical variable with values of 0 and 1, when the categorical variable is zero you are fitting against the average of the dependent variable as the product of $\beta_1 * 0 = 0$. So if there are no more variables you are left with just the intercept and a large error term. As explained in Why is my R-squared so low when my t-statistics are so large? having more observations makes the small explanation of the independent variable by your coefficient more robust but not more precise as your variance remains largely unexplained by the dependent variables.
