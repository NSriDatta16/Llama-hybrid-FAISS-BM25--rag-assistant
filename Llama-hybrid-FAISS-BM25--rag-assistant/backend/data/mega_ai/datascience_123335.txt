[site]: datascience
[post_id]: 123335
[parent_id]: 
[tags]: 
Problem calculating f-1 score when when running hyperparameter tuning using Optuna

I'm trying to run Stratified CV hyperparameter tuning on an XGBClassifier using Optuna. This is a multiclass problem with 3 classes (labelled 0 through 2 in the "classes" variable). These are the dimensions of the inputs: " x " is a (4000, 43) sparse COO matrix " classes " is a (4000,) dense flat numpy array I use Hyperband pruning through callbacks and a custom f-1 function (since XGBoost's .cv() method doesn't provide this metric). The problem is in the function weighted_f1_score (which is executed as a callback through the.cv() method), preds is a flat array of probabilities, so when I try to use "argmax" to get the predicted class for each sample it returns an error. It would work if only .cv() simply returned class predictions instead of probabilities. I'm not sure how to solve this and I'm really stumped by this. I hope someone more knowledgeable can help. Here's the code snippet: import optuna from sklearn.model_selection import StratifiedKFold from xgboost import cv, DMatrix import optuna.integration.xgboost as xgb_integration from sklearn.metrics import f1_score def objective(trial): # Define hyperparameter search space params = { 'objective': 'multi:softmax', 'n_estimators': trial.suggest_int('n_estimators', 50, 300), 'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0, log=True), 'max_depth': trial.suggest_int('max_depth', 3, 10), 'min_child_weight': trial.suggest_int('min_child_weight', 1, 10), 'subsample': trial.suggest_float('subsample', 0.1, 1.0), 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0), 'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True), 'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True), 'gamma': trial.suggest_float('gamma', 0.01, 10.0, log=True) } # Custom weighted F1 score metric for multiclass classification def weighted_f1_score(preds, dtrain): y_true = dtrain.get_label() y_pred = np.argmax(preds, axis=1) f1 = f1_score(y_true, y_pred, average='weighted') return 'weighted-f1-score', f1 # Stratified Cross-Validation using xgb.cv() with XGBoostPruningCallback pruning_callback = xgb_integration.XGBoostPruningCallback(trial, 'test-weighted-f1-score-mean') strat_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) cv_results = cv(params, dtrain = DMatrix(x, label=classes), num_boost_round = 100, folds = strat_folds, early_stopping_rounds = 10, maximize = True, custom_metric = weighted_f1_score, callbacks = [pruning_callback], verbose_eval = False) # Use the mean value across all folds as the objective: return np.mean(cv_results['test-weighted-f1-score-mean']) # Define Optuna study study = optuna.create_study(direction = 'maximize', pruner = optuna.pruners.HyperbandPruner()) # Start optimization process: study.optimize(objective, n_trials = 100, n_jobs = os.cpu_count(), show_progress_bar=True) # Get the best parameters best_params = study.best_params # Print the best hyperparameters and score best_trial = study.best_trial print('Best trial:') print('Value: {}'.format(best_trial.value)) print('Params: ') for key, value in best_trial.params.items(): print(' {}: {}'.format(key, value)) # Retrain XGBClassifier on the whole dataset with the best parameters: best_xgb = XGBClassifier(**best_params, objective ='multi:softmax', n_jobs = os.cpu_count(), booster='gbtree', tree_method = 'hist', random_state = self.random_state) # Fit final model: best_xgb.fit(x, classes)
