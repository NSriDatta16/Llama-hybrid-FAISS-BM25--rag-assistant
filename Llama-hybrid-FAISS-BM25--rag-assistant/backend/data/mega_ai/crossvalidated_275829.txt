[site]: crossvalidated
[post_id]: 275829
[parent_id]: 111362
[tags]: 
The best solution is to use OneHotEncoding for categorical attributes. Have a look at implementation of OneHotEncoding on sklearn on this link. http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html After you convert these categorical data into OneHotEncoded data. It will be like for first attribute the values are A11, A12, A13, A14. so lets say we have training example that starts with A12. It will be converted into 0 1 0 0 in OneHotEncoding. You can similarly convert for all categorical attributes. For numerical data, normalize them to zero mean and standard deviation of 0.01. Although this step is not compulsory, but machine learning algorithms perform good on the normalized data. For the categorical attributes with two values, the best is to give them +1 and -1 Encoding. Once you do this for training data, you can easily import using pandas and differentiate between training data (all columns except last) and training label(last column). Then you can train using sckikit learn. I applied this strategy and for me RandomForestClassifier with 100 trees gave the best performance of 80% accuracy on 100 validation dataset that I separated from the training data.
