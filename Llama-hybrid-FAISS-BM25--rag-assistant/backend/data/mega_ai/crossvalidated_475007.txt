[site]: crossvalidated
[post_id]: 475007
[parent_id]: 474738
[tags]: 
If you're given a lot of freedom in the algorithm design, you can do the following : train one huge but shallow (ad probably non-convolutional, you really want it very powerful but very stupid) neural network to memorize the training set perfectly, as suggested by @Peteris and @Wololo (his solution has converted me). This network should give you both the classification and a boolean indicating whether this image is in your training set or not. To train this first network, you'll actually need additional training data from the outside, to train the "not in training set" part. train the best convnet that you can to actually do your task properly (without overfitting). During inference/evaluation, use the 1st network to infer whether the image is in the training set or not. If it is, output the classification you have "learnt by heart" in the 1st network, Otherwise, use the 2nd network to get the least likely classification for the image That way, with a large-enough 1st network, you should have 100% accuracy on the training data, and worse-than-random (often near-0%, depending on the task) on the test data, which is "better" than 100% vs random output.
