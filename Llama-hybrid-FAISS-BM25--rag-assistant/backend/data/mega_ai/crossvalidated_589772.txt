[site]: crossvalidated
[post_id]: 589772
[parent_id]: 
[tags]: 
Applying Bayes Theorem to combine probability mass functions of time series changes

I apologize. I'm not well trained in formal statistics, so feel free to gently correct my terminology and methods. For a univariate continuous real-valued time series X, I've calculated probability mass functions for changes over intervals 1 to N: ie. calculated the changes X(t) / X(t-n) (separately for n from 1 to N), binned those changes into a histogram and normalized it (sum of all bin values = 1). Note the bins on the ends represent = respectively to capture all values. I'll use PMF[n] to represent the probability mass function for X(t) / X(t-n) . For example, the bin for 1.01 to 1.02 of PMF[7] represents the probability that X(t+7) / X(t) is between 1.01 and 1.02 for any t. Example (I'm actually using hundreds of bins): PMF[1] = { ( 1.02, .2) } When X(t-1) = 734 then I have probabilities for X(t): 10%: .98 * 734 = 748.68 However, I also have PMF[2]. I could use that with X(t-2) and get another set of probabilities for X(t). In general, I want to calculate a combined probability mass function for the value of X(t) where t is one step beyond the data. I have N PMFs and N data points: PMF[1] with X(t-1), PMF[2] with X(t-2),..., PMF[N] with X(t-N). I want to combine these and it seems Bayes Theorem might be a mechanism to do so. At t-10, I have PDF[10]. Then when t-9 is measured, I have new evidence and so can adjust the prediction which seems to be what Bayes Theorem is all about. And I don't want to throw away PMF[10] and only use PMF[9] because PMF[10] is still valid useful information. But I'm a little loss how I might do that. I'd appreciate some direction. Below is my first pass at it but I imagine it's confusing and wrong. Let's look at just combining 2 to start with: combine X(t-2)*PMF[2] and X(t-1)*PMF[1] to predict X(t). For Bayes Theorem, we have: P(A|B) = P(B|A) * P(A) / P(B) A = predicting value at t (expect a pmf out, one probability for each possible bin for A) B = X(t-1) # measured value at t-1 P(B) = PMF1 # The probability that the measured X(t-1) would have happened I'm guessing: P(A) = PMF2 P(B|A) = PDF1 Which gives: P(A|B) = PMF1 * PMF2 / PMF1 But I'm not sure about that, and if it's bin-wise multiplication, it seems like the resulting pmf wouldn't sum to one.
