[site]: crossvalidated
[post_id]: 12585
[parent_id]: 2379
[tags]: 
Michael Jordan has a short article called What are the Open Problems in Bayesian Statistics? , in which he polled a bunch of statisticians for their views on the open problems in statistics. I'll summarize (aka, copy-and-paste) a bit here, but it's probably best just to read the original. Nonparametrics and semiparametrics For what problems is Bayesian nonparametrics useful and worth the trouble? David Dunson: "Nonparametric Bayes models involve infinitely many parameters and priors are typically chosen for convenience with hyperparameters set at seemingly reasonable values with no proper objective or subjective justification." "It was noted by several people that one of the appealing applications of frequentist nonparametrics is to semiparametric inference, where the nonparametric component of the model is a nuisance parameter. These people felt that it would be desirable to flesh out the (frequentist) theory of Bayesian semiparametrics." Priors "Elicitation remains a major source of open problems." 'Aad van der Vaart turned objective Bayes on its head and pointed to a lack of theory for "situations where one wants the prior to come through in the posterior" as opposed to "merely providing a Bayesian approach to smoothing."' Bayesian/frequentist relationships "Many respondents expressed a desire to further hammer out Bayesian/frequentist relationships. This was most commonly evinced in the context of high-dimensional models and data, where not only are subjective approaches to specification of priors difficult to implement but priors of convenience can be (highly) misleading." 'Some respondents pined for non-asymptotic theory that might reveal more fully the putative advantages of Bayesian methods; e.g., David Dunson: "Often, the frequentist optimal rate is obtained by procedures that clearly do much worse in finite samples than Bayesian approaches."' Computation and statistics Alan Gelfand: "If MCMC is no longer viable for the problems people want to address, then what is the role of INLA, of variational methods, of ABC approaches?" "Several respondents asked for a more thorough integration of computational science and statistical science, noting that the set of inferences that one can reach in any given situation are jointly a function of the model, the prior, the data and the computational resources, and wishing for more explicit management of the tradeoffs among these quantities. Indeed, Rob Kass raised the possibility of a notion of “inferential solvability,” where some problems are understood to be beyond hope (e.g., model selection in regression where “for modest amounts of data subject to nontrivial noise it is im- possible to get useful confidence intervals about regression coefficients when there are large numbers of variables whose presence or absence in the model is unspecified a priori”) and where there are other problems (“certain functionals for which useful con- fidence intervals exist”) for which there is hope." "Several respondents, while apologizing for a certain vagueness, expressed a feeling that a large amount of data does not necessarily imply a large amount of computation; rather, that somehow the inferential strength present in large data should transfer to the algorithm and make it possible to make do with fewer computational steps to achieve a satisfactory (approximate) inferential solution." Model Selection and Hypothesis Testing George Casella: "We now do model selection but Bayesians don’t seem to worry about the properties of basing inference on the selected model. What if it is wrong? What are the consequences of setting up credible regions for a certain parameter $β_1$ when you have selected the wrong model? Can we have procedures with some sort of guarantee?" Need for more work on decision-theoretic foundations in model selection. David Spiegelhalter: "How best to make checks for prior/data conflict an integral part of Bayesian analysis?" Andrew Gelman: "For model checking, a key open problem is developing graphical tools for understanding and comparing models. Graphics is not just for raw data; rather, complex Bayesian models give opportunity for better and more effective exploratory data analysis."
