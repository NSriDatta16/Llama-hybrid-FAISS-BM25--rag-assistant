[site]: crossvalidated
[post_id]: 637227
[parent_id]: 
[tags]: 
Active learning for simulation parameters

Suppose we are training a neural network (or more generally, your favorite nonparametric model) $f: \mathbb{R}^k \to \mathbb{R}$ to solve a regression problem. For clarity, $k$ is of the order $\sim10$ . Each training data point is then of the form $(x_1,\dots,x_k,y),$ and the loss is $L = \sum_i d(f(\mathbf{x}_i),y_i),$ where $d(y,y')$ is some positive-definite measure of the deviation between $y$ and $y'$ , and the index $i$ refers to samples. The training data are extracted a posteriori from (expensive) simulations via postprocessing, with each simulation providing many thousands of data points. Crucially, for a given set of simulation parameters (for instance, initial conditions), the distribution of data in feature space is very difficult to predict. I want to implement an active learning protocol that selects new sets of simulation parameters in order to explore new regions of feature space, so as to obtain a best estimate of $f$ while minimizing the requisite number of simulations. In other words, I can easily figure out which regions of feature space require more exploration, but the correspondence between simulation parameters and these regions is unclear. We could say that each set of parameters $\theta$ corresponds to an unknown data density in feature space $p(\mathbf{x} | \theta)$ . What tools are available to perform the task of selecting new simulation parameters? Is there a way, say, to cast it as a Bayesian optimization problem?
