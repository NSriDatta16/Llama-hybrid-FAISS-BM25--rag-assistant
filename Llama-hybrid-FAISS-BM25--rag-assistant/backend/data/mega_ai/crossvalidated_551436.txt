[site]: crossvalidated
[post_id]: 551436
[parent_id]: 
[tags]: 
What is the name for this error metric?

I am following a paper that says that a generalized learning method is optimized by minimizing a regularized error metric: $$ H(f_\mathcal{G}) = (1-\lambda)||y_i-f_\mathcal{G}(\mathbf{x_i})||^2 + \lambda J(f_\mathcal{G}), $$ Where the regularization function $J(f_\mathcal{G})$ is a term which penalizes the higher derivatives of $f_\mathcal{G}$ and $\lambda$ is the regularization constant bounded by $0 . I am new to machine learning, so I am trying to understand where this formula comes from. For me, this looks like Tikhonov regularization however it includes a $(1-\lambda)$ term in front of the squared error. In addition, in Tikhonov regularization, $\lambda$ is only bounded by $>0$ (as far as I am aware). Is there a name for this regularization? I can't find it anywhere online. Why does there need to be a $(1-\lambda)$ term in front of the squared error? In addition, the paper doesn't state what the $J(f_\mathcal{G})$ term could be. Is there a standard function for this term?
