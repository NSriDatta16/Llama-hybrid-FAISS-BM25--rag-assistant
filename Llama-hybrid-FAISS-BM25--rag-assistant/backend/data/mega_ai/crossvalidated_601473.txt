[site]: crossvalidated
[post_id]: 601473
[parent_id]: 
[tags]: 
Sensitivity analysis based on a dataset with dependent variables

I am part of a company that produces data from satellite images and machine learning/deep learning. We produce different data and sometimes the results of one step will be used as input for the next step. For example, we use a Google Earth image and a trained model to detect the roofs of houses in a village. From these detected roofs and lidar data (other remote sensing data), we estimate the height of the house (with a second trained model). Then, we compile the data to obtain the volume of the house. Based on the type of house (recent or old, detected from a third trained model), we estimate the energy consumption of this house. Thus, we now have the estimated data of the houses in the whole village. To compare these results, we also have the actual measurements of the roof areas, house heights, total volume, and energy consumption of each house. The problem is that if we have made a wrong prediction of the roof area (first step), this error will be reflected in the volume of the houses, and also in the energy consumption... How could I estimate the sensitivity of the parameters (as in a sensitivity analysis) from these estimated and real data? The idea would be to guide me on which model to improve first to effectively improve the overall accuracy :)
