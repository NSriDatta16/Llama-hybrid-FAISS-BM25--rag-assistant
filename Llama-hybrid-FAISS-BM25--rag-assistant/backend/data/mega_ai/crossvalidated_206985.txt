[site]: crossvalidated
[post_id]: 206985
[parent_id]: 
[tags]: 
How was this intergral derived from Bayes' Rule in David Heckerman's Bayesian Network paper?

I am trying to follow this paper titled "A Tutorial on Learning With Bayesian Networks" by Microsoft researcher David Heckerman. In it I am unable to figure out how he got to Equation 2 from Equation 1. There is an assumption being made that I can't figure out. $$p(\theta|D,\xi) = \frac{p(\theta|\xi ) p(D|\theta,\xi)}{p(D|\xi)} \tag{Equation 1}$$ $$p(D|\xi) = \int p(D|\theta,\xi ) \, p(\theta|\xi) \, \mathrm{d}\theta \tag{Equation 2}$$ In my attempt to try to help myself, I have found myself learning about contour integration and normalized Gaussian distributions. But I still don't see how the author got to equation 2. Or why he would include that in the paper, as it was never mentioned again. References Heckerman, David (1995). " A tutorial on learning with Bayesian networks. " Microsoft Research Technical Report MSR-TR-95-06.
