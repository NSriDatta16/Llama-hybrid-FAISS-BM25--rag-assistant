[site]: crossvalidated
[post_id]: 486341
[parent_id]: 486302
[tags]: 
For your question: Yes, this is the most predictive feature set based on gini criteria and the 50% train data you sampled. However, you are probably looking for accuracy when you mean predictive. That would have to be calculated for an in-sample and out-sample metric (eg. Mean squared error or mean absolute error). Based on that you can decide whether these are predictive. If you change the train sample (i.e. sample 50% with a different seed, it may be possible to get other features). Given there is no limit of depth I guess, the accuracy in sample would be 100% or 0 MSE or something like that i.e. over-fit. Seed plays a critical role in tree based models. Decision Tree being the most basic model, in this case it seems, these are the only features predictive. However it is for the current training set that has been sampled. If the seed is changed for sampling, the predictive features might change. Random forests therefore have better prediction as it will average across several decision trees. In case of random forests, it must be noted that there is functionality for feature sampling with a seed as well. I find this video on decision trees helpful for intuition: https://www.youtube.com/watch?v=wpNl-JwwplA&feature=youtu.be
