[site]: crossvalidated
[post_id]: 563680
[parent_id]: 
[tags]: 
How to calculate the Posterior distribution $P(\theta|x,y)$?

I'm watching ML course from Stanford on Youtube and on the Bayesian Methods Class, the professor writes the following: $\theta$ ~ Prior $y$ ~ $P(y|x,\theta)$ Posterior distribution: $P(\theta|x,y) = \dfrac{P(y|x,\theta)P(\theta)}{P(y|x)}$ He states $\theta$ and $x$ are independent. I really don't understand how he made this derivation. In my calculations, this should be $P(\theta|x,y) = \dfrac{P(\theta,x|y)}{P(x|y)}$ What am I getting wrong? Are the two derivations the same?
