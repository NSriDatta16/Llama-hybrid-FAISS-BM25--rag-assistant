[site]: crossvalidated
[post_id]: 360595
[parent_id]: 
[tags]: 
Optimize likelihood function to get lambda for Box-Cox transform of two variables

I'm trying to implement the Transformed Normal method (TN) that was described in Faraggi, D., & Reiser, B. (2002). Estimation of the area under the ROC curve. Statistics in medicine, 21(20), 3093–3106. The authors transform the measurements of a diseased and a non-diseased sample to normality using a common $\hat{\lambda}$ in the Box-Cox-transformation and then proceed to calculate a cutpoint using normal theory. The $\hat{\lambda}$ is obtained according to Zou, K. H., Tempany, C. M., Fielding, J. R., & Silverman, S. G. (1998). Original smooth receiver operating characteristic curve estimation from continuous data: Statistical methods for analyzing the predictive value of spiral CT of ureteral stones. Academic Radiology, 5(10), 680–687. https://doi.org/10.1016/S1076-6332(98)80562-X Here's the relevant part of the latter paper: So a profile log likelihood function is constructed and optimized to find $\hat{\lambda}$. $x_{0,i}$ and $y_{0,j}$ are the original, unaltered measurements and $x'$ and $y'$ are the Box-Cox-transformed ones, if I understand the paper correctly. I am now trying to implement this likelihood function in R. Apparently, the Box-Cox-transformed variables are inserted into the likelihood function, so my attempt looks like this: boxcox The data of Zou et al. seem to be roughly lognormally distributed and so is the data I have in mind, so the method should be applicable. However, since some of the $x'$ and $y'$ will become negative after the Box-Cox transformation, terms like $log(x')$ in the likelihood function become NaN . If I insert $x_0$ and $y_0$ instead of $x'$ and $y'$ into the likelihood function, it is a monotonically increasing function. Thus, my question is: What are the mistakes in my implementation? Thank you.
