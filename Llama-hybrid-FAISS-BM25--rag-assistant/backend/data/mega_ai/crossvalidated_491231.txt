[site]: crossvalidated
[post_id]: 491231
[parent_id]: 402121
[tags]: 
Expanding on the comments, the misunderstanding originates in the nature of data reduction. For some matrix with rank $r$ , if you only retain the $k largest PCs, then you will not have a perfect reconstruction because the remaining $r-k$ dimensions are discarded. More information: Does PCA's reconstruction error get reduced with more PCs being used? Therefore, the PCA transform and inverse_transform are only exactly inverses in the case that $k \ge r$ ; otherwise, data is irrevocably lost. Intuitively, this makes sense. If we have data that exists in three dimensions (i.e. has rank 3), but we approximate it using only 2 PCs, then we will lose all variation in that third direction.
