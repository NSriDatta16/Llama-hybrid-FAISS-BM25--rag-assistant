[site]: datascience
[post_id]: 20525
[parent_id]: 
[tags]: 
Should I standardize first or generate polynomials first?

Recently I am dealing a classification problem with some algorithms, say logistic regression. When I preprocess my data, I standardize all my features and then generate polynomial features based on them. from sklearn.preprocessing import PolynomialFeatures, StandardScaler and I do # features is my entire features dataset, labels excluded features = poly.fit_transform(features) features = std.fit_transform(features) After finishing training my model, the accuracy is, say about 80%. Then I invert the two line of preprocessing code to features = std.fit_transform(features) features = poly.fit_transform(features) I have read this post but it seems the answers is not strong enough to help me figure it out. Should I standardize my data first or generate polynomials from original features first?
