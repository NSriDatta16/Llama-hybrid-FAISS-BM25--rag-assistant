[site]: crossvalidated
[post_id]: 620661
[parent_id]: 
[tags]: 
Entropy, Information Gain, etc. in Random Forests

I am new to ML, and just learned about the decision tree, and how entropy and information gain are used for a single tree. I am currently learning about random forest now, and some tutorials mention that a forest is formed from a number of trees, and at the end, majority voting is used on the collection of individual classification results by individual trees. I am deeply grateful for your answers to the following: Apart from majority voting, does the Random Forest itself has entropy and information gain (or any other important measures)? I mean apart from entropy and information gain used for each tree in the forest, does the forest itself uses some type of entropy/information gain or any other measures apart from just counting votes? Could you refer a good resources for learning about details of Random forests and their applications?
