[site]: crossvalidated
[post_id]: 483089
[parent_id]: 482137
[tags]: 
By setting $\beta$ to $0$ we are effectively getting "just Precision" that is because the Recall multipliers cancel each other out and we are left with Precision only. By using a lower $\beta$ we do not down-weight Precision in any way, we are up-weighting as we allow it to dominate the fraction's final value through the numerator. If we already know the cost of our FP/FP we can directly use them. $\beta$ itself reflects our trade-off between Recall and Precision in the sense of $\beta=\frac{\text{Recall}}{\text{Precision}}$ ; therefore the values of $0.5$ and $2$ merely reflect that we hypotheises that: "we value Precision twice as much as Recall" (for $\beta=0.5$ ) or "we value Recall twice as much as Precision" (for $\beta=2$ ). Obviously if we value them equally $\beta=1$ and we get our standard $F_1$ score. Sasaki (2007) The truth of the F-measure presents this discussion very nicely in a formal manner where it grounds it firmly on van Rijsbergen's original 1979 work on Information Retrieval .
