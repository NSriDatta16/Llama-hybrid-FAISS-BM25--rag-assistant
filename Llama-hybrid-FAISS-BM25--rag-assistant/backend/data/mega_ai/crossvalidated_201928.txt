[site]: crossvalidated
[post_id]: 201928
[parent_id]: 
[tags]: 
Forward search feature selection and cross-validation

I've a question regarding forward search for feature selection. Basically, I've found here and here that the procedure is the following: As the procedure suggests, the cross-validation is applied repeatedly as the feature set grows and at the end, we select the set with the best cross-validation performance. However, in another question within the forum, it is mentioned that feature selection should be applied separately: Select one fold as the test set On the remaining folds perform feature selection Apply machine learning algorithm to remaining samples using the features selected Test whether the test set is correctly classified Go to 1. Therefore we will end up with several best feature sets (one for each fold). I'm confused about which is the best procedure to follow. And in case it is the second one, how do we find a unique best feature set?
