[site]: crossvalidated
[post_id]: 237886
[parent_id]: 237862
[tags]: 
If $X \sim \mathcal{N}(\mu_X, \sigma_X^2)$ and $Y \sim \mathcal{N}(\mu_Y, \sigma_Y^2)$, and $X$ and $Y$ are independent, then $$ X-Y \sim \mathcal{N}(\mu_X-\mu_Y, \sigma_X^2+\sigma_Y^2) $$ so difference of two normals is also normally distributed . This means that your question simplifies to asking how many real numbers $a,b$ such that $a-b = c$ exist, and how many real numbers $d,e$ such that $d+e=f$ exist? In both cases you have unlimited number of possibilities. So the model you describe is not identifiable (there is no unique solution for it) and it cannot be estimated. Notice: As Glen_b noted in the comments (see comments under this answer), theoretically it may be possible to estimate such model when using informative priors, however I do not see how it could be implemented. Comment to code posted by adamwlev in answer to his question Answers are not meant to comment other answers, but there is too much to be said to use comments for it, so I'm going to refer to the code in my answer. Moreover, while OP considers his solution to answer the question, it seems that commenting it also answers his misconceptions about mentioned model. First, notice that your code doesn't work . To convince yourself, try using realistic example for testing the code that in fact is a difference of two normals and check if your code correctly finds the appropriate parameters. For example, try the following data and check if the parameters are recovered ds ...they will not. But, as Glen_b noticed, Bayesian estimation can work in here by employing prior , out-of-data knowledge into the model to facilitate identifiability. Let's make one more change in your code and assume perfect knowledge about the searched parameters, where your priors are equal to the true parameters, so the model should not have any problems with finding them (as they are known in advance). So, let's change the following lines: p_x It will diverge from the initial correct values assumed in priors . In fact, it doesn't work exactly for the reason outlined in my answer: such model is not identifable. The presented algorithm does not estimate the model described in the question. The model that was described was $$ X_i \sim \mathrm{Normal}(\mu_X, \sigma_X^2) \\ Y_i \sim \mathrm{Normal}(\mu_Y, \sigma_Y^2) \\ D_i = X_i - Y_i \sim \mathrm{Normal}(\mu_X-\mu_Y, \sigma_X^2 + \sigma_Y^2) $$ while the model described in the algorithm is something closer to $$ X_i \sim \mathrm{Normal}(\mu_X, \sigma_X^2) \\ Y_i \sim \mathrm{Normal}(\mu_Y, \sigma_Y^2) \\ D_i \sim \mathrm{Normal}(X_i - Y_i, \sigma_D^2) $$ So $D$ in here is not a random variable that is a difference of two other random variables $X,Y$, but instead you have $n$ random variables $D_i$ where each of them has different mean equal to $X_i-Y_i$, where you have only one observation per each random variable $D_i$. So in fact from single datapoint you want to estimate two parameters, $X_i,Y_i$ -- you have not identifable model and insufficient data for this. Moreover, calling exactly the same likelihood twice p_x1 won't lead you to calculate different parameters...
