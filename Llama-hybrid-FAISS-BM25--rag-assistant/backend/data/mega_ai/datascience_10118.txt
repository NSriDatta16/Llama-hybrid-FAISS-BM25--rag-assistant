[site]: datascience
[post_id]: 10118
[parent_id]: 10114
[tags]: 
There are plenty of ways to realize this. Originally everybodies approach to the Netflix Prize (quite similar to the movielense dataset) were nearest neighbor methods. Their intuition should be fairly clear. Matrix Factorization became the next big thing and was nicely described by Simon Funk in his journal: http://sifter.org/~simon/journal/20061211.html . If you are more interested in these two topics and don't mind a bit of bad english you may consider this thesis: http://patrick-ott.de/dl/diploma_ott.pdf . The crowd then went on to Restricted Boltzmann Machines for the task, e.g. (cs.utoronto.ca/~hinton/absps/netflixICML.pdf) . I think it is beyond this answer to explain these for this particular task -- maybe worth another question, All three approaches though (Nearest Neighbor, Matrix Factorization and RBMs) never we are able to reach to goal set by Netflix, which let to the development of more or less clever methods to combine their predictions, which finally was enough to get to the point Netflix set out. These are all somewhat old approaches to the problem, their might be newer ones. However, the most recent machine learning hype, i.e. Deep Learning has so far not given many possible solutions although dominating in other fieds.
