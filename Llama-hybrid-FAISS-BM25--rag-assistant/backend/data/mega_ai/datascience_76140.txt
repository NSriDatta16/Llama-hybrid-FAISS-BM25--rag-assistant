[site]: datascience
[post_id]: 76140
[parent_id]: 76115
[tags]: 
There is no point in looking at the prediction at this point. Your model has not learnt the data yet. Suggestions - When copy from a source. Try copying everything first. Run it and then start tweaking for learning Or to map with your own need. You have changed a few things as compared to what Jason has in his post Use the wisdom of researchers . So, you can keep a few things as default - 1. Optimizer - Adam 2. Activation - Relu for Hidden layer 3. Loss - MSE(Regression), Cross-entropy(Classification). Beware of Cros-entropy variance. 4. Activation for Output layer - Linear(Regression), Sigmoid/Softmax(Classification) 3. Have Batch normalization layer when you have a deep network. Try to know why behind every point that I have mentioned. It's will be an easy search on the Internet. A good place to start can be - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, by Aurélien Géron Further reading - Practical Recommendations for Gradient-Based Training of Deep Architectures, by Yoshua Bengio Andrej Karpathy blog Raúl Gómez blog
