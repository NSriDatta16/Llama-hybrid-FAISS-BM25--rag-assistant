[site]: crossvalidated
[post_id]: 74309
[parent_id]: 71615
[tags]: 
SVM doesn't assume normality. But it's still a regression that minimizes some symmetric loss function (I suppose you use symmetric kernel). So... this is just a feeling and I'm too tired to justify/prove all this but: Probably your output variable has highly skewed distribution; And you use symmetric gaussian kernel that leads to symmetric squared loss to minimize (squared error with bump cut-off if I remember correct?); Then SVM still estimates something close to conditional mean of your data if you minimize this loss for original output variable; When you log-transform output variable and minimize that symmetric loss for it, then in terms of original variable it estimates something like a conditional median; it's well-known that mean is the thing that minimizes average squared error and median is the thing that minimizes average absolute error, so when you estimate regression using log-transformed output you get worse MSE but better MAPE. Hope this helps.
