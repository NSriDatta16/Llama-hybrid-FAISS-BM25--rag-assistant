[site]: datascience
[post_id]: 73981
[parent_id]: 73978
[tags]: 
Your problem isn't just a low recall value, your problem is your model needs improving. A high accuracy with a highly unbalanced dataset means practically nothing since simply predicting the most common label will get you a very high accuracy. With imbalanced classes, itâ€™s easy to get a high accuracy without actually making useful predictions. So, accuracy as an evaluation metrics makes sense only if the class labels are uniformly distributed. (or at least close to uniform) For example, imagine you have a cancer detecting model. And your dataset is 990,000 images with no sign of a tumor and 10,000 images of tumors. A simple useless model that predicts "NO TUMOR" for every single image will get an incredibly high accuracy of 99%! But a recall of 0%. Relative to your problem. Imagine if the cancer detecting model was really bad at detecting tumors, but was capable of noticing obvious signs of tumors in images, then it's still a useless model but it will manage to get an accuracy of 99% and a low recall value of 5% for example (because it's only able to detect the obvious signs of tumors). The problem here isn't specifically that we just have a low recall value. The true major problem is that we have a bad model. For more information on evaluation metrics of unbalanced datasets: http://www.davidsbatista.net/blog/2018/08/19/NLP_Metrics/ For information on how to combat imbalanced datasets: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/
