[site]: crossvalidated
[post_id]: 469288
[parent_id]: 
[tags]: 
Categorical features in a random forest

I am currently training a random forest. After transforming a categorical feature into dichotomous columns, should I drop the first level? For example, I have three unique values in a featured named sex : m for male f for female na for not available Thus, I encoded sex into three columns: sex sex_m sex_f sex_na m 1 0 0 f 0 1 0 na 0 0 1 I dropped sex (obviously), but should I also drop one of the three encoded columns? Dropping the base level is necessary when running a regression to avoid multicollinearity, but this is not a problem when running a random forest. So what is the most common approach? For reference, each tree is being trained with a randomly selected set of 8 out of 63 features.
