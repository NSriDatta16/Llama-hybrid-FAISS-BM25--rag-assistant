[site]: crossvalidated
[post_id]: 275518
[parent_id]: 179101
[tags]: 
I'd like to explain that simple diagram in a relatively complicated context: attention mechanism in the decoder of the seq2seq model. In the flow diagram below, $h_0$ to $h_{k-1}$ are time steps(of the same length as the input number with PADs for blanks). Each time the word is put into the ith (time step) LSTM neural(or kernel cell the same as any one of the three in your image) it calculates the ith output according to its previous state((i-1)th output) and the ith input $x_i$ . I illustrate your issue using this is because all the states of the timestep are saved for the attention mechanism rather than just discarded only to get the last one. It is just one neural and is viewed as a layer(multiple layers can be stacked to form for example a bidirectional encoder in some seq2seq models to extract more abstract information in the higher layers). It then encodes the sentence(with the L words and each one represented as a vector of the shape: embedding_dimention * 1) into a list of L tensors(each of the shape: num_hidden/ num_units * 1). And the state past to the decoder is just the last vector as the sentence embedding of the same shape of each item in the list. Picture source: Attention Mechanism
