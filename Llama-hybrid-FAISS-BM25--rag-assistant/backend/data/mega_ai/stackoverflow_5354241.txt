[site]: stackoverflow
[post_id]: 5354241
[parent_id]: 5353108
[tags]: 
This is the solution that we opted to use in legacy system where we could not fix the root cause of these deadlocks as it would mean rewriting a lot of existing and poorly documented code. The system was using DataSets and ADO.NET classes, so if you intent to use NHibernate I fear you would have to research its internals and/or develop your own extension or for if existing functionality is not available for that. 1) If the code is prone to deadlocks they should start appearing at sufficient database load. You need many simultaneous connections working with the same tables using the problematic procedures. It is difficult to reproduce deadlocks in the exact places you want, but if you want general deadlocks for your retry procedure testing do simultaneous reads/inserts into same tables from 10+ threads with differing access order (e.g. table A then B in some of them, table B and then A in others) with small delays and you get one soon. 2) You need to retry the entire code fragment that works with the transaction and retry data initialization too. Meaning, if you are filling datasets within transaction you have to clear them at the beginning of retryable code block. 3) It is .Numer=1205 of SqlException. In general, you can also retry on timeout and network errors: switch (sqlEx.Number) { case 1205: { DebugLog("DEADLOCK!"); canRetry = true; break; } case -2: case -2147217871: { DebugLog("TIMEOUT!"); canRetry = true; break; } case 11: { DebugLog("NETWORK ERROR!"); canRetry = true; break; } default: { DebugLog(string.Format("SQL ERROR: {0}", sqlEx.Number)); break; } } In my experience when retrying on deadlock it is best to discard the connection from the pool with SqlConnection.ClearPool(connection) because it might not be reset properly for the next time.
