[site]: crossvalidated
[post_id]: 270927
[parent_id]: 270911
[tags]: 
It sounds like your data only has missing values at prediction time, not at training time. This rules out some methods for automatically handling missing values(such as xgboost's missing value support). The standard approach is definitely imputation of the missing values. There are a number of libraries for this, see here for a summary of a few. Essentially you train your classifier as normal, and separately you train the imputation model. At prediction time you apply the imputation model first to go from an instance with missing values to a fully specified instance. You then apply the classifier to that instance. In terms of recommendations for machine learning methods, I would suggest first trying multiclass logistic regression (say with glmnet) then once you get that working try a boosted decision tree library such as xgboost . You could perhaps use xgboost's missing value support if you artificially introduced some missing values into your training data at random as well. This is one of those problems where there is many ways to approach it.
