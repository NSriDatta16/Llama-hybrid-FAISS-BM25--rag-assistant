[site]: stackoverflow
[post_id]: 5189421
[parent_id]: 5124993
[tags]: 
I am not aware of any WebGL framework that resolves your problem specifically. I think you could potentially create a grid with your depth data, starting from a rectangular uniform grid and moving each vertex to the back or to the front (Z-axis) depending on the depth value. Once you have this, then you need to generate the texture array and from the image you posted on flickr I would infer that there is a mapping one-to-one between the depth image and the texture. So generating the texture array should be straightforward. You just map the correspondent coordinate (s,t) on the texture to the respective vertex. So for every vertex you have two coordinates in the texture array. Then you bind it. Finally you need to make sure that you are using the texture to color your image. This is a two step process: First step: pass the texture coordinates as an " attribute vec2 " to the vertex shader and save it to a varying vec2. Second step: In the fragment shader, read the varying vec2 that you created on step one and use it to generate the gl_FragColor . I hope it helps.
