[site]: crossvalidated
[post_id]: 301689
[parent_id]: 260754
[tags]: 
At the end of the day, the model class that you choose defines the shape of your decision boundary -- if you use RandomForests as a multiclass or as a one-vs-all multiclass classifier the boundaries will be equally constrained, with the only difference being the data you use to fit your models. Depending on how well your models fit your data, and how susceptible your model is to data imbalance issues, I don't really see an a priori reason that multiclass should be better than one-vs-all. They just give you different things -- one gives you a decision for every pair of classes, at the cost of more models to train, and one gives you the class decision right away. It is entirely plausible to me, especially considering that RandomForests don't solve a convex loss function, that you would get the results you did. If you're specifically interested in finding which features are relevant for your classifier, I'd suggest a logistic regression with an L1 loss penalty, since the sparsity would give you a small subset of features which are predictive for each pair of classes that you have.
