[site]: crossvalidated
[post_id]: 175497
[parent_id]: 175376
[tags]: 
Uncertainty is a rather broad term, so for this I am going to address the specific case of measurement error. My response comes from Greene's "Economotric Analysis" 7th edition text book. The older 5th edition is available for free http://stat.smmu.edu.cn/DOWNLOAD/ebook/econometric.pdf and you can look there for a more detailed discussion of measurment error. It is true that in linear regression there exist a residual error term, $\varepsilon$, who's nature is assumed to be random, "uncertain" and independent of the regressor(s) $x_1,x_2,...,x_k$. Residual error can arise for several reasons, primarily because we cannot hope to perfectly capture every influence on the dependent variable ,$y$, no matter how elaborate a model. Classical linear regression assumes that the error term is composed exclusively of these uncorrelated omitted influences, nothing more and nothing less. These influences are more akin to omitted variables and do not include measurement error. It is the unfortunate case that in practice, measurement error will influence residuals. This can adversely bias the results of the regression to varying degrees depending on the type of measurement error. Certainly, to assume as you have in your comments the the residual term contains measurement error in $X$ and $y$ and that such measurement error is correlated with $X$, completely and utterly invalidates any resulting classical regression. It is a much more severe problem than that of heteroskedasticity (which at most underestimates your standard errors and creates some inefficiency), rather it is a violation of conditional mean independence (also called exogeneity), which results in biased estimates of all the $\beta$ coefficients (potentially very large and misleading biases). In other words,such measurement error results in correlation between $\varepsilon$ and $X$ which classical linear regression assumes does not exist. Again, the degree to which measurement error adversely effects the regression depends on the type of measurement error and can range from benign to extremely severe. Covering the cases in detail would take way to long for this answer. In general, measurement error in $y$ is less concerning than measurement error in $X$, and random measurement error in $X$ (as apposed to measurement error that is correlated with $X$ or $y$) will always bias the $\beta$ toward zero (also called an attenuation bias) making it less concerning in some contexts. Update For an example, suppose you have a data set consisting of 1 million people and you are trying to find the effect of education and demographic variables (degree awarded, years in school, age, ethnicity, parents income and so forth) on annual income using OLS regression. So $y$ is income and $X$ consists of the education and demographic variables. There exists an error term $\varepsilon$ which theoretically consist exclusively of uncorrelated and omitted influences on income. For example, suppose person 123 and 203 had the same $X$ but person 123 earned 1.2 times that of person 203, the difference in earnings could be explained by a variety of potential reasons: person 123 just randomly knew someone who could get them a better job. person 203's mom got ill and he/she had to take time off to care of her leading to a delay in his/her career growth. person 123 had a passion for finance because some teacher he/she had in college so he/she pursued a career path with higher than average earning potential while person 203 did not. This list can go on and on, we can't model everything and this is what creates $\varepsilon$. Notice, however, none of the above are measurement error. For measurement error, an example may be people rounding there annual income or not remembering it exactly when filling out the survey. This is probably random and additive measurement error, so it will not really bias the regression that much. A more severe example of measurement error would be if wealthier individuals consistently under-reported their income while poorer individuals did not, this will lead to a biased regression. An example of an attenuation bias would be if individuals misreported the income of there parents (an $X$ variable) in a random manner. If parent's income effects child's income in any way, the resulting regression would bias such an effect toward zero. Another example would be if those with wealthier parents consistently under-reported their parent's income while others did not. Assuming parents income positively effects child's income, this would likely bias the effect of parent's income upwards.
