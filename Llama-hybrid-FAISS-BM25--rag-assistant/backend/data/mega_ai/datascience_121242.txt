[site]: datascience
[post_id]: 121242
[parent_id]: 121226
[tags]: 
The purpose of a machine learning model is to make predictions on real-world data that isn’t known at model training time. As such, it’s best practice to always do a train-test split at the very beginning of any project, and only use the training data for training the model. The test data should not be used at all until your model is fully trained. To add to this, when tuning the model’s hyperparameters there is an additional subset of the training data used for validation, which is not used for training but for evaluating performance during training. You create train-test-splits of your input data, run through all of your models, and use your aggregate cross-validation score to choose one or two models to concentrate on improving. Based on your results, it looks like logistic regression is getting the highest score, and is probably a good fit for this type of problem – predicting whether an instance of the data is a member of the target or not (“stroke” or “not stroke”). Once this is done, you can tune your model’s hyperparameters (using GridSearch like you’re doing for example) to determine the best parameters for things like regularization (the “C” parameter). Then, and only then, when you have selected your model, tuned the hyperparameters, and trained on your training data only, then you evaluate performance on your test data. For the evaluation, it’s good to understand the performance of your model and what that represents, that’s what your metrics at the end are for. Precision is percentage of true positives over true positives and false positives, and recall is true positives over true positives plus false negatives. F1 score is the harmonic mean of these two values, ROC is the performance of the model at different classification thresholds. If the purpose of the model is to predict strokes, do you want a higher precision which would mean you detect more potential strokes at the risk of higher false positives? Or a higher recall which would mean all the instances classified as high risk of stroke are more likely to be high risk of stroke but at the cost of potentially missing some? Hth,
