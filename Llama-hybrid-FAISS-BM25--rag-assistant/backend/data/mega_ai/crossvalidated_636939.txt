[site]: crossvalidated
[post_id]: 636939
[parent_id]: 
[tags]: 
Meta learning network to predict weights update

I am working on a meta learning neural network that should predict the weight update of another neural network. Here is the way I see it. Let us define the input at training step $t$ as $x_t$ and the ground truth as training step $t$ as $y_t$ . We are looking for $\omega^*$ the optimal parameters of a function $g$ : $$ \hat{y_t} = g(x_t; \omega_t) $$ With whatever loss function, for instance: $L_t = (\hat{y_t} - y_t)^2$ and $L = \frac{1}{N} \sum_t^N L_t$ with $N$ the number of training steps. We then have a second network $f$ defined as follows: $$ \Delta \omega_t = f(\omega_{t - 1}, x_t, y_t ; \theta) $$ which is the meta learner. We want: $$ \omega_t = \omega_{t - 1} + \Delta \omega_t = \omega_{t - 1} + f(\omega_{t - 1}, x_t, y_t ; \theta) $$ I would like the loss function of the meta learner to be proportional to something like: $$ L_t - L_{t - 1} $$ so the optimization would be as fast as possible. I thought about copying the gradient of the loss function at time $t$ with respect to the weights to the output of the meta learner $\frac{\partial L_t}{\partial \omega_t}$ but it does not work because I do not predict the weights directly but the update of the weights. I think it is some kind of learning rate prediction but I cannot find a loss function that works well. Can you help please? Thank!
