[site]: crossvalidated
[post_id]: 57836
[parent_id]: 
[tags]: 
Evaluating features and similarity measures

I am currently developing a classifier, which is supposed to classify into a number of classes. For this purpose I am designing some features and similarity measures which I might use for a later kernel for a support vector machine (SVM). Now I was thinking to myself, how I can roughly evaluate my features and the similarity measures without having to develop the whole classifier first. Here are my ideas, and I'd be very pleased if you could tell me, if they are valid or not (and maybe also give papers where it was done similarly..?) To roughly evaluate the features, I could make a Naive Bayes assumption and try to use one feature at a time with a Naive Bayesian (NB) classifier and see how it performs. To evaluate the similarity measures (and at the same time features) I could calculate the inter-class mean similarity and intra-class mean similarity and see how far it differs. I was thinking, that I could maybe use an ANOVA test to see, if the difference is significant. However, can I just assume that the results are normally distributed and have the same variance? And ANOVA would simply tell me, that one mean is significantly different but it doesn't tell me which one. Maybe another statistical test is more suitable?
