[site]: crossvalidated
[post_id]: 190479
[parent_id]: 190305
[tags]: 
It is common to scale data when doing PCA. Usually, you use the eigenvalues to scale each component by $1/\sqrt{\lambda_i}$. Any rescaling of the data does have a massive effect on the results. PCA can serve as a heuristic if you have many (preferrably continuous - the use of PCA on binary attributes is somewhat questionable) attributes of different scale, and you expect strong correlations to be present in the data do not have information on how to properly rescale and weight the individual attributes In the rare scenario where all attributes have the same importance and scale , PCA becomes much more well-founded. As a rule of thumb: if a variance of $x$ in every attribute has the exact same importance (say because the attributes are coordinates in your measurement chamber) then the use of PCA is strongly backed by theory. If attribute 1 is the shoe size, and attribute 2 is income, then PCA will be ruined by the differences in scale, and the outliers in income.
