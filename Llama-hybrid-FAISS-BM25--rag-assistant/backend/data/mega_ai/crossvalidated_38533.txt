[site]: crossvalidated
[post_id]: 38533
[parent_id]: 38420
[tags]: 
There is an irony that the standard way to do Bayesian computation is to use frequentist analysis of MCMC samples. In this example we might consider $c$ to be closely related to the marginal likelihood, which we would like to calculate, but we are going to be Bayesian purists in the sense of to try to also do the computation in a Bayesian way. It is not common, but it is possible to do this integral in a Bayesian framework. This involves putting a prior on the function $g()$ (in practice a Gaussian process) evaluating the function at some points, conditioning upon these points and computing an integral over the posterior over $g()$. In this situation the likelihood involves evaluating $g()$ at a number of points, but $g()$ is otherwise unknown, therefore the likelihood is quite different to the likelihood given above. The method is demonstrated in this paper http://mlg.eng.cam.ac.uk/zoubin/papers/RasGha03.pdf I don't think anything went wrong with Bayesian methodology. The likelihood as written treats $g()$ as known everywhere. If this were the case then there would be no statistical aspect to the problem. If $g()$ is assumed to be unknown except at a finite number of points Bayesian methodology works fine.
