[site]: datascience
[post_id]: 117120
[parent_id]: 117108
[tags]: 
Predicting 30 days for 10000 without GPU nor CPU is difficult, but you can try different approaches to get the most out of the data and make consistent predictions: Start with a correlation map to find out similar shops. If you find groups of shops with similar behavior, you may just have to train a model for each group. In addition to that, you could visualize 10000 shops using dimensional reduction algorithms like UMAP and detect relevant clusters. This is also interesting to extract features and dependencies of other important variables that could help you improve predictions. I recommend to start with 1000 shops to have the right parameters and prepare the data correctly . Once you have clear clusters, you can apply ARIMA to some of them as they probably have seasonality (= where ARIMA performs the best). For the shops out of clusters, you may apply to them another algorithm for noisy data. Potentially Exponential Smoothing or Random Forest . In conclusion, starting from a general approach to group shops with similar data, extracting knowledge from them, and applying a prediction model for each group could be a good solution in case of low computing power.
