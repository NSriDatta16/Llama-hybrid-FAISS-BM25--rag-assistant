[site]: datascience
[post_id]: 75958
[parent_id]: 75954
[tags]: 
Yes. Image captioning is a very active area of Deep Learning, at the intersection between Computer Vision and Natural Language Processing. These models are based on an Encoder-Decoder structure. In its most classical form, the Encoder consists of Convolutional layers that process pixel data. Their representation is then fed to a Decoder based on Recurrent layers (usually LSTM or GRU) that generate the output sentence. I suggest you to take a look at this tutorial on Image Captioning in TensorFlow 2 . You can download the Notebook and run. That specific model is based on attention mechanism, which is a fancier version of seq2seq models. You can find tons of other models and tutorial simply googling them.
