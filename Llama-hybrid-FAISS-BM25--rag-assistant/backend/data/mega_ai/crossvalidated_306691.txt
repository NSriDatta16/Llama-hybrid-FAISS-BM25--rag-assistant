[site]: crossvalidated
[post_id]: 306691
[parent_id]: 306687
[tags]: 
1. Yes, it could be a HMM. First try to understand the *non-hidden* Markov chain part. Assume that you can observe the balls in the container, and there are $N_b$, $N_y$ and $N_r$ blue, yellow, and red balls respectively. Also, call $N$ the total number of balls. Let's call the Markov chain $X_t$. It takes values on the state space $\mathbb{Z}^3$. It's a three dimensional vector, and the elements will correspond to the number of blue, yellow and red balls. A time $1$, because you haven't removed anything yet, $X_1 = (N_b,N_y, N_r)'$ with probability $1$. So the probability distribution can be encoded by a vector where all entires are $0$ except for the one that corresponds to this state. And in that case, the entry will be $1$. At time $2$, you've just removed a ball, and you assume that you were picking balls all with uniform probability. There are three things that could've happened. Whatever color ball you picked, you reduce the number of that color by $1$. So the transition matrix will have zeros everywhere, except for the entries that correspond to the elements $(N_b-1,N_y, N_r)'$, $(N_b,N_y-1, N_r)'$, $(N_b,N_y, N_r-1)'$. They will have probabilities $N_b/N$, $N_y/N$ and $N_r/N$, respectively. And then you keep going. 2. Yes, your parameter estimates of this model will include $N_b$, $N_y$ and $N_r$. 3. How you write these probability vectors and transition matrices will depend on how you list out all the possible states of the Markov chain. If $N_b$, $N_y$ and $N_r$ are large, it could be messy.
