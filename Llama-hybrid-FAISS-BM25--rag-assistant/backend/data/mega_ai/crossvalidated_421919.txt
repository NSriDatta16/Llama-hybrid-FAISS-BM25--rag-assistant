[site]: crossvalidated
[post_id]: 421919
[parent_id]: 
[tags]: 
How to implement 1D Convolutional Autoencoder with multiple channels?

I want to build a 1D convolution autoencoder with 4 channels in Keras. Instead of images with RGB channels, I am working with triaxial sensor data + magnitude which calls for 4 channels. I haven't seen much information on this and I am not fully sure how to incorporate the channel information for constructing the network. Each example is 100 data points, and 4 channels (x, y, z, mag) so the input is of shape (100,4). Since it's not image data but rather each axis is 1D sensor data, I want to just use 1D convolutions. I am not super concerned with the autoencoder architecture (what I have below is just an example I implemented quickly), but I do want to understand how to implement a 1D convolution autoencoder using multiple channels. This is what I have so far, but I am not sure it is incorporating the channels correctly so I'd love feedback on this! While the final output from the decoder is of shape (100,4), is that the correct way to reconstruct the original input? # Encoder encoder = Conv1D(50, 12, activation = 'relu', padding = 'same')(input_layer) encoder = MaxPooling1D(4, padding = 'same')(encoder) # Decoder decoder = Conv1D(50, 12, activation = 'relu', padding = 'same')(encoder) decoder = UpSampling1D(4)(decoder) decoder = Conv1D(4, 12, activation = 'relu', padding = 'same')(decoder)
