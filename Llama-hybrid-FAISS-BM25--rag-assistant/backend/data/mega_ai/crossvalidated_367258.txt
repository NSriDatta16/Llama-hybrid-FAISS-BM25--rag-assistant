[site]: crossvalidated
[post_id]: 367258
[parent_id]: 367231
[tags]: 
Like one commenter said, it pays to perform regression. There, it is clear that the assumptions relate to errors, and you verify them using residuals. The models are the same so the same assumptions apply. With an independent samples t-test, this is equivalent to verifying the assumptions by group, or better yet, demeaning the outcome variable using the group means (outcome variable - group mean) then testing all the demeaned data as a whole. By testing, I mean graphical evaluation, same as Peter Flom. The larger your sample size, the less normality of the demeaned data is relevant for the hypothesis test of the mean difference that normality may affect (CLT). Also, the larger your sample size, the less a single outlying data point can influence your findings, unless you have a cluster or more of outlying data points. As for homogeneity of variance, don't test it. With the t-test, you already have Welch's adjustment, so just do Welch by default. Unless you have serious sample size imbalance by group coupled with extreme non-normality at small sample size, then you'll be fine using Welch's adjustment. Don't test because we know the tests have their flaws. Additionally, if you choose whether to do t or Welch based on testing homogeneity of variance, the end result on average has problems. Zimmerman's A note on preliminary tests of equality of variances is a good reference on this ( https://onlinelibrary.wiley.com/doi/abs/10.1348/000711004849222 ).
