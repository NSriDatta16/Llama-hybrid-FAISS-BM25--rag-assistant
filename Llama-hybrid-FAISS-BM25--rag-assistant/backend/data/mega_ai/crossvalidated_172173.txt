[site]: crossvalidated
[post_id]: 172173
[parent_id]: 172171
[tags]: 
Do you have a predefined start state ? It is fairly easy to see that in matrix 2, state 3 has no incoming edges. And thus over time, the probability of being in state 3 converges to 0. And if the starting state is not 3, then it is exactly 0. I think it will be interesting to report the stationary distribution of matrix 1. One way of comparing Markov proccesses Usually when dealing with Markov chains, you have a transition matrix $T$ and a reward/cost for being in each state $\vec{r}$ If the stationary distribution $\vec{\pi}$ exists for the two Markov processes, then you have two expected rewards: $$E_1=\vec{r}\vec{\pi_1}$$ $$E_2=\vec{r}\vec{\pi_2}$$ And you can compare which process is more rewarding / less costly Loosely speaking, A stationary distribution is the probability of being in each state when repeating the transitions for infinity.
