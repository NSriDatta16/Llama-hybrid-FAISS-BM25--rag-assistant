[site]: crossvalidated
[post_id]: 360433
[parent_id]: 360293
[tags]: 
Generally, overfitted model works well with the training data but does not reflect well with the test data, which in turn leads to high RMSE value. What I would suggest is that, run the same model for multiple sets of samples (80% of the data for training purpose and 20% of the data for training purpose), calculate the RMSE value with its corresponding test data. If the average of all RMSE scores are closer to one, then the model is just right. If the average of all RMSE scores are on the higher side, then the model is overfitted! For example We have 10000 rows of data points with 5 features (4 independent and 1 dependent variable) Choose 80% of 10000 as training data, which is 8000 data points at random and build the model Use this model to predict test data, remaining 20% of 10000, which is 2000 Calculate RMSE for the current test set Repeat step 2 to 4 multiple times, say 100 times, and calculate the RMSE values for all the 100 samples If the average RMSE value of these 100 samples are closer to zero then your model is a good fit, if this value is much bigger, then the model is not a good fit and the model should be revisited Hope I have answered your question!
