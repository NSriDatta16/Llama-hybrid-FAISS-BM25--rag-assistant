[site]: crossvalidated
[post_id]: 572267
[parent_id]: 478871
[tags]: 
As others have noticed, using Ridge regression with only a single feature is overkill. Ridge regression is used when you have many features, so you want to penalize them to avoid overfitting. From your comments, it seems like your idea is to use Ridge regression as a form of prior There's lot of research showing that experimental intervention effect sizes in the scientific literature tend to be exaggerated. So why not try and regularize the estimated treatment effect towards zero? As you can learn from the Is Bayesian Ridge Regression another name of Bayesian Linear Regression? thread, Ridge regression is a MAP estimate of a Bayesian linear regression with a Gaussian prior for the parameters. Why not just use a Bayesian model? Ridge regression is a poor man's implementation of such a model, going full Bayesian enables you to be more flexible with model definition and would enable you to define the priors more explicitly. Ridge regression would also somewhat work like this, but it is the wrong tool for the job.
