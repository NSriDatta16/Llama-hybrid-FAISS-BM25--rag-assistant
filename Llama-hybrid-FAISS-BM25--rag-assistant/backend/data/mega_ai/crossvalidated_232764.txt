[site]: crossvalidated
[post_id]: 232764
[parent_id]: 180548
[tags]: 
In CBOW the vectors from the context words are averaged before predicting the center word. In skip-gram there is no averaging of embedding vectors. It seems like the model can learn better representations for the rare words when their vectors are not averaged with the other context words in the process of making the predictions.
