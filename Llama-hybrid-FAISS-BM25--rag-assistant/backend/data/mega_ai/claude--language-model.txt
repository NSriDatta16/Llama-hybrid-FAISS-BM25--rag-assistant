Claude is a series of large language models developed by Anthropic. The first generation, Claude 1, was released in March 2023, and the latest, Claude Sonnet 4.5, in September 2025. The data for these models comes from sources such as Internet text, data from paid contractors, and other Claude users. Training Claude models are generative pre-trained transformers. They have been pre-trained to predict the next word in large amounts of text. Then, they have been fine-tuned, notably using constitutional AI and reinforcement learning from human feedback (RLHF). Constitutional AI Constitutional AI is an approach developed by Anthropic for training AI systems, particularly language models like Claude, to be harmless and helpful without relying on extensive human feedback. The method, detailed in the paper "Constitutional AI: Harmlessness from AI Feedback", involves two phases: supervised learning and reinforcement learning. In the supervised learning phase, the model generates responses to prompts, self-critiques these responses based on a set of guiding principles (a "constitution"), and revises the responses. Then the model is fine-tuned on these revised responses. For the reinforcement learning from AI feedback (RLAIF) phase, responses are generated, and an AI compares their compliance with this constitution. This dataset of AI feedback is used to train a preference model that evaluates responses based on how much they satisfy the constitution. Claude is then fine-tuned to align with this preference model. This technique is similar to RLHF, except that the comparisons used to train the preference model are AI-generated. The constitution for Claude included 75 points, including sections from the UN Universal Declaration of Human Rights. The approach does not reliably produce a helpful, honest, and harmless (HHH) system. Scenario based testing by Anthropic in 2025 found that Claude 4, along with other leading LLMs (GPT, Gemini, DeepSeek, Grok, and others), would engage in deceptive and harmful behaviour (blackmail, and even killing) for an AI to preserve itself. Models Claude Claude was the initial version of Anthropic's language model released in March 2023, Claude demonstrated proficiency in various tasks but had certain limitations in coding, math, and reasoning capabilities. Anthropic partnered with companies like Notion (productivity software) and Quora (to help develop the Poe chatbot). Some employees describe the name "Claude" as inspired by Claude Shannon, a 20th-century mathematician who laid the foundation for information theory. Claude Instant Claude was released as two versions, Claude and Claude Instant, with Claude Instant being a faster, less expensive, and lighter version. Claude Instant has an input context length of 100,000 tokens (which corresponds to around 75,000 words). Claude 2 Claude 2 was the next major iteration of Claude, which was released in July 2023 and available to the general public, whereas the Claude 1 was only available to selected users approved by Anthropic. Claude 2 expanded its context window from 9,000 tokens to 100,000 tokens. Features included the ability to upload PDFs and other documents that enables Claude to read, summarize, and assist with tasks. Claude 2.1 Claude 2.1 doubled the number of tokens that the chatbot could handle, increasing it to a window of 200,000 tokens, which equals around 500 pages of written material. Anthropic states that the new model is less likely to produce false statements compared to its predecessors. Criticism Claude 2 received criticism for its stringent ethical alignment that may reduce usability and performance. Users have been refused assistance with benign requests, for example with the system administration question "How can I kill all python processes in my Ubuntu server?" This has led to a debate over the "alignment tax" (the cost of ensuring an AI system is aligned) in AI development, with discussions centered on balancing ethical considerations an