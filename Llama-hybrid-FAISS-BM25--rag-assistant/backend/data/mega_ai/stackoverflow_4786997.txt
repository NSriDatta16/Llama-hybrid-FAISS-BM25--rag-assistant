[site]: stackoverflow
[post_id]: 4786997
[parent_id]: 4786967
[tags]: 
As long as you perform all operation in one method call to the concurrent hash map, you don't need to use additional locking. Unfortunately if you need to perform a number of methods atomically, you have to use locking, in which case using concurrent hash map doesn't help and you may as well use a plain HashMap. @James' suggestion got me thinking as to whether tuning un-need concurrency makes a ConcurrentHashMap faster. It should reduce memory, but you would need to have thousands of these to make much difference. So I wrote this test and it doesn't appear obvious that you would always need to tune the concurrency level. warmup: Average access time 36 ns. warmup2: Average access time 28 ns. 1 concurrency: Average access time 25 ns. 2 concurrency: Average access time 25 ns. 4 concurrency: Average access time 25 ns. 8 concurrency: Average access time 25 ns. 16 concurrency: Average access time 24 ns. 32 concurrency: Average access time 25 ns. 64 concurrency: Average access time 26 ns. 128 concurrency: Average access time 26 ns. 256 concurrency: Average access time 26 ns. 512 concurrency: Average access time 27 ns. 1024 concurrency: Average access time 28 ns. Code public static void main(String[] args) { test("warmup", new ConcurrentHashMap()); test("warmup2", new ConcurrentHashMap()); for(int i=1;i As @bestss points out, a larger concurrency level can be slower as it has poorer caching characteristics. EDIT: Further to @betsss concern about whether loops get optimised if there is no method calls. Here is three loops, all the same but iterate a different number of times. They print 10M: Time per loop 661 ps. 100K: Time per loop 26490 ps. 1M: Time per loop 19718 ps. 10M: Time per loop 4 ps. 100K: Time per loop 17 ps. 1M: Time per loop 0 ps. . { int loops = 10*1000 * 1000; long product = 1; long start = System.nanoTime(); for(int i=0;i
