[site]: crossvalidated
[post_id]: 397160
[parent_id]: 397153
[tags]: 
This question is identical to yours, except for the additional inquiry about Bayesian implementation. The answer provides a link to some course notes on the topic. As a brief summary, logistic regression assumes a binary response variable , and is typically modeled as $$P(Y_i = 1) = g(x_i'\beta)$$ where $g(\cdot): \mathbb R \rightarrow (0,1)$ is called a link function . Strictly speaking, logistic regression always uses a logistic link function $g(t) = 1/(1+\exp(-x))$ , but other link functions are available. Ordinal regression is used when for ordinal response variables , i.e. when $Y_i$ takes values in the set $\{1, 2, \cdots J\}$ where the order of the categories is meaningful. Ordinal regression models this as, $$P(Y_i \leq j) = g(\theta_j + x_i'\beta)$$ with the assumption $$-\infty \equiv \theta_0 Ordinal logistic regression again uses a logistic link function, inducing a "proportional log odds assumption". Peter McCullagh's original paper on this topic is pretty readable. To apply these methods in a Bayesian setting, we need to specify priors on the parameters $\beta_1, \cdots \beta_p$ and $\theta_1, \cdots \theta_{J-1}$ . A quick google search will turn up helpful results, such as STAN and BUGS resources for fitting these models. This paper uses WinBUGS to fit a Bayesian Ordinal Regression model on an Oral Health study. They assign vague normal priors on each regression coefficient $$\beta_k \stackrel{iid}{\sim} N(0, 10^6), \ k=1, \cdots p$$ and truncated vague normal priors on the latent "threshold" parameters. $$\theta_j \sim N(0, 10^6)I(\theta_{j-1}, \theta_{j+1}), \ j=1, \cdots J-1$$ where $I(a,b)$ is a truncation function on the interval $(a, b)$ .
