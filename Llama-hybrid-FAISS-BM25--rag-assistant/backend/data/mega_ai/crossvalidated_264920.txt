[site]: crossvalidated
[post_id]: 264920
[parent_id]: 
[tags]: 
Effects of standardizing variables before regularized logistic regression on results?

I am doing regularized logistic regression (elastic net) on a set of variables that have different ranges (i.e. one ranges from 0~1, another ranges from 2~6, another ranges in the hundreds, and some involves negative numbers as well). I understand that in a case like this where each variable has very different range of values, you should standardize the variables before the regression. Thus I have done so using Rescaling, where rescaled x = ( x - min(x))/( max(x)-min(x)). Before I standardized my variables, the results of my logistic regression (nested 10-fold CV), measured as area under the curve, was in the 0.80 range. However, after I standardized my variables, it has dropped to just chance level (0.50 range). Is it possible for AUC to plummet this much after variable standardization? Or is it more likely that I made a mistake in editing my code? (I edited a few lines in cvglmnet.m and cvlognet.m in the glmnet package for Matlab). **On a side note, I am standardizing the variables so that they are rescaled to have values of 0~1. The min and max values are found for each feature in the training set, and based on this min and max value I rescaled the values of both the training set and test set. However, I noticed that when I do this, I get values that are slightly beyond the 0~1 range in the test set. I am wondering is this correct?
