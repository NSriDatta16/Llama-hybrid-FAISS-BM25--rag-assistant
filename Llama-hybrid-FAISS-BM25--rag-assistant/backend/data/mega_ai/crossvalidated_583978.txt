[site]: crossvalidated
[post_id]: 583978
[parent_id]: 
[tags]: 
question about notation of Bayes theorem

i was reading Yarin's thesis on Bayesian neural networks and MC-dropout and , at section 2.1 at page 18, I stumbled upon this formula $$ p(\bf{w}|\bf{X},\bf{Y})= \frac{p(\bf{Y}|\bf{X},\bf{w})p(\bf{w})}{p(\bf{Y}|\bf{X})}$$ where $\bf{X},\bf{Y} $ is the training set and $$ p(\bf{Y}|\bf{X})= \int p(\bf{Y}|\bf{X},\bf{w}) p(\bf{w}) \,dw $$ is the model evidence. Now my doubt concerns the notation, because I expected to see $$ p(\bf{w}|\bf{X},\bf{Y})= \frac{p(\bf{Y},\bf{X}|\bf{w})p(\bf{w})}{p(\bf{Y},\bf{X})}$$ but i also understand that the $\bf{Y}= f^{\bf{w}}(\bf{X})$ , so it makes sense to put $ \bf{X}$ together with the weights $\bf{w}$ at the right in the first term at the numerator. is it just a notation thing or am i missing some mathematical passage that allows to pass from one form to the other one?
