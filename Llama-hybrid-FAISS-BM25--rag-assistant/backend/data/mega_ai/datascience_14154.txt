[site]: datascience
[post_id]: 14154
[parent_id]: 
[tags]: 
Hashing trick with random forest in scala

I am trying to perform a hashing trick and then a random forest with scala. I have the following code: val documents: RDD[Seq[String]] = sc.textFile("hdfs:///tmp/new_cromosoma12v2.csv").map(_.split(",").toSeq) val hashingTF = new HashingTF() val tf: RDD[Vector] = hashingTF.transform(documents) val splits = tf.randomSplit(Array(0.7, 0.3)) val (trainingData, testData) = (splits(0), splits(1)) val numClasses = 3 val categoricalFeaturesInfo = Map[Int, Int]() val numTrees = 10 val featureSubsetStrategy = "auto" val impurity = "gini" val maxDepth = 8 val maxBins = 32 **val trainingData2=LabeledPoint(1.0,trainingData.collect())** val model = RandomForest.trainClassifier(trainingData2, numClasses, categoricalFeaturesInfo, numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins) But I have the error found : Array[org.apache.spark.mllib.linalg.Vector] required: org.apache.spark.mllib.linalg.Vector in the bold line. Do you know how I can solve it? Thank you, Laia
