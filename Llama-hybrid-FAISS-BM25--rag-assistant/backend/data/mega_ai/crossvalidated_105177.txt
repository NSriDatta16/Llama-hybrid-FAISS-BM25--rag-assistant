[site]: crossvalidated
[post_id]: 105177
[parent_id]: 104819
[tags]: 
No measure will work well for big data. Every measure is an aggregation, say an average . By adding more data, this aggregation will only change at the very last digit(s) . In most cases, a sample will already yield a result of the same quality; by the law of large numbers. But on the other hand, you'll quickly run into the situation where your numerical precision is an issue. Unless you have a very good implementation, chances are that numerical issues with your "big data" implementation will actually make the result worse than one on a sample, where these effects did not yet occur. For EM type of algorithms, starting values will likely have much more influence than different algorithms. Same for k-means: adding more data doesn't really improve results. Because the algorithm only computes a rough aggregation of your data; and aggregating more data doesn't change the outcome a lot anymore.
