[site]: datascience
[post_id]: 17171
[parent_id]: 16488
[tags]: 
Unless you have a lot of data, I have my doubts whether training RNNs for similarity will give you significant improvements. As a baseline, I would go the traditional way first and engineer some features for each pair of text, e.g.: Number of common words in both texts (words should be stemmed) Number of words in each sentence Cosine similarity on TF-IDF vectors (unigrams, word n-grams, character n-grams Glove similarity (you can try the pretrained vectors from wikipedia) Longest common subsequence (LCS) Now you can train a binary classifier on your labeled pairs dataset. For example, start with Logistic Regression or Random Forests. Maybe you can already reach the performance you are looking for. For further reference, search relevance classification is a very similar problem. You can check out the solutions from the Kaggle competitions Homedepot and Crowdflower to get more inspiration for feature engineering.
