[site]: crossvalidated
[post_id]: 185978
[parent_id]: 183520
[tags]: 
Short answer: The latent variable $z$ is needed for negative examples because it is part of the classification score function. In Latent SVM, the score of an example $x$ is defined as $f(x) = \max_z w \cdot \phi(x, z)$ and the training objective is as follows: $$ O(w) = \frac{1}{2} ||w||^2 + C \sum_{i=1}^n \ell_i \quad\quad \text{ where } \quad \ell_i = \max \left\{ 0, 1 - y_i f(x_i) \right\}\tag{1} $$ Longer answer: The bootstrapping (or data-mining) alternative that you are suggesting is equivalent to considering each pair $(x^-, z), \forall z$ as a separate training example (where $x^-$ denotes a negative example) and then doing data-mining to focus on the hard negatives; i.e. pairs of $(x^-, z)$ that are classified positively by the current model. Note that this changes the training objective function of $(1)$ to a great extent. More specifically, the loss function $\ell_i$ changes to: $$ \ell_i = \begin{cases} \max \left\{ 0, 1 - \max_z w \cdot \phi(x_i) \right\} & \text{if } y_i = +1 \\ \sum_z \max \left\{ 0, 1 + w \cdot \phi(x_i) \right\} & \text{if } y_i = -1 \end{cases} \tag{2} $$ Now the question is whether using the loss function in $(2)$ is better than than $(1)$. I argue that $(1)$ works better for training sliding window object detectors; although it is possible that for some other applications $(2)$ may be OK or even beneficial. It all depends on which choice matches the task loss better. In $(1)$ the loss (or penalty) associated to each example is about $1$* whereas in $(2)$ the loss associated to a negative example can be as large as $|Z(x)|$ where $Z(x)$ is the set of possible latent configurations for image $x$. *: the loss for each example is not exactly one because Latent SVM uses hinge loss instead of $0/1$ loss. In $0/1$ loss, however, each mis-classified example gets exactly 1 unit of penalty.
