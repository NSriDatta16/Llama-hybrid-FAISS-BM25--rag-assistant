[site]: crossvalidated
[post_id]: 544416
[parent_id]: 
[tags]: 
Newton's method for Bernouilli likelihood with ridge penalty

I am trying to derive the gradient and hessian of logistic regression with ridge penalty. The log-likelihood should be (correct me if I am wrong): $$\sum_{i=0}^n\Big(\log{(P_i^{y_i}(1-P_i)^{1-y_i}- \lambda\beta^T\beta)}\Big)$$ where: $$P_i = \frac{1}{1+e^{-x_i^T \beta}}$$ Is it possible to derive the gradient and hessian analytically to apply newton's method? I made it work using the autograd library from Python but I am curious about the actual analytical derivation.
