[site]: crossvalidated
[post_id]: 560278
[parent_id]: 
[tags]: 
Time series vs cross validation performance in classification problems

I'm wondering which case is better (or should be better, at least theoretically speaking), between time series or cross validation (or another methodology you could think of) in the case of predicting how likely is the client to purchase the product we are selling. So, I have a dataframe with monthly purchases of clients of this product. So each month I have the purchases that the client did in that month, and another monthly data (monthly expenses, number of transactions with its credit card, amounts, etc.). I have 2 years data = 24 months. So here I'm looking to predict how likely the client will buy the product the next month . The second alternative, is I aggregate the full 2 years data where each row will represent the purchases of each client in the last two years (or if you want, you can have aggregated variables with only the last 3, 6, 9 months, as you wish.. the point is they are aggregated and each row represents one client). So here I'm looking to predict how likely is the client to buy the product . Assuming this alternative is implemented each month (we run the predictions at the beginning of the month and use those predictions for the whole month, and the next month we run the predictions again as we new data) My questions are (I enumerated them to give some structure): Which alternative should perform better? Why? Is there any specific cases where one should out-perform the other? Is there any overall rule or criteria about when you should structure your data to use CV (second alternative) or time series (first alternative), for classification?
