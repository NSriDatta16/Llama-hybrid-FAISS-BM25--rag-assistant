[site]: crossvalidated
[post_id]: 619385
[parent_id]: 
[tags]: 
Comparing probability distributions from the same ML algorithm

Background: We are using a research tool that uses computer vision to quantify facial expressions (ie whether someone is smiling) from a webcam. The raw output for this tool is time series data showing the probability someone is smiling at time x. I want to compare data while people watch two different advertisements, to determine whether one video elicits more smiles than the other. When I plot histograms of the data, they usually fall into one of two shapes: Heavily skewed to the right (facial expressions are fast and transient so a lot of the data will be close to 0) Bimodal and skewed to both left and right (when people smile, the probability score rapidly goes to 1 so while there are in-between measurements of .4, .6, etc it's minimal compared to the two peaks) - then it's a question of what the balance is between the left and right sides. What people have done before: Binarize the data based off a set threshold, and compared the percentage of time that participants spent above threshold for each video. Then people average that across participants and do a t-test. It works okay but I feel like you lose a lot of granularity since you're going from continuous data to a boolean and ignoring all of the "in between" that might fall just short of threshold. Take means of raw data, average across participants, and do a t-test. I also feel like that's not truly representative because of the skewness of the data. Bin the raw data, take averages of those bins, and run statistical comparison across timepoints. This only works if there is a single manipulation between the two advertisements that can be compared directly. If the ads are completely different, comparing them across time becomes moot. Question: Is there another way to compare these probability data that takes the full range of the distributions into account? Should I log-transform the data before comparing and/or use a chi-squared or Kolmogorov-Smirnov test? I've also seen some stuff about logit since the raw data is probability but I don't know if that applies or if I'm missing something. Or do I need something more complex, or are the above approaches actually the best way to handle it? Thanks for the help - I've tried looking up ways to tackle this but often get results on how to use statistics to create the model, but not how to use statistics to compare two sets of predictive output from a model that's been made, it can go into a hole rather quickly :)
