[site]: crossvalidated
[post_id]: 69952
[parent_id]: 
[tags]: 
What train/test accuracy to expect from various classifiers on 6-multiclass problem?

I am testing various classification schemes on a training set with about 3000 instances and 20 attributes. The train set is distributed into 6 classes such that the chance accuracy would be about 18%. I also have and a test set of 500 instances. The data is clean and scaled and I tried these schemes with and without outliers. Out of the 20 attributes I select the most relevant ones suggested by caret::rfe for each scheme and then caret::train the models to determine the best parameters. I extract bootstrap accuracy from the train function and compare it with accuracy on the test set. Here are the results Scheme | Bootstrap Accuracy | Test Set Accuracy ------------ ------------------ ----------------- SVM (C-svc) | 30% | 31% C50 | 85% | 26% RandomForest | 14% | 41% MDA(earth) | 25% | 28% multinom | 18% | 29% glmnet | 23% | 26% My question is how much improvement should one expect from such models since all these models fare much better than the chance accuracy (on train set), but still worse than flip of a coin on the test set. Further what can I do to improve the accuracy of my models?
