[site]: crossvalidated
[post_id]: 6714
[parent_id]: 6652
[tags]: 
I wouldn't call the definition of CIs as wrong, but they are easy to mis-interpret, due to there being more than one definition of probability. CIs are based on the following definition of Probability (Frequentist or ontological) (1) probability of a proposition=long run proportion of times that proposition is observed to be true, conditional on the data generating process Thus, in order to be conceptually valid in using a CI, you must accept this definition of probability. If you don't, then your interval is not a CI, from a theoretical point of view. This is why the definition used the word proportion and NOT the word probability , to make it clear that the "long run frequency" definition of probability is being used. The main alternative definition of Probability (Epistemological or probability as an extension of deductive Logic or Bayesian) is (2) probability of a proposition = rational degree of belief that the proposition is true, conditional on a state of knowledge People often intuitively get both of these definitions mixed up, and use whichever interpretation happens to appeal to their intuition. This can get you into all kinds of confusing situations (especially when you move from one paradigm to the other). That the two approaches often lead to the same result, means that in some cases we have: rational degree of belief that the proposition is true, conditional on a state of knowledge = long run proportion of times that proposition is observed to be true, conditional on the data generating process The point is that it does not hold universally , so we cannot expect the two different definitions to always lead to the same results. So, unless you actually work out the Bayesian solution, and then find it to be the same interval, you cannot give the interval given by the CI the interpretation as a probability of containing the true value. And if you do, then the interval is not a Confidence Interval, but a Credible Interval.
