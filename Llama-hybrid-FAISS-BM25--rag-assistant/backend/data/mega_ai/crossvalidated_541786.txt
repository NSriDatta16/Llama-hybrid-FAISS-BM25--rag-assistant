[site]: crossvalidated
[post_id]: 541786
[parent_id]: 541716
[tags]: 
Batch gradient descent (GD) (or any GD) can run into local minima problem because the algorithm is not exact, it is a heuristic. The paragraph starts with assuming that $S$ is a collection of the same samples in $S_{sub}$ repeated 10 times. So, the minima don't change. It also states that, in large-scale real data, we don't have exact duplicates, but there is approximate redundancy, thus mimicking the duplication assumed above. And, they say that, due to this redundancy, using all the data in every iteration is inefficient. The above was my take on the paragraph you mentioned. But, I believe this post can give you some perspective on the noise introduced by SGD and how it may be useful.
