[site]: crossvalidated
[post_id]: 572765
[parent_id]: 
[tags]: 
Big NN vs Ensemble of Small NNs

Assuming the cost of training these models isn't an issue, is it advantageous to model data using an ensemble of "shallow" neural networks over a single deep neural network? My thoughts right now are that ensembling can help reduce variance, and making a larger, deeper neural network can help reduce bias. Both approaches can reduce mean square error, but it's difficult to determine which approach may be more fruitful without knowing more about the situation and the nature of the shallow/deeper models. Does my reasoning make sense?
