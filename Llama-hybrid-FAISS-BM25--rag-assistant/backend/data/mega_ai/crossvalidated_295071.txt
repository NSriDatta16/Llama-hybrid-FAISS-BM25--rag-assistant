[site]: crossvalidated
[post_id]: 295071
[parent_id]: 
[tags]: 
Testing whether a sample of correlated R.V are $N(\mu,\sigma^2)$?

Suppose I have a sample $X_1,X_2,X_3,...,X_n$. I do not assume these are independent, in fact I suspect they are slightly correlated, however I do suspect that the marginal distribution of each individually is identical and $N(\mu,\sigma^2)$. How does one go about testing whether they are indeed identically distributed? Since I don't have a random sample, the tests I'm used to using can't be applied. I am pretty sure I can come up with some permutation tests to test different aspects of this, but is there a way to test $N(\mu, \sigma^2)$ specifically? Edit: My current approach is to thin the data so I only take every $n$th value. Then the correlation is negligible (it's time series data) and I can treat it as a random sample. However, this causes me to lose a lot of information so I'd really like a better approach.
