[site]: datascience
[post_id]: 48416
[parent_id]: 20118
[tags]: 
In addition to the accepted answer: Relational databases have a large number of bytes of per-row overhead (example: this question ), which is used for bookkeeping, telling nulls from not nulls, ensuring standards such as ACID . Every time you read/write a column, not only the few bytes representing the value of this column will be read, but also these bookkeeping bytes will be accessed and possibly updated. In contrast, pandas (also R data.table) is more like an in-memory column store. One column is just an array of values and you are able to use fast numpy vectorized operations / list apprehensions that only access values that you really need. Just that for tables with few primitive columns makes relational databases multiple times slower for many data science use cases.
