[site]: crossvalidated
[post_id]: 121700
[parent_id]: 2592
[tags]: 
In SVD, if A is an m x n matrix, the top k rows of the right singular matrix V, is a k-dimension representation of the original columns of A where k A = UΣV t => A t = VΣ t U t = VΣU t => A t U = VΣU t U = VΣ -----------(because U is orthogonal) => A t UΣ -1 =VΣΣ -1 =V So $V = A^tUΣ$ -1 The rows of A t or the columns of A map to the columns of V. If the matrix of the new data on which to perform PCA for dimension reduction is Q, a q x n matrix, then use the formula to calculate $R = Q^tUΣ$ -1 , the result R is the desired result. R is an n by n matrix, and the top k rows of R (can be seen as a k by n matrix) is a new representation of Q's columns in the k-dimension space.
