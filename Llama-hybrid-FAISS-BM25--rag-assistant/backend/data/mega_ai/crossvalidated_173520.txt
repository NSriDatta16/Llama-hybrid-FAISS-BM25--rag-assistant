[site]: crossvalidated
[post_id]: 173520
[parent_id]: 
[tags]: 
Random Forests out-of-bag sample size

I am reading the description of RF here . In the "How random forests work" section, it is written that: When the training set for the current tree is drawn by sampling with replacement, about one-third of the cases are left out of the sample. This oob (out-of-bag) data is used to get a running unbiased estimate of the classification error as trees are added to the forest I am unable to understand if the one-third of the cases (out-of-bag samples size) is: an arbitrary value defined in the algorithm an estimate (e.g. on average, sampling with replacement will leave out one-third of the cases) or something else.
