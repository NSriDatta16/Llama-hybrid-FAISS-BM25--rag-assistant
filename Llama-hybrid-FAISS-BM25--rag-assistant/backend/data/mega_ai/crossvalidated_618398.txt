[site]: crossvalidated
[post_id]: 618398
[parent_id]: 
[tags]: 
PCA components - do they represent the features or the samples?

Consider the task to apply dimensional reduction to extract "salient" features from images. I am confused about what components in PCA represents: features or samples ? I understand that PCA projects samples on an orthogonal directions to maximize variance of their features. So, I understand that, having an image of shape (64x64), each pixel is a feature. And when I do: data = image data.shape # (64 x 64) pca_reducer = pca() pca_reducer.fit(data) I will get: pca_reducer.compontents_.shape # 64 x 64 From there, I could explore which components (which projected rows, I interpret) retains the maximimum variance of the original image. I am confused in putting in perspective of more than one image: data = np.array([img1.ravel(), img2.ravel()]) # each image is flattened data.shape # (2, 4096) pca_reducer = pca() pca_reducer.fit(data) I will get: pca_reducer.components.shape # 2 x 4096 It seems to me that each sample (each image) is treated as a component. But then, what is the meaning of extracting the components retaining maximum variance ? Like: pca.transform(data)[:, n_components] It seems to me that would be to extract those images that are used as "directions" or reference for the others. Instead, I would like to identify the components in terms of features, that is, in terms of regions of pixels of through those images. Can you help clarify this concept?
