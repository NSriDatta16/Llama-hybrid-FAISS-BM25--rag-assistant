[site]: crossvalidated
[post_id]: 526706
[parent_id]: 526220
[tags]: 
A common approach is to have the neural network output $u, v$ representing the angle $\hat \theta$ such that $\cos(\hat \theta) = \frac{u}{u^2+v^2}$ , $\sin(\hat \theta) = \frac{v}{u^2+v^2}$ . This avoids "boundaries" in the output which might prove challenging for backprop to learn. Each rotation $\theta$ has a corresponding rotation matrix, which, conveniently, can be constructed with the sin and cosine of the angle. $$R = \left[ \begin{array}{cc} \cos \theta & -\sin \theta\\ \sin \theta & \cos \theta\\ \end{array} \right]$$ Let $\hat R$ be the rotation matrix corresponding to the predicted angle, and $R$ be the true rotation matrix. Then $\text{tr}(R^T\hat R) = 2\cos (\hat \theta - \theta)$ is useful for computing the cosine distance loss. Conveniently, this trace trick also works for 3D rotations, even if the rotation happens along more than one coordinate axis.
