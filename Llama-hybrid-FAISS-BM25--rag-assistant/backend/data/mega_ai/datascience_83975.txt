[site]: datascience
[post_id]: 83975
[parent_id]: 
[tags]: 
How to interpret Low Pearson correlation coefficient between stable signals and high Pearson correlation coefficient between unstable signals?

I calculated the Pearson correlation coefficient between two signals, that described the state of the unit. During normal operation of the unit, both signals were fairly stable and fluctuated very little. At some point in time, the unit began to form a defect, in connection with which the oscillations of the signals increased, and also a trend of growth in their absolute values ​​began to be observed. Signals describing the normal operation of the unit. Signals describing emergency operation of the unit. Signals that describe both normal and emergency operation of the unit (combination 1) and 2)). In each of these three cases, I calculated the correlation coefficients between the signals. In the first case, it was minimal at 0.5, in the second case, at 0.9, and in the third case, at a level close to 1. I have the following questions: Why is there such a low correlation between the signals during normal operation of the unit, when the signals behaved "by eye" in the same way? In fact, both signals at this time had minimal variation and behaved in the same way. High correlation during the occurrence of a unit failure. Both signals showed an upward trend, both again behaved the same "by eye". But why did the correlation become high in this case? During normal operation, both signals also behaved in the same way, stably kept at the same level. Maximum correlation when I combined the normal and emergency signals of the unit. Why, by combining data samples with low (normal operation of the unit) and high (emergency operation of the unit) correlation, I get the samples, the correlation between which turned out to be the highest of all three cases? What could have caused this effect?
