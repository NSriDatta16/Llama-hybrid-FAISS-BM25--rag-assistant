[site]: crossvalidated
[post_id]: 456121
[parent_id]: 
[tags]: 
Estimate an error bound for an estimate

I have two datasets regarding historical data (say, quarterly revenues for companies over time). The first is the actual results of this data and the other is available estimates for these results prior to their release. The datasets have the same shape: company year quarter revenue 1 1 1 10 1 1 2 11 1 1 3 12 1 1 4 13 2 1 1 14 [...] I am trying to use this historical data to evaluate the "expected error" for future estimates. However, I'm unsure as to which metric is appropriate to use in this case. I can obviously join the datasets and calculate the error of each estimate as a percentage: company year quarter revError 1 1 1 0.07 1 1 2 -0.02 1 1 3 -0.10 1 1 4 0.04 2 1 1 0.01 [...] I can then collect the average error and the error's standard deviation per company. As I understand it, this would give me two datapoints: the average would tell me whether there's bias in the estimates, maybe whoever developed the estimates is excessively optimistic about the company. the standard deviation would tell me the breadth of the errors. Companies with good estimates (very close to the actual result) will have small standard deviations and those with unreliable estimates will have larger standard deviations. Is that it? Just calculate that and then apply it to future estimates as "expected revenue of $100 \pm 3\%$ " (if 3% is $2\sigma$ for a 95% confidence interval)? And if the average error indicates a significant bias (i.e. estimates are usually 20% above reality), can I adjust my historical estimates accordingly (such that the bias is synthetically eliminated), recalculate the standard deviation and then use the adjusted SD with my future (adjusted) estimates?
