[site]: crossvalidated
[post_id]: 87032
[parent_id]: 
[tags]: 
Eigenvalues of correlation matrices exhibit exponential decay

I have a data-set of $P$ samples of size $N$, and noticed that the eigenvalues of the correlation matrices $A^TA$, when presented in descending order, can in many cases be described as an exponential decaying function. That is, there is a good fit linear of from $i=1..N$ to $\log|\lambda_i|$. Moreover, for several data sets I found that the exponent of the decay is fairly constant. Is this a well-known fact or just one's tendency for finding patterns? Obviously from PCA / SVD it tells me something about the ability to approximate the data using low-dimensional matrix. Are there any solid mathematical results on the size of the exponent of this decay?
