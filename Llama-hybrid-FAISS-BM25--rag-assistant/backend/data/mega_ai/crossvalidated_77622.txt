[site]: crossvalidated
[post_id]: 77622
[parent_id]: 
[tags]: 
How to report the ratio of two sets of experimental results?

I have measured the time taken to solve a problem by algorithm $X$ and by algorithm $Y$. It takes a quite long time, so I have only 10 data for each algorithm: $$ X : ( x_1, x_2, \dots , x_{10}) \\ Y : ( y_1, y_2, \dots , y_{10}) $$ EDIT: The problem they are solving is randomized . I generated 10 instances of the problem using 10 different random seeds. The 10 computational times correspond to these 10 problem instances. In this sense, the data are paired . The change of a seed does not change the difficulty of the problem very much. END OF EDIT I have computed the ratio of the averages: $$ avg = \frac{\sum_{k=1}^{10} x_k }{\sum_{k=1}^{10} y_k } $$ This however, does not convey any information on how precise the ratio is. One possible way is to estimate the standard deviation . According to this answer , the average of iid random variables is asymptotically normal and therefore the ratio has asymptotical Cauchy distribution , whose standard deviation is infinite . This does not satisfy me, especially since I have only 10 data. Then according to this answer I should approximate the standard deviation using Taylor series . This answer looks better, but it still doesn't feel right. The distribution of a ratio is intuitively highly assymetrical around 1. (you have only the interval $(0; 1)$ to capture the fact that algorithm $X$ is faster, but the entire $(1 ; \infty)$ to capture the fact that $Y$ is faster). So even a well estimated standard deviation can be of little use. It would be better to provide some sort of confidence interval . For example: the ratio is 1,5 with an assymetrical confidence interval of (1,3 ; 2,8). But I have no idea how to estimate this since I do not know the distribution of my data. EDIT2: Here are my data: X Y 111536 160134 111165 164850 112494 165844 115959 166409 121296 161755 119948 167781 119172 168666 117330 169766 116661 166518 129311 169884 EDIT3: To answer the question (in comment) of D L Dahly why not just report that one algorithm is faster in all instances For the brevity of the question I did not mention that I have actually 84 sets of data described in this question. 2 problems x 6 dimensions of the problem x 7 possible sizes of the problem. In some instances X is faster, in some Y is faster and in some instances the results are inconclusive. I do not necessarily need confidence intervals or standard deviations. I just want to provide the reader with something richer than just averages . The reader should have a sense of how well the average represents the experimental results.
