[site]: crossvalidated
[post_id]: 567196
[parent_id]: 
[tags]: 
Why are mixed models robust to missing (at random) data in the response variable?

I have read that mixed effects models are well equipped to handle missing (at random) response data if estimated using likelihood methods. However, I am yet to find a clear (not overly technical) explanation of how this is achieved. Models without random effects (e.g. general linear models) can be fit using maximum likelihood so are these not well equipped for missing response data too? It always seems to be mixed models that people advocate for missing data, so I'm assuming it must have something to do with the within subject correlations...? In my reading I came across this [1]: https://www.uvm.edu/~statdhtx/StatPages/More_Stuff/Mixed-Models-Repeated/Mixed-Models-for-Repeated-Measures1.html Under the section "Missing data" - paragraph 3 it says: But if I can find a way to keep as much data as possible, and if people with low pretest scores are missing at one or more measurement times, the pretest score will essentially serve as a covariate to predict missingness . I believe the author is intimating about a mixed model approach but do not really understand this sentence and thought that this might be key to my understanding. Thank you very much!
