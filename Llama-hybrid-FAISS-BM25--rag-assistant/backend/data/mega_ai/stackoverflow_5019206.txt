[site]: stackoverflow
[post_id]: 5019206
[parent_id]: 
[tags]: 
Google Analytics API - Choice of Metric Affects Dimension Values Returned?

Good morning. I've seen this behavior in the Google Analytics API, which as a SQL guy I find bizarre. I'd like to get a list of all values for adContent, so I query ga:adContent and (because I must also select a metric, for no well-defined reason) ga:organicSearches . It's in the same group (Campaign), so maybe it'll perform better back on the server. I get one row: adContent is "(not set)", organicSearches is 516,674. Huh, I guess adContent isn't being used. But the marketing department swears that it is, and produce some convincing screen shots. Later on, I arbitrarily change the metric to ga:transactions . In the universe I woke up in, this should have absolutely no impact on anything, except the actual value returned in that column. Instead, I get zillions of rows, with plausible values for ga:adContent . The value for ga:transactions is sometimes zero, so it's not the case that GA was filtering for "metric > 0". There are no filters in my query. I did not change the date range between these two variants. Can anyone tell me what's going on? I expect the above queries to translate to something like this, which should return exactly the same number of rows: SELECT adContent, SUM(organicSearches) FROM Campaign WHERE Date BETWEEN X AND Y GROUP BY adContent SELECT adContent, SUM(transactions) FROM Campaign INNER JOIN ECommerce ON WHERE Date BETWEEN X AND Y GROUP BY adContent I realize that GA probably isn't using an ordinary RDMS on the back end, but surely 1 + 1 still equals 2 in any database!
