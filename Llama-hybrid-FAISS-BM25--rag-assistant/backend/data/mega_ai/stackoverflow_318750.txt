[site]: stackoverflow
[post_id]: 318750
[parent_id]: 290436
[tags]: 
You must tokenize your input before starting this kind of process. (I can't recommend the famous Dragon Book highly enough - even the ancient edition stood the test of time, the updated 2006 version looks great). Compiling is the sort of job that's best split up into smaller phases: if your first phase performs lexical analysis into tokens, splitting lines into keywords, identifiers, constants, and so on, then it's much simpler to find the references to macros and look them up in a symbol table. (It's also relatively easier to use a tool like lex or flex or one of their modern equivalents to do this job for you, than to attempt to do it from scratch). The 'clue' seems to be if the code has more number of macros then the code generation takes so much of time . That sounds like the process is linear in the number of macros, which is certainly too much. I'm assuming this process occurs one line at a time (if your language allows that, obviously that has enormous value, since you don't need to treat the program as one huge string), and the pseudocode looks something like for(each line in the program) { for(each macro definition) { test if the macro appears; perform replacement if needed; } } That clearly scales with the number of macro definitions. With tokenization, it looks something like this: for(each line in the program) { tokenize the line; for(each token in the line) { switch(based on the token type) { case(an identifier) lookup the identifier in the table of macro names; perform replacement as necessary; .... } } } which scales mostly with the size of the program (not the number of definitions) - the symbol table lookup can of course be done with more optimal data structures than looping through them all, so that no longer becomes the significant factor. That second step is something that again programs like yacc and bison (and their more modern variants) can happily generate code to do. afterthought: when parsing the macro definitions , you can store those as a token stream as well, and mark the identifiers that are the 'placeholder' names for parameter replacement. When expanding a macro, switch to that token stream. (Again, something things like flex can easily do).
