[site]: datascience
[post_id]: 117370
[parent_id]: 117368
[tags]: 
There are multiply approaches for doing so. In any way, it would be a good idea to use some more knowledge about the concrete setting to decide for the right way. Without this knowledge, I just name some possible options: Intersection You could reduce your time series to the points in time, that appear in both. in your case, that would be t=[0,3] . Probably, this is a very strong reduction in your case and does not lead to the desired results. I would only use this approach, if there is (nearly) independence between nearby measurements, i.e. that the measurement if x1 at time 5 and 6 are independent. Interpolation You could interpolate between the measurements. The choice of a good interpolation method depends on your concrete setting. The tricky part here is to decide for the right points in time that you use for your cross-correlation-computation. You could: Take the time points of one series and only interpolate on the other one. The problem is, that this is not symmetric and you could get different correlations for choosing x1 or x2 as reference series. Take the union of all time points. The problem here is, that you might include some bias in in the computation, since points that differ are slightly will count twice, while identical points will only count once. If you can identify time-points (e.g. 0 with 0, 1 with 2, 3 with 3, ...), you could take the mean of each pair, i.e. t=[0, 1.5, 3, 4.5, 6.5, 8.5] in your case Finally, you could create time points independent of the original ones, e.g. [0,1,2,3,4,5,6,7,8,9] . Due to the disadvantages of interpolations, all these points should ideally be close to real time points . I hope my answer gives you some approaches how to handle you problem.
