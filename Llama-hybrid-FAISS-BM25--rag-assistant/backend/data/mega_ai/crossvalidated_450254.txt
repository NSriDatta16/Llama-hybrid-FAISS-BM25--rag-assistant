[site]: crossvalidated
[post_id]: 450254
[parent_id]: 
[tags]: 
Can all regression networks be reduced to one output?

Lets say I have a neural network that outputs two numbers. I can represent those two numbers uniquely using the Cantor pairing function. Now, this function is for natural numbers, but I think it can be easily remedied for real numbers by multiplying enough powers of 10 so that there are no digits after the decimal (in principle this would not work for say, 1/3, but in practice this decimal would have an end). This function can be generalized to n-tuples, so that n numbers can be represented uniquely by one number. This would greatly reduce number of connections. Has anything like this been implemented?
