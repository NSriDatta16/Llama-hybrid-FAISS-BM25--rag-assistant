[site]: crossvalidated
[post_id]: 175752
[parent_id]: 
[tags]: 
KDD 15 paper: scoring bigrams

I am by no mean into Statistics nor NLP . And I am reading the following paper, trying to learn something new: http://astro.temple.edu/~tuc17157/pdfs/grbovic2015kddA.pdf The authors used a score threshold to pick up bigrams from the processed text. The formula of the score is (section 4.2): $$score(w_i,w_j) = \frac{count(w_i \& w_j)}{count(w_i) count(w_j)}$$ My brain told me I have seen this expression before. After awhile, I recalled that: $$\text{Two events are independent iff. } P(A\&B) = P(A)P(B)$$ Then the score can be reduced to: $$score(w_i, w_j) = \frac{count(w_i \& w_j)}{count(w_i) count(w_j)} \\= \frac{P(A\&B)}{P(A)P(B)} \div \text{number of total occurrences of all words}$$ Therefore the score is just a more convenient way of measuring the ratio of probabilities, since they only differ by a constant. Does this mean if score is higher, the two words are more statistically dependent? How should I interpret this score statistically?
