[site]: crossvalidated
[post_id]: 553287
[parent_id]: 
[tags]: 
Non-Ridge Kernelized Regression?

Every presentation that I have seen for kernelized regression focuses on finding $$\underset{f \in \mathcal{H}_k}{\min} \sum_{i=1}^{n}(y_i-f(\mathbf{x}_i))^2+\lambda \|f\|^2_{\mathcal{H}_k}.$$ Here, $\mathcal{H}_k$ is a Reproducing kernel Hilbert space (RKHS). I was wondering Why the focus on ridge regression? Can we use other penalties here, or is there something about the ridge penalty that is natural in this setting? Can we do un-penalized kernelized regression? Why is this not usually presented prior to kernel ridge regression?
