[site]: crossvalidated
[post_id]: 131354
[parent_id]: 126244
[tags]: 
I have emailed several scholars (almost 30 persons) several weeks ago. Few of them sent their mail (always collective emails). Eugene Demidenko was the first to answer : cov/sqrt(var1*var2) is always within [-1,1] regardless of the interpretation: it may be estimates of intercept and slope, two slopes, etc. The fact that -1 This was followed by an email from Thomas Snijders : The information that is missing is what was actually written about this on page 122, 123, 124, 129 of Snijders & Bosker (2nd edition 2012). This is not about two competing claims of which no more than one can be true, it is about two different interpretations. On p. 123 a quadratic variance function is introduced, \sigma_0^2 + 2 \sigma_{01} * x + \sigma_1^2 * x^2 and the following remark is made: "This formula can be used without the interpretation that \sigma_0^2 and \sigma_1^2 are variances and \sigma_{01} a covariance; these parameters might be any numbers. The formula only implies that the residual variance is a quadratic function of x. Let me quote a full paragraph of p. 129, about a quadratic variance function at level two; note that ONE MIGHT INTERPRET that \tau_0^2 and \tau_1^2 are the level-two variances of the random intercept and random slope, and \tau_{01} is their covariance, but this is explicitly put behind the horizon: "The parameters \tau_0^2, \tau_1^2, and \tau_{01} are, as in the preceding section, not to be interpreted themselves as variances and a corresponding covariance. The interpretation is by means of the variance function (8.7) [note t.s.: in the book this is mistakenly reported as 8.8]. Therefore it is not required that \tau_{01}^2 The variance function is a quadratic function of x (the variable "with the random slope"), and the variance of the outcome is this plus the level-1 variance. As long as this is positive for all x, the modelled variance is positive. (An extra requirement is that the corresponding covariance matrix is positive definite.) Some further background of this is the existence of differences in parameter estimation algorithms in software. In some multilevel (random effects) software, the requirement is made that the covariance matrices of the random effects are positive semi-definite on all levels. In other software, the requirement is made only that the resulting estimated covariance matrix for the observed data is positive semi-definite. This implies that the idea of random coefficients of latent variables is relinquished, and the model specifies a certain covariance structure for the observed data; no more, no less; in that case the cited interpretation of Joop Hox does not apply. Note that Harvey Goldstein already long ago used linear variance functions at level one, represented by a zero slope variance and nonzero slope-intercept correlation at level one; this was and is called "complex variation"; see, e.g., http://www.bristol.ac.uk/media-library/sites/cmm/migrated/documents/modelling-complex-variation.pdf And then, Joop Hox replied : In the software MLwiN it is actually possible to estimate a covariance term and at the same time constrain one of the variances to zero, which would make the "correlation" infinite. And yes, some software will allow estimates such as negative variances (SEM software usually allows this). So my statements were not completely accurate. I refered to "normal" unstructured random structures. Let me add that if you rescale the variable with the random slope to have a different zero-point, the variances and covariances generally change. So the correlation is only interpretable if the predictor variable has a fixed zero-point, i.e. is measured on a ratio scale. This applies to growth curve models, where the correlation between initial status and rate of growth is sometimes interpreted. In that case the value zero should be the 'real' time point where the process starts. And he sent another mail : Anyway, I think Tom's explanation below fits the style of the Snijders/Bosker collaboration better than my more informal style. I would add to page 90 a footnote stating something like "Note that the parameter values in the random part are estimates. Interpreting the standardized covariances as ordinary correlations assumes that there are no constraints on the variances and that the software does not allow negative estimates. If the random part is unstructured the interpretation as ordinary (co)variances is generally tenable.". Note that I wrote about the correlation interpretation in the longitudinal chapter. In growth curve modeling it is very tempting to interpret this correlation as a substantive result, and that is dangerous because the value depends on the "metric of time". If you are interested in that I recommend to go to Lesa Hoffman's website ( http://www.lesahoffman.com/ ). So I think in my situation, where I've specified an unstructured covariance for the random effects, I should interpret the intercept-slope correlation as an ordinary correlation.
