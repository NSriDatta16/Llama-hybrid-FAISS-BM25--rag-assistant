[site]: crossvalidated
[post_id]: 431080
[parent_id]: 431009
[tags]: 
This question is sufficiently broad that a comprehensive answer would require a simulation study (some key parts of which have undoubtedly been done), going far beyond our usual style of answers. A Welch 2-sample t test can't be exactly as good as a pooled t test if we know the two populations have the same variance. (1) A Welch test at "level 5%" with $n_1 = 5, n_2 = 100$ when variances are equal gave Type I error a little above 5% $(0.054 \pm 0.0014).$ I didn't explore samples sizes below 5. set.seed(1234) out = replicate(10^5, as.numeric(t.test(rnorm(5), rnorm(100))[2:3])) mean(out[1,]) [1] 4.902672 # avg DF about 5 mean(out[2,] In the histogram below of 100,000 simulated P-values, the maroon bar at left represents the true significance level (Type I error) of the test. Its width is 0.5 and its height is about 0.108, for a total area of about 0.054, (2) Pooled test at level 5% with $n_1 = 5, n_2 = 100$ when variances are equal. Here, DF = $n_1 + n_2 - 2 = 103$ for all tests. The significance level is very near the intended 5%. set.seed(1234) out = replicate(10^5, as.numeric(t.test(rnorm(5), rnorm(100), var.eq=T)[2:3])) mean(out[1,]) [1] 103 # DF exactly n1 + n2 - 2 = 103 mean(out[2,] (3) However, if the smaller sample has variance 4 and the larger has variance 1, then the pooled tests with a nominal 5% significance level actually has significance level almost 30% (rich in false discoveries). set.seed(1234) out = replicate(10^5, as.numeric(t.test(rnorm(5,0,2), rnorm(100), var.eq=T)[2:3])) mean(out[1,]) [1] 103 mean(out[2,] (4) The Welch test may not have exactly 5% Type I error. Even so, with average P-value near 5%, it is clearly preferable to the pooled test when variances are unequal, as in (3). set.seed(1234) out = replicate(10^5, as.numeric(t.test(rnorm(5,0,2), rnorm(100))[2:3])) mean(out[1,]) [1] 4.209818 mean(out[2,] (5) First of two simulations focused on power. If variances are unequal and sizes are grossly unbalanced $(n_1 = 5, n_2 =100$ ), the power to detect that $\mu_1 = 4$ differs from $\mu_2 = 0$ is about 90%. set.seed(1234) out = replicate(10^5, as.numeric(t.test(rnorm(5,4,2), rnorm(100))[2:3])) mean(out[1,]) [1] 4.209818 mean(out[2,] In the figure below, the green bar at left represents the power of the test. So now, a tall first bar is a good thing. (6) If we balance the data (both samples of size 5), the power of the Welch test is reduced very little if any, compared to the previous simulation. Changing the means to be equal, leaving sample sizes at 5, and leaving variances unequal, a similar simulation (not shown) gave significance level 4.9% set.seed(1234) out = replicate(10^5, as.numeric(t.test(rnorm(5,4,2), rnorm(5))[2:3])) mean(out[1,]) [1] 6.000759 mean(out[2,] Summary comments. None of these simulations changes the advice to prefer the Welch test to the pooled test, except for tiny sample sizes, In that case prior information whether variances are equal might help to decide between Welch test and a pooled test. I have tried to probe in relevant directions with the few simulations above, but I certainly don't claim that they settle anything. If anyone has information from related simulations that would refine or extend my 'no new news' conclusions here, I'd be happy to see them.
