[site]: datascience
[post_id]: 63656
[parent_id]: 
[tags]: 
Using a DCGAN to create an intrusion detection system

The TL;DR of my question is how do you write a discriminator and generator of a DCGAN in pytorch to accept a csv file instead of an image? I am attempting to partial recreate an experiment from the following research paper: A Simple Recurrent Unit Model Based Intrusion Detection System With DCGAN by Jin Yang et al. Specifically I am currently trying to get a DCGAN to work by taking in a data set consisting of malicious user activity from a network firewall from the CSE-CIC-IDS2018 dataset, and I would like to receive an output from the generator that contains new unique packets of data that would appear to be malicious so that I can use those packets to increase the number of malicious packets I have available to train a neural network to detect malicious activity on a network. This data set comes in a csv file that has one packet per row and there are 78 columns with various information about the packets themselves. I haven't been able to find example code where this has been accomplished on something other than pictures. So I have used some code that I found for images and have been attempting to modify that code. I began and then modified the code provided on the following website: dcgan_faces_tutorial I wrote my own dataset class for the DCGAN using information from the following website: data_loading_tutorial My code so far is as follows: # Set random seed for reproducibility manualSeed = 999 #manualSeed = random.randint(1, 10000) # use if you want new results print("Random Seed: ", manualSeed) random.seed(manualSeed) torch.manual_seed(manualSeed) # Root for the IPS dataset. ipsroot = 'test.csv' # Number of workers for dataloader workers = 0 # Batch size during training batch_size = 128 # Spatial size of training images. All images will be resized to this # size using a transformer. image_size = 64 # Number of channels in the training images. For color images this is 3 nc = 3 # Size of z latent vector (i.e. size of generator input) nz = 100 # Size of feature maps in generator ngf = 64 # Size of feature maps in discriminator ndf = 64 # Number of training epochs num_epochs = 1 # Learning rate for optimizers lr = 0.0002 # Beta1 hyperparam for Adam optimizers beta1 = 0.5 # Number of GPUs available. Use 0 for CPU mode. ngpu = 1 class PacketDataset(Dataset): """IPS 2018 Dataset.""" def __init__(self, csv_file, transform=None): """ Args: csv_file (string): Path to the csv file with annotations. #root_dir (string): Directory with all the images. transform (callable, optional): Optional transform to be applied on a sample. """ self.packets_data = pd.read_csv(csv_file) self.transform = transform def __len__(self): return len(self.packets_data) def __getitem__(self, idx): if torch.is_tensor(idx): idx = idx.tolist() packets = self.packets_data.iloc[idx, 0:]#.as_list() packets = np.array([packets]) packets = packets.astype('float') #sample = {'All Data': packets, 'Answer': packets[79]} #if self.transform: #packets = self.transform(packets) return packets packet_dataset = PacketDataset(csv_file=ipsroot) # Create the dataloader dataloader = torch.utils.data.DataLoader(packet_dataset, batch_size=batch_size, shuffle=True, num_workers=workers) # Decide which device we want to run on device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu") # custom weights initialization called on netG and netD def weights_init(m): classname = m.__class__.__name__ if classname.find('Conv') != -1: nn.init.normal_(m.weight.data, 0.0, 0.02) elif classname.find('BatchNorm') != -1: nn.init.normal_(m.weight.data, 1.0, 0.02) nn.init.constant_(m.bias.data, 0) # Generator Code class Generator(nn.Module): def __init__(self, ngpu): super(Generator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( # input is Z, going into a convolution nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False), nn.BatchNorm2d(ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4 nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf * 4), nn.ReLU(True), # state size. (ngf*4) x 8 x 8 nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf * 2), nn.ReLU(True), # state size. (ngf*2) x 16 x 16 nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf), nn.ReLU(True), # state size. (ngf) x 32 x 32 nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False), nn.Tanh() # state size. (nc) x 64 x 64 ) def forward(self, input): return self.main(input) # Create the generator netG = Generator(ngpu).to(device) # Handle multi-gpu if desired if (device.type == 'cuda') and (ngpu > 1): netG = nn.DataParallel(netG, list(range(ngpu))) # Apply the weights_init function to randomly initialize all weights # to mean=0, stdev=0.2. netG.apply(weights_init) # Print the model print(netG) class Discriminator(nn.Module): def __init__(self, ngpu): super(Discriminator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( # input is (nc) x 64 x 64 nn.Conv1d(ndf, nc, 1, bias=False), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf) x 32 x 32 nn.Conv1d(nc, ndf, 1, bias=False), nn.BatchNorm2d(ndf * 2), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*8) x 4 x 4 nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False), nn.Sigmoid() ) def forward(self, input): return self.main(input) # Create the Discriminator netD = Discriminator(ngpu).to(device) # Handle multi-gpu if desired if (device.type == 'cuda') and (ngpu > 1): netD = nn.DataParallel(netD, list(range(ngpu))) # Apply the weights_init function to randomly initialize all weights # to mean=0, stdev=0.2. netD.apply(weights_init) # Print the model print(netD) # Initialize BCELoss function criterion = nn.BCELoss() # Create batch of latent vectors that we will use to visualize # the progression of the generator fixed_noise = torch.randn(64, nz, 1, 1, device=device) # Establish convention for real and fake labels during training real_label = 1 fake_label = 0 # Setup Adam optimizers for both G and D optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)) optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999)) # Training Loop # Lists to keep track of progress img_list = [] G_losses = [] D_losses = [] iters = 0 netD = netD.double() print("Starting Training Loop...") # For each epoch for epoch in range(num_epochs): # For each batch in the dataloader for i, data in enumerate(dataloader, 0): ############################ # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z))) ########################### ## Train with all-real batch netD.zero_grad() # Format batch real_cpu = data.to(device) b_size = real_cpu.size(0) label = torch.full((b_size,), real_label, device=device) # Forward pass real batch through D output = netD(real_cpu).view(-1).double() # Calculate loss on all-real batch errD_real = criterion(output, label) # Calculate gradients for D in backward pass errD_real.backward() D_x = output.mean().item() ## Train with all-fake batch # Generate batch of latent vectors noise = torch.randn(b_size, nz, 1, 1, device=device) # Generate fake image batch with G fake = netG(noise) label.fill_(fake_label) # Classify all fake batch with D output = netD(fake.detach()).view(-1) # Calculate D's loss on the all-fake batch errD_fake = criterion(output, label) # Calculate the gradients for this batch errD_fake.backward() D_G_z1 = output.mean().item() # Add the gradients from the all-real and all-fake batches errD = errD_real + errD_fake # Update D optimizerD.step() ############################ # (2) Update G network: maximize log(D(G(z))) ########################### netG.zero_grad() label.fill_(real_label) # fake labels are real for generator cost # Since we just updated D, perform another forward pass of all-fake batch through D output = netD(fake).view(-1) # Calculate G's loss based on this output errG = criterion(output, label) # Calculate gradients for G errG.backward() D_G_z2 = output.mean().item() # Update G optimizerG.step() # Output training stats if i % 50 == 0: print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f' % (epoch, num_epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)) # Save Losses for plotting later G_losses.append(errG.item()) D_losses.append(errD.item()) # Check how the generator is doing by saving G's output on fixed_noise if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)): with torch.no_grad(): fake = netG(fixed_noise).detach().cpu() #img_list.append(vutils.make_grid(fake, padding=2, normalize=True)) iters += 1 And this is the output when I attempt to run that code: runfile('C:/Users/user/Desktop/Class/CS 898AN/2018 IPS Dataset/test.py', wdir='C:/Users/user/Desktop/Class/CS 898AN/2018 IPS Dataset') Random Seed: 999 Generator( (main): Sequential( (0): ConvTranspose2d(100, 8, kernel_size=(4, 4), stride=(1, 1), bias=False) (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): ConvTranspose2d(8, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): ReLU(inplace=True) (6): ConvTranspose2d(4, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (7): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (8): ReLU(inplace=True) (9): ConvTranspose2d(2, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (10): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (11): ReLU(inplace=True) (12): ConvTranspose2d(1, 78, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (13): Tanh() ) ) Discriminator( (main): Sequential( (0): Conv1d(1, 78, kernel_size=(1,), stride=(1,), bias=False) (1): LeakyReLU(negative_slope=0.2, inplace=True) (2): Conv1d(78, 1, kernel_size=(1,), stride=(1,), bias=False) (3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (4): LeakyReLU(negative_slope=0.2, inplace=True) (5): Conv2d(8, 1, kernel_size=(4, 4), stride=(1, 1), bias=False) (6): Sigmoid() ) ) Starting Training Loop... Training with all-real batch. Formatting all-real batch. Forwarding pass real batch through D. Traceback (most recent call last): File " ", line 1, in runfile('C:/Users/user/Desktop/Class/CS 898AN/2018 IPS Dataset/test.py', wdir='C:/Users/user/Desktop/Class/CS 898AN/2018 IPS Dataset') File "C:\Users\user\Anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 827, in runfile execfile(filename, namespace) File "C:\Users\user\Anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 110, in execfile exec(compile(f.read(), filename, 'exec'), namespace) File "C:/Users/user/Desktop/Class/CS 898AN/2018 IPS Dataset/test.py", line 294, in output = netD(real_cpu).view(-1).double() File "C:\Users\user\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 541, in __call__ result = self.forward(*input, **kwargs) File "C:/Users/user/Desktop/Class/CS 898AN/2018 IPS Dataset/test.py", line 233, in forward return self.main(input) File "C:\Users\user\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 541, in __call__ result = self.forward(*input, **kwargs) File "C:\Users\user\Anaconda3\lib\site-packages\torch\nn\modules\container.py", line 92, in forward input = module(input) File "C:\Users\user\Anaconda3\lib\site-packages\torch\nn\modules\module.py", line 541, in __call__ result = self.forward(*input, **kwargs) File "C:\Users\user\Anaconda3\lib\site-packages\torch\nn\modules\batchnorm.py", line 59, in forward self._check_input_dim(input) File "C:\Users\user\Anaconda3\lib\site-packages\torch\nn\modules\batchnorm.py", line 244, in _check_input_dim .format(input.dim())) ValueError: expected 4D input (got 3D input) I think changed the kernel size to 1, which I think gives a 1x1, do I actually need a 1x1 for this task? I understand that I have given it the wrong dimensions, but I'm not quite sure how to change the expected dimensions of the input. What do I need to modify to get the discriminator and the generator working on the data set that I have?
