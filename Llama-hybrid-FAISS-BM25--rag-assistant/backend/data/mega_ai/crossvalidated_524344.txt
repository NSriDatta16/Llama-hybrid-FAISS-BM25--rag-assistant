[site]: crossvalidated
[post_id]: 524344
[parent_id]: 524284
[tags]: 
As section 3.3 of Statistical Learning with Sparsity notes, one solution is a multi-class logistic regression. That's generally preferable to sets of multiple one-versus-others or one-versus-one models. That text provides an example with a 10-class model and shows how to use a grouped LASSO if you want more overall sparsity in selected predictors. The combination of what predictors are selected and their associated regression coefficients then provides some measure of predictor importance. An alternative is to use a tree-based multinomial model. The principles of tree-based models (bagged trees, random forest, boosted trees) are outlined in Chapter 8 of An Introduction to Statistical Learning . For implementation with boosted trees, both the gbm package and the xgboost package in R allow for multi-class analysis. The above tree-based models provide estimates of predictor importance based on measures, averaged over all the trees, of how much the predictor adds to performance when it's used in tree splits. Be warned, however, that in the $p \gg n$ setting all these approaches only provide estimates of "feature importance" for features that happened to be selected based on your particular dataset. The same type of model on a different dataset sampled from the underlying population might select a completely different set of features, as multiple predictors are inherently correlated in that setting. Thus the vagaries of sampling can lead to differences in what appear to be the "most important" features. You can evaluate this for yourself by repeating your modeling on multiple bootstrapped re-samples of your dataset.
