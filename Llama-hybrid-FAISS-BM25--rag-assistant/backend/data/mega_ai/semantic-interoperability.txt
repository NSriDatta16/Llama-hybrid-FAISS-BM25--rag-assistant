Semantic interoperability is the ability of computer systems to exchange data with unambiguous, shared meaning. Semantic interoperability is a requirement to enable machine computable logic, inferencing, knowledge discovery, and data federation between information systems. Semantic interoperability is therefore concerned not just with the packaging of data (syntax), but the simultaneous transmission of the meaning with the data (semantics). This is accomplished by adding data about the data (metadata), linking each data element to a controlled, shared vocabulary. The meaning of the data is transmitted with the data itself, in one self-describing "information package" that is independent of any information system. It is this shared vocabulary, and its associated links to an ontology, which provides the foundation and capability of machine interpretation, inference, and logic. Historical precursors In the 1960s, Jacques Blois at the Université Libre de Bruxelles (ULB) pioneered semantic interoperability through his morphological analysis system for the DICAUTOM project (1966-1971), funded by Euratom and the CECA. This system standardized multilingual terminology by reducing inflected word forms to their lemmas (e.g., "apprendront" to "apprendre") and linking them to shared semantic units, enabling machine-interpretable meaning across languages. By creating a proto-ontology with metadata-enriched entries, Blois anticipated modern vocabulary-based data exchange and ontologies, as described in his 1962 work Morphologie du français pour la traduction automatique and a 1969 ULB report co-authored with Lydia Hirschberg on a "manual of French coding." His system underpinned EURODICAUTOM (1975), a precursor to the EU's IATE database, facilitating cross-lingual interoperability. Syntactic interoperability (see below) is a prerequisite for semantic interoperability. Syntactic interoperability refers to the packaging and transmission mechanisms for data. In healthcare, HL7 has been in use for over thirty years (which predates the internet and web technology), and uses the pipe character (|) as a data delimiter. The current internet standard for document markup is XML, which uses "< >" as a data delimiter. The data delimiters convey no meaning to the data other than to structure the data. Without a data dictionary to translate the contents of the delimiters, the data remains meaningless. While there are many attempts at creating data dictionaries and information models to associate with these data packaging mechanisms, none have been practical to implement. This has only perpetuated the ongoing "babelization" of data and inability to exchange data with meaning. Since the introduction of the Semantic Web concept by Tim Berners-Lee in 1999, there has been growing interest and application of the W3C (World Wide Web Consortium) standards to provide web-scale semantic data exchange, federation, and inferencing capabilities. Semantic as a function of syntactic interoperability Syntactic interoperability, provided by for instance XML or the SQL standards, is a pre-requisite to semantic. It involves a common data format and common protocol to structure any data so that the manner of processing the information will be interpretable from the structure. It also allows detection of syntactic errors, thus allowing receiving systems to request resending of any message that appears to be garbled or incomplete. No semantic communication is possible if the syntax is garbled or unable to represent the data. However, information represented in one syntax may in some cases be accurately translated into a different syntax. Where accurate translation of syntaxes is possible, systems using different syntaxes may also interoperate accurately. In some cases, the ability to accurately translate information among systems using different syntaxes may be limited to one direction, when the formalisms used have different levels of expressivity (ability to express informa