[site]: crossvalidated
[post_id]: 206334
[parent_id]: 
[tags]: 
Strategy for finding optimal bagging parameters

I am using a BaggingClassifier of SVMs in sklearn. What is the best strategy for finding optimal parameters, using my training/vaildation data? When using the full dataset, I can use grid search to find the best SVM params. However, I presume that these params will change, depending on the number of estimators and max_samples used in bagging? Here is my code: svm = OneVsRestClassifier(svm.SVC(kernel='rbf', probability=True, C=4, gamma=0.001, class_weight='balanced')) n_estimators = 30 clf = OneVsRestClassifier(BaggingClassifier(svm, max_samples=0.3, n_estimators=n_estimators, bootstrap=True, n_jobs=5)) clf.fit(x_train, y_train) clf.predict(x_valid) Is it generally best to just use the highest bagging settings feasible (in terms of computation time)? e.g: 200 estimators and 1.0 max_samples?
