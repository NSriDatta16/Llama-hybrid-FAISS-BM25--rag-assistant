[site]: crossvalidated
[post_id]: 568072
[parent_id]: 55691
[tags]: 
A recent article sheds some light on the arbitrariness of $p$ -values; the selection of two thresholds was motivated, at least in part, as a work-around to a dispute over publishing rights. Briefly, Fisher sought to use continuous-valued $p$ -values as a characterization of strength of evidence. But he would not be able to publish accompanying tables to aid in their computation because of a copyright claim. To avoid copyright infringement, Fisher dichotomized $p$ -values into "significant" and "non-significant." This meant he could publish critical values alone, without reproducing the entire tables. An awareness of the history of $p$ -values might help deflate their swollen stature and encourage more judicious use. We were surprised to learn, in the course of writing this article, that the $p cutoff was established as a competitive response to a disagreement over book royalties between two foundational statisticians. In the early 1920s, Kendall Pearson [ sic -- I believe this is a typo for Karl Pearson , a prominent statistician who published mathematical and statistical tables in the 1920s], whose income depended on the sale of extensive statistical tables, was unwilling to allow Ronald A. Fisher to use them in his new book. To work around this barrier, Fisher created a method of inference based on only two values: $p$ -values of 0.05 and 0.01 (Hurlbert and Lombardi, 2009). Fisher himself later admitted that Perason's more continuous method of inference was better than his binary approach: "no scientific worker has a fixed level of significance at which from year to year, and in all circumstances, he rejects [null] hypotheses; he rather gives his mind to each particular case in the light of his evidence and ideas" (Hurlbert and Lombardi, 2009; 316). A fair interpretation of this history is that we use $p$ -values at least in part because a statistician in the 1920s was afraid that sharing his work would undermine his income (Hurlbert and Lombardi, 2009). Following Fisher, we recommend that authors report $p$ -values and refrain from emphasizing thresholds. from Brent Goldfarb and Andrew W. King. "Scientific Apophenia in Strategic Management Research: Significance & Mistaken Inference." Strategic Management Journal , vol. 37, no. 1, Wiley, 2016, pp. 167–76. Now, this passage does not answer the titular question "Why did Fisher choose 0.05 and 0.01 instead of 0.06 or 0.1?" After all, Fisher could have chosen to publish his book using 0.06 and 0.1 in place of 0.05 and 0.01 (or indeed he could have chosen any other probabilities). However, this passage does show that Fisher understood that the choice was arbitrary in its very nature, and that a single threshold for adjudicating all statistical inference is unsuitable. We might imagine a dramatically different statistical practice around hypothesis testing and inference if Fisher were instead able to publish Pearson's statistical tables! And while we're imagining some alternative worlds, we might also explore whether "significance & non-significance" are essential concepts for inference. Null hypothesis testing has no inherent requirement that $\alpha$ be specified, or that the "significant/non-significant" terminology be adopted. Fisher may have been impelled to those conventions, however, not only by historical antecedents but also by a very practical and personal obstacle. Kendall (1963) relates that "He [Fisher] himself told me that when he was writing Statistical Methods for Research Workers he applied to Pearson for permission to reproduce Elderton's tables of chi-squared and that it was refused. This was perhaps not simply a personal matter because the hard struggle which Pearson had for long experienced in obtaining funds for printing and publishing statistical tables had made him most unwilling to grant anyone permission to reproduce. He was afraid of the effect on sales of his Tables for Statisticians and Biometricians [K. Pearson 1914] on which he relied to secure money for further table publication. It seems, however, to have been this refusal which first directed Fisher's thoughts towards the alternative form of tabulation with quantiles as argument, a form which he subsequently adopted for all his tables and which has become common practice." This is what Fisher referred to when eh explained the absence from his book of more extended tables "owing to copyright restrictions" (Fisher 1925: 78, 1958: 79). Fisher did not invent the "significant/non-significant" dichotomy, but his books and novel tabulations of critical values of test statistics played a large role in its rapid and wide dissemination. from Hurlbert, Stuart H., and Celia M. Lombardi. 2009. “Final Collapse of the Neyman-Pearson Decision Theoretic Framework and Rise of the neoFisherian.” Annales Zoologici Fennici 46 (5): 311–49.
