[site]: crossvalidated
[post_id]: 265135
[parent_id]: 264728
[tags]: 
What the paragraph tries to say is that if you do feature selection before (rather than inside) the cross-validation loop, the selected features may perform poorly at test time. The reason for this is that to pre-select features, one typically uses the whole train-val set, but in the subsequent cross-validation step, the same data is used to evaluate the features. The cross-validation scores will therefore overestimate true performance. This effect will be more pronounced if there are many features to choose from, since the chance of many features explaining (correlating with) y on the train-val set is higher. Note that if the features are selected for each cross-validation fold separately, there is no such problem: for each split, one part of the train-val set is used for feature selection & model fitting, and the other part for evaluation.
