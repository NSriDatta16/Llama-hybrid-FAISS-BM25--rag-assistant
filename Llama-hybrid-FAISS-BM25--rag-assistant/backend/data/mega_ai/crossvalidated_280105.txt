[site]: crossvalidated
[post_id]: 280105
[parent_id]: 
[tags]: 
Log marginal likelihood for Gaussian Process

Log marginal likelihood for Gaussian Process as per Rasmussen's Gaussian Processes for Machine Learning equation 2.30 is: $$\log p(y|X) = -\frac{1}{2}y^T(K+\sigma^2_n I)^{-1}y - \frac{1}{2}\log|K+\sigma^2_n I|-\frac{n}{2}\log2\pi$$ Where as Matlab's documentation on Gaussian Process formulates the relation as $$\log p(y|X, \beta, \theta, \sigma^2) = -\frac{1}{2}\left(y-H\beta\right)^T(K+\sigma^2_n I)^{-1}\left(y-H\beta\right) - \frac{1}{2}\log|K+\sigma^2_n I|-\frac{n}{2}\log2\pi$$ where $H$ is the vector of basis functions and $\beta$ is coefficient vector. My doubts: Why there is difference in the two relations? From my understanding, $H\beta$ is prediction from Gaussian Process; am I right? Thanks
