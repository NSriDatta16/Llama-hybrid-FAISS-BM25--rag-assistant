[site]: crossvalidated
[post_id]: 169018
[parent_id]: 169000
[tags]: 
"Goodness of fit" is sometimes used in one sense as the contrary of evident model mis-specification, "lack of fit"; & sometimes in another sense as a model's predictive performance—how well predictions match to observations. The Hosmer–Lemeshow test is for goodness of fit in the first sense, & although evidence of lack of fit suggests predictive performance (GoF in the second sense, measured by say Nagelkerke's $R^2$ or Brier scores) could be improved, you're none the wiser as to how or by how much until you try out specific improvements (typically by including interaction terms, or a spline or polynomial basis for representing continuous predictors to allow for a curvilinear relationship with the logit; sometimes by changing the link). Goodness-of-fit tests are intended to have reasonable power against a variety of alternatives, rather than high power against a specific alternative; so people comparing of the power of different tests tends to take the pragmatic approach of picking a few alternatives that are thought to be of particular interest to potential users (see for example the frequently cited Stephens (1974), "EDF statistics for goodness of fit & some comparisons", JASA, 69 , 347 ). You can't conclude that one test is more powerful than another against all possible alternatives because it's more powerful against some.
