[site]: crossvalidated
[post_id]: 354884
[parent_id]: 354562
[tags]: 
So you have a situation where: Actions do have influence on the immediate, one-step rewards Actions do not have influence on state transitions, so also do not have influence on future returns other than the immediate one-step rewards. This means that you do not have a "standard" Reinforcement Learning problem, you have what's called a Multi-Armed Bandit problem. More specifically, since you do appear to still have some concept of "states" (which I assume may or may not contain somewhat useful information about which actions might be optimal for one-step rewards given the current states), you have a Contextual Multi-Armed Bandit problem (where "states" are more commonly referred to as "context (vectors"). These really are just special cases of the more general Reinforcement Learning setting. Any algorithm that can handle the more typical RL problem can in theory also handle (contextual) MAB problems. They're probably not the best algorithms though. If you try to throw a standard RL algorithm at a MAB problem, the RL algorithm will "think" that it may have influence on state transitions, and therefore "try to learn" (very informal language here) about that too (even if it's impossible/useless). There also are dedicated algorithms for (contextual) MAB problems. These do not waste any learning effort trying to learn about state transitions which they have no influence over anyway, they just try to learn about the reward distributions per arm (= action) given the current context (= state). As for which variables you should include in your observation space, I'd recommend including as many observable variables as possible if there's a chance that they're somewhat informative, at least if that doesn't lead to computational problems for you. Forgetting to include an informative feature tends to be much more harmful than accidentally adding an uninformative (for example, random) feature. This is just what tends to be my experience, it's impossible to tell for sure for any specific situation. If you want to be sure, try different alternatives and evaluate performance for your specific case.
