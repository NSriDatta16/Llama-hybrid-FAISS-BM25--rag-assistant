[site]: crossvalidated
[post_id]: 139203
[parent_id]: 
[tags]: 
Cross-validation for parameter tuning in data mining process (KDD)

In my project I want to compare different classification algorithms to solve a specific problem with a specific dataset. To do this, I divided the dataset in 2 parts. With the first (bigger) part I am doing cross validation. In this step I try to find out the best parameters for each algorithm (for example the number of neurons in the hidden layer of a neural network), as well as search for the best threshold for the classification. I use the second part of the dataset to evaluate and compare the algorithms, using the parameters found on the previously step. My question: How these two steps (parameter tunning and generalization test) can be mapped in a data mining process (KDD, SEMMA or CRISP-DM)? Should the two steps be two different iteration of the process or perhaps each step should be a different project/process (with the initial stages in common)?
