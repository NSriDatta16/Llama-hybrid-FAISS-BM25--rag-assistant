[site]: stackoverflow
[post_id]: 4967158
[parent_id]: 
[tags]: 
Opinions on my data storage problem (database/homebrew solution)

I have very simply structured data which is currently stored in a home-brew file format, but I am wondering whether we should migrate to something more modern. The data is simply a table of double s, indexed by a double column. The things I need to perform are: Iterating through the table. Insertion and deletion of arbitrary records. Selecting a given number of rows before and after a given key value (where the key might not be in the database). The requirements are: The storage must be file-based without a server. It should not be necessary to read the whole file into memory. The resulting file should be portable between different architectures (wrt endian-ness...) Must be a very stable project (the data is highly critical). Must run on Solaris/SPARC and preferably also on Linux/x64. Access times should be as fast as possible. Must be available as a C++ library. Bonus points for Fortran and Python bindings :) Optional higher precision number representation than double precision would be a bonus. Relatively compact storage size would also be a bonus. From my limited experience, sqlite would be an interesting choice, or perhaps mysql in a non-server mode if sqlite is not fast enough. But perhaps a full-fledged SQL database is overkill? What do you suggest?
