[site]: crossvalidated
[post_id]: 322511
[parent_id]: 
[tags]: 
Machine learning on small datasets

As a beginner at machine learning, I wanted to work on a small project in which the dataset has only 80 rows and 5 columns. The dataset I am working with is related to a medical condition, with 4 columns as biomarkers, and the 5th column indicates whether the row (a patient) has the condition or not. So far, I have fitted the following 5 models (with accuracy and MCC scores): KNN (Accuracy: 43.5%, MCC:-0.164) Logistic Regression (Accuracy: 65.2%, MCC: .312) SVM (Accuracy: 60.9%, MCC: .214 Random Forest (Accuracy: 86.95%, MCC: .769) Decision trees (Accuracy: 65.2%, MCC: .312) I have used 5-fold cross validation to prevent overfitting, and yet most of my models are underperforming. I was also considering ensembling and bootstrapping, but with these lacking results, I am not sure how effective they would be. Do you have any tips concerning either: Better algorithms for small datasets Improvements I could make on the algorithms I have so far Another method (e. g. regularization) Any help would be greatly appreciated.
