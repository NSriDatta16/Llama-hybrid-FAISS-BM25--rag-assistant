[site]: datascience
[post_id]: 111208
[parent_id]: 111189
[tags]: 
First, there is nothing wrong with asking such question. Second, the most straightforward way to select an optimal preprocessing step (whether it is an imputation or something else) is to use a validation set. Split your dataset into 3 parts: training (train the model, estimate model parameters, e.g. weights of a linear regression), validation (compare different models, e.g., one with one data imputation strategy and another with another imputation strategy), and test (this always exists for you to check if you messed up somewhere miserably). If you have drastically different results on validation and test sets, it means that most likely you overfit. If you are interested on selecting an optimal imputation technique your models should only differ in this particular step (everything else should be the same). In this case the model with the best validation score will be the one with the optimal imputation. PS In most real settings you do not want to use any imputation and instead you want to encode the fact that the value is missing (most of the advance implementations, e.g. xgboost are doing this job for you).
