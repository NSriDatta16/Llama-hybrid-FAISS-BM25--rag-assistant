[site]: crossvalidated
[post_id]: 538855
[parent_id]: 
[tags]: 
Correct or most common term for altering a loss function to ignore unlabelled pixels?

In my experience it is quite commonplace to alter the loss function used when training a neural network for segmentation to ignore the contribution to the loss of unlabelled pixels. There are a few ways to implement it, but the one I have used prior is to alter network predictions to always predict truly unlabelled pixels correctly. In psuedo-code predicted[where(labels == unlabelled)] = unlabelled Is there a common, or most common, term for this? I am attempting to add the technique itself as part of a literature review, though I can't find any examples which "directly" reference the technique. I can really only find articles that use the technique, but really make no mention of it.
