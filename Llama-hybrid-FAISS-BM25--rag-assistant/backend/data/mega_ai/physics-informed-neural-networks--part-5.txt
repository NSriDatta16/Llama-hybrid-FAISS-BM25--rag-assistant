chastic differential equation (BSDE) to solve high-dimensional problems in financial mathematics. By leveraging the powerful function approximation capabilities of deep neural networks, deep BSDE addresses the computational challenges faced by traditional numerical methods like finite difference methods or Monte Carlo simulations, which struggle with the curse of dimensionality. Deep BSDE methods use neural networks to approximate solutions of high-dimensional partial differential equations (PDEs), effectively reducing the computational burden. Additionally, integrating Physics-informed neural networks (PINNs) into the deep BSDE framework enhances its capability by embedding the underlying physical laws into the neural network architecture, ensuring solutions adhere to governing stochastic differential equations, resulting in more accurate and reliable solutions. Physics-informed neural networks for biology An extension or adaptation of PINNs are Biologically-informed neural networks (BINNs). BINNs introduce two key adaptations to the typical PINN framework: (i) the mechanistic terms of the governing PDE are replaced by neural networks, and (ii) the loss function L t o t {\displaystyle L_{tot}} is modified to include L c o n s t r {\displaystyle L_{constr}} , a term used to incorporate domain-specific knowledge that helps enforce biological applicability. For (i), this adaptation has the advantage of relaxing the need to specify the governing differential equation a priori, either explicitly or by using a library of candidate terms. Additionally, this approach circumvents the potential issue of misspecifying regularization terms in stricter theory-informed cases. A natural example of BINNs can be found in cell dynamics, where the cell density u ( x , t ) {\displaystyle u(x,t)} is governed by a reaction-diffusion equation with diffusion and growth functions D ( u ) {\displaystyle D(u)} and G ( u ) {\displaystyle G(u)} , respectively: u t = ∇ ⋅ ( D ( u ) ∇ u ) + G ( u ) u , x ∈ Ω , t ∈ [ 0 , T ] {\displaystyle u_{t}=\nabla \cdot (D(u)\nabla u)+G(u)u,\quad x\in \Omega ,\quad t\in [0,T]} In this case, a component of L c o n s t r {\displaystyle L_{constr}} could be | | D | | Γ {\displaystyle ||D||_{\Gamma }} for D < D m i n , D > D m a x {\displaystyle D<D_{min},D>D_{max}} , which penalizes values of D {\displaystyle D} that fall outside a biologically relevant diffusion range defined by D m i n ≤ D ≤ D m a x {\displaystyle D_{min}\leq D\leq D_{max}} . Furthermore, the BINN architecture, when utilizing multilayer-perceptrons (MLPs), would function as follows: an MLP is used to construct u M L P ( x , t ) {\displaystyle u_{MLP}(x,t)} from model inputs ( x , t ) {\displaystyle (x,t)} , serving as a surrogate model for the cell density u ( x , t ) {\displaystyle u(x,t)} . This surrogate is then fed into the two additional MLPs, D M L P ( u M L P ) {\displaystyle D_{MLP}(u_{MLP})} and G M L P ( u M L P ) {\displaystyle G_{MLP}(u_{MLP})} , which model the diffusion and growth functions. Automatic differentiation can then be applied to compute the necessary derivatives of u M L P {\displaystyle u_{MLP}} , D M L P {\displaystyle D_{MLP}} and G M L P {\displaystyle G_{MLP}} to form the governing reaction-diffusion equation. Note that since u M L P {\displaystyle u_{MLP}} is a surrogate for the cell density, it may contain errors, particularly in regions where the PDE is not fully satisfied. Therefore, the reaction-diffusion equation may be solved numerically, for instance using a method-of-lines approach. Limitations Translation and discontinuous behavior are hard to approximate using PINNs. They fail when solving differential equations with slight advective dominance and hence asymptotic behaviour causes the method to fail. Such PDEs could be solved by scaling variables. This difficulty in training of PINNs in advection-dominated PDEs can be explained by the Kolmogorov n–width of the solution. They also fail to solve a system of dynamica