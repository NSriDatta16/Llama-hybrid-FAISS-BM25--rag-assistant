[site]: datascience
[post_id]: 87773
[parent_id]: 
[tags]: 
Tuning the model parameters vs the parameter of optimizer for Deep Neural Networks?

I understand that there are rarely general recipes in field of machine learning and the many results can be achieved only by trial and error, and are task specific as well. My question is, if the model doesn't give a desired quality, but one may expect, that the model of this or similar architecture can achieve a reasonable result, based on some prior assumptions or knowledge, what is, in general, better strategy, more successful in majority cases: Tuning of the optimizer parameters of the optimizer. (playing with the learning rates, random seeds, weight decay, momentum, e.t.c). hoping that it converges to the better optimum Changing some architecture properties of the model (number of hidden layers, dropout rate, width, number of filters in CNN) Here I assume, that the current network is sensible choice - not 1-hidden layer narrow MLP - for solving some complicated task. Minimization of loss function doesn't always lead to improvement of the quality of the model on the test data (well known problem of overfitting), but here let us assume, that one has lot enough data, and the training and test set are organized in a such way, that good score on the training examples would also lead to good accuracy on the test data.
