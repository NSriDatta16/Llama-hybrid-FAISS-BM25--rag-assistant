[site]: crossvalidated
[post_id]: 261523
[parent_id]: 261515
[tags]: 
One of the most successful applications using LSTM (Long Short-Term Memory) for a time series dataset is speech recognition. Over the last few years, all major speech recognition engines (Dragon Professional Individual, Amazon Alexa, Baidu speech recognition, Microsoft speech recognition, Google, etc.) have switched to neural networks (LSTM most of the time, if not all the time, or close variants). Example from {1}: When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score. Example from {2}: As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. References: {1} Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. "Speech recognition with deep recurrent neural networks." In Acoustics, speech and signal processing (icassp), 2013 ieee international conference on, pp. 6645-6649. IEEE, 2013. http://ieeexplore.ieee.org/abstract/document/6638947/ ; https://scholar.google.com/scholar?cluster=9041586046771167211&hl=en&as_sdt=0,22 {2} Amodei, Dario, Rishita Anubhai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Jingdong Chen et al. "Deep speech 2: End-to-end speech recognition in english and mandarin." arXiv preprint arXiv:1512.02595 (2015). https://scholar.google.com/scholar?cluster=12481730786670563937&hl=en&as_sdt=0,22 ; https://pdfs.semanticscholar.org/c2ba/9d550bbfb542e9fdd6e817e9be15585d0f47.pdf ; https://arxiv.org/abs/1512.02595
