[site]: stackoverflow
[post_id]: 4672476
[parent_id]: 
[tags]: 
SQL Server NUMERIC/DECIMAL precision vs storage

Considering what MSDN states regarding SQL Server 2008 R2 storage of NUMERIC/DECIMAL precision. Precision of 1 to 9 is 5 bytes Precision of 10 to 19 is 9 bytes So if my business case logically requires a data type with 2 decimal places and a precision of 5 digits it makes no actual performance or storage difference if I define it as NUMERIC(5, 2) or NUMERIC(9, 2) . One considering I'm intentionally ignoring is the implied check constraint as I'd most likely put an actual check constraint on the column limiting the actual allowed range. Does this make a difference when it comes to indexes, query performance or any other aspect of the system?
