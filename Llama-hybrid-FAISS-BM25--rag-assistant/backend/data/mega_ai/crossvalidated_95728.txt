[site]: crossvalidated
[post_id]: 95728
[parent_id]: 95271
[tags]: 
kmeans for quantization makes a lot of sense, as this example demonstrates. There are some other, more sophisticated, techniques for finding a sparse representation of the data, such that the distortion is minimized. In the context of machine learning it is usually called dictionary learning. In the context of signal processing this is called vector quantization. There are other options based on information theory where the idea is to choose a quantization scheme such that is consistent with the Bayesian Model in use. A well-known paper is "Discretizing Continuous Attributes While Learning Bayesian Networks"
