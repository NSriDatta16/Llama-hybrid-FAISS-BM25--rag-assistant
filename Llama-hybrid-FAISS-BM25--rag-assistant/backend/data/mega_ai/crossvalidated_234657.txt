[site]: crossvalidated
[post_id]: 234657
[parent_id]: 
[tags]: 
In general, is doing inference more difficult than making prediction?

My question comes from the following fact. I have been reading posts, blogs, lectures as well as books on machine learning. My impression is that machine learning practitioners seem to be indifferent to many things that statisticians/econometrics care about. In particular, machine learning practitioners emphasize prediction accuracy over inference. One such example occurred when I was taking Andrew Ng's Machine Learning on Coursera. When he discusses Simple Linear Model, he mentioned nothing about the BLUE property of the estimators, or how heteroskedasticity would "invalidate" confidence interval. Instead, he focuses on gradient descent implementation and the concept of cross validation/ROC curve. These topics were not covered in my econometrics/statistics classes. Another example occurred when I participated in Kaggle competitions. I was reading other people's code and thoughts. A large part of the participants just throw everything into SVM/random forest/XGBoost. Yet another example is about stepwise model selection. This technique is widely used, at least online and on Kaggle. Many classical machine learning textbooks also cover it, such as Introduction to Statistical Learning. However, according to this answer (which is quite convincing), stepwise model selection faces lots of problem especially when it comes down to "discovering the true model". It seems to be that there are only two possibilities: either machine learning practitioners do not know the problem with stepwise, or they do but they do not care. So here are my questions: Is it true that (in general) machine learning practitioners focus on prediction and thus do not care about a lot of things which statisticians/economists care about? If it is true, then what is the reason behind it? Is it because inference is more difficult in some sense? There are tons of materials on machine learning (or prediction) online. If I am interested in learning about doing inference, however, what are some resources online that I can consult? Update : I just realized that the word "inference" could potentially mean lots of stuff. What I meant by "inference" refers to questions such as Did $X$ cause $Y$ or $Y$ caused $X$? Or more generally, what's the causal relations among $X_1,X_2,\cdots,X_n$? Since "all models are wrong", how "wrong" is our model from the true model? Given the information of a sample, what can we say about the population and how confident can we say that? Due to my very limited statistics knowledge, I am not even sure whether those questions fall into the realm of statistics or not. But those are the types of questions which machine learning practitioners do not seem to care about. Perhaps statisticians do not care neither? I don't know.
