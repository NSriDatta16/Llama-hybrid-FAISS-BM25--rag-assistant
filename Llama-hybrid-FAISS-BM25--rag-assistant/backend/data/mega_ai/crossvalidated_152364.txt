[site]: crossvalidated
[post_id]: 152364
[parent_id]: 
[tags]: 
Manually adjusting (stretching) a random forest regressor model

So I have a random forest model (sklearn) fitted to about 3000 data points. It has a poor OOB score (0.3) but it's not completely surprising due to the data set being social media based. The interesting thing I noticed though was that when I plotted the OOB predictions against the actual data, it was fitted fairly linearly, but along a more inclined plane (about a slope of 1.5-2) - basically my model could predict moderate data points fairly well, but couldn't predict any scores at all below a certain threshold, and was really shoddy at the upper bounds. I was wondering if it's possible to add some parameter manually to the random forest model to 'stretch' it, so to speak - basically bring low end predictions closer to 0 and bring high end predictions closer to the max. I know I could chalk it up to outliers and remove them in preprocessing, but the low values aren't really sparse enough to call them outliers. I've ran a grid search multiple times and i've only ever seen minimal improvements. I imagine I could add variable weights, but I'm confused how to that when it comes to sklearn's implementation and it's variable importance output.
