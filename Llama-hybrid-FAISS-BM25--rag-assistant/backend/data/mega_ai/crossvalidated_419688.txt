[site]: crossvalidated
[post_id]: 419688
[parent_id]: 
[tags]: 
Neural Network doesn't learn beyond a specific level, loss doesn't go lower than 0.12

I have a simple shallow neural network with 18 inputs(feature selected from a total of 45) and 400 samples. Keras Implementation: model = Sequential() model.add(Dense(103,input_shape=(18,), activation='relu')) model.add(Dense(73, activation='relu')) model.add(Dense(33, activation='relu')) model.add(Dense(1, activation='sigmoid')) model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics = ['accuracy', precision_m, recall_m, f1_m]) Training loss: 0.12297805808484555 Training accuracy: 0.975 Training precision: 0.9733918130397796 Training recall: 0.9833333313465118 Training f1: 0.9782239258289337 My neural network however I change its number of layers, units in each layer, weight initializers, activation functions, training epochs, learning rate doesn't budge any lower from this value. Insights for solving this needed, please because with this classifier I get a lot of false positives
