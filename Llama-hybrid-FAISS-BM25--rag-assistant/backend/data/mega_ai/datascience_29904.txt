[site]: datascience
[post_id]: 29904
[parent_id]: 
[tags]: 
tuning a convolution neural net, sample size

I keep reading that convolution neural net (CNN) performs best with lots and lots (100k+) of data. Is there any rule of thumb, or lower limit for data size during the grid search phase? For example, if I run a CNN with 100 data points, vary just one parameter (say add an extra layer, or increase a filter size), and get better results, can I reasonably expect better results with those parameters during the actual training phase?
