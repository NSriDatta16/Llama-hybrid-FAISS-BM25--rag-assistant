[site]: stackoverflow
[post_id]: 3745345
[parent_id]: 3745068
[tags]: 
Since there are 600 M records, it seems to be large enough to leverage a database (and not too large to require a distributed Database). So, you could simply load this into a DB (MySQL, SQLServer, Oracle, etc) and run the following queries: select calling_party, called_party, sum(call_duration), avg(call_duration), min(call_duration), max (call_duration), count(*) from call_log group by calling_party, called_party order by 7 desc That would be a start. Next, you would want to run some Association analysis (possibly using Weka), or perhaps you would want to analyze this information as cubes (possibly using Mondrian/OLAP). If you tell us more, we can help you more. Algorithmically, what the DB is doing internally is similar to what you would do yourself programmatically: Scan each record Find the record for each (calling_party, called_party) combination, and update its stats. A good way to store and find records for (calling_party, called_party) would be to use a hashfunction and to find the matching record from the bucket. Althought it may be tempting to create a two dimensional array for (calling_party, called_party), that will he a very sparse array (very wasteful).
