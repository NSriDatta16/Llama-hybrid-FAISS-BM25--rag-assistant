[site]: datascience
[post_id]: 122429
[parent_id]: 
[tags]: 
How do I test with custom images for a model that was trained on quick draw npy dataset

I have been trying to test my CNN model on a custom doodle of an apple that I drew. But even when I preprocess the image to have the same shape with the training data, the model gives wrong prediction even though it had good training and testing accuracy. (The model was trained on 100 classes of quick draw npy dataset) Code to get data: !wget https://raw.githubusercontent.com/FreeBirdsCrew/Google_QuickDraw_Implementation/master/mini_classes.txt with open("mini_classes.txt", "r") as f: classes = f.readlines() classes = [c.replace("\n", "") for c in classes] import urllib def download_data(): base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/' for c in classes: cls_url = c.replace('_', '%20') path = base + cls_url + '.npy' print(path) urllib.request.urlretrieve(path, 'data/' + c + '.npy') # npy files are stored inside data folder download_data() Code to load data: def load_data(root, vfold_ratio=0.2, max_items_per_class=5000): all_files = glob.glob(os.path.join(root, '*.npy')) #initialize variables x = np.empty([0, 784]) y = np.empty([0]) class_names = [] #load each data file for idx, file in enumerate(all_files): data = np.load(file) data = data[0: max_items_per_class, :] labels = np.full(data.shape[0], idx) x = np.concatenate((x, data), axis=0) y = np.append(y, labels) class_name, ext = os.path.splitext(os.path.basename(file)) class_names.append(class_name) data = None labels = None #randomize the dataset permutation = np.random.permutation(y.shape[0]) x = x[permutation, :] y = y[permutation] #separate into training and testing vfold_size = int(x.shape[0]/100*(vfold_ratio*100)) x_test = x[0:vfold_size, :] y_test = y[0:vfold_size] x_train = x[vfold_size:x.shape[0], :] y_train = y[vfold_size:y.shape[0]] return x_train, y_train, x_test, y_test, class_names x_train, y_train, x_test, y_test, class_names = load_data("data", max_items_per_class=8000) num_classes = len(class_names) Preprocessing code for training data: x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32') / 255.0 x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32') / 255.0 y_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes) y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes) Preprocessing code for custom image: def preprocess(image_path): img = PIL.Image.open(image_path).convert('L').resize((28, 28)) img = 1 - np.asarray(img) / 255 preproc_img = np.expand_dims(img, axis=2) preproc_img = np.expand_dims(preproc_img, axis=0) plt.gray() plt.imshow(img) return preproc_img Code for the model model = Sequential([ Conv2D(128, 3, input_shape=(28, 28, 1), activation='relu', padding='same', kernel_regularizer=l2(0.001)), BatchNormalization(), MaxPool2D(), Conv2D(256, 3, activation='relu', padding='same', kernel_regularizer=l2(0.001)), BatchNormalization(), MaxPool2D(), Conv2D(512, 3, activation='relu', padding='same', kernel_regularizer=l2(0.001)), BatchNormalization(), MaxPool2D(), Conv2D(1024, 3, activation='relu', padding='same', kernel_regularizer=l2(0.001)), BatchNormalization(), MaxPool2D(), GlobalMaxPooling2D(), Flatten(), Dense(1024, activation='relu', kernel_regularizer=l2(0.001)), Dropout(0.5), Dense(1024, activation='relu', kernel_regularizer=l2(0.001)), Dropout(0.5), Dense(num_classes, activation='softmax')]) model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['top_k_categorical_accuracy']) rlronp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1) estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True) history_22 = model_24.fit(x=x_train, y=y_train_onehot, epochs=50, validation_split=0.1, batch_size=256, callbacks=[rlronp, estop]) The shape of the preproc_img has to be (1, 28, 28, 1), the same shape as one sample of the training. Why is the model giving incorrect? This is the doodle that I drew
