[site]: crossvalidated
[post_id]: 263816
[parent_id]: 263768
[tags]: 
To find out more about classification in general, take a look at https://en.wikipedia.org/wiki/Perceptron and https://en.wikipedia.org/wiki/Linear_classifier , for example. Answering the question, firstly, a classifier does not need to be able to represent any complex function to be considered non-linear. An example is a quadratic classifier (wiki/Quadratic_classifier), which is a polynomial function of degree 2. We can have infinitely many further examples as polynomial classifiers of degree n, n goes from 3 to infinity. Secondly, no, changing activation function to sigmoid doesn't help if we consider a classical setup. In fact, sigmoid activation function wouldn't even make a sensible classifier. In classical setup the output of perceptron is either -1 or +1, +1 representing Class 1 , and -1 representing Class 2 . If you changed activation function to sigmoid, you would no longer have an interpretable output. (Now, of course, you can apply a step function after sigmoid, but if you think about it, it is the same as using only the step function) Clarifying the connection to the broncoAbierto answer, a composition of arbitrarily many perceptrons with sigmoid activation (i.e., a neural network) indeed is a non-linear classifier. Moreover, it can approximate any complex function. A single perceptron, however, doesn't have any of these properties.
