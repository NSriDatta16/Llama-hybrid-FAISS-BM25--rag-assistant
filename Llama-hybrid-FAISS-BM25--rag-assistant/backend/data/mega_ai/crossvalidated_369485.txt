[site]: crossvalidated
[post_id]: 369485
[parent_id]: 
[tags]: 
activation function for neural network in R

While creating a neural network in R, is it important to normalize the input data based on activation function? For Example - if the activation function is tanh input data should range from -1 to 1 and for sigmoid activation 0 to 1.
