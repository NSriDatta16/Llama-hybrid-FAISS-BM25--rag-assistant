[site]: datascience
[post_id]: 57620
[parent_id]: 39836
[tags]: 
In general, No, CNNs are not scale-invariant . The proof for this is simple: The maximum receptive field for a convolutional network is always fixed and finite, and it is a function of the network's depth, the number and rate of downsampling layers, and of the kernel sizes and strides. All one has to do is give an input that is scaled to exceed the network's maximum receptive field, and you will arrive at a point at which it will not be able to identify the object robustly. Try tinkering with the Receptive Field Calculator here to see some concrete and interactive examples. Since the receptive field is always bounded, the ability of a CNN to match objects is limited to a pixel-space scale comparable to the maximum theoretical receptive field size. Beside the receptive field matter, the behavior of a network that is trained at one scale and tested at another is generally not well-defined. Don't expect it to work. Many papers on recognition tasks improve performance by making the scale of inputs more attuned to the scale expected by the network. This is a key to the success of Spatial Transformer Networks .
