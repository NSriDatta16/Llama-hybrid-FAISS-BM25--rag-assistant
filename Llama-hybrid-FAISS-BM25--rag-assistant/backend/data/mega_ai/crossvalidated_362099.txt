[site]: crossvalidated
[post_id]: 362099
[parent_id]: 
[tags]: 
nmf in scipy returns components with all zero weights

I'm trying to understand whether this behavior is a bug or a feature. Essentially, I have a dataset of ten thousand short pieces of text. I have used the CountVectorizer function to turn this into a term-document matrix, and also converted the raw counts to tf-idf scores using TfidfTransformer. I've then used the NMF function to perform a non negative matrix factorization, as below: nmf = NMF(n_components=100, random_state=1, alpha=.1, l1_ratio=.5) When I do this with 50 components, the output looks fine. But when I use 100 components, I get a number of components spread throughout the 100 that simply have a 0 weight for every feature (in this case, a word). Now, I know NMF uses a stochastic and iterative optimizer, and I believe it potentially uses some regularisation - so are these zero-weighted topics just indicating that the data suggests less than 100 topics? Or is this a failure of the algorithm, or bug in my code?
