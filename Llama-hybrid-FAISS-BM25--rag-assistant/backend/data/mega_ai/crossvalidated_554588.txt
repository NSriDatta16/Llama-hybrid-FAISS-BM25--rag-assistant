[site]: crossvalidated
[post_id]: 554588
[parent_id]: 386716
[tags]: 
@Sycorax answer is what comes the closest to the answer. Usually, overfitting is described as the model training error going down while validation error goes up, which means the model is learning patterns that don't generalize beyond the training set. In the case of an autoencoder, you're training the model to reproduce the input. At an extreme your model could simply be output = input and both validation and training loss would be 0. But that's not what you want from an autoencoder for anomaly detection. You want the model to learn an abstract representation of what the input should look like, so the model develop the ability to generate instances on it's own when presented with an input. The distance or error between what the model "think it should look like" and the input is what tells us if the input is "abnormal" or not. Best way to assess it would be to present the model with valid and invalid instances and monitor the reconstruction error. If it tends to be the same on both set your model is most probably learning the identity function and needs to be modified.
