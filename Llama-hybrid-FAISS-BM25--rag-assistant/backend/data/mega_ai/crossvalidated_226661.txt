[site]: crossvalidated
[post_id]: 226661
[parent_id]: 
[tags]: 
Regression. Interaction term correlated with the variables

Before fitting a multivariable regression model it's common to check if the predictors are correlated. That can be done viewing the correlation matrix, at least for linear effects. Simple least squares regression needs that the predictor variables are independent. We could tolerate small correlations but the problem gets serious if the variables are perfectly collinear. It's common to drop some of the correlated variables, keeping the most meaningful. More complex alternative methods such as PCA o Ridge regression exist. But here is my question: If your model include interactions that interactions use to be very correlated with other variables. For example in $F=a+b·X+c·Y+d·X·Y$ $X·Y$ is likely to be very correlated with $X$ and $Y$. If my model has an interaction term (and it's statistically significant and important for me) but it's very correlated with some variables... Should I drop it or keep it? If I keep it I will be violating the regression condition of non-correlated terms.
