[site]: crossvalidated
[post_id]: 147312
[parent_id]: 
[tags]: 
Wilcoxon signed rank test - Normalize data or not?

I am comparing my algorithm's performance with other algorithms, for a minimization problem. There are ten different benchmark problems, for which I have computed the average solution quality for all the algorithms. For comparison, I need to know whether my result is statistically different(better) than others. For this I have applied Wilcoxon signed-rank test , as I have only ten paired values. But the problem is the benchmark problems are of different size. So, for the problems that are large, the difference is also are large, and as the signed rank test gives higher rank to higher differences. Almost always the bigger problems are being assigned with the higher rank, and thus the results are biased towards the larger problem instances. So, I normalized all the values(with Z-Score normalization) and than applied the signed rank test on the z-scores. This is how I am trying to nullify the bias towards higher values. Is this approach ok ? Thanks in advance. I will be highly obliged if someone can enlighten me, possibly with some reference. *I computed the Z-Score by first taking the mean and SD for all the algorithm for a particular problem. Then for each algorithm I computed their z-score by (algo_result-mean)/SD What I mean about Large problems and the bias: This a optimization problem, similar to TSP. By Large problem I mean, a problem (Problem A) having 400 nodes is large, compared to a problem (Problem B) having only 50 nodes. Now, typically the solution costs will be around 8 times larger for Problem A than B. Say, if the good solutions(near optimal) for Problem B is around 500 than the good solutions to Problem A will be of range 4000. Now about the bias: Say Algorithm 1 has average results 4100 and 600 for Problem A and B respectively. And Algorithm 2 finds results of range 4040 and 640 respectively. For problem A the difference is 60 while, for problem B its 40. While comparing, the test will provide higher rank to the difference of 60, though the deviation of the two algorithm is just 60/4070 = 1.5%. Whereas, for problem B the deviation of the two algorithm is 40/620=6.5% Though, the test will assign the difference 40 with a lower rank. Thus wilcoxon signed rank test is showing a bias towards higher values.
