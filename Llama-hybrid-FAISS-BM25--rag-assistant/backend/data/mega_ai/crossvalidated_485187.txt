[site]: crossvalidated
[post_id]: 485187
[parent_id]: 
[tags]: 
Intuition behind Thompson Sampling in Reinforcement Learning

I am trying to get intuition for solving bandit problem using Thompson Sampling in Reinforcement Learning. I understand following: Beta distribution and effect of alpha and beta params on it Thompson Sampling algorithm. I am referring to algo given here To explain my question/thoughts, lets consider below scenario: Consider there are 2 bandits, one has 90% chance of wining (bandit A) and other has 90% chance of loosing (bandit B). Initially we start with uniform distribution for alpha and beta. As a bandit sees more examples, it becomes skinnier and taller. In every trial, we select a bandit which has higher value for sample chosen from its beta distribution . Taller the distribution for a bandit, higher are its chances of getting selected next time. Distribution would become taller even in case when beta value increase s i.e. we consistently loose. One of the below 2 might happen as a result of random selection: 'B' might get skinnier and taller hugging towards 0. (due to point 5 above) 'A' might get skinnier and taller hugging towards 1. This would imply that we are selecting B, despite of knowing the empirical evidence that there are high chances of loosing when selecting B.
