[site]: crossvalidated
[post_id]: 328496
[parent_id]: 328473
[tags]: 
Yes, you can cut sequences as you want, provided that enough information is kept. In your case, model needs to learn 1-step dependency, so for example you can include X = [A, B] related with Y = [B, C] in your training set. Remark: For time series with long dependence, you need to keep long sequences. In this case training is usually done through stateful LSTM (for example X=[0, 0, ... 0] related with Y = 0, and X=[1, 0, ..., 0] leading to Y=1, as described in http://philipperemy.github.io/keras-stateful-lstm/ )
