[site]: crossvalidated
[post_id]: 362661
[parent_id]: 28608
[tags]: 
Such improvements matter if you want to publish or win a Kaggle competition, but are less important for practical applications. Obviously, more accurate is better, so if you can use something that is more accurate, better for you. But, first, there are implementation costs, for example, Netflix didn't use the algorithm that won their competition and stayed with less accurate, simpler one because the change wasn't worth the additional costs. Second, the fact that some algorithm, trained on some particular training set has achieved some result on a particular test set does not mean that it will do the same for any dataset, or even that the performance won't change over time. Moreover, there is ongoing debate if the algorithms described in the literature aren't overfitting to the test sets that are used by everyone (see Recht et al, arXiv:1806.00451 ). So usually you won't re-design your machine learning pipeline just because the "better" algorithm was described in the literature. On another hand, you may still consider testing it, or it may inspire some improvements in ongoing or future projects, but only after assessing the cost-effectiveness (where cost is time, computational resources needed etc).
