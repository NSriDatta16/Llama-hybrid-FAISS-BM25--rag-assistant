[site]: datascience
[post_id]: 114587
[parent_id]: 75295
[tags]: 
The previous answer is good, and it seems like you are computing pairwise cosine similarity, if it is the case, it's better to use : F.normalise instead of dividing directly with norm. The full answer is : import torch from torch import nn from matplotlib import pyplot as plt import seaborn as sn import torch.nn.functional as F class NPairsLoss(nn.Module): """ The N-Pairs Loss. It measures the loss given predicted tensors x1, x2 both with shape [batch_size, hidden_size], and target tensor y which is the identity matrix with shape [batch_size, batch_size]. """ def __init__(self): super(NPairsLoss, self).__init__() self.ce = nn.CrossEntropyLoss() def show(self, similarity_scores): sn.heatmap(similarity_scores.detach().numpy(), annot=True, annot_kws={'size': 7}, vmin=-1.0, vmax=1.0) plt.show() def similarities(self, x1, x2): """ Calculates the cosine similarity matrix for every pair (i, j), where i is an embedding from x1 and j is another embedding from x2. :param x1: a tensors with shape [batch_size, hidden_size]. :param x2: a tensors with shape [batch_size, hidden_size]. :return: the cosine similarity matrix with shape [batch_size, batch_size]. """ x1 = F.normalise(x1, dim=1) x2 = F.normalise(x2, dim=1) return torch.matmul(x1, x2.t()) def forward(self, predict, target): """ Computes the N-Pairs Loss between the target and predictions. :param predict: the prediction of the model, Contains the batches x1 (image embeddings) and x2 (description embeddings). :param target: the identity matrix with shape [batch_size, batch_size]. :return: N-Pairs Loss value. """ x1, x2 = predict predict = self.similarities(x1, x2) self.show(predict) # by construction the probability distribution must be concentrated on the diagonal of the similarities matrix. # so, Cross Entropy can be used to measure the loss. return self.ce(predict, target) Another way to do this is by using correlation matrix instead of cosine (from Barlow Twins Loss Function) : import torch import torch.distributed as dist def correlation_loss_func( z1: torch.Tensor, z2: torch.Tensor, lamb: float = 5e-3, scale_loss: float = 0.025 ) -> torch.Tensor: """Computes Correlation loss given batch of projected features z1 from view 1 and projected features z2 from view 2. Args: z1 (torch.Tensor): NxD Tensor containing projected features from view 1. z2 (torch.Tensor): NxD Tensor containing projected features from view 2. lamb (float, optional): off-diagonal scaling factor for the cross-covariance matrix. Defaults to 5e-3. scale_loss (float, optional): final scaling factor of the loss. Defaults to 0.025. Returns: torch.Tensor: Correlation Loss. """ N, D = z1.size() # to match the original code bn = torch.nn.BatchNorm1d(N, affine=False).to(z1.device) z1 = bn(z1.T).T z2 = bn(z2.T).T corr = (z1 @ z2.T) / N if dist.is_available() and dist.is_initialized(): dist.all_reduce(corr) world_size = dist.get_world_size() corr /= world_size diag = torch.eye(N, device=corr.device) # if you want invariance between views cdif = (corr - diag).pow(2) cdif[~diag.bool()] *= lamb loss = scale_loss * cdif.sum() return loss ```
