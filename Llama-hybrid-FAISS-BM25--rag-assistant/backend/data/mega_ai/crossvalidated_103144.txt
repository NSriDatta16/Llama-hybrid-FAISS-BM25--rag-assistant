[site]: crossvalidated
[post_id]: 103144
[parent_id]: 97777
[tags]: 
The point here is that in cv.glmnet the K folds ("parts") are picked randomly. In K-folds cross validation the dataset is divided in $K$ parts, and $K-1$ parts are used to predict the K-th part (this is done $K$ times, using a different $K$ part each time). This is done for all the lambdas, and the lambda.min is the one that gives the smallest cross validation error. This is why when you use $nfolds = n$ the results don't change: each group is made of one, so no much choice for the $K$ groups. From the cv.glmnet() reference manual: Note also that the results of cv.glmnet are random, since the folds are selected at random. Users can reduce this randomness by running cv.glmnet many times, and averaging the error curves. ### cycle for doing 100 cross validations ### and take the average of the mean error curves ### initialize vector for final data.frame with Mean Standard Errors MSEs MSEs is the data frame containing all the errors for all lambdas (for the 100 runs), lambda.min is your lambda with minimum average error.
