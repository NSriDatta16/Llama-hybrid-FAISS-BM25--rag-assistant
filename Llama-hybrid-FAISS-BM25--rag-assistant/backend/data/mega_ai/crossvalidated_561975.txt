[site]: crossvalidated
[post_id]: 561975
[parent_id]: 561940
[tags]: 
If a neural net is built with ReLu units, then its asymptotic behaviour is necessarily linear. No training can change this. More generally, no machine learning with a finite training set can train asymptotic behaviour. So extrapolations always reflect a priori assumptions, not training.
