[site]: crossvalidated
[post_id]: 631488
[parent_id]: 631474
[tags]: 
In a Bayesian model, we are often mainly interested in the posterior distribution, as it describes our knowledge about the parameters of interest given our priors and after having seen the data. Now, often, this posterior distribution is not tractable analytically, but we can still sample from it. Based on, e.g., the average of the samples, we can then approximate a posterior mean of the parameters. This is often done with so called MCMC methods - Markov chain Monte Carlo methods. The idea is to devise a strategy of sampling such that, when producing draws via this chain, these draws will be "almost" draws from the posterior distribution from which we want to sample (if we can directly sample from the posterior distribution, we will do so, but often, that is not possible) provided the chain has run long enough . So to make sure that it has run "long enough" (what that is in practice is of course not clear as it stands) we discard the initial draws - the burn ins - that may still be affected by where we initialized the chain and hence not yet be "trustworthy" draws from "almost" the posterior distribution. I haven't mentioned BVARs in my answer as this is a general feature of many modern Bayesian approaches. Also, your question is fairly broad, so that it may not be possible to answer it well CV style (for me at least).
