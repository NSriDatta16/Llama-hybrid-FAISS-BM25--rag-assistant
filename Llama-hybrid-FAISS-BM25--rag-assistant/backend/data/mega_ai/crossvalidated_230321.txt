[site]: crossvalidated
[post_id]: 230321
[parent_id]: 
[tags]: 
Autoencoders for Dimensionality Reduction of Sensor Data with many missing Values

The setting I am considering is the following: In varying time-intervals we receive numerical data from a range of approx. 200 sensors (of unknown nature), which hopefully allow us to predict the internal state of our system. The readouts themselves are unreliable, in the usual case, I will only get a couple of readouts per day (I am pooling all sensory input on the level of a day) while not receiving any data from the other sensors. I would like to learn a lower-dimensional representation of my input data, which, in it's raw form, would be a 200-dimensional vector with many missing values. Would approaching the problem of dimensionality reduction with an autoencoder make sense in such a setting? Especially since the cost-function might be heavily driven by the imputed input values. What kind of imputation strategy would you follow for the missing data?
