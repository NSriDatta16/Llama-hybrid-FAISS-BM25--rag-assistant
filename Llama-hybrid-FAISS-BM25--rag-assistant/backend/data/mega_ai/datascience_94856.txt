[site]: datascience
[post_id]: 94856
[parent_id]: 94831
[tags]: 
There are a number of approaches to try and improve the model but more importantly to understand what is happening. First of all, you've displayed a plot with over 200 'features' and despite scaling the input the coefficients are in the order of 1E17!!! Edit: house prices (in dollars are in the range 1E5-E7, ie less than $10M), yet the coefficients are at least 7 orders of magnitude greater or smaller. Therefore, two immediate steps to take either together or in combination is conduct: dimensionality reduction either using a formal method e.g. PCA or just dropping terms that have coefficients close to zero backed with some plots to help you decide. regularisation - at at the moment you have some extreme and opposite coefficients around +7.5E17 and -7.5E17. See models here https://scikit-learn.org/stable/modules/linear_model.html#linear-model that implement ways to suppress extreme coefficients. Edit: If your input data is between 0-1 ask yourself why for some parameters are at opposite ends, in effect cancelling each other out. Use some personal domain knowledge and evaluate the individual columns. Is there anything that has no bearing on the sale price? Some silly examples might the name of first person who bought it, which has no relevance to house price. Or a telephone number etc. As we're now entering the world of 'hyper-parameter' tuning don't forget to split your data into 3 parts instead of 2.
