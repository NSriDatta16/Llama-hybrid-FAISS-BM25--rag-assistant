[site]: crossvalidated
[post_id]: 391646
[parent_id]: 
[tags]: 
Meaning of Probability Distributions in RBMs

I'm new to machine learning, and am trying to understand some of the basics of Restricted Boltzmann Machines. Unfortunately, I don't have a background in statistics yet beyond a basic understanding, and a lot of the resources I have been finding online use it heavily. I have an understanding of Hopfield networks, so any answer that could relate the two networks with minimal use of statistics would be greatly appreciated. So far, every resource I have found has mentioned that RBMs learn the probability distribution of its training patterns, and training involves minimizing (or maximizing) an objective function of the difference between the "true" and "learned" distributions. My question is the following: What does the "probability distribution" learned by an RBM refer to? My guess is that for each activation state of the network, it learns a distribution over its training patterns that gives the probability of each training pattern resulting in that activation state, but I haven't found anything to confirm that.
