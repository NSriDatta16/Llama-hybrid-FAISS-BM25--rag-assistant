[site]: crossvalidated
[post_id]: 301204
[parent_id]: 
[tags]: 
Best practice of testing for serial correlation in VAR residuals in R

I want to examine the residuals of a VAR and apply the LM test for serial correlation (autocorrelation) like in ( this ) blog post by Dave Giles. In my test, I first examine the optimum lag length for two time series with an intercept and trend and go from here: VAR Now, like in the example of the link above, I want to check which of the proposed lags has the lowest likelihood of serial correlation in the VAR. Following works with serial.test, that (I assume) obviously automatically selects the residuals from a VAR. Now I discovered following testing methods: serial.test() from the vars package - Apparently a Portmanteau Test (asymptotic) statistics for every defined VAR: serial.test(VAR) or Breusch-Godfrey LM test: serial.test(VAR, type="BG") Box.test() from base - Can perform the Ljung-Box text, but only for one column ([,1]): Box.test(residuals(VAR), type = c("Ljung-Box")) does not work. It returns "x is not a vector or univariate time series". Apparently, Box.test does not work with VAR? It apparently only works with residuals(VAR)[,1] , i.e. selecting one column of the residuals. dwtest() from the lmtest package - performs the Durbin-Watson test: dwtest(residuals(VAR)[,1] ~ residuals(VAR)[,2]) bgtest() from the lmtest package - performs the Breusch-Godfrey zest: bgtest(res_data[,1] ~ res_data[,2]) Questions: Do I approach the test correctly (especially, not selecting a lag after the VAR was defined with a lag already)? What would you recommend to do? Can you confirm that Box.test() does not work with VAR?
