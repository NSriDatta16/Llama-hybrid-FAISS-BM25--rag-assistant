 a new decision that is democracy-dependent. Bruce M. McLaren built an early (mid-1990s) computational model of casuistry, a program called SIROCCO built with AI and case-base reasoning techniques that retrieves and analyzes ethical dilemmas. But this approach could lead to decisions that reflect society's biases and unethical behavior. The negative effects of this approach can be seen in Microsoft's Tay, a chatterbot that learned to repeat racist and sexually charged tweets. One thought experiment focuses on a Genie Golem with unlimited powers presenting itself to the reader. This Genie declares that it will return in 50 years and demands that it be provided with a definite set of morals it will then immediately act upon. This experiment's purpose is to spark discourse over how best to handle defining sets of ethics that computers may understand. Some recent work attempts to reconstruct AI morality and control more broadly as a problem of mutual contestation between AI as a Foucauldian subjectivity on the one hand and humans or institutions on the other hand, all within a disciplinary apparatus. Certain desiderata need to be fulfilled: embodied self-care, embodied intentionality, imagination and reflexivity, which together would condition AI's emergence as an ethical subject capable of self-conduct. In fiction In science fiction, movies and novels have played with the idea of sentient robots and machines. Neill Blomkamp's Chappie (2015) enacts a scenario of being able to transfer one's consciousness into a computer. Alex Garland's 2014 film Ex Machina follows an android with artificial intelligence undergoing a variation of the Turing Test, a test administered to a machine to see whether its behavior can be distinguished from that of a human. Films such as The Terminator (1984) and The Matrix (1999) incorporate the concept of machines turning on their human masters. Asimov considered the issue in the 1950s in I, Robot. At the insistence of his editor John W. Campbell Jr., he proposed the Three Laws of Robotics to govern artificially intelligent systems. Much of his work was then spent testing his three laws' boundaries to see where they break down or create paradoxical or unanticipated behavior. His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances. Philip K. Dick's 1968 novel Do Androids Dream of Electric Sheep? explores what it means to be human. In his post-apocalyptic scenario, he questions whether empathy is an entirely human characteristic. The book is the basis for the 1982 science-fiction film Blade Runner. See also Affective computing AI safety AI takeover Artificial intelligence in fiction Formal ethics Friendly artificial intelligence Military robot Moral psychology Philosophy of artificial intelligence Philosophy of mind Robot ethics Self-replicating spacecraft References Further reading Hagendorff, Thilo (2021). Linking Human And Machine Behavior: A New Approach to Evaluate Training Data Quality for Beneficial Machine Learning. Minds and Machines, doi:10.1007/s11023-021-09573-8. Anderson, Michael; Anderson, Susan Leigh, eds (July/August 2006). "Special Issue on Machine Ethics". IEEE Intelligent Systems 21 (4): 10â€“63. Bendel, Oliver (December 11, 2013). Considerations about the Relationship between Animal and Machine Ethics. AI & SOCIETY, doi:10.1007/s00146-013-0526-3. Dabringer, Gerhard, ed. (2010). "Ethical and Legal Aspects of Unmanned Systems. Interviews". Austrian Ministry of Defence and Sports, Vienna 2010, ISBN 978-3-902761-04-0. Gardner, A. (1987). An Artificial Approach to Legal Reasoning. Cambridge, MA: MIT Press. Georges, T. M. (2003). Digital Soul: Intelligent Machines and Human Values. Cambridge, MA: Westview Press. Singer, P.W. (December 29, 2009). Wired for War: The Robotics Revolution and Conflict in the 21st Century: Penguin. Winfield, A., Michael, K., Pitt, J. and Evers, V. (March 2019). Special Issue on Machine Ethics: The Design and Governance of Eth