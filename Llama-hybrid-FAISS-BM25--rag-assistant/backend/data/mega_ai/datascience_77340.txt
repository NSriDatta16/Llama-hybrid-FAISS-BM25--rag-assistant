[site]: datascience
[post_id]: 77340
[parent_id]: 
[tags]: 
Inverse predict the features from known target with fitted sklearn regressor

I understand that the default way a scikit-learn regressor works is that we fit it to a dataset of features and targets ( X_train , y_train ) and then we can use the fitted regressor to predict an unknown target, y1 , from known features, X1 . On the contrary, I know the target, y1 , and would like to evaluate what features X1 would yield the known target with the fitted regressor. I do not think that there is an in-built method (such as inverse_predict ) that can achieve this, or is there such a method??? How do you suggest I efficiently estimate X1 ? Here is a horribly inefficient way I am doing this presently: from sklearn.svm import SVR reg = SVR(kernel='linear') reg.fit(X_train, y_train) # While loop to estimate X1 continue_while_loop = True while continue_while_loop: X1 = X_train[np.random.choice(range(X_train.shape[0]),:] # randomly select a feature vector from X_train X1 = X1 + np.random.normal(np.mean(X_train), 10*np.std(X_train), (X_train.shape)) # Add random noise to X1 y1pred = reg.predict(X1.reshape(1,-1)) error = np.linalg.norm(y1 - y1pred) # Find the error between predicted and true y1 if error
