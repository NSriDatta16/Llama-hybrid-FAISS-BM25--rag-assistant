[site]: crossvalidated
[post_id]: 231368
[parent_id]: 231115
[tags]: 
What can we say on the obtained volatility prediction? If the $x_t^2$ is non-autocorrelated, the estimated GARCH model (consider order (1,1) for simplicity) $$ \sigma_t^2 = \omega + \alpha x_{t-1}^2 + \beta \sigma_{t-1}^2 $$ would have $\hat\omega \approx \hat\sigma^2$, $\hat\alpha \approx 0$, and $\hat\beta \approx 0$, where $\hat\sigma^2$ is the (unconditional) sample variance. Alternatively, you could probably get $\hat\omega \approx 0$, $\hat\alpha \approx 0$, $\hat\beta \approx 1$ with $\hat\sigma_t^2 \approx \hat\sigma^2$ for all $t$. In both cases the fitted values would be approximately constant and the GARCH model would have negligible effect as compared with the alternative of assuming constant variance. The predicted values would also be roughly constant and roughly equal to the fitted in-sample variance $\hat\sigma^2$. Does it mean that the predicted volatility is completely random or that the volatility is simply the mean of the historical volatility? It is the latter. Is the volatility forecast better in absence or in presence of autocorrelation in $x_t^2$? You can say that one forecast is better than another when the object being forecast is the same. However, when you have differently behaved processes (one with ARCH effects and one without), it is not straightforward to say whether one forecast is better than the other. For starters, you can ponder upon questions like: Which of the two series is more predictable? (Then you need to define predictability.) Which of the two series is likely to be predicted more accurately with a GARCH model? (Then you need to define how to compare predictive accuracy for two different targets.) You could choose to compare absolute predictive accuracy across the cases based on some loss function, e.g. square loss. Then you would ask, on average, does one prediction yield a smaller squared loss than the other (for their respective targets)? (Checking this may be nontrivial because time-varying conditional variance is measured with a large error, unless you have data of higher frequency and can obtain a more accurate measure of realized variance.) Now to address the question more directly, take a sample of fixed size and suppose you know the true model of the conditional variance (but you do not know its coefficient values which need to be estimated). The simpler the conditional variance model, the more precisely you will be able to estimate the model and the more precise your forecasts will be. That tells that a constant conditional variance should be easier to estimate and predict than, say, conditional variance of GARCH type. However, if you allow for stochastic conditional variance, estimation and forecast precision will also (inversely) depend on the error variance in the conditional variance equation. Moreover, when you do not have the true model the picture is less clear. EDIT: My impression is that short time forecast is more reliable in presence of autocorrelation in $x_t^2$, while long term forecast is more reliable in absence of it. As mentioned above, when you know the true model you would prefer a simple process to a more complicated one, and low error variance (in the conditional variance equation) to a high one. This should be true both for short- and long-term forecasts.
