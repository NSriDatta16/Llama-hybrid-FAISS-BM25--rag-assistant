[site]: crossvalidated
[post_id]: 370296
[parent_id]: 76784
[tags]: 
For the Normal distribution test in the Mann Whitney U Test, note that the distribution that both $U_1$ and $U_2$ follow is a Normal distribution with mean equal to $n_{1}n_{2}/2$ . But since $U_{1} + U_{2} = n_{1}n_{2}$ , this means the null hypothesis distribution is Normal with a mean equal to the average of $U_{1}$ and $U_{2}$ . In particular, this means that both $U_{1}$ and $U_{2}$ are equally distant from the mean of the distribution (they are both exactly $[\max(U_{1}, U_{2}) - \min(U_{1}, U_{2})] / 2$ units away from the center of the null hypothesis distribution, by definition). Since they are equally distant and the distribution is symmetric about its mean, then both $U_{1}$ and $U_{2}$ must generate identical z-scores (up to a sign difference) in that distribution, and thus also identical p-values. Having a consistent choice like always using the minimum, I suppose, helps with things like software implementation consistency, but it should not have any effect of the output statistics of the test itself. Also, if you calculate the z-score based on $U_{\min}$ , it is guaranteed to be along the left tail of the null hypothesis distribution. Call $z_{\min}$ this z-score. Then the p-value generally of interest will simply be $2 * \textrm{normCDF}(z_{\min})$ , because $z_{\min}$ is already negative on the left tail and you're measuring the probability of a value smaller than what was observed. Doubling it also accounts for the other tail where you care about $P(z > z_{\max})$ , since by the argument mentioned above, $z_{\max} = |z_{\min}|$ . If you base it off of $z_{\max}$ directly, you'd need the ever so slightly more complicated calculation of $2 * (1 - \textrm{normCDF}(z_{\max}))$ , which has a track record of confusing the heck out of people.
