[site]: crossvalidated
[post_id]: 264698
[parent_id]: 
[tags]: 
Is there any way to prove a given error rate of model without testing it so many times?

If I have to prove my machine can infer with an error rate 0.01, that means I have to test it with at least 100 test samples with a single wrong answer. Is there any way to prove error rate testing with less than 100 test samples? I know that the test is to validate your model and knowledge, you can't screen test samples and they have to be randomly chosen. But let's say you use a prior knowledge or hypothesis with its known probabiity and you wish to prove your machine(Gaussian Process, bayesian etc) to have 0.01 error rate without going through 100 sample tests. Say, testing from "uncertain" test samples, just like you do in active learning where you learn uncertain samples over certain similar known samples. Is there any such validation method for effective testing?
