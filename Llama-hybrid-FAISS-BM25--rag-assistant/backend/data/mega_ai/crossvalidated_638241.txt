[site]: crossvalidated
[post_id]: 638241
[parent_id]: 
[tags]: 
time series cross validation and avoidance of overfitting

So. I am doing Time Series Classification on various datasets using different types of classifiers (deep learning, dictionary-based, distance-based, interval-based, feature-based, convolution). As far as I know, k-fold is not a good option for time series, so I've switched to TimeSeriesSplit. However, overfitting is not ensured, of course, even when doing cross-validation. K-fold solves this problem by shuffling, but TimSeriesSplit doesn't do that (that's the point, actually). I would use Dropout Layers or Regularization, but these techniques are only for deep-learning models, and my goals basically is to compare the results of all these algorithms altogether. What would be a good technique to use for all types of classifiers, in my case?
