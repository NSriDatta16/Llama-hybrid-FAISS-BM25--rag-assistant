[site]: crossvalidated
[post_id]: 313664
[parent_id]: 313608
[tags]: 
(not entirely sure about this one). If a certain estimator $\hat θ̂$ is a sufficient statistic for a parameter $θ$, and $p(θ)$ is flat, then $p(\hat θ̂ |θ)=p(D|θ)=c⋅p(θ|D)$, i.e. the sampling distribution is equal to the likelihood function, and therefore equal to the posterior of the parameter given a flat prior. This is incorrect: $p(D|θ)=p(\hat θ̂ |θ)\times p(D|\hat θ)$ when $\hat θ$ is a sufficient statistic $p(D|θ)=c⋅p(θ|D)$ is false when considered as a function of $D$, and when considered as a function of $θ$ (unless one uses the flat prior) only does the posterior based on $\hat θ$ equal the posterior based on $D$ in this context. Furthermore, sufficiency has nothing to do with frequentism versus Bayesianism, even though there exist specifically Bayesian notions of sufficiency. As for instance in model comparison . a Bayesian would probably agree that an unbiased frequentist estimator is generally more desirable than a biased frequentist one The trouble with this part of the question is that Bayesian estimators are frequentist estimators as well in that they satisfy frequentist properties like admissibility or sometimes minimaxity. As discussed in a recent CV entry , Bayes estimates under squared error loss cannot be unbiased . And there is no reason beyond using a special loss function to favour unbiasedness: minimising a posterior loss is all-inclusive and if imposing unbiasedness results in a higher loss it should not be considered. (A last point is that there are very few functions of the parameter that allow for unbiased estimators.)
