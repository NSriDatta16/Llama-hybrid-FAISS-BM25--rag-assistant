[site]: crossvalidated
[post_id]: 137057
[parent_id]: 
[tags]: 
Ridge penalized GLMs using row augmentation?

I've read that ridge regression could be achieved by simply adding rows of data to the original data matrix, where each row is constructed using 0 for the dependent variables and the square root of $k$ or zero for the independent variables. One extra row is then added for each independent variable. I was wondering whether it is possible to derive a proof for all cases, including for logistic regression or other GLMs.
