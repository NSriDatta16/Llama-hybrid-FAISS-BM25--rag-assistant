[site]: crossvalidated
[post_id]: 624442
[parent_id]: 565955
[tags]: 
To add up to the other accepted answer, perhaps some people coming here do not know what convergence in probability means and could use a bit of context. I assume the basic terminology known, if needed, see my other detailed answer . I think what could be the most confusing thing here is the difference between different types of convergence and why are they needed. When random variables are deterministic, all concepts represent the same one. However, in the probabilistic context, different convergences exist and represent different notions of convergence. You could have two random variables whose mean converge (in the sense that $\lim_{n \to \infty} \mathbb E[X_n] = \mathbb E[X] $ ) but which do not converge in probability. For example, the sequence of random variables $X_n$ i.i.d. and which each takes the value $-1$ with probability $0.5$ and $1$ with probability $0.5$ converges in mean to the random value taking at all times the value $0$ ! However, it is obvious that we do not have any other type of convergence, for example: $\lim_{n \to \infty} \mathbb E[|X_n - X|] = 1 \neq 0 $ which if it were equal to $0$ would be called the $L^1$ convergence. These different levels of convergence are clarified very precisely on this Wikipedia page . There exist some relations between the different concepts (again taken from the Wikipedia page): Perhaps one of the first taught distinctions in the context of statistics is the difference between convergence in probability ( $\overset{p}{\to}$ ) and convergence in distribution ( $\overset{d}{\to}$ ). One of the key differences is that convergence in probability tells you something about random variables being close in a pointwise sense (with a high probability) whereas convergence in distribution describes solely the closeness of the distributions. Taking i.i.d. random variables $X, X_n$ , and define $Y$ and define $Y = -X$ . Since all the random variables have the same distribution, we clearly have the convergence in distribution $X_n \to X$ . But we do not expect $X$ to be close to $Y$ in a pointwise sense. For instance, if $X \sim N(0,1)$ then $$\mathbb{P}(|X-X_n|>\delta) = \mathbb{P}(|X|>\delta/2)>0,$$ which means that $X_n$ does not convergence in probability to $X$ . A good place to continue reading is the Wikipedia page, probability theory courses or other mathstack-related questions! Finally, if you are wondering how to write that symbol in Latex , my prefered form is $\overset{p}{\xrightarrow[ n \to \infty]{} }$ , which I found very elegant :) .
