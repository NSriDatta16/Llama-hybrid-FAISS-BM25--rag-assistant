[site]: crossvalidated
[post_id]: 471682
[parent_id]: 471658
[tags]: 
In practice of forecasting there's very little that is absolute. This is one such case where there is not prescribed course of actions. Presumably you started with a time series regression model $y_t=X_t\beta+\varepsilon_t$ where $\varepsilon_t\sim\mathcal N(0,\sigma^2)$ . Once you looked at residuals $\hat\varepsilon_t$ and noticed that they're autocorelated, you decided to improve the model and apply regARIMA model: $$y_t=X_t\beta+\varepsilon_t$$ where $\varepsilon_t=\phi_1\varepsilon_{t-1}+u_t$ with $u_t\sim\mathcal N(0,\sigma^2_u)$ Then you find that residuals $\hat u_t$ are autocorrelated. Now what? You could try to fit higher order ARIMA(p,d,q) instead if the first attempt with AR(1). In fact if you pick high enough orders of P,D,Q, I bet that at some point residuals $\hat u_t$ will start looking like a white noise. Should you do this? Maybe, maybe not. It's up to you. I prefer parsimonious models, and dislike high order models, especially when it comes to differencing D. You also need to be careful with autocorrelation measures since they're sensitive to outliers. For instance, you may have two big events 6 months apart and if the dataset is not large, they'll appear like 6 month frequency seasonality.
