[site]: crossvalidated
[post_id]: 109787
[parent_id]: 
[tags]: 
Basic idea of zero inflated two part models(hurdel) and application to big data (machine learning)

I'm currently working on the data which has 90% 0s in response variable. Based on my research, it seems zero inflated models could be a solution to this. However, while I was reading related documents, it seems the basic idea of two part model( hurdel) is $ E[Y|X] = P(Y>0|X) E[Y|X,Y>0]$ The question is will it be okay if I use any model to get both P(Y>0|X) and E[Y|X,Y>0] ,and multiply the result of those two? More specifically, in R code would be like #for first model FirstModel=randomforest(Y,X) #random forest First_pred=predict(FristModel,newdata,type='prob') #for second model SecondModel=glmnet(Y~X) #glm with L1 L2 penalty Second_pred=predict(SecondModel,newdata) #for E[Y|X] = P(Y>0|X) * E[Y|X,Y>0] First_pred * Second_pred Will this make sense in view of machine learning modeling strategy? In other wards, will this improve accuracy of prediction without considering interpretation?
