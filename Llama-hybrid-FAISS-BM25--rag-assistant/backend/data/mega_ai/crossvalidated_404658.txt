[site]: crossvalidated
[post_id]: 404658
[parent_id]: 
[tags]: 
Error while fitting data in auto.arima - R

I am running auto.arima for forecasting time series data and getting the following error: 1: The time series frequency has been rounded to support seasonal differencing. 2: In value[[3L]](cond) : The chosen test encountered an error, so no seasonal differencing is selected. Check the time series data. This is what I am executing: fit I have weekly time series data. This is how dput(data) looks as follows: structure(c(12911647L, 12618317L, 12827388L, 12967840L, 13264925L, 13557838L, 13701131L, 13812463L, 13971928L, 13837658L, 13550635L, 13022371L, 13507596L, 13456736L, 12992393L, 12831883L, 13262301L, 12831691L, 12808893L, 12726330L, 11893457L, 12434051L, 12363464L, 12077055L, 12107221L, 11986124L, 11997087L, 12264971L, 12164412L, 12438279L, 12733842L, 12543251L, 12627134L, 12480153L, 12276238L, 12443655L, 12497753L, 12279060L, 12549138L, 12308591L, 12416680L, 12516725L, 12326545L, 12772578L, 12524848L, 13429830L, 14188044L, 16611840L, 16476565L, 15659941L, 10785585L, 12150894L, 13436366L, 12985213L, 13097555L, 13204872L, 13786040L, 13760281L, 13295389L, 14734578L, 15043941L, 14821169L, 14361765L, 14300180L, 14357964L, 14271892L, 13248168L, 13813784L, 14092489L, 14100024L, 13378374L, 13225650L, 12582444L, 13267163L, 13026181L, 12747286L, 12707074L, 12534595L, 12546094L, 13030406L, 12950360L, 12814398L, 13405187L, 13277755L, 13142375L, 12742153L, 12610817L, 12267747L, 12570075L, 12704157L, 12835948L, 12851893L, 12978880L, 13104906L, 12754018L, 13213958L, 13584642L, 13963433L, 14471672L, 16312595L, 16630000L, 16443882L, 11555299L, 12018373L, 13031876L, 13013945L, 13164137L, 13313246L, 13652605L, 13803606L, 13308310L, 14466211L, 15092736L, 15346015L, 14467260L, 14767785L, 13914271L, 14185070L, 13851028L, 13605858L, 13597999L, 13876994L, 13026270L, 13113250L, 12288727L, 12925846L, 13525010L, 12594472L, 12654512L, 12888260L), .Tsp = c(2016.00819672131, 2018.48047598209, 52.1785714285714), class = "ts") This is how I am reading data from the csv read_data This is the data in the csv: Year si_act 1/4/16 12911647 1/11/16 12618317 1/18/16 12827388 1/25/16 12967840 2/1/16 13264925 2/8/16 13557838 2/15/16 13701131 2/22/16 13812463 2/29/16 13971928 3/7/16 13837658 3/14/16 13550635 3/21/16 13022371 3/28/16 13507596 4/4/16 13456736 4/11/16 12992393 4/18/16 12831883 4/25/16 13262301 5/2/16 12831691 5/9/16 12808893 5/16/16 12726330 5/23/16 11893457 5/30/16 12434051 6/6/16 12363464 6/13/16 12077055 6/20/16 12107221 6/27/16 11986124 7/4/16 11997087 7/11/16 12264971 7/18/16 12164412 7/25/16 12438279 8/1/16 12733842 8/8/16 12543251 8/15/16 12627134 8/22/16 12480153 8/29/16 12276238 9/5/16 12443655 9/12/16 12497753 9/19/16 12279060 9/26/16 12549138 10/3/16 12308591 10/10/16 12416680 10/17/16 12516725 10/24/16 12326545 10/31/16 12772578 11/7/16 12524848 11/14/16 13429830 11/21/16 14188044 11/28/16 16611840 12/5/16 16476565 12/12/16 15659941 12/19/16 10785585 12/26/16 12150894 1/2/17 13436366 1/9/17 12985213 1/16/17 13097555 1/23/17 13204872 1/30/17 13786040 2/6/17 13760281 2/13/17 13295389 2/20/17 14734578 2/27/17 15043941 3/6/17 14821169 3/13/17 14361765 3/20/17 14300180 3/27/17 14357964 4/3/17 14271892 4/10/17 13248168 4/17/17 13813784 4/24/17 14092489 5/1/17 14100024 5/8/17 13378374 5/15/17 13225650 5/22/17 12582444 5/29/17 13267163 6/5/17 13026181 6/12/17 12747286 6/19/17 12707074 6/26/17 12534595 7/3/17 12546094 7/10/17 13030406 7/17/17 12950360 7/24/17 12814398 7/31/17 13405187 8/7/17 13277755 8/14/17 13142375 8/21/17 12742153 8/28/17 12610817 9/4/17 12267747 9/11/17 12570075 9/18/17 12704157 9/25/17 12835948 10/2/17 12851893 10/9/17 12978880 10/16/17 13104906 10/23/17 12754018 10/30/17 13213958 11/6/17 13584642 11/13/17 13963433 11/20/17 14471672 11/27/17 16312595 12/4/17 16630000 12/11/17 16443882 12/18/17 11555299 12/25/17 12018373 1/1/18 13031876 1/8/18 13013945 1/15/18 13164137 1/22/18 13313246 1/29/18 13652605 2/5/18 13803606 2/12/18 13308310 2/19/18 14466211 2/26/18 15092736 3/5/18 15346015 3/12/18 14467260 3/19/18 14767785 3/26/18 13914271 4/2/18 14185070 4/9/18 13851028 4/16/18 13605858 4/23/18 13597999 4/30/18 13876994 5/7/18 13026270 5/14/18 13113250 5/21/18 12288727 5/28/18 12925846 6/4/18 13525010 6/11/18 12594472 6/18/18 12654512 6/25/18 12888260 Edit1 : I was able to read the data without any errors before, initially, I had 160 records & the model does not throw any error but, then for 80-20 test I removed the last 30 records and this error cropped up. Now also, if I run with all the data I don't get any error but is I run it with first 130 as 80% I get this error.
