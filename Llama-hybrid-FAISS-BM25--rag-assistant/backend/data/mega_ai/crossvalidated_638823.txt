[site]: crossvalidated
[post_id]: 638823
[parent_id]: 638814
[tags]: 
A few thoughts: If your data is partially hierarchical, then do consider hierarchical forecasting with the optimal reconciliation approach. This very often improves forecasts on all levels. The vanilla version only works for expectation forecasts (there are some recent papers on probabilistic hierarchical forecasting, though), and it can't very well handle larger or more complex hierarchies, but it is absolutely a thing to look at. I absolutely agree with paneling your data to pool information for related series. Both these points depend very much on what kind of hierarchy/hierarchies you have. For instance, you might have sales of different products in different locations, and that gives you two separate hierarchical or panel dimensions, both of which you can and should leverage. As you write, plots are often very helpful. Plot aggregates along your hierarchies, per above. Or plot random series (or aggregates). I will often just take 200 series, which is about the limit of what I can look at, then get a cup of coffee and flip book through the plots. You can quickly identify "strange" behavior in single series or aggregates that way, stuff you didn't even think about looking for, and then investigate more deeply and/or treat issues automatically. What is helpful here will very much depend on your dimensionality. If you have 200 products sold in 20 stores each, then you can look at 200 plots of product sales that each summarize the 20 stores in some smart way. For instance, if you have fine granular data, like daily, you might want to not plot total sales, but just have 20 lines of dots corresponding to the 20 stores, with a dot on a day on which this product was sold at this particular store. That once helped me detect markdown sales that were not noted in the data. Alternatively, you might be able to quantify issues during data cleansing, and explicitly look at the "dirtier" time series. For instance, if you detect outliers, you could label each series $(y_t)$ by $\max\{|y_t|\}/\text{mean}\{|y_t|\}$ , look at the top 20 series and think about whether you can do something about these outliers. (Alternatively, model the series and look at residuals rather than series values.) You can also do seasonal plots by plotting beanplots, or boxplots, or raw data, together with some summary statistics. I personally rarely use clustering, to be honest. The feature space is just too large, or put differently, there are just so many things that can go wrong in time series... I find that "flip book" approach above more useful. And when it comes to focusing attention, I usually try to get a handle on the business importance of the different series, and look at the ones that are more important. Here is one thing I always do: when evaluating my forecasts on a holdout set, don't just look at average accuracy. In addition, look at the very bad forecasts. These are (a) the ones that erode your user's trust in your forecasts if they see them, and (b) the ones where you can learn a lot about problems in your data. For instance, you might have a very bad forecast because a series is zero in the complete evaluation period, so you need to figure out whether this series just stopped at some point, and if so, whether you can get this information in some way, or need to forecast it. Of course, this very much depends on getting a scale invariant notion of badness or forecastability, which is not easy... scaled error measures help here, but are not a panacea.
