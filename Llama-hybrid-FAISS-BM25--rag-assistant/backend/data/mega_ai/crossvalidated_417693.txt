[site]: crossvalidated
[post_id]: 417693
[parent_id]: 417686
[tags]: 
Note: though the old answer (below the line) was accepted, the comment below alerted me to the fact that I had misinterpreted the question. My old answer pertains to comparing PCs on different batches of observations (i.e. different rows). But the question is actually about doing PCs on different batches of variables (i.e. different columns). I will now address this. In order to reduce dimensionality, a PCA calculates orthogonal vectors from the entire set of variables. If you do not do the PCA on all variables, you are by definition not achieving this basic goal. By doing PCAs on 5000 variables at a time and retaining 500 PCs from each of the 12 batches, you are at risk of capturing plenty of redundant information in your final set of 6000 PCs. If there are a few dominant axes of variation, these would be captured over and over in each of the 12 batches. You could check the extent to which this is true by doing another PCA on your aggregated 6000 PCs. As for better solutions, I'm not an expert, but here are a couple of thoughts. (i) There are Incremental PCA methods specifically designed for this, and I think they work by loading a few rows into memory at a time. (ii) As that implies, I think you need to use all variables (columns) to do the PCA, but you do not need to use all observations (rows). So a simple option is to do the PCA on a subset of the observations instead and then apply them to the rest of the dataset. You're correct that this is a problem: based on how this has been done, the PCs cannot be compared with each other across batches [of observations] . This is mainly because even small differences in the covariance structure between batches will lead to different orthogonal vectors being identified. In other words, PC1 on batch 1 and PC1 on batch 2 represent different things! If you examine the loadings of some of the PCs across batches, you will see these differences. But even if the covariance structure was identical for some magical reason, a PC might have reversed coefficient signs in a different batch because these are arbitrary. The simplest thing to do would be to do a PCA on all the data simultaneously. If that is too much of a computational challenge, you can do it on a random subset of the data and then apply that PCA to the remaining data. This has been discussed in a number of questions on this site, for e.g. How is PCA applied to new data? As an aside, I note that you are applying a PCA to binary data. Though this can be done, there is valuable discussion here about what that implies and possible better alternatives: Doing principal component analysis or factor analysis on binary data Can principal component analysis be applied to datasets containing a mix of continuous and categorical variables?
