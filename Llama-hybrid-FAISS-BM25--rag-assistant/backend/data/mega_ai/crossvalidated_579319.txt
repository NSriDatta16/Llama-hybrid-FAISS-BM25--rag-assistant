[site]: crossvalidated
[post_id]: 579319
[parent_id]: 579313
[tags]: 
$\varphi_A$ in this excerpt refers to an estimator constructed by aggregating estimators trained on different datasets drawn from the distribution $P$ . So that would be like training different models each on their own dataset and combining their predictions. The result is called the aggregated predictor. The aggregated prediction error is the error of the aggregated predictor on new data. We expect this error to be lower than the error of one individual model. The average of the individual models' prediction errors is the averaged prediction error. With bagging, each predictor is not actually trained on its own independent dataset, so we don't get the aggregated predictor. Instead, predictors are trained on bootstrap random samples from just one dataset. In the excerpt, the distribution of bootstrap random samples is denoted as $P_{\mathcal{L}}$ . The error of this model is the bagged prediction error.
