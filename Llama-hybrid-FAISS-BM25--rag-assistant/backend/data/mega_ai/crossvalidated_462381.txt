[site]: crossvalidated
[post_id]: 462381
[parent_id]: 462363
[tags]: 
Most of your models are from sklearn , so I think you might be able to do something like the following. Note very carefully that I have created a list of the functions, not their instantiations. Note that I instantiate the models at the end. Also, I don't seem to have your xgboost module, nor your lightgbm module, so I left those out. You might or might not be able to extract the right info from their __init__ properties. from sklearn.linear_model import LinearRegression, Ridge from sklearn.ensemble import GradientBoostingRegressor, \ RandomForestRegressor, BaggingRegressor mods = [LinearRegression, Ridge, GradientBoostingRegressor, RandomForestRegressor, BaggingRegressor] def extract_name_from_sklearn_model(model) -> str: """ This function extracts a model's name, and assumes it has a fit method. """ prop = '__init__' # Get a dict of the model's properties. properties = dict(vars(model).items()) # Assume it has a fit method. predict_str = str(properties[prop]) # Get whatever is after the string ' Now you can maintain one list of models, so long as they include a '__init__' method from which you can extract the model's name. I also think your lists could be more elegant. Maybe something like this: score = [rmsle_cv(mod) for mod in mod_classes] scores = [this_score.mean() for this_score in score] stds = [this_score.std() for this_score in score]
