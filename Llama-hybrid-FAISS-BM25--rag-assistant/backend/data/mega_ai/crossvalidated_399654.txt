[site]: crossvalidated
[post_id]: 399654
[parent_id]: 
[tags]: 
Rate of gain or loss - gamma distribution?

Forgive me, I am pretty much going back to high school level statistics. I have a set of data for the rate of gain or loss of a certain unit, per second. I have put it into bins of 0.001 width. The bins range in frequency by a large amount: -0.0305 and lower bins have at most 10 occurences, whereas 0.0055 through 0.0095 have 10,000 each. Mean 0.01067150315 Median 0.007942643757 Is a gamma distribution the best distribution to work with here? If so, how would I calculate the scale factor? EDIT: In my specific example, players in a game can lose or gain territory, but the size of the overall world is not zero-sum since the game will continuously generate more land. Since the territories are flexible in size, and players may join at a different time one way to show how good a player is might be to look at the rate of gain or loss of territory per second of game time. This might be expressed as 0.01 sqm/sec on average, but if a player comes in to a game late and gets immediately destroyed by, say, being located next to a very dominant player, I would not want to punish them for having a one-off, very high, negative rate of gain. In a more general (simple?) example, maybe we can consider poker players at a cash table. They may all start with \$100. Player A may leave after two hours with \$80, player B after one hour and \$120, Player C may leave after three hours with \$130. Their rate of gain per minute would be -10, +20 and +10. Over enough hands, you could rank those players in terms of an hourly wage (or rate of gain) and if a player has a particularly good game at a table, winning \$50 in 5 minutes, we can assess the likelihood that that can be repeated. Similarly, a player that busts on their first hand will have an extremely low negative rate of gain, but the chance of being dealt a hand good enough to go all in on their first hand, and losing, was quite low.
