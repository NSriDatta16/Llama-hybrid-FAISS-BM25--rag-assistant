[site]: crossvalidated
[post_id]: 608330
[parent_id]: 606769
[tags]: 
I think I figured it out. The KL is with respect to the distribution of the actions given a stochastic policy, so it makes sense that int the instuctGPT paper the expectation is w.r.t. (x,y). In the PPO paper the expectation w.r.t. distribution of actions is implicit in the 'KL' function, and the expectation outside is to average across an entire episode.Since in the formulation of instructGPT there is only one step per episode (more akin to bandit setting), this is not needed.
