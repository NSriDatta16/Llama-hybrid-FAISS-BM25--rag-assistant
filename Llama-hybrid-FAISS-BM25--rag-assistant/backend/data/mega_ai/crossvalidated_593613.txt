[site]: crossvalidated
[post_id]: 593613
[parent_id]: 551264
[tags]: 
Some general observations: First, we tend to spend a lot of time using non-robust models when there are many robust options that have equal or greater statistical power. Semiparametric (ordinal) regression for continuous Y is one class of model that is not used often enough. Such models (e.g., the proportional odds model) do not depend on how Y is transformed (as long as the transformation is rank-preserving) and are not affected by outliers in Y (they have the same problems as parametric models with regard to outliers in X). Routine use of semiparametric models would result in fewer assumptions in need of checking. Second, goodness of fit needs to be judged against alternatives. What if a more flexible, well-fitting model requires many more parameters and the net effect is overfitting that makes predictions unreliable and/or makes confidence intervals too wide? Almost always, some kind of analysis is required, and the badness of fit of a proposed model should not rule the day, when the proposed alternative analysis is actually worse. On the second point, it is often more useful to think of assessment of goodness of fit in terms of a contest between the proposed model and a more general model. A fully worked out example is here . In that example the proposed model is a proportional odds model in which the effect of a treatment on lowering the odds that $Y\geq j$ is assumed to be the same for all $j$ save the lowest value. There are at least two alternative models: a partial proportional odds model that relaxes this assumption with respect to treatment, and a multinomial logistic model that relaxes the assumption with respect to all predictors. I cast model checking as a contest between these models and use two metrics for comparison: AIC and bootstrap confidence intervals for differences in predicted probabilities of various $Y=j$ from pairs of models. I also show formal likelihood ratio $\chi^2$ tests of goodness of fit by pairwise comparison of these three models. I show that there is a cost of not assuming proportional odds. The above setting is exactly analogous to comparing (1) a linear model with constant variance with (2) a linear model that allows the residual variance $\sigma^2$ to be a function of X. For continuous Y a very cogent approach in my view is to hope for a simple linear model but to allow for departures from that. A Bayesian model could put priors on the amount of variation of $\sigma^2$ and on the amount of non-normality of residuals. By tilting the model towards normal residuals and constant $\sigma^2$ but allowing for departures from those as the sample size allows, one obtains a general solution that does not require binary model choices. A simple example of this is the Bayesian $t$ -test .
