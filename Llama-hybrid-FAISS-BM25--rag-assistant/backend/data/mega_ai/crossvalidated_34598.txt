[site]: crossvalidated
[post_id]: 34598
[parent_id]: 
[tags]: 
Why are the following probabilities equal to each other?

The following is a Bayesian model, there are variables $Y_1,Y_2 \in \{ 0,1 \}$ and variable $X \in \{ 0, 1\}$ and $\theta$ between $0$ and $1$. The model is: draw $\theta$ from Beta distribution with parameters $a$ and $b$ draw $Y_1$ from Bernoulli $\theta$ draw $Y_2$ from Bernoulli $\theta$ draw $X$ as following: with prob. $\theta$, $X = Y_1\,\, XOR\,\, Y_2$ and with probability $1-\theta$ $X = 1 - (Y_1\,\, XOR\,\, Y_2)$. The joint distribution is: $$p(\theta,Y_1,Y_2,X) = p(\theta |a,b)p(Y_1 | \theta)p(Y_2 | \theta)p(X | Y_1,Y_2,\theta)$$ I calculated the joint $p(X,Y_1,Y_2,\theta)$. The interesting part which I don't have an intuitive explanation for is why $$p(Y_1 = 0 | Y_2 = 0, X = 0) = P(Y_1 = 1 | Y_2 = 0, X = 0) = 1/2$$ which is what I get from my calcs. It seems counter-intuitive, because I would expect $a$ and $b$ to bias this posterior. The probabilities do not equal each 1/2, for example, if we compare $$p(Y_1 = 0 | Y_2 = 0, X = 1)$$ and $$p(Y_1 = 1 | Y_2 = 0, X= 1)$$. Does anyone have an intuitive explanation why the above probabilities, each equals 1/2?
