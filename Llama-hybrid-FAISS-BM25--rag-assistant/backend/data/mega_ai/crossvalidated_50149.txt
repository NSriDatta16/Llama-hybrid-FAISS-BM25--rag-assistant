[site]: crossvalidated
[post_id]: 50149
[parent_id]: 
[tags]: 
How to derive the conditional posterior density in hierarchical bayesian models?

I was reading on Gelman's Bayesian Data Analysis - Chapter 5 - Hierarchical model Suppose: data : $y_j$ s parameter: $\theta$ hyperparameter: $\phi$ On page 126, he mentions the analytical derivation of conditional and marginal distributions. I understand that we can easily derive the joint posterior distribution using factorisation based on Bayes' theorem, but I don't understand how to derive the conditional posterior distribution $p(\theta|\phi ,y)$. Is there a general method to go about deriving the conditional posterior distribution? Based on Bayes' theorem perhaps? Please explain thoroughly.
