[site]: crossvalidated
[post_id]: 172773
[parent_id]: 
[tags]: 
Should I use a contingency table or Wilcoxon Rank-Sum Test? (is chi squared nonparametric)

I have a debate over whether a contingency table or Wilcoxon Rank Sum Test (WRST) should be used in a particular situation. There are several problems with the contingency table, but I will mention one at the end having to do with whether the chi squared test is parametric or nonparametric that I am especially interested in resolving. I favor the WRST, but I am open to arguments in favor of the contingency table. In this situation, N numbers were generated by process 1 and M numbers were generated by process 2, where N > M. The numbers are between 0 and 1. (Or they are percents.) I want to know which process tends to produce bigger numbers. In fact, process 1 basically always produces bigger numbers than process 2, but I want to know if N and M are large enough that this difference is statistically significant. (Actually, N = 8 and M = 6.) I know of no way to find out the probability distribution of process 1 or process 2, so it seems to me that a nonparametric test is called for. I want to use the Wilcoxon Rank-Sum Test. However, another person wants me to use a contingency table. They say that WRST is only useful when process 1 and process 2 are known to have the same distribution, differing only by a shift. This seems untrue, according to Wikipedia's entry on the Mann-Whitney U test, another name for the WRST (see #4 under "assumptions and formal statement of hypotheses" which clearly does not assume the distributions differ only by a shift.) At any rate, the contingency table seems potentially wrong just because if N > M, it is unclear what the size of the table would be. (2 x M or 2 x N?) However, say for the sake of argument that I could coerce the data into a table, maybe by throwing out data from process 1 until they are equal in size or by grouping the data into bins and averaging them. (There are problems with either approach, but bear with me.) There is still a problem in that the data are most naturally expressed as numbers between 0 and 1, but the contingency table I think expects integers as input. Still, for the sake of argument let's say I somehow deal with that problem too. There remains a huge problem (in my opinion) in that I think the chi squared test is parametric. (I think contingency tables are often based on chi squared?) I believe it assumes that the integers in the table are generated by a Poisson or multinomial process; but I don't know if process 1 and process 2 are Poisson or multinomial; they almost certainly are not - there is no reason for them to be. Here is the crux of the problem: the thing that is causing arguments is that some sources say chi square is nonparametric: http://benbaab.com/salkind/ChiSquare.html While other sources say a contingency table assumes its cells are Poisson: http://data.princeton.edu/wws509/notes/c5.pdf (see page 5) Can anyone tell me whether I should use a contingency table or Wilcoxon Rank-Sum Test - and how I can resolve this contradiction between the two websites quoted above in such a way as to prove who is right (both to myself and to the other person)? Are the websites somehow both right? Thanks for any help you can give.
