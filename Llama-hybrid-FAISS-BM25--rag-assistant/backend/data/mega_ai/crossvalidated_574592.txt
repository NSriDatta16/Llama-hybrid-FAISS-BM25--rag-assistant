[site]: crossvalidated
[post_id]: 574592
[parent_id]: 
[tags]: 
Possible ways to feed two variables containing text data into an ML model in an NLP problem

In a natural language processing (NLP) problem, we have a couple of variables, say A and B. A denotes a phrase (1-2 words) and B denotes another phrase (>3 words). There is one target variable that demonstrates the similarity score between A and B for each instance. The similarity scores are characterized in one of these ordered categories; [0.0, 0.25, 0.50, 0.75, 1.0]. The description of these scores are as follows; 1.0 - Very close match. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. “the”, “and”, “or”). 0.75 - Close synonym, e.g. “mobile phone” vs. “cellphone”. This also includes abbreviations, e.g. "TCP" -> "transmission control protocol". 0.5 - Synonyms which don’t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches. 0.25 - Somewhat related, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms. 0.0 - Unrelated. So, I'm treating it as a classification problem. I wish to know two things; Whether it is imperative to treat it as a classification problem? How do I use A and B as features? Must I convert them into bag of words? If yes, how? What are the possible ways that I could employ?
