[site]: crossvalidated
[post_id]: 519389
[parent_id]: 518051
[tags]: 
Many thanks to R Carnell for providing the derivation. To increase my understanding, I ran some simulations to validate the theoretical results. First some helper functions. import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm from scipy.stats import bernoulli # expectation of Y given X -- logistic model def EYX(x,beta0,beta1): denom = 1+np.exp(-(beta0 + beta1*x)) return 1./denom # predict class of Y given X, using logistic model def classify(x,beta0,beta1,c): return np.asarray([int(EYX(xval,beta0,beta1)>c) for xval in x]) Now simulate 100 observations of the dichotomous variable $Y$ such that $P(Y=1)=\theta_1$ and $X\sim N(\mu,1)$ in the group with $Y=1$ and $X\sim N(0,1)$ in the group with $Y=0$ . # parameters mu=1 theta=0.7 # classification cutoff c=0.5 # generate the data using mu,theta n=100 y=np.sort(bernoulli.rvs(theta,size=n)) x0=norm.rvs(loc= 0,scale=1,size=np.sum(y==0)) x1=norm.rvs(loc=mu,scale=1,size=np.sum(y==1)) x=np.concatenate((x0,x1)) Now we calculate the theoretical model coefficients, predict the class of each $Y_i$ # true beta0,beta1 beta0=np.log(theta/(1-theta)) - 0.5*mu**2 beta1=mu # predict class using logistic model yhat=classify(x,beta0,beta1,c) Below, I plot the data, the logistic model, the predicted classes, and the undelrying distributions for $X|Y=0$ and $X|Y=1$. plt.plot(x,y,'o',label='data'); xv = np.linspace(-3,3,100); plt.plot(xv,(1-theta)*norm.pdf(xv),'k--',label='f(X|Y=0)'); plt.plot(xv,theta*norm.pdf(xv,loc=mu),'k--',label='f(X|Y=1)'); plt.plot(xv,EYX(xv,beta0,beta1),label='E(Y|X)'); plt.plot(xv,classify(xv,beta0,beta1,c),label='Predicted Class') plt.legend(); We can also compute the theoretical misclassification rate. def MCR(x,y,beta0,beta1,c): yhat = classify(x,beta0,beta1,c) num_misclass = float(np.sum(np.abs(yhat-y)>0)) return num_misclass/float(y.size) true_PMC = theta*norm.cdf(np.log((1-theta)/theta)/beta1 - beta1/2.) \ + (1-theta)*norm.cdf(np.log(theta/(1-theta))/beta1 - beta1/2.) obsv_PMC = MCR(x,y,beta0,beta1,c) print(true_PMC,obsv_PMC) which yields 0.2530043786236347 0.21 Does the observed misclassification rate match the theoretical value, on average? A quick simulation confirms. ntimes=2000 obsv_PMC=np.zeros(ntimes) for i in range(ntimes): y=np.sort(bernoulli.rvs(theta,size=n)) x0=norm.rvs(loc= 0,scale=1,size=np.sum(y==0)) x1=norm.rvs(loc=mu,scale=1,size=np.sum(y==1)) x=np.concatenate((x0,x1)) obsv_PMC[i] = MCR(x,y,beta0,beta1,c) plt.hist(obsv_PMC,bins=100,alpha=0.7); plt.axvline(x=true_PMC, linestyle='-', color='r', label='True PMC'); plt.legend(); plt.title('Misclassification Rate'); The only confusing aspect is exactly how this relates to the goodness of fit. How does this result imply that there exist cases where PMC goes to zero but goodness of fit does not increase?
