[site]: crossvalidated
[post_id]: 271466
[parent_id]: 271456
[tags]: 
The answer to question 1 is that it depends on the model/optimization method used. In principle, it takes a specialized approach to use new data in order to update the model without retraining (with the entire dataset). For more on this see: Online machine learning . The answer to question 2 is no. As a simplistic (and hand wavy) example, consider the case where you observe a sequence of observations: $$ (y_1, X_1),...(y_n,X_n) \in \mathbb{R^p}\times\mathbb{R}, $$ and that you are interested in estimating a linear regression: $$ y_i = X_i\beta + \varepsilon_i. $$ One possibility is to do so via the usual least squares estimator: $$ \hat\beta = (X^{T}X)^{-1}X^{T}y. $$ Another option, in case outliers are of concern, is to use a robust estimating equation: $$ \hat\beta = \arg\max_\beta \varphi(X\beta - y), $$ for more on robust regression see- Robust regression . Now, suppose that the $n+1$ observation is an outlier, so for example, $$ y_{n+1} = 10^5 * \max_{i\in 1:n} |x_i|. $$ In this case the non-robust estimate will likely change by a lot and the robust regression estimate will not be effected.
