[site]: crossvalidated
[post_id]: 533436
[parent_id]: 533391
[tags]: 
I agree with EdM that the notation is a bit confusing, but this is because the book describes two uses of logistic regression. The first equation describes the log-likelihood when there is a single trial for each unit in the data set; for example, did the patient die or not. This is by far the most common use of logistic regression. This is really the only thing you need to focus on and likely the only use of logistic regression you'll ever encounter. The second equation describes the log-likelihood for a more esoteric use of logistic regression, which is when each individual has multiple trials; for example, how many answers did a student get correct on a test. Each item on the test is a trial for each observation. So, for the analysis of a 5-item test taken by a whole classroom of students, the students are the observations, and each student has 5 trials, so each student's value of $y_i$ could be a number from 0 to 5, and for all students $n_i=5$ (but in principle, if you gave each student a test with different numbers of problems then the $n_i$ s would vary). If each unit has a single trial, then $n_i=1$ and the two expressions for the logistic regression log-likelihood are equivalent. Wikipedia distinguishes between binomial regression , which can have $n_i \ge 1$ , and binary regression , which has $n_i=1$ for all $i$ ; this is exactly the distinction made in the textbook. The reason you are unlikely to see $n_i$ in any equations for logistic regression is that the scenario with multiple trials for each individual is usually not estimated with standard logistic regression. Instead, one might use a mixed model to allow each individual to have their own intercept, which adds flexibility to the model. The form of logistic regression with $n_i \ne 1$ is extremely uncommon. I would not worry about it, and if you are trying to understand logistic regression in its most typical case, assuming $n_i = 1$ is sufficient 99.9% of the time (and all most people ever learn).
