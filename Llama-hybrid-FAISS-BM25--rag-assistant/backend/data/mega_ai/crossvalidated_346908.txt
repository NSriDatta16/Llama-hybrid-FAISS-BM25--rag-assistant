[site]: crossvalidated
[post_id]: 346908
[parent_id]: 345765
[tags]: 
The usual supervised classification approach is to create a rectangle of numbers, one row per thing to be classified, one column per feature, and engineer features to communicate information about the problem domain to the model, information that should in some way be predictive of the target labels. When you have structural information as you’ve described here, you come up with ways to represent that structure for the model. If the graphs have a root, then you could have a feature for depth from that root, or more generally distance from some other kind of related node. For example, levels below (or above) VP, or distance from first ancestor having 200 or more nodes in its subgraph (just to name a couple of examples). You can create features about the graph structure, such as “has self loop” and “degree of node” (or indegree and outdegree if directed). You can create features about the neighborhood, such as total number of nodes within distance 3, or the average of some attribute among all immediate neighbors. You can create features about nodes related by feature, such as what fraction of all records have the same value for f2, or the median value of f4 among all records having the same f5 as this record. There are challenges with cross-validation when all records are somehow related. Usually, you end up having to introduce an arbitrary partition in the graph structure, and need to decide how to handle records that had edges crossing the partition boundary (keep the nodes and drop those edges? Or also drop the nodes?) http://www.unofficialgoogledatascience.com/2018/01/designing-ab-tests-in-collaboration.html discusses some related issues in the context of A/B testing, and there are many other references out there, including Social Network Data Analysis (Springer, 2011) and “Graphs in machine learning: an introduction” ( http://arxiv.org/abs/1506.06962 )
