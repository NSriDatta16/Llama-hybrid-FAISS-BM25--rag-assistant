[site]: crossvalidated
[post_id]: 508733
[parent_id]: 508720
[tags]: 
The problem you're describing is known as "model calibration". A model is well calibrated if the predicted the score corresponds to the expected probability. Simple methods like logistic regression tend to produce well calibrated models, whereas some of the tricks used in modern neural networks tend to produce poorly calibrated models. This paper suggests that Temperature Scaling is a simple and effective way to calibrate modern neural nets: https://arxiv.org/abs/1706.04599
