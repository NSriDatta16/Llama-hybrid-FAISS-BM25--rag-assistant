[site]: crossvalidated
[post_id]: 190658
[parent_id]: 190646
[tags]: 
I suggest you to read http://rsos.royalsocietypublishing.org/content/1/3/140216 that contains most of the elements you need. To answer your first question, for a set of tests providing $p$-values $\in [0.045,0.05]$ and power=0.8, the FDR (as defined in the second statement of your question) is 26% if there are as many tests with true effect as tests with no true effect (page 9 of the paper). Notice that the restriction to $p$-value $\in [0.045,0.05]$ is very important and the FDR decreases with letting the $p$-value having smaller values or/and when the proportion of true effect tests increases. To answer your second question, the two statements are radically different. Indeed, in statement 2 of FDR, the ratio is obtained by averaging over all conclusive tests accounting from both the real effect case and the not-real effect case (with a given proportion). While in the first statement for the type I error, the ratio is computed over the (hypothetical) tests for the all observations that could be generated under the null hypothesis of no real effect only.
