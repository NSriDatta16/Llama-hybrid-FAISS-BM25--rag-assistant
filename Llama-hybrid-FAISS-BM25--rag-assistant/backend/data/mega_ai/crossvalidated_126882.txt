[site]: crossvalidated
[post_id]: 126882
[parent_id]: 
[tags]: 
How to build a predictive model with a billion of sparse features?

I am making a model to learn a dataset which has a big feature number and sparse samples (I am planning to use logistic regression). The feature number can be as big as 1,000,000,000. It is sparse meaning that there are a lot of zeros than ones (maybe one out of one thousand is one and others are zero). To deal with this dataset I should do some dimensionality reduction, or the machine can not deal with the model, and also I want to find some method to deal with the sparseness. So my questions are: How to do reduce the dimension? How to deal with the sparseness?
