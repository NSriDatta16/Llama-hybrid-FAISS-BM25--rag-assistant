[site]: crossvalidated
[post_id]: 617210
[parent_id]: 617205
[tags]: 
This seems like this is related to the problem of perfect separation in logistic regression. If a set of predictors is adequate to completely determine the outcome, you get very high odds ratios along with high standard errors of the regression coefficients. In your case you perhaps don't have perfect separation but something close to it. You need to think carefully about this, based on your understanding of the subject matter. It's possible that this is a real association. You might consider a penalized model, which is also a way to deal with perfect separation in logistic regression. You could just penalize the coefficient for this predictor, leaving the others as is. You can do that with a ridge term in a model fit by the R coxph() function, or use the glmnet package . The risk is that you've accidentally introduced a problem like survivorship bias into your study. That's why you need to approach this from the perspective of your understanding of the subject matter.
