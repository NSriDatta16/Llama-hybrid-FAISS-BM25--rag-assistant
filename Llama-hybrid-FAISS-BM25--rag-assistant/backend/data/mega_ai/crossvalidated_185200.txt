[site]: crossvalidated
[post_id]: 185200
[parent_id]: 
[tags]: 
Roots of characteristic equation reciprocal to roots of its inverse

This is probably just as much an algebra question as a time series question (no homework, self study). I'm looking to understand why there is a reciprocal relationship between the roots of the characteristic equation and the roots of the inverse characteristic equation (of a difference equation in a time series context). More specifically, the n-th order autoregressive difference equation $$ y_t = a_0 + \sum_{i=1}^{n} a_i y_{t-i} + \epsilon_t $$ can be written with the lag operator $L y_i = y_{i-1}$ as $$ (1 - a_1 L - \dots - a_n L^n) y_t = a_0 + \epsilon_t\quad. $$ The roots $\alpha_i$ of the characteristic equation (obtained by substituting trial solution $A \alpha^t$ into the homogeneous part of the difference equation) $$ \alpha^n - a_1 \alpha^{n-1} - \dots - a_n = 0 $$ are the reciprocals $L_i$ of the inverse characteristic equation $$ 1 - a_1 L - \dots - a_n L^n = 0 $$ obtained from determining the roots of the lag polynomial above. (This is stated in W. Enders, "Applied Econometric Time Series", 4th edition, p. 42.) What's a quick way to derive this result?
