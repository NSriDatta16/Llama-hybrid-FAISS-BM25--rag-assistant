[site]: crossvalidated
[post_id]: 310778
[parent_id]: 310766
[tags]: 
I see your intention is towards predictive power, not inference. So consider that your pre-processing pipeline should be run separately in each fold during training, otherwise you incur optimistic bias on your performance estimates: what looks like a outlier in the whole dataset might not look like within a traning fold. So if you intend on removing those points, do so through automatized criteria. If the data acquisition was actually faulty (and you have strong reasons to believe so), you are justified removing what seems to be outliers. See Should I report the descriptive statistics in publication before or after outliers removal? You could try your hand on robust statistics though, more specifically robust estimator for linear regression. These are resistant to leverage points, and are completely automatic from the training point of view.
