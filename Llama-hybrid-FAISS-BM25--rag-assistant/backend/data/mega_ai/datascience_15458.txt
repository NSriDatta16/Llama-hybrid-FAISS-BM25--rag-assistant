[site]: datascience
[post_id]: 15458
[parent_id]: 9302
[tags]: 
Given $y_{true}$ , you want to optimize your machine learning method to get the $y_{predict}$ as close as possible to $y_{true}$ . First question: Above answer has explained the background of your first formula, the cross entropy defined in information theory. From a opinion other than information theory: you can examine yourself that first formula does not have penalty on false-positiveness(truth is false but your model predict that it is right), while the second one has penalty on false-positiveness. Therefore, the choice of first formula or second, will affect your metrics(aka what statistic quantity you would like to use to evaluate your model). In layman word: If you want to accept almost all good people to be your friend but willing to accept some bad people become your friend, then use first formula for criterion. If you want to punish yourself accepting some bad people to be your friend,but at the same time your good-people accepting rate might be lower than the first condition, then use second formula. While, I guess most of us are critical and would like to choose the second one(so as many ML package assume what is cross entropy). Second question: Cross entropy per sample per class: $$-y_{true}\log{(y_{predict})}$$ Cross entropy for whole datasets whole classes: $$\sum_i^n \sum_k^K -y_{true}^{(k)}\log{(y_{predict}^{(k)})}$$ Thus, when there are only two classes (K = 2), you will have the second formula.
