[site]: crossvalidated
[post_id]: 343798
[parent_id]: 
[tags]: 
Train/Test Splitting for Time Series

I'm doing product demand forecasting using 3 years' worth of daily sales data. I've built a few models and now I wish to test them. Based on Rob Hyndman's book and this resource , an expanding window walk forward cross validation is the gold standard for evaluating models in a time series context. My question is, what's the most appropriate splitting? Should I train it initially on the first year (365 days) and do the walk forward test on the remaining 2 years (730 days)? What I expect will happen is that the error in forecasting will decrease as the training set grows, meaning the error will be large when the training set is small. Is it valid to train it initially on the first two years instead, and do the walk forward validation on the last year? Thanks and any insight would be appreciated.
