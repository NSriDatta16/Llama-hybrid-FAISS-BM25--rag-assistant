[site]: crossvalidated
[post_id]: 389223
[parent_id]: 
[tags]: 
Trying to test if an increased rate of use decreases total product

TL-DR: The higher the rate of production on my expendable unit, the less overall product it seems to produce in its lifetime. I want to know how best to model this or 20 pages I could read which would tell me how I should model this; to prove or disprove my hypothesis. Full body: My statistics skills have atrophied in my professional career so feel free to refer me to remedial literature as a solution. Here is my problem: I have a unit which refines product and has a limited lifespan. I suspect that the rate at which the product is produced is inversely proportional to the total quantity of product it produces over it's lifespan(within 2-20%). The data I have: Daily product produced Date put online (brand new) Date taken offline (due to failure) My hypothesis is that if the unit produced (for example) 2 units per day it would produce more over all units than if it produced 3 units per day. Since these units run at the whim of production schedules and are subject to other factors such as quality of feed and quality of manufacturing, I am finding it difficult to tease out a solution that seems statistically sound. My current solution is a simple multi variable regression of with $Y=\text{life span}$ , $X_1=\text{average daily usage for those days online}$ , $X_2=\text{total product produced}$ . Immediately typing this out I see Y and X2 should be flipped but I feel like I am not properly accounting for the day to day variations of production rates. Please advise.
