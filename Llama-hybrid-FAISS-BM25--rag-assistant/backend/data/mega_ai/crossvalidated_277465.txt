[site]: crossvalidated
[post_id]: 277465
[parent_id]: 
[tags]: 
Can one leverage the probability difference between the the predicted class vs the original class?

I have P predictors, C classes After performing training on a training partition I run the test partition through my classifier. Say for a particular test instance the predicted class is Cpred with probability Ppred while the original label is Corig and the probability of it being that class is computed to be Porig by the trained classifier. What type of inferences, insights, uses can I draw from (Ppred - Porig)? Some specific questions? Can I use cases where Ppred - Porig >> mean(Ppred - Porig | Corig, Cpred) to look for mislabelled data? Can I use case where Ppred - Porig >> mean(Ppred - Porig | Corig, Cpred) to further partition the Classes into a new Class Corig,pred -- perhaps the original labels are not expressive enough for the underlying phenomenon? How could one interpret Pi,pred - Pi,orig == Pj,pred - Pj,orig where i and j are two instances in the test set but where Pi,pred >> Pj,pred Notes: How is Porig calculated? Both Porig and Ppred are produced by the classifier. If there are C classes -- the Classifier will output P1, ... , Pc probabilities, one for each class. The predicted class will correspond to the argmax of P1 ... Pc OK, so how is Porig different from Ppred? Ppred is the max(P1, ... Pc) while Porig is P of the labeled class that we know apriori See R code below for a simple illustration using the R Example: set.seed(1) str(iris) train
