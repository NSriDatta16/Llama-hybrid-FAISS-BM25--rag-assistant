[site]: crossvalidated
[post_id]: 626155
[parent_id]: 280917
[tags]: 
Difference plots like your figure are indeed sometimes called "modified Bland-Altman plots". As you say, the term “modified” must be added because Bland and Altman recommended against using the comparator or reference measurement $C$ on the horizontal or “x” axis and instead said to use the average of the index measurement $M$ and the comparator measurement, $(M + C)/2$ . Assume that, on average, $M$ and $C$ differ by a constant, regardless of measurement level. A scatterplot of the difference $M-C$ vs. measurement level should be roughly flat. If you use $C$ instead of $(M+C)/2$ for the measurement level, you will get a spurious negative correlation between the difference and the measurement level. In other words, the regression line will have a negative slope even if the difference $M - C$ does not decrease or become more negative with magnitude. Krouwer recommends using $C$ on the hoirxontal or "x" axis if $C$ is truly a precise reference value with small within-subject variance. The plot that you showed looks like the index test always returned a measurement of $8$ , so that, when the reference value was $5$ , the difference was about $8-5=3$ and when the reference value was $30$ , the difference was $8 - 30 = -22$ . I'm guessing the $Corr(M-C,C) \approx -1$ . A test that returns roughly the same number regardless of the true value is useless. Derivation of negative correlation between $M-C$ and $C$ : $$M = b_M + X +e_{M}, \quad e_{M} \sim N(0,\sigma^2_M)$$ $$C = b_C + X +e_{C}, \quad e_{C} \sim N(0,\sigma^2_C)$$ $X = $ `true' value, a random variable from a distribution with variance $\sigma^2_X$ $M = $ index measurement (variance $\tau^2_M = \sigma^2_X + \sigma^2_M$ ) $C = $ comparator measurement (variance $\tau^2_C = \sigma^2_X + \sigma^2_C$ ) $b_M = $ systematic error for the index method $b_C = $ systematic error for the comparator method $Cov(M,C) = \sigma^2_X$ $Var(M-C) = \sigma^2_M + \sigma^2_C$ \begin{align*} Cov(M-C,C) &= Cov(M,C) - \tau^2_C\\ &= \sigma^2_X - (\sigma^2_X + \sigma^2_C)\\ & = -\sigma^2_C\\ Corr(M-C, C) &= \frac{-\sigma^2_C}{\sqrt{\sigma^2_M + \sigma^2_C}\sqrt{ \sigma^2_X + \sigma^2_C}}\\ \end{align*} So the correlation coefficient between M-C and C should be negative. Bland and Altman do not consider the true value $X$ , but they do use the correlation coefficient $\rho$ between $M$ and $C$ . \begin{align*} Cov(M-C, C) &= \rho \tau_M \tau_C - \tau^2_C\\ Corr(M-C,C) &= \frac{\rho \tau_M \tau_C - \tau^2_C}{\sqrt{ \tau^2_M + \tau^2_C - 2\rho\tau_M\tau_C}\cdot (\tau_C)}\\ &= \frac{\rho \tau_M - \tau_C}{\sqrt{ \tau^2_M + \tau^2_C - 2\rho\tau_M\tau_C}}\ \end{align*} If $\tau_M = \tau_C$ , then $$Corr(M-C, C) = -\sqrt{\frac{1-\rho}{2}}$$ A typical value for $\rho$ is 0.98, so a typical value for the correlation is -0.1. In the absence of a genuine association between the difference $M-C$ and measurement magnitude, the slope of a regression line fit to $M - C$ vs. $C$ will still be negative.
