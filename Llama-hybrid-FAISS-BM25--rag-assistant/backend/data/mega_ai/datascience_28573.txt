[site]: datascience
[post_id]: 28573
[parent_id]: 28564
[tags]: 
In normal RNNs, you can train using either back-propagation through time (BPTT) or teacher forcing. With BPTT the network receives as input for each time step the output of the previous time step. In teacher forcing, the network receives the gold data tokens directly; this induces exposure bias on the trained network. With textual GANs, you normally don't feed the gold data to the generator, because the generator is generating the sequence so there is no gold data to use. In the article you refer, they are taking subsequences from real data, feeding them to the generator and having it only generate the final token. Then the discriminator receives the concatenation of the real sequence prefix and the generated final token. This is what they call "teacher helping".
