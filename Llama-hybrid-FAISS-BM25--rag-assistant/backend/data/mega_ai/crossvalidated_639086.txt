[site]: crossvalidated
[post_id]: 639086
[parent_id]: 
[tags]: 
What is the rate of waiting time increase for a M/M/1 queue where $\lambda = \mu$?

I am almost finished reading The Goal , which emphasizes the importance of managing bottlenecks in production. I'm more into service networks than production, but there is a lot to carry over from one to the other. One the lessons is that meeting capacity with demand on average is not enough due to a combination of uncontrolled/predicted variation in demand/service and dependency between events. This brings us to queuing, as an example, which frequently occurs in the services I am interested in modelling. I have simulated a M/M/1 queue in which $\mu = \lambda$ . It is well-known that this is an unstable system; the wait list will tend to get longer and so will the wait times. But at what rate? I don't know an analytic result around this. Here is an example output where $\lambda = \mu = 10$ : Here is an example output where $\lambda = \mu = 1$ : Prima facie it looks something like the growth is logarithmic (first guess) or like a square root (second guess). I am not sure if this hold true at every quantile, or just specific statistics like the maximum or average. It also appears (based on the two cases that were run) that it dependends on the values of $\lambda$ (or equivalent $\mu$ since they are set to be equal).
