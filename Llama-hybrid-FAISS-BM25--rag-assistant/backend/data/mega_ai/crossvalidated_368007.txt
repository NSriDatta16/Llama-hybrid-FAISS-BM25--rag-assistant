[site]: crossvalidated
[post_id]: 368007
[parent_id]: 
[tags]: 
Best easy and straightforward way of computing McDonald's omega in a unidimensional test with 'psych' in R

I'm preparing a masterclass in Psychometrics for a course, and I would like to introduce McDonald's omega coefficient as the proper index for assessing the reliability of a scale. For what I can see, the function omega in package psych is the best way to do it. However, as can be seen in the function help and elsewhere, this function assumes the existence of group factors, implying a certain lack of unidimensionality in the data. In the example I want to put forth, I am assuming unidimensional scales, which actually have a very low number of items. Being the case that the scale is unidimensional, I assume that all the common variance should be explained by the general (and only) factor, thus not being group factor common variances. In this very precise case, I understand that hierarchical omega ( $\omega_H$ ) and total omega ( $\omega_T$ ) should be the same. The problem when using omega with such data is, to my understanding, that there is no simple way to assume scale unidimensionality. Given this is a class in psychometrics and not about programming in R, I would like to have an easy, straightforward way to compute the index. I give an example below of my attempts to solve it, using one of the supplementary material datasets of the book "Predictive HR Analytics, (Edwards, & Edwards): file "Chapter 5 RAW Survey Results.sav" at https://koganpage.app.box.com/s/c6qwtjlzwwtvdlluk7iivowgnaprim1p First attempt: use omega with a "group factor" per item Using the variables Eng1 to Eng4, I call omega with four group factors: library(tidyverse) library(haven) library(psych) hr_data % read_sav hr_data %>% select(starts_with("Eng")) %>% omega(nfactors = 4, fm = "gls", cor = "poly") # Omega # Call: omega(m = ., nfactors = 4, fm = "gls", cor = "poly") # Alpha: 0.9 # G.6: 0.88 # Omega Hierarchical: 0.9 # Omega H asymptotic: 0.91 # Omega Total 1 # # ... (truncated) This solution works because it yields a "group factor" per item, meaning that the general factor accounts for all the common variance, while the group factors actually explain the uniquenessess of each of the items. Thus, all the variance is considered common variance, and $\omega_T$ = 1 as returned by the function. However, in this case, $\omega_H$ should be the proper value of $\omega_H = \omega_T$ (= .9). Second attempt: same strategy, different scale Now, I try the same strategy, with the items pos1 - pos3: hr_data %>% select(starts_with("pos")) %>% omega(nfactors = 3, fm = "gls", cor = "poly") # Omega # Call: omega(m = ., nfactors = 3, fm = "gls", cor = "poly") # Alpha: 0.77 # G.6: 0.73 # Omega Hierarchical: 0.73 # Omega H asymptotic: 0.83 # Omega Total 0.87 # # ... (truncated) # # Warning message: # In GPFoblq(L, Tmat = Tmat, normalize = normalize, eps = eps, maxit = maxit, : # convergence not obtained in GPFoblq. 1000 iterations used. Probably due to lack of convergence (see the warning at the end of the output), this does not give a solution with a "group factor" per item. Therefore, the solution fails, proving it is not a universal way of computing $\omega$ in my use case. Alternative solution: writing a function UPDATE (24/09/2018): (I was using the wrong formula for omega; I updated it, however I still get a different result with the "Eng" scale) Using the output from fa , I could write a function myself, sort of: omega_unidim % colSums %>% raise_to_power(2) err_var % subtract(loadings %>% raise_to_power(2)) %>% colSums omega % divide_by(true_var + err_var) return(omega) } pos_efa % select(starts_with("pos")) %>% fa(nfactors = 1, fm = "gls", cor = "poly", correct = 0) pos_efa$loadings %>% omega_unidim # GLS1 # 0.8117211 (Note: I am assuming that, given I use polychoric correlations, the score variances are 1 for all the items. However, this does not seem to be the same result as $\omega_H$ computed by omega when I use e.g. the Eng1-Eng4 variables, so probably such a function would not even be correct.) eng_efa % select(starts_with("Eng")) %>% fa(nfactors = 1, fm = "gls", cor = "poly", correct = 0) eng_efa$loadings %>% omega_unidim # GLS1 # 0.9284323 The problem with this approach is that I would like to provide the students with readily available tools (in this case, psych ), and avoid cluttering the class with extra R code, functions, and so. Therefore, the question is: What is the most straightforward way of computing McDonald's omega in a unidimensional test in R, if any? Otherwise, what would be the proper way of computing its value in the unidimensional case with polychoric correlations (without much coding)? Thank you so much in advance.
