[site]: crossvalidated
[post_id]: 613133
[parent_id]: 
[tags]: 
How to subset a binary matrix to maximize the number of unique elements while minimizing duplicates?

Iâ€™m trying to optimize a matrix by subsetting rows and then performing a calculation on the subsetted rows. The calculation is representing each of the columns exactly once and having as few duplicates as possible while also including as many rows as possible. To be clear, the parameters to optimize are the following: p = Number of columns detected (More is better) q = Number of duplicate rows (Less is better) r = Penalty on including a duplicate row to increase p Here is a simple example where there is a clear answer where rows [2,3,4] will be chosen (row 0 is dropped because row 2 is better): A = [ [1,0,0,0,0], [0,0,0,0,0], [1,0,1,0,0], [0,1,0,1,0], [0,0,0,0,1], ] p = 5 (all columns are represented) q = 0 (no duplicates) There will not always be a perfect combination and sometimes it will need to add a penalty (include a duplicate q) to add to the number of columns represented (p). Weighting this will be important which will be done by r. B = [ [1,1,0,1,0], [0,0,0,0,0], [1,0,0,0,1], [0,0,1,0,0], [0,0,0,0,1], ] Best combination is [0,2,3] P = 5 (all columns detected) q = 1 (1 duplicate) Lastly, there will sometimes be 2 or more subsets that have the best combination so it should include all best subsets: C = [ [1,0,0,1,0], [0,1,1,0,1], [0,1,0,0,1], [1,0,0,1,0], [0,0,0,0,1], ] In this one, I spot a few good options: [0,1], [1,3] Other than doing bruteforce of all combinations of rows, can someone help me understand how to start implement this while leveraging any of the algorithms in Scikit-Learn, SciPy, NumPy, or similar in Python? More specifically, what algorithms can I use to optimize the rows in a NumPy array that maximizes p , minimize q weighted by r (e.g., score = p - q*r )?
