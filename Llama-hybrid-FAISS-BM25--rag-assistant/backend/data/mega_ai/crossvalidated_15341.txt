[site]: crossvalidated
[post_id]: 15341
[parent_id]: 15285
[tags]: 
Since in your predictive model the design is very like in discrete choice models within the case of binary response variables (logistic regression for example would be relevant here), the problem could be approached in the same manner. First of all you may consider the generalized $R^2$. Note the last suggestion to scale the $R^2$ by the $R^2_{max}$ that insures the modified coefficient is below $1$. You may also consult the classical text book in econometrics (I used Greene Econometric Analysis Chapter 21.4.5, but a link from SAS help page seems also relevant) regarding the goodness-of-fit for binary response models: McFadden's likelihood ratio index $LRI = 1 - \frac{\log L(\theta)}{\log L(0)}$ the coefficient is pointed to have no clear interpretation though, but this one is a common build-in solution in most of the statistical software Another interesting suggestion is to look either on the average probability of correct predictions as in Ben-Akiva and Lerman: $R^2_{BL} = 1/n \sum_i (y_i \hat F_i - (1- y_i)\hat F_i)$, where $\hat F_i$ is the estimated probability (the estimated value you use to compare with the threshold $0.5$). In unbalanced samples when the number of wins is much different from the number of losses the $R^2_{BL}$ underestimates the smaller group, so you may introduce a measure that compares average correct and incorrect cases $\lambda = (average \hat F_i | y_i = 1) - (average \hat F_i | y_i = 0)$ Cramer's $\lambda$ heavily penalizes incorrect answers. Note that for the unbalanced datasets it is recommended to be cautious about the naive threshold value of $0.5$ since in that case a smaller group risks to be unpredicted too often. The other suggestions for the $R^2$ augmentation are in the abovementioned SAS help page (to be frank, I have never used one thus has no clear opinion regarding them, but the Cragh-Uhler 1 is exactly the generalized coefficient of determination from the wiki page).
