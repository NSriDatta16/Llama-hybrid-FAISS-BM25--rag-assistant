[site]: crossvalidated
[post_id]: 43383
[parent_id]: 38940
[tags]: 
I would use the second-order Akaikeâ€™s Information Criterion ($AIC_c$) for model selection, which is $AIC$ corrected for small sample size using a bias-correction term. $$ AIC = -2ln(L)-2k $$ $$ AIC_c = AIC+\frac{2k(k+1)}{(n-k-1)} $$ where $ln(L)$ is the log-likelihood, $k$ is the number of parameters, and $n$ is the sample size. Sometimes $AIC$ can perform poorly when the ratio of sample size to the number parameters in the model is small (Burnham and Anderson 2002). $AIC$ or $AIC_c$ can be recaled to $\mathsf{\Delta}_i=AIC_i-minAIC$ where the best model will have $\mathsf{\Delta}_i=0$. Further, these values can be used to estimate relative strength of evidence ($w_i$) for the alternative models where: $$ w_i = \frac{e^{(-0.5\mathsf{\Delta}_i)}}{\sum_{r=1}^Re^{(-0.5\mathsf{\Delta}_i)}} $$ This is often refered to as the "weight of evidence" for model $i$ from the model set. As $\mathsf{\Delta}_i$ increases, $w_i$ decreases suggesting model $i$ is less plausible. Also, the weights of evidence for the models in a model set can be use in model averaging and multi-model inference. References: Burnham, K. P., and D. R. Anderson. 2002. Model selection and multimodel inference: a practical information-theoretic approach. Second edition. Springer, New York, USA. Anderson, D. R. 2008. Model based inference in the life sciences: a primer on evidence. Springer, New York, USA.
