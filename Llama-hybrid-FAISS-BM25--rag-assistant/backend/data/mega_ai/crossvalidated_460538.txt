[site]: crossvalidated
[post_id]: 460538
[parent_id]: 459770
[tags]: 
The key here is to understand what you are trying to achieve. Any statistical model will fit its training data better than testing data and if this is unacceptable for your case all you can really do is fit a null model. In many cases, all we care about is the testing data performance. We don't use the training performance as an indication of model performance and just ignore training performance entirely. "Overfitting" generally refers to the point where the model is so complex that the performance on testing data is compromised (you have not reached this point with your model yet). This would be more complicated if the training and testing data weren't entirely independent (e.g. the data were clustered, or time series data, or similar) but in the case of independent observations. Separately, you might wish to penalise the complexity of the model (in other words, you are prepared to accept slightly poorer testing performance if the model has fewer parameters in it). This will lead to less complex models which usually means a smaller difference between training and testing performance.
