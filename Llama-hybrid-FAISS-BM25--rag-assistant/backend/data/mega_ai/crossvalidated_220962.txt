[site]: crossvalidated
[post_id]: 220962
[parent_id]: 179496
[tags]: 
In addition, to the paper by Le Cun outlined in the comments, two more recent practical guides by pioneers in the area are: Practical Recommendations for Gradient-Based Training of Deep Architectures. Yoshua Bengio. 2012. A Practical Guide to Training Restricted Boltzmann Machines. Geoffrey Hinton. 2010. Both of these come from the deeplearning.net reading list, and they are also featured in a book "Neural Networks: Tricks of the Trade". Two other resources I've found helpful are: Andrej Karpathy's course notes for Stanford 231n on Convolutional Neural networks esp. Part 1 , Part 2 , Part 3 . Stochastic Gradient Descent Tricks. Leon Bottou. 2012. This is written as an update to LeCun et al.'s paper More specific recommendations might depend on the problem domain, the network architecture and the type of data you're working with.
