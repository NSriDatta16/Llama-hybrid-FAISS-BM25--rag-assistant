[site]: crossvalidated
[post_id]: 632184
[parent_id]: 168982
[tags]: 
Zheng, B. and A. Agresti. 2000. Summarizing the predictive power of a generalized linear model. Statistics in Medicine 19: 1771â€“1781 gave guarded recommendation of the square of the correlation between observed and predicted responses as a measure that can be applied to generalized linear model results. You need to read the paper before you can fairly dismiss it. For example, consider a logit or logistic regression. The observed outcome is a (0, 1) indicator variable. The predicted outcomes are probabilities between 0 and 1. So, we can calculate the correlation between observed and predicted outcomes and square it. An advantage for many researchers (and their readers) is that they are already familiar with ideas of correlation and $R^2$ . A disadvantage is that this measure doesn't correspond to figures of merit (e.g. likelihood) used by typical logit routines in fitting or reporting fits. But so long as the $R^2$ measure is treated as mostly descriptive or heuristic, no great harm is done. Watch out: for every statistical person who thinks this measure might be of some use or interest, there is likely to be another statistical person who thinks it is bogus, misconceived, and the work of the devil. The other answers are all firm, not to say dogmatic, that there is little or no use for such a measure, but here is a paper in a well-regarded journal saying the opposite. There would perhaps be wider agreement that taking $R^2$ beyond classical linear regression is fraught with various analytical and practical perils. In fact, using $R^2$ within classical linear regression is fraught with perils -- as sometimes useless models enshrining banal or nearly tautological results show high $R^2$ and sometimes interesting or helpful models show low $R^2$ . In many fields of social or medical science, for example, high $R^2$ would be suspect as pointing to a very silly question, a ridiculously over-fitted model, or at worst faked data.
