[site]: datascience
[post_id]: 49331
[parent_id]: 49330
[tags]: 
Basically, the two methods you are proposing are the same. The first one is computationally more consuming, but they are the same. In the first method you are calculating $\sigma$ generating possible values of random variable with already the same $\sigma$ you have had historically. This is the same as calculating $\sigma$ with all the historical data you have. In the second method you are doing a stimation with limited data, this is the correct way unless you have sufficient amount of data to estimate a GARCH model. A GARCH model is a statistical model for time series data that describes the variance of the current error term or innovation as a function of the actual sizes of the previous time periods' error terms. Meaning: $\sigma_t^2 = w+\alpha_1\epsilon_{t-1}^2+...+\alpha_q\epsilon_{t-q}^2+\beta_1\sigma_{t-1}^2+...+\beta_p\epsilon_{t-p}^2$ This model requires a sufficient amount of data and knowledge on time series analysis, of the two options you posted, I would use the second with as much data as possible.
