[site]: crossvalidated
[post_id]: 600676
[parent_id]: 
[tags]: 
Using natural spline in glmnet

I want to ask if it is possible to include a natural spline(as one predictor) in the lasso model. When I do that in glm model, I can use ns() function on the predictor side. I came across the following post mentioning adding the base function to the X matrix. Spline regression with many features in R I used the data from this notebook https://www.kaggle.com/code/floser/glm-neural-nets-and-xgboost-for-insurance-pricing/notebook My code for producing the design matrix is as follows: splined = ns(train.DrivAge, df = 4) splined_df = as.data.frame(splined) X = cbind(train,splined_df) X = X%>% select(-ClaimNb,-Area,-Exposure,-DrivAge) X = model.matrix(~.,data = X ) set.seed(1) cv.lasso =cv.glmnet(x = X, y = train.ClaimNb, weights = train$Exposure, family = "poisson", alpha = 1, nfolds=20) However, I am not convinced that this method will work because if we include the spline base function in X and allow glmnet to estimate the coefficients, the spline may not be continuous as we don't impose the continuity in X. I took a look at the output of the ns() function and found that it has knot, degree and intercept the information. I think ns() output includes more information than just the base function. Unlike the glm function where we can directly use ns() function(including all the continuous constraints), in glmnet we can only estimate the coefficients based on the truncated cubic base function. The continuous constraint information is lost in beta estimation. That will cause the spline of different pieces not able to connect to each other. The coefficients I got for the glmnet with ns spline are as follows. I think the coefficients should keep decreasing but the coefficient corresponding to '4' is higher than others. 1 4.995433e-01 2 2.402127e-01 3 3.476267e-01 4 1.347808e+00 Could you let me know your thoughts? Is there any way to include natural spline in glmnet?
