[site]: datascience
[post_id]: 76916
[parent_id]: 76909
[tags]: 
Imho the "cleanest" option would be to train a probabilistic model on the original categorical target, then obtain the predicted probabilities for every category as the final "predictions". By "training on the original target" I mean designing each instance as an event, e.g. in order to represent that 7/10 people select category A there would be 7 instances where the target is category A out of 10 instances in total. The most simple option is Naive Bayes, but depending on the data it tends to always predict extreme probabilities, which would defeat the purpose. An ad hoc Bayesian model could give very good results but it's probably more work to design it, depending on the features.
