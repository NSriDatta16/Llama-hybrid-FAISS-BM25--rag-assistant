[site]: crossvalidated
[post_id]: 621219
[parent_id]: 
[tags]: 
Prior estimation in Dynamic (sequence to sequence) Variational Autoencoders (DVAE) with LSTMs

I am trying to implement a sequence-to-sequence variational autoencoder that consists of two parallel sequence encoders. One of the encoders is based on a standard normal prior as in the vanilla vae (1). The other encoder uses a prior parameterised by another LSTM which is common in dynamical vae (DVAE) literature. As an example there are two papers S3VAE (2) and TSDSAE (3) that state: Besides, we adopt a trainable LSTM to parameterize the prior of the dynamic variable (2) and For the transition network pθ(zt|z respectively. My understanding is that the "prior" (or transition) RNN networks estimate a prior mean and log-variance that is then used for the reparameterization trick of the actual encoder. Therefore instead of having: $$ z = \mu +log\sigma^2 \cdot \epsilon \text{ where } \epsilon\sim\mathcal{N}(0,1)$$ as is the case for the vanilla vae we have: An LSTM prior network followed by dense layers that output $$\mu_{prior}$$ and $$log\sigma_{prior}^{2}$$ A reparameterization where the LSTM encoder has estimated another mean and prior and a resulting reparameterization of: $$z = \mu + log\sigma^2\cdot \epsilon' \text{ with } \epsilon'\sim\mathcal{N}(\mu_{prior},log\sigma_{prior}^{2})$$ . My first question is if my conceptual understanding makes sense, mathematically and how could I prove that. Algorithmically, based on the paper descriptions it may make sense but mathematically I don't see any difference from the vanilla case other than using an LSTM to compute the prior quantities. Additionally, except for the quotes that I added above, there is no actual explanation of how these prior networks are implemented. Could someone that has worked with DVAEs explain how the prior LSTM works? Currently in my case I am using the following: An LSTM to process the data that also along with the final output exports all the intermediate hidden states. I am passing the LSTM output to two dense layers to extract a mean and a logvariance for z I am using the hidden states and pass them onto the prior-LSTM that is followed by two dense layers for the prior mean and log-variance. Can someone verify whether this is correct/makes sense? As a side-note the implementation for the latter case has issues with exploding gradients and its respective KL divergence has increasingly large values that result to nan at some point during training. References (1) Diederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. In 2nd International Conference on Learning Representations, ICLR 2014, 2014. URL https: //openreview.net/forum?id=33X9fd2-9FyZd. (2) Yizhe Zhu, Martin Renqiang Min, Asim Kadav, and Hans Peter Graf. S3VAE: Self-Supervised Sequential VAE for Representation Disentanglement and Data 64 REFERENCES Generation. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 6537–6546, 2020. doi: 10.1109/CVPR42600.2020.00657. S3VAE URL . (3) Luo, Y. J., Ewert, S., & Dixon, S. (2022). Towards Robust Unsupervised Disentanglement of Sequential Data - A Case Study Using Music Audio. IJCAI International Joint Conference on Artificial Intelligence, 3299–3305. TSDSAE URL
