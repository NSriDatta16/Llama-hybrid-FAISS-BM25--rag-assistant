[site]: crossvalidated
[post_id]: 399776
[parent_id]: 399745
[tags]: 
I think this is a general property of sparse features, not just these models. A similar thing surprised me in my own research, when I had some features that were both very rare and very predictive compared to the others, and the math for my model showed the rare ones to be fairly worthless. For the rare occasions when you're classifying an instance that has that feature, the feature is amazing! But overall, on average across all features, it's not as helpful as those that are relevant for all instances. I'd imagine this can be formalized in ways that would depend on the classifier's optimization function and/or loss function. But for hand-wavy intuition, I think it's similar to the entropy of a Bernoulli variable , in which p = P(feature = 1) and -log(p) = how strongly correlated the feature is with the class label. With sparse features, there's a small chance of a lot of info for classification, but overall a variable is more informative if it gives a small amount of information every time.
