[site]: crossvalidated
[post_id]: 643923
[parent_id]: 
[tags]: 
How can we implement pipelines using LLMs that can consider information from the internet in their responses?

Let us suppose that we are implementing a data processing pipeline based on LLMs and, in some part of the process, we need to search the internet for finding relevant information regarding some topic, in a way that the LLM can use the retrieved information from the internet as context for building its response. How can we do that? I know that chatGPT and Gemini can do that. But I would like to understand how we can implement that feature using our custom pipelines, using open LLMs, for example. I think that we can use a custom query string and, in the specific part of our pipeline, we can call a search engine with this string, collecting information from the top sites, an using that as context in the prompt of the LLM. Does this make sense?
