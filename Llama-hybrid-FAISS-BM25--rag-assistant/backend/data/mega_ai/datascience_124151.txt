[site]: datascience
[post_id]: 124151
[parent_id]: 123087
[tags]: 
In the case of a mel-spectrogram preprocessing, the Short-Term Fourier Transform (STFT) followed by a mel-filterbank reduction and log-scaling is used. It transforms the 1 dimensional audio waveform into a 2d representation of time-frequency, with a particular time and frequency resolution dependent on the mel/STFT parameters. It is possible to use a neural network to learn a conceptually similar (but potentially more powerful) transformation. The most straightforward is to create a filterbank with learnable weights. There are several examples of this in the literature, for example: MatchboxNet: 1D Time-Channel Separable Convolutional Neural Network Architecture for Speech Commands Recognition SincNet This can be beneficial in an embedded/microcontroller/TinyML setting, because a neural network can be quantized to use 8-bit integer operations which has SIMD available on multiple architectures (ex: ARM Cortex M4F), whereas FFT is not as easily done with reduced precision. This makes it theoretically possible that a learned filterbank can be more computationally efficient. But it will probably require careful tuning of hyperparameters.
