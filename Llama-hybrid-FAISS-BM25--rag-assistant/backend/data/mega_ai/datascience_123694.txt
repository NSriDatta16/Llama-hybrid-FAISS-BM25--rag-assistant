[site]: datascience
[post_id]: 123694
[parent_id]: 123691
[tags]: 
Definitely, the input type of data can affect your autoencoder's performance. On one side, the bag-of-words ignores context, but it is easy to train. On the other side, Word2Vec captures the semantic relationships, but again it's not that easy to train the model since it will need a lot of data and resources. You may try One-hot encoding, since it's simple to use and usually used in autoencoders. In general, there isn't necessarily a best choice here; what works best will depend on factors like your specific task requirements, available computational resources etc., so it's usually worth trying out several options if possible.
