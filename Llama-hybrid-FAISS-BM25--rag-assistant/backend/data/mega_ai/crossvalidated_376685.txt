[site]: crossvalidated
[post_id]: 376685
[parent_id]: 376682
[tags]: 
Every model has this problem. For example, logistic regression implies the constant log odd ratio. For binomial distribution, the variance is $p(1-p)$ for one trial. So the different predict value of p implies the different variance. But in the model fitting process this problem is resolve by WLS (weighted least square). For $\hat p = X\hat \beta$ , it is possible for some $X$ , the $\hat p$ can go lower than 0, or higher than 1, especially when the model is used to predict the probability using the $X$ s that is not in the dataset used to build the model.
