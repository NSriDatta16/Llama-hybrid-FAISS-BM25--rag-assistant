[site]: crossvalidated
[post_id]: 481608
[parent_id]: 
[tags]: 
What is the intuitive explanation of the expectation of a mean and variance value in Bishop's PRML book?

In Bishop's Pattern Recognition and Machine Learning book, there are two equations stated as follows. Equation 1.57: $\mathbf{E}[\mu_{ML}] = \mu $ and Equation 1.58: $\mathbf{E}[\sigma^2_{ML}] = (\frac{N-1}{N})\sigma^2$ where $\mu_{ML}$ and $\sigma^2_{ML}$ is the maximum likelihood solution for the mean, and variance. My question is that since $\mu_{ML}$ and $\sigma^2_{ML}$ are already functions of the $N$ dataset, what does it mean when we take the expectation of $\mu_{ML}$ and $\sigma^2_{ML}$ with respect to the dataset again as in the equations 1.57 and 1.58 above? I understand how to prove the equations, but I don't understand what do they mean? Thank you in advance.
