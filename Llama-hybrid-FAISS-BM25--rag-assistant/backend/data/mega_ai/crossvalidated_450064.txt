[site]: crossvalidated
[post_id]: 450064
[parent_id]: 401456
[tags]: 
Results from newer simulations with the code used can be found here: https://www.r-bloggers.com/part-6-how-not-to-validate-your-model-with-optimism-corrected-bootstrapping/ . Zipped code and results can be found on the source website. Note that, the same bias can be seen using; 1) my implementation, 2) caret implementation. It is interesting the random forest model gives much more bias even with more 'usual' dimensions, this confirms that the optimism corrected bootstrapping procedure has a fundamental problem with it which methods such as repeated cross validation do not have. The bias depends on the dimensionality of the data and the type of model used, however, under a range of conditions it will always give a very positive result, even if the data is completely random. Be warned of this method, if in doubt, run the code on this page yourself, it is a pretty straightforward experiment.
