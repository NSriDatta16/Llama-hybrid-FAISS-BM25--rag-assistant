[site]: crossvalidated
[post_id]: 315429
[parent_id]: 
[tags]: 
Unsupervised learning methods on unlabeled data?

I'm facing with a challenge of unsupervised classification of unlabeled data. The case is, I have circa 1.2 million vehicle warranty claims, and must develop a classification model to tell whether one claim is fraud or not, or to predict a claim's fraud probability. Now I have got a wide analytical base table including variables about the claim's defects and corresponding material and labor fees, about the car's characteristics such as retail price, color, car age, distance and warranty history, about the dealer's warranty and service history and fees, about 300 variables in total. However, among the 1.2 million observations, only 4000 are labeled as fraud or normal, and the labeled dataset is not a simple random sample, but a collection of somehow believed-to-be suspicious claims, mainly selected based on dealer information. So I cannot simply use supervised learning. I'm not that into clustering because I cannot explain or evaluate the outcome. I've tried PCA: one principle component can cover 95% of the information, and the component is mainly highly correlated with dealer history, so it can be the difference among dealers instead of claims that counts. I've also tried some kind of label-propagation, and labeled more data based on my small labeled dataset. Then I developed a decision tree on these labeled data, and found that most important features are also the ones about dealers. So I think the result is not convincible, since my initially-labeled dataset was selected based on dealer history. So my questions are: 1) Is label-propagation or PU reasonable in this case? 2) Any experience on which unsupervised learning method should I use?
