[site]: datascience
[post_id]: 35871
[parent_id]: 35869
[tags]: 
You don't. It's random, you shouldn't control it. The parameter is only there so we can replicate experiments. In cases of algorithms producing hugely different results with different randomness (such as the original K-Means [not the ++ version] and randomly seeded neural networks), it is common to run the algorithm multiple times and pick the one that performs best according to some metric. You can do that by just running the algorithm again, without re-seeding. But do not treat the random seed as something you can control. If you want your model to be able to be replicated later, simply get the current seed (most operating systems use processor clock time I think) and store it. Choosing a random seed because it performs best is completely overfitting/happenstance. Note this all assumes a decent implementation of a random number generator with a decent random seed. Some pairs of RNG and seed may produce some predictable or less than useful random sequences.
