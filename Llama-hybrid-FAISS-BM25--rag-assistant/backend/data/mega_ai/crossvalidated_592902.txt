[site]: crossvalidated
[post_id]: 592902
[parent_id]: 
[tags]: 
VQ-VAE objective - is it ELBO maximization, or minimization of the KL-divergence between the posterior and its approximation?

I'm reading two descriptions of the VQ-VAE objective: Kingma claims in page 18 that we want to maximize the ELBO, and shows that it can be written as $ELBO = logp_{\theta}(x) - KL(q_{\phi}(z|x)||p_{\theta}(z|x))$ , the marginal likelihood of the data - the KL divergence between the approximate posterior and the true posterior of the latent variables. Rocca claims that we just want to minimize the same $KL(q_{\phi}(z|x)||p_{\theta}(z|x))$ Kingma mentioned, but doesn't mention ELBO or the marginal likelihood of the data. Are they saying the same thing? if so, why? is it because the marginal likelihood of the data is not a function of our variational parameters $\phi$ ? which is the "true" objective and which is just a math development? I need a good intuition on what is it that we're optimizing here...
