AI data centers use freshwater resources required to operate and cool the infrastructure supporting artificial intelligence (AI) technologies. Data centers housing AI workloads, such as training large language models and processing inference tasks, consume water directly for cooling systems and indirectly through electricity generation and supply chain processes. This consumption has escalated with the rapid growth of AI, driven by advancements in generative models like GPT-3 and increasing global demand for AI applications. As of 2025, AI data centers represent a growing environmental challenge, competing with other sectors for limited water resources amid climate change and population pressures. The environmental impact of AI data centers extends beyond water use to include energy demands and carbon emissions, but water scarcity has emerged as a critical concern. Studies highlight that AI's water footprint is often underestimated, with mechanisms involving evaporative cooling and power production contributing to substantial withdrawals and consumption. Efforts to mitigate these impacts are underway, but transparency and regulation remain inconsistent across regions. Mechanisms of Water Consumption AI data centers consume water through direct and indirect mechanisms. Direct consumption primarily occurs via cooling systems, where water is used to dissipate heat generated by servers and GPUs during intensive AI computations, such as model training and inference. Evaporative cooling towers evaporate water to cool air, leading to losses of up to 80% through evaporation, with the remainder discharged as warm, potentially contaminated wastewater. Metrics like Water Usage Effectiveness (WUE) measure onsite efficiency, averaging 1-9 liters per kWh, varying by climate and technology. Closed-loop systems recirculate water, reducing losses, while advanced methods like liquid immersion cooling submerge servers in dielectric fluids to minimize water needs. Indirect consumption arises from electricity generation, where thermoelectric and hydropower plants use water for steam production and reservoir evaporation, consuming 0.18-2.0 liters per kWh on average. Scope-3 impacts include ultrapure water for semiconductor manufacturing, with low recycling rates (23-45% in some facilities). AI workloads amplify these mechanisms due to higher heat loads from dense GPU clusters. Scale and Projections The scale of water consumption in AI data centers is substantial and growing. In the U.S., data centers consumed approximately 66 billion liters directly in 2023, tripling from 2014 levels, with indirect use adding hundreds of billions more. Globally, major providers like Google and Microsoft reported over 19.5 million and 6.4 million cubic meters in 2022, respectively, with annual increases of 17-34%. Training a model like GPT-3 requires 5.4-15 million liters, while a single AI query can use 16-60 milliliters, scaling to billions of liters for widespread use. Projections indicate rapid escalation: Global AI-related water withdrawal could reach 4.2-6.6 billion cubic meters by 2027, equivalent to half the UK's annual consumption, with U.S. AI alone potentially quadrupling to 150-280 billion liters by 2028. By 2030,data center energy use may hit 1,050 TWh, driving parallel water demands, potentially increasing 11-fold in some scenarios. Geographical and Regional Impacts Water consumption varies geographically, exacerbating stress in arid regions. In the U.S. Southwest (e.g., Arizona, Texas), data centers like Google's in Mesa consume up to 4 million gallons daily, straining Colorado River supplies and competing with agriculture. In the West, facilities in Phoenix and Oregon use 177-355 million gallons annually, representing 10-29% of local municipal water. Northern Virginia's 300+ centers withdrew 2 billion gallons in 2023, a 63% rise since 2019. Internationally, India's Bengaluru centers use 8 million liters daily amid severe shortages, while Sydney, Aust