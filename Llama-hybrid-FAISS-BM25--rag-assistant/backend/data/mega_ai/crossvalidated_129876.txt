[site]: crossvalidated
[post_id]: 129876
[parent_id]: 127247
[tags]: 
I looked into the in the case of a 1D GP and the parametric function $y = f(x)$ a few months ago. This was my findings: In order to get the probability of a function, $y = f(x)$, we have to perform a line integral through the probability distribution provided by the GP. This line integral would therefore be the probability of the curve given the GP. Unfortunately, we can't do this easily as there is no way of writing the GP in closed form to perform this operation. For this reason a sample based approach is the best option (or at least this was what I believed). I thought of to methods to consider. The prediction of the GP at a point is $O(n^2)$ for every additional prediction after training, so if $n$ is small it is cheep to sample the function and the GP at many $x$'s and Monte Carlo methods make sense. When $n$ is very large it is expensive to perform many samples. In this case it makes sense to perform bayesian quadrature to estimate this line integral. In this situation I looked at using normal BQ sampling policies but did think at the time that there maybe an opportunity for novel acquisition functions for this exact situation.
