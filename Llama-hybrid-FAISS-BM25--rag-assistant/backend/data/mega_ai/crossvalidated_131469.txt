[site]: crossvalidated
[post_id]: 131469
[parent_id]: 131455
[tags]: 
There are several ways to generate random values from a distribution, McMC is one of them, but several others would also be considered Monte Carlo methods (without the Markov chain part). The most direct for univariate sampling is to generate a uniform random variable, then plug this into the inverse CDF function. This works great if you have the inverse CDF, but is troublesome when the CDF and/or its inverse are hard to compute directly. For multivariate problems you can generate data from a copula, then use the inverse CDF method on the generated values to have some level of correlation between variables (though specifying the correct parameters to the copula to get the level of correlation desired often requires a bit of trial and error). Rejection sampling is another approach that can be used to generate data from a distribution (univariate or multivariate) where you don't need to know the CDF or its inverse (and you don't even need the normalizing constant for the density function), but this can be highly inefficient in some cases taking a lot of time. If you are interested in summaries of the generated data rather than the random points yourself, then importance sampling is another option. Gibbs sampling which is a form of McMC sampling lets you sample where you don't know the exact form of the multivariate distribution as long as you know the conditional distribution for each variable given the others. There are others as well, which is best depends on what you know and don't know and other details of the specific problem. McMC is popular because it works well for many situations and generalizes to many different cases.
