[site]: crossvalidated
[post_id]: 610981
[parent_id]: 
[tags]: 
Boruta followed by LightGBM for feature selection

Assume that we have a high-dimensional data with a few samples. We want to select a minimum set of best features from this dataset using LightGBM feature importance. This is because of an external restriction that we need to limit the number of features that are used in the final model. We want to select features using LightGBM feature importance vectors. I see this question about applying Boruta before LASSO for feature selection. In the comments, someone referred to this question that shows that features that are important for a non-linear model (such as the random forest applied in Boruta) may not be important for a linear model like LASSO. What about if we use LightGBM as the second step of feature selection after running Boruta? Can this have any benefits compared to just running LGBM without running Boruta?
