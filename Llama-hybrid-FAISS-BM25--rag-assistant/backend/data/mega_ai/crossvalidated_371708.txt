[site]: crossvalidated
[post_id]: 371708
[parent_id]: 371619
[tags]: 
Honestly, this is quite a funny question! My two cents: Usually, one might use exponential smoothing to obtain a "mean" series or a trend and it has a well defined structure. A lot of times, the smoothing parameter is chosen by eye-balling a graph, to satisfy some kind of a need the modeller has in his mind (e.g. perhaps s/he needs the smoothing to account for just the time series trend, other times, they might also be interested in capturing the seasonality, etc.). Here, perhaps there's no explicit "learning" (does human enforced learning count? Hmmmm...) On the other hand, one might express a clear objective function (e.g. minimising the sum of squared forecast errors $\sum (y_i - \hat y_{i|i-1})^2$ ), and here, parameters are optimised to minimize the objective. I'd argue this is would be "learning" in the traditional sense. Minimising any objective, by definition, will improve the "loss" or whatever the objective is, so the argument that there's no incremental "gain" doesn't hold up. Regarding the AIC/BIC, aren't all of these some kind of penalised likelihood approximations? You're maximising some kind of a penalised likelihood, in other words, minimising the negative of a penalised likelihood, which is the objective here.
