[site]: crossvalidated
[post_id]: 156752
[parent_id]: 156743
[tags]: 
The short answer: back-propagation through time. Basically, you can unroll a recurrent neural net and turn it into a feedforward model. You can do this with all sorts of architectures. The architecture that you are describing has been done many times. For more information on backprop through time: https://www.google.com/url?sa=t&source=web&rct=j&url=http://deeplearning.cs.cmu.edu/pdfs/Werbos.backprop.pdf&ved=0CCsQFjACahUKEwjYuP-44YvGAhWGfpIKHQlyAIM&usg=AFQjCNH6wqddTQOqpIg4_r_kNIz2tV346A&sig2=1DXkilm72s1YphHZAKtv7g For Yann LeCun's course on deep learning (look for recurrent neural nets) http://cilvr.cs.nyu.edu/doku.php?id=deeplearning2015:schedule For video lectures: http://techtalks.tv/deep-learning-nyu-spring-2015/
