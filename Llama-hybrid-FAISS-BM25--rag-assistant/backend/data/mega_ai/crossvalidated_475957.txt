[site]: crossvalidated
[post_id]: 475957
[parent_id]: 475567
[tags]: 
Well, let's think at what those numbers actually mean. If we take feature g for example, we know that our model relies on it a bit. So much that if you shuffle its values when making predictions on train data, your model performance drops by around $0.002$ (if I am correct). However, when we do the same thing and shuffle it before predicting unseen data, the model performace is on average unchanged, which means that the feature has no predictive power on your target, and that the importance it has with training data comes from using some pattern of your training data that does not generalize (aka, you are overfitting ). Random forests tend to build very deep trees (possibly, up to a point where no split is possible). This means that even if you have a feature that is just white noise some trees will end up using it for splits at some point because they will see some pattern in it. This means that overall, it is likely even for noise features to have a positive permutation importance on the training data - and this is why the permutation importance you should really care about is on you validation set! Now, what should you do next? Random Forests are somewhat resistant to this kind of overfitting, and having a few variables that contain only noise is not too detrimental to the overall performance, as long as their relative importance (on the training data) is not excessive, and there is not too many of them. However, as you now know that those features are useless for your regression (and in general as good practice), the best option would be to remove them and retrain your model.
