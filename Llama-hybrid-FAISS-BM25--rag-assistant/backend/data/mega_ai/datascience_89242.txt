[site]: datascience
[post_id]: 89242
[parent_id]: 
[tags]: 
Machine learning model (neural network or SVM) for unequal feature matrices size

I have feature matrices obtained from visual bags of words model for various dictionary sizes. Example, Nx5, Nx10, …., Nx15000. Where N is the number of samples and 5, 10, …15000 are the visual vocabulary or dictionary size or feature vectors size. There are classification labels for each samples. There are 13 methods (SIFT, SURF, BRISK and others) to extract the feature descriptors which are eventually used in visual bags of words to encode the images to obtain the feature vector. Also, there are 13 different dictionary sizes 5, 10 to 15000. If I had only one method and one visual vocabulary, I could have created one multi-class classifier. But, here I have 13 methods and for each of them, there are 13 visual vocabulary sizes. Thus, making 169 classifiers if I want to try to train machine learning models individually. This makes things cumbersome to present. So I would like to ask you if there is some method where I can combine these unequal Nx5, Nx10, …., Nx15000 feature matrices to have one classifier model for each 13 different feature descriptors, instead of having 169 classifiers. Please let me know if you have any suggestions.
