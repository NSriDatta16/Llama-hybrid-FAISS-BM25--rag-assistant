[site]: crossvalidated
[post_id]: 577192
[parent_id]: 
[tags]: 
My Neural Network is not learning

Good day for everybody. My name is Brayan, I am mechanical engineer student, in this moment I have a problem with my first neural network. The problem is: I found in kaggle a dataset (50 datas) about 3D printing parameter settings in FDM process and their relationship with mechanical properties. My objecive is predict mechanical properties, so, I have a regressión problem. I have used hyperparameter tuning with functions like HPARAMS and Keras Tuner. I found the optimal architecture of my neural network, is the next: lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay( 0.01, decay_steps=500, decay_rate=1, staircase=False) def get_optimizer(): return tf.keras.optimizers.SGD(lr_schedule) model = Sequential() # Creación de capas model.add(Dense(380, input_dim = 9, kernel_regularizer=regularizers.l2(0.01), activation = 'sigmoid')) model.add(Dropout(0.64)) model.add(Dense(3, kernel_regularizer=regularizers.l2(0.016), activation='relu')) opt = get_optimizer() model.compile(optimizer=opt, loss='mean_squared_error', metrics=["mae"]) # Entrenamiento model_history = model.fit(x_train_norm, y_train, validation_data=(x_test_norm, y_test), batch_size = 4, epochs = 20000, verbose=1) print("Entrenamiento Finalizado") The model converge fast, but in a few epochs all parameters doesnt change with the time (Loss, Val Loss, MAE, Val MAE) Last values are: Loss: 261.76 mae: 7.70 val_loss: 550.52 val:mae: 10.68 I don´t have idea how can I improve the performance of my neural network. I have tried add L2 regularizatión, dropout layer, but is not sufficient. Somebody can help me, please? Thank you so much !
