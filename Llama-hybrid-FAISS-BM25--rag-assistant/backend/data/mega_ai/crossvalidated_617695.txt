[site]: crossvalidated
[post_id]: 617695
[parent_id]: 617681
[tags]: 
It sounds like your end-goal is to come up with a pmf $P(X|Y)$ , i.e. for any signal duration Y, what are the probabilities that you get 0 values, 1 value, 2 values, etc. The only reason to invoke Bayes' theorem for this analysis is if for some reason you know the functional form of $P(Y|X)$ . I.e., given the number of distinct values for sensor 1, what is the conditional pdf of signal duration. It doesn't sound to me like you know this. To that end, I would suggest you just try to model $P(X|Y)$ directly. Seeing as X is an integer which is likely to take a relatively small value, you could (just throwing ideas out) try to model it as a conditional Poisson distribution, that is to say that $X_{i} \sim Poisson(\lambda(Y_{i}))$ and then you'll need to come up with some sensible model for $\lambda$ as a function of Y. You might think that you'd on average expect the number of distinct signals to be proportional to the length of the signal in which case you'd model it as a simple linear. Or you might think it would be some sort of diminishing return and you could model it as a power law or a logarithm. To work through the simple case (linear without intercept), your log-likelihood would look like $\sum_{i=1}^{N}\ln \left[\frac{(a\cdot y_{i})^{x_{i}}e^{-a\cdot y_{i}}}{x_{i}!} \right]=\sum_{i=1}^{N}x_{i}\ln a - ay_{i}+ consts$ and you can now use gradient descent or some other optimisation algorithm to find the maximum of this wrt a The key take-home here is that using Bayes' theorem only helps when you have some information about the inverse problem. For example, if you toss a coin 10 times and it comes up heads 6 times and you want to know the inherent probability of that coin coming up heads, you have more information about the inverse problem. If you knew the inherent probability of a coin coming up heads, then you would know (via the binomial distribution) the probability of seeing 6 heads out of 10 tries. So inverting the problem is helpful. In your case though, you don't have any inherent understanding of how the number of distinct values depends on the signal duration or how the signal duration depends on the number of distinct values (as far as I can tell anyway), so framing one in terms of the other won't help you/is circular. To make progress, unless you have tonnes of data, or Y doesn't have many distinct values relative to the amount of data you have, you won't be able to model $P(X|Y)$ non-parametrically, so you'll have to make some parametric assumptions about the functional form of the distribution of X|Y, and then you can estimate those parameters via maximum-likelihood (or even calculate the full Bayesian posterior on those parameters)
