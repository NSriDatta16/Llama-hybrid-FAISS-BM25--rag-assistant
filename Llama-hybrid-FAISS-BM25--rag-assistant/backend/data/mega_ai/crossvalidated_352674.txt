[site]: crossvalidated
[post_id]: 352674
[parent_id]: 
[tags]: 
Find RMSE from StatsModels OLS Results

I playing around with some regression analyses in Python using StatsModels. I am getting a little confused with some terminology and just wanted to clarify. I have run a regression and get the following results. OLS Regression Results ============================================================================== Dep. Variable: TTo R-squared: 0.048 Model: OLS Adj. R-squared: 0.032 Method: Least Squares F-statistic: 2.933 Date: Fri, 22 Jun 2018 Prob (F-statistic): 0.0921 Time: 11:44:53 Log-Likelihood: -380.18 No. Observations: 60 AIC: 764.4 Df Residuals: 58 BIC: 768.5 Df Model: 1 Covariance Type: nonrobust =================================================================================== coef std err t P>|t| [0.025 0.975] ----------------------------------------------------------------------------------- Intercept 472.7183 17.942 26.347 0.000 436.804 508.633 Var1 -1.2158 0.710 -1.713 0.092 -2.637 0.205 ============================================================================== Omnibus: 25.817 Durbin-Watson: 0.371 Prob(Omnibus): 0.000 Jarque-Bera (JB): 4.466 Skew: 0.107 Prob(JB): 0.107 Kurtosis: 1.681 Cond. No. 25.3 ============================================================================== Now, I get the R-squared values etc and the significance tests. Where can I find the mean squared error which shows the absolute measure of fit within the summary? Is it even there but hidden in something? I found that I can use model.resid_mse , which from the documentation stats it provides a residual sum of squares by dividing by the residual degrees of freedom. Is this the same as the average sum of squares? Is this just assuming it's from a sample? am I being simple? It this is what I am after, then surely to get the RMSE, I can just take the square root of the resid_mse (such as np.sqrt(model.resid_mse) ) to find the absolute fit of the model? Any help to clarify is greatly appreciated. Regards, BJR
