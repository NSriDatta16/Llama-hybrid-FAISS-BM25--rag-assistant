[site]: datascience
[post_id]: 25217
[parent_id]: 
[tags]: 
Methodical approach to improve deep neural network performance?

Working on a binary classification task to identify duplicate documents with 350,000 labeled samples, 70 features. There is about a 10:1 class imbalance. My best performing model so far has been a random forest, but I would like to see if I can use a deep feed forward neural network for better results. I have been playing with the number of layers and hidden units and verify performance using 5-fold cross validation. Here is an example of one architecture: for train_validation, test_validation in sfk.split(X_train,y_train): model = Sequential() model.add(Dense(150, input_dim=X_train.shape[1], activation='relu')) model.add(Dense(125, activation='relu')) model.add(Dense(100, activation='relu')) model.add(Dense(75, activation='relu')) model.add(Dense(50, activation='relu')) model.add(Dense(25, activation='relu')) model.add(Dense(1, activation='sigmoid')) model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy']) model.fit(X_train.iloc[train_validation,:].values, y_train.iloc[train_validation].values.reshape([-1,1]), epochs=13, batch_size=64, verbose=2, validation_data=(X_train.iloc[test_validation ,:].values,y_train.iloc[val_test].values.reshape([-1,1]))) I run that, get the mean/std of the accuracy and error. Then try adding a layer, removing a layer, adding some units, removing some. There is movement in accuracy and error (in the +/- 0.00x range). This approach is unscientific, what is a better way?
