[site]: crossvalidated
[post_id]: 534539
[parent_id]: 
[tags]: 
Is there a way to quantify the amount of spread of a plot of mean values over time?

I have a plot that is a mean of multiple measures of a motion over time with error bars 1 standard deviation away on the positive and negative side, which are calculated for each time point. I am looking for a statistical measure that can give me the amount of spread over the whole length of time to describe the variability. The below plot displays the means of the knee angle for a number of gait cycles. The mean, standard deviation, and variance were all calculated for each time point. The blue line is the mean for each time point and the red lines are 1 standard deviation for that specific time point away from the mean. Essentially I want a way to quantify that this plot for example has less spread than a similar plot in which the error bars are further from the mean. If you see that they are further, you can tell that is the case, but I want to quantify that visualization. I have found the average variance over time, by summing the variances calculated for each time point and then taking the mean. Subsequently I found the average standard deviation by taking the square root of the average variance. Is this measure meaningful and does it show what I am trying to find? If not, is there any measure that does?
