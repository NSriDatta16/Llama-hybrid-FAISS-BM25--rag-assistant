[site]: crossvalidated
[post_id]: 126926
[parent_id]: 126919
[tags]: 
To expand a little on Aksakal's answer, you could use AIC (Akaike information criterion) or BIC (Bayesian Information Criterion) to make this distinction. $$ AIC = 2k - 2ln(L) $$ Given $k$ parameters and $L$ maximum likelihood. Though depending on the sample size you are looking at, you may have to penalize more strongly for additional parameters such that $$ AICc = AIC + \frac{2k(k+1)}{n-k-1} $$ These formulas directly from wikipedia . You will be looking to minimize the AIC. This is how I would approach model selection, though it does not give a test statistic and a P value such that you have asked for. The methods for model selection are many and varied, and you can read about several here . To get a test statistic, you may want to look into $\chi^2$ model selection . Another possibility, if you have a binary response, would be to look into ROC curves . If you build two ROC curves for your two models and test for a difference using, perhaps, the Delong et al. approach for correlated (read: built from the same data set) detailed in R. If there is no significant difference, then the model with more parameters is not a significant improvement over the original model. Hope that gives you something to think about. Good luck!
