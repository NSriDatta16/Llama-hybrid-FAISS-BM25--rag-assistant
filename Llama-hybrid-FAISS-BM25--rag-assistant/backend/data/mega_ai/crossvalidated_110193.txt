[site]: crossvalidated
[post_id]: 110193
[parent_id]: 
[tags]: 
Caret: customizing feature selection, nested inside cross validation

Using caret, I want to train a SVM classifier and estimate its performance using repeated cross validation. My dataset has a very large number of predictors (300K) and I want to reduce this number using a super simple univariate approach (like t-test p-value below a threshold - or two-class anova is fine too). If I want to customize the filter threshold to use only very significant predictors, I believe this is working for me: require(caret) simdata But what if my strategy is to rank the predictors by p-value and simply take the top 100? Can anyone suggest a way to accomplish this? I don't see an obvious way to do that, since the functions of sbf appeared to be applied one predictor at a time. (I may not be using the twoClassSim function correctly -- just trying too provide a reproducible example). Thanks
