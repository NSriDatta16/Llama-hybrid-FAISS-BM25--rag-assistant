[site]: datascience
[post_id]: 14144
[parent_id]: 14002
[tags]: 
Is there a standard approach to evaluating [the] reasonableness of a new implementation of time series analytics? Yes, there is. A way to validate your build-from-scratch is to simulate an ARIMAX timeseries from a data generating process (DGP) of your choice (see e.g. http://robjhyndman.com/hyndsight/arimax/ ). Call your choice of DGP-parameters $\theta$, then: Draw a sample from the DGP. Estimate the model's parameters: $\hat{\theta}$. Make forecasts: $\hat{y}_{T+h|T}$. Assess $|| \hat{\theta} - \theta||_{\text{a metric}}$ and $||\hat{y}_{T+h|T} - y_{T+h}||_{\text{a metric}}$. Repeat 1 to 3 a couple of times, also for different DGPs and sample sizes. You either increase your confidence in the build, or find weak points that need improvement. A sensible metric could be squared loss. Personally, I like to use the "eye-ball metric" for the forecast residuals, their distribution could be assessed by way of histogram.
