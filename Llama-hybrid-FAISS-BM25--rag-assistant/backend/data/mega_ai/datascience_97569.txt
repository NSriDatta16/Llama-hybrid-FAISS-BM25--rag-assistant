[site]: datascience
[post_id]: 97569
[parent_id]: 
[tags]: 
Time Series Target variable taken at much lower sample rate than input features

I have a regression problem that involves predicting a patient's blood pressure from a range of vital sign readings including PTT, PPG, and HR. Each of these input features has been taken at the same sample rate so I have the same number of values for each. The problem I have run into is that the blood pressure data which matches with the input data has been taken at a much lower sampling rate. For every 1 blood pressure reading, I have 120,000 input readings. As I am fairly new to data science I am struggling to know what to search online for methods of how to deal with this problem. I have read a few papers and one method they used was to take attributes before and ahead of the timestamp, as seen below. What I don't understand is what they do with this? The way I have interpreted it is that they copy the blood pressure to the positions in the input data before and after the matched timestamp. I have included a screenshot below showing the way I have gone about implementing that.
