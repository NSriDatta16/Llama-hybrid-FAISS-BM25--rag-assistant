[site]: datascience
[post_id]: 122978
[parent_id]: 122968
[tags]: 
You could have a look at the SHAP package. Here is a link to some similar examples . As described in these examples, the following code will produce the both plots: import xgboost import shap # train xgboost model on diabetes data: X, y = shap.datasets.diabetes() bst = xgboost.train({"learning_rate": 0.01}, xgboost.DMatrix(X, label=y), 100) # explain the model's prediction using SHAP values on the first 1000 training data samples shap_values = shap.TreeExplainer(bst).shap_values(X) # plot the global importance of each feature shap.plots.bar(shap_values) # plot the distribution of importances for each feature over all samples shap.plots.summary(shap_values)
