[site]: crossvalidated
[post_id]: 642887
[parent_id]: 642884
[tags]: 
One problem is that additive effect in life-years cannot apply even approx. for all individuals in in a diverse population. E.g. if we have the whole population of a country with life expectancies varying from healthy babies (80+ y) to 100+ year-olds with aggressive cancers (a few weeks/months), then the effect of not smoking/some gene that increases risk for cancer etc. might on average across the whole population might be several years of higher life-expectancy, but for a lot of individuals this number doesn't really apply. There's easy example where the average doesn't apply for anyone. In contrast, effect measures like hazard ratios at least mathematically could apply to everyone, not just the population average. With that caveat, looking at population averages is certainly possible. However, again, one needs to be clear what the population is, any estimate would apply to the particular population the data are representative for, so data from the US most certainly gives different estimates of years vs. Japan vs. Germany. Similarly, people in research studies might not be representative of the general population and so on. With hazard ratios, the possibility that the effects transport may be somewhat higher, because it's at least a mathematical possibility that the effects could transport to other populations. Median estimates from Cox models are of course fine in that sense, as long as $>> 50\%$ have had the event and the number with an even is large enough. Otherwise the estimate has a large sampling variability and you might be better off using an appropriate parametric model, if you know which one would be adequate for the problem at hand. A problem, again is that when we do not see events for everyone, we make assumptions about what distributions could describe their survival times. If we see times of death for everyone, then we can look whether e.g. a Weibull distribution seems to fit. One difficult in interpretation is that you could get something that looks like Weibull distributed event times in multiple ways (and it's pretty hard to tell the difference): 1) changing hazard rate over time for everyone (conditional on covariates), 2) actually the event rate is constant for everyone, but varies between individuals. With ML type of models, you can in theory use anything you like to describe survival times. E.g. people have fit neural networks for tabular data that output the two parameters of a person-specific Weibull distribution as their outputs with the loss function based on a Weibull-likelihood (for right-censored data, if necessary). People have also split the follow-up period into intervals and used random forest to predict event occurrence for each interval, which with some suitable tricks and tweaks is apparently pretty successful. All these things are totally doable, it's just a matter of implementation (not as readily supported in standard software). However, just like with binary healthcare data (where logistic regression is hard to beat even with fancy ML methods), it may be that at the cost of considerable complexity one gains very little, but unless one tries it (and evaluates appropriately how well it works) one does not know for each particular application whether it helps.
