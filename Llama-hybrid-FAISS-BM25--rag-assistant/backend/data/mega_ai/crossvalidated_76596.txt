[site]: crossvalidated
[post_id]: 76596
[parent_id]: 76211
[tags]: 
As near as I can make out, you have 1000+ patients, one disease which the patients either have or do not have, and about 600 genetic markers, for which you have number of copies of that marker. What you have done with that is to run a polynomial regression of the number of repeats against the disease prevalence. You then have some kind of model (you don't specify what kind) which weights the predicted proportions from the 600 or so univariate polynomial regressions to make a unified prediction of the prevalence, which you test on a hold-out data set. You are running into problems because you may have very few patients with a particular number of repeats, meaning the prevalence could be quite biased. I'll be basing my answer on this interpretation of your question. OK, the answer: To begin with, I think you may not be formulating your problem in the best way. Right now you have: A matrix of counts of repeats of 600 markers for each of ~1,000 patients A boolean vector of whether or not each patient has the condition you want to predict The more conventional way to handle this problem would be to train a classifier on this data directly. If you particularly like regression, you could go with logistic regression, but you could also use a more sophisticated classifier like a support vector machine or random forest. All of these methods can output either absolute predictions, or probabilities, for each individual patient you feed into them. To validate this on your test set, you make a prediction for each patient, and create a truth table against the true disease state. This will let you compute the accuracy (or most likely you want something like both sensitivity and specificity). If you want to be more sophisticated, you could take the probabilities, and compute the area under the receiver operating curve (AUROC), which gives a global measure of the tradeoff between sensitivity and specificity. This approach is much more in line with what you will see in the literature, and avoids most of the problems (and the complexity) you have introduced into your problem, and quite likely will give you much better predictions.
