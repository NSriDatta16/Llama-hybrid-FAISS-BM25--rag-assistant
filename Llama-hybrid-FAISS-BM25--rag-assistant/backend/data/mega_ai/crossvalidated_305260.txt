[site]: crossvalidated
[post_id]: 305260
[parent_id]: 
[tags]: 
KernelPCA from sklearn doesn't return original data

If I do a transform and then an inverse_transform using PCA, I of course get the original data back. If I do the same for KernelPCA, I don't. Is this a property of kernelPCA or a shortcoming of the implementation? Code is here: import numpy as np from sklearn.decomposition import PCA, KernelPCA pca = PCA(n_components=2, copy=True) kpca = KernelPCA(n_components=5, kernel='rbf', gamma=1.0, # default 1/n_features kernel_params=None, fit_inverse_transform=True, eigen_solver='auto', tol=0, max_iter=None) train_set = np.random.rand(5,2) k_transformed = kpca.fit_transform(train_set) k_orig = kpca.inverse_transform(k_transformed) p_transformed = pca.fit_transform(train_set) p_orig = pca.inverse_transform(p_transformed) print "Original Data" print train_set print "PCA" print p_orig print "KPCA" print k_orig Output is here: Original Data [[ 0.60102465 0.37562677] [ 0.78281304 0.20575771] [ 0.55120131 0.31717359] [ 0.48216065 0.85297703] [ 0.77400554 0.86559728]] PCA [[ 0.60102465 0.37562677] [ 0.78281304 0.20575771] [ 0.55120131 0.31717359] [ 0.48216065 0.85297703] [ 0.77400554 0.86559728]] KPCA [[ 0.53530411 0.3594765 ] [ 0.51250412 0.25227312] [ 0.51253417 0.32343322] [ 0.45231888 0.55243246] [ 0.49755706 0.55221213]]
