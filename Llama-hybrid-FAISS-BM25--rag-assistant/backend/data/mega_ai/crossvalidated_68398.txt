[site]: crossvalidated
[post_id]: 68398
[parent_id]: 25820
[tags]: 
Seems you are asking for intuition. In a mixture, this is enough to find clusters of co-occurring words. This means that the distribution over vocabulary i.e. topics will sum to one. So it is sensible that the co-occuring words come in same topic and fewer words in same topic increases the probability of words occuring in the topic as it should sum to one. In LDA, the Dirichlet on the topic proportions can encourage sparsity As topics are sampled from an exchangable dirichilet so all topics are sampled uniformly. But if alpha in dirichlet is less than 1 than by the definition of dirichilet distribution you can see that $\theta^{(\alpha - 1)}$ is $(fraction)^{(-ve)}$ which will be high so the peaks in the simplex will be high at the corners i.e. sparsity as the topics are sampled from that dirichilet.
