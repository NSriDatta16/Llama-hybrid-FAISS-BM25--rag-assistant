[site]: crossvalidated
[post_id]: 331319
[parent_id]: 331250
[tags]: 
Allow me to paraphrase your question: Do I re-train on all $X, y$ before handing over my final model? Yes. And you could report the performance measures you found: test set performance and cross-validation. These estimates do not suffer from optimism bias with respect to out-of-sample performance.$^\text{1}$ They are preferred to in-sample measures of fit that can, and often do, suffer from optimism bias. Lastly, note that random forests come with a natural estimate of out-of-sample prediction performance: the out-of-bag estimator ( OOB ). Simply set oob_score = True . I suspect, that its value will be similar to the ones you already obtained. $\!^\text{1}$ In fact, they are even (slightly) pessimistic with respect to the performance of the model trained on the entire sample ( "all data" ), as a model's ability to generalize improves upon "seeing" more examples.
