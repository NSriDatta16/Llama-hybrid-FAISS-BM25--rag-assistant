[site]: crossvalidated
[post_id]: 565684
[parent_id]: 539910
[tags]: 
What you mean by "Discriminator is not able to differentiate between real and fake" is important. At one extreme, suppose the discriminator performs perfectly, i.e. it is able to determine if a new sample was drawn from the true dataset. Then the generator being successful would mean that it perfectly reproduces samples from the true dataset. In that case, you wouldn't gain anything from augmenting your data with generated cases. At the other extreme, say the discriminator doesn't perform any better than randomly guessing "real" or "fake". In this case the generator could produce anything and be viewed as successful. You certainly wouldn't want to augment your data with those generated cases. These extremes may seem contrived, but one can tilt the performance of a GAN in either direction by making different choices for architecture and/or the objective functions. For example, if the depth/width of the discriminator are very small, it may not be able to perform any better than the random guessing. In short, the ways in which a GAN augments your data (the kinds of variation that would introduce) could be difficult to control or predict. The success of this kind of augmentation would certainly require an intelligent entity to assess the quality of the generated data beyond what the performance measures of the components of the GAN can reflect (i.e. cost functions). Other methods, like perturbing training data according to admissible transformations (for example, adding a little noise to images), would be easier to control.
