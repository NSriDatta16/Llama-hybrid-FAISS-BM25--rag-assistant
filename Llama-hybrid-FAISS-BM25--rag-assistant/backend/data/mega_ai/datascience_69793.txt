[site]: datascience
[post_id]: 69793
[parent_id]: 
[tags]: 
HR Machine Learning: Treating/ Standardizing Part Time Employee Sums To Their Full Time Equivalents in Attrition Modeling

My data set consists of a subset of employees. Each employee has general HR information (typical standard hours, department, site, etc) along with punch card data which gives a clear picture of the types of hours the associate has worked over the past quarter (Night Shift, Time off, etc.) The data set described above is being fed into tree-based models to make binary predictions related to employee attrition. My question involves how to scale punch-card data, so models don't overlook part-time employees. In the past, we have loaded total hours worked by employees assuming that after a certain hours threshold is crossed, an action takes place(example, if an employee works over 40 OT hours in the last quarter, they are more likely to x.) We have come to realize that because our data set consists of full and part-time employees, this logic may be flawed. Associates who work 40 hours a week will always have more hours worked than associates who work 24 hours in a week; thus, they are more likely to reach these thresholds. Our data set isn't big enough to split into models for full and part-time employees. Do we need to make changes to the way we are loading hours data into our models? Should we be scaling part-time employees hours worked to their full-time equivalent? Should we use a ratio of hours worked to total hours to change what we measure from hours sums to percentage of hours worked? Loading in hours as rates would change the logic behind each threshold to something like if 25% of total hours are overtime hours, an employee is more likely to x? If possible, please, provide links to any relevant research papers where a similar problem is handled.
