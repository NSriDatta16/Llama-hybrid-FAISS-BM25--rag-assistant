[site]: datascience
[post_id]: 123543
[parent_id]: 108998
[tags]: 
Absolutely not! This is a basic tenet of Machine Learning. Due to the stochastic nature of training an ML model it's important to test the final model to ensure it satisfies our key criteria. The other answer cites an article that highlights the benefit of using cross-validation. However, the key argument is that once the "best" modelling parameters have been determined, there is no longer a need to test a model and all of the data can be used in training. This misses a key point about model training. Just because you have the best parameters, it doesn't mean that particular model is acceptable. You can see this for yourself, take the same data and repeat the model creation process. Even if you use the exact same data on the same computer you get slightly different results. The concept of a "Final Model" is a leap of faith that it maintains the characteristics of the previous models. You have to take a risk that it is equally good despite make two significant changes: you've increased the amount of data and also it's the first time the model has seen all the data simultaneously. There remains a risk of overfitting for example. Given a decent length of experience in this field will show best practice remains to always test your final model. In terms of best practice when dealing with Time Series data is that the split should not be random. Instead the test data should be the most recent as that's closest to today. Jeremy Howard covers this topic well in one of his videos on Deep Learning.
