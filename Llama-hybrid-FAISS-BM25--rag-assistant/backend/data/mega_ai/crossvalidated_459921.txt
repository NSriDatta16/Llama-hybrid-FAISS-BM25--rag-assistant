[site]: crossvalidated
[post_id]: 459921
[parent_id]: 
[tags]: 
Difference / Relationship of Generative Models / Variational Bayesian Inference

I feel a bit confused trying to merge and unify understandings of generative models and variational bayesian inference methods. Initially, I believed them to be the same thing, namely learning full posterior probabiltiy distributions, s.t. one can sample from them, and generate data samples. Discriminative methods, afaik, learn p(y|x), i.e. a decision boundary for making a prediction. Generative models, on the other hand learn p(y, x) = p(y|x) * p(x), and we can create samples from that. Now, as far as I understand, VI is a method of approximating posterior distributions over latent variables, i.e. p(z|x) (but, from my understanding, whether it is a posterior of some z or y does not matter). Which now again looks more similar to discriminate models though ... Is my confusion a bit clear? It would be great if someone could help me with that!
