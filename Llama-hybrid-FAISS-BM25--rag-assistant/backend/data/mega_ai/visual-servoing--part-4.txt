 assuming that the objects are planar and using a depth estimate. The technique works well in the planar case but tends to be complicated in the general case. The basic idea is based on the work in [4] Moment Invariants have been used in. The key idea being to find the feature vector that decouples all the DOF of motion. Some observations made were that centralized moments are invariant for 2D translations. A complicated polynomial form is developed for 2D rotations. The technique follows teaching-by-showing, hence requiring the values of desired depth and area of object (assuming that the plane of camera and object are parallel, and the object is planar). Other parts of the feature vector are invariants R3, R4. The authors claim that occlusions can be handled. and build on the work described in. The major differ- ence being that the authors use a technique similar to, where the task is broken into two (in the case where the features are not parallel to the cam- era plane). A virtual rotation is performed to bring the featured parallel to the camera plane. consolidates the work done by the authors on image moments. Error and stability analysis of visual servoing schemes Espiau in showed from purely experimental work that image based visual servoing (IBVS) is robust to calibration errors. The author used a camera with no explicit calibration along with point matching and without pose estimation. The paper looks at the effect of errors and uncertainty on the terms in the interaction matrix from an experimental approach. The targets used were points and were assumed to be planar. A similar study was done in where the authors carry out experimental evaluation of a few uncalibrated visual servo systems that were popular in the 90â€™s. The major outcome was the experimental evidence of the effectiveness of visual servo control over conventional control methods. Kyrki et al. analyze servoing errors for position based and 2-1/2-D visual servoing. The technique involves determining the error in extracting image position and propagating it to pose estimation and servoing control. Points from the image are mapped to points in the world a priori to obtain a mapping (which is basically the homography, although not explicitly stated in the paper). This mapping is broken down to pure rotations and translations. Pose estimation is performed using standard technique from Computer Vision. Pixel errors are transformed to the pose. These are propagating to the controller. An observation from the analysis shows that errors in the image plane are proportional to the depth and error in the depth-axis is proportional to square of depth. Measurement errors in visual servoing have been looked into extensively. Most error functions relate to two aspects of visual servoing. One being steady state error (once servoed) and two on the stability of the control loop. Other servoing errors that have been of interest are those that arise from pose estimation and camera calibration. In, the authors extend the work done in by considering global stability in the presence of intrinsic and extrinsic calibration errors. provides an approach to bound the task function tracking error. In, the authors use teaching-by-showing visual servoing technique. Where the desired pose is known a priori and the robot is moved from a given pose. The main aim of the paper is to determine the upper bound on the positioning error due to image noise using a convex- optimization technique. provides a discussion on stability analysis with respect the uncertainty in depth estimates. The authors conclude the paper with the observation that for unknown target geometry a more accurate depth estimate is required in order to limit the error. Many of the visual servoing techniques implicitly assume that only one object is present in the image and the relevant feature for tracking along with the area of the object are available. Most techniques require either a partial pose estimate or a precise de