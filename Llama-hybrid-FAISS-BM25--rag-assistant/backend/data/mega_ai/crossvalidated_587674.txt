[site]: crossvalidated
[post_id]: 587674
[parent_id]: 
[tags]: 
Academic research on MSE as cost function for regression in deep learning

I always see blogs or youtube authors saying that MSE should be used in regression problems, especially when dealing with time series. For example in this site the author says: The Mean Squared Error, or MSE, loss is the default loss to use for regression problems. Mathematically, it is the preferred loss function under the inference framework of maximum likelihood if the distribution of the target variable is Gaussian. It is the loss function to be evaluated first and only changed if you have a good reason. Ok, but why? What is a good reason for changing it? Unfortunately, the author does not cite his references for this statement. I am looking for some papers where authors explain/compare cost functions for time series regression problems but it seems to be not so easy to find them.
