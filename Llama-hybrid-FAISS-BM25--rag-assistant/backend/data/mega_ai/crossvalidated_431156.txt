[site]: crossvalidated
[post_id]: 431156
[parent_id]: 430722
[tags]: 
This is not a complete answer by any means, but I did find, from an entirely separate thread, this blog posting by Jake Westfall. I'll summarize a few key points made there (or at least my interpretation on them). "Classic" Cohen's $d$ is defined in terms of $\sigma$ being the pooled SD in a very simple one-way analysis. Westfall argues that if you're going to call something "Cohen's d", you should probably fit this simple model and estimate $\sigma$ accordingly. Later, he suggests that "classic" Cohen's $d$ has a lot to recommend it, inasmuch as these effect sizes are often used to compare effects from different studies, and this provides a unified basis for doing so. Westfall's discussion of $d_r$ (based on model residual variation) comes close to corroborating my comment on using the total error SD $\sigma_T$ in the homogeneous mixed model. For the multivariate model, I surmise based on (1) and (2) that one might estimate $\sigma$ via $\sqrt{\mbox{avg}(s^2)}$ (average the variances of the multinomial responses), as this is comparable to the pooled SD. Near the end, there is discussion of criticisms of standardized effect sizes that have been expressed by various authors (including Tukey). I thought I agreed with much of what was said, until I go to the very end where he says they are still useful for power analysis. That threw me, because I have actually written about that being inadvisable -- using a standardized effect size as the target value for a sample-size calculation gives you the same $n$ , regardless of how good or bad your instrumentation or your design. All that said, I still regard this question as unresolved. However, for purposes of my R package, I am resolved to leave the specification of $\sigma$ wide open and let the user ( not me ) bear as much responsibility as possible for deciding what to specify.
