[site]: crossvalidated
[post_id]: 117764
[parent_id]: 
[tags]: 
Identifiability in linear regression and time series

The multivariate linear regression model is given by $\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$, where $\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0, \boldsymbol{\Sigma}})$. $\mathbf{X}$ is $n \times p$. We may want to learn a mean for our data in addition to the effect that each of the covariates in the columns of $\mathbf{X}$ has on $\mathbf{y}$. In this case, we would augment $\mathbf{X}$ with a column of $1$s. Is this an identifiable model, and if not, could someone please explain why? Similarly, I am looking at a time series autoregression model of order $p$ (page 34 of Prado and West, 2010) in which the data have a nonzero mean. This is given by $y_t = \mu + (\mathbf{f}'- \mu\mathbf{1})\boldsymbol{\phi} + \epsilon_t$, where $\epsilon_t \sim \mathcal{N}(0, v)$. Here, $\mathbf{f}_t = [y_{t-1}, \ldots, y_{t-p}]'$ and $\boldsymbol{\phi} = [\phi_1, \ldots, \phi_p]'$. Could someone please explain why we need to subtract $\mu\mathbf{1}$ from $\mathbf{f}'$ in order to fit this model?
