[site]: datascience
[post_id]: 115965
[parent_id]: 
[tags]: 
How to train encoder in BiGAN?

I have some difficulties training a BiGAN. In particular, the encoder seems not learning the map between the images x and the latent space z . I have the following encoder: def build_encoder(self): model = Sequential(name = "Encoder") model.add(Conv2D(128, kernel_size = (5, 5), strides = (2, 2), activation = "relu", input_shape = self.image_shape, padding = "same")) model.add(Conv2D(64, kernel_size = (5, 5), strides = (2, 2), activation = "relu", input_shape = self.image_shape, padding = "same")) model.add(Flatten()) model.add(Dense(self.noise_dim)) return model And the following encoder loss: def encoder_loss(self, real_output, real_images, fake_images): real_loss = self.cross_entropy(tf.zeros_like(real_output), real_output) residual_loss = tf.reduce_mean(tf.abs(real_images - fake_images)) total_loss = real_loss + residual_loss return total_loss Where the real output is the discriminator output given real images. The training seems to go pretty well, since the generated images from random latent vectors are good. So the generator learns the map from z to x , but if i try to encode an image and decode it with the generator model, the result will be a complete different picture. Can anybody help me out?
