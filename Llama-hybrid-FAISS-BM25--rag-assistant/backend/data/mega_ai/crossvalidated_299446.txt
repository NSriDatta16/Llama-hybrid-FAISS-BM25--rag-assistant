[site]: crossvalidated
[post_id]: 299446
[parent_id]: 
[tags]: 
Word embeddings with logistic regression

My goals is to classify a set of documents (e.g. 20newsgroups ) into one of twenty categories. I can do this using Logistic Regression for example which takes as input a sparse $D\times V$ matrix in which each row is a document and each column represents a tf-idf smoothed count of words in that document. Instead of using the sparse tf-idf matrix, I want to classify based on word-embeddings ( word2vec or Glove ) where each word is represented by e.g. a 300 dimensional vector. My question is how do you represent a document of word vectors as an input to a logistic regression that takes as input a matrix of size n_samples by n_features? How do you classify a document based on word embeddings?
