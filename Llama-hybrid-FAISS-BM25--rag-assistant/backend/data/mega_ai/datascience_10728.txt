[site]: datascience
[post_id]: 10728
[parent_id]: 
[tags]: 
Neural Networks: How to prepare real world data to detect low probability events?

I have a real world data set of credit borrowers (50,000 records). The set contains categories such as Married, Single, Divorced, etc. as well as continuous data such as Income, Age, etc. Some records are incomplete or contain outliers. The dependent variable is Defaulted / Good (0,1). We are trying to train a neural network to predict defaults based on the training data. I have experience with neural networks and used them for sample data with great results, however, I never had to normalize noisy real world data. Any thoughts what I should keep in mind in respect to: - How to normalize the categories. Can I assign an indexed number? Should I tried to stratify them? - How to deal with missing data. Assign 0 ? - How to deal with the fact that defaults are only about 5 % of the data set. What transfer function would be useful to predict these low probabilities. - Basically any other real world data advice is very much appreciated. Thanks in advance!
