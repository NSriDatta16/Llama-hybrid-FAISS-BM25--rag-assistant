[site]: crossvalidated
[post_id]: 397109
[parent_id]: 396218
[tags]: 
The answer is No. You should never do such a thing. What you are proposing is this: train a model for a number of epochs until it converges. At each epoch, divide the dataset into a training and a testing set. Train on the training set and test on the test set. Repeat this process. Before I can answer your question, let me talk about what the test set is, or rather what it is meant for. Why do you develop a machine learning system or any system for that matter? Usually, you do it for this reason: you want to develop a system that can make appropriate predictions given some input. So to do that, you go through three phases. The first phase is the development phase, where you build your system. The next is the testing phase. Here you want to check whether your system performs as desired. So you give your system some input and you ask it make predictions. You then check if the predictions made are alright. Once your system has passed your tests, it is ready for the deployment phase. Now note that when your system has been deployed, it will get inputs that it had never seen during the training phase. This is because during training you only have access to a small subset of all real-life scenarios. Hence, you would need to know in advance how good your system performs on these "unseen" inputs. So this is where you need to be careful with the testing phase. You would want to test your model on "unseen" inputs - inputs that it has never seen during training. So your test set must consist of inputs not present in the training set. In other words, you training and test sets should have as little overlap as possible. Now lets see what happens with your algorithm: after the first epoch, the model redivides the entire dataset into a training set and a test set. However, now the test set contains (possibly all) examples that it has already "seen" during the first epoch. Which means that your test set does not mimic deployment conditions accurately. Hence, your test accuracy on the second epoch will not be reflective of the accuracy you would get at deployment. If you are worried about, wasting some portion of the dataset on the test set then you could use a technique called cross-validation. Here you divide your dataset in k parts. Say, k is 3. So, you would then train your model on parts 1 and 2 and test on part 3. Then, you would retrain your model (from scratch by initializing randomly) on parts 1 and 3 and test on part 2. Finally, you again retrain your model (from scratch again), but this time on parts 2 and 3 and then test it on part 1. During deployment, you run each of the three models separately and then combine their outputs in an appropriate way (e.g. weighting and linearly combining them). So, in short you can not change the train/test split between epochs because the testing conditions must mimic the "unseen" deployment conditions which means that a model must never be trained on the testing data.
