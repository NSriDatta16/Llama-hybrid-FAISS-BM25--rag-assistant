[site]: datascience
[post_id]: 17720
[parent_id]: 17718
[tags]: 
One advantage of get_dummies is that it can operate on values other than integers (so you don't need the LabelEncoder ) and returns a DataFrame with the categories as column names. Also, you can conveniently drop one redundant category using drop_first=True . One advantage of scikit-learn's OneHoteEncoder lies in the scikit-learn API. OHE gives you a transformer which you can apply to your training and test set separately if you specify the total number of categories. This doesn't work with get_dummies ,for example, if the training set misses categories present in the test set. You can still delete categories by simply deleting columns from the resulting numpy array (e.g. using n_values_ or feature_indices_ to see which columns correspond to the same feature). Some models work regardless, for example tree-based models. Also, L1 regularization can often set redundant features to zero (see Lasso regression ).
