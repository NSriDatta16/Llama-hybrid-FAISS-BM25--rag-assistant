[site]: crossvalidated
[post_id]: 582488
[parent_id]: 582367
[tags]: 
I'm not sure how one would turn Peto's odds ratio method in a meta-regression model, if one wants any study-level covariate adjustment. I've also read that Peto's method has issues with very large odds ratios, but have rather limited experience with it. Of course, things like exact (conditional) logistic regression can do adjustment for further covariates and can at least use studies with cases in at least one arm (even if the other arm has no events). There's no contradiction between doing meta-regression (i.e. adjusting for some trial or arm level covariates such as severity of the trial population) and a fixed effects model (i.e. assuming the odds ratio for treatment is the same in all trials in this case). One pretty serious option in this kind of situation would be a Bayesian logistic regression with a trial main effect, a study main effect and further covariates. As long as one is willing to pre-specify priors for what is expected in the control group, the treatment effect coefficient and the covariates you want to adjust for, this deals very conveniently with study arms with no events (and even appropriately incorporates studies with no events in either arm, which many other methods like Peto's method or exact conditional logistic regression would effectively not use). As desired, one can also easily specify that the treatment effect varies across trials (random effects meta-analysis). What would be sensible priors? They could e.g. be based on previous studies in the same population and one could then widen the priors to incorporate the risk of between trial heterogeneity (or one could even do dynamic borrowing, but that then exchanges information between studies, which may be seen as an issue by some). For the treatment effect, a number of sensible priors have been suggested in the literature, which reflect that most medical interventions don't have huge effects (on the more opinionated end there's N(0, 1), on the very open minded end something like Cauchy(0, 2.5)). The other thing to double-check, of course, is whether this is binary data, at all. E.g. if we are talking about the number of patients that died, had some other medical event or the like, then technically speaking treating the data as binary tends to be invalid. Issues include that the longer a study is, the more events would be expected to happen, which almost guarantees odds ratios cannot be consistent across studies. Additionally, unless the times from which onwards people are no longer followed for events (e.g. people withdraw their consent, or are lost to follow-up) follow exactly the same distribution in all treatment groups within each trial, then proportions would differ between groups without any effect of the treatments on the event of interest. Sometimes this may not make too much of a difference, but sometimes it does and then it's important to use methods for time-to-event data (there's methods when you have patient data, but also when there's only published aggregate data).
