[site]: crossvalidated
[post_id]: 94268
[parent_id]: 
[tags]: 
Can a machine learning algorithm be evaluated based on a random sample?

I am trying to evaluate how well (or bad) a semi-supervised algorithm is performing on a given dataset. The algorithms assigns one of 10 labels to each data point. The dataset is huge, and it's not possible to obtain gold standard labels to each data point. Up until now, I have only come across papers where the evaluation is done against the entire dataset (e.g. using SVM to assign 'positive' or 'negative' labels in a sentiment analysis task, where each data point is a document). Since I can't obtain gold-standard labels for the whole dataset, I was wondering whether it is scientifically valid to evaluate the performance on a randomly selected subset of the data. If yes, then how do I ensure that the subset is indeed a true representation of the entire dataset? I want to provide a valid argument that good performance on such a subset implies good performance on the entire dataset. I don't have a statistics background, so any reference for this will be extremely helpful.
