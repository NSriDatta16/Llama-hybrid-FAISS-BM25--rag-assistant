[site]: crossvalidated
[post_id]: 591124
[parent_id]: 591113
[tags]: 
There is not a reliable test for difference in means between your two groups without stringent assumptions about variances or data varability. Consider: if the variance in average response is, say, about 36 in both groups, then a t test would find no evidence of difference in means at the $\alpha=0.05$ level. However, if the variance in both groups is, say, about .036, then you would find evidence of a difference in means at the $\alpha = 0.05$ level. Why is this? Because hypothesis tests (confidence intervals also) rely on estimates of the standard error, which depends on the estimated variance to calculate the test statistic (there's a simpler form if the variances in both groups can be assumed equal, but this works whether or not they are equal): $$ t = \frac{\overline{x}_1 - \overline{x}_2}{\sqrt{\frac{s^{2}_1}{n_1} + \frac{s^2_{2}}{n_2}}}$$ The $s^2$ s in the above equation is what you are missing, and why you cannot perform a test for group differences in means (or group inferiority/superiority of means, or group equivalence of means).
