[site]: crossvalidated
[post_id]: 500222
[parent_id]: 
[tags]: 
Machine learning algorithm to work with body keypoints from image

I'm working on a project that will predict whether a person approaches and intends to interact. There will be a camera and a pose estimation model that will analyze live frames and save the body parts keypoints of the people in the frame. Now I'm thinking which ML algorithm will learn from our sample videos and know if the person is willing and going to interact with what's under the camera. Every 3-5 seconds with 2 frames each second will be the input of the model, which means 6-10 lists of keypoints, which are x and y coordinates of body parts in a frame. The idea is to process these lists to something meaningful that the model can learn from: The ankles are unnecessary for example, but the ratio between the shoulders in the first and last frames will be (meaning that the person got closer). Also the eyes are valuable. I am expecting some output between 0 to 1 that represents the level of willingness to interact, so that's is also how I'm going to label the sample training. My question is which ML model is suitable for this input and output and you think that will handle this kind of data well and give good predictions?
