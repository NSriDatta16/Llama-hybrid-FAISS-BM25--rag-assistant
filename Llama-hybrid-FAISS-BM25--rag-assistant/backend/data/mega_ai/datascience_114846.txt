[site]: datascience
[post_id]: 114846
[parent_id]: 
[tags]: 
Difference between Siamese Network and Prototypical Networks for One Shot Learning

I am having a bit of trouble understanding how the architecture of prototypical networks in a one shot learning use case differs from Siamese networks. If I’m understanding correctly, Siamese networks maps pairwise examples using same weights and biases into latent space and computes a similarity function. Prototypical networks finds the least distances between query and the mean of the examples in latent space (but in a one shot learning case, the mean would just be the latent vector itself?). I’m confused as to how prototypical networks would compare each example if they are in different latent spaces, so I’m assuming they all are mapped using the same neural network, with same weights and biases as well.
