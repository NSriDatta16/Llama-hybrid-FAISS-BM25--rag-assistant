[site]: crossvalidated
[post_id]: 301802
[parent_id]: 
[tags]: 
Minimizing error of intercept estimate for a given N

Suppose you know that $y = a + bx + \epsilon$ is your generating process, where $\epsilon$ is $N(0, \sigma^2)$, but you don't know the parameters $a, b, \sigma$. You have a limited number of trials to conduct, choosing $x$ and measuring $y$. Your goal is to estimate $a$. Is it always the case that you should conduct all your trials with $x = 0$ (and so your estimate for $a$ will just be the average of the measured $y$'s)? The motivation for this question is a discussion of regression parameter estimation in Freedman's Statistical Models . A quick and dirty simulation suggests that the answer is yes, you're better off choosing $x = 0$ for all trials, especially if there's a measurement error associated with non-zero values of $x$ (but no error for $x = 0$).
