[site]: crossvalidated
[post_id]: 613235
[parent_id]: 613203
[tags]: 
Let's go through each part one-by-one. Call The call section simply spits the formula back at you that was used when modeling your regression. There isn't really much to say about that other than it gives you what you already know. Residuals Recall that residuals are the errors in your model, or how badly your model guesses. These are standard for regression like the one you have. The minimum is the furthest your residuals are below the regression line, in other words how much your regression line overshoots it's prediction. The maximum is the opposite, which shows the value which undershoots the prediction the most. 1Q and 3Q are just quartile ranges of these residuals. The median should usually be somewhere close to zero (rarely is it exactly zero), as the average residuals should over time be close to where the regression line is fit. Coefficients These are simply all of the terms entered in the model. These usually include the intercept and your slopes (from the predictors you entered). The intercept for a Gaussian family regression such as this is generally understood as a conditional mean which is contingent upon the other terms in the model. We normally don't invest a lot of time in the point estimates in this row, as they don't usually in this case provide a lot of value. Your slopes however tell you whether or not your predictors have some utility. For the "personality" predictor here, the estimate is the slope. For every $1$ unit increase in this predictor, we get a $-.005$ decrease in your outcome of "change RT". The standard error and t value here are both used to derive the significance of the slope, which is indicated by the last output in the row. For "personality" the p value is $.7329$ and consequently is not significant. Age however has a low p value and can be deemed "significant" (though this doesn't say much about how strong that effect is). These coefficients can also be used to build a linear equation . Now that we have all of our coefficient values, we simply put them together into an equation like so: $$ RT = .074 + (-.005 * Personality) + (.006 * Age) $$ Signif. Codes You can ignore these, as they simply designate which values are significant and are self-evident. The Rest... I imagine your confusion is the bottom output. The residual standard error is essentially how "precise" the modelâ€™s predictions are. A lower RSE is generally more precise, indicating your model is good at predicting. Multiple $R^2$ is the proportion of variance in the outcome explained by the predictors in your model. We typically use the adjusted $R^2$ instead if we have multiple predictors, as the first value can be inflated by simply adding a bunch of predictors in the same model. Here we can see in either case that the model predicts very little variance in the outcome. The bottom values are the model significance terms, which show the f value and degrees of freedom, which are used to test overall model significance. As indicated by Dimitri's link: "The F-test of overall significance indicates whether your linear regression model provides a better fit to the data than a model that contains no independent variables." So this should give you an idea of what your output here is saying.
