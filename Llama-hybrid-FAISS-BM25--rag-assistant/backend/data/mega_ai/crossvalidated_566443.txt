[site]: crossvalidated
[post_id]: 566443
[parent_id]: 329436
[tags]: 
Your first two approaches seem quite sensible, you simply use some kind of smoothing to get rid of outliers. IIUC, the difference between the first two approaches is simply that in the first one you add classwise probabilities (over a time window) and in the second approach you multiply class probabilities (over a window); in both cases, you normalize in a second step. The third step: you should use the Bayes theorem only if it makes your life easier, i.e. if you can replace probabilities that you don't know with those that you do know. This doesn't seem to be the case here, though. If you are not satisfied with the results of your first or second approach, I would suggest looking into other possibilities for smoothing in time series, e.g. Kalman filter . You might also want to think about varying the time window size.
