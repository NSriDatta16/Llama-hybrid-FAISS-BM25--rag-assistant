[site]: crossvalidated
[post_id]: 126352
[parent_id]: 120821
[tags]: 
It is truly a mystery to me why rtPCR data are so often analyzed on the multiplicative scale. My experience is that those data and their noise variance are much more naturally represented on the $C_t$ scale. That includes analyses performed on preserved samples. Meaning, that I think it is really best to analyze the data on the $C_t$ scale, not after transforming to the multiplicative scale. And, I know that the $\Delta\Delta C_t$ method is widely used, but I think that it is pointless other than its prosody and mathematical appearance. In practice, I recommend the following procedure: Normalize each technical repeat's gene-specific $C_t$ value by subtracting from it the housekeeping gene $C_t$ value. Then, analyze the data using analysis of variance (ANOVA) on the repeat-normalized $C_t$ values, including the control group. If desired, translate effects estimates from the ANOVA onto the multiplicative scale. Here are some notes on each point: Sometimes there is only one technical repeat per subject but often there are more. If you have multiple technical repeats per subject or per subject/time-point, then you could average them after normalizing each repeat separately. Alternatively, if you have a more complicated design, you may want to use some sort of linear mixed effects model. That would allow you to model hierarchical variation --- for example, variation due to technical repeats. As a side note, I have seen some terrible approaches to "normalizing" for controls, including randomly selecting individual measurements from the control group to subtract from treatment group measurements. There is no point in subtracting the mean of the control group from all the values, as that simply amounts to analyzing only the treatment groups, but shifted along the scale. This recommended procedure has several advantages: It normalizes for differential expression appropriately, accounting for repeat-to-repeat and/or subject-to-subject differences in rtPCR analysis. It allows use of all data in estimating the noise variance. Typically, rtPCR data are well-behaved with respect to the ANOVA assumptions when analyzed on the $C_t$ scale rather than the multiplicative scale. All of the tools of linear model theory are available including linear mixed models, means separation methods, weighted least squares, and fairly faithful representation of experimental design. It still allows comparisons of treatment groups with each other, but also allows comparisons with the control group. These comparisons are implicitly performed on a relative scale. It is also possible to calibrate expression. Resources: Here are some resources on normalization with respect to housekeeping genes: ResearchGate discussion How to analyze a qPCR with 2 or 3 housekeeping genes? (Vandesompele, J. et al , 2002) discuss a strategy for combining data from multiple housekeeping genes. For more about the $\Delta\Delta C_t$ methodology: Section VII of Applied Biosystems guide Guide to Performing Relative Quantitation of Gene Expression Using Real-Time Quantitative PCR gives all the calculations. Discussion about the statistical aspects of analyzing rtPCR data: (Yuan, J.S. et al 2006) makes remarks about the primacy of $C_t$ in statistical analysis. References: Vandesompele, J., De Preter, K., Pattyn, F., Poppe, B., Van Roy, N., De Paepe, A., and Speleman, F. (2002). Accurate normalization of real-time quantitative RT-PCR data by geometric averaging of multiple internal control genes. Genome biology , 3 (7), research0034. Yuan, J.S., Reed, A., Chen, F., and Stewart, C. N. (2006). Statistical analysis of real-time PCR data. BMC bioinformatics , 7 (1), 85.
