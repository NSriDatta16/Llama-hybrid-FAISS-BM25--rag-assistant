[site]: crossvalidated
[post_id]: 462561
[parent_id]: 
[tags]: 
Simulation study for anomaly detection methods in time series

Im trying to compare some anomaly detection methods for time series. Since there are not many time series with labeled outliers I decided to do a simulation study. I'm doing the simulation in R using the "arima.sim" function which simulates time series from an ARIMA model. Among the methods are some that are based on iterating through ARIMA processes (tso from tsoutliers package or X13-ARIMA-SEATS from Rjdemtra package) and other methods like those included in the anomalize package, that are based in decompose the time series in seasonality, trend and residuals and apply univariate anomaly detection in the residual. My question is, is the simulation study fair? Are ARIMA error-based models not advantageous if the time series is simulated through an ARIMA process? Is there a method to perform a fair simulation for both methods? Kind regards.
