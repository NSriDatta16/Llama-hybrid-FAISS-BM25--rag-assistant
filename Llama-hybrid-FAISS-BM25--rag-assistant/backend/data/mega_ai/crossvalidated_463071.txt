[site]: crossvalidated
[post_id]: 463071
[parent_id]: 
[tags]: 
Classification using regression coefficients

While circumventing logistic regression, is there a way to binary classify new observations based on learned linear regression coefficients? Clarification : Suppose a variable of interest $A$ is assumed to be linearly dependent of $n$ variables $X = (X_1,\ldots,X_n)$ , i.e. \begin{align} A &= \alpha_1 X_1 + \alpha_2 X_2 + \ldots + \alpha_n X_n + \epsilon, \end{align} where $\epsilon \sim \mathcal{N}(0,\sigma^2)$ . All observations of $A$ belong either to class $-1$ or $1$ , i.e. $A = A^{-1} \cup A^1$ . For observed data, two sets of parameters $\mathcal{D}^{-1}$ and $\mathcal{D}^{1}$ are learnt based on ordinary least squares (OLS), i.e. \begin{align} A^{-1} &= \mathcal{D}^{-1} X + \epsilon \\ A^{1} &= \mathcal{D}^{1} X + \epsilon. \end{align} As new data becomes available, both $A^*$ and $X^*$ , I am wondering whether $D^*$ (such that $A^* = \mathcal{D}^* X^* + \eta, \text{ where } \eta \sim \mathcal{N}(0,\sigma^2)$ ) can be used to assign $A^*$ to class $-1$ or $1$ ?
