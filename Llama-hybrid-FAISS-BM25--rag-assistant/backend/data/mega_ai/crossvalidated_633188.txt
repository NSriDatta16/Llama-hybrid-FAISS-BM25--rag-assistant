[site]: crossvalidated
[post_id]: 633188
[parent_id]: 633003
[tags]: 
The key issue here is that there are latent (discrete) count variable that potentially take values from 10 to 14 for each pack of cigarettes a person has. We can make simplifying assumptions like that the packs a person has are always the same because they stay with the same brand, or that they would be the same on a day etc. - realistically, you'd also wonder about carrying over started packs to the next day, but I assume this is a toy problem to illustrate a concept. Each person then uses a number that is from some count distribution that cannot be higher than the sum of cigarettes they have on the day (which is a latent unknown variable). One question would be what happens with the tail of the distribution beyond that number, for which there's multiple options. In this particular example, I'd speculate that if someone would have smoked 100 cigarettes, if they only could have, they would smoke all the ones they had on them. I.e. all the distributional weight of the distribution tail end up piling up on the number of cigarettes the person has on them. If we look at this that way, then you can consider all values corresponding to the maximum number of cigarettes per person to be left-censored to be $\geq$ to that value. If we instead considered this as a case of truncation in the sense it's usually implemented, then the weight of the tail end of the distribution would be re-distributed across all numbers from 0 to the maximum number of cigarettes for a person. Another question you may want to decide is whether you want to model the number of packs (and how much is in each pack) and what assumptions you are willing to make (about how related this is within person, across adjacent days etc.). If you make the effort, potentially you can recover more information from the main relationship of interest, on the other hand, if you make super-simple assumptions, the problem becomes easier. How so? If I assume that every day for each person the number of packs is i.i.d. drawn with equal probability from $\{0, 1, 2\}$ , the number of cigarettes per pack is drawn from $\{10, 11, 12, 13, 14\}$ and nothing else about a person or what happens on other days can tell us anything of these values, then I can of course write down the resulting discrete mixture of Poisson distributions that then serves as our model likelihood (basically with probability 1/3 the outcome is 0, with 1/3 it's a mixture of 5 Poisson with censoring at $\geq \{10, 11, 12, 13, 14\}$ and with 1/3 it's a mixture of 5 Poisson with censoring at $\geq \{20, 21, 22, 23, 24\}$ ). That's a case where I can easily see how a marginalize out the latent discrete number of cigarettes a person has. I don't think you can fit such a model with lme4 or other common modeling packages, but anything that let's you write a custom likelihood could potentially cope with this, you will just have to deal with the fact that often the latent parameters are not identified in the data (potentially causing problems for maximum likelihood). One natural approach to take that can deal decently with non-identified nuisance parameters would be a Bayesian approach with proper priors. However, the discrete latent variable makes this slightly tricky. That's because e.g. the popular NUTS sampler in Stan does not cope with discrete parameters/latent variables - that is unless you manage to marginalize out the likelihood as above, in which case it's straightforward and just tedious to write down such a model in Stan or if you implement a custom likelihood in brms . Gibbs samplers (e.g. jags) should be able to handle the discrete latent variables, it may also be possible to approach this via ABC (approximate Bayesian computation, where you basically simulate the underlying process and keep realizations that [approximately] match the observed data) but I think that's less well suited to the problem.
