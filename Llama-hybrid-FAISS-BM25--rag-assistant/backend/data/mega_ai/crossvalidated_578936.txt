[site]: crossvalidated
[post_id]: 578936
[parent_id]: 
[tags]: 
Learning from the measurements taken from a single individual

Suppose we take repeated measurements of $x$ and $y$ from an individual (or possibly two) and we want to estimate the effect of $x$ on $y$ . For example we could simulate such data as below: x1 = sample(1:100,100) x2 = sample(1:100,100) y1 = 1 * x1 + rnorm(100,0,20) y2 = 1.5 * x2 + rnorm(100,0,20) df = data.frame(y = c(y1,y2), x = c(x1,x2), participant = c(rep(1,100), rep(2,100))) plot(df $x, df$ y) So the first 100 observations are taken from individual #1 and the rest from individual #2 and the data look like this: Now the questions are: What is the real sample size? Is it only 2 because we have only two individuals or we know more than that because we have repeated measurements from the individuals? How can we update our knowledge about the effect of $x$ on $y$ using such data? If we fit a simple linear regression as if we have 200 independent samples then we are certainly underestimating the uncertainty in the effect. So what would be the alternative approach for getting the most out of such a dataset to properly estimate the effect and account for the uncertainty in the estimate? If you could answer in Bayesian terms that would be great but frequentist approach could also work.
