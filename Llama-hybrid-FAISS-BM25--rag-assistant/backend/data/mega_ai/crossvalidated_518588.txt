[site]: crossvalidated
[post_id]: 518588
[parent_id]: 
[tags]: 
Vector autoregression with p = 2, lagged coefficients seem to "cancel out" (one is positive, one is negative with ~equal magnitude)

I'm analyzing some time series data with vector autoregression (AKA VAR). I'm using the implementation in R's vars package, if that matters, but I believe it is roughly equivalent for my purposes to Stata's. Without going into great detail about the data collection process, it is psychological self-report data collected second-by-second via computer input as they view a stimulus. Each time point, then, is the current state of a psychological variable at a given second (if the participant is not actively changing the input, it rolls over from the prior second). For simplicity's sake, let's just focus on the two-variable case. I have about 1500 time points and the model comparison procedure built into VAR suggests 2 or 3 lags should be used. I end up with a result where, when x is perhaps Granger-causing y , the lag-1 and lag-2 coefficients are both "significant" (i.e., low p-value) with opposite signs. In my case, it is always a positive coefficient on lag-1 and negative on lag-2. If I just added up the coefficients for each lag of x , I would get approximately 0. FWIW, the autoregressive term at lag-1 is large and positive and the autoregressive term at lag-2 is smaller and also positive. Substantively, it's hard for me to understand what this would mean. I do not believe that it is plausible in my case that the true effect is that at lag 1 there could be a positive effect that is then reversed by a negative effect at lag 2. It is plausible that there is a net effect of 0, but I believe it to be very unlikely that it is because of two opposite effects that occur in rapid succession. It makes me wonder if this is either a statistical quirk (i.e., doesn't come close to reflecting the true data-generating process) or perhaps could be a sign of model misspecification. In the interest of full disclosure, this is a simplified explanation â€” I have not just x and y but also w and z and most of their individual models include an example of this positive-negative coefficient pair. I obviously don't expect SE users to tell me if my model is correctly specified, but I wonder whether this phenomenon is at all common and might have a likely cause. If there is some sort of diagnostic that would be helpful to understand the likelihood of model misspecification causing this particular problem, I'd be interested in that as well.
