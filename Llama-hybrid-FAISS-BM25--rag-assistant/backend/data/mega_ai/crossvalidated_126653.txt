[site]: crossvalidated
[post_id]: 126653
[parent_id]: 122409
[tags]: 
The real problem here is your choice of metric: % accuracy is a poor measure of a model's success on an un-balanced dataset (for the exactly reason you mention: it's trivial to achieve 99% accuracy in this case). Balancing your dataset before fitting the model is a bad solution as it biases your model and (even worse) throws out potentially useful data. You're much better off balancing your accuracy metric, rather than balancing your data. For example you could use balanced accuracy when evaluating you model: (error for the positive class + error for the negative class)/2 . If you predict all positive or all negative, this metric will be 50% which is a nice property. In my opinion, the only reason to down-sample is when you have too much data and can't fit your model. Many classifiers (logistic regression for example) will do fine on un-balanced data.
