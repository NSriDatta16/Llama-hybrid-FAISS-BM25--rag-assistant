[site]: datascience
[post_id]: 124740
[parent_id]: 124728
[tags]: 
In general, I stumbled across voices in literature that we shouldn't use dropout with such a big parameter for shallow networks, as it can violate their capabilities. Example: Piotrowski, A. P., Napiorkowski, J. J., & Piotrowska, A. E. (2020). Impact of deep learning-based dropout on shallow neural networks applied to stream temperature modelling. Earth-Science Reviews, 201, 103076. Also, from my experience, your network appears too shallow. The additional aftermath of that is that your first Dense layer is unnecessarily big and it can even hinder the potential of your model. What you can try from my point of view: decrease Dropout's parameter add convolutional layer(s) before the Dense layer add Dropout also after convolutional layer normalization first, activation afterwards - as a plus
