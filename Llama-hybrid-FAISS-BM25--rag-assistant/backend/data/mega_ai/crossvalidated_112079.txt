[site]: crossvalidated
[post_id]: 112079
[parent_id]: 
[tags]: 
Setting up this generative model for inference: uniform priors

I am trying to set up a generative model where I have two images $x$ and $y$ and it is assumed that $y$ can be generated by applying some unknown transformation to $x$ i.e. $$ y = t(x, w) + e $$ i.e. $$ e = y- t(x, w) $$ where $t$ is the applied transformation which has parameters $w$ and e is the error which is assumed to normally distributed IID noise. So, I have a likelihood term given by (for a single pixel in the image): $$ L(w) = \prod_{i=1}^{N}(\frac{\phi}{2\pi})^{\frac{1}{2}} \exp^{\frac{-1}{2} \phi e_i^2} $$ where $\phi$ is the noise precision. I also have a prior on the variance of $\phi$ which is modelled as a gamma distribution. Because they are independent, the likelihood terms can be multiplied as in the equation above. Now, I know absolutely nothing about the nature of the parameters $w$, so I am guessing I should have a uniform prior on $w$? However, I do not know much about how to use these priors mathematically and $w$ can take on any value, so I am not sure how to make a proper distribution out of this uniform prior as well. I was wondering if someone could give me some advice on this. I am interested in inferring maximum mode and also characterise the spread of $w$. At the moment, I am even struggling to understand how to model things in a Bayesian setting when you have no prior belief on the form of these parameters of interest.
