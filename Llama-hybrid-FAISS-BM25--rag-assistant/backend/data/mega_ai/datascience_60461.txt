[site]: datascience
[post_id]: 60461
[parent_id]: 
[tags]: 
How do the policy gradient's cost function and gradients work?

I am not a math expert but have a basic understanding of linear algebra, calculus and probability and I understand the math behind back propagation. Currently I am trying to learn about policy gradient algorithm, but I am having difficulty understanding the underlying math. The most commonly used cost functions in the neural network training includes a target and output. For example: MSE: $$E_{total} = \sum{\frac{1}{2}(target - output)^2}$$ Log Loss: $$Error = Output(i) * (1 - Output(i)) * (Target(i) - Output(i))$$ The idea is to find parameters $\theta$ which reduces the distance between the target and the output. But in policy gradient method the cost function is like this: $$g = \mathbb E\Big[\sum R_t*\frac{(\partial)} {(\partial\theta)}ln\pi_\theta(a_t|s_t)\Big]$$ What is the target and output in policy gradient's cost function? How does this cost function get minimized and how does it works?
