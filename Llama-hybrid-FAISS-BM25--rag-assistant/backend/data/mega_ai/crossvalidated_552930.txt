[site]: crossvalidated
[post_id]: 552930
[parent_id]: 552879
[tags]: 
So, this is a fundamental limitation in ML (the covariate shift problem) -- any distribution shift over your covariates is going to cause you to lose performance in expectation -- so without any knowledge of what the shift looks like, you're doomed. Your problem seems to be related to domain adaptation, where given a small amount of unlabeled data from a new domain, you try to generalize to that domain. This is also similar to domain generalization, in which given examples from a few domains (i.e. images taken at K hospitals), generalize to new domains (i.e. images taken at the K+1th hospital). I want to emphasize that there is no "best" way to address this issue -- the range of possible approaches and good approaches will vary wildly by your specific problem instance, and since I know nothing about that, it's difficult to give you a method to try. Your proposed approaches look like they might work, but it's hard to say for sure. Since there is a ton of well-established research in this area, far more than I can describe here, I can only try to give a few starting points. The first two (reweighting and optimal transport) came out in the pre-deep learning times, so they might be easier to implement without exorbitant compute. Where possible, I tried to include a blog post w/ intuition as the first link in each group. Some domain adaptation/generalization methods Reweighting 1 , 2 : Assuming the covariate distributions of your domains overlap, reweight the target domain distribution to "look like" the source domain distribution and train your model on source data agin. Optimal transport 3 : Find a mapping from your source domain to a target domain, so you can "move" data from your new target domain (where your model may not work) back onto the source domain (where your model works well). The CORAL method is related to this as well. Domain-invariant representations (neural) 4 5 : These methods use adversarial training methods to learn a representation with as little domain-distinguishing information as possible. I think DANN was one of the first widely cited methods in this area? GAN-based methods 6 , 7 : Learn a network to generate images between domains. Causal-inference based methods 8 , 9 : An intervention is going to cause some characteristics of the data to change, while leaving others unchanged (descendants of a node in the causal graph) 8 . Framing a domain shift as an intervention, learn what we can expect to remain "unchanged" under shifts. Every one of these methods makes assumptions about what constitutes a "domain shift" and in some cases, the types of shifts their methods can address. For the neural approaches in particular, there's no guarantee that they'll learn anything useful (though I've personally had success with DANN) or recover an unbiased, robust predictor for all of your new domains (this is a holy grail). You might notice that some of these categories are related -- I agree, and this isn't an objective categorization -- all these methods certainly build upon one another. In the healthcare domain in particular, (10) has proposed a hospital-specific approach with the same general model specification. Disclaimer: I'm affiliated with some of the authors of [9, 10]. Many of these papers are taken from this course syllabus , which overviews a bunch of methods in this area.
