[site]: crossvalidated
[post_id]: 313293
[parent_id]: 312358
[tags]: 
I don't have a full answer and will be happy to learn from new answers. The strictest way to emphasis some features is to provide only them. Other ideas I have are algorithm dependent. There are algorithms in which weight can be given to a feature (e.g., linear regression, logistic regression). Of course, the best will be to compute the proper weight analytically. In some cases we choose not to do so due to computational cost and use search algorithms like gradient decent. Initialising theses feature with higher weight can make the search more efficient. In random forest we can give higher probability to these features to be chosen. In graphical models we can start with a model based on them. In neural networks we can connect them more than other feature. Besides the weight potential, it will enable them to interact in more places. In some implementations of trees, we can set them to the root of the tree and continue building it from there.
