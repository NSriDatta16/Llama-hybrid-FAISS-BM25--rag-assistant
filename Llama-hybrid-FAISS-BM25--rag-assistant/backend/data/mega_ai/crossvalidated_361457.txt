[site]: crossvalidated
[post_id]: 361457
[parent_id]: 
[tags]: 
Writing a conditional probability as a marginal

So I understand that using sum-rule one can write a probability as a marginal: \begin{equation*} P(x) = \int{P(x,\theta)d\theta} = \int{P(x|\theta)P(\theta)}d\theta \end{equation*} But how is this applied to a conditional probability? For instance in bayesian model comparison I come across this formula a lot: \begin{equation*} P(\mathcal{D}|m) = \int{P(\mathcal{D}|\theta,m)}P(\theta|m)d\theta \end{equation*} First of all I'm confused about the notation. Where are the parentheses in $P(\mathcal{D}|\theta,m)$? Is it $P(\mathcal{D}|(\theta,m))$ or is it $P((\mathcal{D}|\theta),m)$? And how is it derived anyway?
