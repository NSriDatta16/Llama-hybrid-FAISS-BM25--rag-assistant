[site]: crossvalidated
[post_id]: 425550
[parent_id]: 
[tags]: 
What type of multi-label method does sklearn's random forest classifier use?

I have trained RandomForestClassifier on data with 3 labels. The label set Y looks like this: Y = array([[0, 0, 0], [1, 0, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 0, 0]]) I have some feature set X: X = array([[13, 4, 2], [2, 2, 4], [7, 17, 1], [5, 2, 0], [4, 1, 12], [2, 3, 3]]) I run the algorithm as follows: from sklearn.ensemble import RandomForestClassifier rfc = RandomForestClassifier(bootstrap=True, max_depth=10, max_features='sqrt', random_state=1) rfc.fit(X, Y) Everything works beautifully, and I get classifications and probabilities to my heart's content. But I don't know exactly what I'm getting. Does the algorithm by default use binary relevance? Power set labeling? Classifier chain? I cannot find any documentation on this here . My main concern is this: am I capturing interactions between the different labels, or am I pretty much just training three independent random forests? It doesn't seem to be the latter; I have verified that the model trained on a 1-dimensional label set does not match the results of the multi-label model. In other words, there are cases where the multi-label model predicts [1, 0, 0] but using only the first label for training the model results in a prediction of 0.
