[site]: crossvalidated
[post_id]: 268761
[parent_id]: 268540
[tags]: 
Residuals can be useful, but there are a few things to watch out for. Your data might be heteroskedastic, i.e. the magnitude of residuals varies with the x-value. In this case, what counts as a "large" residual might depend on the x-value. (This is an issue even with linear relationships.) You might also need to think about the potential for errors in the measurement of the x-value. For example, if y=2x, mismeasuring x by 1 will always cause an error of 2 in your prediction of y. But if y=2^x, mismeasuring x by 1 can cause very small or very large errors in predicting y, depending on what x is. Strictly speaking this isn't heteroskedasticity, but the results look very similar. One common trick is transformation - either of the whole function, or of the residuals. In the example you give, I'd consider a log transformation, which will convert your exponential relationship to a linear one; depending on the sort of errors you encounter, it may or may not remove heteroskedasticity. You can also look at neighbour-based ways to identify outliers. For example, for any given data point P, pick the closest n neighbours to the left and to the right, characterise the range of y-values in that neighbourhood, and then check whether P is consistent with that range. ...and there are many other methods, all the way from "eyeball it on a scatter plot" up to elaborate machine-learning methods like neural nets and SVMs. It's hard to give a definitive answer to your question since it depends on so many factors.
