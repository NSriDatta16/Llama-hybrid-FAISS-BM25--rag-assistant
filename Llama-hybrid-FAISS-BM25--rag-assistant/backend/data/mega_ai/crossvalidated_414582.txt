[site]: crossvalidated
[post_id]: 414582
[parent_id]: 414578
[tags]: 
PCA considers only the variance of the features ( $X$ ) but not the relationship between features and labels while doing this compression. Regularization, on the other hand, acts directly on the relationship between features and labels and hence develops models which are better at explaining the labels given the features. I'm not familiar with other fields but Finance literature, in particular Shrinking the Cross Section , has done this comparison (PCA of features vs regularized model) and found that regularized model does a better job of predicting portfolio returns (better out-of-sample $R^2$ )
