[site]: crossvalidated
[post_id]: 106200
[parent_id]: 106110
[tags]: 
I'll try for an answer which hopefully goes into the right direction, but if not, just comment. Since you mentioned markets, I guess your cockroach corresponds simply to the price, whereas the allowed region is something like support and resistance. (Further, the your questions also remind me a bit about pricing of path-dependent options.) Your problem is probably described by some continuous stochastic model (such as implied by the Kolmogorov equation), but as this is probably not needed in practice I will present a simpler discrete model (such kind of models are called binomial/trinomial, Cox-Ross-Rubinstein or simply lattice methods in option pricing theory). So, assume you have a grid $x_i$ which spans the allowed region (or does so at least with a good probability) and which has a grid-spacing of 1 mm. Let the resulting grid have $N$ gridpoints. Further, we are working at discrete and equally spaced time-points $t$. Suppose further, that the cockroach starts at time $t=0$ at gridpoint $i$. Now consider a random walk on this grid. At each gridpoint $i$, you have a probability $r_i$ of going right and $l_i=1-r_i$ of going left. These probabilities need to be adjusted by you according to your model. Basically, on the left end of the grid the probability $r_i$ for stepping right must be significant, and vice versa. If you have adjusted your model, you can easily evaluate numerically your expected gain and loss by simply simulating the random process (I didn't get exactly the scoring mechanism, but you can for instance assume that each correct direction gives you a factor $q$ on your invested capital, further there should be fixed costs for entering, etc.). I planned to add some formulas here, but as it is simple I'll let it be. Just simulate your random process multiple times and each time you are correct (incorrect) increase (decrease) your money. In the end take the average of all results (that is, do Monte-Carlo. You could alternatively use Dynamic Programming). Further, in a next step, you can optimize the decisions (which decision in left/right and how much capital -- for the latter see the Kelly criterium). However, for this simple model, the conclusion will probably be not all too surprising. I guess you shall always enter with a bet in the opposite direction if the cockroach is on one end. Summarizing, if you want to use the model for something useful, you should tune it to your needs. Still I hope this gives you an idea of how to approach a solution to your question. Tuning the model The above model assumes static and known transition probabilities and one-step up/down moves only. One obvious first extension, stated also in the comment to the original question, would be to remove the assumption that the probabilities are known. Your model then needs to perform some kind of stochastic optimization, i.e. at the same time estimate the probabilities (exploration) and make the best possible profit (exploitation). This model then has some simililarities with the famous multi-armed bandit problem. For the solution, you could then use the methods from Reinforcement Learning or Approximate Dynamic Programming. Although still simple, such a model could already be of practical relevance. Other extensions: Instead of one-step up/down moves you could allow for arbitrary moves on the grid, each one with a probability to be estimated. As the problem might become quickly complex, you can for instance group the parameters (e.g. use common probabilities for gridpoints in the upper/middle/lower regions). Assume non-static but known (--well guessed) parameters (as suggested in the comment by @CarrKnight): here, the parameters are given, but you must estimate in which szenario or hidden state you are at the moment. Non-static, unknown parameters ... this one becomes hard, I guess. Simple models are required. More ideas are welcome.
