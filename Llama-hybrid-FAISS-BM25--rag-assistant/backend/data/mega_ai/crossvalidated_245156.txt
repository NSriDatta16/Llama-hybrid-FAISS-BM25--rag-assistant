[site]: crossvalidated
[post_id]: 245156
[parent_id]: 245135
[tags]: 
Random forests are generally considered to be relatively robust to overfitting. You want to tune the parameter that controls the number of variables considered for each split. The general rule of thumb is to use p/3, where p is the number of predictor variables, so you might start your search around there. A good algorithm will incorporate bagging and you can find the parameter that gives you the lowest error. You want to grow your forest as large as is useful for minimizing error (further trees don't damage your fit, but just require more computation).
