[site]: crossvalidated
[post_id]: 623858
[parent_id]: 623845
[tags]: 
Testability and falsifiability are general ideas that are discussed at length in the philosophy of science, but they manifest in statistics and aspects of these concepts can be framed in statistical or probabilistic terms. It is useful to have a broad understanding of the philosophy of science and its historical development to understand these concepts, but it is also useful to see how they arise in the context of probability and statistics. Below we examine the latter. The principle of "falsifiability" is a consequence of the law of total probability The principle of falsifiability means that in a valid experimental situation relating to a hypothesis, there must be at least one possible outcome that would count as evidence against the hypothesis; if there is not, then the experiment cannot ever be considered to give evidence in favour of the hypothesis. This principle is built into probability theory via the law of total probability , and it occurs in Bayesian reasoning. This rule of probability ensures that if there can be confirmatory evidence for a hypothesis, then it must also be possible for there to be disconfirmatory evidence for that same hypothesis . This property of probability theory is captured in the following simple theorem. Theorem (Principle of falsifiability for countable space): Consider a hypothesis $H$ and suppose we have a partition of the sample space $\mathscr{E}$ composed of a countable number of events. Suppose that there is at least one piece of confirmatory evidence $E \in \mathscr{E}$ that is in favour of the hypothesis ---i.e., a piece of evidence such that: $$\mathbb{P}(H|E) > \mathbb{P}(H).$$ Then there must exist at least one event $E' \in \mathscr{E}$ that is disconfirmatory to the hypothesis ---i.e., a piece of evidence such that: $$\mathbb{P}(H|E') Proof: We will use a proof by contradiction. Suppose ---contra the theorem--- that for all $R \in \mathscr{E}$ we have $\mathbb{P}(H|R) \geqslant \mathbb{P}(H)$ . Using the law of total probability, we then have: $$\begin{align} \mathbb{P}(H) &= \sum_{R} \mathbb{P}(H|R) \mathbb{P}(R) \\[6pt] &= \bigg[ \mathbb{P}(H|E) \mathbb{P}(E) + {\sum_{R \neq E} \mathbb{P}(H|R) \mathbb{P}(R)} \bigg] \\[6pt] &\geqslant \bigg[ \mathbb{P}(H|E) \mathbb{P}(E) + {\sum_{R \neq E} \mathbb{P}(H) \mathbb{P}(R)} \bigg] \\[6pt] &> \bigg[ \mathbb{P}(H) \mathbb{P}(E) + {\sum_{R \neq E} \mathbb{P}(H) \mathbb{P}(R)} \bigg] \\[6pt] &= \mathbb{P}(H) \bigg[ \mathbb{P}(E) + {\sum_{R \neq E} \mathbb{P}(R)} \bigg] \\[6pt] &= \mathbb{P}(H) {\sum_{R} \mathbb{P}(R)} \\[8pt] &= \mathbb{P}(H), \\[6pt] \end{align}$$ which is a contradiction. This establishes the theorem. $\blacksquare$ If you would like to see an application of this principle within Bayesian reasoning, you might be interested in reading O'Neill (2014) on the famous "doomsday argument". This paper argues that the doomsday argument is an example of erroneous reasoning in which there is an argument to a foregone conclusion, in contradiction to the proper application of Bayes' rule. You might also be interested in reading Kadane et al (1996) , which talks generally about the notion of "reasoning to a foregone conclusion" (i.e., without the possibility of falsification) and gives sufficient foundational conditions for probabilistic reasoning under which this cannot occur. The principle of "testability" relates to experimental design and other statistical principles The notion of "testability" means that it is possible to create an experiment that can provide sufficient evidence to test the hypothesis. This idea therefore forms a part of the field of experimental design, which can be regarded as a subfield of statistics. Wrapped up in this notion is the determination of the requirements that would be needed to form a valid experiment for a hypothesis, any protocols that need to be applied (e.g., randomisation, blinding, etc.), and how much evidence needs to be accumulated in order to get sufficient evidence on the hypothesis of interest to make an inference at some minimum level of confidence/accuracy. The last of these is usually determined by making sample size calculations using statistical rules. Testability can be framed in many different ways, with stronger or weaker requirements for particular contexts. It is often framed as requiring it to be possible to determine whether the hypothesis is true or false, and in some contexts it might require one to test causal hypothesis, which then imposes additional requirements. In any case, those are strong notions of testability, but if we are willing to think probabilistically, then a very weak notion of testability would merely require that it is possible to create an experiment that can provide either confirmatory or disconfirmatory evidence to some degree. This is a lot weaker than some demands for testability but it does provide a potential starting point. If we are willing accept a very weak notion of testability then this occurs when it is possible to construct an experiment where the evidence can shift our posterior belief away from our prior belief under some observable evidence. We have already seen above that if it is possible to see confirmatory evidence then it must also be possible to see disconfirmatory evidence, so a belief-shift either way could potentially occur. Weak testability would occur so long as the evidence in the experiment is not (statistically) independent of the hypothesis of interest. If we want to impose a stronger requirement for testability then it might entail having a larger amount of evidence (e.g., a minimal required sample size), or it might require imposing a particular experimental design or experimental protocols.
