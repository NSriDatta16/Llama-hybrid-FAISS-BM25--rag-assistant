[site]: crossvalidated
[post_id]: 40463
[parent_id]: 40421
[tags]: 
I think the main tradeoff is that RD has high internal validity, but low external, and the opposite is true for matching. Since we don't have a great deal of detail about what you are actually doing, you will have to decide which one is better in your case. The regression discontinuity design comes closest to an ideal experiment, so it has high internal validity, but unfortunately low external validity. The parameter it estimates is a very localized sort of local average treatment effect since you're mainly considering units right around the discontinuity cutoff. If you have reasons to think there are heaps of heterogeneity in the effect, you're stuck up the proverbial creek with no paddle. Propensity score matching/reweighting methods can only eliminate bias due to selection on observables, and will yield efficient estimates of many types of treatment effects (average treatment effect or the treatment effect on the treated), so they often have higher external validity compared to RD, but the internal validity that is often questionable since it is rare that selection depends only on observables. If there's selection on unobservables, matching can actually exacerbate bias. Finally, you might also want to consider an RD/Difference-in-Differences hybrid since you may have panel data on your counties: \begin{equation} \hat\beta=\frac{(y_{1}^{+}-y_{1}^{-})-(y_{0}^{+}-y_{0}^{-})}{x_{1}^{+}-x_{1}^{-}} \end{equation} where $y$ is the mean outcome, the signs denote position relative to the cutoff and the numbers denote before and after, and $x$ is the mean treatment (may be 1 in the case of the deterministic assignment or sharp RD design). Update: I just remembered a paper by Keele and Titiunik about geographic RD.
