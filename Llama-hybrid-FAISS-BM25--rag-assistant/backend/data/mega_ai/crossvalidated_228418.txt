[site]: crossvalidated
[post_id]: 228418
[parent_id]: 
[tags]: 
L0 and L1 Minimization of Matrix Equation

I am aiming to solve a 'raw' L0/L1-Minimisation problem, i.e, trying to find $$\min_{\alpha=0,1} \|x\|_{\alpha} : Ax=b $$ where $A,b$ are complex-valued matrices. In particular, I've been trying to find a software package (preferably in Python, Julia or C though I'm also open to Matlab) that would help me solve this. Most code for these $L_\alpha$ minimisation problems seems to come from the machine learning community, and in particular seems to focus on either the L1-approximation problem ($\min \|Ax-b\|_{1}$), or the L1-regularized least-squares problem . I'm new to this kind of optimisation problem, so I'd like to ask the community: Is there a way to translate my problem to fit one of these software implementations? Do people know a software package to solve this 'bare' problem? Would an algorithm to solve my optimisation problem be relatively simple to implement myself?
