[site]: crossvalidated
[post_id]: 312142
[parent_id]: 312118
[tags]: 
I'd stick my neck and say that this described method sounds like abusive use of p-values. Moreover, some variables can be insignificant as individuals but significant as a group (see explanation regarding Linear Regression here ) Generally speaking, there are three common methods for variable selection: a. Best subset b. Forward selection c. Backward selection You can read some more here and here . If you know Linear Regression well, you must have encountered $R^2$ and its wonderfully evil twin $\bar{R}^2$. The latter can be used as a criterion for adding/subtracting a covariate, like many others (AIC, Mallows' $C_p$ and more, see the above links). As we cannot use these methods with logistic regression, my personal favorite criteria is proportional confusion matrix (which is confusion matrix divided by the number of samples). If there's an error type you can define as severer, you should look at minimizing it (usually the case with biostatisics, when true negative is worse than false positive); Otherwise, look at maximizing the correct prediction error (e.g modelling Obama vs. Romney, there should be no difference of severity between type 1 and type 2 errors). This is my favorite criterion, while working with backward selection. This can change, of course, depending on the number of predictors and the type of problem.
