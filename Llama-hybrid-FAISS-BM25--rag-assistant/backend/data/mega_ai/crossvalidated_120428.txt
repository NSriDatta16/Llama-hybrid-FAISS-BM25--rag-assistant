[site]: crossvalidated
[post_id]: 120428
[parent_id]: 120413
[tags]: 
Random forests can handle noisy features as well as correllated ones. In general, a random forest automatically learns which features helped seperating the prediction classes the most. Just train a forest in R and retrieve the variable importance measures like the mean decrease in gini index . This can help you determine the strongest features. Of course you can always do a previous feature selection step. There are suggestions here: Feature Selection Packages in R, which do both regression and classification But in case you have less than 100 features i would guess that you do not need to put too much efford in it, as the random forests are kind of insusceptible for noisy or redundant features.
