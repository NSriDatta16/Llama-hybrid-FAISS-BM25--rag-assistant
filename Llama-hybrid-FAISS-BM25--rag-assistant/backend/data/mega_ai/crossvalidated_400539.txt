[site]: crossvalidated
[post_id]: 400539
[parent_id]: 
[tags]: 
Are legacy values useful for regression models?

I'm building a model that predicts house prices in order to learn some regression techniques. Currently I'm trying to engineer features that might be significant when predicting prices. I got a hold of some historical data which includes the amount of sold houses, amount of constructed homes, etc. I was thinking that, in addition to simply merging the data on the actual date that the houses were sold, it could be useful to feed some historical data to the model. For example: amount homes sold/constructed 1, 3, 5 years ago, etc. My initial though was to compare the difference of amount of homes sold/constructed at the time of the sale with the previous periods. But this leads to many negative values and quite non-normal distributions. A quick test (using a keras neural network), tells me that the predictions end up worse than before. So my question is: is this type of data useful at all? Does it make sense to keep the actual historical values instead of the differences? What are some techniques which I can approach this problem with? Any leads on resources for me to read about this kind of feature engineering would be helpful.
