[site]: crossvalidated
[post_id]: 405951
[parent_id]: 246444
[tags]: 
This is not a dumb question, and a good question to ask. Neural network learns from the data that is provided while the training is happening. A portion of data is not used in the training process and kept for the later stage called the validation/test stage. The idea behind is that, normally in the neural network, a complete learning process would include a feed forward and eventually a backword propagation, where the neural network validates if learning is done right and if not it adjusts the weights accordingly. After this complete cycle, the weights are ready for the prediction and the final output from the model. In validation phase, the actual trained model is tested and validated on the trained model to see if the model really learned well. Since the validation data is unseen by the neural network model and hence the hypothesis should output a minimized error. In this scenario we can call the model is near to perfect model and we have verified that with the unseen data. Now a point to be noted is, there is no adjustment of the weights in this later process and no backward prop. So we can also call it as a half cycle of neural network learning process. And hence the term Backward Propagation vs Cross Validation. Hope it helps, let me know if any question.
