[site]: crossvalidated
[post_id]: 417649
[parent_id]: 
[tags]: 
Is it possible to test overfitting with randomized data?

I have built machine learning models for a classification problem with four classes. They run at around 70% nested cross validation accuracy. I am looking to do further testing to check of overfitting, I am wondering if I gave my models a dataset of randomly generated numbers with random labels between 1-4, could I use this to check if they are overfitting to the data? My assumption would be that at random with 4 labels they should have only ~25% accuracy by chance, if I have a model that is having a higher accuracy could that suggest overfitting? I have been trying to find papers that explore this but I have found none. I am new to machine learning, am I missing something important as to why using randomized data in this way would not work to check overfitting?
