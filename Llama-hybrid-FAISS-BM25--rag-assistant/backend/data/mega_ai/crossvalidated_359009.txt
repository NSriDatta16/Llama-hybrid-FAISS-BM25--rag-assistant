[site]: crossvalidated
[post_id]: 359009
[parent_id]: 359004
[tags]: 
Probably calculate for each image the entropy, energy, contrast, homogeneity, based on the co-occurrence matrix of the delta-matrix of gray-scaled pixel values ($R=G=B=0,1,\ldots,255$). Also, after gray-scaling each image, just line up the pixel values into a vector and calculate the 3rd and 4th moments of the vector. In addition, calculate the "Hu moments" (M. Hu. Visual pattern recognition by moment invariants. IRE Trans. Inf. Theor. IT-8: 179-187, 1962). When done, for each image, clamp the above values to the input side of the ANN and don't input what you are currently using. You basically have to perform a lot of shape transformations on the images, and then use those values as input feature values as inputs to the ANN. While you are getting started with the ANN, I wouldn't say you are not overfitting, as a regularization fanatic would destroy you in a review or via audience participation. So start now, and look at the newer "dropout" method of ANN regularization, whereby you randomly drop out (e.g., zero the activation function values) of maybe 20-50% of the hidden nodes, so the error updates percolating back to the connection weights during back-propagation learning don't get burned in during sweeps (epochs). Dropout is a newer contemporary method that has been proposed as an alternative to the Mackay-type Bayesian regularization. FYI - you can still overfit after Bayesian regularization. Dropout is faster, since you don't have to work with the trace of the Hessian matrix during every iteration.
