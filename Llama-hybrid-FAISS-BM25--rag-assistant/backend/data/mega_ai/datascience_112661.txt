[site]: datascience
[post_id]: 112661
[parent_id]: 
[tags]: 
Why only discrete labels are used for (semi-)supervised VAEs?

I've noticed all semi-supervised VAEs assume discrete (categorical) labels to encourage disentangled representation learning in VAEs. e.g., Kingma, Durk P., et al. "Semi-supervised learning with deep generative models." Advances in neural information processing systems 27 (2014). Maal√∏e, Lars, et al. "Auxiliary deep generative models." International conference onmachine learning. PMLR, 2016. Ilse, Maximilian, et al. "Diva: Domain invariant variational autoencoders." Medical Imaging with Deep Learning. PMLR, 2020. Klys, Jack, Jake Snell, and Richard Zemel. "Learning latent subspaces in variational autoencoders." Advances in neural information processing systems 31 (2018). What is restricting the labels to be discrete for these applications? I understand marginalizing out w.r.t. continuous labels is intractable, but AFAIK this is needed in case of unlabeled data. For fully supervised case, I do not see the reason for restricting the use of continuous labels.
