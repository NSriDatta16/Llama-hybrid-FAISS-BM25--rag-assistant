[site]: crossvalidated
[post_id]: 236706
[parent_id]: 
[tags]: 
Using Transposed Convolutions (DeConvolutions) instead of a Dense layer when predicting Depth Maps

I'm using Keras to try and learn how to predict Depth from images. I have the NYU v2 dataset and was playing with some Neural Networks designs to see how each architecture can learn differently. I can feed a 3 x 120 x 160 Image (3 Channel RGB) into the network and after some convolutions I have 2 options in the final layer. one is to use a normal Dense layer with the shape of (1 * 120 * 160 = 19200 = depth map dimensions) and the other is to use Transposed Convolutions (DeConvolutions) to Upscale the prior layers into the final depth map size. I want to know how these 2 approaches are different from each other and if I'm using the Transposed Convolutions (or the Dense layer) in a right way or there are other more useful approaches to this problem? Thank you
