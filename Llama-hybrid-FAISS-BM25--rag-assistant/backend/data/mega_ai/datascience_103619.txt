[site]: datascience
[post_id]: 103619
[parent_id]: 103403
[tags]: 
So I have finally found out how to use kmeans for dimensionality reduction and if anybody else has the same question, I'm putting it down here so that you will get an idea. Extract features from your object in the dataset : Example - Use color moments to get a feature vector for all the images and vectorize it. This feature vector matrix of all the images will have size nxm, where n is the number of images and m is the size of each feature vector. Dimensionality reduction : This was the tricky part because usually, we do PCA/SVD but kmeans can also be used for dimensionality reduction in a number of ways. One way is to : Initialise k random centroids from the feature matrix, perform k means and cluster the feature vectors into k clusters. Run kmeans until we get the true centroids , that is , until the centroids don't change in the subsequent iterations. Find the distances from each feature vector to the k centroids. (I used np.linalg to find the distances but any distance measure can be used). So we will have k distances. These distances will be the new latent semantics - k distances for each feature vector will give a feature vector matrix of size nxk (we have reduced it from nxm to nxk) Mapping the images to the new latent space : To use the latent semantics that we have extracted, we need to map the images in the database to this new latent space. This can be done by taking a dot product of the inverse of the original feature matrix and the latent semantics. Find k similar images, when given a new image : We perform similar feature extraction and map the new image's feature vector to the new latent space. Compare the new image to all the existing images in the latent space and return the top k similar images based on their similarity.
