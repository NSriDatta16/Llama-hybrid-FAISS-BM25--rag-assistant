[site]: crossvalidated
[post_id]: 389888
[parent_id]: 
[tags]: 
In a LGSSM how do we know that the prediction distribution is Gaussian?

I am trying to follow lecture notes regarding the Kalman Filter from a course taught at Stanford. The lecture notes can be found here . The linear Gaussian state space model (LGSSM) is introduced as \begin{align*} z_0 &\sim N(0, \Sigma_0) \\ z_t &= A z_{t-1} + w_{t-1} &&\text{ for independent } &&w_{t-1} \sim N(0,Q) &\forall t \geq 1 \\ x_t &= C z_t + v_t &&\text{ for independent } &&v_t \sim N(0, R) &\forall t \geq 0 \end{align*} Here $z_i$ represents the hidden state at time $t=i$ and $x_j$ represents the data at time $t=j$ . Also, $x_{0:k} = (x_0, x_1, \ldots, x_k)$ . In section 11.2.1 Time Update, the author stats that "last time, we leveraged the fact that we know $z_{t+1} | x_{0:t}$ will take a normal distribution..." I imagine this detail was discussed during the actual lecture, but I was not in attendance as it dates back to 2014. I tried to work it out for $t=1$ . According to the text I should be able to show that $p(z_2 | x_0, x_1)$ is Gaussian (or at least proportional). \begin{align} p(z_2 | x_0, x_1) &= \frac{p(z_2, x_0, x_1)}{p(x_0, x_1)} && (1) \\[1ex] &= \frac{p(x_1|z_2, x_0) \cdot p(z_2 | x_0) \cdot p(x_0)}{p(x_1|x_0) \cdot p(x_0)} && (2) \\[1ex] &= \frac{p(x_1|z_2, x_0) \cdot p(z_2 | x_0)}{p(x_1|x_0)} && (3) \\[1ex] \end{align} I can't make anything useful out this work however. How do we know that the prediction distribution, $p(z_{t+1}| x_{0:t})$ , is Gaussian?
