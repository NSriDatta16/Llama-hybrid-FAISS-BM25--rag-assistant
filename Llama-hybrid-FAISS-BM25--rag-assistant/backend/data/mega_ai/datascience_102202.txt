[site]: datascience
[post_id]: 102202
[parent_id]: 
[tags]: 
Additional business rules in ensemble methods (RF, Boosted Trees)

How is it possible (if at all) to implement additional business constraints to an ensemble machine learning model, such as random forests or boosted trees? These additional business rules can be useful, for instance, to inform the model that such or such scenario is not possible (e.g. you can't predict this if you see that), which the model would have trouble learning from the training data because of noise. I'm currently using LightGBM but I'd also be interested on how to achieve this in any other library that supports ensemble models.
