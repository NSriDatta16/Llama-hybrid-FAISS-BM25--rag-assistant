[site]: datascience
[post_id]: 20138
[parent_id]: 20095
[tags]: 
You of course cannot use them as training data, but they can still have some potential uses, for example: -You can make predictions on that data and see if the distribution of the classes are similar to those in the labeled data. -You can use them for feature engineering – e.g. if you are using something like principal components, or if you are using averages for some categorical variable (e.g. you have a variable like state and another like income, and you augment the state variable by creating a feature that is the average income for that state). -If you need to impute missing values in the predictors, it’s better to use the whole dataset for that. -You can see if the distributions of the predictor variables are similar, and if you see that, for example, in your test data you tend to predict poorly for observations with a low value of variable ‘x1’ and the data with no labels has mostly low values of ‘x1’, then you should perhaps change your model.
