[site]: crossvalidated
[post_id]: 270024
[parent_id]: 218452
[tags]: 
This is an elaboration of Eric Kernfeld's answer. Please upvote his instead of this one. The information gain optimization of the problem is particularly natural in a Bayesian formulation. The Bayesian formulation also avoids some of the problems with either invariant subspaces or bootstrapping the variance in the plugin estimator. Suppose we have a prior $p(T)$ on transition matrices and a sample $\{T^{(k)}\}_{k=1,\ldots,K}$ from that prior. We can estimate the prior-averaged transition matrix as $\bar{T} = \frac{1}{K} \sum_k T^{(k)}$. The entry $\bar{T}_{s\rightarrow t}$ is the marginal probability of observing state $t$ for a single transition starting from state $s$ with a transition matrix drawn from the prior distribution $p$. Let $f$ be some scalar function of the transition matrix, where $f(T) = \log \pi_2(T) - \log \pi_1(T)$ in the original question. The information gain of observing a transition $s\rightarrow t$ can be defined as $\operatorname{KL}(q_{s\rightarrow t}(f),p(f))$ where $q_{s \rightarrow t}(T)$ is defined as the posterior probability of T after observing the transition $s\rightarrow t$. We can estimate the prior distribution of $f$ using a kernel density estimate on $\{f(T^{(k)})\}_{k=1,\ldots,K}$. To approximate the posterior distribution on $T$, we can use a reweighting estimate. Define the reweighted probability $q^{(k)}_{s\rightarrow t} = T^{(k)}_{s\rightarrow t}/K \bar{T}_{s\rightarrow t}$. The information gain for observing $s \rightarrow t$ is just $$ I_{s\rightarrow t} = \operatorname{KL}(q_{s\rightarrow t}(f),p(f)) \approx \sum_k q^{(k)}_{s\rightarrow t} \log \left(\frac{\sum_{k'} q^{(k')}_{s\rightarrow t} \operatorname{kernel}(f(T^{(k)}),f(T^{(k')}))}{ \sum_{k'} \frac{1}{K}\operatorname{kernel}(f(T^{(k)}),f(T^{(k')}))} \right) $$ The expected information gain from observing a single transition from state $s$ is $I_s = \sum_t \bar{T}_{s\rightarrow t} I_{s\rightarrow t}$. We can choose the initial state $s$ to maximize the information gain. The process can be iterated by replacing the prior distribution with the new posterior after sampling $s\rightarrow t$.
