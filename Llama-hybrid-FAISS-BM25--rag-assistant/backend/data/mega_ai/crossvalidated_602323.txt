[site]: crossvalidated
[post_id]: 602323
[parent_id]: 
[tags]: 
xgboost feature importance vs shap values ranking interpretation

If we have two features, A and B. Feature A has a higher gain than feature B when analyzing feature importance in xgboost with gain . However, when we plot the shap values, we see that variable B is ranked higher than variable A. How would you interpret that, intuitively? Because I understand from these answers: Difference in model feature importance and SHAP summary plot Interpreting XGB feature importance and SHAP values that Shap values are ranked based on how much affect the output (based on the average impact on all datapoint, I guess?). If that's the case, shouldn't a feature with higher impact on final probability have higher gain in feature importance in xgboost? If not, could you give an example? My second question is, how could you explain your answer to a non-technichal stakeholder? Because it's pretty hard to see a plot with feature importances in a certain order, and then see in the shap values plot that a higher importance feature has a less impact in the output probability than a less important feature. (AKA: Could you explain in layman's terms?) PS: This is a kind-of similar question, but it uses weight , the default function of xgboost.plot_importance() instead of gain , and is unanswered yet with 3 years old (and weight argument is very different from the gain argument anyways)
