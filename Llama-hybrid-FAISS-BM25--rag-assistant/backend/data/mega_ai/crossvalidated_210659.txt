[site]: crossvalidated
[post_id]: 210659
[parent_id]: 
[tags]: 
A Bayesian network is a probabilistic directed acyclic graph. Nodes represent random variables in the Bayesian sense (observable or unobservable); edges represent conditional dependencies between nodes. Bayesian networks are also known as Bayes networks or belief networks. Given its parents, each variable (or node) in the Bayes net is independent of its non-descendants. In this manner, the joint probability distribution over all nodes $X_1, ..., X_n$ can be written as: $$P(X_1,...,X_n) = \prod_{i=1}^{n}P(X_i|\text{parents}(X_i))$$ For each node $X_i$ we need only $P(X_i|\text{parents}(X_i)$ to calculate it. This is called a conditional probability table (CPT). Note that CPT size is exponential in the number of parents. Using the structure of a Bayes net, we can use variable elimination to reduce the number of computations required to calculate probabilities. Variable elimination is also known as marginalizing out a variable by summing over all of its atomic events. Note that somewhat confusingly, so-called deep-belief-networks typically have no Bayesian connotation but denote a particular architecture of "regular" neural-networks .
