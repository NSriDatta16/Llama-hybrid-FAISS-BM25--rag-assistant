[site]: crossvalidated
[post_id]: 347696
[parent_id]: 347688
[tags]: 
You have defined the function $\hat{L}(p) = p / (1-p)$ and you are giving it inputs in the argument range $0 \leqslant p \leqslant 1$. This function has the limiting value $\lim_{p \uparrow 1} \hat{L}(p) = \infty$, so it is not surprising that you get $\ln \hat{L}(1) = \infty$. You are getting this output in your R code because that is the correct limiting value of the function with the argument value you are putting into it. Luckily, this is not a problem for using logistic regression on your data. Logistic regression models the data as Bernoulli outcomes (or binomial outcomes if they are aggregated) with an underlying probability function that follows the logit function. This underlying functional form means that the model does not allow zero probabilities or unit probabilities , but it does allow observed binomial with sample proportions of zero or one. Standard estimation methods may have trouble with this in some extreme cases, but usually the model can handle some of the sample proportions being zero or one (so long as this doesn't lead to estimated coefficients of negative or positive infinity). In view of this, you should still be able to fit your data with a logistic regression, and use this to estimate the probabilities of outcomes based on the mean-CT explanatory variable. In the groups where the sample proportion is one, the probability estimate should be close to one, but it won't be exactly equal to one.
