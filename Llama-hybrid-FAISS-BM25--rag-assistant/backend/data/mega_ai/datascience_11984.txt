[site]: datascience
[post_id]: 11984
[parent_id]: 11973
[tags]: 
Ad 1. Assuming the measurements at any given time are normally distributed (they shape approximately a bell curve), you could use simple standard deviation to detect outliers. Specifically, for any given time, you can calculate the mean and standard error. Then you calculate the mean sans outliers by taking into account only the measurements that fall at most some pre-set distance from the mean (e.g. given normal distribution, 68% of measurements fall within one standard deviation from the mean ). Pseudo-code example: # Measurements at time t0 for all 10 days t0 = np.array([0.1, 0.1, 1.4, .9, 1.25, 1.25, 1.5, 0.1, 0.3, 1.75]) # Get mean and standard error mean0, std0 = t0.mean(), t0.std() # Inliers are within one sigma from the mean inliers = np.logical_and(mean0 - std0 t0) # ==> [0, 0, 1, 1, 1, 1, 0, 0, 1, 0] # And the baseline mean at time t0 is baseline0 = t0[inliers].mean() # ==> 1.02 Ad 2. You can find the most similar days to the baseline by using any appropriate distance measure (i.e. for time series: Euclidean or dynamic time warping ). The result, then, consists of those days where distance is the least.
