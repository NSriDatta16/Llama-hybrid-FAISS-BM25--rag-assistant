[site]: datascience
[post_id]: 10533
[parent_id]: 10517
[tags]: 
I tried running a RANSAC model on your data, but got worse results than a straight linear regressor. The ten-fold cross-validated mean absolute error over all three response variables (r,g,b) for the linear model was about 0.37. I also ran a random forest model for comparison, and got about the same score. This suggests that the linear model is not shabby, but it is up to you to decide if either is good enough. import sklearn.linear_model, sklearn.cross_validation, sklearn.ensemble, pandas labels = pandas.read_csv('labels.csv', header=None, names=['r', 'g', 'b']) features = pandas.read_csv('features.csv', header=None, names=['area', 'length', 'index', 'complexity', 'lines', 'curves', 'intensity']) sklearn.cross_validation.cross_val_score(sklearn.linear_model.LinearRegression(), features, labels[:len(features)], 'mean_absolute_error', 10, -1).mean() I also tried visualizing the data with the outliers clipped, but did not find it very enlightening, so I did not include it here.
