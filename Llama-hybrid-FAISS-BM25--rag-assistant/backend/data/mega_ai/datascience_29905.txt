[site]: datascience
[post_id]: 29905
[parent_id]: 29903
[tags]: 
1) Anaconda Spyder, maybe 2) sklearn, random forest has an option to select the number of jobs, and it will take care of parallelizing 3) i don't think so, but you can pickle objects and load them up. you can probably do something like create a variable_name - value dictionary and just pickle that 4) never tried 5) according to https://stackoverflow.com/questions/21288133/loading-rdata-files-into-python , I don't think so
