[site]: crossvalidated
[post_id]: 471727
[parent_id]: 
[tags]: 
Are RNNs Markovian?

On the one hand , one can argue that they are since "the hidden layer is simply [derived from] the last hidden state and current input". On the other hand , the whole point of RNNs is that "their rich internal state allows them to keep track of long-distance dependencies", hence the non-Markovianity. Which one is it? EDIT : There were some questions as to which particular problem domain I was referring to, e.g., natural language processing, reinforcement learning, etc. Ideally, I'd like to keep the question as high-level and domain-agnostic as possible, but what I ultimately want to apply it to is as follows: I have a set labeled, attributed entities that interact over time. If it weren't for the interactions, a straightforward supervised learning on the attributes of the entities would allow for their classification. However, because of the interactions, which we can encapsulate as black boxes, the attributes change over time as they "influence" each other upon "contact". My aim is to model the black boxes. Presumably, the whole history of interactions that an entity undergoes should factor in its latest estimation of the label. However, if one collapses , i.e., aggregates, the history at each time step into a latent representation, then one can forget the past since it's supposed to have been encoded into the current state, hence my confusion as to whether the interaction black boxes I am trying to design behave in a Markovian or time-dependent manner, RNN-like recurrent cells.
