[site]: crossvalidated
[post_id]: 256008
[parent_id]: 
[tags]: 
Understanding the Central Limit Theorem (CLT)

My question revolves around the Central Limit Theorem. To read from the same page, I quickly state it here: Let $X_{1}, ..., X_{n}$ be IID with mean $\mu$ and variance $\sigma^2$ . Let $\overline{X_{n}} = n^{-1} \sum_{i=1}^{n} X_{i}$ . Then lets define $Z_{n} := {\frac{\sqrt{n}(\overline{X_{n}}-\mu)}{\sigma}} \rightarrow Z$ where $\rightarrow$ means convergence in distribution, $Z \sim N(0,1)$ . The central limit theorem therefore does the following: We take the random variable $\overline{X_{n}}$ which as one can show: $\mathbf{E}(\overline{X_{n}}) = \mu$ and $Var(\overline{X_{n}}) = \frac{\sigma^2}{n}$ . Then we rescale it, as if we would assume it is a normal distributed random variable, because for any normal distributed random variable $Y \sim N(\mu_n, \sigma_n^2)$ one can show that $\frac{Y-\mu_n}{\sigma_n} \sim N(0,1)$ . And then, after we rescaled n (the rescaled version is exactly the statement of the CLT as written above), we notice that "by suprise" this scaled version of $\overline{X_{n}}$ is $\sim N(0,1)$ . In other words, our assumption that $\overline{X_{n}}$ is normal distributed was right. Why does this suprise us? Because $\overline{X_{n}}$ , or better to say the underlying $X_{1}, ..., X_{n}$ come from any distribution. Apparently the normal distribution is for this scaled version of $\overline{X_{n}}$ some kind of a "convergence goal", not considering where it started. Fair enough. Until here we should be on track. Now here is my issue: I frequently here from people, especially those who have not deeply studied statistics and use it for example in an application in business, that not just this very specific term $\overline{X_{n}}$ converges in distribution against a standard normal distribution, but also "any sequence" of random variables, as long as you draw enough of them. Let me firstly describe it a little bit intuitively (because that's how I here it from them), and than try to formalize it and understand what this would imply). So what they say is: you draw sufficiently many random variables $A_1, ..., A_n$ from any distribution (so n should be large). Then you plot the histogram of these n random variables that you have just drawn. Then, this histogram looks like a normal distribution (this is what they claim). So here is what I imply from their statement: If that would be true, than any sufficiently large sequence $A_1, ..., A_n$ would "form" a normal distribution. However, this would mean that at least from a certain value $n_0 > 0$ on, all $A_j$ with $j \geq n_0$ would be normal distributed. But does this make any sense? We know that they follow a different distribution, right? So their theroy is wrong, right? Other questions related to this are: What can we imply from this very specific statement of the CLT about the average of random variables? Can we imply anything on the random variables themselves? Or some other statements? Is there any theorem that the above statement can be implied from, using CLT? Thank you guys so much for your help! I would also appreciate any good literature that could help me understand.
