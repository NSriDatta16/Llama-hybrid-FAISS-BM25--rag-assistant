[site]: datascience
[post_id]: 24410
[parent_id]: 24401
[tags]: 
The embeddings are floating point vectors, it's very unlikely that they are exactly the same. And even if they were, it will only minorly impact the performance of your model, which is not what you are after anyway, because you are debugging. That said, if you want to use it for model selection you have a few alternatives. The easiest one is to apply PCA one time to your whole embedding space and take the first n dimensions. This way you reduce your dimensionality without throwing away too much information. A better but more difficult approach would be to train your own Glove vectors, either on a public corpus or a private one, and set a low dimensionality during the training procedure. It might be difficult to use your findings on these embeddings for model selection because more expressiveness could lead to much better performance with deeper models or could lead to more overfitting.
