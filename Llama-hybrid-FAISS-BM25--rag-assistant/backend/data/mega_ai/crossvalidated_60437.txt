[site]: crossvalidated
[post_id]: 60437
[parent_id]: 60315
[tags]: 
As @NickCox explained a “domain expert” is typically someone who knows about the field or issue at hand. The implicit point is that the statistician/modeler/data miner and the domain expert are both experts but not in the same thing. One knows about data analysis and the other about whichever process/phenomenon the data pertains to. Simply calling them “experts” would be confusing. As far as I know, the phrase comes from software engineering because to build a computer system, you need to understand the process it is supporting (which people need access to what, where does which information come from, which reports/output should be produced for whom, etc.) Here process can be a manufacturing process, an administrative process, a medical diagnostic, anything really. For example if we are talking about managing the performance of a chemical process, domain knowledge would be knowledge of chemistry. It is generally difficult for people who are used to deal with the process everyday to describe it formally or to list all the things they know about it. Some things that are obvious to them might even fail to come up in the discussion precisely because they are obvious. There are organizational ramifications as well, people might be unwilling to reveal how they do their jobs (for example if they are “cutting corners” or if their expertise provide them with some career advantages). Often, what actually goes on on a factory floor or in some administrative process is very different from what management think is happening or what official rules imply. This is why it is a challenge to extract relevant information and people have been worrying about tools to extract that information from those who have it, the “domain experts”. In your paragraph, the idea would be to use visualization to communicate preliminary results (e.g. relations between different variables revealed by the data mining effort) to people who know the process but might not be familiar with data analysis and numerical summaries. They would then presumably use their domain knowledge to suggests improvements, interpretations or new hypotheses for the data miner to explore. Incidentally, many machine learning efforts (e.g. Kaggle, “data hackathons”) seem to proceed, rightly or wrongly, from the assumption that much can be achieved without access to domain knowledge by modeling away with a set of standard techniques and a lot of cleverness to fiddle with the tools and put it all together.
