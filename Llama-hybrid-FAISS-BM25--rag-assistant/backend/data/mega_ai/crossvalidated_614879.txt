[site]: crossvalidated
[post_id]: 614879
[parent_id]: 
[tags]: 
Will Support Vector Machine always return linear weights and bias?

This code create the linear bondary between two classes. % Töm clear all close all clc x1 = randn(50, 2); x2 = 10 + randn(50, 2); x = [x1; x2]; y = [linspace(1, 1, 50)'; linspace(-1, -1, 50)']; % Träna en linjär SVM med quadprog C = 10; H = (y*y').*(x*x'); H = H + 10*eye(size(H)); f = -ones(size(y)); Aeq = y'; beq = 0; lb = zeros(size(y)); ub = C*ones(size(y)); %alpha = qp([], H, f, Aeq, beq, lb, ub) %alpha = qp([], H, f, [], [], [], [], [], [eye(size(H)); -eye(size(H)); Aeq; -Aeq], [ub; -lb; beq; -beq]) [alpha, solution] = quadprog(H, f, [eye(size(H)); -eye(size(H)); Aeq; -Aeq], [ub; -lb; beq; -beq]); % Beräkna vikterna för linjär SVM w = sum(repmat(alpha.*y,1,size(x,2)).*x,1); % Hitta stödvektorer tol = 1e-4; sv_idx = find(alpha>tol); b = mean(y(sv_idx)-x(sv_idx,:)*w'); % Plotta träningsdata och linjär SVM figure; scatter(x(y==-1,1),x(y==-1,2),'r'); hold on scatter(x(y==1,1),x(y==1,2),'g'); h = ezplot(@(x2,x3) w(1)*x2+w(2)*x3+b); set(h,'Color','k','LineWidth',2); ylim([min(x(:, 1)) max(x(:, 1))]); xlim([min(x(:, 2)) max(x(:, 2))]); legend('Röda','Gröna','SVM-gräns', 'location', 'northwest'); grid on This creates a nonlinear boundary between two classes. % close close all clear all % Skapa träningsdata x1 = randn(50, 2); x2 = 10 + randn(50, 2); x = [x1; x2]; y = [linspace(1, 1, 50)'; linspace(-1, -1, 50)']; % Träna en icke-linjär SVM med quadprog och RBF-kärna C = 10; sigma = 1; n = size(x,1); K = zeros(n,n); for i = 1:n for j = 1:n K(i,j) = exp(-norm(x(i,:)-x(j,:))^2/(2*sigma^2)); end end H = (y*y').*K; H = H + 10*eye(size(H)); f = -ones(size(y)); Aeq = y'; beq = 0; lb = zeros(size(y)); ub = C*ones(size(y)); %alpha = qp([], H, f, Aeq, beq, lb, ub); [alpha, solution] = quadprog(H, f, [eye(size(H)); -eye(size(H)); Aeq; -Aeq], [ub; -lb; beq; -beq]); % Beräkna vikterna för icke-linjär SVM w = zeros(1,size(x,2)); for i = 1:n w = w + alpha(i)*y(i)*x(i,:); end w % Hitta stödvektorer tol = 1e-4; sv_idx = find(alpha>tol); b = mean(y(sv_idx)-K(sv_idx,:)*alpha); b % Vektor för hyperplanet - Alternativ w = (alpha .* y)' * x b = mean(y - K*(alpha .* y)) % Plotta träningsdata och icke-linjär SVM figure; hold on; scatter(x(y==-1,1),x(y==-1,2),'r'); scatter(x(y==1,1),x(y==1,2),'g'); [x1_grid,x2_grid] = meshgrid(linspace(min(x(:,1))-10,max(x(:,1))+10,100),linspace(min(x(:,2))-10,max(x(:,2))+10,100)); X_grid = [x1_grid(:),x2_grid(:)]; K_grid = zeros(size(X_grid,1),n); for i = 1:size(X_grid,1) for j = 1:n K_grid(i,j) = exp(-norm(X_grid(i,:)-x(j,:))^2/(2*sigma^2)); end end y_grid = K_grid*alpha; y_grid = reshape(y_grid,size(x1_grid)); contour(x1_grid,x2_grid,y_grid); grid on This also create a nonlinear boundary between two classes. % Töm clear all close all clc % Träningsdata x1 = randn(50, 2); x2 = 10 + randn(50, 2); X = [x1; x2]; y = [linspace(1, 1, 50)'; linspace(-1, -1, 50)']; % Polynomisk kärna d = d; K = (1 + X*X').^d; % Kvadratiskt optimeringsproblem H = (y*y').*K; H = H + 10*eye(size(H)); f = -ones(size(y)); A = []; b = []; Aeq = y'; beq = 0; lb = zeros(size(y)); ub = ones(size(y)) * Inf; %alpha = quadprog(H, f, A, b, Aeq, beq, lb, ub); [alpha, solution] = quadprog(H, f, [eye(size(H)); -eye(size(H)); Aeq; -Aeq], [ub; -lb; beq; -beq]); % Vektor för hyperplanet w = (alpha .* y)' * X; b = mean(y - K*(alpha .* y)); % Plotta datapunkterna och hyperplanet x1 = linspace(min(X(:,1)), max(X(:,1)), 100); x2 = linspace(min(X(:,2)), max(X(:,2)), 100); [X1, X2] = meshgrid(x1, x2); XX = [X1(:) X2(:)]; KK = (1 + XX*X').^d; decision_values = KK*(alpha .* y) - b; decision_values = reshape(decision_values, size(X1)); contour(x1, x2, decision_values, [0 0], 'LineWidth', 2) hold on scatter(X(:,1), X(:,2), 50, y, 'filled') colormap('cool') colorbar xlabel('X_1') ylabel('X_2') title(sprintf('Polynomial kernel, degree %d', d)) What they all have in common is that $w$ is a $n$ long array, in this case 2 and $b$ is a scalar. Question: If I only want to use my weights $w$ and bias $b$ to classify the data, can I create for example a nonlinear curve from only $w$ and $b$ that are going to represent the boundary? In this case I'm not using $w$ when I'm using a kernel. The array $w$ is only used when I have a linear kernel. But I want to create a nonlinear boundary in form of an equation. Is that possible?
