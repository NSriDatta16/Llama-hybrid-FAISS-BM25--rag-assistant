[site]: datascience
[post_id]: 28553
[parent_id]: 
[tags]: 
Can you have too uniform test data in a feedforward neural network?

I have been playing around trying to implement my own feedforward neural network. To try it out I decided on an easy example. 3 inputs, 3 output. When you send in (1,0,0) the expected output is (0,1,0) . When you send in (0,1,0) the expected output is (0,0,1) . And so on, you see the pattern. When working with a test data size of one I get a perfect result. After 100 training sessions with the input of (1,0,0) i get (0.0192068, 0.980584, 0.0187576) and the more I train the better the result is. However when I try with 2 sets of training data (1,0,0) and (0,1,0) , I get the same result for trying both inputs after the training: (0.0189567, 0.499995, 0.500002) which isn't really what I wanted. The more I train the more even the result gets. When I try with a 100 diffrent training examples (using an equal distribution of all 7 combinations: (1, 0 ,0), (0, 1 ,0), (0, 0 ,1), (1, 1 ,0), (0, 1 ,1), (1, 0 ,1), (1, 1 ,1) ) the results get just more and more uniform : (0.420004, 0.429997, 0.430002) . So my question is this: Could this result be in response to a general weakness of feedforward neural networks, in other words, it can't handle training data that is too uniform? Or do you think this could be because of a math error that has snuck in somewhere? I am afraid I am new enough to the concept of feedforward neural networks I can't tell one from the other. Ps.: For those who are curious about what code I am using I am following this code: https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network2.py I am doing a port to C++ from that code example. I find porting code is a good way to learn because you really have to dig in deep into what every piece of the code is doing to get a clear understanding of how to port it. I also happen to be one of those weird ones that are more comfortable with C++ rather than Python DS.
