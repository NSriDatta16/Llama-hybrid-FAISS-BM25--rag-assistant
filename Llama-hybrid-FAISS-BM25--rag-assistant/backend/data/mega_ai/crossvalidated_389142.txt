[site]: crossvalidated
[post_id]: 389142
[parent_id]: 389132
[tags]: 
The problem you have to deal with it seems is one of multicollinearity since you stated that both $A$ and $B$ are correlated. If $A$ and $B$ are not strongly correlated, you may be able to safely ignore the multicollinearity and simply include a model that includes $A$ , $B$ , any other relevant relevant predictors and relevant interaction terms. If $A$ and $B$ are highly correlated, then you have some work to do and there are a few options on how to proceed. If it's not terribly important to distinguish unique effects between $A$ and $B$ , then you could consider forming a composite variable from $A$ and $B$ and then include that in your model. For example, if it made sense to form an average or weighted average of $A$ and $B$ , say $C = (A+B)/2$ , then you could include $C$ and the interaction between $C$ and $W$ in your model. Then $C$ would account for the affect of both $A$ and $B$ on $W$ . Alternatively, you could perform a principal components analysis on $A$ and $B$ and use several principal components in your model instead of $A$ and $B$ - but this may make interpretation difficult. Another approach would be to perform an analysis that is not sensitive to multicollinearity. For example, you could consider performing Ridge Regression . This methods allows you to handle multicollinearity problems by creating biased --but potentially more precise -- estimators of the regression coefficients. I won't go into details about this method here as you can easily search for Ridge Regression on CV or check out the text Collinearity and Weak Data in Regression which describes these and other "multicollinearity-proof" methods in detail. UPDATE BASED ON YOUR ADDITIONAL COMMENT If I understand your comment correctly, you are interested in determining if there is an interaction effects between $A$ and $B$ . You can include interaction terms between and $A$ and $B$ in your model. Your model would then look like this: $Y = \beta_0 + \beta_WW + \beta_AA + \beta_XX + \beta_{INT_{WA}}WA + \beta_{INT_{WX}}WX + \beta_{INT_{AX}}AX + \beta_{INT_{WAX}}WAX $ Then you can test to determine if there are interaction effects by testing if the estimated coefficient(s) associated with the relevant interaction(s) are (statistically) significantly different from zero.
