[site]: crossvalidated
[post_id]: 519588
[parent_id]: 519575
[tags]: 
I think the easiest way is just index chasing, not anything elegant. I'll assume the $u$ are all mean zero; if not, the identity does not hold, and the left-hand side isn't the covariance matrix. A. $E[u_{it}u_{js}]=\sigma_{ij}$ if $t=s$ and zero otherwise. B. Now write $S$ for the matrix on the right-hand side, and $s_{itjs}$ for the entry corresponding to $u_{it}$ and $u_{js}$ . Clearly $E[u_{it}u_{js}]=s_{itjs}$ ; that's just what A said. C. The entries of the right-hand side matrix (call it $S$ ) are also either $\sigma_{ij}$ or 0 for some $(i,j)$ . In fact, $T$ of them are $\sigma_{ij}$ for each $(i,j)$ , and $T(T-1)K^2$ of them are zero D. So we just need to work out if the indices match up. The $i$ index varies fastest, so the top left block of the left-hand side has $u_{i1,j1}$ , then the next block to the right has $u_{i1,j2}$ and the first block on the second row has $u_{i2,j1}$ and so on. That is, the $(it,jt)$ entries -- the diagonal blocks -- have entries $\sigma_{ij}$ and the $(it,js)$ entries for $s\neq t$ are zero. That's exactly $I_T\otimes \Sigma_u$ . More formally, if we write $(p,q)$ for the indices of the big matrices, then $p=i+(t-1)K$ and $p=j+(s-1)K$ , and that works for both sides.
