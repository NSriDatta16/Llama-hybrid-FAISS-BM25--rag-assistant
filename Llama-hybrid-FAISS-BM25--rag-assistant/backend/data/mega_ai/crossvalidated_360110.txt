[site]: crossvalidated
[post_id]: 360110
[parent_id]: 360091
[tags]: 
So, for some PDF and observed datapoints, the likelihood function is simply the product of the PDF for each observed datapoint. $L(\theta | x) = \prod_{x=1,..,n, y=1,..,n} f(x, y | \theta_1, \theta_2)$ The log likelihood is (you guessed it!) simply the log of the product of the PDF. Now, one property of logs is that log(x y z) = log(x) + log(y) + log(z). So, the loglikelihood can be expressed as the sum of log PDF, instead of the product of the PDF. $$log(L(\theta | x)) = \sum_{x=1,...,n,y=1,...,n} log(f(x, y | \theta_1, \theta_2) $$ Now, we use this same property of logs to rewrite the PDF. I'm going to leave that to you, but you'll use two properties: 1) $log(a * b) = log(a) + log(b)$ 2) $log(a^b) = b * log(a)$ Now, where does the $\bar{x}$ come in? Well, $\bar{x}$ is the average value for x. In this solution, it's really a convenient way of rewriting the sum of x. For any series x, $\sum x = n * \bar{x}$.
