[site]: crossvalidated
[post_id]: 369811
[parent_id]: 369778
[tags]: 
I would use something simple. If you want to measure relative deviations within a session , you can calculate the coefficient of variation which basically measures what you described when you compared means to standard deviations (it is actually the ratio of standard deviation to the mean). The intuition behind cv is that it tends to be low for narrow distributions (such as a Gaussian with low standard deviation) and grows for wide distributions or distributions with long tail . Using your sample data, you get the following values for the rows: cv[0] = 0.1392971502227546 cv[1] = 0.2059044516443989 cv[2] = 0.13708934947422577 cv[3] = 0.16106278913054062 cv[4] = 0.21328418997614207 cv[5] = 0.32100014994179166 cv[6] = 0.27541420818528267 cv[7] = 0.9984018893647104. Clearly, the last session has a CV close to 1, meaning that the deviations in that case are comparable to the mean. In other words, the average is blurred by the large deviations. Another approach could be to compare result-wise numbers in a session to the distribution you obtained for that same result (same column) in other sessions. In this case, you can use the z-score which is used in many applications related to Gaussian distribution, but you can use it to estimate deviations in each result column. The z-score effectively measures the deviation of your value from the population average in units of the standard deviation of that population. That is, if you already have a large deviation in a result, you can expect large differences. But it will tell you if a specific session has unexpectedly large deviation. That said, I first calculated the mean and standard deviation in each result column: res_means = [740.625, 954.25, 897.125, 943.375, 1050.625, 620.375, 881.5, 1320.875] res_std = [277.986, 136.124, 363.833, 333.640, 174.109, 231.403, 116.040, 303.365] And then the z-scores for each session per result: z_scores[0] = [0.656, 0.093, 0.45, 0.475, 1.346, 0.581, 1.503, -0.915] z_scores[1] = [0.49, -1.588, 0.373, 0.514, 0.978, 0.309, -1.408, -0.751] z_scores[2] = [0.479, 0.38, -0.184, 0.439, -1.203, 0.439, -1.09, -1.044] z_scores[3] = [-0.225, 1.269, 0.178, -0.231, -0.422, 0.382, -0.331, -0.968] z_scores[4] = [0.321, 0.629, 1.123, 0.901, -0.072, 0.456, 0.314, 0.346] z_scores[5] = [0.138, -0.582, 0.626, 0.115, -0.957, 0.067, 0.745, 1.5] z_scores[6] = [0.681, 1.114, -0.135, 0.304, 1.311, 0.382, 1.072, 1.424] z_scores[7] = [-2.541, -1.316, -2.432, -2.518, -0.979, -2.62, -0.805, 0.409] If you look at the values, the last session has many results with large absolute z-score values. As an illustration of this approach, you can count the number of results with absolute z-scores higher than a threshold, let's say 2. This will give you 0 for all sessions but the last, in which case you have 4 result columns with a large absolute z-score.
