[site]: crossvalidated
[post_id]: 304689
[parent_id]: 304687
[tags]: 
A proper procedure always includes training - validation and test set. A small dataset is usually not a good reason to not include a test set, as only this will give you a reasonable estimation of your model. Your approach does not necessarily lead to overfitting. But you will not notice if that happens. How usefull is a model, that does not generalize enough? Especially in a highly imbalanced classification problem, you should hold out a test set. Notice that in k-fold CV every instance is predicted exactly once , so in fact you do not "average" anything here. You just kind of "merge" your predictions of each fold. After you select your threshold, tune parameters etc. you want to use all of your data to train a final model to get the best possible results.
