the Machine Intelligence Research Institute to work toward the creation of self-improving Friendly AI. MIRI's writings that an AI with the ability to improve upon its own design (Seed AI) would rapidly lead to superintelligence. These Singularitarians believe that reaching the singularity swiftly and safely is the best possible way to minimize net existential risk. Many people believe a technological singularity is possible without adopting Singularitarianism as a moral philosophy. Although the exact numbers are hard to quantify, Singularitarianism is a small movement, which includes transhumanist philosopher Nick Bostrom. Inventor and futurist Ray Kurzweil, who predicts that the Singularity will occur circa 2045, greatly contributed to popularizing Singularitarianism with his 2005 book The Singularity Is Near: When Humans Transcend Biology. What, then, is the Singularity? It's a future period during which the pace of technological change will be so rapid, its impact so deep, that human life will be irreversibly transformed. Although neither utopian or dystopian, this epoch will transform the concepts we rely on to give meaning to our lives, from our business models to the cycle of human life, including death itself. Understanding the Singularity will alter our perspective on the significance of our past and the ramifications for our future. To truly understand it inherently changes one's view of life in general and one's particular life. I regard someone who understands the Singularity and who has reflected on its implications for his or her own life as a "singularitarian." With the support of NASA, Google, and a broad range of technology forecasters and technocapitalists, the Singularity University opened in 2009 at the NASA Research Park in Silicon Valley with the goal of preparing the next generation of leaders to address the challenges of accelerating change. In July 2009, many prominent Singularitarians participated in a conference organized by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss the potential impact of robots and computers and the possibility that they may become self-sufficient and able to make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire autonomy, and to what degree they could use such abilities to pose a threat or hazard (i.e., cybernetic revolt). They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and independently choose targets to attack with weapons. They warned that some computer viruses can evade elimination and have achieved "cockroach intelligence". They asserted that self-awareness as depicted in science fiction is probably unlikely, but that there are other potential hazards and pitfalls. Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions. The President of the AAAI has commissioned a study of this issue. Reception There are several objections to Kurzweil's singularitarianism, even from optimists in the A.I. field. For instance, Pulitzer Prize-winning author Douglas Hofstadter argued that Kurzweil's predicted achievement of human-level A.I. by 2045 is not viable. Even Gordon Moore, the namesake of Moore's Law that predicated the notion of singularity, maintained that it will never occur. According to some observers, these criticisms do not diminish enthusiasm for singularity because it has assumed a quasi-religious response to the fear of death, allowing its adherents to enjoy the benefits of religion without its ontological burdens. Science journalist John Horgan wrote: Let's face it. The singularity is a religious rather than a scientific vision. The science-fiction writer Ken MacLeod has dubbed it "the rapture for nerds," an allusion to the end-time, when Jesus whisks the faithful to heaven and leaves us