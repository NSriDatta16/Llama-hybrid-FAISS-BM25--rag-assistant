[site]: datascience
[post_id]: 63360
[parent_id]: 63305
[tags]: 
The best way to understand that part is by looking at figure 1 in the AlphaGo Zero paper . The neural network (NN) minimizes the differences between its own policy $p_t$ and the MCTS policy $\pi_t$ . The value of $\pi_t$ is produced by the MCTS self-play which in return uses the NN from the previous iteration. The same goes for $v_t$ and $z$ . In each iteration the weights of the NN are adjusted to minimize the distance between $v_t$ (output of the NN) and $z$ (output of the MCTS) as defined by the loss function. $z$ does not have a time index here as the full self-play produces just a single value for $z$ each time it is conducted. TLDR for your first question: Both, $\pi$ and $v$ , are being produced by the MCTS as input to the NN. (The indexing in the paper is a bit confusing in my opinion so it is probably easiest to just look at it as stated above) Now, with "input" I do not mean input on the input layer of the NN. As described in the appendix under "Neural network architecture" the input is a "19 x 19 x 17 image stack". which contains the following information: The positions of player 1 for the latest 8 rounds (8 feature planes) The positions of player 2 for the latest 8 rounds (8 feature planes) A color feature indicating whose turn it is (1 feature planes) And those 17 feature planes ( $8+8+1$ ) combined with the $19\cdot19$ sized board is the $19\cdot19\cdot17$ input the NN receives thru its input layer. $\pi$ and $z$ are passed to the NN via the loss function only (i.e. they are the target values in this supervised learning problem!). TLDR for your second question: $\pi$ and $z$ are not fed to the NN thru the input layer but just via the loss function as target values.
