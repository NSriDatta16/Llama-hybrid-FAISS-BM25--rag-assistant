[site]: datascience
[post_id]: 23320
[parent_id]: 23297
[tags]: 
Training GANs becomes much more difficult with increasing input dimensionality. I encountered that sometimes even small changes to your network can decide about convergence/divergence of your network (like initialization of your variables). I recommend following the tipps from https://github.com/soumith/ganhacks . Another thing I personally recognized is that you should not use as many Conv2DTranspose layers as you do in your current network. Try instead increasing the latent space.
