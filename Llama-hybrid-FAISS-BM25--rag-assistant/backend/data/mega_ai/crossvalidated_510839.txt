[site]: crossvalidated
[post_id]: 510839
[parent_id]: 510653
[tags]: 
You should refer to the documentation for specifics. Anyway, an MDP consists of states $S$ , actions $A$ , transition probabilities $P$ , and rewards $R$ . In software implementations, $P$ and $R$ are often both implemented in some step function. The state and action spaces $S, A$ don't have to be implemented per say, but gym does have some relevant datatypes to make specifying them easy. Also I want to point out that most of the "flashy applications" -- robotics, atari, etc -- are just particular instances of MDPs.
