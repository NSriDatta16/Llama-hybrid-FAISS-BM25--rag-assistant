[site]: stackoverflow
[post_id]: 2595284
[parent_id]: 2595176
[tags]: 
My take on it is that you always run the basic classifiers first to get some sense of your data. More often than not (in my experience at least) they've been good enough. So, if you have supervised data, train a Naive Bayes classifier. If you have unsupervised data, you can try k-means clustering. Another resource is one of the lecture videos of the series of videos Stanford Machine Learning , which I watched a while back. In video 4 or 5, I think, the lecturer discusses some generally accepted conventions when training classifiers, advantages/tradeoffs, etc.
