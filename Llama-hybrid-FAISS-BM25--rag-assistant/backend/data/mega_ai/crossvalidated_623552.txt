[site]: crossvalidated
[post_id]: 623552
[parent_id]: 
[tags]: 
Serial correlation and heteroskedasticity in a first-stage regression of a 2SLS

I am about to test a Campbell-Mankiw's based model like: $$\Delta c(t) = \mu + \lambda \Delta y(t) + \theta r(t) + e(t)$$ where $ \Delta y(t) = \ln(y(t)) - \ln(y(t-1)),~ \Delta c(t) = \ln(c(t)) - \ln(c(t-1)), $ and $r(t)$ is the real interest rate. The test requires the use of instrumental variables because both $\Delta y(t)$ and $r(t)$ may be serially correlated to $ e(t).$ I've already tested some IVs and they seem to be both significant and strong (at least the first-stage regressions' Fs are a lot higher than 10). However, some first-stage regressions presents second, third or fourth order serial correlation, and others are heteroskedastic (they pass both Breusch-Pagan's and Gleijser's LM tests but fail Harvey's one). It seems intuitive that these first-stage regressions should not have any serial correlation problem. However, I am not sure about how serious is the heteroskedasticity issue in this case. Is there any rule of thumb I should follow?
