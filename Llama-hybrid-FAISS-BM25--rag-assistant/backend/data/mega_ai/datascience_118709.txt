[site]: datascience
[post_id]: 118709
[parent_id]: 
[tags]: 
What do I make of all classification scores being equal to 1?

I've built an XGBoost classifier on a dataset that has 51 columns and a 1000 rows with following code: from xgboost import XGBClassifier from sklearn.model_selection import train_test_split from sklearn import metrics from sklearn.model_selection import cross_val_score X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42) xgbc = XGBClassifier() xgbc.fit(X_train, y_train) y_pred = xgbc.predict(X_test) rep = metrics.classification_report(y_test, y_pred) print(rep) And I get the scores as follows. Then I performed 5 fold cross-validation: cross_val_score(xgbc, X, y, cv=5) And got the following cv scores. 1.0 1.0 0.99497487 0.98994975 0.98492462 I'm fairly new to machine learning, and I can't figure out if my model is peforming excellently or if it has overfit. Note: In the training data(X), 10-50% of all values in most feature columns are missing. I did not impute the missing values as tree algorithms are robust to missing values.
