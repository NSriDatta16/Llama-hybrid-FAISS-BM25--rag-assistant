[site]: crossvalidated
[post_id]: 476135
[parent_id]: 476133
[tags]: 
You may view building an Autoencoder is doing a representation learning. For NLP, people are doing sentence embedding learning benchmark. SentEval: evaluation toolkit for sentence embeddings We assess their generalization power by using them as features on a broad and diverse set of "transfer" tasks. SentEval currently includes 17 downstream tasks. We also include a suite of 10 probing tasks which evaluate what linguistic properties are encoded in sentence embeddings. Our goal is to ease the study and the development of general-purpose fixed-size sentence representations. I think this also applicable for your case. For selecting the layer size, It can be depending on your data size. Say if you have 10K images, may be the embedding size is 64, and if you have 1 million images, the size can be 256.
