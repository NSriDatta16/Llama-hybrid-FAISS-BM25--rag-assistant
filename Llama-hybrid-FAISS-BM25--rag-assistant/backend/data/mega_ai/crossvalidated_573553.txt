[site]: crossvalidated
[post_id]: 573553
[parent_id]: 573535
[tags]: 
The likelihood principle states that two experiments with the same likelihood functions (up to a multiplicative constant) of the same parameter $\theta$ , provide the same evidence on the parameter $\theta$ . So approximating the likelihood function (as in your example) does violate the likelihood principle, in the sense that it gives you a (slightly) different inference than that of someone who observes the same likelihood function and uses it without approximations. Note however that in the broader Bayesian view, probabilities in general are subjective . The likelihood does not describe the "true" data generating model, but rather what you know (or believe) about the data generating model. So in that sense there's no such thing as the "real" likelihood. The likelihood principle is about deriving inference in way that is consistent with your prior knowledge/beliefs.
