[site]: datascience
[post_id]: 66489
[parent_id]: 66484
[tags]: 
At a high level you need to find historical data matching what you need to forecast (average temperature) and any factors which influence it. So you need to be a domain expert, have access to one, or find data and do exploratory analysis to find for yourself what factors are important. If you're using 30% to train the model, you're holding 70% back to test it. Since you're trying to forecast a timeseries you generally want to work out how the model scores in the future - this implies you train the model with the first 30% of your historical data and test it on the last 70% - which probably won't work well. In your case say you're training using yearly average temps for 100 years. It would mean you train on the first 30 years of data - from 70 years ago which doesn't seem like it would work. An alternative is blocked cross validation where you split the data into blocks which are long enough to minimise the effect of autocorrelation and then assign the blocks into test and train. I've found this method to be quite effective.
