[site]: crossvalidated
[post_id]: 96705
[parent_id]: 96561
[tags]: 
Here is a straightforward example from a blog entry from John Kruschke's Blog ( http://doingbayesiandataanalysis.blogspot.de/ ). This is a Beta-Binomial Model (The sum of independent Bernoulli variables with equal probability is binomially distributed) where $y_{ij}$ is the $i^{th}$ outcome (0,1) of the $j^{th}$ group with probability $\theta_j$. The beta(a,b) distribution is placed as a conjugate prior on the $\theta_j$'s. The hyperparameters $a$ and $b$ determine the strenght of shrinkage exerted on the $\theta_j$'s. If this strength should be determined by the data themselves, it is necessary to place a hyperprior on those hyperparameters . I suppose this is what you mean by "second order prior distribution". In this example, the hyperpriors are not place directly on $a$ and $b$, but on a convenient reparametrization, namely $\mu = \frac{a}{a+b}$ (the mean of the beta distribution) and $\kappa = a+b$ ("sample size"). The parameters $A_\mu$, $B_\mu$, $S_\kappa$, $R_\kappa$ are the parameters of the hyperprior and are set to fixed values unless there would be another level in the data hierarchy such that the hyperparameters $a$ and $b$ would themselves be of interest.
