[site]: datascience
[post_id]: 54371
[parent_id]: 54369
[tags]: 
I'm assuming you understand the original gan paper. So there are 2 distribution at the start - first distribution that the original images follow and a random distribution that the fake images follow. Discriminator task is to figure out which image came from what distribution, whereas generator is trying to learn the real distribution and make the random distribution similar to the real one. Now giving image labels as input is like giving extra bit of information about the distribution. This doesn't change the game, it's the same unsupervised one. There will two consequences of adding this extra bit of information : Even the random distribution that the fake images follow will have some pattern. Hence convergence will be faster. You can control the output of generator at test time by giving label for image you want to generate.
