[site]: crossvalidated
[post_id]: 427070
[parent_id]: 
[tags]: 
Reinforcement Learning - difference between a Policy and a State transition matrix

https://towardsdatascience.com/getting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb A state transition probability tells us, given we are in state s, what the probability the next state $s'$ will occur. $P_{ss'} = P[S_{t+1} = s' | S_t = s]$ We can also define all state transitions in terms of a state transition matrix where each row now tells us the transition probabilities from one state to all possible successor states. $P = \begin{bmatrix} P_{11} & P_{12} & \dots \\ \vdots & \ddots & \\ P_{K1} & & P_{KK} \end{bmatrix}$ A policy is a distribution over actions given states. Policies give the mappings from one state to the next. $\pi(a|s) = P[A_t = a | S_t = s]$ My question is: why do we need the variable A and a to describe the action? Isn't the policy simply the state transition matrix? Why can't the policy simply be written as $\pi(a|s) = P[S_{t+1} = s' | S_t = s]$
