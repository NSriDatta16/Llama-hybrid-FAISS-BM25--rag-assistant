[site]: crossvalidated
[post_id]: 175606
[parent_id]: 175599
[tags]: 
Too long for a comment: If you're applying some regularization $C$, you're constricting the model flexibility so it's not always going to be the case that the SVM will perform well on training data. It sounds as if you're applying labels randomly to the data (suggested by 50% accuracy), regardless of $(x,y)$ coordinates, it shouldn't be surprising that the SVM will generally have difficulty predicting points using $(x,y)$ data, since there's no information for the model to learn from. 25 points is a very small amount of data to use for any classification task. Your prediction function omits an intercept term. Most SVM software estimates a parameter $b$ which is used in the prediction equation in this manner: $$ \hat{y}=b+\sum^n_{i=1}z_iy_iK(x_i,x) $$ where $\hat{y}$ is the signed distance from the decision boundary. Using accuracy is the wrong metric to assess model performance if the costs of misclassficiation are not identical, since it assumes the signum function is the correct decision boundary, which does not respect mis-classification utilities. You don't specify what kernel function you're using, but not all kernel functions are equally well-suited to some specific class. To check if your optimizer is working correctly, see if your output matches that of some other SVM estimation function.
