[site]: crossvalidated
[post_id]: 523051
[parent_id]: 
[tags]: 
Is there theoretical guarantee that principal components are orthogonal?

In the sources I've seen, the support for principal components being orthogonal is rooted in the covariance matrix being symmetrical, which means eigenvectors of the covariance matrix corresponding to distinct eigenvalues are pairwise orthogonal. But from what I can see, there is no theoretical guarantee that all the eigenvalues will be distinct. If we have duplicate values, we may lose the orthogonality unless you form an orthogonal eigenbasis, but I don't think I've seen the concept of "orthogonal eigenbasis" in introductory PCA texts where it is taught that "PCs are orthogonal." So it seems the concept of "principal components" being "orthogonal" is more from a practical perspective because we probably don't see many cases where we see duplicate eigenvalues for a covariance matrix. Is this the case, or is there actually some theoretical guarantee that we'd get distinct eigenvalues for the covariance matrix? I can't see the latter being true since we could run into the case of rank deficiency, and have multiple eigenvalues be zero.
