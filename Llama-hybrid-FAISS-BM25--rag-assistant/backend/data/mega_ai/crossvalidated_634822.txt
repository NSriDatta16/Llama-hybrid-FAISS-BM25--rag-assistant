[site]: crossvalidated
[post_id]: 634822
[parent_id]: 634807
[tags]: 
The problem can be traced back to numerical issues in the calculation of XTX_inv via matlib::inv : matlib::inv(XTX) %*% XTX # carbohydrate age weight protein # [1,] 0.99999309 -0.00031792 -0.00078345 -0.00010996 # [2,] -0.00000260 0.99988772 -0.00030058 -0.00004118 # [3,] 0.00000747 0.00033684 1.00084915 0.00011914 # [4,] 0.00000563 0.00026482 0.00063345 1.00008974 You can do better by using base::solve : solve(XTX) %*% XTX # carbohydrate age weight protein # carbohydrate 1.000000e+00 -2.046363e-12 -3.637979e-12 -5.684342e-13 # age 5.551115e-17 1.000000e+00 1.421085e-14 8.881784e-16 # weight 1.387779e-17 1.776357e-15 1.000000e+00 6.661338e-16 # protein 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 Replacing matlib::inv(XTX) by solve(XTX) in your code solves the apparent inconsistency. Note, however, that stats::lm computes b2 by using a QR decomposition of X , which is more numerically stable: b3 Addendum (2024-01-14) Both matlib::inv and base::solve ultimatly use Gaussian elimination with partial pivoting to calculate the inverse of a matrix. matlib::inv does this by calling matlib::Inverse which in turn calls matlib::gaussianElimination . While the latter provides a reasonable implementation for didactic purposes, base::solve leverages the superior LAPACK subroutine dgesv for its computations. That being said, if the tolerance argument tol of matlib::Inverse , used to check for zero pivots, is set to .Machine$double.eps , we get a better inverse: matlib::Inverse(XTX, tol = .Machine$double.eps) %*% XTX # carbohydrate age weight protein # [1,] 1.000000e+00 1.136868e-12 4.547474e-12 2.273737e-13 # [2,] -2.386980e-15 1.000000e+00 -2.096101e-13 -3.863576e-14 # [3,] 1.115913e-13 5.175860e-12 1.000000e+00 1.780798e-12 # [4,] 6.261658e-14 2.927436e-12 7.105427e-12 1.000000e+00 Instead of solving the normal equations $X^\top X b = X^\top y$ directly (e.g., via Gaussian elimination with partial pivoting) to calculate the OLSE $b$ , stats::lm uses a QR decomposition of $X$ . Some details are given in this answer . This avoids calculations with the matrix cross-product $X^\top X$ , whose condition number squares the one of the (potentially ill-conditioned) design matrix $X$ . Another advantage of stats::lm 's (more precisely, dqrdc2 's) QR decomposition with column pivoting is that it also works with rank-deficient (design) matrices.
