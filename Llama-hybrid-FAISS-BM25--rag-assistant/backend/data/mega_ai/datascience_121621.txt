[site]: datascience
[post_id]: 121621
[parent_id]: 
[tags]: 
How do I interpret GRAD-CAM's feature attribution to time series zero-padding in a CNN classifier?

Problem setting: MTS Classification with CNN architecture I have a multivariate time series (MTS) dataset that contains 30 features. The goal is to solve a classification problem on this MTS dataset. It is important that I have as much explainability as possible, hence extracting features from the dataset and classifying on them is undesired. Every MTS in the dataset has a different length. I zero-padded the MTS in the dataset to make them equal length (to length 131). I use the CNN architecture that is described in the paper XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification . I used the Python implementation in the tsai package. I used per-channel standardization on my data. Problem: GRAD-CAM gives feature attribution to padding Since this is a CNN architecture, I can use GRAD-CAM on the first Conv 1D layer after the input, indicated in red in the figure above. Visualising the result for a time series of length 27 (+ padding to 131) from the test set, I get the following result, where the y-axis has no meaning, of course, and the x-axis is the time: The zero-padding receives a remarkable attribution from GRAD-CAM. I tried this for different test set instances, and the results are equal or sometimes even worse. My question: How do I interpret this result? Does the classifier undesirably use the padding for its classification? Can I ignore the feature attribution to the padding and just focus on time stamps 0 to 27? How can I avoid this result? What I already considered During my search on the Internet, I found no way of making a CNN ignore padding during training or inference. Only RNNs seem to have this ability , but they suffer from poor explainability . The paper Effects of padding on LSTMs and CNNs only examines the effect on classification accuracy. The paper Time series classification for varying length series suggest uniform scaling as a pre-processing alternative. However, due to the nature of my time series and the goal of the explainability, this is not a solution for me. Other propositions of the paper are only applicable to univariate time series. The most related information I found is a question on this website ( here ) that encounters the same problem for images. There is no satisfactory answer. Applying GRAD-CAM on the 2d convolutional block suffers from the same problem. Applying GRAD-CAM on another convolutional MTSC algorithm, such as InceptionTime, suffers from the same problem.
