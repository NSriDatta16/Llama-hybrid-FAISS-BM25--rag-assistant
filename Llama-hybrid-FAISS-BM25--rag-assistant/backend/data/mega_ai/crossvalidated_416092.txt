[site]: crossvalidated
[post_id]: 416092
[parent_id]: 415439
[tags]: 
If you were only interested in decay as a single predictor of patient/normal status, then this problem would disappear if you use decay non-parametrically. Just rank order the cases by decay values and plot true-positive fractions against false-positive fractions for each decay value as a cutoff in sequence to get a receiver operating characteristic (ROC) curve. You can then choose any specific cutoff that you wish for a confusion matrix. There is no need for a logistic regression and potential problems with complete separation. As a comment says that you intend to include decay as only one among several predictors, however, you need to find a way to combine it with the other predictors to get an overall linear predictor of the log-odds of patient/normal status. From what you describe, the problem might arise from your attempt to use decay as an untransformed predictor. With some individual decay times more than 6 standard deviations above the mean in the original scale of seconds, it seems unlikely that the log-odds of patient/normal would be linearly related to untransformed decay values. Yet that is the hidden assumption in the way you are modeling decay . So I recommend trying different transformations of the decay values to find one that bears a better linear relationship to log-odds of patient/normal . Consider a logarithmic transformation, some other power transformation , or maybe even an inverse transformation so that the high-value outliers get bunched close to 0. A few more notes: First, it's possible that your perfect separation is real and that there is some value of decay that perfectly distinguishes patients from normals. If that's the case, your problem is again solved non-parametrically. Check that possibility. Second, I would recommend against the stepwise selection of predictors that you describe in a comment. Recall that logistic regression has an inherent omitted-variable bias so that your coefficient values will be biased if you thus remove from your model any predictor that is related to patient/normal status. Provided that you have on the order of 15 of the lower of patient or normal cases per predictor you shouldn't be in danger of overfitting. It's better to use knowledge of the subject matter rather than stepwise to choose predictors if you have fewer cases than that. Third, unless you have an extremely large number (hundreds to thousands) of cases, the use of separate training and test sets suggested in your code may limit your power. See this page for discussion. Using the entire data set with cross-validation or bootstrapping might be preferable.
