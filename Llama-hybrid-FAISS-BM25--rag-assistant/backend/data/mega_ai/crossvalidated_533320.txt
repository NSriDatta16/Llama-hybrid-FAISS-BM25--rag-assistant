[site]: crossvalidated
[post_id]: 533320
[parent_id]: 
[tags]: 
Bayesian inference data from independent normal two different prior assumptions

Say we have $n$ data points $x_1, x_2, ..., x_n$ , let's also assume that each data point comes from a normal distribution. For Bayesian inference, the first prior assumption is, for each data point $x_i$ , $i=1, ..., n$ , we assume $x_i \sim N(\mu_i,\sigma^2)$ , also assume that $\sigma^2$ is known, so we only need to specify a prior on each $\mu_i$ , we assume $\mu_i \sim N(\lambda_1,\lambda_2)$ ; the second prior assumption is, for each data point $x_i$ , $i=1, ..., n$ , we assume $x_i \sim N(\mu,\sigma^2)$ , $\sigma^2$ is known, we also assume $\mu \sim N(\lambda_1,\lambda_2)$ ; apparently, if we do Bayesian inference for the posterior distribution. The two prior assumptions will give us two different results, for the first one, we have $n$ posterior distributions for each $\mu_i$ , and for the second one, we only have one posterior distribution for $\mu$ . However, what are the differences between the two prior assumptions, it seems like they are the same. And which one is more appropriate?
