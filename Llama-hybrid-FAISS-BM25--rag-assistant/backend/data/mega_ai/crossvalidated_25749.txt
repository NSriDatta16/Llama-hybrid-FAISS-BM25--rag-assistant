[site]: crossvalidated
[post_id]: 25749
[parent_id]: 24730
[tags]: 
Taking the mean of your bootstrap distribution is called bagging (from bootstrap aggregating; link ). I've never seen it used on parameters, just on predictions, but it has a lot in common with Bayesian model averaging, which can work well on parameters. in this framework, your parameter estimated from the original data is like your posterior mode and the bagged estimate is like your posterior mean. The posterior mean often has better accuracy out of sample, but I'm not sure that applies to your case. A few things to consider: Does the mean of your bootstrap distribution look like your maximum likelihood estimate? If so, it might not matter which you choose. Can you try it both ways on a subset of your data and see which works better on a validation set?
