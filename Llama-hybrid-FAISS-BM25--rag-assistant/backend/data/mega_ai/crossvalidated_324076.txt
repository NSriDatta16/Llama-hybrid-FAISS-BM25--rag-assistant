[site]: crossvalidated
[post_id]: 324076
[parent_id]: 323996
[tags]: 
Sure, it is called Data Augmentation Generating Adversarial Networks . The main idea is to train a GAN on another dataset, in another domain; then use it to conditionally generate examples from the target domain (the one in which is used for classification and is rather small in size of data). You can similarly train the GAN on your target dataset, but if that is large enough to train a GAN, then you an use it directly for supervised training. If you have lots of unlabeled data/distribution shift between training and test though, it makes sense to train a GAN on the target dataset as well. The distribution shift solution is explained in the third referenced paper. In other words, if you have generalization problems, it might help. There are some other papers with similar ideas: Data Augmentation in Emotion Classification Using Generative Adversarial Networks : This one is fairly the same idea. GENERATIVE ADVERSARIAL NETWORK BASED ACOUSTIC SCENE TRAINING SET AUGMENTATION AND SELECTION USING SVM HYPER-PLANE : This one is using a rather smart idea to deal with distribution shift in test set. After training an SVM on train set, it trains a GAN on each class of train set separately. Then conditionally generates examples of each class and pinpints the ones close to the support vectors of the boundary of each class. Then adds them to the training and manipulates the SVM decision boundaries in a way that is capable of amazing generalizations on a test set with quite a shift from training.
