[site]: crossvalidated
[post_id]: 358289
[parent_id]: 358275
[tags]: 
When using k fold cross validation method, to plot the learning curve, would training error be the misclassification error on DataTrain and cross-validation error be the misclassification error using the validation subset, testData? No The training error would be the average, over the K-folds, of the error on the trainData . The test error would be the average, over the K-folds, of the error on testData Remember that for each fold, the datasets trainData and testData are different. Source: Sklearn: learning_curve Sklearn: example A cross-validation generator splits the whole dataset k times in training and test data. Subsets of the training set with varying sizes will be used to train the estimator and a score for each training subset size and the test set will be computed. Afterwards, the scores will be averaged over all k runs for each training subset size
