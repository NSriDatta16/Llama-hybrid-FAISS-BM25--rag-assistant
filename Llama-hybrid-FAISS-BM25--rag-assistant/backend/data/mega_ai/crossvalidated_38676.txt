[site]: crossvalidated
[post_id]: 38676
[parent_id]: 
[tags]: 
Confidence intervals vs sample size?

I am totally new to stats and the field of confidence intervals. So this might be very trivial or even sound stupid. I would appreciate if you could help me understand or point me to some literature/text/blog that explains this better. I see on various news sites like CNN, Fox news, Politico etc about their polls regarding the US Presidential race 2012. Each agency conducts some polls and reports some statistics of the form: CNN: The popularity of Obama is X% with margin of error +/- x1%. Sample size 600. FOX: The popularity of Obama is Y% with margin of error +/- y1%. Sample size 800. XYZ: The popularity of Obama is Z% with margin of error +/- z1%. Sample size 300. Here are my doubts: How do I decide which one to trust? Should it be based on the confidence interval, or should I assume that since Fox has a larger sample size, it's estimate is more reliable? Is there an implicit relationship between confidence itnervals and sample size such that specifying one obviates the need to specify the other? Can I determine standard deviation from confidence intervals? If so, is it valid always or valid only for certain distributions (like Gaussian)? Is there a way I can "merge" or "combine" the above three estimates and obtain my own estimate along with confidence intervals? What sample size should I claim in that case? I have mentioned CNN/Fox only to better explain my example. I have no intention to start a Democrats vs Republicans debate here. Please help me understand the issues that I have raised.
