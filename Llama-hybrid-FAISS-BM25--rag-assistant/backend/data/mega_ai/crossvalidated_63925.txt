[site]: crossvalidated
[post_id]: 63925
[parent_id]: 57284
[tags]: 
This is an interesting problem and the associated techniques are have lots of applications. They are often called "interim monitoring" strategies or "sequential experimental design" (the wikipedia article, which you linked to, is unfortunately a little sparse), but there are several ways to go about this. I think @user27564 is mistaken in saying that these analyses must necessarily be Bayesian--there are certainly frequentist approaches for interim monitoring too. Your first approach resembles one of the original approaches to interim monitoring, called 'curtailment.' The idea is very simple: you should stop collecting data once the experiment's outcome is inevitable. Suppose you've got a collection of 100 $As$ and/or $Bs$ and you want to know whether it was generated by a process that selects an $A$ or $B$ at random each time (i.e., $P(A)=P(B)=0.5$. In this case, you should stop as soon as you count at least 58 items of the same kind; counting the remaining items won't change the significance after that point. The number $58$ comes from finding $x \textrm{ such that } 1-F(x;100;0.5) \lt \alpha$, where $F$ is the cumulative binomial distribution. Similar logic lets you find the "inevitability points" for other tests where: The total sample size* is fixed, and Each observation contributes a bounded amount to the sample. This would probably be easy for you to implement--calculate the stopping criteria offline and then just plug it into your site's code--but you can often do even better if you're willing to terminate the experiment not only when the outcome is inevitable, but when it is also very unlikely to change. This is called stochastic curtailment . For example, suppose, in the example above, that we've seen 57 $A$s and 2 $B$s. We might feel reasonably confident, if not absolutely certain, that there is at least one more $A$ in the box of 100, and so we could stop. This review by Christopher Jennison and Bruce Turnbull, works through Stochastic Curtailment in Section 4. They also have a longer book ; you can peek at Chapter 10 via Google Books. In addition to the derivation, the book has some formulae where you can more or less plug in the results of your interim tests. There are a number of other approaches too. Group sequential methods are designed for situations where you may not be able to obtain a set number of subjects and the subjects trickle in at variable rates. Depending on your site's traffic, you might or might not want to look into this. There are a fair number of R packages floating around CRAN, if that's what you're using for your analysis. A good place to start might actually be the Clinical Trials Task View , since a lot of this work came out of that field. [*] Just some friendly advice: be careful when looking at significance values calculated from very large numbers of data points. As you collect more and more data, you will eventually find a significant result, but the effect might be trivially small. For instance, if you asked the whole planet whether they prefer A or B, it's very unlikely that you would see an exact 50:50 split, but it's probably not worth retooling your product if the split is 50.001:49.999. Keep checking the effect size (i.e., difference in conversion rates) too!
