[site]: crossvalidated
[post_id]: 521380
[parent_id]: 
[tags]: 
What does it mean if a simple linear neural network performs better than an LSTM on sequential data?

I'm working on a genetic data project, where one data sample is represented as sequences of integers (of length 2000) and it needs to be classified into one of 4 classes, so I guess it is similar to timeseries. For the project, I built a simple 3-layer linear neural network and a 3-layer LSTM model. I expected the LSTM to outperform the MLP, since the data is sequential and it might therefore be able to pick up on information the MLP can not. However, the LSTM has lousy performance, while the MLP is able to get up to 90 percent test accuracy. Right now I'm just wondering how this might be explained. I figured that maybe the sequences were too long for the LSTM to process them properly, so I performed feature selection and halved the length of the sequences. This improved things slightly, but the MLP is still ways better. Could it be that I need to reduce the features even further? Or can anyone provide some insight into why the LSTM performs so much worse than a simple MLP on this case? Thanks a lot in advance!
