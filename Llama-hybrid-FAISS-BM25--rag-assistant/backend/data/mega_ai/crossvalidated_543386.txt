[site]: crossvalidated
[post_id]: 543386
[parent_id]: 
[tags]: 
How do I know if the difference in performance between two machine learning algorithms is significant?

I built two machine learning models, A and B, and performed 10 times repeated 10-fold cross validation (CV). The mean RMSE and $R^2$ (over all folds) for the models is: Model A: mean RMSE=0.780, mean $R^2$ =0.340 Model B: mean RMSE=0.748. mean $R^2$ =0.390 So, is the difference in performance between the algorithms significant? To check this I used the Wilcoxon rank sum test to compare the RMSE of the 100 folds. The p-value is 0.104, so probably not significant. However, intiuitively, a difference in $R^2$ of 0.05 over 100 folds "feels" to me noteworthy. How can I deal with this situation? Do you have any suggestions? Instead of using 10 repeated CV, I could repeat CV 100 times, but this feels to me too much like p-hacking. What do you think?
