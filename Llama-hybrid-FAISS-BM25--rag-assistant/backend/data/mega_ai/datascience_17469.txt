[site]: datascience
[post_id]: 17469
[parent_id]: 
[tags]: 
Deploying models on bigdata platforms like Hadoop and Spark

Where exactly bigdata platforms fit in to a data science/ machine learning projects ? Say I have a large dataset for a binary classification problem - cats and dogs. Now I need to create a model for real time classification Here is my question. 1 Since dataset is huge I can make use any distributed platform for faster computation and model creation right? 2 Once the model is ready, then there is no need of these distributed platform right ? or are they needed for feature extractions ?
