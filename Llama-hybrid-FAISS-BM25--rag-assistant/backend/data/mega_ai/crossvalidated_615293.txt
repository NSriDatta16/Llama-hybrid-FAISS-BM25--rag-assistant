[site]: crossvalidated
[post_id]: 615293
[parent_id]: 
[tags]: 
How to encode sparse and variable length sequential data

I have 100k historical horse races. The data is sequential in time, so I am wishing to use online learning to train an LSTM (or sequential attention model or something similar...) such that the model updates after each race. The output of the model should correspond to the probability of each horse in a new race winning that race. I am satisfied with the above framing of my problem. But I am very unsure about how to encode each race into a usable input type for some sequential model. Here are some example fields for each race: "timestamp": 1665523432, "grade": "5", "track_name": "Cantebury", "runners": [ { "horse_name": "Pharlap", "finishing_position": 1, "finishing_time": 30.83, "weight": 66 } ... ] I am unsure how to deal with the fact that each race has a variable number of runners. Maybe I can take the max and just zero-pad. There are also over 10k unique runners, so to one-hot encode horse_name intuitively seems too sparse. If anyone could please guide me to some resources, analogous ML problems or offer any advice, I would greatly appreciate it.
