[site]: stackoverflow
[post_id]: 5341639
[parent_id]: 
[tags]: 
Is my implementation of fixed-point arithmetic correct?

A little while ago, I created a bunch of C macros for fixed-point values manipulation. Encouraged by several questions and answers on SO, I was hoping to get performance gains in a calculation-intensive part of my program. While the code seems to produce correct results, I'm wondering if it's not too naive/oversimplified, because it actually runs slower for me than regular floating-point versions of my routines (I'm doing bicubic image interpolation on Wintel). Could you please look at this short piece of code containing my macros and suggest some improvements, particularly with regard to performance? Thanks. // these are architecture-dependent typedef short int fixed16; typedef int fixed32; typedef __int64 fixed64; // value of 2^n #define POW2(n) (1 0.0 ? static_cast (floor((x) * POW2(n) + 0.5)) : static_cast (ceil((x) * POW2(n) - 0.5))) // the same, 32bit #define FP_MAKE32(x, n) ((x) > 0.0 ? static_cast (floor((x) * POW2(n) + 0.5)) : static_cast (ceil((x) * POW2(n) - 0.5))) // and 64bit #define FP_MAKE64(x, n) ((x) > 0.0 ? static_cast (floor((x) * POW2(n) + 0.5)) : static_cast (ceil((x) * POW2(n) - 0.5))) // convert a fixed-point integer from one (n) format to another (m) assuming n m #define FP_CONVERT_DOWN(x, n, m) ((x) >> (n-m)) // convert floating-point value back to float #define FP_FLOAT(x, n) (static_cast (x) / POW2(n)) // same for double #define FP_DOUBLE(x, n) (static_cast (x) / POW2(n)) // and for int. fractional part will be discarded! #define FP_INT(x, n) ((x) >> n) // arithmetic operations for same-format numbers #define FP_NEG(a) ((~a)+1) #define FP_ADD(a, b) ((a) + (b)) #define FP_SUB(a, b) ((a) + FP_NEG(b)) #define FP_MUL(a, b, n) (((a) * (b)) >> n) #define FP_DIV(a, b, n) (((a) > n) #define FP_POW3(a, n) (((((a) * (a)) >> n)*(a)) >> n) // arithmetic for different-format numbers, assuming n is the target (result) format and n > m #define FP_ADD_UP(a, b, n, m) ((a) + ((b) > m) #define FP_DIV_UP(a, b, n, m) (((a) > (m-n))) #define FP_SUB_DOWN(a, b, n, m) ((a) + FP_NEG((b) >> (m-n))) #define FP_MUL_DOWN(a, b, n, m) (((a) * (b)) >> m) #define FP_DIV_DOWN(a, b, n, m) (((a) EDIT: Basically, the answers and comments turned towards these two points: The code is hideous, difficult to use and maintain: I wholehartedly agree and will take the time to encapsulate it inside a class. I had some concerns about performance which were adressed and I have been convinced they were unfounded and I went to all the trouble for nothing. :) Fixed-point is not worth the trouble anyway: While that may be true on my platform, I was creating this to improve the execution speed of my code on a platform where there was no floating-point hardware. There, the floating point operations took too long and fixed was the way to go. I was only testing this on Intel because I have no access to the target hardware at the moment While I am extremely grateful for the insight provided thus far, I was hoping to hear from somebody who actually did some calculations in fixed-point to tell me if these arithmetic operations are indeed the way to go. Perhaps there is some additional spiffy bit-twiddling that I am unaware of, that makes a difference in regard to performance or precision? In other words, if I am to encapsulate this code, can I keep the same arithmetic instructions in the inline operator functions basically the same as they are now, or should I change them somehow?
