[site]: crossvalidated
[post_id]: 507631
[parent_id]: 
[tags]: 
Logistic Regression Limitations

I have been given a problem where I need to create an algorithm to predict a binary variable with 10 coefficients. I have no idea what the relationship is between those coefficients, but I know that there is one. This relationship is likely very complicated. The correct algorithm will likely not only look at each variable as an individual, but how these variables relate to each other: Eg. if (x > y and z 5), return 0. Else, if (insert criteria similar to one above), return 1 It's become pretty clear to me that a human can't really solve this task without using a tedious and excessive amount of guessing and testing. I have decided to use a logistic regression for this task, and I've already programmed a pretty straightforward model using turicreate to do this. My question is: with enough data, can logistic regression models learn to accurately predict variables by assessing the relationship between coefficients? Is there a better way to do this, such as a decision tree / random forest / boosted tree?
