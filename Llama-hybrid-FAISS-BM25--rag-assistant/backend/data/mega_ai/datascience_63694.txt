[site]: datascience
[post_id]: 63694
[parent_id]: 63692
[tags]: 
In the context of a multi-label classifier (that is, having potentially more than one label per data point) we can have a prediction which is either fully correct , partially correct or fully incorrect . To account for this, the following accuracy metric has been proposed: $$\text{Accuracy} = \frac{1}{n}\sum_{i=1}^n\frac{|T_i \cap P_i|}{|T_i\cup P_i|},$$ where $n$ is the sample size, $|\cdot|$ denotes the number of elements of a set, $T_i$ is the set of true labels and $P_i$ is the set of predicted labels for an item of the sample. For instance, let's say the $i$ -th item has actual labels $A, B, C$ and $D$ (that is $T_i = \{A, B, C, D\}$ , but your classifier predicts labels $B, D$ and $E$ (that is $P_i =\{B, D, E\}$ ), then you'd get $$\frac{|T_i\cap P_i|}{|T_i\cup P_i|}=\frac{|\{B,D\}|}{|\{A,B,C,D,E\}|}=\frac{2}{5}.$$ To get the accuracy for the entire training set, you calculate this for each instance $i=1,\dots, n$ and you average it out. You can also have a look at the evaluation metrics section of the article in Wikipedia about multi-label classifiers: https://en.wikipedia.org/wiki/Multi-label_classification#Statistics_and_evaluation_metrics
