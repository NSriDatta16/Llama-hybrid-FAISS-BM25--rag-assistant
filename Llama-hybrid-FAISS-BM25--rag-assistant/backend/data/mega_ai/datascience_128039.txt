[site]: datascience
[post_id]: 128039
[parent_id]: 
[tags]: 
How can I scale my data for a machine learning model in a way that preserves the relationship between columns?

Lets take a simple database with 3 columns called x1, x2 and label for example label is being labeled by this condition if x1-x2> 0 then label = 1 else 0 , i.e if x1 greater than x2, label is 1 else 0 x1 x2 label 100 1 True 200 2 True 4 6 False 3 10 False 500 15 True 600 20 True I want my ML model to accurately predict label based on if x1>x2 After scaling the data with standard scaler and minmax scaler column wise, I get this data standard= StandardScaler() normal= MinMaxScaler() scaled_data = standard.fit_transform(normal.fit_transform(reshaped_data)) print(scaled_data) x1 x2 -0.573437 -1.171080 -0.147090 -1.024695 -0.982731 -0.439155 -0.986994 0.146385 1.131953 0.878310 1.558300 1.610235 After scaling I lose the relationship between x1 and x2 for example in the last data row, where 600>20 got scaled down to 1.5583 which will hinder the performance of the model to learn the condition ( if x1-x2> 0 then label = 1 else 0 ) Above, was just a small example to show that scaling using normal methods disturbs the relationship between columns In my original timeseries dataset I have 200+ columns and I want to train an LSTM Model for multiclass classification . Most of the timeseries columns are not contributing towards the label , some columns are in range 0-3000 and some columns are percentages between 0-1 and some columns are binary . And the Labels are being labeled by some complex formula where columns are interacting with each other, being compared with each other to get the label. It is certain that I will have to scale the data since some columns are in range 0-3000 . But i want to scale the data in such a way that even after scaling, when the same formula is applied to scaled data, I get the same labels. This way I can be certain that the LSTM model will be able to learn the underlying formula and predict the label accurately. If I scale the data normally, i.e. the relationships between the columns are disturbed, then my LSTM model performs poorly on unseen data. How should i scale my data such that the relationship between columns are maintained even after scaling?? This is what I have tried :- Scaling those columns together which are of the same units, for example x1,x2 should be scaled together because they both have same unit. Even if x1 has range of 0-40 and x2 has range of 0-3000, since the units are same, they should be scaled together. Not scaling percentage columns at all, since those columns are already in range of 0-1, no point in scaling them scaling all other columns independently. What I achieved:- with the above method I got the result I want (99% accuracy on unseen data), however I had to do a lot of hard coding since there are 200+ columns, I had to go through each of them and scale them separately. is there an easier way of doing this?
