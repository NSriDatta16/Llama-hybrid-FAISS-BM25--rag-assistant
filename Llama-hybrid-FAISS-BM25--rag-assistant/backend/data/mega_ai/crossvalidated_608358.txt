[site]: crossvalidated
[post_id]: 608358
[parent_id]: 
[tags]: 
GAM: predictor range varying across groups. Should data be transformed?

I am modeling the seasonal occurrence of a species at different sites (count data). I am specifically trying to identify potential drivers of the seasonal pattern. To this end, I have selected a number of environmental variables and I am planning on using the gam() function in mgcv to fit hierarchical GAMs allowing variation of smoothers across sites. I am using the negative binomial distribution for count data. However, the range of the candidate predictor varies across groups (see Plot 1 below, y is the count response per day, x is the environmental variable, and facets represent sites). Plot 2 is a time series of this predictor across sites. Should I transform the predictor scale prior to fitting the model? Maybe by standardizing or normalizing the data (per site) ? For some predictors, I may be able to remove a few isolated points, treating them as outliers (even if ecologically plausible) to reduce the range and fit the regression better for most of the sites. But for others, such as the one plotted below, I cannot discard points as they just reflect different dynamics of the predictor at different sites... This thread does not recommend scaling, while this one answers a similar question on GLMMs. I am worried that leaving the data as they are now will affect the model by increasing the importance of one site (within a single predictor). Similarly, I wonder if such issues would arise among predictors (one variable weighing more in a model), as they are measured on different scales (e.g chlorophyll concentration, day of the year, temperature...). On the other hand; normalizing the data erases the information on inter-site variability in environmental conditions. Are there common practices for such questions in GAMs? Plot 1: Plot 2:
