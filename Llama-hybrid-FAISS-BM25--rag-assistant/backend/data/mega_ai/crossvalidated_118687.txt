[site]: crossvalidated
[post_id]: 118687
[parent_id]: 118684
[tags]: 
You can use something like linear discriminant analysis. However, in your case we do not have equal covariances matrices, as it is assumed in linear discriminant analysis. Let's say that we have stochastic variables $X$ and $G$ where $X$ signifies the measurement, and $G$ the underlying distribution (thus, $G$ takes values in $\{1,2,3\}$ in the example). The coordinates of $X$ are independent and furthermore, $X$ and $G$ are independent. Basically, we're interested in the quantity $$ P(G = k | X =x ), $$ where $x$ is a realization of $X$ and $k\in \{1,2,3\}$. For clarity, I'll just continue the example. The generalization is straight-forward. By Bayes' theorem, we get that $$ P(G = k | X =x ) = \dfrac{f_X(x|G=k)P(G = k)}{f_X(x)}. $$ In your example, we have no prior information on the distributions, so let's assume that they are equally likely before we observe $x$, i.e. $P(G = k) = 1/3$ for $k \in \{1,2,3\}$. We can rewrite the denominator using our assumptions and using that the distribution of $X$ is a mixture of distributions. $$ f_X(x) = \sum_{i=1}^3 f_X ( x | G = i) P(G = i) $$ Thus, we get that $$ P(G= k |X=x) = \dfrac{f_X ( x | G = k)}{\sum_{i=1}^3 f_X ( x | G = i)}. $$ These will be numbers in $(0,1)$ and they sum to $1$, thus it is tempting to see them as probabilities. In a frequentist set-up, let's consider how to interpret these probabilities. There is a true distribution. Hence, this distribution has probability 1 of being the true distribution no matter the outcome. Of course, we do not know which one it is, though. This is analogous to the interpretation of confidence intervals in a parametric model. In a frequentist interpretation, there is a true parameter value. When we observe data and construct a 95% confidence interval, this interval either contains the true value or it doesn't. However, when we repeat the experiment infinitely many times, we would in 95% of the cases get an interval containing the true parameter. I would say that, if one were to interpret the above probabilities in a frequentist manner, one would have to interpret them in terms of repetitions of the experiment, all giving $x$ as the outcome. A Bayesian interpretation is perhaps more straight-forward, as degrees of belief in the different states. In this case the probabilities gives us the posterior distribution.
