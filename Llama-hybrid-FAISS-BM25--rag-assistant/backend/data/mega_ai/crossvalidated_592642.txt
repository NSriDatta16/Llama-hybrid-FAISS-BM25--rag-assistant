[site]: crossvalidated
[post_id]: 592642
[parent_id]: 99988
[tags]: 
This is a situation like a lot of situations that arise when comparing fully nonparametric methods with parametric methods that rely on broad assumptions (e.g., distribution with finite variance leading to the CLT). Assuming that both methods are constructed appropriately, we usually find three things: (1) the parametric method usually works better than the nonparametric method on small sample problems where the underlying assumptions hold; (2) the nonparametric method usually works better than the parametric method on small sample problems where the underlying assumptions for the parametric method are substantially violated; and (3) when the sample size gets large, both methods work about equally well. Under this circumstance, some practitioners do indeed prefer to always use nonparametric methods. Such practitioners typically prefer to use methods that have minimal assumptions and they are suspicious of making statistical assumptions to facilitate analysis in cases where the dataset is small. That is a perfectly reasonable position to take, so if you prefer to always use bootstrap CIs, my view is that that is a defensible position. Having said that, you should be careful not to exaggerate the assumptions made by other methods. The standard CIs for means, variances, etc., do not require us to assume that the underlying data is normal --- rather, we assume that the underlying data is such that we can apply the CLT so that important sample quantities (e.g., sample mean ) are roughly normally distributed over samples that are not too small. I understand the motivation for not using non-parametric tests systematically, since they have less power, but my simulations tell me this is not the case for bootstrap CIs. They are even smaller. Smaller is not necessarily good on its own. Smaller CIs are good if the coverage level is accurate . If the CI is too small, such that the actual coverage level is less than the confidence level, that is bad. If you would like to do a detailed simulation analysis comparing the bootstrap CI to other CIs, I recommend you look at the width of the CIs but also the proportion of the time the true parameter value falls within the CI in the simulations. Ideally, you want the coverage proportion to be the same as the confidence level, but if the confidence level is an underestimate of the true coverage probability, that is not a catastrophic problem. If you do a large simulation study over appropriate cases, you should be able to determine whether the competing methods produce CIs with accurate confidence levels, and whether the intervals produced are more/less accurate (i.e., narrower/wider) under different methods. A similar question that bugs me is why not always use the median as the measure of central tendency. People often recommend to use it to characterize non normally-distributed data, but since the median is the same as the mean for normally-distributed data, why make a distinction? Again, you seem to be proceeding under the view that standard CIs assume normality of the data, when actually what they assume is much weaker than this --- the standard CI for a population mean only assumes that the underlying distribution of the data has finite variance, such that we can apply the CLT to ensure that the sample mean is roughly normally distributed. In samples that are not too small, the sample mean should be roughly normally distributed, but the underlying data usually is not. Consequently, the sample mean will not generally correspond to the sample median in such cases. Here is is worth noting that the use of the sample mean or median really depends on what you want to make an inference about. If you want a CI for the population mean then the sample mean is a natural consistent estimator; if you want a CI for the population media then the sample median is a natural consistent estimator. In both cases there are applicable CLT results that say that these quantities are roughly normally distributed under weak assumptions for samples that are not too small. Nevertheless, other than for underlying symmetric distributions, these two things do not usually correspond.
