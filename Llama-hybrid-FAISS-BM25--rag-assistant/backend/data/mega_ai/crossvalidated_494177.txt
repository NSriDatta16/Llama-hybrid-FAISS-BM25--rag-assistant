[site]: crossvalidated
[post_id]: 494177
[parent_id]: 494015
[tags]: 
While we can statistically test the null hypothesis of the means being equal, finding support in favor of equivalence between means is generally a much more difficult topic. Testing equivalence will unfortunately always require additional assumptions, leading to some amount of arbitrariness. This is unavoidable. There are two standard ways to go about this, but they are not necessarily as mature in the field of circular statistics as they are elsewhere. First, you can consider equivalence testing . In this approach, you set up an effect size bound, and test the null hypothesis that the effect size is greater than this bound. It is not possible to make the bound too small: then, we would almost never reject the null hypothesis. But, if we make it to big, we would almost always reject it. Practically, I am not aware of any software packages that do equivalence testing for circular means. However, if you are decently savvy, you can implement it yourself by means of a bootstrap, for example. The second option (which I personally prefer) is Bayesian hypothesis testing . In this paradigm, we can, in fact find support for the null hypothesis, whatever it is. This is not a magic bullet either, however. This power is granted because we have set up a prior distribution for the parameters in the alternative hypothesis. This means that we need to consider what we expect the distribution to be a priori, which can be a difficult exercise. Practically, you can theoretically do this in any Bayesian software, but computing the required Marginal Likelihoods can be quite difficult. You could do this with the bridgesampling R package. (If you are interested, I have recently published an open access paper on Bayesian tests for circular data, although focused only on the case of uniformity, not mean comparison. However, a lot of relevant considerations are in there. Similarly, hopefully soon I will fix circbayes , so that you can do it there.).
