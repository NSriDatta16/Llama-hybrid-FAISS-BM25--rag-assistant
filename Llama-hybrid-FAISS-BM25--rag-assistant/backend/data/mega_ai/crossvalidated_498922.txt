[site]: crossvalidated
[post_id]: 498922
[parent_id]: 52825
[tags]: 
To add a more modern (but not very deep) perspective, consider how it's used in deep learning (ha, pun intended...): logit is referred to the output of a function (e.g. a Neural Net) just before it's normalization (which we usually use the softmax). This is also known as the code. So if for label $y$ we have score $f_y(x)$ then the logit is: $$ logit = \log \left( \frac{ e^{f_y(x)} }{Z} \right) = score = f_y(x)$$ Where $Z$ is the standard partition function. By the way, this is all over the place in the pytorch and tensorflow documentation. So you can interpret it as: the (unnormalized) score for a label or (functional confidence) for a specific class/label. One of the many references: https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow
