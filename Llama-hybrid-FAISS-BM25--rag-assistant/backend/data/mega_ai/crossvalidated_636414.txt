[site]: crossvalidated
[post_id]: 636414
[parent_id]: 
[tags]: 
Normality assuption violation of time series data in the presence of outliers

I have a dataset containing information on district wise monthly dengue incidence from 2010 to 2021. I have found that there is a sudden increase in the dengue incidence due to a new variant in 2019. I am trying to fit a model to identify the factors affecting dengue incidence, and I applied time series regression. The data were not stationary, therefore I included the differencing transformation on the data. But the model violated both the normality assumption and the auto correlation assumption. I included first log in to the model and it solved the auto correlation problem. But even with the log transformation the model did not satisfy the normality assumption. As the data are both time series and cross sectional, I tried using panel data regression but the model still violated the normality assumption. I think this could be because of the outliers present in the data, however since this is time series, data I cannot remove the outliers. Following are the residual plots of the time series regression model. My supervisor suggested that I should consider the simplest method and try to treat for the normality assumption violation rather than look for new methods. But I still cant find any solution for this problem. Does anyone have an idea about what approach I should take?
