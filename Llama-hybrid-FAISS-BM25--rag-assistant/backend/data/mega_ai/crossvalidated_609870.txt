[site]: crossvalidated
[post_id]: 609870
[parent_id]: 609829
[tags]: 
I've used PCA in facial motion capture for real time animatronic control of the 'lots of dots on a face' variety. I was able to find out which dots - which is to say regions of the face - encoded the most information in movement and emotive expression. It's obvious to some where these may be, and there is a natural correlation between these areas and how much they move, but I wanted to confirm my intuition. I could only track so many dots so with that information I was able to more efficiently place them around the face, with more density in areas that encoded the most useful 'perpendicular' data and more sparsely in those that only became relevant on their own merits occasionally. This is grossly simplified, and there was a lot more to it (the eyes... another world going on there) and I'd probably use a NN or similar with no dots this time round, but PCA played an integral part of the learning.
