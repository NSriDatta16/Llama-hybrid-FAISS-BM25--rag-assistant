[site]: datascience
[post_id]: 68056
[parent_id]: 
[tags]: 
Over/Under Sampling for Multi-classification

I'm trying to apply xgboost and random forest for over and under sampling For imbalanced data: train shape -> (199991, 23) However, reverse my expectation. The accuracy went down for both cases. Questions: Is under and over sampling always not good? What else should I consider when applying over and under sampling?
