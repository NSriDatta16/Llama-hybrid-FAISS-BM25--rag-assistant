[site]: crossvalidated
[post_id]: 606258
[parent_id]: 
[tags]: 
What is the best approach for feature selection if I have 65536 features

Don't want to write a big paragraph and for the beginning, what I would like to say is I started doing a machine vision project and I flattened my 256x256 photos into a vectors of 65,536 features. First of all, I want to point out that I'm a total beginner when it comes to machine vision. I trained a few ML models, using these 65,536 features vectors (in total 1130 images/vectors) and the best accuracy was obtained by Naive Bayes which was 0.73 . Is this a good accuracy? Another question I have would be, is it smart to do a feature selection and potentially "cut/prune/remove" some of my features? If so, how could I do that? Until now, I have only worked with datasets with max of 12 features and I went feature-by-feature in order to determine which one to remove but in this case, if I go feature-by-feature for 65,536 features it might take a year to select the good features. What do you think?
