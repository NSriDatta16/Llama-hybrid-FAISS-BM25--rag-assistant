[site]: crossvalidated
[post_id]: 196680
[parent_id]: 196665
[tags]: 
However, unlike logistic regression, Bayesian is non-parametric i.e. I do not have any coefficients which I can save and use to calculate fresh scores. Nope. It's certainly not a non-parametric model. Maybe look up the definition of the model to confirm. I wanted to understand ways to implement the Bayesian output in SQL frame i.e. how can I automate it in SQL so that for every round of fresh data, I run the trained network to predict the probability score. Right - you want to implement model prediction in your own code after the R has estimated the network parameters. I am trying to use the conditional probability tables from bn.fit so you're using the package bnlearn . and back calculate the predicted probabilities using conditional independence and Bayes theorm. But my results are not matching with R's predicted probabilities output. Indeed. If you looked up the definition of the model earlier you'll notice that while in regular Naive Bayes the observations are conditionally independent given the class, in tree-augmented NB they are not (modeling these dependencies is the augmentation). Hence you'll need to compute the posterior probability of the class taking into account that extra bit of conditioning. It's possible that you can look in the tree.bn specific version of predict to see how the package does already it. Alternatively you can just write down the prior and likelihood in the model and figure out what the posterior would be. It's not much harder than deriving that for the unaugmented NB, particularly as you only need it up to a proportionality. If you end up writing it yourself you'll want to think carefully about overflow issues - particularly with a lot of features - but any machine learning text should explain how to deal with those in a NB context.
