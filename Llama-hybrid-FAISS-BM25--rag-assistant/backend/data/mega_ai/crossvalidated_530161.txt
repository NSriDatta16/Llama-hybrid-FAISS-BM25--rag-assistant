[site]: crossvalidated
[post_id]: 530161
[parent_id]: 
[tags]: 
How is the log likelihood calculated for bayesian networks?

In structure learning, there are score-based methods which rely on information criteria such as BIC or AIC. BIC, specifically, is defined as: $$ BIC = k \ln(n) - 2\ln\left(\hat{L}\right) $$ Where $k$ is the number of parameters in the model, $n$ is the number of training examples and $\hat{L}$ is the likelihood function associating the model itself with observed data $x.$ In the case of structure learning, we are trying to determine how well a bayesian network approximates the underlying causal structure in the observed data. The bnlearn R package implements such calculations in its methods and, as far as I can tell, the log-likelihood is usually the preferred likelihood function, as it is supposed to be easier to compute. So my main question here is: how is $\hat{L}$ calculated in the context of bayesian networks? I understand the "concept" (I think), but I can't seem to visualize a practical way of implementing that. What would be the most straight-forward way of representing such calculation?
