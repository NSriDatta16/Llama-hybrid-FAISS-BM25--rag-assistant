[site]: crossvalidated
[post_id]: 65315
[parent_id]: 65264
[tags]: 
I can answer a couple of your questions, so here goes. (1) Is there a set of generally accepted best practices for pre-processing the predictors (scoring, normalizing, rescaling, etc.) to provide more sensible inputs to the support vector regression step? A general rule of thumb for SVM/SVR is to scale all inputs to the same interval. Common choices are $[-1,1]$ and $[0,1]$. The actual interval doesn't matter much, as long as all inputs are scaled to the same one. This prevents some input dimensions to completely dominate others when evaluating the kernel function. I have no reference for regression, but for classification it is listed in the LIBSVM guide (it holds for regression too). When using kernel functions, like a Gaussian RBF, to transform the inputs, is it fair to say that the only extra degrees of freedom introduced are whatever hyperparameters govern the kernel's functional form? That feels a bit wrong to me, because you're effectively allowing yourself to explore a whole space of unvetted transformations of the data, which isn't really captured in just the functional form of the kernel function. How can you fairly penalize a model like this for having much more freedom to overfit the data with non-linear transformations? When using SVM(/SVR), the degrees of freedom are in fact the number of training instances. Each training instance can become a support vector and as such contribute to the separating hyperplane/regressor. Although this may seem bad, this is exactly why SVM works in infinite dimensional feature spaces, for example using an RBF kernel: the actual number of degrees of freedom is always finite.
