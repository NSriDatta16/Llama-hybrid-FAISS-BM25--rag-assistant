[site]: crossvalidated
[post_id]: 315086
[parent_id]: 
[tags]: 
Effect of normlization on classification accurcy

I am working on a dataset which contains numerical and nominal data with some missing values, using scikit-learn. Steps I followed for preprocessing are: 1. Filled missing values with mean and mode 2. performed encoding on data(label encoder()) 3. Performed splitting of data and then normalization 4. Classification by logistic regression This results in classification accuracy of 99%. Does normalization results in overfitting of data?? And what will it result if normalization is followed with standardization.
