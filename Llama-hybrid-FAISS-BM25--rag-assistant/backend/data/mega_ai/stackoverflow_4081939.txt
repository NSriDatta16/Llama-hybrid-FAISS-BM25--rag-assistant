[site]: stackoverflow
[post_id]: 4081939
[parent_id]: 4081662
[tags]: 
According to Wikipedia, a Markov Chain is a random process where the next state is dependent on the previous state. This is a little difficult to understand, so I'll try to explain it better: What you're looking at, seems to be a program that generates a text-based Markov Chain. Essentially the algorithm for that is as follows: Split a body of text into tokens (words, punctuation). Build a frequency table. This is a data structure where for every word in your body of text, you have an entry (key). This key is mapped to another data structure that is basically a list of all the words that follow this word (the key) along with its frequency. Generate the Markov Chain. To do this, you select a starting point (a key from your frequency table) and then you randomly select another state to go to (the next word). The next word you choose, is dependent on its frequency (so some words are more probable than others). After that, you use this new word as the key and start over. For example, if you look at the very first sentence of this solution, you can come up with the following frequency table: According: to(100%) to: Wikipedia(100%) Wikipedia: ,(100%) a: Markov(50%), random(50%) Markov: Chain(100%) Chain: is(100%) is: a(33%), dependent(33%), ...(33%) random: process(100%) process: with(100%) . . . better: :(100%) Essentially, the state transition from one state to another is probability based. In the case of a text-based Markov Chain, the transition probability is based on the frequency of words following the selected word. So the selected word represents the previous state and the frequency table or words represents the (possible) successive states. You find the successive state if you know the previous state (that's the only way you get the right frequency table), so this fits in with the definition where the successive state is dependent on the previous state. Shameless Plug - I wrote a program to do just this in Perl, some time ago. You can read about it here .
