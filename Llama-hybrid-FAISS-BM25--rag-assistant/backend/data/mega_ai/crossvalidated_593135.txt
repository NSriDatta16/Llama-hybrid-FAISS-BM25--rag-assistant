[site]: crossvalidated
[post_id]: 593135
[parent_id]: 
[tags]: 
Keras Prediction one step beyond

I am trying to make time series forecasting with keras. Has any one observe the phenomenon where the model can predict the next value after the current (the one that should predict)? If in fact I move the the forecasting values one position to the left (starting the predicted dataset from 1 instead of zero) the accuracy is very good Here is the code. "ts" is the time series that comes from another time series. The first 4 rows are as below x 0 596.449044603317 1 579.397435343439 2 564.145409470115 3 530.482937258399 ... ... Here is the code. def create_dataset(dataset, look_back=1): dataX, dataY = [], [] for i in range(len(dataset)-1-look_back): a = dataset[i:(i+look_back), 0] dataX.append(a) dataY.append(dataset[i + look_back, 0]) return np.array(dataX), np.array(dataY) # fix random seed for reproducibility _seed=42 tf.random.set_seed(_seed) seed(_seed) # load dataset ts=gt.copy() try: ts.drop(columns='index', inplace=True) except: print("No index column was found") # normalize the dataset scaler = MinMaxScaler(feature_range=(0, 1)) dataset = scaler.fit_transform(ts) # split into train and test sets train_test_threshold=14 train_size = int(len(dataset) -train_test_threshold) test_size = len(dataset) - train_size train, test = dataset[0:train_size], dataset[train_size:len(dataset)] # reshape into X=t and Y=t+1 look_back = 7 trainX, trainY = create_dataset(train, look_back) testX, testY = create_dataset(test, look_back) # reshape input to be [samples, time steps, features] trainX_r = np.reshape(trainX, (trainX.shape[0], trainX.shape[1],1 )) testX_r = np.reshape(testX, (testX.shape[0], testX.shape[1], 1)) # create and fit the LSTM network model = Sequential() model.add(LSTM(4, input_shape=(trainX_r.shape[1],1),return_sequences=True)) model.add(LSTM(2, return_sequences=False)) model.add(Dense(1)) model.compile(loss='mean_squared_error', optimizer='adam') model.fit(trainX_r, trainY, epochs=500, batch_size=16, verbose=0) # make predictions trainPred = model.predict(trainX_r) testPred = model.predict(testX_r) # invert predictions trainPredict = scaler.inverse_transform(trainPred) trainY = scaler.inverse_transform([trainY]) testPredict = scaler.inverse_transform(testPred) testY = scaler.inverse_transform([testY]) plt.style.use('fivethirtyeight') plt.figure(figsize=(24,12)) plt.title('1 day ahead Electricity Price Forecasting') plt.xlabel('Step (1 day)', fontsize=14) plt.ylabel('Electricity Price (EU)', fontsize=18) plt.plot(testPredict) plt.plot(testY.transpose()) plt.legend(['Forecast', 'Actual']) plt.show() No matter if I change the parameters of the neural network the results remains the same. Can any one tell me where I have done the error in the code? Here is an image It seems like the prediction have moved to the right, predicting one step beyond. Any help would be very much appreciated.
