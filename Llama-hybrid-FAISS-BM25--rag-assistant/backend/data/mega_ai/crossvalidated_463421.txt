[site]: crossvalidated
[post_id]: 463421
[parent_id]: 463277
[tags]: 
This particular network is a special case of a neural network. It has 0 hidden layers, so it is an ordinary regression problem, except with two target (output) features instead of the more typical 1 target. Under certain conditions, regression is a strongly convex optimization problem. The strong convexity of the regression problem implies that the optimal parameter configuration to this network is not sensitive to the choice of initial guess. A note on terminology: It's typical for a neural network to have 1 or more hidden layers. In particular, the distinguishing characteristic of "DL" (deep learning) models is that they have many hidden layers. The large number of hidden layers is what makes them "deep" as opposed to "shallow." The statement about "breaking symmetry" should be read with this in mind.
