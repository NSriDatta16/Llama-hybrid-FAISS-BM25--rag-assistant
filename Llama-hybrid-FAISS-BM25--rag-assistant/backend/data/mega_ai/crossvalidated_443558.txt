[site]: crossvalidated
[post_id]: 443558
[parent_id]: 443445
[tags]: 
I agree with X'ian that the problem is under-specified. However, there is an elegant, scalable, efficient, effective, and versatile solution worth considering. Because the product of the sample mean and sample size equals the sample sum, the problem concerns generating a random sample of $n$ values in the set $\{1,2,\ldots, k\}$ that sum to $s$ (assuming $n \le s \le kn,$ of course). To explain the proposed solution and, I hope, justify the claim of elegance, I offer a graphical interpretation of this sampling scheme. Lay out a grid of $k$ rows and $n$ columns. Select every cell in the first row. Randomly (and uniformly) select $s-n$ of the remaining cells in rows $2$ through $k.$ The value of observation $i$ in the sample is the number of cells selected in column $i:$ This $4\times 100$ grid is represented by black dots at the unselected cells and colored patches at the selected cells. It was generated to produce a mean value of $2,$ so $s=200.$ Thus, $200-100=100$ cells were randomly selected among the top $k-1=3$ rows. The colors represent the numbers of selected cells in each column. There are $28$ ones, $47$ twos, $22$ threes, and $3$ fours. The ordered sample corresponds to the sequence of colors from column $1$ through column $n=100.$ To demonstrate scalability and efficiency, here is an R command to generate a sample according to this scheme. The question concerns the case $k=4, n=100$ and $s$ is $n$ times the desired average of the sample: tabulate(sample.int((k-1)*n, s-n) %% n + 1, n) + 1 Because sample.int requires $O(s-n)$ time and $O((k-1)n)$ space, and tabulate requires $O(n)$ time and space, this algorithm requires $O(\max(s-n,n))$ time and $O(kn)$ space: that's scalable . With $k=4$ and $n=100$ my workstation takes only 12 microseconds to perform this calculation: that's efficient . (Here's a brief explanation of the code. Note that integers $x$ in $\{1,2,\ldots, (k-1)n\}$ can be expressed uniquely as $x = nj + i$ where $j \in \{0,1,\ldots, k-2\}$ and $i\in\{1,2,\ldots, n\}.$ The code takes a sample of such $x,$ converts them to their $(i,j)$ grid coordinates, counts how many times each $i$ appears (which will range from $0$ through $k-1$ ) and adds $1$ to each count.) Why can this be considered effective ? One reason is that the distributional properties of this sampling scheme are straightforward to work out: It is exchangeable: all permutations of any sample are equally likely. The chance that the value $x \in\{1,2,\ldots, k\}$ appears at position $i,$ which I will write as $\pi_i(x),$ is obtained through a basic hypergeometric counting argument as $$\pi_i(x) = \frac{\binom{k-1}{x-1}\binom{(n-1)(k-1)}{s-n-x+1}}{\binom{n(k-1)}{ s-n}}.$$ For example, with $k=4,$ $n=100,$ and a mean of $2.0$ (so that $s=200$ ) the chances are $\pi = (0.2948, 0.4467, 0.2222, 0.03630),$ closely agreeing with the frequencies in the foregoing sample. Here are graphs of $\pi_1(1), \pi_1(2), \pi_1(3),$ and $\pi_1(4)$ as a function of the sum: The chance that the value $x$ appears at position $i$ while the value $y$ appears at position $j$ is similarly found as $$\pi_{ij}(x,y) = \frac{\binom{k-1}{x-1}\binom{k-1}{y-1}\binom{(n-1)(k-1)}{s-n-x-y+2}}{\binom{n(k-1)}{ s-n}}.$$ These probabilities $\pi_i$ and $\pi_{ij}$ enable one to apply the Horvitz-Thompson estimator to this probability sampling design as well as to compute the first two moments of the distributions of various statistics. Finally, this solution is versatile insofar as it permits simple, readily-analyzable variations to control the sampling distribution. For instance, you could select cells on the grid with specified but unequal probabilities in each row, or with an urn-like model to modify the probabilities as sampling proceeds, thereby controlling the frequencies of the column counts.
