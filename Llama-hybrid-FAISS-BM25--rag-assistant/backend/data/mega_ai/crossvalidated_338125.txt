[site]: crossvalidated
[post_id]: 338125
[parent_id]: 338105
[tags]: 
From $f(x,n)$, we try to get the kernel for conditional distributions like follows: $\pi(X|N=n) = ae^{-3x}x^n $ $\pi(N|X=x) = bx^{n}/n! $ where a nd b do not depend on x and n respectively.From this we can see that X~$Gamma(n+1,3)$ and N~$ Pois(x)$. Now you need to generate samples from f(x,n). Setting up a Gibbs Sampler (which is a variant of Markov Chain Monte Carlo algorithm) as follows: Get random initial values for x and n, from say x~Unif(0,1) and n from sample(1:100,1) . (This needs to be tweaked based on how well algorithm works.) Let's propose Xi from Gamma(n+1,3) and accept Xi. Next propose Ni from Poisson(Xi), where Xi is current state of X. Repeat steps 2 and 3, each time the conditional distribution Poisson(Xi) and Gamma(ni+1,3) depending on last value of Xi and ni. Calculate effective sample size. I suggest using R package mcmcse if you're not familiar with effective sample size. Once you have decent sample size (say 200s or 500s), stop the algorithm. You have pairs (X1,N1)...(Xn,Nn). P(X^2 Hope this helps. Make sure to check that X and N have good variability (good mixing chain). Else try different starting values for X and N.
