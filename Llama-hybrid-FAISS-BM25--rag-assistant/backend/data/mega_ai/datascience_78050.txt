[site]: datascience
[post_id]: 78050
[parent_id]: 78047
[tags]: 
So your question is asking how to go about making a model which predicts whether the YouTube comment is paedophilic given the text provided in the YouTube comment itself. Before I provide an answer, it is worth considering the ethical applications of this model and what this will be used for because models do implicitly cause bias in all stages of model production, from data collection to model implementation. So before taking this task on, I urge to read this paper on model ethics ( https://arxiv.org/abs/1901.10002 ) Firstly, you obviously need data/YouTube comments. The most important part to consider is labelling. Now, this stage is particularly important as you want to get multiple people involved with labelling these comments as (non-)paedophilic. In this step, ensure that you use comments which are have a higher inter-labeller agreement. For the model, something like a RNN/LSTM with a many-to-one configuration with a final 2 node softmax layer after the sequential architecture has been fed all of the text input. Again, before you start such an endeavour, do be aware of the ethical consequences of this model.
