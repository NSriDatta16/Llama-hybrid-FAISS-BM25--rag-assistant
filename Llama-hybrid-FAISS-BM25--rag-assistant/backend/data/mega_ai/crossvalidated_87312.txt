[site]: crossvalidated
[post_id]: 87312
[parent_id]: 86912
[tags]: 
I'm more of an engineering guy, not a stats guy, so lets talk nuts-and-bolts. Find: estimated object metric uncertainty (state covariance) (possibly) an established standard measurement for finding measurment uncertainty. Given: random replacement of the object measured after each measurement, so paired comparison is not allowed. two measurement tools with different measurement uncertainty, one of whose uncertainty is not characterized. Considerations: Calibration. Most measurement systems are calibrated against high quality standards and so they have minimal bias. I should be able to assume this, but your system indicates bias as an issue. Sample size. Taking 100 measurements is pretty weak. I prefer at least 300, but that is related to my data. You need to make sure that you get enough samples to minimize the error in your estimates, but not so much that you are buried. I can easily get 10M samples, but it is beyond the scope of MatLab and my laptop to do anything more than basics with that many rows. Approach: convert your code from R to a language I know well, MatLab. look at CDF-domain interploation and scatterplots. MatLab of your code: function MySimulation %houekeeping clc; %parameters N=1000 true_mean = 0 true_sd = 1 % I simulate the property to be measured for N objects, here the property is % normally distributed... true_values = normrnd(true_mean,true_sd,N,1); % but it could also be a mixture of normal distributions: % it could be anything. A Gaussian mixture is crazy-tame compared to what % it could be, but we have to assume something to start this. % The "quality" of instrument B is "good enough" to measure the true values: gain_B = 1; offset_B = true_sd/10; dispersion_B = true_sd/10; % The instrument B has a lower "quality" than the one of instrument A: gain_A = 1.1*gain_B; offset_A=-2*offset_B; dispersion_A=5*dispersion_B; % I simulate the measuremente made by instrument A: L_A = instrument_measurement(true_values,gain_A,offset_A,dispersion_A); % I make the sample: % sample_to_measure_with_B = sample(true_values,100,replace=F) sample_to_measure_with_B = randsample(true_values,100); % I simulate the measuremente made by instrument B: L_B = instrument_measurement(sample_to_measure_with_B,gain_B,offset_B,dispersion_B); % I plot the empirical CDF of the true values, of the measurements made with % instrument A and of the measurements made with instrument B figure(1); clf; hold on h1=cdfplot(true_values); set(h1,'Color',0.5.*[1,1,1],'Linewidth',2); h2=cdfplot(L_A); set(h2,'Color','b','Marker','+'); h3=cdfplot(L_B); set(h3,'Color',[1,0.65,0],'Marker','o'); legend('true','A','B','location','northwest') title('Empirical CDFs') xlabel('x-measured property') ylabel('value of empirical CDF') function [out] = instrument_measurement(true_value,gain,offset,dispersion) % The instrument has three parameters: the true_value is transformed by means % of a linear transformation described by parameters offset and gain; then there % is a dispersion parameter. An ideal instrument would have gain=1, offset=0 % and dispersion that approaches to zero. out=normrnd(gain*true_value-offset,dispersion,length(true_value),1); return Your picture, translated: 10x Higher sampling: Now when we plot the A vs. B using the following [xa,fa]=ecdf(L_A); [xb,fb]=ecdf(L_B); xb2=xa; fb2=interp1(xb,fb,xb2); we get the this: If you look at it, you see that, except for runaway at the tails, the relationship between these two distributions is essentially linear. It is scale and offset. I would use sample size to figure out where to truncate the tails, then fit an analytic line through that. Then I can translate from one sensor reading to another. The trick of mapping through CDF's is how to deal with many distributions. You need to make sure that your sample size is high enough to capture the characteristics of the underlying distribution. If you were dealing with one bite at a time, iteratively instead of 10k samples at a time, then you could use a kalman filter to determine the mean and variance, or the transform between A and B. The preceding is a "rev1" brute force sort of approach. It is inelegant. It has holes and weaknesses. It is not strongly characterized. It does not stand on amazingly strong theoretical foundations. It is, however, reasonably quick and "good enough" which are also nice measures of goodness. About Welch has a great introduction. ( link ) A keyword for this is "sensor fusion". Here is a second link on the topic. ( link ) Best of luck.
