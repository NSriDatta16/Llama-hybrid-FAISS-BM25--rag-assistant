[site]: crossvalidated
[post_id]: 626112
[parent_id]: 626087
[tags]: 
No, this isn't going to work in any straightforward way. The difference between IID and Markov Chain bounds is the whole problem . That is, going from bounds for a mean to bounds for an empirical CDF is solved by the Dvoretzky–Kiefer–Wolfowitz inequality, but the problem of getting bounds even for a mean is the part that's actually difficult. The autocorrelation of outputs from MCMC isn't just between adjacent samples; it can be quite long range. For example, a random-walk Metropolis algorithm can spend arbitrarily long wandering around one mode of a target distribution without ever encountering the other modes. It's true that the past and future are independent conditional on the present, by the Markov property, but you need the unconditional distributions.
