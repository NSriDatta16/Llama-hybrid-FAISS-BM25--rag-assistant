[site]: crossvalidated
[post_id]: 448009
[parent_id]: 
[tags]: 
Why should one scale variables before performing PCA?

Frankly, this is an old topic, but I am hoping this is a new perspective. Though it is been a while, I am pretty familiar with PCA and all the linear algebra/math beneath it. I was thinking about using PCA for some task today and was following the standard recipe to normalize features before performing PCA, but couldnt wrap my mind around one detail. Intuitively, if the dataset is multivariate Gaussian, the contour is an ellipsoid. What PCA does is removing the shorter orthogonal axis after a linear transformation. See image below. The part that is unclear is that after you standardize your variables, the ellipsoid becomes a ball. All the orthogonal axis have the same length. What is the point of doing PCA then?
