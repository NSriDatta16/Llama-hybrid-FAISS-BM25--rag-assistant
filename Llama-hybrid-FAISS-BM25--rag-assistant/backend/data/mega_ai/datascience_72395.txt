[site]: datascience
[post_id]: 72395
[parent_id]: 
[tags]: 
Neural Network Architecture to approximate simple function

What neural network architecture would approximate this function? This is monotonically decreasing non negative time series, that has non-stationary mean. $$ q(t) = \frac{qi}{(1+b*D*t)^(\frac{1}{b})}. $$ Currently, I have a function to generate a time series of $q(t)$ as a function of $ qi , b ,D $ at any given time $ t $ . I use this function to generate many sequences varying the parameters of $ qi , b ,D $ for a set of times. So my synthetic data looks like $ q(1),q(2)...q(n)$ I then split that data in a train period and test period of different lengths: $ [q(1)...q(m)][q(m+1)...q(n)]$ I am attempting to train a neural network on this synthetic data, so I have essentially unlimited training data. I have tried MLP, LSTM, CONV-LSTM, but don't have a clear sense of how many layers/neurons are needed for this task. I have tried a few layers with 30-60 neurons in each. It is not clear how much synthetic data I need to generate also and over 100,000 in single model fit slows down training significantly. Does anyone have any advice how to approach this problem?
