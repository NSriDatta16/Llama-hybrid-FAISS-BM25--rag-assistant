[site]: datascience
[post_id]: 104682
[parent_id]: 104680
[tags]: 
mBART available in huggingface transformers is not in its base architecture. This means you will not be able to fit this transformer into single GPU offered by Colab. To deal with GPU OOM problem, you can refer to the PyTorch documentation at https://pytorch.org/docs/stable/checkpoint.html . Refer to this answer for detailed information.
