[site]: crossvalidated
[post_id]: 501959
[parent_id]: 
[tags]: 
Scaling embedding layer's outputs in Tensorflow

I have a neural network that takes categorical and quantitative features as inputs. The quantitative features are scaled in $[0,1]$ . I apply an embedding layer to get a continuous representation of the categorical features and then i concatenate them with the quantitative features again. My question is, in this case, what is the best way to ensure the embeddings and the quantitative features have the same scale before feeding them to the next layer?
