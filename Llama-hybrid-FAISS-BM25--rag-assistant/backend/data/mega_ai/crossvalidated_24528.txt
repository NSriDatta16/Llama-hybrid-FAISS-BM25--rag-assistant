[site]: crossvalidated
[post_id]: 24528
[parent_id]: 24514
[tags]: 
For specificity in the following I'm going to assume that an ANN here means a feedforward multilayer neural network / perceptron as discussed in e.g. Bishop 1996. and an SVM is the the vanilla version e.g. from Hastie and Tibshirani. @Dikran Marsupial's points about the structure of the domain are important ones. In fact you might want to read DM's other answer about SVMs. The possibility of having a posterior over classes is important if you expect to apply a loss function or otherwise act on your level of classification certainty as well as the actual classification. If not: well, not. In addition, I can see four more ways to choose. Loss function One way to distinguish the two is to decide whose loss function you prefer. Classically, ANNs have smooth loss functions, e.g. cross-entropy for multi-class classification. SVMs tend to have some kind of 'hinge loss': 0 to a point then increasing. One of these may be a more natural fit to your problem. Data size Another consideration is data size and storage. You mention your category balance but not the total size of the data. SVMs by definition keep and use only the 'support vectors', a subset of observations that anchor the separating hyperplane(s). This can make for a small final classifier. Also, traditional ANN training can be slow - the space of functions as smooth as the implicit gaussian process that your ANN is approximating with its finite number of hidden nodes is large... Multiple classes If you have multi-category data, SVMs have several ways to construct the necessary multi-class classifier out of individual two class SVM models. At least three methods are available which, as @fabee points out, may not give the same answers. His reference looks like a useful one. The options are a lot clearer in ordinary smoothed statistical classification model territory, where your ANN belongs. Interpretability If you care about discerning the the importance of different covariates, then ANNs give you hyperparameters to do so, although more traditional methods might be as or more efficient and straightforward at this, e.g. the Lasso (L1 regularisation) for linear regression models. If prediction success is your only goal then this aspect is, of course, irrelevant.
