[site]: crossvalidated
[post_id]: 362079
[parent_id]: 
[tags]: 
Deep learning unerfitting/overfitting

I started to perform deep learning for sentiment analysis on word embedding. I have plot the model loss and accuracy graph for each epochs to understand the performance better. I read the following post which is related to underfitting and overfitting. https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/ However, for my model the training accuracy is increasing but the validation accuracy is constant just after 4 epochs. I just wanted to ask what if the training accuracy increases/ training loss decreases while the validation loss and accuracy remain same? What does this specific case mean? How can I overcome it? Does this mean that there is not enough test data or I need a better model?
