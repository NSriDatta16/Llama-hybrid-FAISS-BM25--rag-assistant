[site]: crossvalidated
[post_id]: 63637
[parent_id]: 63631
[tags]: 
One way to assess the quality of your model is using k-fold cross validation. The idea is to split your training data into (say k=10) 10 parts, train on 9/10 of the training data and predict 1/10 of the data. This way you can get an indication of the quality of your model. You can also combine this with trying out different "tuning" parameters, to find the optimum settings given a training data-set. Another way is using a machine-learning algorithm which is interpretable, i.e. each feature is given a weight. This enables you to observe which features are important and which are not and make a decision based on your prior information about the problem. Linear SVM and Adaboost are both interpretable
