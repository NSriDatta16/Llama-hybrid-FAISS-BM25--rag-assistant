[site]: stackoverflow
[post_id]: 2166940
[parent_id]: 2166425
[tags]: 
It depends on how many cores you have. If you have only 2 cores (cpu, processors, hyperthreads, you know what i mean), then OpenMP cannot give such a tremendous increase in performance, but will help. The maximum gain you can have is divide your time by the number of processors so it will still take 100 - 150 ms per frame. The equation is parallel time = (([total time to perform a task] - [code that cannot be parallelized]) / [number of cpus]) + [code that cannot be parallelized] Basically, OpenMP rocks at parallel loops processing. Its rather easy to use #pragma omp parallel for for (i = 0; i and bang, your for is parallelized. It does not work for every case, not every algorithm can be parallelized this way but many can be rewritten (hacked) to be compatible. The key principle is Single Instruction, Multiple Data (SIMD), applying the same convolution code to multiple pixels for example. But simply applying this cookbook receipe goes against the rules of optimization. 1-Benchmark your code 2-Find the REAL bottlenecks with "scientific" evidence (numbers) instead of simply guessing where you think there is a bottleneck 3-If it is really processing loops, then OpenMP is for you Maybe simple optimizations on your existing code can give better results, who knows? Another road would be to run opengl in a thread and data processing on another thread. This will help a lot if opengl or your particle rendering system takes a lot of power, but remember that threading can lead to other kind of synchronization bottlenecks.
