[site]: crossvalidated
[post_id]: 432451
[parent_id]: 
[tags]: 
Accuracy converging to one in neural network (tensorflow.keras)

I was wondering if somebody would be able to shine a light on accuracy converging to 1 relatively quickly during training. I am working on some new data and this is the first time i have seen this. I have attached the imaged of accuracy and loss (actual and validation set). I am running a multi-label network where the data fits in to either class one, two or three. The code I am using is as follows: model= tf.keras.models.Sequential() model.add(tf.keras.layers.Dense(units=416, input_dim=20539, activation="relu")) model.add(tf.keras.layers.Dense(units=288, activation="relu")) model.add(tf.keras.layers.Dense(units=576, activation="relu")) model.add(tf.keras.layers.Dense(units=3, activation="softmax")) model.compile(loss="categorical_crossentropy", optimizer="SGD", metrics=['accuracy']) history=model.fit(X_trainERSC.values, y_trainERSC, epochs=20, batch_size=32, verbose=1, validation_split=0.15, callbacks=[EarlyStopping(monitor='val_loss', patience=5)],shuffle=True) Now the network trains fine and everything seems ot be ok and in a similar trend to data i have worked with previously. However, unlike the previous data which converges to about 97% for accuracy, the accuracy in this data converges to 1. I was wondering if this is normal? I know this seems vague, but i am not sure what to make of this and if for, accuracy and loss, extremely low loss as well as convergence to 1 is normal? Many thanks!!
