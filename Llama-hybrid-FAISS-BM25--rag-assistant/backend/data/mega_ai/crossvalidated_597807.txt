[site]: crossvalidated
[post_id]: 597807
[parent_id]: 597751
[tags]: 
It's hard to tell without understanding the data or having a baseline model to compare your model to it Without Knowing It might be several things: Validation Data Might be Easier as you said The dataset is easily predicted overall (for example by taking the average of the last 10 days I can predict Y) Now to answer your questions: Yes It's acceptable in that range, although if it's diverging or the difference is high it might be that the validation data is straightforward and small This is a tricky question to answer because it depends on the use case and the metric you're using Judging from the loss only isn't going to help you, you need to check, If it's a regression problem check what's the average error you'd accept in this case and so on or compare to a baseline model. Sadly you can't add a number, and you need a metric specific to your use case to decide, but generally, you want the difference to be constant across the training epochs(Both the training and validation loss are moving together). Define a good metric to decide the performance of your model, use your test data to evaluate your model, and compare your model to available benchmarks or baseline
