[site]: crossvalidated
[post_id]: 69583
[parent_id]: 68837
[tags]: 
Another way to do it is to calculate directly using the properties of the auto-covariances which are $\gamma (k) = \rho^{k} \gamma (0)$, where $\gamma (0) = \sigma^{2} / (1 - \rho)$ is the variance. Thus, the average for K periods is given by \begin{align*} \tilde x_{t} &= \frac1K \sum\limits_{t=1}^{K} x_{t} \end{align*} The average mean is $\mathbb E_{t} \tilde x_{t} = \frac1K \sum\limits_{t=1}^{K} \mathbb E_{t} x_{t} = \mu$ and denoting $\hat x_{t} = x_{t} - \mu$ to simpleify notation. The variance is given by. \begin{align*} V ( \tilde x_{t} ) &=\mathbb E_{t} \left[ \left( \frac1K \sum\limits_{t=1}^{K} x_{t} - \tfrac{n}{n} \mu \right)^{2} \right] =\frac1{K^{2}} \mathbb E_{t} \left[ \left( \sum\limits_{t=1}^{K} (x_{t} - \mu) \right)^{2} \right] =\frac1{K^{2}} \mathbb E_{t} \left[ \left( \sum\limits_{t=1}^{K} \hat x_{t} \right)^{2} \right] \end{align*} This square matrix of $N \times N$ elements with the $ij^{th}$ element being $\hat x_{i} \hat x_{j}$ can be written in terms of its diagonal and twice the upper triangular matrix as the upper and lower halves are symmetric. \begin{align*} V ( \tilde x_{t} ) &= \frac1{K^{2}} \mathbb E_{t} \left[ \sum\limits_{i=1}^{K} \hat x_{i}^{2} + \sum\limits_{i=1}^{K-1} \sum\limits_{j=i+1}^{K} 2 \hat x_{i} \hat x_{j} \right] = \frac1{K^{2}} \mathbb E_{t} \left[ \sum\limits_{i=1}^{K} \gamma (0) + 2 \sum\limits_{i=1}^{K-1} \sum\limits_{j=i+1}^{K} \gamma (j-i) \right] \end{align*} which with a reordering of the summation in the last term from $\sum\limits_{i=1}^{K-1} \sum\limits_{j=i+1}^{K} \gamma (j-i)$ to $\sum\limits_{i=1}^{K-1} \sum\limits_{j=1}^{i} \gamma (j)$ and recalling that $\gamma (k) = \rho^{k} \gamma (0)$ then, \begin{align*} & \sum\limits_{i=1}^{K-1} \sum\limits_{j=1}^{i} \gamma (j) = \gamma (0) \sum\limits_{i=1}^{K-1} \sum\limits_{j=1}^{i} \rho^{k} \end{align*} Now, the geometric sum $\sum\limits_{j=1}^{i} \rho^{k} = \rho + \rho^{2} + \ldots + \rho^{i} $ can be simplified to $\sum\limits_{j=1}^{i} \rho^{k} = \tfrac{\rho (1-\rho^{i} ) }{1- \rho}$ which leaves you with \begin{align*} & \sum\limits_{i=1}^{K-1} \sum\limits_{j=1}^{i} \gamma (j) = \frac{\gamma (0) \rho}{1-\rho} \sum\limits_{i=1}^{K-1} (1 - \rho^{i}) \end{align*} And the final sum can be simplified as follows \begin{align*} \sum\limits_{i=1}^{K-1} (1- \rho^{i}) &= ( 1 - \rho ) + ( 1 - \rho^{2} ) + \ldots + ( 1 - \rho^{K-1} ) = (K-1) - ( \rho + \ldots + \rho^{K-1})\\ &= (K-1) - \left( \frac{\rho (1-\rho^{K-1} ) }{1- \rho} \right) \end{align*} Combining back together, we get \begin{align*} V ( \tilde x_{t} ) &= \frac1{K^{2}} \mathbb E_{t} \left[ \sum\limits_{i=1}^{K} \gamma (0) + 2 \sum\limits_{i=1}^{K-1} \sum\limits_{j=1}^{i} \gamma (j) \right] \\ &= \frac1{K^{2}} \left[ K \gamma (0) + 2 \frac{\gamma (0) \rho}{1-\rho} \left( (K-1) - \left( \frac{\rho (1-\rho^{K-1} ) }{1- \rho} \right) \right) \right] \end{align*} or after some algebra\footnote{ Cancelling terms we have \begin{align*} &= \frac{\gamma (0) }{K^{2}} \left[ K + 2 \frac{ \rho}{1-\rho} \left( (K-1) - \left( \frac{\rho (1-\rho^{K-1} ) }{1- \rho} \right) \right) \right] = \frac{ \gamma (0) }{K^{2} (1 - \rho) } \left[ K (1-\rho) + 2 \rho (K-1) - \left( \frac{ 2 \rho^{2} (1-\rho^{K-1} ) }{1- \rho} \right) \right] \\ &= \frac{ \gamma (0) }{K^{2} (1 - \rho) } \left[ K (1 + \rho) - 2 \rho - \left( \frac{ 2 \rho^{2} (1-\rho^{K-1} ) }{1- \rho} \right) \right] = \frac{ \gamma (0) }{K^{2} (1 - \rho)^{2} } \left[ K (1 + \rho)(1-\rho) - 2 \rho (1 - \rho) - 2 \rho^{2} (1-\rho^{K-1} ) \right] \\ &= \frac{ \sigma^{2} }{K^{2} (1 - \rho)^{2} (1-\rho^{2}) } \left[ K (1 - \rho^{2}) - 2 \rho (1-\rho^{K} ) \right]. \end{align*} } \begin{align*} V ( \tilde x_{t} ) &= \frac{ \sigma^{2} }{K^{2} (1 - \rho)^{2} (1-\rho^{2}) } \left[ K (1 - \rho^{2}) - 2 \rho (1-\rho^{K} ) \right] \end{align*} Using Julius's method above I get exactly the same answer as this as well. Hope it helps.
