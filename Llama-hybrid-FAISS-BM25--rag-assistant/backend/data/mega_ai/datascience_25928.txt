[site]: datascience
[post_id]: 25928
[parent_id]: 22441
[tags]: 
Here's an approach: Get the lower dimensional embedding of the training data using t-SNE model. Train a neural network or any other non-linear method, for predicting the t-SNE embedding of a data point. This will essentially be a regression problem. Use the model trained in step 2 to first predict the t-SNE embedding of a test data point and then assign it to a class using kNN. This ensures that there is no data leakage between your training and test set. I believe this approach is a hacky way of bringing t-SNE into the binary classification picture. Do note that t-SNE was mainly intended for visualization of high dimensional data points and not to extract good features for a classification model. The fact that you could observe a clear separation between classes using the t-SNE visualisation implies that the data can be easily modeled as a binary classification task using a non-linear classification algorithm. If I were you, I would consider using ELMs, SVMs with non-linear kernels or good old Logistic Regression with regularisation.
