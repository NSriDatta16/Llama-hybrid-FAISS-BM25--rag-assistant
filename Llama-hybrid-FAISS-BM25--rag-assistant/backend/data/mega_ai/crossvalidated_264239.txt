[site]: crossvalidated
[post_id]: 264239
[parent_id]: 
[tags]: 
Understanding Bayesian Histogram

I'm reading about Dirichlet Process Models in "Bayesian Data Analysis" by Gelman et. al. To motivate the idea, they start with a section on Bayesian histograms. I am a little confused about their discussion. I'm sure it's obvious to the initiated, but alas, I'm uninitiated. I just want to verify that I understand correctly. I understand it might be hard to give an "answer" that's not just "yes" if I'm right. However, if enough people just say "yes", in the comments, I can answer my question by a simulated illustration, or something. Of course, if I'm wrong, then an answer would be correcting me :). Summary of their description We have iid data $y_i \sim f$, and we divide the data into intervals defined by $\xi_0 The probability model for the density is $$ f(y)=\sum_{h=1}^{k} 1_{\xi_{h-1} Where $\pi=(\pi_1,\ldots,\pi_k)$ is the parameter of probabilities. We can work out the posterior of $\pi$ under a $Dirichlet(a_1 \ldots a_k)$ prior. $$p(\pi \mid y) =^{\mathcal{D}} Dirichlet(a_1 + n_1, \ldots, a_k + n_k)$$ where $n_h = \sum_i 1_{\xi_{h-1} My Understanding If we want to get the "Bayes histogram" density estimate, we Specify the hyperparameters $a_1 \ldots a_k$ We calculate the values of $n_h$ from the data We sample a bunch of $\pi$ vectors from the posterior distribution and calculate the posterior mean vecctor (or some other estimate) We take $\hat{f}(y) = \frac{\pi_h}{(\xi_h-\xi_{h-1})}$ as our estimated density over the interval $[\xi_{h-1}, \xi_{h}]$, ie for all $y\in [\xi_{h-1}, \xi_{h}]$
