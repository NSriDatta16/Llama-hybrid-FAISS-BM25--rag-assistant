[site]: crossvalidated
[post_id]: 321620
[parent_id]: 
[tags]: 
Dimension in Locally Linear Embedding (LLE)

I am using LLE to do nonlinear dimensionality reduction. In my understanding, in the step 3, the eigendecomposition problem is with respect to the matrix M which has the dimension NxN (N is the number of points in training set). And the eigenvectors are the low dimensional embedding for the training point. However, there can be up to N eigenvectors that the embedding can even lie in a higher dimensional space (N>m, m is the original dimension of the training examples). Why it is the case? And if I want to find the pre-image of the low-dimensional embedding or the approximation error for the data point (the part of infomation that is lost when the data is represented by the low-dimensional embedding), is there any available algorithm? Thank you!
