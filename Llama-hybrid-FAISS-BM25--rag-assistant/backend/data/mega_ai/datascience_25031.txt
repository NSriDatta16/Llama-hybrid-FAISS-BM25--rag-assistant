[site]: datascience
[post_id]: 25031
[parent_id]: 24966
[tags]: 
In my experience GBM does at least as well as LR on small datasets too. The main advantages of GBM over LR occur when you have correlated variables nonlinearity interactions If you want to simplify your GBM you can use feature importances to drop unimportant features. You might also want to try PCA to see if you can reduce the number of features. After this you could try a LR model on the resulting features to see the model performance. If you're worried that you've overfit your model to the test set, you'll need to find a new test set!
