[site]: crossvalidated
[post_id]: 259180
[parent_id]: 259103
[tags]: 
First, some notation / recap. In most supervised machine learning models, we want to minimize $\DeclareMathOperator{\E}{\mathbb E}$ $$ L(f) = \E_{(x, y) \sim P}\left[ \ell(f(x), y) + \lambda J(f) \right] ,$$ where $\ell : \mathcal Y \times \mathcal Y \to \mathbb R$ is a loss function, e.g. $\ell(y, y') = \tfrac12 (y - y')^2$, $J$ is some kind of regularization function that penalizes complexity of the model, and $\lambda$ is a weight trading off between the two. Since we don't have access to the data distribution $P$, we instead use samples: $$ \hat L(f) = \frac{1}{n} \sum_{i=1}^n \ell(f(x_i), y_i) + \lambda J(f) .$$ Typically, we use an optimizer based on gradient information: $$ \nabla \hat L(f) = \frac1n \sum_{i=1}^n \nabla \ell(f(x_i), y_i) + \lambda \nabla J(f) .$$ "Minibatching" can be used to refer to two different things: Evaluating $f(x_i)$ and/or $\nabla \ell(f(x_i), y_i)$ for several different $(x_i, y_i)$ pairs at the same time (with the same $f$). Estimating $\hat L$ and $\nabla \hat L$ based on averages over subsamples of the data. To answer your specific questions: Yes, I think this is right. Yes, it is the case that the biggest advantage in the neural network context is that minibatches can be evaluated on a GPU in almost the same time as a single-point batch would have been. Even on "traditional" CPUs, though, SIMD processing means that some (smaller) level of minibatching is potentially helpful. Note that the size of a minibatch also affects the relative number of function and gradient evaluations, and if those have dramatically different computational costs then the tradeoff can change. You are correct that the gradient averaging does not have to be the same size as the computational averaging (though of course it can't be smaller). If you can only fit your model into GPU memory for 5 inputs at a time, you might decide to e.g. use optimization minibatches of size 50 but compute that in 10 separate passes. People generally don't do this for two reasons: one is that it's much simpler code-wise to do everything at the same time. The other is that, since you'll need to recompute the forward step with your new batch anyway, it takes almost exactly the same amount of time to do an optimization step with 5 inputs followed by another optimization step with 5 inputs as it does to do a single optimization step with 10 inputs computed over two passes, and the former usually gets you farther along in the optimization. I'm not sure I understand this question, but typically we need to compute the gradients for specific inputs at a time; TensorFlow or Theano will do all it can in combining gradients at model-building time, but it just gives you some function that needs data to evaluate the actual gradient at that point. We need the average gradient on a batch of data, so we might as well compute it all at once. I don't know what you're talking about here. An example of an explanation that doesn't make sense to you might help here.
