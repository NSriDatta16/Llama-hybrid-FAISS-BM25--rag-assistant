[site]: datascience
[post_id]: 25668
[parent_id]: 23828
[tags]: 
Support Vector Machines attempt to find a hyerplane that divides two classes with the largest margin. Therefore this is an optimization problem. Support vectors are the points that lie along the supporting hyerplane. One key factor that plays into the complexity of the runtime for a support vector is the slack parameter C. The slack parameter allows for a soft-margin and better generalization. The number of support vectors varies depending on how much slack we allow and how the data is distributed. The less slack we give the SVM the fewer support vectors we get and converserly the more slack we give it the more support vectors we receive. There also exist a relationship between the complexity of the model. The more complex the models tend to require more support vectors. In short, it doesn't really matter how many features you feed it, the SVM computational complexity is linear in the number of support vectors.
