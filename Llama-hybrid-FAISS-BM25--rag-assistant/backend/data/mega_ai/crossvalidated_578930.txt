[site]: crossvalidated
[post_id]: 578930
[parent_id]: 
[tags]: 
Small n - dimension reduction and regression

I am trying to develop a valid method for modeling some biological data. I do not need it to be predictive necessarily, but I want to be able to show relationships and determine which set (of many) has a strong relationship. In general, my data has n = 18 with x ~ 17 (though this varies) collinear variables. Based on what I know about the biology, there should be some sort of linear combination of variables that I can use to predict outcomes. I have been reading as much as I can, including a lot of Frank Harrell's work, but I am having a hard time determining if my approach is valid (or if there is something better that I can do). Process: Variable reduction via PCA. I can get to 90% of variation explained on 6 PCs, and usually hit ~ 60% on just two Use best subsets regression with the PCs to build linear models. Pick the "best" one using AIC or BIC criteria. Due to the small n, I am trying to stick to 3 or fewer components in the model. Present adjusted R2, p-value (?), AIC/BIC, and residual standard error I also have considered using rms::validate and presenting the index.corrected R-square and/or MSE. Is there something that I'm missing here? Is there something you (as a reader of this hypothetical study) would like to see presented that I am leaving out? This is aimed at biologists, not statisticians, so the stats need to be sound, but not revolutionary. Due to small sample size, I have stayed away from LASSO due to not wanting to sacrifice data for parameter tuning. I know nothing of Bayesian methods other than the simple things I have tried to teach myself, but I am open to all suggestions.
