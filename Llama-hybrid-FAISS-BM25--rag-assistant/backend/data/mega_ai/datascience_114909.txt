[site]: datascience
[post_id]: 114909
[parent_id]: 114904
[tags]: 
In a regression problem you have a set of observations $\mathcal{D}:= \{(x_{n},y_{n})\}_{n=1}^{N}$ with $x_{n}\in X \subset \mathbb{R}^{k}$ and $y_{n}\in Y \subset \mathbb{R}$ . The assumption is that there exists a function $$f:X \rightarrow Y\; \text{ such that}\; y_{n}=f(x_{n})+\varepsilon_{n}$$ with $\varepsilon_{n} \sim Normal(0,\sigma^{2})$ for $n=1,\ldots,N$ . The goal is to find a function which get's as close as possible to the function $f$ which is usually measured using an error metric $d$ . Examples are MSE=Mean Squared Error $MSE(y,\hat{y})=\sum\limits_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)$ RMSE=Root Mean Squared Error $RMSE(y,\hat{y})=\sqrt{\sum\limits_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)}$ . with $\hat{y}_{i}$ being the prediction for observation $i$ . From a high level, Kernel Ridge Regression is just one of many regression models, Linear Regression and Random Forest are other examples, that are used to approximate $f$ . Independent of your model is the error metric which is used to choose among your models, f.e. one model vs. another or which features to use in your model. As the error metric measures the discrepancy between your predictions and the true value, smaller values are better. Therefore one cannot answer the question in general which values of the RMSE are good given you use Kernel Ridge Regression but only compare between Kernel Ridge Regression with different kernels or between Kernel Ridge Regression and a Linear Model and choose the one with the smallest error metric.
