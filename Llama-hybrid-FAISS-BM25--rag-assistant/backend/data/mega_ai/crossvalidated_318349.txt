[site]: crossvalidated
[post_id]: 318349
[parent_id]: 318283
[tags]: 
Your flipped graph is logistic regression . A good description of the relationship between logistic regression and the naive Bayes classifier can be found in Jordan 1995 . You will not get the same results in both models. In general logistic regression will be superior because it only needs to characterize a decision boundary rather than full conditional distributions, which is easier. Indeed it makes no assumptions about the distribution of the Xs at all. The parameters of both models can be estimated using the usual principles, e.g. Bayes or ML (most likely with a regularizer). However, only for the naive Bayes model do these have a closed form. Late addition (2022) since I just noticed: There are undirected connections drawn between the $X$ 's in the first graph and, strictly speaking, Naive Bayes assumes that there are only $Y \rightarrow X$ connections. So if the generative model is as you draw it then Naive Bayes will get things wrong by assuming those connections are absent. In contrast, logistic regression - the second version - need not assume any distribution for $X$ s at all (and if it does, it won't matter), so correlations induced by those connections are not problematic for estimation or for predicting $Y$ . In that sense it's usually more practically appealing.
