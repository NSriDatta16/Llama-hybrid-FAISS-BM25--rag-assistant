[site]: datascience
[post_id]: 128145
[parent_id]: 
[tags]: 
How to handle time series data in ANN?

I want to use ANN to forecast the next #games played in my mobile game. There are 39 features: 9 features that describe the player's state (level, amount of in game-currencies, etc.) and the last 30 game-days (= number of games played condition the player played at least 0 games). Initially I sampled each player once. However I think it is possible to improve the accuracy of the model by increasing the number of samples (currently I have 1.8M samples). So I looked at historical data: I sampled each player, and each game-day in the last 180 days. Should I use just one sample from each user every 30 game-days? Since right now two adjacent samples are identical in 28 out of 30 game-days (with a shift of +1). My concern is that e.g., the data will have 28 samples where after a day of 104 games comes a day of 30, will this could make an overfit problem? import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, Masking from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from tensorflow.keras.callbacks import EarlyStopping from joblib import dump, load # Split the data into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Replace NaN values to 0 X_train = X_train.fillna(0) X_test = X_test.fillna(0) # Standardize the data (optional but recommended for neural networks) scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled = scaler.transform(X_test) dump(scaler, '/content/drive/MyDrive/Colab Notebooks/forecasting GPD/GPD_Forecasting_NN_Model.joblib') # save the scaler # Define the model with a Masking layer model = Sequential() model.add(Masking(mask_value=0., input_shape=(X_train_scaled.shape[1],))) model.add(Dense(64, activation='relu')) model.add(Dense(42, activation='relu')) model.add(Dense(1, activation='linear')) # Linear activation for regression model.summary() # Compile the model model.compile(optimizer='adam', loss='mean_squared_error') # Define early stopping callback early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # Fit the model to your data history = model.fit(X_train_scaled, y_train, epochs=30, batch_size=42, validation_data=(X_test_scaled, y_test), callbacks=[early_stopping]) # Evaluate the model mse_nn = model.evaluate(X_test_scaled, y_test) print('Mean Squared_error (Neural Network):', round(mse_nn, 3)) # Save the model to a file model.save("/content/drive/MyDrive/Colab Notebooks/forecasting GPD/GPD_Forecasting_NN_Model.keras")
