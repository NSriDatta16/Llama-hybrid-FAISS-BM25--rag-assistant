[site]: datascience
[post_id]: 77317
[parent_id]: 77160
[tags]: 
"Place coding" == "one-hot encoding" This is the conventional way of encoding a category at the output of a classifier: for N categories, use an N-dimensional vector where the k-th component is "turned on" and all other turned off to encode the category k. In general, the values for "on" and "off" do not need to be 1 and 0 (or +1 and -1). They could be anything. The alternatives to "place code" are "coarse coding" and "distributed representation" of which "error-correcting codes" are a special case. The classifier in the paper uses a form of distributed representation in which similar characters (like o, O, and 0) are represented by similar bit patterns. That way, when the system is not sure if the character is o, O, or 0, it will produce an output bit pattern that still identifies the character as one of those 3 categories, and leave it up to the post-processing (e.g. a language model) to resolve the ambiguity.
