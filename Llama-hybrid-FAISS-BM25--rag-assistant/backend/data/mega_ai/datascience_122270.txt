[site]: datascience
[post_id]: 122270
[parent_id]: 121403
[tags]: 
Currently I am working in a marketplace too, and I am trying to combine text and embedding features. I am doing this by simply concatenation of them. It's important to normalize the text features and embeddings separately to achieve better results with cosine similarity. If you want you can add weight between your embeddings, but if you want unit distance (in range [0;1]) you should normalise again after reweighting. I think concatenation is way more convenient, than separate search. You can store vectors via one storage, there may also be problems with the union of two results, for example, if these sets are disjoint.
