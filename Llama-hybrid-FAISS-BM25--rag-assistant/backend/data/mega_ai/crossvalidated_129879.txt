[site]: crossvalidated
[post_id]: 129879
[parent_id]: 
[tags]: 
SVM RBF performance on "dissimilar" data

I've been studying the performance of machine learning algorithms on "dissimilar" data (that is, prediction on new data that are not that "similar" to the training set) and I came up with this example where SVM with a radial kernel completely fails, so I would like your opinion on this. First I generated data from a simple cubic function, but with x restricted from -60 to 100, so the training set starts to show the cubic form but not all of it: set.seed(100) f Here is the plot of the training data: Then I generated additional data of two kinds: (i) similar to the training data (that is, in the range of the observed data); and, (ii) "dissimilar" to the training data (that is, outside of the range of the observed data): x2 The stripchart of the the data is as follows: After that I assessed how both the polynomial and the radial kernel SVMs would perform on the dissimilar data set. As expected, the polynomial gets it right, but the radial completely misses it. svmRadial I have played with the tuning parameters, but could not find ones that would make the radial SVM get the pattern right. So: Is this a known difficulty with the radial SVM (predicting polynomial patterns out of the predictors range)? Could you provide a technical explanation of the hard time SVM is having in this situation? Also, if possible, it would be nice to point out some papers on this subject (known limitations of radial kernel SVMs with dissimilar predictors).
