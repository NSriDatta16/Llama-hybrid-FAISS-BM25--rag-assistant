[site]: stackoverflow
[post_id]: 2266961
[parent_id]: 2266737
[tags]: 
Binary files have sort of an ambivalent relationship with VCS because: they do not merge (so the all "branching support" is not that interesting) they do not diff very well (meaning the storage of their history is not very compact) they usually can be generated or they can be fetched from other kind of repositories Binary files are part of Git limits as they tend to slow down the all workflow, and do not scale in size (the repo quickly becomes too large to manage/backup efficiently). So the question is: could you store those files is some other repo than a VCS? A Maven repo perhaps (managed by a repo manager like Nexus , not exactly distributed, but made to reference precise version of any kind of set of files). Jakub NarÄ™bski (actual Git contributor ) rightly points to a Git fork project able to manage more efficiently big files. [git-bigfiles (ok, the project logo is awesome ;) ) The question remains: is a VCS the right tool for managing such large objects? Because in my experience, the question of "cleaning up the history" will be asked one day or another, because of a ever increasing amount of disk space used. And VCS are fundamentally not made for "clean-up" their history. Git itself cannot do it without changing its SHA1 key, making any future publication to other public repo problematic.
