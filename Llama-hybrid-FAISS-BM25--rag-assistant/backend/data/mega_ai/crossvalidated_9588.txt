[site]: crossvalidated
[post_id]: 9588
[parent_id]: 
[tags]: 
After the fact hypothesis testing

I'm not really a statistician, but rather in need of statistical guidance, so I hope this is not too much of an off-topic question. I'm writing a master's thesis (computational linguistics/NLP), and I've got several result sets I'm comparing. Now, I didn't really formulate a null and an alternative hypothesis before I ran the experiments, which I understand means that ideally I shouldn't really go about using the T-test on my datasets. But some of the different results are so close that I've given in to the temptation and T-tested them. How unclean is this? Is it bad enough that I should leave it out of my thesis entirely, or is it less severe? In case it matters, the data are the error rates of different language models, by 10-fold cross-validation.
