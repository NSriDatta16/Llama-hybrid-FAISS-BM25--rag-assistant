[site]: datascience
[post_id]: 89860
[parent_id]: 
[tags]: 
Input shape of an Xception CNN model

I have a Keras Xception based model for gesture recognition. The accuracy of the model is around 60-70% for classifying 7 different gestures. The training dataset consists of 320x240 and 640x480 pixel images. Currently, I'm leaving the input_shape parameter of the model equal to default value of the Xception model in Keras, which is (299, 299, 3) . I assume under the hood the network is rescaling all inputs to 299x299 pixels, which probably isn't a good approach. My questions are: Is the Xception model somehow optimized for the 299x299 image size? That is to say, should I aim to crop/pad the input to 299x299 pixels rather than change the model's configuration? All usage examples I've seen so far have input width = height. Is there a reason to prefer square images? If I don't use cropping/padding, I have two options for the input shape: rescale all images to 640x480 in a preprocessing step, or rescale all to 320x240. Is the 640x480 option likely to result in much better accuracy?
