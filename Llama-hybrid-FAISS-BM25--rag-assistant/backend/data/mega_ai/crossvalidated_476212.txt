[site]: crossvalidated
[post_id]: 476212
[parent_id]: 
[tags]: 
Is there a point where null hypothesis testing is superflous?

Say you're writing a paper and you have the following data Each bar represents an average over a 120 values. I want to determine if the left five and right five sets of data are significantly different from each other, e.g. left datapoint one vs right datapoint one and so forth. The smallest difference is the fourth data point respectively, with the left being about 1.9 times bigger than the right. Is it common to perform a null hypothesis testing for a difference this (apparently) significant? Or, asked differently, is it conceivable to have data where you would have to accept the null hypothesis even though the data looks to be this skewed, especially over 120 samples.
