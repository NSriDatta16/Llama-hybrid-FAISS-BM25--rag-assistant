[site]: crossvalidated
[post_id]: 579907
[parent_id]: 320451
[tags]: 
There's a nice old Neural Computation paper on the relationship between the Laplace approximation and variational inference with a Gaussian proxy posterior: http://www0.cs.ucl.ac.uk/staff/c.archambeau/publ/neco_mo09_web.pdf In fine, the variational approximation is equivalent to requiring the Laplace approximation to hold on average , where the average is taken under the proxy posterior, as opposed to just "locally." Thus, the mean of the proxy posterior under a Laplace approximation is the point (assuming there's only one) where the gradient of the true log-posterior is zero; whereas the mean of the proxy posterior under the variational Gaussian approximation is the point that renders the average of the gradient of the true log-posterior zero. Similarly for the covariance matrix.
