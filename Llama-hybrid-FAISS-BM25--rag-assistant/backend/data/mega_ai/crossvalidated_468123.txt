[site]: crossvalidated
[post_id]: 468123
[parent_id]: 467701
[tags]: 
Let's lead off with a wonderful approximation. Here is a plot of two functions. The underlying tan curve is the graph of $\Phi,$ the standard Normal CDF. The overplotted blue curve is the graph of $\Lambda:z \to 1/(1 + \exp(-7z/4)),$ a scaled version of the logistic function. To see how well they approximate each other, here is a plot of their difference $\Phi-\Lambda$ (over a wider range): Their values never differ more than $\pm 0.015,$ less than one sixtieth of their full range (from $0$ to $1$ ). That's close. It means you can use one or the other as the link in a logistic regression and it will make practically no difference. ( $\Lambda$ implements (up to a scale factor that will be absorbed in the coefficient estimates) the usual logit link while $\Phi$ implements the probit link.) Turn now to the question. With no loss of generality, choose units of measurement for $X$ that give it a unit variance. To emphasize this, I will call this variable $Z,$ because it has a standard Normal distribution. Let $\Phi$ be the cdf of the standard Normal distribution. Adopting conventional notation, let $Y$ be the response given by thresholding a noisy version of $\beta_0 + \beta_ 1 Z$ at a value $t$ (for "threshold," instead of the less mnemonic $c$ in the question), $$Y = \mathcal{I}\left(\beta_0 + \beta_1 Z + \sigma W \gt t\right)$$ where $W$ has a standard Normal distribution independently of $Z$ and $|\sigma|$ is the error standard deviation. With the foregoing conventions, the question concerns the case $\beta_0=0$ and $\beta_1=1,$ but it will turn out there's nothing special about these choices: we will derive a universal result. It is immediate that $Y$ , conditional on $Z,$ has a Bernoulli $(p(Z))$ distribution with $$\eqalign{ p(Z) &= \Pr(Y = 1) = \Pr(\beta_0+\beta_1 Z + \sigma W \gt t) \\ &= \Pr\left(W \gt \frac{t - (\beta_0+\beta_1 Z)}{\sigma}\right) \\ &= \Phi\left(\frac{-t + (\beta_0+\beta_1 Z)}{\sigma}\right). }$$ The trick is to approximate $\Phi$ by $\Lambda.$ (Alternatively, perform your logistic regression using the probit link, which will give an exact result.) Applying the logit (the inverse of $\Lambda$ ) to both sides of the foregoing equation produces $$\operatorname{Logit}(p(Z)) \approx \frac{-t + (\beta_0+\beta_1 Z)}{4\sigma/7} = \frac{7(\beta_0-t)}{4\sigma} + \frac{7\beta_1}{4\sigma}Z.$$ This is the (approximate) logistic regression for the model (or, if you wish to think of it this way, of an entire population). Therefore, the logistic regression estimates from any sufficiently large random sample of this model must approximate its coefficients. (This is a well-known asymptotic property of the Maximum Likelihood procedure used to estimate those coefficients.) Writing such estimated coefficients as $\hat\beta_0$ and $\hat\beta_1,$ we find that $$-\frac{\hat\beta_0}{\hat\beta_1} \approx -\frac{7(\beta_0-t)/(4\sigma)}{7\beta_1/(4\sigma)} = \frac{t - \beta_0}{\beta_1}.$$ (It is now obvious that the potentially annoying factor of $7/4$ in the preliminary approximation is not a problem!) In the question, $\beta_0=0$ and $\beta_1=1,$ giving $$-\frac{\hat\beta_0}{\hat\beta_1} \approx t,$$ QED.
