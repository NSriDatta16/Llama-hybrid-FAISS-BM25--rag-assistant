[site]: crossvalidated
[post_id]: 563453
[parent_id]: 
[tags]: 
Sklearn PCA projection differences while reproducing projection sample by sample

I've been stuck on this issue due to inability to reproduce the performance of PCA-classification pipeline on training data, but in case the pipeline receives one sample at a time. This seems to be floating point arithmetic issue. Using sklearn I fit the PCA model to the matrix data: pca.fit(X_) - shape of X_ is (109,400), the model has 10 components Z = pca.transform(X_) I calculate the difference between recalculate the Z using fitted coefficients: x_ = X_ - pca.mean_ X_transformed = np.dot(x_, pca.components_.T) sum(Z - X_transformed) last line of course returns 0.0 Using the same coefficients I project single sample from the X_ matrix x_ = X_[0:1] - pca.mean_ x_transformed = np.dot(x_, pca.components_.T) Z[0:1] - x_transformed the result error vector array([[ 2.22044605e-16, -8.88178420e-16, 1.94289029e-16, -1.77635684e-15, -1.11022302e-16, 4.44089210e-16, 2.22044605e-16, 4.44089210e-16, -4.44089210e-16, 1.11022302e-16]]) It seems to me that this must be a floating point arithmetic issue i.e. the numerical representation of a number is a e-16 precision number rounded to a different place after coma in each case.* I don't understand why it behaves that way and how can I make sure those differences are always 0 (rounding those numbers on some level will only work once I understand the problem). Please help. Edit: The errors seem too small to care, but there is no guarantee that errors won't be magnified in specific case to bring bad result.
