[site]: crossvalidated
[post_id]: 224430
[parent_id]: 171043
[tags]: 
This is an older question but thought I would share how I tune xgboost parameters. I originally thought I would use caret for this but recently found an issue handling all of the parameters as well as missing values. I was also considering writing an iterating loop through different combinations of parameters but wanted it to run in parallel and would require too much time. Using gridSearch from the NMOF package provided the best from both worlds (all parameters as well as parallel processing). Here is example code for binary classification (works on windows and linux): # xgboost task parameters nrounds
