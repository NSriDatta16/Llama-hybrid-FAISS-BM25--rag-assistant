[site]: datascience
[post_id]: 107011
[parent_id]: 106946
[tags]: 
Provided you have the data already, and the data is labelled (i.e., split into the two classes $A$ and $B$ ), it makes sense to produce a number of visualisations to gauge what the model output would be. If you start with traditional classification algorithms like logistic regression, then the model output is going to be the probability of belonging to a particular class (say class $A$ ). Given the model output is a probability, it would make sense to look at the proportion of observations that fall into class A by several factors that are available on your dataset. For example, you could look at the average proportion that fall into class A over time, by age, by height, etc. EDIT There's two parts to 'explaining the model without building it'. You need to (1) Show what sort of predictions you're expecting, and (2) Gauge which factors are going to drive that prediction. Say you're building a model to determine whether or not it will rain in the next week ( $Y$ ). Let $y$ be a realisation of $Y$ with $y=1$ when it rains, and $y=0$ otherwise. Let $X$ be a vector of factors you're going to use to determine if it rains or not. On (1) , take a given factor from $X$ (call it $x_i$ ). If $x_i$ is continuous, bin it into several groups ( $x_{i,j}$ $j = 1, 2, ..., g$ where $g$ is the number of groups). These groups should align to the business understanding. In the absence of business understanding, just split the variable into deciles (or similar). For each group $j$ of $x_i$ , compute $$\delta_{i,j} =\frac{\sum_{l=1}^ny_i}{n}$$ where $n$ is the number of records on the dataset. Repeat this for each of the $g$ groups. After this, plot the results. The x-axis will be the $x_{i,j}$ 's and the y-axis will be $\delta_{i,j}$ 's. By doing this, you can determine what sort of predictions the model will produce . On (2) , you should look into the information value .
