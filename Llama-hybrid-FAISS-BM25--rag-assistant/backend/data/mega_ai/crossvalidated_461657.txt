[site]: crossvalidated
[post_id]: 461657
[parent_id]: 461559
[tags]: 
Before answering the question, let's first make clear the mindset behind kmeans and mixture model: kmeans : you believe that your samples are generated by k hidden components, each sample belongs to only one of the k components. The characteristics of a component is completely described by it's centre. Say for each component, there's a centre $c_i,i=1...k$ . mixture model : (take mixture of multivarite normal for example)you believe that the samples are generated by k hidden components, each sample belongs to only one of the k components. The characteristics of a component is completely described by it's centre and it's "concentrations" around the centre. Say for each component you use a multivariate normal distribution $MVN(\mu_i,\Sigma_i),i=1...k$ to represent the characteristics of it, where $\mu_i$ is the mean vector, the "centre"; and $\Sigma_i$ is the covariance matrix ( between your predictors/features ), the "concentration", of the component. When you assume the predictors/features are independent of each other and with the same scale, this is equivalent to setting $\Sigma_i = I\sigma^2,i=1...k$ in the mixture model, where $I$ is the identity matrix, $\sigma^2$ is a constant. Apply EM algorithm on this model is the same as applying the kmeans iterations on it, the two models will reach the same result and $c_i=\mu_i$ . As for your second question, how to decide the number of groups/components. There are two commonly used methods: Method1: Use Bayesian mixture model and calculate the BIC of your model with different instances of $k$ , pick the one $k$ that can minimize the BIC. Method2: Use Bayesian non-parametric methods such as Dirichlet process to select the most likely k automatically. Hope it helps!
