[site]: crossvalidated
[post_id]: 482347
[parent_id]: 482339
[tags]: 
Since math is rarely the main focus of deep learning papers (excepting theory papers of course), usually the notation is not that polished, and small typos are not uncommon. I find that the key is to ignore all mathematical notation at first, and try to figure out the motivation / high level ideas from the authors. In the case of this paper, based on a 2 minute skim, I figured out that they're starting from something called a "triplet loss" (which I am familiar with), then add on "hard negative mining" (another popular idea), and then tweaks it a bit more to turn it into equation 6. Since I am already familiar with triplet loss and hard negative mining, I can make sense of equation 4 and 5 without trying to reference how every single subscript or superscript is defined. Then it's not much of a leap to see how the authors arrive at equation 6. It's very easy to get lost by trying to parse every bit of notation sequentially. I think it's much more efficient to be familiar with the past literature and the common ideas in the literature (in this case, triplet loss + hard negative mining), figure out what the authors are trying to change / improve on at a conceptual level, Using this knowledge, you can usually decipher what the math says without reading the fine notation. To be honest it would never cross my mind to do this kind of vectorization, not with my current level of understanding. How the author of this blog, was able to understand that equation and to write it with this level of vectorization? Also how the author of the paper was able to write this equation? I have difficulty interpreting basic operations in matrix formula notation. I think this is a separate problem -- It's very important to have an good understanding of basic linear algebra if you want to understand a lot of the notation. On the other hand if you're just referring to the code -- I think the broadcasting and manipulations of rank-n "tensors" common to many ML frameworks is tricky for everyone the first time they see it -- just keep reading and implementing and it should come naturally.
