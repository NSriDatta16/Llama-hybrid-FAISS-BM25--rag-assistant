[site]: crossvalidated
[post_id]: 420166
[parent_id]: 395045
[tags]: 
The first issue is that there is an error in your pairwise comparison function - you are just repeating the "general comparison" test 15 times. The p-values are slightly different each time due to the random nature of the permutations. Your function should look like this: for(i in 1:length(rownames(df))){ temp % dplyr::filter(Site == df $Site1[i] | Site == df$ Site2[i]) temp_data_dist $envfit.p_value[i] Site, strata = temp $Year, perm = 999)$ factors$pvals) } This will show that none of your pairwise comparisons have significant p-values - likely due to small sample size. I'm not an expert in envfit, so may be incorrect, but I believe it is testing for how well the centroids of your factor (Site) fit the ordination you made - is that what you want? You are constraining it to only permute sites within the Year groupings - I'm not sure what this leaves it to test...? There will always be differences between two sampled communities - what do you mean when you say you want to test this statistically? Is there a threshold above which these differences are "significant" or "non-significant"? I would recommend having a look at the vegan function "adonis" rather than "envfit", and also thinking about what it is you want to test with your permutations. For example, it would be possible to test whether your sites show a greater similarity to themselves when they are re-sampled in subsequent years than they do to the other sites. Adonis would do this by calculating distances between the same Site across multiple Years, and then seeing if this is significantly smaller than if you calculated distances to the other Sites instead. I can't really think of any other test you could do with this dataset.
