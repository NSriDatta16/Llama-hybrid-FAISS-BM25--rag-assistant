[site]: datascience
[post_id]: 113934
[parent_id]: 107012
[tags]: 
Try this. This will average the word embeddings to obtain the sentence embeddings. # import libs import gensim from sklearn.metrics.pairwise import cosine_similarity # load word2vec model = gensim.models.KeyedVectors.load_word2vec_format('path to word2vec e.g. GoogleNews-vectors-negative300.bin', binary=True) # your inputs first_sentence_list = ['driver', 'backs', 'into', 'stroller', 'with', 'child', ',', 'drives', 'off'] second_sentence_list = ['driver', 'backs', 'into', 'mom', ',', 'stroller', 'with', 'child', 'then', 'drives', 'off'] # remove oov first = [word for word in first_sentence_list if word in model.key_to_index] second = [word for word in second_sentence_list if word in model.key_to_index] # average word embeddings to get sentence embeddings first_sent_embedding = np.mean(model[first], axis=0) second_sent_embedding = np.mean(model[second], axis=0) # calculate similarities result = cosine_similarity(first_sent_embedding.reshape(1,-1),second_sent_embedding.reshape(1,-1)) print(result)
