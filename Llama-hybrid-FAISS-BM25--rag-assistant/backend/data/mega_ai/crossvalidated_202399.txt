[site]: crossvalidated
[post_id]: 202399
[parent_id]: 
[tags]: 
Different predictions on multiple run of the same algorithm scikit neural network

Since a MLP can implement any function. I have the following code, using which I am trying to implement the AND function. But what I find that on running the program multiple times, I end up getting different predicted values. Why is this happening ? Also how does one determine which type of activation function has to be provided at different layers ? from sknn.mlp import Regressor,Layer,Classifier import numpy as np X_train = np.array([[0,0],[0,1],[1,0],[1,1]]) y_train = np.array([0,0,0,1]) nn = Classifier(layers=[Layer("Softmax", units=2)],learning_rate=0.001,n_iter=25) nn.fit(X_train, y_train) X_example = np.array([[0,0],[0,1],[1,0],[1,1]]) y_example = nn.predict(X_example) print (y_example)
