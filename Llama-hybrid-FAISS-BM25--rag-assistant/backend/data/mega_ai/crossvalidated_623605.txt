[site]: crossvalidated
[post_id]: 623605
[parent_id]: 260736
[tags]: 
In the visualization, each color corresponds to a different output category. If the t-SNE is to be believed, then your categories are rather hard to distinguish; I see lots of colors next to other colors. This means that your features are not adequate for distinguishing between the categories. In such a case, it might be wise to consider additional features. Just because you want strong performance on your features doesnâ€™t mean that it is possible. For instance, in the simulation below, the categories have identical distributions on the first two features. If you do not have access to the third feature, you will never reliably separate the categories. library(MASS) set.seed(2023) N The x1 and x2 features have the same joint distribution for all levels of the outcome y , so you can never reliably distinguish between categories if you only have those features, no matter how sophisticated of a model you use (not even deep learning on an enormous sample size). However, introducing the x3 feature allows for perfect ability to distinguish between categories, but you need to consider that third feature to have any ability to do so. It is, however, possible that the t-SNE has removed separability where there is quite a bit. To get at this, there are other ways to think of possible separability on these features. Could a human reliably distinguish between categories just by looking at the features? For instance, the $784$ pixels of the MNIST digits are enough for a human to distinguish between the digits. If a human can do so reliably with just the given features, then the features contain enough to separate the classes. Otherwise, the features might not. Have other attempts had luck distinguishing between categories based on these features? If other models have been successful, then it might be that your model is missing something about how the features lead to categories. For a logistic regression, for instance, it might be that an interaction is important, but if you do not specify an interaction term in the regression, the model will not pick up on its importance. Perhaps your model is not flexible enough to use the features effectively. If others have not worked with your data or similar data, do a bit of exploring. For instance, if you plot some univariate or even bivariate distributions of the features, subsetted by class, consider if there are obvious separations between the classes. If there are, perhaps the t-SNE missed that while working with a high-dimensional space.
