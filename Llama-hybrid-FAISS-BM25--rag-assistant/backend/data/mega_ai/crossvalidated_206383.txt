[site]: crossvalidated
[post_id]: 206383
[parent_id]: 206275
[tags]: 
( Expanding my comment to a proper answer. ) As I mentioned, it depends on your goal. The expected value $\mathbb{E}[f(x)]$ is only one of many possible choices for the optimization target. For example, assuming that the $f(x)$ are normally distributed, you could do: $$ x^\text{opt} = \arg \min_x \left\{ \mathbb{E}[f(x)] + \kappa \sqrt{\mathbb{Var}[f(x)]} \right\} $$ for some $\kappa \in \mathbb{R}$ that manipulates risk-sensitivity. If $\kappa > 0$ you are looking for a robust solution that is likely to be best and discourages large positive fluctuations. Vice versa, a negative $\kappa$ would favour an "optimistic" optimization that looks for large negative fluctuations (negative is good since we are minimizing). You can choose $\kappa$ based on quantiles of the normal distribution (see reference 2 below). In general, Bayesian optimization (BO, which is related to Gaussian processes and kriging ) deals with costly and sometimes noisy function evaluations; although most of the focus of the literature has been on the former part. You can find reviews for Bayesian optimization at this question . Several people have applied BO to noisy functions. As an introdution to the topic, David Ginsbourger gave a nice talk titled "Variations on the Expected Improvement" at the Workshop on Gaussian Processes for Global Optimization (Sheffield, Sept 17, 2015). You can find his talk here , and all the talks are available on this page (I also recommend all the other talks as an excellent general introduction to BO.) As references, I would start with the work done by Ginsbourger and colleagues, and Gramacy and colleagues: Picheny, V. and Ginsbourger, D., 2014. "Noisy kriging-based optimization methods: a unified implementation within the DiceOptim package". Computational Statistics & Data Analysis , 71, pp.1035-1053. ( link ) Picheny, V., Ginsbourger, D., Richet, Y. and Caplin, G., 2013. "Quantile-based optimization of noisy computer experiments with tunable precision". Technometrics , 55(1), pp.2-13. ( link ) Gramacy, R.B. and Lee, H.K., 2012. "Bayesian treed Gaussian process models with an application to computer modeling". Journal of the American Statistical Association . ( link ) Gramacy, R.B. and Apley, D.W., 2015. "Local Gaussian process approximation for large computer experiments". Journal of Computational and Graphical Statistics , 24(2), pp.561-578. ( link ) Both Ginsburger and Gramacy have R packages that implement their BO methods, respectively DiceOptim and tgp .
