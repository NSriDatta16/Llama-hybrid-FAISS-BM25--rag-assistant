[site]: crossvalidated
[post_id]: 577357
[parent_id]: 577333
[tags]: 
A Bayesian computation provides not just point estimates of the unknown parameters (as in "standard" regression) but a full probability distribution of those parameters. If your model is $$ y|x,\theta \sim f(x,\theta) $$ where $\theta$ represents the unknown parameters of the model, then the Bayesian calculation gives the posterior probability distribution of $\theta$ , $$ \hat P(\theta) \equiv P(\theta | x,y) \propto f(x,\theta)\pi(\theta) $$ from which you can calculate the prediction for a new data point $x^*$ , by integrating over all possible values of $\theta$ given its posterior distribution $$ P(y^*|x^*) = \int d\theta P(y^*|x^*,\theta) \hat P(\theta) $$ which is again a probability distribution for $y^*$ (called the posterior predictive distribution). You can use this distribution to calculate, for example, the mean of $y^*$ as well as intervals having a particular probability of containing $y^*$ ( Credible Intervals ) , as demonstrated for example by this plot (taken from this blog )
