[site]: crossvalidated
[post_id]: 490294
[parent_id]: 490174
[tags]: 
You don't need a boosted tree, or even interaction terms/deep trees, to get this type of behavior. This is an example of omitted-variable bias , which can show up in a context as fundamental as ordinary least-squares regression. This answer shows a simple example, in which adding a new categorical predictor actually flips the direction of a continuous predictor's relationship to outcome. That was just from adding the categorical predictor to the model without an interaction term. In ordinary linear regression this is a risk if you omit a predictor that is correlated both with outcome and with the included predictors. In logistic regression, more closely related to your boosted decision trees, an omitted predictor doesn't even need to be correlated to the included predictors to lead to trouble; see this page for an analytical demonstration in probit probability models. It will probably be hard to figure out directly from your gradient-boosted trees, with their high interaction depths, just what is going on. I suspect that logistic regression involving the feature X and the ones that you added to the the model, along with investigating the correlations of those added predictors with X, will provide important and readily interpretable hints.
