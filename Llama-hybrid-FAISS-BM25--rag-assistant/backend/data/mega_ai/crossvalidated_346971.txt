[site]: crossvalidated
[post_id]: 346971
[parent_id]: 346964
[tags]: 
This would be my approach to it: First, estimate the memory needed for the LSTM: How can calculate number of weights in LSTM I get that calculation to be 8552 params for all your layers. Now consider that each parameter will need to be stored as a floating point value. If we assume 32-bit resolution of these parameters is ok, you will need 4 bytes per parameter, so your lower memory bound will be: lstm_parameter_memory_size = parameters * 4 lstm_parameter_memory_size = 34208 bytes Of course you will need more memory than this, but this is (for the LSTM) the dominating factor. The exact timing response will require quite the analysis, so I suggest to use a tool to check Keras/TensorFlow execution or make a rough estimate on the number of instructions per LSTM unit. A more pragmatic and less theoretical approach: Buy something like an ESP-32, implement the LSTM in C and just try it. It is a powerful and inexpensive device: https://en.wikipedia.org/wiki/ESP32 . This approach allows you to scale your hardware solution down or up also, since most platforms will run your C code with smaller adjustments.
