[site]: crossvalidated
[post_id]: 125060
[parent_id]: 125050
[tags]: 
If you are using a single layer perceptron model, then I would advise against PCA and just add a regularisation term (weight-decay) to prevent over-fitting the training data. Regularised linear models generally don't have problems dealing with high dimensional data, provided the regularisation parameter is set carefully (e.g. my minimising the cross-validation error), and if you are unlucky, the discriminant information might lie in the low variance components that you discard using PCA. My advice would be to set the number of components by minimising the cross-validation error, rather than rules-of-thumb, which may work well on average, but very badly on your particular problem.
