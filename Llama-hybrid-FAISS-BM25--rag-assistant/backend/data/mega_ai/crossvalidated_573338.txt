[site]: crossvalidated
[post_id]: 573338
[parent_id]: 558895
[tags]: 
Some vague thoughts: "what do observations in the same cluster have in common?" You can take two views of clustering. One is to find groups of data points with attributes that are similar in some way. The other is as a generative model, in which case the things that observations in the same cluster have in common is the process that generated the data (Gaussian clustering is normally of this nature). So for example, if we were to cluster the penguin dataset we might identify two clusters, and one would contain most of the Gentoo penguins and the other would be a mix of Adelie and Chinstrap penguins. The thing that gives rise to these clustered variations in flipper length and body size is a biological difference in the populations that generated the data. Adding more variables might allow clustering algorithms to distinguish Adelie penguins from Chinstrap penguins In all of these cases, the user has to perform exploratory data analysis on the covariates of all observations assigned to the same cluster, and hope that observations in the same cluster share some defining feature that is unique to their cluster relative to the other clusters. That is rather the use of clustering, as a tool for exploring the data, so we can discover the differences in the data generating procedures by e.g. scientific means. Discovering the data generating processes by scientific means alone might be much more difficult. For example, if we were to run a clustering on the Iris Dataset, we could take the average value of the sepal length, sepal width, petal length, petal width of each cluster - then we could say that average sepal length of all flowers in the first cluster is 5.1 cm and the average sepal length of all flowers in the second cluster is 2.1 cm. This is slight missing the point for me. The clustering allows you to see if the data have a cluster structure (or can be explained as a group of overlapping sub-populations), that you can then investigate to see if there may be real differences in the generative process (e.g. whether the different groups of penguins/irises actually are different species). They are a tool for learning the underlying structure of the data to help us understand it. The centroid of the group may not be representative of the whole cluster, even if it is all generated by the same process. " but when you wanted to make predictions on new data, you wouldn't know which of the two regression models to use!" This is why I prefer clustering algorithms with soft assignment, as you can then use a weighted combination of the two models, depending on the attributes of the test case. BTW if you are interested in looking for differences in the data generating process, the clusters don't necessarily need to be distinct and well-separated from each other to be useful. There may just be an excess of observations in a small within the normal range of variation, and identifying that sub-population may be useful, and e.g. Gaussian Mixture Models can do that for you. Personally I only really like the non-generative clustering methods, where often you have soft-assignment of observations to clusters. I don't really see the point in hard-clustering algorithms in statistics (they are useful in engineering, c.f. vector quantisation ).
