[site]: datascience
[post_id]: 19400
[parent_id]: 
[tags]: 
Deep Learning Binary Text Classification

I am looking to build a model for specific news and blog articles which merge fashion with patterns in biology. I have 35 websites that I read daily (it is exhausting). I am wondering how to approach creating such a model so that I can send articles to it daily and it can predict whether or not they deserve reading (ie relevant vs irrelevant). For example, in a perfect world I send it 230 articles of which 12 are returned as relevant based on previous training and testing articles. Assuming all 12 are relevant I save them to the training dir and recompile to strengthen the model. After reading Deep Learning with Keras I was hoping Chapters 5 and 6 on Word Embeddings and RNNs(simple, LSTM, GRU) would point me to how to develop such a model. I was also reading how to implement a CNN for text classification but cannot seem to construct a basic conceptual framework for how to start with a few articles and adding to the training data every day to strengthen the model. Is there a term for this type of strategy? Has it been done in some form on Kaggle, Github, etc?
