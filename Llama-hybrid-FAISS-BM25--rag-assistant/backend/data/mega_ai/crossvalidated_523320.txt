[site]: crossvalidated
[post_id]: 523320
[parent_id]: 523290
[tags]: 
Anyone who tries to make predictions from limited data needs at least to be wary of overfitting: finding a "result" that happens to fit a small data set well but that fails miserably when you try to apply the "result" to a new sample. There's a particular problem with logistic regression, where it can be surprisingly easy to get " perfect separation ": a combination of predictors that exactly predicts outcomes in your limited data set . There's no assurance that "perfect" result will apply to a new case. Chapter 4 of Frank Harrell's course notes is a useful reference on how to do modeling with multiple predictors, with the case-number/overfitting issue covered in Section 4.4. A rough rule of thumb for logistic regression is that you should only evaluate one predictor per 15 of the lowest-prevalence outcomes. The link provided by kjetil b halvorsen goes into more detail. One way to try to work around limited data is to use a penalization technique that counteracts overfitting. Ridge regression is one useful approach, as it keeps all of your predictors in the model while reducing the magnitudes of their coefficients to avoid overfitting. But if you only have 10 customers you have no more than 5 in the lower-prevalence outcome category, and your optimal ridge-regression model probably wouldn't be much different from a null model.
