[site]: datascience
[post_id]: 47091
[parent_id]: 47073
[tags]: 
It could be the case that your GPU cannot manage the full model (Mask RCNN) with batch sizes like 8 or 16. I would suggest trying with batch size 1 to see if the model can run, then slowly increase to find the point where it breaks. You can also use the configuration in Tensorflow, but it will essentially do the same thing - it will just not immediately block all memory when you run a Tensorflow session. It will only take what it needs, which (given a fixed model) will be defined by batch size. You should alter your code example to be: config = tf.ConfigProto() config.gpu_options.allow_growth = True session = tf.Session(config=config)
