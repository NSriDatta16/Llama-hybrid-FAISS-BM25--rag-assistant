[site]: crossvalidated
[post_id]: 295042
[parent_id]: 41394
[tags]: 
An area of research in which the Bayesian methods are extremely straightforward and the Frequentist methods are extremely hard to follow is that of Optimal Design . In a simple version of the problem, you would like to estimate a single regression coefficient of a logistic regression as efficiently as possible. You are allowed to take a single sample with $x^{(1)}$ equal to whatever you would like, update your estimate for $\beta$ and then choose your next $x^{(2)}$, etc. until your estimate for $\beta$ meets some accuracy level. The tricky part is that the true value of $\beta$ will dictate what the optimal choice of $x^{(i)}$ is. You might consider using the current estimate of $\hat \beta$ of $\beta$ with the understanding that you are ignoring the error in $\hat \beta$. As such, you can get a maybe only mildly sub-optimal choice of $x^{(i)}$ given a reasonable estimate of $\beta$. But what about when you first start? You have no Frequentist estimate of $\beta$, because you have no data . So you'll need to gather some data (definitely in a very suboptimal manner), without a lot of guiding theory to tell you what to pick. And even after a few picks, the Hauck-Donner effect can still prevent you from having a defined estimate of $\beta$. If you read up on the Frequentist literature about how to deal with this, it's basically "randomly pick $x$'s until there exists a value of $x$ such that there are 0's and 1's above and below that point" (which means the Hauck-Donner effect will not occur). From the Bayesian perspective, this problem is very easy. Start your prior belief about $\beta$. Find the $x$ that will have the maximum effect on posterior distribution Sample using value of $x$ chosen from (2) and update your posterior Repeat steps 2 & 3 until desired accuracy is met The Frequentist literature will bend over backwards to get you try to find reasonable values of $x$ for which you can hopefully take samples at and avoid the Hauck-Donner effect so that you can start taking sub-optimal samples... whereas the Bayesian method is all very easy and takes into account the uncertainty in the parameter of interest.
