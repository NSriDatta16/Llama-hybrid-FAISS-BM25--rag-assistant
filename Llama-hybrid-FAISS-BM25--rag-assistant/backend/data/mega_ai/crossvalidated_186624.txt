[site]: crossvalidated
[post_id]: 186624
[parent_id]: 181
[tags]: 
Automated ways of building neural networks using global hyper-parameter search: Input and output layers are fixed size. What can vary: the number of layers number of neurons in each layer the type of layer Multiple methods can be used for this discrete optimization problem, with the network out of sample error as the cost function. 1) Grid / random search over the parameter space, to start from a slightly better position 2) Plenty of methods that could be used for finding the optimal architecture. (Yes, it takes time). 3) Do some regularization, rinse, repeat.
