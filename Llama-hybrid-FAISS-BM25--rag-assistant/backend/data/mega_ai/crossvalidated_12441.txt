[site]: crossvalidated
[post_id]: 12441
[parent_id]: 12425
[tags]: 
If you are using R, the caret package will save you from re-inventing the wheel. For example, the following code uses cross-validation to choose the tuning parameters for a random forest model, and then outputs the mean and standard deviation of accuracy for each cross-validation fold. Finally, it calculates class probabilities for the model. library(caret) library(PerformanceAnalytics) data(iris) #Make a yes/no dataset Dataset The nice thing about caret is that it makes it very easy to compare different predictive models. For example, if you want to try an SVM, you can replace the text method='rf' with method='svmLinear' or method='svmRadial'. You can also choose your tuning parameters based on AUC rather than accuracy by adding a line to the trainControl parameter: summaryFunction=twoClassSummary . Finnally, there's a bit of code in there from the PerformanceAnalytics package, chart.Correlation(Dataset[-5], col= Dataset$Class) , which is not needed to build the model, but provides a nice visualization of your dataset.
