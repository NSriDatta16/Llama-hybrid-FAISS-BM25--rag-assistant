[site]: crossvalidated
[post_id]: 422476
[parent_id]: 422430
[tags]: 
Are you familiar with autoencoders ? They are defined in terms of two networks: encoder and decoder , that are usually symmetrical. The general assumption is that to decode the data from the latent representation, you probably need similar kind of architecture, as was needed for encoding it. While re-using the weights from encoder in many cases would be possible and may seem reasonable, defining septate decoder network is more popular solution, because it is much simpler. The embeddings are floating-point numbers, to translate them to words you need a function that will map the numbers to words. There are many ways how this can be achieved, e.g. with recurrent neural networks that create words byte by byte, or $n$ -gram by $n$ -gram, or predicting the one-hot encodings for the words (usually the number of words is huge, so you need approximate solutions ), you may take into consideration the words that appear before or after the predicted word and use etc. There is no single best approach, because this is problem specific.
