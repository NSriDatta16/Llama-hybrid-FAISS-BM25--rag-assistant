[site]: crossvalidated
[post_id]: 133741
[parent_id]: 
[tags]: 
Statistical significance versus sample size

Statistical significance of a (variable in a) model grows with sample size. Citing Gilbert (1986) : If one uses test statistics with constant size (i.e. a constant degree of confidence), almost any simple model will be rejected given a sufficiently large data set. ...[On the other hand] any hypothesis can be maintained by testing it on a sufficiently short time series. From a practitioner's perspective, this is troubling. Statistical significance is often used in convincing that a (variable in a) model is relevant; but once you know it grows with sample size, the argument loses much of its power. Here is a related discussion (e.g. the answer by Mark Claesen). Questions: (1) How to overcome the sample-size-dependence of statistical significance? (2) Can we adjust statistical significance to make it independent of sample size? (3) What to use instead of statistical significance? The goal is to find out whether a given (variable in a) model is relevant and useful.
