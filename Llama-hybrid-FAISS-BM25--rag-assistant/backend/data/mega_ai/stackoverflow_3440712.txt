[site]: stackoverflow
[post_id]: 3440712
[parent_id]: 3293156
[tags]: 
I ultimately agree with Erik's last paragraph: "Ultimately, it all comes down to the exact system and its unique pattern of data access combined with decisions about which parts you want optimized..." This is the basic thing I force people to learn: there's no universal solution. You have to know your data and the actions performed against it. You have to know how frequent different type of actions are and their impact and expected execution times (you don't have to hard tune some rarely executed query and impact everything else if the end user agrees the query execution time is not so important--let's say waiting for few minutes for some report once per week is okay). Of course, as Erik said "performance isn't just about user wait time or even query response time but also about server resources" If such a query affects overall server performance, it should be considered as a serious candidate for optimization, even if execution time is fine. I've seen some very fast queries that used huge amount of CPU on multiprocessor servers, while slightly slower solution were incomparable "lighter" from resource utilization point of view. In that case I almost always go for the slower one. Once you know what is your goal you can decide how many indexes you need and which one should be clustered. Unique constraints, filtered indexes, indexes with included columns are quite powerful tools for tuning. Choosing proper columns is important, but often choosing proper order of columns is even more important. And at the end, don't kill insert/update performance with tons of indexes if the table is frequently modified.
