[site]: crossvalidated
[post_id]: 511723
[parent_id]: 399681
[tags]: 
I agree that the naive (not accounting for autocorrelation) t-test would tend to reject far too often under the null. For example, mean(replicate(500, t.test(arima.sim(list(ar=0.8), n = 1000))$p.value returns rejection frequencies around 50% in my runs, so that half of all mean-zero series are false declared to have a nonzero mean. However, generating time series with a small non-zero mean, as in mean(replicate(500, t.test(.01+arima.sim(list(ar=0.8), n = 1000))$p.value does not generate very different rejection frequencies, so that the type-II error - at least for alternatives close to the null - is not much different, and for any given non-rejection observed for some real time series fow which you do not know the true DGP you are not going to know if you just made a correct decision under the null or a type-II error. Of course, not knowing if, when you did not reject, you made a correct decision or a type-II error, is not fundamentally different when your test is sized correctly, but at least the rejection frequencies under the null are then controlled at some (typically small) level $\alpha$ .
