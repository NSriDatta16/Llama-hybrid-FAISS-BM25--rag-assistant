[site]: crossvalidated
[post_id]: 446267
[parent_id]: 446262
[tags]: 
I have comments on five levels. On this evidence this is a limitation of a particular R function shapiro.test() and need not imply that that there aren't other ways to do it in R, on which I can't advise specifically. It may or may not be of practical relevance to you that no such limit applies to all software. For example, the Stata command swilk isn't limited in quite this way, but the manuals and the command output warn that P-value calculation can't be trusted much for sample sizes above about 5000. (EDIT: this paragraph edited 26 January 2021 in the light of @Ben Bolker's comment and separate answer.) I can't comment on why that particular function won't perform, but the larger question is why you are doing this kind of testing at all. A good reason not to care is generic: for sample sizes of that order, or even larger, such tests are arguably fairly useless as even minute deviations from normality will qualify as significant at conventional levels. More specifically: why is it important or interesting to test for normality? People often apply such tests to marginal distributions given a widespread myth that marginal normality is a requirement for very many procedures. Where normality is a relevant assumption, or ideal condition, it usually applies to distributions conditional on a structure of mean outcomes or responses. In response to your specific query of whether subsampling is acceptable, the serious reply in return is acceptable in what sense? A personal reply: as a reader, author and reviewer of statistical papers, and as a statistical journal editor, my reaction would be to suggest that such subsampling is at best awkward and at worst an avoidance of the main issue , which would be to find an implementation without such a limit, or more likely to think about the distribution in different terms. As often emphasised on CV, and elsewhere, the most helpful and informative way to check departure from normality is a normal quantile plot , often also called a normal probability plot, a normal scores plot, or a probit plot. Such a plot not only provides a visual assessment of degree of non-normality, it makes precise in what sense there are departures from the ideal shape. The lack of an associated P-value is not in practice much of a loss, although the procedure may be given some inferential impetus through confidence levels, simulations and so forth. (EDIT 26 January 2021: yet other terms are Gaussian percentile plot and Gaussian probability plot.) Specifically, your examples consist of generating lognormal samples and then establishing that indeed they fail to qualify as normal with P-values $\ll 10^{-15}$ . That has to seem puzzling, but be reassured that with larger samples your P-values will be, or should be, even more minute, subject to a machine level question of the minimum reportable P-value here. Conversely, it may well be that your real problem lies elsewhere and these examples are no more than incidental illlustrations.
