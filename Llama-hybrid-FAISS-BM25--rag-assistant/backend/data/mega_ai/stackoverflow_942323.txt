[site]: stackoverflow
[post_id]: 942323
[parent_id]: 
[tags]: 
How do database perform on dense data?

Suppose you have a dense table with an integer primary key, where you know the table will contain 99% of all values from 0 to 1,000,000. A super-efficient way to implement such a table is an array (or a flat file on disk), assuming a fixed record size. Is there a way to achieve similar efficiency using a database? Clarification - When stored in a simple table / array, access to entries are O(1) - just a memory read (or read from disk). As I understand, all databases store their nodes in trees, so they cannot achieve identical performance - access to an average node will take a few hops.
