[site]: crossvalidated
[post_id]: 333875
[parent_id]: 333856
[tags]: 
Chi-squared seems inappropriate to your aim, which is to determine if there is a strong relationship between your model and your data. Chi squared tests for differences, not similarity nor association so is the inverse of your needs. You cannot 'prove' a null hypothesis, only fail to reject it or state that you have a defined level of confidence it does not apply. Many articles and discussion boards cover this topic extensively, resources I found invaluable when I began to understand this aspect of statistical inference (regretfully more years into my research career than I care to admit, it took me a lot of head aches and diving deeper than I ever wished) https://www.researchgate.net/post/how_to_interpret_P_values http://www.dummies.com/education/math/statistics/what-a-p-value-tells-you-about-statistical-data/ http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values https://academic.oup.com/jnci/article/99/4/332/2522393 This means that a low p value for your Chi Square test would be interpreted that the probability of there being zero difference between your proposed distribution and you observed distribution is very low. A high p-value would be interpreted as the differences between the distributions could arise from random chance. Neither of these interpretations are identical to 'graphical inspection clearly shows that the numbers do conform to Benford's law quite perfectly'. This phrase suggests that you wish to demonstrate concordance/equivalence or association between your expected and observed data. This suggests that the hypothesis you wish to falsify is 'the observed data is equivalent to Benford's law within a confidence interval of X'. Correlation would be a more relevant statistic and will tell you the strength of agreement between your model and the data. $ R^2 $ will tell you the proportion of your data that can be explained by your model. There will be some that isn't, which suggests that some other factors are perturbing the data slightly away from your ideal model. Your observed data will not be Benfords law plus true random noise, instead it will be Benford's law plus other subtle but real effects that cause small but real deviances. Using a big sample number gives you greater power for detecting these non-random subtle effects. Whether those subtle deviances are big enough to matter will be handled by $R^2$. Whether it is worth examining the additional factors that mean your data deviates from the model will depend on $ R^2 $, which I suspect will be large. It will come down to matter of practical significance rather than statistical significance. It is not that chi squared is over powered, I suggest it is answering a different question to what you want.
