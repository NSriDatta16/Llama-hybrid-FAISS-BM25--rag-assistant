[site]: crossvalidated
[post_id]: 324730
[parent_id]: 
[tags]: 
How to write loss function for variational autoencoder?

So I've trying to follow various resources (Geron, Doersch, Altesaar, et al.) to construct a working loss function for my variational autoencoder but I'm finding that formulations either seem to work only for binary images (mine are 8-bit RGB), or if they succeed, it is only because the generative and reconstructive loss terms are out of balance and the VAE essentially just ignores the KL divergence term. Another way to put this perhaps is that I don't know how to define the analog of cross-entropy for image data. I use square-error instead and currently add a manual scaling parameter, with results that generally aren't very good. In particular following Geron (and leaving out my lambda) I've got: generative_loss = tf.square(xhat - x) latent_loss = 0.5 * (tf.square(bn_mean) + tf.square(bn_sd) - 1 - tf.log(eps + tf.square(bn_sd)) cost = generative_loss + latent_loss Where bn_mean and bn_sd are the corresponding latent space (bottleneck) mean and standard dev. vectors. What is a better way?
