[site]: crossvalidated
[post_id]: 598732
[parent_id]: 337414
[tags]: 
Often times (actually, most of the time) data can contain just as many categorical variables as continuous ones. Regardless, the task is to compute customer segmentation analysis. In parallel, you need to detect associations and correlations with categorical variables - a good lead-in to customer segmentation, anyway. So some approaches: Evaluate k-modes again, but first use a dimensionality reduction technique like principal component analysis to extract a few set of variables that are explaining the maximum variance in the dataset. Hard to "visualize" k-modes outputs if it's too cluttered. Take it one variable at a time. Use chi-square tests to evaluate associations between 2 categorical variables. Beware that in high-count comparisons, very similar groups can still yield statistically significant differences (though they aren't), so good to apply a Cramer's V correction to it. But once associations evaluated here, can layer on chi-square automated interaction detector (CHAID). It's a decision tree classifier that creates groupers. And from this you can evaluate segments. Logistic regressions also work well, and most importantly, is interpretable. Look at significant odds-ratios. Remember to understand which of the variables is serving as the baseline (e.g., when looking at gender, males are 1.5x more likely than females to get/have/etc "y" - whatever your outcome "y" is). Evaluate cosign similarity Last, though very useful in other cases, here I would not recommend one-hot encoding to generate numerical values just to get them working in a k-means algorithm. It's forcing a category to be a number, when there's no inherent Euclidean distance between "cat" and "dog", or "Boston" and "San Francisco." They're different, yes. But how different numerically? Impossible to know, except in the sense of frequency distributions with respect to another variable. One-hot encoding will simply enforce a category to be 0 or 1, which are relatively extreme values and will make models apply more weight to them than continuous variables when both are introduced simultaneously into your model.
