[site]: crossvalidated
[post_id]: 111746
[parent_id]: 
[tags]: 
Interpreting conflicting results from Random Forest & Logistic Regression?

I am using SKLearn and Statsmodel in python to build a RF and Logistic Regression, respectively. I have a feature that the RF indicates is important (feature importance of 0.202, closely behind #1 and #2 most important features). However, in running the logistic regression, the coefficient associated with this same feature is 0.0009, nearly 0. What is going on here? Why would splitting on this variable lead to higher information gain in the Random Forest, but contribute little to the logistic regression model?
