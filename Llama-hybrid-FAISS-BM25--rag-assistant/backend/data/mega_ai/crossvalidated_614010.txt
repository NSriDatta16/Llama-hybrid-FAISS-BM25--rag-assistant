[site]: crossvalidated
[post_id]: 614010
[parent_id]: 613718
[tags]: 
As you pointed out, each observation $(x_i,t_i)$ gives you information on the value of the cumulative distribution at the point $x_i$ , however notice that the probability of this observation is $\Phi(x_i)^{t_i-1}(1-\Phi(x_i))$ (the first $t-1$ offers rejected and the last one accepted). So, without additional assumption on $\Phi$ (such as smoothness), you can only directly estimate from the data the set of values $\{\Phi(x_i)\}$ . Now there are many possible methods of statistical inference, but most are based on the likelihood function, so that's a good place to start. Denote $p_i = \Phi(x_i)$ the set of unknown parameters and assume that the $x_i$ 's are sorted such that $0 \le p_1 \le p_2 \le ...\le p_n \le 1$ . The likelihood function is then $$\log \mathcal L(p_1,...,p_n) = \sum_{i=1}^n (t_i-1)\log p_i + \log(1-p_i).$$ The constraint on the $p_i$ 's being monotonically increasing makes this a slightly less trivial problem, but we can still find the maximum likelihood estimators (MLE) with a bit of work. The unconstrained MLE's are easily found by setting the respective derivatives of the likelihood to zero: $$ \frac{\partial \log \mathcal L}{\partial p_i} = \frac{t_i - 1}{p_i} - \frac{1}{1-p_i}=0 $$ which gives $$ \hat p_i = \frac{t_i-1}{t_i}.$$ If this set of MLE's satisfy the constraint $0 \le \hat p_1 \le \hat p_2 \le ... \le \hat p_n \le 1$ then we are done. Otherwise, since there is only a single local maximum at the interior of the parameter space, the global maximum must be on the boundary, namely there must be some $i$ such that $\hat p_i = \hat p_{i+1}$ . One can test all possible $n$ pairs, but it is quite clear the highest value of the likelihood will be achieved by applying this to a pair that is in the "wrong" order. Applying this additional constraint only affects the terms in the likelihood involving $p_i$ and $p_{i+1}$ so the equation for the MLE becomes: $$ \frac{\partial \log \mathcal L}{\partial p_i} = \frac{t_i + t_{i+1}-2}{p_i} - \frac{2}{1-p_i}=0 $$ Which is, understandably, the same equation we got before just with the average $(t_i+t_{i+1})/2$ replacing $t_i$ . Repeating this procedure for all out of order pairs will give us the constrained MLE's. If there are three or more consecutive estimators that are out of order, the number of possibilities we need to test becomes larger. In general there are $2^n$ ways of choosing which consecutive pair of estimators are equal, so this might become non-feasible if all the estimators are completely out of order, but in that case we probably can't say much about $\Phi(x)$ anyway. Finding the MLE's is just the tip of the iceberg. You may also want to estimate the uncertainty of the estimators, add assumptions on the shape on the distribution $\Phi$ and so on. Describing all methods of doing it will require a full course in statistics. The particular methods that are best suited to your case will depend on the nature of your assumptions and data, and what purpose you want to use it for. UPDATE As a simple example we can apply this to the same input data as given in @Ben's answer: $t=(2,7,6,12,15)$ . There is one pair in the wrong order $(7,6)$ so we conclude that $p_2=p_3$ , and we proceed by replacing those values with the average $6.5$ and simply calculating $(t-1)/t$ for the set $(2,6.5,6.5,12,15)$ : this results in $\hat p = (0.5000, 0.8462, 0.8462, 0.9167, 0.9333)$ , In complete agreement with @Ben's numerical calculation.
