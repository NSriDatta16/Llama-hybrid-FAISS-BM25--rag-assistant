[site]: datascience
[post_id]: 88432
[parent_id]: 88357
[tags]: 
Coming to Neural Networks We can tweak a lot of parameters that can improve performance of the network. Sometimes changing a small parameter value can result in a big performance increase and sometimes we have to tweak a lot to get good performance. This depends on the problem. In general the following parameters are often important in terms of getting good performance: Number of layers: change number of layers by adding more layers or removing some layers. Number of layers. Number of Kernels Kernel Size activation function(most people use relu but we can try more like prelu, elu..etc) weight initialization techniques: try different weight initializers with respect to activation function used. Try dropout layers which we reduce overfitting Try Batch Normalization use pretrained models(Transfer Learning) which can increase performance very much. These are some of popular parameters on which performance of model depends. Try tweaking them and get a good knowledge of these.
