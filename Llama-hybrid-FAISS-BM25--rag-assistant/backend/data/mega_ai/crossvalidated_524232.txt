[site]: crossvalidated
[post_id]: 524232
[parent_id]: 497944
[tags]: 
If you already have good values, then you probably want to focus on small improvements instead of going through the entire search space. This makes methods such as Bayesian optimization less desirable. As you mentioned, Confident Local Optimization is one such method, though from a brief glance at it, it seems to be context-dependent. Some other localized search algorithms also include SPSA as you mentioned, as well as simulated annealing. These last two can be applied to more general situations and are quite easy to implement in comparison to many others. It's worth pointing out that CLOP: Confident Local Optimization for Noisy Black-Box Parameter Tuning suggests SPSA to be quite closely competitive to it. I would not recommend using a global optimization algorithm, such as random search, near your initial point. These algorithms simply aren't built for optimizing near a point, as they often rely on tactics such as exploring the search space. On a localized scale, you can take advantage of the fact that the objective is relatively smooth, meaning minimized exploration and focused refinement in directions you know are likely going to offer good results. Even if you wish to have more exploration, there are methods such as simulated annealing which allow such behaviors.
