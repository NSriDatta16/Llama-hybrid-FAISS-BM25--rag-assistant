[site]: crossvalidated
[post_id]: 371571
[parent_id]: 371295
[tags]: 
Is there some sort of methodology for training a model to make predictions on many (seemingly unrelated) time series data? The closest thing to an actual methodology for this is hierarchical forecasting . On my team (I work in demand forecasting) we use a type of hierarchical forecasting to generate forecasts for product/location groups (for example for an entire class of products across an individual region). However we don't do any sort of clustering or scientific similarity analysis, instead we have a pre-defined product similarity matrix defined by the business (according to product type, supplier, etc...). The approach is similar in spirit to the paper that Dr. Kolassa mentioned, in the sense that the group level forecast provides the seasonality and the shape of the forecast - and then individual product histories are used simply to adjust the height of the signal. Train a model (maybe a neural network or LSTM) on all the different time series at the same time, with the hope that this model would then be capable of producing 'good' predictions per time series fed to it. On the other hand, the approach you describe in (2) is what Amazon uses with their DeepAR model . It is a gigantic LSTM that takes in all products at the same time, and then tries to learn the correlations between the different products to give one big model that is used for all the products. Although even with DeepAR, you still have to provide with product attribute features so that it correctly estimate product similarity.
