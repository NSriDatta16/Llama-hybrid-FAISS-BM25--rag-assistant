[site]: crossvalidated
[post_id]: 104931
[parent_id]: 104500
[tags]: 
Being able to generalize well This is the essence of a good model. And it is the essence of what makes the best practitioners of the art of machine learning stand out from the crowd. Understanding that the goal is to maximize performance on unseen data, i.e minimize generalization error , not to minimize training error . Knowing how to avoid both over-fitting and under-fitting. Coming up with models that are not too complex yet not too simple in describing the problem. Extracting the gist of a training-set, rather than the maximum possible. It is surprising how often, even experienced machine learning practitioners, fail to follow this principle. One reason is that humans fail to appreciate two vast theory-vs-practice magnitude differences : How much larger is the space of all possible examples compared to the training-data at hand, even when the training data is very large. How much larger is the full "hypothesis space" : number of possible models for a problem, compared to the practical "solution space": everything you can think of, and everything your software/tools are capable of representing. The 2nd magnitude gap is especially incomprehensible. Even for the simplest problem with $N$ inputs and a binary outcome, there are $2^N$ possible input-examples. And this is dwarfed by the exponentially larger "hypothesis space" number which is $2^{2^N}$ possible models. It is also what most of the above answers said in more specific and concrete ways. to generalize well is just the shortest way I could think of, to put it.
