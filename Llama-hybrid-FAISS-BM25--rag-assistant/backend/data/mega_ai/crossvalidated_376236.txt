[site]: crossvalidated
[post_id]: 376236
[parent_id]: 
[tags]: 
Higher order extensions of gaussian distribution?

I anticipate that this question may be predicated on some misconceptions or confusion. Please have patience. Through Bishop's PR&ML book, as well as a little bit of exposure to statistical mechanics, I understand that the Gaussian distribution has maximal entropy for a given choice of first and second order moments. For multivariate statistics this is still true, and the complete description of second order moments is an order 2 tensor, i.e. the covariance matrix. My question is: Is there a natural extension that takes these properties to higher order moments, for example, using an order 3 tensor for the 3rd order statistics? Is this sort of construction ever used? Edit: I rephrased the question in the comments below: If all I know are the mean and covariance of a random variable, then there are infinitely many distributions it might have. However, among all such distributions the Gaussian best represents my state of knowledge. The question then is, what distribution should I assume if I also knew all of the third order moments. It seems as though I can find such a distribution via Boltzmann's theorem, but I'm interested in whether this approach ever actually comes up in statistics / Bayesian inference / etc. I'm happy with reading suggestions if you find this question is too poorly conceived to give a good answer.
