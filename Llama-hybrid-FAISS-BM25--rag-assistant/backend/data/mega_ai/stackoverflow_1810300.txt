[site]: stackoverflow
[post_id]: 1810300
[parent_id]: 1763099
[tags]: 
Here are a variety of suggestions: Issue tokens required for redemption along with each AJAX request. Expire the tokens. Track how many queries are coming from each client, and throttle excessive usage based on expected normal usage of your site. Look for patterns in usage such as sequential queries, spikes in requests, or queries that occur faster than a human could conduct. Check user-agents. Many bots don't completely replicate the user agent info of a browser, and you can eliminate programatic scraping of your data using this method. Change the front-end component of your website to redirect to a captcha (or some other human verifying mechanism) once a request threshold is exceeded. Modify your logic so the respsonse data is returned in a few different ways to complicate the code required to parse. Obsfucate your client-side javascript. Block IPs of offending clients.
