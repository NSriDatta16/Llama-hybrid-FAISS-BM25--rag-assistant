[site]: datascience
[post_id]: 77258
[parent_id]: 25712
[tags]: 
I was thinking about this very question this week, and I had an idea. Forgive me if this is way off. Suppose an n dimensional dataset to be sorted into k clusters. If we have a 3 layer network: input layer: n neurons hidden layer: k neurons, softmax activation output layer: n neurons, linear activation If we use our dataset as both x and y (this is a typical autoencoder, yes?), and we use a loss function that minimizes the euclidean distance between the predicted and actual values, will we not end up with a layer that is trained to cluster? I would think that the output of the second layer would end up being the cluster that the data point belonged to. I would think that if we removed the input layer and instead added an input layer that was k dimensions and passed a one-hot value for each cluster to the predict function we'd get the centroids, and I would think that the error at convergence during training could be used for plotting a variance graph and finding an 'elbow' to determine the optimal number of clusters.
