[site]: datascience
[post_id]: 87671
[parent_id]: 87619
[tags]: 
The article [coursera] use properly the GRU so, these changes would be neccesary: Architecture: Use only one GRU layer having in front the Conv1D not Conv2D (super trivial). The input should be a fixed length 1D vector, (single row extracted from the 2D spectra at t0, vector of 5511 in the article). Then feed the vector from next row at t+1, then next row t+2 and so on in little sequential steps as spectra evolve in time over the very audio sample. They used 101 rows in article (referring to rows from spectra as "timesteps"). If learning starts and yield results can experiment with 2 GRU deep one, but start with one layer, RNN are much harder to train in deep/stacked form. RNNs are also hard to quantize and accelerate (sequential nature). Having them on hardware especially on edge low resource ones is difficult. Classic 2D CNN are better choice even for audio or other sequential data types.
