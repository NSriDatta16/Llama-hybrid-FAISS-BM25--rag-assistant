[site]: crossvalidated
[post_id]: 573568
[parent_id]: 
[tags]: 
Training loss goes back up but validation accuracy continues growing (XGBoost)

Using an XGBoost classifier model on a few hundred thousands rows with +/- 300 numerical features and 3,000 target classes, training with multi:softproba . Main settings for the classifier are as follow: xgb_settings = { 'max_depth': 12, 'n_estimators': 160, 'learning_rate': 0.1, 'reg_alpha': 0.1, 'colsample_bytree': 0.9, 'subsample': 0.95, 'grow_policy': 'lossguide', 'objective': 'multi:softproba', 'tree_method': 'gpu_hist', 'booster': 'gbtree', } At some point around iteration 80, the training loss stops decreasing are starts growing again, while the validation accuracy still improves to the end: I'm curious of why this happens and how to interpret it. It is tempting to let the training go further because the validation accuracy is improving, but is the training loss going up a problem here? Would it be a sign of overfitting or underfitting?
