[site]: datascience
[post_id]: 29275
[parent_id]: 
[tags]: 
Suitable Autoencoder for Activity Recognition dataset Feature Extraction

I have text data representing sensor outputs. Dataset : 1458996986002; 11.43,-15.86,11.20,508.26; -1.59,-0.22,6.17,40.68; 126.0,-150.9,-105.0,49671.81; Walk 1459002923002; 16.69,-12.68,13.96,634.65; -2.55,2.13,4.87,34.87; 126.0,-150.9,-105.0,49671.81; Walk timestamp; acc_x,acc_y,acc_z; gyro_x,gyro_y,gyro_z; magn_x,magn_y,magn_z; ActivityName My Goal : I would like to extract features from the text lines before feeding it into a Recurrent Neural Network (GRU/LSTM). So, my goal is automatic feature extraction . Those extracted features (encoder network) will be used before the neural network for an activity recognition task (classification). My Question : Which Autoencoder (denoising, variational, sparse) is suitable for such dataset? Or should I use RBM instead? After choosing a feature extraction method, how do I compare the output with input, since the input is not 0s and 1s? What I have read : I read that RBM is generative model, which, even if you give some similar input, it can generate similar correct output. And training autoencoder is said(1) to be easier(2) than RBM. On the other hand, variational autoencoder can do something similar ( generative ). First question would be is having generative ability has any advantage for above problem, because at the end of pretraining i would just use encoder part and throw decoder layers ? If no, denoising autoencoder seems right approach I'm my opinion. Last thing: I know to force network to learn important features from data (instead of memorizing), you can choose following methods: 1) use sandwich like layers , 2) add noise to input 3) regularize autoencoder =make only some nodes active at the same time
