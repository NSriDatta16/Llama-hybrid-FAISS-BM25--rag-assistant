[site]: datascience
[post_id]: 80938
[parent_id]: 
[tags]: 
Do I need to square a column if I want a neural network to try using that?

In the classical linear regression implementation, if I suspect the square of the values of the column is correlated to the target, then I actually need to create a new column with the squares for the algorithm to make use of that. Is this also necessary when using neural networks? I know it's a broad question - are there cases where this is necessary and cases where it isn't?
