[site]: datascience
[post_id]: 116010
[parent_id]: 107389
[tags]: 
One solution that should work for most use cases, datasets, and models -- train a model on the data and use the predicted probabilities to obtain a notion of what's normal and what's not normal for all classes. While other answers have mentioned that there is no hard-fast rule to determine what is an outlier, the benefit of this approach is that you can obtain a outlier likelihood score for every example. Then you just choose the cutoff threshold that works for you based on inspection. A free open-source python package that will do this for you (for any model and any classification dataset as well as unlabeled data) is cleanlab: https://github.com/cleanlab/cleanlab . I am an author on the package (I created it in grad school. Raised funds to hire a team of 10 folks who add new algorithms to it regularly, including for outlier detection). Outlier detection using feature embeddings from cleanlab.outlier import OutOfDistribution ood = OutOfDistribution() # To get outlier scores for train_data using feature matrix train_feature_embeddings ood_train_feature_scores = ood.fit_score(features=train_feature_embeddings) # To get outlier scores for additional test_data using feature matrix test_feature_embeddings ood_test_feature_scores = ood.score(features=test_feature_embeddings) Outlier detection using predicted probs from a model from cleanlab.outlier import OutOfDistribution ood = OutOfDistribution() # To get outlier scores for train_data using predicted class probabilities (from a trained classifier) and given class labels ood_train_predictions_scores = ood.fit_score(pred_probs=train_pred_probs, labels=labels) # To get outlier scores for additional test_data using predicted class probabilities ood_test_predictions_scores = ood.score(pred_probs=test_pred_probs) Tutorial for outlier detection: https://docs.cleanlab.ai/stable/tutorials/outliers.html ICML Workshop Paper: https://arxiv.org/abs/2207.03061
