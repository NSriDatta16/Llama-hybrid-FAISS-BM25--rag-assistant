[site]: crossvalidated
[post_id]: 229393
[parent_id]: 229354
[tags]: 
The answer to this depends on the field you're in. If you're a mathematician, then all norms in finite dimensions are equivalent : for any two norms $\|\cdot\|_a$ and $\|\cdot\|_b$, there exist constants $C_1,C_2$, which depend only on dimension (and a,b) such that: $$C_1\|x\|_b\leq \|x\|_a\leq C_2\|x\|_b.$$ This implies that norms in finite dimensions are quite boring and there is essentially no difference between them except in how they scale. This usually means that you can choose the most convenient norm for the problem you're trying to solve . Usually you want to answer questions like "is this operator or procedure bounded" or "does this numerical process converge." With boundedness, you only usually care that something is finite. With convergence, by sacrificing the rate at which you have convergence, you can opt to use a more convenient norm. For example, in numerical linear algebra, the Frobenius norm is sometimes preferred because it's a lot easier to calculate than the euclidean norm, and also that it naturally connects with a wider class of Hilbert Schmidt operators . Also, like the Euclidean norm, it's submultiplictive: $\|AB\|_F\leq \|A\|_F\|B\|_F$, unlike say, the max norm, so it allows you to easily talk about operator multiplication in whatever space you're working in. People tend to really like both the $p=2$ norm and the Frobenius norm because they have natural relations to both the eigenvalues and singular values of matrices, along with being submultiplictive. For practical purposes, the differences between norms become more pronounced because we live in a world of dimensions and it usually matters how big a certain quantity is, and how it's measured. Those constants $C_1,C_2$ above are not exactly tight, so it becomes important just how much more or less a certain norm $\|x\|_a$ is compared to $\|x\|_b$.
