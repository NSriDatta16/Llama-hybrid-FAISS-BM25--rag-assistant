[site]: datascience
[post_id]: 82877
[parent_id]: 82553
[tags]: 
So far I have tried a few things that have helped a lot: First, embarassingly I was inputting images in BGR format to a network trained on RGB format. Second, trying the optimizer: optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, ResnetRPN.parameters()), lr=0.001, momentum=0.9, weight_decay=0.0005) Perhaps the Adam optimizer is not good for convolutional neural networks ?? as in the original paper, in addition to a learning rate scheduler that after 24 epochs decreases the learning rate to 0.0001. As for which layers to freeze, I am going to try pretty much everything including: only training the RPN heads freezing 1 layer and no longer removing any of the Resnet101 sequential blocks training the entire thing from scratch without pre-trained weights training the entire thing from scratch with pre-trained weights Moreover, the normalization of the input images was tuned for the Imagenet dataset, which has different channel means and standard deviations than the Pascal VOC 2012 dataset. Further, to test just the RPN I have written a class of 4 comparison RPNS which generate random boxes: random boxes in the image of any width, height, centre position random boxes from each of the four image quadrants of random width and height from an array dimensions = [4, 16, 32, 64, 128, 256, 512] random anchor boxes without learned displacements as in the anchor boxes used in Faster RCNN Finding the mean and (std) of the x_min, y_min and width, and height of bounding boxes in the Pascal VOC 2012 training set, and randomly sampling from a normal distribution of each of these values (and using math.floor, math.ceil to make them valid boxes) My network is at the very least outperforming the ROIS performed by these comparison RPNs, which I am measuring by computing the max IOU for each box per image with the 300 ROIS generated per image by the RPNS. I am also going to train my network on MS COCO 2014 train_val data. I hope this info helps someone.
