[site]: crossvalidated
[post_id]: 406042
[parent_id]: 239209
[tags]: 
Yes it does. Here you can find example of network that uses multiplication, among other methods, for combining embeddings. As described in my answer element-wise product $u*v$ , is basically an interaction term, this can catch similarities between values (big * big = bigger; small * small = smaller), or the discrepancies (negative * positive = negative) (see example here ). So it is perfectly reasonable way of combining weights, but often, as in above example, people use in parallel several different methods for combining them, to produce different kind of features for the model.
