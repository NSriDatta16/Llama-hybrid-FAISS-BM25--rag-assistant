[site]: crossvalidated
[post_id]: 581227
[parent_id]: 
[tags]: 
Formal conditions on classes of mappings $f$, as in $y=f(x)$, that can NOT be inferred from $\{x,y\}$ data

A large class of machine learning problems are posed as regression/inference problems trying solve for the mapping $f: X \rightarrow Y$ , with $y \in Y \subset \mathbb{R}^n$ and $x \in X \subset \mathbb{R}^m$ , from finite subsets : $\hat{X}=\{x_1,x_2,...,x_T\} \subset X$ and $ \hat{Y}=\{y_1,y_2,...,y_T\} \subset Y$ While there is much discussion on how to compute $f$ from $\hat{X}$ and $\hat{Y}$ , I have not been able to find much theory discussing mathematical structure of the spaces $X$ and $Y$ , aside from the trivial case of linear subspaces, as related to computability of the mapping $f$ . Are there certain mappings that are not computable from $\hat{X}$ and $\hat{Y}$ , and ultimately, why? With that said, my question here is the following: Are there formal conditions on classes of $f$ to indicate that it can NOT be inferred/learned from the finite subsets $\hat{X}$ and $ \hat{Y}$ , regardless of the size, $T$ , or the choice of the subsets? Posed slightly differently, in terms of $X$ and $Y$ , are there topological properties of $X$ and $Y$ that would influence recovery of $f$ from $\hat{X}$ and $ \hat{Y}$ ? Thanks much in advance.
