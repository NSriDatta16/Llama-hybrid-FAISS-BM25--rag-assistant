[site]: crossvalidated
[post_id]: 279316
[parent_id]: 278440
[tags]: 
The predictions usually depend on your model. Decision trees in general yield quite "calibrated" outputs which can nearly be interpreted as a probability. Some like SVM for example, don't. But this also highly depends on over-fitting/under-fitting. Or on the number of features (no, it does not have to be "better" necessarily). Actually, if this is one class, the first one probably over-fitted. But first things first: where is your other class? As your doing predictions, you should always plot both classes (with different colours). From the predictions of one class, you cannot say too much. If you want to measure the performance and to make conclusions about how much is learned from the features, use a score like ROC AUC where the order of events matters and not the distribution. If you intend to work with distributions, you may have a look at probability calibration methods (or read which classifiers yield good calibrations anyway). They are not perfect but aim at transforming the predictions into probabilities (and therefore give a meaning to the output).
