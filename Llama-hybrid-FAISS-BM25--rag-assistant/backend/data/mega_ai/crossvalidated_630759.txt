[site]: crossvalidated
[post_id]: 630759
[parent_id]: 630733
[tags]: 
Without caring about too much rigor, a heuristic calculation can go as follows (suppose $k \geq 0$ ): \begin{align*} & \gamma_k = \operatorname{Cov}(Y_t, Y_{t - k}) = E((Y_t - \mu)(Y_{t - k} - \mu)) \\ =& E\left[\sum_{m = 0}^\infty \omega_me_{t - m} \times \sum_{n = 0}^\infty \omega_ne_{t - k - n}\right] \\ =& \sum_{m = 0}^\infty\sum_{n = 0}^\infty \omega_m\omega_nE[e_{t - m}e_{t - k - n}] \\ =& \sigma_e^2\sum_{m = k}^\infty \omega_m\omega_{m - k} \tag{1}\label{1} \\ =& \sigma_e^2\sum_{j = 0}^\infty \omega_j\omega_{j + k}. \tag{2}\label{2} \end{align*} In $\eqref{1}$ , we used the condition $\{e_t\} \sim WN(0, \sigma_e^2)$ so that $E[e_ie_j] = \delta_{ij}\sigma_e^2$ , that is, $E[e_{t - m}e_{t - k - n}]$ is non-zero if and only if $t - m = t - k - n$ , hence the double-sum can be reduced to a single-sum. For a more formal proof that deals with the interchanging of infinite sum and the expectation operator (note that we need to impose conditions on coefficients $\{\omega_k\}$ in order $\eqref{2}$ holds, typically this condition is called absolutely summable , i.e., $\sum_{k = 0}^\infty |\omega_k| ), refer to Proposition 3.1.2 and Theorem 3.2.1 in Time Series: Theory and Methods (2nd edition) by P. J. Brockwell and R. A. Davis.
