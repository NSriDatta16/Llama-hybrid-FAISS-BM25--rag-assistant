[site]: crossvalidated
[post_id]: 641708
[parent_id]: 
[tags]: 
Is this a correct way of resampling the MCMC chain?

Please understand I am not familiar to the statistical languages. All I want is to resample a probability distribution from an existing sample drawn from another distribution using MCMC, without postponing my dissertation by a year or two. Suppose I have sampled a series of vectors, $\{\vec{x}_i\}_{i=1}^{N}$ , that follows a certain probability distribution $p_x(\vec{x})$ using MCMC ( samp1 in the code). Now, I have a new parameter, $y$ , and new probability distribution, $p_y(y|\vec{x})$ , making the posterior $p(\vec{x}, y) = p_x(\vec{x}) \cdot p_y(y|\vec{x})$ . The problem I have is that calculating $p_x(\vec{x})$ is extremely expensive that running another MCMC is outright impossible. However, I do have a chain long enough to mimic the distribution. I simplified this problem into 1-D setup without $y$ but instead of just updating the probability. First thing that came across my mind is a rejection sampling . While it produces a chain closely mimic the desired distribution ( samp2 in the code), this is rather inefficient since the rejection rate is quite high. I can tinker the proposal function a bit to make it more efficient, although I am not sure how much better I can do. Alternatively, I harassed a couple LLMs (poor ChatGPT and Gemini) to do this stuff, and they proposed me to use np.random.choice function ( samp3 in the code). Basically, it weights $\{\vec{x}_{i}\}$ based on the probability that would be used for rejection test, normalize them, and then they choose which of $\vec{x}_i$ to be drawn based on that weight. This seems to be working great, and fast , but I am not sure if this is correct or how this should work. Can someone please provide insights on this? Is this correct? Is this equivalent to rejection sampling? What is it called and how do I describe this? Lastly, can I have a reference regarding this? import numpy as np def normal_dist_pdf(x, mu, sig): return (1/(np.sqrt(2*np.pi)*sig))*np.exp(-0.5*((x-mu)/sig)**2) # p(x): mu=0, sig=3 # q(x): mu=3, sig=2 mu1, sig1 = 0, 2 mu2, sig2 = 3, 2 nsamp1 = 10000 nsamp2 = 1000 samp1 = mu1+sig1*np.random.randn(nsamp1) # Rejection Sampling (Inefficient...) samp2 = np.empty(nsamp2, dtype=float) isamp2 = 0 rej_scale = 1/np.max(normal_dist_pdf(samp1, mu2, sig2)/normal_dist_pdf(samp1, mu1, sig1)) while isamp2
