[site]: crossvalidated
[post_id]: 500344
[parent_id]: 
[tags]: 
how does the posterior predictive distribution account for differences in uncertainty?

Recent research in the field of bayesian deep learning allows for the quantification of uncertainty in estimates of ML models. This can be done because the posterior predictive distribution of the model can be computed. Bayesian methods allow us to be more uncertain over regions where the model has not seen data. The example below illustrates this point. Picture is taken from A bayes by backprop implementation of a neural network The distribution for $y^*$ given each $x^*$ (denoted by the coloured regions) is obtained by averaging the distribution $p(y^*|x^*,\theta)$ over empirical $\theta$ values sampled from the posterior over model weights. The posterior predictive distribution is computed as $$p(y^*|x^*) = \int p(y^*|x^*,\theta)p(\theta|X)d\theta$$ My question is how does the equation for posterior predictive result in a wider distribution for samples in which the model has not "seen"(Eg. $x$ values that are $>$ 4 and values that are $ -4) as compared to samples that are within the range of $-2 ? The current intuition I have on why uncertainty estimates are larger at regions in which the model has not seen the data is because the posterior weight distributions will lie in a region that can try to best explain how data "fed into" the model was generated. The likelihood for samples which are not seen by the model is very low under the posterior weights. When the posterior weights are sampled and the distribution of $y^*$ plotted under the different weights, I do not know why the variance is large for these "unseen" data. Hope my question is clear.
