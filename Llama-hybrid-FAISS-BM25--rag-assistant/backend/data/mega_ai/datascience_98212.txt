[site]: datascience
[post_id]: 98212
[parent_id]: 
[tags]: 
How to interpret .get_booster().get_score(importance_type='weight') for XGBRegressor()

I am trying to do feature selection using XGRegressor(). I am doing this because I have many features to choose from over 4,000. Once I have a set of features I have a neural network I created to use these features to predict median_gross_rent. My question is the following, I have these feature important scores from feature_important = model.get_booster().get_score(importance_type='weight') keys = list(feature_important.keys()) values = list(feature_important.values()) feat_imp_df = pd.DataFrame(data=values, index=keys, columns=["score"]).sort_values(by = "score", ascending=False) Is there a threshold score that I should set to make a cutoff? What are the best practices for feature selection in determining out of large amount of features to use? Thanks!
