[site]: datascience
[post_id]: 117589
[parent_id]: 117573
[tags]: 
I think about the distinction in these terms. Suppose we already have the data stored in a database and want to train a good ML model on it. This involves three steps: move data to the right computers where the model will be trained (Data Engineering) format data in the right way such that model could be trained on it (Data Preprocessing) try various transformations of data values that allow us to train the best model, without altering the model's hyperparameters or training algorithm (Feature Engineering). Step 1 can get complex when the dataset is massive or streaming in real-time, and involves lots of infrastructure work and data pipelining. Step 2 (Data Preprocessing) refers to basic steps that need to be taken to even get the data in a format that is compatible input to our ML model (eg. vector for a feedforward neural net). In Step 3 (Feature Engineering), one applies transformations to the data values (rescaling numerical values, creating interaction terms, encoding categorical/text features, etc), trying to find the best new representation of the data that when input to our model allows the model to be easily trained to high accuracy. Some call this process ELT (Extract, Load, Transform) or ETL. But in this space it is usually assumed the optimal feature transformations to get best model are already known, and the goal is to execute Steps 1-3 as efficiently as possible within a single pipeline to quickly go from raw data to well-trained model.
