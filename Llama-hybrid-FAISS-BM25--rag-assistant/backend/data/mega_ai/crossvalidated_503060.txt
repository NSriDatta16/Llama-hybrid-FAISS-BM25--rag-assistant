[site]: crossvalidated
[post_id]: 503060
[parent_id]: 502896
[tags]: 
In general, if you don't have a dataset that contains those 7 classes, you wouldn't be able to get a neural network which performs your task of semantic segmentation. My understanding of your question is the following: you own a dataset, each image labelled with a single class label you are able to train a CNN or similar structure with these images you want that neural network to perform semantic segmentation for you at inference This task seems to be a "zero-shot learning task" for image segmentation trying to leverage related image filters for the task. You could try training a neural network for your classification task and then replacing the last layers with randomly initialised layers to provide the segmentation. However, that would hardly provide any useful performance for you. Most likely, an already trained image segmentation model would be the best way to proceed in your case. The main problem is that you have in my opinion is that you won't be able to get away with segmenting at least part of the masks if you have completely novel segmentation classes, otherwise you won't be able to claim what method works for your dataset in a quantitative way. If you really have to do the problem zero shot, I would try to look at zero shot segmentation papers. For example, this work might be interesting for your case. In their work, they exploit relations between semantic word embeddings to alleviate annotation needs where generalisation to new classes are required.
