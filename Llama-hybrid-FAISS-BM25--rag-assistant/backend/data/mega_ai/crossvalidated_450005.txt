[site]: crossvalidated
[post_id]: 450005
[parent_id]: 
[tags]: 
Is it bad if the train score is much higher thanthe test score?

I'm doing a binary classification problem and using accuracy as my metric (I know that's not always advisable but, for now, it makes sense here). I trained a random forest classifier with grid search on the training set and then took the model with the best parameters and applied it to the test data. The results I got are: Training data: accuracy is 93.28% Testing data: 82.44% I know that this means that, on further unseen data, I should expect an accuracy of about 82.44% (under assumptions relating to the data coming from the same sample). My question is this: is it bad that the model is so over-fit? Is this something I should try to avoid? Or, if I'm happy with an 82% accuracy, can I just accept this?
