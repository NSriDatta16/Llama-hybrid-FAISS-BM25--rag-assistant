[site]: datascience
[post_id]: 63894
[parent_id]: 63880
[tags]: 
That's because using NN for chatbots have proven super challenging. Basically once you type a query the NN (whether its NN or RL) has to tag it to a particular intent based on which u give a templatized response ( generating a human like response goes into even more complex territory of natural language generation) The issue with NN like LSTM , GRU etc is that they don't understand "turns" in a conversation. So if u type in a query one after the other the bot will treat them as separate sentences and try and tag them individually. But a human would form a context based on the whole conversation and can handle turns. There's some labelled data for a few verticals that shows turns in the conversation but it's just not enough Coming to RL , it seems like a good fit for handling conversation since the current state (sentence) totally depends on the prior state. But what kind of reward function do you have in mind ? How, based on the action of the agent, will the network learn a policy to identify a "conversation"? When will u stop the episode ? When a conversation ends ? Or a fixed number? Me thinks these are still hard problems to solve since convergence is a challenge in such use cases If someone has cracked it, they most likely will not publish anything since a true researcher will only publish stuff that is reproducible or they are just being secretive :)
