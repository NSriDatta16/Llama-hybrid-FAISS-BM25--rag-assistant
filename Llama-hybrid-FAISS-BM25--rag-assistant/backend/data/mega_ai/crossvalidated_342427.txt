[site]: crossvalidated
[post_id]: 342427
[parent_id]: 342287
[tags]: 
Unfortunately not. We often have to use multiple restarts if we are using convex optimisation and even then you often find poor hyper parameters. One direction people have gone done is to use Monte Carlo based optimisation and this seems to work ok but the cost of evaluating the log likelihood / it's gradient isn't exactly cheep. There was a bit of a push to use Bayesian optimisation to solve this and the die hard GP crowd are a big fan of being fully Bayesian using Bayesian quadrature to marginalise over hyperparameters. However these both essentially aim to use GPs to solve the problems of GPs and there is sense of inception going on!
