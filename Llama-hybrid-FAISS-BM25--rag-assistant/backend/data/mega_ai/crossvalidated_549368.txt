[site]: crossvalidated
[post_id]: 549368
[parent_id]: 
[tags]: 
When using cross validation, I have similar results for accuracy on each fold. Is this ok?

I am doing a classification problem where I need to do 10-Fold Cross validation. At the end, I obtain accuracy results for 6 different models: KNN, SVM, Decision Tree, Random Forest, Multilayer Perceptron, and Gradient Boosting Ensemble. My issue is that for each fold, for each model the accuracies are all very similar. For example, for KNN I have the following accuracies, over 10 folds: [0.8824006488240065, 0.8994322789943228, 0.8896999188969992, 0.8807785888077859, 0.8848337388483374, 0.8953771289537713, 0.8872668288726683, 0.8969991889699919, 0.8888888888888888, 0.8832116788321168] Is the similarity in accuracies a normal result? My TA said they should be more different.
