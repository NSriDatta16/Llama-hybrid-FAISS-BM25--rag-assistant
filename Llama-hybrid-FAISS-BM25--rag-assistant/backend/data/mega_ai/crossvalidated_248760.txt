[site]: crossvalidated
[post_id]: 248760
[parent_id]: 
[tags]: 
Understanding RNN/LSTM

I am trying to understand how to use RNN/LSTM; but I cannot understand some concepts related to topology. I found really useful information in this article: http://colah.github.io/posts/2015-08-Understanding-LSTMs/ . But then, when comparing that topology 1 to the one Alex Graves says in his LSTM writing 2 , and the one described here 3 , we can see the differences (in the first one the inputs never go to previous states, whereas they do in the other two topologies). What is going on? Thank you
