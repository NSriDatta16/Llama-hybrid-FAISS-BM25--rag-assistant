[site]: crossvalidated
[post_id]: 508661
[parent_id]: 508658
[tags]: 
The conditions you quote are for training : SVM attempts to find $w$ and $b$ such that $$ y_i (w \cdot x_i + b) \ge 1 $$ where $y_i \in \{-1, 1\}$ . However, this can only succeed if the classes are linearly separable. If not, as your case suggests, you need a soft margin SVM, by introducing slack variables: $$ y_i (w \cdot x_i + b) \ge 1 - \xi_i $$ For classification, the result is simply compared to 0: If $w \cdot x_i + b > 0$ , classify $x_i$ to class " $+1$ ", and otherwise to " $-1$ ".
