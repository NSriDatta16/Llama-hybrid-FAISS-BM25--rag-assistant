[site]: crossvalidated
[post_id]: 468227
[parent_id]: 
[tags]: 
Bayesian inference with false models: to what does it converge?

This is the second follow up question from these two previous questions: Bayesian inference and testable implications How do I perform an actual "posterior predictive check" in this model? Consider again the model of the previous question, which I will repeat here for clarity. $$ \text{Likelihood:}\\ \\ y \sim \mathcal{N}(\mu_1, \sigma_1)\\ x \sim \mathcal{N}(\mu_2, \sigma_2)\\[2em] \text{Prior:}\\ \begin{aligned} \mu_1 &\sim \mathcal{N}(0, 1000)\\ a &\sim \mathcal{U}(0,2)\\ \mu_2 &\leftarrow \mu_1 + a\\ \sigma_1 &\sim \mathcal{U}(0, 100)\\ \sigma_2 &\sim \mathcal{U}(0, 100) \end{aligned} $$ Where $\mathcal{N}()$ denotes a gaussian and $\mathcal{U}()$ denotes a uniform distribution. Here is the implementation in rjags: library(rjags) model Now let's consider we have infinite data from a data generating process that cannot be captured by this model . Below I show such an example in R (here "infinite" of course is approximated by a large sample and low standard deviation). n Compiling model graph #> Resolving undeclared variables #> Allocating nodes #> Graph information: #> Observed stochastic nodes: 2000 #> Unobserved stochastic nodes: 4 #> Total graph size: 2012 #> #> Initializing model samp $mu1) #> Min. 1st Qu. Median Mean 3rd Qu. Max. #> 7.988 7.999 8.002 8.003 8.006 8.048 summary(post$ mu2) #> Min. 1st Qu. Median Mean 3rd Qu. Max. #> 9.986 9.995 9.997 9.997 9.999 10.009 Now note that the posterior does not converge to the true values of 2 and 10 as expected, since the model cannot capture a difference of more than 2 units apart. But, specifically, the model "converges" to something: $\mu_1 = 8$ and $\mu_2 = 10$ . If you run a different chain, it "converges" to $\mu_1 = 2$ and $\mu_2 = 4$ . What characterizes these solutions? What should be the theoretical posterior distribution in this case? Are these the only peaks, so it should converge to a 50% point mass in both? What characterizes the solutions in this case? More generally, when the true DGP cannot be captured by your bayesian model (in practice, almost always), what characterizes the solutions it eventually converges to?
