[site]: crossvalidated
[post_id]: 623301
[parent_id]: 
[tags]: 
Why can Variational Autoencoders (VAEs) approximate arbitrary distributions?

I am trying to reason to myself why is it that VAEs can approximate arbitrary probability distributions even though $q_{\phi}(z|x)$ and $p_{\theta}(x|z)$ are Gaussian. I understand that the parameters are typically learned using neural networks $\phi = f_{w}(x)$ and $\theta = g_{w}(z)$ , where $f$ and $g$ denote arbitrary neural networks. Therefore, some ideas I had is perhaps the entire VAE is able to learn differentiable, change of variables mappings, which allows the VAE to ensure that, although $\phi$ and $\theta$ both characterize Gaussian distributions, they do so using some transformation of the original variables $x$ and/or $z$ and so effectively correspond to some arbitrary distribution rather than a Gaussian in $x$ or $z$ . However, and I may just be unnecessarily picky here, but I can't quite convince myself why the Gaussian PDF itself, even with the change of variables mapping, will not act as a "bottleneck" in learning some rather complex non-Gaussian distributions. I was wondering if there is some universal approximation theorem in the case of VAEs, as there in feed-forward neural networks / RNNs etc. If anyone could explain this, I would greatly appreciate it, thanks.
