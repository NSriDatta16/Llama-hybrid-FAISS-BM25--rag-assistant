[site]: crossvalidated
[post_id]: 398853
[parent_id]: 398646
[tags]: 
For me, the most important part was: ...[We] urge authors to discuss the point estimate, even when they have a large P value or a wide interval, as well as discussing the limits of that interval. In other words: Place a higher emphasis on discussing estimates (center and confidence interval), and a lower emphasis on "Null-hypothesis testing". How does this work in practice? A lot of research boils down to measuring effect sizes, for example "We measured a risk ratio of 1.20, with a 95% C.I. ranging from 0.97 to 1.33". This is a suitable summary of a study. You can immediately see the most probable effect size and the uncertainty of the measurement. Using this summary, you can quickly compare this study to other studies like it, and ideally you can combine all the findings in a weighted average. Unfortunately, such studies are often summarized as "We did not find a statiscally significant increase of the risk ratio". This is a valid conclusion of the study above. But it is not a suitable summary of the study, because you can't easily compare studies using these kinds of summaries. You don't know which study had the most precise measurement, and you can't intuit what the finding of a meta-study might be. And you don't immediately spot when studies claim "non-significant risk ratio increase" by having confidence intervals that are so large you can hide an elephant in them.
