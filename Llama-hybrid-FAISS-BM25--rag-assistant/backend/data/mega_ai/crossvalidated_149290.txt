[site]: crossvalidated
[post_id]: 149290
[parent_id]: 
[tags]: 
Binary logistic regression with only positive training examples - does that even make sense?

(I have learned about polynomial linear regression, logistic regression, and neural networks.) I have a binary logistic regression problem. I need to classify things to be true or false. What makes this hard for me to understand is that I only have y=1 training examples. Is it possible to get a decision boundary for this data set? I simplified the problem by only thinking about 2 of my features. I experimented a little bit by placing fake y=0 training examples everywhere. Gradient descent with the real and fake training sets seems to fit the data ok. It is a bit underfit, taking into account that this is a degree 6 curve and regularization is turned off. There has to be a better way to approach this problem. Heck, I could even calculate the convex hull! (Not sure how well that will work in 15+ dimensions.) Any advice?
