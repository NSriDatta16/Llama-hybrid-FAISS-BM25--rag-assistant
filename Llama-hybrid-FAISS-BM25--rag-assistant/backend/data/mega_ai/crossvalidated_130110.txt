[site]: crossvalidated
[post_id]: 130110
[parent_id]: 
[tags]: 
Maximize log-likelihood of logistic regression

I'm trying to understand the derivation of the equations for the logistic regression. I'm following the cs229 notes: http://cs229.stanford.edu/notes/cs229-notes1.pdf At some point in the derivation, in the notes we need to maximize the log-likelihood of the parameters: ℓ(θ) = log L(θ) = y log h(x) + (1 - y) log(1-h(x)) In the notes, after the derivation we get: $\frac{\partial}{\partial \theta_j}$ = (y $\frac 1 {h(x)}$ - (1 - y) $\frac 1 {1 - h(x)}$ ) $\frac{\partial}{\partial \theta_j}$ h(x) Shouldn't this be: $\frac{\partial}{\partial \theta_j}$ = (y $\frac 1 {h(x)}$ + (1 - y) $\frac 1 {1 - h(x)}$ ) $\frac{\partial}{\partial \theta_j}$ h(x) I've been looking at this for a while and I can't see where this minus sign is coming from... Thanks for your help!
