[site]: crossvalidated
[post_id]: 20402
[parent_id]: 
[tags]: 
Logical extensions after logistic regression

I have a number of predictors to use for a binary (Classes 0 and 1) classification task. Let us call them $x_1, x_2, x_3, ... x_n$. The way these are calculated, my naive heuristic assumption is that $S = \sum_{k=1}^n x_k$ should predict Class 1. That is higher $S$ means it is more likely that it is Class 1. Since this did not perform as well as I had hoped, I want to show that my scores $x_k$ can collectively achieve a better performance, than, say some other baseline methods and even my own single scores such as $x_1$. Due to the way I justify my calculations of $x_k$, I do not want to use a black-box technicque such as SVM or Random Forest. More concretely, if I use a very complex model, there is a greater burden on me to prove that I am not over-fitting or just getting as lucky as any other combination of various predictors used in the field. I first tried to use logistic regression and its performance was not very spectacular. I then proceeded to use MARS models, and I got much better classification performance (using Precision-Recall and ROC curves). But scientifically, I am not sure I can simply justify using MARS models and comparing it to logistic regression. So I want to know which models are the logical extensions to use after logistic regression to add a little more complexity. I have thought of splines, MARS, additive models, adding binary interactions $x_i x_j$ as inputs to the logistic regression. I have planned to use PR and ROC curves on cross-validation data sets to do the comparisons. For logistic regression, one can use model likelihood as a measure but are there any other measures to use across models such as these?
