[site]: datascience
[post_id]: 28495
[parent_id]: 22335
[tags]: 
Machine Learning can be rightly considered Black boxes, solutions for the XOR problem using neural networks can be modelled but as the number of inputs grow, so does the complexity and dimensions. If it is too complex to understand and explain, then it is a black box, whether or not we can calculate the results or not We can only perceive them upto 3 dimensions but this is sufficient because we can extrapolate this upto higher dimensions using the 3d model as a point of reference. We can imagine local minimums, as well as parts of datasets that are partially learnt. I have toyed with the idea for a while and so I produced animations of neural networks at work and improved my understanding of neural networks. I have produced animations with 1 and 2 hidden layers (3rd is mostly done) and how they learn data. The animation is slow and the top right animation showing the upper layers is worth watching, you can speed the animations on Youtube if you like, significant changes can be seen on the top right animation with the Blue and Red Mesh at 3:20 Orange and Red mesh at 6 mins and the Blue, Orange and Red mesh at 8:20. The directions of the weight changes are obviously in the bottom left animation https://www.youtube.com/watch?v=UhQJbFDtcoc
