[site]: crossvalidated
[post_id]: 457241
[parent_id]: 
[tags]: 
What is the dimensionality of the cost function with this specific ANN structure?

I have the following ANN architecture, the neuron is a sigmoid neuron: Where the weight and parameter matricies are given by: $$ \begin{vmatrix} & x1& & x2& & x3& \end{vmatrix} \begin{vmatrix} & w1& & w2& & w3& \end{vmatrix} $$ My cost function for one training example is given as such, it is just MSE: $$ C(a,y)=(a-y)^2 $$ Where y is the actual output and a is defined below, $$ a=σ(w∙x) $$ I have two questions: What is the dimensionality of my cost function in this case? How does this calculation extend to N training examples, how are the weights updated through backprop in that scenario? Is the average of the gradient across all training examples taken and used to update the weights?
