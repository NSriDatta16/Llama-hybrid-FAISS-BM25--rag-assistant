[site]: datascience
[post_id]: 104917
[parent_id]: 
[tags]: 
What is The difference of xgboost.sklearn.XGBClassifier and xgboost.XGBClassifier?

xgboost.sklearn VS xgboost.XGBClassifier Here is my code that I tried to train make_moons datset from sklearn.datasets and see the difference of this to functions, but it made the same results: Data: from sklearn import datasets from sklearn import model_selection X, y = datasets.make_moons(n_samples=100000, noise=0.4, random_state=341) x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=431) Classifiers: xgb1 = xgboost.sklearn.XGBClassifier(max_depth=2) xgb2 = xgboost.XGBClassifier(max_depth=2) Train Part: xgb1.fit(x_train, y_train) xgb2.fit(x_train, y_train) Test Part: print(xgb1.score(x_test, y_test)) print(xgb2.score(x_test, y_test)) Results: xgb1: 0.8626 xgb2: 0.8626 As you can see, The Results are the same so, why there are two different ways of them to approach? If they are different, can you explain what is the difference? And which is more preferable to use? My Problem isn't about classifier itself, it is about only xgboost.sklearn , I want to know may I use only xgboost or xgboost.sklearn ? And why?
