[site]: crossvalidated
[post_id]: 383380
[parent_id]: 
[tags]: 
How to test whether E[X]>E[Y] controlling for Z?

Question in mathematical terms. Assume an observation consists of three continuous variables $X$ , $Y$ and $Z$ . The sample comprises a sufficiently large number of observations. I would like to check whether $[X]>[Y]$ , i.e. on average X being larger than Y. However, the added complication is that I am worried about confounder $Z$ and therefore would like to control for it. How could I approach this problem statistically? Problem explained using regression. Without an confounder $Z$ , I think one could test whether $[X]>[Y]$ by fitting the regression model $$Y_i=\beta_0+\beta_1X_i+\varepsilon_i$$ and checking whether $\beta_0$ is negative and significant. Just adding Z as control wouldn't work because it messes up the sign of $\beta_0$ . I guess mean-centering $Z$ doesn't help either, because $\beta_0$ would remain unchanged. Context of question is causal inference. In simple terms, I am facing the following problem. Participants are asked to choose a subset $S$ of items to maximise a certain complicated objective function. The optimal subset $S^*$ provided by a computer algorithm is also known. Each item has two properties; lets assume these here to be size and weight. I want to check whether the average size $X$ of items in the participants' subsets $S$ is lager than the average size $Y$ of items in the optimal subsets $S^*$ . However, I want to make a causal inference. The problem is that the size and the weight are positively correlated with each other. Let $Z$ be the average weight of the items in the participants' subsets $S$ . I want to say that the average size of items in the participants' subset $S$ is larger than the average size in the optimal subset $S^*$ BECAUSE participants look for larger items in terms of their size than optimal rather than look for heavier items when picking their subset $S$ . UPDATE: CONCLUSION. It seems to be untestable. The reason is that in many cases one could show both $[X]>[Y]$ and $[X] depending on how exactly one controls for Z (e.g. either picking a postive or negative coefficient, respectively), and there is no telling what is right. Obviously, a test which could produce contradictory results wouldnâ€™t be a credible statistical test.
