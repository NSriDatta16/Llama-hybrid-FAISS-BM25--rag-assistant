[site]: crossvalidated
[post_id]: 512155
[parent_id]: 
[tags]: 
Standard error of a hypothetical predicted value in logistic regression?

I'm not sure how to ask this question to Google, so I'm coming here. Learning (some) stats long ago, I was shown that once you've calculated your regression results and built a new model (in plain English: equation) with the coefficients as your betas, you could "predict" the value of the outcome for a hypothetical set of values for the inputs/covariates/independent variables. I recall being able to do this for all sorts of variations on regression, even logistic regression. My question is: while I'm pretty sure this works to get a number for an outcome, how can I (or can I?) get an estimate of the precision of such a "prediction"? Here's an example logistic regression result in Stata. I'm trying to model the log odds of being admitted to university ( admit ) as a linear combination of the predictors GRE (GRE test score), GPA (Grade point average), and rank (High school rank, factor variable, range: 1 - 4, with 1 being highly ranked). (Here's the source dataset: data ) Crudely, the regression model looks like this before analysis (dummy variables used for rank ): logit( admit ) = b0 + b1( GRE ) + b2( GPA ) + b3( rank=2 ) + b4( rank=3 ) + b5( rank=4 ) Here are the results: And here's the complete model: logit( admit ) = -3.989 + .00226( GRE ) + .804( GPA ) - .675( rank=2 ) - 1.34( rank=3 ) - 1.55( rank=4 ) All normal so far, I think. Now, say that I wanted to know what the log odds of getting admitted to college were for a student with a 650 GRE, a 3.24 GPA, and who went to a rank-1 high school. Plug and chug, right? logit( admit ) = -3.98+0.0022(650)+.804(3.24) = .05496 (Which in odds ratio form is exp(.05496) = 1.056 ) So: how precise is this estimate? Can I get a 95% CI for it somehow, or even an SE? Thanks!
