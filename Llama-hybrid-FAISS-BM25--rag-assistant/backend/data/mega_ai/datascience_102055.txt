[site]: datascience
[post_id]: 102055
[parent_id]: 
[tags]: 
What is the best way to flatten my data to be used by an SVM algorithm?

I am trying to classify data from an 8 channel SEMG sensor (different gestures) by using an SVM. So far, I have managed to record the data and for each channel, I've calculated 7 appropriate features, which I've placed into a 7x8 matrix. I've standardized all the calculated values using the formula (calculatedValue - mean)/standardDeviation I've then performed a PCA on said 7x8 standardized matrix to reduce the number of dimensions as to not put too much strain on the SVM classification algorithm**. Turns out I need only 2 dimensions for my application, hence I've obtained an 8x2 feature vector matrix. I've obtained my final data set by multiplying (dot product) the transpose of the feature vector matrix 8x2 and the transpose of the standardized 7x8 matrix. This resulted in me getting a 2x7 matrix that contains the data that is to be fed to the SVM algorithm. The problem is that SVM, as far as I uderstand it, is not capable of classifying multidimensional arrays (Ex: {{{a,b,c,d,e,f,g},{h,i,j,k,l,m,n}},{{...},{...}},...). Having described the nature of my method of obtaining the data: Is it safe to just flatten the data, such that {{a,b,c,d,e,f,g},{h,i,j,k,l,m,n}} becomes {a,b,c,d,e,f,g,h,i,j,k,l,m,n} and feed that into the SVM to train it and later to classify different gestures, or should I restrain form doing that and rather try something else because of some peculiar reason? ** I have adapted the PCA and SVM algorithms in C++ to run on a microcontroller, I do not intend on using a tabletop computer for the classification/training. My goal is to be able to run the entire process from data acquisition to classification on a microcontroller.
