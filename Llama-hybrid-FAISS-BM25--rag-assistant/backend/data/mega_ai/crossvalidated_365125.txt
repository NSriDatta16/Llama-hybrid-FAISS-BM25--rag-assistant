[site]: crossvalidated
[post_id]: 365125
[parent_id]: 
[tags]: 
What are some good canned classifiers for high-dimensional data with probablistic labels, besides neural nets?

I've got a classification problem where my labels are $N\times4$ matrices of probabilities of class membership, and I've got about 1800 covariates. The covariates are mostly granular, in the sense that an additively separable model (like a penalized multinomial logit) probably would work that well. I also haven't had much luck with using standard multinomial classifiers, after assigning each observation to the highest-probability class -- xgboost and random forest don't find much. A neural net is the obvious solution, but tuning the hyperparameters is a huge chore that I'd like to avoid if possible. Are there other good options that require less futzing time? For background, the class probabilities are all weights from a finite mixture model. I trained it and it fits really well, but I'm only just now realizing that I won't know the class weights for new data unless I know their outcomes! D'oh!
