[site]: datascience
[post_id]: 53351
[parent_id]: 
[tags]: 
Why the accuracy decreased with more data

When working with a random forest model, it is surprising that the cross-validation score on the training dataset is much higher than the score on the whole dataset. Here is the code: X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2) model = RandomForestClassifier(n_estimators=100) cv_score1 = cross_val_score(model, X_train, y_train, cv=3).mean() print('CV score for the training data is : {:.3f}'.format(cv_score1)) cv_score2 = cross_val_score(model, X, y, cv=3).mean() print('CV score for all data is : {:.3f}'.format(cv_score2)) The first score is 0.887 while the second score is 0.645. The trend is the same with a linear support vector machine model. Is this normal? Or I have done something wrong? How can I fix it? Thank you!
