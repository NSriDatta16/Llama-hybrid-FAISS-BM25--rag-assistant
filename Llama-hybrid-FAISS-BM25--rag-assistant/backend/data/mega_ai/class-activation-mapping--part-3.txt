onal layer and before the final linear classifier layer. This last element of the architecture connects the output logits (the network predictions) y C {\displaystyle y^{C}} , to the GAP values, with its respective fine-tuned weights, w k C {\displaystyle w_{k}^{C}} . Considering A k {\displaystyle A^{k}} as the last feature maps of the last convolutional layer, GAP produces one value for each feature map, by averaging all the matrix elements (i, j) of the feature map: F k = 1 m n ∑ i = 1 m ∑ j = 1 n A i j k {\displaystyle F^{k}={\frac {1}{mn}}\sum _{i=1}^{m}\sum _{j=1}^{n}A_{ij}^{k}} with A k = [ A 11 k A 12 k ⋯ A 1 n k A 21 k A 22 k ⋯ A 2 n k ⋮ ⋮ ⋱ ⋮ A m 1 k A m 2 k ⋯ A m n k ] = { A i j k ∣ 1 ≤ i ≤ m , 1 ≤ j ≤ n } {\displaystyle A^{k}={\begin{bmatrix}A_{11}^{k}&A_{12}^{k}&\cdots &A_{1n}^{k}\\A_{21}^{k}&A_{22}^{k}&\cdots &A_{2n}^{k}\\\vdots &\vdots &\ddots &\vdots \\A_{m1}^{k}&A_{m2}^{k}&\cdots &A_{mn}^{k}\end{bmatrix}}=\left\{A_{ij}^{k}\mid 1\leq i\leq m,\ 1\leq j\leq n\right\}} Namely, in the GAP layer, each feature map is reduced to a single scalar via GAP, producing k values, hence reducing the dimensionality of the network. A k × {\displaystyle \times } m × {\displaystyle \times } n tensor is reduced to k scalars, shrinking the parameter count for the linear classifier head. The final output logits are calculated as the linear sum of the GAP values, weights and bias: y C = ∑ k w k C F k {\displaystyle y^{C}=\sum _{k}w_{k}^{C}F^{k}} The localization map is computed as follows: L C A M C ( x , y ) = R e L U ( ∑ k w k C A k ( x , y ) ) {\displaystyle L_{CAM}^{C}(x,y)=ReLU(\sum _{k}w_{k}^{C}A_{k}(x,y))} namely, A k ( x , y ) {\displaystyle A_{k}(x,y)} is the activation of node k in the target layer of the model, and w k C {\displaystyle w_{k}^{C}} is the class-specific weight, for the channel k, in the linear classifier layer. Advantages and drawbacks The use of the GAP layer represents an example of an interpretability by design (IBD) approach. IBD refers to a technique which uses the model's own architecture to help explain its predictions. The main drawback of CAM is that it is highly model-specific, being applicable to CNN architectures whose layer before the softmax one is a GAP. Since the approach relies on the post-GAP weights for the overall evaluation, the method can't be applied to intermediate layers. The choice of dealing with an IBD approach restricts the possibility to generalize the model architecture. Moreover, IBD methods often require re-training of the model. Gradient-weighted class activation mapping (Grad-CAM) Gradient-weighted class activation mapping (Grad-CAM) is a generalized version of CAM and it tackles its architectural limitations. Grad-CAM computes the gradient of a target class score, the pre-softmax logit, with respect to the feature maps of a convolutional neural network. The gradients are global-average-pooled to obtain importance weights, which are used to compute a class-specific localization map by linearly weighting the feature maps. The result is a heatmap that highlights the regions in the input image that are the most influential for predicting the target class. The main advantage of Grad-CAM, with respect to the standard CAM, is that it is model agnostic (provided that the network still needs to be differentiable), meaning that it generates visual explanation for any CNN-based network without architectural changes or re-training, making it broadly applicable to pre-trained models. Mathematical description Considering: y C {\displaystyle ^{C}} the logits (i.e. the pre-softmax activated neurons responsible for a certain class prediction) of interest; A k {\displaystyle ^{k}} the feature activated map for a specific convolutional layer; L Grad-CAM C {\displaystyle _{\text{Grad-CAM}}^{C}} ∈ R u × v {\displaystyle \mathbb {R} ^{u\times v}} the class-discriminative localization map, of width u and height v for any class c; Grad-CAM, employing backpropagation, computes the logit gradient w