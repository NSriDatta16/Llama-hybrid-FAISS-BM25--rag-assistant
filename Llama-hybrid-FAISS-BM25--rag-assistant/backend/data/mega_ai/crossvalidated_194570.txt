[site]: crossvalidated
[post_id]: 194570
[parent_id]: 
[tags]: 
When is BIC reasonable approximation to evidence?

I've recently seen a few papers in physics using the Bayesian information criterion (BIC) to evaluate models. I'm much more familiar with Bayesian evidence, $p(x|M)$. I've read in a few places, e.g. Wikipedia , that $$ \text{BIC} \approx -2\cdot\ln p(x|M) $$ provided a few conditions are met. Wikipedia, however, is a bit confusing concerning the conditions, as it appears to offer a tautology: The BIC is an asymptotic result derived under the assumptions that the data distribution is in the exponential family. That is, the integral of the likelihood function $p(x|\theta,M)$ times the prior probability distribution $p(\theta|M)$ over the parameters $\theta$ of the model $M$ for fixed observed data $x$ is approximated as $$ {-2 \cdot \ln{p(x|M)}} \approx \mathrm{BIC} = {-2 \cdot \ln{\hat L} + k \cdot (\ln(n) - \ln(2 \pi))}. \ $$ I read this as saying the approximation holds if the approximation holds, as the approximation is that the evidence may be approximately written as a member of the exponential family (which is basically the approximation in question). My instinct is the BIC could only approximate the evidence in very special cases - after all, BIC cannot approximate arbitrary evidence integrals with arbitrary priors - and that BIC is probably misused in physics. What exactly are the conditions under which the BIC might approximate the evidence? It can't just be e.g. flat priors, because I could reparameterise any model such that priors were flat.
