[site]: crossvalidated
[post_id]: 518081
[parent_id]: 517961
[tags]: 
You could use a Bayesian machine learning model. The distribution of your predictions shows you how accurate the model is. If your model overfits it will have a large variance in the predictions, because every model of the ensemble overfits differently. When you have enough data the distribution is very narrow and when you have infinite data equals the prediction of the non Bayesian model. Every parameter of your model is now a distribution. Depending on the type of the model they can even be interpretable. One easy way to obtain a Bayesian model is via Bayesian bootstrapping. You can either do that by training the model multiple times with different weights for each data point or by using a package like bayesian_bootstrap . The weights must be drawn from a Direchlet distribution (which in this case is a multivariate uniform distribution).
