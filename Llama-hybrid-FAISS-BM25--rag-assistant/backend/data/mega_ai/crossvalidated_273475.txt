[site]: crossvalidated
[post_id]: 273475
[parent_id]: 
[tags]: 
Clarifying Berger et al. "A Maximum Entropy Approach to NLP"

Unfortunately, I do not know where else to turn to for clarifications that I require regarding the notations and definitions in the initial sections of the paper by Berger et al (1996). In Section 3.2, they say, "To express the event that in translates as en when April is the following word, we can introduce the indicator function $f(x,y) \overset{\mathrm{def}}{=}\, 1$ if $y = $ en and April follows in ; $f(x,y) \overset{\mathrm{def}}{=}\, 0$ otherwise. " Immediately afterwards, they start discussing the expected value of $f$. I don't get it. Isn't $f$ an indicator function? Why should we treat it like a random variable? I don't see any "randomness" in the values that $f$ returns (cf. definition above). Is there an intuition behind this random variable $f$ and its expected value? I feel that this is crucial to understanding the rest of the paper and would appreciate any help. Perhaps this has to do with my unfamiliarity with the general writing style in this field. Thanks in anticipation.
