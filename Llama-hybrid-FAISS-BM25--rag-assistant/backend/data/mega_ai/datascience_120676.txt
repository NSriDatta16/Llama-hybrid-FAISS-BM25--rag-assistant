[site]: datascience
[post_id]: 120676
[parent_id]: 117293
[tags]: 
I am also working on building a model to evaluate students' essays and I am trying to combine word embeddings from bert, bertweet and roberta. I am able to combine the cls tokens from these models. My question is on what encoding and attention masks, I will be fitting the final model as I have three sets of word encodings and attention masks. This is the model structure:-
