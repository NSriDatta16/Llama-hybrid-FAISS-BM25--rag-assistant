[site]: crossvalidated
[post_id]: 589764
[parent_id]: 577846
[tags]: 
Bias-variance trade-off is an old fashioned concept from classical statistics which fails to be useful in high-dimensional setting. Here's an example of famous statistician being surprised that overfitting is reduced by increasing the number of parameters in linear regression. A better way to explain good performance of neural networks is through the lens of statistical learning theory. One direction of work shows that if A) your learner is not very sensitive to small changes in your training set, and B) fits training data data it will also fit test data. See for instance, this paper by Bousquet. Hastie's paper shows that adding parameters restricts final solution to a smaller L2-norm ball, hence improving stability A). At the same time, adding parameters can improve training fit, hence improving B). B) is actually the harder part, much of modern progress in NN's has been achieved by coming up with clever ways of fitting the training data and ignoring generalization aspect.
