[site]: crossvalidated
[post_id]: 554571
[parent_id]: 
[tags]: 
Validation loss is significantly higher than train loss

I'm trying to train several models to solve an image regression problem. I'm using MSE as my loss function. Here's a couple of charts illustrating the training process: As you can see, on both charts validation loss is significantly higher than train loss. According to articles dedicated to deep learning aspects, this is a good sign of overfitting. But as far as I know, an overfitted model is a model that deals exceptionally well with train data, but fails on any unseen samples. In my case all predictions on train data are quite poor and unsatisfactory. I've carefully examined my data and concluded the following: There's no data leakage between train and validation sets Data distribution between sets is just fine (85% train, 15% validation) Number of samples in the dataset seem to be satisfactory (7500) I've tried the following measures to improve performance: Learning rate tuning with various tecniques (ReduceLROnPlateu, Scheduler) Changing initial weights Changin batch size
