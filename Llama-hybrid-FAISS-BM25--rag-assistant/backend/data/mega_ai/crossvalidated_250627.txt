[site]: crossvalidated
[post_id]: 250627
[parent_id]: 
[tags]: 
How does the activation of neurons work?

I would need to understand better how the activation of the neurons in a neural network works. Let's suppose to work with Tanh (ranging in [-1,1]). I know that a neuron must be able to choose whether to accept the input from another neuron or not. But how is this process related to the activation function? If the value of Tanh for a certain neuron is close to -1, is that neuron switched off or is it still actively involved in the training? (And if it is actively involved, then why do we talk of "activation"?) Also, I'm using h2o for deep learning anomaly detection. How do I choose between Tanh and Rectified Linear? I tried both and the outputs differ a lot...
