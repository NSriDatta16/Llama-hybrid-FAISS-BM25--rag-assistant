[site]: crossvalidated
[post_id]: 423120
[parent_id]: 
[tags]: 
What is bits per dimension (bits/dim) exactly (in pixel CNN papers)?

If it is for the lack of my effort to search, I apologize in advance but I couldn't find a explicit definition of bits per dimension (bits/dim). The first mention of its definition I found was from 'Pixel Recurrent Neural Networks'. But it is still quite unclear to me so let me ask. Defining the 256-softmax output of a image $\boldsymbol{x}$ as $\boldsymbol{y} \in \mathbb{R}^{32 \times 32 \times 256}$ , the negative log-likelihood, to my understanding, is $$ - \mathbb{E}_{\boldsymbol{x}} \ln p(\boldsymbol{y}|\boldsymbol{x}). $$ (Note that we are assuming here that image is one-channeled with its size being $32 \times 32 \times 1$ .) According to the above paper (and possibly other materials), it seems to me that the definition of bits/dim is $$ \text{bit/dim} = \dfrac{- \mathbb{E}_{\boldsymbol{x}} \log_2 p(\boldsymbol{y}|\boldsymbol{x})}{32\cdot 32\cdot 1} $$ because it says 'The total discrete log-likelihood is normalized by the dimensionality of the images '. Questions. 1) Is the above definition correct? 2) Or should I replace $\mathbb{E}_{\boldsymbol{x}}$ by $\sum_{\boldsymbol{x}}$ ?
