[site]: crossvalidated
[post_id]: 264585
[parent_id]: 
[tags]: 
Why does autoencoder not work for dimensionality reduction?

According to my last question, I tried out stacked Autoencoders instead of PCA to reduce the dimensionaly of my problem from ~130 to ~15. Here comes what I´m doing: hiddenSize1 = 80; autoenc1 = trainAutoencoder(Data, hiddenSize1, 'MaxEpochs', 400, 'L2WeightRegularization', 0.004,'SparsityRegularization', 4, 'SparsityProportion', 0.15, 'ScaleData', false); feat1 = encode(autoenc1, Data); hiddenSize2 = 15; autoenc2 = trainAutoencoder(feat1, hiddenSize2, 'MaxEpochs', 400, 'L2WeightRegularization', 0.002,'SparsityRegularization', 4, 'SparsityProportion', 0.1, 'ScaleData', false); autoenc_stacked = stack(autoenc1, autoenc2); Data_Reduced = autoenc_stacked(Data); Test_Data_reduced = autoenc_stacked(Test_Data); But it doesnt work at all. The first autoencoder´s performance and gradient is never really decreasing much. Second is doing better. Shouldnt it at least perform equally to PCA?
