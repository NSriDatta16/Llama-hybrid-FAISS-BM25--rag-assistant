[site]: crossvalidated
[post_id]: 254115
[parent_id]: 254106
[tags]: 
A hidden Markov model is made of two levels: A Markov chain, $(X_t)$, driven by a transition kernel $K$, e.g., $$X_{t+1}=K(X_t,\epsilon_{t+1})$$where $(\epsilon_t)$ is an iid white noise sequence; A noisy observation of the Markov chain, $(Y_t)$, driven by a noise distribution, e.g., $$Y_t=H(X_t,\xi_t)$$where $(\xi_t)$ is an iid white noise sequence. It is called hidden because the sequence $(X_t)$ is not observed. In your example, the Markov chain is made of the sequence of dishes one eats every evening, while the observation sequence is made of the type of container found in the trash the next morning. One possible use of a hidden Markov model is to infer the hidden chain $(X_t)$ from the $Y_t$'s. Another use is to infer the parameters driving the model, i.e., the parameters of $K$ and $H$. The book Inference in Hidden Markov Models [to which I contributed one chapter] is a suggest entry on the topic, albeit at a rather advanced level. [The above diagram is reproduced from an earlier Stack Exchange question on that topic.]
