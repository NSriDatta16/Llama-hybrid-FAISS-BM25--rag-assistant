[site]: datascience
[post_id]: 114399
[parent_id]: 114370
[tags]: 
The short answer is yes. The long answer is the following. Machine learning (ML) algorithms are designed to build models from data, but there is a general motto among ML practitioners: "garbage in, garbage out." That said, if you have trained your model in an intelligent way to distinguish between strange accents on words, then testing the resulting model on sentences with such accents is a good practice; in particular, I'm thinking of Spanish and Italian words, for instance, where a missing accent could give a completely different semantics to such sentences. Nevertheless, a more practical approach in the field of natural language processing (NLP) is to perform a text normalization (e.g., lemmatization) of your text before learning since specific words are less frequent than more general lemmas. For your specific task, there is a post that has Python code that could remove accents from words if you are willing to drop the take this journey. I hope that this gives you more insight into the complexity of NLP tasks. EDIT There are papers on accent-related researches, such as 1 , 2 , and 3 , among many others.
