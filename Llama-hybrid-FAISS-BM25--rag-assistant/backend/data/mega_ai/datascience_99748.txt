[site]: datascience
[post_id]: 99748
[parent_id]: 99742
[tags]: 
It depends on what kind of difference you examine statistically. If you have two groups drawn from the same distribution, you should not be able to distinguish between them reliably. This is a feature, not a bug, of machine learning. If you have two groups drawn from different distributions that have the same mean, you should be able to distinguish between them. Your performance might not be great, but you can do better than randomly guessing. For example, if you include a quadratic term in a logistic regression, you can distinguish between $N(0,1)$ and $N(0, 2)$ . Your performance will not be amazing, but it beats randomly guessing. # install.packages('pROC') # You might need to run this. library(pROC) set.seed(2021) N Without the quadratic term, the performance is terrible, and the AUC is basically chance, at $0.5426$ . With the quadratic term, the performance is far from amazing, but we do better than chance, with an AUC of $0.6847$ . (Even better could be to compare the log loss or Brier score, though those metrics seem less popular in data science than in statistics.) If you plot the densities of the two groups, it is clear why they can be distinguished better than chance. library(ggplot2) d0 If you get a point near $0$ , it is more likely to be from group $0$ than group $1$ . If you get a point far from $0$ , it is more likely to be from group $1$ than group $0$ . Around $\pm2$ , the group is more ambiguous, but you can do decent when you are in the middle or way out far. The lesson to learn here is that some model should be able to make some progress in distinguishing between the two distributions, unless the distributions are identical. Linear methods like vanilla logistic regression (with just linear terms, so no $x^2$ like my L2 model) work best when the means are different. A logistic regression with nonlinear terms, such as my L2 model that has a quadratic term or a model with splines, can fit (but also overfit) other differences. In the extreme, a model that finds its own nonlinear terms, such as a neural network, can find all kinds of differences (while also risking overfitting). Getting back to your example, you know that if you make an extreme observation, it is more likely to belong to some groups that have extreme observations than other groups that are clustered near the mean.
