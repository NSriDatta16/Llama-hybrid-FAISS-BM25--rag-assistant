[site]: crossvalidated
[post_id]: 588441
[parent_id]: 
[tags]: 
How can I ensure that the actions in my RL algorithm are not all over the place?

TLDR : My actions represent a torque of a physical system. How can I make sure that there aren't any large "jumps" between consecutive actions $a_t\rightarrow a_{t+1}$ ? So I have this very simple simulation of a wing that is connected to a motor. when the motor applies some torque $\tau_{motor}$ , the wing rotates with angle $\phi$ . My simulation finds $\phi(t)$ in every time window given the ODE $I\ddot\phi = \tau_{motor}-\tau_{drag}$ , where $I$ is the wing's moment of inertia and $\tau_{drag}$ is proportional to $(\dot\phi)^2$ . The interesting part is that I treat $\tau_{motor}$ as an action that is given via an RL algorithm - in every timestep I use PPO to tell me which action $\tau_{motor}$ is optimal given the state $\phi_t$ , and given a reward that is essentially the lift force that the wing generated using that specific action and given that specific state. As the actions are torques, which is a physical unit - I would like to incorporate some smoothness to them. For example, $a_t=-0.1$ followed by a $a_{t+1}=+0.1$ is not physically possible, as this means the fast transition from negative to positive torque, which is not realizable in real-world problems. Any ideas?
