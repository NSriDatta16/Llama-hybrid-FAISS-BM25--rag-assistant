[site]: datascience
[post_id]: 29864
[parent_id]: 13385
[tags]: 
I provide you some steps to perform this task: extract plain content from the news, for example using dragnet . tokenize each text and represent them with vectors with the bag of words technique. A simple way to perform this is using TfidfVectorizer from sklearn. Clusterize them using some classification technique like k-NN (k nearest neighbors). You will find the k-NN sklearn implementation very helpfull. The key to perform the task is using the TfidfVectorizer which weigths more the tokens that only appear in a few notices, like "Apple" and "Tim Cook". Using a simple count vectorizer will not be usefull.
