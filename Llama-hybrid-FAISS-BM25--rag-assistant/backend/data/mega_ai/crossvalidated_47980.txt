[site]: crossvalidated
[post_id]: 47980
[parent_id]: 46022
[tags]: 
I just know of two methods to deal with unbalanced sets with SVMs: Use bagging: you create bootstrap samples of your data, so that you a a big number of well-balanced problems. You train a SVM on each of them, and then use majority voting on the resulting ensemble of classifiers. If you are using C-SVM, then you can reweight the missclassification cost, $$C\sum_{i}\psi_{i}$$ into $$ C_{+}\sum_{i \epsilon I_{+}}\psi_{i} + C_{-}\sum_{i \epsilon I_{-}}\psi_{i}$$ where $I_{+}$, resp. $I_{-}$, is the set of indices for the positive examples, resp. for the negative examples. You choose the new soft-marging constants so that $\frac{C_{+}}{C_{-}} = \frac{n_{-}}{n_{+}}$, where $n_{+}$ and $n_{-}$ are the number of positive and negative samples resp.
