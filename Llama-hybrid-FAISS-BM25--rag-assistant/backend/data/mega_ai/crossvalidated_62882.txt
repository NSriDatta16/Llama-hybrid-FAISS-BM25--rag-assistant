[site]: crossvalidated
[post_id]: 62882
[parent_id]: 
[tags]: 
With k-fold cross-validation, do you average all $k$ models to build the final model?

When performing k-fold cross validation, I understand that you obtain the accuracy metrics by pointing all the folds except one at that one fold and make predictions, and then repeat this process $k$ times. You can then run accuracy metrics on all of your instances (precision, recall, % classified correctly), which ought to be the same as if you calculated them each time and then averaged the result (correct me if I'm wrong). The end result you want is a final model. Do you average the models obtained to make your set of $k$ predictions to end up with the model that has the accuracy metrics obtained by the above method?
