[site]: crossvalidated
[post_id]: 23730
[parent_id]: 23547
[tags]: 
I recommend reading "A Practical Guide to Support Vector Classification" by Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin In the work I've done much lower values of C work better - in the range of $10^{-4}$ to $10^{-2}$. 1-100 is a pretty high value of C, at least for the data I've worked with, which means you are not allowing much 'slack' and so its not surprising that you are finding your model over-fits the data. I would recommend trying with much smaller values of C and in orders of magnitude increments. Another alternative is to try nu-SVM rather than C-SVM. The parameter nu ranges from 0 to 1 (.1 to .8 in practice) and is much more intuitive: .1 means a small proportion of your data points are support vectors (and therefore you have a narrow margin and little slack), .8 means a very large percent are support vectors (and therefore a wide margin and a good deal of slack).
