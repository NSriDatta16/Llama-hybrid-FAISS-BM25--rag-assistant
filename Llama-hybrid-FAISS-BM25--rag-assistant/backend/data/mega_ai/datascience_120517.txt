[site]: datascience
[post_id]: 120517
[parent_id]: 57805
[tags]: 
GAN generators can have any type of output activation function. Some have shown to work better than others, such as TanH, but sigmoid is also often used. The key here is that it depends on your real data. If your real data is in the feature space $[0, 1]^n$ , then your output activation should probably be a sigmoid function. If your data resides in a $[-1, 1]^n$ space, it should be a TanH function. However, if your data lies in $[-\infty, \infty]^n$ , you could opt even for a linear output layer. The generator simply should be able to generate in the same space as the real data that you throw towards the discriminator.
