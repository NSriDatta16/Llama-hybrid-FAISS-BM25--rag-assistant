[site]: stackoverflow
[post_id]: 3728492
[parent_id]: 3728467
[tags]: 
Crawlers can usually be identified with the User-Agent HTTP Header. Look at this page for a list of user agents for crawlers specifically. Some examples are: Google: Mozilla/5.0 (compatible; Googlebot/2.1; + http://www.google.com/bot.html ) Googlebot/2.1 (+ http://www.googlebot.com/bot.html ) Googlebot/2.1 (+ http://www.google.com/bot.html ) Also, here are some examples for getting the user agent string in various languages: PHP: $_SERVER['HTTP_USER_AGENT'] Python Django: request.META["HTTP_USER_AGENT"] Ruby On Rails: request.env["HTTP_USER_AGENT"] ...
