[site]: crossvalidated
[post_id]: 594495
[parent_id]: 
[tags]: 
When is an unbalanced dataset large enough for calculating a decision threshold?

I have a (large i.e. >1M rows) very unbalanced (1% event label, binary classification) dataset with data from various institutions. At the moment, I train an XGBoost model on this data and get good performance on average (in production) across all institutions. The decision threshold is calculated on the test dataset to give a model with a defined target level of precision (we care about false positives). This means, however, that for some institutions the performance is subpar and being more or less strict i.e. having a lower or higher decision threshold would be beneficial. I understand I'm walking into overfitting territory, but at the same time the individual institutions complain they're not getting good performance. So my question is: how would you determine if a dataset (in this case, the data relative to a certain institution) is large and diversified enough (enough rows, but also enough event labels) to undertake that threshold optimisation (the model is the same, I'm only asking about the decision threshold)? I understand the answer is usually "depends on the data", but I don't have a heuristic to determine what factors to look into.
