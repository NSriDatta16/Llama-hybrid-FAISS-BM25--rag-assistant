[site]: datascience
[post_id]: 38029
[parent_id]: 38027
[tags]: 
Parts of Speech (POS) This is what it is called when you label each of the words (often called tokens ) of a sentence or many sentences. Usually they are labelled with grammatical descriptions, such as Noun, Adjective, Adverb . They can often get quite specific, also distinguishing e.g. between types of nouns ( proper nouns etc). You can then use these descriptions of the tokens as input to a model or to filter the tokens to extract only the parts you are interested in. POS are usually parts of the output when we parse a block of text using an NLP toolkit, such as spaCy . Have a look here for their available POS . Here is a snippet of parse tree of the sentence: Apple is looking at buying a UK startup for $1 billion. Apple has been recognised as a proper noun ( NNP ) as well as being the subject of the first verb (shown by the arrow labelled nsubj ). For a nice introduction to POS among many other terms within NLP, check out this article. . Sentiment Analysis Perspective There are many many reasons to include POS in a sentiment model (some examples below), but they really all boil down to one overarching reason: polysemy . The definition of which is: the coexistence of many possible meanings for a word or phrase. So essentially saying, that words in different contexts can have different meanings. This is of course a massive gain in information that we can pass to a model! The word duck can be a noun (the bird) or a verb (the motion, to crouch down). If we can tell a model which one of these it is in a given sentence, the model can learn to make a lot more sense out of the sentence. Beyond distinguishing between meanings of single words, we can also simply uses them on their usage , or placement. One example use would be to use the adverb: however . If our parser is good enough to tell us that it used in a particular sentence as a contrasting conjunction (which technically, would be grammatically incorrect!). An example sentence could be: I really love muffins, however, I hate strawberries. We have two clauses: a positive one before however and one after. The first clause is positive, the latter negative. If we have a scale of -5 ro +5 for sentiment for each clause (perhaps the mean of each word in that clause) we could imagine scores such as +3 for the positive clause and -3 for the negative. This is where I have seen some models (Vader, SentiStrength, etc.) using POS to scale those base scores. In our example, perhaps however would be used to increase the magnitude of the negative clause's score by 10%, giving it a final score of -3.3 . Whether or not that makes sense depends on the use case, the data and probably the developers general experiences. Summary There are many uses for POS, you can imagine quite a few, whether to hand-tailor a sentiment model of just to produce more features. In any case, it is a process that extracts more information from the original raw text, applying langage models (like grammar!) that have been tested and are known to be robust for any official form of writing.
