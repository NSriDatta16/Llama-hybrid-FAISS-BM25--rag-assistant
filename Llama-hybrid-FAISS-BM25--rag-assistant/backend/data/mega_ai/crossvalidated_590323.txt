[site]: crossvalidated
[post_id]: 590323
[parent_id]: 
[tags]: 
$\sin(x)$ is a counterexample to the universal approximation theorem

Inspired by AnoE's answer to the problem Can a neural network with only 1 hidden layer solve any problem? , I want to rigorously prove that the sine function over the real line cannot be well approximated by a shallow neural network. So we want to show that $$ \sup_{x\in \mathbb{R}} |f(x) - \sin(x)| \geq 1$$ for any, say, neural network $f$ with 1 hidden layer and ReLU activation function. Can you give me some ideas on how to approach this problem?
