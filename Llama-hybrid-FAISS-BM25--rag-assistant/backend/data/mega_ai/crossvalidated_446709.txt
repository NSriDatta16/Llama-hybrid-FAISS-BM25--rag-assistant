[site]: crossvalidated
[post_id]: 446709
[parent_id]: 444507
[tags]: 
To my knowledge, there aren't any truly robust methods. One strategy that I have seen in involved for the nearest neighbor (often using Euclidean distance). From there, the practitioner conducts visual inspection to check that overfitting is not occuring. This tends to be a poor indicator though because nearest-neighbor approaches tend not to work in such high-dimensional space. Also, see here for failures of pixel-wise loss. Another strategy involves looking at the nearest-neighbors of embeddings of the images (both synthesized and original data) into some space that is designed to extract features. This sounds better but doesn't seem to have much empirical or rigorous theoretical justification, with only a heuristic explanation.
