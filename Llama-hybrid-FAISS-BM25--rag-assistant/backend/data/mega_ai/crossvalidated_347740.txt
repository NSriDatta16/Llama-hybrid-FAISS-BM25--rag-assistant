[site]: crossvalidated
[post_id]: 347740
[parent_id]: 347730
[tags]: 
In general, ridge regression won't necessarily improve the error. Recall that the goal of the regularization is to make a simpler model to avoid overfitting and thus better prediction on the independent set. However, if overfitting is not a problem (for example when there are much more samples than features), more complex model (less regularized) might predict better. Often models predict better when they are more complex and not less, which is why things like neural networks, random forests and kernels exist. Traditional way to improve prediction is to look at your carefully at your data and think about what assumptions is your model making. Linear regression assumes that all your variables have linear effect and that there are no interactions between variables. So if oyu have a U shaped effect of some variable on the outcome or when variable A behaves differently for males and females, your model won't predict as well as it could.
