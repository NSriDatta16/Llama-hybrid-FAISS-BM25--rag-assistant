[site]: crossvalidated
[post_id]: 558833
[parent_id]: 13054
[tags]: 
Determining an "optimal" discretization scheme probably depends on the context of the problem. Generally, this question and Calculating optimal number of bins in a histogram sound like two sides of the same coin. Here is a summary (to date) of the answers there: MDL histogram density estimation discretizes data by fitting a normalized maximum likelihood distribution. This method is appealing to me as it is backed by sound principles in information theory. Freedman-Diaconis , prescribes a formula for determining a bin width that minimizes the integral of squared error between the resulting histogram and "underlying/true" probability distribution. Shimazaki-Shinomoto is similar in flavour to Freedman-Diaconis. Variations on the histogram is a bit different from the two above, and is related to creating histograms with "equal-area" per bin. They cut the empirical CDF diagonally. Bayesian blocks has a similar flavour to the above. The bin widths are variable. See more methods summarized on Wiki/Histogram
