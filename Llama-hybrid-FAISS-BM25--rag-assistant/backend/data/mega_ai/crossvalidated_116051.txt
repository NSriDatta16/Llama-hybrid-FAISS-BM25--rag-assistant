[site]: crossvalidated
[post_id]: 116051
[parent_id]: 
[tags]: 
Training nnet and avNNet models with caret when the output has negatives

My question is about the typical feed-forward single-hidden-layer backprop neural network, as implemented in package nnet, and trained with 'train()' in package caret. This is related to this question [Multi-layer neural network wont predict negative values ] but in the context of the nnet and caret packages in R. I demonstrate the problem with a simple regression example where Y = sin(X) + small error: (a) raw Y ~ raw X: predicted outputs are uniformly zero where raw Y (b) scaled Y (to 0-1) ~ raw X: solution looks great; see code below. library(nnet) X When using train() in caret, there is a preProcess option but it only scales the inputs. train(..., method = "nnet", ...) appears to be using the raw Y values; see code below. library(caret) ctrl Of course, I could linearly transform the Y variable(s) to have a positive range, but then my predictions will be on the wrong scale. Though this is only a minor headache, I'm wondering if there is a better (built-in?) solution for training nnet or avNNet models with caret when the output has negative values. Thanks for any suggestions or insight you can provide!
