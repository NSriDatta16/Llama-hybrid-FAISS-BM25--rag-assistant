[site]: datascience
[post_id]: 37545
[parent_id]: 
[tags]: 
Neural network example not working with sigmoid activation function

I'm running the Neural Network example written in in BogoToBogo The program worked fine: (array([0, 0]), array([ 2.55772644e-08])) (array([0, 1]), array([ 0.99649732])) (array([1, 0]), array([ 0.99677086])) (array([1, 1]), array([-0.00028738])) The neural network learned XOR, using tanh as activation function by default. However, after I changed the activation function to "sigmoid" nn = NeuralNetwork([2,2,1], 'sigmoid') Now the program outputs: epochs: 0 ... epochs: 90000 (array([0, 0]), array([ 0.45784467])) (array([0, 1]), array([ 0.48245772])) (array([1, 0]), array([ 0.47365194])) (array([1, 1]), array([ 0.48966856])) The output for the 4 inputs are all near 0.5. The result shows that neural network (with the sigmoid function) didn't learn XOR. I was expecting the program would output: ~0 for (0, 0) and (1, 1) ~1 for (0, 1) and (1, 0) Can somebody explain why this example with sigmoid doesn't work with XOR?
