[site]: datascience
[post_id]: 53808
[parent_id]: 53792
[tags]: 
I don't have a proof for this, but I expect the best you can do is estimate the normal distribution of interval times from your training data, and then just predict points at the mean interval time. You don't seem to have any features the would indicate when an interval will be shorter or longer than average, so all you can do is predict the average and let it work out in the long run. Of course, if the mean interval time is longer than double your minimum prediction interval (epsilon), you should insert more predictions in the gap since there is no downside to doing so.
