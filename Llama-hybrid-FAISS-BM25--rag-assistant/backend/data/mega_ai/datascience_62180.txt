[site]: datascience
[post_id]: 62180
[parent_id]: 62164
[tags]: 
The number of parameters is the number of weights connecting the layer to the previous one, so for the layer $i$ it depends on the number of neurons in the layer $i$ and the previous one $i-1$ . The exact formula for a fully connected neural network is: $$n_i(n_{i-1}+1),$$ where $n_i$ is the number of neurons in the layer $i$ , $n_{i+1}$ the number of neurons in the layer $i+1$ , and the $+1$ term takes into account the bias. So for dense_2477 you indeed get $$n_{\mathrm{params}}=8(16+1) = 136,$$ and for dense_2482 , $$n_{\mathrm{params}}=16*(8+1) = 144,$$ as expected.
