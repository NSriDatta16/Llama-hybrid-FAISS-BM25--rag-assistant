[site]: crossvalidated
[post_id]: 4868
[parent_id]: 
[tags]: 
Using k-fold cross-validation to test all data

Is it possible to do k-fold cross-validation to test all data, rather than using kfcv to find the optimal hypothesis as is typically done. Example: Say I want to use a svms on a dataset of size 1000. Could I use 900 events to train the svm for the testing of the other 100 events. Then use a separate 900 events to train the svm for a separate 100 events, repeating this process 10 times until all of the data has been tested. Would events tested using separately trained svms be comparable? i.e. through this technique could I then use my entire dataset instead of setting aside a certain fraction for training, or is this a statistically unwise thing to do? Thanks for any help, Colorado PS) Any references to why this would['nt] work is greatly appreciated, I'm discussing this technique in an academic setting.
