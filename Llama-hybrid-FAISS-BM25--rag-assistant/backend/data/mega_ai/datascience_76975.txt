[site]: datascience
[post_id]: 76975
[parent_id]: 76824
[tags]: 
One thing that can be a gotcha coming from R to Python is that the Python stats ecosystem tends to be more machine learning-ey oriented rather than inferential stats-ey oriented. This can create some hiccups, because some of the defaults in R that are the defaults because people who do inferential stats like in the social sciences always use them, are not the defaults in the main Python libraries. For example, Statsmodels, one of the standard libraries for inferential stats, doesn't include the intercept by default when you do linear regression , UNLESS you use the R-style formulas with Patsy , in which case it is included. Another example : Scikit-learn in Python uses the divide-by-n ("population") formula for standard deviation, while R uses the divide-by-n-1 ("sample") formula. Those sort of things tend to be really confusing for people new to the ecosystem, and create totally unnecessary cognitive burden. So that's a tradeoff.
