[site]: crossvalidated
[post_id]: 595303
[parent_id]: 
[tags]: 
Understanding the Predictive Distribution of Bayesian Linear Regression

So there are a few questions that have asked this before here and here , but I seem to be missing a step. $$ \begin{aligned} p(f_*|x_*,X,y) &= \int p(f_*,w|x_*,X,y)~dw \quad \text{(marginalise $w$)}\\ &= \int p(f_*|x_*,X,y,w)p(w|x_*,X,y)~dw \quad \text{(chain rule)}\\ &= \int p(f_*|x_*,w)p(w|X,y)~dw \quad \text{($f_* \mathrel{\unicode{x2AEB}} X, y$ given $w$ and $w \mathrel{\unicode{x2AEB}} x_*$)}\\ \end{aligned} $$ Now, I don't understand what distribution $p(f_*|x_*,w)$ is, isn't it just a constant when both { $x_*, w$ } are given? There seems to be some step I'm missing after substituting $f_* = x_*^Tw$ and then solving the integral: $$ \begin{aligned} p(f_*|x_*,X,y) &= \int p(f_*|x_*,w)p(w|X,y)~dw\\ &= \int p(x_*^Tw|x_*,w)p(w|X,y)~dw \quad \text{($f_* = x_*^Tw$)}\\ &= \textbf{what goes here?}\\ &= x_*^T\mathcal{N}\left(\frac{1}{\sigma_n^2} A^{-1}Xy, A^{-1}\right) \quad \text{(is this right?)}\\ &= \mathcal{N}\left(\frac{1}{\sigma_n^2} x^T_*A^{-1}Xy, x_*^TA^{-1}x_*\right) \end{aligned} $$
