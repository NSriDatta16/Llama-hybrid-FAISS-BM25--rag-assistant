[site]: crossvalidated
[post_id]: 273737
[parent_id]: 273473
[tags]: 
A simulation based answer is to treat the $X_i$'s as latent variables and include these in a global MCMC sampler. At iteration $t$, it could proceed as follows Simulate the $X_i^t$'s given the $S_j$'s and the current value of the parameters ${\theta}^t$ Given the $X_i^t$'s and their log-Normal mixture distribution, simulate the next value of the parameters, $\theta^{t+1}$ Step 2 is straightforward in that this is equivalent to simulate the posterior of a Normal sample. Step 1 can be decomposed in a sequence of Gibbs steps where each $X_i$ is generated conditional on the $8$ other $X_k$'s and the corresponding $S_j$. Meaning any MCMC move targeting the distribution $$\{pf_1(x_i;\mu_1,\sigma_1)+(1-p)f_2(x_i;\mu_2,\sigma_2)\}\times \{pf_1(s_j-x_{10(j-1)+1}-\ldots-x_{10j};\mu_1,\sigma_1)+(1-p)f_2(s_j-x_{10(j-1)+1}-\ldots-x_{10j};\mu_2,\sigma_2)\}$$
