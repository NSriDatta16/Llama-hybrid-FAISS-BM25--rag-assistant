[site]: crossvalidated
[post_id]: 223662
[parent_id]: 
[tags]: 
Random initialization/order in neural network â€” bias or variance?

I'm puzzled about how to describe differences occurring between neural networks trained on the same data and with the same configuration. They differ only in the initial weights (different seeds used for random initialization) and in the random order in which they process the training data. Are these two examples of bias or variance? I tend towards bias, as both effects have no connection to the data, yet only to the initial state of my model. Thanks!
