[site]: crossvalidated
[post_id]: 304988
[parent_id]: 
[tags]: 
Understanding the Logistic Regression and likelihood

How does the parameter estimation/Training of logistic regression really work? I'll try to put what I've got so far. The output is y the output of the logistic function in form of a probability depending on the value of x : $$P(y=1|x)={1\over1+e^{-\omega^Tx}}\equiv\sigma(\omega^Tx)$$ $$P(y=0|x)=1-P(y=1|x)=1-{1\over1+e^{-\omega^Tx}}$$ For one dimension the so called Odds is defined as follows: $${{p(y=1|x)}\over{1-p(y=1|x)}}={{p(y=1|x)}\over{p(y=0|x)}}=e^{\omega_0+\omega_1x}$$ Now adding the log function to get the W_0 and W_1 in linear form: $$Logit(y)=log({{p(y=1|x)}\over{1-p(y=1|x)}})=\omega_0+\omega_1x$$ Now to the problem part Using the likelihood (Big X is y ) $$L(X|P)=\prod^N_{i=1,y_i=1}P(x_i)\prod^N_{i=1,y_i=0}(1-P(x_i))$$ Can any one tell why we're considering the probability of y=1 twice ? since : $$P(y=0|x)=1-P(y=1|x)$$ and how get the values of Ï‰ from it?
