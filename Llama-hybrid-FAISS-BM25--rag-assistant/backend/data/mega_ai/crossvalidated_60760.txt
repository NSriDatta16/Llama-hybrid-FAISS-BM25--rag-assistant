[site]: crossvalidated
[post_id]: 60760
[parent_id]: 
[tags]: 
Finite output in logistic regression with divergent `glm` algorithm

let m be my matrix of data x_i y_i [1,] 0.0 0 [2,] 0.0 0 [3,] 0.0 0 [4,] 0.0 0 [5,] 0.1 0 [6,] 0.2 0 [7,] 0.3 0 [8,] 0.4 0 [9,] 0.5 0 [10,] 0.6 0 [11,] 0.0 1 [12,] 0.0 1 [13,] 0.0 1 [14,] 0.9 1 [15,] 1.0 1 My aim is to study the logistic regression y~x , where the covariate x has observations m[,1] and similarly for y . Please note that we have no complete separation in the data but the "anomalous" entries in rows m[11,], m[12,] and m[13,] all correspond to observations with x_i=0 . I expect glm to diverge as the likelihood function reaches no maximum in the ray $k\beta$, for $k\rightarrow \infty$ and $\beta=(-0.7,1)$. Using glm with 1 iteration I get the output Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -1.2552 0.7648 -1.641 0.101 x 1.6671 1.7961 0.928 0.353 (Dispersion parameter for binomial family taken to be 1) Null deviance: 19.095 on 14 degrees of freedom Residual deviance: 18.275 on 13 degrees of freedom AIC: 22.275 Number of Fisher Scoring iterations: 1 with an error message (the algorithm does not converge). Moreover, with the default number of iterations (=25) the output is Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -1.1257 0.7552 -1.491 0.136 x 1.4990 1.6486 0.909 0.363 (Dispersion parameter for binomial family taken to be 1) Null deviance: 19.095 on 14 degrees of freedom Residual deviance: 18.246 on 13 degrees of freedom AIC: 22.246 Number of Fisher Scoring iterations: 4 and no error warning. I see a contradiction; even in presence of 1 iteration the algorithm does not converge but the output is "finite" (I have not explicitly computed the inverse of the Hessian of the likelihood function, unfortunately). Moreover, with 25 iterations the warning message disappears and the output is still finite. What do you think about this situation? Is it possible that glm stops automatically after the first iteration? Thank you, Avitus
