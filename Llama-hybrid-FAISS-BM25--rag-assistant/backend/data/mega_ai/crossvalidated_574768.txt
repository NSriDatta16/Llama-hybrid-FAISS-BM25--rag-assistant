[site]: crossvalidated
[post_id]: 574768
[parent_id]: 
[tags]: 
How to compute minimum sample size of a simple linear regression model with given statistics values

Suppose the statistics values are given as follows: $\sum_{i=1}^{n}x_i, \sum_{i=1}^{n}y_i, \sum_{i=1}^{n}x_iy_i, \sum_{i=1}^{n}x_i^2,\sum_{i=1}^{n}y_i^2$ Firstly, we can compute the regression coefficient $\beta_0, \beta_1$ such that: $Y =\beta_0 + \beta_1 X$ An ANOVA (F-test) can also be carried out to see whether X and Y are dependent. Suppose $F , p-value $> 0.05$ such that there is no strong evidence that $\beta_1 \ne 0$ . i.e. X and Y are independent. However, what if we were told that $\sum_{i=1}^{n}(x_i-\bar x)^2, \sum_{i=1}^{n}(y_i-\bar y)^2, \sum_{i=1}^{n}(x_i-\bar x)(y_i-\bar y)$ were doubled, X and Y are dependent by ANOVA, and find the minimum sample size $n$ . My approach: I am new to ANOVA and statistics test, the only I can think of is to start it with F-test formula , and if X and Y are dependent, it should fulfill $F>F_{critical}$ but $F_{critical}$ is unknown due to unknown sample size $n$ . Besides, the new model has the same $\beta_1$ as before. from doubling up $\sum_{i=1}^{n}(y_i-\bar y)^2$ . We can also find out the new $SS_{TOTAL}$ Apologies for the unorganised ideas above. I have no idea of the right direction to solve this problem. I would like to know how to solve this please. Thank you very much.
