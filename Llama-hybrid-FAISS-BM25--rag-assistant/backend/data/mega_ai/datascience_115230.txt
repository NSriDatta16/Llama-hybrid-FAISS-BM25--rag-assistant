[site]: datascience
[post_id]: 115230
[parent_id]: 115225
[tags]: 
This is a typical Feature Selection problem in the world of machine learning. The following are a few fundamental points that can be used before plugging any data into machine learning models. Perform a feature correlation analysis before diving into ML. Correlated features do not provide any additional information for ML models. You just need to have one feature among the correlated ones basically because the other one is redundant. Once those straight correlations are removed, then you can employ more complex feature selection methods that make use of techniques like mutual information. What I would suggest is to use a combination of feature selection methods with a voting strategy to find the best features. With your simple experiment itself you have proved that mutual information does not always win. There are methods like Correlation-based feature selection, Relief-F etc. In short first check, simple correlations and then use more sophisticated methods. Additionally, mutual information may not always be useful. Rather there is no single method that will always work for all different datasets.
