[site]: crossvalidated
[post_id]: 273227
[parent_id]: 273193
[tags]: 
The traditional t test assumes normality and homogeneity of variance because those assumptions make derivation of the sampling distribution of t mathematically tractable, and frequentists want the sampling distribution so they can compute a p value. But if your data aren't well described by equal-variance normal distributions, then the best-fitting parameter values don't really tell you much, and the p value might be way off too. (You can fit a hat to your foot, and find the best fitting hat size and the probability that a null hat would produce sizes as big as your foot, but that information about hats is not a very useful description of your foot.) Bayesian approaches to comparing groups also must make model assumptions, of course. If the Bayesian model assumes equal-variance normal distributions, it too will not be a very good description of heterogeneous non-normal data. Now to your question: How do you check whether the model is a good description? This is usually called a posterior predictive check , because you check whether the data appear to be well described by the model when set at the posterior parameter values. Of course, in the Bayesian world, you don't conduct the test with p values (IMHO, see this article [Kruschke, J. K. (2013). Posterior predictive checks can and should be Bayesian: Comment on Gelman and Shalizi, ‘Philosophy and the practice of Bayesian statistics’. British Journal of Mathematical and Statistical Psychology, 66, 45-56. doi:10.1111/j.2044-8317.2012.02063.x]. Fortunately, Bayesian models implemented in software like JAGS or Stan are very flexible, so if your data don't match the assumptions of traditional models, you instead use a model that better describes your data. In the case of two groups, it's easy to assume heavy-tailed distributions with unequal variances. For an extensive description with accompanying software in JAGS, see this page . Finally, Bayesian "null hypothesis testing" is done by computing a Bayes factor for model comparison. The models in the model comparison must make assumptions about normality or not, homeogeneous variance or not, etc. In any case, the Bayes factor by itself tells you only which of the models is least bad, not whether any of the models is any good. You still need to do a posterior predictive check that involves looking at the detailed predictions of the winning model.
