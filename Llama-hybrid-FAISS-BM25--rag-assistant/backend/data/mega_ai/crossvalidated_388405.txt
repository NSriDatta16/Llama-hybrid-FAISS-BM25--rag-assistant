[site]: crossvalidated
[post_id]: 388405
[parent_id]: 388269
[tags]: 
The likelihood function is defined in the context of parametric distribution. Given a family of pmf's $p_θ(x)$ , $x\in\mathfrak{X}$ meaning that, for every and all values of $θ$ , $p_θ(\cdot)$ is a probability density over $\mathfrak{X}$ [wrt to a well-defined dominating measure] and an observation $x^o$ , supposedly generated from one of these pmf's, ${p_{θ^o}}(\cdot)$ say, the likelihood function $$ℓ:\Theta \longrightarrow \mathbb{R}^+$$ is a function (of $θ$ ) proportional to $p_θ(x^o)$ , $$\ell(θ) \propto p_θ(x^o)$$ proportional in the sense that there exists a constant $κ$ such that $$ℓ(θ)=κp_θ(x^o)$$ $κ$ being constant in $θ$ (but possibly depending on $x^o$ , dependence that does not matter since $x^o$ is observed, hence fixed). If one does not adopt a Bayesian or a fiducial approach, the likelihood cannot be defined more precisely, that is, there is no general principle towards selecting a value of $κ$ . Hence the statement that it is proportional to the pmf, taken at $x^o$ , a probability density in $x$ and not in $\theta$ . The likelihood is not a probability distribution in $\theta$ as the "likely" in "likelihood" refers to the probability of observing the observed $x^o$ given the inputed value of the parameter $\theta$ .
