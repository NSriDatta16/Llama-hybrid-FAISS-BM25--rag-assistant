[site]: crossvalidated
[post_id]: 260172
[parent_id]: 
[tags]: 
Question about reward function in Inverse Reinforcement Learning (IRL)

In Reinforcement Learning (RL), we specify the reward function so that the agent can learn the optimal policy. This reward function can come in various forms. It can be a scalar, a function, or anything else. In the problem of Inverse Reinforcement Learning (IRL), the reverse happens: we are trying to find the reward function that can explain an expert's/demonstrator's behaviour. My question is, upon finding this reward function, in what form does the reward function appear? Is it a scalar? A Function? or What? I am trying to learn IRL, looking at some codes in the internet that demonstrate this concept. So far I am not really sure what the output is and how the reward looks like. Your insights are appreciated.
