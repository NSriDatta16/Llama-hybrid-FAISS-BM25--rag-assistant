[site]: crossvalidated
[post_id]: 610282
[parent_id]: 610274
[tags]: 
In a very simplified way: Posterior probability = $P(\gamma | D)$ = probability that your parameter (or vector of parameters) $\gamma$ is equal to the value you've sampled given your dataset $D$ . Prior = arbitrary guess of the value of $\gamma$ based on an expert knowledge (or ignorance for uninformative prior) However, a question you don't ask is "what means the likelihood" in the Bayesian formula: basically, it is the opposite of the posterior probability. Likelihood = $P(D|\gamma)$ = probability that your data is observed for the given values of the parameter(s) $\gamma$
