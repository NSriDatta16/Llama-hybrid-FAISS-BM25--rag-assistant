[site]: datascience
[post_id]: 51421
[parent_id]: 
[tags]: 
additional of features decrease the accuracy of the model

I am using sklearn's random forests module to predict a binary target variable based on 166 features. When I increase the number of dimensions to 175 the accuracy of the model decreases (from accuracy = 0.86 to 0.81 and from recall = 0.37 to 0.32) . I would expect more data to only make the model more accurate, especially when the added features were with business value. I built the model using sklearn in python. Why the new features did not get weight 0 and left the accuracy as it was ?
