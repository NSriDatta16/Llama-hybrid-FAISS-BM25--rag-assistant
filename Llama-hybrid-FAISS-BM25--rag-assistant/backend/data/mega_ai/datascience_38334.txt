[site]: datascience
[post_id]: 38334
[parent_id]: 
[tags]: 
Activity recognition in smart homes with different sources

I have a dataset collected in a smart home and I would like to do Activity Recognition . I am used to classification but in this case data comes from 4 different sources: Accelerometer from wrist Binary sensors around the house proximity beacons (to understand which room the user is at any moment) ground pressure from floor Data is labelled and has 25 activities. At the moment I am working with a CNN on the activity images coming from the sensors and I can reach 45% accuracy, but I need to add the other sources to achieve better results. My questions: how to use all (or a group of) different sources for example in a NN? Can I train 4 different classifier that works together to make a prediction? Maybe some classifiers try to understand simpler activities and other try to find more complex activities?
