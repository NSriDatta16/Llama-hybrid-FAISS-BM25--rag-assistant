[site]: crossvalidated
[post_id]: 481141
[parent_id]: 480915
[tags]: 
Entropy pops up everywhere in statistical inference and machine learning. For instance: Finding a parameter which maximizes the likelihood of the data is equivalent to finding a parameter which minimizes the KL divergence. The Principle of Maximum Entropy is applied to find statistical models that have the greatest entropy for a set of given constraints (a way of avoiding overfitting). A great example of entropy applied in machine learning is the restricted Boltzmann machine. If you haven't already, I would check out the book Information Theory, Inference, and Algorithms by David MacKay and Probability Theory: the Logic of Science by E.T. Jaynes.
