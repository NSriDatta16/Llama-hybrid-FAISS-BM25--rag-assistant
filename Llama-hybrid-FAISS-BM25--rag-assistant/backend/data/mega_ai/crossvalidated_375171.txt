[site]: crossvalidated
[post_id]: 375171
[parent_id]: 268793
[tags]: 
The paper https://arxiv.org/pdf/1807.04587.pdf (July 2018) reports on some efforts to find artificial neural network learning algorithms that are biologically plausible. They focus mainly on backpropagation, but also discuss weight sharing. They review a lot of work by major researchers in the field and others. They conclude that algorithms that work well are not plausible, and algorithms that are plausible don't work well. Their references look like a good starting point for further reading, and it looks like the whole question is heating up again a little bit. I think there is some confusion about what is meant by convolutional. ConvNets, in ANN research, use weight sharing (aka weight tying). There is a tutorial at https://www.quora.com/What-exactly-is-meant-by-shared-weights-in-convolutional-neural-network . Weight sharing, not convolution per se, is the point here. It is essential for translational invariance, which is one of ConvNets' most important claims. Without it they wouldn't be able to learn anything in reasonable time. So folks in ANN research tend to assume that "convolutional" implies weight sharing. In other disciplines, I think there is no such notion as weight sharing. Convolutional structures are familiar in the brain, as @Carl says, but there seems to be nothing known in the brain that is like weight sharing in form or function. So to answer the OP's original question: convolution is highly plausible, but weight sharing is not. Therefore there is no biologically plausible model for ConvNets, in vision or any other domain, nor for some other kinds of ANN that also use weight-sharing. (One could also say the same thing about all ANN's that use backprop, which includes most supervised learning, whether convolutional or not.) Caveat: I only glanced at the paper @Carl referenced. Too much chemistry for me, so I just assumed that it has nothing about convolution with weight sharing .
