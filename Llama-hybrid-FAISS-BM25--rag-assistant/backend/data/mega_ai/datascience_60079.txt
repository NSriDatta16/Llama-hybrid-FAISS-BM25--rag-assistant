[site]: datascience
[post_id]: 60079
[parent_id]: 60044
[tags]: 
I see a couple of parts to your question Part 1 Why would we use global basis functions instead of local basis functions to introduce non-linearity into our linear machine learning model? Local (non-global) basis functions are used sometimes. For example, radial basis functions (RBF) are sometimes used as a basis in linear regression ( see these lecture notes ). However, often it matters that a model is interpretable and more complicated models are harder to interpret / draw certain conclusions from. For example, imagine you're doing a controlled experiment, you may not care about "just" predicting some variable from (the variable you're manipulating + the variables you're controlling for). But rather, how much of an effect your manipulation has on the output. Part 2 Why don't we discretize our feature space and optimize on a linear function space? RBFs kind-of discretize feature space. People don't usually literally discretized feature space because discrete optimization is much much more complicated than continuous optimization.
