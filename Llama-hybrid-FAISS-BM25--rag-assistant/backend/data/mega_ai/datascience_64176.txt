[site]: datascience
[post_id]: 64176
[parent_id]: 49313
[tags]: 
As far as I know, no neural network can be immune to catastrophic forgetting during fine-tuning (which is essentially controlled retraining). The key is to not fine tune the pretrained model for longer epochs, or with higher learning rates. This ensures that the learned knowledge from the lower layers is preserved more or less intact, while also helping the model learn from the new data used for fine-tuning, as mentioned here : https://github.com/huggingface/transformers/issues/1019
