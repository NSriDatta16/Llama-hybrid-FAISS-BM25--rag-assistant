[site]: crossvalidated
[post_id]: 167672
[parent_id]: 167665
[tags]: 
It's not necessarily true that you'll need to do feature selection for this data. A model like Random Forest will be fine; it can even perform well in cases where you have more features than observations! On the other hand, models in the ordinary linear regression family will likely struggle, so a regularized version (LASSO or elastic net) will likely improve its performance while performing feature selection at the same time. Your instincts are correct, though: you should not do supervised feature selection and then train a model on that same data. Performance metrics of the model will be very biased upwards. One way to mitigate the effect of this bias would be to perform nested cross-validation, so that at each "outer" CV step, you're exposing the model to new data. This can become expensive as you add CV layers, though. I don't know how AttributeSelectedClassifier works. A careful study of what it does and a comparison to what you want to do will be the best guide of whether or not it's acceptable for your purposes.
