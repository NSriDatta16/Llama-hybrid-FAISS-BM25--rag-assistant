[site]: crossvalidated
[post_id]: 412675
[parent_id]: 412650
[tags]: 
I don't think anybody claimed that it isn't convex, since it is convex (maybe they meant logistic function or neural networks). Let's check 1D version for simplicity $$L = - t \log(p) + (1 - t) \log(1-p)$$ Where $p = \frac{1}{1 + \exp(-wx)}$ $t$ is target, $x$ is input, and $w$ denotes weights. L is twice differentiable with respect to $w$ and $\frac{d}{dw^2} L = \frac{x^2 \exp(wx)}{(1 + \exp(wx))^2} > 0$ , so the loss function is convex.
