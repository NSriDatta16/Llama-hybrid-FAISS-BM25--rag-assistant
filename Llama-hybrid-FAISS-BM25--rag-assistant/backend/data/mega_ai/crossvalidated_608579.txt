[site]: crossvalidated
[post_id]: 608579
[parent_id]: 606983
[tags]: 
Based on your reference I believe that you are estimating the vector $\boldsymbol{\beta}$ of size $p_n$ with a posterior distribution based on the observation of the vector $\mathbf{Y}$ of size $n$ in the model $$\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon}$$ where $\mathbf{X}$ is a fixed regression matrix $n \times p_n$ matrix. The components $\beta_i$ from the vector $\boldsymbol{\beta}$ have a prior distribution that follows the model that you described. If you have a fixed $p$ then consistency seems guaranteed by a Bayesian law of large numbers, or consistency of likelihood/posterior for an i.i.d sample ( When do posteriors converge to a point mass? ). Or maybe I am missing something? Say we use some fixed $p$ while letting $n$ increase, then the Bayesian posterior density $f(\boldsymbol{\beta}|\mathbf{Y})$ will concentrate near the true $\boldsymbol{\beta}$ (if the prior is not zero). The same is true when $p$ is not fixed, but still with a finite upper bound. We can consider all $p$ 's below the bound together while letting $n \to \infty$ and if they are all individually consistent, then we will also have consistency when we change $p$ while letting $n$ increase.
