[site]: stackoverflow
[post_id]: 601549
[parent_id]: 601438
[tags]: 
Every application gets tested. Some applications get tested in the form of does my code compile and does the code appear to function . Some applications get tested with Unit tests . Some developers are religious about Unit tests, TDD and code coverage to a fault. Like everything, too much is more often than not bad. Some applications are luckily enough to get tested via a QA team. Some QA teams automate their testing, others write test cases and manually test. Michael Feathers, who wrote: Working Effectively with Legacy Code , wrote that code not wrapped in tests is legacy code. Until you have experienced The Big Ball of Mud , I don't think any developer truly understands the benefit of good Application Architecture and a suite of well written Unit Tests. Having different people test is a great idea. The more people that can look at an application the more likely all the scenarios will get covered, including the ones you didn't intend to happen. TDD has gotten a bad rap lately. When I think of TDD I think of dogmatic developers meticulously writing tests before they write the implementation. While this is true, what has been overlooked is by writing the tests, (first or shortly after) the developer experiences the method/class in the shoes of the consumer. Design flaws and shortcomings are immediately apparent. I argue that the size of the project is irrelevant. What is important is the lifespan of the project. The longer a project lives the more the likelihood that a developer other than the one who wrote it will work on it. Unit tests are documentation to the expectations of the application -- A manual of sorts.
