[site]: crossvalidated
[post_id]: 479040
[parent_id]: 479025
[tags]: 
Your data. First, I digitized your data (approximately) from the dot plots at the top of your figure and entered them into R. [My version of your data may not be exactly correct, but close enough for what I want to do.] x1 = c(30,38,41,41,42, 43,45,53,53,54, 56,57,63,64,64, 66,66,67,67,69, 73,83,84,88,90) x2 = c(48,59,60,61,61, 62,63,65,67,67, 67,68,68,71,71, 71,74,75,78,79, 79,80,83,84,84) summary(x1); sd(x1) Min. 1st Qu. Median Mean 3rd Qu. Max. 30.00 45.00 63.00 59.88 67.00 90.00 [1] 16.2694 # SD x1 summary(x2); sd(x2) Min. 1st Qu. Median Mean 3rd Qu. Max. 48.0 63.0 68.0 69.8 78.0 84.0 [1] 9.059985 # SD x2 mean(x2) - mean(x1) [1] 9.92 The scores in the second group were higher by 9.92 points. So it looks as if Brand 2 was favored over Brand 1. The question is whether the difference is large enough, considering the variability in scoring, to be declared 'significantly different' in a statistical sense. The scores may not be exactly normally distributed, but there are several points in favor of assuming they are approximately normal. Each score is the sum of ten components, and such scores are often approximately normal. The dot plots show no marked skewness or extreme outliers. Both data vectors x1 and x2 are found to be consistent with sampling from normal populations, according to a Shapiro-Wilk normality test. (In both tests, P-values are far above $0.05).$ . shapiro.test(x1) $p.val [1] 0.5010366 shapiro.test(x2)$ p.val [1] 0.4639407 Welch one-sided, two-sample t test. Therefore, it seems reasonable to use a two-sample t test to judge whether the observed difference of 9.92 is statistically significant. Because the sample standard deviations of x1 and x2 are somewhat different, I will use a Welch 2-sample t test, which accommodates samples with different variability. The null hypothesis is that the two populations have equal means $H_0: \mu_1 = \mu_2$ and the one-sided alternative is that the first group has a smaller mean than the second $H_a: \mu_1 t.test(x1,x2, alte="less") Welch Two Sample t-test data: x1 and x2 t = -2.6635, df = 37.579, p-value = 0.005661 alternative hypothesis: true difference in means is less than 0 95 percent confidence interval: -Inf -3.639094 sample estimates: mean of x mean of y 59.88 69.80 The verdict whether or not to reject $H_0$ has to be stated in terms of the data because we have access to the data (and have no way of knowing exact values of population means $\mu_1, \mu_2.)$ The P-value $0.005661$ of the test indicates that the difference between the sample means is relatively large. If the population means were equal (as stated by $H_0,$ then there are fewer than 6 chances in 1000 that we would observe such a large difference (or a larger one) between sample means. By 'relatively', I mean that the sizes and variability of the samples have been taken into account in assessing how to interpret the size of the difference between sample means. [If you like, you can take a look at the formula for the t statistic and its degrees of freedom df : you will see sample sizes $n_1 = n_2 = 25$ and sample standard deviations $S_1 and S_2$ in these formulas.] The image in your Question shows the P-value $0.006$ which indicates that if population means were equal as large a difference (or larger) between sample means as we have observed would occur very rarely. That's 6 chances in 1000; not exactly the same as for the Welch t test I showed above, but both P-values strongly indicate rejection of $H_0$ in favor of $H_1.$ It is common to test hypotheses at the 5% level, which means that 1 chance in 20 is often considered strong enough evidence to reject $H_0.$ If there is a question whether the assumptions for a t test are met, statisticians look for other ways to find a P-value that will use sample sizes and variabilities of the two samples to judge whether an observed difference is large enough to be called 'statistically significant'. Permutation test. In your question it seems that a permutation test is used to find a useful P-value. You can read about permutation tests in Wikipedia , which gives some of their history and shows several elementary examples. There are many kinds of permutation tests and from your question I can't tell which of them was done; only the results are shown, not the procedure. So I will do a permutation test of my own, hoping it will give you a general idea what is involved. First, we need a 'metric', a way to measure the difference between the scores in samples x1 and x2 . As my metric, I will choose the difference in sample means: $D_\mathrm{obs} = \bar X_2 - \bar X_1.$ Second, I will perform permutations of the data. Specifically, we have $n_1+n_2 = 50$ scores in the two groups combined. Strictly at random, I will pick 25 of the 50 to put into group 1 and put the remaining 25 into group 2. For each such permutation I will find $D^* = \bar X_2^* - \bar X_1^*$ where the * 's mean that permuted groups rather than original groups are used. Third, I will do $B = 10,000$ of these permutations of the data and get a $D^*$ from each one of them. Information about the sample sizes and variabilities of the data gets used in all of this permuting and averaging. So I will get a useful 'permutation distribution' of the 10,000 $D^*$ s. Finally, I will compare the permutation of $D^*$ s with the original $D_{\mathrm{obs}} = 9.92.$ The proportion of $D^*$ s that is larger than or equal to $D_{\mathrm{obs}}$ will be the P-value of the permutation test. The following R code assumes that the data vectors x1 and x2 are already present in R. d.obs = mean(x2) - mean(x1) x = c(x1, x2) g = rep(1:2, each=25) set.seed(1234) B = 10^4; d.prm = numeric(B) for (i in 1:B) { g.prm = sample(g) # randomly scrambles groups d.prm[i] = mean(x[g.prm==2]) - mean(x[g.prm==1]) } mean(d.prm >= d.obs) [1] 0.0064 hdr="Permutation Distribution of Group Mean Differences" hist(d.prm, prob=T, br=30, col="skyblue2", main=hdr) abline(v=d.obs, col="red") The P-value $0.0064$ from my permutation test is about the same as the P-value from the permutation test in your Question. A permutation test is a random procedure (depending on random permutations of the observations into two groups), so results might differ slightly from one run to another. In any case my permutation P-value and the one in your Question are essentially the same. Both are small enough to lead to rejection of $H_0.$
