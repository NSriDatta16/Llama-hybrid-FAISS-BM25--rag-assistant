[site]: crossvalidated
[post_id]: 579589
[parent_id]: 
[tags]: 
Classifier as loss function for image generation, "tricked" too easily

I have a StyleGAN model for which I want to manipulate some properties of the generated image, e.g. eyes being opened/closed [1]. I finetuned a classifier (using pretrained ConvNeXt) on subset of 500 samples with closed eyes and 500 samples with opened eyes. My data is not very diverse but I also used lot's of augmentation to help with that [2]. The classifier works really well when applied to other images from the same dataset (for which I don't have labels). I then apply[3] classifier to StyleGAN model which quickly progresses towards 1.0 prediction, yet it's pretty obvious it "tricked" the classifier, i.e. it "closed eyes" by painting black some regions roughly around eyes. This makes sense to me, my classifiers learned (in most efficient way) someimage features that are very different from my definition of open/closed eyes. Unfortunately I am missing some ML/vision fundamentals to figure out how to try to fix this. I have tried different amount of finetuning in case my model is overfit, but the result is always roughly the same. Should I collect more data? Any anecdotal examples? 5k/50k/500k images? Or is my approach fundamentally wrong and I should be looking somewhere else? [1] I am familiar with many other techniques to do so, but I specifically want to explore classifier based approach. [2] Here is my augmentation config in fastai augmentations = [ Warp(p=0.5), Rotate(15, p=0.5, mode='bilinear'), Brightness(max_lighting=0.3,p=0.5), Contrast(max_lighting=0.4, p=0.5), Flip(p=0.5), Hue(p=0.5, max_hue=0.9), Saturation(p=0.5), RandomErasing(p=0.5, sh=0.1), RandomResizedCropGPU(256, p=0.5, min_scale=0.5, max_scale=1.2), Warp(p=0.5) ] [3] Using my classifier as loss function for input optimization.
