[site]: crossvalidated
[post_id]: 460039
[parent_id]: 459504
[tags]: 
There are several ways of dealing with the problem: 1) You may treat you feature data as time series and then employ time series models such as RNNs, LSTMs etc. These models come along with a large number of parameters though. 2) You may treat you feature data as time series and then extract time series features (mean, max and the like). There are automated tools for that, such as TSfresh ( https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwi1iYDU9ePoAhWh8uAKHYMUB5AQFjAAegQIBBAB&url=https%3A%2F%2Freadthedocs.org%2Fprojects%2Ftsfresh%2Fdownloads%2Fpdf%2Flatest%2F&usg=AOvVaw1CI4BY7i0vxThJC4C5QAmZ ) 3) You may indeed employ all of the $FxH$ features in your model, as you've described, provided the total number of features doesn't blow up in comparison to the number of data points (alerts) in your training set 3) If your training set is too small for (3), which most likely is the case, then go for dimensionality reduction (PCA etc.) to boil down your vast feature set. Hope this helps...
