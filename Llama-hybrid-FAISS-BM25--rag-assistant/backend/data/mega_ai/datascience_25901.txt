[site]: datascience
[post_id]: 25901
[parent_id]: 25891
[tags]: 
The choice of the metric is somewhat dependent on how you are representing the text. A common metric for vector space models would be cosine similarity. Cosine similarity: K(X, Y) = / (||X||*||Y||) Blockquote My initial thought was that, for example, in logistic regression, the normalisation used would be L1 (Manhattan) or L2 (Euclidean). Would this be correct? In vector space models for text representation, the vectors are from a high dimension and sparse. When using L2 or L1 norm, there will be a term for every dimension which has a term in either vector. However, for consine similarity, since it is a dot product, there will only be a term when both elements in either vector is non-zero. The sparsity renders the consine similarity a better choice for such comparisons.
