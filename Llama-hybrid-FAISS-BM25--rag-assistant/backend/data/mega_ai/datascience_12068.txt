[site]: datascience
[post_id]: 12068
[parent_id]: 
[tags]: 
Account for unknown error in time series data

Given: Time series data collected from sensors. There is an unexpected gradual drop in the initial data when sensors are idle. However, this drop is not so visible when sensors are active because the drop is masked by the actual measurements. Main question: How do I eliminate this drop from the sensor output? Not sure if this is an accurate assumption, but let's assume that the drop is a convolution of an unknown system X (leak, sensor drift etc.) with the system being measured G. I am feeding this into a neural network. How do I get an approximation to the unknown influence X (from initial data)? My goal: Apply (-X) to all other data collected from G before training the neural net and expect an increase in performance. Should I expect an increase in performance?
