[site]: stackoverflow
[post_id]: 5203100
[parent_id]: 5202721
[tags]: 
As others have said in their comments you really don't want to attempt to write an HTML parser by iterating over input as a series of characters. Your code fragment's references to tell() and read() methods suggest that you're thinking of this in terms of walking through an open file rather than even thinking at the higher level (a document read into a buffer as a string). There are a number of tools already written, freely available, widely tested, well maintained and broadly acclaimed which are designed specifically to perform this sort of task for you. The most popular of these, by far, is one called "BeautifulSoup" which is famed for its robustness and tolerance of the sort of HTML that's found "in the real world." The goal of BeautifulSoup is, roughly speaking, to parse any HTML that your browser would reasonably display. Thus it can handle a wide variety of extremely common errors in HTML --- improperly nested tags, containers with missing closing tags, non-standard "tags" and tags with nonstandard and ill-formed attributes and attribute=value pairs and so on. Here's an extremely simple example of some Python code using BeautifulSoup: #!/bin/env python import urllib2 from BeautifulSoup import BeautifulSoup def get_page(url): fetcher = urllib2.urlopen(url) results = fetcher.read() fetcher.close() return results def find_tags(data): results = list() parser = BeautifulSoup(data) results.extend(parser.findAll()) return results if __name__ == '__main__': import sys, time for url in sys.argv[1:]: html=get_page(url) for n, each in enumerate([str(x) for x in find_tags(html)]): print n, each, '\n\n\n' ... as you can see the references to BeautifulSoup only account for a few of the lines here. The rest is fetching the HTML and printing the results. These results, incidentally, aren't quite what you're looking for in that they represent a depth-wise traversal of each HTML container from the outermost down through the and its components, and thence through the and its components, etc. In your code you'll probably want to traverse this tree and determine when you're at a leaf and then capture text/contents or tags/code in some way as you do so. You'll want to read the BeautifulSoup: Documentation for details that will match your needs more precisely.
