[site]: crossvalidated
[post_id]: 529981
[parent_id]: 
[tags]: 
Kernel trick to logistic regression

Why can't I apply the kernel trick in logistic regression? My reasoning is: in SVM the logit is: $z = \sum_i \alpha_i K(x_i, x) + b$ Where K is the kernel function. In logistic regression you have to minimize the cross entropy, that depends on the sigmoid function of the logit. But it still holds the formula for the logit (or, at least, it looks like this to me), so what is the problem in using the kernel trick here? Is it because you also have to map $y_i$ in the higher space?
