[site]: crossvalidated
[post_id]: 263595
[parent_id]: 263425
[tags]: 
It's not only the "average thorax width" coefficient that differs between the models. The signs of the coefficients for the categorical predictor variables differ, too. These differences arise from the different choices about the reference levels for categorical variables between R and SPSS. For categorical variables, R by default chooses the lowest level as the reference while SPSS chooses the highest. So for a 2-category predictor like your "Treatment" the signs of the coefficients will be opposite. When you include an interaction term in a model, you need to be very careful in thinking about what the coefficients mean. The coefficient for a continuous variable that has an interaction with a categorical variable will be reported as its value when the categorical variable is at its reference level . To get its coefficient for a non-reference level of the categorical variable, you add to that the interaction coefficient. R and SPSS, as you have used them, differ in their choice of categorical reference levels so they report different values for the "average thorax width" coefficient, and they report opposite signs for the interaction coefficient. As @mdewey implies in comments, R and SPSS thus produce the same coefficients for "average thorax width" at both levels of the "Treatment" variable when you take the difference in categorical reference levels into account. Added in response to comment: In your particular application, you are under-powered to test this many coefficients. The usual rule of thumb in Cox or logistic regressions is to have about 15 events per predictor variable being considered. (For this, interaction terms count as predictor variables.) Your 53 events thus would limit you to about 3 predictors, while your model includes 6. Note that your overall model does not reach standard statistical significance ( p -value is > 0.05 for the omnibus tests), so you should not be paying much attention to the individual regression coefficients anyway. This model is not significantly different, by standard frequentist criteria, from no model at all. You might consider a model without interaction terms, particularly as this analysis shows that they are far from significant. That would bring you down to 4 predictors. The p -value calculations wouldn't strictly be correct any more, as this simpler model will have been designed only after you saw the results of this larger model. That distinction, however, is often ignored in practice. And more data seldom hurt.
