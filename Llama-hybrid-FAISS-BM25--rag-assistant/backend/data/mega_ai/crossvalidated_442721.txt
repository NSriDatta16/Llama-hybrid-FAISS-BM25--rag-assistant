[site]: crossvalidated
[post_id]: 442721
[parent_id]: 442714
[tags]: 
Thinning has nothing to do with Bayesian inference, but everything to do with computer-based pseudo-random simulation. The whole point in generating a Markov chain $(\theta_t)$ via MCMC algorithms is to achieve more easily simulations from the posterior distribution, $\pi(\cdot)$ . However, the penalty for doing so is creating correlation between the simulations. (With respect to the question, this correlation persists even asymptotically in $t$ .) By subsampling or thinning out the Markov chain $(\theta_t)$ , this correlation is usually (but not always) reduced as the thinning interval grows. Thinning has however nothing to do with convergence of the Markov chain to the stationary distribution $\pi(\cdot)$ since it is a post-processing of the simulated Markov chain $(\theta_t)$ . Thinning only makes sense once the chain is (approximately) stationary. Removing early values of the Markov chain to eliminate the impact of the starting value is called burning or warmup. Note furthermore that thinning is rarely helpful when considering approximations of posterior expectations (by the Ergodic Theorem) $$\frac{1}{T}\sum_{t=}^T h(\theta_t) \longrightarrow \int h(\theta(\pi(\theta)\text{d}\theta$$ since using the entire (unthinned) chain most often reduces the variance of the approximation. If specific needs call for an almost iid sample from $\pi(\cdot)$ , thinning may appeal, but except for specific situations where renewal can be implemented, there is no guarantee that the sample will be either "i" or "id"... The alternative solution of running several chains independently in parallel produces independent samples but again with rarely a guarantee that the points are exactly distributed from $\pi(\cdot)$ .
