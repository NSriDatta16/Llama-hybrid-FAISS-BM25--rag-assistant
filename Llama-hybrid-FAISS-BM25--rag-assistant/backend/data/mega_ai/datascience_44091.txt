[site]: datascience
[post_id]: 44091
[parent_id]: 
[tags]: 
Is empirical risk the same thing as loss function?

I am reading the article Stochastic Gradient Descent Tricks by LÃ©on Bottou (avaible here ) and on the very first page they introduce empirical risk $E_n(f) = \frac{1}{n} \sum_{i=1}^{n} l(f(x_i),y_i),$ where $l(f(x),y)$ is a loss function, that measures the cost of predicting $f(x)$ when the actual answer is $y$ . Then, there is written: We seek the function $f \in \mathcal{F}$ that minimizes the loss $Q(z,w) = l(f_w(x),y)$ averaged on the examples. I fail to see the difference between empirical loss and the $Q$ loss function, can anybody provide explanation? Also I am not native speaker so there might be misunderstanding in "averaged on examples".
