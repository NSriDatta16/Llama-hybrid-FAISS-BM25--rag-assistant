[site]: datascience
[post_id]: 71952
[parent_id]: 
[tags]: 
BERT classifier with Ktrain API is unable to predict new data

I have trained a classifier for sentiment analysis using BERT architecture. I am able to train the classifier and I am getting a validation accuracy of 87%. But whenever I feed in test data, or some simple sentence like "What an amazing movie", "I would love that book", etc, the model predicts the class for one and says list index out of range for other. I tried to find if there is a bug in my code as well. (x_train, y_train), (x_test, y_test), preproc = text.texts_from_csv(TWITTER, preprocess_mode='bert', text_column = 'text', label_columns = ['target']) model = text.text_classifier('bert', (x_train, y_train), preproc=preproc) learner = ktrain.get_learner(model,train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=6) learner.fit_onecycle(2e-5, 1) predictor = ktrain.get_predictor(learner.model,preproc) predictor.predict(['I am very happy to meet you!']) Error that I am getting IndexError Traceback (most recent call last) in () ----> 1 predictor.predict(['I am very happy to meet you!']) 1 frames /usr/local/lib/python3.6/dist-packages/ktrain/text/predictor.py in (.0) 56 preds = np.squeeze(preds) 57 if len(preds.shape) == 0: preds = np.expand_dims(preds, -1) ---> 58 result = preds if return_proba or multilabel or not self.c else [self.c[np.argmax(pred)] for pred in preds] 59 if multilabel and not return_proba: 60 result = [list(zip(self.c, r)) for r in result] IndexError: list index out of range My problem is that if I have any bugs in my code, then I should get this error every time I execute the predict method. Say I have 100 new test points, I am getting this error only for 30 to 40 test points and the remaining are classified properly. I tested this theory by feeding in tweets one tweet at a time. But I do not understand why is this happening.
