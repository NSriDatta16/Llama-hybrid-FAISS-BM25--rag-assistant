[site]: crossvalidated
[post_id]: 380203
[parent_id]: 380201
[tags]: 
For linear models, the intercept is the value of the linear predictor when all covariates are zero. In linear regression, this is equivalent to the y-intercept of the line of best fit. In logistic regression, it is the log odds of the baseline group. Suppose we did not add an intercept term for the regression. We would then be positing that when all covariates are 0, the linear predictor is 0. In summation, we add the bias to improve interpretability and add flexibility to the model. Having no independent variables means no prediction can be made. Suppose you have a model for cancer incidence based on age. Since you do not know my age, you can not put my data into your model, and thus you can not make predictions.
