[site]: crossvalidated
[post_id]: 337595
[parent_id]: 337592
[tags]: 
You can use Random Forest to check for feature importance as follows: from sklearn.datasets import load_boston from sklearn.ensemble import RandomForestRegressor import numpy as np #Load boston housing dataset as an example boston = load_boston() X = boston["data"] Y = boston["target"] names = boston["feature_names"] rf = RandomForestRegressor() rf.fit(X, Y) print "Features sorted by their score:" print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True) The above code snippet is borrowed from here . You can also try Logistic Regression by fitting a Logistic Regression checking the coefficients of different independent variables. log_reg.fit(X, Y) log_reg.coef_
