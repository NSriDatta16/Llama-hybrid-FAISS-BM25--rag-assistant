[site]: crossvalidated
[post_id]: 355552
[parent_id]: 355169
[tags]: 
The general approach you are after is termed 'imputation' (or 'multiple imputation', though that typically includes a subsequent analysis step as well). Broadly speaking, this involves filling in (i.e. imputing) missing values in datasets. There are a variety of techniques that can be used for this, which fall into two broad classes. Fill in the missing values with guesses based on the non-missing values of the same variable. Typically, the mean (or median, mode, etc.) of the non-missing values is used as the best guess for the missing values. Note that this approach does not use the information on the relationships between variables. A better approach is to construct a model based on the non-missing values, and use this to predict the missing values. In your case, this model could be a multiple linear regression, random forest, gradient boosting machine, or other such technique. The second approach has an additional advantage: it can incorporate uncertainty in imputed values. Basically, you can generate a number of different imputed datasets, each of which differs in its imputed values to a degree based on the uncertainty in the underlying model. For example, if a multiple regression identifies at best a weak relationship between parameter A and the remaining parameters, then each imputed dataset will have large differences in the imputed values for parameter A. Conversely, if parameter B is strongly explained by the remaining parameters, the imputed datasets will vary only slightly in the imputed values of parameter B. The utility of incorporating this uncertainty is that subsequent analyses can be run for each imputed dataset, and then the results across all imputed datasets pooled to generate a final answer that accounts for imputation uncertainty. So I would approach your problem by: Pooling your data from all experiments. Generating a large number of imputed datasets (using the second approach). Running identical analyses on each imputed dataset. Finally, pooling the results from all imputed datasets. If you use R , these imputation approaches (with several variants) and the subsequent pooling of analyses can be done with the mice package. This is a tutorial explaining how to do this using the mice package. And a book describing the approach by the author of the package: Van Buuren, S. (2012). Flexible imputation of missing data. Chapman and Hall/CRC. Also take a look at the multiple-imputation tag for related questions: https://stats.stackexchange.com/questions/tagged/multiple-imputation?sort=votes&pageSize=50
