[site]: crossvalidated
[post_id]: 551115
[parent_id]: 551108
[tags]: 
The answer is no, too many claims in your post, not only to the main question. The difference between ML and stats is arbitrary, superficial, and not important. There is plenty of statisticians that are doing predictive models where the main goal is, of course prediction. Common machine learning methods have been developed by statisticians and published in statistical journals. The most popular ML book is the elements of statistical learning, after all. Also, there is a huge subfield of ML that is concerned about the interpretation of fitted models and the effects of individual variables. I can tell you that (at least contemporary) papers discussing differences between ML and stats are cynical citation grabs and not really worth the time. Both ML and stats are concerned about learning the underlying pattern from the data. In stats, this might be called estimating effects, but it is the same thing. "[in ML] We never want to have a perfect fit of the model into the training data." Sometimes you do (search double descent) Statisticians do care about the generalization. I would even say more than ML people. All these statistical concepts, like controlling for type I error, confidence intervals, credible intervals etc., are there to tell you how well your findings generalize to the population. Now, if a machine learner tests 2 models in a test set and one is better than the other, this does not tell you much about how this finding will generalize to the population unless you calculate some standard errors, p-values or something on that difference. This is usually not the problem in computer vision with hundreds of thousands of examples, where pretty much any difference will be significant, but it is important in smaller problems. If a model has large goodness of fit because it is overfitted, p/t/F values will not be good, and statisticians will not find significant results in that scenario. In this case, variables will be colinear, standard errors will be huge, and nothing will be significant. in stats, we are often not using test sets because these statistical procedures had been developed to be valid without the need of the test set. If I use F-test to compare which model is better, the results will be generalization to the population because that's what the test is for. It will not automatically select the model with a higher R2. In summary, statisticians are concerned about the generalization, and the common statistical measures and concepts are there for this purpose. On the other hand, ML people are often not interested in generalization because simple CV or test set performance is often not treated as an estimate of the performance in the population,
