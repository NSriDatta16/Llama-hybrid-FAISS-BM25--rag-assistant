[site]: crossvalidated
[post_id]: 110990
[parent_id]: 28968
[tags]: 
Multiple output decision trees (and hence, random forests) have been developed and published. Pierre Guertz distributes a package for this ( download ). See also Segal & Xiao, Multivariate random forests, WIREs Data Mining Knowl Discov 2011 1 80â€“87, DOI: 10.1002/widm.12 I believe the latest version of Scikit-learn also supports this. A good review of the state of the art can be found in the thesis by Henrik Linusson entitled "MULTI-OUTPUT RANDOM FORESTS". The simplest method for making the split choices at each node is to randomly choose ONE of the output variables and then follow the usual random forest approach for choosing a split. Other methods based on a weighted sum of the mutual information score with respect to each input feature and output variable have been developed, but they are quite expensive compared to the randomized approach.
