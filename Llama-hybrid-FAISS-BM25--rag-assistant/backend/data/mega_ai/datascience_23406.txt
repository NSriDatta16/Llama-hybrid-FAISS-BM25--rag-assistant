[site]: datascience
[post_id]: 23406
[parent_id]: 19124
[tags]: 
Let's say we want to predict if a student will land a job interview based on her resume. Now, assume we train a model from a dataset of 10,000 resumes and their outcomes. Next, we try the model out on the original dataset, and it predicts outcomes with 99% accuracy… wow! But now comes the bad news. When we run the model on a new (“unseen”) dataset of resumes, we only get 50% accuracy… uh-oh! Our model doesn’t generalize well from our training data to unseen data. This is known as overfitting, and it’s a common problem in machine learning and data science. Overfitting V/s Underfitting We can understand overfitting better by looking at the opposite problem, underfitting. Underfitting occurs when a model is too simple – informed by too few features or regularized too much – which makes it inflexible in learning from the dataset. Simple learners tend to have less variance in their predictions but more bias towards wrong outcomes (see: The Bias-Variance Tradeoff). On the other hand, complex learners tend to have more variance in their predictions. Both bias and variance are forms of prediction error in machine learning. Typically, we can reduce error from bias but might increase error from variance as a result, or vice versa. This trade-off between too simple (high bias) vs. too complex (high variance) is a key concept in statistics and machine learning, and one that affects all supervised learning algorithms.
