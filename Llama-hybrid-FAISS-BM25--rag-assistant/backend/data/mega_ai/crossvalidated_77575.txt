[site]: crossvalidated
[post_id]: 77575
[parent_id]: 
[tags]: 
Bayesian Aproach: Infering the N and $\theta$ values from a binomial distribution

I am doing a homework about infering the N value of a binomial distribution for my Bayesian Statistics Course and I have seen a paper in Biometrika magazine published in 1988 for doing so. The question is how to simulate the N and $\theta$ values based on their respective marginal posteriors. The properties about the model are explained below: $$X\sim Binom(N,\theta)$$ The priori distribution of N:$$ N\sim Poisson(\mu)$$ $$\lambda = \mu\theta$$(The logic here is that it may be easier to formulate a prior considering the unconditional expectation of the observations, rather than the mean of the unobserved N). The $\lambda$ and $\theta$ a prior are distributed as:$$\lambda \sim Gamma(\kappa_{1},\kappa_{2})$$ $$\theta\sim Beta(\alpha,\beta)$$ After doing the procedings found on the paper which this link is below, the N marginal posterior is the following one: $p(N|x_{1},x_{2},..,x_{n})\propto(N!)^{-1}\Gamma(N+\kappa_1)\{\prod_{i=1}^5\dbinom{N}{x_i}\} \int_0^1 \! \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{-N+S+\alpha-1}(1-\theta)^{nN-S+\beta-1}(\theta^{-1}+\kappa_{2})^{(N+\kappa_{1})} \, \mathrm{d}\theta $. How can create a random variable generator from that marginal probability function? Then, I suppose that this integral:$ \int_0^1 \! \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{-N+S+\alpha-1}(1-\theta)^{nN-S+\beta-1}(\theta^{-1}+\kappa_{2})^{(N+\kappa_{1})} \, \mathrm{d}\theta $ represents part of the marginal posterior of $\theta$ but I don´t know if this is true, My second question is that: Which could be the marginal distribution function for $\theta$? and How can I create a random variable function for getting $\theta$ values? . I attached the paper I 've working with, the only thing I added is a Beta prior distributión for $\theta$. http://ftp.stat.washington.edu/raftery/Research/PDF/bka1988.pdf
