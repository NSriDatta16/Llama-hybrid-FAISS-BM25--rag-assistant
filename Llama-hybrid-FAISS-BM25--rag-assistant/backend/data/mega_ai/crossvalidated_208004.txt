[site]: crossvalidated
[post_id]: 208004
[parent_id]: 
[tags]: 
Efficiently sampling from Markov Chain with low-probability transitions

I need to sample a large number of paths from a Markov Chain with known state transition matrix $T$, where some of the state transitions are low probability (~0.01%). For example, I might have a large collection of products that can migrate through various states, including to a low probability failure state. By repeatedly simulating a path for each product I can characterize the number of failures across the whole collection, as well as other sample statistics (as I've described it I wouldn't need to use simulation, but the real situation is a little more involved). Because some of the simulations are very low probability, I need to generate a very large number of paths to come up with a stable answer. I wonder if there are any typical ways of making this more computational efficient, for example somehow oversampling the low-probability events and then re-weighting them later.
