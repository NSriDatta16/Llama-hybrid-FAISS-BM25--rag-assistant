[site]: datascience
[post_id]: 49007
[parent_id]: 49006
[tags]: 
Assuming you are using Python, an easy way to do this is to use utilities available in scikit-learn: from sklearn.datasets import load_svmlight_file, dump_svmlight_file from sklearn.model_selection import train_test_split # load features and labels X, y = load_svmlight_file('path/to/libsvm/data') # split into train/test sets (change test_size if you like) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # write the train & test datasets to disk dump_svmlight_file(X_train, y_train, 'train.svm') dump_svmlight_file(X_train, y_train, 'test.svm') In reference to your comment It seems to me that the algorithm should just require a single full set of data, use all of the data to train and build a model, and then apply that model to the original data set and determine if the labels are being assigned "0 or 1" accurately. I would recommend reading about overfitting . In short, overfitting happens if your model is very good at classifying the data that you used to train the model, but performs poorly on unseen data. If you fit a model to a dataset, and then test the model on the same dataset, you will likely get very optimistic estimates for performance that may lead you to believe that your model is much better than it actually is. After finding a set of hyper-parameters that work well and testing to ensure that your model isn't overfitting, you can train the model on the full dataset using the hyper-parameters that worked. Some good references on overfitting: Why Is Overfitting Bad in Machine Learning? Overfitting in Machine Learning: What It Is and How to Prevent It
