of disillusionment" phase. Applications Notable types of generative AI models include generative pre-trained transformers (GPTs), generative adversarial networks (GANs), and variational autoencoders (VAEs). Generative AI systems are multimodal if they can process multiple types of inputs or generate multiple types of outputs. For example, GPT-4o can both process and generate text, images and audio. Generative AI has made its appearance in a wide variety of industries, radically changing the dynamics of content creation, analysis, and delivery. In healthcare, for instance, generative AI accelerates drug discovery by creating molecular structures with target characteristics and generates radiology images for training diagnostic models. This ability not only enables faster and cheaper development but also enhances medical decision-making. In finance, generative AI services help create datasets and automate reports using natural language. It automates content creation, produces synthetic financial data, and tailors customer communications. It also powers chatbots and virtual agents. Collectively, these technologies enhance efficiency, reduce operational costs, and support data-driven decision-making in financial institutions. The media industry makes use of generative AI for numerous creative activities such as music composition, scriptwriting, video editing, and digital art. The educational sector is impacted as well, since the tools make learning personalized through creating quizzes, study aids, and essay composition. Both the teachers and the learners benefit from AI-based platforms that suit various learning patterns. In the educational field, in Colombia, student use of Meta's generative AI programs resulted in a decline in scores. Text and software code Large language models (LLM) are trained on tokenized text from text corpora. Such systems include ChatGPT, Gemini, Claude, LLaMA, and BLOOM. LLMs are capable of natural language processing, machine translation, and natural language generation. LLMs can be used as foundation models for other tasks. They can be trained on computer code, which makes it possible to generate source code for new computer programs with prompts, a practice known as vibe coding. Examples include OpenAI Codex, Tabnine, GitHub Copilot, Microsoft Copilot, and the VS Code fork Cursor. Some AI assistants help candidates cheat during online coding interviews by providing code, improvements, and explanations. Their clandestine interfaces minimize the need for eye movements that would expose cheating to the interviewer. Audio In 2016, DeepMind's WaveNet showed that deep neural networks are capable of generating raw waveforms. WaveNet's ability to model raw waveforms meant that it could model any kind of audio, including music: for example, it was capable of generating relatively realistic-sounding human-like voices by training on recordings of real speech. In subsequent years, research shifted from concatenative synthesis to deep learning speech synthesis, with models like Tacotron 2 in 2018 demonstrating that neural networks could convert text into natural speech by being trained on tens of hours of speech. In 2020, a free text-to-speech website called 15.ai showed that deep neural networks could generate emotionally expressive speech with only 15 seconds of speech, a large reduction compared to the tens of hours of data previously required. Other platforms that use generative AI to produce speech include Amazon Polly, Meta's Voicebox, and ElevenLabs. Systems that can generate music via text descriptions (text-to-music) include Meta's MusicGen and Google's MusicLM. Audio deepfakes have been used to generate vocal tracks of lyrics that mimic the voices of other singers. Images Generative AI can be used to create visual art. Such systems are trained on sets of images along with their text captions. Examples of text-to-image models include Stable Diffusion, DALL-E, Midjourney, Imagen, Adobe Firefly, and Flux. 