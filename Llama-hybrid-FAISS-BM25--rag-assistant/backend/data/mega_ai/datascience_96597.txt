[site]: datascience
[post_id]: 96597
[parent_id]: 96571
[tags]: 
In short: what you can learn is that you data variability is distributed on multiple of the orthogonal dimensions and PCA can not reduce it further. Longer: In an extreme scenario, imagine you have four features/dimensions which have variability distributed across all dimension. It is hard to think of a four dimension object but think you have a perfect cube (three dimension) which each edge get various multiple color (the fourth dimension). Here is a dedicated post on understanding geometrically four dimension object Since all these dimensions are orthogonal (in this example the color is not but just imagine it meets the statistical assumption of the PCA) the PCA can not do much. (In fact PCA of a cube, is a cube and nothing less). What you can do : explore some non-linear dimension reduction - Principle Components from PCA are orthogonal - perhaps if you choose a non-linear method, you find subset of dimensions which can carry the variability - but you won't get anything less than four - but more PCs. Still I doubt you can reduce that it.
