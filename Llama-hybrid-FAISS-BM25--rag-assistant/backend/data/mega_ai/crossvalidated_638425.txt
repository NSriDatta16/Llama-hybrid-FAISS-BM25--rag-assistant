[site]: crossvalidated
[post_id]: 638425
[parent_id]: 638422
[tags]: 
You can always run a validation/simulation: take your dataset, split it, use part of it that has balanced classes for training, and in the second part, if there is balance, random sample one of the classes, then perform validation. This way you will find out whether metrics (e.g., true positive rate, or false positive rate) will be the same for training as for the validation. I would guess that they will be different, but I am not a data science theoretician, so I would simply do an experiment and find out.
