[site]: crossvalidated
[post_id]: 149293
[parent_id]: 149274
[tags]: 
That's a little bit confusing. If you are doing logistic regression, you predict binary class memberships, e.g., 0 and 1. The class label is basically the outcome of a thresholding function that is $sigmoid(z) \ge 0.5 \rightarrow 1 $, and 0 otherwise. where $z = w^Tx$ (w=weights, x=sample), and $sigmoid$ is the inverse-logit function $\frac{1}{1 + e^{-z}}$ or equivalently to save this one step of computation you can directly compute: $z \ge 0 \rightarrow 1 $, and 0 otherwise. The conditional probability $p = sigmoid(z)$ is basically your "confidence". I think what you want is the confidence of this probability? You could do this by calculating the standard error of your prediction on the linear scale $w^Tx$, and then calculate the upper and lower bounds of your, e.g., 95%, confidence interval via $[ pred. value +/- 1.96\times std. err ]$. After you obtained the upper and lower bounds, you can use the sigmoid function to transform those onto the logit scale.
