[site]: crossvalidated
[post_id]: 562520
[parent_id]: 
[tags]: 
Why binary classification with highly imbalanced dataset output low probs?

I'm doing a frauds detection project which is using imbalance dataset(almost, 9:1). And I using logistic, xgboost, and ligthgbm for Binary Classification. When I predict my test set, I see all of Target's probabilities are so low. Is it wrong for my models? or Is it natural for imbalanced case?
