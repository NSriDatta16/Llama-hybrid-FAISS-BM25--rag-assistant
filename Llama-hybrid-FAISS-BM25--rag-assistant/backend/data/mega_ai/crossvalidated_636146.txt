[site]: crossvalidated
[post_id]: 636146
[parent_id]: 
[tags]: 
Sensitivity Analysis for Raw Model Output or Model Predictions?

For a variety of reasons, many researchers have suggested that, for attempting to make causal inferences with non-linear statistical models, one should generally avoid endowing a causal interpretation to raw model output ( Mood 2009 , Daniel et al. 2020 , Norton et al. 2019 , Long and Mustillo 2018 ). Instead, model predictions can be used to evaluate the causal effect (assuming identifying assumptions hold) of a given treatment. One popular strategy to obtain model predictions is the estimation of marginal effects. However, even following the estimation of marginal effects, an estimated marginal effect from an observational study is, by itself, not indicative of a causal relationship. The primary culprit generating suspicion is the potential for unadjusted confounding biasing a marginal effect estimate. As a result, a key tool to lend credibility or to cast further suspicion on a given estimate are sensitivity analyses. I am fairly familiar with the sensitivity analyses developed by Cinelli et al. 2020 and McGowan 2022 . However, these sensitivity analyses examine how much a given coefficient, ratio, etc. would shift under a set of assumptions. However, if I am not interested in the raw output of a model, how much should I care about the sensitivity of such a coefficient, ratio, etc. in the first place? Or is the sensitivity to the raw model output analogous to the sensitivity (sensitivity to unspecified confounding) of a model prediction such as an average marginal effect?
