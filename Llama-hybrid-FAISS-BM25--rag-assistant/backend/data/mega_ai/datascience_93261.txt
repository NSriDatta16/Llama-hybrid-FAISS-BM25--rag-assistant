[site]: datascience
[post_id]: 93261
[parent_id]: 93253
[tags]: 
The reason to average the embedded vectors of the words in a paragraph or document is to obtain a single fixed-size vector that represents the whole text. Then, the document-level vector can be used as input to a document classification model or any other document-level model. If you explicitly want to compute word-level representations and then combine them into a document/paragraph-level representation, then averaging is the standard approach. On the other hand, to obtain document/paragraph/sentence-level representations in general, there are many alternatives to combining word-level vectors. Some remarkable examples include doc2vec for paragraph/document-level, or LASER or BERT for sentence-level representations.
