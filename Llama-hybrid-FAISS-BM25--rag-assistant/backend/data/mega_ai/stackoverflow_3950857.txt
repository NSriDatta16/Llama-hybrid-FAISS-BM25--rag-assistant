[site]: stackoverflow
[post_id]: 3950857
[parent_id]: 
[tags]: 
fetch pages [LWP] parse them [HTML::TokeParser] and store results [DBI]

A triple job: I have to do a job with tree task. We have three tasks: Fetch pages Parse HTML Store data... And yes - this is a true Perl-job! I have to do a parser-job on all 6000 sub-pages of a site in suisse. (a governmental site - which has very good servers ). see http://www.educa.ch/dyn/79362.asp?action=search and (if you do not see approx 6000 results - then do a search with . A detailed page is like this: [link text][1] Ecole nouvelle de la Suisse Romande Ch. de Rovéréaz 20 Case postal 161 1000 Lausanne 12 Website info@ensr.ch Tel:021 654 65 00 Fax:021 654 65 05 another detailed pages shows this: educa.ch Adresse - Schulen in der Schweiz &#160; Auseklis - Schule für lettische Sprache und Kultur &#160; Mutschellenstrasse 37 8002&#160;Zürich &#160; latvia.yourworld.ch schorderet@inbox.lv &#160; Tel: +41786488637 Fax: &#160; I want to do this job with ** HTML::TokeParser or HTML::TokeParser** or * HTML::TreeBuilder::LibXML * but i have little experience with HTML::TreeBuilder::LibXML Which one would you prefer for this job: Note - I want to store the results in a MySQL-DB. Best things would be to store it immitiately after parsing: so we have three tasks: Fetch pages Parse HTML Store data First item: Use LWP::UserAgent to fetch. There are many examples in this forum of using that module to post data and get the resulting pages. BTW we can use Mechanize instead if we prefer. Second: Parse the page as eg with HTML::TokeParser or some other module to get at only the data we need. Third: Store the data straight away into a database. There is no need to take an intermediate step and write a temporary file. hmmm - the first and the second question - how to fetch and how to parse.
