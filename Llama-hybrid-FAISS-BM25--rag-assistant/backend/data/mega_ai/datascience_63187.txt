[site]: datascience
[post_id]: 63187
[parent_id]: 63185
[tags]: 
They are very different things. sklearn.feature_selection is a general library to perform feature selection. xgboost feature_importances is simply description of how each feature is important (for details should refer in the xgboost documentations) in regards with model-fitting procedure and it is simply attribute and it is up to you how you can use this importance. You can however, apply feature selection on top of xgboost model or models that follow some level of sklearn models api structure, for example using sklearn.feature_selection.RFE .
