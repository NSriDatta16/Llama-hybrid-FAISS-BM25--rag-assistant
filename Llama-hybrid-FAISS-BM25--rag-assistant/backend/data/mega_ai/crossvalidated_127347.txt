[site]: crossvalidated
[post_id]: 127347
[parent_id]: 127340
[tags]: 
It looks like you are interested in tools from text mining . You are on the right track in thinking about that gigantic matrix - it's called a sparse matrix , because most of the elements are zeros. Text mining algorithms work off of that. But don't manually do it, because there are R packages that can already do all of these steps for you. Useful R packages would be: R has some great packages for this: tm rtexttools wordcloud twitteR (this is for pulling tweets in real time, great tool, you just need a Twitter account) They all have good vignettes that can walk you through what you are doing. As far as methods to find common terms, the dominant method to do this is cluster analysis: you look at how tweets can be clustered together based on the terms included in them. There are numerous cluster analysis algorithms used, ranging from more rudimentary (like k-means) to much more complex (like latent Dirichlet allocation, or LDA). I would not recommend getting into something like LDA until you are pretty comfortable with what it is actually doing. I'm no expert in it, but when I've used it I've found it fairly difficult to interpret the results. You also want to consider how you will clean up the tweets. This includes things like: - Removing stop words (like "the" "is", etc. - removing case (i.e. making everything lower case) - dealing with emoticons - dealing with negation ("no","not","isn't","ain't",etc) - stemming (e.g. converting words like "transformer", "transforming" to "transform") This Web page gives a decent introduction with working examples in R. There is actually a substantial amount of work on text mining tweets. A lot of it is for sentiment analysis, a thriving area. Some of it is to identify themes, though in my limited experience the shortness of tweets makes it very difficult to extract too much common meaning, though if you have a subset of tweets that are related to a similar topic you may be better off.
