[site]: crossvalidated
[post_id]: 475167
[parent_id]: 475159
[tags]: 
The reason that $R^2$ is dubious for a model without an intercept is because it compares the model fit (sum of squares errors) to the fit for a model with just an intercept. However, by expressing interest in $R^2$ , you are saying that the sum of squared errors interests you. So compare the sum of squared errors! What you lost when you do this is the ability to gauge if a model is doing a decent job of predicting. It sounds good to get $R^2=0.95$ ; the model explains most of the variability. If your sum of squared errors is $17$ that’s fairly meaningless. However, that model has a better fit than a model with a sum of squared errors of $37$ . You can compare the sum of squared errors for any two models on the same data set. It sounds like you’re doing linear models, but it would be perfectly valid to compare to the sum of squared errors of a random forest model (for instance). Out-of-sample testing might be a topic that interests you for this work. And as EngrStudent wrote, there could be many other viable metrics, depending on what you value. Sum of squared errors seems to be the default in the absence of an argument for another metric, however.
