[site]: crossvalidated
[post_id]: 509058
[parent_id]: 
[tags]: 
Whats exactly deterministic and non deterministic in deterministic and nondeterministic MDP policies?

Consider below Markov Decision Process: Blue hexagons are states and orange circles are actions. I have rather simple confusion. What will be nature of deterministic and non deterministic MDPs? This confusion stems from the fact that I don't know if probabilities are specified for actions or for next state. In the diagram, probabilities seem to have specified for next states. For example, from (S3,a1), S4 will be next state with probability 0.6 and S1 will be next state with probability 0.4. Q1. But I was guessing can MDP also specify probabilities with which a1 and a2 are followed from S3. If answer to Q1 is yes, then Q2. What deterministic policy will specify, fixed action and next state for given state, or just fixed action? That is, from S3, we can take a1 and go to S4 vs we can take a1 (and go to either S4 or S1 with corresponding probabilities)? Q3. Similar to Q2, what non deterministic policy will specify? PS: please note that the title of question is single and self-sufficient. I formed these sub questions to help answerer to better answer by explicitly focusing on them. Answering these three subquestions will completely answer original question in the title.
