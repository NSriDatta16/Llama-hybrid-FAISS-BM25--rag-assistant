[site]: crossvalidated
[post_id]: 491613
[parent_id]: 
[tags]: 
Focal Predictions from a linear model: How to test for difference between factor levels (pairwise) instead of comparing errorbars?

Sorry for the cluelessness, I know this is a topic that arises often in different variations. Still, I couldn't find an answer for my situation. In my work, I sample people and try to generalize the results to say something meaningful about the population from which the sample was taken. To do so, I typically need to account for potential biases in my sample that are due to unrepresentativeness. For example, if I want to study driving habits and ask people how often they speed over the limit, I need to verify that variables such as age or gender -- in the sample I work on -- are distributed in a similar way to the entire population I wish to say something about. Otherwise, if I remain oblivious to influences of confounding variables (e.g., risky driving habits are more likely in young male adults), and take my sample as-is without accounting for those variables, it would damage the validity of any conclusions I would make regarding the population. My solution for addressing the influence of confounding variables is to run a multiple regression. The predicted variable is my variable of interest, whereas the predictor variables are potential variables that (I have a reason to believe) could confound the results. After fitting the model, I predict. For the predictors, I specify values that are of the "average person in the population". That is, for age I enter the average as it is in the population. For gender , I do something else. If my sample data has gender coded as a factor with 0 / 1 for male/female, then gender for the average person in the population would be 0.5 . The prediction I get reflects the average response in the population, while controlling for confounding variables. If I want to test whether any of those predictors/confounding variables has a significant influence on the predicted variable, I check the model summary and see which predictors are significant (by their p-value). Often, my predictors are factors with multiple levels. For example, when testing driving habits, variable such as education might confound the results. Typically, education is a factor variable with the following levels 1 = no high school diploma / 2 = high school diploma / 3 = 2-yrs at College / 4 = 4-yrs at College or Bachelor degree / 5 = Master's degree / 6 = PhD . When I embark on my investigation and go to sample people, I collect a lot of demographic information. My primary goal when analyzing people's responses is to control for confounding variables while I'm on my mission to say something general about the population. So I throw into the regression any demographic variables that might confound the results. I then predict the "average response in the population" using the method I described above. However, sometimes, after I get my result , I'm curious to see whether a certain predictor happened to be significant in the model. Furthermore, in the case of a factor variable, I'm curious whether different levels of that predictor were different from each other. My go-to solution is to compare errorbars. Do they overlap or don't? But I know this method is inaccurate. So my question is, given the procedure detailed above, how can I compare different pairs of factor levels and say whether the difference I see between those levels is indeed significant, rather than just random error? Demonstrating with an example Multiple linear regression - Measuring Driving habits Data 1000 People answered two questions: "How often do you speed over the limit?" "How often do you text while driving?" Choosing one value on a scale of 0 ( "Never" ) to 5 ( "Always" ). In addition, I measure each person's age, gender, and level of education. person_id q_speeding q_texting age is_female education 1 1 3 4 31 1 3 2 2 2 1 41 1 6 3 3 5 4 25 1 2 4 4 2 1 25 1 1 5 5 3 0 78 1 3 6 6 5 4 64 1 1 7 7 5 5 46 1 1 8 8 3 3 21 1 5 9 9 2 2 56 1 6 10 10 0 1 61 0 1 # ... with 990 more rows Fitting a model lm(person_response ~ age + is_female + education) Predicting the average response in the population (i.e., dealing with sample unrepresentativeness) prediction_data Average response generalized to population level, beyond sample biases Now I wonder... are any predictors significant? Speeding question Call: lm(formula = subject_response ~ age + is_female + education, data = .x) Residuals: Min 1Q Median 3Q Max -2.7880 -1.4289 -0.1604 1.4433 3.4144 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 2.622815 0.196877 13.322 texting question Call: lm(formula = subject_response ~ age + is_female + education, data = .x) Residuals: Min 1Q Median 3Q Max -2.9521 -1.5222 0.2574 1.4463 2.6586 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 2.169711 0.193563 11.209 Given that education seems to be a significant predictor, I want to split up the results by levels of education Diving into the levels of education within each question, I'd like to be able to say which levels differ indeed ("significantly") from each other, and which differences might simply reflect "noise" in the data. So far, I've used the malpractice of comparing errorbars. I know it's not the right way, and I want to do better. In summary I will be thankful for advice on how to achieve the testing for differences between factor levels given the focal predictions I got . It will be helpful if someone could frame my problem in context. I'm familiar with relevant terminology: "setting contrasts", "ANOVA", "pairwise comparisons", "post-hoc comparisons", etc. But I cannot organize all of this in relation to my problem: dealing with predicted data. Any hint on utilizing the relevant code or functions in R would be very helpful too. I'm posting this question here and not on Stack Overflow because I don't know how to begin asking there. This is first and foremost a question about statistics and only afterwards it's a question about implementing it with programming. Appendix -- Code for generating the data, models, and plots ## Data ## library(tidyverse) library(magrittr) set.seed (2022) n % mutate(education = case_when(q_speeding > 3 ~ sample(c(1:6), prob = c(0.5, 0.3, 0.05, 0.05, 0.05, 0.05), size = n, replace = TRUE), q_speeding ## First Plot (Only Means) and Model Underlying It ## ## prediction data ## prediction_data % pivot_longer(starts_with("q_"), values_to = "subject_response") %>% group_by(name) %>% tidyr::nest() %>% mutate(model_fit = map(data, ~ lm(data = .x, subject_response ~ age + is_female + education )), predicted_values = map(model_fit, ~ bind_cols(prediction_data, as.data.frame(predict(newdata = prediction_data, .x, type = "response", se.fit = T))) %>% rowwise() %>% mutate(estimate = fit, conf.low = fit - qt(.975, df) * se.fit, conf.high = fit + qt(.975, df) * se.fit))) ## plot ## model_fits_and_ci %>% unnest(predicted_values) %>% ggplot(aes(x = name, y = estimate)) + geom_bar(stat = "identity", position = position_dodge(width = .95), fill = "royalblue", width = 0.4) + geom_errorbar(stat = "identity", aes(ymin = conf.low, ymax = conf.high), colour = "black", width = .15, position = position_dodge(width = .95)) + geom_text(aes(label = round(estimate, 2)), vjust=1.6, color="white", size=4.5, position = position_dodge(width = 1)) + ylab("average response") + xlab("question") ## Second Plot (Split by education levels) ## ## prediction data ## prediction_data % pivot_longer(starts_with("q_"), values_to = "subject_response") %>% group_by(name) %>% tidyr::nest() %>% mutate(model_fit = map(data, ~ lm(data = .x, subject_response ~ age + is_female + as.factor(education) )), predicted_values = map(model_fit, ~ bind_cols(prediction_data, as.data.frame(predict(newdata = prediction_data, .x, type = "response", se.fit = T))) %>% rowwise() %>% mutate(estimate = fit, conf.low = fit - qt(.975, df) * se.fit, conf.high = fit + qt(.975, df) * se.fit))) ## plot ## model_fits_and_ci_by_education %>% unnest(predicted_values) %>% ggplot(aes(x = name, y = estimate, group = education, fill = as.factor(education))) + geom_bar(stat = "identity", position = position_dodge(width = .95), width = 0.8) + geom_errorbar(stat = "identity", aes(ymin = conf.low, ymax = conf.high), colour = "black", width = .15, position = position_dodge(width = .95)) + geom_text(aes(label = round(estimate, 1)), vjust=1.6, color="white", size=3.5, position = position_dodge(width = 1)) + scale_fill_hue(labels = c("no high school diploma", "high school diploma", "2-yrs at college", "4-yrs at college or bachelor degree", "master's degree", "phd")) + labs(fill = "education level") + ylab("average response") + xlab("question") + facet_wrap(~ name, scales = "free")
