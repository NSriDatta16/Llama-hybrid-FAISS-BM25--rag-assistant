[site]: datascience
[post_id]: 87952
[parent_id]: 87940
[tags]: 
First, you are right that word co-occurrence graphs have been used in various applications of NLP. More precisely in applications related to the meaning of the words, typically for topic modelling or word sense induction . These applications follow the linguistic principle that words which occur in similar contexts tend to have a similar meaning. This is the basis of distributional semantics . However this principle is unlikely to help finding words which have a similar syntactic function, simply because the co-occurrences in a sentence don't correspond to their syntactic role: a sentence usually contains many distinct POS tags, it doesn't have a specific POS category. Basically, word co-occurrences are useful for semantics, not syntax . If the goal is to implement a POS tagger, why not use state of the art methods known to work very well for POS tagging? There is a lot of training data available, for instance the Universal Dependencies corpora. Note that POS tagging is normally a supervised task (based on annotated data), whereas your idea appears to be about finding groups of similar POS in an unsupervised way. This would be another story entirely, probably involving grammatical inference .
