[site]: datascience
[post_id]: 102473
[parent_id]: 102472
[tags]: 
To improve a model there are multiple things you can do, not just feature engineering or using different models. For example you haven't tried hyperparameter tuning for any of the above models. Here are some of the things you could try to improve the score (keep in mind that these are general tips for anyone who wants to improve their model):- 1.) First of all clean the data i.e deal with nan values and outliers. You can either remove nan values or impute them with a statistical value. For outliers you have to be careful as not all outliers are redundant. Try to see if they make sense and if so keep them. Else remove them. Also remove duplicate values from your dataset. 2.) The next step would be feature engineering. Try to see if 2 or more features can be combined into one. This will help in reducing the dimensionality (although you say this results in lower performance). 3.) Feature selection where you keep useful features only and remove the redundant features. The best tool you can use for this purpose is domain knowledge. Use your domain knowledge to see if any feature is worth removing. If you don't have enough domain knowledge, only then go for feature selection techniques like filter based, wrapper based, hybrid etc. (RFECV and BorutaShap are 2 of the best ones out there imo) 4.) Hyperparameter tuning! You can use any of the techniques out there for this purpose (go for Optuna if you ask me!). 5.) Try more models! I don't know how many models you have tried but here you mention only a few. There are more than 36 Regression models out there so try as many as you can to see which give best results. Here is an extensive list! 6.) Simply get more data. In your case this will probably not be of much use since you took the dataset from Kaggle!
