[site]: datascience
[post_id]: 112966
[parent_id]: 112785
[tags]: 
According to https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html#simplest-invocation-to-ocr-an-image you are doing the correct thing by trying eng+rus . I.e. that is the answer to the question. You could also try rus+eng (though according to those docs that only affects the time taken?). If that is not giving good enough quality one possibility is to fine-tune on your own data. See https://tesseract-ocr.github.io/tessdoc/#training-for-tesseract-5 and https://tesseract-ocr.github.io/tessdoc/tess5/TrainingTesseract-5.html#introduction where it mentions fine-tuning might give good results even with a relatively limited amount of training data. Another approach is to run OCR twice, as each English and Russian, then analyze the resulting strings for likeliness. E.g. match against a dictionary, or run through a character language model. The thinking here is that "Xonogunbxuk" does not look at all English. And "KncnenAR" (sorry, can't type Cyrillic here) doesn't look like valid Russian. Even "60150R" vs. "601508" can be done, if you know that you are expecting codes to always be 5 digits then a capital letter. Note that this is not really extra work: you are going to need a validation step anyway, because OCR output is unreliable even in a single language.
