[site]: crossvalidated
[post_id]: 342497
[parent_id]: 183438
[tags]: 
In Speech Recognition, we often include some context about neighboring phones when modelling a certain phone. This means that our system not only knows phones for A , B and so on, but instead has a concept for E-then-A , O-then-B , X-then-A and so on. These context-depended units are called senones in literature , which is of course a made-up word. For speech recognition systems, these senones usually equal the HMM states of the acoustic model, which can be predicted by a neural network, if a DNN/HMM hybrid approach for acoustic modelling is used. The term Senones was coined by the developers of the Janus speech recognition toolkit. It was then adopted by Dong Yu and Li Deng for their ASR book. That was in the time before NNs were used for acoustic modelling. Therefore the term is confusing.
