[site]: datascience
[post_id]: 74686
[parent_id]: 74682
[tags]: 
If you properly isolate your test set such that it doesn't affect training, you should only look at the test set accuracy. Here are some of my remarks: Having your model being really good on the train set is not a bad thing in itself. On the contrary, if the test accuracy is identical, you want to pick the model with the better train accuracy. You want to look at the test accuracy. That is your primary concern. So pick the model that provides the best performance on the test set. Overfitting is not when your train accuracy is really high (or even 100%). It is when your train accuracy is high and your test accuracy is low. it is not abnormal that your train accuracy is higher than your test accuracy. After all, your model has an advantage with the train set since it's been given the correct answer already. At the end of the day, training a machine learning model is like studying for a test. You (the model) use learning resources such as books, past exams, flash cards etc. (train set) to perform well on a test/exam (test set). Knowing your learning resources perfectly doesn't mean you are overfitting. You would be overfitting if this is all you knew and couldn't perform well on the exam at all.
