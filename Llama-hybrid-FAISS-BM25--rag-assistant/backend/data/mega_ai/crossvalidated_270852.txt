[site]: crossvalidated
[post_id]: 270852
[parent_id]: 31440
[tags]: 
If you are not tied to logistic regression I would suggest you use a random forest classifier because it has a sort of built in clustering. The idea would be to use use the proximity matrix to cluster. The proximity matrix is the N_Obs by N_Obs matrix for the fraction of out of bag trees where the observations where in the same terminal node. You can then aggregate this into a feature level by feature level matrix where the elements are the average of the fraction in the proximity matrix. You would then cluster all levels together when they past a threshold and see if this improves your prediction. It is likely best to take a step-wise iterative approach to find the optimal clustering but you can choose a threshold in other ways. When this clustering is done you could replace the feature with the cluster labels or add the cluster labels as a new feature. I suppose at this point you could switch back to logistic regression if you really wanted.
