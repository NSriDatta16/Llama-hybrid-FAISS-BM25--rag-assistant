[site]: datascience
[post_id]: 55531
[parent_id]: 51808
[tags]: 
There are two not so widely known in the data science community metrics that work well for imbalanced data and can be used for multi-class data: Cohen's kappa and Matthews Correlation Coefficient (MCC). Cohen's kappa is a statistic that was designed to measure inter-annotator agreement, but it can be used to measure agreement between the ground truth and a prediction. There are number of explanations online e.g. on Wikipedia or here and it is implemented in scikit-learn . MMC was initially designed for a binary classification but then generalized for multi-class data. There are also multiple online sources for MCC, e.g. Wikipedia and here , and it is implemented in scikit-learn . Hope this helps.
