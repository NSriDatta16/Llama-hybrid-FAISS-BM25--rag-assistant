[site]: crossvalidated
[post_id]: 367338
[parent_id]: 367333
[tags]: 
Some Machine Learning algorithms require all features to be in the same range to function properly, or they'll tend to pay more attention to some features rather than the other. An example of such algorithms are distance-based algorithms. For example say you have a dataset where two features are: age = [33, 35, 55, 67, 77, 78, 80, 83, 85, 93] height = [1.67, 1.72, 1.73, 1.76, 1.8, 1.81, 1.83, 1.85, 1.88, 1.91] The difference from the tallest to the shortest person is just 0.24 units, while the difference from the oldest to the youngest is 60 units. This means that this algorithm will treat the ages as far more important than the heights. By normalizing the features to the same distance, you are ensuring that the algorithm treats them with equal importance. You can also read this relevant post, with a more detailed answer on why normalization is required for k-NN.
