[site]: crossvalidated
[post_id]: 515242
[parent_id]: 
[tags]: 
How to choose the value of nu parameter in one class SVM data without outliers

The nu parameter is an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. I quote from scikit-learn : This estimator is best suited for novelty detection when the training set is not contaminated by outliers. This is exactly my case. I have a dataset of 2000 labeled samples (Class 0). I want to train my oneclassSVM model on this dataset, then try to predict 200 unlabeled unseen samples whether they belong to class 0 or not. In this case, when training the model, the nu parameter should be 0, right ? Because I don't have any outliers in my training data. But, this is not even possible because its value should be in the interval (0, 1] Can someone clarify to me how do we correctly choose the value of nu? And how could we train a model with positive data only?
