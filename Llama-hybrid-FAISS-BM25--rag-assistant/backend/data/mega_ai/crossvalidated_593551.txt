[site]: crossvalidated
[post_id]: 593551
[parent_id]: 593524
[tags]: 
Edit: Per @James Stanley's suggestion, let me add a tl;dr at the top. The basic issue is that interacted regression models are somewhat complex/subtle to interpret, so the counterintuitive "difference" you see likely arises from the coefficient not corresponding to the comparison you actually want to make. I am guessing from context that what concerns you is that the coefficient for taskfocNear is highly significant even though the averages of the blue and red dots seem very close to one another. The highly significant result is not necessarily a statistical error so much as it is an indication that the interpretation of the coefficient in front of taskfocNear is highly non-intuitive and probably not what you think it means. Specifically, you need to think carefully about the model you estimated. The regression formula is $$y = \beta_0 + \beta_1 taskfocNear + \beta_2nearFC + \beta_3 taskfocNear\times nearFC + \epsilon$$ Let us begin by trying to understand what $\beta_0$ , the intercept means. In this case, it should correspond to the predicted value of $y$ when $taskfocNear=nearFC=0$ . Given the distribution of nearFC in your data, you should note that this is a very strange prediction to try to make. Even though your lowest value of nearFC is greater than 1, you are trying to ask the model what it predicts for nearFC =0, which may not even make sense in your context. Now, let us move on to the interpretation of $\beta_1$ . For this, note that $\beta_1 +\beta_0$ corresponds exactly to your predicted value of $y$ when taskfocNear =1, but nearFC =0. Thus, $\beta_1$ corresponds to the predicted difference in $y$ when taskfocNear =1 vs when taskfocNear =0 for observations when nearFC =0. Again, because you never see values of nearFC =0 in your data, this is a very odd prediction to be asking of your model and may not even be a coherent question to ask given the context of your data. Looking at the plot, you can also see why this difference is so large. Because there is an evident difference in the slope of the red vs blue line, when you try to extrapolate these different slopes from values of the nearFC in your data (ranging from 1-4) all the way down to when nearFC =0, these differences get greatly amplified, which ultimately leads to the estimate of $\beta_1$ highly statistically different from 0. So what should you do to correct this? The answer to this question depends on what question you really want to ask of your data (that is a question you will need to answer for yourself), but here is one possibility. Perhaps what you really want $\beta_1$ to reflect is something like the answer to the question "for typical values of nearFC , what is the predicted average difference in $y$ if taskfocNear =0 vs when taskfocNear =1. In that case, if you were willing to operationalize the word "typical" to mean "average", then one possibility would be to instead estimate the slightly modified model $$\begin{aligned}y=\beta_0+\beta_1 taskfocNear &+ \beta_2(nearFC-\overline{nearFC}) \\&+ \beta_3taskFOCnear\times(nearFC-\overline{nearFC})+\epsilon\end{aligned}$$ where here, $\overline{nearFC}$ is the average value of nearFC in your sample. In this case, $\beta_2$ and $\beta_3$ will continue to have the same interpretation (namely, $\beta_2$ will be the slope of the best fit line for $y$ and nearFC for taskfocNear =0 while $\beta_2+\beta_3$ will be the slope of the best fit line for taskfocNear =1. However, $\beta_1$ will now have the interpretation of "what is the predicted difference in $y$ between taskfocNear =0 vs taskfocNear =1 when nearFC is fixed at its average value within the sample.
