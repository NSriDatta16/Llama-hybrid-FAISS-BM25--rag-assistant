[site]: datascience
[post_id]: 25576
[parent_id]: 
[tags]: 
Best method to deal with too many zeroes in regression problem?

I'm trying to solve a simple regression problem using TensorFlow and Pandas to see what's the expected conversion rate for a given product given how much I'm willing to pay for each visit (cost per click or cpc ). Each data point represents a single day and its given acquisition cost and conversion rate. I expect conversion rate to decrease exponentially as visits increase because my audience gets wider and not as focused anymore. The data seems to agree with this: The problem is that for the majority of data points, the conversion rate is zero (i.e. no products were sold) so any model is likely to perform well by merely guessing zero sales. For this particular subset (one of the best selling products) the ratio of zero-to-non-zero is roughly 4:1 but in the general data it's about 300:1. The two best ways that I can think of dealing with this are a) summarizing data by time periods large enough to contain at least one conversion in them (problem with this is that I lose data by having to settle for the average cost instead of the more detailed daily data) b) splitting the problem into a classification problem ( will I sell at least one unit ) and a regression problem ( given that I'm going to sell at least one unit, how many units can I expect to sell ) Do either of those sound like a smart idea? Are there any tried-and-true methods to solve this kind of problem?
