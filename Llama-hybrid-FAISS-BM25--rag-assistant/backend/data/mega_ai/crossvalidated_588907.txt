[site]: crossvalidated
[post_id]: 588907
[parent_id]: 411175
[tags]: 
Method: Simulation assuming multivariate normality of coefficients You could use the coefficients and their covariance matrix returned by the model to do simulations (Carsey & Harden 2013, King et al. 2000). The procedure works as follows: Estimate the model and store the coefficients and covariance matrix. Draw randomly from a multivariate normal distribution in which the means and covariance matrix are set to the stored values from step 1. Repeat step 2 a large number of times and store the random draws of each simulation. Calculate the quantities of interest for each draw of coefficients and store them. Summarize the stored quantities of interest (e.g. with the mean and quantiles). Here's the example with your simulated data: library(MASS) set.seed(1234) x Based on this simulation using $100\,000$ random draws, the difference of predicted probabilities is $0.478$ with a corresponding 95% confidence interval of $(0.296; 0.633)$ . This is similar to the other answers. The package clarify simplifies these steps greatly. Here is it in action (output is not shown): library(MASS) library(clarify) set.seed(1234) x Method: Parametric bootstrap A parametric bootsrap confidence interval can be calculated using the following steps (Adjei & Karim 2016): Estimate the model and store the predicted probabilities $\hat{\pi}_i$ . Draw a bootstrap sample $(x, y^{*})$ where $y^{*}_i=\operatorname{Ber}(\hat{\pi}_i)$ . Fit the model with the data obtained in step 2. Estimate the difference in predicted probabilities from model in step 3 and store them. Repeat steps 2-4 a large number of times. Summarize the stored differences. Again in R: set.seed(1234) x Based on this simulation using $10\,000$ replications, the difference of predicted probabilities is $0.49$ with a corresponding 95% confidence interval of $(0.319; 0.658)$ . Method: Nonaparametric bootstrap A nonparametric bootsrap confidence interval can be calculated using the following steps (Adjei & Karim 2016, see also my answer here ): Draw $n$ observations from the original dataset of size $n$ with replacement. Fit the model using the data obtained in step 1. Estimate the difference in predicted probabilities from model in step 2 and store them. Repeat steps 1-3 a large number of times. Summarize the stored differences. Here's how you could do it in R: set.seed(1234) x Based on the nonparametric bootstrap using $10\,000$ replications, the difference of predicted probabilities is $0.49$ with a corresponding 95% confidence interval of $(0.327; 0.655)$ . References Adjei, I. A., & Karim, R. (2016). An application of bootstrapping in logistic regression model. Open Access Library Journal, 3(9), 1-9. Carsey, T. M., & Harden, J. J. (2013). Monte Carlo simulation and resampling methods for social science. Sage Publications. King, G., Tomz, M., & Wittenberg, J. (2000). Making the most of statistical analyses: Improving interpretation and presentation. American journal of political science, 347-361.
