[site]: crossvalidated
[post_id]: 366704
[parent_id]: 
[tags]: 
Why is distance covariance defined squared, while covariance is not?

I am dealing in a data science project with correlation analyses using pearson and distance correlation. While trying to understand the differences between them, I learned about the differences by reading Szekely's paper and finding this very good question here . So in my understanding the main difference of both is the methodological approach. I understand the underlying covariance of pearson's correlation is influenced by the sum of distances to a centroid (the mean), while for the distance covariance it is the sum of distances to all points of the data. The covariances in both cases are defined as the expectation value of those distances. The math approach to calculate all following quantities like correlation etc is equal for both. The only difference is the definition of the covariance "usual" covariance: ${\displaystyle \operatorname {cov} (X,Y):=\operatorname {E} {{\big [}(X-\operatorname {E} [X])(Y-\operatorname {E} [Y]){\big ]}}}$: Linear definition Distance covariance: ${\displaystyle \operatorname {dCov} ^{2}(X,Y):=\operatorname {E} {\big [}d_{\mu }(X,X')d_{\nu }(Y,Y'){\big ]}}$: Squared definition. Why is this the case?
