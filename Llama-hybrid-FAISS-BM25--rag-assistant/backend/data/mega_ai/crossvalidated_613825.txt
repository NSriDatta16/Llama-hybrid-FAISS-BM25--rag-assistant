[site]: crossvalidated
[post_id]: 613825
[parent_id]: 613489
[tags]: 
The standard regression without random effect assumes that all observations in all studies can be used to estimate the same main effect. The effective sample size for estimating this main effect then is the number of observations overall. In a model with a random effect, there is an underlying study mean, which is the main effect plus the random deviation of the specific study from the main effect. Each observation contributes to estimating what I call the underlying study mean, so observations in different studies estimate different things. The overall main effect can only be estimated bringing the different study effects together. So the effective sample size would be the number of studies (in fact less than this because a study with a low number of observations will estimate it's own study mean potentially very imprecisely), which is of course lower than the number of observations overall. This means that the estimation of the main effect will be much less precise under the model involving random study effects. Be wary though of taking this as an argument for using the model without random effect, as this model may not capture the realistic uncertainty appropriately, so the larger precision you get may well be deceptive. It is not appropriate to compare the behaviour of a standard regression assuming that no random effect exists with a model with random effect assuming that a random effect exists . Obviously each model will do better in a situation in which its model assumptions are fulfilled, but the random effects model is more general, i.e., even if the random effect variance is in fact zero, i.e., the random effect does not exist, the random effect model will do an OK job, whereas the standard regression may well not, in case a random effect exists. If I understand things correctly, this by the way may play out both in terms of the test level, i.e., the model without random effect may reject a null model too easily in case a random effect exists, and in terms of power, or in only one of these respects, probably depending on the number of studies, and how the within-study variance relates to the variance between studies. (My intuition is that anticonservativity, i.e., too large rejection probability under the null hypothesis, will likely be the dominating issue here, rather than potential loss of power.) Fun fact: If a single study is run, this will never be modelled involving a random study effect, as such effect cannot be identified based on one study only. This means that if we consider a single study, the effective sample size will be the number of observations, say, 200. Now let's say three further studies are run, and somebody meta-analyses these using a random effect. This additional information reduces the effective sample size to 4, the number of studies! We become far less precise by observing more. The explanation is that any potential problem causing the first study to in fact deviate on average from the overall main effect cannot be detected as long as further studies do not exist, i.e., we rely on a model that makes stronger assumptions not because there is any more reason that this is true, but rather because this is our only chance to say anything. PS: I add something after having seen the added Orthodont data example in the question. In fact two things happen when adding a random effect. One is the change of the effective sample size, already discussed above. The other one is that the random effect will explain some of the variation in the data, and for this reason the fixed effect will account for less variation and can in principle be estimated more precisely. Both of these point in opposite directions, so the estimated precision of the fixed effect estimators may go up as well as down when adding a random effect. Factors for having an estimated standard error of the fixed estimator rather larger when adding a random effect are (1) the number of clusters is very small compared to the number of observations within clusters (as often happens in meta analysis) and (2) the variance of the random effect is rather low, compared to the within-clusters variance.
