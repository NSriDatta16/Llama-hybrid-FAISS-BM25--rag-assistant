[site]: stackoverflow
[post_id]: 1879297
[parent_id]: 1025589
[tags]: 
There are two reasons: Avoid crashes when double-freeing Written by RageZ in a duplicate question . The most common bug in c is the double free. Basically you do something like that free(foobar); /* lot of code */ free(foobar); and it end up pretty bad, the OS try to free some already freed memory and generally it segfault. So the good practice is to set to NULL , so you can make test and check if you really need to free this memory if(foobar != NULL){ free(foobar); } also to be noted that free(NULL) won't do anything so you don't have to write the if statement. I am not really an OS guru but I am pretty even now most OSes would crash on double free. That's also a main reason why all languages with garbage collection (Java, dotnet) was so proud of not having this problem and also not having to leave to developer the memory management as a whole. Avoid using already freed pointers Written by Martin v. LÃ¶wis in a another answer . Setting unused pointers to NULL is a defensive style, protecting against dangling pointer bugs. If a dangling pointer is accessed after it is freed, you may read or overwrite random memory. If a null pointer is accessed, you get an immediate crash on most systems, telling you right away what the error is. For local variables, it may be a little bit pointless if it is "obvious" that the pointer isn't accessed anymore after being freed, so this style is more appropriate for member data and global variables. Even for local variables, it may be a good approach if the function continues after the memory is released. To complete the style, you should also initialize pointers to NULL before they get assigned a true pointer value.
