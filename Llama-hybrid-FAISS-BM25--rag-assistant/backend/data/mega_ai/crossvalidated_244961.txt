[site]: crossvalidated
[post_id]: 244961
[parent_id]: 
[tags]: 
How to impute data when missing data is greater than the number of complete observations?

I have a dataset of 54,681 rows and 10 features. I'm trying to predict whether or not a user will complete an a specific action, ie a binary target label. There are several features such as signup_date , item_added_date and action_completed_date . My problem is that all of these data are only recorded for users that complete the action, if they don't then these features are recorded as NaN . Therefore, I only have complete information for users who actually complete the action and introduces bias into the data. Estimation techniques such as Logistic regression, naive bayes, or random forests are all incompatible with the NaN data type. I've been looking at scikit-learn's methods for data imputation . Of the 54,681 rows only 6,137 have complete data. Is it a reasonable technique to compute some imputation when the amount of missing data is nearly ten times the number of complete observations? Or should I rethink my entire approach?
