[site]: datascience
[post_id]: 117986
[parent_id]: 117983
[tags]: 
A loss function is differentiable if you can compute its derivative with respect to the model parameters. In your example, there is not enough information to say if the loss function is differentiable, because we don't know how $L$ and $F$ are defined. An example of differentiable loss function is the mean squared error, that is $\mathbf{L} = \frac{1}{n}\sum_{i=1}^n(y_i - F(x_i))^2$ , where $F$ is our model (e.g. a neural network), which must also be differentiable. Differentiable loss functions matter for gradient-based optimization approaches, like gradient descent for neural networks, because to be able to apply them you need the loss function (and the model) to be differentiable.
