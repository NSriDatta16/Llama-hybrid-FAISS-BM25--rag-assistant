[site]: crossvalidated
[post_id]: 109102
[parent_id]: 109052
[tags]: 
Sounds like you have three distinct populations (math students, boys, & girls), from each of which you have two independent samples (non-band music participant = T / F ), and you're looking to test mean differences on the same dependent variable (achievement) within each population. Is that right? You could perform three separate independent-samples t -tests (or Mann–Whitney U / bootstrap / permutation / generalized linear model slope / etc. tests, for that matter) as @RussLenth suggests. That might work just fine, but it might not be the most conservative approach. With only two samples per population, an OLS ANOVA would be equivalent to a t -test. However, a MANOVA would work as an omnibus significance test controlling for familywise error inflation. This might make sense in your context, since you're testing very similar hypotheses in each population. If this seems to you like taking three swings at the same metaphorical baseball, it's probably appropriate to account for the fact that this gives you three independent chances to make a false positive detection error. (They are independent, right? Or do you have some of the same participants in each sample?) On the other hand, if you think these are meaningfully separate hypothesis tests and want to consider each separately without adjusting for familywise error inflation, that may be defensible, and there are those who would defend your choice. The ad absurdum argument against familywise error correction: one might argue (somewhat insanely) that every analysis you ever do in your career should be corrected for researcher-wise error inflation. Another option to consider is treating this as a job for a three-way 2×2×2 ANOVA. This is especially important to consider if some of your girls or boys are also math students, hence your 3×2 samples aren't independent. Certainly your math student sample is composed of boys and girls, so if you have gender information about that sample as well, why not treat math student status as a third factor? Here's how a few rows of that dataset might look: \begin{array}{cccc}\rm ID&\rm Gender&\rm Math\ Student&\rm Music\ Participant&\rm Achievement\\\hline1&\rm Male&\rm False&\rm True&A_1\\2&\rm Female&\rm True&\rm True&A_2\\3&\rm Male&\rm False&\rm False&A_3\\...&...&...&...&...\\n&{\rm Gender}_n&{\rm Math\ Student}_n&{\rm Music\ Participant}_n&A_n\\\end{array}Then your general(ized, depending on the error distribution of achievement) linear model could be:$$A_i = \alpha+\beta_1{\rm Gender}_i+\beta_2{\rm Math\ Student}_i+\beta_3{\rm Music\ Participant}_i+\varepsilon_i$$Again, this is the appropriate approach if your populations of boys and girls aren't independent of your math student population or if you have gender info on your math student population. This approach also affords you some statistical perks like controlling any effects of gender and math student status when testing the effect of music participation, maybe increasing your effective sample size for the one unified analysis, and if you wish, you can test interactions this way too. E.g., is the effect of music participation the same for boys and girls? This would require adding product terms to the GLM above. I'd also encourage you to check the distribution of your outcome variable and consider alternatives to OLS if it's not distributed normally. OLS GLMs don't assume a normally distributed outcome, but they do assume this about prediction residuals, which are probably less likely to fit a normal distribution if the variable itself doesn't. Transformations can help with this, but so can specifying different error distributions with a generalized linear model, and so can nonparametric analysis, which may be just as powerful anyway depending on your choice among them. Re: sample size – 765 sounds like plenty to me, but it depends on the hypothetical size of the effect(s) that you want to be able to detect. If you think the effect(s) might be really small or inconsistent, you might need more data, but my intuition is that your power to detect a Cohen's $d\ge.3$ should be at least 80%, which is a common target for statistical power ($1-\beta$, the chance of failing to detect a real effect). If you want more power than that, or are interested in detecting smaller / less reliable effects, consider performing a power analysis after choosing your hypothesis test(s). Note that if you've already "peeked" at your data (e.g., tried your t -test or ANOVA ideas), then as Russ Lenth says, it's already too late to collect more data to include in the sample you have, speaking from a strictly confirmatory hypothesis testing perspective. On the other hand, if you focus instead on effect size estimation and treat your confidence intervals as secondary interests, there's little or no harm in appending more data to your sample AFAIK, and some precision to be gained for your estimate(s).
