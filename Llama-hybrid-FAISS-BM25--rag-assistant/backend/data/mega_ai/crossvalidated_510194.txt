[site]: crossvalidated
[post_id]: 510194
[parent_id]: 
[tags]: 
Formal statistics vs naive Statistics

In the last year I started to study Data Science by some Udemy and Coursera courses. As a pure mathematician, my curiosity makes me study statistics more formally and deeper. Yesterday, I rewatched one of these Udemy courses (btw this course is one of the tops in terms of the ratings and the number of people watching) and I was impressed how sloppy the instructor was in an univariate linear regression problem. He basically just verified if the data is more or less linear and applied a cross-validation analysis with $R^2=0.8$ , He didn't check more carefully the linear assumption with the residuals graph, the independence and constant variation of the residuous neither, etc. I suppose many of the 6-months-DS-without-stat/math-background make predictions in this way. (In some kaggle challenges most of people just apply a bunch of algorithms blindly (maybe some algorithms may need opposite assumptions) and choose the one that gives them the best prediction(type I/II error or a mixed of the two). So my question is if I'm doing a linear regression project during the night and I'm happy with $R^2=0.8$ can I just close the lid of my laptop and sleep deeply?
