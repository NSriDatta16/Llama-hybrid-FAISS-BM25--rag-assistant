[site]: datascience
[post_id]: 29969
[parent_id]: 
[tags]: 
Difference between XGBRegressor and XGBClassifier

I'm trying to understand the difference between xgboost.XGBRegressor and xgboost.sklearn.XGBClassifier. Can someone explain the difference in a concise manner? Because when I fit both classifiers with the exact same data, I get pretty different performance. This is how I fit the data. clf = xgboost.XGBRegressor(alpha=c) #clf = xgboost.sklearn.XGBClassifier(alpha=c) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) print('Model roc auc score: %0.3f' % roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)) print('Model pr auc score: %0.3f' % average_precision_score(y_test, y_pred)) when clf = xgboost.sklearn.XGBClassifier(alpha=c) Model roc auc score: 0.544 Model pr auc score: 0.303 when clf = xgboost.XGBRegressor(alpha=c) Model roc auc score: 0.703 Model pr auc score: 0.453 What would cause this performance difference?
