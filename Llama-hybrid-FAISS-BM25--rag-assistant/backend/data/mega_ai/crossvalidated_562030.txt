[site]: crossvalidated
[post_id]: 562030
[parent_id]: 
[tags]: 
Proof of Stochastic Gradient Descent

When it comes to the classical Gradient Descent Algorithm, for optimizing Convex Functions - there is a standard proof that demonstrates the convergence of this algorithm provided certain conditions are met: As I understand, the above theorem indicates as the number of iterations reaches towards infinity, the difference between the true minimum of the function and the minimum provided by the Gradient Descent Algorithm will move towards 0. In other words, for Convex Functions, Gradient Descent is likely to find the true Global Minimum when the number of iterations are large. My Question: For Convex Functions, are there any similar ("classical") proofs that indicate that Stochastic Gradient Descent will also converge to the true minimum of the function as the number of iterations reach towards infinity? I found some references where some proofs are provided for the convergence of Stochastic Gradient Descent on Convex Functions (e.g. https://arxiv.org/abs/2103.14350 , https://raghumeka.github.io/CS289ML/gdnotes.pdf ) - but are there any proofs that are considered the standard reference for demonstrating the convergence of Stochastic Gradient Descent on Convex Functions? Thanks!
