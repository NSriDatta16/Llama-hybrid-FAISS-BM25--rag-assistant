[site]: datascience
[post_id]: 27591
[parent_id]: 418
[tags]: 
With the little information you have provided regarding the nature of your data, I would advise you to follow the following approach: Convert text data into categories. You can try different alternatives for how much information the categories should contain, but specific categories have to exist for each variable. As an example, I will assume a variable that came from a text field of a survey questionnaire regarding preferable way of people to get to work. At first, we need to make sure that answers with similar meaning are written on the same way and belong to the same category (e.g. "by bike", "cycling", "by bicycle" all have the same meaning). Then you can try further merging into less detailed categories (e.g. merge "tram", "metro" and "bus" into "Means of public transport") or even more (e.g. "Walking", "Jogging", "Cycling" into "Physical activity") depending on what you are trying to find out. You can even put some different combinations in your dataset and then the next steps will determine which ones will be used for the analysis. In cases where the text data can be "translated" in ordered variables make sure you do this (e.g. if you have "small, medium, high" transform it to "1,2,3"). Turn your categorical variables (not the ordinal ones) into dummy (binary) variables. Most of classification/feature selection algorithms do this automatically, but make sure this is the case with the ones you select. I realise that the dimensionality of the data will become quite big at this point, but this will be handled in the next step. Apply a feature selection/dimensionality reduction technique on your data. You can find a useful review of such techniques here . If you are using Python, sklearn tools give you a lot of options (see more details here ). Make sure you use a technique that also considers multicollinearity. I would try Principal Component Analysis or a tree-based algorithm. For classifying the data, I would go with Decision Tree Classifier (also available via sklearn ). It also performs feature selection setting importance weights to the features. You can set the level of detail on the generated tree depending on your options (e.g. max_depth, min_samples_split) Make sure to adjust the level of detail based on cross-validation to avoid overfitting.
