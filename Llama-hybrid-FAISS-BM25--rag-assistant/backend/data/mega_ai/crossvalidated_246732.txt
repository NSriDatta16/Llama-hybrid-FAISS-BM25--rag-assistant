[site]: crossvalidated
[post_id]: 246732
[parent_id]: 
[tags]: 
Omitted Variable Bias in a VAR-Model

I am concerned about the following issue. One big problem in OLS regression is omitted variable bias, which is normally reflected with explanatory variables being collinear with the error term. Now, I am modelling a VAR-Model with lag length $p=3$ and 6 variables. The model is stable and there is no autocorrelation in the residuals. The conclusion according to LM-test is that residuals are white noise. By definition this would mean that there is no information "left" in the error term and the model is well specified. I then conclude with an analysis of impulse response functions. When evaluating the validity of the model and explaining limitations, one point I have been thinking of has been confounding variables / omitted variable bias. However, my Time Series Econometrics text-books solely speak about omitted variable bias with regards to taking first differences and lag mis-specification. Now, I was wondering if it could be that a variable outside the model exists(unobserved variable), which correlates with two or more variables in the model. If this would be the case, I conclude that my results from the VAR Model are biased. In a standard OLS framework this could be tested by for example the Ramsey test. But also in standard models this variable would have been incorporated in the error term. But in the VAR-Model the error term is a white noise process. According to my understanding a white noise process cannot contain any series and thus I would exclude the possibility of an omitted variable bias based on this reasoning. So now, I am asking myself if this is correct or if a VAR-Model can still be subject to an omitted variable bias through other forms and if so why?
