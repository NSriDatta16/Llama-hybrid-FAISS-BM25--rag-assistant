[site]: crossvalidated
[post_id]: 591610
[parent_id]: 591596
[tags]: 
As @utobi correctly notes in another answer, with such a large data set almost any test of a violation of model assumptions will tend to produce "statistically significant" results that might be practically unimportant. You need to apply your understanding of the subject matter carefully. A big question is how much your robust standard errors differ from the usual OLS standard errors. If there is a big difference, it suggests that there is a problem with specification of your model (e.g., in the functional form of the regression, or assumptions about distributions and variance functions) that needs to be addressed. King and Roberts discuss this in How Robust Standard Errors Expose Methodological Problems They Do Not Fix, and What to Do about It .* They show several examples, and provide code that includes a test they propose for evaluating the difference between standard and robust standard errors. As they describe in Section 2, the simplest robust standard error estimator is based on an assumption that there is no autocorrelation. So if your data might involve autocorrelation and you didn't use a robust estimator designed to handle that (see Section 2.4 of King and Roberts), then your robust errors are already problematic. It certainly is OK to report robust standard errors; as King and Roberts note, a great number of articles in political science and in other fields do so. But it's still important to evaluate and explain why they were needed. From Section 7 of King and Roberts: Scholarly work that includes robust standard errors that differ from classical standard errors requires considerable scrutiny. At best their estimators are inefficient, but in all likelihood estimators from their model of at least some quantities are biased. The bigger the difference robust standard errors make, the stronger the evidence for misspecification. To be clear, merely choosing to report only classical standard errors is not the solution here, as our last empirical example illustrates. And reporting only robust standard errors, without classical standard errors, or only classical without robust standard errors, is similarly unhelpful. Robust standard errors should be treated not as a way to avoid reviewer criticism or as a magical cure-all. They are neither. They should instead be used for their fundamental contribution—-as an excellent model diagnostic procedure. *Final published version: Political Analysis (2015) 23:159–179 doi:10.1093/pan/mpu015
