[site]: crossvalidated
[post_id]: 346857
[parent_id]: 
[tags]: 
Gradient function for log-likelihood

We are trying to calculate the gradient for a logistic regression where the log-likelihood function is: $$ll(x,y,\beta)=ln\left(\frac{\Pi {(e^{x_i\beta}})^{y_i}}{\Sigma {e^{x_i\beta}}}\right)$$ $x$ is a $c\times v$ matrix containing independent variable information. $x_i$ is the $i$th row of the $x$ matrix and corresponds to a specific data observation. $y$ is a vector of length $c$ containing the dependent variable information on a normalized scale (sum is 1.0). $y_i$ is the corresponding response to the observation $x_i$. $\beta$ is a vector of length $v$ which are the coefficients we are trying to maximize with the gradient in a Newtonian method. We have tried to derive the first and second derivatives to get the gradient function, but it's above my linear algebra skills. I apologize if this is already available, but I did not find it when I looked around.
