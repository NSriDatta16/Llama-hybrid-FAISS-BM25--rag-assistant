[site]: crossvalidated
[post_id]: 407642
[parent_id]: 407638
[tags]: 
My suggestion Model: Run a model only with the independent variables you are interested in. Model: Add the variables you want to control for into the model. Reason for the suggestion If you add all the variables together this might change the coefficients of your predictors, i.e. increase/ decrease or even change the direction of the coefficients. If there is no contradiction between borh models you can interpret the coefficient of the independent variable from the second model. Example I'll use an example that I was taught by a statistic professor of my university. Let's assume you want to predict success at work (variable: success; higher is better) and you collected different variables to do this. Among others, you know what the average grades of the people are (variable: grades; higher is better) and how much people are afraid of exams (variable: fear; higher is worse, i.e. more fear). You run a multiple regression and you get the following results: Variable Estimate Std. Error t value p Intercept 0.00 0.12 0.00 1.000 fear 0.33 0.14 2.42 0.019 grades 0.67 0.14 4.85 Incredible: The more someone was afraid of exams the more successful he/ she is at work. Who would have thought that! But wait: Actually, I made up the data and in fact the correlation matrix looks like this (see R code below): success fear grades success 1 0 .5 fear 0 1 -.5 grades .5 -.5 1 As you can see, actually there is no correlation between fear and success. Keep in mind the relationship between correlation and regression : If the correlation is zero, the estimate of the regression will be zero, too. Why does the estimate of fear incease in the multivariate regression? We have a suppression effect here: fear does not explain variance in the dependent variable but in the other independent variable grades. This means you would draw a wrong conclusion if you would only look at the multivariate regression ! Altough the estimate of fear is positive and significant in the multivaraite regression you can not say that having more fear increases success at work. And you can only understand that this conclusion would be wrong if you compare the univariate (1. model) and the multivariate (2. model) regression. Real world examples and a bigger picture The example above shows why I disagree with @Florian Hartig who wrote that "suppressors are secondary, and seldom crucial for the scientific conclusions". To stress this point, please note that " Reversal in association (magnitude or direction) are examples of Simpson's Paradox, Lord's Paradox and Suppression Effects. The differences essentially relate to the type of variable " ( here ). Thus not only the suppression but Simpson's and Lord's paradox can occure in multivariate regression, too, hence, the suggestion to run two models in order to avoid misleading results applies here, too. You can find real world examples here or here . Also, looking for suppression on cv shows that people do encounter this problem. See here or here , for example. Last notes Also keep in mind that there are concepts that are close to suppression. So " in order to interpret these results you will have to think about / have some theory of why the relationships manifest as they do. That is, you will need to think about the pattern of causal relationships that underlies your data " ( here ). R Code require(MASS) df
