[site]: crossvalidated
[post_id]: 399754
[parent_id]: 399745
[tags]: 
Think about how a decision tree works (random forest). Imagine you have a sparse variable in which only 10 out of 1000 observations have a value of 1 and the rest have 0. Now lets say you have the beginning node with 1000 observations. If you were to then split on this sparse variable, you could move at most 10 observations into a new node. The other node would still contain (at least) 990 observations and look quite similar to the node with 1000 observations. Thus this decrease in impurity this would cause (how importance is measured for random forests) would be quite small.
