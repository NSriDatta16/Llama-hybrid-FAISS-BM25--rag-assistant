[site]: crossvalidated
[post_id]: 344900
[parent_id]: 250381
[tags]: 
Maybe check this paper: https://arxiv.org/pdf/1712.08645.pdf They use dropout to rank features. ... In this work we use the Dropout concept on the input feature layer and optimize the corresponding feature-wise dropout rate. Since each feature is removed stochastically, our method creates a similar effect to feature bagging (Ho, 1995) and manages to rank correlated features better than other non-bagging methods such as LASSO. We compare our method to Random Forest (RF), LASSO, ElasticNet, Marginal ranking and several techniques to derive importance in DNN such as Deep Feature Selection and various heuristics...
