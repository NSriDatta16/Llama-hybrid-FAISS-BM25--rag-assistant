[site]: datascience
[post_id]: 51646
[parent_id]: 
[tags]: 
What does "exaggeration" mean in the context of Boosting?

I am learning boosting , the machine learning ensemble meta-algorithm. The professor is grouping 3 weak classifiers into an ensemble and said that before this time point it is easy to understand. Take a dataset, train a simple model, find the smallest error rate, something like this. This idea is easy to implement, for instance, gradient descent would take logistic regression to the smallest error rate. Then, the professor talked about the data with an exaggeration of classifier errors. My question: What does that mean? Can anyone give a sample for this operation based on an open dataset in Python or R?
