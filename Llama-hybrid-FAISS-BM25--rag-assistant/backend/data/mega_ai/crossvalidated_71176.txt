[site]: crossvalidated
[post_id]: 71176
[parent_id]: 
[tags]: 
Intuition behind logistic regression

Recently I began studying machine learning, however I failed to grasp the intuition behind logistic regression . The following are the facts about logistic regression that I understand. As the basis for hypothesis we use sigmoid function . I do understand why it's a correct choice, however why it's the only choice I don't understand. Hypothesis represents the probability that the appropriate output is $1$, therefore the domain of our function should be $[0,1]$, this is the only property of sigmoid function I found useful and appropriate here, however many functions satisfy this property. In addition, sigmoid function has a derivative in this form $f(x)(1-f(x))$, but I don't see the utility of this special form in logistic regression. Question : what so special about sigmoid function, and why we cannot use any other function with domain $[0,1]$? The cost function consists of two parameters ${\rm Cost}(h_{\theta}(x),y)=-\log(h_{\theta}(x))$ if $y=1, {\rm Cost}(h_{\theta}(x),y)=-\log(1-h_{\theta}(x))$ if $y=0$. In the same was as above, I do understand why it's correct, however why is it the only form? For example, why couldn't $|h_{\theta(x)}-y|$ be a good choice for the cost function? Question : what is so special about the above form of cost function; why cannot we use another form? I would appreciate if you could share your understanding of logistic regression.
