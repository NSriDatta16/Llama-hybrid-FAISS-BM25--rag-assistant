[site]: crossvalidated
[post_id]: 346482
[parent_id]: 288193
[tags]: 
You can combine rolling forward origin with k-fold cross-validation (aka backtesting with cross-validation). Determine the folds up-front once, and at each rolling time iterate through the k folds, train on k-1 and test on k. The union of all the held out test folds gives you one complete coverage of the entire dataset at that time, and the train folds cover the dataset k-1 times at that time, which you can aggregate in whatever way is appropriate (e.g., mean). Then score train and test separately as you ordinarily would to get the separate train/test scores at that time. When optimizing parameters, create a separate holdout set first, and then do the cross-validation just described on only the remaining data. For each parameter to be optimized, you need to decide whether that parameter is independent of time (so you can perform the optimization over all rolling times) or dependent on time (so the parameter is optimized separately at each time). If the latter, you might represent the parameter as a function of time (possibly linear) and then optimize the time-independent coefficients of that function over all times.
