[site]: crossvalidated
[post_id]: 211363
[parent_id]: 
[tags]: 
How do GBR trees differ from random forests regression in terms of predictive performance?

Is there a case when one would use gradient boosted regression trees instead of random forests regression (or vice versa)? It appears gradient boosted regression trees have done far better in several ML competitions. However, random forests regression normally works exceptionally well for virtually any problem. Are there any hard numbers regarding the performance between these two algorithms? Predictive performance? Execution performance?
