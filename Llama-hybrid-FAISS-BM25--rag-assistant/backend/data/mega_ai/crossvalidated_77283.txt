[site]: crossvalidated
[post_id]: 77283
[parent_id]: 
[tags]: 
How to decompose a model using linear regression?

I'm using "decompose" in a figurative sense here. I have a simple regression model: y = b + b1x1 + b2x2 + e The "e" term is the residual and "b" the intercept. I want to show the contribution of x1 (and also x2) toward y For the contribution of x1 I remove x2 by setting it to zero. That yields: y|x1 = b + b1x1 For x2 then: y|x2 = b + b2x2 The problem is that these two contributions do not sum to the modeled y values as the intercept is double-counted: y|x1 + y|x2 = 2b + b1x1 + b2x2 != y When I force the regression thru the origin it works fine and there are solid physical reasons to do so but I am looking for a more elegant way to do this? Comments to answers here (I can't add comments below for some reason): To Peter, yes, that is it. Imagine a stacked bar chart. I want my bar chart to have 3 components, the amount of y determined by x1, the amount of y determined by x2, and the residual. These should add up to the raw data.
