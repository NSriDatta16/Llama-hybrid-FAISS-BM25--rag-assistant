[site]: crossvalidated
[post_id]: 76190
[parent_id]: 
[tags]: 
What are the differences between these two kinds of PCA?

The book "Elements of Statistical Learning" describes Principal Components Analysis through SVD as follows: $$X = UDV^T$$ Then $ UD $ are the Principal Components and $ V $ are the directions. However, later in the book, in section 14.7.1 "Latent Variables and Factor Analysis" the authors write: $$ S = \sqrt{N}U $$ $$ A^T = DV^T/\sqrt{N} $$ $$ X = SA^T $$ Then: $$ X_p = a_{p1}S_1 + ... + a_{pp}S_p $$ Questions: What can be done with the second one that can't be done with the first one? Is the first one for a "tall" matrix and the second one for a "wide" matrix? So then does the matrix as used in the first one need to be transposed before it is used in the second one? Why does the second one have $\sqrt{N}$ ? Any other mathematical differences that I have missed? If my matrix is set of functions/curves, what is the difference between having $V$ as the curves and $S$ as the curves? Is there any advantage to using full SVD over reduced SVD? It seems like the first is takes $UD$ and $V$ and the second one takes $U$ and $DV'$. Does it actually matter which one we take as long as the matrix is transpose accordingly?
