[site]: crossvalidated
[post_id]: 183389
[parent_id]: 
[tags]: 
Is it good practice to correct for reliability of a measure in meta analysis? (Cronbach's Alpha / Test Re-Test)

Is it good practice to correct for reliability of your measure in a meta analysis? This is what is suggested by Hunter and Schmidt (2004), but it seems weird to me to calculate your average effect for a perfect situation (perfect reliability) that will never exist. It also feels like the reported effects will be larger in this type of meta analysis than is ever possible to obtain in the real world of data collection? Can you refer me to some more reading & give my your personal opinion on this procedure? References Hunter, J. E., & Schmidt, F. L. (2004). Methods of meta-analysis: Correcting error and bias in research findings (2nd ed.). Newbury Park, CA: Sage
