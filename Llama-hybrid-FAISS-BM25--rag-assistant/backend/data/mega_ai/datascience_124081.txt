[site]: datascience
[post_id]: 124081
[parent_id]: 123931
[tags]: 
I would frame this problem as a denoising task, that is, having a model learn to reconstruct a corrupted input. In this case, the noise to remove would be the missing label/target's. For this, you would need enough fully labeled data to train the model, which would be artificially corrupted by replacing the label/target with some special [MASK] element. The model's expected output would be the correct label/target's at the masked positions. Given that your data seems to be sequences of discrete elements, I would use a Transformer encoder, which can use the full sequence to make its predictions. Therefore, I would use something like BERT . The idea would be as follows (this assumes knowledge on BERT; please have a look at this maked language modeling tutorial and the questions about BERT in this site for more): the model receives a sequence of pairs of symbols: [(label/target1, VM1), (label/target2, VM2), ...]. A percentage (e.g. 15%) of the input positions have their label/target replaced with a special [MASK] symbol. to feed the pair of symbols (label/target, VM) to the neural network, I would use separate embeddings for each component of the pair. At each position, we would embed each part of the pair and add together the resulting vectors, together with the Transformer's positional encodings. the model generates the (label/target) at each position. Only the positions where the input was masked are taken into account for the loss function. For the training data, you should have the sequences where you have all the label/target information.
