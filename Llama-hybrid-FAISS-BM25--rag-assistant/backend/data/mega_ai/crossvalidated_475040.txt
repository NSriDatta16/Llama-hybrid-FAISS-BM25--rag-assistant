[site]: crossvalidated
[post_id]: 475040
[parent_id]: 475033
[tags]: 
There is no maximization of anything unless you are using maximum a posteriori (MAP) estimation, where you maximize the posterior probability $$ \hat \mu = \underset{\mu}{\operatorname{arg\,max}} \; p(\mu | y_1, y_2, \ldots, y_n) $$ Otherwise, when using MCMC, we are just taking samples from the posterior distribution. We don't need to "maximize" anything, since we know the posterior distribution by applying Bayes theorem, i.e. multiplying likelihood by the prior $$ p(\mu | y_1, y_2, \ldots, y_n) \propto p(y_1, y_2, \ldots, y_n | \mu) f(\mu) $$ What we don't know, is the normalizing constant , that would enable us to get rid of the " $\propto$ " sign and make this a proper conditional distribution. Hopefully, for optimization (MAP), or MCMC sampling, we don't need to know the normalizing constant. So in a sense, yes, MCMC "takes" the posterior distribution and draws samples from it. However it is not correct to say that beforehand any "maximization" has taken place, since the only thing that has happened is we derived the posterior from likelihood and prior by multiplying one by another.
