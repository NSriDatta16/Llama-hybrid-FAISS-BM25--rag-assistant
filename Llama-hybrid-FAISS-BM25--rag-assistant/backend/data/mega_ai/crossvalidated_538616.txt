[site]: crossvalidated
[post_id]: 538616
[parent_id]: 43471
[tags]: 
The answer provided by Christoph Hanck compares a Bayesian predictive probability to a frequentist point estimate. Below are frequentist p-values for making a prediction (Johnson 2021a) as compared to a Bayesian posterior predictive distribution and a discussion on willingness to bet. Recall the problem statement, "A coin has been tossed $n=14$ times, coming up heads $k=10$ times. If it is to be tossed twice more, would you bet on two heads? Assume you do not get to see the result of the first toss before the second toss (and also independently conditional on $\theta$ ), so that you cannot update your opinion on $\theta$ in between the two throws." Let $\theta$ be the probability of heads and $r$ be the number of heads in the next two flips. To predict the result of two coin tosses the frequentist will calculate the p-value testing the hypothesis that the next two throws will be heads, $H_0: r=2$ or equivalently $H_0: \hat{\theta}_2=1$ , using an ancillary quantity where $\hat{\theta}_2=r/2$ and $\hat{\theta}_{14}=k/14$ . A candidate for such a quantity could involve $$\hat{\theta}_{14}-\hat{\theta}_2. $$ Based on 100,000 simulations the sampling distribution for this quantity is approximately ancillary, meaning it approximately does not depend on the unknown fixed true $\theta$ . Near $\theta=10/14=0.71$ we could try approximating it with a bell curve. Since our observed estimate and hypothesized value yield $\hat{\theta}_{14}-\hat{\theta}_2 = 10/14 - 2/2 = -0.29$ , the lower-tailed p-value using an approximate Wald test would be $$\Phi\Bigg(\frac{\hat{\theta}_{14}-\hat{\theta}_{2}}{\hat{\text{se}}}\Bigg)=0.20, $$ where $\hat{\text{se}}=\sqrt{\hat{\theta}_{14}(1-\hat{\theta}_{14})/14 + \hat{\theta}_{14}(1-\hat{\theta}_{14})/2}$ . If we increase the number of bins in our histogram and look specifically at the sampling distribution of our statistic at $\theta=10/14$ we see that it may not look quite so bell shaped. Referencing this sampling distribution the lower-tailed probability of $\hat{\theta}_{14}-\hat{\theta}_{2}=-0.29$ or something more extreme is $0.31$ , not far off from our crude Wald p-value. Below is a table of predictive p-values as a function of the hypothesis for $r$ being tested based on the above simulated sampling distribution, as well as posterior predictive belief "probabilities" based on a $\text{Beta}(1,1)$ prior, $k=10$ , and $n=14$ . There are in fact two conclusions the frequentist could draw based on the observed data and the approximate sampling distribution. Had we witnessed, say, $k=9$ or $k=11$ this ambiguity would not have occurred. Interestingly, the Bayesian finds himself in a similar predicament. $$H_0:\hat{\theta}_2=0\iff H_0: r=0$$ $$H_0:\hat{\theta}_2 = 0.5\iff H_0: r = 1$$ $$H_0:\hat{\theta}_2=1\iff H_0: r=2$$ Predictive p-value [smallest one-sided] 0.05 [upper] 0.34 [upper] 0.31 [lower] Confidence curve 1 [one-sided p-value] 0.05 [upper] 0.34 $|$ 0.76 [upper $|$ lower] ( 0.64 ) 0.31 [lower] Confidence curve 2 [one-sided p-value] 0.05 [upper] 0.34 [upper] 0.81 [upper] ( 0.66 ) Posterior predictive distribution 0.11 0.40 0.49 Conclusion 1 To the frequentist, $H_0: r=1$ or equivalently $H_0: \hat{\theta}_2=0.5$ could be regarded as the most plausible hypothesis because it has the largest tail probability of $0.34$ and the other two hypotheses have smaller p-values. This is consistent with the point estimate $\hat{\theta}_{14}=0.71$ since this estimate is closer to $H_0: \hat{\theta}_2=0.5$ than to $H_0: \hat{\theta}_2=1$ . Not only can $\hat{\theta}_{14}=0.71$ be viewed as an estimate for the unknown fixed true $\theta$ , it can also be viewed as an estimate for the as of yet unobserved $\hat{\theta}_2$ . To the Bayesian, $r=2$ has the largest predictive posterior belief and is therefore most "probable" (plausible). This is contrary to the conclusion drawn by Christoph Hanck that the Bayesian would not bet on $r=2$ while the frequentist would. To the frequentist, since we can "rule out" $r=0$ at the $0.05$ level and $r=2$ at the $0.31$ level we are $64\%$ confident in the alternative which is $r=1$ . This confidence level is nothing more than a restatement of the p-values for $r=0$ and $r=2$ , $100(1-0.05-0.31)\%$ . In the long run $\hspace{0mm}64\%$ of the time we see a discrepancy like $\hat{\theta}_{14}-\hat{\theta}_2=10/14-1/2=0.21$ [i.e. within (-0.29, 0.71)] regardless of the unknown fixed true $\theta$ (approximately). These statements of confidence are presented in the table above as "Confidence curve 1." Based on the observed data the frequentist would be most surprised by a result of $r=0$ followed by $r=2$ , and least surprised by $r=1$ . In terms of a willingness to bet the frequentist would bet $\$0.31$ and expect $\$1$ in return if $r=2$ based on the long-run characteristics of the test above, whereas the Bayesian would be willing to bet $\$0.49$ based on his beliefs that all $\theta$ 's were equally likely until the coin came up heads $k=10$ times in $n=14$ throws. The frequentist would gladly "buy this bet in the market" at $\$0.31$ and "sell it" (play the bookie) to the Bayesian at $\$0.49$ making a risk-free $\$0.49-\$0.31=\$0.18$ regardless of whether the coin actually lands twice on heads (Dutch book). To the frequentist at no point was the coin randomly selected from a uniform distribution and then imagined instead to have been selected from a $\text{Beta}(1+10,1+14-10)$ . Conclusion 2 Since the upper-tailed p-value testing $H_0:r= 1$ is smaller than the sum of the p-values testing $H_0:r=0$ and $H_0:r=2$ , the frequentist could conclude that $H_0:r=2$ is the most plausible hypothesis. That is, since we can rule out $H_0:r=1$ (and by extension $H_0:r=0$ ) at the one-sided $0.34$ level we are therefore $66\%$ confident in the alternative which is $r=2$ . This is shown in Confidence curve 2 (note these p-values are not expected to sum to 1). In the long run $66\%$ of the time we see a discrepancy like $\hat{\theta}_{14}-\hat{\theta}_2=10/14-2/2=-0.29$ [i.e. greater than 0.21] regardless of the unknown fixed true $\theta$ (approximately). While this does not coincide with the point estimate $\hat{\theta}_{14}=0.71$ being closest to $H_0:\hat{\theta}_2=0.5$ , it does coincide with the probability mass of the sampling distribution being concentrated most heavily around $\hat{\theta}_{14}-\hat{\theta}_2$ $=10/14-2/2$ $=-0.29$ . Based on this conclusion the frequentist would be most surprised by a result of $r \le 1$ and least surprised by $r=2$ . To the Bayesian, $r=0$ and $r=1$ have a combined posterior predictive belief of $0.51$ , and therefore $r\ne 2$ is most "probable" (plausible). In terms of a willingness to bet the frequentist would bet $\$0.66$ and expect $\$1$ in return if $r=2$ based on the long-run characteristics of the test above, whereas the Bayesian would be willing to bet $\$0.49$ based on his beliefs that all $\theta$ 's were equally likely until the coin came up heads $k=10$ times in $n=14$ throws. The frequentist would gladly "buy the other side in the market" at $\$1-\$0.66=\$0.34$ and "sell it" (play the bookie) to the Bayesian at $\$1-\$0.49=\$0.51$ making a risk-free $\$0.51-\$0.34=\$0.17$ regardless of whether the coin actually lands twice on heads (Dutch book). The second conclusion could be deemed the most appropriate since it results in a higher confidence level for the favored outcome. This interpretation utilized evidential p-values under a Fisherian framework. Under a Neyman-Pearson framework one would pre-specify a single strawman null hypothesis or default prediction, say, $H_0:r=2$ and pre-specify an arbitrary type I error rate, say, $\alpha=0.35$ . Based on the results above, this hypothesis would be rejected in favor of the alternative, $H_a:r\ne 2$ . If, however, one had pre-specified a lower type I error rate of, say, $\alpha=0.20$ the strawman default prediction of $H_0:r=2$ would have been retained. This approach is useful if there are no consequences when predicting $H_0:r=2$ and getting it wrong, and dire consequences when predicting $H_a:r\ne 2$ and getting it wrong. Below are confidence curves for $\theta$ from inverting an exact likelihood ratio test based on our sample of size $n=14$ , which produces a 95% confidence interval for $\theta$ of (0.42, 0.92). Since our quantity $\hat{\theta}_{14}-\hat{\theta}_2$ for predicting $r$ is not exactly ancillary we could perform a number of sensitivity analyses to see how the p-value changes depending on the unknown fixed true $\theta$ . The above analysis and suggested sensitivity analysis are less than ideal since the quantity we chose is not exactly ancillary (the sampling distribution is not exactly the same for any value of $\theta$ ). We could look for another quantity that is exactly ancillary or a closer approximation to ancillary. Many Bayesians would presume as Christoph Hanck did that the frequentist is forced to assume that $\theta$ is known to be exactly equal to $10/14$ and reference the above binomial sampling distribution for $r$ when making predictions. This might seem at odds with our prediction above. After all, our best estimate for $\theta$ is $\hat{\theta}_{14}=0.71$ and therefore our best estimate for the probability of observing two heads, $\theta^2$ , is $\hat{\theta}_{14}^2=0.51$ . However, by chance alone we could have easily observed $9$ out of $14$ heads leading to an estimate of $\hat{\theta}_{14}^2=0.41$ . The confidence curves below from inverting an exact likelihood ratio test account for the sampling variability of our estimator with a $64\%$ confidence interval matching the level of confidence in our prediction for $r$ . Based on the long-run probability of our experiment we are $5\%$ confident that $\theta^2$ is less than or equal to $0.21$ , $31\%$ confident that $\theta^2$ is greater than or equal to $0.64$ , and therefore $64\%$ confident that $\theta^2$ lies within $(0.21, 0.64)$ . If $\theta^2$ is truly $0.21$ then the probability that $r=1$ is $0.50$ , which is in line with conclusion 1. However, if $\theta^2$ is near $0.64$ then $r=2$ has the highest probability, in line with conclusion 2. Performing inference on $\theta^2$ has the benefit of exact inference on a continuous hypothesis space compared to forming a prediction for $r$ . It also formulates the solution in terms of a direct probability statement about $r$ while accounting for the uncertainty around having estimated $\theta$ . This may make it easier for non-statisticians to interpret and understand (Johnson 2021 b) . Nevertheless, this solution though exact still leaves ambiguity as to which bet to take. The real solution to the problem might simply be that we do not have enough information to reliably predict $r$ , whether constructing predictive p-values or performing inference on $\theta^2$ . For more information we would need to increase our sample size $n$ (Johnson 2021 c) . Although the Bayesian and frequentist results differ numerically, a similar conclusion is reached under both paradigms since a Bayesian belief of $0.50$ is interpreted as "undecided." While the Bayesian can reliably model his beliefs for any sample size, beliefs are not facts. If our prediction is not based on facts, it will not be reliable. No one is ever interested in how a prophet believes in his prediction. They only ever care about how often he gets it right. %let k=10; %let n=14; data sim; *do theta=0.1, 0.25, 0.5, 0.75, 0.9; do theta=round(&k./&n.,0.01); do sim=1 to 100000; y14=rand('binomial',theta,&n.); y2=rand('binomial',theta,2); *T=log( ((y2/2)/(1-y2/2)) / ((y14/&n.)/(1-y14/&n.)) ); *T=log( (y2/2)/(y14/&n.) ); *T=(y2/2)/(y14/&n.); T=y14/&n.-y2/2; output; end; end; run; %let Wald_r0=; %let Wald_r1=; %let Wald_r2=; data pvalue; do r=0 to 2 by 1; theta14=&k./&n.; theta2=r/2; t=theta14-theta2; se=sqrt( theta14*(1-theta14)/&n. + theta14*(1-theta14)/2 ); Wald_pvalue=min(cdf('normal',t/se ,0 ,1), 1-cdf('normal',t/se ,0 ,1)); if r=2 then call symput('Wald_r2',Wald_pvalue); if r=1 then call symput('Wald_r1',Wald_pvalue); if r=0 then call symput('Wald_r0', Wald_pvalue); output; end; run; data pvalue; set pvalue; if r=2 then Wald_confidence=1-&Wald_r0.-&Wald_r1.; if r=1 then Wald_confidence=1-&Wald_r0.-&Wald_r2.; if r=0 then Wald_confidence=1-&Wald_r2.-&Wald_r1.; max=max(&Wald_r0.,&Wald_r1.,&Wald_r2.); if round(Wald_pvalue,0.001) ne round(max,0.001) then Wald_confidence=Wald_pvalue; keep r Wald_pvalue Wald_confidence; run; proc print data=pvalue noobs; var r Wald_pvalue Wald_confidence; footnote 'One-sided Wald p-values'; run; footnote; ods escapechar="^"; ods graphics / height=3in width=6in border=no; proc sgpanel data=sim; panelby theta / onepanel rows=1; histogram T ;*/ nbins=6; *density T / type=normal; refline %sysevalf(&k./&n.-1) / axis=x lineattrs=(color=darkblue thickness=2); refline %sysevalf(&k./&n.-0) / axis=x lineattrs=(color=darkblue thickness=2); refline %sysevalf(&k./&n.-0.5) / axis=x lineattrs=(color=darkblue thickness=2); colaxis label="^{unicode hat}^{unicode theta}14 - ^{unicode hat}^{unicode theta}2"; run; proc sort data=sim out=sort; by T; run; ods trace on; ods select none; proc univariate data=sim pctldef=3; var t; cdf t; ods output cdfplot=cdf; run; ods select all; data cdf; set cdf; ecdfx=round(ecdfx,0.0001); run; data cdf; set cdf; by ecdfx; if not last.ecdfx then delete; complementary_cdf=100-ecdfy; complementary_cdf=lag(complementary_cdf); if complementary_cdf=. then complementary_cdf=100; if ecdfx=round(&k./&n.-1,0.0001) then r=2; if ecdfx=round(&k./&n.-0.5,0.0001) then r=1; if ecdfx=round(&k./&n.-0,0.0001) then r=0; if r ne . and ecdfy lt complementary_cdf then refline1=ecdfx; if r ne . and complementary_cdf lt ecdfy then refline2=ecdfx; run; proc sgplot data=cdf; refline refline1/ axis=x; step x=ecdfx y=ecdfy / markers markerattrs=(symbol=circlefilled); title 'p-value from simulated sampling distribution'; xaxis grid minor minorgrid label="^{unicode hat}^{unicode theta}14-^{unicode hat}^{unicode theta}2"; yaxis grid minor minorgrid label="Cumulative distribution function"; run; title; footnote; proc sgplot data=cdf; refline refline2 / axis=x; step x=ecdfx y=complementary_cdf / markers markerattrs=(symbol=circlefilled); title 'p-value from simulated sampling distribution'; xaxis grid minor minorgrid label="^{unicode hat}^{unicode theta}14-^{unicode hat}^{unicode theta}2"; yaxis grid minor minorgrid label="Complementary CDF"; run; title; footnote; proc sort data=cdf out=cdf_pvalue (where=(r ne .)); by r; run; data cdf_pvalue; set cdf_pvalue; pvalue=min(ecdfy, complementary_cdf); if r=2 then call symput('r2', pvalue); if r=1 then call symput('r1', pvalue); if r=0 then call symput('r0', pvalue); run; data cdf_pvalue; set cdf_pvalue; p0=&r0.; p1=&r1.; p2=&r2.; if r=2 then confidence=100-p0-p1; if r=1 then confidence=100-p0-p2; if r=0 then confidence=100-p2-p1; max=max(p0, p1, p2); if round(pvalue,0.001) ne round(max,0.001) then confidence=pvalue; pvalue2=pvalue/100; confidence2=confidence/100; *keep r pvalue2 confidence2; rename pvalue2=pvalue confidence2=confidence; run; proc print data=cdf_pvalue noobs; var r pvalue confidence; footnote 'One-sided p-values from simulated sampling distribution'; run; footnote; data bayes; do sim=1 to 100000; theta=rand('beta',1+&k.,1+&n.-&k.); r=rand('binomail',theta,2); output; end; run; ods select none; proc univariate data=bayes; var r; cdf r; ods output cdfplot=cdf_bayes; run; ods select all; ods noproctitle; proc freq data=bayes; table r / nocum; footnote 'Bayesian predictive distribution'; run; footnote;
