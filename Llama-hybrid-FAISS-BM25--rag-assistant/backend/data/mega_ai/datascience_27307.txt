[site]: datascience
[post_id]: 27307
[parent_id]: 
[tags]: 
logistic regression algorithm fails to work

I'm trying to code my own logistic regression algorithm using Andrew NG's machine learning using Octave. lectures. So what I did was make a csv file, the first row being some parameter and the second one being the result: 121,1 124,0 97,0 104,0 110,0 ... Overall there are only 24 examples, but I've chosen points such that some pattern can be followed . Here is my code: data = load('data.dat'); x = data(:, 1); y = data(:, 2) m = length(y); #plot(x, y, 'rx', 'MarkerSize', 10); #xlabel('IQ'); #ylabel('Pass/Fail'); #title('Logistic Regression'); x = [ones(size(x, 1), 1) x]; alpha = 0.00001; i = 15000; g = inline("1 ./ (1 + exp(-z))") theta = zeros(size(x(1, :)))'; j = zeros(i, 1); for num = 1:i z = x * theta; h = g(z); j = (1./m) * ( -y' * log( h ) - ( 1 - y' ) * log ( 1 - h)) grad = 1./m * x' * (h - y); theta = theta - alpha * grad; end However the output of the sigmoid function shows every value below 0.5... surely this has to be wrong. I've also tried with different learning rates and iterations, but to no avail. What is wrong with the code, or data? Help would be appreciated.
