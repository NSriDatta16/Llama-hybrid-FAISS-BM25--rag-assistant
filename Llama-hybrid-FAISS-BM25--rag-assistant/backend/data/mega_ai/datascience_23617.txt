[site]: datascience
[post_id]: 23617
[parent_id]: 12830
[tags]: 
A fully connected layer (for input size $n*n$ over with $i$ channels, and $m$ output neurons) IS NOT equivalent to a 1x1 convolution layer but rather to an $n$x$n$ convolution layer (i.e. a big kernel, same size as input- no pad) with number of filters equal to the FC output/hidden layer (i.e. $m$ filters) As you asked, it has the same number of parameters as the FCN, i.e. $n*n*i*m$ (plus bias): FCN: $n*n*i$ (weights per input layer= input$*$channels) $* m$ (times output/hidden layer width) CNN: $n*n$ (each kernel) $* i $ (kernel per input channel) $* m$ (number of filters) ( Source )
