[site]: crossvalidated
[post_id]: 615844
[parent_id]: 615836
[tags]: 
Technically, according to Wikipedia , A Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. I suppose that you could re-define your data in a way to incorporate a series of "events" that represents covariate exposures or patterns of exposures, but that seems unnecessarily complicated here. There is no reason to go beyond your simple two-state model, provided that you take care in defining your predictor variables. You are correct that a Cox model only evaluates predictor values that are in place at event times. Nothing, however, prevents you from defining time-varying predictors that incorporate the histories of covariates in some way: cumulative values, running averages, averages weighted toward more recent observations, anything that makes sense based on your understanding of the subject matter. Then, as Frank Harrell points out in another answer (+1), it won't really matter whether you set the problem up as a two-state Markov model or as a Cox model.
