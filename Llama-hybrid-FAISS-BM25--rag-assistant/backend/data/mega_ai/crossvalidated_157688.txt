[site]: crossvalidated
[post_id]: 157688
[parent_id]: 157683
[tags]: 
Note this is a continuous-time Markov chain so $Q$ is a matrix of rates, and not probabilities. To find the probability matrix for time $t$, we need to solve the differential equation $$ P'(t) = P(t)Q $$ This is telling you how $P$ is changing with time, and could be compared to a standard linear differential equation such as $$ \frac{dN}{dt} = \lambda N $$ For which the solution is $$ N(t) = N(0) e^{\lambda t} $$ Now compare: the two differential equations are of the same form, just one is a matrix equation, but we can still use matrix exponentiation . So the solution must be $$ P(t) = P(0)e^{tQ} = e^{tQ} $$ as $P(0) = I$. To make this easier to work with, your lecture has taken a Taylor series approximation of $P$ around $t = 0$, i,e. $$ P(t) \approx I + Qt + \frac{(Qt)^2}{2} $$ this is fine since we are only interested in $t = 0.1$. Note this is still a matrix equation. You are told the initial state probabilities are $\pi = (1/3, 1/3, 1.3)^T$, so you just need to evaluate $P(0.1)\pi$ using the above Taylor series. And you only need the first column because you are only interested in state 0.
