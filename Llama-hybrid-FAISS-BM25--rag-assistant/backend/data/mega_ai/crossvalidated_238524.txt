[site]: crossvalidated
[post_id]: 238524
[parent_id]: 
[tags]: 
Covariate shift problem for text classification

I need to classify social media texts, there are just positive and negative classes and everything seems to be easy. However the main problem is in an extremely large covariate shift between training data and test data for BOTH positive and negative examples. Yes, we some way don't really know what we are looking for - positive class cannot be simply modeled by some reasonable corpus and Bag Of Words based methods don't work (extremely overfit), there are just way too many ways to express what is considered 'positive'. So, we have some positive and negative examples, but a complete set is nearly impossible to acquire. Thus, my question is, are there any known methods/articles that address this problem? It seems, that words embedding must help (yay, word2vec) and I've also found about negative covariate shift , but still not sure what to start with.
