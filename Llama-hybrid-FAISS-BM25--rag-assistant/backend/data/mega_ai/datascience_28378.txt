[site]: datascience
[post_id]: 28378
[parent_id]: 
[tags]: 
Deep CNN with variable number of classes and "vanishing" data

I am using a deep CNN to predict the class an image belongs to (N classes). However, the number of classes is not stationary. I.e. over the time the network will be used, some new classes may emerge while others may not be relevant anymore (I do not need to identify these in any way but I know the relevant classes at any time step). Additionally, I am facing the constraint that the data I can use for this task "vanishes". This means that, at a point in time, I can only use the data of the previous M time steps (e.g. months) where M remains constant. This prohibits simply retraining the network on the entire dataset here and then while dropping some classes/adding new classes (i.e. changing the size of the output layer). I was thinking of using the feature extracting part of the CNN to generate the feature vector and then use binary classifiers (e.g. logistic regressions) on that. This would enable me to simply discard a binary classifier when a class has become irrelevant or add a new binary classifier in case a new class comes up. This approach would take significantly more time in the inference stage (training stage is not critical) as inference would need to be performed for each class separately. Unfortunately, I am also facing tight time constraints at the inference stage. Therefore, I was wondering whether (A) my idea generally makes sense and (B) if there is a more elegant/efficient multi-class classification approach (i.e. a single inference step) that is applicable in my very special case.
