[site]: crossvalidated
[post_id]: 592366
[parent_id]: 589520
[tags]: 
I didn't know what T5 was so I started to ask the question to an online AI question and answer generator (akshara.ai). I asked them "Does the concept of "confidence" apply to text generation tasks?" And I got 9 answers. The first answer is positive The concept of "confidence" can definitely be applied to text generation tasks. When generating text, it's important to have confidence in your choices - whether that means trusting your own judgement or relying on the suggestions of a tool. With enough practice, you'll get better at knowing when and how to use different sources of information to create text that sounds natural and believable. It is however not conclusive. This is the second answer There is some debate about whether the term "confidence" applies to tasks such as text generation. Some people argue that the term should only be used when there is a clear measure of accuracy, while others believe that the term can be used more broadly to refer to a feeling of assurance or self-assurance. In general, though, it seems that having confidence in one's ability to generate text can lead to better results. I am not sure whether the AI completely understands that the question was about the statistical concept of confidence. So I started ask the question in a different way. "Does the concept of "confidence intervals" apply to text generation tasks?" And I got confidence intervals are a way of estimating how likely it is that a given value falls within a given range. When applied to text generation tasks, this means that the algorithm can estimate how likely it is that any particular sentence or paragraph generated by the algorithm will be rated as "good" by human evaluators. I believe that this makes some sense. It should be possible to have a text to text generator provide an additional estimate for the 'confidence', a value for how likely it is that the answer/estimate is right. More specific in relation to intervals In text generation tasks, we can think about the confidence interval as a range of likely outcomes for the text being generated. In the case of text generation intervals might not be so useful but for a single text output one could imagine something as a probability being estimated/computed, that provides a probability that the text is a sufficient answer. However... such a probability is more like a Bayesian credibility than a frequentist confidence. In everyday language we might consider it as confidence but in statistics it has a more specific meaning. (In a same way as 'significance' has a more narrow meaning in statistics than in everyday language). Confidence relates to parametric models and data created by it. It relates to a hypothesised parameter value and the potential data that can be generated with that parameter value. Confidence expresses the following probability: If the output/estimate is correct, how likely would it have generated the observed data?
