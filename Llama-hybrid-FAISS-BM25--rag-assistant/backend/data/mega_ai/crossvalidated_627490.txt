[site]: crossvalidated
[post_id]: 627490
[parent_id]: 6214
[tags]: 
If you want to make "soft restrictions" it is very natural to do this with Bayesian priors on contrasts (linear combinations of $\beta$ s). See here . This doesn't require re-arranging the original model but instead one specifies side constraints. To make a constraint almost "hard" one can specify a prior standard deviation of, for example, 0.001. This is a more general way to think about it, exemplified in the example given at the link in which linearity is enforced over one interval of a predictor.
