[site]: crossvalidated
[post_id]: 286890
[parent_id]: 286774
[tags]: 
Terminology is not consistent across different sub-fields of statistics. In econometrics a loglinear model typically refers to a linear model using a log transformed dependent variable. In other fields (in particular in the biological/medical fields and certain parts of sociology) it refers to a model for patterns in a (possibly high dimensional) cross tabulation. Since you are referring to odds I will assume you are using the term loglinear model in the latter sense. Lets start with an example. I'll use Stata, but the logic applies to any other Stats program. Say we have the following data: . desc Contains data from ZA4578_v1-0-0.dta obs: 4 vars: 3 size: 40 -------------------------------------------------------------------------------- storage display value variable name type format label variable label -------------------------------------------------------------------------------- husb_career float %9.0g husb_career * wife should support husband's career east float %9.0g east region of residence _freq int %12.0g Frequency * indicated variables have notes -------------------------------------------------------------------------------- Sorted by: east husb_career Note: Dataset has changed since last saved. . list +-------------------------+ | husb_c~r east _freq | |-------------------------| 1. | disagree west 9297 | 2. | agree west 4403 | 3. | disagree east 5639 | 4. | agree east 1770 | +-------------------------+ Then we can estimate a log-linear model using Poisson regression of the cell frequencies ( _freq ) with the row ( husb_career ) and column ( east ) variable and their interaction. . poisson _freq i.east##i.husb_career, irr nolog Poisson regression Number of obs = 4 LR chi2(3) = 5815.16 Prob > chi2 = 0.0000 Log likelihood = -20.497687 Pseudo R2 = 0.9930 ------------------------------------------------------------------------------ _freq | IRR Std. Err. z P>|z| [95% Conf. Interval] -------------+---------------------------------------------------------------- east | east | .6065397 .0102377 -29.62 0.000 .5868024 .6269409 | husb_career | agree | .4735936 .008664 -40.85 0.000 .4569133 .4908829 | east#| husb_career | east#agree | .6627738 .0217506 -12.53 0.000 .6214855 .706805 | _cons | 9297 96.42095 881.04 0.000 9109.926 9487.915 ------------------------------------------------------------------------------ Notice that I have asked for the exponentiated coefficients (I used the option irr ). The constant now shows the expected cell frequency for someone in West-Germany and who disagrees with the statement that women should primarily support their husband's career. Since we estimated a saturated model the expected count corresponds exactly with the observed count. The main effect of east shows that this count changes by a factor 0.61 if you move to east Germany but continue to disagree. This means that we expect for those people who disagree 0.61 East-Germans for every West-German. In general the odds can be described as the expected number of "failures" per "success", so the main effect in a log-linear model is an odds. Similarly, the main effect for husb_career shows that in West-Germany we expect to find 0.47 people who agree with the statement that that wifes should mainly support their husband's career for every person who disagrees with that statement. The interaction effect shows that this odds of agreeing in East-Germany is 0.66 times the odds of agreeing in West-Germany. So the interaction effect (exponentiated) is the ratio of the odds in the east and the odds in the west. In other words, it is the odds ratio. The logarithm of this coefficient (i.e. before exponentiating) is probably the coefficient you were referring to in your question. Negative number correspond to odds ratios less than 1 and positive numbers correspond to odds ratios more than 1. This is why a negative number means that the odds is smaller in the East than the West. Bonus: In simple tables like this you can get the exact same results with logistic regression: . logit husb_career i.east [fw=_freq], or nolog Logistic regression Number of obs = 21,109 LR chi2(1) = 161.27 Prob > chi2 = 0.0000 Log likelihood = -12675.893 Pseudo R2 = 0.0063 ------------------------------------------------------------------------------ husb_career | Odds Ratio Std. Err. z P>|z| [95% Conf. Interval] -------------+---------------------------------------------------------------- east | east | .6627738 .0217506 -12.53 0.000 .6214855 .706805 _cons | .4735936 .008664 -40.85 0.000 .4569133 .4908829 ------------------------------------------------------------------------------
