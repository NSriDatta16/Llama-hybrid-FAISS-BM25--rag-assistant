[site]: crossvalidated
[post_id]: 612607
[parent_id]: 
[tags]: 
Do we lose information when we normalize an image?

Before training a machine learning algorithms, it is advisable to perform feature scaling. Suppose we have a "toy" dataset where each image is composed of two pixels $x_0$ and $x_1$ . Lets assume that $x_0 \approx 0$ and $x_1 \approx 1$ for all the training samples. Initially, all images will be $(0, 1)$ but after e.g. min-max normalization they become $(1, 1)$ , that is we have lost the "contrast". Are there cases where feature scaling should be perform with caution? Should a per image normalization makes more sense in the aforementioned example? How normalization should be performed? In case of min-max normalization do we use the min and max values across all pixels of all images? I am asking this because when we have a dataset where columns are features (e.g. height, weight etc) we normalize per column. Does this per column normalization makes sense in images (if we flatten an $n\times n$ image into a vector with $n^2$ entries)?
