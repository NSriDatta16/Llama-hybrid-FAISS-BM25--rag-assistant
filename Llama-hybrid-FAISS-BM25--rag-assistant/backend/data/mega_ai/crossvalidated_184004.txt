[site]: crossvalidated
[post_id]: 184004
[parent_id]: 183427
[tags]: 
I have not worked out all of my concerns. However, I have worked out the connection between the multinomial logit link in my original post and multinomial logistic regression. Suppose there are three state: a , b and c . The relationship between probabilities of states a and b to the linear predictor for state b as used in multinomial logistic regression is: $\log(\frac{P (b)}{ P (a)}) = \beta_{0b} + \beta_{1b}X + \beta_{2b}X^2 $ $\log(\frac{P (c)}{ P (a)}) = \beta_{0c} + \beta_{1c}X + \beta_{2c}X^2 $ which equals: $e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} = \frac{P (b)}{ P (a)} $ $e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2} = \frac{P (c)}{ P (a)} $ and reorganizing: $P(a) e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} = P (b) $ $P(a) e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2} = P (c). $ Now add probabilities for all three states to obtain 1: $P(a) + P(a) e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + P(a) e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2} = 1. $ Now factor out $P(a)$: $P(a) (1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}) = 1. $ and divide to isolate $P(a)$: $P(a) = \frac{1} {1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}}. $ The above equation for $P(a)$ is the same as the one I used in my original post. To obtain the equation for $P(b)$ used in my original post substitute the equation immediately above for $P(a)$ into the equation given a few lines up for $P(b)$: $P(b) = \frac{1} {1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}} e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2}. $ Do the same for $P(c)$: $P(c) = \frac{1} {1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}} e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}. $ Lastly, recall that $P(a)$ is: $1 - \frac{1} {1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}} e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} - \frac{1} {1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}} e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2} $ because: $\frac{1} {1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}} + \frac{1} {1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}} e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + \frac{1} {1 + e^{\beta_{0b} + \beta_{1b}X + \beta_{2b}X^2} + e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2}} e^{\beta_{0c} + \beta_{1c}X + \beta_{2c}X^2} = 1 $ Here is an example of multinomial logistic regression in R code showing how the parameter estimates relate to the probabilities: library(nnet) my.data This post shows, I believe, that the equations and parameters used in multinomial logistic regression are the same as those I presented in my original post for the multinomial logistic link. However, I still need to study both approaches to understand my original questions of 1). how to obtain estimates of the intercept and slope parameters algebraically (that might not be possible), 2). whether the intercept and slope estimates of b must vary as the covariate varies and 3). whether the intercept of a must vary as the covariate in b varies. If I make progress in my understanding of those three questions I will post an update. FIRST EDIT - Nov 28, 2015 Model estimates seem to be better if I include covariates for State a , even though I want $P(a)$ to be a constant 0.40 in this example. Note the nice standard errors. library(nnet) my.data
