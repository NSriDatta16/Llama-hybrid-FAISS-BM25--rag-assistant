[site]: datascience
[post_id]: 44693
[parent_id]: 
[tags]: 
What model is suitable for classification of a small data set?

I have a dataset that consists of 365 records, and I want to apply a classification model on it (binary classification). As an output, in addition to the classification labels, I want to retrieve the classification confidence for each instance. I don't know how to deal with such a case. Can I use, for example, linear classifiers (SVM, logistic regression) with this small dataset? Because, I want to retrieve the classification confidence as well. I read that decision trees can be a good classifier for small datasets, but how can I retrieve the classification confidence with it? The dataset consists of tweets, each classified as positive or negative (from a sentiment perspective), and my feature vector consists of 2400 features (combination between word2vec embeddings and other features). Also, do you recommend me to use word2vec embeddings with such a small dataset? I think the classifier can't learn something from them using small dataset.
