[site]: crossvalidated
[post_id]: 446639
[parent_id]: 446515
[tags]: 
For single predictors, the AIC and p-value criteria are effectively the same , with the AIC criterion equivalent to a p-value cutoff of 0.157. That's a very strict criterion to use in real-world applications with correlations among predictors and when, by design, a stepwise approach that starts in the forward direction doesn't take into account the associations of the omitted predictors with outcome. A forward approach using such a strict cutoff might miss important real relationships that would be found with a less strict cutoff. So the problem with forward stepwise isn't just that it can find associations with outcome that aren't really there . Your proposed use of p As you are doing logistic regression the problem with the forward approach is exacerbated. Unlike linear regression, omitting any predictor associated with outcome leads to downward bias in the magnitudes of the coefficients of the included predictors, even if the omitted predictors are uncorrelated with the included ones . So there's a serious risk that the p values will be higher than they would be if you had been using a model including multiple predictors to start. The questions you raise with respect to categorical predictors having more than 2 levels might be one reason why you see so little stepwise use of p-value criteria. What would usually make logical sense would be to rule the entire predictor, with all of its levels, in or out of the model. The AIC criterion does that quite naturally. The p values returned for such a predictor in standard summaries are for the differences of the coefficient for each level from the reference level, so you have multiple p values that depend on the choice of the reference level. What is then needed would be a test like an ANOVA F-test to get a p value that evaluates all levels of the predictor. Even if you did that, however, as I understand this answer the statistic wouldn't properly follow the F distribution so the reported p values would be meaningless. Other than that, your understanding of the initially forward but bidirectional stepwise approach, allowing for removal as well as addition of predictors, is pretty much as it is implemented in functions like the step() function in R, which uses subfunctions add1() and drop1() to add/subtract predictors individually at each step, where "individually" means entire categorical predictors with all of their levels. Looking at the open-source code for those functions might be helpful. If for some reason you need to do predictor selection and wish to understand how it is implemented, you will be better off learning about LASSO , which has a more principled basis and penalizes regression coefficients to minimize the overfitting that is endemic with standard stepwise approaches. The issue you raise about multi-level categorical predictors is then handled by the group LASSO .
