[site]: crossvalidated
[post_id]: 123080
[parent_id]: 
[tags]: 
Strategies for parallelising neural networks

When it comes to parallelising a problem, it involves the division of routines and subroutines between a number of nodes, namely; the master node and the slave nodes. Once each of these nodes completes its respective task, all the results from all the nodes are concatenated together to give the final output, hopefully in a shorter time than when using sequential computing methods. My question is, is there a standard strategy which migrates this method over to the realm of neural networks? For example, my initial reasoning was that what would be "parallelised" in this case would be the feature vector, and each portion of this vector is computed simultaneously, and then concatenated together into one again and the final result will be classified. Would this strategy make sense or would it be better to parallelise the neurons themselves instead?
