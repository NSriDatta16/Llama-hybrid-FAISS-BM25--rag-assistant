[site]: crossvalidated
[post_id]: 636524
[parent_id]: 
[tags]: 
Solving a system of equalities using a neural network

Assume $P$ is a set of pairs $(x, y)$ , where both $x$ and $y$ are in $\mathbb{R}^n$ . Assume $P'$ is a subset of $P$ . I want to train a neural network $N: \mathbb{R}^n \to \mathbb{R}^m$ such that, for any pair $(x, y)$ in $P'$ , I get $N(x) = N(y)$ . Let's call this constraint $C_1$ . I also want to enforce some other constraints on $P \setminus P'$ , which are not necessarily satisfied when $C_1$ is also satisfied for $(x, y)$ in $P \setminus P'$ . For example, when $m = 1$ , I define $C_2$ as $N(x) - N(y) \geq 1$ for all $(x, y)$ in $P \setminus P'$ . What I have observed is that, after training, almost always one of the following cases happens: $N$ becomes a trivial answer for $C_1$ ; e.g., $N(x) = 0$ for any $x$ . $N$ satisfies all of the constraints, except for $C_1$ . Why is this almost always the case? Is there a way to avoid this, e.g. by adding some term to my loss function? Edit: added an example for another constraint.
