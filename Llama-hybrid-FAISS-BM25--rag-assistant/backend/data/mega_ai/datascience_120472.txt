[site]: datascience
[post_id]: 120472
[parent_id]: 
[tags]: 
Deep Learning book - PCA - showing the covariance of z is diagonal

In the Deep Learning book at Page 146, the authors are showing that the covariance of the representation $z = W^T x$ is diagonal (Eq. 5.92 through Eq. 5.95). The terms are conveniently arranged: $$ Var[z] = \frac{1}{m-1} Z^T Z = \frac{1}{m-1} W^T X^T X W = \ldots = \frac{1}{m-1} \Sigma^2 $$ However, I am stuck on: $$ Var[z] = \frac{1}{m-1} Z^T Z = \frac{1}{m-1} {(W^T X)}^T W^T X = \frac{1}{m-1} X^T W W^T X $$
