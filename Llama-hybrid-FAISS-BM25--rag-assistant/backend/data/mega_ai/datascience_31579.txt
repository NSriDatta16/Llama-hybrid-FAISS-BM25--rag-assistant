[site]: datascience
[post_id]: 31579
[parent_id]: 29028
[tags]: 
One hot encoding is only a symptom. The cause of the problem is that your factor valible has not the same leveles in the test and train data. Here you should distinct. Is it only a problem of sampling? You created your test data as (say) 20% sample of the original data. Some levels with small cardinalty could fail to get in the sample. If it is the case you must take care to sample all levels and get 20% of data for each level. Other problem is if your factor valible is not static and through the time new lavels can emerge. Here is it realy possible to encounter new levels in "unseen data". One possible approach to handle this is to train an explicit unknown level based on some prepared average data. In the preprocessing phase all new levels are recognised and mapped to this unknown level. Periodlcally refresh the model to include the recent appeared levels.
