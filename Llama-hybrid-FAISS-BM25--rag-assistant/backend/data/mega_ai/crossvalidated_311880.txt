[site]: crossvalidated
[post_id]: 311880
[parent_id]: 
[tags]: 
Are there rules of thumb for selecting images for a supervised learning training set?

Background I have a fairly small image set (about 300 images) and I need to detect rectangular plates present in these images. Each of the images are annotated, but some examples are clearer than others due to lighting conditions (after pre-processing). The articles which I've read on supervised learning only go so far as to say that I need annotated images. Questions I'd like to find some rules of thumb for picking annotated images. For example, I have the following questions: Should I include obstructed annotations in my training set? Should I include annotations that I cannot make out myself due to lighting conditions? Is it bad if, inside the image set, I have unlabelled examples of wrenches? I.e. will this confuse my network? Should I augment the training set by performing rotations, even if I only expect to see horizontally aligned rectangular plates? Implementation I'm using the Python implementation of Faster-RCNN with VGG16. The setup is described here .
