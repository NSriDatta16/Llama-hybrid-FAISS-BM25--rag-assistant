[site]: datascience
[post_id]: 88254
[parent_id]: 88248
[tags]: 
First of all it's a question which can lead to some awesome discussions from the community :) To me, calling the process of training the model "parametrization" is somewhat correct as essentially what we are doing is to make the model more optimized to solve the problem statement just like Google's Duplex which was able to pass the Turing test for a specific domain only. But then there comes the concept of Reinforcement Learning where agent's works on maximizing the reward and take actions which could never have thought of. Take the case of AlphaGo where AI tries to understand the game and learns from it's mistake.
