[site]: crossvalidated
[post_id]: 308177
[parent_id]: 280297
[tags]: 
Have you tried early stopping? Usually early stopping is enough for small neural network architecture over dropout. Dropout is most widely used for hundreds and thousands of parameters, usually it is the employ to prevent over-fitting in high dimensional models. In other words, you can use early stopping first, then you can tweak your architecture for more improvements like weight decay and other things.
