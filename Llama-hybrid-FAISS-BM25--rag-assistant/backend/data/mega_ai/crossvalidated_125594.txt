[site]: crossvalidated
[post_id]: 125594
[parent_id]: 125470
[tags]: 
I'm going to presume to rephrase the question in two ways. If you don't like the new question please let me know in the comments and I can adjust. Given: An estimated total population of 20,000 which exist in two states appropriate to a binomial model (or even a SIR model) That five samples taken at (presumably random) from this population were "positive" Determine: What is the likely rate of occurrence in the population? Include CI if possible. If rate cannot be determined, what bounds can be placed on it? Requirements: If a programming language like "R" is used, provide code. Describe both the method and some justification for it. (Working) Thoughts on approach: I don't know the rate, so I'm going to use resampling to find the rate where 50% the time a random draw will yield 5/5 positive samples. After I do that, I will use that rate and resampling to determine the variation of results. I will lock in the rate, redraw 1000 times, and look at the distribution of results. I'm assuming that the sick creatures are tagged, and you aren't just putting sick fish back into the river. This means sampling is done without replacement. This is about disease in a natural population so an SIR model is much more appropriate to the "physics" of the phenomena. I need to think about this and maybe do something eventually. I don't believe in "pristine" results. It allows only reproduction of exact results, but is i.m.o. dishonest about the path so it does not allow application of the sometimes inelegant actual path and denies access to innovation in two ways. The broken road gets to all destinations that along roads that are similar to the one described. When the student is faced with a real and "non-pristine" problem they can become dis-spirited and abandon the correct but inelegant approach. I hope to capture more of the road without too much of the rocks. Code: #housekeeping rm(list = ls()) plot.new() dev.off() #make candidate rates #how many steps in rate myratecount 1)] The result of this is the following plot. Remember that the red lines are LOWER than textbook 3-sigma or 3.5-sigma Upper control limits (UCL) or Lower control limits (LCL). If this was a perfect model then you could have only a 96% rate in your population and still get 5 samples that were positive. The (HUGE) problem with that is that we need to have a scale of sigma appropriate to our population - we are trying to draw a box around where the data can live. If I look at a t-table for 5 samples (nu=4) and find the 95% CI scale then I get a value of 2.132. This means that we can expect the majority of variation in data to occur with a window of +/- 2.132*Sample_standard_deviations around the central tendency. If we scale the sample_standard_deviation by this value then it yields a truer 1-sigma boundary. Lets make the truer 2-sigma boundary by multiplying 2.132 by 2. If I modify the code (not shown) so that the UCL and LCL are mean +/- 2.132*2*sigma then the following results. The really surprising (for me) consequence here is that the scaled 2-sigma UCL is at 100% below a population mean of 60%. A few numeric lookups gives the value as 0.57546, or about 57%. It is not entirely out of the realm of consideration that though you got 5/5 positive, the actual population rate is around 57%. If you have to have a highest plausible rate then pick 100%. If you have to pick a lowest then pick 57%. The midpoint between 100 and 57%, one that is equidistant to the extremes of error is about 78%. If you have to make a guess then 78% is what I would put as the least likely erroneous rate, all else being equal. Thought: It is worthy to contemplate "what if I had one more sample". If you have 6 samples (aka nu=5) then your t-scale on variation goes from 2.132 to 2.015. Your minimum plausible threshold goes from 57% up to 66%. That is about a 9% change in estimate for a single sample. So now you can relate an increase in sample size by one to a value in the estimate. I have to ask about selection bias. If you have a buddy who is a below-average hunter, and he is tranquilizing coyotes and taking blood samples, and this is where your data comes from then there might be a selection bias issue. He is going to have an easier time going after the weakest/slowest. If that were the case, and you could get estimates of the pack-sizes then you might be able to do some sort of extreme-value-distribution related analysis. It would change each positive from being 1/1 to 1/pack-size. The 5 samples would, hopefully, come from different packs. ... SIR thoughts to come later .. possibly never. It is too complex, and I don't know anything about the nature of the creature or the nature of the "positive". You could be looking at hormone levels in fish, counting parasites on shrimp, looking at bark-beetles in southwest pine trees, or Ebola patients in Mali. A general model to blindly handle that is ... too big for me to work on right now.
