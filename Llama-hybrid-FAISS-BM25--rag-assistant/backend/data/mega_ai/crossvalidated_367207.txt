[site]: crossvalidated
[post_id]: 367207
[parent_id]: 367177
[tags]: 
PCA. If a few principal components explain a significant portion of the variance, you could achieve meaningful dimension reduction this way. PCA also has the added benefit of giving you uncorrelated variables, which helps with satisfying the Naive Bayes assumptions (i.e. Naive Bayes assumes that given the class, feature are independent). You could also take a look at factor analysis, and checking if your factor loadings are interpretable (although I guess that's not super important for an ML application). Factor scores are also uncorrelated.
