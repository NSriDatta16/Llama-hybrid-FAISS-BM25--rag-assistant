[site]: crossvalidated
[post_id]: 453082
[parent_id]: 
[tags]: 
Should we apply PCA before calculating similarities in high-dimensional space if my observations have length 1?

I have high-dimensional space (around 20 features) and I want to calculate similarity based on the angle of observation, not the magnitude. I have a nice function that can compute euclidean distance fast, so I wanted to use it instead of some worse performant function to compute cosine similarities. But as there's direct relationship between euclidean distance and cosine similarity as explained enter link description here here I think I'm fine as long as I normalise each observations to have length 1. So I did. But since it is high-dimensional space I feel I could benefit from using PCA. Before PCA, scaling features is advisable as they have ranges and, therefore, variances. But after scaling features I don't have the observations of length 1 anymore, so euclidean distance is not "equivalent" to cosine similarity anymore. My understanding is that since performing PCA and choosing n principal components changes our features space I should normalise observations in the new feature space and not the old one, because I am calculating similarities on the new feature space. But it still feels like kind of a chicken-or-egg situation. Am I right about normalising observations in new feature space obtained from PCA? Or should we normalise the observations before PCA? If so, why?
