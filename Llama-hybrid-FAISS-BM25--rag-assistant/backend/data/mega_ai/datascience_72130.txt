[site]: datascience
[post_id]: 72130
[parent_id]: 
[tags]: 
Dimensionality reduction and prediction when all columns have approximately same variance

I have a dataset of 25 columns where the goal is to predict the value of the 25th column based on the previous 24 columns. The dataset is quite big that's why I initially thought to proceed with PCA before doing any prediction. The problem is that PCA did not produce any good results in the sense that it outputs a 4% variance explained on each PC. I suspect that this can be attributed to the fact that the variance of all columns is approximately the same (say from 90-91% for each column). I am wondering what can be done in such a case to reduce dimensionality and what data science algorithms are most suited to address this problem. I have already tried OLS, Random Forests, SVR and Gradient Boosting regression but their scores seem quite disappointing at the moment, letting aside the fact that the computational time is quite large.
