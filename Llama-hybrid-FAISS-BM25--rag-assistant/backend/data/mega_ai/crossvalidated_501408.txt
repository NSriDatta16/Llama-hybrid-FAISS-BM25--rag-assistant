[site]: crossvalidated
[post_id]: 501408
[parent_id]: 497403
[tags]: 
In some settings, it would be fine to keep training the network, and the validation loss will continue decreasing towards an asymptote. However, boosting the model's confidence is a poor motivation for continuing the training. First, it is unclear whether your model becomes more calibrated as you keep training. Typically, these deep neural networks just become over-confident without correctly capturing their probability of correct classification. To check this, you have to use a calibration plot or measures such as Expected Calibration Error (ECE). Secondly, there are ways of adjusting your model's confidence that are both computationally cheaper and more principled. In general, these calibration methods operate by scaling the confidence via the adjustment of few parameters (or even a single parameter) in the readout layer such that some cost function defined on held-out data is minimized. This function can be cross-entropy if your aim is well-calibrated models. Reference: Guo, Chuan, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. "On calibration of modern neural networks." arXiv preprint arXiv:1706.04599 (2017).
