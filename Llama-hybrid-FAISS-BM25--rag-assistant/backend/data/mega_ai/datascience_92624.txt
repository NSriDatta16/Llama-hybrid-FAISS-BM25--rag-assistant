[site]: datascience
[post_id]: 92624
[parent_id]: 92602
[tags]: 
A common intuition is viewing attention as probabilistic retrieval: given a query, you want to retrieve some information from some states (values) given some keys that describe the values. With single-head attention, you get a weighted average of some hidden states with everything that is contained in there. Once you introduce, the head-specific projection, the model has much more flexibility. The information you use for retrieving (in the query-key comparison) can be of a different kind than the value. One head can retrieve a piece of information from some states, another head can retrieve a different piece of information. The head-specific projections also allow throwing away what is no longer relevant for the next layers.
