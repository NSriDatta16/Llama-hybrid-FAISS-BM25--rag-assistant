[site]: crossvalidated
[post_id]: 386304
[parent_id]: 283261
[tags]: 
I think this can be better explained from a digital signal processing point of view. Intuitively max-pooling is a non-linear sub-sampling operation. Average pooling , on the other hand can be thought as low-pass (averaging) filter followed by sub-sampling. As it has been outlined by Shimao with a nice example, the more the window size is increased, the more information is lost. Considering first average pooling (which is linear and thus maybe easier to understand) if overlapping is maximum it is in fact just a convolution with a moving average kernel followed by sub-sampling. In other words it is akin to a anti-aliasing (low-pass) filter followed by a decimation operation. If overlapping is not one we are decimating more (just apply the dsp noble identities) thus we are subjected to spatial aliasing as more information is lost and the anti-aliasing filter certainly would not suffice. Back to max-pooling the reasoning should be similar. If the pooling regions do not overlap, the pooling regions are disjointed and if that is the case, more information is lost in each pooling layer. If some overlap is allowed the pooling regions overlap with some degree and less spatial information is lost in each layer . Loss of spatial information by pooling even if is thought to give some degree of spatial invariance to CNNs can be detrimental if abused because it can lead to overfitting as the network will "focus" only on some dominant features; but because the pooling regions are disjointed, it looses quickly any information (in higher layers) of where the feature is located in the image . This obviously can happens for high capacity, deep, models. Letting the pooling regions overlap allows to mitigate for this effect.
