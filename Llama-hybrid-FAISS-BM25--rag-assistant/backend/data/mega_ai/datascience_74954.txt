[site]: datascience
[post_id]: 74954
[parent_id]: 
[tags]: 
Using word embeddings for kaggle?

Not sure, if this is the right forum so redirect me if it wrong. I have started on an NLP problem in kaggle. There i have word embeddings from google news, wiki, glove in a zipped folder. I want to use one of them, say glove, without unzipping the zipped file. This is beecause if I try to unzip, it exceeds the 4.9 Gb space limitation and throws error and stops. Any idea on how to deal with it? I found out the way around for it. import io import zipfile dim=300 embeddings1_index={} with zipfile.ZipFile("../input/quora-insincere-questions-classification/embeddings.zip") as zf: with io.TextIOWrapper(zf.open("glove.840B.300d/glove.840B.300d.txt"), encoding="utf-8") as f: for line in tqdm(f): values=line.split(' ') # ".split(' ')" only for glove-840b-300d; for all other files, ".split()" works word=values[0] vectors=np.asarray(values[1:],'float32') embeddings1_index[word]=vectors
