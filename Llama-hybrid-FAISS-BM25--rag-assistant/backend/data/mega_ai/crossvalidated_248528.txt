[site]: crossvalidated
[post_id]: 248528
[parent_id]: 
[tags]: 
Mixed Effects Model with a Large Sample

I have data with over 40,000 observations. The dependent variable is binary, and I have around 20 independent variables, some numerical and some categorical. The data involves women who gave birth in a specific hospital, and the dependent variable is telling us if the woman chose to stay (and pay) in the hospital's motel. Every row in the dataset is a birth (with 1 or more babies). The data was collected for years, therefore, some women gave more than one birth, and so I have a mother ID variable. Out of ~40,000 rows, I have ~30,000 different mothers. I wish to run a mixed effect logistic regression. Here is the problem: with the size of my data, all the P-Values are significant, even though the odds ratios are close to 1. This is fine, since I can get a CI for the odds ratio and distinguish between "real" findings and "non real". The problem is the modelling process. I do not use stepwise or other automatic methods. I enter and remove variables from my model manually according to the P-Values (following the algorithm of Collett). In my case, everything is significant. I wanted to ask, how should I build the correct model, how do I choose the variables to be in it, and is it problematic that I have 30,000 clusters out of 40,000 observations? If you can give me an example of R code for it, even better, I ran it with SAS, but prefer to compare an alternative. I will appreciate any advice on this complicated matter. Thank you.
