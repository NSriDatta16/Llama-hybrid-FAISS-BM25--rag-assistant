[site]: crossvalidated
[post_id]: 112340
[parent_id]: 112322
[tags]: 
I think the slides are a bit ambiguous. For the Bayesian approach you can (among many other things) assume that: All protocols share the same $p$. Then there's a single prior over what that $p$ might be. Each study $i$ has its own $p_i$. Then you can either 2.1. Assume that there's nothing in common to the three protocols, so that nothing in the results of one protocol could be informative about the others. Then you might want three independent priors, one for each $p_i$. Or, perhaps more reasonably... 2.2 Assume that all are these three protocols are a 'sample' of the possible protocols that could have been run. In which case it's natural to think of the $p_i$ for each protocol to be a draw from a common prior over $p$. You might formalise this as reflecting an exchangeability assumption, but that doens't much matter for your question. Assumption 1 (plus model and data) will generate a marginal posterior over $p$. Both of assumptions 2 will generate a marginal posterior over [$p_1, p_2, p_3$], but with potentially different properties. But I suppose what the slides are going for is the idea that, from a Frequentist perspective, a natural null hypothesis to test is that $p=p_1=p_2=p_3$. Rejecting this suggests that there is variation across the $p_i$ which one might investigate further. However one might, in equally Frequentist mode, simply ask for confidence intervals for the different $p_i$ and see if they overlap (assuming you could get the coverage right, etc.) This would give results rather closer to those generated through assumption 2.1., without formally assuming, even as a null hypothesis, that there was a single fixed $p$. This second approach makes the Frequentist and Bayesian approaches look much more like each other. And spoils the overly sharp contrast that the slides seems to be making.
