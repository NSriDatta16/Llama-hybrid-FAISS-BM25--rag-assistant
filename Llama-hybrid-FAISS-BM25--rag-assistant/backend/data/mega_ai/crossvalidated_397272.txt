[site]: crossvalidated
[post_id]: 397272
[parent_id]: 397257
[tags]: 
There is no definition of how big a "large" state space is. That being said, a table with 1 million Q values is too large. Instead of using the table lookup as an exact Q function, you should use function approximation with number of parameters $k . This could be something as simple as state aggregation (treat many states as one), linear function approximation, or nonlinear approximation with a neural network. If you do some kind of function approximation, instead of updating the Q value directly, you'll update your function parameters. $$\left.\mathbf{w}_{t+1} = \mathbf{w}_t + \alpha\left[r+\gamma \max_{a'} \hat{Q}(S_{t+1},a';\mathbf{w}_t) - \hat{Q}(S_t,A_t; \mathbf{w}_t)\right]\nabla_{\mathbf{w}_t}\hat{Q}(S_t,A_t; \mathbf{w}_t)\right.$$ I recommend reading Chapter 9 of Sutton and Barto's Intro to RL book for more about function approximation in RL. And you absolutely can speed up learning by having parallel agents share information! I don't know the specifics, but I wouldn't be worried about corrupted shared data. I'm pretty sure Python would handle a mutex or something for that.
