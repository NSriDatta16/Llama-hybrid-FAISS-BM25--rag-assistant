[site]: datascience
[post_id]: 30898
[parent_id]: 
[tags]: 
Can you sum up gradients and apply in batch?

I'm following this Reinforcement Learning Tutorial . There, training data is collected during an episode. When the episode is done, the data is used to do backpropagation. However, instead of applying the calculated gradients to the model, they are stored in a buffer. The gradients of multiple episodes get summed up before they are applied. I wonder if that is a reasonable thing to do. Usually, if the model is very good after training with the first episodes data, the gradients of the other episodes will be close to 0 (no change). If you used the tutorials code, the gradients of all episodes would be large, and the model would move away from the optimum. Am I missing something? Edit: I tried buffering gradients with Q-Learning and compared it to directly updating the weights. It is working, but buffering is definitely worse.
