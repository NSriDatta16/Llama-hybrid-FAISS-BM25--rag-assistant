[site]: crossvalidated
[post_id]: 363686
[parent_id]: 
[tags]: 
Power and Sample Size Estimation for Logistic Regression (Mixed) Models

I am working on designing a study based on some initial pilot data and would like to conduct a sample size estimation. I have previously used simr with linear mixed effects models. In this case, I think a logistic (glm) or logistic mixed model (glmer) are more appropriate, but am unsure if I am approaching things correctly/defensibly. I have data from 29 subjects with two continuous predictors (scores on two assessment), a binary outcome of event occurrence in the last 12 months, and the count of events in the last 12 months. Example data: Data I have tried I have tried poisson and binomial logistic and logistic mixed models: # Logistic models Mod1 I have tried some estimating power using powerSim in the simr package: powerSim(Mod1, nsim = 100) Power for predictor 'Score', (95% confidence interval): 5.10% ( 3.82, 6.65) Test: z-test Based on 1000 simulations, (0 warnings, 0 errors) alpha = 0.05, nrow = 29 powerSim(Mod2) Power for predictor 'Score', (95% confidence interval) 3.20% ( 2.20, 4.49) Test: z-test Based on 1000 simulations, (0 warnings, 0 errors) alpha = 0.05, nrow = 29 powerSim(Mod3) Power for predictor 'Score', (95% confidence interval): 4.60% ( 3.39, 6.09) Test: z-test Effect size for Score is 9.1e-05 Based on 1000 simulations, (11 warnings, 0 errors) alpha = 0.05, nrow = 29 powerSim(Mod4) Power for predictor 'Score', (95% confidence interval): 1.70% ( 0.99, 2.71) Test: z-test Effect size for Score is -0.0038 Based on 1000 simulations, (715 warnings, 1 error) alpha = 0.05, nrow = 29 Power is low, so I'd like to know how much larger the sample should be to get closer to 80%. My first question is whether a standard ( glm ) is more appropriate than a mixed ( glmer ) approach? I've seen some conflicting views on the appropriateness and risk of over-fitting with single observation groupings. My second questions is how to go about extending the models with the extend function in simr . How do I extend the model to estimate the effects of more subjects? I have tried the following for the standard ( glm ) models: powerCurve(extend(Mod1, along = "Score", n = 100)) Power for predictor 'Score', (95% confidence interval), by largest value of Score: 3: 0.00% ( 0.00, 0.37) - 7 rows 14: 2.70% ( 1.79, 3.90) - 23 rows 25: 5.40% ( 4.08, 6.99) - 40 rows 35: 4.70% ( 3.47, 6.20) - 54 rows 46: 4.50% ( 3.30, 5.98) - 74 rows 57: 3.50% ( 2.45, 4.83) - 87 rows 68: 4.20% ( 3.04, 5.64) - 106 rows 78: 3.60% ( 2.53, 4.95) - 122 rows 89: 3.70% ( 2.62, 5.06) - 138 rows 100: 4.50% ( 3.30, 5.98) - 155 rows powerCurve(extend(Mod2, along = "Score", n = 100)) Power for predictor 'Score', (95% confidence interval), by largest value of Score: 3: 0.00% ( 0.00, 0.37) - 7 rows 14: 3.80% ( 2.70, 5.18) - 23 rows 25: 5.80% ( 4.43, 7.43) - 40 rows 35: 5.60% ( 4.26, 7.21) - 54 rows 46: 4.90% ( 3.65, 6.43) - 74 rows 57: 5.80% ( 4.43, 7.43) - 87 rows 68: 7.90% ( 6.30, 9.75) - 106 rows 78: 8.40% ( 6.76, 10.29) - 122 rows 89: 10.50% ( 8.67, 12.57) - 138 rows 100: 10.40% ( 8.58, 12.46) - 155 rows These results don't make sense to me, since each row represents an observation and the model has one observation per subject. The output goes to 155 rows rather than 100. How do I simulate the effects of adding more subjects? Am I going about this all wrong? For the mixed ( glmer ) models, I got rank-deficiency errors during simulation, so I dropped "Score1" and used: Mod5 These look more like what I'd expect. But, I had to drop one of the predictors to get it run and more importantly I'm unsure about whether or not a mixed model is appropriate and/or defensible.
