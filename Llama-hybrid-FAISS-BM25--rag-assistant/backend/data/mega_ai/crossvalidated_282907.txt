[site]: crossvalidated
[post_id]: 282907
[parent_id]: 
[tags]: 
Bayesian in R, the posterior of OLS with non-informative prior

I know that beta and sigma2 in Bayesian OLS could be simulated by standard distribution, i.e., sigma2 by inverse gamma and beta by normal. Instead of that, as a beginner, I try to practice MCMC methods directly on the OLS posterior with non-informative. That is, (X contains a column of 1 to account the intercept, is it right?) Prior: g(beta,sigma2) ~ 1/sigma2 Likelihood: y|beta,sigma2,X ~ N(X*beta,sigma2*I) So posterior: beta,sigma2|y,X ~ N(X*beta,sigma2*I)*(1/sigma2) I want to make sure sigma2 is positive, so I do variable transformation by sigma2=exp(eta). If I'm not wrong, the posterior will be changed to New posterior: beta,eta|y,X ~ N(X beta,eta I) Thus, in R, I write the following function for posterior, b_ols I have three IVs, stored in the 2nd to 4th column of data, the DV in the 5th column of data. Data[,1] contains a vector of 1 to account for the intercept. Similarly, theta includes beta and eta. However, the algorithm failed to generate the correct result. I wonder is there anything wrong the posterior function I have written? Or my way of thinking?
