[site]: crossvalidated
[post_id]: 360366
[parent_id]: 
[tags]: 
Why not detect convergence in word2vec (skip-gram and cbow)?

In the word2vec software, as well as the implementation in gensim , training is done for a given number of epochs, and the learning rate (alpha) is decreased every 10000 words till a minimal alpha. Hence the training rate and termination have nothing to do with how well we are doing in maximizing the objective function. How do we know that this method gives embeddings that optimize the objective function and that we are not really far from a local optimum when we stopped training? Computing the value of the objective function is expensive in word2vec, but wouldn't it be better to compute (some approximation of) the objective function and use that to adjust the learning rate and decide when to quit training? Would this result in better embeddings?
