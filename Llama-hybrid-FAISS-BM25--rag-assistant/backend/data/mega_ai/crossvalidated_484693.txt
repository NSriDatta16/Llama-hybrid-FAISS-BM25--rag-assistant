[site]: crossvalidated
[post_id]: 484693
[parent_id]: 484645
[tags]: 
The same exact procedure (which qualifies as importance sampling implemented via Metropolis-Hastings) applies to any integration range $(a,b)$ . Select an importance probability density $w(\cdot)$ over $(a,b)$ [for instance, $w(x)\propto e^{x^2}-1$ ] Simulate a Markov chain $(X_t)_t$ with stationary distribution $w(\cdot)$ Approximate the integral $\int_a^b f(x)\text{d}x$ by the empirical average $$\frac{1}{T}\sum_{t=1}^T f(x_t)/w(x_t)$$ or, if the normalising constant is unknown, $$\sum_{t=1}^T f(x_t)/w(x_t)\Bigg/\sum_{t=1}^T 1/w(x_t)(b-a)$$ The bottom approximation is based on the identity \begin{align*}1&=\int_a^b \frac{1}{b-a}\text{d}x\\&=\int_a^b \frac{1}{b-a}\frac{w(x)}{w(x)}\text{d}x\\&=\int_a^b \frac{A}{(b-a)w(x)}\frac{w(x)}{A}\text{d}x\\&=\mathbb{E}\left[\frac{A}{(b-a)w(X)}\right]\end{align*} (It is a safe version of the harmonic mean estimator .) As for suggesting textbooks on MCMC integrations, there are many to pick from Computational Bayesian Statistics by Antónia Amaral Turkman, Carlos Daniel Paulino, and Peter Müller Statistical Rethinking: A Bayesian Course with Examples in R and Stan by Richard McElreath Bayesian Data Analysis by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Don Rubin (avoiding citing my own books !)
