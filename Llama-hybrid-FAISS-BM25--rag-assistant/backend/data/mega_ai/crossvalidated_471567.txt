[site]: crossvalidated
[post_id]: 471567
[parent_id]: 
[tags]: 
Similar error and R2 on Multiple Linear Regression and Random Forest, but very different predictions for new values?

I'm trying to compare a Multiple Linear Regression model against a Random Forest Regression model using sklearn. I have 4 features and one continuous variable to predict. I am training on 70% of the data and testing on the remaining 30%, the original dataset size is ~10000 samples. I have set a random state for splitting the data and also tuned the parameters for RF using cross validation and grid search (n_estimators=1675, min_samples_split=10, min_samples_leaf=1, max_features="sqrt", max_depth=40, bootstrap=True) . The results are very similar with as little as 30 trees. The metrics I get for Multiple Linear Regression (test data): R2: 0.4556 MAE: 0.0193 RMSE: 0.0246 The metrics I get for Random Forest Regression (test data): R2: 0.5111 MAE: 0.0183 RMSE: 0.0233 But when I use the same set of new values to generate a new prediction (out of sample) I get very different values (the range should be approximately 0-1): MLR: 0.3894 RF: 0.1442 Furthermore I looked at the QQ-plot for the residuals and it seems to be fairly straight for Multiple Linear Regression, while it seems to curve in opposite directions at each end for Random Forest. I'm new to RF but this seems very odd to me, is there any possible explanation? Is it plausible the error be so similar yet the prediction be so different? In which case, what model should be trusted more?
