[site]: crossvalidated
[post_id]: 602560
[parent_id]: 
[tags]: 
Can XGBoost do classification based on linear combinations?

Suppose we have a data set $\mathcal{D}$ consisting of $n_C$ continuous features $\boldsymbol{X}_1, \boldsymbol{X}_2, \dots, \boldsymbol{X}_{n_C}$ and we wish to target a discrete variable $\boldsymbol{X}_D$ which takes 4 levels based on some linear combination of the continuous features. For simplicity, assume that $X_{i,D}$ is based on the value of $X_{i,1}+X_{i,2}$ (where $i$ refers to the $i$ th observation) (e.g. if $X_{i,1}+X_{i,2} \in [a,b]$ then $X_{i,D} = 1$ , if $X_{i,1}+X_{i,2} \in [c,d]$ then $X_{i,D} = 2$ etc. with $[a,b]$ and $[c,d]$ disjoint even, for simplicity). Would an XGBoost classifier be able to detect this relationship and build a classifier targeting $\boldsymbol{X}_D$ that uses all continuous features as predictors (obviously any other feature besides the 2 determining the relationship will be given an almost 0 importance)?
