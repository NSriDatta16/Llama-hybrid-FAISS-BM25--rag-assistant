[site]: crossvalidated
[post_id]: 439146
[parent_id]: 439097
[tags]: 
Simple Models If you are looking for simple models I would test these: Linear Regression Exponential Smoothing with seasonality Seasonal ARIMA models Rule of thumb methods: seasonal naive method, seasonal mean, simple mean. These models should help you in assessing a baseline for the model performance. I believe models 1-2-3 are already implemented in the statsmodels library. Depending on how granular your forecast needs to be, you might want to perform a hierarchical forecast . I've used a top-down hierarchical approach for a client (Fashion Retail) that needed forecasts for both product categories and single skus inside the category. Moreover, these models have the advantage of being more transparent and interpretable compared to machine learning models. If your model produces crazy non-sensical predictions, it's much easier to debug them. Machine Learning Algorithms If you don't have constraints for model transparency/interpretability, you can employ some Machine Learning algorithms, such as: Gradient Boosted Tree Methods (lightgbm, catboost, xgboost, sklearn libraries): these methods don't need a ton of data to be effective, so they should work with monthly observations. It took me a while to study the math behind them, but you don't really need to know how they work to get predictions from them. These libraries are also well documented and there are a ton of examples online. Neural networks: they have been employed succesfully both in literature and in online competitions . They usually need a lot of data to shine, though. If you never used them before, I'd try the other models first. However if you are not doing this stuff for work, I suggest you check them out because in my opinion they make use of very interesting concepts and ideas. Ensemble models: they combine the predictions of different models, for example by using the average or the median of your models' predictions. This can usually improve your forecast, especially if there is low correlation between the prediction errors of the different models. Of course, it is more time consuming to maintain more than one model in production. Data You should avoid including data features that can't be predicted with a reasonable amount of accuracy. For example, if you have information about daily temperature/weather, you can easily see its effect on past sales, but you can't really use weather forecasts for predicting far into the future, because weather forecasts become unreliable after 3 days in the future. Promotional activities heavily impact sales. They can also be planned in advance, so if you can get your hands on this data, try to assess if it can be beneficial to your model. Inventory/Stock out information: sometimes it can happen that your product is so in demand, that you run out. If you don't have any information about stock-outs, your demand data is "censored", and you have no way of knowing if you didn't sell because people didn't want to buy or because the product wasn't available. Note that there is a distinction between predicting Sales and Demand. Predicting sales is useful for forecasting financial performance, while predicting demand is useful for optimally allocating inventory. Holidays and special events. This information is probably not so useful if you have to generate a monthly forecast. It still might be useful if you have important festivities that sometimes fall in one month, and sometimes in the other (e.g. forecasting sales of Easter eggs and colomba cakes in Italy). Outlier removal techniques can be useful for improving the staibility (and sometimes error metrics) of your forecast Additional sources that I found useful (I wrote a thesis on demand forecasting 2 years) https://otexts.com/fpp2/ My favorite book on forecasting (code implementations are in R, but I found equivalent Python tutorials/examples for most models) kaggle.com has a lot of great notebooks written by really smart and skilled people. https://www.youtube.com/watch?v=68ABAU_V8qI Great video that explains the tradeoffs between complexity and predictive power of a model. It also has some neat "tricks" that can be used in forecasting (although not all are applicable for monthly time series). Tips: Make sure that your model/feature engineering choices are aligned with the granularity and forecasting horizon of the problem at hand. if you use Python and pandas to handle your data, the resample function is a great tool. It allows you to quickly aggregate data in periods of specified length (for example, weekly, monthly, quarterly) with just one line of code. Transforming the target variable before fitting the model can be useful. For example, if you try to estimate the variable y = log(Sales) and then do an inverse transformation, you can ensure that your predictions are positive.
