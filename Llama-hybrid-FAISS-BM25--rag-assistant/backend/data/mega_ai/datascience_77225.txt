[site]: datascience
[post_id]: 77225
[parent_id]: 
[tags]: 
Conventions for dimensions of input and weight matrices in neural networks?

Im currently learning neural networks and I see conflicting decsriptions of the dimensions of weight and input matrices on the internet. I just wanted to know if there is some convention which more people use than the other. I currently define my input matrix X with the dimensions of: (m x n) Where m is the number of samples and n is the number of features. And I define my weight matrices with the dimensions: (a x b) Where a is the number of neurons in the layer and b is the number of neurons in the last layer. Is that conventional or should I change something?
