[site]: stackoverflow
[post_id]: 3226414
[parent_id]: 3226268
[tags]: 
I don't think that it really matters, but it is more important to group the thread blocks logically, so that you are able to use other CUDA optimizations (like memory coalescing) This link provides some insight into how CUDA will (likely) and organize your threads. A quote from the summary: To summarize, special parameters at a kernel launch define the dimensions of a grid and its blocks. Unique coordinates in blockId and threadId variables allow threads of a grid to distinguish among them. It is the programmer's responsibility to use these variables in the kernel functions so that the threads can properly identify the portion of the data to process. These variables compel the programmers to organize threads and there data into hierarchical and multi-dimensional organizations.
