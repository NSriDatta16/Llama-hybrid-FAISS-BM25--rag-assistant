[site]: crossvalidated
[post_id]: 495408
[parent_id]: 413467
[tags]: 
over-parametrization is a simple method to introduce additional dimensionality and help make the local minimal to be a saddle point so the optimizer would be less likely stuck at local minimal and can find the global minimal. Actually, in deep learning, over-parametrization does not necessarily lead to overfitting, and it works well in practice
