[site]: crossvalidated
[post_id]: 587414
[parent_id]: 455524
[tags]: 
Totally agree with Jindrich, I work in Chinese Grammatical Error Correction (CGEC) and BiLSTM-CRF is the fundamental structure of our network. Basically, BiLSTM is used to take the context into consideration, while CRF is capable of considering longer relationships. Although CGEC is different from NER, it shares the same logic. In CGEC we need to tag the grammatically incorrect characters with a label. BiLSTM reads the text embedding and provides a probability about NER encoding, CRF uses the probability as an input , find the shortest path using the Viterbi algorithm, and ultimately gives the final result. The reason that CRF can learn the internal logic is that based on BiLSTM it gives the probability distribution and emission score matrix as the input of CRF, CRF would learn from the input to know how to label the sequence.
