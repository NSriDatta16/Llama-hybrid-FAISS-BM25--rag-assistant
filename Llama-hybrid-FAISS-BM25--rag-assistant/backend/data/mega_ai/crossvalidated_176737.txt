[site]: crossvalidated
[post_id]: 176737
[parent_id]: 176704
[tags]: 
The below answer is restricted to the MA(2) coefficient which I am calling $\phi_2$ . All of this may be generalized to the other coefficients which aren’t significant. Here $\phi_2$ represents the “true” value of the MA(2) coefficient which is unknown. Your estimate of $\phi_2$ is $\hat \phi_2$ which you do know because it came with the output of your ARIMA model. Just to be perfectly clear the hypothesis test being conducted in the background is $$H_0:\;\; \phi_2=0\;\;\;\;\;H_a:\;\; \phi_2 \neq 0$$ This is what is used by standard statistical packages when reporting p-values in output. If you are referring to some other test you will have to correct me. Below is what failure to reject the above hypothesis and "insignificant" mean and do not mean in this context. Things it means You cannot reject the null hypothesis that $\phi_2=0$ (holding all other coefficients constant of course). For example suppose $\alpha$ =5%, and you estimated $\hat \phi_2= .1$ . If you asked yourself: “if I assume a priori the the true value of the MA(2) coefficient was zero ( $\phi_2=0$ ), what is the probably of getting $|\hat \phi_2|\geq .1$ ?” the answer would have to be greater than 5% (the p.value is the answer to this question). If the answer was 5% or lower, it would make you suspect of the null hypothesis and you would reject that $\phi_2=0$ , but because it wasn’t, you are unable to reject the null that $\phi_2=0$ , thus the MA(2) coefficient is “insignificant”. Things it does not mean: I am including this only because most people end up making these incorrect assumptions at some point in time. The below may or may not be true given failure to reject $\phi_2=0$ ; $\phi_2$ is probably equal to zero, or approximately zero You would be better off leaving $\phi_2$ out of the model, a model without $\phi_2$ would offer better forecasts. What this type of hypothesis test is useful for? These types of tests are useful when rejected because they provide strong evidence that a non-zero coefficient exists where we had previously not thought one to exist before. In a time series setting an example may be showing that a shock to the unemployment rate persists for a certain number of lags, which may be important to policy makers at the federal reserve or something. When a lot of coefficients in your model are insignificant, (this may be your case), it could be a potential sign of overfitting. This is because when you include an excessive number of parameters or partially redundant parameters, the standard error of all the parameters in the model have a tendency to increase (Note: this does mean that the inclusion of any additional parameter will cause standard errors to increase). What this type of hypothesis test is not useful for ? Though lots of insignificant coefficients hint towards an overfit model, they should not, in and of themselves, be used for model selection and/or removing coefficients, rather AIC, BIC, MSFE, and methods of that nature are built for that purpose. In my own experience I have discovered instances where models with a lot of insignificant coefficients outperform models with all significant coefficients.
