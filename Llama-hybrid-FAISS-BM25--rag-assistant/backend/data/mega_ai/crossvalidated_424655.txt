[site]: crossvalidated
[post_id]: 424655
[parent_id]: 
[tags]: 
Threshold crossing: Integrating posterior distribution over a forecast period

Suppose I have some time series $\{Y_t\}_{t=1}^T$ and I have come up with some probabilistic model: $$p(Y_{t+h} \mid Y_{1:t}, \theta)$$ for any horizon $h$ , and some parameters $\theta$ . Now suppose I'm interested in the probability that the time series stays below some threshold in the forecast period: $p(Y_{t+1:t+h} . Maybe $u$ is a critical level of temperature on a machine. If even one future $Y$ ends up above $u$ , we'll experience bad times and so we want to make sure that the probability of staying below this threshold at any time $t$ , given our history, is large for a forecast period $[t+1, t+2, \ldots, t+h]$ . Let's just call this a "threshold probability". If we have a generative model (like ARIMA), we could compute our threshold probability via recursive simulation (monte carlo) with the estimated parameters but this is expensive in my application. Instead, I think I can use the following procedure: Given our data $\{Y_t\}_{t=1}^T$ , a prior distribution, and some model $\mathcal{M}$ , we can compute the predictive posterior distribution for $Y_{t+1:t+h}$ . Denote this as $q := p(Y_{t+1:t+h} \mid Y_{1:t}, \mathcal{M})$ Once I have this predictive distribution over the forecast period, suppose that some amount of the posterior distribution is crossing the threshold $u$ in the horizon. I can then "integrate" the forecast by drawing samples from $q$ (over the entire horizon) and counting the number of them that are greater than $u$ : $$\operatorname{draw} Y^*_i \sim q, \space i = 1,2, \ldots, N$$ $$P_u := p(Y_{t+1:t+h} My thinking is that since the predictive posterior has all the information we need about the horizon, the overall probability (given our model) of hitting $u$ is just going to be the area of the posterior that is crossing $u$ . Since we can just sample from the posterior to approximate it, by the Law of Large Numbers, this sampling should approximate the probability of hitting $u$ within the context of our model. Now that we have this probability $P_u$ , we can then use some loss function $\mathcal{L}$ that characterizes our loss in terms of $P_u$ , and we can decide to take an action or not, based on our model. Does this make sense? Computationally, it is more efficient since we do not have to estimate many sample paths. Rather we are directly sampling from the posterior predictive.
