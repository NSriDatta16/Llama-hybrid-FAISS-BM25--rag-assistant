[site]: crossvalidated
[post_id]: 576216
[parent_id]: 
[tags]: 
Building a bootstrapped distribution to test reliability of empirical data

I have data from a study where subjects (considered as "generations" in a Telephone-like game) sang short melodies from one to the next, starting from a randomly-generated melody (seed) given to the subject who acted as the first generation. The dependent variable was the average number of unique pitches (specifically, pitch classes, "PCs") across generations. The data came from 5 different experiments differing only in parameters not relevant here. Relevant for the conclusions of the study is whether a decrease in this number took place across generations, and if so, for which experiment version. Plotting the data shows a decrease in two of the expt. versions (3f and 3m): However, it seems frugal to just claim this based on the plot, without any sort of statistical test. I don't refer here to effect size (whether there's been "enough" of a decrease), but to how likely it is for such an effect (of any size) to have arisen through chance alone. I'm guessing bootstrapping would be the specific "control" against which to test for the significance of said decrease in the number of unique picthes. But it is unclear to me how the null/bootstrapped distribution should be obtained in this case, and how exactly I would then go ahead with the significance test (I've never used bootstrapping, just know of it). In the plot above, I included the DV's value for the seed, as that is as good a control as any, for x=1. However, I guess the bootstrapping would have to extend across the same number of data points (8 generations across the x-axis, in this case), and not just cover me for the first time point. I did these analyses in Matlab, if relevant. Any thoughts how this test could be implemented (or what extra details I need to give to make the question answerable) would be very much appreciated.
