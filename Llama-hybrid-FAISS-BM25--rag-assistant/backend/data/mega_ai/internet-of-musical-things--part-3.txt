ence had only the role of passively observing everything. This began to change when artistic movements led by Allan Kaprow and the Fluxus and Gutai groups began to allow for more active audience participation. In this context, interactive art emerged, characterized by allowing the viewer a degree of active involvement in the show, either by walking among the installations and sculptures, or by producing sounds, images, and movements. The architecture of these environments is designed to handle different types of signals, ranging from audio and video to those produced by the human body, such as heartbeats. As such, they also require functionality that ensures interoperability and handles data delivery delays. Ubiquitous music Ubiquitous music, usually abbreviated to ubimus, is a research field that combines music, technology, and creative processes with strong social and community engagement. Although its original proposal is focused on music production, current technological developments have opened new social and cognitive dimensions to this field, leading it to become increasingly interested in educational and artistic topics. Thus, current perspectives encompass a wide diversity of subjects and actors, ranging from casual participants to highly trained musicians. The ubimus ecosystem supports the integration of audio tools and audience interaction, and can be reconfigured to meet the needs of users. Consequently, the desired concepts are not dependent on specific implementations. Other important features are conceptual approaches and reliance on empirical methods. These aspects encourage the development of technologies for music creation, especially those that make use of common objects and spaces in the daily lives of those involved in the process. Web Audio, cloud computing and edge computing Web Audio is a JavaScript API for audio processing and synthesizing in web applications, representing a technological evolution in this segment. It presents some features common to DAWs, such as audio signal routing, low latency, and effects application. It also allows participative networked performances and expands the capabilities of using smartphones in these media. Its environment uses audio nodes for manipulating sound in a musical context. They are connected by their inputs and outputs to create paths for routing audio, which is modified by effect nodes along the way. In this way, it is able to support numerous sources with different layouts, as well as being flexible and creating complex functions with dynamic effects. Web Audio paves the way for using web browsers for musical purposes. Among the advantages observed from this are easy distribution (no installation required) and maintenance, platform and architecture independence, security (the browser can prevent plugins with incorrect behavior from affecting the system), and emergence of new types of collaboration. Cloud computing, on the other hand, is a structure composed of distributed servers that simulate a centralized network, allowing load balancing and resource replication, minimizing the amount of network consumption and improving its scalability and reliability. It aims to provide numerous services, ranging from file storage to intercommunication between music applications, offering an unprecedented level of participation and performance. Its main feature is to allow users to access the services without the need for knowledge about the technology used. Thus, they can access them on demand and regardless of location. Other points worth highlighting in this network are: broad access, elasticity, and resource management. Cloud computing infrastructure is mostly composed of numerous physical machines connected together in a network. Each machine has the same software configurations, but can differ in the central processing unit, memory usage, and disk storage capacity. This model was developed with three main objectives in mind: i) reduce the cost in the acquisition an