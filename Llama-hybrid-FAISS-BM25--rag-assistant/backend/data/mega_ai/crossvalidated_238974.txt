[site]: crossvalidated
[post_id]: 238974
[parent_id]: 
[tags]: 
Gibbs sampling for spike and slab priors

In Spike and slab variable selection (equation 4) there is a model setup of the form $\beta_k | \lambda_k, \tau_k \sim \text{Normal} (0, \lambda_k \tau_k^2)$ $\lambda_k | \nu_0, w \sim (1-w)\delta_{\nu_0}(\lambda_k) + w \delta_1(\lambda_k)$ where $\beta_k$ is the $k^{th}$ regression coefficient and $\delta_x$ is the dirac-delta function centred at $x$ (I have changed notation slightly). I'm trying to derive a Gibbs sampler for a similar model. The Gibbs sampler for this algorithm is in the appendix of the above link (page 43). My confusion comes from the update for $\lambda_k$: $p(\lambda_k | \cdot) \propto p(\beta_k | 0, \lambda_k \tau_k^2) p(\lambda_k | \nu_0, w)$ which if you follow through gives you an unnormalised density of the form $\frac{1}{\sqrt{\lambda_k \tau_k^2}} \exp(-\frac{2}{\lambda_k \tau_k^2}\beta_k^2)[(1 - w) \delta_{\nu_0}(\lambda_k) + w \delta_1(\lambda_k)]$ Intuitively, I can see how multiplying the exponent factor with the first term gives a point mass at $\nu_0$ and with the second gives a point mass at $1$, which we then normalise to give the Gibbs update in the attached paper (ie all the $\lambda_k$s in the above equation get set to either $\nu_0$ or $1$ for the update). However, I feel some things don't entirely make sense: Dirac-delta functions "pick out" the point mass values when integrating over the region around the point mass, but there is no such integration here. How does one sample from such a conditional distribution anyway? Is it simply the weighted average of the two point masses, or one or the other point mass with probabilities given by the weights? If it is the weighted average, isn't this similar to ARD rather than spike-and-slab since we're back at a continuous measure of sparsity?
