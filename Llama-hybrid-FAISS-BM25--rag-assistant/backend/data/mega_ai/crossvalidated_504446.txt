[site]: crossvalidated
[post_id]: 504446
[parent_id]: 496475
[tags]: 
At the end of the process of VQ-VAE you will have a categorical distribution which you can sample from, and generate images that will looks "real" based on the distribution of your training set. You can encode the class into one on the dimensions in the latent space, this will make it possible to control over which class to generate. i.e. you can choose your own class, then sample the rest of the random integer from the trained prior and generate image from this class. I am not sure which changes exactly you want to perform on your images but every time you sample randomly from the prior you will get different images i.e. different images for different sampled codes. You can't however "control" which specific changes to make, because the latent space is not easily interpretable. Regarding the self un supervised clustering: you can try the following: after sampling from the prior and getting codes (or alternatively run the encoder over a given image and get the codes) you can pull all the relevant embeddings according to the codes, concatenate them, this will create a vector that will represent one image. You can then generate a vector for each image, and cluster these vectors with your favourite clustering algorithm.
