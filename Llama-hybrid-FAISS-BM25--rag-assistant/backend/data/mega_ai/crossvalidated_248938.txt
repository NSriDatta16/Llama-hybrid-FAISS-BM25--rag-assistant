[site]: crossvalidated
[post_id]: 248938
[parent_id]: 248935
[tags]: 
The usage of correlated predictors in a model is called colinearity, and is not something that you want. You need to use a dimensionality reduction approach. The simplest way to avoid multicolinearity is to perform a principal component analysis (PCA) from the two correlated variables. If the correlation is high, as you are suggesting, then the first component will explain a really high portion of variance. Then, you can use the first component in your subsequent analysis. ( to reduce data dimensionality, you can use MatLab functions pca() or princomp() , and then use biplot to visualize your principal components.) About comparing the two predictors, an accepted approach seems to involve the usage of bootstrap to generate a distribution of correlations for each predictor. Then you can measure the difference between the two distributions with an effect size metric (like Cohens' d ). Function bootstrp() is what you need. Hope this helps.
