[site]: datascience
[post_id]: 101855
[parent_id]: 101772
[tags]: 
PCA will find a new orthogonal basis and new features for your data, maximizing variance along the new features/axes. Moreover by selecting a limited number of the most usefull/meaningfull new features/axis you will be able to do dimension reduction. Note that two linearly related features (x1 and x2) will probably be replaced by a unique new feature (xn) in the new basis. So the new feature (xn) may be not/less correlated to the other new features. If you train/test your model after applying PCA and keeping only most relevant features (try aroud 50 or adjust the number) you should gain efficiency as it will be faster to train and also generalize better. So It should 'work' in most case.
