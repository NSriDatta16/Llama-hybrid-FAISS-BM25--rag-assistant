[site]: datascience
[post_id]: 89733
[parent_id]: 
[tags]: 
Understanding Node Embeddings

I have only just started to look into graph neural networks and I am a little confused on the node embedding process. Here is my understanding, please let me know if i misunderstood: Given unlabelled data, we try to construct a graph $G=(V,E)$ and generate a mask that contains important features of each node such as shape, size, intensity etc. Then let's say the aim is to try and classify the nodes. So, this is where we use node embedding, it seems that it takes all of those aforementioned features and tries to condense them into a embedding matrix. And the reason we do this is because this removes all unneccessary information from the adjacency matrix and only contains all the important features of the nodes. Then afterwards we use this matrix with graph convolutions to ultimately classify unseen images. Is this right? So let's take an example, I've been looking into GraphSage , as this seems one of the best methods (is it?). It seems it can learn embeddings from a local neighbourhood, but i want to know how does that work?
