[site]: crossvalidated
[post_id]: 218940
[parent_id]: 
[tags]: 
LSTM mimicking unseen time series data during testing

I have built a LSTM network which has been trained on a time series dataset (which is week-wise logged). The LSTM is able to make pretty accurate predictions as of now. Training data seems to have this trend : Note that the training data for each of the 3 weeks is almost similar in shape. LSTM predictions on unseen testing data (week 4 data): As you can see, the LSTM is still able to trace the unexpected peak in the graph which was never seen in the training data. Any reason as to how the LSTM is able to do the above? The requirement is that the model should not be able to trace the unexpected peak and the unexpected peak gets flagged as an anomaly when an output layer on top of the LSTM compares the actual and the model predicted values and detects the large variation. Is LSTM not a suitable fit for the above scenario? Thanks in advance.
