[site]: crossvalidated
[post_id]: 593800
[parent_id]: 
[tags]: 
Input Normalization for Preprocessing Time Series Data

I have data traces for separate days that I am reading in from separate files. I'm splitting the data into smaller sequences to train a state-prediction model on, but all the data in a sequence must come from the same file. I know it's best practice in ML to normalize all input data to the network, but I am not sure how to properly normalize this input data. If I read all the data in at once, I need to split it into train and test sets before I normalize it, so I wouldn't be able to properly split it into sequences as the data would get shuffled. However, if I split the data into sequences, I can no longer normalize it because many values are present in multiple series. Is the best approach to just split the data files into train and test sets and use the first method? Just want to make sure there isn't some conventional wisdom I'm missing. Any advice is appreciated!
