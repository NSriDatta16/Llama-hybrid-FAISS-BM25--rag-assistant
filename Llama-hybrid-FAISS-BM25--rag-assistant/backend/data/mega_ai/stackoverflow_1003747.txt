[site]: stackoverflow
[post_id]: 1003747
[parent_id]: 999883
[tags]: 
Given that textures A and B are RGB images, then perhaps you can make one of them into an RGBA image, and render the mask in the alpha channel of one image. This gets you within the iPhone's limit of two texture units, allowing you to do this in one pass, without blending. GLSL pseudocode: vec4 a = texture2D(textureA, texcoord); vec4 b = texture2D(textureB, texcoord); gl_FragColor = vec4(a.rgb * a.a + b.rgb * (1-a.a), dont_care.a); Texture Environment for Unit 0: (samples RGB image B, and passes it on to the next stage) glActiveTexture(GL_TEXTURE0); glBindTexture(GL_TEXTURE_2D, textureB); glTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_REPLACE); Texture Environment for Unit 1: (image B are available in Cp and 'Ap' source. A is available in 'Cs'. Mask is available in 'As'. see Table 3.15 in the GL spec). glActiveTexture(GL_TEXTURE1); glBindTexture(GL_TEXTURE_2D, textureA); glTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_DECAL); Read section 3.7.12 Texture Environments and Texture Functions in the OpenGL ES 1.1 spec for full information. To actually render your scene into the alpha channel of the image, it may be helpful to use glColorMask(), to allow writing to only the alpha channel. How you actually get the data into that channel really depends on exactly what you're drawing to generate that mask.
