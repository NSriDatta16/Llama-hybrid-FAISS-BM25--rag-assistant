[site]: crossvalidated
[post_id]: 535499
[parent_id]: 
[tags]: 
Remove fatures with low Gini importance score to improve accuracy of Random forest

For a research project on a networking related subject, I am training and testing a Random forest model with a data set that contains 20 features. Initially, I obtained a baseline accuracy of around 77%. In order to improve the accuracy, I obtained the Gini importance scores of all the 20 features and systematically dropped the features with lower scores from the training set. This let me obtain a Random forest model with an accuracy of 90+%. My question : Is this an acceptable method? Or is there another approach that can be used in place of this, which is more acceptable in the research community? If it is acceptable, what do I need to show that it is a valid method? PS: I tried several other methods like PCA, but they were less successful.
