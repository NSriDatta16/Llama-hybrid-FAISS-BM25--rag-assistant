[site]: crossvalidated
[post_id]: 188382
[parent_id]: 188372
[tags]: 
Consider two parameters and assume for simplicity that they are estimated independently. Say the sample mean and variance of a normal population which are estimates for the respective population quantities and are known to be indepedent. From basic statistics we know how to construct confidence intervals for $\mu$ and $\sigma^2$ based on our estimates. Since this is a normal distribution, we have two beautiful pivotal quantities, namely $$\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim N(0,1)\quad \text{and} \quad \frac{\left(n-1 \right) S^2}{\sigma^2} \sim \chi^2_{n-1} $$ Based on these distributions we can now find quantiles such that $$ P \left[ -z_{0.975} Easy enough but there is a logical fallacy in these intervals, which you might have picked up. In the first interval I have assumed that $\sigma$ is known and this is clearly not the case, otherwise we wouldn't need the second interval! What we can do to resolve this contradiction is use the four inequalities to determine a confidence region for both $\mu$ and $\sigma^2$. Thus we will now be concerned with the probability \begin{align} \label{eq:1} P\left[-z_{0.975} With a slight reformulation of the above inequalities it is possible to determine the boundaries of $\mu$ and $\sigma^2$. Here is how the resulting region looks like Pay no attention to the labels in the graph, these are just minor differences in the notation of the quantiles. You can now project onto the coordinate axes to obtain a confidence interval for both $\mu $ and $\sigma^2$. But we still do not know the level of this confidence region. We have now arrived at the crux of the matter. My question to you is exactly that : what is the confidence level of this region ? Surely we have used two 95% intervals so at first one might think that we are still at the 95% level. A moment of reflection will reveal however that this is incorrect. In this simplified setting the confidence level can be computed exactly using the independence $\bar{X}$ and $S^2$. Take a look at equation (\ref{eq:1}) and recall that for two independent events A and B, $P\left[ A \cap B \right] = P[A] P[B]$. Thus $$ P\left[z_{0.975} And we have found out the hard way that two 95 % intervals do not mean that the joint confidence level, i.e. the confidence level of equation (\ref{eq:1}), is 0.95. By Bonferroni's inequality we can establish a lower bound - which is nearly attained in this case - but other than that not much can be said for the general case of non-independence. In view of this, it is often preferable to take a conservative approach and specify simultaneous confidence intervals that have at least 0.95 coverage. Indeed, the concept of exact confidence interval no longer exists in simultaneous interval estimation. Tukey's, Scheffe's and even Bonferroni's procedures are all conservative in nature. For instance, in ANOVA when you want to test contrasts you will be able to build intervals that are at least of 0.95 level but you can never be sure what their exact level is. Of course, the intervals then are much wider than in the individual cases. It appears that we cannot do better, however, so better be safe than sorry. Hope this helps.
