[site]: crossvalidated
[post_id]: 257128
[parent_id]: 
[tags]: 
Testing for significant differences in Likert-type data, including random factors

I have data from a number of subjects who rated conditions 1 through 8 on a Likert-type ordinal scale (from “much worse” to “much better”, here, coded from -3 to 3). It results in the following counts of occurrences: -3 -2 -1 0 1 2 3 1 1 2 8 18 46 28 17 2 13 15 47 24 17 2 2 3 0 5 13 21 39 24 18 4 0 5 12 25 40 26 12 5 12 12 40 32 17 5 2 6 12 12 42 31 13 9 1 7 0 8 13 60 17 20 2 8 0 9 23 54 21 10 3 Obviously, I also have the data in a regular format, where each row is a combination of subject, condition, and rating. How can I tell whether some condition pairs are significantly different from each other in terms of their ratings? For example, I may want to look at comparing conditions 3 and 4, as well as 5 and 6, since they seem very similar. Now, typically – at least in our field – people would go ahead and calculate an average rating per condition over all subjects, and then compare those means using T-tests or an ANOVA for the entire experimental design. I'm quite sure this is not the way to go, since the scale itself is ordinal (so, a no-no for calculating means). I also didn't check for normality of the responses. If I was lazy, I'd do: > t.test(subset(d, condition == 3, select = rating), subset(d, condition == 4, select = rating)) t = 0.59428, df = 237.19, p-value = 0.5529 So, I thought, a nonparametric test such as Mann-Whitney U test seems logical – at least this is what some people have used for Likert scales: > library(coin) > wilcox_test(rating ~ condition, distribution = "exact", data = filter(d, condition %in% c(3,4))) Z = 0.62165, p-value = 0.5353 Is this the correct way to go? How would I go about considering the subject being a random factor? I know the ratings can be paired by subject, but the tests do not consider this yet.
