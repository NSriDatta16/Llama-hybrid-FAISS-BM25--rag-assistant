[site]: crossvalidated
[post_id]: 133140
[parent_id]: 
[tags]: 
Question about posterior mean calibration

I'm reading the article "Prior distributions for variance parameters in hierarchical models" by Andrew Gelman( link ). This is an extract that I don't understand very well: Posterior inferences can be evaluated using the concept of calibration of the posterior mean, the Bayesian analogue to the classical notion of “bias ”. For any parameter $\theta$, we label the posterior mean as $\hat{\theta}=E(\theta|y)$ and define the miscalibration of the posterior mean as $E(\theta|\hat{\theta},y)-\hat{\theta}$, for any value of $\hat{\theta}$. Since I'm more familiar with frequentist statistics, I have some doubts about this. Can I consider $\hat{\theta}$ as the true posterior mean? What is exactly $E(\theta|\hat{\theta},y)$? The notation confuses me...can I consider it as the expected value of a estimator as in frequentist statistics? Is the miscalibration of the posterior mean the same concept of bias of a bayesian estimator? I've researched a bit in the internet but I've found out that the miscalibration of the posterior mean doesn't seem to be a common concept in bayesian statistics. Thank you
