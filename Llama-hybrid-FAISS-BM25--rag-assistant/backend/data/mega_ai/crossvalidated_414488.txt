[site]: crossvalidated
[post_id]: 414488
[parent_id]: 414481
[tags]: 
This is strongly connected with bias variance trade off and with the greedy nature of decision trees. A decision tree with large depth will tend to have large variance because it happens often that another tree to be very different, but might have small bias because it is very local (small regions). In contrast a tree with small depth does not vary that much but can have large bias because it might be not so complex. Now, random forests uses bagging, which is model averaging. Averaging reduces mostly the variance. So rf are good to reduce deep trees, it is not so effective on small one. Boosting uses gradients, which means going in small steps to target. If the tree is deep, it might go in a local minima very soon, so itâ€™s better to have a much global view. This is doable better with shallow trees because of stability and myopic view, which is equivalent with a global viw
