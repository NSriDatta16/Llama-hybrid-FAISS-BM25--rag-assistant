[site]: crossvalidated
[post_id]: 392102
[parent_id]: 
[tags]: 
Two separate repeated k-fold cross-validations vs. nested repeated k-fold cross-validation

I have set up a code in R which does 2 different repeated cross-validations with different random-indices (two different set.seed) for random forest: the first random forest run with cross-validation tunes the parameter mtry using a gridsearch the second random forest run with cross-validation uses the optimized parameter mtry from the first run and produces the cross-Validation estimate of prediction error Does my approach with the two separate cross-validation runs produce an error estimate which is also not optimistically biased? Would it be better to use nested cross-validation? Why would it be better?
