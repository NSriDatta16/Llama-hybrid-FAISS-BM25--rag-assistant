[site]: datascience
[post_id]: 121140
[parent_id]: 
[tags]: 
Why is a RNN inherently better for Time series than normal NN?

Similar to this question but I would like further clarification. I understand that in abstract, RNNs can process inputs recursively and feed some state of memory through the recursion to have a sense of context and order. However, why can a normal NN not achieve this? The input vector is inherently ordered. For example in language modelling, one might define a length for each token, and input a series of these tokens into the standard NN, and the NN could work out by itself that these are ordered and infer context in order to output its best prediction of the next token. Is the benefit that the input be 1 token at a time and so the RNN needs less complexity? Or is there something about RNN's that a normal NN simply cannot achieve? Or are they just more effective at interpreting the ordered nature of the input? If so why? I suppose I could generalise the question to - why do we need any kind of specific NN? Can a normal NN not approximate any function? Surely it could therefore learn any behaviour that some specific kind of NN exhibits?
