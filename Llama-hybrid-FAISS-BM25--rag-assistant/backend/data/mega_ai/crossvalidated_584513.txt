[site]: crossvalidated
[post_id]: 584513
[parent_id]: 
[tags]: 
How do we find a feature space where our data is linearly seperable and how do we find a kernel for this feature map?

I am dealing with Kernel SVM right now and there is one thing I don't fully understand. As I have understood the only thing we have to know to compute the hyperplane are the expressions of the form $x_i^Tx_j$ . The idea is now that I could map my features into another space where my data is linearly seperable. Therefore I only need to compute $\Phi(x_i)^T\Phi(x_j)$ via a kernel function $K(x,y)$ . My questions is how do we actually find such a function $\Phi$ , I assume most of the data is high dimensional so that you cannot just "look at it" and directly find an appropriate feature map which will make the data seperable. The second thing is, if I have found such a feature map, how do I find a kernel such that $K(x_i,x_j) = \Phi(x_i)^T\Phi(x_j)$ ?
