[site]: datascience
[post_id]: 102367
[parent_id]: 102314
[tags]: 
I am assuming, your focus here is the prediction accuracy and not interpretability? So, as there is a class imbalance, you can do two things: As suggested by the other user, you can use SMOTE or any technique. Use a non-parametric method that is more robust in handling the class imbalance. I tried to use Random Forest on your data, and the classification result was already promising without any parameter tuning. A R code which I used: library(randomForest) data_A $V2 = factor(data_A$ V2, levels = c(0, 1,2)) set.seed(4) classifier_random What if I divide it into Training and Testing set with an 80:20 ratio? smp_size Misclassification is more but still, it is working, that too without any tuning. The code is in R which might not be totally beneficial for you, but I hope you get the point that I am trying to convey here.
