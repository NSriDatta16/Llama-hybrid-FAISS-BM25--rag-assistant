[site]: crossvalidated
[post_id]: 312909
[parent_id]: 312865
[tags]: 
The process by which categorical variables are encoded is detailed in the H2O documentation . There is a categorical_encoding variable in H2O algorithms and for Deep Learning the default is "One Hot Internal". If you don't know what One-Hot encoding is, then you can read about it here or look at my simple example below. The "internal" designation just means that it's done on-the-fly, internally, in the algorithm, as opposed to first creating the whole, expanded one-hot encoded version of the whole dataset and then passed to the algorithm. On-the-fly is more memory efficient, which is why it's done that way. If you have a variable, x , with three categories, say "A", "B", "C", then the one-hot encoding of that looks like this: Original data (e.g. 1 column data frame with header "x"): "x" A B B C NA A One-hot encoded version (a binary column for each category indicating which value, A, B, C or NA, corresponds to that row): "x.A" "x.B" "x.C" "x.missing(NA)" 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 So if you use an autoencoder to reconstruct those values -- it's trying to predict the original values. It probably rarely predicts the actual 0 or 1 value, but if you wanted to map these predictions back to original categories, then you'd look at the predicted values for each category, find which value is the highest, and then use that category. For example, if row 1 in the dataset above was reconstructed like this: "x.A" "x.B" "x.C" "x.missing(NA)" 0.8 0.1 0.001 0.1 Then you could assume that to be category "A". I don't think the values across the rows necessary add up to 1, but it shouldn't matter either way. Just choose the label with the highest predicted value.
