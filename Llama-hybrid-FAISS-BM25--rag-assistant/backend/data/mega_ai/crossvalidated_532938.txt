[site]: crossvalidated
[post_id]: 532938
[parent_id]: 276497
[tags]: 
What we know today as Maximum Mean Discrepancy is actually derived from the following Integral Probability Metric [A]: If p and q are two distributions and $\mathcal{F}$ is a class of real valued bounded bounded measurable functions, then the metric is defined as, $$D(p, q, \mathcal{F}) = \sup_{f \in \mathcal{F}} \left|\mathbb{E}_p[f(x)] - \mathbb{E}_q[f(x)]\right|$$ If you select the function class $\mathcal{F} = \{f \;\;|\;\; \|f\|_{\mathcal{H}} \leq 1\}$ where $\mathcal{H}$ represents the reproducing kernel Hilbert space with reproducing kernel $k$ , it can be shown that the above metric reduces to [D]: $$D(p, q, \mathcal{F}) = \left|\mathbb{E}_p[k(x, \cdot)] - \mathbb{E}_q[k(x, \cdot)]\right|$$ Thus, it so happens, that computing the differences of the mean in the kernel space gives you the distance between the distribution computed over a certain function class. Several other metrics can actually be derived this way, by selecting certain classes of functions and analyzing the original integral probability metric under that function class e.g. Total Variation Distance, Wasserstein Distance [B]. Now, coming to the description you gave in the original post, I am a little worried about how you are going about computing the MMD. Even for the original MMD measure, the kernel had to satisfy some properties [C]. However, all you seem to be doing is multiplying your features with some matrix and computing distance in that space. Which doesn't really mean anything unless the projection matrices are special. So, it would be good to go through the linked articles and ensure that what you are doing abides by requirements of a kernel mean embedding. [A] Integral Probability Metrics and their Generating Classes of Functions, Muller, 1997 [B] On Integral Probability Metrics, Ï•-divergences and Binary Classification, Sriperumbudur et. al, 2009 [C] Universality, Characteristic Kernels and RKHS Embedding of Measures, Sriperumbudur et. al, 2012 (PDF) [D] Kernel Mean Embedding of Distributions: A Review and Beyond, Muandet et. al, 2016
