[site]: crossvalidated
[post_id]: 212038
[parent_id]: 
[tags]: 
Improving accuracy of classification by inverting predicted labels

I'm new to machine learning and classifiers output analysis. Let's say that I have a classifier that correctly classifies my data with an accuracy of 30% (which is worse than a random one), in a binary classification context. I can compute that percentage (accuracy) thanks to the confusion matrix . Why can't I say that my classifier is correct at 70% if I "invert" my confusion matrix and say that every instance classified is from the other class?
