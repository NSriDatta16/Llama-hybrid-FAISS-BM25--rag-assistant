[site]: crossvalidated
[post_id]: 623875
[parent_id]: 
[tags]: 
Why do causal convolutions require positional encoding for image generation?

I'm following this course on deep learning. In lecture 10.2 (page 23 in the handout for the lecture ) causal convolutions are introduced as a method for image generation. A bit later it is said, that these convolutions need to be supplied with positional encoding to improve the quality of the generated pictures since "a convolutional model has no way of making the prediction position-dependent". Could somebody explain this to me on an intuitive level? I understand that through pooling spatial information is lost, but I don't think that's the intended point here? Is it perhaps because the kernels don't have global context, i.e., they're input is limited to their receptive field and thus they cannot account for their global positioning? Thanks!
