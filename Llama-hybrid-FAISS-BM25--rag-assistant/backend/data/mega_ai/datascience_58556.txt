[site]: datascience
[post_id]: 58556
[parent_id]: 23969
[tags]: 
The generalized solution consists of the following steps - Featurization or word embeddings of a sentence. Applying a similarity metric among sentences. For 1. word2vec is the best choice but if you don't want to use word2vec, you can make some approximations to it. One ways is to make a co-occurrence matrix of words from your trained sentences followed by applying TSVD on it. Coccurance matrix of $nXn$ dimensionality when converted into $nXd$ dimensionality, makes for word vectors of $d$ dimensions. Once you get word embedding of each word, you can apply any of the similarity metrics like cosine similarity, etc. on each sentence to measure similarity with others.
