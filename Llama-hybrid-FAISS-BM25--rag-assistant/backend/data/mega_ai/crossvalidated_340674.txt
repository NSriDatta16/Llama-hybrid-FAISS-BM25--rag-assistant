[site]: crossvalidated
[post_id]: 340674
[parent_id]: 199074
[tags]: 
The mathematical operation of convolution means to compute the product of two (continuous or discrete) functions over all possible shift-positions. The most simple example is to convolve a 1-dimensional vector ${\bf {\it x}}=(x_1,x_2,x_3,\dots,x_n)^T$ with a sampled Gaussian function (the Gaussian probability density function), ${\bf {\it y}}=(y_1,y_2,y_3,\dots,y_v)^T$. Practically this means to compute the summed dot-product, element-by-element: \begin{equation} c\left(\frac{v}{2}\right) = \sum_{i\,=-v/2, \; i \le 0}^{v/2} x_{i} \cdot \ y_{(i+v/2)} \end{equation} Now letting the running variable $z$ in $c(z),\; z = \frac{v}{2}$ run over the whole range of the vector ${\bf {\it x}}$ yields a vector of output values from the convolution, for each position. In a 2-dimensional (gray-level) image, a convolution is performed by a sliding-window operation, where the window (the 2-d convolution kernel) is a $v \times v$ matrix. When a neural network is used for convolution, a $v$-by-$v$ window of pixel values can be provided as input. In this way, the neural network can be trained to recognize objects of a certain size. Also a feature-based neural network can perform a convolution, when the feature vector is computed locally for each pixel coordinate. See Fig.1 in the reference: [M. Egmont-Petersen, E. Pelikan, Detection of bone tumours in radiographs using neural networks, Pattern Analysis and Applications 2(2) ,1999, 172-183]. Image-processing applications of neural networks have been reviewed in: [M. Egmont-Petersen, D. de Ridder, H. Handels. Image processing with neural networks - a review, Pattern Recognition, Vol. 35, No. 10, pp. 2279-2301, 2002]
