[site]: crossvalidated
[post_id]: 549851
[parent_id]: 549608
[tags]: 
OP stated in a comment that decreasing the size of the learning rate achieved the kind of progression in the loss that they were looking for: Decreasing does actually seem to give the kind of output I'd expect. Thanks for that Tuning the learning rate (optimizer step size) is an important part of estimating a neural network. More information can be found in high-quality textbooks about neural networks such as Goodfellow's Deep Learning.
