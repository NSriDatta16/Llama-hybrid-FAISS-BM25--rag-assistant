[site]: crossvalidated
[post_id]: 422261
[parent_id]: 422259
[tags]: 
Strictly speaking, you have to rerun your MCMC algorithm from scratch to approximate the new posterior. MCMC algorithms are not sequential, which means that you cannot update their output with new data to update your estimate of the posterior. You just have to redo it. However, you can use importance sampling to recursively update your posterior approximation with new data. Here are two approaches: Quick and Dirty (and not quite right) You already have the output $\{\theta^{(i)}\}_{i=1}^M$ from an MCMC algorithm that targets $p(\theta\,|\,y_{1:t-1})$ . You then observe $y_t$ , and you want to somehow recycle $\{\theta^{(i)}\}_{i=1}^M$ to approximate $p(\theta\,|\,y_{1:t})$ without having to re-do everything. As I said, in order to be doing things 100% correctly, you should rerun the MCMC from scratch. But if you were hellbent on not doing that, you could do the following. Pretend that $\{\theta^{(i)}\}_{i=1}^M$ are iid draws from $p(\theta\,|\,y_{1:t-1})$ . Then treat them as proposal draws for an importance sampling approximation to $p(\theta\,|\,y_{1:t})$ . The importance weights will be $$w_i\propto\frac{p(\theta^{(i)}\,|\,y_{1:t})}{p(\theta^{(i)}\,|\,y_{1:t-1})}\propto p(y_t\,|y_{1:t-1},\,\theta^{(i)}).$$ The leap of faith here is treating the MCMC draws like they were evenly-weighted, iid draws from the source density $p(\theta\,|\,y_{1:t-1})$ . But for private, exploratory purposes, it's not an insane thing to do when you already have the MCMC draws lying around and you want to update the approximation based on one or two new observations. Best Practices If you know in advance that you'll want to be recursively updating your posterior approximation when you observe new data, the best thing to do from the outset is to use sequential Monte Carlo (SMC) to approximate the posterior. Here are some papers: Chopin (2002 Biometrika) ; Chopin (2004 Annals of Statistics) . Like the other approach, SMC is an importance sampling based method that allows you to iteratively update your posterior approximation as new data arrive. You start with a sample of iid draws from the prior, and then you recursively re-weight the sample to reflect the new information. Along the way, you also use MCMC to move each draw in your sample to a location in the parameter space that better reflects the influence of new data.
