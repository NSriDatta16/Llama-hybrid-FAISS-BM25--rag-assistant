[site]: datascience
[post_id]: 126728
[parent_id]: 
[tags]: 
Is vision transformer (ViT) always better than CNN?

The paper - AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE proposed vision transformer and outperformed CNN-based models in many cases. When it comes to sequential data, we usually use transformer models instead of recurrent models such as RNN, LSTM. Is the same case with images using ViT instead of CNN?
