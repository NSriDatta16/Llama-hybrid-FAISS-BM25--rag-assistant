[site]: crossvalidated
[post_id]: 74122
[parent_id]: 
[tags]: 
Understanding Sufficient Statistics

As I began my study of sufficient statistics I stumbled upon a definition that puzzled me. The conditional probability distribution of the sample values given an estimator $\hat{\Theta}=\hat{\theta} $ is given by $$ f\left( x_1,x_2,\ldots,x_n|\hat{\theta} \right) = \frac{f \left(x_1,x_2,\ldots,x_n,\hat{\theta} \right)}{g\left( \hat{\theta} \right)}=\frac{f\left( x_1,x_2,\ldots,x_n \right) }{g \left(\hat{\theta} \right)} $$ The first equality is of course the definition of the conditional distribution $P \left(A| B \right) = \frac{P\left( A \cap B \right)}{P \left( B \right)} $. What I do not understand is where the numerator in the second equality comes from. It looks like we are assuming that $A \subset B \Rightarrow A \cap B =A $. But how is that possible in our case? Any insight on that? Thank you!
