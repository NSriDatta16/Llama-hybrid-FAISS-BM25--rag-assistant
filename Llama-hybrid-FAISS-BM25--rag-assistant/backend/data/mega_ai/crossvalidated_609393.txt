[site]: crossvalidated
[post_id]: 609393
[parent_id]: 609166
[tags]: 
As stated by many others: the likelihood function $\mathcal L_y$ is the probability density function $f_\theta$ of the observed data $y$ , but viewed as a function of the (unknown) parameter $\theta$ , i.e., $\mathcal L_y(\theta) = f_\theta(y)$ . To provide some intuition, let's consider discrete data 1 and continuous data separately: For discrete data we have $\mathcal L_y(\theta) = \mathbb P_\theta(Y = y)$ , i.e., the likelihood function is the probability of the observed data viewed as a function of the parameter $\theta$ . For continuous data let's assume that in practice we can only measure, and thus observe, data with limited accuracy. Then, observing $Y = y$ (say, for the sake of simplicity, for real-valued $Y$ ) can be understood as indicating that $Y$ took a value in a small interval $[y - \delta, y + \delta]$ . For the probability of the observed datum $y$ we then have $$ \mathbb P_\theta(Y \in [y - \delta, y + \delta]) = \mathbb P_\theta(y - \delta \leq Y \leq y + \delta) = \int_{y - \delta}^{y + \delta} f_\theta(y) \,\mathrm d y. $$ Now, the approximation $$\int_{y - \delta}^{y + \delta} f_\theta(y) \,\mathrm d y \approx f_\theta(y) \cdot \left[\left(y + \delta\right) -\left(y - \delta\right)\right] = 2\delta \cdot f_\theta(y) $$ suggests that the probability of the observed datum $y$ is approximately proportional to $f_\theta(y)$ . In this sense $\mathcal L_y(\theta) = f_\theta(y) \overset{\text{approx.}}\propto \mathbb P_\theta(Y \in [y - \delta, y + \delta])$ still indicates how "likely" a paramter value $\theta$ is for the observed datum $y$ . 1 here the probability mass function referred to in some of the other answers can be seen as probability density function w.r.t. the counting measure. Reference Held, L., & Sabanés Bové, D. (2020). Likelihood and Bayesian inference: With applications in biology and medicine (Second edition). Springer.
