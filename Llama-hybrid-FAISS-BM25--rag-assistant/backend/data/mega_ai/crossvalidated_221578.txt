[site]: crossvalidated
[post_id]: 221578
[parent_id]: 212228
[tags]: 
After more investigation I can answer my own question. When deciding between logistic regression models, we can use cross-validation and choose the metric of ROC to evaluate the area under the curve of varying cutoffs that build the ROC curve. There is also a cv.glm function that cross validate an error metric to choose between different models. I have found another good way to evaluate models on the test set, which would be constructing an ROC (pROC package) object, and then using coords, which can return a variety of ROC metrics and using best.method = "closest.topleft" to optimize the metrics returned.
