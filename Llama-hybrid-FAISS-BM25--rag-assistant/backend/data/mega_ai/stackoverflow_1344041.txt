[site]: stackoverflow
[post_id]: 1344041
[parent_id]: 1343746
[tags]: 
The recursive size() method is probably not a good place to do the caching. I put a call to cache.put(i, size); inside the main()'s for-loop and it works much more quickly. Otherwise, I also get an OOM error (no more heap space). Edit: Here's the source - the cache retrieval is in size(), but the storing is done in main(). public static void main(String[] args) { long num = 0; int maxSize = 0; long start = new Date().getTime(); for (long i = 1; i = maxSize) { maxSize = size; num = i; } cache.put(i, size); } long computeTime = new Date().getTime() - start; System.out.println(String.format("maxSize: %4d on initial starting number %6d", maxSize, num)); System.out.println("compute time in milliseconds: " + computeTime); } private static int size(long i) { if (i == 1l) { return 1; } if (cache.containsKey(i)) { return cache.get(i); } return size(process(i)) + 1; } Note that by removing the cache.put() call from size(), it does not cache every computed size, but it also avoids re-caching a previously computed size. This does not affect the hashmap operations, but like akf points out, it avoids the autoboxing/unboxing operations which is where your heap killer is coming from. I also tried a "if (!containsKey(i)) { cache.put() etc" in size() but that unfortunately also runs out of memory.
