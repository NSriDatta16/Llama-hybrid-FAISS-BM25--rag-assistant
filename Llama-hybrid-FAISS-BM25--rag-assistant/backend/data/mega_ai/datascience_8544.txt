[site]: datascience
[post_id]: 8544
[parent_id]: 8542
[tags]: 
One can copy the 'bag of words' model for documents, though it becomes a 'bag of characters' model. (jamesmf extends this to n-grams, which will be more useful.) But if you want a feature to be salient to the algorithm, you need to give the algorithm access to that feature. You don't need to tell it what classes that feature is relevant for--just whether or not the feature is present. For example, the length of the string, number of digits in the string, and number of capital letters in the string are probably very useful for differentiating several of the classes you described, but will not be part of the feature vector unless you put them there. But all you need to do is identify them, assign them numbers, and then let the SVM take care of deciding how relevant they are. Similarly, having a binary variable for whether or not the last four characters are .com (or whether .com appears in the string if it's not always at the end) in the feature vector will convey the same amount of helpful information without also giving the algorithm a bunch of worthless information--there may be other 4-grams that are important, but it seems unlikely to me that it's worth the cost of considering all 4-grams and 3-grams in order to get the known features of .com , .net , .org , and so on.
