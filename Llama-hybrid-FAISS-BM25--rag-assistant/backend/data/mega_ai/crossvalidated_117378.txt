[site]: crossvalidated
[post_id]: 117378
[parent_id]: 
[tags]: 
Expected survival time: comparisons when measurements are an average over other measurements?

Set up We have a few types of interventions. For each intervention, a failure occurs randomly at some time $t$ after start for each subject. We take $n$ measurements of $t$ using $n$ subjects, and we do this between subjects for all interventions. The easy part I understand that we can take a time $T$ and compute confidence intervals for $\Pr(t \leq T$) for each intervention by assuming a binomial distribution. We can compare interventions using a Chi-square test to determine if one intervention is significantly more likely to fail before $T$. We can also use Cox regression to compare interventions. The tricky part Now I want to compare the expected survival time per intervention, given that we are willing to wait a maximum of $T$ time units. Pretend that we only need to use the intervention for $T$ time units, and if the intervention stops there is no chance of failure. I calculate expected use time as an average of failure times less than $T$ and $T$ for all times greater than or equal to $T$: $\tilde{U}(T) = \dfrac{\sum_{i = 1}^n u(t_i)}{n}$, where $u(t_i) = \begin{cases} t_i, t_i Question What is the best way to compare expected use times between interventions? I want to say that, if you only need an intervention for time $T$, item $X$ has significantly higher expected use time than item $Y$. What is the right way to go about this? Are there better alternatives to the bootstrap?
