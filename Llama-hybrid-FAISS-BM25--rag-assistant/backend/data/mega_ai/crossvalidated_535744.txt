[site]: crossvalidated
[post_id]: 535744
[parent_id]: 
[tags]: 
Permutation Invariant Tree Gradient Boost Models

Suppose we are dealing with a classification problem whose input is a bag of users $u_i$ and their data, stored as $u_{ij}$ . Each user might have $n$ features like age, gender, description, purchase habits, etc, which we would store as $u_{ij}$ for $j=1,2,\cdots,n$ . I'm curious if there are tree GBM models similar to XGBoost and CatBoost, which would be invariant under permuting these users groups. To be concrete, naively we would train a GBM using row vectors of $[u_{11},\cdots,u_{1n}, u_{21}\cdots, u_{2n},...]$ . I'd like the model to be invariant under permutations of the blocks of $[u_{i1},\cdots,u_{in}]$ . I could accomplish this with neural networks by using an attention layer.
