[site]: datascience
[post_id]: 30028
[parent_id]: 
[tags]: 
Reformatting data for future time series prediction LSTM(Keras)

So I am following this notebook (at least for the data portion)and have a trained model. What I am trying to do is true future predictions as LSTM are capable of generating data for unseen time steps(if they are stateful). Trying to follow this post here as it is the only thing I can find on this concept. here is the default function: def load_data(filename, sequence_length): # Read the data file raw_data = pd.read_csv(filename, dtype=float) raw_data = raw_data.values print (raw_data) # Change all zeros to the number before the zero occurs for x in range(0, raw_data.shape[0]): for y in range(0, raw_data.shape[1]): if (raw_data[x][y] == 0): raw_data[x][y] = raw_data[x - 1][y] # Convert the file to a list data = raw_data.tolist() # Convert the data to a 3D array (a x b x c) # Where a is the number of days, b is the window size, and c is the number of features in the data file result = [] for index in range(len(data) - sequence_length): result.append(data[index: index + sequence_length]) # Normalizing data by going through each window # Every value in the window is divided by the first value in the window, and then 1 is subtracted d0 = np.array(result) dr = np.zeros_like(d0) dr[:, 1:, :] = d0[:, 1:, :] / d0[:, 0:1, :] - 1 # Keeping the unnormalized prices for Y_test # Useful when graphing bitcoin price over time later start = 2400 end = int(dr.shape[0] + 1) unnormalized_bases = d0[start:end, 0:1, 7] # Splitting data set into training (First 90% of data points) and testing data (last 10% of data points) split_line = round(0.9 * dr.shape[0]) training_data = dr[:int(split_line), :] # Shuffle the data np.random.shuffle(training_data) # Training Data X_train = training_data[:, :-1] Y_train = training_data[:, -1] Y_train = Y_train[:, 7] # Testing data X_test = dr[int(split_line):, :-1] Y_test = dr[int(split_line):, 6, :] Y_test = Y_test[:, 7] # Get the day before Y_test's price Y_daybefore = dr[int(split_line):, 5, :] Y_daybefore = Y_daybefore[:, 7] # Get window size and sequence length sequence_length = sequence_length window_size = sequence_length - 1 # because the last value is reserved as the y value return X_train, Y_train, X_test, Y_test, Y_daybefore, unnormalized_bases, window_size and trying to refactor according to the post: def load_data_future(filename, sequence_length): # Read the data file raw_data = pd.read_csv(filename, dtype=float) raw_data = raw_data.values print (raw_data) # Change all zeros to the number before the zero occurs for x in range(0, raw_data.shape[0]): for y in range(0, raw_data.shape[1]): if (raw_data[x][y] == 0): raw_data[x][y] = raw_data[x - 1][y] # Convert the file to a list data = raw_data.tolist() # Convert the data to a 3D array (a x b x c) # Where a is the number of days, b is the window size, and c is the number of features in the data file result = [] for index in range(len(data) - sequence_length): result.append(data[index: index + sequence_length]) # Normalizing data by going through each window # Every value in the window is divided by the first value in the window, and then 1 is subtracted d0 = np.array(result) dr = np.zeros_like(d0) dr[:, 1:, :] = d0[:, 1:, :] / d0[:, 0:1, :] - 1 # Keeping the unnormalized prices for Y_test # Useful when graphing bitcoin price over time later start = 2400 end = int(dr.shape[0] + 1) unnormalized_bases = d0[start:end, 0:1, 7] # Splitting data set into training (First 90% of data points) and testing data (last 10% of data points) split_line = round(1 * dr.shape[0]) training_data = dr[:int(split_line), :] # Shuffle the data np.random.shuffle(training_data) #Reformatting training data X_train = training_data[:,:-1] Y_train = training_data[:,1] #Y_train = Y_train[:, 1] # Get the day before Y_test's price Y_daybefore = dr[int(split_line):, 5, :] Y_daybefore = Y_daybefore[:, 7] # Get window size and sequence length sequence_length = sequence_length window_size = sequence_length - 1 # because the last value is reserved as the y value entire_data = dr return X_train, Y_train, Y_daybefore, unnormalized_bases, window_size,entire_data What am I doing wrong?? I can see that its formatted samples, outputs,timesteps per feature. Not sure how to manipulate this to acheive what I am going for. Even high level pointers would be helpful in the comments!
