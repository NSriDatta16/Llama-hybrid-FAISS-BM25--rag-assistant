[site]: crossvalidated
[post_id]: 436034
[parent_id]: 433963
[tags]: 
An answer to a very similar (but not the actual $\color{red}{^*}$ ) question is, White's Reality Check and Hansen's Superior Predictive Ability (SPA) Test . See Section 17.5.2 in Elliott & Timmermann (2016) for a summary of both tests. Below I give a summary of the summary (consisting in no small part of direct quotes): White (2000) asks how confident we can be that the best forecast, among a set of competing forecasts, is genuinely better than a prespecified benchmark, given that the best forecast is selected from a potentially large set of models. The null hypothesis tested by the Reality Check is that the benchmark model is not inferior to any of the $m$ alternatives: $$ H_0\colon \max_{k=1,\dots,m}\mathbb{E}[d_{k,t+1|t}(\beta^∗_k)]\leq 0, $$ whereas the alternative is that at least one model produces lower expected loss than the benchmark: $$ H_1\colon \max_{k=1,\dots,m}\mathbb{E}[d_{k,t+1|t}(\beta^∗_k)]>0. $$ Here, $d_{k,t+1|t}(\beta^∗_k)$ is the loss differential between a prespecified benchmark model and its $k$ th competitor, and $\beta^∗_k=\text{plim}(\hat\beta_{k,T})$ is the pseudo-true value (given the estimation method) of the parameter vector $\beta_k$ of the $k$ th model. Hansen (2005) notes that the bootstrap procedure used for constructing the null distribution of the test statistic in White (2000) means that, in practice, the assumption under the null hypothesis is that $\mathbb{E}[d_k(\beta^∗)]=0$ . He shows that if the maximum of $\mathbb{E}(\bar{d})$ is negative, then with probability 1 we get a degenerate distribution of the test statistic when the benchmark model is better than all other models. Here, $\bar{d}$ is the vector of sample averages of loss differentials. Hansen's Superior Predictive Ability (SPA) Test modifies the Reality Check by normalizing and recentering the test statistic to get rid of the assumption mentioned above. $\color{red}{^*}$ An important caveat : the interest in White's Reality Check and Hansen's Superior Predictive Ability (SPA) Test is in comparing forecasting performance of competing models in a hypothetical setting when the pseudo-true values of the models' parameters are known . In other words, their null hypotheses assume perfect estimation precision of the underlying forecasting models. This is not necessarily an interesting question in practice, where true values are not known but their imperfect estimates are used. Importantly, this assumption is at odds with the assumptions of the Diebold-Mariano test, but is in line with some papers by Clark, McCracken and West. Therefore, this answer addresses a slightly different question that the OP is asking. A direct answer to the OPs question is still sought after. References Elliott, G. & Timmermann, A. (2016). Economic Forecasting . Princeton University Press. Hansen, P. R. (2005). A test for superior predictive ability . Journal of Business & Economic Statistics, 23 (4), 365-380. White, H. (2000). A reality check for data snooping . Econometrica, 68 (5), 1097-1126.
