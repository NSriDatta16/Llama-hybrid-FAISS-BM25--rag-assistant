[site]: crossvalidated
[post_id]: 284939
[parent_id]: 283801
[tags]: 
The definition is completely analogous if you use the so-called working residuals and if regressors and residuals are weighted appropriately. The working weights are part of the usual iteratively weighted least squares (IWLS) algorithm employed for generalized linear models (including logistic regression). The main idea is to use derivative of the log-likelihood with respect to the mean or the corresponding linear predictor as a measure of deviation. Alternatively, you can use the so-called scores or estimating functions as a measure of deviation, i.e., the derivative of the log-likelihood with respect to the coefficients of the linear predictor. All these ideas are employed in our sandwich package for R to enable object-oriented implementations of the different sandwich estimators. See Zeileis (2006, Object-Oriented Computation of Sandwich Estimators , doi:10.18637/jss.v016.i09 ) for the details. A worked illustration in R using a logistic regression for labor market participation is: data("SwissLabor", package = "AER") m The classical Eicker/Huber/White sandwich covariance matrix can be computed using our sandwich package: library("sandwich") vcov_sandwich And by hand you can easily extract the working residuals and regressors, appropriately weighted with the working weights: r Then, the formula for the covariance matrix is just the same as in the linear regression model vcov_byhand Two caveats: (1) Of course, one shouldn't compute the sandwich like this but more efficient and numerically more stable matrix computations can be employed. (2) For data with independent binary responses, these sandwich covariances are not robust against anything. They are consistent, that's ok, but there is no way to misspecify the likelihood without misspecifying the model equation.
