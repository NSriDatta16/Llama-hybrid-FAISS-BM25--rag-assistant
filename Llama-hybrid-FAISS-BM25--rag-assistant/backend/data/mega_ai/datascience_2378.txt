[site]: datascience
[post_id]: 2378
[parent_id]: 
[tags]: 
Matrix properties and machine learning/data mining

I'm doing some data analysis in a Statistical Pattern Recognition course using PRML. We analyzed a lot of matrix properties, like eigenvalues, column independence, positive semi-definite matrix, etc. When we are doing, for example, linear regression, we need to calculate some of those properties, and fit them into the equation. So my question is, my question is about the intuition behind these matrix properties, and their implications in the ML/DM literature. If anyone could answer, can you teach me what is the importance of eigenvalue, positive semi-definite matrix, and column independence for ML/DM. And possibly, other important matrix properties you think important in study the dataset, and why. I'd be really appreciated if someone can answer this question.
