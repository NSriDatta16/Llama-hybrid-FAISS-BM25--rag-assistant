[site]: crossvalidated
[post_id]: 564451
[parent_id]: 
[tags]: 
when to choose predictive power of a model over explainability?

I am currently working on a binary classification with 1000 records. class distribution is 75:25 I tried both logistic and random forests, My results are better for random forests. However, when I try Xgboost, they are even better than random forests. Meaning, the recall for minority class increases by 3 points (from 39 to 42). And our business objective is to identify/predict the negatives correctly (missing negatives is costly and critical for the business). My questions are as follows a) As a data scientist, considering the dataset size, I am not naturally inclined to try Xgboost because I feel it is overkill for such a small dataset. note, I already tried hyperparamter tuning for RF. I could only get 39% recall for minority. So, should I go for Xgboost for the sake of predictive power? With the advent of Explainable AI solutions like Lime, Shap etc, do you think it is okay to go for high end models like boosting even for small dataset if predictive power is important?
