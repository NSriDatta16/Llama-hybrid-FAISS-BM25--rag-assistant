[site]: crossvalidated
[post_id]: 353626
[parent_id]: 353596
[tags]: 
Maybe. You could take a look at how you can frame the search routine, to decide if there is any benefit to using RL. A problem is a good fit to Reinforcement Learning if: It can be framed in terms of an agent interacting with an environment , by taking actions and observing reward and state values that follow. The environment should present a state (either directly, or via some observation that the agent can make). As much as possible, that state should be a good predictor of what the likely rewards and next states should be. State information that has this trait is described as having the Markov property . The agent needs to be able to take meaningful actions during the search. This could be as basic as suggesting next set of parameters to try, or could be making choices between search strategies e.g. random sampling, grid search, hill climbing. The tough part in my opinion is creating a good state representation. The current search point is not enough data to predict likely results of trying yet another point. Somehow you need to summarise the history of the search to date. A quick look for papers turned up this recent one which uses RL to optimise parameters for processing CT scan images: Intelligent Parameter Tuning in Optimization-based Iterative CT Reconstruction via Deep Reinforcement Learning I think it may tackle a similar problem, and could be of interest.
