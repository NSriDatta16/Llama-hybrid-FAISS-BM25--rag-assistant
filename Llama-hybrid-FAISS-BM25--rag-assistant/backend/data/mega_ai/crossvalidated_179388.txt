[site]: crossvalidated
[post_id]: 179388
[parent_id]: 179387
[tags]: 
1) What is the difference between SMO (weka) and the LibSVM algorithms? Which is the best? Because the parameter requirements of the two are very different. SMO is a clever way to solve SVM training problems. LibSVM implements SMO. The fact Weka uses different parameters than LibSVM has little to do with SMO, but rather they parameterize the training problem itself differently. Both are essentially equivalent. In fact, Weka uses LIBSVM . 2) Feature reduction (e.g.PCA) and feature selection (e.g. InfoGain) are two different techniques for reducing features. Which one to rely on? In which conditions are they to be used? If you're going to be using SVM, neither feature reduction nor feature selection are required. Typically, they contribute very little to overall performance. For other learning algorithms your mileage may vary. Won't answer (3) as it's irrelevant. 4) Is accuracy the only thing that I should be looking for? Of course there is overfitting, but can I quantify the predictive power of the model other than just CV accuracy? Some other measure or technique? Accuracy is a fairly bad metric to optimize. You typically want to at least look at the performance of your model across its entire operating range, for example using receiver operating characteristic (ROC) curves. Better yet would be to create your own utility function that explicitly models the tradeoffs in your own application and optimize that directly (e.g. are false positives and false negatives equally bad?). If you want to automatically find suitable hyperparameters for a given task based on some criterion you choose, you should have a look at software libraries like Optunity (an example specifically about SVMs is available here ).
