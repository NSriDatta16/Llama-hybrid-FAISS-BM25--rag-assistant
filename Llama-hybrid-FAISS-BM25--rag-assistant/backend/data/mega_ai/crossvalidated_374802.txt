[site]: crossvalidated
[post_id]: 374802
[parent_id]: 374795
[tags]: 
The issue arise because your models are estimating a variance term (the variance of the random intercepts) from just 3 cluster (Blocks), and because the differences across blocks are smaller in 2016, as indicated by the standard deviations > sd(tapply(stat16 $Yield, stat16$ Block, mean)) [1] 193.4393 > sd(tapply(stat17 $Yield, stat17$ Block, mean, na.rm=T)) [1] 535.5668 As a result when considering 2016 alone, the model does not have enough evidence to believe that different Blocks have different average values of Yield, and the estimated standard deviation turns out to be zero: > VarCorr(yield2016) Groups Name Std.Dev. Block (Intercept) 0.00 Residual 641.15 This is different from what you get in 2017, where the estimated standard deviation is very close to the standard deviation computed above > VarCorr(yield2017) Groups Name Std.Dev. Block (Intercept) 536.05 Residual 505.32 (As a test, if you artificially increased the between-block variance, the model would estimate a non-zero variance also for 2016) > stat16 $Yield[stat16$ Block==1] $Yield[stat16$ Block==1] + 800 > yield2016 VarCorr(yield2016) Groups Name Std.Dev. Block (Intercept) 494.07 Residual 646.92 If you do not believe that the variance across block is zero in 2016, I would suggest to use a Bayesian approach and incorporate your prior knowledge in the model (you could do that with rstanarm package and the stan_glmer() function)
