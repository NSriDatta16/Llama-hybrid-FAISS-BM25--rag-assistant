[site]: crossvalidated
[post_id]: 84055
[parent_id]: 1444
[tags]: 
Suppose Y is the amount of money each American spends on a new car in a given year (total purchase price). Y will spike at 0; will have no values at all between 0 and about 12,000; and will take other values mostly in the teens, twenties and thirties of thousands. Predictors would be proxies for the level of need and/or interest in making such a purchase. Need or interest could hardly be said to be zero for individuals who made no purchase; on these scales non-purchasers would be much closer to purchasers than Y or even the log of Y would suggest. In a case much like this but in health care, I found that the most accurate predictions, judged by test-set/training-set crossvalidation, were obtained by, in increasing order, Logistic regression on a binary version of Y, OLS on Y, Ordinal regression (PLUM) on Y binned into 5 categories (so as to divide purchasers into 4 equal-size groups), Multinomial logistic regression on Y binned into 5 categories, OLS on the log(10) of Y (I didn't think of trying the cube root), and OLS on Y binned into 5 categories. Some will recoil at this categorization of a continuous dependent variable. But although it sacrifices some information, categorizing seems to help by restoring an important underlying aspect of the situation -- again, that the "zeroes" are much more similar to the rest than Y would indicate.
