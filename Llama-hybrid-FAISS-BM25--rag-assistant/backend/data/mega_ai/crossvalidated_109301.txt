[site]: crossvalidated
[post_id]: 109301
[parent_id]: 109300
[tags]: 
Typically what you describe is more or less how kernel methods work. First there's a projection in a high dimensional space of pairwise similarities of samples and then a linear large-margin classifier is applied to that space. The reason that this naif approach is not followed directly by modern implementations is due to the fact that storing the full Kernel matrix can be ridiculously expensive (N^2 space + the computational cost of computing the kernel function on every pair of samples). If you find that SVMs are slow for the volume of the data you have then probably you need a different classifier with lower complexity, or a linear kernel. Also, you need to choose if it makes sense to work on the dual or the primal. That depends on the number of features and number of samples and what's computationally less expensive.
