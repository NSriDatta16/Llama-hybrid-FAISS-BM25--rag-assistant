[site]: crossvalidated
[post_id]: 260923
[parent_id]: 260909
[tags]: 
You basically have a $5,000,000$-dimensional classification problem with $20$ samples. This is going to be very difficult. Having so many measurements is in some respects a bad thing: it provides so many opportunities for random noise that, just by chance, looks like it can divide the positive and negative samples well. Any method that doesn't incorporate strong priors about what the structure of the classification space looks like is probably doomed to failure because of this issue: there are going to be many splits that divide the training data perfectly, the vast majority of which will just be noise. You'll have to add some a lot of appropriate inductive bias to have any shot at choosing a good decision boundary. For example, you could make the assumption that the identity of individual cells doesn't matter, but rather the distribution of markers across the body in 10-dimensional space. With 500,000 samples, you can have a reasonably good understanding of each of those distributions, and differences between them might be meaningful. But you'll have to manually define a distance between distributions that's meaningful for your classification problem, and with so few samples you don't have a lot to work with there. Plus, it seems like you don't think this the right kind of thing for your problem. You could assume that only a few particular measurements in a few particular cells matter, and run a lasso -type model. Again, 20 examples is just too few here. You could, as you suggested, just train an RNN and hope it picks out something meaningful. Good luck with that. You'll have to very carefully design the structure of the network to be able to pick out the right kind of decisions, and the optimization space is going to be horrendous with so few examples. although I'm making this assumption based on logic alone and no domain knowledge whatsoever Get some domain knowledge. Talk to doctors about what kinds of things they think might matter. Design your models very carefully. Be incredibly careful about data hygiene. Even with only 20 examples, you need to pick out a held-out test set and never look at it until you've decided on a final model; otherwise, you'll be overfitting to the test set in model selection for sure. If at all possible, get more data. I don't envy you your task.
