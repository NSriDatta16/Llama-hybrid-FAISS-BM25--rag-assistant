[site]: crossvalidated
[post_id]: 606052
[parent_id]: 
[tags]: 
Meta-analysis effect size computation

I've been working on a meta-analysis off and on for a while. I am at the analysis stage. Meaning that all relevant effect sizes have been computed. However, I need help understanding what to do when a study reports more than one relevant comparison but some of those comparisons are not significant. For example, let's say Study A is comparing display platform 1 to display platform 2. They run analyses to see which platform has a significant effect on response time. Let's say the conducted 2 experiments. The first experiment shows a significant effect where Display platform 2 is faster than display platform 1. But the second study shows no significant difference between display platforms. For the meta-analysis, I have to compute the effect size for both the significant effect and the no effect. Meaning that, for this study, I have two effect size calculations. What do I do when I go to analyze the overall effect size and do the analysis? Do I average the two effect sizes together so that this one study ends up with only one effect size? It's important to include the null effects in a meta-analysis but the null effects don't have a direction: for example, if I compute the d of a null effect and get d = 0.09, I don't know which direction to code this effect (in favor of display 1 or display 2?). This problem also occurs if the first experiment showed that the effect was significant where display 1 led to faster RTs than display 2, but experiment 2 shows display 2 led to faster response times than display 1. In this case, I again have 2 effect sizes. One could be coded as a + d value and the other as a - d value, but what do I do next? Do I average the two effect sizes? Overall, I'm not sure how to handle studies that have multiple effect sizes. Any guidance/resources would be great. Thanks.
