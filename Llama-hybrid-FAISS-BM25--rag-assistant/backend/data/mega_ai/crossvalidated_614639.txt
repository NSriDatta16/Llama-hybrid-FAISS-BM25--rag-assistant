[site]: crossvalidated
[post_id]: 614639
[parent_id]: 
[tags]: 
Models do not predict peak values

I am training three models, ANN, LSTM and RNN to predict the PV energy production. The data contains two features which are the irradiation which is normalised (highest value 1) and the historical production values which are also normalised. The data is available in a 15min interval which correspond to 94 observations per hour. However, since in the night the production as well as the irradiation is zero, I decided to only take 52 observations per day (6am to 19pm). The input data consist of two days in the past for both features. Therefore, 2x2x52 = 208. The output is the energy production for 52 timesteps. The data is always shifted by one day. This means: input 01.Jan - 02.Jan. output 03.Jan input 02.Jan - 03.Jan. output 04.Jan input 03.Jan - 04.Jan. output 05.Jan My output layer of the NNs is always a Dense(52). The problem is that the predictions do never reach the peak values of the true values. Here is the code for my ANN: # x_train_r: (28595, 104, 2) # y_train: (28595, 52) # x_test_r: (12255, 104, 2) # y_test: (12255, 52) learning_rate = 0.001 def lr_decay(epoch, initial_lr=learning_rate): drop = 0.98 epochs_drop = 10.0 lr = initial_lr * math.pow(drop, math.floor((1 + epoch) / epochs_drop)) return lr filepath = f'models/ANN_Klimazone02_{datetime.datetime.now().date()}.h5' checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min') tf.keras.backend.clear_session() lr_scheduler = LearningRateScheduler(lr_decay, verbose=1) model = Sequential() model.add(Flatten(input_shape=(x_train_r.shape[1], 2))) model.add(Dense(32)) model.add(Dense(32)) model.add(Dense(16)) model.add(Dense(52)) model.build() opt = Adam(learning_rate=learning_rate) model.compile(optimizer=opt, loss='mse') history = model.fit(x_train_r, y_train, epochs=100, batch_size=52, validation_data=(x_test_r, y_test), callbacks=[lr_scheduler, checkpoint]) y_pred_ann = model.predict(x_test_r) I am not sure if the input shape, in my case (104,2), is correct or if it should be (52,2)? I also read about to specify the input_shape as batch_input_shape as well as the predict as predict_on_batch . However I do not know if I should chance that, or what is wrong with my code, or my method. The RNN and LSTM are very similar. Does somebody know what I could try to improve my predictions?
