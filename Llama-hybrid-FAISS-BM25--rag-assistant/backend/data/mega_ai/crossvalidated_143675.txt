[site]: crossvalidated
[post_id]: 143675
[parent_id]: 
[tags]: 
Multi-Level (Sparse) A/B Testing

I've been reading some articles about Bayesian A/B testing such as: http://engineering.richrelevance.com/bayesian-ab-tests/ but my application requires a framework for handling sparsity and group level effects. If the goal were regression, I would have no problem dealing with these issues, but inference is less in my wheel-house. I was wondering if anyone has come across a similarly well laid out framework for this application. I don't believe this question is repeated, but if it is, please let me know. Thank you in advance! Edit: The more I think about this, the more the word logistic keeps coming to mind. Would the following be reasonable: Let $t \in \{A, B\}$ be a treatment, and $g \in \{ 1,\dots, n\}$ be a group. I have data of the form $(T_{t,g}, S_{t,g})$, trials and successes. Assume the following priors: $$ \alpha \sim \mathcal{N}(0, \sigma^2), \\ \beta_g \sim \mathcal{N}(\mu, \tau^2). $$ I could now model, $$ S_{t,g} \sim \mathcal{B}(T_{t,g}, p_{t,g}), \\ p_{t,g} = logit^{-1}(\alpha\cdot\delta_{t,B} + \beta_g). $$ So, for a fixed $(\mu, \sigma, \tau)$, I should be able to work out (though it might be ugly, oh how I miss you conjugacy) the posterior distribution of $\alpha$. Then I could proceed with the same Monte Carlo approach used in the article. My hesitation is that this doesn't feel natural. Where did Beta go. Did I have to desert it? The idea of choosing which Beta prior to use, seems like a much more comfortable position than choosing $\sigma, \tau$.
