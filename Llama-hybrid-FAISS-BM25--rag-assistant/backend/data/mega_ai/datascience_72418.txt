[site]: datascience
[post_id]: 72418
[parent_id]: 72025
[tags]: 
For MT, I always use the Multi30k dataset , English to German for debugging. It has only 30k sentences which are simple and template-like, with a correctly configured Transformer model, you should get around 30 BLEU points in 2 minutes. My experience is that toy problems such as copying, capitalization, reversing character order in words are too simple and the model can learn them despite severe bugs that prevent models for real problems from training.
