[site]: datascience
[post_id]: 116180
[parent_id]: 
[tags]: 
Word embedding for Non-NLP words

I would like to embed words with a context, but that is not "Natural Language" - but just a list of words about more or less the same topic. Is there a way to use this context for the embedding ? I suppose Bert and other pre-trained models won't work out of the box, as they are trained for Natural Language ?
