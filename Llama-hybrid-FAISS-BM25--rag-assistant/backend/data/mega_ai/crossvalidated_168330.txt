[site]: crossvalidated
[post_id]: 168330
[parent_id]: 
[tags]: 
Does removing mildly correlated features (0.5) improve performance in predictive models? (SVM, random forests)

I am trying to model a binary response using a 500+ dataset. I already removed many non useful features in order to reduce dimensionality and improve my model. I am wondering whether in general removing features with correlation of around 0.5, 0.6 could improve the model performance when predicting new values. In particular I would like to know if in better predictive perfomarce can be achieved following this approach with Random Forests and SVM. If the case above is not true, which models are more sensitive to correlated features? Thanks
