[site]: crossvalidated
[post_id]: 504921
[parent_id]: 504896
[tags]: 
I would not say that Slutsky's theorem in its oft presented form is a worthwhile theorem to use here. Slutsky's theorem, as far as I have ever seen, deals with convergence in distribution involving combinations of a sequence of random variables that converges in distribution to some random variable $X$ , and a sequence of random variables that converges to a constant $a$ . And then only deals with convergence in distribution of combinations of those two sequences, not convergence in probability. It's a nice result for establishing central limit theorem type results to estimators. I believe that it should be the Continuous mapping theorem that applies here, since it deals directly with convergence in probability; not only that, but also convergence in distribution and almost sure convergence. The gist of the theorem and how it applies to your case is that if you can show that a getting the inverse of a matrix (supposing it exists) is a continuous mapping, then the convergence in probability holds. This continuity of calculating the inverse is shown in the answer to Continuity of the inverse matrix function (as mentioned in your comments). So if $X_n \overset{p}{\to} Y$ then $X_n^{-1} \overset{p}{\to} Y^{-1}$ by the continuous mapping theorem. In any situation like this, look for continuity. If you have continuity then you have your convergence. Just make sure you are paying attention to the right type of convergence.
