[site]: crossvalidated
[post_id]: 213089
[parent_id]: 212994
[tags]: 
There is no connection between the bias to hidden nodes and those to the reconstructed layer. To understand that this is not possible you can look at the dimensions of $b$ and $b'$. $b$ needs to be $d'$-dimensional and $b'$ is $d$-dimensional, one term for each node in the respective layer. If you need to save $b'$ depends on what you want to do with your autoencoder. If you only want to perform dimensionality reduction there is really no need for the decoder part, the same goes if you want to use your autoencoder to initialize a deep neural network. However, if you want to build a deep autoencoder you would need the $b'$:s. And I guess it would not be that much of a trouble of saving them anyway.
