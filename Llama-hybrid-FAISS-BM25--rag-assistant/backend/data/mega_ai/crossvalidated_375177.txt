[site]: crossvalidated
[post_id]: 375177
[parent_id]: 134084
[tags]: 
In addition to the excellent answers already posted, I will try from another point of view. All models are approximations, in some sense ... Look at some regression model, and some irrelevant variable is significant. What can explain it? Maybe it just is not irrelevant, that todays scientific consensus on that matter is just wrong . Apart from that: It could be a stand-in or proxy for some omitted variable which is relevant, and which is correlated with the irrelevant variable. Some relevant variable, included linearly in the model, could be acting non-linearly, and your irrelevant variable could be a stand-in for that part of the relevant variable. Some interaction between two relevant variables is important, but not included in the model. Your irrelevant variable could be a stand-in for that omitted interaction. The irrelevant variable could just be very highly correlated with some important variable, leading to negatively correlated coefficients. This could be important especially if there are measurement errors in this variables. There could be some observations with very high leverage, leading to strange estimates. Surely others ... an important point is that a linear regression model could be a very good approximation with a small sample, only large effects will be significant. But a larger sample will lead to lower variance, but it cannot reduce bias due to approximations . So with larger samples those inadequacies of the model becomes manifest, and will eventually dominate over variance.
