[site]: datascience
[post_id]: 19234
[parent_id]: 19220
[tags]: 
I'll first reference some quotes from similar questions: When it comes to matrix operations, you don't think twice, you always opt for GPUs. source â€Œ The parallel architecture in a GPU is well adapted for vector and matrix operations. source So if you read through these questions, you'll see that they advise to use GPU regardless of the case; it will always provide some improvement. The reason you may have read that 'small' networks should be trained with CPU, is because implementing GPU training for just a small network might take more time than simply training with CPU - that doesn't mean GPU will be slower. A 100-hidden unit network is kind of small , i'd call it a small network relative to the big deep networks out there. Recurrent architectures (mostly) have more synapses thant feed forward networks, so a 100-hidden units RNN is 'bigger' than a 100-hidden unit FFN.
