[site]: crossvalidated
[post_id]: 187448
[parent_id]: 
[tags]: 
How can I assess many explanatory variables with a sample small enough for in-depth qualitative (case-study) analysis?

The problem: My study is on the impact of human factor on regional development. My “subjects” are regions of the European Union. 276 exist in total under NUTS 2 classification. The idea is to use a sample of 16-20, so that I can also do a small case study on each of them and approach them qualitatively as well. My independent variables are demographic statistics (e.g. % of people with university degrees, % regional GDP spent on R&D and so on). I have around 20 different potential IVs or predictors, although I suppose I can group them or skip some unnecessary ones and narrow them down to around 8 if necessary. I have a single dependent variable which will be taken from some widely-accepted scale showing the level of regional development so that doesn’t need tampering with. Obviously, the goal is to check the impact of the IVs (both separately and as a complete model) on the DV. A regression seems to be the right way to go. My questions: Is it incorrect to attempt to check the impact of 20 predictors on such a small sample (16-20 regions)? If so, will things improve if I narrow down the predictors to 8 or so? What is the best way to narrow down or group the predictors into few important ones? Common sense? Factor analysis? Cronbach’s Alpha? A stepwise regression? If that is still not enough, should I also increase the sample size to, say, 50 or 100 regions (out of a total “population” of 276) and skip the qualitative part? Is a regression the best choice for the “main” test? Somebody mentioned an “artificial neural network” to me!? Isn’t that way too complicated for a relatively straightforward study like this one?
