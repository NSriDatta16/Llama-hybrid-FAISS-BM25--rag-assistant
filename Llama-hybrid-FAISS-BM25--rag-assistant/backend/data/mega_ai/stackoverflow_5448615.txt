[site]: stackoverflow
[post_id]: 5448615
[parent_id]: 
[tags]: 
Programming a simple compiler

I am writing a compiler for a simple language. I made a lexer/tokenizer that takes a file and prints the tokens in stdout . Now I want to to make the syntactical analysis, but I don't know how to modify my lexer in order to take the tokens as input. A linked list is extremely inefficient for large files (source files around 80MB take about 1.3GB of ram) I could modify my lexer to give the next token every time it is called (idea taken from the Dragon Book), but I don't know what I will do if somewhere in the process I have to go back and read a previous token. What is the right way to do these things?
