[site]: stackoverflow
[post_id]: 1650371
[parent_id]: 1650094
[tags]: 
The first thing I'd try would be a map or unordered_map : I'd be surprised if performance is a factor of 60 slower than what you did without any unique-ification. If the performance there isn't acceptable, another option is something like this: // get the computed data into a vector std::vector ::size_type count = 0; std::vector scores; scores.reserve(num_rows); while ((row = data.next_row())) { float score = calc_score(data.next_feature()) scores.push_back(score_pair(score, row->docid)); } assert(scores.size() Note that the use of reverse and stable_sort is because you want the last score for each doc_id, but std::unique keeps the first. If you wanted the first score you could just use stable_sort, and if you didn't care what score, you could just use sort. The best way of handling this is probably to pass reverse iterators into std::unique, rather than a separate reverse operation. But I'm not confident I can write that correctly without testing, and errors might be really confusing, so you get the unoptimised code... Edit: just for comparison with your code, here's how I'd use the map: std::map scoremap; while ((row = data.next_row())) { scoremap[row->docid] = calc_score(data.next_feature()); } std::vector scores(scoremap.begin(), scoremap.end()); std::sort(scores.begin(), scores.end(), score_cmp); Note that score_pair would need a constructor taking a std::pair , which makes it non-POD. If that's not acceptable, use std::transform, with a function to do the conversion. Finally, if there is much duplication (say, on average 2 or more entries per doc_id), and if calc_score is non-trivial, then I would be looking to see whether it's possible to iterate the rows of data in reverse order. If it is, then it will speed up the map / unordered_map approach, because when you get a hit for the doc_id you don't need to calculate the score for that row, just drop it and move on.
