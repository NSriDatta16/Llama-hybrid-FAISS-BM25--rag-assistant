[site]: datascience
[post_id]: 36747
[parent_id]: 36743
[tags]: 
From what I can remember from Andrew Ng's Deep Learning course on Coursera, he recommends making vectors of the kind $(y, b_x, b_y, b_w, b_h, c_0, c_1),$ where: $y$ indicates whether the picture contains one of the objects you're looking at (so it'd be $1$ in $5\%$ of your examples and $0$ in the others); $b_x$, $b_y$ indicate the $x$ and $y$ coordinates of where the picture's midpoint is found; $b_w$, $b_h$ indicate the width and height of the bounding boxes of your image; $c_0$ is $1$ if the picture contains a dog and $0$ otherwise; $c_1$ is $1$ if the picture contains a cat and $0$ otherwise. So, for example, a picture of a dog would get tagged as $(1, .3, .7, .2, .2, 1, 0)$, a picture of a cat of the same size in the same position would get tagged as $(1, .3, .7, .2, .2, 0, 1)$, and a picture with neither would have $0$ as its first coordinate and it wouldn't matter what the other coordinates were, as the initial $0$ has already signalled that the picture doesn't contain either of the objects we're seeking.
