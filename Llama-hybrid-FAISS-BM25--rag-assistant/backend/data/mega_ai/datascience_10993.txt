[site]: datascience
[post_id]: 10993
[parent_id]: 10946
[tags]: 
Construct a new data set with differences in the numeric variables and new factors in the categorical data containing the first and second levels to represent change. Then fit a linear model: data = cbind(data.t1, data.t2) names(data)=c("a1","b1","c1","response1","a2","b2","c2","response2") data$da = paste(data$a1,"-",data$a2) data$db = data$b2 - data$b1 data$dc = data$c2 - data$c1 data$dresponse = data$response2 - data$response1 So now the data columns we are interested in look like this: > data[,9:12] da db dc dresponse 1 red - blue 1 752.33 10000 2 yellow - blue -1 7910.44 -21100 3 blue - yellow -2 -126.33 -80800 4 blue - blue 1 -101.33 -80000 5 red - red -1 -3212.45 -71000 6 blue - red -1 -91.00 -493810 7 yellow - yellow 1 145.00 -21600 8 blue - red -1 3595.02 -20000 9 red - blue 2 3097.89 -63000 10 red - red 0 2090.43 -826000 So now see how the change in response from data.t1 to data.t2 depends on the change in the (numeric or factor) variables: > m = glm(dresponse ~ da + db + dc,data=data) The summary(m) will give you a coefficients table: Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 4.953e+05 8.904e+05 0.556 0.677 dablue - red -1.395e+06 1.822e+06 -0.766 0.584 dablue - yellow -1.713e+06 2.337e+06 -0.733 0.597 dared - blue 2.558e+05 6.113e+05 0.418 0.748 dared - red -1.206e+06 1.209e+06 -0.998 0.501 dayellow - blue -1.413e+06 2.666e+06 -0.530 0.690 dayellow - yellow 4.828e+04 6.543e+05 0.074 0.953 db -5.712e+05 7.489e+05 -0.763 0.585 dc 4.109e+01 1.541e+02 0.267 0.834 which you can interpret in the usual way. The process you describe about choosing which variables are most influential sounds like you just want the variables with the largest point estimate, but you may want to do some standardisation. For example, in the above, a unit change in b from 1 to 2, say, decreases the dresponse by -570000, but a unit change in c changes the response by +41.09 in the fitted model. But c has a much bigger range, so perhaps you want to standardise your numeric variables to have mean 0 and sd=1 first. The factor variables have a similar interpretation - rows with "yellow-yellow" increase response by 48280 compared to the average change in response. I'm not sure how you standardise categorical variables, since they are just a bunch of step-changes... Statistically none of these variables make any difference to the response (none of the t-values are big enough and there's no stars in the P column).
