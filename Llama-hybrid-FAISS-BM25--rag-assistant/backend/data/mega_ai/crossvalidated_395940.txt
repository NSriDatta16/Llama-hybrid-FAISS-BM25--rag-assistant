[site]: crossvalidated
[post_id]: 395940
[parent_id]: 
[tags]: 
Numerically/approximately integrating over independent gamma variables

Problem Statement For a problem in biology, I am testing out a joint distribution of the form: $$ X \sim Multinomial(\frac{\theta_1}{\sum \theta_i}, ...,\frac{\theta_n}{\sum{\theta_i}}) \\ \theta_i \sim Gamma(\alpha_i, \beta_i) $$ (where I use the shape-rate parametrization of the Gamma distribution). I am interested in the (logarithm of) marginal distribution $$ P(X | \alpha_{1..n}, \beta_{1..n}) = \int Multinomial(X|\Theta) \prod_i Gamma(\theta_i | \alpha_i, \beta_i) d \Theta $$ I know that in the special case of $\beta_1 = \beta_2 = ... = \bar\beta$ , the marginal distribution is Dirichlet Multinomial (DM). The DM distribution however does not fit the data I am encountering, the data are more dispersed than what the DM distribution can accomodate. How could I evaluate/approximate the general integral at least slightly efficiently? I would need to this within a larger inference, so for many combinations of the parameters. The $\alpha_i$ and $\beta_i$ come from a deeper level of the model and they are constrained so that $\sum E(log(\theta_i)) = 0$ . It is possible this is actually a very hard problem and pointer to why this is hard would be a sufficient answer. Things I've tried Letting $\beta_{1..n}$ to vary and treating $\theta_{1..n}$ as explicit latent variables, this model fits the data reasonably well, but is very slow even for small $n$ due to the large number of latent variables (I am using Stan). I don't believe there is an analytic solution for $P(X | \alpha_{1..n}, \beta_{1..n})$ in the general case, but would it be possible to write an approximation or have a numerical integration scheme that would let me to compute the (log of) this density efficiently? It feels like the structure of independent Gammas could be somehow exploitable (in fact, the integral may be restated to be over i.i.d Gammas taking advantage of the Gamma's scaling properties). I've tried a naive Monte-carlo scheme (sample from the gammas, compute the multinomial density, average over samples) which was hopelessly slow to converge even with few dimensions and a simple importance sampling scheme, using samples from the Dirichlet distribution as proposals for $\theta_1 / \sum \theta_i$ (to sample near the maximum likelihood area of the multinomial), but that only made things worse. I've tried to find the Laplace approximation to $P(log(\Theta)|X, \alpha_i, \beta_i)$ which looks reasonably Gaussian-like for many parameter combinations, but turns out to be problematic, as when $x_i = 0$ and $\alpha_i \leq 1$ , the mode is not defined. $P(\Theta)|X, \alpha_i, \beta_i)$ does not resemble Gaussian at all. From approximation point of view the question What is the expected value of modified Dirichlet distribution? (integration problem) is related. But all my attempts ended as very poor approximations. Slightly philosphical note: I believe DM does not fit my data because DM arises also from multinomial sampling of negative binomial variables with a fixed Fano factor (mean/variance ratio) - see e.g. Analytically solving sampling with or without replacement after Poisson/Negative binomial . Neg. binomial is Gamma-Poisson, where the $\beta$ parameter determines the Fano factor. But my data correspond to multinomial sampling of neg. binom variables where the Fano factor varies
