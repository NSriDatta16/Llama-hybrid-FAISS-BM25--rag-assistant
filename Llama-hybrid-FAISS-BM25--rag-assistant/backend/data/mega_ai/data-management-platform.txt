A data management platform (DMP) is a software platform used for collecting and managing data. DMPs allow businesses to identify audience segments, which can be used to target specific users and contexts in online advertising campaigns. They may use big data and artificial intelligence algorithms to process and analyze large data sets about users from various sources. Advantages of using DMPs include data organization, increased insight on audiences and markets, and more effective advertisement budgeting. On the other hand, DMPs often have to deal with privacy concerns due to the integration of third-party software with private data. This technology is continuously being developed by global entities such as Nielsen and Oracle. More generally, the term data platform can refer to any software platform used for collecting and managing data. It is an integrated solution which as of the 2010s can combine functionalities of for example a data lake, data warehouse or data hub for business intelligence purposes. However, this article discusses the use such technology platforms used for collecting and managing data for digital marketing purposes specifically. Characteristics Purpose A DMP is any kind of software that manages the gathering, storage, and organization of data so that useful information can be leveraged from it by marketers, publishers, and other businesses. The data stored may include customer information, demographics, and mobile identifiers or cookie IDs, which the DMP will analyze to allow businesses to create targeting segments for advertisements. DMPs can help brands learn more about their customer segments to inform acquisitions strategies and increase their sales. They also allow businesses to gauge the effectiveness of their advertising campaigns. History First and second generation programming languages During the 1950s, data management became a problem for companies as computers were not quick with computations and needed a great amount of labor to deliver results. Companies started by storing their data in warehouses. Early programs were written in binary and decimal and this was known as absolute machine language, which later was called the first generation programming language. After this, assembly language - which came to be known as second generation programming languages - came into existence. This symbolic machine code grew popular among programmers as they were able to utilize alphabet letters for coding. This led to less errors in programs and improved code readability. High-level languages Throughout the 1960s and 1970s, as technology continued to progress and programmers became more in touch with computers, the First and Second Generation Programming Languages evolved into high-level languages (HLL). These languages are known for being easily readable by a human and were important for allowing one to write a generic program that does not depend on the kind of computer used. HLL were known for emphasizing memory and data management and many of the languages that came out in this era (i.e. COBOL, C, and C++) are still widely used today. Online data management and databases Online transactions soon were a big part of many industries. This was made possible by online data management systems. These systems can analyze information quickly and they allow programs to read, update and send information to the user. In the 1970s, Edgar F. Codd developed an easy-to-learn language, Structured Query Language (SQL) that had English commands. This language dealt with relational databases, improved data processing and decreased duplicated data. This relational model allowed large amounts of data to be processed quickly and improved parallel processing, client-server computing, and graphical user interfaces and it made multiple users to interact simultaneously. To deal with the processing and research of Big Data, NoSQL came into existence. NoSQL's greatest power is its ability to store vast amounts of data. NoSQL was 