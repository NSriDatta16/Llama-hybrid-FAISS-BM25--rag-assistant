[site]: stackoverflow
[post_id]: 678848
[parent_id]: 678771
[tags]: 
MIPS is generally used to measure the capability of a processor. Algorithms usually take either: a certain amount of time (when running on a certain processor) a certain number of instructions (depending on the architecture) Describing an algorithm in terms of instructions per second would seem like a strange measure, but of course I don't know what your algorithm does. To come up with a meaningful measure, I would suggest that you set up a test which allows you to measure the average time taken for your algorithm to complete. Number of assembly instructions would be a reasonable measure, but it can be difficult to count them! Your best bet is something like this (pseudo-code): const num_trials = 1000000 start_time = timer() for (i = 1 to num_trials) { runAlgorithm(randomData) } time_taken = timer() - start_time average_time = time_taken / num_trials
