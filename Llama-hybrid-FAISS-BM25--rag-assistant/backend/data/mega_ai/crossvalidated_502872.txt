[site]: crossvalidated
[post_id]: 502872
[parent_id]: 
[tags]: 
What does it mean to say that "the prior over $f$ induces a prior over probabilistic classifications $\pi$"?

I am currently studying the textbook Gaussian Processes for Machine Learning by Carl Edward Rasmussen and Christopher K. I. Williams. Chapter 1 Introduction says the following: We now turn to the classification case, and consider the binary (or two-class) classification problem. An example of this is classifying objects detected in astronomical sky surveys into stars or galaxies. Our data has the label $+1$ for stars and $-1$ for galaxies, and our task will be to predict $\pi(\mathbf{\mathrm{x}})$ , the probability that an example with input vector $\mathbf{\mathrm{x}}$ is a star, using as inputs some features that describe each object. Obviously $\pi(\mathbf{\mathrm{x}})$ should lie in the interval $[0, 1]$ . A Gaussian process prior over functions does not restrict the output to lie in this interval, as can be seen from Figure 1.1(a). The approach that we shall adopt is to squash the prior function $f$ pointwise through a response function which restricts the output to lie in $[0, 1]$ . A common choice for this function is the logistic function $\lambda(z) = (1 + \exp(−z))^{−1}$ , illustrated in Figure 1.2(b). Thus the prior over $f$ induces a prior over probabilistic classifications $\pi$ . I'm confused by this part: Thus the prior over $f$ induces a prior over probabilistic classifications $\pi$ . Wasn't it just said that $f$ is the prior? So what does it mean by "the prior over $f$ induces a prior over probabilistic classifications $\pi$ "?
