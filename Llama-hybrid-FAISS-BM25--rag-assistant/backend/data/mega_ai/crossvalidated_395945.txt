[site]: crossvalidated
[post_id]: 395945
[parent_id]: 222687
[tags]: 
Do not use a 50-50 dataset for testing, as that would be too far from the real usage of the model and you may be unable to get information about the classifier's actual behaiviour. However, you can perform oversampling/undersampling of the classes in the training set in order to correct for bias in the model. My approach would be: First, I'd try creating my training and testing sets forgetting about the imbalance. If the model I get is good, then I am happy and carry on with my life. If that does not work as well as desired, I would split my testing set as before, but now, on the training set, remove random majority class observations until reaching balance. Now we can try to fit the model and test it. If that does not work either (undersampling the majority class may imply a loss in valuable information), have a look at the SMOTE procedure for creating new artificial observations of the minority class. And if that does not work either, well... Sometimes life is hard! Other approaches are converting the classification problem in an anomaly detection problem, but since the imblanace is only 4:1, I don't really think that's the best way to go. As a final thought, take into account the relative importance of the classes (ie: What would be worse, false positives or false negatives?) and pay attention to precision or recall accordingly. Do NOT use accuracy as a performance measure when working with unbalanced data. I hope this helped
