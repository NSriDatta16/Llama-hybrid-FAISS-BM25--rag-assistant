[site]: crossvalidated
[post_id]: 245881
[parent_id]: 245865
[tags]: 
There is nothing magical in machine learning. Say that your feature is altitude and you want to predict the temperature. This feature only is not sufficient to obtain correct predictions. Adding features like cos(altitude) or log(altitude) will not help your model. On the contrary, you will add useless dimensionality and suffer from curse of dimensionality. That means that your model will have more struggle to find a good minima. Performing some feature engineering (like adding feature such as f(altitude) ) can be useful if you know that there is some reality behind this new feature. In this case, you will help a lot models which are mostly linear such as linear regression or feedforward neural network. Therefore, I would say not to do it if it is totally random and do it if you know or think that your output has some dependencies with the new features.
