[site]: crossvalidated
[post_id]: 565191
[parent_id]: 
[tags]: 
How to find the expected mean of a very smalll subgroup, while still considering the larger group?

Context: For a Machine Learning challenge, I have a national exam dataset, containing over 3 million scores, from over 5k cities (unbalanced distribution). For example: ID City Other Score 01 NY ... 85 02 NY ... 90 03 NY ... 95 ... ... ... ... 10001 LA ... 60 10002 LA ... 40 10003 LA ... 50 ... ... ... ... 2999999 a small city ... 20 3000000 just another city ... 80 My Goal: Given another individual, their city (and other data), guess their score. My approach: Generating another column containing the mean of the city, like so: ID City City_mean Other Score NY01 NY 70 ... 90 NY02 NY 70 ... 70 NY03 NY 70 ... 50 ... ... ... ... LA01 LA 55 ... 65 LA02 LA 55 ... 55 LA03 LA 55 ... 45 ... ... ... ... ... 2999999 a small city 20 (?) ... 20 3000000 just another city 80 (?) ... 80 Problem: When I have a big city, with thousands of samples, I'm quite glad with the mean. But when I handle small cities, with very few samples, this average will often be extreme values, too far from the global average. That just happens by accident. My proposed solution: Adding some virtual average observations to all cities. To mitigate this small-sample-aberration , I've added 50 average virtual people in each city. So small sample observations will lean toward the global mean. For example, with only 5 observations, the mean would be: (5*city_mean + 50*global_mean)/55 It looks like it solves my problem, but I hate picking arbitrary numbers (50) and it feels like there's a right way to do this. Maybe involving standard deviation , or Bayesian theory... Final Question: What's the best theoretical approach for estimating subgroups scores, when some subgroups have very few sizes?
