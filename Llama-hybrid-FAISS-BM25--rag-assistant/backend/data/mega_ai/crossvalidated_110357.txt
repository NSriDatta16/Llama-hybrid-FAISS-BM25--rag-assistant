[site]: crossvalidated
[post_id]: 110357
[parent_id]: 
[tags]: 
Estimating the time for completing a sequence of actions

In short: suppose I have observations for times taken to do some action. I want to estimate, how long will it take to complete a sequence of actions. The estimate should minimize the mean absolute error (L1 norm). === Details: I have observations for positive, non-identically distributed RV $x_i$, it can be assumed that RV are independent. I am interested in $y = \sum_{i=1}^n x_i$. For example, $x_i$ can be the time for action $i$, and $y$ the time for completing a sequence of actions. I would like to find an estimate $\hat{y}$ that would minimize the mean absolute error (L1 norm). So I need to estimate $\mathit{median}(y)$. For $n = 1$ the estimate is straightforward $\hat{y} = \mathit{median}(x_1)$. For large $n$ I have observed that $\hat{y} = \sum_{i=1}^n \mathit{mean}(x_i)$ gives a reasonably good estimate. I suppose this is explained by the Central Limit Theorem: for large $n$, $y$ approaches the normal distribution, thus $\mathit{median}(y) \approx \mathit{mean}(y)$, and $\mathit{mean}(\sum_{i=1}^n x_i) = \sum_{i=1}^n mean(x_i)$. Question: Is there any analytical solution for approximating median of the sum of independent non identically distributed RV for small $n$, i.e. for approximating $\mathit{median}(y)$ for small $n$ in this context? Practically, in the data $n$ is distributed: $n=1$ ($10\%$), $n=2$ ($20\%$), $n=3\ldots 5$ ($20\%$), $n=6\ldots 10$ ($10\%$), and $n>10$ ($40\%$), maximum $n$ is $70$. === So far my solution is as follows. I assume that that $\hat{y} = \sum_{i=1}^n \big((1-w)*\mathit{median}(x_i) + w*\mathit{mean}(x_i)\big)$, where $w \in [0,1]$ is a weight. When $n=1$, $w=0$. When $n\rightarrow \infty$, $w \rightarrow 1$. Then I model $w$ as a function of $n$. I estimate an empirical distribution of all observations (ignoring that the variables are non identically distributed), generate synthetic data from that distribution. On that data I learn $w = f(n)$ using some machine learning approach, e.g. ANN. The data is generated as follows. I sample $n$ uniformly at random. I compute the true $\mathit{median}(y)$. I let $w$ run from $0$ to $1$ and pick $w$ that gives the minimum absolute deviation of $\hat{y} = \sum_{i=1}^n \big((1-w)*\mathit{median}(x_i) + w*\mathit{mean}(x_i)\big)$ from $\mathit{median}(y)$. This gives me one data point. I generate, say 10000 such data points and learn a function on this data. This gives a slight improvement over simply using $w=0$ or $w=1$ for all $n$, but not much, and not always. === And finally, to illustrate my intuition that there may exist a nice functional form of $w$, here is an example of $w = f(n)$ learned on synthetic data sampled from log-normal distribution $ln {\cal N}(0,s)$. Solid lines denote estimated functions, circles denote out-of-sample test data.
