[site]: datascience
[post_id]: 121270
[parent_id]: 
[tags]: 
tensorflow recommeders item item recommender

I am trying to create an item-item recommender using tensorflow recommenders (TFRS). I have successfully created a user-item recommender using TFRS using the code at this link as a template: TFRS retrieval There is an explanation at the bottom of the page of that link that describes how to implement an item-item architecture: ' Item-to-item recommendation In this model, we created a user-movie model. Training models like this would follow the same pattern as shown in this tutorial, but with different training data. Here, we had a user and a movie tower, and used (user, movie) pairs to train them. In an item-to-item model, we would have two item towers (for the query and candidate item), and train the model using (query item, candidate item) pairs. ' ' We have a total of about 7000 unique user_id values and 100000 unique domain (purchases) values. The domain values will be predicted as purchases for the user_id. I will only be using user and item features. No rating or other features. each user_id corresponds to a unique user. each unique company number can exist in multiple rows with different domain values or repeated domain values. A row consists of a user and their respective purchase. I have the following attempt at the model: import tempfile import pandas as pd import numpy as np import tensorflow as tf import tensorflow_recommenders as tfrs import mlflow from pyspark.mllib.evaluation import RankingMetrics import os import cloudpickle import sys import shutil train_data = pd.read_csv('/path/to/train_data.csv', index_col=0) train = train_data[[user_col, item_col]] train = train.dropna() test_data = pd.read_csv('/path/to/test_data.csv', index_col=0) test = test_data[[user_col, item_col]] test = test.dropna() train_tf = tf.data.Dataset.from_tensor_slices(dict(train)) test_tf = tf.data.Dataset.from_tensor_slices(dict(test)) df_tf = train_tf.concatenate(test_tf) data = pd.concat([train, test]) # Features of all the available domains. domains = data[[item_col]].drop_duplicates() domains_tf = tf.data.Dataset.from_tensor_slices(dict(domains)) user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None) user_ids_vocabulary.adapt(df_tf.map(lambda x: tf.strings.as_string(x[user_col]))) domain_vocabulary = tf.keras.layers.StringLookup(mask_token=None) domain_vocabulary.adapt(data[item_col].apply(str).values) df_tf = df_tf.map(lambda x: { "query_domain": tf.cast(domain_vocabulary(tf.strings.as_string(x[item_col])), tf.int64), "candidate_domain": tf.cast(domain_vocabulary(tf.strings.as_string(x[item_col])), tf.int64), "company_number__c": tf.strings.as_string(x[user_col]) }) query_item_model = tf.keras.Sequential([ tf.keras.layers.StringLookup(vocabulary=user_ids_vocabulary.get_vocabulary(), mask_token=None, input_shape=()), tf.keras.layers.Embedding(len(user_ids_vocabulary.get_vocabulary()) + 1, 32) ]) candidate_item_model = tf.keras.Sequential([ tf.keras.layers.StringLookup(vocabulary=domain_vocabulary.get_vocabulary(), mask_token=None, input_shape=()), tf.keras.layers.Embedding(len(domain_vocabulary.get_vocabulary()) + 1, 32) ]) task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(candidates=domains_tf.batch(1000).map(lambda x: candidate_item_model(tf.expand_dims(tf.strings.as_string(x[item_col]), -1))))) class ItemItemModel(tfrs.Model): def __init__( self, query_item_model: tf.keras.Model, candidate_item_model: tf.keras.Model, task: tfrs.tasks.Retrieval): super().__init__() self.query_item_model = query_item_model self.candidate_item_model = candidate_item_model self.task = task def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor: query_item_embeddings = self.query_item_model(features["query_domain"]) candidate_item_embeddings = self.candidate_item_model(features["candidate_domain"]) return self.task(query_item_embeddings, candidate_item_embeddings) model = ItemItemModel(query_item_model, candidate_item_model, task) model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1)) model.fit(df_tf.batch(4096), epochs=10) index = tfrs.layers.factorized_top_k.BruteForce(model.query_item_model) index.index_from_dataset( tf.data.Dataset.from_tensor_slices(dict(domains)).batch(1000).map( lambda x: (x[item_col], model.candidate_item_model(x[item_col])) ) ) # Generating recommendations user_id = "12345" _, titles = index(tf.constant([user_id])) recommended_domain_ids = [domain_vocabulary.get_vocabulary()[x] for x in titles[0].numpy()] # Print the top 10 recommended domains for the user print("Top 10 recommended domains for user:", user_id) print(recommended_domain_ids[:10]) I seem to be chasing around type errors. Is there an obvious problem with this model that I am missing? An example of the data would resemble this dataframe import pandas as pd import numpy as np # generate user_id and item_id arrays user_id = np.repeat(np.arange(100), 100) item_id = np.tile(np.arange(200), 50) # create dataframe df = pd.DataFrame({'user_id': user_id, 'item_id': item_id}) # shuffle the items within each group of user_id df = df.groupby('user_id', group_keys=False).apply(lambda x: x.sample(frac=1)) # reset the index of the dataframe df = df.reset_index(drop=True) ```
