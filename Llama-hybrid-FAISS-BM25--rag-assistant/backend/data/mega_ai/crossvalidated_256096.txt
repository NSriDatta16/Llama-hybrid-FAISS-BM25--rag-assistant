[site]: crossvalidated
[post_id]: 256096
[parent_id]: 
[tags]: 
Formulating a cartoon-caption matching problem

In my dataset I have cartoons, which are actually just sets of word tags. Those tasg come in two sub sets, one stands for the context of the cartoon and the other stands for the anomaly in it. An example - imagin a duck giving a presentation. The context tags could be - office, preserntation, seminar, workplace. An anomaly tag could be - duck, animal. Each cartoon has a caption (I know which cartoon belongs to which caption), and my task is given two cartoons $a_1,a_2$ and two captions $b_1 ,b_2$ to match a cartoon with the correct caption. The simplest approach would of course be to take the average word2vec for each $a_1,a_2,b_1,b_2$ and match the couples according to distances between them. I thought maybe to use clustering on my whole data set and perhaps measure the distances to those clusters and not directly between a caption and a cartoon. But is'nt that the same actually? So, what I would like to know is: Is my problem formal enough? I feel like Im missing here something, because the cartoon tags/captions could contain information that is quite sparse in comparisson to the whole drawing. In what machine learning category can I put my problem in to? it's not calssification because $b_1,b_2$ could just as be $b_2,b_1$? or perhaps I want to classifiy each caption and cartoon seperatly, and then check for matches? I'm new to this kind of work - so I'd appreciate if you could tell me about concepts or software libraries (I work wth python+gensim+nltk) or simillar works that I should be familliar with.
