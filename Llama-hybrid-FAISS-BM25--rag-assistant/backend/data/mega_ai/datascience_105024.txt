[site]: datascience
[post_id]: 105024
[parent_id]: 53703
[tags]: 
One approach is to frame your model as text classification. Given a corpus of documents, learn the features that predict the discrete categories. Text classification can be done by learning an embedding and training a model to learn to classify the documents into categories. Something like this: from tensorflow.keras.layers import Activation, Dense, Embedding, Convolution1D, MaxPooling1D from tensorflow.keras.models import Sequential from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.utils import to_categorical docs = ['year of education', 'years education', 'years of educational', 'two years of education', 'years of education beyond', 'education four year', 'of proven sales experience', 'knowledge of and', 'experience or education high', 'assigned knowledge skills', 'accountable for driving', 'administrative and leadership skills', 'advanced negotiations skills', 'must have keyboarding skills', 'must have skills', 'activities preferred skills', 'of clinical skill ',] # Tranform string documents into numeric sequences tokenizer = Tokenizer(num_words=100) # Tokenizer lowercases and strips punctuation tokenizer.fit_on_texts(X) X = tokenizer.texts_to_sequences(X) # Convert texts to token sequences y = ['Education']*5 y += ['Ability']*5 y += ['Experience']*5 # Tranform string categories into numeric categories mapping = {word: i for i,word in enumerate(y)} # Hashing trick to encode string as category vec = [mapping[word] for word in y] # Apply hashing trick y = to_categorical(vec) # Convert numerical values into one-hot encoded values # Create the model model = Sequential() # The Embedding layer is similar to word2vec model.add(Embedding(input_dim=100, output_dim=3, input_length=4 )) # Convolution layer model.add(Convolution1D(filters=64, kernel_size=2, activation='relu',)) model.add(MaxPooling1D()) # The target specific output layer model.add(Dense(units=3)) model.add(Activation('softmax')) model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) # Train the model model.fit(X, y, batch_size=256, epochs=100); # Predict the categories for new data docs_new = ["There is a requirement of four-year professional degrees", "Able to drive the teams to higher levels", "Must have programming experience in C, C++",] for X_new in docs_new: X_new = tokenizer.texts_to_sequences(X_new) model.predict(X_new)
