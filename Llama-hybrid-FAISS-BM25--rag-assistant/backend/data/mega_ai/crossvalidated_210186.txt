[site]: crossvalidated
[post_id]: 210186
[parent_id]: 210027
[tags]: 
You basically want to find the distance between the two distributions, and pick the sampler that has the smaller distance from the probability distribution $p$. The most natural thing to consider is the Total Variation distance since convergence of Markov chains is generally assessed using TV distance. Although, to use this, you might want to make sure you run all the 1000 samples for the same number of iterations before picking the last sample. The total variation distance between two distributions $P$ and $Q_1$ defined on a space $\mathcal{X}$ is $$\|Q_1 - P\|_{TV} = \sup_{A \subset \mathcal{X}}|Q_1(A) - P(A)|. $$ Intuitively, TV distance is the largest difference between the two distributions over all possible subsets. You can find the TV distance from $P$ for $Q_1$ and $Q_2$, and compare. I believe package distrEx in R can do this for you. You can also use something like the Kullback-Leibler Divergence . This is more popular in information theory. Note that KL-Divergence is not a distance (which means it is not symmetric). So $KL(P\|Q_1)$ is not the same as $KL(Q_1\|P)$. $KL(P\|Q_1)$ finds the divergence of $Q_1$ from $P$. So you can find $KL(P\|Q_1)$ and $KL(P\|Q_2)$ and compare. In R you can use the package FNN .
