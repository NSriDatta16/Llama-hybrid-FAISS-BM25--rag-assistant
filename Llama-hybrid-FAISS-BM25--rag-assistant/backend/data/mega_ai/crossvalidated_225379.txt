[site]: crossvalidated
[post_id]: 225379
[parent_id]: 
[tags]: 
What happens inbetween switching test and training sets in k-fold cross validation

The general idea of k-fold cross validation is to partition your test data from your training data, then within your training data you make another partition where all but one of those partitions are used for training and the one being left out is used for testing. Now you repeat this process for each of those partitions. What I want to know is concretely what happens to the weights at each step? For example, for my first training/testing cycle, if I have 7 partitions, 6 are used for training, one is used for testing. This process creates some set of weights. Now do I initialize an entirely different validator with weights at zero for the next cycle where I switch the testing set? Or are the same weights that were created in the first cycle used ? Do you save the weights at each cycle somewhere else, perhaps in some list object and at the end average them all together?
