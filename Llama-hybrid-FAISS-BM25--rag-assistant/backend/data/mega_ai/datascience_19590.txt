[site]: datascience
[post_id]: 19590
[parent_id]: 19586
[tags]: 
As the error message states, the invocation to cross_val_score fails because the shape arguments differ in their first dimension (1460 vs. 1459). This is consistent with the number of lines in the CSV files. However, the underlying problem is that you are mixing the test and the training sets. You should invoke it only with the test set: cross_val_score(lm, my_test_dataset_X, lm.predict(my_test_dataset_X), cv=10) . Update : My initial suggestion was NOT correct, you cannot use your own predictions to validate! You should leave a subset of the labeled data for hold out on which to compute the cross validation. Yours is not only a linear regression. The bulk of your code is in charge of data manipulation (feature selection, data imputation) and not linear regression. Actually, you are reusing scikit-learn's implementation of linear regresion, not coding your own. If you want a code review of your snippet, maybe you should try in http://codereview.stackexchange.com (I don't know if this fits there either, you'd better check their help center ). UPDATE: About whether your code is sound from a data science point of view, it seems to me (after only a quick review) that you are doing reasonable things. There are some things that could be improved, like only handling float64 and int64 (while you can do as described here ), only imputing NaNs and Nones (while there can be other values that should be imputed in certain cases, like outliers), or imputing blindly with the median (which is a safe decision but should be assessed taking into account the nature of each variable). But generally speaking seems Ok.
