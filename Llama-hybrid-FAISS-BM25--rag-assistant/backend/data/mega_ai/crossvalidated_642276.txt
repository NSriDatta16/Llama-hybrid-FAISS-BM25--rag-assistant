[site]: crossvalidated
[post_id]: 642276
[parent_id]: 642125
[tags]: 
Thanks for the reproducible example. I agree with Gavin that a Gaussian observation model is not really appropriate here. But you have other complexities to deal with as well. I'll use an R package, { mvgam }, to illustrate. This package was designed for exactly these kinds of problems, i.e. using GAMs to analyse and forecast time series (installation instructions and examples are found here: https://nicholasjclark.github.io/mvgam/ ). First I load the data, add a series and a time indicator and plot features of the series: url % mutate( Date = as.Date(Date), YearDay = as.numeric(format(Date, "%j")), Year = as.numeric(format(Date, "%Y")), # Ensure 'season' is a factor with appropriate levels season = factor(season, levels = c("Summer", "Rainy season", "Autumn", "Late autumn", "Winter", "Spring")) ) # Load mvgam; add a 'series' indicator and look at the data library(mvgam) dengue %>% mutate(time = dplyr::row_number(), series = as.factor('Dhaka')) -> dengue # Huge autocorrelation and many zeros to think about plot_mvgam_series(data = dengue, y = 'Dhaka_DI') As Gavin mentioned, your response is non-negative integers and there are many zeros. A Gaussian observation model won't respect these constraints. Next I split the data into training and testing as you have done, and fit a model that only includes the seasonal effects as well as a latent dynamic process (as an AR1 process): # Splitting the data split_date % filter(Date % filter(Date >= split_date) # Fit a simple model with Poisson observations over a cyclic YearDay # smooth, a parametric season effect and a latent AR1 process gam_mod By default, mvgam() will estimate model parameters using Stan for full Bayesian inference. This takes a while to fit (120 seconds on my i9 processor), which is a bad sign given the simplicity of the model. The summary doesn't tell us too much, apart from showing that the seasonal spline is a bit difficult to estimate (look at the low effective sample sizes of the spline coefficients, and the warnings about treedepths): summary(gam_mod) GAM formula: Dhaka_DI ~ s(YearDay, k = 12, bs = "cc") + season Family: poisson Link function: log Trend model: AR() N series: 1 N timepoints: 598 Status: Fitted using Stan 4 chains, each with iter = 1000; warmup = 500; thin = 1 Total post-warmup draws = 2000 GAM coefficient (beta) estimates: 2.5% 50% 97.5% Rhat n_eff (Intercept) 2.30 3.100 3.80 1.01 528 seasonRainy season -1.30 -0.530 0.21 1.00 1099 seasonAutumn -1.10 -0.097 0.80 1.00 1295 seasonLate autumn -0.75 0.470 1.60 1.00 1255 seasonWinter -1.80 -0.490 0.72 1.00 1275 seasonSpring -2.50 -1.300 -0.27 1.00 830 s(YearDay).1 -2.80 -1.800 -0.83 1.02 298 s(YearDay).2 -3.20 -2.200 -1.10 1.02 388 s(YearDay).3 -3.00 -1.900 -0.77 1.02 517 s(YearDay).4 -1.80 -0.760 0.38 1.01 561 s(YearDay).5 -0.12 1.000 2.20 1.01 435 s(YearDay).6 1.10 2.400 3.60 1.02 325 s(YearDay).7 1.70 3.000 4.00 1.02 314 s(YearDay).8 1.50 2.800 4.10 1.00 374 s(YearDay).9 0.95 2.300 3.60 1.00 414 s(YearDay).10 -0.10 1.100 2.30 1.01 433 Approximate significance of GAM observation smooths: edf Chi.sq p-value s(YearDay) 7.46 16008 0.0078 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Latent trend parameter AR estimates: 2.5% 50% 97.5% Rhat n_eff ar1[1] 0.86 0.91 0.95 1.01 500 sigma[1] 0.50 0.55 0.59 1.01 768 Stan MCMC diagnostics: n_eff / iter looks reasonable for all parameters Rhat looks reasonable for all parameters 0 of 2000 iterations ended with a divergence (0%) 399 of 2000 iterations saturated the maximum tree depth of 12 (19.95%) *Run with max_treedepth set to a larger value to avoid saturation E-FMI indicated no pathological behavior Samples were drawn using NUTS(diag_e) at Sun Mar 10 9:56:02 PM 2024. For each parameter, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split MCMC chains (at convergence, Rhat = 1) Plotting the cyclic smooth doesn't really indicate any issues: plot(gam_mod, type = 'smooths') But showing the conditional cyclic smooth against the observed data is more useful (these plots use support from the { marginaleffects } package: plot_predictions(gam_mod, condition = c('YearDay'), points = 0.6) + theme_classic() Here you can see that the seasonality changes quite a lot between years, and the cyclic smooth is forced to make a compromise between the two years. As a result, it doesn't fit the data very well and the latent AR1 process is forced to compensate by being extremely flexible (almost behaving as a Random Walk): plot(gam_mod, type = 'trend') The resulting forecast is therefore not great: fc I suggest you look into the data a bit more and try to work out why seasonality changes so much from year to year. In the past I've had success doing this with distributed lags of climate variables, for example to predict time-varying seasonal curves of tick paralysis incidence in Australian dogs: https://www.youtube.com/watch?v=Yu5zD4WSrmA&list=PLzFHNoUxkCvtIGABuakH_T5CLVZPedaXQ . But I can't say whether this would work in your context
