[site]: crossvalidated
[post_id]: 249902
[parent_id]: 249876
[tags]: 
First, though you say what we do know, based on the assumption from the transformation, is that: $E[y^\frac 12] \sim N(\mu,\sigma^2)$ note that if "the ML algorithm" is something like linear least squares , then there should be no expectation, i.e. $\sqrt{y}$ is normally distributed, rather than its mean. However, the distributional assumption is not strictly needed to answer your question. If $z=\sqrt{y}$ has mean $\mu$ and variance $\sigma^2$, then by definition $\mathbb{E}[z]=\mu$ and $\sigma^2=\mathbb{E}\left[(z-\mu)^2\right]=\mathbb{E}[z^2]-\mu^2$. Then since $y=z^2$ its average is given by $$\mathbb{E}[y]=\mu^2+\sigma^2$$ Note that to compute error bars, you would have to use some distributional assumption. Technically if $z$ is Normal, then $y/\sigma^2$ will have a non-central Chi-squared distribution. However in practice, as implied by Carl's answer, you can just compute "normal" confidence intervals on $z$ (i.e. in terms of $\pm\sigma$) and then square their endpoints (e.g. $[y_{10},y_{90}]=[z_{10}^2,z_{90}^2]$, since order statistics are "preserved" under monotonic transforms).
