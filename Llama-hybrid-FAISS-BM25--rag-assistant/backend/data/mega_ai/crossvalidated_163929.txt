[site]: crossvalidated
[post_id]: 163929
[parent_id]: 163580
[tags]: 
Your both examples concern with deterministic time series, with no noise and no trend. Deterministic time series, with no trend is not really the kind of data that ARIMA was designed for (see this question to learn more on ARIMA assumptions). Actually to forecast future trend given your data what you could do is simply to take averages of different time lags and then repeat them in the same order. The problem in here is to determine the number of lags to use, that is, to find out the length of the window that repeats itself. This could be simply achieved, using sum of squared errors or other error measure. If you define average $k$'th lag value as $$ \overline x_{(k)} = \frac{1}{N/K} \sum_{i=0}^{(N/K)-1} x_{k+i \times K} $$ and sum of squared errors is $$ \mathrm{SSE} = \sum_{k=1}^K \sum_{i=0}^{(N/K)-1} \left( x_{k+i \times K} - \overline x_{(k)} \right)^2 $$ then you can use SSE to choose the best window size. Below you can find an example in R. tsPattern Below you can see the results plotted (red points are estimated values, lines are actual data). This primitive approach works very good for your examples of deterministic time series with no trend and no noise, it would fail however with real life data, i.e. exactly in such cases as ARIMA (and other similar time-series methods) were designed for. Below you can see results of using this method and auto.arima for real life data ( WWWusage dataset in forecast library).
