[site]: crossvalidated
[post_id]: 305549
[parent_id]: 305440
[tags]: 
I have two suggestions for approaches that you might try: Naïve Bayes and Neural Networks. Naïve Bayes From Wikipedia , Naïve Bayes classifiers apply Bayes's Theorem to determine the probability that a given instance belongs to each class. In your case, given the feature vector $\vec{v} = (v_1,...v_{10})$ and you want to predict one of $k$ classes $ID$, a Naïve Bayes classifier would compute: $$P(ID_k | \vec{v}) = \frac{P(ID_k) \times p(\vec{v}|ID_k)}{P(\vec{v})} $$ One limitation to this approach is that it assumes complete independence between the variables (that's the "naïve" part), but in practice you can still get good results if your variables are mostly independent. Neural Networks Another approach would be to train a neural network with one neuron per variable $(v_1,...v_{10})$ in the input layer, a certain number of hidden layers and then an output layer that gives you $ID$. You might want to do some data preparation to encode the IDs in an "easy-to-represent" format for the neural network, but a lot of the tuning like that is problem dependent. Depending on how in depth your knowledge is of Neural Networks, Geoff Hinton's series of videos on them are quite illuminating and accessible.
