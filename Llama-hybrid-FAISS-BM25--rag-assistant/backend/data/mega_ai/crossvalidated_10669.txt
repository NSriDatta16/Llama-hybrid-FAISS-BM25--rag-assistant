[site]: crossvalidated
[post_id]: 10669
[parent_id]: 
[tags]: 
Decision tree output -- learning

I am running a model for which I am getting a very bad percentage detection of events in the confusion matrix (basically my true positives). Obviously that implies my false negatives are too hight. When I gave these dataset to a neural network node or a decision tree node, I see that the percentage detection by these two techniques is quite good (65% - 67% vis a vis mine 15%). I went to the decision tree diagram and saw the various cuts under which it divides the population. I obviously understand that the variable which falls on the root of the tree has highest importance and the leafs have lowest. How can the decision tree "tree" help me create categorical variables or treat continuous variables so that the accuracy of my model improves? To clarify, if a decision tree can generate a matrix with 65% detection, it would have some rule inside it to get such accuracy. These rules would display in the tree diagram we get as output. Can we use this tree to create out variables in a different way and get close to the accuracy given by decision tree?
