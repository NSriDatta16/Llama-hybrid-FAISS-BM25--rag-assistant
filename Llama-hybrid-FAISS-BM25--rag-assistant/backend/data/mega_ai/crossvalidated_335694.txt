[site]: crossvalidated
[post_id]: 335694
[parent_id]: 335233
[tags]: 
There is no way to compare joint distributions of $(X, y)$ between A and B sets, when you haven't seen any single observation of $y$ on the B set. Thus, you cannot directly measure whether the datasets are similar enough. You have to rely on bare intuition . However, you can do some indirect checks to aid your intuition: Obtain proxies for $y$ You can invent a metric $\tilde{y}$ which is expected to correlate with $y$, and see how the predictive power of the model $p(\tilde{y}|X)$ changes between A and B sets. For example, in credit scoring you can get information about defaults on other loans in bureau, or use credit card utilization and early delinquency rates as a proxy to default rate. Compare distributions of $X$ Having no data, you could make a heroic assumption that $p(y|X)$ is simimlar on A and B. However, even in this case your model could be useles on B, if the unconditional distribution of $X$ on B is very different. You can check this by comparing distribution of individual components of $X$ on A and B. If you want some numerical metrics of difference of two distributions, you can use KL divergence, or "population stability index". Assess individual coefficients Sometimes adequacy and/or generalizing ability of linear models (including GLM such as logistic regression) can be judged from individual coefficients. If every coefficient conforms your expectations of how the corresponding regressor should affect your target, you can hope that the model generalizes well. However, as it was said in the comments, no amount of assumptions will enable you to test the model unless you have your $y$s. Thus, I would advise to concentrate your attention on the ways to measure $y$ in the quickest and cheapest way.
