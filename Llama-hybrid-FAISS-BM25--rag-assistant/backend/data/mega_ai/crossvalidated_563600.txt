[site]: crossvalidated
[post_id]: 563600
[parent_id]: 563590
[tags]: 
You are probably right in diagnosing what went wrong, and yes there are techniques to mitigate this. Xgboost offers regularization options to make sure nodes have "enough" data. The "gamma" parameter does this by requiring a minimum improvement in the training objective - you should be able to increase gamma to a point where this value isn't being singled out. There is also a "min_child_weight" parameter - if you are using the sum of squared errors objective this is just a minimum number of rows per node. Increasing this should also be able to prevent the problem. But even more simply, if you know that you only have one row with this value, and you know you never want your decision trees to use this feature to distinguish that record, you could always just cap the variable at some lower threshold before training the model.
