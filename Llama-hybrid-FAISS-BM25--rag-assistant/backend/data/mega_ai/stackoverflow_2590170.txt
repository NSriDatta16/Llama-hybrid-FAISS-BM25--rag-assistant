[site]: stackoverflow
[post_id]: 2590170
[parent_id]: 2555049
[tags]: 
I'm not sure what to say about the matter of practical applications. Does modeling cognitive abilities with generative models constitute a "practical application" in your mind? The key importance of Church (at least right now) is that it allows those of us working with probabilistic inference solutions to AI problems a simpler way to model. It's essentially a subset of Lisp. I disagree with Chris S that it is at all a toy language. While some of these inference problems can be replicated in other languages (I've built several in Matlab) they generally aren't very reusable and you really have to love working in 4 and 5 for loops deep (I hate it). Instead of tackling the problem that way, Church uses the recursive advantages of lamda calaculus and also allows for something called memoization which is really useful for generative models since your generative model is often not the same one trial after trial--though for testing you really need this. I would say that if what you're doing has anything to do with Bayesian Networks, Hierarchical Bayesian Models, probabilistic solutions to POMDPs or Dynamic Bayesian Networks then I think Church is a great help. For what it's worth, I've worked with both Noah and Josh (two of Church's authors) and no one has a better handle on probabilistic inference right now (IMHO).
