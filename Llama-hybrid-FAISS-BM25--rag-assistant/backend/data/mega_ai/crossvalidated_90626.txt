[site]: crossvalidated
[post_id]: 90626
[parent_id]: 90480
[tags]: 
This approach is called bag-of-words. During training you get features (SIFT in your case) from all the training images. Because each image contains different number of features extracted and there are too many of them you perform $k$-means clustering. This process creates a codebook which is something like compressed version of the initial features. After clustering given an image you extract SIFT features and map each of them to the closest $k$-means centroid. Finally you calculate a vector of frequencies which consists of the number of SIFT features mapped to the first centroid, second, and so on. This vector is $k$ dimensional. Once such conversion is possible you can create $k$ dimensional representation for both training and testing images and learn SVM.
