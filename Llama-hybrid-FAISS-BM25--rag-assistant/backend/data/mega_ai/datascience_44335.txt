[site]: datascience
[post_id]: 44335
[parent_id]: 
[tags]: 
Test for heteroscedasticity in time series

I want to test heteroscedasticity in time series. The tools in python like: statsmodels.stats.diagnostic.het_breuschpagan require residuals as input obtained by fitting model to data. Since this kind of test relies on the goodness of the model trained. I want to test the heteroscedasticity on time series without training any model, directly on the data itself. So I use McLeod.Li test in R to test it on raw time series. I analyzed individual features have heteroscedasticity. To remove heteroscedasticity, I added 1 to all entries in data (since it has 0 entries) and computed heteroscedasticity the pvalues moved to 0. Why?
