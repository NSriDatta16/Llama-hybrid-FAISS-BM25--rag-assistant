[site]: datascience
[post_id]: 41827
[parent_id]: 41815
[tags]: 
Basically, a decision tree grows itteratively putting more significance on the number of observed units within a node, whilst a logistic regression attempts to fit all observations in some line of theoretical distribution. The former approach, apparently, can bring more information from smaller counts than the latter. As a result, a tree combines the probabilities of classification from each node achieved by a "heterogeneous" ruleset, while a regression cares more about a "homogeneous" formula which describes rather the magnitude of a factor significance to fitting that distribution. Having that said, a log reg is not really a classifier, but is often used as one. For a better understanding of the two approaches, I'd recommend reading where they come from and for what purposes they were developed.
