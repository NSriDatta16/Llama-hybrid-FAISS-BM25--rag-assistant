[site]: crossvalidated
[post_id]: 622188
[parent_id]: 
[tags]: 
Normalizing a data set by using z-scores from a related data set

I am trying to come up with a normalization for a set of data. My company puts our products through a series of testers (people) to score our products on key metrics. I am able to access all records from each tester and when I look at the averages, I find that some testers always have scores higher than the standard deviation and some testers always have scores below the standard deviation. Since we only have 3-4 testers on each product, this variance in testers could impact our decision on products. I was able to calculate a Z-Score for each tester. I was thinking about using this to create some form of normalization factor that I could apply to their raw scores. I didn't think using a z-score transformation was the right approach as this process is using a z-score from a different data set. I want the normalization to be using the testers scores and applying that to the products overall score. Is this the right approach? I'm not the best at statistics so maybe there is a totally different method that works better. Thank you Further info: Testers will have already tested hundreds of products (depends on how long they've been on staff). Products are randomly assigned to testers, testers never test the same product twice. They will typically score on 8 keys areas on a scale of 1-5 per product. We take an average of these scores to come up with the tester's final score (average). The products are then then sent to other testers for their averages. The testers scores are all averaged together to get a final score. I know sometimes averaging averages can be bad, but in this case, the scale of ratings (1-5) never changes, so I believe it works here.
