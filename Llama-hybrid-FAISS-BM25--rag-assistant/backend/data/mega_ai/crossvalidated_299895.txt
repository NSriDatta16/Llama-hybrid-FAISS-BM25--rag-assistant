[site]: crossvalidated
[post_id]: 299895
[parent_id]: 
[tags]: 
State recognition and representation in Reinforcement learning: methodology

Is there a general framework for recognition and representation of states in markov decision process? Let's say, I want to train an agent to play tic-tac-toe and I use simple Q-learning and $\epsilon$-greedy policy to find the optimal Q-function. I would proceed like this: Let $\mathbb{S}$ be a set of all possible states and $\forall s \in S: s = (s_1, \ldots , s_n) $ and $ s_i \in \mathbb{R}$ Define hash function $F:\mathbb{S}\longrightarrow \mathbb{N}$ as an injective function. Use values of $F$ as links to Q-table with estimates of Q-function Now this attitude seems quite clumsy, since the hash function for more complex or more dimensional state spaces could be pretty difficult to write. Also it could be difficult to ensure that the function be injective. So my question is: Is there a better way to store list of states other than in integer form? Can I avoid converting the state of the board through some hash function to a unique integer code? Is there an overview of state recognition and representation methods with advantages and drawbacks of them? Edit: The question is meant to be about general methodology of state representation. Specific implementations of different languages are not the subject of interest.
