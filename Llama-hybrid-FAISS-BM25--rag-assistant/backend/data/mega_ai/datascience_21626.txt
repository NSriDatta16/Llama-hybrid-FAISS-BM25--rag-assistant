[site]: datascience
[post_id]: 21626
[parent_id]: 21625
[tags]: 
So we have that a word to vector model has been trained on a certain corpus to be able given words as inputs (one hot encoding is one way for the input) to represent the word as a vector of a usually high dimensionality of numbers. Does it carry information? Yes, we could say that it carries the information about the words. Similar words have similar vectors. The point is that us as humans we do not define the similarity but the neural network defines the similarity for us based on the corpus that we are providing. Does it carry meaning? No, because this representation does include grammatical or syntactical information and therefore the answer would be that it does not carry any meaning.
