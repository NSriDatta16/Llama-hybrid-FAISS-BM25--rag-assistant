[site]: crossvalidated
[post_id]: 69864
[parent_id]: 
[tags]: 
I am still confused with Gaussian kernel in SVM

From the slides http://www.csie.ntu.edu.tw/~cjlin/talks/kuleuven_svm.pdf , $$\min \frac{1}{2}w^Tw $$ subject to $$y_i(w^T\phi(x_i)+b)\ge 1,i=1,\cdots,n$$ I think most people are very familiar with this equation. I assume $w$ is in the same space of $\phi(x_i)$, in this way, $w^Tw$ always be 1 when uses Gaussian kernel. $w$ is in feature space, here for Gaussian kernel, it is infinite space. But I think $w=\phi(w')$, $w'$ is in the original space. Then $\phi(w')^T\phi(w')=w^Tw=k(w',w')=1$ and $\phi(w')^T\phi(x)$ is always be positive if $w'$ exists.
