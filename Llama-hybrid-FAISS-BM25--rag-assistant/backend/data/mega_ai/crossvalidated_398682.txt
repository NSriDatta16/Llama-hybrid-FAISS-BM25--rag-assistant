[site]: crossvalidated
[post_id]: 398682
[parent_id]: 
[tags]: 
Pooled Covariance Matrix with very different amount of samples per class

I have a dataset with 10 classes, and want to estimate the covariance. It turns out that due to numerical stabilitiy, it is much better to use a pooled covariance matrix. Suppose I have $N$ samples per class. Then $$S_{\mathrm{pooled}} = \frac{1}{10 * N} \sum_{i=1}^{10} \sum_{j=1}^N (x_j - \mathrm{mean}(x_j)) (x_j - \mathrm{mean}(x_j))'$$ I would also like to perform LDA (for dimensionality reduction and later classification) on the dataset, and the computation of the Within-Class Scatter Matrix $S_W$ is almost the same upto the scaling factor. I do have a very unbalanced classes - quite different number of samples per class. For example for class 1, I have only $100$ samples whereas for class 4 I have $5000$ samples! Let $N_1, N_2, ... N_{10}$ denote the amount of samples for each class. According to https://en.wikipedia.org/wiki/Pooled_variance , one computes as $$S_{\mathrm{pooled}} = \frac{1}{N_1 + N_2 + ... N_{10} - 10} \sum_{i=1}^{10} \sum_{j=1}^{N_i} (x_j - \mathrm{mean}(x_j)) (x_j - \mathrm{mean}(x_j))'$$ For my data set this gives not a good estimation of the covariance matrix. What did work was to artifically equalize the amount of samples per class by re-using data, and then estimating the covariance by the first equation. For example for class 1, I artifically increased the number of samples by re-using the 100 samples 50 times to get an amount of 5000 samples for this class, i.e. adding the same data again and again. This seems to remove an apparent bias. It works quite well, but I have no mathematical explanation or intuition why???
