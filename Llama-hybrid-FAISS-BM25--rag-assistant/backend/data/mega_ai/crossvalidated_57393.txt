[site]: crossvalidated
[post_id]: 57393
[parent_id]: 
[tags]: 
Loss Matrix Equivalent with Neural Networks and random Forest

I'm doing classification (0,1) on a dataset for which different types of errors should be weighted differently. IE, false positives would be weighted 10 x more than false negatives. In decision trees, specifically the rpart implementation of CART in R, I can simply pass the function a loss matrix. [0,1] [10,0] which would result in weighting errors differently and build trees based on that. for random Forest, it SHOULD be possible to do exactly the same, since it's still based on the same algorithm. With neural networks, I would think it'd still be possible, but I would have to modify the error/loss function in such a way to account for the difference in errors. I'm hoping someone will lead me in the right direction on how to go about this. Thanks.
