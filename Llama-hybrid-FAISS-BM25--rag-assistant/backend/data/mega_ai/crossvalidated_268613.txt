[site]: crossvalidated
[post_id]: 268613
[parent_id]: 
[tags]: 
Classification (regression) with rolling window for time series-type data

This is rather a conceptual question, than technical. I am interested in performing a rolling (sliding) window analysis, where I aim to predict a label ('0' or '1') of the next value of my time-series. For example, consider the time-series data and the array of labels: (I work with Python and sklearn) ts = array([11, 15, 3, 18, 6, 10, 9, 25, 7, 15]) lab = array([ 0, 0, 0, 1, 1, 0, 0, 1, 0, 1]) What I am doing is trying to learn a function 'F', which maps the input features (extracted from the window from the 'ts' array) to the binary labels 'lab': F(feat(ts)) -> lab . Conceptually, this problem is equivalent to the labeling of windows of size-k conditioned on the next timestamp. F(ts[i:i+3]) -> lab[i+3] Practically: Consider a window of size 3, then we get: F([11,15, 3]) -> y = 1 F([15, 3,18]) -> y = 1 F([ 3,18, 6]) -> y = 0 F([18, 6,10]) -> y = 0 F([ 6,10, 9]) -> y = 1 F([10, 9,25]) -> y = 0 F([ 9,25, 7]) -> y = 1 (the very last value is unused). The real time-series is much longer. QUESTION : For training, testing and cross-validation, may I (pretend and) use my instances as i.i.d? What I mean is: can I randomly divide the instances to training, validation and test sets? Of course they are not i.i.d., but when I naively tried to process my data and to learn a classifier (simple logistic regression), it surprisingly worked very well and I got quite reasonable results for the classification metrics. EDIT I'm reading the paper A Note on the Validity of Cross-Validation for Evaluating Time Series Prediction of and authors clearly state, that: "....and CV can and should be used without modification, as in the independent case.."
