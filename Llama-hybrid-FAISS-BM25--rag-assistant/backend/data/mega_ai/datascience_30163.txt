[site]: datascience
[post_id]: 30163
[parent_id]: 30160
[tags]: 
Applying machine learning without labels is called unsupervised learning . These methods are definitely harder to train and evaluate as you have pointed out than supervised learning. I will warn that 200 features is quite a lot, the more features you have the higher the dimensionality and thus the higher the complexity. Unsupervised learning techniques are not well suited for highly complex data. In general, unsupervised learning assumes that your data is separated into $k$ separate classes. Each with a distinct distribution. The model you will choose will try to estimate the distribution parameters which describes each of the $k$ classes. What you can do to measure a fitness for your model? You can try to find an adequate balance between the similarity of instances within clusters and dissimilarity between instances in different clusters. The distance between the points within a cluster (intra-cluster distance) should be minimized. Whereas the distance between instances in different clusters should be maximized.
