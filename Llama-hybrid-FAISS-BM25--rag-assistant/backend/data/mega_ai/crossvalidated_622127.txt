[site]: crossvalidated
[post_id]: 622127
[parent_id]: 
[tags]: 
Should I fit(X_train, y_train) or fit(X,y) when using pipeline with gridsearchCV and cross_validate? (python)

I'm trying to make a pipeline that will do the following things: preprocessing, train one model (e.g. random forest), use GridSearchCV to tune hyperparameters (using nested cross validation to prevent data leak), and use cross_val_score to assess the performance of the model. When I look online I'm finding that some people do fit(X,y) whereas other people do fit(X_train, y_train). I've included an example of each below (I appreciate that the first example has more preprocessing but I don't think that makes a difference here). I'm confused on this. Why does one version use all the data whilst the other version only uses the training set? I presumed you always used the training set. Does the decision just hinge on whether youre using cross_validate (or cross_val_score) or not? As in, if I do cross_validate (or cross_val_score) at the end I should use fit(X, y) and if I don't use cross_validate I should use fit(X_train, y_train)? (I'm looking to use the 1st code example, so if there's anything else obviously wrong with it please do let me know) Example that uses fit(X,y): #Organise data X = df.drop('target', axis= 1) y = df['target'] continuous_var = ['X1', 'X2', 'X3'] cat_var = ['X4', 'X5', 'X6'] #Preprocessing pipe con= Pipeline([('scale', MinMaxScaler()),('missing', KNNImputer())]) cat = Pipeline([('encoding', OrdinalEncoder())]) pipe = ColumnTransformer([("cont_features", con, continuous_var), ("categorical_features", cat, cat_var)]) pipe_rf= Pipeline([('cleaning', pipe), ('clf', RandomForestClassifier())]) param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] grid_params_rf = [{'clf__criterion': ['gini', 'entropy'], 'clf__min_samples_leaf': param_range, 'clf__max_depth': param_range, 'clf__min_samples_split': param_range[1:]}] gs_rf = GridSearchCV(estimator=pipe_rf, param_grid=grid_params_rf, scoring='accuracy', cv=10, n_jobs=jobs) gs_rf.fit(X, y) ############# Example with fit(X_train, y_train): #Organising data X = df.drop('target', axis= 1) y = df['target'] X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0) pipe_rf = Pipeline([('scl', StandardScaler()), ('clf', RandomForestClassifier(random_state=42))]) param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] grid_params_rf = [{'clf__criterion': ['gini', 'entropy'], 'clf__min_samples_leaf': param_range, 'clf__max_depth': param_range, 'clf__min_samples_split': param_range[1:]}] gs_rf = GridSearchCV(estimator=pipe_rf, param_grid=grid_params_rf, scoring='accuracy', cv=10, n_jobs=jobs) gs_rf.fit(X_train, y_train) ############ ```
