[site]: crossvalidated
[post_id]: 406645
[parent_id]: 406590
[tags]: 
Hi: What you said about the normal and the brownian motion is correct. So, for the case of 100 points and 1 simulation you can do the following steps. A) generate 100 normal random variables N(0,s) with s = 0.01. Then label them $X_{1}, X_{2}, \ldots X_{100}$ The key thing to understand here is that, at any time say $t = k$ , the sum of any of these $k$ normals is N(0, k \times .01). More importantly, this sum is a discrete approximation to the true brownian motion process $W(t = .01 \times k)$ where time is continuous. This is the most important part to understand. The proof of this is probably in most advanced stochastic processes texts but I think your professor wants you to accept this as given, atleast for now. So, when you simulate those normal random variables, then, if you add them up, you are simulating an brownian motion approximately, since, by definition $W(.01) \sim X_{1}$ , $W(.02) \sim X_{1} + X_{2}$ $W(.03) \sim X_{1} + X_{2} + X_{3}$ $W(.01 \times k ) \sim X_{1} + X_{2} + \ldots X_{k}$ and so on and so forth. So, the values of $W(.01 \times k)$ for any $k = 1 \ldots 100 $ gives you the location of your simulated ( approximate ) brownian process $W(.01 \times k )$ at time .01 * k. So, what you have done up to now is generate an approximation to the true brownian motion process, W(t), one time. Any value of $W(.01 *k)$ tells you where the approximated process, $W(t)$ is ( the value of the process if you want to think of it that way. Personally, I think location gives you a better idea of what's going on ) at time $t = .01 \times k$ . So, you need to keep in mind that what was generated with the 100 normals is only an approximation to the true $W(t)$ process where $t$ is continuous. B) Take your $W(.01 * k)$ process and check if any of the locations ( values, if you will ) of the process are less than -3. C) If any of them are, then , for this first simulation, the event min over all $k$ $W(.01 * k) happened so set $success_1 = 1$ for. Otherwise, set $success_1 = 0$ . END OF STEPS. Next, Do STEPS A-C, 10000 times ( 10000 simulations ) and count up the $success_i$ from $i = 1 \ldots 10,000$ and call the sum, sum_success. Then, the estimate of the probability of the event min over $k$ W(.01 * k) $success_i$ was 1 so the estimate of the probability is sum_success divided by 10,000. For the second part, if you split time into 10,000 points rather than 100 points ( for any one simulation ), the approximation to the true brownian motion process $W(t)$ becomes better and better because you are making the time step (in the 10,000 case it's .0001 ) smaller and smaller. What using 10,000 points rather than 100 points does to the probability estimate is an exercise for the reader !!!!!! Your estimate in the 10,000 split case compared to the 100 split case should tell you what happens. James Hamilton's "Time Series Analysis" has a really nice section on the approximation to brownian motion through the use of normals. It does a way better job than I've done here so I highly recommend it. There are probably many other nice explanations in other places but that's the one I always go back to. .
