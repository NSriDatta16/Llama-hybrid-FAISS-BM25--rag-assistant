[site]: crossvalidated
[post_id]: 631532
[parent_id]: 631528
[tags]: 
BEWARE OVERFITTING! The danger of using an in-sample measure of performance is that it is quite easy to overfit to coincidences in the sample instead of to the real trends. That is, you can have strong measures of performance on the in-sample data, but when you go to use your model to make new predictions, those coincidences are not present, and your performance is poor. Out-of-sample testing mimics the use case of making truly new predictions when you can catch if your model can generalize beyond the training data. You might be able to drive your in-sample McFadden $R^2$ close to a perfect $1$ . However, you need to do something to account for model complexity. Out-of-sample testing is one option. It has its drawbacks (you withhold valuable training data from model development, for instance, which could be quite damaging to a studies like yours that have limited data) yet is highly common. Example (This is a modification of a post of mine on Data Science.) library(MLmetrics) set.seed(2023) # Function to calculate McFadden's R^2 the way I believe it correct # See: https://stats.stackexchange.com/q/590199/247274 # r2_mcfadden In this example, the in-sample McFadden $R^2$ is (within rounding) equal to a perfect $1$ every time. However, every out-of-sample McFadden $R^2$ is less than zero, indicating that the predictions would have been better (in terms of log loss) by predicting the in-sample mean every time, which I claim is a reasonable baseline model with "must-beat" performance. (It took me $\sim$$30$ minutes to run that block of code, which is longer than I like for an example on here, but you can lower R to get a quicker run time.)
