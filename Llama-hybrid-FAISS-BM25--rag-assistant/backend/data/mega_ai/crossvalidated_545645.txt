[site]: crossvalidated
[post_id]: 545645
[parent_id]: 
[tags]: 
Regarding Gibbs sampling and HMC in fitting Bayesian model, their differences and advantages

I have a question regarding the two MCMC algorithms, Gibbs sampling and Hamiltonian Monte Carlo (HMC) for performing the Bayesian analysis. If using Gibbs sampling, my understanding is that we need to derive the exact formulas for different conditional distributions corresponding to interested latent variables. The Gibbs sampling scheme has to rely on these formulas. If we are handling complex models in practice, deriving the exact formula might be infeasible. If using HMC, we do not need to derive these exact formulas and rely on gradient information, (like probabilistic programming) to fit the model. This makes modeling a complex Bayesian model feasible in practice. Is this understanding correct?
