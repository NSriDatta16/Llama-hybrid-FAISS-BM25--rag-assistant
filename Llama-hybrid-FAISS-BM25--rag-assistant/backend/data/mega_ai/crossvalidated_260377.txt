[site]: crossvalidated
[post_id]: 260377
[parent_id]: 258374
[tags]: 
Since I left a comment here, I've not had the time to come back and continue with an answer. I took a sick day today, so I've finally had the time to provide some additional comments to this question. Albeit Denis' answer is correct, I feel it is lacking in clear corrections/critique of the simulation the OP began his question with. I believe the objective for OP was to illustrate how sampling from a non-Normal distributed sample affects the t-statistic, and presumably Type I errors and power of the test. Thus, the purpose for this second answer is simply to add to the first to provide a more thorough answer. So first, some pointed out stating that the reason OP did not see a difference between histograms was because of the sample size. As stated in my comment, I disagree. If for 1000 iterations you calculate the mean of a sample of 5 from a $U(0,1)$, you will still see a normal-ish histogram. N=5 rept=1e3 cal_t_stats2 So I would disagree that the issue is sample size. What the example shows is that the distribution of the t-test centers around zero. Next, below is a modified example taken from Veranzi ( https://cran.r-project.org/doc/contrib/Verzani-SimpleR.pdf , page 51). The example works to illustrate how $\frac{\bar{X} - \mu}{\sigma/ \sqrt{n}} \sim N(0, 1)$ for skewed data. In the example, $\sigma$ is estimated from the data, as opposed to being known apriori. Example: CLT with exponential data Let’s do one more example. Suppose we start with a skewed distribution, the central limit theorem says that the average will eventually look normal. That is, it is approximately normal for large n. What does “eventually” mean? What does “large” mean? We can get an idea through simulation. f = function(n=100,mu=10) (mean(rexp(n,1/mu))-mu)/(mu/sqrt(n)) iters = c(5, 10, 20, 100) ## sample sizes par(mfrow = c(2,2), mar = c(2,2,2,2)) for(i in iters){ s First, data is being generated from a an exponential distribution with rate 0.1, at samples of 5, 10, 20, 100 and 1000. The first four graphs show how the scaled means progress to looking more normal-ish as sample size is increased for each scaled mean (or t-stat) calculation. Finally, at 1000 samples, the histogram appears settled. Beyond this, I think the next issue is power of a t-test if the sampled data is non-normal. A More Realistic Look at the Robustness and Type II Error Properties of the $t$ test to Departures From Population Normality TL;DR The authors say that data that come from a nice looking normal-ish distribution is pretty rare (unicorn), and is quite evident in education research data. So the authors run some Monte Carlo simulations on some 8 "real world" data sets whose distributions look funky and not very bell-curve-shaped. Their results show that the two sample t-test was fairly robust (usually, but not always) against Type I errors. Also, the t-test did fine (usually, but not always) against Type II errors. The authors comment on when the two sample t-test does well (read the abstract). Robustness? I've not finished reading this paper, but this brings some useful commentary when discussing the topic of "robustness" of a statistic. It was also cited in the first article. That said, I hope this provides some useful comments to the simulation, or at least a good reference or two.
