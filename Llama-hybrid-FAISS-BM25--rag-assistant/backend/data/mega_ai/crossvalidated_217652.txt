[site]: crossvalidated
[post_id]: 217652
[parent_id]: 
[tags]: 
How to understand randomness in the training data from bias-variance tradeoff?

The bias-variance decomposition of MSE is $MSE = (\mathbb{E}(\hat{\theta})-\theta)^2 + Var[\hat{\theta}]$. $\mathbb{E}(\hat{\theta})$ can be explained as the average from the randomness in the training data. In a real-world scenario, we are trying to build models based on a particular dataset, in this sense, what does it mean by "the randomness in the training data"? Is it relevant to sampling from the data? Edit : Suppose given a dataset D, it is easy to get an estimate of the parameter $\hat\theta$. However, $\mathbb{E}(\hat{\theta})$ implies there are multiple estimations of $\hat\theta$. My question is, why there are multiple estimations for the same dataset?
