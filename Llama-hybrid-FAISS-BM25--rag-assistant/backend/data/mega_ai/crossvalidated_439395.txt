[site]: crossvalidated
[post_id]: 439395
[parent_id]: 372272
[tags]: 
This is an example of where a Bayesian estimator is examined with respect to its frequentist properties ---i.e., how it behaves over repeated trials conditional on the parameter value . Although Bayesian estimators are derived using a prior distribution over the possible parameter values, ultimately, the estimators are functions of the data (and possibly some hyperparameters) and so it is possible to examine their behaviour conditional on a parameter value . Bayesians also believe that there is a true parameter value, and they have a prior belief about what it is. Nevertheless, in the history of Bayesian statistics, a natural question was whether Bayesian estimators have good freqentist properties --- i.e., how do they perform over repeated trials if we condition on a stipulated parameter value . Your confusion on this issue appears to be coming from equivocation of two separate issues. You are correct that the Bayesian estimator is formed using a prior distribution over the parameter. This is a reflection of the fact that the true value is unknown, and the Bayesian paradigm applies a prior distribution to describe one's prior belief about the true value. However, the assessment of the frequentist properties of a Bayesian estimator is a separate issue from the formation of the estimator; it is done by conditioning on a stipulated value of the parameter, and then asking how the estimator performed over repeated trials relative to this true value. In particular, when examining consistency, efficiency and unbiasedness, we condition on the value of the parameter --- this is also the case even if we are assessing the properties of a Bayesian estimator. The good news here is that Bayesian estimators have good frequentist properties, so long as the model (i.e., likelihood function) is specified correctly. In particular, Bayesian estimators can be shown to be "admissible", which means that they are not "dominated" by any other estimator in terms of their efficiency. Since Bayesian estimators have been proven to have good frequentist properties, it is common for Bayesians to feel that they can safely forget about this issue, and work entirely within the Bayesian paradigm. That is quite reasonable, but it is also handy to be able to pop back into the classical paradigm and understand the frequentist assessment of these estimators. Asymptotic efficiency of a Bayesian estimator: Under broad regularity conditions, if we have a Bayesian estimator $\hat{\theta}_n$ of an unknown parameter $\theta \in \Theta$ that is formed by minimising the posterior MSE, it is possible to show that there is asymptotic convergence: $$\sqrt{n} (\hat{\theta}_n-\theta) \overset{\rightarrow}{\sim} \text{N} \Big( 0, \frac{1}{I(\theta)} \Big) \quad \quad \quad \text{for all } \theta \in \Theta,$$ where $I$ is the Fisher information. This convergence result holds conditional on each $\theta \in \Theta$ , so it is a frequentist result, rather than a marginal result aggregated over a prior. Since this variance in the asymptotic distribution is the Cram√©r-Rao lower bound, that is sufficient to establish asymptotic efficiency of the estimator. There are of course other estimators that are also asymptotically efficient, but it is nice to know that this Bayesian estimator has that property.
