[site]: stackoverflow
[post_id]: 515568
[parent_id]: 
[tags]: 
Activation function when training a single layer perceptron

When training a multi-layer neural network, using a sigmoidal activation function is necessary for it to learn efficiently. Is there any advantage to using a sigmoidal activation function when training a single layer perceptron, or is a simple step (heaviside) function sufficient (or even preferable)? I'm slowly getting my head around neural networks but any help with this would be appreciated.
