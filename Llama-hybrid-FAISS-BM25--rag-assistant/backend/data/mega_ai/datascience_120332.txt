[site]: datascience
[post_id]: 120332
[parent_id]: 49103
[tags]: 
I don't know which method will be best speaking generally. Still, I like to cross-validate my model's performance using KerasRegressor wrapper from the SciKeras module with scikit-learn's RandomizedSearchedCV ( +KFold ). I've learned this method from Machine Learning Mastery: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/ Generally, it is better to play around with possibilities and resolve problems through experimentation than deductively. Deep learning is math, but due to the complexity and raw computation power at hand instead of solving problems theoretically before designing an experiment, You can just go straight to experimentation. Below is my code, used for a BullionPredict project (predicting gold daily gold close price data): You create a function that will generate models for KerasRegressor: def create_LSTM_model(learning_rate=0.001, units=32, dropout=0.2, activation='tanh', recurrent_activation='sigmoid'): model = Sequential() model.add(InputLayer( input_shape=(INPUT_SHAPE,))) model.add(Lambda(lambda x: tf.expand_dims(x, axis=1))) model.add(LSTM( units=units, activation=activation, recurrent_activation=recurrent_activation, dropout=dropout, )) model.add(Dense(OUTPUT_SHAPE, activation='linear')) model.compile( optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=tf.keras.losses.MeanAbsoluteError(), metrics=['mse', 'mape']) return model You should include hyperparameters You want to tune as function parameters. You create KerasRegressor object. model_5 = KerasRegressor(build_fn=create_LSTM_model, verbose=0, learning_rate=0.001, activation='tanh', units=16, recurrent_activation='sigmoid', dropout=0.2) You define parameters that include not only model building/compiling hyperparameters, but also can include training hyperparameters, like nr of epochs or the batch size. params = {'activation': ["relu", "tanh", 'elu', 'sigmoid'], 'recurrent_activation': ["relu", "tanh", 'elu', 'sigmoid'], 'dropout': [0.2, 0.4, 0.6, 0.8], 'batch_size': [16, 32, 64], 'units': [16, 32, 64, 128], 'epochs': [50, 100], 'learning_rate': [0.01, 0.001, 0.0001]} You create RandomizeSearchCV object and fit it. random_search_5 = RandomizedSearchCV(model_5, param_distributions = params, cv = KFold(3), n_iter=30, n_jobs=-1, scoring='neg_mean_squared_error', return_train_score=True, error_score='raise') random_search_results_5 = random_search_5.fit(train_price_feats, train_price_labels) Then You can use Your random search dictionary to perform some Exploratory Data Analysis and draw conclusions Yourself. If You have more time and or computational power You can also use GridSearchCV instead of RandozmizedSearchCV. Cheers!
