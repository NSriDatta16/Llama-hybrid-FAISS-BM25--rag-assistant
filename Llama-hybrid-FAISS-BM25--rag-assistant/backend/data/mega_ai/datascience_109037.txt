[site]: datascience
[post_id]: 109037
[parent_id]: 
[tags]: 
Determine optimal number of layers for a neural network based on the dataset

I have a Neural network architecture where there are N parallel-connected layers (min. 3). Based on the dataset and classes it has, the optimal number of layers differ. Eg. for dataset1 optimal number is somewhere between 6 and 9 whereas, for dataset2 optimal number is 4 or 5. By training models with different numbers and looking at how accuracy is growing, we can manually come up with an optimal number. The task here is to get optimal numbers dynamically. By reading different articles and technical papers, one way is to use meta-data of the trained models, i.e. accuracy, time-per-epoch, loss etc. What I have observed is, when we increase the number of layers, accuracy tends to increase and then it plateaus. There is not much of an improvement as we keep adding more layers. And, unlike accuracy, time-per-epoch keeps on increasing. Here, a model with 7 layers had an accuracy of 86% and after that even though we added 14 more layers, accuracy increased by less than 5%. (More complex models took more epochs for training) Using this observation, what I plan is to compare the accuracy and time-per-epoch of the current model with the previous model and see if there is a reasonable increase in accuracy. After a certain number of layers, there won't be much increase in accuracy but there will be an increase in time. This little increase in accuracy is not justified by an increase in time. I'm looking to get some number/score using accuracy and time-per-epoch for each model. And I assume that the score will increase as we increase the number of layers and after some time it will decrease and we can say that model with the highest score is optimal for the given datasets. The above image is what I assume would be the result. Here scores are on the y-axis and the number of layers used is on the x-axis. Then by looking at it, we can conclude that model with 7 layers has the highest score and 7 will be optimal number for the given dataset. It is not mandatory to just use accuracy and time-per-epoch, we can use other available meta-data like a loss. So I'm looking for an algorithm or a formula or something using which I can get this score. This was the simplest method I could find. Other methods involved using meta-learning and neuroevolution which might help but I'm not familiar with them. Any other solutions are also appreciated.
