[site]: datascience
[post_id]: 104940
[parent_id]: 
[tags]: 
Difference between regret and pseudo-regret definitions in multi-armed bandits

I posted this question Cross Validated , but didn't get any answer. So I am posting it here too, as the question is very relevant to machine learning I am following the book Bandit Algorithms . In page 48, they introduces regret after $n$ rounds as $$ \mathbf{R} = n\mu^\star - \mathbb{E}\Bigg[\sum_{t=1}^n \mathbf{X}_t\Bigg] \tag{1} $$ In page 55, they also define pseudo-regret as $$ \bar{\mathbf{R}} = n\mu^\star - \sum_{t=1}^n \mu_{A_t} \tag{2} $$ In the paper Regret Analysis of Stochastic and ... , authors introduces pseudo-regret as $$ \bar{\mathbf{R}} = n\mu^\star - \mathbb{E}\Bigg[\sum_{t=1}^n \mu_{A_t}\Bigg] \tag{3} $$ Can anyone tell me the differences in the three definitions ? In the first definition, due to the linearity of the expectation, we can write it exactly like (2). Hence (1) and (2) should be referring to the same quantity ? Since $\mu_{A_t}$ is not a random variable, $\mathbb{E}[\mu_{A_t}] = \mu_{A_t}$ , and due to the linearity of expectation, (2) and (3) should be referring to the same quantity. Anyone can help me out with these definitions ?
