[site]: datascience
[post_id]: 111191
[parent_id]: 
[tags]: 
AttributeError: 'Functional' object has no attribute 'predict_classes''

I am trying to use run a GoogLeNet code using FERET datasets. When I run the code, I get the following error message: Traceback (most recent call last): File "C:\Users\JoshG\PycharmProjects\GoogLeNet\GoogLeNet5.py", line 221, in y_pred = (model.predict_classes(testX)) AttributeError: 'Functional' object has no attribute 'predict_classes'' Can anyone tell me what I am doing wrong? I am new to python, so please patient with me understanding. Below is the full code: # Python: 3.9 # keras: 2.2.4 for GoogLeNet on CIFAR-10 # Tensorflow :1.13.0 # cuda toolkit: 10.0 # cuDNN: 7.4.2 # scikit-learn 0.20.2 # Imutils # NumPy # set the matplotlib backend so figures can be saved in the background import matplotlib from matplotlib import pyplot import matplotlib.pyplot as plt # import packages from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, \ f1_score from sklearn.preprocessing import LabelBinarizer from pipeline.nn.conv import MiniGoogLeNet from pipeline.callbacks import TrainingMonitor from keras.preprocessing.image import ImageDataGenerator from keras.callbacks import LearningRateScheduler from keras.optimizers import SGD from keras.utils.np_utils import to_categorical import tensorflow as tf from keras.datasets import cifar10 from image_dataset_loader import load import numpy as np import argparse from sklearn.model_selection import train_test_split import os from sklearn.utils.multiclass import unique_labels # define the total number of epochs to train for along with initial learning rate NUM_EPOCHS = 50 INIT_LR = 5e-3 def poly_decay(epoch): # initialize the maximum number of epochs, base learning rate, # and power of the polynomial maxEpochs = NUM_EPOCHS baseLR = INIT_LR power = 1.0 # compute the new learning rate based on polynomial decay alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power # return the new learning rate return alpha # construct the argument parser ap = argparse.ArgumentParser() ap.add_argument("-m", "--model", required=True, help="path to output model") ap.add_argument("-o", "--output", required=True, help="path to output directory (logs, plots, etc.)") args = vars(ap.parse_args()) # load the training and testing data, converting the image from integers to print("[INFO] loading FERET Dataset...") # Josh Plan 1 path = "C:/Users/JoshG/PycharmProjects/Local-Binary-Patterns/Images_FERET/Plan1-DL/Images_AlexNet" imgPath = "C:/Users/JoshG/PycharmProjects/Local-Binary-Patterns/Images_FERET/Plan1-DL/Images_AlexNet/Josh_Training_ADT_8I_24S_227" testPath = "C:/Users/JoshG/PycharmProjects/Local-Binary-Patterns/Images_FERET/Plan1-DL/Images_AlexNet/Josh_Testing_ADT_24S_227" # Keras library for CIFAR dataset # from keras.datasets import cifar10 (trainX, trainY), (testX, testY) = load(path, [imgPath, testPath]) # ((trainX, trainY), (testX, testY)) = cifar10.load_data() # Dimension of the datasets #(trainX, trainY), (testX, testY) = load(path, [imgPath, testPath]) print('Train: X = %s, Y= %s' % (trainX.shape, trainY.shape)) print('Test: X = %s, y= %s' % (testX.shape, testY.shape)) # plot first few images for i in range(9): # define subplot pyplot.subplot(330 + 1 + i) # plot raw pixel datapython.exe googlenet_cifar10.py --model output/minigooglenet_cifar10.hdf5 --output output pyplot.imshow(trainX[i]) # show the figure pyplot.show() # Print out first test to make sure we can see images trainX = trainX.astype("float") testX = testX.astype("float") # apply mean subtraction to the data mean = np.mean(trainX, axis=0) trainX -= mean testX -= mean # Train-validation-test split trainX, x_val, trainY, y_val = train_test_split(trainX, trainY, test_size=.12) # Since we have 10 classes we should expect the shape[1] of trainY,y_val and testY to change from 1 to 10 trainY = to_categorical(trainY) y_val = to_categorical(y_val) testY = to_categorical(testY) # Verifying the dimension after one hot encoding print((trainX.shape, trainY.shape)) print((x_val.shape, y_val.shape)) print((testX.shape, testY.shape)) # Image Data Augmentation train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1) val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1) test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1) # Fitting the augmentation defined above to the data train_generator.fit(trainX) val_generator.fit(x_val) test_generator.fit(testX) # construct the image generator for data augmentation aug = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True, fill_mode="nearest") # construct the set of callbacks figPath = os.path.sep.join([args["output"], "{}.png".format(os.getpid())]) jsonPath = os.path.sep.join([args["output"], "{}.json".format(os.getpid())]) callbacks = [TrainingMonitor(figPath, jsonPath=jsonPath), LearningRateScheduler(poly_decay)] # initialize the optimizer and model print("[INFO] compiling model...") opt = SGD(lr=INIT_LR, momentum=0.9) model = MiniGoogLeNet.build(width=227, height=227, depth=3, classes=24) model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"]) model.evaluate(testX, testY) # train the network print("[INFO] training network...") model.fit_generator(aug.flow(trainX, trainY, batch_size=8), validation_data=(testX, testY), steps_per_epoch=len(trainX) // 64, epochs=NUM_EPOCHS, callbacks=callbacks, verbose=1) # Plotting the training and validation loss f, ax = plt.subplots(1, 1) # Creates 2 subplots under 1 column # Assigning the first subplot to graph training loss and validation loss ax.plot(model.history.history['loss'], color='b', label='Training Loss') ax.plot(model.history.history['val_loss'], color='r', label='Validation Loss') plt.legend() plt.show() f, ax = plt.subplots(1, 1) # Creates 2 subplots under 1 column # Plotting the training accuracy and validation accuracy ax.plot(model.history.history['accuracy'], color='b', label='Training Accuracy') ax.plot(model.history.history['val_accuracy'], color='r', label='Validation Accuracy') plt.legend() plt.show() # Defining function for confusion matrix plot def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues): if not title: if normalize: title = 'Normalized confusion matrix' else: title = 'Confusion matrix, without normalization' # Compute confusion matrix cm = confusion_matrix(y_true, y_pred) if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] print("Normalized confusion matrix") else: print('Confusion matrix, without normalization') # Print Confusion matrix fig, ax = plt.subplots(figsize=(4, 4)) im = ax.imshow(cm, interpolation='nearest', cmap=cmap) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=classes, yticklabels=classes, title=title, ylabel='True label', xlabel='Predicted label') # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor") # Loop over data dimensions and create text annotations. fmt = '.2f' if normalize else 'd' thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha="center", color="white" if cm[i, j] > thresh else "black") plt.tight_layout() return ax # Making prediction y_pred = (model.predict_classes(testX)) y_true = np.argmax(testY, axis=1) print(y_pred) print(y_pred.shape) # Plotting the confusion matrix confusion_mtx = confusion_matrix(y_true, y_pred) CLASS_NAMES = [f.name for f in os.scandir(imgPath) if f.is_dir()] class_names = CLASS_NAMES print(class_names) print("ypred\n", y_pred) print("ytrue", y_true) # Plotting non-normalized confusion matrix plot_confusion_matrix(y_true, y_pred, classes=class_names, title='Confusion matrix, without normalization') plt.show() # Plotting normalized confusion matrix # plot_confusion_matrix(y_true, y_pred, classes=class_names, normalize=True, title='Normalized confusion matrix') # plt.show() # Classification Metrics acc_score = accuracy_score(y_true, y_pred) print('\n\n\t\t Accuracy Score: ', str(round((100 * acc_score), 2)), '%') prec_score = precision_score(y_true, y_pred, average='macro') print(' Precision Score Macro: ', str(round((100 * prec_score), 2)), '%') prec_score = precision_score(y_true, y_pred, average='micro') print(' Precision Score Micro: ', str(round((100 * prec_score), 2)), '%') prec_score = precision_score(y_true, y_pred, average='weighted') print('Precision Score Weighted: ', str(round((100 * prec_score), 2)), '%') rec_score = recall_score(y_true, y_pred, average='macro') print('\t\t\tRecall Macro: ', str(round((100 * rec_score), 2)), '%') rec_score = recall_score(y_true, y_pred, average='micro') print('\t\t\tRecall Micro: ', str(round((100 * rec_score), 2)), '%') rec_score = recall_score(y_true, y_pred, average='weighted') print('\t\t Recall Weighted: ', str(round((100 * rec_score), 2)), '%') f_score = f1_score(y_true, y_pred, average='macro') print('\t\t F1 Score Macro: ', str(round((100 * f_score), 2)), '%') f_score = f1_score(y_true, y_pred, average='micro') print('\t\t F1 Score Micro: ', str(round((100 * f_score), 2)), '%') f_score = f1_score(y_true, y_pred, average='weighted') print('\t F1 Score Weighted: ', str(round((100 * f_score), 2)), '%')
