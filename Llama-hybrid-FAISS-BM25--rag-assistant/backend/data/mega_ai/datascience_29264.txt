[site]: datascience
[post_id]: 29264
[parent_id]: 
[tags]: 
Text classification with neural network number of input neurons

I am classifying documents I have around 4000 of them that I am trying to categorise into 5 categories. I am using a bag of words model which equates to about 18,000 unique words (features) and therefore I have an input layer of a neural network with 18,0000 inputs which doesn't seem right. It is taking a huge amount of memory to try and train this network and so much time it will never converge! Is there a way of reducing the number of input neurons seeing as a large portion of this data will be nulls?
