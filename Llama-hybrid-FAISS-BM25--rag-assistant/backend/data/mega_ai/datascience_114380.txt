[site]: datascience
[post_id]: 114380
[parent_id]: 
[tags]: 
How to optimize transposed convolution?

I have implemented an encoder-decoder architecture-based neural network with Neural Network API(NNAPI) Android Ndk. There are 5 encoders and 5 decoders. The first encoder's input dimension is -> 1x160084 and the last encoder's output dimensions are 1x624. It takes 6 seconds to finish. Every encoder contains two convolutions. The first Decoder's input dimension -> 1x624 and the last decoder's output dimensions are 1X160084. It takes 26 seconds to finish. Every decoder has a convolution and a transposed convolution. The execution time is much slower in the decoder. But both work on the roughly same size of data. Why is there such a difference? I need to decrease the execution time for the decoder. I have found that transposed convolution is taking maximum time. For the first transpose convolution input dimension is (1x624x1024) Output dimension is (1x2500x512),kernel size is (1x8x1024). Stride is 4. It is taking almost 5 seconds for this transpose convolution operation. If we used a naive approach for transposed convolution it would take -> 1024 * 624 * 8 * 512 * 2 = 5234491392 operations. So it would be executed in 52s(if 1e8 operations are executed in 1 s). So there might be some optimization NNAPI implementation for transposed convolution. Is there any way to see the implementation of NNAPI for transposed convolution and how to further improve it?
