[site]: crossvalidated
[post_id]: 242595
[parent_id]: 
[tags]: 
Is the Gaussian Kernel still a valid Kernel when taking the negative of the inner function?

In support vector machines (SVMs) and other Kernel based methods, like Gaussian processes, the Kernel replaces the inner product of two feature vectors $k(x_n,x_m)=x_n^Tx_m$. The Gaussian kernel $$k(x_n,x_m) = \exp(- \frac{\theta}{2} \lVert x_n-x_m\rVert^2)$$ is a valid kernel function when $\theta \ge 0$. $\theta$ then plays the role of the inverse variance (precision). My question is, is this function still a valid kernel function for SVMs and Gaussian processes when $\theta
