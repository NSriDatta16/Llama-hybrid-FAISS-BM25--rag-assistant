[site]: crossvalidated
[post_id]: 361254
[parent_id]: 
[tags]: 
Separating Hyperplanes equation for SVM

I am currently reading on Separating Hyperplanes in order to understand Support Vector Machines better. Assuming one has points of two classes in two dimensions, the resulting hyperplane equation would be $$\{x : f(x) = β_0 + β_1x_1 + β_2x_2 = 0\}$$ which looks a lot like the classical regression equation. However, where does the zero come from in this case?
