[site]: crossvalidated
[post_id]: 501034
[parent_id]: 
[tags]: 
In reinforcement learning, what is the correct definition of "value function"?

This is a follow up to: In reinforcement learning, what is the correct mathematical definition of the discounted reward? I discovered that there seems to exist an extremely large and disparate definition of the value function in reinforcement learning. Here is a brief sample platter: Andrew Ng Notes, page 130 The value function is, $$V^\pi(s) = \mathbb{E}[R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) ... | s_0 = s, \pi], \gamma \in [0,1)$$ This is also the same one as given on Wikipedia: https://en.wikipedia.org/wiki/Reinforcement_learning David Silver Notes The value function is, $$V(s) = \mathbb{E}[G_t| S_t = s]$$ where $G_t = R_{t+1} + \gamma R_{t+2} + \ldots, \gamma \in [0, 1]$ Note that this definition loses the conditioning on $\pi$ and is also not starting from $s_0$ . Note that this definition agrees with Richard Sutton (except that Sutton does condition on $\pi$ ) and Szespevari Van Der Schaar notes, pg 8 The value function is, $$V^\pi(s) = R(s, \pi(s)) + \mathbb{E}[\sum_{t=1}^\infty \gamma^t R(s_t, \pi(s_t))]$$ This is yet another definition that is different from the above ones. Zico Kolter Notes, pg 12 The value function is, $$V^\pi(s) = \mathbb{E}[R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) ... | s_0 = s, s_{t+1}, a_t = \pi(s_t)], \gamma \in [0,1)$$ This definition is similar to Andrew Ng's one, but is conditioning on a lot more things than Andrew Ng's definition. This is different from David Silver, Richard Sutton and Var Der Schaar. Notes from the University of Toronto, p. 15 $$V^\pi(s_t) = \mathbb{E}[R_t + \gamma R_{t+1} + \gamma^2 R_{t+2} + \ldots], \gamma \in [0,1)$$ This definition is different than all of the above given the lack of conditioning, but also it takes $R_t$ (the current reward) as part of the expectation, whereas say David Silver one starts from $R_{t+1}$ . Which one is correct and why is there such a seemingly large amount of definitions? Again my concern is that, different definitions translate into different objectives of the problem, so people are solving different problems and calling all of them reinforcement learning.
