[site]: datascience
[post_id]: 109070
[parent_id]: 
[tags]: 
Regression tree cross validation confusing results

Setup I have implemented regression trees in go: full repository Using the full dataset and cost-complexity pruning , I get the following alphas and corresponding average residual (again, against the full dataset): alpha 0, avg residual 14.134395421607389 alpha 0.12883399209486168, avg residual 14.148010046113317 alpha 0.1653326745718049, avg residual 14.185322598514801 alpha 0.16639262187088283, avg residual 14.294436412237312 . . . alpha 621.0306084614934, avg residual 36.3987567628702 alpha 739.3793217781949, avg residual 43.51964252487374 alpha 837.3864710344569, avg residual 61.267903297185946 alpha 1026.5185269754365, avg residual 84.4195561561656 I believe this is correct because smaller alphas penalize larger trees less, so smaller alphas should also have lower average residuals. Since these are results from the training dataset, we run cross validation and get the following best alpha/residual for each fold (typical results): fold 0: alpha 0, error: 911.9933467781559 fold 1: alpha 15.414289473684207, error: 599.9848234221355 fold 2: alpha 7.063954870729459, error: 1168.1684906780179 fold 3: alpha 0.29686925647451967, error: 2082.105952653071 fold 4: alpha 15.08986257309941, error: 2491.851239853936 fold 5: alpha 1.2758108552631582, error: 1543.555675071225 fold 6: alpha 651.0241925560358, error: 2373.5789896637143 fold 7: alpha 2.3170317286271227, error: 1363.5892092966592 fold 8: alpha 1.7122904483430803, error: 1209.2366845834206 fold 9: alpha 59.18484461152882, error: 1927.6639759480731 Running cross-validation several times returns average alphas that don't seem to be consistent. Question Could it be possible that cross-validation returns such different results for each fold? I would expect that each fold returns similar results, but it also seems like decision trees are particularly volatile during construction, i.e. a small change in the dataset could result in a vastly different tree.
