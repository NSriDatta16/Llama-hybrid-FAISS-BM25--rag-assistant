[site]: crossvalidated
[post_id]: 107789
[parent_id]: 105128
[tags]: 
You can't sum mean squared errors like that unless your variables are all in the same unit, on the same scale. The unit of your RMSE is the square root of the sum of the squared units of its components. This is a completely meaningless unit in most practical applications I can think of. You could center and rescale all your variables first, to get RMSE in terms of number of standard deviations from the mean. Personally, I'm not sure if this is such a great idea. I think it depends on what you're using this "overall" measure of fit for, since there's no absolute "good" and "bad" RMSE. If you're going to be comparing different imputation models, it might not be a bad approach. Then again, if you're comparing imputation models for the purpose of fitting a model, you're better off (in my source-less opinion) just fitting the model with each imputation method and comparing the final model fits. The question you linked refers to a "different" overall RMSE. That answer is explaining how to properly average the RMSE's from a cross-validation procedure, on a single variable ($y$ in the answer's notation). I can't think of any reason to take your simulation's data-generating process into account. The point of simulation studies are to see how your model performs on new data. You don't know the underlying data-generating process. Therefore your estimate of model performance should not take into account things you wouldn't plausibly know when you're fitting your model. I also can't think of how you'd incorporate the missingness stratification if you wanted to, and how to interpret the resulting quantity.
