[site]: datascience
[post_id]: 121148
[parent_id]: 121034
[tags]: 
In the official Explosion demo repository, you can find a sample JSONL file where each line is a sample input with multiple labels (categories), each label is marked with 0.0 or 1.0 . That is, if your input should contain that label, you mark it with 1.0 , otherwise, 0.0 : {"text":"Moving from MySQL to Hybrid SQL","cats":{"DOCUMENTATION":0.0,"OTHER":1.0}} In this particular case, you see two labels (categories), but nothing prevents you from adding another category, e.g. "SOME OTHER LABEL / CATEGORY": 1.0 . For more information about JSONL format, please see: https://jsonlines.org . In the same repository, you'll also see convert.py script that demonstrates how to convert such a JSONL file into spaCy's binary DocBin format that can be used by spaCy's training system: """Convert textcat annotation from JSONL to spaCy v3 .spacy format.""" import srsly import typer import warnings from pathlib import Path import spacy from spacy.tokens import DocBin def convert(lang: str, input_path: Path, output_path: Path): nlp = spacy.blank(lang) db = DocBin() for line in srsly.read_jsonl(input_path): doc = nlp.make_doc(line["text"]) doc.cats = line["cats"] db.add(doc) db.to_disk(output_path) if __name__ == "__main__": typer.run(convert) I believe this should be enough for you to get started encoding your text input with whatever labels you want. The important thing is that, every single entry (e.g. line in JSONL file) should have all of the labels and then for the labels that are not associated with that input you should mark them with 0.0 , otherwise 1.0 . You might ask: "but why should I start with JSONL?". You don't have to! If you want, of you course you can directly in your Python code create some text data and its related labels, and directly convert these to DocBin and save that, but I generally find it more convenient and human-readable to first have that data stored as JSONL file.
