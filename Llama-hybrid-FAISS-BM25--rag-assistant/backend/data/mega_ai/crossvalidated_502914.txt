[site]: crossvalidated
[post_id]: 502914
[parent_id]: 502349
[tags]: 
NOTE: I'm still editing this post, need a bit more time to finish Here's a philosophical aside on the limits of few-shot learning. It is not exactly the answer to the question, but I guess it could help set the expectations straight. Part 1: Naive estimate of number of samples needed for classifier convergence . Let's say we did some dimensionality reduction on the available images and extracted $N$ features. We could argue that these features are representative of the images as finer features are weak and likely imperceptible for the human eye. For simplicity, let us assume that all of the features are orthogonal. Further, for the sake of the argument, let's assume that exactly 1 of these features is used by the participant to classify the images as those they like vs those they don't. Our goal is to find which feature that is. We have to know this well, or we would not be able to make predictions. Let's assume that each feature has a standard normal distribution $\mathcal{N}(0,1)$ over the available images, and that the important feature will be greater than zero if the image is liked, otherwise below, meaning that the participant will like approximately half of all the images. The question now is: how many trials do we require to find the correctly-predicting feature. The expected number is $\log_2 N$ - there will be some features which will be predictive at random, and at every trial each of them will have 50% probability of still being predictive by chance, meaning that 50% of them will drop out. A related and a bit more realistic question is - how many trials do we require to guarantee that all non-informative features have dropped off (e.g. with 95% confidence). A little less intuitively, but this value also scales as $\log_2 N$ . The proof is as follows: after $t$ trials, the probability that one non-informative feature still looks informative by chance is $p_1 = 2^{-t}$ . We are looking for the probability that $N$ non-informative features have all been revealed, and we want this probability to be greater or equal to 95%. This can be written as $(1 - p_1)^N \geq 0.95$ . If we solve this inequality for $t$ and use series expansion, we will get $t \geq C + \log_2 N + O(\frac{1}{N})$ for some small constant $C$ . Part 2: Effect of noise . But this is the absolute lowest unrealistic estimate. The difficulty starts when we consider that participants such as humans and mammals are known to have variance in their choice, meaning that they do not stay consistent to their general strategy at all trials. To model this, we must allow for a fraction of trials to be non-informative. Let's say that fraction of correct trials for informative features is $p_I = 90\%$ . We need a condition to refute the feature if it is non-informative. Dropping some finer details of hypothesis testing , we will find the fraction $\phi=\frac{t_{good}}{t}$ of trials for which the feature is informative, and compare it with $p_I$ . The more trials we measure, the closer we would expect the observed fraction to be to the true fraction. So, we would consider the channel as informative, if the observed fraction of trials $\phi$ is greater or equal to some threshold $\phi_0$ , which can be written as $$\phi_0 = p_I+\frac{\sigma_I}{\sqrt{t}}K$$ where $\sigma_I$ is the variance of the fraction (in our binomial case it is $\sigma_I = \sqrt{p_I(1-p_I)}$ ), and $K$ is some constant which depends on the desired confidence of the test (for normal approximation it is $K=\sqrt{2}erf^{-1}(2\alpha - 1)$ where $\alpha$ is the confidence level). Next, we need to find the probability that a non-informative feature fails the test $\phi \geq \phi_0$ , namely, that the result will be $\phi . For a non-informative trial, the fraction of correct trials will be $p_{NI}=50\%$ . Using DeMoivre-Laplace approximation , the sample fraction for non-informative features will be normally distributed, namely $$\phi \sim \mathcal{N}(\frac{1}{2}, \frac{1}{4t})$$ Part 3: Effect of feature synergy . Finally, situation is further complicated if individual features are insufficient for good prediction, and synergistic predictors are required. For example, if we require a pair of features to be simultaneously high (e.g. a person likes red images that are also very sharp), then we effectively have $N^2$ features to consider. TL;DR : Humans have to be cheating when performing few-shot learning. The only way to learn fast is to have prior information on what features are likely to be salient (predictive of outcome).
