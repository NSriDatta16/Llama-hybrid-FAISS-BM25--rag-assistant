[site]: crossvalidated
[post_id]: 444476
[parent_id]: 444418
[tags]: 
Indeed, your data do not support that hypothesis that there is significant variation in the outcome between the levels of the grouping factor. library(lme4) library(tidyverse) dat > summary(fit) Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod] Family: binomial ( logit ) Formula: y ~ 1 + (1 | f) Data: dat AIC BIC logLik deviance df.resid 480.8 488.6 -238.4 476.8 362 Scaled residuals: Min 1Q Median 3Q Max -1.3257 -1.3257 0.7543 0.7543 0.7543 Random effects: Groups Name Variance Std.Dev. f (Intercept) 0 0 Number of obs: 364, groups: f, 6 Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept) 0.5639 0.1090 5.173 2.31e-07 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 convergence code: 0 boundary (singular) fit: see ?isSingular This is because you don't have enough data to conclude that the groups significantly differ with respect to the outcome measure: > dat %>% group_by(f) %>% summarize(m = mean(y)) # A tibble: 6 x 2 f m 1 a 0.606 2 b 0.6 3 c 0.755 4 d 0.628 5 e 0.615 6 f 0.651 Notice all the means are fairly close together. Given the total number of observations, and the number of observations in each group, and most critically, the number of groups (only 6) it's hard to say variation exists. I recommend looking into rstarnarm or brms to fit the analogous model from a fully Bayesian point of view. (However, this is my opinion, and there is by no means consensus in the statistical community on how to deal with this problem, see ?isSingular ) library(rstanarm) fit2 > fit2 stan_glmer family: binomial [logit] formula: y ~ 1 + (1 | f) observations: 364 ------ Median MAD_SD (Intercept) 0.6 0.1 Error terms: Groups Name Std.Dev. f (Intercept) 0.24 Num. levels: f 6 ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg
