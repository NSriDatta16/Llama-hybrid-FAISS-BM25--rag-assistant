[site]: crossvalidated
[post_id]: 444760
[parent_id]: 444267
[tags]: 
I think your reasoning is basically correct: we could use an iterative solver like Newton's method to get a really good approximation to the optimal $\gamma$ , but that's a lot of work. The xgboost software uses a second-order Taylor expansion of $(3)$ because quadratics are easy to optimize. (Described in https://xgboost.readthedocs.io/en/latest/tutorials/model.html ; scroll down to the section "Structure Score.") Because of its simplicity, I wouldn't be surprised if this is the approach taken in most boosting libraries. An extensive answer about xgboost can be found here: XGBoost Loss function Approximation With Taylor Expansion
