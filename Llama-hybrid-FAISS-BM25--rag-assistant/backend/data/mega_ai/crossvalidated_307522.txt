[site]: crossvalidated
[post_id]: 307522
[parent_id]: 307495
[tags]: 
Different implementations of exponential smoothing differ in how they set initial values of the level, trend and seasonal components. Why? Even in a state space framework, there are many parameters to estimate (e.g., two initial values for the level and the trend, twelve initial values for monthly seasonality, plus the smoothing constants), typically with somewhat limited data - if you go with the rule of thumb of about 20 observations per degree of freedom, you would need 30 years of monthly data. Your time series are typically much shorter than this. (And even if you do have 30 years of data, the reasonable assumption is that the data generating process has changed in the meantime, unless you are dealing with astronomical data.) As a consequence, most implementations use a mixed approach, setting initial values heuristically and only using a variant of maximum likelihood for estimating the smoothing constants. And crucially, there are many reasonable heuristics for the first part, and different implementations will differ on how they do this. Sometimes the software documentation is explicit about what heuristics are used, but more often, it isn't, and your only possibility is to go into the source code. The canonical reference for state space models is Hyndman, Koehler, Ord & Snyder (2008), Forecasting with Exponential Smoothing: The State Space Approach . If you really want to go into the details, it's best to consult that book directly.
