[site]: crossvalidated
[post_id]: 62715
[parent_id]: 62714
[tags]: 
One way of reducing the dimensionality of your samples might be the so-called " sparse PCA " (SPCA), but I don't know whether it is available for Stata. SPCA limits the number of variables with non-zero weight per component and thus allows you to select the variables much more tightly. Alternatively, use the top N variables with the largest absolute loading and test how well your model performs then. But be warned: never use the same samples for test and selection procedure; otherwise your results will be worthless. Another approach that I personally find very useful in such a setting is to use PLS-DA, which is both a dimension reduction technique and a supervised machine learning algorithm. However you have to mind the way you are validating your results (see paper by Westerhuis et al. and van Dorsten, Metabolomics 2008). Other machine learning algorithms also are suitable for variable selection -- another one that I have experience with is random forests, where variables are given weights and can be selected for a refined model with a limited number of variables.
