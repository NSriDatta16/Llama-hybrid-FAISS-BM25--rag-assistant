[site]: datascience
[post_id]: 17228
[parent_id]: 17223
[tags]: 
If you are new to data science and data munging, this could be kind of a tricky task, but a good one to get your feet wet. Many programming languages have the capability to do this (R, Python, Matlab, etc.). I use R primarily, so I'll give you a brief heuristic for how I'd approach the task in R. Perhaps looking into these steps will get you started. Install R Install some packages that will help you along ('tm' for text mining,'dplyr' for cleaning/organizing your data, and perhaps also 'lubridate' for working with dates/times) Read in your data from your source, be it a text file, spreadsheet, or some database (if a database, you'll have to conquer connecting R to said database too) You want to do a word frequency analysis for each month. How you accomplish this will depend on how the data is organized, which I do not know, but it would involve first rounding all your dates to month (using lubridate's 'floor_date()' function is one way), then parsing the text for each month into a corpus that can be analyzed (using package tm). Finally, for each month I would make a table counting words, sorting by frequency. That would give you, for each month, the top 'trending' words. To discount words like 'the' and 'a', I might also use some of the tools in the 'tm' package to clean things up. Note that in #5 I said 'words', not 'terms'. If you want to account for terms consisting of > 1 words, you'll have to 'tokenize' them, but that's beyond the scope of this very brief intro. As with many data science tasks, there are many ways to attack this; the above is but one of many possibilities. Hope that helps.
