[site]: crossvalidated
[post_id]: 417102
[parent_id]: 417065
[tags]: 
Without proposing here a complete recap of Markov chain Monte Carlo methods, let me point out that the fundamental concept behind these methods is that they converge to the distribution $\pi^\star(\cdot)$ they aim at simulating, rather than simulating values from that distribution from the start of the method (as in, e.g., accept-reject algorithms). This means that the simulated Markov chain $(X^{(t)})_t$ is such that $X^{(0)}$ is distributed from an arbitrary distribution with density $\pi_0(\cdot)$ as for instance a Normal distribution (or a Dirac mass at 0); $X^{(1)}$ is distributed from a distribution $\pi_0(\cdot)$ that is not $\pi^\star(\cdot)$ but the transform of $\pi_0(\cdot)$ via the Markov kernel of the MCMC algorithm, $K$ , namely $$\pi_1(x)=\int_\mathcal X\pi_0(\text{d}y)K(y,x)$$ $$\vdots$$ 4. $X^{(t)}$ is distributed from a distribution $\pi_0(\cdot)$ that is not $\pi(\cdot)$ but the transform of $\pi_0(\cdot)$ via the Markov kernel of the MCMC algorithm, $K$ , applied $t$ times, namely $$\pi_t(x)=\int_\mathcal X\pi_0(\text{d}y)K^t(y,x)$$ The chain $(X^{(t)})_t$ is furthermore ergodic which means that, no matter what $\pi_0$ is , the distribution $\pi_t$ does converge to the target $\pi^\star$ . This means, that, asymptotically, $X^{(t)}$ is distributed from $\pi^\star$ and also that an average like $$\frac{1}{T}\sum_{t=1}^T h(X^{(t)})\tag{1}$$ converges to $\mathbb E^{\pi^\star}[h(X)]$ no matter what $\pi_0$ is (Ergodic Theorem). Then what is burning (or warmup) intended to do? It is there to remove the strong influence or bias of the starting values of the chain $(X^{(t)})_t$ on the starting distribution $\pi_0$ that slows down convergence of (1) to $\mathbb E^{\pi^\star}[h(X)]$ . In loose terms, it means waiting till the chain $(X^{(t)})_t$ has "reached stationarity", i.e., the time when $\pi_t$ is almost equal to $\pi^star$ . Here is a toy example where the target is $$\pi^star\propto x^2\underbrace{\varphi(x-4)}_\text{normal density}$$ and the Metropolis-Hastings proposal is $$K(x,y)=\underbrace{\mathfrak t_5(y-x)}_\text{$\mathfrak T_5$ density}$$ ] 1 where 10 MCMC chains are started from a standard Normal distribution and take a little while to reach a stationary regime and region where they all behave the same. The burning would thus be 20 or 30 in that case. But starting with a much more widespread initial distribution shows the difference in the impact on the values of the chains: However, removing the first iterations also remove the reduction in Monte Carlo variability which may mean that it is not always worthwhile, as shown by the comparison below for the approximation of $\mathbb E^{\pi^\star}[X^2]$ without and with burning (29 off):
