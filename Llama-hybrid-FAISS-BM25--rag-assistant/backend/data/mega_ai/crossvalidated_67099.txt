[site]: crossvalidated
[post_id]: 67099
[parent_id]: 67015
[tags]: 
Intuitively, the length-scale parameter controls how fast the functions sampled from your GP oscillate. If $\phi$ is large, then even points that are far away would have meaningful kernel covariance, therefore, your functions would oscillate slowly and vice versa. More, rigorously $\phi$ is related to the expected number of up crossings of level $u$ (when your random function increases pass height $u$) on a unit interval. See page 80-81 of the GPML book . This is for 1D (input) process. For higher dimensional processes, the notion of level crossing doesn't work anymore. Instead one has to use the topology of level sets to understand the geometry of the GP, see Geometry of Random Fields by Adler . To check if your estimation of $\phi$ (and other hyperparameters) is reasonable, in 1D and 2D, it's best to plot the posterior (mean function +/- 1 or 2 standard deviation) over the training data. In higher dimensions, it's harder to visualize, but there are two standardized prediction scores that you can look at on a validation set, namely the standardized mean squared error (SMSE) and standardized negative log probability (see GPML book for definitions). Generally speaking, if you see SMSE close to 1 (e.g. > 0.7) and SNLP close to 0 (e.g. > -0.1), your hyperparameters (or choice of kernel/ mean function) are probably way off. From my experience, agnostic to datasets, GP with good selection of hyperparameters can generally get to SMSE
