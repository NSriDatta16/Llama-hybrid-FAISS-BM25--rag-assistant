[site]: crossvalidated
[post_id]: 566362
[parent_id]: 
[tags]: 
How to speed up random forest using indicator features derived from the original input features?

I have a set of explanatory variables $X_1, \dots, X_n$ . Instead of learning a random forest model to predict the response $Y$ as a function of $(X_1, \dots, X_n)$ , I want to define a new feature $X_1'$ , which is an indicator variable $X_1'=I(X_1>x_1)$ , where $x_1$ is constant. For any given $x_1$ value, I could run a random forest of $Y$ using $I(X_1>x_1), X_2, \dots, X_n$ as features. I want to find the prediction for arbitrary $x_1$ . It would be inefficient to build a random forest for each value of $x_1$ . Is there a way to somehow consider the commonality of this group of random forest on different values of $x_1$ so that they can be generated efficiently? I'd prefer the new way having a time complexity less than linear of the number of $x_1$ values.
