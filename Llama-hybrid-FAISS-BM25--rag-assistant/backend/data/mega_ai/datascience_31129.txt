[site]: datascience
[post_id]: 31129
[parent_id]: 
[tags]: 
Sample Importance (Training Weights) in Keras

How do you add more importance to some samples than others (sample weights) in Keras? I'm not looking for class_weight which is a fix for unbalanced datasets. What I currently have is: trainingWeights which is the desired importance I want to give to each sample. epochs = 30 batchSize = 512 # Fit model with selected data model.fit(trainingMatrix, trainingTargets, batch_size=batchSize, epochs=epochs, sample_weight=trainingWeights) However the training error is much lower than before, and according to Keras' documentation : sample_weight: Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only). As I understand it, this option only calculates the loss function differently without training the model with weights (sample importance) so how do I train a Keras model with different importance (weights) for different samples. PD. This is a similar question xgboost: give more importance to recent samples but I would like an applicable answer to Keras.
