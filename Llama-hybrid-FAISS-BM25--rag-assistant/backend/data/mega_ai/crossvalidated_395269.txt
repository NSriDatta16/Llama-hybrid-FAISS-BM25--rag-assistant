[site]: crossvalidated
[post_id]: 395269
[parent_id]: 
[tags]: 
Why Random Forest predominantly predicts class 0 with balanced classes?

Similar question has been asked here: Binary Classification: good at predicting negative class but bad at predicting positive class but no answer, hence posting my question again. I have a binary classification problem with 100+ features. The classes are fairly balanced (close to 50-50 split). I don't understand why the model is predicting class 0 well with a recall of over 90% but class 1 extremely poorly with a recall of only 17%. I have solved this problem often by weighing, oversampling & under-sampling and changing the cut off point when the classes are imbalanced. Here, classes are fairly balanced, yet such a strange pattern. Has anyone solved this before? Any idea what is going on? What techniques could I use to improve the prediction for both the classes?
