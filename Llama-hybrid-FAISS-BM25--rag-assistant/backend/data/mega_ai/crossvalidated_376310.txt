[site]: crossvalidated
[post_id]: 376310
[parent_id]: 375612
[tags]: 
Adjusting for the mean shift: set.seed(1023) library(strucchange) ts1 Minimum BIC value for breaks=1. breakdates(bp, breaks=1) [1] 500 bp_fit tst_mean_adj Expect stationarity. library(urca) (urdftest_lag = floor(12* (length(tst_mean_adj)/100)^0.25)) summary(ur.df(tst_mean_adj, type = "none", lags = urdftest_lag, selectlags="BIC")) ############################################### # Augmented Dickey-Fuller Test Unit Root Test # ############################################### Test regression none Call: lm(formula = z.diff ~ z.lag.1 - 1 + z.diff.lag) Residuals: Min 1Q Median 3Q Max -7.5212 -1.3343 -0.0208 1.3132 5.5892 Coefficients: Estimate Std. Error t value Pr(>|t|) z.lag.1 -0.87281 0.04400 -19.836 We can reject null hypothesis of unit root presence for no-drift scenario. Based on level breakpoints fit and mean adjusted time series standard deviation, for time series "tst" we can suggest a model as: $$ b_{t} = 0.06 s_{t} + (5.01-0.06) s_{t-500} y_{t} = b_{t} + 1.95 \epsilon_{t} $$ where s_{t} step function and \epsilon_{t} white gaussian noise N(0,1). If we had fit the original time series "tst" without taking into account the level shift, we might (erroneously I think) have determined an I(1) model for, as herein depicted. library(forecast) tst_aa and the fit would have been: plot(tst) lines(fitted(tst_aa), col = 'green')
