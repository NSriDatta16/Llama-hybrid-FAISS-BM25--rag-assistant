[site]: crossvalidated
[post_id]: 494103
[parent_id]: 494049
[tags]: 
I've read all the mentioned answers there but they all agree on not standardizing training and test sets together because it'd cause data leakage. This means, any standardisation coefficient, e.g. min/max, median, mean, IQR, std is estimated from the training set and applied on the test set. This is in line with what Prof. Andrew Ng says. Some quotes from them: Second: Also for the sake of example say you have 10 years of data and you want to train your model on the first 9 years and test on the last year. When you standardize, you should only standardize over data from the first 9 years. Fourth: Formally speaking, for the prediction of 16 and onwards, there is no leakage because the standardisation does not include information that would be unavailable at the time of prediction. The third one isn't about normalization. The first one seems a bit vague. There is trend in the time series and the advice is to take the first difference to get rid of it. The standardisation applied in the original question is correct. The answer also says the following, which means the OP shouldn't standardize using the entire dataset: Don't standardize on the entire dataset (that's leaking data, and I think it's cheating).
