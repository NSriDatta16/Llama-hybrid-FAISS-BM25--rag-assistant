[site]: datascience
[post_id]: 29295
[parent_id]: 
[tags]: 
Is it effective to use one-hot encoding when its dimension is as large as thousands

Here I try to construct a classifier using DNN(deep neural network) with its inputs being many portfolios. In essence, each portfolio contains several stocks which are labeled by there inner-code, for example "1430" or "5560", etc. Since the inner-code is discrete digital number, I prefer to use on-hot encoding to represent each portfolio. However, there are as many as a few thousand different inner-code which means that the dimension of on-hot code may also be that large. I wonder whether the dimension is too large for real training and is there any way to solve or ease this problem, such as using PCA afterward.
