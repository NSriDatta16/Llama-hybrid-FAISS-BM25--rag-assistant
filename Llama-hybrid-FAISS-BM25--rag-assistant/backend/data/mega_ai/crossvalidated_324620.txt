[site]: crossvalidated
[post_id]: 324620
[parent_id]: 
[tags]: 
How to detect that a neural network input is out of scope?

I have built a neural network that detects dog breeds. My issue is that I don't know how to handle images that don't contain dogs. Indeed, whenever I input a flower image, it will be classified as a dog breed. Is there a way I could train my neural network to the output "I don't know"? Attempt: I have tried adding pictures from other objects than dogs. Unfortunately, I don't know what proportion of external images with the not_a_dog label I should add to correctly detect non-dog images. I don't want to create a bias in my data.
