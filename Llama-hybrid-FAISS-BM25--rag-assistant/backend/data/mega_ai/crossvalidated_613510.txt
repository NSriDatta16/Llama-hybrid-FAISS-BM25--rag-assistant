[site]: crossvalidated
[post_id]: 613510
[parent_id]: 
[tags]: 
General question on model weighting and averaging

I've had a stats related question I've been wondering for a while, but for which I have yet to find good sources on. I'm aware of things like the Akaike Information Criterion for weighting candidate models, but afaik this doesn't account for model autocorrelation (potentially leading to double counting if extremely similar models are included). Meanwhile, there is also the approach of simply putting every model into a multiple regression against the target variable to get weights, but in my experience, especially without large numbers of observations, these weights tend to do ~strange~ things (for instance, often giving a negative weight to one of two models with high correlation to the target variable when they're correlated to each other, which seems to me to typically be overfitting). It seems to me the best possible solutions to this are to A) use something like the AiC, but account for autocorrelation somehow (maybe by multiplying by something like (.5+.5*(1-autocorrelation^2)) across all other prospective models, to halve the weight if two models are highly correlated), or B) to use the model weights given by raw multiple regression, but with some sort of prior to avoid negative weights unless it's obvious they're an actual reflection of the underlying relationship. My question is, is there any pre-existing literature on this? Moreover, do any individual members of this messageboard have insight on this? I'm somewhat of a stats novice, and understand general theoretical concepts better than their specific mathematical functionings when it comes to this area, so my apologies if I'm raising something foolish or ignoring something obvious.
