[site]: crossvalidated
[post_id]: 283690
[parent_id]: 278443
[tags]: 
As you have noted in your comment, if your model is $y_i = w' x_i + e_i$, it implies that $Y_i = \sum_i y_i = w' \sum_i x_i + \sum_i e_i$ and performing a least squares fit of $Y_i$ from the sum of the input groups $\sum x_i$ would work well. This can be generalized in a straightforward way to non-linear models where $y_i = w' \phi(x_i) + e_i$, where you can view $\phi(x_i)$ is a high-dimensional (kernel) expansion of $x_i$. Then $Y_i = w_i \sum_i \phi(x_i) + \sum_i e_i$. Now if $K(x_i, x_j) = \phi(x_i)' \phi(x_j)$ is a given kernel function over your input space, the kernel function $K_s(\sum_i \phi(x_i), \sum_i \phi(x_j) = \sum_i \sum_j K(x_i, x_j)$. Therefore a least squares solution using a given p.s.d. kernel function over your input space, can be done using your aggregate samples by constructing the sum kernel $K_s$ over your example sets $\{x_i\}$ and building a kernel regressor (least-squares SVM, say) to $Y_i$ and then using the solution weight vector with the original kernel $K$ to predict $y_i$. This is all speculative, and I have no guarantees for how well it works for your problem.
