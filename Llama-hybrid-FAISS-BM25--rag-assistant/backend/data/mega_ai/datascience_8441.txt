[site]: datascience
[post_id]: 8441
[parent_id]: 1025
[tags]: 
I recommend anybody interested in the topic take a look at the paper which combines TDL and deep-learning. Roughly, you'll need to make the engine play games against each other. Record the mini-max evaluation for each position. At the end of the game, you'll get a reward, which is {0,1,-1} for chess. Then you'll need to adjust your parameters with: This equation tells us we should adjust the weights by temporal differences, weighted by how far you should do it. If you have a perfect evaluation, your temporal difference would always be zero, thus you wouldn't need to make any adjustment. Next, you'll need use the new parameters to play a new game. Repeats until as many games as you can afford or when you think it's converged. Few remarks: The paper I quote applies a discount factor. It's done for the backproportion algorithm for neural network. You don't need it. You'll need to experiment with the optimal learning rate (alpha in the equation). Too large will make your learning unstable, too little will take longer to converge. I've seen people using 0.70. The paper I quote used 1.0.
