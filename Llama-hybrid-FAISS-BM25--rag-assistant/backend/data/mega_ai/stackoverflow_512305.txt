[site]: stackoverflow
[post_id]: 512305
[parent_id]: 512262
[tags]: 
Based on my experience I'd say keep them in the database. We've moved two of our systems to doing this. Putting it in the database means: It's easy to access, even from multiple servers It's backed up automatically (instead of having to have a separate job to do that) You don't have to worry about space (since people keep the DB from overfilling the disk, but may forget to monitor where the documents are stored) You don't have to have a complicated directory scheme We had documents out of the database. It becomes a problem with lots of documents. A normal directory in Linux is one block, which is usually 4K. We had a directory that was 58MB because it had so many files in it (it was just a flat directory, no hierarchy). It had that many indirect blocks. It took over an hour to delete. It took minutes to get a count of the number of files in the directory. It was abysmal. This is on ext3. With the filesystem you need: Separate backup mechanism (from the DB backup) To keep things in sync (so the record doesn't exist in the DB without the file being there) A hierarchy for storage (to prevent the problem listed above, so no directory ends up with 10,000s of files) Some way to view them from other servers if you need a cluster (so probably NFS or some such) It's really a pain. For any non-trivial number of documents, I'd recommend against the file system based on what I've seen.
