[site]: crossvalidated
[post_id]: 502195
[parent_id]: 
[tags]: 
Are Graph Neural Networks (GNNs) generalizations of Convolutional Neural Networks (CNNs)?

In lecture 4 of this course , the instructor argues that GNNs are generalizations of CNNs, and that one can recover CNNs from GNNs. He presents the following diagram (on the right) and mentions that it represents both a CNN and a GNN. In particular, he mentions that if we particularize the graph shift operator (i.e the matrix S, which in the case of a GNN could represent the adjacency matrix or the Laplacian) to represent a directed line graph, then we obtain a time convolutional filter (which I hadn’t heard of before watching this, but now I know that all it does is shift the graph signal in the direction of the arrows at each time step). That part I understand. What I don’t understand is how we can obtain 2D CNNs (the ones that we would for example apply to images) from GNNs. I was wondering if someone could explain.
