[site]: crossvalidated
[post_id]: 380845
[parent_id]: 380509
[tags]: 
You have two models, $M_1$ and $M_2$ . Each model is characterized by a distribution for an observation $p(y_i|M_j)$ . Let $y = (y_1, \ldots, y_n)$ . Consistent with an earlier answer, let \begin{equation} p(y|M_j) = \prod_{i=1}^n p(y_i|M_j) . \end{equation} Given the data $y$ , this expression provides the likelihood for the model. For Bayesian inference you will also need the prior probabilities for the models, $p(M_j)$ , where $p(M_1) + p(M_2) = 1$ . Using Bayes rule, the posterior probability of $M_j$ is given by \begin{equation} p(M_j|y) = \frac{p(y|M_j)\,p(M_j)}{p(y)} , \end{equation} where \begin{equation} p(y) = \sum_{j=1}^2 p(y|M_j)\,p(M_j) . \end{equation}
