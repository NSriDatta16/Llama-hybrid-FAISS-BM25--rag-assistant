[site]: crossvalidated
[post_id]: 168368
[parent_id]: 168330
[tags]: 
There could both be situations where correlation pruning would improve - and deteriorate prediction performance. RF and SVM are both not sensitive to collinearity, but to small data-sets of few hundreds of samples it could show to be an advantage to perform some kind feature selection. Remember feature selection (grid-search also) will make inner prediction performance e.g. OOB over-optimistic. Therefore, the entire modelling should be wrapped in an outer validation loop. Removing features having a correlation(pearson/spearmann) = 0.6 would probably be unnecessary. Consider to select features with 'variable importance' instead. @ which models are more sensitive to correlated features? - Classifiers/regressors with low or no regularization e.g. LDA or MLR.
