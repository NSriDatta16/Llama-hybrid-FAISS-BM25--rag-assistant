[site]: crossvalidated
[post_id]: 166499
[parent_id]: 165062
[tags]: 
[edit: chose not to delete answer. What Dougal wrote is clearly a better answer] Random forest will effectively apply an prior expectation matching the class distribution of the training set. You can modify this distribution with stratification/downsampling or apply class weights during training. You can also modify the voting aggregation rule. You can use the vote ratio as predicted pseudo probabilities. Use ROC plots to investigate sensitivity and selectivity. Here's another answer including coding in R.
