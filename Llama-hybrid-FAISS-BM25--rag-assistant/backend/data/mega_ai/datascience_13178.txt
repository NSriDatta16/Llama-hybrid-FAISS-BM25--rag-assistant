[site]: datascience
[post_id]: 13178
[parent_id]: 
[tags]: 
How to normalize data for Neural Network and Decision Forest

I have a data set with 20000 samples, each has 12 different features. Each sample is either in category 0 or 1. I want to train a neural network and a decision forest to categorize the samples so that I can compare the results and both techniques. The first thing I stumbled upon is the proper normalization of the data. One feature is in the range $[0,10^6]$, another one in $[30,40]$ and there is one feature that mostly takes the value 8 and sometimes 7. So as I read in different sources, proper normalization of the input data is crucial for neural networks. As I found out, there are many possible ways to normalize the data, for example: Min-Max Normalization : The input range is linearly transformed to the interval $[0,1]$ (or alternatively $[-1,1]$, does that matter?) Z-Score Normalization : The data is transformed to have zero mean and unit variance: $$y_{new}=\frac{y_{old}-\text{mean}}{\sqrt{\text{Var}}}$$ Which normalization should I choose? Is normalization also needed for decision forests? With Z-Score normalization, the different features of my test data do not lie in the same range. Could this be a problem? Should every feature normalized with the same algorithm, so that I decide either to use Min-Max for all features or Z-Score for all features? Are there combinations where the data is mapped to $[-1,1]$ and also has zero mean (which would imply a non-linear transformation of the data and hence a change in the variance and other features of the input data). I feel a bit lost because I can't find references which answer these questions.
