[site]: crossvalidated
[post_id]: 409972
[parent_id]: 22804
[tags]: 
Casual inference is must. And how to address it's fundamental problem, you can't go back in time and not give someone a treatment. Read articles about rubin, fisher the founder of modern statistics student.).... What to learn to address this problem, proper randomisation and how Law of large numbers says things are properly randomised, Hypothesis testing ,Potential outcomes (holds against hetroscastisty assumption and is great with missingness ), matching (great for missingness but potential outcomes is better because it's more generalised, I mean why learn a ton of complicated things when you can only learn one complicated thing ), Bootstrap ,Bayesian statistics of course( Bayesian regression, na√Øve Bayesian regression, Bayesian factors) , and Non papmetric alternatives. Normally in practice just follow these general steps , Regarding a previous comment you should genrally first start with an ANOVA (random effects or fixed effects, and transform continuous types into bins) then use a regression (which if you transform and alter can sometimes be as good as a ANOVA but never beat it) to see which specific treatments are significant,( apposed to doing multiple t test and using some correction like Holm methid) use a regression. In the cases where you have to predict things use bayasian regression. Missingness at more than 5% use potential outcomes Another branch of data analytics is supervised machine learning which must be mentioned
