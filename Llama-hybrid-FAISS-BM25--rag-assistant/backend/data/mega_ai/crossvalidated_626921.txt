[site]: crossvalidated
[post_id]: 626921
[parent_id]: 
[tags]: 
Should I sample or compute the innovation term in the recursive estimation OLS algorithm applied to time-series data?

I have time-series data $\{Z_{[t]}\} = Z_t, Z_{t-1}, ..., Z_1$ of length $L$ , and I would like to estimate a model for the $\{Z_{[t]}\}$ so I can forecast $Z_{t+1}$ as a function of a number of its past values. $$ Z_{t+1} = \sum_{i = 0}^t \phi_{t-i}Z_{t-1} + \epsilon \quad \quad [1] $$ where $\epsilon$ has a distribution $D$ and finite variance $\sigma^2$ . Once $Z_{t+1}$ is computed, I'd like to append it to the data vector $\{Z\}$ to re-estimate the parameters $\phi \in \Phi$ . Suppose I decide to estimate a model with two parameters for $\{Z_{[t]}\}$ . Using OLS, I could do $$ \boldsymbol{\phi} = (\boldsymbol{X}^\top \boldsymbol{X})^{-1} \boldsymbol{X}^\top y \quad \quad [2] $$ where $\boldsymbol{\phi} \in \mathbb{R}^2, \boldsymbol{X} \in \mathbb{R}^{(L-2)\times 2}$ is a matrix of lagged ${Z}$ values, and $y \in \mathbb{R}^{(L-2)}$ is the vector $\{Z_{t},Z_{t-1}, ..., Z_{t - L + 2}\}$ . To help visualize what I mean, suppose the time series has only 6 data points. I could write $y$ and $\boldsymbol{X}$ respectively as $$ y = \begin{pmatrix} Z_6 \\ Z_5 \\ Z_4 \\ Z_3 \end{pmatrix} \\ \\ \boldsymbol{X} = \begin{pmatrix} Z_5 & Z_4 \\ Z_4 & Z_3 \\ Z_3 & Z_2 \\ Z_4 & Z_3 \\ Z_2 & Z_1 \end{pmatrix} $$ With $y$ and $\boldsymbol{X}$ , I obtain $\{\phi_1, \phi_2\}$ and forecast $Z_7$ using $Z_6, Z_5$ as input and an innovation $\epsilon$ (noise) term. Question 1: What's the recommended way to sample $\epsilon$ ? So far, I have used the fitted model to calculate the error $\epsilon_{TD}$ on the training data $Z_6, ..., Z_3$ . I checked the error's mean and variance and visualized its distribution with a histogram. Using a qqplot, I assessed the likelihood of the data being normally distributed. If it looks "normal enough", I'd sample $\epsilon$ from a normal distribution such that $\epsilon \sim \mathcal{N}(\text{mean}(\epsilon_{TD}), \text{var}(\epsilon_{TD}))$ . Question 2: Is the normal distribution the ideal distribution for the error? Or is it OK to have a different distribution? I know that in the OLS distribution, it's expected that the error show no temporal correlation and display a normal-distribution behavior. Once I have $Z_7$ , I can append it to $y$ and re-estimate the model parameters. In searching for a way to update the parameters without having to compute the normal equation, Equation 1 , again, I looked up "recursive estimation with OLS". I found a vast literature in the field of System's Identification and Estimation, and one recurrent fact caught my attention. As seen in Powell's writings here (pg. 165-167) and here as well as in Mendel's book , it is assumed that a new "measurement" or "signal" will "come"/"arrive"/"be read", and that allows for the calculation of the innovation term: $\epsilon_{t+1} = Z_{t+1} - Z_t$ . As far as I understand, this approach won't work with me. I can't expect a new "measurement" to "arrive"; I have to forecast it. The innovation or noise term is calculated from data instead of being generated from a distribution. Question 3: Is the generation of the innovation a legitimate way to go about this? My questions mostly stem from the fact that in the examples I read, the data were not time-dependent. In my case, however, the data at a time $t$ will depend on past values.
