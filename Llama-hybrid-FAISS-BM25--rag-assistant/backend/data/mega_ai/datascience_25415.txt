[site]: datascience
[post_id]: 25415
[parent_id]: 25411
[tags]: 
Your are mixing two different beasts. Despite both having encoder and decoder parts, the way in which a normal feedforward image transformation network (i.e. the autoencoder) and an autoregressive model (i.e. the seq2seq) are actually used is very different: In the type of image transformation done in a vanilla autoencoder, you input an image and get another image at the output. That's it, both at training and at inference time. In an autoregressive model like seq2seq, you feed the network with the input and the initial tokens of the expected output sequence (i.e. the prefix), and you get the next token as output. During training, those initial tokens are normally from the gold data ( aka teacher forcing), that is, you feed as prefix real tokens from the training data. In inference, those tokens are generated by the model itself: you generate the first token, then you generate the second token given the first one you previously generated, then you generate the third token given the previous 2 generated tokens, and so on.
