[site]: crossvalidated
[post_id]: 639680
[parent_id]: 
[tags]: 
Determining number of repeat measures needed to deal with measurement error through bootstrapping?

I have a performance test with a high degree of inherent measurement error. I have some data from a pilot study where I took 30 repeat measures with a single device and I want to figure out how many repeat measures (hopefully less than 30!) will provide me with a reasonable estimate of the mean for an individual device. I wrote a script in R to try to check convergence for various sample sizes. The general idea is, for each sample size from n to N Pull a random sample (without replacement) of size n from the original sample of size N Run a bootstrap parameter estimate on this sample using B resamples Do it again X times Average the X parameter estimates and check convergence (i.e. check standard deviation between measurements) to see how many samples I need. Is this a valid approach for trying to figure out how many repeat measures to include for each device in a performance test? I was planning to do X=10,000 estimates for each sample size using B=10,000 resamples each. Does this sound like enough? Would X=1,000 and B=100,000 be better? Not sure how to determine what is best. I ran a test with X=10,000 and B=500 and it took a little under an hour, so I don't expect any problems resource-wise.
