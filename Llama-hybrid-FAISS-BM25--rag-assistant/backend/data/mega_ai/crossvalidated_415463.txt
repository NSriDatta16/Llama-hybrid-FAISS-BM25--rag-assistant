[site]: crossvalidated
[post_id]: 415463
[parent_id]: 
[tags]: 
Precision/Recall against threshold curve not useful in improving model performance

I am doing fraud detection (binary classification) on an unbalanced credit dataset, using SVM. My current precision is 5% while recall is 90%. (I am using undersampling to train and test a model from original data's training set, and predicting on original data's test set) The Precision/Recall against threshold curve is quite weird when testing the model on the undersampled data: The Precision/Recall against threshold curve for predicting on original test data shows ~0.45 value at the intersection of the precision and recall line. I expected that if i used predict_probability > threshold then 1, else 0 values in my confusion matrix, i would get a recall and precision of ~0.45. However, it turns out recall is now 85% but precision 11%. I've some questions below: 1) Why isn't it ~45% recall and ~45% precision like the curve shows? 2) If not , what is the use of the curve? When i increased the threshold above 0.45, it actually gives better precision. Like this, do i just trial and error to find optimal threshold where precision is similar to recall? edit addon: I am using linear kernel SVM from sklearn. classifier= svm.SVC(C= 1, kernel= 'linear', random_state= 0, class_weight='balanced') Code for precision and recall (i had 1 for undersampled test data, 1 for original test data) precision, recall, th = precision_recall_curve(y_test, y_pred) This is the graph code (gives a curve rather than line when using other models as expected) plt.plot(th, precision[1:], label="Precision",linewidth=5) plt.plot(th, recall[1:], label="Recall",linewidth=5) plt.title('Precision and recall for different threshold values') plt.xlabel('Threshold') plt.ylabel('Precision/Recall') plt.legend() plt.show()
