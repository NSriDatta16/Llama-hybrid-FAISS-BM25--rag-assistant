[site]: crossvalidated
[post_id]: 213929
[parent_id]: 213905
[tags]: 
I think you are missing the case of events where you don't observe a success/failure within the first 10 flips. Your Frequentist estimation would be that the probability of say a Heads would be either 1 or 0, which you may know to be untrue. The Bayesian approach would leave the possibility as finite though unlikely. This is discussed in the Rule of Succession link you provided. If you want to argue that there are such possibilities where it is impossible to get a success or failure then I would suggest that you are using an improper prior. I would suggest you use the prior discussed in your linked Rule of Succession article that gives a better prior for that case. I should also note that your metric for success is kind of weird in my opinion. The situation you give is having just flipped 10 coins and estimating the probability on those flips. I don't know how you you want to treat being off, whether it is better to underestimate, overestimate, or if both equally bad, but your metric currently doesn't do that. It instead takes the average of the predictions and packages them, this would violate the one universe idea. I took your code and ported it to R since I'm more comfortable with that language and it has some built in features that are perfect for what we are trying to do. I also added a mean absolute error metric (quick and easy to implement): set.seed(10) calc_probs Starting with a histogram of $p$: Next we examine the error by decile for the frequentist estimate: Finally we look at the error by decile for the bayesian estimate you provided: Comparing for when the bayesian approach is better (note this isn't by how much so it is a bit of a cheat): We notice that the frequentist estimate has less average error when $p$ is more extreme (near 0 or 1) and the bayes approach when $p$ is closer to 1/2. This is expected based on the prior we chose for the bayes approach. Overall the average error calculated by my code is: "Average frequentist estimate error: 0.0999418570390359" "Average bayesian estimate error: 0.0928987467885039" So the average mean absolute error is better for the Bayesian approach. One may point out that I originally claimed that the point of the Rule of Succession was to avoid problems when the probability was low or high. In order to better demonstrate the ability of the Bayesian Method I would like to use a more standard error metric for these types of problems. In particular the log loss function. This can be done by adjusting my calc_probs function as follows (If this is wrong someone point this out so I can fix it.): calc_probs Doing so running my code to plot these loss functions I get the following results. For the frequentist method the binned mean log-loss function is: For the bayesian method I get: For the which is better comparison I get: Finally overall loss I get: "Average frequentist estimate log loss: -0.110217675806207" "Average bayesian estimate log loss -0.184244915921267" A reasonable objection to my implementation of log-loss here is that I have used $p$ instead of making an eleventh prediction then doing a classification error based on that. This is a reasonable objection and I will have to return to update my method to take this into account. Ignoring the objection we see that universally the Bayesian method works better for the log-loss error function. This is inline with the Rule of Succession idea since its purpose is to avoid a $p=0$ prediction for events that are possible.
