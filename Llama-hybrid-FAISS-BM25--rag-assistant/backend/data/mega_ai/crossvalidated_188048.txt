[site]: crossvalidated
[post_id]: 188048
[parent_id]: 187827
[tags]: 
You're right that the answer is no. Using a CNN is one approach - the max-pooling operation makes it a little more translation invariant with each added layer, until in the final layer you just end up with a bag of features. Another approach, which is a bit more tricky and more recent, is to use attention (a mechanism which focuses on a certain part of the image, then feeds that to a neural net). The attention mechanism can either be trained through reinforcement learning or backpropagation if it is differentiable (the DRAW paper does something like this, but it's not a normal MLP). If you're actually just working with digits on a blank background, some kind of hand-coded recenter/rescale/deskew system is probably best.
