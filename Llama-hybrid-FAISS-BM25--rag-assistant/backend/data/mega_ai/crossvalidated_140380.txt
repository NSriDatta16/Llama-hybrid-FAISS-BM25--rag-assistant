[site]: crossvalidated
[post_id]: 140380
[parent_id]: 
[tags]: 
How to understand if 2 very correlated predictors influence the output?

I have a binary output $y$ and a small set of predictors $x_1, x_2,\dotsc$ Two of these predictors are very correlated. It is known that one of them has influence on the output we want to know if also the other is relevant or not. Is there any typical way to solve this problem? EDIT I have tried various methods to solve this problem but I would like to know if there is a better one. run a simple logistic regression and look at the p-value ortogonalize the input variables define $x_2^{new} = x_2 - x_1\cdot x_2x_ 1$ (like the gram schmidt algorithm) Compute the AUC error using bootstrap and check if the model, where both the variables are present, lead to a lower AUC error. (The models are all incredibly weak and all the prediction performances are very bad) I need to run this kind of analysis with different combinations of input and various output values. I will so not discuss the result obtained with these methods. I would like to know if there is a standard way to do that. MY BACKGROUND: I am a mathematician but I have a good knowledge of machine learning. I know a little bit of statistics as well but not too much.
