[site]: datascience
[post_id]: 43877
[parent_id]: 43858
[tags]: 
Pal, you have set alpha to 1. Alpha is a L2 regularization term, its value is normally around 0.0005 ... 0.0001. By setting it to 1 you force the optimizer to make your model's weights almost zero. P.S. After setting l2 reg term to its default value, you might get better accuracy, but if not, pay attention to the following. The ratio between the amount of data size (1500 samples, how many feature vectors?) and the number of weights (20x60x60x60xN, so more than 4M weights) is too small. It might well be that the model simply memorize the training set and does not generalize for sound classification. Here are some suggestions that might help in training a sound classifier: Start with a simpler model. Sounds are known to be well classified with Gaussian mixture models, for instance. Unlike deep learning models, those are easier to train. Use data augmentation to increase the amount and diversity of your training data. You can mix the sounds with some light background noises. Try to reduce the amount of weights. Three layers with 60 neurons each is too much. Usually, layers become smaller with going up, something like 64->32->16. Also, convolutional layers can be very useful here, as they share the weights across their neurons. I used them quite successfully for sound classification. scikit-learn is quite unusual choice for training deep learning models. I would try Keras, it works perfectly with numpy arrays.
