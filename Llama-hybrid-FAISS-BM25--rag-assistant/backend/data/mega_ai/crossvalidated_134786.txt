[site]: crossvalidated
[post_id]: 134786
[parent_id]: 134779
[tags]: 
Both sites are suggesting the same thing but one is posing a way to consistently select the amount of adjustment. This has been attributed to a number of people but I don't think anyone knows who really came up with it first. Different fields have a different seminal book or author on signal detection. What's important is that the method you select is reasonable. The one method you posted usually is taken to imply that if you had a much larger set of items (2N) then you would have been able to detect at least one error. If this is a reasonable way to think about the problem then you're done. I doubt it is for a memory test. In the future you might want to raise N to insure this is much less likely to happen. Nevertheless, the method is salvageable if you consider it a different way. You're adjusting on a hypothetical average of two runs of the same number of memory items. In that case you're saying that in another run of the experiment (assuming new items or they forgot all of the old ones) there would have been an error. Or, more simply, you're just selecting half way between the highest imperfect score that you can measure and a perfect score. This is a problem with no simple universal solution. The first question you need to ask is whether you believe, in your case, you have genuine perfect classification. In that case your data is your data. If not, then you believe it's just variability in the sample causing hits to be 100%. Once you conclude that's the case then you've got to consider reasonable ways to generate an estimate of what you believe d' to be. And so you have to ask yourself what it actually is. The easiest way to determine what d' should be is to look at the other data in that same condition. You could perhaps estimate that the accuracy for this one participant is half way between the next best value that you have and 100% (which may turn out to be exactly the same as the value you found). Or, it could be some very small amount greater. Or it could just be equal to the best values. You've got to select what you believe is the best answer based on your data. A more specific question posted might help you here. You should attempt to insure you do is make as little impact on the criterion as possible. In your case an adjustment to hits and FAs will cause the criterion not to shift at all. However, if you adjust hits when say, FAs = 0.2, then you have to be careful about how that adjustment would impact the interpretation of criterion. You're sort of obligated in that case to make sure hits is very high.
