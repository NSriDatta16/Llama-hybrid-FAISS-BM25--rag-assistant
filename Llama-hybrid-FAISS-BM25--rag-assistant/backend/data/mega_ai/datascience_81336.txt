[site]: datascience
[post_id]: 81336
[parent_id]: 81335
[tags]: 
First have a look at your data scale. Deep learning models are sensitive to data scaling so it would be better to preprocess your data to keep in within accetable ranges: scale [-2,2] - apply scaling so that all features and label are within this range mean 0: try to center your data around 0 Second, deep learning models are regularised overfitting models. One thing you can try here is to progressively increase the size of your model (i.e. more hidden layers or hidden units) and also add regularisation. Your options are: weight decay - keras Dense layers can be augmented with weight decay. Have a look at the documentation layer regularisation (batch norm, dropout, layer normalisation) these are a bit more advanced and work on a case by case basis - have a look at this paper as a start.
