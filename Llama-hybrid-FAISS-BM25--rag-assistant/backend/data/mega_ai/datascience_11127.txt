[site]: datascience
[post_id]: 11127
[parent_id]: 11126
[tags]: 
I'd suggest you to try a hybrid approach: First, train your car in supervised fashion by demonstration . Just control it and use your commands as labels. This will let you get all the pros of SL. Then, fine tune your neural net using reinforcement learning. You don't need extra sensors for that: the rewards may be obtained from distance sensors (larger distances = better) and from the speed itself. This will give you the pros of RL and train your NN to the correct goal of driving fast while avoiding obstacles instead of the goal of imitating you. Combining both approaches will get you the pros of both SL and RL while avoiding their cons. RL won't start from random behavior, just small gradual deviations from what you tought the NN. A similar approach was applied successfuly by Google DeepMind with AlphaGo . You can always include explicit rules on top of this. Implement them with high priority and call the NN only when there is no explicit rule for current situation. This is reminiscent of the Subsumption Architecture .
