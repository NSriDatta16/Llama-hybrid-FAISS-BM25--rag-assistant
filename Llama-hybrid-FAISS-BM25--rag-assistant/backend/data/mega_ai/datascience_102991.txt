[site]: datascience
[post_id]: 102991
[parent_id]: 102975
[tags]: 
All GridSearch does is it looks for the best performing model among the parameters you have supplied it with. It won't fix overfitting for you. Overfitting happens when the model is to well adjusted to the training data. In case of SVM the model with C=1000 would definitely overfit and that is why it was not the best one. C=0.1 would probably underfit and that is also why it was not the best one. Random Forests are protected from overfitting. Breiman L (2001). “Random Forests.” Machine Learning, 45, 5–32. I don't really see the issue of overfitting here. It is to be expected that the score of training set will be better then the one of the test set. The parameters for SVM are way to extreme. You should narrow your search closer to the values in the output. Edit: Hyperparameter tuning is not the only tool for improving accuracy. If you are not satisfied with the results you can do some feature engineering or review your methodology this far.
