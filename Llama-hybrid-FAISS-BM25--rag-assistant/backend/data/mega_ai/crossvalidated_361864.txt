[site]: crossvalidated
[post_id]: 361864
[parent_id]: 361863
[tags]: 
There's a very simple way to have "all previous time steps" available to the model: retain the memory state. At each time step, the memory is updated according to (1) the new time step; (2) the previous memory state and (3) the parameters (weights and biases) of the neural network. If you discard the memory state, then you're losing all of that accumulated information from the previous time-steps; but if you retain the memory state, then that information is available for making predictions in the future.
