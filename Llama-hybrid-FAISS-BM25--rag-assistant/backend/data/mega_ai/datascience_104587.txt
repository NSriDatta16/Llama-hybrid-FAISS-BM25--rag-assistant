[site]: datascience
[post_id]: 104587
[parent_id]: 
[tags]: 
How to handle censored data?

We are building QSAR/SQPR models for ADME properties (related to drug discovery). Very simply put, our data are: molecular structures as the independent variables, and various properties measured for those molecules as the dependent variables. Example: $X$ = molecular structure of aspirin; $Y_1$ = solubility in water at pH 7.4, $Y_2$ = intestinal permeability, $Y_3$ = human plasma protein binding, ... We have a large number (about 100 K) of $X$ 's, with (sparse) $Y$ associated data. We want to make a multitask model or alternatively single task models that predict $Y_i$ 's from $X$ . However, as you surely know it often happens, for many of the $Y$ properties we cannot measure the whole range of values. E.g. for $Y_1$ above, we might be able to measure only between $0.01\ mg/L$ and $1000\ mg/L$ . Still, some molecules will have a solubility outside these boundaries, and then we will get a censored response, like $ or $> 1000\ mg/L$ . I'll put here my question, as a sort of TL;DR. Further down my more detailed explanations and arguments. Is there any consensus in data science about what should be done with such type of censored data? Any guidelines, common practice, methodologies one can use to decide how to handle it, whether to use it at all, etc? Based on previous work (and some literature), at the moment we are completely removing all censored values from our data. Why? Because including censored data in the model training by simply removing the $ or $>$ had a "detrimental" effect on the model performance, for other (non-ADME) data that were looked at previously. I had a rather animated discussion with my teammates regarding this aspect. Of course I understand that censored data are by definition extremely uncertain. A molecule with solubility $> 1000\ mg/L$ can actually be $1000$ , $10000$ , $100000$ ... So yes, I get it, putting in the data like that, just removing the qualifiers, might well make the model worse (even if in the test set there are no censored data, to avoid that classic 'horizontal line' effect). On the other hand, IMO just completely ignoring all that information (which sometimes makes up as much as 30% of the whole data we have for a $Y$ ) cannot possibly be the right thing to do: I am really convinced that the information must be used somehow, if not by removing $ or $>$ , in some other way. And this not just on theoretical grounds, but very pragmatic ones too. Imagine if someone wants to use our model. As we have not included in the training any data about molecules with very low or very high solubility, it is quite likely that all prospective molecules of that type will get essentially random predictions from the model. And that, I think, would look extremely bad. To address this, I suggested that we build a classification model telling apart the molecules with data within the measurable range, below the lower limit and above the upper limit; then our regression model, trained only with the molecules whose $Y$ falls in the measurable range, can be applied only to the molecules that the classifier says are in that category. This in fact would be a closer in silico reproduction of the wet experiment, which also gives categorical responses. [I am told that mixed classifier-regression models exist, but that they are harder to implement, at least within the modelling framework we are using, due to some required modifications of the loss function]. I'd please like to hear from you if this issue has already been addressed, if there are any standards or procedures, or literature you can suggest on the topic.
