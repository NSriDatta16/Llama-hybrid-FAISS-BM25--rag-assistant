[site]: crossvalidated
[post_id]: 221628
[parent_id]: 221616
[tags]: 
A1. This sounds like a sensible plan to me. Just to mention a couple of points. You'll want to test with different error metrics ($L^p$, K-L divergence, etc.) since methods will perform differently depending on the loss function. Also, you'll want to test for different number of samples. Finally, many density estimation methods perform notoriously badly near discontinuities/boundaries, so be sure to include truncated pdfs in your set. A2. Are you interested only in 1-D pdfs or is your plan to test the multivariate case? As for a benchmark suite of pdfs, I asked a somewhat related question in the past with the goal of testing MCMC algorithms , but I did not find anything like a well-established set of pdfs. If you have plenty of time and computational resources, you might consider performing some sort of adversarial testing of your idea: Define a very flexible parametric family of pdfs (e.g., a large mixture of a number of known pdfs), and move around the parameter space of the mixture via some nonconvex global optimization method (*) so as to minimize performance of your method and maximize performance of some other state-of-the-art density estimation method (and possibly vice versa). This will be a strong test of the strength/weakness of your method. Finally, the requirement of being better than all other methods is an excessively high bar; there must be some no free lunch principle at work (any algorithm has some underlying prior assumption, such as smoothness, length scale, etc.). In order for your method to be a valuable contribution, you only need to show that there are regimes/domains of some general interest in which your algorithm works better (the adversarial test above can help you find/define such a domain). (*) Since your performance metric is stochastic (you will be evaluating it via Monte Carlo sampling), you may also want to check this answer about optimization of noisy, costly objective functions.
