[site]: crossvalidated
[post_id]: 99704
[parent_id]: 69874
[tags]: 
In the forecasting context, removing outliers is very dangerous. For instance, you're forecasting sales of a grocery shop. Let's say there was a gas explosion in the neighboring building, which caused you to close the shop for a few days. This was the only time the shop was closed in 10 years. So, you get the time series, detect the outlier, remove it, and forecast. You silently assumed that nothing like this will happen in the future. In a practical sense, you compressed your observed variance, and the coefficient variances shrank. So, if you show the confidence bands for your forecast they'll be narrower than they would have been if you did not remove the outlier. Of course, you could keep the outlier, and proceed as usual, but this is not a good approach either. The reason is that this outlier will skew the coefficients. I think a better approach, in this case, is to allow for an error distribution with fat tails, maybe a stable distribution. In this case, your outlier will not skew the coefficients too much. They'll be close to the coefficients with an outlier removed. However, the outlier will show up in the error distribution, the error variance. Essentially, you'll end up with wider forecast confidence bands. The confidence bands convey a very important piece of information. If you are forecasting that the sales would be \$1,000,000 this month, but there's a 5% chance that they'll be $10,000, this impacts your decisions on spending, cash management, etc...
