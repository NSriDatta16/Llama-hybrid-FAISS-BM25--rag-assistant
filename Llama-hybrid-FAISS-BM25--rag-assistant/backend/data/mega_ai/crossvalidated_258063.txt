[site]: crossvalidated
[post_id]: 258063
[parent_id]: 257959
[tags]: 
You cannot "merge" neural networks as layers are generally nonlinear. To estimate the overall error you can just average your ten errors. If you want to apply this model in the real world just train a new network on the full data. Also note that you did not use a validation set in your split. If you are optimizing hyperparameters on the test set you are bound to falsify your results as you let the test set influence your classifier, thus introducing bias. Check this for a more detailed explanation on how to use cross validation with neural networks: https://stackoverflow.com/questions/25889637/how-to-use-k-fold-cross-validation-in-a-neural-network
