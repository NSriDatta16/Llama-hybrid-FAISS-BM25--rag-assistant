[site]: crossvalidated
[post_id]: 507529
[parent_id]: 507458
[tags]: 
First of all, observing substantial variation depending on the random seed means that you should explore this in more detail, just like you'd explore and deal with any other important source of random uncertainty in your modeling process: At the very least, measure the variance you get from this source of variation. Do this by re-running the entire fitting procedure with varying random seeds sufficiently often to get an estimate of the variance this causes in your final results (e.g. various figures of merit of the verification/validation of the model). Once you know the variance and know that it is important, there are usually 2 very different approaches to deal with random uncertainty: You can reduce the variance in the model training process, i.e. stabilize it/make it more robust. This is usually done by restricting model complexity, e.g. heavier regularization, using less features from the very beginning (data-driven feature selection will typically not help here, but rather exhibit unstable selection of features), put a penalty on hyperparameter optimization that acts towards less complex models, ... The 2nd approach is to average over a sufficiently large population that exhibits the variance in question, in order to obtain a "mean" that is subject to less variance. This would be an aggregated model consisting of an ensemble of models that were obtained from varying random seeds in your case. The verification and validation of the final optimized model should not enter these thoughts in any way: that part needs to be entirely independent of the training process. However, the final model validation should include ruggedness wrt. random seed. More or less folds in the cross validation should ideally not influence the cross validation results. Looking at variance between folds without distinguishing variance due to finite number of tested cases (which varies per fold but it constant once you look at all folds of a CV run) from variance due to model instability will give a hard to interpret conglomerate of these two factors. There are some optimization heuristics (like the one-sd-rule) that nevertheless use between-fold-variance. Since you do have substantial model instability, you'd need to dig down and at least find out roughly what the dominating source of variance is.
