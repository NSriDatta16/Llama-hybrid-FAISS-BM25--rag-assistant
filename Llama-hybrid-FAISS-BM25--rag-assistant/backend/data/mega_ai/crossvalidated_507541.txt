[site]: crossvalidated
[post_id]: 507541
[parent_id]: 
[tags]: 
F1 weighted vs. Log loss in SciKit learn RandomSearchCV

I am sorry to ask another question regarding this topic but I am still puzzled about the following: When I use 'F1_weighted' as my scoring argument in a RandomizedSearchCV then the performance of my best model on the hold-out set is way better than when neg_log_loss is used in RandomizedSearchCV . In both cases, the brier score is approximately similar (in both training and testing ~ 0.2). However, given the current emphasise on neg_log_loss scores as cost-function it almost feels like any other scorer would be plainly wrong to use (even when the performance is better). Is this true? EDIT I To give more background on the study and the sample size: Goal is to find the top-predictors related to hospitalisation (this could be indicative of disease deterioration) --> These findings may guide new research on these predictors and are not directly intended as prognostic tool. I have a dateset that is split in X_train, X_test, where the test set is only used for predictions after hyperparameter optimisation. The classes are imbalanced (1/3 of the patients were not hospitalised and 2/3 were hospitalised) The following classifiers were considered (logistic regression with lasso, SVC with RBF or poly kernel, RF, XGBoost) RandomSearchCV with RepeatedStratifiedKFoldCV was used (10 folds, 5 repeats) I am having a hard time deciding on a appropriate scorer to optimise during RandomSearchCV --> neg_log_loss or F1_weighted. Would it make sense to bootstrap the test-set and check for the performance variance on the hold-out test set, instead of using "one" hold-out test set? The imbalance was countered by putting class_weights during randomsearchCV and the train-test split were stratified on the basis of the class imbalance. EDIT II Overview of calibration measures: F1_weighted in RandomizedSearchCV --> brier score = 0.19 (hold-out test set) & Log_loss = 0.76 (hold-out test set) Neg_log_loss in RandomizedSearchV --> brier score = 0.2 (hold-out test set) log_loss = 0.58 (hold-out test set). The log_loss in F1_weighted is way higher than in log_loss (optimalisation worked) but there is pretty much no difference in brier score?
