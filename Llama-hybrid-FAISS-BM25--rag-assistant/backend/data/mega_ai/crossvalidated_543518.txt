[site]: crossvalidated
[post_id]: 543518
[parent_id]: 543510
[tags]: 
There is the Inversion Theorem, which states that a probability density function can be derived from the Characteristic function, here are two pdf that discusses this matter with proofs https://sas.uwaterloo.ca/~dlmcleis/s901/chapt6.pdf , https://nptel.ac.in/content/storage2/courses/108106083/lecture26_CF.pdf The important is that if $C_{X}(t)$ corresponds to the characteristic function of a random variable $X$ , then you can express the density function in terms of $C_{X}(t)$ as: $$f_{X}(x)=\frac{1}{2\pi}lim_{T\rightarrow \infty} \int_{-T}^{T}e^{-itx}C_{X}(t)dt$$ So, if you prove that $\mathbb{E}[e^{itX_{2}}]= \frac{e^{\frac{i(r-r_{1})t}{(1-2it)}}}{(1-2it)^{(\theta-\theta_{1})/2}}$ Then you will know that $X_{2}$ follows your desired distribution Also, note that if $A$ and $B$ are two independent random variables then the characteristic function of their sum can be decomposed, i.e. $$\mathbb{E}[e^{it(a+b)}]=\mathbb{E}[e^{ita}]\mathbb{E}[e^{itb}]$$
