[site]: crossvalidated
[post_id]: 575090
[parent_id]: 575032
[tags]: 
One interpretation of your situation is that you have obtained a random sample $Y_1, \ldots, Y_n$ from a distribution with a finite variance, say $\sigma^2,$ but you have observed the values $X_i = Y_i + E_i$ where the variances of the "errors" $E_i$ are known. Let's refer to these error variances as $\sigma_i^2.$ One interpretation of the "error associated with the average" is that you are looking for the variance of the arithmetic mean of the $X_i.$ This mean is defined as $$\bar X = \frac{1}{n}\sum_{i=1}^n X_i = \frac{1}{n}\sum_{i=1}^n \left(Y_i + E_i\right) = \bar Y + \bar E.$$ Assuming all the values $Y_i$ and all the errors $E_j$ are uncorrelated, the laws of variances say $$\operatorname{Var}(\bar X) = \frac{1}{n^2}\sum_{i=1}^n (\operatorname{Var}(Y_i) + \operatorname{Var}(E_i)) = \frac{\sigma^2}{n} + \frac{1}{n^2}\sum_{i=1}^n \sigma_i^2.$$ Your formula for the "error" of $\bar X$ is the square root of the right hand side, neglecting the observational error variances $\sigma_i^2.$ At this point we're stuck, because we almost never assume we know $\sigma^2.$ Usually we are trying to use the observations $X_i$ to estimate it. But we can still say some things from this result, including The error of $\bar X$ exceeds the error of $\bar Y$ (which is $\sigma/\sqrt{n}$ ). Since you know or assume you know the $\sigma_i^2,$ if you can somehow obtain an estimate of $\sigma^2,$ then you can adjust it to estimate $\operatorname{Var}(\bar X).$ One subtlety is that with observations reported in the form " $X_i \pm \tau_i,$ " as in the question, it is possible that the $\tau_i$ equal the $\sigma_i,$ or $2\sigma_i,$ or $1.32 \sigma_i,$ or $1.645\sigma_i,$ or maybe even something else--I have listed only the commonest conventions. You have to rely on your source of these data to tell you what it means.
