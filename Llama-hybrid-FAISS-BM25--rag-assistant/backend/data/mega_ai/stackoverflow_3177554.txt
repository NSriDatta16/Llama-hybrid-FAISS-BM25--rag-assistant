[site]: stackoverflow
[post_id]: 3177554
[parent_id]: 3176761
[tags]: 
The very issue with your question Albert, is that there is not ONE hash table, there are many of them. The heart of the problem here is the big-O complexity given for some operations. In average a hash-table should yield O(1) complexity to find an item. A binary tree yields O(log N) in average. In term of speed, it really depends on the size of N, because those are asymptotic complexities, hence they represent order of magnitude when N is big (think million) and the real speed may be much different for small collections. So, instead of trying to elaborate more on your question, I think you should get a better grasp of hash tables. A quick overview: Hash tables may or may not be implemented in term of buckets: non-bucket implementation include open-addressing schemes (which are more cache-friendly by the way). Buckets may or may not be implemented in term of a linked-list. Other schemes include using another hash function (each bucket being a hash-table itself) or a binary tree (map), the latter requires some ordering though. Reallocation may be done at once: ie once you exceed the capacity a new (bigger) hash-table is allocated and all the content is copied or use a linear reallocation scheme to smooth the reallocating cost and avoid a big hit from time to time. Read the article on Wikipedia, it addresses these points and more.
