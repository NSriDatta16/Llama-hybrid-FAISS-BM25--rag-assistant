[site]: crossvalidated
[post_id]: 312083
[parent_id]: 
[tags]: 
Why do p-values for logistic regression coefficients not jibe with p-values for the differences in predicted probability based on those coefficients?

I am running a logistic regression based on a complex survey design. I want to know, for example, the probability of a black male from the 3rd income quintile going to jail vs. a white male from the same quintile going to jail, and I want to know if the difference in probabilities is statistically significant. The problem I'm running into is that when I calculate the p-value for any given comparison, based on the predict function, it doesn't seem to line up with the p-values presented for each coefficient from the regression readout. To simplify, here's the readout from a model without income as a variable: svyglm(formula = jailedBinary ~ sex + race, data = data.w, family = "binomial", design = addHealth) Survey design: svydesign(ids = ~data.w$CLUSTER2, data = data.w, weights = data.w$GSWGT4_2) Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -1.9700 0.1412 -13.953 My understanding is that, holding sex constant, the p-value for the difference in log odds between raceBlack and raceWhite is 1.31e-05. Next I use the predict function to get a predicted probability and a confidence interval for each pairing of race and sex (see: https://stats.idre.ucla.edu/r/dae/logit-regression/ ): newdata The printout for newdata2 looks like this: sex race link SE UL LL PredictedProb 1 Female Black -1.9699868 0.14119141 0.15534870 0.09563260 0.12239031 2 Male Black -0.5886185 0.13753092 0.42090536 0.29771993 0.35695190 3 Female White -2.5884743 0.10725691 0.08484629 0.05739458 0.06988389 4 Male White -1.2071060 0.07436215 0.25705037 0.20540387 0.23021351 This seems pretty straightforward, as the link column is just adding the coefficients to the intercept in the cases where the variable level isn’t a part of the intercept. Then PredictedProb is just converting log odds to probability. (I don’t know where the SE comes from for each specific combination of levels, though.) Next I write a (probably cumbersome) function that will let me calculate a standard error for the difference between any two predicted probabilities and then divide the difference in those means by that standard error to get a z statistic for calculating p-value (using the formula from here: http://www.bmj.com/content/343/bmj.d2304 ): cisp Now I plug in the predicted probabilities and confidence intervals (copy/paste the last from the last three columns of newdata2 ) for the two comparisons I want to make. First, black males to white males, then black females to white females: cisp(0.42090536, 0.29771993, 0.35695190, 0.25705037, 0.20540387, 0.23021351) cisp(0.15534870, 0.09563260, 0.12239031, 0.08484629, 0.05739458, 0.06988389) In the first case, I get a p-value of 0.009, and in the second case, a p-value of 0.026. This seems right, but, again, it doesn’t match up to the p-value we got for raceWhite as a variable level, which is p sex constant, Male in one case, Female in the other, and vary race , through all of the possibilities, by using the provided coefficients and the intercept. But none of the possible combinations returned a p-value close to the p-value of the raceWhite coefficient. In this example, we have statistically significant results no matter which way we look at it. But in some cases, it’s the difference between p > 0.05 and p Am I making a mistake in calculating the p-values in the predicted probability comparisons? and If not, which way is better to interpret it? That, eg. race is significant at the p Males , and p Females ? And if anybody can explain to a beginner like me where that lower p-value for the coefficient itself comes from, that would also be very awesome. Thank you so much.
