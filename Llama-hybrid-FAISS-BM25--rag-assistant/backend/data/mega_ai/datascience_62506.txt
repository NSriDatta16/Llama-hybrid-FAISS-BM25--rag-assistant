[site]: datascience
[post_id]: 62506
[parent_id]: 62493
[tags]: 
You have textual descriptions, i.e. unstructured data. So you should probably use one of the standard representation methods for text. There are many options including sentence embeddings and this kind of advanced methods, but I'm going to describe the simple traditional option: Each description value can be represented as a vector of feature, one for each word in the full vocabulary (i.e. over all the values for this field). The value of each feature can be boolean (i.e. does this word appear in this description) or better a TF-IDF weight for the word. Obviously this would lead to too many features, so one needs to apply select the most relevant ones. This part is very experimental, you might have to try various options to find the right one: Get rid of the stop words since they provide no semantic information. Discard all the words which appear only once, and probably also all the words which appear less than some minimum frequency $N$ (try with $N=2,3,4...). The rationale is that rare words are more likely to cause overfitting than to really help any kind of classification. Beyond that, you could use general feature selection (e.g. information gain) or feature clustering. [ obsolete answer to the first version of the question ] I would definitely try to normalize these values, because semantically they are numerical and in their original form they are almost useless, no matter the method to categorize them. Making them categorical loses a lot of information, especially the ones which actually provide a number. Since some of the strings used are very vague I would probably try using intervals, i.e. two numeric values for every original input value: three and a half inches, three and 1/2 inches -> min 3.4 - max 3.6 27.6234 inches -> min 27.6234 - max 27.6234 tall -> large range high values short, kinda short -> large range low values Normally there are not that many ways to give numbers as words, only a few patterns should be enough to capture all the variants. For the other non-standard cases such as "kinda short" I would start by looking in the data their distribution: if a value is frequent enough (e.g. probably "short", "tall") then manually predefined range. Values which are not frequent can be ignored, e.g. replaced with NA (since they are not frequent that shouldn't affect the data too much).
