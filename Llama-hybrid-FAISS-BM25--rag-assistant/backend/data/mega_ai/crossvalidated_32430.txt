[site]: crossvalidated
[post_id]: 32430
[parent_id]: 
[tags]: 
Two unbiased estimators for the same quantity

In several situations, I have two unbiased estimators, and I know one of them is better (lower variance) than the other. However, I would like to get as much information as possible, and I would like to do better than throwing out the weaker estimator. $$\newcommand{\Outcome}{\text{Outcome}}\newcommand{\Skill}{\text{Skill}}\newcommand{\Luck}{\text{Luck}}\Outcome = \Skill + \Luck$$ $\Outcome$ is observed. $\Skill$ is what I would like to determine. $\Luck$ is known to have the average value $0$. From other observables, I can estimate $\Luck$ by $L$ so that $\mathbb E(L) = 0$ and $\mathrm{Var}(\Luck-L) \lt \mathrm{Var}(\Luck)$. $\Outcome$ is an unbiased estimator for $\Skill$. A better estimate from variance reduction is $\Outcome - L$, which is also unbiased. For example, in one situation $\Outcome$ is the average of repeated trials, and I might produce a $95\%$ confidence interval of $[-5.0,13.0]$ without using variance reduction. Using variance reduction, I might get a confidence interval of $[-2.0,4.0]$. The typical practice is for people to use $\Outcome-L$ instead of $\Outcome$. However, this is unsatisfactory to me because in my experience, there is more information in the pair $(\Outcome, \Outcome-L)$ than in just $\Outcome-L$. Specifically, in some situations I know that if $\Outcome$ is low, then $\Outcome-L$ tends to be an underestimate for $\Skill$, and if $\Outcome$ is high, then $\Outcome-L$ tends to be an overestimate for $\Skill$. What's a good way to take advantage of the extra information from knowing both estimators?
