[site]: crossvalidated
[post_id]: 338301
[parent_id]: 
[tags]: 
Calculate classifier accuracy from per label accuracy

I would like to have a per Label accuracy and classifier level accuracy, but my calculations seem incorrect. Here is my full example. Let's say I have a multilabel classifier which predicted in the following fashion for labels [1, 2, 9, 11] PREDICTED __________________ | | 1 2 9 11 | |====|=============| T | 1 | 0 1 0 1 | R | 2 | 1 0 0 0 | U | 9 | 0 0 1 0 | E | 11 | 0 0 0 0 | ================== For each label, I have calculated the following accuracy ($\frac{TP+TN}{ TP+TN+FP+FN}$) Accuracy per Label Label : Accuracy 1 : tp:0, tn:1, fp:1, fn:2 ==> 1/4 = 0.25 2 : tp:0, tn:2, fp:1, fn:1 ==> 2/4 = 0.50 9 : tp:1, tn:3, fp:0, fn:0 ==> 4/4 = 1.00 11 : tp:0, tn:3, fp:1, fn:0 ==> 3/4 = 0.75 Therefore, How can accuracy for the classifier be calculated by using the accuracies per label? My original thought was average the results $ClassifierAccuracy = \frac{1}{4}\sum{[0.25, 0.5, 1.0, 0.75]} = 0.625$ But I know, when calculating the classifier accuracy, it would be the diagonal sum over the total. >>> X.diagonal().sum() / X.sum() 0.25 It seems like I may be double counting, but I am unsure how to calculate the result of the classifier from the label accuracies. Is this possible?
