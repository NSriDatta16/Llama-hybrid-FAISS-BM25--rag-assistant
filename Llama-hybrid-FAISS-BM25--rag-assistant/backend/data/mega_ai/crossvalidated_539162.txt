[site]: crossvalidated
[post_id]: 539162
[parent_id]: 539154
[tags]: 
The key to appreciating frequentist inference is to frame it similar to a proof by contradiction. It is by design that the p-value follows a uniform distribution under the null, i.e. $20\%$ of the time you get a p-value less than or equal to $0.2$ . It answers the question, "If this other hypothesis is true, how often would I get a result like the one I've just witnessed?" It's like playing devil's advocate. A reality check. If the p-value was not uniformly distributed under the null you would not get this reality check. There is no bias nor is there an "independent property" because the population parameters do not randomly change from one repeated experiment to the next according to anyone's belief. Bayesians have a very different way of thinking, so it is not surprising that these criticisms would be levied. Bayesian "probability" measures the belief of the experimenter, and beliefs are not facts. Any claim that the p-value overstates the evidence compared to a posterior probability is mistaking beliefs for facts. There are one-to-one analogs on everything between the two paradigms. Bayesians often criticize frequentism for not incorporating outside information into an analysis, but Bayesian updating of a prior into a posterior maps to a frequentist meta-analysis with p-values and confidence intervals [1] [2] . Bayesians often criticise frequentism for not accounting for all uncertainty in a model when making predictions, but Bayesian predictive distributions map to frequentist prediction intervals [3] . However, this one-to-one mapping is not a reason to use an unfalsifiable subjective definition of probability. Even in non-normal models, central limit theorem aside, it is possible to construct confidence intervals by inverting a hypothesis test or a cumulative distribution function to find a range of plausible values of a parameter.
