[site]: crossvalidated
[post_id]: 486384
[parent_id]: 
[tags]: 
Is it possible to normalize features by one specific feature?

I have a dataset of genes with features that describe the genes at different scales (epigenetic, protein, cell, drug data etc. all numeric data). I use this dataset in supervised ML with a xgboost regression model scoring the genes between 0 to 1 (with 1 being most likely to cause a disease and 0 being least likely). However, for genes of longer lengths they are more likely to have more data only due to their gene size and not due to them truly being more causal to the disease. This is problematic as when I condense data by taking the most significant data point per gene the longer genes will be biased due to their length (having more data points to choose from in order to have the 1 value per gene for each feature). I am looking to regulate all my features by gene length, however I am not sure how to do this. By using xgboost I cannot normalize my features as tree-based models are invariant to monotone transformations. Are there any methods of regulating/normalizing features by another specific feature? I have also tried just including gene length as a feature for the ML model to use itself but this is a difficult blackbox to interpret if the model is truly considering gene length correlations with other features as it should. edit: If I were to simply do normalization of gene length such as: genetic_feature_column_normalised = genetic_feature_column / gene_length_column Doing this so I normalise each gene's features row by row by each gene's gene length - would that be problematic at all? If this is acceptable would it mean I should or shouldn't include gene length as a feature - as maybe this normalisation could be just a preprocessing step only?
