[site]: crossvalidated
[post_id]: 427639
[parent_id]: 
[tags]: 
Bootstrapping regression coefficient for time series

One of the fundamental assumptions of bootstrap is that the samples are independent and identically distributed (i.i.d). This is the reason why it is difficult to bootstrap time-series because the random re-sampling destroys the time dependence structure of the original sample. On the other hand, I know that bootstrapping can be used for 5% ~ 95% confidence interval of regression coefficients. Here's what I understand. Let $\mathbf{x}=[x_1, x_2, x_3, ...,x_n]$ , and $\mathbf{y}=[y_1, y_2, y_3, ... y_n].$ And that the model I want to optimize is a linear model with $y_n=ax_n + b$ With bootstrap linear regression, I would do random resampling with replacement from the consistent indices of $\mathbf{x}$ and $\mathbf{y}$ , and then optimize the parameters $a$ and $b$ . Because I fit the parameters from different portions of the data, the value of $a$ and $b$ are expressed in a range. What I don't understand is that, the y-axis of a regression model is also dependent, but bootstrapping says that the samples need to be independent. And I've read many time that you can't use naive bootstrapping (other than block bootstrapping) with time series because it destroys the time dependence structure, but it seems that it's not the case if you want to fit regression coefficients on time series. How is this possible? Is there a practical difference between bootstrapping the time series to get its C.I. of the mean, and bootstrapping the time series to get the C.I. of its regression coefficients? Edit: CI of mean for time series would be something like this: Whereas CI of regression model would be:
