[site]: datascience
[post_id]: 122853
[parent_id]: 
[tags]: 
What neural network architecture would help me model a spectrogram?

I'm really a novice working with these technologies and I'm struggling to design a neural network that is powerful enough to model a spectrogram. For a personal project, I'm working on a spectrogram VAE but the convolutional networks that I've seen online seem very suboptimal at reconstructing these images. To illustrate my point, I'm trained it on a single example for about 100 epochs to see if it was able to overfit as I expected. The results are very underwhelming, and it seems barely able to model even the simple features, like the empty space and straight lines. Now, I'm wondering, is this an issue with my code/network, or are there layers besides convolution that would work better at this type of data structure? On a spectrogram, there is generally high correlation between features along the x axis and along the y axis. What do you think about using more rectangular convolutions along the x and y axis, to try to capture those relationships? Do recurrent layers like GRU work well at capturing these dependencies? I might be really misunderstanding how image construction tasks should be approached, but it seems to me that the features of this spectrogram should be easy to model with the right network. Please ask if I should give more details. I'm really just looking for some advice in what direction to continue. Here's an image of the reconstruction after 40 more epochs (it still hasn't figured out how to draw a vertical line): Here's the code defining my network. The block function is just a conv/transconv layer. The spectrograms are 128x126.
