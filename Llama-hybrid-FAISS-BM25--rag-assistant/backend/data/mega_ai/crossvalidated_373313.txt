[site]: crossvalidated
[post_id]: 373313
[parent_id]: 373167
[tags]: 
There are two possibilities by which an out-of-stock (OOS) detection model might self-derail: The relationship between inputs and OOS might change over time. For instance, promotions might lead to higher OOS (promotional sales are harder to predict than regular sales, in part because not only average sales increase, but also the variance of sales, and "harder-to-predict" translates often into OOS), but the system and its users might learn this and lay in additional stock for promotions. After a while, the original relationship between promotions and OOS does not hold any more. This is often called "model shift" or similar . You can overcome it by adapting your model. The most common way is to weight inputs differently, giving lower weight to older observations. Even if the relationship between a predictor and OOS does not change, the predictor's distribution might. For instance, multiple days with zero sales of a particular stock keeping unit (SKU) might signal an OOS - but if the model performs well, then OOS might be reduced across the board, and there might simply not be as many sequences of zero sales. Changes in the distribution of a predictor should not be a problem. Your model will simply output a lower probability of OOS. In the end, you probably don't need to worry overmuch. There will never be zero OOS. Feedback mechanisms like the ones above do occur, but they will not work until OOS are completely eradicated. Some pending OOS may simply not be avertable. "I have one unit on the shelf and will probably face a demand for five over the coming week, but the next delivery is only due a week from today." Some OOS will be very hard to predict, even if they are avertable, if they had been known in time. "If we had known we would drop the pallet off the forklift and destroy all the product, we would have ordered another one." Retailers do understand that they need to aim for a high service level, but that 100% are not achievable. People do come in and buy up your entire stock on certain products. This is hard to forecast (see above) and sufficiently rare that you do not want to fill up your shelves on the off chance this might happen. Compare Pareto's law: a service level of 80% (or even 90%) is pretty easy to achieve, but 99.9% is much harder. Some OOS are consciously allowed. Something similar to Moore's law holds: the better ML becomes, the more expectations will increase, and the harder people will make life for the model. While OOS detection (and forecasting) algorithms improve, retailers are busy making our life more difficult. For instance through variant proliferation. It's easier to detect OOS on four flavors of yoghurt than on twenty different flavors. Why? Because people don't eat five times as much yoghurt. Instead, pretty much unchanged total demand is now distributed across five times as many SKUs, and each SKU's stock is one fifth as high as before. The Long Tail is expanding, and signals are getting weaker. Or by allowing mobile checkout using your own device. This may well lower psychological barriers to shoplifting , so system inventories will be even worse than they already are , and of course, system inventories are probably the best predictor for OOS, so if they are off, the model will deteriorate. I happen to have been working in forecasting retail sales for over twelve years now, so I do have a bit of an idea about developments like this. I may be pessimistic, but I think very similar effects are at work for other ML use cases than OOS detection. Or maybe this is not pessimism: it means that problems will likely never be "solved", so there will still be work for us even decades from now.
