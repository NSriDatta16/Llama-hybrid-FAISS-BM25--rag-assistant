[site]: crossvalidated
[post_id]: 139714
[parent_id]: 22665
[tags]: 
I would suggest you take a look at this paper. It does a nice job showing the relationship between gaussian family distributions and PCA-like learner systems. http://papers.nips.cc/paper/2078-a-generalization-of-principal-components-analysis-to-the-exponential-family.pdf EDIT Synopsis : while many think of PCA from the geometric interpretation of finding the orthogonal vectors within a dataset most responsible for the variance and then providing parameters to correctly re-orient one's space to those vectors, this paper builds up PCA using exponential probability functions in the context of generalized linear models, and offers a more powerful extension of PCA for other probability functions within the exponential family. In addition, they build a PCA-like learner algorithm using bregman divergences. It's fairly easy to follow and for you, it seems like it could help you understand the link between PCA and generalized linear models. citation : Collins, Michael et al. "A Generalization of Principal Component Analysis to the Exponential Family". Neural Information Processing Systems
