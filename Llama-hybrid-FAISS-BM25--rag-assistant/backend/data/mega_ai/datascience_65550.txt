[site]: datascience
[post_id]: 65550
[parent_id]: 
[tags]: 
Fine tune gpt2 via huggingface API for domain specific LM

i am using the script in the examples folder to fine-tune the LM for a bot meant to deal with insurance related queries. So if someone were to type "i am looking to modify my ..." , the autocomplete suggestions would be " modify my name ", "modify my surname", modify my vehicle number etc My training data set has plenty of such samples BUT is always prefixed or suffixed by policy details, personal details etc which seems to be throwing off the fine-tuning and in predictions it always includes some random names , numbers /text , like "i want to modify my father's name into 1235..." Etc ..i hope u get the idea One way of dealing with this issue would be to clean up the training dataset using some NER and get rid of specific information (not very impressive) or maybe unfreeze some other layers of the gpt2 model. Tried exploring the API but it simply allows loading pre trained wirghts and explicitly unfreezes only the last classification layer (?) ..any pointers on resolving this would be extremely helpful.. appreciate any inputs
