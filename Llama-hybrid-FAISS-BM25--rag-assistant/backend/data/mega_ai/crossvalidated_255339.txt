[site]: crossvalidated
[post_id]: 255339
[parent_id]: 
[tags]: 
How to See Heteroskedasticity in Simple Linear Regression of Time Series Data

This is my first post on Cross Validated. I'm fascinated by statistics, but still trying to build a better knowledge base. I'm doing a simple linear regression where I'm trying to predict one time series from another. I ran an Augmented Dickey Fuller test and confirmed that both time series are stationary. So, from my research I believe the linear regression is appropriate (as opposed to cointegration). My main concern is that the residuals look like they might be heteroskedastic. I know for linear regressions on non-time series data you can see the triangle on the residuals scatter plot, but since this is time series data, there is only one residual per point in time. But it looks like the variance increases toward the end of the the chart below: I also did the Durbin Watson Test and found that (as the plot implies) there is serial positive correlation in the errors. I'm pretty sure I can correct that with the Hansen method (based just on what I've read). Any thoughts or pointers about if heteroskedasticity is a problem here? Do you see any huge errors in the whole procedure (like I said, I'm really new to this)?
