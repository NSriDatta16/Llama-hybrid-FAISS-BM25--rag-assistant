[site]: crossvalidated
[post_id]: 174800
[parent_id]: 174509
[tags]: 
I want to put my own answer here, both for my own reference and also for others that stumble upon this question. I have been thinking about this for a while now... and it was fun! The reason why this is an important question and why it is of interest to look into this is because this problem is tightly related to studying the properties of resampling techniques, such as bootstrapping . You can think about your problem in a way of buckets and balls. I.e. you have $d$ buckets ( which represent the different cards ) and you can throw $n$ balls ( balls represent the draw of a card ) into the buckets. The number of balls that fall into bucket $i$ is a random variable $X_i$. Now you have a random vector $\mathbf{Z}=(X_1,X_2,...,X_d)$ which has the property that $\sum_{i=1}^d X_i = n$. This random vector follows a uniform multinomial distribution . Uniform means that there is equal probability of throwing a ball into each bucket, i.e. $\frac{1}{d}$. Now we can define another random variable $M=\max(\mathbf{Z})$. Your question can now be reformulated as, how can we find the probability mass function of $M$? After laying under fur for a couple of days I have not yet managed to find an explicit formula for the probability mass function, and I was starting to think that it may not even exist. This MO question asks exactly about this reformulation of the question which refers to this paper , which is essentially an algorithm to calculate this, but not an explicit formula. Even calculating the expectation of $M$ is only achieved via bounds. So there do exist bounds that might give you rough estimates but getting an explicit formula is a significantly harder problem. The solution presented by @jlimahaverford is an algorithm which is created via a recurrence relation. It is not any simple recurrence relation, so I am not sure if that can be reduced to an explicit formula, but that is probably a good start if someone wants to try it. After my search, I think that his solution is one of the more elegant ways I have seen to do this. So hats of to him! But! There is a way to get the exact distribution and it is presented in this paper .
