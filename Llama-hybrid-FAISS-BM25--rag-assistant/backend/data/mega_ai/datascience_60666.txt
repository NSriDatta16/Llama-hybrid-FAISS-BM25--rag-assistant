[site]: datascience
[post_id]: 60666
[parent_id]: 56135
[tags]: 
I would try using xgboost classifier. In my case, xgboost outperformed Random Forest. import xgboost as xgb xgb_model = xgb.XGBClassifier( learning_rate=0.1, n_estimators=1000, max_depth=3, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27) You can use the below snippet to avoid over fitting problem. xgb_model = xgb_model.fit(X_train, y_train.astype(int), early_stopping_rounds=50, eval_set=[(X_test, y_test['target'])])
