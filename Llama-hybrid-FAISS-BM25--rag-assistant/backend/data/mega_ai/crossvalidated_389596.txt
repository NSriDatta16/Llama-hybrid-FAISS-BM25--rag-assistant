[site]: crossvalidated
[post_id]: 389596
[parent_id]: 250278
[tags]: 
You need (maybe ...) interval level data to compute a (Pearson) correlation, but the correlation coefficient itself is a unitless number, and it is not clear that characterizing it by level of measurement is useful. If it can be used as predictor in a regression model is a more pragmatic choice, and you didn't tell us the context, so we have nothing to say. But I cannot understand that it should be prohibited to use . That would need quite strong arguments. Otherwise, there is much wisdom in some of the comments, so I will just copy them here: "It is clear that correlations are not normally distributed, and it is also clear that they are bounded (by +/- 1, obviously) both of which require transforming them before using them in a regression model." Not so. There is no objection to bounded or non-normal predictors in regression. If there were, then using indicator variables would be out of court, but it is utterly standard . There is no objection to non-normal responses as such. If you are trying to predict correlations, there could be a case for predicting them using e.g. Fisher's z as a scale. â€“ Nick Cox You say in another comment that As practice goes, people usually do prefer to enter correlations under the Fisher transform when building regression models due to the boundedness on Pearson's r . If this is intended as a comment about its use as predictor , it is difficult to see any good reason. How would you interpret the resulting coefficients?
