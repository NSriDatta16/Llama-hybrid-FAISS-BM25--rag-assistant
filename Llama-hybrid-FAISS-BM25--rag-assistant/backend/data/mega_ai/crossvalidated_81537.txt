[site]: crossvalidated
[post_id]: 81537
[parent_id]: 
[tags]: 
Gridsearch for SVM parameter estimation

I'm currently experimenting with gridsearch to train a support vector machine. I understand that, if I have parameter gamma and C, the R function tune.svm performs a 10-fold cross validation for all combinations of these 2 parameters. Since I did not know how to start, I tried to get some information about it, for example wikipedia 2 suggests values that are not linear, e.g. C in the range {10, 100, 1000}. So far I use the examples from my second wikipedia link, which is: gammas = 2^(-15:3) costs = 2^(-5:15) Which results into 399 combinations. This takes very, very long (~2000 samples). For example for the kernel "radial" my best result is gamma = 0.5 and cost = 2. Couldn't I get the same result if I just used values like (1, 2, 3, 4, ... 10) for costs and (0, 0.5, 1, 1.5, 2) for gammas? I know this example is constructed because I already know the result. My question: But why this exponential scale? There are so many values between 0 and 1 that I think this is a waste of computation time and only so few very big numbers that it couldn't find a very exact result anyway. It would only make sense for me if this was used to find a smaller range, let's say we then know the best cost is 2^3 and then we search around that. But it's nowhere mentioned that is performed that way.
