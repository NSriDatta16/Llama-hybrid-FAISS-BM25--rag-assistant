[site]: crossvalidated
[post_id]: 353544
[parent_id]: 
[tags]: 
General form of a machine learning algorithm

This is the general function that represent any machine learning algorithm: $Y=f(X)+\epsilon$ , where $Y$ is the dependent variable, $X$ is the independent variable and $\epsilon$ is the random error term. I have some doubts about this formula : 1) Do the Y and X represent the input and output of a computed machine learning model ? Or are they intended to be understood as properties of the real event that we want to model ? 2) According to this equation, if i use the same input many times i can get different values of Y. Is this true ? Thanks
