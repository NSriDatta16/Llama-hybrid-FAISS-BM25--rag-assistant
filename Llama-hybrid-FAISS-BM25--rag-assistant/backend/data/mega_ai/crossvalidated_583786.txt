[site]: crossvalidated
[post_id]: 583786
[parent_id]: 
[tags]: 
consistent gap between training and validation metrics

I am training a neural network (Deep and cross network) for a multi-label classification task (~700 labels). I am seeing a uniform gap between training and validation results on various metrics. E.g. see the graphs below. What are the potential explanations for such phenomenon? My conjecture would be some sort of information leakage issue, but I double checked the data and re-did train/test/validation split and the gaps persisted.
