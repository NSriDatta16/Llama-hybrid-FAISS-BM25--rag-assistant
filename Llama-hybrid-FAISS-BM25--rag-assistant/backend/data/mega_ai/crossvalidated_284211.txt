[site]: crossvalidated
[post_id]: 284211
[parent_id]: 
[tags]: 
How to force a neural network to have Gaussian hidden activations

Let the task be classification and the neural network under discussion to have Sigmoid activation functions and be trained by Backpropagation and SGD. How can I force the networks hidden activations to be normally distributed for each class while using gradient descent? The idea is to simplify statistical analysis with only slight degradation of performance.
