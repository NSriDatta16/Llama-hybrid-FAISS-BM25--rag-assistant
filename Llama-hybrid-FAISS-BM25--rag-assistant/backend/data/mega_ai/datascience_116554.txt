[site]: datascience
[post_id]: 116554
[parent_id]: 
[tags]: 
Create ML model from dataframe with small number of rows

I have a dataframe with 50 rows (one row for each US state), and about 20 columns with different attributes with state related data. I'm looking to build a linear regression model to predict prevalence of diseases given the different state's attributes and prevalences. For example, predictor variable would be depression prevalence, and variables I'm using to predict are number of sunny days per year and average precipitation per year. Let's say state 1 has 18% depression rate, 200 sunny days per year, and 10 inches precipitation per year. And state 2 has 8 % depression rate, 300 sunny days per year and 3 inches precipitation per year, etc. If the trend is more sunny days and less precipitation correlates with lower depression prevalences, I would use number of sunny days and inches of precipitation to predict depression prevalence. The only data I have is per state but I'm using that state related data to a) see correlation with weather and mental wellbeing, and b) predict the prevalence of illnesses given the weather features. I'm pretty new to machine learning and model building and I'm not sure if creating a train/test set for such a small number of rows would give accurate results. Would what I'm trying to do work? What's the best way to go about this? Any help would be greatly appreciated! With what I tried, my linear regression model doesn't seem super accurate (but I may just be building that wrong)
