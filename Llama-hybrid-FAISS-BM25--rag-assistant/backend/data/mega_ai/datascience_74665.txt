[site]: datascience
[post_id]: 74665
[parent_id]: 74661
[tags]: 
Unfortunately, there is no direct way to assess the "importance" of a variable in a Neural Network. One option, very time consuming, consists in removing each variable, one by one, replacing it with random noise, and checking how the performance changes. That will give you an idea on the contribution of a variable. Alternatively, stick with importance scores of Tree-based models (such as Random Forests), or with good old statistical analysis. Shapley value regressions are a famous example.
