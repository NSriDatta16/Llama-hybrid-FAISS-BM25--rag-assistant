[site]: crossvalidated
[post_id]: 611223
[parent_id]: 
[tags]: 
Large sample limit of linear and ridge regression

I wanted to check if these reasonings are correct. The formula for a multilinear regression, input $X_{s,i}$ , where $s$ is the sample and $i$ the features, and output $Y$ , is given by: $$\beta=(X^+X)^{-1}X^+Y$$ Now if we define: $Q_{ij}=\sum_s X_{si}X_{sj}, M_j=\sum_s X_{js}Y_s$ than the equation is equivalent to: $$\beta_i=\sum_{j} [Q^{-1}]_{ij}M_{j}$$ Now we can add the number of samples into this formula $N_s$ : $$\beta_i=\sum_{j} [Q/N_s]^{-1}_{ij}[M/N_s]_{j}$$ and observe that we have some sample averages: $Q_{ij}/N_s=\sum_s \left( X_{si}X_{sj}\right) /N_s \rightarrow E[X_iX_j]$ and: $M_j/N_s=\sum_s \left( X_{js}Y_s \right)/N_s \rightarrow E[X_jY]$ , so that in the large sample limit we expect: $$\beta_i \rightarrow (E[X_*X_*])_{i,j}^{-1}E[X_jY]$$ Question 1. Is this result expected/trivial/correct ? Now we can try to get a large sample limit for Ridge regression. Looking at internet this implies that $Q$ must be replaced with $Q+\lambda I$ and the formula becomes, after inserting as before the number of samples: $$\beta^R_i=\sum_{j} [(Q+\lambda I)/N_s]^{-1}_{ij}[M/N_s]_{j}$$ But here it looks that as before: $(Q+\lambda I)/N_s \rightarrow Q/N_s \rightarrow E[X_iX_j]$ because the added factor becomes negligible. If we want to have a different limit we should have $\lambda$ scaling with the samples : $\lambda=\rho N_s$ and in this case: $(Q+\rho N_s I)/N_s \rightarrow Q/N_s \rightarrow E[X_iX_j]+\rho I$ , so that: $$ \beta^R_i \rightarrow (E[X_*X_*]+\rho I)_{i,j}^{-1}E[X_jY] $$ Question 2. Is this result expected/trivial/correct ? Question 3. If yes, is it correct that the ridge regression factor should scale with $N_s$ to get a finite value ? Question 4. Can we understand something about the behavior of Ridge regression looking at the large sample limit formulas?
