[site]: crossvalidated
[post_id]: 314249
[parent_id]: 314241
[tags]: 
This question is a bit subjective. Anyway, I do not think that you can/should assume theft based on such statistical numbers (So Q1: no it is not a 'very objective' valid way). But for sure you can use it to see where relatively more or less generous behavior occurs (without making a statement of good/bad). Sklearn seems good if you have sufficient data. In that case you won't need to make a model yourself which may be difficult/impossible/subjective/etc Take care that The data collection is done carefully. Sufficient confounding variables are taken care of (Q2: So yes you should "normalize" somehow. I believe if you add factors to your classification problem then the normalizing thing is dealt with. For specific details you should re-ask or update your question). You do not fall into the trap of the prosecutor's fallacy While this answer is quite general, and does not give you a specific solution (which I believe is difficult), I would like to add a link to a legal case that has some connections with your problem and is very interesting to read since it provides very good insights into careful statistical thinking. Several errors and simplifications had been made in that legal case, and there is lots of subjectivity behind the numbers and calculations with different views (such as Bayesian probabilities) providing completely different outcomes. 'Elementary Statistics on Trial (the case of Lucia de Berk)' 2010 by Gill, Groeneboom and de Jong 'On the (ab)use of statistics in the legal case against the nurse Lucia de B' 2006 by Meester, Collins, Gill and van Lambalgen
