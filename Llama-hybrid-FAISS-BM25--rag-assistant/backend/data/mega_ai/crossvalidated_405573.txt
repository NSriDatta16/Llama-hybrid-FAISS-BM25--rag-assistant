[site]: crossvalidated
[post_id]: 405573
[parent_id]: 404607
[tags]: 
Right now you are fitting a normal spline and hope that it will turn out monotone. Ideally you would fit a spline which would be monotone by definition. The requirements for monotonicity of a piece-wise linear spline are complicated. It is much simpler for the I-splines . They produce a monotone fitted curve if all the regression coefficients are non-negative. For example look at the I-splines of order 1 (which is basically just a reparameterization of the standard piece-wise linear splines): $$ b_k^{I\text{-spline}}(x)=\begin{cases} \frac{1}{\xi_{k+1}-\xi_k} (x-\xi_k)_+ \quad &\text{for }x A curve fitted with those splines are clearly non-decreasing if and only if all regression coefficients are non-negative. However, constraining parameters in the optimization process is not easy/common. In R, there are - to my knowledge - only a few packages that optimizes some regression types with constraints; nnls handles least squares regression and addreg handles poisson, binomial and negative binomial (only with identity link). I am afraid you will have to implement non-negative logistic regression yourself if you want to use it. You also suggest leaving out the last spline. It is equivalent to removing the last knot from the splines, which would not be bad; the fitted curve would still be piecewise linear and interpretable using the remaining knots. The biggest problem is the (small) model selection bias that arises from rejecting the first model with all knots. So if removing the last knot (and rerunning the analysis) luckily produces a monotone fitted curve, I think you can use it.
