[site]: crossvalidated
[post_id]: 87234
[parent_id]: 
[tags]: 
AIC values and their use in stepwise model selection for a simple linear regression

The Wikipedia article for AIC says the following (emphasis added): As an example, suppose that there were three models in the candidate set, with AIC values 100, 102, and 110. Then the second model is exp((100−102)/2) = 0.368 times as probable as the first model to minimize the information loss, and the third model is exp((100−110)/2) = 0.007 times as probable as the first model to minimize the information loss. In this example, we would omit the third model from further consideration. We then have three options: (1) we could decide to gather more data, in the hope that this will allow clearly distinguishing between the first two models; (2) we could simply conclude that the data is insufficient to support selecting one model from among the first two; (3) we could take a weighted average of the first two models, with weights 1 and 0.368, respectively, and then do statistical inference based on the weighted multimodel. However, a video discussing the stepwise method for model selection in R removes the smallest AIC value . It may be that I am grossly misunderstanding something in between how AIC works and how AIC is applied. Could anyone explain why we would not want to select the largest value in the video as was done in the Wikipedia example?
