[site]: crossvalidated
[post_id]: 582570
[parent_id]: 581482
[tags]: 
I would not say so. The idea behind ensembles is that the errors ML models make are in part systematic and in part random. When we train different classifiers for ensembling, we assume that the random part of the error will zero out and will get a better result. All the models in the ensemble do the same thing, but with a different random error. The intuition behind multi-headed attention is quite the opposite. It is there to allow each head to focus on a different type of information in the attention input representation. In NLP, there is a lot of literature on what the attention heads do: they can look at syntactically related words, some heads can look at surrounding words, and some heads can emulate coreference chains (see e.g., Chapter 5 of this book ). When trained correctly, each head should do a different thing.
