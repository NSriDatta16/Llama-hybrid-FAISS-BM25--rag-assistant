[site]: crossvalidated
[post_id]: 159632
[parent_id]: 159267
[tags]: 
Here is a compilation and expansion of some of my comments, which should be worthy of being an answer. This can basically be solved as a simulation optimization problem. It's "easy" due to only be one dimensional, since per the comments, x is a scalar (as are all the input parameters). Step 1 is to write a stochastic (Monte Carlo) simulation routine to evaluate the expectation. Steps 2 and preferably 3 are to do the same for the first and second derivatives. You ought to be able to differentiate "under the integral", i.e., d/dx(E(f(x)) = E(d/dx(f(x)). That lets you avoid using finite differences, which is a good thing to do. Two sources of error is no problem. That's handled in the simulation. I am guessing that eta and epsilon are independent. But if not, that's not a problem either - just generate dependent pairs of (eta, epsilon) in the simulation. You want to use common random numbers across objective function and derivative evaluations for all values of x encountered in the optimization. That is THE MOST IMPORTANT thing to do. There should be extremely high correlation in this simulation, so common random numbers will be of huge benefit to the optimization, and may reduce the needed number of simulation replications, per value of x, by orders of magnitude. Then you should use a robustified safeguarded Newton or steepest descent algorithm on this. I'm not going to tell you how to do the robustification (see next paragraph). Gradient descent is not a very good or robust algorithm for this problem. Gradient descent should be a LAST resort, never a first resort. Gradient descent MAY NOT DESCEND, It is misnamed. Descent algorithms need to safeguard to ensure descent. But with noisy function evaluation you can never get a perfect guarantee, but there are ways to robustify. I won't provide the details here as I'm not ready yet to share with the world in the current state of development. I don't think anyone is going to be providing an (anywhere close to accurate) closed form solution in terms of the parameters. The parameter values are needed to generate a concrete solution. The local extrema landscape and character of the problem could potentially change depending on the values of he parameters. There are no a priori guarantees on whether there is only one local minimum, or multiple local minima with different objective values, and that may depend on the values of the various input parameters. I might be able to figure that out to high confidence in the course of solving.
