[site]: crossvalidated
[post_id]: 497273
[parent_id]: 
[tags]: 
Variance-bias tradeoff problem and how Bayesian and non-Bayesian approaches perform in a big data setting

When it comes to deal with the variance-bias tradeoff issue, I assume that bias is automatically induced in the Bayesian approach just from using a prior, while non-Bayesian approaches use math to determine whether a particular estimator is biased or not. Now comes big data, which may solve the variance-bias tradeoff issue. My question is, is it possible to formulate a general principle on the performance of Bayesian and non-Bayesian approaches when dealing with the variance-bias tradeoff issue in a big data setting? I.e. one outperforms the other (solves the issue faster) for the same model complexity?
