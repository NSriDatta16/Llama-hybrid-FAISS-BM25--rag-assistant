[site]: datascience
[post_id]: 53796
[parent_id]: 53527
[tags]: 
Obviously, without knowing the exact data, everything I will say is mere speculations. Here are some of my guesses why this might happen: Your production data has a different distribution from your training data This can happen, data analysis would be required to double check how your production data might deviate. If this is the case, I would investigate what might cause this, is it something you can adapt to? Or is it due to an external factor you can measure? Your network is too large and overfitted artifacts in training If your network is large, you might have overfitted on certain artifacts that are present in your train and test set and therefore, it performs badly on your production data. I would train smaller networks or on many smaller snapshots to double check that your model can learn appropriately. Your evaluation method is not appropriate When training time series, make sure to always evaluate on future data and not past (that's cheating!) Bugs Obviously, bugs may always be the cause of some issues. Maybe preprocessing is doing something funky.
