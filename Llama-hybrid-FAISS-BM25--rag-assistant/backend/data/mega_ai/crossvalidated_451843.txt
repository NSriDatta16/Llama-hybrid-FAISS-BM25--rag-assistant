[site]: crossvalidated
[post_id]: 451843
[parent_id]: 
[tags]: 
Validating model in a small dataset (n = 40) with overloaded feature engineering

I am using a small dataset of 40 subjects, each subject is an imaging temporal sequence. I extract imaging texture features for each timeframe and then I analyze temporal sequences of each feature by means of frequency transformations (fft,dct,kurtosis, skewness...) . I obtain 30000 features per subject. All features are scaled between 0 and 1. Then I apply cross validation with a simple decision stump and decision tree of depth 3, obtaining leave one out cross validation scores of 0.9 for the decision stump and 0.83 for the decision tree. Other models without parameter tuning work worse. Average 10-fold cross-validation over 50 random seeds is 0.86 for depth 1 and 0.82 for depth 3. How can I check the integrity of the experiment? An example of a decision tree with depth 2 obtained:
