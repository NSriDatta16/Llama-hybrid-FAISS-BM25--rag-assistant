[site]: datascience
[post_id]: 61680
[parent_id]: 
[tags]: 
Keras - Autoencoder different from Encoder + Decoder

I build a CNN 1d Autoencoder in Keras, following the advice in this SO question , where Encoder and Decoder are separated. My goal is to re-use the decoder, once the Autoencoder has been trained. The central layer of my Autoencoder is a Dense layer, because I would like to learn it afterwards. My problem is that if I compile and fit the whole Autoencoder, written as Decoder()Encoder()(x) where x is the input, I get a different prediction when I do autoencoder.predict(training_set) w.r.t. if I first encode the training set in a set of central features, and then let the decoder decode them. These two approaches should give identical answers, once the Autoencoder has been trained. from tensorflow.keras.layers import Input, Dense, BatchNormalization, Flatten, Lambda, Activation, Conv1D, MaxPooling1D, UpSampling1D, Reshape from tensorflow.keras.models import Model from tensorflow.keras import optimizers from tensorflow.keras.layers import GaussianNoise import keras.backend as K from tensorflow.keras.layers import Add import tensorflow as tf import scipy.io import sys import matplotlib.pyplot as plt import numpy as np import copy training = # some training set, 1500 samples of 501 point each testing = # some testing set, 500 samples of 501 point each # reshaping for CNN training = np.reshape(training, [1500, 501, 1]) testing = np.reshape(testing, [500, 501, 1]) # normalize input X_mean = training.mean() oscillations -= X_mean X_std = training.std() training /= X_std copy_of_test = copy.copy(testing) testing -= X_mean testing /= X_std ### MODEL ### def Encoder(): encoder_input = Input(batch_shape=(None, 501, 1)) e1 = Conv1D(256,3, activation='tanh', padding='valid')(encoder_input) e2 = MaxPooling1D(2)(e1) e3 = Conv1D(32,3, activation='tanh', padding='valid')(e2) e4 = MaxPooling1D(2)(e3) e5 = Flatten()(e4) encoded = Dense(32,activation = 'tanh')(e5) return Model(encoder_input, encoded) def Decoder(): encoded_input = Input(shape=(32,)) encoded_reshaped = Reshape((32,1))(encoded_input) d1 = Conv1D(32, 3, activation='tanh', padding='valid', name='decod_conv1d_1')(encoded_reshaped) d2 = UpSampling1D(2, name='decod_upsampling1d_1')(d1) d3 = Conv1D(256, 3, activation='tanh', padding='valid', name='decod_conv1d_2')(d2) d4 = UpSampling1D(2, name='decod_upsampling1d_2')(d3) d5 = Flatten(name='decod_flatten')(d4) d6 = Dense(501, name='decod_dense1')(d5) decoded = Reshape((501,1), name='decod_reshape')(d6) return Model(encoded_input, decoded) # define input to the model: x = Input(batch_shape=(None, 501, 1)) y = Input(shape=(32,)) # make the model: autoencoder = Model(x, Decoder()(Encoder()(x))) # compile the model: autoencoder.compile(optimizer='adam', loss='mse') for layer in autoencoder.layers: print(K.int_shape(layer.output)) epochs = 100 batch_size = 100 validation_split = 0.2 # train the model history = autoencoder.fit(x = training, y = training, epochs=epochs, batch_size=batch_size, validation_split=validation_split) # Encoder encoder = Model(inputs=x, outputs=Encoder()(x), name='encoder') print('enc:') for layer in encoder.layers: print(K.int_shape(layer.output)) features = encoder.predict(training) # features # Decoder decoder = Model(inputs=y, outputs=Decoder()(y), name='decoder') print('dec:') for layer in decoder.layers: print(K.int_shape(layer.output)) score = decoder.predict(features) # score = np.squeeze(score) predictions = autoencoder.predict(training) predictions = np.squeeze(predictions) # plotting one random case # score should be equal to predictions! # because score is obtained from the trained decoder acting on the encoded features, while predictions are obtained form the Autoencoder acting on the training set plt.plot(score[100], label='eD') plt.plot(predictions[100], label='AE') plt.legend() plt.show() plt.close()
