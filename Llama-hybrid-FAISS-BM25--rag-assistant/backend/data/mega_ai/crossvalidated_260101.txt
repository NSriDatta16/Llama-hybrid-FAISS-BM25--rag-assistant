[site]: crossvalidated
[post_id]: 260101
[parent_id]: 199605
[tags]: 
Let me explain first, why do we need Reparameterization trick in VAE. VAE has encoder and decoder. Decoder randomly samples from true posterior Z~ q(z∣ϕ,x) . To implement encoder and decoder as a neural network, you need to backpropogate through random sampling and that is the problem because backpropogation cannot flow through random node; to overcome this obstacle, we use reparameterization trick . Now lets come to trick. Since our posterior is normally distributed, we can approximate it with another normal distribution . We approximate Z with normally distributed ε . But how this is relevant ? Now instead of saying that Z is sampled from q(z∣ϕ,x) , we can say Z is a function that takes parameter (ε,( µ, L)) and these µ, L comes from upper neural network (encoder). Therefore while backpropogation all we need is partial derivatives w.r.t. µ, L and ε is irrelevant for taking derivatives.
