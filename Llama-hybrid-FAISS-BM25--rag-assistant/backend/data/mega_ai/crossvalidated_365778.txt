[site]: crossvalidated
[post_id]: 365778
[parent_id]: 
[tags]: 
What should I do when my neural network doesn't generalize well?

I'm training a neural network and the training loss decreases, but the validation loss doesn't, or it decreases much less than what I would expect, based on references or experiments with very similar architectures and data. How can I fix this? As for question What should I do when my neural network doesn't learn? to which this question is inspired, the question is intentionally left general so that other questions about how to reduce the generalization error of a neural network down to a level which has been proved to be attainable , can be closed as duplicates of this one. See also dedicated thread on Meta: Is there a generic question to which we can redirect questions of the type "why does my neural network not generalize well?"
