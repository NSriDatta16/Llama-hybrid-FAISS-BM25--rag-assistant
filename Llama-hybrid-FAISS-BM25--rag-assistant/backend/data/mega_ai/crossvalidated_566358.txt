[site]: crossvalidated
[post_id]: 566358
[parent_id]: 
[tags]: 
Is parallel trends assumption necessary in difference-in-differences analysis?

Reading the literature on the subject, I haven't encountered clear reasoning why the parallel trends assumption must hold. In fact, there have been recent papers on ways to relax this assumption (see Rambachan and Roth (2019) , Bilinski and Hatfield (2019) , Freyaldenhoven, et al. (2019) ). To me, it seems like the parallel trends assumption is solving a problem that doesn't exist. The goal in DiD analysis is to estimate the average treatment effect on the treated, either as an absolute change or percentage change. Does it matter if the baseline means and trends for the outcomes differ for the treatment and control groups, if we're only interested in comparing the changes in those trends in the post-treatment time period? For example, consider the following statistically significant linear trends for made-up monthly medical cost data (with unspecified but unequal intercepts): $$ \begin{array}{c|lcr} \text{Period} & \text{Control group} & \text{Treatment group} \\ \hline \text{Pre} & y_{ctrl} = \beta_0 + 10*t & y_{trmt} = \beta_2 + 20*t \\ \text{Post} & y_{ctrl} = \beta_1 + 15*t & y_{trmt} = \beta_3 + 25*t \\ \end{array} $$ The pre/post trend in cost increases by 50% in the Control group and increases by 25% in the Treatment group. The baseline trends are not the same but we're still seeing a significantly lower pre/post trend change for the Treatment group.
