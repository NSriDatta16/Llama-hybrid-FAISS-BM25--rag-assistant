[site]: stackoverflow
[post_id]: 2649483
[parent_id]: 2649324
[tags]: 
Actually, there are plenty of languages where the types of variables arent known at compile-time. This does tend to add some run-time overhead though. To answer your first question, I think you're getting hung up on the name "char". The char type is a one byte integer in C (actually not quite true- it's an integral type large enough to hold any character from the basic character set, but its size is implementation dependent.) Note that you can have both signed chars and unsigned chars, something that doesn't make a lot of sense if you're talking about a data type that only holds characters. But the one byte integer is called "char" in C because that's the most common use for it (again see disclaimer above.) The rest of your question covers a lot of ground- might have been better to break this up into a few questions. Like the char type wchar_t's size is implementation dependent- the only requirement is that it be large enough to hold any wide character. It's important to understand that Unicode, and character encodings in general are actually independent of the C language. It's also important to understand that character sets are not the same thing as character encodings. Here's an article (by one of SO's founders, I believe) that gives a brief intro to character sets and encodings: http://www.joelonsoftware.com/articles/Unicode.html . Once you have a better understanding of how they work you'll be in a better position to formulate some questions for yourself. Do note that a lot of character sets (the Windows code page, for instance) only require a single byte of storage.
