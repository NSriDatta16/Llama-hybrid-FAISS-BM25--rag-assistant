[site]: datascience
[post_id]: 119926
[parent_id]: 118913
[tags]: 
In a random forest classifier, there is no backpropagated loss. Instead, the N trees are grown independently from each other and then, for a new prediction, a majority vote is performed among all N outcomes. The only function that is used at each split is the Entropy / Information Gain, but this function uses the entire training subset available for the growing of each tree and does not have any learning component.
