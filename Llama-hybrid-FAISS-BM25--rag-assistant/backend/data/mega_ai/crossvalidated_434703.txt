[site]: crossvalidated
[post_id]: 434703
[parent_id]: 434697
[tags]: 
There are many predictive models for binary classification, but yes, logistic regression augmented with a decision rule is one way to go about it. But it seems you have some slight misunderstandings with respect to how to apply it. So, I can create a logistic model, and feed it records of doctors who have been observed to switch from Drug A to Drug B. Yes, but you'll also want to feed it the records of doctors who have NOT switched. The model needs to learn what values of the independent variable are typically associated with switching and what values are typically associated with not switching. But I don't really care about who has switched. I already know that since I have the data. I want to know who is likely to switch in the future. You care about them in the sense that they will teach your model what switchers and non-switchers looks like, so that it can predict future outcomes After you've trained the model on data with known outcomes, you can apply it to unknown cases, the model will spit out a probability, and then you can decide what to do with that probability. This is really where the logistic regression model ends. If you need to spit out a binary "will switch" or "will not switch", you're stepping outside the bounds of the probability model , but obviously people do it all the time. So: data cleaning → model fitting → model diagnostics → (if model is good) apply to unknowns → make binary decision if you have to
