[site]: crossvalidated
[post_id]: 268546
[parent_id]: 
[tags]: 
Understanding how sensitive a model is to a predictor only implicitly part of the model

Suppose one has a GLM, say logistic regression, y~x1+...+x8 , where y is a binary variable. In my particular problem-space, y represents a customer defaulting on a loan. Half of the predictors are individual customer data (say x1-x4) and the other half (x5-x8) are macroeconomic variables, possibly with some multicollinearity. While none of the macroeconomic variables are exactly the interest rate, some of them are dependent on it or correlate with it. For example, suppose x5 = customer-interest-rate - risk-free-interest. Suppose that I am quite happy with the model and it seems to perform well when validated with bootstrap/CV/forward-chaining, etc, with a proper scoring rule. The problem is that while my initial goal was prediction , I am now being asked by the-powers-that-be to demonstrate the sensitivity of the model, assuming it is true, to changes in the risk-free-interest rate . That is, they would like to be able to simulate interest rate scenarios and judge how stable the model is under these scenarios. This seems like a difficult problem... Is there any principled way to ask this question of the model, without jointly forecasting all of the macroeconomic variables x5-x8? If it helps, I have massive data and can construct my model in such a way as to make this question easier to answer. I would prefer not to sacrifice prediction very much for interpretability, if possible. One possibility I considered was to approximate this model by a simpler model with the risk-free-interest rate, but this doesn't seem intuitive to me. Any thoughts?
