[site]: crossvalidated
[post_id]: 408150
[parent_id]: 
[tags]: 
Bayesian methods are about averaging over uncertainty rather than optimization. Explain?

I came across the statement "The key ingredient in Bayesian methods is to average over your uncertain variables and parameters, rather than to optimize". Can someone explain why this is? My confusion is that in Bayesian model selection, if you compute the model evidence, surely that involves some element of optimization... you then compute the posterior probability to get the Bayes factor, for example, but it seems there is some element of optimization still. Is this incorrect?
