[site]: crossvalidated
[post_id]: 593367
[parent_id]: 377697
[tags]: 
Your question relates to the variance of the residual vector in multiple linear regression and the resultant studentised residuals (see related answers here and here for some useful discussion on this topic). Under OLS estimation the conditional variance of the (raw) residuals can be shown to be: $$\mathbb{V}(R_i|\mathbf{x}) = \sigma^2 (1-L_i),$$ where $L_i \equiv [\mathbf{h}]_{i,i}$ is the leverage value for the data point, which is the $i$ th diagonal entry of the hat matrix $\mathbf{h}$ . We "studentise" the residuals by dividing the raw residuals by their estimated standard deviation: $$R_{i, \text{Stud}} = \frac{R_i}{\hat{\sigma} \sqrt{1-L_i}}.$$ As in other contexts, the "studentisation" divides the initial quantity by an estimate of its standard deviation, so that it is roughly standardised. This involves estimation of the error variance in the regression, so it is not as perfect as "standardisation" but it is the best we can do since the true error variance is unknown. It is worth noting that there are actually two main kinds of studentised residuals corresponding to two kinds of estimators used for the error variance. The internally studentised residuals use the standard MSE estimator for the error variance, whereas the externally studentised residuals use an estimator that removes the $i$ th data point. Both of these types of residuals roughly adjust for the variance of the raw residuals. (The externally studentised residuals have slightly cleaner statistical properties, since the numerator and denominator are independent; for large samples there is little difference between the two.)
