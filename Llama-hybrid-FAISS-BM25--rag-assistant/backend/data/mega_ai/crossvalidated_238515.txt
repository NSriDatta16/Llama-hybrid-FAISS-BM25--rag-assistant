[site]: crossvalidated
[post_id]: 238515
[parent_id]: 238485
[tags]: 
You can make two different kinds of features from the file names. Use BoW on the file names. The tokenizer in TFIDF is set such that it extracts each words separated by / or . or _. Remember that there should be no stop words. Try with small values of n-grams like unigram or bigram. The other feature to use will be letter tokens. This will help capture the A, B, D etc. in each file names. You'll have to use tokenizer properly. Also a longer value of n-gram might work better. If you use FeatureUnion in Pipeline then you can try different settings of transformer_weights. Finally when your features are ready try SVM with default RBF. Naive Bayes might also work fine because enough priors might be available. If you have large amount of features then try linear kernel. ~Sarah
