[site]: crossvalidated
[post_id]: 254145
[parent_id]: 
[tags]: 
Which is the correct order of a ML problem pipeline?

I'm very new to Machine Learning, and I'm struggling to understand how to improve a model I built. Let's say that I'm reaching a 60% accuracy on the test set, and a 70% F1-score, and given the problem (finance) it is very satisfactory, but I'd like to make it better. I know that I can: change the model: Neural Networks, Deep Convolutional Neural Networks, SVM, Random Forests, Decision Trees, simple Logistic Regressions, etc. change the dataset, with feature selection: using either the Recursive Feature Elimination, or K-best score, or looking at the feature importance via an Extra Tree Classifier, etc. tuning hyperparameters: the optimal alpha rate, the regularisation parameter, the number of nodes in the network or of trees in the forest or of branches in the tree, etc. However, I don't know in which order I should test this! First the model, then the dataset, then the params? Or the other way around? The problem is that they are not independent, and changing one might yield different results on the other. Secondly: which criteria should I use to evaluate the performance? Accuracy, evaluated on k-fold cross-validation sets? Or F1 score? Or the mean of both?
