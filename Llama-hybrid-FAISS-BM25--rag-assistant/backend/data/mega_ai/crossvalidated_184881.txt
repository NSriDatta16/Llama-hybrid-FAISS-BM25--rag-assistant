[site]: crossvalidated
[post_id]: 184881
[parent_id]: 
[tags]: 
Baysian Models Test Set performance metric

I am wondering which kind of test set performance metric is used to access the predictive performance of Bayesian models. All I can find in the literature are measures that are suitable for model selection but not for model validation (accessing the absolute predictive performance). Does bayesian machine learning simply not care about that and takes the predictive distribution for a new data point conditioned on the selected model $M$ and the training set $D_t$ $$p(y|M,D_t)$$ for granted? The predictive log probability of a holdout set $D_h$ $$\sum_{y \in D_h} \log(p(y|M,D_t) $$maybe comes closest. But, as far as I understand, the log probability is a relative measure, that is, a log probability of $x$ has no substantive meaning; it is only useful to compare different models on the same data set. One could maybe use the predictive mean $$\mathbb{E}(y|M,D_t)$$ and compare its values against the observed valued in a holdout set using, e.g., the squared loss function. However, this would ignore the variance of the predictive distribution. I am just a bit puzzled that in contrast to classical machine learning methods (SVM, Neural Networks) there seems to be not much emphasis on accessing how well the model predicts. Do people really end their GPR analysis with a presentation of the predictive distribution? For me this is unsatisfactory.
