[site]: crossvalidated
[post_id]: 414906
[parent_id]: 414349
[tags]: 
This problem comes up in my field of hydrology when assessing how well models predict streamflow from rainfall and climate data. Some researchers ( Chiew and McMahon, 1993 ) surveyed 93 hydrologists, (63 responded ) to find out what diagnostic plots and goodness of fit statistics they used, which were the most important, and how they were used to classify the quality of a model fit. The results are now dated but the approach may still be of interest. They presented the results of model fits of various qualities and asked hydrologists to classify them into 4 categories (1) perfectly acceptable result; (2) acceptable but use with reservation; (3) unacceptable, use only if there is no other alternative; and (4) never use under any condition. The most important diagnostic graphs were timeseries plots and scatter plots of simulated and recorded flows from the data used for calibration. R-squared and Nash-Sutcliffe model efficiency coefficient (E) were the favoured goodness of fit statistics. For example, results were considered acceptable if E => 0.8 There are other examples in the literature. When assessing an ecosystem model in the North Sea, the following categorisation was used E > 0.65 excelled, 0.5 to 0.65 very good, 0.2 to 0.5 as good, and Allen et al., 2007 ). Moriasi et al., (2015) provides tables of acceptable values for metrics for various types of models. I've summarised this information and references in a blog post . Allen, J., P. Somerfield, and F. Gilbert (2007), Quantifying uncertainty in high‐resolution coupled hydrodynamic‐ecosystem models, J. Mar. Syst.,64(1–4), 3–14, doi:10.1016/j.jmarsys.2006.02.010. Moriasi, D., Gitau, M. Pai, N. and Daggupati, P. (2015) Hydrologic and Water Quality Models: Performance Measures and Evaluation Criteria Transactions of the ASABE (American Society of Agricultural and Biological Engineers) 58(6):1763-1785
