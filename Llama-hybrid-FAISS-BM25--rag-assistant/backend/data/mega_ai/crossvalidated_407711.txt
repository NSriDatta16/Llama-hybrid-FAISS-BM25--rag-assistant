[site]: crossvalidated
[post_id]: 407711
[parent_id]: 242547
[tags]: 
My first question is do you agree with my thought process about the strength of the Bayesian inference? No. I do not agree. You should not run both together and which one you run should be based on the problem that you are seeking to solve. Also, avoid Bayes factors until you are very skilled. When you have non-binary choices, they have all of the issues that p-values have. Consider reading: Michael Lavine and Mark J Schervish (May 1999). Bayes Factors: What They Are and What They Are Not. The American Statistician. 53(2). pp. 119-122 When used as intended, they are fine but be careful not to infer too much from them. Likewise, you should read: Wetzels, R., Matzke, D., Lee, M. D., Rouder, J. N., Iverson, G. J., & Wagenmakers, E.-J. (2011). Statistical evidence in experimental psychology: An empirical comparison using 855 t tests. Perspectives on Psychological Science, 6, 291-298. You should use a Bayesian method in four primary circumstances. The first one is when you have prior information regarding the relative probability of which of the two models are true. If you have prior knowledge from research or experience, then it should be quantified into the prior and you should be using the posterior odds ratio rather than Bayes factors. The second one is when you are gambling money on the outcome, such as budgeting resources, setting inventory or so forth. The third one is when your primary concern is to estimate the value of a parameter accurately, but you are unconcerned with bias. If you are willing to exchange bias for accuracy, then you should use Bayes. The fourth one is when you want to assess the subjective probabilities of two or more sets of cases or parameters. So, for example, there is a 90% chance model X is true, a 6% chance that model Y is true and a 4% chance model Z is true. It is valuable for both model selection and model averaging. It is an excellent exploratory tool. There are five reasons to use Frequentist methods. You should use Frequentist methods when you lack prior information and, since you have no prior information to condition on to protect you from statistical runs and strange results, you want to minimize the maximum possible loss you could experience from being unlucky and choosing a bad sample. You should also use Frequentist methods when you want to remove broad classes of potential hypotheses from consideration conclusively. Fisher's no effect hypothesis is an incredibly powerful tool to cut through the crap in science when it is used as intended. It can foreclose many competing hypothesis by assuming the one you believe to be true to be false. Falsification of the false statement is very close to accepting the true statements. Although unbiased estimators are informationally costly, they have the tremendous advantage that they are unbiased. As a tool for rhetoric, an argument built around an unbiased estimator avoids the inevitable discussion of whether the bias introduced by the estimation method caused the results to be different in a material way from another method. The fourth reason is in the case of a sharp null hypothesis, such as when the hypothesis is $\theta=k,\text{ } \theta\in\Theta$ where $\Theta$ is continuous. Bayesian methods have no good way to solve this issue. There are workarounds such as ROPE, regions of practical equivalence, but they are a bit dangerous because they really must be equivalent. Consider $\Pr(\theta|X)\sim\mathcal{N}(0,1)$ and a sharp null of $\theta=0$ . It is true that $\theta$ is near zero if $\pm{3}$ is considered close, but if it is not, then while it is true that zero is in the highest density region, so is -1 and 1. There are an infinite number of possible values in the highest density region, only one of them is zero. Remember the difference is that the Frequentist test would be $\Pr(X|\theta=0)$ versus the Bayesian test $\Pr(\theta=0|X)$ . If $\theta$ is continuous, then $\Pr(\theta=0|X)=0.$ Finally, if there is a material dispute regarding the prior distribution in the field, a Frequentist estimator avoids this by ignoring the prior distribution. Secondly, should I expect this to always happen when performing both tests? You shouldn't be performing both sets of tests. They are built on conflicting assumptions. The posterior probabilities and the p-value are orthogonal constructions. They should not be interpreted similarly. For example, you chose to use the word significant with a posterior probability above. When speaking of Bayesian probabilities, you should drop the phraseology and the thinking of p-values. Imagine you saw 10,000,000 observations and P(X)=.9, P(Y)=.1, is that significant? Arguably it is not. If you saw 10,000,000 of something and do not have conclusive evidence such as P(X)=.999999, then maybe you should be concerned. On the other hand, if you saw 10 observations and P(X)=.9 then you should be very excited because that is a strong probability for such a small sample. You should not be thinking in terms of an $\alpha$ cut-off value. These are straight probabilities that something is true. Likewise, the null is a very arrogant and powerful statement. If your null is $\mu=0$ then you are saying there is a 100% chance that $\mu$ is 0 and then you are looking at how extreme your data would have to be if the null were true. Is the deductive reasoning available in Frequentist methods useful? Your choice between accepting the arrogance of creating a prior distribution and the arrogance of the null hypothesis should be based on what your needs are.
