[site]: crossvalidated
[post_id]: 326620
[parent_id]: 326583
[tags]: 
As other have said in their answers, using your laptop should be perfectly fine for running inference on trained models. However, training a network from scratch (or even fine-tuning one) takes quite a long time, and having a training occupying 100% of your laptop's CPU for a week just to find out you need to change some hyperparameters and start again will be probably not the best for your workflow. If you consider training your own models but don't want to invest in the high-end hardware, you might want to use some of the deep learning cloud computing platforms. For example, FloydHub seems to have very user-friendly interface (even though I have no personal experience with the service). Other options include Amazon Web Services , Google Cloud , and even Nvidia has their own cloud solution. Also, I am not sure if you are affiliated with a university or a company, but it might be the case the institution has some high-performance computing platform available. I would inform myself with your boss/supervisor and colleagues from other departments.
