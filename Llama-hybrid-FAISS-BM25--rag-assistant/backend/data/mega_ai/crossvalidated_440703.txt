[site]: crossvalidated
[post_id]: 440703
[parent_id]: 
[tags]: 
ML technique recommendations where each feature has multiple properties and the number of features per observation varies

Here is an abstracted version of the problem I am facing. I wish to predict the true value of a variable from multiple noisy predictions as to its value. There are three complicating factors: For each observation, I receive multiple noisy predictions from different sources. The sources may each provide valuable information, but are likely to differ in their accuracy (I'm using accuracy in its common sense rather than as a technical term here). Each prediction is timestamped, with later predictions tending to be more accurate than earlier ones. The function which defines the relationship between time and accuracy is strictly increasing but otherwise unknown (e.g. it may be discontinuous, the order rather than the amount of time elapsed may be the only thing that matters). The number of predictions obtained from any given source is not constant across observations (and the number of predictions for any given observation varies from source to source). Just to provide a very rough illustration: obs 1: y = 2.5, x[t=10,s=1] = 2.6, x[t=7,s=3] = 2.2, x[t=4,s=1] = 2.3, x[t=3,s=3] = 3.1 obs 2: y = 4.2, x[t=8,s=3] = 4.5, x[t=3,s=1] = 3.7, x[t=2,s=1] = 3.8 x[t=1,s=2] = 3.8 etc So what do I do guys? I'm having real trouble seeing how to translate this data into a table of features. The main problem I can see is that the source, timestamp, and value for each observation of x seem to be inseparable and thus ought to be coded as a single feature. But this appears to be impossible. I suppose modelling each source separately and ensembling the models would be easier, but it doesn't seem ideal. For instance, even if source 1 is generally more accurate, it shouldn't be weighted as highly if its predictions are on average earlier for a given observation. I imagine that some kind of neural network would be best at aggregating these data in such a way as to take advantage of all the potential non-linearities, but I'm struggling to work out would the best algorithm would be and how to engineer features for it.
