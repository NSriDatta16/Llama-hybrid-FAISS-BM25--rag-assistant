[site]: crossvalidated
[post_id]: 319975
[parent_id]: 
[tags]: 
What is the relationship between data generating process and validity of inferences?

This is a hypothetical example: I was assigned a section of land in an experiment station. I divided the land into 40 plots and planted grass species A in 20 randomly selected plots and grass species B on the other 20. Seeds for both grasses were purchased at the local supplier. I measured the total mass of hay produced by each plot and analyzed the data using correct calculations and frequentists statistical procedures. The 95% confidence interval for the difference (A-B) between average hay production in ton/ha was {2.0, 2.5}. This is a big difference in practical terms. What is the population of inference? Under what conditions should I repeat the experiment 100 times such that I can have a reasonable expectation that the mean (whose mean, by the way?) is bracketed by the 95% CI in 95 of the tests? What would be the formal frequentist statistical basis or method by which having the data from the experiment would allow me to have a better guess of what would happen if I buy seeds from a different supplier, and or plant the grass in other section of land in the same station, and or plant the grasses another time in another place?
