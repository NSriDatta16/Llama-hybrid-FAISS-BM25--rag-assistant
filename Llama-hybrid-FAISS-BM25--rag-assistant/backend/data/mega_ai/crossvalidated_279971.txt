[site]: crossvalidated
[post_id]: 279971
[parent_id]: 
[tags]: 
Alternatives to logistic regression when data is unbalanced

Using Python's pandas, sklearn, and stats models API, I have trained a logistic regression on a training dataset that tells me whether or not a particular purchase (based on gender, and other features) was fraudulent. I held out a test set, and under a logistic regression all datapoints are predicted to be within %20 percent of unfraudulent (where fraudulent =0, unfradulent =1). In other words, arbitrarily setting a decision boundary to be 50%, all test points are predicted to be unfraudelent. This is because many many more data points are unfraudulent in the training set than fraudulent. I am new to statistics, and would like to improve my model. What's the next step?
