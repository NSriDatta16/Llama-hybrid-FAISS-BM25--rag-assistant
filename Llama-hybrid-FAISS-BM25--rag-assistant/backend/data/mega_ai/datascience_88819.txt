[site]: datascience
[post_id]: 88819
[parent_id]: 
[tags]: 
How to improve a LSTM self-attention model given the absence of overfitting

I am doing a binary classification on time series data. Class 0 is a single class but class 1 is actually a combination of 7 different classes. My objective to classify class 0 from other classes. The training set has a shape of (4917,100,136) as (batches, timesteps, features). In the beginning, the model shows significant overfitting problem. I managed to minimize the overfitting problem through: Reduced layer units. Increased or decreased number of layers( did not affect the model much) Applied regularization through l2 and dropout . I have also applied class_weight to the model to mitigate the unbalanced issue. I tried different Adam and RMSprop , not much difference. Dense_unit = 32 LSTM_unit = 32 dense_reg = 0.003 attention_param = LSTM_unit*2 attention_init_value = 1.0/attention_param u_train = np.full((X_train.shape[0], attention_param), attention_init_value, dtype=np.float32) u_val = np.full((X_val.shape[0],attention_param), attention_init_value, dtype=np.float32) u_test = np.full((X_test.shape[0],attention_param), attention_init_value, dtype=np.float32) with keras.backend.name_scope('BLSTMLayer'): # Bi-directional Long Short-Term Memory for learning the temporal aggregation input_feature = Input(shape=(X_train.shape[1],X_train.shape[2])) x = Masking(mask_value=0)(input_feature) x = Dense(Dense_unit,kernel_regularizer=l2(dense_reg), activation='relu')(x) x = Dropout(dropout)(x) x = Dense(Dense_unit,kernel_regularizer=l2(dense_reg),activation='relu')(x) x = Dropout(dropout)(x) x = Dense(Dense_unit,kernel_regularizer=l2(dense_reg),activation='relu')(x) x = Dropout(dropout)(x) y = Bidirectional(LSTM(LSTM_unit,activity_regularizer=l2(0.0029),kernel_regularizer=l2(0.002),recurrent_regularizer=l2(0.002),return_sequences=True, dropout=dropout))(x) y = Bidirectional(LSTM(LSTM_unit,activity_regularizer=l2(0.0029),kernel_regularizer=l2(0.002),recurrent_regularizer=l2(0.002),return_sequences=True, dropout=dropout))(y) with keras.backend.name_scope('AttentionLayer'): # Logistic regression for learning the attention parameters with a standalone feature as input input_attention = Input(shape=(LSTM_unit * 2,)) u = Dense(LSTM_unit * 2, activation='softmax')(input_attention) # To compute the final weights for the frames which sum to unity alpha = dot([u, y], axes=-1) # inner prod. alpha = Activation('softmax')(alpha) with keras.backend.name_scope('WeightedPooling'): # Weighted pooling to get the utterance-level representation z = dot([alpha, y], axes=1) # Get posterior probability for each emotional class output = Dense(num_classes, activation='softmax')(z) model = Model(inputs=[input_attention, input_feature], outputs=output) optimizer = opt_select(optimizer,learning_rate) model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer) print(model.summary()) hist = model.fit([u_train, X_train], y_train, shuffle=False, batch_size=batch_size, epochs=epochs, class_weight = {0:1.75607143,1:0.69903327}, validation_data=([u_val, X_val], y_val) ) The training accuracy is very close to the validation accuracy(orange line) as shown in the screenshot. Further regularization didn't improve validation accuracy. Questions: How can one improve the model under these situations? The self-attention actually did not make the prediction better than models contains only pure LSTM. Can anyone suggest how to apply more self-attention layers into the model?
