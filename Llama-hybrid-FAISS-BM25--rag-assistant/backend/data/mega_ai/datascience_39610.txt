[site]: datascience
[post_id]: 39610
[parent_id]: 
[tags]: 
When training a neural network on a windows machine, what can task manager tell me about how it's going?

When I trained a simple convolutional network in pytorch, I could see in task manager that my cpu was hitting 100%, and I could see my ram spike up. When running with CUDA, I could see my GPU, go from 0% to only 1-2% utilization. I'm just curious about several things: I only ever see the Copy graph going up with the other 3 graphs (3D, video encode, video decode) doing nothing. Is that normal? I would've thought lots of matrix operations would make the 3D go up? I can easily max out CPU training, but I can never go above single digit % utilization for GPU training (and I don't even have a powerful GPU). I know it's because I probably have too simple a network, but besides increasing the batch size, are there ways to "take up slack"?
