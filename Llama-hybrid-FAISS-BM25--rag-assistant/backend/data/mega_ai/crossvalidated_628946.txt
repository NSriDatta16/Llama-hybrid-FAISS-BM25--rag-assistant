[site]: crossvalidated
[post_id]: 628946
[parent_id]: 628242
[tags]: 
I have two issues but the first one may not be relevant. When you de-trend your series, how can you one assume that the resulting process is not stochastic ? Once you take the trend off, the resulting series is not a constant, right ? So, it would seem to me like the de-rtrended series would have to be stochastic. This is my first issue. I've heard of doing OLS where all of the IVs were fixed and I've heard of doing OLS where all of the IV's were stochastic. But I've never heard of using a combination. Theoretically speaking, some strange assumptions would have to be made about $X^{\prime} X$ in order for OLS to hold from a theoretical perspective when the IV's were of mixed type. Halbert White's "asymptotic theory for econometricians" talks about the assumptions in OLS for both the fixed sampling case and the stochastic regressor case. This is my main issue. When one uses OLS without time subscripts, the effects are viewed as "one-time" effects. By this I mean that, if one is trying to estimate a model of say weight versus height for say male teenagers, then the weight at time $t$ versus the weight of the same person at time $t+1$ is not an issue because the person is sampled once. OTOH, when one builds an OLS models with time subscripts, even if the independent variables are not stochastic, the issue of multi-collinearity is present. For example, let's suppose for simplicity ( this model is made up and will not work ) that the monthly stock price, $Y_t$ is linearly related to the steepness of the yield curve, so the 10 year minus the one year treasury. Now, if one wants to estimate a regression model using this data, it's essentially impossible for the steepness of the yield curve to not be correlated with the steepness of the yield curve at time $t+1$ . But, when one estimates an OLS model, there is nothing in the model for handling this. The effect of the steepness of the yield curve on stock price is not going to happen all in one period. It's going to be distributed over time. Maybe, when the yield curve initially becomes steep, the effect is large, and then, over time, the effect gets less and less over time. But the less and less effect is still caused by the same steepness that occurred whatever time units ago. In this case, ( which was constructed artificially of course ) the steepness of yield curve effect is said to be distributed over time. A standard regression model does handle this issue. This is mainly why I'm hesitant about your model. The assumptions in OLS don't work once one has data where the effects don't occur all at once. So, even if you want to not worry about the one IV being stochastic, I still believe that the time issue needs to be dealt with. One methodology for handling time in a regression is through the use of a distributed lag. Formally, they are called "Autoregressive distributed lag models" and they are mainly used in econometrics. A very special one is the koyck distributed lag. If you want some literature references on this, let me know. Any decent time-series econometrics book should have a chapter on ARDLs. At the bottom is one paper ( political science ) where time is deal with in an ARDL. The literature is enormous because it crosses fields so I'm not sure what to suggest as far as suggested references. My thinking would be some good time-series econometrics textbook. Baltagi does a reasonable job in one of his chapters. I hope this helps some as far as what might be problematic. The de-trending could be okay but I bet the resulting series is significantly autocorrelated. If it is, then any results as far as estimated coefficients are going to be extremely biased. https://www.lukekeele.com/wp-content/uploads/2016/03/AJPSR4.pdf
