[site]: crossvalidated
[post_id]: 383570
[parent_id]: 381611
[tags]: 
Q: why copula oly works on standard uniform distribution Consider some arbitrary distribution, let's say log normal for the sake of discussion. Picture the shape of the density function ( $f(x)$ ). It is roughly bell shaped with positive skew. Now imagine taking a sample ( $s$ ) from this distribution. You would expect it, on average, to have a histogram of roughly the same shape. Now here comes the tricky part... Consider the cumulative density function of the same distribution ( $F(x)$ ). $F(x)$ takes a value from your sample space, and returns the probability of observing a value that is less than or equal to x. Consider the shape of $F(x)$ . Moving along the x-axis from left to right, it starts with a flat section, then gets very steep, then flattens out again. The flat sections indicate that your sample is not expected to contain many observations in that range, because changing the x value by a bit, doesn't change the probability very much. The steep section indicates that your sample is expected to contain many observations in that range, because changing the x value, changes the probability a lot. Now consider what happens if you feed your sample into $F(x)$ . What would the output look like? Remember, the output is a bunch of probabilities. So what distribution would your output have? It would have a uniform distribution, because most of your sample is from the steep section, which gets spread out on the y-axis because the function is steep. And the few observations from the flat section get compressed on the y axis because the function is flat. So parts of your x axis that are tightly clustered become spread out on the y axis, and parts of your x axis that are spread out, get more clustered on the y axis. The result is that if you feed data from any distribution through its corresponding cdf, you will be left with uniformly distributed data. But this is boring with uni-variate data. It is more interesting with multi-variate data. A coplula is basically doing this same exercise for multivariate data. It describes how high probabilities from variable 1, correlate with high probabilities from variable 2, for example. I read that we need to transform the margins to the uniform distribution in order to get the copula data First let's get a definition clear. Marginal distribution: A distribution of some data that comes from a multivariate distribution, but you ignore all the other variables and only consider the distribution of the variable in question. So a copula is what you get when you take a multivariate distribution and factor out all the marginal distributions . What you are left with is a multivariate uniform distribution, for the reasons I mentioned above. we can transformed the margins distribution non-parametically using their empirical cumulative distribution function. I wonder is that correct? You can get an empirical copula by obtaining the ranks for each variable in each observation. Convert the ranks to numbers between 0 and 1, and you are done. See the following R demo library(MASS) mu = seq(0.1, 0.2, length.out = 10) Sigma = matrix(0.8, ncol = 10, nrow = 10) diag(Sigma) = seq(1,1,length.out = 10) x = mvrnorm(n = 100000, mu = mu, Sigma = Sigma) marg1 = x[,1] plot(density(marg1, bw = "SJ")) ranks = sapply(1:10, function(i){rank(x[,i])}) / 100000 marg_rank_1 = ranks[,1] plot(density(marg_rank_1, bw = "SJ")) plot(ranks[,1],ranks[,2], cex = 0.5, col = rgb(0,0,0,alpha = 50,maxColorValue = 255), pch = 16) Here I have shown the distribution of the first variable, which is normal. However, the ranks are uniform. The ranks in this demo, is your copula data.
