[site]: crossvalidated
[post_id]: 66874
[parent_id]: 66862
[tags]: 
This is GBM: http://rss.acs.unt.edu/Rdoc/library/gbm/html/gbm.html http://cran.r-project.org/web/packages/dismo/vignettes/brt.pdf " I don't think that ... " has been the dangerous first part of many sentences. Good enough is meaningless without a measure of goodness, a rubric. What are the measures of goodness for any other method? Difference between model and data (sse, ...) Divergence of Error in a holdout set (training error vs. test error) Parameter count to sample count ratio (most folks like 5 samples per parameter or 30 samples per parameter) Cross validation (ensemble methods on divergence of error tests) Like a neural network, or spline, you can perform piecewise linear interpolation on the data and get a model that cannot generalize. You need to give up some of the "low error" in exchange for general applicability - generalization. More links: http://yaroslavvb.com/papers/moody-effective.pdf http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.529
