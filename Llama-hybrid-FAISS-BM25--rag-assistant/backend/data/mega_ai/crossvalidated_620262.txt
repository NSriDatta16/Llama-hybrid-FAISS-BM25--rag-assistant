[site]: crossvalidated
[post_id]: 620262
[parent_id]: 620249
[tags]: 
Presumably, the text you are reading means that you are in state $i$ at some time $t$ , and look at the probability that you are in state $j$ after $n$ additional time steps, that is at time $t+n$ . It is a very characteristic property of Markov chains, that the time $t$ where you start does not matter. This is actually called "Markov property" and means that the past history, before time $t$ , has no influence on the future. The probability to be in state $j$ after $n$ time steps, when you started in $i$ , can be denoted as $P^n(i, j)$ . The convergence result that you mentioned means that $P^n(i,j)$ converges to a constant which we could call $P^\infty(i,j)$ , as $n$ goes to infinity. In response to edit: For any $n$ , the probability to get from $i$ to $j$ after $n$ steps is always fixed, but if the chain is "nice enough" to have exactly one stationary steady state, these probabilities converge to a number and that no longer depends on $i$ . Then $P^\infty(i,j) = \pi(j)$ , where $\pi(j)$ is the probability of being in state $j$ in steady state. By "a chain is nice enough" I meant that it is irreducible and recurrent.
