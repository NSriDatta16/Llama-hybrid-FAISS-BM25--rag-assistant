[site]: crossvalidated
[post_id]: 502889
[parent_id]: 477359
[tags]: 
Confidence and certainty are different concepts, though strongly linked. There are two important properties for use cases such as decision making. We look for classifiers that are certain about their outcome (they rely on clues that lead to actually correct outcomes), and confident (among all possible answers, the selected answer is deemed as much more likely to be true, with his own probability estimates). To give a particular example: neural networks are prone to be overconfident (even when giving a wrong answer, the preferred answer has a much higher score than the rest). They are confident, but not certain (see On Calibration of Modern Neural Networks for a description of this issue). I would like to have a classifier that I can rely on, whenever he says is confident about an answer. Confidence, thus, refers to how "sure" a classifier is about its outcome. In your example, the classifier is much more confident in his second prediction. But that does not mean it is certain. Entropy gives you a measure of how confident the predictions are, but not of how certain. Confidence is about the distributions of the outcome probabilities. Certainty is more about being calibrated (the classifier estimates reflect the actual chances of something actually happening). Again, refer to the article.
