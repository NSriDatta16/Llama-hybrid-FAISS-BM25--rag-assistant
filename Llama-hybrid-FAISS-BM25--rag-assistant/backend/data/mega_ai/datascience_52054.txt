[site]: datascience
[post_id]: 52054
[parent_id]: 
[tags]: 
xgboostclassifier prediction error after saving the model and restoring it

I have trained a xgboost model and during training, the prediction works fine. But if I stop the script and start a restoring script to restore and predict, then for the same test dataset I get every data classified into one class. The weird part is that, even with the first prediction, i restore the model as shown below, X = df.drop(['label'], axis=1) y = df['label'] training_count = 0 X_train, test_data, y_train, test_label = train_test_split(X, y, test_size=0.1, random_state=7) model = XGBClassifier(learning_rate=0.5, n_estimators=250, max_depth= 5) model.fit(X_train, y_train) model.save_model('trained_model_full') #validation model = XGBClassifier(learning_rate=0.5, n_estimators=250, max_depth= 5) booster = xgb.Booster() booster.load_model('trained_model_full') model._Booster = booster model._le = LabelEncoder().fit(test_label) start = time.time() pred = model.predict(test_data) end = time.time() The above code works and gives me 99% accuracy. But if I remove the training part and just restore it like below, then it fails to work. I get 50% accuracy. X = df.drop(['label'], axis=1) y = df['label'] training_count = 0 X_train, test_data, y_train, test_label = train_test_split(X, y, test_size=0.1, random_state=7) #validation model = XGBClassifier(learning_rate=0.5, n_estimators=250, max_depth= 5) booster = xgb.Booster() booster.load_model('trained_model_full') model._Booster = booster model._le = LabelEncoder().fit(test_label) start = time.time() pred = model.predict(test_data) end = time.time() This is a strange issue. Have anyone come across something like this? if so could you help me out?
