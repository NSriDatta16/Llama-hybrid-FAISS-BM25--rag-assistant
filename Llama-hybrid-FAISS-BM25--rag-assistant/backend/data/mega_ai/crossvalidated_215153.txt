[site]: crossvalidated
[post_id]: 215153
[parent_id]: 215137
[tags]: 
Assumption 1: All initial problems orders are uniformly random, and that the only question we have is: how to randomize the problems (i.e. should we randomize them for each model? or should we randomize them once for all models?)? (which I think is your question). Following assumption 1 If we model $k$-fold x-val as a function, I would suggest the following to represent the average accuracy of model $m$: $$f(m,k,\mathcal{P}, o)$$ where $\mathcal{P}$ is the set of problems, and $o$ defines the order of the problems in $\mathcal{P}$ before they got partitioned into $k$ folds. So, in other words, in my view, the score of $k$-fold x-val is only a function of: Model under evaluation (i.e. $m$). Total problems set (i.e. $\mathcal{P}$). Initial order of problems set before partitioning them (i.e. $o$). And total number of folds (i.e. $k$). Let's now consider various cases and how they relate to the value $f(m,k,\mathcal{P}, o)$. Case 1: If $k = |\mathcal{P}|$ (i.e. total number of folds is equal to total number of problems, then for any different orders $o_1$ and $o_2$, the scores are identical: $$f(m,k,\mathcal{P}, o_1) = f(m,k,\mathcal{P}, o_2)$$ So in the case when $k = |\mathcal{P}|$, clearly the order doesn't matter. But, in some cases it's impossible to have $k = |\mathcal{P}|$ without causing a class imbalanced in training or testing folds. So I think we should not be too happy about Case 1 . Let's look at another case where the order $o$ does not matter. Case 2: For any orders $o_1$ and $o_2$, the following is true: $$ \lim_{|\mathcal{P}| \rightarrow \infty}f(m,k,\mathcal{P}, o_1) = \lim_{|\mathcal{P}| \rightarrow \infty}f(m,k,\mathcal{P}, o_2) $$ In my view this statement is true because of the law of large numbers . But similarly to Case 1 , I think we should not get too excited about this because usually our problems are not large enough to trigger this equality. Let's look at another case that is more realistic. Case 3: For a finite problems set, it is IMO very likely that there exists orders $o_1$ and $o_2$ such that: $$f(m,k,\mathcal{P}, o_1) \ne f(m,k,\mathcal{P}, o_2)$$ This is an empirical thing. Personally, based on all datasets that I have evaluated against, the probability that this inequality is true is $1$. Perhaps you can run a Monte-Carlo based simulation to estimate the probability that the inequality above is true as follows: $$\begin{split} =&\frac{\text{total num of times }f(m,k,\mathcal{P}, o_1) \ne f(m,k,\mathcal{P}, o_2)}{\text{total number of evaluations}}\\ =&\frac{1}{n} \sum_{i=0}^{n} I(f(m,k,\mathcal{P}, o_{1+i}) \ne f(m,k,\mathcal{P}, o_{2+i}))\\ >& 0 \ \ \ \ \ \text{(I think this is true for most cases)} \end{split}$$ where $I$ is an indicator function that returns 0 if statement is false, else returns 1. I think you wouldn't be surprised if it's $> 0$ for all your datasets. So, clearly, for any models $m_1$ and $m_2$, and any orders $o_1$ and $o_2$, the following test -by itself- is not very meaningful: $$f(m_1,k,\mathcal{P},o_1) > f(m_2,k,\mathcal{P},o_2) \ \ \ \ \ \ \ \ (1)$$ because there are two variables: two models $m_1$ and $m_2$, and also two different orders $o_1$ and $o_2$. Therefore, you can't know which one is causing which. Is it due to the order $o_1$ that is very lucky and helping $m_1$ to score better? Or is due $m_1$ being really good? Or a mixture of other factors? Alternatively, if you choose a single fixed order $o_1$, then (note that order is $o_1$ for both models): $$f(m_1,k,\mathcal{P},o_1) > f(m_2,k,\mathcal{P},o_1) \ \ \ \ \ \ \ \ (2)$$ means that model $m_1$ is better than model $m_2$ when tested against $\mathcal{P}$ problems as ordered by the specific order $o_1$. So clearly $(2)$ is telling us more information about the models than $(1)$. I.e. at least now we could say something about models $m_1$ and $m_2$ even though it is still somewhat useless as it is speific to the order $o_1$, but at least better than $(1)$ that didn't even isolate the effect of the order! So, $(2)$ tells us more information about the models, but it is specific to order $o_1$. Do we care? Usually, no. We don't care about the order. So while $(2)$ is better than $(1)$, it is still not very useful. Therefore, we need to repeat $(2)$ multiple times (forget about $(1)$), each time with a different order $o_i$ (where $i \in \{1, 2, \ldots, n\}$. Then, we need to perform statistical significance tests across all the orders $o_1, o_2, \ldots, o_n$, and then measure the $p$ value. Then we conclude that, for any $i \in \{1,2,\ldots,n\}$, $f(m_1,k,\mathcal{P},o_i) > f(m_2,k,\mathcal{P},o_i)$ is the case only if $p \le \alpha$. Therefore, we now define another $k$-fold x-val function that is independent of the order $o$ as follows: $$ g(m,k,\mathcal{P}) = \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i=1}^n f(m,k,\mathcal{P},o_i) $$ But since we cannot realistically choose $n \rightarrow \infty$, we choose $n$ that is large enough. How large is large enough? I suggest the following: Large enough to give us a $p$ value that is less than $\alpha$. Important note: choosing $n$ that is large enough (maybe $n=1000$) to give you a small enough $p$ value (maybe $p \le \alpha$) does not necessarily mean that model $m_1$ is significantly better than $m_2$. Instead, it only means this: A1: the order-independent $k$-old x-val process thinks that the score of $m_1$ is higher than that of $m_2$. Which is a different answer than the following: A2: $m_1$ is better than $m_2$. Simply calculating the $p$ value above to show A1 does not show A2 . Unanswered useful questions (beyond your main question) What if Assumption 1 is violated? This could be interesting for time series problems? Is the number $n$ independent of the size of the problems set $\mathcal{P}$? How to show A2 ?
