[site]: crossvalidated
[post_id]: 242698
[parent_id]: 242676
[tags]: 
Pattern recognition is a broad term. I'll try to cover the basics. It can roughly be split up into Classification What is it? Segmentation Where is it? Syntax Recognition How is it constructed? To find an algorithmic, i.e. by a computer, solution to any of the mentioned tasked, you'd approach this in the following (or a similar) way: Data Obviously, you'll need a sufficiently large data set. There are plenty free and large data sets to play around with, e.g. the iris flower data set, or the MNIST digit data set. Model You define a formal model of the patterns you want to detect. For this you'll need expert knowledge, i.e. you have to have some kind of domain knowledge. The model also defines valid in- and output. The model is used to predict, i.e. to compute some function that maps an input to an output. An input could e.g. be an image and the output would be "It is a dog" ( classification ), "the dog is in upper left corner" ( segmentation ). Features In order to predict something, you may have to computer features describing the input. For image you could e.g. compute the color, lighting, position, gradient, etc. Usually this a very important step as you'll need a lot of domain knowledge. Prediction To predict, your model need to learn parameters first. You could say it tries to find a function that maps input to output. The way you learn depends greatly on the task you want to achieve and the data you have. But in general, it goes as follows: Split your data into Test (~20%), Validation (~15%), and Training Data (~65 %) Assign the ground truth to the Training and Validation Data. This means that you have to user your expert knowledge and assign each data point a corresponding class (in classification). Initialize the parameters randomly. Feed your Training Data into the model. Predict the Validation Data. As you know the ground truth, you can estimate the error made. User the error to determine how much you have to change the parameters. After a fixed number of iterations (steps 3-5), stop and predict your test data. Example Let's say you have two dimensional data, e.g. hight and age of a person. Your goal is to determine the gender of that personl. So you have a two class problem defined as: $f(x_0, x_1) = c$ where $x_0$ is age, $x_1$ is hight, and $c \in \{m, f\}$ is the gender. So this means we have to find a function $f$ that tells us the gender of that person. Generally, there are two cases: Data is linearly separable (easy case) Data is not learly separable (common but hard case) This figure illustrates the two cases. Left is lin. sep. and right is not. So in the left case $f$ is linear, i.e. it has the form of $f(x_0, x_1) = mx + b$, where $m$ and $b$ are the parameters of the model. In the right case it would be more like $f(x_0, x_1) = \alpha_0 * \beta^3 + \alpha_1 * \beta^2 + \alpha_3 * \beta$, where the parameters are the $\alpha$ and the $\beta$ values. You can approximate them e.g. by Linear Discriminance Analysis, which esentially works in the mentioned steps. Here you could also think of transforming $x_0, x_1$ into a higher dimensionality (compute features). Ususally it gets lin. sep. then. There are many, many methods and models. Popular are Artificial Neural Networks, Support Vector Machines, and Ensemlbe Methods. Ressources To get you started, you can use Caffe Theano Tensorflow The R Programming Language Matlab Just search for these terms and you can start teaching your computer to recognize patterns.
