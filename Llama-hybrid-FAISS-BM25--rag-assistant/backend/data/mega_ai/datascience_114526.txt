[site]: datascience
[post_id]: 114526
[parent_id]: 114521
[tags]: 
Both of your models (with and with no extra layer) have high train accuracy but much lower scores on test data which indicates that both models overfit, i.e. they suffer from high variance (using the bias-variance trade-off terminology). In essence, it means that your models perform poorly on unseen data. To gain a better understanding of what is happening, I'd plot the learning curves of your model with no extra layer ( see here for an explanation of and links to further reads on learning curves). Generally, instead of adding an extra layer (and thereby increasing model capacity) you rather need to do the opposite in case of overfitting, e.g. by reducing model complexity (e.g. train for less epochs) or increasing the dataset size (e.g. by data augmentation). The Deep Learning book by Ian Goodfellow provides some helpful practical recommendations in this chapter .
