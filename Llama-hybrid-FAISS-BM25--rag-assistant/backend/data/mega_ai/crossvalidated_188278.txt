[site]: crossvalidated
[post_id]: 188278
[parent_id]: 188274
[tags]: 
There is one practical difficulty in standardizing your data in terms of having others be able to reproduce your results. If others used your same questions but had a different distribution of responses (different means/SDs) then their "scales" after standardization would be different from yours, even with the same questions. There is no need to standardize predictors for this analysis, and based on that difficulty I would argue against standardization. As you describe it, it seems that you have tried to develop something like a Likert scale based on the sums of responses to multiple questions designed to assess the same underlying phenomenon. See this page for an introduction to ways to use Likert scales; they aren't always best treated as (quasi)-continuous variables in the way that you propose. You should look carefully at the literature on Likert scales to see if your approach, with different individual questions having different response values, really makes sense. For logistic regression, the most important issue is whether the log odds of the response variable is linearly related to the predictor variables. That has to be your main priority, and you might need some other transformations of your predictor variables to meet that goal. Finally, your question suggests that you are trying to compare scale A and scale B. That raises a set of additional issues beyond the one you note about the different ranges of scale A and scale B. If comparing scales A and B is the main goal of your study, you might consider asking a new question about how best to compare different rating scales in this type of model. If you do ask such a question, please provide a bit more background about what scales A and B are designed to assess and what you are trying to accomplish with the comparison.
