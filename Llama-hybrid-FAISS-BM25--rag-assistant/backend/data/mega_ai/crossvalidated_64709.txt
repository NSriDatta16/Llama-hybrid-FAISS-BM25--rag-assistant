[site]: crossvalidated
[post_id]: 64709
[parent_id]: 
[tags]: 
Prioritizing data collection

In toxicology machine learning methods are used to estimate the probability of compound toxicity. Unfortunately most toxicology datasets contain on the order of 100 compounds and sometimes contain many more variables than compounds. When organizing the creation of new data one might ask how we can use a generative model to determine which chemicals would be valuable to test next, and which tests to perform on those chemicals. The goal of such data collection would be to improve the underlying model as quickly as possible. After doing some searching I have not found any papers approaching this question. Is anybody aware of methods used to organize data collection to improve the predictivity of a machine learning model as quickly as possible?
