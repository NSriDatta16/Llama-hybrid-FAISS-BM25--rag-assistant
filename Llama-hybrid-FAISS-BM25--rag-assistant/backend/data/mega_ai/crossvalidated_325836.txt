[site]: crossvalidated
[post_id]: 325836
[parent_id]: 325817
[tags]: 
It depends on a lot of parameters. Calling $h$ the height, $w$ the width of the image and $n_{channels}$ then number of channels, probably 3, then we define $p=h*w*n_{channels}$. The PCA step has a complexity of $O(np^2+p^3)$ for training and O($np$) for predictions. Calling $p'$ the number of principal components you keep, running a (naive) $k$ Nearest Neighbours search on the points will have a complexity of $O(p'n)$. So increasing the training size by 20% should increase the time taken by 20%, which I find a little puzzling (unless you run into memory issue and other things happen). Besides, if you want to make your method faster, based on the definition of $p$ you may note that the size of the image is critical. Dividing $w$ and $h$ by two may divide the time taken by the PCA by $(2*2)^2=16$. Regarding the kNN step, it is worth noting that there are many smart implementation relying on quadtrees (in R SearchTrees , per example) that significantly decrease the prediction time.
