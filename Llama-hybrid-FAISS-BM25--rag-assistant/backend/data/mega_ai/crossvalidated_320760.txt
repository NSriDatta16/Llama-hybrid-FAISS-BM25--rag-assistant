[site]: crossvalidated
[post_id]: 320760
[parent_id]: 
[tags]: 
Markov Chains vs. Bayesian Network

Background: I'm doing a project that takes a user's tweets and uses Markov Chaining to make up tweets. I'm putting together a presentation on this, and I'm struggling to make a meaningful distinction between Markov Chains and Bayesian Networks. I've looked at other explanations that are mainly about the more general Markov Process. They describe the Markov Process quite well, but things seem to go a bit over my head when they get into the Bayesian Network details. At one point they describe the Bayesian Network as "representing a factorization of some joint probability distribution." Could someone break this down for me a bit more simply? That's one thing that may help! From what I can tell, a Markov Chain is a directed, potentially-cyclic graph with weights between 0 and 1 (and with any given node's edges summing to 1). A Bayesian network is a directed, acyclic graph which doesn't seem to have weights, but rather a table of bayesian probabilities ? It's not very useful to me to think of the difference between them as being the presence of loops, and I'm not sure I fully understand a Bayesian Network â€“ is the difference going to mainly be that the Markov Chain introduces a random element, or is that also in the Bayesian Network? Thank you for your time!
