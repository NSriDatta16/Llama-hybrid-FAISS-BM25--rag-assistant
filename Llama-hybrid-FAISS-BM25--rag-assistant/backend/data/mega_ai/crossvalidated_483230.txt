[site]: crossvalidated
[post_id]: 483230
[parent_id]: 
[tags]: 
LSTM model in keras (R) with time-dependent and not time-dependent branches of inputs

I am using keras in R . I am studying 600 stations. For each station two types of information are available. The first type is time-dependent (time series) consisting of four variables T, E, P, and Q. The second type is not time dependent (non-sequence) consisting of two variables S (slope) and A (area), which are constant for each station. The objective is to predict the time series of the target variable Q. What I did so far is that I developed a local LSTM model that took and was trained based on time series of T, E, P from only one station and output time series of Q. In this model, I used generator as it was applied in this tutorial . For this model, I did not use non-series variables. My model worked fine for all stations. In a second step, I would like to develop a global model that uses and is trained based on information from all stations. To do this, I thought about using non-series variables to distinguish between the stations. I would like to use this global model at the local scale of one station and compare its performance with my initial local model. To implement the idea, I tried to use the keras's functional API considering two branches of inputs: the upstream branch (a dense layer ) that took non-series data of one station and the second branch (an lstm layer ) that took time-series data of the data station and then concatenating the two branches and repeat this procedure in a loop for all stations. Probably it is due to my lack of expertise, but I do not manage to implement this due to the presence of generators in the LSTM branch. I would appreciate if you could explain me how I could do this properly. Many thanks.
