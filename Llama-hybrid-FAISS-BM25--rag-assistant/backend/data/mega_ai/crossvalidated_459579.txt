[site]: crossvalidated
[post_id]: 459579
[parent_id]: 459501
[tags]: 
The quote in question seems to originate from marianne.net (in French) and, as it stands, is definitely wrong. But, as Demetri and Dave pointed out, with some language bending there might be some truth to it. In my understanding, Prof. Raoult confuses significance and effect size. In a small sample, the effect size has to be large (i.e. of practical relevance) to be statistically significant. In large samples, even very small effects, negligible for all practical purposes, can be statistically "significant". Just as a practical example: If the true effect of a drug is to prolong the life of a patient by, on average, one day, it is most likely useless for all practical purposes. In a small sample, say 20 persons, this small life extension will probably drown in the noise and wouldn't be noticeable at all. In a sample of $10^9$ persons, you might be able to see it. That doesn't mean that smaller samples are better. Just because you have found that the effect is non-zero doesn't mean that the hypothetical drug is worth its price (I assume there are some direct cost associated with it, and there are probably other opportunity costs). "Statistical significance" is not the right criterion for making decisions, and even the effect size isn't enough (although you should always look at it). Decision making always involves balancing costs and benefits. As of refuting the original statement: If a smaller data set is better, why don't we take the empty set, of size zero, and simply announce the result which is the most convenient to us?
