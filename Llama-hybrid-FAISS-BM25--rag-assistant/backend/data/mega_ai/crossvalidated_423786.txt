[site]: crossvalidated
[post_id]: 423786
[parent_id]: 423054
[tags]: 
I emailed kind Dr. Hastie who is the maintainer of the glmnet package and got the following answer: In the traditional case, the base category is arbitrary. In fact you can take a fitted model where say category one is the base category, and simply by subtraction of coefficients, make an equivalent model where another is the base (and the fit is identical). (Care must be taken with the standard errors). Concretely, if category 1 is the base, and you have coefficient vector \beta_k for category k , k=2,…,K (with \beta_1=0) you can make say category K the base. In this case the new coefficients would be \beta’_k = \beta_k-\beta_K and the fitted probabilities would be unchanged. With glmnet we chose a symmetric option instead, because we use regularization. With regularization, it would matter and make a difference if you used an asymmetric representation because of the way the shrinking works. I like the type.multinomial= “grouped” option. In this case a group lasso penalty is applied to the set of coefficients for each feature, and the estimated coefficients average 0. Again, you can post hoc move to an asymmetric representation as above without changing the fitted model.
