[site]: crossvalidated
[post_id]: 354502
[parent_id]: 354322
[tags]: 
To answer some of your questions I guess my main question is what does knn() do, what does k represent, and how is the model so accurate when k=1? knn() finds the k records in your dataset (the k-nearest neighbors) that are closest to the record it is currently trying to classify. What we mean by closest is that the distance between the records calculated using your auxiliary variables and some distance measure (knn probably defaults to Euclidian distance but I am not sure on that). It then takes the average of the k-nearest neighbors and that is what it uses to classify the record of interest. K represents the number of records to include in your neighborhood. If you choose k=1 you look only at the record that is closest. Typically bias will increase as the choice of K increases but variance will decrease. As to why your model is so accurate, without looking at your data I would not be able to tell you. It could be that you simply have very predictive auxiliary information
