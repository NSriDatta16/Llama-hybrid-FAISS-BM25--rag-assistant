[site]: crossvalidated
[post_id]: 608414
[parent_id]: 
[tags]: 
AUC ROC and accuracy for different datasets of same problem

I have datasets that correspond to different traffic load inputs. I am doing binary classification on them. The proportion of 1s to 0s varies from dataset to dataset. E.g., dataset 1 is imbalanced with >80% of class 1, dataset 2 has >70% class 1 samples, and so on. I am training different neural networks for each dataset, i.e., for each input traffic load value. When I was using dataset 1 and dataset 2, I used AUC ROC as a metric. My dataset 3 has 59% class 1 samples, and I am confused if I should use AUC ROC as a metric still. Or is accuracy much better here since it's not very imbalanced. My subsequent datasets will have the proportion changing to class 0 being dominant. So I may have to revert to AUC ROC again to deal with that imbalance. I want to compare the performance of the neural networks over increasing traffic loads in which case I should tune to obtain the possible optimal classifier for each dataset case using the same metric. I cannot say that I used AUC in the beginning and ending datasets and accuracy for in-between ones as they were more balanced. or can I? Please anyone suggest? I use 1 as positive class and 0 as negative class unlike most of the blogs that say minority class is the positive class. Hope my approach is also correct. I am equally interested in predicting both classes. I also read some AUC PR is also good. Is it so and should I use this for all cases instead od AUC ROC? I am anyway capturing this alongside& AUC PR values seem to be always higher than AUC ROC.
