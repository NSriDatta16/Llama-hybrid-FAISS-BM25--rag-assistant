[site]: crossvalidated
[post_id]: 540858
[parent_id]: 
[tags]: 
How to interpret OOB Error in a Random Forest model

I'm currently training two separate Random Forest classifier models using a dataset where the target feature is imbalanced (fraud): RF 1 is trained on the imbalanced data and RF 2 is trained on SMOTE-applied data. Both models are trained with n_estimators = 300 and make use of train, test and validation sets. (I will move to cross-validation later on in my analysis) Here are the results: Results of Random Forest fitted on imbalanced data: Recall Training: 1.0 Recall Validation: 0.8485299590621511 Recall Test: 0.8408843783979703 - Accuracy Training: 1.0 Accuracy Validation: 0.9398255813953489 Accuracy Test: 0.9343023255813954 - F1 Training: 1.0 F1 Validation: 0.9167671893848011 F1 Test: 0.9112333071484682 - OOB-Error 0.06497211068515052 ################################################################### Results of Random Forest fitted on SMOTE-applied data: Recall Training: 1.0 Recall Validation: 0.8489021213248976 Recall Test: 0.8412468285610728 - Accuracy Training: 1.0 Accuracy Validation: 0.9392441860465116 Accuracy Test: 0.9341569767441861 - F1 Training: 1.0 F1 Validation: 0.9160642570281123 F1 Test: 0.911089303238469 - OOB-Error 0.05621284006966554 As you can see, both RFs score virtually the same across all performance metrics apart from the OOB-Error in which the second RF scores better (I think?). My question is how am I supposed to interpret the OOB-Error when looking that the other performance metrics. In the first RF, the OOB-Error is 0.064 - does this mean for the OOB samples, it predicted them with an error rate of 6%? Or is it saying it predicts OOB samples correctly 94% accuracy/confidence? I understand what OOB errors and samples are but I'm struggling to interpret this metric intuitively. Thank you in advance.
