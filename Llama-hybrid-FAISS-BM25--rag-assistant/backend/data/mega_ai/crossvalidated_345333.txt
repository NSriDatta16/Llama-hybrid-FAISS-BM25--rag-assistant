[site]: crossvalidated
[post_id]: 345333
[parent_id]: 
[tags]: 
Bad classification accuracy with RF, XGBoost and Deeplearning with multiple categorical predictors and unbalaced class

I have a classification problem that deals with a big dataset with various categorical variables of multiple levels and the RF and XGBoost even deep learning cannot work better than 60% -70% in accuracy. Since the classes of the response are quite unbalanced (one class only account for 7%, the other two are more than 40% respectively), even after I balance the classes with oversampling, the methods still do not work well with the class that has quite a few observations, thus I thought it may be due to the original features I used. While I haven't found a good solution to do feature selection in terms that so many predictors are categorical and only a few are continuous. Can somebody offer some advice in terms of feature selection specific to categorical predictors (if there is any such methods), or any advice in terms of improving the accuracy. Thanks!
