[site]: crossvalidated
[post_id]: 436860
[parent_id]: 436856
[tags]: 
I would say it is both a yes and a no. Ignoring impossibility by design, say like predicting negative output but with final ReLU activation, Yes, we could argue there might exist a configuration that might generate a "satisfactory" approximation. Now come the second problem, how do we reach there? Neural Network, must also be seen from optimization stand-point which begs the question given some initialized weights, would our model be able to converge to a satisfactory solution? I think if you have dealt with neural network quite sometime you might heard problems like vanishing or exploding gradient this is something that your activation function of choice should be able to at least handle. And hence a big No.
