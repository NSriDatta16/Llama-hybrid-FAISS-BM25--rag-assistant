[site]: crossvalidated
[post_id]: 364696
[parent_id]: 67350
[tags]: 
There is no need for "downsampling", not even for speed. What you have is binomial data, and a good logistic regression routine should be able to use data in that form (R can do that). So I will give a simple simulated example with R showing how: set.seed( 7*11*13 ) # My public seed x Now, if the number of observations in each binomial experiment was 1000 and not 10 (for a total of 10000 bernoulli experiments), the data frame would still have only 100 rows and computing time should be the same. Now, if speed is the main problem, there is another approach. From your example it seems that the denominators of the ratios are always large. So, that being the case, calculate a logit transform of the ratio $y = \log(\hat{p}/(1-\hat{p}) )$ and use a usual linear model. This was done as an approximation before the days of fast computers.
