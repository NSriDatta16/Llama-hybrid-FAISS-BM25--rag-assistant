[site]: datascience
[post_id]: 82303
[parent_id]: 81904
[tags]: 
It is quite possible that the original model does already a very good job - it is not possible to improve it. For example the true relationship between original input variables and target might be linear, so a neural network doesn't add anything. As a test, I would increase hidden_layer_sizes and set early_stopping=False and even just doing a grid search (without CV): RMSE Training should get better than RMSE Feature. Most likely RMSE Testing will be worse, but at least you will have evidence there are no other unexpected circumstances (eg. a bug in the code). It does make sense to use predictions of a base model as inputs. Especially if that original base model is constrained somehow, and you expect your new model to outperform the original one because in the new model you don't have that constraint. For example the original model might be linear (ARIMA or ARIMAX), while yours is nonlinear - a neural network. Even if the true relationship between inputs and target is nonlinear, you don't have too much playroom here for a neural network (remember we want to outperform a base model). As I understand you have only ~ 4*365 observations. You can easily overtrain with many neurons, but with only a few neurons training can stuck in local minima.
