[site]: crossvalidated
[post_id]: 388740
[parent_id]: 
[tags]: 
Using PCA to reduce dimensionality of training and testing data

I've read so many contradicting opinions that I feel like I need to ask the question myself. Say I use PCA on a dataset with 60 variables and find that I can explain 98% of variance with 6 principal components and I get a decent model predicting what I want. Now I get some new data (testing), this data should then be translated to the same "PCA space" in order for my model to interpret it right? So I would scale it using the same scaling used on my training data and then use the loading scores from the original PCA to translate my new data to "PCA space"? The reason I'm asking is that I've seen tons of people doing PCA before doing test/train splits so their testing data is already "transformed", this seems like a mistake to me? Shouldn't the PCA be used on the training data exclusively and then using the loadings from that PCA translate the testing data to the same dimensionality?
