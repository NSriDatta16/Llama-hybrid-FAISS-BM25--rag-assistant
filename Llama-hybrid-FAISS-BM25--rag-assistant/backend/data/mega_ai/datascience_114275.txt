[site]: datascience
[post_id]: 114275
[parent_id]: 114270
[tags]: 
As so often, the answer is: "It depends". In this case, it depends on the algorithm / model / method you are going to use. There are some methods, e.g. tree-based methods, that can handle NULL-values. In this case, it could make sense not to impute at all. Note at this point the difference between informative missing (in our case: there was no lightning before) and non-informative missing (in our case: I don't know if there was a lightning). Some methods only work well with non-informative missings. In this case, I would create a dummy variable (see below). If you use some method based on linear elements (e.g. linear or logistic regression, neural networks), I would suggest the following approach: Create two variables: one contains your variable (or 0 imputed for NULL value) and the other one is a binary dummy variable with is 1, if there is a NULL value, and 0 otherwise. Why to do so? Look at the linear term: $\beta_1x_1+\beta_2x_2+...$ . If $x_1$ is the value and $x_2$ is the flag, then the we have two cases: If the value is not NULL, then $\beta_1x_1+\beta_2x_2=\beta_1x_1$ If your value is NULL, then $\beta_1x_1+\beta_2x_2=\beta_2$ So your model will learn the best value for imputation.
