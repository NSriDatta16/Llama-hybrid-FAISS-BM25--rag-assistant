[site]: crossvalidated
[post_id]: 444422
[parent_id]: 
[tags]: 
Impact on exploratory factor analysis of limiting number of data imputations

I intend to use multiple imputation to deal with missing continuous data before conducting exploratory factor analysis (EFA) on survey data, and to obtain factor scores for each individual case. I would ideally like to be able to subject the factor scores to further analyses (regression and possibly latent profile analysis). Background: I am a researcher in psychology, and am new to both EFA and data imputation. Data: 221 participants answered 60 questions, all of which asked them to indicate the extent of their agreement with a statement on a scale of 0-100. During EFA I encounter some very low communalities (below .2). My understanding is that I therefore need to run the analysis multiple times, removing the variable with the lowest communality each time before re-running. On dry runs with singly imputed data, this means I end up with about 25 variables in the final factor solution. 95% of the original 60 variables have missing data, which results from selection of a ‘don’t know’ option. The proportion of missing data ranges from 0-10.9% on each variable, with a mean of 3.4%. The missing data are MAR or MCAR, multivariate and non-monotone. Most of the variables have data that are skewed, some highly, and some with a high mass near 0 or 100. I want to impute data and conduct EFA in a way that is appropriate for the distribution of the data and results in a minimum of distortion to standard errors. I am planning to use the programme FACTOR . It uses hot-deck imputation, which seems to be appropriate for non-normal data, then performs multiple EFAs and averages their factor solutions after Procrustes rotation. Factor scores are simply averaged as well (Lorenzo-Seva & Van Ginkel, 2016; Ferrando & Lorenzo-Seva, 2017). For the EFA I will use Unweighted Least Squares/Principal Axis Factoring to deal with the non-normal distribution, and direct oblimin rotation to obtain an oblique solution. However, FACTOR limits users to 5 imputations. 95% of my variables have missing data. Bodner (2008) recommends having as many imputations as the percentage of cases with missing data, and Graham (2007) recommends about 100 imputations when 90% or more variables have missing information. How serious a problem is this limited number of data imputations: for the factor solution for subsequent parametric analysis using the resulting factor scores? I have tried an alternative technique that I hoped would avoid this problem: R package mifa calls package mice to impute data – with no limit on the number of imputations - using predictive mean matching (PMM), and combines the resulting covariance or correlation matrices. An averaged covariance or correlation matrix can be passed to package psych for EFA. However, I can only get factor weights this way, not individual factor scores. I assume this is because package psych is using the correlation matrix rather than case-level data. The author of package mifa has been extremely helpful, but mifa cannot currently get to a single set of factor scores for individuals using Rubin’s rules.
