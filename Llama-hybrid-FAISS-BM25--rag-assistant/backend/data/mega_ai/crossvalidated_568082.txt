[site]: crossvalidated
[post_id]: 568082
[parent_id]: 
[tags]: 
How can I minimize forecasting error in 100 probably correlated time series data streams with incomplete data from each one?

Suppose that I have 100 restaurants with identical menus and ingredients they need to procure to stay in business. Let’s assume that they have 100 menu items per restaurant and 500 ingredients in total per restaurant. Now let’s assume that you want to - for whatever reason - centrally coordinate the procurement of these ingredients through quarterly reports from each restaurant to forecast coming quarters for the entire chain of restaurants. Further assume that each restaurant has a distribution regarding usage patterns and that any two restaurants might be correlated via external factors (weather, geographical proximity, general human traits, and so on). Lastly, we assume that, in reality, our hypothetical restaurants will be somewhat non-compliant in their reporting. So, for example, while one restaurant consistently might report data for every quarter of the year, another might send you the first two quarters lumped together, and a third might send you the second and third quarter data lumped together and so forth. The data is therefore not reported simultaneously and it regards different time periods for different restaurants. We do, however, have such non-uniform data dating several years back. Assuming there is a connection between the distributions - albeit maybe a weak one - is there a theoretically optimal way to combine the lossy data streams from every restaurant to approximate the proper underlying distributions for each? Optimally, I would like to "add" every new observation that I manage to get in order to refine my predictions for all restaurants, if possible.
