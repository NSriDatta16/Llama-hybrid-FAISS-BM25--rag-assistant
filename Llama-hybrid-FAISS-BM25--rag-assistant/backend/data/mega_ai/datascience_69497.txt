[site]: datascience
[post_id]: 69497
[parent_id]: 69487
[tags]: 
This answer might not make a lot of sense without a little background on quantum computing A QCNN ( https://arxiv.org/abs/1810.03787 ) is a type of quantum model that the authors in this paper use to model quantum data. At the core it is just a quantum circuit acting on a set of qubits in order to model quantum data that is on those qubits. The authors use it to predict a particular property of their quantum data. Here is a piece from the paper where they explain the architecture at a high level: The circuit's input is an unknown quantum state $\rho_{\text{in}}$ . A convolution layer applies a single quasi-local unitary ( $U_i$ ) in a translationally-invariant manner for finite depth. For pooling, a fraction of qubits are measured, and their outcomes determine unitary rotations ( $V_j$ ) applied to nearby qubits. Hence, nonlinearities in QCNN arise from reducing the number of degrees of freedom. Convolution and pooling layers are performed until the system size is sufficiently small; then, a fully connected layer is applied as a unitary $F$ on the remaining qubits. Finally, the outcome of the circuit is obtained by measuring a fixed number of output qubits. As in the classical case, circuit structures (i.e. QCNN hyperparameters) such as the number of convolution and pooling layers are fixed, and the unitaries themselves are learned. To contrast this a little bit with the classical CNN: The QCNN is best used when dealing with quantum data that you wouldn't normally be able to deal with (easily) classically. The authors made a very smart choice here in choosing to model data that could be prepared on a quantum computer, data which might be harder for a classical computer to prepare. If you have classical data (like MNIST or CIFAR) then the CNN is still your best bet over the QCNN for performance. If you have quantum data on a quantum computer the QCNN has a much stronger case. If you've been using TensorFlow Quantum, one of the tutorials shows this exact performance comparison where a quantum computer modelling classical data has a really hard time keeping up with the scaling of the classical computer ( https://www.tensorflow.org/quantum/tutorials/mnist ). We are hoping to use TensorFlow Quantum to better understand quantum data and it's not too likely any QCNNs are going to pop up in serious classical ML pipelines for NLP or Image classification at scale that are going to drastically improve performance..... yet :P
