[site]: crossvalidated
[post_id]: 474767
[parent_id]: 
[tags]: 
What exactly does a proper scoring rule want to do?

I will adapt an excellent simulation by our St√©phane Laurent for this question. x1 The setup is that I have two binary predictor variables and a binary response variable, and I want to fit a model of the response variable, probably logistic regression. I assess my model with a proper scoring rule. What does the proper scoring rule want to achieve, perfect accuracy (all $0$ s called $P(1)=0$ and all $1$ s called $P(1)=1$ ) or the perfect probability at the four combinations of predictors? Perfect probability of predictors: $$P(Y=1\vert x_1=0, x_2=0) = 0.73$$ $$P(Y=1\vert x_1=0, x_2=1) = 0.12$$ $$P(Y=1\vert x_1=1, x_2=0) = 0.95$$ $$P(Y=1\vert x_1=1, x_2=1) = 0.50$$ This idea can be extended to models with continuous predictors, but two binary predictors makes it easy to give all of the possible combinations of predictors. (Typing out this question, I think it has to be the latter case, the true probabilities, but it sure would be nice to get confirmation.) EDIT After discussing proper scoring rules on the data science Stack , I now have doubts about my parenthetical comment at the end of the original post. How does a proper scoring rule both want to find the true probabilities and optimize according to observed classes? EDIT 2 The Brier score, for instance, is minimized when the categories are correctly predicted as $0$ and $1$ . How is that related to finding the "true" probabilities? In my simulation, if I predict $P(Y=1\vert x_1=0, x_2=0) = 0.73$ , I get penalized by the Brier score, since I would have the true category be either $0$ or $1$ . Or is the idea that, if I sampled many times from $x_1=0, x_2=0$ that I would get $73\%$ of the observations to be $1$ and $27\%$ of the observations to be $0$ , so the best prediction is $0.73$ instead of a pure $0$ or $1$ ? (Now I think I see what's going on, but it would be great to have someone confirm!)
