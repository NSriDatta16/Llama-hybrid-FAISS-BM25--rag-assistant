[site]: datascience
[post_id]: 81222
[parent_id]: 
[tags]: 
Is there any reason not to use classification instead of regression when looking for ranges?

In the case I want to predict only ranges from a continuous value, is there any reason to use regression instead of classification ? Could it depend on the type of model I am using (neural network, decision tree, bayesian, ...) ? Example Let say I have a dataset with images. Each image has one human on it and is labeled with his/her height. Now I am only interested in predicting height ranges, for instance these four classes [ A, B, C, D ] = [ 190 ] (in cm) . Is there any reason why one of the two following approaches should lead to better performances ? case 1 : using regression - First create and fit a model that predicts the exact height from an image, then simply gives its associated height range. case 2 : using classification - First label all the images with the wanted ranges (=classes), then create and fit a classifier to predict this height range. Note : I am wondering if there is a general answer to this question, not only to this example EDIT As @n1tk pointed out, in the post Performance of CNN based deep models with number of classes , the question is answered if we think about increasing the number of classes. In my question, I am wondering about regression vs classification . So try to fit a continuous value vs ranges from this value.
