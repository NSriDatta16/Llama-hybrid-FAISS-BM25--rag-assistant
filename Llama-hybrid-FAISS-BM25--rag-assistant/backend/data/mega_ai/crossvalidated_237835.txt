[site]: crossvalidated
[post_id]: 237835
[parent_id]: 
[tags]: 
Some variants of Bayesian optimization are especially appealing because they strive to keep the total number of function evaluations to a minimum. This is desirable when function evaluations are very expensive (either because it takes quite a bit of computing power, or because they require physical experiments). Some methods require no knowledge about the function at all (derivatives, functional form, etc.). This is useful when there is no known function (such as the response surface for a model wrt its hyper-parameters) or the function is so complex that computing derivatives is impractical. Some key resources about Bayesian optimization include the following papers: Shahriari et al., "Taking the Human Out of the Loop: A Review of Bayesian Optimization" (2015). Jones et al. "Efficient Global Optimization of Expensive Black-box functions." (1998).
