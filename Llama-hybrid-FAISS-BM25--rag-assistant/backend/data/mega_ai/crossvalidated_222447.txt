[site]: crossvalidated
[post_id]: 222447
[parent_id]: 222433
[tags]: 
@Gabe is correct that your model significantly "explains" some of the variance in your dependent variable, and that per_pro deserves special attention. Part of your problem comes from the large numbers of predictor variables relative to the number of cases. If the dependent variable "PerMemChng" is continuous, then with 44 cases you should be evaluating no more than 4 or so predictor variables, not 7, in a standard linear regression like this (about 10 cases per predictor). Otherwise you risk overfitting, forming a model that "fits" your present data sample but that would perform poorly on another sample from the same population. If your predictors are correlated with each other, the large number of predictors may also make it difficult to demonstrate a true significance of any one. I disagree, however, about using stepwise selection to choose a final model, as discussed on this Cross Validated Page among many others. The best approach is often to start with your knowledge of the subject matter and use that to select a number of predictors suitable for the number of cases you have available, or to accumulate more cases if you really want to consider all 7. Alternatively, you could use a method like ridge regression that would allow you to incorporate all 7 variables by "penalizing" the coefficients down to lower magnitudes than their ordinary linear-model coefficients, thus minimizing the risk of overfitting. That often works well with a moderate number of correlated predictors. For future reference, if you are doing predictions from a properly fit (not overfit) model then you should not worry about whether a particular variable meets some test of significance, as noted for example on this page . Predictions are typically improved by including all appropriate variables in a model.
