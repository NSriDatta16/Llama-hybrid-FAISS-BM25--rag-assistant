[site]: crossvalidated
[post_id]: 301876
[parent_id]: 
[tags]: 
Formulating a hierarchical Bayesian model for gambling (Pymc3)

I am quite new to Bayesian modeling and trying to wrap my head around how to choose hyperpriors and formulate the model. I am using Pymc3 My example data is gambling related. People play a 'balloon' task, where they roll a fair 6-sided die and earn points until they bank the money keep rolling until they hit a 1 and lose the amount they accumulated this round. I have $i...N$ subjects that play $T_i$ trials resulting in an unbalanced dataset ~17000 obs. (not all people play the same amount of trials). I want to model the probability of the players banking their earnings $P(stop)$. I have 3 variables that I am trying to explain the data with: $points$ - accumulated points for each trial, for each subject. This is a discrete variable that takes values from 0 to ~ 500, e.g. [20,40,100,120...]. $steak_{high}$ - a counter that accumulates when the die rolls 5 or 6. $steak_{low}$ - a counter that accumulates when the die rolls 2 or 3. $stop$ - a dummy that indicates if the subject stopped at trial $i$. I can easily pool all subjects together and estimate a logistic linear model using pm.glm.GLM.from_formula('stop ~ seqearn + high_count + low_count', data, family = pm.glm.families.Binomial()) which gives meaningful results, such as people increasing their probability to stop, as points increase. However, I would like to model a simple hierarchical model that allows each subject to express variability, and at the same time, use their underlying similarity (they all want to maximise end number of points) al√° this blog post . Here is the 'adapted' code: def run_HM(): points = data.points.astype(theano.config.floatX) with pm.Model() as hierarchical_model: mu_a = pm.Normal('mu_alpha', mu=0., sd=100**2) sigma_a = pm.Uniform('sigma_alpha', lower=0, upper=100) mu_b = pm.Normal('mu_beta', mu=0., sd=100**2) sigma_b = pm.Uniform('sigma_beta', lower=0, upper=100) # Intercepts a = pm.Normal('alpha', mu=mu_a, sd=sigma_a, shape=len(data.subject.unique())) b = pm.Normal('beta', mu=mu_b, sd=sigma_b, shape=len(data.subject.unique())) # Error eps = pm.Uniform('eps', lower=0, upper=100) # Expected value stop_est = a[data.subject.values] + b[data.subject.values] * data.points.values # Likelihood y_like = pm.Normal('y_like', mu=stop_est, sd=eps, observed=data.stop) with hierarchical_model: # Use ADVI for initialization mu, sds, elbo = pm.variational.advi(n=100000) step = pm.NUTS(scaling=hierarchical_model.dict_to_array(sds)**2, is_cov=True) hierarchical_trace = pm.sample(5000, step, start=mu) However, the results are not very good. Several distributions does not converge and some of them look multimodal. What would be useful hyperpriors for $points$ and $steak_{high/low}$? Obviously, the normal distribution is a poor choice How do I specify dependence on several variables? In the blog post, floor level is the only variable that goes into the model. Thanks!
