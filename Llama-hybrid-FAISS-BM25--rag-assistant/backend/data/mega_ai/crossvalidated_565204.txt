[site]: crossvalidated
[post_id]: 565204
[parent_id]: 565090
[tags]: 
As another answer and some comments pointed out, you should have in mind that the estimation of causal effects and prediction are not the same thing. The amount of consumption of chocolate in a country might help you to predict from which country the next Nobel laureate in medicine will come from, but it will not tell you that much about the causal "story" that produces nobel laureates in some countries (probably that story has something to do with economic growth). But the knowledge of causal mechanisms may help to improve prediction: Let's say you want to generalize your results from a trained model to new environments, $e$ . Causal relationships of the kind $X^{e} \rightarrow Y^{e}$ , $X$ and $Y$ being some random variables, should go along with so called invariant conditional distributions $P(Y^{e} |X^{e})$ , which are the same for all environments $e\in \mathcal{E}$ from some environment space $\mathcal{E}$ . So having $X^{e}$ in your model when predicting $Y^{e}$ should improve the robustness of your predictions when dealing with different environments. An example from this book Ref1 : let $X^{e}$ be the height of a mountain and $Y^{e}$ the temperature measured at a certain height. So you might deduce from some physical theory that there is something like a causal relation between height and temperature ("the higher, the colder"). This relationship should hold between different environments, such as the Swiss and the Austrian Alps. Hence your prediction model built on data from the Swiss Alps should also hold for the Austrian Alps (robust prediction). See this great article here: Ref2 . Or this nice talk: Ref3 . In a semi-supervised learning setting the exploitation of causal mechanisms may also be fruitful (see anticausal learning in Ref4 ). Note also: You can also improve the estimation of causal effects using machine learning ( Ref5 ).
