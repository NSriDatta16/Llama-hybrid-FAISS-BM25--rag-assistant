[site]: crossvalidated
[post_id]: 337757
[parent_id]: 
[tags]: 
For creating the joint posterior distribution for multiple variables, are the associated Bayesian priors usually assume independent of each other?

Suppose that we have data, $D$, and two parameters we want to learn about, $\theta_1, \theta_2$. We will usually put priors on $\theta_1, \theta_2$, then have the expression: $$ p(\theta_1, \theta_2\mid D) \propto p(D\mid \theta_1, \theta_2) p(\theta_1) p(\theta_2) $$ I am wondering why most set-ups assume that the priors above are independent. What happens if we do not have it?
