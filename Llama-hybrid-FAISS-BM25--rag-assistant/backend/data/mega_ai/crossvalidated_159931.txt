[site]: crossvalidated
[post_id]: 159931
[parent_id]: 159754
[tags]: 
We have had some discussions about weights on the Stan-development Google group. Although I don't think we reached a resolution, I would say while what you are proposing is somewhat accepted in the frequentist literature, it seems difficult to reconcile it with a Bayesian approach. The weights just do not fit into Bayes' theorem very well because if the weight is greater than 1, you are conditioning on additional data that you have not actually observed (and conversely if the weight is less than 1). I believe what you are implying is that the standard deviation of the measurement error is a decreasing function of the true measurement. If so, it should be possible to model that directly without resorting to weights. We know that if the true value has a Pareto distribution, then its logarithm has a shifted exponential distribution. In your case, $\log{x} - \log{x_{min}} = \log{x_{true}} - \log{x_{min}} + \log{e}$ where $e$ is log-normal and $\log{x_{true}} - \log{x_{min}}$ is exponential with rate $\alpha$. So the .stan program could be something like data { int N; vector[N] log_x; } parameters { real alpha; vector[N] log_e; real log_minimum; } transformed parameters { vector[N] truth; truth That said, I'm not sure if Stan would be able to sample from the posterior distribution very well due to the rapidly changing curvature of each element of log_e .
