[site]: crossvalidated
[post_id]: 419920
[parent_id]: 
[tags]: 
What does it mean to "directly learn a distribution?"

I'm currently reading the paper for the attention model ( Neural Machine Translation By Jointly Learning to Align and Translate (Bahdanau et al., 2015) ) and had a question regarding a statement made in the paper. I'm sure this concept also applies to factors outside of deep learning and machine translation, but I just wanted to provide some context as to what prompted me to ask this question. In the second paragraph of section 2, the authors state that "Recently, a number of papers have proposed the use of neural networks to directly learn this conditional distribution." What they're referring to is that the concept of machine translation is basically to maximize the conditional probability $$P(\mathbf{y}\ |\ \mathbf{x})$$ where $\mathbf{y}$ is the target sentence and $\mathbf{x}$ is the source sentence. My assumption is that they're basically saying that the authors used neural networks to "learn" the features automatically rather than having to do so manually as was the case for previous translation models. My question is, what does it exactly mean to "directly learn" a distribution?
