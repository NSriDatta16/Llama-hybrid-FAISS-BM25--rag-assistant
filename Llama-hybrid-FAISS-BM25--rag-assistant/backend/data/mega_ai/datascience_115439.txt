[site]: datascience
[post_id]: 115439
[parent_id]: 
[tags]: 
Maximum likelihood estimation - effect of reducing the number of data rows (by averaging)

Say I want to estimate $\overline x$ given matrix $A$ and $\overline y$ and assume $\overline \epsilon \sim N(0,\sigma^2 I)$ : $$\overline y = A \overline x + \overline\epsilon$$ I want to study the effect on the ML estimate of $\overline x$ if we reduce the number of rows in $A$ and $\overline y$ . For example, if the data consists of $N$ rows, I'd construct a new matrix $A'$ with $\frac{N}{2}$ rows: row $n$ of $A'$ is constructed by taking the mean of row $2n$ and row $2n+1$ of $A$ . In a more practical example, I would partition the output range of $\overline y$ in $K$ classes and construct a new matrix $A'$ and vector $\overline y'$ with $K$ rows, where row $k$ of $A'$ is the mean of the rows of $A$ belonging to class $k$ and $(\overline y')_k$ is the mean of the elements in $\overline y$ in class $k$ . A numerical example is shown at the end of this question. What I've tried to do, is to find an expression for the mean squared error (MSE) of $\overline x_{ML}$ and $\overline x_{ML}'$ . I found the following formula here : $$ MSE = \mathbb{E}[\|\overline x-\overline x_{ML}\|_2^2] =\|(A^H A)^{-1}A^H\|_F^2\sigma^2 $$ and I would now like to relate the expressions $MSE$ and $MSE'$ , where $MSE'$ uses the same formula but with $x_{ML}'$ and $\sigma'$ . I expect $MSE'$ to be larger than $MSE$ since we have a loss of information. On the other hand, the variance $\sigma'^2$ is lower than $\sigma^2$ since the variance of the mean of i.i.d. normal distributions is lower than the variance of any of the normal distributions. Can anyone point me in the right direction to analyze this type of problem? I will include a numerical example for clarification. Let's say I partition the elements of $\overline y$ using the following intervals (classes): $[0, 2.5), [2.5, 5), [5, 7.5), [7.5,10)$ . $y_1$ belongs to class $1$ , $y_2, y_5$ and $y_6$ belong to class $2$ . No elements belong to class $3$ . $y_3$ and $y_4$ belong to class $4$ . We bundle the rows of $A$ and elements of $y$ of each class together by taking the mean across the class:
