[site]: datascience
[post_id]: 85973
[parent_id]: 
[tags]: 
BERT minimal batch size

Is there a minimum batch size for training/re-fining a BERT model on custom data? Could you name any cases where a mini batch size between 1-8 would make sense? Would a batch size of 1 make sense at all?
