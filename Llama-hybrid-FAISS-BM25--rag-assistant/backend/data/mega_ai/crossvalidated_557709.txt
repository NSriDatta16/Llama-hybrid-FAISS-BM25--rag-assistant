[site]: crossvalidated
[post_id]: 557709
[parent_id]: 
[tags]: 
What is an acceptable value of square loss in machine learning (using mxnet gluon's square loss function)?

I have checked the gluon's square loss function implementation in mxnet, where it is calculated as follows: $$L=\frac{1}{2}\sum_i\left|label_i−pred_i\right|^2$$ https://mxnet.apache.org/versions/1.8.0/api/python/docs/api/gluon/loss/index.html#mxnet.gluon.loss.L2Loss The key here is that the loss is squared and then multiplied by $\frac{1}{2}$ . Now, let's suppose I want to predict a label ∈ {0,1} where P(1)=P(0)=0.5 And instead of doing any calculation I simply always predict that my value is equal to 0.5 If the label is 1, I get a loss $L=\frac{1}{2}\sum_i\left|1−0.5\right|^2$ =0.125 And if my label is 0, I also get $L=\frac{1}{2}\sum_i\left|0−0.5\right|^2$ =0.125 Does this mean I should aim for my loss to be less than 0.125 for my predictions to be of any use? Or in this case ( if labels are ∈ {0,1} ) , would it be more sensible to switch to softmax model?
