[site]: crossvalidated
[post_id]: 401004
[parent_id]: 400996
[tags]: 
A short answer that works in general: these terms are sort of loose, and can always mean whatever is the most useful in a particular context. If you have a whole bunch of samples, why not use them all and consider $X$ to be the collection of all samples. If you have only a single sample, then that's all you can use. You are free to do whatever you want. But to answer your questions more directly: You give two expressions for likelihood: $\prod_x p(x\mid\theta)$ and $p(x\mid\theta)$ . The second expression is just the conditional probability of a point $x$ given a choice of parameters $\theta$ , and that's how it should be interpreted. The former expression is the product of many of these conditional probabilities, or in other words it is the conditional probability of many datapoints $X=\{x\}$ assuming that they are independent. In general, if we didn't know anything about independence of the datapoints, we would have to work with the joint distribution $p(X\mid\theta)$ , but given that $x$ are independent we can factor the distribution into the product $\prod_x p(x\mid\theta)$ . The independence assumption is common so that's probably why you saw it. I hinted at this in 1, but people often use lowercase $x$ to refer to a single sample, and capital $X$ to refer to the whole collection of data in this context of likelihoods of data. (Often in a more theoretical context a capital $X$ would be a random variable; the capital here comes from the convention that matrices are capital letters.) So as a rule of thumb I'd say $L(\theta\mid X)$ would probably be the likelihood of the parameters given a whole dataset. But again, you are free to do what you want. Again, it is not necessarily true that capital $X$ means a random variable. It might be true in that context, but you should always pay attention to the context and the usage of the authors you're interested in. Mathematicians are loose with notation and that is what it is. I guess my moral here is not to always assume that the same letters mean the same things in different papers. For instance, on that EM page, they are doing something rather complicated, which is taking an expectation against the probability measure of the entire dataset. This object is rather abstract and hard to conceive of, and I think it's best to understand EM concretely by working through a particular case -- it's really a whole family of algorithms and describing it in general tends to be vague. Answers to questions in comments: I can say that for sure, $P(X=x\mid\theta)$ tends to refer to the probability that a random variable $X$ takes on a value $x$ given the parameters $\theta$ . But in $P(X\mid\theta)$ , $X$ might be a random variable or a dataset. Again, these things should always be clear in a given case, so I think it's not worth worrying about these generalities. In the case where $X$ is a random variable, $P(X\mid\theta)$ is probably referring to the entire distribution rather than a particular probability, so I might be inclined to interpret it as a probability distribution (a function(al)) rather than a probability (a number) if I came across it. As for the notation on Wikipedia that you asked about -- certainly it can be both, and MLEs will improve in accuracy with more data, so you might as well think about it as the whole dataset. But Wikipedia tends to have really strange and inconsistent notation since it is written collaboratively by random people with different backgrounds, so I would really not stress the notation on that site. In particular, if you're trying to learn these things, don't do it on Wikipedia -- get a textbook. Maybe "Elements of Statistical Learning" or another classic text -- I think that's outside the scope of this question.
