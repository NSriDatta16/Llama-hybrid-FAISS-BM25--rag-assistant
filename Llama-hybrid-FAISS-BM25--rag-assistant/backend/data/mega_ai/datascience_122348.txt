[site]: datascience
[post_id]: 122348
[parent_id]: 122343
[tags]: 
There is not one easy solution to your problem, as it is not well-defined, but there are ways to narrow it down and come closer to a solution. Here are some points that can help you to do so. 1. Something like correlation To my understanding, you are looking for something like correlation (but more complex) that identifies time series that belong together. This is a vague description. Can you by yourself identify matching series? (see also Point 2) describe what makes a match (correlation looks for linear dependencies) maybe even mathematically define a similarity or distance measure between ? (In this case, you might not need deep learning and just use the similarity/distance measure) 2. Supervised or unsupervised Do you have labeled training data, i.e. a set of time series where you know which series match and which don't? If you want to train a neural network, you might need quite an amount of such labeled pairs. In case you do have such labeled data, a supervised approach might work (e.g. classification ). Note : If you use correlation to identifiy matching pairs for the training, then your neural network will just learn to reproduce the correlation results. You need to put manual effort into creating better matches. If you do not have such labeled data, i.e. you just have the set of time series, you need to look for an unsupervised method. 3. Classification If you want to turn this into a classification task, you could use two time series as input and have a binary target (matching: yes/no). Note that in this case you need to test all pairs of series to find the matching pairs. 4. Unsupervised methods There are two classes of unsupversised algorithms that might be of help, here. Clustering groups your samples (=time series) in subgroups. You might need a clustering algorithm that creates many small clusters (ideally each cluster is one matching pair). Hierarchical clustering might be able to do so. The downside is, that you need a suitable distance function (see 1. above) Embeddings transform your data (e.g. your time series) into a low-dimensional fixed-size vector. Famous algorithms are t-sne and umap. This can be used as preprocessing step for a clustering. A euclidean distance might already work well on the low-dimensional embeddings. About the architecture If all time series have the same time steps the architecture can treat these as fixed-size vectors. Otherwise you might need an architecture that deals with dynamic length inputs (LSTMs, GRU, Attention, Transformer, ...) How complex dependencies shall be recognized. More parameters in the network allow for more complex dependencies. A larger dimension of an embedding would do so, too.
