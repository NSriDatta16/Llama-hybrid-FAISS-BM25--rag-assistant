[site]: crossvalidated
[post_id]: 350378
[parent_id]: 350364
[tags]: 
This issue is very controversial. I imagine that this answer will have many negative votes. It has implications for the daily lives and work of many. But you have to do what you have to do. That's more or less how I understand the story: 100 years ago Fisher developed a method for data testing. Neyman and Pearson took what Fisher developed and developed it further. The two proposals are similar but contradictory on some points. Since the proposals were published, there have been publications that questioned them. Towards the 1940s or 1950s (a task for historians), the two theories were almost anonymously combined into a single theory now called NHST (null hypothesis statistical tests). No one is the author of the NHST. It's one more rule of thumb. So you can't discuss this theory with any author. Since their anonymity, NHSTs have been criticized. There are hundreds (or thousands) of articles indicating that they are not the most appropriate method of doing scientific research. Last year the ASA in its conference "a world beyond p NHST problems: Logical: based on failed logical tests. Real: It is based on ideal distributions, which are rarely found in reality. They are of anonymous creation: With which author can you argue?. They give a false sense of security. The problem of inference is hundreds or thousands of years old. Philosophers still can't figure it out. We do? Researcher positions: Abandon NHSTs and use Bayesian statistics. Problem: It is not a total solution because it would have the same problem as the NHST, in some cases reasoning in the same way. Use NHSTs well. Problem: 5 books will explain NHSTs in 5 different ways, because there is no established method for making NHSTs. NHSTs were invented by us, there's no evidence on how to evaluate the evidence! Create new methods for data testing. That's where some of the authors are.
