[site]: crossvalidated
[post_id]: 458454
[parent_id]: 
[tags]: 
Intuition for LSTMs?

I've been reading the book "Neural Network Methods for Natural Language Processing" by Goldberg and in it he describes the LSTM framework. Apparently there are 3 gates, forget, input and output. These gates are supposed to control what part of the memory component $c_j$ and hidden component $h_j$ are supposed to be passed to the next time step. Since there are weights associated with each gate, how can we be certain they behave in a way we expect? To be more precise, Goldberg suggests the following example of controlled memory access to inspire some intuition for the LSTM. Let $g\in {0,1}^n$ be a binary vector, $x\in \mathbb{R}^n$ be an input vector and $s\in \mathbb{R}^n$ be a memory vector. We can update memory $s^\prime \leftarrow g \circ x+ (1-g) \circ s$ where $g$ acts as a gate that controls which indices of the memory vector to keep and which to update with the input vector. In the context of neural networks, since we want to apply gradient descent, we want the gating mechanism to be differentiable, so $g\in\mathbb{R}^n$ . In the LSTM framework, we have $c_j=f \circ c_{j-1}+i\circ z$ where $c_j$ is the memory component, $f$ and $i$ are the forget and input gates respectively, and z is the update candidate. Since there are learnable weights for the gates, it's possible that $f=\mathbf{1}$ and $i=\mathbf{1}$ (vector with all 1's). That wouldn't be of the same form as the above, where $g+(1-g)=\mathbf{1}$ . If $f=i=\mathbf{1}$ then we are simply adding vector $c_{j-1}$ with vector $z$ . How do we know that the LSTM is not behaving like this?
