[site]: crossvalidated
[post_id]: 105643
[parent_id]: 
[tags]: 
Identify points significantly outside a regression model

I would like to update my previous question "Methods to determine reliability of measurements using median and median absolute deviation" . I have data from biological experiments, that look like this: v1 2 1.8 1.5 1.9 2.1 1.78 1.95 2.0 2.1 v2 2 100 -5.2 v3 1 -1.3 -2 2.3 v4 1 1.5 1.6 1.9 2.1 2.0 2.4 -1.1 2.3 1.5 1.6 1.9 1.8 1.6 These represent gene expressions. Now, I would expect that all values of each variable (genes) are more or less similar, since the values are ripetute (?) measurement of the same gene. Having a variable with such huge difference, as v2, doesn't have sense. That means that it does not make sense to have a gene with such a huge variation in expression. Therefore, it has to come from a methodological error. I was looking for a method (possible a statistical test) which could identify the "average variability" among my samples and report me which variables(genes) have a variability significantly greater. This means that for these gens my data are not good enough to estimate the expression, and I have to discard them. ** In the first place I would really appreciate any suggestion on test I could use for my purpose. ** I thought at something like that: I consider for each gene the ratio between median absolute deviation (mad) and median (med) . I would expect this ratio has a normal-like distribution, assuming that the variability comes from error in the measurement occurred by chance. Therefore, I could identify then all variables (gene) that have a mad/med ratio significantly higher that the average distribution, or if you want that are "positive outliers". For me it sounds quite intuitive but I'm not sure how to perform that in an appropriate way. I would really appreciate your opinions about my method and also your suggestions on how I could perform the analysis.
