[site]: datascience
[post_id]: 17866
[parent_id]: 
[tags]: 
Is it true that a neural network with many layers converges to a solution?

For one hidden layer exist Universal approximation theorem by George Cybenko. But for multi layers net converges result is stohastic or determ and guaranteed as one hidden layer net? And is there an appropriate proof?
