[site]: crossvalidated
[post_id]: 59039
[parent_id]: 
[tags]: 
What coefficient could I use to calculate the relative difficulty of a test in relation to others using only mean and population standard deviation?

I have a series of tests, all of them of different difficulty, and from each of them I get an average score and a population standard deviation; e.g: 86.94% 16.27% 84.17% 6.52% 99.55% 1.19% 81.70% 9.61% 99.82% 0.34% Now, clearly the last test, that has an average of 99.82% and a standard deviation of 0.34% is a lot easier than the one with a mean of 81.7% and a standard deviation of 9.61% (supposing of course the variations of results are effect of the difficulty and not of the population that took the test). What I'm trying to figure out is a coefficient that uses only that data to get a number that properly reflects how much more difficult was one test than the others. I hope you can help. btw: sorry for the wrong tag, I'm not sure which would have been a good fit.
