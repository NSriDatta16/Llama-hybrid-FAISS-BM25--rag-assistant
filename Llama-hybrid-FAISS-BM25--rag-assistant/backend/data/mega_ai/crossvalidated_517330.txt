[site]: crossvalidated
[post_id]: 517330
[parent_id]: 517297
[tags]: 
This part of the book is wrong Your misgivings on this matter are appropriate, because this part of the book is wrong. Even when making inferences about infinite populations, random sampling does not give independent random variables --- it gives conditionally independent random variables, conditional on the empirical distribution of the underlying superpopulation from which they were sampled. Once we reduce to sampling from a finite population, the sampled values are not conditionally independent given the underlying distribution of the population. In any case, it is not true that knowledge of the commuting time on one day gives no information about the commuting times on other days. Indeed, this is obviously not true, because if it were true then there would be no basis for making inferences from random samples at all. If you would like to understand more about this topic, you can find a full elaboration (looking at both classical and Bayesian statistics) in O'Neill (2009) . I'll give a short outline of the issue here, looking first at inferences in an infinite superpopulation. Consider a sequence of random variables $X_1,X_2,X_3,...$ with limiting empirical distribution $F_\infty$ . De Finetti's representation theorem (as extended by Hewitt and Savage) shows that if the sequence is exchangeable (so that the first $n$ values are a simple random sample) then we have: $$X_1,X_2,X_3,... | F_\infty \sim \text{IID } F_\infty.$$ This result means that random sampling from an infinite superpopulation gives values that are conditionally independent, conditional on the limiting empirical distribution. Once we condition on a finite population, things become even trickier. We can still say that the values are conditionally independent, conditional on $F_\infty$ (i.e., conditional on the distribution of an infinite superpopulation where the finite population is embedded), but this is not much use. Suppse we let $F_N$ denote the empirical distribution of the first $N$ values (a finite population), and we look at behaviour conditional on this distribution. Each sample value has this marginal distribution, but we cannot validly assert even conditional independence: $$\quad \quad \quad \ \ X_i |F_N \sim F_N \quad \quad \quad \quad \quad \ \text{(valid result)}$$ $$X_1,X_2,...,X_N | F_N \sim \text{IID } F_N. \quad \quad \quad \text{(erroneous result)}$$ In fact, for any population values $i \neq k$ we have the conditional distribution: $$X_i|X_k, F_N \sim F_{N,-k}$$ where $F_{N,-k}$ is the empirical distribution of the population, excluding the $k$ th value (see below for details). Except in the case where all population values are the same, we have $F_N \neq F_{N,-k}$ , which means that the values $X_i$ and $X_k$ are not independent. Your remarks about urn models illustrate exactly this. Empirical distributions: The population empirical distribution $F_N: \mathbb{R} \rightarrow [0,1]$ is defined by: $$F_N(x) = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(x_i \leqslant x).$$ Excluding the $k$ th value gives the corresponding empirical distribution $F_{N,-k}: \mathbb{R} \rightarrow [0,1]$ , defined by: $$F_{N,-k}(x) = \frac{1}{N-1} \sum_{i=1}^N \mathbb{I}(i \neq k) \cdot \mathbb{I}(x_i \leqslant x).$$ Since $(N-1) F_{N,-k}(x) + \mathbb{I}(x_k \leqslant x) = N F_N(x)$ , we can write the latter in terms of the former as: $$F_{N,-k}(x) = \frac{N}{N-1} \cdot (F_N(x) - \mathbb{I}(x_k \leqslant x)).$$
