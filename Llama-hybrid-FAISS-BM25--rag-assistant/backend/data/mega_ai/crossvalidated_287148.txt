[site]: crossvalidated
[post_id]: 287148
[parent_id]: 287143
[tags]: 
Let's break down the code: apply(actuals_preds, 1, min) Takes, for each row, the minimum of the prediction and the result. Similarly, apply(actuals_preds, 1, max) takes the maximum. Suppose the test outcomes are $y_1, \ldots, y_n$, and the predictions are $\hat{y}_1, \ldots, \hat{y}_n$. For any $i$, there are two cases: The first case is $\hat{y}_i = y_i - \epsilon_i$ for some $\epsilon_i \geq 0$. In this case, row $i$ will add to the mean, the term \begin{equation} \frac{y_i - \epsilon_i}{y_i} = 1 - \frac{\epsilon_i}{y_i}. \end{equation} The second case is $\hat{y}_i = y_i + \epsilon_i$ for some $\epsilon_i \geq 0$. In this case, row $i$ will add to the mean, the term \begin{equation} \frac{y_i}{y_i + \epsilon_i} \sim 1 - \frac{\epsilon_i}{y_i}. \end{equation} where the approximation holds for $\epsilon_i Finally mean(min(actual, predicted)/max(actual, predicted)) takes the average of all these terms, obviously. The better the prediction, the higher it will be (approx. 1 for a nearly perfect prediction).
