[site]: crossvalidated
[post_id]: 320654
[parent_id]: 313725
[tags]: 
During production features like "after" are ignored because they were not seen during training. There is the concept of Pipeline (e.g., with scikit-learn at http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html ) for automating this process and avoiding creating different feature spaces. The whole idea however is that a model can not explicitly account (after training) for features that were not observed during training. Training a classifier e.g., a Logistic Regression for the problem shown in the example actually means learning a set of weights that are associated with each feature. During prediction these weights are multiplied (dot product) with the value of the feature and depending on the value of the dot product a decision is made (True/False). In other words, training is the process of optimizing these associate weights that will result in better (more accurate) predictions. It follows that for features (like 'after') that are not seen during training no weights can be learned and, hence, they should be ignored during production as they can not contribute to the output of the aforementioned dot-product.
