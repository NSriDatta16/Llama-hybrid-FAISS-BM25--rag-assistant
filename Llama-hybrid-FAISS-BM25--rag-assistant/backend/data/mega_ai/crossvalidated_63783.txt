[site]: crossvalidated
[post_id]: 63783
[parent_id]: 63776
[tags]: 
I believe the bias in RFs is "a feature, not a bug." Decision trees have a tendency to overfit the data, so the bias in random forests counter-acts the overfit somewhat, making a random forest model more robust than a straight-forward decision tree otherwise would have been. If you want to further attack overfit, you may be interested in using regularized trees for feature selection: http://arxiv.org/pdf/1201.1587.pdf , also check out the RRF package. Of course, this doesn't answer your question which was what options are available for tuning your model. For one automated approach, the randomForest package has a tuneRF() function for tuning the mtry paramter (the number of variables sampled in each tree).
