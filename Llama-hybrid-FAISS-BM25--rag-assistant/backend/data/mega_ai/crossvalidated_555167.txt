[site]: crossvalidated
[post_id]: 555167
[parent_id]: 
[tags]: 
Why is deviance $\neq -2\times$logLik for logistic regression in R?

Just tried to compute McFadden's $R^2$ from hand in R from a fitted logistic regression, but stumbled accross the problem that the reported deviance is not equal to -2 times the reported log-Liklihood: library(MASS) fit AFAIK, the deviance is defined as $-2(\ell(m) - \ell(m_s))$ , where $m$ is the model at hand and $m_s$ is the saturated model with perfect predictions. Perfect predictions in a binary logistic regression lead to a Likelihood of one, and thus a log-Likelihood of zero. I would thus have thought that, for logistic regression, $D = -2\ell$ . Am I missing something?
