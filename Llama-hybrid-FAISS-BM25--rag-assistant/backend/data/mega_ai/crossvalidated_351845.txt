[site]: crossvalidated
[post_id]: 351845
[parent_id]: 351828
[tags]: 
This assumes that your network is not grossly overtrained. If you want to keep your architecture the same, then you can try looking at activations of your network across images and outright delete any dead or almost-dead neurons. Alternatively, if you're using say, 1x1 convolutions, you might be able to discard a prune convolutions that have not been feature-selected by the 1x1s. Overall, you're probably not going to achieve much in terms of reduction and compression using these techniques (assuming you've already used batch normalization, reasonable learning rates, etc.). Reasonably, you can probably expect upwards of 2x speedup. There are many more techniques, and a nice overview can be found in A Survey of Model Compression and Acceleration for Deep Neural Networks - Cheng, et. al. . You can alternatively use floating-point reduction. An example of this is NVIDIA tensorflow RT , which fine-tunes the existing network with lower floating-point precision. This invariably ends up with a much faster neural network, and less memory for weights. However, if you're willing to switch architecture, a good example of this is MobileNets , which can achieve reasonable accuracy, while being much smaller than most other architectures out there (Resnet, Inception, etc.). The above paper presents nice examples of this, one being a mobilenet implementation of FaceNet. The nice thing about their approach is that they didn't have to use the original dual-embedding techniques from facenet (along with notoriously difficult hard negative mining). Instead, they just train the mobilenet to reproduce facenet's embeddings. A similar approach can be undertaken for other problems.
