[site]: crossvalidated
[post_id]: 198143
[parent_id]: 189907
[tags]: 
The easiest way to handle 'tuning' of the num_rounds parameter is to let XGBoost do it for you. You can set the early_stopping_rounds parameter to n in the train method and the model will stop training once error hasn't decreased for n rounds. See this example from the Liberty Mutual Kaggle Competition : As noted in the code below, you'll need to also use the watchlist parameter to enable early stopping. # You can write R code here and then click "Run" to run it on our platform # The readr library is the best way to read and write CSV files in R library(readr) library(xgboost) library(data.table) library(Matrix) library(caret) # The competition datafiles are in the directory ../input # Read competition data files: train
