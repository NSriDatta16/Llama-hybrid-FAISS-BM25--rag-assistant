[site]: crossvalidated
[post_id]: 395097
[parent_id]: 131028
[tags]: 
The actual logic behind it is much simpler: There are two ways to estimate the variance in the population when you have several groups but you assume the values all come from the same distribution. look at the variance in each group Each group can be considered a random sample from the population and each one provides an estimate for the population variance. We need a single estimate, so we take the average. This is the within-variance $\hat{\sigma}_\mathrm{within}^2$ look at the variation of the means The means of the different groups can be seen as a sampling distribution of means from the population. The variance of this distribution is: $\hat{\sigma}^2_{\bar{x}} = \frac{\hat{\sigma}^2}{n}$ Crucially, we are interested in the population variance $\hat{\sigma}^2$ so we have to multiply the variance of the means with the sample size: $\hat{\sigma}^2 = \hat{\sigma}^2_\bar{x} n = \hat\sigma^2_\mathrm{between}$ If all values really come from a single distribution, the two ways to estimate the variance should give the same result. But obviously drawing samples is a random process, so we calculate a $p$ -value, which tells us the probability of deviations from equal variances (even though all values come from a single population). If the probability is very low, we might argue that the values do not come from a single population. Then the means will variate much more than we expected and the ratio increases. To me its astounding that ANOVA is not taught in this way. Most instructors just start with sum of squares and degrees of freedom and the formulas do not make any sense. When seeing that both variances are actually estimates of the population variance, the formulas start to make sense. Note that I assumed a balanced design where the sample size for each group is the same ( $n$ ). If this is not the case one has to take weighted averages.
