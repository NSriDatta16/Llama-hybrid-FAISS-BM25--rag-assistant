[site]: crossvalidated
[post_id]: 464864
[parent_id]: 464628
[tags]: 
Only for the trivial problems you can apply Bayes theorem directly to calculate the posterior distributions. For almost all real-life statistical problems we use algorithms for approximating the posterior distribution. Currently the most popular approach to this is using Markov Chain Monte Carlo (see questions tagged as mcmc ), for example the NUTS sampler ( Hoffman and Gellman, 2011 ). Since for Bayesian neural networks those algorithms may be inefficient because of the huge number of parameters, in such cases people often use variational inference (see variational-bayes ), with algorithms like ADVI ( Kucukelbir et al, 2016 ) to estimate the posterior distributions. This is dynamically changing field, with a lot of ongoing research on this subject, and many more algorithms were proposed in the literature, so it is hard to summarise it in Q&A site answer. Moreover, it is plausible that the methods that are popular in this field today, would not be that popular in a year or two, since we would find better algorithms. I would encourage you to google for "bayesian neural networks" , since this would reveal thousands of relevant search results including academic papers, books, online tutorials, recordings of conference talks etc. on this subject.
