[site]: crossvalidated
[post_id]: 411319
[parent_id]: 276924
[tags]: 
I don't see why cross-validation (see answer by @phanny) would make things any better in this case. What you may want to look at is an oversampling/undersampling technique. Generally, "plain old oversampling" the minority class leads to overfitting, so I would recommend to either go for SMOTE https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume16/chawla02a-html/chawla2002.html or for combining undersampling and cross-validation (perform each round of cross-validation training with an equal number of cases from each label, so, basically, what you suggested in the final paragraph of your question, but with cross-validation involved) For more info, check https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis Anyway, don't expect any miracles! Unbalanced data is one of the major problems in classification problem, specially in "harder" ones (in the sense of there not being a simple separation between the classes) This compensating techniques always risk to overestimate the chance of any individual being in the minority class, which is OK (compared to the opposite case) in some problems like medical diagnose, but may not be in your particular problem. Finally, consider usgin a Random Forest (or AdaBoost) to increase the performance of your trees. Also, don't use overall accuracy as a validation metric for problems with unbalanced data. Try a precision-recall compromise instead.
