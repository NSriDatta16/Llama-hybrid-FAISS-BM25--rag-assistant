[site]: crossvalidated
[post_id]: 262699
[parent_id]: 262686
[tags]: 
Only approach (a) serves the purpose of testing hypothesis. In case of using supervised machine learning algorithms (b), they cannot neither prove or disprove hypothesis about distingness of groups. If machine learning algorithm does not classify the groups correctly it may happen because you used "wrong" algorithm for your problem, or you didn't tuned it enough etc. On another hand, you may "torture" the totally "random" data long enough to produce overfitting model that makes good predictions. Yet another problem is when and how would you know that the algorithm makes "good" predictions? Almost never you would aim at 100% classification accuracy, so when would you know that the classification results prove anything? Clustering algorithms (c) are not designed for supervised learning. They do not aim at recreating the labels, but to group your data in terms of similarities. Now, the results depend on what algorithm you use and what kind of similarities you are looking for. Your data may have different kinds of similarities, you may want to seek for differences between boys and girls, but the algorithm may instead find groups of poor and rich kids, or intelligent and less intelligent, right- and left-handed etc. Not finding the grouping that you intended does not prove that the grouping does not make sense, but only that it found other "meaningful" grouping. As in previous case, the results may depend on the algorithm used and the parameters. Would it suite you if one in ten algorithms/settings found "your" labels? What if it was one in one hundred? How long would you search before stopping? Notice that when using machine learning in vast majority of cases you won't stop after using one algorithm with default settings and the result may depend on the procedure that you used.
