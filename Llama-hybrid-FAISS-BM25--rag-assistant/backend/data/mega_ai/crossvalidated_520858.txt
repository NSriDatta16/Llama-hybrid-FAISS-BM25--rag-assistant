[site]: crossvalidated
[post_id]: 520858
[parent_id]: 520765
[tags]: 
I will crawl very far out on a limb and speculate that you have Likert-7 data from $n = 100$ subjects, and that you are making the usual (but not always defensible) assumption that it is OK to regard them as numerical. If this is way off target, you can use that as a basis for refining your question. Then maybe one of us can come closer to a useful answer. Thus your data might be something like the fictitious data simulated and described in R below: set.seed(421) x = sample(1:5, 100, rep=T, p = c(1,1,2,3,3)) table(x) x 1 2 3 4 5 14 10 20 35 21 summary(x) Min. 1st Qu. Median Mean 3rd Qu. Max. 1.00 3.00 4.00 3.39 4.00 5.00 stripchart(x, ylim=c(.7,2.5), meth="s", pch=20) Classical approaches are questionable. The data are pretty clearly not normal, so I am reluctant to trust a t confidence interval $(3.13, 3.65)$ as valid. Also, there are too many tied values to make good sense of a 95% confidence interval $(3,4)$ for the 'pseudo-median' based on a one-sample nonparametric Wilcoxon test. I am not saying that either of these intervals is "wrong"--only that I cannot confirm that the assumptions underlying them are warranted. Nonparametric bootstrap CIs. One kind of bootstrap confidence interval arises from taking $B = 3000$ re-samples from among the $n = 100$ scores x , and take the average of each re-sample. This gives a good idea of the variability of average scores Finally, by taking quantiles 0.025 and 0.9975 of the re-sampled averages I get a quantile 95% nonparametric CI $(3.13, 3.64)$ for the population mean Likert-5 score. Perhaps without taking any assumed numerical meaning of the Likert scores too seriously, we can say the the average population scores lie between 3 and 4. [Even so, we have inevitably assumed some numerical qualities for Likert scores: for example, that the differences between scores 1 and 2 are as important as differences between scores 3 and 4. That these assumptions are almost routinely made in some disciplines does not mean that they are always correct or useful.] set.seed(2021) a.re = replicate(3000, mean(sample(x,100,rep=T))) quantile(a.re, c(.025,.975)) 2.5% 97.5% 3.13 3.64 Among the 3000 re-sampled means a.re there only 82 uniquely distinct values, so we should not take the second decimal places in the boundaries of the bootstrap CI very seriously. For example, the corresponding 90% CI $(3.17, 3.61)$ and 99% CI $(3.06, 3.67)$ are not a lot different. length(unique(a.re)) [1] 82 quantile(a.re, c(.05,.95)) 5% 95% 3.17 3.61 quantile(a.re, c(.005,.985)) 0.5% 98.5% 3.06 3.67 Here is a histogram of the 3000 resampled averages, along with the boundaries of our 95% nonparametric bootstrap CI. Treating Likert scores as if numerical, the point estimate of the population mean score is $\bar X = 3.39$ (in the summary table above): if you really need a 'standard error` of this average, then you might use $0.133.$ sd(a.re) [1] 0.1327829 It is not very much different than the standard error of $\bar X,$ which is $S/\sqrt{n} 0.131.$ (That would be correct for normal numerical data.) sd(x)/sqrt(100) [1] 0.1309599
