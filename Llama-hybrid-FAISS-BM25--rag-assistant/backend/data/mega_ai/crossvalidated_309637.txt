[site]: crossvalidated
[post_id]: 309637
[parent_id]: 276857
[tags]: 
Read the following paper . It's a great read. On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima, Nitish Shirish Keska et al, ICLR 2017. There are many great discussions and empirical results on benchmark datasets comparing the effect of different batchsizes. As they conclude, large batchsize causes over-fitting and they explain it as it converges to a sharp minima. The code is also available here.
