[site]: crossvalidated
[post_id]: 271701
[parent_id]: 
[tags]: 
Why is step function not used in activation functions in machine learning?

The activation functions I have seen in practice are either sigmoid or tanh. Why isn't step function used? What is bad about using a step function in an activation function for neural networks? What are the effects of using step function? In what ways are sigmoid/tanh superior over step?
