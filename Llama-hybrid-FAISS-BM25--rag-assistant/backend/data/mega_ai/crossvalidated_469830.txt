[site]: crossvalidated
[post_id]: 469830
[parent_id]: 469518
[tags]: 
With cross-validation the basic steps for your case is: Starting with ncomp=1 Remove a fixed portion of data from training set Build a model with ncomp = 1 with the remaining data Predict the removed samples Compare the prediction with the actual values of removed samples (again for removed samples ofc.) Put the removed samples back into training set If all samples are removed once, calculate an average error, otherwise go to step 2 By doing so, an error estimate is calculated for ncomp=1. Similarly, for each ncomp the error is calculated. This is to somewhat simulate the performance of each ncomp on unseen data. On the other hand, autoprediction errors, that is calculating RMSE for each ncomp using entire training set each time , can provide a minimum RMSE for THAT DATA SET. In fact, for PLS, if you use all possible components you may end up with a nearly zero RMSE for training set while performing very bad on validation set or on any other unseen data. 99% of the time, CV is better for finding optimum parameter (ncomp) because it provides a good estimate for a higher predictive performance on unseen data or in other words for avoiding overfitting.
