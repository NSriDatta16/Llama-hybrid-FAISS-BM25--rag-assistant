[site]: crossvalidated
[post_id]: 400372
[parent_id]: 400326
[tags]: 
Normality testing with this kind of sample size (or in fact any sample size) is not a good way to pick your analysis method. It is pretty likely to reject a normal distribution (which you hopefully - if at all - checked for the residuals of a regression model that correctly takes correlations into account, not the raw data), even if the deviation are irrelevant for using a normal distribution based method. If the data are for the same time and date (if that is not the case, then you need to check that you are not getting differences simply due to measuring at different times), then this is actually paired data for those datetimes, plus there is likely correlation over time. If you use methods that do not reflect this, you will understate uncertainty and have p-values that are inappropriately too small. You may think you have 10,000+ observations per location, but depending on the correlations, you probably effectively don't. If you read the temperature 10,000 times within 1 second, you would effectively have barely more than 1 observation per location. Presumably your case is somewhere inbetween, but the p-values you've got since far are completely invalid. You probably need a model that reflects paired measurement occasions in time (e.g. random effect on the intercept for that) with either those or the residuals correlated in some way over time (something as simple as AR(1) is usually inappropriate) and models the time series of temperatures (or simpler, you could take the predicted temperatures for the region from some wheather service that gives sufficient granularity in time - e.g. by hour with you smoothing that out to minutes). You can then put a location effect into the model and test for that. You may also wish to consider whether there might be interactions - e.g. time of day with location (e.g. one location may be shaded by trees for longer on the morning than another). Finally, "statistically significant" does not equate to an effect having a meaningful size, so one may certainly say that while some difference was statistically significant the effect size was not of practical relevance.
