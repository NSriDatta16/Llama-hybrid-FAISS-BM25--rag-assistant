[site]: crossvalidated
[post_id]: 464551
[parent_id]: 
[tags]: 
Logistic Regression with continuous exogenous variable

So I'm trying to understand how a logistic regression can work with a continuous exogenous variable. I'm trying out this code with Python and statsmodels import statsmodels.api as sm import numpy as np X = pd.DataFrame({"v1": np.random.randn(10), "v2": np.random.randn(10), "v3": np.random.randn(10)}) y = np.abs(np.random.randn(10)) y /= y.max() X = sm.add_constant(X) print(X) print(y) >>> const v1 v2 v3 0 1.0 0.936366 1.733046 -1.431488 1 1.0 0.910953 -0.238240 1.391923 2 1.0 -0.547712 -0.027873 1.383092 3 1.0 -0.300446 -2.396009 -0.026780 4 1.0 2.797107 -0.727303 0.092896 5 1.0 1.059871 -0.191622 1.297797 6 1.0 0.449026 0.304059 0.499104 7 1.0 0.116308 -1.160632 -0.679466 8 1.0 -1.488820 0.559057 -0.657087 9 1.0 0.202345 -0.271734 -0.272912 >>> [1. 0.10742025 0.33584461 0.66050692 0.13558646 0.27380763 0.18360422 0.13515612 0.56243905 0.20743443] my_results = sm.Logit(y, X).fit() print(my_results.summary()) >>> Logit Regression Results ============================================================================== Dep. Variable: y No. Observations: 10 Model: Logit Df Residuals: 6 Method: MLE Df Model: 3 Date: Mon, 04 May 2020 Pseudo R-squ.: 0.1391 Time: 18:03:38 Log-Likelihood: -5.0427 converged: True LL-Null: -5.8575 Covariance Type: nonrobust LLR p-value: 0.6527 ============================================================================== coef std err z P>|z| [0.025 0.975] ------------------------------------------------------------------------------ const -0.3598 0.760 -0.473 0.636 -1.850 1.130 v1 -0.2760 0.686 -0.402 0.688 -1.621 1.069 v2 0.2650 0.687 0.386 0.699 -1.080 1.611 v3 -0.6850 0.827 -0.828 0.408 -2.306 0.936 ============================================================================== But what is actually going on under the hood? This seems to use the maximum likelihood to find the best coefficients, but I thought maximum likelihood is only defined for binary values
