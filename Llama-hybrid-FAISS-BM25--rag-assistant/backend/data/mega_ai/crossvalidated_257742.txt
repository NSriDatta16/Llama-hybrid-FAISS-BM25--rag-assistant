[site]: crossvalidated
[post_id]: 257742
[parent_id]: 
[tags]: 
Bayesian parameter estimation with negative binomial data. No model fit achieved!

I edited this question to a (hopefully) less confusing structure. The full R code is still available at the end of the post. My problem is a bad fit of the parameter n to my data. I will try to shortly explain the steps I have already taken on solving the problem. My question is, do you suggest that this function I am using is unsuitable for my data, or do I miss anything at the implementation of the model? The rjags model I am working on is this: model { for (i in 1:N) { y[i] ~ dnegbin (p[i], r) p[i] I run the sampler with 3 chains, 10000 adapt steps, 50000 burn-in steps and 300000 iterations. I am under the impression, that I am already using the reparameterization by parameters m and r, as J. Kruschke suggest in his blog post from 7th of April 2012. J. Kruschke blog I also tried to get a better prior on n: · I narrowed the mean and variance parameters of the dnorm distribution on the prior for n. · I used a truncated normal distribution · I tried a poisson distribution Every time I narrowed the parameter space below a critical point, the posterior distribution of n was highly dependent on the prior. Every time I used an uninformed, broad prior like log.n ~ dnorm(0,0.00001), the posterior distribution becomes bimodal and contains huge values. The function I am using has a biological meaning. The b parameter is a proportion of suitable habitats and the n parameter the total number of habitats. It is obvious that the parameter n should not expand to incredibly high numbers. This is the old, complete text, with some more details and the data I got 36 observations of count data. The data is negativ binomial distributed. I am using rjags so I used the JAGS code. The negbin parameter p is derived from the mean of the model (mu) I want to fit to the data and r, which has a uniform prior. For the model (mu) the parameters b and n use transformed values (logit for b, its a rate) and n (log) to match the normal prior distributions I choose. The model I choose has a certain meaning in my research context, so I would avoid changing the model, if possible. My problem is a bad fit of the parameter n! As you can see in the last plot, the estimated model line does not fit the data at all. I am not shure if I am doing it right by looking at the posterior distributions and HPD for each parameter on it's own. I am under the impression that there has to be a "best fit" joint probability for both parameter together? library(rjags) library(coda) library(dplyr) library(ggplot2) library(lattice) library(faraway) setwd("R:/desktop") y PS: I have in total 24 of those kind of data sets. This one is not the only one with such a confusing outcome.
