[site]: datascience
[post_id]: 37313
[parent_id]: 
[tags]: 
How do you generalize from stochastic to batch learning using gradient descent?

I understand pretty OK how to derive the formulas and implement stochastic gradient descent for a deep neural network (even though the total derivative magic for hidden layers is a bit pushing my limits). I'm struggling to grasp the fundamentals of generalizing the method to batch or mini batch training. From what I understand, in batch training you feed forward all of your batch's examples and then backpropagate the error. In stochastic backpropagation most computations involve taking the derivative of the error with respect to neurons' activations. But in the case of batch training there is one activation per training example. Do you average them or something ? Or is the math radically different? Is there a simple example somewhere that doesn't involve tensors?
