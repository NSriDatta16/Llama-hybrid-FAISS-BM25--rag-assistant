[site]: crossvalidated
[post_id]: 371199
[parent_id]: 371035
[tags]: 
OK, so you're really thinking of a discrete time process. Well, then you can maybe define p(t) to be piecewise constant, for example like p( $0:t_1$ ) = 0.5, p( $t_1:t_2$ ) = 0.2, p( $t_2:t_3$ ) = 0.5....p( $t_{S-1}:t_S$ )=0.7, in $S$ pieces. Then you can try something like reversible jump MCMC to sample different $S$ and different vaues for $t_1$ , $t_2$ etc, ie sample different # of changepoints. https://people.maths.bris.ac.uk/~mapjg/papers/RJMCMCBka.pdf Peter J. Green's paper in section 4 has an example, # of coal mining disasters, and the RJMCMC finds changepoints in the historic data. In your case, instead of using Poisson distribution for # of disasters each year, you can use a Bernoulli distribution. I've written a paper that uses Bernoulli likelihood (in small time windows) to infer a changing $\lambda(t)$ (or p_t, in your notation) given spike observations here: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005596 The above paper inferred a latent, unobserved $\lambda(t)$ from observation using Gibbs sampling and state space modeling, using Polya-Gamma data augmentation to sample for Bernoulli variables. http://www.academia.edu/download/46693506/Bayesian_Inference_for_Logistic_Models_U20160621-17860-1f6j9b3.pdf You could just as well say $\lambda(t_{n-1}:t_n)$ is piecewise constant over $S$ segments, and use RJMCMC explained in Green's paper.
