[site]: crossvalidated
[post_id]: 624671
[parent_id]: 624587
[tags]: 
Here are a couple of options that would be straightforward for you to implement: What you are doing is called hard voting i.e. each model votes on the class outcome. A likely better option is soft voting , in which each model's vote is weighted by its confidence. I've explained this in more detail here: Hard voting, soft voting in ensemble based methods Another way to integrate the information in the separate models is stacking . This involves training a different model on the predictions of the individual models in the ensemble. In general, there's only a few strategies that are generally used to integrate different machine learning models, discussed well in this thread: Bagging, boosting and stacking in machine learning
