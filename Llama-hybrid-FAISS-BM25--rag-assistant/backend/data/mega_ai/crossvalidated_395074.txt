[site]: crossvalidated
[post_id]: 395074
[parent_id]: 280684
[tags]: 
I would like to clarify that consistency in general does not imply asymptotic unbiasedness. Consider an estimator for $0$ taking value $0$ with probability $(n-1)/n$ and value $n$ with probability $1/n$ . It is a biased estimator since the expected value is always equal to $1$ and the bias does not disappear even if $n\to\infty$ . However, it is a consistent estimator since it converges to $0$ in probability as $n\to\infty$ . Asymptotic unbiasedness does not imply consistency either as it is mentioned in other answers. For example, the periodogram is an asymptotically unbiased estimator of the spectral density, but it is not consistent. Roughly speaking, consistency means that for large values of $n$ we are going to be close to the true value of the parameter with a high probability, i.e. estimates are going to be close to the true value of the parameter. Asymptotic unbiasedness means that for large values of $n$ on average we are going to be close to the true value of the parameter, i.e. the average of estimates is going to be close to the true value of the parameter, but not necessarily the estimates themselves.
