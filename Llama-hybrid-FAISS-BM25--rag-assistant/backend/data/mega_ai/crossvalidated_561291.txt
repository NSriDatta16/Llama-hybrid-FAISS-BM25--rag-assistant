[site]: crossvalidated
[post_id]: 561291
[parent_id]: 
[tags]: 
Usefulness of hierarchical variables in ML model

I am working on a binary classification problem with 1000 rows and 20 variables. The problem is about finding which product will meet the expected order quantities. We already have examples of certain products meeting expected order quantities and certain products not meeting the expected quantities. So, we have labels of positive and negative cases. Now, if a new order (for a specific product) comes in, we would like to know what is the likelihood that it will meet the expected order quantity (positive class) and if yes, what are the factors/variables which are influencing the outcome. I intend to use logistic regression for this problem My objective is to find out which product, from which region I have variables like product_id , city , state , country , product family , product type , product segment etc etc.. As you can see that most of my variables are hierarchical variables. Meaning, if I know the city name, I can infer/populate other variables like state , country etc. Same with product_id as well. If I know product_id info, I can get all info about product_family , product_segment , product type etc. My questions are as follows a) So, should I use only the granular level detail variables in my ML model and ignore other levels of same variable? because I guess it would be correlated b) Any suggestion or tips on how can we handle this scenario in our model? c) Should I drop this project because I only have very few granular level detail variables (and rest of it can be inferred based on them even without using AI)? d) If I make a prediction, I believe the contribution of hierarchical variable is same. For ex: If variable city contributes to prediction by 10%, am I right that state , country all contribute the same 10% as well. (meaning all together contribute 10% to the outcome) Can you help me with this please? Looking forward to your inputs
