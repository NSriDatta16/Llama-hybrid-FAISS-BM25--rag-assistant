[site]: datascience
[post_id]: 28980
[parent_id]: 28978
[tags]: 
You don't need word embeddings. Actually, in neural machine translation is frequent not to use them and simply train the embeddings along with the task. Nevertheless, word embeddings work as a data augmentation technique, as you normally use a different (and much larger) dataset to train them, so they can be useful when you don't have much training data. Therefore, the decision of using pre-trained word embeddings or not should be driven by the available data.
