[site]: crossvalidated
[post_id]: 286574
[parent_id]: 
[tags]: 
Getting the betas of a logistic regression tuned with CalibratedClassifierCV

Is there a way, after calibrating a logistic regression, to average out the 3 resulting logistic regressions' coefficients into a single Logit? Example (in sklearn): from sklearn.calibration import CalibratedClassifierCV from sklearn.linear_model import LogisticRegression calibrated_logit = CalibratedClassifierCV(LogisticRegression(), cv=3) calibrated_logit.fit(X_train, y_train) This code will generate 3 models, each of which will emit a different proba, which then gets averaged out. Is there a way to combine the coefficients of each logit into a single one that would achieve the same effect? Note: I'm aware that there are a number of publications claiming that logistic regressions to not need to be calibrated, but I've been finding considerable empirical evidence to the contrary in highly unbalanced datasets.
