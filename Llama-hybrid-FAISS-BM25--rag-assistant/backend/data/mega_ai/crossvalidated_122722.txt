[site]: crossvalidated
[post_id]: 122722
[parent_id]: 
[tags]: 
Please explain the waiting paradox

A few years ago I designed a radiation detector that works by measuring the interval between events rather than counting them. My assumption was, that when measuring non-contiguous samples, on average I would measure half of the actual interval. However when I tested the circuit with a calibrated source the reading was a factor of two too high which meant I had been measuring the full interval. In an old book on probability and statistics I found a section about something called "The Waiting Paradox". It presented an example in which a bus arrives at the bus stop every 15 minutes and a passenger arrives at random, it stated that the passenger would on average wait the full 15 minutes. I have never been able to understand the math presented with the example and continue to look for an explanation. If someone can explain why it is so that the passenger waits the full interval I will sleep better.
