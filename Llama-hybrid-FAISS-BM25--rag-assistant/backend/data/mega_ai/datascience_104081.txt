[site]: datascience
[post_id]: 104081
[parent_id]: 
[tags]: 
Can a random forest learn time series correlations?

We have a data set with a set of N engineered features in each row. These features are actually a time series. I am being asked to use them to train a random-forest-type model for classification. However no effort is being made to treat the features as a time series such as account for correlations or seasonality. The model formula is just identical to that of an additive linear model: y ~ b0 + b1 + b2...b120 The lead insists that the random forest, because it learns complex interactions, will learn the appropriate correlations foe the time series. Is this right?
