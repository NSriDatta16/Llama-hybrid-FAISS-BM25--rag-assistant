[site]: crossvalidated
[post_id]: 249729
[parent_id]: 249603
[tags]: 
This type of fine-tuned (Gibbs) MCMC is appropriate for cases when one conditional distribution is most "sticky" than other conditional distributions in the problem. For instance, updating only one [random] part of $\beta$ may be profitable when updating the whole vector results in high rejection rates or in very small moves. An early reference on mixing several MCMC steps is Tierney (1994) . (Gareth Roberts and Jeff Rosenthal have also written several papers on comparing such mixtures of MCMC steps.) However, updating the same parameter twice in a row, using the full conditional distribution given all others, is a waste of computational time since it means simulating twice from exactly the same distribution. The way the code is written, it seems to be the case: theta since the update function does not depend on the current value of theta . But when using a Metropolis-Hastings move using several iterations instead of one can make sense when the moves are of limited magnitude. Similarly, if the iterated calls to update modify only parts of the whole parameter theta and if those parts are chosen at random, this is a form of random block Gibbs sampling. And this is perfectly valid. Here is an instance of such a strategy. And an older one . (In an even older paper with Christophe Andrieu , we looked at an adaptive choice for the size of the blocks, if not for the number of moves for given blocks. But this can be incorporated within an adaptive MCMC algorithm as well.) Suggested Reading: A most relevant paper that appeared on arXiv a few days ago is The Recycling Gibbs Sampler for Efficient Learning by Luca Martino, Victor Elvira and Gustau Camps-Valls that I reviewed on my blog yesterday .
