[site]: crossvalidated
[post_id]: 89188
[parent_id]: 
[tags]: 
Optimizing False Negative Rate after Logistic Regression

I created a probit model and tested it against a random sub sample of my dataset. I am interested specifically in seeing how many data points I can predict to be FALSE without having too many that are actually TRUE. Using the threshold of 0.1 (see below), I was able to predict to be FALSE about 30% with a false negative rate of 2.5%. However, I don't know if this is optimal. Is there a way for me to pick my threshold that maximizes my FALSE predictions while minimizing my false negatives? glm.fit=glm(Outcome~A+B+C+D+E+F+G,data=myData,family=binomial(link="probit")) test=mysample .1]=1 x
