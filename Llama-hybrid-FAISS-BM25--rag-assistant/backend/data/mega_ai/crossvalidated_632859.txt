[site]: crossvalidated
[post_id]: 632859
[parent_id]: 352858
[tags]: 
As has been pointed out, using clustering as a feature engineering step is common practice. If you think you have discreet clusters present in your data and those meaningfully contribute to your classification then you can use an appropriate clustering algorithm and use the output as a new feature and as such make a mini ensemble model. Although be careful when doing so, different clustering algorithms will produce very different results. It really depends on the question you are trying to answer, one popular application is anomaly detection. As for constructing two models on separate clusters. Usually this approach is used when you know you have separate clusters of data, let's say you work in a bank and one group of transactions are outgoing transactions, the other incoming ones. In such cases it makes sense to make two separate models based on the knowledge you have about the data, no clustering needs to be used. Sure you could also just use a clustering algorithm and then make separate models for each cluster, but it's easier then to just build a gradient boosted tree model with the whole dataset and make it heavily depend on the feature that you got from clustering for its decision making, not that i would recommend it though. A much more robust way of doing it would be to make multiple features with different clustering algorithms (used in a appropriate way) and then let the gradient boosting model decide which features it wants to use.
