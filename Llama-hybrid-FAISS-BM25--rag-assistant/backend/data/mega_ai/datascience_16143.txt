[site]: datascience
[post_id]: 16143
[parent_id]: 
[tags]: 
What is the procedure to create a bag of visual words model with SIFT?

I have more than 1500 black and white classified images in a training set and I want to create a probabilistic model to classified new images. To be more explicit, given a new black and white image, my model has to predict: animal: 84% vegetal: 12% mineral: 4% I watched this lecture and I still have questions about the procedure to create this model. 1. Extraction of the keypoints of each image If I correctly understood the video, the first step is to extract all the keypoints with SIFT from all the images to create a kind of dictionary of visual words. Each word is described by a multidimensional vector. Next, I have to use the $k$-means method to create groups of visual words. Question 1: how many groups should I create? Does it exist a rule-of-thumb to determine the $k$ number I have to use? 2. Creation of histograms Now, for each image, I have to create an histogram/a vector where each features corresponds to one group defined in part 1. The value associated to each feature corresponds to the frequency of the word in the image. Question 2: how can I create this vector? Indeed, each image is unique and will never match perfectly with the words in my dictionary (words who is, by the way, mean of different words). Who can I bypass this problem? 3. Creation of the model Finally, I have to create my model. In the video, the lecturer used SVM and has to create one classifier by category (binary classifier). In my case, I have 100 different categories (my introduction was a simplification) and I prefer to have only one classifier. Also, I want to get the probabilities, given an image, to be part of a category. Question 3: is it possible to create only one classifier who gives probabilistic data? To finish, don't hesitate to make suggestions or corrections about the procedure I described if you know a better way to classified my data.
