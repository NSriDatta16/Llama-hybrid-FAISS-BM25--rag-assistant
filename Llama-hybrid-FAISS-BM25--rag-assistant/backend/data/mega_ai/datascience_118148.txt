[site]: datascience
[post_id]: 118148
[parent_id]: 118144
[tags]: 
All machine learning and Deep Learning frameworks take advantage of the multiple cores of the GPUs (CUDA) to make tensor calculations faster. The integrated graphics cards don't have CUDA support so the frameworks will use the CPU. I recommend you to write this line in your code: device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu") And send the processes to the device. Doing this PyTorch will use the GPU if it's available.
