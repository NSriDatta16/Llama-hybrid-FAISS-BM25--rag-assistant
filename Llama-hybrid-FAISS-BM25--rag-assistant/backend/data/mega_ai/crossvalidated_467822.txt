[site]: crossvalidated
[post_id]: 467822
[parent_id]: 
[tags]: 
Positional features and feedback loops in ranking

I read the following in the Google "rules for machine learning" : Rule #36: Avoid feedback loops with positional features. The position of content dramatically affects how likely the user is to interact with it. If you put an app in the first position it will be clicked more often, and you will be convinced it is more likely to be clicked. One way to deal with this is to add positional features, i.e. features about the position of the content in the page. You train your model with positional features, and it learns to weight, for example, the feature "1st­position" heavily. Your model thus gives less weight to other factors for examples with "1st­position=true". Then at serving you don't give any instances the positional feature, or you give them all the same default feature, because you are scoring candidates before you have decided the order in which to display them. I'm not I understand the advice. Why would anyone ever use positional features for ranking IF you don't have that information at serving time? If that's not feature that your system has at serving time, what value does it have to use it?
