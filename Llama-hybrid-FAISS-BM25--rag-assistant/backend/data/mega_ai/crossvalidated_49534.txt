[site]: crossvalidated
[post_id]: 49534
[parent_id]: 49506
[tags]: 
For number 1 the answer is no when computed correctly (but is possible when the original value is left out). Instead of sum(res$shufflederr you should use something like: sum(c(res$shufflederr,observed$regerror) which includes the original ordering as one of the possible permutations and switches from less than to less than or equal to, since there could be many permutations that give the same test statistic and those need to be counted as well. For number 2, when you need a cutoff for the p-value then you should choose that cutoff in similar ways as you would for parametric or other tests. This should represent your understanding of the consequenses of the possible errors, not something specific to the way you calculate the p-values. For 3, look into parallel processing. This is an example of an embarassingly parallel problem and would be very easy to parallelize. For the innermost loop you could replace it with a call to replicate , then you don't need to keep using rbind . If not then it is better to preallocate a matrix of the correct size and assign into the rows of that matrix than to keep rbind ing to a matrix, this slows things down as you keep making copies and it fragments your memory.
