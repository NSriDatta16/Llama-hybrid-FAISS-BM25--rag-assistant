[site]: crossvalidated
[post_id]: 286570
[parent_id]: 162257
[tags]: 
There is some confusion that may arise here. Originally a perceptron was only referring to neural networks with a step function as the transfer function. In that case of course the difference is that the logistic regression uses a logistic function and the perceptron uses a step function. In general both algorithm should yield the same decision boundary (at least for a single neuron perceptron). However: The parameter vector for the perceptron may be arbitrarily scaled compared to the one derived by logistic regression. Any scaling of the parameter vector will define the same boundary, but the probabilities calculated by logistic regression depend on the exact scaling. The output from a step function can of course not be interpreted as any kind of probability. Since a step function is not differentiable, it is not possible to train a perceptron using the same algorithms that are used for logistic regression. In some cases, the term perceptron is also used to refer to neural networks which use a logistic function as a transfer function (however, this is not in accordance with the original terminology). In that case, a logistic regression and a "perceptron" are exactly the same. Of course, with a perceptron it is possible to use multiple neurons all using a logistic transfer function, which becomes somewhat relatable to stacking of logistic regression (not the same, but similar).
