[site]: crossvalidated
[post_id]: 559896
[parent_id]: 
[tags]: 
features selection and hyperparameter tuning

I am testing optimal subsets of features and I choose the SVM classifier. In the process, the training set is used for feature selection to train models with different subsets, validate the subset on the validation set, and test them on an unseen test set. whereas, I am optimizing the hyperparameters separately using all features and using the tuned hyperparameters for training the different subsets. I just want an opinion that the way I am conducting this experiment is right or not? if I am tuning the hyperparameters separately, do I need to have a validation set for validating the subsets? Or should i tune the hyperparameters for each subset or just globally?
