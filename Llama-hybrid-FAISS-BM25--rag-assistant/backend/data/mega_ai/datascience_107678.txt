[site]: datascience
[post_id]: 107678
[parent_id]: 
[tags]: 
Consistency between multiple word predictions in a single NLP sentence

Considering a model which predicts multiple missing words in a sentence: The ___ is preparing the ___ in the ___ There is no pre-existing context in this masked sentence which could inform the model on what the topic is. In the context of either an LSTM-based or convolutions-based model, what would be some strategies to apply either in the modelling part, or in the loss function part, to favor predictions which are consistent with one another? Examples of consistent predictions: The [cook] is preparing the [meal] in the [kitchen] The [mechanic] is preparing the [car] in the [garage] The [sound engineer] is preparing the [microphone] in the [studio] Examples of inconsistent predictions: The [cook] is preparing the [microphone] in the [park] The [translator] is preparing the [chicken] in the [office]
