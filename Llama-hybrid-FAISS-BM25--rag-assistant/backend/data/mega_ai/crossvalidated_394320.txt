[site]: crossvalidated
[post_id]: 394320
[parent_id]: 
[tags]: 
Why is information gain rarely used as a reported effect size?

Commonly, in reporting effect sizes in medical articles, papers typically report: risk difference (RD), relative risk (RR) and odds ratio (OR) (and for variable timescale cases and other situations, proportional hazard CPH, which I'll ignore for this). By contrast, machine learning methods looking to maximize discrimination between groups may optimize information gain (IG), or information gain ratio IGR (e.g. most methods employing decision trees). In ML, this is strongly the favorite measure of group difference. Each of these methods are simply group difference effect size scores (scores of a confusion matrix) and can be all applied in the same scenarios to detect 'surprise'. Hypothesis: RD, RR, OR are less commonly used in ML for decision tree building because they are less effective at building models in out-of-sample tests. (Is it true? I assume , so.) Question: Why are IG, IGR not popular measures of group discrimination in reporting? (Notably its not mentioned once in this book: https://www.amazon.com/Essential-Guide-Effect-Sizes-Interpretation/dp/0521142466 )
