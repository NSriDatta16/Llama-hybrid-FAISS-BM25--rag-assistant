[site]: crossvalidated
[post_id]: 499028
[parent_id]: 
[tags]: 
Learning curve for kNN train set doesn't change with training size. Why?

I am training several models for a binary classification task (balanced dataset). After hyperparameter tuning, the learning curves for Logistic Regression converge to a value (no overfitting). This is not the case for kNN, as the curve for the training set has an almost constant value around 1. Why is that exactly? How can I fix it? I have attached a photo that shows this: The code I use for plotting learning curves (influenced from the documentation ): def plot_learning_curve(estimator, name, X, y, cv = None, train_sizes = np.linspace(0.1, 1.0, 5)): train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv = cv, n_jobs = -1, train_sizes = train_sizes, scoring = 'accuracy') train_scores_mean, train_scores_std = np.mean(train_scores, axis = 1), np.std(train_scores, axis = 1) test_scores_mean, test_scores_std = np.mean(test_scores, axis = 1), np.std(test_scores, axis = 1) . . .
