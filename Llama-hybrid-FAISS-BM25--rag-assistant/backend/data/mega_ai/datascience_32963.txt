[site]: datascience
[post_id]: 32963
[parent_id]: 32927
[tags]: 
Training scores can be expected to be better than those of the validation when the machine you train can "adapt" to the specifics of the training examples while not successfully generalizing; the greater the adaption to the specifics of the training examples and the worse generalization, the bigger the gap between training and validation scores (in favor of the training scores). In cases in which training as well as validation examples are generated de novo , the network is not presented with the same examples over and over. It thus cannot overfit to accommodate them while losing the ability to respond correctly to the validation examples - which, after all, are generated by the same process as the training examples. For an example of such an approach you can have a look at my experiment . As you commented, this in not the case here, you generate the data only once. So this does not explain why you do not see overfit. Other explanations might be that this is because your network does not have enough trainable parameters to overfit, coupled with a relatively large number of training examples (and of course, generating the training and the validation examples with the same process). It might also be possible that you will see overfit if you invest more epochs into the training. Might be an interesting experiment. Okay, so this explains why the validation score is not worse. But why is it better? Be advised that validation, as it is calculated at the end of each epoch, uses the "best" machine trained in that epoch (that is, the last one, but if constant improvement is the case then the last weights should yield the best results - at least for training loss, if not for validation), while the train loss is calculated as an average of the performance per each epoch. Thus, if the machine is constantly improving and does not overfit, the gap between the network's average performance in an epoch and its performance at the end of an epoch is translated into the gap between training and validation scores - in favor of the validation scores. Give or take minor variations that result from the random process of sample generation (even if data is generated only once, but especially if it is generated anew for each epoch).
