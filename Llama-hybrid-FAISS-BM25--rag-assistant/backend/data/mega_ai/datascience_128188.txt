[site]: datascience
[post_id]: 128188
[parent_id]: 
[tags]: 
CNN to estimate a density map of an image, used to predict the object count

I'm trying to count the number of objects (larvae in this case), from a video. The constraint is, I cannot use any ML model, nor can I train my dataset as there are no annotations available. This being the overall goal, I first tried density map on all the frames from the video, and it gave me a very large prediction, i.e., the predicted value was of the order 1e7, when the larvae count is ~50. On looking at density plots more closely, I notice the algorithm is counting objects which are not even larvae, so I thought let me narrow down the question to just one frame at the moment. In the first frame, I look at applying the k-means cluster on the colours present in the image. Then after a lot of manipulation, I decide, it is top 20 colours expressed is something that I should look at. After finding the right tolerance value for masking the image and manually deciding the colour which most closely align with the colour of the larvae, I apply density map on masked image for the colour of interest. It now happens that the count is now of thee order 1e3, but still wrong. When looking closely at the density maps, it is predicting/ counting the density of point objects and this is the reason for my issue. I need help with two major things: How to automatically choose the colour of larvae instead of manually choosing them? How do I change the density map such that it doesn't count point objects, but give me a closer answer for my actual count. For the 1st aspect, I am thinking, I take 1st from from the the (n,n+10) frames and check thee colours which have moved a lot, the ones which have major shift should be the colour of larvae, but I am not sure if this will work, nor am I sure on how to code this. For the second I have no clue about it, and am hoping someone can help me out here. The code for kmeans clustering that I'm using is: import numpy as np import cv2 import matplotlib.pyplot as plt # Create a video capture object video_path = '/Users/dev.barbhaya9gmail.com/Library/CloudStorage/OneDrive-IITKanpur/Research/Nitin_Gupta/VID_20240129_182938.mp4' cap = cv2.VideoCapture(video_path) # Get the video properties frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Process the first frame ret, frame = cap.read() if ret: # Reshape the frame to a 2D array of pixels and 3 color values (RGB) pixel_values = frame.reshape((-1, 3)) # Convert to float pixel_values = np.float32(pixel_values) # Define criteria for K-means clustering criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2) # Number of clusters (colors) to detect k = 20 # Change this to 20 for top 20 colors # Perform K-means clustering _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) # Convert back to 8-bit values centers = np.uint8(centers) # Get the top twenty dominant colors unique, counts = np.unique(labels, return_counts=True) top_twenty_indices = np.argsort(counts)[-20:][::-1] top_twenty_colors = centers[top_twenty_indices] # Create a masked frame for each of the top twenty dominant colors for i, color in enumerate(top_twenty_colors): # Define a threshold for color matching color_match_threshold = 20 # Adjust this threshold as needed # Create a mask for the current color mask = np.linalg.norm(frame - color, axis=-1) The code for density map is: import numpy as np import tensorflow as tf from tensorflow.keras.layers import Conv2D, Input from tensorflow.keras.models import Model from tensorflow.keras.losses import MeanSquaredError import cv2 # Create the density map estimation model def create_density_map_model(input_shape): inputs = Input(shape=input_shape) x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs) x = Conv2D(64, (3, 3), activation='relu', padding='same')(x) density_map = Conv2D(1, (1, 1), activation='linear', padding='same')(x) model = Model(inputs=inputs, outputs=density_map) return model # Load the image image_path = 'color_17.png' image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED) # Extract the alpha channel from the image alpha_channel = image[:, :, 3] # Threshold the alpha channel to get a binary mask where non-transparent pixels are white (255) and transparent pixels are black (0) _, binary_mask = cv2.threshold(alpha_channel, 0, 255, cv2.THRESH_BINARY) # Get the height and width of the image image_height, image_width = image.shape[:2] # Create and compile the model input_shape = (image_height, image_width, 1) model = create_density_map_model(input_shape) model.compile(optimizer='adam', loss=MeanSquaredError()) # Preprocess the image image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) image_normalized = image_gray / 255.0 image_input = np.expand_dims(image_normalized, axis=-1) image_input = np.expand_dims(image_input, axis=0) # Predict the density map for the image predicted_density_map = model.predict(image_input) # Reshape the predicted density map to match the shape of the image predicted_density_map = np.reshape(predicted_density_map, (image_height, image_width, 1)) # Create a size factor map (assuming all pixels have the same size factor for simplicity) size_factor_map = np.ones_like(predicted_density_map) # Apply the size factor map to the predicted density map predicted_density_map_filtered = predicted_density_map * size_factor_map # Expand the dimensions of the binary mask to match the number of channels in the predicted density map binary_mask_reshaped = np.expand_dims(binary_mask, axis=-1) # Apply the binary mask to the filtered density map to only keep values where the image isn't transparent predicted_density_map_filtered = predicted_density_map_filtered * (binary_mask_reshaped / 255.0) ## Apply the binary mask to the filtered density map to only keep values where the image isn't transparent #predicted_density_map_filtered = predicted_density_map_filtered * (binary_mask / 255.0) # Save the filtered density map as an image cv2.imwrite('density_plot_filtered.jpg', (predicted_density_map_filtered * 255.0).astype(np.uint8)) # Calculate the number of larvae predicted from the filtered density map num_larvae_predicted = int(np.sum(predicted_density_map_filtered)) # Print the number of larvae predicted print(f"Number of larvae predicted: {num_larvae_predicted}") The video that I used for the first code, i.e., the kmeans for identifying the top 20 expressed colours can be found here: https://iitk-my.sharepoint.com/:v:/g/personal/abint21_iitk_ac_in/EexjUqun0pZFmzRTxTBHGFoB8ML2hX5iZ6luH9QVWpLjKA?e=mLQLfb To add, the colour of interest when viewed with rgba palette looks like this: The density plot for this image comes out as something like this: I hope this information was helpful for making the details clear. Please let me know in case more details are needed.
