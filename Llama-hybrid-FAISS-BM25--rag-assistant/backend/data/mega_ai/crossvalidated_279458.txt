[site]: crossvalidated
[post_id]: 279458
[parent_id]: 277568
[tags]: 
When MCMC research gained momentum in the 90s, there was a lot of emphasis on diagnosing convergence of the Markov chain. A variety of diagnostics were proposed. A lot of them imposed certain conditions that were difficult to check, i.e. geometric rates of convergence or existence of a Markov chain central limit theorem. Proving that these conditions hold requires careful analysis of each individual MCMC algorithm. One reason for there not being a lot of research in convergence diagnostic is because the Markov chain will have generally never converged in truth, since convergence is only an asymptotic property (as Xi'an's comment below indicates, this is not always the case, and she/he outlines some instances where drawing exact samples is possible). Another reason is that the distribution to which Markov chain is converging is unknown, so determining whether the chain has converged to this unknown distribution is very difficult. Consider the "Witch's Hat" distribution, which is uniform distribution in any closed interval around 0 and positive mass at 0. Without knowing this true underlying distribution, the Markov chain is likely to never move to 0, and any convergence diagnostic will incorrectly declare the Markov chain to have converged to a uniform distribution. Alternatively, lately, there has been more research into ensuring large enough Monte Carlo sample size to ensure small error in estimation. These methods don't worry much about Markov chain converging, but more about whether the estimates obtained are good. See this , this , and this .
