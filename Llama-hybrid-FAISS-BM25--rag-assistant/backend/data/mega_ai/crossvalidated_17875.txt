[site]: crossvalidated
[post_id]: 17875
[parent_id]: 17854
[tags]: 
When I hear the statement "A tends to be greater than B" it sounds like A is greater than B a bunch of the time, say, more than 50% of the time. This can happen when $\mu_{A}$ is greater than $\mu_{B}$, but it can also happen that $\mu_{A}$ is greater than $\mu_{B}$... yet $P(A > B) (For a concrete example of what I'm getting at, let B be identically 1/2, and let A put probability $1 - p$ on zero with its remaining probability $p$ on some integer $n \geq 1$. We can make $P(A > B)$ as small as we like by letting $p \to 0$, yet we can make $\mu_{A}$ as big as we like by letting $n \to \infty$.) On top of all this, it looks like your "B" is itself a "mean", which complicates the language. So, my first thought is to try to figure out whether you'd be more interested in $\mu_{A} > \mu_{B}$ or if you'd rather be more interested in $P(A > B) > 0.50$. If you're interested in the means then the t-test should be just fine. If you're more interested in $P(X > Y)$, you might consider the Sign Test . It's a nonparametric test, it's light on assumptions, and you don't need to be so concerned about outliers. If you could additionally say that the distribution of the differences of organic matter was symmetric, you could do one better and go for the Wilcoxon Signed Rank test . Anyway, suppose you can say nothing more about the distributions, and suppose they are appropriate for the Sign Test. The data given above had 8 out of 9 pairs with A greater than B. For these data, in R, you would do binom.test(8, 9, alt = "greater") The output would give a p-value and a 95% one-sided Clopper-Pearson confidence interval (which generally is conservative).
