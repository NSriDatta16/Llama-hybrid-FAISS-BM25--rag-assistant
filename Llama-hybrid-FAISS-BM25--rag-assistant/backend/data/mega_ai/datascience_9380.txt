[site]: datascience
[post_id]: 9380
[parent_id]: 9175
[tags]: 
Check this lecture and this visualization Usually it is used type 2.1 convolution. In the input you have $NxMx1$ image, then after first convolution you will obtain $N_1xM_1xk_1$ , so your image after first convolution will have $k_1$ channels. The new dimension $N_1$ and $M_1$ will depend on your stride $S$ and padding $P: N_1 = (N - 3 + 2P)/S + 1$ , you compute $M_1$ in analogy. For the first conv layer you will have $3x3xk_1 + k_1$ weights. There is added $k_1$ for biases in nonlinear function. In the second layer you have as an input image with size $N_1xM_1xk_1$ , where $k_1$ is new number of channels. And after second convolution you obtain $N_2xM_2xk_2$ image (array). You have $5x5xk_2xk_1+k_2$ parameters in the second layer. For $1x1$ convolution with $k_3$ filters and input $NxMxC$ ( $C$ is number of input channels) you will obtain new image (array) $NxMxk_3$ , so $1x1$ make sense. They were introduced in this paper Bonus 1: pooling is applied per feature map. For details please see slides for CNN course on Stanford - you have there nice visualisation how convolution is summed from several input channels.
