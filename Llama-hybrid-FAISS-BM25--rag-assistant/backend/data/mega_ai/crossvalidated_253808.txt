[site]: crossvalidated
[post_id]: 253808
[parent_id]: 
[tags]: 
Reducing the multiclass SVM problem with 2 classes to the standard SVM problem

Given the multiclass SVM problem with a hinge loss, and no bias (e.g. $b=0$): $$ f= \sum_{j\in[K]}\frac12||\mathbf w_j||^2+\frac{C}m \sum_{i=1}^m \ell(\mathbf w_1,...,\mathbf w_K,\mathbf x_i,y_i)$$ Where $\ell(\mathbf w_1,...,\mathbf w_K,\mathbf x_i,y_i)=\max_{j\in[K]}\{\mathbf w_j\cdot\mathbf x_i-\mathbf w_{y_i}\cdot\mathbf x_i + 1(j\neq y_i)\}$ I want to show that for $K=2$ the function $f$ reduces to the standard SVM problem, e.g. $$ f'= \frac12||\mathbf w||^2+C \sum_{i=1}^m \max\{0,1-y_i\mathbf w \cdot \mathbf x_i\} $$ By simply plugging $K=2$ in $f$, we get: $$ f= \sum_{j\in[K]}\frac12||\mathbf w_j||^2+\frac{C}m \sum_{i=1}^m \max_{j\in[K]}\{0,(\mathbf w_1 - \mathbf w_2)\mathbf x_i+1,(\mathbf w_2 - \mathbf w_1)\mathbf x_i+1\}$$ I tried to define $\mathbf w = \mathbf w_1 - \mathbf w_2$, but the first summing term still remains. I also tried to calculate the derivatives with respect to $\mathbf w_1$ and $\mathbf w_2$ in order to find their values at optimum, and by setting the result to $0$, I got that $\mathbf w_1= -\mathbf w_2$. Yet, it didn't lead me to something. What am I missing?
