[site]: crossvalidated
[post_id]: 304849
[parent_id]: 
[tags]: 
Machine learning model metrics vs predicted probability?

If I train a machine learning model, how do you explain the relation between model metrics and a predicted output? For example with a Logistic Regression, through a series of parameter tuning CV iterations I find a model that preforms 0.95 overall accuracy, 0.75 precision on positive class, and 0.66 recall on positive class. Now when I make some predictions on two new datapoints, I get 0.45 and 0.99 as the predicted probabilities. How would you explain these outputs to someone? Would you say the 0.45 is 45% confident/likely to be a positive class, while the model is still only 0.75 precise? My business goal is to make a model that can say "we are X% sure that something will happen". Which numbers are valid to use to define X?
