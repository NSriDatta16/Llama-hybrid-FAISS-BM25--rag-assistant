[site]: datascience
[post_id]: 26808
[parent_id]: 26779
[tags]: 
The closest I can think of is research into "adversarial" transformations of data (usually images) that cause classifiers (usually CNNs) to fail. Here's a blog post which discusses a bit about how these transformations are constructed, some approaches that have been tried to address them, and what some of the consequences of their existence might be. You might also be interested to read about the No Free Lunch Theorem .
