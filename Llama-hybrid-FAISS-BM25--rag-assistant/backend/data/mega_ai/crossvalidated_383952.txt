[site]: crossvalidated
[post_id]: 383952
[parent_id]: 
[tags]: 
Odd SVM output - Need explanation

I built a linear SVM model. My data has 105 subjects and 115 features, which I ordered from least important to most important. I iterated through them to find the f1-score with all 115 features, then with the best 114 features, then with the best 113 features, etc... Why are the f1-scores so unstable? And how is it possible to have a high(ish) f1-score with only 1 feature? My code and output graph are below: y = np.array(mimic_d['Recurrent_epis']) x = np.array(mimic_d.drop(['Recurrent_epis'], 1)) rows, columns = x.shape f1 = [] num_features = [] np.random.seed(123) for i in range(columns): pred = x[:, i:115] num_features.append(pred.shape[1]) pred_s = scale(pred) xs_train, x_test, y_train, y_test = train_test_split(pred_s,y,test_size=0.30) svclf = SVC(kernel='linear') svclf.fit(xs_train, y_train) y_pred = svclf.predict(x_test) classification_report(y_test,y_pred) p, r, f, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted') f1.append(f)
