[site]: datascience
[post_id]: 120292
[parent_id]: 120189
[tags]: 
Class-wise confidence thresholding In the previous answer, Manual Annotation was suggested as a Human-SuperVised method for mapping classes. However, I asked the same question to ChatGPT, and the gist of its response was : How could CIFAR 100 be used to measure OOD performance for a multi-classifier trained on CIFAR 10? "To measure the OOD performance of the model, we can evaluate its ability to correctly identify samples from CIFAR 100 as OOD. One approach is to use the model's predictive uncertainty to identify OOD samples. For example, if the model's predicted probability for a sample from CIFAR 100 is low for all classes, we can conclude that the sample is likely OOD. On the other hand, if the model's predicted probability for a sample from CIFAR 100 is high for one of the classes in CIFAR 10, we can conclude that the sample is not OOD."
