[site]: crossvalidated
[post_id]: 368001
[parent_id]: 
[tags]: 
Is the output of a variational autoencoder meant to be a distribution that can be sampled, or a sample directly?

It is difficult to ask this question succinctly in the title, so let me explain. From all the examples of VAEs I have seen, there seem to be 2 approaches used to implement them. In these , approaches , the output of the decoder is a distribution. Specifically, a Bernoulli distribution. The loss is related to the likelihood of the input data with respect to this distribution. When generating new variables, not only are samples drawn from the latent space distributions, but also, samples are drawn from the output distributions. I have a question related to the parameterization of the output distributions using this approach, but I will save that for the end. In these , approaches , the output of the decoder is the actual predicted data points, which are then compared to the input to calculate the loss, as mean squared error. The only thing that ever gets sampled is the latent space. These 2 approaches are fundamentally different. I notice that in the first approach, the authors relate the idea to a statistical/probabilistic motivation, and it seems to have a solid theoretical foundation. For this reason I am inclined to adopt the 1st approach. So my questions are: Are either of these approaches considered to be superior? The second question is more of a sense check: Bernoulli distribution makes sense for grey scale pixels. But for something like stock returns, we would want some other distribution, such as a t-distribution. In this case, the output of the encoder would be 3 vectors, 1 for location, 1 for scale, and 1 for degrees of freedom, right?
