[site]: crossvalidated
[post_id]: 38659
[parent_id]: 29990
[tags]: 
An outlier is a point that is "too far" from "some baseline". The trick is to define both those phrases! With nonlinear regression, one can't just use univariate methods to see if an outlier is "too far" from the best-fit curve, because the outlier can have an enormous influence on the curve itself. Ron Brown and I developed a unique method (which we call ROUT -- Robust regression and Outlier removal) for doing detecting outliers with nonlinear regression, without letting the outlier affect the curve too much. First fit the data with a robust regression method where outliers have little influence. That forms the baseline. Then use the ideas of the False Discovery Rate (FDR) to define when a point is "too far" from that baseline, and so is an outlier. Finally, it removes the identified outliers, and fits the remaining points conventionally. The method is published in an open access journal: Motulsky HJ and Brown RE, Detecting outliers when fitting data with nonlinear regression – a new method based on robust nonlinear regression and the false discovery rate , BMC Bioinformatics 2006, 7:123. Here is the abstract: Background. Nonlinear regression, like linear regression, assumes that the scatter of data around the ideal curve follows a Gaussian or normal distribution. This assumption leads to the familiar goal of regression: to minimize the sum of the squares of the vertical or Y-value distances between the points and the curve. Outliers can dominate the sum-of-the-squares calculation, and lead to misleading results. However, we know of no practical method for routinely identifying outliers when fitting curves with nonlinear regression. Results. We describe a new method for identifying outliers when fitting data with nonlinear regression. We first fit the data using a robust form of nonlinear regression, based on the assumption that scatter follows a Lorentzian distribution. We devised a new adaptive method that gradually becomes more robust as the method proceeds. To define outliers, we adapted the false discovery rate approach to handling multiple comparisons. We then remove the outliers, and analyze the data using ordinary least-squares regression. Because the method combines robust regression and outlier removal, we call it the ROUT method. When analyzing simulated data, where all scatter is Gaussian, our method detects (falsely) one or more outlier in only about 1–3% of experiments. When analyzing data contaminated with one or several outliers, the ROUT method performs well at outlier identification, with an average False Discovery Rate less than 1%. Conclusion. Our method, which combines a new method of robust nonlinear regression with a new method of outlier identification, identifies outliers from nonlinear curve fits with reasonable power and few false positives. It has not (as far as I know) been implemented in R. But we implemented it in GraphPad Prism. and provide a simple explanation in the Prism help .
