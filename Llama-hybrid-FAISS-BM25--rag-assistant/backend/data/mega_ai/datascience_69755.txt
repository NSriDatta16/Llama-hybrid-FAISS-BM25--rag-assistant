[site]: datascience
[post_id]: 69755
[parent_id]: 65795
[tags]: 
I think your interpretation is not entirely correct. Loosely rephrasing Lundberg et al. [arXiv:1802.03888] , the SHAP value of feature $i$ is $$ E[f(x) \mid S \cup \{i\}] - E[f(x) \mid S] $$ averaged over all possible subsets of features $S$ , $i \notin S$ . Here $f(x)$ is the prediction of the model for inputs $x$ . Figure 2 from the preprint is a good illustration: We are interested in the (signed) length of arrow for a particular feature, averaged over all permutations of the features. For a linear model $y(x) = w^Tx$ the SHAP value of feature $i$ would be simply $w_i x_i$ . Now to your items: SHAP value of 0 for some feature means that in the current example the value of that feature is ignored by the model. In the linear model this feature's weight would be 0. SHAP value of 4 means that the value of that feature in the current example increases the model's output by 4. Let me use your summary plot as an illustration. It was produced with Boston housing data, and we can check in the dataset that the maximal value of feature ‘RM’ (average number of rooms per house) is around 9. The plot shows that the brightest shade of red for this feature corresponds to SHAP values of around 3, 4, and 8. This means that having 9 rooms in a house tends to increase its price by 3, 4, or 8 thousand USD. The summary is just a swarm plot of SHAP values for all examples. The example whose power plot you include below corresponds to the points with $\text{SHAP}_\text{LSTAT} = 4.98$ , $\text{SHAP}_\text{RM} = 6.575$ , and so on in the summary plot.
