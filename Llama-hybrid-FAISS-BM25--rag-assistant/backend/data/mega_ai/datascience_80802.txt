[site]: datascience
[post_id]: 80802
[parent_id]: 70164
[tags]: 
Explainable Machine Learning is the domain of AI . It consists of interpretable models . One could say the difference is that one is a tool and the other is a field of study. In brief, interpretable machine learning is a tool used to solve problems present in the domain of explainable machine learning. To define your answer: One shall use an interpretable model to help " explain " the model and explain why the model gives out the specific results. Detail Explanation: Assume you need a cnn to classify whether there is a dog in the image. The architecture of the cnn would be the interpretable aspect of the machine learning problem. And the final saliency map or heatmap which shows the output and the focus of the cnn would be the explainable part of it.
