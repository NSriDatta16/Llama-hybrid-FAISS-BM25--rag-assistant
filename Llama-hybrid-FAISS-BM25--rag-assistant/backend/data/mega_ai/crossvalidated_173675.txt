[site]: crossvalidated
[post_id]: 173675
[parent_id]: 173672
[tags]: 
These are both huge families of algorithms, so it's difficult to give you a precise answer, but... Gradient ascent (or descent) is useful when you want to find a maximum (or minimum). For example, you might be finding the mode of a probability distribution, or a combination of parameters that minimize some loss function. The "path" it takes to find these extrema can tell you a little bit about the overall shape of the function, but it's not intended to; in fact, the better it works, the less you'll know about everything but the extrema. Monte Carlo methods are named after the Monte Carlo casino because they, like the casino, depend on randomization. It can be used in many different ways, but most of these focus on approximating distributions. Markov Chain Monte Carlo algorithms, for example, find ways to efficiently sample from complicated probability distributions. Other Monte Carlo simulations might generate distributions over possible outcomes.
