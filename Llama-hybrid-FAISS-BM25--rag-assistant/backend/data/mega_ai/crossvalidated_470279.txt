[site]: crossvalidated
[post_id]: 470279
[parent_id]: 470253
[tags]: 
Removing the variables one-by-one, based on some criteria like AIC, is called stepwise selection and is one of the worst algorithms for variable selection . In many cases the problem is not about removing variables, but about regularizing the model, although some recent results show that maybe some common beliefs about regularization that we held are not exactly true. LASSO is just a one, of many, approaches to regularization and variable selection. LASSO is using $L_1$ penalty, but you could use $L_2$ penalty, or both as in elastic net regularization , there are model-agnostic algorithms like Boruta, FSelector , or genetic algorithms, there is a ton of ways for regularizing models in deep learning like dropout, early stopping, weight decay, batch normalization, etc. Neither of those is "best", if it was the case we would stop searching for new ones and just stick to the best one.
