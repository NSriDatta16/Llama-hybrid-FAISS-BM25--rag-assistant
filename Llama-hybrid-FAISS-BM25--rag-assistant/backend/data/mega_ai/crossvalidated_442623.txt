[site]: crossvalidated
[post_id]: 442623
[parent_id]: 441712
[tags]: 
Item variances are rarely constant across items in factor analysis. Most typically, items are only congeneric, which means that their loadings on the common factor and their residual variances both may differ across items, so that their total variances may differ. So there is nothing unusual here. Your observed variables are averages--does that mean equally weighted sums divided by the number of items in each sum? Then the weights are not subject themselves to random sampling error, so they don't contribute to uncertainty about the values of the sums. Deriving a common factor from the variances doesn't make a lot of sense to me. If you wanted to overcome the information loss due to the construction of averages, you might try modeling the original items in a second order factor analysis. However, my bet would be that the model would not fit well. However, you have a further problem--factor indeterminacy (see, e.g., Grice 2001; Rigdon et al 2019). The value of the common factor for each case is indeterminate--an infinite number of different sets of scores for the factor will be equally consistent with the data and model. Regression-method "factor scores" ignore this indeterminacy, at the cost of not exactly reproducing the factor. "Plausible factor score" methods arbitrarily choose one set of scores from among this infinity of sets, concealing the indeterminacy. Whether or not you are comfortable with this may depend on what you mean to do with the scores. Grice, J. W. (2001). Computing and evaluating factor scores. Psychological methods, 6(4), 430. Rigdon, E. E., Becker, J. M., & Sarstedt, M. (2019). Factor indeterminacy as metrological uncertainty: Implications for advancing psychological measurement. Multivariate behavioral research, 54(3), 429-443.
