[site]: crossvalidated
[post_id]: 184976
[parent_id]: 184974
[tags]: 
In principle, your decision tree should be able to handle nonlinear effects, by splitting appropriately. My first instinct would be to simply include your data numerically, without capping. Without knowing what kind of data you have, how many variables and so forth, we won't be able to tell you the "best" model here. Try different transformations of your variables and see how well they perform. Experiment a bit! For this, split your data into a training and a test set. (Or, if you want to avoid overfitting on your test set, use a third partition as a validation set.) Or do actual cross-validation. Finally, once you are comfortable with decision trees, take a look at Random Forests , which are a fast and very accurate generalization of decision trees.
