[site]: crossvalidated
[post_id]: 339723
[parent_id]: 
[tags]: 
Ljung-Box test p-values

I am using the Ljung-Box test from the python statsmodel package to test if there are autocorrelations in a time series. To make sure I understand the test, I am performing it on white noise and checking that the null hypothesis H0 that there is no autocorrelation is being rejected a number of times consistent with the chosen p-value. However, I am finding that, for large lags, H0 is being rejected more than expected on average. I wrote the simple code: import numpy as np import statsmodels import statsmodels.api as sm from statsmodels import stats N = 10000 T = 100 x = np.random.normal(0, 1, T) _, pvalues = statsmodels.stats.diagnostic.acorr_ljungbox(x) ret = np.zeros(shape=pvalues.shape) for i in range(N): x = np.random.normal(0,1,T) _, pvalues = statsmodels.stats.diagnostic.acorr_ljungbox(x) ret += (pvalues The typical output of the code is like the following: [ 0.0522 0.0514 0.052 0.0512 0.0539 0.0549 0.0573 0.0592 0.0605 0.0625 0.0638 0.067 0.0674 0.0694 0.0703 0.0719 0.0715 0.0734 0.0749 0.0747 0.0769 0.0765 0.077 0.0774 0.0797 0.079 0.0817 0.083 0.0857 0.0873 0.0874 0.088 0.0891 0.0914 0.0909 0.0914 0.0926 0.0934 0.0936 0.0934] So the H0 tends to be consistently rejected more often than 5% of the times for larger lags. Am I misinterpreting the meaning of this test or making any other conceptual mistake? EDIT: Based on the comment below I changed the number of observation and made plots of the fraction of times the null hypothesis is rejected. Therefore it looks like for a set of observation of size 100, testing beyond a lag of around 5-10 incurs in a larger type I error
