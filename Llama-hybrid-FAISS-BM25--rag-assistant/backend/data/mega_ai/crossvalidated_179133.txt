[site]: crossvalidated
[post_id]: 179133
[parent_id]: 179132
[tags]: 
You're absolutely correct that they're very different. The particular possibility you mentioned, that the SD is much smaller, is the reason that n-1 is the denominator in the sample standard deviation (SD) but, of course, the SD could be very different for other reasons. That's true of every property of the sample. This is why the assumption of representativeness is critical in statistics. You won't find it listed as an assumption of any test but if you don't assume that the sample is in some way representative then using samples is pointless. Keep in mind that one doesn't always use the sample SD, or only the sample SD. In Bayesian statistics you look at prior research and weight or adjust the sample SD given the relatively believability of the prior information and the sample. Or, you might have some reasonable estimate of population SD that you substitute knowing that SD estimates can be highly variable. And consider that in the t-test itself you typically pool the the SD's from the samples to generate a more reliable estimate. If you're thinking along these lines you might enjoy working with simulations. You can get a better feel for exactly what happens when sampling occurs moreso than calculations of standard error or Type X error rates provide. These are easy to do in R: sd( rnorm(100, 1.2, 1.05) ) That gives you a SD from a random sample. You can use a function like replicate to make lots of them and look at the distributions of them with hist .
