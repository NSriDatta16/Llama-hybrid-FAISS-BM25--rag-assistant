[site]: crossvalidated
[post_id]: 554275
[parent_id]: 
[tags]: 
How to understand the posterior distribution is the same as likelihood function

So I read this post Why is the posterior distribution the same as the likelihood function when uniform prior distribution is used in Bayesian Analysis , and learned that when we have a uniform prior, the posterior distribution is the same as the likelihood function. However, we also have that What is the reason that a likelihood function is not a pdf , i.e. likelihood is not a pdf. For example, the sum of the likelihood might not be 1. Given these, how should we understand the posterior distribution is the same as the likelihood function when we have a uniform prior? Does this mean the sum of a posterior distribution doesn't need to be 1?
