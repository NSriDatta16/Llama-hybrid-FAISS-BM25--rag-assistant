[site]: crossvalidated
[post_id]: 140552
[parent_id]: 
[tags]: 
Incremental autocorrelation coefficient lag 1

I am a developer and I am trying to compute the autocorrelation coefficient of lag 1 incrementally. The problem is I have to test the results with some certified results from NiST Datasets . The autocorrelation coefficient used in these datasets is the following (it uses the time series analysis definition of autocorrelation, as explained here ): $$r1 = \frac{\sum_2^N(y_{i} - \overline{y})(y_{i-1} - \overline{y})}{\sum_1^N(y_{i} - \overline{y})^2}$$ I have tried to reuse the covariance incremental formula and adapt it but it does not work. I got closest to the exact results and my results differ in the third decimal digit. It's not a problem of loss of significance since I am using BigDecimal and numerically-stable algorithms to compute the mean and variance. I am using $$r1 = \frac{\sum_2^N(y_{i} - \overline{y_{1}})(y_{i-1} - \overline{y_{2}})}{\sum_1^N(y_{i} - \overline{y})^2}$$ which is the standard comoment divided by the second central moment. The problem here is I am using different means in computing them and I have to use the same mean in both terms. Nonetheless, I cannot adapt this to my current scheme. Currently, I process data incrementally. I have a class called Correlation, this class updates the estimators while receiving a new pair of values by updating two internal classes (Sample, which contains descriptive statistics of certain set of data). I am updating the class Correlation with $$(y_{i-1}, y_{i})$$Then, the first value updates the first sample and the second one the second sample. I cannot keep the same mean in both samples. At least, I don't find any way of doing it. Any clue? What I am looking for is an incremental way of computing the autocorrelation coefficient in one pass while mantaining my current scheme, if possible.
