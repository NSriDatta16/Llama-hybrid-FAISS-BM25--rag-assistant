[site]: crossvalidated
[post_id]: 270356
[parent_id]: 269384
[tags]: 
There's really no magic to "extending" those examples to other data types: Simply choose a relevant likelihood and a suitable prior. So, to model discrete data: Pick a likelihood $p(x|\theta)$ that generates discrete data, e.g. Poisson or negative binomial. Choose a suitable prior $p(\theta)$. It would be peculiar to choose a prior without support on the full domain of the likelihood parameters: You're essentially ruling out whole intervals of possible parameters. (Hence why beta-Weibull is odd.) Either approximate (MCMC, variational) or analytically solve for the posterior using Bayes rule: $$p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)}$$ Those Bernoulli examples you run into choose those distributions because beta is conjugate to Bernoulli: The posterior can be solved for analytically. To figure out a simple discrete conjugate model in this vein, start here with one of the distributions mentioned above. In this case, changing your choice of prior parameters is straightforward. (Read about any conjugate prior and you'll generally see the posterior expressed in terms of prior parameters and data.) For models lacking analytic solutions—ones where $p(x)$ is difficult to compute—you're left to approximate methods. The full role of the prior in these seems beyond the scope of your question. Interestingly enough, your rounded Weibull gives this probability mass function for an integer $x$. (Follows from the CDF of the Weibull .) $$p(x|\lambda, k) = \exp{-\Big(\frac{x+\frac{1}{2}}{\lambda}}\Big)^k - \exp{-\Big(\frac{\max{\big(x-\frac{1}{2}},0\big)}{\lambda}}\Big)^k$$ Maybe you want to put a prior on either of those parameters and see what you can come up with analytically or via MCMC. Could be fun.
