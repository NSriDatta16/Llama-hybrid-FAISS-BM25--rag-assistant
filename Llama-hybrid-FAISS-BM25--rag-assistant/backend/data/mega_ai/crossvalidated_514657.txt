[site]: crossvalidated
[post_id]: 514657
[parent_id]: 
[tags]: 
How to adjust estimates to account for regression to the mean?

Let us consider an example where we have a number of runners and an estimate of speed in mph for each runner. The estimate for each runner may be based on an equal or unequal number of independent and identical experiments where that runner is timed running a constant distance. We assume each runner's time is ditributed randomly according to some distribution. If we wish to identify the runner with the highest expected value of speed, we might select the runner in our dataset who has the highest average speed. Even though that may be a fine procedure for finding the best runner, that runner's average speed, calculated from the data, will be a biased estimate for their expected speed because we chose the runner based on the fact that they had the highest speed in the dataset. My question is: Is it possible to adjust our estimate for the runner's expected speed by accounting for the procedure by which we selected the runner? Eg., if we select the runner with the highest average speed, the adjusted estimate will be lower than their calculated average, and vice-versa. I'm interested in a solution even if it requires introducing additional assumptions.
