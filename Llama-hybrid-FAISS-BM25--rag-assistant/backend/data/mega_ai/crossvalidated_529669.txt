[site]: crossvalidated
[post_id]: 529669
[parent_id]: 
[tags]: 
Quality of model and dropout

I am training my neural network (modified VGG) for solving the problem of 3-class classification. For reaching the best model I am trying to fit slightly different models. I have some questions about choosing the best model via loss and accuracy plots. Here are two plots: First: Second: So the questions are: Am I correctly understand, that in general case, not only in my task, for instance, accuracy plot depending from num of epochs should monotonously increase, but in the end, when num of epochs will be big, accuracy should stuck at some value? Similarly, for loss plot, but in that case, loss should monotonously decrease, but also should stuck at some value? Which model is better? On the one hand, in first plot, there is no overfitting, but train and validation accuracy are not so big, as in second plot. But in the second plot, we have overfitting. My last question is about dropout. Here is my classification part of NN: self._head = nn.Sequential( nn.Linear(in_features=7*7*512, out_features=12000), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(in_features=12000, out_features=6000), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(in_features=6000, out_features=3000), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(in_features=3000, out_features=1200), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(in_features=1200, out_features=600), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(in_features=600, out_features=num_classes), ) 3.1. I heard, that depending on after which layer (conv or linear) I will put the dropout layer,I should assign different values for p. Moreover, this value should increase with num of linear layer. Is it true? What is the rule? Where I can read about it? 3.2. Am I correct, that if I will put larger value for p, say 0.9, the regularization effect will be more, that if p=0.5?
