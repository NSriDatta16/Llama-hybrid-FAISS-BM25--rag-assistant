[site]: datascience
[post_id]: 87416
[parent_id]: 
[tags]: 
Help Interpreting Machine Learning Results

I am trying to implement a machine learning model for a regression task in bioinformatics. It is a task analogous to scoring images. The goal is to get the predicted label for an input as close to its true label as possible. Ideally, one would feed the model with raw data and have the model learn features during the training process. Unfortunately this is not possible due to the comparatively small dataset size. I have tried the following approaches with both raw sequence data and pre-featurized data. Model 1 : Pre-Featurized Data $\Longrightarrow$ CNN Block $\Longrightarrow$ Dense Network $\Longrightarrow$ Output Model 2 : Pre-Featurized Data $\Longrightarrow$ Dense Network $\Longrightarrow$ Output Model 3 : Raw Sequence Data $\Longrightarrow$ CNN Block $\Longrightarrow$ Dense Network $\Longrightarrow$ Output Model 4 : Raw Sequence Data $\Longrightarrow$ Embedding Layer* $\Longrightarrow$ CNN Block $\Longrightarrow$ Dense Network $\Longrightarrow$ Output *Description of embedding layer linked . Models 1, 3, and 4 perform similarly and eventually settle at a validation loss of about 0.6. Model 2, however, has an extremely high validation loss at more than 10. This is very confusing to me. If raw data is insufficiently featurized, then models 3 and 4 should not have performed well. If the pre-featurized data was not capturing features that were meaningful to the task, model 1 should not have performed well. I am at an absolute loss here. I would be very appreciative of anyone who can make sense of these results.
