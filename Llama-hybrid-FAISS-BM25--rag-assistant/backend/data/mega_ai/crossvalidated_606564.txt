[site]: crossvalidated
[post_id]: 606564
[parent_id]: 
[tags]: 
Conceptual understanding of effect of standardizing after normalization for clustering

My general understanding is that, before running a clustering algorithm, one typically wants to consider trying to normalize or standardize the data depending on its content and use. In my case, I have a problem where standardizing features (centering and dividing by standard deviation) after l2 normalizing across the rows resulted in much better clusters. I have never heard anyone suggest to do both and only by happenstance did it myself. I'd like to better understand in which cases this might be sensible, what it means that it worked, or if this was just perhaps luck? My particular use case is I have something that resembles a typical recommender problem where I have rows (items) by columns (proportional user interaction with each item). I run truncated SVD on that huge set of columns (the user interactions) to get 300-lenght item embeddings. After this step, the norming and scaling occurred. I then run K-Means clustering. L2 norming makes sense to me in the context of recommender systems (I've heard it suggested before), but I'm not even sure what my data "means" by following it up with standardization. The difference in results was clear enough though. Any way to better understand this is appreciated.
