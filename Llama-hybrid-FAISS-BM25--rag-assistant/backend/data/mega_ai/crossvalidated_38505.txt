[site]: crossvalidated
[post_id]: 38505
[parent_id]: 38502
[tags]: 
We had a similar problem when I worked in the medical device industry. We wanted to determine the reliability of our product in my case a pacemaker. Physicians were encouraged to report failures that are detected when they explant the device. Most failure are battery depletions but other modes of failure occur. We used the Kaplan-Meier estimate of time to failure as our performance measure perhaps focussing on its value at 5 years post implant. Reports are coming in continuously. So we don't have the problem of picking arbitrary intervals. This is a different approach to the same problem but it does have valid statistical methods for characterizing the failure time distribution. A parametric approach which would involve say fitting a Weibull distribution to the reporting data would provide you with a function that describes how the failure rate increases or decreases with time given the estimated parameters. But the real underlying problem we had and you might as well is underreporting. Although the physicians are supposed to report the failures back to the manufacturer or better yet return the explanted device to the manufacturers so that the manufacturer's engineers can diagnose the failure they don't always to it. Underreporting rates were thought to be as high as 30%. You can have a very large bias (estimating that your failure rate is lower than it is in reality at any given time since implant). The FDA had a plan for postmarket surveillance that would adjust for this bias based on independent detailed tracking of a random sample of the implants. I published a paper in the DIA Journal that showed that the adjustment depended heavily on some assumptions and overcorrection was possible. However in principle a statistical methodology for this would be to fit a parametric survival curve and adjust the parameter estimates based on random sampling the devices.
