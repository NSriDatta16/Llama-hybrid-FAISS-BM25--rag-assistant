[site]: crossvalidated
[post_id]: 397108
[parent_id]: 397102
[tags]: 
Let's first talk about PCA use cases - • Reducing dimensionality of the dataset - since with high dimensionality you can overfit easily, and moreover it might need more compute power. • Removing Noise from dataset up to certain extent. If you want any of the above from your dataset you can go about doing PCA. Standardizing your dataset is very important. Since Classifier/Regressors like linear/logisitic can have huge impact if features are on different scales. With this in mind we usually only standardize Continuous Values/ Numbers but if in your case there are categorical features you might have to Label Encode/One-hot Encode them ( One hot encoder is better , but at the cost of increased dimensionality). The problem is that if you don't standardize ( use Z-scores ) then you usually end up with noisy weights in LR and hence the model performs poorly or it just takes longer time for the model to achieve good performance which it could have done faster had the features been standardized.
