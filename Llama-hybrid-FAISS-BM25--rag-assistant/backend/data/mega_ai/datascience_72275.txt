[site]: datascience
[post_id]: 72275
[parent_id]: 
[tags]: 
Detecting low-quality, user-created text content

I run a website that allows visitors to publish text content. It is very similar to a forum in terms of functionality. I'd like to automatically exclude or flag, submitted text content that is "spammy" or "low quality" (subjective I know). Obviously I want to detect content that is offensive or classic spam. I also want to detect content that is meaningless or nonsense. I know this must be a common problem for those that run web apps that allow user-submitted content, but I haven't found an obvious solution yet. Ideally I'd like to use open source software that can run on Linux, suitable for me to install on my webservers, or an AWS service. I've tried AWS Comprehend which, without any custom training, can detect the sentiment of text accurately, It doesn't seem to detect low-quality or spam out-of-the box. It supports training of custom classifiers, you simply provide a csv containing class/document pairs. This could be a good way to go, can anyone suggest a free dataset that I could use to train it? It seems like text quality detection would be such a common requirement that I thought there might be some software out there that is pre-trained for that exact purpose, perhaps a Linux package. Does anyone have any suggestions? I wasn't sure wether to post this in Data Science or Programming, I apologize if this is misplaced.
