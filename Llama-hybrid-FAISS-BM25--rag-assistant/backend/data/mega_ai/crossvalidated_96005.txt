[site]: crossvalidated
[post_id]: 96005
[parent_id]: 
[tags]: 
Random Forest and Factor Predictors

How do decision tree based ensembles like random forest deal with categorical ("factor") predictor variables? My guess would be that indicator variables are created for each factor via a one-hot-encoding (aka 1 of K coding) but I wonder if that is true? The reason I doubt it is that it seems that such a coding for a factor with many levels would of course results in many additional variables and the selection (random) of which predictors to consider for splitting at each node would not actually be picking "variable 1" or not, but instead would be selecting a potential subset of the indicators that resulted from "variable 1". I was under the impression that Caret in R expanded all factors out using model.matrix in its train function before passing to (any) modeling algorithm including RF however so that made me reconsider. Does anyone know how these things are treated?
