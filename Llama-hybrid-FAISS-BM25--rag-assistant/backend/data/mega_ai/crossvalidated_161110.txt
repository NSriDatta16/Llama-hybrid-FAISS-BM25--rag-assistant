[site]: crossvalidated
[post_id]: 161110
[parent_id]: 161101
[tags]: 
I don't claim to be an expert on Logistic Regression. But I imagine it goes something like this - suppose $Y$ is a binary random variable taking on either the value $0$ or $1$. Define $$\pi=\mathbb{P}\left(Y=0âˆ£X\right)\text{,}$$ where $X$ is the independent variable (I'm assuming only one predictor for simplicity). Then logistic regression assumes the form $$\ln\left(\dfrac{\pi}{1-\pi}\right)=\beta_0+\beta_1 X + \epsilon$$ where $\epsilon$ is independent from $X$ and has mean $0$, and the $\beta_i$ are estimated using maximum likelihood. With Bayesian logistic regression, I imagine you use something like $$\pi = \dfrac{\mathbb{P}\left(X = x\mid Y = 0\right)\mathbb{P}\left(Y = 0\right)}{\displaystyle\sum\limits_{j}\mathbb{P}\left(X = x\mid Y = j\right)\mathbb{P}\left(Y = j\right)}$$and assign something for the distribution of $X \mid Y = j$ and a prior distribution for $Y$. This is, from my limited understanding, I believe the basis of Linear Discriminant Analysis.
