[site]: datascience
[post_id]: 76287
[parent_id]: 76241
[tags]: 
If you are looking for a statistical trick, I don't know, but Recently Andrew NG team recently published about NGBoost . NGBoost is a new boosting algorithm, which uses Natural Gradient Boosting, a modular boosting algorithm for probabilistic predictions. In this Towards Data Science toy example you can see how to use the Python API : Quoting the TDS author: NGBoostâ€™s one of the biggest differences from other boosting algorithms is can return probabilistic distribution of each prediction. This can be visualized by using pred_dist function. In their web they say "NGBoost can be used with any base learner, any family of distributions with continuous parameters, and any scoring rule." So it seems pretty flexible to do whatever you consider.
