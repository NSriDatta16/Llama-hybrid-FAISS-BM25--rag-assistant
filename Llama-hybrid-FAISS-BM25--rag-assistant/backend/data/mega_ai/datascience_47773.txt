[site]: datascience
[post_id]: 47773
[parent_id]: 
[tags]: 
The principle of LM deep model

Language model(LM) is the task of predicting the next word. Does the deep model need the encoder? From the ptb code of tensor2tensor, I find the deep model do not contains the encoder. Or both with-encoder and without-encoder can do the LM task?
