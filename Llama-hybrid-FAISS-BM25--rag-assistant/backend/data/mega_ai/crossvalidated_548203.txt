[site]: crossvalidated
[post_id]: 548203
[parent_id]: 548195
[tags]: 
One of the ways to compute PCA is by using eigen-decomposition of the covariance matrix of the data matrix $\underset{N \times n}{X}$ , which is $\underset{n\times n}{X^TX}$ if $X$ is mean-centralized. Since we generally have $n \ll N$ , it's computationally much faster to compute the eigenvectors of the covariance matrix $X^TX$ . It outputs $n$ eigenvalues and an $n \times n$ matrix with $n$ orthonormal eigenvectors as columns where the dimension of each eigenvector is $n \times 1$ . But, sometimes we have $N \ll n$ (e.g., for patient-genes data), then it's computationally very expensive to do the eigen-decomposition of $X^TX$ , instead it's easier to do the eigen-decomposition of $\underset{N \times N}{XX^T}$ , since both have same eigenvalues and the eigenvectors of $X^TX$ can be computed easily from the eigenvectors of $XX^T$ . For example, let $XX^T$ has eigenvalue $λ$ and the corresponding eigenvector $v$ , then we have, $XX^Tv=λv⟹(X^TX)(X^Tv)=λ(X^Tv)$ , i.e, $\underset{n\times N}{X^T}.\underset{N \times 1}{v}$ is an eigenvector of $X^TX$ (upto normalization).
