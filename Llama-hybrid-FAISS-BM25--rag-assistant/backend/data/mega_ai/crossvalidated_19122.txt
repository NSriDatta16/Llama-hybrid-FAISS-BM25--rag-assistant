[site]: crossvalidated
[post_id]: 19122
[parent_id]: 19044
[tags]: 
The Nelder-Mead simplex method can involve as many function evaluations as a simple grid search. Usually the error surface is smooth enough close to the optimal parameter values that a coarse grid search followed by a finer one in a smaller region should suffice. If you're interested in gradient based optimization of C and gamma, there are methods like optimizing the radius-margin bounds or optimizing the error rate on a validation set. The computation of the gradient of the objective function involves something like one SVM train but a simple gradient descent may involve only a few dozen iterations. (Look at http://olivier.chapelle.cc/ams/ for an article and a Matlab implementation.)
