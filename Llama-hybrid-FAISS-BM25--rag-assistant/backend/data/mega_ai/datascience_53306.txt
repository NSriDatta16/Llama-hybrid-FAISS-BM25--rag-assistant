[site]: datascience
[post_id]: 53306
[parent_id]: 53296
[tags]: 
Do machine learning on microcontrollers or other edge devices ( link1 , link2 , link3 , link4 , link5 ). This is a hot topic, new emerging technologies, and it will make your profs happy from both electronics and IT departments. There was a recent news article ( link ) where a team from the Fraunhofer IMC did a handwritten digits recognition on an Arduino Uno. They claim that they not only run a trained neural network (which would be easy) but actually train the network on Arduino. However, they don't show their code. On their license page ( link ) they only say some blah-blah-blah about discussing possibilities with partners and customers and boast 30 years of experience in the development of microelectronic circuits. This is lame. I am sure that this can be done by an undergraduate student without 30 years of experience and that student will write a blog post about it. If you develop a machine learning code that would do such tasks on an Arduino or even something smaller, like ATTINY85 that would be cool. Your model should be able to be trained on a microcontroller given the restrictions of its memory and computational capacity. Then upload your code on a github or a blog, put your link here. If your code is good, it will get lots of likes, you will showcase your abilities to your employers, and will put those Fraunhofer dinos who hide their "great discoveries" to shame. Besides, it is very useful because of emerging technologies with IoT, 5G, etc. By the way, it does not have to be a neural network. Other models, like SVM, KRR would also be great. Also, it does not have to be Arduino. Other microcontrollers, like PIC or ST are also OK.
