[site]: crossvalidated
[post_id]: 586482
[parent_id]: 
[tags]: 
In what ways do conjugate priors compose?

A lot of conjugate priors are known for a lot of likelihood distributions (mostly the exponential family). But most Bayesian models in practice don't just consist of one distribution. Usually, you have a hierarchical model, a network, or some other way of combining simple distributions into a more complicated one. In the context of networks, my question is whether the existence of conjugate priors for the constituents of a network extends to a conjugate prior of the whole network. There are some simple examples where composing distributions in some way gives a new conjugate prior. For example, assume the prior is a convex combination, $p(\theta) = \sum_i c_i p_i(\theta)$ where $\sum_i c_i = 1$ , and each $p_i(\theta)$ is a conjugate prior for the same likelihood $p(x | \theta)$ , then $p(\theta | x)$ splits up into the same sum. But would a generalisation of this principle still work if, for example, we draw the $c_i$ from a Dirichlet distribution? Another composition principle is that if two parameters are independent, $p(\theta_1, \theta_2) = p(\theta_1)\,p(\theta_2)$ , and the likelihood is also independent over the parameters, $p(x|\theta_1, \theta_2) = p(x|\theta_1)\,p(x|\theta_2)$ , then the posterior splits the same way, and is thus again in the same family as the prior: \begin{align*} p(\theta_1, \theta_2 | x) &= \frac{p(x | \theta_1, \theta_2)}{p(x)}\,p(\theta_1, \theta_2)\\ &= \frac{p(x | \theta_1)\,p(x | \theta_2)}{\int_{\theta_1, \theta_2}p(x | \theta_1)\,p(x | \theta_2)\,d\theta_1\,d\theta_2}\,p(\theta_1)\,p(\theta_2)\\ &= p(\theta_1 | x)\,p(\theta_2 | x) \end{align*} (Slight abuse of notation maybe, by $p(\theta_i | x)$ I mean a distribution from the same family as $p(\theta_i)$ was, with the parameters updated by $x$ .) This example can be seen as the case where we take two Bayesian networks and put them next to each other, independently. But what can we say if we add edges to the graph? Maybe the answer will be something like "each non-root node of the graph must have conditional conjugate priors", I'm not sure. Anyways, conditional conjugate priors seem to be less studied, I can't find a simple table like this one on Wikipedia . I find this an interesting question because if the answer is "often/always, conjugate priors arise for the whole network", this opens the possibility for a probabilistic programming language based completely on these. It would not be as expressive as a general PPL, but the programs you can express in it are all extremely fast and precise to execute (no MCMC needed). Since composing programs from smaller building blocks is fundamental to programming, I'm interested in all ways you could compose conjugate priors such that they can be used in a PPL.
