[site]: crossvalidated
[post_id]: 115292
[parent_id]: 115258
[tags]: 
I don't think that a list with pros and cons exists. The activation functions are highly application dependent, and they depends also on the architecture of your neural network ( here for example you see the application of two softmax functions, that are similar to the sigmoid one). You can find some studies about the general behaviour of the functions, but I think you will never have a defined and definitive list (what you ask...). I'm still a student, so I point what I know so far: here you find some thoughts about the behaviours of tanh and sigmoids with backpropagation. Tanh are more generic, but sigmoids... (there will be always a "but") In Deep Sparse Rectifier Neural Networks of Glorot Xavier et al, they state that Rectifier units are more biologically plausible and they perform better than the others (sigmoid/tanh)
