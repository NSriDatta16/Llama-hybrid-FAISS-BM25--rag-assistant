[site]: datascience
[post_id]: 69973
[parent_id]: 69943
[tags]: 
For synonyms I would directly use WordNet . [added] For contextually similar words the traditional approach is to extract a context vector for every target word: for every occurrence of a target word extract the words within a -/+ N window (e.g. N=5). for every target word aggregate all its context words in a single context vector over the whole vocabulary. Finally once a context vector has been calculated for every target word a similarity measure can be used, for example cosine. That means for every target word, compare its vector against any other candidate. The same approach can be used with word embeddings instead of context vectors.
