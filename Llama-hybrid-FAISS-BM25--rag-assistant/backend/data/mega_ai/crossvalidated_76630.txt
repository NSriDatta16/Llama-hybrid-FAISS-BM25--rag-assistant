[site]: crossvalidated
[post_id]: 76630
[parent_id]: 76623
[tags]: 
To get a sense of what might be going on here, consider a simple logistic regression model with one continuous regressor $$P(Y=1\mid X) = \Lambda (g(x)) =\Big(1 + \exp\{g(x)\}\Big)^{-1} =\Big(1 + \exp\{a+bx\}\Big)^{-1}$$ The marginal effect is $$\frac {\partial P}{\partial X} = \Lambda (1-\Lambda)b $$ The 2nd-order Maclaurin series of $\Lambda$ (its Taylor expansion centered at zero) with respect to the logit is $$\Lambda \approx \frac 12 +\frac 14 g(x)$$ because the 2nd-order term is zero. Then $$\frac {\partial P}{\partial X} \approx \left(\frac 12 +\frac 14 g(x) \right)\left(1-\frac 12 -\frac 14 g(x)\right)b = \left(\frac 14 -\frac 1{16} g(x)^2\right)b$$ $$= \frac 14b -\frac 1 {16}\left(a^2 +2abx + b^2x^2\right)b$$ $$= \frac 14\Big(1 -\frac 1 {4}a^2\Big)b - \frac 18ab^2x - \frac 1{16}b^3x^2$$ So depending on the range of $X$, and the value of $\hat b$, it may be the case that the 2nd order approximation is good and the last term that features the regressor squared is "small", hence giving an approximate linear relation between the probability and the regressor.
