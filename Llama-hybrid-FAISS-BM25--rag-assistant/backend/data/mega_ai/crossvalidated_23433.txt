[site]: crossvalidated
[post_id]: 23433
[parent_id]: 
[tags]: 
Are MFCCs the optimal method of representing music to a retrieval system?

A signal processing technique, the Mel frequency Cepstrum , is often used to extract information from a musical piece for use in a machine learning task. This method gives a short-term power spectrum, and the coefficients are used as input. In designing music retrieval systems, such coefficients are considered characteristic of a piece (obviously not necessarily unique, but distinguishing). Are there any characteristics that would better suit learning with a network? Would time-varying characteristics like the bass progression of the piece used in something like an Elman network work more effectively? Which characteristics would form an extensive enough set upon which classification could take place?
