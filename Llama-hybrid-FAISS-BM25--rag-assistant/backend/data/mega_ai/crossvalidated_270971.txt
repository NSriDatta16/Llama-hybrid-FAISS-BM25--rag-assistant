[site]: crossvalidated
[post_id]: 270971
[parent_id]: 
[tags]: 
How to address multicollinearity in multinomial regression without dropping independent variables?

In my statistical model, using multinomial logistic regression, I have used age , region (urban/ rural) and number of pregnancies (G) as independent variables. As expected, Age and G are correlated (rho=0.5, p G and region . Highest level of pseudo-R squared value is achieved when I include G and region , but I cannot (At least I think so) drop age as it is an important predictor variable. Is there some kind of mediator effect ? and can I address it in multinomial regression? Is there anyway to include both of the variables? or perhaps using a merged variable, such as (age*g)? And, these are a bit irrelevant but anyway... Should I drop insignificant variables that contribute strongly to overall pseudo R squared? 4.What does this warning mean and how to address it ? "Unexpected singularities in the Hessian matrix are encountered. This indicates that either some predictor variables should be excluded or some categories should be merged." Thank you for your response, forgive me for any possible statistical mistakes, as I'm quite new to this! After JKP and AaronDefazio's comments, Here is the code spss produced: (included pregNum, Age and region not included) NOMREG CTstat (BASE=FIRST ORDER=ASCENDING) BY PregNum NEW_PT TStat35 UStat WITH GDPGr EduLvl /CRITERIA CIN(95) DELTA(0) MXITER(100) MXSTEP(5) CHKSEP(20) LCONVERGE(0) PCONVERGE(0.000001) SINGULAR(0.00000001) /MODEL /STEPWISE=PIN(.05) POUT(0.1) MINEFFECT(0) RULE(SINGLE) ENTRYMETHOD(LR) REMOVALMETHOD(LR) /INTERCEPT=INCLUDE /PRINT=FIT PARAMETER SUMMARY LRT CPS STEP MFI. And here is the frequency tables for my categorical variables included in the regression.
