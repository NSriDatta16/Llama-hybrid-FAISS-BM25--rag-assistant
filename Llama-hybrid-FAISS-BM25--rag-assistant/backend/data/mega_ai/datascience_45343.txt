[site]: datascience
[post_id]: 45343
[parent_id]: 
[tags]: 
Tensorflow Deep learning network not utilizing GPU?

I have a Nvidia GeForce GT 755M (PC), which I heard should be at least functional for running deep learning models. But when I train my model (DCGAN) and check the task manager process info (Win 10) I see close to 100% CPU utilization, and very little GPU activity (1-5%). That amount of GPU activity seems to be the constant even if I'm not running a model...so my concern is that I'm not using my graphics card at all, and that I would get better performance if I did. Furthermore, when I run the following code it indicates that no GPU was found: import tensorflow as tf import warnings if not tf.test.gpu_device_name(): warnings.warn('No GPU found. Please use a GPU to train your neural network.') else: print('Default GPU Device: {}'.format(tf.test.gpu_device_name())) So my questions are the following: Is my GPU something that should improve performance vs using the CPU? Why isn't tensorflow finding the GPU? How can I make Tensorflow utilize the GPU? I am just beginning to learn about the hardware aspect of ML so any advice and any recommended beginners tutorials for getting basic understanding/intuition would be much appreciated! Screenshot of component utilization while training a convolutional NN: Thanks!
