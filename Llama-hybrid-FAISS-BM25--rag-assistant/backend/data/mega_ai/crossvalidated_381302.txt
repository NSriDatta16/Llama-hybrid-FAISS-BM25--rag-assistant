[site]: crossvalidated
[post_id]: 381302
[parent_id]: 381218
[tags]: 
I can think of at least two reasons why it seems desirable for the latents to come from a Gaussian distribution: Sampling It's easy to sample random numbers from a Gaussian, so then drawing samples from our generative distribution, $p(x)$ , is easy because we first sample $ z \sim \mathcal N(0,\mathrm I)$ , then sample each variable $x_i \sim p(x_i|z)$ (since our generative model usually assumes conditionally independent variables). For this purpose, there seem to be many other distributions that would suffice. Per-sample likelihood calculation For VAE, we can analytically calculate a lower bound on the likelihood of generating a single sample point, x, using the ELBO. To get this to work, the KL divergence of the encoder has to "match" the prior in form. So if our encoder, $q(z|x)$ adds Gaussian noise, then we can make the prior, $p(z)$ , Gaussian and get a tractable expression. If we change $p(z)$ , we'll have to change the form of q(z|x) as well. Even then, there are many distributions where an analytic form for $D_{KL} (q(z|x)||p(z))$ would not be available. In practice, I think your intuition is correct that there are many degrees of freedom in the optimization and most autoencoders don't actually achieve this desiderata (i.e., the distribution of latent factors that we get from applying the encoder, $q(z)$ , is not actually Gaussian as our generative model, $p(z)$ , specified). For VAEs this is shown and discussed in the InfoVAE paper . They also show how to add a penalty so that $D_{MMD}(p(z), q(z))$ is minimized. Another approach that might be more powerful for getting true Gaussian latent factors is "normalizing flows". I'm not an expert on those, but one place to start is this paper .
