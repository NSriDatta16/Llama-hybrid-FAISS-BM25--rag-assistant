[site]: crossvalidated
[post_id]: 494627
[parent_id]: 494621
[tags]: 
CNNs are typically constructed by stacking convolutional layers on top of each other, with each convolutional layer taking in the previous feature map and producing a successive feature map. The spatial resolution of the feature maps and the input raster data often differ -- for example, every feature in the feature map might "correspond" (informally) to a 4x4 patch of pixels in the input. Different feature maps of the CNN also often have different resolutions. In general, "multi-scale architecture" is a vague term used to express the idea that a neural network somehow integrates information from both the small scale (high resolution feature maps) and the large scale (lower resolution feature maps). Exactly what "integrates information" means varies a lot in different contexts. In the context of this paper, "multi-scale architecture" means that the latent space of the generative model is split up across multiple feature maps of different resolutions, and the model has to integrate "information" across these different scales to perform inference/sampling.
