[site]: crossvalidated
[post_id]: 478083
[parent_id]: 478079
[tags]: 
By construction, random forests heavily overfit on the training set. Thus, never use insample results and predictions for any purpose (except to verify this fact). For independent observations, this can elegantly fixed by studying out-of-bag (OOB) results/predictions. With clustered samples like in your case, OOB predictions are biased and can't help as well. As a solution, I would probably work with cross-validated predictions using grouped sampling. By grouped sampling, I mean that all three rows per patient are kept together in one fold when building the cross-validation folds. It depends on the aims if it is smart to drop time and subject id. Often, subject id is of no use because the model could not be applied to new patients. Dropping time sounds a bit strange though.
