[site]: crossvalidated
[post_id]: 105606
[parent_id]: 105510
[tags]: 
One problem is that distribution-free procedures typically rely on being unaffected by monotonic transformation to preserve their distribution-free property. On the other hand, interaction is affected by exactly that - monotonic transformation can convert no interaction to interaction, or strong positive interaction to strong negative - or any other combination. Here's an example done in R: y=c(2.2239, 3.9927, 3.6603, 1.9891, 2.512, 3.1115, 2.3917, 2.8291, 3.7057, 1.987, 2.6568, 3.9810, 2.1337, 2.1669, 3.3876, 2.9638, 2.9076, 4.377, 2.1319, 3.5533, 3.8489, 1.9695, 3.271, 4.0011, 3.1308, 4.0777, 4.9145, 3.5395, 4.3199, 5.0562, 2.6234, 4.5491, 5.2568, 3.1569, 3.3236, 5.3585, 3.1803, 4.3212, 5.5523, 2.6577, 3.7098, 4.4573, 3.2331, 4.0703, 4.5332, 2.5392, 4.2835, 4.9115, 4.6319, 5.3323, 5.6393, 4.222, 5.5367, 5.5239, 3.8044, 5.6456, 5.2564, 4.8723, 4.9721, 6.1518, 4.6626, 5.1306, 6.1608, 4.012, 4.6824, 6.1099, 4.4195, 4.9327, 6.0989, 3.6916, 5.8146, 5.6579) xa = rep(1:3,24) xb = rep(1:3,each=24) (Note that here xa and xb are numeric, not factors, but you can get the same issue with factors.) summary(lm(y~xa*xb)) summary(lm(log(y)~xa*xb)) summary(lm(exp(y)~xa*xb)) The interaction line from each summary is: Estimate Std. Error t value Pr(>|t|) xa:xb 4.882e-06 7.217e-02 0.000 1.000 (original) xa:xb -0.05499 0.02028 -2.712 0.00846 (log-scale) xa:xb 60.322 9.713 6.210 3.63e-08 (exp-scale) Note that the interaction changed from 0 to significant negative (at the 1% level) to significant positive (at any sensible level). Larger samples could achieve whatever significance level was desired. Since each of the results can be obtained from any of the others by a simple monotonic transform, we see that taking ranks could destroy the interaction on the scale you have - it might reverse it or make it 0 or give you interaction where there was none. That doesn't mean distribution-free analysis isn't possible, it's just not as straightforward as it might seem. In particular, you'll want to avoid any transformation of that data that may impact the interaction. You can perhaps do something with permutation tests, for example, which are distribution free while not playing with the scale of the data. A common suggestion I have seen is to consider ordinal logistic regression, which generalizes the Kruskal-Wallis type approach, and can handle factorial designs. I don't know that it necessarily avoids this issue though -- I haven't worked through it. There are other possibilities, some quite simple, but better advice really comes down to why you think you need a specifically nonparametric procedure. Edit: see also here and here , which says something similar.
