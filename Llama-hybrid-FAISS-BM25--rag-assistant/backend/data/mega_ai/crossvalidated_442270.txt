[site]: crossvalidated
[post_id]: 442270
[parent_id]: 
[tags]: 
How to use the likelihood-ratio to compute the error probability?

In Bayesian decision theory, There is an analytical form of error rate, which is $$P(e)=\int P(e|\bf{x})p(\bf{x})d\bf{x}$$ . For binary classification, we can compute the type I error probability with: $$P_1(e)=\int_{R_2} p(\bf{x}|\omega_1)d\bf{x}$$ . Where $R_2$ is the region in which $\bf{x}$ is classified as $\omega_2$ . But, this is computation-complex, for that we should do a multivariable calculus. Then a single-variable calculus is introduced by log-likelihood ratio $h(x)=\ln\frac{ p(\bf{x}|\omega_2)}{p(\bf{x|\omega_1})}$ . Now, it could be computed by: $$P_1(e)=\int_t^\infty p(h|\omega_1) dh$$ , where $t=\ln\frac{P(\omega_1)}{P(\omega_2)}$ . I want to know how is the equation below established? $$P_1(e)=\int_{R_2} p(\mathbf{x}|\omega_1)d\mathbf{x} = \int_t^{\infty}p(h|\omega_1)dh$$ It would be better if you can offer the concrete deducing process.
