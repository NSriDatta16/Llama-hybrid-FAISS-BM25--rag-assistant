[site]: datascience
[post_id]: 103389
[parent_id]: 
[tags]: 
HuggingFace hate detection model

I am trying to train and evaluate a hate detection model using the HuggingFace Transformers library and this dataset . Model performance is secondary, just trying to get it going. I have preprocessed the data and tokenised it as shown below: import pandas as pd import numpy as np from numpy.random import RandomState import re import preprocessor as p from transformers import AutoTokenizer # Loading raw data original_data = pd.read_csv('../data/data.csv') # Make a random test and train split rng = RandomState() train = original_data.sample(frac=0.7, random_state=rng) test = original_data.loc[~df.index.isin(train.index)] # Preprocessing: remove special characters using RegEx REPLACE_NO_SPACE = re.compile("(\.)|(\;)|(\:)|(\!)|(\')|(\?)|(\,)|(\")|(\|)|(\()|(\))|(\[)|(\])|(\%)|(\\\$)|(\>)|(\ The above code generates a table for the test data as: As I understand, the next part should be the model training part and extracting the % of hate tweets. Any suggestions on implementation?
