[site]: datascience
[post_id]: 76150
[parent_id]: 72958
[tags]: 
It looks like you are using an imbalanced dataset in your model. The results look poor with high false negative values/low sensitivity ratio. One metric you may want to use in addition is the AUC/ROC. This works well for comparing results for imbalanced data. There are many options to improve your model for a better sensitivity result, such as Using different weights for predicting a majority vs predicting a minority label Up-sample or down-sample the training data to help balance the prediction across minority and majority, or use SMOTE for datasets with few features. Choose a modeling algorithm that is better at handling imbalanced data, such as machine learning/neural networks, or a classical algorithm such as bagging or boosting algorithms and/or decision trees Resources: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/ https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/
