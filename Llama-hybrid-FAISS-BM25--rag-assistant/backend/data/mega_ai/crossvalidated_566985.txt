[site]: crossvalidated
[post_id]: 566985
[parent_id]: 
[tags]: 
Do I need to use nested cross validation to select the best algorithm?

Suppose I want to compare the performance of several classification algorithms on a data set to choose the best algorithm to use with that data set. To do this, I run logistic regression, k-nearest neighbors, and naive Bayes using k-fold cross validation on the data set. Based on the results from the k-fold cross validations, I select the algorithm that produced the most accurate result and train it on the entire data set to obtain the final model. My questions are: Is this a valid method of choosing between machine learning algorithms, or do I have to use nested cross validation instead? Would the best k-fold cross validation result be an upwardly biased estimate?
