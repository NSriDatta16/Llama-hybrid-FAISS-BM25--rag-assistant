s used by the service provider (for instance, to train the software). Zero-knowledge encryption implies that the only unencrypted copy is at the client, and the server cannot decrypt the data any more easily than a monster-in-the-middle attacker. Platforms Scribes may operate on desktops, laptop, or mobile computers, under a variety of operating systems. These vary in their risks; for instance, mobiles can be lost. The underlying mobile or desktop operating systems are also part of the trusted computing base, and if they are not secure, the software relying on them cannot be secure either. Confabulation, omissions, and other errors Like other LLMs, medical-scribe LLMs are prone to confabulation, where they make up content based on statistically associations between their training data and the transcription audio. LLMs do not distinguish between trying to transcribe the audio and guessing what words will come next, but perform both processes mixed together. They are especially likely to take short silences or non-speech noises and invent some sort of speech to transcribe them as. LLM medical scribes have been known to confabulate racist and otherwise prejudiced content; this is partly because the training datasets of many LLMs contain pseudoscientific texts about medical racism. They may misgender patients. A survey found that most doctors preferred, in principle, that scribes be trained on data reviewed by medical subject experts. Relevant, accurate training data increases the probability of an accurate transcription, but does not guarantee accuracy. Software trained on thousands of real clinical conversations generated transcripts with lower word error rates. Software trained on manually-transcribed training data did better than software trained with automatically transcribed training data (such as YouTube captions). Autoscribes omit parts of the conversation classes as irrelevant. The may wrongly classify pertinent information as irrelevant and omit it. They may also confuse historic and current symptoms, or otherwise misclassify information. They may also simply wrongly transcribe the speech, writing something incorrect instead. If clinicians do not carefully check the recording, such mistakes could make their way into their medical records and cause patient harms. Patient consent Professional organizations generally require that scribes be used only with patient consent; some bodies may require written consent. Medics must also abide by local surveillance laws, which may criminalize recording private conversations without consent. Full information on how data is encrypted, transmitted, stored, and destroyed should be provided. In some jurisdictions, it is illegal to transmit the data to any country without equivalent privacy laws, or process or store the data there; vendors who cannot guarantee that their products won't illegally send data abroad cannot be legally used. Some vendors collect data for reuse or resale. Medical professionals are generally considered to have a duty to review the terms and conditions of the user agreement and identify such data reuse. General practices are generally required to provide information on secondary uses to patients, allow them to opt out of secondary uses, and obtain consent for each specific secondary use. Data must only be used for agreed-upon purposes. Technology and market The medical scribe market is, as of 2024, highly competitive, with over 50 products on the market. Many of these products are just proprietary wrappers around the same LLM backends, including backends whose designers have warned they are not to be used for critical applications like medicine. Some vendors market scribes specialized to specific branches of medicine (though most target general practitioners, who make up about a third of doctors). Increasingly, vendors market their products as more than scribes, claiming that they are intelligent assistants and co-pilots to doctors. These broader uses raise more a