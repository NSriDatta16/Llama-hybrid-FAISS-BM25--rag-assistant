[site]: crossvalidated
[post_id]: 587146
[parent_id]: 584011
[tags]: 
While the estimated standard deviation is at the same scale as the estimated mean, it is not in the space as the mean. The mean is ultimately an "average point" while the standard deviation is an "average spread". The space they are defined upon is not the same so the same transformation can often lead to nonsensical results (as you have already experienced). The most straightforward idea will be to calculate 1- and 2-SD intervals around the estimated mean in the transformed domain, i.e in the $[-1,1]$ interval, and then back-transform those in the original scale. That is a common technique when working with GLMs, where we for example with a logistic GLM we construct lower and upper 95% Wald confidence limits on the logit (log-odds) scale and then back-transform them to the probability scale. So, do not try " inverting the standard deviation " but rather use it in it's appropriate domain. A thread in SO with a worked example on logistic regressionc can be found here: https://stackoverflow.com/questions/14423325 , the same exact mechanics apply in this GP use case. Finally, do note that in the transformed domain $[-1,1]$ we might indeed end up with CIs (or even predictions at some extreme cases) outside the bounds of $\pm 1$ ; that is just the (harsh) reality of using a truncated domain to predict/estimate upon. In general, I would not suggest a min-max normalisation as the one done here unless we have good reasons too believe our data is also truncated in their "real domain"; for example in Computer Vision applications normalising pixels values from $[0,255]$ to $[-1,1]$ is probably fine because ultimately, $255$ is our max value, on the other hand for daily temperature fluctuations or stock-price volatility we have little reason to expect some hard bounds.
