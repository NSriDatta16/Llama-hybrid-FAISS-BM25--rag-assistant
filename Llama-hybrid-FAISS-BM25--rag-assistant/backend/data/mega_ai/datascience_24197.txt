[site]: datascience
[post_id]: 24197
[parent_id]: 24193
[tags]: 
What you have here is some data that's too specific. I don't know if there's a widely accepted name for that, but I've seen it be called "leaking" or "cheating" data. Using this kind of data is potentially dangerous for the algorithm, as you have seen in your experiments. Here's a quick example: I want to predict whether a costumer prefers to wear white socks or black socks. I have a lot of information from this costumer, like the city he lives or how many TVs he owns (let's pretend there's some relation with preferred sock color). For some reason, the people handling the interview I use as data sorted the 200 interview responses by class - the first 120 responses are for white socks, and the next 80 are for black socks. Each response has an identifier from 1 to 200. Now I run this data through a decision tree learner. It comes up with a stump (a tree with only a single node) containing the rule: If Id This is completely useless! If I just keep giving new identifiers to people, I'll assume every new costumer prefers black socks! (Except if one of the first 120 comes back). While may be some advanced ways to deal with this problem to use the fact the user may repeat and that's relevant (it usually is), I wouldn't recommend it. 17k instances isn't that much to try for a more complex model, you could be overfitting. Only go towards some other strategy (like frequent pattern mining, or turning the problem in a time series of sort) if and only if removing the Id column is not good enough.
