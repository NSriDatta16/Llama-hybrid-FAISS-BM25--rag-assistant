[site]: crossvalidated
[post_id]: 206966
[parent_id]: 206841
[tags]: 
Typically boosted tree-based models, random forests, or other ensemble methods are often superior in terms of predictive accuracy. The biggest advantage of single standalone trees (specifically those with constant fits in each node) is the interpretability. The do not produce black-box results but are easy to understand and communicate to practitioners. Whether there predictive performance is still good enough to justify their use over boosted trees or forests surely depends on the data and the purpose of the analysis. As for model trees: These try to form a compromise between classical regression models and regression/classification trees with constant fits. They are often still interpretable while improving the predictive accuracy over standard trees. However, they are often still outperformed by boosting/forests. Model trees have been used in practice but standard constant fit trees as well as boosting/forests are certainly used much more widely.
