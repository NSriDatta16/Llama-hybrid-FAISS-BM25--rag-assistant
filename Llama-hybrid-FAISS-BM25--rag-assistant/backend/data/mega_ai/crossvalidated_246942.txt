[site]: crossvalidated
[post_id]: 246942
[parent_id]: 246886
[tags]: 
Your methodology seems fine. From a theoretical perspective, it broadly agrees with recommendations in time series textbooks. From an empirical perspective, your models have well-behaved residuals, so they are decent approximations of the data. More generally, there is no methodology that is universally the best. Model selection should depend on the intended use of the model. If you intend to do forecasting, a sensible lag order selection criterion is AIC. AIC tends to select the model (from the pool of candidate models) that yields the smallest squared forecast error 1 step ahead. If you want to recover the true model (from a pool of candidate models that includes the true model), a sensible lag order selection criterion is BIC. Asymptotically it should select the true model with probability 1. However, the assumption that the true model is in the candidate pool may be very restrictive, especially when working with real world applications where models are approximations of the (very) complex reality. Well-behaved residuals are desirable, but they do not necessarily suggest you have picked a good model for the underlying data generating process. It is always possible to construct a rich, flexible model that fits the data sufficiently well to produce well-behaved residuals. However, this does not make the model likely to be a good approximation of the data generating process. It fits well in sample but may not fit well out of sample, and it is normally the latter that we care about (either by intending to forecast it or to test some hypothesis about it). (But of course, residual diagnostics should not be neglected; a particular pattern in ill-behaved residuals may indicate how the model could be changed for the better. Also, for hypothesis testing you need to account for autocorrelation or heteroskedasticity if it is present, e.g. by using HAC standard errors.)
