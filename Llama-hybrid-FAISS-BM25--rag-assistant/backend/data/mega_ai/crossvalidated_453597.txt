[site]: crossvalidated
[post_id]: 453597
[parent_id]: 
[tags]: 
Bayesian Linear Regression and the Exponential Family

In a straight forward linear regression model, assuming a fixed input $\mathbf{x}$ , and additive noise with unit variance we can write: \begin{equation} p(y\mid \mathbf{x,w})=\frac{1}{\sqrt{2\pi}\sigma^2}\exp\left(-\frac{1}{2\sigma^2}(y-\mathbf{w}\cdot\mathbf{x})^2 \right), \end{equation} from which point we can expand the square and collect the terms such that the expression fits within the exponential family framework. In particular if we assume the exponential family has the form: \begin{equation} f_{X}(x\mid \theta )=h(x)\exp \left[\eta (\theta )\cdot T(x)-A(\theta )\right] \end{equation} then we can see that $\eta(\theta) = [\mathbf{w}\cdot\mathbf{x}/\sigma^2, -\frac{1}{2\sigma^2} ]$ , $T(x) = [y,y^2]^\intercal$ , where the remaining terms can be collected as needed. I am interested in extending this to Bayesian linear regression, in particular I consider some extension: $p(y,\mathbf{w} \mid \mathbf{x},\beta)$ = $p(y\mid \mathbf{x,w})p(\mathbf{w}\mid \beta)$ , where I add some Gaussian prior over the weights, such that I have the expression (once again considering unit variance): \begin{equation} p(y,\mathbf{w} \mid \mathbf{x},\beta) = \frac{1}{\sqrt{2\pi}\sigma^2}\exp\left(-\frac{1}{2\sigma^2}(y-\mathbf{w}\cdot\mathbf{x})^2 \right)\cdot\frac{1}{\sqrt{2\pi}\sigma^2}\exp\left(-\frac{1}{2\sigma^2}(\mathbf{\beta}-\mathbf{w})^{\intercal} \mathbf{\Sigma} (\mathbf{\beta}-\mathbf{w}) \right) \end{equation} Question: Is it possible to express this via the exponential family? As I understand both likelihood and prior need the same $\eta(\theta)$ term to appear, but in the likelihood we have the expression $ \mathbf{w\cdot x}$ , but only $\mathbf{w}$ in the prior, and I am not finding it easy to massage $\mathbf{w}$ into a form which has something like " $\mathbf{w\cdot x / x}$ " going on. Perhaps we can consider something like $\mathbf{w}\cdot 1$ , s.t. $\mathbf{x}$ is constrained to lie on $\mathbf{x}=1$ ? Therefore is it possible to express the above model via the exponential family form? If so, how would the log partition function look like? Is there a proof somewhere online I can inspect for this? If the above answer is yes, would your solution extend naturally to the case of $\phi(\mathbf{w\cdot x})$ (i.e. non-linear transformation)? Intuitively in the linear case I believe the answer should be yes, as Gaussians are closed under multiplication, but the algebra for this one corner case has stumped me a little...
