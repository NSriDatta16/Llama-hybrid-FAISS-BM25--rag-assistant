[site]: crossvalidated
[post_id]: 555954
[parent_id]: 
[tags]: 
Understand the idea of margin in contrastive loss for siamese networks

I was studying siamese networks for authentication. Loss is: Y is 0 for dissimilar pairs and 1 for similar pairs. D_w is the distance (e.g. euclidean distance) between two pairs (by using weights w). If pairs are similar, then loss is equal to the green box in loss function. If pairs are dissimilar, then loss is equal to the red box in the loss function. Suppose that we have two similar samples, then the loss is equal to the distance^2 between them. Since the aim of the training is to minimize the loss, therefore by training on similar pairs, will help to minimize the distance between similar pairs. If we have two dissimilar samples, therefore there is an m term, which signifies margin in the loss function. According to the red box, if margin face x (aim: to understand input is face x or not), what margin does? Is it something linear (like SVM margin), circle or another form? Should it have a specific form? Why if margin Edit 1: I found this explanation but I did not understand. I put it, in case it helps you to understand: taken from here : Role of margin m: It is to be noted that the representations of negative pairs will only contribute to the loss if the estimated distance ||f(x)-f(y)||
