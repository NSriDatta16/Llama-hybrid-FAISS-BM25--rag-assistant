[site]: crossvalidated
[post_id]: 621784
[parent_id]: 621780
[tags]: 
I'm not sure what point you are trying to make. Weakly informative priors affect the results weakly. If you used less weakly informative priors, they would affect the result even more. With a growing sample size, the influence of the prior diminishes, but still with a very strong prior this may be slow. If your point is to remove the impact of the priors, why bother using the Bayesian approach at all? As for the small sample size, keep in mind that a non-Bayesian approach would not be a remedy. If the sample is small, it may be very vulnerable to small differences in the data. Even something as simple as an arithmetic mean can fluctuate a lot in the small sample if you change even a single value. For some of the more complicated models, you may not be able to estimate their parameters at all if you don't have enough data (while it could be possible with the Bayesian approach). Also, non-Bayesian models have their own assumptions and parameters that do affect the results. So given the reasons above, one could paraphrase the question as: "Should we do statistics with small samples at all?" The problem is that sometimes we have to because there is simply no more data available.
