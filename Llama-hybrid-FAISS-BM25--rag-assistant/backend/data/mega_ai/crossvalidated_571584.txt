[site]: crossvalidated
[post_id]: 571584
[parent_id]: 
[tags]: 
Creating a holdout set just for feature engineering?

I recently encountered a feature engineering technique that I haven't seen before: Create the usual training, validation, and test sets. Create another set by splitting the train set; call this the "feature engineering" set. Use the feature engineering set tp fit any pre-processing that needs to be fitted, e.g. target encoding or median imputation. Apply the transformations that were obtained in (3) to the main training set, then proceed with model building. Is there any additional benefit to the extra feature engineering split in this procedure? My guess was that it should result in more "realistic" results for fitting the main model, by avoiding overfitted "in-sample" outputs from the feature engineering stages. Is this common practice? Has it been shown to produce better results? The example I saw was in a target encoding tutorial , (cells 4-5). Did I misunderstand the example?
