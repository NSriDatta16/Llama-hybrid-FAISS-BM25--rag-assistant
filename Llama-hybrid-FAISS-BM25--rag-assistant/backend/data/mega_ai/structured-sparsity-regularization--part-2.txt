{\displaystyle \phi _{j}:X\rightarrow \mathbb {R} } with j = 1 , . . . , p {\displaystyle j=1,...,p} . min w ∈ R d 1 n ∑ i = 1 n V ( y i , ⟨ w , Φ ( x i ) ⟩ ) + λ ‖ w ‖ 0 , {\displaystyle \min _{w\in \mathbb {R} ^{d}}{\frac {1}{n}}\sum _{i=1}^{n}V(y_{i},\langle w,\Phi (x_{i})\rangle )+\lambda \|w\|_{0},} The regularization term λ ‖ w ‖ 0 {\displaystyle \lambda \|w\|_{0}} penalizes each w j {\displaystyle w_{j}} component independently, which means that the algorithm will suppress input variables independently from each other. In several situations we may want to impose more structure in the regularization process, so that, for example, input variables are suppressed according to predefined groups. Structured sparsity regularization methods allow to impose such structure by adding structure to the norms defining the regularization term. Structures and norms Non-overlapping groups: group Lasso The non-overlapping group case is the most basic instance of structured sparsity. In it, an a priori partition of the coefficient vector w {\displaystyle w} in G {\displaystyle G} non-overlapping groups is assumed. Let w g {\displaystyle w_{g}} be the vector of coefficients in group g {\displaystyle g} , we can define a regularization term and its group norm as λ R ( w ) = λ ∑ g = 1 G ‖ w g ‖ g {\displaystyle \lambda R(w)=\lambda \sum _{g=1}^{G}\|w_{g}\|_{g}} , where ‖ w g ‖ g {\displaystyle \|w_{g}\|_{g}} is the group ℓ 2 {\displaystyle \ell _{2}} norm ‖ w g ‖ g = ∑ j = 1 | G g | ( w g j ) 2 {\displaystyle \|w_{g}\|_{g}={\sqrt {\sum _{j=1}^{|G_{g}|}(w_{g}^{j})^{2}}}} , G g {\displaystyle G_{g}} is group g {\displaystyle g} , and w g j {\displaystyle w_{g}^{j}} is the j-th component of group G g {\displaystyle G_{g}} . The above norm is also referred to as group Lasso. This regularizer will force entire coefficient groups towards zero, rather than individual coefficients. As the groups are non-overlapping, the set of non-zero coefficients can be obtained as the union of the groups that were not set to zero, and conversely for the set of zero coefficients. Overlapping groups Overlapping groups is the structure sparsity case where a variable can belong to more than one group g {\displaystyle g} . This case is often of interest as it can represent a more general class of relationships among variables than non-overlapping groups can, such as tree structures or other type of graphs. There are two types of overlapping group sparsity regularization approaches, which are used to model different types of input variable relationships: Intersection of complements: group Lasso The intersection of complements approach is used in cases when we want to select only those input variables that have positive coefficients in all groups they belong to. Consider again the group Lasso for a regularized empirical risk minimization problem: λ R ( w ) = λ ∑ g = 1 G ‖ w g ‖ g {\displaystyle \lambda R(w)=\lambda \sum _{g=1}^{G}\|w_{g}\|_{g}} , where ‖ w g ‖ g {\displaystyle \|w_{g}\|_{g}} is the group ℓ 2 {\displaystyle \ell _{2}} norm, G g {\displaystyle G_{g}} is group g {\displaystyle g} , and w g j {\displaystyle w_{g}^{j}} is the j-th component of group G g {\displaystyle G_{g}} . As in the non-overlapping groups case, the group Lasso regularizer will potentially set entire groups of coefficients to zero. Selected variables are those with coefficients w j > 0 {\displaystyle w_{j}>0} . However, as in this case groups may overlap, we take the intersection of the complements of those groups that are not set to zero. This intersection of complements selection criteria implies the modeling choice that we allow some coefficients within a particular group g {\displaystyle g} to be set to zero, while others within the same group g {\displaystyle g} may remain positive. In other words, coefficients within a group may differ depending on the several group memberships that each variable within the group may have. Union of groups: latent group Lasso A different approach is 