[site]: datascience
[post_id]: 39801
[parent_id]: 39800
[tags]: 
You've not provided the dataset but I will try to answer based on your descriptions. how many (multiple of 200?) rows do I choose for train/test sets? Actually, the train/validation/test splits do not really depend on the length of the time series. It is more dependent on the number of examples, time series here. $300k / 200 = 1.5k$ which means the size of your dataset is small and you can use the customary percentages for your splits. Something like 60/20/20 for train/validation/test. Is my batch size 200? $200$ is not your batch size, it is the length of your signal. In LSTM networks, you usually deal with temporal data. For each sample, you have 12 features for each time step. $200$ means each sample has $200$ steps. In vectorise implementations of LSTMs it is customary to define batch size. That is, you stack $m = batch size$ samples for acceleration in training, it has details that I skip. What is the basis for choosing number of neurons? Take a look at here . Although the details of MLPs are described, they can be generalised to LSTMs too. Consider RNNs like simple MLPs which take the inputs of the current time step and the outputs of the previous step.
