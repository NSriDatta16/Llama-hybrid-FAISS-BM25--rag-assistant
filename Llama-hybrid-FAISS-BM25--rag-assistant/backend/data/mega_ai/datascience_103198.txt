[site]: datascience
[post_id]: 103198
[parent_id]: 103123
[tags]: 
First of all, in problems like you brought, you typically start with preprocessing. Specifically, in your case, you need to normalize it. That means, using some processing, you have to change both Are you there and are you there??? to just are you there . By doing that, you are removing duplicate examples there. Now, unlike Erwin , I suggest that in general. The reason is your model will only learn on important examples. It will also generalize well with small data. That is because, your preprocessing step removes any kind of impurities that will create headache for your model. Specially in deep learning case, you have to have good examples. Not removing them will only work if you have very sufficient amount of data that allows your model to accurately capture the relationships between words and word derivatives. For example, your model should learn that there and there??? are the same given Are you and are you are present. If you normalize it, you are doing the model a huge favor there. Secondly, as Erwin pointed out, the labeling in the problem is concerning. Yes, sometimes, same sentences spoke with different tones create different sentiments. In that case, you need to augment more information on the inputs to signal that. That could be a few seconds of the actual voice. Without such treatment, your model will get confused and never converge.
