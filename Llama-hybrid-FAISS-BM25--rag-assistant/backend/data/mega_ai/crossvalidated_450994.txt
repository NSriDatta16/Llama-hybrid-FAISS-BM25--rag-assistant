[site]: crossvalidated
[post_id]: 450994
[parent_id]: 450975
[tags]: 
Let us consider as an example a coin with $p=0.1$ provability of heads. If we learn that the coin turned heads, our "surprise" is given by $\log_2{\frac{1}{0.1}}\approx3.3$ , which is indeed greater than the 1 bit yielded by the fair coin. On the other hand, if we learn the coin turned tails, our surprise is only $\log_2{\frac{1}{0.9}}\approx0.15$ , which is less than 1 bit. On average, the surprise we get is $0.9\cdot\log_2{\frac{1}{0.9}}+0.1\cdot\log_2\frac{1}{0.1}\approx0.47$ , which is less than 1 bit! The entropy of this unfair coin with $p=0.1$ is given by $0.47$ , not $3.3$ or $0.15$ . That is so because entropy is the average surprise across all possible outcomes , not the surprise associated with a single event. Algebraically, we can state that the entropy is given by: $$H=\sum p_i\log_2 \frac{1}{p_i}$$ In the case of a coin experiment, this equation becomes $H=p\log_2\frac{1}{p}+(1-p)\log_2\frac{1}{1-p}$ , which have a maximum point at $p=0.5$ .
