[site]: crossvalidated
[post_id]: 573418
[parent_id]: 573398
[tags]: 
In your case of $\text{sum}(XY)/\text{sum}(X)$ you have that the $X$ and $Y$ are correlated. We can rewrite it in a different form such that we have a similar weighted average expression but with uncorrelated $X$ and $Y$ . You will get that you can relate it to the following expression: $$1 + 4 E\left[\left(\frac{\sum_{i=1}^{M} X_iZ_i}{\sum_{i=1}^{M} X_i}\right)^{-1}\right]$$ where the weights are $X_i \sim U(a,b)$ and the variable $Z_i \sim Pareto(\alpha = 1, x_m = 1)$ follows a Pareto distribution . Possibly it is easier to first solve the simpler (but still difficult) problem with $\beta_i = 1$ constant. $$E\left[\left(\frac{1}{M}{\sum_{i=1}^{M} Z_i}\right)^{-1}\right]$$ Derivation The equation could be simplified (easier to read) by using different variables like $\alpha_i = 1-\varphi_i^2 \sim U(0,1)$ and $\beta_{i} = \phi_{0,i}^2 \sim U(a,b)$ such that your question becomes $$E\left[ {\frac{{\sum\limits_{i = 1}^M {\frac{{\beta_{i}}}{{\alpha_i}} \cdot \left( {1+4\alpha_i } \right)} }}{{\sum\limits_{i = 1}^M {\frac{{\beta_{i}}}{{\alpha_i}}} }}} \right]$$ where $\beta _{i} \sim U\left( {a,b} \right),b > a > 0$ and $\alpha_i \sim U\left( {0,1} \right)$ . The expression can also be simplified further $$E\left[ {\frac{{\sum\limits_{i = 1}^M {\frac{{\beta_{i}}}{{\alpha_i}} \cdot \left( {1+4\alpha_i } \right)} }}{{\sum\limits_{i = 1}^M {\frac{{\beta_{i}}}{{\alpha_i}}} }}} \right] = E\left[ {\frac{{\sum\limits_{i = 1}^M { \frac{{\beta_{i}}}{{\alpha_i}} + 4 \beta_{i} } }}{{\sum\limits_{i = 1}^M {\frac{{\beta _{i}}}{{\alpha_i}}} }}} \right]= E\left[ {\frac{{\sum\limits_{i = 1}^M { \frac{{\beta_{i}}}{{\alpha_i}} + \sum\limits_{i = 1}^M 4 \beta_{i} } }}{{\sum\limits_{i = 1}^M {\frac{{\beta _{i}}}{{\alpha_i}}} }}} \right] = 1 + 4 \cdot E\left[ {\frac{\sum\limits_{i = 1}^M \beta_{i} }{{\sum\limits_{i = 1}^M {\frac{{\beta _{i}}}{{\alpha_i}}} }}} \right]$$ Alternative viewpoint as random walk For $M=1$ we get: $$1 + 4 \cdot E\left[ \frac{\beta_{1}}{\frac{\beta _{1}}{\alpha_1}} \right] = 1 + 4 \cdot E\left[ {\alpha_1} \right] = 3$$ For $M=2$ we get: $$1 + 4 \cdot E\left[ \frac{\beta_{1} + \beta_{2}}{\frac{\beta _{1}}{\alpha_1} + \frac{\beta_{2}}{\alpha_2}} \right] = 1 + 4 \cdot E\left[ \frac{\beta_{1}\alpha_2\cdot \alpha_1 + \beta_{2}\alpha_1\cdot \alpha_2}{\beta_{1}\alpha_2\phantom{\cdot \alpha_1} + \beta_{2}\alpha_1\phantom{\cdot \alpha_1} } \right] $$ For $M=3$ we get: $$1 + 4 \cdot E\left[ \frac{\beta_{1} + \beta_{2}}{\frac{\beta _{1}}{\alpha_1} + \frac{\beta_{2}}{\alpha_2}} \right] = 1 + 4 \cdot E\left[ \frac{\beta_{1}\alpha_2\alpha_3\cdot \alpha_1 + \beta_{2}\alpha_1\alpha_3\cdot \alpha_2+ \beta_{3}\alpha_1\alpha_2\cdot \alpha_3}{\beta_{1}\alpha_2\alpha_3 \phantom{\cdot \alpha_1} + \beta_{2}\alpha_1\alpha_3 \phantom{\cdot \alpha_1} + \beta_{3}\alpha_1\alpha_2\phantom{\cdot \alpha_1} } \right] $$ For more general $M$ You seem to get the expectation of a weighted average of $\alpha_i$ where the wheighing is $\beta_i \prod_{l \neq i} \alpha_l $ . $$X_{k} = \frac{\sum_{i = 1}^k \left( \beta_i \prod_{l \neq i} \alpha_l \right) \cdot \alpha_i} {\sum_{i = 1}^k \left( \beta_i \prod_{l \neq i} \alpha_l \right)}$$ When we add a sample $\beta_{k+1},\alpha_{k+1}$ to a sample of size $k$ then we can recompute the value as $$X_{k+1} = \frac{\left(Q_k\alpha_{k+1}\right) \cdot X_{k} + \left(\beta_{k+1} \prod_{i=1}^k \alpha_i \right) \cdot \alpha_{k+1}}{\left(Q_k\alpha_{k+1}\right) \hphantom{\cdot X_{k}} + \left(\beta_{k+1} \prod_{i=1}^k \alpha_i \right) \hphantom{\cdot \alpha_{k+1}}} $$ where $Q_k = \sum_{i = 1}^k \left( \beta_i \prod_{k \neq i} \alpha_k \right)$ This seems like some sort of random walk $$X_{k+1} = \phi_{k+1} X_k + (1-\phi_{k+1}) \alpha_{k+1}$$ with $$\phi_{k+1} = \frac{Q_k\alpha_{k+1}}{Q_k\alpha_{k+1} + \beta_{k+1} P_k } $$ and $P_{k+1} = P_{k} \alpha_{k+1}$ and $Q_{k+1} = Q_k \alpha_{k+1} + P_k \beta_{k+1}$ The below code demonstrates this alternative view of how the random variable $X_n$ evolves from $n$ to $n+1$ a = 1 b = 3 alpha = runif(1,0,1) beta = runif(1,a,b) X = alpha Q = beta P = 1 for (i in 1:1000) { alpha_n = runif(1,0,1) beta_n = runif(1,a,b) alpha = c(alpha, alpha_n) beta = c(beta, beta_n) phi = Q*alpha_n /(Q*alpha_n + P*beta_n) X = c(X,phi * tail(X,1) + (1-phi) * alpha_n) Q = Q * alpha_n + P * beta_n P = P * alpha_n } ### two different ways to compute a series of X plot(X*4+1, type = "l") plot(1+4*cumsum(beta)/cumsum(beta/alpha), type = "l") I wonder if we can use this iterative process to express the expectation value as some recursive relationship. Geometric interpretation The problem is equivalent to evaluating the expression $$E\left[ \left( \frac{{\sum\limits_{i = 1}^M {\frac{{\beta _{i}}}{{\alpha_i}}} }}{\sum\limits_{i = 1}^M \beta_{i} } \right)^{-1}\right]$$ with $\alpha_i \sim U(0,1)$ and $\beta_i \sim U(a,b)$ We can focus on the sum inside $$\frac{{\sum\limits_{i = 1}^M {\frac{{\beta _{i}}}{{\alpha_i}}} }}{\sum\limits_{i = 1}^M \beta_{i} }$$ This is equal to the integral of a random path which that is created by ordering the $\alpha_i$ and making a horizontal step of size $\frac{\beta_i}{\sum\limits_{i = 1}^M \beta_{i} }$ at a height of $\alpha$ Let this curve be $\alpha(x)$ then we have $$ \int_0^1 \frac{1}{\alpha(x)} dx = \frac{{\sum\limits_{i = 1}^M {\frac{{\beta _{i}}}{{\alpha_i}}} }}{\sum\limits_{i = 1}^M \beta_{i} }$$ and we can see the expectation as $$E\left[\frac{1}{\int_0^1 \frac{1}{\alpha(x)} dx }\right]$$ here this curve $\alpha(x)$ resembles an empirical distribution function for a uniform variable.
