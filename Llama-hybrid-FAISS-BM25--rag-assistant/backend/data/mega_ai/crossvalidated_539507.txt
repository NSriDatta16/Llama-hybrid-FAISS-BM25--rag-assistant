[site]: crossvalidated
[post_id]: 539507
[parent_id]: 539475
[tags]: 
One answer might be to create a generative model that assumes some distribution over the properties of computers to be repaired, something about the measurement process at each lab, the process for deciding whether to repair it send to another lab, and the same processes there. You may or may not struggle with this due to a lack of sufficient data identifying all aspects of the model. Or you leave out the bit where you model the distribution of items to be repaired and chain a bunch of non-generative models (i.e. specific input distributions sort of taken as given) after each other (or a single multi-output neural network or something like that) and model just the process in the company. Maybe that would be better informed (but also more fragile to changes in the system). Clearly, either approach would work better on the second scenario you described, but even better if you collected even more data that's not routinely created (e.g. send some items to be measured in all 3 labs no matter what and possibly even randomize where these items get repaired).
