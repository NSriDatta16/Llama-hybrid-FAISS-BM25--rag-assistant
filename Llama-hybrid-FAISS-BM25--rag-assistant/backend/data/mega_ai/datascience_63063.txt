[site]: datascience
[post_id]: 63063
[parent_id]: 
[tags]: 
Is there any optimal way on feature selection for more than one classification algorithms?

I have a wine dataset with 13 features that indicates 3 different wine classes (target), and k-NN, SVM with linear kernel and SVM with rbf kernel algorithms to be tried with this dataset. My goal is to obtain the best classification accuracy, and to obtain this accuracy: Which classification algorithm (kNN, SVM with linear kernel or SVM with rbf kernel) should I choose? Among all the features, which ones of them (based on backward elimination, maybe according to p-values) should be chosen? I have thought of using GridSearchCV with 3 estimators for the algorithms above. But in this case, the problem is feature selection part as you guess. Is there any optimal way to achieve both? Thanks!
