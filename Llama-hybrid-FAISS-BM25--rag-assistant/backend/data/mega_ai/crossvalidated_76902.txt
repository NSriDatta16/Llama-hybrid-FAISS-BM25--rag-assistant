[site]: crossvalidated
[post_id]: 76902
[parent_id]: 76899
[tags]: 
The complexity of SVM regression is similar to the complexity of SVM classification. If problems of that size are feasible for you in a classification context, they are also feasible in regression. When using a nonlinear kernel, training complexity is quadratic in terms of the number of training instances. 100k training instances is quite a lot, so I most definitely recommend trying a linear kernel first. For the linear kernel, you should consider using LIBLINEAR instead of LIBSVM (same authors, the former is made specifically for large-scale problems). The impact of the number of dimensions on training time is not very high, this is one of the advantages of kernel methods. Knowing that, you may well go for 4000 dimensions straight away. If you have 4000 dimensions, linear models are likely to perform quite well . It is very hard to give a good estimate of the actual run time as it depends on a lot of things, related to the data and your hardware. That said, you can expect training time to be in the order of hours tens of minutes per model for LIBSVM. If you use LIBLINEAR, it will be a couple of seconds.
