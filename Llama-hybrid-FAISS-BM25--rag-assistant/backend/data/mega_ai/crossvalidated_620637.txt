[site]: crossvalidated
[post_id]: 620637
[parent_id]: 252937
[tags]: 
I don’t think you should set both a p-value and Q (the upper value of FDR). The p-values are calculated and, with the BH correction, statistical significance depends on both the set of p-values and such Q. The link you report actually sets a Q of 0.25 (and defends such choice even in case of all p-values between 0.10 and 0.24): I’ve never seen a Q above that. The reason for discrepancies across fields, in my opinion, may be understood by reading the original paper: https://rss.onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1995.tb02031.x The FDR is given by the number of false positives on the number of significant findings. However, a crucial point is that, in case of no significant findings, the FDR is set to 0. This makes the FDR equal to the p-value in the single-test case (when the null hypothesis is true). Of course, this is not interesting because it’s the degenerate case. However, the point is that, when the number of tests is low, or there’s the possibility that all null hypotheses are true, using an alpha above 0.05 would be suspect. For example, with only two tests, you would consider two p-values between 0.05 and 0.1 as evidence of a double effect, and you would consider a p-value of 0.05 in one test as significant regardless of the value of the other test: this would be even less conservative than ignoring the fact you’re doing two tests. If, instead, it is not realistic to assume that all null hypotheses are true, it may make sense to use a higher Q, since the possibility of no significant findings becomes less realistic. Moreover, the formula in the original paper shows that you just select an upper bound for FDR, but that actual FDR is below the product between the chosen Q and the proportion of null hypotheses that are true ( $E(Q) \leq \frac{m_o}{m}q* \leq q*$ , in the paper’s terminology). This implies that, the higher the ratio of false null hypotheses, the lower the real FDR. This explains why, in situations where a plethora of tests are performed, like in genetics, one may choose higher Qs. Consider however that use of a Q of 0.05 allows you to express q-values as BH-adjusted p-values, and that you’ll be sure to have both 1) BH-adjusted p-values more conservative than unadjusted p-values and 2) BH-adjusted CIs for significant findings (see, for example, here: https://onlinelibrary.wiley.com/doi/10.1111/psyp.12616 ) with a higher coverage than 95% and not including the null. Instead, with a Q above 0.05, you could find significance in comparisons with a p-value above 0.05 (and with a 95% unadjusted CI including the null). Moreover, referees might not accept a Q above 0.05, for analogy between FDR and type-I error.
