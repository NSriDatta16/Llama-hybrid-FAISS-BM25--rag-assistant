[site]: crossvalidated
[post_id]: 577892
[parent_id]: 
[tags]: 
Are the number of neurons in a hidden layer equal to the dimensions in which a hyperplane is being sought by the network?

My question stems from this example and my basic understanding of neural networks so far. Forgive my ignorance if I am totally off. So in this example, a neural network with 2 neurons cannot find a representation for this data that fully separates the two. A third neuron must be added after which the problem can easily be solved by a neural network. So by adding the third neuron, the network can map the data into a three dimensional space and find a representation that can be linearly separated. My question that arises from this: are the number of neurons in a hidden layer equal to the dimensional space in which a hyperplane is being sought by the network?
