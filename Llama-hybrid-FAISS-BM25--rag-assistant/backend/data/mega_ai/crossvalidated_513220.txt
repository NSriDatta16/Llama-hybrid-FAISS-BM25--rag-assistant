[site]: crossvalidated
[post_id]: 513220
[parent_id]: 
[tags]: 
How to find credible interval for multiple bayesian distributions that disagree?

Feel free to suggest changes to my terminology here, I don't think this is proper Bayesian analysis. I'm a scientist trying to produce a credible interval for an unknown experimental value X. The experiments allow me to ask the question: P( X | experiment ) I get this value by looking at the p-value of a binomial function at every value of X and asking: "How likely is it that I could get this data if X == X 0 ". (So my P distribution doesn't sum to 1 but rather maxes out at 1.) By combining multiple experiments together, I arrive at the following representation of my problem: P( X | all_data ) = P( X | experiment1 ) * P( X | experiment2 ) ... Here are the P(X) traces for a single parameter estimation: Let's say I'm trying to produce a 95% credible interval. I have two different methods that produce satisfactory results here: Normalize the graph such that sum( P( X | all_data ) ) == 1 . Produce a cumulative distribution. And select cumul( X_lb ) == 0.025 and cumul( X_ub ) == 0.975 Simply pick X_lb and X_ub where the graph crosses 0.025. My problem comes from estimating the bounds when the experiments do not agree with each other. Consider the following experimental traces where the P( X | all_data ) maxes out at 1e-60: Since the P( X | all_data ) is very sharp here, my credible interval estimations produce very narrow intervals. But this is exactly the opposite of what should happen! My data isn't self-consistent, and so my interval should be huge! I would like to know the proper way to produce these intervals. For the purposes here, just assume the data is what it is and that I have to produce an upper and lower bound. Normalization is fine, but my traces will always come from p-values of a binomial.
