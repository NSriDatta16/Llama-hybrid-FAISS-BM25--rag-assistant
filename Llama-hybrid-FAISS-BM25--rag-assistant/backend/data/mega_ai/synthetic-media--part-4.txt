re otherwise impossible to create through traditional game development methods. Computer hardware company Nvidia has also worked on developed AI-generated video game demos, such as a model that can generate an interactive game based on non-interactive videos. Concerns and controversies Apart from organizational attack, political organizations and leaders are more suffered from such deep fake videos. In 2022, a deep fake was released where Ukraine president was calling for a surrender the fight against Russia. The video shows Ukrainian president telling his soldiers to lay down their arms and surrender. Deepfakes have been used to misrepresent well-known politicians in videos. In separate videos, the face of the Argentine President Mauricio Macri has been replaced by the face of Adolf Hitler, and Angela Merkel's face has been replaced with Donald Trump's. In June 2019, a downloadable Windows and Linux application called DeepNude was released which used neural networks, specifically generative adversarial networks, to remove clothing from images of women. The app had both a paid and unpaid version, the paid version costing $50. On June 27 the creators removed the application and refunded consumers. The US Congress held a senate meeting discussing the widespread impacts of synthetic media, including deepfakes, describing it as having the "potential to be used to undermine national security, erode public trust in our democracy and other nefarious reasons." In 2019, voice cloning technology was used to successfully impersonate a chief executive's voice and demand a fraudulent transfer of €220,000. The case raised concerns about the lack of encryption methods over telephones as well as the unconditional trust often given to voice and to media in general. Starting in November 2019, multiple social media networks began banning synthetic media used for purposes of manipulation in the lead-up to the 2020 United States presidential election. In 2024, Elon Musk shared a parody without clarifying that it’s a satire but raised his voice against AI in politics. The shared contains Kamala Harris saying things she never said in real life. A few lines from the video transcription include, “I, Kamala Harris, am your Democrat candidate for president because Joe Biden finally exposed his senility at the debate,” The voice then says that Kamala is a “Diversity hire”, and that she has no idea about “the first thing about running the country”. These are some examples of synthetic media potentially affecting the public reaction to celebrities, political party or organizations, business or MNCs. The potential to harm their image and reputation is concerning. It may also erode social trust in public and private institutions, and it will be harder to maintain a belief in their ability to verify or authenticate "true" over "fake" content. Citron (2019) lists the public officials who may be most affected are, “elected officials, appointed officials, judges, juries, legislators, staffers, and agencies.” Even private institutions will have to develop an awareness and policy responses to this new media form, particularly if they have a wider impact on society. Citron (2019) further states, “religious institutions are an obvious target, as are politically engaged entities ranging from Planned Parenthood to the NRA. ” Indeed, researchers are concerned that synthetic media may deepen and extend social hierarchy or class differences which gave rise to them in the first place. The major concern tends to revolve around synthetic media is that it isn’t only a matter of proving something that is wrong, it’s also a concern of proving that something is original. For example, a recent study shows that two out three cyber security professionals noticed that deepfakes used as part of disinformation against business in 2022, which is apparently a 13% increase in number from the previous year. Potential uses and impacts Synthetic media techniques involve generating, manipul