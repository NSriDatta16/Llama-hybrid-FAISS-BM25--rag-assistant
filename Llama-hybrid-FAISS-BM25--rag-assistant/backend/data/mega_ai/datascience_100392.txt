[site]: datascience
[post_id]: 100392
[parent_id]: 
[tags]: 
Why are words represented by frequency counts before embedding?

Before getting vector representations of words by embedding, the words are mapped to numbers. These numbers are chosen to be the frequency of that word in the dataset. Why does this convention exist? Does it have any effects, or is it arbitrary?
