[site]: datascience
[post_id]: 83952
[parent_id]: 82810
[tags]: 
There are three methods I can think of, two of them are dependent on the method you use: If a linear model is used - the linear regression theory provides estimates for the uncertainty of the predictions. If a random forest or bagging algorithm is used - we can provide an estimate of the uncertainty of the prediction by taking all the trees predictions and aggregating them using the standard deviation. There's also a method to estimate errors that doesn't depend on the algorithm that is used. The idea is to train a regular model to predict the average outcome. After this model is fit, you apply the model on a new validation set, and compute the absolute errors that the model is making. After that, you use another model to predict these absolute errors. Using this second model allows you to give uncertainty estimates - if the prediction made by this second model is low, the uncertainty will be low, otherwise the uncertainty will be high. And, of course, a Bayesian framework can be used, which is the natural language to model uncertainty in the first place.
