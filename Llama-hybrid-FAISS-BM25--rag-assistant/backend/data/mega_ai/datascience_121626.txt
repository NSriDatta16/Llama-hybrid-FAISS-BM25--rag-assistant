[site]: datascience
[post_id]: 121626
[parent_id]: 85096
[tags]: 
Shortly said, they differ in the value function they optimize: Q-learning estimates the optimal action-value function (Q-function) and directly learns the values associated with state-action pairs. G-learning estimates the optimal value function (V-function) and focuses on learning the values associated with states. These reinforcement learning algorithms are comparable in that they try to find an optimal policy by optimising their value functions. Q-Learning is used when you have a discrete action space. This is why it includes the actions in its value function. G-Learning is more suitable for continuous action spaces.
