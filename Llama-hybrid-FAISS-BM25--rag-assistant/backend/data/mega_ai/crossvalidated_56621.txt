[site]: crossvalidated
[post_id]: 56621
[parent_id]: 56590
[tags]: 
Logistic regression is linear when the parameter, $\pi$, that controls the behavior of the Bernoulli response is transformed into a log odds: $$ \ln\left(\frac{\pi_i}{1-\pi_i}\right) = \beta_0 + \beta_1x_i $$ Your variable PASS is a vector of predicted probabilities. These can be converted into log odds using the LHS of the equation above. Once there, these should form a straight line as a function of RIT . Here is some R code to do this: oPASS = PASS / (1-PASS) loPASS = log(oPASS) A plot of these values shows that there was some rounding in the predicted probabilities that you were given: You can also see the issue if you look at the loPASS variable: > loPASS [1] -Inf -Inf -Inf -4.5951199 -4.5951199 -4.5951199 [7] -3.8918203 -3.1780538 -2.7515353 -2.1972246 -1.7346011 -1.2083112 [13] -0.7081851 -0.2006707 0.2818512 0.8001193 1.3249254 1.8152900 [19] 2.3136349 2.7515353 3.1780538 3.8918203 4.5951199 4.5951199 [25] Inf Inf Inf Inf Inf Inf [31] Inf Inf Inf Inf Inf Inf [37] Inf Thus, we will work with the 7th & 23rd data points to get a reasonably accurate result. Once we have these values, we can calculate the slope using the point-slope formula , and the intercept, by algebraically rearranging the equation of the line: b1 = (loPASS[23]-loPASS[7]) / (RIT[23]-RIT[7]) b0 = loPASS[7] - b1*RIT[7] That yields the parameter estimates that had been used to generate the predicted probabilities that you were given: > b0 [1] -19.80483 > b1 [1] 0.1060868 For more information about logistic regression, it may help you to read my answer here: difference-between-logit-and-probit-models .
