[site]: datascience
[post_id]: 94521
[parent_id]: 94519
[tags]: 
I don't know if I understood correctly the question, but basically, epochs are the unit of measure of the time spent on training the machine learning models. An epoch is conventionally considered as a full pass on the dataset, meaning that for each epoch , you feed the data to the model from the beginning to the end of the dataset. Once an epoch is complete, you can start again another epoch training your model from the beginning of the dataset to the end, and so on and so forth. The convergence of the performance of the models is of course dependant on the epochs, because usually what happens is that the more epochs you train your model, the less noisy (more stable) will be the predictions. Hope I answered your question.
