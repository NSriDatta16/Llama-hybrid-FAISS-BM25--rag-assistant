[site]: crossvalidated
[post_id]: 80108
[parent_id]: 
[tags]: 
Machine Learning on scarce data - how to tackle this task?

We are making algorithm for prediction of Conversion Rate (CR) for CPC advertising. We have historical (statistical) data that we can analyze in many projections (in many factors). For example we have such independent variables (factors, projections) as: keyword date source landing page among others. Then, when we unite them in the table, many combinations have too few clicks (statistical base). The table looks like this: keywords - date - source - landing page - number of clicks - transactions - conversion rate buy socks - 12.05.2013 - google - buysocks.com - **100** - 1 - 1% buy red socks - 12.05.2013 - google - buysocks.com/red - **10** - 0 - 0% buy red socks now - 12.05.2013 - google - buysocks.com/redsocknow - **1** - 0 - 100% The problem is that we have combinations of factors that lead to too few clicks, meaning that statistically the information is almost useless. Could you give us advice, how to deal with this kind of task? We thought of: Aggregation (grouping) of factors (for example we can unite all the long-tail keywords with less than 100 clicks in group "other keywords"). Though after grouping of factors, we still are left with combinations with few clicks. Initially, not to drill in too many factors (projections). Elimination - we can just delete the combinations with low data. Do nothing - just find algorithm that can can deal with low-statistical data. Somehow use probability coefficients that will adjust the data.
