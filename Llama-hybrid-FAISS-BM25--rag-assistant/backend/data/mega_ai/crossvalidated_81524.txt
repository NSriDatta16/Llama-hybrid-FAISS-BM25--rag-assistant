[site]: crossvalidated
[post_id]: 81524
[parent_id]: 55302
[tags]: 
I would be surprised if you did see improvement when you had 30% 'rare' data in the training set. 30% isn't really all that rare in the context of machine learning. What you could do is cross validate with various levels of synthetic data to determine what's giving you the best accuracy on your hold-out data (pretty standard approach to parameter tuning) and then go with that for your final model build. But I would be very surprised based upon personal experience if you saw significant gains in accuracy when you SMOTE past 20-25% positive class instances in your training set.
