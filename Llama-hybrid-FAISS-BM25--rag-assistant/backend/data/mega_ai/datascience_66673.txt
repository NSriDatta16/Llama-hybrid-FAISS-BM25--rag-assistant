[site]: datascience
[post_id]: 66673
[parent_id]: 
[tags]: 
Scipy.optimize getting back x0 for optimization of input to recurrent neural network

I need help with this optimization problem which is either not getting solved at all or is taking a copious amount of time. I am trying to find optimized input to an RNN (GRU) model of a process plant, which will minimize the difference between the output and desired output. I am using obj = (model_output(x) - desired_output(x))**2 If I use 1) sol = minimize(objective,x0, method = 'SLSQP', bounds = bnds, options = {'disp' : True}) It just gives back x0 2) sol = differential_evolution(objective,bnds) is taking extremely large amount of time (Several minutes for 1 x. If I use it iteratively, it takes several hours) P.S. I mentioned recursively since x is an input over 20 timesteps, then I need to move from 1:20 indices to 2:21 and so on till 381:400 timesteps for my problem. So I am running this operation recursively using for loop. Also bounds are simple bounds to input like x should be between (60,80).
