[site]: datascience
[post_id]: 47700
[parent_id]: 47449
[tags]: 
"Experience replay" lets agents remember and reuse experiences from the past. Experience replay bundles previous experiences (state and action pairs) which allows training on sparse rewards. Experience replay stores the agent's experiences in a buffer. Then train the agent against the entire contents of the buffer. If state and action pairs in the buffer yield a reward, they are reinforced. If state and action pairs in the buffer did not yield a reward, they are not reinforced. The training signal at the end of the buffer is called "experience transitions". It is typically uniformly sampled. However, important experiences can be also prioritized . " A Deeper Look at Experience Replay " paper goes into greater detail about the technique.
