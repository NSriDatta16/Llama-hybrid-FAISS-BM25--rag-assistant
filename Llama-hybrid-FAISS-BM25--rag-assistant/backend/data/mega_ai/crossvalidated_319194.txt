[site]: crossvalidated
[post_id]: 319194
[parent_id]: 319190
[tags]: 
Let's leave aside the concept of ergodicity itself, which is rather deep, abstract and difficult, and use its consequences: when a stochastic process $\{X_i\}$ is ergodic, the "time" average (the average across the index, which often represents time, but this is not necessary) converges in probability to the ensemble average. Ergodicity comes in levels: a process may be "ergodic for the mean", but not for the variance, etc. A way to think about this is as a generalization of the Law of Large Numbers. LLN theorems have assumptions that make the sequences of random variables under examination ergodic (and here, the index does not necessarily represent time). In most cases, "wide-sense" stationary processes over time (or more accurately "covariance-stationary" processes) are also ergodic, and so averaging over the available time-series observations provides a consistent estimator for the common mean (and then of the variance and of the covariance). But this is not always the case. The author the OP mentions provides an example were we have stationarity but not ergodicity for the autocovariance, which implies that that the sample autocovariance in this case is not a consistent estimator of the true autocovariance. I would suggest to look up Hamilton's Time Series Analysis , p. 46-47 for a discussion and another such example, and ch. 7 for some sufficient conditions that ensure that a stationary process is also ergodic.
