[site]: crossvalidated
[post_id]: 235114
[parent_id]: 
[tags]: 
Parameters tuning for auto-encoders

Currently I am using auto-encoders for some classification task. And I am using Matlab (Code) . It seems to me that there are many parameters need to be tuned during training. For example, Maximum number of training epochs or iterations. The coefficient for the L2 weight regularizer in the cost function. Coefficient that controls the impact of the sparsity regularizer. Desired proportion of training examples a neuron reacts to (i.e., sparsity proportion). Actually, the cost function of a sparse auto-encoder is like I tested with my datasets, it seems that all these four parameters have impact on the final results. Are there any general rules of 'optimal' settings of these four parameters? When I was using Support Vector Machine based classifier, there is a 'grid search' method to optimize the two hyper-parameters of the SVM. Are there any similar method available for (sparse) auto-encoders? As far as I see, grid search is feasible to optimize two parameters, but may not work for tuning four parameters. Am I right? Any thoughts of these please share. Thanks a lot. A.
