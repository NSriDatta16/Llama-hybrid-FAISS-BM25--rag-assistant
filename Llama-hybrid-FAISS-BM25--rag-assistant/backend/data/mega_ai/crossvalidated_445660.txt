[site]: crossvalidated
[post_id]: 445660
[parent_id]: 445633
[tags]: 
With any time series model - not just SARIMA - the longer the forecast, the harder it might prove for the time series model to predict accurately. The challenge with time series modelling is to capture all relevant seasonality trends and repeating patterns. This is why using 10 years of weather data to predict that of next year is feasible - whereas using only 1 year of training data might lead to issues. As an example, here is a graph of the maximum recorded air temperature in Dublin, Ireland over an extended period of time. Decomposing the series reveals an upward trend along with clear seasonality patterns: When a SARIMA model was used to forecast the test data (185 periods forward) - over 70% of the forecasts deviated from the actual by less than 10 percent: >>> print(results.summary()) Statespace Model Results ========================================================================================== Dep. Variable: maxtp No. Observations: 740 Model: SARIMAX(1, 0, 0)x(2, 1, 0, 12) Log Likelihood 468.218 Date: Thu, 14 Mar 2019 AIC -926.436 Time: 16:54:47 BIC -903.485 Sample: 12-01-1941 HQIC -917.580 - 07-01-2003 Covariance Type: opg ============================================================================== coef std err z P>|z| [0.025 0.975] ------------------------------------------------------------------------------ intercept 0.0006 0.005 0.126 0.900 -0.009 0.011 ar.L1 0.1728 0.032 5.469 0.000 0.111 0.235 ar.S.L12 -0.6074 0.023 -26.858 0.000 -0.652 -0.563 ar.S.L24 -0.3256 0.023 -14.108 0.000 -0.371 -0.280 sigma2 0.0161 0.000 39.691 0.000 0.015 0.017 =================================================================================== Ljung-Box (Q): 129.08 Jarque-Bera (JB): 2081.35 Prob(Q): 0.00 Prob(JB): 0.00 Heteroskedasticity (H): 0.76 Skew: -0.97 Prob(H) (two-sided): 0.04 Kurtosis: 11.05 =================================================================================== Warnings: [1] Covariance matrix calculated using the outer product of gradients (complex-step). >>> predictions=results.predict(741, 925, typ='levels') >>> predictions=np.exp(predictions) >>> test=np.exp(test) >>> mse=(predictions-test)/test >>> mse=abs(mse) >>> below10=mse[mse >> all=mse.count() >>> accuracy=below10/all >>> accuracy 0.7081081081081081 Therefore, forecasting 140 data points may well be feasible, but ideally your training data would be significantly greater than 140 data points. Depending on the type of data under analysis, too few data points in the training set risks that the model will not adequately capture the appropriate trend and fluctuations influenced by seasonality.
