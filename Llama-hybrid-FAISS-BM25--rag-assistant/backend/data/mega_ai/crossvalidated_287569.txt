[site]: crossvalidated
[post_id]: 287569
[parent_id]: 
[tags]: 
Do I need a test set when using time series cross-validation?

I'm working with time series data (Forex data) using a random forest. When training the model using the caret package in R I have few options. One of the options is to use e.g. 10-fold cross validation but I'm not 100% sure that it's a good idea for time series. I could also use time series cross validation ( timeslice in the caret package). What I don't understand is the need for independent test set when using time series cross validation to get an estimate of the prediction error. As this figure shows (figure by Rob J Hyndman: https://robjhyndman.com/hyndsight/tscv/ ) during the training you've never used the validation set (red dots) when training the model, the validation set is always a new unseen data. Unlike 10-fold cross validation where 9 out of 10 times you have seen the data during the training so the prediction error is underestimated. So my questing is, isn't the training error a perfect estimate of the testing error when using time series cross validation as the figure above shows ? If I understand correctly the chapter 2.5 in "Forecasting: Principles and Practice" then I do not need an independent test set but I'm not 100% sure my understanding is correct.
