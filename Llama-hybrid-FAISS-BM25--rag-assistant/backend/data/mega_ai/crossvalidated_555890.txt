[site]: crossvalidated
[post_id]: 555890
[parent_id]: 
[tags]: 
What can and can’t you say about a series with a unit root as evidenced by an ADF test?

I have a time series with 500+ observations which has a unit root, as evidenced by an ADF test at the sub 1% significance level. I want to explain to my class mates why that’s important and change the way they think about the particular series (it’s an interest rate). Can I say the series follows a random walk process? I ask because the first differences of the series do not have a unit root (ADF) but also appear to not have constant variance, and definitely have a 40% autocorrelation at lag 3. Doesn’t that go against the idea that first differences in a random walk are white noise (mean = 0, constant variance)? Can I say “the best prediction of a future value is the past value?” Related to the above… I’ve heard some people say a unit root does not always mean we have a random walk. I ran lagged correlations between this series and another series I first differenced. I’m struggling to tell them why exactly it’s better to think of the relationship between the two in first differences and not just in levels. Any guidance here would be appreciated.
