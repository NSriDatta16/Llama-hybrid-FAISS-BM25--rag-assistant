[site]: crossvalidated
[post_id]: 184331
[parent_id]: 183536
[tags]: 
I'm assuming your derivation there comes from something like the one on this page . I have a distribution with only positive outcomes, and the confidence intervals include negative values. Well, given the normal approximation that makes sense. There is nothing stopping a normal approximation from giving you negative values, which is why it is a bad approximation for a bounded value when the sample size is small and/or the variance is large. If you crank up the sample size, then the intervals will shrink because the sample size is in the denominator of the expression for the width of the interval. The variance enters the problem through the density: for the same mean, a higher variance will have a different density, higher at the margins and lower near the center. A lower density means a wider confidence interval because the density is in the denominator of the expression. How the effects of changing sample size and variance together affect the width of the confidence interval and the quality of the approximation will depend on the distribution generating the data as well as the particular quantile. A bit of googling found this page , among others, which uses the normal approximation to the binomial distribution to construct the confidence limits. The basic idea is that each observation falls below the quantile with probability q , so that the distribution is binomial. When the sample size is sufficiently large (that's important), the binomial distribution is well approximated by a normal distribution with mean $nq$ and variance $nq(1-q)$. So the lower confidence limit will have index $j = nq - 1.96 \sqrt{nq(1-q)}$, and the upper confidence limit will have index $k = nq - 1.96 \sqrt{nq(1-q)}$. There's a possibility that either $k > n$ or $j In the following re-write of your code I constructed the confidence limit on the empirical data and tested to see if the theoretical quantile falls inside of that. That makes more sense to me, because the quantile of the observed data set is the random variable. The coverage for n > 1000 is ~ 0.95. For n = 100 it is worse at 0.85, but that's to be expected for quantiles near the tails with small sample sizes. #find 0.975 quantile q n) u = n if (l =d[l] & q_norm As far as determining what sample size is "big enough", well, bigger is better. Whether any particular sample is "big enough" depends strongly on the problem at hand, and how fussy you are about things like the coverage of your confidence limits.
