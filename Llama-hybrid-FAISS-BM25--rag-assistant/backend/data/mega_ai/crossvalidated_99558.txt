[site]: crossvalidated
[post_id]: 99558
[parent_id]: 
[tags]: 
Evaluating correlation with multiple human annotators

Assume we have 3 annotators, each one of which has assessed the quality of 3 products in a scale from 1 to 7. ANN PRODUCT SCORE an1 pr1 5 an1 pr2 2 an1 pr3 3 an2 pr1 7 an2 pr2 1 an2 pr3 2 an3 pr1 3 an3 pr2 3 an3 pr3 4 We also have a computer model that makes predictions for the same products using a number of features. pr1 0.70 pr2 0.25 pr3 0.35 There are two ways to calculate the correlation of model's scores with human scores. First average the human scores, and then get the correlation with model's scores PRODUCT ANN.SCORE MODEL SCORE pr1 (5+7+3)/3 0.70 pr2 (2+1+3)/3 0.25 pr3 (3+2+4)/3 0.35 Repeat the model's score for every annotator and product, as follows: ANN PRODUCT ANN.SCORE MODEL SCORE an1 pr1 5 0.70 an1 pr2 2 0.25 an1 pr3 3 0.35 an2 pr1 7 0.70 an2 pr2 1 0.25 an2 pr3 2 0.35 an3 pr1 3 0.70 an3 pr2 3 0.25 an3 pr3 4 0.35 and then get the correlation. My question is, which method makes more sense from a statistical point of view? What are the actual differences between the two ways of measuring the correlation?
