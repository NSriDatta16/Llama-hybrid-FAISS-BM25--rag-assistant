[site]: datascience
[post_id]: 107227
[parent_id]: 
[tags]: 
Proving Catastrophic Forgetting in Traditional Machine Learning Models

Catastrophic Forgetting is the phenomenon when Machine Learning Model forgets previously learned information upon learning new information. I am very clear about the definition of Continual / Lifelong Learning which is one of the methods to alleviate Catastrophic Forgetting and Three Scenarios of it. In every paper, I searched for proof of how the models are evaluated in a sequence of tasks (At test time which tasks examples are being provided and how exactly they test), the authors describe that Neural Nets / Traditional ML models such as RandomForests, Decision Trees are prone to forgetting, i.e, when they are trained on a sequence of tasks (The data is only available per task), they only perform better on the most recent task forgetting the previous tasks. But how exactly the traditional ML models can be trained without having the whole data at once? In the case of Neural Networks, we can say that the weights will serve as initialization and the final layer will always be modified while learning new tasks (As the number of classes is increasing). But how to test the Catastrophic Forgetting Scenario in Traditional Methods such as Decision Trees or SVMs without training on Whole the data? Won't the traditional ML models completely Forget the previous tasks they are trained for? For example, let there are two tasks and in each task, we are training a binary classifier. be {1,2}, {3,4}. In traditional Methods won't the classifier completely Forget {1,2} classes when we sequentially train on the first and second tasks as we can't just do something like changing the last layer as in the Neural Network case. Is the way I'm thinking right? If not how do we justify Catastrophic Forgetting in Traditional ML models?
