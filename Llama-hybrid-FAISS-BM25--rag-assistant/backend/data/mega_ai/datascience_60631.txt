[site]: datascience
[post_id]: 60631
[parent_id]: 
[tags]: 
Tree based method are robust against low probability feature space zones when using ML general interpretability methods?

I have this intuition but I'm not able to verify it. There are a lot of techniques to understand the effect of single features in ML models. Some take inspiration from counterfactual frameworks, like ceteris paribus, and evaluate the unconditional contribution of feature $X$ by observing the change in prediction when varying $X$ values leaving all other variables fixed. The most common of such techniques are PDPs https://christophm.github.io/interpretable-ml-book/pdp.html . The problem is that this methodology are not robust for impossible combinations of the predictors. For example in a model to predict bike-sharing count given weather conditions and period of the year, it's possible to make predictions for a temperature of 40Â°C in wintertime, even if there's no such data point in the training set. There are various techniques to accommodate for this bias, like accumulated local estimation plots (ALE). I was wondering though if tree-based methods (simple or ensemble) are naturally more robust than regression-based ones to such bias; I expect this, because tree-based predictions vary only among partitions of the feature space that are present in the data, while regressions allow prediction variation for never observed predictors combinations. For example, this is the output of a conditional tree trained on the bikes problem: [1] root | [2] temp 4: 2852 (n = 133, err = 216353574) | | [6] season in WINTER | | | [7] hum 82.3: 2781 (n = 9, err = 26537744) | [9] temp > 12.2 | | [10] hum 13.2: 5285 (n = 149, err = 326330122) | | [13] hum > 84.8: 3382 (n = 30, err = 47251364) as expected, the temperature and the seasons are correlated, therefore we won't find rules regarding winter for higher (>12.2) temperatures. So I expect that forcing Winter with a temperature of 14 won't produce a different prediction than Summer. I expect also that this robustness would replicate also for more complex blackbox models like random forests and boosted trees. Instead, regression-based methods will allow impossible predictions as shown by the following linear model, where the effect of temperature is unbounded. (Intercept) temp seasonWINTER hum windspeed seasonSUMMER holidayHOLIDAY 4888.4 152.1 1307.1 -37.6 -64.0 673.2 -621.4 Can someone confirm/dispute this, preferably with a theory-based explanation?
