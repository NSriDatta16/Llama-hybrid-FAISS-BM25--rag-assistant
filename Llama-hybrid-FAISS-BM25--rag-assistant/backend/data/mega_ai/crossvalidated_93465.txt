[site]: crossvalidated
[post_id]: 93465
[parent_id]: 93461
[tags]: 
I doubt there are strict, formal definitions that a wide range of data analysts agree on. In general however, time series connotes a single study unit observed at regular intervals over a very long period of time. A prototypical example would be the annual GDP growth of a country over decades or even more than a hundred years. For an analyst working for a private company, it might be monthly sales revenues over the life of the company. Because there are so many observations, the data are analyzed in great detail, looking for things like seasonality over different periods (e.g., monthly: more sales at the beginning of a month just after people have been paid; yearly: more sales in November and December, when people are shopping for the Christmas season), and possibly regime shifts. Forecasting is often very important, as @StephanKolassa notes. Longitudinal typically refers to fewer measurements over a larger number of study units. A prototypical example might be a drug trial, where there are hundreds of patients measured at baseline (before treatment), and monthly for the next 3 months. With just 4 observations of each unit in this example, it is not possible to try to detect the kinds of features time series analysts are interested in. On the other hand, with patients presumably randomized into treatment and control arms, causality can be inferred once the non-independence has been addressed. As that suggests, often the non-independence is considered almost a nuisance, rather than the primary feature of interest.
