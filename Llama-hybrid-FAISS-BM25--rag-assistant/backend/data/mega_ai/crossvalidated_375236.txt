[site]: crossvalidated
[post_id]: 375236
[parent_id]: 375228
[tags]: 
For all $0 \leqslant x \leqslant 1$ the logarithm of the sampling density is: $$\ln f(x|\theta) = \begin{cases} 0 & & \text{for } \theta=0, \\[6pt] -\ln 2 - \tfrac{1}{2} \ln x & & \text{for } \theta=1. \\[6pt] \end{cases}$$ So you have the log-likelihood function: $$\ell_\mathbf{x}(\theta) = \begin{cases} 0 & & \text{for } \theta=0, \\[6pt] -n \ln 2 - \tfrac{1}{2} \sum \ln x_i & & \text{for } \theta=1. \\[6pt] \end{cases}$$ This is a binary function (only two possible inputs) and so you maximise it by comparing the outputs for those two inputs. (There is no differentiation involved.) Define $T(\mathbf{x}) \equiv \tfrac{1}{n} \sum |\ln x_i|$ , which is the average absolute logarithm of the data (this is a sufficient statistic). Maximising this function yields the MLE: $$\begin{equation} \begin{aligned} \hat{\theta}(\mathbf{x}) &= \mathbb{I} \Big( \ell_\mathbf{x}(1) > \ell_\mathbf{x}(0) \Big) \\[6pt] &= \mathbb{I} \Big( -n \ln 2 - \tfrac{1}{2} \sum \ln x_i > 0 \Big) \\[6pt] &= \mathbb{I} \Big( - \tfrac{1}{2} \sum \ln x_i > n \ln 2 \Big) \\[6pt] &= \mathbb{I} \Big( \tfrac{1}{n} \sum |\ln x_i| > 2 \ln 2 \Big) \\[6pt] &= \mathbb{I} ( T(\mathbf{x}) > 2 \ln 2 ). \\[6pt] \end{aligned} \end{equation}$$ (Note that the MLE is not uniquely determined for the case where $T(\mathbf{x}) = 2 \ln 2$ . In this case either parameter value gives the same log-likelihood value. This means that you can use non-strict inequality in the above MLE formula and this still gives a valid MLE.)
