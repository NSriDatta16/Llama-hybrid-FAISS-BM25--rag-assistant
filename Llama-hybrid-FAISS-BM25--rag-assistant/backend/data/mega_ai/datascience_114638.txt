[site]: datascience
[post_id]: 114638
[parent_id]: 
[tags]: 
Proof that averaging weights is equal to averaging gradients (FedSGD vs FedAvg)

The first paper of Federated Learning "Communication-Efficient Learning of Deep Networks from Decentralized Data" presents FedSGD and FedAvg. In Federated Learning the learning task is solved by a federation of participating devices (which we refer to as clients) which are coordinated by a central server. Each client has a local training dataset which is never uploaded to the server. Instead, each client computes an update to the current global model maintained by the server, and only this update is communicated. Now, the authors present 2 algorithms, FedSGD and FedAvg. Basically, in FedSGD after 1 epoch of training we average the gradients, while in FedAvg we average the weights after 1 or more epoch of training. They say that FedSGD=FedAvg when we train for 1 epoch, so basically averaging weights is equal to averaging gradients. Can you explain me why?
