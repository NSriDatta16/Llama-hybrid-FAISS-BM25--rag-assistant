[site]: crossvalidated
[post_id]: 257049
[parent_id]: 
[tags]: 
Monotone machine learning

I have a binary classification (supervised learning) problem, where all my features are boolean, with the following twist: I want to learn a classifier $f:\{0,1\}^n \to \{0,1\}$ that is monotone . In other words, changing any subset of features from 0 to 1 should never change the output of the classifier from 1 to 0. How can I learn a monotone classifier? Can I adapt standard classification methods somehow, to enforce the monotonicity constraint? I can see how to adapt logistic regression in a way that ensures it will learn a monotonic model: we can require that each feature's coefficient be non-negative, and then apply a constrained optimization algorithm to infer the coefficients of the model. Is there a reasonable way to adapt other supervised learning schemes (e.g., random forests, gradient boosting, neural networks)? Or are there dedicated algorithms that are appropriate for this situation? Unfortunately just applying a standard random forests classifier is not guaranteed to yield a monotone classifier, even if the training set is monotone (it comes from a monotone setting, and has no noise or violations of monotonicity). See https://cs.stackexchange.com/q/69220/755 for an explicit example, i.e., an example of a monotone training set, where random forests might learn a non-monotone classifier -- even though there exists a monotone classifier that is equally good. This suggests that we might need some more sophisticated technique if we want to learn a monotone classifier.
