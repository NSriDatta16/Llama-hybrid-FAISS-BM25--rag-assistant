[site]: datascience
[post_id]: 42706
[parent_id]: 
[tags]: 
Defining Input Shape for Time Series using LSTM in Keras

I have been trying to model Time Series forecast using Keras LSTM algorithm. My dataset consists of weekly sales data from Jan-2016 and I also have external features such as Festivals/Events each modeled as a flag (0/1) for each week. So for e.g. let's say 2016W01 has sales of 100 units and has flag value 1 for the NewYearFlag. Likewise, I have created flags for many such events such as Independence Day, Diwali (this is in a different week every year) and so on. Based on the Time Series decomposition analysis,I also know that 5 week lags are signficant. So it is Week-1, Week-2, Week-3,Week-4 and Week-5 variables. Essentially,my dataframe row looks like Week Number (Row Index), SalesQty, SalesQtyW-1,SalesQtyW-2, SalesQtyW-3,SalesQtyW-4,SalesQtyW-5,NewYearFlag,DiwaliFlag, IndepdenceDayFlag, ChristmasFlag. So I have X = {SalesQtyW-1,SalesQtyW-2, SalesQtyW-3,SalesQtyW-4,SalesQtyW-5,NewYearFlag,DiwaliFlag, IndepdenceDayFlag, ChristmasFlag} Y = {SalesQty} So when I pass my dataframe to Keras LSTM layer, I pass (144,9) as there 144 rows (52+52+40) in my training data. I always get the error - Expected 3 dimensions but got only two (144,9) I am not sure where I am going wrong. Please help. I checked most of the questions of similar nature but not able to find the right answer. Dont know where am I going wrong!!!
