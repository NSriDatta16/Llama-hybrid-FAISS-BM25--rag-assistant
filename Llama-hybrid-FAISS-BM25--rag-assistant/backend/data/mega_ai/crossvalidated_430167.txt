[site]: crossvalidated
[post_id]: 430167
[parent_id]: 430149
[tags]: 
You have chosen to seek a solution to one of the most technically complex Bayesian questions out there. I will give you two answers as I am not sure of one aspect of your problem. It is the phrase Now suppose I get evidence from elsewhere that $P(\theta = E>0) = .95$ . The reason is that my answer will depend strongly on whether you simply strongly believe that it is ninety-five percent, or if you are conditioning on it being ninety-five percent because you are sure of it $\Pr(\theta=.95)\equiv{1}$ . You are in the field of Bayesian nonparametrics. Let me restate your problem, before seeing the data; as if the simulated data had never been seen. You are about to observe data drawn from a function in nature whose structure is unknown to you. You believe(know) that $\Pr(E>0)=.95$ . To understand the difference, I am going to restate the problem in a non-applicable, but analogous parallel form. You are about to observe data drawn from a normal distribution. In case one of this problem, you are certain, with probability one, that ninety-five percent of the mass of the function will be greater than zero. In case two, you strongly believe that the mass of the density function will be very near to ninety-five percent. Since it is normal, the first case holds whenever $\mu=1.6449\sigma$ . As a result, you would only need to estimate one parameter instead of two. If you know one, then you know the other. In the other case, you could place a prior over $\mu$ and another factor $\alpha$ such that the center of $\alpha$ is $1.6449$ , but there is uncertainty. $\sigma$ is still a multiple of $\mu$ , but it is just very near to $1.6449\mu$ . The problem is that if you do not know the density, then you have an infinite number of choices. If it were the sum of two normal distributions, or a normal and another distribution, then the surface of the ball of joint parameters that would force five percent of the mass to the left would become complicated quickly. That leaves binning to make it discrete. If you were to condition on .95, then you would use a multinomial likelihood, but you would constrain the bins on the left such that they sum to .05. What you would get is a mass on each point of the ball. You would not need to constrain the right because normalization would force the right side to .95. The density and the priors would be on the ball, not on the individual parameters. You would need to create one bin for the data less than any observed and one bin for any to the right of the maximum value. There are several bin optimization procedures out there. If you relaxed the assumption that it must be .05 and .95, then you could do something simple. You could make it uniform to the right of zero with total prior mass of 0.95 and uniform up to and including zero with a total prior mass of .05. You could create a Dirichlet-Multinomial posterior and find the predictive density. That predictive density would be the final form of your histogram. Ultimately, how you solve it would depend in part on your resources and in part on how important the answer is.
