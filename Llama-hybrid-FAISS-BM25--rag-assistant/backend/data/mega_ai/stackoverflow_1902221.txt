[site]: stackoverflow
[post_id]: 1902221
[parent_id]: 1901953
[tags]: 
Two good hash functions can both be mapped into the same space of values, and will in general not cause any new problems as a result of combining them. So your hash function can look like this: if it's an integer value: return int_hash(integer value) return string_hash(string value) Unless there's any clumping of your integers around certain values modulo N, where N is a possible number of buckets, then int_hash can just return its input. Picking a string hash is not a novel problem. Try "djb2" ( http://www.cse.yorku.ca/~oz/hash.html ) or similar, unless you have obscene performance requirements. I don't think there's much point in modifying the hash function to take account of the common prefixes. If your hash function is good to start with, then it is unlikely that common prefixes will create any clumping of hash values. If you do this, and the hash doesn't unexpectedly perform badly, and you put your several million hash values into a few thousand buckets, then the bucket populations will be normally distributed, with mean (several million / a few thousand) and variance 1/12 (a few thousand)^2 With an average of 1500 entries per bucket, that makes the standard deviation somewhere around 430. 95% of a normal distribution lies within 2 standard deviations of the mean, so 95% of your buckets will contain 640-2360 entries, unless I've done my sums wrong. Is that adequate, or do you need the buckets to be of more closely similar sizes?
