[site]: crossvalidated
[post_id]: 404902
[parent_id]: 
[tags]: 
Does zero-one loss correspond to any maximum likelihood procedure?

Squared loss for linear regression corresponds to a MLE of a Gaussian model, and cross entropy loss corresponds to MLE of a logistic model with discrete probabilities. Can zero-one loss be justified by MLE of any probability model? Why or why not? That's the main question. This question also has to do with intuition for zero-one loss, but doesn't have anything to do with MLE. but also I'd like to state some things I believe are true about zero-one loss, and please correct me if I'm wrong: MAP is Bayes optimal for zero-one loss Logistic regression models probabilities directly, and classifies to the largest, but its parameters are optimized based on maximum likelihood (leading to cross-entropy) rather than optimizing zero-one loss directly The performance of logistic regression could be improved by using zero-one loss, or you could ditch logistic regression entirely and use frequency tables to approximate $P(\text{class} | X)$ , though both of these options are entirely intractable
