[site]: crossvalidated
[post_id]: 423968
[parent_id]: 
[tags]: 
High variation of AUC score when fitting a logistic regression model

I'm using sklearn LogisticRegression with a training data set of 279 inputs. Each input point belongs to $[0,1]^2$ and to a class. There are two classes: $\{0, 1\}$ . I evaluate AUC score with cross_val_score with below code snippet. aucs = [] num_runs, num_splits = 40, 5 for seed in range(num_runs): # Use logistic regression with L2 penalty estimator = LogisticRegression(penalty="l2", C=0.05, solver="liblinear") cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=seed) # Cross validation on the training set auc = cross_val_score(estimator, X=features_train, y=labels_train, cv=cv, scoring="roc_auc", verbose=0) aucs.append(auc) aucs = np.array(aucs) print(f"AUC: max {aucs.max()}, min {aucs.min()}, mean {aucs.mean()}, std {aucs.std()}") The issue I have is that AUC score has large variations depending on the training / validation split: AUC: max 0.9696969696969696, min 0.659846547314578, mean 0.8303383462619687, std 0.05924693385612475 The main questions I'm asking myself: Is the range of those variations "normal" considering the size of the training data set? Would regularization be a good topic for increasing AUC stability? Overall, is there a way to obtain a more stable model?
