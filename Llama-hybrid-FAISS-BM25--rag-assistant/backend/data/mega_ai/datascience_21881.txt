[site]: datascience
[post_id]: 21881
[parent_id]: 21870
[tags]: 
A shallow neural network is the wrong approach for a problem with a small training set. Deep learning is even worse for small training sets. 139 samples is severely insufficient to train any deep learning model, or even a shallow neural network. As a very general rule of thumb I use 100 examples for each feature in my dataset for deep learning. This then increases exponentially with every single different class you expect. I suggest you use a machine learning technique such as SVM. This will likely result in better results given the size of your dataset. Try these techniques instead and see what results you get: k-NN, kernel SVM, k-means clustering. If you have an unbalanced dataset then you would want to use anomaly detection algorithms which can be trained on a single distribution. You can learn the distribution of each output class you want. From there, novel examples can be classified based on the likelihood they fit within a given distribution.
