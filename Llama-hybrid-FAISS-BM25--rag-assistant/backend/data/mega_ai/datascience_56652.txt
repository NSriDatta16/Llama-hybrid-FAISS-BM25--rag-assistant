[site]: datascience
[post_id]: 56652
[parent_id]: 
[tags]: 
How can one determine that Word2Vec (CBOW method) embeddings are related to each other?

I read some fascinating stuff about the potential for using the Word2Vec algorithm to speed up the pace of scientific discovery here https://www.researchgate.net/publication/334209824_Unsupervised_word_embeddings_capture_latent_knowledge_from_materials_science_literature . In the paper, the researchers trained the algorithm on millions of materials science abstracts to identify potential associations that human researchers had missed. My question concerns using the Word2Vec in contexts that are more disparate than a single scientific field. The CBOW method takes in an input of words and returns a predicted word that would most likely be associated with it. So if I had trained the algorithm on economics papers, an input of externalities, public good, and tragedy of the commons might return a prediction of carbon pollution. However, had I trained on ecology papers and used the same input, I would not get the same output, and the input might well be meaningless due to the lack of those words in the training set. The question then becomes, how can one tell if the embedding of a word in one field, is similar to that in another field? The application I am imagining for this is the potential to solve problems in one field using thought processes and methodologies already developed in another field. Would words with similar vectors in different field automatically indicate a connection between them, at least in the structure of the words around them?
