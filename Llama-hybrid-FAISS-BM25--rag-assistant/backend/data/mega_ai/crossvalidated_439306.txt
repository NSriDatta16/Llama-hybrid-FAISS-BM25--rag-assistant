[site]: crossvalidated
[post_id]: 439306
[parent_id]: 439302
[tags]: 
If the data were truly missing completely at random (MCAR) and the percentage is that low, you might be best off to just analyze the complete data. However, unless you randomly introduced the missingness yourself, you cannot know that the data are MCAR. You can tell MAR vs. MCAR (basically, is there anything in the data that predicts missingness), but you cannot ever know for sure (unless perhaps if you deeply understand exactly why the data are missing and exactly why it happened) whether the data are not perhaps MNAR. There is purely statistically no possibility of testing MNAR vs. MAR/MCAR. An appropriate multiple imputation would have you covered under both MCAR and MAR, but exactly how you should do it really depends on the type of data. MICE can make sense for a sequence of assessments/measurements/obvervations, but can have trouble (at least I've seen that in a few applications) fully reflecting the full dependence structure over time (or whatever dimension you are "chaining" over). A single joint imputation for everything can in some cases work really nicely (and e.g. the software Amelia for which there are packages in many programming languages like R covers a reasonable range of possible data types). However, you may also run into situations where there is no good off-the-shelf imputation method available (then you can either try to find the best way of making things fit into an existing one, or can e.g. consider writing something like a Bayesian model for the data that allows for imputation).
