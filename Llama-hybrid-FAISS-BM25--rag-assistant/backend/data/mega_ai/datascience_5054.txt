[site]: datascience
[post_id]: 5054
[parent_id]: 5050
[tags]: 
There are many algorithm to do classification: Naïve Bayes, logistic regression, SVM, decision tree..etc. My suggestion is to try Naïve Bayes first by calculating below probabilities which a new document belongs to $class_{good}$ or $class_{bad}$. ( https://web.stanford.edu/class/cs124/lec/naivebayes.pdf ) $$ P(Class_{good} \vert document_{new}) = \frac{P(document_{new} \vert Class_{good}) \cdot P(Class_{good}) }{P(document_{new})} $$ $$ P(Class_{bad} \vert document_{new}) = \frac{P(document_{new} \vert Class_{bad}) \cdot P(Class_{bad}) }{P(document_{new})} $$ And generally, when we are doing text mining questions, we will do several preprocess on one document: Tokenization(1-gram/bigram/...etc) remove stop words ('a', 'the' 'at', ... etc) Stemming: transforms a word into its root form. (studied => study) My suggestion is to do above preprocesses and try more features not just the words in one document, if there are some metadataes.
