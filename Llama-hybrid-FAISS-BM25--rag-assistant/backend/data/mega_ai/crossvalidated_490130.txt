[site]: crossvalidated
[post_id]: 490130
[parent_id]: 
[tags]: 
Computing similarity between a series of two datasets' Principal Components

I have implemented a framework where two data matrices (with same rows or data points, but different columns or features) are compared by the Pearson correlation of their first principal components (PCs). In this way, I am attempting to measure the similarity of the data sitting on each matrix. This approach so far worked well, but I would like to include few other PCs, while calculating the similarity (or distance). As a first step, I had concatenated first three PCs to obtain a single vector for each matrix and then compare these vectors with Pearson correlation. However, I am after a more structured way of doing that. Possible solutions might be: After comparing individual PCs, combining this information (e.g. averaging) to get a better estimate. Using a multivariate correlation/similarity measure. Of course, I am open to other approaches, too! I will very glad if you can steer me into any technique that is mathematically justified.
