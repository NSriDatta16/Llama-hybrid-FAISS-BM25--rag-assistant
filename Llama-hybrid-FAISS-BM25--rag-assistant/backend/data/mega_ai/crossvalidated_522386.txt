[site]: crossvalidated
[post_id]: 522386
[parent_id]: 
[tags]: 
Does the convergence of algorithms in machine learning to train set make sense?

Think of the hypothetical situation where we have a y reponse and a scalar input x, we want a function that maps x to y perfectly at least in the training set. This does not make sense, it is just imagining a situation where there are two instances with the same value of x but different responses, it is mathematically impossible to propose a function that correctly predicts these two instances. In view of this problem, why are convergence criteria used in some ML algorithms such as neural networks?
