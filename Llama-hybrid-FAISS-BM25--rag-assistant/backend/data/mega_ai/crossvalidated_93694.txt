[site]: crossvalidated
[post_id]: 93694
[parent_id]: 92752
[tags]: 
I'm glad you mentioned this example, as one project I am working on is writing a whole chapter on Bayesian A/B testing. We are interested in two quantities: $P( p_A > p_B \;|\; data)$ and some measure of "increase". I'll discuss the $P( p_A > p_B \;|\; data)$ quantity first. There are no error bounds on $P( p_A > p_B \;|\; \text{data})$, it is a true quantity. This is similar to saying "What is the mean of the posterior?", there is only 1 mean, and we can compute it by taking the average of all the samples (I'm ignoring any Monte Carlo errors, as they can be reduced to insignificance by sampling more). I think you are mixing up unknown quantities, where we can say something like "+- 3%", and posterior-computed quantities. What I am saying is that $P(p_A > p_B \;|\; \text{data}) = 0.95$ is certain: given your observed data and priors, this is your conclusion. Note that we will know $p_A > p_B$ quickly: it requires only moderate amounts of observations for different enough $p_A$ and $p_B$. It is much harder, and more interesting, to measure what increase A has over B (and often this is the goal of an A/B test: how much are we increasing conversions). You mentioned that $\frac{p_A - p_B}{p_B} >$ 5% -- how certain are you of this? Note that while $p_A > p_B$ is a boolean, and hence easy to measure,$\frac{p_A - p_B}{p_B}$ is certainly not a boolean. It is a distribution of possibilities: As more and more data is acquired, this distribution converges to the actual relative increase, one can say the distribution stabilizes. This is where I suggest thinking about terminating the experiment. Once this distribution seems to "calm down", and we can feel confident about the increase, then terminate the experiment.
