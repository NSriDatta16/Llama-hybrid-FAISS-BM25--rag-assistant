[site]: crossvalidated
[post_id]: 7320
[parent_id]: 5430
[tags]: 
You could simply smooth the data and find the peaks. Since there are presumably several pertinent, distinct (larger) objects amongst many irrelevant, indistinct (smaller) objects providing the noisy distance environment, you could probably assume that the distance distribution of pertinent objects is likely to be uniform, no? If you can't rely on any particular distance distribution for pertinent objects, then fitting distribution functions won't help at all. Thus you're left with identifying real peaks amongst false peaks. A low-pass filter can help with that - even as simple as a moving average filter. You could tune the filter using the likely range of distances of each pertinent object (e.g. a non-uniform object of about 2 metres in size might give peaks that vary within a 2m range). There may also be further machine learning approaches(?)
