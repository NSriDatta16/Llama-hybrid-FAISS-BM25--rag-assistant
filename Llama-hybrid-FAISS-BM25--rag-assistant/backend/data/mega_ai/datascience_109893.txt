[site]: datascience
[post_id]: 109893
[parent_id]: 
[tags]: 
Time Series Forecast using LSTM and Neural Network

I am doing a univariate time series forecast using Keras. The first Image shows forecasts using a neural network and the second image shows forecasts using an LSTM model. The models have been trained on the same number of training points for a particular period and then tested to make sure both the loss curves converge. My question is why am I getting such different forecasts. I would like to know if this has anything do to with the nature of how both models operate? When making a forecast, I am using the last observation (transformed as a sequence of 5 columns), making a forecast, and that forecast value feeds back as a training point to generate a new forecast point. Let me know if you need more information. Unfortunately, I cannot share too many details. But I can provide more context around the code. TIA
