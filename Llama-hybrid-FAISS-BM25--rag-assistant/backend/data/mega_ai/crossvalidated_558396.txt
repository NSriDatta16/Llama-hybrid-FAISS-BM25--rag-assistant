[site]: crossvalidated
[post_id]: 558396
[parent_id]: 558394
[tags]: 
Welcome to Cross Validated and a +1 from me. I once wondered this, and I saw two issues. That definition of a p-value is not quite right. $$p=P(X\ge x \vert H_o)$$ (Or something similar for a two-sided test) With that in mind, you are not quite flipping around the conditioning to derive to posterior probability of the null hypothesis. We want to know the posterior probability of $H_0$ after looking at the data, but that p-value bring in that “or more extreme” business. What are the probabilities of the null hypothesis and the observed test statistic? I have yet to come up with a better answer than to say that both have a probability of zero. In that case, our fraction has a $\frac{0}{0}$ term. Finally, even in a true Bayesian setting, the probability of a single point like $\mu=0$ is zero for a continuous posterior distribution, so I’m not convinced that this kind of Bayesian p-value is at all what we want. Bayesian inference can be wonderful for a lot, but it doesn’t magically make continuous distributions have positive probability measure for individual points.
