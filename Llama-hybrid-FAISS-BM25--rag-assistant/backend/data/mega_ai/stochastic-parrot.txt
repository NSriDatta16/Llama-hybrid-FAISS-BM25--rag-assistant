In machine learning, the term stochastic parrot is a metaphor, introduced by Emily M. Bender and colleagues in a 2021 paper, that frames large language models as systems that statistically mimic text without real understanding. Origin and definition The term was first used in the paper "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ" by Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell (using the pseudonym "Shmargaret Shmitchell"). They argued that large language models (LLMs) present dangers such as environmental and financial costs, inscrutability leading to unknown dangerous biases, and potential for deception, and that they can't understand the concepts underlying what they learn. The word "stochastic" â€“ from the ancient Greek "ÏƒÏ„Î¿Ï‡Î±ÏƒÏ„Î¹ÎºÏŒÏ‚" (stokhastikos, "based on guesswork") â€“ is a term from probability theory meaning "randomly determined". The word "parrot" refers to parrots' ability to mimic human speech, without understanding its meaning. In their paper, Bender et al. argue that LLMs are probabilistically linking words and sentences together without considering meaning. Therefore, they are labeled to be mere "stochastic parrots". According to the machine learning professionals Lindholm, WahlstrÃ¶m, Lindsten, and SchÃ¶n, the analogy highlights two vital limitations: LLMs are limited by the data they are trained by and are simply stochastically repeating contents of datasets. Because they are just making up outputs based on training data, LLMs do not understand if they are saying something incorrect or inappropriate. Lindholm et al. noted that, with poor quality datasets and other limitations, a learning machine might produce results that are "dangerously wrong". Dismissal of Gebru by Google Gebru was asked by Google to retract the paper or remove the names of Google employees from it. According to Jeff Dean, the paper "didn't meet our bar for publication". In response, Gebru listed conditions to be met, stating that otherwise they could "work on a last date". Dean wrote that one of these conditions was for Google to disclose the reviewers of the paper and their specific feedback, which Google declined. Shortly after, she received an email saying that Google was "accepting her resignation". Her firing sparked a protest by Google employees, who believed the intent was to censor Gebru's criticism. Usage "Stochastic parrot" is a neologism used by AI skeptics to signify that LLMs lack understanding of the meaning of their outputs. Whether this is true is subject to debate (see Â§ Debate). The term carries a negative connotation. Sam Altman, CEO of Open AI, used the term when he tweeted, "i am a stochastic parrot and so r u". The term was designated to be the 2023 AI-related Word of the Year by the American Dialect Society. Debate Some LLMs, such as ChatGPT, have become capable of interacting with users in convincingly human-like conversations. The development of these new systems has deepened the discussion of the extent to which LLMs understand or are simply "parroting". Subjective experience In the mind of a human being, words and language correspond to things one has experienced. For LLMs, words may correspond only to other words and patterns of usage fed into their training data. Proponents of the idea of stochastic parrots thus conclude that LLMs are incapable of actually understanding language. Hallucinations and mistakes The tendency of LLMs to pass off false information as fact is held as support. Called hallucinations or confabulations, LLMs will occasionally synthesize information that matches some pattern. LLMs may fail to distinguish fact and fiction, which leads to the claim that they can't connect words to a comprehension of the world, as humans do. Furthermore, LLMs may fail to decipher complex or ambiguous grammar cases that rely on understanding the meaning of language. As an example, borrowing from Saba et al., is the prompt: The wet newspaper that fell down off the