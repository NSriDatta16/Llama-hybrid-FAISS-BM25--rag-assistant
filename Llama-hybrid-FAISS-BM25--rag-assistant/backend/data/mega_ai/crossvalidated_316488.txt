[site]: crossvalidated
[post_id]: 316488
[parent_id]: 8817
[tags]: 
As @ogrisel highlighted, scikit-learn is one of the best machine learning packages out there for Python. It is well suited for data-sets as small as 100k (sparse) features and 10k samples, and even for marginally bigger data-sets that may contains over 200k rows. Basically, any dataset that fits in the memory. But, if you are looking for a highly scalable Python Machine Learning framework, I'd highly recommend Pyspark MLlib. Since datasets these days can grow big exponentially (given the big data and deep learning wave), you would often need a platform that can scale well and run fast not just on the model training phase, but also during the feature engineering phase (feature transformation, feature selection). Let's look at all the three metrics for Spark Mllib platform that you are interested in: Scalability: If your dataset can fit in the memory, scikit-learn should be your choice. If it's too big to fit in the memory, Spark is the way to go. The important thing to note here is that Spark works faster only in a distributed setting. Comprehensiveness: Sklearn is far richer in terms of decent implementations of a large number of commonly used algorithms as compared to spark mllib. The support for data manipulation and transformation is also more richer in scikit-learn. Spark Mllib has sufficient data transformation modules that does the trick majority of the times. So, in case you end up with spark mllib for scalability concerns, you will still be able to get the job done. It has all the support for correlation analysis, feature extraction (tf-idf, word2vec, CountVectorizer), feature transformation (Tokenizer, StopWordsRemover, nn-gram, Binarizer, PCA etc). For a detailed list see the link below: Extracting, transforming and selecting features in Spark mllib Classification: Spark mllib has all the major algorithms' implementation that you'd be using majority of the times (including algos that work well for text classification). For a detailed overview of what algorithms are available through mllib, see the link below. Mllib Classification and regression Bonus: Apache Spark has support for Python, R, Java, and Scala. So, if tomorrow you decide to experiment with a different language (as a personal choice or for professional reasons), you won't have to learn an entirely new framework.
