[site]: stackoverflow
[post_id]: 4405525
[parent_id]: 3895387
[tags]: 
Meanwhile the SQL92 standard explains the feature even less helpfully, stating only that NATIONAL CHARACTER is stored in an implementation-defined character set. As opposed to a mere CHARACTER, which is stored in an implementation-defined character set. Which might be a different implementation-defined character set. Or not. Coincidentally, this is the same "distinction" the C++ standard makes between char and wchar_t . A relic of the Dark Ages of Character Encoding when every language/OS combination has its own character set. Should one use NVARCHAR for all character (non-binary) storage purposes? It is not important whether the declared type of your column is VARCHAR or NVARCHAR . But it is important to use Unicode (whether UTF-8, UTF-16, or UTF-32) for all character storage purposes. Are there currently-popular DBMSs in which it will do something undesirable Yes: In MS SQL Server, using NCHAR makes your (English) data take up twice as much space. Unfortunately, UTF-8 isn't supported yet. EDIT : SQL Server 2019 finally introduced UTF-8 support .
