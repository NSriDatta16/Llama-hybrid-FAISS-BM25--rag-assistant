[site]: crossvalidated
[post_id]: 377446
[parent_id]: 351060
[tags]: 
Back in around 2005 when "Data Mining" was the latest threat to the statistical profession, I remember seeing a poster with "Data Mining Principles," one of which was "let the data speak" (can't remember if "for itself" was included). If you think about algorithms that might be considered "Data Mining," apriori and recursive partitioning come to mind, two algorithms that can be motivated without statistical assumptions and result in pretty basic summaries of the underlying data set. @Ben understands more of the history of the phrase then I do, but thinking about the quote as cited in the paper: MCA can be seen as the counterpart of PCA for categorical data and involves reducing data dimensionality to provide a subspace that best represents the data in the sense of maximizing the variability of the projected points. As mentioned, it is often presented without any reference to probabilistic models, in line with Benz´ecri [1973]’s idea to “let the data speak for itself.” it appears to me that the procedure of MCA does resemble apriori or recursive partitioning (or hell, the arithmetic mean for that matter) in that it can be motivated without any modeling at all and is a mechanical operation on a data set that makes sense based on some first principles. There is a spectrum of letting the data speak. Fully bayesian models with strong priors would be on one end. Frequentist nonparametric models would be closer to the other end.
