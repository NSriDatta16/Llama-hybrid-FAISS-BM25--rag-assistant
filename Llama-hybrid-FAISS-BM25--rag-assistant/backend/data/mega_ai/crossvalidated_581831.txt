[site]: crossvalidated
[post_id]: 581831
[parent_id]: 581826
[tags]: 
Obviously, the results are not the same comparing both methodologies, and I wonder why it is. Well for one thing, the former is constrained to be between 0 and 1 (assuming you take the absolute value of the coefficients in the denominator), and the latter is supported on the real line. Frankly, I think each of the ways listed here isn't great. Your approaches suffer from the important drawback that each coefficient may be in different units This can artificially inflate the coefficient which is often why the covariates are scaled prior to fitting the model. This makes the relative effects of the scaled variables more or less comparable. Additionally, the z value approach (logistic regression uses z values for reasons we won't get into here) can be especially misleading because it depends on the precision of the estimate and the amount of data you have. Small effects can have large z value by virtue of having lots of data. Were I to suggest a method for answering "which feature is most important" I might scale my variables so then the coefficients are interpreted as the change in the log odds when the predictor changes by one standard deviation. And, beyond that, if I want to know how each variable contribute to the final score (like SHAP values), what methodology should I use? Since logistic regression is a linear model (linear in the log odds), you may find it favorable to read up on SHAP values for linear models. The linearity makes the interpretation very easy.
