[site]: datascience
[post_id]: 96628
[parent_id]: 
[tags]: 
Autoencoder: Size of out_backprop doesn't match computed

This question was asked before and non of the answered worked for, I have the code def AutoEncoder(cfg): input_img = Input(shape=(cfg.patch_size, cfg.patch_size, cfg.input_channel)) h = Conv2D(cfg.flc, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(input_img) h = Conv2D(cfg.flc, (8, 8), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc*2, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc*2, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc*4, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc*2, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(h) encoded = Conv2D(cfg.z_dim, (8, 8), strides=1, activation='linear', padding='same')(h) h = Conv2DTranspose(cfg.flc, (8, 8), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(encoded) h = Conv2D(cfg.flc*2, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc*4, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2DTranspose(cfg.flc*2, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc*2, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2DTranspose(cfg.flc, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2D(cfg.flc, (3, 3), strides=1, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2DTranspose(cfg.flc, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2DTranspose(cfg.flc, (4, 4), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) h = Conv2DTranspose(cfg.flc, (8, 8), strides=2, activation=LeakyReLU(alpha=0.2), padding='same')(h) decoded = Conv2DTranspose(cfg.input_channel, (4, 4), strides=2, activation='sigmoid', padding='same')(h) return Model(input_img, decoded) and the model summary is: _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) [(None, 512, 512, 3)] 0 _________________________________________________________________ conv2d (Conv2D) (None, 256, 256, 32) 1568 _________________________________________________________________ conv2d_1 (Conv2D) (None, 128, 128, 32) 65568 _________________________________________________________________ conv2d_2 (Conv2D) (None, 64, 64, 32) 16416 _________________________________________________________________ conv2d_3 (Conv2D) (None, 32, 32, 32) 16416 _________________________________________________________________ conv2d_4 (Conv2D) (None, 32, 32, 32) 9248 _________________________________________________________________ conv2d_5 (Conv2D) (None, 16, 16, 64) 32832 _________________________________________________________________ conv2d_6 (Conv2D) (None, 16, 16, 64) 36928 _________________________________________________________________ conv2d_7 (Conv2D) (None, 8, 8, 128) 131200 _________________________________________________________________ conv2d_8 (Conv2D) (None, 8, 8, 64) 73792 _________________________________________________________________ conv2d_9 (Conv2D) (None, 8, 8, 32) 18464 _________________________________________________________________ conv2d_10 (Conv2D) (None, 8, 8, 500) 1024500 _________________________________________________________________ conv2d_transpose (Conv2DTran (None, 8, 8, 32) 1024032 _________________________________________________________________ conv2d_11 (Conv2D) (None, 8, 8, 64) 18496 _________________________________________________________________ conv2d_12 (Conv2D) (None, 8, 8, 128) 73856 _________________________________________________________________ conv2d_transpose_1 (Conv2DTr (None, 16, 16, 64) 131136 _________________________________________________________________ conv2d_13 (Conv2D) (None, 16, 16, 64) 36928 _________________________________________________________________ conv2d_transpose_2 (Conv2DTr (None, 32, 32, 32) 32800 _________________________________________________________________ conv2d_14 (Conv2D) (None, 32, 32, 32) 9248 _________________________________________________________________ conv2d_transpose_3 (Conv2DTr (None, 64, 64, 32) 16416 _________________________________________________________________ conv2d_transpose_4 (Conv2DTr (None, 128, 128, 32) 16416 _________________________________________________________________ conv2d_transpose_5 (Conv2DTr (None, 256, 256, 32) 65568 _________________________________________________________________ conv2d_transpose_6 (Conv2DTr (None, 512, 512, 3) 1539 ================================================================= Total params: 2,853,367 Trainable params: 2,853,367 Non-trainable params: 0 I'm unclear why I would get the error tensorflow.python.framework.errors_impl.InvalidArgumentError: Conv2DCustomBackpropInput: Size of out_backprop doesn't match computed: actual = 4, computed = 8 spatial_dim: 1 input: 8 filter: 8 output: 4 stride: 1 dilation: 1 [[node model/conv2d_transpose/conv2d_transpose (defined at train2.py:75) ]] [Op:__inference_train_function_2995] Any help is really appreciated
