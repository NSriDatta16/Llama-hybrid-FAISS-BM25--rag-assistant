[site]: crossvalidated
[post_id]: 523840
[parent_id]: 
[tags]: 
Are power law relations between means and standard deviations inherent in normally distributed data?

In a recent paper I submitted for publication I document a power law relation between the means and standard deviations of several time series. That is, when plotting the log of the means of each of these (stationary) series against the log of their respective standard deviations, you get a straight, positively sloped line (with non-zero y axis intercept). When researching for this paper I scoured the internet for any possible statistical or mathematical explanation for this behavior, but found none, and could recall nothing from my own training in statistics that would explain this either. I discovered variance functions and Bartlett's identities along the way, but this still fell far short of explaining the relation I was documenting. The data I am dealing with are all normally distributed. My paper was rejected, and one of the main grounds for rejection given by the editor was that the power law relation between means and standard deviations I had observed is "inherently true of more or less normally distributed sets of data". Can someone please explain to me what the editor is talking about? Do power law relations trivially exist between the means and standard deviations of different normally distributed sets of data? Edit: Some details on the data - Each data set is a stationary yearly time series. Number of observations in each series is the same. My logged plot of the means against their respective standard deviations follows below. In this graphic, the different shapes and colors of the points correspond to different commodity groups.
