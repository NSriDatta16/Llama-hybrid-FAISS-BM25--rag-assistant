[site]: datascience
[post_id]: 32501
[parent_id]: 32442
[tags]: 
A simple trick to do outlier detection is to use the output probability of your model. If you are using a neural network for instance, you can use a softmax output which will give you a probability for each labels: \begin{equation} p(y=y_i) = \frac{e^{W_i^Tx+b_i}}{\sum_j e^{W_j^Tx+b_j}} \end{equation} If your model is accurate, for most points in your dataset, the probability should be peaked on the true label. However, if you have an outlier, then the model should get confused and then return probabilities that are more spread out over the labels. You could measure this spread by measuring the entropy of the output softmax probability distribution p(y): \begin{equation} H[p] = - \sum_y p(y)\log p(y), \end{equation} where $y$ takes one the different output categories (labels). Entropy is a measure of uncertainty, so if you have $H(p)=0$, the model is confident of the output, whereas if $H[p] = \log(N_c)$ ($N_c$ the number of labels), the model has no idea what to predict. Thus, using a threshold on the entropy (you might have to tune that threshold depending on your specific problem), you categorize a point as being an outlier or not. I think this may be a good starting point for high-dimensional data. For low-dimensional data, you can always do some density estimation and use the density as a threshold.
