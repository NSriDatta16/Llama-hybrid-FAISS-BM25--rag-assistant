[site]: stackoverflow
[post_id]: 5686739
[parent_id]: 5684662
[tags]: 
I wish to extend @AProgrammer answer. Your hash map is simple because it is custom tailored to your need. On the other hand std::tr1::unordered_map has to fulfill a number of different tasks, and do well in all case. This require a mean-performance approach in all cases, so it'll never be excellent in any particular area. Hash containers are very special in that there are many ways to implement them, you chose Open-Addressing, while the standard forces a bucket approach on the implementors. Both have different trade-offs, and this is one reason why the standard, this time, actually enforced a particular implementation: so that performance do not change dramatically when switching from one library to another. Simply specifying Big-O complexity / amortized complexity would not have been enough here. You say that you instructed the unordered_map as to the number of finals elements, but did you change the load factor ? Chaining is notoriously "bad" (because of the lack of memory locality) in case of collisions, and using a smaller load factor would favor spreading out your elements. Finally, to point out one difference: what happens when you resize your hash map ? By using chaining, the unordered_map does not move the elements in memory: references to them are still valid (even though the iterators may be invalidated) in case of big or complex objects, there is no invocation of copy constructors This is in contrast with your simple implementation , which would incur O(N) copies (unless you use linear rehashing to spread out the work, but this is definitely not simple). It seems, therefore, that the choice for unordered_map was to smooth the spikes , at the cost of a slower average insert. There is something you can do though: provide a custom allocator . By writing a specific allocator for your usecase, and allocate all its memory in one go (since you know how many objects will be inserted, and can have the allocator report how much memory is a node). Then allocate the nodes in a stack-like fashion (simple pointer increase). It should improve (somewhat) the performance.
