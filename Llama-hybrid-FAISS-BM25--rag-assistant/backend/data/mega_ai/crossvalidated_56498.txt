[site]: crossvalidated
[post_id]: 56498
[parent_id]: 
[tags]: 
Re-scaling a confusion matrix after down sampling one class

Let's say I have a large, un-balanced binary classification problem (in reality nrow is more like 500k, and ncol is more like 500): set.seed(42) nrow sum(Y==1)/length(Y) [1] 0.0027 Before modeling, I down-sampled the negative class. I don't have a strong theoretical justification for doing this, but it makes my models fit a lot faster, and they seem to be better too. keep sum(Y==1)/length(Y) [1] 0.5 Fitting a model to the down-sampled dataset is pretty quick: library(caret) Y And I can use the cross-validation folds to estimate some statistics about the model's predictive ability: > max(model$results$ROC) [1] 0.9777778 > confusionMatrix(model) Cross-Validated (10 fold) Confusion Matrix (entries are percentages of table totals) Reference Prediction X0 X1 X0 41.0 3.3 X1 9.0 46.7 However, I would like to estimate these statistics on the FULL dataset, preferably without cross-validating my model on the full dataset, which would be extremely slow. I was thinking of doing a naive re-scaling of the confusion matrix, like this: scaling_factor round(CM/sum(CM)*100, 2) Reference Prediction X0 X1 X0 81.56 0.04 X1 17.90 0.50 Does this seem like a reasonable calculation? Is there a similar method I could use to re-scale AUC? Or do I expect AUC to stay the same? /edit: in response to B_Miner. I am fairly certain that fitting the downsampled model to the full dataset will overestimate its performance. It's easy to see why if we fit a random forest instead of a glmnet: model And predict this model on the full dataset: pred_full table(pred_full, Yfull) Yfull pred_full 0 1 X0 8531 0 X1 1442 27 Because every single positive instance was used to train the model, the model can perfectly predict these instances, even on the full dataset. /edit2: To clarify. I understand the the down-sampled model is biased. However, I suspect that the model's bias is predictable and consistent. I'm looking for a theoretical way to correct for this bias, under the assumption that the removed negative observations come from the same distribution as the negative observations in the training set.
