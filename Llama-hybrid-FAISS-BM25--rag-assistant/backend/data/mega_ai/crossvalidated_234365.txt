[site]: crossvalidated
[post_id]: 234365
[parent_id]: 
[tags]: 
Features in xgboost based on f1 score

Suppose I have a data set with around 3M rows and around 50 columns(features). I have analyzed the data and cleansed it properly as much as possible. When I train this data set on xgboost, a feature map can be plotted with the help of the model which provides the f1 scores for different features in the dataset. Now, if among these 50 features if 10 features have a very low f1 score as compared to the other features, say the f1 scores are in the range of 1-20 for these 10 features, then will dropping these features from my model and training it again improve my accuracy ? And if yes, will the improvement be differentiable?
