[site]: stackoverflow
[post_id]: 1450698
[parent_id]: 1450599
[tags]: 
There are quite a few articles about proper implementation of memory managers. Most of these articles provide time measurements of what took what time, and why. So I would suggest you to take a look at what has already been done in this field. There are quite a few interesting ideas, many of which work well, and have wise and interesting concepts. Although machine learning techniques are interesting to learn and know, I suspect that they will not give good results in real life. The reason is the large overhead they need in order to work. I believe more in methods closer to the way modern caches work - different variations on the least recently used method. So in your example, I would do the following: Use a "cache" made of different sizes, and use it. This means saving a minimal size that is not returned to the system, and used for 'reuse'. The cache size could be determined dynamically: Check how often new memory is allocated and de-allocated for this thread. If threshing is made too often (often could be a parameter of time), the cache size is increased. Regarding stealing: the cache size could be non-stealable, solving problems of caching and threshing. The main drawback of this method is the memory overhead. It too can be reduced if cache sizes are reduced (as it is a trade-off in your case).
