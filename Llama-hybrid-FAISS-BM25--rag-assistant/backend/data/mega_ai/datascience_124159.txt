[site]: datascience
[post_id]: 124159
[parent_id]: 
[tags]: 
How is it called when instead of creating predective models finding patterns in observed data (ML) you tried to guess the model theorically...?

I'm a college student appasionated of machine learning and I've decided to my bachelor thesis about it. I thought that as an interesting introduction to machine learning, I could introduce it by oppose it to the "traditional way": trying to reason it For example, if I have a string that is vibrating and I want to know to the height of a point in the string in a time, a good physicist can model that (if you add as features the time, the position, the elasticity of the string, the density of the air etc...it will give you the so-called "wave equation" that can be solved as it almost deterministic). On the other hand, if someone had lots of previous observations (instances), someone can try to find patterns and through that can make good predictions on the height Â¡Without knowing anything about physics (or any other subject) There are times that its better to use "traditional" models: When you have deep knowledge in the subject and you don't have any previous observations and you can't afford taking thousands of observations On the other hand: if the subject that we are studying is still new and,we can reason in which way the features are related, yet we see there is a strong relationship empiracally throught collected data between some variables and the target one, we should use machine learning I would like to express this idea properly in a bachelor thesis, ideally with examples of when to use each one or historical precedents. However, I haven't seen any article or book explaining it in proper terms and its frustating me. Any help aprecciated. Thanks.
