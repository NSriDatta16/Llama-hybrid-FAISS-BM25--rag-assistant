[site]: crossvalidated
[post_id]: 373136
[parent_id]: 
[tags]: 
Softmax weights initialization

I am a new to deep learning and neural networks, and I need to know if there is a good weights initialization method to use if the activation function is Softmax like Tanh, ReLU and Sigmoid. Related answer.
