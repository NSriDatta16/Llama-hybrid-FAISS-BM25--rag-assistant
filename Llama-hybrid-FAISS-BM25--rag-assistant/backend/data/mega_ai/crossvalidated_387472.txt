[site]: crossvalidated
[post_id]: 387472
[parent_id]: 386518
[tags]: 
From your initial specification, your model is $K_1,...,K_n \sim \text{IID Pois}(\lambda)$ , which gives likelihood function: $$L_\boldsymbol{k}(\lambda) \propto \prod_{i=1}^n \text{Pois}(k_i|\lambda) \propto \lambda^{\sum k_i} \exp(-n\lambda) \quad \quad\ \quad \text{for } \lambda \geqslant 0.$$ You have observed data values $k_1 = ... = k_n = 0$ so the likelihood function in this case is the monotonically decreasing function $L_\boldsymbol{k}(\lambda) \propto \exp(-n\lambda)$ . Your goal is to get an interval estimate for the parameter $\lambda$ . It is worth noting at the outset that it is possible to include $\lambda = 0$ as an allowable parameter in this model. In this case the Poisson distribution degenerates down to a point-mass distribution on zero, which is a possibility in this case, since you have not observed any non-zero outcomes. Thus, the above specification of the range of $\lambda$ as including zero is not a typographical mistake --- it is an extension of the standard Poisson model to include the possibility of a point-mass distribution at zero. Bayesian analysis: This method is applied by giving a prior to your parameter and then determining the highest posterior density region as an appropriate interval estimate for the parameter. For simplicity, we will take the "non-informative" Jeffrey's prior : $$\pi(\lambda) \propto \frac{1}{\sqrt{\lambda}} \propto \text{Ga}(\lambda|\tfrac{1}{2},0).$$ This is an improper prior with infinite variance, so it is highly diffuse. This gives the posterior: $$\pi_n(\lambda) \propto \frac{\exp(-n\lambda)}{\sqrt{\lambda}} \propto \text{Ga}(\lambda|\tfrac{1}{2}, n).$$ Since the posterior is monotonically decreasing, the highest posterior density interval is an interval from zero up to some upper bound. If we define the bound $\lambda_*$ as the solution to $\Gamma(\tfrac{1}{2}, n \lambda_*) = \alpha \sqrt{\pi}$ then the highest posterior density interval with coverage $1-\alpha$ is $0 \leqslant \lambda \leqslant \lambda_*$ . That is, we have: $$\mathbb{P}(0 \leqslant \lambda \leqslant \lambda_*| \boldsymbol{k}) = 1- \alpha.$$ This gives you a useful solution to your inference problem. As $n \rightarrow \infty$ , if you keep observing zeros then the above form holds and you get $\lambda_* \downarrow 0$ , which accords with intuition. That is, if you keep observing no events in more and more data, your interval estimate for the true parameter will keep shrinking down to zero. Classical analysis: Since the likelihood function is monotonically decreasing you have MLE $\hat{\lambda} = 0$ in this case, as you have recognised. (Since we have included this parameter value in the allowable range for the model, the MLE exists in this case and is zero.) It is unsurprising that this is the MLE, given that all the data values you observed were zero. In order to get an interval estimate in classical statistics you form a confidence interval via a pivotal quantity. Grosh (1989, p. 59) derives a confidence interval for the Poisson distribution using its relationship to the chi-squared distribution. If we define the bound $\lambda_{**}$ as the solution to $\Gamma(1, n \lambda_*) = \alpha$ then this confidence interval (with minimum coverage $1-\alpha$ ) is $0 \leqslant \lambda \leqslant \lambda_{**}$ . We can see that this corresponds to the Bayesian HPDI in the case where we use an improper uniform prior.
