[site]: crossvalidated
[post_id]: 341786
[parent_id]: 
[tags]: 
Calculate expected cross entropy loss for a random prediction

Is it possible to do this? Given a multi-class classifier and the number of classes, is it possible to calculate what the loss should be, on average, for random predictions? Concretely, I'd like to know if this is possible in order to evaluate the implementation of a neural network. I think that it'd be useful to know what the loss for an untrained model should be.
