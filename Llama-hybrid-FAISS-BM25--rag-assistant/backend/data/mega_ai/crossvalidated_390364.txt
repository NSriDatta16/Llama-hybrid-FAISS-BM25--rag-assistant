[site]: crossvalidated
[post_id]: 390364
[parent_id]: 
[tags]: 
CNN: Relationship between kernel size and node size in convolution layer

I have a question and that is maybe because I have a misunderstanding. In CNN, the convolution layer uses different filters (kernels). Let's imagine I have a network with 81 nodes in the input layer (my images have a size of 9*9). The second layer is my convolution layer. Now I want to use a kernel with a size of 3*3. I have here four questions: After using the kernel all over my image, the size of my image is reduced to 7*7. That means that the nodes of my first convolution layer should be at least 7*7. Is that correct? If the size of the convolution layer is much smaller e.g. 3*3 then the kernel has to slide e.g. with a slide size of 2. Is this correct? Then, also each node in the convolution layer should be just connected to 3*3 = 9 nodes of the input layer. Is that correct? As my kernel (here 3*3) has 9 constant weights, which you run on the input nodes, then the 9 input weights of each node in convolution layer should also have exactly the same 9 weights. ( this image illustrates what I mean with the 9 weights). Is this correct? If my mentioned assumptions are correct then I have this last question: I was reading this article about implementing CNN with keras. There it uses images with size of 28*28. But then he writes the following code for its first convolution layer of its CNN: model.add(Conv2D(64, kernel_size=3, activation=’relu’, input_shape=(28,28,1))) I don't understand why he converts a 28*28 image to 64 nodes i.e. 8*8 image. Then the kernel of 3*3 must jump more about three pixel. Doesn't it loose much information? Many pixels are not even considered by the kernel.
