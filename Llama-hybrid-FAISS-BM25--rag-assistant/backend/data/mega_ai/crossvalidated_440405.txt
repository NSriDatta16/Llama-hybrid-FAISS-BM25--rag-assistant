[site]: crossvalidated
[post_id]: 440405
[parent_id]: 401070
[tags]: 
The coefficients or parameter estimates table is giving you the estimated model coefficients for the saturated model (with all possible interactions among your three variables). The loglinear model is very similar to a factorial analysis of variance (ANOVA) model, except that the response that is modeled in a loglinear model is the natural logarithm of the cell count for each cell defined by the combinations of levels of your three variables. The general equation for a three-way loglinear model is: $$ln(m_{ijk})=\mu+\lambda^{i}+\lambda^{j}+\lambda^{k}+\lambda^{ij}+\lambda^{ik}+\lambda^{jk}+\lambda^{ijk}$$ where $m_{ijk}$ is the cell count in the cell at the $i^{th}$ level of the first factor, the $j^{th}$ level of the second factor, and the $k^{th}$ level of the third factor, $\mu$ is a grand mean or intercept term, $\lambda^i$ is the main effect of the first factor at level $i$ , $\lambda^j$ is the main effect of the second factor at level $j$ , $\lambda^k$ is the main effect of the third factor at level $k$ , $\lambda^{ij}$ is the two-way interaction effect of the first two factors at the $ij^{th}$ combination, $\lambda^{ik}$ is the two-way interaction effect of the first and third factors at the $ik^{th}$ combination, $\lambda^{jk}$ is the two-way interaction effect of the second and third factors at the $jk^{th}$ combination, and $\lambda^{ijk}$ is the three-way interaction effect at the $ijk^{th}$ combination. In order to know the specifics of how to interpret your parameter estimates, you have to know how the model has been parameterized. The solution presented for saturated models in the HILOGLINEAR or Model Selection Loglinear procedure in SPSS treats the intercept $\mu$ as the average of the logarithms of the cell counts, and the $\lambda$ coefficients indicate deviations from this grand mean. (Note: By default a $\delta$ of .5 has been added to each cell before taking the logs to prevent problems in models with 0 cell counts. The $\delta$ value can be specified by the user, including 0 if appropriate.) The procedure unfortunately does not present the intercept or grand mean estimate $\hat{\mu}$ in the output. You have to calculate this manually if you want to evaluate the equation using the parameter estimates. To do this, take the observed cell counts from the Cell Counts and Residuals table for the saturated model, take the natural logarithm of each one, and calculate the mean of these logged values. That's your $\hat{\mu}$ value. To calculate the predicted value for the log of the cell count for the first cell, where each of your three variables are at their first level, you would simply add the appropriate coefficients for all the terms for that cell: $$ln(\hat{m}_{111})=\hat{\mu}+.506-.210-.411+.077+.123-.132+.123+.006=\hat{\mu}-.041$$ (I would generally suggest drilling into the values and using more than three decimals if you want to reproduce the cell counts to acceptable precision.) This parameterization is often referred to in ANOVA models as sum-to-0 restrictions. The .506 value for the first level of INTUSE indicates an increase of .506 from the mean. The value for the second level of INTUSE wouuld be -.506. For HAPPY you have -.210 and .622 for the first two levels. The value for the third level is then the negative of the sum of these two levels, or -.412. This summing to 0 of parameter estimates across levels of factors extends to rows and columns (and layers) of crosses of factors in the interaction effects. Some good information on these models, with particular attention to SPSS, is available in the Advanced Statistical Procedures Companion written by Marija Norusis (see here ). Even though the newest version of this book is many releases old, these concepts have not changed. Since in your situation the best model would seem to be one that excludes the three-way interaction, if you want to be able to look at parameter estimates for that model, you'll have to use a different procedure, GENLOG, or Analyze>Loglinear>General in the menus. The HILOGLINEAR procedure uses IPF (iterative proportional fitting) for its estimation, which doesn't produce parameter estimates, only estimates of the cell counts under different models. Parameter estimates for saturated models can be calculated using closed-form expressions, but this is generally not the case for simpler loglinear models. GENLOG uses Newton-Raphson iterative estimation and is able to produce parameter estimates for any loglinear model appropriate to a given set of data. GENLOG uses a different kind of parameterization, often referred to as set-to-0 restrictions, and it produces parameter estimates for each parameter in the model, including the constant or intercept for Poisson loglinear models, and the redundant parameters (for which all estimates are 0). It's easier to reproduce the modeled logs of cell counts using the parameter estimates from GENLOG, because you only have to add the appropriate values (no calculating negatives of sums of earlier ones) and the output labels them for you more explicitly than is done in the HILOGLINEAR output. In this parameterization, the constant or intercept term estimates the value for the last cell in the design instead of the average over cells, and other estimates show increases or decreases relative to that value.
