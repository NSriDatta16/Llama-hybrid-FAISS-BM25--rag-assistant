[site]: crossvalidated
[post_id]: 409580
[parent_id]: 316522
[tags]: 
I'm not entirely sure if I understand your question correctly, but if I visualise some worst case scenarios it will look like this (1st row = expected result, 2nd row = actual outcome, for 6 races size 2 to 7): 1 2 2 1 -> 2/2 1 2 3 3 2 1 -> 4/3 1 2 3 4 4 3 2 1 -> 8/4 1 2 3 4 5 5 4 3 2 1 -> 12/5 1 2 3 4 5 6 6 5 4 3 2 1 -> 18/6 1 2 3 4 5 6 7 7 6 5 4 3 2 1 -> 24/7 The arrows show the absolute rank difference/race size. As you can see, the absolute difference increases more than the size of the race. So a larger race can potentially have a higher average rank difference. (specifically the relationship is: (n^2 +n) /2 - (ceil(n/2)) versus n , with n being the race size) Normalise by maximum error I think it's important to understand what you really want to normalise. Of course you can simply normalise using the maximum possible rank difference. So normalise so that size 2 maximum error equals size 7 maximum error. Or in otherwords, state that 2/2 = 100% wrong, and 28/7 is also 100% wrong, and go from there. Take nr of contestants incorrect into account? Of course you can also look at number contestants that were ranked incorrectly. For instance in race size 3: 1 2 3 3 2 1 -> 4/3 but 1 2 3 3 1 2 -> also 4/3 In the first case only two contestants are ranked incorrectly, but in the second case all three are ranked incorrectly (although two of them "less incorrect"). Alternatively, use historical or current data Alternatively, you can normalise using historical data, or your current results evenly. I.e. state that size2 0.4992 error equals your size12 3.9764 error (assuming you indeed consider that these are ranked equally good). Of course you need to be able to explain why you consider these equal, so you'll need some metric of an "equally good ranking" Small number statistics One thing to take into account is small number statistics. A race with size 2 has only two outcomes: 100% correct, or 100% wrong (assuming no split 1st place). So it might be difficult to compare the results if you do not use enough test cases.
