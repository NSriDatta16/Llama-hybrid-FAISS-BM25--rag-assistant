[site]: crossvalidated
[post_id]: 386188
[parent_id]: 
[tags]: 
Data Augmentation in Keras: How many training observations do I end up with?

I'm reading through Francois Chollet's "Deep Learning with Python" and was recently introduced to a concept I had never encountered before in my statistics studies. Namely, data augmentation. I have a question about what the following code does (appearing on pg 141 of the book): train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True,) test_datagen = ImageDataGenerator(rescale=1./255) train_generator = train_datagen.flow_from_directory(train_dir, target_size = (150,150) batch_size = 32, class_mode='binary') history = model.fit_generator( train_generator, steps_per_epoch=100, epochs=100, validation_data=validation_generator, validation_steps=50) What I want to know is how the ImageDataGenerator() is working. E.g., if I have a training directory with 2000 images, will the data augmentation create more than 2000 observations to train with? How do I know/control how many observations are developed? Thank you in advance.
