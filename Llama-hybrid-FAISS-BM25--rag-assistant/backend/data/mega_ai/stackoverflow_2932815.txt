[site]: stackoverflow
[post_id]: 2932815
[parent_id]: 2932515
[tags]: 
Is there any benefit to replacing STL containers/algorithms with hand-rolled ones? I would only consider this as a last option. The STL containers and algorithms have been thoroughly tested. Creating new ones are expensive in terms of development time. Along similar lines, for std::vectors whose needed sizes are unknown but have a reasonably small upper bound, is it profitable to replace them with statically-allocated arrays? First, try reserving space for the vectors. Check out the std::vector::reserve method. A vector that keeps growing or changing to larger sizes is going to waste dynamic memory and execution time. Add some code to determine a good value for an upper bound. I've found that dynamic memory allocation is often a severe bottleneck, and that eliminating it can lead to significant speedups. As a consequence I'm interesting in the performance tradeoffs of returning large temporary data structures by value vs. returning by pointer vs. passing the result in by reference. Is there a way to reliably determine whether or not the compiler will use RVO for a given method (assuming the caller doesn't need to modify the result, of course)? As a matter of principle, always pass large structures by reference or pointer. Prefer passing by constant reference. If you are using pointers, consider using smart pointers. How cache-aware do compilers tend to be? For example, is it worth looking into reordering nested loops? Modern compilers are very aware of instruction caches (pipelines) and try to keep them from being reloaded. You can always assist your compiler by writing code that uses less branches (from if , switch , loop constructs and function calls ). You may see more significant performance gain by adjusting your program to optimize the data cache. Search the web for Data Driven Design . There are many excellent articles on this topic. Given the scientific nature of the program, floating-point numbers are used everywhere. A significant bottleneck in my code used to be conversions from floating point to integers: the compiler would emit code to save the current rounding mode, change it, perform the conversion, then restore the old rounding mode --- even though nothing in the program ever changed the rounding mode! Disabling this behavior significantly sped up my code. Are there any similar floating-point-related gotchas I should be aware of? For accuracy, keep everything as a double . Adjust for rounding only when necessary and perhaps before displaying. This falls under the optimization rule, Use less code, eliminate extraneous or deadwood code . Also see the section above about reserving space in containers before using them. Some processors can load and store floating point numbers either faster or as fast as integers. This would require gathering profile data before optimizing. However, if you know there is minimal resolution, you could use integers and change your base to that minimal resolution . For example, when dealing with U.S. money, integers can be used to represent 1/100 or 1/1000 of a dollar. One consequence of C++ being compiled and linked separately is that the compiler is unable to do what would seem to be very simple optimizations, such as move method calls like strlen() out of the termination conditions of loop. Are there any optimization like this one that I should look out for because they can't be done by the compiler and must be done by hand? This an incorrect assumption. Compilers can optimize based on the function's signature, especially if the parameters correctly use const . I always like to assist the compiler by moving constant stuff outside of the loop. For an upper limit value, such as a string length, assign it to a const variable before the loop. The const modifier will assist the Optimizer. There is always the count-down optimization in loops. For many processors, a jump on register equals zero is more efficient than compare and jump if less than . On the flip side, are there any techniques I should avoid because they are likely to interfere with the compiler's ability to automatically optimize code? I would avoid "micro optimizations". If you have any doubts, print out the assembly code generated by the compiler (for the area you are questioning) under the highest optimization setting. Try rewriting the code to express the compiler's assembly code. Optimize this code, if you can. Anything more requires platform specific instructions. Optimization Ideas & Concepts 1. Computers prefer to execute sequential instructions. Branching upsets them. Some modern processors have enough instruction cache to contain code for small loops. When in doubt, don't cause branches. 2. Eliminate Requirements Less code, more performance. 3. Optimize designs before code Often times, more performance can be gained by changing the design versus changing the implementation of the design. Less design promotes less code, generates more performance. 4. Consider data organization Optimize the data. Organize frequently used fields into substructures . Set data sizes to fit into a data cache line . Remove constant data out of data structures. Use const specifier as much as possible. 5. Consider page swapping Operating systems will swap out your program or task for another one. Often times into a 'swap file' on the hard drive. Breaking up the code into chunks that contain heavily executed code and less executed code will assist the OS. Also, coagulate heavily used code into tighter units. The idea is to reduce the swapping of code from the hard drive (such as fetching "far" functions). If code must be swapped out, it should be as one unit. 6. Consider I/O optimizations (Includes file I/O too). Most I/O prefers fewer large chunks of data to many small chunks of data. Hard drives like to keep spinning. Larger data packets have less overhead than smaller packets. Format data into a buffer then write the buffer. 7. Eliminate the competition Get rid of any programs and tasks that are competing against your application for the processor(s). Such tasks as virus scanning and playing music. Even I/O drivers want a piece of the action (which is why you want to reduce the number or I/O transactions). These should keep you busy for a while. :-)
