[site]: crossvalidated
[post_id]: 253333
[parent_id]: 
[tags]: 
Realize reducible nonstationary kernels as solution to SDEs and its extensions

I am interested in a regression application where my kernel is of the form \begin{equation} k(t,t^{\prime}) = k_s\left(\phi(t),\phi(t^{\prime})\right)= k_s\left(\phi(t)-\phi(t^{\prime})\right), \end{equation} where $k_s$ is a stationary kernel. I came across this paper (section 5) which classifies such kernels as reducible kernels. I am using such a kernel for time series extrapolation via Gaussian process regression. Assuming I know $\phi(\cdot)$, is there a way to leverage that information to do the regression in the space of the stationary kernel instead of the nonstationary one? It is known that for a time series application, Gaussian process regression with a stationary kernel can be done via Kalman smoothing (see here ). This is possible via synthesizing a stationary process from white noise. \begin{eqnarray} x(t) &=& w(t) * h(t) \\ k_x(\tau) &=& h(\tau)*h^\star(-\tau) \\ S_x(\omega) &=& H(\omega) H^\star(\omega) = \left|H(\omega) \right|^2 \end{eqnarray} Therefore, by finding $h(t)$ or equivalently $H(\omega)$, one can express a GP in terms of white noise. Matern kernels accept such decompositions naturally and can be expressed in terms of differential equations of white noise. For other stationary kernels like RBF, aforementioned paper proposes Taylor approximation. To give a simple example; Ornstein-Uhlenbeck process with the kernel $k_{OU}(t,t^{\prime}) = \exp\left(-\lambda \left|t-t^\prime \right| \right)=\exp(-\lambda \left| \tau \right|)$ and the spectral density $S_{OU}(\omega) = \frac{2\lambda}{\omega^2 + \lambda^2}$ can expressed as \begin{equation} \frac{dx}{dt} = - \lambda x(t) + w(t) \end{equation} Hence; whole GP regression can be reduced into a standard filtering/smoothing problem. This results in linear computational burden instead of a cubic one, and also naturally fits to the temporal nature of data. I would like to know whether this is extensible to the reducible nonstationary kernels. For instance if my kernel is $k(t,t^\prime) = k_{OU}(\phi(t),\phi(t^\prime))$ where $\phi(\cdot)$ is some known function, can I somehow utilize the above differential equation? tldr, are there any benefits if you have a reducible kernel?
