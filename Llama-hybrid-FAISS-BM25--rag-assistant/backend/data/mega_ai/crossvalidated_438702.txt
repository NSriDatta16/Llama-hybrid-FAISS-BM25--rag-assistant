[site]: crossvalidated
[post_id]: 438702
[parent_id]: 
[tags]: 
MCMC Metropolis-Hastings Understanding

I am having trouble understanding a key aspect of MCMC - does the collection of states the Markov chain passes through represent the target distribution, or for a single sample, are we running $n$ Markov chains of length $d$ and taking the $n$ states $x_d^{(1)}...x_d^{(n)}$ to be our sample? While I am under the impression that the correct answer is the former, I am interested in why the following justification for the latter would be incorrect. Say you are interested in sampling from a target distribution $\pi$ so you construct a Markov chain with a stationary distribution $\pi$ . Now, you start running your Markov chain. Does the property of a stationary distribution not say that only the final state $x_n$ for some large $n$ will follow $\pi$ . And if so, the first $n-1$ samples of the Markov chain are waste? If this is the case, it would be my impression that MCMC requires that for a sample $x^{(t)} = (x_1^{(t)}, x_2^{(t)}, ... x_d^{(t)})$ each $x_i^{(t)}$ would be the $d$ th element from a Markov chain with stationary distribution $\pi$ run for a long period of time. When looking at examples of code, however, this does not seem to be whats going on, but I cannot grasp what really is going on if the first $n-1$ realized states of the Markov chain do not follow the stationary distribution.
