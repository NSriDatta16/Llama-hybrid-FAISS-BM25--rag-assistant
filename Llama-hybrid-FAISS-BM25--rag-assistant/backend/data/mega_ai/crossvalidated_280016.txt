[site]: crossvalidated
[post_id]: 280016
[parent_id]: 279918
[tags]: 
As kjetil writes , there is rather little data here - too little to draw truly firm conclusions. My personal impulse in such a situation is to look at multiple models and see whether they agree in principle. Let's first draw a graph. year Well, the graph does look rather convincing, even if it is only 16 data points. I'd certainly rather bet on the 2017 observation to be larger than 4, rather than 4 or less. Here is the R analogue to the linear regression you calculated in SPSS. Note that the p values match: summary(lm(sightings~year)) Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -796.7588 220.6300 -3.611 0.00283 ** year 0.3985 0.1098 3.628 0.00274 ** As kjetil suggested, a Poisson regression would also make sense: summary(glm(sightings~year,family="poisson")) Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -227.69850 61.49336 -3.703 0.000213 *** year 0.11395 0.03058 3.726 0.000194 *** This model also finds a significant trend. However, the linear and the Poisson regression posit very specific trends: a linear one in the first case and an exponential one in the second case. An alternative would be to test the correlation between sightings and year. The pearson correlation again calculates a linear trend: cor.test(sightings,year,method="pearson") t = 3.628, df = 14, p-value = 0.002742 Note how the p value is exactly the same as for the simple linear model. Alternatives would be the spearman and the kendall correlations, which test for any kind of monotonous relationship between years and sightings, not only linear or exponential ones: cor.test(sightings,year,method="kendall") z = 2.9576, p-value = 0.0031 cor.test(sightings,year,method="spearman") S = 156.75, p-value = 0.0004915 Although both tests output warnings, because they cannot calculate exact p values if ties are present, they again find significant trends. Finally, as Michael Chernick notes , you actually have a time series, so a time series analysis might be useful. Your count data really call for an INAR model or similar, but there are really no common count data time series models that account for trend, so I'll just fit an ARIMA model and an ETS one: library(forecast) auto.arima(sightings) Series: sightings ARIMA(0,1,0) sigma^2 estimated as 8: log likelihood=-36.88 AIC=75.76 AICc=76.07 BIC=76.47 ets(sightings) ETS(A,N,N) Call: ets(y = sightings) Smoothing parameters: alpha = 0.3891 Initial states: l = 1.3 sigma: 2.3277 We note that auto.arima() models an ARIMA(0,1,0) process, which means that it believes that first differences are white noise. First differences again indicate a trend. Finally, ETS is the only one that does not find a trend, it only finds additive error (the first "A"), no trend ("N") and no seasonality ("N"). However, it finds a very large smoothing value of $\alpha = 0.39$, so it thinks your sightings might be a weak kind of a random walk. Note that these models are fitted using information criteria, so it doesn't make sense to assign a p value to the trends they find (or not). In summary, most of these different models do find a trend, even if they are designed to look at different kinds of trends (linear, exponential, general monotone, first differences). This, together with the plot, would certainly be enough to convince me that there is indeed a trend in your data.
