[site]: crossvalidated
[post_id]: 571047
[parent_id]: 
[tags]: 
Does threshold on the model probability depend upon the spread in the dataset among positive and negative classes (binary classification)?

I think that the threshold on model probability through which one discern positive (y=0) and negative(y=1) class depends on the spread in the training dataset b/w y=0 and y=1. This question came when I did a random oversample of the minority class for a classification task. The same precision(say 60%) which was coming previously (without oversampling) at a threshold of say 30% is now (with oversampling) coming at a threshold of 50%. I then checked the distribution of model probability (for both y=0 and y=1) across different oversampling rates and found that there was an increase in the model probability with the increase in oversampling rate. This shouldn't happen if there is a high variance in the positive and negative class in the training dataset. The most probable reason behind the increase in the model score for both y=0 and y=1 is the presence of mis-classified training data points (For few cases when y=1, the distribution looks like y=0 and vice-versa) I will explain this variance (or spread) term through one example: Consider a dataset which has 2 classes y=0 and y=1. And there is a singly training data feature (x) which takes value as 1 for y=0 and 2 for y=1. x={1 when y=0, 2 when y=1} If we apply a simple logistic regression (LR) on this example, then it will give a probability(of y=1) as 96% where y=1, and 5% where y=0. Now, let's add a misclassified example to the dataset (False positive), i.e., y=0 and x=2. Now, LR will give probability as 50% where y=1, and 5% where y=0. Now, let's add 2 misclassified example to the dataset (False positive & False negative), i.e., (y=0 and x=2) & (y=1 and x=1) Now, LR will give probability as 50% where y=1, and 12% where y=0. And so on.. As one adds false negative examples to the dataset, then the probability of y=0 classes would increase, and hence one needs to have a higher threshold on model probability to classify y=1 cases. Adding misclassified examples in the dataset would decrease the variance (or spread) b/w positive (y=0) and negative (y=1) class. Through which, one can summarise that as the spread in the dataset decreases, the threshold on the model probability to classify y=1 would accordingly vary. Is my understanding correct? Please elaborate in your answer. Also, which classical ML models one should use to mitigate this issue (misclassified examples in the dataset)?
