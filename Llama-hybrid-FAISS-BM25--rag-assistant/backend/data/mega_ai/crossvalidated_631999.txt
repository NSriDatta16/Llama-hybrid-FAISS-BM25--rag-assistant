[site]: crossvalidated
[post_id]: 631999
[parent_id]: 631195
[tags]: 
Yes, autocorrelation (or spatial correlation or ...) do not destroy the unbiasedness of the sample mean as an estimator of population mean. Expectation is a linear operator, so when you calculate the expectation of the sample mean by $$ \DeclareMathOperator{\E}{\mathbb{E}} \E \left\{ \frac1n \sum_i^n X_i \right\} =\frac1n \left\{ \E X_1 + \E X_2 + \dotsm + \E X_n \right\} = \dotsm $$ The only thing you need to calculate to finnish is $\E X_i = \mu$ , which only involves the marginal distribution of the $X_i$ `s, correlations or other aspects of bivariate or multivariate distributions are simply not used. With (strong) correlations there might well be better estimators of the population mean $\mu$ than the simp,e sample mean, for example weighted means. But the sample mean is still unbiased. EDIT Added after user whuber`s comment below. The answer above is formal, let us look more closely at what can happen with a highly correlated time-series, if it is not long enough to mix well. With a very high correlation a time series might stay for a long time in a limited region of its state-space. For a simulated example I will use fractional Gaussian noise, which is defined as the increments of fractional Brownian motion. While the increments of the usual Brownian motion are independent, with the fractional case this is not true. The theoretical mean of the simulated series is zero, but look how the red series is always above zero ... none of these four series are really exploring the full statespace. Below the R code used: library(fractionalBM) # Not on CRAN, installed from github library(ggplot2) library(reshape2) set.seed(7*11*13) N Note also that this problem can be difficult to detect with only limited data. Below a table of estimated (with R function acf ) and known, theoretical autocorrelations (based on Hurst exponent 0.95 as used in the simulation). The estimation uses only one of the simulated series: est the [1,] 1.000 1.000 [2,] -0.176 0.866 [3,] -0.206 0.800 [4,] 0.320 0.767 [5,] -0.086 0.745 [6,] -0.187 0.728 [7,] 0.037 0.715 [8,] -0.089 0.704 [9,] -0.180 0.695 [10,] 0.205 0.686 [11,] 0.011 0.679 First column is the estimated autocorrelations, which is effectively pure noise. Effective estimation of such strong autocorrelations needa much longer series.
