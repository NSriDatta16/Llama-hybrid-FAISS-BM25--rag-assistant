[site]: crossvalidated
[post_id]: 491981
[parent_id]: 
[tags]: 
Probability density from Hilbert-Schmidt integral operator

The Hilbert-Schmidt integral operator determines the underlying measure, if a universal kernel is used. Now, do eigenvalues of the Hilbert-Schmidt integral operator determine the underlying measure up to translation, reflection and rotation? Details: Suppose we have a measure $\mu$ on a Euclidean space $X=\mathbb R^n$ and a kernel $\kappa: X \times X \rightarrow \mathbb R$ (which is symmetric and every Gram matrix $G$ defined by $G_{i,j} = \kappa(x_i, x_j)$ from a finite set $\{x_1, \dots x_m\} \subset X$ is positive semidefinite). Assume that $\kappa$ is given by distance function: $\kappa(x,y) = \kappa_0(\|x-y\|)$ , for example $\kappa(x,y) = e^{-\gamma \|x-y\|^2}$ . Suppose we are given a class of measures $\mathcal S$ on $X=\mathbb R^n$ , for example those induced by continuous probability density functions that integrate to 1. We then define the Hilbert-Schmidt integral operator : $$K_{\mu}: \phi \mapsto \int_X \kappa(x,-) \phi(x) \text{d} \mu (x)$$ The operator is both compact and self-adjoint, and thus admits an orthogonal decomposition and real eigenvalues by the spectral theorem. Let's define its vector of eigenvalues by: $$\vec \lambda(\mu) = (\lambda_1, \lambda_2, \cdots) \text{ where } \lambda_i \phi_i = K_{\mu} \phi_i \text{ and } \lambda_1 \ge \lambda_2 \ge \cdots $$ We immediately observe that $\vec \lambda(\mu) = \vec \lambda (\rho \cdot \mu)$ where $\rho$ is an isometry of $X = \mathbb R^n$ and $\rho \cdot \mu := \mu \circ \rho^{-1}$ . This is because $\rho^{-1} \cdot K_{\rho \cdot \mu}(\rho \cdot \phi) = K_\mu(\phi)$ if we define $\rho \cdot \phi = \phi \circ \rho^{-1}$ : $$\left( \rho^{-1} \cdot K_{\rho \cdot \mu}(\rho \cdot \phi)\right) (y) = \int_X \kappa(x, \rho y) \phi(\rho^{-1} x) d (\rho \cdot \mu)(x) \\ = \int_X \kappa(\rho x, \rho y) \phi(\rho^{-1} \rho x) d (\rho \cdot \mu)(\rho x) = K_\mu(\phi)(y)$$ so that $$K_\mu \phi = \lambda \phi \implies K_{\rho \cdot \mu} (\rho \cdot \phi) = \rho \cdot (K_\mu \phi) = \rho \cdot (\lambda \phi) = \lambda (\rho \cdot \phi) $$ The question is now whether the converse holds: do we have $\vec \lambda(\mu) = \vec \lambda(\nu) \implies \exists \rho: \mu = \rho \cdot \nu$ ? The kernel $\kappa$ is characteristic iff the map $\Phi: \mu \mapsto K_\mu(\textbf{1}) = \mathbb{E}_{x \sim \mu} [\kappa(x,-)]$ is injective. The Gaussian (or RBF) kernel $\kappa(x,y) = e^{-\gamma\|x-y\|^2}$ is an example of a characteristic kernel. Thus, the map $\mu \mapsto K_\mu$ is all the more injective. Therefore, the Hilbert-Schmidt integral operator determines the underlying measure (but isn't invariant with respect to isometry). My question then concerns how much information we can remove from the operator while telling apart underlying measures up to the isometries of a Euclidean space. Namely, can we do without the eigenvectors?
