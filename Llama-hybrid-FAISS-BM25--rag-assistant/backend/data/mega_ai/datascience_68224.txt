[site]: datascience
[post_id]: 68224
[parent_id]: 17910
[tags]: 
You face three problems and here are my recommendations: 1. unbalanced classes Logistic regression (unlike other methods) is very well capabable of handling imbalanced classes per se. There is the bias weight that shifts all the predictions around the correct mean. But it comes with some caveats mentioned in the paper below. 2. different class distribution in train/test data First of all it is a sign of danger that you have different kind of data in train and test set. If your taining data does not represent your test (or more important) prediction situation very well, even the best model does not generalize and might make poor predictions. Anyway, you can change (or have different) class distribution in the training set and still obtain unbiased predictions. This can be done by introducing using small modifications to the prediction (or the model). For more see King, G., Zeng, L. (2001) ‘Logistic Regression in Rare Events Data’ Political Analysis, 9, Pp. 137–163 . 3. potential overfitting You should introduce regularization (l1/l2 a.k.a. lasso/ridge) and conduct a grid search to find the optimal hyper parameters. I prefer to use the optimizing algorithm itself to find the most important features w.r.t. explanatory power. You should only use unsupervised dimensionality reduction (like PCA) if you really need to simplify the optimization problem.
