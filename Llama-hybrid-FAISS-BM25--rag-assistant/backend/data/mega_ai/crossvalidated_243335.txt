[site]: crossvalidated
[post_id]: 243335
[parent_id]: 
[tags]: 
Judging the quality of a statistical model for a percentage

I have a data set with multiple predictors, and a single response variable which is a percentage, thus is bounded between 0 and 100. I cannot share the dataset unfortunately. I would like to build a simple model for the response. I then tried, perhaps mindlessly, to use logistic regression using glm . R throws the following error: logistic_regression The error message might not be exactly that because I had to translate it from my language (I had never seen R throw errors in my language before!). The concept is there, however, and it's right: my $y\in[0,100]$. I must rescale it so that $y^*\in[0,1]$. I then get logistic_regression This time, I don't get an error but a warning. This makes sense: after all, the response variable for logistic regression should be a binary variable, not a continuous one. On the other hand, the model ran. My questions: How do I judge the quality of this model? Does it make sense to look at residuals vs fitted, distribution of residuals, etc.? I am mainly interested in prediction, thus point estimates and prediction intervals for unseen data. A secondary goal would be interpretation of coefficients: if I increase $x_1$ by 1 ceteris paribus , does $y$ increase by a fixed amount? A fixed ratio? Neither of those? The third goal is inference on the coefficients: I care more about uncertainty estimates for $\hat{y}$, but if I can have confidence intervals for the coefficients of the model, that would be good, too. Does the model make sense at all? Should I do something completely different, such as for example beta regression, or can I use something simpler/more similar to what I did?
