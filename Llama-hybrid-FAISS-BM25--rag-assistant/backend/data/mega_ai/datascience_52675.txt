[site]: datascience
[post_id]: 52675
[parent_id]: 46508
[tags]: 
This article presents 2 ways to implement ACD metric. You talk about ACD-I (using the article's notation). As I understood, you first average colors, i.e. sum over pixels in the image plane, for each color in all frames: $\mathrm{avg}_i = \frac{1}{MN}\sum_{x,y}\mathrm{Frame}_i $ . then, in the resulting 3D vectors for every two consecutive ones, you calculate L2 distance: $d_i = \sqrt{\sum_{l=1}^3(\mathrm{avg}_{i,l} - \mathrm{avg}_{i+1,l})^2}$ . In general, you might want to use other distances, which is not prohibited. sum it up (since we take into account all frames we have, not just one pair) and divide by the number of frames (because the metric should not depend on it [at least, I suppose so], otherwise longer videos will have larger metric values): $\mathrm{ACD} = \frac{1}{K-1}\sum_i d_i$ (if there are K frames). ACD-C is obtained in the same way but instead frames you use feature vectors extracted from images (frames) with 'encoding-like' network. OpenFace probably is a good choice when dealing with facial expressions. Your formula might work differently from the authors' intention. Imagine a white spot on a black screen. From frame to frame that spot is gradually moving from one side to the other. Your metric shows that the content in this video is changing. And the faster the spot moves, the greater changes happen (ok, in case of a spot and a black screen at a certain speed the saturation point will be reached and your metric will stop changing [when in one frame the spot moves a distance equal to its diameter], but that's another story) . However, in fact, there are no changes in the content. You still have the spot and the black screen. This is why you need averaging (not summing 'changes' and making it independent from the image size - this is what your formula does) Here you can see the implementation of ACD metric(s) . I cannot vouch that is 100% correct. So, let me know if there are any kind of uncertainties.
