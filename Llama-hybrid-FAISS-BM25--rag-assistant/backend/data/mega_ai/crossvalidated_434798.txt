[site]: crossvalidated
[post_id]: 434798
[parent_id]: 434796
[tags]: 
I think I just figured it out. The advantage of policy gradients is that approaching a deterministic policy is dependent on the experiences as only certain experiences will push the score of some action towards infinity. With $\epsilon$ -greedy however, this is not the case as the decay factor is set externally and is not dependent on the security of the policy or the learned experiences so far. That being said, policy gradients can approach a deterministic policy in the limit if choosing actions deterministically really is the (locally) best option. $\epsilon$ -greedy however will certainly approach a deterministic policy as this is preset in advance. However, this deterministic policy might actually not be desirable.
