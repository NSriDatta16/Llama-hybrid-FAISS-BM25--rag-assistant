[site]: crossvalidated
[post_id]: 228373
[parent_id]: 
[tags]: 
Use Pearson's correlation coefficient as optimization objective in machine learning

In machine learning (for regression problems), I often see mean-squared-error (MSE) or mean-absolute-error (MAE) being used as the error function to minimize (plus the regularization term). I am wondering if there are situations where using correlation coefficient would be more appropriate? if such situation exists, then: Under what situations is correlation coefficient a better metric compared to MSE/MAE ? In these situations, is MSE/MAE still a good proxy cost function to use? Is maximizing correlation coefficient directly possible? Is this a stable objective function to use? I couldn't find cases where correlation coefficient is used directly as the objective function in optimization. I would appreciate if people can point me to information in this area.
