[site]: stackoverflow
[post_id]: 1489966
[parent_id]: 1488672
[tags]: 
isn't an iterator a pointer? An iterator is something that acts like a pointer from the outside. In most (perhaps all) cases, it is actually some form of object instead of a bare pointer. An iterator might contain a pointer as an internal member variable that it uses to perform its job, but it just as well might contain something else or additional variables if necessary. Furthermore, even if an iterator has a simple pointer inside of it, it might not point directly at the object you're interested in. It might point to some kind of bookkeeping component used by the container class which it can then use to get the actual object of interest. Fortunately, we don't need to care what those internal details actually are. So with that in mind, here's what's going on in (char*)&(*i) . *i returns a reference to the object stored in the list. & takes the address of that object, thus yielding a pointer to the object. (char*) casts that object pointer into a char pointer. That snippet of code would be the short form of doing something like this: Referral& r = *i; Referral* pr = &r; char* pc = (char*)pr; Why do i need to be messing around with addresses anyway? And why does it need the size? fstream::write is designed to write a series of bytes to a file. It doesn't know anything about what those bytes mean. You give it an address so that it can write the bytes that exist starting wherever that address points to. You give it a size so that it knows how many bytes to write. So if I do: MyClass ExampleObject; file.write((char*)ExampleObject, sizeof(ExampleObject)); Then it writes all the bytes that exist directly within ExampleObject to the file. Note: As others have mentioned, if the object you want to write has members that dynamically allocate memory or otherwise make use of pointers, then the pointed to memory will not be written by a single simple fstream::write call. will serialization give a significant boost in storage efficiency? In theory, binary data can often be both smaller than plain-text and faster to read and write. In practice, unless you're dealing with very large amounts of data, you'll probably never notice the difference. Hard drives are large and processors are fast these days. And efficiency isn't the only thing to consider: Binary data is harder to examine, debug, and modify if necessary. At least without additional tools, but even then plain-text is still usually easier. If your data files are going to persist between different versions of your program, then what happens if you need to change the layout of your objects? It can be irritating to write code so that a version 2 program can read objects in a version 1 file. Furthermore, unless you take action ahead of time (like by writing a version number in to the file) then a version 1 program reading a version 2 file is likely to have serious problems. Will you ever need to validate the data? For instance, against corruption or against malicious changes. In a binary scheme like this, you'd need to write extra code. Whereas when using plain-text the conversion routines can often help fill the roll of validation. Of course, a good serialization library can help out with some of these issues. And so could a good plain-text format library (for instance, a library for XML). If you're still learning, then I'd suggest trying out both ways to get a feel for how they work and what might do best for your purposes.
