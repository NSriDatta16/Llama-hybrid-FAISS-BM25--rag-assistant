[site]: datascience
[post_id]: 33064
[parent_id]: 32273
[tags]: 
I ended up writing a python generator, which actually works very well, for manually feeding desired number of images chunk by chunk into my CNN model like this: def image_batch_generator(df,images_path, batch_size): ''' A generator that takes a dataframe (for image names) and with a given image path goes to conver images to numpy array over batch (chunk by chunk). "df": is the "Attributes Annotations" text file from CelebA dataset. It has a column for image names, and another 40 attributes columns (binary) for each image. "images_path": it is the path to CelebA dataset image files. "batch_size": the batch size by which image will be read chunk by chunk. ''' L = df.shape[0] files = df['Images'].tolist() #this line is just to make the generator infinite, keras needs that while True: batch_start = 0 batch_end = batch_size while batch_start Hope it will help someone out there.
