[site]: crossvalidated
[post_id]: 525697
[parent_id]: 
[tags]: 
Why is it that my colleagues and I learned opposite definitions for test and validation sets?

In my master's program I learned that when building a ML model you: train the model on the training set compare the performance of this against the validation set tweak the settings and repeat steps 1-2 when you are satisfied, compare the final model against the test (hold out) set When I started working as a DS I raised a question as to the size of the test and validation sets, because it looked as though someone had labeled them wrong. This caused confusion because apparently everyone else used the "test" set in step 2 and held out the "validation" set for step 4. I assumed I had learned it wrong and no harm was done because I just switched the terms to be consistent. However I was restudying some deep learning books and noticed that according to the creator of Keras, I was right all along! Just before I wrote this question I found this one that suggests the OTHER definition of test/validation sets are correct... Is this something that is agreed upon? Is there a divide among the classical ml method and deep learning practitioners as to what the correct terms are? As far as I can tell nobody has really discussed how some statisticians/data scientists use completely opposite definitions for the two terms.
