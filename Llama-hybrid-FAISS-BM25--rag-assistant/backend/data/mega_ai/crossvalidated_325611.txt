[site]: crossvalidated
[post_id]: 325611
[parent_id]: 
[tags]: 
Endogeneity of variables in non-linear prediction models

I am new to R and try to predict customer returns for unknown data based on a known dataset. For feature selection and engineering I used the Random Forest (RF) based importance scores, which showed that the average number of returns for a particular customer is highly relevant for predicting their returns. I am using non-linear prediction methods (Artificial Neural Networks, RF) and was wondering whether the use of average returns for each customer as an explanatory variable may cause problems for obtaining accurate/stable partial effects (via dependence plots) or accurate/stable predictions. If so, is there a way to a) detect whether the problem does in fact exist? b) solve this problem without discarding the variable if a) is affirmative? I know that endogeneity of variables in a linear model (e.g., regression) is not a problem for prediction but makes it impossible to estimate partial effects (beta coefficients) with normal OLS. Hence my question.
