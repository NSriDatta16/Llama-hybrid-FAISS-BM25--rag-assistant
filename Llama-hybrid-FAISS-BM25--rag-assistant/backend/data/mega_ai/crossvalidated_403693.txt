[site]: crossvalidated
[post_id]: 403693
[parent_id]: 
[tags]: 
Are covariates in a mixed model estimated between-group, within-group, or somewhere in-between? And why?

Consider a linear (perhaps mixed) model where we have one factor $p$ , one covariate $x$ , and no interaction. I want to understand how the coefficient estimate $\hat\beta$ of $x$ , and its standard error, are affected by the decision to make $p$ random or fixed. That is, how the factor 's type affects the inference on the covariate . Intuitively, it feels to me that a model with a fixed $p$ should give the same $\hat\beta$ as one with random $p$ . My reasoning for this is that with no interaction, we are declaring that $\beta$ should be the same across all levels of $p$ , so it shouldn't matter how many levels $p$ has, nor whether it is random or fixed. Playing with toy examples, I have found this to be the confirmed in all but cases with small datasets and correlation between $x$ and $p$ . More specifically: for large datasets, random and fixed $p$ give the same $\hat\beta$ . For tiny datasets, a model with random $p$ gives the same $\hat\beta$ as one where $p$ is left out altogether (call this the "pooled model"). For some boundary cases in-between, $\hat\beta$ cones out part-way between the two. Mathematically, I'm totally happy with why these exceptions happen: because there is a likelihood cost to magnifying the effects of the random factor, and not for the fixed factor. When we don't have enough evidence to support expanding the random factor, it is as if it weren't there. But intuitively, as to how to understand $\hat\beta$ in these cases, I'm stumped. In some cases $\hat\beta$ seems to represent the within-group slope, in others the between-group slope, and in others it is somewhere in-between. It has echoes of partial pooling, but I don't think the same logic applies here. This realisation has undermined my confidence in interpreting a specific real-world example I'm dealing with. The following code and graph gives an example of one of these boundary cases, which I find particularly hard to justify. Lines represent $\hat\beta$ in the fixed (magenta), pooled (blue) and mixed (black) models, and the mixed model gives us a $\hat\beta$ in no-man's land in-between the other two: Code to generate Graph library(lme4) set.seed(1) beta = -1 sigma = 5 nppt = 5 nperppt = 10 generatedataforppt = function(ppt,n){ x = rnorm(n)+ppt y = beta*x + 3*ppt + rnorm(n,sd=sigma) cbind(x=x,y=y,p=ppt) } data = as.data.frame(do.call(rbind,lapply(1:nppt,generatedataforppt,nperppt))) plot(y~x,data=data,pch=data $p) data$ p = factor(data$p) pooled.model = lm( y~x, data=data) fixed.model = lm( y~x+p-1, data=data) mixed.model = lmer(y~x+(1|p), data=data) abline(coefficients(pooled.model)[1], coefficients(pooled.model)[2], col="blue", lwd=3) abline(coefficients(fixed.model)[2], coefficients(fixed.model)[1], col="magenta", lwd=3) abline(coefficients(mixed.model) $p[1,1], coefficients(mixed.model)$ p[1,2], col="black", lwd=3)
