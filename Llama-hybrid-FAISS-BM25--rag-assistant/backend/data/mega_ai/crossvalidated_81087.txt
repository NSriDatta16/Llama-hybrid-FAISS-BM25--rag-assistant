[site]: crossvalidated
[post_id]: 81087
[parent_id]: 81074
[tags]: 
The CLT certainly informs applications all the time, since we deal with distributions of averages or sums very frequently (including in cases that may not be always obvious; for example, $s_n^2$ - the sample variance with denominator $n$ - is an average, and so the ordinary sample variance is just a slightly rescaled average). The CLT can tell you to expect an approach to normality with increasing sample size for a particular statistic, but not when , exactly, you can treat it as normal. So while you know that normality should kick in eventually, to know if you're close enough at a particular sample size, you will need to check (say algebraically, or more often via simulation). You may sometimes run into 'rules of thumb' that say "oh, n=30 is enough for the central limit theorem to kick in". Such rules are nonsense without specifying the exact circumstances (what the distribution is we're dealing with, and what properties we care about, and 'how close is close enough'). If you have an $X$ with a distribution like this: Then sample means, $\bar X$ for $n=1000$ have a shape like this: ... which for some purposes might be just about okay to treat as normal (proportion within 2 s.d.s of the mean, say); for other purposes (probability of being more than 3 s.d.s above the mean, say), perhaps not. Sometimes n=2 is plenty, sometimes n=1000 isn't enough. Another example: the sample third and fourth moments are averages and so the CLT should apply. The Jarque-Bera test relies on that (plus Slutsky, I guess, for the denominator, along with asymptotic independence), in order to obtain a chi-square distribution for the sum of squares of standardized values. But as Bowman and Shenton had pointed out (5 years before!), this shouldn't be expected to work well until large sample sizes. Indeed my own simulations suggest that for normal data, bivariate normality of the skewness and kurtosis doesn't kick in well until the sample sizes are surprisingly large (at small and middling sample sizes, the contours of the joint distribution look more like a banana than a watermelon) Increasingly often, however, sample sizes can be huge. I've helped with several real-data problems where the sample sizes were very large indeed (in the millions). In those situations, things the CLT suggests should approach the normal as $n$ approaches infinity are often extremely well approximated by normal distributions. I wouldn't say the CLT is useless - it tells you what distribution to look for - but it doesn't do more than point to it as an eventual outcome; you still have to check whether it's a suitable approximation for your purposes at the sample size you have.
