[site]: crossvalidated
[post_id]: 324213
[parent_id]: 324107
[tags]: 
There is no reason for these to be exactly the same. The only similarity I can see in here is being used in dimensionality reduction and hidden variable estimation. A FA has Gaussian assumption and usually uses a Gaussian likelihood and Expectation-Maximization for optimization and learning the factor matrices. An Auto-encoder is totally a different story. It's a neural network, often with non-linearities, trained with gradient descent, often with the objective of mean squared error to reconstruct the input. There's no reason whatsoever these two have to converge to the same solution, unless for a very specific problem where the optimum solution for both methods are exactly the same, which is quite unlikely. Since the objectives and the optimizers (and even structures, considering nonlinearity in NNs) are not the same, there is no guarantee that the parameters learned (weights) should be the same, or even have similar properties. Also judging based on value similarities is not a good measure. If you want to compare two methods, perhaps try to use measures like eigen values of the covariance or such, or run some experiments and compare the empirical results. You could perhaps compare FA with PCA, with a prior, which indeed have similarities, but still not the same. Comparing FA with an AE is a bit out of context.
