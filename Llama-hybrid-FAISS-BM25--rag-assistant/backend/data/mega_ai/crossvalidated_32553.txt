[site]: crossvalidated
[post_id]: 32553
[parent_id]: 32522
[tags]: 
I think it might be helpful to your intuition to think of a mixed model as a hierarchical or multilevel model . At least to me, it makes more sense when I think of nesting and how the model is working within and across categories in a hierarchical manner. EDIT: Macro, I had left this a little open-ended because it does help me view it more intuitively, but I'm not sure it's correct. But to expand it in possibly incorrect directions... I look at it as fixed effects averaging across categories and random effects distinguishing between categories. In some sense, the random effects are "clusters" that share some characteristics, and larger and more compact clusters will have greater influence over the average at the higher level. With OLS doing the fitting (in phases, I believe), larger and more compact random effect "clusters" will thus pull the fit more strongly towards themselves, while smaller or more diffused "clusters" will pull the fit less. Or perhaps the fit begins closer to larger and more compact "clusters" since the higher-level average is closer to begin with Sorry I can't be clearer, and may even be wrong. It makes sense to me intuitively, but as I try to write it I'm not sure if it's a top-down or bottom-up thing, or something different. Is it a matter of lower-level "clusters" pulling fits towards themselves more strongly, or of having greater influence over the higher-level averaging -- and thus "ending up" nearer to the higher-level average -- or neither? In either case, I feel that it explains why smaller, more diffuse categories of random variables will be pulled farther towards the mean than larger, more compact categories.
