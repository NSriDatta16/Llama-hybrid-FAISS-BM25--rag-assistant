[site]: crossvalidated
[post_id]: 122891
[parent_id]: 122656
[tags]: 
My cursory search did not find this option either. As you describe the problem, you want to use: An imbalanced dataset (85:15). Random Forest. ROC and AUC-based loss definitions. Weka. Let's try to relax one condition at a time. Here are some possible alternatives: Intentionally skew the data: take all the instances from the 15% label and sample a similar number from the other label. Say you have 850 yellow instances and 150 blue, take all the blue instances and sample 150 yellow ones. Then train a random forest using Weka. You can use bootstrap resampling if you want to diversify the data. Use a cost-sensitive classifier, and mark the cost of false negatives higher. cost-sensitive classification in Weka Use a different loss function. Like you, I could not find how to do this for the current framework/algorithm combination. Use a different algorithm. SGD in Weka can use different loss functions. Use a different ML framework. scikit-learn seems more flexible, but I am unsure whether its implementation of random forest allows for ROC curve-based loss.
