[site]: crossvalidated
[post_id]: 421069
[parent_id]: 421058
[tags]: 
I realize this bias will vanish in larger samples because the mismatches will average out, but I think it will vanish slower if the slopes are steep and, at least in my work, it could be confused for confounding bias in small samples. If $X$ and $T$ are independent, then there is no bias, for any sample size: $$E[Y|T=1] - E[Y|T=0] = \delta + \beta_x (E[X|T=1] - E[X|T=0]) = \delta$$ The effect you're describing does make the difference in treated and control units a worse estimator of $\delta$ , however, because it increases its variance. Randomly, if not systematically, the $X$ values of treated units will differ from the $X$ value of control units, and that difference will end up causing a difference in $Y$ as well. This increases the variability of treatment and control units and so also the variability of their difference: $$Var(Y|T=1) = Var(Y|T=0) = \beta_x ^2 Var(X)$$ As you can see, a larger $\beta_x$ will translate into more variability in the difference of outcomes that isn't due to the treatment effect $\delta$ , making it a worse estimator. This is why it's often recommend that you add $X$ to the model even when you run an experiment which guarantees $T$ is not confounded by $X$ . Controlling for $X$ will reduce the variance and gives a more precise estimator. The stronger $X$ predicts $Y$ ( $\beta_x$ larger), the larger the gains in precision if you include $X$ in the model.
