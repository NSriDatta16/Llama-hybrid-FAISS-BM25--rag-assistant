[site]: crossvalidated
[post_id]: 567163
[parent_id]: 530044
[tags]: 
I am trying to understand what you thought on the application of ResNet. As far as I am concerned, the residual block which contains two type of connections. The first one is the identify block which is just a shortcut connection of input tensor. Another one is the convolution block which needs to be downsampled so that the input tensor can have same shape when it adds to the output of the convolution layers in the residual block. When to use either of them depends on the condition which typically is between the each hop of residual blocks. You don't necessarily use average pooling or maxpooling within a residual block since the stride=2 downsamples the shape of input tensor. On the other hand, you need to use AdaptiveAvgPool() and Flatten() in the final layer.
