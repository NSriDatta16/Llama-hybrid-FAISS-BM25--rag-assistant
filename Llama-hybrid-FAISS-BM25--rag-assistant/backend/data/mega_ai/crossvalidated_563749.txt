[site]: crossvalidated
[post_id]: 563749
[parent_id]: 563665
[tags]: 
What you are effectively doing here is assuming a different model for the distribution of $y$ . In the first approach, this distribution is assumed to be $$y|x,\theta \sim p(y|x,\theta)$$ While in the second approach it is $$ y|x,\mu,\Sigma \sim \int p(y|x,\theta)p(\theta|\mu,\Sigma) d\theta.$$ In this case you can think of each sample of $y$ as being generated by first generating $\theta$ from $p(\theta|\mu,\Sigma)$ and then generating $y$ from $p(y|x,\theta)$ . Furthermore, in the first case you calculate the posterior probably of $\theta$ , which you can do analytically because the model is linear and the distribution is normal, While in the second case you only find the MLE of $\mu$ and $\Sigma$ - this model is not linear (in $\Sigma$ ) and you are not doing a Bayesian calculation (finding the joint posterior probability of $\mu$ and $\Sigma$ ). Now what is the meaning of the second model ? you can consider it as a family of distributions where the linear model is the special case where $\Sigma \to 0$ (such that $p(\theta|\mu,\Sigma)$ becomes a delta function). That is, by estimating $\Sigma$ (via its MLE) you are estimating how 'non-linear' your data is. This might be a sensible thing, but of course there are many other ways to model non-linearity in the data, and ones where you can do a full Bayesian analysis, so it is not clear what you are gaining here. Also, based on your initial question, it doesn't seems that this generative process describes your knowledge on how the $y$ samples are actually being generated.
