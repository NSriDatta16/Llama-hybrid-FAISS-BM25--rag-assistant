[site]: stackoverflow
[post_id]: 1235986
[parent_id]: 1235861
[tags]: 
Your last paragraph is the typical way it needs to be done. The usual suspects in this field (at least as far as I know for market data (wall street) latency) are: TSA (TS Associates) Correlix Corvil Napatech (hardware capture devices) Endace (hardware capture devices) There was another badly run company that recently burned through their VC money (4 million?). For data that is processed (let's say at a direct exchange feed or RMDS or other server that changes the protocol) into different formats you need to be able to parse the payloads to correlate the messages. It can be challenging since sometimes data vendors do not expose the message definitions. I think there are hardware devices that will inject payload information with timestamps in it so the client can see these. Of course, as another poster pointed out - the question of time is very important. All the devices and clients have to have the same reference point for time. It has to be accurate... The last time I spoke with TSA, an installation with 4 observation points was on the order of $150k. I suspect that the others listed above are similar in price. The hardware cards listed above start around $2k (for a bare bones card) and go up (significantly) from there. To do it in software you'd need to have clients using pcap (or something similar) and look at the payloads and try to match them up. In some cases it is difficult to get this to be deterministic - especially at the start of a "session" or if messages are missing from one pipe. Usually after some threshold if you don't match something, you just drop it. EDIT: DISCLAIMER: I am also part of the venture now and should disclose that.
