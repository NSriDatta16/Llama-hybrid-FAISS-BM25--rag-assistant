[site]: crossvalidated
[post_id]: 311810
[parent_id]: 
[tags]: 
how to measure mutual information in deep neural network

I'm considering how to measure mutual information between layers in deep neural network. For example, in a MNIST dataset, with few layers of network. I simply flatten each layer to 1d array and calculate their entropy. And the mutual information should be the different between two layers' entropy. This is for single input. And I just randomly choose, say, 1000 inputs from the whole dataset, and calculate the avg mutual information of those inputs. It's the simplest way I can come out with. Is it reasonable? Or any better advice?
