[site]: crossvalidated
[post_id]: 549520
[parent_id]: 549509
[tags]: 
One counterexample is when there's no consistent estimator. Suppose $X_i\sim N(\mu_i,1)$ where $\mu_i$ are all distinct unknown parameters. The UMVUE of any $\mu_i$ is $X_i$ , but it's not consistent. You can make matters worse. Suppose you a have single $X\sim N(\theta,1)$ together with $Y_i\sim\text{Bernoulli}(p)$ with $\mathrm{logit}\,p=\theta$ for $i=1,\dots,n$ . Then $\mathrm{logit}\, \bar Y_n$ is a consistent estimator for $\theta$ as $n\to\infty$ , but no function of $Y_i$ is unbiased for $\theta$ . This means the UMVUE of $\theta$ is just $X$ , which is not consistent. However, for iid $X_i$ , $i=1,\dots,n$ , if we assume there exists some unbiased estimator $\tilde\theta$ that has finite variance for all $n$ greater than some $n_0$ , the MVUE must be consistent. We can divide the $n$ observations into $[n/n_0]$ blocks of size at least $n_0$ and take the average of $\tilde\theta$ for each block. If $\sigma^2$ is the variance of each block-specific $\tilde\theta$ then the variance of the average is $\sigma^2/[n/n_0]$ , which goes to zero as $n\to\infty$ . So there is a consistent unbiased estimator and so the MVUE is also consistent.
