[site]: crossvalidated
[post_id]: 16647
[parent_id]: 16646
[tags]: 
A) What is the best single index of the degree to which the data violates normality? B) Or is it just better to talk about multiple indices of normality violation (e.g., skewness, kurtosis, outlier prevalence)? I would vote for B. Different violations have different consequences. For example, unimodal, symmetrical distributions with heavy tails make your CIs very wide and presumably reduce the power to detect any effects. The mean, however, still hits the "typical" value. For very skewed distributions, the mean for example, might not be a very sensible index of "the typical value". C) How can confidence intervals be calculated (or perhaps a Bayesian approach) for the index? I don't know about Bayesian statistics, but concerning classical test of normality, I'd like to cite Erceg-Hurn et al. (2008) [2]: Another problem is that assumption tests have their own assumptions. Normality tests usually assume that data are homoscedastic; tests of homoscedasticity assume that data are normally distributed. If the normality and homoscedasticity assumptions are violated, the validity of the assumption tests can be seriously compromised. Prominent statisticians have described the assumption tests (e.g., Levene’s test, the Kolmogorov–Smirnov test) built into software such as SPSS as fatally flawed and recommended that these tests never be used (D’Agostino, 1986; Glass & Hopkins, 1996). D) What kind of verbal labels could you assign to points on that index to indicate the degree of violation of normality (e.g., mild, moderate, strong, extreme, etc.)? Micceri (1989) [1] did an analysis of 440 large scale data sets in psychology. He assessed the symmetry and the tail weight and defined criteria and labels. Labels for asymmetry range from 'relatively symmetric' to 'moderate --> extreme --> exponential asymmetry'. Labels for tail weight range from 'Uniform --> less than Gaussian --> About Gaussian --> Moderate --> Extreme --> Double exponential contamination'. Each classification is based on multiple, robust criteria. He found, that from these 440 data sets only 28% were relatively symmetric, and only 15% were about Gaussian concerning tail weights. Therefore the nice title of the paper: The unicorn, the normal curve, and other improbable creatures I wrote an R function, that automatically assesses Micceri's criteria and also prints out the labels: # This function prints out the Micceri-criteria for tail weight and symmetry of a distribution micceri cat.tail[,i]) + 1)} ss cat.sym[,i]) + 1)} tlabels Here's a test for the standard normal distribution, a $t$ with 8 df, and a log-normal: > micceri(rnorm(10000)) Tail weight indexes: 97.5% 95% 90% Q Q1 2.86 2.42 1.88 2.59 1.76 Micceri category: About Gaussian Asymmetry indexes: Skewness MM.75% Q2 0.01 0.00 1.00 Micceri category: Relatively symmetric > micceri(rt(10000, 8)) Tail weight indexes: 97.5% 95% 90% Q Q1 3.19 2.57 1.94 2.81 1.79 Micceri category: Extreme contamination Asymmetry indexes: Skewness MM.75% Q2 -0.03 0.00 0.98 Micceri category: Relatively symmetric > micceri(rlnorm(10000)) Tail weight indexes: 97.5% 95% 90% Q Q1 6.24 4.30 2.67 3.72 1.93 Micceri category: Double exponential contamination Asymmetry indexes: Skewness MM.75% Q2 5.28 0.59 8.37 Micceri category: Exponential asymmetry [1] Micceri, T. (1989). The unicorn, the normal curve, and other improbable creatures. Psychological Bulletin, 105 , 156-166. doi:10.1037/0033-2909.105.1.156 [2] Erceg-Hurn, D. M., & Mirosevich, V. M. (2008). Modern robust statistical methods: An easy way to maximize the accuracy and power of your research. American Psychologist, 63 , 591-601.
