[site]: crossvalidated
[post_id]: 477155
[parent_id]: 477152
[tags]: 
The mean squared error is the cross-entropy between the data distribution $p^*(x)$ and your Gaussian model distribution $p_{\theta}$ . Note that the standard MLE procedure is: $$ \begin{align} \max_{\theta} E_{x \sim p^*}[\log p_{\theta}(x)] &= \min_{\theta} \left(- E_{x \sim p^*}[\log p_{\theta}(x)]\right)\\ &= \min_{\theta} H(p^* \Vert p_{\theta}) \\ &\approx \min_{\theta} \sum_i \frac{1}{2} \left(\Vert x_i - \theta_1\Vert^2/\theta_2^2 - \log 2 \pi \theta_2^2\right) \end{align} $$ Where $H(p^* \Vert p_{\theta})$ denotes the CE and we use a Monte Carlo approximation to the expectation. And as you stated, this is equivalent to minimizing the KL divergence between the data distribution and your model distribution. Commonly the variance $\theta_2$ is fixed and drops out of the objective. Some people get confused because certain textbooks introduce the cross-entropy in terms of the Bernoulli/Categorical distribution (almost all machine learning libraries are guilty of this!), but it applies more generally than the discrete setting.
