[site]: crossvalidated
[post_id]: 1385
[parent_id]: 
[tags]: 
Techniques for Handling Incomplete/Missing Data

My question is directed to techniques to deal with incomplete data during the classifier/model training/fitting. For instance, in a dataset w/ a few hundred rows, each row having let's say five dimensions and a class label as the last item, most data points will look like this: [0.74, 0.39, 0.14, 0.33, 0.34, 0] A few might look something like this: [0.21, 0.68, ?, 0.82, 0.58, 1] So it's those types of data points that are the focus of this Question. My initial reason for asking this question was a problem directly in front of me; however, before posting my Question, i thought it might be more useful if i re-phrased it so the answers would be useful to a larger portion of the Community. As a simple heuristic, let's divide these data-handling techniques based on when during the processing flow they are employed--before input to the classifier or during (i.e., the technique is inside the classifier). The best example i can think of for the latter is the clever 'three-way branching' technique used in Decision Trees. No doubt, the former category is far larger. The techniques i am aware of all fall into one of the groups below. While recently reviewing my personal notes on "missing data handling" i noticed that i had quite an impressive list of techniques. I just maintain these notes for general peace of mind and in case a junior colleague asks me how to deal with missing data. In actual practice, i don't actually use any of them, except for the last one. Imputation : a broad rubric for a set of techniques which whose common denominator (i believe) is that the missing data is supplied directly by the same data set--substitution rather than estimation/prediction. Reconstruction : estimate the missing data points using an auto-associative network (just a neural network in which the sizes of the input and output layers are equal--in other words, the output has the same dimension as the input); the idea here is to train this network on complete data, then feed it incomplete patterns, and read the missing values from the output nodes. Bootstrapping : (no summary necessary i shouldn't think, given it's use elsewhere in statistical analysis). Denial : quietly remove the data points with missing/corrupt elements from your training set and pretend they never existed.
