[site]: crossvalidated
[post_id]: 552068
[parent_id]: 355781
[tags]: 
As noted in cdalitz's answer, the percentile bootstrap gives better confidence intervals than the empirical/basic bootstrap quite often. I'd now like to offer a justification as to why this is the case. I'm unaware of a frequentist justification for the percentile bootstrap. However, the percentile bootstrap (or a close cousin) can easily be derived from a Bayesian point of view. The Bayesian bootstrap assumes that: Before observing any data, any possible data point is equally probable. There is no "smoothing" of the data -- any new information or data that increases the probability of $x$ has no bearing on the probability that the next data point will equal $x + .0000...1$ . Let's say that we have a probability of $p$ assigned to the observed values, and a probability $1-p$ for the infinitely many values that were not observed. By an abuse of infinities that would make any mathematician cry, this means all the points not observed have a probability of $(1-p)/\infty$ , i.e. 0. So we ignore any data points that did not show up in our data, and instead assume that the probability is spread out equally over the observed data. (This can be made sensible by talking about a limit of Dirichlet processes, which I'll avoid getting into here.) The maximum entropy distribution to assign to the data is then a uniform distribution (more precisely, a Dirichlet distribution with $\alpha = 1$ ), so this is the most justifiable way to spread out the probability among the observations. Having done this, we can simulate our posterior by drawing random frequencies for each observed value from this uniform distribution. One way to think about this is that the Bayesian bootstrap assumes the observed empirical distribution is equal to the actual likelihood function, and updates accordingly. This gives us a posterior that looks very similar to the frequentist percentile bootstrap. Some Bayesians have argued that Haldane's distribution is a less informative prior than the uniform distribution; if you use Haldane's distribution, you get the percentile bootstrap exactly . In practice the two will hardly differ for any reasonable sample size. So if you'd like to interpret your bootstrap distribution as an approximate posterior, the percentile bootstrap does a better job than the basic/empirical bootstrap.
