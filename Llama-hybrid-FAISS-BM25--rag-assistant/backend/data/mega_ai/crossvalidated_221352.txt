[site]: crossvalidated
[post_id]: 221352
[parent_id]: 221332
[tags]: 
The sum of the squares of the fractions (to let your text align with your arithmetic) is indeed a much re-discovered or re-invented measure of the concentration of distributions divided into distinct categories. It is now in its second century at least, allowing a little latitude to include under the same umbrella its complement and its reciprocal: all three versions have easy interpretations and uses. There are (wild guess) perhaps twenty different names for it in common use. Let's write generically $p$ for proportion or probability, where necessarily $1 \ge p_s \ge 0$ and $\sum_{s=1}^S p_s \equiv 1$ . Your measure is $\sum_{s=1}^S p_s^2 =: R$ . At least for biologists the index $s=1, \dots, S$ is mnemonic for species. Then that sum is for ecologists the Simpson index (after E.H. Simpson, 1922-2019, the person for whom Simpson's paradox is named); for economists it's the Herfindahl-Hirschman index; and so on. It has a long history in cryptography, often clouded in secrecy for decades by its use in classified problems, but most famously featuring A.M. Turing. I.J. Good (who like Simpson worked with Turing in World War II) called it the repeat rate, which motivates the symbol $R$ above; for D.J.C. MacKay it is the match probability. Suppose we rank the proportions $p_1 \ge \dots \ge p_S$ . Then at one extreme $p_1$ grows to $1$ and the other $p_s$ shrink to $0$ and then $R = 1$ . Another extreme is equal probabilities $1/S$ so that $R = S (1/S^2) = 1/S$ . The two limits naturally coincide for $S = 1$ . Thus for $2, 10, 100$ species $R \ge 0.5, 0.1, 0.01$ respectively. The complement $1 - R$ was one of various measures of heterogeneity used by Corrado Gini, but beware serious overloading of terms in various literatures: the terms Gini index or coefficient have been applied to several distinct measures. It features in machine learning as a measure of impurity of classifications; conversely $R$ measures purity. Ecologists usually talk of diversity: $R$ measures diversity inversely and $1 - R$ measures it directly. For geneticists $1 - R$ is the heterozygosity. The reciprocal $1/R$ has a 'numbers equivalent' interpretation. Imagine as above any case in which $S$ species are equally common with each $p_s = 1/S$ . Then $1/R = 1/\sum_{s=1}^S (1/S)^2 = S$ . By extension $1/R$ measures an equivalent number of equally common categories, so that for example the squares of $1/6, 2/6, 3/6$ give $1/R \approx 2.57$ which matches an intuition that the distribution is between $2/6, 2/6, 2/6$ and $3/6,3/6, 0$ in concentration or diversity. (The numbers equivalent for Shannon entropy $H$ is just its antilogarithm, say $2^H, \exp(H)$ or $10^H$ for bases $2, e = \exp(1)$ and $10$ respectively.) There are various generalisations of entropy which make this measure one of a wider family; a simple one given by I.J. Good defines the menagerie $\sum_{s} p_s^a\ [\ln (1/p_s)]^b$ from which $a =2, b=0$ gives our measure; $a = 1, b=1$ is Shannon entropy; $a =0; b=0$ returns $S$ , the number of species present, which is the simplest measurement of diversity possible and one with several merits.
