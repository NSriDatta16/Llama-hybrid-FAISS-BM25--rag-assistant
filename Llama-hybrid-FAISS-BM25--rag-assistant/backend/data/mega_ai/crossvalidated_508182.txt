[site]: crossvalidated
[post_id]: 508182
[parent_id]: 506994
[tags]: 
I can get a 95% CI for pA and pB: pA: 0.398 [0.236, 0.697] pB: 0.607 [0.338, 0.971] I used MultinomCI which gives confidence intervals for multinomial proportions https://www.rdocumentation.org/packages/DescTools/versions/0.99.39/topics/MultinomCI I chose the Wilson interval because I think that it gives good coverage for binomial proportions so I guessed that it would be ok for this as well. In Python: import numpy as np import rpy2.robjects as ro from rpy2.robjects.packages import importr package_name = "DescTools" try: pkg = importr(package_name) except: ro.r(f'install.packages("{package_name}")') pkg = importr(package_name) pkg r_string = """CI = MultinomCI(c(11,0,6,11), conf.level=0.95, method="wilson") """ ro.r(r_string) R_C = ro.r['CI'] A_C = np.array(R_C) print(' ') print('Estimate, CI') print(A_C) print(' ') # Nomeclature: the estimate of A=1, B=1 with a 95% CI is E_11(L_11,H_11) E_11 = A_C[0][0] E_10 = A_C[1][0] E_01 = A_C[2][0] E_00 = A_C[3][0] L_11 = A_C[0][1] L_10 = A_C[1][1] L_01 = A_C[2][1] L_00 = A_C[3][1] H_11 = A_C[0][2] H_10 = A_C[1][2] H_01 = A_C[2][2] H_00 = A_C[3][2] print('sum prob = 1: ', (E_11+E_10+E_01+E_00)) print(' ') p_A = E_11 + E_10 p_B = E_11 + E_01 CI_A = [(L_11 + L_10), (H_11 + H_10)] CI_B = [(L_11 + L_01), (H_11 + H_01)] print('pA: ', p_A) print('CI_A: ', CI_A) print(' ') print('pB: ', p_B) print('CI_B: ', CI_B) print(' ') print('Improvement (I) = pB/pA-1: ', p_B/p_A-1) Now to try and get a 95% CI for: Improvement (I) = pB/pA-1 I think that I first need to fit skew normal distributions to pA and pB: import numpy as np from scipy.stats import skewnorm from scipy.optimize import differential_evolution import matplotlib.pyplot as plt pA = 0.398 pB = 0.607 CI_A = [0.236,0.697] CI_B = [0.338,0.971] print('fit a distribution...') def fun(z): Skew, Scale, loc = z lst = skewnorm.rvs(a=Skew, loc=loc, scale=Scale, size=1000) lst=lst.tolist() #mean = sum(lst)/len(lst) median = np.percentile(lst, 50) #mode = max(set(lst), key=lst.count) CI = [np.percentile(lst, 2.5), np.percentile(lst, 97.5)] # Error Me_E = median - pB Lo_E = CI[0] - CI_B[0] Hi_E = CI[1] - CI_B[1] error = Me_E**2 + Lo_E**2 + Hi_E**2 return error # Bounds of Skew, Scale & loc bounds = ((-1,1),(0.1,1),(0,1)) maxiter = 5000 # Optimiser DE = differential_evolution(fun,bounds,maxiter=maxiter) print('success = ',DE.success) print(DE.message) Skew = DE.x[0] Scale = DE.x[1] loc = DE.x[2] print('skewness parameter = ',Skew) print('scale = ',Scale) print('loc = ',loc) print('Sampling from the skew normal distribution') lst = skewnorm.rvs(a=Skew, loc=loc, scale=Scale, size=1000) lst=lst.tolist() mode = max(set(lst), key=lst.count) print('mode = ',mode) mean = sum(lst)/len(lst) print('mean = ',mean) median = np.percentile(lst, 50) print('median = ',median) CI = [np.percentile(lst, 2.5), np.percentile(lst, 97.5)] print('CI = ',CI) fig, ax = plt.subplots(1, 1) ax.hist(lst) plt.show() That gives distribution parameters that give almost the same pA & pB: pA: 0.423 [0.205, 0.642] pB: 0.607 [0.336, 0.928] Figure 1, pA and pB Next, I combine the two distributions to get the CI for Improvement (I) = pB/pA-1 from scipy.stats import skewnorm import matplotlib.pyplot as plt import numpy as np fig, ax = plt.subplots(1, 1) A_ske = 0.9139952525939643 A_sca = 0.13849932254197161 A_loc = 0.3500567328083086 B_ske = 0.9960244237545532 B_sca = 0.18411099887378107 B_loc = 0.5126020868512271 Step = 0.001 ExeS = np.linspace(0+Step,1-Step,1/Step-1) print('Inverse CDF transform') A_val = skewnorm.ppf(q=ExeS, a=A_ske, loc=A_loc, scale=A_sca) B_val = skewnorm.ppf(q=ExeS, a=B_ske, loc=B_loc, scale=B_sca) # Improvement Improv = np.divide(B_val,A_val) Improv = Improv -1 CI = [np.percentile(Improv, 2.5), np.percentile(Improv, 97.5)] print('CI = ',CI) A_PDF = {} B_PDF = {} for x in ExeS: A_PDF[x] = skewnorm.pdf(x=x, a=A_ske, loc=A_loc, scale=A_sca) B_PDF[x] = skewnorm.pdf(x=x, a=B_ske, loc=B_loc, scale=B_sca) # Dict to Lists labels, A_data = [*zip(*A_PDF.items())] labels, B_data = [*zip(*B_PDF.items())] # Plot ax.plot(ExeS, A_data, label='A', linewidth=5, color='k', linestyle='-') ax.plot(ExeS, B_data, label='B', linewidth=5, color='k', linestyle='--') for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()): item.set_fontsize(22) legend = ax.legend(loc=0, ncol=1, bbox_to_anchor=(0.6, -.3, 1, 1), fancybox=True, shadow=False, framealpha=1, fontsize=22) plt.setp(legend.get_title(),fontsize=22) plt.xlabel(' $x$ ') plt.ylabel(' $P$ ') plt.grid(b=True, which='major', color='b') plt.xlim([0,1]) plt.ylim([0,4]) fig = plt.gcf() fig.set_size_inches(4,4) plt.show() plt.clf() This method assumes that the sample is just as representative of the population for method A as it is for method B. This is the other extreme from assuming independence. This gave a different improvement CI each time I ran it: [40%,62%] [41%,60%] [41%,49%] [43%,68%] [39%,48%]
