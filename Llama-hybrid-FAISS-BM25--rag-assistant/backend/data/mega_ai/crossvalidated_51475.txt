[site]: crossvalidated
[post_id]: 51475
[parent_id]: 
[tags]: 
Series dimensionality reduction for classification Input

I am looking to construct a predictive model where the outcome variable is binary and the input is time series. To make it more concrete, the model will predict if a customer churns (left the company; coded as 1 or 0) based on the amount they spent with the company in the prior 60 days. So, the data is one customer per row and the columns are an outcome factor (1 or 0) and 60 additional columns for the amount spent the in time t-1, t-2....t-60. Here is some example data: #create the data a series of length 60 and a class ID sc The actual model may have many of these series for each customer, so I need to reduce the dimensionality of the data for the series, e.g. instead of using 60 values, I need to reduce this down to a handful. Of course, I can use the mean, min, max etc of the series but I have been reading about using Discrete Fourier Transform. Questions: Is the DFFT in R a proper method to use for my purpose? Any information on how it works would be appreciated. Assuming this R function is correct, how do you extract just the most meaningful coefficients to achieve dimensionality reduction? ADD: There seems to be a consensus that using DFFT for dimension reduction is not a wise choice, but it seems that in data mining, this function, DWT and SVD are all commonly used: Time Series Mining starting on page 20.
