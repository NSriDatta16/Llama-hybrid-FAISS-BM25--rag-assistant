[site]: datascience
[post_id]: 86061
[parent_id]: 77588
[tags]: 
There are two common options: Stratified sampling within each batch. Regardless of batch size, make sure each group is equally represented. The downside this approach is that it would significantly slow down training. Train with increased batch size (say 32-256) and over the course of the epochs the random fluctuations will "average" out.
