[site]: stackoverflow
[post_id]: 323125
[parent_id]: 323079
[tags]: 
On the subject of LINQ in general - again, a good fit due to your size issues: Just some notes on the scale, each billing system produces roughly 6 million records / day at a total file size of about 1 gig. LINQ can be used fully with streaming solutions. For example, your "source" could be a file reader. The Where would then iterate over the data checking individual rows without having to buffer the entire thing in memory: static IEnumerable ReadFoos(string path) { return from line in ReadLines(path) let parts = line.Split('|') select new Foo { Name = parts[0], Size = int.Parse(parts[1]) }; } static IEnumerable ReadLines(string path) { using (var reader = File.OpenText(path)) { string line; while ((line = reader.ReadLine()) != null) { yield return line; } } } This is now lazy loading... we only read one line at a time. You'll need to use AsQueryable() to use it with dynamic LINQ, but it stays lazy. If you need to perform multiple aggregates over the same data, then Push LINQ is a good fit; this works particularly well if you need to group data , since it doesn't buffer everything. Finally - if you want binary storage, serializers like protobuf-net can be used to create streaming solutions. At the moment it works best with the "push" approach of Push LINQ, but I expect I could invert it for regular IEnumerable if needed.
