[site]: crossvalidated
[post_id]: 220941
[parent_id]: 220933
[tags]: 
This is an issue even if the "quality of observations" (noise in predictors) is identical for every observation -- you have an errors in variables problem which will bias your estimates if you don't account for it properly. Stefanski and Carroll (1985)[1] (paper is open access) discuss several estimators for the errors-in-variables case for logistic regression. They perform a simulation study which indicates different estimators perform better (in terms of bias and efficiency) in different circumstances. (The estimators have reduced bias at the cost of some efficiency when the errors-in-x are zero.) They do include in their study a case where the precision can vary (a contaminated normal model). However, they did not discuss the case where the relative uncertainties in the X's were varying-but-known. Nevertheless this would be a good starting place. Aitken and Rocci (2002)[2] discuss general ML estimation and give an example of a case with Bernoulli response. Their approach looks like it may be useful for your situation. [I have not used any of these estimators myself. There are a number of other papers relating to measurement error models in logistic regression, enough that a complete survey would be lengthy for an answer here. These papers will tend to appear in references of papers that would be useful, and the terminology of these will provide a good starting place for search terms.] [1] Leonard A. Stefanski and Raymond J. Carroll (1985), "Covariate Measurement Error in Logistic Regression" Ann. Statist. , Vol 13 , No. 4 , 1335-1351. https://projecteuclid.org/euclid.aos/1176349741 [2] M. Aitkin and R. Rocci (2002), "A general maximum likelihood analysis of measurement error in generalized linear models" Statistics and Computing , April, Vol 12 , No 2 , pp 163-174 (You might also find some value in Roeder, Carroll & Lindsay (1996) "A semiparametric mixture approach to case–control studies with errors in covariables", JASA 91, 722–32.)
