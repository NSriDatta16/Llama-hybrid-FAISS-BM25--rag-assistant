[site]: crossvalidated
[post_id]: 267384
[parent_id]: 267069
[tags]: 
I'm not aware of any method which takes hints like "Variable X1 is more important than Variable X3". As the comments to the OP reflect, this isn't straightforwardly a Bayesian regression issue, since you're interested in weighting the inclusion of variables, not (directly) in weighting possible values of the coefficients. Three thoughts on what could be done: Use Bayesian Regression and give your preferred variables the usual priors, while giving non-preferred variables sparsity-inducing priors such as the Horseshoe. I don't know if this would actually work, but the idea would be to give the non-preferred variables more opportunity to have their coefficients be driven to zero. Modify a LARS-style regression to weight the angles inversely-proportionally to whether they are favored variables or not. Modify a stepwise regression (I don't like stepwise, but it would be easier to modify) such that it prefers to add the preferred variables first. Or perhaps starts with the preferred variables in and then adds or subtracts the other variables in the steps. (See this other posting.)
