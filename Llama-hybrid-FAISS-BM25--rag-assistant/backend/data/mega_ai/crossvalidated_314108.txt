[site]: crossvalidated
[post_id]: 314108
[parent_id]: 
[tags]: 
back-propagation derivatives

In the 10th video of week3 of Ng course on Deep Neural Networks in coursera, there is a slide that i attached. Why he used elementwise product (vs normal matrix product) in this slide? Is it only for match-up of matrices for other products?
