[site]: datascience
[post_id]: 61310
[parent_id]: 
[tags]: 
What is the use of having shared weights in later layers of a CNN?

In a CNN, all the neurons in a single layer use the same weights and bias. As a result, all the neurons detect the same feature. The early layers of a CNN detect simple features like edges and hence it makes sense to use the same feature detector in all parts. But the later layers are shown to detect complex features. Since these need not occur in all regions of an image, what is the use of having shared weights and bias in later layers? Instead isn't it better to have separate weights and bias so that different features can be learnt in a single channel? Advantage of this over Fully Connected layers is that we are still making use of local receptive fields and the number of parameters are still less. For eg, in a face recognition network, suppose one of the feature detectors is to detect a certain type of eye. What is the use of using that detector at the bottom of the image? Since we already know eyes cannot occur at the bottom of a face.
