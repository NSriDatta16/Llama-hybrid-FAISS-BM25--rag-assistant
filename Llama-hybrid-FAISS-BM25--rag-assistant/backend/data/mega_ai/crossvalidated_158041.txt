[site]: crossvalidated
[post_id]: 158041
[parent_id]: 
[tags]: 
Having trouble understanding/implementing backpropagation algorithm

I have a simple feedforward neural network with 2 input neurons (and 1 bias neuron), 4 hidden neurons (and 1 bias neuron), and one output neuron . The feedforward mechanism seems to be working fine, but I have trouble fully understanding how to implement the backpropagation algorithm. There are 3 classes : Neural::Net ; builds the network, feeds forward input values (no backpropagation for the moment) Neural::Neuron ; has characteristics of the neuron (index, output, weight etc) Neural::Connection ; a structure-like class that randomizes the weights and hold the output, delta weight etc.. Now to make things clear, I take calculus class so I understand a few notions although this is quite advanced but I still want to make it work. The transfer function is a logistic function. The weights of the synapses are "attached" to the neuron outputting the value. This is my attempt at a back propagation function: void Net::backPropagate(const vector & targetVals) { Layer& outputLayer = myLayers.back(); assert(targetVals.size() == outputLayer.size()); cout 0; --i) { // Traversing hidden layers all the way to input layer Layer& currentLayer = myLayers[i]; Layer& nextLayer = myLayers[i + 1]; for (unsigned int j = 0; j I tried to train my network to: Input {1,1} -> Output {0} Input {0,0} -> Output {1} But the outputs for both are very close to 1 (~0.998) no matter how many times I train it so obviously something is wrong. Here is the full code: // STL_Practice.cpp : Defines the entry point for the console application. // #include #include #include #include #include #include "ConsoleColor.hpp" using namespace std; namespace Neural { class Neuron; typedef vector Layer; // ******************** Class: Connection ******************** // class Connection { public: Connection(); void setOutput(const double& outputVal) { myOutputVal = outputVal; } void setWeight(const double& weight) { myDeltaWeight = myWeight- weight; myWeight = weight; } double getOutput(void) const { return myOutputVal; } double getWeight(void) const { return myWeight; } private: static double randomizeWeight(void) { return rand() / double(RAND_MAX); } double myOutputVal; double myWeight; double myDeltaWeight; }; Connection::Connection() { myOutputVal = 0; myWeight = Connection::randomizeWeight(); myDeltaWeight = myWeight; cout & topology); void setTarget(const vector & targetVals); void feedForward(const vector & inputVals); void backPropagate(const vector & targetVals); void printOutput(void) const; private: vector myLayers; }; Net::Net(const vector & topology) { assert(topology.size() > 0); for (unsigned int i = 0; i & inputVals) { assert(myLayers[0].size() - 1 == inputVals.size()); for (unsigned int i = 0; i & targetVals) { Layer& outputLayer = myLayers.back(); assert(targetVals.size() == outputLayer.size()); cout 0; --i) { // Traversing hidden layers all the way to input layer Layer& currentLayer = myLayers[i]; Layer& nextLayer = myLayers[i + 1]; for (unsigned int j = 0; j myTopology; myTopology.push_back(2); myTopology.push_back(4); myTopology.push_back(1); cout
