[site]: datascience
[post_id]: 82435
[parent_id]: 
[tags]: 
Why an increasing validation loss and validation accuracy signifies overfitting?

When I train a neural network, I observe an increasing validation loss, while at the same time, the validation accuracy is also increased. I have read explanations related to the phenomenon, and it seems an increasing validation loss and validation accuracy signifies an overfitted model. However, I have not really grokked the reasons why an increasing validation loss and validation accuracy signifies an overfitting. Could you please give the explanations behind this phenomenon?
