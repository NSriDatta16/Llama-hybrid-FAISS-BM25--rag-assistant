[site]: datascience
[post_id]: 56667
[parent_id]: 
[tags]: 
How to define a neural model as linear or non linear

TL;DR : in what sense is the model of a neuron seen in the image above nonlinear? In chapter 1, section 1.3 MODELS OF A NEURON of Simon Haykin's Neural Networks book, the standard model of a single neuron is described and visualised in the picture above. Haykin states that this model, which consists of a set of inputs x1..xm, their corresponding weights w1..wm, a linear combiner that sums the weighted inputs and the bias (b) and an activation function that takes that sum and produces the output, is nonlinear. So, my question is, isn't the output linearly dependent on the input? For example, if the neuron only takes one input, x1, then the linear combiner takes the form v = x1 + b and the activation function is Ï†(v). So, the only way that I can see this model being nonlinear is if the activation function is nonlinear. But there are clearly cases where the activation function is linear (like the piecewise-linear function described in that same section of the book). So how can this model be inherently nonlinear? I realise that this isn't a major concern, but I'd like to understand every part of the book before moving on, and this has been bugging me since I saw it. Thanks to everyone in advance for your answers.
