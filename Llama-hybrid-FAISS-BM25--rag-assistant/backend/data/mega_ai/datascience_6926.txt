[site]: datascience
[post_id]: 6926
[parent_id]: 
[tags]: 
How to rank documents using Bag of words approach

I want to cluster the documents I get for Google scholar search using the Bag of words model. I thought of using Java as the language. Assume for the keyword k , Google scholar gives me 50 results. If I have a predefined set of words w1, w2, w3... wn, how can I rank the the documents which have the predefined set of words most? How can I apply Bag of words model for this? Do I need a clustering algorithm like k-means? And do I need to perform NLP techniques as well? Say that the word w1 has several synonyms. How can I consider those synonyms as well for document ranking? Will I have to create a corpus containing all the abbreviations, synonym etc for that? Are there any good tutorials available for this? Will choosing Java over Python will be an disadvantage since most of the resources (Ex - Scikit) were in Python?
