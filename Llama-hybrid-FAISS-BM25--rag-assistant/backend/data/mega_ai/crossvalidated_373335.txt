[site]: crossvalidated
[post_id]: 373335
[parent_id]: 
[tags]: 
How are support vectors in SVM equidistant?

In most literature on Support Vector Machines,we start with a decision boundary $\vec w\cdot \vec x+b=0$ . The support vectors are then assumed to lie on the planes $\vec w\cdot \vec x+b=1$ and $\vec w\cdot \vec x+b=-1$ . How can we assume that the support vectors will always be equidistant from the decision boundary? Or is it that the algorithm starts with two random points, assume that they are the support vectors, then call the median plane of the support vectors the decision boundary. I find it hard to visualize how the discovery of the best decision boundary in the second case can be analytical in nature.
