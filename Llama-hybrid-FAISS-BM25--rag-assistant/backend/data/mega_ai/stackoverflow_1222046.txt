[site]: stackoverflow
[post_id]: 1222046
[parent_id]: 1218986
[tags]: 
You will not be able to do this automatically with anything like 100% accuracy. The reason for this is that the only info you have is the colour which you know that some pixels in the image are attempting to blend nicely with. Only some pixels in the image will actually be using colours at or close to this value for the purposes of shading into the background, others will be using (in the case white) because the actual object represented are in fact white (damn the precision of these imperial storm troopers). The sort of sophisticated machine learning to detect which is which is an interesting problem domain, and might be a fun project for you but it certainly won't make for a quick solution to your immediate problem. The other problem you have is that, even if you could detect with good reliability those areas of the image which are attempting to blend into the back ground you will have issues 'unblending' them and then reblending them into your new background colour unless the colours are reasonably compatible. In this case your gray may work since it is a broad spectrum colour like the white. The technique you want to use is as follows: Use a flood fill algorithm to select, from the edges of the image inwards all pixels within x%(1) of the known backdrop colour. For those pixels set their alpha channel to a value as a proportion of their match to the original colour and eliminate the colour cast which was associated with it. So if the backdrop is RGB value a,b,c and the pixel is a+5,b,c-7 then the result is RGBA 5,0,0,((a+b+c-7)/(a+b+c)*256)(1) composite this alpha blending image over a pain square of the new back ground colur. render the result with no alpha channel as the new image. This will still have issues for objects whose colour is close to the either background colour. * in the case of the original then it may be that shadowing is being used to imply the presences of the object, as such the flood fill will 'invade' the inside of the image. * in the case of the latter the resulting image will lose definition of the object and no subtle shading, highlights or just plain lines will be present to indicate where the object ends and the back ground ends. This is a very rough first approximation but may cover a reasonable percentage of your target. Those pictures with transparent fully enclosed holes (like the gaps in the outer arch in your example) are not likely to ever work nicely in an automatic fashion since the algorithm will be unable to distinguish between white holes and white stormtrooper. You may wish to make you algorithm highlight the regions of the picture it plans on reblending and allow the simple selection of regions to include/exclude (using the magic wand selection tool from Pain.Net as an example of how to do this if you want to be fancy, allowing simple per pixel selection for less upfront effort. the value for x will be something you tune - it may be that, based on some aspects of the image (say the proportion of the image which is close to the back ground colour) you can tweak it automatically. Note that this formulae assumes a close to white colour, for close to black you would want to invert
