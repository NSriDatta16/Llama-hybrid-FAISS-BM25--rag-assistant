[site]: datascience
[post_id]: 6208
[parent_id]: 
[tags]: 
Working with inaccurate (incorrect) dataset

This is my problem description: "According to the Survey on Household Income and Wealth, we need to find out the top 10% households with the most income and expenditures. However, we know that these collected data is not reliable due to many misstatements. Despite these misstatements, we have some features in the dataset which are certainly reliable. But these certain features are just a little part of information for each household wealth." Unreliable data means that households tell lies to government. These households misstate their income and wealth in order to unfairly get more governmental services. Therefore, these fraudulent statements in original data will lead to incorrect results and patterns. Now, I have below questions: How should we deal with unreliable data in data science? Is there any way to figure out these misstatements and then report the top 10% rich people with better accuracy using Machine Learning algorithms? -How can we evaluate our errors in this study? Since we have unlabeled dataset, should I look for labeling techniques? Or, should I use unsupervised methods? Or, should I work with semi-supervised learning methods? Is there any idea or application in Machine Learning which tries to improve the quality of collected data? Please introduce me any ideas or references which can help me in this issue. Thanks in advance.
