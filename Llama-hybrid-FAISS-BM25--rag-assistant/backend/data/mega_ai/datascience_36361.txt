[site]: datascience
[post_id]: 36361
[parent_id]: 36348
[tags]: 
In each layer of a CNN you have a number of filters. Suppose for the first convolutional layer you have $C_{out} = 10$ filters. The customary dimension for each of these filters is $(C_{input}, H, W)$ where $C_{input}$ represents the number of channels of the inputs of the current convolutional layer. $H$ and $W$ represents the height and width of the window of the filter. Consider this point that you are convolving each filter with the inputs. An input is a volume with $(C_{input}, H^{'}, W^{'})$ dimension. What you do as convolution is convolving these volumes, each filter and the input. The height and the width of the input $H^{'}$ and $W^{'}$ are the same or bigger than the height and width of each filter, but the depth or the number of the channels of each filter has to be the same as the input channel. After convolving each filter you will have a two-dimensional activation map. By stacking the result of each filter you will have $C_{output}$ number of output feature maps which is equal to the number of filters.
