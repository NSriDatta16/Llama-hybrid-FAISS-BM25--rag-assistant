[site]: crossvalidated
[post_id]: 387736
[parent_id]: 
[tags]: 
A different proof for KL divergence non-negativity

KL divergence's non-negativity can be proved in many ways. One could use the inequality $\log x \leq x - 1$ as a main step in the proof, another one could leverage the property of concave of the logarithm function to yield the non-negativity. Although those proofs are concise and simple, I found they less obvious to come up with, particularly, for one who is not familiar with concavity and inequality. Therefore, I am trying to find an alternative proof which doesn't require knowledge of logarithm inequality as well as concavity. The following is what I've come up with: $KL(p||q)\geq0$ $\Leftrightarrow\sum_i p_i \ln p_i \geq \sum_i p_i\ln q_i$ $\Leftrightarrow\sum_i \ln p_i^{p_i} \geq \sum_i p_i\ln q_i^{p_i}$ $\Leftrightarrow e^{\sum_i \ln p_i^{p_i}} \geq e^{\sum_i p_i\ln q_i^{p_i}}$ $\Leftrightarrow e^{\ln p_1^{p_1}}...e^{\ln p_n^{p_n}} \geq e^{\ln q_1^{p_1}}...e^{\ln q_n^{p_n}}$ $\Leftrightarrow p_1^{p_1}...p_n^{p_n} \geq q_1^{p_1}... q_n^{p_n}$ Constrains: $0\leq p_i,q_i \leq 1$ and $\sum_i p_i=1$ and $\sum_i q_i=1$ To prove that $KL(p||q)\geq0$ , now I need to prove that: $ p_1^{p_1}...p_n^{p_n} \geq q_1^{p_1}... q_n^{p_n}$ $(*)$ Hopefully, $(*)$ is simpler to prove in terms of not using logarithm function. However, I am stuck here. I would appreciate any idea helps to prove $(*)$ or corrections for the transformation (if any).
