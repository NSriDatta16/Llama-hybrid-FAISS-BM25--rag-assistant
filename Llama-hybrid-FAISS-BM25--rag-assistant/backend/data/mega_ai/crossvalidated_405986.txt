[site]: crossvalidated
[post_id]: 405986
[parent_id]: 405967
[tags]: 
There are two approaches; direct methods and statistical testing methods: Direct methods: consists of optimizing a criterion, such as the within-cluster sums of squares or the average silhouette. The corresponding methods are named elbow and silhouette methods, respectively. Statistical testing methods: consists of comparing evidence against the null hypothesis. An example is the gap statistic. Elbow method - see this paper for details. Essentially, a line is plotted on a graph and the bend in the line indicates a possible number of clusters. In R it can be done using the NBClust package. Average silhouette method computes the average silhouette of observations for different values of k. The optimal number of clusters k is the one that maximizes the average silhouette over a range of possible values for k (Kaufman and Rousseeuw 1990). The gap statistic compares the total within intra-cluster variation for different values of k with their expected values under the null reference distribution of the data. The estimate of the optimal clusters will be a value that maximizes the gap statistic (i.e, that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points. The fviz_nbclust() function ` in factoextra R package can be used to compute the three different methods elbow, silhouette and gap statistic for any partitioning clustering methods like K-means, K-medoids (PAM), CLARA, HCUT. Besides, you can also look at some similar questions asked in 1 , 2 For cluster validation metrics, see this post Finally, remember clustering is an explorative technique. Assuming "true" clusters is a paradox. Your objective should be in exploring different clusterings of the same data to learn more about it. Treating clustering as a black box never works well.
