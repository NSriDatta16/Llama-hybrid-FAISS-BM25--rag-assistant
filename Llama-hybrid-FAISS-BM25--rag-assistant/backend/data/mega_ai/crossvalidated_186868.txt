[site]: crossvalidated
[post_id]: 186868
[parent_id]: 
[tags]: 
Understanding Monte Carlo sampling

In rejection sampling or Markov chain Monte Carlo methods, we usually have a target distribution $p(x)$ whose form makes it difficult or impossible to draw samples directly, but we can evaluate $p(x)$ up to a normalising constant. We then sample from a simpler distribution which is proportional to $p(x)$. My problem appears here: In order to accept/reject the proposed value $x'$, we evaluate the value of $p(x')$ and see if its within its bounds. Why can we evaluate a value $p(x)$, but not sample directly from $p(.)$? It seems like if we can resolve $p(x)$ for all $x$, say uniformly sampled over the support of $p(.)$, we can directly assess the shape of $p(x)$ without any distribution convergence steps. If someone could spot where I am confused, it would be very appreciated, as I donÂ´t seem to find any clear explanation on this issue anywhere (must be really trivial..! )
