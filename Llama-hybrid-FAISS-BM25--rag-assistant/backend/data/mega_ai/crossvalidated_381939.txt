[site]: crossvalidated
[post_id]: 381939
[parent_id]: 358101
[tags]: 
For Question 1, @Sycorax provided a comprehensive answer. For Question 2, to the best of my knowledge, averaging predictions from subjects is incorrect. I decided to use bootstrapping to compute p-values and compare models. In this case, the procedure is as follows: For N iterations: sample 5 subjects with replacement sample 100 test cases with replacement compute mean performance of sampled subjects on sampled cases for model M1 compute mean performance of sampled subjects on sampled cases for model M2 take the difference of mean performance between M1 and M2 p-value equals to the proportion of differences smaller or equal than 0 This procedure performs one-tailed test and assumes that M1 mean performance > M2 mean performance. A Python implementation of bootstrapping for computing p-values comparing multiple readers can be found in this GitHub repo: https://github.com/mateuszbuda/ml-stat-util
