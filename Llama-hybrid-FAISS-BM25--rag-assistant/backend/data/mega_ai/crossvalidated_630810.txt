[site]: crossvalidated
[post_id]: 630810
[parent_id]: 630493
[tags]: 
As pointed out in the comments, Durrett's definition is a general definition of the Markov property in an underlying discrete-time stochastic process, whereas the definition you have given is a type of framing of the Markov property in the special case of a discrete-time discrete-state-space process. The intuition behind the Durrett equation is as follows (taking $n$ as the "present" time). The filtration $F_n$ gives you the whole history of the process up to the present time $n$ , whereas $X_n$ only gives the state of the process at the present time $n$ . The Durrett equation says that when you condition on the filtration (i.e., the entire history up to the present time) then the resulting conditional probability $X_{n+1} \in B$ for the next state of the process can be written as a function only of the space $B$ and the value $X_n$ at the present time. In other words, the conditional probability of the next state given the entire history of the process up to the present only depends on the part of the history that is the state of the process at the present time value. This is the Markov property which defines a Markov chain.
