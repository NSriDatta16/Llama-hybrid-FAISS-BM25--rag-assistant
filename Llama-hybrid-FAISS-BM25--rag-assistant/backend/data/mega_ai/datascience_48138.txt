[site]: datascience
[post_id]: 48138
[parent_id]: 
[tags]: 
how can LSTM output ever be negative with 0 initialization?

From the lstm equations, e.g. as they appear on p406 of the Deep Learning Book , it looks to me like initializing with zeros (as is common practice), must always produce a strictly positive output. When $s_0 = 0$ , then the $i$ th output unit at the first time step can be written as $h_i = \sigma(A)tanh((\sigma(B)(\sigma(C))$ where $A$ , $B$ and $C$ are linear functions on the current input and the previous output. But isn't then $h_i > 0$ for all real numbers $A$ , $B$ and $C$ ?
