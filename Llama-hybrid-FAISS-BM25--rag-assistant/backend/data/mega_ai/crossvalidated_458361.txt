[site]: crossvalidated
[post_id]: 458361
[parent_id]: 458358
[tags]: 
Normally, using some kind of hyper-parameter search, e.g. grid search, for each of the hyper-parameters, you'll train your model on $n-1$ folds, and test on the holdout fold, repeat this experiment $n$ times and typically report the average of the scores you have over these $n$ holdout folds. This way, you'll quantify how good you've done for each of the different hyper-parameter configurations and pick the best one to apply and report your final success on the test set.
