[site]: crossvalidated
[post_id]: 565961
[parent_id]: 
[tags]: 
Training accuracy growing way faster than validation accuracy?

i've been trying to solve this classification problem using a convolutional neural network for some days but no matter what I do I can't seem to find the correct hyperparameters and configuration to make it work properly. So far i've tried changing loss function, optimizer, learning rate, number of epochs, batch size, changing the size of the input, using dropout layers, and regularizers. (it's a dataset of pictures with resolution of 200x200). I am fairly new to machine learning so I was wondering what am I doing wrong? I'll paste below the code for the best result i've had so far. from keras.models import Sequential from keras.layers import Conv2D from keras.layers import MaxPooling2D from keras.layers import Flatten from keras.layers import Dense from tensorflow import keras import pandas as pd classifier = Sequential() batch_size = 64 optimizer = keras.optimizers.Adam(learning_rate=0.001) loss = 'categorical_crossentropy' epochs = 50 classifier.add(Conv2D(32,(3,3), input_shape = (64,64,1), activation = 'relu')) classifier.add(MaxPooling2D(pool_size = (2,2))) classifier.add(Conv2D(64,(3,3), activation='relu')) classifier.add(MaxPooling2D(pool_size = (2,2))) classifier.add(Flatten()) classifier.add(Dense(units = 32, activation = 'relu')) classifier.add(Dense(units = 29, activation = 'softmax')) classifier.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy']) from keras.preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, validation_split = 0.2) test_datagen = ImageDataGenerator(rescale = 1./255) training_generator = train_datagen.flow_from_directory( 'asl_alphabet_train', target_size=(64,64), batch_size = batch_size, color_mode = 'grayscale', class_mode = 'categorical', subset = 'training') test_generator = test_datagen.flow_from_directory( 'asl_alphabet_test', target_size = (64,64), batch_size = batch_size, color_mode = 'grayscale', class_mode = 'categorical') validation_generator = train_datagen.flow_from_directory( 'asl_alphabet_train', target_size = (64,64), batch_size = batch_size, class_mode = 'categorical', color_mode = 'grayscale', subset = 'validation') #Found 69600 images belonging to 29 classes. #Found 35 images belonging to 29 classes. #Found 17400 images belonging to 29 classes. model = classifier.fit( training_generator, steps_per_epoch = training_generator.samples // batch_size, validation_data = validation_generator, validation_steps = validation_generator.samples // batch_size, shuffle = True, epochs = epochs) these are the accuracy and loss graphs: at this point I'm not sure if my model is experiencing overfitting or I wrote something wrong in the code.
