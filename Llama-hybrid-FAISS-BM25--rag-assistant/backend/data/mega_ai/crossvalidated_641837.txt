[site]: crossvalidated
[post_id]: 641837
[parent_id]: 595852
[tags]: 
There are many styles and flavors of diffusion models. For a forward Markovian inference process popularized by Denoising Diffusion Probabilistic Models ( DDPM ) , the solution is to apply the reparameterization trick recursively. $x_{t} \: = \: \sqrt{\smash[b]{\alpha_{t}}} \cdot x_{t-1} \: + \: \sqrt{\smash[b]{1-\alpha_{t}}} \cdot \epsilon_{t-1} \\ \\ = \sqrt{\smash[b]{\alpha_{t}}} \cdot \big( \sqrt{\smash[b]{\alpha_{t-1}}} \cdot x_{t-2} \: + \: \sqrt{\smash[b]{1-\alpha_{t-1}}} \cdot \epsilon_{t-2} \big) \: + \: \sqrt{\smash[b]{1-\alpha_t}} \cdot \epsilon_{t-1} \\ \\ = \sqrt{\smash[b]{\alpha_{t}\alpha_{t-1}}} \cdot x_{t-2} \: + \: \sqrt{\smash[b]{\alpha_{t} \: - \: \alpha_{t}\alpha_{t-1}}} \cdot \epsilon_{t-2} \: + \: \sqrt{\smash[b]{1 \: - \: \alpha_{t}}} \cdot \epsilon_{t-1} \\ \\ = \sqrt{\smash[b]{\alpha_{t}\alpha_{t-1}}} \cdot x_{t-2} \: + \: \sqrt{\smash[b]{ \sqrt{\smash[b]{\alpha_{t} \: - \: \alpha_{t}\alpha_{t-1}}}^2 \: + \: \sqrt{\smash[b]{1 - \alpha_{t}}}^2 }} \cdot \epsilon_{t-2} \\ \\ = \sqrt{\smash[b]{\alpha_{t}\alpha_{t-1}}} \cdot x_{t-2} \: + \: \sqrt{\smash[b]{\alpha_{t} \: - \: \alpha_{t}\alpha_{t-1} \: + \: 1 \: - \: \alpha_{t}}} \cdot \epsilon_{t-2} \\ \\ = \ldots \\ \\ = \sqrt{\smash[b]{ \prod_{t=1}^T \: \alpha_{t}}} \cdot x_{0} \: + \: \sqrt{\smash[b]{ 1 \: - \: \prod_{t=1}^T \: \alpha_{t}}} \cdot \epsilon_{t} \\ \\ = \sqrt{\smash[b]{\bar{\alpha_{t}}}} \cdot x_{0} \: + \: \sqrt{\smash[b]{1 \: - \: \bar{\alpha_{t}}}} \cdot \epsilon_{t}$ given by $\bar{\alpha_{t}} = \prod_{t=1}^T \: \alpha_{t}$ , and each noise random variable $\epsilon \sim \mathcal{N}(0, \mathcal{I})$ . The final equation applies the mathematical property governing the mean of two independent Gaussian random variables as the sum of the two means, and likewise, the variance as the sum of the two variances. Notice the dependence of the result on the initial input $x_{0}$ . As $t \to \text{T}$ , the signal-to-noise (SNR) decreases in value, and the ratio approaches zero such that $\bar{\alpha_t} \approx 0$ until the final target distribution is equivalent to $\mathcal{N}(0,\mathcal{I})$ . Furthermore, keep in mind these parameters could be directly learned or indirectly optimized for using SNR. The following excerpts are taken from my book on variational inference. Learn more on the topic by visiting https://www.thevariationalbook.com/
