[site]: datascience
[post_id]: 63280
[parent_id]: 63271
[tags]: 
I think you mixed up the terms that you do here. The task is called transfer learning and you FINETUNE the model. The reasoning is that after experimentation we found that earlylayers of CNN captures the general features of images such as edges,lines, etc, and later layers capture more specific features e.g. faces, shape of object. We only wish to alter the few layers or even only the output classifying layer. Pretrained model is trained with datasets that are most likely bigger than your dataset. Also because of reason number 1 and we have trained it with bigger dataset, we have first few layers that is able to generalize well and hence helps you combat overfitting. You save time and resource by doing this. First because you are only backpropagating within last few layers. Architecture-wise, people spend time researching how every features interact with image and hence it is recommended to use this architecture and published/publicly known result implies that it gives good result. So in general it is recommended practice to do transfer learning for image classification unless you have a very strong reason not to do so. There are many resources that tells you how to do it. Imo, VGG16 is outdated, it is also heavy and inefficient. You might want to check efficientnet. Medium source regarding CNN filter. Medium source
