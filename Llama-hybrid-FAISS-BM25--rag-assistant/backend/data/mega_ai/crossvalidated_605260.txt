[site]: crossvalidated
[post_id]: 605260
[parent_id]: 
[tags]: 
Theoretical analysis of STL decomposition

I would like to know if, for some specific models, the STL ("seasonal-trend decomposition using LOESS, see here ) algorithm for time series analysis is proved to converge (in some sense). For example, if $N = kn$ for two non-zero integers $k,n$ , if $a,b \in \mathbb{R}$ , and if $(e_j)_{j \in \{0,\cdots, N-1\}}$ is a i.i.d. sequence of gaussian variables, let us define $\forall j \in \{0,\cdots,N-1\}$ , $y_j := a\cdot j + b\cdot e^{i\frac{jk}{N}} + \epsilon_j$ . Then $(y_j)_{j \in \{0,\cdots,N_1\}}$ is a random time series. Can one prove that there is a choice of parameters of the STL algorithm that almost surely outputs $j \mapsto a\cdot j$ as the trend component and $j \mapsto b\cdot e^{i\frac{jk}{N}}$ as the seasonal component? Or, maybe just, in a loose sense, that the trend and seasonal components are close to these ones?
