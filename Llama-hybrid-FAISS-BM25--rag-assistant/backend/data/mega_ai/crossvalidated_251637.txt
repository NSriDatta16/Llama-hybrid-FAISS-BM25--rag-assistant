[site]: crossvalidated
[post_id]: 251637
[parent_id]: 249585
[tags]: 
I'm not aware of a paper but I would suggest the following scheme - 1) Take an image input and distort till you are ok with noise 2) Feed both image and its distortions to a siamese network and return True 3) Feed image and all other images and return False 4) Repeat This will give you a prediction on when the images are the same. You can adjust the distortions in your training data to tune to what level of noise are you ok with practically. The bad news is that you have to maintain a dictionary of ground truth images. Let's say you don't want to do that. So another way is to compress the image. I don't think you even need a neural net for that, anything like SVD/PCA will work. Once compressed, hash it and save that hash somewhere. Most images that are similar should 'hash' to the same thing. A new image should hash to something else. You can combine with other classifiers that count the number of objects in the picture, etc to create a better hash. But idea is the same. Let me know if either of these ideas are tenable.
