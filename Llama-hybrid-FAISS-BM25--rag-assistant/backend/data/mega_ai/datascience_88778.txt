[site]: datascience
[post_id]: 88778
[parent_id]: 88701
[tags]: 
The learning rate is one of those first and most important parameters of a model, and one that you need to start thinking about pretty much immediately upon starting to build a model. It controls how big the jumps your model makes, and from there, how quickly it learns. There are learning rate technique called Cyclical Learning Rates. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations. Check this out : Cyclical Learning Rates for Training Neural Networks . And implementation in pytorch and details blog : Adaptive - and Cyclical Learning Rates using PyTorch . By this small trick, you can build a stable version of your model. Best of luck.
