[site]: datascience
[post_id]: 124767
[parent_id]: 
[tags]: 
Model can not fit to 8 datapoints

I have 10 groups of biological experiments, all of size 100. I want to estimate experimental performance (success rate) of each groups of experiments, but have only ran experiments in two groups. My plan was to train a model on the 200 data points to predict experimental performance and use that model to predict experimental performance across the other 8 groups. Experimental performance here is defined as the fraction of successful experiments. I've done 10 fold cross validation on a random forest, and the performance on the 2 groups is pretty good f1~.94 precision~.95, recall~.93. To estimate experimental performance, I trained 100 RF models on bootstrapped versions of the training data (This gives me some error bounds). But when I try to use a model to estimate experimental performance I under estimate the experimental performance on one of the groups that we have actually run experiments for. Looking into this further, I observe that no matter what i do, there are 8 datapoints that are always classified as false negatives, which is reducing the performance. How should I handle these 8 points? Is it ok to just say, these could be issues with the data and move on? Or is there something I can do to try to correctly classify these points?
