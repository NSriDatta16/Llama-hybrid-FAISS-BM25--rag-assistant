[site]: stackoverflow
[post_id]: 937099
[parent_id]: 835585
[tags]: 
If you want to find out whether the backpropagation of the network is correct, there is an easy way. Since you calculate the derivate of the error landscape, you can check whether your implementation is correct numerically. You will calculate the derivative of the error with respect to a specific weight, ∂E/∂w. You can show that ∂E/∂w = (E(w + e) - E(w - e)) / (2 * e) + O(e^2). (Bishop, Machine Learning and Pattern Recognition, p. 246) Essentially, you evaluate the error to the left of the weight, evaluate it to the right of the weight and chheck if the numerical gradient is the same as your analytical gradient. (Here's an implementation: http://github.com/bayerj/arac/raw/9f5b225d6293974f8adfc5f20dfc6439cc1bed35/src/cpp/utilities/utilities.cpp )
