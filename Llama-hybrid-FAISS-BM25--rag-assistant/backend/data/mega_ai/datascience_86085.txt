[site]: datascience
[post_id]: 86085
[parent_id]: 51520
[tags]: 
In some cases where you know that the underlying process slightly changes, a good course of action is to have an adaptive forecasting model. Thus, model parameters are slightly re-calibrated at each new observation (analogous to online learning). An example would be forecasting power output for a wind turbine: due to some factors such as blades getting dirty and weather slowly changing, it is actually in your best interest to have a time adaptive model. Also, local learning algorithms are essentially re-trained at each new observation, since kernel weights are re-estimated. This includes algorithms like k-NN, kernel regression, local linear regression, etc. In this case the training is always conducted when the prediction is needed; the only requirement is that you update your historical observations. Regarding retraining batch models I have not seen general consensus, only empirical evidence. In some applications, such as electricity price forecasting, a lot of researchers re-train models using a rolling approach. The length of the rolling window usually is 2 times the length of the longest seasonal period. Sometimes this approach is coupled with exponentially decaying weights. However, I have noticed that this applies usually to researchers from econometric background rather than machine learning/ computational intelligence.
