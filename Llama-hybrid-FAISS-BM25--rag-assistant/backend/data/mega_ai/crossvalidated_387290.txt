[site]: crossvalidated
[post_id]: 387290
[parent_id]: 380833
[tags]: 
The reason you find the behaviour of the beta distribution a bit confusing here is probably that your intuition is based on distributions such as the normal, which are supported on the entire real line. The beta distribution, on the other hand, is bounded on both sides ( $0 \leq x \leq 1$ ), and it is for this reason that the variance (and therefore the standard deviation) has a maximum possible value. Specifically, the variance of a distribution is the average squared deviation from the mean. For the beta distribution there is an upper limit to how much any value can deviate from the mean (with maximal deviation at $x=0$ or $x=1$ ), and there is therefore also an upper limit for the variance (and consequently for the standard deviation, which is the square root of the variance). In the case of the beta (a=1, b=1) distribution, where values are distributed uniformly between 0 and 1 and the mean is 0.5, it turns out that the average squared deviation from the mean is $\frac{1}{12}$ . The standard deviation corresponding to this distribution is therefore $\sigma = \sqrt{\frac{1}{12}} \approx 0.289$ . Beta distributions with larger parameter values ( $a>1,b>1$ ) will have a single peak between 0 and 1 (specifically the mode is at $\frac{a-1}{a+b-2}$ ; see example below). Since values in these distributions are more highly concentrated around the mean, the variance and standard deviation will be smaller than for the uniform distribution. It should be noted that you can actually have beta distributions with standard deviation larger than 0.289: In cases where $a the beta distribution will be U-shaped, with values concentrating near 0 and 1 (see example below). The upper limit of the standard deviation is 0.5 (corresponding to an upper limit of 0.25 for the variance), which only occurs approaching the limit at $a = b = 0$ . (Intuitively, at the limit, one can think of all values as being evenly distributed between 0 and 1, meaning they all have a deviation of 0.5 from the mean, and therefore an average squared deviation of 0.25). Coming back to the specific Bayesian modeling context, where you want to use a beta distribution as a prior on some parameter: Here you can in principle directly specify the a and b parameters according to your prior beliefs, but it might be more intuitive to instead specify the expected mean and standard deviation of the prior distribution. Based on these you can then compute the corresponding values for a and b using Kruschke's equations 5.6 in the book also linked above . If you think the parameter you are modeling has a value somewhere between 0 and 1, then a unimodal prior with $a>1, b>1$ is a reasonable choice, and here the standard deviation will always be less than 0.289. If you think the parameter is either close to 0 or to 1, but you don't know which, then a bimodal prior with $a could be a good description, and here you will have $0.289 \leq \sigma \leq 0.5$ . If you use Krusckhe's equation and try to enter $m = 0.5$ and $s > 0.5$ you will get negative (impossible) values for a and b. If you keep the standard deviation below 0.289 (as suggested by Kruschke) then you can choose any value in $[0,1]$ for m and get valid values for a and b. If you set the standard deviation to be between 0.289 and 0.5 then only some values of m are possible (you can only achieve high standard deviation if the mean is near the middle of the interval).
