[site]: crossvalidated
[post_id]: 44989
[parent_id]: 44945
[tags]: 
IIRC WISARD was a RAM based neural network method developed by Igor Aleksander at Imperial College in the 1980s and early 1990s. RAM based neural networks essentially use look up tables to store the function computed by each neuron, and hence are easily implemented in digital hardware and have efficient training algorithms. They don't seem to be used much these days. In think the best source of information would be Aleksander and Morton's book "Introduction to neural computing" (sadly I can't find my copy). I don't think these sort of networks are used much these days, which is a pity as they are rather interesting; my favourite variant was the "Single layer look up perceptron", which is related to n-tuple classifiers (see this paper, and this one, for details.) They seem reminiscent in some ways to random forest methods and also "extreme learning" methods (as a linear model is trained using a fixed set of random basis functions). A Google scholar search for Igor Aleksander WISARD should find most of the relevant material.
