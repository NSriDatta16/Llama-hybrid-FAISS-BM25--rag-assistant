[site]: stackoverflow
[post_id]: 2941445
[parent_id]: 2869750
[tags]: 
This doesn't stack overflow - even in the interpreter, where there are no optimizations and no rewrite rules - because it doesn't use the stack. Look at the definition of (++), for example,: (++) :: [a] -> [a] -> [a] (++) [] ys = ys (++) (x:xs) ys = x : xs ++ ys The key thing is x : (xs ++ ys) -- that is, it is recursion guarded by the (:) "cons" constructor. Because Haskell is lazy, it allocates a thunk for the cons operation, and the recursive call goes onto this (heap-allocated) thunk. So your stack allocation is now heap allocation, which can expand quite a bit. So all this does is walk the big list, allocating new cons objects on the heap to replace the ones it is traversing. Easy! "reverse" is a bit different: reverse l = rev l [] where rev [] a = a rev (x:xs) a = rev xs (x:a) That is a tail recursive, accumulator-style function, so again, it will allocate on the heap. So you see, the functions rely on using cons cells on the heap, instead of on the stack, hence no stack overflow. To really nail this, look at the runtime stats from the GC vm: $ time ./B +RTS -s 99 833 MB total memory in use (13 MB lost due to fragmentation) Generation 0: 3054 collections, 0 parallel, 0.99s, 1.00s elapsed %GC time 82.2% (85.8% elapsed) There's your big list -- it is allocated on the heap, and we spend 80% of the time cleaning up cons nodes that are created by (++). Lesson: you can often trade stack for heap.
