[site]: crossvalidated
[post_id]: 569233
[parent_id]: 
[tags]: 
XGBoost Feature Importance Changes with Random Seed

Analysis Goal: Identify features that provide an accurate prediction of a binary outcome and also explain how the features are related to the output Data: 72 features and 200 instances. Process: Sampled 70% of the data with a random seed and trained an XGBoost model. With different random seeds, variable importance and prediction performances change. Some more detail: Using the fitted model on the training data, I have calculated Shapley values for all training instances for the top 4 important features. For each of these features, I am plotting the feature values versus Shapley values to identify some thresholds that can result in a positive or negative log(odds) of the event of interest. I have also tested recursive partitioning. The thresholds keep changing with different seed values and AUC(ROC) is almost 20% lower than XGBoost. Finally, there is nothing holy about 4 features (as opposed to 5 or 6 or all), I have chosen them for the sake of simplicity in the interpretations. Problem: The thresholds and top 4 features keep changing whenever I change the random seed. Is there a systematic way to make some inferences like the ones I am looking for with confidence? I have looked at other posts here but could not really find answers (e.g. this , this , this ).
