[site]: crossvalidated
[post_id]: 336080
[parent_id]: 
[tags]: 
When training a CNN, why does l2-loss increase instead of decrease during training?

When training a deep CNN on CIFAR-100, what are the factors that make the l2-loss increase instead of decrease during training? The regularization loss looks kind of funky like this, where there's decay in learning rate at step 40k: The training(dark blue) and test(light blue) - performances are: As you can see in the figure, I'm overfitting to the data set, and that's why I'm looking at the regularization. Dropout is set with rate 0.2, initial learning rate is 1e-3 and I'm using momentum optimizer with momentum 0.9 Thanks!
