[site]: crossvalidated
[post_id]: 172093
[parent_id]: 172048
[tags]: 
Simply: You can't. Also you should never assume that your data is free from gross or systematic errors (GS). Estimators which are based on least squares techniques require data which are free from GS . Only in this case they will yield the most probable parameter values [(in german), p. 115 and following ]. However this is plain theory and applies to GS with arbitrary big magnitude which is unlikely. In practice least squares $L_2$-Norm estimators can deal with ~ 5% GS unless you're very unlucky. The presence of GS will always smear your parameter but controlled-bad observations will remain visible in residuals. You may want to check this paper how to snoop in your dataset . However: There is no way to see uncontrolled-bad observations in residuals. Another point is model complexity. The more complex (non-linear) your model is, the more likely for you to suffer from gross and systematic errors. Suffer means that these GS will smear your parameters and won't reveal much in the residuals. In my field I'm dealing with a large amount of data, gathered through automatic processes where I simply can't ensure that each observation is valid and not an gross error. To avoid silly questions or statements during conferences or journal reviews which claim that my dataset might have been corrupted I use robust estimators wherever it's possible. Here is an example for line fitting. The first image is an $L_2$-Norm estimator, the second image is an robust $L_1$-Norm estimator. Both use data snooping techniques from the cited paper to remove outlier. Since line fitting is a linear model with low complexity a huge outlier ratio can be found by using plain statistics. However there will be a huge drop once you enter a more complex modelling domains like neural networks. You can 'tolerate' GS as long as you have enough data. If you don't want to keep them since you fear that they your parameter with an unacceptable magnitude then the best option is to use robust estimators with a high break point and use data snooping techniques as an argument to remove certain observations. Mention this techniques in your paper and compare your parameter before and after elimination to provide more transparent results so no one can blame you.
