[site]: crossvalidated
[post_id]: 245219
[parent_id]: 
[tags]: 
Bayesian parameter estimation: Transforming parameters to use uninformed priors

First of all: Please excuse my ignorance. There are some parts of the concept of bayesian inference I may have not yet understand! What I have so far: I have count data with a negativ binomial distribution and I want to fit a model to this data. The model contains of two unknown parameters ( b and n ). b is real-valued on an interval between 0 and 1 and should be normal distributed. n is also real-valued and normal distributed (on an invinit scale), too. I want to estimate these parameter values. Here I give you my R code to run with rjags: model { for (i in 1:N) { y[i] ~ dnegbin (p[i], r) p[i] I decided to use a logistic transformation on parameter b and a logaritmic transformation for parameter n , with a correspondent normal distribution. My Questions When I use the proposed code, the posterior distribution is for the transformed parameters. Any further examination with the resulting mcmc.list object will give me these transformed values. Is there a possibility to back transform the results inside the mcmc.list object or before they are stored as such? The more fundamental question: Is this transformation a correct procedure after all, or should I use a proper distribution for the prior in the first place? In that case, what distribution would you propose?
