[site]: crossvalidated
[post_id]: 489496
[parent_id]: 
[tags]: 
NLP Emotion Detection - Model fails to learn to recognize negations

I am working on a nlp emotion detection project. The emotions that I try to predict are 'joy', 'fear', 'anger', 'sadness'. I used some publicly available labeled datasets to train my model e.g. ISEAR, WASSA etc. I have tried the following approaches: Traditional ML approached using bigrams and trigrams. CNN with the following architecture: (X) Text -> Embedding (W2V pretrained on wikipedia articles) -> Deep Network (CNN 1D) -> Fully connected (Dense) -> Output Layer (Softmax) -> Emotion class (Y) LSTM with the following architecture: (X) Text -> Embedding (W2V pretrained on wikipedia articles) -> Deep Network (LSTM/GRU) -> Fully connected (Dense) -> Output Layer (Softmax) -> Emotion class (Y) The NN models achieve more than 80% accuracy but still when I use the the trained model to predict the emotion on text that includes some negation I get the wrong results. For example: Text : "I am happy with easy jet, it is a great company!" Predicts Happy Text: I am not happy with easyjet #unhappy_customer Predicts Happy Any suggestions on how to overcome this problem?
