[site]: datascience
[post_id]: 56102
[parent_id]: 56098
[tags]: 
Boosting typically only use one algorithm as it's base learner (almost exclusively decision trees). However, you could use a mixed set of algorithms as your base learners. Something like this: Boosting round 0: Add decision tree Boosting round 1: Add neural network Boosting round 2: Add KNN Boosting round 3: Add decision tree ... The reason you only see boosting using the same algorithm is probably just because it works better. I speculate that the diversity that comes from using several algorithms shine more when they are trained in parallel and combined. In boosting the base learners are trained in a sequence.
