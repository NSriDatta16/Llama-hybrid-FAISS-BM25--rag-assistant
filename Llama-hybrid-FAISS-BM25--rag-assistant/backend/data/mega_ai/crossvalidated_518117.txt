[site]: crossvalidated
[post_id]: 518117
[parent_id]: 518099
[tags]: 
I took this question to be asking about the MSE of the regression estimator, rather than the MSE of a prediction. The comments by the OP have subsequently clarified that he wanted the latter, so this answer is looking at something different to what he wants. I am going to leave this answer here anyway, since it is useful for analysis of the former. In a regression context, usually the explanatory variables would be treated as fixed, so the MSE calculation would condition on them. I will give you the conditional result first, followed by looking at the unconditional result. Under OLS estimation you have $\hat{\boldsymbol{\beta}} - \boldsymbol{\beta} = (\mathbf{x}^\text{T} \mathbf{x})^{-1} \mathbf{x}^\text{T} \boldsymbol{\varepsilon}$ , which means that the squared-norm of the estimation error can be written as the quadratic form: $$\begin{align} ||\hat{\boldsymbol{\beta}} - \boldsymbol{\beta}||^2 &= (\hat{\boldsymbol{\beta}} - \boldsymbol{\beta})^\text{T} (\hat{\boldsymbol{\beta}} - \boldsymbol{\beta}) \\[6pt] &= ((\mathbf{x}^\text{T} \mathbf{x})^{-1} \mathbf{x}^\text{T} \boldsymbol{\varepsilon})^\text{T} (\mathbf{x}^\text{T} \mathbf{x})^{-1} \mathbf{x}^\text{T} \boldsymbol{\varepsilon} \\[6pt] &= \boldsymbol{\varepsilon}^\text{T} \mathbf{x} (\mathbf{x}^\text{T} \mathbf{x})^{-2} \mathbf{x}^\text{T} \boldsymbol{\varepsilon} \\[6pt] &= \boldsymbol{\varepsilon}^\text{T} \mathbf{A}(\mathbf{x}) \boldsymbol{\varepsilon}, \\[6pt] \end{align}$$ where $\mathbf{A}(\mathbf{x}) \equiv \mathbf{x} (\mathbf{x}^\text{T} \mathbf{x})^{-2} \mathbf{x}^\text{T}$ is an $n \times n$ matrix that is fully determined by the explanatory variables. Using a well-known rule for the expected value of a quadratic form , the MSE conditional on the explanatory variables is: $$\begin{align} \text{MSE}(\hat{\boldsymbol{\beta}}, \boldsymbol{\beta} | \mathbf{x}) &\equiv \mathbb{E}(||\hat{\boldsymbol{\beta}} - \boldsymbol{\beta}||^2 | \mathbf{x}) \\[6pt] &= \mathbb{E}(\boldsymbol{\varepsilon}^\text{T} \mathbf{A}(\mathbf{x}) \boldsymbol{\varepsilon}) \\[6pt] &= \text{tr}(\sigma^2 \mathbf{A}(\mathbf{x}) \mathbf{I}) \\[6pt] &= \sigma^2 \text{tr}(\mathbf{A}(\mathbf{x})). \\[6pt] \end{align}$$ Consequently, given any distribution for the (random) design matrix $\mathbf{X}$ we get the marginal MSE: $$\begin{align} \text{MSE}(\hat{\boldsymbol{\beta}}, \boldsymbol{\beta}) &= \sigma^2 \mathbb{E}( \text{tr} (\mathbf{A}(\mathbf{X}))) \\[6pt] &= \sigma^2 \int \text{tr}(\mathbf{A}(\mathbf{x})) \cdot p (\mathbf{x}) \ d \mathbf{x}. \\[6pt] \end{align}$$ Given your stipulated distribution for the design matrix of your regression, it should be possible to compute the expected value above, giving you the marginal MSE for the analysis. I am not aware of a closed form solution in this case, so I would suggest simulating the expectation of interest through importance sampling or some MCMC method.
