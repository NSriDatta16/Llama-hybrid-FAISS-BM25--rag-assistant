[site]: crossvalidated
[post_id]: 416875
[parent_id]: 416809
[tags]: 
The text is trying to illustrate how the operations of conditioning and marginalization work in a Bayesian network. You should not be computing $P(l^1)$ by averaging the $l^1$ column. Instead, you should write the joint distribution over $D$ , $I$ , $G$ , and $L$ as a product of CPD factors using the chain rule for Bayesian networks. Then you should marginalize out $D$ , $I$ , and $G$ by summing the joint distribution over all possible assignments to these random variables. The result will be the marginal distribution over $L$ , i.e. two numbers specifying $P(l^0)$ and $P(l^1)$ . To compute the conditional probability $P(l^1 | i^0)$ , set $P(i^0) = 1$ and ignore the rows in the grade distribution where $I = i^1$ , then follow the same procedure as above. Chapter 2 in the textbook you mentioned reviews the relevant concepts in basic probability.
