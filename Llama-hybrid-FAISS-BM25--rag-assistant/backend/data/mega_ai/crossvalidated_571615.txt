[site]: crossvalidated
[post_id]: 571615
[parent_id]: 571527
[tags]: 
This is an interesting question. I will say this simulation is biased to favor regression methods because the predictors explain a huge amount of variance in the treatment, meaning there is incomplete overlap and extremely severe imbalance, which are the situations in which IPW fares the worst. Take a look at the distribution of the covariate in the last dataset in the simulation: There is clearly so little overlap and the true propensity scores for a large number of units (i.e., anyone outside the area of overlap) are near 0 or 1. This means that any method to estimate the ATE will necessarily require extrapolation. IPW cannot do extrapolation; indeed, this is its strength. Regression gets the answer right but only because the extrapolation is correct because the outcome model is linear; if the outcome model outside the area of overlap were not linear, the extrapolation would be incorrect and regression would be severely biased. Only using IPW allows you to see that the effect cannot be estimated without extrapolation. In order for IPW to yield the correct answer, it needs to achieve balance. And here, it does not. Again, using the final dataset, the unadjusted standardized mean difference (SMD) is 2.18, and the weighted SMD is .66. SMDs need to be less than .1 to even be plausibly considered balanced. So, IPW failed to balance the covariates (because it is impossible for it to do so given the initial imbalance), and you should not attempt to estimate the effect from an imbalanced dataset. Note that the phenomenon observed here is basically identical to those observed in this question and this question . If you want to designed an unbiased simulation to accurately compare the performance of two methods, you can't do so in a way that is unrealistic and automatically guarantees one of the methods to fail. Let's go through your questions: Q1) You use two different estimators. syvglm() uses what's known as a Hajek estimator, and your manual approach uses a Horvitz-Thompson estimator. You should always use Hajek estimators (even though in this case the MSE was large for the Hajek estimator). The way covariate balance is assessed and the way to incorporate an outcome model into an IPW weighted estimator is more in line with Hajek estimators. In more realistic scenarios, Hajek estimators perform better. The HT estimator is, as you wrote, $$ \tau_{HT} = \frac{1}{n}\sum_{i=1}^n{A_i w_i Y_i} - \frac{1}{n}\sum_{i=1}^n{(1-A_i) w_i Y_i} $$ The Hajek estimator is $$ \tau_{Hajek} = \frac{\sum_{i=1}^n{A_i w_i Y_i}}{\sum_{i=1}^n{A_i w_i}} - \frac{\sum_{i=1}^n{(1-A_i) w_i Y_i}}{\sum_{i=1}^n{(1-A_i) w_i}} $$ The weighted least square estimator (what svyglm() does with a continuous outcome) is equal to the Hajek estimator (so you will get the same answer using lm() ). Q2 and Q3) These two questions are essentially the same, which is under what circumstances is it better to use regression vs. IPW? Rather than answer that explicitly, I'll describe the features of this simulation design that make it unfairly biased toward regression. The outcome model is linear and correctly specified. When the outcome model is incorrectly specified but the treatment model is correctly specified, IPW will generally do better than regression in terms of bias. There is severe imbalance. IPW does not perform well in cases of severe imbalance because the weights will be extreme. This doesn't affect regression much. Other methods of weighting are less affected by this; for example, overlap weighting, where the weights are $1-p$ for the treated units and $p$ for the control units (where $p$ is the propensity score), does not have this problem and can yield the right answer without extrapolating. There is no effect modification. Regression assumes the relationship between the covariates and each potential outcome is the same. Doing g-computation by fitting separate models relaxes this requirement. IPW always averages over any possible effect modification, so it doesn't matter whether you think there is or isn't any. This flexibility comes at the cost of precision There is very little overlap. I mentioned this before; the lack of overlap yields the significant imbalance observed and requires extrapolation to correctly estimate the effect. Regression does extrapolation and in this case gets it right because the outcome model is linear even beyond the area of overlap. IPW can only interpolate. Overlap weights restrict the estimation to the area of overlap, so they do not suffer from this problem. In realistic settings, the true outcome model is likely not linear, so you can't rely on a linear model to get it right. You can use a machine learning method to do g-computation, but then you can't do valid inference. You can augment the g-computation estimator with a doubly-robust method that incorporates IPW using augmented IPW or targeted minimum loss-based estimation (TMLE), which de-biases the treatment effect estimate and provides a pathway for valid inference. Or, you can use a flexible machine learning method or optimization-based method to estimate the weights without requiring the outcome model to be correct. You can augment the weighted estimator using outcome regression using augmented IPW or TMLE as previously mentioned, which improves the precision and makes inference more valid. See my (cheeky) post here about when to use matching (e.g., weighting) vs. outcome regression models to estimate effects.
