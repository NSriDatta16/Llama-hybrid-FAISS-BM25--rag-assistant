[site]: crossvalidated
[post_id]: 466052
[parent_id]: 
[tags]: 
Evaluation method of content-based recommendation system with no known ground truth

I am building a content-based recommendation system using cosine-similarity between 2 sets of texts A and B. For each document in A, I'll recommend top-n similar documents in B. Because this is the first time that a recommendation is built on this dataset, there is no known ground truth (i.e, we have no prior data where users indicate a pair of documents are relevant/similar). I plan to evaluate as follow: Prepare a sample of N items from A and their top-10 recommendations from B. Send this to a set of users. Ask users to rate the similarity/relevance (either True or False). For all items in N, calculate the average precision @1, @3, @5, @10. May I know if this method is sound? Secondly, I am also thinking of asking users to give a relevance score from 1 to 5 (1: least similar/relevant, 3: neutral, 5: most similar/relevant) => is there an evaluation metric that includes both precision@k and the rating score (instead of just true/false)?
