[site]: crossvalidated
[post_id]: 20766
[parent_id]: 20756
[tags]: 
Just to make sure we are on the same page: You have a sequence of 1000 samples with 7 features each. There is a sequential pattern in there, which is why you process them with an RNN. At each timestep: It depends. It might get better if you use different normalizations, hard to tell. To me it just sounds like classification. I am not sure what you mean by ranking exactly. No reason to be skeptical. Normally, training error drops like that--extremly quick for few iterations, very slow afterwards. No, absolutely not. For some tasks, less than 100 iterations (= passes over the training set) suffice. You are the one who has to say whether the error is small enough. :) We can't tell you without knowing what you are using the network for. Hard to tell. You should use early stopping instead. Train the network until the error on some held out validation set rises--that's the moment from which on you only overfit. Use the weights found then to evaluate on a test set. (That makes it three sets: training, validation, test set). Here are some tips that I can give: make sure to clamp your maximal updates to some fixed value. E.g. when you do a learning step, don't apply updates bigger than 0.1 (RPROP can already do this), try Long Short-Term Memory , try Hessian free optimization ( Ilya Sutskever has code on his webpage ).
