[site]: crossvalidated
[post_id]: 20652
[parent_id]: 20636
[tags]: 
Essentially, the answer to your question is that the behavior of $\alpha_n$ and $\beta_n$ is somewhat different when the Bayesian minimum-error-probability rule is used and one is trying to minimize $e_n$. This is because the decision regions $A_n$ and $A_n^c$ are different. In contrast to your (1) and (2), the behavior is of the form $$\begin{align*} -\frac{1}{n}\log \alpha_n &\rightarrow D(P_\lambda||P_1)\\ -\frac{1}{n} \log \beta_n &\rightarrow D(P_\lambda ||P_2) \end{align*}$$ so that $$ \lim -\frac{1}{n} \log e_n = \min\{D(P_\lambda||P_1), \,\,D(P_\lambda||P_2)\}. $$ Since $D(P_\lambda||P_1)$ is an increasing function of $\lambda$ while $D(P_\lambda||P_2)$ is a decreasing function of $\lambda$, choosing $\lambda$ such that $D(P_\lambda||P_1)=D(P_\lambda||P_2)$ gives $C(P_1,P_2)$. All this is described in Chapter 12 of the first edition of Cover and Thomas. Has it been deleted in the second edition since you refer us to Chapter 11 of Cover and Thomas?
