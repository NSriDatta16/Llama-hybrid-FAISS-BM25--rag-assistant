[site]: crossvalidated
[post_id]: 448548
[parent_id]: 
[tags]: 
Parameter dimensionality reduction in a Kalman filter framework

My problem is related to parameter identification with maximum likelihood in a Kalman filter. This framework consists of a multivariate set-up, wherein the unobserved components of the initial variable are linked to the unobservables in other variables. As previous literature and my initial unconstrained estimations would suggest, I'm suffering from a pile-up problem whenever I'm trying to estimate the hyperparameters of my model. To structure my question as neatly as possible, I'll introduce briefly the general framework with underlying assumptions before moving on to a problem description. Framework As my problem is closely interlinked to the bivariate model considered by Clark (p. 29-30, 1989 ), I will describe my problem utilizing a modified version of the bivariate model in his paper. The extension here introduces a drift term in the stochastic trend component of $y_t$ . To save some space, I will focus on the state-space form related to his work. The bivariate model in Clark (p. 29-30, 1989) decomposes two variables into a trend and cycle, wherein the unobserved cycle (AR(2) process) in the first variable $(y_t)$ determines the cycle in the second component $(u_t)$ . The measurement equation is defined as (following Durbin and Koopman's notation) $\underbrace{\begin{bmatrix}y_t\\u_t\end{bmatrix}}_\text{$y_t$} = \underbrace{\begin{bmatrix}1 & 1 & 0 & 0 & 0\\ 0 & \rho_1 & \rho_2 & 1 & 0\end{bmatrix}}_\text{$Z_t$} \underbrace{\begin{bmatrix}y_t^n\\y_t^c\\y_{t-1}^c\\u_t^n\\\mu_t\end{bmatrix}}_\text{$\alpha_t$} + \underbrace{\begin{bmatrix}0\\\sigma_t^{uc}\end{bmatrix}}_\text{$\epsilon_t$}$ , and the transition equation is defined as $\underbrace{\begin{bmatrix}y_t^n\\y_t^c\\y_{t-1}^c\\u_t^n\\\mu_t\end{bmatrix}}_\text{$\alpha_{t+1}$} = \underbrace{\begin{bmatrix}1 & 0 & 0 & 0 & 1 \\ 0 & \phi_1 & \phi_2 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1\end{bmatrix}}_\text{$T_t$} \underbrace{\begin{bmatrix}y_{t-1}^n\\y_{t-1}^c\\y_{t-2}^c\\u_{t-1}^n\\\mu_{t-1}\end{bmatrix}}_\text{$\alpha_t$} + \underbrace{\begin{bmatrix}\sigma_t^{yn}\\\sigma_t^{yc}\\0\\\sigma_t^{un}\\\sigma_t^\mu\end{bmatrix}}_\text{$\eta_t$} $ , or in short $y_t = Z_t \alpha_t + \epsilon_t, \quad \epsilon_t \sim N(0,H_t)$ $\alpha_{t+1}=T_t\alpha_t + \eta_t, \quad \eta_t \sim N(0,Q_t)$ To reiterate, the stationary components (cycle) follow an AR(2) process, whereas the nonstationary components are stochastic trends. Furthermore, the first trend component, $y_t$ , has a drift term. The error terms are independent white noise processes. Identification problem As we can see from aforementioned state-space equations, the model has 9 unknowns that need estimating $(\phi_1, \phi_2, \rho_1, \rho_2, \sigma^{uc}_t, \sigma^{yn}_t, \sigma^{yc}_t, \sigma^{un}_t,\sigma^\mu_t)$ . Here's where the problem becomes apparent; both observables are forced to identify multiple unknowns in the estimation process. Previous literature, such as Clark (1989) do not address the issue of identification (at least in that article). However, more recent papers—such as the ones by Laubach and Williams (p. 6-8, 2016 ) and Tasci (p. 13-14, 2012 )—address this problem more thoroughly. The aforementioned papers attempt to reduce dimensionality with the help of relative ratios. As the model considered by Tasci (2012) builds on the bivariate model established by Clark (1989), I have attempted to study the identification problem in the former paper more in-depth. The model considered by Tasci (2012) is essentially the same as above, with the exception of an additional variable to be decomposed (which has the same structure as $u_t$ above). In that paper, the author imposes relative ratios to reduce dimensionality and performs a grid search over different $\gamma_i$ values to determine the optimal ratio. The optimal ratio is determined as the ratio which maximizes the log-likelihood value. In effect, this approach removes the need to estimate the error terms for the cyclical components. For the bivariate model discussed above, the approach considered by Tasci would entail the following modifications: $\gamma_y = \frac{\sigma_t^{yn}}{\sigma_t^{yc}}$ $\gamma_g = \frac{\sigma_t^{\mu}}{\sigma_t^{yc}}$ $\gamma_u = \frac{\sigma_t^{un}}{\sigma_t^{uc}}$ This is where I seem to hit a snag. According to my understanding, the error terms of the cyclical components are eliminated from the estimation process. However, I have been unable to find any literature as to how to modify the state-space equations above to accomplish this task. Durbin and Koopman (p. 44-45, 2001 ) present their take on this as follows: $y_t = \mu_t + \epsilon_t, \quad \epsilon_t \sim N(0,\sum_\epsilon) \\ \mu_{t+1} = \mu_t + \eta_t, \quad \eta_t \sim N(0,\sum_{\eta})$ , which they modify as below $\sum_{\eta} = q\sum_\epsilon$ , to impose a signal-to-noise ratio (q is a scalar). This seems to be a basic transformation of the $\gamma_i$ values above, such that $\sigma_t^{jn} = \gamma_i \sigma_t^{jc}$ . According to my understanding, this seems to be an inverse case of the one considered in Tasci (2012), as it implies that the error terms associated with the trend components are replaced with scaled cyclical error terms. Am I missing something here, or is the Tasci (2012) case simply the following transformation $\frac{\sigma_t^{jn}}{\gamma_i} = \sigma_t^{jc}$ ? I have attempted to estimate both constrained alternatives, but based on the results I must be going wrong somewhere. Does anyone know how this signal-to-noise ratio should be defined to effectively reduce dimensionality? Any help, such as references to relevant literature is highly sought after! If something remains unclear in my question, feel free to ask! To my understanding, there are also other methods available such as concentrating the log-likelihood function. However, imposing a signal-to-noise ratio and performing a grid search for different $\gamma_i$ values is sufficient for my problem. (Edit: this question has been moved from math here.)
