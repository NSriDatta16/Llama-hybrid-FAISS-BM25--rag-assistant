[site]: crossvalidated
[post_id]: 545585
[parent_id]: 545559
[tags]: 
You want to have as many data points in the test set as possible. You also want to have as many data points in the training set as possible. Given a constrain on the total amount of data points, increasing the data points in the test set will reduce the number of data points in the training set. So you will want to look for an optimum. Example/Illustration Below is an example where we change training set size and test set size. We do this in order to see if there is some optimum for the sizes that is balancing the pros and cons. In the training we fit different models. In the testing we select the model which is best. We validate by computing the difference with the known theoretic function. (the theoretic function that we created ourselves, but we do the training and testing while pretending that we do not know the real theoretic function) Let's use a model where we generate randomly 20 independent variables $X_i; 1\leq i \leq 20$ that are potentially in a linear model, which is in reality only made up from only the first five parameters $Y = X_1 + X_2 + X_3 + X_4 + X_5 + \text{noise}$ . We do the fitting by regularization. Let's use 400 measurements for an experiment (which need to be divided into training and testing). We repeat this experiment 100 times for each test set size. Let's see how the regularization parameter varies based on the size of the test set. Let's see how the performance parameter varies based on the size of the test set. (we plot the average of the 100 experiments per test size in red) Interpretation of the graphs: In the first graph we see: when we increase the test size then this increases the lambda parameter. We can see this as an increase in the control of 'overfitting' (which is the reason that we use a test data set). In the second graph we see that there is some optimum for the test size. Increasing the test size initially improves the result, but at some point it does come with some costs. The reason is that increasing the test data size, decreases the training data size. When the training data size becomes smaller, then the models will perform less well. In this particular example we see that this balance between large training data set (which improves the quality of the models) and the large test data set (which improves the control on overfitting) is optimal around a test data set of 33% of the entire data. Note: The example indicates how the test data set size is influencing the results. But the result of 33% is not a general result. For each problem this size of the test data size differs. The optimum will depend on the amount of risks of overfitting versus risks of misfitting (noise). R-code to produce graphs library(glmnet) set.seed(1) n = 400 n_train = 20 vars = 20 lambda = 10^-4 * 1.5^c(1:60) cvglmnet $lambda,RSS_train, log = "x", ylim = c(min(Ytot),max(Ytot)), # ylab = "RSS", xlab = "lambda") #lines(mod$ lambda,RSS_test) #points(mod$lambda[nm], RSS_test[nm], pch = 21, col = 1, bg = 2) return(list(lambda = mod$lambda[nm], performance = perf)) } set.seed(1) n_rep = 100 n_train
