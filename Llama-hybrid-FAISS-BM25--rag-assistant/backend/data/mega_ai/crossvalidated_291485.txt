[site]: crossvalidated
[post_id]: 291485
[parent_id]: 
[tags]: 
How is KKT complementary slackness embedded in SVM

I can't really see from all the online resources I find how this particular condition is embedded in the training of the algorithm. We can certainly ensure that the gradient of lagrangian is 0 and the lagrange multipliers are greater than or equal to zero, but I don't see how this automatically guarantees complementary slackness.. Could someone explain this to me I've spent so much time trying to understand the intuition behind this but couldn't quite figure it out. Do we need to set certain conditions to ensure complementary slackness is guaranteed in the process of training SVM? Or do we even need to consider this condition in addition all the constraints when training?
