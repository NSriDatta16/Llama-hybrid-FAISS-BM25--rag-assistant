[site]: crossvalidated
[post_id]: 496075
[parent_id]: 491705
[tags]: 
This scale factor allows you to translate the default covariance functions (under which $\text{Var}[f(x)]=1$ ) into the actual covariance function you want to associate to $f(x)$ in your prior. It does not affect the correlation between any $f(x)$ and $f(x')$ , although it does affect their covariance (multiplying it by $\eta^2$ ). Now, when do you need such a scaling factor? Whenever you don't want a distribution with $\text{Var}[f(x)]=1$ . Then, you can use a deterministic scaling factor (just multiplying that covariance function by some float) or you can learn the scale from the data itself (like the first example in your question). For example, if one were modeling average height of children as a function of time. Would it make sense to have $\text{Var}[f(x)]=1$ ? It would certainly depend on the units that are being used, and it would make sense to multiply the covariance function by some scale factor in centimeters or inches. And even if $f(x)$ has no units, you may want it to have a variance greater than 1, or smaller than 1. Scale factors allow you to choose this variance at your own discretion, or even consider put a prior on it, instead of just taking the default value of $1$ for granted. Hope it was helpful
