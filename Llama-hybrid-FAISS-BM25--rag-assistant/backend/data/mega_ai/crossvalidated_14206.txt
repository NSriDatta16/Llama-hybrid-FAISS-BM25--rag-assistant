[site]: crossvalidated
[post_id]: 14206
[parent_id]: 
[tags]: 
Improving the SVM classification of diabetes

I am using SVM to predict diabetes. I am using the BRFSS data set for this purpose. The data set has the dimensions of $432607 \times 136$ and is skewed. The percentage of Y s in the target variable is $11\%$ while the N s constitute the remaining $89\%$. I am using only 15 out of 136 independent variables from the data set. One of the reasons for reducing the data set was to have more training samples when rows containing NA s are omitted. These 15 variables were selected after running statistical methods such as random trees, logistic regression and finding out which variables are significant from the resulting models. For example, after running logistic regression we used p-value to order the most significant variables. Is my method of doing variable selection correct? Any suggestions to is greatly welcome. The following is my R implementation. library(e1071) # Support Vector Machines #-------------------------------------------------------------------- # read brfss file (huge 135 MB file) #-------------------------------------------------------------------- y 1] I ran with $1000$ (training = $700$ and test = $300$) samples since it is faster in my laptop. The confusion matrix for the test data ($300$ samples) I get is quite bad. true pred N Y N 262 38 Y 0 0 I need to improve my prediction for the Y class. In fact, I need to be as accurate as possible with Y even if I perform poorly with N . Any suggestions to improve the accuracy of classification would be greatly appreciated.
