[site]: crossvalidated
[post_id]: 408780
[parent_id]: 
[tags]: 
Non significant intercept but significant coefficients in mixed effect modelling

I am using mixed effect models to predict a time series of data. I am using lmertest() in R to overload lmer() to gain p values via Satterthwaite approximation. The general model for each formula in R syntax is: Dependent Variable ~ time^2 + time + (time | random effect) For those not versed in R, this is predicting my dependent variable using the fixed effect of time and time squared (to mimic a quadratic function) whilst allowing the second and trailing coefficients in a quadratic function to vary per time series. All models are using maximum likelihood. My model appears to account for a reasonable amount of variance (~ .06 R^2m, .94 R^2c) but I'm having difficulty understanding the p values. my intercept is highly non significant (~.76), but both the coefficients return My questions are therefore: What is the Satterthwaite approximation actually doing to create these values? My fixed effects appear to be highly significant whilst my intercept isn't, how should I interpret this finding? My gut tells me this means that the model could find good coefficients which meant time could predict my DV, but that the intercepts the model found cannot be trusted as assisting with predictions? Is there a better way to force out p-values from a mixed effect model than this? I'm considering using the anova() function from the car package which does a wald test mainly. How concerned should I be about the non-significant intercept, given my question is does my nature in general tend to follow a concave polynomial shape over time? Cheers.
