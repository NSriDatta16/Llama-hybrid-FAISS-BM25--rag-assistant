[site]: datascience
[post_id]: 94743
[parent_id]: 
[tags]: 
How to train and evaluate machine learning models with growing/changing datasets over time

Assume that you have a classification machine learning model, and you start with an initial dataset that contains 3 classes. You split the initial dataset into training/testing spits, you train the initial model and evaluate it, and then overtime, you collect more data for your dataset. Now you have more data that you want to add to you initial training dataset. The question is: How do you you organize you dataset and model training regiment so you can effectively quantify possible improvement between the initial model and the new model? One possible solutions: if you split the initial training dataset into training/testing data, once you have more data, you just split that data and then add the respective new training/testing splits into the original splits. But this approach feels a little too simplistic, and it could potentially lead to drift in the dataset itself. This is similar to doing regression testing but for machine learning models, but I am not sure im using the correct technical jargon for it.
