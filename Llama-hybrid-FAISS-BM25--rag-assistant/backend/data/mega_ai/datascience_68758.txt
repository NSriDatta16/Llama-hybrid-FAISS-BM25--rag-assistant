[site]: datascience
[post_id]: 68758
[parent_id]: 68599
[tags]: 
Just to add another, hopefully clarifying example: You may have fitted 100 trees in a random forest model and you want to add 10 more. Then you can achieve this by setting estimator.set_params(n_estimators=110, warm_start=True) and calling the fit method of the already fitted estimator. It typically would not make sense to fit the first 100 trees on one part of the data and the next 10 trees on a different part. Warm start doesn't change the first 100 trees. Similarly for GradientBoostingClassifier you can add more boosted trees using warm_start . You wouldn't want an additional boosted tree to be fitted on a different mini-batch. This would result in a chaotic learning process.
