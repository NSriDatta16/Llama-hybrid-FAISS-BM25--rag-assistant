[site]: crossvalidated
[post_id]: 113288
[parent_id]: 
[tags]: 
What is the role/purpose of hidden variables in graphical models?

Is there a formal treatment of the role/power of latent/hidden variables in graphical models and other machine learning models (e.g., structural equation models)? For example, the Restricted Boltzman Machine is a graphical model which is a compact representation of a probability distribution of $x$, but it is modeled as a joint distribution with a hidden variable $h$ (i.e., we model $p(x,h)$ instead of $p(x)$). Why is $p(x,h)$ any more powerful than a suitable representation for $p(x)$?
