[site]: crossvalidated
[post_id]: 387632
[parent_id]: 
[tags]: 
Running XGBoost with *highly* imbalanced data returns near 0% true positive rate. Tried SMOTE and it did not improve much. What else can I do?

I'm using XGBoost on a dataset of ~2.8M records of hard drive failures, where less than 200 are tagged as failures. After cleaning, there are 11 features in this dataset. Below is my R code, as well as a link to the dataset I uploaded to my S3 bucket: library(tidyverse) library(caret) library(xgboost) library(DMwR) # SMOTE library(Matrix) #' Load data from S3: ST4000DM000 % filter(capacity_bytes > 0) %>% mutate_at(.vars = c("read_error_rate", "start_stop_count", "reallocated_sector", "power_on_hours", "power_cycle_count", "reported_uncorrect", "command_timeout", "high_fly_writes", "airflow_temprature", "load_cycle_count", "total_lbas_written"), # scale across vector of covariate names funs(scale(.))) %>% select(failure, read_error_rate, start_stop_count, reallocated_sector, power_on_hours, power_cycle_count, reported_uncorrect, command_timeout, high_fly_writes, airflow_temprature, load_cycle_count, total_lbas_written) #' Next, partition & create training/test datasets: set.seed(42069) idx $failure failure) # this step is required later for input into SMOTE labels_training $failure)-1 # need the -1 because as.numeric() on factor gives 1,2 labels_test failure) dMtrxTrain 0.5, 1, 0) #' Confusion Matrix confusionMatrix(as.factor(xgb.pred), as.factor(labels_test), positive = "1") Here's what my confusion matrix looks like: Confusion Matrix and Statistics Reference Prediction 0 1 0 1410667 97 1 370 1 Accuracy : 0.9997 95% CI : (0.9996, 0.9997) No Information Rate : 0.9999 P-Value [Acc > NIR] : 1 Kappa : 0.0042 Mcnemar's Test P-Value : So, really bad. I thought to try using SMOTE to over-sample the failures: #' SMOTE dat_train_smote 0.5, 1, 0) #' Confusion Matrix confusionMatrix(as.factor(xgb.pred.smote), as.factor(labels_test), positive = "1") Here are the results: Confusion Matrix and Statistics Reference Prediction 0 1 0 1328741 49 1 82296 49 Accuracy : 0.9416 95% CI : (0.9413, 0.942) No Information Rate : 0.9999 P-Value [Acc > NIR] : 1 Kappa : 0.0011 Mcnemar's Test P-Value : It did not improve much. In looking at a chart of variable importance however, the results seemingly "make sense" (that is, they follow my intuition about hard drives and failures): So my question is: How can I improve this model? (if at all) What additional steps/methods should I consider? EDIT: Here's the ROC curve: #' Use ROCR package to plot ROC curve & AUC library(ROCR) library(pROC) xgb.perf
