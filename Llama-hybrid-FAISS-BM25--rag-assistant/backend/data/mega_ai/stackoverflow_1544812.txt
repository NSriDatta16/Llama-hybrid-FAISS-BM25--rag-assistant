[site]: stackoverflow
[post_id]: 1544812
[parent_id]: 1544770
[tags]: 
Why not just do a 'delayed' import method? Allow the CSV import, process the data in a 'temporary storage' database, and on the backend you lookup ISBN's via the Amazon process. The user will be prompted with a "your records are being processed, you will be asked to review them once we have finished validating", etc; At that point they can go through your listing locally and not be limited by the 1/second ISBN lookup of Amazon. I doubt a user would want to sit there while 10/20 are processed then wait more for the next page, and the next. So the process should fold out like so: User imports data (while on the backend a cronjob/process goes through the records one by one without making the user wait). User prompted to come back to verify data / User comes back after period of time (is notified etc) User goes through the list of data and validates it (paginated), upon acceptance you move the accepted/valid entries into your final database (live valid data). If the user wants to stop @ record 100 of 100,000 you give them that option, and they have this sort of 'queue' of validation. Hows that sound? A bit more work but seems the best approach for handling large data entries like this.
