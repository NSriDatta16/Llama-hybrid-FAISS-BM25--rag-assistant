[site]: crossvalidated
[post_id]: 594740
[parent_id]: 
[tags]: 
Why $V^{\pi^*}(s) = \max_{a \in A}Q^{\pi^*}(s,a),\forall s \in S$ in reinforcement learning?

When i read some notes about RL i encounterd following equation and try to prove it: $$ V^{\pi^*}(s) = \max_{a \in A}Q^{\pi^*}(s, a),\forall s \in S $$ Here is my attemption: Firstly, i only need to prove " $\geq$ " as " $\leq$ " is obvious. Soppose that $\exists S_0 \subset S$ such that $\forall s_0 \in S_0,V^{\pi^*}(s_0) .(W.L.G, soppose there is only single state $s_0 \in S_0$ ), i want to construct a new policy $\pi_{\text{new}}$ to derive the contradiction to $V^{\pi^*}(s) \geq V^{\pi}(s), \forall s \in S$ and all policy $\pi$ . I try to create the following policy: $$\pi_{\text{new}}(a\vert s)=\begin{cases} 1& s=s_0,a=\text{argmax}_{a\in A}Q^{\pi^*}(s_0,a)\\ 0& s=s_0, a\neq \text{argmax}_{a\in A}Q^{\pi^*}(s_0,a) \\ \pi^*(a\vert s)& s \in S - s_0 \end{cases} $$ Next I want to show $$ V^{\pi_{\text{new}}}(s_0) = \max_{a\in A}Q^{\pi^*}(s_0, a) $$ And thus $V^{\pi_{\text{new}}}(s_0) > V^{\pi^*}(s_0)$ to get contradiction. But I encounted some trouble as follow when derived it. $$ V^{\pi_{\text{new}}}(s_0) = \sum_{a \in A}\pi_{\text{new}}(a \vert s_0)Q^{\pi_{\text{new}}}(s_0, a) = Q^{\pi_{\text{new}}}(s_0, \text{argmax}_{a\in A}Q^{\pi^*}(s_0, a)) \overset{?}{=} \max_{a \in A}Q^{\pi^*}(s_0, a) $$ I guess the last equation is hold but i can't find a way to prove it. Because policy changed. Please give me some methods to state it. Thanks advanced for your help!
