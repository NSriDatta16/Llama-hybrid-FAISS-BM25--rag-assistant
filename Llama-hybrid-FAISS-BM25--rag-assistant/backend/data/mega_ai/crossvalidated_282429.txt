[site]: crossvalidated
[post_id]: 282429
[parent_id]: 282413
[tags]: 
That's true. Boosting is meant for weak learners, meaning models that are only a little bit better than random guessing because it allows you to combine all these different weak models that are good at classifying specific examples, but are pretty bad with the rest. In other words, they turn out to be uncorrelated (I bet that's another word you've seen in the articles. Believe me, I've been there). Neural networks, however, definitely tend not to be weak. Tend to be pretty strong actual, but that does depend on the data you are working with and its structure. I am actually working on a project where I am boosting feedforward networks with data that has significant temporal structure. I include a few time lags in my feature vector, and am hoping that boosting will take care of the rest.
