[site]: crossvalidated
[post_id]: 618336
[parent_id]: 
[tags]: 
Logistic Regression with Repeated Independent Values for Both Dependent Values

I'm running a multiple logistic regression with a binary output 0,1 with inputs of both continuous and discrete variables- around 6 independent variables total. The output is if a customer will buy or not, but there are a lot of results in which they bought at one point (1) and then decided to no longer buy (0). As such there are repeated values of the independent variables for both choices. Further, this portion of the dataset is large- 850 repeats/8000 overall data points. I am able to get significant results with the data included, but was wondering what the best practice is. Mainly, should this data be removed, should only one of the data points be used (perhaps 1 since they bought at one point), and what is the effect on the model in regards to adding noise or statistical issues? Thank you so much! Edit Thank you for the reply, I realize my initial question was very unclear. I am taking goodness of fit into account- though I do not fully understand how removing data from this effects the accuracy of the model or could skew the model. For example I'll compare the original full dataset (6508 data points), a subset of data keeping the duplicated values only when they were a customer (i.e. removing them from no longer being a customer*)(5498 data points), and a subset of the data with all duplicates removed (4655 data points). *The reasoning for the middle option is that they chose to be a customer at one point, and the reason for them no longer continuing to be a customer can be complex/external to why they initially chose to be a customer. The Hosmer-Lemeshow Goodness-of-Fits are below (holding variable selection constant/model): Full Data Hosmer-Lemeshow Goodness-of-Fit Test Chi-squared: 5.281 df: 8 p-value: 0.727 Summary: model seems to fit well. Keeping Duplicates as 1's Hosmer-Lemeshow Goodness-of-Fit Test Chi-squared: 10.295 df: 8 p-value: 0.245 Summary: model seems to fit well. Removing all duplicates Hosmer-Lemeshow Goodness-of-Fit Test Chi-squared: 10.915 df: 8 p-value: 0.207 Summary: model seems to fit well. From this we see that the best P-value seems to be from keeping all of the data in, but I was curious if this is bad practice or needs further considerations. @Frank-Harrell brilliantly pointed out such duplications may need to be considered by modeling with a random effects binary logistic model. Would this be the way to move forwards considering that most customers will not be repeated (though this would mean that new customers would have no data in regards to them and would be the random effect). The tradeoff here would be that the model already has a very low psuedo-R^2 and would introducing mixed effects make this intractable? My apologies for my lack of knowledge into mixed effects, I have not had experience with them prior. Thank you!
