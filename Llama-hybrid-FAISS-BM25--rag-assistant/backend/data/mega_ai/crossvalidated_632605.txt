[site]: crossvalidated
[post_id]: 632605
[parent_id]: 
[tags]: 
How are weights adjusted iteratively in Doc2Vec neural network and how are results from different word predictions combined?

For those unfamiliar, Doc2Vec is referred to as a 'simple' neural network with one hidden layer that is built very similar to word2vec. As I understand it (in dbow, the implementation I am using), the document id is used to predict the words in a given context window from that document. https://en.wikipedia.org/wiki/Word2vec I am struggling to understand some of it so would appreciate any guidance please. I get that the document id is fed through the network to predict a given context word but there are two things I am not understanding: I think the sequence is 1)feed document id, 2)predict word, 3)compute loss 4)adjust weights based on loss and rerun but I'm wondering how many times the loss is computed and fed back into the network for each individual word prediction? My intuition suggests to me that just feeding the loss back once would have a similar effect to many times?....but I'm thinking that I'm wrong for some reason After one word in the context window is predicted (a) for a document (y) and the network then predicts the next word in the context window (b) for document y. How are the results from (a) and (b) combined to adjust the weights for document y? Thank you
