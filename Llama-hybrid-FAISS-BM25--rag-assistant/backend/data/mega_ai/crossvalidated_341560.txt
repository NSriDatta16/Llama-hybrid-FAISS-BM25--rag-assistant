[site]: crossvalidated
[post_id]: 341560
[parent_id]: 341553
[tags]: 
1) A posterior probability distribution is simply the probability distribution of your parameter after having seen the data. In the general framework of Bayesian statistics, you put a prior distribution on your parameter that reflects your belief about what it might be. You also have a likelihood function for your data that says if we know what the parameter is, then this is how the data will be distributed. Given these pieces of information along with the data we observe, we can determine the posterior probability distribution. The idea is that we have an initial belief about the parameter, then we observe some data that tells us something about the parameter, and then we update our belief based on the data. The result of this update is the posterior probability distribution. The posterior probability distribution tells us the degree of belief we should have for any particular value of the parameter. 2) A p-value is a frequentist construction. A p-value tells us "What is the probability we observed this data if the null hypothesis is true?". This is why a low p-value implies it is less likely the null hypothesis is true. 3) No, they're not interchangeable. The fundamental difference between a p-value and a posterior probability is that a p-value is a statement about the probability of observing data, while a posterior probability is a statement about the degree of belief of a particular parameter. The difference in using one or the other is often a subjective choice. Some people like the frequentist philosophy better than the Bayesian philosophy and vice versa. One reason for using the Bayesian method is that you have the ability to specify a prior, which might be useful if you have domain information you wish to incorporate into your analysis. Bayesian methods can also be more effective in the case of small sample size, since they do not rely on asymptotics or large sample properties.
