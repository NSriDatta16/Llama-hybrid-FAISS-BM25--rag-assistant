[site]: crossvalidated
[post_id]: 483309
[parent_id]: 
[tags]: 
What is the Intuition behind the GAN Discriminator loss? How does Discriminator loss works?

I have just stated learning GAN and the loss used are different for same problems in same tutorial. Could someone please tell me intutively that which loss function is doing what? For example, in the blog by Jason Brownlee on GAN losses , he has talked about many loss functions but said that Discriminator loss is always the same . So he says that it is maximize log D(x) + log(1 – D(G(z))) which is equal to saying minimize y_true * -log(y_predicted) + (1 – y_true) * -log(1 – y_predicted) . What I got from this that the D , which is a CNN classifier would get the Original images and the Fake images generated by the Generator and tries to classify it whether it is a real or fake [0,1]. But What I don't get is that instead of using a single neuron with sigmoid and binary crossentropy , why do we use the equation given above? I mean how is that supposed to be working? What is the difference is this one making?
