[site]: datascience
[post_id]: 49110
[parent_id]: 49109
[tags]: 
To answer this question I should clarify what cost (loss) function and what evaluation metric's function are. Cost (loss) function the cost function is a function that measures the average dissimilarity between your target samples (labels) and the outputs of your network (when it is fed by your feature vectors). Your machine learning algorithm tries to minimize the cost function 's value during training process (when your network is fed by training feature vectors only). So in the case of LSTM network, it tries to tweak LSTM weights in each epoch to decrease the cost function's value calculated on training samples. In your problem, depending on the number of your labels, the cost function can be cross-entropy or binary cross-entropy for more than two classes or two classes cases, respectively. Evaluation metric's function Evaluation metric's function is a function that measures the average similarity between your target training samples or validation samples and the outputs of your network (when it is fed by your training or validation feature vectors). Unlike the cost function, your machine learning algorithm does not use evaluation metric's function to tweak the LSTM network weights. Instead, it uses evaluation metric's function just to evaluate the model ability to predict the class labels when given feature vectors as input. In your problem, accuracy is the evaluation metric. So, you should not be surprised if the training_loss and val_loss are decreasing but training_acc and validation_acc remain constant during the training, because your training algorithm does not guarantee that accuracy will increase in every epoch. That's because it does not inspect accuracy to tweak the model's weights, instead it inspect training_loss to do it.
