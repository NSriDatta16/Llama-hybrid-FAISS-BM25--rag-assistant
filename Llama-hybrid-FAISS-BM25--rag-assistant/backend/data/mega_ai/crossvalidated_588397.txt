[site]: crossvalidated
[post_id]: 588397
[parent_id]: 588343
[tags]: 
This is a follow-up question to your first question about this data and I have a follow-up answer. I take advantage of your comments to the previous question to rename X1 as Proficiency score, Test1 as Written score and Test2 as Oral score. This makes it easier to put the analysis in context. The plan is: Follow @whuber's advice to do multiple imputation, with two caveats: I use aregImpute from the Hmisc package instead of the mice package. This choice is mostly determined by the fact that I use Gls from the rms package to analyze the data. The Hmics and rms packages go hand in hand as they are both written by Frank Harrell. Aside : I encourage you to read his Regression Modeling Strategies course notes. I "pivot" the data to do multiple imputation, so that all three scores of a participant (proficiency, written, oral) are on the same row. I suspect this leads to better imputation. First we look at the patterns of missingness in the data. Almost one third of the participants are missing their proficiency score. I impute the test score data 20 times. n.impute Then I refit the generalize least squares (GLS) model on each of the 20 completed datasets. [The full R code is attached at the end.] The mean structure of the model allows for a smooth nonlinear effect of proficiency on written and oral test scores. I include an interaction with Test type, so that the proficiency effect can be different for written and oral scores. The variance structure of the model allows for correlation between the two scores of each participant and that written and oral scores have different variance. model Finally I plot the 20 model fits. The result is a bit different from my first analysis. As before proficiency is predictive of test score only at the two extremes: low proficiency below 40 and high proficiency above 80. But in this analysis we also see stronger interaction between test scores and low/high proficiency. You are the expert in education and you know much more about this particular data: Is there a "story" that can explain the different slope of written and oral test scores for students with low proficiency below 40 and students with high proficiency above 80? PS: Some care is probably warranted in interpreting the results as oral scores are in the range [0,60] while written scores are in the range [0,100]. So there might be floor/ceiling effects. The R code to reproduce the figures and the analysis: library("naniar") library("rms") library("nlme") library("tidyverse") iccmlr::theme_set_amazon() data % read_csv( col_types = cols(PARTICIPANT = col_character()) ) %>% rename( X1 = X1_notCentered ) %>% select( PARTICIPANT, X1, X2, SCORE ) %>% pivot_wider( id_cols = c(PARTICIPANT, X1), names_from = X2, values_from = SCORE ) %>% rename( Written = Test1, Oral = Test2, Proficiency = X1 ) data %>% select(-PARTICIPANT) %>% vis_miss() to_long % pivot_longer( c(Written, Oral), names_to = "Test", values_to = "Score" ) } data_long % Predict(Proficiency, Test) %>% as_tibble() } n.impute % map_dfr( ~ fit.one.impute(., xtrans, data), .id = "i" ) mult.fits %>% ggplot( aes( Proficiency, yhat, group = interaction(i, Test), color = Test ) ) + geom_point( aes( Proficiency, Score, group = Test, color = Test ), inherit.aes = FALSE, data = to_long(data), size = 2, shape = 1, stroke = 1 ) + geom_line( alpha = 0.5, show.legend = FALSE ) + labs( y = "Score" )
