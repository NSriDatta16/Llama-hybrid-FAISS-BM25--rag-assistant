[site]: crossvalidated
[post_id]: 230337
[parent_id]: 
[tags]: 
Modeling cricket bowlers getting batsmen out

I have a data set detailing a large number of cricket games (a few thousand). In cricket "bowlers" repeatedly throw a ball at a succession of "batsmen". The bowler is trying to get the batsman "out". In this respect it's quite similar to pitchers and batters in baseball. If I took the whole dataset and divided the total number of balls that got a batsman out by the total number of balls bowled, I can see that I would have the average probability of a bowler getting a batsman out - it will be around 0.03 (hopefully I haven't gone wrong already?) What I am interested in is what I can do to try and calculate the probability of a specific batsman being bowled out by a specific bowler on the next ball. The dataset is large enough that any given bowler will have bowled thousands of balls to a wide range of batsmen. So I believe that I could simply divide the number of outs a bowler achieved by the number of balls he has bowled to calculate a new probability for that specific bowler getting an out from the next ball. My problem is the dataset is not large enough to guarantee that a given bowler has bowled a statistically significant number of balls at any given batsmen. So if I'm interested in calculating the probability of an out for a specific bowler facing a specific batsmen I don't think this can't be done in the same simplistic way. My question is whether the following approach is valid: Across the whole dataset the probability of a ball getting an out is 0.03. If I calculate that on average bowler A has a probability of getting on out of 0.06 (ie twice as likely as an average bowler), and on average batsman B had a probability of being out of 0.01 (a third as likely as an average batsmen), is it then valid to say the probability of that specific batsman being out on the next ball to that specific bowler is going to be 0.06 * (0.01 / 0.03) = 0.02?
