[site]: crossvalidated
[post_id]: 502421
[parent_id]: 502390
[tags]: 
Nearly always we assume that the data is noisy. That’s one of the points of thinking of data is statistics in terms of random variables. That’s also why we think of our models in form of $y = f(x) + \varepsilon$ , where the $\varepsilon$ term stands for noise that cannot be modeled. Because you usually assume the data to be noisy, there’s no “extra steps” to be taken besides the standard practices of statistical modeling and machine learning. Of course, the different story is if you have additional knowledge about the nature of the noise that can be considered in the model, but this is considered in case-by-case basis.
