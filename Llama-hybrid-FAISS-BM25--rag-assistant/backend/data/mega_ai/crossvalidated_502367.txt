[site]: crossvalidated
[post_id]: 502367
[parent_id]: 
[tags]: 
What is meant by this idea that a covariance function of a Gaussian process "induces" properties? And what is the connection to stationarity?

I am currently studying the textbook Gaussian Processes for Machine Learning by Carl Edward Rasmussen and Christopher K. I. Williams. Chapter 1 Introduction says the following: The specification of the prior is important, because it fixes the properties of the functions considered for inference. Above we briefly touched on the mean and pointwise variance of the functions. However, other characteristics can also be specified and manipulated. Note that the functions in Figure 1.1(a) are smooth and stationary (informally, stationarity means that the functions look similar at all $x$ locations). These are properties which are induced by the covariance function of the Gaussian process; many other covariance functions are possible. I don't understand what is meant by the following: These are properties which are induced by the covariance function of the Gaussian process; many other covariance functions are possible. What is meant by this idea that a covariance function of a Gaussian process "induces" properties? And what is the connection to stationarity? The Wikipedia article for covariance function doesn't seem to have any information on this. And here is a related question (about stationarity) from the same textbook: Stationary function
