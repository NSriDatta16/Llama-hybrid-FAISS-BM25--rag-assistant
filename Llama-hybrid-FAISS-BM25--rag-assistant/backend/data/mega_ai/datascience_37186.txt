[site]: datascience
[post_id]: 37186
[parent_id]: 
[tags]: 
Early stopping on validation loss or on accuracy?

I am currently training a neural network and I cannot decide which to use to implement my Early Stopping criteria: validation loss or a metrics like accuracy/f1score/auc/whatever calculated on the validation set. In my research, I came upon articles defending both standpoints. Keras seems to default to the validation loss but I have also come across convincing answers for the opposite approach (e.g. here ). Anyone has directions on when to use preferably the validation loss and when to use a specific metric?
