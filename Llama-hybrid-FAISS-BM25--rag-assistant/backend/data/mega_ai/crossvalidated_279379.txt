[site]: crossvalidated
[post_id]: 279379
[parent_id]: 
[tags]: 
What conclusions can be drawn from the 'feature importance' attribute of a Random Forrest?

I am working on my class project for machine learning, for a smaller part of my project I am fitting a sklearn.ensemble.RandomForestRegressor to my data over a range of n_estimators and max_features and plotting the resulting out of box error versus n_estimators for each value of max_features . I noticed that RandomForestRegressor has an attribute feature_importances_ that I would like to try to draw some conclusions from. The data I am fitting has 6 features and 1 response variable. I know based on how this data is created (data from a real physical process) that a specific feature is the "most important" to the response's value. Though when I inspect the attribute feature_importances_ this variable is always of very low importance. What can be said about this discrepancy? After thinking about it I have to assume that this is explained by the fact that a Random Forest "does not care or know" about where the data comes from. The importance it places on the features is purely based on their predictive power; their power to lower the error rate for a given tree, for a given split. Does this mean nothing about the process that generates this data can be inferred? In general, and to make the answer(s) hopefully more succinct and useful to others too, what are the top few conclusions that can be drawn from the attribute feature_importances_ ? Specifically with discrepancies like the one I have outlined?
