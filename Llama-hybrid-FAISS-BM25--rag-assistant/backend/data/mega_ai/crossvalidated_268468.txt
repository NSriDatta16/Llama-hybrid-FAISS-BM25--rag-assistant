[site]: crossvalidated
[post_id]: 268468
[parent_id]: 
[tags]: 
Why can a regression tree not identify a perfect predictor?

If a dataset contains a perfect predictor a linear regression is able to identify this variable. Why is it that a tree model cannot do the same? In the R code below, the dataframe df contains an independent variable IndPerfect that is identical to the dependent variable Target . For the illustration only the last row is used for out of sample forecasting. A linear regression gives a perfect forecast and the parameters of the other parameters are set to (almost) zero: set.seed(1) df This result is not surprising. However, I was not able to generate a perfect forecast by using a tree method such as in R's extraTrees or xgboost. The following code uses xgboost including the validation sample of 10 rows from the code above: library(xgboost) #Gradient Booster name It does not matter what parameters I choose - no tree model (xgb or et) ever gives a perfect forecast. Is there a theoretical reason for a tree model to not be able to make perfect forecasts?
