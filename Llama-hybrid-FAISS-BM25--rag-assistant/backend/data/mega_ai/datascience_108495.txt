[site]: datascience
[post_id]: 108495
[parent_id]: 
[tags]: 
Am I over-complicating stuff?

I'm trying to classify some 1-D time series data, so I used a simple 1D CNN and fine-tuned the model via Bayesian Optimization (nothing fancy, just used the Keras tuner). And I got very good results (this is on the test dataset, obviously): But then I saw a method using Continuous Wavelet Transform, we convert the 1-D time series to 2-D scaleograms (frequency vs time graph) and input it to a 2-D CNN. I tried this, and even used transfer learning and Bayesian Optimization, yet, I constantly overfitted the model, and my validation accuracy stuck at 43% while my validation loss got higher and higher (as far as I know, this is overfitting, where the model doesn't learn anything). So, my question is this: should I focus on the 1D-CNN, or should I try to improve in the second method? (I have to add one thing: this is for a research paper; so the only reason I started to work on the second method was the fact that my advisor told me that the second method will add "scientific value" to the paper (which I strongly disagreed) and will make the accepting of the paper more "probable.")
