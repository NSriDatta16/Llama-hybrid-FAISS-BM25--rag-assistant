[site]: crossvalidated
[post_id]: 626575
[parent_id]: 
[tags]: 
Identifying Incorrect/Unreliable/Noisy Data to Reduce Variance of Mean Estimator

I have two questions concerning variance reduction in the setting where I believe that some of my data is nonsensical/unreliable/incorrect/noisy. To make my problem concrete, I'll use a toy example of students taking tests. Suppose I have $S$ students and I give them all an exam with $P$ problems. This gives us a matrix of scores $X \in \mathbb{R}^{S \times P}$ . I'd like to estimate how well each student performed. Normally, we could estimate each student's performance by averaging over the $P$ examples. The estimator of each student's average score of course has some variance, and I'd like to reduce this variance to know how students compare. For reasons I won't get into, I strongly suspect that a subset of the test problems are nonsense. For instance, maybe the problem is unclear or the material wasn't taught, and students are forced to guess at the answer. My questions are: What are different approaches for identifying which test problems should be discarded (or perhaps weighted)? How will each of these approaches affect the variance of the mean estimator?
