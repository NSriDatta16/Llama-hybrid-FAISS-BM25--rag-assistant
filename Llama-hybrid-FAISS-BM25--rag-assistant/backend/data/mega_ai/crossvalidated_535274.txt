[site]: crossvalidated
[post_id]: 535274
[parent_id]: 534538
[tags]: 
As @Dave suggests, train first a model that fits the training data. There is no point to talk about overfitting if the model does not fit the data at all. Weighted f1-score of 77% on binary classification is probably not what you would be happy with. Such a model may be a random forest. Give a try to xgboost . Think about regularisation when you are already fine on training data. Poor test score may be caused by different distribution of the test data, not necessarily by overfitting. It seems that your validation set is similar to train set and there the gap is much smaller.
