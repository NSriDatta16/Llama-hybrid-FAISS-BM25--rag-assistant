[site]: crossvalidated
[post_id]: 34858
[parent_id]: 34857
[tags]: 
Since you have more than two (in this example you have five, to be precise) dimensions, plotting would hardly help. Finding the maximum-margin separating plane is exactly what SVM is for. Unless you intend to implement it yourself, I suggest that you run LIBSVM on your data and read the resulting model file, which will contain the support vector coordinates. I'm not sure how to get the separating hyperplane out of that, but even if you do, it'll only be a hyperplane in the kernel space, not in the one where your samples are. If you just want to do linear classification, it may be better to use LIBLINEAR instead -- it's input format is the same as that of LIBSVM. The decoding (i.e. predicting the class for a new sample) can be done either by invoking the corresponding binary from the distribution.
