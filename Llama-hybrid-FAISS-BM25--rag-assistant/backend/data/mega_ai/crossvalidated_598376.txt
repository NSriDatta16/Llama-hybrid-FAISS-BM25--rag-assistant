[site]: crossvalidated
[post_id]: 598376
[parent_id]: 598374
[tags]: 
Frequentist approaches make sense in the context of randomized control trials (RCTs). In an RCT, an "exposure" is randomly assigned to a patient. If the exposure were nothing more than a placebo (i.e. we were just randomizing for the sake of randomizing) then the null hypothesis literally would be true. So knowing that (and making some assumptions about the sampling distribution of the test statistic), frequentist statistics make a lot of sense. You can say "had the exposure had no effect, then the probability I would see results at least as extreme as what I saw is...". Of course, you have to make modelling and distributional assumptions when you make this statement. Bayesian methods are not immune to this. Additionally, it isn't like the analysis of RCTs is a uniquely frequentist thing. Bayesian methods can be used for that too. But Frequentist methods can bound things like the false positive rate and the false negative rate (conditional on aforementioned assumptions, which I will repeat must be made in the Bayesian framework too). Being able to control these error rates is very valuable in medicine and drug discovery. You're (ostensibly) able to ensure that 20% of all interventions which do have an effect fail to be discovered (or whatever your false negative rate is) $^\star$ . Bayesian's don't care about false positive/negative rates. And I think there is your answer: We still use frequentist methods when care about those error rates. If you care about those rates or not (or should care about them) is orthogonal in my opinion. IF you care about them, frequentism is a good tool. $^\star$ Little bit of nuance here. Its 20% of all interventions which have the assumed minimal detectable effect. Here we see a really important point against frequentism; it isn't very intuitive and is filled with overloaded words like "confidence". I feel this is a more damning objection to the framework.
