[site]: crossvalidated
[post_id]: 63538
[parent_id]: 
[tags]: 
Interpreting Coefficients from Logistic Mixed Effects Model

I am trying to use glmer to create logistic mixed effects models (LMEMs) and then run a model comparison between them. Respondents can click "Yes" (coded as 1) or "No" (0), which is used as the DV. They can make three responses to each stimulus across time. The fixed effects are viewing duration of a stimulus at the point of each rating (continuous, the main variable of interest), the rating number (1st, 2nd, 3rd, which will be highly correlated with cumulative viewing duration) and whether the true answer was "Yes" or "No" (which I'll call 'veracity'). I have specified my models as: complex model -- response = 1 + rating number (1-3) + cumulative viewing duration + veracity + (1 + cumulative duration | participant number) + (1 + cumulative viewing duration | stimulus item number) simple model -- response = 1 + rating number (1-3) + veracity + (1 + cumulative duration | participant number) + (1 + cumulative viewing duration | stimulus item number) The simple model is missing the cumulative viewing duration main effect. asking for anova(simple, complex) gives the following: Data: data Models: simpleML: resp ~ 1 + responseno + veracity + (1 + cumdur + veracity | pno) + simpleML: (1 + cumdur | itemno) complexML: resp ~ 1 + responseno + cumdur + veracity + (1 + cumdur + veracity | complexML: pno) + (1 + cumdur | itemno) Df AIC BIC logLik Chisq Chi Df Pr(>Chisq) simpleML 12 2248.1 2313.8 -1112.0 complexML 13 2241.1 2312.3 -1107.5 8.9558 1 0.002766 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 I understand this to mean that the addition of the cumulative viewing duration variable significantly enhances the model. I am interested in knowing how the odds of responding "Yes" changes with each additional unit of cumulative viewing duration (measured in seconds). So to do that, I figured I should look at the complex model in more detail: the beta will surely be reported there, and then I can use the exponent link function to give me a log odds (hopefully I'm right so far). So here's the complex model: Generalized linear mixed model fit by the Laplace approximation Formula: resp ~ 1 + responseno + cumdur + veracity + (1 + cumdur + veracity | pno) + (1 + cumdur | itemno) Data: data AIC BIC logLik deviance 2241 2312 -1108 2215 Random effects: Groups Name Variance Std.Dev. Corr pno (Intercept) 3.1359e-01 0.5599916 cumdur 3.3268e-05 0.0057679 -0.014 veracity 6.8532e-01 0.8278393 -0.900 0.063 itemno (Intercept) 3.5810e-01 0.5984182 cumdur 7.7778e-05 0.0088192 -0.052 Number of obs: 1764, groups: pno, 49; itemno, 12 Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept) 0.326981 0.314613 1.039 0.299 responseno -0.224734 0.148566 -1.513 0.130 cumdur -0.001513 0.005310 -0.285 0.776 From this, I first notice the p-value is non-significant. I would have assumed the p-value here is a partial value: the effect of cumulative duration when the other variables are held at zero. So this worries me. Second, the beta is incredibly small, and the exponential of -0.001513 = 0.9985. In real terms, this means for each 1 second of cumulative viewing time, the odds of making a 'yes' judgment is lower by (1 - 0.9985 = ) 0.002%. Or for each 100 seconds of cumulative viewing time (which is probably about half the length of a stimulus item on average), the odds of making a 'yes' judgment is lower by 0.2%. This seems so incredibly small that the p=.776 makes sense to me. But then why does the Likelihood Ratio Test (i.e. "anova(complex, simple)") find a strong significant effect? I have tried googling for various answers, reading Bates' documentation and even asking work colleagues, but to no avail. Any help at all would be greatly appreciated! EDIT - Possible Answer? Dave Vinson has been kind enough to help me out, and I now have further information. This information is entirely credited to him (and any mistakes entirely credited to my misunderstanding). I have for now ignored the random effects, and regressed response (yes/no, y-axis) on the rating number (1, 2 or 3, x-axis). This gives y = 0.61 - 0.05x, where x is the rating number and y the predicted response: *[apparently I cannot post images without sufficient reputation. Annoying. Hopefully the model above gives you some idea of the effect.] Having done that, I then calculated the residuals (y minus response). These residuals, the unexplained variance, were then regressed on the cumulative viewing duration, shown below. Residual is plotted on the Y-axis, cumulative duration on the X-axis. As can be seen, the slope is remarkably shallow. *[sorry, not able to post images.] Perhaps the structure of the mixed effects models was incorrect. Specifying a slope for cumulative duration in the simple model could be wrong, resulting in the variance that would normally be explained by the fixed effect of cumulative duration to start being accounted for in the random effect. Plausible? And how might I check for this?
