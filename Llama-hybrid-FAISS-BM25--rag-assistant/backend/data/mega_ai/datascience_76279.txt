[site]: datascience
[post_id]: 76279
[parent_id]: 76276
[tags]: 
The goal of having a "forest" (baggging ensemble) of trees is to make the prediction more solid. Individual decision tree tend to overfit, and with Random Forest the sampling, features selection and bagging helps to make a more robust score. Its weird that you have an empty tree, since decision tree are greedy and they will fit to anything. Even if there is just random noise in your data they will make splits (depends a bit on how you have configurated it). If you have an empty tree, random forest wont do nothing since is just a bunch of decision trees. With out seeing your code, or nothing else I would guess that you have a coding error somewhere.
