[site]: crossvalidated
[post_id]: 559576
[parent_id]: 545947
[tags]: 
Residual variance only makes sense when the distribution of the data is Gaussian (see Stroup, 2012 for examples). For non-Gaussian data, in your case Poisson, Nakagawa and Schielzeth or Nakagawa et al. (2017) try to generalize some of those ideas to other distributions (Poisson, Negative Binomial) by using approximations (i.e., Delta method). As such, what you are interested in is the variance of the approximation, or the variance of a function of a variance component. Like Florian mentioned, you can get those using Bayesian methods by looking at the posterior standard deviation of the parameters estimated. Also, when the distribution of the data is assumed to be Poisson, the dispersion parameter is set to $\omega=1$ . I have included an example using simulated data and JAGS below. n = 1000 beta0 = 2 beta1 = 1 x = rnorm(n) mu = beta0*1 + beta1*x lambda = exp(mu) y = rpois(n, lambda) modelcode = textConnection('model{ # Likelihood for(i in 1:n){ y[i] ~ dpois(lambda[i]) # Poisson likelihood lambda[i] The relevant part of the output > summary(output) Iterations = 1001:11000 Thinning interval = 1 Number of chains = 1 Sample size per chain = 10000 1. Empirical mean and standard deviation for each variable, plus standard error of the mean: Mean SD Naive SE Time-series SE beta[1] 2.0076 0.012982 1.298e-04 5.120e-04 beta[2] 0.9933 0.010197 1.020e-04 4.155e-04 tau 0.1260 0.001537 1.537e-05 6.063e-05 Hope this helps.
