[site]: crossvalidated
[post_id]: 622886
[parent_id]: 
[tags]: 
What is the complexity to compute the sample entropy of a time series of length N?

background Some algorithms are linear in operations, so the number of operations to complete is $O \left(N\right)$ , while others are quadratic $O\left(N^2\right)$ , cubic $O \left(N^3\right)$ , or non-integer $O \left(N\cdot log N \right)$ . Sample entropy has been around for a while ( link ) but I can't seem to find a clear statement showing the relationship between time-series length and number of operations to estimate the number of operations given the number of elements in the series. For example, Matrix inversion can have complexity of $O \left(N^{2.778} \right)$ ( link ). question What is the expected relationship between number of operations and time-series length? If you need to include a term for complexity, feel free, but I was hoping for a mostly average answer. Derivation would be nice but references are required. ( Updated 2-Aug-2023 ) question (from comments) - which algorithm? First version: R::pracma::sample_entropy ( link ) (I think its from Pincus 1991, link ) Alternate version: Python::entropy.sample_entropy ( link ) (I think its from ( here ), but seems to split at N = 5000 into numba vs. mne speedups)
