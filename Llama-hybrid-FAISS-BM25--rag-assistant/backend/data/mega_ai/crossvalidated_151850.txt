[site]: crossvalidated
[post_id]: 151850
[parent_id]: 
[tags]: 
Can you solve (avoid) an autocorrelation problem by adding an independent variable?

I am working on modeling what amounts to a time series, the DV is measured 40 times a day on 40 different days--- the actual timing of measurements on a given day varies, and the number of days between these sessions also varies. I am told that with such data (this is a single participant case study) autocorrelation is expected to be a problem, and so we should 'worry' about it and try to account for it. However, in my regression model I see no signs of autocorrelation in the residuals-- either when looking at an ACF plot or when using the Durbin-Watson test. I thought--- how can this be, if apparently its 'always' a problem? Then I saw that if I remove a certain independent variable, namely the session # itself, then I do see serious autocorrelation. Compare the models and ACF plots below: You can see that in the first ACF plot, lag-1 is significant, and there is a clear decreasing trend, whereas in the second the lag-1 is tiny and there is no obvious trend. The different between these models of course, as you can see at the heading, is that the latter includes session # as an independent variable. Is it WRONG for any reason to include that variable (session)?? It is of interest-- we want to know if the dv is changing with session, so a priori this is the model I designed. And if that is okay, which I can't see why it wouldn't be, then I don't understand why everyone doesn't just "solve" autocorrelation issues in regression by including an independent variable that 'captures' the non-independent nature of the trial structure. Any thoughts/comments on this are VERY welcome, I have to wrap my head around all of this before I can start writing a paper about our results!
