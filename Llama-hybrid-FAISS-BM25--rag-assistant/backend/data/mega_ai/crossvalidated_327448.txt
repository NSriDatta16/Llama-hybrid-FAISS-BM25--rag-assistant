[site]: crossvalidated
[post_id]: 327448
[parent_id]: 
[tags]: 
Can a random forest be 100% accurate using only 1 predictor that is not linearly separable?

A random forest classifier is reporting perfect classification accuracy when I pass it the data that it was trained on even though it has only 1 predictor that with overlapping values between classes. Is this possible or am I making a error? If it is possible, how? The distributions of the values in the two classes are shown below. I know passing training data doesn't give meaningful results on how good the classifier is, and that using only 1 feature in a random forest is strange, but I am trying to assess whether the classifier is overfitting by sequentially adding more features to the classifier and looking at the accuracy on the training and the test set.
