[site]: crossvalidated
[post_id]: 620721
[parent_id]: 620702
[tags]: 
If you use word embeddings, you can use any standard clustering algorithm since they are based on distance metrics which are defined even for higher dimensions. An example process could be: Convert words to embeddings. Run K-means clustering to obtain groups of words. View examples in each cluster to label possible topics you notice. Step 3 can be annoying since it is manual, but this can be further automated like so! Collect centroids (cluster centers) from step 2 above. Create a list of possible topics and convert them into embeddings. Compare similarities between the centroids and topic embeddings to label the clusters (i.e. run a 1-nearest neighbor classifier)
