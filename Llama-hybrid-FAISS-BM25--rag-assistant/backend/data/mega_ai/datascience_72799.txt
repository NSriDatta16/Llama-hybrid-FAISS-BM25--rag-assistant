[site]: datascience
[post_id]: 72799
[parent_id]: 
[tags]: 
Fit model function out defined data range

I have asked this on SO but it has not been well accepted because it seems to be more about data science than programming. Let's say I have a set of data (x=times,y=observation) that have gaps in time. Whatever is their trend, let's assume it linear for this discussion. The actual data do not have a linear trend, and the gaps are more than one, but for the sake of simplicity I would like to deal with a general example that I can understand and then extend to a more specific case. During the gap in time, there is a decay that makes data deviate from the purely linear trend, until observations start again and the linear trend is recovered. I want to model the decay as part of the function. from scipy.optimize import curve_fit import matplotlib.pyplot as plt def f(x, A, B, decay): return A*x + B + decay x=[1,2,3, 12,13,14] y=[2,4,6, 5, 7, 9] popt, pcov = curve_fit(f, x, y) figure = plt.figure(figsize=(5.15, 5.15)) figure.clf() plot = plt.subplot(111) ax1 = plt.gca() plot.scatter(x,y) plt.show() How do I model the decay variable as part of the function and obtain its best-fit value, let's say in the case where the decay is linear or quadratic? How do I plot the whole function ? I have read something about imputing but I it is the first time I read about it and I am not even sure that is what makes my day.
