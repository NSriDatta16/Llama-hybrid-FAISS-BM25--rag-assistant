[site]: crossvalidated
[post_id]: 219241
[parent_id]: 
[tags]: 
Gradient for logistic loss function

I would ask a question related to this one . I found an example of writing custom loss function for xgboost here : loglossobj Logistic loss function is $$log(1+e^{-yP})$$ where $P$ is log-odds and $y$ is labels (0 or 1). My question is: how we can get gradient (first derivative) simply equal to difference between true values and predicted probabilities (calculated from log-odds as preds )?
