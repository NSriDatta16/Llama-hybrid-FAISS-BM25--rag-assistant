[site]: crossvalidated
[post_id]: 505329
[parent_id]: 505315
[tags]: 
Seems off to me. The KLD term of the loss function is supposed to push the parameters of the latent distribution towards N(0, 1) by imposing a penalty proportional to how much the two... well, diverge. You said you looked at the loss and it seems fine. If I had to guess, there is some kind of issue with its implementation. The KLD term may not be included at all, or it's artificially low due to some bug, the spikes in the loss may occur only for some anomalous datapoints and get averaged out, or the reconstruction loss turns negative so the gains in reconstruction in training massively outweigh the costs of increased divergence.
