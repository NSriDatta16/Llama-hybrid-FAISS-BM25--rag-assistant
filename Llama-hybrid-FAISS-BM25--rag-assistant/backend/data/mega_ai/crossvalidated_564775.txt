[site]: crossvalidated
[post_id]: 564775
[parent_id]: 
[tags]: 
Testing 'extreme cases' for reality check in machine learning

I'm wondering if there is some general machine learning best practice to do a 'reality check' for your model. I'm coming at machine learning from a physics perspective, where it is common to test so-called 'extreme cases' in your model, so you can get an idea of whether it behaves how you expect. For example, setting an extremely high mass, low temperature, small interaction parameter etc. You boil things down to a simple case to check your code does what you expect. Is there a similar idea for testing a machine learning model, given that you generally train on specific data, and with a large, intentionally 'black-box' model?
