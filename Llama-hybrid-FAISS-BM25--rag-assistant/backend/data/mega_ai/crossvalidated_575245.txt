[site]: crossvalidated
[post_id]: 575245
[parent_id]: 
[tags]: 
How can I adjust cumulative entropy of moose observations?

I have downloaded the dates of every moose ( Alces alces ) observation worldwide on iNaturalist. This amounts to about $2 \cdot 10^4$ observations at present. I excluded one observation that was either incorrectly dated or was amazing evidence of time travel (they didn't have digital cameras in 1018, did they?). If we take the number of moose observations on a given day to be $C_t$ , and the count on the next day to be $C_{t+1}$ , we can compute the stochastic matrix $P$ of going from one count to another. Such a stochastic matrix can be computed in a cumulative fashion $P_{\leq t}$ , giving us sequence of matrices. Each matrix represents a probability distribution whose entropy can be computed by $$H_{\leq t} = -\sum_i \sum_j p_{ij} \log_2 p_{ij}$$ where $p_{ij}$ are the entries from $P_{\leq t}$ . While every $P_{\leq t}$ is square, they are not necessarily the same size. Each $H_{\leq t}$ can be normalized by the log of the number of observed state transitions. The following plot shows the normalized scores of $H_{\leq t}$ . We can note that it is initially large because of a single observation retroactively added from early last century, and quickly drops due to many transitions from zero-to-zero. Since iNaturalist was purportedly launched in 2008, all observations before 2008 are presumably retroactive. I think the later upward trend in the normalized entropy is largely driven by an accumulation of unique values in the daily counts. The following plot on the y-axis is the cumulative number of unique counts, and the horizontal axis is time. It seems to support my inference. I would like to estimate how uniform these transition matrices are in a way that is corrected for the number of unique counts changing. One guess is to average the normalized entropies by the number of unique counts, which results in the plot belong, but I am not sure if this really achieves the desired result. Does this approach of dividing by the number of unique values quantify how uniform the distribution are in a way that corrects for the number of unique counts changing? Is there a better way to go about this?
