[site]: datascience
[post_id]: 126469
[parent_id]: 126337
[tags]: 
It's generally not related to Data Science but what goes around; typically all sort of bad practice relating to laziness / looking for short term rewards. I wouldn't say DS is pushing for it but rather avoiding to test it thoroughly trough robust tests. Notably, the examples you provide are quite outdated and do not represent the whole Data Science approach , but some people make quick answer to get short term rewards. I can honestly provide you as much anecdotal evidence about some Data Scientist not finding imbalance to be a problem. One of my favorite would be this one: https://www.kaggle.com/competitions/amazon-employee-access-challenge/discussion/5086 I'd argue you cannot really make generalities about DS making a topic out of imbalance like that. The main problem is that there are significant incentives to create a problem when there is none and provide solutions. From my experience, once you try to test it robustly the problem mostly disappear. Over time I have found some use-cases where it mattered: Very strong imbalance means you have a lot of unusefull data. And the bottleneck of your pipeline is the maximum memory used. So under sampling the majority class is a good start to reduce memory usage without loss in performance . For NNs, it seems that some standard library do not accept batches without any positive instances. That is, for some NN implementations, you need to ensure a minimal balance so each batch has at least one positive instance. It seems that, for NN, having balanced batch accelerate learning: http://proceedings.mlr.press/v97/byrd19a.html but notice that balancing is done through weight rebalancing. Also some evidence on why rebalancing would work: Some papers indicates a performance gain , but are quite rare/outdated and difficult to replicate in my opinion. I've never seen a replicable example of rebalancing significantly increasing performance. Adding noise to the data can make the model more robust (Gaussian noise is widely accepted). Generative techniques might work in that sense, but it is not exactly about rebalancing Measurable costs imbalance. Yes, nowadays the way to go would be to add weights or implement a custom loss. But I suspect that those approach were not always available, and possibly not the easiest way to go. I also suspect a confusion between cost imbalance and data imbalance (typically as you do) to play a role. This happen when cost imbalance is not measurable, but target imbalance is, or in some case cost imbalance quite match target imbalance, typically in finance. Overall, that stuff relates to MLE aspects of the project, or confusion about business constraints , rather than the DS one. The over-focusing of DS on data imbalance is mostly due to confusion and is partially irrational and lead by some bad habits I describe below, in a rework of a previous answer on SMOTE ( Why SMOTE is not used in prize-winning Kaggle solutions? ) to tell in my opinion Why is class imbalance seen as a problem and why solution to it are popular: Bad research practices / work ethics (a.k.a. 'publish or perish') that lead to create solution to problem that marginally or do not exist, marginally new techniques, technique with non-robust increment in performance ... etc. despite any application on any real life data set. It's quite difficult in the middle of your PHd thesis / paper to just go 'well nevermind this problem don't exist, let's just throw my last 6 month of work into the bin - and the funding with it'. Some of those practices can be found in business too. It also apply in business, where under a short time constraint you have to produce something, find an article on it on TDS and cc it into a notebook, then send it to management that can't read python code. Bad influencer practices: (you know those linkedin people sharing half baked Tds article), that are led by visibility instead of quality. Unfortunately, this sort of behavior is also present on other forums, like here or Kaggle forums (enven encouraged by the vote / medal system). Basically you are encouraged to see a problem and solve it. I'd even goes to add that it is often an UX problem. Typically discussion on imbalance are more prevalent on forums where there is no downvote buton, typically TDS. Bad interviewing practices: somehow Imbalance has become an interview question, it appears on interview question lists. Now you have both non-technical people asking about class imbalance and young DS learning to answer a list of stuff when they are asked about data imbalance. This is not a context where actually tried the stuff matters. Bad ML practices: Using wrong metrics and poorly designed cv it is very easy to gain performance as some over/undersampling techniques are leaky. It is then easier to publish / grab attention from your employer with a gap up in performance and put another coin in the hype machine. Bad evaluation practices: even with a good metric if you add a bit of noise in your data you have roughly 50% chance to improve the performance. It is often really easy (often incentivised) to be lead by non-robust evaluation, both in business and research. When you have a gain in performance do you go tell your boss or do you go 'well this might not be robust' better hire an intern and spend the next 6 months reworking the thing ? Bad default parameters , as mentionned, With some library, if the user is lazy he will tend to not change the default parameters too much. And as, you mention it the choice of a default 0.5 threshold in sklearn predict is absolutely awfull when there is imbalance. Sklearn default threshold is not the only thing promoting imbalance as a problem but it might be the worst. Overall it is not that much of a problem when you stop listening to inexperienced data-scientist. Typically G. Lemaitre, author of imbalanced learn package shows how imabalance is not a problem and how rebalancing is not useful: Get the best from your scikit-learn classifier .
