do not use AI, and information privacy concerns about collected data may pose a hazard to workers. Psychosocial Psychosocial hazards are those that arise from the way work is designed, organized, and managed, or its economic and social contexts, rather than arising from a physical substance or object. They cause not only psychiatric and psychological outcomes such as occupational burnout, anxiety disorders, and depression, but they can also cause physical injury or illness such as cardiovascular disease or musculoskeletal injury. Many hazards of AI are psychosocial in nature due to its potential to cause changes in work organization, in terms of increasing complexity and interaction between different organizational factors. However, psychosocial risks are often overlooked by designers of advanced manufacturing systems. Einola and Khoreva explore how different organizational groups perceive and interact with AI technologies. Their research shows that successful AI integration depends on human ownership and contextual understanding. They caution against blind technological optimism and stress the importance of tailoring AI use to specific workplace ecosystems. This perspective reinforces the need for inclusive design and transparent implementation strategies.Einola, Katja; Khoreva, Violetta (2023). "Best Friend or Broken Tool? Exploring the Co-existence of Humans and Artificial Intelligence in the Workplace Ecosystem". Human Resource Management. 62 (1): 117–135. doi:10.1002/hrm.22147. Changes in work practices AI is expected to lead to changes in the skills required of workers, requiring training of existing workers, flexibility, and openness to change. The requirement for combining conventional expertise with computer skills may be challenging for existing workers. Over-reliance on AI tools may lead to deskilling of some professions. While AI offers convenience and judgement-free interaction, increased reliance—particularly among Generation Z—may reduce interpersonal communication in the workplace and affect social cohesion. As AI becomes a substitute for traditional peer collaboration and mentorship, there is a risk of diminishing opportunities for interpersonal skill development and team-based learning. This shift could contribute to workplace isolation and changes in team dynamics. Increased monitoring may lead to micromanagement and thus to stress and anxiety. A perception of surveillance may also lead to stress. Controls for these include consultation with worker groups, extensive testing, and attention to introduced bias. Wearable sensors, activity trackers, and augmented reality may also lead to stress from micromanagement, both for assembly line workers and gig workers. Gig workers also lack the legal protections and rights of formal workers. AI is not merely a technical tool but a transformative force that reshapes workplace structures and decision-making processes. Newell and Marabelli argue that AI alters power dynamics and employee autonomy, requiring a more nuanced understanding of its social and organizational implications. Their study calls for thoughtful integration of AI that considers its broader impact on work culture and human roles.Newell, Sue; Marabelli, Marco (2021). "Artificial Intelligence and the Changing Nature of Work". Academy of Management Discoveries. 7 (4): 521–536. doi:10.5465/amd.2019.0103. There is also the risk of people being forced to work at a robot's pace, or to monitor robot performance at nonstandard hours. Bias Algorithms trained on past decisions may mimic undesirable human biases, for example, past discriminatory hiring and firing practices. Information asymmetry between management and workers may lead to stress, if workers do not have access to the data or algorithms that are the basis for decision-making. In addition to building a model with inadvertently discriminatory features, intentional discrimination may occur through designing metrics that covertly result in discrimination t