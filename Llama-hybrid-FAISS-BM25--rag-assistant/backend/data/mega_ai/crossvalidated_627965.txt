[site]: crossvalidated
[post_id]: 627965
[parent_id]: 
[tags]: 
Offline Reinforcement Learning to Create Heuristics

I am interested in using offline reinforcement learning to develop heuristics (aka dynamic treatment regimens) for when to send certain notifications to mobile app users. I am unclear what the nuts and bolts are of the actual offline reinforcement learning. If I were to use Q learning, would I get a model that is interpretable and I can develop rules based on the results? Or is the only result a model which can then be applied to new data. My question is similar to this, but I don't understand if/how you translate the results of the Q learning into a set of heuristics (e.g. don't send notifications if they received one in the last 2 hours, etc.): Reinforcement Learning on Historical Data I am new to RL, so maybe I am misunderstanding how complex it is and the optimizations are happening within individual, so no overarching set of rules can be crafted. I do wonder if you could create subgroups and establish heuristics that optimize at the mean level?
