[site]: datascience
[post_id]: 41677
[parent_id]: 41676
[tags]: 
I don't know what kind of image you have, 16 channels?! oh boy :) Anyway, if they are images, the first one is better. The reason is that in the second approach you are somehow unrolling the input signal. By doing so, you are removing the information about the locality. You are removing the information of near adjacent inputs. Convolutional neural nets attempt to find these kinds of features. As an example, consider the MNIST dataset. You can learn using CNN and MLP but the former is used due to the fact that CNNs care about patterns which are somehow replicated in different parts of inputs. If they are not images and you are aware that adjacent pixels or inputs are related, again you should exploit CNNs. Consider that the convolutional layers are CNNs are for extracting appropriate features. The classification task is done using dense layers in CNNs. About efficiency, consider two points. Graphic cards are called SIMD computers. It stands for single instruction multiple data. Matrix operations are done using GPUs very efficiently as the name of Graphic cards implies. Consequently, Dense layers are very fast in GPUs compared to CPUs. The other point is about parallel programming. Each filter in convolutional layers are independent; consequently, they can be applied using paralyzed instructions. Again appropriate GPUs are very good at this too. I know I've said two things but there are actually three things to be kept in mind. Forget all of the above mentioned points! The most important thing to consider is the memory and the bus. There are situations that you don't have a graphic card with more than 6 Gig of memory. In those situations, I really prefer the last generations of CPUs instead of GPUS. The reason is that you have to deal with the limitations of memory. In your case consider that if you use dense layers exactly after inputs, the number of parameters will be science fictional although You are supposed to use CNNs.
