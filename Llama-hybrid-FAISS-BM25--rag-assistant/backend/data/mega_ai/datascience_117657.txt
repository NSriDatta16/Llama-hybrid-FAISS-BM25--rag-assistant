[site]: datascience
[post_id]: 117657
[parent_id]: 100191
[tags]: 
I assume you are talking about a Machine Learning application. I like to think about the distinction in terms of at what point a model is being trained: EDA - no model trained yet, just exploring the data to see if there are potential problems in the dataset (outliers, mislabeled data, unwanted correlations between variables/samples, etc). Preprocessing - the steps required to go from raw data to a format suitable to input to your ML model. For say a linear/logistic regression model, this would mean the input data needs to be converted to vector format (eg. imputing missing values, one-hot encoding categorical variables, etc). After preprocessing, you could train a model on the dataset. Feature engineering - now that you have the data in a format where model can be trained, train model and see what happens. After that, start trying out ideas to transform the data values into a better representation such that the model can more easily learn to output accurate predictions. Here you may train many different versions of your model on differently transformed datasets, the goal is to produce the most accurate model you can by transforming the data values (eg. re-scaling numeric features, creating interaction terms, etc). The types of transformations considered during feature engineering are often inspired by discoveries made during the EDA phase of inspecting the dataset.
