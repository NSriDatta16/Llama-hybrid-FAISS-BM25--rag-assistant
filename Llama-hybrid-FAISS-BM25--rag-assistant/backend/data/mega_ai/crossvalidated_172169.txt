[site]: crossvalidated
[post_id]: 172169
[parent_id]: 172120
[tags]: 
As the name suggests, the ideal observer is ... ideal, in that it makes the best possible use of the information available to it and cannot be beat, even by very sophisticated techniques. However, keep in the mind that an ideal observer isn't really a classification algorithm per se . Unlike a support vector machine or Naive Bayes, its purpose isn't making predictions. Instead, perceptual experiments use ideal observer models to provide an upper bound on subjects' performance: if someone could perfectly(!) analyse this information in order to make a decision about that , how well could they do? We can then compare these theoretical calculations with data from actual subjects using the same data to make the same decision. If your ideal observer model is choosing between different (known) probability distributions, then a Bayesian classifier is optimal (see this short summary ). If you have only a single feature, then this is the same as the a Naive Bayes classifer.
