[site]: crossvalidated
[post_id]: 590808
[parent_id]: 590805
[tags]: 
The neurons are only dropped temporarily during training. They are not dropped from the network altogether. It is just that it turns out that we get better weights if we randomly set them to zero, temporarily, so the other neurons "think" they cannot "rely" on the other neurons and have to "perform well themselves". The neural network that you get out at the end contains all the neurons.
