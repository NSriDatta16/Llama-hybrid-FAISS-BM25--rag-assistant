[site]: crossvalidated
[post_id]: 197775
[parent_id]: 197048
[tags]: 
If you just want to compare the link functions and find which one is the "best", I think you can use a likelihood-ratio test, where you compare the ratio of likelihoods with the quantile of a $\chi^2$ distribution (Wilks theorem). If the test rejects H0:"the likelihoods are equal" then it means that one of the models gets a significantly better fit to the data. So, you can select the one with the highest likelihood. For GLMM, you have numerical methods for evaluating the likelihood, take a look here for instance : http://people.math.aau.dk/~rw/Undervisning/Topics/Handouts/6.hand.pdf Or inside the R package "glmm". If the variables of your models are not the same, it seems to me that it is more adequate to use criteria like Akaike Information Criteria (AIC) or Bayesian Information Criteria (BIC). This kind of criterion allow to select the model with the best fit to the data, while avoiding overfitting. To compute these criteria, you also have to compute the likelihood of each model. Next, you choose the model with the smaller criterion.
