[site]: datascience
[post_id]: 124465
[parent_id]: 124459
[tags]: 
In my understanding, LLMs are, very simplified speaking, probabilistic solvers. Math problems such as matrix multiplications are, on the other hand, deterministic in nature. Thus, using a an LLM for solving a math problem mostly comes down to using the wrong tool for the task. Of course, when it comes to text problems, LLMs should be beneficial because they can "understand" language and thus should be able to do precisely the task in question, translate a problem from language to mathematics. However, this does not work on more complex tasks (generally, many of them apparently do not pass the 6th grade in China https://arxiv.org/pdf/2306.16636.pdf ). An entire discussion about the use of LLMs and their obstacles with math problems can be found here https://arxiv.org/abs/2301.09723 However, some the shortcomings of LLMs can be circumventent. Instead of asking an LLM "How much is 3+2" it should be asked "Please write a program which adds two numbers and use the program to add 3 and 3 and show me the result" - just for much more sophisticated problems, as can be seen here https://www.pnas.org/doi/abs/10.1073/pnas.2123433119 As a simple thought experiment, you can try to set up a feedforward network which adds two numbers, preferably they should add to less than ten. Even when setting up a perfect network (and there is no gurantee that it would actually turn out like that once learned) there are a number of obstacles to face. The idea comes from the book (which I haven't read in a while and have no access to any more) "Deep Learning with Python, Second Edition" by Francois Chollet.
