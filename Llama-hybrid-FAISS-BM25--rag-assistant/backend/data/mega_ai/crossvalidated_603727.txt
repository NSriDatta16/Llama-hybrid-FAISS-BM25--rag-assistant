[site]: crossvalidated
[post_id]: 603727
[parent_id]: 
[tags]: 
Understanding the Effect of a Prior on the Posterior

Today I attended a seminar in which a tutorial was provided on how to "estimate a proportion using Bayesian estimation". In particular: Suppose we flip a coin 10 times and observe 7 heads We are interested in estimating the "probability of success" (i.e. the "p" parameter in a Binomial Distribution) using Bayesian estimation We decide to place a prior on "p" using the Beta(a,b) Distribution - this is because the product of a Binomial Distribution (i.e. Likelihood Function) and the Beta Distribution are proportional to another Beta Distribution (i.e. Conjugate Prior). Exploiting this relationship allows us to avoid MCMC sampling From this new Beta Distribution, we take its "MAP" (i.e. Expected Value) to determine the "probability of getting a heads". We can also construct a "Credible Interval" by integrating this new Beta Distribution over some desired range. Unlike the Frequentist Confidence Interval, this will tell us that "there is a 95% chance that the true probability of getting a heads is contained within our Credible Interval" I think I was able to follow this logic - but I had a question on selecting values of "a and b" for the Prior Beta Distribution. If I understand correctly: We have the ability to select values of "a and b" Our choice regarding "a and b" will indirectly impact how much "influence" we decide our observed data to influence the final estimate vs how much "influence" we decide our Prior to influence the final estimate As such, "a and b" can take any value (I was told that it is recommended to pick "a and b" to be positive integers) I was also told that " smaller values of "a" and "b" " will result in the Prior having less impact on the final estimate - whereas "larger values of "a" and "b" " will result in the Prior having more impact on the final estimate. However, I do not understand this logic. I suppose that I could create some fake examples where I keep the Likelihood constant and compare the final estimate for Beta Distributions with smaller "a and b" values vs Beta Distributions with larger "a and b" values - but I was wondering if there is a more "objective" way to demonstrate why this fact is true. Can someone please help me understand why larger values of "a and b" will result in the Prior having more impact on the final estimate? Thanks!
