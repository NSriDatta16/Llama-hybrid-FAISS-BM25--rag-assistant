[site]: crossvalidated
[post_id]: 488623
[parent_id]: 
[tags]: 
What will happen to the accuracy of machine learning models when we add more data?

If we have 100,000 labeled documents based on news topics (e.g., health, sports, science), and the accuracy of machine learning models is 70%. I want to see if adding more "good" data would improve the accuracy, and maybe adding "not so good" data would do nothing or just minor improvement. Should the new data be part of the training or testing or both? And is there a minimum size to add (e.g., 10% of the original data) or just try some random numbers? Let's say we add 10,000 new labeled documents, should we reduce the size of the total data from 110,000 to again 100,000 so that the comparison would be fair with the original experiment? And is there a recommended statistical test to compare the 2 experiments? And are there any recommended resources or papers on similar problems?
