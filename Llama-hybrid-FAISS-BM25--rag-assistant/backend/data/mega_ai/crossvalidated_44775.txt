[site]: crossvalidated
[post_id]: 44775
[parent_id]: 
[tags]: 
Basic Inter-rater reliability and type of data

I am looking to find out the type of data I have and the ideal test to use calculate inter-rater reliability. Research question: Functional Movement Screening: How reliable are we in our investigations? Aim: to look into the inter-rater reliability of Physiotherapists performing a functional movement screen (12 tests) on 2 athletes. My current data collection includes: 6 raters each scoring 12 tests with a yes and no answer. There are 2 sets (2 athletes) in total and each rater has given me y and n data for both. Example: Rater 1 6 Yes / 6 No Rater 2 7 Yes / 5 No Test 1 3 yes / 3 no (from raters) Test 2 4 yes / 2 no I would like to know: 1. the type of data I have? 2. am I looking at the reliability of the tests or do I need to focus on the raters scores? 3. the groups I need to organise the data into to give me the results? 4. the statistical test that would give me the inter-rater reliability of the raters and the tests? I am afraid statistics isn't one of my strong points and so apologies if this is very basic but any help anyone could give me would be much appreciated as I am having difficult at present.
