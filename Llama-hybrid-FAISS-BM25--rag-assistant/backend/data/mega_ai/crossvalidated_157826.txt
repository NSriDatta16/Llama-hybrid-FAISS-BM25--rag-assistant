[site]: crossvalidated
[post_id]: 157826
[parent_id]: 1856
[tags]: 
If you have discrete inputs, I'm writing a program to predict missing values of a binary input, given previous inputs. Any categories, e.g. "1 of 6", can be converted into binary bits, and it will work just fine; it won't effect it. The purpose of the algorithm I'm writing is to learn as fast as mathematically possible. Consequently it has very poor time and space complexity (space complexity about O(4^N)!. But for that you get essentially 1-off learning, for any system whose state can be expressed as a bit vector. For instance, a full-adder has 8 distinct input states. The algorithm will learn a full adder perfectly after only 8 distinct training samples. Not only that, but you can then give it the answer and have it predict the question, or give it part of the answer and part of the question and have it fill in the remaining. If the input data has a lot of bits, it'll be pretty computation and memory intensive. But if you've got very few samples, - or so the design goal is - it will give you near the best predictions possible. You just train it with bit vectors, including a bit vector of which bits are unknown. To get a prediction, you likewise just feed it a bit vector, which bits are unknown, and which bits you want it to predict. Source code available here: https://sourceforge.net/p/aithroughlogiccompression/code/HEAD/tree/BayesianInferenceEngine/src/_version2/
