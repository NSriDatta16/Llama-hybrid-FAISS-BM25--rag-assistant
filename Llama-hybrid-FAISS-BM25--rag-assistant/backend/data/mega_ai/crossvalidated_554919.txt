[site]: crossvalidated
[post_id]: 554919
[parent_id]: 498726
[tags]: 
To me it seems weird to compute the model, use the variable importance options and use the same model/algorithm for your classification model..., how weird are these steps to build a model? This is not weird, but exactly what variable importances were developed for! They do not provide a universal measure of relevance of the predictors; they only give a ranking of relevance for each predictor for the fitted model . One could argue it would be weird to use the variable importances of one fitted model to inform the fitting of a different model. You can fit different decision tree ensembles to the same data with (near) identical predictive accuracy, and obtain different values for the variable importances. Furthermore, computation of variable importances (re)uses data points, and the computed importance values will vary, depending on the distribution of these data points, as well as the possible permutation approach used. Your question seems to imply variable importances should be used to tune the model-fitting parameters of your model, or to perform some kind of inference (i.e., which variables do or do not affect the outcome). They should be used for neither. They quantify the contribution of each variable to the predictions generated by your model. This may be helpful because stakeholders may want to get at least some indication of why a black-box model makes certain predictions, but they obviously do not tell the whole story. Using variable importances to tune your model will likely lead to overfitting. Using variable importances to perform inference will likely lead to invalid conclusions. E.g., random forests and lasso regression tend to use many more variables for generating predictions, than actually affect the outcome (and, as you point out in one of the comments, xgboost and many random forest implementations suffer from biased variable selection). Predictive accuracy is often not much hurt by this, because of the averaging over many predictor's contributions that the methods perform. But for inference, it can be rather problematic.
