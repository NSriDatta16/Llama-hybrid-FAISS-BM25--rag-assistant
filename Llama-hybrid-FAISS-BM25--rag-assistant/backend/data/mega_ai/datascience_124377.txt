[site]: datascience
[post_id]: 124377
[parent_id]: 
[tags]: 
Bootstrapping formula for TD learning in Reinforcement Learning

In Reinforcement Learning (Sutton & Barto, 2018), p.120, equations (6.3)-(6.4) , to explain the idea of bootstrapping in Temporal-difference learning: \begin{equation} v_{\pi}(s) := E_{\pi}[G_t|S_t=s]\ (6.3) \\ = E_{\pi}[R_{t+1}+\gamma G_{t+1}|S_t=s] \ (\text{from}\ (3.9))\\ = E_{\pi}[R_{t+1}+\gamma v_{\pi}(S_{t+1})|S_t=s] \ (6.4) \end{equation} I am confused about the logic from the second line to (6.4). Why is $E_{\pi}[G_{t+1}|S_t=s] = E_{\pi}[v_{\pi}(S_{t+1})|S_t=s]$ ? The term $v_{\pi}(S_{t+1})$ also does not really make sense to my intuition because I interpret $S_{t+1}$ as a random variable. How can the value function take a random variable as the input?
