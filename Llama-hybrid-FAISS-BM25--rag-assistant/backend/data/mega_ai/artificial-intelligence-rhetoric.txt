Artificial intelligence rhetoric (AI rhetoric) is a term primarily applied to persuasive text and speech generated by chatbots using generative artificial intelligence, although the term can also apply to the language that humans type or speak when communicating with a chatbot. This emerging field of rhetoric scholarship is related to the fields of digital rhetoric and human-computer interaction. Description Persuasive text and persuasive digital speech can be examined as AI rhetoric when the text or speech is a product or output of advanced machines that mimic human communication in some way. Historical examples of fictional artificial intelligence capable of speech are portrayed in mythology, folk tales, and science fiction. Modern computer technology from the mid-20th century began producing what can be studied as real-world examples of AI rhetoric with programs like Joseph Weizenbaum's ELIZA, while chatbot development in the 1990s further enhanced a foundation for texts produced by generative AI programs of the 21st century. From an additional perspective, AI rhetoric may be understood as the natural language humans use, either typewritten or spoken, to prompt and direct AI technologies in persuasive ways (as opposed to traditional computer coding). This is closely related to the concepts of prompt engineering and prompt hacking. History While much of the research related to artificial intelligence was historically conducted by computer scientists, experts across a wide range of subjects (such as cognitive science, philosophy, languages, and cultural studies) have contributed to a more robust understanding of AI for decades. The advent of 21st-century AI technologies like ChatGPT generated a swell of interest from the arts and humanities. Generative AI technology and chatbots gained notoriety and rapid widespread use in the 2020s. Questions and theories about the power of machines, computers, and robots to persuasively communicate date back to the very beginnings of computer development, more than a decade before the first computer language programs were created and tested. In 1950, Alan Turing imagined a scenario called the imitation game where a machine using only typewritten communication might be successfully programmed to fool a human reader into believing the machine's responses came from a person. By the 1960s, computer programs using basic natural language processing, such as Joseph Weizenbaum's ELIZA, gave some users the illusion of humanity as human research subjects reading the machine's outputs became "very hard to convince that ELIZA is not human." Future computer language programs would build on Weizenbaum's work, but the first generation of internet chatbots in the 1990s up to the virtual assistants of the 2010s (like Apple's Siri and Amazon's Alexa) received harsh criticism for their less-than-humanlike responses and inability to reason in a helpful manner. By the late 1980s and early 1990s, scholars in the humanities began laying the groundwork for AI rhetoric to become a recognized area of study. Michael L. Johnson's Mind, Language, Machine: Artificial Intelligence in the Poststructuralist Age argued for the "interdisciplinary synthesis" necessary to guide an understanding of the relationship between AI and rhetoric. Lynette Hunter, Professor of the History of Rhetoric and Performance at the University of California, Davis, published "Rhetoric and Artificial Intelligence" in 1991, and was among the first to directly apply the lens of rhetoric to AI. Twenty-first century developments in the scholarship of AI rhetoric are outlined in the July 2024 special issue of Rhetoric Society Quarterly, which is devoted to "Rhetoric of/with AI". Special issue editors S. Scott Graham and Zoltan P. Majdik summarize the state of the field when they write "rhetorical research related to AI engages all manner of specialty domains [...] Because AI now touches on almost all areas of human activity, rhetorics of AI can help co