[site]: crossvalidated
[post_id]: 563818
[parent_id]: 563780
[tags]: 
A cleaner approach would be to predict only the numerator and divide by this target feature in the end. However, if your only decision (as you wrote in the comments) is to include or exclude this feature, I don't see a reason to exclude it, but only if this feature is fully accessible on serving time. The main risk to include labels in the features, is data snooping, i.e. you "cheat" on training time, getting good performance, but then fail on serving because not all the features is fully accessible during serving. Another advantage to go with the cleaner approach, is that sometimes it is harder (not impossible though) for some models, e.g. neural networks, to model multiplication or division. For example, in NN, the output is a composition of non linear function over linear combination of the features and the weights. Getting a direct $x_1 * x_2$ is not possible and harder to model.
