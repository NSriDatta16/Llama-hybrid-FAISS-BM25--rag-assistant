[site]: crossvalidated
[post_id]: 641587
[parent_id]: 
[tags]: 
Ensemble Methods for Probabilities

I am currently trying to build a stacked algorithm in order to determine how many people in each region of a country will be likely to buy a product versus its competitors. I have some data from an online survey which collects user's demographics as well as their preferred product and I've weighted these so they reflect my customer base correctly. I currently have three models that I am happy with (XGBoost, Random Forest and Multi-Layer Perceptron) - they give me probabilities that I can then use to poststratify to determine how many people in each region will buy each product. I now want to stack these models together so I can get a better model that incorporates all of the predictions. I would like to do this so that at the end I get some distributions of how many people I might be able to target in each region, rather than just a point estimate. I have tried building a model in BRMS (R) which uses the predicted probabilities from each model and treats them linearly, e.g. product ~ prob_A_XGB + prob_B_XGB + prob_A_RF + prob_B_RF + ... where I have dropped one of my products to avoid multicollinearity in the model. Unfortunately, my meta model gives very different predictions to my base models. I have also tried building a model which uses a majority voting by using the predicted product from each model but this performs even worse. Is there anyway to essentially take a "weighted" average of the class probabilities in my base models that will give me a distribution of the potential number of customers in each region?
