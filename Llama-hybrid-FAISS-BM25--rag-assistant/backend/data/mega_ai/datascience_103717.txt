[site]: datascience
[post_id]: 103717
[parent_id]: 
[tags]: 
Machine translation transformer output - "unknown" tokens?

Cross post from my original post in Stackoverflow: https://stackoverflow.com/questions/69595863/machine-translation-transformer-output-unknown-tokens Based on the feedback , I have now updated my approach to use WordPiece from Huggingface's pretrained BERT tokenizers. However, I still run into "unk" tokens when translating. I am curious why that still happens? I thought that WordPiece would try to decode without outputting any "unk" tokens. This is how I tokenized my data, I am using German to english for the translation task. from transformers import BertTokenizer bert_tokenizer_en = BertTokenizer.from_pretrained("bert-base-uncased") bert_tokenizer_de = BertTokenizer.from_pretrained("bert-base-german-cased",do_lower_case=True) Example out: ground truth = ['a', 'girl', 'in', 'a', 'jean', 'dress', 'is', 'walking', 'along', 'a', 'raised', 'balance', 'beam', '.'] predicted = ['a', 'girl', 'in', 'a', ' ', 'costume', 'is', 'jumping', 'on', 'a', 'clothesline', '.', ' '] ````
