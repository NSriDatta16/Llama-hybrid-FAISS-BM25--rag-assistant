[site]: crossvalidated
[post_id]: 423638
[parent_id]: 
[tags]: 
First derivative of splines in bayesian model

Inspired by this post https://www.fromthebottomoftheheap.net/2014/05/15/identifying-periods-of-change-with-gams/ , I'm trying to identify periods of change in a GAM model, using bayesian inference. However, I find that my choice of epsilon (the delta difference between two points), is very sensitive to the resulting confidence intervals. If I choose a really small epsilon, which is what we should want and do, my intervals of the associated first derivative blow up. If this epsilon is bigger, the intervals are narrower. I'm using the method of finite differences , where we estimate the trend at two points very close to each other, and calculate the difference between those two points to estimate the slope. I'm clearly missing out on something while calculating the derivatives. library(dplyr) library(magrittr) library(ggplot2) library(brms) library(mgcv) set.seed(08242019) dta % cbind(lower_finite_diff) %>% cbind(upper_finite_diff) %>% cbind(first) %>% ggplot(.,aes(x2, mean_finite_diff, group = fac)) + geom_smooth(aes(color = fac), se = FALSE) + geom_ribbon(aes(ymin = lower_finite_diff, ymax = upper_finite_diff), alpha = 0.05) However, when you decrease the epsilon, epsilon % mutate(x2 = x2 + epsilon) ## get predictions first_preds % cbind(lower_finite_diff) %>% cbind(upper_finite_diff) %>% cbind(first) %>% ggplot(.,aes(x2, mean_finite_diff, group = fac)) + geom_smooth(aes(color = fac), se = FALSE) + geom_ribbon(aes(ymin = lower_finite_diff, ymax = upper_finite_diff), alpha = 0.05) The width of the intervals blow up
