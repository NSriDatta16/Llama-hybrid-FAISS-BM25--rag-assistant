[site]: crossvalidated
[post_id]: 628581
[parent_id]: 
[tags]: 
How are Markov chains memoryless when they have memory of size 1?

Markov chains are typically described as memoryless as the next state depends only on the current state but not any of the past states. But wouldn't true memorylessness mean that the next state does not depend on any state? The way I view it, if the next state depends on the current state, then the system has a memory of size 1 - making it not memoryless. In other words: X_t+1 = f(X_t) -> Markov Chain X_t+1 = f() -> What is this called? Put differently: If the Markov process as such is described as memoryless, then what would you call a process that can jump randomly to any state regardless of where it currently is (which the Markov process can not do)? Memorylesser ?
