[site]: crossvalidated
[post_id]: 210414
[parent_id]: 210326
[tags]: 
A generative model is basically a story of how the data could have been generated. Inside this story, we leave some parameters unspecified: these are the parameters that we are interested in learning about by collecting the data. For example, if we have collected the height of 100 persons, and we want to determine the mean height in the county these people come from, one fiction we could come up with is: "some person's height = a Gaussian centered a the population mean with std 30 cm" Now, once we have a generative model, we can ask what the data tells us about the parameters of interest, under this model. You can be Bayesian here: you would then compute the posterior of the paramater of interest. But you don't have to be: you can also, for example, find the parameter-value which fits the data the best: the maximum-likelihood value. That's a frequentist approach to generative models. So the answer to your question is: "no". Generative models are necessary to apply bayesian methods, but you can also do maximum-likelihood (frequentist) inference on them.
