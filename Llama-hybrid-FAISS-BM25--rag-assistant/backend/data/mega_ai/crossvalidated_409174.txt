[site]: crossvalidated
[post_id]: 409174
[parent_id]: 407866
[tags]: 
The question is a bit vague, but here are my (similarly vague) thoughts on the individual points: Whether this is the best way to capture what I'm trying to capture. I am highly skeptical that there is a "best" analysis, let alone that a "good" analysis can be determined without deeply understanding the dataset you have. Your proposed rough sketch seems OK-ish, although I see few areas where you could likely improve a bit (or not, really depends on the data and domain knowledge I do not possess). It also depends on how deep into the rabbit hole are you willing to go. Generally, I really like the brms R package, which should have most of the stuff you are likely to need already implemented. Some ideas for improvement: Instead of linear or quadratic effect of time, you could use splines to allow for a wide array of smooth time vs. effect relationships. This rids you of the arbitrary splitting of data into time ranges. The downside is that to estimate the spline effect, you would probably need to make the time effect constant (in some sense) across studies. This might and might not be wrong. When working on the log scale (as you likely will be), this assumption will expect the subjects to have a different prevelence/severity in each study, but then the proportions halving at about the same time for all studies. Is this reasonable? I don't know, I know nothing about mental health :-) Fitting a single model for all data - assuming that the studies with prevalence give a cutoff score for the depression scale where they considered patients as having depression, you can consider the data as continuous, but censored (from both sides) at the cutoff. I think this can be achieved in brms via the cens keyword, but not sure you can easily put it together with using the metaanalysis features of brms What's the best way to generate these study-specific slopes IMHO a normal varying slope coefficient could work well. When using brms the formula could be something like severity | se(severity_se) ~ 1 + (1 + time || study) where severity_se is the standard error from the study (not tested, please check yourself). Whether the process of generating them will be different for studies contributing proportions versus those contributing means/SDs Not really, as a first approximation the same formula should IMHO work, just using the binomial response distribution and swapping se(severity_se) for trials(n_subject) to indicate the precision of the measurement. How to test whether linear or quadratic slopes are more appropriate for a given study (or whether I need to use the same kind of slope across studies) First, I think quadratic slopes are easy to get wrong, so I would be wary. Note that you will likely be working on log or log-odds scale, linear slope means exponential decay/increase of syndroms, while quadratic is kind of hard to interpret. Generally brms lets you to do posterior predictive checks to see whether the model has systematic problems fitting the data. If one model has those and the other one doesn't, it is an indication that the latter is to be preferred. Whether it will be a problem that many studies only include 2 effect sizes Not necessarily, especially when you are using a fully Bayesian treatment (as brms does). You are however likely to obtain only very vague estimates of the effects. How to then meta-analyze the resulting slopes This really depends on the question you are asking. The estimate of the between-study variability of the slope may be of interest on its own (tells about heterogeneity of the data). You can also let brms do predictions of the prevalence/severity over time for a hypothetical new study drawn from the same population of studies as you used and interpret those.
