[site]: crossvalidated
[post_id]: 34499
[parent_id]: 34479
[tags]: 
Using disjoint data across runs is preferable. Training sets that overlap will have some positive correlation in the fitted models, so the variance of the average test error will be greater, Var($\sum_i X_i$) = $\sum_i$ Var($X_i$) + $2\sum_{i If you are restricted to only fitting 5 models I would do 5-fold cross validation; use 20k points to train and 5k points to test (overlapping training data, disjoint test data). There is a trade-off between training size and number of test error samples. The larger the training size the smaller any given test error variance (variance of $\beta$ in regression behaves like $O(n^{-1/2})$ for instance). However the more test error samples the smaller the variance of their average (variance of mean also $O(n^{-1/2})$). The choice here should not depend on how large (3k) you expect future test sets to be, but rather how much training data you have and how much data you need to fit each model reasonably well. If you can afford to do this with disjoint train/test data it is preferable, should you have this luxury.
