[site]: stackoverflow
[post_id]: 3905787
[parent_id]: 3905632
[tags]: 
For such large ammounts of data you need to only have a portion of the data in memory. The other data should be serialized to the hard drive. I tackled such a problem like this: I Created an extended storage that can store a custom record either in memory or on the hard drive. This storage has a maximum number of records that can live simultaniously in memory. Then I Derived the record classes out of the custom record class. These classes know how to store and load themselves from the hard drive (I use streams). Everytime you need a new or already existing record you ask the extended storage for such a record. If the maximum number of objects is exceeded, the storage streams some of the least used record back to the hard drive. This way the records are transparent. You always access them as if they are in memory, but they may get loaded from hard drive first. It works really well. By the way RAM works in a very similar way so it only holds a certain subset of all you data on your hard drive. This is your working set then. I did not post any code because it is beyond the scope of the question itself and would only confuse.
