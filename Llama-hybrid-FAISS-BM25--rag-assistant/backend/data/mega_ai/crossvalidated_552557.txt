[site]: crossvalidated
[post_id]: 552557
[parent_id]: 
[tags]: 
Survival Analysis in the Absence of Censoring

I am interested in better understanding the effects of "censoring" in Survival Analysis. I have heard that two of the main motivations which started the field of Survival Analysis were: 1) Survival Regression Models allow you to estimate hazard and survival probabilities over a period of time (e.g. 1021 days from now, what is the survival probability of someone in a specific cohort?) - whereas Classical Regression Models (e.g. time_of_event = b_0 + b1_age + b2_weight) would only allow you to measure the average expected survival time (i.e. a point estimate, e.g. someone in a specific cohort will experience the "event" 200 days from now, plus-minus 15 days). 2) Survival Regression Models allow for Censored Data (e.g. a patient in a medical study has to move to a new country before the study is finished - we have some information about this patient, but are still missing the "response" for this patient) . For example, in the case of the Cox Proportional Hazards, a special likelihood function was developed to estimate model parameters in the presence of censored data. In short, Survival Models allow you to use the "complete" part of "incomplete data", whereas standard regression models would require you to discard these observations all together. My Question: I have consulted other questions (e.g. Time to event with no censoring - use survival or normal regression? ) which suggest that "censoring" is not required for Survival Analysis Models, and that Survival Analysis Models (e.g. Kaplan-Meier, Cox PH) can full work in the absence of censoring. I have also consulted other questions (e.g. How do you compare two "survival times" when there is no censoring per se? ) which state that not only Survival Models can work without "censoring", but the absence of censoring can be considered as a "blessing". Are there any theoretical results that show for Survival Models (e.g. Kaplan-Meier, Cox PH) that show "(for a given dataset) no censoring is better than censoring?" Or that "less censoring is better than more censoring"? Perhaps the confidence intervals become tighter when censoring is less? Do any such results exist within the domain of Survival Analysis?
