[site]: crossvalidated
[post_id]: 313281
[parent_id]: 313026
[tags]: 
The bootstrapped distribution of effect estimates using your approach cannot be interpreted as an approximation to the population sampling distribution of effects from either a sampling or randomization perspective, so it would be inappropriate to use the standard errors you got from that method as standard errors of the effect estimate. The approach to average the effect estimates seems reasonable to me; it's a version of multiple imputation, where you are imputing the missing potential outcomes multiple times with different matched units in each "imputation" (.e., each bootstrap iteration). It would then be appropriate to apply Rubin's rules to get an effect estimate and standard errors from the imputed samples. Your standard error would include within-imputation variability due to sampling/randomization AND across-imputation variability due to the variation in matched units. The variability in your bootstrap distribution of effect sizes would be the main factor in this second component, but you'd still need to compute the first component using traditional methods (e.g., Abadie and Imbens SEs, etc.). This approach has not been studied, but this might make an interesting research project. Don't take my word for it; this is intuition based on my understanding of multiple imputation and related processes of arranging data within your sample (e.g., parceling in confirmatory factor analysis). I think a better approach would be to use a deterministic matching algorithm and using all matched units. For example, if 5 control units fall within the caliper of 1 treated unit, use all 5 control units as matches. This is called variable matching and has been shown to be more effective than 1:1 matching at reducing bias and variability.
