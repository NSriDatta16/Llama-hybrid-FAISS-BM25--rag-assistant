[site]: datascience
[post_id]: 16468
[parent_id]: 16422
[tags]: 
As a research area, Deep Learning is really just a sub-field of Machine Learning as Machine Learning is a sub-field of Artificial Intelligence. 1) Unsupervised Feature Learning Conceptually, the first main difference between " traditional " (or " shallow ") Machine Learning and Deep Learning is Unsupervised Feature Learning. As you already know, successfully training a " traditional " Machine Learning model (ex: SVM, XGBoost...) is only possible after suitable pre-processing and judicious feature extraction to select meaningful information from the data. That is, good feature vectors contain features distinctive between data points with different labels and consistent among data points with the same label. Feature Engineering is thus the process of manual feature selection from experts. This is a very important but tedious taks to perform! Unsupervised Feature Learning is a process where the model itself selects features automatically through training. The topology of a Neural Network organized in layers connected to each other have the nice property of mapping a low-level representation of the data to a higher-level representation. Through training, the network can thus " decide " what part of the data matters and what part of the data doesn't. This is particularly interesting in Computer Vision or Natural Language Processing where it is quite hard to manually select or engineer robust features. (picture credits: Tony Beltramelli) As an example, let's assume we want to classify cat pictures. Using a Deep Neural Net, we can feed in the raw pixel values that will be mapped to a set of weights by the first layer, then these weights will be mapped to other weights by the second layer, until the last layer allows some weights to be mapped to numbers representing your problem. (ex: in this case the probability of the picture containing a cat) Even though Deep Neural Networks can perform Unsupervised Feature Learning, it doesn't prevent you from doing Feature Engineering yourself to better represent your problem. Unsupervised Feature Learning, Feature Extraction, and Feature Engineering are not mutually exclusive! Sources: http://deeplearning.stanford.edu/tutorial/ https://arxiv.org/abs/1404.7828 https://arxiv.org/abs/1512.05616 (Chapter 2, Section 2) 2) Linear Separability Deep Neural Networks can solve some non-linearly separable problems by bending the feature space such that features become linearly separable. Once again, this is possible thanks to the network topology organized in layers mapping inputs to new representations of the data. (picture credits: Christopher Olah) Sources: http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/ 3) Statistical Invariance Lastly, Deep Neural Networks are surpassing traditional Machine Learning algorithms in some domains because some architectures are showcasing Statistical Invariance (ex: Spacial Statistical Invariance with Convolutional Neural Networks and Temporal Statistical Invariance with Recurrent Neural Networks) Check this Udacity video for more details: https://www.youtube.com/watch?v=5PH2Vot-tD4
