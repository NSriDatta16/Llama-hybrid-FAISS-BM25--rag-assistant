[site]: crossvalidated
[post_id]: 436223
[parent_id]: 436207
[tags]: 
If you are using R , then what you want is to use the offset argument to include a fixed, known constant in your linear predictor. See below for a simulated example. Type ?glm and look for the entry on offset for the explanation. set.seed(1) n = 100 x = rnorm(n) alpha = 0.3; #true intercept beta = 0.9; #true coefficient y = rbinom(n, 1, plogis(alpha + beta * x)); #Here is your vanilla logistic regression summary(glm(y ~ x, family = "binomial")); Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) 0.3131 0.2225 1.407 0.159468 x 1.0938 0.2958 3.697 0.000218 *** #Here is your logistic regression accounting for the known offset summary(glm(y ~ 1, family = "binomial", offset = x * beta)) Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) 0.3148 0.2171 1.45 0.147 Note: There are several reasons that the estimated coefficient from the literature would not be expected to have the same (true) value as yours. For example, your model would need to adjust for exactly the same set of covariates as the historical model (note, this means you cannot adjust for anything additional). Otherwise you would not expect the coefficient estimates to have the same true asymptotic value. See https://www.jstor.org/stable/pdf/1403444.pdf . Or your sampling populations might be different. You may consider a middle ground between ignoring the historical literature entirely and assuming that it is exactly as reported with no statistical uncertainty, e.g. by placing a Bayesian prior on your coefficient, centered at the reported historical value. See https://www.kaggle.com/avehtari/bayesian-logistic-regression-with-rstanarm
