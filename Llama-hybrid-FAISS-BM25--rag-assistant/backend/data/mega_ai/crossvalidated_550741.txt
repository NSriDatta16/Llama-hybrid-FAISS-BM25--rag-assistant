[site]: crossvalidated
[post_id]: 550741
[parent_id]: 550731
[tags]: 
Logistic regression is a generalized linear model . Generalized linear models are rather simple, easily explainable, linear in parameters models that generalize the idea behind linear regression. While linear regression predicts $$ E[y|X] = \mathbf{X}\boldsymbol{\beta} $$ generalized linear models predict $$ E[y|X] = g^{-1}\Big( \mathbf{X}\boldsymbol{\beta} \Big) $$ where $g^{-1}$ is an inverse of a link function "provides the relationship between the linear predictor and the mean of the distribution function". In case of logistic regression, the mean of Bernoulli distribution is probability, so it is bounded between zero and one. Logistic function is one of the links that maps the linear predictors to the interval (you can use also other links, for example probit , complementary log-log, or other). If likelihood is another distribution, the link would differ, for example, with Gaussian the link is an identify function (no link), for Poisson you could use log link because it needs to be non-negative, etc. The documentation of the family method in R summarizes the possible choices: The gaussian family accepts the links (as names) identity, log and inverse; the binomial family the links logit, probit, cauchit, (corresponding to logistic, normal and Cauchy CDFs respectively) log and cloglog (complementary log-log); the Gamma family the links inverse, identity and log; the poisson family the links log, identity, and sqrt; and the inverse.gaussian family the links 1/mu^2, inverse, identity and log. If you didn't use the link function for logistic regression, you would be predicting the probabilities that are below zero or above one, they wouldn't be valid.
