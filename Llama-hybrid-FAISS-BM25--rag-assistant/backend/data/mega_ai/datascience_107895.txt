[site]: datascience
[post_id]: 107895
[parent_id]: 107840
[tags]: 
I could figure out the issue with my code. It was "data leakage". My earlier sequence of pre-processing code was below: Load the data Augment the data Balance the data Shuffle the data Split the data between "Train" and "Validation" Saturate the "Train" outliers to a constant value Saturate the "Validation" outliers to a constant value Normalize the data between 0 and 1 Feed the "Train" and "Validation" data to the model Plot the training and validation graph As you can see in the above sequence the information was leaking from the validation data to the training data. Hence I was getting a perfect picture of converging model (as graph posted in the original question). I modified the sequence of pre-processing as below: Load the data Split the data between "Train" and "Validation" Augment the "Train" data Balance the "Train" data Shuffle the "Train" data Shuffle the "Validation" data Saturate the "Train" outliers to a constant value Saturate the "Validation" outliers to a constant value Normalize the "Train" data between 0 and 1 Normalize the "Validation" data between 0 and 1 Feed the "Train" and "Validation" data to the model Plot the training and validation graph Now the graph gives me much more realistic picture of accuracy and loss in the CNN. See below. It looks like after 100 iterations, accuracy remains constant (around 70%) and loss blows up. I do not know how to fix the exploded loss. However, at least I am not getting a false picture now.
