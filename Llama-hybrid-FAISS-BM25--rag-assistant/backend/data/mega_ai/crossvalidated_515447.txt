[site]: crossvalidated
[post_id]: 515447
[parent_id]: 
[tags]: 
why is the accuracy of my RNN model going up and down so much

So I am using RNNs and using the train and test datasets. I have pre processed all the data and used one hot encoding, normalization, feature selection etc but the accuracy of the model is looking a bit off on the testing set and I am not sure what it means. It could be overfitting possibly? I have plotted the outcome on a line graph for the outcome of the model accuracy and the loss of the model if it helps. model = Sequential() model.add(LSTM(units= 20, activation='relu', return_sequences=True, input_shape =(1,121))) model.add(Dropout(0.1)) model.add(LSTM(units= 40, activation='relu', return_sequences=True)) model.add(Dropout(0.1)) model.add(LSTM(units= 60, activation='relu', return_sequences=True)) model.add(Dropout(0.1)) model.add(Dense(1)) model.add(LSTM(units= 80, activation='relu', return_sequences=True)) model.add(Dropout(0.1)) model.add(LSTM(units= 100, activation='relu')) model.add(Dropout(0.1)) model.add(Dense(1)) model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) model.summary() history = model.fit(x_train_binary, y_train2, batch_size=128, epochs=125, validation_data=(x_test_binary, y_test2))
