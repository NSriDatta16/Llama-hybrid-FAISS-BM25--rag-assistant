[site]: crossvalidated
[post_id]: 386436
[parent_id]: 297076
[tags]: 
To agree on basic terminology, there are two classes - positive (i.e., "good customers") and negative ("bad customers"). You want to build a function $f$ that can classify good vs. bad customers. Your labeled data consists of only "good" customer information. There are two approaches you can explore: Simpler Approach One-Class Learning : The basic intuition is that you want to construct a probability distribution over the support for the true distribution of "good" customers. There are a few approaches you can use here including: One-Class SVM , Isolation Forest , etc. The problem with the one class approach is that you are only considering information in the labeled data (which is usually far smaller than the unlabeled set). This often leads to poorer results. A Better Approach Positive-Unlabeled (PU) Learning : This technique fits perfectly for your scenario. PU learning is a specialized form of semi-supervised or transductive learning. It builds a classifier using the positive (labeled) data and unlabeled data together. Elkan and Noto published one of the seminal results in this field. The paper is quite beautiful as it uses basic probability theory to build a very powerful and effective PU classifier. You can find open source implementations of Eklan and Noto's algorithm online.
