[site]: datascience
[post_id]: 73381
[parent_id]: 63874
[tags]: 
As Victor proposed, you probably need the graph convolution networks. 40K nodes is borderline too much for the memory, so you could consider GraphSAGE-alike approaches, which propose to sample subgraphs around target points and then run some sort of GCN or GAT (graph attention networks) for them. You could use library like DGL or pytorch geometric for that. Other notable approach is Deep Walk, it generates some embedding by neighborhood. As a plus, it preserves the locality in the embedding. The minus, in my experience, it's not scales so well, but you can give it a try.
