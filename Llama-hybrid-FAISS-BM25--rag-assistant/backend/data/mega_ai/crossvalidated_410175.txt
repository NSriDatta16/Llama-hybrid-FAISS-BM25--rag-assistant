[site]: crossvalidated
[post_id]: 410175
[parent_id]: 
[tags]: 
How do I compare the predictive power of two predictors within a single (logistic) regression?

I've read about how F-tests can be used to compare models and to decide whether an additional variable should be included in the regression. However, I want to test whether A vs. B are better predictors of Y. (In the case of my actual project, I have two models, A vs. B, that attempt to predict some phenomena and I want to test which is a stronger predictor). So I run a linear regression: Y ~ A + B This gives me an ANOVA table showing that the F-value associated with A and B are both significant. However, the F-value of A is a powerful 20, but the F-value of B is a wimpier 5. How should I compare the predictive powers of A vs. B? I want to definitively say that one is more predictive than the other one (preferably using non-Bayesian statistics). Comparing the slopes of the regression seems not appropriate since the value distributions of A and B may have different variances. Should I take the SquaredSum(A) / SquaredSum(B) = my new F-value? If I do this, should the F-critical value have DF1 = n-2, DF2 = n-2, where n = number of subjects? None of this would change if I was doing a logistic regression and/or a multilevel model, right? Would this answer be most elegantly framed in terms of AIC or BIC? Thanks (I don't want to use Bayesian statistics for simplicity's sake if I'm explaining results to others. If I can do this all with a straightforward F-test, that would be nice.)
