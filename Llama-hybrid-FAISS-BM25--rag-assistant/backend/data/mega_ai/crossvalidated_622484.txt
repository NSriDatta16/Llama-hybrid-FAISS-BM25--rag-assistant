[site]: crossvalidated
[post_id]: 622484
[parent_id]: 
[tags]: 
Why does Non-negative Matrix Factorization not give me 100% R^2 at full rank?

IMPORTANT: Please read the question carefully before labeling it a "code question" & sending it to stack overflow. The question is in fact a theoretical stats question (barring the possibility of a bug in the NMF R library). Because I can do better than NMF (at full rank) on a positive matrix A, by using the identity transform! i.e. W=A,H=I (identity), s.t. A~=WH. How could NMF possibly be so bad?? I don't understand why NMF would behave like this while PCA gives perfect invertibility even at much lower rank. I'm using the R library: NMF & NMF method: "brunet" This is my code: library(NMF) mass_NMF = nmf(mass_frac_data, rank=ncol(mass_frac_data)) # NOTE: mass_NMF@fit@W==mass_PCA$x, mass_frac_data~=mass_NMF@fit@W%*%mass_NMF@fit@H cat('NMF R^2 on original data: ', get_explained_var(mass_NMF@fit@W, mass_frac_data)) This is the output: NMF R^2 on original data: 0.9240395 (aka 92%) (PCA obviously gets approximately 99%, even at much lower rank) The get_explained_var(X_df, Y_df) function (thoroughly tested) fits linear models to each of the Variables/Columns in Y_df & uses all the variables in the X_df + a bias for predictors (i.e. lm_i = lm(Y_df[,i]~X_df)) then it takes the average of all R^2 values from these linear models.
