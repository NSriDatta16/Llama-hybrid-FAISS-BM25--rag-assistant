[site]: crossvalidated
[post_id]: 33186
[parent_id]: 33175
[tags]: 
I think Chl has pointed you to a lot of good material and references without directly answering the question. The answer I give may be a little controversial because I know some statisticians don't believe in multiplicity adjustment and many Bayesians don't believe in p-value. In fact, I once heard Don Berry say that using the Bayesian approach, particularly in adaptive designs, controlling the type I error is not a concern. He took that back later after seeing how practically important it is to the FDA to make sure that bad drugs don't get to market. My answer is yes and no. If you do 45 tests, you certainly need to adjust for multiplicity but not to Bonferroni because it could be far too conservative. The inflation of the type I error when you data mine for correlation is clearly an issue that got attention with the cited post "look and you shall find correlation". All three links provide great information. What I think is missing is the resampling approach to p-value adjustment as developed so nicely by Westfall and Young. You can find examples in my bootstrap book or complete details in their resampling book. My recommendation would be to consider bootstrap or permutation methods for p-value adjustment and perhaps consider false discovery rate over the stringent family-wise error rate. Link to Westfall and Young: http://www.amazon.com/Resampling-Based-Multiple-Testing-Adjustment-Probability/dp/0471557617/ref=sr_1_1?s=books&ie=UTF8&qid=1343398751&sr=1-1&keywords=peter+westfall A recent book by Bretz et al on multiple comparisons: http://www.amazon.com/Multiple-Comparisons-Using-Frank-Bretz/dp/1584885742/ref=sr_1_2?s=books&ie=UTF8&qid=1343398796&sr=1-2&keywords=peter+westfall My book with the material in section 8.5 and tons of bootstrap references: http://www.amazon.com/Bootstrap-Methods-Practitioners-Researchers-Probability/dp/0471756210/ref=sr_1_2?s=books&ie=UTF8&qid=1343398953&sr=1-2&keywords=michael+chernick
