[site]: crossvalidated
[post_id]: 545796
[parent_id]: 545686
[tags]: 
With the binomial regression, you are assuming that when you see level 3, you had 5 independent binary yes/no outcomes that each could have been yes or no independent (conditional on the observed covariate values for that subject) from each other. You are assuming that the probabilities of each binary outcome are the same (conditional on the observed covariates values, which are identical for a subject), which may mismatch your observed data rather badly. This model also mismatches the data generating process: you can only get to level 3, if you are already above levels 0, 1 and 2, but if you did not get from level 3 to 4, then whether you hypothetically would have mde it from 4 to 5 does not matter. In a Bayesian setting something like posterior predictive checks might be able to illustrate just how much this does or does not mismatch the actually data distribution. So, on a whole, that model produces a smaller standard error by making lots and lots of assumptions and these assumptions seem to be rather questionable to me. A small standard error certainly does not mean anything is good about a model (counter example: "my model" always estimates 42 with a standard error of 0). Proportional odds logistic regression, of course, also makes assumptions. These are less strong than the ones spelled out above and can, if truly necessary, be relaxed further. It would be a rather obvious starting point though. Perhaps one additional perspective would be to do cross-validation and to see which of the two models predicts better on the out-of-fold data (admittedly not quite the same task as inference), perhaps simply in terms of mean absolute error (0=correct category predicted, 1=missed by one category, 2=missed by two categories etc.).
