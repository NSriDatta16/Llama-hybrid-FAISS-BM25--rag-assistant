ained AI models, which may have significant societal impacts. They argue that the Act's narrow focus on deployment contexts and reliance on providers to self-declare intended purposes creates opportunities for misinterpretation and insufficient oversight. Additionally, the Act often exempts open-source models and neglects critical lifecycle phases, such as the reuse of trained models. Trained models store decision-mappings as parameters that approximate patterns from the training data. This "model data" is distinct from the original training data and is typically classified as non-personal, as it often cannot be traced back to individual data subjects. Consequently, it falls outside the scope of other regulations like the GDPR. Some scholars also criticize the AI Act for not sufficiently regulating the reuse of model data, warning of potentially harmful consequences for individual privacy, social equity, and democratic processes. See also Algorithmic bias Artificial intelligence and elections â€“ Use and impact of AI on political elections Ethics of artificial intelligence European Artificial Intelligence Office Existential risk from artificial general intelligence Regulation of algorithms Regulation of artificial intelligence in the European Union Notes == References ==