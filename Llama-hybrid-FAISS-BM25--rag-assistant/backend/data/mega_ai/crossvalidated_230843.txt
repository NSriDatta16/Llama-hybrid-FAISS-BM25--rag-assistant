[site]: crossvalidated
[post_id]: 230843
[parent_id]: 229862
[tags]: 
The measures ME, RMSE, MAE, MPE, MAPE, and MASE reported in the model output are in-sample measures. They are not robust to overfitting as you can improve them simply by fitting a richer model. Therefore, they should not be central in guiding the model choice. Meanwhile, AIC, AICc and BIC are robust to overfitting, as long as you are not comparing too many models at once (see Hansen "A winnerâ€™s curse for econometric models: on the joint distribution of in-sample fit and out-of-sample fit and its implications for model selection (2010)). AIC and AICc target one-step-ahead preditions. (AICc offers improvement over AIC in small samples, so you could just ignore AIC and stick to AICc.) If you want to select the model that should be better at forecasting (which seems to be your goal), look for the one with the lowest AIC and AICc values. Meanwhile, BIC may select the true model if it is among the candidate models. The true model need not be the one that predicts best (paradoxical as it may sound) but sometimes you are just interested in how the data was generated. Then look for a model with the lowest BIC value. However, for AIC, AICc and BIC to be directly comparable across models, you need the dependent variable to be exactly the same across the models. I suspect here it is not the case. The two models reported above include seasonal differencing; the seasonal periods differ (23 and 35). This way the model for the differenced data is fit on a longer time series in case of 23 than in case of 35. What you could to to circumvent this is cut the first 12 observations for the model with period 23. Then the AIC, AICc and BIC should be comparable.
