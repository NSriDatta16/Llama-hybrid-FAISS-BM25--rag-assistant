[site]: stackoverflow
[post_id]: 2228621
[parent_id]: 
[tags]: 
robots.txt ignrore all folders but crawl all files in root

should i then do User-agent: * Disallow: / is it as simple as that? or will that not crawl the files in the root either? basically that is what i am after - crawling all the files/pages in the root, but not any of the folders at all or am i going to have to specify each folder explicitly.. ie disallow: /admin disallow: /this .. etc thanks nat
