[site]: crossvalidated
[post_id]: 448624
[parent_id]: 448580
[tags]: 
Firstly, I would consider a fifth "baseline" model $M_0$ which basically is a model that always predicts using the average (In your example 33.165) and now we have the following 5: m0 Firstly, let's take a look at a the train data. # Baseline model vs Model with X1 and X2 only anova(m0, lm(y~x1,data=train) , test = "F") anova(m0, lm(y~x2,data=train) , test = "F") # Model with X1 vs m1 and model with X2 vs m1 anova(lm(y~x1,data=train), m1 , test = "F") anova(lm(y~x2,data=train), m1 , test = "F") # Model m1 vs m2 anova(m1, m2, test = "F") From the training data, we can see that the simple regression models with X1 and X2 only yield statistically significant better fit vs the model with just the average (looking at the p-values). Similarly for the combination of X1 and X2 vs the models with X1 and X2 independently. However, we have no evidence than a model with more variables works better than m1. This is all from the training dataset. Now, let's predict on the new test dataset and see how accurate each model is. We will then calculate the MSE to see how close are predicted values are to the real values (You can think of the MSE as the average difference between real values and the predicted ones squared. It basically measures how close the predicted to real are and then it squares it so that it penalises them the further they are) pred_m0 $y)^2) m1_MSE y)^2) m2_MSE $y)^2) m3_MSE y)^2) m4_MSE It seems that $M_1$ has the lowest out-of-sample MSE and thus the best predictive power which in that case agrees with what we saw before in the training dataset. To measure some kind of accuracy for models 1 and 3 I will compare them with the baseline model (predicting with just the average) sum((pred_m1 - test $y)^2)/ sum((pred_m0 - test$ y)^2) sum((pred_m3 - test $y)^2)/ sum((pred_m0 - test$ y)^2) And to me this shows that $M1$ predicts with a less than 1% error compared to the baseline model whereas $M3$ predicts with 20% of the error of the baseline model. In other words, one predicts 260 times better than the average and the other one 5 times better than the average.
