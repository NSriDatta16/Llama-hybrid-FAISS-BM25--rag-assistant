[site]: crossvalidated
[post_id]: 610574
[parent_id]: 
[tags]: 
xgboost algorithm is giving excellent auc score on train, validation and test datasets (0.94) but giving worst public score (0.5) after submission

I am a beginner in ML modelling. I am working on Santander Customer Satisfaction Prediction competition and the evaluation metric is AUC . The dataset has 370 features and the target variable is TARGET with values 0/1. It dataset has rows around 75K. I tried logistic regression algorithm which gave me the auc score of 0.76 on train and test sets and 0.74 approx. on submission(test.csv dataset). I tried Xgboost algorithm to improve the score and built a base model which gave auc score of around 0.94 on training, validation and test datasets. But on submission(test.csv) I'm getting very low score of 0.55 approx. If the model is overfitting then I believe I should get a similar low score on validation and test sets as well. But that is not happening here. The only feature engineering step I did before splitting the data into val and test sets is counting the no. of zero valued features in a data point. I don't think there is data leakage because of this. Code details: adding zeros column: df.insert(1,'zeros', (df == 0).astype('int64').sum(axis=1)) train, val and test split: x_train, x_test, y_train, y_test = train_test_split(features_df, target, train_size=0.75, random_state=100, shuffle=True) print(x_train.shape, y_train.shape) print(x_test.shape, y_test.shape) print('-'*150) x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.80, random_state=100, shuffle=True) print(x_train.shape, y_train.shape) print(x_val.shape, y_val.shape) Hyperparameters for xgboost algorithm: xgb_model = XGBClassifier(learning_rate=0.2, n_estimators=37, max_depth=5, min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27) Kaggle notebook link
