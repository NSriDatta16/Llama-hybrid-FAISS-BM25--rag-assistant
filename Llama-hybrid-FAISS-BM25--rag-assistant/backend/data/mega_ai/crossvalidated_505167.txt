[site]: crossvalidated
[post_id]: 505167
[parent_id]: 
[tags]: 
What issues arise when you perform stats on scores attributed to concepts/objects rather than people? (2-way independent ANOVA example)

• Pianos have 5 different types of black note, and 7 different types of white note, on them. • A famous music psychology paper examined the effects of note colour (black vs white) and instrument (piano vs keyboard vs synthesised sound - N.B., referred to as ‘timbre’) in a 2-way ANOVA. It reported the following: • "It is clear that the white-key notes are responded to more correctly than are the black-key notes for all timbres. An analysis of variance showed that this difference was highly significant [F(1, 30) = 24.16, p • From the degrees of freedom it seems to me that the participants weren’t individually scored, but rather the number of times they correctly identified each note was counted and then pooled together to give a total score attributed to each of the 12 notes , rather than to any person. • This would mean that for each of the three instruments, scores for the 5 black notes were in the 'black' level of the note colour factor, and scores for the 7 white notes were in the 'white' level of the note colour factor. This would result in degrees of freedom for the sum of squares within (error) of: 5 black notes = 5 - 1 = 4; 7 white notes = 7 - 1 = 6; 6 + 4 = 10; 10 x 3 [i.e., 3 instruments] = 30. Thus F(1, 30) • What are the implications of giving scores to notes (a concept) rather than to the participants that really gained those scores? • Things that trouble me: If there are 5 black notes vs 7 white notes for 3 instruments then there are unequal group sizes (n=15 vs n=21). As 21/15 = 1.4 (so, under 1.5) perhaps this isn't an issue? Is this binomial data? The participant responses to the notes can either be correct or incorrect. However: a) each participant encounters each note a number of times, so we’re either dealing with aggregated scores or averages b) the scores are then given to the notes themselves, rather than to the participants. So, do points a and b change the nature of the data? • The way the experiment was conducted was repeated measures: the same people (n=7) experienced all notes on all instruments. As the scores are allocated to the notes rather than the participants perhaps this isn't an issue? However... • Even here I think it should be a mixed design. Surely each note can be classified as a colour (between subjects, as in the white notes are never in the black notes group, and vice versa) but is subjected to being played by different instruments (within subjects, as in the same group of notes are being played in each condition). I can't remember how this would affect the degrees of freedom, but I don't think they'd come out as '1, 30' (as is the case in the paper) were this a mixed design? FYI this is the paper I'm referring to: Miyazaki, K. I. (1989). Absolute pitch identification: Effects of timbre and pitch region. Music perception, 7(1), 1-14. Does this data analysis trouble you? What troubles you about it? Also is there any literature on best practice for assigning scores to non-sentient beings, such as concepts (differently coloured piano notes, in this instance)?
