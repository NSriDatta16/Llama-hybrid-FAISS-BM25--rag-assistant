[site]: datascience
[post_id]: 16602
[parent_id]: 16601
[tags]: 
There is no requirement for specific pixel dimensions for convolutional neural networks to function normally. It is likely the values have been chosen for pragmatic reasons - such as a compromise between using image details vs number of parameters and training set size required. In addition, if source data has a range of different aspect ratios, some portrait, some landscape, with the target object usually in the centre, then taking a square crop from the middle could be a reasonable compromise. When you increase the input image size, you will also increase the amount of noise and variance that the network will need to deal with in order to process that input. That could mean more layers - both convolutional and pooling. It could also mean that you need more training examples, and of course each training example will be larger. Together, these increase the computation resources you need to complete training. However, if you can overcome this requirement, it is possible that you will end up with a more accurate model, for any task where the extra pixels could make a difference. One possible rule of thumb for whether you would want higher resolution is if, for goal of your network, a human expert could make use of the extra resolution and perform better at the task. This might be the case in regression systems, where the network is deriving some numerical quantities from the image - e.g. for face recognition extracting biometrics such as distance between facial features. It might also be desirable for image-processing tasks such as automated masking - state of the art results for these tasks may still be lower resolution than the commercial images where we would like to apply them in practice.
