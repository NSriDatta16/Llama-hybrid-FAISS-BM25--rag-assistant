[site]: datascience
[post_id]: 72162
[parent_id]: 72153
[tags]: 
First I did a visualization of what your code is doing (see code at the bottom) The model seems completely fine. The coefficient of the linear regression is close to 0, where it should be given how you have created the data. You are misunderstanding regularized_logistic_regression_model.scores_ {1: array([[0.47058824, 0.47058824, 0.47058824, 0.47058824, 0.47058824], [1. , 1. , 1. , 1. , 1. ], [0.63636364, 0.63636364, 0.63636364, 0.63636364, 0.63636364]])} I quote from sklearn documentation: scores_dict: dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold This is the prediction of one of the folds (note that if you increase the cv parameter it changes length) The data created is sorted! If you plot the values of X vs the Index you can see You are getting those results because the data is sorted! Not just because of luck. If you shuffle the data you wonÂ´t have perfect predictions. Your result is around 0.7 that is actually what makes sense by looking at the image I attached. I shuffled the data, not in the most elegant way but you get now different results. import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn.linear_model import LogisticRegressionCV from sklearn.linear_model import LogisticRegression plt.style.use('seaborn-whitegrid') def gen_y(x): p1 = np.clip(x + 0.5, 0, 1) v = np.random.uniform(0, 1) if v
