[site]: crossvalidated
[post_id]: 341370
[parent_id]: 
[tags]: 
Accuracy measurement for sequential feature selector in Linear Discriminant Analysis

One of the known issues with Linear Discriminant Analysis is it's tendency to overfit to high dimensional data. Although there's a wide range of methods to reduce this (PCA, bagging etc). I'm interested in looking at applying sequential feature selector to reduce the number of dimensions down to a more reasonable dataset. However, which evaluation measure is most suitable? Classic accuracy almost seems counter intuitive since we're not directly trying to optimize this but rather ensure the value is accurate (We are applying CV within the sequential feature selector) Would mean_absolute_error or F1 be better values, and if so why? Notes: I'm using the Mlxtend python library This question is purely out of interest/thought experiment, I'm not interested in other methods
