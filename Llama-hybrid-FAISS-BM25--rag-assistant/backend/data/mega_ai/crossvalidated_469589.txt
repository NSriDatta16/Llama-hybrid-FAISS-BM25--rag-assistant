[site]: crossvalidated
[post_id]: 469589
[parent_id]: 
[tags]: 
Logistic Regression gives unexpected results

I am trying to predict binary outcome (Response) with a single feature (V1) using scikit-learn implementation of Logistic Regression (default parameters). V1: [2.56, 1.12, 1.38, 1.38, 1.25, 1.28, 0.92, 1.51, 2.23, 1.91, 2. , 1.31, 1.41, 1.51, 1.35, 1.12, 1.68, 1.94, 1.61, 2.56, 2.23, 1.54, 1.41, 2.04, 1.18, 1.38, 1.48, 1.54, 1.22, 1.08, 1.77, 2.17, 1.58, 1.38, 1.35, 1.38, 1.35, 1.87, 1.51, 1.77, 1.28, 1.48, 1.74, 1.81, 1.84, 1.84, 1.84, 1.71, 1.84, 1.91, 1.31, 2. , 2.04, 1.35, 1.71, 1.51, 1.31, 1.54, 1.51, 1.38, 1.77, 1.38, 1.12, 1.61, 1.41, 1.68, 1.84, 1.81, 2. , 2.27, 1.05, 2.07, 2. , 1.12, 1.91, 1.97, 1.81, 2.17, 1.28, 1.38, 1.81, 1.48, 1.48, 1.64, 1.97, 2.23, 1.35, 2.2 , 1.77, 1.38, 1.81, 1.58, 1.87, 1.61, 1.58, 1.84, 1.31, 0.92, 1.84, 1.61, 1.18, 1.61, 1.71, 1.31, 1.41, 2.1 , 1.41, 1.81, 1.48, 1.74, 1.41, 1.84, 1.35, 1.54, 1.71, 1.68, 2.1 , 1.61, 1.08, 1.77, 1.61, 1.84, 2.23, 1.91, 1.77, 1.71, 1.68, 2.46, 2. , 2. , 1.97, 2.5 , 2.3 , 2.04, 2.04, 1.94, 1.54, 2.66, 2.04, 1.51, 2.04, 1.91, 2.14, 1.58, 1.77, 1.94, 0.13, 0.16] Response:[0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.] I used k-fold cross-validation with 30 repetitions. The mean test AUC I got is 50%, which means the model has no skill to distinguish the two classes. However, when I plot ROC at different thresholds of feature V1, i get AUC of 0.35, showing a negative correlation with the outcome variable. See figure below Also results from univariate statistical tests give significant p-value (0.02). I used glm function from R for univariate test as I like it better for statiscal anlaysis dm_data |z|) (Intercept) 0.4229 0.9341 0.453 0.6508 V1 -1.3228 0.5868 -2.254 0.0242 * --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 127.86 on 147 degrees of freedom Residual deviance: 122.54 on 146 degrees of freedom AIC: 126.54 Number of Fisher Scoring iterations: 4 Thus I assume that this variable is atleast a moderate predictor of the outcome. but median AUC i get from Logisticregression doesnot support my analysis. My implementation is as follow dataset=pd.read_excel('Myexcel.xlsx') np_dataset=dataset.values X= np_dataset[:,1] y=np_dataset[:,0] X=X.reshape(-1,1) # reshaped as there is only feature #Gridsearch for best params grid_param = { 'penalty':['l1', 'l2', 'elasticnet' 'none'], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'C': [0.001,0.01,0.1,1.0]} gsc = GridSearchCV(estimator=LogisticRegression(), param_grid=grid_param, scoring='roc_auc', cv=3, n_jobs=-1) grid_result = gsc.fit(X, y) best_params = grid_result.best_params_ kfold = RepeatedStratifiedKFold(n_splits=3, n_repeats=30,random_state=1) ROC_test=[] for train, test in kfold.split(X,y): model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], solver=best_params['solver']) model.fit(X[train], y[train]) yhat_test= model.predict_proba(X[test]) auc_test= roc_auc_score(y[test], yhat_test) ROC_test.append(auc_test) print('Test AUC Median: %.2f' %np.median(ROC_test)*100)) [Output] Test AUC Median: 50.00% Can anyone please help me to understand the reason for this 0.5 auc of logisticregression model. Thanks
