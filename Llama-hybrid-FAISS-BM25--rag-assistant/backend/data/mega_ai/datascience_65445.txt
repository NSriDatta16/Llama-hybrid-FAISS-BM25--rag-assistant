[site]: datascience
[post_id]: 65445
[parent_id]: 65430
[tags]: 
You can leverage word-vector similarity in embedding models . TL;DR similiar vectors of words (for example fruits) will be clustered together in this high (vector) dimensional space. For every possible class-set you will have a class-set representative (centroid) that is actually a key (so in your case fruit, vegetable etc) all you need to do is train/find a representative word embedding model of your corpus.
