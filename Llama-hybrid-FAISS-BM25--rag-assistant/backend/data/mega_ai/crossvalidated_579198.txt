[site]: crossvalidated
[post_id]: 579198
[parent_id]: 578849
[tags]: 
As @Bj√∂rn explains, your test set is biased because you created it by deterministically choosing the "top examples" to label. This introduces bias in the evaluation that you cannot correct for. However, you don't necessarily need to sample examples randomly to evaluate machine learning models correctly if you are more strategic in how you select examples to label. This is called active testing ; you can learn more about it in [1]. The gist: It's okay to introduce bias by actively selecting test examples to label as long as it is possible to remove the bias afterwards. Obviously this makes for more efficient evaluation; it can also reduce the variance of the performance estimator. The procedure outlined in [1] uses a surrogate model to estimate acquisition probabilities , which indicate how valuable an example is to label next. So instead of choosing an example deterministically, you sample it according to its acquisition probability. The idea behind using the surrogate is to (a) account for uncertainty over the outcomes; (b) make predictions that are diverse to the model f(x) under evaluation, and (c) incorporate information from all available data. [1] J. Kossen, S. Farquhar, Y. Gal, and T. Rainforth. Active testing: Sample-efficient model evaluation. In Proceedings of the 38th International Conference on Machine Learning , 2021. https://doi.org/10.48550/arXiv.2103.05331
