[site]: crossvalidated
[post_id]: 587801
[parent_id]: 
[tags]: 
Embedded minimum spanning trees for visualizing effects of dimensionality reduction?

Gist Construct a minimum spanning tree (MST) of the data, perform a dimensionality reduction procedure, and plot the embedding MST to study a "skeleton" of the transformed data. Mathematical Preamble Suppose I have a transform $T:\mathbb{R}^n \mapsto \mathbb{R}^2$ where $2 , and a metric $d:\mathbb{R}^n \times \mathbb{R}^n \mapsto \mathbb{R}_{\geq 0}$ . For a finite set of points $S = \{x_1, \cdots, x_m \} \subset \mathbb{R}^n$ , we can construct the weighted graph $G = (V,E,W)$ where $V = \{1, \cdots, m \}$ is an index set for $S$ , $E$ is the set of all combinations of points of size two, and $W$ is the set of edge weights $w_{i,j} = d(x_i, d_j)$ . We can take this graph to have the vertex embedding $\phi: V \mapsto \mathbb{R}^2$ satisfying $\phi(i) = T(x_i)$ for $i \in V$ , with edges assumed to be geodesics according to $d$ . Letting $M$ be the minimum spanning tree of $G$ , we can make the composition $(T \circ \phi )(V(M))$ where $V(M) = V$ be the vertex set of $M$ . Recall that a minimum spanning tree is always a planar graph. Example 1: PCA Below is a visualization of the famous Iris data set collected by Edgar Anderson . I used the Euclidean metric to find the MST, and principal components analysis (PCA) to transform the the 4-dimensional data set into a two-dimensional projection. I effectively assumed Euclidean space for the purposes of drawing the edges and calculating the metric. I've mapped the MST to the points into the projected space, and colored the points by class. Example 2: tSNE Same as in Example 1, except tSNE was used with default parameters in SKlearn. The minimum spanning tree is the same as before, but the embedding is different. Question Where the edges intersect in the image of $T$ , does that imply that $T$ has distorted something about the original embedding of the MST? I'm guessing it is hinting at depth that has been flattened. Misc Background I've tried other types of graphs in place of MST, such as Delaunay tesselations, but they are almost always too visually messy to interpret in the resulting plot. The edges might be more interpretable by colouring them by the edge weights, although that should not be done in a way that confuses the class colouring of the points (if used). This approach is not identical to TMAP introduced by Probst and Reymond 2020 because the layout (choice of embedding) is different. This approach is not identical to STAD introduced by Alcaide and Aerts 2019 because it does not make use of the mapper algorithm. I was directed from Do minimum spanning trees drawn on points in $\mathbb{R}^2$ always have non-intersecting edges? that all Euclidean MSTs for points already placed on the plane will have a planar embedding. The intersections of edges in my examples above (mapped from $n$ -dimensions) have something to do with the choice of $T$ . I think this because all trees are planar graphs, so there exists a choice of $T$ that would have mapped the Euclidean MST in $n$ -dimensions to a planar embedding on the plane. While the Euclidean MST is easier on the eyes, the planarity of the Delaunay tesselation implies that we could count the number of intersecting edges (in the sense of intersecting line segments) to quantify something about the distortions caused by $T$ .
