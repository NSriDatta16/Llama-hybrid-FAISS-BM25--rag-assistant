[site]: crossvalidated
[post_id]: 491572
[parent_id]: 491547
[tags]: 
Depending on what you are trying to do with your CNN, regularization may indeed make sense. Pruning your network by regularization to make it sparse has two main advantages: It simplifies the network, making training and computation faster and easier; It prevents overfitting, and allows to make sure your network will generalize well on new data. An intuitive way to reach these objectives is to perform $L_0$ regularization, which penalizes parameters than are not strictly equal to 0. This induces sparsity in the network. This procedure is described in the following paper : https://arxiv.org/abs/1712.01312 The authors also discuss other kinds of regularization (namely $L_1$ regularization).
