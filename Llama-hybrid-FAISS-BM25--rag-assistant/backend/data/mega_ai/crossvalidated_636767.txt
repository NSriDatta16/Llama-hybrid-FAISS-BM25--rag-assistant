[site]: crossvalidated
[post_id]: 636767
[parent_id]: 
[tags]: 
Calculation of Cohen's Kappa with different categories and number of instances

I have a dataset that contains commentary on football matches. We have two labelers, and they have labeled which team is attacking in each commentary. As you can see, different matches have different teams competing against each other. Also, the number of commentaries is different for each match. How can I calculate inter-annotator agreement here? I have calculated kappa values for each match separately, but how can I determine the overall kappa score for the labelers? I am considering getting the weighted average value of these kappa scores, i.e., multiplying each kappa value by the number of commentaries and dividing it by the total number of commentaries. I did not find anything in the literature.
