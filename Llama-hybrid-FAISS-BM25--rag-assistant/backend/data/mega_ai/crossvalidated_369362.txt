[site]: crossvalidated
[post_id]: 369362
[parent_id]: 
[tags]: 
Optimizing popular convolutional networks for grayscale

Common questions in the stack community are variants of " how do I use a pretrained alexnet for grayscale images?", or "How can I do transfer learning from a pretrained network on grayscale images?" https://stackoverflow.com/questions/48630313/vgg16-trained-on-grayscale-imagenet https://datascience.stackexchange.com/questions/22684/is-it-possible-to-use-grayscale-images-to-existing-model https://stackoverflow.com/questions/44668771/can-we-use-the-weights-of-a-model-trained-on-rgb-images-for-grayscale-images Of course, there are two solutions. The first is to stack up the grayscale images into 3 channels, and fine tune the pretrained network. The second is to remove 2 channels from the input layer of the CNN and just work with that. However I think these approaches are overcomplicated from a computational complexity standpoint. Alexnet for instance has 64 convolutional filters in its first layer, and a large portion of these filters encode color information (see slide 5 in http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf ), so they should be dead on grayscale images. Now to my question. I would like to make a minimal alexnet for a regression task on grayscale images. I would like to exclude the filters from a pretrained network's layers which do not respond strongly to grayscale images, and then fine tune / transfer learn from this reduced network. I imagine an alexnet architecture where the convolutional layers are all about half as deep so the computational expense is minimized while grayscale comprehension is unchanged. Has anyone seen anything like this? How can I ascertain if a certain filter is interpreting color information or not?
