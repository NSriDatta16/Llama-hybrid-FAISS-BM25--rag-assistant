[site]: datascience
[post_id]: 122832
[parent_id]: 
[tags]: 
Dataset I am working with seems to have been artificially created and the target variable has the same average value no matter the split

I am trying to run a Random Forest on a dataset that has 4 synthetic features, with distributions ranging from approximately -5 to 5. It is not possible to say what those features mean. The dataset also has product_id, customer_id, product_category and customer_segment. There is absolutely no correlation between the synthetic features and the target variable (total sales), and whichever column I group by (product_id, customer_id, product_category or customer_segment) and find the average total_sales, the average value is the same for each level and very close to the average total sales for the whole dataset. When I run Random Forest, including all the variables above (synthetic which are numerical and others which are categorical) the model fails miserably on the test set and predicts the average total sales for each row, though it performs better on the train set, I think this suggests overfit. If I try to control for overfit by setting max_depth value for example to 10, the model again defaults to average total sales and predicts almost the same value for each row. Is there any work around about this, or is it just that the dataset is non-sensical? Thanks in advance
