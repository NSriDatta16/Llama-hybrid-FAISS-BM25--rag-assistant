[site]: datascience
[post_id]: 115758
[parent_id]: 
[tags]: 
Is hyperparameter tuning with different samples of data on each run a bad idea?

I have 2k time series and want to optimize the hyperparameters of my prophet model. It takes 1 hour to train and evaluate on every time series for each hyperparam combination. So, I want to run it on a sample to speed thing up. Options: Use the same sample of training data for every hyperparameter combination (I've been doing this but feel like I'm not getting my money's worth) Use a different sample of training data for each hyperparam combination (Gives me more data coverage but throws another variable in the mix - how can I be sure that this set of params does perform better and not that it just got lucky with the data?) Manually craft a smaller dataset that contains a good combo of time series to test the model. I feel like 3 is the right answer... but how bad is number 2? Would you ever advise this? Note: this question asks about the disadvantages of number 1. I'm asking about number 2.
