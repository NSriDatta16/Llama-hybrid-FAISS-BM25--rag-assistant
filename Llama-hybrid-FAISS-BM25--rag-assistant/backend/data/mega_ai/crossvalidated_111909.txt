[site]: crossvalidated
[post_id]: 111909
[parent_id]: 
[tags]: 
Does the precision/recall metrics on train set must be better than on test set?

I ran a big Neural Network with the initialized weight matrix learned by RBM (Restricted Boltzmann Machine), and the result shows something like this. On train dataset The best precision: 0.79564. And the best recall: 0.75685. The best f1: 0.775760 On test dataset The best precision: 0.7356. And the best recall: 0.6568. The best f1: 0.69939 I know it's very suspicious. So, I doubt that if I implement the code wrong(all the RBM and NN code was implement by myself with Matlab, and I took the DeepLearnToolbox library as reference). Is it absolutely(or in majority such as 90% probability) correct that the precision/recall/f1 metrics should be better on train set than on test set? Or does it have the theory basis to prove that the evaluating metrics should/must be better on train set? Or it just seems like the code I have implemented has some mistake in it? Or could you just answer the question which whether you have seen the situation that the code is correct but the metrics is like the trend of my metrics?
