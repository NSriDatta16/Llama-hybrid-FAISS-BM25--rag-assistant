[site]: crossvalidated
[post_id]: 599414
[parent_id]: 
[tags]: 
Bayesian Inference with a Normal Likelihood and Gamma Prior

I am fairly new to (the eye-opening world of) Bayesian inference and machine learning and I am stuck at a inference problem that is important to my current research, where I want to introduce Bayesian thinking into the field. I want to estimate a the psoterior for a variable V that must remain positive. Now, first i want to use a conjugate normal updating of the mean to showcase the utility of Bayesian inference, and afterwards I wanted to move away from the conjugacy to further demonstrate what MCMC algorithms can do (e.g.via JAGS/STAN). In the conjugate analysis, I'd assume both likelihood and prior to be normal. This is not a problem, since I know the closed form solution for updating the mean and variance of V. If I switch the prior for V to be a gamma distribution (e.g. with scale a and shape b of 2) to keep the inference positive, I have a hard time defining the parameters of the model, since i have a shape and scale in the prior and a mean and variance in the posterior. Before i could just define the mean and variance as the parameters of the model, but with the gamma prior I can't get it to work in a similar way. So in essence I have... Prior: p(V) ~ gamma (2,2) Likelihood: p(d|V) ~ normal(mean(V), sd(V)) I've been trying to code this in JAGS to obtain the posterior, but i struggle to formulate a suitable prior and likelihood for the inference problem. Is there someone proficient with e.g. JAGS here that can help me? Any help would be greatly appreciated, since I have to finish the paper until the end of this year. My current (obviously unfinished) JAGS code looks as follows: model_code
