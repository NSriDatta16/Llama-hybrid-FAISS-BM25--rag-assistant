[site]: datascience
[post_id]: 88792
[parent_id]: 
[tags]: 
Batching data for LSTMs vs fully connected models

I've implemented an LSTM auto-encoder. It trained well, and does what I want it to so far. But, I think I've misunderstood something fundamental about lstms. In a simple dense network whose input layer is size 7, I can feed a tensor of shape (batch_size, 7) where batch_size = len(data) / 7 and get the expected results. I successfully perform inference on the entire dataset at once. I thought it would be the same with my LSTM autoencoder, but it only seems to work if I feed the data one entry at a time in a for-loop. Dense reconstruction using of for-loop: OR a single "batch": LSTM reconstruction using for-loop: LSTM using a single "batch": I know that LSTMs are sequential by nature, but I was under the impression that you can feed batches to the LSTM and some fancy optimization of for-loops occurs. Did I miss something conceptually?
