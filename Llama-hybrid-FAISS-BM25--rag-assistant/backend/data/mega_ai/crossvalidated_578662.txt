[site]: crossvalidated
[post_id]: 578662
[parent_id]: 538744
[tags]: 
If your original data was relatively discrete (had many "ties" for some or all the features), then this is a likely outcome, even after reducing the number of features. In a tree model like yours, at each node every potential split is evaluated: for each feature and each unique value thereof, split the data into the values less than or greater than that value. (Some implementations may shrink the space potential splits e.g. with histogram binning.) When your original data was somewhat discrete, this was a much smaller space of potential splits than the actual number of entries in your dataframe. After PCA though, you've effectively rotated the axes (and dropped some) of your space, and so two rows having the exact same value of a principal component is much less likely. So the number of candidate splits will be very close to the total number of entries in your dataframe, and even if there are fewer columns this might be significantly larger than the original number of candidate splits. And naturally it takes longer to evaluate them all.
