[site]: crossvalidated
[post_id]: 584520
[parent_id]: 286532
[tags]: 
I had been looking to find an answer to the same question but did not manage to find it anywhere. So I tried to derive the answer myself using as a guide the MethComp paper linked to the wikipedia page Jensen . The difference to the paper is that we are trying to solve for a following model: \begin{align} x_i = \xi_i e_{xi} \end{align} \begin{align} y_i = \beta \xi_i e_{yi} \end{align} where random part is normally distributed \begin{align} e_{xi} \sim N(0, \sigma^2) \end{align} \begin{align} e_{yi} \sim N(0, \lambda \sigma^2) \end{align} This leads to a slightly easier likelihood function: \begin{align} f = \prod_{i=1}^n(2\pi\sigma^2)^{-\frac{1}{2}} exp(-\frac{(x_i-\xi_i)^2}{2\sigma^2})(2\pi\lambda\sigma^2)^{-\frac{1}{2}} exp(-\frac{(y_i-\beta\xi_i)^2}{2\lambda\sigma^2}) \end{align} The maximum likelihood solution is following: \begin{align} \beta = \frac{A_{yy}-\lambda A_{xx}+\sqrt{(A_{yy}-\lambda A_{xx})^2 + 4 \lambda A_{xy}^2}}{2A_{xy}} \end{align} \begin{align} \xi_{i}=\frac{\lambda x_i + \beta y_i}{\lambda+\beta^2} \end{align} where: \begin{align} A_{xx} = \frac{1}{n} \sum_{i=0}^n x_i^2 \end{align} \begin{align} A_{yy} = \frac{1}{n} \sum_{i=0}^n y_i^2 \end{align} \begin{align} A_{xy} = \frac{1}{n} \sum_{i=0}^n x_i y_i \end{align} The whole difference to the original solution with the intercept is lack of correction for averages in definition of $A_{kk}$ .
