[site]: datascience
[post_id]: 74571
[parent_id]: 
[tags]: 
my xgboost model accuracy decreases after grid search with

I tried grid search for hyperparameter tuning in XGBoost classifier but the best accuracy is less than the accuracy without any tuning // this is the code before the grid search xg_cl = xgb.XGBClassifier(objective='binary:logistic', seed = 22) xg_cl.fit(x_train, y_train) y_pred = xg_cl.predict(x_test) print(metrics.confusion_matrix(y_test, y_pred)) print(metrics.accuracy_score(y_test, y_pred)) [[11 1] [ 1 26]] 0.9487179487179487 also, worth mentioning that the dataset shape is (195, 11) after PCA, and i am trying to classify whether a patient has a parkinsons disease or not. // this is the grid search code clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic') params__grid = { 'n_estimators' : range(50,150,10), 'max_depth': range(2, 12), 'colsample_bytree': np.arange(0.5,1,0.1), 'reg_alpha' : np.arange(0,0.6,0.1), 'reg_lambda' : np.arange(0,0.8,0.1) } search = GridSearchCV(estimator=clf_xgb, param_grid=params__grid, scoring = 'accuracy', cv = 4 ) search.fit(x_train,y_train) print('best score:/n',search.best_score_) print('bestparams:/n' ,search.best_params_) best score: 0.9038461538461539 best params: {'colsample_bytree': 0.5, 'max_depth': 7, 'n_estimators': 50, 'reg_alpha': 0.2, 'reg_lambda': 0.1} then I used these parameters to build and train a new classifier clf_xgb_1 = xgb.XGBClassifier(objective = 'binary:logistic', max_depth = 7, n_estimators = 50, reg_alpha = 0.2 , reg_lambda = 0.1, colsample_bytree = 0.5 ) clf_xgb_1.fit(x_train,y_train) y_pred_2 = clf_xgb_1.predict(x_test) print('accuracy:/n', metrics.accuracy_score(y_test,y_pred_2)) print('confusion matrix:/n', metrics.confusion_matrix(y_test,y_pred_2)) accuracy: 0.8974358974358975 confusion matrix: array([[ 9, 3], [ 1, 26]], dtype=int64) How come my results are worse? I would expect that GridSearch would improve on the results.
