[site]: crossvalidated
[post_id]: 499471
[parent_id]: 499391
[tags]: 
Cox regressions have a potential problem with omitted-variable bias , similar to that seen with logistic regression . Even if X is uncorrelated with the other predictors, if it's associated with outcome you risk a downward-magnitude bias for all coefficients in the model, potentially missing true associations for the other predictors. So your decision to include X in your model is good. By extension, however, setting a separate category for "not measured" means that you are effectively omitting the proper outcome-associated value of X from the model for those cases, posing a similar (although perhaps not so serious) risk. Vittinghoff et al address this directly in Section 11.3.1: Unfortunately, this can create biased estimates for other regression coefficients in the model, even when the data are MCAR. The reason for this is that, for the subset coded as missing, we are not adjusting for the value of [the missing predictor], whereas for the rest of the data we are...Bias is introduced when the unadjusted and adjusted coefficients differ and there is a sizeable percentage of observations in the missing data category. On the other hand, if the adjusted and unadjusted coefficients are similar and the percentage of observations in the missing data category is small, little bias will be introduced. Multiple imputation can seem daunting, but it's pretty simple in practice and will avoid some potential problems with both of your proposed approaches. The general problems with other approaches and methods to implement multiple imputation are nicely explained in the online book Flexible Imputation of Missing Data . If you're worried that multiple imputation is too hard to explain to your audience or will seem incompatible with other analyses of the data set, you could consider implementing both your separate-coding approach and multiple imputation. If the results are close enough, you can report the results from your proposed approach while noting that multiple imputation provided a similar result. (Ideally, provide details of the multiple imputation in supplemental material.) If the results of the two models aren't similar, then the multiple-imputation approach would certainly need to be reported instead. Finally, if you are absolutely positively sure that your values are missing completely at random (MCAR), then you could consider omitting those cases. Throwing away 40% of your data is wasteful, but, with standard errors related to the square root of the number of events, 60% of the data would still provide 77% of the precision you would get otherwise. I"m not recommending that, both because of the extra precision you can get from multiple imputation and because I tend to question whether values are MCAR based on expert opinion without statistical verification. But I suppose that should be noted as an option for MCAR data even if it's not the best choice.
