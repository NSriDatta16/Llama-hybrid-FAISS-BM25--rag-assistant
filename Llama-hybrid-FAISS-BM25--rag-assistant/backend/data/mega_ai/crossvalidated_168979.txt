[site]: crossvalidated
[post_id]: 168979
[parent_id]: 168978
[tags]: 
Check out the mboost package, which implements generalized additive models of the multinomial family within a boosted framework that is resistant to the curse of dimensionality as well as problems of separation and partial separation (the logistic regression equivalent of multicollinearity). The package allows you to construct an ensemble of boosted base learner models where the terms can be linear, additive (penalized splines), random effects (exploiting the finding the a varying coefficients model, also allowed as a base learner, can be formulated as a random effect), and 2d effects (I believe they are Markov random fields). There is one hyper parameter that you will need to tune, which governs the number of boosting iterations. The function of interest is mboost::gamboost . In my experience, the package also performs quite well even on sizable datasets in the range of hundreds of thousands of datapoints. In my opinion, mboost and the packages that depend on it are among the most valuable packages for building models in R, and there is to my knowledge nothing quite like it available in Python, though I could be wrong.
