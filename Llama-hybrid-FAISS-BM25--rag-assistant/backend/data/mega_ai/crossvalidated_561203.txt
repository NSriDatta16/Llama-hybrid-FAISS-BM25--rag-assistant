[site]: crossvalidated
[post_id]: 561203
[parent_id]: 259562
[tags]: 
It is a mistake to equate "common" and "sensible". As the comment by Dikran Marsupial mentions, such a procedure could give a meaningful answer to a question about the stability of cross validation across multiple partitions, but it is a mistake to think that $100$ iterations of $10$ -fold cross validation, averaging the performance across the $10$ folds each of the $100$ times, is equivalent to $1000$ separate out-of-sample tests. Think of it this way. The random variable of interest, $X$ , is the distribution of out-of-sample performance scores. We are interested in $Var(X)$ . When we do $10$ -fold cross validation and average the performance on the $10$ folds, we get $\bar X$ , and $Var(\bar X)=\frac{Var(X)}{10}$ . By looking at the $100$ values of $\bar X$ , we estimate $Var(\bar X)$ instead of $Var(X)$ . The procedure proposed in the OP will underestimate the true variance and mislead us into thinking there is more stability in the out-of-sample score than there really is.
