[site]: crossvalidated
[post_id]: 351998
[parent_id]: 
[tags]: 
Multi-tiered (nested?) uncertainty & confidence bands - subset populations

I have a current and historical dataset of likelihood that a population gets into a car accident. I have my predictions for a rare event - say the % chance that a given driver gets in a car accident in a given calendar quarter. Conceptually I want to understand how much I can trust my predictions based on history. Since I have historical data of my predictions and actual accidents, I can generate a metric of confidence in (and bands around) the expected values in a few different ways. For example, based on the distribution of the time series of observed v. predicted accidents. All things being equal, the differences should be more or less normally distributed around 100%. But more specifically, I'd like to get a picture of how confident I can be in my expected % chance of an accident for any given individual. I understand that this is meaningless in a vacuum - it's a binary observation, so a range around the likelihood doesn't really mean anything. But the idea is to be able to "roll this up" to get these metrics aggregated the same way I can for expecteds, but for any subset of the population. Alongside this (or another way to think about this) is to find a way to measure which attributes of the individual are the biggest drivers of this confidence. The question is simply how can I get to this? The rest is simply some of my thoughts and possible paths: If I want aggregated confidence bands around only males, I should be able to do this directly in the same way as the population as a whole. But as the subsets get smaller, say, a population of a) male b) 18-21 year-old c) smokers d) with one accident in the last 12 months and e) no high school diploma, ...is there some way I can derive this from the variances of the larger, more credible populations? Could I, for example: Get intervals for all combinations of attributes large enough to produce a subset with credible values, and derive either an overall "confidence (or variance) impact" or "base confidence level" for a given attribute? That is, I have a specific % likelihood that a male, 18-21 year-old, smoker, etc., gets in an accident in a given quarter. Thus, where attributes a-d are constant, I know the difference in predicted likelihood if the individual does/not have a high school diploma. Can I similarly know the change of the variance/confidence bands? Other thoughts/ideas: If I have 40 quarters of data, and: ---(A) 40000 male 18-21 year-olds @ quarter with a predicted 2%/quarter chance of accident, and my prediction tracks at 101% of actual observations, +/- 2.4%/quarter. ---(B) 4000 male smokers @ quarter with a predicted 1.7%/quarter chance of accident, my prediction is 100.5%, +/- 4.7% in any given quarter. ---(C) 400 male 18-21 year-old smokers @ quarter, but I don't trust the size of this population. If I measured it directly the variance would be huge, but it seems that I should know something about this since I know a lot about males, 18-21 year-olds, and smokers. Could I derive a value for a subset of a population by evaluating the impact of removing it from the total population? That is, if I have what I need for B above, and I remove the population of C, can I derive C by comparing B to [B-C]? Or [A-C]? Or am I overthinking this? Is it as simple as some variation of contingent probability A*B = C? That doesn't seem right, because I essentially need to be constructing the entire distribution for the subset of every combination of all attributes to get where I need to be. It seems like I'm thinking about this in entirely the wrong way.
