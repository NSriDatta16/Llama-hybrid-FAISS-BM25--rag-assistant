[site]: crossvalidated
[post_id]: 563557
[parent_id]: 563524
[tags]: 
What you are describing is a mixture of Bernoulli random variables . First, let's start with a minor correction, if you have two sub-populations, than for the $\pi_i$ mixing proportions you don't need Dirichlet distribution, just use the beta distribution so the proportions are $$ \pi \sim \mathsf{Beta}(\alpha_\pi, \beta_\pi) $$ where the mixing proportions for the subgroups are $\pi$ and $1 - \pi$ respectively. In such a case, your model is $$\begin{align} \theta_i &\sim \mathsf{Beta}(\alpha_{\theta_i}, \beta_{\theta_i}) \\ \pi &\sim \mathsf{Beta}(\alpha_\pi, \beta_\pi) \\ y_i &\sim \pi \; \mathsf{Bern}(\theta_1) + (1 - \pi) \; \mathsf{Bern}(\theta_2)\\ \end{align}$$ As with other mixtures, it does not have a closed-form solution. The usual approach would be to fit it using maximum likelihood, or Bayesian estimation. To estimate the parameters, you either need to use the E-M algorithm (see e.g. those slides ), or MCMC sampling in the Bayesian approach (e.g. this paper ). If you decide to use Bayesian approach, beware of the label switching problem , that would usually need some special precautions . After you found the posterior distribution, if you are interested in the point estimate that minimizes the squared error, just take the posterior mean as it minimizes the squared error .
