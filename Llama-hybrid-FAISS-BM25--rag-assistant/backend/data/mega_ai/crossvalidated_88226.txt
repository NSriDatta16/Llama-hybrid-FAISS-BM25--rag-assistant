[site]: crossvalidated
[post_id]: 88226
[parent_id]: 
[tags]: 
How to describe and present the issue of perfect separation?

Folks who work with logistic regression are familiar with the issue of perfect separation: if you have a variable specific values of which are associated with only one of the two outcomes (say a binary $x$ such that all observations with $x=1$ have outcome = 1), the likelihood blows up, and the maximum likelihood estimates run off to infinity. glm in R may or may not handle that terribly well, as the perfect prediction error message can show up for reasons other than perfect prediction/separation. logit in Stata identifies such variables and problematic values, and discards them from the analysis. My question is different from what to do if you have a perfect separation. That I can handle by recoding my variables (they are all categorical, so I can simply combine categories), or with Firth version of logistic regression if I want to be fancy. Instead, I wonder what the common ways are of describing this. I have a data set with circa 100 patients with about 50% proportion "positive", and some categories of the demographic variables produce this perfect prediction. Let's just say that all 7 green-eyed people have a "positive" outcome. This may be a small sample peculiarity that would disappear if I had sample size of 1000 and 70 green-eyed people, but it may be clinically meaningful, as in that larger sample I could have 60 out of 70 green-eyed people that would have a "positive" outcome with high odds ratios. So it's nice to say that I used a Bayesian or some other shrinkage method, but in describing how I got there, I would need to admit that I had perfect prediction/separation, and had to find a more sophisticated technique to get any results at all. What would be a good language to use here?
