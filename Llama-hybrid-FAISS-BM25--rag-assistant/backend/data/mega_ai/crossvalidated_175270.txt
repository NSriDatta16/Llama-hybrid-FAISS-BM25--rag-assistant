[site]: crossvalidated
[post_id]: 175270
[parent_id]: 
[tags]: 
Distance metric invariant to dimensionality?

I'm working on a classification/prediction problem where I have to predict a location of an object. The problem that I have is that for every location, I have a unique and different number of feature dimensionality. So for example if I'm searching for an object in 5 possible locations. I have 10'000 training and testing samples in location 1, that have dimensionality 1000, location 2 features have dimensionality 500, and so forth, (let's imagine location 5 has dimensionality 50). What would be the correct way of assessing a prediction if the features have different dimensions? For example, using an euclidean distance metric by doing Nearest Neighbours would be a poor approach since I will very likely have a minimal distance (on average) for the 50 dimensional case than the 1000-dim case, even though the 1000 dim case might be correct. How should I go about this for the Nearest Neighbour scenario, or for other classifiers like LDA and SVM? Applying a soft-max, on the score of every output doesn't seem to do the trick for the previous reasons explained before...
