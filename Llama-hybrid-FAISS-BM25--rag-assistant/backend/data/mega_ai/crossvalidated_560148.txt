[site]: crossvalidated
[post_id]: 560148
[parent_id]: 560146
[tags]: 
You mention two options, $\epsilon=0$ and $\epsilon>0$ . For $\epsilon=0$ there is no exploration, it's all exploitation, so your agent will always select the arm with the maximal reward. If you star from the beginning and all the rewards are random or 0 then this is a very poor choice (you may still get some exploration if you break ties at random). For $\epsilon>0$ at each time step you will with probability $1-\epsilon$ select the current best action (best lever), and with probability $\epsilon$ you will select an action (lever) at random. This does not change over time. This is done for exploration. In the end if you wanted to figure out what are the best actions you would look at the best actions only. For $\epsilon=1$ all actions in all time steps are random, no exploitation.
