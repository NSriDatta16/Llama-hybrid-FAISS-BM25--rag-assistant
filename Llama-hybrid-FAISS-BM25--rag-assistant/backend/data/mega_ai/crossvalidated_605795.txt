[site]: crossvalidated
[post_id]: 605795
[parent_id]: 
[tags]: 
Normalized Wasserstein distance

The wasserstein_distance will be smaller the longer u_values and v_values are. from scipy.stats import wasserstein_distance def wassersteindist(n): a = np.random.randn(n) b = np.random.randn(n) w = wasserstein_distance(a,b) return w np.mean([wassersteindist(100) for r in range(1000)]) 0.1786 np.mean([wassersteindist(1000) for r in range(1000)]) 0.0579 np.mean([wassersteindist(10000) for r in range(1000)]) 0.0180 Is there a way to calculate a normalized wasserstein distance with scipy? EDIT: Let's say I 'm interested in comparing the distances from different individuals that happened to have a different amount of time points in their time series. id1_a = np.random.randn(100) id1_b = np.random.randn(100) id2_a = np.random.randn(1000) id2_b = np.random.randn(1000) id1_dist = wasserstein_distance(id1_a, id1_b) 0.3539204677483332 id2_dist = wasserstein_distance(id2_a, id2_b) 0.0685546301855615 id1_dist is larger than id2_dist only because the vectors for id1 are shorter than for id2 . EDIT2: With correlations I don't have the problem that they are consistently lower/higher for longer time series: def corrr(n): a = np.random.randn(n) b = np.random.randn(n) c = np.corrcoef(a,b)[0][1] return c np.mean([corrr(100) for r in range(1000)]) 0.0004 np.mean([corrr(1000) for r in range(1000)]) 0.0012 np.mean([corrr(100) for r in range(1000)]) -0.0001 np.mean([corrr(1000) for r in range(1000)]) -0.0008
