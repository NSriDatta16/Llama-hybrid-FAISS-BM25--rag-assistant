[site]: datascience
[post_id]: 89527
[parent_id]: 
[tags]: 
Autoencoder implementation using ImageDataGenerator

I'm using the concept demonstrated in this paper . Their training data consists of "GOOD" images and "BAD" images. They train the AE using "BAD" images (X) to make it produce "GOOD" image. "BAD" images in this case maybe very similar to "GOOD" image but with small dent or scratch. I've had success using ImageDataGenerator on mnist number data but in such case it is trained by using X -> X or if not using ImageDataGenerator the model fitting code will be something like model.fit(x_train, x_train) . However, in this AE problem, we want to train using X_good_and_defect -> X_good or model.fit(x_good_and_defect_train, x_good_train) . Not sure how to achieve this using ImageDataGenerator . I'm using keras's image data generator to load the images. train_dir = r'chunks/training' train_datagen = ImageDataGenerator(rescale=1 / 255) train_generator = train_datagen.flow_from_directory(train_dir, target_size=(256,256), color_mode='grayscale', class_mode='input', batch_size=256) ... autoencoder.fit(train_generator, epochs=5, batch_size=128, shuffle=True, validation_data=(test_generator, train_generator), callbacks=[])
