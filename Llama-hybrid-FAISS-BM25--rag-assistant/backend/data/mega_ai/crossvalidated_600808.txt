[site]: crossvalidated
[post_id]: 600808
[parent_id]: 
[tags]: 
Applying Leibniz's integral rule to the Gaussian distribution's normalization condition

I'm working on problem 1.8 of Bishop's Pattern Recognition and Machine Learning and am having a hard time understanding one of the technical details in a solution that I found online. Specifically, the problem statement is to show that the expectation of $x^{2}$ under the Gaussian distribution is equal to $\mu^{2}$ + $\sigma^2$ , and comes with the hint to differentiate both sides of the Gaussian normalization condition. I've attached an excerpt of the solution below. To me, it appears that differentiation of the integral with respect to $\sigma^{2}$ as shown implicitly utilizes Leibniz integral rule, or something akin to it. However, the statement of Leibniz integral rule as I've seen it precludes usage in the case of indefinite integrals. In this sense, it appears to me that the differentiation carried out in the solution is technically "illegal", despite producing the correct value. Can someone please help me to understand what's going on here? Does this solution utilize Leibniz integral rule, or am I misreading it? If Leibniz integral rule isn't being used, how instead could the integral be differentiated with respect to $\sigma^{2}$ ?
