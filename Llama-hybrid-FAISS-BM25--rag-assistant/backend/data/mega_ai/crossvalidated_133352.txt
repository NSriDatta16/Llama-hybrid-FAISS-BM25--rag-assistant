[site]: crossvalidated
[post_id]: 133352
[parent_id]: 95495
[tags]: 
Look no further! Yoshua Bengio published one of my favorite applied papers, one that I recommend to all new machine learning engineers when they start training neural nets: Practical recommendations for gradient-based training of deep architectures. To get his perspective on hyperparameter turning: including learning rate, learning rate schedule, early stopping, minibatch size, number of hidden layers, etc., see Section 3.
