[site]: datascience
[post_id]: 77150
[parent_id]: 
[tags]: 
Classification model accuracy with ensemble methods

I came through this statement in a Machine Learning text book based on law of large numbers: Suppose you build an ensemble containing 1,000 classifiers that are individually correct only 51% of the time (barely better than random guessing). If you predict the majority voted class, you can hope for up to 75% accuracy! I understand the analogy if we consider average over 1000 predictions but how majority votes lead to 75% accuracy from 51% (individual)?
