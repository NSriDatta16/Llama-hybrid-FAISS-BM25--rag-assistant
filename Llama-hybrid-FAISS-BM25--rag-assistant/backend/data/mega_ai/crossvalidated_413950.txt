[site]: crossvalidated
[post_id]: 413950
[parent_id]: 
[tags]: 
Coordinate Descent for the Binary Logistic Regression

I am studying Binary Logistic Regression (BLR) with the LASSO penalty and am trying to solve my objective function using the coordinate descent as discussed in the paper by https://web.stanford.edu/~hastie/Papers/glmnet.pdf , Section 3. What I am struggiling with is how to achieved from eqauation (14) to equation (15) in the paper. I have tried to use the below questions but neither of them seems to answer my question: Coordinate descent soft-thresholding update operator for LASSO Coordinate descent for binomial decision in elastic net for logistic regression My objective function is given by: $$\mathrm{argmin} \left\{\frac{1}{n}\sum_{i=1}^n -(\bf x_i^T \bf{\beta}) y_i+ \log(1+\exp(\bf x_i^T\bf{\beta})) +{\lambda}||{\beta}||_1\right\}$$ The above is the negative log-likelihood for the BLR, can someone provide a details proof of how to use the coordinate descent to solve the above?
