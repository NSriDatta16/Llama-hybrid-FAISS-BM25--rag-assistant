[site]: datascience
[post_id]: 110239
[parent_id]: 110236
[tags]: 
I think that is because logistic regression with ~3k labels is not a good choice you are right but I rephrase it a bit better: In general, Classification with ~3k labels is not a good choice! You basically have a Search/Recommendation problem. Given your input, you find the best fitting ticket/dashboard and assign it. It is a very interesting ML project actually! I give a confident starter. If it did not work, please come back with results and I update the answer: If you want to go Unsupervised Query-Document Matching Use a simple TF-IDF to vectorise your text Apply a dimensionality reduction to reduce high-dimensionality sparse vectors to low-dimensionality dense vectors. If you use matrix factorisations for this, you are basically doing famous classic LSA In that vector space, you find the closest label to your query and assign it to the query Topic Modeling Apply a simple LDA to model topics for the corpus Given a query, find the best matching topic of that query and assign the query to that topic (cluster) Please note that LDA finds intrinsic topics. So if your labels are different than topics that it finds, you need to rely on labels and ignore this solution A little bit more Supervised## Create a dataset from your corpus (or maybe you already have it) in which sentence pairs (titles, descriptions, etc.) which belong to same topic/label have label $1$ , and sentence pairs which belong to different topics/classes/labels have label $-1$ and sentence pairs with neutral relation have the label $0$ . I put an example as PS at the end. Feed this data to S-Bert to fine-tune the pre-trained model Read this, learn it and use it for finding most similar ticket/dashboard to the query PS: How data for S-Bert looks like (I just made up some dummy examples! hope you get the idea) sentence1: He is a man sentence2: He is male label: 1 sentence1: programming is hard sentence2: Maradona was a magician label: -1 sentence1: don't know what to write here sentence2: never mind, I think you got what I mean label: 0 . . .
