[site]: crossvalidated
[post_id]: 139033
[parent_id]: 
[tags]: 
How might Google go about estimating and updating traffic speeds?

This is, I guess, a specific example of a wider class of problem, one to which there must be a well-established solution, but which I, as a relative layman when it comes to statistics have thus far been unable to find. I understand that Google can track the speed of cars on road segments, and therefore has a set of speed observations which are taken at irregular intervals. I initially, therefore, have two questions: How can one take those irregular observations and come up with an estimate of current traffic speed (or indeed traffic speed at any point in time during the set of observations) given that traffic speed will vary over time, and How can the uncertainty in that estimate be calculated given a knowledge of when the observations were taken? For my second question, I would assume that the further in the past one's last observation was taken, the greater the uncertainty in the estimate, but how can this be formalised mathematically? Is this a Bayesian problem?
