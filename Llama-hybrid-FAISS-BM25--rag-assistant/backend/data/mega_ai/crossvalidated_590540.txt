[site]: crossvalidated
[post_id]: 590540
[parent_id]: 590527
[tags]: 
The way you simulated your data, everyone with a value of p greater than .5 gets a 1, and everyone with a value of p less than .5 gets a 0. To get a p greater than .5 is to have xBeta greater than 0, and therefore to have x1 greater than -.2. So, everyone in your population who has x1 greater than -.2 gets a 1, and everyone in your population who has x1 less than -.2 gets a 0. This does not correspond to a logistic regression model generating process; this corresponds to a sharp threshold, where there is no randomness given a unit's value of x1 . Logistic regression is for whenever you have a "non-deterministic" process where each individual has some nonzero, non-one probability of getting the outcome, and the goal is to model that probability. In your case, you set each unit's probability of getting the outcome to be either 0 (if x1 x1 > -.2). The model you fit is trying to mimic a steep threshold by giving you an extreme odds ratio, which is why the coefficient value is so high. The coefficient refers to the steepness of the bend in the logistic S-curve, and in this case, the true curve is a straight vertical line because you programmed a strict threshold. If you want p to refer to the probability of each unit getting the outcome, you need to flip a coin for each unit where heads is weighted with the value of p . To do that in R, you can use rbinom(n, 1, p) . This returns a vector of 0s and 1s, where the probability of 1 for each unit is equal to p (the 1 in the function call refers to the fact that were flipping one coin). So, as @utobi said, you need to replace y=(p > 0.5)+0 with y to correctly simulate the logistic process.
