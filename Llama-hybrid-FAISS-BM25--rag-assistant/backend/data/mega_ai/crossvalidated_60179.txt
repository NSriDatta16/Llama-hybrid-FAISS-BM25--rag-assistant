[site]: crossvalidated
[post_id]: 60179
[parent_id]: 
[tags]: 
Identifying a minimum time on web page as proxy for successful search outcome

Given a correlation between two sequences of numbers, I need to find to what point in one sequence the correlation is strongest. Here's why: I'm tracking large numbers of pages in a knowledge base, and flagging certain pages for followup. For example, if a page is among the most frequently viewed but also has a high ratio of negative ratings, it makes sense to prioritize that for further investigation and improvement. One of the more specific things I'd like to target is pages that have a high number of unrelated searches. It's no good if many people land on a page, but it's not actually what they were looking for. In that case, perhaps the page title and first paragraph or meta description need to be improved to cut out misleading vocabulary and more clearly indicate what the page is about. However, it's very time-consuming to look at search queries for hundreds of pages. I'd like to get a proxy metric to flag potential problem pages first, before diving into the search queries for those pages. I think I've found such a metric: average time on page. After manually grading a large number of pages based on the ratio of related keywords to unrelated keywords, I found that there was a positive correlation between low time on page and a high ratio of unrelated keywords. To be precise, an Excel CORREL formula came back with 0.46, which I'm led to believe is a reasonable indicator of a correlation. (By now, I'm sure it's obvious that I'm not a professional statistician. ;-) ) Is this a good start? If so, what kind of Excel formula could I run on the existing data to identify a minimum time on page, below which a page would be flagged for further followup? (I.E., a formula that would find the best cutoff point, above which the time on page didn't correlate so strongly with unrelated searches.)
