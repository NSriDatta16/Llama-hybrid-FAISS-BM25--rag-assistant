[site]: datascience
[post_id]: 100074
[parent_id]: 100073
[tags]: 
Is there a specific portion that you are having an issue understanding or is it more general? If it is more general, there is an excellent tutorial notebook that is linked to in that website you linked. We can also gain a more intuitive understanding of the different parts of the ML metadata from the below image, which was taken from the same link you provided. In the image, we see that the data and model are considered artifacts. The Execution is that of the Trainer of the model. Events in this flow were the input of the data and the model output while the Context annotates the entire experiment. From here, it is easier to understand where an Attribution and Association would fit in to this scheme. EDIT To add to prior post it is best to use the following image as well from the documentation: I am also new to TensorFlow so I am definitely with you on the documenation's lack of clarity, but I think we can look at "Artifacts" as "objects" and "executions" as a process, sort of like instructions on how to act on the artifacts. From there the "Events" can be seen merely as when data is inputted into the process and predictions are fed out, but its important to look at "Events" as just the process by which the data is read in and the predictions are read out and not the data/predictions themselves. It is rather abstract and why it took me awhile to get a grasp on it. The "Attribution" and "Association" can be thought of as the primary and foreign keys of database table in that they describe how certain items are related to each other which is why they are needed. As for your questions on components, the TFX User guide explains that: A TFX pipeline is a sequence of components... So basically, "components" in TensorFlow are merely the constituent parts of the pipeline. The standard components of a TensorFlow pipeline are listed in the TFX User guide. When it comes to workflow, I gather that its really just a generic term used to describe the end-to-end machine learning process. I believe that the term "conceptual grouping" is also generic as a "ContextType" is user-defined as per the API documentation. Also runtime parameters are explained in the "Understanding TFX Pipelines" documentation as: ...inputs to pipelines that are known before your pipeline is executed. I believe this edit as addressed the issues you have outlined. Hopefully this helps.
