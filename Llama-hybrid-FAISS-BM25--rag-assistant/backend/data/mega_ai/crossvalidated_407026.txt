[site]: crossvalidated
[post_id]: 407026
[parent_id]: 
[tags]: 
How normalize a list of time series features with pyspark?

My goal is to normalize a list of time series to perform a kmeans clustering My dataset is a dataframe with hashtags as entries and column containing time serie features like: +--------------------+--------------------+ | hashtag| features| +--------------------+--------------------+ | aldubseeyousoon|(119,[51,52,53,54...| | aldubsummerlove|(119,[9,10,11,12,...| | primaryday|[0.0,8.0,2.0,2.0,...| | aldubebfathersday|(119,[73,74,75,76...| | dolceamoresacrifice|(119,[90,91,92,93...| | 4yearswithexo|(119,[0,1,2,3,4,5...| (Some features lists are given as sparse) My question: If I want to normalize the dataset, is it enough to normalize for each line or do I have to do something else ?
