[site]: crossvalidated
[post_id]: 364888
[parent_id]: 364867
[tags]: 
I would suggest genetic algorithms (GA) or other global optimisers for this search, as your sequential score as you "build" the painting into more complex states is probably not the best guide. There are a few examples of similar puzzles, such as building Mona Lisa out of circles , and here is a more recent example of the same problem, with code examples . A GA approach would basically consist of a population of 100s of randomly generated sets of strokes, which you score and assess the best options. Then you select from the population, favouring solutions with the best score (there are lots of options for that, such as only picking from the top fraction, to using a skewed distribution that favours the top). Create pairs of solutions and "breed" them by taking some parts from the first and some from the second parent. Add just a little random noise as a "mutation". When you have done that enough to create a second generation, repeat the whole process. There are lots of variations. RL should also work, but you may have an uphill task to create a policy or value function that can learn the mapping from stroke actions and the current state to the eventual policy or value. It's definitely feasible from a theoretical standpoint though. The state is the current image. The action is a choice of next stroke. The reward is the improvement in score, and should probably be assessed on each action (but could be done every 10, every 50, or even just at the end - longer delays will challenge the RL more, but might allow faster iteration). Most RL algorithms, such as Q-learning, should be able to cope with avoiding "dead end" results where early good scores are false leads, and need to be revised. I don't know, but would be very interested to see, whether a GA or RL solves this problem more efficiently . . . my gut feeling is GA would be the way to go.
