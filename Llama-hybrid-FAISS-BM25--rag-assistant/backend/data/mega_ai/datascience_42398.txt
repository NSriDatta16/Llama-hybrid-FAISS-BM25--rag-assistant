[site]: datascience
[post_id]: 42398
[parent_id]: 
[tags]: 
KL divergence in VAE

If I understand correctly KL-divergence is relative entropy of two distributions. To calculate KL divergence of two distributions, you would need two vectors of random variables. What I do not understand it, how you can calculate KL divergence in VAE (latent space vector and N(0,1) as it is stated in many tutorials. Latent space vector is not a vector of random variables. It is a vector of product of input, weights,bias and activation functions. All these do not make your vector a random variable vector. My question is, how to properly create latent space vector as random variable vector, so you could eventually calculate KL divergence.
