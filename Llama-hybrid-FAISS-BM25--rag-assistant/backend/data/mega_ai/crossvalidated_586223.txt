[site]: crossvalidated
[post_id]: 586223
[parent_id]: 
[tags]: 
Improper Prior in Logit and Probit Models: Proper Posterior Conditions

Let $y_i \vert p_i \sim \mathrm{Bernoulli}(p_i)$ , $p_i = F_h(X_i^\prime \beta) \ \ , \ \ h = 1,2 \ ,\ \ X , \beta \in \mathbb R^p$ , where $F_1(x) = (2\pi)^{-1/2}\int_{-\infty}^x \exp(-t^2/2) \ dt \ $ and $F_2(x) = \big(1+\exp(-x) \big)^{-1}$ . So if $h=1$ or $h=2$ we have the probit or logit model respectively. In chapter $4$ of book "Bayesian Core: A Practical Approach to Computational Bayesian Statistics" (Marin and Robert) the authors suggest the use of $2$ kind of priors for these models, i.e. $\pi(\beta) \propto 1 \ $ (flat prior), $ \beta \vert \sigma^2 \sim N_p \big(0_p, \sigma^2 (X^TX)^{-1} \big) \, , \, \pi(\sigma^2) \propto \sigma^{-3/2}$ (g-like-prior) . However both of them are improper, so one needs to check if the posterior is a proper distribution. The authors leave this task as exercise but I do not have any idea to do this. More precisely, I know one needs to prove $$ \int_{\mathbb R^{p}} \pi(\beta) L(y; \beta) d \beta where $L(y; \beta)$ is the likelihood. I do not know how to find conditions on $(y,X)$ such that $\pi(\beta) L(y; \beta)$ is integrable in the cases of probit and logit likelihood. So, are there some references (book or papers) that explain and prove the conditions such that $\beta \vert y$ is a proper distribution with the use of flat and g-like-prior under probit and logit models? Thank you for the help EDIT: As suggested by @Xi'an I have tried the latent variable representation, i.e. $y_i = \mathbb I\{s_i > 0\} \ , \ i = 1,2, \dots, n$ , $s = X \beta + \epsilon$ , where $\epsilon_i \overset{iid} \sim N(0,1)$ and $\epsilon_i \overset{iid} \sim Logis(0,1)$ in the probit and logit model respectively. In the case of probit model one has $s \vert \beta \sim N_n(X \beta, I_n)$ , so by assuming a flat prior on $\beta$ one has $$ \pi(s) = \int_{\mathbb R^p} \pi(s \vert \beta) \pi(\beta) d\beta = \int_{\mathbb R^p} (2 \pi)^{-\frac{n}{2}} \exp \big(-\frac{1}{2} (s - X \beta)^T (s - X \beta) \big) d\beta $$ with some algebra one obtains $$ \pi(s) \propto \exp \Big(-\frac{1}{2} s^T(I_n - X(X^T X)^{-1} X^T)s \Big) \, . $$ Therefore one needs to check if $\pi(s \vert y) \propto \mathbb \prod_{i=1}^n I\big( (2y_i-1)s_i \ge 0 \big) \pi(s)$ is integrable. Let $n_0$ be the number of $y_i$ 's equal to $0$ , let $n_1$ be the number of $y_i$ 's equal to $1$ and let $M = I_n - X(X^TX)^{-1}X^T$ , thus $$ \int_{\mathbb R^{n_0}_-} \int_{\mathbb R^{n_1}_+} \exp \Big(-\frac{1}{2} s^T M s \Big) ds \, . $$ Let $A$ a diagonal matrix with entries $A_{ii} = 2y_i-1$ , let $s = Au$ thus $\lvert det(A) \rvert = 1$ and the domain of integration of $u$ is the positive orthant of $\mathbb R$ , then $$ \int_{\mathbb R^{n}_+} \exp \Big(-\frac{1}{2} u^T A M A u \Big) du \, . $$ since $M$ is a projection matrix it is always diagonalizable and has $n-p$ ones and $p$ zeros as eigenvalues. For the sake of simplicity assume the first $n-p$ are ones, So $$ \int_{\mathbb R^{n}_+} \exp \Big(-\frac{1}{2} u^T A M A u \Big) du = \int_{\mathbb R^{n}_+} \exp \Big(-\frac{1}{2} u^T A PDP^T A u \Big) du \, . $$ Let $t = P^T A u$ then $\lvert \det AP \rvert = 1$ and the domain of integration is $S(t) = \{t \in \mathbb R^n:APt \ge 0_n\}$ , so one has $$ \int_{S(t)} \exp \Big(-\frac{1}{2} t^T D t \Big) dt = \int_{S(t)} \exp \Big(-\frac{1}{2} \sum_{i=1}^{n-p} t_i^2 \Big) dt \, . $$ But from this point I do not know how go on. Thank you for the help
