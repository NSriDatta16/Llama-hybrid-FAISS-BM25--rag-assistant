[site]: datascience
[post_id]: 110040
[parent_id]: 110034
[tags]: 
Word2vec is trained on a specific corpus and the lookup runs in constant time. When you don't want context sensitive embeddings of the word depending upon the surrounding words, you can use word2vec. Word2Vec runs blazingly faster than BERT. Hence, when your requirement for word embedding is sufficed by word2vec, no over engineer by taking BERT.
