[site]: crossvalidated
[post_id]: 575740
[parent_id]: 
[tags]: 
Usefulness of KS tests and other similar distribution comparing tests

I am working on a machine learning binary classification problem. I have an outcome variable status called as loan paid and loan default . So, I have the loan amount data for each of the loans. Now, I would like to know whether the loan amount borrowed is significantly different for loan paid and loan default applicants. So, I tried KS-test to compare the loan amount for these two groups. Am I right to do this way? data1 = loan_df[(loan_df['status']=='default')]['loan_amount'].reset_index(drop=True) data2 = loan_df[(loan_df['status']=='paid')]['loan_amount'].reset_index(drop=True) from scipy.stats import ks_2samp #perform Kolmogorov-Smirnov test ks_2samp(data1, data2) I get a result as below KstestResult(statistic=0.504473708788643, pvalue=5.551115123125783e-16) My questions are as follows a) What is the usefulness of these tests? Meaning, if they are significantly different from each other, do they help in predictive power? b) what kind of inference can be made from such tests? c) Is there any other methods available to compare two distributions? So, I can double confirm/cross-verify that it is indeed different
