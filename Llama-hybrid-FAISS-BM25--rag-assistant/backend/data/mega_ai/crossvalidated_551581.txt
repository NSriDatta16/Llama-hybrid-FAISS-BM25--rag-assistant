[site]: crossvalidated
[post_id]: 551581
[parent_id]: 
[tags]: 
Can a power of y (dependent variable) be used in neural network as input?

I am using MLP (Multilayer perceptron) for regression and predicting a continuous variable y (which is the waiting time of passengers in an intercity station). Unfortunately, the fit of the model is bad and It does not predict the variable y well. The residuals of the model have ascending linear pattern. I want to know, can I insert a power of y (for example y^2) as an input to my neural network model (my transfer functions are linear and tansig)? I have seen many times that in situations of having an ascending linear pattern of residual in linear regression we can use a power of y as an input to manage the errors. Can we do the same in MLP? Thanks in advance for your time and consideration.
