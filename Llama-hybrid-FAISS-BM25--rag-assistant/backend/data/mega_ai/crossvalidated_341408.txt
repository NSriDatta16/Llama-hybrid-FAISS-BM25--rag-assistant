[site]: crossvalidated
[post_id]: 341408
[parent_id]: 341393
[tags]: 
That depends on what you mean to be a null. If you mean that there is a binary set of hypotheses, but neither is presumed to be correct then there could be a null hypothesis. If you mean that you are asserting some hypothesis as true, such as $\mu=0$ or $\mu\le{0}$, then no nothing like this exists. There is a sizable literature on the problems of p-values. What most people do not realize is that Bayes factors can share all of the same problems that p-values have. However, posterior probabilities lack the problem that either Bayes factors or p-values have. You cannot avoid the prior in Bayesian thinking. In fact, choosing a flat prior is a subjective choice. There are many cases where if you use an improper flat prior that you will get a solution that does not integrate to unity and your inferences won't be valid. You also shouldn't want to. For example, I used a nearly flat prior with zero mass over places where a parameter was not supported, and my relative efficiency against the Frequentist alternative was 16:1. The greatest challenge for people in Bayesian statistics seems to be dealing with shades of gray. Generally speaking, the goal should be to use the posterior density. Bayes factors have problems that a posterior ratio does not have. Still, a Bayesian analysis may not be appropriate for your problem at all anyway. If there is prior research that you could use to form the prior densities, then it should be incorporated into your research. If there is no research on the topic, then Frequentist methods may have a significant advantage. Frequentist methods minimize the risk of taking the maximum possible loss from making decisions based upon the parameter outcomes of an experiment. They also provide a guaranteed minimum level of protection against false positives. This is because Frequentist p-values are not true probabilities but instead are mini-max probabilities. It is also possible to determine power. Neither of these things is possible with Bayesian methods because power presumes that some form of repetition of the experiment will happen, whereas Bayesian methods only consider the actual sample you gathered. Likewise, because Bayesian probabilities are actual probabilities, given the data, there is no ability to protect against false positives because there is no thought about the sample space it could have come from, only what was seen. If it is a weird sample, then no protections are present. You should be using Bayesian methods when you have real prior information because the gain in information can be enormous, as in my example above. In Brad Effron's famous paper on Stein's Lemma in Scientific American he improves the precision of estimating end-of-season batting averages by four to one over the Frequentist. While he was using a shrinkage estimator, it was the mathematical equivalent to the Bayesian solution with an empirical prior. You should only consider Bayesian methods if you are gambling on the outcome, either in a direct true gamble or through things like budgeting. Only Bayesian methods generate odds that can be successfully gambled on. Using other methods allows a crafty person or set of persons to actually rig the outcome in their favor in all states of nature. I have actually done games in a class where the Bayesian students were nearly guaranteed to double their money and the Frequentist students had a fifty-percent chance of breaking even. The Frequentist estimator was the minimum variance unbiased estimator, but the Bayesian method was so much more accurate that breaking even was almost impossible and doubling the money was the strong expectation. Finally, you should think of the prior as a tool for argument. I wrote a paper where I gave the accepted theory 999,999:1 prior odds in favor that it was correct. My argument was that if my work was still significant over such prejudiced odds, then it would be meaningless to still consider accepted teaching. Even with that prior, I decisively excluded standard teaching. In probability and statistics, there is no such thing as a free lunch. If you choose a Bayesian method you may get very material gains in accuracy and realistic probability statements, but you have to take the prior as part of the deal. If you choose a Frequentist method, then you have to accept that a parameter estimate may be in a place that is excluded by theory or logic, that you cannot distinguish if something is falsified by chance or actually false and results that are unsafe to use if life or money is on the line. Use the posterior odds not Bayes factors, bite the bullet. Get a prior.
