[site]: crossvalidated
[post_id]: 318088
[parent_id]: 
[tags]: 
How to avoid distortion through normalization

I'm training a neural network to predict some numbers that can be positive or negative and the range can vary. The network will eventually be used to predict if the number will be positive or negative. I noticed that when I normalize the number with scikit's learn minmaxscaler scaler = MinMaxScaler(feature_range=(-1, 1)) the end result of the training is much worse than if I don't normalize anything. How can I avoid distortion in predicting positive and negative numbers?
