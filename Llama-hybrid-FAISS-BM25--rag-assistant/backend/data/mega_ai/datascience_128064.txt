[site]: datascience
[post_id]: 128064
[parent_id]: 
[tags]: 
Systematic bias of neural network regression

I am not sure if here is the correct place to ask this question. I was trying to do graph-level regression task using graph convolutional networks, basically I concatenated 3 linear layers after several GCN modules, I used ReLU activation function before each linear layer. Each of my graph is generated by 3 parameters: lambda, mu and K, I used randomly sampled parameters to generate a whole set of graphs, and use graph neural network to learn to estimate the parameters used to generate those graphs. I plotted (prediction - ground truth value) against ground truth value for lambda, mu and K, the results are as following: It is clear that the predicted values of each parameter are strongly linearly correlated to the ground truth values of itself but not correlated to other parameter's ground truth values, if we look at the diagonal panels. Can we say that the predictions of my model are systematically biased? Is there any general method to correct this kind of bias? More figures showing predicted values against true values. From new figures we can see that there are a set of samples that caused GNN to predict exactly the same lambda, mu and K values.
