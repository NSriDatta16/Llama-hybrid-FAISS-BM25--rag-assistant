[site]: crossvalidated
[post_id]: 361079
[parent_id]: 
[tags]: 
If we do not consider overfitting and regularization, should I try super hard to make training loss close to 0? Is there any lower bound for it?

Background: when build supervised machine learning models, the first step is usually to fit the training data well. Later on, we may add some regularizations to avoid overfitting. My question is that, at the first step , should we try super hard to make the loss close to 0, by making the model super complex (say, millions of parameters or very deep neural network)? My experience is it seems there are some lower bound of the loss, that no matter what I do to intentionally overfit the training data, the loss would not decrease. Why?
