[site]: datascience
[post_id]: 64776
[parent_id]: 64770
[tags]: 
That's the point of RFECV over RFE: the former selects the best number of features through cross-validation. If you want 15 features, use RFE instead (or some other feature selection method). From the API docs , cross-validated selection of the best number of features and from the User Guide RFECV performs RFE in a cross-validation loop to find the optimal number of features. To respond to the comments (my response is a bit too long for comments): Yes, RFECV is meant to produce the optimal number of features. RFE is run from the full feature set down to 1 feature on each of the cross-validation splits, then those models are scored on the test folds and averaged; then the best-scoring number of features can be taken and then RFE is run again down to that number of features. The thought is that (barring some special domain knowledge) RFECV is better than RFE, except that it may take rather longer to run. By definition, the RFECV's accuracy ( on the CV-splitted training set ) will be better than RFE with any other fixed number of features. Now, the usual caveats apply. The number of features returned by RFECV may not necessarily generalize the best to unseen data, especially if that data isn't perfectly iid with the training data. Especially with small datasets, the splits made in the CV may affect the results, and perhaps going from the smaller CV train sets to the whole train set should allow more (or fewer?) features. And the top features on each of the splits may not be the same, so again when going to the full training set the question of increasing (decreasing?) number of features is reasonable.
