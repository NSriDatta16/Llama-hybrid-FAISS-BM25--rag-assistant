[site]: crossvalidated
[post_id]: 223862
[parent_id]: 
[tags]: 
What can be said about about significant predictors in simple regression that become insignificant in multiple linear regression?

I have two predictor variables: An indicator variable A and a continuous variable B. My response variable is continuous (and also bounded, have not made it logit for reasons of simplicity). In simple linear regression, both predictors are significant. When including the two in multiple regression, both become insignificant in an overall significant model. Other details: An interaction variable composed of the two variables is insignificant Beta for quantitative variable B is quite different between the two groups of the indicator variable A if I do a stratified analysis with a regression with B (That is, separate the data into the 0 and 1 groups for indicator A, then run regression using B as predictor). VIF's are low for the two variables, suggesting no multicolinearity. Crucial to the theory my study is about is the possibility that the variance explained by B is in large part explained by variable A. It doesn't seem like I am able to justifiably make any such claim. But what can I say in regards to the impact of A and B on the response and their relationship with one another? I am happy to provide more details if needed. Requested info about confidence intervals: Here are the intervals -- FAB.Average is quantitative predictor, the HSSorSTEM is the indicator. My n = 30, but each datapoint is the average of 500+ observations, if that makes any difference. I'm not quite sure what a joint confidence ellipse is (I work with a knowledgable statistician, but am not myself one), but here was my try at making one:
