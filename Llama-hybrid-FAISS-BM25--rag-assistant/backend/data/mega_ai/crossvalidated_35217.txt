[site]: crossvalidated
[post_id]: 35217
[parent_id]: 30762
[tags]: 
I would use Akaike’s Information Criterion ($AIC$) for model selection where: $$ AIC = -2ln(L)-2k $$ Though a better alternative is often $AIC_c$, which is the second-order Akaike’s Information Criterion ($AIC_c$). $AIC_c$ is corrected for small sample size with an addtion bias-correction term because $AIC$ can perform poorly when the ratio of sample size to the number parameters in the model is small (Burnham and Anderson 2002). $$ AIC_c = -2ln(L)-2k+\frac{2k(k+1)}{(n-k-1)} $$ In fact, I would always use $AIC_c$ since the bias-correction term goes to zero as sample size increases. However, there are some types of models where it is difficult to determine sample size (i.e., hierarchical models of abundance see links to these model types here ). $AIC$ or $AIC_c$ can be recaled to $\mathsf{\Delta}_i=AIC_i-minAIC$ where the best model will have $\mathsf{\Delta}_i=0$. Further, these values can be used to estimate relative strength of evidence ($w_i$) for the alternative models where: $$ w_i = \frac{e^{(-0.5\mathsf{\Delta}_i)}}{\sum_{r=1}^Re^{(-0.5\mathsf{\Delta}_i)}} $$ This is often refered to as the "weight of evidence" for model $i$ from the model set. As $\mathsf{\Delta}_i$ increases, $w_i$ decreases suggesting model $i$ is less plausible. Also, the weights of evidence for the models in a model set can be use in model averaging and multi-model inference.
