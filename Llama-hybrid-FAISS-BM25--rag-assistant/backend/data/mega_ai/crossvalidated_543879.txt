[site]: crossvalidated
[post_id]: 543879
[parent_id]: 
[tags]: 
Predicting the lifetime of events using ML, based on observation window

I am trying to predict the lifetime of events based on the features X of the event. There are some caveats to the samples that make training the NN non-trivial: Samples were gathered in a small observation window of 24h. I am only interested in getting the short-term events accurately. The ones that are less than 24h. 60% of events are long-term. They last much longer than 24h. If an event existed before the start of the observation window, there is no way of detecting when it started. If an event started within the observation window, but lasted beyond the end of observation, I again have no way of detecting how long it lasted. I currently feed the long-term events in with the maximum lifetime of y=24h. This is obviously not their true lifetime, but there is no way of knowing what is. Because such a large amount of samples are longer than the observation window, the neural network tends to guess higher lifetimes for the short term events. This is the reverse of what I am trying to achieve. I want to predict the short-term events as accurately as possible and don't care much about the accuracy of the long-term ones. I have tried filtering out all samples that cross the observation boundaries, but this leads to the NN not really knowing what a long-term event looks like, which leads to it predicting long-term events as having a short lifetime. I thought about writing the loss function in such a way that observations, which cross the boundaries and have a higher predicted lifetime, are punished less than normal. The logic being, that the high guess may be accurate - there is no way of knowing. I'm not sure if this is the right approach. Are there any common approaches to problems like this?
