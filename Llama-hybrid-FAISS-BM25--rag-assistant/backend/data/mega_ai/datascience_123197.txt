[site]: datascience
[post_id]: 123197
[parent_id]: 122285
[tags]: 
For some type of chatbot, like a customized chatbot, may it be better to fine-tune the LM for the domain-specific data and the type of question instead of relying on the prompt as prompts have to be processed by the LM every time? Prompt, because according to the LIMA: Less Is More for Alignment paper: These results strongly suggest that almost all knowledge in large language models is learned during pretraining , and only limited instruction tuning data is necessary to teach models to produce high quality output.
