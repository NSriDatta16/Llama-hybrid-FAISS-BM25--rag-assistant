[site]: crossvalidated
[post_id]: 592913
[parent_id]: 591769
[tags]: 
Several confusions here: The VQ-VAE ELBO objective can be written as the KL divergence between the true and approximate posterior, as in Rocca which can be shown to be written as the expectation of the conditional likelihood - the KL divergence between the approximate posterior and the prior : $$ argmax ELBO = argmin KL(q_x(z), p(z|x)) = $$ $$argmax(E_{z: q_x}(logp(x|z)) - KL(q_x(z),p(z)))$$ Now if the prior is uniform over the K possible values of z, and $q_x(z)$ is a one-hot distribution, it's clear that the KL divergence is a constant $logK$ , so we're left with only maximizing $logp(x|z_q(x))$ , which is exactly what's presented in VQ-VAE . Also, if we assume that p(x|z) is a Gaussian whose mean is a deterministic function of z (the decoder), and the covariance is $cI$ , we can arrive at the familiar reconstruction MSE loss. All this is unrelated to the initialization of the $e_k$ embedding values, which is also uniform but might as well be from another distribution.
