[site]: crossvalidated
[post_id]: 326219
[parent_id]: 326194
[tags]: 
It is indeed confusing when using confusing notations! As, e.g., in your question with $Pr(\cdot)$ for all probabilities. Let us consider an MCMC algorithm where detailed balance holds. This means that, given the Markov transition kernel $K$ with density $k(x,x')$ [which is also the generator of the Markov chain in that $X_{t+1}|X_t=x\sim k(x,x')$], there exists a probability density $\pi$ such that$$\pi(x)k(x,x')=\pi(x')k(x',x)$$i.e., there is time reversibility in the Markov chain: if $X_t$ is distributed from $\pi$, $X_t\sim\pi$, then $X_{t+1}$ is distributed from $\pi$, and also $X_{t-1}$ is distributed from $\pi$. Why is this different from Bayes' rule? It is true that Bayes' rule allows for the inversion of a joint distribution from marginal of $X$ times conditional of $Y$ to marginal of $X$ times conditional of $Y$ . However, if one starts with a random variable $X_t$ with marginal distribution (density) $\pi_t$ and applies the Markov kernel $K$, then $X_{t+1}$ will be distributed from a marginal distribution (density) $\pi_{t+1}$, providing the general equality $$\pi_t(x)k(x,x')=\pi_{t+1}(x')\tilde{k}(x',x)$$ where $\tilde{k}$ denotes the density of the time-reverse kernel [obtained as the distribution of $X_t$ given $X_{t+1}$]. Therefore the detail balance property is very specific wrt Bayes' inversion formula in that $\pi_t(x)=\pi_{t+1}(x)$ [stationarity] $k(x,x')=\tilde{k}(x,x $ [reversibility] and it only holds for a subfamilly of MCMC algorithms like the Metropolis-Hastings algorithm.
