[site]: crossvalidated
[post_id]: 574902
[parent_id]: 574898
[tags]: 
Mathematical modelling appears in a lot different fields, especially statistics that are just a way of making models using empirical data or introduce randomness. The is no "superiority", since both field are intricated. When it comes to machine learning (or statistics, this is the same), some models are more easily interpreted than others. For example the simplest model: linear regression. It is easily interpreted because the physical meaning of the coefficients can be identified. However, this means that the observed phenomenon must be able to be modelled by a linear law, with one transformation, for example a power law is nothing other than a linear law in a log-log graph. If the phenomenon is "simple", you can probably come up with a theoretical model and then validate it on data using machine learning/statistics , good! On the other hand, if you are studying an extremely complex phenomenon, the modelling task becomes much more difficult. This is where deep-learning models (or other very complex models that work like a black box) can outperform "classical" hand-made models if you have enough data, since the model itself will be learned. But in general, these models will be difficult to interpret. This can be a bit discouraging in a way... Finally, the fact that machine learning is "mainstream" (which is not really the case, but there is a bit of a hype around it indeed) comes from the fact that there are libraries that have already implemented many algorithms for you. But if you're not able to understand what you're doing I don't think anyone will accept your work...
