[site]: crossvalidated
[post_id]: 414015
[parent_id]: 414009
[tags]: 
It's usually important to keep all the data that you can--especially if the non-response mechanism (the reason why the data might be missing or the reason why the respondent failed to complete the entire survey) may be related to your variables of interest. Generally speaking, it's okay to drop a respondent (i.e. throw out a respondent's data) when the data is Missing Completely at Random (MCAR) . For example, data might be missing completely at random if a random technical problem brought down the web-server hosting an online survey. Certainly the timing of when a server went offline would rarely have anything to do with the rest of the variables in your dataset. If data is not missing completely at random, then you will need to do some more work. For example, if your survey is about income, you might find those who are quitting the survey prematurely are less likely to be persistent or patient, and this might, in fact, be related to income. If you were to exclude those who prematurely quit the survey, you might, unknowingly bias your income analysis. Instead, it's typically best to impute your data. Simply put, this essentially means you try to fill in the missing values with good statistical "guesses." There are a number of methods to do this, including, but not limited to, nearest neighbor imputation, hot-deck imputation , and cold deck imputation. Perhaps the most popular imputation method now in practice is the one derived by Don Rubin : multiple imputation (but keep in mind there are different implementations of multiple imputation too!). This method basically involves making different statistical guesses at what the missing values would be, deriving multiply imputed datasets, and then averaging over the datasets for the analyses. So, in summary, it's best to try to determine the cause of the missingness, and if it's missing completely at random to proceed with a complete cases analysis, if you have sufficient data to power your study. If the data is not missing completely at random, then it's wise to impute the data, and then proceed with an analysis of the imputed data.
