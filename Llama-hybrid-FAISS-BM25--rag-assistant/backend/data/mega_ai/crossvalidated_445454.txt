[site]: crossvalidated
[post_id]: 445454
[parent_id]: 223256
[tags]: 
I've revisited this question as I now disagree with the answer I previously accepted. Cross entropy loss CAN be used in regression (although it isn't common.) It comes down to the fact that cross-entropy is a concept that only makes sense when comparing two probability distributions. You could consider a neural network which outputs a mean and standard deviation for a normal distribution as its prediction. It would then be punished more harshly for being more confident about bad predictions. So yes, it makes sense, but only if you're outputting a distribution in some sense. The link from @SiddharthShakya in a comment to my original question shows this.
