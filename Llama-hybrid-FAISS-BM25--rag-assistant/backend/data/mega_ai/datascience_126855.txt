[site]: datascience
[post_id]: 126855
[parent_id]: 126853
[tags]: 
If outright retraining is out of the question (which honestly makes sense since it'd likely be time and resource intensive), then you can try a couple things: Treat this as an out-of-vocabulary problem and keep an OOV token that you apply to unseen words Partial retraining as you described: there are methods (I haven't used them so YMMV) where you add new rows for your unseen words, fix the parameters corresponding to your existing vocabulary, and you train and update the new rows. Example PyTorch discussion Imputing OOV: FastText and other methods that learn character/sub-word level embeddings could be useful for assembling new words. LOVE FastText Transfer Learning where you get a larger pre-trained embedding layer that hopefully has the vocabulary you need EDIT: This also could be connected to this question here
