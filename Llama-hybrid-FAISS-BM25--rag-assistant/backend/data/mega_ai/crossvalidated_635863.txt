[site]: crossvalidated
[post_id]: 635863
[parent_id]: 635677
[tags]: 
when implementing the effects coding approach, there is no way to get modification indices when I use MODEL CONSTRAINTS: Using lavaan in R, this is quite straight-forward using lavTestScore() . Regardless of software, effects-coding makes it complicated to test 1 item at a time because even if you use different labels for one item (e.g., Item 4, with loading labeled LLL4 ), the constraint that the average of 4 loadings = 1 would imply the save value of the fourth loading across all 4 occasions. The practical solution is to apply the effects-coding identification constraint to only the loadings that are held invariant (i.e., "anchor" items): MODEL CONSTRAINT: LLL1= 3 - LLL2 - LLL3; ! 4th item omitted Then you can define NEW parameters that represent DIF difL_12 = T1L4 - T2L4; difL_13 = T1L4 - T3L4; difL_23 = T2L4 - T3L4; ... Those user-defined DIF parameters each get their own 1- df Wald test. But if you want a single omnibus Wald test, you can use MODEL TEST to test the set of constraints: MODEL TEST: T1L4 = T2L4; ! this test has df=3, so T1L4 = T3L4; ! all 6 pairwise equalities T1L4 = T4L4; ! are implied by these 3 there other information I could consider for making adjustments to the model? The problem with this DIF-searching method is the inflated Type I error rate for non-DIF items that are tested when using DIF items as anchors. This is still a useful method for empirically choosing anchor items, though. After testing each item (while each test assumes the other 3 are DIF-free), you can take the 50% of items with the smallest test statistics to treat as anchors. Then you fit the partial-invariance model and calculate Wald tests for the other 50% of items. Because the empirically chosen anchor items are much less likely to include DIF (any Type I errors are probably a small effect size, so limited contamination), the Wald tests of other items tend to have very little bias or Type I error inflation. This 2-step method (first select anchors, then test DIF) was first proposed for multigroup IRT models: https://doi.org/10.1177/0146621607314044 But the general idea works just as well for multigroup or multioccasion CFA or MIMIC models: https://doi.org/10.3758/s13428-018-1151-3
