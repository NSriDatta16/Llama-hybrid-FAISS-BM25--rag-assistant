[site]: stackoverflow
[post_id]: 1842990
[parent_id]: 1841629
[tags]: 
How are you getting displayImage and what ColorModel is it using? If it is an IndexColorModel , that may explain a lot. The first code fragment will return a BufferedImage using a DirectColorModel . That will require 4 bytes per pixel vs typically 1-byte per pixel for an indexed image. That 1:4 expansion could be causing your out of memory condition. The second code fragment makes a BufferedImage with the same model as the source. When that is an IndexColorModel and the interpolation is not NEAREST_NEIGHBOR , the filter() call will create a temporary BufferedImage with a DirectColorModel . It will use that as the destination of the filter operation, then requantize the temporary buffer and draw it into your displayImage2 . So, twice as many bitblits. If you're only doing a single transform, I'd say go with the second form. If you're doing multiple operations, allocate a pair of BufferedImage s with a DirectColorModel . large enough to hold your biggest image. Draw you source image into one of them and perform your filters back and forth between them. Then when you're finished, use a ColorConvertOp to requantize back to an indexed image. That way you only need to color convert once instead of on each filter call.
