[site]: datascience
[post_id]: 117329
[parent_id]: 
[tags]: 
I can't get the tiny grad README example to work

I tried out the GitHub project, tinygrad, and it shows a Torch example, and an equivalent TinyGrad example. For import torch x = torch.eye(3, requires_grad=True) y = torch.tensor([[2.0,0,-2.0]], requires_grad=True) z = y.matmul(x).sum() z.backward() print(x.grad) # dz/dx print(y.grad) # dz/dy I get a sensible looking tensor([[ 2., 2., 2.], [ 0., 0., 0.], [-2., -2., -2.]]) tensor([[1., 1., 1.]]) but when I try from tinygrad.tensor import Tensor x = Tensor.eye(3, requires_grad=True) y = Tensor([[2.0,0,-2.0]], requires_grad=True) z = y.matmul(x).sum() z.backward() print(x.grad) # dz/dx print(y.grad) # dz/dy I get with grad None> with grad None> I am on a Mac Studio running Ventura (13.0.1 (22A400)) using Python 3.10.8. Am I missing some kind of low level driver or accelerator or something? I am new to all of this (my first attempt to look at Deep Learning technology) so I don't understand what I am looking at. I see references to MovementOps in accel/opencl/ops_opencl.py so I'm thinking some kind of post processing step is missing?
