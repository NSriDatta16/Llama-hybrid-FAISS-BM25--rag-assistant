[site]: crossvalidated
[post_id]: 488238
[parent_id]: 486842
[tags]: 
It's true that GANs generally produce good results when trained on a massive amount of data. However, CycleGAN has been around for a while and they produce realistic images when trained only on a few images (the open-sourced datasets used by the authors have about 1000 images on an average). That said, this (very recent) paper talks about differentiable augmentation as a novel technique for training data-efficient GANs. Their results include experiments with a fraction of data in CIFAR10 and CIFAR100 datasets. This paper from MIT considers evolutionary GAN training as a means to reduce the amount of data used for training. It would also help to look specifically into the papers that use GANs for medical image synthesis or translation problems because data is already scarce in the medical domain, hence people have found some interesting techniques to get around it. As for the non-image-generation applications of GANs, WaveGAN is a model for synthesizing audio, spaceGAN for geospatial modeling, etc. This Reddit discussion gives many more examples of GANs in non-image applications.
