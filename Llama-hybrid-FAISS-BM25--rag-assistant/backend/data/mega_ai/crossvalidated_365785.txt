[site]: crossvalidated
[post_id]: 365785
[parent_id]: 175523
[tags]: 
Thank you very much for the answers ! As I still had questions, I performed some numerical simulations to have more insights about the behavior of these two methods. Extra trees seem to keep a higher performance in presence of noisy features. The picture below shows the performance (evaluated with cross validation) as random columns irrelevant to the target are added to the dataset. The target being just a linear combination of the first three columns. When all the variables are relevant, both methods seem to achieve the same performance, Extra trees seem three times faster than the random forest (at least, in scikit learn implementation) Sources Link to the full article : random forest vs extra trees .
