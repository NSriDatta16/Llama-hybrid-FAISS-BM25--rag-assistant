[site]: stackoverflow
[post_id]: 1239204
[parent_id]: 1239058
[tags]: 
Hmmm... I suppose my stumbling block is around the shared data structure itself... I've been using something like public class LotsOfData { int fee; int fi; int fo; int fum; long[] other = new long[123]; /* other fields too */ } where the publisher updates data often, but only one field at a time. It sounds like maybe I should find a way to serialize updates in a way that's conducive to using a producer-consumer queue: public class LotsOfData { enum Field { FEE, FI, FO, FUM }; Map feeFiFoFum = new EnumMap (); long[] other = new long[123]; /* other fields too */ } and then post change items to a queue, like (FEE, 23) for the feeFiFoFum fields, and (33, 1234567L) for the other array. (Bean-type reflection is almost certainly out, for performance reasons.) Still, it seems like I'm spoiled by the apparent simplicity of just having the publisher write whatever it wants, and knowing that there will be time (eventually) for the reader(s) to go in and get a consistent set of data, if only it had a flag it could use to tell if the data has been modified. update: interesting, I tried this approach, with a ConcurrentLinkedQueue of Mutation objects (storing only the state necessary for 1 change) for a class similar to the first LotsOfData above (4 int fields and an array of 27 longs), and a producer that produces a total of 10 million mutations with Thread.sleep(1) in between batches of about 10000, and a consumer that checks the queue every 100 milliseconds, and consumes whatever mutations are present. I ran the test in a number of ways: empty action within test framework (just looping 1000 times, calling Thread.sleep(1), and checking whether to use a null object): 1.95 sec on my 3GHz Pentium 4 running jre6u13. test action 1 -- create and apply mutations on the producer end only: 4.3 sec test action 2 -- create and apply mutations on the producer end, place each on queue as they are created: 12 sec so that's 230nsec on average to create each mutation object, and 770nsec on average to enqueue/dequeue each mutation object onto the queue in the producer and pull it off in the consumer (time to execute the mutations for primitive types seems negligible, compared to object creation and queue operations, as it should be). Not bad I guess, and it gives me some metrics to estimate performance cost for this approach.
