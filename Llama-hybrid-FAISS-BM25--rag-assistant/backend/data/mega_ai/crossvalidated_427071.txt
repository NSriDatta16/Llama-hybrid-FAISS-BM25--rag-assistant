[site]: crossvalidated
[post_id]: 427071
[parent_id]: 427048
[tags]: 
Are you training your network with a single one of those training sets? Meaning that you just have 200 samples for the training of which one is positive and the rest negative? I think this is a tough classification problem anyways, because you classes are highly imbalanced. In this case, you usually want to re-balance the dataset, but this might be difficult in your case. However, you should try to include as much training data as possible and probably try some weighted accuracy measures like weighted cross-entropy (see here and here for a short explanation). Due to the lack of data you might also want to consider other (and maybe less sophisticated) models like decision trees/random forests or basic logistic regression.
