[site]: crossvalidated
[post_id]: 429058
[parent_id]: 429021
[tags]: 
This is a comment, but too long. I looked at the cited paper by Robert Nau, and here is actual citations: (page 6 of pdf) You should try to avoid using “mixed” models in which there are both AR and MA coefficients, except in very special cases. with this footnote: An exception to this is that If you are working with data from physics or engineering applications, you may encounter mixed ARIMA(p, 0, p-1) models for values of p that are 2 or larger. This model describes the discrete-time behavior of a system that is governed by a p-order linear differential equation, if that means anything to you. For example, the motion of a mass on a spring that is subjected to normally distributed random shocks is described by an ARIMA(2, 0, 1) model if it is observed in discrete time. If two such systems are coupled together, you would get an ARIMA(4, 0, 3) model. Also, among his list of typical models, he includes one model breaking this advice ARIMA(1, 1, 2) = linear exponential smoothing with damped trend (leveling off) showing the advice is meant to be tentative. The paper is an instructional one aimed for business students, and much advice is modified by ... for a business application . Lot of other interesting advice, one example cite: (page 20 of pdf) If you apply one or more first-difference transformations, the autocorrelations are reduced and eventually become negative, and the signature changes from an AR signature to an MA signature. An AR signature is often the signature of a series that is “slightly underdifferenced,” while an MA signature is often the signature of a series that is “slightly overdifferenced.” If you apply one difference too many, you will get a very strong pattern of negative autocorrelation.
