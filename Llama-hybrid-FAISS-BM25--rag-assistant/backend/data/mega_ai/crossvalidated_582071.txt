[site]: crossvalidated
[post_id]: 582071
[parent_id]: 582061
[tags]: 
It is common to find flawed data analysis in health research, not only flawed machine learning analysis but also flawed standard statistical analysis. cross-validation just helps you to estimate out-of-sample prediction, but it won't help you to correct standard errors or p-values of individual coefficients in a model. You can use bootstrap for that, where feature elimination and model selection steps are repeated in each bootstrap repetition. Machine learning is not magic. If you are afraid of over-fitting some standard statistical model, it won't help to use an even more flexible model. Various feature importance metrics are not improvements on your standard statistical tools but rather bad approximations. Usually, they just tell you what is happening in your model, but they cannot be made to make inferences about effects in the population. Also, the goal of a statistical model is not just to find any relationship between variables but to estimate an effect of a variable while correcting for other variables or other known structures in your data. backward selection is not a recommended tool, and statisticians actively warn against it. If you care about valid statistical inference, then the solution is not to exchange bad statistics for machine learning but to use good statistics. I am not saying that machine learning doesn't have its place in health research, and there cannot be interesting research questions answered using ML methods, but it is not an automatic solution to statistical problems.
