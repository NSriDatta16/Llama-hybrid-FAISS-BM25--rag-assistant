[site]: crossvalidated
[post_id]: 513429
[parent_id]: 496653
[tags]: 
I eventually convinced myself this is okay, so here's my intuition: Assuming we had infinite data, at any point we could calculate the fraction of positives. We don't have infinite data, but essentially the same thing is happening. If at a certain x value, the true fraction of positives was 0.25, then we'd expect our finite data to reflect that, i.e. there should be roughly 3 times as many 0 labels around that area than 1 labels. This would pull the curve downwards to roughly the right place. The same thing happens in Logistic Regression when we want to train a binary classifier.
