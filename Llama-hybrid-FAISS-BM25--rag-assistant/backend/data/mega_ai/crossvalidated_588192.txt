[site]: crossvalidated
[post_id]: 588192
[parent_id]: 
[tags]: 
Is it appropriate to discretize conditional posteriors in an MCMC as an alternative to techniques like Metropolis-Hastings or slice-sampling?

Background Suppose I am interested in sampling the posterior distribution defined by $p(\theta_1,\theta_2|y)$ , where $\theta_1,\theta_2$ are parameters of interest and $y$ is a vector of observations. With proper priors $p(\theta_1)$ and $p(\theta_2)$ , I set up my Gibbs sampler as follows: Draw $\theta_1$ from a distribution with pdf proportional to $p(y|\theta_1,\theta_2)\times p(\theta_1)$ Draw $\theta_2$ from a distribution with pdf proportional to $p(y|\theta_1,\theta_2)\times p(\theta_2)$ I can repeat steps 1 and 2 to create a chain, and after some burn-in the cumulative distribution of draws should approach the posterior. Question When the conditional posteriors are not standard distributions, the typical approach is to use something like rejection sampling, slice sampling, Metropolis-Hastings or similar to conduct the sampling. Would it be reasonable instead to discretize the pdf via simple evaluation along a grid, normalize and draw from the resulting discrete distribution? I know grid-search is valid in simple problems for the full-posterior, but I've never seen it applied to the conditional posteriors as above. Optional Context You might wonder why on earth I would do this. I'm actually working on a Variational-Bayes problem and the code is very performance sensitive- so the purpose of the discretization is to compute the moments quickly. I phrased the above in terms of an MCMC since those techniques are much more widely known.
