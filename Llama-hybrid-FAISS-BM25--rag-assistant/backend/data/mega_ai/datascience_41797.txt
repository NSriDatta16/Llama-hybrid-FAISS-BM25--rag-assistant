[site]: datascience
[post_id]: 41797
[parent_id]: 
[tags]: 
Random state in machine learning models

I am confused about random_state parameter in some algorithms like AdaboostClasifier, DecisionTree and so on Here is an example from sklearn.model_selection import * from sklearn.ensemble import AdaBoostClassifier param_grid = { 'learning_rate':[0.001, 0.10, 0.1, 1], 'n_estimators':range(50, 400, 50) } abc = AdaBoostClassifier(random_state=123) # run grid search grid_abc=GridSearchCV(abc, param_grid, scoring = 'accuracy') grid_abc.fit(X_train, y_train) #The best hyper parameters set print("Best Hyper Parameters:\n",grid_abc.best_params_) print("training accuracy:\n",grid_abc.best_score_) prediction=grid_abc.best_estimator_.predict(X_test) #importing the metrics module from sklearn import metrics #evaluation(Accuracy) print("Accuracy:",metrics.accuracy_score(prediction,y_test)) #evaluation(Confusion Matrix) print("Confusion Matrix:\n",metrics.confusion_matrix(prediction,y_test)) print("\t\tclassification report") print("-" * 52) print(metrics.classification_report(prediction,y_test)) The accuracy results is 0.9420289855072463 But when i change the random_state value to 0 I got another accuracy results 0.8584070796460177 How can i fix the result and be sure of the final results.It is ricky by the way Do i have to set random_state value of the train_test split as the classifier or no?
