[site]: crossvalidated
[post_id]: 340205
[parent_id]: 
[tags]: 
How to detect fraudulent values in a data set?

First off, I don't know if this is the appropriate place to ask this question? If not, I apologize, and I'd appreciate any advice on where else to go with it. If it's ok, here's a description of my situation: I'm a research biologist, who mostly does data analysis--nothing fancy, just multivariate analysis and figure preparation for old ecologists who are afraid of computers. Most of my work is analysis of other people's data, so I have zero exposure to the data collection and no way to independently verify its legitimacy. I understand the biology behind the data though, and how it should interrelate. I have deep suspicions about a data set I'm working with, and don't want to be a coauthor on a fraudulent paper. But it's a sensitive situation, because I rely on grant funding which is connected to this work, and accusing folks could jeopardize that, so I don't really want to make a stink unless I have to. I also don't know much about investigating fraud in data sets, and I'm not even sure this data set is large enough for that kind of analysis (~200 trees, 40 attributes for each) Here are the particulars: I was handed a data set a few months ago, (measurements of various 'health metrics' for about 200 trees) and I couldn't find any interesting relationships in the data. The trees were also scored as Good, Average, or Poor (G, A, P) by a forester, using 'traditional' methodology, and these broad categories should have correlated, at least somewhat, with the other attributes that were measured. They didn't. I wrote this all up and gave it back to the ecologists. A couple weeks later I heard back from one of the researchers saying, "Oops, some of the trees were mislabeled, with the wrong numbers, but we cleared it up. I think it will make more sense now." So, red flag, right? But sure enough, now when I run simple correlations between those G, A, P health categories, there are significant relationships with these other metrics that the ecologists measured. However, when I look a level deeper, at the multivariate relationships among this data, there is no underlying structure. But there really should be. I know that there are certainly real world cases where what I'm seeing would be legitimate, but I have pretty strong a priori reasons for thinking this isn't one of them, based on my biology training. A tree that's in poor health should be poor in multiple attributes (same with a person, if you're sick, you'll have multiple symptoms and we'll be able to measure it in your temperature, your color, your biochemistry, your urine...). But, when I run PCA on multiple attributes (which all independently correlate significantly with the G, A, P categories) and color the biplot points according to G, A, P, there is no relationship at all, it's just noise. This doesn't make sense. These attributes should all be correlated naturally (autocorrelated?) because they are just different attributes of the same organism's physiology... This all suggests to me that somebody monkeyed with the data in an unsophisticated way, to get better results (maybe just randomly changed a few cells here and there to alter group means, or maybe they sorted by certain attributes and changed the tree #'s for the high and low ones...). Anyway, this all seems really fishy to me, but I'm not sure where to go from here? I'd appreciate any advice about how to test my doubts, or how to come up with a more concrete way of describing why the lack of structure in the data makes me suspicious. Thanks.
