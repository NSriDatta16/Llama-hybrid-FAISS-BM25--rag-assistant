[site]: datascience
[post_id]: 14371
[parent_id]: 13314
[tags]: 
Data : It depends on how distinguishable your classes are. Like cats vs dogs is quite easy, while disgust expression vs angry expression is quite hard. Epochs : Over-fit your model and do early stopping. To handle over-fitting, increase regularization or decrease the complexity of model by decreasing the number of hidden neurons / layers. See what's best for you given the time and performance. Learning rate : Start with the largest learning rate that allows the model to learn. From there, experiment by dividing that learning rate by 10 or 2, observe the results, see which learning rate allows your model to converge faster and leads to higher accuracy. There are still a lot of things to consider to achieve the maximum performance such as learning rate decay, gradient descent optimization algorithms, weight initializations, etc. More observations = more productivity. Be mindful of the time and speed in choosing the best hyperparameters. To know more, I suggest reading this by Michael Nielsen - Neural Networks and Deep Learning
