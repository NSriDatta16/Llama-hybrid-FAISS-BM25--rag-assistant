[site]: crossvalidated
[post_id]: 439052
[parent_id]: 439050
[tags]: 
You may be confused about the distinction between a random variable and a realization of a random variable. If $X_1, X_2, ..., X_n$ are the random variables representing the first, second, ..., $n$ th observations in a sample and $x_1, x_2, ..., x_n$ are their corresponding realizations (the actual numbers in your sample - once you observe it), then $\bar{X}$ is the random variable that is average of the random variables $X_1, ..., X_n$ and $\bar{x}$ is the actual sample mean (both the realization of $\bar{X}$ and the average of $x_1, ..., x_n$ ). $\bar{X}$ is not a number (you might think of it as a random outcome) but $\bar{x}$ is a number. It's important to keep these concepts distinct. If you want to figure out the properties/behavior of means of random samples you deal with the first sort of thing. If you want to talk about what happened in a particular sample, you need the second sort of thing. When you add $X_1$ and $X_2$ you are not computing the sum of their distributions. You are computing the distribution of their sum. In general such a calculation involves an integral on the joint distribution. If they're independent, as here, this simplifies to a convolution of their densities (pmfs for discrete variates). There are a variety of other ways to compute this though - you might use MGF s for example (where they exist in a neighborhood of 0), or characteristic funtions.
