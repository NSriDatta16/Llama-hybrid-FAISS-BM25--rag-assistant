[site]: crossvalidated
[post_id]: 576773
[parent_id]: 576767
[tags]: 
The max-features parameter dictates how many features would be randomly selected in order to find a split. This is done to avoid over-fitting. For more details look at the following answer: https://datascience.stackexchange.com/questions/41417/how-max-features-parameter-works-in-decisiontreeclassifier Not sure what strongest implies, many of the parameters are there to avoid over-fitting of the tree. Think about the case where for each leaf there is a single leaf. This implies that each observation is predicted its true value, making your loss 0, and indicating that the tree was over-fitted. Read more about bias-variance decomposition here . For your last question, yes, observations in the same leaf receive the same value (their average), unless a more exotic tree variant such as M5 (where a linear function is fitted at each leaf).
