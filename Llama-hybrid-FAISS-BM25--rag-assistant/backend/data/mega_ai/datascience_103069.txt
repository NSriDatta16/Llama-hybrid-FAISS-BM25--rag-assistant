[site]: datascience
[post_id]: 103069
[parent_id]: 103031
[tags]: 
A million observations of 20 features should be very manageable on a laptop, if a little slow. Cloud computing for very large datasets is staggeringly expensive and offers little or no benefit unless and until you have good parallelization in place. I would recommend keeping that option as your last resort. For the initial data exploration and experimentation, I suggest you sample your data. Spending a few minutes googling "data sampling" will save you a lot of time and effort later. Only when you are getting reasonable results with your samples should you consider apply your methods to the larger dataset. Also give some serious thought to dimensionality reduction, methods like PCA can be very helpful here. If you haven't already done so, a correlation analysis of your features might help you eliminate the less useful ones.
