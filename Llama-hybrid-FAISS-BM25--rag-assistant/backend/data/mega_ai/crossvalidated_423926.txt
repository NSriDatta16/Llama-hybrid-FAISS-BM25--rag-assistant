[site]: crossvalidated
[post_id]: 423926
[parent_id]: 
[tags]: 
Bayesian Data Analysis 2.7a

I'm self-studying Bayesian Data Analysis by Gelman et al. and I'm struggling to understand the solution to exercise 2.7a. The question: For the binomial likelihood, $y\sim Bin(n, \theta)$ , show that $p(\theta) \propto \theta^{-1}(1-\theta)^{-1}$ is the uniform prior distribution for the natural parameter of the exponential family. What I understand: Per the question -- the natural parameter = $\phi = log(\frac{\theta}{1-\theta})$ . So, $p_\phi(\phi)$ needs to be uniformly distributed. I need to show that setting $p_\theta(\theta) \propto \theta^{-1}(1-\theta)^{-1}$ results in a uniform distribution on $p_\phi$ . The solution per Gelman's website: $q(\theta)=|\frac{d}{d\theta}log(\frac{\theta}{1-\theta})|p(\frac{e^{\phi}}{1+e^{\phi}}) \propto \theta^{-1}(1-\theta)^{-1}$ and $\frac{e^{\phi}}{1+e^{\phi}} = \theta$ . Earlier in the text we're given that $p_v(v)=|J|p_u(f^{-1}(v))$ is how one transforms a continuous R.V. My reading of the above solution, transforming it to fit the formula above, we have $v = \phi, u = \theta$ , because $f^{-1}$ here is $\frac{e^\phi}{1 + e^\phi}$ , so the $p_u$ on the right takes values of $\theta$ . The derivative is equal to the proposed prior, so we get the term on the right of the solution if $p(\theta) = 1$ . But that doesn't answer the question, as I've understood it. Also, $q(\theta)$ on the left, takes $\theta$ as an argument, so we have two parts of this taking $\theta$ when it should be one on the right or the left. So the solution makes no sense to me. Is the answer as given on Gelman's website correct? Where am I misunderstanding what the answer is supposed to show?
