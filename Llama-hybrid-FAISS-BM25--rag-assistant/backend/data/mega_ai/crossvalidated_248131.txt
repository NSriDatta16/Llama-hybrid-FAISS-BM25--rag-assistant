[site]: crossvalidated
[post_id]: 248131
[parent_id]: 
[tags]: 
epsilon-greedy policy improvement?

I am learning reinforcement learning from David Silver's open course and Richard Sutton's book. While I enjoy the course and the book much, I am currently confused in $\epsilon$-greedy policy improvement. Both the book and the open course have a theorem saying that For any $\epsilon$-greedy policy $\pi$, the $\epsilon$-greedy policy $\pi'$ with respect to $q_\pi$ is an improvement, i.e., $v_{\pi'}(s)\ge v_{\pi}(s)$ which is proved by where the inequality holds because the $\max$ operation is greater than equal to an arbitrary weighted sum. (m is the number of actions.) However, the theorem does not make sense to me, because if $\epsilon\approx 1$, what the theorem implies is that an (almost) random policy would be better than the current one. When I was walking through the proof, I found that the weights should be nonnegative, i.e., $\pi(a|s)-\epsilon/m\ge 0$ indicating that $\epsilon$ is bounded by $\epsilon \le \min_a m \pi(a|s)$. Further, in determinsitic (e.g., greedy) policies, $\pi(a|s)=0$ for $a\ne\arg\max_a q_\pi(s,a)$. Then the theorem tells little. Could anyone verify my understanding or shed more light in the theorem?
