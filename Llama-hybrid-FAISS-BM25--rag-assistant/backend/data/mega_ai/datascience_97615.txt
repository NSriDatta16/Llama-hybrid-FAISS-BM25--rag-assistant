[site]: datascience
[post_id]: 97615
[parent_id]: 97613
[tags]: 
Size of the training set and test test should not be in similar size why ? because what ever the model your are testing it will fist applicable on the training set equal size of data will create noise. In the machine learning world, data scientists are often told to train a supervised model on a large training dataset and test it on a smaller amount of data. The reason why training dataset is always chosen larger than the test one is that somebody says that the larger the data used for training, the better the model learns. Larger test datasets ensure a more accurate calculation of model performance. Training on smaller datasets can be done by sampling techniques such as stratified sampling. It will speed up your training (because you use less data) and make your results more reliable.
