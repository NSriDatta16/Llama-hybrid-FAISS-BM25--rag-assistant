[site]: crossvalidated
[post_id]: 577832
[parent_id]: 
[tags]: 
Sampling from transition model in particle filter

I am reading the foundational paper about Bayesian bootstrap particle filter (Gordon, Salmond, Smith, 1993) and they are solving the following discrete time estimation problem: $x_k\in R^n$ , $$f_k:\mathbb{R}^n\times\mathbb{R}^m \rightarrow\mathbb{R}^n$$ is the transition function $$x_{k+1}=f_k(x_k,w_k)\,, \quad\text{where }\ w_k \in \mathbb{R}^m$$ is a zero mean white noise, $$y_k:\mathbb{R}^n\times\mathbb{R}^r \rightarrow\mathbb{R}^p$$ is the observation function $$y_k=h_k(x_k,v_k)\,, \quad y_k\in \mathbb{R}^p\,,\quad\text{where }\ v_k \in \mathbb{R}^p$$ is also a zero mean white noise and $D_k = \{y_i\}^{k}_{i=1}$ . The prediction step can be formulated recursively: $$p(x_k|D_{k-1})=\int p(x_k|x_{k-1})p(x_{k-1}|D_{k-1})$$ and if we assume that $$\hat{p}(x_{k-1}|D_{k-1}) = \sum^n_{i=1}{w_i\cdot \delta(x_{k-1}-x^i_{k-1})}$$ is represented by samples we can plugin into the equation above and get: $$\hat{p}(x_{k}|D_{k-1})=\int p(x_k|x_{k-1})\hat{p}(x_{k-1}|D_{k-1})=\sum^{n}_{i=1}{w_i}p(x_k|x^{i}_{k-1})$$ In order to sample from $\hat{p}(x_{k}|D_{k-1})$ we need to sample from a mixture and one way of doing it is to sample weights $w_i$ according to a multinomial distribution and then sample the motion model of $x_i$ that was chosen. However, in the bootstrap filter the authors propagate the particles $\{(w_i,x^i_{k-1})\}$ one by one and I don't understand why it is equivalent to sampling from $\hat{p}(x_{k}|D_{k-1})$ ?
