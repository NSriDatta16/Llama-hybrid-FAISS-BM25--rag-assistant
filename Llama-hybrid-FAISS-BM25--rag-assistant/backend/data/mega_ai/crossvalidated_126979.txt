[site]: crossvalidated
[post_id]: 126979
[parent_id]: 126976
[tags]: 
I'm not sure what the context of your data is, but you should beware of relying on $R^2$ for determining goodness of fit. As you add more explanatory variables to your model, $R^2$ can get inflated, making it look like you have a 'good fit', but really all your doing is lowering your total sum of squares(since the goal is to minimize sum of square residuals, which is a component of total sum of squares). You should check out Wikipedia's page on Coefficient of Determination and scroll down to "Inflation of $R^2$" and "Notes on Interpreting $R^2$". You could also perform statistical inference on the coefficients of your regression model to see if they are statistically significant. Methods like Decision Trees and SVM are used more or less for classification, but can also be used in regression as well. What is the data you are working with?
