[site]: datascience
[post_id]: 57364
[parent_id]: 
[tags]: 
Is hyperparameter tuning more affected by the input data, or by the task?

I'm working on optimizing the hyperparameters for several ML models (FFN, CNN, LSTM, BiLSTM, CNN-LSTM) at the moment, and running this alongside another experiment examining which word embeddings are best to use on the task of binary text classification. My question is: should I decide on which embeddings to use before I tune the hyperparameters, or can I decide on the best hyperparameters and then experiment with the embeddings? The task remains the same in both cases. In other words, is hyperparameter tuning more affected by the task (which is constant) or by the input data?
