[site]: crossvalidated
[post_id]: 643034
[parent_id]: 
[tags]: 
GLMER and p values when all outputs are 1: strange results?

I'm running a mixed effect logistic regression model (function glmer from the package lme4 ) in RStudio with two random intercepts ad three different predictors as fixed effects. All the indipendent variables are categorical. However, although the model does not show any convergence problem, there is something strange. One of the categorical predictors (Age) has three different layers (7, 8, 20). When the level of this categorical predictor is 20, all the values of the dependent variable are 1. I've compared contrasts, and while there is significant difference between 7 and 8, no difference appear between 7 and 20, 8 and 20 and 7+8 vs 20. This sounds strange, since when Age=7 there are both 0 and 1 outputs (due to the other predictors), as well as when Ahe=8. So, the difference between 7 and 20 and 8 and 20 or 7+8 vs 20 should be bigger than the one between 7 vs 8. Is there a command that I can add to my model to solve the problem? I'm just using the optimizer control = glmerControl(optimizer = "bobyqa") . I think this is a case of near-to perfect separation of data, since when one of the predictors assumes a specific level, the dependent variable is always 1. What are the possible solutions? I have read about Firth penalization, but I am not sure it can be applied to mixed models.
