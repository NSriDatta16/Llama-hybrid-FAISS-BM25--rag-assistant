[site]: crossvalidated
[post_id]: 492442
[parent_id]: 
[tags]: 
Accuracy of Volatility Forecast

I understand the basic concept of ARCH/GARCH models and the basic mathics behind it. That is, one models the "volatility" of a time series, i.e. the residuals of a time series describing model, which in turn allows the forecasting of volatility. However, how is the volatility forecast evaluated? In a conditional mean setting, one just compares the actual value with the forecasted value. In a conditional volatility setting, what is being compared? The difference between the aforementioned values and the forecasted residual? In this case, I can theoretically imagine a scenario in which the residual is always being forecasted correctly, in turn implying that the point forecast is always wrong (if the residual is greater zero). This can not be the correct evaluation method, as it is strongly dependent on how biased the point forecast is. But how do we correctly evaluate ARCH/GARCH forecasts?
