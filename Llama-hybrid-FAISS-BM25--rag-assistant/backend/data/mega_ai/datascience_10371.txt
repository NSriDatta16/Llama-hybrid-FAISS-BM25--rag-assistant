[site]: datascience
[post_id]: 10371
[parent_id]: 10369
[tags]: 
Since you didn't mention labels of any kind, I presume you are not doing supervised learning. Note, if you were, there would be no need to throw out features. You could use something like lasso regression to build a model that sparsely selects the influential features while fitting a predictive model. Unsupervised methods exist to reduce your feature set size but could potentially lose their original feature interpretability (if that's important to you), like PCA or auto encoders. But there are alternatives to these as well, so depends what you are looking for.
