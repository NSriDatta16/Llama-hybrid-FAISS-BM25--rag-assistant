[site]: crossvalidated
[post_id]: 602793
[parent_id]: 602783
[tags]: 
If we are to avoid trivialities related to outlying values, evidently crossing is an indication the regression model isn't correct. So, all you need is suitably poor goodness of fit along with a little leverage and not too many data points. For example, generate conditional distributions, some of whose quantiles vary nonlinearly with the explanatory variables, and fit linear models to the quantiles. Something like $Y\mid x \sim\mathcal{N}(0,\exp(x))$ ought to do the trick. Here is an example, zoomed at the right to show the details of the crossing regression lines. It was created by setting df = 1 at the beginning of the R code below, which generates 601 data points. The colors of the fitted lines start dark at low quantiles and graduate to lighter colors at higher quantiles. They are in the correct order for $x gt 2$ or so, but cross at lower values of $x.$ The crossings are severe: ultimately, near $x=0,$ the fitted $5^\text{th}$ percentile exceeds the fitted $95^\text{th}$ percentile! Even more complex regression models are subject to this problem. Here are the same data fitted with a natural spline with three degrees of freedom (using the code below unchanged). The nonlinearity is achieved through the strong variation of the conditional response variance, as suggested above. The points at the right are given greater leverage by sampling them disproportionately more often. This causes the trends at the right to overwhelm the fewer amounts of data at the left. These patterns are consistent with other datasets (comment out the set.seed call to see). In most cases the software does not issue a warning that the fit might not be unique. library(quantreg) # # Generate a dataset. # set.seed(17) n
