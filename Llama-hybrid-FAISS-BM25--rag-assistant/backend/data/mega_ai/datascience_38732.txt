[site]: datascience
[post_id]: 38732
[parent_id]: 38729
[tags]: 
You are right that $p(e)$ is the probability of the English sentence. Estimating the probability of a sentence is achieved by a language model . This kind of machine translation model is known as the noisy channel model . The noisy channel model says that given a french sentence $f$ , its best English translation is $$e^* = \arg\max_{e\in E} p(e)p(f|e)$$ In this equation the $p(e)$ is the language model. Back in the era of IBM models (which are built upon the noisy channel approach), it is usually an n-gram based language model, calculated as (assuming bigram) $$p(e_1e_2...e_n)=p(e_1| )p(e_2|e_1)p(e_3|e_2)...p( |e_n)$$ And $p(f|e)$ is the translation model where you need to use the EM algorithm to solve. Inside the EM algorithm you do not update the language model parameters, so yes, $p(e)$ and $p(f)$ don't affect the optimization problem .
