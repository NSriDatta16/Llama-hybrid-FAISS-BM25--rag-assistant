[site]: crossvalidated
[post_id]: 616013
[parent_id]: 
[tags]: 
Estimating sigma in Bayesian inference

I'm currently testing the Bayesian inference approach for a model given some data. However, I am running into the problem of estimating $\sigma$ (I am assuming a normal distribution of the data at each time step). I currently treat $\sigma$ in the same way as the other model parameters, i.e. I also estimate it using the MCMC algorithm. I set the prior for $\sigma$ to the uniform distribution. When I now run the MCMC algorithm, I notice that the derived samples of $\sigma$ are always very close to the upper bound, even when I set it urealistically high values. To test whether my model is working, I have also used a fitting approach, which gives really good results and a $\sigma=0.5$ , but my posterior distribution hovers around 10 when I set the uniform distribution to the interval $[0,10]$ and doesn't even come close to $0.5$ . Why does this happen and how can I fix it? My only idea at the moment is to simply infer $\sigma$ deterministically given the current set of parameters, but this seems out of flavour in a Bayesian inference approach. Maybe a better prior distribution? As a remider to other i just want to give a small update to what was the cause of my problem. When defining the log_likelihood function I forgot that when multiplying the normal distribution that in addition to getting the square sum of the distance to the mean the exponent you also need to change the normalisation part of the function where the $\sigma$ gets an additional exponent which is the multiplication. :/.
