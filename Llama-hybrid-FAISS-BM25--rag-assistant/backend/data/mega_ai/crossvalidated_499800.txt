[site]: crossvalidated
[post_id]: 499800
[parent_id]: 
[tags]: 
What is this "trick" for finding posterior distributions?

I am new to Bayesian statistics. I am trying to understand a certain passage in my course notes. Excerpt: Discussion: I don't understand much about the above excerpt. I think that the goal here is to compute something along the lines of $\pi(\theta | x) = \frac{f(x | \theta) \pi(\theta)}{f(x)}$ , where $f(x) = \int f(x | \theta) \pi(\theta)d\theta$ . We are trying to turn our model for the data and the parameter into a posterior distribution for the parameter given the data. I do not see what the trick is. What I see is that, for example, if $\theta | x \sim \text{Beta} (\alpha, \beta)$ , then $\pi (\theta | x) = \frac{\theta^{\alpha - 1}(1 - \theta)^{\beta - 1}}{\text{B}(\alpha, \beta)}$ , where the denominator is a constant (I think) so it follows that $\pi(\theta|x) \propto \theta^{\alpha - 1}(1 - \theta)^{\beta - 1}$ . I believe the same procedure works for the other two examples, in which you set up the equation for the known form of the density, strip out the constants, replace $=$ with $\propto$ , and Bob's your uncle. Or maybe the point is that if $\pi(\theta | x) = \frac{f(x | \theta) \pi(\theta)}{f(x)}$ where the denominator is a nasty integral, then it's simpler to write $\pi(\theta | x) \propto f(x | \theta) \pi(\theta)$ . So maybe the upshot is that we perform the multiplication $f(x | \theta) \pi(\theta)$ , see if it similar to a known distribution, and this gives us information about the type of distribution the posterior has. I think the subsequent example in the notes seems consistent with my expectations. (Sorry, these notes seem sloppily written.) I appreciate any help.
