[site]: crossvalidated
[post_id]: 468458
[parent_id]: 
[tags]: 
Data leakage in temporally overlapping train-test split

Question: In the sliding window train-test split strategy, will there be data leakage if, say, I train on a dataset $X_{t}$ to predict values $y_t$ that were collected after my test data $X_{t+1}$ ? Background: I'm trying to predict whether returns on investments for companies in a portfolio on a twelve month horizon will do better or worse than average (binary classification). I have 100,000 historical monthly observations of companies financial information (a hundred features like market cap, daily liquidity,...) taken at one month intervals, companies in each interval are not necessarily the same. I have tried splitting the data into train and test but they had different distributions and models were performing badly (~51%). So I did a sliding split, training on a given month $t$ and testing on the following one and had good results doing so (80%). But I was told by a more experienced statistician, that I should use test data collected after returns on month $t$ were known. Meaning the test set should be the data collected in month $t+13$ or later. But I don't see where the problem is since I don't have access to returns in my training data.
