[site]: crossvalidated
[post_id]: 130459
[parent_id]: 129210
[tags]: 
Just as unnormalized probabilities (likelihoods) can be compared but not turned into probabilities (without normalizing) â€” similarly, given log-likelihoods $\phi$ and $\psi$, you cannot calculate the KL divergence, but you can compare KL divergences. For example, if you were trying to select a predictive unnormalized distribution $p$ out of $p_1, p_2, \dotsc$, given an observed unnormalized distribution $q$. Then you would want to choose $\text{arg min}_i D(q; p_i)$. You can estimate this by sampling $x$s and taking a weighted average of $-\log p_i(x)$ weighted according $q(x)$. This requires no integration.
