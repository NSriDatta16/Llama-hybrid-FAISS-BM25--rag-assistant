[site]: stackoverflow
[post_id]: 4797338
[parent_id]: 4796996
[tags]: 
I think that what you are doing is a fair approach, with the possible exception that you might want to implement some sort of caching mechanism/threshold for recalculation if you are doing this often or on a lot of points. Calculating distances accurately involves non-Euclidean geometry and is computationally expensive. http://en.wikipedia.org/wiki/Haversine_formula Depending on where the points are located on the globe and whether or not precision is highly important, you can also fudge things by pretending to be working in a Euclidean space and leveraging the Pythagorean theorem. I have used this kind of scheme to create a gross filter over a large dataset and then resorted to more precise calculations on points that pass the filter.
