[site]: crossvalidated
[post_id]: 97435
[parent_id]: 93818
[tags]: 
I can deliver an answer to my question only empirically using a simulation. Using this two cross validation contributions mixed and logistic I could create some fake datasets and using the mixed logistic regression. With R and glmer from library(lme4) I used this formula: fit1 y is a dichotomous variable, x1 is continuous and j is random. First I built a balanced dataset d with the grouping variable j with 20 groups. Then I build two datasets from d with m groups which have only one observation. The simulations shows that the variance of j and the fixed coefficient b1 of x are very similar to the "true" values for all kind of datasets. This is due to "perfect" randomization. In reality there will be some bias. The limits of this answer: lacking of theoretical foundation (but intuitively it makes sense). The simulation could be improved if packed in a loop to get many estimates and comparing the average with the true values var(uj) and coefficient b1. Simulation: # -- Model # yj[i] = b*0 b1*xj[i] # b0 = g00 + u0j, u0j ~ N(0,1) # b1 = const # => zj[i] = g00 + u0j[i] + b1*xj[i] # -- Libraries library(lme4) library(sqldf) # -- Create balanced dataset d # Number of clusters (level 2) N
