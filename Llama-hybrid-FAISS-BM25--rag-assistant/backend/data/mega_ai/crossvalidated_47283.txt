[site]: crossvalidated
[post_id]: 47283
[parent_id]: 47233
[tags]: 
You need the loss function because it tells you how to penalize each misclassification. What you want to do is compute the expected Bayesian risk: $r(a, \pi) = \int_{\theta} L(\theta, a)\pi(\theta|x)d\theta$, where L() is the loss function and $\pi()$ is the posterior distribution. The loss function is indexed by the action, $a$, this is how you classify the data point, and $\theta$, the actual class of the object. This tells us what our expected penalty is for taking action $a$ when our posterior beliefs are $\pi$. For any data point, you want to assign the data to the class in which the risk is minimized. There are a few resources online that I've found pretty useful by searching for "optimal Bayesian classification" or "bayesian risk" (e.g. these course notes ).
