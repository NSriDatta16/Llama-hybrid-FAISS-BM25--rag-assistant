[site]: crossvalidated
[post_id]: 452209
[parent_id]: 
[tags]: 
Differences between Sampler, MonteCarlo, Metropolis-Hasting method, MCMC method and Fisher formalism

1) I make confusions about what we call a "sampler" . From what I understand, a sampler allows to generate a distribution of points that follows a known PDF (probability distribution function), doesn't it ? 2) On the other side, it exits Monte-Carlo method which allows for example to compute the number Pi by generating random values (x_i,y_i) and see if x_i^2+y_i^2 3) Moreover, I have used previously the Metropolis-Hasting in this simple form, i.e to generate a distribution of points with a known PDF. But I have also seen that we can use it to do estimation of parameters of a model : at which level can we distinguish the "Sampler" Metroplis-Hasting from "Estimation of parameters" method. 4) For example, there is also the acceptance method (called also Von Neumann method), very used in Nuclear physics, which generates also a distribution from a known PDF : can it be qualified also of "sampler" ? 5) Finally, the Markov chain coupled with Monte Carlo (MCMC) is a pure method to estimate the parameters of a model given the data: what is the respective role of Monte-Carlo and the Markov chain in this method. To summarize, I show you below the problematic in which I am: it is about Forecast in astrophysics. In this post, I am talking about "Inverse problem" in Physics, i.e, we don't predict the data from a very accurate theoretical model but I want to estimate the parameters of my theoretical model given the data I have from experiment or from simulated data (what's we call fake data). The using of Bayes theorem is very practical in this kind of approach since we have a relation of proportionality between the posterior (probability of parameters given the data) and the likelihood (product of PDF taken at data values given the parameters model). 6) Fisher formalism is very useful for estimation of the standard deviation compared to the fiducial values but we need to know these fiducial values before and second point, we have to assume that posterior distribution is always Gaussian, haven't we ? (or that likelihood is Gaussian, I don't remember ... if someone could indicate this assumption). So as you have seen, there are a lot of concept to integrate for me and I would like to convert this mess into ordered things. The most important : I would like to make the difference between a "sampler" and an estimator method. After, any remark is welcome to clarify my confusions. Any help is welcome, sorry for those who find all these questions boring. I think that I am going to start a bounty to clarify all these points.
