[site]: crossvalidated
[post_id]: 108675
[parent_id]: 108145
[tags]: 
I think there are some issues with the question as posted by @jeanrjc. I will address some of the issues and try to answer some of them, but I do not know the whole answer. First, the figure in the question does not seem to be what the OP said it is. It does not seem to be the proportion of A and B IN the Nth ranking (in the 20% ranking) but seems to be the number of As and Ba UP TO the Nth ranking. This will explain why at the end of the figure the proportions of As and Bs stabilizes around 50% - 50% of the ants that terminated up to the 100% ranking are A and 50% are B! Second point: the OP seems to be interested in performing both an exploratory analysis and a confirmatory analysis with the same data! For example, one can see that at 40% the differences between A and B seems to be at the highest, and so the p-value of any test would be at the lowest. One can make then a very high evidence statement that B ants are much more likely to arrive in the top 40% than A ants. What happened is that one looked at the data to find the maximal difference between A and B (the exploratory part) and then performed a test to verify that the difference was significant (the confirmatory part). Another example is the OPs statement: "but both are equally good at performing bad." - just select a region where there is the least difference between A and B, and then show that the differences are not significant in this region. This mixing of exploratory and confirmatory analysis ON THE SAME DATA makes me very uncomfortable (I dont know the name of the this "error" in statistics, but in machine learning it is sometimes called overfitting - the idea that one can select the best parameters/statements on a "test" set and expect that it will work as well on yet unknown data). If one must do both a exploratory and a confirmatory analysis, I would do it an different sets of races. Select a random set of races to find the "best statements" and test these statements on the remaining races. The third issue is that a hypothesis testing require a hypothesis to be tested. Isn't there statements that are meaning full to your problem that you can define before looking to the data? If you want to find out if A ants are faster than B ants, is not enough to test if A ants are significantly more likely to be among the top 50% than B ants? Maybe the OP does not have a single statement but wants to test 10 statements of the form: A ants are more likely then B ants to be among the top N%, for N=10, 20, 30..100 In this case there is the fourth problem: multiple comparisons. If you make 10 statements/tests, each with a 5% change of being wrong (95% confidence on your tests) then there is a 50% chance that one of your statements will be wrong ( well not exactly but close). Thus one must be careful on how many tests are being made and adjust the confidence level on each test appropriately. Please follow the tags: multiple-comparisons , pairwise-comparison or multiple-hypothesis in CV. The last issue is that if one decides to make multiple tests, these tests are not independent. For example, given that the difference between A and B are at the highest/most significant at the 40% according to the figure in the question, it is unlikely that the difference will not be significant at the 50%. In other words, given that you already know that B is more likely than A to be among the top 40%, I dont think the correct null hypothesis for the 50% is that they are both equally likely! But I dont know how to solve this problem.
