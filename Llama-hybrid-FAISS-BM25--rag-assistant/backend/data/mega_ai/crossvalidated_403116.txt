[site]: crossvalidated
[post_id]: 403116
[parent_id]: 273403
[tags]: 
It is difficult to say whether you are overfitting only looking at the ROCs for training and test. Even though it is true that the difference between the two is an estimate of the generalisation error, from a practical standpoint, you are overfitting when you reach that level of complexity that starts to deteriorate the out-of-sample performances of the model. Two useful tools to diagnose overfitting are learning curves and validation curves (see here for a quick introduction). As for the remedies: If possible, add more training data Perform feature selection Since you are using a Random Forest, increasing the number of estimators will decrease the variance of your model, hence mitigating overfitting. See online or this question for the meaning of the hyperparameters, and their effect on the bias/variance tradeoff As suggested by @Nesvold, A good practice is to have a simpler, high bias, baseline model (e.g. a Logistic Regression) to compare your results with
