[site]: datascience
[post_id]: 100605
[parent_id]: 
[tags]: 
RMSE vs R-squared

Question: Which is a better metric to compare different models RMSE or R-squared ? I searched a bit usually all the blogs say both metrics explain a different idea, R-squared is a measure of how much variance is explained by the model and RMSE is giving you hint on average error. My answer: I think RMSE can be used to compare training error and validation error basically telling if model over fits or not. This will also say how well can two models perform on unseen data but R-squared only says information about model fit it gives no information about how model will perform on unseen data. Hence RMSE is better than R-squared if you worry about how your model will perform to unseen or test data. Is my answer correct ? (Note: Please add any points if you know any scenario when R-squared is better than RMSE)
