[site]: datascience
[post_id]: 25619
[parent_id]: 
[tags]: 
Using ML to create unique descriptors?

I have a problem that doesn't seem to fall into a common machine learning category, and I was wondering if this still could potentially be solved with ML. Problem: I have two signals recorded from two sensors, and would like to determine whether they are correlated (i.e. record the same physical event) or not. The catch : I don't have access to the full signal time series of both sensors, but only one at a time - I can only exchange a small descriptor on the order of 32 bits to see if the signals match or not. Our current approach is to calculate a bunch of numerical signal features such as mean, derivative, zero-crossings, FFT etc. and see which ones provide the best correlation - but that seems to be a lot of guesswork and doesn't work very well in any case. So now I had the following idea: Start with a neural network which takes a fixed window out of the signal (+ possibly the FFT of that window) as an input, and produces a 32-bit output Pick two random correlated samples out of the pool of examples, and run the network twice , once with each sample (and its FFT) Take the difference between the two output values as error measure and perform backpropagation as usual Repeat from 2. until the difference for all examples is below a threshold Here are my questions: Does this approach seem feasible at all? As someone relatively new to machine learning, how would I implement this? I've had a look at Keras - would this be a suitable starting point? Thanks in advance, and best regards, Florian Addendum: I've found this somewhat related post ( Is it possible using tensorflow to create a neural network that maps a certain input to a certain output? ), but I don't think that this is the same problem, as I don't actually care what the output looks like, just that it is as unique as possible for each matching pair of samples.
