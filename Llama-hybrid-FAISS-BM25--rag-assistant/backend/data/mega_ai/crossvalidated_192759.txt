[site]: crossvalidated
[post_id]: 192759
[parent_id]: 192758
[tags]: 
For (a) I wound up using logistic regression to determine the weight coefficients. In real life, tree-based approaches might be more sensitive to the strengths of different predictors in different parts of the feature space, but I didn't impose that structure on the fake data. train_rows 0.9, this works well predict(fit_glm, newdata=dt[-train_rows], type='response')) I'm still a little stuck on (b). I found another question on relative importance in logistic regression suggesting caret 's varImp , which I believe (based on the docs and messing around) is using a performance measure like AUC rather than a parametric approach like using $|t|$ from the glm. library('caret'); varImp(fit_glm) This approach wasn't terribly useful for me without a cutoff value for "not useful." Clearly x_5 is less important, but it's not obviously useless. (And because it's a composite of multiple predictors, it might not stand out on a correlation matrix.) I also considered: drop1(fit_glm, test='Chisq') # Single term deletions # # Model: # y ~ x_1 + x_2 + x_3 + x_4 + x_5 # Df Deviance AIC LRT Pr(>Chi) # 93.35 105.35 # x_1 1 281.98 291.98 188.630 So I see that AIC goes down when dropping x_5 , and the p=0.4418 seems to indicate that the model without x_5 is not significantly different from the one with it. So I would be inclined to keep the first four predictors only. I'm just posting what I tried, but hoping the experts here can point out anything I overlooked.
