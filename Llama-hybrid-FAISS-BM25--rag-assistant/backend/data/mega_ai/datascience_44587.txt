[site]: datascience
[post_id]: 44587
[parent_id]: 38535
[tags]: 
You can refer to the following link XGBOOST is slower than Random Forest on the Xgboost Github. Its a weakness of GBT's in general when there are many classes. The reason is that gradient boosting requires that you train [number of iterations] * [number of classes] trees, whereas random forest only requires [number of iterations] trees.
