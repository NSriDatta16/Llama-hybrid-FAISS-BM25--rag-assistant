[site]: crossvalidated
[post_id]: 211247
[parent_id]: 211237
[tags]: 
Your conceptual misunderstanding may come from one of the few complaints I have about ISLR, its overemphasis on misclassification rates as a measure of model quality. If you look at page 158 of ISLR you will see that the authors propose the same solution as @BrentFerrier in another answer here, which is to use a cutoff of 0.5 in the predicted probability for the classification. Although I appreciate the simplicity of this measure from an early-stage pedagogical purpose, this measure has the implicit assumption that all types of classification errors are equally important, which is seldom true in practice. There are, however, much better possibilities for overall evaluation of logistic regression models than misclassification based on a cutoff of 0.5 probability. This page provides some entry into this area, and this page briefly compares 2 simple measures. For example, the Brier score is the mean-square difference between the predicted probabilities and the actual 0/1 outcomes. Measures of the calibration curve, as provided in the rms package in R, can be even better.
