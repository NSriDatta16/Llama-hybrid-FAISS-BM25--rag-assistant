[site]: crossvalidated
[post_id]: 438064
[parent_id]: 
[tags]: 
Why does gradient descent fail training a network for predicting times table?

I am training a feedforwardnet with gradient descent traingd as backpropagation algorithm to predict times table. X = [repmat([1:10]', 10, 1) repelem([1:10]', 10)]; y = X(:, 1) .* X(:, 2); net = feedforwardnet(8); % Create a neural network with 8 neurons in the hidden layer net.layers{1}.transferFcn = 'logsig'; % Hidden layer activation function set to logsig net.trainFcn = 'traingd'; % Set backpropagation algorithm to gradient descent net.divideParam.trainRatio = 0.6; net.divideParam.testRatio = 0.2; net.divideParam.valRatio = 0.2; [net, TR] = train(net, X', y'); % Train the network But when I try to train my network it directly fails, I mean validation error keeps increasing from the start as you can see below. I couldn't figure out the reason so I wanted to ask it here. When I train my network using Levenberg-Marquardt trainlm as backpropagation algorithm then everything works fine.
