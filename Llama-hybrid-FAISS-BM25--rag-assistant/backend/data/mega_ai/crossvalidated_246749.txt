[site]: crossvalidated
[post_id]: 246749
[parent_id]: 200254
[tags]: 
I think it would help if you would describe more what your actual goal is. In supervised learning , there is always a clear definition of error that quantifies how well $f(X)$ is an approximation of $y$. We can then use cross validation to obtain an estimate o the out-of-sample (or generalization) error of a model. This error we can use to do mode selection. In unsupervised learning , such as clustering, there is usually no clear definition of error. Due to this, also cross-validation cannot be used for this purpose. However, there are some methods that determine the quality of a clustering via its stability. Here, stability is assessed via cross-validation or bootstrap schemes, see e.g. Ben-Hur, Asa, Andre Elisseeff, and Isabelle Guyon. "A stability based method for discovering structure in clustered data." Pacific symposium on biocomputing. Vol. 7. 2001. Tibshirani, Robert, and Guenther Walther. "Cluster validation by prediction strength." Journal of Computational and Graphical Statistics 14.3 (2005): 511-528. Fang, Yixin, and Junhui Wang. "Selection of the number of clusters via the bootstrap method." Computational Statistics & Data Analysis 56.3 (2012): 468-477. or Haslbeck, J., & Wulff, D. U. (2016). Estimating the Number of Clusters via Normalized Cluster Instability. arXiv preprint arXiv:1608.07494. which contains a summary of these approaches.
