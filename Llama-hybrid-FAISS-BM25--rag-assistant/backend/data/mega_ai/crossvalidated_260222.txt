[site]: crossvalidated
[post_id]: 260222
[parent_id]: 
[tags]: 
Test for decreasing rate of performance during an experiment

I have $N=20$ participants and $K=500$ trials. For each trial, I have a binary $\text{yes}/\text{no}$ response. The response is either $\text{correct}$ or $\text{incorrect}$. The task is quite demanding. I have binned the data and drawn boxplots corresponding to different parts of the experiment. It seems the performance rates decrease as a function of trial number (time). What would be the ideal way to quantify this? I was first thinking to average the data for each trial, and do a linear regression between the mean performance rate and trial. However, would this not be the wrong thing to do since the data is serially correlated (decreasing performance rate)? The variance is also slightly increasing by trial number.
