[site]: crossvalidated
[post_id]: 240838
[parent_id]: 240823
[tags]: 
I'm no expert in identifiability, but I would say yes. Roughly speaking, you have more predictors than independent parameters. More precisely: it's unclear to me whether you are modeling a time series (because of the $_t$ suffix) or you are performing regression on a random sample (because you mention OLS). I'll go with the latter: I think the answer would be the same with the former, but I'm not sure. Assume $u_t$ is a Gaussian zero mean error term, uncorrelated with the vector $\mathbf{x_t}=(x_t, z_t)$. Then for $(\alpha_1,\beta_1)\neq(\alpha_2,\beta_2)$, the two models $y_t=\alpha_i+\beta_i x_t + \frac{z_t}{\beta_i}+u_t=\alpha_i+\beta_i x_t + \gamma_i z_t+u_t,\quad i=1,2$ correspond to different distributions for $y_t$. Thus in principle the model is identifiable. In practice, since it's a nonlinear model, of course you can't use OLS to estimate it. Also, if you use any NLS method, I think you'll run into trouble unless you can put a lower bound on the absolute value of $\beta$, i.e., unless your NLS estimation algorithm can handle the nonlinear constraint $|\hat{\beta}|>\epsilon$. Here I'm assuming you're not modeling a time series: if you are, then OLS wouldn't make sense even if the model were linear, since errors are now autocorrelated. For now, I don't know enough about time series models to help you out there.
