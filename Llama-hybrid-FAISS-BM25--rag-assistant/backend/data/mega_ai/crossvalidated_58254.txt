[site]: crossvalidated
[post_id]: 58254
[parent_id]: 
[tags]: 
Reducing the dimension of an embedding

Let $O \in \mathbb R^{p\times m}$ be a data matrix of observations. Suppose we are given a model $\mu : \mathbb R^n \rightarrow \mathbb R^m$ which is able to approximately fit the observations. Fix $l \begin{equation} \sum_{i=1}^p \left[\min_{y \in \mathbb R^l} \Vert \mu(\varepsilon(y)) - O_i\Vert ^2\right]\end{equation} Are there standard approaches (algorithms) to solve this problem? What if $\varepsilon$ is restricted to being linear?
