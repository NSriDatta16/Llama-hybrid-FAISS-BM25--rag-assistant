[site]: crossvalidated
[post_id]: 470021
[parent_id]: 470006
[tags]: 
The relevant scientific community would, or should , be partial to the interpretation provided in the post you referenced. The columns of your model matrix are not linearly independent. Suppose you have a 5-level categorical input and you want separate estimates for each level of that input. Software will invariably return estimates for all but one category, which serves as the “reference” category. Manually forcing the “reference” level onto the right-hand side of your equation with the remaining 4-levels will result in singularities. As a compromise, software often drops (omits) a category (variable) for you. One level must be omitted to serve as a reference, a choice which is often arbitrary. To put this in perspective, I encourage you to regress the referent on all remaining categories. Your model will be perfectly fit. In fact, once you feed the model the other four categories as inputs/regressors, then you can perfectly predict the referent. If your audience is the relevant scientific community or subject matters experts in your field, then you could simply state that a column (variable) was dropped due to collinearity concerns. Or, you could indicate that a column (variable) was dropped to avoid perfect multicollinearity. Redundant predictors are often dropped in practice, and most practitioners will know why you (or your software) did it. It is difficult to offer further guidance on scientific language without seeing your output, but this should help!
