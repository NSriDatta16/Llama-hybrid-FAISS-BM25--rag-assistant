[site]: crossvalidated
[post_id]: 584813
[parent_id]: 583778
[tags]: 
A bit of elaboration on Frank Harrell's answer (+1), in response to your addition to the question. Throwing away data via subsampling is not generally a good idea. You want to use as much information as you have available. Chapter 7 of Frank Harrell's course notes is devoted to such issues in longitudinal measurements, but now goes beyond the original focus of that chapter of his book on generalized least squares for continuous outcomes. For your second specific question, you can directly model autocorrelation where outcomes can change over a time series. You specify a function that combines time, prior outcome, and the time interval between measurements in a generalized linear model. Adapting an equation on page 7-39 of the current notes, where observation times $t$ are indexed by $i$ , you can write a first-order Markov generalized linear model (GLM) as: $$ g(Y(t_i)|X,Y(t_{i-1})) = \alpha + X\beta + f(Y(t_{i-1}), t_i, t_i - t_{i-1})$$ where $g()$ is the GLM link function, $Y$ is the outcome, $X$ is the set of covariates with coefficients $\beta$ to be estimated, $\alpha$ is an intercept, and the function $f()$ involves any number of regression coefficients for a main effect of $t$ , the main effect of time gap $t_i − t_{i−1}$ if this is not collinear with absolute time, a main effect of the previous state, and interactions between these. If you want higher-order correlations, include more prior outcome observations and intervening gap times. The illustration in the course notes is for a proportional odds ordinal logistic model; the principles apply in general. This post shows how this can be done for binary outcomes at irregular observation times. That also addresses part of the first specific question. Beyond that, the big problem with pseudoreplication is in estimating too narrow confidence intervals. One could argue that there's nothing wrong with giving a particular individual with more observations more weight, provided that you recognize those observations within the same individual aren't independent. The "cluster sandwich robust covariance matrix estimate" starts with a model that assumes "working independence" and estimates the coefficients themselves as if all observations were independent. The covariance matrix is then adjusted for the clusters (subjects in your case). Random effects in mixed models, another standard way to handle multiple observations on subjects, also puts more weight on those with more observations. Finally, unless you have tens of thousands of observations, your implied split into training and test sets is likely to lose precision in the training and lose power in the testing . Building the model on all the data and evaluating the modeling process by bootstrapping is superior. If you do have that many observations, simply splitting by subjects should be OK; you can check by doing repeated train/test splits.
