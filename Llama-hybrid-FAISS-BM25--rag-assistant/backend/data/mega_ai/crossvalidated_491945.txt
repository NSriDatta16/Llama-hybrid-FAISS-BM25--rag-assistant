[site]: crossvalidated
[post_id]: 491945
[parent_id]: 491940
[tags]: 
My understanding of the Gram matrix, is that it comes from a product $X^{T}X$ where $X$ is a $k\times n$ matrix of coordinates (assuming your points lie in k dimensions). In your case $n$ would be 4 since the distance matrix is $4\times 4$ (pairwise distances between four points). In order to find a/the Gram matrix, you first need to find the location of the 4 points (in your case $k=3$ since you have a tetrahedron) so that their pairwise distances give you the distance matrix you have. Edit: Since this is a tetrahedron with all unit distances, you can fairly easily compute locations of those vertices by hand. Otherwise, if you don't want to (or can't) do it by hand, then use Multidimensional Scaling . Note: PCA doesn't do this. Edit: To reproduce the eigenvalues demonstrated (computationally) you can do the following: from sklearn.manifold import MDS import numpy as np # Given distance matrix D = np.array( [ [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]] ) # n_components = 3 says your are finding points in 3 dimensions # dissimilarity = 'precomputed' alerts the algorithm that you are handing it a distance matrix embedding = MDS(n_components=3, dissimilarity='precomputed') # Fitting the distance matrix give you a list of points realizing the distances (note that this process is random and approximate). Xt = embedding.fit_transform( D ) #Xt is a 4x3 matrix (so it's X^T) # Get the transpose of that value (for computing X^T X) X = np.transpose( Xt ) # Compute the Gram Matrix Gram_Matrix = np.matmul( Xt, X ) # Check the eigenvalues print( np.linalg.eigvalsh( Gram_Matrix ) )
