[site]: crossvalidated
[post_id]: 400452
[parent_id]: 
[tags]: 
How to explain the utility of binomial logistic regression when the predictors are purely categorical

The resources that I have seen feature graphs such as the following This is fine if the predictor $x$ is continuous, but if the predictor is categorical and just has a few levels it's not clear to me how to justify the logistic model / curve. I have seen this post , this is not a question about whether or not binary logistic regression can be carried out using categorical predictors. What I'm interested in is how to explain the use of the logistic curve in this model, as there doesn't seem to be a clear way like there is for a continuous predictor. edit data data that has been used for this simulation library(vcd) set.seed(2019) n = 1000 y = rbinom(2*n, 1, 0.6) x = rbinom(2*n, 1, 0.6) crosstabulation > table(df) y x 0 1 0 293 523 1 461 723 > prop.table(table(df)) y x 0 1 0 0.1465 0.2615 1 0.2305 0.3615 mosaic plot Edit 2 This is an attempt to plot the logistic curve when there is on binary predictor. The straight line is a linear regression whereas the curve is that of the binomial logistic regression (messy) code for the above image : x_0 = rbinom(1000 , 1 , 0.8) x_1 = rbinom( 300 , 1 , 0.1) df $x, df$ y) abline(lm(y ~ x, df)) m $x, df$ y,ylab="probability",xlab="level (0 or 1)", main = "binary logistic regression with one binary predictor") curve(predict(m, data.frame(x = x), type = "resp"), add = TRUE, lwd=3 ) clip(0, 1.1, -100, 100) abline(lm(y ~ x, df), lty = 2, lwd = 2) clip(-1, 2, -100, 100) sz = 1.5 p1 = df[df $x == 0,]$ y df $p1y = mean(p1) df$ p1x = 0 points(df $p1y ~ df$ p1x, col="red", pch=19, cex = sz) p2 = df[df $x == 1,]$ y df $p2y = mean(p2) df$ p2x = 1 points(df $p2y ~ df$ p2x, col="red", pch=19, cex = sz)
