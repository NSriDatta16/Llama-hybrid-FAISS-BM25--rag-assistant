[site]: datascience
[post_id]: 19732
[parent_id]: 
[tags]: 
Explain output of logistic classifier

[Note : There is some serious problem with logic used to get the best banner. I got it late. Directly read the answer to get general info, or you can also try to the find the mistake.] Problem: Given a set of user features, select an ad with the highest probability to be clicked. Dataset - https://www.kaggle.com/c/avazu-ctr-prediction/data (First 100000 tuples from training set and split that it 80:20 training:testing) Tutorial followed - https://turi.com/learn/gallery/notebooks/click_through_rate_prediction_intro.html C14 is my ad id. Problem :- Given ('device_type', 'C1', 'C15') return ad id. Training:- I have taken 'click' as my target and ('device_type', 'C1', 'C15', 'C14') as my input features. I used logistic regression classifier in graphlab library to train the model. I am doing ad selection in the following way:- Given a set of features ('device_type', 'C1', 'C15', X) Iterate X over all possible values of C14 and pass the features to predictor to get the probability that X ad will be clicked. Return the ad with maximum click probability. MY PROBLEM IS LOGISTIC CLASSIFIER IS ONLY RETURNING ONE AD for every test tuple, though with different click probability, it means only one ad is getting the highest probability to be clicked. Can anyone explain this observation? When using boosted tree classifier instead of logistic classifier for the above prediction, I am able to get different ads as my prediction and hence getting better results.
