e Bill 1047, which would require that companies that develop advanced AI conduct safety tests and create liability for AI model developers if their models cause catastrophic harm and they did not take appropriate precautions." The options were "Support", "Oppose", and "Not Sure". Their poll results were 53.8–64.2% support in July, 60.1–69.9% support in early August, and 65.8–74.2% support in late August. On the other side of the aisle, the California Chamber of Commerce conducted its own poll, showing that 28% of respondents supported the bill, 46% opposed, and 26% were neutral. The framing of the question has however been described as "badly biased". The summary of the bill in their question was "Lawmakers in Sacramento have proposed a new state law—SB 1047—that would create a new California state regulatory agency to determine how AI models can be developed. This new law would require small startup companies to potentially pay tens of millions of dollars in fines if they don’t implement orders from state bureaucrats. Some say burdensome regulations like SB 1047 would potentially lead companies to move out of state or out of the country, taking investment and jobs away from California." A YouGov poll commissioned by the Economic Security Project, which co-sponsored the bill, found that 78% of registered voters across the United States supported SB 1047, and 80% thought that Governor Newsom should sign the bill. Their question was "The California legislature passed a bill recently to regulate artificial intelligence, or AI, and since so many AI companies are based there, it could have national impacts.The bill would require California companies developing the next generation of most powerful AI systems to test for safety risks before releasing them. If testing shows that the AI system could be used to cause catastrophic harm to society, such as disrupting the financial system, shutting down the power grid, or creating biological weapons, the company must add reasonable safeguards to prevent these risks. If the company fails to test or adopt reasonable safeguards, they could be held accountable by the Attorney General of California." A David Binder Research poll commissioned by the Center for AI Safety, a group focused on mitigating societal-scale risk and a sponsor of the bill, found that 77% of Californians support a proposal to require companies to test AI models for safety risks, and 86% consider it an important priority for California to develop AI safety regulations. Their question was "The proposal would require California companies developing the next generation of most powerful AI systems to test for safety risks before releasing them. If testing shows that the AI system could be used to cause catastrophic harm to society, such as disrupting the financial system, shutting down the power grid or creating biological weapons, the company must add reasonable safeguards to prevent these risks. If the company fails to test or adopt reasonable safeguards, they could be held accountable by the Attorney General of California." See also Artificial general intelligence Regulation of AI in the United States Regulation of artificial intelligence Notes References External links Bill tracker CalMatters Supporting website Economic Security California Action, Center for AI Safety Action Fund, and Encode AI Opposing website Andreessen Horowitz