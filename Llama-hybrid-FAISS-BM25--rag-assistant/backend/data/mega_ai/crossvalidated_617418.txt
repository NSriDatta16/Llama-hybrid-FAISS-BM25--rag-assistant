[site]: crossvalidated
[post_id]: 617418
[parent_id]: 616920
[tags]: 
As @whuber has pointed out, the expressions in your post are true for non-negative random variables, not in general. For a random variable $X$ with distribution function $G$ , one has in general $$E(X)=\int_0^\infty (1-G(x))\,\mathrm dx-\int_{-\infty}^0 G(x)\,\mathrm dx\,,$$ whenever the expectation exists. As for your question, if $X,Y$ have distribution functions $G,F$ respectively, and $(X,Y)$ has distribution function $H$ , then $$E|Y-X|=\int (F(x)+G(x)-2H(x,x))\,\mathrm dx \,, \tag{$\star$}$$ whenever the expectation exists. [An elegant proof of this result (no non-negativity assumption here) is shown in this Math.SE post .] In essence, this is based on the fact that \begin{align} |Y-X|&=(Y-X)\mathbf1_{\{Y\ge X\}}+(X-Y)\mathbf1_{\{Y Taking expectation on both sides, and using Fubini/Tonelli's theorem yields $(\star)$ . In particular, when $X$ and $Y$ are independent, we have $$E|Y-X| = \int F(x)(1-G(x))\,\mathrm dx + \int G(x)(1-F(x))\,\mathrm dx $$ And when $X$ and $Y$ are i.i.d, this is just $$E|Y-X|=2\int F(x)(1-F(x))\,\mathrm dx$$
