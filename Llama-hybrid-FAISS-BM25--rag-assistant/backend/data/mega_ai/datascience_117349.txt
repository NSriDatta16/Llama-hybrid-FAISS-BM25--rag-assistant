[site]: datascience
[post_id]: 117349
[parent_id]: 117009
[tags]: 
To use multiple multivariate time series with different lengths and timestamps as input to a Keras LSTM model, you can follow these steps: Pad the time series to the same length: You can pad each time series to the same length by adding zeros or a padding value at the end of the series. This will ensure that all the time series have the same shape and can be used as input to the LSTM model. import numpy as np import tensorflow as tf import tensorflow.keras as keras # Assume that `X` is a list of time series with shape (n_timestamps, n_features) # and `y` is a list of target series with shape (n_timestamps, 2) # Find the maximum length of the time series max_length = max([X[i].shape[0] for i in range(len(X))]) # Pad the time series to the same length X_padded = [] for i in range(len(X)): padded = np.pad(X[i], ((0, max_length - X[i].shape[0]), (0, 0)), 'constant') X_padded.append(padded) X_padded = np.array(X_padded) # Pad the target series to the same length y_padded = [] for i in range(len(y)): padded = np.pad(y[i], ((0, max_length - y[i].shape[0]), (0, 0)), 'constant') y_padded.append(padded) y_padded = np.array(y_padded) Create batches of short sequences: You can create batches of short sequences by dividing each time series into overlapping or non-overlapping subsequences of a fixed length. For example, if you have 200 time series with the longest one having 3000 timestamps and you want to create sequences of length 50, you can create 60 batches of (200, 50) shape by dividing each time series into overlapping subsequences of length 50. Alternatively, you can create 2950 batches of (200, 1) shape by dividing each time series into non-overlapping subsequences of length 1. # Create batches of short sequences by dividing each time series into overlapping subsequences of length 50 X_batches = [] y_batches = [] for i in range(0, max_length - 50 + 1, 50): X_batch = X_padded[:, i:i+50, :] y_batch = y_padded[:, i:i+50, :] X_batches.append(X_batch) y_batches.append(y_batch) X_batches = np.array(X_batches) y_batches = np.array(y_batches) # Alternatively, you can create non-overlapping subsequences of length 1 # X_batches = X_padded[:, :-1, :] # y_batches = y_padded[:, 1:, :] Define the model: You can define the model using the Keras functional API by specifying the input and output layers. You can also add a Masking layer to ignore padded values in the input sequences. # Define the model inputs = keras.layers.Input(shape=(50, n_features)) masked = keras.layers.Masking(mask_value=0)(inputs) lstm = keras.layers.LSTM(32)(masked) outputs = keras.layers.Dense(2)(lstm) model = keras.Model(inputs, outputs) Compile and fit the model: You can compile the model by specifying the loss function, optimizer, and metrics. You can then fit the model on the batches of short sequences using the fit function. # Compile and fit the model model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy']) model.fit(X_batches, y_batches, epochs=10, batch_size=32) Predict on new data: You can use the predict function to get the predictions on new data. For example, to predict on a new time series of shape (n_timestamps, n_features), you can pad the time series to the same length as the training data, divide it into batches of short sequences using the same method as in step 2, and then use the predict function to get the predictions on each batch. # Assume that `X_new` is a new time series of shape (n_timestamps, n_features) # Pad the time series to the same length as the training data X_new_padded = np.pad(X_new, ((0, max_length - X_new.shape[0]), (0, 0)), 'constant') # Create batches of short sequences X_new_batches = [] for i in range(0, max_length - 50 + 1, 50): X_new_batch = X_new_padded[:, i:i+50, :] X_new_batches.append(X_new_batch) X_new_batches = np.array(X_new_batches) # Predict on each batch predictions = [] for X_batch in X_new_batches: y_pred = model.predict(X_batch) predictions.append(y_pred) predictions = np.concatenate(predictions, axis=1) Hope this is useful.
