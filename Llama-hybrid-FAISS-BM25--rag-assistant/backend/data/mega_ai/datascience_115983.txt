[site]: datascience
[post_id]: 115983
[parent_id]: 115969
[tags]: 
I would argue that tree based models are not even Markovian per se, since those models are totally agnostic of time. Thus not even the formulation that from $x_t$ you predict $\hat{y_{t+1}}$ is misleading. Actually what you get using a tree is that from a vector $x$ you predict an output $y$ and this is it. Since this estimator is not constraint functionally (does not require some specific form for hypothesis) it is flexible enough to incorporate any kind of features, which is good. The drawback comes from the same liberty, you need to have plenty of data and that data to be relevant to your problem. Incorporating lagged features increase exponentially the need of training data, and that comes from the same flexibility of the model. And of course, since there is no structure, feature engineering gains much more importance in the process. If you would have used a model which has functional constrains, like ARIMA-like stuff you do not need exponentially more data since this is reduced by the assumed functional connection between variables. One the other hand, if the assumed structure does not hold for your problem, any amount of data is of no use. Regarding if it is not clear if the past contains enough information for the future this is an unsolved problem. Even when you use ARIMA like stuff, you don't test if the information is enough, but if the functional form of the model is of any use (like significance of fitted terms are statistically different from $0$ ). Since you limited your question to tree based model, I think you cannot do much more than be imaginative with your feature engineering (various combinations of features with products, transformations and so on) and adding more data are the only things I can imagine you can try.
