[site]: crossvalidated
[post_id]: 253865
[parent_id]: 253827
[tags]: 
LDA is a "bag of words" model , so a lot of the "structural" information you're talking about (e.g., the order of the words) is not pertinent to LDA. With respect to "correlations" between words, LDA does take into account co-occurrences of words within a particular document. For instance, if a document containing one word always contains another word, it's highly likely that LDA will assign both of those words to the same topic. See this answer for more details. Some people have tried to combine LDA with more sophisticated models that are not based on a bag of words. See, for instance, `lda2vec' , a technique that simultaneously learns word embeddings (as in word2vec), and topics (as in LDA). Another good reference is David Blei's review article . In particular, see the section where he discusses "relaxing the assumptions of LDA".
