[site]: datascience
[post_id]: 82201
[parent_id]: 
[tags]: 
Can machine learning models treat a vector as a whole feature to learn

We know a ML model naturally takes a feature vector with real valued elements as input and learn to predict. But can it treat a fixed-size vector as a whole feature to learn? For example, when using a 128-bit string as a feature, we can calculate the total number of different strings occurred in datasets and apply one-hot encoding to them. However, the dimension of the encoding can be very large（thousands）in this way. Or we can use binary to represent the 128-bit string, which only contributes to 128 dimensions. I don't know if the traditional ML models (not CNN) such as random forests are able to learn the dependence of the 128 features. Or is there any ways they can treat the 128 features as a whole?
