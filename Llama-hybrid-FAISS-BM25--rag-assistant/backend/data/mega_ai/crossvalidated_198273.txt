[site]: crossvalidated
[post_id]: 198273
[parent_id]: 
[tags]: 
A question about the choice and interpretation of the jumping distribution in Metropolis-Hastings algorithm

In order to implement the MH algorithm you need a proposal density or jumping distribution $q(⋅|⋅)$, from which it is easy to sample. If you want to sample from a distribution $f(⋅)$, the MH algorithm can be implemented as follows: Pick a initial random state $x_0$. Generate a candidate $x^*$ from $q(⋅|x_0)$. Calculate the ratio $\alpha=\frac{f(x^*)}{f(x_0)} \frac{q(x_0|x^*)}{q(x^*|x_0)}$. Accept $x^*$ as a realisation of f with probability min(1,α). Take $x^*$ as the new initial state and continue sampling until you get the desired sample size. $q$ is often symmetrical so $\frac{q(x^*|x_0)}{q(x_0|x^*)}=1$ I have two questions : Does $q$ describe the Birth-or-Death move that is often associated with Metropolis Hastings algorithm? When would you want to take $q$ non symmetrical? A colleague of mine wants to implement MH for sampling from a complex distribution (Y is a sample from X with a distribution $f$), and said he would impose different probabilities of picking $u$ in $X-Y$ to make the chain converge quicker (with Y the sample at a time and $\{Y-{v}\}\cup{\{u\}}$ the sample retained the next time if the ratio is big enough at step 3). Is it standard? The context in which I personally use MH algorithm is for Bayesian model averaging. In this context, I have some models $M_i$ with an a priori probability $\pi$, some data D and an a posteriori probability I want to sample from. So the ratio of the 3th step of the algorithm becomes $\frac{f(D|M_i)\pi(M_i)}{f(D|M_j) \pi(M_j)}$ (Bayes formula). Do you agree that $q$ in this case is still about the modification of $M_i$ between two iterations and the Bayesian context doesn't change anything about it? Shouldn't my colleague adopt a Bayesian approach and choose a a priori distribution on the observations to favour those he wants to select more often rather than changing the jumping distribution? Sorry for the naive questions, I want to be sure I understood the algorithm. EDIT : some of you say there is no link between MH and Birth-death moves, but here is what is explained in the vignette of the BMS package I use : "In addition to enumerating all models, BMS implements two MCMC samplers that differ in the way they propose candidate models: Birth-death sampler (bd): This is the standard model sampler used in most BMA routines. One of the K potential covariates is randomly chosen; if the chosen covariate forms already part of the current model Mi, then the candidate model Mj will have the same set of covariates as Mi but for the chosen variable ('dropping' a variable). If the chosen covariate is not contained in Mi, then the candidate model will contain all the variables from Mi plus the chosen covariate ('adding' a variable). Reversible-jump sampler (rev.jump): Adapted to BMA by Madigan and York (1995) this sampler either draws a candidate by the birth-death method with 50% probability. In the other case (chosen with 50% probability) a 'swap' is proposed, i.e. the candidate model Mj randomly drops one covariate with respect to Mi and randomly adds one chosen at random from the potential covariates that were not included in model Mi. Enumeration (enum): Up to fourteen covariates, complete enumeration of all models is the default option: This means that instead of an approximation by means of the aforementioned MCMC sampling schemes all possible models are evaluated. As enumeration becomes quite time-consuming or infeasible for many variables, the default option is mcmc="bd" in case of K > 14, though enumeration can still be invoked with the command mcmc="enumerate" ." I just want to know if there is a link between the sampling option and $q$.
