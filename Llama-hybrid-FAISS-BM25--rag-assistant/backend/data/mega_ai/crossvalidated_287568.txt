[site]: crossvalidated
[post_id]: 287568
[parent_id]: 287557
[tags]: 
Outliers are rather tricky beasts that appear and disappear in our experiments. Let's consider the facts: we are analyzing a population of "occurrences" by running an experiment and taking samples from said population. We have chosen a certain set of variables as part of the design of said experiment. While running some of the sets of captures, some of the individuals of some samples present what seems like outlier values. Is it the result of a measurement error? Is it the result of a error in the process of data capture, data registration, or data transcription? Is it that we are using the wrong set of variables? Is it that the samples are too small, or the data captures are not evenly spaced in time, or maybe some other factor not properly considered by the design of the experiment? The point is, there could be a few open fronts in the design of said experiment. To figure out outliers, we need to consider a set of strategies based on different approaches to analyze them, and then produce a hierarchy of results to determine if any given individual is really an outlier or is not. In these strategies based on different approaches, we should always include cluster analysis, to validate how individuals are grouped (are groups changing over time?), and discriminant analysis, PCA and Factor Analysis to check to which group or groups belong each and every given individual of a sample, but we should always strive to keep our options open and flexible. Do we really understand the main forces that drive the behaviour of the occurrences that we are capturing? Is the design of the experiment giving us the proper insights into these forces and how they drive and control the behaviour of the occurrences?
