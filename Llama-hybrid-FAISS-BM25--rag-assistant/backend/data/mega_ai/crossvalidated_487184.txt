[site]: crossvalidated
[post_id]: 487184
[parent_id]: 
[tags]: 
Do the selected hyperparameters from the inner loop of a nested k-fold cross validation still induce bias?

I think the nested k-fold cross validation does not really provide an unbiased estimate of performance. If I understand correctly, in the image below, we will first perform a 10-fold cross validation with each training dataset on the right (inner loop), performing hyperparameter tuning. I believe that the result is biased if we pick the best model from the inner loop by averaging the performance over the different inner loop training set K-folds (all the orange/red rows on the right) and then retraining and test on the outer loop test set. I think that is because each yellow box on the each row on the left (outer loop) might not be part of the corresponding row on the right (inner loop), but it has essentially been used for hyperparameter tuning by calculating the K-fold CV score of the inner loop for the rest of the datasets. For example, the test data (yellow box) of the first row in the outer loop has been used as training data by being incorporated in all the other training sets in the inner loop (2nd, 3rd, 4th, 5th). Is my logic flawed or have I misunderstood how nested cross validation works?
