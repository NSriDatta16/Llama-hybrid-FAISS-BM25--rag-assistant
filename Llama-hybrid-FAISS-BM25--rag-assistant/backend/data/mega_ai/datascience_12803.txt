[site]: datascience
[post_id]: 12803
[parent_id]: 12751
[tags]: 
I recently did a lot of reading and code writing on LSTMs so I'll try to pitch in and answer the question, though I'm not yet familiar with Theano Keras or deeplearning4j. From a quick scour of the Internet it seems that the meaning of batch_size is program-dependent, so it might be a good idea to check the online Help files. From what I gather though, it can refer to a couple of different things: 1) the count of cases fed into the training algorithm for processing before the next examination of inputs and/or outputs. 2) the number of iterations of the training algorithm over the last set of input before the next examination of inputs and/or outputs. 3) the size of sequences fed to the LSTM algorithms. With that in mind it seems almost certain that Theano and deeplearning4j are referring to #1 and/or #2, given the following links. On the other hand, I've run across journal articles recently, where batch size referred to sequence size, so watch out for a potential mismatch between the software and academic terminology: ☻ This post at CrossValidated indicates that in deeplearning4j and Keras the batch_size should be set to 1 for online learning. So in other words, batch_size controls the number of training cycles before the next input/output check. ☻ In Keras, the batch_size apparently sets the number of training cycles to execute or # of cases to train on before checking the inputs and/or outputs again, according to this Github page . ☻ This Github package also seems to use a different variable to denote sequence length. ☻ From Tony Kanh's answer at this StackOverflow page , in TensorFlow the batch_size determines the size of the output vector. This is probably identical to the number of items processed in each training cycles, since multiplying it by the num_steps and size (probably the sequence size?) determines the dimensions of the output. ☻ For closely related neural nets like Bidirectionals, the batch size is apparently equivalent to the sequence size, not the number of cases fed into the training algorithm. See p. 5, Berglund, et al., "Bidirectional Recurrent Neural Networks as Generative Models," available at the Cornell University Library website without a paywall . As I said I haven't used Theano and deeplearning4j yet, but I hope that at least provides a starting point to find the correct answer.
