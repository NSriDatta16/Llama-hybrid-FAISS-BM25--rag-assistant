[site]: datascience
[post_id]: 92478
[parent_id]: 
[tags]: 
Improve Convolutional Autoencoder

I just built a Convolutional Autoencoder to try to reconstruct a time series with shape (4000, 10, 30) . This is the code, I used a batch size of 32, but I think it is overfitting since it performs well on the training set but starts not reconstruction well in the validation and test set. What are the steps I can do to improve it? How can I define the right number of filters for each layer? kernel_size = 7 stride = 1 model = Sequential() model.add(Conv1D(filters=128, kernel_size=kernel_size, activation='relu', padding="same", strides=stride, input_shape=(TIME_STEPS, n_features))) model.add(Conv1D(filters=64, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(Conv1D(filters=32, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(MaxPooling1D(pool_size=2)) model.add(Conv1D(filters=16, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(Conv1DTranspose(filters=16, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(UpSampling1D(size=2)) model.add(Conv1DTranspose(filters=32, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(Conv1DTranspose(filters=64, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(Conv1DTranspose(filters=128, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(Conv1DTranspose(filters=n_features, kernel_size=kernel_size, padding="same")) This is the optimizer: optimizer = tf.keras.optimizers.Adam(learning_rate=1e-04) model.compile(optimizer=optimizer, loss="mse", metrics=[tf.metrics.MeanAbsoluteError(), 'accuracy']) EDIT: Dropout version: model = Sequential() model.add(Conv1D(filters=20, kernel_size=kernel_size, activation='relu', padding="same", strides=stride, input_shape=(TIME_STEPS, n_features))) model.add(Dropout(0.2)) model.add(Conv1D(filters=15, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(MaxPooling1D(pool_size=2)) model.add(Conv1D(filters=10, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(Conv1DTranspose(filters=10, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(UpSampling1D(size=2)) model.add(Conv1DTranspose(filters=15, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(Dropout(0.2)) model.add(Conv1DTranspose(filters=20, kernel_size=kernel_size, activation='relu', padding="same", strides=stride)) model.add(Conv1DTranspose(filters=n_features, kernel_size=kernel_size, padding="same"))
