[site]: crossvalidated
[post_id]: 30409
[parent_id]: 30406
[tags]: 
Given your five categorical predictors with let's say 20 outcomes each, then the solution with a different prediction for each configuration of predictors needs $20^5$ parameters. Each of those parameters needs many training examples in order to be learned well. Do you have at least ten million training examples spread over all configurations? If so, go ahead and do it that way. If you have less data, you want to learn fewer parameters. You can reduce the number of parameters by assuming, for example, that configurations of individual predictors have consistent effects on the response variable. If you believe that your predictors are independent of each other, then logistic regression is the unique algorithm that does the right thing. (Even if they're not independent, it can still do fairly well.) In summary, logistic regression makes an assumption about independent influence of predictors, which reduces the number of model parameters, and yields a model that's easy to learn.
