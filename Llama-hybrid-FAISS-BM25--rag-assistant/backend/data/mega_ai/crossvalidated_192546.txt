[site]: crossvalidated
[post_id]: 192546
[parent_id]: 31249
[tags]: 
Ideally, once you have more training examples you’ll have lower test-error (variance of the model decrease, meaning we are less overfitting), but theoretically, more data doesn’t always mean you will have more accurate model since high bias models will not benefit from more training examples . See here: In Machine Learning, What is Better: More Data or better Algorithms High-variance – a model that represent training set well, but at risk of overfitting to noisy or unrepresentative training data. High bias – a simpler model that doesn’t tend to overfit, but may underfit training data, failing to capture important regularities.
