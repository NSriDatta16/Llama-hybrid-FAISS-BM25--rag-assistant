[site]: crossvalidated
[post_id]: 7554
[parent_id]: 
[tags]: 
How to express error as a percentage?

I have data about how many unique users do a certain thing for each day of a month. I can average it, and i would like to display the variation in a intuitive format (such as % of something). Is there a standard way of doing this? I've found standard error, which is $\frac{\sigma}{\sqrt{n}}$, which is not particularly intuitive for users of the data. If anyone needs clarifications, please ask. I'm not too clear about this myself. EDIT: in response to the answers, it's for building out a analytics dashboard for use by the entire company (so many people probably don't understand standard deviation). In particular, we are doing A/B testing for various metrics over a period of say 1 month. We basically would average all the metric per day to give a number for that period, but there are variations day-to-day and would like to have some good way of expressing that.
