[site]: datascience
[post_id]: 32122
[parent_id]: 32109
[tags]: 
In case of zero mean, that is because some machine learning models do not include bias term in their representation so we have to move data around origin before feeding it to the algorithm to conpensate for lack of bias term. In case of unit variance, that is because lots of machine learning algorithms use some kind of distance (e.g. Euclidean) to decide or predict. If a particular feature has broad values (i.e. large variance), the distance will be highly affected by that feature and the effect of other features will be ignored. By the way, some optimization algorithms (including gradient descent) have better performance when data is standardized.
