[site]: crossvalidated
[post_id]: 608433
[parent_id]: 
[tags]: 
Estimating a trickily defined nonlinear function (e.g., via neural networks)

I have numerical vectors $y$ , $a$ , $x$ , each with length $N\approx 10^6$ , representing data from an experiment. Mechanistically, $y$ is related to $a$ and $x$ in the following way ( $i\in \{1,\ldots,N\}$ ): $$ y_i \sim \sum_{j=1}^N \big( a_i\cdot f(x_i,x_j) - a_j\cdot f(x_j,x_i) \big) $$ with some nonlinear differentiable function $f: \mathbb{R}^2 \to \mathbb{R}$ , which I have no other a priori information about. I need to estimate the function $f$ that provides the best fit, i.e. that minimises the error $\sum_{i=1}^N \Big( y_i - \sum_{j=1}^N \big( a_i\cdot f(x_i,x_j) - a_j\cdot f(x_j,x_i) \big) \Big)^2 $ . My idea is to represent $f$ by a neural network (2 input notes, a few hidden nodes, 1 output node). I would initialise a random set of weights and biases, compute the error, and try to iteratively converge to the optimal weights and biases. Before I dive into this, I wanted to ask if anyone can see an easier way to estimate $f$ by using existing packages (Python/R), rather than me having to implement a custum backpropagation and gradient descend algorithm from scratch. I am also completely open to approaches other than NNs. //edit: I asked ChatGPT to adapt the Adam gradient descend approach that I usually use in skilearn to my specific problem, using the above error $\sum_{i=1}^N (y_i - \ldots)^2$ for the loss function - this solved my problem.
