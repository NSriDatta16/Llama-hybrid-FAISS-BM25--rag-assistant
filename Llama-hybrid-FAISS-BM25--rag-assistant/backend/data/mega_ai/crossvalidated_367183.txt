[site]: crossvalidated
[post_id]: 367183
[parent_id]: 367117
[tags]: 
One roundabout way to get the unadjusted p-values for all the pairwise comparisons would be to fit the model several times. Each time you fit the model, you set the reference level of Treatment to something else. Something like this: d$Treatment First model fit: d$Treatment The summary output for the first model fit will give you the unadjusted p-values for the treatment comparisons AY vs AX, BX vs AX, BY vs AX. Second model fit: d$Treatment The summary output for the second model fit will give you the unadjusted p-values for the treatment comparisons BX vs AY and BY vs AY. Third model fit: d$Treatment The summary output for the third model fit will give you the unadjusted p-values for the treatment comparison BY vs BX. Once you have the 6 unadjusted p-values produced by the above, you can store them into a vector p: p (Note that I made up the above p-values for illustration purposes - you would have to insert the actual p-values derived from your data in the above code line.) Finally, you can use the p.adjust() command to get the BH-adjusted p-values from the unadjusted ones: p.adjust(p, "BH") As for your descriptive paragraph, you can make it more informative by adding further details: A linear mixed effects model was used to relate the continuous outcome variable Length to the categorical explanatory variable Treatment, with the latter variable having the categories AX, AY, BX and BY; The model included a random (intercept) effect for the grouping variable Experiment; The model was fitted to the data by REML (or ML); Post-hoc pairwise comparisons of the 4 levels of the explanatory Treatment variable with respect to mean Length were performed (for the typical experiment) after fitting the model to the data and Benjamini-Hochberg adjusted p-values were reported for the 6 resulting comparisons; The post-hoc pairwise comparisons found no statistically significant differences between treatments with respect to mean Length for the typical experiment; their results are visualized in Figure 1. Something specific along the lines suggested here is more informative for the reader than a vague paragraph which asks the reader to do all the heavy lifting and fill in the missing information. You can add something on the fact that you use BH to control for the false-discovery rate or something to that effect. As for the letter system to be used in your Figure 1, as long as you explain in the figure legend what that system is, readers should be able to make sense of it.
