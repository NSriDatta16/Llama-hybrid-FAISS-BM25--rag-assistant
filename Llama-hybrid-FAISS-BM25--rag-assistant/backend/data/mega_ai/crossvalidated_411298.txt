[site]: crossvalidated
[post_id]: 411298
[parent_id]: 410849
[tags]: 
My Question Is: I'm confused why a single component solution is working equally well compared to 3 component solution for my simulated data below- as I think i've simulated 3 independent components explaining variance in Y, and a 4th component which is independent of Y. Your simulation has only one data generating process built into $FactorY$ : FactorY=Factor1_score*1+Factor2_score*.3+Factor3_score*.8+rnorm(N,sd=.6) This means there is only one latent process (typically describe as a latent factor, but this would confuse the use of $Factor$ in your question) for $FactorY$ expected, only one expected combination of the $Factor$ #s that correlates with $FactorY$ . Adding random noise does not create any additional significant predictors of $FactorY$ . Try creating a new $FactorY$ Compare what happens with something like: FactorY=Factor1_score*1+Factor2_score*.3+Factor3_score*.8+rnorm(N,sd=.6) + Factor1_score*0.1+Factor2_score*1+Factor3_score*.3+rnorm(N,sd=.4) + Factor1_score*0.3+Factor2_score*.4+Factor3_score*1+rnorm(N,sd=.9) This will give multiple components that are then weighted and combined to give the final regression coefficients. If you want to play around some more to get deeper understanding try simulating orthogonal or independent data generating processes and see how the components compare to the defined data generating process. As a reference about multiple underlying contributors to PLS see Henseler which specifically examines the single data generating process (called factor in the paper, so be sure to interpret the meaning of factor differently to your question) vs multiple process scenario for PLS. Why does PLS behave differently to PCA? Doing a principle component regression as expected does find that you need 3-4 components to best explain variance in the outcome, though i know this is not the same as PLS Because PLS reduces the data to balance least squares error in X and Y, while PCA only reduces X. Since the $Factor\#$ s are independently created, PCA sees them that way. However, PLS has access to information PCA does not have, $FactorY$ so now PLS can find a connection that PCA could not find. PLS is much more efficient at reducing data to optimise information from in dependent variable than PCA, especially when plenty of noise is present. For a presentation comparing PCA with PCR and PLS showing how the data reduction differs see here Explicit answer to the question When does partial least squares provide >1 component solutions? PLS provides >1 component solutions when there are more than 1 data generating processes for $FactorY$ that provide a signal greater than the noise. Terminology Note: Some confusion may be coming from the use of the word 'factor' by in the question. Based on my original reading of the question the word appeared to be referring to 'independent variable'. In multivariate analysis 'factor' is often reserved for use in reference to uniquely identifiable linear combinations of independent variables such as in factor analysis or when referring to latent factors. Upon re-reading I can see that maybe the OP's intention was to use factor in the multivariate sense and was simply jumping ahead and directly simulating the factor scores rather than the underlying independent variables. If this is the case then the number of factors included in the PLS is the number of factors given a weighting in the regression coefficients. This is not an acceptable way to compare PLS and PCR as each technique reduces the data differently so PLS factors are not the same as PCA factors. To compare the two you need to go back to simulating the original data.
