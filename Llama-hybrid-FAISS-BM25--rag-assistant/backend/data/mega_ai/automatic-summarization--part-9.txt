ear in both the reference summary and the automatic summary out of all unigrams in the reference summary. If there are multiple reference summaries, their scores are averaged. A high level of overlap should indicate a high degree of shared concepts between the two summaries. ROUGE cannot determine if the result is coherent, that is if sentences flow together in a sensibly. High-order n-gram ROUGE measures help to some degree. Another unsolved problem is Anaphor resolution. Similarly, for image summarization, Tschiatschek et al., developed a Visual-ROUGE score which judges the performance of algorithms for image summarization. Domain-specific versus domain-independent summarization Domain-independent summarization techniques apply sets of general features to identify information-rich text segments. Recent research focuses on domain-specific summarization using knowledge specific to the text's domain, such as medical knowledge and ontologies for summarizing medical texts. Qualitative The main drawback of the evaluation systems so far is that we need a reference summary (for some methods, more than one), to compare automatic summaries with models. This is a hard and expensive task. Much effort has to be made to create corpora of texts and their corresponding summaries. Furthermore, some methods require manual annotation of the summaries (e.g. SCU in the Pyramid Method). Moreover, they all perform a quantitative evaluation with regard to different similarity metrics. History The first publication in the area dates back to 1957 (Hans Peter Luhn), starting with a statistical technique. Research increased significantly in 2015. Term frequency–inverse document frequency had been used by 2016. Pattern-based summarization was the most powerful option for multi-document summarization found by 2016. In the following year it was surpassed by latent semantic analysis (LSA) combined with non-negative matrix factorization (NMF). Although they did not replace other approaches and are often combined with them, by 2019 machine learning methods dominated the extractive summarization of single documents, which was considered to be nearing maturity. By 2020, the field was still very active and research is shifting towards abstractive summation and real-time summarization. Recent approaches Recently the rise of transformer models replacing more traditional RNN (LSTM) have provided a flexibility in the mapping of text sequences to text sequences of a different type, which is well suited to automatic summarization. This includes models such as T5 and Pegasus. See also Sentence extraction Text mining Multi-document summarization References Works cited Potthast, Martin; Hagen, Matthias; Stein, Benno (2016). Author Obfuscation: Attacking the State of the Art in Authorship Verification (PDF). Conference and Labs of the Evaluation Forum. Further reading Hercules, Dalianis (2003). Porting and evaluation of automatic summarization. Roxana, Angheluta (2002). The Use of Topic Segmentation for Automatic Summarization. Anne, Buist (2004). Automatic Summarization of Meeting Data: A Feasibility Study (PDF). Archived from the original (PDF) on 2021-01-23. Retrieved 2020-07-19. Annie, Louis (2009). Performance Confidence Estimation for Automatic Summarization. Elena, Lloret and Manuel, Palomar (2009). Challenging Issues of Automatic Summarization: Relevance Detection and Quality-based Evaluation. Archived from the original on 2018-10-03. Retrieved 2018-10-03.{{cite book}}: CS1 maint: multiple names: authors list (link) Andrew, Goldberg (2007). Automatic Summarization. Alrehamy, Hassan (2018). "SemCluster: Unsupervised Automatic Keyphrase Extraction Using Affinity Propagation". Advances in Computational Intelligence Systems. Advances in Intelligent Systems and Computing. Vol. 650. pp. 222–235. doi:10.1007/978-3-319-66939-7_19. ISBN 978-3-319-66938-0. Endres-Niggemeyer, Brigitte (1998). Summarizing Information. Springer. ISBN 978-3-540-63735-6. Marcu, Daniel (2000). T