[site]: crossvalidated
[post_id]: 388868
[parent_id]: 388859
[tags]: 
There are a number of ways to do it. Most of these have already been covered in a number of posts over StackOverflow, Quora and other content websites. To summarize, most of the techniques listed can be grouped into two classes of solutions, namely, Transformations Inherent Network Property In transformations, one can look up techniques such as Resize , which is the simplest of all the techniques mentioned Crop , which can be done as a sliding window or one-time crop with information loss One can also look into networks that have inherent property to be immune to the size of the input by the virtue of layer behaviour which builds up the network. Examples of this can be found in terms of, Fully convolutional networks (FCN) , which have no limitations on the input size at all because once the kernel and step sizes are described, the convolution at each layer can generate appropriate dimension outputs according to the corresponding inputs. Spatial Pyramid Pooling (SPP) , FCNs do not have a fully connected dense layer and hence are agnostic to the image size, but say if one wanted to use dense layer without considering input transformations, then there is a interesting paper that explains the layer in a deep learning network. References: https://www.quora.com/How-are-variably-shaped-and-sized-images-given-inputs-to-convoluted-neural-networks https://ai.stackexchange.com/questions/2008/how-can-neural-networks-deal-with-varying-input-sizes https://discuss.pytorch.org/t/how-to-create-convnet-for-variable-size-input-dimension-images/1906 P.S. I might have missed citing a few techniques. Not claiming this to be an exhaustive list.
