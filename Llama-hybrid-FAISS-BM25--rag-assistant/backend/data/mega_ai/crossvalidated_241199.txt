[site]: crossvalidated
[post_id]: 241199
[parent_id]: 
[tags]: 
Bonferroni Correction & machine learning

In psychology studies I learned that we should use the Bonferroni method to adjust the significance level when testing several hypothesis on a single dataset. Currently I am working with machine learning methods such as Support Vector Machines or Random Forest for classification. Here I have a single dataset which is used in crossvalidation to find the best parameters (such as kernel parameters for SVM) yielding the best accuracy. My intuition says (and maybe is completely off) that it is a similiar issue. If I am testing too many possible parameter combinations, the chance is high that I find one which yields great results. Yet this could be just chance. To sum up my question: In machine learning we use crossvalidation for finding the right parameters of a classifier. The more parameter combinations we use, the higher the chance to find a great one by accident (overfitting?). Does the concept that is behind bonferroni correction also apply here? Is it a different issue? If so, why?
