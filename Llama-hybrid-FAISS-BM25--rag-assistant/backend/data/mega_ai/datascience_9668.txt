[site]: datascience
[post_id]: 9668
[parent_id]: 
[tags]: 
Same SVM configuration, same input data gives different output using Matlab and scikit-learn implementation of SVM, in a classification problem

I have a classification problem with 60 data points in a 2-dimensional feature space. The data originally is divided into 2 classes. Earlier I was using Statistics Toolbox of Matlab so it was giving me fairly good results.It was giving 1 false negative and no false positive. I used the following code: SVMstruct = svmtrain(point(1:60,:),T(1:60),'Kernel_Function','polynomial','polyorder',11,'Showplot',true); I am using a polynomial kernel and with polynomial order of 11. But when I use same kernel configuration in scikit-learn SVC it does not gives the same result rather it gives very undesirable result with classifying all of them to single class. I am using it as svc = svm.SVC(kernel='poly', degree=11, C=10) I have used with many values of C too. No major difference. Why there is so much difference in results ? How can I get same result as I got using Matlab ? For me it is compulsory to do with python-scikit.
