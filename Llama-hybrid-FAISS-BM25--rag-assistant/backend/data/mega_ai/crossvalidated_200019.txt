[site]: crossvalidated
[post_id]: 200019
[parent_id]: 
[tags]: 
Understanding Kernel Functions for SVMs

I am learning about Support Vector Machines, and in particular, those with kernels for non-linear decision boundaries. I understand the concept of projecting the original data to a higher-dimensional space, such that a linear decision boundary can be inserted. But what I don't understand is how the kernel function actually does this mapping. For example, consider the radial basis function as a kernel $K(x, x') = -\lambda || x - x' || ^2$. What does this actually mean? Is it saying that for every data point $x$, you find its squared distance to the point x'? And this distance corresponds to its value in the new higher-dimensional space? But what is $x'$ anyway? And also, this is only mapping to a one-dimensional space, because the value is just a distance...not a higher-dimensional space. Of course, my understanding is totally wrong, but please could somebody explain where I am getting confused? Thanks!
