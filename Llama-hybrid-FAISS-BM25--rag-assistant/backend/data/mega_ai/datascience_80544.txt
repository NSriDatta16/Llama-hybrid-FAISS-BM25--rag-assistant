[site]: datascience
[post_id]: 80544
[parent_id]: 80541
[tags]: 
I would say that the best thing to do here is to concatenate both embeddings and use the concatenated vector as an input for your binary classification model without using the norm -> you loose way too much information, i.e.: final_layer = concatenate [ book_1_attention, book_2_attention] I reckon that concatenating without norm will increase the dimension (but that's potentially a problem for which you have solutions - such as regularisation)
