[site]: crossvalidated
[post_id]: 251570
[parent_id]: 
[tags]: 
Understanding parameter learning use of Principle of maximum entropy in Bayesian networks

I was reading Bayesian network on wiki: https://en.wikipedia.org/wiki/Bayesian_network And It stated for parameter learning use of "Principle_of_maximum_entropy". And according to Principle_of_maximum_entropy on wiki: https://en.wikipedia.org/wiki/Bayesian_network "By choosing to use the distribution with the maximum entropy allowed by our information, the argument goes, we are choosing the most uninformative distribution possible. To choose a distribution with lower entropy would be to assume information we do not possess. Thus the maximum entropy distribution is the only reasonable distribution" It seems counter intuitive, that we want to maximize entropy, which is "most uninformative distribution". Can somebody help me, what I am missing here?
