[site]: crossvalidated
[post_id]: 221622
[parent_id]: 
[tags]: 
Interpreting multinomial logistic regression in scikit-learn

I am running a multinomial logistic regression for a classification problem involving 6 classes and four features. Here is the code: from sklearn.linear_model import LogisticRegression from sklearn.cross_validation import train_test_split X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20) logreg = LogisticRegression(multi_class = 'multinomial', solver = 'newton-cg') logreg = logreg.fit(X_train, Y_train) output2 = logreg.predict(X_test) logreg.intercept_ logreg.coef_ logreg.classes_ And I get the following output: Intercept array([-1.33803785, -1.55807614, -1.63809549, -0.05199907, 3.72777888, 0.85842968]) Coefficients array([[ 3.59830486, 5.1370334 , 1.32336325, 4.89734568], [ 3.5507364 , 5.2459697 , 1.48523684, 4.81653704], [ 3.35193267, 5.40124363, 2.04869296, 3.885547 ], [ -5.4930705 , 5.49483357, 1.96479926, -6.7624365 ], [ -8.61513183, -3.77761893, -7.79363153, -11.72171457], [ 3.6072284 , -17.50146139, 0.97153921, 4.88472135]]) Classes array([u'Dropper', u'Flat', u'Grower', u'New User', u'Non User', u'Stopper'], dtype=object) I am not able to interpret the models. As I understand multinomial logistic regression, for K possible outcomes, running K-1 independent binary logistic regression models, in which one outcome is chosen as a "pivot" and then the other K-1 outcomes are separately regressed against the pivot outcome. As per this, there must be 5 equations for the 6 classes. But here there are 6. How come?
