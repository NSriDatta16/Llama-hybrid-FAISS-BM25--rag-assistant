[site]: crossvalidated
[post_id]: 615538
[parent_id]: 
[tags]: 
External validation of diagnostic model: Performance in subgroups

We are performing an independent external validation of a 2 published diagnostic risk prediction tools (logistic regression models) which estimate the risk for having a specific disease (model A and model B). We have done the following. Assessed discrimination by calculating c-index Evaluated model calibration using calibration plots Compared the two models using decision curves Doing so told us that calibration of A and B were ok (around 0.80 for both), and calibration was better for B (close to ideal, whereas model A undererstimated the risk for most patients). Finally, model B had the highest net benefit across a wide range of thresholds. My specific questions: Given sufficient statistical power, does it make sense to do the above for subgroups of patients (e.g. women, men, age-groups etc) to identify individuals in which the model works best? I saw this being done by prediction model experts here . Would this be possible for all subgroups or only for subgroups based on covariates in the model (e.g. can I only look at the performance of women/men separately if sex is a predictor)? I was able to compare the performance of the models using decision curves. As they are based on different covariates, does it (in theory) make sense to evaluate the performance of applying both models sequentially? Many thanks for your help.
