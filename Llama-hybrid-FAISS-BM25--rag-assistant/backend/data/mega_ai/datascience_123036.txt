[site]: datascience
[post_id]: 123036
[parent_id]: 
[tags]: 
Recommended way to embed a text thousands of tokens long?

I've split the text up sections each 512 tokens long and created embeddings for each of them. I want to combine them into 1 embedding for the full text. How do I do that? Is this even recommended? AdaV2 has max token limit of 8k, I thought about concatenating each embedding like str(embed1) + str(embed2) + ... and stopping when it reaches 8k tokens. But each embed is 15k tokens if converted to a string.
