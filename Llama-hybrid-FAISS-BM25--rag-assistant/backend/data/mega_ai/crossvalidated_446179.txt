[site]: crossvalidated
[post_id]: 446179
[parent_id]: 208248
[tags]: 
Least squares is a way of defining the objective function of a model, which refers to the core of the problem that models are trying the solve: to have the least amount of errors in making predictions. You can define errors in different ways: sum of absolute error, sum of square of error, weighted errors, or other definitions. You can use the good old method that Gauss used a few hundreds years ago, OLS, or its many modern variations, such as penalized (or regularized) linear regression with a loss function that is akin to least squares. To give a context, you can even use different types of gradient descent to solve a least squares problem. GLM refers to the model specification, not the definition of loss. You can certainly try to use least squares. The original GLM formulators John Nelder and Robert Wedderburn proposed an iteratively reweighted least squares method for maximum likelihood estimation of the model parameters. Maximum-likelihood is the default method on many statistical computing packages such as SAS and R.
