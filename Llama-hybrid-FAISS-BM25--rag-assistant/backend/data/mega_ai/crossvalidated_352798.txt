[site]: crossvalidated
[post_id]: 352798
[parent_id]: 260430
[tags]: 
Victor Lavrenko's "Evaluation 12: mean average precision" lecture contains a slide that explains very clearly what Average Precision (AP) and mean Average Precision (mAP) are for the document retrieval case: To apply the slide to object detection: relevant document = predicted bounding box whose IoU is equal or above some threshold (typically 0.5). IoU = Intersection over Union, see image below for a visual definition: Example of IoU computation on an actual picture: ( image source ) FYI: Mean Average Precision vs Mean Reciprocal Rank
