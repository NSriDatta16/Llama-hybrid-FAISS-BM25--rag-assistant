[site]: crossvalidated
[post_id]: 317316
[parent_id]: 317297
[tags]: 
Consider $d$ machines numbered $1,2,\ldots, d$, each with chance $p(d)$ of winning. Let's find the expectation of beginning with machine $1$, playing until a loss, proceeding to machine $2$, etc , and cycling around from machine $d$ to machine $1$ if necessary until $n$ games have been played. The question concerns the case $d=2$, but the analysis (and computation) isn't any harder for larger $d$. Let $e_j(k)$ denote the expected winnings from playing $k$ games beginning with machine $j$. Because each game is either a win (gaining $1$ dollar) with probability $p(j)$ or a loss with probability $1-p(j)$, leaving $k-1$ games to go, the rules of conditional expectation imply $$e_j(k) = p(j)(e_j(k-1) + 1) + (1-p(j))(e_{(j \operatorname{mod} d)+1}(k-1))$$ when $k \ge 1$ and otherwise $e_j(k)=0$. This is a simple dynamic program requiring $O(dn)$ computational effort and $O(dn)$ storage: in other words, it's a quick easy computation. You can even do it by hand. As an example, here is an R implementation. The argument p is an array of probabilities $p(j)$. It returns a $d\times n+1$ array indexed by machine and number of games (from $0$ through $n$). expectation 0) for (i in 1:n) { for (j in 1:d) { P[j, i+1] Given an initial probability distribution $c(1), c(2),\ldots, c(d)$ for the choice of which machine to start with, the rules of conditional expectation state that the expected winnings will be the sum of $c(j)e_j(n)$. This answers the question. Intuitively, machines that tend to fail will rarely be operated and those that tend to win are allowed to run. The $e_j(n)$ therefore will rapidly tend to a common value approximately equal to the $p$-weighted average of the $e_j(n)$ as $n$ grows, and the differences among the $e_j(n)$ will be no greater than the differences among the raw probabilities $p(j)$. Here are some examples for $d=2$. The panel headings list the probabilities for machine "a" and machine "b" in order. It's always good to check probability calculations. I carried out simulations as shown in this R program: p It exploits the fact that the number of wins obtained from a machine has a geometric distribution, allowing the simulation to proceed fairly quickly. (The computation actually amounts to counting how many machines were tried in turn, rather than counting the wins directly.) The output is an array of winnings, one for each iteration of the scenario. Because this dataset is large and not too skewed, we may compare its mean to the theoretical calculation using a Z-test. m The output in this (reproducible) case is Simulation Calculation Z 3.950 3.930 0.889 It says the average among the (10,000) simulations was 3.95, the calculation of the expectation came out to 3.93, and the Z-score is 0.889 (which is not a significant difference). Repeated simulations for different $p$ and $n$ continue to agree with the calculations, providing assurance the calculations are correct.
