[site]: crossvalidated
[post_id]: 294744
[parent_id]: 
[tags]: 
Random Search parameters optimization

This is an example, of hyper-parameters search in a hypothetical python code. My question is How can I be sure that RandomSearch really will find the best parameters that lies within the top 5% of the true maximum, with 95% probability. I read this answer , and its claims that with 60 iterations of random search I will find that 5% with 95% of probability. But that looks like a magic number and I don't know if that works just for any case or any type of problems without considering any other characteristic of the problem or the amount of hyper-parameters import numpy as np from sklearn.model_selection import ParameterSampler #... lot of imports and code that doesn't matter right now parameters = { "sequence_length": np.arange(50, 300, 50), "vocabulary_size": np.arange(1000, 50000, 1000), "embeddings_size": np.arange(64, 257, 64), "dropout": np.arange(0.2, 0.8, 0.1) } param_grid = ParameterSampler(parameters, n_iter=60) for grid in param_grid: my_awesome_lstm_model.fit(parameters=grid)
