[site]: datascience
[post_id]: 127021
[parent_id]: 
[tags]: 
What do special tokens used for in Roberta?

When I use this code: from transformers import RobertaTokenizer tokenizer = RobertaTokenizer.from_pretrained('roberta-base') captions = "This is an example caption" output = tokenizer(captions, padding='longest') input_ids = output['input_ids'] print(input_ids) tokens = tokenizer.convert_ids_to_tokens(input_ids) print(tokens) The output is: [0, 713, 16, 41, 1246, 3747, 2] [' ', 'This', 'Ġis', 'Ġan', 'Ġexample', 'Ġcaption', ' '] What is the purpose of the special tokens and , are they really necessary, does the performance decrease if I remove them using add_special_tokens = False ? Thanks
