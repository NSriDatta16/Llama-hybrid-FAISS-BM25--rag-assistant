[site]: crossvalidated
[post_id]: 620681
[parent_id]: 
[tags]: 
In what conditions do MC-Dropout-based uncertainties fail to be expressive?

I trained a neural network with dropout regularization and computed uncertainty scores for predictions on a test set. However, I found that these uncertainties exhibit a very weak correlation (Pearson: 0.03, Spearman: 0.01) with the model's error, rendering them ineffective. Under which conditions do MC-Dropout-based uncertainties fail to adequately capture model uncertainty?
