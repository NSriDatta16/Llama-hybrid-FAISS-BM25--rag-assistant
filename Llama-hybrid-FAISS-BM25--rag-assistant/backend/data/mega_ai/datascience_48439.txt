[site]: datascience
[post_id]: 48439
[parent_id]: 
[tags]: 
robots.txt communication in webmining

I hope this is the right subforum as I did not really find a suiting one. I'm mining data from a website that does specifically exclude some crawlers from it's site in the robots.txt like this: User-agent: * Disallow: User-agent: Proxetrics2000 Disallow: / While I'm pretty sure I'm not Proxetrics2000, how can I know which User-Agent to comply to? Let's say I'm mining too frequently and the admin wants to restrict me from certain sites. He would want to add my name to User-Agents: dnns Disallow: / Is there a way to tell the website "a name" of my crawler? I'm looking forward to your answers. To me this seems an oddly obvious questions, however I did not find anything while searching for it. Cheers, Dennis
