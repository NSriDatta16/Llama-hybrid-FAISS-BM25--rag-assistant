[site]: crossvalidated
[post_id]: 77413
[parent_id]: 77270
[tags]: 
Cross validation is used to select your model. The out-of-sample error can be estimated from your validation error. Usually this validation error is the mean value of your ten validation errors. Please note that the model here not only means the feature number, but also refers to your function model (whether it is y=ax1+bx2+c or y=ax1^2+bx2+cx1x2+d...etc.), and it mainly means the latter. Yet after the validation process you may have a rough idea of what features are of more importance. Once your model is determined, use all your data for the training, and use extra new data for test. You can still keep all the features (or most features if storage and computing is not a huge issue), just adding more regularization parameters to those features that contribute evidently less than others. The learning process will hopefully 'eliminate' those less-contribution-features. Here is another thread discussion on the similar topic with more details and various opinions, for your reference: Feature selection for "final" model when performing cross-validation in machine learning
