[site]: crossvalidated
[post_id]: 293884
[parent_id]: 293868
[tags]: 
Different field seem to take a different approach to whether responses to a Likert-type scale can be submitted to parametric or non-parametric analyses. Technically, they are ordinal in nature, though there have been studies of scale use demonstrating that people's responses often reflect a quasi-interval scale (though there's no guarantee). Pragmatically, check out what the standard is in your particular field, but verify that any parametric results you might obtain (e.g., based on t-test, ANOVA, OLS regression) are confirmed by non-parametric tests, such as the one's mentioned by Sal Mangiafico. The fact that your posing the question concerning the use of logistic regression is slightly puzzling because that particular analytical tool typically refers to the analysis of binary outcomes. While you mention binary outcomes, the majority of your post seems to refer to continuous (Likert-type) survey responses. Logistic regression only applies to binary outcomes. Yet, the bigger question you pose concerns the large number of significance tests you plan to conduct, and you seem to be concerned about an inflation of the alpha error. Depending on how deep you want to get into this topic, this question can get tricky very quickly as any need for adjustment of the alpha criterion depends on whether you choose to rely on "experiment-wise" or "family-wise" alpha errors. Again, my recommendation would be to look at what's customary in your particular field. Often, you will see that researchers do not engage in any kind of adjustment of the alpha error when reporting survey results such as yours. However, given that your concern is a good one, in the parametric world of things one classical way of tackling this particular issue has been through the use of MANOVA-based "step-down" procedure. To the extent that you have 2+ parametric outcome variables, which are also correlated with one another, you submit all of them at the same time to a MANOVA in which you use a set of continuous or categorical predictor that should apply to all outcomes. You will obtain a multivariate effect for each predictor, which tells you, whether across the string of outcome variables (a vector) this particular predictor is related to variation. If you do observe a significant multivariate effect, you still don't know for which of the specific outcomes (of the set of 2+ outcomes) the predictor has a significant effect. Thus, in the presence of a significant multivariate effect you examine the univariate effects, and have "license" to interpret them, if significant. (The implication of this method is that you should not interpret any significant univariate effect in the absence of a non-significant multivariate effect.) The focus on the multivariate effects helps protect against redundant univariate effects, i.e. you observe that X has an effect on Y1, but also on X on Y2, even though Y1 and Y2 might be highly correlated.
