[site]: crossvalidated
[post_id]: 540792
[parent_id]: 539638
[tags]: 
Well, I think the lack of an answer that explains how to detect whether class imbalance is a problem in a particular application, even when a modest bounty of +50 reputation was on offer, suggests cause for concern about research on the topic of class imbalance. I suspect practitioners are frequently re-balancing or re-weighting the datasets simply because they are imbalanced, rather than because the imbalance is actually causing a problem. I further suspect that often this is just making matters worse by over-compensating (e.g. by fully balancing the dataset). Class imbalance can cause a problem when there are two few examples of the minority class to adequately characterise it's statistical distribution. When this happens, the decision boundary does tend to be unduly biased in favour of the majority class. However, as you add more data, the problem goes away. This shouldn't be a surprise. If you have a large enough neural network, it will be a universal approximator, able to implement essentially any (one-to-one or many-to-one) mapping between the input and output spaces. If it is fitted using a proper scoring rule then asymptotically it will output the true posterior probabilities of class membership. So if you have enough data, it doesn't matter how imbalanced the problem is, a complex enough model will learn the optimal decision surface. I think any means of detecting and dealing with class imbalance problems will be very tricky though. Essentially if there is a bias, you will want to re-sample or re-weight the training sample just the right amount to compensate for the bias due to the "imbalance". Exactly balancing the dataset is likely to way over-compensate and make accuracy (or expected loss) worse rather than better. The trouble is, if you don't have enough data to describe the minority class, where are you going to get the data to choose the optimal degree of bias? I suspect the best approach will be some Bayesian scheme that determines what the plausible true positive rate (for example) could be if the model were correct. Essentially, I know from experience that class imbalance can cause estimation problems, in a small data setting, but I'm not convinced that there is a great deal we can do about it because we don't have enough independent data to tune the compensation applied. I think we should be very wary of up/down sampling or reweighting simply because there is an imbalance, and if we do, we need to be able to determine whether it has worked or not. This requires at least that we know what criterion is important for our application, and why it is important. No application is primarily interested in the true positive rate, if that were true, we would just assign everything to the positive class and go home satisfied with having done the optimal job! ;o)
