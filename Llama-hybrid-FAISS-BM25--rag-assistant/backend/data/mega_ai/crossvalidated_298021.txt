[site]: crossvalidated
[post_id]: 298021
[parent_id]: 297581
[tags]: 
The really interesting aspect of this question is that the doses are recorded as intervals and those intervals span sizable portions of the total range. This means we should be concerned that standard procedures, like logistic regression, that represent the doses as individual numbers might be misleading. By means of visualizations, I will take you step-by-step through a simple (and no means thorough) analysis until we arrive at the final complex but highly illuminating graphic. Your time might best be used by skimming down the plots, then backing up to study anything that captures your interest. Let's look at this more closely. Suppose that any given dose $x$ (not a range--an actual dose) is associated with a chance of $p(x, s)$ that any cockroach of species $s$ will die in these experimental conditions. Further suppose that cockroach deaths are (statistically) independent. (This assumption can in principle be tested; for now, it is needed because relevant information for testing it is unavailable.) This is a Binomial Generalized Linear Model (albeit without a specified link function--yet). These assumptions can (and should) be written mathematically so that we can determine an appropriate procedure to estimate $p(x,s)$. Consider a cockroach of species $s$ that was administered a dose $x$ between $a$ and $b$ units. The indicator of its death is a random variable taking the value $1$ with probability $p(x,s)$. The total number of deaths of $20$ such individuals is the sum of $20$ such variables, where $x$ ranges between $a$ and $b$ as determined in the experiment. If $x$ were fixed, that total would therefore have a Binomial$(20, p(x,s))$ distribution. But if $p(x,s)$ varies over that interval $(a,b]$, then the total has a different distribution. To make further progress, we have to specify how $p$ might vary with $x$. A standard, simple way is with a "logistic link function" where the log odds of death are assumed to be a linear function of dose. Equivalently, let's suppose $$p(x,s) = 1 - \frac{1}{1 + \exp{\left(\alpha(s) + \beta(s)x\right)}}$$ for numbers $\alpha(s)$ and $\beta(s)$ that could differ between the two species. (This gives two competing models: when $\alpha$ or $\beta$ differ between the species the model has an "interaction.") In the next plot, $x$ values were randomly assigned (independently) within each interval (limiting the "20+" interval to the range 20-25) and the model without interaction was fit. The curves plot $p(x,s)$ for $s=1,2$. The uncertainty arising from recording each dose only with its interval can be assessed by repeating this random selection of possible doses within the intervals. For the next figure, 100 models were fit. The doses within each interval were chosen according to various scaled Beta distributions with randomly-selected parameters; some of those parameter choices could cause most of the doses to be near one end of an interval or another. For each iteration the same Beta distribution, appropriately scaled, was used in each interval: thus, doses might be consistently chosen near the low ends or near the high ends of the intervals. To combine the two assessments of uncertainty--prediction error as estimated within the model and variation due to uncertain location of the doses within each interval--the last figure superimposes all 100 "error polygons" (as shown in the second figure above). Most of the data fit nicely within these visual envelopes. The only exception is the observation of no deaths for Species 1 (red) at a dose of 0-1 units: its interval, plotted in the bottom left corner, appears to be a little low. I will end by saying a little more about the "interaction." For all 100 datasets, both models were fit (with and without interaction). Just as an analyst might do in practice, the no-interaction model was chosen unless the model with interaction was determined to be "more significant" than the one without interaction. The decision was made by comparing the AICs of the models, referring the difference to a $\chi^2(1)$ distribution, and setting the significance level at $95\%$. What actually happened is that in every case, the no-interaction model was chosen. Visually, no interaction means that the fitted curves are horizontal translates of each other: that is, there will be some constant $\mu$ for which $p(x,1)=p(x-\mu,2)$ for all $x$. You can see this in the second figure above: the fit (black curve) for Species 1 is about $\mu=9$ dose units to the right of the fit for Species 2. One might interpret this as follows: The susceptibility of Species 2 to the dose is about the same as giving nine more units of the dose to an individual of Species 1. As an example of what effect this dynamic model selection might have, let's alter the data a tiny bit. Suppose that $12$ instead of $20$ deaths were observed in Species 1 at a dose of "20+". Now, fairly frequently, the data appear to have different "shapes" for the two species. The models with interaction fit steeper dose-response curves to Species 2 than to Species 1. What is especially interesting is how these overlapping fits and error envelopes collectively account for (a) uncertainty computed within each model, (b) uncertainty due to how doses were recorded, and now (c) uncertainty due to the analyst's choice of model.
