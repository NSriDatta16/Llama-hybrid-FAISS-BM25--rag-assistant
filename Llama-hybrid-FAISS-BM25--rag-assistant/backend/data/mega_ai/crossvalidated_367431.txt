[site]: crossvalidated
[post_id]: 367431
[parent_id]: 
[tags]: 
Why researchers use conv1d for embeddings instead of dense layers?

In some papers (like Reinforcement learning for Vehicle Routing Problem ), researchers use conv1d to embed the problem input into a hyperspace; for example, in solving TSP, they use conv1d on the (x,y) coordinates of node, but I don't understand why use conv1d if dense layers will allow the network to capture more relations. What I understand is that conv1d will produce output channels that aren't related to one another and can't share info between each other while dense layers can share info on propagating the input to their output. Shouldn't the latter be better or I am missing something? Wasn't convolution made for inputs that are large but at the same time have a repeating feature (like edges) that we want to detect?
