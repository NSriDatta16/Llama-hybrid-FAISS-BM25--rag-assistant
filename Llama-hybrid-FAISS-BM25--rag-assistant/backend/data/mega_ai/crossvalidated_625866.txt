[site]: crossvalidated
[post_id]: 625866
[parent_id]: 
[tags]: 
Approximating Median Absolute Deviation (MAD) with Rolling Median for Normalization: Trade-offs?

I'm working with a time series dataset and am interested in normalizing the data using the rolling Median Absolute Deviation (MAD). The true MAD is defined as: $$ \text{MAD} = \text{rolling median}(|X_i - \text{median}(X)|) $$ However, due to computational constraints, I'm considering an approximation method that uses the rolling median of the absolute deviations from the rolling median: $$ \text{approx MAD} = \text{rolling median}(|X_i - \text{rolling median}(X)|) $$ Here's a snippet of my Python code for clarity: window = 20 mad = lambda x: np.median(np.fabs(x - x.median())) test_x['mean'] = test_x['x'].rolling(window).mean() test_x['median'] = test_x['x'].rolling(window).median() test_x['centered_absolute'] = abs(test_x['x] - test_x['median']) test_x['approx_mad'] = test_x['centered_absolute'].rolling(window).median test_x["mad"] = test_x['x'].rolling(window).apply(mad, raw = False) The approximation is significantly faster, but I'm concerned about the potential trade-offs in terms of accuracy, especially when the data is used for further analysis. I guess my main question is what are the potential pitfalls of using this approximation, especially in terms of sensitivity to outliers and skewed data (my main goal is to find outliers for timeseries)?
