[site]: crossvalidated
[post_id]: 55200
[parent_id]: 
[tags]: 
lag in prediction outputs in one-step ahead neural network autoregressive model

I am working on an ARX forecasting problem mostly using feed-forward neural networks in MATLAB. The functional model is of the form $y(t) = f(y(t-1),...,y(t-n),u(t))$. My data is at half hourly resolution. The problem is that forecasted outputs appear to be lagged by one time step when compared to the true outputs. I have successfully applied my forecasting model to a similar data set. A new set I am testing has a lot more variation sample-to-sample. That is, the trained model gives a prediction $\hat{y}(t)$ that is very close to $y(t-1)$. When I consider predictions farther into the future, such as $y(t) = f(y(t-j),...,y(t-n-j),u(t))$, where $j>4$ and the short-term autoregressive contribution is weaker (which is also observed in the trained model), I don't observe this offset. To sanity check, I have trained a simple AR(n) model using OLS, and I observe the same sorts of lags on my data. When I use the same procedure on my earlier, and smoother, data set, no such lag exists. I have also generated a model $y(t) = \sin(t) + w(t)$, where $w(t) \sim N(0,\sigma^2)$, sampled at .1 s, and attempted to train a model using both neural networks and OLS. The inputs are $y(t-1),\ldots,y(t-4)$, and the targets are $y(t)$. For both, when $\sigma$ is sufficiently small (say $ .1$), I notice the one-step lag. Could you please let me know what's going on? I'm hoping this is just a beginner's mistake... but I'm quite puzzled as I have tried a number of other modeling approaches and observed similar behavior. Thanks in advance!
