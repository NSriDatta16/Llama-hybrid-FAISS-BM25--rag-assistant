[site]: crossvalidated
[post_id]: 7331
[parent_id]: 7319
[tags]: 
Since $X_i$ and $Y_i$ are AR(1) processes, we can treat $(X_i,Y_i)$ as a VAR(1) process. Then testing the difference of means means testing the restrictions on VAR coefficients. For this simple case there is a formula derived in Hamilton's book "Time series analysis". The formula in the link is the one before the start of new section. Unfortunately it is not implemented in R, as far as I know. I checked only vars package, but I can say with some confidence that if it is not implemented there, it is not implemented in other packages. Here is some code I've cobbled to calculate this statistic for simulated AR(1) processes: n After playing with different values of means, it seems that statistic is working more or less. Of course the results should be tested for different values of variance of errors and different AR specifications and different sample sizes. On the other hand from theoretical point of view statistic is quite nice, since it allows unequal variances. Update Out of curiosity I did some MC simulations. For this I wrote a bit more efficient version of test: ham.test.lm2 This runs about 60 times faster than the original. Then I wrote special function for generating two AR(1) processes given their parameters. gen.arima This function generates N pairs of n sized sample of two AR(1) processes. Then I ran the following simulation. library("iterators") library("foreach") library("multicore") library("doMC") registerDoMC(16) ##the simulations ran on server with 2 quad-core Xeon processors with HT rho This simulation calculates the number of times the statistic rejects the null hypothesis that the means are zero for various sample sizes and various combinations of parameters of AR(1) processes. I used the maximum burn in for $\rho=0.9$ when generating AR(1) processes. I also compare the performance of the statistic to simple t-test. The resulting data.frame can be downloaded here . Here is a few graphs illustrating the perfomance. This is for AR(1) processes with $\rho=0.1$, 0.1 and 1 indicate the variance of the errors. mudiff is the true difference of the means. Here is the similar graph for $\rho=0.9$: Now the same graphs for t.test ($\rho=0.1$): And $\rho=0.9$: Here is the code which produced the graphs: mc Conclusions Note that the graphs measure the power of the statistic for mudiff greater than zero and size of the test for zero mudiff , so ideally the the blue line for mudiff=0 should be straight line at 0.05, and all the other lines should be straight lines at 0.95. Since the statistic is assymptotic this does not happen. What it is clear that t.test is not suitable for higher values of $\rho$, it performs quite nice for $\rho=0.1$, but very bad for $\rho=0.9$. Hamilton's test on the other hand has low power even for larger sample sizes when the true difference in means is not very large. Also the results are the same for error variance 0.1 and 1, so I do not rule out the error in my code.
