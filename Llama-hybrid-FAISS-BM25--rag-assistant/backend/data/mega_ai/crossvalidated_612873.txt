[site]: crossvalidated
[post_id]: 612873
[parent_id]: 
[tags]: 
Bayesian inference on a set of functions of random variables

I have a set of $k$ random variables, $y_i(x) = f_i(x) + \epsilon_i, y \in \mathbb{R}$ where, $\epsilon_i \sim \mathcal{N}(0, \sigma_n^2)$ (a noise term) $x \sim \mathcal{U}(-\infty,\infty; -\infty,\infty)$ (a 2D uniform variable) $f_i(x) = \varphi(x,\mu_i,\Sigma_s), \mu_i \in \mathbb{R}^2, \Sigma_s = \begin{bmatrix}\sigma_s^2 & 0 \\\ 0 & \sigma_s^2\end{bmatrix} $ (i.e., the 2D multivariate normal P.D.F.) I am interested in the joint posterior probability, $P(x|y)$ , and so I am attempting to use Bayes' theorem, $P(x|y) = \frac{P(y|x) P(x)}{P(y)}$ Since $P(x)$ is uniform, it only has the effect of scaling the result. However, I am unsure of how to arrive at the other terms, or even if I can expect a closed-form solution. I can easily simulate these results for small k, but I would like an analytic solution when k is large. One observation is that $P(y_i | f_i(x)) = P(\epsilon_i = y_i - f_i(x)) = \varphi(y_i, f_i(x), \sigma_n^2)$ . Thus, given a realization of $f_i(x)$ I can estimate the probability of $y_i$ . I also know that $P(x|f_i(x))\neq0$ defines a circle in $\mathbb{R}^2$ (or more generally an ellipsoid), so I was thinking that I need some generalization of the delta function. In this way I think I can go from $P(x) \rightarrow P(f_i(x)) \rightarrow P(y_i|f_i(x)) \rightarrow P(y_i|x)$ . However, I am not sure how to arrive at $P(y|x)$ from $P(y_i|x)$ , since the $y_i$ are not conditionally independent. I am even less sure of how to approach $P(y)$ . The range of $f_i(x)$ is strictly positive, but I don't know its probability distribution, much less $P(y_i)$ or the joint $P(y)$ . However I imagine since I am working with the normal distribution that if there is a solution it has been studied before. Is there a solution to this problem? Are there similar problems that do have solutions (e.g., adding a scale factor or other transformation to $f_i$ , discretizing $x$ )?
