[site]: datascience
[post_id]: 80074
[parent_id]: 
[tags]: 
Text generation - Input text (one sentence or many sentences)

I am currently working on a project: I want to generate text with a LSTM using Pytorch. My model is working but I have a question about the methodology: I'm using the BPTTIterator and something seems weird to me: you have to give one big example with all your text in it then it will provide your neural network with the current word and the target word for each step. So, it looks like that my LSTM won't be able to "understand" if it's the beginning or the end of the sentence. I saw that usually you feed your LSTM with one sentence at the time with SOS and EOS tokens. My question is: what does it changes to use one or another method and which one is the best practice ?
