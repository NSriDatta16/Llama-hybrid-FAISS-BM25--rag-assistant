[site]: crossvalidated
[post_id]: 363717
[parent_id]: 363666
[tags]: 
I would strongly oppose the answer of @Dave Harris. What do frequentists do? The make assumptions about the true underlying relations of the random variables, compute some new realization of a random variable that has a certain distribution they know (due to the assumptions on the underlying relations) and then see how 'probable' it is that this random variable produced this concrete realization. So this is in no way a 'direct' assertion of the probability of the parameter being zero or so. In short: "It seems to be accepted by the community" to transfer the assertion to some object/setting/... topic and then make this related object/setting/... precise. What do Bayesians do? Let us say that we chose the model $$Z = \beta_0 + \beta_1X + \beta_2Y + \text{error}$$ and we are given realizations (training set) $x_1, y_1, z_1, ..., x_N, y_N, z_N$. We then make some natural assumptions (the touples $W_i = (X_i, Y_i, Z_i)$ are independent of each other and so on). So far everything is as in the frequentists approach. Here comes the 'new' step: We imagine the $\beta_0, \beta_1, \beta_2$ being outcomes of random variables $B = (B_0, B_1, B_2)$ as well and put a rasonable so-called prior on these, i.e. we assume that $B$ has some density $f_B$. Then from the assumptions on the structure of the model and the independence and so son we can explicitly write down the conditional density $p(B|W)$ where $W = (W_1, ..., W_N) = (X_1, Y_1, Z_1, ..., X_N, Y_N, Z_N)$. Then the Bayesian viewpoint is that we do not search for the parameter that best explains the generation of the data (i.e. we do not maximize $p(W;\beta_0,\beta_1,\beta_2)$ which we can somewhat interpret as $p(W|B)$) but rather we compute the point in the density of the switched order $p(B|W)$ that is maximal (i.e. what is the parameter that has the highest probability given the data that we observed). Those two viewpoints are linked by the following formula $$p(B|W) = \frac{p(W|B)p(B)}{p(W)}$$ What we are after in the end is a more or less complete description of $p(B|W)$. In the very concrete example above we could, for example, get the distribution of $B_1$ (which encodes the relation of $X$ to $Z$) given the data, i.e. $p(B_1|W)$ by marginalizing out $B_0$ and $B_2$. We could get different pictures then. Ill provide three examples and then I state how I interpret them: Situation 1 Situation 2 Situation 3 Situation 1: The mean and highest peak of the density is around 0 so the model suspects $\beta_1$ to be zero. The fact that there is almost no deviation from that value (i.e. the density put very much mass around a very small space around 0) tells us that the model is very certain that $\beta_1=0$. This corresponds to th case where the Null hypothesis can be rejected, we can safely claim that $\beta_1=0$. Situation 2: The mean and highest peak of the density is around 0 so the model suspects $\beta_1$ to be zero. However, the peak is much smaller and the density puts a lot of mass outside that region around 0. Hence, the model suspects that $\beta_1=0$ but it 'cant prove it'/it is uncertain. This corresponds to the situation where the Null hypothesis may be right but we do not have enough evidence to reject it. In this case we tell our boss that (using this model) it might be true that $\beta_1=0$ but we cannot prove it. So either we need to change the model (this can be dangerous and could correspond to 'p-Hacking') or we need to collect more data. Situation 3: The mean and highest peak of the density is around -2 so the model suspects $\beta_1$ to be $-2$. However, it is not as certain as in situation 1. So like in the frequentists approach (they set the acceptance threshold to p=0.05 which is absolutely arbitrary! Why not 0.01 or 0.0001?) it is up to you to define a measure/threshold that applies to the density in order to decide whether or not you want to state that $\beta_1=-2$ in that case. However, if the question is whether or not $\beta_1=0$ then again, the mass the density puts around $0$ is VERY little so we can safely claim that $\beta_1 \neq 0$.
