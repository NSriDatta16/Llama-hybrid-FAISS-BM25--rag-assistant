[site]: datascience
[post_id]: 3817
[parent_id]: 3770
[tags]: 
For known and unknown properties, how should I proceed to go from daily to weekly/monthly data ? Aggregation. For example, you have the number of time people searched for 'widgets' every day. Add up the daily totals for a month to get monthly totals. I would need to see more specifics about the actual data collected at each granularity to give you a more complete version. For known and unknown properties, how should I proceed to go from weekly/monthly to daily data ? You can't. In physics, a comparable idea is the Nyquist frequency . The general idea is that you can't add more information than what you already have present in your data without bringing in more data. Given only the day someone ran a query, how can you tell what time of day that query was ran? You may be able to make some inferences, but the only way to answer the question is to directly or indirectly bring in more information to the system. There are things you can do to make informed guesses at the daily state of monthly variables (as gchaks mentioned, interpolation), but your data is still fundamentally monthly data stretched to look daily. When given two time series with different time steps, what is better: Using the Lowest or the biggest time step ? That totally depends on what you're trying to answer. The smaller granularity will be more sensitive to noise and other anomalies. The lager granularity will be able to answer questions more confidently, but loose some of it's usefulness. For example, if you're trying to see when people start looking up venues to weekend plans to know when to launch marketing campaigns for a new night club, you'll want to be looking at daily data, if not smaller. If you're looking at the general trending of night clubs to figure out who you want to invest in, then monthly would probably be better.
