[site]: crossvalidated
[post_id]: 617729
[parent_id]: 
[tags]: 
Could one use mixtures of Gaussians to turn MCMC posterior samples into a new prior?

Theoretically in Bayesian inference one could use one experiment's posterior as another experiment's prior, such that knowledge of the parameters accumulates from $p(\theta) \rightarrow p(\theta|\mathbf{X}_{1}) \rightarrow p(\theta|\mathbf{X}_{1}, \mathbf{X}_{2}) \rightarrow \ldots$ But in practice, of course, this is only possible with conjugate priors that guarantee that posteriors have the same nice parametric form. With MCMC sampling, all you have are empirical distributions. It was asked many times before how one could turn posteriors into new priors, but to take it a little further: I was wondering if one could fit a mixture of Gaussians to the empirical distribution of MCMC samples? Because, if I recall correctly, Gaussian mixtures' "universal approximation" property should allow them to approximate any probability distribution. Could this work, or has it even been implemented before? References would be greatly appreciated.
