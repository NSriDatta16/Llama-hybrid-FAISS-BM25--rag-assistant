[site]: datascience
[post_id]: 21646
[parent_id]: 21645
[tags]: 
A random forest will work, however standard regression will also work with categorical variables as predictors. You will have to "one-hot" encode your categorical predictors into 6 "dummy" variables (classes-1 = 7-1 = 6). The first dummy variable will encode 0/1 for whether or not the observation is class A, second dummy variable as 0/1 for class B, etc. You only need 6 dummy variables because if all of them are 0 for a given observation, that means the observation is in group 7 (G). In some languages, such as R, the regression command will automatically do this one-hot conversion for you. For python, the pandas package can do this for you with pd.get_dummies(data) .
