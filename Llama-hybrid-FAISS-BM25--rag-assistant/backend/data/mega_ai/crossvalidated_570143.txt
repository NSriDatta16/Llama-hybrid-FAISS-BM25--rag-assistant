[site]: crossvalidated
[post_id]: 570143
[parent_id]: 569801
[tags]: 
I thought about it a bit more, and here is another simple explanation of why, for the least square loss $\mathcal P = \|\cdot\|_2^2$ , using that method to learn your typical fully connected feedforward ReLU network is a terrible idea and you're not just likely but guaranteed to have a useless model after training (which also resolves the "paradox" of how a convex function can achieve multiple minima, as I asked in my question too) : If $\lambda$ is taken large enough so that the program $(2)$ is convex, then it is straightforward to show that there exists a unique global minimum on the domain $\Theta^N$ , let's call it $\theta^*$ . So in this setting, we know that $\theta^*$ is unique, SGD should be able to pretty quickly converge to it and furthermore because $\lambda$ is probably pretty large the solution will not overfit the data. Great, isn't it ? No, not really. The thing is, even if the minimizer is unique, any multilayer network is non-identifiable. That is, for any given set of weights $\theta$ , there exist permutations of these weights $\tilde \theta$ that computes the exact same function (in fact, there are many such permutations, see here , here , or just the answer above). That property still holds for the minizer $\theta^*$ , but we just said $\theta^*$ is unique ! So that implies that for any $\tilde \theta^*$ that is an appropriate permutation of $\theta^*$ , we have $$\tilde \theta^*_i=\theta^*_i,\quad \forall\, 1\le i\le N$$ It is thus easy to conclude from these observations that, at the minimum, for a non-identifiable loss such as least squares, all the weights are in fact equal , i.e. $\theta^* \in\mathrm{span}\{(1,1,\ldots,1)^T\}$ . The neural network learned this way is thus essentially a non-linear function of only one parameter, which will be totally useless for the kind of problems that do require neural networks in the first place. Now, as mentioned in my updated question, it doesn't necessarily mean that such an approach is doomed to fail : one could circumvent the non-identifiability issue by adding some acceptable constraints to the network such as adding some dropout (also known as skip connections ). The penalty $\mathcal P$ could be chosen non-identifiable as well, although it would in some sense add some extra bias to the model that is not necessarily needed. I mainly asked out of curiosity, so I'm not planning to implement any of these ideas anytime soon, but if someone does I'd love to see the results !
