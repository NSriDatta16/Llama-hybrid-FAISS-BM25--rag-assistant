[site]: datascience
[post_id]: 71468
[parent_id]: 
[tags]: 
Question about Beware of the inherent skew in ranking problems in Google Rule of ML

I try to understand the Rule 35 from Rule of ML from Google. When you switch your ranking algorithm radically enough that different results show up, you have effectively changed the data that your algorithm is going to see in the future. This kind of skew will show up, and you should design your model around it. There are multiple different approaches. These approaches are all ways to favor data that your model has already seen. Why the algorithm is going to see in the feature? I can't get it. Is it mean there will be some bias that data is the result from previous model? Have higher regularization on features that cover more queries as opposed to those features that are on for only one query. This way, the model will favor features that are specific to one or a few queries over features that generalize to all queries. This approach can help prevent very popular results from leaking into irrelevant queries. Note that this is opposite the more conventional advice of having more regularization on feature columns with more unique values. It mean put more penalty on those general feature, and less for unique feature. But this opposite the conventional advice, how can we leverage? Only allow features to have positive weights. Thus, any good feature will be better than a feature that is "unknown". What it mean "Unknown"? Negative weights maybe the feature is nagtive correlation?
