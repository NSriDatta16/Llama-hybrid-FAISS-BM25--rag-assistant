[site]: crossvalidated
[post_id]: 47388
[parent_id]: 47367
[tags]: 
The random forest technique is related to decision trees. A metric that it outputs is a variable importance measure. This measure of often used for feature selection, which is a technique to select a subset of variables. They key aspect to understand is that there are many ways to go wrong with feature selection (subset selection). For example, if your model is assessed with a resampling plan (cross validation/bootstrap), you must repeat the variable selection at each iteration. This requires a good amount of background reading to fully appreciate. But searching this site and others for "randomForest", "variable importance", "variable selection", "cross-validation", and "overfitting" will get you started.
