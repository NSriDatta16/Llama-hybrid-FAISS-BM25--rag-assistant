[site]: crossvalidated
[post_id]: 519293
[parent_id]: 519219
[tags]: 
Your descriptions of Statistical Model Building and Machine Learning are imcomplete if not false. Adding and deleting data based on their AIC ist stepwise regression and that is widely discouraged because it leads to overfitting to the data at hand. So that is not what we should do in statistics. In machine learning you left out the important aspect of splitting you data into training, tuning and test data. Let's take LASSO regression as an example. It usually does not lead to $p$ -values but it has a tuning paramater $\lambda$ that decides, how easily the model accepts or rejects additional data. This tuning parameter is usually defined via cross validation so that the model should have no more or no less parameters than are optimal for prediction purposes. A statistics models gets it's justification from some complicated-to-explain $p$ -value that should lie below some completely arbitrarily chosen limit. A machine learning model gets it's justification from cross validation. So machine learning does not have something less, just something different that does not appear in your depiction of ML.
