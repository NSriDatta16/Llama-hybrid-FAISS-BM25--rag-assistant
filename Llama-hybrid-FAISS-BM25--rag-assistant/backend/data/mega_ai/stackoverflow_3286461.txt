[site]: stackoverflow
[post_id]: 3286461
[parent_id]: 
[tags]: 
How to calculate actual months difference (calendar year not approximation) between two given dates in C#?

Example: given two dates below, finish is always greater than or equal to start start = 2001 Jan 01 finish = 2002 Mar 15 So from 2001 Jan 01 to the end of 2002 Feb months = 12 + 2 = 14 For 2002 March 15/30 = 0.5 so grand total is 14.5 months difference. It's very easy to work out by hand but how do I code it elegantly? At the moment I have the combination of a lot of if else and while loops to achieve what I want but I believe there are simpler solutions out there. Update: the output needs to be precise (not approximation) for example: if start 2001 Jan 01 and finish 2001 Apr 16, the output should be 1 + 1 + 1= 3 (for Jan, Feb and Mar) and 16 / 31 = 0.516 month, so the total is 3.516. Another example would be if I start on 2001 Jul 5 and finish on 2002 Jul 10, the output should be 11 month up to the end of June 2002, and (31-5)/31 = 0.839 and 10/31 = 0.323 months, so the total is 11 + 0.839 + 0.323 = 12.162. I extended Josh Stodola 's code and Hightechrider 's code: public static decimal GetMonthsInRange(this IDateRange thisDateRange) { var start = thisDateRange.Start; var finish = thisDateRange.Finish; var monthsApart = Math.Abs(12*(start.Year - finish.Year) + start.Month - finish.Month) - 1; decimal daysInStartMonth = DateTime.DaysInMonth(start.Year, start.Month); decimal daysInFinishMonth = DateTime.DaysInMonth(finish.Year, finish.Month); var daysApartInStartMonth = (daysInStartMonth - start.Day + 1)/daysInStartMonth; var daysApartInFinishMonth = finish.Day/daysInFinishMonth; return monthsApart + daysApartInStartMonth + daysApartInFinishMonth; }
