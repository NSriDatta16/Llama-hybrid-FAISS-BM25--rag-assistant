[site]: datascience
[post_id]: 61300
[parent_id]: 
[tags]: 
Why do we operate with graphical models in VAE, if there are no probabilites involved?

In the variational autoencoder, I often see graphical models e.g. $P(X|Z)$ for the decoder, but when I looked at code, I don't see any random variables, I see just deterministic network, with composite functions. I am very confused by that, can someone explain where the magic happens? I am not interested in KL divergence and other stuff. I just don't understand how graphical model > $P(X|Z)$ == composite functions.
