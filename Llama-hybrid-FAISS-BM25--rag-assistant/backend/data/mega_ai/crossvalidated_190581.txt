[site]: crossvalidated
[post_id]: 190581
[parent_id]: 190566
[tags]: 
It depends on the structure of the correlation. If the errors are correlated 'over time', for instance, you might consider an autoregressive model for the errors or some other time-series model. Or you can use Genearlized Least Squares Estimation which will allow you to model the correlation of the error terms directly: if you're using R you can use lm.gls() in the MASS package for this. If they are correlated due to being 'repeated measures' or clustered (for example, family members answering the same questionnaire), then you might consider a 'hierarchical' or 'mixed' model, etc. Genearlized Estimating Equations also do not assume that the errors are uncorrelated: https://en.wikipedia.org/wiki/Generalized_estimating_equation Basically the 'bad effects' can be mitigated by choosing a different model. Another option, if the error terms are serially correlated (as in time series): continue using OLS (if that's what you're using) and 'fix' the errors using, for instance, a Newey-West estimator: https://en.wikipedia.org/wiki/Newey%E2%80%93West_estimator These are just a few options: really it depends on what you're investigating and the structure of the correlation between the errors...
