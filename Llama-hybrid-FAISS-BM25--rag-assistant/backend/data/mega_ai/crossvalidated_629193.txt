[site]: crossvalidated
[post_id]: 629193
[parent_id]: 
[tags]: 
Does k-fold cross validation strictly require shuffling of data before splitting it into k groups?

Both according to Wikipedia , and to this blog post , k -fold cross validation seems to require that you shuffle the data. I have two questions: Firstly, why? If you have a time sequence of training examples where (on average) an individual training example is more similar to other examples that are closer to it temporally than other examples that are farther away from it temporally (such as for example a sequence of video frames, if that's what your input data consists of), doesn't it make sense to omit shuffling the data before splitting it up, since if you do shuffle it, then for each validation example, you will almost be certain to have some training example with a high degree of similar to it (which wouldn't be the case if you didn't shuffle it), which kind of defeats the purpose of doing validation from the first place (since you want to see how your model would perform on new data, which would most likely have a significantly lower degree of similarity to anything you had trained it on)? Secondly, what if you don't shuffle the dataset before splitting it, can't you call the validation method k -fold cross validation anymore? Then what do you call it?
