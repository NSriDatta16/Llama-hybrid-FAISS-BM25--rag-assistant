[site]: datascience
[post_id]: 99692
[parent_id]: 
[tags]: 
How to create classification decision trees on a dataset that has both numerical and categorical variables?

I am quite new to Data Science and learning things hands-on in the job. I am a fraud analyst and my job is to predict whether an application is fraudulent or not based on data. Before moving on to many advanced models, I am asked to build decision trees on the dataset. Now the dataset which I have has 1500 columns; some categoricals and some numeric. Different categorical variables have different levels; some are binary and some have 100+ levels. I came across the fact that scikit-learn can work only if the entire dataset comprises numeric variables (discrete or continuous). And the frequent work-around that I am seeing is around one-hot encoding like here - which I do not believe is pragmatic in my case because of a sheer number of columns and levels. I asked my bosses to give me few weeks to understand most of the data so as to limit my variables and possibly do one-hot encoding but that's not flying well with them. Has anyone any experience building classification decision trees on a mixed datatype dataset with large counts of variables? Thanks.
