[site]: crossvalidated
[post_id]: 563855
[parent_id]: 563846
[tags]: 
A probability density function is also a function. Usually a neural network 'acts' as a parametric function $g_\theta(.)$ and the process of training is selecting the $\theta$ based on some notion of optimality. If, say for example, you choose to model things as $g_\theta: \mathbb R^N \rightarrow \mathbb R^2$ you might be using the first entry of the output as the mean of a distribution and the second as the log of the variance. Your optimisation criterion would then be something, e.g. like maximizing log likelihood.
