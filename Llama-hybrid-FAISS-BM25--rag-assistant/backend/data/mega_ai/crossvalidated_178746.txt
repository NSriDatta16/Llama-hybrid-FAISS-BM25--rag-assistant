[site]: crossvalidated
[post_id]: 178746
[parent_id]: 178730
[tags]: 
Such mixture models are prominently featured in the theory of multiple testing. Here again you have such a mixture; the so-called "two-groups" model. The one group corresponds to hypotheses drawn from the null distribution and the other to hypotheses drawn from the alternative distribution. Indeed, there are people crazy enough to attempt to estimate both $G$ and $H$ and $\alpha$ from the same sample! This is often called empirical null modelling and it was essentially pioneered by Prof. Bradley Efron. One of the assumptions to do that kind of modelling is that $\alpha > 0.9$, but I digress. My main point from this paragraph is that you can find a lot of inspiration to answer your question in the multiple testing literature; and I will attempt to do so below. What people actually usually end up assuming in the multiple testing literature is that the distribution under the null hypothesis (say it is $G$) is known. Then, using your notation (i.e. $\hat{F}(x)$ is the ECDF), one can estimate $H$ as follows: $$\hat{H}(x)=\frac{\hat{F}(x)-aG(x)}{1-a}$$ This as you say is unbiased and consistent, but not a distribution function! In one of my favorite preprints , Bodhisattva Sen and Rohit Kumar Patra try to improve the estimation, by imposing exactly the same condition you talked about! In particular, let $X_1, \dotsc, X_n \sim F$ be the observations from $F$ and assume for now that $\alpha$ is known. Then they solve the following optimization problem: $$ \displaystyle\min_{W \text{ CDF}} \sum_{i=1}^n (W(X_i)-\hat{H}(X_i))^2$$ The argmin of the above is our new estimator $\tilde{H}$ which actually is a distribution function! In other words they project the naive estimator $\hat{H}$ onto the space of distribution functions and thus improve estimation. They show that this is a convex problem which can be quickly solved with PAVA (pool-adjacent-violator algorithm) and then derive lots of nice asymptotic properties of this estimator. They also go a bit further and show when and how one can also estimate $\alpha$ when it is unknown (it is not always identifiable) and prove results for that as well, though in your case you already know it. So basically I think you can just apply this method with $G(x)$ replaced by $\hat{G}(x)$. Indeed, because you estimate $G$ based on an independent data-set, I am quite confident that you could also adapt all their asymptotic consistency results to the case where you are also estimating $G$ by its ECDF.
