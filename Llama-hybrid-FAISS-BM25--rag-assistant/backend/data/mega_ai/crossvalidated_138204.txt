[site]: crossvalidated
[post_id]: 138204
[parent_id]: 
[tags]: 
Are PCA components of multivariate Gaussian data statistically independent?

Are PCA components (in principal component analysis) statistically independent if our data is multivariate normally distributed? If so, how can this be demonstrated/proven? I ask because I saw this post , where the top answer states: PCA does not make an explicit Gaussianity assumption. It finds the eigenvectors that maximize the variance explained in the data. The orthogonality of the principal components means that it finds the most uncorrelated components to explain as much variation in the data as possible. For multivariate gaussian distributions, zero correlation between components implies independence which is not true for most distributions. The answer is stated without a proof, and seems to imply that PCA produces independent components if the data is multivariate normal. Specifically, say our data are samples from: $$\mathbf{x} \sim \mathcal N(\mathbf{\mu}, \mathbf{\Sigma})$$ we put $n$ samples of $\mathbf{x}$ into rows of our matrix of samples $\mathbf{X}$, so $\mathbf{X}$ is $n \times m$. Computing the SVD of $\mathbf{X}$ (after centering) yields $$\mathbf{X} = \mathbf{USV}^{T}$$ Can we say that the columns of $\mathbf{U}$ are statistically independent, also then the rows of $\mathbf{V}^T$? Is this true in general, just for $\mathbf{x} \sim \mathcal N(\mathbf{\mu}, \mathbf{\Sigma})$, or not true at all?
