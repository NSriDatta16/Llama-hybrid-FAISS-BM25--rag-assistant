[site]: crossvalidated
[post_id]: 374005
[parent_id]: 
[tags]: 
Feed-forward neural network (MSE and Cross-entropy) questions

Question 1 Why do we divide by the number of data points (N)? I think it's done to minimize the error being back-propagated, but can't we just don't do that and instead decrease the learning rate to decrease the "learning" instead? Question 2 For classification tasks, would it work to apply a softmax activation function to the last (output) layer and then calculate the error using the Mean Squared Error formula? (For the sake of simplicity, cross-entropy is harder compared to MSE)
