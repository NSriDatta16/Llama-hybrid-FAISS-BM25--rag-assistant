[site]: crossvalidated
[post_id]: 562504
[parent_id]: 562442
[tags]: 
There's multiple ways to use (image) augmentation with different machine learning approaches: Approaches that update model parameters in iterations (aka epochs for neural networks): In these, you can for each iteration (or epoch) change the training data e.g. using data augmentation, gradual resizing and so on. Example of algorithms, where this fits, include neural networks, SVMs, most standard regression models and so on. Of course, standard implementations of these algorithms do not typically provide facilities for doing things (except for neural networks). Tree based approaches (e.g. random forest or gradient boosted trees): In these, one can augment the data differently for each tree (or even for each node in a tree). Again, standard implementations of these algorithms do not provide facilities for doing this. One can also augment the training data multiple times and combine these augmented copies of the training data with the original data. This strategy works with just about any machine learning algorithm, but of course will make the dataset substantially larger so that one pass through it will take longer (possibly an issue with e.g. SVMs). The important thing though is that you end up with non-independent records and you need to be careful: E.g. you need to make sure that test- and validation-splits (including for cross-validation) never split different versions of the same image into different parts of a split. Otherwise, you will mis-evaluate performance (often very, very badly) and end up setting the hyperparameters you pick (e.g. via cross-validation) completely wrongly (the algorithm would be rewarded for managing to re-recognize augmented version of an image, instead of "learning" something that generalizes). This usually means manually creating your own (cross-)validation and test splits instead of just relying on some standard parameter for number of validation folds in a call to a model function. Luckily, most standard implementations of models (e.g. scikit-learn etc.) make it easy to specify your own splits. Additionally, you'd ideally want algorithms that involve sampling records or boostrapping them to respect what images are augmented versions of each other. I'm not aware of anything that does this other than for neural networks. I'm also not entirely sure how much this hurts performance, but it probably does a bit. As you can see, there are many options and some are easier to implement with out-of-the-box functions/packages than others, while some approaches would likely involve writing your own implementation of some algorithms. By the way, if you are just not meant to use convolutional neural networks, then there are of course other neural networks that perform about as well, where image augmentation and transfer learning are, again, easy. These include image transformers and multi-layer perceptrons (see e.g. the models covered in the PyTorch image models package).
