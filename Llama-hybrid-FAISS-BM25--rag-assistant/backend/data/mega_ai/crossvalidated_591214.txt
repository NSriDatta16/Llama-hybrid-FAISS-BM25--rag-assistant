[site]: crossvalidated
[post_id]: 591214
[parent_id]: 591202
[tags]: 
So there are two things here, 1. can the chi-squared test be used on data that cannot be represented as a contingency table? 2. what is scikit-learn doing? most commonly, when you search for the chi-squared test, you will find the test on the contingency table, however, the chi-squared is more general, and it refers to any test that uses the chi-squared distribution. With this, you can test the goodness of fit of many different models, not just the contingency table. The most important test here is the likelihood-ratio test, which is also a chi-squared test, because the test statistics should follow the chi-squared distribution. This test compares the goodness of fit of two nested models, and most of your standard tests can be expressed as comparing two nested models and are equivalent to some form. So the chi-squared test can be used to test pretty much anything. It is not uncommon that scikit-learn implements some statistical procedures badly. This is because, as developers say, it is a machine learning library and not a stats library and the developers are also not statisticians but machine learners. And they get a bit rude and defensive when someone points out that something doesn't work as a stats person would expect (at least in the past). Anyway. In the docs for chi2 it says This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes. So it seems like the function is implementing the standard chi-squared test on the contingency tables, and in this case, its use in the iris tutorial would be wrong. I assume, but I am not going to check the code for it, that the function just calculates the chi-squared statistics according to the formula that you would use for the contingency table, but using any feature values.
