[site]: datascience
[post_id]: 36648
[parent_id]: 31994
[tags]: 
I recommend several checks to make sure you get reasonable mAP@IoU scores for object detection API: Try varying the Intersection over Union (IoU) threshold, e.g 0.2-0.5 and see if you get an increase in average precision. You would have to modify matching_iou_threshold parameter in object_detection/utils/object_detection_evaluation.py Try different evaluator classes (the default one is EVAL_DEFAULT_METRIC = 'pascal_voc_detection_metrics' ). If you are training on Open Image Dataset it makes sense to use open_images_V2_detection_metrics Check your eval config file and increase the number of examples used in the evaluation set, e.g. eval_config: { num_examples: 20000 num_visualizations: 16 min_score_threshold: 0.2 # Note: The below line limits the evaluation process to 10 evaluations. # Remove the below line to evaluate indefinitely. max_evals: 1 } Train the object detector for more iterations Check current mAP against reported metrics (e.g. COCO mAP@IoU=0.5):
