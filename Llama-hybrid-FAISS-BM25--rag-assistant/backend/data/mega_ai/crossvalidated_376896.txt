[site]: crossvalidated
[post_id]: 376896
[parent_id]: 
[tags]: 
Polluting a dataset with "non-determinables"

Let's say I'm working on solving sudoku puzzles with machine learning. Now, plenty of good methods exist for solving sudoku algorithmically, no machine learning required, but let's play along to get to the interesting stuff. I train my model on completed sudoku boards, where the outputs are completed boards, and the inputs are the same boards with most of the squares cleared. Now mathematically speaking, if you empty enough squares from the board, you'll lose uniqueness in solutions, ending up with multiple possible completed boards resulting from a given input puzzle. Generating completed sudoku boards is easy, clearing out those boards into puzzles for training is even easier. Figuring out which puzzles no longer have unique solutions is hard. Does it matter? Can I train my model on my generated dataset, knowing that some of the samples are "non-determinables" where I'm only training on one possible solution out of a few solutions possible for that given board? What effect will this have on training rate and accuracy?
