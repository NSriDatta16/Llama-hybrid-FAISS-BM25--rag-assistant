[site]: crossvalidated
[post_id]: 164240
[parent_id]: 164085
[tags]: 
It depends on what you intend by "better fit". Goodness of fit statistics measure deviation from perfect fit in some manner (we'll take it as given - as you assume in your question - that our statistic is organized such that smaller values mean closer fit to the distributional model in the null). Such statistics are sensitive to some kinds of deviation, and may be insensitive to other kinds of deviation. If the kinds of deviation from the hypothesized model that the test statistic is good at picking up are the ones important for you to pick up (for whatever purpose you're testing for), then a smaller value of the statistic does indeed mean the fit is better (in the sense of 'better fit' defined by whatever you're trying to do). If on the other hand there can be important deviations from the hypothesized model that the test statistic is not sensitive to then a smaller value doesn't necessarily mean better fit for your purposes. [Note that since people's purposes may differ, what is a better fit for person 1 may not be a better fit for person 2.] This makes it important to use a statistic that does pick up the sort of deviations that are important for you to pick up -- not just pick one at random. A well chosen statistic will then represent better or worse fit in a specific sense that's directly relevant to you. I'm trying to figure out which distribution is best for a data set of pipe diameters. Since this amounts to the distribution of manufacturing deviations from spec (on top of measurement errors, of course), I believe the data might be normally distributed. There are also historical data which suggest that is usually the case with this particular data set. Do you think that KS is OK for this particular application? No, I don't, for three reasons: Nothing about your hypothesis specifies the parameter values for the normal distribution, and the Kolmogorov-Smirnov test is for a completely specified distribution. While it's possible to use the same statistic for a general goodness of fit test for normality if you calculate new "tables" (a new distribution of the test statistic under H0), at which point you get Lilliefors' test , it's typically less powerful than the Shapiro-Wilk test, so you'd need good reason (such as a specific alternative in mind that it is better at) to choose the Lilliefors. We actually can tell the underlying random variable isnt truly normal right from the start (pipe diameters are positive; manufacturing errors are also bounded, on at least one side). You must already know that before you even collect data. So the question " are these data drawn from a normal distribution? " is one you already know the answer to (no, they're not). Failure to reject would indicate that your sample size was too small to find it.Your actual question is more like " is the underlying distribution close enough to normal for my purposes? ". That question isn't answered by any of these tests, it's nearer to a question about effect size (something more like how non-normal is the distribution and in what ways? ). [You might discern that many times that people test goodness of fit, they're not really addressing the question they need answered. One of many posts that have some discussion of issues like that is here .] If you have a specific reason for wanting to check normality, that underlying reason may also tend to suggest ways to check its plausibility for that purpose. So why do you need to know these values are from a normal distribution? I'm trying to calculate a failure probability for this data set. So I have several variables (of which pipe diameter is one), a failure model (a formula that takes in these variables and outputs a resistance value) and some load cases, which allows me (in theory) to describe the joint distribution of the pipe resistance. In order to do that, I'd need to describe each of those variables' data sets. Hence the search for the distribution that best describes these data No simple-form distribution is likely to 'best describe' your data -- real data are nearly always more complex than our simple models. To quote George Box -- Remember that all models are wrong; the practical question is how wrong do they have to be to not be useful -- George Box & Norman R. Draper, Empirical Model-Building and Response Surfaces (we can guess these are Box's words rather than Draper's because he's said very similar things elsewhere) The relevant issue for you seems to be whether your model would be enable you to calculate failure probability accurately enough for your purposes. I see no reason why you'd use a goodness of fit test for any part of that, since a goodness of fit test simply doesn't address that issue . (followup to discussion) One way to assess the sensitivity to any assumed distribution for inputs in some Monte Carlo simulation of failure rates is to assume some other distribution is the real situation, simulate "real data" from that and see how much your assumption (including any fitting you're doing) affects the results of your subsequent Monte Carlo.
