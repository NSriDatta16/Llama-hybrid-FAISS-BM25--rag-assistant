[site]: crossvalidated
[post_id]: 350594
[parent_id]: 
[tags]: 
Making sense of AICc ranking vs. R2 and standardized coefficients

Mixed/hierarchical models and model ranking is fairly new to me. I'm just wondering if someone can help me make a little more sense out of this.... I used the lmer() to build 7 linear mixed effects models, which are a combination of 3 (scaled) continuous fixed effects. Each model includes a random intercept and random slope effect for two different factors. I've ranked my models using AICc to determine which model, relative to the others, best explains my data, and which predictor variable is most important. I've also computed the marginal and conditional R2 values to assess relative fit, and to determine variance explained by the fixed effects as well as the model as a whole. I'm mostly interested in the fixed effects, but I want to determine which of the 7 models best predicts/explains the variance observed in my independent variable. In addition to presenting the AICc (w and delta also) and R2 values, I've presented the standardized coefficients to show the relative effect size of each predictor variable. I've read through a few different threads now, but I'm still a little unclear as to (1) whether or not it is appropriate to use the standardized coefficients to show relative effect (should I just model average?); and (2) why I would see predictor variables with larger standard coefficients in models ranked lower? The models with predictor variables with larger standard coefficients also have larger marginal R2 values, but yet are still ranked lower. The best model might not include the predictors which explain the largest amount of variance? Any insight or help would be appreciated!
