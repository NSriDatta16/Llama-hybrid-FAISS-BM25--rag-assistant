[site]: datascience
[post_id]: 126395
[parent_id]: 
[tags]: 
how does sigmoid activation implementation in tensorflow works?

I am running the following mnist implementation: import tensorflow as tf from tensorflow.keras import layers, models from tensorflow.keras.datasets import mnist from tensorflow.keras.utils import to_categorical from tensorflow.keras.callbacks import LambdaCallback # Load and preprocess the MNIST dataset (train_images, train_labels), (test_images, test_labels) = mnist.load_data() train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255 test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255 train_labels = to_categorical(train_labels) test_labels = to_categorical(test_labels) # Build the neural network model model = models.Sequential() model.add(layers.Flatten(input_shape=(28, 28, 1))) # Add hidden layers with sigmoid activation model.add(layers.Dense(256, activation='sigmoid')) model.add(layers.Dense(128, activation='sigmoid')) model.add(layers.Dense(64, activation='sigmoid')) # Output layer with 10 units for 10 classes and softmax activation model.add(layers.Dense(10, activation='softmax')) # Compile the model model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Define a callback to print the weighted sum of each neuron in the hidden layer during training def log_hidden_layer_info(epoch, logs): hidden_layer_weights = model.layers[1].get_weights()[0] # Weights of the first hidden layer hidden_layer_biases = model.layers[1].get_weights()[1] # Biases of the first hidden layer hidden_layer_outputs = model.layers[1].output # Adjust index based on the layer you want to inspect hidden_layer_model = tf.keras.Model(inputs=model.input, outputs=hidden_layer_outputs) sample_image = train_images[0:1] activations = hidden_layer_model.predict(sample_image) for i in range(hidden_layer_weights.shape[1]): weighted_sum = (activations * hidden_layer_weights[:, i:i + 1]).sum() + hidden_layer_biases[i] print(f'Epoch {epoch + 1}, Neuron {i + 1} - Weighted Sum: {weighted_sum}, Activation: {activations[0][i]}') log_callback = LambdaCallback(on_epoch_end=log_hidden_layer_info) # Train the model with the callback model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2, callbacks=[log_callback]) # Evaluate the model on the test set test_loss, test_acc = model.evaluate(test_images, test_labels) print(f'Test accuracy: {test_acc}') As you can see I print both weighted sum for a hidden layer and the activation result (which I assume is sigmoid operates on the weighted sum) I get the following output: ... Epoch 10, Neuron 14 - Weighted Sum: 4576.98388671875, Activation: 0.9452044367790222 Epoch 10, Neuron 15 - Weighted Sum: 275.4674072265625, Activation: 0.9996762871742249 Epoch 10, Neuron 16 - Weighted Sum: -789.8799438476562, Activation: 0.04697105288505554 Epoch 10, Neuron 17 - Weighted Sum: -2768.070556640625, Activation: 0.11655014753341675 Epoch 10, Neuron 18 - Weighted Sum: 1269.995849609375, Activation: 0.7969928979873657 Epoch 10, Neuron 19 - Weighted Sum: -1751.06103515625, Activation: 0.8819616436958313 Epoch 10, Neuron 20 - Weighted Sum: -3794.892578125, Activation: 0.0007617903756909072 ... I can't figure out the results because sigmoid(-3794.892578125) is almost 0, but sigmoid(-1751.06103515625) should also be almost 0. Also, sigmoid(275.4674072265625) should be close to 1 (0.9996762871742249 above), but sigmoid(1269.995849609375) is 0.7969928979873657, and sigmoid(4576.98388671875) is 0.9452044367790222, how come? Can anyone explain how does it work?
