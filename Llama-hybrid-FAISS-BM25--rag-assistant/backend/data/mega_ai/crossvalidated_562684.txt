[site]: crossvalidated
[post_id]: 562684
[parent_id]: 
[tags]: 
Why is my AR forecast better than my ARIMA forecast even though data is I(1)

I am trying to build a time series model for forecasting. The time plot of the data is as shown Evidently, there is a trend component and the series is not stationary. As the interest is in forecasting, I did a 90/10 train-test split (i.e., to forecast and compare with the last 10% of data). After performing a first difference on the train set, and executing Augmented Dickey Fuller (ADF) test, the differenced series is stationary. Upon trying various orders of p and q of AR and MA respectively, the model with the lowest AIC suggests p to be 2 and q to be 0 (i.e., ARIMA(2,1,0) model). The forecast of the ARIMA(2,1,0) model is as shown and the MSE is 53.33. However, I have also tried forecasting with ARIMA(2,0,0) model and the results is as shown and the MSE is 7.08, which is much much better than the ARIMA(2,1,0) model. Why would the ARIMA(2,0,0) model outperform the ARIMA(2,1,0) when differencing is required? I have also looked into the model diagnostic, e.g., Ljung-Box statistic and ACF of residuals to ensure that the model does not violate relevant assumptions. Any help would be greatly appreciated.
