[site]: crossvalidated
[post_id]: 428665
[parent_id]: 428662
[tags]: 
If the 3 classifiers all make the same mistakes, then their joint precision is approximately the mean of their individual precisions. If the 3 classifiers all make completely different sets of mistakes, then their joint precision may be much higher than the mean. Imagine the case where each individual mistake is only made once by a single classifier, whereas the other two classifiers don't make that mistake. In that case, you could argue the joint precision is 100%, depending on how you are defining 'average precision', even though all the classifiers have less than 100% precision. The difference between the mean of the individual precisions, and the precision of the ensemble should be informative as to the degree of independence between the mistakes made by the different classifiers.
