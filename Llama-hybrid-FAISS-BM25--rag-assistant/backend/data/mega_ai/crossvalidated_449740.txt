[site]: crossvalidated
[post_id]: 449740
[parent_id]: 449733
[tags]: 
No, there is no connection between the two. The backfitting algorithm that is used to fit GAMs, iteratively improves the estimator $\hat {f_j}$ by subtracting the contribution of each predictor $j$ from the response $y$ that is influenced by all, say ' $p$ ' predictors, followed by smoothing using optimal bandwidth, which is yet solving a linear equation although you are working with a nonlinear $f_j$ . On the other hand, backpropagation algorithm which is used to find weights in a neural network works through by computing gradients(derivatives, these do not exist for the linear equation that backfitting is solving) of non-linear functions and propagating the results via chain rule. Hope it helps!
