[site]: crossvalidated
[post_id]: 573166
[parent_id]: 
[tags]: 
Find combination of time-dependent values that shows largest anomaly after event

What I have are timeseries of about 500 variables (which are more or less correlated to each other). The variables refer to standardized anomalies (mean=0, std=1). I now define certain event dates in the timeseries. I look at the average for each of the variables before, during and after these events. Some variables show zero anomaly during the defined events, indicating that the events do not impact the variable. Other variables show large anomalies during the defined events, indicating that there is a physical relation between the event and the variable. What I aim for is dimensionality reduction. I do not want to display the evolution of 500 variables during the defined events. I want to have a single index, that is being computed by, e.g., averaging a certain subset of variables. The index should show the largest possible anomaly during the defined events. In that way, it should capture the "fingerprint" of the events in a best possible way. Example Illustration : Assume given variables v1, v2, ..., v500. Say, an index i1 is defined as the average of variables v2, v40 and v371. During the events, i1 shows an average anomaly of +2 standard deviations. A different index i2 is defined as the average over variables v1, v3, v5, v7, ..., v499. Index i2 shows an average anomaly of +3 standard deviations during the defined events. Index i2 better captures the fingerprint of the events than index i1. Is there a systematic way to come up with the best definition of an index, with respect to the defined events?
