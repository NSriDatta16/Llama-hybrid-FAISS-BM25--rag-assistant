[site]: crossvalidated
[post_id]: 605485
[parent_id]: 605474
[tags]: 
Firstly, the default is in many prediction situations pretty good. It's an improvement over solely imputing e.g. a mean or median and having a special 0-1 variable for whether the value was missing (because both approaches more or less do the same thing/have the same limitations, but the LightGBM default requires fewer splits in trees to capture the predictive value of missingness). Secondly, where more sophisticated imputation will outperform the approach is when you understand something about the data generating mechanism. E.g. imagine you are trying to learn a linear relationship like $Y_i = \beta_0 + \beta_1 \times X_i + \beta_2 Z_i + \epsilon_i$ , that any value of $X_i$ that is $>x_\max$ gets set to missing and that $X_i$ and $Z_i$ are somewhat weakly or moderately correlated. This is a situation, where you'd expect something like a multiple imputation that captures that the the missing values must be $>x_\max$ + fitting LightGBM to each imputation (and then in the end averaging the predictions across models) to outperform the default handling in LightGBM by a good bit. EDIT/ADDITION: Illustrative example In the example that follows what I described above, the default imputation actually does a bit better than a single value imputation to a value above the censoring threshold (that surprised me a bit), but both areoutperformed by multiple imputation using our knowledge of the problem at hand. The RMSE results with 90% CIs are below: approach rmse rmse.lcl rmse.ucl 1 1.741364 1.734353 1.748346 2 1.769537 1.762528 1.776518 3 1.727564 1.720581 1.734519 Of course, you could repeat this simulation several times and see what you find. Here's the code for this: library(tidyverse) library(lightgbm) cut_point % mutate(x = ifelse(x>cut_point, NA_real_, x)) %>% dplyr::select(y, x, z) } set.seed(123) # Simulate a lot of training and test data train_data % dplyr::select(x,z) %>% as.matrix(), label = train_data %>% pull(y)) lgb.cveval1 % dplyr::select(x,z) %>% mutate(x=ifelse(is.na(x),cut_point+0.1,x)) %>% as.matrix(), label = train_data %>% pull(y)) lgb.cveval2 % dplyr::select(x,z) %>% mutate(censor = ifelse(is.na(x), "right", "none"), lbx = -Inf, x = ifelse(is.na(x), cut_point, x))) imputations % filter(is.na(x)) %>% dplyr::select(z) %>% mutate(censor = "none", lbx = cut_point), summary = F) test_imputations % filter(is.na(x)) %>% dplyr::select(z) %>% mutate(censor = "none", lbx = cut_point), summary = F) test_preds % filter(is.na(x)) %>% dplyr::select(-x) %>% bind_cols(tibble(x=imputations[imputation,])) %>% bind_rows(train_data %>% filter(!is.na(x))) dtrain3 % dplyr::select(x,z) %>% as.matrix(), label = tmp_train %>% pull(y)) if (imputation==1){ lgb.cveval3 % filter(is.na(x)) %>% dplyr::select(-x) %>% bind_cols(tibble(x=test_imputations[imputation,])) %>% bind_rows(test_data %>% filter(!is.na(x))) test_preds[[imputation]] % dplyr::select(x,z) %>% as.matrix()) } avg_test_preds % dplyr::select(x,z) %>% as.matrix()), y = test_data $y) %>% bind_rows( tibble(approach=2, predy=predict(lgb.model2, test_data %>% dplyr::select(x,z) %>% mutate(x=ifelse(is.na(x), cut_point+0.1, x)) %>% as.matrix()), y=test_data$ y)) %>% bind_rows( tibble(approach=3, predy=avg_test_preds, y=tmp_test$y)) %>% group_by(approach) %>% summarize(rmse = sqrt(mean( (predy-y)^2)), rmse.lcl = sqrt( rmse^2 - sd( (predy-y)^2 ) / sqrt(n()) * qnorm(0.95) ), rmse.ucl = sqrt( rmse^2 + sd( (predy-y)^2 ) / sqrt(n()) * qnorm(0.95) )) %>% data.frame()
