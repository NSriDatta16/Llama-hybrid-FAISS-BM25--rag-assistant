[site]: crossvalidated
[post_id]: 112479
[parent_id]: 
[tags]: 
Does the parameter change during data generation in Bayesian Inference?

Let's assume that we have the following graphical model: This graph encodes the joint distribution $P(p,x_1,x_2,x_3,x_4) = P(p)\prod_{i=1}^{4}P(x_i|p)$. In the Bayesian inference, if we know $x_1,x_2,x_3$ then a full Bayesian predictive posterior for $x_4$ is given as: $$ P(x_4|x_3,x_2,x_1) = \int_{p}P(x_4|p)P(p|x_3,x_2,x_1)dp$$ I used to interpret a model like in the above as follows: Some probabilistic system picks a $p$ from $P(p)$. Then this picked $p$ generates data as $x_1\sim P(x_1|p),x_2\sim P(x_2|p),x_3\sim P(x_3|p)$. We do not know the true value of $p$ and therefore we integrate over all possible values of $p$ using its posterior distribution given the data in order to obtain the posterior predictive distribution of $x_4$. In this interpretation, the value of $p$ stays the same once it is picked from the prior, during the data generation. But our lack of knowledge about it leads us to integrate over its all possible values in order to infer $x_4$. This can be considered as a generative model. My question is, is my interpretation correct here? I am asking this, because I have seen some sources on web which imply that $p$ changes during generating $x_i$s. If it were that way, shouldn't each of these different values be named as different random variables like $p_1$ for $x_1$, $p_2$ for $x_2$, etc. ? This has greatly confused me. I appreciate any comments.
