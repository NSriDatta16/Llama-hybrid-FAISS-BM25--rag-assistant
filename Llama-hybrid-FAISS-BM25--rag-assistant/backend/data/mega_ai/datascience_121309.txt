[site]: datascience
[post_id]: 121309
[parent_id]: 78054
[tags]: 
Did you try weighted binary cross entropy? In this method, you assign different weights to the positive and negative samples during training. You can assign higher weights to the positive samples to make the model more sensitive to them. The idea is to penalize misclassifications of the positive class more heavily. You could even try ensemble methods. Training multiple models and combining their predictions can often lead to better performance. You can train multiple models using different random seeds or with different configurations and then average their predictions or use more sophisticated ensemble techniques.
