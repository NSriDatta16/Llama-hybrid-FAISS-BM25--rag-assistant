[site]: crossvalidated
[post_id]: 610118
[parent_id]: 
[tags]: 
I need to get 100% accuracy on my training data

I know this is undesirable in most cases, but I have a very niche case where I must achieve 100% accuracy on training data. I do not care about unseen points, I only care about given X points what is the Y value for each point. I will train the model before hand but I must get 100% accuracy guaranteed. Some knowledge I know about the data: The data is always increasing (its sorted). It is not increasing at a specific rate, it could be random from point to another. The data comes in chunks, I do not have all the data right away. I can not store the data at all, the moment I get a chunk, it will be deleted. I can probably temporarily store it before the next data comes but can't store it long. Each chunk is roughly about 100MB in size. I can store some information about chunk 1 if needed, such as max, min, average, etc... I can analyze it and store anything from the analytics. Example: Assume chunk 1 arrives at minute 0, then at minute 2 chunk 2 arrives but chunk 1 is gone. Days later I will receive the exact same data, 100% the same. I will receive it in the same order and same sized chunks. My goal is to predict the result for each value in the chunk at a 100% accuracy given that the data was seen before. What I have tried: Obvious solution is to store a mapping between the input and their corresponding values, but again this is impossible because it would require me to store the data when it is impossible for me to store. I used different types of trendlines; But this fails miserably as the error is huge, plus it requires me to create a different trendline for each chunk (I don't mind but not preferred) As I am researching I cam across Lagrange Polynomial which sounded very promising. But with more research I found out that I can not use it because it requires all of the data to already exist before I can "predict" the point I am looking for, which obviously defeats the purpose. Unless I have understood it wrong, or misusing it. I have been researching but can't find much information since most use cases do not require a a use case where you get 100% on training data, it is usually considered a bad practice because of "overfitting". I have also tried different things but none worked, so I finally came to the conclusion that maybe I could train an AI model? But really not sure where to start to be able to get 100% accuracy on training data. I am open to using tensorflow or any other tools. I am basically open for any leads to solve this issue.
