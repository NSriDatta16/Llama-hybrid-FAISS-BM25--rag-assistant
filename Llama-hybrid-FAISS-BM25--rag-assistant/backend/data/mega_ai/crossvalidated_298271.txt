[site]: crossvalidated
[post_id]: 298271
[parent_id]: 264851
[tags]: 
I would offer a different perspective: I believe ML estimation CAN be used to test for mediation. This is a trick I thought of which gets Sobel's test statistic from a linear model. The trick is the following: suppose you have a dataset with an outcome Y, an exposure of interest X, and a mediating variable M. These variables are related via a conditional linear model that satisfies: $E[Y|X,M] = \beta_0 + \beta_1 X + \beta_2 M$, as well as the marginal linear model $E[Y|X] = \gamma_0 + \gamma_1 X$. The assumption of "no mediation" is specifically that $\beta_1 = \gamma_1$. In R , you can get an approximate result with LM by duplicating the dataset and using an indicator for fitting the conditional and marginal model. For instance, using the mediation example from lavaan : set.seed(1234) X Obtains the following result for the derived parameter ab (the product-path coefficient ala Baron and Kenny); Defined parameters: Estimate Std.err Z-value P(>|z|) ab 0.374 0.092 4.059 0.000 (really the p should be The linear model can be obtained: Data2 by not including the main effect for the M:ind product term, the product term x:ind is the difference of coefficients between the marginal and conditional model (reversed, but that is correctable). Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 0.19287 0.11350 1.699 0.090857 . X 0.40995 0.11220 3.654 0.000332 *** ind -0.02929 0.16057 -0.182 0.855448 X:ind -0.37360 0.16690 -2.238 0.026326 * ind:M 0.78832 0.10922 7.218 1.15e-11 *** You'll notice however the inference is quite different, still significant but much less precise. This is because the standard errors are the average of the two models. We know theoretically that the conditional model must have smaller standard errors if the design matrix is non-singular. To permit this, we must fit two regression models, obtain their log likelihoods and add them across, then fit the "reduced" model where the $\beta_1$ and $\gamma_1$ are a common coefficient. Estimating that common coefficient is tricky, but if you aim to do it with ML, there may be estimating equations but I'm too lazy to write them down and did it numerically. negLogLik1 The test statistic then is 5.2 which follows a chi-square distribution with 1 degree of freedom. Comparing this to the Z value for the lavaan test, which was a normal test statistic of 4, we see the SEM is much more powerful here. This got me thinking about a whole other way of testing linear models where a referent dataset is duplicated, data are simulated under the specific set of causal assumptions, and a likelihood ratio test can be produced under a wide set of conditions... but I digress.
