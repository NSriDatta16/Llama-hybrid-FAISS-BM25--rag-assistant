[site]: crossvalidated
[post_id]: 270092
[parent_id]: 
[tags]: 
Independence in gene set enrichment testing

Edit: I apologize if the question is considered to broad. In fact, it is concerning a very specific task in bioinformatic analysis of high throughput data set, and in my opinion the problem presented here, albeit not formulated formally, is very specific. In HT data sets in biology, such as transcriptome profiles, very frequently we have a large number of variables (e.g. genes) which are somehow measured. The results of an experiment provide us with lists of significantly regulated genes which often include thousands of variables that, after correction for multiple testing, still show a significant difference. To interpret such results biologists often use a technique called "gene set enrichment analysis". Variables such as genes can be grouped a priori into sets which share a common biological mechanism (for example, genes stimulated by interferon). We now ask the question, which sets of genes are significantly enriched among the genes that are differentially expressed. The simplest (but not optimal) way to test it statistically is to use a contingency table (gene in set / gene not in set vs gene significantly regulated / gene not significantly regulated) and a suitable test such as hypergeometric test. However, there is not a single gene set that we test, but a number of them. And, worse, these sets include often the same genes; for example, different diseases may result in the same genes being up-regulated, so gene sets defined for these diseases will overlap. A core practical problem in testing for significant gene set enrichment¹ is that many gene sets overlap to a large extent. For example, the gene sets A and B which are characteristically enriched in diseases A and B may both include interferon inducible genes -- therefore, both sets will be enriched in any condition that involves interferon induction. This of course has statistical problems -- if the tests on different gene sets are not independent, how can we use an FDR or FWER correction that assumes independence? And yet, this is what is usually done. This poses also a practical problem for the person interpreting the results: I get 100 significant gene sets, however only one handful of genes driving that response in all of the genes. One way of solving this problem has been implemented in the hyperGTest by Falcon and Gentleman ( R package GOstats ). Here, the gene set analysis is performed several times. Given the hierarchical structure of gene sets defined by GO terms, for each given node, the test is performed only using the genes that were not present in any significantly enriched children of a given node: When ’conditional(p) == TRUE’, the ’hyperGTest’ function uses the structure of the GO graph to estimate for each term whether or not there is evidence beyond that which is provided by the term’s children to call the term in question statistically overrepresented. The algorithm conditions on all child terms that are themselves significant at the specified p-value cutoff. Given a subgraph of one of the three GO ontologies, the terms with no child categories are tested first. Next the nodes whose children have already been tested are tested. If any of a given node’s children tested significant, the appropriate conditioning is performed. This heuristics gives, from the point of view of a biologist, results which are much more easily interpreted -- boring repetitions are avoided; if B is significant, then A is reported only if there is additional information in A not already contained in B. My questions: What is the validity of the above procedure from a purely statistical point of view? Given no hierarchical structure, how could one implement such a heuristics? Not being a bayesian statistician myself, given that what I am interested in is a measure of novel information provided by a set of genes, I imagine a bayesian approach could be a way to go. Any hints are welcome! ¹ there exists a range of statistical tests used, including U-test, hypergeometric testing, ANOVA variants, randomization tests and many more. The issue I am describing here remains for most if not all of them.
