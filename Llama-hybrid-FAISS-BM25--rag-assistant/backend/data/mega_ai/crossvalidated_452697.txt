[site]: crossvalidated
[post_id]: 452697
[parent_id]: 
[tags]: 
Are features in Random Forest sampled with replacement

My understanding from the sklearn random forest classifier documentation is that at every node, a new sample of m features are sampled from a total of M. Some criterion is computed for each of them and the best one is selected to split on. My question is, are these features sampled with replacement? Here they say they do Random forest tree growing algorithm and to stop at some number of samples in a leaf to be able to detect some relationships, but the default value for the min samples leaf parameter in the sklearn implementation is 1. If this is the case why would you split on the same feature twice? My guess would be that they are not, such that at every node a new feature sample of size m is taken from M removed with all features previously split on, hence every tree wil either grow to depth of max M or stop once every leaf node is pure. Which one of the two is it?
