[site]: crossvalidated
[post_id]: 480973
[parent_id]: 
[tags]: 
Changing representation in deep neural network

Say I have a neural net that outputs a vector of length 4 such as: [0, 1, 2, 3] Now say that the only way to calculate the loss is to convert this output to a one-hot vector matrix and pass that into the loss function: [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]] This is a hypothetical question (obviously the answer to this question wouldn't be to the aforementioned scenario, but to another more realistic, relevant one). So, once we have calculated the loss using the one-hot vector matrix, is it still possible to back propogate and train the network even though there were two different representations used. A more general question would be, if I convert representations from the output of the neural net to the loss function ( output of neural net => some representation conversion => loss function), is it still possible to back propogate and optimize?
