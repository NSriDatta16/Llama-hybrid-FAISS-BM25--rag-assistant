[site]: crossvalidated
[post_id]: 242065
[parent_id]: 193492
[tags]: 
DISCLAIMER : This answer is incomplete, but I don't have time to make it current right now. I hope to work on it later this week. Question: what were the state-of-the-art methods of solving genera problems of predicting from data circa 1969? Note: this is not going to repeat the excellent answer by 'Matt Krause'. "State of the Art" means "best and most modern" but not necessarily reduced to practice as an industry norm. In contrast, US Patent law looks for "non-obvious" as defined by "ordinary skill in the art". The "state of the art" for 1969 was likely put into patents over the next decade. It is extremely likely that the "best and brightest" approaches of 1969 were used or evaluated for use in ECHELON (1) (2) . It will also show in evaluation of the other, quite mathematically capable superpower of the era, the USSR. (3) I takes several years to fabricate a satellite, and so one would also expect that the technology or content for the next ~5 years of communication, telemetry, or reconnaissance satellites to show the state of the art of 1969. One example is the Meteor-2 weather satellite started in 1967 and with preliminary design completed in 1971. (4) The spectrometric and actinometric payloads engineering is informed by the data-processing capabilities of the day, and by the envisioned "near-future" data handling of the time. The processing of this sort of data is where to look for best practices of the period. A perusal of the "Journal of Optimization Theory and Applications" had been operating for several years and has its contents accessible. (5) Consider this (6) evaluation of optimal estimators, and this one for recursive estimators. (7) The SETI project, started in the 1970's, was likely using lower budget technology and techniques that were older to fit the technology of the time. Exploration of the early SETI techniques can also speak to what was considered leading around 1969. One likely candidate is the precurser to " suitcase SETI ". The "suitcase SETI" used DSP to build autocorrelation receivers in ~130k narrow-band channels. The SETI folks were particularly looking to perform spectrum analysis. The approach was first used offline to process Aricebo data. It was later connected it to the Aricebo radio telescope in 1978 for live data and result were published the same year . The actual Suitecase-SETI was completed in 1982. Here (link) is a block diagram showing the process. The approach was to use off-line long-Fourier transforms (~64k samples) to search bandwidth segments including handling chirp, and real-time compensation for Doppler shift. The approach is "not new" and references were provided including: See, for instance, A. G. W. Cameron, Ed., In- terstellar Communication (Benjamin, New York,1963); I. S. Shklovskii and C. Sagan, In-telligent Life in the Universe (Holden-Day, San Francisco, 1966); C. Sagan, Ed., Communication with Extraterrestrial Intelligence (MIT Press, Cambridge, Mass., 1973); P. Morrison, J. B. M. Oliver and J. Billingham, "Project Cyclops: A Design Study of a System for Detecting Extraterrestrial Intelligent Life," NASA Contract. Rep. CR114445 (1973). Tools used for prediction of the next state given the previous state that were popular at the time include: Kalman (and derivative) filters (Weiner, Bucy, nonlinear...) Time series (and derivative) methods Frequency domain methods (Fourier) including filtering, and amplification Common "keywords" (or buzz-words) include "adjoint, variational, gradient, optimal, second order, and conjugate". The premise of a Kalman filter is optimal mixing of real world data with an analytic and predictive model. They were used for making things like missiles hit a moving target.
