[site]: crossvalidated
[post_id]: 215034
[parent_id]: 
[tags]: 
Bayesian errors-in-variables model definition in JAGS and symbolically

I'm fairly new to probability theory and am attempting to understand and implement an errors-in-variables simple linear regression model. I am assuming a model of the form $$ Y=\theta X_a+\epsilon_Y \\ X_a=X_o+\epsilon_X $$ where $X_a$ is the true (unknown) covariate and $X_o$ is the covariate observed with error. This r-bloggers post describes the JAGS model that seems to fit the bill: model { ## Priors alpha ~ dnorm(0, .001) beta ~ dnorm(0, .001) sdy ~ dunif(0, 100) tauy What is unclear to me is how exactly this JAGS model would be expressed in probability notation. According to Bayes' Rule, my intuition of the high-level form of the model I want is $$ P(\theta,X_a|Y,X_o)\propto P(Y,X_o|\theta, X_a) P(\theta,X_a), $$ since $\theta$ and $X_a$ are both dependent on the data $Y$ and $X_o$. How can this be expressed in simpler terms? How would the above JAGS model be expressed symbolically as Bayes' Rule? EDIT: Clarity
