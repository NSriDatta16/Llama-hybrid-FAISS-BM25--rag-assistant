[site]: crossvalidated
[post_id]: 610687
[parent_id]: 
[tags]: 
Bayesian update for sequential coin toss

I'm trying to calculate the posterior probability of a coin toss resulting in "heads". We assume the uniform distribution of the prior $p(\theta)=1,\theta\in[0,1]$ . Now suppose we toss a coin the first time and see "heads". The posterior distribution after the first toss is: $p(\theta|heads)=\frac{p(\theta) p(heads|\theta)}{\int_0^1 p(\theta)p(heads|\theta) \, d\theta }=\frac{\theta }{\frac{1}{2}}=2 \theta$ Looks ok. Now I update my prior to $p(\theta)=2\theta$ , make the second toss and see "tails". To calculate the posterior for the second experiment I do: $p (\theta |tails)=\frac{p(\theta) p (tails|\theta ))}{\int_0^1 p(\theta) p (tails|\theta )) \, d\theta }=-\frac{2 (1-2 \theta ) \theta }{\frac{1}{3}}=-6 (1-2 \theta ) \theta$ Which is incorrect, because $-6 (1-2 \theta ) \theta$ has negative values if $0 . What is wrong with my calculations?
