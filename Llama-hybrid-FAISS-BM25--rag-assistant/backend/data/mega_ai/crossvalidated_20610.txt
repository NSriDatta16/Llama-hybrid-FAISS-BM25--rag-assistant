[site]: crossvalidated
[post_id]: 20610
[parent_id]: 20608
[tags]: 
One way is to inspect the covariance matrix, $\Sigma$, of your parameter estimates. If two parameter estimates are perfectly (approximately) correlated with each other or one parameter estimate is a (approximately) linear combination of several others, then your model is not identified; the parameters that are functions of the others are not necessary. In each of these cases, $\Sigma$ will also be (approximately) singular. So, if $\Sigma$ is approximately singular, this may give you reason to be concerned about identifiability issues. (Although I don't think this would detect non-linear relationships between parameter estimates that would give rise to non-identifiability). The practical problem is that it is often difficult to calculate $\Sigma$ for even mildly complicated models. If you are doing a maximum likelihood problem, then you know the asymptotic covariance matrix of your estimates is equal to the inverse of the fisher information evaluated at the MLE. So, checking the fisher information matrix for (approximate) singularity is also a reasonable way of assessing identifiability. This also works where the theoretical fisher information is difficult to calculate because it is often possible to very accurately numerically approximate a consistent estimator of the fisher information matrix by, for example, estimating the expected outer product of the score function by the observed average outer product. In you are not doing an ML problem then you may be able to get a handle on $\Sigma$ by simulating data from the model and estimating parameters a large number of times and calculating a sample covariance matrix.
