[site]: crossvalidated
[post_id]: 224926
[parent_id]: 224904
[tags]: 
(answer was updated to mention HEP) Given that question author's background I'm assuming this question is about high energy physics (HEP). In HEP we need unbiased quality estimation and we want to make use of all available data (since for many analyses amount of available data is very limited) at the same time. That is why in HEP we often use k-folding scheme: divide data into k folds train k classifiers on k-1 folds of data predict i-th fold of data by i-th classifier, which is not trained on this i-th fold Then using the same data, which now are marked, we estimate quality (we want to preserve as much as possible statistics for estimation, that is why i.e. we don't divide data into training and test parts). After that we need to apply the model to data from collider to compare quality: expected and observed (we test hypothesis if we have in data from collider searched decay). The answer below should be considered in the context of HEP above problem. If you use stable models and have enough data samples then the distributions of the classifiers' outputs for signal and background events will be very similar across all folds (assuming you use the same parameters for all classifiers in the folding scheme). During new data prediction, which didn't take part in the training process, it is a bad idea just to use any of the classifiers from folding scheme. In this case efficiency for chosen threshold will be overestimated or underestimated (due to the reasons you named). There are two ways of predicting new data: Predict a sample by all classifiers in the folding scheme, take the average. This gives you reliable stable prediction for a new sample. Take a random trained classifier from the folding scheme set of the classifiers. This is equivalent to divide new data into k-folds and predict each fold by only one classifier, like the training sample. In my practice in rare decays analyzes to preserve data as much as possible we use folding scheme and predict new data the second way. In this case the same model is applied to the training and test sample and thus we will have correct quality estimation on the test sample for different measures like efficiency (thus single threshold is chosen for all classifiers).
