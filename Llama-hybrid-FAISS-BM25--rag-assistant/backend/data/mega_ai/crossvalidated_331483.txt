[site]: crossvalidated
[post_id]: 331483
[parent_id]: 
[tags]: 
Taking into account dependencies in Bayesian model selection

Each member of a small group composed of 10 men and 10 women answered a long questionnaire. The questionnaire is made of numerous (e.g., 1000) two-choice questions about preferences such as ‘ blue or green? ’, ‘ Seinfeld or Friends? ’ and so on. Given the responses of a new participant to the same questionnaire, we’d like to estimate the probability that this participant is a woman. How should this be done? Below is my novice attempt at applying a Bayesian model selection approach and where it fails (tl;dr - inter-item correlations are hard to account for). Bayes tells us that: $p(Woman|Responses)=\frac{p(Responses|Woman)P(Woman)}{p(Responses|Woman)p(Woman)+p(Responses|Man)p(Man)}$ So the critical ingredient are the likelihood probability functions $p(Responses|Woman)$ and $p(Responses|Man)$). We'll try to build this up from the likelihood of a particular response - e.g., $p(Seinfeld|Woman)$. Since we had only 20 participants, we can’t safely use the ratio of Seinfeld responses among the 10 women as a Bernoulli success probability $p_{Seinfeld;Woman}$ (the probability of responding Seinfeld given the participant is a woman) - due to the small sample size, there's uncertainty about this ratio in the population. However, if we assume a uniform prior (beta distribution with $\alpha=1$ and $\beta=1$) over the $p_{Seinfeld;Woman}$, then the Posterior Predictive Distribution is Bernoulli distributed with $p_{Seinfeld;Woman}=\frac{n_{Seinfeld;Woman}+1}{n_{Seinfeld;Woman}+n_{Friends;Woman}+2}$ (the $n$'s are the counts of ' Seinfeld ' and ' Friends ' responses among our 10 women). So we have an analytic solution for $p(Seinfeld|Woman)$. But how do we get from that to $p(Responses|Woman)$? Simply taking the product of the individual responses unwarrantably assumes independence between items. In other words, $p(Responses|Woman)=\prod_\limits{i}p(Response_{i}|Woman)$ is not necessarily correct. To illustrate this issue, let's suppose that the responses to the question ‘ Breaking Bad or The Sopranos ’ are perfectly correlated with the responses to ‘ Seinfeld or Friends ’. Then, collecting the responses to the two questions won't increase the evidence compared with collecting a single response, yet the multiplication of individual item probability erroneously assumes it does. This might lead to over-confidence of our model's decision. So how inter-item dependencies should be taken into account? Explicitly modeling the 1000x1000 correlation matrix seems somewhat impractical. And even if it’s feasible for this binary case, it doesn’t seem to be scalable to the more general multinomial case (consider questions like ' Seinfeld, Friends, Cheers or Frasier? '). The only solution that comes to my mind is calibrating the probability estimate resulting from the product using a logistic regression fitted in some cross-validation scheme. Any better ideas? Alternative approaches? Can a non-parametric model save the day?
