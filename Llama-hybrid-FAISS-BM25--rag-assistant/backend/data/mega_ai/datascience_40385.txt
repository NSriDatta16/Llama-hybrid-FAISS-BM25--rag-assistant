[site]: datascience
[post_id]: 40385
[parent_id]: 
[tags]: 
Why is my VGG16 not learning?

I've been following the series on Keras Python Deep Learning and, afaik, have produced the same code as used in the examples. However, I cannot produce the same result. # Imports import numpy as np import keras from keras import backend as K from keras.models import Sequential from keras.layers import Activation from keras.layers.core import Dense, Flatten from keras.optimizers import Adam from keras.metrics import categorical_crossentropy from keras.preprocessing.image import ImageDataGenerator from keras.layers.normalization import BatchNormalization from keras.layers.convolutional import * from matplotlib import pyplot as plt from sklearn.metrics import confusion_matrix import itertools import matplotlib.pyplot as plt %matplotlib inline # https://github.com/smileservices/keras_utils/blob/master/utils.py # plots images with labels within jupyter notebook def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None): if type(ims[0]) is np.ndarray: ims = np.array(ims).astype(np.uint8) if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1)) f = plt.figure(figsize=figsize) cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1 for i in range(len(ims)): sp = f.add_subplot(rows, cols, i+1) sp.axis('Off') if titles is not None: sp.set_title(titles[i], fontsize=16) plt.imshow(ims[i], interpolation=None if interp else 'none') def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues): """ This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. """ if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] print("Normalized confusion matrix") else: print('Confusion matrix, without normalization') print(cm) plt.imshow(cm, interpolation='nearest', cmap=cmap) plt.title(title) plt.colorbar() tick_marks = np.arange(len(classes)) plt.xticks(tick_marks, classes, rotation=45) plt.yticks(tick_marks, classes) fmt = '.2f' if normalize else 'd' thresh = cm.max() / 2. for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black") plt.ylabel('True label') plt.xlabel('Predicted label') plt.tight_layout() ``` # Setup # https://www.kaggle.com/c/dogs-vs-cats/data # train_path = 'cats-and-dogs-demo/train' # 20 # valid_path = 'cats-and-dogs-demo/valid' # 8 # test_path = 'cats-and-dogs-demo/test' # 5 # https://keras.io/preprocessing/image/ # 20 train_batches = ImageDataGenerator().flow_from_directory( train_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=10, shuffle=True ) Found 40 images belonging to 2 classes. imgs, labels = next(train_batches) plots(imgs, titles=labels) # 8 valid_batches = ImageDataGenerator().flow_from_directory( valid_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=4, shuffle=True ) Found 16 images belonging to 2 classes. valid_imgs, valid_labels = next(valid_batches) plots(valid_imgs, titles=valid_labels) # Build Fine-Tuned VGG16 Model vgg16_model = keras.applications.vgg16.VGG16() # vgg16_model.summary() model = Sequential() for layer in vgg16_model.layers[:-1]: model.add(layer) for layer in model.layers: layer.trainable = False model.add(Dense(2, activation='softmax')) model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy']) model.fit_generator( train_batches, steps_per_epoch=4, validation_data=valid_batches, validation_steps=4, epochs=5, verbose=1 ) Epoch 1/5 4/4 [==============================] - 16s 4s/step - loss: 2.0606 - acc: 0.3500 - val_loss: 1.5746 - val_acc: 0.3125 Epoch 2/5 4/4 [==============================] - 15s 4s/step - loss: 1.7596 - acc: 0.3500 - val_loss: 1.8654 - val_acc: 0.3125 Epoch 3/5 4/4 [==============================] - 16s 4s/step - loss: 1.3629 - acc: 0.4000 - val_loss: 1.4927 - val_acc: 0.5625 Epoch 4/5 4/4 [==============================] - 19s 5s/step - loss: 0.8355 - acc: 0.5750 - val_loss: 1.0068 - val_acc: 0.5000 Epoch 5/5 4/4 [==============================] - 19s 5s/step - loss: 0.4258 - acc: 0.7750 - val_loss: 0.9116 - val_acc: 0.6875 # 5 test_batches = ImageDataGenerator().flow_from_directory( test_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=5, shuffle=False ) Found 10 images belonging to 2 classes. test_imgs, test_labels = next(test_batches) test_labels = test_labels[:,0] test_labels array([1., 1., 1., 1., 1.], dtype=float32) predictions = model.predict_generator(test_batches, steps=1, verbose=0) cm = confusion_matrix(test_labels, np.round(predictions[:,0])) cm_plot_labels = ['cat','dog'] plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix') Confusion matrix, without normalization true cat [[0 0] dog [3 2]] c d a o t g Predicted test_imgs, test_labels = next(test_batches) test_labels = test_labels[:,0] test_labels array([0., 0., 0., 0., 0.], dtype=float32) # Predict using Fine-Tuned VGG16 Model predictions = model.predict_generator(test_batches, steps=1, verbose=0) cm = confusion_matrix(test_labels, np.round(predictions[:,0])) cm_plot_labels = ['cat','dog'] plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix') Confusion matrix, without normalization True cat [[1 4] dog [0 0]] c d a o t g Predicted
