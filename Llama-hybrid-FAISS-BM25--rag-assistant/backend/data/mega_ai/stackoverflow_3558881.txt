[site]: stackoverflow
[post_id]: 3558881
[parent_id]: 3558787
[tags]: 
Regex could easily give you all the words: import re s1 = "Fantini, Rauch, C.Straus, Priuli, Bertali: 'Festival Mass at the Imperial Court of Vienna, 1648' (Yorkshire Bach Choir & Baroque Soloists + Baroque Brass of London/Seymour)" s2 = "Vinci, Leonardo {c.1690-1730}: Arias from Semiramide Riconosciuta, Didone Abbandonata, La Caduta dei Decemviri, Lo Cecato Fauzo, La Festa de Bacco, Catone in Utica. (Maria Angeles Peters sop. w.M.Carraro conducting)" s1w = re.findall('\w+', s1.lower()) s2w = re.findall('\w+', s2.lower()) collections.Counter (Python 2.7+) can quickly count up the number of times a word occurs. from collections import Counter s1cnt = Counter(s1w) s2cnt = Counter(s2w) A very crude comparison could be done through set.intersection or difflib.SequenceMatcher , but it sounds like you would want to implement a Levenshtein algorithm that deals with words, where you could use those two lists. common = set(s1w).intersection(s2w) # returns set(['c']) import difflib common_ratio = difflib.SequenceMatcher(None, s1w, s2w).ratio() print '%.1f%% of words common.' % (100*common_ratio) Prints: 3.4% of words similar.
