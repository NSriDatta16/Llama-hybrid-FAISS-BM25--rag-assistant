[site]: crossvalidated
[post_id]: 551645
[parent_id]: 551593
[tags]: 
1. Citizenship example This seems to be a poor but valid test. It makes sense with an extreme p-value cut off $\alpha = 0$ . This way we would only reject those citizens whose profession is not found anywhere in the US. So maybe we would say "Robbert cannot be a US citizen because he is a suicide bomber and there are no suicide bombers in the united states" - a valid conclusion. The same in hypothesis testing terms: " $p = 0$ and so the null hypothesis is rejected (obtaining observed sample from H0 is impossible)." Different p-value cut-offs are then just compromise thresholds about how strict we want to be. 2. p-values, calculations by hand, and assumptions p-values are not tied to computations other than counting the number of occurrences when generating samples for the null hypothesis. And that generation can be performed by physical experiments in the real world. Moreover, we can use p-values for testing non-quantifiable or subjective things. So p-values can stand on their own as a philosophical construction without the need for concrete calculations, and there is no point in stating that they were invented in the age when calculations were performed by hand. And p-values themselves don't assume anything. It's the statistical tests that have assumptions. And even they are very flexible about that. Sometimes, for example, the assumption is about the sampling distribution of the parameter, and not the observations themselves. In addition, and I think author acknowledges this in the text, non-parametric tests also make one big assumption - they assume that the observed sample represents all the points from the population. The question is then simply which assumption is more warranted. A simplistic obvious case is with frequencies. Say you want to test if the chance of manufacturing defect is bigger than 5%, you get 10 samples and all of them are without defects. What would you be bootstrapping with 10 zeroes? 3. Confidence intervals Confidence intervals are a flip-side of the p-value. With p-value you test how surprising your observed sample is given some theoretical null hypothesis and with a confidence interval you define a set (mostly an interval) of hypotheses that would not be surprising given the observed sample. It's somewhat strange to me that so many people criticise one for the other. 4. Other One different point made against p-values in the text is about business people, to whom the values were reported, didn't understand them. But the answer is simple - don't show people things they might misunderstand. And I really doubt that someone not familiar with the intricacies of a p-value will be able to interpret confidence intervals without mistakes. "The job of a p-value is to prevent you from making a fool of yourself, and not report things as significant" - quoting someone (forgot who, sorry).
