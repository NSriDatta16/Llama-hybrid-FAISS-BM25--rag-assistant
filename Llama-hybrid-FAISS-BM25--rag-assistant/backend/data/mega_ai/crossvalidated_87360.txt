[site]: crossvalidated
[post_id]: 87360
[parent_id]: 86912
[tags]: 
The model you use to "simulate your problem" can be used almost verbatim to estimate the parameters you are interested in using Bayesian estimation. Here is the model I'll use (using the same notation as you): $$ L_B \sim \mathrm{Normal}(\mu, \sigma) \\ x_i \sim \mathrm{Normal}(\mu, \sigma) \mathrm{\ for\ i\ from\ 1\ to\ N} \\ L_{Ai} \sim \mathrm{Normal}(x_i \cdot \mathrm{gain} - \mathrm{offset}, \mathrm{dispersion}) \mathrm{\ for\ i\ from\ 1\ to\ N} \\ $$ The glaring omision in this model compared to your problem is that I don't include the assumption that some of the same $x_i$s that got measured by B could then be measured again by A. This could probably be added, but I'm not completely sure how. This model is implemented in R & JAGS below using very vague, almost flat priors, the data used is the one you generated in your question: library(rjags) model_string Let's run it and see how well it does: model The resulting estimates are reasonably close to the values you used when you generated the data: c(gain_A, offset_A, dispersion_A) ## [1] 1.1 -0.2 0.5 ...except for, perhaps, dispersion. But with more data, perhaps more informed priors and running the MCMC sampling longer this estimate should be better.
