[site]: datascience
[post_id]: 98289
[parent_id]: 
[tags]: 
How do you research and list up thinkable encoders and decoders when you build NLP models?

I'm a beginner in NLP and deep learning fields, and have stacked with the phase how research and list up available and substitutional encoders and decoders. For example, I read a thesis that Bidirectional LSTM and CRF were selected for named-entity recognition, like below. Named entity recognition with bidirectional lstm+CRF (with tensorflow code) - NER However, if my dataset and these encoders and decoders didn't show high performance, I need to try other encoders and decoders. My question is: When you have the specific NLP task, like NER , and dataset to train, how do you research applicable encoders and decoders?
