[site]: crossvalidated
[post_id]: 334013
[parent_id]: 
[tags]: 
Computing the posterior mean using a Gaussian prior?

I was reading through "Machine Learning: A Probabilistic Perspective" by Kevin Murphy and came across this example using priors but I don't understand how the posterior mean was calculated (page 168): I tried computing the posterior mean myself, but I don't understand how it is 3.43. Since the likelihood and prior are conjugate Gaussian, we can use a closed form formula to get the posterior mean (Lemma 5 here) : $$ \theta = \frac{\sigma^2_0}{\sigma^2 + \sigma^2_0}x+\frac{\sigma^2}{\sigma^2 + \sigma^2_0}\mu_0 $$ where the prior is $\theta \sim N(\mu_0, \sigma^2_0)$, and $\sigma^2$ is the variance of the observed $x$'s distribution. So the posterior mean should be $$ \theta = \frac{2.19^2}{1+2.19^2}5 + \frac{1}{1+2.19^2}0 = 4.14 $$ Am I doing something wrong or misinterpreting the example? Why is the posterior mean 3.43?
