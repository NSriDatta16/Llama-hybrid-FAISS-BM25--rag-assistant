[site]: crossvalidated
[post_id]: 116576
[parent_id]: 116548
[tags]: 
First of all, probably a (competitive) Kaggle dataset is not the best dataset to start with. There are many university courses and textbooks online that have exercises specially designed for beginners. I think you're confusing modelling a distribution (simplified: does this histogram look like a normal distribution or a uniform distribution) and modelling the relationship between the outcome $y$ and the predictors $x$ (given $x$, what is our estimate of $y$). You have a bunch of training data, for which you know the mapping between $x$ (which might be a vector / tuple with $n$ elements) and $y$ (a scalar). Your task is to learn the relationship between $x$ and $y$, so that you can predict the $y$ value for other values of $x$. The first thing to consider is: Is your $y$ qantitative (can it have arbitrary numerical values, at least within some range) or is it categorical (only certain values, maybe not even numerical, i.e. 'yes'/'no', 'red'/'green'/'black')? For the first scenario, you want to perform a regression , for the latter a classification . For your first problems, you don't have to perform feature selection or feature engineering. You also don't have to try to select the best kind of model -- just pick whatever you want to learn (or what is suggested by the exercise). In this case, the step from training data to a model is quite easy: Your model will simply have as many inputs as your problem has predictors: For linear regression you use a model with $n+1$ parameters (one for each input plus the offset); for a neural network you select $n$ input nodes; $k$-nearest neighors will work in $n$-dimensional space. You train the model with the training data according to the training equations/algorithm (either you do some calculations by hand, or you use a compute library for it or you write your own program) and can then use the trained model to predict new instances (again: either calculate by hand or use a library or write some code). Where to go from there? You should learn to do your modelling using a computer program (e.g. R, Weka, Numpy); try different types of models (linear regression, neural network, regression trees, SVM); learn metrics to compare different models (mean squared error; accuracy) and how to properly do this (training/test sets, cross validation, bootstrap); learn about overfitting (and bias and variance) and ways to prevent it (regularization); learn how to deal with the curse of dimensionality (normalization, feature engineering, feature selection). And tackle real-world problems.
