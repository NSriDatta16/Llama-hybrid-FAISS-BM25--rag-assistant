[site]: crossvalidated
[post_id]: 633233
[parent_id]: 632089
[tags]: 
Acknowledging that I provided the linked answer to #4 prior to providing a response. In your opinion, which of these methods conceptually most closely aligns with the verbal hypothesis that "predictor 1 relates more strongly to y than predictor 2"? To an extent, it depends on what you are trying to convey to the audience. You note being interested in whether one predictor ' ...will have a stronger relationship... ' with the outcome. What that means can affect the recommendation. For simplicity, I'll assume $X_1$ and $X_2$ are binary variables (i.e., coded as $0$ and $1$ ) and that they have more or less the same mean (and are effectively standardized relative to one another). Approach #1 and #3 both evaluate whether $b_1 - b_2 = 0$ . That is, does changing from $0$ to $1$ for both $X_1$ and $X_2$ produce the same mean difference on $y$ . If more interested in 'by how much' the predictor increases $y$ /it's mean value (irrespective of impact on total predicted variation in $y$ ), this is likely preferred. For example in the evaluation of a policy or intervention, the variable that increases the mean the most might be the better way to evaluate the relative importance of variables as it suggests one 'works better' and might be better to use. Approach #4, assuming you using general dominance statistics, evaluates whether the amount of variance explained in $y$ (as dominance analyzed; which accounts for an extensive set of increments to the $R^2$ ) by $X_1$ and $X_2$ is the same. The difference in dominance statistics gets more at relative explanatory utility and balances mean differences as reflected by the coefficients, with the relative variation in the predictors. This then speaks more to, in the context of the observed values, how much does the mean difference result in predicted differences on $y$ . This is a more 'data dependent' measure than the mean difference given it's translated through variance at least in part. I'm not sure #2 gives a useful test in this case and one would have to do a lot of work to get it to look like #1 and #3 (which #2 would be mimicking anyway). The linked example focuses on mean differences between groups (i.e., qualitatively different levels of some factor among observations) and does not, to my understanding, assume a data pivot/reshape to evaluate the effect of different variables as groups. What exactly is the null hypothesis of each test, in a sentence? This was more or less stated in the set-up of each of the approaches above. In your opinion, which of these methods is most flexible to real-world issues one is likely to face, such as multicollinearity? As was noted in the comments, regression coefficients, as such, are directly affected by multicollinearity and that's just a side effect of including correlated predictors. Dominance analysis is 'order independent' (i.e., the $R^2$ component averages across all ways one could 'include' a predictor in the sequence of ways one could include all the predictors). People usually interpret that controlling for multicollinearity. That's probably not, strictly speaking, true. Dominance does, at a minimum, include $R^2$ values across a number of different sub-models and produces an additive decomposition of the $R^2$ . Is there another method not mentioned here that is worth mentioning? I would be open to a bayesian perspective as well. Some interesting work using Bayes factors that can allow for specific orders of coefficient magnitudes/explanatory power that could be of definite value as well (e.g., Xu, 2023). My sense is that such methods are most valuable in the cases that you have a specific ordering that you wish to test (and not an exploratory situation; which it seems like might be more like the case here). References Gu, X. (2023). Evaluating predictorsâ€™ relative importance using Bayes factors in regression models. Psychological Methods, 28(4) , 825.
