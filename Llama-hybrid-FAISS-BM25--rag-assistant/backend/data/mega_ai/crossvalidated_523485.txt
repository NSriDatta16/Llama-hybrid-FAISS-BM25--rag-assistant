[site]: crossvalidated
[post_id]: 523485
[parent_id]: 
[tags]: 
Why is AIC or BIC commonly used in model selections for time series forecasting?

On scikit-learn documentation , I found the following comments about AIC: Information-criterion based model selection is very fast, but it relies on a proper estimation of degrees of freedom, are derived for large samples (asymptotic results) and assume the model is correct, i.e. that the data are actually generated by this model. They also tend to break when the problem is badly conditioned (more features than samples). My questions are: Why would AIC break when we have more features than samples? Why is AIC and BIC commonly used in forecasting model like ARIMA?
