[site]: datascience
[post_id]: 89012
[parent_id]: 88584
[tags]: 
I would suggest you refer to the paper by Hu et al, Show, Attend and Tell: Neural Image Caption Generation with Visual Attention . The brief idea is that the network learns the 'areas' to focus on that are on the feature maps (the last layer of the feature detectors) which can be in return mapped back to a certain location on the image. It is not a complex topic but requires some knowledge in RNNs and LSTMs as well that help with sequential data. Best of luck.
