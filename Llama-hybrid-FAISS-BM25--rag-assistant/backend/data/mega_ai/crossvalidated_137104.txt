[site]: crossvalidated
[post_id]: 137104
[parent_id]: 136987
[tags]: 
Proximity of a function $f$ to "straightness" measures the extent to which $f$ is "close" to a linear function of time. Great flexibility and power to specify straightness can be achieved by extending the linear functions, which are linear combinations of the constant function $1$ and the identity function $t\to t$, to a basis $E$ of the (Hilbert) space of $L^2$ integrable functions of the set of times. Conventional extensions include the polynomials $$E = (e_0, e_1, e_2, \ldots, e_k, \ldots) = (1, t, t^2, \ldots, t^k, \ldots)$$ but can be any set of linearly independent functions. Intuitively, the further out we go into one of these bases, the more we "depart from linearity." Given $p$ time series $$\mathrm{x}_i = ((t_1, x_{i1}), (t_2, x_{i2}), \ldots, (t_j, x_{ij}), \ldots, (t_n, x_{in}))$$ let us compute their projections onto the first $p+1$ elements of this basis using ordinary least squares, giving $$x_{ij} = b_{i0} + b_{i1}t_j + b_{i2}e_2(t_j) + \cdots + b_{ip}e_p(t_j) + \varepsilon_{ij}.$$ We seek a linear combination of the $\mathrm{x}_i$, with coefficients $\mathbf{\lambda} = (\lambda_1, \lambda_2, \ldots, \lambda_p)$ that is "straightest" in the sense that all the coefficients of $e_j$ for $j\gt 1$ vanish. That is, $$\sum_{i=1}^p \lambda_i b_{ij} = 0, \ j = 2, 3, \ldots, p.$$ This is the most we can hope for with $p$ series: if we tried to make one more coefficient vanish, we would have $p$ simultaneous linear equations governing the $\lambda_i$ and usually only $\lambda_i=0$ would be the solution. By invoking only $p-1$ equations, we are guaranteed to have a system with a nontrivial kernel. We are left to choose a basis element of that kernel. Assuming it is just one-dimensional (which will generically be the case), we may impose one more condition. A convenient one is to make the resulting linear combination look like an arithmetic mean of the time series. I do that by standardizing it so that its variance is $1/p$ times the collective variance of all the time series data. This can easily be done in two steps: first, require that the coefficients sum to unity: $$\lambda_1 + \lambda_2 + \ldots + \lambda_p = 1.$$ Then, perform the standardization. All other solutions will be linear functions of this one plus a linear function of time. Let's turn to a worked example. This proposal is implemented in the following R code, which generates an array of time series (which may have irregular spacing and multiple observations per time), finds the coefficients $b_{ik}$ using least squares fits, adjoins the sum-to-unity vector $(1,1,\ldots, 1)$ to this matrix, and solves for $\lambda$. That directly produces the linear combination of the original series, $\sum_{i}\lambda_i \mathrm{x}_i$, which is then standardized. The original series are plotted (in color, using dashed lines) and the "straightest" linear combination is overplotted (black solid line) for comparison. # # Specify the problem. # n
