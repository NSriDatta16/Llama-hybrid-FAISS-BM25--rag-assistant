[site]: crossvalidated
[post_id]: 174073
[parent_id]: 
[tags]: 
Is RMSProp safe to use with one-hot encoded inputs?

I was hoping for an explanation of why (if?) RMSProp is safe to use as an optimizer for a neural network with one-hot encoded natural language input. Here's my issue: the first layer of such a neural network will often be an embedding layer that maps my one-hot input vectors of length V to vectors of length H ( V here is my vocabulary size, H is the number of hidden nodes in my first layer). Now, many words in the vocabulary will be fairly rare, so for instance "pineapple" might only show up in 1/1000 training examples. So most of the time the gradient weights corresponding to the embedding of "pineapple" into a vector of length H will be 0. Now RMSProp determines its step size by scaling the gradient of the error by the inverse of the root mean square of its recent gradient values. For the weights associated with "pineapple", they will be 0 for most training examples, so every time we do see one the effective RMS is close to 0. RMSProp limits the maximum scaling of the gradient, but even still this means that the pineapple vector's components will tend to "jump" by very large amounts every time there is a pineapple example. This seems like a significant issue, but I can't seem to find any discussion of it. Won't this in many cases cause these vectors to fail to converge? I feel like there should almost be a special case and we should instead take the RMS of the non-zero values of the gradient. Incidentally it seems like this could also be a problem for ReLUs where lots of activations are 0.
