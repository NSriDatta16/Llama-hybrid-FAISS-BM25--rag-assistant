[site]: datascience
[post_id]: 37981
[parent_id]: 37975
[tags]: 
Could somebody kindly explain to me the intuition behind stacking 2 or more consecutive convolution filters. Why couldn't the 2 filters be merged into 1? No, when having two consecutive convolution layers can't be combined into one. The subsequent filter's inputs are the features extracted from the previous one. This results in the second layer's features are of higher-level than the previous. This is the basis of the whole CNN. Having multiple convolutional layers stacked along the depth of the network, allows the network to extract high-level features (not just edges and corners) from the input images. Edit. The first convolutional layer of a CNN is essentially a standard image filter (+ a ReLU). Its goal is to take a raw image and extract basic features from it (e.g. edges, corners). These are referred to as low-level features . The second convolutional layer, instead of the raw image, accepts the features extracted by the first as its input. This allows it to combine these basic shapes into more complex features . The features extracted become more and more complex as we go further down the network. Layers near the middle of the network extract the so called mid-level features , while the final layers extract high-level features . CNNs are powerful tools because it is trained to extract the best features for each task. This results in the network extracting different features for different tasks. For example, take the image below: While the low-level features are the same for each task, mid and high-level features differ greatly. For instance, for the first CNN that recognizes faces: The low-level features are basic geometric shapes (edges, corners, circles, etc.). The mid-level features combine the previously extracted shapes to extract more complex features (eyes, noses, lips), specific to the task of facial recognition. Finally, the high-level features combine the previous to extract even more complex features (in this case different faces).
