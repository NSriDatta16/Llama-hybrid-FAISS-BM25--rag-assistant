)}+\beta _{i}} Here, γ {\displaystyle \gamma } and β {\displaystyle \beta } are parameters inside the BatchNorm module. They are learnable parameters, typically trained by gradient descent. The following is a Python implementation of BatchNorm: Interpretation γ {\displaystyle \gamma } and β {\displaystyle \beta } allow the network to learn to undo the normalization, if this is beneficial. BatchNorm can be interpreted as removing the purely linear transformations, so that its layers focus solely on modelling the nonlinear aspects of data, which may be beneficial, as a neural network can always be augmented with a linear transformation layer on top. It is claimed in the original publication that BatchNorm works by reducing internal covariance shift, though the claim has both supporters and detractors. Special cases The original paper recommended to only use BatchNorms after a linear transform, not after a nonlinear activation. That is, ϕ ( B N ( W x + b ) ) {\displaystyle \phi (\mathrm {BN} (Wx+b))} , not B N ( ϕ ( W x + b ) ) {\displaystyle \mathrm {BN} (\phi (Wx+b))} . Also, the bias b {\displaystyle b} does not matter, since it would be canceled by the subsequent mean subtraction, so it is of the form B N ( W x ) {\displaystyle \mathrm {BN} (Wx)} . That is, if a BatchNorm is preceded by a linear transform, then that linear transform's bias term is set to zero. For convolutional neural networks (CNNs), BatchNorm must preserve the translation-invariance of these models, meaning that it must treat all outputs of the same kernel as if they are different data points within a batch. This is sometimes called Spatial BatchNorm, or BatchNorm2D, or per-channel BatchNorm. Concretely, suppose we have a 2-dimensional convolutional layer defined by: x h , w , c ( l ) = ∑ h ′ , w ′ , c ′ K h ′ − h , w ′ − w , c , c ′ ( l ) x h ′ , w ′ , c ′ ( l − 1 ) + b c ( l ) {\displaystyle x_{h,w,c}^{(l)}=\sum _{h',w',c'}K_{h'-h,w'-w,c,c'}^{(l)}x_{h',w',c'}^{(l-1)}+b_{c}^{(l)}} where: x h , w , c ( l ) {\displaystyle x_{h,w,c}^{(l)}} is the activation of the neuron at position ( h , w ) {\displaystyle (h,w)} in the c {\displaystyle c} -th channel of the l {\displaystyle l} -th layer. K Δ h , Δ w , c , c ′ ( l ) {\displaystyle K_{\Delta h,\Delta w,c,c'}^{(l)}} is a kernel tensor. Each channel c {\displaystyle c} corresponds to a kernel K h ′ − h , w ′ − w , c , c ′ ( l ) {\displaystyle K_{h'-h,w'-w,c,c'}^{(l)}} , with indices Δ h , Δ w , c ′ {\displaystyle \Delta h,\Delta w,c'} . b c ( l ) {\displaystyle b_{c}^{(l)}} is the bias term for the c {\displaystyle c} -th channel of the l {\displaystyle l} -th layer. In order to preserve the translational invariance, BatchNorm treats all outputs from the same kernel in the same batch as more data in a batch. That is, it is applied once per kernel c {\displaystyle c} (equivalently, once per channel c {\displaystyle c} ), not per activation x h , w , c ( l + 1 ) {\displaystyle x_{h,w,c}^{(l+1)}} : μ c ( l ) = 1 B H W ∑ b = 1 B ∑ h = 1 H ∑ w = 1 W x ( b ) , h , w , c ( l ) ( σ c ( l ) ) 2 = 1 B H W ∑ b = 1 B ∑ h = 1 H ∑ w = 1 W ( x ( b ) , h , w , c ( l ) − μ c ( l ) ) 2 {\displaystyle {\begin{aligned}\mu _{c}^{(l)}&={\frac {1}{BHW}}\sum _{b=1}^{B}\sum _{h=1}^{H}\sum _{w=1}^{W}x_{(b),h,w,c}^{(l)}\\(\sigma _{c}^{(l)})^{2}&={\frac {1}{BHW}}\sum _{b=1}^{B}\sum _{h=1}^{H}\sum _{w=1}^{W}(x_{(b),h,w,c}^{(l)}-\mu _{c}^{(l)})^{2}\end{aligned}}} where B {\displaystyle B} is the batch size, H {\displaystyle H} is the height of the feature map, and W {\displaystyle W} is the width of the feature map. That is, even though there are only B {\displaystyle B} data points in a batch, all B H W {\displaystyle BHW} outputs from the kernel in this batch are treated equally. Subsequently, normalization and the linear transform is also done per kernel: x ^ ( b ) , h , w , c ( l ) = x ( b ) , h , w , c ( l ) − μ c ( l ) ( σ c ( l ) ) 2 + ϵ y ( b ) , h , w , c ( l ) = γ c x ^ ( b ) , h , w , c ( l ) + β c {\displaystyle {\begin{aligned}