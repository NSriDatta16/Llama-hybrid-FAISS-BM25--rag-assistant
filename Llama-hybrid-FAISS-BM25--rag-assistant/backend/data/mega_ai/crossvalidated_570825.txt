[site]: crossvalidated
[post_id]: 570825
[parent_id]: 570823
[tags]: 
THIS APPLIED BEFORE THE QUESTION EDIT . I will leave it here as a reference for the situation where performance is worse than chance. Your accuracy is $93\%$ . If you just classify everything as the majority class, you score $97\%$ , so your error rate is more than double this na√Øve guessing of everything being in the majority class. Something in your model is amiss. I suspect at least part of it has to do with your use of a complex neural network on a sample size of only $4110$ . That sounds like a recipe for overfitting and creating a model whose out-of-sample performance is worse than chance. My guess is that your software does not give $AUC and is reversing the probabilities, meaning that your true $AUC\approx 0.01$ , if you base your $AUC$ calculation on the true outputs of the neural network. To test this out, you could write some ROC curve plotting code from scratch, using the exact probability values outputted by the neural network. If you do it yourself, then you know for sure that the true $AUC$ is awful. A crude implementation would be to loop over $0$ , $0.01$ , $0.02$ , $\dots$ , $0.98$ , $0.99$ , $1$ and calculate the sensitivity and specificity with each such value as the threshold. Then plot the sensitivity values on the vertical axis and one minus the specificity values on the horizontal axis.
