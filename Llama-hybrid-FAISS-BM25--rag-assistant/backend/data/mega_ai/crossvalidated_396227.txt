[site]: crossvalidated
[post_id]: 396227
[parent_id]: 396139
[tags]: 
I would recommend reading Chapter 3 of Sutton and Barto's RL book . In it, you will learn about how reinforcement learning problems are formulated as a series of interactions between an agent and its environment. This is the key diagram. The "agent" is the entity that makes decisions. The "environment" is everything else, defined in the book as "everything outside of the agent's absolute control." Notice that the environment responds to the agent's action with a reward $R_{t+1}$ and a next state $S_{t+1}$ . Both of these are, in general, random variables with probability distributions conditioned on action $A_t$ and current state $S_t$ . In its attempt to behave optimally in a stochastic or uncertain environment, an agent has the option to introduce randomness of its own in the form of a stochastic policy. Here, a policy is a distribution over possible actions conditioned on the agent's current state. The agent samples from this distribution to decide what action to take. Q-learning is a popular algorithm in RL, but I would suggest you start with reading the fundamentals (in the book I mentioned) before trying to implement any RL algorithms.
