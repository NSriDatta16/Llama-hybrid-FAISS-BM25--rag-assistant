[site]: crossvalidated
[post_id]: 493930
[parent_id]: 474767
[tags]: 
Your thinking is correct. I recommend Gneiting & Raftery (2007, JASA ) for an in-depth discussion of scoring rules. A scoring rule $S$ is a mapping that takes a probabilistic prediction $\hat{p}$ and a corresponding observed outcome $y$ to a loss value $S(\hat{p},y)$ . In our application, $\hat{p}$ is just a single number (that will depend on predictors, see below), but in a numerical prediction, it will be an entire predictive density. We typically take averages of this loss value over multiple instances $y_i$ , each with its own (predictor-dependent) prediction $\hat{p}_i$ . And we usually aim at minimizing this average loss (though the opposite convention also exists; it's always a good idea to verify how a particular paper's scoring rules are oriented). A scoring rule is proper if it is minimized in expectation by the true probability. Now, in the present case, the key aspect is that we have only two predictors, both of which can only take the values $0$ and $1$ . In this setting, we cannot distinguish between two instances with different outcomes $y$ but the same predictor settings, so we cannot have different (probabilistic) predictions for two instances with the same predictor settings. Having a hard $0$ prediction for an instance with $y=0$ , but a hard $1$ prediction for an instance with $y=1$ is simply not possible if the two instances have the same predictor values. All we can have is a probabilistic prediction $\hat{p}_{ij}$ in the case where the first predictor has value $i$ and the second predictor has value $j$ . Now, let's assume that the true probability of $y=1$ , given that the first predictor has value $i$ and the second predictor has value $j$ , is $p_{ij}$ . What is the expected value of the Brier score of our probabilistic prediction $\hat{p}_{ij}$ ? Well, with a probability of $p_{ij}$ , we have $y=1$ and a contribution of $(1-\hat{p}_{ij})^2$ to the Brier score, and with a probability of $1-p_{ij}$ , we have $y=0$ and a contribution of $\hat{p}_{ij}^2$ to the Brier score. The total expected constribution to the Brier score is $$ p_{ij}(1-\hat{p}_{ij})^2+(1-p_{ij})\hat{p}_{ij}^2. $$ Differentiating this expression with respect to $\hat{p}_{ij}$ and setting the derivative equal to zero, we find that this expected score is minimized when $\hat{p}_{ij}=p_{ij}$ , so we have found that the Brier score is proper in our situation. It aims at getting the correct (specifically: calibrated and sharp) probabilistic prediction. And of course, if now a third predictor turns up that would allow perfect $0-1$ predictions, then the Brier score of this expanded model would be lower than that of the two-predictor model's predictions (namely, zero). Which is exactly how it should be.
