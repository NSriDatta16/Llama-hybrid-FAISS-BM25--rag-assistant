[site]: crossvalidated
[post_id]: 109113
[parent_id]: 108998
[tags]: 
So I just skimmed the paper... but the idea is to perturb the data returned from a query to stop a snooper discovering personal information by making very specific 'summary' queries. eg (my example- I just skimmed the paper) maybe you have an age variable and just add zero mean gaussian random noise to each person in the database. Then in any sizeable group (in your database query, eg 40-50 year old smokers ) the average age stays ~ the same (as the unperturbed statistic for the group, say =48). it is unbiased meaning that if you do multiple queries for the average age of your group (adding new noise each time to your data), then the average over each query for the average age using the perturbed data will converge to the average age for the unperturbed data ( as you average over more and more queries). Now if you ask for the variance in age of the group then this will be biased by adding noise to the age variable - since the very addition of noise makes the perturbed age data more variable than the original group's (imagine you only had 1 person in the group). No amount of averaging of the variance across different queries will reduce the variance to that of the original groups variance.
