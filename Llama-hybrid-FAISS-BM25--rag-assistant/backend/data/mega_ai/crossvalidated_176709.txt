[site]: crossvalidated
[post_id]: 176709
[parent_id]: 176707
[tags]: 
Python does not handle factor directly (see : this stack overflow thread for more details). You can either encode them (turn them into ints, enforcing an order and making some splits "hard to see" for the algorithm). It is legitimate to do this if you suspect a natural order of your factors. Alternatively, you can "one-hot" encode them (creating dummy variables). If you create dummy variables for a factor with a large number of levels, a lot of columns will correspond to this specific value, giving it more importance (each tree will be grown learning from a several number of these columns). Indeed, the trees are grown on a sub-sample of the columns (by default, the columns are chosen randomly with equal probability). If you have two numeric predictors and a factor with 100 levels, almost all your trees will not take the information about the numeric values into account. R on the other hand, will try every partition of the levels of the factor . See How to choose the split in Random forest for categorical predictors (features)? for more information about this. Having un-encoded factors usually makes it much slower. If you had more than 53 levels, the number of splits to try is $2^{53}$ which would be irrealistically slow. And the number of split to consider doubles at every new level.
