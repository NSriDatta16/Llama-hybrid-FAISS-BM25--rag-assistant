[site]: crossvalidated
[post_id]: 462334
[parent_id]: 
[tags]: 
What is the difference between log-likelihood and expected pointwise log predictive density

I'm currently switching from Maximum Likelihood Estimations to Bayesian inference models where I can specify my own priors. I used to do K-fold cross-validation: estimate the parameters on the training set, and compute the log-likelihood on the testing set. Is this what is called the expected log predictive density? It seems like it would be, but I have a small doubt... Thanks.
