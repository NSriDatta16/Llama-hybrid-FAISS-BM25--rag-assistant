[site]: crossvalidated
[post_id]: 543378
[parent_id]: 61783
[tags]: 
I think the standard error that we are talking about here is the standard error of the $MSE$ s or $Err$ s generated across different cross-validation iterations. But the simulation done by Xavier Bourret Sicotte calculated the standard error of $MSE$ or $Err$ based on repeatedly drawing different sample data from the population. If you refer to the lecture on Cross-Validation of Rob and Trevor Hastie (free online), they gave the formula for standard error of $CV_k$ as $$ \widehat{\mathrm{SE}}\left(\mathrm{CV}_{K}\right)=\sqrt{\sum_{k=1}^{K}\left(\operatorname{Err}_{k}-\overline{\operatorname{Err}_{k}}\right)^{2} /(K-1)} $$ where $$ \mathrm{CV}_{K}=\sum_{k=1}^{K} \frac{n_{k}}{n} \operatorname{Err}_{k} $$ where $\operatorname{Err}_{k}=\sum_{i \in C_{k}} I\left(y_{i} \neq \hat{y}_{i}\right) / n_{k}$ So in my opinion the simulation was not correctly done: Generate 10,000 points from the distribution sin(x)+ϵ where the true variance of ϵ is known Iterate i times (e.g. 100 or 200 times). At each iteration, change the dataset by resampling N points from the original distribution For each data set i: Perform K-fold cross validation for one value of K Store the average Mean Square Error (MSE) across the K-folds Once the loop over i is complete, calculate the mean and standard deviation of the MSE across the i datasets for the same value of K this is where I think it is not right >> Repeat the above steps for all K in range {5,...,N} all the way to Leave One Out CV (LOOCV)
