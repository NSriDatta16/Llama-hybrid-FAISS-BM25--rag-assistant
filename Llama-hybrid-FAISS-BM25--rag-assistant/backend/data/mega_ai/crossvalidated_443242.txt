[site]: crossvalidated
[post_id]: 443242
[parent_id]: 
[tags]: 
Is there a typo in the paper "Evolution Strategies as a Scalable Alternative to reinforcement learning" by OpenAI?

Original paper: https://arxiv.org/pdf/1703.03864.pdf On page 2-3, it writes, But this equation is clearly wrong. Since the step needed to derive the equation involves the argument, let $$\theta = \psi + \sigma \epsilon, \epsilon \sim N(0,I)$$ Therefore by a straight forward substitution, $$\mathbb{E}_{\theta \sim p_\psi} F(\theta) = \mathbb{E}_{\epsilon \sim N(0,I)} F(\psi + \sigma\epsilon) $$ and NOT, $$\mathbb{E}_{\theta \sim p_\psi} F(\theta) =\mathbb{E}_{\epsilon \sim N(0,I)} F(\theta + \sigma\epsilon) $$ ( $\theta$ and $\psi$ exchanged) as written in the paper. Hence all the rest of the results are wrong. One can argue that the authors, confusingly, implicitly exchanged the notation of $\psi$ and $\theta$ , where now $\theta$ refers to the mean of the Gaussian distribution (which was previously denoted by $\psi$ ) However, this implies that their main algorithm is wrong, Because $\theta$ here is clearly not the mean of the Gaussian. $\theta$ clearly refers to the neural network parameter (weights) in the original paper. Can someone check for me? Note that this error is also pointed out in an earlier post How is the equation in "Evolution Strategies as a Scalable Alternative to Reinforcement Learning" derived? however, in my opinion this is not just an abuse of notation "confusing" but it is flat out wrong.
