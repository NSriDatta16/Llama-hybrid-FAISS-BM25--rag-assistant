[site]: crossvalidated
[post_id]: 394678
[parent_id]: 
[tags]: 
Treating outliers when missing values are in large amount

I am having a hard time coming up with a strategy to treat missing values and outliers in a dataset where more than 75% of values are missing. The present values are somehow extremely variable. If I decide to set all the missing values to the mean, the number of outliers grows by a factor 40, so this means that the choice of the missing values treatment strategy influences the outliers treatment strategy. At first glance, I would think in a physical way and assume that the missing values may be distributed similarly to the present values, thus outliers should be individuated before treating the missing values. But this poses me a problem: when I set all the missing values to the mean I will automatically generate outliers, that will of course affect the accuracy of my predictors (a neural network, random forest, or linear regression). This would not solve my problem. How should I treat these NA values to learn the most I can from my dataset?
