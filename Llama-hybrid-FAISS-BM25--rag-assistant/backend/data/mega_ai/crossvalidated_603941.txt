[site]: crossvalidated
[post_id]: 603941
[parent_id]: 603939
[tags]: 
Your interpretation in the second bullet point makes sense to me. Your goal as a statistician is to predict the value. Once you are good at this, a clinician can use your predictions. If that means the clinician (or patient) wants to see values around $25$ , so be it. Your job is to make sure that a prediction of $25$ should be taken seriously. Consequently, it makes sense that a positive coefficient means that people at the low end would want to increase their value of that covariate in order to meander into the "good" zone, while people at the high end would want to decrease their value for the same reason. To address the other two bullet points: $1)$ Omitting data like that is dicey. Among the issues are that you can lose your ability to speak intelligently about individuals from that population and that you lose sample size. Particularly troubling to me, however, is that the data are omitted based on the outcome. Presumably, this outcome is not something you observe (easily, or maybe not until later), so you want to predict it. However, since you don't get to see it, you cannot know if the individual for whom you are making predictions belongs to the population used for model training. If they do not, the model need not apply. $3)$ While it might be tempting to run a logistic regression to predict the probability that someone is in the "good" range or the "bad" range, doing so destroys information. This kind of binning has been admonished on Cross Validated many-a-time, such as here . For instance, if someone has a value of $29.9$ , that's technically in the "good" range, but it's really close to being in the bad range. I, as a patient, would like to know if I am on thin ice, even if I am dry for now. (That is, the thin ice has not broken and dropped me in the lake.)
