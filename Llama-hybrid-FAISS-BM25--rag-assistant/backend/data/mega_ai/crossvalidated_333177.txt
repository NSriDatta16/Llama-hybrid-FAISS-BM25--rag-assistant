[site]: crossvalidated
[post_id]: 333177
[parent_id]: 332713
[tags]: 
The answer is no : there is no such property. Any property of the form "a.s. something" that implies convergence in probability also implies a.s. convergence, hence cannot be equivalent to convergence in probability. Proof: Write $X=(X_n)_{n\in\mathbb{N}}$. Let's assume all variables $X_n$ are binary (in $\{0;1\}$) for simplicity. Then convergence in probability (implicitly to 0 in all that follows) of $X$ is simply: $$\lim_{n\rightarrow+\infty} P(X_n=1)=0$$ For any property $\psi$ of sequences of 0s and 1s, "a.s. $\psi(X)$" means "for almost all $\omega$, $\psi(X(\omega))$". For every infinite part $A$ of $\mathbb{N}$ define the property (of sequences of 0s and 1s): $$\phi_A(x): \exists n\in A\quad x_n=0$$ Clearly, convergence in probability of $X$ implies a.s. $\phi_A(X)$. Now assume convergence in probability of $X$ is implied by a.s. $\phi(X)$ for some property $\phi$. For any $A$, a.s. $\phi(X)$ implies convergence in probability of $X$ implies a.s. $\phi_A(X)$. Then it is clear that for any sequence $x$ of 0s and 1s, $\phi(x)$ implies $\phi_A(x)$: just use a random sequence $X$ identically equal to $x$. Thus $\phi(x)$ implies $\forall A\space \phi_A(x)$ where $A$ ranges over all infinite parts of $\mathbb{N}$. $\forall A\space \phi_A(x)$ says there is no infinite part of $\mathbb{N}$ where $x$ is constant to 1. In other words it says $x$ has only finitely many 1s. That is $x$ tends to 0. Thus a.s. $\phi(X)$ implies a.s. convergence of $X$. About about this property: $$\phi((x_n)_{n\in\mathbb{N}}): \forall\epsilon>0\quad\lim_{n\rightarrow+\infty}\frac{\#\{k \epsilon\}}{n}=0$$ "Almost surely $\phi$" is not equivalent to convergence in probability. First, it is not implied by convergence in probability. A counter example is not so easy to find. The implication holds for independent variables. A counter example can be constructed by creating successive independent groups of 0/1 variables. All variables in the same group are equal: their common value is called the value of the group. And we have: the length of each group is large enough (say $2^k$) so that a group having value 1 influences the average sufficiently almost surely infinitely many groups have value 1 so that the above happens infinitely many times the probability for a group to have value 1 tends to 0 so that convergence in probability (to 0) holds The last two points can be be obtained by saying that the probability for the $k^{th}$ group to have value 1 is $1/k$ and using the second Borrel-Cantelli lemma. "Almost surely $\phi$" does not imply convergence in probability either. But it's not far from it. "For all subsequences of $X$, almost surely $\phi$ for this subsequence" implies convergence in probability and this is quite easy to prove. Going further than this seems to raise key theoretical difficulties: how to define asymptotic empirical frequency in a more general way than this.
