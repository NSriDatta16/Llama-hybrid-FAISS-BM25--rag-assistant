[site]: crossvalidated
[post_id]: 618900
[parent_id]: 618722
[tags]: 
Let me try to summarise here the argument of our paper . (Note that I am mostly using different notations, cut&pasted from my set of slides .) The original Metropolis-Hastings estimate of $\mathbb E[h(X]$ writes as $$ {\delta_n} =\frac{1}{n}\sum_{t=1}^n h(x^{(t)})={\frac{1}{n}\,\sum_{i=1}^{M_n} \mathfrak n_i h(\mathfrak z_i)}\,, $$ after $n$ iterations where $(x^{(t)})_{1\le t\le n}$ is the original Markov chain produced by the Metropolis-Hastings kernel (targetting density $\pi(\cdot)$ with proposal density $q(\cdot|\cdot)$ ) $(\mathfrak z_i)_{1\le i\le M_n}$ is the sequence of distinct values in $(x^{(t)})_{1\le t\le n}$ $(\mathfrak n_i)_{1\le i\le M_n}$ is the corresponding sequence of the number of occurrences of these distinct values in $(x^{(t)})_{1\le t\le n}$ So far, there is no difference in running the MCMC chain, simply an alternative representation of the basic estimate. It is rather straightforward to establish that The sequence $(\mathfrak z_i,\mathfrak n_i)$ satisfies $(\mathfrak z_i,\mathfrak n_i)$ is a Markov chain $\mathfrak z_{i+1}$ and $\mathfrak n_i$ are independent given $\mathfrak z_i$ ; $\mathfrak n_i$ [given $\mathfrak z_i$ ] is distributed as a geometric random variable with probability parameter \begin{equation} {p(\mathfrak z_i) := \int \alpha(\mathfrak z_i,y)\,q(y|\mathfrak z_i)\,\text dy}\,; \end{equation} $(\mathfrak z_i)_i$ is a Markov chain with transition kernel $\tilde Q(\mathfrak z,\text dy)=\tilde q(y|\mathfrak z)\text dy$ and stationary distribution $\tilde \pi$ such that $$ {\tilde q(\cdot|\mathfrak z) \propto \alpha(\mathfrak z,\cdot)\,q(\cdot|\mathfrak z)\quad \mbox{and} \quad \tilde \pi(\cdot) \propto \pi(\cdot)p(\cdot)}\,. $$ Were the density $p(\mathfrak z_i)$ available in closed form, an improved estimator would be $$\delta^* = \frac{1}{n}\,\sum_{i=1}^{M_n} \dfrac{h(\mathfrak z_i) }{p(\mathfrak z_i)}$$ since $$\mathbb E[\mathfrak n_i|\mathfrak z_i]=\frac{1}{p(\mathfrak z_i)}$$ But since the density $p(\mathfrak z_i)$ is not available in closed form, a reduced variance alternative to $\mathfrak n_i$ is available by Rao-Blackwellisation. Using the representation $$ \mathfrak n_i =1+ \sum_{j=1}^\infty \prod_{\ell\le j} \mathbb{I}\left\{ u_\ell \ge \alpha(\mathfrak z_i,y_\ell) \right\}\,, $$ which, again, is not modifying the original Metropolis-Hastings output, we propose an improvement by integrating out the $u_\ell$ uniform (at the potential cost of having to possibly generate more proposed $y_j$ 's). If $(y_j)_j$ is an iid sequence (of proposals) with distribution $q(y|\mathfrak z_i)$ , the quantity $$ {\hat\xi_i = 1+\sum_{j=1}^\infty \prod_{\ell\le j} \left\{ 1 - \alpha(\mathfrak z_i,y_\ell) \right\}} $$ is an unbiased estimator of $1/p(\mathfrak z_i)$ which variance, conditional on $\mathfrak z_i$ , is lower than the conditional variance of $\mathfrak n_i$ , $\{1-p(\mathfrak z_i)\}/p^2(\mathfrak z_i)$ . Therefore, the Rao-Blackwellised estimator $$\hat \delta_n = \frac{1}{n}\,\sum_{i=1}^{M_n} \hat\xi_i h(\mathfrak z_i)$$ is an improvement over $\delta_n$
