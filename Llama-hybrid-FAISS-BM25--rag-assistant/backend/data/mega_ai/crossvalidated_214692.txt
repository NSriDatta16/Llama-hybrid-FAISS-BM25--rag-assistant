[site]: crossvalidated
[post_id]: 214692
[parent_id]: 214674
[tags]: 
Author here. There are a few points I can elaborate on: Your data is going to be distributed across many computers in a real cluster, so each computer has a fraction of the data. Locally, then, the computations should run fine. But the question next is: how do you combine all these inferences? Sure you could just merge the traces from each computer, but then you haven't gained anything from having all this extra data. As the data increases, the posterior (typically) becomes more and more peaked and narrow, and the rest of the space is much flatter, which means the MCMC algorithm will have a hard time finding the location of the posterior (assume it starts far away). This really affects convergence. My note also applies to the number of unknown variables - with more variables, the space the posterior lives in higher and higher dimensions, so convergence of the MCMC is less guaranteed. Typically big data comes with more unknown variables.
