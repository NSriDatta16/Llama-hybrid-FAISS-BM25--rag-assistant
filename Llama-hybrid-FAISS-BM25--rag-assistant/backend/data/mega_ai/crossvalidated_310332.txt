[site]: crossvalidated
[post_id]: 310332
[parent_id]: 
[tags]: 
Classification: Random Forest vs. Decision tree

Suppose you are given a dataset with 4 attributes (F1, F2, F3, and F4). The class label is contained in attribute F4. Now you build a random forest classification model and you test its performance using 10-fold cross-validation. For building the model you have used all four attributes (F1, F2, F3, and F4). The precision and recall of your experiment are both close to 100%. Is there anything that went wrong? Would you obtain similar performance if you used a decision tree instead?
