[site]: crossvalidated
[post_id]: 308799
[parent_id]: 308795
[tags]: 
First of all you want to get standard deviations that says something about test errors not training errors. There are different aproaches to solve the problem. Ensampling/bootstrapping: multiple different splits of your training data and get out of bag estimates for each split. Then for each observation calculate the standard error of th prediction. For test data just calculate the standard errors for all the estimates. The mean of the estimates are by the way a better model than any single model. So this can improve your prediction error. Modeling the standard error directly: Make a neural network that outputs the (log of the) standard error of the prediction given an input trained on your validation errors. This is then optimized using MLE and should be pretty straight forward. Just train a network with the following objective and the residuals as the targets (logsigma(X) is a neural network outputing a scalar from negative infinity to infinity). $obj=\sum-1/2*logsigma(X_i)-\frac{residual_i^2}{2*exp(logsigma(X_i)*2)}$ Pros and cons: The ensampling bootstrapping is well tested, but it gives you the standard derivation of the estimate, not the expected standard error of the observation. Modeling the standard error directly is not as well accepted, but it gives you unbiased estimates of the standard error of your residuals for each observation. If you have time and the courage I would try the latter one. You can off course make both, so you make an ensemble of models and make a neural network trained on the out of bag residuals.
