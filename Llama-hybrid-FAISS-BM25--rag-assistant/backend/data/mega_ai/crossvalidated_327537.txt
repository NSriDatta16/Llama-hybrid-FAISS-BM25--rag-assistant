[site]: crossvalidated
[post_id]: 327537
[parent_id]: 327496
[tags]: 
Since you are asking if loss function is quantifying a vector. It is better to put a bit formally. At the output layer, the loss function is a $R^c\rightarrow R$ mapping, where $c$ is the number of classes. For multiclassification, the target in your data need to be one-hot-coded to a vector of length $c$. For binary classification, if standard logistic regression is used, then $c=1$, if a softmax layer is used, then $c=2$. The mapping is basically to sum up (or average) the errors for all classes for all data examples. For each data example, you will have this $$Loss = \sum_{i=1}^c Error^i$$ $$ Error^i=f(y_i, \hat y_i(x, w))$$ $y_i$ is the $i$th element in the one-hot coding vector, and $\hat y_i$ is its estimate by the neural network, $f(\cdot)$ can be squared error or something else. My answer for your question is yes, the loss function is just summing up a vector of errors for all classes.
