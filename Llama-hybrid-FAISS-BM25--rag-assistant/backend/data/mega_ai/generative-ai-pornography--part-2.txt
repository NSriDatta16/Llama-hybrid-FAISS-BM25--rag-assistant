ram has more than 100,000 monthly users. Alibaba, the Chinese tech company, released an AI video generation model in 2025 called Wan 2.1, which was modified to produce non-consensual pornography. Several US states are taking actions against using deepfake apps and sharing them on the internet. In 2024, San Francisco filed a landmark lawsuit to shut down "undress" apps that allow users to generate non-consensual AI nude images, citing violations of state laws. The case aligns with California's recent legislation—SB 926, SB 942, and SB 981—championed by Senators Aisha Wahab and Josh Becker and signed by Governor Gavin Newsom. These bills aim to protect individuals from AI-generated explicit images by criminalizing non-consensual distribution, mandating disclosures, and empowering victims to report and remove harmful content from platforms. Differences from deepfake pornography While both generative AI pornography and deepfake pornography rely on synthetic media, they differ in their methods and ethical considerations. Deepfake pornography typically involves altering existing footage of real individuals, often without their consent, using AI to superimpose faces or modify scenes. In contrast, generative AI pornography is created using algorithms, producing hyper-realistic content without the need to upload real pictures of people. Hany Farid, digital image analysis expert, also described the difference between "AI porn" and "deepfake porn." Legality The legality of generative AI pornography varies widely by jurisdiction and remains an evolving issue. In some countries, laws addressing digital impersonation, obscenity, or deepfake technologies may indirectly apply, particularly when AI-generated content involves the likeness of real individuals without consent. The absence of a physical performer further complicates traditional regulatory frameworks, which are often grounded in performer protection and distribution laws. In the United States, legal responses have primarily focused on non-consensual deepfakes and impersonation. Some states, such as Virginia, California, and Texas, have enacted legislation criminalising the creation or distribution of non-consensual explicit deepfake content. However, there is no comprehensive federal law addressing AI-generated pornography, leaving a patchwork of legal interpretations and enforcement standards across different jurisdictions. According to a 2023 report, South Korea accounts for approximately 53% of global deepfake pornography production. In September 2024, South Korea's National Assembly amended the Act on Special Cases Concerning the Punishment of Sexual Crimes, introducing two significant reforms related to deepfake content. The first criminalises the possession, viewing, purchase, and storage of non-consensual deepfake material, with penalties of up to three years in prison or fines of up to 30 million won (approximately USD 20,000). The second reform specifically addresses the exploitation of minors, establishing that individuals who use deepfakes to threaten or blackmail minors face a minimum of three years' imprisonment, and at least five years if they coerce minors into unwanted acts. See also Artificial intelligence controversies == References ==