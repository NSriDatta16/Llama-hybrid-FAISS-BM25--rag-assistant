[site]: crossvalidated
[post_id]: 631344
[parent_id]: 
[tags]: 
Confidence interval for sum of product of scaled binomial random variables

I have discrete, independent, but not necessarily identically distributed random variables $X_1,\dots,X_n$ that take on non-negative integer values. Each random variable has unknown distribution function $F_1,\dots,F_n$ . However, for each $X_i$ , I've got $n_i$ values that were drawn from it, $\mathbf{d}_i = (d_{i1}, \dots, d_{i n_i})$ . I can use this data to build each $X_i$ 's empirical distribution function $\hat{F_i}$ , which can be used to estimate each CDF. Now suppose I were to form a sample where I draw one value per $X_i$ , meaning I generate the sample $(x_1,\dots,x_n)$ where $x_i \sim X_i$ for $i=1,\dots,n$ . Then the probability that $x_1$ is the maximum value of this sample is given by \begin{equation} m_1=\sum_{x=0}^{x=\infty} f_1(x) \prod_{i=2}^n F_i(x) . \end{equation} Since we don't know the CDFs of each random variable, we estimate $m_1$ with the point estimator \begin{equation} \hat{m}_1=\sum_{d \in \mathbf{d}_1^u} \hat{f_1}(d) \prod_{i=2}^n \hat{F_i}(d), \end{equation} where $\hat{f_1}(d)$ is the number of data points equal to $d$ divided by $n_1$ , and $\mathbf{d}_1^u$ is the set of unique values in $\mathbf{d}_1$ (because duplicate values are accounted for already in the definition of $\hat{f_1}$ .) I would like to place a confidence interval on $\hat{m}_1$ . If it helps, \begin{equation} \hat{m}_1 \prod_{i=1}^n n_i \sim \sum_{d \in \mathbf{d}_1^u} \text{Bin}(n_1, f_1(d)) \prod_{i=2}^n \text{Bin}(n_i, F_i(d)). \end{equation} My attempt with CLT The data set used to build each $\hat{F_i}$ is the list $\mathbf{d}_i$ containing $n_i$ data points, \begin{equation} \mathbf{d}_i = (d_{i1}, \dots, d_{i n_i}), \end{equation} so that \begin{equation} \hat{F}_i(x) = \frac{1}{n_i} \sum_{d \in \mathbf{d}_i^u} \mathbf{1}(d \leq x). \end{equation} Then we have that \begin{align*} \mathbb{E}[\hat{m}_1] &= \mathbb{E} \left[ \sum_{d \in \mathbf{d}_1^u} \hat{f}_1 (d) \prod_{j=2}^{n} \hat{F}_j (d) \right], \\ &= \sum_{d \in \mathbf{d}_1^u} \mathbb{E} \left[ \hat{f}_1 (d) \prod_{j=2}^{n} \hat{F}_j (d) \right], \\ &= \sum_{d \in \mathbf{d}_1^u} \mathbb{E}[\hat{f}_1 (d)] \prod_{j=2}^{n} \mathbb{E}[\hat{F}_j (d)], \\ &= \sum_{d \in \mathbf{d}_1^u} f_1 (d) \prod_{j=2}^{n} F_j (d), \\ &= m_1, \end{align*} and I can't be bothered to show the work here, but \begin{equation} \text{Var}(\hat{m}_1)=\sum_{d \in \mathbf{d}_1^u} \left( \frac { f_1(d) + (n_1 - 1) f_1(d)^2 } {n_1} \prod_{j=2}^{n} \frac { F_j(d) + (n_j - 1) F_j(d)^2 } {n_j} - f_1(d)^{2} F_1(d)^{2} \right). \end{equation} Define the sample variance as \begin{equation} s(\hat{m}_1)=\sum_{d \in \mathbf{d}_1^u} \left( \frac { \hat{f}_1(d) + (n_1 - 1) \hat{f}_1(d)^2 } {n_1} \prod_{j=2}^{n} \frac { \hat{F}_j(d) + (n_j - 1) \hat{F}_j(d)^2 } {n_j} - \hat{f}_1(d)^{2} \hat{F}_1(d)^{2} \right), \end{equation} which is a biased estimator of the variance, but consistent. Then the random variable $\frac{m_1 - \hat{m}_1}{\sqrt{s(\hat{m}_1)}}$ should tend to a standard normal distribution as each $n_i$ tends towards infinity. Thus an approximate two-tailed CI at the $\alpha$ significance level is $\left( \hat{m}_1 - z_{\alpha/2} \sqrt{s(\hat{m}_1)}, \hat{m}_1 + z_{\alpha /2} \sqrt{s(\hat{m}_1)} \right)$ . The main problem with this method is that these kinds of confidence intervals are only good when each $n_i$ is large; otherwise, the coverage is very poor. Same reason why the Wald interval usually sucks for small samples. And unfortunately, with the data I'm working on, the length of each $\mathbf{d}_i$ is pretty small. I'm hoping there is a better CI out there, but since $\hat{m}_1$ is basically the sum of the product of scaled binomial random variables whose parameters are already uncertain, I'm not sure we can do much better.
