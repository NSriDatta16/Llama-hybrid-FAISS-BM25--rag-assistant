[site]: stackoverflow
[post_id]: 5626259
[parent_id]: 5625987
[tags]: 
Actually, on a full-blown Map/Reduce framework, such as Hadoop , the data storage itself is distributed. Hadoop, for example, has the HDFS distributed file storage system that allows for both redudancy and high performance. The filesystem nodes can be used as computing nodes, or they can be dedicated storage nodes, depending on how to framework has been deployed. Usually, when mentioning computing times in this case, it is assumed that the input data already exists in the distributed storage of the cluster. The master node merely feeds the computing nodes with data ranges to process - not with the data itself.
