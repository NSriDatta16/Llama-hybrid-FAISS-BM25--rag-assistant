[site]: datascience
[post_id]: 24507
[parent_id]: 
[tags]: 
Q learning and Neural Network for Tic Tac Toe

I have been working on a tic-tac-toe assignment for my Robot Learning class. We were asked to program a tic-tac-toe game and assign; +1 if X wins, -1 if O wins and 0 it the game results with a draw. In part 1, we were told to use Q table and in part 2 we were told to replace the Q table with a Neural network as the functional approximator. It is my understanding that both methods should be achieving the optimal policy, can you confirm or deny my understanding?
