[site]: crossvalidated
[post_id]: 412510
[parent_id]: 
[tags]: 
Treating Word Embeddings as Multivariate Gaussian Random Variables

Suppose I want to specify some probabilistic clustering model (such as a mixture model or lda) over words, and instead of using the traditional method of representing words as an indicator vector $z$ , where $z \sim \text{discrete}(\pi)$ , I want to use the corresponding word embeddings extracted from word2vec, glove, etc. as input. Is it fine for me to specify, say, a gaussian distribution for the word vectors, $x \sim \text{Normal}(\mu, \sigma^2)$ , even if the true data generating process for these embeddings is not from a gaussian? Furthermore, if I were to run this generative model forward and obtain a sample of $x$ , how would I determine what word $x$ would represent? That is, would I just take the word whose embedding was closest (using some distance metric) to $x$ ?
