[site]: crossvalidated
[post_id]: 298775
[parent_id]: 298563
[tags]: 
The simplest approach would be to maximise a weighted sum of the objectives. By giving a larger weight to the harder-to-achieve objectives you encourage the agent to place more emphasis on them. Finding the correct weights to give the desired trade-off between can be difficult though, and sometimes may not be possible as there may be no weights which actually result in certain solutions being obtained. The alternative is to use a non-linear scalarisation of the objectives as suggested in shimao's answer. However that may cause convergence problems for reinforcement learning methods like Q-learning which are based on the Bellman equation. I co-authored a survey paper a few years ago which provides a detailed discussion of these issues, which you may find useful: https://arxiv.org/abs/1402.0590
