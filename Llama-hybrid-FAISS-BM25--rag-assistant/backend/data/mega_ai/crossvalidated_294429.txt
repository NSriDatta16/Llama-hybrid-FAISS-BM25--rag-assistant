[site]: crossvalidated
[post_id]: 294429
[parent_id]: 
[tags]: 
Why is PCA normalization necessary?

I have read a lot of threads concerning this question but I still seem not to understand the reason we normalize data for PCA. If we normalize the data, every feature is on the same scale. To make use of this normalized data for, say, making similarity prediction, we have to normalize new data and project the new data to the obtained PC's. However, if we don't normalize the training data and simply perform PCA, although the PC will change direction to favor features with large variations, we don't need to normalize input data to make similarity prediction anymore. And the new data's features will be on different scales which nicely fit into the PCA model without normalization. Wouldn't it achieve the same thing as normalizing everything and making predictions on normalized data?
