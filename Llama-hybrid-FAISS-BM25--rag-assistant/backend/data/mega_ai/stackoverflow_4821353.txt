[site]: stackoverflow
[post_id]: 4821353
[parent_id]: 4794495
[tags]: 
It looks like you've misunderstood the AJAX crawling guide. The #! notation is to be used on links to the page your AJAX application lives within, not on the URL of the service your appliction makes calls to. For example, if I access your app by going to example.com/app/ , then you'd make page crawlable by instead linking to example.com/app/#!page=1 . Now when Googlebot sees that URL in a link, instead of going to example.com/app/#!page=1 – which means issuing a request for example.com/app/ (recall that the hash is never sent to the server) – it will request example.com/app/?_escaped_fragment_=page=1 . If _escaped_fragment_ is present in a request, you know to return the static HTML version of your content. Why is all of this necessary? Googlebot does not execute script (nor does it know how to index your JSON objects), so it has no way of knowing what ends up in front of your users after your scripts run and content is loaded. So, your server has to do the heavy lifting of producing a HTML version of what your users ultimately see in the AJAXy version. So what are your next steps? First , either change the links pointing to your application to include #!page=1 (or whatever), or add to your app's HTML. (See item 3 of the AJAX crawling guide .) When the user changes pages (if this is applicable), you should also update the hash to reflect the current page. You could simply set location.hash='#!page= n '; , but I'd recommend using the excellent jQuery BBQ plugin to help you manage the page's hash. (This way, you can listen to changes to the hash if the user manually changes it in the address bar.) Caveat: the currently released version of BBQ (1.2.1) does not support AJAX crawlable URLs, but the most recent version in the Git master (1.3pre) does, so you'll need to grab it here . Then, just set the AJAX crawlable option: $.param.fragment.ajaxCrawlable(true); Second , you'll have to add some server-side logic to example.com/app/ to detect the presence of _escaped_fragment_ in the query string, and return a static HTML version of the page if it's there. This is where Google's guidance on creating HTML snapshots might be helpful. It sounds like you might want to pursue option 3. You could also modify your service to output HTML in addition to JSON.
