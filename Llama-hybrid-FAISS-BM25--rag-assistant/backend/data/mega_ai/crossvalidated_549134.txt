[site]: crossvalidated
[post_id]: 549134
[parent_id]: 
[tags]: 
Explicit form and function of posteriori probability when Y=1

I'm a machine learning student doing a deeper dive into Bayesian classification, but I'm having some real trouble with the notation and mathematics of the underlying statistical mechanisms. I'm trying to derive the explicit form of the posteriori probability when $Y = 1$ . Let $X\in\mathbb{X}=[0,1]$ and $Y\in\{ 0,1 \}$ and suppose $\pi_y=P(Y=y)=1/2$ for $y\in{0,1}$ and conditional distributions $[X|Y=y]$ are characterised by $f(x|Y=0)=2-2x$ and $f(x|Y=1)=2x$ . Define Bayes' classifier for $Y\in\{0,1\}$ as $r^*(x)=\begin{cases}1\quad if\space\tau_1(x)>1/2,\\0\quad otherwise,\end{cases}$ where $\tau_1(x)=P(Y=1|X=x)$ I'm not exactly sure what the explicit form of $\tau_1$ is? Is it $\tau_1(x)=\frac{\tau_1f_1(x)}{\sum_{g'=1}^G\pi_{g'}f_{g'}(x)}$ ? And finally, how would you plot it? Is it just $f(x)=x$ ?
