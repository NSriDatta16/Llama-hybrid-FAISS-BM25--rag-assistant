[site]: crossvalidated
[post_id]: 482220
[parent_id]: 
[tags]: 
Does machine learning on random situations require a cryptographically-secure random number generator?

I'm working on a project involving using machine learning to figure out optimal strategies to play board games, and after a few rolls of the virtual dice a thought hit me: For the games that involve randomness, such as those with dice, there can be significant value in predicting future dice rolls. And the rolls themselves are not, of course, truly random. Given this, do I reasonably have to fear that after learning through all the low-hanging fruit as far as gameplay is concerned, my ML models may try to optimize for the specific random number generator I am using, such as by predicting future rolls? If so, would a cryptographically-secure random number generator be necessary to obviate this, or are there computationally-cheaper alternatives that offer the same protection from ML "gaming the system" in this way?
