[site]: crossvalidated
[post_id]: 123876
[parent_id]: 
[tags]: 
Unclear area in Convolutional Neural Net

I have a question about the conv neural net. Specially from the deeplearning tutorial at http://deeplearning.net/tutorial/lenet.html . In Fig 1 from that url, (and also similarly in between C3 and S4, in Fig 2 of the Gradient Based Learning paper by Lecun Yann), I cannot understand how all the feature maps from layer m-1 gets into a single pixel on layer m, using a single filter/kernel. For this to happen the kernel needs to be 3D. But I cannot understand how exactly a 3D kernel convolution works on 3 different images. Is it a average of the 3 values after applying 3 2D convolutions ? The documentation says "and pool over several input channels" . What is the significance of pool here ? Also the kernel (or weights) as created in the code below (under "We use two convolutional filters with 9x9 receptive fields. ...."), has all values different. I would have assumed that at least per filter/kernel the values will be replicated on the 3 planes. So that the same feature is extracted from all the 3 maps. If the values are all different, then conceptually, the "one value" that comes out of the convolution does not seem to have a "purpose" as it is getting all mixed messages.
