[site]: crossvalidated
[post_id]: 104743
[parent_id]: 
[tags]: 
When is it a good idea to just use the average for imputation?

Suppose we have a data set test : 1 8 12 14 . . 19 The . denotes missing values. When would it be better to use the average of the non-missing values to impute the missing values rather than assuming that the data comes from a normal distribution?
