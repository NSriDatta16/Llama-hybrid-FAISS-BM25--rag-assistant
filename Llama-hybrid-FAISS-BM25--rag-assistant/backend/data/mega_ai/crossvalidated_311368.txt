[site]: crossvalidated
[post_id]: 311368
[parent_id]: 311334
[tags]: 
The easiest solution is to use the linear regression formulation of DID: Regress the binary customer ratings on a constant, a post dummy, an area A dummy, and the interaction of last two. It may be appropriate to add other regressors measuring characteristics that are time-invariant at the individual level, but whose distribution changes through time at the group level. This may help with the significance issue below if it soaks up some residual variance. The DID is the coefficient on the interaction of post and group A. You can conduct the hypothesis test that it is zero or just look at the p-value or t-stat. Since treatment does not vary within area, the usual standard errors will be off (usually too small, but sometimes too large, when the within cluster error correlation is negative). The typical solution is to cluster the standard errors by area or cross-section, but with only 2-4 clusters, that will not work well since that is not enough clusters for the asymptotics to kick in. I don't really have a great solution for you here. Stata does compute something below, but it is not likely to be reliable (even with the small number of clusters adjustment). I do suspect that the correct adjustment will not yield significance since the conventional standard error on the DID coefficient is so large. People will often use simulation in cases like this to gauge how far off the SEs are. Here's this analysis for your data: . clear . input area_a time noobs rating area_a time noobs rating 1. 1 0 64 1 2. 1 0 66 0 3. 1 1 82 1 4. 1 1 36 0 5. 0 0 44 1 6. 0 0 56 0 7. 0 1 60 1 8. 0 1 40 0 9. end . egen cs = group(area_a time) . reg rating i.area_a##i.time [fw=noobs] Source | SS df MS Number of obs = 448 -------------+---------------------------------- F(3, 444) = 6.05 Model | 4.34181458 3 1.44727153 Prob > F = 0.0005 Residual | 106.149257 444 .239074903 R-squared = 0.0393 -------------+---------------------------------- Adj R-squared = 0.0328 Total | 110.491071 447 .247183605 Root MSE = .48895 ------------------------------------------------------------------------------ rating | Coef. Std. Err. t P>|t| [95% Conf. Interval] -------------+---------------------------------------------------------------- 1.area_a | .0523077 .0650368 0.80 0.422 -.0755105 .1801259 1.time | .16 .0691484 2.31 0.021 .0241012 .2958988 | area_a#time | 1 1 | .0426076 .0929871 0.46 0.647 -.1401419 .225357 | _cons | .44 .0488953 9.00 0.000 .3439051 .5360949 ------------------------------------------------------------------------------ . reg rating i.area_a##i.time [fw=noobs], vce(cluster area) // or vce(cluster cs) Linear regression Number of obs = 448 F(0, 1) = . Prob > F = . R-squared = 0.0393 Root MSE = .48895 (Std. Err. adjusted for 2 clusters in area_a) ------------------------------------------------------------------------------ | Robust rating | Coef. Std. Err. t P>|t| [95% Conf. Interval] -------------+---------------------------------------------------------------- 1.area_a | .0523077 1.08e-16 4.8e+14 0.000 .0523077 .0523077 1.time | .16 1.01e-16 1.6e+15 0.000 .16 .16 | area_a#time | 1 1 | .0426076 1.30e-16 3.3e+14 0.000 .0426076 .0426076 | _cons | .44 1.01e-16 4.4e+15 0.000 .44 .44 ------------------------------------------------------------------------------ The interpretation of the interaction coefficient in both specifications is a 4.3 percentage point increase in liking your service post-intervention. The linear model has the advantage of easier interpretation of an additive effect on a probability rather than a multiplicative effect on log odds. Moreover, in a non-linear logit model, clustering is problematic since the coefficients are identified up to scale only, the interpretation of interactions and identifying assumptions can get tricky, and the DID is no longer just the cross difference in the four means (see the Puhani paper cited below on the latter point). Finally, in a fully saturated model with all the interactions, the logit and the linear model will give identical point estimates of the cross difference marginal effect (though that is not the parameter you care about): . /* Cross difference to mimic OLS, but wrong */ . logit rating i.area_a##i.time [fw=noobs], nolog Logistic regression Number of obs = 448 LR chi2(3) = 17.87 Prob > chi2 = 0.0005 Log likelihood = -298.57102 Pseudo R2 = 0.0291 ------------------------------------------------------------------------------ rating | Coef. Std. Err. z P>|z| [95% Conf. Interval] -------------+---------------------------------------------------------------- 1.area_a | .2103904 .2671347 0.79 0.431 -.3131839 .7339647 1.time | .6466272 .2867945 2.25 0.024 .0845203 1.208734 | area_a#time | 1 1 | .2073448 .3911528 0.53 0.596 -.5593006 .9739902 | _cons | -.2411621 .2014557 -1.20 0.231 -.6360081 .1536839 ------------------------------------------------------------------------------ . margins r.area_a#r.time Contrasts of adjusted predictions Model VCE : OIM Expression : Pr(rating), predict() ------------------------------------------------ | df chi2 P>chi2 -------------+---------------------------------- area_a#time | 1 0.21 0.6456 ------------------------------------------------ -------------------------------------------------------------------- | Delta-method | Contrast Std. Err. [95% Conf. Interval] -------------------+------------------------------------------------ area_a#time | (1 vs 0) (1 vs 0) | .0426076 .0926461 -.1389755 .2241906 -------------------------------------------------------------------- I believe the correct marginal effect of 4.6 percentage points is given by this: /* Puhani's DID Estimator */ gen at = area*time logit rating i.area_a i.time i.at [fw=noobs], nolog margins, at(area_a==1 time==1 at ==1) at(area_a==1 time==1 at==0) contrast(atcontrast(a._at) wald) "The Treatment Effect, the Cross Difference, and the Interaction Term in Nonlinear “Difference-in-Differences” Models by Patrick A. Puhani, Economics Letters, 2012, 115 (1), 85-87.
