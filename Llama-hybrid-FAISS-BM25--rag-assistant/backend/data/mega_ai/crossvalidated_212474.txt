[site]: crossvalidated
[post_id]: 212474
[parent_id]: 172502
[tags]: 
This question is quite old but I stumbled upon this when I had the same question and was able to figure out an answer. For the voted perceptron, There are nonlinear boundaries. Consider a simple example: You have two weight vectors $(0,1)$ and $(-1,0)$ and are trying to discern between positive and negative examples. Both weight vectors have a "survival time" of 1 (i.e. they both last the same number of iterations during the training phase). The only instances which are labeled as positive will be in the upper left quadrant. Clearly this is nonlinear. For the averaged perceptron, consider the same example. In this case, we have a linear boundary becasue we just average the two weight vectors: $\frac{1(0,1) + 1(-1,0)}{2} = (-1/2, 1/2)$. Clearly this single weight vector defines a linear decision boundary.
