[site]: datascience
[post_id]: 57910
[parent_id]: 
[tags]: 
measuring flip-flop behaviour across several topics

I'm trying to analyze a behavior called "sentiment flipping" of users in a dataset, but I'm not able to step on. Let's suppose that I have two groups of users, say them good and bad users. My dataset contains N tweets that classified into 6 topics. The tweets were created by the bad and good users. The 6 topics are about general issues, but 3 of these topics are about organization/individuals supported (A) by the "bad" users and the other 3 are against (B) their ideologies. The difference between the bad and good users in their tweeting behavior is: The good user posted tweets in some of the topics (and maybe all of them) without forcing "positive" or "negative" sentiment in the topics. The bad user posted tweets contain negative sentiment on the topics against her/his ideologies and positive sentiment on the topics she/he supports. The clear difference between both users also is that the bad user posts negative sentiment profusely on B topics and positive sentiment on A topics. How can I measure/show this flipping behavior in a score/value; given that each tweet is represented by a vector like: . I think a good solution will consider how dense and ideologically clear the bad user behavior. This image summarizes the previous description:
