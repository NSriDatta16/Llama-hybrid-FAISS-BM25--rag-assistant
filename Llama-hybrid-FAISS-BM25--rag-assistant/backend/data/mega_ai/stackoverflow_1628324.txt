[site]: stackoverflow
[post_id]: 1628324
[parent_id]: 1628032
[tags]: 
For question 1, external fragmentation normally causes an overhead of about 2x or so, 1 plus you have internal fragmentation from allocation granularity. Neither of these comes close to explaining your observation. So, I don't think it is normal steady-state fragmentation. The most obvious speculation is that 1.5MB is the high-water mark; at one time it really did have either 1.5MB bytes of entries or 1.5MB/2 bytes of entries with expected fragmentation. Another speculation is that the 50% rule is being defeated by a non-Markovian allocation. Imagine that I name files with "tmp%d", so, tmp1, tmp2, ... tmp1000, tmp1001, ... The problem here is that rm tmp1 doesn't make room for tmp1001 . This is obviously a wild guess. Q2: There isn't a good way to read the raw directory. AFAIK, you would need to either hack the kernel or use debugfs to change the inode type, read it, then change it back, or use debugfs to read the inode, get the block numbers, then read the blocks. A functional debugging approach is probably more reasonable. You can address the performance issue by making sure that indexing is enabled. See tune2fs . 1 Knuth's fifty percent rule: in the steady state, 50% of ops are allocations, 50% are frees, 50% of free blocks merge, then holes are 50% of allocations, and 50% of the space is wasted. (Aka, 100% overhead.) This is considered "normal". Malloc has the same problem.
