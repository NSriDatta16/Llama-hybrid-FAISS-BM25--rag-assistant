[site]: crossvalidated
[post_id]: 368692
[parent_id]: 368658
[tags]: 
I'm going to provide a Bayesian answer, I suspect/hope others will provide a more frequentist view. I would first come up with an answer to the question "given a car which I know nothing about, what would be the distribution reflecting my beliefs about the likely mpg of that car, given the data set I've just seen?". As a Bayesian, you have to make some assumptions, perhaps the mpg distribution of all cars is Gaussian or (as it technically can't be normal) gamma, lognormal etc. Using this plus a prior, calculate a posterior distribution. Effectively you're saying, given the cars you've seen, what do you think the range of possible mpgs of all cars out there might look like. You can perform the same for cars of all colours, and for cars of all interiors. Finally, you can do the same for cars of all colour-interior combinations. Of course, as you go more and more sparse, you have less data, meaning your likelihood function will be less peaked and your posterior will look more like your prior (which, provided you chose a sensible prior, will be pretty wide, as you should approach the problem with an open mind, but this subjectively is clearly the weakness of any Bayesian method). Based on your posteriors, you can start to answer questions like "what is the probability that a red car has an mpg of at least 1 better than a car I have no information about?", or "what is the probability that a red car has an mpg of at least 2 better than a green car?" As you start asking more detailed questions such as "what is the probability that a red, interior leather car has an mpg of X better than a green car with a cotton interior?", you'll start to find that you get less and less useful answers (e.g. the probability is basically the same as if you had no information about the cars), so you reach this tradeoff where having more information about the car is actually like having less, because you have less data to base your assertions on. Yes, this approach has subjective elements, the choice of distribution for your likelihood (technically you can do model selection, but this is hard work), and the prior, and requires a lot of manual examination of plots and judgements, but in many ways it's also very intuitive and in my own personal opinion, very powerful.
