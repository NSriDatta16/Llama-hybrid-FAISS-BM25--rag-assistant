[site]: stackoverflow
[post_id]: 2244888
[parent_id]: 2243966
[tags]: 
With such small magnitudes of difference (10^-08, you state), I suspect that intermediate calculations are causing the problem. Note that double-precision values are 64 bit, but the registers can work with 80 bits of precision. So, if you have a code sequence where the compiler will keep all your intermediate calculations on the registers, you will actually get better precision than if the same calculations are made across different points in your code, forcing the intermediate results to be held in 64 bit storage locations. If you store values within Excel cells as part of your calculations, this, too, will result in truncating your intermediate calculations to 64 bits of precision. You really need to show your code: show both (a) the Excel calculations (is it a worksheet formula or are you making programmatic assignments to the cell values?) and (b) the C# calculations that you are making. If you do that, then we should be able to help you more precisely. But with the information you've given so far, we can only make broad guesses. -- Mike
