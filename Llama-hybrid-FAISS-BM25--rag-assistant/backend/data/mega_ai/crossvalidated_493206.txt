[site]: crossvalidated
[post_id]: 493206
[parent_id]: 493050
[tags]: 
Such relationships are conventionally summarized with contingency tables, as in this (random) example: Col 1 Col 2 Col 3 Col 4 Row 1 3 6 40 34 Row 2 18 6 9 1 Typically we are interested in comparing these data to values suggested by some default model, such as a null model of independent row and column proportions. When comparing the data to those values, the actual counts are important because they are proportional to the variances of the differences. Consequently, a good visualization would clearly show the counts and their expected values, preferably organized to parallel the table. Studies by psychologists and statisticians indicate that graphical elements like hue and shade do a relatively poor job in depicting quantities like counts. Although length and position tend to be clearest and most accurate, they are suited only for showing relative counts: that is, their proportions. Not good enough. I therefore propose to represent any count $k$ by drawing $k$ distinct, non-overlapping identically-sized graphical symbols, so that each symbol clearly represents one thing that is counts. To make this work well, my experiments have found the following: Clustering the symbols into a compact object seems to work better than positioning them randomly within a drawing area. Overplotting the symbols on a polygon whose area represents the expectation permits a direct visual comparison of the count to its expectation. Rectangles, concentric with the symbol clusters, suffice for this purpose. As a bonus, the standard error of each count, which is proportional to its square root, is thereby represented by the perimeter of its reference polygon. Although this is subtle, it's nice to see such a useful quantity appear naturally in the graphic. People gravitate towards colorful graphics, but because colors might not reproduced (think of page charges in a research journal, for instance), I apply color to distinguish the cells but not to represent anything essential. Here is an example of this solution for the table above: It is immediately clear which cells have overly large counts and which have overly small ones. We even get a quick impression of how much they exceed or fall short of their expectations. With a little practice, you can learn to eyeball the chi-squared statistic from such a plot. I have decorated the figure with the usual accompaniments: row and column labels to the left and top; row and column totals to the right and bottom; and the p-value of a test (in this case, Fisher's Exact test of independence as computed with a million simulated datasets). For comparison, here is the visualization with randomly dispersed symbols: Because the symbols are no longer clustered, it's useless to draw the reference rectangles. Instead, I have used the cell shading to represent expected values. (Darker is higher.) Although this method still works, I get more out of the first (clustered) version. When either or both of the variables are ordered, the same visualization is effective provided the rows and columns follow the ordering. Finally, this works well for $2\times 2$ tables. Here is one that came up in an analysis of an age discrimination case where it was alleged that older workers were preferentially fired. Indeed, the table looks a little incriminating because no younger people were let go at all: Old Young Kept 135 26 Fired 14 0 The visualization, however, indicates a close agreement between the observations and the expected values under the null hypothesis of no relationship with age: The Fisher Exact test p-value of $0.134$ supports the visual impression. Because I know people will ask for it, here is the R code used to produce the figures. m nrow*ncol) { warning("Unable to generate enough samples") n
