[site]: crossvalidated
[post_id]: 179255
[parent_id]: 
[tags]: 
Hypothesis testing - significant differences in 2D spatial data

This question is derived from a previous post , but the problem has changed somewhat and more information is provided here. The challenge: In an actual experiment, 40 dice are dropped into a body of water from a single point at the surface. They naturally diffuse as they sink through the water and settle on the floor of a tank. We have three different types of die, small, medium and large. Naturally the large dice diffuse more and occupy a larger area on the bottom after settling. Now, we can assume that the distribution of dice at the bottom have an isotropic normal distribution. A light and a heavy dice drop of 50.000 dice have been simulated by: N = 50000; sigma = 1; % The diffusion, 1 for small dice and 3 for large dies to emphasize difference x = (normrnd(0,sigma,N,1)); y = (normrnd(0,sigma,N,1)); pos = [x y]; r = sqrt(y.*y + x.*x); % Calculate the distance from the centroid to each die scatter(x,y); hist(r,50); hist(sqrt(r),50); sigma = 1 and sigma = 3 produced the following two plots: Now, I want to prove that the diffusion at sigma=1 is significantly different to sigma = 3. Of course, sigma will be unknown and a result of empirical observations. This can possibly be done by using the average radius r. An idea: The radial distribution looks like this: This looks fine, but many tests such as ANOVA assume normality. Obviously, these plots are positive skewed. Applying a sqrt() transform yields this: Would it now make sense to run a one-way ANOVA on the sqrt(r) data? I find the sqrt() transform strange to use as r would never be normally distributed. Any help is greatly appreciated.
