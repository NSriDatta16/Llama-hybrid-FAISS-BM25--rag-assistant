[site]: crossvalidated
[post_id]: 146106
[parent_id]: 146092
[tags]: 
I think you're confusing how to build a model from data and how to quantify a model accuracy once it's built. When you want to build a model (linear regression in your case I guess?), you would usually use the least square error method that is minimizing the "total" euclidean distance between a line and the data points. Theoretically the coefficients of this line can be found using calculus but in practice, an algorithm will perform a gradient descent which is faster. Once you have your model, you want to evaluate its performances. Thus, in the case of regression, it may be good to compute a metric which evaluate "how far" is your model to the actual data points (or test set data if you have one) in average. The MSE is a good estimate that you might want to use ! To sum up, keep in mind that LSE is a method that builds a model and MSE is a metric that evaluate your model's performances.
