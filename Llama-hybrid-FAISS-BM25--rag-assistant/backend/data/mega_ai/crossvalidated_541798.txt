[site]: crossvalidated
[post_id]: 541798
[parent_id]: 380296
[tags]: 
The Kolmogorov-Smirnov test is a test of the null hypothesis that your data come from some prespecified distribution, $F$ . Coming from a Normal distribution is a much wider null hypothesis; there are lots of Normal distributions. At one time it was common to find the best-fitting Normal distribution to your data (by estimating the mean and variance from the data), then pretend that was a prespecified distribution and do a Kolmogorov-Smirnov test. It's pretty clear that you will be less likely to reject the null that way -- the fitted normal distribution will fit your data better, because it has been fitted to your data. So, if you take the test statistic $D$ and your observed value $d$ , and calculate the $p$ -value $P(D\geq d)$ as if you had a prespecified distribution, the number you get will be too large. It will be larger than the true $P(D>d) for the testing procedure you actually used. Lilliefors's test fixes this up. It uses the same test statistic $D$ (the maximum vertical difference between cumulative distribution functions), but it calculates the null distribution of $D$ taking account that you have estimated the mean and variance from the same data. How does it do that? By brute-force simulation. Someone (Hubert Lilliefors, or perhaps his research assistants) generated lots of sets of data from Normal distributions, did the KS test on each set, and made a big table of the null sampling distribution. They did this in 1967 when it was a big deal; you could do the same thing in a few minutes now with R but we've gotten used to using the stored tables.
