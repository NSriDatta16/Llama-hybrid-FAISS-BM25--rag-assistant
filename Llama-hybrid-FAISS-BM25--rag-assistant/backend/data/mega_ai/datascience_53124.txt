[site]: datascience
[post_id]: 53124
[parent_id]: 53114
[tags]: 
Before I answer your question, let me tell you this, You can go on and train a model from scratch, but you will definitely end up using one of the object detection architectures, be it Mask R-CNN, Faster R-CNN, Yolo or SSD. Your problem is a simplified version of what these architectures are trying to solve. These are generic object detectors that some of which supports more 1k classes. You have a single class detection problem. Now back to your question. For training an object detection model, should the image be kept as an input and the coordinates as the output of the model? Should there be Convolution layers for feature extraction and then FC layers for learning the features for producing 4 outputs ( coordinates of the bounding box )? No, it is not that simple. Training a FCN to output 4 values as Bounding boxes wont work. All object detectors mentioned earlier are based on assumptions, Faster R-CNN for example generates proposals (regions) its assuption is that these regions are very likely to contain an object, then does an additional step by classifying which class each region contains (you only have one class) and finally refining the output. The most important thing in Faster R-CNN is region proposal network, which iterates through the final convolution layer in a sliding window fashion, generating proposals in the different aspect ratios, for example 1:1, 1:2 and 2:1. Why am I saying all this? Because I want you to understand, that the problem is not as easy as you think it is. Further Reading: https://medium.com/@tanaykarmarkar/region-proposal-network-rpn-backbone-of-faster-r-cnn-4a744a38d7f9 https://medium.com/diaryofawannapreneur/yolo-you-only-look-once-for-object-detection-explained-6f80ea7aaa1e
