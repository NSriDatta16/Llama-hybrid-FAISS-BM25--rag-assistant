[site]: crossvalidated
[post_id]: 548010
[parent_id]: 
[tags]: 
Why would AUC on a validation set increase while loss increases?

I'm training a deep learning model in PyTorch. The first two images I posted here make perfect sense as they are the classical idea of overfitting. The training loss keeps decreasing while the validation loss reaches a minimum and then starts to increase again. I assume this is where it would make sense to stop training the model. What I don't understand is why the AUC on the validation set would keep increasing monotonically the entire time. Shouldn't it also reach a maximum and then start to decrease due to overfitting?
