[site]: crossvalidated
[post_id]: 41814
[parent_id]: 41092
[tags]: 
This is a classical example in the field of Probabilistic Graphical Models (PGMs). PGMS are widely used in several areas, from text mining to bioinformatics, for problems such as inference and naturally belong within Machine Learning/pattern recognition/artificial intelligence. As you have correctly suggested, the Bayes rule play a major role here. In essence, you can think of PGMs as a simplified representation of a very large joint distribution over many variables (simplified due to independence of variables), and some of the methods consist of repeatedly applying the Bayes rule. A simple example of a PGM is a Hidden Markov Model (HMM), which is especially relevant to your example. Lucky for you, there is very good material for studying PGMs and even more on HMMs: Prof. Daphne Koller from Stanford gives a free PGM course online, and I also recommend her book if you want a very rigorous (CS/math) treatment of the subject. For HMMs you can just google to find dozens of tutorials and select the one that fits your background the most. Finally, PGMs are just one way of doing this kind of inference and if you want to expand your knowledge of such predictive methods you should look into the more general field of Machine Learning which I think you will find rich, deep and applicable (but maybe that's just me).
