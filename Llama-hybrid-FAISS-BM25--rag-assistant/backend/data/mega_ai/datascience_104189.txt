[site]: datascience
[post_id]: 104189
[parent_id]: 15135
[tags]: 
I would like to summarize all the good and elegant answers. The sklearn.model_selection. train_test_split is de facto option for train, validation split. However, if you want train,val and test split, then the following code can be used. (Extending answer from 0_0 ) Let's say you want to do a split of 75,15 and 10 percentages. If you have data and labels in the panda dataframe then use the following # suffle and split train_df, val_df, test_df = np.split(df.sample(frac=1), [int(.75*len(df)), int(.9*len(df))]) Let's say you have data and labels in 2 different NumPy arrays. data = np.arange(1000) data = np.reshape(data,(100,10)) # 100 examples with 10 features labels = np.arange(100) # assuming 100 different categories print(data[3]) print(labels[3]) idx = np.random.permutation(len(data)) # get suffeled indices x,y = data[idx], labels[idx] # uniform suffle of data and label x_train, x_val, x_test = np.split(x, [int(len(x)*0.75), int(len(x)*0.9)]) # split of 75:15:10 y_train, y_val, y_test = np.split(y, [int(len(y)*0.75), int(len(y)*0.9)]) print(len(x_train),len(x_val),len(x_test)) print(x_train[:3]) print(y_train[:3])
