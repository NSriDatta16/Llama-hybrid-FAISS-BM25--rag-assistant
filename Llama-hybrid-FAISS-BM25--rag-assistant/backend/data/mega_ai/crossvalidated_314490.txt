[site]: crossvalidated
[post_id]: 314490
[parent_id]: 
[tags]: 
Regression RMSE when dependent variable is log transformed

I want to predict the duration a trip would take. For this I transformed my dependent variable (trip time in sec) to log transformed. When I do regression on this variable with some other features, I get this: The score on held out data is: 0.08395386395024673 Hyper-Parameters for Best Score : {'l1_ratio': 0.15, 'alpha': 0.01} The R2 Score of sgd_regressor on test data is: 0.0864573982691922 The mse of sgd_regressor on test data is: 0.5503753581 The mean absolute error of sgd_regressor on test data is: 0.566328128068 This is the code which does the above calculation: from sklearn.metrics import mean_squared_error, mean_absolute_error # print("The R2 Score of "+ name + " on test data is: {}\n".format(self.g_cv.best_estimator_.score(self.test_X,self.test_Y))) print ("The mse of "+ name + " on test data is:",\ mean_squared_error(test_Y, self.g_cv.best_estimator_.predict(self.test_X))) print ("The mean absolute error of "+ name + " on test data is:",\ mean_absolute_error(test_Y, self.g_cv.best_estimator_.predict(self.test_X))) Problem is R2 as you see is very bad. 0.08, but RMSE and Mean Absolute error seem to be very low. If I look at Mean Absolute Error, its just 0.56 sec. Which means on an average my predicted time is only half a second different from true time. Something doesn't look right. Do I need to convert the predicted and original time variable back to linear scale from log scale before I calculate the above metrics (RMSE and MAE)?.
