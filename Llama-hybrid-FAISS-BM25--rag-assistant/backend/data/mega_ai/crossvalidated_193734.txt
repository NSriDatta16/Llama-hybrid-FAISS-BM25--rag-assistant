[site]: crossvalidated
[post_id]: 193734
[parent_id]: 
[tags]: 
How do I reduce number of features without rebuilding the model?

I'm pretty new to ML/NLP thus my question maybe naive. How do I reduce number of features without rebuilding the model for Naive Bayes Classification? I'm using MALLET to build the model to classify scientific articles to ~30 categories. I lemmatize text before processing. It brings the problem of excessive number of words/features. For 230K articles I have ~13M unique words :( So I thought what if I build model for ~5000 articles, sort probabilities of features for each class, take top 1000 and use only them. I could of course create white-list of words and rebuild the model but that would be slow. Can I just take top N words, throw away the rest and then scale probabilities of new set or words to make the sum ~1.0 ? Would it be mathematically correct ? In case you wonder how it's implemented I wrote following code (in Scala) var classifier: NaiveBayes = ... // Loaded valid model here val numWords = 10000 // Number of words/features I want to use per class val multinomials = classifier.getMultinomials // Map of -> val topProbabilities = multinomials.map { prob => val probabilities = prob.getValues.map(Math.exp).zipWithIndex.sortBy(_._1).reverse probabilities.take(numWords).map(_.swap) } // Map of position of words in old alphabet to actual word and position in new alphabet val alphMap = topProbabilities.flatMap(_.map(_._1)).distinct.zipWithIndex.map { case (oldId, newId) => (oldId, (newId, classifier.getAlphabet.lookupObject(oldId)) ) }.toMap val alphabetNew = new Alphabet(alphMap.values.toArray.sortBy(_._1).map(_._2)) // Create array of doubles with scaled probabilities per each class val newProbabilities = topProbabilities.map { pairs => // I fill blanks for probabilities of missing words to minimal positive number val doubles = Array.fill(alphabetNew.size())(Double.MinPositiveValue) pairs.foreach{ case (oldPos: Int, v: Double) => doubles(alphMap(oldPos)._1) = v } val factor = 1 / doubles.sum val doublesScaled = doubles.map(v => v * factor) new Multinomial.Logged(doublesScaled, alphabetNew) } var classifierNew = new NaiveBayes(classifier.getInstancePipe, classifier.getPriors, newProbabilities) val words = scala.io.Source.fromFile("/home/expert/test_article.txt").getLines().mkString("").split(" ") println(classify(classifier, words).getLabeling.getBestLabel) println(classify(classifierNew, words).getLabeling.getBestLabel) Sadly new "reduced" model misclasifies any article to first class :(
