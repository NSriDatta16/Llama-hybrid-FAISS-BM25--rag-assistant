[site]: crossvalidated
[post_id]: 31386
[parent_id]: 
[tags]: 
Evaluation of groups of parameters across multiple data sets in logistic regression

I have a logistic regression problem where I want to evaluate the aggregate contribution of groups of parameters (independent variables) across different sets of observations. For instance, let's say I have 10 total parameters, 5 of which belong to Group1, for a given data set. I can easily compare the full model to the model without Group1, using a pseudo R^2, likelihood ratio test, AIC, or similar, to describe the contribution of Group1 to DataSet1. What I need to do is aggregate these comparisons across different data sets, where the solutions are not necessarily related (ie the 'true' coefficients are not the same per parameter across data sets) - I am interested in the amount of information conveyed by the group of parameters in aggregate, not the coefficients themselves. So, I cannot train a single model using all the observations. One example solution I came up with is to add the model deviances (deviance = -2*loglikelihood) after solving each model independently and calculate the likelihood ratio/AIC/pseudo R^2 etc as if it were one large model. One complication of this, however, is that the number of parameters in the group or full model might change in each data set. For instance, in DataSet1, Group1 may have 5 parameters (or 6 parameters but no observations for parameter 6 - the params are usually categorical - etc), but in DataSet2, Group1 may have 3 or 7 or 150 parameters, etc. So, to calculate AIC or p-value for the likelihood ratio test, I have calculated the effective #params as the weighted average #params based on #observations in each data set. Alternatively, I could fix the #params as the max from each data set, but I fear this would artificially squash my results. I'd love some feedback on this approach or pointers to alternatives.
