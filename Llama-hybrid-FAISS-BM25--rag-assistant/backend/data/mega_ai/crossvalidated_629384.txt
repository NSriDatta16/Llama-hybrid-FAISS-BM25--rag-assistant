[site]: crossvalidated
[post_id]: 629384
[parent_id]: 527080
[tags]: 
I decide to add this answer because temperature in Softmax is a case of wonder: From How does entropy depend on location and scale? , we would have: The (differential) entropy of $z=y\beta$ is the entropy of X plus $\log(Ïƒ)$ . So, as $\beta \to 0$ , the differential entropy of $z$ tends to $-\infty$ . At the same time, as $z$ tends toward a continuous variant of degenerate distribution, the Shannon entropy of the projection $z_i$ now tends toward $\frac{1}{n}$ . So while high temperature increase the Shannon entropy for $z_i$ , it actually decreases the differential entropy of the complete embedding vector $z$ .
