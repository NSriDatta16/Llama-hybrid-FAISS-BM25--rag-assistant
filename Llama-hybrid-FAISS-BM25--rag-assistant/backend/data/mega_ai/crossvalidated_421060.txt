[site]: crossvalidated
[post_id]: 421060
[parent_id]: 
[tags]: 
Shapley value vs ridge regression

My goal is to get the feature importance for multiple regression. I have a data set with some multicollinearity. I found two methods to solve this problem. The first one is the Shapley value. Shapley value computes the regression using all possible combinations of predictors and computes the R $^2$ for each model. Then for each predictor, the average improvement will be calculated that is created when adding that variable to a model. As an example, I use the Boston data set (I found this result on different data sets). library(relaimpo) library(MASS) data(Boston) mod_lm = lm(medv ~ ., data = Boston) calc.relimp(mod_lm, type = c("lmg")) The relative importance is scaled to 100%. In the case, Islat is ~5.5 times as important as tax (I just show the relative importance but not the whole output). Relative importance metrics: lmg crim 0.03669197 zn 0.03349910 indus 0.05101231 chas 0.02139033 nox 0.04511571 rm 0.25259867 age 0.02975151 dis 0.04087946 rad 0.03190385 tax 0.04967225 ptratio 0.10602348 black 0.03093651 lstat 0.27052485 Ridge regression adds a penalty to all beta coefficients. The size of the penalty is dependent on the RMSE in the cross-validation or bootstrap. I standardize the data to get the relative importance. library(caret) Boston_scaled = scale(Boston) fit = train(medv~., data = Boston_scaled, method = "glmnet", preProcess = NULL, tuneGrid = expand.grid(alpha = 0, lambda = seq(0,1, by = 0.1))) coef(fit $finalModel, fit$ bestTune$lambda) In this case, Islat is only 3.5 times as important as tax. 14 x 1 sparse Matrix of class "dgCMatrix" 1 (Intercept) -0.0000000000000006334209 crim -0.0819019359606095592730 zn 0.0828741063806194971919 indus -0.0283478772157603683968 chas 0.0800825186065121513712 nox -0.1501007822559678184238 rm 0.3064458129978267497684 age -0.0114206187124149035478 dis -0.2561703730728009387185 rad 0.1455422731561680227408 tax -0.1053881725850110001597 ptratio -0.2012584716226800130023 black 0.0900702979932691133458 lstat -0.3668119207994711694631 Since both metrics are standardized I should get similar results. Can someone explain the difference in the results?
