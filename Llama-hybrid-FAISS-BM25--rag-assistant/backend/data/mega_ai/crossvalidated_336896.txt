[site]: crossvalidated
[post_id]: 336896
[parent_id]: 336882
[tags]: 
Any model seems to only recognize the shape, without worry to any correct dimensions or rotation It is a known problem that CNNs aren't particularly good at handling such transformations (precisely, their output is not invariant/equivariant under such transformations). The way to handle this in practice is to augment your data (in Keras you can do this with these tools ). Is mobilenet the wrong structure? Should the output layers be structured differently? You didn't mention which layers you use. Did you try lower layers? Sometimes higher layers are adapted to specific high level features - remember that on ImageNet your model learned to distinguish cars from cats for example, so maybe the last weights aren't so good at extracting features relevant to your task. All that being said, I don't think that there is a definite answer - note that pretrained models are trained on huge datasets, so maybe you just don't have enough data for your task to train a deep network (even with transfer learning). BTW do you actually need neural net for this? Your task doesn't seem to be particularly complex, maybe it can be tackled using classical computer vision tools (which most likely won't require any training, like in this example ).
