[site]: crossvalidated
[post_id]: 152566
[parent_id]: 152558
[tags]: 
There are two "kinds" of regression coefficients: "True" regression coefficients (usually denoted $\beta$) that describe the underlying data-generating process of the data. These are fixed numbers, or "parameters." An example would be the speed of light $c$, which (we assume) is always the same everywhere in the accessible universe. Estimated regression coefficients (usually denoted denoted $b$ or $\hat \beta$) that are calculated from samples of the data. Samples are collections of random variables, so estimated regression coefficients are also random variables. An example would be an estimate for $c$ obtained in an experiment. Now think about what covariance means. Take any two random variables $X$ and $Y$. If $\left| \mathrm{Cov}\left(X,Y\right) \right|$ is high, then whenever you draw a large absolute value of $X$ you can also expect to draw a large absolute value of $Y$ in the same direction. Note that "high" here is relative to the amount of variation in $X$ and $Y$, as pointed out in the comments. The (estimated) covariance of two regression coefficients is the covariance of the estimates , $b$. If the covariance between estimated coefficients $b_1$ and $b_2$ is high, then in any sample where $b_1$ is high, you can also expect $b_2$ to be high. In a more Bayesian sense, $b_1$ contains information about $b_2$. Note again that "high" is relative. Here "$b_1$ is high" means that "$b_1$ is high relative to its standard error," and their covariance being "high" mean "high relative to the product of their standard errors." One way to smooth out these interpretive hiccups is to standardize each regression input to by dividing by its standard deviation (or two standard deviations in some cases). One user on this site described $\mathrm{Cov}\left(b_1,b_2\right)$ as "a bit of a fudge," but I don't entirely agree. For one thing, you could use this interpretation to come up with informative priors in Bayesian regression. As for what this is actually used for, Cliff AB's answer is a good summary.
