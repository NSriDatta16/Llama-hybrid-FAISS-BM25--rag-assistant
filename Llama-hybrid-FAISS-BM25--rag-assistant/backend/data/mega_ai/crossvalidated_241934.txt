[site]: crossvalidated
[post_id]: 241934
[parent_id]: 
[tags]: 
Major and minor principal axes using kernel PCA on a 2D dataset

I have these two data sets: x1 = [0.97955,0.7177,0.2374,-0.4374,-1.1126,-0.9457,-0.5329,0.2991,0.9846,1.2218]; y1 = [-0.1727,0.6582,0.7419,0.6433,0.3406,-0.0354,-1.0199,-0.9105,-0.6879,0.2234]; and x2 = [1.7821,1.5386,0.4578,-0.7798,-1.5705,-1.8621,-1.2983,0.1988,1.3197,2.4700]; y2 = [-0.1231,1.4351,1.9311,1.9097,0.5310,-0.9644,-2.0165,-1.8719,-1.3210,-0.03921] I used the Gaussian Kernel PCA algorithm with sigma = sqrt(10) . After finding my $K$ matrix, I then sorted the eigenvectors of $K$ and took the first two largest eigenvectors. column1 [0.1528 0.1553 0.0666 -0.0741 -0.2206 -0.2197 -0.2078 -0.0366 0.1155 0.2222 0.2882 0.3119 0.1572 -0.050 -0.275 -0.4011 -0.3586 -0.1172 0.12466 0.36817] and column2 [0.0930 -0.1122 -0.1716 -0.2018 -0.1777 -0.0861 0.15884 0.20136 0.20255 0.02489 0.13522 -0.1859 -0.3636 -0.4339 -0.2350 0.04714 0.26192 0.35898 0.33280 0.15149] My k-PCA projection points were then calculated. I got this plot: How do you go about finding the major and minor axes for the k-PCA projected points?
