[site]: crossvalidated
[post_id]: 488008
[parent_id]: 487972
[tags]: 
What you call "metrics" are performance characteristics of the test. Regardless of what the true value of $\mu$ is (which we never know), a test that rejects a $H_0$ that is true too often is not good and a rejection is then meaningless. This is what you get from type I error calculations. You also may carry out power calculations. For this you may choose several values of $\mu$ or one borderline value that you "for sure" would like to lead to a significant result. You may also want to know whether the test will likely reject given that the true $\mu$ is not 100 but so close to 100 that you'd consider the $H_0$ still as "practically true" (if not theoretically). (Added after seeing a comment on the other answer:) This can mean that the power of the test is "too high", rejecting the null even in cases in which pragmatically in the real situation there's nothing wrong with it. This as well does not rely on the true $\mu$ , because you don't know that, however you can compute whether the test has the performance characteristics given any value of $\mu$ you'd like to try that you expect from it. Note also that a test does not investigate whether the $H_0$ is true, but rather whether the data are compatible with the $H_0$ , i.e., whether they look like typical data generated from the $H_0$ . This can well be the case even if the $H_0$ is in fact not true, which means that whatever the true $\mu$ is, the data cannot be used to argue that there's evidence against $H_0$ . This (and no more) is what you get from a test. A last remark: You say the likely situation in the real world is that $\mu$ is not precisely 100. I say it's worse than that. In the real world there is no such thing as a normal distribution, and not even i.i.d. data according to any well defined parametric distribution. There's no such thing as a true distribution, and there's no such thing as a true $\mu$ (which is defined within an assumed model), be it 100, 102 or whatever. Models are thought constructs that help us reasoning about a world that is essentially different. The best thing we can ever do is say, these data look like data generated from an artificial model with a certain parameter value (or a confidence set of parameter values) that has certain characteristics that we may want to interpret.
