[site]: crossvalidated
[post_id]: 464911
[parent_id]: 
[tags]: 
Formulating posterior predictive distribution from hierarchical model

I have been reading a couple related papers using Bayesian inference in hierarchical models 1, 2, 3 but am struggling to bridge the gap in one aspect of the papers. I think the struggle is in relation to the posterior predictive distribution. The model is described as $$log(y_{i,t}) \sim \mathcal{N}(\beta_{0,i} + \beta_{1,i}a_{i,t} + \eta_t, \sigma_y^2)$$ $$\eta_t \sim \mathcal{N}(\beta_2 x_t, \sigma_{\eta}^2)$$ $$x_t \sim \mathcal{N}(\mu_x, \sigma_x^2)$$ In this case, $y_{i,t}$ , $a_{i,t}$ , $x_t$ are measured but the goal will be to predict new values of $x_t$ (climate) for which we have measures of $y_{i,t}$ and $a_{i,t}$ . They state that the posterior predictive distribution can be sampled from $$x_t^{(j)} \sim \mathcal{N}\left(\frac{\sigma_{\eta}^{2(j)}\mu_x^{(j)} + \sigma_x^{2(j)}\beta_2^{(j)}\eta_t^{(j)}}{\sigma_{\eta}^{2(j)} + \sigma_x^{2(j)}\beta_2^{2(j)}}, \left[\frac{1}{\sigma_x^{2(j)}} + \frac{\beta_2^{2(j)}}{\sigma_{\eta}^{2(j)}} \right] \right) $$ where $(j)$ represents the $j^{th}$ MCMC sample. I know that the posterior predictive distribution is defined as $$p(\tilde{x} \mid x) = \int_\theta p(\tilde{x} \mid \theta)p(\theta \mid x)d\theta$$ However, I am unable to get from the model description to the posterior using this equation. Could anyone walk me through the probability/integration steps necessary to come up with this specific posterior predictive distribution? 1. Schofield et al. 2016 ↩ 2. Steinschneider et al. 2017 ↩ 3. Schofield and Barker 2017 ↩
