[site]: crossvalidated
[post_id]: 49605
[parent_id]: 48889
[tags]: 
I would strongly advise against using Markov Models, Hidden Markov Models, or Dynamic Bayesian networks for sequence classification. A number of discriminative methods are known to be much more effective for this task. The most commonly used discriminative methods for sequence classification are based on sequence/string kernels. The Sparse Spacial Sample Kernel and the Local Alignment Kernel are particularly effective for protein sequence classification, and it might be possible to adapt them for your task. If you are working with continuous data, you can create alignment kernels by adapting the dynamic time warping algorithm to the Local Alignment Kernel setting. One problem with kernel methods is that they can be computationally intensive. If you precompute the kernel matrix, you would need $O(N^2)$ kernel computations (where $N$ is the size of the dataset), and alignment-based kernels are generally $O(T^2)$ complexity (where $T$ is the length of the sequence). (Computing the Local Alignment kernel for a standard 4000-sequence protein dataset probably requires over six months of single-processor computation time.) Techniques like the one mentioned the following paper can reduce the number of kernel computations: http://leon.bottou.org/papers/ertekin-bottou-giles-2011 . Other discriminative techniques involve specially constructed neural networks, as described in this paper: http://www.cs.bris.ac.uk/~flach/ECMLPKDD2012papers/1125783.pdf Learning linear classifiers in large subsequence feature spaces using coordinate descent techniques has also been shown to be effective for both text data and protein sequences ( http://arxiv.org/abs/1008.0528 ), but this technique might require discrete features.
