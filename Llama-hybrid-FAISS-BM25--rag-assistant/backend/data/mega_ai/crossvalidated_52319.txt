[site]: crossvalidated
[post_id]: 52319
[parent_id]: 
[tags]: 
Coin flipping, decision processes and value of information

Imagine the following setup: You have 2 coins, coin A which is guaranteed to be fair, and coin B which may or may not be fair. You are asked to do 100 coin flips, and your objective is to maximize the number of heads . Your prior information about coin B is that it was flipped 3 times and yielded 1 head. If your decision rule was simply based on comparing the expected probability of heads of the 2 coins, you would flip coin A 100 times and be done with it. This is true even when using reasonable Bayesian estimations (posterior means) of the probabilities, since you have no reason to believe that coin B yields more heads. However, what if coin B is actually biased in favor of heads? Surely the "potential heads" you give up by flipping coin B a couple of times (and therefore gaining information about its statistical properties) would be valuable in some sense and therefore would factor into your decision. How can this "value of information" be described mathematically? Question: How do you construct an optimal decision rule mathematically in this scenario?
