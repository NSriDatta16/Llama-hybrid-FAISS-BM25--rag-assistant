el melodies and musical complexities are regarded even today as difficult deep-learning tasks, and near-perfect transcription is still a subject of research. In 1997, an artificial intelligence program named Experiments in Musical Intelligence (EMI) appeared to outperform a human composer at the task of composing a piece of music to imitate the style of Bach. EMI would later become the basis for a more sophisticated algorithm called Emily Howell, named for its creator. In 2002, the music research team at the Sony Computer Science Laboratory in Paris, led by French composer and scientist François Pachet, designed the Continuator, an algorithm uniquely capable of resuming a composition after a live musician stopped. Emily Howell would continue to make advancements in musical artificial intelligence, publishing her first album From Darkness, Light in 2009. Since then, many more pieces by artificial intelligence and various groups have been published. In 2010, Iamus became the first AI to produce a fragment of original contemporary classical music, in its own style: "Iamus' Opus 1". Located at the Universidad de Malága (Malága University) in Spain, the computer can generate a fully original piece in a variety of musical styles. In August 2019, a large dataset consisting of 12,197 MIDI songs, each with their lyrics and melodies, was created to investigate the feasibility of neural melody generation from lyrics using a deep conditional LSTM-GAN method. With progress in generative AI, models capable of creating complete musical compositions (including lyrics) from a simple text description have begun to emerge. Two notable web applications in this field are Suno AI, launched in December 2023, and Udio, which followed in April 2024. Software applications ChucK Developed at Princeton University by Ge Wang and Perry Cook, ChucK is a text-based, cross-platform language. By extracting and classifying the theoretical techniques it finds in musical pieces, the software is able to synthesize entirely new pieces from the techniques it has learned. The technology is used by SLOrk (Stanford Laptop Orchestra) and PLOrk (Princeton Laptop Orchestra). Jukedeck Jukedeck was a website that let people use artificial intelligence to generate original, royalty-free music for use in videos. The team started building the music generation technology in 2010, formed a company around it in 2012, and launched the website publicly in 2015. The technology used was originally a rule-based algorithmic composition system, which was later replaced with artificial neural networks. The website was used to create over 1 million pieces of music, and brands that used it included Coca-Cola, Google, UKTV, and the Natural History Museum, London. In 2019, the company was acquired by ByteDance. MorpheuS MorpheuS is a research project by Dorien Herremans and Elaine Chew at Queen Mary University of London, funded by a Marie Skłodowská-Curie EU project. The system uses an optimization approach based on a variable neighborhood search algorithm to morph existing template pieces into novel pieces with a set level of tonal tension that changes dynamically throughout the piece. This optimization approach allows for the integration of a pattern detection technique in order to enforce long term structure and recurring themes in the generated music. Pieces composed by MorpheuS have been performed at concerts in both Stanford and London. AIVA Created in February 2016, in Luxembourg, AIVA is a program that produces soundtracks for any type of media. The algorithms behind AIVA are based on deep learning architectures AIVA has also been used to compose a Rock track called On the Edge, as well as a pop tune Love Sick in collaboration with singer Taryn Southern, for the creation of her 2018 album "I am AI". Google Magenta Google's Magenta team has published several AI music applications and technical papers since their launch in 2016. In 2017 they released the NSynth algorithm and dataset, a