[site]: crossvalidated
[post_id]: 246041
[parent_id]: 245811
[tags]: 
I believe I have found the problem. Because the predictor is a summary based on a psychological model, it does not fully capture the behavior in the participants. Because the data is skewed and only randomized during presentation, some additional behavior causes an actual tendency of the participants to choose one option more frequently, and this tendency is not captured by the model. Since there is nothing in the logistic regression which could capture this additional behavior besides the intercept and because this behavior is quite stable, the logistic regression "incorrectly" uses the intercept to fit this additional behavior (which it can only do, because of the bias in the data). I can by now reproduce some similar tendencies in the data. The current model and simulation only uses a so called "bayesian decision strategy". If I add additional participants, who are using take-the-best (TTB) instead, then I get a similar skew and a reproducible significant intercept (which really does not mean much, since the "correct" model is missing). I am not yet sure if this is really caused by TTB participants. Non-linear processing of the provided information may also add additional biases, which could not be captured by the bayesian strategy I am testing in the regression. So there is an additional pattern in the data, and because of problems with the experimental design, this pattern is biased. The lesson I would take from this, is that it is not enough to just randomize displays, but the actual data used for presentation should also be symmetric, to keep additional patterns from appearing as intercepts. I am still not sure, though, what would be the best method to actually analyze the data. One approach I am currently using, is to "flip" half of the data randomly. I.e. I just switch Option1 and Option2 in all regards. This will keep the actual pattern, but now this pattern is not biased anymore, so it cannot produce a faulty intercept. However, since there still are additional patterns in the data not captured by the model I am using, this can still cause my parameter estimates to be off, if the factors I am actually testing correlate with the additional pattern by accident.
