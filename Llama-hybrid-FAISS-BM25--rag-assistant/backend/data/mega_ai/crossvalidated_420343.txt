[site]: crossvalidated
[post_id]: 420343
[parent_id]: 
[tags]: 
Relation between size of parameters and complexity of model with overfitting

I'm reading the book Pattern Recognition and Machine Learning by Bishop, specifically the intro where he covers polynomial regression model. In short, let's say we generate $10$ data points using the function $\sin(2\pi x)$ and add some gaussian random noise to each observation. Now we pretend not knowing the generating function and try to fit a polynomial model to these points. As we increase the degree of the polynomial, it goes from underfitting ( $d=1,2$ ) to overfitting ( $d=10$ ). One thing the author notes is that the higher the degree of the polynomial, the higher the values of the coefficients (parameters). This is my first doubt: why does the size of the coefficients increase with the polynomial degree? And why is the size of the parameters related to overfitting? Secondly, he states that even for degree $10$ , if we get sufficiently many data points (say $100$ ), then the high degree polynomial will no longer overfit the data and should have comparatively better generalization performance. Second doubt: Why is this so?
