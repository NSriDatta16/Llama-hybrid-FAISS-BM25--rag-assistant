[site]: crossvalidated
[post_id]: 71929
[parent_id]: 
[tags]: 
Good non-informative priors for estimating the parameters of a Gaussian with MCMC (using PyMC)?

Say I want to estimate the mean $\mu \in [0, 10] $ of some Gaussian data $\mathbf{x}$ with known variance $\sigma^2 = 1$ using MCMC. Usually I'd use a prior like $\mu \sim \mathrm{Uniform}(0, 10)$ and end up with samples $\hat{\mu}$ that are distributed like this (where $\mu = 5$). This is pretty much what I'd expect, and works fine. Since the samples $\hat{\mu}$ are also Gaussian though, it seems like I should be able to precisely estimate their mean and variance by sampling them directly using priors like these: $\mu \sim \mathrm{Norm}(\mu_0, \sigma^2_0)$ $\sigma^2_0 \sim \mathrm{Uniform}(0, 2)$ $\mu^2_0 \sim \mathrm{Uniform}(0, 10)$ I hoped to get samples of $\mu_0$ and $\sigma^2_0$ that were very concentrated around the mean ($\approx 5$) and variance ($\approx 0.02$) of $\hat{\mu}$, but instead neither was more precise . $\mu_0$ is spread out a lot and $\sigma^2_0$ is pretty much uniform. Is there a better set of priors/hyperpriors that would be more suitable to sampling in cases like this? I suspect that using uniform, independent hyperpriors might be the issue, but I'm not sure. Here's my PyMC code BTW (possibly there's a bug): from __future__ import division import pymc as mc from pylab import * # create test data N = 50 mu = 5 data = randn(N) + mu # start PyMC variables mu_0 = mc.Uniform('$\mu_0$', 0, 10) sigma_0 = mc.Uniform('$\sigma_0^2$', 0, 2) mu = mc.Normal('$\mu$', mu_0, 1/sigma_0) data = mc.Normal('data', mu, 1, observed=True, value=data) # sample mcmc = mc.MCMC([data, mu, mu_0, sigma_0]) mcmc.sample(iter=50000, burn=5000) # plot figure() for i, v in enumerate(('$\mu$', '$\mu_0$', '$\sigma_0^2$')): x = mcmc.trace(v)[:].reshape(-1) subplot(1, 3, i+1) hist(x, 50) title(v) show()
