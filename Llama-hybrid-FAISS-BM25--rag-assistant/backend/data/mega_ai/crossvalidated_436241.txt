[site]: crossvalidated
[post_id]: 436241
[parent_id]: 436230
[tags]: 
Given the update (that the variable is analogous to rolls of a potentially biased k-sided die), I think that the model you probably want to work from is a Dirichlet Distribution. From this, you would model the probability (and variance) of selecting each value (e.g., die face), calculate the expected value (and variance) for each value, and then sum the results. This is most commonly done in a Bayesian framework, but you should be able to estimate the distribution even without a prior (though, particularly in low-sample-size situations, this could be problematic for cases where none of a particular variable were drawn). If we start with a four-sided die number 1, 2, 4, 8, we should be able to extend to any value of k arbitarily distributed values. Unless you have other good information (e.g., from prior rolls or a moderate belief that the die is fair), I would start with an uninformative prior with 1 for each member of alpha (the Dirichlet parameter vector). If we then have results of: |Value | Count| |------|------| | 1 | 15 | | 2 | 10 | | 4 | 6 | | 8 | 20 | |------|------| We get a posterior distribution with alpha of 16, 11, 7, and 21. From this, we can calculate the mean (expected value) easily enough by noting that this means the mean probability for each value is [0.291, 0.2, 0.127, 0.382] (note that the prior shifts these a little bit). We then multiply each by the values of the available variables to get an expected value of 4.220 (it would be 4.255 without the prior). There is a mathematical approach to calculating the variance around this based on the variance and covariance matrices for the distribution (see Wikipedia ), but (like any good Bayesian) I am lazy and would rather just sample from the posterior as long as we have a good one. In R, this is relatively straightforward (I am using rdirichlet from the MCMCpack package, but there are many others out there). For each iteration, I sample a possible true distribution from the dirichlet and then draw a single value from that distribution. First, I store the variables for each item (the counts of each roll, the chosen weights for the prior, and the numeric value of each of the faces/values): roll_counts Then, I sample (100,000 times, in this case), and store the drawn value for each iteration: dir_results_one We can confirm that this matches our mathematically calculated expected value by taking the mean of dir_results (I got 4.222, which is very close). Then, we take the standard deviation of dir_results to estimate the standard deviation of the variable. I got 3.055, though the value will drift a little. We can also assess our confidence in the estimate of the mean by sampling from the posterior and calculating the expected value at each point (just like we did with the mean): dir_results Then, we find the middle 95% (e.g, with quantile(dir_results, c(0.025, 0.975)) ). In my iteration, the 95% confidence interval was from 3.462 to 5.001. The other advantage of this kind of resampling is that we can simulate the results of any number of samples. For example, here is the calculation of the expected value when we draw 5 samples from the distribution: dir_results_five This gives a mean of 21.084 with a standard deviation of 7.065. The details of your finite set matter immensely. In most circumstances, continuous variables are actually pulled from such a finite set due to measurement limitations (e.g., you can only measure to the nearest inch, gram, mL, etc.). However, if the finite set is large and evenly spaced over a truly continuous underlying variable (e.g., you can just as easily read 1, 2, 3, and 4 rather than only being able to read 1, 2, and 4), you can often treat the discrete variable as if it were continuous. This is all very different if the finite set does not map directly to a continuous variable (e.g., if it is a Likert Scale). In those cases, your exact path forward again depends on the nature of your variable and what you would like to be able to conclude from it. It sounds like the finite set A does map to the continuous underlying distribution directly, so it is unclear what additional information about A would impact the calculation of the mean or the confidence interval. In particular, it is unclear if A places limitations on the true value of X or merely on the measured/recorded value.
