[site]: crossvalidated
[post_id]: 245721
[parent_id]: 
[tags]: 
Why does my AUC keep decreasing on each fold?

For some reason, the sklearn random forest keeps returning a smaller and smaller value for AUC when I use it for binary classification. I'm using some data that I generated myself, and the labels are 'yes' or no' and they have been converted into 1 and 0 . import pandas as pd import sklearn from sklearn.ensemble import RandomForestClassifier from sklearn import cross_validation as skcv from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc from sklearn.grid_search import GridSearchCV from sklearn.metrics import f1_score, make_scorer from sklearn import cross_validation from sklearn import base new_df = pd.DataFrame() new_df['A']=[0.99, 0.88, 0.39, 0.98, 0.23, 0.54, 0.19, 0.97, 0.123, 0.34, 0.234, 0.46, 0.56, 0.27, 0.576, 0.16, 0.689] new_df['B']=[0.01, 0.14, 0.78, 0.18, 0.29, 0.64, 0.24, 0.95, 0.23, 0.35, 0.45, 0.49, 0.59, 0.39, 0.578, 0.19, 0.78] new_df['C']=[0.51, 0.64, 0.18, 0.68, 0.19, 0.98, 0.39, 0.89, 0.35, 0.45, 0.51, 0.52, 0.60, 0.34, 0.98, 0.35, 0.90] new_df['y']=['yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes','no','no','no','yes','yes','no','no','yes'] numerical_cols = [] for col in filter(lambda col: col!='y', new_df.columns): if not (new_df[col].dtype != 'int64' and new_df[col].dtype != 'float64'): numerical_cols = numerical_cols + [col] feature_df = new_df.replace({'y':{'no':0, 'yes':1}}) num_feature_df = feature_df[numerical_cols+['y']] num_feature_cols = filter(lambda col: col != 'y' , num_feature_df.columns) for train_index, test_index in skcv.KFold(len(num_feature_df), n_folds = 3): rf = sklearn.ensemble.RandomForestClassifier( random_state = 10, oob_score = True, n_estimators = 200, min_samples_leaf = 3, max_depth = 3) rf.fit(num_feature_df.iloc[train_index][num_feature_cols], num_feature_df.iloc[train_index]['y']) _scores = rf.predict_proba(num_feature_df.iloc[test_index][num_feature_cols])[:,1] auc = roc_auc_score(num_feature_df.iloc[test_index]['y'], _scores, average='macro', sample_weight=None) print auc The AUC consistently decreases after each fold in the k-folds. It doesn't matter how many folds, and it doesn't matter the hyper-parameters for the random forest, and even if the data is a little bit different it doesn't matter - the AUC consistently decreases at each iteration. Why is the AUC consistently decreasing after each fold in k-folds cross validation?
