[site]: crossvalidated
[post_id]: 413760
[parent_id]: 413606
[tags]: 
What is the correlations among the independent variables? This is less important for pure prediction, but if you want to gain some inferential information it is important that the independent variables be fairly uncorrelated. Typically, when you use logistic regression in a business setting, both inferential information about the variables used along with a good prediction are what stakeholders are looking for. Additionally, another good reason to remove variables is for model parsimony. Some reasons for this is for internal review purposes, legal regulation, and ease of implementation. These lead to it being highly desirable to find the smallest set of variables that give good business information and good predictions. For example, if you are developing a credit model, every variable is subject to legal review, every variable has to be available and immediately return values when called to score the loan, and the stakeholders (who usually are not versed in model building) tend to not want to look at complicated models loaded with variables. It may be also helpful to try a random forest to get some idea of variable importance and also to check the predictive power with and without all the variables. Finally, you should have a good reason for transforming a variable. Throwing every transformation against a variable until you find one that gives you the result you want is a good way to get an overfit model that performs poorly on new data.
