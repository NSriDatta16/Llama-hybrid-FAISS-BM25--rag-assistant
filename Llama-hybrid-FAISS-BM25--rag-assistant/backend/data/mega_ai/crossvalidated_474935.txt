[site]: crossvalidated
[post_id]: 474935
[parent_id]: 474039
[tags]: 
This apparent bias was a confusing way to put a symptom of a not perfectly fitted model. Every linear model, in which the coefficients are estimated by minimizing the sum of squared errors (the ERMS), shows the same. If one tries to make a linear regression model using explanatory variables that are uncorrelated with the dependent variable, the variance of the predicted time series will be relatively small, and the regression coefficients will converge to zero, because the sum of squared variances is minimized (left). It is a direct consequence that the model will overestimate low values and underestimate high values. Ordering the dependent variable in ascending order is just another - and confusing - way to visualize the same thing (middle). Fitting yet another line to the red dots here and rotate them would destroy the regression model. One would have to scale each red dot by a different value, thus missing the point of having a couple of regression coefficients capable of scaling the explanatory variables as a whole. If the explanatory variables are a bit more correlated, the same is observed. Model has lower variance than dependent variable, therefore model doesn't reach peaks, and overall over- and underestimates high and low values. This is when someone feels the urge to just rotate the red dots anti-clockwise, but it does not make any sense, if the goal is to have one regression model, and not as many scaling factors as data points.
