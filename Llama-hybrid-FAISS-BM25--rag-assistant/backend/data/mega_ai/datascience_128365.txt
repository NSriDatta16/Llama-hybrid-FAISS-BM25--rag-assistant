[site]: datascience
[post_id]: 128365
[parent_id]: 
[tags]: 
Is it necessary to average the shap values ​that have been processed through cross validation?

Is it necessary to average the shap values ​​that have been processed through cross validation? I saw a post in Towards Data Science that calculated the shap value through 10 CV and then averaged it. The author stated that the reason for averaging was reliability. My question is, do I really need to average? For example, let's say you have 1000 pieces of data and divide it 8:2 to use only 200 pieces for the test set. Then, 200 shap values ​​are also created. If you do 10 cv, 100 shap values ​​are used in the test set 10 times, resulting in a total of 1000 shap values. if you do cross validation, you can get 5 times more shap values than when you do single learning. This means that there are 5 times more cases, so doesn't this in itself provide enough credibility for the results?
