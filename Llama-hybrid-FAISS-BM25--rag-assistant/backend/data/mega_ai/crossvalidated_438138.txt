[site]: crossvalidated
[post_id]: 438138
[parent_id]: 
[tags]: 
Why does VGG16 model use 13 hidden layers and 3 full connected layers, rather than 12 hidden layers or 11 hidden layers?

Why does VGG16 use 13 hidden layers, rather 12 hidden layers, or maybe 10 hidden layers? What is the motivation of the architecture? I think that maybe if we use only 12 hidden layers, similar performance could be achieved. I want to know the motivation of the deep neural networks' architecture, but almost all the deep neural networks are too complex to understand the motivation behind them.
