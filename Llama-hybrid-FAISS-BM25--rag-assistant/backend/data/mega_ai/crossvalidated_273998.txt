[site]: crossvalidated
[post_id]: 273998
[parent_id]: 
[tags]: 
Training convolutional neural network?

I am currently training a convolutional neural network, and for some reason keep overfitting my network... Overfitting is one thing but the way it overfits is bit of puzzle to me.. The accuracy is constant in a long time, and then suddenly begins the overfitting? how come like this? I tried chopping the network down, which in the end would lead to same result.. I tried with dropout layers as well and that does not seem to help either. What I am trying to do is to phoneme classification, given a visual representation of mel-seperated filterbanks. The input is a image portion of size (15 frames,40 filterbanks) divided in to small sections for example it could be sections of size (15,8) Each frame has it own phoneme, so the classification is done on 15 phonemes at the time. Each section has it own convolutional+pooling layer - As speech is interpreted differently in different frequecy ranges, thus different weight/kernels has to be learned to extract the nessesary featueres. The current network structure is: Conv[for all section seperately] -> pool[for convolution seperataly] -> merge[all pool] -> reshape[15,-1] -> Dense[300 neuron - relu] -> Dense[200 - relu] -> Dense[145 - Softmax] Any suggesting on why my data is performing poorly on the data - an tries to overfit all the time?
