[site]: datascience
[post_id]: 126926
[parent_id]: 
[tags]: 
sklearn Random Forest classifier vs R’s Random Forest classifier

I’m trying to implement the R’s random forest classifier equivalent in python- ## train random forest set.seed(5136) ty.rf = randomForest(y=ty.y, x= ty.x, ntree=1000, importance=T, strata=ty.y, sampsize=c(100,100), do.trace=10, proximity=T) The above classifier was implemented for an imbalanced data. I had tried to implement the above as following in python. Here’s my implementation in python - ###random forest rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model’,RandomForestClassifier(n_estimators=1000,class_weight='balanced', random_state=5136, oob_score=True, bootstrap = True))]) rf_pipeline.fit(ty_x, ty_y) Is this the equivalent syntax here? Also, after implementation in R code OOB estimate of error rate: 19.41% and in python OOB estimate of error rate: 7.14%, is this expected? I was expecting the oob_error to be similar. Can someone please clarify?
