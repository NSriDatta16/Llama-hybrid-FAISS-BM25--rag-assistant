[site]: crossvalidated
[post_id]: 211502
[parent_id]: 211451
[tags]: 
Figuring out how likely a given value is to be produced by a given distribution (e.g., given that a mystery value was drawn from a standard normal distribution, how likely is to be positive?) is easy enough. But the opposite problem, figuring out how likely a given distribution is to be responsible for a given value (e.g., given that I got the value 3, how likely is the mystery distribution it came from to be a standard normal distribution?) is quite a bit more complex. You'd need to begin by specifying a universe of models (or just distributions) to consider, which could be a small finite set or an infinite set. Perhaps there's a more direct way to do what you want to do here. What problem are you trying to solve? Edit: After further clarification in the comments, here's a more specific suggestion. Use a Bayesian method in which you set hyperparameters to encode your starting beliefs about the voting distribution, measure each vote's distance from the distribution so far with the likelihood, and use each vote you get to update the distribution. Specifically, for the continuous case, suppose votes come from a normal distribution with mean μ and standard deviation σ, μ is drawn from a fairly wide and flat normal distribution, and σ is drawn from a wide uniform distribution from .0001 to 100 or so. (You can also try the conjugate prior for the normal distribution .) For the discrete case, suppose votes come from a categorical (multinomial) distribution whose parameters come from a Dirichlet distribution. The benefit of using these Bayesian methods over the methods you described is that they do something reasonable even when you don't have any data yet or only a little data (instead of, say, assuming that categories yet unseen have probability 0) and they provide a natural transition (as the sample size increases) into using the data alone to estimate the distributions.
