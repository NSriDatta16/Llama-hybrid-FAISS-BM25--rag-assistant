[site]: crossvalidated
[post_id]: 145080
[parent_id]: 
[tags]: 
Comparing two values in a normal distribution after cutting off the tail of the distribution

I'm doing a sports-related analysis about comparing regular-season performance versus playoff performance, in particular which teams tend to do better during the playoffs. Thus, I'm making a "regular season rating" and "playoff rating" for each team in the league, which I'm scaling so that the average rating is a 50 and its standard deviation is 20. However, I'm having a problem exactly comparing team ratings in the playoffs. For example, let's say there is a team with a rating of 90 and a team with a rating of 40. During the regular season, their difference is 50. However, when the playoff field is chosen, the left tail of the rating distribution is cut off . Let's look at the teams' playoff ratings. Because the left 20% or so of the distribution is cut off, we have to rescale. However, unless I'm wrong, the 90 team will drop about 5 points, and the 40 team will drop about 20 points. This makes it seem like the difference is greater in the two systems, when it is actually the same. Is there any way to make my rating system so that the difference between the two stays the same in both models?
