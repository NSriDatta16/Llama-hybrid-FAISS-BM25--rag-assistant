[site]: crossvalidated
[post_id]: 451087
[parent_id]: 451056
[tags]: 
AIC can most definitely select an overfit model, because you e.g. only assess overfit models (so one of those gets selected), or you offer up an overfit model vs. an inappropriate model (seems to be your example)/a very overfit model/an underfit model, or you compare more than one model via AIC (the more models the worse this gets) and by testing several you end up overfitting via the model selection. While AIC attempts to balance fit to the training data vs. model complexity, there is nothing inherent to it that would provide a guarantee that model selection would result in an non-overfit model (of course, it penalizes model complexity more than if you selected solely on fit to the training data, so in that sense overfitting ought to be a bit more avoided). In fact (see point 3 above), the very fact of doing model selection involves the potential for overfitting to the data on which you select the model and model averaging (and various other approaches) have been proposed to avoid this issue (see e.g. Model Selection and Multimodel Inference by Burnham and Anderson ).
