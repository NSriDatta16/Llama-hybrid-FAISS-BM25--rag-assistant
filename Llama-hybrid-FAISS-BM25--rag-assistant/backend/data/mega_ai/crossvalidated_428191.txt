[site]: crossvalidated
[post_id]: 428191
[parent_id]: 
[tags]: 
Should I remove duplicates from my dataset for my machine learning problem?

I am new to machine learning and have a problem. I have a dataset with 1191 samples with 10 features which belong to 5 different classes. I have trained a neural network with this dataset and obtained a good accuracy of about 0.9. I noticed that about 350 samples are duplicated. All random selections of data for testing the network, contain about 180 samples which also have been in training data. My question is should I remove the duplicates from the dataset? Do they contribute to this accuracy?
