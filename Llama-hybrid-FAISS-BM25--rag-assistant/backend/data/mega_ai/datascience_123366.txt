[site]: datascience
[post_id]: 123366
[parent_id]: 
[tags]: 
Macro Averaging vs. Samples Averaging in multilabel classification problems

I am currently working on a multilabel classification problem and I have developed some models to solve it using the SciKit-Learn framework. I wish now to evaluated the models by producing scores for precision, recall, and F1 (once again, using SciKit-Learn framework), and I noticed that there are different averaging methods to produce such a final score. The two averaging strategies that interested me the most are "macro" and "samples". I know since earlier about "macro" and its justification, but I do not really know as much about "samples". I have seen that some people have recommended using "samples" for multilabel classification, but I am not sure if it is as meaningful as the "macro" averaging strategy. At least I know that when using "macro", the precision-, recall-, and F1 scores for each individual label are equally important for the corresponding overall scores and the model will be penalized when not performing well on the less frequent labels, whereas with "samples", the scores are calculated per sample rather than per label, and then averaged altogether. With respect to this background, my question is: what is the justification for using "samples" rather than "macro" in multilabel classification problems? What certain properties does the "samples" averaging strategy have that the "macro" averaging strategy does lack?
