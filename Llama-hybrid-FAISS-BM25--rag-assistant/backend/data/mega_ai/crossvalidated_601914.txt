[site]: crossvalidated
[post_id]: 601914
[parent_id]: 601900
[tags]: 
If we write out the problem, the neural network you're using is trying to estimate $A, B$ in $$ x = (Ax)B $$ where $x$ has shape $3 \times 1$ , $A$ has shape $1 \times 3$ and $B$ has shape $1 \times 3$ . (I've omitted the activation here.) It would be tempting to write $$ B^{-1}x=Ax $$ but this isn't possible because in the proposed network $A,B$ are vectors, not square matrices. (Indeed, if you use $3\times 3$ matrices instead, then the problem is easily solved, but one must wonder if this demonstration has accomplished anything at all.) The encoding step $Ax$ can be expressed as a linear operation, because these 3-bit vectors $x$ have identical floats $y$ , because $[4,2,1]^\top x=y$ . However, the decoding task is to go from float $y$ back to binary $x$ : $z ^\top y = z$ for a fixed $z$ of shape $1 \times 3$ . This isn't expressible as a vector-vector product. In general, we're seeking solutions of the form $$ x = [ay, by, cy] $$ but there is not a way to choose fixed $a,b,c$ from among real numbers so that $x$ is binary and $y$ is the integers 0 through 7. For $y=7$ , you want $a = 1/7$ , but that fails for $y=2$ because the result is $2/7$ .
