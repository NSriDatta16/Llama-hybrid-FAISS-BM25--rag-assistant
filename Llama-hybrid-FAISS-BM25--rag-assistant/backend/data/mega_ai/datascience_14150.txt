[site]: datascience
[post_id]: 14150
[parent_id]: 14092
[tags]: 
Since you're using Python and scikit-learn you could have a look at one of the following online learning algorithms: sklearn.naive_bayes.MultinomialNB sklearn.naive_bayes.BernoulliNB sklearn.linear_model.Perceptron sklearn.linear_model.PassiveAggressiveClassifier sklearn.linear_model.SGDClassifier sklearn.linear_model.PassiveAggressiveRegressor sklearn.linear_model.SGDRegressor All of these online learning algorithms (in particular with SGD) allow for streaming the data through memory one entry at a time. Your memory would be more than sufficient for this approach. In scikit-learn this is implemented via the partial_fit() method. More on this out-of-core approach can be found in the scikit-learn user guide. If you want stick to tree based algorithms, you can have a look at the xgboost package which also allows for streaming data through memory. However, this approach is a little more involved because it only accepts data in the LIBSVM format in order to parse it in the memory cache preserved for xgboost . Also, it doesn't allow for parameter tuning, since xgboost works on numpy objects and converting from LIBSVM to numpy dumps the data from the cache to the main memory and therefore doesn't scale. You could also use the Databricks Community Edition which let's you spin up Spark clusters (of limitied size for the free edition) where you can run pyspark or plain python scripts.
