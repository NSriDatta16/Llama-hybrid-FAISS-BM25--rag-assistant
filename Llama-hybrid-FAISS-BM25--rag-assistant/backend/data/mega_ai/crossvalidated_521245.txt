[site]: crossvalidated
[post_id]: 521245
[parent_id]: 
[tags]: 
In what way are SGD and the Perceptron learning algorithm very similar?

I'm reading Hands-On Machine Learning and the author states that: You may have noticed the fact that the Perceptron learning algorithm strongly resembles Stochastic Gradient Descent. In fact, Scikit-Learnâ€™s Perceptron class is equivalent to using an SGDClassifier with the following hyperparameters: loss="perceptron", learning_rate="constant", eta0=1 (the learning rate), and penalty=None (no regularization). Can someone please explain why?
