[site]: datascience
[post_id]: 17934
[parent_id]: 
[tags]: 
sentence classification with RNN-LSTM - output layer

i have read a few blogs and papers on the IMDB exercise w.r.t sentiment classification using LSTM's (and at times in conjunction with CNN) but there the output layer can contain just 1 neuron with a sigmoid since the sentiment can either be good or bad. But if i need to use the same technique to classify, say, 30,000 sentences into 20 different labels then what should my output layer look like ? if i am not mistaken i should have the same number of neurons in my output layer as the number of labels i am training the data for (20 in this case) each of which has the same sigmoid. Can you please let me know if this makes sense ?
