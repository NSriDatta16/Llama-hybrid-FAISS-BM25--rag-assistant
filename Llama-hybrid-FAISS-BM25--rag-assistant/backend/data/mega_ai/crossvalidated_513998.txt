[site]: crossvalidated
[post_id]: 513998
[parent_id]: 
[tags]: 
Why limit the volume of the autoencoder in self supervised learning?

In this article: self-supervised learning: The dark matter of intelligence the authors tried to unify the self-supervised learning for tasks with discrete outcomes and continuous outcomes. They predict that non-contrastive methods for the latent-variable energy-based model would be a promising direction for models with continuous outcomes like images, audio, videos, and other signals. But I get stuck by this statement about autoencoder(a non-contrastive method for the latent-variable energy-based model): The main obstacle is that they require a way to minimize the capacity of the latent variable. The volume of the set over which the latent variable can vary limits the volume of outputs that take low energy. By minimizing this volume, one automatically shapes the energy in the right way. What does it mean that the volume of the set over which the latent variable can vary limits the volume of outputs that take low energy? Can we just limit the volume by reducing the number of latent nodes(the bottleneck layer)?
