[site]: crossvalidated
[post_id]: 309070
[parent_id]: 
[tags]: 
"normalized accuracy" as an estimator for the classifier's performance -- what's the drawback?

I am facing a problem with the classification of an imbalanced sample, and I was looking into solutions for both dealing with the imbalance (e.g. oversampling/undersampling) and a metric which would be suitable for the estimation of the classifier performance on the imbalanced sample. I need to mention that my sample is not extremely imbalanced, at most 1:2 to 1:3 ratio. Regarding the metrics, I found many alternatives to accuracy, except for the one which seemed very logical to me -- what I call in my head "normalized accuracy". Simply said, it is the average of the ratios of the correctly identified samples within each class. On a confusion matrix for two classes, it would be (TP/(TP+FN) + TN/(TN+FP))/2. This seems very logical to me, symmetrical and extendible to multilabel classification. However, when I tried to find any mentions in the literature regarding this, I completely and repeatedly failed. Is it known under another name? Is it somehow so flawed that nobody ever discusses it anymore? Can someone enlighten me about this?
