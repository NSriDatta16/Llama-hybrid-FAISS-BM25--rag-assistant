[site]: crossvalidated
[post_id]: 475886
[parent_id]: 475883
[tags]: 
You are suggesting you are using R. So here is an example for PCA and Kmeans clustering on toy data. d = mtcars d2 = prcomp(d, scale=T) x =d2 $x[,1:2] y = kmeans(x,2) y$ cluster plot(x,col=y $cluster,cex=0.1) text(x,row.names(mtcars),col=y$ cluster) In this example, the original data has 11 features, and we reduce them into 2 and run kmeans clustering to cluster the data into 2 clusters. To summarize the code: We have 32 data points (32 cars), and 11 features (car's weight, cylinders etc.), and we convert it into another data matrix X that also has 32 rows, but 2 features. These 2 features are linear combinations of original feature, and do not have a clear physical meaning. When we run clustering, we are still clustering these 32 cars based on new transformed feature. The clustering results shows the cars are similar to each other in transformed feature space. So, if we lose a lot of information in PCA, we cannot say the cars in the same cluster are similar to each other (in original space). Here is an example to tell what is each cluster: we check the data in one cluster and find the commonalities in original space. For example, In this cars clustering, we can tell the red cluster has the cars that are more heavy, more cylinders and less mpg. (The clustering is basically a split on PC1, and we can check the loadings to see what is PC1 made of)
