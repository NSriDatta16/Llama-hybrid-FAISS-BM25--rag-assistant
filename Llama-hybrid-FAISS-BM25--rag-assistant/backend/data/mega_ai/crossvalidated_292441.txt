[site]: crossvalidated
[post_id]: 292441
[parent_id]: 
[tags]: 
Convolutional network doesn't give a lower log loss than the class means

I have tried multiple methods to try to improve the performance of my convolutional neural network on a multilabel classification problem, but the log loss of the prediction on the test set always seems to stabilize around 0.31. I have tried image augmentation, different neural net architectures, transfer learning, and hyperparameter tuning. If I compute the log loss based off of the mean for each label compared to the test set. As in I compute the means for each class and use the results as the prediction for each test observation, I get a log loss of 0.30. There are 800 training images and 17 possible labels. What does this mean and what should I do to improve my results? The only idea I have left is to try pretraining the conv net on a similar dataset to improve segmentation of the image since there is limited training data, but I have not found a similar dataset. Thanks.
