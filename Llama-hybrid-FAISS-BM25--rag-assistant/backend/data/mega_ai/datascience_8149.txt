[site]: datascience
[post_id]: 8149
[parent_id]: 8146
[tags]: 
For your particular problem I'm not sure that using a supervised Logistic Regression approach is ideal, but I suppose that is a different and larger topic. To answer your question, yes you can use a "bag of words" representation of your text. Python's sci-kit learn library offers this functionality via both CountVectorizer and TfidfVectorizer . This will result in a sparse matrix representation of n-grams and occurrences of those n-grams in your corpus. From here you basically have 2 options, (1) training your supervised model directly on the sparse matrix or (2) reducing the dimension of your sparse matrix so it be represented as a dense matrix. Luckily sklearn offers functionality for both these, their LogisticRegression class supports sparse matrices and their TruncatedSVD implementation of PCA/LSA supports sparse matrices as well. That should give what you need from a technical perspective to build a model, but I think the real question is what feature engineering you may be able to do in addition to simply training on the bag of words representation of the text.
