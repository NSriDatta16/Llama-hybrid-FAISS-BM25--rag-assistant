[site]: crossvalidated
[post_id]: 333968
[parent_id]: 
[tags]: 
Understanding the YOLO algorithm

I am trying to understand the logic behind object detection and the YOLO algorithm. I have read numerous blogs, tutorials, videos, papers, yet I am still not sure if I understood it correctly. Let's assume our network can predict three classes --- cat , dog , bird --- and we want to have $10 \times 10$ boxes. 1) We create CNN without FC layers, instead we use $1 \times 1$ Dimension Convolution layer. 2) We train it to input a $10 \times 10$ image, and output a vector with dimension of $1 \times 1 \times 5 \times 8$, where 5 is the number of anchor boxes and 8 is the number of features (the features are a confidence score, measuring how sure CNN is something is there, x, y, width, height, and indicator variables for the classes). In training, we say the object belongs to $10 \times 10$ that contains its center. Questions: Do we put anchor boxes there or do we just train CNN to output random boxes there? If we do the latter, while training it, how do we label them? For example, if there is one small bird, do we divide him into these boxes or what's the trick? How do we say the image belongs to some $10 \times 10$ boxes? Also wouldn't this mean that all $10 \times 10$ boxes that does not contain center would get confidence score of zero? 3) We input our image into our CNN networks (that takes a $10 \times 10$ image). Thanks to convolution the output will be $K \times K$, where $\forall i\in{K}$ is actually our vector of features. 4) We remove all boxes that have confidence scores $ 5) We use nonmax suppression to retrieve our boxes Question: Is this correct? Have I made any mistakes?
