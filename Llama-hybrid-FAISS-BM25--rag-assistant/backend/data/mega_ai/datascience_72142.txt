[site]: datascience
[post_id]: 72142
[parent_id]: 72138
[tags]: 
If RAM memory is a problem during training, and you have run for 1500 episodes, it would suggest to me that you are saving some information in each episodes (e.g. appending to a list ). That will slowly add up over time and cause a crash. After a quick look at your code, it looks like the scores and ep_history grow with every loop. You could consider writing that information to disk e.g. to a json , file or pickle object, with something like this import pickle if episode % 1000 == 0: with open(f"./results_dir/scores_{episode}.pkl", "wb") as file_handle: pickle.dump(scores, file_handle) You should of course retain the amount of history required for your print() statements and computing average scores over time. You rarely need to worry about freeing up some RAM yourself, as Python (and then afterwards, the operating system itself) will start to allow memory to be overwritten. The results is the same, they are essentially being deleted.
