[site]: crossvalidated
[post_id]: 397239
[parent_id]: 
[tags]: 
Sample complexity of deep reinforcement learning agents on smaller state spaces versus zero-padded state spaces

If I train two agents, one on environment A and one on environment A', where A' is just environment A padded with 10 rows of zeros, what can I predict will happen in terms of relative sample complexity of each agent? Let's say the algorithm is soft actor critic. In general, what principle would we use to think about this?
