[site]: crossvalidated
[post_id]: 311571
[parent_id]: 
[tags]: 
Modeling Attrition: Imbalanced Training

First of all, let me say I am new to Machine Learning and am eager for any sort of feedback. I am attempting to create a predictive attrition model, and my training and test data each have ~ 17% records for leaving. My goal would be to produce a "good" model for predicting attrition. Is this considered imbalanced? Do I need to use SMOTE or some sort of resampling here? If yes, I know that in order to use SMOTE, I must do it to the training set only, but I am unsure of how to re-sample while simultaneously cross-validating? Once the model is constructed, what are "acceptable" levels for accuracy/precision/recall? Should I care about other things as well? Here is the code I have used for SMOTE: # Create training and test data sets # Ensure results are repeatable set.seed(7) training % unlist() train_data % as.data.frame() train_data Next, I used a XGBoost model: train 0.5,1,0) # Look at Confusion Matrix confusionMatrix(xgbpred,ts_label,positive = '1') Results are in screenshot below. I know that my recall is low, I was hoping to improve the model. Any feedback is appreciated!
