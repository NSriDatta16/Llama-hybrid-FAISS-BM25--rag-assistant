[site]: crossvalidated
[post_id]: 612698
[parent_id]: 612542
[tags]: 
I think this can be chalked up to overfitting. While x2 doesn't actually contribute in the data-generating process, its noise compared to x1 is sometimes more useful to fit to the training data, so xgboost uses x2 to split reasonably often, and so it is correctly identified by gain and shap as important to the model's predictions.
