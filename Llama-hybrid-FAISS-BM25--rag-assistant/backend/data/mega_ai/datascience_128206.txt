[site]: datascience
[post_id]: 128206
[parent_id]: 
[tags]: 
How are the cross validation and training processes interlinked here?

Please consider the code given below. # Define categorical and numerical features categorical_features = X.select_dtypes( include=["object"] ).columns.tolist() print(categorical_features) numerical_features = X.select_dtypes( include=["float64", "int64"] ).columns.tolist() print(numerical_features) # Preprocessor preprocessor = ColumnTransformer( transformers=[ ("cat", OneHotEncoder(), categorical_features), ("num", StandardScaler(), numerical_features), ] ) # Gradient Boosting classifier pipeline pipeline = Pipeline( [ ("preprocessor", preprocessor), ("classifier", GradientBoostingClassifier(random_state=42)), ] ) # Cross validation and training cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5) pipeline.fit(X_train, y_train) After identifying the categorical and numerical features, a preprocessor is defined based on these two. This is followed by a pipeline comprising the aforementioned preprocessor and a classifier. Near the end, we perform cross-validation and training. Apparently, the results from cross-validation are not being used in the training process. cv_scores is not among the arguments used by pipeline.fit . Are the cross-validation and the training process interlinked in some manner where results or effects from the former are being passed to the latter?
