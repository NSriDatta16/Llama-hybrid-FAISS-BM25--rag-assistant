[site]: datascience
[post_id]: 11509
[parent_id]: 
[tags]: 
Is there any domain where Spiking Neural Networks outperform other algorithms (non-spiking)?

I'm reading about reservoir computing techniques like Echo State Networks and Liquid State Machines . Both of the methods involve feeding inputs to a population of randomly (or not) connected spiking neurons, and a relatively simple readout algorithm that produces the output (e.g. linear regression). The neuron population weights are either fixed, or trained via a Hebbian-like local activity rule like STDP . These techniques perform well when modelling multi-dimensional inputs that have significant temporal components. However, computing the spiking neuron membrane potentials involves differential equation integration and can be computationally expensive. Are there any examples of where the additional computational complexity of reservoir computing techniques is outweighed by gains in a prediction or classification task? For example, are there any cases of SNN techniques outperforming comparably complex architectures based on RNNs, ANNs, SVMs, DNNs, CNNs, or other algorithms?
