[site]: crossvalidated
[post_id]: 448847
[parent_id]: 
[tags]: 
Intuitive explanation of why a stochastic process constructed by a uniformly distributed stopping time is not Markov

Consider a Markov chain that waits a time $T^{∗}$ before leaving the current state, where $T^{∗}$ has uniform distribution over the set of times $\{1, 2, 3, 4\}$ If $(W_k)_{k\geq}$ would be a stochastic process constructed so that it stays in each state $i$ for a time distributed to $T^{*}$ , what would be an intuitive explanation of why this is not a Markov chain?
