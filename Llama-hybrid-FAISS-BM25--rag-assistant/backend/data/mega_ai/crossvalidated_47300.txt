[site]: crossvalidated
[post_id]: 47300
[parent_id]: 
[tags]: 
SVM decision function

our decision function e.g. in SVMs for binary classification (where the response is labeld by $y_i \in \{-1,1\}$) has the form: $f(\mathbf{x}) = \text{sgn}(\mathbf{w}^\top \mathbf{x} + b)$ where $\mathbf{w}^\top \mathbf{x} + b =0$ is the equation of the separating hyperplane. But what happens if a new example $\mathbf{x}_{new}$ lies on the hyperplane $\mathbf{w}^\top \mathbf{x}_{new} + b = 0$ then $f(\mathbf{x}_{new})=0$ because $\text{sgn}(0)=0$. In which class $y_i \in \{-1,1\}$ do we than classify our new example? Do we randomize between -1 and 1?
