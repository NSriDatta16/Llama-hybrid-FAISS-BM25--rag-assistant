[site]: datascience
[post_id]: 110231
[parent_id]: 110053
[tags]: 
Simple spike detection (what I would do) Get your time series data into a pandas dataframe in python iterate over each element, and see how much greater it is than the, lets say, 2 hour average. Let's call that spikeness if spikeness(i) > threshold, it's a peak you'll get something like this, 00000000011111111000000111111110000, finding when it flips between 0 and 1 is a good solution. You might need to "debounce" this signal. more advanced spike detection check out sklearn comparing trends Data science isn't a free lunch, and the most powerful neural network is your own head. I'm skeptical, for non value added work that is as volatile as bug tracking, you'll be able to get results that justify the cost. However: looking into clustering seems reasonable. This might help you see the data differently, and isn't too hard to set up (t-sne is a good one) you could train a time series LSTM or CNN to try to learn. I don't recommend this approach for your use case the rub You're stepping into an incredibly deep pond, but it seems like your pebble is right on the edge. You could dive in, but I would recommend really analyzing what you need and trying to implement the simplest solution to meet that goal. Setting thresholds compared to the baseline (2x the average over the last day, for instance) for each graph seems like a great place to start. Some related things in this deep pond, that I don't think you need to spend copious amounts of time on: clustering supervised learning time series analysis CNN LSTM signal processing frequency domain analysis sklearn pandas numpy I think data science suffers from glist and glam, with people wanting to over engineer solutions to problems that aren't even really problems. The first step of a ML/data science project is bringing those pie in the sky ideas back down to reality.
