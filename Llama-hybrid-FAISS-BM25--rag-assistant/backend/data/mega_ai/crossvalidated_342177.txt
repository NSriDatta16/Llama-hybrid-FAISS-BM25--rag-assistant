[site]: crossvalidated
[post_id]: 342177
[parent_id]: 342175
[tags]: 
Is it possible for a neural network to learn based on its own predictions? This is called a recurrent neural network (RNN). On my own intuition, I think that it might lead the model into a state where it doesn't work well with new input since what it knows too much only about itself. Not very clear what you are stating here, but it sounds like you might want to check out Hopfield Networks, a specific type of neural network which have a tendency to converge towards stable local minimum states, and considered to be closer to the way human memory works than standard feedforward neural networks. Also I thought of having the model learn from its own predictions that pass a certain uncertainty. Check Boltzmann Machines, a probabilistic version of Hopfield Networks. But I also have a hard time determining uncertainty for a neural network model and Im using keras. Again, not very clear what you are asking. But you can create RNN in Keras, and Boltzmann Machines with TensorFlow.
