[site]: crossvalidated
[post_id]: 383166
[parent_id]: 380371
[tags]: 
Two-way anova interpretation For the experiment you describe, you need a two-way anova (two-way since you have two factors in your experiment). The lm function ( lm(outcome ~ treatment*condition) ) that you describe fits this model, but there are different ways to get the results. The presentation of the results can be quite different, even though the underlying models is the same. First way: using anova() my_lm = lm(outcome ~ treatment*condition, data) anova(my_lm) The anova table will give you an estimate for each of your factors and the interaction. So this will tell you wether (1) the treatment has a significant effect on the outcome and (2) whether the condition has a significant effect on the outcome and (3) whether the treatment effect is different for certain conditions (this is the interaction effect). Second way: using summary() my_lm = lm(outcome ~ treatment*condition, data) summary(my_lm) To interpret this, we could look firstly at overall quality of the model (F-statistic and p-value, R squared and adjusted R squared. And secondly the coefficients table contains all estimated effects from the linear model. Those estimates are in the form of contrasts, meaning that there is not one estimate per 'variable', but that there is one estimate for each group (one less than number of categories, since the first category is taken as control group). On way to change the control group is using relevel() . With the same summary result, to find the estimated outcome for MM doing activity 2, you would need to sum the intercept + the estimate for MM + the estimate for activity 2. Using this table, the estimate and the p-value for MM will tell you whether the outome of MM is on average significantly higher than the control group. Pairwise comparisons and adding self-specified contrasts: You want not only to compare MM to the automatically selected control group but also to other effects. One way is to get pairwise comparisons, or post hoc tests, where you compare each treatment category to each other(pairwise meaning test every possible combination for significance). To do this easily you can use the Tukey post hoc tests in TukeyHSD() . Unfortunately, they do not work with an lm object, so you need to re-fit the exact same model but with the functiom aov . my_lm = aov(outcome ~ treatment*condition, data) TukeyHSD(my_lm) This will give you pairwise comparisons for each of your treatments, so basically the same as the summary output but then repeated for each group as a reference group. Also the significance values are adjusted for the fact that you do many repeated tests. If you want to compare even more, you can take a look into contrasts. They will allow you to compare two groups of treatment categories that you specify yourself. For example you could specify a contrast for MM and FF on one side vs MF and FM on the other side. To do this, you should look into custom contrasts. A very good explanation an be found in the answer of this question: How to set custom contrasts with lmer in R Some other reference material on contrasts here: https://rcompanion.org/rcompanion/h_01.html And here a general reference on multi-factor anova: https://onlinecourses.science.psu.edu/stat502/node/152/ Edit: 1 - All the comparisons that I mention (even pairwise) can be specified using contrasts. I've taken a look at the felm documentation and there's also a constrast parameter that you can specify. I give you the following link that is very complete on setting up contrasts : https://rstudio-pubs-static.s3.amazonaws.com/65059_586f394d8eb84f84b1baaf56ffb6b47f.html Basically for comparing a category A vs B and C you specify A as -1, B as 0.5 and C as 0.5 (or inverse negative / positive) as long as the sum is 0. Then it will compare the negative groups against the positive ones. 2 + 3 - For finding out whether a certain treatments works better for certain conditions, you should look at the interaction effect and see whether it is significant. Then the pairwise comparisons or specify particular constrasts for the interaction effect will detail this for particular groups. It can become complicated here to specify those contrasts. To make it happen you could do what you propose in point 3, that is combine everything into one factor. The overall result should be the same (the F value of the omnibus test). Of course you're not going to have the split in treatment and condition and interaction effect. Here a link that confirms this : Can you convert three-way ANOVA to one-way ANOVA?
