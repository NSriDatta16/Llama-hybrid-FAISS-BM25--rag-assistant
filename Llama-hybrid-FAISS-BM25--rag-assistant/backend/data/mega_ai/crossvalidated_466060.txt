[site]: crossvalidated
[post_id]: 466060
[parent_id]: 465969
[tags]: 
A possible explanation are different default parameters determining the size of the tree. Random forests are based on the idea of averaging a lot of slightly different, very deep decision trees. By default, leaf nodes often contain as little as a handful of observations. A single such overfitted tree would perform very badly if applied to unseen data. Averaging a lot of unstable trees results in a quite robust model, an idea similar to economic diversification of a portfolio of highly risky single assets. In order to make a single tree perform acceptably well, it needs to be smaller than in a random forest. Thus, default parameters are usually very different. In your case, the regularization is so strong that not a single split is made.
