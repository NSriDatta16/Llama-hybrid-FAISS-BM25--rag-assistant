[site]: crossvalidated
[post_id]: 258360
[parent_id]: 
[tags]: 
Connection between MCMC and Optimization for Inverse/Parameter-Estmation Problems

I've been considering two approaches to solving inverse/parameter-estimation problems, and I'm curious to the connection and/or difference between the two approaches. Set up: Say we have a forward model, $F$, that gives a response, $y$, given some unknown parameters to be estimated $\theta$, and uncertain known parameters $\rho$, $y = F(x|\theta,\rho) + \epsilon$. We have some prior on the parameters $p(\theta)$, measured/realized data, $d$, and iid Gaussian noise, so likelihood is $p(d|\theta,\rho) = C*exp(-\sum(d_i - F(x_i|\theta,\rho))^2)$. Using Bayesian inference, the distribution for desired parameters is, $p(\theta|d,\rho) = p(d|\theta,\rho)p(\theta)$. Solution Method 1: Sample values from distributions for $d$ and $\rho$, Find optimal $\theta$: $\hat{\theta} = argmax(p(\theta|d,\rho) = p(d|\theta,\rho)p(\theta))$ This is MAP estimate for $\theta$ for the realized values for $d$ and $\rho$. Repeat to get collection of optimal $\theta$. The collection of "optimal" $\theta$ is clearly related to the full posterior for $p(\theta|d)$ Solution Method 2 (MCMC) Given some symmetric proposal distribution slash method to get realizations of $\theta$ and $\rho$, Sample to get values for $\theta$, $\rho$, and $d$ Run forward model, $F(x|\theta_i,\rho_i)$ and calculate likelihood, $p(d_i|F)$ Calculate acceptance probability using the posterior, $\alpha = \min(1,\frac{p(d_i|F)p(\theta_i)}{p(d_{i-1}|F)p(\theta_{i-1})})$ Collection of accepted $\theta$ values is the discrete approximation for the posterior. Questions I've read about MCMC; however, I'm struggling to get comfortable with the application to a real problem where we want to consider uncertainty in measurements and uncertainty in model parameters to perform an inverse problem as I've outlined above. What I've seen in worked examples usually are very simple, or don't fully work things out on a problem of realistic complexity. For example, the knapsack problem , where new proposals are generated by switching one entry of the current state. Anyone have links to examples that fit this middle ground? What are the differences between the methods? My immediate observations: Method 1 is much more expensive computationally Both methods avoid computing the normalization constant of the posterior since the acceptance ratio in MCMC and optimization operations use the relative change in the posterior as the algorithms progress Lastly, in the MCMC approach, is it reasonable to just sample values for $\theta$ from the prior $p(\theta)$, and sample values for $d$ and $\rho$ from their respective distributions? If so, the Markov Chain is totally independent of the previous state (i.e., $q(x_{i+1}|x_i) = q(x_{i+1})$), yes?
