[site]: crossvalidated
[post_id]: 475432
[parent_id]: 
[tags]: 
What are the best known techniques to verify that a GAN samples correctly from a given distribution?

I would like to know what are the best known techniques to check that a generative adversarial network (GAN) samples from the correct distribution. Naively, I would say it all boils down to a estimating a distance (or divergence such as Kullback-Leibler) between the two empirical distributions (the one generated by the GAN, and the one given and used as training input). However, in very high dimension, this divergence estimation is not an easy task. I have read about some alternative approach using Topological Data Analysis (TDA) such as this paper Geometry Score: A Method For Comparing Generative Adversarial Networks , but not sure it is 'technology' yet (in the sense, working well and effortlessly for non-toy problems). I am looking for pointers to the best practice and tools.
