[site]: stackoverflow
[post_id]: 4641499
[parent_id]: 4554218
[tags]: 
Without claiming it's a best solution, this is how my team currently does staging and deployment. Developers initially develop at their local machine, the OS is free to choose, but we strongly encourage using the same JVM as will be used in production. We have a DEV server where frequently snapshots of the code is being pushed to. This is simply a scp from the binary build produced from the IDE. We plan to build directly on the server though. The DEV server is used for stakeholders to continuously peek along with development. By its very nature it's unstable. This is well known with all users of this server. If the code is good enough, it's branched and pushed to a BETA server. Again, this is a scp of a binary build from the IDE. Testing and general QA takes place on this BETA server. Mean while, if any emergency changes should be necessary for the software currently in production, we have a third staging server called the UPDATE server. The UPDATE server is initially only used to stage very small fixes. Here too we use scp to copy binaries. After all testing is conducted on UPDATE , we copy the build from UPDATE to LIVE . Nothing ever goes to the live servers directly, it always goes via the update server. When all testing is finalized on BETA , the tested build is copied from the beta server to the UPDATE server and a final round of sanity testing is performed. Since this is the exact build that was tested on the beta server, it is very unlikely that problems are found in this stage, but we uphold the rule that everything deployed to the live server should go via the update server and that everything on the update server should be tested before moving it on. This sliding strategy allows us to develop for 3 versions in parallel. Version N that's currently in production and staged via the update server, version N+1 that will be the next major release that's about to be released and is staged on the beta server, and version N+2 that is the next-next major release for which development is currently underway and is staged on the dev server. Some of the choices that we made: A full application (an EAR) typically depends on artifacts from other projects. We choose to include the binaries of those other projects instead of building the whole thing from source. This simplifies building and gives greater assurance that a tested application is bundled with exactly the right versions of all its dependencies. The cost is that a fix in such a dependency has to be manually distributed to all applications that depend on it. Configuration for every staging is embedded in the EAR. We currently use a naming convention and a script copies the right version of each configuration file to the right location. Parameterizing the path for each configuration file, e.g. by using a single {stage} placeholder in a root config file is currently being considered. The reason we store the config in the EAR, is because the developers are the ones who introduce and depend on configuration, so they should be the ones responsible for maintaining it (adding new entries, removing unused one, tweaking existing ones, etc). We use a DevOps strategy for a deployment team. It consists of a person who is purely a developer, two persons who are both developer and operations and two persons who are purely operations. Embedding the configuration in the EAR might be controversial, since traditionally operations needs to have control about e.g. the DB data sources being used in production (to what server it points to, how many connections a connection pool is allowed to have, etc). However, since we have persons on the development team who are also in operations, they are easily able to sanity check the changes made by other developers in the configuration while the code is still in development. Parallel to the staging we have the continuous build server server doing a scripted (ANT) build after every check-in (with a maximum of once per 5 minutes), and runs unit tests and some other integrity tests. It remains difficult to say whether this is a best-of-breed approach and we're constantly trying to improve our process.
