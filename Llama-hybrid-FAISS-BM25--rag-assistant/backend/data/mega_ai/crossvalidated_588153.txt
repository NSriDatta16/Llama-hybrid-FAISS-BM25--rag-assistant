[site]: crossvalidated
[post_id]: 588153
[parent_id]: 
[tags]: 
Is asymptotic unbiasedness different from unbiasedness in practice?

Given some estimator T for a parameter θ, by definition T is unbiased if its bias B(T) is 0. It is asymptotically unbiased if B(T) is not 0, but some value that tends to 0 as n goes to infinity. My question is: how are these properties different in practical terms? Unbiasedness by itself is only true for infinitely large n: given that B(T) = E(T) - θ, and the expected value E(T) is the mean of T's values over infinitely large n , it would seem that the two properties are saying the same thing. So, given they have the same variance, how do you distinguish between an estimator: whose sampling average tends towards θ for large n [E(T) = θ, unbiased] whose sampling average tends towards some value that tends towards θ for large n [E(T) = θ + f(n), where f(n) tends to 0 for large n, asymptotically unbiased]
