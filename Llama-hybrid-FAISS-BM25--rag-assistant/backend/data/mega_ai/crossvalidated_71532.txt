[site]: crossvalidated
[post_id]: 71532
[parent_id]: 71525
[tags]: 
Any effect size is possible, it's hard to tell what you mean by "makes sense". There are many power calculators on the internet found with a simple Google search. You'll see that G*Power is often recommended here. Conceptually you calculate power more or less the same way. In the independent case you're probably using the pooled variance of your conditions to get an SD. That's a Cohen's D. However, with the repeated measures case it will be the SD of the effect, which incorporates the covariance between the conditions. If you have a well justified repeated measures design the covariance should be fairly large, which will result in a small effect SD. Therefore, you'll require a smaller N. You need to somehow find this effect SD or covariance (or correlation). If there are no repeated measures studies from which to derive it or you don't have prior data you might better off taking a different approach (at least for your first repeated measures study). You don't have to calculate power before conducting a study. You could take the following approach. You could decide how much of an effect you care about. Let's say it's 4 (not 4SDs, 4 on your scale, whatever it is...it could even be your original 2 SDs, although that's rather large). Effects smaller than that wouldn't really mean much even if the test was significant and you want to be able to detect effects at least that size. Run subjects until you can detect an effect of that size (calculate the width of an effect confidence interval). Stop once you can detect the desired value. I've previously posted the simulations that show that this does not inflate alpha appreciably, and gives you the expected power and N on average. (Keep in mind that you are not allowed to make decisions on significance of a test, only sensitivity. That requires discipline.)
