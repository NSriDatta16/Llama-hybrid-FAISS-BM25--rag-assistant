[site]: datascience
[post_id]: 65065
[parent_id]: 65058
[tags]: 
1. univariate feature importance ( that is c) in your list) You are correct. Univariate statistics to estimate feature importance does not capture feature interactions. But they are fast and simple. 2. model-based feature importance (that are a) and b) in your list) On the other hand model-based feature importance estimates can capture interactions as long as the model is capable of doing so (see "Introduction to Machine Learning with Python"; Mueller, Guido; 2017; p. 238/239). Which is not the case for linear regression. For model-based feature importance estimates using trees there are ways to derive p-values. And at least R does have some implementations for that. Have a look at section "2.5 Importance testing procedures" in this paper The revival of the Gini importance? .
