[site]: crossvalidated
[post_id]: 292303
[parent_id]: 292292
[tags]: 
Random forest technically has only one hp: the # estimators E. By increasing E, we can reduce variance (a pure RF has no bounds on max_depth, e.g. (See Breiman's page ). Especially with many predictors (or perhaps many spurious predictors) or some other characteristic of the data, E might need to be very large. Each tree grown to full size is an extremely overfit classifier; only as part of an ensemble does it give any kind of reasonable accuracy. I have seen it described elsewhere on this site that you must simply "add estimators until RF converges". The point of convergence depends on the dataset. It might be worth plotting learning curves to see whether the previous ensembles with fewer estimators were overfitting.
