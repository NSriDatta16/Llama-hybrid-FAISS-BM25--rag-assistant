[site]: crossvalidated
[post_id]: 194056
[parent_id]: 
[tags]: 
Advantages of Particle Swarm Optimization over Bayesian Optimization for hyperparameter tuning?

There's substantial contemporary research on Bayesian Optimization (1) for tuning ML hyperparameters. The driving motivation here is that a minimal number of data points are required to make informed choices about what points are worthwhile to try (objective function calls are expensive, so making fewer is better) because training a model is time-intensive -- some modestly-large SVM problems that I've worked on can take between minutes and hours to complete. On the other hand, Optunity is a particle swarm implementation to address for the same task. I'm not overwhelmingly familiar with PSO, but it seems like it must be less efficient in the sense of requiring a larger number of trial points, and therefore objective function evaluations, to assess the hyperparameter surface. Am I missing a key detail that makes PSO preferred to BO in the machine learning context? Or is the choice between the two always inherently contextual for the hyperparameter tuning task? (1) Shahriari et al, "Taking the Human out of the Loop: A Review of Bayesian Optimizaiton."
