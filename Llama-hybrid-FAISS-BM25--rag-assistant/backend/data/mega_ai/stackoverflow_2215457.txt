[site]: stackoverflow
[post_id]: 2215457
[parent_id]: 2215363
[tags]: 
The reason the subsequent fflush() operations succeed is that there is no (new) data to write to disk. The first fflush() failed; that is tragic but history. The subsequent fflush() has nothing to do, so it does so successfully. If you are writing to a database, you have to be careful about each write - not just dealing with problems at the end. Depending on how critical your data is, you may need to go through all sorts of gyrations to deal with problems - there are reasons why DBMS are complex, and failed writes are one of them. One way of dealing with the problem is to pre-allocate the space for the data. As others have noted, classic Unix file systems allow for sparse files (files where there are empty blocks with no disk space allocated for them), so you actually have to write some data onto each page that you need allocated. Then you only have to worry about 'disk full' problems when you extend the space - and you know when you do that and you can deal with that failure carefully. On Unix-based systems, there are a variety of system calls that can help you synchronize your data on disk, and options to 'open' etc. These include the 'O_DSYNC' and related values. However, if you are extending a file, they can still cause failures for 'out of space', even with the fancy synchronizing options. And when you do run into that failure, you have to wait for space to become available (because you asked the user to tell you when it is available, perhaps), and then try the write again.
