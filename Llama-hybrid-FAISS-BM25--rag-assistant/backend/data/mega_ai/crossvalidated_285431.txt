[site]: crossvalidated
[post_id]: 285431
[parent_id]: 285384
[tags]: 
The number of predictions you'll have to make once your model goes into production doesn't matter. The real problem is overfitting on a small training dataset. Regarding your specific questions: If the distributions differ, then you should re-sample the training dataset so that it more closely resembles what you expect to see in production. This won't work if the two sets are extremely different. The degree of difference is a rule of thumb that you'll have to decide based on your domain expertise. Use simpler and smaller models for smaller datasets. An obvious example would be: don't assign more trees to your random forest than there are data points in your training data set. If your dataset is very small (several hundred records) then you should probably use a linear model. If you have an imbalanced data set (e.g., predicting fraud, which doesn't happen often) and the class of interest occurs only 1% of the time, then several thousand rows is very small, and you'll probably only want to use a linear model.
