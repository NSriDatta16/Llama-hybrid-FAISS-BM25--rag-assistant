[site]: datascience
[post_id]: 114414
[parent_id]: 114355
[tags]: 
Lots of different approaches, you could instead of 1 or 0 you could have more granular information of their time on the pitch (if your data supports it). I think number of goals is a bad feature to use for all players as presumably defenders and goal keepers generally dont score. You could keep it if you reduce it to known strikers maybe. Also I question if number of goals directly correlates to a win/draw/lose. A match can be won with only one goal scored and could still be lost if many are scored but feel free to model it. Otherwise 1 and 0 should be fine. I am assuming you have players as the columns and rows are matches played. In which case there is no point in standardising the data as each column represents the same range of possible values. Ideally you would have more rows than columns but if its for fun I would say why not model it. I produced a psuedo-random dataset (ie random unless player 0 playes then score that as a win) that simulates what you are asking then did simple Logistic regression. import pandas as pd import numpy as np from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split player_list = [f'player_{i}' for i in range(500)] players_selected = [] for i in range(380): a_list = np.array([0 for i in range(500)]) for j in np.random.choice(np.arange(500),size = 380): a_list[j] = 1 players_selected.append(a_list) players_selected = np.array(players_selected) df =pd.DataFrame(players_selected, columns=player_list) df['game_result'] = np.random.choice([0,1,2],size = (380)) df['game_result'] = df['player_0'].apply(lambda x:2 if (x == 1) else np.random.choice([0,1])) X = df.iloc[:,:-1] y = df.iloc[:,-1] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) LR = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, y_train) print(LR.predict(X_test)) print(LR.score(X_test, y_test)) output was:
