[site]: crossvalidated
[post_id]: 624514
[parent_id]: 624475
[tags]: 
With shuffling, I get a MAE of about 0.06: Without shuffling, it's about 10 times worse, resulting in a bad fit. I think this is because your features (date) are linearly increasing, meaning that each split will have very different statistics, rather than the splits exhibiting similar statistics. Shuffling is necessary in this case to make the statistics of each split more similar. import pandas as pd import numpy as np import matplotlib.pyplot as plt from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold from xgboost import XGBRegressor start_date = '2010-01-01' end_date = '2020-01-01' dates = pd.date_range(start=start_date, end=end_date, freq='D') unix_dates = np.array([int(pd.Timestamp(d).timestamp()) for d in dates]) freq = 'D' # Monthly frequency date_rng = pd.date_range(start=start_date, end=end_date, freq=freq) prices = np.sin(unix_dates) data = pd.DataFrame({'ds': date_rng, 'y': prices}) params = { 'max_depth': [3, 6, 12], 'learning_rate': [0.001, 0.01, 0.3], 'n_estimators': [1, 10, 50, 500], } model = XGBRegressor(random_state=0) model.get_params() #Prepare data for algorithm by # converting datetime to a numeric format X = data[['ds']].values.astype(np.int64) y = data.y.values search = GridSearchCV( model, params, n_jobs=-1, cv=KFold(n_splits=3, shuffle=True, random_state=0), #with shuffling return_train_score=True, scoring='neg_mean_absolute_error', verbose=0, ).fit(X, y) cv_results = search.cv_results_ #View the CV results (sorted by test_score) results_df = ( pd.DataFrame(cv_results) .eval('mean_test_score = -mean_test_score') .sort_values('mean_test_score') ) display(results_df.head(3)) #Get prediction using the best estimator predictions = search.best_estimator_.predict(X) #View the first 100 samples plt.plot(y[:200], linewidth=10, color='tab:green', label='y') plt.plot(predictions[:200], color='tab:red', linestyle='--', linewidth=1.8, label='prediction') plt.legend() plt.xlabel('index') plt.ylabel('value')
