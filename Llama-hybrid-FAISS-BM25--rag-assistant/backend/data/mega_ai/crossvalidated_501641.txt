[site]: crossvalidated
[post_id]: 501641
[parent_id]: 501623
[tags]: 
I don't think #1 is true because if you decrease C, then you are allowing more misclassification in the training set. So it can't mean more overfitting. I think #2 is partly true, but how can you ever for sure know what will happen in the testing set? I find this strange. Certainly in the training set, as you increase C, you will decrease the number of misclassified data in the training set. But how can you ever guarantee that your number of correctly classified testing points would increase. If that were true then everybody would just have an extra high C value. So I don't know, I wouldn't even say that's correct. #3 I think is true. The width of the gaussian kernel itself will be smaller, therefore being more likely to fit to the training set but not generalizing well with the test set. (see here: http://haohanw.blogspot.com/2014/03/ml-how-sigma-matters-in-svm-rbf-kernel.html ) #4 Again, how can you know what happens in the test set. If you knew a solid rule like this, then no one would need grid searches. Anything could happen if you increase the width of the kernel. It could either increase the number of correctly-classified points, or impinge on the boundary of the other class, causing a higher error rate.
