[site]: crossvalidated
[post_id]: 627337
[parent_id]: 
[tags]: 
How does the least squares solution replace expectation by averages over the training data?

This is a follow-up question for this post This question is related to what is written in 19 page of ESL. We have two statements. The following is a quote from the post. The one below is the matrix notation of the Least squares equation, after derivating w.r.t . (eq: 2.6) $\widehat{\beta} = (\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}\boldsymbol{y}$ The second equation is obtained after assuming $f(x)\approx x^{T}\beta$ . This is then substituted in the equation EPE()=E(âˆ’())2 and then differentiating, we get the below equation (eq: 2.16) $\beta =(E[X^{T}X])^{-1}E[XY]$ Regarding the two statements, the books says The least squares solution (2.6) amounts to replacing the expectation in (2.16) by averages over the training data. I am not clear abou what it means by saying replacing the expectation by averages over the training data. Where does the averages come from?
