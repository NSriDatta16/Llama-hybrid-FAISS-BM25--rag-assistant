[site]: crossvalidated
[post_id]: 254333
[parent_id]: 
[tags]: 
Influence of noisy training data on neural network

I want to count instances of an object in an image. I can generate as many images as desired in an automated fashion. However I can not yet guarantee that one instance will not completely cover another instance. My Data-Generator would return that there are (for example) 5 instances visible, but even a human could only possibly see 4. My question: Given that the probability of an occlusion is pretty low, how big of a problem is it that some training-samples are labeled with too big of a value? To clarify: It is expected that sometimes an instance in the front may partially cover an instance in the back. This should be detected and is part of the problem (and some of my samples are carefully generated with this in mind). But as of yet I am not able to guarantee that a full occlusion will not happen.
