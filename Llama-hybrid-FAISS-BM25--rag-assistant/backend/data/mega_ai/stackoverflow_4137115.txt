[site]: stackoverflow
[post_id]: 4137115
[parent_id]: 4136900
[tags]: 
In C++11 and later, there's no reason to use volatile as a poor-man's std::atomic with std::memory_order_relaxed . Just use std::atomic with relaxed . On compilers where volatile works the way you wanted, std::atomic with relaxed will compile to about the same asm which is equally fast. See When to use volatile with multi threading? (never) This answer is about the separate question of what the rule are exactly for volatile . It's not as well defined as you probably want it to be. Most of the relevant standardese from C++98 is in section 1.9, "Program Execution": The observable behavior of the abstract machine is its sequence of reads and writes to volatile data and calls to library I/O functions. Accessing an object designated by a volatile lvalue (3.10), modifying an object, calling a library I/O function, or calling a function that does any of those operations are all side effects , which are changes in the state of the execution environment. Evaluation of an expression might produce side effects. At certain specified points in the execution sequence called sequence points , all side effects of previous evaluations shall be complete and no side effects of subsequent evaluations shall have taken place. Once the execution of a function begins, no expressions from the calling function are evaluated until execution of the called function has completed. When the processing of the abstract machine is interrupted by receipt of a signal, the values of objects with type other than volatile sig_atomic_t are unspecified, and the value of any object not of volatile sig_atomic_t that is modified by the handler becomes undefined. An instance of each object with automatic storage duration (3.7.2) is associated with each entry into its block. Such an object exists and retains its last-stored value during the execution of the block and while the block is suspended (by a call of a function or receipt of a signal). The least requirements on a conforming implementation are: At sequence points, volatile objects are stable in the sense that previous evaluations are complete and subsequent evaluations have not yet occurred. At program termination, all data written into files shall be identical to one of the possible results that execution of the program according to the abstract semantics would have produced. The input and output dynamics of interactive devices shall take place in such a fashion that prompting messages actually appear prior to a program waiting for input. What constitutes an interactive device is implementation-defined. So what that boils down to is: The compiler cannot optimize away reads or writes to volatile objects. For simple cases like the one casablanca mentioned, that works the way you might think. However, in cases like volatile int a; int b; b = a = 42; people can and do argue about whether the compiler has to generate code as if the last line had read a = 42; b = a; or if it can, as it normally would (in the absence of volatile ), generate a = 42; b = 42; (C++0x may have addressed this point, I haven't read the whole thing.) The compiler may not reorder operations on two different volatile objects that occur in separate statements (every semicolon is a sequence point) but it is totally allowed to rearrange accesses to non-volatile objects relative to volatile ones. This is one of the many reasons why you should not try to write your own spinlocks, and is the primary reason why John Dibling is warning you not to treat volatile as a panacea for multithreaded programming. Speaking of threads, you will have noticed the complete absence of any mention of threads in the standards text. That is because C++98 has no concept of threads . (C++0x does, and may well specify their interaction with volatile , but I wouldn't be assuming anyone implements those rules yet if I were you.) Therefore, there is no guarantee that accesses to volatile objects from one thread are visible to another thread. This is the other major reason volatile is not especially useful for multithreaded programming. There is no guarantee that volatile objects are accessed in one piece, or that modifications to volatile objects avoid touching other things right next to them in memory. This is not explicit in what I quoted but is implied by the stuff about volatile sig_atomic_t -- the sig_atomic_t part would be unnecessary otherwise. This makes volatile substantially less useful for access to I/O devices than it was probably intended to be, and compilers marketed for embedded programming often offer stronger guarantees, but it's not something you can count on. Lots of people try to make specific accesses to objects have volatile semantics, e.g. doing T x; *(volatile T *)&x = foo(); This is legit (because it says "object designated by a volatile lvalue " and not "object with a volatile type ") but has to be done with great care, because remember what I said about the compiler being totally allowed to reorder non-volatile accesses relative to volatile ones? That goes even if it's the same object (as far as I know anyway). If you are worried about compile-time reordering of accesses to more than one volatile value, you need to understand the sequence point rules, which are long and complicated and I'm not going to quote them here because this answer is already too long, but here's a good explanation which is only a little simplified . If you find yourself needing to worry about the differences in the sequence point rules between C and C++ you have already screwed up somewhere (for instance, as a rule of thumb, never overload && ). If you also need run-time ordering of the visibility of volatile stores as seen by volatile loads in other threads on ISAs other than x86, you'd need inline asm or intrinsics for barrier instructions... Or better, use std::atomic with a memory order other than relaxed , e.g. std::memory_order_acquire and std::memory_order_release . (Those orderings are still "free" on x86, but will use special load/store instructions or barriers on non-x86 with weakly ordered memory models.) std::atomic also has the huge advantage of being able to establish happens-before synchronization between threads, e.g. making it possible to release-store a data_ready flag so readers can acquire-load and then (if the flag is true) access a plain array. (MSVC historically gave volatile acquire and release semantics so it could do this. /volatile:ms enables this behaviour, /volatile:iso disables that extra ordering.)
