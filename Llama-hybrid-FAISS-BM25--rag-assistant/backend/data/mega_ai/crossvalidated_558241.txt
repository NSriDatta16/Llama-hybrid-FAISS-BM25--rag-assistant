[site]: crossvalidated
[post_id]: 558241
[parent_id]: 558214
[tags]: 
First, you can use simple $\log$ rules to transform into the natural logarithm. Change of base is $\log_b(y)=\frac{\log_a(y)}{\log_a(b)}$ and hence $\log_{10}(y)=\frac{\ln(y)}{\ln(10)}$ and you can write $$\ln(y)=\ln(10)\cdot(2.49 - 0.0006X_1 + 0.0328X_2)=5.73344-0.00138X_1+0.075523X_2$$ which is easier to swallow. That's part 1. Part 2 is the concept of a link function . In many regression models, the output variable $\hat{y}_i$ is not equal to the linear predictor $\hat{\theta}_i=\hat{\beta}^Tx_i$ but rather some transformation, i.e $\hat{y}_i=g\left(\hat{\theta}_i\right)$ . This $g$ function is called the link function , which allows us to convert the output variable from $\mathbb{R}$ to the relevant support. In classic linear regression, $g$ is the identity function, but that is not always the case: for example, in logistic regression the output variable is a probability and thus $g$ is the sigmoid function which satisfies $g:\mathbb{R}\rightarrow[0,1]$ . In Poisson regression, however, the output is an integer so a very common link function is the exponential: $\hat{y}_i=\exp\left(\hat{\theta}_i\right)$ which can be equivalently written as $\ln(y_i)=\hat{\beta}^Tx_i$ . I think this looks familiar.
