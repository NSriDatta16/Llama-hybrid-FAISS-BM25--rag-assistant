[site]: crossvalidated
[post_id]: 451988
[parent_id]: 450408
[tags]: 
Let's first describe with mathematical notation what happens in the simulation (when dividing by n) and then lay out the statistics that would lead one to expect the result. bootstrap_resamples = np.random.binomial(n, theta, size) Generates $S=1000$ binomial random variables, $Y_s$ each consisting of the sum of $N=1000$ Bernoulli trials with success probability $\theta$ , $Y_s = \sum_j^{N} X_{s, j}$ sample_mean = resample/float(n) sample_variance = sample_mean*(1-sample_mean) / n Calculates $\hat{\theta}_s = \frac{1}{N} \sum_j^{N} X_{s, j}$ and $\hat{\text{v}}_s = \frac{\hat{\theta_s}(1-\hat{\theta_s})}{N}$ S_n = np.mean(sample_means) sigma_squared = np.mean(sample_variances) sigma = np.sqrt(sigma_squared) test_statistic = (S_n - theta)/(sigma/np.sqrt(1000)) Calculates $\hat{\theta} = \frac{1}{S} \sum_s^S \hat{\theta}_s$ and $\hat{\text{v}} = \frac{1}{S} \sum_s^S \hat{\text{v}_s}$ then $\text{stat} = \frac{ \hat{\theta} - \theta}{ \sqrt{ S^{-1} \hat{\text{v}} } }$ if not stats.norm.ppf(alpha/2.0) Finally, compute the indicator variable $Q = \text{stat} \not \in (-1.96, 1.96)$ Now, what is the sampling distribution of $Q$ ? If $\text{stat}$ is approximately standard normal, then it approximately equals $5\%$ . This is in fact the case because a central limit theorem applies. Looking at $\hat{\theta} = \frac{1}{S \cdot N} \sum_s \sum_j X_{s,j}$ that is just an average of $S\cdot N$ Bernoulli variables. If we subtract its mean divide by its standard deviation, it will have mean zero and variance 0. It consists of a sum of iid random variables, so will be approximately normal in large samples and be within (-1.96, 1.96) $95\%$ of the time. We have $E[ \hat{\theta} ] = \theta$ and $Var( \hat{\theta} ) = \text{V} = \frac{\theta(1-\theta)}{S\cdot N} $ . So $$\frac{ \hat{\theta} - \theta }{ \sqrt{\text{V}}}$$ is approximately standard normal by a CLT. In the simulation, the approximation will be really good because the sum is over a million random variables. If you want to focus only on understanding the CLT, divide by $v$ in the simulation. And you could have just looked at the mean of 1000 bernoulli trials instead of the mean over 1000 means. However, the denominator of $\text{stat}$ isn't $\sqrt{V}$ and yet the simulation still yields $Q$ at around $5\%$ anyways. Why? Because the denominator of $\text{stat}$ converges in probability to the root of $V$ by a law of large numbers. And there's another theorem ( https://en.wikipedia.org/wiki/Slutsky%27s_theorem ) that says asymptotically, that's as good as if it it actually was $V$ . To see the denominator works out: The denominator of $\text{stat}$ is the root of $\frac{1}{S \cdot S} \sum_s^S \hat{\text{v}_s} = \frac{1}{S \cdot S} \sum_s^S \frac{\hat{\theta_s}(1-\hat{\theta_s})}{N} = \frac{1}{S \cdot N} \left( \frac{1}{S} \sum_s \hat{\theta_s} - \frac{1}{S} \sum_s \hat{\theta_s}^2 \right)$ . The quantities inside the brackets will converge to $\theta$ and $\theta^2$ by a law of large numbers, so the denominator will converge to the root of $V$ and Slutsky's theorem kicks in.
