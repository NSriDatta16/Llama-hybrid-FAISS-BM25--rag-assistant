[site]: datascience
[post_id]: 25305
[parent_id]: 25221
[tags]: 
Both approaches are 'lossy'. For PCA, assuming you retain fewer components than variables, you necessarily throw away information. If you don't have a few components that capture most of the variance, you could throw a lot away. For feature selection, (I assume you mean an automated approach like lasso), you again throw away information, hopefully only incremental so. But, depending on how you structure the selection routine, you let an algorithm make some level of design decisions which result in less data. Whether this is bad or not depends on intent. Fire pure classification it's less an issue. For interpretability it can be essential.
