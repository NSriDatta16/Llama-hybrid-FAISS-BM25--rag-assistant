[site]: crossvalidated
[post_id]: 306504
[parent_id]: 306489
[tags]: 
I disagree with the other comment-or on "oversampling". There is such a thing as "over-sampling" but it is a relative term and more related to design of experiment than simply fitting data like you are doing here. Once you have the data, we call it "up-sampling" when you repeat observations/measurements -- but this is another advanced trick akin to re-weighting your data and should only be done when you know exactly what you're doing and why (for instance, you want to bias your model purposefully). That being said, your dealing with high dimensional data and is a classic problem in machine learning. You need to look at techniques that can handle high-dimensional data properly...primarily using cross validation of some kind (hence the forum name -- Cross-Validated :-)). I advise against PCA, it's not a very useful method in practice -- you're better off going straight for the goal using all features but using regularization via a validation set. This can include LASSO/Ridge regression, PLS, ANN, or others depending on your data and what you desire. Note that LASSO/Ridge have issues when you have more features than observations which is one of the reasons PLS is used (so you may want to investigate PLS first).
