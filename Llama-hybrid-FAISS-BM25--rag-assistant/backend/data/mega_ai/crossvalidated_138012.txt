[site]: crossvalidated
[post_id]: 138012
[parent_id]: 
[tags]: 
guidance and help required on improving open source ML/Data Mining Libraries

We would like to crawl a bunch of websites for specific information like the about us,company,technology pages of start-ups and enable sharing it across a social network which my organization is developing. 1) Crawling such websites is the first challenge. We tried using Crawler4j and bolierpipe which are openly available. Crawler4j does not remove the bolierplate content and it confuses our summarization algorithm due to presence of unstructured text commonly generated by it after crawling any of start-up websites. Bolierpipe(created to crawl news sites) on the the other hand performs better but has its limitations since its not accurate when removing all bolierplate content(it uses some advanced data mining algorithm which is currently beyond our expertise). 2) Our second challenge is text Summarization. We are currently using Classifier4j(Openly available) which again is not accurate to the levels or Production Quality. Firstly since the data is unstructured (since its generated after crawling a webpage and not a normal document) it gets confused with sentences(We are also not sure how the internal algo treats the raw data). Also about summarizing webpages just like facebook summarizes using the meta content in a HTML page we dont have that opportunity since most of start-ups in FMCG sector don't use meta tags in their webpages.I understand we can provide training data but this is beyond the scope of our current expertise. I tried using other libraries like Dragon toolkit (which is a bit old since it was written in 2008) but getting them to work is a challenge. Any direction to a new library or technical guidance as to what ML algorithm to use and attempt to build will be greatly helpful.
