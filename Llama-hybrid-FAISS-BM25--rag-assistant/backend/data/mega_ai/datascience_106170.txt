[site]: datascience
[post_id]: 106170
[parent_id]: 106168
[tags]: 
That's a good question. We can take a look at the distribution of the output, the distribution of the model parameters, and the distribution of the input. The probability distribution of the output plays a central role in classification problems, where we assume that the classes follow a categorical distribution. We ensure this by applying some sort of normalization, e.g., a softmax in neural networks. Then we minimize some information-theoretic measure that is based on the predicted output distribution and the true output distribution, such as cross-entropy (X-ent) loss or Kullback-Leibler (KL) loss. Otherwise, we would have to resort to simple classification losses, such as simply the MSE. But X-Ent and KL losses provide a smoother loss landscape and thus allow gradient descent to convergence more quickly. It is also central in reinforcement learning, where we assume that the continuous actions the agent takes are Gaussian distributed: our model learns the mean $\mu$ and the log-variance $\log\sigma$ of the action distribution. In each step, we then proceed according to our policy $p(a|s) = \mathcal{N}(\mu,\sigma)$ . It is similar for categorical actions ( softmax over the Q-values). This allows us to incorporate uncertainty and model exploration, which would not be possible if we took the action as a deterministic output. We can also place a distribution over the parameters of a model, such as is done in stochastic neural networks. The weights $\omega$ are then given by a distribution $p(\omega|x)$ . This allows us to incorporate uncertainty into the model. When we are interested in the distribution of the input, we are dealing with a generative model. Here, the goal is to model the data generating process to create new data. Prominent approaches are Generative Adversarial Networks and Variational Auto-Encoders.
