[site]: crossvalidated
[post_id]: 462964
[parent_id]: 207780
[tags]: 
I spent a bit of time researching on this for my master thesis. Even though this question is a bit old, I've decided to share my findings anyway since it would have helped me earlier when I ran into this page and didn't think the answers so far gave a full picture. The short story : The question is non-trivial for general state and action spaces. Here are a couple of results: Let $A(s) \subseteq \mathcal{A}$ denote the set of available actions at a state $s \in \mathcal{S}$ . Thm : If $\mathcal{S}$ is countable and $\mathcal{A}$ is standard Borel $A(s)$ is compact for all $s \in \mathcal{S}$ For every $s \in \mathcal{S}$ the reward function $r(s, \cdot)$ is upper semicontinuous. Then there exists a deterministic optimal policy $\pi^*$ . Thm : If $\mathcal{S}$ is standard Borel $A(s)$ is finite for all $s \in \mathcal{S}$ Then there exists a deterministic optimal policy $\pi^*$ . The long story : Here are some references that I found useful: A good source for an overview, and basis for the short story above: Feinberg: Total Expected Discounted Reward MDPs: Existence of Optimal Policies . The most 'deep' of the results comes, as far as I can see, from this article Sch√§l: On dynamic programming: Compactness of the space of policies . Another good source giving its own comprehensive account is Bertsekas & Shreve: Stochastic Optimal Control: Discrete time case chapters 7,8 and 9. Cheers.
