[site]: datascience
[post_id]: 8274
[parent_id]: 8264
[tags]: 
You didn't say whether you were building a regression or classification model, but here goes anyway. As ever, it depends ... though several neural network approaches, such as deep learning or RBF networks, have shown promise with high dimensional data. It is possible to have KNN approaches which use representative points, either as cluster centres or class boundaries, to reduce the computation burden. As a test I tried computing the Euclidean distance between a single vector and 20,000 , 20,000 feature vectors. This took around 7 seconds on a single core of a desktop machine using Mathematica. If you have the RAM and several cores KNN should be feasible in your time scales. Feature engineering might gain you speed benefits but you would want to tune that in concert with prediction/classification accuracy. There are several methods for achieving regularisation if you suspect you are overfitting, you might want to explore Ridge Regression/Tikhonov regularisation or early stopping if you are following the neural network path. Good luck.
