[site]: stackoverflow
[post_id]: 688479
[parent_id]: 354254
[tags]: 
Just as James Curran says, the fact that most programs follow the law of locality of references, the frequent code and data page count will be narrowed over time to a manageable size by the OS disk cache. RAM disks were useful when operating systems were built with limitations such as stupid caches (Win 3.x, Win 95, DOS). The RAM disk advantage is near zero and if you assign a lot of RAM it will suck memory available to the system cache manager, hurting overall system performance. The rule of thumb is: let your kernel to do that. This is the same as the "memory defragmentation" or "optimizers" programs: they actually force pages out of cache (so you get more RAM eventually), but causing the system to do a lot of page-faulting over time when your loaded programs begin to ask for code/data that was paged out. So for more performance, get a fast disk I/O hardware subsystem, maybe RAID, faster CPU, better chipset (no VIA!), more physical RAM, etc.
