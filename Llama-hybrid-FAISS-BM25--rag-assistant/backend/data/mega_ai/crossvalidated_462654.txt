[site]: crossvalidated
[post_id]: 462654
[parent_id]: 
[tags]: 
Logistic Regression loss function?

During linear regression the algorithm jumbles with the coefficients to create a linear model that closely fits real life data points. How good/crappy models are is tested by measuring the residuals, squaring them and taking the sum. If you graph the sum of squared residuals for a series of linear models (each of them getting progressively better at predicting the real life data points) it will look like a quadratic function. So ultimately the best model produces the minimized value of the quadratic loss function. I also understand that in order to test how good/crappy a linear classification model is, you can measure how many misclassifications there are and assign one point for every misclassification and zero points for every correct classification (0-1 loss function - it looks like a step model, check picture below). Therefore the best linear classification model is selected by determining which model minimizes the number of misclassifications. I have recently learned that the loss function for logistic regression appears to be exponential in shape (look at picture). I have questions regarding this loss function. First Question: The connection between linear regression and the quadratic loss function is very clear to me. I can graph the sum of squared residuals for progressively better linear models and it will produce a quadratic function (a parabola). However how is logistic regression models and the exponential loss function connected?? Can you prove/tell me how this is possible? I read that the traditional 0-1 loss function is altered for logistic regression models and a heavier penalty (not just one point) is applied for misclassification - however I'm still lost in seeing the connection between logistic regression and its corresponding loss function. Second Question: If the loss function for logistic regression is an exponential function, how do we look to minimize this loss function? If I look at the quadratic loss function i can clearly see the minimum value, moreover I can even take the derivative of the quadratic loss function to find when the slope is zero. If I'm looking at the logistic loss function how would I minimize the function? Please use plain english
