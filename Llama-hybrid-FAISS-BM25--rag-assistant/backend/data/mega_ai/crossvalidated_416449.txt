[site]: crossvalidated
[post_id]: 416449
[parent_id]: 
[tags]: 
What is the meaning of calculating Maximum Likelihood from complete data for Bayesian Nework paremeter learning?

I am taking a subject on Bayesian Network on Youtube. Somehow, I am struggling from understand the meaning of calculating Maximum Likelihood estimates from complete data for a for bayesian nework paremeter learning?. Appreciations if somebody can explain the meaning of it. ===================== Added part for a clarification to my question ===================== I am studying how to learn the concept and implementation of structural learning on Bayesian Network. While studying it, I have faced parameter learning and structural learning. One thing that I couldn't understand was that there were some methods to do the parameter learning on complete data and incomplete data. I was wondering why we need to learn the parameters on the network while we have a complete set of data. The lecturer was saying we can just count them and build empirical distributions. Somehow, I didn't really understand what he was saying. For incomplete data set, the lecturer said we can use EM algorithm. I understand what he was trying to say, somehow It was kind of confusing to figure out the specific way that he was trying to say. Another thing that I want to know is how to do the structural learning for a bayesian network. I want to know how the mathematical expressions are implemented. as you told me the two methods, I'd like to know how they are implemented. I don't mind mathematical ways of explanations as long as it shows the steps. Do I need to choose one of the two methods, you mentioned in your answer, to do learning structure? What kind of independence test is needed to do it? Do I have to apply the method 'a' and the method 'b' together? How can I implement it? Hope I can have a small example for it.
