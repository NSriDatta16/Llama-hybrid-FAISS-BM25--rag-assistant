[site]: crossvalidated
[post_id]: 185876
[parent_id]: 182312
[tags]: 
For two time series $X_t$ and $Y_t$ to be cointegrated two conditions are met: $X_t$ and $Y_t$ must be $I(1)$ processes, i.e. $\Delta X_t$ and $\Delta Y_t$ must be stationary processes (in a weak sense, i.e. covariance stationary). There exists a set of coefficients $\alpha,\beta\in \mathbb{R}$ such that the time series $Z_t=\alpha X_t+\beta Y_t$ is a stationary process. The vector $(\alpha,\beta)$ is called cointegrating vector. Since stationarity is invariant to shift and scale it immediately follows that coefficients $\alpha$ and $\beta$ are not uniquely defined, namely they are unique up to multiplicative constant. Cointegration tests come in two varieties: Tests on residuals of regression of $Y_t$ on $X_t$. Tests on matrix rank in a vector-error correction representation of $(Y_t,X_t)$. Both varieties rely on certain theoretical results, namely: OLS of $Y_t$ on $X_t$ gives a consistent estimate of cointegration vector Granger representation theorem. The OP question is about the first variety of tests. In these tests we have a choice: estimate regression $Y_t=a_1+b_1 X_t+u_t$ or $X_t=a_2+b_2 Y_t+v_t$ on $Y_t$. Naturally these two regressions will give two different cointegrating vectors: $(-\hat b_1, 1) $ and $(1, -\hat b_2)$. But due to above mentioned theoretical result the probability limits of $-\hat b_1$ and $-1/\hat b_2$ must be the same, since the cointegrating vector is unique up to a constant. Due to algebraic properties of OLS the residual series $\hat u_t$ and $\hat v_t$ are not identical, although from theoretical perspective they both should be equal to $\frac{1}{\beta}Z_t$ and $\frac{1}{\alpha}Z_t$ respectively, i.e. they should be identical to multiplicative constant. If the series $X_t$ and $Y_t$ are cointegrated then $Z_t$ is a stationary series, so since $\hat u_t$ and $\hat v_t$ approximate $Z_t$ we can test whether they are stationary. That is how the first variety of cointegration tests are performed. Naturally since the $\hat u_t$ and $\hat v_t$ are different any tests on them will differ too. But from theoretical point of view any difference is simply a finite sample bias, which should disappear asymptotically. If the difference between the stationarity tests on series $\hat u_t$ and $\hat v_t$ is statistically significant, this is an indication that the series are not cointegrated, or assumptions of stationarity tests are not met. If we take ADF test as a stationarity test for residuals I think it would be possible to derive asymptotic distribution of difference between the ADF statistics on $\hat u_t$ and $\hat v_t$. Whether it would have any practical value I do not know. So to summarize the answers to the three questions are the following: See above. No. The asymptotic distribution of difference of the tests would depend on the test. Your methodology is fine. If time series are cointegrated, both statistics should indicate so. In case of no cointegration, either both statistics will reject stationarity, or one of them will. In both cases you should reject the null hypothesis of cointegration. As in testing for unit root you should safeguard against time trends, change points and all the other things that make unit root testing quite challenging procedure.
