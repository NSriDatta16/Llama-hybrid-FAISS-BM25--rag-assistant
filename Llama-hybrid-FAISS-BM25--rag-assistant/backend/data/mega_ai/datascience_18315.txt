[site]: datascience
[post_id]: 18315
[parent_id]: 18286
[tags]: 
Why doesn't table-look up generalize? Generalization means you find rules which apply to unseen situations. For example, let's say I have a function $f: \mathbb{R} \rightarrow \mathbb{R}$ and I give you the (input, output) pairs (0, 1), (1, 2), (3, 4), (3.141, 4.141). If you learn by table look-up, you know exactly those 4 tuples. But If I ask you what $f(5)$ is, you have a problem. Because you didn't find the general rule/pattern, but you simply memorized the data. Another example: Imagine you have $n$ data points $(x, y)$ and you decide to fit a polynomial to it. As you know, you can fit any $n$ points (with the x's pairwise different) to a polynomial of degree $n-1$. But if you do that, even the slightest noise or a different unterlying model causes your predictions to be awefully wrong because your polynomial bounces like crazy. What does he mean by hand generated features? If you have a vector of $n$ numbers $(x_1, \dots, x_n)$ as input, you might decided that the pair-wise multiplication $x_3 \cdot x_{42}$ helps the classification process. Hence you add $x_{n+1} = x_3 \cdot x_{42}$. This is a hand generated feature. In contrast, neural networks learn non-linear combinations of the input.
