[site]: datascience
[post_id]: 31698
[parent_id]: 31691
[tags]: 
You can solve this problem using traditional recommendation system algorithms for text. I will show you two ways how this can be implemented, one using a simple linear search and the other using some clustering approach. First, you will need to vectorize your descriptions. Feature extraction You will build a dictionary of existing words or character sequences and then you will fill this vector with the number of occurances in your short description. There are two techniques, I would recommend for this, the first is bag-of-words, don't forget to only use the stem of words since coffee should be the same as coffees. The second is n_grams which is sequences of characters. n-grams n-grams is a feature extraction technique for language based data. It segments the Strings such that roots of words can be found, ignoring verb endings, pluralities etc... The segmentation works as follows: The String: Hello World 2-gram: "He", "el", "ll", "lo", "o ", " W", "Wo", "or", "rl", "ld" 3-gram: "Hel", "ell", "llo", "lo ", "o W", " Wo", "Wor", "orl", "rld" 4-gram: "Hell", "ello", "llo ", "lo W", "o Wo", " Wor", "Worl", "orld" Thus in your example, if we use 4-grams, truncations of the word Hello would appear to be the same. And this similarity would be captured by your features. Bag-of-words This builds a dictionary of the words it has seen during the training phase. Then using the word the frequency of each word in the example a vector is created. This can then be used with any standard machine learning technique. For example: If the dictionary includes the words {car, coffee, motel, hotel, world, van, soup} and we have the description "the soup in this motel is amazing!". Then the resulting vector would be $[0, 0, 1, 0, 0, 0, 1]$ . Applying your search You will now have a vector representation of each of your descriptions. Then for a search term like "yummy food motel", you can vectorize it as $[0, 0, 1, 0, 0, 0, 0]$ , then find the most similar instance in your set to this vector. You can use the Euclidean distance as a metric of similarity. This method can be considered a k-nearest neighbors (k-NN) approach.
