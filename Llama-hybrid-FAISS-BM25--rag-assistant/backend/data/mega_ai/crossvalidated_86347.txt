[site]: crossvalidated
[post_id]: 86347
[parent_id]: 
[tags]: 
Correction of data reduces quality of results

I'm running a logistic regression with a small sample size: I corrected my data for outliers after checking the standard error (1.07) and the confidence intervall (0.51 - 11.55) for one of my variables. Those with a cook distance > 1 and DFBeta > 1 were excluded which resulted in an even higher standard error (2.15) and confidence intervall (0.15 - 676.20). I assume this happened due to the small sample size. Is it right to include those again that were excluded before, though they influence the regression so much? How would my argumentation for that step look like?
