[site]: crossvalidated
[post_id]: 243037
[parent_id]: 
[tags]: 
What does sample_weight mean in LinearSVC in scikit-learn?

Mathematically, what does sample_weight mean in sklearn.svm.LinearSVC and also svm.SVC? According to what they say in the document, I assume the weights directly changes the C for each sample, i.e., for ith sample the penalty is Cw_i. Well but I executed the code here SVM: Weighted samples Using SVC with linear kernel and LinearSVC (only just change the class to LinearSVC), and it seems that LinearSVC gets sample results regardless of the weights (while SVC results change with weights). The developers say that Linear SVC is "less sensitive to sample_weight," but in what sense is it less sensitive (mathematically)? Another thing - is there any way to use SVC without an intercept? That's after all why I use LinearSVC...
