[site]: crossvalidated
[post_id]: 632476
[parent_id]: 632398
[tags]: 
The p-value is computed with the sampling distribution Given a parameter $\theta \in \Theta$ , an observed data vector $\mathbf{x}$ and a test statistic $T$ that is increasing with respect to evidence for the alternative hypothesis (i.e., a higher value is more conducive to the alternative), the p-value for the null hypothesis $H_0: \theta \in \Theta_0$ is defined as: $$\begin{align} p(\mathbf{x}) &\equiv \sup_{\theta \in \Theta_0} \mathbb{P}(T(\mathbf{X}) \geqslant T(\mathbf{x}) | \theta) \\[12pt] &= \sup_{\theta \in \Theta_0} \ \int \limits_{\mathbf{r} : T(\mathbf{x}) \geqslant T(\mathbf{r})}^\infty f_\mathbf{X}(\mathbf{r}|\theta) \ d \mathbf{r}, \\[6pt] \end{align}$$ As you might be able to see, the p-value is a function of the sampling distribution $f_\mathbf{X}(\ \cdot \ |\theta)$ . The sampling distribution is the distribution of the data vector conditional on the parameter , so it is neither the prior distribution (unconditional distribution of the parameter) nor the posterior distribution (conditional distribution of the parameter given the data) used in Bayesian statistics.
