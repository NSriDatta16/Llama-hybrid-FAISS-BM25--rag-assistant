[site]: crossvalidated
[post_id]: 74394
[parent_id]: 
[tags]: 
Correct use of cross validation in LibsSVM

I am classifying data points from two different groups using LibSVM . I do the following: Creating the input file for LibSVM . In the input file, I put all the data I have. Scaling it (using svm-scale ). Using grid.py of libSVM for choosing gamma and c parameters. Using svm-train for training. I use the entire dataset. I also use the -v 10 option for 10-fold cross validation ( svm-train flag ). My questions are : a. Is the -v 10 option of cross validation can replace the testing step? b. The result given by the steps above is suspiciously high (96%), and so I'm wondering if I am doing something wrong? c. Could the use of grid.py for parameter selection before the train + cross validation damage the results (as if I were testing on data I've already trained)?
