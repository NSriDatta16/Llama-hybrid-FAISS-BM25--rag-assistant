[site]: crossvalidated
[post_id]: 103823
[parent_id]: 103755
[tags]: 
It's still not completely clear what you're doing, but it sounds like it involves comparing the coefficients of determination ($R^2$s) for regression models of different responses— individual observations & groupwise averages— & drawing conclusions about the adequacy of the first model. This makes no sense. The coefficient of determination is the ratio of the regression sum of squares to the total sum of squares † $$R^2=\frac{\sum_i (\hat y_i - \bar y)^2}{\sum_i (y_i - \bar y)^2}$$ where $y_i$ is the response for the $i$th observation. A model that changes the estimates $\hat y_i$ to be farther from the grand mean $\bar y$ increases the regression sum of squares at the expense of the residual sum of squares, thus explaining more of the variability in the response. A model that redefines every $y$ in the equation is simply incomparable. Predicting groupwise averages is a different task to predicting individual observations: & an easier one; you'd expect the lower variability in averages, & the reduced number of data points compared to estimated parameters, to result in better fit. Your example in fact illustrates the issue: regressing $B$ on $A$ gives $R^2\approx 0.7$; regressing the groupwise averages of $B$ on the grouped values of $A$ gives $R^2=1$. So there's no evidence that the model on individual observations is inadequate, & no reason to suppose that its inadequacy would be somehow hidden from the usual diagnostic methods. There are no assumptions on the distribution of predictors in regression, so knowing there are many zeroes is at most a clue to the form of model worth considering, in a particular context. For example, if you wanted to predict the ferocity of a swan ($y$) from how many cygnets it has ($x_1$), it would make sense to treat the having some / having none distinction specially— by including a dummy variable $x_2$ in the model to indicate when the count of cygnets is exactly zero: $$\operatorname {E} Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2$$ where the $\beta$s are the coefficients to be estimated. The effect is to fit the usual regression line through non-zero counts of cygnets ($x_1>0 \Rightarrow x_2=0$) $$\operatorname {E} Y = \beta_0 + \beta_1 x_1$$ & independently estimate ferocity for a zero count ($x_1=0\Rightarrow x_2=1)$ $$\operatorname {E} Y = (\beta_0 + \beta_2)$$ See How to Include an Independent Variable with one-half 0s, one-half non-0 values for a graphical illustration. † For OLS fits with an intercept.
