[site]: datascience
[post_id]: 106724
[parent_id]: 106713
[tags]: 
For the question - Why the performances of weka random forest and sklearn random forest are similar but they use different methods to compute class probabilities of an input instance? Often different algorithms will have similar results. This is not surprising. If you run the data through a GBM or logistic regression (with the proper feature engineering) you may get very similar results. At the model metric view. The data is separable. Many algorithms will find something very similar. They are all looking for the separation. The question though is where you want to use the model, how are the results. For example, the AUROC might be very similar but AUROC is no sensitive to where you want to use the model and the relative size of errors. Size of errors might be if you are predicting something with money, then being wrong on a large money transaction might be much worse then being wrong on a low money transaction. Sometimes the different algorithms might do a little better with individual observations even though the overall model metric is the same. Specific problems, such as NLP and image classification, very often work better with algorithims designed for this problem. Neural Nets with the appropriate architecture rather should be better than a RF or GBM for these problems. An interesting paper on this subject is by David J. Hand here .
