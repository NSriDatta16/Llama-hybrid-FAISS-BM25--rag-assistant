[site]: datascience
[post_id]: 31493
[parent_id]: 23969
[tags]: 
There is some recent work based on Variational Auto-Encoder in RNN models. Generating Sentences from a Continuous Space , with pytorch implementations: github code . they managed to compress the semantic, syntactic global feature of a sentence into some latent space expressed maybe with some finite 10 to 30 independent random variables (factorized distribution). the novel idea in this work, they interpolate between two sentences. and the results were quite amazing.
