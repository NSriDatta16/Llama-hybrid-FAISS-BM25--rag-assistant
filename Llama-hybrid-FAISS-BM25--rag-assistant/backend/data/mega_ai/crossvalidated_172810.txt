[site]: crossvalidated
[post_id]: 172810
[parent_id]: 
[tags]: 
Are there any new approaches to generating random examples in Combined Multiple Models (CMMs)?

A recent question got me wondering about the current state of the art in Combined Multiple Models (CMMs). I am familiar with work by Domingos in the 90s, such as this ICML paper : Domingos, Pedro. "Knowledge Acquisition from Examples Via Multiple Models." In Proceedings of the Fourteenth International Conference on Machine Learning . 1997. It describes a way to make a single C4.5 classifier from a bagged ensemble of C4.5 classifiers, and the approach requires making many randomly generated examples $\overrightarrow{x}$ from the ensemble of C4.5 rules. Has there been follow-up work on alternative methods of generating random examples? And particularly, has there been any focused on Decision Trees and Random Forests? I've searched with Google Scholar and found one promising result : Van Assche, Anneleen, and Hendrik Blockeel. "Seeing the forest through the trees: Learning a comprehensible model from an ensemble." Machine Learning: ECML 2007. Springer Berlin Heidelberg, 2007. 418-429. The acronym CMM has been hard to search for, however, so I am turning to the wisdom of CrossValidated for additional references or summarization. Thanks.
