[site]: crossvalidated
[post_id]: 562097
[parent_id]: 
[tags]: 
Is Bayesian approach best for this problem and if so, how do I calculate likelihood?

I have 5 years of solar irradiance (power) data measured at a particular location. I would like to understand whether the measured data, which very often is not accurate and has integrity issues, is coming from the same distribution as 14 years of measured data from a nearby location from a verified source. Although the data is collected at 15-minute intervals year-round, in order to make this comparison we need to aggregate the instantaneous power readings to get energy per time period. This is because January 8 AM readings don't follow the same distribution as January 3 PM readings and June 8 AM readings. It is common practice to rollup power readings and compare energy at an annual level. In this way we actually have just 5 datapoints from the test site and 14 datapoints from the verified site. Even if we were to aggregate at the monthly level, we would need to compare month-by-month (i.e. January distribution between test and verified site) and still have the same data limitation. Thus, we can't use frequentist methods and it seems we can frame this in a Bayesian way. Namely, if we calculate the posterior odds, we can avoid having to calculate the probability of the data: $$\frac{P(TargetData \cap VerifiedData | belief_0) * P(belief_0)}{P(TargetData \cap VerifiedData | belief_1) * P(belief_1)}$$ where belief 0 is that the datasets are from the same distribution and belief 1 are that they are not. If this is the correct formulation framework, then the challenge is calculating the likelihoods. Given that the data are from the same distribution, how would we estimate the probability of seeing the data from both datasets? Once we get this Bayes factor, we can make a conclusion about the strength of belief 0 over belief 1 .
