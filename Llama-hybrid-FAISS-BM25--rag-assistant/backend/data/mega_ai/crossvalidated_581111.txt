[site]: crossvalidated
[post_id]: 581111
[parent_id]: 581097
[tags]: 
To elaborate on whuber's comment, consider the case of only categorial features, which means that the distribution is a frequency vector $\vec{h}=(h_1,\ldots,h_d)$ . You can compute the Euclidean distance as suggested (your proposal of a 2D PCA projection implicitly uses Euclidean distance, because PCA approximately preserves Euclidean distances), i.e. $$d(\vec{h},\vec{g})=\sqrt{\sum_{i=1}^d (h_i-g_i)^2}=\sqrt{\langle\vec{h}-\vec{g},\vec{h}-\vec{g}\rangle}=\sqrt{(\vec{h}-\vec{g})^T(\vec{h}-\vec{g})}$$ This does, however, not take into account the distances between the levels that the components of the vector represent. Consider, e.g., the case of a color image where the components represent cells in a color space: In this case, the distance between the cell midpoints should be taken into account (how to possibly define it, is a can of worms that I do not wnat to open here). One way to take it into account is by introducing an "interaction matrix" $A$ $$d(h,g)=\sqrt{(\vec{h}-\vec{g})^T A(\vec{h}-\vec{g})}$$ While it might be possible to estimate $A$ from training data (e.g. $A=\Sigma^{-1}$ , which leads to the Mahalanobis distance), it is generally better to construct $A$ on basis of domain knowledge. The same holds for other distance measures between histograms like the "earth mover's distance" which requires a (domain specific) distance between the cells.
