[site]: datascience
[post_id]: 41398
[parent_id]: 
[tags]: 
using sklearn class weight to increase number of positive guesses in extremely unbalanced data set?

Hi I have a poorly correlated and unbalanced data set I have to work with. The set is 2 classes, 0 has 96,000 values and 1 has about 200. When I run random forest or other methods I get an output like: precision recall f1-score support 0 1.00 1.00 1.00 38300 1 1.00 0.01 0.02 90 avg / total 1.00 1.00 1.00 38390 Precision is very high but it only classified one row as positive? I tried using {class_weight = 'balanced'} in the random forest parameters and it provides: micro avg 1.00 1.00 1.00 38390 macro avg 1.00 0.51 0.51 38390 weighted avg 1.00 1.00 1.00 38390 But still not many positive guesses? Should I look into oversampling?
