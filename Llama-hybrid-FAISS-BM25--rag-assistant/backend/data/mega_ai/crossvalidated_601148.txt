[site]: crossvalidated
[post_id]: 601148
[parent_id]: 601038
[tags]: 
So I have figured out a partial answer to my question: I think it would be good to approach this from a Bayesian perspective where we have a prior over normal distributions given the second moment and then calculate the posterior over prior distribution using the likelihood of the observed sample given the model. Finally we can integrate over the posterior to get the (unnormalized) PDF of our believe distribution about what the next sample would look like. So we can parametrize our normal distribution model by the standard deviation $d$ . Given we know the second moment $s$ , the mean will be $\sqrt{s - d^2}$ . Then we can derive the Jeffreys prior like this: If I now plot the unnormalized PDF of our believes, it looks a lot like a mixture of two Gaussians: Splitting up Jeffreys prior and integrating the summands seperately seems to confirm this hypothesis: However, I have not been able to analytically verify this or compute the parameters of the mixture. If someone is able to do that I would be happy to accept that as an answer!
