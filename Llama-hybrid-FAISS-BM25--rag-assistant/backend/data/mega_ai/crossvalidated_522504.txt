[site]: crossvalidated
[post_id]: 522504
[parent_id]: 522422
[tags]: 
It sounds like you're looking for the pointwise mutual information (pmi) , which relates two events. Mutual information averages the pmi over all possible events. What this measures is whether two events tend to occur together more often you'd expect, just considering the events independently. If they occur more often than that, pmi is positive. Less often, it's negative. Conditionally independent, it's zero. $$\operatorname{pmi}(x;y) \equiv \log\frac{p(x,y)}{p(x)p(y)} = \log\frac{p(x|y)}{p(x)} = \log\frac{p(y|x)}{p(y)}$$ I'll leave to your own intuitions the sort of events that do or don't have high pmi. In the example you provide, $x$ might be the event of a cloudy sky, from a space of options $\mathcal{X} = \{\text{cloudy}, \text{not cloudy}\}$ , and $y$ might be the event of rainy weather, from a space of options $\mathcal{Y} = \{\text{rainy}, \text{snowy}, \text{hazy}, \text{sunny}\}$ . By averaging the pmi over all of these combinations, you get the mutual information.
