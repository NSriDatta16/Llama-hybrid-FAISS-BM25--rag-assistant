[site]: crossvalidated
[post_id]: 384758
[parent_id]: 
[tags]: 
Clarification: text2vec, embeddings, doc2vec

I am trying to grasp the concept of word / document embeddings; I am using R as coding language, and I try to understand the text2vec package. Are the following statements about text2vec correct? The vectorization function of the text2vec package ( http://text2vec.org/vectorization.html ) is a "normal" bag-of-word vectorization resulting in a DTM, which I also can achieve with other tools / packages in R (e.g. by means of tidytext count(), cast_dtm() ) The GloVe functionality in text2vec is the step where I create an embedding, i.e. a lower-dimensional and dense representation of my text There is no implementation of "doc2vec" in text2vec Thus, the tutorial under https://www.r-bloggers.com/twitter-sentiment-analysis-with-machine-learning-in-r-using-doc2vec-approach/ , named "Twitter sentiment analysis with Machine Learning in R using doc2vec approach" is misleading, because it uses the vectorization function of text2vec, but no doc2vec. Neither does it use an embedding. Is my understanding here correct? Thank you very much :)
