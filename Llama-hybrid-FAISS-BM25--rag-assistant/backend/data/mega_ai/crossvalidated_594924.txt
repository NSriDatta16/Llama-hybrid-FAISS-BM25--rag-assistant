[site]: crossvalidated
[post_id]: 594924
[parent_id]: 
[tags]: 
Fisher information for predictions

Assume I have a model (linear regression, neural network, etc) in the form $g(\theta)$ and I assume that my data is generated according to $f(x; g(\theta))$ (eg $f$ is the pdf of a normal Gaussian random variable and I am parametrizing the mean $g(\theta)$ with my model). I then optimize my model by maximizing the log likelihood $\log f(g(\theta); x)$ . In this example we can assume $\theta \in \mathbb R^n, g: \mathbb R^n \to \mathbb R^m$ I would like to get a confidence interval on the predictions of the model $g(\theta)$ using the fisher information. However, I am a bit confused on how to go about that exactly: If I compute the fisher information wrt to $g(\theta)$ , which is what actually determines the pdf, I obtain an interesting statistics (how much information about each parameter of the pdf (eg the mean) is in the data) but this does not depend on the model, so I cannot use it as a measure of how confident we are in a specific prediction $g(\theta)$ I can compute the fisher information wrt to $\theta$ , the parameters of the model, but then I have confidence intervals on the parameters, not on the predictions, and I care about the confidence intervals on the prediction $g(\theta)$ . I could at that point vary the parameters across a specified confidence interval (e.g. $\pm 1.96 \cdot \text {fisher information}$ ) and see what happens to $g(\theta)$ , but that would probably be inaccurate (probably does not guarantee a 95% confidence interval) and more than that, it's too expensive (exponential in $n$ ). Can you clarify how I should proceed? Links to resources are appreciated!
