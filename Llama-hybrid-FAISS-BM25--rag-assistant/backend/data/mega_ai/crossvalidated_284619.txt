[site]: crossvalidated
[post_id]: 284619
[parent_id]: 20523
[tags]: 
They are very similar. In both models, the probability that $Y=1$ given $X$ can be seen as the probability that a random hidden variable $S$ (with a certain fixed distribution) is below a certain threshold that depends linearly on $X$ : $$P(Y=1|X)=P(S Or equivalently : $$P(Y=1|X)=P(\beta X-S>0)$$ Then it's all a matter of what you choose for the distribution of $S$ : in logistic regression, $S$ has a logistic distribution. in probit regression, $S$ has a normal distribution. Variance is unimportant since it is automatically compensated by multiplying $\beta$ by a constant. Mean is unimportant as well if you use an intercept. This can be seen as a threshold effect. Some invisible outcome $E=\beta X-S$ is a linear function of $X$ with some noise $-S$ added like in linear regression, and we get a 0/1 outcome by saying: when $E>0$, outcome is $Y=1$ when $E The differences between logistic and probit lies in the difference between the logistic and the normal distributions. There ain't that much. Once adjusted, they look like it : Logistic has heavier tail. This may impact a little how events of small ( 99%) probability are fitted. Practically, the difference is not even noticeable in most situations : logit and probit predict essentially the same thing. See http://scholarworks.rit.edu/cgi/viewcontent.cgi?article=2237&context=article "Philosophically", logistic regression can be justified by being equivalent to the principle of maximum entropy : http://www.win-vector.com/blog/2011/09/the-equivalence-of-logistic-regression-and-maximum-entropy-models/ In terms of calculation : logistic is simpler since the cumulative distribution of the logistic distribution has a closed formula unlike the normal distribution. But normal distributions have good properties when you go to multi-dimensional, this is why probit is often preferred in advanced cases.
