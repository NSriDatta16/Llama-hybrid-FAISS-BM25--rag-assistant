[site]: datascience
[post_id]: 47263
[parent_id]: 
[tags]: 
Validation vs. test vs. training accuracy. Which one should I compare for claiming overfit?

I have read on the several answers here and on the Internet that cross-validation helps to indicate that if the model will generalize well or not and about overfitting. But I am confused that which two accuracies/errors amoung test/training/validation should I compare to be able to see if the model is overfitting or not? For example: I divide my data for 70% training and 30% test. When I get to run 10 fold cross-validation, I get 10 accuracies that I can take the average/mean of. should I call this mean as validation accuracy ? Afterward, I test the model on 30% test data and get Test Accuracy . In this case, what will be training accuracy ? And which two accuracies should I compare to see if the model is overfitting or not?
