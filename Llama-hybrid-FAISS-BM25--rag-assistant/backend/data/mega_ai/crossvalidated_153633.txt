[site]: crossvalidated
[post_id]: 153633
[parent_id]: 99346
[tags]: 
While it looks generally wise to require closer investigation of the data, the authors overlooked important facts that weaken their argumentation. I'll show these fact on the illustrational examples they provide. 1) The first is about the possible interaction of child's sex and health status to "grief" (about the child's death?). This is --as often in psychometrics-- measured on an ordinal, not metric scale. So it is not allowed do calculate differences in grief. (What should if be after all? How far you are bowed down to the floor with grief?) This eradicates a major requisite of the author's argumentation, namely the decomposition of the effects into interaction and main effect by taking differences of the means (also not appropriate in ordinal analysis). In the end, for such an ordinal layout, all you can say is in fact "healthy male > healthy female > sick female > sick male". This is in conjunction to a noteworthiness of the term "interaction" in such settings, and another flaw both of the authors and those they criticize. Namely, the only way to prove an $2\times 2$ ordinal interaction to be significant would be a X shaped interaction plot. (Like in Figure 1 in the paper). Why? Assume a " So an ordinal interaction would have been "healthy male >= sick female > healthy female >= sick male". This X-shaped pattern cannot be destroyed by monotonically rescaling the (arbitrary) ordinal scaling of "grief". 2) Concerning the second example, there is a totally different flaw. This example considers something metric, namly the numbers of hits of baseball players, who were subjected to $2\times 2$ possibly interacting conditions. Now it is OK to calculate differences in hits, and a decomposition into main effect and interaction effect is allowed. But is it unique? We can never tell. Consider Table 6: a0 a1 b0 b1 b0 b1 group mean 3 3 5 7 row effect -1.5 -1.5 1.5 1.5 column effect -0.5 0.5 -0.5 0.5 grand mean 4.5 interaction +0.5 -0.5 -0.5 +0.5 What makes the authors believe that -1.5 is an unbiased estimator of the row effect of a0 and 1.5 of a1 ? They chose these values analogously to least squares estimation, but LSE can only estimate the expected value. It cannot tell us how to decompose unknown parameters into even more unknown summands. And we are interested in these unkown summands! Why is there a colum effect of +/-0.5 between a0b0 and a0b1 if both cell values are exactly the same? It is because of the other cells. That means, due to completely different baseball players, namly those under condition a1 , we conclude that if we would treat a player of group a0 with condition b1 instead of b0 , he would hit once more per game? Although in group a0 no difference between condition b1 and b0 has been observed? Can this be true? Or is it simply a statistical mirage? The statistical background of this phenomenon has been discovered by Rao (1962) and is called estimability . It can be shown that in this simple $2\times2$ layout with all four interaction effects, main effects are not estimable, that means they depend on something arbitrary. That causes this mirage. The main effect estimators can only become unique if we remove the interactions from the model. So Rosnow and Rosenthal want to compare terms that are simply not present at the same time. This error leads also to the erroneous conclusion that significant interactions are always X-shaped. But they are not completely wrong: If you don't find a significant interaction in ANOVA and want to start considering only the main effects, one should have in mind that a type-II-error could have occured, and that there is in fact an interaction that biases the estimation and tests of the main effects. So an interaction plot with confidence intervals would be a good idea, as it also sheds more light on the effects themselves.
