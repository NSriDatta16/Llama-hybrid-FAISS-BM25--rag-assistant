[site]: crossvalidated
[post_id]: 262717
[parent_id]: 262544
[tags]: 
First of all, you have lots of interactions in play here, so it is very likely highly misleading to just do simple marginal comparisons. That said, the summary results are actually a sequential anova table, with terms entered in the order shown in the rows of the table. You might want to try library("car") Anova(Duration1) # note the capital "A" in "Anova" Each test in this table is conditional on all other terms in the model that do not contain the one in question. Second, I am still concerned that you get the model right before proceeding to post-hoc stuff. Many people try to find the shortest route to a P value and -- in the process -- base their inferences on a model that doesn't fit the data. If that's the case here, then that's another way to be doing meaningless things. Did you do any residual plots? Did you explore whether the linear trend in Temperature is reasonable? More specifics on these matters... It is sometimes the case that a response transformation will improve the residual distribution and also remove or reduce interactions. Your response is measured on a ratio scale, and it may be that a log or square root or even a reciprocal makes for a better-fitting model. Changing the model so that Temperature is replaced by poly(Temperature, 2) or poly(temperature, 3) would make it possible to see if the quadratic or cubic effects are needed. Also, since Size is a factor, I hope you coded it as a factor in your model even though it has only two levels. That doesn't change the anova at all, but it makes the results easier to interpret. In what follows, I am assuming that Size is of class "factor" . With two factors and a covariate involved, perhaps TukeyHSD can be made to work right, but I will instead shamelessly suggest using my lsmeans package, which is designed for multi-factor situations. LS means are the model's predictions over a regular grid of factor combinations, or marginal averages thereof. See the documentation for details. First off, get an idea visually of what is going on. This can be done with an interaction-plot-style display: library("lsmeans") lsmip(Duration1, Stage ~ Temperature | Size, at = list(Temperature = c(15, 20, 25, 30)) ) You'll see the temperature trend for each stage and size. Since there are interactions, these lines will be of different slopes. If there is, however, some regularity among these slopes, it may be reasonable to ignore some of the interactions even though they are statistically significant. (Also, if larger predictions tend to differ more than smaller predictions, that's a situation that shows some hope of being ameliorated by a response transformation.) If the lines go all over the place, then you can't ignore the interactions. You might also want to look at other plots (e.g., with Temperature ~ Stage | Size ) to get different perspectives. Now, to compare sizes or stages, we should (probably) do that separately for each combination of the other two factors. For example: Size.lsm = lsmeans(Duration1, "Size", by = c("Temperature", "Stage"), at = list(Temperature = c(15, 20, 25, 30)) ) Size.lsm contrast(Size.lsm, "pairwise") # or just pairs(Size.lsm) From the above, you'll actually get 28 tables of means, and 28 tables of comparisons. [Do test(pairs(Size.lsm), by = NULL, adjust = "mvt") to get one table with all 28 comparisons and a multi-variate $t$ adjustment for the 28 tests.] You could do pairwise comparisons of the 4 temperatures in an analogous way. However, since this is a quantitative factor, you could just estimate and compare the slopes of the lines in the plot produced earlier, like this: Temp.lst = lstrends(Duration1, "Stage", by = "Size", var = "Temperature") Temp.lst pairs(Temp.lst) pairs(Temp.lst, by = "Stage") # compares the two sizes at each stage This is long-winded, but I hope it gives you an idea of how you might proceed. Again, get the model right first before proceeding to any of the post-hoc analyses.
