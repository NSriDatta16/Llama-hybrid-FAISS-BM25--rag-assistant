[site]: datascience
[post_id]: 26954
[parent_id]: 26926
[tags]: 
This is an optimization problem and optimization is all what Machine Learning does in classic sense (mostly not unsupervised approaches). Your problem can be designed to be solved by Genetic Algorithms. For this you need to make a sequences of ingrediants which is called chromosome (genetic representation of solution) and an objective function which is to be minimized/maximized according to the chromosomes (it's usually called fitness function and is to be maximized then). You have genetic operators to be applied randomly on your chromosomes: Reproduction : 2 parent chromosomes result in two children. Mutation : One single bit (one of ingrediants) is randomly chosen to be switched with another one (like in a genetically normal family, a baby is born with a genetic phenomenon). Natural Selection : Uncle Darwin believed that nature "keeps the best and discards the rest". But who is the best? Well, you already have a fitness function! Continue till you reach the optimum and select the best chromosome. Of course it was the intuitive explanation of this beautiful idea. See more here and if you needed implementation details please drop a comment here. Good Luck. Update: More Details I have an optimization problem which is too complex or large to be solved analytically so I need a heuristic method to approximate the optimal solution. For instance each subset of $28$ ingredients outputs a result $y$ where $y \in [0,100]$ (it's much bigger than your sample problem just to use optimization properly). Initialization: Randomly produce $n$ combinations of material as initial population. Choose probabilities $P_{crossover}=0.25$ , $P_{mutation}=0.01$ and $n_{selection}=250$ (values are just examples) Evaluation of Fitness: Evaluate the output for each of them | input | output | ------------- |:-------------:| | ABCDEFGH | 23.5 | | BDCGTRFJ | 45.6 | | ZHTRFGOIUPOIZ | 18.3 | | ... | ... | Choose top $n_{selection}$ and ignore the rest. If you found an optimal solution (in your case you said output=3 is desired) stop, if not: According to $P_{crossover}$ choose 25% of survived samples and reproduce children by combining them through a breaking point (image from here ). For instance if $ABCDEFGH$ and $BCDEFGHJ$ are survived, then choose a breaking point and exchange their parts (the image is 2-point crossover. You may apply 1-point crossover. It's all about the variations of the same concept). Technically the crossover point should be also determined probabilistically but I just skipped it. Break them from wherever you want! Here we choose $3^{rd}$ gene for this so $ABCDEFGH$ and $BCDEFGHJ$ will become $ABDEFGHJ$ and $BCCDEFGH$ . Two children out of two parents. Apply it on all chosen survived samples. According to $P_{mutation}$ choose 1% of survived samples and randomly(again, technically with a predefined probability) change one material in it (technically the samples are usually binary so you flip between $0$ and $1$ . Here as you have nominal variables you need to change the variable). Let's say in survived sample $FVBGTZHU$ I randomly choose $V$ and exchange it with $P$ so I get $FPBGTZHU$ . Now the new generation is born (keep it as the same size of the original population for better structure). Go back to 2 and continue till you find your answer. For different variations of GA (Elitism, Island Model, etc.) see the literature for Evolutionary Algorithms e.g. this one . Hope it helps!
