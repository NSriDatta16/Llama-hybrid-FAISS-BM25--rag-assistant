[site]: crossvalidated
[post_id]: 366518
[parent_id]: 
[tags]: 
Sample size for comparing two properties of time series data

I have a dataset of observations of two properties of an object ( x and y ), which are distributed over time, t : | t | x | y | ------------------------- | 1 | 5 | A | | 1 | 4 | A | | 1 | 5 | A | | 1 | 6 | B | | 1 | 10 | A | | 2 | 3 | A | | 2 | 7 | A | | 2 | 2 | A | | 2 | 8 | B | | 2 | 9 | A | This is just an example to show the structure of the dataset. In reality the dataset consists of several million rows. For each timestep t there are around 1000 observations of x and y . Importantly , within each timestep there is only one observation where y = B , the other observations all have y = A . I want to compare the average value of x over the entire timeseries for y = B against values of x where y = A . However, for practical reasons it is not possible to retrieve all the values where y = A , so for each timestep I need to take a sample for comparison. My question is therefore, how do I calculate the sample size to take at each timestep t to make a comparison? Or should the sample size be the same (i.e. 1 datapoint at each timestep t ). A second question would be, how would this vary if we had several values of y within each timestep (but not the same amount in each timestep). Thanks for any help or pointers in the right direction!
