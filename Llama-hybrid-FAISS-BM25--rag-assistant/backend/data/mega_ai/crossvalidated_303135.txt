[site]: crossvalidated
[post_id]: 303135
[parent_id]: 
[tags]: 
the proof of Markov chain recurrent state in the book Neural Networks and Learning Machines

It's about the definition of a recurrent state. I think there might be something wrong in this book. it is said as following. Suppose a Markov chain starts in state i. State i is said to be a recurrent state if the Markov chain returns to state i with probability 1; that is, pi =P(ever returning to state i) =1 If the probability pi is less than 1, state iis said to be a transientstate (Leon-Garcia, 1994). If the Markov chain starts in a recurrent state, that state reoccurs an infinite number of times. If it starts in a transient state, that state reoccurs only a finite number of times, which may be explained as follows: We may view the reoccurrence of state i as a Bernoulli trial with a probability of success equal to pi .The number of returns is thus a geometric random variable with a mean of (1 - 1/pi). If pi You can see those italics. I can't figure out what kind of the Bernoulli trail it is. Why it has a mean of (1 - 1/pi), which indicates that when pi
