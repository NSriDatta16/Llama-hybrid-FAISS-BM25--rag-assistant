[site]: crossvalidated
[post_id]: 384583
[parent_id]: 
[tags]: 
In-sample evaluation with different classifiers

I've tested in-sample evaluation with different classifiers (Decision trees, Random Forests, Gaussian Naive Bayes) within sklearn and Iris datasets. import sklearn.datasets as datasets import pandas as pd from sklearn.tree import DecisionTreeClassifier from sklearn.naive_bayes import GaussianNB from sklearn.ensemble import RandomForestClassifier iris=datasets.load_iris() df=pd.DataFrame(iris.data, columns=iris.feature_names) y=iris.target First with decision trees, I get 100% accuracy clf=DecisionTreeClassifier() clf.fit(df,y) print(str(clf.score(df, y))) For other classifiers, the score is strictly lower than 100% For example within Random forests I have: clf = GaussianNB() clf.fit(df,y) print(str(clf.score(df, y))) In [47]: 0.96 With RandomForestClassifier, the score is 98%. It's also the case with other classifiers such as KNeighbors. My question: Is there a theoretical reason for which decision trees give a 100% accuracy score for in-sample evaluations, and why the other classifiers do not ? In other words, is there a case where decision trees can have an accuracy score strictly lower than 100% for in-sample evaluation ? Thanks a lot.
