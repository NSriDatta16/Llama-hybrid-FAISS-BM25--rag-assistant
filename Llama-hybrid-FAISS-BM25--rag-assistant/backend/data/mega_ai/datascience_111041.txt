[site]: datascience
[post_id]: 111041
[parent_id]: 111025
[tags]: 
MAE gives the mean error value across all the test instances, while MSE squares the error value before taking the mean. This has the effect of making large errors penalized more strongly with MSE than with MAE. Example: let's say that 4 instances have error 3, 4, 1, 5 MAE = 13/4 = 3.25 MSE = 51/4 = 12.75 Now suppose we add an instance with error 20: MAE = 33/5=6.6 MSE = 451/5=90.2 Note that the MAE doubles, but the MSE is 7 times higher because the large error has more effect. In your example, one could say that M1 is better than M2 in average but M2 is better than M1 about minimizing the largest errors (although not by much).
