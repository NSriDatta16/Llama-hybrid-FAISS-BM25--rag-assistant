[site]: datascience
[post_id]: 103360
[parent_id]: 60466
[tags]: 
Regarding your first question, no your dataset is not small to give you bad results, although adding more data would definitely help. I have worked with smaller datasets than yours. The answer to your second question depends on weather you have performed feature selection/engineering. Usually the best type of feature selection is with the help of domain knowledge/expertise. Statistical feature selection techniques may or may not be accurate so it is usually advised to first use domain knowledge to eliminate features. If the performance does not improve then only use other techniques, albeit with a pinch of salt. What you can do is remove the product id feature as id's usually do not contribute much to the model other than increasing the dimension. (I don't know what domain you are working on but if you think that product id's are important and help in predicting the target, then by all means keep the feature.) Other than that, there are many things you can do to improve your model, some of which are (first of all create a baseline model where you do not perform feature selection and hyperparameter tuning. This will help you get a base score to compare to):- 1.) Use domain knowledge for feature engineering and see if you can reduce the dimensions by combining 2 or more numerical features into 1. 2.) Use domain knowledge for feature selection and if that doesn't help, use other feature selection techniques. 3.) Hyperparameter tuning 4.) Try different models 5.) Add more data One or more of these things is absolutely going to help you in building a better model. Remember, model building is an iterative process and you have to keep trying different things in order to get the best possible model. Don't try a couple things and come to the conclusion that the model is not the best one. Best of luck!
