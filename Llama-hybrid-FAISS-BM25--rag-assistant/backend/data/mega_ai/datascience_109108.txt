[site]: datascience
[post_id]: 109108
[parent_id]: 109085
[tags]: 
you actually need to reduce the size of your embedding. Use a nonlinear dimensionality reduction algorithm such as LLE, UMAP or using an Autoencoder and reduce the size of Word2Vec from $n$ to $m$ . Choosing $m$ is done through a simple hyperparametr tuning for your model
