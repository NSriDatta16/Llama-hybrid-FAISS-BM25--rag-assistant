[site]: datascience
[post_id]: 14129
[parent_id]: 14122
[tags]: 
We cannot go directly from input layer to max pooling because of the convolution layer in between. The reason for convolution is to extract features. Max pooling down-samples the features that have been extracted. If you think there are features which are missing because of the direct jump from a large matrix to a max pooling layer, you can add more layers of convolution in between till you seem satisfied with a size and then do max pooling onto it so that it is not an overkill. Max pooling, which is a form of down-sampling is used to identify the most important features. But average pooling and various other techniques can also be used. I normally work with text and not images. For me, the values are not normally all same. But if they are too, it wouldn't make much difference because it just picks the largest value. A very good understanding from wiki - The intuition is that once a feature has been found, its exact location isn't as important as its rough location relative to other features. The function of the pooling layer is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. It is common to periodically insert a pooling layer in-between successive conv layers in a CNN architecture. The pooling operation provides a form of translation invariance.
