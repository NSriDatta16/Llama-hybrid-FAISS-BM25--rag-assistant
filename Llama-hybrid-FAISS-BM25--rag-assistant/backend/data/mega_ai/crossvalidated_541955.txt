[site]: crossvalidated
[post_id]: 541955
[parent_id]: 
[tags]: 
Interpreting lagged IVs in simple linear regression?

If we have dependent variable y and independent variable x (where x and y are measured in the same month for each data pair, and represent month over month financial returns), running a simple linear regression tells us what happens when x moves by, say, 1%. If we assume a regression coefficient of 2, this means for every 1% increase in x, y will increase by 2%. Implied above, assume x and y are both time series data, measured monthly. How does the above interpretation change if we run a regression between x measured in month i and y in month i+1?
