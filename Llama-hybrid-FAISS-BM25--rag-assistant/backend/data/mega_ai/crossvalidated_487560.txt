[site]: crossvalidated
[post_id]: 487560
[parent_id]: 
[tags]: 
Can a machine learning model be trained to not be optimal?

I am thinking about AI bots in strategy games, let's say chess. The concept to train a model to choose always the movement most likely to end in victory is intuitive, even if it is not easy to implement. How can we train a model to be suboptimal, and let the human player choose difficulty settings? A badly implemented model could work as an easy settings, but butchering the training set doesn't seem right.
