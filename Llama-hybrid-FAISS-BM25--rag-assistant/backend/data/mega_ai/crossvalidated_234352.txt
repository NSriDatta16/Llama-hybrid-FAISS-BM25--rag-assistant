[site]: crossvalidated
[post_id]: 234352
[parent_id]: 232727
[tags]: 
{1} explored one way to take prior knowledge on features into account when training a neural network. Abstract: Different features have different relevance to a particular learning problem. Some features are less relevant; while some very important. Instead of selecting the most relevant features using feature selection, an algorithm can be given this knowledge of feature importance based on expert opinion or prior learning. Learning can be faster and more accurate if learners take feature importance into account. Correlation aided Neural Networks (CANN) is presented which is such an algorithm. CANN treats feature importance as the correlation coefficient between the target attribute and the features. CANN modifies normal feedforward Neural Network to fit both correlation values and training data . Empirical evaluation shows that CANN is faster and more accurate than applying the two step approach of feature selection and then using normal learning algorithms. I didn't read the paper carefully, I am unsure how sound it is, and I'd be quite cautious. The same author published a few other papers on the same topic, e.g. {2}. Personally I rely on backpropagation to do the job. Perhaps another way could be to change the weigh update rule and/or weight initialization rule for this feature, so as to bias the weights connected to your important feature to have an absolute value larger than the other weights connected to the other features. A last idea would be to connect your most important feature to layers other than the first layer. {1} Iqbal, Ridwan Al. "Using Feature Weights to Improve Performance of Neural Networks." arXiv preprint arXiv:1101.4918 (2011). https://scholar.google.com/scholar?cluster=15075021269543299652&hl=en&as_sdt=0,22 ; http://arxiv.org/abs/1101.4918 {2} Al Iqbal, Ridwan. "Empirical learning aided by weak domain knowledge in the form of feature importance." In Multimedia and Signal Processing (CMSP), 2011 International Conference on, vol. 1, pp. 126-130. IEEE, 2011. https://scholar.google.com/scholar?cluster=13856845400679996300&hl=en&as_sdt=0,22 ; http://arxiv.org/abs/1005.5556
