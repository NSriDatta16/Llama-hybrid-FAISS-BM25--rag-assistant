[site]: datascience
[post_id]: 94067
[parent_id]: 
[tags]: 
Machine Learning - Euclidian Distance Classifier exercise

I'm taking part in an elective subject at university which mainly focuses on the foundations of Machine Learning. Now we got our first exercise - this task should be done practically in any language (I've chosen Python). Our teacher doesn't explain the relations between theory and practice well and so it's hard for all of us to follow along - so I decided to post this question here. I don't want anyone to give me a solution, I just don't understand what he wants and may be a hint how to approach this question.: Here is the full exercise: Euclidean distance classifier Develop an Euclidian distance classifier as below: Generate 1000 random points corresponding to each class out of 3 classes with feature size 2 for a 3-class classification problem. For the simplicity consider the classes following N([0 1 2], I), N([0 0 1], I) and N([1 0 0],I) respectively. Generate the output an 1000-dimensional vector whose ith component contains the class where the corresponding vector is assigned, according to the minimum Euclidean distance classifier. I understand that I should generate random points with two features which are belonging to one of the three classes - okay. But I don't get the second part of the sentence. The classes are normally distributes with a mean(?)-vector of [0, 1, 2], [0, 0, 1] and [1, 0, 0]? For what does the second paramter I stand in the normal distribution Does the vector stand for the position/mean of the multivariate normal distribution? How would you approach this question? Using a k nearest neighbor algorithm? Thanks for any helpful answers! Max
