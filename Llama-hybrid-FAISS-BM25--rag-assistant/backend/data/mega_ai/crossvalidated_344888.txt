[site]: crossvalidated
[post_id]: 344888
[parent_id]: 344884
[tags]: 
Using neural networks, unsupervised learning is typically done via autoencoders . In a super simple words: An autoencoder is a neural network that takes an input vector and outputs the same vector at the end. It may look like this (image from [1] ): That does not sound very useful: Any network realizing an identity mapping does that. The interesting part is that the network has to "encode" the input first and then reconstruct it from the encoded version, ideally preserving as much information as possible. This way the network can learn to extract useful information about the data without needing any labels. There are different types of autoencoders, varying in the way they ensure the resulting encoding is useful. The simplest autoencoders rely on a bottleneck (e.g. like in the above image), where the encoded representation of input has lower dimension than the original input. Other options include denoising autoencoders and contractive autoencoders . As far as I am aware, neural networks themselves are not being used for clustering. However, it is possible to use autoencoders to encode the data into some low-dimensional or sparse representation and use any common clustering algorithm to cluster data in this domain.
