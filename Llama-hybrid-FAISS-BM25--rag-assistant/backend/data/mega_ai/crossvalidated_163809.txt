[site]: crossvalidated
[post_id]: 163809
[parent_id]: 162569
[tags]: 
You could try non-hierarchical partitioning. If you're willing to play in R, you could try package optpart. You'll find a variation of k-means, pam (see Kaufman & Rousseeuw, 1990), as well as two methods of non-hierarchical partitioning, OPTPART and OPTSIL , available. http://cran.r-project.org/web/packages/optpart/optpart.pdf . Functions silhouette and stride additionally help you decide on the proper number of partitions. These methods can potentially be used (with some modification) for hierarchical clustering methods as well. A final method to look into is ISODATA (though I admittedly know little about it) I don't think Dave Roberts has extended OPTPART in any way to Python, but I'm sure some version of pam can be utilized in python with little to no effort. OPTPART usually creates the best partitions for me, so it might be worth looking into. In the end, I'm not sure these methods will necessarily help you any better but, at the very least, they'll provide you with a handful of additional (often overlooked) clustering methods to try. Hope this helps!
