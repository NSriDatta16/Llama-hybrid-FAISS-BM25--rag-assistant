[site]: datascience
[post_id]: 118598
[parent_id]: 
[tags]: 
Theory behind time Series Test dataset being the last x%

The standard flow for time-series that i'm aware of, is that you divide your dataset for Training & Validation (60% and 20% respectively for example) and the last 20% is used for Unbiased Testing. Percentages aside, is there benefit in having the Testing being split into 2 chunks? for example 10% in the middle 10% in the end. Or just using the 20% middle. Any simple theory references to check would also be appreciated.
