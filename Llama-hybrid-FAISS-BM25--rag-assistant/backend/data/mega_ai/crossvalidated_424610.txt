[site]: crossvalidated
[post_id]: 424610
[parent_id]: 421935
[tags]: 
Where are people getting the key, query, and value from these equations? The paper you refer to does not use such terminology as "key", "query", or "value", so it is not clear what you mean in here. There is no single definition of "attention" for neural networks, so my guess is that you confused two definitions from different papers. In the paper, the attention module has weights $\alpha$ and the values to be weighted $h$ , where the weights are derived from the recurrent neural network outputs, as described by the equations you quoted, and on the figure from the paper reproduced below. Similar thing happens in the Transformer model from the Attention is all you need paper by Vaswani et al , where they do use "keys", "querys", and "values" ( $Q$ , $K$ , $V$ ). Vaswani et al define the attention cell differently : $$ \mathrm{Attention}(Q, K, V) = \mathrm{softmax}\Big(\frac{QK^T}{\sqrt{d_k}}\Big)V $$ What they also use is multi-head attention, where instead of a single value for each $Q$ , $K$ , $V$ , they provide multiple such values. Where in the Transformer model, the $Q$ , $K$ , $V$ values can either come from the same inputs in the encoder (bottom part of the figure below), or from different sources in the decoder (upper right part of the figure). This part is crucial for using this model in translation tasks. In both papers, as described, the values that come as input to the attention layers are calculated from the outputs of the preceding layers of the network. Both paper define different ways of obtaining those values, since they use different definition of attention layer.
