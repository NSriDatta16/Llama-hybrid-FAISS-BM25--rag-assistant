[site]: datascience
[post_id]: 76296
[parent_id]: 
[tags]: 
XGBoost model performance barely budging, and max_depth is basically irrelevant

I have a dataset that includes 62 features and around 1 million observations. The 62 features are mostly socioeconomic status indicators for students as they start a school year. The labels are the students grade in the next school year. My goal is to help identify students at the beginning of the year who will perform poorly, and then give them access to additional resources to prevent poor grades. More specifically, my goal is to properly predict which students will be in the bottom 3%ile of grades in coming school year. The magnitude of errors is important - if I predict a student will be in the bottom 3% and the student ends up being an A+ student, that is very costly to me. For this reason, I tried making an XGBoost regression (since classification doesn't punish wildly wrong answers). However, my results so far have been disappointing. My features are either percentile data (continuous from 0 to 1) or binary. My labels are percentile data (continuous from zero 1). It seems that no matter which hyperparameters I adjust, the RMSE starts at 0.28 and barely budges from there. Here is the model with output for max_depth = 1. #Regression Model params = { 'tree_method' : 'exact', 'min_split_loss':5, 'colsample_bynode':0.5, 'reg_lambda':20, 'reg_alpha':100, 'subsample':0.5, 'learning_rate': 0.3, 'max_depth':1, 'objective': 'reg:squarederror', 'verbosity':0, } watchlist = [(train, 'train'), (test, 'val')] reg = xgb.train(params, train, num_boost_round=100, early_stopping_rounds=3, evals=watchlist) [0] train-rmse:0.281513 val-rmse:0.28249 Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping. Will train until val-rmse hasn't improved in 3 rounds. [1] train-rmse:0.281126 val-rmse:0.282324 [2] train-rmse:0.280893 val-rmse:0.282113 [3] train-rmse:0.280809 val-rmse:0.281991 [4] train-rmse:0.280657 val-rmse:0.281931 [5] train-rmse:0.280601 val-rmse:0.281875 [6] train-rmse:0.280551 val-rmse:0.281833 [7] train-rmse:0.280432 val-rmse:0.281818 [8] train-rmse:0.28036 val-rmse:0.28174 [9] train-rmse:0.28033 val-rmse:0.281737 [10] train-rmse:0.280312 val-rmse:0.281732 [11] train-rmse:0.280273 val-rmse:0.281694 [12] train-rmse:0.280262 val-rmse:0.281682 [13] train-rmse:0.280207 val-rmse:0.28168 [14] train-rmse:0.280184 val-rmse:0.281649 [15] train-rmse:0.28017 val-rmse:0.281634 [16] train-rmse:0.280159 val-rmse:0.281638 [17] train-rmse:0.280128 val-rmse:0.281641 [18] train-rmse:0.280114 val-rmse:0.281637 Stopping. Best iteration: [15] train-rmse:0.28017 val-rmse:0.281634 And here is the output when I increase to max_depth = 6: [0] train-rmse:0.281331 val-rmse:0.282431 Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping. Will train until val-rmse hasn't improved in 3 rounds. [1] train-rmse:0.280839 val-rmse:0.282097 [2] train-rmse:0.280446 val-rmse:0.281867 [3] train-rmse:0.280329 val-rmse:0.281756 [4] train-rmse:0.280185 val-rmse:0.281703 [5] train-rmse:0.280153 val-rmse:0.281693 [6] train-rmse:0.280151 val-rmse:0.281695 [7] train-rmse:0.280106 val-rmse:0.281692 [8] train-rmse:0.280081 val-rmse:0.28167 [9] train-rmse:0.280081 val-rmse:0.281671 [10] train-rmse:0.28008 val-rmse:0.281672 [11] train-rmse:0.280062 val-rmse:0.281654 [12] train-rmse:0.280062 val-rmse:0.281654 [13] train-rmse:0.280025 val-rmse:0.281638 [14] train-rmse:0.280025 val-rmse:0.281638 [15] train-rmse:0.280025 val-rmse:0.281638 [16] train-rmse:0.280014 val-rmse:0.281642 Stopping. Best iteration: [13] train-rmse:0.280025 val-rmse:0.281638 It doesn't make sense to me that a max_depth of 1 yields virtually the same results as max_depth = 6, when I have 62 features... Also the RMSE at 0.28 isn't much better than just random, which would be around 0.4. I feel like there is something blatantly wrong given max_depth is essentially irrelevant. Does anyone have some advice to improve the performance? Or perhaps a different machine learning technique rather than regression?
