[site]: datascience
[post_id]: 78069
[parent_id]: 
[tags]: 
Any useful tips on transfer learning for a text classification task

I am doing a supervised binary text classification task. I want to classify the texts from site A, site B, and site C. The in-domain performance looks OK for texts of each site. (92%-94% accuracy). However, if I applied the model trained on texts of one site directly onto texts of another site(without fine-tuning), the performance downgrades a lot. (7%-16% downgrade for accuracy). Approaches I already tried: Doc2vec embedding(trained on texts from one site) + logistic regression. Bert embedding + logistic regression. (Using bert-as-a-service to generate the embeddings based on google pre-trained bert models). TF-IDF + logistic regression. Pre-trained Word2vec embedding(average word embedding for text) + logistic regression. All of those approaches don't work very well. I knew that the performance downgrade is unavoidable, but I would like to get a maybe 3% - 5% downgrade.
