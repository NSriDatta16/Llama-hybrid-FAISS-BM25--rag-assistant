[site]: crossvalidated
[post_id]: 623386
[parent_id]: 564146
[tags]: 
There is a case to be made for using data augmentation on the validation set, as using several copies of the same validation example with different augmentations and averaging their outputs effectively is a type of ensemble method, and ensemble methods in general tend to lead to better performance. This practice is known as test-time augmentation, and was among others used in the original Alexnet paper : At test time, the network makes a prediction by extracting five 224 × 224 patches (the four corner patches and the center patch) as well as their horizontal reflections (hence ten patches in all), and averaging the predictions made by the network’s softmax layer on the ten patches. A clue to why this works is given in the paper Making Convolutional Networks Shift-Invariant Again , in which they show that the output likelihood for the correct class can vary wildly as a function of a shift of the image. When the specific shift gives rise to a low output likelihood, the loss can become very high (especially since it's not linear to the likelihood but logarithmic to it), and it becomes significantly more probable that an incorrect class is predicted. For that reason, it would probably make sense to take several shifts of the image, feed all of them to the network, and take the average of the outputs for the different shifts (even though what they're doing in the paper is probably smarter), which would be a kind of test-time augmentation. The technique has also been covered by Jason Brownlee here and here .
