[site]: crossvalidated
[post_id]: 10417
[parent_id]: 10356
[tags]: 
There are many ways in which you can think of logistic regressions. My favorite way is to think that your response variable, $y_i$, follows a Bernoulli distribution with probability $p_i$. An $p_i$, in turn, is a function of some predictors. More formally: $$y_i \sim \text{Bernoulli}(p_i)$$ $$p_i = \text{logit}^{-1}(a + b_1x_1 + ... +b_nx_n)$$ where $\text{logit}^{-1} = \frac{\exp(X)}{1+\exp(x)}$ Now does it matter it you have low proportion of failures (bad accounts)? Not really, as long as your sample data is balanced, as some people already pointed. However, if your data is not balanced, then getting more data may be almost useless if there is some selection effects you are not taking into account. In this case, you should use matching, but the lack of balance may turn matching pretty useless. Another strategy is trying to find a natural experiment, so you can use instrumental variable or regression disconinuity design. Last, but not least, if you have a balanced sample or there is no selection bias, you may be worried with the fact the bad account is rare. I don't think 5% is rare, but just in case, take a look at the paper by Gary King about running a rare event logistic. In the Zelig package,in R, you can run a rare event logistic.
