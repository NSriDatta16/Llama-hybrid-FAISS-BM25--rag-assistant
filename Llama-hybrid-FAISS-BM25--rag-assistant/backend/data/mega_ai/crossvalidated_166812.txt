[site]: crossvalidated
[post_id]: 166812
[parent_id]: 
[tags]: 
Why add one in inverse document frequency?

My textbook lists the idf as $log(1+\frac{N}{n_t})$ where $N$: Number of Documents $n_t$: Number of Documents containing term $t$ Wikipedia lists this formula as a smoothed version of the actual $log(\frac{N}{n_t})$. That one I understand: it ranges from $log(\frac{N}{N})=0$ to $\infty$ which seems intuitive. But $log(1+\frac{N}{n_t})$ goes from $log(1+1)$ to $\infty$ which seems so odd... I know a little about smoothing from language modelling but there you would add something in the numerator as well as in the denominator because you are worried about the probability mass. But just adding $1$ doesn't make sense to me. What are we trying to accomplish here?
