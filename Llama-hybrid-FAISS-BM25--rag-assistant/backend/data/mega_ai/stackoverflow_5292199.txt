[site]: stackoverflow
[post_id]: 5292199
[parent_id]: 5248954
[tags]: 
Do you know how many groups you need to split it into ahead of time? Do you have some limit to the maximum size of a group? A few algorithms for variations of this problem: Knuth's word-wrap algorithm algorithms minimizing the number of floppies needed to store a set of files, but keeping any one file immediately readable from the disk it is stored on (rather than piecing it together from fragments stored on 2 disks) -- I hear that "copy to floppy with best fit" was popular. Calculating a cutting list with the least amount of off cut waste. Calculating a cutting list with the least amount of off cut waste What is a good algorithm for compacting records in a blocked file? What is a good algorithm for compacting records in a blocked file? Given N processors, how do I schedule a bunch of subtasks such that the entire job is complete in minimum time? multiprocessor scheduling .
