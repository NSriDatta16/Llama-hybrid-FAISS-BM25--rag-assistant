[site]: crossvalidated
[post_id]: 482662
[parent_id]: 
[tags]: 
Various Methods to Calculate Linear Regression

I have just started learning Machine Learning and one of the very first topics that I have encountered in this venture is Simple Linear Regression. From Andrew Ng's course, I have learned to perform simple linear regression using gradient descent using the loss function. But recently I was watching this YouTube video where the professor gives an equation to find the slope and the interception in 1 step. Say if my equation is this $y=a_1 x + a_0$ Then, we can calculate $a_1$ and $a_0$ by these equations $a_1$ = $\frac{\sum_{i=1}^{n}x_i y_i â€“ \sum_{i=1}^{n}x_i\sum_{i=1}^{n}y_i}{n\sum_{i=1}^{n}{x_i}^2 -(\sum_{i=1}^{n}x_i)^2 }$ $a_0$ = $\bar{y}-a_1 \bar{x}$ wherer $\bar{y}=$ $mean$ $of$ $y$ and $\bar{x}=$ $mean$ $of$ $x$ Question 1: Since this method involves no iteration that is needed to compute slope and intercept in the case of Gradient Descent, isn't it better than gradient descent? Question 2: And what is the name of this method?
