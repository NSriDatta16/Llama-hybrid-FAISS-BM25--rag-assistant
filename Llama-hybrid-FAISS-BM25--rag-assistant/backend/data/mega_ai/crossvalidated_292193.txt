[site]: crossvalidated
[post_id]: 292193
[parent_id]: 292191
[tags]: 
A state can be or represent anything. There are too many examples to list to do the generality of this any justice. For you, it just needs to be a continuous state space Markov Chain. That should sound pretty abstract. It sounds like you're using dynamic linear models. If that's true, your state will represent a time-varying coefficient. It will be like a linear regression model, only your coefficients will be allowed to vary over time randomly. To do this I used a Kalman Smoother to get the 'filtered' estimates of the states and then plotted those. This isn't correct. A smoother gives you smoothed estimates of the states, while a filter gives you filtered estimates of your states. More on that in the next paragraph. However, I'm not sure if what I've done is what I was trying to obtain It depends on your application. If you want to use an entire window of observed data $y_1, \ldots, y_T$ to estimate your states $x_1, \ldots, x_T$, then you use a smoother. This is more accurate than filtering, however, it is using data you wouldn't have had at certain times. A smoother will give you the probability distribution $p(x_{1:T}|y_{1:T})$ or in the marginal case $p(x_t|y_{1:T})$ for $t=1,\ldots,T$. If you plot the means over time of this distribution, you will see how your coefficients/states change. However, if you're using a filter, you get the sequence of distributions $p(x_{1:t}|y_{1:t})$ or $p(x_t|y_{1:t})$ for $t=1,\ldots,T$. Notice that these sequences only use information up to the most recent time period. There is no looking forward with filtering distributions. However, they are less accurate than smoothing distributions typically, in the sense that they have higher variance. And by the way, all of this assumes that you know the variance parameters of your model.
