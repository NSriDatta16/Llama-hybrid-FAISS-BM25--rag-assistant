[site]: crossvalidated
[post_id]: 230495
[parent_id]: 230462
[tags]: 
If you are looking for average distance from the mean, then the most common choice of such measure is variance . If $x_1,\dots,x_n$ is your sample and $\bar x$ is it's arithmetic mean, then we define variance as $$ \frac{1}{n} \sum_{i=1}^n (x_i - \bar x)^2 $$ so we take average squared difference from the mean. To have your measure in the same scale as your data, you can take square root of it, i.e. calculate standard deviation . There are also other measures as well, for example if you were working with medians, you could use more robust median absolute deviation , that is defined as $$ \operatorname{median}\left(\ \left| X_{i} - \operatorname{median} (X) \right|\ \right) $$ However squaring the difference and using variance (or standard deviation) is preferred since it has many nice properties, what you could learn from following threads: Why square the difference instead of taking the absolute value in standard deviation? Why should I prefer the standard deviation over other measures of variance? Understanding "variance" intuitively or Why is variance calculated by squaring the deviations? thread on ResearchGate.net. Moreover, in your case squaring penalizes the extreme outlying cases more then taking absolute value, so it better serves for your purpose.
