[site]: datascience
[post_id]: 58730
[parent_id]: 58728
[tags]: 
Welcome to DS StackExchange. I'll go through your list: ANN (Artificial Neural Network): it's a very broad term that encompasses any form of Deep Learning model . All the others you listed are some forms of ANN. ANNs can be either shallow or deep . They are called shallow when they have only one hidden layer (i.e. one layer between input and output). They are called deep when hidden layers are more than one (what people implement most of the time). This is where the expression DNN (Deep Neural Network) comes. CNN (Convolutional Neural Network): they are designed specifically for computer vision (they are sometimes applied elsewhere though). Their name come from convolutional layers : they are different from standard (dense) layers of canonical ANNs, and they have been invented to receive and process pixel data. RNN (Recurrent Neural Network): they are the "time series version" of ANNs. They are meant to process sequences of data. They are at the basis of forecast models and language models. The most common kind of recurrent layers are called LSTM (Long Short Term Memory) and GRU (Gated Recurrent Units): their cells contain small, in-scale ANNs that choose how much past information they want to let flow through the model. That's how they modeled "memory". If you want to learn how to implement all these forms of ANN in TensorFlow, I suggest you this wonderful book: Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition by Aurélien Géron this is the best book on ML and DL, IMHO.
