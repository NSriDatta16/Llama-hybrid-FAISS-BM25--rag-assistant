generated by robots by 2025-2030 in case LLMs soar. Frazier also mentioned a study according to which efforts to help users in detection of artificial content would often backfire and even increase skepticism about the nature of content. Edwards said in September 2024 that people are facing increasing difficulty in telling what's real from what's fake since the rise of political deepfakes. In an article for Folha de S.Paulo, Eduardo Saron mentions one study by IA Pearl-Censuswide according to which 41% of Generation Z trust AI more than humans and 56% of millennials feel more comfortable asking questions to AIs instead of co-workers. In another study by Microsoft-Carnegie Mellon University, the rise in AI trust could be related to a decrease in critical thinking. The right to reality may come also as a broader response to AI-related issues, since simply labeling AI content as such may not be enough to tackle broader problems such as diminishing trust in institutions and political processes. Applications Frazier advocated in his article for a system of classification of internet content (similar to nutrition labels) that would inform users of the degree to which AI has or has not been used to create said content while also allowing users to even filter content according to their own preferences. He also wrote that the application of a right to reality "would not require the removal of any content nor discrimination based on the viewpoints asserted by that content" but would be "a disclosure requirement". He mentioned Lawrence Lessig's anticipation of the rise of AI-detection tools and that those would become prevalent in the media market. Edwards supports the labeling of AI-generated content with methods such as watermarkings as proposed by the C2PA and the European Union's AI Act. However, Edwards herself and Fazier admit it may not be enough. Speaking to Digital Frontier, Frazier said that "even the labelling of a right can have a big impact on the ability of people to advocate for the provision of that right" and compared the advocacy for it to citizens' assemblies. Saron concedes both that there's no such thing as an "absolute reality", since according to him reality is always filtered by subjective, social and symbolic layers, and that the digital world can also create new realities or amplify existing ones. The right to reality could take years to translate into actual legal developments, much like the right to privacy is still discussed over a hundred years after the publishing of "The Right to Privacy" or the right to repair, which emerged in the 20th century and was only incorporated in EU and US legislation in the 2020s. Limitations Frazier analyses that a "right to reality" in the United States could conflict with the First Amendment. While, according to him, the U.S. Supreme Court has interpreted the Amendment as a guarantee of "an uninhibited marketplace of ideas in which truth will ultimately prevail", said marketplaces, such as social media platforms, will be overrun with AI content to the point that such guarantee is jeopardized if the right to reality is not taken into consideration. On the other hand, he argues that because social media platforms are not yet seen as public forums by First Amendment jurisprudence, nor as state actors by the Court, "the right to reality may not find a legal home in the U.S. Constitution". Lilian Edwards pondered that because most of the relevant social media platforms are hosted in the US, UK & Europe-based regulations and legislation are made harder. Criticism Brazilian educational researcher Rafael Parente, while agreeing with most of Eduardo Saron's thoughts, believes that the right to reality should be expanded to the right to a "worthy hybrid reality", where human and machine would not be separate, but fairly integrated. Regarding Saron's "synthetic inequality" theory, Parente sees it as an opportunity for "expanded equity" instead, in that marginalized children would have 