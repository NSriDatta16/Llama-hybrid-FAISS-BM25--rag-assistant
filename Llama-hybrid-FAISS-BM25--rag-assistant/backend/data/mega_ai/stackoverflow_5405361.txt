[site]: stackoverflow
[post_id]: 5405361
[parent_id]: 5405325
[tags]: 
If you want a specific URL (or a directory) no not be indexes by crawlers, a simple solution is to use a robots.txt file -- which will allow you to specify what can, and cannot, be indexed. For more informations, see About /robots.txt For example, if you want a crawler not to index the /my-page.php URL, you could use something like this in your robots.txt file : User-agent: * Disallow: /my-page.php As a sidenote : files that should not be visible from end-users (like include files, libraries, non-interpreted templates, ...) should not be served by your webserver : no-one should be available to access those. If using Apache, using a .htaccess file in a given folder (provided this feature is enabled) , you can prevent Apache from serving any file from that folder : Deny from All Note : nothing will be served by Apache from the directory that contains a .htaccess file with that content !
