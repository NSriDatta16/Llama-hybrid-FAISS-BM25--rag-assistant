[site]: stackoverflow
[post_id]: 3815970
[parent_id]: 3814188
[tags]: 
Since you're only doing a merge, not a complete sort, it's just the basic merge loop. Purely sequential I/O. No need to worry about buffers. Picture a zipper on a jacket. It's that simple. (Note: it could be a lot faster if the numbers are in binary format in the files. Not only will the files be smaller, but the program will be I/O limited, and the numbers will be perfectly accurate.) double GetNumberFromFile(FILE file){ if (feof(file)){ return BIGBIGNUMBER; } else { return ReadADouble(file); } } double A = GetNumberFromFile(AFILE); double B = GetNumberFromFile(BFILE); while (A Responding to your question, consider a simpler problem, copying one file to another. You're only doing sequential I/O, which the file system is really good at. You write a simple loop to read small units like a byte or int from from file, and write it to the other. As soon as you try to read a byte, the system allocates a nice big buffer, swipes a big chunk of the file into the buffer, and then feeds you the byte out of the buffer. It keeps doing that until you need another buffer, when it invisibly gloms another one for you. The same sort of thing happens with the file you are writing. Now the CPU is pretty quick, so it can iterate through the input bytes, copying them to the output, in a fraction of the time it takes to read or write a buffer, because the reading or writing can't go any faster than the external hardware. The only reason a larger buffer would help is that part of the reading/writing time is what's called "latency", basically the time it takes to move the head to the desired track, and wait for the desired sector to come around. Most file systems break up the files into chunks that are sprinkled around the disk, so the head is jumping anyway. You can hear it. The only difference between copying and a merge algorithm like yours is it's reading two files, not one. Either way, the basic time sequence is a series of buffer reads and writes interspersed with a small amount of CPU action. (It is possible to do overlapped I/O, so that the CPU action takes place while the I/O happens, so there is basically no delay between buffer reads and writes, but it was a bigger deal when CPUs were 1000 times slower.) Of course, if you can arrange it so that the files being read and written are all on separate physical disk drives, and the drives are not fragmented much, then the amount of head motion could be minimized, and larger buffers might help. But basically, with a simple program, you can pretty much expect the simple code to go about as fast as the disk can move data, and giant buffers might help, but not much.
