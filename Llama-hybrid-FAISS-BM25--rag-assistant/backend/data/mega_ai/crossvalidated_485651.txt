[site]: crossvalidated
[post_id]: 485651
[parent_id]: 458057
[tags]: 
There is also the concept of Stacked Regression . Given a set of predictions $v$ from different models, you can apply constrained least squares in order to find a weighted average combination that minimizes prediction error. It can be formulated as: $min \sum_n(y_{i}-\sum_ka_kv_{kn})^2, s.t. a_k\geq0, \sum a_k=1$ . The paper also provides a theoretical discussion on why constraint least squares outperforms ridge regression, although it would not make a huge difference to apply unconstrained least squares.
