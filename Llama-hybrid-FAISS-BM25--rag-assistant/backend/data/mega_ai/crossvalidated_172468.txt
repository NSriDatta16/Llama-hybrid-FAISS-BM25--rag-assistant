[site]: crossvalidated
[post_id]: 172468
[parent_id]: 169623
[tags]: 
I'll address my answer specifically to the question, "What non-Bayesian methods for predictive inference are there that take into account uncertainty in parameter estimates?" I will organize my answer around expanding the meaning of uncertainty . We hope statistical analyses provide support for various kinds of claims, including predictions . But we remain uncertain about our claims, and this uncertainty arises from many sources. Frequentist statistics is characteristically organized around addressing only that part of our uncertainty arising specifically from sampling . Sampling may well have been the main source of uncertainty in the agricultural field experiments that historically provided much of the stimulus to the development of frequentist statistics. But in many of the most important current applications, this is not the case. We now worry about all kinds of other uncertainties like model misspecification and various forms of bias---of which there are apparently hundreds (!) of types[1]. Sander Greenland has a wonderful discussion paper [2] that points out how important it can be to take account for these other sources of uncertainty, and prescribes multiple-bias analysis as the means to accomplish this. He develops the theory entirely in Bayesian terms, which is natural. If one wishes to carry forward a formal, coherent treatment of one's uncertainty about model parameters, one is led naturally to posit (subjective) probability distributions over parameters; at this point you are either lost to the Bayesian Devil or have entered the Bayesian Kingdom of Heaven (depending on your religion). To your question, @Scortchi, about whether this can be done with "non-Bayesian methods," a non-Bayesian workaround is demonstrated in [3]. But to anyone who knows enough about Bayesianism to write your question, the treatment there will look rather like an attempt to implement Bayesian calculations 'on the sly' so to speak. Indeed, as the authors acknowledge (see p. 4), the closer you get to the more advanced methods toward the end of the book, the more the methods look like precisely the integration you describe in your question. They suggest that where they depart from Bayesianism ultimately is only in not positing explicit priors on their parameters before estimating them. To tie this in explicitly to prediction , one need only appreciate the 'prediction' as a function of the estimated parameters. In [2], Greenland uses the notation $\theta(\alpha)$, where $\alpha$ is the vector of model parameters, and $\theta$ is the function of those parameters which is to be estimated. (In terms of Greenland's example application, a meaningful prediction could be the impact in terms of reduced pediatric leukemia of a policy of relocating power lines.) Chavalarias, David, and John P A Ioannidis. “Science Mapping Analysis Characterizes 235 Biases in Biomedical Research.” Journal of Clinical Epidemiology 63, no. 11 (November 2010): 1205–15. doi:10.1016/j.jclinepi.2009.12.011. Greenland, Sander. “Multiple-Bias Modelling for Analysis of Observational Data (with Discussion).” Journal of the Royal Statistical Society: Series A (Statistics in Society) 168, no. 2 (March 2005): 267–306. doi:10.1111/j.1467-985X.2004.00349.x. Lash, Timothy L., Matthew P. Fox, and Aliza K. Fink. Applying Quantitative Bias Analysis to Epidemiologic Data. Statistics for Biology and Health. New York, NY: Springer New York, 2009. http://link.springer.com/10.1007/978-0-387-87959-8 .
