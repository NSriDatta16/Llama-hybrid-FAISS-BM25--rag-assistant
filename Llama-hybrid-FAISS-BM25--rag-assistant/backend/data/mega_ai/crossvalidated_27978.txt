[site]: crossvalidated
[post_id]: 27978
[parent_id]: 27974
[tags]: 
Econometric models often try to determine causality in a time series context. For example, studying the impact of tax rate changes on economic growth. Panel data, a time series of cross-section data sets, is often employed to estimate causal effects. Difference-in-difference estimators are commonly employed here for precisely this exercise (essentially, omitted variables are differenced out). To answer your direct question, yes, we would be concerned about omitted variables when we are trying to determine causal links. If these variables are correlated with our treatment variable, then we can get a biased estimate of the causal effect. For prediction, we aren't looking to ascribe causal links and thus omitted variables bias may be less of a concern. Knowing that the number of people carrying umbrellas is a good predictor of whether or not it will rain in the afternoon is useful enough for me to forecast the weather, but I can't explain it. The explain-predict difference is key if the omitted factor is changing over time. If people decide that they don't want to be exposed to the sun and start carrying umbrellas on rainy and sunny days, then my forecasting ability breaks down. Without a causal factor, I can't anticipate these model failures. This is how omitted variables bias can be important even "just" for forecasting. Given that the model doesn't break down, I might be able to generate better predictions using non-causal factors in addition to causal ones. Whatever I can get my hands on to reduce my prediction variance.
