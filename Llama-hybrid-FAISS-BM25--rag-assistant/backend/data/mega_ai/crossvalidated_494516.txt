[site]: crossvalidated
[post_id]: 494516
[parent_id]: 494456
[tags]: 
In NLP, I have seen it done with one-hot encoding: https://colab.research.google.com/github/AndreasMadsen/python-textualheatmap/blob/master/notebooks/huggingface_bert_example.ipynb But I've seen more places use embedding, then normalize the embedding to get a single score per token. This recent survey of input saliency shows better results for aggregating using the L2 norm: https://arxiv.org/pdf/2009.13295.pdf (as opposed to averaging). I also believe that (embedding) is what the Captum interpretability library uses. Examples: https://captum.ai/tutorials/Bert_SQUAD_Interpret https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb#scrollTo=di_oai-BvG5k
