[site]: datascience
[post_id]: 72053
[parent_id]: 62436
[tags]: 
Discriminative models output some tensor $Y$ describing a label given some input tensor $X$ describing some input data. The method of mapping $X$ to $Y$ might be deterministic or not - there's no need for it to be (consider the example of taking a deterministic model and adding a small amount of random noise to it, so that it is perhaps $1\%$ less accurate and more random). The accuracy of the model is the average accuracy over the validation/testing data. The model estimates the probability that the label is $Y$ given the input data is $X: P\left(Y|X\right)$ . Generative models generate a tensor that is drawn from a learned distribution that is similar (as a result of the learning) to the distribution of some training data. For sequence generation, the probability of a generated tensor ( $X$ , say) at time t is dependent on the probability that the tensor generated at time step $t-1$ was correct ( $P\left(Y\right)$ , say) and the probability of the new tensor ( $X$ ) if the previous one is taken as given (probability of $X$ given $Y$ , or $P\left(X|Y\right)$ ). The probability of the recently-generated tensor is $P\left(X|Y\right) \cdot P\left(Y\right)$ . I don't really like the notation in the text you're reading, and I agree with you that it's confusing. However, in answer to your question "Why do we denote $P\left(Y|X\right)$ for Discriminative models": model outputs are always estimates and should ideally reflect the fact that the input data doesn't perfectly predict the class. That is, even deterministic models should communicate their estimates in the language of probability; for example even a deterministic model might give an output that can be interpreted as " $80\%$ of the time, input data with these features means the class is C"
