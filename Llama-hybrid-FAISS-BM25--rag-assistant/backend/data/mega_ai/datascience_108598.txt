[site]: datascience
[post_id]: 108598
[parent_id]: 108435
[tags]: 
SQL is not a programming language, rather a (human-understandable) query language; hence, it is very uncommon to have, for example, any implementation of Random Forests (RFs). Nevertheless, (declarative and procedural) SQL is Turing-complete and, as such, RFs could be implemented if wanted. There are no coefficients if the intended meaning is similar to those of neural networks. If we consider the regression case with RFs (the classification task can be viewed as a particular case), the output is the average of each (base, decision tree) regressor output, that is: $$ \hat{y} = RF(\vec{x}) = \frac{1}{K} \cdot \sum_{k = 1}^K DT_k(\vec{x}) = \frac{1}{K} \cdot DT_1(\vec{x}) + \frac{1}{K} \cdot DT_2(\vec{x}) + \ldots + \frac{1}{K} \cdot DT_K(\vec{x}), $$ where $\hat{y}$ is the predicted output , $K$ is the number of trees in the RF model and $DT_i(\vec{x})$ , for $1 \le i \le K$ , is the predicted output of the $i$ -th tree on the input vector $\vec{x}$ . Then, the $K$ -dimensional coefficients' vector can be learned by, for example, a linear regression model. Finally, as DaCard said, feature importance is not related to coefficients.
