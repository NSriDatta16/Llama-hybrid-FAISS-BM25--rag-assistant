[site]: datascience
[post_id]: 121249
[parent_id]: 
[tags]: 
Bayesian linear regression using pymc

Assume three features: $x_1,x_2,x_3,$ and a continuous label $y.$ I want to use pymc in python to fit a Bayesian linear regression based on training samples. I was asked for two questions: At what $x_3$ , $y$ is a maximum? Provide a distribution of this $x_3$ (that maximizes $y$ ). For 1, I understand as we should first fix the left features say $x_1 = 1, x_2 = 2.$ Then numerically find $x_3$ to maximize the mean of posterior distribution: $m(x_3) = E[y|x_1=1,x_2=2,x_3].$ I am not familiar with pymc, how do we call the above posterior distribution $P(y|x_1=1,x_2=2,x_3)$ ? is pm.plot_posterior the expected distribution for question 2? I doubt that here maximum is the maximum of probability i.e. MAP estimation or it seems not easy to solve.
