[site]: datascience
[post_id]: 54360
[parent_id]: 53995
[tags]: 
According to all answers(Thank you) and my google search I got a better understanding, So my newly updated understanding is: The embedding in machine learning or NLP is actually a technique mapping from words to vectors which you can do better analysis or relating, for example, "toyota" or "honda" can be hardly related in words, but in vector space it can be set to very close according to some measure, also you can strengthen the relation ship of word by setting: king-man+woman = Queen. so we can set boy to (1,0) and then set girl to (-1,0) to show they are in the same dimension but the meaning is just opposite. And all nouns that just diff in gender can be parallel~ My initial guess that embedding is extracting features from something is close but not specific enough. And for my last point when you met a jargon in some special area how to quickly get the essential meaning of it, I still didn't find a very good way, maybe a website that can explain the meaning of jargon in that area will save great time for us.
