[site]: crossvalidated
[post_id]: 231910
[parent_id]: 231785
[tags]: 
[The first five emotional replies censored.] That is one of the strangest questions on the site, frankly. And shows how much disconnect there is between what your professors say and the real life -- that is, the life outside of the ivory tower. It's good that you are peeking out of it... but you (meaning, Ph.D. students in economics) definitely need to do this more often. Yes, there are jobs outside academia where people (surprise, surprise) use causal inference methods. And (surprise, surprise) publish papers. My answers are U.S.-specific, but I am sure you can find similar organizations in other countries. Example 1 (only because I am familiar with it internally at my job). I work in a subsidiary to a large contract research organizatoin, Abt Associates . It employs about 2,300 people in 50 countries, and most of them work on conducting or supporting evaluation research, and implementing interventions. One of the top 6 technical people (referred to as Senior Fellows ), Jacob Klerman, is the editor of Evaluation Review , overseeing a board of editors of whom about 5/6 have academic affiliations. So that is a private sector example for you. (Check the company position ads to see specifically what kind of skills a company like that may be looking for -- I am not entirely sure everybody advertises at JOE as that's expensive; I can easily name another dozen in the U.S. who'd be happy to hire a craftsy econometrician.) Example 2 (I have but a passing familiarity with that because I know people who started this project from other venues): What Works Clearinghouse at the U.S. federal Department of Education is a website devoted to meta-analysis of the published analysis of educational programs. WWC operates through a network of reviewers who are given specific instructions as to what is considered a study that has sufficient rigor to support causal claims, and what isn't. It turns out that most of that published research is absolute crap. As in, bullshit. No control group. No checking of the balance on the demographic covariates/baseline equivalence. Only about 3-5% of the studies (published in the peer-review literature, for goodness sake) "meet standards without reservations" -- meaning, they had some semblance of randomization, controlled attrition and cross-contamination of the experiment arms, and did the analysis in a more or less acceptable way down the line. (By Bayes theorem, when you hear somebody say, "But I saw it published that chewing gum increases math achievement", you can respond, "BS", and you'd be right 90+% of the time.) At any rate, this is a federal department project, so that's an example for you where a government agency reviews the proper use of causal inference tools. (Throw your name into the hat as a study reviewer, this will be a great educational experience for you. If I were teaching program evaluation, I would have made this a requirement for my students.) (For biostatisticians working with FDA, where you have to submit your analysis code before you collect any data, WWC standards are still very lax.)
