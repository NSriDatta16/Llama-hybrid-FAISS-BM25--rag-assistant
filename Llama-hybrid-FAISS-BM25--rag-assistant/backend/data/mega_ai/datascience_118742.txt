[site]: datascience
[post_id]: 118742
[parent_id]: 
[tags]: 
Combining text and image features with different scales

I have computed text features using [SBERT][1] and image features using VGG-16. The text features range from -1.58 to 1.58, whereas the image features range between 0 and 521. I would want to concatenate the text and image features and use them to compute cosine similarities. However, as you've probably noticed, the difference in scale would mean that the image features would completely dominate the text ones. My idea was to use something like sklearn's MinMaxScaler and scale down the image features to the same scale as the SBERT computed features; however, I'm not sure if this is the best solution for my case since other [answers][2] here suggest normalizing both features. In my case, I would say that the text features are more important than the image ones. [1]: https://github.com/UKPLab/sentence-transformers [2]: Creating a feature by combining 2 features with different units?
