[site]: crossvalidated
[post_id]: 286646
[parent_id]: 
[tags]: 
Neural Networks: Mixed Regression and Classification Problems

I am examining a problem that has elements of both regression and classification. The domain is speech processing, and the example problem is a bit of a "toy" problem where existing algorithms can yield a good approximation of ground truth. Specifically, an input is a "frame" of data representing a short length of audio recorded human speech. (Could be raw sample data, could be pre-processed.) An output is either: 0, if the frame of data is unvoiced, or a number representing the pitch (i.e., the frequency of glottal vibration) if it is voiced. This is the convention in the field, and it is a useful one. (In this case, there happens to be a guard-band around 0, i.e., if the value is not 0, it will be positive, and larger than 50.) It is important to note that 0 does not connote a pitch of 0 Hz, but the absence of a pitch. In this sense, the problem is classification: Voiced/unvoiced. But all other values do correspond to true numeric values. In this sense, the problem is regression: predict the continuous value. First: Is there a name for this sort of mixed problem in the literature? No obvious term for it that occurred to me yielded good search results. Second: Are there principled neural network approaches for such problems? I can think of several, but they all seem "hackish" in one way or another: Train a V/uV classifier on all frames, train a pitch regression on all voiced frames, and use the one to trigger the other Train a single dual-output network with a classifier and a regression section, and use the classifier to "gate" the output somehow. Treat it as a regression problem and squelch all values below the guard band. Quantize the pitch output and reduce to a classification with a large number (50 to 100) classes, one of which corresponds to unvoiced. These seem "hackish" to me because in three cases I cannot settle on an appropriate overall loss function, and in the final case it seems that the massive imbalance between the unvoiced bin and all other bins might impede training.
