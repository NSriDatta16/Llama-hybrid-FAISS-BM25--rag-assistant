[site]: datascience
[post_id]: 121213
[parent_id]: 
[tags]: 
Creating LLM chatbot using llama-index + langchain

As the title suggests: I'm trying to build a chatbot which his goal should be sort of like "chatgpt". The chatbot will be installed on Slack workspace and I'm struggling with which scope I should create the documents on for building the index. At the moment the document scope is " per channel " (i.e. every channel is a whole document ), but I'm not sure it's the right approach (maybe it should be far smaller - does it make any difference at all?) I'm also using huggingface transformers library, but since I'm newbie to this whole new evolving technology, I'm not sure what type of model should I use : text2text text-generation summarization quiestion-answering I want the bot to address all (maybe I'm a bit naive). ... so overall, 2 questions: What should the Document scope be? Which type of model should I look at? Any specific recommended one?
