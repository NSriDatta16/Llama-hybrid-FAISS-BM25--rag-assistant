[site]: crossvalidated
[post_id]: 268225
[parent_id]: 255877
[tags]: 
The theory of maximum likelihood is generally not tractable for generative models, as seen here . Instead, methods such as VAEs and GANs, the likelihood is approximated by a KL Divergense, on VAEs, and JS Divergense on GANs. Such functions are a measure of how much two distribution probabilities diverges, also known as relative entropy. Roughly, although two distribution of the same shape but different means have same entropy, you can think that while such functions adapt the shape learned by the network, the Discriminator (in case of GANs), when optimal, decide where is the mean. For example, if a GAN is trying to learn a Gaussian distribution of mean -1 and standard deviation 2, the discriminator, which reaches its optimum state over time, is responsible for locate that mean, while the divergence function learn its shape. Tecnically, it is possible because, according to the proof in the article, the optimal Discriminator should achieve a cost of -log(4). So the Generator indirectly approximates its actual distribution to reach this value in Discriminator's cost, ensuring the convergence to the mean and the shape.
