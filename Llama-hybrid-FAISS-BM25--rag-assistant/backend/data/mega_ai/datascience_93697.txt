[site]: datascience
[post_id]: 93697
[parent_id]: 93695
[tags]: 
what I understand from your code is you are fitting a one-hot encoder on your training set, which may not include all words that appear in your test set. So when you get a new word in your evaluation method, your transformer cannot hash it, and hence throw an error. the easiest way to solve this would be to use the unknown_error argument in one hot encoder def prepare_targets(y_train, y_test): ohe = OneHotEncoder(handle_unknown='ignore') ohe.fit(y_train) y_train_enc = ohe.transform(y_train) y_test_enc = ohe.transform(y_test) return y_train_enc, y_test_enc now when you encounter a new word in the test set your encoder will output an array of all zeros, and if your try inverse transforms on all zeros, you will get none. The downside is obvious here, your Neural Network does not what to do for zero vector as it has never seen such an example in training. So expect a weird response when a new word is evaluated. The smart way of solving this problem would be to assume there are some unknown words in the training set by synthesizing few rare (unique) words as 'unknown' (replace words with the word 'unknown') and then do the one-hot encoding. while evaluating you will then first check if the word is not part of words set in training data, then you will replace that word with 'unknown'.
