[site]: crossvalidated
[post_id]: 370456
[parent_id]: 239926
[tags]: 
May be this is late but it might help you, in problems like mnist it is common to flatten all values, if you want you can do this in your problem too. There is nothing wrong in flattening, even CNN at the end just flatten all the calculated feature maps and then pass those values followed by fully connected layers. One more thing you can try is use a recurrent neural networks, which takes 1 (mean, variance) at each current recurrent state, by this you can feed your network (mean, variance) one at a time. All the best.
