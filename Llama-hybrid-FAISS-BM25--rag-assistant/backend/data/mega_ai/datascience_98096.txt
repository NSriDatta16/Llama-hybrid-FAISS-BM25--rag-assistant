[site]: datascience
[post_id]: 98096
[parent_id]: 
[tags]: 
Possible to use predict_proba without normalizing to 1?

I'm using xgboost multi-class classifier to predict a collection of things likely to fail. I want to run that prediction, and report anything that the classifier identifies with probability > 75% . However if I use xgb.predict_proba() , the sum of the results in the array add up to 1. So, if there are a lot of things likely to fail, they will all have tiny percentages in the result array. Looking at the predict_proba code , I can see where the array is getting normalized. However I can't figure out how to prevent this. In the end, I think my code would look something like this (except with the pre-normalized probabilities): probas = xgb.predict_proba(single_element_dataframe) for class_name in xgb.classes_: class_index = np.where(xgb.classes_ == class_name) proba = probas[0][class_index] if proba > 0: print(f"{class_name}: {proba}") Any ideas?
