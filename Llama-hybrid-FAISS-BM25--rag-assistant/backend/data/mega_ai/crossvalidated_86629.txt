[site]: crossvalidated
[post_id]: 86629
[parent_id]: 86623
[tags]: 
In most cases we don't really care about the inference on the intercept. But the computer does not know when we do and don't and calculating that inference is quick the computer will present it just in case. The main thing to consider is does your data include values of 0 for all predictor variables? (and is that an interesting area to think about?) An example of where we might care is if $x_1$ is the dosage of a drug and $y$ is the change in cholesterol level. If some subjects received a placebo ($x_1=0$) then the intercept could be interesting (would be a measure of cholesterol change due to placebo, or being in the study without active drug). Another example would be $x_1$ is the average daily intake of water (including in other drinks) and $y$ is weight loss over the length of the study. Now anyone with $x_1=0$ will be dead by the end of the study, so it will not be in the data and is not really anything of interest. It may be that over the range of values we collect that the relationship is linear enough that a linear regression works, but as the amount of water goes below the smallest value we observed there is non-linearity, then the actual value of the intercept is not directly interpretable, it just makes sure our line is in the right place and any inference (test, interval) will be meaningless and should be ignored. My guess is yours is a case where there is non-linearity between your smallest observed value and a value of 0, and the inference on the intercept should therefore be ignored (you may want to do some diagnostic plots on the data to make sure that a line is reasonable within the range that you have).
