[site]: crossvalidated
[post_id]: 74821
[parent_id]: 74804
[tags]: 
Say we have 2 observations, an event ($X_1=1$) and a non-event ($X_2=0$). Say our first model "predicts" probabilities $P(X_1)=.55$ and $P(X_2)=.45$. If our decision rule for prediction of an event is based on a $.5$ probability threshold, then this first model is perfect (given our decision rule and the estimated probabilities). But notice the probabilities are close to $.5$ (close to that of getting tails on a coin flip!). Now we change the model and the new probabilities are $P(X_1) =.95$ (much closer to observed $1$) and $P(X_2)=.51$ (not very different from the previous estimate, but importantly, crossing the threshold!). Considering the same decision rule for prediction, our predictions are not perfect anymore. However, considering the change in estimated probabilities, now we have a much better fitting model overall. This brief discussion is based on the decision rule for prediction which I have assumed you are using. If your view of your model's performance is based on correct guesses, then the performance of your model depends on how you make guesses. Chances are, you could merely change the decision rule and see a completely different evaluation of your model's performance. There are many ways to measure model performance. Some more imperfect than others. It's probably worth mentioning that such a decision rule is not an inherent element of logistic regression. Logistic regression models the probability of events, not dichotomous guesses about whether they occurred.
