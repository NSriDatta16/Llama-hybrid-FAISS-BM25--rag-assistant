[site]: datascience
[post_id]: 9010
[parent_id]: 8999
[tags]: 
There are two main functions they undo. The pooling layers in the convolutional neural network downsample the image by (usually) taking the maximum value within the receptive field. Each rxr image region is downsampled to a single value. What this implementation does is store which unit had the maximum activation in each of these pooling steps. Then, at each "unpooling" layer in the deconvolutional network, they upsample back to a rxr image region, only propagating the activation to the location that produced the original max-pooled value. Thus, "the output of an unpooling layer is an enlarged, yet sparse activation map." Convolutional layers learn a filter for each image region that maps from a region of size r x r to a single value, where r is the receptive field size. The point of the deconvolutional layer is to learn the opposite filter. This filter is a set of weights that projects an rxr input into a space of size sxs , where s is the size of the next convolutional layer. These filters are learned in the same way that as regular convolutional layers are. As the mirror image of a deep CNN, the low-level features of the network are really high-level, class-specific features. Each layer in the network then localizes them, enhancing class-specific features while minimizing noise.
