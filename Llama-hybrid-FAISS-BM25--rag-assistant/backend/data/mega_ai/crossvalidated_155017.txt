[site]: crossvalidated
[post_id]: 155017
[parent_id]: 154679
[tags]: 
I translate your question into: If I want to determine the difference in response to the same treatment of two species of mice, what is the correct approach? how do I test if my idea (about the effectiveness) is correct? Thoughts: I think that this is a good places for Bayes rule. ( Yudkowsky Bayes ) I also think that you should look at confidence intervals and sample sizes. Bayes would come after the CI given sample sizes, imo. My first question would be : "What is the lower 95% confidence interval (CI) given my sample size." If I have 10 mice of each species then the ratios mean something substantially different than for 100 mice. Here is a great calculator for approaching the question: link . The column that I recommend is Jeffreys. If I have 10 mice and 3 of them have the disease then my lower 95% CI is 9.27% my lower 95% CI is 60.58% my mean is 30.00% This means that there is good chance that the "true" value is somewhere between 9% and 61%, and poor chance that it is outside of these values given the data. The region where "true" is expected to live is about 50% - half the entire domain. If I have 100 mice and 30 of them have the disease then my lower 95% CI is 21.68% my lower 95% CI is 39.45% my mean is 30.00% This means that there is good chance that the "true" value is somewhere between 21% and 40%, and poor chance that it is outside of these values given the data. The region where "true" is expected to live is 20% - one fifth the entire domain. It took 10x the samples, but reduced the domain by 2.5x. You can see how higher sample rate substantially pulls in the width. You can also see how with only 10 samples, a value of 10% is interior to the 95% CI. That means if you only had 10 samples of each breed per treatment, the experimental approach might have a problem. It might not give enough data to clearly differentiate the two. My second question would be : "If I have a mouse of a given species, and it does not have the disease, and I have equal counts of both mouse species in my population, what is the likelihood that it was given a treatment". Here is some code using Bayes rule (hopefully not incorrectly): #set random seed set.seed(1) #total number of mice over 4 # each treat, each species is this value N When I put this into a table and compare it with the analytic result I get the following: where: You can see where I manually entered the numeric results from running the R code and compared it to the "pure case". Bottom lines: What this tells me is: I got pretty consistent results using two separate modes so if I made a mistake, then I did it two separate times. If I have a critter that is both treated AND diseased, it is 10x more likely to be from Species30 than to be from Species10. If I have a critter that is diseased, the chance of it having been treated is 2.75x higher if it is from Species30 than if it is from Species10. The sample size may be high, but given the 1% rate for species 10, there is still a pretty big difference between realistic results and the limit of infinite samples. That 12% relative error when all others are between 5% and 0.2% is a warning. You might want to unset the seed from the code above and run the simulation a few hundred times, storing the estimates, and determine not only the mean value, but the tolerance around the mean given your sample sizes. This will put some error bars around the 10x and the 2.75x. Having a clear understanding of the difference between points 2 and 3 is likely going to be important in the discussion. The difference is whether or not you know if it has been treated. For the intended outcome do you want knowledge of treatment to be a given as in you are going to treat the entire population? Are you looking at narrower scope in your solution? Every technical analysis has to support a business decision. Every business decision is about maximizing return of value. Reliable and excellent growth come from maximizing return of value to the customer. This means that many analyses could be improved in clarity and effect if the nature of the customer, the nature of value, and the nature of the decision are clearly articulated. It is better to ask the question 2 or 20 times and be sure you are asking the right question than to spend resources 2 or 20 times answering the wrong question. Most business harm, like many aircraft accidents, are a tragic sequence of repeatedly asking the wrong question. Good management of point 4 is likely going to ensure repeatability. My estimate is a mean absolute relative error of 14.45% but a max near 92%. You are not unlikely to get an experimental rate 14.67% through 5.52% instead of 9% for the "probability of treated given species10 and diseased". If N is 4000, then the range is from 13.02 to 6.22. Doubling the sample size shaves of around 1% from either side of the tolerance band. To be completed later. Lunch is calling.
