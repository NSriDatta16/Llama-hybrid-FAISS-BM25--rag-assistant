[site]: crossvalidated
[post_id]: 305697
[parent_id]: 303047
[tags]: 
I suggest trying Simultaneous Perturbation Stochastic Approximation . The link has a very clear beginner tutorial and a link to Matlab code; I'll alter the basic algorithm slightly to deal with the min / max issue and present some R code on a toy saddlepoint problem. SPSA is designed for problems which involve minimizing or maximizing an unconstrained, continuous-in-expectation, stochastic function. It can be pretty easily extended to problems with a small number of constraints, and there is a root-finding variant as well. It has been extended to discrete problems as well. I've used it on problems with hundreds of parameters with success. The basic idea is that, at every iteration $k$, we form an estimate of the gradient in a randomly-chosen direction by sampling the function $f$ at two points $\theta_k \pm c_k\Delta$ around the current parameter value $\theta_k$. $\Delta$ is typically chosen by generating a vector of $\pm 1$ values; $c_k$ is a scaling parameter that decreases slowly as the number of iterations increases. Our gradient estimate is formed in the obvious way: $$g_k = (f(\theta + c_k\Delta)-f(\theta - c_k\Delta)/2c_k\Delta$$ where the division is done elementwise so $g$ is a vector of the appropriate length. Once we have a gradient, we step in the appropriate direction (depending on whether we are minimizing or maximizing) to get the next iteration's estimate of $\theta$ $$\theta_{k+1} = \theta_k - \alpha_kg_k$$ where $a_k$ is a stepsize that decreases as $k$ increases. Obviously, I've assumed we are facing a minimization problem in the line above. Guidelines for choosing the sequences $a_k, c_k$ abound, but it's really pretty easy and in my experience not much experimentation is needed. In your case, since you are minimizing with respect to some parameters and maximizing with respect to others, you'd simply switch the sign of the derivative for the parameters you're maximizing on. On to an example! We have the function $f(x) = x_1^2 - x_2^2$ with some noise (distributed $N(0,1)$) added to the return value. We will try to minimize with respect to the first parameter and maximize with respect to the second parameter. Using the excellent package plot3D in R, we plot the de-noised function in the vicinity of the saddlepoint: The saddlepoint, which we are trying to find, is at $x = (0,0)$. We will start at $x=(2,-2)$, for which $f(x)=0$, just as it does at the saddlepoint. The R code, written for clarity instead of efficiency, is: f The trace of the parameter values at each iteration looks like: > matplot(x_history, xlab='Iteration count', ylab='Parameter values') Or, superimposed on the de-noised function: > f_values M surf3D(x=M$x, y=M$y, z=f_values(M$x, M$y), theta=30) > scatter3D(x=x_history[,1], y=x_history[,2], z=f_values(x_history[,1], x_history[,2]), type='b', add=TRUE, pch=19, colkey=FALSE) As we can see, the algorithm is, give or take some randomness, moving towards $x = (0,0)$ along the line $f(x) = 0$. In this iteration of the answer, it actually jumped almost all the way there on iteration 4. One common approach to forming the final estimate of the optimum parameter values is to average over some number of iterations. This isn't useful if alpha = 1 for technical reasons, but is more useful as alpha -> 0.606 (the lowest it should be.) For our sample run, we get: > colMeans(x_history[4:51,]) [1] 0.1106594 0.0896351 > f_values(0.1106594, 0.0896351) [1] 0.004211052 which isn't too bad, given that we have done no parameter tuning. Note that because the values at each step are going to be autocorrelated, the sample standard deviation will be biased, although you could remove a lot of the bias by applying a simple ARMA model to the series over the iterations where it seems to have stabilized and using the resulting estimates. Of course, your mileage will vary. It may be that you require several hundred iterations to achieve convergence, which given your function evaluation times might take several hours of computation. Parameter tuning may also take some considerable time. There are second-derivative versions that converge more quickly when you get in the neighborhood of the optimum, but require somewhat more coding and parameter tuning. There is a structured way of selecting the $\Delta$ at each iteration that may speed convergence a little. But, generally speaking, I haven't found any off-the-shelf techniques for optimizing stochastic functions that are as good across as wide a range of problems as SPSA and its variants.
