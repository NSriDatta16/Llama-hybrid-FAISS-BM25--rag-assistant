[site]: crossvalidated
[post_id]: 183038
[parent_id]: 182958
[tags]: 
The output of the logistic model is a calibrated probability (not a classification or pseudo-probability as produced by many machine learning algorithms) - thus you can change the cost simply by changing the probability cut-off used for classification. So instead of using the default 50% probability cut-off you can try any cut-off 0-100% probability. It is often worth checking model calibration using a test set if you want to explore this visually, you can use the AUC curve and a family of cost lines. The gradient of the cost lines = (1-p)CFP/pCFN with p=prevalence. So if fraud 1% of time, cost FP to FN 1:5 then gradient = 19.8. The optimal point is the point of the AUC where a line with this gradient forms a tangent with curve. Relatively low prob cut-off with low sensitivity and high specificity In practice usually use crossvalidation or test data to optimize probability cut-point to a given ratio of FP/FN (I think there is a formula to derive this cut-point but can never find it when I'm looking for it)
