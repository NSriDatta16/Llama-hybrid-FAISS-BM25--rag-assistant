[site]: crossvalidated
[post_id]: 253201
[parent_id]: 
[tags]: 
Projected Gradient Descent

Consider the primal SVM problem: $$ \frac12||w||^2 +\frac Cm \sum_{i=1}^m \max(0,1-y_iw\cdot x_i) $$ We want to find a solution with a bounded norm, by using SGD with a projection onto the convex set: $ K=\{x | ||x|| \le R \} $ Concretely, the update step would be $w_{i+1}=\Pi_K(x_i-\eta_i \nabla f(x_i))$, where $\Pi_K(x):=\arg \min_{z\in K}||z-x||$. I'm trying to figure a way to actually calculate the projection. Is there a simple algorithm to do this? (My first thought here, is that this is another optimization problem, which maybe can be solved with another SGD...)
