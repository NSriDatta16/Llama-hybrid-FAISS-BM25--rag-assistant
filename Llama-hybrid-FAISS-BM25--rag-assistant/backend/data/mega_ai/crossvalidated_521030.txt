[site]: crossvalidated
[post_id]: 521030
[parent_id]: 
[tags]: 
Is there any meaning to using several validation metrics in cross validation for logit models?

My question might be a bit dumb since I'm relatively new to analysises using k-fold CV, but here goes: I want to compare two logit models using k-fold CV, and then compare with another model type on a held out test set. Until now I have usually just computed one metric during the CV, which is the rate of incorrect classifications. But would it make sense to compute other validation metrics for model selection? Such as pseudo-R^2 and Likelihood Ratio? Or do I select the one that has the lowest average rate of incorrect classifications, use it to make predictions on the test data, and then compute the validation metrics they have in common?
