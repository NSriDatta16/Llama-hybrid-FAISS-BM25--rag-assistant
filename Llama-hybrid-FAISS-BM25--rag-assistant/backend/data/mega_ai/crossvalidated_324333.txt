[site]: crossvalidated
[post_id]: 324333
[parent_id]: 324208
[tags]: 
They output 6 of their own images, basically showing where those edges were detected. That's not exactly like this. Convolutional filters (a.k.a. kernels) don't show where the edges are detected, they show what kinds of edges are most descriptive subject to the training images and the loss function. It just so happens that simple shapes such as edges and corners are very helpful for the future layers. HOWEVER, the problem I see is that to combine edges, what you really want is to see that edge 1 is connected to edge 2 is connected to edge 3, forming a triangle or something like that. Also not exactly like that. Each convolutional layer doesn't take the filters as input (the filters are usually small, e.g. 3x3), they take the training input image after applied the previous convolution and non-linearity (we can ignore downsampling, batch-normalization and other complications for this discussion). It is true that the convolutional layer is boosting the signal, where the filter has matched. Hence, the second layer will likely see higher values at the edges (enhanced by the first layer). But it's still the input image, which will probably have a lot of details and complex shapes in it. In other words, it is possible to learn a triangle-like shape, even though the lower layer doesn't have filters exactly like triangle edges. Realistically, it could be a combination of different edges, enhanced by different filters. But, to be fair, many of the deeper layers' filters aren't easily interpretable to make any firm conclusions (see also this discussion on AI.SE ). Hope this clarifies the learning process inside a CNN. Also, maybe related but maybe not: Is there an intuition for why we want smaller images but more filters as we go deeper in the network? What purpose does that serve? If by images you mean filters, the latest tendency is to use small filters all the time: since VGGNet, 3x3 seems like a standard, Inception was the first network to apply asymmetrical 1x3 and 3x1 filters, now they are also very common. But it is true that the number of filters usually increases in the deeper layers, because the earlier layers serve as feature extractors , so that the deeper layers learn more complex shapes. Increasing feature complexity naturally demands more filters for CNN to work better.
