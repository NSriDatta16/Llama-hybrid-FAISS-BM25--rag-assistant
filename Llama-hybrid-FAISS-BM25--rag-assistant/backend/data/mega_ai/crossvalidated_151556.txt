[site]: crossvalidated
[post_id]: 151556
[parent_id]: 
[tags]: 
Random Forest Underfitting

I am running a random forest for different sets of data, with an attempt to make it dynamic enough to optimize for all sets of data (they are are similar data sets). There are around 150 predictor variables. What is the main reason for underfitting in a random forest? How do you achieve the optimal amount of bias and variance. Which one is better to introduce over the other? Better yet is, there an intuitive way to make an RF optimize using the parameters - "n"-number of trees grown and "r" to solve for this. I moved away from OLS to see if RF could handle a much larger amount of predictor variables with a smaller set of sample data. Any help is much appreciated!
