[site]: crossvalidated
[post_id]: 162589
[parent_id]: 162532
[tags]: 
All three methods have different assumptions and way of calculating components. These are data transformation techniques and the actual dimension reduction depends upon the correlation between the variables. For example in PCA, the eigen values represent percentage variance explained by the PCs. These are eigen values of the correlation matrix of the data. Suppose in my data analysis I see my eigen values are not very different. This means my variables are not very highly correlated. If I decide to choose few PCs for the purpose of dimension reductions, I am actually loosing valuable information (I wont do it). On the other hand if the first few eigen values are large compared to the rest, I can happily perform dimension reduction without loosing valuable information. you may look at the scree plot for this pattern. Similarly ICA focuses on Independence and FA assumes N(0,1) factors and the rest as error. To perform FA you need to decide on the number of factors and that may not be easy for all kind of problems. To summarize - you should evaluate the result in context with your data and have a theoretical understanding of these techniques.
