[site]: crossvalidated
[post_id]: 312868
[parent_id]: 311831
[tags]: 
If you think that first convolutional layer extracts simple features, like lines, than the next convolutional layer has to combine these lines into more complected structure. Basically, each channel in the next layer responsible for the combination of different lines into more complicated structure. Since structure getting more complicated there are getting more features that you can construct from simple lines. If you think of lego-building classifier. First layer learns basic building lego-blocks, the second one looks for what things you can construct using these blocks and clearly there are way more things that you can build from basic building blocks. Another analogy is a digital number classifier. You have 7 LEDs in one matrix, which means that you can learn using first layer all 7 lines (or maybe 2 if you learn that there is one horizontal and one vertical line, just in different places). Using just 7 features you can construct 10 different digits. In addition to it, you can construct letters, like L, A, H and so on. So in the next convolutional layer, you should have more than 7 layers in order to be able to learn different letters and digits. These are toy-examples, but the same intuition you can extend to more realistic problems that large convolutional neural networks are trying to solve
