[site]: datascience
[post_id]: 106541
[parent_id]: 106533
[tags]: 
The procedure that you can use is the following. First cluster your data with gaussian mixture models. This method should also work with multiple lines with different slopes. It should be able to deal with intersections as points near an intersection can belong to both clusters and a wrong classification will not lead to huge differences in the results of the regression. I will post the complete code. # Your code for generating the data import numpy as np import matplotlib.pyplot as plt np.random.seed(42) slope = 2.4 offsets = np.arange(0,500,100) xslist=[] yslist=[] for offset in offsets: size = np.random.randint(low=50,high=100) xs = np.random.uniform(low=np.random.uniform(-5,-2), high=np.random.uniform(2,5),size=size) ys = slope * xs + offset + np.random.normal(loc=0, scale=0.1, size=1) + np.random.normal(loc=0, scale=0.01, size=size) xslist.append(xs) yslist.append(ys) xs = np.concatenate(xslist) ys = np.concatenate(yslist) We will use your data points to generate multiple gaussian mixture models. We will fix the number of components by using the number of components with the minimal value of the Bayesian Information Criterion (BIC). # Create multiple Gaussian Mixture models from sklearn.mixture import GaussianMixture X = np.vstack((xs, ys)).T n_components = np.arange(1, 21) models = [GaussianMixture(n, covariance_type='full', random_state=0).fit(X) for n in n_components] # Get optimal number of components by using the index of the components with the minimal value for the Bayesian Information Criterion (BIC) n_components_optimal = np.argmin(np.array([model.bic(X) for model in models])) + 1 Plot the results and see how well the clustering with the optimal number of clusters works. # Code for plotting gaussian_mixture_model_optimal = GaussianMixture(n_components_optimal, covariance_type='full', random_state=0).fit(X) labels = gaussian_mixture_model_optimal.predict(X) plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis') Now, use the clustered data and create subdataframes from them and fit your linear regressions. import pandas as pd df = pd.DataFrame({ "x": xs, "y": ys, "cluster": labels, }) # cluster_number = 1 X_sub = df.query('cluster == @cluster_number').values
