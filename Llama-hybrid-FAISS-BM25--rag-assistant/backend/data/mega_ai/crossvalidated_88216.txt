[site]: crossvalidated
[post_id]: 88216
[parent_id]: 
[tags]: 
Is the p-value equivalent to the false alarm value in the Bayesian rule?

Is a p-value from a traditional significance test the same as the false alarm value in the Bayesian rule? And/or is it "close enough" to give correct results when used that way? The definitions of the two terms seem to be talking about the same things, but I know it's easy to be tripped up by subtleties. Wikipedia says that a p-value is "the probability of obtaining a test statistic at least as extreme as the one that was actually observed, assuming that the null hypothesis is true." This page says the false error rate P(D|H') in the Bayesian rule is the probability of observing D if H' is true. In both cases, you are talking about the probability of seeing data that says H when the reality is H'. However, I see two possible problems with assuming that the two are equivalent: D in the definition of P(D|H') seems to refer to a single datum, while the definition of a p-value seems to refer to a range of values ("at least as extreme as"); and I'm not quite smart enough to figure out whether H' is equivalent to the null hypothesis. In all the simple Bayesian examples I've worked through it certainly seems to be, but I haven't yet found a definitive statement. I also haven't found a definitive statement of how p-value and the false alarm value are related if they aren't the same, given that they're both saying at least loosely analogous things about data and hypotheses.
