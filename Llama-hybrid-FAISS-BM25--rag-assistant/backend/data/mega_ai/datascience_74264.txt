[site]: datascience
[post_id]: 74264
[parent_id]: 61563
[tags]: 
From the top of my head I think you could build something similar to an autoencoder. $X$ as input, $Y$ as label: $Y' = f_\theta(X) \approx Y$ as label, $f_\theta$ is a Neural Network, $\theta$ the weights and your loss $\mathcal{L} = d(Y,Y')$ , where $d$ is some convex distance measure like Mean-Squared-Error or Binary-Crossentropy (if you scale your output and labels between $(0,1)$ ). If you have new data $\{\hat{X},\hat{Y} \}$ , feed $\hat{X}$ to your network $f_\theta$ and look for the sample in $\hat{Y}$ which has the minimal distance $d(\hat{Y},\hat{Y'})$
