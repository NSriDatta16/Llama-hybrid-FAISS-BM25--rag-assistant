[site]: crossvalidated
[post_id]: 384827
[parent_id]: 
[tags]: 
What types of AI can learn (evolve) from self play in domains that aren't 'real time'

I'm not sure if all my terminology is on point so I'll try to explain what I mean in detail, with an example. This is purely a learning exercise for myself! I have a game that I want my AI to learn to play. It's turn based, so when thinking about how best to program for it I fall back onto the typical chess/checkers examples. In the past when I've played with AI's the learn to play games by just playing the game and being scored I use NEAT mainly because I've seen the power of NEAT in so many papers and you tube videos. However the way NEAT works requires that there is a natural 'lag' between information into the network and responses out. This is because networks developed by NEAT can have connections that go from any node to any other node, it can have feedback loops and all sorts of funky connections; because of this the network just processes each nodes outputs through it's connections. Each time the network is processed everything just moves one step. My game at the moment is turn based, so is there a type of AI (ideally something that can be applied to neural networks) that allows agents to learn via self play, or more to the point allows agents to evolve using the principals of genetic algorithms via self play in a domain where the game is turn based? I hope I've explained myself well enough, if not please ask questions in comments! Edit #1 There's been a vote suggesting that this question may be too broad. My intention here is to find the name of a group of AI's (or just one, if only one exists) that can handle neural network evolution whilst allowing the input data to be fully processed (not including a latency). I hope that helps to make the question a little narrower.
