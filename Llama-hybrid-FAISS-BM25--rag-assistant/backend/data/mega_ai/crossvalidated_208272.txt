[site]: crossvalidated
[post_id]: 208272
[parent_id]: 
[tags]: 
Model Averaging: Standard Error vs Adjusted Standard Error

I'm having trouble understanding when to use Std. Error or Adjusted SE in model averaging (model.avg). What/Why/When to use Adjusted SE? This is my code: > summary(mdavg) Component model call: lm(formula = , data = MA_data) Component models: df logLik AICc delta weight 23 4 -96.07 200.68 0.00 0.25 13 6 -93.93 201.02 0.34 0.21 3 3 -97.41 201.14 0.46 0.20 123 7 -92.83 201.22 0.54 0.19 2 3 -98.64 203.60 2.92 0.06 12 6 -95.60 204.35 3.67 0.04 (Null) 2 -100.23 204.61 3.93 0.04 Term codes: yr.code age BW 1 2 3 Model-averaged coefficients: (conditional average) Estimate Std. Error Adjusted SE z value Pr(>|z|) (Intercept) 1.03200 1.22743 1.23930 0.833 0.4050 age 0.08546 0.05461 0.05548 1.540 0.1235 BW 0.08255 0.03523 0.03579 2.306 0.0211 * yr.codeone -0.16072 0.26381 0.26794 0.600 0.5486 yr.codethree 0.19479 0.25988 0.26415 0.737 0.4609 yr.codetwo -0.45875 0.23784 0.24174 1.898 0.0577 . In Burnham & Anderson 2002 they talk about Adjusted Standard Errors but it is going over my head: We will hazard a suggestion here; it has not been evaluated in this context, but a similar procedure worked in a different context. If for each fitted model we have degrees of freedom $df_i$ for the estimator ${\rm Var}(\hat θ_i|g_i)$ , then for generally small degrees of freedom one might try using the interval $\hat θ_i ± z_{1−α/2} {\rm ase}(\hat θ_i)$ , where the adjusted standard error estimator is
