[site]: crossvalidated
[post_id]: 387836
[parent_id]: 162257
[tags]: 
Suppose that our training observations are the feature vectors $x_1,\ldots, x_N \in \mathbb R^n$ , and the corresponding labels are $y_1,\ldots,y_N \in \{-1, 1 \}$ . For notational simplicity, let's append a $1$ to the end of each vector $x_i$ . The perceptron algorithm can be interpreted as using stochastic subgradient descent to solve the optimization problem \begin{align} \tag{1}\text{minimize} & \quad \frac{1}{N}\sum_{i=1}^N \max(-y_i\beta^T x_i,0). \end{align} The optimization variable is $\beta \in \mathbb R^{n+1}$ . From this perspective, the difference between the perceptron algorithm and logistic regression is that the perceptron algorithm minimizes a different objective function . (The derivation of logistic regression via maximum likelihood estimation is well known; in this post I'm focusing on the interpretation of the perceptron algorithm.) The objective function in problem (1) can be written as $\frac{1}{N}\sum_i \ell_i(\beta)$ , where $$ \ell_i(\beta) = \max(-y_i \beta^T x_i,0). $$ A subgradient of $\ell_i$ at $\beta$ is the vector $$ g = \begin{cases} 0 & \quad \text{if } -y_i \beta^T x_i \leq 0 \qquad \text{(so $y_i$ and $\beta^T x_i$ have the same sign)}\\ - y_i x_i & \quad \text{otherwise.} \end{cases} $$ Each epoch of stochastic subgradient descent (with step size $t > 0)$ ) sweeps through the training observations and, for the $i$ th observation, performs the update $$ \beta \leftarrow \beta - t g = \begin{cases} \beta & \quad \text{if $y_i$ and $\beta^T x_i$ have the same sign} \\ \beta + t y_i x_i & \quad \text{otherwise.} \end{cases} $$ We recognize that this is the iteration for the perceptron algorithm (with learning rate $t$ ).
