[site]: crossvalidated
[post_id]: 111228
[parent_id]: 
[tags]: 
Gibbs Sampling Detecting Change point in time series

I was reading through this one page paper on using Gibbs sampling for detecting a change point in a time series like data. While I understand the part where the $\lambda$ and $\phi$ are chosen from a gamma distribution I do not understand how the author generated the posterior distribution for $k$. My thinking is, if the first $k$ points came from a Poisson distribution then the probability of $P(k|\lambda,\phi,Y_i)$ $$ P(k|\lambda,\phi,Y_i) = \Pi_{i=1}^{k}\frac{e^{-\lambda}\lambda^{Y_i}}{Y_i!} \times \Pi_{i=k+1}^{N}\frac{e^{-\phi}\phi^{Y_i}}{Y_i!} $$ The author shows an expression of the form $\frac{A}{B}$ where $B$ is the normalizing term. This part I understand. However it is unclear to me how he found the numerator term which appears to be a log of $$ P(k|\lambda,\phi,Y_i) = \frac{\Pi_{i=1}^{k}\frac{e^{-\lambda}\lambda^{Y_i}}{Y_i!}}{\Pi_{i=k+1}^{N}\frac{e^{-\phi}\phi^{Y_i}}{Y_i!}} $$ How does he arrive at that? Any help appreciated. Thanks in advance
