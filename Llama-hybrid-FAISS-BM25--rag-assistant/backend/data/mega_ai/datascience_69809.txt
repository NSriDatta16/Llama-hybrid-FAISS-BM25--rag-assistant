[site]: datascience
[post_id]: 69809
[parent_id]: 
[tags]: 
LSTM loss value not change, accuracy stucked at 50%

I'm using LSTM for time series prediction, my data is highly skewed, with class weight 197.16865807 : 0.50127117 With Label 0 : 25359 and Label 1 : 9974641 my model is shown below n_input = 100 n_features = 36 class_weights = class_weight.compute_class_weight('balanced', np.unique(y_target), y_target) model = tf.keras.Sequential([ tf.keras.layers.LSTM(64, activation='tanh', input_shape=(n_input, n_features),return_sequences = True), tf.keras.layers.LSTM(64, activation='tanh',return_sequences = True), tf.keras.layers.LSTM(64, activation='tanh',return_sequences = True), tf.keras.layers.LSTM(64, activation='tanh',return_sequences = True), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dense(1,activation='sigmoid')]) model.compile(optimizer='adam', loss= 'binary_crossentropy' ,metrics=METRICS) model.fit_generator(train_generator, epochs= 1,steps_per_epoch=len(train_generator),class_weight=class_weight) I have tried the following method to dealing with my unchanged accuracy and loss value. I tried to adjust class weight, but it seems not working, my predictions are all 1 I tried to use RandomSampler from imblearn to undersample my data, but the accuracy stucked at 50% I tried to change the loss function to weighted_cross_entropy_with_logits , but I did not find any examples show how to use it in Sequential model like the one above I feel my model is not predict the result, since when I feed balanced dataset, the accuracy is around 50% , when I feed imbalanced dataset, the accuracy is 99% . Can anyone help me with this? I wondering if it's the problem of my model, or the problem of my imbalanced dataset Thank you!
