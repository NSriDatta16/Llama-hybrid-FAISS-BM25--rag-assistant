[site]: crossvalidated
[post_id]: 635407
[parent_id]: 
[tags]: 
Does this loss curve indicate overfitting?

I am proposing unsupervised training using python and graph neural network. I am using (SAGE) as main GNN layer, tanh as activation function and SGD optimizer with learning rate = 0.05, momentum= .9, weight_decay=0.01 my loss curve is showing this result, why it does not converge smoothly and instead it oscillates? does that mean overfitting, what is the name of this scenario any help is appreciated
