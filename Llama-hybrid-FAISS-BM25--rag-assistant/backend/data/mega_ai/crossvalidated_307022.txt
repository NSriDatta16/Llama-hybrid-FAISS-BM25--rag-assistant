[site]: crossvalidated
[post_id]: 307022
[parent_id]: 306977
[tags]: 
For a test, the power is the probability to say "no" when it is "no". It depends on: the "distance" between the real parameter $\theta$ and the parameter $\theta_0$ of the null hypothesis : how much the real distribution is different from the tested one. "When it's no" is not a binary concept but a continuous one. the number of samples the $\alpha$ being chosen Typically, testing if a coin is unbiased has very small power when the real coin has head probability equal to 0.49999 (and say usual $\alpha$). Expect if you have billions of trials. The efficiency of an estimator is (can be) measured by the average standard error: $\sqrt{E((\hat\theta-\theta)^2)}$. You could define the efficiency as the inverse of the error. The smaller error, the better estimator. The efficiency also grows with the sample size but unlike a test it is does not depend on the distance to a null hypothesis (there is no null hypothesis here) nor a $\alpha$ convention. So both functions grow with the sample size, but they are different functions. Crucially one of them depends on a d($\theta_0$,$\theta)$ which does not exist for the other one. In a case such as t-test you will find a $\sqrt{n}$ term somewhere in both functions where $n$ is the sample size but apart from this the functions are just different.
