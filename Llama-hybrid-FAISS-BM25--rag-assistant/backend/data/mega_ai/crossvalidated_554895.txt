[site]: crossvalidated
[post_id]: 554895
[parent_id]: 554875
[tags]: 
There are a few different diagnostic options you can do prior to a sensitivity analysis. Typically, these weights are referred to as inverse probability of treatment weights (IPTW) (IPSW generally stands for inverse probability of sampling weights). Linked here are some diagnostic examples that may be useful. I will list some diagnostic you may want to consider. Then a few sensitivity analysis options Diagnostics First, you can assess the mean weights between the treated and untreated. For unstabilized IPTW the mean should be 2 and stabilized IPTW the mean should instead be 1. Next, you can look at the distribution of the propensity scores. There should be good overlap between the groups. If there isn't, this indicates either positivity issues or your propensity score model is misspecified (you won't know which by the plot alone). If there is non-overlap, this would indicate truncation or trimming should be used. Another plot is the love plot (example also at the link). This can visually display the marginal balance of covariates in the unweighted and weighted data. Sensitivity Analyses If you had to trim the propensity scores so that the weights were well-behaved, you can trim the propensity scores are a number of places and see how estimates change. I would also recommend this paper which details best practices on constructing IPTW. That paper also points to a few sources on how to run a sensitivity analysis on unmeasured confounders. There are both the 'theory' papers and a few applied examples provided. Unmeasured Confounders In response to the comments, there is a sensitivity analysis that you can still consider. The following is the one mentioned in the last sentence and described in Robins 1999 . This sensitivity analysis is principally for estimation of the average treatment effect (not the hazard ratio) and is most informative when there is outside information on the unmeasured confounder (e.g., it is a variable that wasn't measured in your study, but something is known about it in your population). First, consider the function $$q(a,a^*,W) = E[Y^a | W, a] - E[Y^a | W, a^*]$$ where $a$ is the true, $a^*$ is what is estimated in the study, $Y^a$ is the potential outcome, and $W$ is the measured confounders. If $a=a^*$ , then $q(a,a^*,W) = 0$ , which is the 'no unmeasured confounding' assumption. The idea behind the sensitivity analysis is that while we can't ever verify this assumption, we can specify some non-zero function for $q(a,a^*,W)$ . We can then take that function and see how the estimated ATE changes across a single function $q(a,a^*,W)$ or a collection of $q(a,a^*,W)$ functions. As stated earlier, this sensitivity analysis is most informative when we have a good idea of what $q(a,a^*,W)$ looks like (it would narrow the collection of functions we would have to look at in the sensitivity analysis). For how to apply this sensitivity analysis: see pages 169-170 of Robins 1999 (linked above), Brumback et al. (2004) , Ko et al. (2003) , or Cole et al. (2005) . I would recommend the Brumback et al. for the most details on this approach. However, as I stated before, the idea behind this sensitivity analysis focuses on the average treatment effect, not the hazard ratio (which is the output of the Cox PH model). There may be an extension of this type of sensitivity analysis for hazard ratios, but I am unaware of it.
