[site]: datascience
[post_id]: 41792
[parent_id]: 41785
[tags]: 
The values that are far out of the core distribution are called as outliers. In general, we do not want to have outliers in the features since we want generalization. Outliers are the points that are found rarely but increase the error inproportional to the general distribution of your samples. Outliers strongly pull the model through themselves upon training since they create large errors where the optimization task is to minimize it. If you do not have outliers on your dataset at the training set, do not expect your model to perform well on those points since it has no experience on those. If you have outliers in your training dataset, your model will lose some generalization (it will perform worse in overall), yet your model will perform better at outliers. Your model can only learn what you give at it, neither classic machine learning algorithms nor neural networks are magicians. Hope I could help. If not, I will be around.
