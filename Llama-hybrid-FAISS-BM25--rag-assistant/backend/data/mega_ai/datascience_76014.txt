[site]: datascience
[post_id]: 76014
[parent_id]: 76013
[tags]: 
You can do mainly two things: bootstrap or oversampling. With statistical data you can do bootstrapping (random sampling with replacement) Bagging method s help boosting you model accuracy. The pseudocode will be a bit like this. for estimator in range(number of estimators): Sampling some data Fitting a model Predicting mean(predictions) This way you are able to train different models with the same sample of data and helps in boosting accuracy. Well known as Random Forest use this technique. There is other way to create synthetic data and they are the oversampling/undersampling techniques that you can have a look in the imblearn documentation . Techniques like SMOTE (Synthetic Minority Over-sampling Technique) are sometimes used, but they generate synthetic data. With statistical data you can not rotate, add brightness...
