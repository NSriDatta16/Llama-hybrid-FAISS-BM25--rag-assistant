[site]: crossvalidated
[post_id]: 331024
[parent_id]: 
[tags]: 
Understanding the equivocation inequality for channel entropies: $H(\mathcal B\vert\mathcal A)\le H(\mathcal B)$

Background Consider a channel $\Gamma$ with input $\mathcal A$ and output $\mathcal B$ (I'm following the notation in Jones and Jones ). We define the input and output entropies as $$H(\mathcal A)=\sum_i p_i \log\frac{1}{p_i}, \qquad H(\mathcal B)=\sum_i q_j \log\frac{1}{q_j}. $$ One can then define the conditional entropies as $$H(\mathcal A\vert\ b_j) = \sum_i \Pr(a_i|b_j)\log\frac{1}{\Pr(a_i|b_j)},$$ and $$H(\mathcal B\vert\ a_i) = \sum_j \Pr(b_j|a_i)\log\frac{1}{\Pr(b_j|a_i)}.$$ I can easily understand the meaning of such conditional entropies: they quantify the uncertainty associated with the input (output) of the channel, in the situation in which one knows that a specific output (input) has been produced. One can then go on and define the equivocation of the channel as the following quantity: $$H(\mathcal B|\mathcal A)=\sum_i p_i H(\mathcal B|a_i),$$ and similarly for $H(\mathcal A|\mathcal B)$. In other words, the equivocation is the average of of the conditional entropies. One can then go on and show results such as $$H(\mathcal A\vert\mathcal B)\le H(\mathcal A),\\ H(\mathcal B\vert\mathcal A)\le H(\mathcal B).$$ Question What I'm struggling with is to understand what $H(\mathcal A\vert\mathcal B)\le H(\mathcal A)$ represents. In Jones and Jones it is stated (chapter 4.3) that $H(\mathcal A|\mathcal B)$ represents (...) the receiver's average uncertainty about $\mathcal A$ when receiving $\mathcal B$, or equivalently, how much extra information would be gained by also knowing $\mathcal A$. What I don't find clear about this is that it seems to state that $H(\mathcal A|\mathcal B)$ somehow represents uncertainty over the input under the assumption of knowing the output . But how is this the case? With $H(\mathcal A|b_j)$ we are assuming to know the output, sure thing, but with $H(\mathcal A|\mathcal B)$ we are averaging over the possible realizations of the output, therefore we do not really know it.
