[site]: crossvalidated
[post_id]: 577718
[parent_id]: 
[tags]: 
Is "sensitivity at fixed specificity" a valid metric for comparing different classifiers?

For a given dataset, a common way to compare 2 classifiers is to compare their average validation accuracies using cross-validation. Is it valid to replace the accuracy with other classification metrics that I care more about? For example, say I care about the sensitivity (recall) at a given specificity level (say 0.99). Is it still valid to compare A and B by computing the average sensitivities using cross-validation? (for each fold, train the model, plot the ROC curve, get the recall for specificity=0.99)
