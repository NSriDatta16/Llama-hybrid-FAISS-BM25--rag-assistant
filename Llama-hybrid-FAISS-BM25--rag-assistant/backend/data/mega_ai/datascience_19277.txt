[site]: datascience
[post_id]: 19277
[parent_id]: 19276
[tags]: 
First of all good job done in processing the data and coming up with your base model. I would suggest few things that you can try: Improve your model my adding bigrams and tri-grams as features. Try doing some topic modelling like latent Dirichlet allocation or Probabilistic latent Semantic Analysis for the corpus using a specified number of topics - say 20. You would get a vector of 20 probabilities corresponding to the 20 topics for each document. You could use that vector as input for your classification or use it as additional features on top of what you already have from your base model enhanced with bigrams and trigrams. Another thing I would say is try using a tree based classifier ensemble to capture non-linearity and interactions between the features. Either of random forest or gradient boosting would be fine. In gradient boosting you can use xgboost as its a pretty good package that gives good classification. If you are familiar with Deep Learning you can give a try with a Recurrent Neural network architecture(mostly the LSTM versions). Hope this helps and let me know if this improves your classification accuracy.
