[site]: crossvalidated
[post_id]: 226653
[parent_id]: 226593
[tags]: 
I think this may be my answer. If LSTM don't use recurrent projection layer and non-recurrent projection layer, use this equivalent. (nc*nc*4*di)+(ni*nc*4*di)+(nc*no)+(nc*3*di) nc = number of LSTM cells ni = number of input no = numbre of output di = number of layers if LSTM use projection layer, number of weights obtain from this: (nc*nr*4*di)+(ni*nc*4*di)+((nr+np)*no)+(nc*nr*di)+(nc*3*di)+(nr*nc*4*(di-1)) nr = number of recurrent projection layer np = number of non-recurrent projection layer For my exmaple : I use recurrent layer too. Recurrent projection layer = 256 Non-recurrent projection layer = 256 (1024*256*4*3)+(39*1024*4*3)+((256+256)*34)+(1024*256*3)+(1024*3*3)+(256*1025*4*(2)) = 6535168 = 6.5M I used this reference: LONG SHORT-TERM MEMORY BASED RECURRENT NEURAL NETWORK ARCHITECTURES FOR LARGE VOCABULARY SPEECH RECOGNITION
