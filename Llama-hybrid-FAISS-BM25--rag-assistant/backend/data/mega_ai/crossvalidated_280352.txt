[site]: crossvalidated
[post_id]: 280352
[parent_id]: 
[tags]: 
Visualizing High Dimensional weight space for perceptrons

I am watching the Neural Network videos by Prof. Geoff Hinton. In there he talks about a high dimensional Weight Space for perceptrons. In particular, I am referring to following two slides. Also here is a link to the timestamped youtube video where he describes this weight space : https://youtu.be/0T57_yjjB58?list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9&t=80 Questions: Why is the training case a plane? Why is this plane through origin? Why is the input vector perpendicular to this plane? How is the input vector different from the training case?
