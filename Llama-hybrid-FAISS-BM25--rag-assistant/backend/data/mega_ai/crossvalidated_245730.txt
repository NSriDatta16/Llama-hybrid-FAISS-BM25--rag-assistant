[site]: crossvalidated
[post_id]: 245730
[parent_id]: 
[tags]: 
Empirical probability and Dirac distribution

According to Deep Learning p.65(Ian Goodfellow and Yoshua Bengio and Aaron Courville, available online): (...) This can be accomplished by defining PDF using the Dirac delta function $\delta(x)$: $$p(x)=\delta(x-\mu)$$ (...) By defining $p(x)$ to be $\delta$ shifted by $\mu$ we obtain infinitely narrow and infinitely high peak of probability mass where $x=\mu$. A common use of Dirac delta distribution is as a component of an empirical distribution, $$\widehat{p}(x)=\frac{1}{m}\sum_{i=1}^{m}\delta\left(x-x^{(i)}\right)$$(where $x^{(i)}$ are our data empirical datapoints). My questions are: 1) Can we think of $\widehat{p}(x)$ as a kernel density estimator with the kernel $K()$ defined as the Dirac function at zero? 2) How can we calculate the mean of Dirac function? 3) What is the intuition behind the above empirical probability distribution $\widehat{p}(x)$? 4) If $x=x^{(i)}$ then $\widehat{p}\left(x=x^{(i)}\right)=+\infty$?
