[site]: datascience
[post_id]: 17364
[parent_id]: 
[tags]: 
Gradient Boosting Tree: "the more variable the better"?

From the tutorial of the XGBoost, I think when each tree grows, all the variables are scanned to be selected to split nodes, and the one with the maximum gain split will be chosen. So my question is that what if I add some noise variables into the data set, would these noise variables influence the selection of variables (for each tree growing)? My logic is that because these noise variables do NOT give maximum gain split at all, then they would never be selected thus they do not influence the tree growth. If the answer is yes, then is it true that "the more variables the better for XGBoost"? Let's not consider the training time. Also, if the answer is yes, then is it true that "we do not need to filter out non-important variables from the model". Thank you!
