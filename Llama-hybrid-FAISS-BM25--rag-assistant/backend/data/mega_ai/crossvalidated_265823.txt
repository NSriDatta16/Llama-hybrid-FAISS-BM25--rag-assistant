[site]: crossvalidated
[post_id]: 265823
[parent_id]: 
[tags]: 
Cross validation with Test_size = 1% of the whole dataset; am I violating any machine learning rule?

I have a dataset of 21 classes with 90 samples per class. Each sample is 30s. I want to know what is the minimum number of samples required for the testing (this is for biometrics, so the lower the # of samples the better). I have done a StratifiedShufflesplit (10x10 fold) with 1 and 9 samples per class for the testing. The accuracies I got are: 9 samples: 89.21% 1 samples: 89.38% But I know Andrew Ng recommends to divide data in 80%-20% (training, testing). With 9 samples, I have 90%-10% With 1 sample, I have 99%-1%
