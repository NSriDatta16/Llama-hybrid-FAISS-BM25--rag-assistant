[site]: crossvalidated
[post_id]: 191689
[parent_id]: 
[tags]: 
Question about the Scikit-learn "SVM-Anova: SVM with univariate feature selection" example

Can anyone explain to me why in the Scikit-learn "SVM-Anova: SVM with univariate feature selection" example http://scikit-learn.org/stable/auto_examples/svm/plot_svm_anova.html when we use all features (100 percentile), the model has much better accuracy (90%) than when we use say the top 20 percentile of features (20% accuracy). I'm confused because I think 1) Only the first 64 features are predictive 2) This is a cross-validation measure already Does it mean the ANOVA feature selection has selected many random features with no relation to the dependent variable?
