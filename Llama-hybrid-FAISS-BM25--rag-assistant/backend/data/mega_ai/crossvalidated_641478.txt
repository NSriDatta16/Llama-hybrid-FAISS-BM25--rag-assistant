[site]: crossvalidated
[post_id]: 641478
[parent_id]: 
[tags]: 
For activity recognition with skeletal keypoints data, how can I use videos for training?

I have some training videos and skeletal keypoint data with annotated labels for each activity. There are around 15 activities. After segmenting the keypoint data by their labels, the sample size is around 10k. I have extracted basic features like velocity, acceleration, joint angles and distances. For models, I have tuned a bunch of decision trees and SVM. XGBoost is giving around 80% accuracy. For testing I only have skeletal keypoints. But I still haven't utilized the videos. Is there any feature I can extract directly from the videos for better training? What other features/models can I use to better the accuracy?
