[site]: crossvalidated
[post_id]: 61928
[parent_id]: 
[tags]: 
Choosing non-informative priors

I am working on a model relying on an ugly parametrized function acting as a calibration function on a part of the model. Using a Bayesian setting, I need to get non-informative priors for the parameters describing my function. I know that ideally, I should derivate reference or at least Jeffreys priors but the function is very ugly, have many parameters and I am pessimistic on the possibility to obtain actually a result. So I decided to drop this possibility and to empirically choose my priors prying for them to be quite non-informative. Here are my two questions. Can I make more than prying and give insights of their non-informativness from inference results ? Edit : I guess that plotting posterior Vs prior would be a first point. Maybe comparing MAP and ML estimations could be a second argument ? Moreover, is that make sense to justify some aspect of the choice from a "dimensional analysis"? As an example, if I consider a likelihood structure of the form (in a simple regression setting): $$ Y | a,b,x = a.x+b.e^{-x} + \epsilon $$ Do you think that I can guess any "structure" for the prior on $a$ and $b$ based on the fact that one weighs $x$ while the other weighs $e^x$ ?
