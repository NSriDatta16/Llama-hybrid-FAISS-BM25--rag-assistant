[site]: crossvalidated
[post_id]: 349584
[parent_id]: 349496
[tags]: 
The Neyman-Pearson decision-theoretic approach to hypothesis testing (reject/accept) is closely aligned with Popper's Falsification . This method is not invalid, it just has not accommodated the growing human greed for consumption of knowledge, products, and professional gain. The validity of Popper's approach to science is strongly based on 1. Prespecifying hypotheses 2. Only conducting research with adequate power and 3. Consuming the results of positive/negative studies with equal earnest. We have (in academia, business, government, media, etc) over the past century done none of that. Fisher proposed a way of doing "stats without hypothesis tests". He never suggested that his p-value be compared to a 0.05 cut-off. He said to report the p-value, and report the power of the study. Another alternative suggested by many is to merely report the confidence intervals (CIs). The thought is that forcing one to evaluate a trial's results based on a physical quantity, rather than a unitless quantity (like a p-value), would encourage them to consider more subtle aspects like effect size, interpretability, and generalizability. However, even this has fallen flat: the growing tendency is to inspect whether the CI crosses 0 (or 1 for ratio scales) and declare the result statistically significant if not. Tim Lash calls this backdoor hypothesis testing. There are meandering and endless arguments about a new-era of hypothesis testing. None have not addressed the greed I spoke of earlier. I am of the impression we don't need to change how we do statistics, we need to change how we do science .
