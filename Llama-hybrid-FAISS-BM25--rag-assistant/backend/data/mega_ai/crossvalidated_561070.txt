[site]: crossvalidated
[post_id]: 561070
[parent_id]: 561034
[tags]: 
One of the great advantages of decision trees is their relative robustness against different distributions. Because they simply make axis-parallel cuts in the data, their performance is generally considered invariant to skewness. In other words, one of the big advantages of decision trees is that they are aggressively non-parametric. I can't find any empirical research directly addressing this, but researchers commonly allude to it in there research. See here and here . The biggest limitation seems to be a tendency to struggle with class imbalance, as I found a couple of different research papers that address this. I would note that if possible you should consider random forests as they are substantially better.
