[site]: crossvalidated
[post_id]: 584848
[parent_id]: 584823
[tags]: 
SGD can not be parallelised for a single model in vanilla form because it is a single update sequential algorithm by construction. However, SGD-based parallelisation is possible, running multiple streams of batches to construct (build) multiple models and then combine these models, i.e., model averaging. For neural networks, simple periodic-averaging works Parallel training of DNNs with Natural Gradient and Parameter Averaging . For collaborative filtering, similar approach could be implemented by introducing averaging procedure for the matrices that gives some convergence gurantees.
