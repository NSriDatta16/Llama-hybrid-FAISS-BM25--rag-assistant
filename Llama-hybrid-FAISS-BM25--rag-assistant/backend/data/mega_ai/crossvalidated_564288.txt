[site]: crossvalidated
[post_id]: 564288
[parent_id]: 564274
[tags]: 
First off: Bias and variance of a model are measures of how bad your model is, while over- and underfitting are possible reasons for why your model is bad. Definition of bias and variance Bias and variance are defined e.g. here . The idea is this: You want to learn some function $f(x)$ . You have a lot of datasets $\{D_i\}_{i=1}^s$ , $D_i = ((x_{i1}, y_{i1}), \ldots, (x_{in}, y_{in}))$ , all of size $n$ , and all drawn from the same population. Let's denote this set of datasets with $S$ . Then you train your predictor $\hat f$ on each dataset $D_i$ , so you end up with $s$ different predictors $\hat f_k, k=1,\ldots,s$ . Next, you fix an $x$ and you compute the sample mean and the sample variance of all your $s$ predictors on this single $x$ : $$ \begin{align} m_{\hat f}(x) &:= avg_i(\hat f_i(x))\\ s^2_{\hat f}(x) &:= avg_i((\hat f_i(x) - m_{\hat f}(x))^2) \end{align} $$ Finally, you define the bias as the difference between $m_{\hat f}$ and the actual value $f(x)$ : $$ bias_{\hat f}(x) = m_{\hat f}(x) - f(x). $$ Of course, the real value $f(x)$ is not known, so you cannot really compute the bias. Nevertheless, you can still reason about it. (To be precise, the real bias and variance of the model at $x$ would only be obtained with $s\to\infty$ .) Note again, that this is dependent on $x$ , i.e. each $x$ can have a different bias and variance. So we don't talk about the variance in a dataset, but about the variance of the predictions $\hat{f}_i$ at $x$ when learning from many different datasets $D_i$ from the same population. If you want to, you could average those over all $x$ which would then yield the average bias and variance of your model. Bias-Variance Tradeoff Often, but certainly not always, changes to your learning procedure that decrease the bias would increase the variance, and the other way around, hence the name bias-variance tradeoff. E.g., reducing the neighborhood size in nearest-neighbor methods would decrease the bias but increase the variance. However, increasing the size of your training dataset would often reduce both your model bias and variance. Connection between over- and underfitting and bias and variance Overfitting usually increases the variance, while underfitting increases the bias: Overfitting means that you have fitted an overly complex model to your training data, so a small variance in your training set can result in a large variance of $\hat f(x_{test})$ at your test data covariate $x_{test}$ . Underfitting, on the other hand, occurs if you fit an overly simple model, that is not capable of adjusting to the peculiarities of your data. So, while $\hat f(x_{test})$ will not vary much at your test data covariate $x_{test}$ (because, being simple, it doesn't have the capacity to), it will often not be capable of "reaching" all points in your dataset, hence large bias.
