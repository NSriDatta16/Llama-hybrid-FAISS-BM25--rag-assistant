[site]: datascience
[post_id]: 115665
[parent_id]: 115649
[tags]: 
Bert is a model that is able to extract meaning from text and make good classifications, even if the text hasn't been learned before. That's why you can train a Bert model with many sentences that cover all classes, and then you should be able to classify any text. https://www.analyticsvidhya.com/blog/2021/12/text-classification-using-bert-and-tensorflow/ https://www.kaggle.com/code/merishnasuwal/document-classification-using-bert This is the most universal solution adapted to any text. Here are all text classification models: https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads They are mostly built to classify sentiment, but they could classify anything, like this one: https://huggingface.co/cardiffnlp/roberta-large-tweet-topic-multi-all?text=I%27m+sure+the+%7B%40Tampa+Bay+Lightning%40%7D+would%E2%80%99ve+rather+faced+the+Flyers+but+man+does+their+experience+versus+the+Blue+Jackets+this+year+and+last+help+them+a+lot+versus+this+Islanders+team.+Another+meat+grinder+upcoming+for+the+good+guys
