[site]: datascience
[post_id]: 49136
[parent_id]: 49074
[tags]: 
Standardization is actually a type of normalization (see below for an explanation of normalization). Generally, the goal of normalization is to scale a distribution in some way so that they may be compared to one another in the future (see below for more detailed explanation of normalization.) However -- The goal of standardization is to specifically, produce a distribution that has mean 0 and a standard deviation of 1. To obtain the standardized distribution you subtract every sample by the mean of the population then divide by the standard deviation of the population: $${\frac {X-\mu }{\sigma }}$$ Frequently in industry (as opposed to academia), people refer to normalization as max-min scaling where the distribution is scaled from 0 to 1. This is probably how you are thinking normalization is defined. However, if you think of max-min scaling, and standardization as both types of normalization you can maybe imagine why you wouldn't want to do both. The goal is to produce distributions that can be compared to one another. One method is enough to do so. Therefore the question is really what is the best way to perform normalization for my specific problem? Generally (and including CNNs as you ask about), its best to go with standardization. In statistics and applications of statistics, normalization can have a range of meanings.In the simplest cases, normalization of ratings means adjusting values measured on different scales to a notionally common scale, often prior to averaging. In more complicated cases, normalization may refer to more sophisticated adjustments where the intention is to bring the entire probability distributions of adjusted values into alignment. In the case of normalization of scores in educational assessment, there may be an intention to align distributions to a normal distribution. (From Wikipedia)
