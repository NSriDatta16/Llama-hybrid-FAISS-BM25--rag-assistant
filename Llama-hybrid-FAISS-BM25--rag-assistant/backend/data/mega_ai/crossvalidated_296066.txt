[site]: crossvalidated
[post_id]: 296066
[parent_id]: 161520
[tags]: 
Old question but I feel the answers are missing an important concept which is ANOVA (Analysis of variance). When we fit a model with categorical variables, logistic or linear regression we will get coefficients for each of the dummy variables, and we get a p_value for each of these variables. It is straightforward to interpret the coefficients but the p_values don't say much. In such a situation I resolve to hypothesis testing. This is straight forward if you are working with R, you can call the Anova function from package 'car'. In Python, this is a type 2 test if you are working with the stats models package. This groups all your dummy variables under one name and gives the significance of that category as a whole. If you manually want to perform this test, let's assume we are performing a logistic regression. We fit one model (say fit1) with the categorical feature. The second model (fit2) without the categorical variable (we omit the dummy variables). We now want to test the significance of that categorical feature. To do this we need to calculate the deviance $$\text{Deviance}=\text{Diviance}_\text{fit1}-\text{Deviance}_\text{fit2}$$ Finally the significance of the catagorical feature as a whole is calculated using the Chi-sq test, $$\text{p_value} = 1-\text{sci.chi2.cdf(deviance,df)}$$ (In python and using scipy) Where df = # Dummy variables for that feature. This procedure also works with continuous features with df=1.
