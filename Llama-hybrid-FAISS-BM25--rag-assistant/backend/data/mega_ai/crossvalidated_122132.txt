[site]: crossvalidated
[post_id]: 122132
[parent_id]: 121077
[tags]: 
I don't think this totally answers your question, but perhaps provides a useful framework. An Asymptotic Preliminary Let $X_{i}$ denote the training data in fold $i$, let $T_i \equiv T(X_i)$ be the trained classifier under data $X_i$, and let $L(T_i, Y_k)$ be the observed loss of the classifier under test data $Y_k$. In all cases, let's assume test data $Y_k$ is independent within and between folds. It will be helpful to consider two limiting cases: (a) $X_i=X_j$ for all $i, j$ and (b) $X_i \perp X_j$ for all $i,j$. Case (a) corresponds to training on a fixed data set, so for large enough $Y$, will give you the conditional risk of your estimator (conditional on the training data $X_i$), while case (b) corresponds to training on completely independent data, and will allow an estimate of the average risk of your estimator (averaging over the distribution of the training data and test data). Now for both cases (a) and (b) you can just invoke empirical process theory to establish that the empirical distribution of $L(T_i, Y_k)$ will converge to its true distribution over independent training and test samples, with the rate of convergence given by standard results on the empirical process. To make this concrete, suppose that $L(T_i, Y_k)$ is zero-one loss, and we are operating under scenario (a). Then we'd have that $L(T_i, Y_k)$ is just the average mis-classification in training set $k$, and for every mis-classification rate $p$, the distribution of $L(T_i, Y)$ (loosely speaking) converges pointwise to a $$N\left(\hat F(p), \frac{\hat F(p)(1-\hat F(p))}{\sqrt n }\right),$$ distribution, where $\hat F(p)$ is the empirical distribution function of the average misclassification. Note that there are some simplifications that you can exploit in the linearity of the training loss $L(T_i, Y_k)$ in observations $Y$ to reduce the previous display to something prettier, I think. So you can see the flavor of this analysis ends up looking like confidence intervals on Binomial variables, because we are converging to something with a variance equal to $p(1-p)/\sqrt n$. But it also would generalize to other losses, like your Rijsbergen's F-measure. What's missing There are (at least) two missing pieces to this. First, it's almost certain that you don't have enough data to want to employ the somewhat absurd cross-validation procedure suggested in (a) and (b). So instead, your training samples and estimators $T_i$ are going to be dependent, and I think that in general it is not possible to estimate the amount of dependence . Cross validation, in general, does something that ends up being a mix of procedures (a) and (b). Section 7.10 in " Elements of Statistical Learning " provides a good discussion on this point. I am pessimistic that that's any solution to be found to this. Secondly, I just gave you an asymptotic result, but if the amount of independent test data $Y$ is small, then the asymptotics will be doubtful. This is how I'd translate your concern about plugging in the estimate for $p$. For this, it seems intuitively likely that you should be able to account for the uncertainty in the plug-in estimate through some sort of monte carlo procedure. Like cross-validation nested within a bootstrap? Or vice-versa?
