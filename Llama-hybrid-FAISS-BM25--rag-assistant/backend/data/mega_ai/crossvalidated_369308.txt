[site]: crossvalidated
[post_id]: 369308
[parent_id]: 367451
[tags]: 
Good p but low R2 This is not a strange situation since you have a lot of data points. You are dealing with a sort of law of large numbers (decreasing probability for small deviation of the mean for large number of data). For larger number of data small deviations of the trend line (R2 is deviation of trend line divided by deviation of the data) become less probable. See the images below for example. set.seed(1) layout(matrix(1:3,1)) for (i in 1:3) { n $`Pr(>F)`[1]-0.01) `Pr(>F)`[1] r Improvement of model Your data is basically data of success and failure. For each click/impression you may or may not get a click/conversion. This can be modeled as binomial distributed data (you model the probability to get a success as a function of the variables like campaign gender and interest). Then it is better to use a generalized linear model instead of an ordinary linear regression (it allows a link function but most important of all it allows to model probability of the erro differently, as binary data instead of gaussian distributed data). Below is an example how to put it in code: data $y Total_Conversion,data $Impressions-data$ Total_Conversion) data[1,] mod summary(mod) Call: glm(formula = y ~ as.factor(xyz_campaign_id) + as.factor(age) + as.factor(gender) + as.factor(interest), family = binomial(), data = data) Deviance Residuals: Min 1Q Median 3Q Max -4.8862 -0.4765 0.3319 1.0702 5.7332 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -8.35436 0.21102 -39.590 The actual implementation in the GLM function is not so important for this particular case. For low probabilities of success and high number of trials the binomial distribution is almost the same as the Poisson distribution, and also the link functions are similar in the tail, e.g. $log(p) \approx log(\frac{p}{1-p}) $ How good is the model? I would not use $R^2$ for this type of data (instead use $\chi^2$ to measure goodness of fit). This is because you naturally have a variation in the data because it is Poisson/Binomial distributed or according to some other distribution of counts that is a sum of Bernoulli trials. For instance, imagine you have to model coins that have probability for heads and tails between 0.49 and 0.51. Then your model may very accurately model this small variation (between coins) in the probability, but the data may have a large variation (within repeated flips of a single coin). E.g. if you flip a coin 10 times then it will have a mean close to 5 times heads, but the variance will be 2.5 and you will have a large $R^2$ but your model can not be much better (the data varies with 2.5 but your model only differs between 0.49 and 0.51 for the probability of heads and tails). Something similar occurs when you will model the probability of an impression turning into a click. The model will be over-fitted (even though the $R^2$ is only around 0.25) See the images below (generated with the code below) left a plot of predicted clicks vs observed clicks right a plot of modeled data (average of ten repetitions) using binomial distribution with the predicted value for the probability of v click and the observed number of impressions as the number of trials. Note that the observations are more close to the predictions than the modeled data. This indicates over-fitting (or under-dispersion, making us model the data with too large variance). The imaged below show the results of a Monte Carlo simulation (10 000 times) to estimate the distribution for $\chi^2$ and $R^2$ . The values for the model are: > # compute chi-sq > sum(((npred-data $Clicks)^2/npred)) [1] 586.4344 > # compute R^2 > var(predict(mod, type='response')) / var(data$ Clicks/data$Impressions) [1] 0.275814 The low chi-square value (and also the relatively high $R^2$ ) indicate that the fit is too good to be true. It would be much more plausible to observe $R^2$ around 0.10 and it should not be expected that a model with a higher value is truly a better model. To expect a low $R^2$ is simply due to the variability of the measurements, that are comparable to the variability in the example with the coin flips. Small note: when you model the conversions/impressions then you do get a lower $R^2$ and higher $\chi^2$ than expected. # create data column for binomial model data $y Clicks,data $Impressions-data$ Clicks) # model mod $xyz_campaign_id)!=1)],data$ Clicks[which(as.factor(data$xyz_campaign_id)!=1)], pch=21,col=rgb(0,0,0,0.1),bg=rgb(0,0,0,0.1),cex=0.7,log="", xlim = c(0,365),ylim=c(0,365), xlab = "n predicted", ylab = "n observed") # plot vs modelled data plot(-100,-100, pch=21,col=rgb(0,0,0,0.01),bg=rgb(0,0,0,0.01),cex=0.7,log="", xlim=c(0,365),ylim=c(0,365), xlab = "n predicted", ylab = "y modeled") for (i in 1:10) { test $Clicks)^2/npred)) # compute R^2 var(predict(mod, type='response')) / var(data$ Clicks/data$Impressions) # compare with monte carlo simulation v_chi $Impressions,predict(mod,type='response')) v_chi[i] Impressions) } hist(v_chi, xlab=expression(chi^2),main=expression(paste("Histogram of ",chi^2," for modeled data"))) hist(v_p, xlab=expression(R^2),main=expression(paste("Histogram of ",R^2," for modeled data")))
