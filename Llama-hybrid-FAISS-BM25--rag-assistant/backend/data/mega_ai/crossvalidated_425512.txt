[site]: crossvalidated
[post_id]: 425512
[parent_id]: 424663
[tags]: 
The main point is that the algorithm (similarly to minimax or alpha-beta) tries to find the move that has the best worst-case behavior. In other words, the value I assign to various moves is a lower bound on their actual value. If the opponent plays suboptimally, it means I will get into a better situation than I expected, but they cannot make a move that would make me worse. You would typically run a new search starting from the new position after the opponent moves so you adapt to it. If your opponent is predictably stupid, you might be able to win quicker by doing risky moves that rely on your opponent's mistakes, but that is usually not reasonable - if the opponent is stupid, you will win anyway, but if they are not you may make your situation worse. It would also expose the agent to traps: a smart opponent could pretend to be stupid to make the agent attempt a risky move. Once the agent commits to the risky move, the opponent stops pretending and chooses the optimal (and devastating) response. Note that this is not at all specific to MCTS, the same logic applies to all search-based algorithms for playing games.
