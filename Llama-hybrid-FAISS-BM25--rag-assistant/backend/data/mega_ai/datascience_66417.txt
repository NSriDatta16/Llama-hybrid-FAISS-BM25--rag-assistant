[site]: datascience
[post_id]: 66417
[parent_id]: 66416
[tags]: 
In brief, backpropagation references the idea of using the difference between prediction and actual values to fit the hyperparameters of the method used. But, for applying it, previous forward proagation is always required. So, we could say that backpropagation method applies forward and backward passes, sequentially and repeteadly. Your machine learning model starts with random hyperparameter values and makes a prediction with them ( forward propagation ). Then it compares with real values while adjusting those random initial values ( backpropagation ), trying to minimize the error ( depending of your objective function and optimization method applied ). And then, it starts over again, until you reach the stopping criteria. You may find a better explanation in this question . Furthermore, you will find more topic explanation here .
