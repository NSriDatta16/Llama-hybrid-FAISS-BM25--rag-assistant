[site]: crossvalidated
[post_id]: 561997
[parent_id]: 
[tags]: 
Is it useless to model deep learning/classic stat model if p-value for correlation/granger causality(timeseries) makes us not reject null hypothesis?

Working with general data(not timeseries) is it worth to create a e.g deep-learning model if the p values for correlation between e.g x and y makes us not be able to reject the null hypothesis(zero correlation)? Or for timeseries and my task: Working with RNN/CNN/VAR-models or timeseries in general, is it even worth to do it if several variables fails an granger causality test? I am working on a timeseries prediction task where i have two features(budgets) and one target(sales) and i came across this and this question arose. The variance for the variable(budget) that fails the test is really low and the one that pass it have high variance. The target sales have high autocorrelation since it is really dependent on month, date, day of week etc... this can be clearly seened with a decompose. Why i am doing this is to be able to adjust the features for maximizing the output y. So the relation between the features(budgets) and y(sales) is key. Hence just modelling the autocorrelation of the target y is useless in my case. Why i am doing this is to be able to adjust the features for maximizing the output y. So the relation between the features(budgets) and y(sales) is key. Hence just modelling the autocorrelation of the target y is useless in my case. So maybe arimax would be the way to go... but then im stuck on base 1, what if the variables dont pass any tests.. how can i be sure that i dont just pick up the the autocorrelation of y and not the relation between the features and y? I want the general idea behind the model to work on different datasets, but since the relations between variables can differ alot depending on dataset i would probably train one model on each and every dataset. The datasets are quite small(60-120 timesteps) depending on the dataset.. I stationarized the timeseries before the test.. However i have not checked that the data can be adequately described by a linear model" so i head to that next. Probably it will not be. Is there any best practice for checking the causality for nonlinear relationships? Lets say i instead of treating the data as a series inject the time data as variables, e.g instead of (budget1, budget2) and a series i have features(budget1, budget2, day, month) per timestep, am i running into any risks? i assume based on previous understandings(high correlation between date and target) that i will see a strong correlation between the date variables and y and maybe less so between the budgets and y. Another idea would be to sum the budgets for an month and then predict the total sales for that month, and then let it roll one timestep per sample. So im thinking about this: I could adjusted the the features for a month and see the output and maybe from then it could pass the test. I assume quite drastic shifts of values would be the best, Could this be a smart strategy?
