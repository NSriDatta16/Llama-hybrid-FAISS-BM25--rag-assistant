[site]: crossvalidated
[post_id]: 443451
[parent_id]: 
[tags]: 
Distribution of gradients across dimensions for neural networks

Does the distribution of gradients for neural networks known to follow a particular distribution? That is, suppose I've a model with $N$ parameters. Then, the (stochastic) gradient at some point is a $N$ dimensional vector $(x_1, x_2, \dots, x_N)$ . Can we say anything regarding how $x$ values are distributed over this vector?
