[site]: crossvalidated
[post_id]: 599865
[parent_id]: 
[tags]: 
Heavy vs light tail distributions when modelling with outliers

I am reading this lecture notes on using the MLEs from other distributions (as Laplace) rather than a Gaussian when dealing with outliers. The lecture notes came from Oxford University: https://www.cs.ox.ac.uk/people/varun.kanade/teaching/ML-MT2016/lectures/lecture03.pdf . Probabilistically, we may view this as follows: the Gaussian distribution has very light ‘tails’, i.e., there is very little probability mass a couple of standard deviations away from the mean. Thus under this model outliers are very very unlikely and so the model will not treat them as such and try to fit a model that accounts for them rather than ignoring them. Instead, we can model the noise using a distribution that has heavier tails. My question is this: Seeing that a Laplace distribution has a heavier tail compared to Gaussian, isn't it true though that there will be even less 'mass' on the tails of Laplace a few standard deviations from its mean? (I am just going by the logic that is presented by the paragraph above, which came from the lecture notes.) I understand the motivation why there is a need to look for alternatives than the Gaussian when dealing with outliers, but I fail to understand how Laplace is able to solve this problem.
