[site]: crossvalidated
[post_id]: 74065
[parent_id]: 
[tags]: 
How to think of reduced dimensions in PCA on facial images (eigenfaces)?

I've been reading up a bit on eigenfaces. I think I understand the basic concept of it - vectorize a set of facial images then reduce the dimensionality of the images using PCA. What I don't really understand is the visualization of the lower-dimensional representation of the images. In the facial images, the number of dimensions is the number of pixels so if you reduce the dimensionality of an image, you reduce the number of pixels. But then how do you visualize this image? Is it just a much smaller version of the full-dimensional original? The examples that I have seen do not look like this. Or do you alternatively make each pixel bigger so that the overall image is the same size as the original?
