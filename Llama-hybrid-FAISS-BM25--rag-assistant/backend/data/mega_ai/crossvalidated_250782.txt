[site]: crossvalidated
[post_id]: 250782
[parent_id]: 
[tags]: 
Time Series Modelling - Empirical Variance Seasonality

I'm following this book with regards to modelling temperature data in a piece-by-piece manner. On page 44, after fitting an AR(3) model to the de-trended and de-seasonalised data, the authors examine the variance of the residuals and: calculate the daily empirical variance by averaging the values of the squared residuals of a particular day over all years. Which they then proceed to model via a truncated Fourier series. On the next page (page 45) they eliminate the seasonal dependency in the variance (the empirical variance) by: dividing the residuals by the square root of the fitted variance. My question is this: 1) Are they dividing the original residuals by stretching out the fitted variance across the length of the original residuals? 2) Why would you approach modelling the variance like this (i.e. create the empirical variance time series) instead of just fitting a truncated Fourier series to the squared residuals?
