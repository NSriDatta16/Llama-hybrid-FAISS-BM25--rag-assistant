[site]: crossvalidated
[post_id]: 419783
[parent_id]: 419750
[tags]: 
Consider the following sentence in english and german (taken from wikipedia): He has eaten an apple. Er hat einen Apfel gegessen. The literal translation of the german sentence is He has an apple eaten. Suppose you're training an english -> german translation network. Suppose the network has already generated the first 3 words Er hat einen You might intuit that when generating "Apfel", the attention of the model should be focused on the english word "apple". However, "Apfel" is the 4th word in the german sentence but the fifth word in the english sentence. So a naive strategy like always focusing on the $k$ th word of the source sentence when generating the $k$ th word of the target would not be sufficient. This ability of the model to figure out that it should pay attention to the 5th word of the english sentence to generate the 4th word of the german one is called alignment.
