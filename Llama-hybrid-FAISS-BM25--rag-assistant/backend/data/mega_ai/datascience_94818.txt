[site]: datascience
[post_id]: 94818
[parent_id]: 94815
[tags]: 
I think there is a good bit of confusion in how you define Machine Learning: There are different types of learning: if the model is trained with data annotated with the "correct" answers, then it's supervised learning. There are many different "families" (methods) for supervised ML. Your description focuses on Neural Networks, but there are many others. Your last two steps probably refer to validation (during training) and/or evaluation (after training and on a separate test set), but it's not very clear. Supervised ML can be summarized as follows: The goal is for the system to find a function $f$ which transforms an input $x$ (features) into an output $y$ (target variable) The system is provided with a sample of pairs $(x,y)$ (training data). Note that this sample is only a subset of the population data: after the training the system must be able to find $y$ for any input $x$ , not only the values of $x$ seen in the training data. This is why the system must generalize from the data, i.e. find the patterns in $x$ which are useful to determine $y$ . If the system doesn't generalize and only stores exactly which $x$ gives which $y$ then it cannot predict the answer $y$ for any value $x$ which was not seen in the training data, and that's useless. In a sense the process of generalization can be seen as compressing the knowledge contained in the training data. However there are at least a couple major differences: The goal of compression is to represent a specific input $x$ using as little space as possible in a way which makes it possible to re-obtain the same $x$ , possibly with some loss. The goal of supervised ML is to predict an output $y$ for any $x$ . First $y \neq x$ , but more importantly the ML cannot produce back the data it was trained with (in general, see exception just below). A ML model doesn't have to reduce the size of the training data. For example instance-based learning just stores all the instances in order to later use it for predicting.
