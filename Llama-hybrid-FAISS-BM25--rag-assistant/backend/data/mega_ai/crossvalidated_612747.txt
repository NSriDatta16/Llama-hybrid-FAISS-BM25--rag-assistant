[site]: crossvalidated
[post_id]: 612747
[parent_id]: 
[tags]: 
Softmax Response vs MC Dropout for Uncertainty Estimation

Some papers I see take the uncertainty estimation of a prediction as simply its softmax/sigmoid output, whereas some papers will use techniques such as MC Dropout and calculate the variance across the predictions. The softmax function is typically used in machine learning models to convert a set of input values, often called logits or scores, into a set of output probabilities. These output probabilities can be interpreted as the model's confidence but I have often heard they cannot be used to check the confidence so other methods such as MC dropout is used , why is this the case , what causes the softmax to give high confidence even for predictions that are false? Is it because the soft max can be intuitively thought of as an ensemble of various activations of neurons and this leads to some noise creeping in and making the softmax make wrong predictions confidently. Why wouldn't the MC dropout lead to such problems , During inference, the input image is passed through the network, and each neuron in the network computes an activation value based on its weighted inputs. The weights in the network are learned during training, so they are optimized to produce the correct output for a given input image. So, as the input neurons are removed during MC dropout, the pattern of activation in the neurons will also change which would lead to varied predictions and it should technically give high variance for all inputs but it dosent happen often.
