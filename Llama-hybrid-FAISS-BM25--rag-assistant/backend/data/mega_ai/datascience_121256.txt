[site]: datascience
[post_id]: 121256
[parent_id]: 
[tags]: 
How to analyze 2 NLP datasets and understand their differences

I have 2 test sets (let's call them test set #1 and test set #2), and 2 Language models (let's call them model A and model B). The issue I'm facing is that model A is performing better than model B on the test set #1, and model B is performing better than model A on the test set #2. A user survey showed that model B is better than model A. So test set #2 is closer to what user experience. I wish I could just use the training data #2, but unfortunately my company doesn't have access to this data anymore. My task is to understand the difference between the 2 tests sets, in order to fix our training data so that test set #1 reflects the user experience. I've been unsuccessful at understanding how these two test sets differs so far. What I've tried : Apply different preprocessing to see if it impacts the results Take a look (manually) at the sentences and try to understand the differences between each test set Extract the sentences from each test sets where each model perform well to see if I can spot any difference Look at the most common mistakes of the models to see where they fail But so far I was unable to find a clear reason why test set #1 is behaving so differently than test set #2... How should I approach this problem ?
