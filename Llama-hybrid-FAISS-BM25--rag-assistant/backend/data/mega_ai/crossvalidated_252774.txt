[site]: crossvalidated
[post_id]: 252774
[parent_id]: 
[tags]: 
logistic regression for option elimination?

The usual scenario for logistic regression is that the correct output label $y \in \mathbf{y}$ is provided for an input $\mathbf{x}$, and we maximize $P(\mathbf{y} = y | \mathbf{x}; \theta)$ I am dealing with a situation where the correct label is not always provided. Instead, I have definite information about (one of more) output labels which are not correct. i.e. I know for sure that $P(\mathbf{y} = {y_w} | \mathbf{x}; \theta) = 0$ Are there any references for learning in such an environment? This seems to be a fairly common occurrence for option elimination, and how humans reason in multiple choice questions.
