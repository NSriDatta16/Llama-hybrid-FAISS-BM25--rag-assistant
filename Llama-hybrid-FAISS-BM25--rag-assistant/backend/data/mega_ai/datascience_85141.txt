[site]: datascience
[post_id]: 85141
[parent_id]: 
[tags]: 
how to prevent machine crash while searching for hyper parameters of XGBoost with GridSearchCV

I am searching for best hyper parameters of XGBRegressor using GridSearchCV. Here is the code: from xgboost import XGBRegressor from sklearn.model_selection import GridSearchCV, KFold param_grid_xgb_b1 = { 'num_leaves': np.arange(20, 500, 5), 'max_depth': np.arange(5, 50, 2), 'reg_alpha': np.arange(0.01, 0.5, 0.01), 'min_data_in_leaf': np.arange(50, 1_000, 10), 'colsample_bytree': [0.65, 0.75, 0.85, 0.95, 1], 'subsample': [0.65, 0.75, 0.85, 0.95, 1] } kfold_xgb_b1 = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X_train, y=y_train) grid_search_xgb_b1 = GridSearchCV(estimator=XGBRegressor(learning_rate=0.01, n_estimators=20_000, random_state=0, tree_method='gpu_hist', subsample_freq=5), param_grid=param_grid_xgb_b1, scoring=rmse_score, cv=kfold_xgb_b1) grid_search_xgb_b1.fit(X=X_train, y=y_train, verbose=3) I am using Google Colab with GPU. Machine is dual core CPU with 12.72GB of RAM. And GPU is Tesla T4 with CUDA Version 10.1. How do I prevent crash and search for hyper parameters? EDIT 1: Crash type: RAM filling up; size of data: 300,000 rows and 40 columns.
