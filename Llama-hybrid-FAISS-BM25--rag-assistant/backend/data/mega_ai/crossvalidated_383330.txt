[site]: crossvalidated
[post_id]: 383330
[parent_id]: 383329
[tags]: 
If you have a neural network policy $\pi_\theta(\cdot | s)$ , you can compute the effect of $\theta$ on $\pi$ simply by doing a single forward pass of the network. On the other hand, there is no easy way to compute the distribution of states given that your agent is following the policy $\pi_\theta$ . Just try to think of how you would compute it -- there's no good way.
