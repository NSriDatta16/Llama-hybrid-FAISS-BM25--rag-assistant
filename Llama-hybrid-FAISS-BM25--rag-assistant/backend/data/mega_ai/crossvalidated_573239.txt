[site]: crossvalidated
[post_id]: 573239
[parent_id]: 573237
[tags]: 
The model is not trained multiple times. The main idea is to model the weights as distribution instead of point wise (i.e. instead of a single number for each weight, each weight will be represented as a distribution). Usually, a natural pick for neural network, is to model the weights as a normal distribution, where each weight is represented by two numbers $\mu, \sigma$ . Now, you can sample from this distribution, and get a different result for each sample, and then you can average them. The hard part is to prove that the optimization part is approximating to the posterior distribution (which is intractable this is why we only approximating), and this is done by bayesian inference.
