[site]: crossvalidated
[post_id]: 197011
[parent_id]: 196860
[tags]: 
You didn't get any answer yet, so let me throw some ideas. I am going slightly out of my comfort zone in here, so let me provide a general answer suggesting some areas that can be explored further. Alternative and more clever way of defining your problem is to think of it as a case of multi-armed bandit problem (cf. Scott, 2010). In multi-armed bandit scenario you have multiple marketing campaigns and you are assigning customers to different campaigns, so to check their efficiency. The trick is to learn from data in online fashion, so as you observe more data you can learn from it what campaigns are more efficient and adjust your approach by moving more customers to those campaigns. Quoting Google's post : Experiments based on multi-armed bandits are typically much more efficient than "classical" A-B experiments based on statistical-hypothesis testing. They’re just as statistically valid, and in many circumstances they can produce answers far more quickly. They’re more efficient because they move traffic towards winning variations gradually, instead of forcing you to wait for a "final answer" at the end of an experiment. They’re faster because samples that would have gone to obviously inferior variations can be assigned to potential winners. The extra data collected on the high-performing variations can help separate the "good" arms from the "best" ones more quickly. notice that (Scott, 2010): The choice involves a fundamental trade-off between the utility gain from exploiting arms that appear to be doing well (based on limited sample information) vs exploring arms that might potentially be optimal, but which appear to be inferior because of sampling variability. The trade-off has also been referred to as ‘earn vs learn.’ So what you could do is to assign mice to different dose-groups, check the results of intervention and based on the results make another assignments. Classical multi-armed bandit scenario would be inefficient in here since it would initially need you to assign mice to multiple mice to different groups, however it may be inspiration for something similar. Your problem can be viewed as a logistic regression problem, where probability of success is estimated using Bayesian logistic regression model, where binary-coded success is predicted by dosage. Initial estimates of parameters can be based on random sample of outcomes of different dosages and prior set-up using your "gut feeling", as described in your question. After the initial trial you would have some idea about the dose-effectiveness relationship, posterior estimates from initial trials can be used as priors when analyzing samples in next trial using sequential Bayesian updating . So $$ \text{posterior} \propto \text{prior} \times \text{likelihood} $$ becomes $$ \text{revised} \propto \text{current} \times \text{new likelihood} $$ Posterior probabilities of success for different dosages may also help you to decide on what dosage-ranges that maximize probability of success to focus in future trials in similar manner as in multi-armed bandit problem. You would continue your trials until finding critical dosage that leads to 90% success rate. Check also Freedman et al (1994) paper to learn more about Bayesian approach to clinical trials monitoring. Scott, S. L. (2010). A modern Bayesian look at the multi‐armed bandit. Applied Stochastic Models in Business and Industry, 26 (6), 639-658. Freedman, L. S., Spiegelhalter, D. J., & Parmar, M. K. (1994). The what, why and how of Bayesian clinical trials monitoring. Statistics in medicine, 13 (13‐14), 1371-1383.
