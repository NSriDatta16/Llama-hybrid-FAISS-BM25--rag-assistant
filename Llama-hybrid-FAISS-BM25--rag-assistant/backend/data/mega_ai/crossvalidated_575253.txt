[site]: crossvalidated
[post_id]: 575253
[parent_id]: 295383
[tags]: 
The objective of regularization is to improve the generalization capability of the model (in other words its ability to perform well on unseen data). Regularization can be explicit or implicit. The first case refers to techniques that can constrain the effective capacity of the model in order to reduce overfitting. Examples include adding a penalty term in standard statistical estimators such as OLS or weight decay and dropout in deep learning. In the second case (implicit regularization) instead of explicitly constraining the capacity of the model we use indirect methods. One example, is using SGD to train linear models as it always converges to a solution with a small norm ( https://arxiv.org/pdf/1611.03530.pdf ). Similarly, data augmentation (which has many forms e.g. adding predictors, adding artificially created data, resampling) will help the model to generalize better and is thus considered to be an implicit regularization method.
