[site]: stackoverflow
[post_id]: 4138802
[parent_id]: 4138720
[tags]: 
There isn't really a good solution. You can, as you said, disallow everything, which announces things to the world. If you're not tied to the current url structure, you could consider creating an "allowed" directory, and then symlink your desired content into there. Then you only have to disallow your top level directories. Alternatively, you could build some kind of server-side filter for bot user agents. Allow the major ones in your robots.txt , and then filter their access server-side with an appropriate response code, while blocking all others. This is probably a worse solution than my other option, but it retains your canonical urls.
