[site]: datascience
[post_id]: 27878
[parent_id]: 6676
[tags]: 
SGDClassifier, as the name suggests, uses Stochastic Gradient descent as its optimization algorithm. If you look at the implementation of LogisiticRegression in Sklearn there are five optimization techniques(solver) provided and by default it is 'LibLinear' that uses Coordinate Descent(CD) to converge. Other than number of iterations, optimization, type of regularization(penalty) and its magnitude(C) also affect the performance of the algorithm. If you are running it on Iris data-set tuning all these hyper-parameters may not bring significant change but for complex data set they do play a meaningful role. For more, you can refer the Sklearn Logistic Regression Documentation .
