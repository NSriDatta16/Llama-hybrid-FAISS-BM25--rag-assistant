[site]: datascience
[post_id]: 53187
[parent_id]: 53162
[tags]: 
Square loss is the overall amount of error in your model. However, it depends on the number of observations you have. A loss of a billion might not be so bad if you have a trillion observations. On the other hand, a loss of 500 might be awful if you have 25 observations. MSE accounts for the number of observations by averaging the loss over all of the observations. The MSE in the former example is 0.001, while the MSE in the latter example is 20. If you think about a classification problem, square loss would be analogous to the number of misses, while MSE would be analogous to the accuracy. You will have more incorrect classifications if you attempt more classifications, but this doesn't mean that your model performance is any worse when you attempt many classifications. Except for numerical technicalities on a computer, you should find the same model by minimizing the square loss or MSE loss functions, so in some sense, you're right to say that they "do the same job."
