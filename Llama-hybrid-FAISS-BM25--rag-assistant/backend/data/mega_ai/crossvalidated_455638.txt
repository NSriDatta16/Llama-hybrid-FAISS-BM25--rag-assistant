[site]: crossvalidated
[post_id]: 455638
[parent_id]: 455637
[tags]: 
How do I know which parameters are important? Do I simply look at the p-values of the model and decide from there? No, for the reasons I talk about here . I highly suspect you are experiencing seperation of your data. There likely exists some hyperplane which perfectly separates the positive and negative cases. This leads to unidentifiability, which I discuss in this blog post as a motivating topic . In this case, regularization is one approach you can take, or you can decide which variable to remove a priori (that is, without referencing model fits). Now every time I playfully delete/add predictors, I am creating a 'new' model, am I not? Is there a way to rank the models from 'least' useful to 'most' useful using AIC or BIC? People like to do this. It isn't my preference, but it has been done and seems to be inoffensive. Again, I would encourage you not to do this if your goal is inference. Instead, I would say think about the question you are trying to answer and determine which variables are most important to answer that question. If your goals are exploratory, then use AIC.
