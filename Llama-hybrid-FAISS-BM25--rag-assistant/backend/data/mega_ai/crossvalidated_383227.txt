[site]: crossvalidated
[post_id]: 383227
[parent_id]: 
[tags]: 
SVD for simultaneous row and column reduction of a squared matrix

I have an n x n similarity matrix which I'd like to reduce to a smaller square matrix. I am aware of this answer: How to use SVD for dimensionality reduction to reduce the number of columns (features) of the data matrix? The answer shows how you can use SVD to reduce the number of columns of a matrix. Essentially, if $A= USV^T$ , then taking $US$ , gives a matrix with fewer columns than the original. Therefore, I know how to reduce the number of columns using SVD, but how about the number of rows and columns? Can I apply the procedure twice, first to reduce the columns, then to the transpose of the result to reduce the rows? If my similarity matrix is symmetrical; does it make the problem simpler?
