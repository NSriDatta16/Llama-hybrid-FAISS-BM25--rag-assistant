[site]: crossvalidated
[post_id]: 482221
[parent_id]: 481856
[tags]: 
Turns out, the paper (Twisk, J., Bosman, L., Hoekstra, T., Rijnhart, J., Welten, M., & Heymans, M. (2018)) I mentioned before has a lot of the answers I was looking for. Also, the paper (McKenzie, D. (2012)) mentioned by @Dimitry has been helpful. I'll share some of my insights from studying them more thoroughly: The kind of randomized control trial or experiment I'm referring to can often be found in a medical context. That's why there are a lot of papers in medical journals dealing with similar cases. It is often called a pre/post study or a repeated measurement study. Gliner, J. A., Morgan, G. A., & Harmon, R. J. (2003) is a good start for a concise overview. So, how should you analyze the result of such an experiment? It would be totally fine to just take the group means for your post measurement and compare those with a simple t-Test. But is this always the best strategy? The answer seems to be: No ! Why is that? Well, even when you randomize your groups there will be baseline differences between them. Because in expectation, the difference in outcomes will only depend on your intervention in the test group, this seems not to be a big issue (especially when your n is high). But it is a problem for your Power ! If there are stark differences between characteristics of your individuals which are correlated with your outcome, you will have a harder time finding the effect of the intervention. Just by chance there will be cases where your randomization produces very unequal groups. Imagine having 20 persons (10 male / 10 female) to randomize into two groups. If you end up with a test group of 10 f and control of 10 m and sex is related to your outcome, you will have a bad time looking at your results. Another aspect to consider is "regression to the mean" : groups with a low (high) measure at baseline are more likely to increase (decrease) their measure in the post period. This might happen in the absence of any intervention effect! Moreover, baseline differences don't even have to be significant in order to be problematic . Twisk et al. argue that this is a huge misunderstanding and you should always account for them. One solution can be stratification. By stratifying, you make sure that your groups end up equal. You reduce uninformative grouping outcomes and thereby variance. This increases Power. Another solution is to account for baseline differences when your pre period measure is related to the post measure. You can do so by using appropriate inference methods . While there has been some debate on whether this should be done, this is mostly settled (Twisk et al.). However, many people are unsure which method is appropriate to deal with baseline differences (I was one of those). So, which method is best for taking baseline differences into account and increasing the Power of your experiment? I've turned my code from above into a simulation script . This has helped me to make sense of the more theoretical concepts outlined by Twisk et al. and especially by McKenzie. One of my mistakes in the original post, was not taking into account the correct structure of the data. Let's correct this. Here is how the data looks: | id | pre | post | test | |----:|---------:|---------:|-------:| | 1 | 8.31908 | 1.06574 | 0 | | 2 | 9.06334 | -9.53055 | 0 | | 100 | 10.4542 | 47.5967 | 1 | | 101 | 12.6218 | 3.11528 | 1 | This is the "wide" data format and represents cross-sectional data (even though we have an underlying time component). We apply the following inference methods to it: FORMULAE = [ "post ~ test", # 0a t-Test on Outcome Means "post ~ test + pre", # 1a cross-sectional reg. control for baseline "I(post - pre) ~ test", # 3a t-Test on outcome change "I(post - pre) ~ test + pre", # 3b cross-sec. reg. with control for baseline ] I've named the formulas according to the Twisk et al. paper for direct comparison. However, they didn't include the simple t-Test (0a). It will be interesting to see how this most naive approach compares to the other though. While you might think that 3a controls for baseline effects, it does not! You still need to add the baseline as a covariate, thus we add 3b . Actually, 3b is analogous to 1a . (see Twisk et al. for the derivation) The coefficient for test will be the Average Treatment Effect (ATE) in all cases. For the upcoming methods, we need to adapt the data structure. This is what i didn't account for in my original post: | id | test | period | value | |--------:|-------:|---------:|--------:| | 1 | 0 | 0 | 14.107 | | 1 | 0 | 1 | -9.5547 | | 100 | 1 | 0 | 8.9816 | | 100 | 1 | 1 | 22.5591 | Here, we really use the longitudinal / panel structure of the data. This is needed for the following methods: FORMULAE = [ "value ~ test + period + test * period", # 2a panel regression with interaction "value ~ period + I(test * period)" # 2c " without treatment covariate ] These approaches can be helpful, when you have missing data. Subjects that have at least a baseline observation still contribute to the model. This is not the case with the previous approaches. Notice that 2a does not take baseline differences into account. Hence, 2c is introduced. (refer to Twisk et al. for more details) For 2a you need to calculate test + interaction coefficient for the ATE. For 2c the ATE is simply the interaction coefficient. Here's the results. Cross-Sectional format data: | formula | auto_corr | r_sq | nobs | df_resid | df_model | c_intercept | p_intercept | c_test | p_test | c_pre | p_pre | |:---------------------------|------------:|----------:|-------:|-----------:|-----------:|--------------:|--------------:|---------:|---------:|----------:|--------------:| | post ~ test | 0.505331 | 0.0163235 | 200 | 198 | 1 | 59.9287 | 6.83357e-56 | 5.15359 | 0.239359 | nan | nan | | post ~ test + pre | 0.505331 | 0.270734 | 200 | 197 | 2 | 0.0369226 | 0.519833 | 5.10506 | 0.195384 | 5.99582 | 1.25446e-07 | | I(post - pre) ~ test | 0.505331 | 0.0172487 | 200 | 198 | 1 | 49.94 | 8.34025e-47 | 5.14368 | 0.225567 | nan | nan | | I(post - pre) ~ test + pre | 0.505331 | 0.209847 | 200 | 197 | 2 | 0.0369226 | 0.519833 | 5.10506 | 0.195384 | 4.99582 | 9.28722e-06 | Panel format data: | formula | auto_corr | r_sq | nobs | df_resid | df_model | c_intercept | p_intercept | c_test | p_test | c_period | p_period | c_test:period | p_test:period | c_i(test * period) | p_i(test * period) | |:--------------------------------------|------------:|---------:|-------:|-----------:|-----------:|--------------:|--------------:|------------:|-----------:|-----------:|------------:|----------------:|----------------:|---------------------:|---------------------:| | value ~ test + period + test * period | 0.505331 | 0.713389 | 400 | 396 | 3 | 9.9887 | 2.01945e-08 | 0.0099174 | 0.923874 | 49.94 | 8.7505e-54 | 5.14368 | 0.237087 | nan | nan | | value ~ period + I(test * period) | 0.505331 | 0.713379 | 400 | 397 | 2 | 9.99366 | 2.26815e-14 | nan | nan | 49.935 | 1.78043e-65 | nan | nan | 5.15359 | 0.159908 | What are the main insights? When you have a pre/post experiment and a baseline for your measure, account for it! How well the methods perform strongly depends on the (auto)correlation of the data. Especially the p-value varies greatly, while coefficients are somewhat more stable. With low correlation between pre and post ( 0.5) the methods differ strongly. (fits the main findings of McKenzie) There are large power gains to be had when accounting for the baseline. Especially when the measure has high correlation over the time dimension. (see Kahan, B. C., Jairath, V., Dor√©, C. J., & Morris, T. P. (2014) Method 1a seems to be a good choice all over. You can and should (in many cases) add additional covariates in a similar fashion. However, adding the baseline is the most important one. (see Kahan et al. 2014) All this only hold when you have randomized groups. In observational studies you must not control for the baseline like this! (see Twisk et al.)
