[site]: crossvalidated
[post_id]: 395239
[parent_id]: 168622
[tags]: 
I think that multicollinearity should be checked in machine learning. Here is why: Suppose that you have two highly correlated features X and Y in our dataset. This means that the response plane is not reliable (a small change in the data can have drastic effects on the orientation of the response plane). Which implies that the predictions of the model for data points far away from the line, where X and Y tend to fall, are not reliable. If you use your model for predictions for such points the predictions probably will be very bad. To put it in other words, when you have two highly correlated features, as a model, you are learning a plane where actually the data mostly falls in a line. So, it is important to remove highly correlated features from your data for preventing unreliable models and erroneous predictions.
