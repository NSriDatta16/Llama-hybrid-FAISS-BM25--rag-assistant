[site]: datascience
[post_id]: 42987
[parent_id]: 
[tags]: 
Running out of memory while processing csv file data

I'm getting an error while processing 0.2 million of text data. I'm using CNN text classification in tensorflow. Output raw data shape is 204177x22000. while passing to numpy.array(out_raw), here it is consuming 100% memory(Using 8GB RAM). Tried with data in batch but didn't work. If i need to increase my RAM size then kindly help me out with formula. What are the methods to take care of this problem statement?
