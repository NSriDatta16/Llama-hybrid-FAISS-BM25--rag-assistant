[site]: crossvalidated
[post_id]: 442787
[parent_id]: 
[tags]: 
Why Expectation and Maximization algorithm not used in Machine Learning while Gradient Descent algorithm used in Machine Learning?

I know that Newton Raphson, Expectation & Maximization, and Gradient Descent are all known to be optimization methods. Somehow, I wonder why Gradient Descent is chosen to be used in most of Machine Learning applications but I never heard that Expectation & Maximization or Newton Raphson algorithms have been applied. Hope to hear some.
