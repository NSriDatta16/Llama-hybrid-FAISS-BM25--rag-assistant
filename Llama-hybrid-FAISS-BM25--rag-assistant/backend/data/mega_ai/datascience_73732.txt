[site]: datascience
[post_id]: 73732
[parent_id]: 45471
[tags]: 
There are beta regression models for R and Python . They are designed to handle values between 0 and 1. However, as far as I'm aware, there is no direct beta regression implementation with LightGBM, XGboost etc. Some folks seem to expand beta regression into tree-based approaches , but this is not equivalent to boosting. Also see this post for a very similar problem. As mentionned there, a naive approach could be to simply run a normal regression in a boosting setup and see how "bad" the results are (i.e. values $ and $>1$ ). Alternatively you could try to predict the continuous features and calculate the success probability from predicted values.
