[site]: crossvalidated
[post_id]: 588318
[parent_id]: 
[tags]: 
Is Z score standardization usable for deployed machine learning algorithms?

First, we assume use Z-score based standardization defined by: $$ Z=\frac{x-μ}{σ} $$ Given that Z-score based standardization is based on the mean (μ) and standard deviation (σ) of the distribution of a current dataset, how is it practically useful at the time of inference for new data that changes the dataset mean and standard deviation? My initial intuition is that the two options to solve the dynamic nature of the dataset distribution are as follows: (1) Use μ, σ of the pre-defined dataset; however, this does not take into account the new data distribution of the updated dataset and, therefore, may not be a good standardization of the data (i.e. the "standardized" variables are no longer standardized to the same scale) (2) Re-standardize all data according to the new distribution and re-fit the model. In a practical sense, this is not feasible for any models requiring long training times. I feel that I am missing something in this analysis. Any pointers in the correct direction are greatly appreciated.
