[site]: datascience
[post_id]: 41565
[parent_id]: 30919
[tags]: 
Answering my own question several months later (after reading the answer by @SanjayKrishna). My 'approach 1' seems more correct, but causes more hustle than is actually needed. Don't forget that the Cost is the Mean Squared Error. In my specific case it's the average of the errors from each timestep. It's this MSE which allows us to see the "delta". $$C = MSE= \frac{1}{T}\sum_{t=0}^{t=T}(actual_t-wanted_t)^2$$ Thus, we should do the following: peturb a single weight upwards perform a full forward prop (for example, 15 timesteps), get the cost_a from your MSE. It should be just a single scalar value. peturb the weight downwards redo the full fwd prop to obtain the cost_b from your MSE which is another scalar value. compute the delta (just a single scalar value) by subtracting cost_a from cost_b compare the delta to your gradient for that was computed during BackPropThroughTime (your gradient for that particular weight, estimated from all the timesteps) Edit I am actually using something like "Mean SoftMaxedCrossEntropy", not MSE. But the idea is the same: sum up the errors at each timestep, divide by $T$ and that's my Cost.
