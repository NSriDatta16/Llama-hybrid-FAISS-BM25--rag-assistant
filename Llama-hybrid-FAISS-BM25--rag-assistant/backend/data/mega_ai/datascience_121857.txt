[site]: datascience
[post_id]: 121857
[parent_id]: 
[tags]: 
How to Implement padding and masking sequences for RNN

As an exercise, I'm building a network for binary classification of sequences (whether a sequence belongs to type A or type B). The network consists of an RNN with one LSTM layer, and on top of it an MLP that outputs the classification. I input batches of sequences with different lengths into the network, which means I need to pad the sequences to make them equal in length, and to mask the outputs of the network to make them the same length as the original sequences. What is the correct way to implement padding/masking in PyTorch? I have read about functions like pad_sequence() , pack_sequence() , pack_padded_sequence() , etc., but I have already become confused with all these functions... Or is there any other "secret" way that I don't know of?
