[site]: crossvalidated
[post_id]: 230784
[parent_id]: 
[tags]: 
Shift Invariance in an SVM

I have a problem where I need by vectors to be invariant to shifting the feature around. The order of the features doesn't matter as long as their relative distances from one in other is preserved (I think, given a priori knowledge about the problem) For example if my feature vector is (1, 2, 3, 4, 5) then the vector (5, 1, 2, 3, 4) should produce the same classification (binary problem) Currently I'm using an SVM with an RBF kernel and getting decent results but my suspicion is that for the few examples it is misclassifying is due to the possible shift. I thought of just producing artificial examples by taking all images with a -1 label (since this is a detection problem and the feature should highlight a defect) and shifting them. I've also seen papers of creating artificial examples by doing something like this to the support vectors. My question is either (1) is this a sound idea or is there some other approach to try and (2) how can I evaluate this classifier. I've been using 10-fold cross validation but that would possibly put artificial examples created from real examples in both the training set and testing set giving my a far optimistic estimate. I could also just split before hand(80/20) and create examples from the 80% but given that I don't have millions of examples and unbalanced classes I get an estimator with pretty high variance.
