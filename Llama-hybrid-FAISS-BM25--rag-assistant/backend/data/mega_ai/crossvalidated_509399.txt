[site]: crossvalidated
[post_id]: 509399
[parent_id]: 
[tags]: 
Random matrix theory impact on covariance matrix analysis

Framework: From RMT, eigenvalues have a semicircle distribution for symmetric matrices each with i.i.d normally distributed entries as the size of the matrix grows. The restrictions on i.i.d have recently been shown to not matter so we can proceed nevertheless. Example: If we take a covariance matrix of all stock tickers beginning in A comparing the average daily return over a period of time (or any process with no underlying relation), with each entry we can assume lognormal distribution forming a, lets say, 10000 by 10000 symmetric matrix. Over a duration of time we get a sequence of such matrices. Each of the entries we assume to be i.i.d since the stocks have 'nothing' to do with each other (although a weaker results holds for non-i.i.d entries). Now this series of matrices forms a chain of covariance matrices tending towards the underlying covariance matrix of the entire history of the stocks (if we sampled correctly). Random Matrix Theory implications: We known from RMT that once we decompose these matrices into their eigenvalues, the eigenvalues tend to the semicircle distribution. Since this distribution is continuous, there's a spread in results i.e. there is some underlying variance to the eigenvalue decomposition of covariance matrices. Conclusion: Thus when we use covariance matrices shouldn't there be some sort of hypothesis test that's able to filter out this underlying distribution, similar to comparing normal distributions where we need to account for variance when comparing two mean values. This would be dependent on how i.i.d the random variables are, the size of the matrix, the number of samples taken, and the mean/variance of the random variables themselves. What would be weird about this hypothesis test is that we'd expects as $n$ gets larger so does the error bound, captured by the asymptotic relationship between the size and convergence to the semicircle distribution. TLDR: Is there some sort of hypothesis testing for PCA, or any eigenvalue method, that filters out the underlying tendency of random matrices to share similar eigen-distributions? Similar to how when you compare the mean of two normal distributions you need to perform a hypothesis test to account for the variance. Edit - Solution: I found this paper Random Matrix Wishart Hypothesis Testing which seems quite promising although it'll take a few days for me to fully understand. It seems like this is an on-going area of research. Any further comments or recommendations are always appreciated.
