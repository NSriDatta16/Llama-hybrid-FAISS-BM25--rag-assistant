[site]: crossvalidated
[post_id]: 332508
[parent_id]: 69886
[tags]: 
It is possible to apply logistic regression even to a contiuous dependent variable. It makes sense, if you want to make sure that the predicted score is always within [0, 100] (I judge from your screenshots that it is on 100-point scale). To accomplish it, just divide your score by 100, and run logistic regression with this [0,1] - based target variable, like in this question - you can do it, for example, with R , using glm(y~x, family="binomial", data=your.dataframe) I don't know whether this approach helps with outliers - it depends on the sort of outliers you are expecting. But sometimes it improves goodness of fit (even $R^2$, if your dependent variable has natural lower and upper bounds. As for the second question, $R^2\approx 0.3$ may be the best what you can squeeze out of your data, without overfitting. If you build your model for the purpose of inference, low $R^2$ is totally fine, as long as the coefficients important to you are significant. If you want to check whether the model is overfitted, you can check its $R^2$ on a test set , or even do a cross-validation.
