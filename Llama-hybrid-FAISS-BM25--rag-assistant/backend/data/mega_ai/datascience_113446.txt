[site]: datascience
[post_id]: 113446
[parent_id]: 
[tags]: 
Low accuracy VGG16 model when using ImageDataGenerator.flow_from_directory but high accuracy using image_dataset_from_directory as inputs

I am currently trying to understand why is it that a certain model gives very different accuracy results when using two different ways to input the same training dataset to train it. I have the following model: from tensorflow import keras from tensorflow.keras import layers import matplotlib.pyplot as plt conv_base = keras.applications.vgg16.VGG16( weights="imagenet", include_top=False ) conv_base.trainable = True for layer in conv_base.layers[:-4]: layer.trainable = False data_augmentation_CVGG = keras.Sequential( [layers.RandomFlip("horizontal"), layers.RandomRotation(0.2), layers.RandomZoom(0.2)]) inputs_CVGG = keras.Input(shape=(150, 150, 3)) x = data_augmentation_CVGG(inputs_CVGG) x = keras.applications.vgg16.preprocess_input(x) x = conv_base(x) x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x) x = layers.MaxPooling2D(pool_size=2)(x) x = layers.Flatten()(x) x = layers.Dense(512)(x) x = layers.Dropout(0.4)(x) outputs = layers.Dense(1, activation="sigmoid")(x) model_CNN_VGG = keras.Model(inputs_CVGG, outputs) model_CNN_VGG.summary() model_CNN_VGG.compile(loss="binary_crossentropy", optimizer=keras.optimizers.RMSprop(learning_rate=1e-5), metrics=["accuracy"]) If I use the generators from the following as input: from tensorflow.keras.preprocessing.image import ImageDataGenerator train_datagen_CVGG = ImageDataGenerator(rescale=1./255) test_datagen_CVGG = ImageDataGenerator(rescale=1./255) train_generator_CVGG = train_datagen_CVGG.flow_from_directory( base_dir+"/"+"train", batch_size=20, class_mode='binary', target_size=(150, 150)) validation_generator_CVGG = test_datagen_CVGG.flow_from_directory( base_dir+"/"+"validation", batch_size=20, class_mode='binary', target_size=(150, 150)) and train the model with: history = model_CNN_VGG.fit( train_generator_CVGG, epochs=20, verbose=2, validation_data=validation_generator_CVGG) I get very low accuracy (50~60%). But the problem is that it doesn't improve a whole lot with more epochs. Now, consider the following: from tensorflow.keras.utils import image_dataset_from_directory train_dataset = image_dataset_from_directory( base_dir+"/"+"train", image_size=(150, 150), batch_size=20) validation_dataset = image_dataset_from_directory( base_dir+"/"+"validation", image_size=(150, 150), batch_size=20) history = model_CNN_VGG.fit( train_dataset, epochs=20, verbose=2, validation_data=validation_dataset) This way, the exact same model immediately gives accuracy over 85% and gets over 95% after a few epochs. I have searched around but every other similar question focuses on improving the accuracy of the first method (.flow_from_directory()) by tweaking parameters. I have tried different learning rates, different optmizers, etc etc but the accuracy doesn't get better. Besides, I am not trying to get the accuracy to go higher, I am trying to understand why is it so much better using image_dataset_from_directory than ImageDataGenerator.flow_from_directory I already read this but that doesn't explain the differences in the outcome of training the same model both ways. What am I missing? Thanks.
