[site]: crossvalidated
[post_id]: 386339
[parent_id]: 
[tags]: 
feature importance using forward selection

In the following article the author has correctly mentioned that the "petal" is more important than "sepal" in case of iris data: https://towardsdatascience.com/feature-importance-and-forward-feature-selection-752638849962 Is the function mentioned in the article the correct way of finding important features? It looks like ensemble models have feature selection methods built-in (e.g., LightGBM - feature_importance , xgboost - booster().get_fscore() or randomforest - feature_importance_ ). Is the technique explained in that article limited to certain supervised modules?
