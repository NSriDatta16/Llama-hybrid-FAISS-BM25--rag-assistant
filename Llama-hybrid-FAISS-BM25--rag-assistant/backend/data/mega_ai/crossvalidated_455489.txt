[site]: crossvalidated
[post_id]: 455489
[parent_id]: 
[tags]: 
Hypothesis Test for a Linear Combination of Three or More Probabilities

Suppose that you have a parameter w. As you change the value of that parameter, the probability of a given event occurring increases or decreases. I want to use the Method of Finite Differences to estimate the second derivative at a point, we'll call this w1. The probability of the event occurring at w1 is p1. Define w0 as w1 - h and w2 w1 + h, where h is a small step size. The probability of the event occurring at w0 is p0 and at w2 is p2. An estimate of the second derivative with respect to the event occurring at w1 is (p2 - 2*p1 + p0)/(h^2). I am estimating the linear combination of probabilities L = p2 - 2*p1 + p0 with L̄ = p̄2 - 2*p̄1 + p̄0 I want to test H0: L = 0 H1: L != 0 I tried the Wald test: Where beta is the weight vector (1,-2,1), lambda = 0, and q̄i = 1 - p̄i. z2 ~ Chi-Square(1). I ran the following simulation to see if the Wald test works well for this: Initialize probabilities. p2 = 0.4 p1 = 0.5 p0 = 0.55 Generate a Unfiform(0,1) random number. If less than given probability (p2, p1, or p0) return 1. This is how we'll estimate p2, p1, and p0. game = function(p) { u= runif(1,min=0,max=1) if (u We will begin a simulation and keep track of our estimates of p2, p1, and p0. Each game after the first 10, we will run a hypothesis test with: H0: L = |p2e - 2*p1e + p0e| = 0 HA: L = |p2e - 2*p1e + p0e| > 0 We will run this hypothesis test until we can reject H0 with 95% confidence. Once that confidence level is reached, we will terminate the program and return s = sign(p2e - 2*p1e + p0e). If s 0, it was mistakenly identified as positive due to random chance. We'll then keep track of the percent of the 1000 iterations of this process that correctly identified L as negative. results = c() j = 1 while (j 10 because I couldn't figure out how to use TryCatch() if (i > 10) { if (pchisq(q = z2, df = 1, lower.tail = T) > 0.95) { if (l The true L is -0.05 and I set my confidence to 95%. Thus, if the Wald test were applicable here, we would expect that in approximately 950 of the 1000 iterations, L was correctly identified as negative and in approximately 50 of the 1000 iterations it was mistakenly identified as positive. This should be the case because we steadily increased our sample size n until 95% confidence was achieved. However, this is not what I found. I got 871 successes. Pr(Binomial(n=1000,p=0.95) I ran another simulation using the process outlined in Andrés et. al (2012) and didn't get much more encouraging results. Does anyone have any suggestions? Thanks in advance. Martín Andrés, Antonio & Herranz, Inmaculada & Álvarez Hernández, María. (2012). The optimal method to make inferences about a linear combination of proportions. Journal of Statistical Computation and Simulation. 82. 123-135. 10.1080/00949655.2010.530601. https://en.wikipedia.org/wiki/Finite_difference_method
