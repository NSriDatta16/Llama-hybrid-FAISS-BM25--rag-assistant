[site]: crossvalidated
[post_id]: 485964
[parent_id]: 
[tags]: 
Loss functions in statistical decision theory vs. machine learning?

I'm quite familiar with loss functions in machine learning, but am struggling to connect them to loss functions in statistical decision theory [1]. In machine learning, a loss function is usually only considered at training time . It's a differentiable function of two variables, loss(true value, predicted value) , that you iteratively minimize over the training set to converge to (locally) optimal model weights. In statistical decision theory, a loss function seems to be relevant at prediction time (?). You want to rationally choose a value for an unknown quantity, based on your assessment of its probable values, and your loss of making a wrong prediction. What is the intuition of how these two concepts relate to each other? [1] For example, in Ch 6.3 of "Machine Learning: A Probabilistic Approach" or Ch 2.4 of "Elements of Statistical Learning".
