[site]: crossvalidated
[post_id]: 533503
[parent_id]: 
[tags]: 
When should you remove Outliers - Entire Dataset or Train Dataset?

I have been trying to understand the concepts of data leakage and outlier analysis as I am new to data analysis and machine learning. I have googled these topics and understand data leakage but it is not clear on when to perform outlier analysis. To build a accurate and correct model, my understanding is: Split dataset into train/test as first step and is done before any data cleaning and processing (e.g. null values, feature transformation, feature scaling). This is because the test data is used to simulate (see) how the model will perform if it was deployed in a real world scenario. Therefore you cannot clean/process the entire dataset. Outlier detection (in general terms) should be done on the train dataset. This again simulates a real world scenario as the model will need to determine if there are any outliers and then take the correct action (e.g. remove, impute, cap to certain threshold). Checking outliers for the entire dataset (and doing some action) results in data leakage. My qeustion is: should outlier detection/analysis be done on the training dataset or on the entire dataset before it is split into train/test? I am trying to undersand what is the most common practice. I understand that outlier detection is not as straightforward as above as other factors may need to be considered. Note: When searching CrossValidated, there are lots of answers regarding data leakage from train/test split, but there is no clear answer on when to remove outliers.
