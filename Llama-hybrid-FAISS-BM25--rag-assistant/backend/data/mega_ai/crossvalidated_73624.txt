[site]: crossvalidated
[post_id]: 73624
[parent_id]: 
[tags]: 
Mean absolute deviation

Wikipedia states: The mean absolute error (MAE) is a common measure of forecast error in time series analysis, where the terms "mean absolute deviation" is sometimes used in confusion with the more standard definition of mean absolute deviation. The same confusion exists more generally. What does that mean? What exactly is the confusion? Also, why is MAE is used in time series analysis specifically? (as opposed to more general measures of error such as MSE)?
