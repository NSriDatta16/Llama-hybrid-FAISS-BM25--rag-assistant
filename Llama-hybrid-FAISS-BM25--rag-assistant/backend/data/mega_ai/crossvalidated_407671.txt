[site]: crossvalidated
[post_id]: 407671
[parent_id]: 
[tags]: 
EDIT) Bayesian prediction using regression

I have a very basic, introductory statistical background but learning Bayesian analysis with Bayesian Data Analysis(A.Gelman) and I desperately need any hint to help me grasp a concept. As long as I remember the expectation of conditional probability is the $E(x|y)= ∫(xf(x|Y=y))dx$ And I am assumed to detect the joint distribution and conditional distribution of two normally joint distribution. They share equal variance (unknown) and mean (160) and the correlation was given(0.5). The posterior mean of theta is all of the sudden : $E(θ|y) = 160 + 0.5(y-160)$ I cannot infer how this equation come from, as no joint distribution was given. And the explanation continues that under repeated sampling of data, the expectation of posterior mean becomes $160 + 0.25(θ-160)$ (WHY) but the estimate of theta is $\hat{θ} = 160 + 2(y-160)$ The main purpose of those explanation was (I presume) to prove that the expectation of posterior mean is not unbiased. However I am stuck with the coefficients. I would appreciate any insight to help me understand the difference and origin of those equations. Thank you @prometheus for help. Now I understand the very first function. As mean of y and θ is both 160, the conditional expectation of θ given y is $$160 + 0.5(\rho)*(variance(θ)/variance(y) = 1) *(y-160)$$ . And the prior distribution of θ follows normal distribution, so p(θ) will be $ N(160,\Lambda_0)$ , which is the first function. Also, as $\theta$ follows normal distribution , $p(\theta) \sim N(160, \Lambda_0)$ Now I can get posterior mean by multiplying the prior distribution and likelihood function, right? The likelihood function is $\sum(y_{i}-\theta)^t\Sigma^{-1}(y_i-\theta)$ Then it would be $P(\theta|y) \propto exp(-\frac{1}{2}[(\theta-160)^{T}\Lambda^{-1}_0(\theta-160)] + \sum(y_{i}-\theta)^t\Sigma^{-1}(y_i-\theta))$ Where $\Sigma, \Lambda $ are both variance of y and theta And the answer will be, $p(\theta|y) \propto N(\mu_n, \Lambda_n)$ $\mu_n = (\Lambda^{-1}_0+n\Sigma^{-1})^{-1}(\Lambda^{-1}_0\mu_0+n\Sigma^{-1} \bar{y})$ $\Lambda^{-1}_n = \lambda^{-1}_0+n\Sigma^{-1}$ Now I am stuck with same situation. It does not give any information about correlation coefficient. I think I am missing some trivial points, focusing on word by word and not seeing big picture.
