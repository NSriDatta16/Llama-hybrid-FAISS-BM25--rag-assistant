[site]: crossvalidated
[post_id]: 314705
[parent_id]: 
[tags]: 
Visualizing neural network inferences

I know this is an ongoing and hard question to answer, but if anyone has experience in this then please share your knowledge. Suppose I have made a neural network with the task of predicting an event x. Therefore, the network can be structured as a 2-class binary classification problem with n inputs and a single output. Aside from training the network to predict such events, I'm having a hard time trying to visualise any patterns/inferences which have been made by the neural network. As of now, I can think of the following: Variable importance based on weight connection strength. (Garson, Olden) Partial dependent plots (observe the networks output whilst sampling an input of interest. Although these plots are nice and give us a descent amount of information, I'm looking to produce a more graphicy plot. After researching, I've discovered Self Organizing Maps (SOM) which can be used as a visual tool of discovering patterns which may or may not exist in the giving the inputs. Essentially vector quantisation. So my current thought process is to: Build a SOM map for all training data and analyse the patterns Classify the data using my neural network model Build new SOM maps for the classified cohorts and see if there's anything interesting. So I guess I'm essentially looking for an intuitive plot which can show the inferences made by the neural network (or any machine learning approach for that matter). Following advice in the comment section, my current network structure is as follows: 25-5-1 # 25 inputs, 5 units in a single hidden layer, single output I started with an equal number of units in the hidden layer but reduced to 5 after optimising via the ROC metric.
