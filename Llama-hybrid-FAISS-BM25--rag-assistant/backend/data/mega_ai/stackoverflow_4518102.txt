[site]: stackoverflow
[post_id]: 4518102
[parent_id]: 
[tags]: 
mysql optimization for a large database

i'm creating a ecommerce web applicaiton using PHP and MYSQL(MYISAM). i want to know how to speed up my queries I have a products table with over a million records with following columns: id (int, primary) catid(int) usrid (int) title (int) description (int) status (enum) date(datetime) recently i split this one table into multiple tables based on the product categories(catid). thinking that it might reduce the load on the server. Now i need to fetch results from these tables combined with following sets of conditions 1. results matching a usrid and status. (to fetch a users products) 2 results matching status and title or description (eg: for product search) now currently i have to use UNION to fetch results from these all tables combined which is slowing down the permormance also i can't apply the LIMIT to the combined result set also. I thought of creating an index on all these columns to speed up the searching but this might slow down the INSERTS and UPDATES. also i'm begingin to think that splitting the table was not a good idea in the first place. i would like to know the best approach to optimize the data retrieval in such a situation. I'm open to new database schema proposals as well.
