[site]: crossvalidated
[post_id]: 452163
[parent_id]: 
[tags]: 
Do we need to rerun a baseline deep Q-learning algorithm's code to get its learning curves in the Atari-57 benchmark?

In the Atari-57 benchmark, when we compare a proposed algorithm with some baseline algorithms, we might want to plot the training curves of the proposed algorithm versus those of the baseline ones, e.g., the figure below (which is from https://arxiv.org/abs/1806.06923 ). My question is that where do we get those learning curves of the baseline algorithms? Do we need to rerun the basline algorithms to get those learning curves or the learning curves are published somewhere (which I don't know)? In a baseline algorithm, they do report numerical results (e.g., normalized scores across games) which can be obviously used as a comparison metric without rerunning the baseline algorithm code. But for the learning curves like the figure below, I am not sure if we must rerun the baseline code to get its learning curves or if there is some resource out there that already makes available the learning curves of some popular Q-learning algorithms. Really appreciate it if you know an answer, especially from those who published in this domain.
