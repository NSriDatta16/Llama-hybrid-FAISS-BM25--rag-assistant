[site]: crossvalidated
[post_id]: 213647
[parent_id]: 213474
[tags]: 
You could consider using feature wrappers (e.g. in R caret ) to find the optimal combination of features. In contrast to feature filters (which consider the inter-feature-correlation and feature-target correlation), wrappers also include the model in their evaluation, therefore measure the model performance. They usually either incrementally add or remove features from the currently used feature set, until a reasonable combination of features is found that optimized your model performance. If your data shows correlation between features (which might be the case if it represents e.g. visual information in some form of spatial way), then dimensionality reduction could in fact make sense, simply due to visual sensing likely only observing a subspace of what could be represented in the whole feature space. Besides using PCA, you could consider using Partial least squares (PLS) regression or similar approaches for this purpose (you could think of PLS regression as a supervised sibling to PCA, as it additionally considers the target variable). Further, it might be the case that the feature-target-relation is too complex for your current model, in which case you would simply have a bias problem and get stuck with a certain amount of error even in training. Using a more powerful model could help in this case.
