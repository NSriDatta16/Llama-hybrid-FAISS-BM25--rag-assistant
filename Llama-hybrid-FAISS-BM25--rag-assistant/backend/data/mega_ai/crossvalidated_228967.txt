[site]: crossvalidated
[post_id]: 228967
[parent_id]: 
[tags]: 
Simulator - a deterministic function of random variables

In this paper, the first discussion ( Universal latent variable representation by C. Andrieu, A. Doucet and A. Lee) authors state that Sampling exactly $Y \sim f(y|\theta)$ on a computer most often means that $Y=\phi(\theta,U)$ where $U$ is a random vector of probability distribution $D(\cdot)$ and $\phi(\cdot,\cdot)$ is a mapping either known analytically or available as a â€œblack-box". And they explain it further. I am trying to understand their point but I am lost. I think I managed to use this idea on a simple example. I did a Approximate Bayesian Computation (should work also for the exact) inference using normal likelihood (known mean, unknown precision $\tau$). So in this case $\theta=\tau$, $U\sim U[0,1]$ and $\phi(\cdot,\cdot)$ is a Box-Muller transformation. So when I simulate data from the likelihood, instead of using numpy normal distribution, I simulate $U$ from uniform distribution and use Box-Muller transformation to get my normally distributed data. However, even if I'm right with this example, I don't know how to apply it to real-world problems. In general I am working on a ABC code to infer from an Agent Based Model (that was given to me in NetLogo, I just call it from my code in Python). So instead of having to simulate from $N(\mu, \frac{1}{\tau})$, I have to run the NetLogo model with proposed parameters $\theta$ ($\theta$ is a multidimensional vector). So my only input to NetLogo model are there parameters. My question is: how can I use the idea from this paper in my case? I.e., what would $U$ and $\phi$ be? I would be grateful for any explanation and help!
