[site]: crossvalidated
[post_id]: 485818
[parent_id]: 485797
[tags]: 
This is actually a very controversial subject. In my career I've noticed that people who understand the CLT often have worse understanding of what is really important when it comes to real-world data. And too often they don't take the time to do simple simulations that show that the CLT can require far greater sample sizes to work than they thought. The idea of large sample theory and asymptotics is not appealing once you get comfortable with the Bayesian paradigm, which focuses on exact inference using flexible models. For example, the Bayesian t-test has parameters for two things we don't know: the ratio of the variances in the two populations, and a parameter for the degree of non-normality in the true unknown distribution. Bayesian posterior inference is exact at all sample sizes and will account for unequal variance and non-normality, and in addition will give you the probability of non-normality. This is explained in my BBR course in section 5.9.3 of the course notes. Another way to get around any need for normality is to use semiparametric models which encompass basic nonparametric tests as special cases. This is also discussed in BBR.
