[site]: crossvalidated
[post_id]: 641413
[parent_id]: 641383
[tags]: 
You seem to have started on the right path, but there are some potential missteps to avoid. I'll assume that you have found that the assumptions underlying the model have been met adequately. With respect to the first question First, the Intercept is the estimated outcome when all predictors are at reference levels (evidently Month6 for Timepoint and the non-WT Genotype ). So adding the Timepoint_Month2 coefficient to the intercept only gives you the estimate for the reference ( non-WT ) level of Geneotype at Month2 . Second, you have to continue that coefficient-addition process carefully as you proceed to predictions that involve the interaction coefficients. For example, to get the Timepoint_Month2 estimate for the non-reference value of Genotype ( WT ) you would start with the above sum to get the reference value at Month2 , then add the coefficient for the non-reference level ( Genotype_WT , for its difference at the reference Month6 ), and finally add the Timepoint_month2:Genotype_WT interaction term that estimates the further difference from what would be predicted based solely on the lower-level coefficients. Third, any such estimate should be accompanied by a corresponding standard error or confidence interval. For that you need access to the coefficient covariance matrix, which is presumably produced as part of the model fit but isn't shown in your model summary. Then use the formula for the variance of a weighted sum of correlated variables to get the variance of whatever linear combination of coefficients that you wish. With respect to the fourth question There are a few potential problems when you say that you want to do post-hoc tests "assuming the interaction term was found to be significant." First, when there are interactions the apparent "significance" of any coefficient depends on how its interacting predictors are coded. See this page , for example. Second, you don't have a single interaction coefficient. You have 3. I assume that Matlab's anova function can give you an overall estimate of the "significance" of all the interaction terms together, but be warned that some ANOVA methods can give misleading results when data are imbalanced. See this page , for example. Third, there's no need to limit yourself to a situation with a "significant" interaction for performing comparisons. If you have a particular comparison of interest, do it while including any interaction coefficient that's involved. Use the coefficient covariance matrix and the formula for the variance of a weighted sum of correlated variables, as above. That's the best description of your data, as lack of statistical significance does not necessarily mean lack of practical significance. If you do several such comparisons, however, you need to take precautions against the multiple comparisons problem . With respect to the second and third questions Bar charts aren't often very useful. For this type of data, plots of estimated outcomes and their confidence intervals over time for each Genotype (at a random intercept value of 0, presumably what the fixed-effect coefficients represent) would be a good choice . As the linear model pools information across all time points and genotypes and individuals to get the underlying error estimates, display the point estimates and confidence intervals from the modeled values instead of from the individual Timepoint:Genotype combinations, which would be complicated here by the random-effect components. In response to comment. The point estimates and standard errors for each combination of Timepoint and Genotype , based on the raw, unmodeled data, aren't the best description of your results if the assumptions underlying your model hold. A linear regression model assumes that all observations share a common random error distribution around the modeled values, which is estimated after taking into account all the combinations of fixed and random effects. The reliability of each model estimate (which is presumably what you want to display) is based on that pooled information about the random error distribution, not on the vagaries of which particular sample of that error distribution was represented in any particular Timepoint and Genotype combination. With a mixed model even the average values at each Timepoint and Genotype combination can be misleading. The random intercepts in your model are estimated by forcing a Gaussian distribution on the set of individual intercept estimates among the Complete_ID levels, each of which is like an extrapolation back to the reference situation ( non-WT and Month6 here). Again, all the data are used to estimate the random effect. Using the raw averages thus doesn't represent your best estimate of the underlying process, as they depend on the vagaries of which individuals (and their random intercepts) happened to be included in each Timepoint and Genotype combination. Final thoughts I'm not sure whether there are tools available in Matlab to simplify the types of calculations above. R has a wide range of tools that simplify modeling and post-model calculations. For example, the emmeans package can take a mixed model (e.g., from the lmer() function of the lme4 package ) and get the point estimates and confidence intervals for each of the Timepoint:Genotype combinations, with appropriate correction for multiple comparisons. The DHARMa package is particularly helpful for evaluating the quality of a mixed model fit, which can be trickier than evaluating an ordinary least squares model.
