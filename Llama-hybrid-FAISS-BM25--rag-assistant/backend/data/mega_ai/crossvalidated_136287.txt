[site]: crossvalidated
[post_id]: 136287
[parent_id]: 123905
[tags]: 
I would consider the following two approaches: dimensionality reduction and sparse regression . The traditional methods for the dimensionality reduction are projective and manifold , as mentioned in my answer here and the reference within, as well as latent variables modeling (LVM) methods, such as exploratory factor analysis (EFA) and confirmatory factor analysis (CFA) . Recently I've run across two R packages - ClustOfVar and clere - that essentially implement dimensionality reduction, but differently than traditional methods like PCA, and, in my view, are closer in their nature to the LVM approach. This alternative approach is referred to as variable clustering and you can find more details in the packages' JSS vignettes: this paper and this paper (unpublished yet?), correspondingly. Additionally, since high-dimensional data is frequently sparse, the second main approach is to use sparse regression . R ecosystem offers many packages, useful for sparse regression analysis, such as Matrix , SprseM , MatrixModels , glmnet and flare . For links and more relevant resources, please see my related answer on DS SE site: https://datascience.stackexchange.com/a/918/2452 . For some overview and more specific examples of support for categorical explanatory variables by PCA, MDS and MCA methods as well as latent variable modeling approaches, please see this paper , these presentation slides (starting from slide 15), this paper , this paper and this paper .
