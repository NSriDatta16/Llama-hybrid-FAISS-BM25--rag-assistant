[site]: crossvalidated
[post_id]: 284413
[parent_id]: 284234
[tags]: 
Neural nets are a broad class of models, and many different loss functions can be used. In fact, SVMs can be thought of as a particular kind of shallow neural net. SVMs are much narrower in scope than neural nets. You can't just pop in any arbitrary loss function, or you'd no longer have an SVM. Furthermore, cross entropy is defined on probability distributions, so it can only be used as a loss function when the classifier gives a probability distribution over classes. SVMs don't do this, so cross entropy won't work. SVMs don't use MSE, they use the hinge loss , which gives them their maximum margin properties.
