[site]: crossvalidated
[post_id]: 433011
[parent_id]: 
[tags]: 
Difference between Mixed Logit model and hierarchical bayesian logit?

I'm studying the discrete choice analysis; The utility of person $i$ for alternative $k$ is: $$U_{ik} = \beta_kx_{ik} + \epsilon_{ik}$$ where $\beta_k$ is the parameter of interest and with $\epsilon_{ik} \sim $ extreme value. For the mixed logit model, this specification is generalized by allowing $\beta_k$ to be random (follow some distribution $f(\beta_k)$ ). The utility of person $i$ for alternative $k \in [K]$ in the mixed logit model: $$ U_{ik} = \beta_{ik}x_{ik} + \epsilon_{ik}$$ with $\epsilon_{ik} \sim $ extreme value. Now we can compute the probability person $i$ choose $k$ as follows: $$\mathbb{P}(i \text{ choose } k) = \int L_i(\beta_k)f(\beta_k)d\beta_k$$ where $L_i(\beta_k) = \frac{\text{exp}(U_{ik})}{\sum_{k'} \text{exp}(U_{ik'})}$ . We can assume that $\boldsymbol{\beta} \sim p(\boldsymbol{\beta} | \boldsymbol{\mu}, \Sigma)$ where $\boldsymbol{\beta} = (\beta_1, \dots, \beta_K) \in \mathbb{R}^K$ . And again $\boldsymbol{\mu}, \boldsymbol{\Sigma}$ has their own distributions and let their prior to be $\boldsymbol{\mu} \sim p(\boldsymbol{\mu}), \boldsymbol{\Sigma} \sim p(\boldsymbol{\Sigma})$ . (I used bolded to represent the vector of size $K$ ) =========================== Now; I feel this is exactly the hierarchical bayesian logit model.The hierarchical structure is as follow (1) Draw from prior, $\boldsymbol{\mu} \sim p(\boldsymbol{\mu}), \boldsymbol{\Sigma} \sim p(\boldsymbol{\Sigma})$ . (2) Draw $\boldsymbol{\beta} \sim p(\boldsymbol{\beta} | \boldsymbol{\mu},\boldsymbol{\Sigma}) = \text{Normal}(\boldsymbol{\mu},\boldsymbol{\Sigma} )$ (3 Posterior distribution would be : $$p(\boldsymbol{\beta},\boldsymbol{\mu},\boldsymbol{\Sigma} | X) \propto L(\boldsymbol{\beta})p(\boldsymbol{\beta} | \boldsymbol{\mu},\boldsymbol{\Sigma})p(\boldsymbol{\mu})p(\boldsymbol{\Sigma})$$ To compute the probability formulated above By specifying the likelihood as above, (1) ran MCMC to get many of the samples to Monte Carlo estimate : $\boldsymbol{\beta},\boldsymbol{\mu},\boldsymbol{\Sigma} \sim p(\boldsymbol{\beta},\boldsymbol{\mu},\boldsymbol{\Sigma} | X)$ $$\mathbb{P}(i \text{ choose } k) = \int_{\boldsymbol{\mu}} \int_{\boldsymbol{\Sigma} } \int_{\beta_k} L_i(\beta_k)p(\boldsymbol{\beta},\boldsymbol{\mu},\boldsymbol{\Sigma} | X)$$ So; mixed logit is basically multinomial logit when you allow $\beta$ has its own distribution; and we can hence, build up hierarchical from there. Am I correct ?
