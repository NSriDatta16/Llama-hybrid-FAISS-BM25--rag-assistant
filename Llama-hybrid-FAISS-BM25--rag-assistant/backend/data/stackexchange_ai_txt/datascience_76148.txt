[site]: datascience
[post_id]: 76148
[parent_id]: 
[tags]: 
deep learning and uncertainty estimation

Recently I got very interested in NLP applications of deep learning. Diving into literature (on arXiv for instance) I noticed that is very unpopular to quote and estimate uncertainties on scores of ML tasks. In the era of pretrained language model (i.e. bert, gpt etc.) all further improvements quoted in papers seems to be compatible among each other within 1 or less standard deviations, making all the results statistically compatible with a fluctuation due to stochastic optimization in neural network training procedure (at fixed data-set). I am a physicist, and this looks really confusing to me when compared to the statistical treatment of experimental data performed by routine in laboratories. I am sure this question has already been discussed in the past in ML/Data Science community, could you point me some review or paper addressing this issue? Also, could you please share with me your thoughts about? Thank you very much
