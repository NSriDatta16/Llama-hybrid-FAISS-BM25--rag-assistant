[site]: crossvalidated
[post_id]: 12024
[parent_id]: 11833
[tags]: 
You may use CUR decomposition as an alternative to PCA. For CUR decomposition, you may refer to [1] or [2]. In CUR decomposition, C stands for the selected columns, R stands for the selected rows and U is the linking matrix. Let me paraphrase the intuition behind CUR decompsosition as given in [1]; Although the truncated SVD is widely used, the vectors $u_i$ and $v_i$ themselves may lack any meaning in terms of the field from which the data are drawn. For example, the eigenvector [(1/2)age − (1/ √2)height + (1/2)income] being one of the significant uncorrelated “factors” or “features” from a dataset of people’s features, is not particularly informative or meaningful. The nice thing about CUR is that basis columns are actual columns (or rows) and better to interpret as opposed to PCA (which uses trancated SVD). The algorithm given in [1] is easy to implement and you can play with it by changing the error threshold and get different number of bases. [1] M.W. Mahoney and P. Drineas, “CUR matrix decompositions for improved data analysis.,” Proceedings of the National Academy of Sciences of the United States of America, vol. 106, Jan. 2009, pp. 697-702. [2] J. Sun, Y. Xie, H. Zhang, and C. Faloutsos, “Less is more: Compact matrix decomposition for large sparse graphs,” Proceedings of the Seventh SIAM International Conference on Data Mining, Citeseer, 2007, p. 366.
