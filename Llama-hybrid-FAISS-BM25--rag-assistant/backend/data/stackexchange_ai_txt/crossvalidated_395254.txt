[site]: crossvalidated
[post_id]: 395254
[parent_id]: 395253
[tags]: 
As I mentioned in my reply to your other question, I am not deeply versed in Bayesian thinking, so take this response with a pinch of salt. I know for these plots that the posterior distribution has the property that is highly likely to be less than 0.8 because most of the mass of the distribution lies below 0.8. I don't actually see the posterior distribution in the first plot. Perhaps it coincides with the prior? (You did use an uninformative prior for that one.) Anyway, your interpretation there is clearly correct. I am also not sure how to determine which is the best model. I'm assuming the third model is the best since it has a narrow posterior distribution which means the values are a lot more certain. I ain't completely sure though. I'm pretty sure this is going about things the wrong way. You select a prior based on the knowledge that you actually have. If your team of experts actually said that the prior probability of choosing drug T (or whatever event this is) was beta distributed with $\alpha = 30, \beta = 15$ , then sure, the obvious choice is to go with the last model. You should note that if your experts said this, then their uncertainty around the distribution P(T) is actually less than your actual data (i.e. the likelihood). If you did not have that prior knowledge, then you needed to use one of the other two priors. I am not familiar with prior selection, so I can't say which is more principled, but both produce pretty similar posterior distributions, which are very similar to your likelihood, which is the data you actually observed - presumably 15 successes in 25 total trials, for a mean of 0.6. Based on the information presented here and in your previous question, there's no best model. It depends on what prior information you can legitimately claim to have.
