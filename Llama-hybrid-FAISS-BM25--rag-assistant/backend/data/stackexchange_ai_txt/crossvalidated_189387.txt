[site]: crossvalidated
[post_id]: 189387
[parent_id]: 186658
[tags]: 
you correctly adopted the train-and-test approach, instead of cross validation. In fact, you should test the model on non-resampled data, in order to maintain the same distribution as in the population and obtain realiable indices of performances. To do this, you need to apply a filtered classifier, then SMOTE and/or undersampling. Still, accuracy (correct guesses on total instances) is not a realiable index of performance in highly skewed datasets, and sensitivity alone does not express the trade off in terms of reduced specificity. You should therefore adopt AUC or Youden Index (J=TPR-FPR) to verify your results. Also, after applying PCA, you may try a decision tree or rule-based algorithm. Hope this helps.
