[site]: crossvalidated
[post_id]: 294409
[parent_id]: 
[tags]: 
Learning from the flaws in the NHST and p-values

I have been reading a lot about problems with null hypothesis significance testing (NHST) and p-values: the replication crisis, reproducibility issues, p-hacking, issues with low statistical power, misunderstandings of p-values, etc. However, it is difficult for me to actually turn these concerns into action, especially regarding the flaws in the NHST. I just have the feeling that in biomedical research where both statistical and clinical significance have a role, the view that the issues with NHST are not that big a deal is reasonable. Let's say I perform a randomized clinical trial in which I aim to investigate the effect of an unnamed drug. I compare it to a placebo. My main interest is some continuous variable, say pain in VAS scale or systolic blood pressure. I measure it after drug/placebo administration. Let's put p-hacking, data dredging all other issues aside and say that in the placebo group the drug effect is $\mu_1$ and in the other group it is $\mu_2$ when compared to the baseline value. SDs are same in both groups. I perform a test. $H_0$ states that $\mu_1=\mu_2$ . I get a p-value of 0.0001. According to the NHST, I reject H0 and conclude that $\mu_1\ne \mu_2$ , which is defined by $H_1$ . I understand quite well the literature about the flaws in this reasoning: The p-value obtained has nothing to do with $H_1$ , the defined $H_1$ is nonsense, it could have been anything, etc. But if I find a mean difference, say, in pain, using the VAS of 0.5cm I can conclude that my result is clinically insignificant since a dozen studies have shown that patient can only notice a change of 1cm in VAS scale. So does this neutralize the issues with NHST? If I do not perform a significance test, what would be most appropriate method to compare these groups? An obvious answer is to use a Bayesian framework, but currently I would prefer other ways. Would bootstrapping or a likelihood ratio test work? And how are these performed in this sort of simple case with a mean comparison? I understand that I should estimate uncertainty much more than to come up with a binary yes/no answer thereby contributing to the p-value fallacy. I just don't understand clearly how to achieve it.
