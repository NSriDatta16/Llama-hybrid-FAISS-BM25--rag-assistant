[site]: crossvalidated
[post_id]: 609045
[parent_id]: 609042
[tags]: 
You can have correlation in two ways in settings like this: the error in $x_i$ is correlated with the error in $y_i$ the error in $x_i$ is correlated with the error in $x_{i+1}$ In both situations, the effect of correlation is on how the positive and negative errors cancel (or reinforce) each other. If the errors in $x_i$ and $y_i$ are positively correlated, the error in $x_i+y_i$ is larger and the error in $x_i-y_i$ is smaller than if they were independent. Similarly, if the errors in $x_i$ and $x_{i+1}$ are positively correlated, the error in the sum (or average) will be higher than if they are independent. In the real world there are reasons why correlated measurement errors are plausible $x$ , $y$ , and $z$ are all measured on the same physical sample, which might not be perfectly representative (air pollution, soil sampling) $x_i$ and $x_{i+1}$ are measured in the same location at different times, and that location is high/low compared to the average measured in the same lab (lab drift/batch effects) negative correlation because $x$ , $y$ , and $z$ add up to a fixed total (% calories from different sources) measurements derived from the same imperfectly accurate theoretical model etc, etc In your case, then, you have the questions: are your measurements positively or negatively correlated? is your function $N$ more like an average or more like a difference? (low-pass or high-pass in engineering terms) These questions aren't how you calculate -- you do that by simulating appropriately correlated errors -- but they are useful for thinking about what you should expect.
