[site]: crossvalidated
[post_id]: 605415
[parent_id]: 
[tags]: 
What happened to the Γ-minimax approach to statistics?

The Γ-minimax approach to statistics seems to offer a pretty nice way of thinking about things foundationally. It essentially views Bayesian and Frequentist statistics as two ends of a spectrum, based on how "big" the family of priors you are considering is/how well you can specify your prior. If you have a completely specified prior, the approach boils down to the usual Bayesian stats. If you have a completely unspecified prior, the approach boils down to the Frequentist minimax approach. Despite the fact that Γ-minimax seems to provide a fairly intuitive way to think of Bayesian vs Frequentist statistics, the most recent meaningful discussion about this topic that I can find is the book " Γ-Minimax: A Paradigm for Conservative Robust Bayesians " which was wrote back in 2000 (though I can't access that book without paying an arm and a leg, so I am unsure of its content beyond knowing that it is cited whenever the Γ-minimax approach is used). Before this, it seems like in 1985 Jim Berger was also discussing this approach. So, what happened? Is the approach dead? Is there some fatal flaw, or is it too difficult to apply? Or is it "fine" but nobody is really too concerned with it? Edit: Just to clarify, I am aware of a few recent papers that invoke the Γ-minimax approach beyond the ones I mentioned, but they are few and far between. What I am asking is why there is very little mention of this approach in present-day statistical discussions, despite the fact that it seems to answer an important question and was an active topic back in the day.
