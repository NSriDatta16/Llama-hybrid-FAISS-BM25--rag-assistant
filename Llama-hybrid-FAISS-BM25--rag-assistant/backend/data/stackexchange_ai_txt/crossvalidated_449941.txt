[site]: crossvalidated
[post_id]: 449941
[parent_id]: 
[tags]: 
Bayesian estimation of case fatality rate?

Let's say we're tracking a global epidemic, such as COVID-19, and we want to estimate the case fatality rate (CFR). The formula for CFR is just 100 * [n(deaths)/n(confirmed cases)] , so the simplest way to get a current estimate of CFR is just to do that computation with the latest available global data. As of yesterday, that's 100 * (1770/71226) , or about 2.5%. Is there a Bayesian approach to deriving that estimate that would allow me to account for observed variation in the CFR across spatial units? Using yesterday's data, we see quite a bit of variability in the observed rate across provinces/states, the lowest level of observation in the data I'm using : Min. 1st Qu. Median Mean 3rd Qu. Max. 0.0000 0.0000 0.0000 0.9868 0.6591 33.3333 This variability isn't just random noise, as it also stems, in part, from meaningful differences in things like healthcare capacity, response strategies, the politics of reporting these cases, and so on. So what I'd like is to find a way to derive an estimate that accounts for those aspects. The approach that came to mind was to fit a mixed-effects model to the data with the observed rates as the dependent variable, a fixed intercept, and then random intercepts for spatial units (e.g., countries) within which these rates are observed. In R, I would do that with: lme4::lmer(cfr ~ 1 + (1 | Country.Region), data = df) When I ran that line on the latest data from 54 provinces/states (the unit of observation) nested in 30 countries, here's what I got. Note that the estimated fixed intercept does differ from the global stat, which was about 2.5%. Linear mixed model fit by REML ['lmerMod'] Formula: cfr ~ 1 + (1 | Country.Region) Data: . REML criterion at convergence: 298.3 Scaled residuals: Min 1Q Median 3Q Max -1.06936 -0.03151 -0.03151 -0.00290 2.97269 Random effects: Groups Name Variance Std.Dev. Country.Region (Intercept) 38.2494 6.1846 Residual 0.5201 0.7212 Number of obs: 75, groups: Country.Region, 30 Fixed effects: Estimate Std. Error t value (Intercept) 1.694 1.136 1.491 Is there a better way to do this? What am I missing? And, if this approach (or one like it) is reasonable, how can I account for the fact that the quantity of interest is bounded at 0 and 100 when I run simulations from the model to generate a distribution of plausible CFRs? I'm guessing I need to use a different family of model in the first place, but which would be most appropriate for a dependent variable that's a rate? For the intrepid, here's a dput of the data I'm using when I run that call to lmer . It's a table with 75 rows representing 75 states or provinces ( Province.State ) nested in 30 countries ( Country.Region ). The rate of interest is cfr , which was computed from n_deaths and n_confirmed . structure(list(Country.Region = c("Australia", "Australia", "Australia", "Australia", "Belgium", "Cambodia", "Canada", "Canada", "Canada", "Egypt", "Finland", "France", "Germany", "Hong Kong", "India", "Italy", "Japan", "Macau", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Mainland China", "Malaysia", "Nepal", "Others", "Philippines", "Russia", "Singapore", "South Korea", "Spain", "Sri Lanka", "Sweden", "Taiwan", "Thailand", "UK", "United Arab Emirates", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "Vietnam" ), Province.State = c("New South Wales", "Queensland", "South Australia", "Victoria", "", "", "British Columbia", "London, ON", "Toronto, ON", "", "", "", "", "Hong Kong", "", "", "", "Macau", "Anhui", "Beijing", "Chongqing", "Fujian", "Gansu", "Guangdong", "Guangxi", "Guizhou", "Hainan", "Hebei", "Heilongjiang", "Henan", "Hubei", "Hunan", "Inner Mongolia", "Jiangsu", "Jiangxi", "Jilin", "Liaoning", "Ningxia", "Qinghai", "Shaanxi", "Shandong", "Shanghai", "Shanxi", "Sichuan", "Tianjin", "Tibet", "Xinjiang", "Yunnan", "Zhejiang", "", "", "Diamond Princess cruise ship", "", "", "", "", "", "", "", "Taiwan", "", "", "", "Boston, MA", "Chicago, IL", "Los Angeles, CA", "Madison, WI", "Orange, CA", "San Antonio, TX", "San Benito, CA", "San Diego County, CA", "Santa Clara, CA", "Seattle, WA", "Tempe, AZ", ""), Lat = c(-33.8688, -27.4698, -34.9285, -37.8136, 50.5039, 12.5657, 49.2827, 42.9849, 43.6532, 26.8206, 61.9241, 46.2276, 51.1657, 22.3193, 20.5937, 41.8719, 35.6762, 22.1987, 31.82571, 40.18238, 30.05718, 26.07783, 36.0611, 23.33841, 23.82908, 26.81536, 19.19673, 38.0428, 47.862, 33.88202, 30.97564, 27.61041, 44.09448, 32.97027, 27.61401, 43.66657, 41.29284, 37.26923, 35.65945, 35.19165, 36.34377, 31.20327, 37.57769, 30.61714, 39.29362, 30.1534, 41.11981, 24.97411, 29.18251, 4.2105, 28.3949, 35.4437, 12.8797, 61.524, 1.3521, 37.5665, 40.4637, 7.8731, 60.1282, 23.6978, 13.7563, 55.3781, 23.4241, 42.3601, 40.6331, 34.0522, 43.0731, 33.7879, 29.4241, 36.5761, 32.7157, 37.3541, 47.7511, 34.0489, 21.0278 ), Long = c(151.2093, 153.0251, 138.6007, 144.9631, 4.4699, 104.991, -123.121, -81.2453, -79.3832, 30.8025, 25.7482, 2.2137, 10.4515, 114.1694, 78.9629, 12.5674, 139.6503, 113.5439, 117.2264, 116.4142, 107.874, 117.9895, 103.8343, 113.422, 108.7881, 106.8748, 109.7455, 114.5149, 127.7622, 113.614, 112.2707, 111.7088, 113.9456, 119.464, 115.7221, 126.1917, 122.6086, 106.1655, 96.02564, 108.8701, 118.1529, 121.4554, 112.2922, 102.7103, 117.333, 88.7879, 85.17822, 101.4868, 120.0985, 101.9758, 84.124, 129.638, 121.774, 105.3188, 103.8198, 126.978, -3.7492, 80.7718, 18.6435, 120.9605, 100.5018, -3.436, 53.8478, -71.0589, -89.3985, -118.2437, -89.4012, -117.8531, -98.4936, -120.9876, -117.1611, -121.9552, -120.74, -111.094, 105.8342), date = structure(c(18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308, 18308), class = "Date"), n_confirmed = c(4L, 5L, 2L, 4L, 1L, 1L, 4L, 1L, 2L, 1L, 1L, 12L, 16L, 57L, 3L, 3L, 59L, 10L, 962L, 380L, 551L, 287L, 90L, 1316L, 237L, 144L, 162L, 300L, 445L, 1231L, 58182L, 1004L, 70L, 617L, 925L, 89L, 121L, 70L, 18L, 236L, 537L, 328L, 129L, 481L, 124L, 1L, 71L, 171L, 1167L, 22L, 1L, 355L, 3L, 2L, 75L, 29L, 2L, 1L, 1L, 20L, 34L, 9L, 9L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 16L), n_deaths = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 6L, 4L, 5L, 0L, 2L, 2L, 2L, 1L, 4L, 3L, 11L, 13L, 1696L, 3L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 1L, 0L, 3L, 3L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), n_recovered = c(4, 0, 0, 4, 0, 1, 0, 1, 0, 0, 1, 4, 1, 2, 3, 0, 12, 5, 255, 108, 207, 82, 54, 465, 49, 46, 52, 105, 79, 440, 6639, 464, 8, 218, 240, 30, 40, 33, 13, 71, 173, 140, 50, 131, 45, 1, 12, 42, 456, 7, 1, 0, 1, 2, 18, 9, 2, 1, 0, 2, 14, 8, 4, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 7), cfr = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8.33333333333333, 0, 1.75438596491228, 0, 0, 1.69491525423729, 0, 0.623700623700624, 1.05263157894737, 0.907441016333938, 0, 2.22222222222222, 0.151975683890578, 0.843881856540084, 0.694444444444444, 2.46913580246914, 1, 2.47191011235955, 1.05605199025183, 2.91499089065347, 0.298804780876494, 0, 0, 0.108108108108108, 1.12359550561798, 0.826446280991736, 0, 0, 0, 0.37243947858473, 0.304878048780488, 0, 0.623700623700624, 2.41935483870968, 0, 1.40845070422535, 0, 0, 0, 0, 0, 33.3333333333333, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), class = "data.frame", row.names = c(NA, -75L)) PS. On GitHub, I have since found a great worked example of a non-Bayesian approach to this problem; see here . I guess this is how the epidemiology pros tackle the problem in real time...
