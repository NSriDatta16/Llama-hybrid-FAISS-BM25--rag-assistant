[site]: crossvalidated
[post_id]: 567158
[parent_id]: 
[tags]: 
Is there a name for this "generalized PCA"?

I was trying to understand the difference between Principal Component Analysis (PCA) and Canonical Covariate Analysis (CCA), and noticed that if you write them down to look as similar as possible, there's a generalization of the PCA that pops out: $\DeclareMathOperator{\Var}{Var}$ $\DeclareMathOperator{\Cov}{Cov}$ $\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}$ (Let $\mathbf x$ and $\mathbf y$ be two vector-valued random variables (not necessarily of the same dimension) with finite second moments.) PCA: At the $i$ th step, find a vector $\mathbf \alpha _i$ that maximizes $\Var(\mathbf \alpha _i ^T \mathbf x)$ subject to the constraint that $\norm{\mathbf \alpha _i} = 1$ and the constraint that $\mathbf \alpha _i$ is orthogonal to $\mathbf \alpha _j$ for all $j . CCA: At the $i$ th step, find a vectors $\mathbf \alpha _i$ and $\mathbf \beta _i$ that maximize $\Cov(\mathbf \alpha _i ^T \mathbf x, \mathbf \beta _i ^T \mathbf y)$ subject to the constraint that $\Var(\mathbf \alpha _i ^T \mathbf x) = \Var(\mathbf \beta _i ^T \mathbf y) = 1$ and the constraint that $\Cov(\mathbf \alpha _i ^T \mathbf x, \mathbf \alpha _j ^T \mathbf x) = \Cov(\mathbf \beta _i ^T \mathbf y, \mathbf \beta _j ^T \mathbf y) = 0$ for all $j . "Generalized PCA": At the $i$ th step, find a vectors $\mathbf \alpha _i$ and $\mathbf \beta _i$ that maximize $\Cov(\mathbf \alpha _i ^T \mathbf x, \mathbf \beta _i ^T \mathbf y)$ subject to the constraint that $\norm{\mathbf \alpha _i} = \norm{\mathbf \beta _i} = 1$ and the constraint that $\mathbf \alpha _i$ is orthogonal to $\mathbf \alpha _j$ , and that $\mathbf \beta _i$ is orthogonal to $\mathbf \beta _i$ is orthogonal to $\mathbf \beta _j$ for all $j . So if $\mathbf x = \mathbf y$ , then the "Generalized PCA" between $\mathbf x$ and $\mathbf y$ is just equivalent to the PCA on $\mathbf x$ . Is there a standard name for this "Generalized PCA"? Is it useful for anything, and where can I learn more about it?
