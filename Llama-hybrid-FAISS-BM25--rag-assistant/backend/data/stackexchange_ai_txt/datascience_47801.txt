[site]: datascience
[post_id]: 47801
[parent_id]: 47790
[tags]: 
In general, if you only have $5$ to $6$ scalar features. I would simply start with easy methods like logistic regression and discriminant analysis. I would guess that you should be able to get good results. You should also look at the distribution of the scalar features. Maybe you can derive new features that are helpful in separating. A simple visual way to see if it is possible to separate the classes by a linear hyperplane is to use a principal components analysis (short PCA) and extract 2 or 3 factors. Then use these factors to visualize your datapoints (maybe use a random sample from the training data set and repeat this three or more times to see if the trend is there in all random samples that you looked at). You should see if the classes are well sparable. If you see that your model performance is not good enough I would try out decision trees (these are very interesting as they allow you to see how the decisions of your classifier are made). Depending on the model performance you could also use neural networks. I personally would rather try it with simpler models first. Neural networks are very powerful function approximators, but you will most likely not be able to extract some useful information about the relationship between the features and the classes of products.
