[site]: crossvalidated
[post_id]: 213612
[parent_id]: 213574
[tags]: 
I think that the difference in what logistic regression does compared to support vector machines is well covered in other questions: for example The difference between logistic regression and support vector machines? and ultimately, the best way to understand that question is to full understand how logistic regression works, and fully understand how support vector machines work (this answer - How does a Support Vector Machine (SVM) work? - may help with the second) But the second question around the use cases has possibly not been explored as well as it might - in the SVM vs logistic regressions a lot of the advice is of the type 'try it with your data and see', which is fair enough, but doesn't mean there aren't reasonable distinctions that can be made. With respect to logistic regression, at the top of its list of advantages is that it will produce a model that is considerably more explainable. Also, as it comes from the family of GLMs, there are statistical tools available to understand the relationships between the predictors and the target, and, most importantly, to formally statistically test the relationship between the predictors and the target. The trade-off is that you have the adhere to the usual GLM assumptions of linearity, independent predictors etc. The strict requirements to adhere to those assumptions don't apply to SVMs to the same extent, and hence you can apply them successfully to a wide range of data. In particular, via the kernel trick you can deal with non-linear decision boundaries successfully. However, in return you give up the kind of understanding of how each predictor contributes to the model that logistic regression provides.
