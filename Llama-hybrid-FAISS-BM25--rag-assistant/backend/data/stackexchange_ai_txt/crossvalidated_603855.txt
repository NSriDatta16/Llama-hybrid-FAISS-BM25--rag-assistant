[site]: crossvalidated
[post_id]: 603855
[parent_id]: 
[tags]: 
Why data-scaling in range (0,1) is important?

Often a preprocessing technique to do is to normalize our data in a range (0,1) before we tow our model (example neural network) on them. I understand why in a practical way (for example if we have the height of something in kilometers and its weight in like picograms). However, if we are dealing with, for example, images in a range (0,255) why do we convert these in a range (0,1) (through a images = images /255. ). Everyone talks about the benefits of doing this, but I haven't found any papers that actually talk about it. Could you give me some papers/books where this is discussed?
