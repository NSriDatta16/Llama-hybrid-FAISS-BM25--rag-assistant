[site]: crossvalidated
[post_id]: 241315
[parent_id]: 239926
[tags]: 
Well, the whole idea of machine learning is that you let the algorithm decide which inputs are important and which aren't. At times, we might want to restrict the algorithm to focus on combining inputs in certain ways. An example for images is convolutional neural nets. Here we use the fact that patterns in images are based on the values of near-by pixels. What you could do for example is first feed the inputs in one dimension into sub-nets and then combine the outputs of those nets into a final net. For example first feed all the means into one net and the variances into another and then combine the outputs of those nets into a final net. However you could also feed all properties of each pixel into subnets and then feed the outputs of each pixel into a bigger net. In this case, it isn't obvious what would give better results and why. So my advice would be that if you have obvious structure like in images, you might make use of it like in convolutional neural nets. However if it isn't obvious, just let the network figure it out. That is what it's for.
