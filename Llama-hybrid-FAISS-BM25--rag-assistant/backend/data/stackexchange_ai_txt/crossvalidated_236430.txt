[site]: crossvalidated
[post_id]: 236430
[parent_id]: 
[tags]: 
Seeking help in Bayesian Mixed Effects Model

I am implementing a Bayesian Mixed Effects model in my research problem. The model is written as, $y_i = X_i(\alpha + \beta_i) + \epsilon_i$, where $i = 1, 2, \ldots, m$ is the index of response, $j = 1,2, \ldots, n_i$ is the number of samples collected for each $i$th response, $k = 1, 2, \ldots, p$ is the index of predictor variable and $\alpha_k$ is the $k$th fixed effect and $\beta_{ik}$ is the $k$th random effect on $i$th response. The design matrix is same for both fixed and random effects i.e. suppose I am generating a test data by using $Y \sim \mathcal{N}(X\alpha, X\Sigma_{\beta}X^T + \sigma^2_\epsilon \mathbb{I})$. Suppose $m=4$, $n_i = 5$ and $p = 3$. So, $Y$ is a matrix of size $5\times4$, $X$ is $4\times 3$, $\alpha$ is $3 \times 1$, $\beta$ is $4 \times 3$. I am assuming $\Sigma_{\beta} = \text{diag}(\sigma_1^2, \sigma_2^2, \sigma_3^2)$. Prior specification: $\alpha \sim \mathcal{N}(0, D_\gamma^{-1})$ with $D_\gamma = \text{diag}(\gamma_1, \gamma_2, \gamma_3)$ $\beta_i \sim \mathcal{N}(0, D_\delta^{-1})$ with $D_\delta = \text{diag}(\delta_1, \delta_2, \delta_3)$ $\sigma^{-2} = \rho \sim \text{Gamma}(a, b)$ $\gamma_k \sim \text{Gamma}(c_k, d_k)$ $\delta_k \sim \text{Gamma}(e_k, f_k)$. My aim is here to ask you to verify whether I am going correct or not. (1) Before going into the computation of full conditionals for Gibbs sampling, $X_1$ for $y_1$ i.e. response $1$ is represented as $1$st row of $X$ repeated 5 times, for response 2 $X_2$ as $2$nd row of $X$ repeated $5$ times and so on. (2) In implementing Gibbs sampling when I am finding the full conditionals, I am getting stuck at finding conditional for random effects. I am finding conditionals in independent manner i.e. for each $\beta_{ik}, i = 1, \ldots,4; k = 1, \ldots, 3$ like $p(\beta_{ik}|y_i, \alpha, \beta_{i,-k}, \rho, D_\gamma, D_\delta)$, where $\beta_{i,-k}$ is $k$th component is removed from $\beta_i$. I feel there will be $p = 3$ variances for posterior distributions of $\beta_k$s. I mean to say that the variances of posteriors of random effects will depend upon number of predictor variables and not on the number of responses. Can anybody please tell me if I am doing anything wrong or not?
