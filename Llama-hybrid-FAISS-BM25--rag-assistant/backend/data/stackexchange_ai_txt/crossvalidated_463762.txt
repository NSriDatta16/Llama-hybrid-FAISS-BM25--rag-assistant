[site]: crossvalidated
[post_id]: 463762
[parent_id]: 463751
[tags]: 
This isn't exactly what you've asked for, but it's a very easy solution to implement in neural network libraries like keras, tensorflow and pytorch. The main idea is to penalize the loss whenever the inequality $L_1 > L_2$ is violated. This inequality is violated whenever $L_2 \ge L_1$ ;on the other hand, we don't want to penalize the loss at all when $L_1 > L_2$ . This describes a ReLU function in $L_1, L_2$ : $$ \min L_1 + L_2 + \lambda\text{ReLU}(L_2 - L_1) $$ The hyper-parameter $\lambda>0$ controls how steep the penalty should be for violating the inequality. This loss doesn't guarantee that the inequality is satisfied, but it is an improvement over minimizing $L_1 + L_2$ alone. This loss is just a composition of functions readily available in modern neural network libraries, so it's simple to implement. In comments, jkpate makes the following suggestion: Notice that if you incorporate a maximization over $\lambda$ , then we do get exactly what the poster asked for because we now have a two-player formulation of the Lagrange dual to the original constrained optimization problem. Essentially, rather than setting $\lambda$ be fixed, we allow the penalty for a violation to grow. See Cotter et al. "Two-Player Games for Efficient Non-Convex Constrained Optimization" (2019) for the theory and https://github.com/google-research/tensorflow_constrained_optimization for a Tensorflow implementation. If I understand correctly, this allows the estimation procedure to select a good value of $\lambda$ , rather than the user fixing a particular value ahead of time and worrying about whether that fixed value is a good choice.
