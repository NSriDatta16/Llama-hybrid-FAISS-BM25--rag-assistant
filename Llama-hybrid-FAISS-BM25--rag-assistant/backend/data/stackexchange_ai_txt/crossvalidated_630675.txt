[site]: crossvalidated
[post_id]: 630675
[parent_id]: 630662
[tags]: 
The matrix dimensions are unrelated to the maximum length of the input. This becomes clear if you examine the equations for whatever RNN variety you're interested in: they all have recurrence in common, so the same weights are re-used to predict $t+1$ using data at $t$ and hidden state information $h_t$ . The hidden weight dimension $H \times H$ refers to the number of units in the hidden layers: $H$ inputs mapped to $H$ outputs.
