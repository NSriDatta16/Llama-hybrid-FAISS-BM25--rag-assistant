[site]: crossvalidated
[post_id]: 358922
[parent_id]: 234615
[tags]: 
Deep learning requires a neural network having multiple layers — each layer doing mathematical transformations and feeding into the next layer. The output from the last layer is the decision of the network for a given input. The layers between the input and output layer are called hidden layers. A deep learning neural network is a massive collection of perceptrons interconnected in layers. The weights and bias of each perceptron in the network influence the nature of the output decision of the entire network. In a perfectly tuned neural network, all the values of weights and bias of all the perceptron are such that the output decision is always correct (as expected) for all possible inputs. How are the weights and bias configured? This happens iteratively during the training of the network — called deep learning. (Sharad Gandhi)
