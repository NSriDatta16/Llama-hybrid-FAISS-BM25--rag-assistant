[site]: datascience
[post_id]: 29824
[parent_id]: 
[tags]: 
Using L1 penalty in XGBoost

I'm trying to use L1 regularization to select features in XGBoost classifier. However, I don't see any example code on how to specify the penalty of l1. This is how I do in sklearn's LogisticRegression. C = [10, 1, .1, .001] for c in C: clf = LogisticRegression(penalty='l1', C=c) clf.fit(X_train, y_train) print('C:', c) print('Training accuracy:', clf.score(X_train, y_train)) How should I specify penalty and C in XGBoost?
