[site]: crossvalidated
[post_id]: 285058
[parent_id]: 
[tags]: 
Why Machine Learning is indifferent regarding the dependence / muti-collinearity of predictors in regression?

Machine Learning is in generally impervious to the violation of the independence assumption among the predictors of a regression model -- frequently employing in its models features that are correlated and dependent. Prediction accuracy empirically does not seem to suffer because of this tolerance to multi-collinearity of predictors. Why is this the case? After all --speaking for example about logistic regression-- the conditional probability of the even of interest Y to happen given the data X = {X1, X2, ..., Xn} is defined as the product of the conditional probabilites Y | Xi, which is true only if Xi are independent and therefore uncorrelated. Your advice will be appreciated.
