[site]: datascience
[post_id]: 102404
[parent_id]: 
[tags]: 
Best Practices For Dealing With This Scenario

I'm presently building a spam classifier. The model is unable to even overfit the training set at present. To investigate, I plotted the distributions of the model's features, and compared them across spammers and non-spammers. I've noticed that the distributions for most features between the two classes are almost identical - suggesting many spammers look similar to non-spammers in terms of behavior. I suspect this confuses the model. To counter this, I'm conducting more feature engineering, as well as some data re-labelling (not sure if my labels are trustworthy), to see if I can inject more signal into the model. I'm not sure if this is the best approach, and would appreciate any insights / reading material on how to deal with this situation. Thanks.
