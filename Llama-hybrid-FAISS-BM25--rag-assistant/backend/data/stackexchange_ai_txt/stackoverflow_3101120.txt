[site]: stackoverflow
[post_id]: 3101120
[parent_id]: 3101048
[tags]: 
we are facing a similar problem. The solution we came uo with was to not use xslt for this case, and instead use Linq to Xml transformations while stteaming the data. You can leverage the c# yield keyword to iterate through an xml stream and tackle the file piecemeal this way. See streaming with linq to xml the nature of xslt requires the xml to be loaded into memory. what needs to occur is you need to break down the large file into more managable pieces. if you use the xml streaming technique, you can break the document up into sub elements which you can then individually apply the xslt to. you may have to rewrite the xslt to accomodate this behavior. Aside from this, the only other option is to throw more hardware at it, but this might even require an operating system upgrade depending on RAM limitations...
