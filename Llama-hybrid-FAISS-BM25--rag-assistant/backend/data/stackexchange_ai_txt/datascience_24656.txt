[site]: datascience
[post_id]: 24656
[parent_id]: 
[tags]: 
Machine Learning algorhtm that can be trained to learn Pig-Latin

Pig-Latin , and other similair argots , were quite popular when i was young (but since i grew up in Sweden the biggest was Rövarspråket ). These language games almost always consist of a given set of rules from which letters and words are translated into something else. For example in Pig-Latin the rules are the following ( source ): For words that begin with consonant sounds, all letters before the initial vowel are placed at the end of the word sequence. Then, "ay" is added, as in the following examples:[10] "pig" = "igpay" "latin" = "atinlay" When words begin with consonant clusters (multiple consonants that form one sound), the whole sound is added to the end when speaking or writing.[11] "cheers" = "eerschay" "shesh" = "eshshay" For words that begin with vowel sounds, one just adds "way" or "yay" to the end (or just "ay"). Examples are: "eat" = "eatway" or "eatay" "omelet" = "omeletway" or "omeletay" An alternative convention for words beginning with vowel sounds, one removes the initial vowel(s) along with the first consonant or consonant cluster. This usually only works for words with more than one syllable and offers a more unique variant of the words in keeping with the mysterious, unrecognizable sounds of the converted words. Examples are: "every" = "eryevay" "omelet" = "eletomay" My question is if there are any Machine Learening algorithms that is suitable to be able to learn to translate a sentence to Pig-Latin by training on a large set of "english"="pig_latin" -pairs without explicity knowing anything about the rules? Or if anybody can motivate and point me to the right direction. My goal is to be able to input an arbitrary word, which might not even be a real word, and get the "Pig-Latin"-translated word. My initial idea was to set up a Neural Network (mainly because thats what I know best) where the input neurons should take the ASCII-code for each letter and the output should be the ASCII-code for each letter (always capital letters), i.e. Input (for PIG): 080 073 071 Output (for IGPAY)): 073 071 080 065 089 A neural network can be trained to map for example 080 to 073, but how do i for example handle the aribtrary length of the input and output (if Neural Networks ar applicable to this problem).
