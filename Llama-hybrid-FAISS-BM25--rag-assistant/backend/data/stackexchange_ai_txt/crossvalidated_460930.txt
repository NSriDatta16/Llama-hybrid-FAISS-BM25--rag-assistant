[site]: crossvalidated
[post_id]: 460930
[parent_id]: 
[tags]: 
Using AIC to compare models with collinear explanatory variables

I'm using logistic regression to test whether the proportion of seeds to germinate across an elevational gradient is explained by temperature, precipitation, elevation, or other site features that I didn't directly measure. These other features are represented within a categorical variable for site id. My model looks like this: model_1 Due to an admittedly sub-optimal experimental design, each site has only one value for each temperature and precipitation and each site logically has only a single value for elevation. Due to the lack of site-level variation in these variables, the above model fails due to perfect multicollinearity*. Since the model fails, I can't test if any of the continuous variables explain variation in emergence beyond what's explained by the site id variable. To get around this, I've considered splitting the model into the following and comparing the AIC/BIC values to see which model is a better predictor of emergence. model_2 Since not all of the continuous predictors in model 2 may be important in predicting emergence, I could perform backward selection with AIC to find the optimal model. But as far as I can tell from other online discussions, model selection through AIC is philosophically incompatible with my intended way of assessing the importance of each explanatory variable (likelihood-ratio tests comparing models with and without each variable, comparisons of estimated marginal mean emergence per site and trend-lines of estimated marginal means for continuous variables). So, my question in general terms is how can I assess the importance of colinear variables in driving a phenomenon? Any advice would be greatly appreciated. The VIF values for model 1 are ~ 150 but in model_3 (site removed), the VIF values are
