[site]: datascience
[post_id]: 61336
[parent_id]: 61312
[tags]: 
Big Note: Unless you do not define what "interesting" is, Machine Learning can not do anything for you. Clustering only tells you which documents are similar to eachother but YOU need to define which cluster is interesting (BTW, clustering in terms of context is called Topic Modeling as each cluster of written text is about some topics). Now my suggestions: Topic Modeling Use a simple LDA to detect topics of each document and cluster docuemnts based on topics. For each topic, print first 5 dominant keyword and if they interest you, then rad the articles. Keyword Search Set up a list of keywords you would like to read about. Using a simple TF-IDF model you can find "high score" docuemnts according to your favorite keywords. Keyword Extraction You may extract keywords of each document usng RAKE with a score higher than a manual threshold. See if keywords interest you or not. (conceptually close to LDA but here you can extract keywords from each individual document, while LDA makes sense if you have a corpus of text.) Update According to the additional info in the comments, the question turned even more towards classic recommender systems. We have the number of clicks per article and we use it as the interestingness score. Now one may say (a very basic idea to be honest): Crawl all the articles and Use RAKE to extract keywords from n most interesting articles. Use those keywords as search queries. Use BM25 algorithm to search those queries and get bm25 score for each article according to queries. Aggregate those bm25 score with interestingness score (e.g. simply multiply them) and rank articles from most interesting to least interesting.
