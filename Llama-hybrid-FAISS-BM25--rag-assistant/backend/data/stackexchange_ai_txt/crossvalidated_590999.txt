[site]: crossvalidated
[post_id]: 590999
[parent_id]: 
[tags]: 
Correction for multiple comparisons using sum contrasts with linear regression

I am computing the following model using the lme4 package in R: score ~ expertise*(mood + condition + course) **(EDIT: + (1|participant))** Outcome: score / numeric (1-7) Inputs: expertise / factor (NOVice, expert) condition / factor (ALOne, together) mood / numeric (1-7) course / factor (YES, NO) All the factors are coded using sum contrasts. The result looks like this: Predictor b Std.Er df (Intercept) 1.52941 0.22044 152.36196 6.938 1.07e-10 *** expertiseNOV -0.26262 0.22044 152.36196 -1.191 0.23539 condALO 0.02033 0.03133 710.39747 0.649 0.51666 mood 0.31964 0.03153 744.54866 10.137 If I interpret this model correctly, expertiseNOV to courseYES should be the main effects at the average level of the other predictors. Furthermore, the interaction "expertiseNOV:condALO" is for example telling me that there is a significant difference between experts and novices for the condition "alone". I now would like to know if there is also a significant difference for the condition "together". I could now reorder the factors and get the results for the following interaction: "expertiseNOV:condTOG" Would I then need to correct my results for multiple comparisons? Or is this just the wrong way to approach this issue? EDIT 04.10.2022 As I assigned the contrast schemes manually, I seem to have made a small mistake when assigning the names for the factor "condition". Here is the complete procedure I am using based on simulated data as proposed by @dipetkov. The code features one model using treatment contrasts and one using sum contrasts. set.seed(1234) n % mutate( expertise = as.factor(expertise), cond = as.factor(cond), course = as.factor(course), ) #sum contrasts contr_sum Output model_sum: Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 0.09177 0.23428 0.392 0.696 expertiseNOV 0.28286 0.23428 1.207 0.230 mood 0.01672 0.05225 0.320 0.750 condTOG 0.03264 0.10073 0.324 0.747 courseYES 0.15819 0.10194 1.552 0.124 expertiseNOV:mood -0.06743 0.05225 -1.290 0.200 expertiseNOV:condTOG 0.06188 0.10073 0.614 0.541 expertiseNOV:courseYES -0.04754 0.10194 -0.466 0.642 Output model_trea: Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 0.57980 0.41055 1.412 0.161 expertiseNOV -0.59440 0.60245 -0.987 0.326 mood -0.05071 0.06741 -0.752 0.454 condTOG -0.18903 0.26240 -0.720 0.473 courseYES -0.22131 0.26476 -0.836 0.405 expertiseNOV:mood 0.13485 0.10451 1.290 0.200 expertiseNOV:condTOG 0.24750 0.40291 0.614 0.541 expertiseNOV:courseYES -0.19014 0.40774 -0.466 0.642
