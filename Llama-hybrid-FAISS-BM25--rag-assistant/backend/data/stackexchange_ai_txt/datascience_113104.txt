[site]: datascience
[post_id]: 113104
[parent_id]: 113086
[tags]: 
"Unbalanced" data are not a problem, unless you use unsuitable error measures... like accuracy , or precision, recall and the F1 (or any other Fbeta) score, all of which suffer from exactly the same problems as accuracy. Instead, work directly with probabilistic predictions, and assess the probabilistic predictions directly using proper scoring rules. Do not use thresholds in evaluating your statistical model. The choice of one or more (!) thresholds is an aspect of the decision , together with your probabilistic classification. It is not part of the statistical model. We have many, many, many threads on unbalanced data at CrossValidated, and we are at a bit of a loss what to do with these, because the data science community apparently sees a problem here that completely disappears once you move away from intuitive but misleading evaluation measures . We have a Meta.CV thread dedicated to this, with a number of links to other CV threads.
