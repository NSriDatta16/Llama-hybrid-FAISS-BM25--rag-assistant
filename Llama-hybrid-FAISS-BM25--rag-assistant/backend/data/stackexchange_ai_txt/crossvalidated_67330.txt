[site]: crossvalidated
[post_id]: 67330
[parent_id]: 46485
[tags]: 
In my opinion, some of the most convincing results from the deep learning community in the past few years have come from the area of automatic speech recognition (ASR). At this point, ASR has seen about four decades of excellent work from a number of really smart people, so the field has been on something of a plateau for the past 10 years or so. For example, it's generally considered publishable in this field if you get a result with one-half percent decrease in word error rate over the state of the art. However, results using deep models have seen remarkable progress in the field in the past few years. Notably, deep models have resulted in a 5% decrease in word error rate for some systems. In addition, deep models appear to be able to learn appropriate feature representations from simpler encodings of speech ; that is, instead of using a typically hand-coded pipeline transforming speech waveforms into mel-frequency cepstral coefficients (MFCCs), deep models appear to be able to learn effective representations of speech data solely from the data, thus removing the need to hard-code these cepstral (or other) representations. These results are remarkable given the historical progress in the field. Sample references L Deng et al. "Recent Advances in Deep Learning for Speech Research at Microsoft." ICASSP 2013. A-R Mohamed et al. "Deep belief networks using discriminative features for phone recognition." ICASSP 2011. G Dahl, T Sainath, G Hinton. "Improving Deep Neural Networks for LVCSR using Rectified Linear Units and Dropout." ICASSP 2013.
