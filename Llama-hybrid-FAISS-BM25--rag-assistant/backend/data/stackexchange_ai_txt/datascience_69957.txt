[site]: datascience
[post_id]: 69957
[parent_id]: 
[tags]: 
Why ROC value area under curve of two models is different whereas accuracy, precision, recall, f1-score and confusion matrix is same

I am applying logistic regression and support vector machines on the extacly same dataset with 70% data for training and 30% for test. Both perform exactly the same have the same precision, recall, f1-score and confusion matrix. The confusion matrix and classification report for both can be seen below. [1180 0] [ 17 0]] precision recall f1-score support 0 0.99 1.00 0.99 1180 1 0.00 0.00 0.00 17 accuracy 0.99 1197 macro avg 0.49 0.50 0.50 1197 weighted avg 0.97 0.99 0.98 1197 I applied 10-fold cross validation to both models too both achieve the same mean accracy of 98.57% both failing to achieve any True Positives across all 10 folds, also have same number of TP,TN,FP,FN in each of the 10-fold However, the problem is when I compute the roc area under curve values they are different as seen below: Logistic Regression: 0.86 Support Vector Machines: 0.23 These values indicate logistic regression is much better as compared to support vector machines although there confusion matrix and classification report is the same I am really confused as all the other reuslts indicated same performance by both models ?? Can someone please help why both get different values of roc whereas everything else is the same.
