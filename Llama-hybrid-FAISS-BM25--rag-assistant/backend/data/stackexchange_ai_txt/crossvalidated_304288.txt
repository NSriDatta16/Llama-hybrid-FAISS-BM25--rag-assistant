[site]: crossvalidated
[post_id]: 304288
[parent_id]: 304287
[tags]: 
Usually you initialise them to 1.0 Biases should be trainable variables not constant, their value must be allowed to change during training. Biases are necessary in every deep network architecture I know of, without them your network will most likely be unable to learn anything. I don't know what a siamese neural network is but in architectures where weights are shared (such convolution neural networks) weights and biases are always shared together as they come in pairs, the combination of the two is what defines a layer.
