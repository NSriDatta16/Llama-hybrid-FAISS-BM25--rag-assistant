[site]: crossvalidated
[post_id]: 126447
[parent_id]: 126305
[tags]: 
I'm not entirely sure what you meant, but as I understood, you want to know which features out of your 46 those 12 are, correct? In other words, you want to go back to your original data and find out what they were. Also you want to know the relative importance of each feature. When you look at your PCA loadings, these values tell you something about the relative importance of your individual features for each Principal Component. You can calculate the norm of each feature, which will tell you how important that variable is. Usually, what you would ideally get is a list of "norm values" (one per feature). When a "norm value" is close to 1, the variable is important to your PCA separation; if it's close to 0, it is not important. Do keep in mind that depending on your data, you have to include any number of PC's. In low-dimensional data, you may need to include only the first 3 PCs, whereas in high-dimensional data, you might need to include 50 PCs to get a sufficient "norm value". However, an easier approach may be to use some kind of machine learning method that includes feature selection like Random Forests . With Random Forests, you can also have it calculate the feature importance, so that would solve your problem too. Hope this helps :)
