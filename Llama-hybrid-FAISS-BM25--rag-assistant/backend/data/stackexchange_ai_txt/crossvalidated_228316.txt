[site]: crossvalidated
[post_id]: 228316
[parent_id]: 
[tags]: 
Absolute Error as a tool to evaluate model

I want to predict a binary response variable y using logistic regression. x1 to x4 are the log of continuous variables and x5 to x7 are binary variables. Call: glm(formula = y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, family = binomial(), data = df) Deviance Residuals: Min 1Q Median 3Q Max -2.6604 -0.5712 0.4691 0.6242 2.4095 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -2.84633 0.31609 -9.005 The output of the GLM shows that most of my variables are significant for my model, but the various goodness of fit test I have done: anova tell me that there is a lack of evidence to support my model. More over, I have a bimodal deviance plot. I suspect the bimodal distribution is caused by the sparsity of my binary variables. So I calculated the absolute error abs(y - y_hat) , and obtained the following: 77% of my absolute errors were in [0;0.25], which I think is very good! On the following plot, Y=1 is red, and Y=0 is green. This model is better at predicting when Y will be 1 than 0. My question is thus the following: The goodness of fit tests all assume that my null hypothesis follows a Chi square distribution of some sort. Is it correct to conclude that based on my absolute error, my model's prediction is OK, it's just that it doesn't follow a Chi square distribution and thus perform poorly with these tests?
