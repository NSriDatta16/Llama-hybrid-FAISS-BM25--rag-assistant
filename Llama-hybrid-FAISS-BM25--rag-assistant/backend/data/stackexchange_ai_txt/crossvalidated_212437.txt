[site]: crossvalidated
[post_id]: 212437
[parent_id]: 212436
[tags]: 
Standard crawling and screenscraping is the way to go for such tasks (tools like scrapy are extremely powerful if you learn their full capabilities). Very often, the information you are looking for is fairly easy to crawl, based on div classes and so on (even across webpages). Writing a sufficiently generic crawler that requires little tuning for new webpages should not take too long. Machine learning methods for such tasks are typically not fully automated either, or make a lot of mistakes (which means you have a lot of work postprocessing anomalies manually). Overall, it would take you much much longer to perform such tasks with machine learning at the moment. The first problem would be a lack of training sets, and if you want to construct those manually you end up writing screenscrapers anyway.
