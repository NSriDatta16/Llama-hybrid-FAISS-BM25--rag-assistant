[site]: crossvalidated
[post_id]: 623110
[parent_id]: 623101
[tags]: 
Just to give an example that hasn't been mentioned yet: in logistic regression, a regularizing term based on the Jeffreys prior was shown by Firth to produce unambiguously better estimates (in terms of reducing both bias and variance) than vanilla MLE. And as a cherry on top it also mitigates the problem of perfect separation (see Heinze and Schemper ). There's already a great post explaining why it works , so I'm not going to repeat it here. Ironically it is not commonly "advertised" as a Bayesian method, but rather a form of penalized maximum likelihood estimation.
