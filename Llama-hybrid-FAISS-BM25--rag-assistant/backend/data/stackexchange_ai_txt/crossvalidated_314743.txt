[site]: crossvalidated
[post_id]: 314743
[parent_id]: 314208
[tags]: 
However, there exists unlimited variables in the universe. And in psychology/epidemiology research, there are a lot of demographic variables (e.g., age, gender, income, marital status, number of children, etc). When do we need to control for them? Is there a rule of thumb? If you are worried about observational prediction, then variable selection is a natural consequence of your model selection criteria based on predictive performance. But you seem to be worried about bias for making causal inference. That is, you want to make scientific causal claims based on your results. If that's the case, the problem of knowing which variables to select for the identification of a causal claim via adjustment has been (mathematically) solved : you should include in your regression the variables that satisfy the backdoor criterion --- that is, these are variables that block all the backdoor (confounding) paths from $X$ to $Y$, do not open other spurious paths, and do not mediate the effect you are trying to measure. You should also take a look here and here. The backdoor is about identification. After that you have to consider efficiency. There might be variables which are not "confounders" but will help you get more precise estimates, so you might want to adjust for them. And if you have too many variables you know you need to control for, but too little data relative to the amount of variables, you might want to resort to regularization techniques, trading-off some bias for less variance --- but keeping in mind you're doing the regularization to optimize the inference with respect to a specific causal quantity, not overall observational prediction. For example, you might want to check double/debiased machine learning methods.
