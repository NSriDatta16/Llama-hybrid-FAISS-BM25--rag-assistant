[site]: crossvalidated
[post_id]: 407412
[parent_id]: 404973
[tags]: 
In this case the modellers should be using a time series model and can include mixed-effects to sweep out some of the variation they are not interested in. If they are not using time series, the modelling is a wasted effort as the observations (weeks) are not independent of one another, and therefore violate the underlying tenant of independence. To evaluate the predictive capacity of the model we typically use either cross-validation or a boot-strap approach. Cross-validation is a little more common. In the case of time-series, we typically use a rolling window. I.e. fit the model to x time points and then use this model to predict x + 1 - keep doing this till you reach the last data point and then you combine the results. A common and useful metric for this is root mean square error as it is on the original scale, and thus easily interpretable. This directly quantifies the predictive capacity of the model and tells you how well it will extrapolate. You can increase the width of the window (i.e. how well it predicts x + 1, x + 2, x + 3 etc.) to see just how far you can trust the predictions. Let me know if anything is unclear.
