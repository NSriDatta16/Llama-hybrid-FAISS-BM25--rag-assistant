[site]: crossvalidated
[post_id]: 583149
[parent_id]: 581616
[tags]: 
I doubt whether exact recovery of the function from a finite number of test points is possible in general. And if it is possible, it will be difficult. But there are very practical ways to bound the error and based on this error bound to devise designs of test points to minimise the error. For simplicity I will largely ignore the constraints on the coefficients and the values for $s$ as I do not think they change the basics of the problem. The vector space spanned by the set of functions $\{f(x)=\exp(-\frac {(x-s)^2} {2})\mid s\in\mathbb{R}\}$ is a reproducing Hilbert space (RKHS) with kernel $K(x,s)=\exp(-\frac {(x-s)^2} {2})$ . Since $K$ is a positive definite function, this space is infinite dimensional. Your equation $EP=F$ will always have a unique solution, no matter how many (distinct) interpolation points you choose in $F$ . Furthermore, this solution can be characterised as the function with minimum Hilbert-space norm among all interpolating functions and of course by construction it is a N-component function. But this Hilbert space is large and in general there will be other interpolating functions, some of them also with $N$ -components. This can be demonstrated by a simple example with N=2. In the picture below I plot the functions $\frac{1}{2}\exp(-\frac {(x+ 1)^2}{2})+\frac{1}{2}\exp(-\frac {(x- 1)^2}{2})$ and $\frac{1}{2}\exp(-\frac {(x+ 2)^2}{2})+\frac{1}{2}\exp(-\frac {(x- 2)^2}{2})$ . Note that the graphs intersect. If you happen to choose these points for interpolation you have two possible 2-component interpolants and you will not be able to distinguish between them from the test points alone. One may argue that these intersections look like very special points, which may be avoided. But if you allow larger $N$ these functions can get more and more complicated and the intersections harder and harder to describe. The full space (without constraints) is actually universal , which means you can approximate every continuous(!) function on a compact interval in the uniform norm. That said, if you do not require exact recovery but can live with approximation then RKHS theory provides you with pointwise error estimates. Those are based on the kernel function $K$ , the fill distance of your design of test points, which is basically the largest possible distance to any of your test points and the norm of your target function $f$ . For details see Chapter 14 of Gregory E. Fasshauer, "Meshfree Approximation Methods with MATLAB" and in particular Example 15.1 for the approximation order of the Gaussian kernel. Finally, the Gaussian kernel is known to be numerically fickle. See cit.loc. Example 16.1 for a discussion of the condition number of Gaussians. This can be addressed by various methods, such as pre-conditioning and choosing a better basis. See cit.loc. Chapter 34 for a discussion of those issues.
