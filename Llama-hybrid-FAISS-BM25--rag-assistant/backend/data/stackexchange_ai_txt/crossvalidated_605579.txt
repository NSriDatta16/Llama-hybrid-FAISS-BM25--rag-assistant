[site]: crossvalidated
[post_id]: 605579
[parent_id]: 415830
[tags]: 
Classic MDS is a linear dimensionality reduction technique. One may confirm its linearity by finding a transformation matrix $\mathbf W \in \mathbb R^{d \times d'}$ such that $\mathbf Z = \mathbf W^\top \mathbf X$ , where $\mathbf X \in \mathbb R^{d \times m}$ is the collection of samples in original space, and $\mathbf Z$ the samples in reduced space. Let the inner product matrix $\mathbf B = \mathbf X^\top \mathbf X = \mathbf V\boldsymbol\Lambda\mathbf V^\top$ . By classic MDS, one may find $\mathbf Z = \boldsymbol\Lambda_\ast^{1/2}\mathbf V_\ast^\top \in \mathbb R^{d^\ast \times m}$ , where $\boldsymbol\Lambda_\ast$ is a diagonal matrix containing $d^\ast$ largest (positive) eigenvalues of $\mathbf B$ and corresponding eigenvector matrix $\mathbf V_\ast$ . In addition, let $\mathbf U\tilde{\boldsymbol\Lambda}\mathbf U^\top$ be the eigenvalue decomposition of $\mathbf X\mathbf X^\top$ . One is able to show that $\mathbf X^\top\mathbf X$ and $\mathbf X\mathbf X^\top$ share the same nonzero eigenvalues, and that for any nonzero eigenvalue, the corresponding eigenvectors of the two matrices satisfy $\boldsymbol v = C X^\top\boldsymbol u$ , where $C$ is an arbitrary constant. Therefore, $\mathbf Z$ can be written as $\boldsymbol\Lambda_\ast^{1/2}\mathbf C^\top\mathbf U_\ast^\top \mathbf X$ , where $\mathbf C$ is an arbitrary diagonal matrix. This way, the transformation matrix $\mathbf W = \mathbf U_\ast\mathbf C\boldsymbol\Lambda_\ast^{1/2}$ .
