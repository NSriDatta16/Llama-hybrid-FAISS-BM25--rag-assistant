[site]: crossvalidated
[post_id]: 335926
[parent_id]: 335666
[tags]: 
In LASSO one generally examines a range of values of $\lambda$ and then chooses a value of $\lambda$ that meets some criterion for an "optimal" model, typically by cross-validation. If you don't specify values for $\lambda$, then programs will typically choose a reasonable range. In your example with Coxnet() , $\lambda$ of 2.144e-01 gave 0 non-zero coefficients ( nzero ). That's as high in $\lambda$ as you need to go in this case, but the highest useful $\lambda$ value will depend on the particular data being examined. Specifying values for parameters nfolds or foldid tell Coxnet() to perform cross-validation across a range of $\lambda$ values. As appropriate for a measure of optimality in a Cox survival model, Coxnet() then reports "average cross-validation partial likelihood cvm and its standard error cvse , and index with max indicating the largest cvm " ( Coxnet manual , page 5). Standard practice would be to choose that value of $\lambda$, 3.949e-02 in your example. Choose the regression coefficients that are determined at the optimal value of $\lambda$. For example, Coxnet() seems to return coefficients at all tested values of $\lambda$ in fit$Beta and can if requested return the coefficients at the optimal $\lambda$ in fit$Beta0 . Resist the temptation to just take the non-zero predictors from LASSO and set up a brand-new Cox regression model based on them alone. LASSO penalizes the regression coefficients (lowers their absolute magnitudes) to minimize overfitting. If you just take the selected predictors and set up a new model, you have undone this good that LASSO does so your model will end up overfit. Also, the p -values that you get in a new model would not be correct as they would not take into account your prior selection of those predictors based on the data. Just use the coefficients found at the optimal $\lambda$ value. Model assessment might best be done by repeating the entire model-building process on multiple bootstrap samples of the original data, and evaluating how well the multiple models (which in LASSO will likely differ in the particular choices of predictors) work at predictions on the original data set.
