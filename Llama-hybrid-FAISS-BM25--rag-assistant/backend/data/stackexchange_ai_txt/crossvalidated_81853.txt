[site]: crossvalidated
[post_id]: 81853
[parent_id]: 81840
[tags]: 
This definitely depends on too many factors to give a good answer. The data's specificities and the classifying power of the feature can make a lot of difference. Usually such a low number of samples (34) would be too low for any classifying method, which will likely overfit however hard you try to use any variance reduction techniques (or just have terrible predictive performance). But if your features classify your data exceptionally well, you might train a decent classifier notwithsanding. Imagine the following situation : you are trying to classify whether a person is male or female. One of your features is "has male sexual organs". Then it really won't matter how many samples you have, your classifier will always be correct (this is somewhat equivalent to Michal's explanation, as in this case the classes do not overlap at all in the space of features, and there is no variance within a class). Of course this is a gross exaggeration but you get the idea. Bottom line - 1) you can't tell if a classifier will work without knowing the data's specificities, and 2) you won't know until you try.
