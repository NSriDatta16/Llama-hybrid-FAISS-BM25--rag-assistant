[site]: datascience
[post_id]: 48166
[parent_id]: 
[tags]: 
Why can decision trees have a high amount of variance?

I have heard that decision trees can have a high amount of variance, and that for a data set $D$ , split into test/train, the decision tree could be quite different depending on how the data was split. Apparently, this provides motivation for algorithms such as random forest. Is this correct? Why does a decision tree suffer from high variability? Edit: Just a note - I do not really follow the current answer and have not been able to solve that in the comments.
