[site]: datascience
[post_id]: 118622
[parent_id]: 
[tags]: 
Getting Error: TypeError: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not tuple

I am working on a CNN multi-class classification of different concentrations (10uM, 30uM, etc.) I create my dataset to include the images as the features and the concentrations as labels. Note that the concentrations are left as a string. When running the code, I am getting the following error: TypeError: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not tuple The following is my dataset class: class CustomDataset(Dataset): def __init__(self, path, method): """ Args: csv_path (string): path to csv file data_path (string): path to the folder where images are transform: pytorch transforms for transforms and tensor conversion """ # Transforms self.to_tensor = transforms.ToTensor() # Read the excel file self.data_path = pd.read_excel(path, sheet_name=method) # First column contains the image paths self.img_arr = np.asarray(self.data_path.iloc[:, 0]) # Second column is the labels self.label_arr = np.asarray(self.data_path.iloc[:, 1]) def __getitem__(self, index): # Get image name from the pandas df img_path = self.img_arr[index] # Open image img = cv2.imread(img_path) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Converts the image from BGR to RGB # Transform image to tensor img_tensor = self.to_tensor(img) # Get label(class) of the image based on the cropped pandas column img_label = self.to_tensor(self.label_arr[index]) img_label = self.label_arr[index] return (img_tensor, img_label) def __len__(self): return len(self.data_path) I am aware that the reason is most probably due to the fact that the labels are left as tuples, so the loss function is unable to compare the CNN output with the label. However, I am unable to find any resources that explain how labels are dealt with in multi-class classifications of tuple type labels. The solution seems simple, but I am a bit confused on how to solve it. Can anyone direct me? This is the implemented training loop: def train_epoch(model,dataloader,loss_fn,optimizer): train_loss,train_correct = 0.0, 0 model.train() #Sets the mode to train (Helpful when using layers such as DropOut and BatchNorm) for features,labels in dataloader: #Zero grad optimizer.zero_grad() #Forward Pass output=model(features) print(output) print(labels) loss=loss_fn(output,labels) #Backward Pass loss.backward() optimizer.step() train_loss += loss.item()*features.size(0) #features.size is useful when using batches. scores, predictions = torch.max(output.data,1) # 1 is to create a 1 dimensional tensor with max values from each row train_correct += (predictions==labels).sum().item() return train_loss, train_correct This is the output of "output" and "labels", respectively: tensor([[-0.0528, -0.0150, -0.0153, -0.0939, -0.0887, -0.0863]], grad_fn= ) ('70uM',)
