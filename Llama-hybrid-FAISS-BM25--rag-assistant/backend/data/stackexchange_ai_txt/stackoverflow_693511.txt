[site]: stackoverflow
[post_id]: 693511
[parent_id]: 690805
[tags]: 
I agree with Paul that this is often solved by using a soft reference cache, though it may evict entries earlier than you prefer. A usually acceptable solution is to use a normal cache that evicts to the soft cache, and recovers entries on a miss if possible. This victim caching approach works pretty well, giving you a lower bar but extra benefit if free memory is available. The memory size can be determined by enabling the Java agent, and usage is pretty simple when using the SizeOf utility ( http://sourceforge.net/projects/sizeof ). I've only used this for debugging purposes, and I'd recommend benchmarking the overhead before adopting it for normal usage. In my caching library, I am planning on adding the ability to plug in a evaluator once the core algorithm is implemented. This way you could store a collection as the value, but bound the cache by the sum of all collection sizes. I have seen unbounded collections as values in caches cause OutOfMemoryExceptions, so having control is quite handy. If you really need this, and I'd advise not to, we could enhance my current implementation to support this. You can email me, ben.manes-at-gmail.com.
