[site]: crossvalidated
[post_id]: 543677
[parent_id]: 543456
[tags]: 
"I want to calculate the sample size required to detect a given effect size.": The problem with this is that your answer is a function of the effect size and the effect size is unknown. So this can't be calculated. "I'm not sure where to start with this": Thankfully, there's a very simple solution. Since you're able to control which people can receive the 'treatment' of a limit change, we don't even have to apply a statistical model -- we can simply do a randomized controlled trial, as follows. Let the total number of customers be $N$ . Choose a proportion, p, of customers that will experience a limit change (s.t. $N*p$ customers will have a changed limit; $N*(1-p)$ customers won't have a changed limit). Denote $n*p$ and $n_{1}$ and $n*(1-p)$ as $n_{2}$ . Make sure the allocation to the two groups are completely random (e.g. can use a random number generator), to ensure that on average, the two groups are 'equivalent', i.e. have similar incomes, credit scores, etc. (whatever info you have about the customers). A higher number of customers will help here (in the sense of producing higher-confidence results), as would making $p$ as close to 0.5 as feasible. Then, you must wait a while to observe behavior. Finally, let $\bar{x_{1}}$ the the average loss of the treated group (where limits were changed) and $\bar{x_{2}}$ be the average loss of the control group (where limits weren't changed). Similarly, let $s_{1}$ and $s_{2}$ be the sample standard deviations of the losses of the two groups. Note for people with no losses should be included, e.g. if the first group contains 8 people with losses: 0,0,0,450,0,212,0,0; $\bar{x_{1}}=82.75$ and $s_{1}=165.9016$ (obviously in reality, there will be much more than 8 people). $d=\frac{(\overline{x_1}-\overline{x_2})}{SE(\overline{x_1}-\overline{x_2})}$ Where: $SE(\overline{x_1}-\overline{x_2})=\sqrt(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})$ To assess statistical significance, you use a one-sided t-test (not two sided because we know increasing limits will never decrease loss in population (may happen in-sample just by chance)). If you have more than a couple of hundred of people in each group, the distribution of the 'd' statistic (which is a t-statistic) will be approximately normal. This means that if 'd' is greater than 1.64 for example, you can conclude increasing the limit led to an increase in the average loss with 95% confidence. For other confidence levels, and for what to do for smaller sample sizes, refer to standard normal tables and t-statistic tables respectively. If you have a statistically significant result, your estimate of the difference in average loss is simply $\bar{x_{1}} - \bar{x_{2}}$ , and you can be confident that the 'true' value of this difference is greater than 0 with 95% confidence. There is one issue and that is (if I'm understanding correctly), that there was only two losses in a five-month sample period. This means you have very low 'sampling variation' which will increase the standard error (denominator of d), thereby decreasing d, thereby (all else equal) leading to results that will be less statistically significant. You will need to use a greater number of people to produce statistical significance. As stated before, the exact number is unknown because the effect size is unknown. If this is not feasible, you can simple compare the averages without using the above statistical tests, with the knowledge that random chance will have a large effect impact on results. However as a rough guide, if you expect the control group to have, say, 10 nonzero losses in a given period, I would imagine that would be the minimum time-frame necessary to be confident in the conclusions of the above experiment. But the more losses, the better (for the efficacy of this experiment that is, not your business). Less than 0 means that random chance will have a very substantial impact and the observed difference may be substantially difference that what will happen in the future.
