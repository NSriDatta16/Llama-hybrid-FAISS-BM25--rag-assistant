[site]: crossvalidated
[post_id]: 393927
[parent_id]: 
[tags]: 
Why would one use gradient boosting over neural networks?

I'm referring to a specific Kaggle set: https://www.kaggle.com/c/petfinder-adoption-prediction There are a lot of columns, and I'm (for now) ignoring the images / videos. I'm training a standard neural network, but it gets stuck very quickly. I'm happy to post my entire Keras code if it'll be helpful. I don't understand gradient boosting, but does it somehow stop from getting stuck?
