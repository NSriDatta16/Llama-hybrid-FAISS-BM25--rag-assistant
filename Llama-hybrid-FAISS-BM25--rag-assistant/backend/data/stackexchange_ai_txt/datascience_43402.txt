[site]: datascience
[post_id]: 43402
[parent_id]: 43355
[tags]: 
The Atari games are some of the best examples in which you would need a function approximator (e.g. Neural Network) in order to solve them. This is because the state space explodes and thus you would need something that will generalize quite well in unseen states. I am not quite sure what you mean by I want to use the image as the state of my algorithm, but I came up with a doubt: Is the state all the possibilities for all the pixels of the image? The state at a specific timestep represents the state of the game and will be the input to your algorithm. Why you would need all the possible combinations of the pixels in that image (most of these combinations won't make any sense and the agent will never encounter them. What you need though is your agent to encounter enough game states that will enable it to generalize well in unseen states. If you were trying to solve Atari games with a look up table then you would have to store every single image, that your agent encounters at every single time step, in a table (more precisely a reference of that image which will correspond to a $Q$ value). In other words you are trying to store all the states that your agent might encounter in the game (impossible in Atari games - unless you do some very sloppy assumptions about the nature of the states).
