[site]: crossvalidated
[post_id]: 502784
[parent_id]: 
[tags]: 
Determining the minimum number of tosses, for heads to be twice more likely than tails in the next toss

I would like some help with the following statistical problem. We have a coin with probability $\theta$ for heads, with prior for $\theta$ being a Beta(a,a) distribution (a is a known parameter). After tossing the coin n times, we get n-1 times heads. Assuming that we toss the coin again, we would like to find the minimum n for which heads is at least two times more likely than tails. I tried to address the problem in the following way: We have that $\pi(\theta)=Beta(a,a)$ and $L(\theta;x)=f(x;\theta)=Bin(n,x)$ Therefore we get: $\pi(\theta|x) \propto Beta(a,a) \times L(\theta;x) \implies \pi(\theta|x) =Beta(a+x,a+n-x)$ Obviously, the posterior of $\theta$ is a function of n and x But for x=n-1 we get $\pi_n(\theta|x) \propto Beta(a+n-1,a+1)$ , that is the posterior of $\theta$ depends only on n. The n+1 toss is a Bernoulli trial with parameter $\theta$ following the beta distribution described by $\pi_n(\theta|x)$ , i.e. $Beta(a+n-1,a+1)$ . In order for heads to be at least two times more likely than tails, we must have $\theta \geq 2/3$ . I am not quite sure, how to continue with the problem after this point. After skimming some Bayesian Statistics textbooks, I came to the conclusion that the standard Bayesian approach would be to take : $E[\pi_n(\theta)] \geq 2/3$ Still, I am not sure about this. I have, also, thought of $\frac{\int_{2/3}^{1}\pi_n(\theta)}{\int_{0}^{2/3}\pi_n(\theta)} > 1$ So, summing up, I am not sure how to continue after having calculated the posterior distribution $\pi_n(\theta|x)$ of $\theta$ . Any help would be greatly appreciated.
