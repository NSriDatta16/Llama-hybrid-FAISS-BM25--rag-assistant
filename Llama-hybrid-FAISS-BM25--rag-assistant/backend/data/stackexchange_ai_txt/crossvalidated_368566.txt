[site]: crossvalidated
[post_id]: 368566
[parent_id]: 
[tags]: 
Why with two classes, LDA gives only one dimension?

I am working with dimensionality reduction algorithms. Linear Discriminant Analysis (LDA) is a supervised algorithm that takes into account the class label (which is not the case of PCA for example). I am using Python to do a comparative study between some algorithms. Why with two classes (k = 2) , regardless of the data dimensionality, LDA gives one dimension, i.e. the new subspace is composed of only one dimension? For example if I try to project my dataset (of 100 attributes and 2 classes) to 10-dimensional space by using LDA(n_components=10) I only obtain 1 dimension? For k>2 I can obtain the number of discriminant vectors that I specified as n_components . How can I get n_components dimensions for k=2 ?
