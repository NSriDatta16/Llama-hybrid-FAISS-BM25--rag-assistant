[site]: crossvalidated
[post_id]: 626189
[parent_id]: 
[tags]: 
Using validation data in optimization scenarios e.g. with genetic algorithms

I'm not too familiar with optimization algorithms e.g. genetic algorithms and I'm wondering whether it makes sense to employ a validation set in this context similarly to when we train a supervised machine learning model. Let's say we are in a chemical domain and we have experimental measures $f_1, \dots f_N$ of some quantity $f$ . Then we want to optimize the parameters of a theoretical model $g(x_1, \dots , x_n, a_1, \dots,a_n)$ where $x_1, \dots x_n$ are parameters involved in the optimization and $a_1, \dots a_n$ are fixed. As the objective function we choose for example the mean absolute error: $$MAE(f,g) = \frac{1}{N}\sum_{i=1}^N |f_i - g_i| \, .$$ So the optimization problem is $\min_{x_1, \dots,x_n} MAE(f,g)$ . My question is, should we hold out part of the initial measurements as validation data and at each iteration evaluating the objective both on training and validation sets? Is validation used in this type of optimization and is there a possibility of overfitting to training data as it usually happens with standard supervised ML models?
