[site]: crossvalidated
[post_id]: 477187
[parent_id]: 
[tags]: 
What is the name for this type of sensitivity measure in regression analysis?

I have a way of calculating sensitivity of a regression that is very useful for my particular domain, but I don't know what it is called. I would like a name for it so I can look up additional information. I do a regression over some data to find the optimal parameters of the model. I then pick particular values for the independent variables and determined the predicted value for the dependent variables to synthesize a new data point. I then determine how much the predicted value changes as the position of this data point changes when re-optimizing the model parameters as the data point is perturbed. This is represented as a ratio that ranges from 0 to 1. This creates a measure of how resistant the model parameters are to new data that is measured at a particular point. If the ratio of predicted value change to data point change is one, then the current data is offering no resistance at that point, and it would clearly be better to have more measurements for that independent value. As the ratio becomes lower, we know that our current solution is more stable for that independent value. If the ratio is zero, then the results are perfectly stable at that point. Adding more measurements there would have no effect. This seems like a very useful measure in general, so I'm sure it's been studied, but I haven't been able to find anything that matches this exactly. It seems related to sensitivity analysis, stability, and robustness, but these seem to be global measures and are related to impact on the parameters rather than impact on the optimal residuals at one particular point. It isn't really a measure of goodness-of-fit either, since I'm not trying to validate my model. UPDATE: Thanks to @RyanVolpi, I realize that this is closely related to the concept of leverage . The only difference being that I'm determining the leverage of synthesized data points rather than observations.
