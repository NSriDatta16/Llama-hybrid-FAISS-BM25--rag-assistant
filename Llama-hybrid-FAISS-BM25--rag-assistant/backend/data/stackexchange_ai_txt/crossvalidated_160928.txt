[site]: crossvalidated
[post_id]: 160928
[parent_id]: 
[tags]: 
Ensembling Logistic Regressions Fit on Different Datasets

I would like to predict a binary response variable $Y_i$ using sets of predictors $\textbf{X}_{1i}, \textbf{X}_{2i}, \textbf{X}_{3i}$ for $i=1,\dots,n$. Each $\textbf{X}$ contains a few dozen predictors. For a large enough $n$, I could simply fit a standard logistic regression. However in my setting, $n$ is relatively small compared to dim($\textbf{X}$), so that it's difficult to fit such a model. Alternatively, I have available separate datasets with $Y$ and each $\textbf{X}$ (with much larger $n$). Since I don't have a good way to combine these datasets into one large dataset, I'd like to fit three individual models and then ensemble them in some way based on my "wide but short" dataset. Now I've got a set of 3 probabilities $p_1, p_2, p_3$ which I'd like to combine into some overall probability $p$. I've considering combining them on the following scales Probability Odds Log-odds The log-odds approach seems initially appealing since it will have predictors that live on the real line (seems reasonable that it could be close to linearly related with the logit of the response $Y$, but I'm not entirely sure. I've found this paper, which seems related, but a slightly different setting, since I don't have "many forecasters". Is there some theoretical justification for choosing one of these (or something completely different) to ensemble my three models?
