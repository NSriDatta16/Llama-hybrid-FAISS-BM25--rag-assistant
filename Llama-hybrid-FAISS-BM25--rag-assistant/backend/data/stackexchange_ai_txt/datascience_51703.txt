[site]: datascience
[post_id]: 51703
[parent_id]: 
[tags]: 
Cross-validation for model comparison: use the same folds?

Let's say we have model M1 and model M2 that we want to compare. When we do 5-fold (say) cross validation, would the correct method to be to partition the data into F1, F2, F3, F4, and F5 and then run both models through those folds? Then would the way to assess if M2 outperforms M1 be to do a paired t-test? I'm mostly thinking about a situation where I have the results of a cross-validation that someone else did and want to see if my model can beat their average of 80% accuracy. In that case, I would not have their exact folds or perhaps not even how many folds they used, so a paired t-test would not be possible. What would be the pitfalls of comparing to their metric or to their 5 metrics on the 5 folds when I don't know exactly how they allocated the observations into folds?
