[site]: stackoverflow
[post_id]: 2392014
[parent_id]: 2376093
[tags]: 
Clojure link dumps, covering enlive, based on tagSoup and agents for parallel downloads (roundups/ link dumps aren't pretty, but I did spend some time googling/searching for different libs. Spidering/crawling can be very easy or pretty involved depending on the structure of sites crawled, HTML, XHTML, etc.) http://blog.bestinclass.dk/index.php/2009/10/functional-social-webscraping/ http://nakkaya.com/2009/12/17/mashups-using-clojure/ http://freegeek.in/blog/2009/10/downloading-a-bunch-of-files-in-parallel-using-clojure-agents/ http://blog.maryrosecook.com/post/46601664/Writing-an-mp3-crawler-in-Clojure http://gnuvince.wordpress.com/2008/11/18/fetching-web-comics-with-clojure-part-2/ http://htmlparser.sourceforge.net/ http://nakkaya.com/2009/11/23/converting-html-to-compojure-dsl/ http://www.bestinclass.dk/index.php/2009/10/functional-social-webscraping/ apache http client http://github.com/rnewman/clj-apache-http http://github.com/heyZeus/clj-web-crawler http://japhr.blogspot.com/2009/01/clojure-http-clientclj.html
