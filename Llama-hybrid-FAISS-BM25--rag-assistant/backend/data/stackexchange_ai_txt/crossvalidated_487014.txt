[site]: crossvalidated
[post_id]: 487014
[parent_id]: 486956
[tags]: 
The resolution of this issue lies in recognition of the difference between conditional independence versus marginal independence . Conditional independence does not generally imply marginal independence, and indeed, in most cases it implies positive marginal correlation. This occurs because outcomes of one of the random variables in the set gives information on the underlying parameters (the conditioning parameters of the underlying distribution) and this in turn gives information on the other random variables in the set. If you would like a more detailed answer than this, I recommend you read O'Neill (2009) . This paper sets out the relationship between conditional and marginal independence in classical and Bayesian models, and it discusses some of the implications of conditional independence. It also gives conditions for induced marginal positive correlation for conditionally IID variables. In the hierarchical model you have given, the elements $x_1,...,x_N$ are conditionally independent given $\beta$ . (You are wrong to assert that they are IID --- this holds only conditionally on the parameter $\beta$ and only assuming that $z_1,...,z_N$ are identically distributed conditional on $\beta$ .) Each observed value $x_i$ gives information about the underlying value $z_i$ and through it gives information about $\beta$ . Conditional on the underlying parameter value $\beta$ the observations are independent, but once you take that conditioning away they are no longer independent because they each give information on $\beta$ , and so they indirectly give information on each other. Unless you are dealing with a pathological case, if you derive the joint density for $x_1,...x_N$ (without conditioning on $\mathbf{z}$ or $\beta$ ) you will find that there is dependence between the values, and most likely positive correlation. This is a standard result in Bayesian models and a standard outcome for conditionally IID values in general.
