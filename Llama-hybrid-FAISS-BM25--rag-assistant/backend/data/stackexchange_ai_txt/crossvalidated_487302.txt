[site]: crossvalidated
[post_id]: 487302
[parent_id]: 210596
[tags]: 
Hopefully someone will come in with a more mathematically rigorous answer, but in a lot of cases it seems to just be about cramming your data into the shape you need. For example, in Magenta Coconet, the algorithm is trying to inpaint a musical score, and so the output dimensions are the same as the input dimensions (with a small exception that isn't relevant to your question), so they don't even use fully connected layers at the end. They just use as many hidden layers as sounded good to them, and then threw on input and output layers that made the sizes right. In a classification problem though, you have to change higher dimensional data (images or something) into a 1 dimensional array (categories), and so fully connected layers can be used to reshape the data.
