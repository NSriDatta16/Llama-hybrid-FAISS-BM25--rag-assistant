[site]: crossvalidated
[post_id]: 306105
[parent_id]: 94647
[tags]: 
Since inverse gamma distributions are so often used in Bayesian Inference, another approximate finite sample inference approach is to use MCMC or Gibbs sampling to draw from a posterior using an uninformative prior to obtain credible intervals. Whilst credible != confidence, most agree the approach yields approximately equivalent inference when using non-informative priors. Using the simulation suggestion from @KjetilBHalvorsen, I generate the same X and fit a BUGS model with: model { for(i in 1:200) { invx[i] To obtain the following posterior distribution samples, which have 2.5 and 97.5 quantiles given by Inference for Bugs model at "cat.txt", fit using WinBUGS, 2 chains, each with 5000 iterations (first 2500 discarded), n.thin = 5 n.sims = 1000 iterations saved mean sd 2.5% 25% 50% 75% 97.5% Rhat n.eff shape 1.070 0.096 0.887 1.009 1.067 1.129 1.280 1.000 1000 scale 1.084 0.122 0.860 1.001 1.078 1.164 1.329 1.002 790 deviance 396.018 1.994 394.100 394.600 395.400 396.800 401.800 1.005 520 For each parameter, n.eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor (at convergence, Rhat=1). DIC info (using the rule, pD = Dbar-Dhat) pD = 2.0 and DIC = 398.0 DIC is an estimate of expected predictive error (lower deviance is better). Which agrees somewhat with the maximum likelihood approach used above.
