[site]: crossvalidated
[post_id]: 636302
[parent_id]: 3730
[tags]: 
In order to add something that hasn't been said yet in 14 years but in my opinion should be said, it is in my view generally wrong to say that "model assumptions have to be fulfilled" in order to apply a model-based statistical model. Statistical models are idealisations and their job is not to be "true" in reality; reality doesn't normally behave like formal models. The idea that something that supposedly "assumes" normality cannot be applied if data are not normally distributed is wrong. If this were true, no model-based statistical method could ever be applied, and neither nonparametric methods as long as they still involve formal model assumptions such as independence. Model assumptions mean that a method can be shown to perform in a desirable or optimal manner in a certain idealised situation. Model-based statements such as about inference (probabilities for type I or type II error, confidence interval coverage probabilities, Bayesian posteriors) can be used as quantitative orientations, but do not refer to what is true in reality, rather to formal models of it. Of course one can hope that these results give a good and useful orientation at least in situations in which data look similar to data having been generated by the assumed model, and one may be more skeptical if they don't. This makes some sense, but formalising and proving/checking such an intuition in a mathematical way isn't straightforward. It can be done in more than one way, and results are often ambiguous (for example from simulations in which methods are applied to data generated from models that deviate from the assumptions), i.e., the intuition may often but not always hold. The thing that is most important is ultimately to understand what the considered statistics are actually doing to the data, and to know in what cases it can be misleading. Also it is important to take into account to what extent inference is of interest, and what the consequences can be. If statistical inference is not of interest, computing statistics such as Pearson correlation is possible without any assumptions, but the question is still relevant to what extent the value tells you what you want to know. Other answers say much about the details (such as that Pearson correlation is strongly affected by outliers, Spearman less so) and I won't repeat things here, but note that Pearson correlation does not "assume" linearity either (standard inference based on it does; but bootstrap and permutation tests are possible that don't). It is true that a value of 1 or -1 is equivalent to perfect linearity, and Pearson correlation can be interpreted as slope of a standardised data summary line. Testing whether this is zero (using for example a permutation test) is not the worst thing to do even when interested in testing independence against not necessarily linear monotonicity. There are better alternatives in many specific situations (with outliers Spearman will normally be better), however a Pearson correlation larger than zero, say, means that there is a tendency of one variable to be larger/smaller that its expected value when the other one is (also measuring to what extent amounts of deviation from the mean in the two variables are proportional in a standardised manner), and this is often a sensible thing to be interested in, whether a relationship is really linear or not.
