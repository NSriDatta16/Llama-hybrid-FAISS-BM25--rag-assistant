[site]: crossvalidated
[post_id]: 128771
[parent_id]: 128725
[tags]: 
The logistic regression estimates conditional probabilities $$\hat P(y_i\mid x_i, z_i) = \Lambda(\hat \alpha + \hat \beta x_i +\hat \gamma z_i)$$ with $y_i$ "going to college", $x_i$ "income" and $z_i$ "gender", with $z_i=1$ representing "male". Let $i$ index the observations related to males, and $j$ the observations related to females. We will write for compactness $\Lambda(\hat \alpha + \hat \beta x_i +\hat \gamma z_i) = \hat \Lambda_i$,and analogously for females, $\hat \Lambda_j$. Based on the question, we examine the case where we have $x_i =x_j ,\; \hat \Lambda_i > \hat \Lambda_j$, which implies $\hat \gamma >0$. Since "income" is (treated as) a continuous regressor, the "marginal effect of income" for males is $$m_i(x_i)\equiv \frac {\partial \hat P(y_i\mid x_i, z_i=1)}{\partial x_i} = \hat \Lambda_i(1-\hat \Lambda_i)\hat \beta$$ while for females is $$m_j(x_j)\equiv \frac {\partial \hat P(y_j\mid x_j, z_j=0)}{\partial x_j} = \hat \Lambda_j(1-\hat \Lambda_j)\hat \beta$$ The expression $\Lambda (1-\Lambda)$ is maximized at $ \Lambda = 1/2$. It follows that for $x_i=x_j$, in general we will have $m_i(x_i) \neq m_j(x_j)$, although we won't necessarily have $m_i(x_i) > m_j(x_j)$ -this will depend on whether, for the given level of income, $\Lambda_i$ is closer to $1/2$ than $\Lambda_j$. Now, $\Lambda (1-\Lambda)$ is the conditional variance, and it is the sole source of the difference of the two "marginal effects". And naturally , we expect that $\hat \Lambda_i(1-\hat \Lambda_i) \neq \hat \Lambda_j(1-\hat \Lambda_j)$, because in the one the variable $z$ is set equal to $1$, while in the other it is set equal to $0$. In a sense, we have here two different conditional distributions. Why should we expect that they should have the same variance? Why the variance of the random indicator function "going to college or not" should be the same for males and for females, conditional on the same level of income? The conditional probability itself, the expected value of the indicator function, is not equal, why should the variance suddenly become equal? We did perform something familiar, the operation of differentiation on some mathematical expression with respect to some variable. In mathematical terms, it does express mathematically how the expression changes as the variable changes, something we do call the "marginal effect". But it requires per-case interpretation as to what it reflects and represents in the context of the specific framework on which we have mapped and applied our mathematical tools.
