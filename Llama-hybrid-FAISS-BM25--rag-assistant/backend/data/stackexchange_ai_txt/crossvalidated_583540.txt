[site]: crossvalidated
[post_id]: 583540
[parent_id]: 
[tags]: 
What is the mathematical term for a real world categorical function that yields several categories for the same inputs?

Background and Color Contextually, this is pertaining to machine learning and natural language processing. Specifically, it has to do with the labeling of real world data for partitioning by a machine learning model. When labeling text data sections for partitioning in ML, I have hundreds or even thousands of sentences. Over the course of annotating these sentences for continuous phrases that belong in one category or another, there may be some ____ (the word I am looking for) or "confusion" in the result. For example, the sentences: S10232 is the flawed product. Bean bag S10232 failed to resist even mild spills Ref No. T123 the Supremo Bean Bag 5000 was impervious to even flooding; replacing the cover is all that was necessary. If, over the course of many hours, I were to annotate "S10232" as a SERIAL_NO, "Bean bag S10232" as a PRODUCT, and "Ref No. T123" as a TEST_NO with "Supremo Bean Bag 5000" as another "PRODUCT", an optimal ML model with data memorization and reliance on literal spellings repressed for general applicability would conceivably learn the following categories under the hood: SERIAL_NO: { "S10232", "T123", "5000"} TEST_NO: {"S10232", "Ref No. T123", "Supremo Bean Bag 5000"} PRODUCT: {"Bean bag S10232", "Ref No. T123 the Supremo Bean Bag 5000"} And, in terms of categorical partitioning, it would be impossible to train a model that correctly classified all entities in the three sentences due to the _____ (word I am looking for) in the function it is set to learn. More Abstractly What is the mathematical word for a descriptive mapping that is ill-posed as a 'function'? For example, { a, b, c } -> m -> Tiger { c, d, e } -> m -> Giraffe { e, f, g } -> m -> Elephant Here, c and e map to both Tiger | Giraffe and Giraffe | Elephant , respectively. In this scenario, the labeling of c and e are not separable into discrete categories, and the function is therefore not learnable due to the _____ (the word I am looking for) of the data set. I want to say that the word is hysteresis , but although this is hysteresis in the pure math sense (the same input in X yields many different values in Y), there is an element of physical time and continuity in the definition of hysteresis . So my question amounts to: if not hysteresis , what is the math word that would describe a dataset which labels analytically equivalent content to more than one category s.t. it is impossible to deduce the correct category without additional differentiating information? More to the point In order to improve the ML modeling result, I must go through the data and reduce the categorical ambiguity, which is called "______" (hysteresis?), otherwise the model, no matter how optimal, cannot learn to label the data correctly because the data labels are inconsistent with respect to the information available to the model during training. In math (or psuedo-math) terms, the data set would not be PAC-Learnable and could never be Shattered ; the upper limit of the Bayes Optimal Classifier's performance would have a ceiling directly proportional to the amount of ____ (the word I am looking for) in the set labeling. The stand in concept under the microscope is, for now, from set theory. However, it is not "snappy" or "elegant" (can't present it in a power point). It is also not the same kind of thing as I am looking for. But, it is a starting point. The concept or topic is: The Multi-Valued or Set-Valued Function But this is something that can yield a Metric that defines a limit on the Bayes Optimal Classifier from statistics which relates to the model's PAC-Learnability . As the metric, ____ (the word I am looking for), approaches zero, the Bayes Optimal Classifier performance limit will approach 1.0. The name for the metric characterizing the degree of 'multi-valued-ness' in the multi-valued function is what I am looking for. As I've explored, argued, and defended this question in the math stack exchange, I recalled the idea from combinatorics referred to as a "derangement". The "derangement" is a lower level term than the label set of sets in a labeled ML, but I think I can extend it (for now). So, I'll use the phrase Categorical Derangement . Derangement's definition in an injective, 1:1 setting from combinatorics is: Derangement . Although " derangement " might not be the optimal term from a math perspective, I currently do not have the mathematics perspective. In the meantime, it is an absolutely fantastic word for a power point, developing work around the idea, and setting up tasks. This usage of the word would be a refinement or generalization of the word "Derangement" to refer to a more or less continuous metric characterizing the degree of derangement of the overall multi-valued function's output. In this 'metric', a Bayes Optimal Classifier gives every single input every single class with equal probability (or 1 class with 100% probability) when the dataset is perfectly deranged. And, when the dataset is perfectly sane with zero derangement (unachievable, in most practical cases), a Bayes Optimal Classifier can be constructed s.t. the training data is classified with 100% accuracy. But this is an innovation. The right word is probably something else, and I am a purist. I would prefer to give respect where it is due, and use the right word. In short, there is simply no way I am the first person to try to word or measure this problem. The question is: what is the word?
