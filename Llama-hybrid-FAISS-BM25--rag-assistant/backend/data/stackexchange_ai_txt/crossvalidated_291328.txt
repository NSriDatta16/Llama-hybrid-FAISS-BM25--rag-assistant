[site]: crossvalidated
[post_id]: 291328
[parent_id]: 
[tags]: 
How can I impute a large multivariate dataset?

I am researching a medical dataset that has a large number and complexity of variables (> 900 variabes, > 3000 with dummy variables). Not only biomarkers and the patient's demographical data is included, but also questionnaires (continuous, non-ordered categorical and ordered categorical, non-respectively). Due to this complexity I have not managed to use MICE in R or Python, it errors out and states message that the data is numerically impossible to solve. This lead me to try to impute the questionnaires apart from the other variables, because they are the largest part of the dataset and because the correlation between missing data has the highest probability. Because it is a longitudinal study, some people might not have been able to fill out the first questionnaire for example, because they were not yet included in the study, so by using the other questionnaires we might be able to impute for the missing data of the first questionnaire. The method I tried to use to impute for the questionnaires was MICE, which failed, again. The other method I tried was order the questions according to missing data, where v1 had the least amount of missing data and vn the largest amount. I then tried to find variables that had no overlapping missing data with v1, let's call them [ v2 ... vn]. I then tried to create a logistic regression between variables [v2 ... vn] after deleting the patients with missing data, the problem was that the logistic regression could not converge, because only 1 of the two classes was available (there were no 1's available in the data after deleting the patients with missing data for the predictor variables: [v2 ... vn]) Because this also failed I am currently going to try to do this: find the 10% most correlating questions with v1 that do not have any overlapping data with v1: [v2 ... vn], impute these predictors ([v2 ... vn]) with their mean and then logistically regress them with the non-missing data in v1. Then I will predict the missing data in v1 with the non-missing data from [v2 ... vn]. Now, even though this is likely to work, it does not seem very statistically correct and that is my main question, is this a solid method to use for imputing a large multivariate dataset, if not, what can I improve or are there other methods that I have overlooked?
