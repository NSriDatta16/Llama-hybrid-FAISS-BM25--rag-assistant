[site]: crossvalidated
[post_id]: 615360
[parent_id]: 
[tags]: 
Orthogonal embeddings

I am looking to develop a neural network in which the output from one set of nodes is "orthogonal" to the output from another set of nodes in the sense that if the first set of nodes is used to predict A then the second set of nodes is uninformative of A. For example: from tensorflow.keras import Model from tensorflow.keras.layers import Dense, Input, Lambda from tensorflow.keras import backend as K # Define the size of the input input_size = 10 # Replace this with the size of your input # Input layer inputs = Input(shape=(input_size,)) # Dense layer dense = Dense(8, activation='relu')(inputs) # Split the dense layer into two halves dense1, dense2 = Lambda(lambda x: split(x, num_or_size_splits=2, axis=1))(dense) # Classification layers output1 = Dense(1, activation='sigmoid')(dense1) output2 = Dense(1, activation='sigmoid')(dense2) # Create the model model = Model(inputs=inputs, outputs=[output1, output2]) # Compile the model model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Print the model summary model.summary() I am looking for a way to ensure that dense1 is uninformative of output2 and dense2 is uninformative of output1 . Any ideas on how this can be achieved?
