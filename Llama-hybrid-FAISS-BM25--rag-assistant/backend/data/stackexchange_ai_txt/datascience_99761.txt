[site]: datascience
[post_id]: 99761
[parent_id]: 56108
[tags]: 
Cross validation is a procedure used to get a sense of model performance with the procedure (type of model, preprocessing, selected hyperparameters etc) you have selected. Let's suppose you have 2 models A and B and you want to know which to select. You would perform similar CV on both the models and avergae the score of both the CV to get an estimate of their performance. Let's say A performed better. So you would select A and then train on your entire train set and then predict on test set. Same procedure goes for hyperparameter tuning. You should take the average of the CV score you get. That score will be an "indicator" of your model performance and not the "final" model.
