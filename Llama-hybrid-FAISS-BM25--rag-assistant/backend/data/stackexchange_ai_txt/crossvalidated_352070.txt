[site]: crossvalidated
[post_id]: 352070
[parent_id]: 352041
[tags]: 
The most common split I've seen is 80% train, 20% test, although I suspect the exact ratio doesn't matter that much providing the train set is sufficiently large for whatever ML method you're using to capture all its nuances. If you're training a Neural Network, your dataset should be pretty big anyway. Any ratio where the training set is larger than the test set, yet the test set captures enough of the variation in the entire dataset to allow for an accurate test of the model. Making sure the train and test set are assigned randomly is also critical, but I see you have done that. I'm not quite sure what you mean by comparing the two sets in prediction... If you mean comparing the fit of the training set as well as the test set - if the accuracy of the test set is roughly the same as that of the train set, that means your model is generalising well. If the accuracy of the train set is much better than the test set, this indicates that you might be overfitting the data and need to rethink the parameters/hidden nodes you are using.
