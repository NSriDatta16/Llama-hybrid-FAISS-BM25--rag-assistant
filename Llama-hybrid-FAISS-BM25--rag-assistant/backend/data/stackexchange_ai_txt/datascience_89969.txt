[site]: datascience
[post_id]: 89969
[parent_id]: 88143
[tags]: 
SVM is effectively a 2-layer NN. It is better to use a neural network for creating an embedding. Since, you don't have negative examples, you can't use something like a Siamese Network. One good way for you to create those embeddings would be use the bottleneck layer of an autoencoder. Or if you have image data, use ResNet to get the embeddings (the penultimate layer). Or if you have tabular data, use TabNet to get the embeddings. Once you have the embeddings, take the distance of the embeddings (or you can use K-Means to get cluster heads and then take distance from them) from the new example. You set a threshold, it the distance is larger than that. Then, yay, it is a novelty. The distance you can use is L1, L2 or cosine. For all the above techniques, the code is readily available in Python.
