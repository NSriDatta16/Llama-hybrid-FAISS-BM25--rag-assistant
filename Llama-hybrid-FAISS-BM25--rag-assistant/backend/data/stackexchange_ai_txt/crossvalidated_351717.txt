[site]: crossvalidated
[post_id]: 351717
[parent_id]: 127542
[tags]: 
It is entirely possible to use a CNN to make time series predictions be it regression or classification. CNNs are good at finding local patterns and in fact CNNs work with the assumption that local patterns are relevant everywhere. Also convolution is a well-known operation in time series and signal processing. Another advantage over RNNs is that they can be very fast to compute since they can be parallelized as opposed to the RNN sequential nature. In the code below I will demonstrate a case study where it is possible to predict electricity demand in R using keras. Note that this is not a classification problem (I did not have an example handy) but it is not difficult to modify the code to handle a classification problem (use a softmax output instead of a linear output and a cross entropy loss). The dataset is available in fpp2 library: library(fpp2) library(keras) data("elecdemand") elec Next we create a data generator. This is used for creating batches of training and validation data to be used during the training process. Note that this code is a simpler version of a data generator found in the book "Deep Learning with R" (and the video version of it "Deep Learning with R in Motion") from manning publications. data_gen num_batches){ i Next we specify some parameters to be passed into our data generators (we create two generators one for training and one for validation). lookback The lookback parameter is how far in the past we want to look and the lookahead how far in the future we want to predict. Next we split our dataset and create two generators: train_dm train_gen Next we create a neural network with a convolutional layer and train the model: model % layer_conv_1d(filters=64, kernel_size=4, activation="relu", input_shape=c(lookback, dim(dm)[[-1]])) %>% layer_max_pooling_1d(pool_size=4) %>% layer_flatten() %>% layer_dense(units=lookback * dim(dm)[[-1]], activation="relu") %>% layer_dropout(rate=0.2) %>% layer_dense(units=1, activation="linear") model %>% compile( optimizer = optimizer_rmsprop(lr=0.001), loss = "mse", metric = "mae" ) val_steps % fit_generator( train_gen, steps_per_epoch = 50, epochs = 50, validation_data = val_gen, validation_steps = val_steps ) Finally, we can create some code to predict a sequence of 24 datapoints using a simple procedure, explained in the R comments. ####### How to create predictions #################### #We will create a predict_forecast function that will do the following: #The function will be given a dataset that will contain weather forecast values and Demand values for the lookback duration. The rest of the MW values will be non-available and #will be "filled-in" by the deep network (predicted). We will do this with the test_dm dataset. horizon % array_reshape(dim = c(1, dim(input_batch))) prediction % predict_on_batch(input_batch) test_data[predict_idx, ycol] and voila: Not too bad.
