[site]: crossvalidated
[post_id]: 126264
[parent_id]: 
[tags]: 
How to compare predictions from MLE-based regression Vs. predictions from bayesian regression?

Say I have two linear regression models that I want to use for predictions. Linear regression: \begin{equation} \mathbf{y} \sim \mathcal{N}(\mathbf{X^Tb}, \Sigma_y) \end{equation} Bayesian linear regression: \begin{align} \mathbf{y | b} &\sim \mathcal{N}(\mathbf{X^Tb}, \Sigma_y) \notag\\ \mathbf{b} &\sim \mathcal{N}(0, \Sigma_b) \end{align} Predictions For the linear regression, I find the coefficients by MLE: \begin{equation} \mathbf{b}_{\text{MLE}} = \mathbf{(X X^T)^{-1} X y} \end{equation} The predictions for the the test set are: \begin{equation} \mathbf{y_{test}} = \mathbf{X_{test}^T b_\text{MLE}} \end{equation} For the bayesian linear regression, I find the predictive posterior: \begin{equation} p(\mathbf{y_{test}} | \mathbf{X_{test}} , \mathbf{y}, \mathbf{b}) = \int p(\mathbf{y_{test}} | \mathbf{X_{test}}, \mathbf{b}) p(\mathbf{b} |\mathbf{y}) \text{d}\mathbf{b} \end{equation} (Thought this integral could be analytically derived, I find it by Gibbs sampling since in my actual model the different $b_i$ come from a mixture of gaussians.) The predictions are plotted here, where for the bayesian prediction I also plotted the variance of every $y$ (computed from the traces of the Gibbs sampler) Questions How should I compare the two models? Should I use $R^2$ (and then all the bayesian machinery is for nothing?) (forgetting about MLE) How to evaluate the performance of the bayesian estimators? I've found a lot about model selection, but what about the accuracy of a single model?
