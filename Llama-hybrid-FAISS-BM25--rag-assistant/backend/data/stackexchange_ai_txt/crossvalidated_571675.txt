[site]: crossvalidated
[post_id]: 571675
[parent_id]: 571669
[tags]: 
You are right, the activation functions prevent the neural network (NN) from being a linear function, unless you only use linear activation functions, but then it would be again just a linear model. It's this nonlinearity in the activation functions which makes them perform so well in some situations. If you want to obtain a linear model, you should fit a linear model. Even if you would find a way to use a NN and somehow apply some constraints that makes it learn a linear model, this wouldn't be better, and likely worse, than fitting a linear model.
