[site]: datascience
[post_id]: 104387
[parent_id]: 
[tags]: 
Finding logistic loss/negative log likelihood - binary logistic regression classification

I am new to ML and data science and am struggling with a simple problem. In my problem, I am given a series of datapoints $X_i$ where $X_i = (x_{i1}, x_{i2})$ with each data point having a label $y_i$ where $y_i \in [-1, 1]$ . My first task that I must complete the following: Given a weight vector $w$ , write a function to compute the logistic loss (also known as the negative log likelihood) for a given dataset. I also am tasked with building a function that computes the gradient of the logistic loss evaluated at $w$ , and both of these functions in tandem will be used to run gradient descent on the given dataset. For now, I am strictly concerned with developing the first function. I understand log likelihood to be $\sum_{i=1}^n y_i \log p(x_i) + (1 − y_i) \log (1 − p(x_i))$ for a binary classifier, but I am unsure of how to write a function that computes the negative log likelihood. Specifically, how do we calculate $p(x_i)$ and how does a given weight vector $w$ factor into things?
