[site]: crossvalidated
[post_id]: 289414
[parent_id]: 288061
[tags]: 
Red flags go off in my head when someone says (paraphrasing heavily) I can assume property X for my algorithm, but this peroperty X need not be present in the data. That immediately points to possible performance issues and/ or grounds to revaluate model selection step. Having said that, I haven't worked with GMM for clustering beyond the base EM algorithm to find density parameters of points. But to my best understanding, clustering using GMM is fuzzy, i.e. depending on implementation methods you can vary cluster assignment based on some criteria of interest. Working off the above approach I recommend self-organizing maps that semantically group together similar items. As a second step, clustering can be applied on top of it. ( Reference ) Also, when working with mixed models, exploring kernel methods can be quite fruitful as now, your decision boundaries can be more expressive in higher dimensional space. Here's a paper that talks theoretically about how to make common clustering methods more robust using kernel, it covers data with mixture of Gaussian densities as well.
