[site]: crossvalidated
[post_id]: 340736
[parent_id]: 
[tags]: 
Computing the posterior probability in VAE's decoder

The decoder layer of a Variational Autoencoder (VAE) is supposed to allow us to sample $x$ given the prior $z$ on the latent layer. In the VAE tutorial on Keras ( https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py ), the code for sampling new digits is # build a digit generator that can sample from the learned distribution decoder_input = Input(shape=(latent_dim,)) _h_decoded = decoder_h(decoder_input) _x_decoded_mean = decoder_mean(_h_decoded) generator = Model(decoder_input, _x_decoded_mean) # display a 2D manifold of the digits n = 15 # figure with 15x15 digits digit_size = 28 figure = np.zeros((digit_size * n, digit_size * n)) # linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian # to produce values of the latent variables z, since the prior of the latent space is Gaussian grid_x = norm.ppf(np.linspace(0.05, 0.95, n)) grid_y = norm.ppf(np.linspace(0.05, 0.95, n)) for i, yi in enumerate(grid_x): for j, xi in enumerate(grid_y): z_sample = np.array([[xi, yi]]) x_decoded = generator.predict(z_sample) digit = x_decoded[0].reshape(digit_size, digit_size) figure[i * digit_size: (i + 1) * digit_size, j * digit_size: (j + 1) * digit_size] = digit plt.figure(figsize=(10, 10)) plt.imshow(figure, cmap='Greys_r') plt.show() I want to know if there is a way of modifying this code so that given a sample $x$ and a prior $z$ for the latent layer, we can calculate the posterior probability $p(x \mid z)$.
