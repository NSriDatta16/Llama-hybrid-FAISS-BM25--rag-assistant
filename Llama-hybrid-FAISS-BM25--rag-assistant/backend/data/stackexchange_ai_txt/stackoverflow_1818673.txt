[site]: stackoverflow
[post_id]: 1818673
[parent_id]: 1734030
[tags]: 
One of the assumptions with O(n) algorithm efficiency estimations is that our actual running time approaches the theoretical value. Thus, we shouldn't get too wrapped around the axle trying to figure out small variances. An O(n) algorithm may finish in O(n/2) time if we're doing a simple iterative search through an unsorted dataset (on average we'll find the value by the halfway point) for instance, but it is still an O(n) algorithm. If you have a function that has to complete three subprocesses on a dataset before it can exit, then the slowest subprocess's running time on that dataset will be the longest pole in the tent, so to speak. In the specific example given, the function ('algorithm') runs in O(n) time, and we don't worry if it's O(n + n*log(n) + log(n)); the difference between that sum and O(n) is at most a factor of two. What we care about is the relative magnitude, i.e., whether running time is log(n), or (n) or (n^2) or (n^3) ad infinitum. What we care about is a factor of 10, or 100, or 1000.
