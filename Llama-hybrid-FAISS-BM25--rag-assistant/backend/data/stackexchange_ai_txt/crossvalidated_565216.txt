[site]: crossvalidated
[post_id]: 565216
[parent_id]: 564903
[tags]: 
It sounds like you are in a play-the-winner scenario: You pick amongst several effect sizes and only select the largest ones (or only those that are "statistically significant) or something like that. In that case, your estimate of the effect size for the picked comparison will indeed be biased upwards. What can one do about it? As others pointed out, you can valid confidence intervals by adjusting the confidence level in line with Bonferroni (i.e. using two-sided 99.375% confidence intervals instead of 95% ones), but I'm not sure how helpful that truly is (depends somewhat on what you do with these next). An experimental solution is to run another experiment afterwards to get a second unbiased estimate. Other ideas of addressing this include using Bayesian hierarchical models such as with a regularized horseshoe prior that both shrink point estimates and provide credible intervals (where the main challenge is picking a suitable prior = specifying the "needed" amount of shrinkage).
