[site]: crossvalidated
[post_id]: 374163
[parent_id]: 374143
[tags]: 
You should probably standardize your data before PCA. PCA involves projecting the data onto the eigenvectors of the covariance matrix . If you don't standardize your data first, these eigenvectors will be all different lengths. Then the eigenspace of the covariance matrix will be "stretched", leading to similarly "stretched" projections. See here for an example of this effect. This is not what you want. See also here for several good answers describing the geometry of PCA. However, there are situations in which you do want to preserve the original variances. See here for discussion on that topic. As for your follow-up question, of whether you will lose dependencies between variables if you apply standardized independently: the answer is no. In fact, correlation between un-standardized random variables is equivalent to the covariance of standardized random variables. Do note that covariance is inherently a measure of linear association. The covariance between a uniform random variable on $[-1, 1]$ and its square, for example, should be exactly 0. So higher-order relationships between variables could in fact be discarded by PCA. This is one motivation for kernel PCA .
