[site]: crossvalidated
[post_id]: 225423
[parent_id]: 
[tags]: 
Training instances importance in Random Forest?

Is it possible to determine the importance of the training examples in Random Forests, analogously to what's done with predictors? Basically the idea would be to find important samples in the data, kinda like what's done in sparse margin-based classifiers. Taking into account the way trees are grown I'm led to believe it makes sense. Instances are somewhat sampled i.e. bootstrapped analogously to predictors. Could we define something akin to that but instead for the training instances? Thinking about it some more, out-of-bag (OOB) sample accuracy would not be a good importance metric. I'm thinking more along the lines about importance in the tree building process, so OOB is out of the question.
