[site]: datascience
[post_id]: 70162
[parent_id]: 
[tags]: 
greater reconstruction error with Autoencoder while training on Google Colab

I am training an Autoencoder on Google Colab using the GPU. Every time I run the training afresh, the predicted result seems to have a greater image reconstruction error than the last time. The weights are initialised randomly, however this should not have a very significant impact on the predictions. And each new training is done as the training is done the first time. I want to know why does this happen. Is this problem related to the complexity of the model or a cache related problem?
