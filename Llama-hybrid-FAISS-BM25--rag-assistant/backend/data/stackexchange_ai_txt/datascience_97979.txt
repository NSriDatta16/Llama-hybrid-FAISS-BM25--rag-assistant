[site]: datascience
[post_id]: 97979
[parent_id]: 97963
[tags]: 
The most intuitive way of visualizing your cluster results would be by using a linear projection like PCA. In this way you can visualize for example the first 3 components and assign a color to each point according to cluster_id Also important, you should in this case check the explained_variance as measure of how reliable the projection is, since you are projecting your original space into a 3D dimension space. from sklearn.cluster import KMeans from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler, FunctionTransformer from sklearn.decomposition import PCA import plotly.express as px kmeans = Pipeline([("scaling",StandardScaler()),("clustering",KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0))]).fit(X) pca = Pipeline([("standarize", StandardScaler()), ("pca",PCA(n_components = 3)), ("dataframe", FunctionTransformer(lambda x: pd.DataFrame(x, columns = ["first_comp", "second_comp", "third_comp"])))]).fit(X) X3D = pca.transform(X) exaplained_variance = pca["pca"].explained_variance_.cumsum() px.scatter_3d(x = "first_comp", y = "second_comp",z = "third_comp", data_frame= X3D, color= kmeans["clustering"].labels_, title= f"Explained variance: {round(exaplained_variance,3)}") You should obtain a plot similar to this one: Hope it helps!
