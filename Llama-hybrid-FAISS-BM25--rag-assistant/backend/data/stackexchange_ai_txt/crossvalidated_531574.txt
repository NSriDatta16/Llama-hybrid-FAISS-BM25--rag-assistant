[site]: crossvalidated
[post_id]: 531574
[parent_id]: 531572
[tags]: 
This is only a partial answer as this comes from my personal experience of training classifiers rather than the literature. Many classifiers output a weight (or probability) for each class simultaneously, which means the weights are paired by the example from the data set. The approach I have taken is to treat this resulting matrix (rows correspond to examples, columns to the class, and entries are the output weights) as a dataset unto itself to study. In some cases this involves estimating conditional metaprobabilities between classes, but often pairplots and dimensionality reduction plots (PCA/MDS/etc) reveal a lot about what is going on between classes. However, the metaprobability distributions may be what you're interested in if you wish quantify dependence between class confidences.
