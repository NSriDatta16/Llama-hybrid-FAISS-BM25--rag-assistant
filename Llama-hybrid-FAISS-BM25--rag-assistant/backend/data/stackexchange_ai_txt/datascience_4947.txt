[site]: datascience
[post_id]: 4947
[parent_id]: 4944
[tags]: 
A common strategy for dealing with imbalance is to penalize harder the missclassifications that select the class with higher frequency. In a binary classification problem you could penalize by dividing 1/n where n is the number of examples of the opposite class. See the following from Prof. Jordi Vitri√° This is the loss function for structured output SVM. The problem you mention is common in object recognition and object classification in images where much more background images are used than images containing the object. A stronger case happens with exemplar SVM's where just a single image of the object is used.
