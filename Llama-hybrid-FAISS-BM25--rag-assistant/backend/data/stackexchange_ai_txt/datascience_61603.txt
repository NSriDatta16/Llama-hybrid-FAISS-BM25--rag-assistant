[site]: datascience
[post_id]: 61603
[parent_id]: 
[tags]: 
Difference between Gensim word2vec and keras Embedding layer

I used the gensim word2vec package and Keras Embedding layer for various different projects. Then I realize they seem to do the same thing, they all try to convert a word into a feature vector. Am I understanding this properly? What exactly is the difference between these two methods? Thanks!
