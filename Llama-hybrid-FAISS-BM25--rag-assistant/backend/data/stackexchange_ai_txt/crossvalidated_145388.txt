[site]: crossvalidated
[post_id]: 145388
[parent_id]: 145247
[tags]: 
You need to also use the training data $\{(x_i, y_i)\}$; as you've realized, regression via kernel smoothing needs to have the training data at evaluation time. The typical data split would be something like: Training data, where you use the $(x_i, y_i)$ pairs for the model. Validation data, used for model selection (picking $h$) e.g. by trying a bunch of different $h$ values and looking at their prediction error on the validation data. Test data, just $x$, which you give final predictions on using the training $(x_i, y_i)$ and $h$ from model selection. You could also include the validation data pairs in your model at test time; this might make your choice of $h$ less valid (because you picked based on a different setting than you're actually using) but would give more training data, which may improve your final model or not. It would also be common to do model selection based on the average of several different training/validation splits, in a cross-validation scheme.
