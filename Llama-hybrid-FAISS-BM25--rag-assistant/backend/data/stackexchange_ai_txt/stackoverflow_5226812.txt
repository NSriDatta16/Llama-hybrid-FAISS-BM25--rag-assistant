[site]: stackoverflow
[post_id]: 5226812
[parent_id]: 
[tags]: 
Streaming XNA ouput via Expression Engine SDK for a live Augmented Reality Feed

I am attempting to write an application that first merges video into the XNA game engine, adds some augmented reality content, and then streams the rendered content out to another user. All of this needs to happen in real time or near real time. Essentially the system would look like this: Video -> XNA(Game) -> (???) -> Expression Engine -> Live Stream -> Network -> Client The clean and elegant way to do this would be to treat XNA's rendered output as a LiveDeviceSource and feed that directly into an Expression Engine stream Job. Is it possible to write a custom LiveDeviceSource or something similar to do this? Basically does someone know how to create a custom source for the expression engine where I can just push the rendered XNA buffer straight to the encoder? It would be fairly easy to dump the buffer to file and have the expression engine encode that, but I am afraid writing to disk would incur too much latency because of the time required to write to disk. The alternative, quick and dirty hack, is to have the Expression Engine do a screen capture of the output window and then have it stream that. I can get the Expression Engine to capture the screen shot, but I can't get it to stream live. Can someone suggest how to go about doing both simultaneously? Apologies in advance for this question not being all that well formed as I am still getting familiar with the Expression Engine SDK. For reference I am using XNA 4, MS Expression Engine 4, and Visual Studio 2010. Our goal is to eventually integrate this technology with a forthcoming release of Goblin XNA. I would also be open to suggestions for other ways to stream live video directly from XNA. We're not married to the Expression Engine, it just appears to be the best streaming solution we've come across so far (we are having problems with ffmpeg).
