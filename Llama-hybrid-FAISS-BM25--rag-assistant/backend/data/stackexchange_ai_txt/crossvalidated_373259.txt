[site]: crossvalidated
[post_id]: 373259
[parent_id]: 373205
[tags]: 
Graphing the predictions and the data is helpful in interpreting such a complex interaction, so let's begin there. These graphs were made by asking the software for the fitted values of the response at all eight possible combinations of the categorical regressors f1 and f3 , using two extreme values of the continuous regressor f2 at each combination--which is enough to determine a line. The R code to do that is X I find it difficult to understand these plots because the data are scattered everywhere. That's because this model is overfit and none of the variables are significant. (At this point you should stop and re-fit a simpler model, but I will presume the data in the question are offered only as an example and are not the real data.) Just to aid our visualization and understanding, here are plots for a new dataset in which the fitted coefficients are exactly the same but the residual standard deviation is just one-tenth as great. Now the data closely follow the fitted lines, as we would hope. The dots represent the data, color-coded by time ( f3 ) and gender ( f1 ). The lines of the same color are the model's predictions. The dots are connected vertically to their predictions (by nearly-transparent line segments) to make this relationship visually obvious and to display the residuals (represented by the segments). Each set of dots, then, shows the empirical relationship between f2 and the response dep , broken down by day and gender (eight total combinations). The three-way interaction f1*f2*f3 amounts to fitting a different line to ( f2 , dep ) for each of the eight combinations of f1 and f3 . How might we read the parameters of those lines from the output? As an example, consider the orange line at the right: males on day 1. Let's look at all coefficients that reference this class, along with the model intercept: Fixed effects: Estimate Std. Error t value (Intercept) 0.34060 0.17029 2.000 f1Male 0.07985 0.28134 0.284 ... f1Male:f2 0.24027 0.50410 0.477 The first two do not involve f2 : their sum, $0.34060 + 0.07985 = 0.42045,$ is the intercept of the fit for males on day 1. The coefficient of f1Male:f2 is the slope. We can verify this: such a line passes through the points $(0, 0.42045)$ and $(1, 0.42045+0.24027)=(1,0.66072).$ Indeed, that looks like an accurate description of the orange line in the right panel. As another example, consider females on day three (the cyan elements of the left hand plot). The relevant coefficients are Fixed effects: Estimate Std. Error t value (Intercept) 0.34060 0.17029 2.000 ... f3day3 0.08267 0.24178 0.342 ... f2:f3day3 -0.17483 0.46797 -0.374 The intercept is the sum of coefficients that do not involve f2 , $0.34060 + 0.08267 = 0.42327.$ The slope is the sum of all coefficients that do involve f2 , namely $-0.17483$ itself. The line therefore passes through $(0,0.42327)$ and $(1, 0.42327-0.17483) = (1, 0.24844).$ That is an accurate description of the cyan line in the left panel. Notice that females are never explicitly named in the output: they are the "reference class." Thus, " f3day ", because it does not mention males, is the intercept for females on day 3 relative to the overall intercept for the model. In this sense the full 16 lines of output contain eight intercept terms (which do not mention f2 ) and eight slope terms (which do mention f2 ). It is a good exercise to repeat these calculations for the remaining six combinations of gender and day. Finally, this was relatively simple to interpret because the model is not a mixed one: there's no variation in the subjects that isn't already accounted for by the fixed effects. (You can confirm this by replacing lmer by lm and summarizing its results.) In a real mixed model these fixed-effect "predictions" are applied to an idealized subject whose random responses are average: that is, they are all zero. For the record--and to make this thread stand alone without requiring readers to run the code--here's the full output of the model summary. The 16 lines of coefficients and the eight lines in the graphics provide equivalent information. Random effects: Groups Name Variance Std.Dev. sub (Intercept) 0.00000 0.0000 Residual 0.09684 0.3112 Number of obs: 72, groups: sub, 6 Fixed effects: Estimate Std. Error t value (Intercept) 0.34060 0.17029 2.000 f1Male 0.07985 0.28134 0.284 f2 0.04282 0.34608 0.124 f3day2 0.35641 0.29089 1.225 f3day3 0.08267 0.24178 0.342 f3day4 -0.02534 0.26100 -0.097 f1Male:f2 0.24027 0.50410 0.477 f1Male:f3day2 0.06930 0.45320 0.153 f1Male:f3day3 0.12338 0.39152 0.315 f1Male:f3day4 0.03710 0.39234 0.094 f2:f3day2 -0.05340 0.48516 -0.110 f2:f3day3 -0.17483 0.46797 -0.374 f2:f3day4 0.31651 0.54514 0.581 f1Male:f2:f3day2 -1.11295 0.77543 -1.435 f1Male:f2:f3day3 -0.27124 0.72289 -0.375 f1Male:f2:f3day4 -0.72224 0.71385 -1.012 Here is the R code used to generate the plots. It is run after executing the data-creation code in the question. library(lme4) # lmer library(ggplot2) # ggplot # # Fit the model. # m $Predicted Predicted
