[site]: crossvalidated
[post_id]: 608924
[parent_id]: 
[tags]: 
What is the correct (regression) test to quantify changes of tumor size of an inhomogeonus data set?

I am analysing a dataset of tumor volumes over time of a tumor that occurs in children. It is hypothesized that the tumors shrink over time and shrink faster the younger you are. The question is how much the tumors decrease on average over time during different ages. I therefore thought I would need some regression and the slope would be my decrease of size over a certain time frame. However the dataset is very inhomogenous. Some tumours were measured several times (e.g., 5 volume measurements over time), others only twice, others 10 times. In addition the measurements happened at different ages. This means one tumor was measured three times, e.g., at 4, 49 and 205 days of age, another was measured two times at 45 and 603 days of age and another at 200 and 412, 415, 490 and 1700 days of age (just example data). So the questions I need to answer are: Do tumors shrink in volume over time, if yes, how much on average in my dataset over a certain timeframe. Do tumors shrink faster when a patient is within, e.g., his first year of life compared to later years. I first did a linear regression analysis of different time frames and used every measurement as individual unrelated data point, but I think this doesn't make sense as information of the measurements that are from the same patient is lost and patients and timeframes that have more measurements are overrepresented. But I am not sure if this is a problem. It probably is... Other regression tests I looked into required that every patient has a value at the very same timepoint (every patient needs a measurment exactly at, e.g., 0 days, 10 days, 20 days, 50 days, etc) and if just one value was missing it gave an error. What is the correct test I need to do and can do with my type of data?
