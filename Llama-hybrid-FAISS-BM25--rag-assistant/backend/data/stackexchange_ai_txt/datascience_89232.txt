[site]: datascience
[post_id]: 89232
[parent_id]: 
[tags]: 
Sum of squares for matrix valued data over $\mathbb{R}$ and $\mathbb{C}$

Let us assume we have $k \times k$ matrix valued data and assume this is organized (possibly as time series): $$ M_1, M_2, \ldots, M_n $$ Now, assume we are interested in writing down an error function that mimics sums of squares. This can naively be written as $$ \sum_{i=1}^n (M_i - \hat M_i)^2 $$ where $\hat M_i$ is the $i$ -th estimation. The question is, what is actually the proper way to write this function explicitly ? For vectors, the Euclidean norm is "naturally" picked. What about this case? One option is to multiply out these matrices and treat each of the resulting matrix's elements on its own. For example the element at position 11 would have its own "error function" that looks like: $$ \sum_i (a_{11}^2 +a_{12}a_{21}) $$ and similarly for the other three elements. Here $M-\hat M \equiv A = (a)_{ij}$ . Does this even make sense? Furthermore, how to treat the same example having complex valued matrices ?
