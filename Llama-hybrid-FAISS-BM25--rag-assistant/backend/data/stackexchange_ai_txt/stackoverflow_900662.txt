[site]: stackoverflow
[post_id]: 900662
[parent_id]: 869744
[tags]: 
You already got the most part of the answer via the code samples above. Using asynchronous I/O operations is absolutely the way to go here. Async I/O is the way the Win32 is designed internally to scale. The best possible performance you can get is achieved using completion ports , binding your sockets to completion ports and have a thread pool waiting for completion port completion. The common wisdom is to have 2-4 threads per CPU (core) waiting for completion. I highly recommend to go over these three articles by Rick Vicik from the Windows Performance team: Designing Applications for Performance - Part 1 Designing Applications for Performance - Part 2 Designing Applications for Performance - Part 3 The said articles cover mostly the native Windows API, but they are a must-read for anyone trying to get a grasp at scalability and performance. They do have some briefs on the managed side of things too. The second thing you'll need to do is make sure you go over the Improving .NET Application Performance and Scalability book, that is available online. You will find pertinent and valid advice around the use of threads, asynchronous calls and locks in Chapter 5. But the real gems are in Chapter 17 where you'll find such goodies as practical guidance on tuning your thread pool. My applications had some serious problems until I adjusted the maxIothreads/maxWorkerThreads as per the recommendations in this chapter. You say that you want to do a pure TCP server, so my next point is spurious. However , if you find yourself cornered and use the WebRequest class and its derivatives, be warned that there is a dragon guarding that door: the ServicePointManager . This is a configuration class that has one purpose in life: to ruin your performance. Make sure you free your server from the artificial imposed ServicePoint.ConnectionLimit or your application will never scale (I let you discover yourself what the default value is...). You may also reconsider the default policy of sending an Expect100Continue header in the HTTP requests. Now about the core socket managed API, things are fairly easy on the Send side, but they are significantly more complex on the Receive side. In order to achieve high throughput and scale, you must ensure that the socket is not flow controlled, because you do not have a buffer posted for receive. Ideally for high performance you should post ahead 3-4 buffers and post new buffers as soon as you get one back ( before you process the one got back), so you ensure that the socket always has somewhere to deposit the data coming from the network. You'll see why you probably won't be able to achieve this shortly. After you're done playing with the BeginRead/BeginWrite API and start the serious work, you'll realize that you need security on your traffic, i.e., NTLM/Kerberos authentication and traffic encryption, or at least traffic tampering protection. The way you do this is you use the built in System.Net.Security.NegotiateStream (or SslStream if you need to go cross disparate domains). This means that instead of relying on straight socket asynchronous operations you will rely on the AuthenticatedStream asynchronous operations. As soon as you obtain a socket (either from connect on client or from accept on server) you create a stream on the socket and submit it for authentication, by calling either BeginAuthenticateAsClient or BeginAuthenticateAsServer. After the authentication completes (at least your safe from the native InitiateSecurityContext/AcceptSecurityContext madness...) you will do your authorization by checking the RemoteIdentity property of your Authenticated stream and doing whatever ACL verification your product must support. After that you will send messages using the BeginWrite and you'll be receiving them with BeginRead. This is the problem I was talking before that you won't be able to post multiple receive buffers, because the AuthenticateStream classes don't support this. The BeginRead operation manages all the I/O internally until you have received an entire frame. Otherwise, it could not handle the message authentication (decrypt frame and validate signature on frame). Though in my experience the job done by the AuthenticatedStream classes is fairly good and shouldn't have any problem with it. I.e., you should be able to saturate a 1 Gbit/s network with only 4-5% CPU. The AuthenticatedStream classes will also impose the protocol-specific frame size limitations on you (16k for SSL, 12k for Kerberos). This should get you started on the right track. I'm not going to post code here, and there is a perfectly good example on MSDN . I've done many projects like this and I was able to scale to about 1000 users connected without problems. Above that, you'll need to modify registry keys to allow the kernel for more socket handles. And make sure you deploy on a server OS, that is, Windows Server 2003 , not Windows XP or Windows Vista (i.e., client OS), it makes a big difference. BTW, make sure, if you have databases operations on the server or file I/O, you also use the async flavor for them, or you'll drain the thread pool in no time. For SQL Server connections, make sure you add the 'Asyncronous Processing=true' to the connection string.
