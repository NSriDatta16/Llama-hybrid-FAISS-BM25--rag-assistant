[site]: crossvalidated
[post_id]: 76888
[parent_id]: 76865
[tags]: 
Based on your update pseudo code it looks like you're using a sigmoid output. In this case given an input $x$ your output should be $$ \sigma(x) = \frac{1}{1 + e^{-(w^T x + b)}}. $$ It is worth noting that if you assume a log-loss function (which is what you should use for classification) your setup is just binary logistic regression. In this case your update should be $$ w_\text{new} = w_\text{old} + \eta \sum_{j}[d(j) - \sigma(x(j))] x(j), $$ where $\eta$ is the learning rate. If on the other hand you're using a squared loss (which it seems like you are, but is normally not the right choice for classification) the update will look like $$ w_\text{new} = w_\text{old} + \eta\sum_{j}[d(j) - \sigma(x(j))][1 - \sigma(x(j))]\sigma(x(j))x(j). $$ The reason your weights are diverging is probably due to forgetting the parenthesis when translating the above, you have w(new) = w + step/N * sum_all(d(j) - o(j) * o(j) * (1 - o(j)) * x(j)) which should be w(new) = w + step/N * sum_all((d(j) - o(j)) * o(j) * (1 - o(j)) * x(j)) All that being said the above isn't really the standard perceptron algorithm. Normally the output for a perceptron is given by $$ f(x) = \mathbb{I}\{w^T x > 0\}, $$ where $\mathbb{I}$ is the indicator function. In this case you can learn the parameters using subgradient descent which results in an update of the form $$ w_\text{new} = \left\{\begin{array}{l l} w_\text{old} + \eta [d(j) - f(x(j))] x(j) &:\; d(j) \neq f(x(j)) \\ w_\text{old} &:\; \text{otherwise.} \end{array}\right. $$
