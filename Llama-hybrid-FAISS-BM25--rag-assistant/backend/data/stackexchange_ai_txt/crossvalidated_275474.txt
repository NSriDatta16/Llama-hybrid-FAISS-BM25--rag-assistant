[site]: crossvalidated
[post_id]: 275474
[parent_id]: 81861
[tags]: 
The score function measures whether the DAG structure that has been learnt is a good fit to the dataset. Of course, you can define the score function in several ways, depending on the dataset, and the ultimate objective of learning the DAG structure. One commonly used score function is the log-posterior . Given dataset $D$ and a vector $\mathbf{X}$ of variables, the log posterior score function $S(D,G)$ is defined as $$ S(D,G) := \log{p_{pr}(G)} + \log{p(D|G)} $$ where $p_{pr}$ is the prior over the DAGs. Let the set of parameters be $\theta \in \Theta$. $p(D|G)$ is the marginal likelihood $$ p(D|G)= \int_{\Theta}{p(D|G, \theta) \cdot p_{pr}(\theta)d\theta} $$ The bnlearn R Package defines several score functions depending on the nature of the data (whether it is categorical, continuous or mixed). Categorical data (multinomial distribution): the multinomial log-likelihood; the Akaike Information Criterion (AIC); the Bayesian Information Criterion (BIC); a score equivalent Dirichlet posterior density (BDe); a sparse Dirichlet posterior density (BDs); a Dirichlet posterior density based on Jeffrey's prior (BDJ); a modified Bayesian Dirichlet for mixtures of interventional and observational data; the K2 score; Continuous data (multivariate normal distribution): the multivariate Gaussian log-likelihood; the corresponding Akaike Information Criterion (AIC); the corresponding Bayesian Information Criterion (BIC); a score equivalent Gaussian posterior density (BGe); Mixed data (conditional Gaussian distribution): the conditional Gaussian log-likelihood; the corresponding Akaike Information Criterion (AIC); the corresponding Bayesian Information Criterion (BIC). For $n$ variables, the number of possible DAGs is super-exponential. Here is a link to the integer sequence. As you can see, the number grows very fast. https://oeis.org/A003024
