[site]: stackoverflow
[post_id]: 5293159
[parent_id]: 5293017
[tags]: 
$lastUrl = trim(file_get_contents('last_url.txt')); while($lastUrl == ($randUrl = $urls[rand(0, count($urls) - 1)])){} file_put_contents('last_url.txt', $randUrl); // ... echo $randUrl; Ensures that on each page load, you will not receive the previous URL. This, however is just an example. You would want to incorporate file locking, exception handling (perhaps) or an entirely different storage medium (DB, etc.) To ensure the URL is not the same as the current, this should do the trick: // get current URL $currentUrl = 'http://' . $_SERVER["SERVER_NAME"] . $_SERVER["REQUEST_URI"]; // randomize URLs until you get one that doesn't match the current while($currentUrl == ($randUrl = $urls[rand(0, count($urls) - 1)])){ } echo $randUrl; Google "PHP get current URL", and you'll get considerably more detailed ways to capture the current URL. For example, conditions on whether or not you're use HTTPS , to append an ' s ' to the protocol component.
