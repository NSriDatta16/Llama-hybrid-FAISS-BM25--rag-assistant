[site]: crossvalidated
[post_id]: 296645
[parent_id]: 296640
[tags]: 
The traditional frequentist definition of a $p$-value is, roughly, the probability of obtaining results which are as inconsistent or more inconsistent with the null hypothesis as the ones you obtained. $H_0$ can be neither observed nor randomly varying, so it's appearance in a probability statement is a aberration of frequentist notation. If $T$ is a statistic that summarizes an experiment such that $T$ takes a known value (assume WLOG this is 0) when the null hypothesis is true, and takes non-zero values otherwise, a notational expression might be $p = P_{H_0} (t > T)$, where $t$ is the sampling distribution of the test statistic, a hypothetical distribution of replications of the very experiment you conducted. The conditional, $H_0$ imposes some restrictions on $t$, so that it takes a known form under the null, and this enables comparisons without actually conducting thousands upon thousands of replications of the experiment. To explain a frequentist "p" value in Bayesian terms we need some clarity. Bayesian probability and Bayesian testing are two separate concepts. The likelihood ratio can be roughly understood as a Bayes Factor without a prior. Bayesian probability doesn't help us understand a frequentist $p$-value because $H_0$ "fixes" the parameter to be a particular value, and Bayesians do not take data to be randomly varying (in the sense of repeated experiments).
