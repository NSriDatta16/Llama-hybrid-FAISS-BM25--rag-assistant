[site]: datascience
[post_id]: 89790
[parent_id]: 
[tags]: 
Results of quadratic SVM in Matlab are different from the results obtained in Python

I am trying to replicate a quadratic SVM classifier from Matlab to Python, however I am having different results regarding the accuracy. In Matlab the accuracy is 0.8955 meanwhile in Python the accuracy is 0.82089. I believe a 7% difference is high enough to be something there that I am doing wrong. For instance my Python code is the following: # Standardize the input data mean = np.zeros(descriptors) std = np.zeros(descriptors) scaled_mean = np.zeros(descriptors) scaled_std = np.zeros(descriptors) for i in range (0,descriptors): mean[i] = x_train[i].mean() std[i] = x_train[i].std(ddof = 1) x_train[i] = (x_train[i] - mean[i])/std[i] scaled_mean[i] = x_train[i].mean() scaled_std[i] = x_train[i].std(ddof = 1) #If gamma = 'auto' it goes into an infinite loop, Matlab gamma therefore is used clf = svm.SVC(kernel = 'poly', degree = 2, gamma = 0.4955, cache_size = 1000) clf.fit(x_train, y_train) # save the model to disk joblib.dump(clf, filename) As my training dataset consists of 3 features with 66 rows each I have done no validation in the classification learner app that Matlab provides, but I do have in mind that overfitting might be a problem in the future. Aside from that I would like to point out that I have used previously the scaler that sklearn provides to standardize, but since it does not take into account the ddof parameter that Matlab does I have chosen to compute the standardization myself. I leave the datasets that I have used here, but please note that in the the matlab train.mat file only the first 3 columns are used to train, and the last column contains the labels (0,1), the remaining ones are not used at all. https://ufile.io/f/rrf6g
