[site]: crossvalidated
[post_id]: 404740
[parent_id]: 
[tags]: 
Question about using Bayesian rule as a classification for continuous data set

Please note that my question is not about coding. I am now learning Bayesian classification and I think I understand it in a discrete case. I have trouble understanding it for multivariate continuous data. My problem is in calculating the posterior. Example: Assume that we have a data set with two classes. The first class ( D ) is the patient with a disease. The second class ( H ) is healthy patients. Assume that I have 25 patient. 15 of patients are suffer from the disease. Now we can estimate the posterior probability that the new patient is healthy (using Bayesian theorem) as: $P(Glass= H | X=x)= \frac{\pi_{H} f_{h}(x)}{\pi_{H}f_{H}(x)+\pi_{D}f(_{D}(x)} \rightarrow {(1)} $ . Where x is a realisation of the random vector X (the patient), $f_{H}, f_{D}$ are the density of each class respectively. Assume that I fit a copula model to this data. Assume further that I calculate the density of each class. Using copula, I will have this: This is just an example not a real data (for a simplification I assumed that u is the data.) set.seed(123) u Now the density values of the first class is stored in f_D . As we can see there are 15 values in f_D . My question is (assume the prior of each class is 0.5 ): For the Bayesian theorem, how can I calculate the posterior in (1) ? Here, I have 15 values for f_D . Then, I should multiply them by 0.5 (the prior). However, I will not get a single value for the posterior! So, do I have to sum the values in f_D or product them? Any help is appreciate.
