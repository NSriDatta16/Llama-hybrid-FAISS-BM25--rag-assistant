[site]: datascience
[post_id]: 89490
[parent_id]: 89093
[tags]: 
When you say " ...how various aspects of a movie contribute to its gross revenue. " I'm assuming you want " If I were to change $A_1$ of a movie, how would it's gross revenue be affected? " Which is a causal statement. With this assumption in mind, I will rewrite Approach 1 and 2 ; Approach 1 - Don't control for anything, and measure the effect $A_1$ has on revenue Approach 2 - Control for everything, and measure the effect $A_1$ has on revenue. Both have fundamental problems, stemming from how the data was generated, and how attributes affect each other ; Approach 1 's problem is confounders , attributes that affect both $A_1$ and revenue. Here's a good example of a confounder: It has been seen that children with a larger shoe size have a better reading ability. The trick is that age affects both reading ability and shoe size, the older you get, the larger your shoe size, as well as (generally) better reading ability. That make age here a confounder of shoe size and reading ability. So, for the movie example, genre might affect runtime as well as revenue, making it a confounder of runtime and revenue. Approach 2 's problem is colliders (and potentially mediators ). A collider is an attribute that $A_1$ and revenue affect. For example if we say that both talent and beauty contribute to an actor's success, then, if we look at successful actors, we will see a negative correlation between beauty and talent (basically saying being beautiful makes you less talented). The reason for this is because, if we see an actor is unattractive, that increases our belief that the successful actor is very talented instead. Here, success was the collider, and when we controlled for it, it warped our connection between talent and beauty . An example in the movies might be that the number of reruns of a movie is affected by revenue and runtime, making number of reruns a collider of the two, thus, if we control for it, it will warp the relationship between runtime and revenue in ways we don't want. Another potential problem with Approach 2 is mediators, attributes that affect revenue and are affected by $A_1$ An example of a mediator would be Fire → Smoke → Fire Alarm. Fire creates Smoke which triggers the Fire Alarm. If we were to control for Smoke, we would be removing the mechanism Fire uses to trigger Fire Alarm, which would lead us to believe that Fire can't trigger Fire Alarm (which is technically true, fire itself doesn't trigger the Fire Alarm, fire doesn't have a direct effect on Fire Alarm). We have to be aware of the mediators and that controlling for them turns the total effect of $A_1$ on revenue into the direct effect $A_1$ has on revenue. So, If you're looking for the total effect, then Approach 2 falls victim to mediators as well, if you want the direct effect, that would make Approach 1 falls victim instead. These are the fundamental flaws with Approaches 1 and 2 , but there's also the problem of too small bin sizes, that would just be mostly noise (nicely explained in David Cian's answer ). You can fix this by either getting more data or making more assumptions (e.g. assuming 10 minutes in a movie's runtime won't make a difference, and binning runtime into 10 minute wide bins). So, in conclusion (for Approach 1 and 2 ), If you want to do something like Approach 1 and 2 , you need to do a mix of the two. Find out what attributes are confounding and control for them, then, you can safely measure how revenue changes as $A_1$ changes, and rank the attributes based on that. Of course, to find the confounders, you need to know the model from which your attributes were generated from (known as a " Causal Model "), which can be tough to find. There's a great book on of this, " The Book of Why " by Judea Pearl . I highly recommend it, if you're interested in this sort of thing. Now, let's talk about Approach 3 , the more volatile approach I would say; The thing is, many algorithms can measure "feature importance", and it's hard to say what exactly the algorithm looks for when it says "important" (one thing is for certain though, it won't measure "If I were to change $A_1$ of a movie, how would it's gross revenue be affected?"). But if you want an answer, Random Forests don't make any assumptions about the data, and have a nice way of measuring feature importance. However of course, they are highly parametric, and will just memorize (i.e. overfit) the data if left unconstrained, so you need to do quite a bit of parameter tuning. Another model I like is the KNN, it doesn't assume much about the data (just that it's all on the same scale, which is easy to do), and doesn't have many parameters you have to fine-tune (just "number of neighbours" really), however, it unfortunately doesn't have a good way to measure feature importance. I did come up with an algorithm to find feature importances involving the KNN though (how it works is it goes through every feature and temporarily removes it, then, it fine-tunes a KNN to it, and measures the accuracy, and assigns the accuracy to the feature, the lower this accuracy, the more important the feature is). However, in the end, the algorithm I would recommend if you're going with Approach 3 is the Random Forest. Conclusion " What assumptions do I need to check for approach 1? " - Make sure the bins are large enough to contain meaningful information, this also applies to Approach 2 . " Are there any potential flaws or gotchas in approaches 1 and 2? " - Approach 1 falls prey to confounders , Approach 2 falls prey to colliders and you need to keep in mind mediators . " What approach would you prefer out of the three? " - Approach 3 , because the other two approaches have fundamental flaws, but if there was an Approach 4 - "Find all of the confounders, control for them, and measure how revenue changes with respect to $A_1$ ", I would choose that instead. " What ML model should be used for approach 3? " - I recommend the Random Forest.
