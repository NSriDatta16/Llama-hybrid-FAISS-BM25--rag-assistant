[site]: crossvalidated
[post_id]: 365109
[parent_id]: 
[tags]: 
McDonald's Omega: Assumptions, Coefficients and Interpretation

After browsing cross validated and several other sources on the web, I still cannot get a grip on McDonald's Omega as a measure of internal consistency. I have a hunch that many fellow social scientists feel similarly insecure about the measure, so I hope to get some clarification on several aspects on this measure: Assumptions / Prerequisites While the assumptions for Cronbach's Alpha are commonly discussed (e.g. Cronbach Alpha Assumptions ), I haven't managed to get a full picture of the prerequisites for McDonald's Omega. My questions being: What are the general assumptions underlying Omega? Is there a rule of thumb regarding sample size, or a ratio between variables and observations that should be considered? Is Cronbach's Alpha superior to Omega under any circumstances at all? Coefficients and Interpretation Secondly, it appears that there still is a great deal of confusion around the different Omega coefficients, perhaps most notably returned by the psych -package in R. For clarification, maybe someone could offer a full interpretation of coefficients in the following example, in ?psych::omega , library(psych) #create 9 variables with a hierarchical structure v9 v9.omega$omega.group total general group g 0.7984002 0.6857363 0.1126608 F1* 0.7449332 0.6034008 0.1415325 F2* 0.6303512 0.4034189 0.2269323 F3* 0.5022309 0.2460886 0.2561423 > v9.omega$omega.lim [1] 0.858888 My questions regarding this example: How does the interpretation between omega.tot and omega_h (general) differ in this example? Or: What would the correct global measure of internal consistency for the entire measure/questionnaire be? What is group telling us? When is omega.lim relevant? In addition: It appears that omega_h (general) is getting the most attention in posts/reports, but these values always strike be as surprisingly low in almost every example I have seen. How come? Thanks
