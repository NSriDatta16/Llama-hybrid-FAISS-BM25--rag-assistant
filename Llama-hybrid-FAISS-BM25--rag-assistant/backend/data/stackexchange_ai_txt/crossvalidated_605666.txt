[site]: crossvalidated
[post_id]: 605666
[parent_id]: 
[tags]: 
Solving the SVM Dual Problem

This toy problem was just thought of by me to get an better intuition for the SVM algorithm. Assume the following optimization problem: $$ L(w, b, \alpha)=\frac{1}{2}||w||^2 - \sum_{i}\alpha_i[y_i(\langle w, x_i\rangle)+b)-1] $$ This is the objective function of a SVM problem. To find the boundary that solves a given Classification problem, we have to solve $$ \underset{w, b}{\mathrm{argmin}} \underset{\alpha}{\mathrm{argmax}}=\frac{1}{2}||w||^2 - \sum_{i}\alpha_i[y_i(\langle w, x_i\rangle)+b)-1] $$ To find a decision boundary that is able to correctly classify data points. I tried a very simple problem with two points $x_1 = [1, 1]$ , $x_2 = [2, 3]$ and $y_1 =-1$ , $y_2=1$ . Taking the partial derivative for each variable, I was able to find the correct solution. Now, this objective function can be further simplified by plugging in the optimal values for $w$ and $b$ : $$ \underset{\alpha}{\mathrm{argmax}}-\frac{1}{2}\sum_{i}\sum_j \alpha_i \alpha_j y_i y_j \langle x_i, x_j \rangle + \sum_i \alpha_i $$ $$ s.t.\sum_i \alpha_iy_i=0 $$ I tried to solve the problem the same way, taking the partial derivative of each $\alpha$ , setting to zero and try to solve it. However, this will not give me any solution, I arrive at $a_1 = 7$ and $a_2 = 15$ which does not satisfy the constraint. I read that this is an quadratic optim. problem, and thus needs a different approach. If this is true, why was I able to solve the first opt. problem?
