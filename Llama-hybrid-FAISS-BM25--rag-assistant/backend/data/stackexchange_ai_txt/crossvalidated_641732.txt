[site]: crossvalidated
[post_id]: 641732
[parent_id]: 641726
[tags]: 
Is this a common approach in your field? I mean forming composites over several self-report measures and performance-based measures such as cognitive tests? Not that there's necessarily anything inherently wrong with it but by my reading it seems uncommon and may make it more difficult to publish your results (if your goal is journal publication). Usually you'd make separate composites of pre-established scales or maybe combined some scales with very similar content. Also, it could be argued that self-reports and reports by close other offer slightly different perspective, so averaging them loses information. However, to do this, a typical way to start would be factor analysis. As you have the idea that all these scales and tests could be combined, you could test a one-factor confirmatory factor analysis. In essence, you'd try to find evidence that your different measures are indeed all strongly related to each other, strongly enough that they can be said to be represented by one common latent factor. lavaan is a great package for CFA in R. If you want to try exploratory factor analysis (in which the model will suggest number of factors to you), package psych has good functions. Then again, because you're particularly interested in prediction, maybe another way would be some type of penalized regression such as LASSO or elastic net regression. For this, you don't need to form a composite but you can put all your predictors into the model to get the best predictive model (I don't know much about this approach, just a thought).
