[site]: crossvalidated
[post_id]: 635365
[parent_id]: 
[tags]: 
How to prepare sequential word data for many-to-many LSTM?

I want to build a many-to-many LSTM and I need some guidance on how to prepare the data that I have for such a model. My data frame consists of subject_ID (dance couple), Time (in s, time step in a song when the move happened, so from 0s to 3min), Behavior (dance move name). The data would look something like this: I know that the LSTM needs data with the format of [samples, time steps and features]. I would assume that nb_samples is the total amount of dance moves in the dataset. Then nb_timestep is the number of moves I want to look back to predict the next one, so in this case we can say 3. Lastly, nb_feature is 1, which is a dance move name. My questions are: are these assumptions correct? is there any logic to how I can select an appropriate nb_timestep? Should I base my decision on the nature of my data and some dance theory, or rather the architecture of LSTM? I have 63 unique dances, thus 63 unique dance moves sequences. How would I take this into account when preparing my input data? I guess I somehow need to indicate where the new dance begins so the model does not assume that the last move of the previous couple should be used for the prediction of the next coupleÂ´s move. I am rather new at machine learning and neural networks, so any guidance or redirection to sources would be helpful and appreciated. Thank you!
