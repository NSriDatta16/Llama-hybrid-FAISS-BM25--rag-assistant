[site]: datascience
[post_id]: 53223
[parent_id]: 
[tags]: 
How is the loss between actual and predicted labels being calculated?

Quoting from this example of Predicting movie review with BERT and Tensorflow, with tf.variable_scope("loss"): # Dropout helps prevent overfitting output_layer = tf.nn.dropout(output_layer, keep_prob=0.9) logits = tf.matmul(output_layer, output_weights, transpose_b=True) logits = tf.nn.bias_add(logits, output_bias) log_probs = tf.nn.log_softmax(logits, axis=-1) # Convert labels into one-hot encoding one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32) predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32)) # If we're predicting, we want predicted labels and the probabiltiies. if is_predicting: return (predicted_labels, log_probs) # If we're train/eval, compute loss between predicted and actual label per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1) loss = tf.reduce_mean(per_example_loss) return (loss, predicted_labels, log_probs) How is the loss between actual and predicted labels being calculated? The above example id for multi-class, single-label setting. If I want to calculate the loss for a multi-class, multi-label problem, how can I do the necessary computation in Tensorflow?
