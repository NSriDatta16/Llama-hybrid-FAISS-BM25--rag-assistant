[site]: crossvalidated
[post_id]: 13751
[parent_id]: 13739
[tags]: 
The usual test scenario where you want to consider FDR is when you have a vector $(T_i)_{i=1,\ldots,n}$ of test statistics. The $i$'th test statistic could, for instance, be a test of differential expression between two cases (two levels in @Mike's terminology) for the $i$'th gene in a microarray experiment. The literature on FDR deals with choosing a threshold for the test statistics and providing an estimate of FDR for that threshold. How to do that correctly depends on the whether the test statistics are independent or dependent (and how they are dependent). My understanding is that the question is based on a data matrix $X$ of dimension $m \times n$ of $m$ observations of an $n$-dimensional vector and that you want to use PCA to make a dimension reduction of $X$ to an $m \times n'$ matrix with orthogonal rows before you compute $n'$ test statistics. The test statistics could be tests of whether there is a statistically significant difference between two subgroups of the $m$ observations. First, don't mix up the geometric orthogonality of the computed principal components with independence of the resulting test statistics. Although PCA "de-correlates" the columns above it does not imply statistical independence of the computed test statistics. However, there could be a point in reducing the $n$ to a (perhaps much smaller) $n'$. As @Mike remarks, if all the rows in the original data matrix are identical, say, there is really only one test, and if you do multiple testing corrections under the independence assumption you would be overly conservative. On the other hand, if only a small fraction of the rows represent differences between the two cases, then these differences might drown when you compute the principal components. Whether the suggested method is a "powerful combination" or not depends upon the power of the resulting method. Will or will you not be able to detect the differences between the two cases across samples better by computing principal components first? The answer to this is a complicated function of the setup you consider and there will not be a simple answer. In the given example the use of PCA could equally well produce a set of directions where the differences have been smeared out as it could produce a set of directions that emphasize the differences. Given that you are only interested in detecting if there is a difference, it seems to me that you are really looking for a way to aggregate the data or the different test statistics. A simple idea, like taking the average, might work just as well.
