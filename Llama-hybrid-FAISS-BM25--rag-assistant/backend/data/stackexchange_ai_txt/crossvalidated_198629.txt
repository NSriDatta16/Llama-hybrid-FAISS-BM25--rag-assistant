[site]: crossvalidated
[post_id]: 198629
[parent_id]: 
[tags]: 
difference between overtraining and overfitting

After reading several tutorials, journal articles, and websites, I am confused about the difference between overtraining and overfitting. Could some gurus enlighten? -# Others remarks:-#- In J. Chem. Inf. Comput. Sci., 1995, 35 (5), pp 826â€“833 ( http://pubs.acs.org/doi/abs/10.1021/ci00027a006 ), the authors said: ANN = artificial neural networks with one hidden layer (ANN) "Since a neural network with a sufficient number of neurons in the hidden layer can exactly implement an arbitrary training set, it can learn both investigated dependencies and a noise that will lower the predictive ability of the network. Two conditions influence the problem: *size of ANN *time of ANN training The overfitting problem refers to exceeding some optimal ANN size, while overtraining refers to the time of ANN training that may finally result in worse predictive ability of a network. " Moreover, this mailing list also has some discussions: https://groups.google.com/forum/#!topic/comp.ai.neural-nets/V_ryR8fgw2E -# my understanding:-#- So my understanding is that over-fitting occurs when a model is too complex, where anything can be correlated with anything if there are enough variables/ factors. Cross validation is to avoid over-fitting. In a regression model, Using q2 (cross-validated r2) can judge if a model is over-fitting ( J. Am. Chem. Soc. 1988,110, 5959- 5967)? 0.4 good predictive power 0 poor model Also, my understanding is that when a model is over-fitting, it is likely it doesn't have strong predictive power and therefore it is a over-trained model? If yes, good validation results (good q2), but poor prediction results (poor r2 in a regression model) suggests over-training? Could some gurus enlighten? Thanks.
