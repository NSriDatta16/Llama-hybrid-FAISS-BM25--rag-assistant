[site]: crossvalidated
[post_id]: 551085
[parent_id]: 
[tags]: 
Regression on principal components (number of modes, evaluation, predictive value)

I seek advice on the use of regression on principal components. I have a large dataset of anatomical shapes with point correspondence, on which I have performed PCA to investigate the main modes of variation. For these anatomical shapes, corresponding metadata such as sex and age is available. The ultimate goal is to accurately predict sex and age of other, unknown instances of the same shape. The idea was to fit a stepwise logistic model with PC modes as predictors and sex as response, and separately, a stepwise linear model with PC modes as predictors and age as response. However, I am confused on three things: 1) how many PC modes to include in the model and 2) how to evaluate the predictive value of the fitted model and 3) how to find the model with the best predictive value. Based on methods such as a compactness plot and Horn's parallel analysis, only the first N modes should be retained; the remainder modes have mainly captured noise and not true variance of the dataset. However, some modes further down the line seem to have a good predictive value for sex or age. The finding that modes with small eigenvalues can be useful in regression, is corroborated by literature ( https://www.jstor.org/stable/2348005?origin=crossref ). The question is, how is it possible that modes that mainly captured noise, be useful for e.g. sex prediction? Am I allowed to include all modes in a regression model? Let's consider the logistic model for predicting sex. The more modes I include in the model, the better my Rsquared and adjusted Rsquared values are. At some point, these approximate 1.0 - the input data is separated perfectly into male/female subgroups. Of course, this is the point where the model is potentially overfitted. I evaluated the model by leaving one case out and predicting sex for this case based on the resulting model. Eventually, I calculate in how many cases sex is predicted correctly - in my view, this is an intuitive parameter to evaluate how the model performs. Is leave-one-out cross-validation a good method for evaluating a regression model? I built various stepwise logistic models for sex, including different numbers of PC modes (e.g. modes 1-3, 1-10, 1-20, 1-50). Upon evaluation (see question 2), the resulting models have different predictive success rates. The success rate does not always increase when including a larger number of PC modes in the model. How can I find the model that has the best predictive value?
