[site]: datascience
[post_id]: 109012
[parent_id]: 
[tags]: 
ValueError: Exception encountered when calling layer "transformer" (type Transformer)

So I code a Transformers neural network that works as an ASR, it works, it trains good and saved the model as... model.save("savedmodel.model") The problem is that when I want to predict, I do this.. speech_model = load_model('D:\DOT\Speechrecognition\speechrecognitionE.model') path = "D:\DOT\Speechrecognition\Data\LJSpeech-1.1\wavs\LJ001-0001.wav" def path_to_audio(path): # spectrogram using stft audio = tf.io.read_file(path) audio, _ = tf.audio.decode_wav(audio, 1) audio = tf.squeeze(audio, axis=-1) stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256) x = tf.math.pow(tf.abs(stfts), 0.5) # normalisation means = tf.math.reduce_mean(x, 1, keepdims=True) stddevs = tf.math.reduce_std(x, 1, keepdims=True) x = (x - means) / stddevs audio_len = tf.shape(x)[0] # padding to 10 seconds pad_len = 2754 paddings = tf.constant([[0, pad_len], [0, 0]]) x = tf.pad(x, paddings, "CONSTANT")[:pad_len, :] return x x = path_to_audio(path) #print(x) speech_model.predict(x) The path to audio function, converts the audio path to an spectrogram, in the training model it receive audio spectrograms as inputs, but it show this error.. Traceback (most recent call last): File "C:\Users\berna\Desktop\Programming\AI_ML_DL\Projects\DOT\DOT-alpha.py", line 72, in speech_model.predict(x) File "C:\Users\berna\AppData\Roaming\Python\Python39\site-packages\keras\utils\traceback_utils.py", line 67, in error_handler raise e.with_traceback(filtered_tb) from None File "C:\Users\berna\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\framework\func_graph.py", line 1129, in autograph_handler raise e.ag_error_metadata.to_exception(e) ValueError: in user code: File "C:\Users\berna\AppData\Roaming\Python\Python39\site-packages\keras\engine\training.py", line 1621, in predict_function * return step_function(self, iterator) File "C:\Users\berna\AppData\Roaming\Python\Python39\site-packages\keras\engine\training.py", line 1611, in step_function ** outputs = model.distribute_strategy.run(run_step, args=(data,)) File "C:\Users\berna\AppData\Roaming\Python\Python39\site-packages\keras\engine\training.py", line 1604, in run_step ** outputs = model.predict_step(data) File "C:\Users\berna\AppData\Roaming\Python\Python39\site-packages\keras\engine\training.py", line 1572, in predict_step return self(x, training=False) File "C:\Users\berna\AppData\Roaming\Python\Python39\site-packages\keras\utils\traceback_utils.py", line 67, in error_handler raise e.with_traceback(filtered_tb) from None ValueError: Exception encountered when calling layer "transformer" (type Transformer). Could not find matching concrete function to call loaded from the SavedModel. Got: Positional arguments (2 total): * Tensor("inputs:0", shape=(None, 129), dtype=float32) * False Keyword arguments: {} Expected these arguments to match one of the following 4 option(s): Option 1: Positional arguments (2 total): * [TensorSpec(shape=(None, None, 129), dtype=tf.float32, name='inputs/0'), TensorSpec(shape=(None, 199), dtype=tf.int32, name='inputs/1')] * False Keyword arguments: {} Option 2: Positional arguments (2 total): * [TensorSpec(shape=(None, None, 129), dtype=tf.float32, name='inputs/0'), TensorSpec(shape=(None, 199), dtype=tf.int32, name='inputs/1')] * True Keyword arguments: {} Option 3: Positional arguments (2 total): * [TensorSpec(shape=(None, None, 129), dtype=tf.float32, name='input_1'), TensorSpec(shape=(None, 199), dtype=tf.int32, name='input_2')] * False Keyword arguments: {} Option 4: Positional arguments (2 total): * [TensorSpec(shape=(None, None, 129), dtype=tf.float32, name='input_1'), TensorSpec(shape=(None, 199), dtype=tf.int32, name='input_2')] * True Keyword arguments: {} Call arguments received: • args=('tf.Tensor(shape=(None, 129), dtype=float32)',) • kwargs={'training': 'False'} What does that means? what is wrong with the prediction?
