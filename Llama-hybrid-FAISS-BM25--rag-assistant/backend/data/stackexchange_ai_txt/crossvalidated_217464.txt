[site]: crossvalidated
[post_id]: 217464
[parent_id]: 
[tags]: 
Correlation between vectors with non-matching y values without using interpolation

Is there a way to calculate the correlation between two time series that have been adaptively downsampled and thus (may) have different y values? This is easiest to explain with an example, so consider the case of two downsampled time series (n=100->down_n=5) in the range of time-points 1 to 100: S1 = (10,1), (20,30.5), (30,35), (40,70.95), (50,100) S2 = (10,1), (15,10), (40,80.2), (45,85), (60, 100) Because the x values are all increasing, there is a definite correlation, however the oddly spaced y values mean that it's not as strong as it initially seems. I know I could interpolate so the y values match (or just add some of the original points back in), but I have downsampled because of memory constraints in other processing so I want to avoid adding points back in. Hopefully this makes sense. I tried to keep it clear without overloading information. Thanks in advance! EDIT - To clarify the data: In the example x is the value and y is the time. In the downsampling, floating point y values can be interpolated. So (10,1) means that at time point 1, the observed value was 10, while (20,30.5) means at time point 30.5, it is likely/interpolated that the value for x would have been 20.
