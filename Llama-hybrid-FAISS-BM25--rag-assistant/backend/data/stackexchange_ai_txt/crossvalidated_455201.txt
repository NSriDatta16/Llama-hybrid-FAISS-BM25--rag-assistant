[site]: crossvalidated
[post_id]: 455201
[parent_id]: 455200
[tags]: 
Firstly, random chance is always a possibility (especially without knowing more details - e.g. if you have a really small training and test dataset, then randomly changing anything may have just about any effect). I.e. it may not mean anything. Secondly, multi-collinearity is not much of an issue for prediction models. It generally just indicates that some variables contain different information and may not add all that much value once one of the other multi-collinear ones ist included. However, it may still be that there are some small differences that still have value for predictions. To some extent, one just has to try this out (with cross-validation or a hold-out set - I assume you did that, and the F1-score is not just on the training data). Multi-collinearity is primarily an issue, if you are trying to interpret contributions (e.g. regression coefficients in logistic regression) from different similar predictors (these then become highly unstable and very hard to interpret).
