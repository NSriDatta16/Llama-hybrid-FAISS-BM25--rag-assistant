[site]: crossvalidated
[post_id]: 286975
[parent_id]: 
[tags]: 
Correlation matrix and redundant information

I am using a neural network model for a classification task with 13 inputs. I study through the connection weights to depict the relevant variables. I have also made a correlation matrix to check the relationship between them: Some groups of variables seem to have strong positive and negative relationships. My fear is that I would have to remove some because they are redundant (?). However, I may consider keeping them to let the network decide by itself which ones to use among those to get rid of. Is it generally advised to remove redundant information (if highly correlated) when training neural networks? My study aims at defining the best variables to use (for similar future classification task) so that we get the best prediction performance at the end. In this purpose, I have removed some of the highly correlated variables but got lower prediction accuracy.
