[site]: crossvalidated
[post_id]: 205965
[parent_id]: 205932
[tags]: 
"inverting the dropout during the training phase" should be preferable. Theoretically if we see Bernoulli dropout as a method of adding noise to the network, it's better that the noise could have a zero mean. If we do the scaling at training time to cancel out the portion of deactivated units, the mean of the noise would be zero. There are other types of dropout/noise methods came out later (e.g. Gaussian multiplicative dropout, Gaussian additive noise ) that also possess a zero mean. In terms of training and testing neural networks in practice, there a reason to prefer such implementation as well. Say I want to compare the performance of two models with the same architecture, one is trained by dropout and one is not. If I "scale the activation at test time", then I'll need two different networks at test time. If I use the "inverted version" then I could just apply the same test network (code) to both sets of trained parameters.
