[site]: crossvalidated
[post_id]: 498146
[parent_id]: 
[tags]: 
Cross-validation necessary when using Random Forest?

I am new to this forum, but I am stuck with a couple questions related to image classification, and seeing the kind and highly useful messages that people provide, I had the hope that someone could help me out in clarifying something for me. I will try to be as explicit and clear as possible on my problem, but I am rather confused as you might see. So here goes: Question 1: I am wanting to use an object based image analysis in ERDAS to assess differences in vegetation types (i.e. shrubs, grasses, trees, mosses) in a peatland landscape using spectral imagery, but I am unsure about the methods to use and which steps follow each other. Now you can just press on some buttons in a program, but I am wanting to understand better where my decision comes from and if this is credible. The questions therefore are: how do you determine which kind of classifier is best for your data, and if and what kind of resampling method to use? I read for example that it is necessary to resample your samples (e.g. Monte-Carlo cross-validation, or k-fold) and average accuracies of all splits you made to increase their validity. Besides, does resampling follow after classification? So would the steps then be: Subset your data (e.g. 67:33 into training, testing) Pick a classification algorithm that suits your needs and data Run the classification and note accuracy Resample (split) your data into new training and testing data using a resampling technique Re-run classification for all unique splits Average accuracies of all splits to get the "real" accuracy Question 2: Let's say I were to pick RandomForest, which I think is one classification algorithm; would I still need to cross-validate my data with a resampling technique? For example, I read that RandomForest sort of contains its' own cross-validation because it prevents overfitting through the use of bootstrapping of the variables used in the decision trees. Does this mean that instead of just a classification algorithm, RandomForest is a classification algorithm Ã¡nd cross-validation in one? Is it then still possible or needed to cross-validate the models by using for example five splits of data (67:33 training versus testing) and running the RandomForest with each of these unique splits, and then summarizing this information, or would that be overkill? I am sorry if there is too many questions, and I am willing to clarify if needed. I hope someone could help me and I appreciate all the effort in advance! Sincerely, Jasper
