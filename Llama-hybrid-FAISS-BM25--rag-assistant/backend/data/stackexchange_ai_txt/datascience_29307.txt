[site]: datascience
[post_id]: 29307
[parent_id]: 29179
[tags]: 
There are multiple things at play here. First of all, if your training and testing data are different then it becomes difficult to learn to generalize, because it will learn the relationships in your training data and if those relationships are significantly different then it will learn the wrong things. It could be that the data density is just different in your testing set which is not as much of a problem. Second of all, if the relationship that you see is not linear, your logistic regression might not be able to pick up the relationship due to the underlying linear assumption. Third of all, maybe other features are highly (co)correlated and adding the new feature does not add any signal but does add the potential for fitting additional noise, thus explaining the performance reduction.
