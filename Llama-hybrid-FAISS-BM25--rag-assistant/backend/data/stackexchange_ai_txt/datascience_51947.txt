[site]: datascience
[post_id]: 51947
[parent_id]: 51946
[tags]: 
In general any tool that many researchers use is by definition useful/helpful. For the particular case of Keras and other neural network frameworks (like PyTorch, TensorFlow, etc), a lot of people use them. You can see this by reading papers in the topic, as it is usually mentioned which framework the implementation is made in. You can also check "popularity" by counting references, for example for keras and tensorflow , both have thousands of citations. In general you should prefer well known tools that are used in the field. These are validated and you can at least have a degree of trust that the results they produce are correct (minus user mistakes, of course). Implementing a neural network framework from scratch is not easy and any reviewer can point out that there could be programming errors and/or mistakes. Also as you mention there is the advantage of reproducibility, as it is much more likely that people can run your code. Also note that many frameworks were actually made by researchers, so they are specifically targeted for other researchers, and their design is made for easy experimentation. In keras for example, it is easy to implement some custom functionality as a loss or layer, so you can integrate it with another network design. A framework can have another target userbase such as deployment for low power platforms or computers, which Keras doesn't. Finally, you have to consider that since a lot of people use Keras, there is a large community around it from where you can get support, such as Stack Overflow or the keras-users google group . Using custom code will make this more difficult or impossible. If you want not to depend on a specific framework, you can always export networks in ONNX format so you can use it with another framework or your own code.
