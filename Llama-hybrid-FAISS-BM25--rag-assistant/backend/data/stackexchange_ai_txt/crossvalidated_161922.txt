[site]: crossvalidated
[post_id]: 161922
[parent_id]: 161806
[tags]: 
The most convenient goodness-of-fit for random forest is out-of-bag cross-validation, it can provide a R² value and e.g. std.dev of prediction. It is important to use cross-validation, as the direct goodness-of-fit is completely misleading for any non-linear machine learning model, as they can fit mostly anything also noise. Here's a link on the interpretation of R² for the randomForest package: Link! p-values are not much used in random forest context, as the hypothesis space is so huge. If you want to identify related variables,use variable importance. If you want to make a fair comparison on prediction performance between MLR an RF you need to design a cross-validation and embed both models. 10-fold and 10 times repeated would normally be regarded as solid. From such a cross validation a R² and std.error could be extracted.
