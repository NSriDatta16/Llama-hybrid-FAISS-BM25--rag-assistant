[site]: crossvalidated
[post_id]: 24583
[parent_id]: 6652
[tags]: 
R.A. Fisher had a criterion for the usefulness of confidence intervals: A CI should not admit of "identifiable subsets" that imply a different confidence level. In most (if not all) counterexamples, we have cases where there are identifiable subsets that have different coverage probabilities. In theses cases, you can either use Bayesian cred-intervals to specify a subjective sense of where the parameter is, or you can formulate a likelihood interval to reflect the relative uncertainty in the parameter, given the data. For example, one case that seems relatively contradiction-free is the 2-sided normal confidence interval for the population mean. Assuming sampling from a normal population with given std., the 95% CI admits of no identifiable subsets that would provide more information about the parameter. This can be seen by the fact that the sample mean is a sufficient statistic in the likelihood function - i.e., the likelihood function is independent of the individual sample values once we know the sample mean. The reason we have any subjective confidence in the 95% symmetric CI for the normal mean stems less from the stated coverage probability and more from the fact that the symmetric 95% CI for the normal mean is the "highest likelihood" interval, i.e., all parameter values within the interval have a higher likelihood than any parameter value outside the interval. However, since likelihood is not a probability (in the long-run accuracy sense), it is more of a subjective criterion (as is the Bayesian use of prior and likelihood). In sum, there are infinitely many intervals for the normal mean that have 95% coverage probability, but only the symmetric CI has the intuitive plausbiltiy that we expect from an interval estimate. Therefore, R.A. Fisher's criterion implies that coverage probability should equate with subjective confidence only if it admits of none of these identifiable subsets. If subsets are present, then the coverage probabilty will be conditional on the true values of the parameter(s) describing the subset. To get an interval with the intuitive level of confidence, you would need to condition the interval estiamte on the appropriate ancillary statistics that help identify the subset. OR, you could resort to dispersion/mixture models, which naturally leads to interpreting the parameters as random variables (aka Bayesian statistics) or you can calculate the profile/conditional/marginal likelihoods under the likelihood framework. Either way, you've abandoned any hope of coming up with an objectively verifiable probabilty of being correct, only a subjective "ordering of preferences." Hope this helps.
