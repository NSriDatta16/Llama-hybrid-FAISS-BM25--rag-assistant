[site]: crossvalidated
[post_id]: 374615
[parent_id]: 374409
[tags]: 
Thank you to @a_statistician for the correct analytical solution. I've since realised why my simulation results haven't agreed with this analytic result ( cov(x1, x2) == var(x1) ): the effect of sampling error is surprisingly strong here, even with large N, and so the correlation between $x_1$ and $\epsilon$ weren't necessarily 0, and the sample variances of $x_1$ and $\epsilon$ weren't necessarily their population values of $\sigma^2_1$ and $\sigma^2_{\epsilon}$ . Here's the corrected simulation code. library(tidyverse) orthogonalise = function(x1, x2){ X = data.frame(x1, x2) %>% as.matrix pca = prcomp(X) pX = X %*% pca $rotation return(list(x1=pX[,1], x2=pX[,2])) } exact.orthogonal.samples = function(var1, var2){ n = 1000 x1 = rnorm(n, 0, 1) x2 = rnorm(n, 0, 1) # Remove correlation ox = orthogonalise(x1, x2) x1 = ox$x1 x2 = ox$ x2 # Set variance x1 = x1 * (sqrt(var1)/sd(x1)) x2 = x2 * (sqrt(var2)/sd(x2)) return(list(x1=x1, x2=x2)) } vals = 2^seq(1, 8) vals = seq(1, 10, 1) d = expand.grid(var1=vals, var2=vals) d $cov = res = pmap_dbl(d, function(var1, var2){ # Generate random variables and check covariance between x1 and x2 (= x1 + e) X = exact.orthogonal.samples(var1, var2) x1 = X$x1 e = X$ x2 x2 = x1 + e cov(x1, x2) }) jet.colors
