[site]: crossvalidated
[post_id]: 219262
[parent_id]: 217995
[tags]: 
This is my take on the linear algebra behind PCA. In linear algebra, one of the key theorems is the Spectral Theorem. It states if S is any symmetric n by n matrix with real coefficients, then S has n eigenvectors with all the eigenvalues being real. That means we can write $S = ADA^{-1} $ with D a diagonal matrix with positive entries. That is $ D = \mbox{diag} (\lambda_1, \lambda_2, \ldots, \lambda_n)$ and there is no harm in assuming $\lambda_1 \geq \lambda_2 \geq \ldots \geq \lambda_n$ . A is the change of basis matrix. That is, if our original basis was $x_1,x_2, \ldots, x_n$ , then with respect to the basis given by $A(x_1), A(x_2), \ldots A(x_n)$ , the action of S is diagonal. This also means that the $A(x_i)$ can be considered as a orthogonal basis with $||A(x_i)|| = \lambda_i$ If our covariance matrix was for n observations of n variables, we would be done. The basis provided by the $A(x_i)$ is the PCA basis . This follows from the linear algebra facts. In essence it is true because a PCA basis is a basis of eigenvectors and there are atmost n eigenvectors of a square matrix of size n. Of course most data matrices are not square. If X is a data matrix with n observations of p variables, then X is of size n by p. I will assume that $ n>p$ (more observations than variables) and that $rk(X) = p $ (all the variables are linearly independent). Neither assumption is necessary, but it will help with the intuition. Linear algebra has a generalization from the Spectral theorem called the singular value decomposition. For such an X it states that $ X = U \Sigma V^{t} $ with U,V orthonormal (square) matrices of size n and p and $\Sigma = (s_{ij}) $ a real diagonal matrix with only non-negative entries on the diagonal. Again we may rearrange the basis of V so that $s_{11} \geq s_{22} \geq \ldots s_{pp}> 0 $ In matrix terms, this means that $ X(v_i) = s_{ii} u_i$ if $ i \leq p$ and $ s_{ii} = 0 $ if $ i> n$ . The $ v_i$ give the PCA decomposition. More precisely $ \Sigma V^{t} $ is the PCA decomposition. Why ?Again, linear algebra says that there can only be p eigenvectors. The SVD gives new variables (given by the columns of V) that are orthogonal and have decreasing norm.
