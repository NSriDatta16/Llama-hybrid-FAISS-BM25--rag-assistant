[site]: crossvalidated
[post_id]: 554140
[parent_id]: 
[tags]: 
defining posterior distribution when doing Bayesian linear regression

Trying to derive the posterior distribution for the following model with $n$ observations $$y=\beta_{0} + \beta_{1}X_{1}+\beta_{2}X_{2}+\epsilon$$ where the error terms $\epsilon$ follow a normal distribution $N(0,\sigma^2_{\epsilon})$ with a normal prior on $\beta_0 \sim N(0, \sigma^2_{\beta_0})$ and normal priors on coefficient terms $\beta_1, \beta_2 \sim N(0, \sigma^2_{\beta})$ . $\sigma^2_{\epsilon}$ has an inverse gamma prior with parameters $\alpha, \gamma$ . $\sigma^2_{\beta_0} \sigma^2_{\beta} \alpha, \gamma$ are constant. Im having particular trouble defining the likelihood. Any help much appreciated!
