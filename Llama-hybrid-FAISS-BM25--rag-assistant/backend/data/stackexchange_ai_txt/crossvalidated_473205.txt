[site]: crossvalidated
[post_id]: 473205
[parent_id]: 473180
[tags]: 
You can’t. Even for $x+y=10$ there’s infinitely many possible inputs. You can pick random $x$ , say $526149.6427855$ and solve for $y$ $$ 526149.6427855 - 10 = y $$ same can be done for any $x$ , or for any $y$ . Neutral networks are deterministic, but much more complicated then summation, so solving it wouldn’t be that simple. Moreover, they almost always have multiple inputs, for example you input $32\times 32 \times 3$ image and get single number as output, or for recurrent neutral network, you take a sequence of any length, possibility infinite, and get a number, so that’s much harder then two unknowns. Neural networks also use many non-linear and wasteful transformations, e.g. ReLU activation transforms any $x to zero, MaxPool takes many different values and returns single, highest one, etc., so there’s many inputs that lead to their output. Even finding a single input that might have produced the given output of neutral network is non-trivial problem, since its seeking for a needle in a haystack, not talking about finding all such inputs.
