[site]: crossvalidated
[post_id]: 532609
[parent_id]: 532603
[tags]: 
I've seen mostly seen $*$ used when you have items $i=1,\ldots,I$ for which you have random effects, say, $\theta_i \sim N(0, \tau^2)$ and you've observed some data. Then you have some estimates $\hat{\theta}_i$ for each of those $\theta_i$ . So, when you predict something for these items $i=1,\ldots,I$ , you condition on the estimate of the random effect for these items (or in the Bayesian setting, you condition for each MCMC sample $k=1,\ldots,K$ on the estimate $\hat{\theta}_i^{(k)}$ ). A different situation arises, when you are trying to predict for a new item, for which you have no data. That often gets index with $*$ and you predict essentially by sampling $\theta_*$ from $N(0, \hat{\tau}^2)$ . Or, in the Bayesian seetting, you draw $\hat{\theta}_i^{(k)} \sim N(0, {\hat{\tau}^{(k)}}^2)$ . Why do I keep mentioning the Bayesian setting? Mostly, because that handles the uncertainty about the estimates of the $\theta_i$ and $\tau$ "better" when making new predictions.
