[site]: crossvalidated
[post_id]: 136727
[parent_id]: 
[tags]: 
Choosing a good binary classifier to be trained by a small set of labeled data

I have a small set of labeled data (diagnosis in individual subjects): ~50 of "sick" observations ~100 of "healthy" observations In reality, only ~1% of the observations are expected to be considered "sick". I have 10-30 variables (I'm still working on them), some of them are related to each other, so I prefer a classifier that can take into account non-linear functions of variables, or can handle large number of variable (so I'll just define additional variables as the relations I think might be explanatory) Unfortunately it could be that the classification is independent on any of the variables, so I need to be careful about overfitting. Since the training set is really small, running time are not important. I can also run multiple different methods and make a decision based on all of them. A method that can identify an uncertainty conditions is preferable over a method that just classify. In case of uncertainty some value to indicate the level of certainty should be returned or at least a warning flag. Based on the mentioned considerations and constraints, what is the best classifier(s) I can choose? What method can I use to classify based on the results of different algorithms? Update: I'm looking for answers with a specific suggested method. I'm using matlab, so existing solutions implemented in matlab are preferred but it's not a must. I have some knowledge of matlab, but almost no knowledge in statistics or machine learning . Please describe an actual method that uses some different algorithms/ensembles and decide on a final classification based on them.
