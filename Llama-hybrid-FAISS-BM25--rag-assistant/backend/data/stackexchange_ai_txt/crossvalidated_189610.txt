[site]: crossvalidated
[post_id]: 189610
[parent_id]: 
[tags]: 
How to interpret when logistic regression is performing better than classification trees?

I used both techniques on a rather unbalance data set (90%/10%) with 2500 observations and about 20 features. Firstly, I compared the default models. In a second step, I weighed the misclassification costs differently to correct for the skewed distribution. However, classification trees kept to perform worse. Before weighing the costs differently, the trees kept splitting only once (after pruning). How should I conclude here? A few points which crossed my mind are the following: the problem might be kind of linearly separable and this is why logistic regression is performing better the features do not interact with each other the features can simply not explain the response (but this brings up the question of why the variables are significant in the logistic model)
