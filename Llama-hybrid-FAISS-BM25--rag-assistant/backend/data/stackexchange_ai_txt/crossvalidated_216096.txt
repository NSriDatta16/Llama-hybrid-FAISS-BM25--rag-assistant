[site]: crossvalidated
[post_id]: 216096
[parent_id]: 216073
[tags]: 
Your question is a little broad so I will try to write briefly some of the assumptions statisticians make about the variables used in the analysis. If you need explanation of a particular assumptions, look up CV, and if useful thread not found, post a new question. Consider the regression equation $\hat y = \beta_0 + \beta_1x_1 + \beta_2x_2 + ... + \beta_px_p + \epsilon_i$ and below are the common OLS regression assumptions: Linearity: relationship between dependent and independent variables is linear in nature. You should see from scatter plot of DV vs IV whether the relationship is linear. Various transformations help achieve linearity in case of non-linear relationship. Normality: the variables as well as the unexplained error term, $\epsilon$, are normally distributed (bell shaped). It should be clear from histograms of variables and of error terms (residuals) whether normality assumption holds. A normal probability plot or normal quantile plot of the residuals can be used to check if the distribution of $\epsilon$ is normal. More about normality . Statistical independence of the errors: the error terms, $\epsilon, $ are not correlated with independent variables. Also, there is no correlation between consecutive errors themselves in the case of time series data. Error term has zero-mean: the mean of errors is $0$, i.e. , $E[\epsilon] =0$ Homoscedasticity (constant variance) of the errors: the error term does not vary over time. A plot of residuals versus predicted values should indicate presence of constant variance. See more about homoscedasticity
