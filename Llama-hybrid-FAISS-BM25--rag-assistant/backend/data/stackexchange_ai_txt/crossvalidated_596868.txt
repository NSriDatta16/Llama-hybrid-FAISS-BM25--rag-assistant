[site]: crossvalidated
[post_id]: 596868
[parent_id]: 596866
[tags]: 
Cross-validation is a tool for assessing prediction performance. It applies equally well to any type of model, but perhaps is even more obviously needed for models with hyperparameters that need tuning (e.g. RF, GBDT, NNs etc.), while fitting a statistical model via maximum likelihood may seem to not have tunable hyperparameters (but you can of course apply penalization etc.). If you do inference such as answering a question on whether a treatment compared with placebo improves blood pressure based on a randomized trial using a pre-specified regression analysis model, there's usually no point in doing cross-validation. There's no hyperparameters to choose and the predictive capability of the model is not really per-se of interest. There's of course areas that lie between these two cases, where the answer is not so clear and where mixtures of approaches may be appropriate. Note: As an aside, by most definitions of "machine learning" any regression model is a form of machine learning.
