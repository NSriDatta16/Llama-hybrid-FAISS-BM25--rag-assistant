[site]: crossvalidated
[post_id]: 472736
[parent_id]: 468054
[tags]: 
The straightforward application of Euler Lagrange equation would lead to the sought result. First, the derivative of the integrated expression with respect to $y'$ is zero, simply because $y'$ is nowhere to be seen. Here $F(y(\mathbf x),\mathbf x)=\int (y(\mathbf x)-t)^2 p(\mathbf x,t)dt$ , so we get: $\frac{\partial}{\partial y'}F=0$ Second, the derivative of $F$ with respect to $y(\mathbf x)$ is trivial, no need to even apply Leibnitz rule : $$F_y= \frac{\partial}{\partial y(\mathbf x)}\int (y(\mathbf x)-t)^2 p(\mathbf x,t)dt =2\int (y(\mathbf x)-t) p(\mathbf x,t)dt$$ So, there you get the equation that you're looking for: $$F_y=2\int (y(\mathbf x)-t) p(\mathbf x,t)dt=0$$ This condition minimizes the expectation. As to reference to all math that's used in machine learning, there's no such a thing. Whatever the researches decides to use is a fair game. For instance, number theory and abstract algebra concepts can be used, like in this paper . The most common tools tend to be linear algebra, real analysis (calculus), probability and typical computer science toolset such as graph theory.
