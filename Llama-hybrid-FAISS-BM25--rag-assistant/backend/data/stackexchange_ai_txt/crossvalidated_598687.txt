[site]: crossvalidated
[post_id]: 598687
[parent_id]: 598239
[tags]: 
Your implementation is correct. It doesn't matter that the rows corresponding to the padding tokens have a uniform attention because the next module that uses the attention's output (variable out in your code) should ignore these padding tokens. For example, if the next module is a linear layer followed by a cross-entropy loss (common in sequence tagging), when you compute the mean loss you have to mask these padding positions. Therefore, your loss wouldn't include these invalid positions, so their attention values don't matter.
