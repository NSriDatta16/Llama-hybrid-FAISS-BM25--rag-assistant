[site]: datascience
[post_id]: 86819
[parent_id]: 
[tags]: 
pix2pix GAN with Rectangular Image Dataset

I am currently working on a project (for university) which translates sketches of faces to images of this person. For implementing this, I decided to use a pix2pix GAN architecture . However, I have the issue that the dataset contains photos in the format of 200x250 pixel instead of the 256x256 pixel the TensorFlow reference implementation is designed for. The dataset is a modified version of the CUFS dataset provided by my professors. I identified the following three possibilities for managing this dataset: Rescaling all images to 256x256 pixel which I implemented as a first draft and which works quite okay, pad the images to size 256x256 pixel and accept that parts of the training effort goes towards learning pixel which will always have a value of 0, or to modify the architecture in order to process images of size 200x250 pixel, which was suggested by my professor. I have implemented the first two alternatives, but I would like to also try to implement the third alternative. However, I am kind of afraid I might break the architecture by randomly changing the dimensions of the convolution layers. Thus, I want to ask you if you have any suggestions on how to adapt the architecture for inputs of size 200x250 pixel? The source code is available as a Jupyter notebook hosted on Google Colab . I also provide a link to the dataset , in case you need it. Just for your information, I have to use TensorFlow and Keras for this project.
