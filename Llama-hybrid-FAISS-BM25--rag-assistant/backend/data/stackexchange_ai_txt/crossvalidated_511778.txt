[site]: crossvalidated
[post_id]: 511778
[parent_id]: 
[tags]: 
How to calculate the z-score to an interpolated 2-dimensional point?

I have many 2-dimensional data-points (x,y) and I know that there is a correlation between x and y. Now, for a certain point P, I want to calculate something like a z-score (in y), given its x-value. Visually, I imagine something similar to this, just instead of the confidence interval, I would be interested in the expected standard-deviation at the given x-positions: My real data: 2 3 4 5 6 (Red dot is my point of interest. Blue dots are averaged background-values, after sorting and grouping them by x-value.) I have over 100 such points and their respective 2d background distributions and I would like to know whether these 100 points, as a whole, are significantly higher in y, than expected for their x-values. Could you give me some tips how to code such an analysis? Is there anything I have to check before attempting such an analysis? I.e. homoscedasticity along x?
