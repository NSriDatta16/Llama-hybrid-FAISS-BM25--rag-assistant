[site]: crossvalidated
[post_id]: 5196
[parent_id]: 
[tags]: 
Why use Platt's scaling?

In order to calibrate a confidence level to a probability in supervised learning (say to map the confidence from an SVM or a decision tree using oversampled data) one method is to use Platt's Scaling (e.g., Obtaining Calibrated Probabilities from Boosting ). Basically one uses logistic regression to map $[-\infty;\infty]$ to $[0;1]$. The dependent variable is the true label and the predictor is the confidence from the uncalibrated model. What I don't understand is the use of a target variable other than 1 or 0. The method calls for creation of a new "label": To avoid overfitting to the sigmoid train set, an out-of-sample model is used. If there are $N_+$ positive examples and $N_-$ negative examples in the train set, for each training example Platt Calibration uses target values $y_+$ and $y_-$ (instead of 1 and 0, respectively), where $$ y_+=\frac{N_++1}{N_++2};\quad\quad y_-=\frac{1}{N_-+2} $$ What I don't understand is how this new target is useful. Isn't logistic regression simply going to treat the dependent variable as a binary label (regardless of what label is given)? UPDATE: I found that in SAS changing the dependent from $1/0$ to something else reverted back to the same model (using PROC GENMOD ). Perhaps my error or perhaps SAS's lack of versatility. I was able to change the model in R. As an example: data(ToothGrowth) attach(ToothGrowth) # 1/0 coding dep
