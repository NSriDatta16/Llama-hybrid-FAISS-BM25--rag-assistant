[site]: datascience
[post_id]: 67070
[parent_id]: 67047
[tags]: 
There might be an nan value present in your dataset somewhere. I ran the code above on another dataset and it executed without issue. That said, I did not specify the input shape in the first layer - instead doing so before initializing the RNN. Check to see if your dataset has any errors, but the below amendment is also something you might consider. # reshape input to be [samples, time steps, features] X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1])) # Initialising the RNN regressor = tf.keras.Sequential() # Adding the first LSTM layer and some Dropout regularisation regressor.add(LSTM(units = 50, return_sequences = True)) regressor.add(Dropout(0.2)) # Adding a second LSTM layer and some Dropout regularisation regressor.add(LSTM(units = 50, return_sequences = True)) regressor.add(Dropout(0.2)) # Adding a third LSTM layer and some Dropout regularisation regressor.add(LSTM(units = 50, return_sequences = True)) regressor.add(Dropout(0.2)) # Adding a fourth LSTM layer and some Dropout regularisation regressor.add(LSTM(units = 50)) regressor.add(Dropout(0.2)) # Adding the output layer regressor.add(Dense(units = 1)) # Compiling the RNN regressor.compile(optimizer = 'adam', loss = 'mean_squared_error') # Fitting the RNN to the Training set regressor.fit(X_train, Y_train, epochs = 100, batch_size = 32)
