[site]: crossvalidated
[post_id]: 270249
[parent_id]: 270207
[tags]: 
This is a classic confusion. An r-value indicates how accurately X (linearly) predicts Y in your particular data set. A P-value indicates how likely it is for an r-value of that magnitude to have occurred by chance in a world where X and Y are not actually (linearly) related. If you have a small data set, it's easy to get a large r-value by chance: Suppose you observe two men with blue eyes and one woman with green eyes. That's an r=1 correlation between sex and eye color! Should you be highly confident that sex predicts eye color? Contrapositively, if you have a large data set, it's quite possible to observe a very weak correlation, but still be very confident that it didn't occur by chance (i.e. have a low P-value): Suppose you measure the heights of a million men and women. The typical scatter in human heights is larger than the difference in male and female averages, so you would not expect to get a very high r-value. But you would get a fantastically small P-value, because even though the height difference between the sexes is relatively small, there is very definitely a real difference between those averages. One pity formulation of this: "statistical significance is not the same a practical significance".
