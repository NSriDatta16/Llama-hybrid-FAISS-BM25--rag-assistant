[site]: crossvalidated
[post_id]: 471912
[parent_id]: 471867
[tags]: 
Savage has a result about any procedure for making decisions under uncertainty that satisfied a set of reasonable-looking conditions including coherence. He showed it implied the existence of finitely-additive beliefs over events and linear utilities over states of nature. There's a description here If you have well-defined priors over everything in the world I don't think it's controversial that you would update them using Bayes' Theorem, so this gets basically at the same point that non-Bayesian inference must fail to be coherent. The 'Dutch Book' argument is related but slightly different: it says that if you identify degrees of belief in uncertain statements with willingness to take certain bets, and if the degrees of belief aren't Bayesian probabilities, someone can find a set of bets you will accept that has negative value with probability 1 and take all your money. The problem with the Dutch Book argument is that it assumes everyone should always be willing to take one or other side of every offered bet. Since they clearly aren't , the claim that they rationally must be is a hard sell, and one can argue that the whole problem is an artifact of identifying degrees of belief with willingness to bet. That's combined with the lack of any real evidence that frequentists are subject to Dutch Book tricks to siphon away all their money. If you regard the betting part of the argument as just a metaphor and not really about betting or money you are basically back at Savage's argument. Savage's argument is, I think, regarded as more persuasive, at least in an ideal sense. The reason it doesn't convince people that Bayesian statistics is the only way in practice, is that it assumes you are already able to make coherent decisions over all possible events (in order to have coherent priors). In that case you wouldn't need Bayesian statistics, you'd naturally just update your beliefs properly. Perfectly rational beings would automatically be Bayesian, but it doesn't necessarily follow that the best strategy for imperfect humans is to try to do formal Bayesian inference. It's a plausible supporting argument, but the proof isn't as airtight as people sometimes argue.
