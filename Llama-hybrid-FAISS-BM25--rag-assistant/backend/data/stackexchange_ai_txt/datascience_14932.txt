[site]: datascience
[post_id]: 14932
[parent_id]: 
[tags]: 
Neural network accuracy in Torch depends on compute power?

I am new to machine learning and have quite good understanding of basic concepts. I was implementing a 3 Layer neural network on MNIST dataset with 784, 100, 10 neurons in input, hidden, output layer respectively. I did not use any regularization here. Firstly I trained the network on Intel i5 4th generation quad-core CPU with 4GB of ram which gave me 64% of accuracy. Then I trained the exact same network, with exact same code on Intel i5 7th generation quad core CPU with 8gb of ram which gave accuracy of about 89% This is the link to the implementation . My question is in Torch, does the compute power effect the accuracy of the network? or is it something else that I am missing which has resulted in this huge change. I did not use any different weight initialization method than the default provided in the torch libraries, so that is ruled out. I also did not use anything else which may effect the network to change its accuracy to this extent.
