[site]: crossvalidated
[post_id]: 571994
[parent_id]: 571716
[tags]: 
I got the answer where I am going wrong. The biggest culprit was the formula for calculating accuracy. In numerous places [ 1 , 2 , 3 ] it is written that the formula for accuracy is $Accuracy = \frac{TP+TN}{TP+FP+TN+FN}\tag{1}$ but the catch is that this formula holds true for binary classification systems only. A better formulation for calculating accuracy of the system over all classes should be as follows: $Accuracy =\frac{\sum_{i}^{C}{TP_i}}{|Dataset|} \tag{2}$ where $C$ is the number of classes. In simple words, accuracy is obtained by diving sum of True Positives over all classes with the length of dataset. Some properties of binary classification system are: TPs of class 0 is same as TNs of class 1 and vice versa. Sum of TP, FP, TN, and FN (of either class) equals to the length of dataset. Hence equation $(1)$ is a specialized case of equation $(2)$ applicable for binary classification system only. This derivation applies to binary classification system only. Equation $(2)$ also satisfies the original question: "Why sklearn shows accuracy in place of micro-average F1?" or "Why micro-average F1 equals to accuracy equals to micro-average precision equals to micro-average recall?" (as stated by this blog post). We know that equation of F1 is $\frac{2*precision*recall}{precision+recall}$ substituting the values of precision and recall we get $F1 = \frac{TP}{TP+\frac{1}{2}(FP+FN)}$ then micro-average F1 is simply $\frac{\sum_{i}^{C}{TP_i}}{\sum_{i}^{C}{TP_i}+\frac{1}{2}(\sum_{i}^{C}{FP_i}+\sum_{i}^{C}{FN_i})}\tag{3}$ Since in any confusion matrix for C classes, $\sum_{i}^{C}{FP_i}$ will be the sum of all non-diagonal elements (vertically), as shown in figure below. Moreover, $\sum_{i}^{C}{FN_i}$ will also be the sum of all non-diagonal elements (horizontally), as shown in figure below. As you can see, both $\sum_{i}^{C}{FP_i}$ and $\sum_{i}^{C}{FN_i}$ are summing the same terms but with different ways. Hence, $\sum_{i}^{C}{FP_i} = \sum_{i}^{C}{FN_i}$ . Therefore micro-average precision, micro-average recall, and micro-average F1 all are identical. And putting $\sum_{i}^{C}{FP_i} = \sum_{i}^{C}{FN_i}$ in equation $(3)$ , we get micro average F1 = $\frac{\sum_{i}^{C}{TP_i}}{\sum_{i}^{C}{TP_i}+\sum_{i}^{C}{FP_i}} = \frac{sum\ of\ diagonals}{sum\ of\ diagonals + sum\ of\ non-diagonals} = \frac{\sum_{i}^{C}{TP_i}}{|Dataset|}$ Hence Micro-average F1 = Accuracy = Micro-average precision = Micro-average recall
