[site]: datascience
[post_id]: 120634
[parent_id]: 117920
[tags]: 
Could you treat this like a classification problem? As in, assume that the concepts have subclasses and consider texts to be similar if they are in the same class? It's hard to pin down specific concepts in an embedding space. The dimensions are effectively meaningless, but you can get some information by comparing embeddings with other embeddings in the space. The Euclidean properties of an embedding space do sometimes hold information about specific concepts; like the classic example in word embeddings where ('King' - 'Man' + 'Woman') â‰ˆ 'Queen' suggests that the vector ('King' - 'Queen') is something like a masculine/feminine axis. But this is oversimplified, because the words King and Queen aren't used in identical contexts, so the difference in their meaning isn't just a single concept.
