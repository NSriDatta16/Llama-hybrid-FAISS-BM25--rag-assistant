[site]: crossvalidated
[post_id]: 381498
[parent_id]: 
[tags]: 
Error in the standard deviation when simulating an ARMA(1,1) using arima.sim

I'm trying to simulate an ARMA(1,1) process whose autoregressive and moving average parameters are, respectively, 0.74 and 0.47. Moreover, I want the simulated data to have mean equal 900 and standard deviation equal to 230. To accomplish this, I tried set.seed(100) fit = arima.sim(list(order = c(1,0,1), ar = 0.74, ma = 0.47), n = 10000, rand.gen= rnorm, sd = 230) + 900 The mean of the synthetic time series is acceptable. mean(fit) #922.749 However, when I calculate the standard deviation, the difference between the calculated value and the one I stipulated as the standard deviation for fit is too large. sd(fit) #511.3077 - almost two times higher than the value I thought I'd observe How can I change my code to make sure the simulated series will have a standard deviation close to the one I stipulate inside the arima.sim function?
