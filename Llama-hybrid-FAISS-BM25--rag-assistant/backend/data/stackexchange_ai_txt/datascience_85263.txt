[site]: datascience
[post_id]: 85263
[parent_id]: 84202
[tags]: 
When you use buckets you lose some information. Basically you assume the relationship between the variable and the target is flat within the interval. When this is probably not the case. This is point #3 on Frank Harell's list of reasons why you generally shouldn't categorise at all. More specifically, 80% of your instances seems to be in one bucket. That mean your algo can't learn what happen inside this bucket. As a starting point you may use more buckets to check if that was the problem . More convoluted techniques would include splines to smooth the response (removing noise help not learning from it). Honestly given that you work with a tree like algo (Xgboost) you should probably let it choose optimal splits instead of enforcing some splits trough variable categorisation. That is : don't use a priori variable categorisation at all , enforce the absence of overfitting trough other parameters (tree depht at least) and if you really need category use those found by the algo. Edit: re-reading your question it seems that you are overfitting in both case... the solution might be more about tuning your xgboost parameters.
