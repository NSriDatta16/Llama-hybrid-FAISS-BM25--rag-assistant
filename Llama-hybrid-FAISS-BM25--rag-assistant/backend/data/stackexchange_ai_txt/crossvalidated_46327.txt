[site]: crossvalidated
[post_id]: 46327
[parent_id]: 
[tags]: 
Time series forecasting lookback windows -- sliding or growing?

Are there any good reasons to prefer a sliding model training window to a growing window in online time series forecasting (or vice versa)? I'm particularly referring to financial time series. I would intuitively think a sliding window should perform worse -- out of sample-- as it is has more potential for over-fitting specific sample window characteristics, but some of the empirical results I've seen are counter to this. Also, given that a sliding window is preferred by some, what would your approach be to determine the look-back length (any good reasons to prefer one over another, aside from pure heuristics)? Although I didn't specify a model, an example might be ARIMA. EDIT: I should add there there is a related blog post by By. Rob Hyndman, with what he dubbed 'time-series' cross validation. While it does cover the concepts described, it doesn't give much of a formal reason about why one method might be preferential over the other, nor any ideas about an optimal look-back window parameter.
