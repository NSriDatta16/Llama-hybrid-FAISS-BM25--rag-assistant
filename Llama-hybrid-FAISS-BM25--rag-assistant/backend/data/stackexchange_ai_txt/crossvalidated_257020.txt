[site]: crossvalidated
[post_id]: 257020
[parent_id]: 
[tags]: 
Sentence sampling based on frequency

I have a database with 300k+ Russian sentences and their English translation. My goal is to use these sentences as flashcards, so the users can learn the top N most frequent Russian words (let's assume N = 10k). A requirement is that the easiest sentences are shown first, and more complex sentences get slowly introduced as you progress. The notion of easy/complex relates only to word frequency and maybe sentence size to break ties. I thought on doing the following: Get the word frequency from the entire corpus Rate each sentence What's a good and simple way to achieve step 2? A simple average would work, or it's better to multiply each word frequency? I appreciate any suggestions on this, thanks! Note Since Russian has declensions (noums/adjectives/pronoums change their endings according to grammatical function), that bring's another problem, but maybe I could ignore it.
