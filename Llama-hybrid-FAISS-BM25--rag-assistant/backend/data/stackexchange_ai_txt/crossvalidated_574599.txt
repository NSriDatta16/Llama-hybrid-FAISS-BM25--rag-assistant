[site]: crossvalidated
[post_id]: 574599
[parent_id]: 
[tags]: 
weighted maximum likelihood as loss function

I have built a little neural network that I use for regression. import tensorflow as tf from tensorflow.keras.layers import Dropout from tensorflow.keras.layers import Input from tensorflow.keras.layers import Dense from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam import tensorflow_probability as tfp def NLL(y, distr): return -distr.log_prob(y) def normal_exp(params): return tfd.Normal(loc=params[:,0:1], scale=tf.math.exp(params[:,1:2]))# both parameters are learnable def modelcov(): inputs = Input(shape=(1,)) hidden = Dense(200,activation="relu")(inputs) hidden = Dropout(0.1)(hidden, training=True) hidden = Dense(200,activation="relu")(hidden) hidden = Dropout(0.1)(hidden, training=True) hidden = Dense(200,activation="relu")(hidden) hidden = Dropout(0.1)(hidden, training=True) params_mc = Dense(2)(hidden) dist_mc = tfp.layers.DistributionLambda(normal_exp, name='normal_exp')(params_mc) modello = Model(inputs=inputs, outputs=dist_mc) return modello where the last layer produce a realization from a normal distribution. The problem is that my dataset (x,y,y_std) cointains the errors y_std on the measured values of y. Since data with bigger errors contains less information, I was wondering if from the statistical point of view made sense to set sample_weight= 1/y_std**2 in the compile method so that the neural network would use a weighted maximum likelihood estimator, rather than the simple MLE test = modelcov() test.compile(Adam(learning_rate=0.004), loss=NLL) storia = test.fit(x,y,sample_weight=1/y_std**2, epochs=5000,verbose=0,batch_size=128) Is it correct in the Bayesian framework to use the square of the inverse of the uncertainties on the measurements y as weights for the loss function ?
