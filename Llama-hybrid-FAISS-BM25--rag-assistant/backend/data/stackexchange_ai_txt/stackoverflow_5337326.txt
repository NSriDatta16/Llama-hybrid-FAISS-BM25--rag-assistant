[site]: stackoverflow
[post_id]: 5337326
[parent_id]: 
[tags]: 
Matrix operations in CUDA

What is the best way to organize matrix operations in CUDA (in terms of performance)? For example, I want to calculate C * C^(-1) * B^T + C , C and B are matrices. Should I write separate functions for multiplication, transposition and so on or write one function for the whole expression? Which way is the fastest?
