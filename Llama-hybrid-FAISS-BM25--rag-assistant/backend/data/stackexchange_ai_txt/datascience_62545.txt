[site]: datascience
[post_id]: 62545
[parent_id]: 62538
[tags]: 
Text data is at the same time: very structured, because swapping only a few words in a sentence can make it complete gibberish, and very flexible, because there are usually many ways to express the same idea in a sentence. As a consequence, it's very hard to have a text sample which is representative enough of a "population" text, i.e. which covers enough cases for all the possible inputs. But augmentation methods are practically sure to fail, because either they are going to make the text gibberish or just cover minor variations which don't improve the coverage significantly. That's why a lot of the work in NLP is about experimental design and preprocessing.
