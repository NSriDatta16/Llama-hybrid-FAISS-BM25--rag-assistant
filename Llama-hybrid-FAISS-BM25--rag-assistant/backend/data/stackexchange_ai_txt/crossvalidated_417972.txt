[site]: crossvalidated
[post_id]: 417972
[parent_id]: 417835
[tags]: 
Complementary podludek's nice answer (+1). We cannot state that the most important features for the XGboost algorithm are also the most important for the training of the DNN. This is not only because our models might be dissimilar in terms of their structure (e.g. a gradient boosting model vs. a convolutional neural network) but also because: 1. they might be dissimilar in terms of the metric they optimise against (e.g. cross-entropy vs AUC) and 2. the feature importance method used might encapsulate different dynamics (e.g. SHAP values vs permutation importance). Finally, I would draw attention to why the task of assigning feature importance is performed to begin with. If we do it so we can just focus on certain variables, that is mostly likely problematic approach. Overall model performance can be harmed when focusing exclusively on "important features". Using methods that employ regularisation within their fitting procedure (e.g. like Gradient Boosting Machines) is preferable to the complete exclusion of certain variables to the expense of others. On the other hand, if it is done as a sanity check to identify potential data leakage issues, or to recognise potentially expensive to acquire but low-contributing variables, or present to a layman audience the main drivers behind a model; it is a reasonable thing to do.
