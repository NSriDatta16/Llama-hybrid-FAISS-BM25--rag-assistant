[site]: datascience
[post_id]: 10051
[parent_id]: 10047
[tags]: 
No , he actually says the opposite: One final note: I should say that in the machine learning as of this practice today, there are many people that will do that early thing that I talked about, and said that, you know...â€‹ Then he says (the "early thing" he talked about): selecting your model as a test set and then using the same test set to report the error ... unfortunately many people do that In this lesson he explains about separating the data set: training set to train the model; cross validation set to find the right parameters; test set to find the final generalization error (of the function with the best parameter values found during using the cross validation set ). So Andrew Ng is complaining that many people us the same data set to find the right parameters, and then report the error of that data set as final generalization error .
