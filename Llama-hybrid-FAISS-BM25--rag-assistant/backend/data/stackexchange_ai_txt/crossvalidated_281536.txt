[site]: crossvalidated
[post_id]: 281536
[parent_id]: 281524
[tags]: 
A regression model must include an error term in order to make sense \begin{equation} b_i = \alpha \cdot x_i + \epsilon _i \end{equation} Otherwise, you can't mathematically find a single $\alpha$ that works for all combinations of $(x_i, b_i)$. This is relevant because now it's clearer why your second approach might not work so well: by suggesting that \begin{equation} E[b_{i+1}] = \alpha \cdot x_{i+1} = \dfrac{b_i}{x_i} \cdot x_{i+1} \end{equation} you are ignoring the error term $\epsilon _i$: \begin{align} b_i &= \alpha \cdot x_i + \epsilon _i \\ &\neq \alpha \cdot x_i \end{align} The average of all error terms must be zero, yes, but any particular $\epsilon _i$ can be arbitrarily large (which would happen if the pair $(x_i, b_i)$ were an outlier) In other words, the model parameter $\alpha$ contains information about all $N$ $(x_i, b_i)$ pairs. In estimating $E[b_{i+1}]$ using only the information from $(x_i, b_i)$, you are ignoring the information that the pairs $(x_j, b_j) _{j \neq i}$ contain. As an example, consider your original example: \begin{align} X_{LV} &= (1, 2, 4, 5, 6, 8, 10, 11, 15, 20, 30) \\ B_{LV} &= (2, 4, 8, 11, 12, 15, 19, 22, 31, 40) \end{align} Doing the math on the first $N = 10$ elements of both vectors, $\alpha _{LV} = 2.01 \pm 0.08$. You would like to predict the next element in $B_{LV}$, so \begin{align} E[b_{LV, 11}] &= \alpha _{LV} \cdot x_{LV, 11} \\ &= 60.06 \end{align} Using your proposed alternative, we get \begin{align} E'[b_{LV, 11}] &= \dfrac{b_{LV,10}}{x_{LV,10}} \cdot x_{LV, 11} \\ &= 60.0 \end{align} which represents a $0.1\%$ difference. However, if we run the regression on these series instead \begin{align} X_{HV} &= (1, 2, 4, 5, 6, 8, 10, 11, 15, 20, 30) \\ B_{HV} &= (2, 4, 8, 11, 12, 15, 19, 22, 21, 47) \end{align} then we would get an $\alpha _{HV} = 2.0 \pm 0.4$. Note that the slope has a lot more variance in the high variance case. To predict $b_{HV, 11}$ we calculate \begin{align} E[b_{HV, 11}] &= \alpha _{HV} \cdot x_{HV, 11} \\ &= 59.76 \end{align} Your proposed alternative, however, yields \begin{align} E'[b_{HV, 11}] &= \dfrac{b_{HV,10}}{x_{HV,10}} \cdot x_{HV, 11} \\ &= 70.5 \end{align} which represents a much larger $18\%$ difference. This happens because the pair $(x_{HV,10}, b_{HV,10})$ is an outlier: In other words, $\alpha _{HV}$ has information on all $(x_{HV, i}, b_{HV,i}) _{i \in [1\ldots 10]}$ pairs, which results in much better predictions. In contrast, the alternative amplifies any errors present in the $(x_{HV, 10}, b_{HV,10})$ pair.
