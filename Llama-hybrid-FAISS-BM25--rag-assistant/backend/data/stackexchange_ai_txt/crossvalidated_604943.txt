[site]: crossvalidated
[post_id]: 604943
[parent_id]: 604319
[tags]: 
Writing the density of $X$ as $f_X(x)$ and the conditional density of $Y| X=x$ as $f_{Y|x}(y|x)$ we find the joint density as $$ \frac{{\mathrm e}^{\frac{-\left(-x +\mu \right)^{2} \theta^{2} x^{2}-y^{2} \sigma^{2}}{2 \sigma^{2} \theta^{2} x^{2}}}}{2 \sigma \pi \theta {| x |}} $$ which I cannot recognize as a known distribution. We can try to find the density of $Z=X+Y$ by transformation to $(Z=X+Y, Y)$ (which have a jacobian of 1) and then integrating out $y$ , I find the joint density of $(Z,Y)$ to be $$ \frac{{\mathrm e}^{\frac{-\left(-z +y +\mu \right)^{2} \left(-z +y \right)^{2} \theta^{2}-y^{2} \sigma^{2}}{2 \sigma^{2} \left(-z +y \right)^{2} \theta^{2}}}}{2 \sigma \pi \theta {| -z +y |}} $$ but trying to integrate out $y$ does not give a closed form: $$ \int_{-\infty}^{\infty}\frac{{\mathrm e}^{\frac{-\left(-z +y +\mu \right)^{2} \left(-z +y \right)^{2} \theta^{2}-y^{2} \sigma^{2}}{2 \sigma^{2} \left(-z +y \right)^{2} \theta^{2}}}}{2 \sigma \pi \theta {| -z +y |}}d y $$ but you could use this expression for finding the likelihood via numerical integration. See Parameter Estimation for intractable Likelihoods / Alternatives to approximate Bayesian computation for other ideas for intractable likelihoods. Another idea is to calculate the moment generating function, which do have a closed form. It can be found relatively easily via the double expectation theorem (again I jump the details, I did those with maple): $$ \DeclareMathOperator{\E}{\mathbb{E}} M_Z(t)= \E e^{tZ} = \frac{\exp\left\{ -\frac{t(\mu^2 t \theta^2+\sigma^2 t + 2\mu)}{2(\sigma^2 t^2 \theta^2 -1)} \right\}}{\sqrt{1-\sigma^2 t^2 \theta^2}} $$ which is valid as long as the argument of the square root is positive, which is for $t^2 . Then we can use the saddlepoint approximation, see How does saddlepoint approximation work? , as an approximate likelihood function. Out of time now, will add details later.
