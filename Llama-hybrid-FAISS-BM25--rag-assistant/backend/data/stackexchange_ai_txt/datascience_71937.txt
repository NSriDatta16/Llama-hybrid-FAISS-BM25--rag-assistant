[site]: datascience
[post_id]: 71937
[parent_id]: 13977
[tags]: 
I know this is a 4-year old question but anyway. If you are using Keras there's a parameter called loss_weights= in the model compile method. So if you have output_1 and output_2 and output_1 converges first you can try loss_weights=[0.2, 0.8] . IIRC the default loss in Keras is the sum of loss for outputs, not average, so here I've also normalized the loss so it is comparable across models with variable numbers of outputs (e.g. if you want to use standard values for learning rates but those are for models with single outputs and you have a hundred outputs).
