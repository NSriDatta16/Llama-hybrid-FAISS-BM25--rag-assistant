[site]: crossvalidated
[post_id]: 401676
[parent_id]: 
[tags]: 
What autoencoder architectures are effective for large images?

I've had easy success in the past making autoencoders for small images using necked down dense networks, but my new application has images of ~1M pixels, which is impractical to address (I think) with a flattened image. I've experimented with convolutional approaches where I use convolution and pooling layers, then upsampling/deconvolution to come back, but have had no real success. Upon thinking about it, there seems to be a fundamental problem in that the pooling layers, by nature, throw away spatial information that can never be retrieved. Are there architectures that can manage large images without losing spatial location information? In my application, the relevant information in the image is sparse, but location is critical.
