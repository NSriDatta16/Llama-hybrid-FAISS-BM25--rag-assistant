[site]: crossvalidated
[post_id]: 245417
[parent_id]: 
[tags]: 
Making sense of a small data set

I have a small data set for a binary classification problem, with N_0=18 and N_1=11 instances in 0 and 1 classes respectively. The problem is how to make sense of the classification procedure with this tiny data set and assess the classification quality. I compared a simple cross validated logistic regression to the dummy baseline classifier which always predicts the most prevalent class (0). Here is my code (Python with scikit-learn v0.18) >> from sklearn.model_selection import GridSearchCV >> from sklearn.linear_model import LogisticRegression >> from sklearn.model_selection import StratifiedShuffleSplit >> from sklearn.dummy import DummyClassifier >> sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2) >> parameters = {'clf__C': logspace(-4,2,100)} >> pipe_logistic = Pipeline([('scl', StandardScaler()),('clf', LogisticRegression(class_weight='balanced'))]) >> grid_search = GridSearchCV(estimator=pipe_logistic, param_grid=parameters, verbose=1, scoring='f1', cv=sss) >> clf_dummy = DummyClassifier(strategy='most_frequent',random_state=0) >> grid_search.fit(df[['f_1','f_2']], df['label']) >> clf_dummy.fit(df[['f_1','f_2']], df['label']) >> grid_search.score(df[['f_1','f_2']], y) >> 0.63636363636363635 >> print confusion_matrix(y,grid_search.predict(df[['f_1','f_2']])) >> array([[14, 4], [ 4, 7]]) >> clf_dummy.score(df[['f_1','f_2']], y) >> 0.62068965517241381 >> confusion_matrix(y,clf_dummy.predict(df[['f_1','f_2']])) >> array([[18, 0], [11, 0]]) >> print classification_report(y, grid_search.predict(df[['f_1','f_2']])) precision recall f1-score support 0 0.78 0.78 0.78 18 1 0.64 0.64 0.64 11 avg / total 0.72 0.72 0.72 29 >> print classification_report(y, clf_dummy.predict(df[['f_1','f_2']])) precision recall f1-score support 0 0.62 1.00 0.77 18 1 0.00 0.00 0.00 11 avg / total 0.39 0.62 0.48 29 Obviously, the logistic regression does better (f1 score), but their accuracies are almost the same. Here is the data I used for classification: >> print df f_1 f_2 label 0 11.0 0.5 0 1 6.0 0.0 0 2 11.0 8.0 0 3 9.0 4.5 0 4 6.0 0.5 0 5 15.0 0.5 0 6 69.0 18.0 0 7 3.0 0.5 0 8 39.0 18.0 0 9 2.0 0.0 0 10 1.0 0.0 0 11 25.0 8.0 0 12 7.0 2.0 0 13 8.0 0.0 0 14 6.0 0.5 0 15 5.0 2.0 0 16 2.0 0.0 0 17 5.0 2.0 0 18 31.0 0.0 1 19 11.0 0.5 1 20 26.0 4.5 1 21 37.0 0.5 1 22 8.0 0.0 1 23 39.0 2.0 1 24 9.0 2.0 1 25 59.0 2.0 1 26 0.0 0.0 1 27 3.0 0.0 1 28 3.0 0.5 1 Question: How to report my classification results? The accuracy of the logistic regression is almost the same as a dummy classifier, while its f1 score is singnificantly better (0.72 vs. 0.48). Should I do a nested cross validation, in order to better estimate the classification metrics? What is the best practice to work with this small data set and report correct classification results? Classes: Red - 0, Blue - 1
