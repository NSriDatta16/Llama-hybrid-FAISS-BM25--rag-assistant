[site]: crossvalidated
[post_id]: 524817
[parent_id]: 143705
[tags]: 
Let's derive the equivalence through the Bayesian/PGM approach. Here is the Bayesian network of linear regression: We can factorize the joint distribution according to the above graph $\mathcal{G'}$ : $$P(y, w, X) = P(y|w, X)P(w)P(X)$$ Since the $P(X)$ is fixed we obtain this: $$P(y, w, X) \propto P(y|w, X)P(w)$$ Since maximum likelihood is a frequentist term and from the perspective of Bayesian inference a special case of maximum a posterior estimation that assumes a uniform prior distribution of the parameters. Then we just ignore $P(w)$ . Then we get this: $P(y, w, X) \propto P(y|w, X)$ , and we assume $P(y|w, X)=\mathcal{N}(y|w^TX, \sigma^2I)$ due to the normal residuals assumption. Alone the same line in this answer we see that the least square method is equivalent to the meximum likelihood method in your case.
