[site]: crossvalidated
[post_id]: 511363
[parent_id]: 446102
[tags]: 
You are evaluating model performance using the OOB misclassification error, which is sensitive to accuracy of classifications only. However, the trees in the forest are constructed by optimizing the Gini index, which is sensitive to the accuracy of predicted probabilities. Your results suggest that several pairs of variables can be used to obtain the same classification accuracy. However, the importances based on the Gini index (which are based on training, not on OOB eror), suggest that the variables with higher importances may contribute additional accuracy for predicting probabilities. Because the default in classification random forests is to get predictions from every tree in the form of class labels, and the final prediction being a majority vote or the proportion of trees predicting each of the classes, the predicted values of the random forest are good at classification, but are not good estimators of probability.
