[site]: crossvalidated
[post_id]: 103328
[parent_id]: 
[tags]: 
When forecasting sequential data is it best to use auto-regressive models or build a more traditional n x p dataset with features?

I'm familiar with the use of auto-regressive models when it comes to forecasting a single vector of time-series data. Is anybody familiar with a more traditional modeling approach, i.e. - creating sets of features such as indicators for day of the week, time of the day, day of the month, holiday, and then running a model such as a regression or random forest on this? Are there pros/cons to each of these methods? I'm basically tasked with forecasting hourly requests based on A LOT of historical data. There are strong intraday trends as well as pretty strong weekly trends. So far we have been using the average of the past 4 data points of the same hour in the same day (so for this Friday at 4 PM we would average the last 4 Friday's counts at 4 PM) and this works surprisingly well. Is it even worth building a more sophisticated model? Would I have to continually retrain it between every hour or would a few months worth of this hourly data be enough to forecast for several days before retraining? I'm sure I left some questions out so any suggestions and literature you could point me to would be much appreciated.
