[site]: crossvalidated
[post_id]: 90091
[parent_id]: 79371
[tags]: 
The most valid way of doing this is inferring that if the p-value on the subsample is significant, then it's consistent with a difference in the same population that the full sample would have inferred. E.g. p Barring that, there are two representation rules that allow you to use a subsample to infer results from a larger population, given you can first incorporate data from the larger sample. These are matching and weighting. These are extremely contextually driven. Those methods in particular usually have to do with sampling individuals from a larger cohort of eligible subjects for whom some expensive assay for exposure or outcome cannot be applied across. I don't think I've ever encountered the case where weighting/matching was motivated by the complexity of the proposed analyses (usually large data => simple analyses like GEE). You could simplify your analyses greatly by rewriting the estimation routine as an estimating equation or an objective function and then linearizing it to come up with a simple estimation rule. You can derive an influence function and, probably, show that results go to normal distributions by CLT, they have asymptotically consistent standard error estimates, and you get simple estimators... not intractable integrals that need sophisticated MCMC routines to be solved.
