[site]: crossvalidated
[post_id]: 486770
[parent_id]: 
[tags]: 
Why do distances to hyperplane increase with more training samples in a One-Class SVM?

I am using a One-Class SVM from for anomaly detection. I observe that the distance of classified samples increases roughly proportional with the number of training samples . This is true for inliers and outliers. I am using sklearn.svm.OneClassSVM.decision_function() to get the signed distance to the hyperplane. On the following image you can see on the x-axis that the distance of e.g. the leftmost orange cluster increases, the more training samples are used: I tried various, kernels, gammas, and nus and always observe the increase in distance. I studied the theory of SVM's for almost two days but didn't find any explanation in the math. The only suspect that I have are the Lagrange multipliers that maybe change the output of the distance function somehow and are not normalized for the number of samples. The change in distance does not make sense to me, because the hyperplane should move around between the samples during training but the samples never move themselves and therefore can not move away from the hyperplane. So how can the distance of outliers and inliers increase at the same time?
