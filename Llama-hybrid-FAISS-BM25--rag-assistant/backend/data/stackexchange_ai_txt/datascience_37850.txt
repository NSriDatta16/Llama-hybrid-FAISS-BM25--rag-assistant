[site]: datascience
[post_id]: 37850
[parent_id]: 37832
[tags]: 
I'm assuming you're taking a certain neural net (NN) architecture and doing a train/test/validate cycle on dataset A to get 90% accuracy, then you reset your parameters and train/test/validate on dataset B to get 70% accuracy To expand what @mohit-motwani says: There does not exist a machine learning model that will approximate all functions to any desired degree. By corollary, there is no single neural net architecture that will best fit any given data. Try tweaking various hyperparameters and see if that helps. Activation functions, convolution size, padding, pooling, even a few more/less hidden layers can drastically change your results. NNs have been getting a lot of praise lately as "automated learning machines" but in reality, you still have to know the theory behind them, and what's under the hood to fully appreciate how they work. You'll get better with experience, but don't think any one NN architecture is "best"
