[site]: crossvalidated
[post_id]: 393176
[parent_id]: 
[tags]: 
Interpretation of spectral entropy of a timeseries

The tsfeatures package for R has an entropy() function. The vignette for the package describes it as: The spectral entropy is the Shannon entropy $$-\int_{\pi}^{\pi} \hat{f}(\lambda)\log\hat{f}(\lambda) d\lambda$$ where $\hat{f}(\lambda)$ is an estimate of the spectral density of the data. This measures the “forecastability” of a time series, where low values indicate a high signal-to-noise ratio, and large values occur when a series is difficult to forecast. The documentation for the ForeCA::spectral_entropy() which is used by entropy() function suggests the density is calculated such that $$\int_{-\pi}^{\pi} f_x(\lambda) d\lambda = 1$$ . I'm wondering what the most accurate interpretation of this calculated quantity is (I'm sure there's a good reason why 'forecastability' is in quotation marks). I've got a suspicion it's based on a narrow interpretation of what is forecastable. Is it correct in saying that the spectral density is obtained using a (discrete?) Fourier transform on the time-series? Would it be more accurate to say that this calculation measures 'forecastability' by testing whether the time series is a linear combination of signals at different frequencies and at different levels of power? What other assumptions are made? Surely this measure has very limited ability to account for path dependence and other complex/non-linear behavior which may or may not be forecastable given a sophisticated understanding and model?
