[site]: crossvalidated
[post_id]: 622606
[parent_id]: 622578
[tags]: 
If you know the width of the moving average window, you can undo a lot of the damage done by the construction of rolling means. Let the window width be denoted by $L$ . Forming a new target variable $y^*_t$ by differencing the existing one ( $y^*_t = y_t - y_{t-1}$ ) greatly reduces the correlation in the target variable. This constructs the series we would have seen had we a) had the original data, say $w_t$ , and b) differenced it at $L$ periods: $y^*_t = w_t - w_{t-L}$ . We then difference the right hand side variable(s) $x_t$ with lag $L$ to form $x^*_t = x_t - x_{t-L}$ ; this allows us to run a regression on relatively uncorrelated target variables with the time indices and differencing aligned. An example in R follows: First, we construct the data: library(data.table) x_orig The initial observations in y are filled with NA values, so, at this point, y , y_orig , and x_orig all have the same number of observations. Note that the observations for x_orig line up with the rolling mean of y_orig through the same time period - the rolling means are right-aligned, in the parlance of the function we've used. The relationship between the original $y$ and $x$ values looks like: ... but the relationship between the rolling mean and the $x$ values looks like: We now execute the procedure described above: y |t|) (Intercept) 0.01364 0.10536 0.13 0.897 dx 0.95952 0.04969 19.31 As we can see, the coefficient estimate for dx is almost the same as the true value of 1.0. However, we can do better than this by taking into account the remaining autocorrelation in the data. Let's look at an autocorrelation plot of the residuals from the regression: As we can see, there is some autocorrelation at a lag of 7 periods, which corresponds to our window width $L=7$ . The arima function enables us to run a regression taking this into account: arima_regr In this case, the coefficient estimates and their standard errors did not change much, except for the standard error of the intercept. I would expect this to be the case for $L$ small relative to the total number of observations, as it is here, and, if so, it may not be worth building the arima model at all.
