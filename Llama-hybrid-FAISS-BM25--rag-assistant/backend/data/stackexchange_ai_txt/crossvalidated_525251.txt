[site]: crossvalidated
[post_id]: 525251
[parent_id]: 
[tags]: 
Ordinary least squares input - provide average and uncertainty vs all data

Assume any linear model (sth like this): $y=a*x + c + \epsilon$ And some measurements $Y$ for a set of fixed points $x\in{[1,2,3,..]}$ where there are multiple measurements $y_i$ for a given point in $x$ , i.e. for $x=1$ there are $y$ values [1,2,3..] and so on. Does it matter for the least squares algorithm, whether I provide the the measurement data $Y$ as $\mu+-\sigma$ for each $y_i$ compared to providing the measurements directly? My minimal example shows slight differences but (probably because its too simple) I dont know if this is based on how the solver handles the data input or due to different assumptions between providing the full data and Âµ+sd. Since this is my first question here, I would also appreciate you commenting how I should improve the questioning style in the future! Minimal example: from scipy.optimize import leastsq import numpy as np def residual(variables, x, data, eps_data): """fit model to data""" m = variables[0] b = variables[1] model = m*x+b return (data-model) / eps_data # generate synthetic data with noise x = np.array([1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3]) np.random.seed(0) y = x*2 + 0.5 + np.random.normal(0,0.1, len(x)) # fit data to linear model variables = [1.0,1.0] eps_data = np.ones_like(x) out1 = leastsq(residual, variables, args=(x, y, eps_data)) print(out1) # do the same fit but using avg + sd as input y_sd = np.array([np.std(y[:6]), np.std(y[6:12]),np.std(y[12:18])]) y_avg = np.array([np.mean(y[:6]), np.mean(y[6:12]), np.mean(y[12:18])]) x_avg = np.array([1.0,2.0,3.0]) out2 = leastsq(residual, variables, args=(x_avg, y_avg, y_sd)) print(out2) ```
