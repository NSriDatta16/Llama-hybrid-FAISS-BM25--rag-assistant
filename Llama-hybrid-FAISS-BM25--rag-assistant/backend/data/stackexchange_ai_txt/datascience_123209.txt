[site]: datascience
[post_id]: 123209
[parent_id]: 
[tags]: 
Create a TensorFlow Input pipeline from GCS Bucket?

I wish to generate a TensorFlow input pipeline (i.e. tf.data pipeline) for an image classification project. The images stored in a GCS bucket having access controls and is not publicly accessible . And making it publicly accessible is not allowed by the Project Admin. My service account has the required IAM Roles (but not Storage Admin) and I can access the bucket content using the Storage API (i.e. google.cloud.storage Python API). Also, I can authenticate my credentials using the google.oauth2.service_account Python API. For your reference: CODE that I tried : img_dataset = tf.data.Dataset.list_files( file_pattern="gs://"+GCS_BUCKET_NAME+"/dataset/train" ) ERROR that I got : PermissionDeniedError Traceback (most recent call last) in () ----> 1 img_dataset = tf.data.Dataset.list_files( 2 file_pattern="gs://"+GCS_BUCKET_NAME+"/dataset/train" 3 ) 2 frames /usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name) 7260 def raise_from_not_ok_status(e, name): 7261 e.message += (" name: " + name if name is not None else "") -> 7262 raise core._status_to_exception(e) from None # pylint: disable=protected-access 7263 7264 PermissionDeniedError: {{function_node __wrapped__MatchingFiles_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error executing an HTTP request: HTTP response code 401 with body '{ "error": { "code": 401, "message": "Anonymous caller does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist).", "errors": [ { "message": "Anonymous caller does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist).", "domain": "global", "reason": "required", ' when reading gs://GCS_BUCKET_NAME/dataset [Op:MatchingFiles] Is there a way that I can use the service account credentials (as JSON file) to gain access and then create the tf.data input pipeline? Thanks in advance.
