[site]: crossvalidated
[post_id]: 227173
[parent_id]: 
[tags]: 
Scalable dimension reduction

Considering the number of features constant, Barnes-Hut t-SNE has a complexity of $O(n\log n)$, random projections and PCA have a complexity of $O(n)$ making them "affordable" for very large data sets. On the other hand, methods relying on Multidimensional scaling have a $O(n^2)$ complexity. Are there other dimension reduction techniques (apart from trivial ones, like looking at the first $k$ columns, of course) whose complexity is lower than $O(n\log n)$ ?
