[site]: crossvalidated
[post_id]: 412809
[parent_id]: 
[tags]: 
Practical Examples: Expectation of a function with respect to a probability

I have encountered the following phrasing while reading Bishop's " Pattern Recognition and Machine Learning ": Although for some applications the posterior distribution over unobserved variables will be of direct interest in itself, for most situations the posterior distribution is required primarily for the purpose of evaluating expectations , for example in order to make predictions. As I know from Neural Networks, you usually want the posterior for predictions. Therefore I don't understand what the use-case for evaluating expectations would be. If you could please help me with a couple of practical examples for where one would decide to compute expectations of functions with respect to a probability or redirect me to an explanation, I would be very thankful.
