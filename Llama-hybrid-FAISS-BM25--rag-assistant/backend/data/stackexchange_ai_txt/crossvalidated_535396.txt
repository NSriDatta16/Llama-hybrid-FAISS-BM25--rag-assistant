[site]: crossvalidated
[post_id]: 535396
[parent_id]: 534165
[tags]: 
The setup seems to imply that $(\theta_1,\ldots\theta_M)$ are only sampled once. $\theta_x$ for given $x$ will always be the same regardless of $n$ . There is no $\theta^*_x$ different from the original $\theta_x$ . Note that there is a certain confusion of notation between random variables and their realisations (which is often found in Bayesian notation). I denote by $\tilde\theta_x$ the random variable (over which the prior is defined) that has taken the value $\theta_x$ . In fact, $E(\hat y^{n+1}|\tilde\theta_x=\theta_x)=\theta_x$ . Now we don't know $\theta_x$ at this point, but we know what we expect it to be: $E(\hat y^{n+1}|\mathcal{F}^n)=E_n(\tilde\theta_x)=\mu_x^n$ (it looks like you use $x=x^n$ for ease of notation), therefore $E(\hat y^{n+1}-\mu_x|\mathcal{F}^n)=0$ .
