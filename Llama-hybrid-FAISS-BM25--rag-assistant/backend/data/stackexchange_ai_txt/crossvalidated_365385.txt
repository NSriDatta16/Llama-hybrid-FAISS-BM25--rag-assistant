[site]: crossvalidated
[post_id]: 365385
[parent_id]: 94402
[tags]: 
An alternative way to look at is by the quantile function. $$Q(F(x)) = x$$ Then we can compute a moment or expectation $$E(T(x)) = \int_{-\infty}^\infty T(x) f(x) dx\\$$ alternatively as (replacing $f(x)dx = dF$): $$E(T(x)) = \int_{0}^1 T(Q(F)) dF \\$$ Say we wish to compute the first moment then $T(x) = x$. In the image below this corresponds to the area between F and the vertical line at $x=0$ (where the area on the left side may count as negative when $T(x) The curves in the image show how much each quantile contributes in the computation. For the normal curve there are only very few quantiles with a large contribution. But for the Cauchy curve there are many more quantiles with a large contribution. If the curve $T(Q(F))$ goes sufficiently fast enough to infinity when F approaches zero or one, then the area can be infinite. This infinity may not be so strange since the integrand itself distance (mean) or squared distance (variance) can become infinite. It is only a question how much weight , how much percent of F, those infinite tails have. In the summation/integration of distance from zero (mean) or squared distance from the mean (variance) a single point that is very far away will have more influence on the average distance (or squared distance) than a lot of points nearby. Thus when we move towards infinity the density may decrease, but the influence on the sum of some (increasing) quantity, e.g. distance or squared distance does not necessarily change. If for each amount of mass at some distance $x$ there is half or more mass at a distance $\sqrt{2}x$ then you will get that the sum of total mass $\sum \frac{1}{2^n}$ will converge because the contribution of mass decreases, but the variance becomes infinite since that contribution does not decrease $\sum ((\sqrt{2}x)^n)^2 \frac{1}{2^n} \to \infty$
