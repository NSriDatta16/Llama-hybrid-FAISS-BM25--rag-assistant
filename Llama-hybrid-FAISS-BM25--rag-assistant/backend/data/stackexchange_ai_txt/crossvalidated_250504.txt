[site]: crossvalidated
[post_id]: 250504
[parent_id]: 
[tags]: 
Using a model to select between a/b in a a/b test

I am wondering what the best way is to model an A/B test. Meaning, if I run an a/b test, I want to run a model to determine if A or B is better for each individual. A/B would be assigned randomly (50% get A, 50% get B for example) My thinking: Split data in training/validation/test On training, run a model on A customers and run a separate model on B customers (response variable being conversion yes/no). I would use a logistic regression for this. Then run both models on the validation/test data to see if A or B estimates a better chance of conversion. Whichever estimates a higher % chance is the predicted treatment (A or B). Then I would calculate the uplift in conversion by comparing the overall conversion rate compared to the conversion rate of those that got the correct treatment (IE their actual treatment, A or B, matched their predicted treatment) Does this sound like the right approach?
