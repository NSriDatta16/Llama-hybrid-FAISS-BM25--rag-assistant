[site]: datascience
[post_id]: 52065
[parent_id]: 
[tags]: 
Improving the results of CNN

Edit 2 I solved my problem. The issue was caused by the validation_generator. I used the method flow_from_directory with shuffle = true. By changing the value to false and calling the method validation_generator.reset() before model.predict_generator() for computing the confusion matrix solved my problem. The reset()-method seems to be very important. Edit: I was able to isolate the problem a little. I noticed that evaluate_generator method returns the correct values from the training, e.g. [0.068286080902908, 0.9853515625]. However, the predict_generator() method behaves strangely. The results look like this: [[8.8930092e-06 5.8127771e-04 3.8436747e-06 7.7528159e-07 9.9940526e-01] [1.4138629e-03 9.9854565e-01 5.4473304e-07 3.9719587e-05 1.8904993e-07] [9.0803866e-07 2.7020766e-05 7.9189061e-07 4.9350000e-09 9.9997127e-01] ... [5.0964586e-06 4.5610027e-04 2.6184430e-06 1.6962146e-07 9.9953604e-01] [2.9692460e-08 3.1284328e-10 4.7919415e-09 1.0000000e+00 1.4161311e-12] [2.1354626e-06 9.6519925e-06 1.9460406e-07 4.6475903e-09 9.9998796e-01]] #### I did some image classification with a CNN. The Accuracy of the training and validation set are high and the losses for both of them are low. However, my confusion matrix does not have the typical diagonal from the upper left to lower right. If I understand the confusion matrix correctly, I have a lot of misclassifications. So, how can I improve my model to get better results? The distribution of samples each class is: early: 800 healthy: 749 late: 764 leaf mold: 761 yellow: 708 The Structure of the model: model = models.Sequential() model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3))) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Dropout(0.15)) model.add(layers.Conv2D(64, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Dropout(0.2)) model.add(layers.Conv2D(128, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(256, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(256, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(BatchNormalization()) model.add(layers.Flatten()) model.add(layers.Dropout(0.6)) model.add(layers.Dense(150, activation='relu', kernel_regularizer=regularizers.l2(0.002))) model.add(layers.Dense(5, activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=1e-3), metrics=['acc']) These are the accuracy and losses of the training: Epoch 00067: val_loss did not improve from 0.08283 Epoch 68/200 230/230 [==============================] - 56s 243ms/step - loss: 0.0893 - acc: 0.9793 - val_loss: 0.0876 - val_acc: 0.9784 Epoch 00068: val_loss did not improve from 0.08283 Epoch 69/200 230/230 [==============================] - 58s 250ms/step - loss: 0.0874 - acc: 0.9774 - val_loss: 0.1209 - val_acc: 0.9684 Epoch 00069: val_loss did not improve from 0.08283 Epoch 70/200 230/230 [==============================] - 57s 246ms/step - loss: 0.0879 - acc: 0.9803 - val_loss: 0.1384 - val_acc: 0.9706 Epoch 00070: val_loss did not improve from 0.08283 Epoch 71/200 230/230 [==============================] - 59s 257ms/step - loss: 0.0903 - acc: 0.9783 - val_loss: 0.1352 - val_acc: 0.9728 Epoch 00071: val_loss did not improve from 0.08283 Epoch 72/200 230/230 [==============================] - 58s 250ms/step - loss: 0.0852 - acc: 0.9798 - val_loss: 0.1324 - val_acc: 0.9621 Epoch 00072: val_loss did not improve from 0.08283 Epoch 73/200 230/230 [==============================] - 58s 250ms/step - loss: 0.0831 - acc: 0.9815 - val_loss: 0.1634 - val_acc: 0.9574 Epoch 00073: val_loss did not improve from 0.08283 Epoch 74/200 230/230 [==============================] - 57s 246ms/step - loss: 0.0824 - acc: 0.9816 - val_loss: 0.1280 - val_acc: 0.9640 Epoch 00074: val_loss did not improve from 0.08283 Epoch 75/200 230/230 [==============================] - 57s 247ms/step - loss: 0.0869 - acc: 0.9774 - val_loss: 0.0777 - val_acc: 0.9882 Epoch 00075: val_loss improved from 0.08283 to 0.07765, saving model to C:/Users/xxx/Desktop/best_model_7.h5 Epoch 76/200 230/230 [==============================] - 56s 243ms/step - loss: 0.0739 - acc: 0.9851 - val_loss: 0.0683 - val_acc: 0.9851 Epoch 00076: val_loss improved from 0.07765 to 0.06826, saving model to C:/Users/xxx/Desktop/best_model_7.h5
