[site]: stackoverflow
[post_id]: 3821179
[parent_id]: 3788806
[tags]: 
Having never found even a hint of an answer to this, I decided to move in a different direction. I'm using Pig to load and parse the large file, but then streaming each record that I care about to PHP for additional processing that Pig doesn't seem to have the capability to handle cleanly. It's still not complete (read: there's a great big, very unhappy bug in the mix) , but I think the concept is solid--just need to work out the implementation details. everything = LOAD 'categories.txt' USING PigStorage() AS (category:chararray); -- apply filter -- apply filter -- ... -- apply last filter ordered = ORDER filtered_categories BY category; streamed = STREAM limited THROUGH `php -nF process_categories.php`; DUMP streamed;
