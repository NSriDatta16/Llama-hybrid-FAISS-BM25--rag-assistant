[site]: crossvalidated
[post_id]: 520835
[parent_id]: 
[tags]: 
Optical flow models (FlowNet) training/finetuning process

I'm reading about optical flow models, particularly FlowNet and PWC-Net . I thought I understood how training and finetuning are being done, but I don't believe so anymore after trying to understand the results. For example in the FlowNet paper, from the sections discussing the available datasets as well as the later sections discussing training and finetuning, my understanding was that the models are all trained on the authors own FlyingChairs synthetic dataset, as the previously existing datasets are too small for a CNN. Then when benchmarking on one of the other datasets, for example focus on MPI Sintel, they also examine the effect of finetuning on the target dataset. This is reflected in the results (Table 2 in the paper) where they have models FlowNetS, FlowNetC as well as FlowNetS+ft and FlowNetC+ft to reflect the models with or without finetuning. So my understanding was the first two are just trained on FlyingChairs and then applied to the Sintel train and test sets, while the second two are the result of taking the first two and performing finetuning on the Sintel training set before applying them to the Sintel train and test sets. From looking at the quoted results it seems this cannot be right because the models which have not been finetuned still perform significantly better on the Sintel train data compared to test, even though according to this interpretation this data wouldn't have been seen before by these models. There would be no reason for the models which were not finetuned to perform any better on Sintel train compared to test. Is anyone familiar with these models and knows what I'm missing here in how the models are trained and finetuned?
