[site]: crossvalidated
[post_id]: 230233
[parent_id]: 228553
[tags]: 
This is not a direct answer to your question, and I don't have enough reputation to comment, but one thing you can do is use the Machine Learning in R package. There are many random forest learner implementations there that can use data with missing values. You can also tune the learners based on what your dataset is. Links to the package and documentation are on the main tutorial page, here: https://mlr-org.github.io/mlr-tutorial/release/html/index.html Also, consider that answering your question becomes much easier if you provide a sample of your dataset. If you need a direct answer, looping a series of RF calls on the imputed datasets might work. E.g. if you have five imputations: res = data.frame(matrix(0,nrow=nrow(test),ncol=5) for (i in 1:5){ data = complete(miceResult, 1) rf.res = cforest(data,formula ~ [which formula?]) res[,i] = predict(rf.res, test) } Then you can pool the results by majority voting or averaging, depending on your dataset. You can also group the 5 imputations together and train the learner with the combined dataset. Both methods are suboptimal, however. Hope this helps.
