[site]: crossvalidated
[post_id]: 589875
[parent_id]: 589798
[tags]: 
I disagree with @frank's advice to include interactions (with $x$ ) but no main effects for the stimulus , lighting and colony variables. But see How do you deal with "nested" variables in a regression model? for an important exception to this rule. Moreover, a scatterplot of the data reveals that the two colonies are observed under different conditions. The difference is most pronounced when stimulus = "Cold" as there is complete separation in the $x$ values. (This may indicate that $x$ is not really a "treatment" assigned randomly to units as @frank interprets it.) This pattern suggests to interact colony with all the other variables, which leads — visually at least — to a better model fit. Update : The OP has provided additional context. The experimental design is still unclear but it seems the units were randomized to one of four conditions ( stimulus × lighting ), given time to train under the assigned condition ( x ), and then tested "officially" ( y ). The numerical variables x and y are number of successfully completed tasks in a fixed amount of time (everyone got the same amount of time). The number of attempted but unsuccessful tasks is ignored though it may be important: what if stimulus and lighting affect the number of trials but not the success rate of a trial? Also unexplained is the concept of a colony . The number of successes x during training under Cold stimulus is markedly different for colonies 1 and 2 . On its own, the data cannot explain why this happened and therefore the data cannot point out which is the most scientifically justified model either. Instead the OP should explain/examine the difference between the two colonies. If these two colonies were sampled from a larger population, it would help to do followup experiments to investigate the variability between colonies under "Cold" stimulus. If these two colonies are the only ones of interest, it would help to sample more units from each colony to study the variability within each colony. To highlight the importance of colony and following comments by @SextusEmpiricus, let's compare two model fits: the full model y ~ x * stimulus * lighting * colony (figure above) and the restricted model y ~ x * stimulus * lighting (figure below). The full model fits better statistically (in terms of an F-test). As it fits a regression line for each stimulus × lighting × colony combination, the full model interpolates well "unusual" points. I've highlighted one such point in each panel without testing formally that these points are outliers or high-leverage . The restricted model fits a line for the four stimulus × lighting combinations (four panels) and — within each panel — it uses the same line for the two colonies. Qualitatively, the fit is not bad and I can come up with a nice story that training is effective (the regression lines have positive slopes) under all conditions except for "dark and cold". Whether this story is meaningful depends on what the colonies actually are. Here is R code to reproduce the figures and play with different models for this data. library("broom") library("tidyverse") # Cast `colony` and `ID` as categorical (rather than numeric) variables. df % mutate( colony = as.character(colony) ) outliers $call$ formula)) } plot_model_fit % augment( newdata = df ) %>% ggplot( aes(x, .fitted) ) + geom_line( aes(color = colony) ) + geom_text( aes(x, y, color = colony, label = colony ), data = df, inherit.aes = FALSE ) + geom_label( aes(x, y, color = colony, label = colony ), data = df %>% filter(ID %in% outliers), inherit.aes = FALSE ) + facet_grid( stimulus ~ lighting ) + theme( plot.title = element_text( size = 12 ), legend.position = "none" ) + ggtitle( title, extract_model_formula(model) ) } m0 ```
