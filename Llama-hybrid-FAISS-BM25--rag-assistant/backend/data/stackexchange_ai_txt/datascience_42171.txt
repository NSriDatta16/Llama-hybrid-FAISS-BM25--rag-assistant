[site]: datascience
[post_id]: 42171
[parent_id]: 42020
[tags]: 
I'm not sure if you have already done this, but your first task would be to use a library such as OpenCV to extract all frames from the video (i.e. all possible images). Once this has been done, you need to create training and test data which would indicate whether a visual is "bad" or not. For example, suppose you have extracted 10,000 frames from the video. You could then use 5,000 of those images (as an example), with half of those classified as "good" visuals, with the other half being classified as "bad". For instance: Training set 1: 2,000 good images Test set 1: 500 good images Training set 2: 2,000 bad images Test set 2: 500 bad images Then, once the CNN (convolutional neural network) has been adequately trained with a high training and validation accuracy, the remaining images can either be classified as 1 = good, 0 = bad. The idea is that you will have already trained the model to differentiate between good and bad images based on their characteristics.
