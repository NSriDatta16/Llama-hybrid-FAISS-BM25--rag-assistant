[site]: crossvalidated
[post_id]: 616387
[parent_id]: 
[tags]: 
Steps for condensed nearest-neighbor algorithm

I'm in the middle of writing my Master's thesis on undersampling techniques in imbalanced datasets, and I wanted to refer on this paper explaining the Condensed Nearest-Neighbor algorithm and what kind of adjustments is Tomek Links making on it. What niggles me is the beginning of the article that explains the steps of CNN algorithm. As far as I know, the algorithm ends when we assigned all the examples either to a new prototype subset $E$ or to absorbed points. But in the following explanation point h) tells to go back to b) , which essentially starts over the whole procedure by setting $E={\{x\}}$ which is a random datapoint from $D$ . Am I missing something there or is this simply wrong?
