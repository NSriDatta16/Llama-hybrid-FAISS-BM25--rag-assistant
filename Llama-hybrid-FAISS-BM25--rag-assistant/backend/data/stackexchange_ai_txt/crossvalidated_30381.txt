[site]: crossvalidated
[post_id]: 30381
[parent_id]: 30369
[tags]: 
When I'm trying to be relatively uninformative, I have tended to use a uniform prior on $\ln \sigma$ and specify an upper bound, which corresponds to $p(\sigma) \propto 1/\sigma$ over a finite rangeâ€”relatively uninformative, and equal to Jeffreys' prior over the range ( not equal to what the Jeffreys prior would be if you knew there was an upper bound on $\sigma$ and what it was.) If the posterior piles up against your upper bound, you can increase it and rerun, unless you have some strong reason for choosing that upper bound. This was suggested by Andrew Gelman in the Prior distributions for variance parameters paper here . (Some of the other articles in this issue of Bayesian Analysis are possibly relevant too, hence the link to the journal page.) However, recently I've tried the beta-prime prior suggested in the first response to Weakly informative prior distributions for scale parameters and that worked out well for me also. Importance sampling on the output of the MCMC indicated that the differences between the posteriors of the parameters of interest using the two priors were trivial, which, after all, is what you want when you're trying to be relatively uninformative - and it gets you away from that annoying specification of an upper bound on $\sigma$. This question and answer may also be relevant: Random effect on scale parameter
