[site]: crossvalidated
[post_id]: 568634
[parent_id]: 
[tags]: 
Distribution of Bayesian Information Criteria - using BIC when there are multiple datasets

I have two competing nested models : $M1$ and $M2$ . $M1$ has way less parameters. I know that $M2$ is definitely a true model for data (i.e., can explain data fully) but I claim that it is not the most parsimonious. I claim that the more parsimonious and still a true model is $M1$ . For example, suppose the data is a*x = y. Let's call this $M1$ . If you include an intercept into the model, we obtain $M2$ . Both $M1$ and $M2$ are true models in terms of their explanatory power (i.e., they can fully explain the data). Only the values of intercepts in $M2$ will turn out to be zero after estimating model parameters. That's what I mean by having two true models. To state it more generally, when M2 model parameters have some constraints, M1 is obtained. If M1 can accurately predict data and is a true model, M2 will also be a true model in terms of explanation accuracy. As opposed to classical case where one has a single dataset to compare models, I have $N >> 1$ datasets. I don't know if I can combine the datasets since true values of model parameters can vary between datasets (i.e., the models still have the same parameters but only their values are different between different datasets). Furthermore, datasets are of different lengths. I calculated BICs for all dataset, and it's not always the case that $M1$ outperforms the $M2$ . Instead, I have a distribution. Is there a way I can still test my claim without compromising statistical validity based on a distribution of information criteria values ? Here is a refined statement of my problem for my actual data. My datasets consists of neurons. In each dataset, I have a different number of neurons. To generalize, let's suppose there are $N_i$ neurons for the dataset $D_i$ . For each neuron $j$ in a dataset $i$ , there is a dependent variable $Y_{ij}$ and an independent variable $X_{ij}$ . The relation between DV and IV for a given neuron can be accurately captured by a regression relationship $$Y_{ij} = \alpha_{ij} X_{ij} + \beta_{ij}.$$ For all neurons, I am interested in, this regression is statistically significant and very accurate (can explain between %50-%90 of the variance in each neuron). If you consider all neurons in a given dataset $D_i$ , the model of each dataset has $2 N_i$ coefficients : $N_i$ for $\alpha_{ij}$ s and $N_i$ for $\beta_{ij}$ s (i.e., $j = 1, ... N_i$ ). This is my model $M_2$ . Note that, in each dataset, values of model coefficients are not necessarily the same. Although $M_2$ is great in explaining the variance in neurons, I claim that it is not the most parsimonious model. My claim is that, for a given dataset $D_i$ , the regression coefficients satisfy the constraint $$ \dfrac{\alpha_{ij}}{\beta_{ij}} = c_i \quad\forall j = 1, ..., N_i.$$ Note that $c_i$ constants can be different between datasets. With this constraint, the model of a single dataset has now $N_i + 1$ coefficients. I call this model $M_1$ . Model $M_1$ is a reduced model obtained from $M_2$ under the special constraint. My ultimate goal is to compare these two models using BIC. Because I have many datasets, one can compute BIC of each model for each dataset. This gives a distribution of Bayesian Information Criteria.
