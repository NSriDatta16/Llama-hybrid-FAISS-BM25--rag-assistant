[site]: stackoverflow
[post_id]: 4591120
[parent_id]: 4579317
[tags]: 
My experiences are: The primary challenge would be to think in No-SQL terms when coming from relational background. For example, HBase (built on Hadoop DFS) will only give you ascending order, if you want to do a descending order lookup you will need to maintain a reverse index; i.e. ID 1 point to book A and in reverse index (max - 1) pointing to 1. Documentation is a problem but - the community, as in all OSS, is very important. Along Git and Jersey I would say the HBase community is extremely helpful so that makes up for the lack of documentation and HBase documentation is improving all the time. Another challenge would be searching. We often use SQL RDBMS for searching, HBase, e.g., is not at all suited for that purpose. It is advised to use other software for searching while using HBase for reliable storing, e.g. Elastic Search, Apache Solr, Apache Lucene etc. That actually depends from project to project, in case of HBase There are improvements largely from 0.20.X to 0.90.X (its release is eminent). AFAIK the data store format does not change, neither the API drastically, but like any major OSS with major version change the API changes, but with minor changes there are no API changes. Though not vastly experience in upgrading, but from my little adventure in this I noticed not problem retrieving the data. This is tricky and vastly depends on the type of application in question here. As you mention memcached I would like to share the experience we are currently going through. We are not using HBase for any searching other than straight forward primary key lookup. All other searches go through Apache Solr (which is based on Lucene). So search result is cached in by Solr. In application layer, as we use Java, we use Ehcache for storing raw objects. In the web caching we use Varnish Cache , using ESI we fragmented the page into per user content, e.g. login, logout, account, cart etc., and general content, e.g. news, events, products etc. the achieve high throughput. I would like to agree with Mark Tozzi on it.
