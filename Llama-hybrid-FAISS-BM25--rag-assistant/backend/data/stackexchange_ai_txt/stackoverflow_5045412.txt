[site]: stackoverflow
[post_id]: 5045412
[parent_id]: 
[tags]: 
Hadoop, hardware and bioinformatics

We're about to buy new hardware to run our analyses and are wondering if we're making the right decisions. The setting: We're a bioinformatics lab that will be handling DNA sequencing data. The biggest issue that our field has is the amount of data, rather than the compute. A single experiment will quickly go into the 10s-100s of Gb, and we would typically run different experiments at the same time. Obviously, mapreduce approaches are interesting (see also http://abhishek-tiwari.com/2010/08/mapreduce-and-hadoop-algorithms-in-bioinformatics-papers.html ), but not all our software use that paradigm. Also, some software uses ascii files as in/output while other software works with binary files. What we might be buying: The machine that we might be buying would be a server with 32 cores and 192Gb of RAM, linked to NAS storage (>20Tb). This seems a very interesting setup for us for many of our (non-mapreduce) applications, but will such configuration prevent us from implementing hadoop/mapreduce/hdfs in a meaningful way? Many thanks, jan.
