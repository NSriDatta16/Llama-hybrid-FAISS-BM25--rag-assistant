[site]: datascience
[post_id]: 24153
[parent_id]: 24137
[tags]: 
For encoding of the categorical variables with high cardinality (i.e. with large number of levels) you may want to try the so called impact coding . The main idea is very simple, you just split the dataset into non-overlapping buckets by the variable of interest (“protocol” in your case) and calculate average of your response variable over each bucket. Then, the values of the categorical variable can be substituted by the average value over particular bucket. Avg(response | protocol=”tcp”) Avg(response | protocol=”icmp”) Avg(response | protocol=”udp”) The tricky part is to avoid data leakage, this can be done by splitting the entire dataset into several subsets (e.g. “encoding”, “training”, “validation”,…) and using only the data from “encoding” dataset for the nominal-to-numerical conversion. I’ve learned about this approach from Win-Vector blog and their paper: vtreat: a data.frame Processor for Predictive Modeling , which I highly recommend.
