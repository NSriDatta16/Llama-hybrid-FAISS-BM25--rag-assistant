[site]: crossvalidated
[post_id]: 332316
[parent_id]: 332313
[tags]: 
Hoping I could find some references that illustrate this approach more formally than the mental model I currently have I think there are a lot of research papers addressing the binning of continuous variables (here's one: http://www.m-hikari.com/ams/ams-2014/ams-65-68-2014/zengAMS65-68-2014.pdf ), however this approach is relatively rare (at least in my opinion) in machine learning approaches due to much more manual work needs to be done to create great binning. Binning is usually (very often) used in actuarial credit, risk, premium models due to the nature that the industries are highly regulated and the model output need to make sense, especially since the most popular model in actuarial science is logistic regression, the linearity relationship between each variable in the model and the reponse need to be assessed with much much more care. And the approach is binning to create reasonable nominal variables to find the best linear relationship between the variables. It also serves as a way to reduce the effect of extreme values as well. However, the downside is that it will really take your time to assess each variable to create bins. And this needs to be done back and forth for all variables in your model. Whether I should just be using Random Forest? Short answer, you can. If you have no restrictions on which model to use, random forest will typically give you better result as it will handle the non-linearity of your data. However, this is going to reduce the interpretability of your model output compare to logistic regression; if this doesn't matter to you, go ahead.
