[site]: crossvalidated
[post_id]: 352168
[parent_id]: 
[tags]: 
How do I improve model accuracy predicting categorical outcome using categorial predictors?

I'm trying to predict Para using Col s. My data is in this format: Record ID Para Col2 Col3 1 A x a 1 A x b 2 B y a 2 B y b 1 A z c 1 C x a So far, I have tried applying One Hot Encoding (OHE) and running algorithms on the following transformed data: Record Para a b c x y z 1 A 1 1 1 1 0 1 1 C 1 1 1 1 0 1 2 B 1 1 0 0 1 0 The accuracy has been shoddy, highest of 27% with Logistic Regression. I tried kNN, Random Forest, Decision Tree. Next, I tried encoding the Col s to ordinal variables and then reran the algorithms (except Logistic Regression). Similarly poor results. Am I doing something incorrectly? How can I improve the accuracy? The raw data is 249681 rows × 9 columns . Both outcome and predictor columns are categorical. When doing OHE, the data is 5534 rows × 865 columns . One thing that I'd like to try is Naive Bayes that calculates P(Outcome|Predictor) and then assign the highest probability predictor to the outcome. Is that a reasonable approach to take?
