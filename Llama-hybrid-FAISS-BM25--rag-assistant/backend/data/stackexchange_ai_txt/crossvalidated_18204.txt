[site]: crossvalidated
[post_id]: 18204
[parent_id]: 18178
[tags]: 
If your data are grouped by $x$ values, you can compute the model predicted value and it's associated confidence interval, and see if the observed percentage falls within that range. For example, if you had 10 observations at $x=10$, 10 obs at $x=20$, 10 obs at $x=30$, etc., then mean(y[x==10]==1) , mean(y[x==20]==1) , etc., would yield percentages that can be compared to predictions. Bear in mind, that even if the model is perfect, some observed percentages will bounce outside of the 95% CI, just like in OLS regression. If your data are not grouped, you can form your own groups by binning the data according to ranges of the $x$ variable, as you suggest. This isn't fully valid, as it will depend on the choice of bins, can be useful as a way of exploring your model. In general, the task you have given yourself here is difficult. That's because, with logistic regression, you are dealing with two different kinds of things. The model's predictions are a latent variable, whereas your observed response variable (while presumably generated by a latent variable) is not. Of course, people will often want to know what the predicted response is, and that's totally reasonable; this is just one of those cases where life isn't fair. If you do want to predict the outcome, you need to decide what you want to maximize. If you have just 1 case, and you want your prediction to be most likely to be right, you should predict $y=1$, if $\hat y\ge .5$. (This is all pretty intuitive.) On the other hand, if you want to maximize overall accuracy over your total sample (or any other group), you should predict $y=1$, if $\hat y \ge p(y=1)$. For example, let's say that in your sample, 30% of all cases are 1's, then if $\hat y = .31$, you should predict that $y$ will be $1$, even though it's $ A more comprehensive way to think about how much information is in your model, is to integrate over how accurate you would be given every possible threshold $(0, 1)$. This is the area under the curve (AUC) of the model's receiver operating characteristic (ROC), discussed by @Nick Sabbe. Remember that there is no $R^2$ for logistic regression. There are so called 'pseudo $R^2$'s, but the AUC (or the concordance, $c$, a synonym) is probably the best way to think about this issue.
