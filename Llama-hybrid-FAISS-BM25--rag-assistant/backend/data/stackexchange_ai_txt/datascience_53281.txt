[site]: datascience
[post_id]: 53281
[parent_id]: 53089
[tags]: 
Apache Spark currently has no Deep Learning libraries. However, you can run TensorFlow models on clusters. According to this article "The TensorFlow library can be installed on Spark clusters as a regular Python library". Additionally, I just found the SparkFlow module, that should be meant to interface Spark and TensorFlow. The GitHub repo is here .
