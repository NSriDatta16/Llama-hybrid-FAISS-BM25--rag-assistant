[site]: datascience
[post_id]: 22325
[parent_id]: 17471
[tags]: 
Kenny's answer is correct â€“ if you're using convolutional D , output of layers before dense may serve as features. My intuition is that it will work better for AC-GANs (or similar architectures, which make D classify input in addition to determining if it's fake or real). There is an approach called BiGAN which adds an Encoder component able to map generated and training samples to latent distribution z used to "initialize" generator. Authors show that it can effectively be used as a feature set for transfer learning and other tasks.
