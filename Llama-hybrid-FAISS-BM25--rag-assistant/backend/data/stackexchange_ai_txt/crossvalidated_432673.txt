[site]: crossvalidated
[post_id]: 432673
[parent_id]: 
[tags]: 
What do these equations on Bayesian regression (MAP) from Chapter 3.3 in PRML by Bishop mean?

This was taken from Ch 3.3 on Bayesian Linear Regression from Pattern Recognition in Machine Learning by Bishop. Apparently the posterior can be described by eq 3.49. Eq 3.48 represents the prior with Gaussian distribution with mean $$m_0$$ and variance $$S_0$$ What I'm struggling to understand are equations 3.50 and 3.51. I assume they're suppose to represent the mean of over n samples and inverse variance over n samples, but how did the author get to these calculations?
