[site]: crossvalidated
[post_id]: 6374
[parent_id]: 6181
[tags]: 
The multiple correlation in standard linear regression cannot be negative, the maths are easy to show it, although it depends on what "multiple correlation" is taken to mean. The usual way you would calculate $R^{2}$ is: $$R^2=\frac{SSR}{TSS}$$ where $$ SSR = \sum_{i} (\hat{Y_i}-\bar{Y})^2$$ and $$ TSS = \sum_{i} (Y_i-\bar{Y})^2$$ Since sums of squares can never be negative, neither can the $R^2$ value, as long as its calculated this way. However, $R^2$ calculated this way can be greater than 1, if you use an estimator which does not have the observed residuals sum to zero. Or mathematically, $R^2$ will be necessarily bounded by 1 if $$\sum_{i} (\hat{Y_i}-Y_i)=0$$ and $$\sum_{i} (\hat{Y_i}-Y_i)\hat{Y_i}=0$$ Or in words, the average of the residuals is equal to 0, and the fitted values are uncorrelated with the residuals over the whole data set. This is because you can expand TSS as follows $$ TSS = \sum_{i} (Y_i-\bar{Y})^2 = \sum_{i} ([Y_i-\hat{Y_i}]-[\bar{Y}-\hat{Y_i}])^2$$ $$=\sum_{i} (Y_i-\hat{Y_i})^2-2\sum_{i} [Y_i-\hat{Y_i}][\bar{Y}-\hat{Y_i}]+\sum_{i} (\bar{Y}-\hat{Y_i})^2$$ $$=\sum_{i} (Y_i-\hat{Y_i})^2-2\bar{Y}\sum_{i} [Y_i-\hat{Y_i}]+2\sum_{i} [Y_i-\hat{Y_i}]\hat{Y_i}+\sum_{i} (\bar{Y}-\hat{Y_i})^2$$ $$=\sum_{i} (Y_i-\hat{Y_i})^2+\sum_{i} (\bar{Y}-\hat{Y_i})^2$$ $$\implies TSS=SSR+\sum_{i} (Y_i-\hat{Y_i})^2 \geq SSR \geq 0$$ $$\implies 1 \geq \frac{SSR}{TSS}=R^2 \geq 0$$ The constraints listed are always satisfied by the usual OLS estimators (in fact they form part of the equations that define OLS estimation) $R^2$ can go negative if it is calculated by $1-\frac{SSE}{TSS}$ Where $SSE=\sum_{i} (Y_i-\hat{Y_i})^2$ instead of the way I described. As a (silly) example of $R^2>1$, you can put as the estimate $\hat{Y_i}=\bar{Y_i}+TSS$ So That $SSR=n(TSS)^2$ and $R^2=n(TSS)$ Which will exceed 1 for big enough n or TSS. To make $R^2$ go negative, set $\hat{Y_i}=Y_i+TSS$ so that $SSE=n(TSS)^2$ and $R^2=1-n(TSS)$ which will be less than 0 for big enough n and TSS
