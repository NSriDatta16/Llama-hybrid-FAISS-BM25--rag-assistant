[site]: crossvalidated
[post_id]: 621066
[parent_id]: 
[tags]: 
I have weekly averages, and weekly 2-minute peaks, can I estimate 30-second peaks?

I have been given weekly averages and weekly 2-minute peaks of flow to a process. I'd like to predict the 30-second peak. To clarify: By “weekly averages”, I mean that once a week, I get the average value of the process over the past week. By “2-minute peaks”, I mean that every week, I am given the highest 2-minute average value of the process of all continuous 2-minute intervals in the past week. I'm pretty sure my current approach is full of issues, and I'll include it here for the sake of exciting some indignation at the abuse of these statistical concepts. Basically, I assume that all flows can be approximated by a normal distribution. Then I assume the 2-minute peak is approximately equal to the true 99.980th percentile of all flow rates (2 minutes divided by a week of minutes is 0.99980). Then I assume the 30-second peak is approximately equal to the true 99.995th percentile of all flow rates (30 seconds divided by a week of seconds is 0.99995). The graphics below demonstrate this approach. Note that in these charts I am using the minimum observed week average and the maximum observed 2-minute peak to approximate the normal distribution. That is because overestimating the 30-second peak is appropriate for my situation. Is there a better way to estimate the 30-second peak? What are the major flaws with my current approach? Here is the Python code I used to generate those plots, in case it is helpful: # imports import pandas as pd import scipy.stats as st import matplotlib.pyplot as plt import numpy as np # example data df = pd.DataFrame( columns = [ 'week average', 'week 2-minute peak' ], data = np.array( [np.random.normal(loc=0.00, scale=0.33, size=60), np.random.normal(loc=1.16, scale=0.36, size=60)] ).T ) # boxplot of data plt.title('Example Observations') plt.ylabel('flow') plt.boxplot([df['week average'], df['week 2-minute peak']], labels=['obseved week averages', 'observed week 2-minute peaks']) plt.show() # approximating z-value of known 2-minute peak and unknown 30-second peak seconds_per_week = 60*60*24*7 z120 = st.norm.ppf(1-120/seconds_per_week) z030 = st.norm.ppf(1-30/seconds_per_week) # approximating true mean with the minimum of observed weekly averages mean = min(df['week average']) # minimum # aproximating true 2-minute peak with the maximum observed weekly 2-minute peak peak120 = max(df['week 2-minute peak']) # maximum observed weekly peak # relating z score to flow def z_to_flow(z): return ((peak120-mean)/z120*z+mean) def flow_to_z(flow): return flow-mean*z120/(peak120-mean) # approximating 30-second peak peak030 = z_to_flow(z030) # plotting normal probability density function x = np.linspace(st.norm.ppf(0.00001), st.norm.ppf(0.99999), 100) y = st.norm.pdf(x) fig, ax = plt.subplots(constrained_layout=True) ax.plot(x, y) ax.set_xlabel('z score') ax.set_ylabel('rough probability of occurance') # plotting points of interest ax.plot([0,0], [min(y),max(y)*1.05 ], label = r'observed weekly average $\approx$ true mean') ax.plot([z120,z120], [min(y),max(y)*1.05 ], label = r'observed 2-min peak $\approx$ 99.980th percentile') ax.plot([z030,z030], [min(y),max(y)*1.05 ], label = r'99.995th percentile $\approx$ 30-s peak') secax = ax.secondary_xaxis('top', functions=(z_to_flow, flow_to_z)) secax.set_xticks([mean,peak120,peak030]) secax.tick_params(labelrotation = 90) secax.set_xlabel('flow') ax.set_title('Example Flows Approximated as Normal Distribution\n') ax.legend() plt.show()
