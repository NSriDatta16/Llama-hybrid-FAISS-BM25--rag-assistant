[site]: crossvalidated
[post_id]: 623715
[parent_id]: 623689
[tags]: 
Here is a hack to achieve what I am looking for. Specifically, add transform to the regression estimator directly. It is relatively lightweight but somewhat disheartening that I can't find an out-of-the-box solution for this pattern. import pandas as pd from sklearn.pipeline import Pipeline from sklearn.compose import ColumnTransformer from sklearn.linear_model import LinearRegression from sklearn.model_selection import cross_val_score w1 = [x for x in range(10)] w2 = [x ** 2 for x in range(10)] x1 = [-x for x in range(10)] x2 = [2*x for x in range(10)] y = [x + 2 for x in range(10)] df = pd.DataFrame({'w1': w1, 'w2': w2, 'x1': x1, 'x2': x2, 'y': y}) def generic_transform(self, X): return self.predict(X=X).reshape(-1, 1) LinearRegression.transform = generic_transform lr_transformer = ColumnTransformer( [ ("lr_w", LinearRegression(), ['w1', 'w2']), ("lr_x", LinearRegression(), ['x1', 'x2']), ] ) pipeline = Pipeline( [ ("lr_transformer", lr_transformer), ("model", LinearRegression()) ] ) cross_val_score(estimator=pipeline, X=df, y=df['y'], scoring='neg_mean_squared_error', cv=10).mean()
