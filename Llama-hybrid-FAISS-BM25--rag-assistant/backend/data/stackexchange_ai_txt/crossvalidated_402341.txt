[site]: crossvalidated
[post_id]: 402341
[parent_id]: 
[tags]: 
Are there limitations to backshift operator algebra in Time Series Analysis?

After algebraic gymnastics with the backshift operator $\text{B}$ (i.e., $\text{B}y_t=y_{t - 1}$ ) I thought I found a convenient dynamic representation for a nonlinear model, but the representation fails in simulation. The situation is described below, but the high level questions are: Are you allowed to multiply a transfer function numerator and denominator by $\text{B}$ , leading to higher-order lags? If your shift operator algebra leads to a problematic error structure for OLS or GLS estimation, what are your options? Situation : In an athletic performance context, assume fitness $x_t$ and fatigue $w_t$ decay by proportions $\theta_x$ and $\theta_w$ per unit of time and are driven by exogenous training stimulus $u_t$ : $$ x_t = \theta_x x_{t - 1} + \theta_x u_{t - 1} \\ w_t = \theta_w w_{t - 1} + \theta_w u_{t - 1}. $$ Performance is modeled to be the effective net of fitness and fatigue plus white noise: $$ y_t = \mu + k_x x_t + k_w w_t + \epsilon_t, $$ where $\epsilon_t \sim N(0, \sigma^2)$ . Using the backshift operator $\text{B}$ , this can be reframed as: $$y_t - \mu = \left[\frac{k_x\theta_x\text{B}}{1 - \theta_x\text{B}} + \frac{k_w\theta_w\text{B}}{1 - \theta_w\text{B}}\right] u_t + \epsilon_t.$$ I tried to combine the fractions in the brackets by getting both denominators to $(1 - \theta_x\text{B})(1 - \theta_w\text{B})$ , or $$1 - (\theta_x + \theta_w) \text{B} + \theta_x \theta_w \text{B}^2.$$ This seemed great, because I could multiply by both sides of the equation by this "quantity" to knock out the denominator components. What's left is apparently a regression model of $y_t$ vs $y_{t-1}, y_{t-2}, u_{t-1}, u_{t-2}$ with MA(2) errors. However, when I tried this with simulated data, I was unable to recover the theoretical coeffients of the dynamic model. I later realized that -( $\theta_x + \theta_w$ ), one of the MA(2) parameters and the theoretical coefficient of $y_{t - 1}$ , is likely to be absolutely greater than 1. Did I push this method too far? What rules did I break? Update To follow up on @whuber's suggestion that there might be something wrong with the model, allow me to provide a bit more context. I've been studying the fitness-fatigue model of athletic performance, and I wrote this blog article which contains code to simulate data and recover parameters from the following model: Later I came across an article from Kolossa et al where they put the fitness-fatigue model in the Kalman Filter framework. This is how they structured it, where A is the transition matrix, B multiplies the control (training) inputs, and C multiplies the latent vector to get to the observable performance: . I'm using a slightly simpler version where the bottom entry of the B-matrix is just like the top and I have both entries of C as free parameters, but I did test it out and it seemed to work. This dynamic representation was what motivated me to see if there was an even simpler dynamic regression implementation.
