[site]: crossvalidated
[post_id]: 172337
[parent_id]: 49426
[tags]: 
The idea that there is greater uncertainty (randomness) in early data points suggests to me the possible need to incorporate Generalized Least Squares ( i.e. weighted estimation) when estimating an appropriate ARIMA model or Transfer Function model (if one has predictor/user specified causal/explanatory series). The whole idea is to identify a possibly useful model and then incorporate the suggestion of Tsay http://www.unc.edu/~jbhill/tsay.pdf to empirically identify the weights (diagonal adjustments to the variance-covariance matrix) after any appropriate intervention variables are incorporated in order to render the ultimate set of errors to be homogeneous. I have been reasonably successful in programming and using this approach for a number of years. My understanding is that the ARIMA structure remedies the off-diagonal "complications" of the variance-covariance matrix thus two distinctly different weighting schemes are involved. One takes into account the time response ( i.e. ARIMA how to weight the past (moving average of the past) while the second type of weights encodes changing uncertainty/volatility/believabilty of the historical values themselves. Continuing ... the first deals with the expected value i.e. the first moment while the second deals with the second moment (variability).
