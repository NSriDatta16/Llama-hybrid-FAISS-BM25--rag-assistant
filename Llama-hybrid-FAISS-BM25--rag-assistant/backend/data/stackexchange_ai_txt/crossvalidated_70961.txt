[site]: crossvalidated
[post_id]: 70961
[parent_id]: 
[tags]: 
Is there a problem with multicollinearity and for splines regression?

When using natural (i.e. restricted) cubic splines, the basis functions created are highly collinear, and when used in a regression seem to produce very high VIF (variance inflation factor) statistics, signaling multicollinearity. When one is considering the case of a model for prediction purposes, is this an issue? It seems like it will always be the case because of the nature of the spline construction. Here is an example in R: library(caret) library(Hmisc) library(car) data(GermanCredit) spl_mat UPDATE: I reached out to Dr. Harrell, the author of Hmisc package in R (and others) and he responded that as long as the algorithm converges (e.g. the logistic regression) and the standard errors have not exploded (as Maarten said below) - and the model fits well, best shown on a test set, then there is no issue with this collinearity. Further, he stated (and this is present on page 65 of his excellent Regression Modeling Strategies book ) that collinearity between variables constructed in an algebraic fashion like restricted cubic splines is not an issue as multicollinearity only matters when that collinearity changes from sample to sample.
