[site]: datascience
[post_id]: 88044
[parent_id]: 
[tags]: 
Neural Network Optimization steps order

I have a very basic question on the optimization algotithm, when I'm adjusting weights and biases in a NN, should I: Forward propagate and backpropagate to calculate gradient descent (DC) for each batch once and then repeat for iterations_number times. or Forward propagate and backpropagate to calculate gradient descent (DC) one batch for iterations_number times and then continue with the next batch.
