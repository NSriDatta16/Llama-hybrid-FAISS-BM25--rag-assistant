[site]: crossvalidated
[post_id]: 496449
[parent_id]: 
[tags]: 
What model assumptions are necessary for a changepoint detection based on permutation test

I am writing about the change point detection algorithm suggested by Taylor W. in my bachelor thesis. The full description can be found here: https://variation.com/wp-content/uploads/change-point-analyzer/change-point-analysis-a-powerful-new-tool-for-detecting-changes.pdf The algorithm is based on cumilative sums (CUSUMs) $S_{i}$ calculated from the data $(X_{1},...,X_{n})$ and a permutation test executed on a statistic $S_{diff}$ (defined below). The permutation test is performed by shuffling the data $(X_{1},...,X_{n})$ and used to determine a confidence level for the occurrence of a change point. The individual statistics are defined as: \begin{equation} S_{diff}:=S_{max}-S_{min} \end{equation} where \begin{equation} S_{0}:=0\\ S_{i}:=S_{i-1}+(X_{i}-\bar X), \quad for\; i=1,...,n \end{equation} I already know that the confidence level is conditional on errors (cf. https://www.jstor.org/stable/1392523 ) and that under the null hypothesis all permutations have to be equally likely. Thus in the permutation test the assignment of errors to the individual data points is fixed and not stochastic, whereas the specific occurrence in time is random. However, I'd like to define model assumptions that are sufficient and/or necessary for arguing that all permutations are equally likely. In the cited paper of Taylor only the mean-shift model, defined as follows, is required for performing the test. Definition: Let $X_{1},X_{2},..,X_{n}$ represent the data in time order. The mean shift model satisfies: \begin{equation} X_{i}=\mu_{i}+\epsilon_{i} \end{equation} where $\mu_{i}$ is the average at time $i$ . Generally, $\mu_{i}=\mu_{i-1}$ except for few indices $i$ called change-points. $\epsilon_{i}$ are independent random variables with mean 0 and called random errors. Are these conditions sufficient for arguing the exchangeability of the data or is it necessary that the random errors have the same distribution (ie. they are iid and e.g. the variance can not change in time). An literature source about permutation tests in the time series setting or rigoros mathematical explanations would be highly appreciated. Thank you!
