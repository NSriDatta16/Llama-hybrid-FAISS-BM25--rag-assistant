[site]: crossvalidated
[post_id]: 307952
[parent_id]: 
[tags]: 
Euclidean vs Manhattan distance behaviour in high dimension - curse of dimensionality

I have compared different distance functions by computing the average tf/idf distance between documents. My results show a range between $10-15$ for the Manhattan and a range between $1-1.5$ for the Euclidean distance. I am asked "what behaviour can we expect about the $L_1$ vs. $L_2$ norms as the dimensionality of the data increases? Is this behaviour observed in our dataset? If not, why not?" Any one have a clue about what is asked here? I know that $L_1$ is more robust than $L_2$ and that the $L_k$ norm worsens faster with increasing dimensionality for higher values of $k$ but I don't really know what I am supposed to answer.
