[site]: crossvalidated
[post_id]: 433282
[parent_id]: 433148
[tags]: 
So first let's see what happens when you run some logistic models on a toy data set. I'll modify the cbpp data set that downloads with lme4 to start. library(lme4) cbpp $incidence_dich incidence==0, 0, 1) cbpp $herd!="2",] cbpp herd!="8",] # For starters only using hers with 4 obs mean(cbpp$incidence_dich) Okay so we see that the observed probability of incidence > 0 is around .6. What do we get out of our unconditional logistic regression? logit_1 Alright, so far so good. As expected the uncoditional model just returns the observed probability of an incidence value being greater than 0. Now what happens when we deal with the nested structure of these data? Specifically, we want to specify a model that includes a random effect for herd . logit_2 Okay so we get a warning ( boundary (singular) fit: see ?isSingular ), so not great, but I don't really care about the model. For the purposes of your question, we'll ignore the warning (which is really just that the random effect variance was estimated to be 0). So what we see here is that we are replicating the observed probability in both modeling approaches. Now it would seem these data have a few things going on with them that guarantee that to be the case. First, the number of observations per herd was equivalent. Second, and much more importantly there was no random effect variance estimated by the model. I'll deal with the latter in the next section. I'll simulate some data we can be confident contains a random intercept. This will also allow us to know what the "true" population value is so we can see if one approach is better than the other. set.seed(102619) #to ensure reproducibility pop_prob Alright, so now we have a data set with a random intercept that varies by group. Let's see the observed probability that y_obs == 1 in these data. mean(dat$y_obs) A value of .576 seems reasonable given a population value of .6. Now what do we get from a simple unconditional model? logit_3 Alright, matches up... so far so good. What about our fancier, generalized multilevel linear model - that accounts for nesting. logit_4 Interesting... if you run the code you'll see that the logistic glm model replicates our observed mean perfectly ( .576 ), but the probability estimated from the glmer model is estimated to be .5958997 . Note that it may be of interest that the estimate for the nested model is much, much closer to the actual population value of .6 Maybe that is just one weird simulation right? Well what if we do the same thing 5000 times? n_sims Let's now take a look at the results when plotted. We can see a consistent difference between the relugar glm version and the slightly more complex glmer versions of the model. library(bayesplot) library(tidyverse) sim_results What is happening here? Well in a nutshell the regular glm model appears to be ever-so-slightly undershooting the predicted population probability when random effects occur in the data. In general, I would tend to have more faith in the multilevel model when random effects are present in the data, all other things being equal. Remember the goal is to estimate the population value after all, not the sample value. Now there could be a number of other factors that I did not walkthrough (missing data on your x 's, differences in number of observations per grouping unit, etc.). I would need to know more about your use case, or you can take this code walkthrough and modify it to more closely reflect your sample/population.
