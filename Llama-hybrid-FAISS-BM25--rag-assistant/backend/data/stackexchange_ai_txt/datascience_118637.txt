[site]: datascience
[post_id]: 118637
[parent_id]: 
[tags]: 
Given 20+ input numbers, predict 4-5 output numbers, using past data with the same 20+ inputs / 4-5 output for training

I'm a veteran Python software engineer, but very amateur at this stuff. I've used PyTorch for some NLP (sentiment and classification), and I've spent a bit of time attempting to learn data science, barely getting beyond Euclidean Distance, etc. I'm only giving this foreword as context for the inevitable naivety of my first question. BTW, I always select an answer on Stack Exchange. So, I work for a consulting company, and we do some tax-related consulting. We get some basic info from our clients ( NAICS number, etc.), and then we get financial data (revenue, employee costs, other costs, a lot of the bottom-line numbers you'd give to a CPA, etc.). We then work with these clients to determine some other things that help us determine whether they qualify for some specific tax breaks. The amounts of the tax breaks are based on the financial numbers, but the qualification is derived from some questions that are unrelated to the financial data they give use - it's a lot of manual work and Q&A within the company, and the result is 4-5 numbers on a few tax forms, which nets the clients some tax savings that they otherwise have been losing. However, our most experienced consultant is able to look at the financial numbers, combined with some basic knowledge of the client (NAICS number, number of years in business, etc.), and make a pretty accurate prediction about some of the answers to the Q&A portion, as well as usably accurate prediction about the numbers that will go into the tax forms. This is also based on the consultant looking at spreadsheets of the same set of data from the hundreds of projects worked on over the years and the resulting output in each case. IOW, there is a strong enough correlation, between patterns in the initial data we receive and the output of our consulting, to make fairly accurate predictions, potentially avoiding costly on-site visits in cases where we can preemptively say " we're not going to be able to save you enough to make it worth your time / fees ", etc. Given that backstory, and the data involved - some basic company info + bottom-line some financial numbers - and the output requirements - some estimated numbers based on the aforementioned - do you thin it is appropriate to apply some ML model to this problem, or am I barking up the wrong tree? My thinking is that there must be some PyTorch, Keras, etc. models out there that I can start with, and if I can provide it some cleaned up data with outliers removed, maybe we can make some rough estimates that will save us some time and energy. What high-level approach would you take, in this situation?
