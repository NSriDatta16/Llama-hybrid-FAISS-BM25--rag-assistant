[site]: crossvalidated
[post_id]: 463803
[parent_id]: 463798
[tags]: 
$h_\theta(x)$ can never be $0$ or $1$ for real $x$ . And, logistic regression is known to be a convex optimisation problem when cross-entropy loss is used, which means the cost is a convex function wrt parameters. Since the problem is convex, gradient descent can be used to approach the global optimum arbitrarily close, while typical implementations use second-order optimisation methods. Note: logistic regression will create a linear decision boundary again. $h(x)$ has nothing to do with feature transformation.
