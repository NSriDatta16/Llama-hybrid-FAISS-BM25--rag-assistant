[site]: crossvalidated
[post_id]: 361999
[parent_id]: 
[tags]: 
Model Selection: Goodness-of-Fit Statistic when Noise is Unknown (vs Reduced Chi-Squared)

I have data D_k and different models M_i, and I would like to calculate a goodness-of-fit statistic for undertaking model comparison between the different M_i's, in the case of unknown uncertainties sigma_k on the data points in D_k. What is the best way to calculate a goodness-of-fit statistic (derived preferably in the most general/fully bayesian way) that can be used to select between models? For the case of known/measured uncertainties/noise/error bars/sigmas, in the general case I would usually compute the full posterior plus bayesian evidence - analytically or via MCMC/nested sampling - and use the Bayes factor for model selection. Under the more restrictive assumptions of a gaussian, uncorrelated and unimodal posterior distribution I would maximize the likelihood and use a (reduced) chisq/chi-squared statistic, but this is usually a function of some known sigma_k. Some helpful references: De Sivia, Data Analysis: A Bayesian Tutorial, Section 3.5.1 McFadden, Statistical Tools, Chapters 6 and 7 (In particular, (1) implies use of a Student-t distribution rather than a chi-squared in this case - is there a meaningful equivalent of a "reduced" Student-t?) Also: Equation (31) of https://arxiv.org/pdf/1706.01629.pdf shows one potential route - " the best fit line is simply the line that minimizes the sum of the squared perpendicular distances of points from the line " - but (i) I need the value of the likelihood itself, including the prefactor, and (ii) the residuals d_i given in that case are a function of the gradient of the best-fit line, to which - unusually - I don't have access.
