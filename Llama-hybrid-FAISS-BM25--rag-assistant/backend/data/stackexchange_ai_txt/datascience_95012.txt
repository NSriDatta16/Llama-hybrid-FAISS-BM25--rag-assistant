[site]: datascience
[post_id]: 95012
[parent_id]: 
[tags]: 
Why we shift target(output) by one offset in language modelling

I have been working in sequence prediction tasks (very similar to language modelling) where I want to predict the next token(s)/item(s) given past sequence of tokens. I have always taken an approach like the below for data preparation [0,1,2,3] -> [4] [4,5,6,7] -> [8] or [0,1,2,3] -> [4,5,6,7] [4,5,6,7] -> [8,9,10,11] I have recently seen people taking output/target as one offset shifted from X. Since the goal of language modelling is to predict next token. Why and in which situation would one use this data format? For example a famous book D2l.ai provide example format of the data as X: [[27. 28. 29. 30. 31.] [12. 13. 14. 15. 16.]] Y: [[28. 29. 30. 31. 32.] [13. 14. 15. 16. 17.]] Isn't it predicting token 28 after tokens [27. 28. 29. 30. 31.] wheras actaly Y(output) should be [32] or [32,33,34,...] ? How would next prediction (which actually is 32 ) be retrieved after token 31 ?
