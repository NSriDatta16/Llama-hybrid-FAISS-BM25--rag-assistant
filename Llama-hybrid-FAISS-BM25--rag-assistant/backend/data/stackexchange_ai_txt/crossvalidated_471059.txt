[site]: crossvalidated
[post_id]: 471059
[parent_id]: 470987
[tags]: 
You know already, I believe, that in machine learning feature selection is almost always omitted. Actually, if you are asked to do it, it is to save computational resources rathen than to enhance predictions at higher computational cost. Would we do that if we had "infinite computation power"? Well, probably yes, but for the way ML works in our finite-resources world, that wouldn't really change much. As every statistician knows well, useless features do exist. You often have variables in your data set that simply don't have any effect on the outcome, there is no relation, it's just noise that will creep into predictions and worsen them. However, let's see how this works in a machine learning workflow: To measure how feature selection benefits your model, you have to implement it as an algorithm and try it on a training set, to compare the results on a developement set (or many, if you do CV). You have to chain the feature selection algorithm with the model learning one, which uses at least one form of regularization, probably two or even some more. This way you have another hyper-parameter to tune in your pipeline: I'm not going into feature selection algorithms, but they need a parameter that specifies how strict must the selection be, or at least to dictate if it shall run or not. Adding a parameter to tune makes the training algorithm more flexible, which easily means better developement set results, but also less reliable ones: tuning is a kind of learning itself, and it can overfit. Also, feature selection algorithms are either linear (which means that they can leave out useful non-linear predictors) or unstable by some other mean (like random forest feature importance, which can be computed in different ways, each of them has pros and cons), or simply too expensive (like trying to run the entire model with certain, if not all, subsets of the available predictors). Even if we don't worry about computation time and go for the most expensive method possible, regularization already does a pretty good job on reducing the effect of noisy variables, so dropping them can only improve the model by a tiny bit, and still it can worsen it if the variable actually is of some use. Cross validation is not an exact method, it can select a bad feature selector. There are such better ways to use that computational power!
