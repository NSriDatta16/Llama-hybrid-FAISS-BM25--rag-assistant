[site]: crossvalidated
[post_id]: 606637
[parent_id]: 579132
[tags]: 
I was wondering the same question and my guess (inspired by the answer above) is that the start/end vector is unique (after model training) and it is probably a linear layer. How it works (still a guess): The input is a concatenation between question and context. Inside the BERT structure, each token in the context can attend to the tokens of the question, i.e. the output embedding contains knowledge of the question. The unique start/end vector simply extract the information from the output embedding by dot-product.
