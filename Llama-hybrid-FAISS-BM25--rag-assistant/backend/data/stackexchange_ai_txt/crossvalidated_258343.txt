[site]: crossvalidated
[post_id]: 258343
[parent_id]: 
[tags]: 
How to work around short time series (24 months) when rich daily data is available

I have been tasked to put together a monthly forecast model. I'm hoping to use some of the models in scikit-learn for this. My original dataset is daily level and very rich. If I aggregate it to month-level, this gives me only 24 usable observations so many models may struggle with that. It feels like I should be able to make more use of my richer, daily dataset for my problem. I have heard somewhere (but can't remember where or whether I imagined it!) that a workaround is to create "fake" monthly data by creating rolling sums say from 26th Dec to 26th January. So for December I would have 31 "fake months", one starting on each day of December and ending on the corresponding day number in January. So for December I'd have 31 entries: 1st Dec: aggregated data for 1st Dec - 1st Jan 2nd Dec: aggregated data for 2nd Dec - 2nd Jan ... 31st Dec: aggregated data for 31st Dec - 31st Jan Specifically, is this a valid workaround to artificially increase sample size in short time series in order to train machine learning models? I can see straight off the bat that autocorrelation is a massive issue and likely falls short when next month has fewer number of days. Are there any other workarounds for working with short time series beyond "getting more data" which I can't. Have googled but nothing came up -- I think I am lacking the necessary vocabulary? Thank you
