[site]: crossvalidated
[post_id]: 416814
[parent_id]: 
[tags]: 
How do we combine probability distributions component-wise to make a more accurate probability distribution?

This subject intrigues me. My application is in the field of sports prediction. In sports prediction the experts compete who is the best - or we make it look as if they compete. So we try to find from the individual forecasts a composite forecast statistically more accurate than the best of the company of the forecasters. If we try to do that then of course we need to know the individuals past pereformances and then we need a formula to "add" them. I frequently do this: Q = P1^W1 * P2^W2 ... and then normalize the Q values to 1 and then try to work out the W1, W2 etc values for best results. By best results I mean the sum of |Log(Q)| of the winners should be maximum. Now it happens sometimes that the result is W1 = 1, W2 = 0. This means the forecaster labelled "2" is useless. How can this happen ? In two ways: One way is that "2" always copies "1" (since we don't know what these fellows are actually doing when they prepare their newspaper wrteups !). The other way is that while the "1" is doing some serious studying, the "2" is content to give us random predictions - such as the license number of the first car crossing the road ! But real life is somewhere in between. There is always some overlap (or "copying") and as for the useless ones, well we are likely to know them in advance. Now what is the ideal case ? When are the forecasters predictions totally independent ? Never really. You are likely to fancy Brazil to win the next world cup football series for more or less the same reasons as I do. But there is this thought experiment that makes them totally independent: I am a sportcaster with a known score p (0 p she tells a lie. But I am her spokesman -can't do otherwise- and what she says I say to you in the morning. Then she goes on and appears in your dream and she is doing precisely the same thing, only the random number has to be Now can this concept -with the fairies- be used to derive a better formula than mine (the P1^W1 * P2^W2 ...) ? That's the question. I have seen some writeups but I 'm not convinced. Can you solve this example for me (with the ideal case formula - the fairies concept): We have a four way event, such as a horse race. Predictor A says the probabilities are 0.6, 0.4, 0, 0. Predictor B says they are 0.3, 0.3, 0.2, 0.2. What is the ideal average ? There is the following similar thread Combining two probability scores but I 'm not satisfied with the answers given
