[site]: crossvalidated
[post_id]: 522586
[parent_id]: 
[tags]: 
Use of lowercase letters for random variables in machine learning

In statistics/probability, a random sample from a distribution $D$ is a set of i.i.d. random variables denoted by $X_1, X_2, \dots, X_n$ , each with distribution $D$ . A realization of a random sample is a set of values denoted by $x_1, x_2, \dots, x_n$ . Here the important point is the convention to use uppercase letters for random variables and lowercase letters for realizations. However, in machine learning texts, I see the use of lowercase letters to denote a random sample from a distribution (which happens to be the dataset). For example, Andrew Ng uses lowercase letters here to denote random samples and, moreover, he uses $x^{(i)} \sim \mathcal{N}(\mu,\,\sigma^{2})$ , that is, uses a lowercase letter, $x$ , for describing the associated distribution for a random variable. I can give examples from other authors. Is this a common practice for machine learning researchers? And if it is a common convention, is there some reason why ML researchers use a different notation given that there is an established convention in statistics/probability? That really creates confusion (at least for me).
