[site]: crossvalidated
[post_id]: 8603
[parent_id]: 8566
[tags]: 
Naive Bayes and Logistic Regression (Classification) are both linear classifiers. If you remove all misclassified instances, then you will allow an infinite number of separators to have 0 training error. In the case of the logistic regression, this translate to your information matrix being singular (The information matrix must be inverted at each iteration of GLM). I don't know if that's what you mean by overfit.
