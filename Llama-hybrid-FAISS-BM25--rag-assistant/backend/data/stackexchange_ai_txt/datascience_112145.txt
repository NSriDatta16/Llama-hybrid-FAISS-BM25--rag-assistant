[site]: datascience
[post_id]: 112145
[parent_id]: 112135
[tags]: 
super-interesting question! My approach to the problem would be not to do any preprocessing on the data. This is, feed all the experiments to the network with the target being the 0/1 variable corresponding to lose/win. For example, if you have a dataset like | hand of cards | game output | |-------------------|-------------| | [1, 0, 0, ..., 1] | 1 | | [1, 0, 0, ..., 1] | 0 | | [1, 0, 0, ..., 1] | 1 | | [0, 1, 1, ..., 1] | 1 | | [0, 1, 1, ..., 1] | 1 | | [0, 1, 1, ..., 1] | 1 | instead of training the model with | hand of cards | winning prob | |-------------------|--------------| | [1, 0, 0, ..., 1] | 0.66 | | [0, 1, 1, ..., 1] | 1 | I would train the model with the first dataset, and try to predict the game output. This is, instead of using a regression model using a classification model. Of course, with this approach, your dataset will have entries with the same features and different targets , however, this is not a problem , since you can interpret the output of the classification model as the probability of winning or losing. From my experience, when I've dealt with similar problems, this approach is the one that gave the best results. On the other hand, I would try an approach using decision trees, such as XGBoost or a simple RandomForest, since they use to work better with the kind of data you are dealing with.
