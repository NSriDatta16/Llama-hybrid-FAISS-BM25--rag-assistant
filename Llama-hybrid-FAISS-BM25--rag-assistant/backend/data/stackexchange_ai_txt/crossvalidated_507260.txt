[site]: crossvalidated
[post_id]: 507260
[parent_id]: 507259
[tags]: 
There are two possible approaches: Use a clustering algorithm that automatically figures out the number of clusters, like removing inconsistent edges in the Euclidean Minimum Spanning Tree. An edge $e$ is "inconsistent", if its weight $w_e$ is greater than $\mu_e + q\cdot\sigma_e$ , where $\mu_e$ and $\sigma_e$ are mean and standard deviation, respectively, of the edges that are at most $k$ steps afar from $e$ . $q$ and $k$ are tweakable parameters. Try out a clustering algorithm that requires a fixed number of clusters (like K-Means) and test the result with some "internal" clustering index . If you are looking for approximate circular clusters, the Calinski-Harabasz index might be a good choice. To find review articles about cluster indices that address this problem, do a literature search for "internal cluster validation". Here are some starting points: Overview over different internal indices: Arbelaitz, Olatz, et al.: "An extensive comparative study of cluster validity indices." Pattern Recognition 46.1 (2013): 243-256. An older study based on Monte Carlo simulations: Milligan, Cooper: "An examination of procedures for determining the number of clusters in a data set." Psychometrika 50 (1985): 159-179 A recent suggestion, specifically suited for non-circular clusters: Rojas-Thomas, et al.: "New internal index for clustering validation based on graphs." Expert Systems with Applications 86 (2017): 334-349.
