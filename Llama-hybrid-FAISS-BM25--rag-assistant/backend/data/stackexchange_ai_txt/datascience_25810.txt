[site]: datascience
[post_id]: 25810
[parent_id]: 25793
[tags]: 
Reinforcement learning is more about interacting with an environment, and while this could be posed as an RL problem, I think using Global Optimization would be a more direct approach. Essentially you want to design a cost function that describes how good a particular seating is and then use it to search the space of possible seatings. For example to solve the problem with Simulated Annealing : Design a cost function $e(s)$ that measures how good a seating arrangement is. Lower cost means better seating. Design an acceptance probability function $P(e, e', T)$ that takes the costs of seating arrangements $s$ and $s'$, and a temperature $T$, and returns a probability $P$ with the properties (a) $P>0$ even if $s'$ is worse than $s$ (b) the better $s'$ is relative to $s$, the higher $P$ is and (b) the lower the temperature, $T$, the close $P$ is to $0$ when $s'$ is worse than $s$. Set some large initial $T$ and design an annealing schedule for decreasing $T$ with the number of iterations. Start with some seating arrangement $S$. This can be random or chosen according to a greedy strategy that tries to satisfy as many constraints as possible. Repeat for $i$ in $k$ steps (for some sufficiently large $k$): Consider a neighboring state $S'$ that can be reached by randomly swapping two seated people or moving someone to an empty seat. Set $S$ to $S'$ with probability $P(S, S', T)$ Decrease $T$ according to the annealing schedule at step $i$ The simulation starting at (4) can be run once or many times saving only the best result. At the end you should arrive at close to or exactly the best possible seating arrangement.
