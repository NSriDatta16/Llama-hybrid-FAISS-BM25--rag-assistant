[site]: datascience
[post_id]: 120580
[parent_id]: 120574
[tags]: 
As mentioned Noe, UMAP is 100% for dimensional reduction, ONLY to group similar data and separate different ones, THEN we apply a clustering algorithm such as DBSCAN to identify those groups in the projected space. Multi-dimensional reduction is the most difficult part because you need to detect similarities and differences among plenty of variables and then project them in a lower dimensional space, generally in 2D. PCA was initially one of the first dimensional reduction algorithm (even if it is not exactly a dimensional reduction one) but it has a problem: it is linear. UMAP is a non-linear reduction algorithm, meaning it can detect complex correlations between features. Therefore, it uses Riemannian manifolds that are useful for representing complex, non-linear geometries that are difficult to capture with simple Euclidean distance measures. UMAP constructs a weighted graph representation of the data, where the weights between each pair of data points are determined by a distance measure that considers the geometry of the Riemannian manifold. This graph is then optimized using a gradient-based algorithm to produce a low-dimensional embedding that preserves the high-dimensional geometric structure of the data. More info: https://pair-code.github.io/understanding-umap/
