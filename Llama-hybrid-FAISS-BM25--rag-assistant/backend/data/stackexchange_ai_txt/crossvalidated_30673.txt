[site]: crossvalidated
[post_id]: 30673
[parent_id]: 
[tags]: 
Linear regression with shot noise

I'm looking for the right statistical terminology to describe the following problem. I want to characterize an electronics device that has a linear response $Y = \beta_0 + \beta_1 X + \epsilon$ where $\epsilon \sim N(0,\sigma^2_{ro})$ is a term due to the read-out noise of the device. In order to determine $\beta_0, \beta_1, \sigma^2_{ro}$ I would measure a series of responses $\{X_i,Y_i\}$ and apply the standard linear regression toolbox. But I don't know what the $X_i$ are exactly, because I use a source that is affected by shot noise. That is I know that if I set the dial on the source to a certain value $J_i$ then $X_i \sim N(\mu, \mu)$ (a Gaussian with average $\mu$ and variance $\mu$). This looks like an errors-in-variables model of linear regression ( http://en.wikipedia.org/wiki/Errors-in-variables_models ), where not for the fact that in order to characterize my device over its entire input range, during the measurements I have to change the value of $J_i$, and now the variance of the $X_i$ is not fixed, but it depends on $X_i$ (through J_i), although because of the shot noise if $X_i=X_j$ this does not mean that the variance of $X_i$ is the same as the variance of $X_j$. What is this model called, and are there articles where I can find out such a problem is approached? Or am I formulating in the wrong manner?
