[site]: crossvalidated
[post_id]: 28856
[parent_id]: 28287
[tags]: 
I suggest to use Expected Utility or R-score . Assume your model has created an ordered list of recommendations where the first item is the one the user is most likely and the last is the one the user is least likely interested in. Let's say that this recommendations are specified by $r_i$ where $i$ is the position in the list. Expected utility for a particular user u is now defined as: $R_u=\sum_{i=1}^{n}\frac{f_u(r_i)}{2^{\frac{i-1}{\alpha-1}}}$ where ... $f_u(r_i)=1$, if the recommended item $r_i$ is the user's library, else 0 $\alpha$ specifies the slope of the decay. The smaller alpha, the greater the slope. This metric measures how likely it is that a user will view a recommended item, assuming a list of items is recommended to him. If the item of interest is placed at a very high position, it is unlikely that the user will bother to scroll/look that far, even if it exactly what he/she wanted. In this sense, $\alpha$ specifies how patient the average user is. To calculate the R-score for a set of users, it is recommended to normalize the R-score per user beforehand. The resulting score is $R =\sum_u\frac{R_u}{R_u^*}$ where $R_u^*$ is the maximum R-score you can achieve for one user. That is, given a user has k items in his library you want to predict, the items at the first k positions are exactly these ones. For more metrics or as a general read I recommend Evaluating Recommendations Systems by Shani & Gunarwadana
