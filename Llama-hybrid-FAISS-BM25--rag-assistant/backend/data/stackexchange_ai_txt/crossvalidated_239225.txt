[site]: crossvalidated
[post_id]: 239225
[parent_id]: 
[tags]: 
Confusion to understand the Pooling in CNN

I am trying understand Pooling part from the Deep Learning . Ian Goodfellow and Yoshua Bengio and Aaron Courville. 2016:. I am confuse in this figure: A pooling unit that pools over multiple features that are learned with separate parameters can learn to be invariant to transformations of the input. Here we show how a set of three learned filters and a max pooling unit can learn to become invariant to rotation. All three filters are intended to detect a hand-written 5. Each filter attempts to match a slightly different orientation of the 5. When a 5 appears in the input, the corresponding filter will match it and cause a large activation in a detector unit. The max pooling unit then has a large activation regardless of which pooling unit was activated. We show here how the network processes two different inputs, resulting in two different detector units being activated. The effect on the pooling unit is roughly the same either way. What I understand from this text is: We have an input image '5' and we have 3 filter of different orientations. When the input image is convolve with the filters and it matches with the first filter. Therefore, it cause a large activation in the detector unit. When it goes to the pooling layer, it will select the maximum regardless of which unit of activated. Please correct me if I am wrong to understand this part. For the second part: This principle is leveraged by maxout networks (Goodfellow et al., 2013a) and other convolutional networks. Max pooling over spatial positions is naturally invariant to translation; this multi-channel approach is only necessary for learning other transformations. I couldn't this part. Anyone, please explain this part in easy way or with examples.
