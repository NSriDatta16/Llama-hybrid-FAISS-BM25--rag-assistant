[site]: crossvalidated
[post_id]: 576797
[parent_id]: 
[tags]: 
Cross Validation for Time Series Classification (Not Forecasting!)

Is it possible to use regular k-fold cross validation where the folds contain entire time series in time series classification? I'm asking because most sources discussing cross validation with time series say a specific rolling window approach should be used. I'm doing a time series classification project where I have a large number of multivariate time series of equal length with the same dimensions. I understand that one should not arbitrarily split the time series themselves in the time dimension, and that a sliding window should be used in such a case (where the folds are supersets of preceding folds). However, I do not understand why the folds cannot contain entire time series (e.g training on Time Series 0-100, testing on 101-200, then training on time series 101-200 and testing on 0-100). I also noticed that in sktime (a python package for time series analysis) the rolling window approach to cross validation splitting was only implemented in their forecasting module, and not in their classification module. Therefore I'm wondering if the sliding window approach to cross validation is only relevant for forecasting tasks where you perhaps only have one time series (and therefore must split in the time dimension) and not for time series classification (where you have multiple entire time series that can be used in distinct folds).
