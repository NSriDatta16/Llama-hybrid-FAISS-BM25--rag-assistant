[site]: crossvalidated
[post_id]: 43735
[parent_id]: 43730
[tags]: 
There is quite a lot of research going on right now on how to best tune the parameters of networks. One idea is to model the landscape of the generalization error with a Gaussian process and then do a good guess on what mightbe the best next set of parameters to try. Recent work includes Random Search for Hyper-Parameter Optimization , Bergstra et al, Algorithms for Hyper-Parameter Optimization , Bergstra et al, Practical Bayesian Optimization of Machine Learning Algorithms , Snoek et al. You can find theoretical work on your approach in the first link and extensions in the other two. An important point is that you divide your data into training, validation and test as usual. But instead of letting the human do the tuning, let it be done by the algorithm. Also, do not use the validation set in the algorithm, otherwise you might overfit.
