[site]: crossvalidated
[post_id]: 223657
[parent_id]: 223622
[tags]: 
This is a Hidden Semi-Markov Process (HSMM), the "hidden" version of a semi-Markov process . The time/duration spent at a single state is called the sojourn time, and the HSMM specifies the distribution on the sojourn time for each possible state. They have been studied in the literature. For instance, such a model has been used for speech detection, where it was found that the Weibull distribution is a better fit for sojourn times than the geometric distribution assumed by ordinary HMM's. There are algorithms in the literature for inferring model parameters of a HSMM. For instance, one can use the EM algorithm to build an analog/variant of the Baum-Welch procedure for inferring model parameters. It looks like the calculations get a bit messy, though. Fortunately, there's also a R package, hsmm , as described in the hsmm documentation and an accompanying research paper . It implements analogs of the Viterbi and Baum-Welch algorithms. However, it is a bit limited on what distributions it supports: for instance, it doesn't support Weibull-distributed sojourn times. Another pragmatic approach that might or might not work in any particular setting is to use standard HMM algorithms and tweak their output. In particular, given a set of output sequences: Use Baum-Welch or similar algorithms to learn a HMM model (i.e., via maximum-likelihood estimation), treating sojourn times as geometric for the moment (even though may not actually be in real life). For each output sequence, use the Viterbi algorithm to find the most likely sequence of states. Based on this, calculate the sojourn time spent in each state. For each state $q_i$, fit a distribution to the sojourn times (i.e., choose parameters for the sojourn time distribution that best fit the observed durations from step 2 above). Construct a HSMM, using the sojourn time distributions calculated in step 3 and the between-state transition probabilities calculated in step 1. You can even iterate steps 2-4 until convergence, using re-estimated parameters (computed from inferred state sequences) to adjust the model parameters. Here's a survey/overview paper on the subject that seems useful: Shuh-Zheng Yu. Hidden semi-Markov models . Artificial Intelligence, vol 174, pp.215-243, 2010. [ pdf ]
