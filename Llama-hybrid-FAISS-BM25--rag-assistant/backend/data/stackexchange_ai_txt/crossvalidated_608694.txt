[site]: crossvalidated
[post_id]: 608694
[parent_id]: 
[tags]: 
My machine learning model has precision of 30%. Can this model be useful?

I've encountered an interesting discussion at work on interpretation of precision (confusion matrix) within a machine learning model. The interpretation of precision is where there is a difference of opinion so my description centers a little bit simplified around precision. The problem discussed with some numbers for reference: Suppose we have a machine learning model A for binary classification. The training dataset has 100.000 datapoints. The data is quite imbalanced: 5% is classified as 1, 95% as 0. The model is tested on another (unseen) dataset of 50.000 datapoints. For evaluation a confusion matrix is made to evaluate model A. Precision (TP/(TP+FP) = 30%. From here on there is a difference in view between the data scientists (both camps are intelligent people). Group 1: We think the model is useful. While precision is low (30%), it is quite higher than random (5%). Therefore the model has some value. We can use the output the model generates and can expect the model to pinpoint datapoints which on average have a 30% probability of being a 1. Group 2: You can not use this model. Precision needs to be at minimum 70-80% for a model to be useful. The point is, precision only measures the model, and not the underlying data. Therefore one can only use models with a minimum of 70-80% precision. Balanced or imbalanced data doesn't matter. I myself find myself more in group 1. So if someone can explain why group 2 is right (if they are right) I would be happy. More context : We produced a model to pinpoints locations where inspectors can find objects with on error. In the past ( al the datapoints) inspectors found on average in 5% of their visits an error. Model A had a precision of 30%. So the reasoning of group 1 is if inspectors only go to these 30% locations pinpointed by the model they will on average find more errors than the historic 5%. I should ad that only about 500 visits per year will be done, false negatives have no associated costs. So any precision gain more than 5% would be good.
