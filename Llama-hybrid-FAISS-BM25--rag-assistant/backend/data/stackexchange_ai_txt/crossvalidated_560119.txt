[site]: crossvalidated
[post_id]: 560119
[parent_id]: 
[tags]: 
Time series k-fold cross validation for classification

I'm trying to understand something. I undertand what I want and the logic behind it, but I'm doubtful about what it is 'officially' and if it's right. I used this similar question as input, but my question doesn't assume that years are independent and this it's a classification problem. Context: I have a dataset of purchases of a certain product of clients per month. I need the predict the sales of that product for the next month. I want to use multiple models (XGBoost, RF, etc.) with k-fold cross validation and compare them. So, each fold in k-fold will be a month such as: (Assuming that the present month is month 12 and we are looking to predict month 13): Step 1: We train the models: fold 1 : training [1 2 3 4], test [5] fold 2 : training [2 3 4 5], test [6] fold 3 : training [3 4 5 6], test [7] fold 4 : training [4 5 6 7], test [8] fold 5 : training [5 6 7 8], test [9] fold 5 : training [6 7 8 9], test [10] Step 2: We assess twice the models on out-of sample data and choose one: hold-out month: test [11] hold-out month: test [12] Step 3: We implement the model Implementing the model: predict_next_month [13] Questions: Given an algorithm, the model choosen is one of the k-fold models or some mix of those k-fold models? If it's a mix, how is the "learning" mixed? If it's one of the k-fold models, how it's chosen? I can't find any sklearn code to do this example (found this built-from-scratch code example). Should I start learning how to build models (a.k.a. write the code of the algorithm instead of using sklearn ML codes) from scratch in order to be able to customize them at my problem? ( this answer shows my logic and it says "shouldn't be too hard to code up", but I don't find any good first-step to start in python, in R I found it here ) If there is a trend in the time series, there is no need to remove the trend as there is no need to extrapolate (because it's a classification problem). If we would need to extrapolate (if it were a regression problem, like in this answer) we would need another alternative to tree-based models because tree-based models can't predict a value bigger or smaller than the value in their training set). Is this conclusion FULLY right? PS: After we will predict month 14, month 15, month 16, and so on.. PS2: I'm considering training at least a full year and maximum two years, I just used four months for training in this example for simplicity.
