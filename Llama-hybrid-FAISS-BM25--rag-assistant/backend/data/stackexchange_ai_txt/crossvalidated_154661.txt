[site]: crossvalidated
[post_id]: 154661
[parent_id]: 
[tags]: 
Generating features: What level of interaction?

I have multi (3) level data indexed by i,j,t. As such, I can generate fixed effects (dummies) for either ij, it, or jt, (and still achieve identification). I can also do i,j,t separately as well. I can also interact all these with continuous variables. If I am implementing machine learning algorithms (stepwise regression, lasso, random forest, SVM), is there a guideline on how to generate features? Are more refined dummies going to be better always, even some might be perfectly collinear? (Will R packages typically automatically drop perfectly collinear features?) I know this is a broad question and it depends on the ML technique at play (for example, my understanding is that if I use a flexible kernel with SVM, higher order and interactions need not be generated a priori by me.), but is this ever discussed anywhere in ML, such as in Hastie, Tibshirani, and Friedman book, "The Elements of Statistical Learning"?
