[site]: crossvalidated
[post_id]: 279163
[parent_id]: 
[tags]: 
Cross validation in ExtraTreesRegressor

I've read that Random Trees do not require cross validation as it's implicitly integrated into the forest growing algorithm. I'm using Scikit's ExtraTreesRegressor on about 15K rows and 300 columns, split into 85% training data and 15% test data. The test results I obtain are quite satisfying but validation on training set brings even better scores which surprises me as I expected both training and test scores to be rather similar. I would like to avoid overfitting as I want to use my estimator to predict y values also for my training set and compare them to the real values. Here's the validation output: mean (whole dataset) 1713.7427037 std (whole dataset) 1082.71436419 Coefficient of determination on training set: 0.998891590121 Average coefficient of determination using 2-fold crossvalidation: 0.988970576187 oob_score : 0.991159257778 TRAIN - Evaluation mean of train set 1715.27367884 mean_squared_error 1309.10693306 mean_absolute_error 13.291585397 median_absolute_error 4.64 TEST - Evaluation mean of test set 1705.07049892 mean_squared_error 6304.20435691 mean_absolute_error 28.4441070137 median_absolute_error 9.62 The params of my ExtraTreesRegressor estimator are: n_estimators=50, bootstrap=True, criterion='mse', warm_start=False, min_samples_leaf=1, oob_score=True, random_state=33 Am I missing something?
