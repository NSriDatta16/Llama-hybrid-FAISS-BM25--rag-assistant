[site]: crossvalidated
[post_id]: 642727
[parent_id]: 
[tags]: 
How is data generated when using an improper prior

Let $X$ be an $\mathcal{X}$ valued random variable. We are doing Bayesian statistics. Suppose that $\theta$ is a $\Theta$ valued random variable with known prior distribution $\Pi$ and that the regular conditional probability $P_{X \mid \theta}$ is known. If $\Pi$ is proper (i.e. $\Pi(\Theta)=1$ ), then we consider $X$ as a random variable whose distribution $P_X$ is, for any measurable $A \subseteq \mathcal{X}$ : \begin{equation} P_X(A) = \int_{\Theta} P_{X \mid \theta = u}(A) d \Pi(u) \end{equation} That is, rather than the frequentist approach where $P_X$ is based on one true $\theta$ , here we model $P_X$ as an integral of all possible values of $\theta$ according to the prior chosen. Edit : If the sample size is $n$ , then the usual assumption is that $X_1$ , $\ldots$ , $X_n$ are independent identically distributed when conditionned on $\theta$ . So we calculate, any rectangle $A = \prod_{i=1}^n A_i$ with measurable $A_i \subseteq \mathcal{X}$ : \begin{equation*} \begin{split} & P_{X_1, \ldots, X_n}(A) = \int_{\Theta} P_{X_1, \cdots, X_n \mid \theta = u}(A) d \Pi(u) = \int_{\Theta} \prod_{i=1}^n P_{X_i \mid \theta = u}(A_i) d \Pi(u) \\ & = \int_{\Theta} \prod_{i=1}^n P_{X_1 \mid \theta = u}(A_i) d \Pi(u) \end{split} \end{equation*} So, the question is, how is $X$ generated if we are using an improper prior ? Given the discussion above, it does not feel like a natural generalization because $P_X$ would not be a probability distribution. Do we just think about $X$ as a generic measurable function ? I know that for practical purposes we need to consider improper priors like non-informative prior. But is there any theoretical motivation for improper priors?
