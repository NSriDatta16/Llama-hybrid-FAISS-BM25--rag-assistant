[site]: datascience
[post_id]: 112143
[parent_id]: 112126
[tags]: 
SVM are not meant to solve "arbitrarily long" classification problem, therefore you have few choices: use PCA for sequences, however it takes very long since it has to build a giant matrix over which it can perform PCA change model, and pick a better suited one (eg RNN) pad and cut your data (most often is not needed the whole phrase to predict the output) introduce some prior knowledge, for example order the most recurrent words, and remove all of those that don't add anything to the meaning (be careful, this might lead to many problems, for example if you remove "not") use recurrent autoencoders, to transform a sentence to a fixed size vector, over which you can perform any ML algorithm (but this might cause some problem from the POV of explainability) In my opinion, cut&pad is the best option to start with, simple to implement and often very powerful, but this might change from context to context
