[site]: crossvalidated
[post_id]: 106212
[parent_id]: 106211
[tags]: 
Although not a method for ensembles for ensembles, I see many parallels with: Caruana, Rich, Alexandru Niculescu-Mizil, Geoff Crew, and Alex Ksikes. "Ensemble selection from libraries of models." In Proceedings of the twenty-first international conference on Machine learning, p. 18. ACM, 2004. Available without a paywall here: http://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml04.icdm06long.pdf The idea is to construct an ensemble from a diverse range of classifiers such as SVMs, ANNs, KNN and decision trees. Furthermore, rather than optimizing the parameters of each of the individual classifiers, simply include one classifier for each parameter value in the library from which the ensemble is constructed. The resulting ensemble is called a heterogeneous ensemble, contrasted with more common homogeneous ensembles like random forests where the base learners are all of the same type. Such heterogeneous ensembles have been shown to achieve state-of-the-art classification performance in credit risk. See Lessman et al (2013) "Benchmarking state-of-the-art classification algorithms for credit scoring: A ten-year update" available here: http://www.business-school.ed.ac.uk/waf/crc_archive/2013/42.pdf
