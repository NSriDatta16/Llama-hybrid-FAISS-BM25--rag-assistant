[site]: crossvalidated
[post_id]: 34379
[parent_id]: 
[tags]: 
need help understanding Dirichlet (coursera's PGM class week 7 - Bayesian prediction)

I'm trying to work through Coursera's probabilistic graphical models class (week 7: Baeysian prediction) and a have several questions. In the Dirichlet distribution, I'm having difficulty trying to understand why there's a -1 in theta's exponent: $$P(\theta)=Dir(\alpha_1, ..., \alpha_k) = \frac{1}{Z} \cdot \prod_{j} \theta_{j}^{\alpha_{j}-1}$$ How do you get from here: $$P(X)=\int_{\theta}P(X|\theta)P(\theta)d\theta$$ to here: $$P(X=x^{i}|\theta) = \int_{\theta} \frac{1}{Z} \cdot \theta_{i} \prod_{j} \theta_{j}^{\alpha_{j}-1}$$ Also, how do you step through the integration for the following?: $$\int_{\theta} \frac{1}{Z} \cdot \theta_{i} \prod_{j} \theta_{j}^{\alpha_{j}-1} = { \alpha_{i}\over{\sum_{j} \alpha_{j}} }$$ These are the lecture notes . My questions refer to the first slide.
