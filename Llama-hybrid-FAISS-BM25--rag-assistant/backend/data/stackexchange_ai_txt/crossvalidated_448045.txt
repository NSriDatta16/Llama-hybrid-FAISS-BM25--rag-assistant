[site]: crossvalidated
[post_id]: 448045
[parent_id]: 
[tags]: 
Negative Binomial regression: effect of scaling input data on model's output

I have implemented a neural network for time series forecasting. The time series consists of count data, so I chose to model it with a negative binomial distribution. My network is an autoregressive model that, given a number of time steps, outputs the mean $\mu$ and dispersion $\theta$ of the negative binomial distribution of the next time step: $$ \Pr(X = x) = \binom{x+\theta-1}{x} (1-p)^\theta p^x $$ $$ \Pr(X = x) = \binom{x+\theta-1}{x} \left(\frac{\mu}{\theta + \mu}\right)^\theta \left(\frac{\theta}{\theta + \mu}\right)^x $$ To help with training, I want to scale the input data (e.g., divide each element of an input timeseries by the timeseries average value $k$ ). If I do so, I know I have to multiply the $\mu$ predicted by the network by $k$ to bring the mean back into the original scale. My question is what I have to do with $\theta$ to remove the scaling effect.
