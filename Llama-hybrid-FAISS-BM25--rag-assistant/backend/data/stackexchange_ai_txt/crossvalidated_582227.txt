[site]: crossvalidated
[post_id]: 582227
[parent_id]: 
[tags]: 
Train a model subject to max error

I would like to train a neural network by minimizing a loss over samples (as usual), but doing so in a way that the maximum error is bounded. What options do I have? Some that come to mind are: preferential sampling loss modification (e.g. minimize loss*loss instead of loss, which is a softening of $L_\infty$ ) Are there other methods? How to best (or easily) implement these ways?
