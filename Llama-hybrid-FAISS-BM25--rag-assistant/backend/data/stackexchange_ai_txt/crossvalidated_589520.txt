[site]: crossvalidated
[post_id]: 589520
[parent_id]: 
[tags]: 
Does the concept of "confidence" apply to text generation tasks?

I'm currently using the T5 model to solve a text classification task as text generation. Specifically, I'm using the T5ForConditionalGeneration model from the HuggingFace Transformers library. What I'm wondering is, is there a way that we can use the concept of "confidence" for this kind of setting? I'm asking because some samples I'm using are either mislabeled or don't have enough information to effectively make a classification decision. I was hypothesizing that the model's "confidence" for such samples would be relatively lower, and we could use such a measure to prevent the model from making predictions on those samples or something. I don't think that the concept of "confidence" would apply to text generation, but was wondering if there's any other way we could make such decisions. Thanks!
