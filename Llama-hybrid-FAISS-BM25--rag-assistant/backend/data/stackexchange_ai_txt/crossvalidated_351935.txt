[site]: crossvalidated
[post_id]: 351935
[parent_id]: 351904
[tags]: 
No, they are not the same thing. In the first example, bias refers to the intercept of a linear model. It is simply a parameter just like $w$ that needs to be learned. In the second example, bias is the difference between the ground truth and the expected prediction of the model. Here, the expectation is taken over different training sets from the same ground truth data distribution. It expresses how much is the specific model going to be wrong on average, thus the name bias .
