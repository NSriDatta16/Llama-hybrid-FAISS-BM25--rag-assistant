[site]: crossvalidated
[post_id]: 602252
[parent_id]: 
[tags]: 
Can the observation function in a POMDP be a function of the previous state?

I would like to model my problem with a Partially Observable Markov Decision Process (POMDP) but I have as an observation the previous state $o_t = s_{t-1}$ . However, I see in all formal definitions of POMDPs that the observation function can only be a function of the current state, and previous action: $o_t=\mathcal{O}(s_t, a_{t-1})$ and not a function of the previous state. A imagine a simple way could be to define $\bar{s_t} = (s_t, s_{t-1})$ but I was wondering if there exists some cases where we can have $o_t=\mathcal{O}(s_t, a_{t-1}, s_{t-1})$ . Thank you very much for your help!
