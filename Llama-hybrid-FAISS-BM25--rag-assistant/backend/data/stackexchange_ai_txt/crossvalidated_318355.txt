[site]: crossvalidated
[post_id]: 318355
[parent_id]: 
[tags]: 
Are Bayesian models just frequentist models with one more layer?

We all know the formula for Bayesian inference: $$P(\theta|\mathbf{x}) = \frac{P(\theta|\gamma)P(\mathbf{x}|\theta)}{P(\mathbf{x})}$$ In this approach, we replace a fixed $\theta$ with a latent, random effect $\theta \sim P(\theta|\gamma)$ with $\gamma$ being what are called "hyperparameters". Now, in the context of inferring $\theta$, this approach differs markedly from the frequentist approach, where our only source of randomness comes from the data generated by the true model. However, what if we were to try to estimate $\gamma$? -- it seems that we've simply "plugged in" an estimate for $\gamma$ and went from there; yet, we are assuming $\gamma$ is fixed. How is this not just like the frequentist paradigm? In other words, have we used Bayes theorem to simply move the frequentist aspect up one level, where we care less about the accuracy or actual value of the hyperparameter?
