[site]: datascience
[post_id]: 43197
[parent_id]: 43195
[tags]: 
Yes embedding works on unseen images. That is the point of the approach - instead of learning to classify each face in the training set directly, the model learns a vector that is intended to be: far apart when the face itself is different similar when the face is the same, but other items in the image - e.g. background, hair style etc - are different In order to use embeddings to recognise someone, you need one or more sample images of that person, so that you can generate a target embedding. Then you can predict any new image that generates a new embedding close enough to the target embedding(s) to be an image of the same person. This can still suffer usual problems of overfitting to training set. So it is important to understand what training data was used for the model. Embeddings generated from images that are very different from the training data will not be as reliable as embeddings of images that are similar to the training data.
