[site]: datascience
[post_id]: 121274
[parent_id]: 
[tags]: 
Image based ML paradigms where input vector integrates pixel intensity with pixel coordinates

Are there image based machine learning formulations where the input is not just the plain 2D image grid but one where pixel intensity $I(x,y)$ , at position $(x,y)$ is coupled with the actual position information $(x,y)$ . This is so that the final input vector to the machine learning problem may be a set of triplets $(I(x,y),x,y)$ . This is applicable to situations where the sensor grid is irregular and not necessarily rectangular for example. A paper that gets close is this "Dynamic Graph CNN for Learning on Point Clouds" https://arxiv.org/abs/1801.07829 But I am hoping there is work on irregular 2D sensor/image grids. Any references to papers would be greatly appreciated.
