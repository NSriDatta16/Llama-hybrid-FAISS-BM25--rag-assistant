[site]: datascience
[post_id]: 30041
[parent_id]: 
[tags]: 
Generator loss not decreasing- text to image synthesis

I am implementing Scott Reed's paper on Generative Adversarial Text to Image Synthesis.( https://arxiv.org/pdf/1605.05396.pdf ) The dataset I am using is a simple one, consisting of images of circles, equilateral triangles and rectangles. The caption of for example a circle is "This is a circle of radius 10". Instead of the GAN used in the paper, I am using a BiGAN(this shouldnt make that much of a difference in the losses) and training it for 200 epochs. The fake images generated by the generator look quite real in the end. However, the generator loss doesn't seem to decrease, while the discriminator loss decrease fairly rapidly. I can attach more details if needed. Here are the plots of both the generator and the discriminator loss: https://i.stack.imgur.com/li2A7.jpg Any ideas as to why this is happening?
