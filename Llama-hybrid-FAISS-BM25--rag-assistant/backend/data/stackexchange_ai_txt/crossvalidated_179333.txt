[site]: crossvalidated
[post_id]: 179333
[parent_id]: 179315
[tags]: 
You're using two different meanings of significance here. how do we know the difference in term of accuracy is significant enough? Here you're talking about practical impact, or effect size. What effect size is important? That really depends. If your financial model gives better results to the extent that you're earning an extra 100.000€/year, but switching models costs 1.000.000.000€, the 100.000€/year is not sufficiently better. If your machine learning system saves the lives of 1% of the treated people (by detecting the disease early) and the disease affects 1.000.000 people/year, it probably is an important effect. Note that you're talking here about degrees of significance; something can be more or less significant than something else. statistical test Now this is a completely different question. Typically, statistical tests give only binary results, they're only compared to a pre-defined threshold (e.g. the famous p This signal may have zero practical importance, but it seems to be there. Now you can do significance tests to compare classifiers and machine learning models. This depends on the type of model, and by what measure you want to evaluate them. Very often, bootstrapping is indeed used here. However, make sure you're truly interested in significance in the statistical sense, not the practical, effect size sense.
