[site]: crossvalidated
[post_id]: 544691
[parent_id]: 543897
[tags]: 
I studied briefly this problem a few years ago, and my conclusion at the time was that there is no gold standard for calibrating multi-category forecasts yet. There are some methods to calibrate the probabilities directly in the simplex space that involves using a Dirichlet distribution, but to the best of my knowledge, most approaches consist of a reduction to binary calibration tasks followed by the coupling of the adjusted probabilities. From multiple categories to multiple binary tasks First, there are many ways of decomposing a multi-category problem to binary tasks: ”all pairs”: e.g. 0 vs 1, 0 vs 2, … 1 vs 2, 1 vs 3, …, 2 vs 3 … 18 of 55 ”one-against-all”: e.g. 0 vs all, 1 vs all, … or something else. For instance, for an ordinal score, it would be interesting to do $y \leq 0$ vs $y > 0$ , $y \leq 1$ vs $y > 1$ , etc. (i.e. using the cumulative distribution function). In general, any decomposition can be represented by an Error-Correction Output Coding (ECOC) matrix. Calibrating the binary problems Then you can calibrate these binary tasks using your prefered method: Platt scaling, isotonic regression, beta calibration, etc. Coupling the probabilities And finally, the calibrated forecasts for each binary task needs to be coupled together. This is not trivial because you want to make sure the probabilities are a simplex (all positive and sum to one), without adding additional bias to your calibrated binary probabilities. In a "one-against-all", if $p_i$ is the calibrated probability for the binary problem " $i$ vs all", then you can derive a multi-category calibrated forecast $\hat{p_i} = \frac{p_i}{\sum_j p_j}$ . Note this is probably what OneVsRestClassifier is doing, but do check the documentation first. If your data is ordinal and you choose the binary classification task corresponds to predicting the cumulative distribution function, you can use Frank et Hall's method [1] to derive the multi-category calibrated forecasts. Essentially, this consist in noticing that for $y \in \{1...K\}$ , $P(y = 1) = P(y \leq 1)$ , $P(y = K) = 1 - P(y and for $1 , $P(y = k) = P(y \leq k) - P(y \leq k -1)$ . The approach may lead to negative probabilities because the calibration of the different binary tasks are independent, but it's possible to slightly modify the equations using conditional probabilities to address this problem (see section 2.4 in [2] for example). Other approaches In the problem I encountered a few years ago, I ended up realising that I could obtain calibrated probabilities by using a more appropriate model. Usually, I find calibrating probabilities is the answer to the wrong problem. If you have predictions that are not calibrated, more often than not there is a problem with your model, so if you really care about calibration, you may want to consider using a model that is likely to yield calibrated probabilities in the first place. For instance, you could consider using multinomial logistic regression or ordinal logistic regression (with or without regularisation). References [1] E. Frank and M. Hall, “A simple approach to ordinal classification,” in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 2001, vol. 2167, pp. 145–156. [2] J. S. Cardoso and J. F. Pinto Da Costa, “Learning to classify ordinal data: The data replication method,” J. Mach. Learn. Res., vol. 8, pp. 1393–1429, 2007.
