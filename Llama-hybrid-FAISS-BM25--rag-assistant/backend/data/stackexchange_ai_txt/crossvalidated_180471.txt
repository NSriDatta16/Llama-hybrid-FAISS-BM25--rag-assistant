[site]: crossvalidated
[post_id]: 180471
[parent_id]: 
[tags]: 
remove outliers before doing regression

I'm having troubles eliminating the outliers out of my data, before running a regression through it. data set structure: | price | livingArea | area | discrete | dummy | what I'm doing: I'm assuming that 60% of the price can be explained by the livingArea , 20% of it by the area and the rest by dummy and discrete . After this I'm trying to find and remove the outliers of priceForLivingArea/livingAreaSqm and priceForArea/areaSqm . For the outlier detection I'm using the IQR , Q1 and Q3 . After removing the "outliers" I'm running a rlm regression through the data. Also I customized the regression with following parameters: maxit = 100000, method = "MM", psi = psi.huber, acc = 0.000001,test.vec = "resid", k2 = 1.345, scale.est = "proposal 2" priceForLivingArea In a minimum average case scenario (data), everything works fine but when the data distribution is bad, the result is horrible. Also I tried to remove the variable area from the regression, if skewness((priceForArea/area)) > 1.5 but this approach proved itself to be not useful. code: indexesToRemove 0) { data (qnt[2] + H)))) } plot: As you can see in the plot, in this case, my approach wasn't really useful. questions: (a) is it really justifiable to remove the outliers? (b) is there a better way of removing the outliers, than what I'm using now? (c) if I'm removing the outliers, is there still the need to use a robust regression method? UPDATE - correlation matrix price livingArea area discrete dummy price 1.0000000 0.4424315848 0.22561863 0.5260871713 0.18492175 livingArea 0.4424316 1.0000000000 0.23964809 -0.0002193865 0.03934906 area 0.2256186 0.2396480895 1.00000000 0.2300601225 0.07928183 discrete 0.5260872 -0.0002193865 0.23006012 1.0000000000 0.22303584 dummy 0.1849217 0.0393490626 0.07928183 0.2230358365 1.00000000 UPDATE - model purpose the purpose of my model is prediction.
