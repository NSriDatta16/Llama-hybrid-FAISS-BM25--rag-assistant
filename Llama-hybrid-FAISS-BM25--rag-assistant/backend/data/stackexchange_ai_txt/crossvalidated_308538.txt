[site]: crossvalidated
[post_id]: 308538
[parent_id]: 
[tags]: 
Model (and algorithm) selection when variance is high

I work on a classification task in which the uncertainty regarding some groups of entities is pretty high, i.e. there is little information on these entities in the data. I am trying to select a model and an algorithm for this problem. Regarding model selection, I experience that the validation curves have a high standard deviation. An example is this one here (this is from a decision tree and this is the "min_samples_split" in sklearn): An even more extreme example is here where we basically cannot distinguish over the entire space (this is the max_feature parameter of a random forest classifier): Generally, one could do one of the following: Select the model with the highest mean score. But, in the decision tree environment I am lookin at, my feeling is that his model overfits the data. Select a conservative model, i.e. select, for instance, the model that is the most parsimonious (most conservative) within one standard deviation of the mean of the model with the highest mean score. But, in the decision tree environment I am looking at, my feeling is that this model is too conservative. Are there any methods/ tools to approach this situation. Similar, in the space of algorithm selection when I estimate the performance of an algorithm with a nested cross validation approach, I find that mean scores of algorithms are closely together (i.e. within one standard deviation). Again, are their any tools to approach algorithm selection in this case? Thanks
