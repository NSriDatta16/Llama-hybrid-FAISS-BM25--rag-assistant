[site]: crossvalidated
[post_id]: 411428
[parent_id]: 139181
[tags]: 
I am not sure I fully understand the notation that my search results are using to describe Lyapunov exponents, but it reminds me of a Dobrushin coefficient for a Markov chain: $$ \delta(K) = \frac{1}{2} \sup_{(x,x')} \left\Vert K(x,\cdot) - K(x',\cdot) \right\Vert_{TV}, $$ which can be useful for showing certain chains are ergodic. Note: some books define it without the half in the front, and use a $\beta$ instead of a $\delta$ . The smaller this number is, the faster the chain forgets its past, or the closer the observations are to iid. This is because you can show that, for two probability measures $\mu$ and $\nu$ , $$ \left\Vert \mu K - \nu K \right\Vert_{TV} \le \delta(K)\left\Vert \mu - \nu\right\Vert_{TV}. $$ Because $0 \le \delta(K) \le 1$ for any kernel $K$ , this is saying that applying the kernel to two measures can't make them farther apart, and might even make them closer. This sort of resembles the first equation on here[ https://en.wikipedia.org/wiki/Lyapunov_exponent] . You can see this doesn't really have anything to do with precision. This is because $\mu$ and $\nu$ may have small or large precision, and it doesn't change anything that we're talking about here. Edit Yeah, we're dealing with long run stability, not dispersion/variance/precision. Meyn and Tweedie talk about some connections between Markov chains and deterministic dynamical systems on page 17. They describe the one that arises "most naturally" is based on the sequence of marginal distributions $\mu P^k$ , where $P$ is some transition kernel, and $\mu$ is an initial measure. On page 141, in the chapter on Feller chains, they define the dynamical system $(P, \mathcal{M},d_m)$ to be stable in the sense of Lyapunov if for each measure $\mu \in \mathcal{M}$ $$ \lim_{\nu \to \mu}\sup_{k \ge 0}d_m\left(\nu P^k, \mu P^k \right) = 0. $$ $d_m$ here is some distance between measures. The TV norm I discussed earlier is one such example.
