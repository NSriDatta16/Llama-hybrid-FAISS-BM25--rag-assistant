[site]: crossvalidated
[post_id]: 257326
[parent_id]: 257314
[tags]: 
To summarize the various comments and answers so far: If the predictions are on data that was not part of the training sample, there could be a systematic difference between the training data and the prediction data. For example, if you are fitting time-series data and the data contains an upward-curving trend, then predicting the future from the past with a linear model will yield under-predictions on average. If the model always under-predicts on training data (or even just on average), it could be a less commonly used variety of linear model, such as a quantile regression model; or it might not contain an intercept (or terms which can linearly combine to form an intercept). If the model is standard linear least squares and does contain an intercept or equivalent spanning terms, then Benjamin's post is correct. The phenomenon you observed cannot possibly happen. So there must be an error in the computational code used for the model's training or prediction.
