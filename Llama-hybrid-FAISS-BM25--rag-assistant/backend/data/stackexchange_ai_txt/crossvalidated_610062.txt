[site]: crossvalidated
[post_id]: 610062
[parent_id]: 311360
[tags]: 
here is e.g. of OLS non-linear curve but linear in parameters. Just consider OLS assumptions e.g. here : OLS Assumption 1: The regression model is linear in the coefficients and the error term OLS Assumption 2: The error term has a population mean of zero OLS Assumption 3: All independent variables are uncorrelated with the error term. This assumption is also referred to as exogeneity. When this type of correlation exists, there is endogeneity. OLS Assumption 4: Observations of the error term are uncorrelated with each other OLS Assumption 5: The error term has a constant variance (no heteroscedasticity) OLS Assumption 6: No independent variable is a perfect linear function of other explanatory variables OLS Assumption 7: The error term is normally distributed (optional) So, if you do not care about errors & stat.significance - you can afford to use biased model for your purposes. Nevertheless avoid autocorrelation in residuals - as it can serve as evidence of any unrecognized pattern still being latent & hidden for your linear model. And (as of assumption 6) the problem of Multicollinearity still can be the real problem for OLS (resulting in inflating the variance). To detect this problem - can use VIF : Variance inflation factor (VIF) is used to detect the severity of multicollinearity (>4) in the ordinary least square (OLS) regression analysis. & can use Correction of Multicollinearity as a solution to this problem: PCA & PLS , but be cautious about using them 'cause they can help only in the cases when really multicollinearity exist Or just remove highly correlated variables (Xs) from your regression equation P.S. initially (before regressing) removing outliers from dataset - because they also inflate variance as well as lead to biased estimations =========== If your relationships between x and y are really non-linear in nature - than use logarithmic or semi-logarithmic models - - it's all about transformations of Xs at preprocessing stage P.S. linearization of dependencies (with betas) just serves for the ease of using linear_algebra_calculations to model the process P.P.S. and even beta can create a non-linear dependancy in your linear regression model
