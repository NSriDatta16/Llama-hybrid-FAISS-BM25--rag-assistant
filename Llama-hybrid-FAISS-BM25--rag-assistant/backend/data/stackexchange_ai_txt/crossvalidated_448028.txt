[site]: crossvalidated
[post_id]: 448028
[parent_id]: 
[tags]: 
Reading a pressure gauge with a CNN

Using standard Computer Vision pipelines to read pressure gauges is well established, and not overly accurate or generalizable: For various reasons, I would like to use a CNN to do this. Since the learning task is not classification but regression, of course I would need to modify the standard architectures. Ideally, the model should work for multiple manometers, in variable illumination conditions. In practice, a solution which works for a single manometer in good illumination conditions could be acceptable - the model will be of 0 practical interest, not having any advantage over well-established classical CV pipelines, but it can still be fun as an exercise, toy problem or demonstrator. How would you go about building such a solution? My ideas: The "simple" way I "just" collect a large set of pressure gauge images, with indices in different positions, and associate to each of them the corresponding reading (real number). I swap the CNN top layer (the softmax layer) with a linear layer, fine tune a pretrained CNN over my dataset and Boom! let Deep Learning do its magic. I'm not overly confident this will work, for two reasons: the amount of data which needs to be scraped. Most of the images (or videos) you find on the Web are actually catalogue pics, not pics of mounted, working pressure gauges. Thus, finding images from the test distribution may be difficult, which would lead to distribution shift between train & test and thus, worse results. Also, even if I find, say, 10000 images of pressure gauges in a working environment, they won't be labeled and I will have to annotate them manually, which will further hinder the dataset generation process. Happy to be proven wrong, but I don't think there are large, labeled datasets of pressure gauge images. Also, different gauges have different scales - even assuming that all/most dataset images are close-up front views of pressure gauges, the gauges will at least have different scales. Some will have two scales (an inner and an outer one, such as the pressure gauge in the above picture). The neural network should pick up the relationship between the position of the pointer, the small numbers/ticks on the scale, and the output (the actual reading). Given enough images, it could still work. But, as noted before, I don't think I'll be able to collect and label enough images. The "complicated" way Start by reading the scale(s). OCR would be the tool of choice here. Actually, since every decent pressure gauge has a linear scale(s), I wouldn't really need to read all the numbers on the scale - the first and the last one would be enough. However, it's probably easier to just let the OCR tool return all numbers on the scale, and store only the smallest (which is always 0) and the largest one. Since OCR tools return also the coordinates of the characters, in principle it should be easy to discriminate between inner and outer scale. With a little trigonometry it should also be straightforward to determine the angular position of the two ends of each scale. Now I need to get the reading. I could use a CNN which returns the angle measured from the bottom of the scale. Since the other model gave me the angular extension of the scale, as well as the maximum measurable pressure (60 psi in the current image), I could immediately compute the actual measurement. This way, I would explicitly encode the knowledge of how to read a gauge, given that you are able to see its pointer, and read the start and the end of the scale. The CNN wouldn't have to learn that the same angular position of the pointer corresponds to different measurements, for pressure gauges having different scales. What do you think? Does this make sense? Would you use another approach?
