[site]: crossvalidated
[post_id]: 576670
[parent_id]: 
[tags]: 
Euclidean distance between points in PCA space along different principal component dimensions

I've picked up this project half way through, and I'm working through the last guy's code, so please bear with me. So the original data consists of 500+ points in 150 dimensions, and I want to calculate the distance between pairs of points. I also want to calculate the distance from a 'neutral' point, that is an array of 150 zeros. Cosine distance works quite well to calculate distances between pairs of points in the original space, but cannot calculate a distance from a vector of zeros. To deal with this, we ran PCA using pretty straightforward code from sci-kit learn: X = StandardScaler().fit_transform(X) pca = PCA(n_components = 16) # N=16 was determined using the Kaiser criterion principal_components = pca.fit_transform(X) ... which allows for the calculation of Euclidean distance between (a) pairs of points in PCA space (i.e. by treating each of the components as a new dimension), and (b) a single point and a 'neutral' vector of zeros. So here's my concern. My understanding of PCA is that the first component accounts for the most variance in the data, the second component accounts for the second most, etc. So doesn't this mean that the 'true' distance between the points depends on the dimensions along which they lie? E.g. if there are two points with a Euclidean distance of 1 that lie along the dimension corresponding to the first component, and two points with a Euclidean distance of 1 that lie along the dimension corresponding to the second component, are the 'true' distances the same? (E.g. in the figure below, is it appropriate to say that the A-B distance is equivalent to the B-C distance?)
