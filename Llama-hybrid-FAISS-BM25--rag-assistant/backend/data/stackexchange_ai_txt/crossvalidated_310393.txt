[site]: crossvalidated
[post_id]: 310393
[parent_id]: 
[tags]: 
Several types of classifiers result bad accuracy

This question might be strange but I am really disappointed with the bad results I have been getting so I decided to get some ideas from experts. I have a dataset X of binary classes y=(1,-1) . This dataset has 100,000 samples and 128 features. Each feature is basically a binary value 0 or 1 . For instance, one sample would look like: x=[0,1,0,0,0,1,1, .... ,1,1], y=[-1] . Using scikit-learn , I have tried the following classifiers: Random Forests, Naive Bayes, Linear SVC, and Multi-layer Perceptron classifier. For instance, using LinearSVC() : from sklearn.model_selection import cross_val_score from sklearn.svm import LinearSVC clf = LinearSVC() score = cross_val_score(clf, X, y, cv=10) print("Accuracy= %0.2f (+/- %0.3f)" % (score.mean(), score.std() * 2)) For each one, I used Cross-Validation of 10-Folds. As a result, none of these classifiers exceeds 50% accuracy! I am not sure what is wrong! The dataset is generated from a reliable source (from my research team). I cannot think of any other way so I am asking for hints from those who might have faced such a problem before. Thank you in advance.
