[site]: datascience
[post_id]: 38204
[parent_id]: 38198
[tags]: 
Data exploration I would suggest exploring the data a little further, which might help decide what would be the best approach for this bird-song dataset. For example, have a look at the spectrogram of each bird (there are only 66 different genus types), to see how you might extract more data from the samples. Here is the spectrogram of a sample taken from here : We can see that there is clearly a repeating pattern! We can see those tall light green blocks intermittently appearing throughout. So although the sample is indeed just over 70 seconds of sound, the call of the bird seems to really only last about 2 seconds! Either with a simple filtering algorithm or even building a model to find those chunks, you could extract those chunks and only work on those, perhaps along with the data regarding the gaps between those chunks. That is just one example of data-specific pre-processing; I am sure there are many other ways to improve the information density. Samplerate This is another degree of freedom you could look at. One idea would be to accept different samplerates within your input to a model. One could adjust the sample rate to ensure the final samples all are all of the same length. My idea would be to use the length of the shortest sample and then perform regular sampling of all longer sound snippets, such that they the resulting snippets are all of the same length as your shortest sample. This method will obviously be compromising the quality of the data (irregularly across samples), but if the starting samplerate is sifficiently high, you might be able to get away with it! Have a look at this useful article that describes many methods in (pre-processing) sound waves. Two models In your particular case, if you really only have two possible lengths: 8637686 and 3227894 ... it might be feasible to simple create two models, one for each sample length. It definitely isn't an optimal solution; however, it would allow for very quick development and model iterations, as you could use the same model and would only need to change on parameter to use both parts of the data. Basics As well as truncating your longer samples (cutting them to match the length of the shorter/shortest samples - you could using padding to simple make the shorted samples match the length of the longest sample. Typically, this is done by simply adding zeros to the end of the vectors. You could also try adding zeros at the beginning and end to keep the information centered within each sample. If you create a neural network using Keras, you would probably be best by first looking at the ZeroPadding1d layer .
