[site]: datascience
[post_id]: 68884
[parent_id]: 
[tags]: 
Scalable test-to-control matching method needed for Amazon cloud environment

I'm working on a project to port some of my employer's processes from our local Unix servers to the Amazon cloud. One process matches records from a test group to records from a control group using propensity score matching. Local process is implemented with some messy SAS scripts. I'm looking to replace the SAS scripts with something that can run in the Amazon cloud and that satisfies these conditions: can handle large data sets (e.g., matching 10 million test records to 30 million control records) not SAS (since we have little SAS expertise in-house) leverages open source languages/frameworks (because cost matters) At the moment, we're evaluating Python. We're able to use LogisticRegression in sklearn.linear_model to compute propensity scores, but we're struggling to find a scalable method to do the matching task. We tried using linear_sum_assignment() from scipy.optimize since it's intended to find optimal bipartite matching, but it ran for nearly five hours on a just small subset of the records before we terminated the job. I feel fairly sure this kind of assignment/matching problem is common enough that there might be some generalized solutions that we could leverage, but we've yet to find one. To elaborate, the "matching task" is a process to match Test and Control records with very similar propensity score values. It's a fairly common technique for observational studies. Propensity scores are computed and assigned to all Test and Control records. Then Test records are matched 1-to-1 with Control records, provided the records have propensity scores within a specified difference or "caliper." Test records are matched to a single Control record, and vice versa. Some Test records might not be matched if they don't have a suitable partner in the Control group.
