[site]: crossvalidated
[post_id]: 242162
[parent_id]: 242143
[tags]: 
Bias is perhaps not the right term. The model estimated effects are "true" in the sense that they are internally valid, or that they "generalize" only to those data which you've collected (not any kind of generalization at all). The more pertinent issue is that they may not generalize to external data which would be collected in a follow up or independent cluster. Those independent data would give rise to a different model, but the difference between those models would not be bias, but just difference between two internally valid models with no external validity. A fitting method which estimates the same effects in both independent datasets could be said to be externally valid. Otherwise the method is flawed. The truth is your model is overfitted . This leads to biased effect estimates, but the bias is not the issue. The fact is that this model is not guaranteed to generalize to future or separate data collection, it is not externally valid. This is a bigger issue than just cross validation, its an issue of defining the scope of your model. Nonetheless, cross validation will help relieve the bias, partially by encouraging you to fit a model on a smaller fraction of the total training set. A better approach yet is to focus on the science of the problem and what is known about the larger temporal and spatial frame whence these data came.
