[site]: crossvalidated
[post_id]: 202077
[parent_id]: 156020
[tags]: 
It has been 9 months since you asked this question, so I suspect that you might not still be searching for a simple solution to the "label-switching" problem (or might have yourself discovered one). However, for the sake of others who might stumble upon this thread, here are my 2 cents. One easy hack that can potentially get you around the label-switching problem is to enforce identifiability constraints, similar to the one mentioned here (along with a lucid explanation). In your case, this amounts to enforcing $mean_0 This can be done by post-processing the four traces for the means stochastic so that they conform to the above mentioned constraint. One should note that this is not guaranteed to solve the problem, as evident from the example shown in this paper (section 2.2 and 2.3). It goes on to propose a more complex, but effective post-processing method. This thread has quite a few references to papers/discussions aimed at this problem. As an aside, the autocorrelation plot seems to strongly suggest that the MCMC chain has not converged (or maybe it has; low autocorrelation is a sufficient condition for convergence, but not necessary). Wrong convergence might also be an artefact of the way you have declared the stochastics as blocked arrays. Quoting from this answer The problem is caused by the way that PyMC draws samples for this model. As explained in section 5.8.1 of the PyMC documentation, all elements of an array variable are updated together. For small arrays ... this is not a problem, but for a large array ... it leads to a low acceptance rate. I suggest you to change labels = mc.Categorical('labels', p = np.array([.25,.25,.25,.25]),size = ndata) to labels = mc.Container([mc.Categorical('label_%d' % i, p = np.array([.25,.25,.25,.25]) for i in xrange(0, ndata)]) and read the answer referenced above for few more suggestions.
