[site]: crossvalidated
[post_id]: 252368
[parent_id]: 
[tags]: 
Model selection: before or after nested cross-validation?

I want to build a neural network over a data set. My idea is to use cross-validation on a training set to select the "best" neural network (and evaluate it on a separate test set) and to use nested cross-validation to make some statistical predictions. I'd use nested CV to plot bias and variance of my grid search's hyper-parameters. This way I can estimate my method's performance. If these assumptions are not wrong, what should I do first? Model selection or estimation?
