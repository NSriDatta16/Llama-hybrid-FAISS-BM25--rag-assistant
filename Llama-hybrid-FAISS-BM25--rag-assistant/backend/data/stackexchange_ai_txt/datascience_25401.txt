[site]: datascience
[post_id]: 25401
[parent_id]: 25399
[tags]: 
My friend - Thushan Gave me this answer . So I will post it . I think it will describe it . Sometimes in the run time it's not desirable to work with immediate rewards . It can mess up the agent. I will quote it here . Your argument makes sense, but not always. And this is a design decision you make in your problem formulation. However to highlight why this won't work in some situations, I'll give an example. Say you're playing a shooting game with a RL agent. And at some specific location you get killed by getting shot from an enemy. However if you include the reward with the state, this might suggest to the algorithm, that this location is always bad and will try to avoid it (which is wrong). We should't be avoiding locations, but enemies.
