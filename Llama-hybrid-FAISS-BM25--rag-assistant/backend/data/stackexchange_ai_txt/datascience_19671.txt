[site]: datascience
[post_id]: 19671
[parent_id]: 
[tags]: 
How to choose validation set for production environment?

I am using XGBoost for a time-series regression problem. During development, i choose my validation set on last %10 percentage of data. Using timeseries split cross validation and grid-search, I got my best model on this with corresponding xgb hyperparameters. My question is, how to choose validation set (for early stopping) on my production environment? 1) i have chosen last %10 percentage of my data as validation set, but this set is also included on training data. therefore overfit. very sensitive to noisy data. 2) my predicted data (lets say Y) changes over time, when i choose random rows within last year (%10 amount) and dont include them in training set, it gave me worse results on production than first option. 3) when i choose last week's data as validation data, not included in training set, it gave better result on 2. option. but i am not including last week's data to training procedure. 4) Or do i need a validation set on my production environment? should i set iteration count from the experiments done in development stage? (e.g i got best result on 10k th iteration, so i should limit my production-setup iteration count with 10k without using validation set at all?) -- So, how can i choose validation set for my production environment? Best practices, or are there any tips/tricks for this?
