[site]: crossvalidated
[post_id]: 448656
[parent_id]: 
[tags]: 
How is it possible that validation MSE is low while test MSE is really high?

I'm having the following problem. I'm training a neural network LSTM using keras with the following architecture: model = keras.Sequential() model.add(keras.layers.LSTM(units=64, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True)) model.add(keras.layers.LSTM(units=128, input_shape=(x_train.shape[1], x_train.shape[2]))) #model.add(keras.layers.Dropout(rate=0.5)) model.add(keras.layers.Dense(units=1)) model.compile(loss='mse', optimizer=Adam()) The training phase goes pretty smoothly: the training loss begins at around 12000 and descreases a lot in the first epoch to around 10- ish . My data is a time-series with 5 variables and I'm trying to predict one of these variables. My data is sampled at second-rate. This data consists of sensor readings of an industrial machine. I'm using the following function to generate the datasets (previously divided into train, valid and test): def create_dataset(X, y, time_steps): Xs, ys = [], [] for i in range(len(X) - time_steps): v = X.iloc[i:(i + time_steps)].values Xs.append(v) ys.append(y.iloc[i + time_steps]) return np.array(Xs), np.array(ys) From the 5 variables of the original data, three of those variables are scaled between maximum and minimum value. The target variable is not scaled . First of all, this is the loss and valid_loss plot after 10 epochs of training: This behaviour is weird right? I would say the model is overfitting. Now, to the main problem: Although the validation metrics are reasonably good, when I make predictions this is happening: Predictions: Predictions with true value for the test set: I would say that my network is capable of understanding the "pattern", but its not working in the same scale. Why is this happening? 1 When I measure the test MSE I got, as expected quite a high value - 82.
