[site]: crossvalidated
[post_id]: 495458
[parent_id]: 
[tags]: 
How can a column in a dataset be considered a vector?

The term “vector” is used heavily in both math and machine learning. In math/physics it’s a geometric object that has both magnitude and direction, while in machine learning it’s a data structure. In both cases they are essentially just a list of numbers that can be represented as pointing in vector space. In machine learning the vectors we speak of are “feature vectors” since the list of numbers we work with is a row in a dataset, and each row is a list of numbers whose elements are the values for each feature (column in the dataset). So in this case a “vector” is defined as a row in the dataset. But there are other situations where it seems to make more sense to consider a column as a vector. For example, if we wanted to know the correlation between 2 variables in a dataset we would be looking to compare 2 columns. Correlation can be interpreted geometrically using vectors in vector space. This means a column would be considered a vector. But how can the list of numbers in a column be a vector in vector space if each element in the list (each row value for that column) belongs to only one feature? In other words, if we were visualizing the vector in vector space, how do all the numbers in the list that make the vector get plotted? In the case of a feature vector this is obvious, since each column is a dimension in the plot, but in the case where a single column is itself a vector it isn’t obvious how this would be plotted in vector space.
