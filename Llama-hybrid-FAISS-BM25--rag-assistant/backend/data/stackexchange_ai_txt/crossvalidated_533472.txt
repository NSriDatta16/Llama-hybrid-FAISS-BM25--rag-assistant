[site]: crossvalidated
[post_id]: 533472
[parent_id]: 365328
[tags]: 
There are many possible solutions if you have many features in the data: feature selection -- just drop some of the categories that are of less importance, for example, in a natural language processing scenario, this may be some very rare words, that are unlikely to be useful, though in most cases this would be the worst possible solution (e.g. the rare words can have great predictive power), dimensionality reduction -- use a dimensionality reduction algorithm (for example, PCA , or have neural network produce categorical embeddings ) on the data, regularization -- I have no experience with using self-organizing maps, but most of the machine learning algorithms have some ways of regularizing them (see regularization ), e.g. by using $L_1$ or $L_2$ penalties, dropout, etc, hashing trick -- you can reduce the number of dimensions by randomly binning together some of the categories, it sounds crazy, but it is known to work quite well in some cases.
