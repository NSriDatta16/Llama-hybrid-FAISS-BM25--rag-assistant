[site]: datascience
[post_id]: 74644
[parent_id]: 74610
[tags]: 
We compare the child entropy with the parent. So we must weigh the child as per the split size not 50-50. Intuition - ( A very big "ugly" child and a "Great" small child ) Weighing these two without considering the respective size, will give you a decent entropy but actually it's not a great split. Code e.g. a = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1] p(0) = 0.4, p(1) = 0.6 entropy = -(0.4*np.log2(0.4) + 0.6*np.log2(0.6)) #It's equal to - 0.97 #Let's split and calculate the weighted dip a1 = [0] ; a2 = [0, 0, 0, 1, 1, 1, 1, 1, 1] #Without weight a1 = 0 a2 = -(0.33*np.log2(0.66) + 0.66*np.log2(0.33)) #It's equal to - 1.25 Average = 1.25/2 #It's equal to - 0.625 Looks like a great dip(0.97 --> 0.625) in entropy but the data doesn't look any different than the parent #With weight a1 = 0 a2 = -(0.33*np.log2(0.66) + 0.66*np.log2(0.33)) #It's equal to - 1.25 Weighted average = (9/10) * 1.25 #It's equal to - 1.125 It is coming more(0.97 --> 1.125) than that of the parent
