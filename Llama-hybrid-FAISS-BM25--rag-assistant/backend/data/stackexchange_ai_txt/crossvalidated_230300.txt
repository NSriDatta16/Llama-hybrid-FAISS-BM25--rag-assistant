[site]: crossvalidated
[post_id]: 230300
[parent_id]: 
[tags]: 
adaptive Kalman filtering

I am learning about Kalman filters/dynamic linear models/state-space models and I am interested in whether the following scheme is possible, in which I try to estimate distribution parameters simultaneously with a sequence. Suppose that there is some sequence $\{x_0,x_1,\dotsc,x_t,\dotsc\}$ which we would like to estimate (in a sense I will make precise asap). All we are given is the observations $Y_{\leq t} = \{y_0,y_1,\dotsc,y_t\}$, which include some error, so $y_t = x_t + v_t$ and $v_t\sim[0,V_t]$. Let's write the prediction error as $\varepsilon_t = \mathbb E(y_t|Y_{\leq t-1})-y_t$. I would like to write an algorithm that minimises the RMS of prediction errors, that is, minimises $\lVert\{ \varepsilon_1,\varepsilon_2,\dotsc,\varepsilon_t,\dotsc\}\rVert_2$. I do not want to specify any parameters. I do not know if $\{x_t\}$ is constant, linear, has 'jumps' or anything; let's only write $x_{t+1}\sim [x_t + \mu_t,W_t]$. I am willing to make some quality of life assumptions (such as the signal error $v_t$ having $0$ mean), but would e.g. prefer not to assume that $V_t,\mu_t,W_t$ is a constant or known value. Hence I need to adapt my Kalman gain as I go along. Finally, I want to output $\mathbb E(y_{t+1}|Y_{\leq t})$. Of course, for this I must first find $\mathbb E(x_t|Y_{\leq t})$, using a Kalman gain/adaption coefficient $K_t$ to determine how much weight to give to my previous estimate versus the new observation: $$\mathbb E(x_t|Y_{\leq t}) = K_t\mathbb E(x_t|Y_{\leq t-1}) + (1-K_t)y_t.$$ The parameter $K_t$ is usually the signal variance divided by the total variance. I want to update my estimate of signal variance $V_t$, and total variance $V_t + W_t$, with each new piece of data. Of course, to update the $V_t,W_t$-estimates I also need to use a Kalman gain. This is a chicken-and-egg problem. If $ K_t = \frac{ \mathbb E(V_t|Y_{\leq t}) }{ \mathbb E(V_t|Y_{\leq t}) + \mathbb E(W_t|Y_{\leq t}) }$, but $\mathbb E(V_t|Y_{\leq t}) = K_t\mathbb E(V_t|Y_{\leq t-1}) + (1-K_t)(y_t - \mathbb E(x_t|Y_{\leq t}))^2$ (and similarly $\mathbb E(W_t|Y_{\leq t})$), how can I resolve this issue ? Is there something like a prior Kalman gain + a posterior Kalman gain, or some Bayesian tool, that can be brought to bear ? I appreciate any pointers to the literature.
