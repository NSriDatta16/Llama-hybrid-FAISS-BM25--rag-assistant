[site]: crossvalidated
[post_id]: 637983
[parent_id]: 
[tags]: 
What are the best ways to perform feature selection for a binary classification problem with extremely imbalanced dataset

I have a classification problem where the size of the dataset is about 1 million lines but the target group is only about 0.6% of the dataset. I have about 40 feature including both categorical and continuous features and some of the continuous features have correlation with each other. The way I used to do features selection for problems like this was running a random forest model on it by giving extra weight to the target group and using the feature importance module. But it's not working very well with this question. Also I've noticed that this method usually lables all categorical features as unimportant when logically some of them seem like very good features. So I wanted to see if there are better ways of doing this.
