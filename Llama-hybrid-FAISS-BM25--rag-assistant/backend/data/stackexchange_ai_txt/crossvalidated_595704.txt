[site]: crossvalidated
[post_id]: 595704
[parent_id]: 595651
[tags]: 
Your interpretations of the coefficients are correct. With this type of report format, the (Intercept) is the baseline value, individual coefficients represent the additional contributions from the corresponding predictor values, and interaction coefficients represent the extra contributions of combinations of predictors beyond that from their individual coefficients. With a logistic regression, the units are in log-odds. That seems to be just what you wrote as your interpretations. The p -values for all coefficients are for differences of the estimated values from 0. For an interaction coefficient, that represents whether there's a "statistically significant" interaction between the predictors in relationship with outcome. With multi-level categorical predictors it's usually best to evaluate all related terms at once, either by comparing nested models with likelihood-ratio tests or performing Wald tests on multiple coefficients (e.g., the Anova() with capital "A" function in the R car package ). For example, you could compare a model without the interaction term to one with the interaction term to see if the interaction between species and temperature is significant overall. A thought on the modeling It looks like the 35-degree condition is close to lethal, leading to enormous standard errors in the corresponding coefficient estimates. That also might be why your model is taking so long to converge (22 iterations). See the discussion on perfect separation in logistic regression. Although your model overall doesn't suffer from that, it looks like the 35-degree condition comes close. Consider whether you gain anything by including those values in the model. Keeping them in certainly will make it impossible to do reliable tests that involve combinations of coefficients, like those I suggested above.
