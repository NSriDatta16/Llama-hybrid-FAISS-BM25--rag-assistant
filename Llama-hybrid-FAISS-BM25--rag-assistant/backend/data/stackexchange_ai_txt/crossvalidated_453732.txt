[site]: crossvalidated
[post_id]: 453732
[parent_id]: 453709
[tags]: 
Your question is basically a classification question, not so much a question about LDA. The issue about "cats" is commonly a cat vs. dog (other animals, cars, trucks, airplanes) question, where one image from many objects of the same class are employed. But the question can focus on your cat vs. another cat, based on multiple images of each object. Regarding LDA, however, assigning class predictions to objects is based on the Mahalanobis distance. Let $\boldsymbol{\Omega}$ represent the number of classes, and $\omega$ $(1,2,\ldots,\boldsymbol{\Omega})$ represent a single class. For a given object $\bf y$ represented by a $p \times 1$ vector of feature values (this is your $X_i$ ), the Mahalanobis distance from the object to the centroid of class $\omega$ is defined as \begin{equation} \underset{(1 \times 1)}{D_{\omega}({\bf y})} = \underset{(1 \times p)}{({\bf y} - \bar{\bf y}_{\omega})}' \underset{(p \times p)}{{\bf S}_{pl}^{-1}} \underset{(p \times 1)}{({\bf y} - \bar{\bf y}_{\omega})} , \end{equation} where $\bar{\bf y}_{\omega}$ is a $p \times 1$ vector of mean feature values for objects in class $\omega$ , for which the individual elements are \begin{equation} \bar{y}_j= \frac{1}{n_{\omega} } \sum_{i=1}^{n_{\omega}} y_{ij} \quad \quad j=1,2, \ldots p \quad y_{ij} \in \omega, \end{equation} and ${\bf S}_{pl}^{-1}$ is the inverse of the pooled covariance matrix. The decision rule $D({\bf y}\rightsquigarrow \omega)$ is to assign object $\bf y$ to the class for which $D_{\omega}({\bf y})$ is the smallest. Fisher's Discriminant Analysis (FDA) Using your notation, the easiest way to classify a new test object (not in the training set) is to first calculate \begin{equation} \mathbf{w} = \mathbf{S}_{W}^{-1} (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_2 ) , \end{equation} and estimate \begin{equation} w_0 = \frac{1}{2} (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_2 )^\top \mathbf{S}_{W}^{-1} (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_2 ) - \log \left(\frac{P_1}{P_2} \right), \end{equation} where $P_1$ and $P_2$ are the proportion of training objects in each class. Next, for a test object $\mathbf{x}_i$ with unknown class label, assign the object to class 1 if \begin{equation} \mathbf{w}^\top \mathbf{x}_i + w_0 >0 \end{equation} and assign to class 2 otherwise. Obtaining $\mathbf{x}_i$ for each image Note: I am using $\mathbf{x}_i$ for your $X_i$ . For a single image $\mathbf{x}_i$ , let $j$ represent each pixel $(j=1,2,\ldots,p)$ . To begin, you need to "gray-scale" each $j$ th pixel's R,G,B values (which range from 0-255) into a single gray color value, and call this $x_{ij}$ . When done, there will be $p$ values of $x_{ij}$ represented by $\mathbf{x}_i$ . Cross-validation (training and testing) If you have e.g. 100 images for each of 2 cats ( $n=200$ total images) and want to call each cat a class (i,e, classes 1,2), here's what I would do for 10-fold cross-validation. Create a 2x2 confusion matrix $\mathbf{C}$ , which has two rows and two columns. Rows represent the true class of each test image, and columns represent the predicted class. Randomly permute the order of the 200 images (for both cats), this is called shuffling. Using the randomly sorted images, assign the first 20 images to fold 1. Then assign images 21-40 to fold 2, do this for each set of 20 images, up to the 10th fold with images 181-200. Next, train the FDA algorithm by using the 180 images in folds 1-9, and leave out images 180-200 in fold 10 for testing. This will result in new values of $\boldsymbol{\mu}_1$ , $\boldsymbol{\mu}_2$ , $\mathbf{S}_{W}$ , $\mathbf{w}$ , and $w_0$ . Note that $\boldsymbol{\mu}_1$ will contain $p$ averages ( $p=\#pixels$ ) based on true class 1 images within the 180 training images. Same thing for $\boldsymbol{\mu}_2$ being derived from true class 2 images within the same 180 training images. The sample size for images in class 1 vs class 2 does not have to be the same -- in fact it won't be most of the time. Using $\mathbf{w}$ and $w_0$ , if $\mathbf{w}^\top \mathbf{x}_{181} + w_0 >0$ , assign to class 1, and 2 otherwise. Do this for images 182-200. Each image (181-200) will have a true class and predicted class, since you know which cat each image is from (class 1 = your cat, class 2=other cat). For each test image, add a 1 to element $c_{true,predicted}$ of the confusion matrix $\mathbf{C}$ based on each image's true class and predicted class. The sum of entries in matrix $\mathbf{C}$ will now be equal to 20, since there were 20 test images in fold 10. Repeat steps 4 and 5 using images in folds 1-8, and fold 10 for training, while using images in fold 9 for testing. This, will result in a sum of 40 in the confusion matrix elements. Repeat steps 4 and 5 using images in folds 1-7, and folds 9-10 for training, while using images in fold 8 for testing. By now, you should get the picture, i.e., you are using the 20 images in single folds 1-10 for testing with images in the 9 remaining folds for training. When done, the predictive accuracy of FDA based on 10-fold CV will be \begin{equation} acc = \frac{c_{1,1} + c_{2,2}}{c_{1,1} + c_{1,2} + c_{2,1} + c_{2,2}} \end{equation} Note: you will be calculating values of $\boldsymbol{\mu}_1$ , $\boldsymbol{\mu}_2$ , $\mathbf{S}_{W}$ , $\mathbf{w}$ , and $w_0$ ten times, since there are ten folds used during 10-fold CV. In other words, when the 20 images in each "test" fold are left out of training and are used for testing, the values for $\boldsymbol{\mu}_1$ , $\boldsymbol{\mu}_2$ , $\mathbf{S}_{W}$ , $\mathbf{w}$ , and $w_0$ will always be derived from the 180 images which are in the remaining 9 "training folds."
