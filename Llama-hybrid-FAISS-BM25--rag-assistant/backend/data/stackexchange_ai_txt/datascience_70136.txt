[site]: datascience
[post_id]: 70136
[parent_id]: 12872
[tags]: 
GloVe Will "Most Likely" Work For Your Purposes I found myself with a question similar to yours about 1 month ago. I met with some fellow data scientists that had more experience with NLP word vectorization than me. After reviewing many options, I felt that Global Vectors (GloVe) would work best for me. It is doing well for my purposes, and, for my purposes, I have found that training on my own available specialized corpora (plural for corpus = a bunch of documents), I was able to get good utility for my synonym searching needs. The process was introduced HERE , and clarified for me HERE , but I found the most help as a python user HERE , which will give you guidance on how to use trained models. Using python, I found I that I could only make use of pip install glove==1.0.0 per THIS StackOverflow Answer Follow THIS for an idea of how to train your own corpus. IF you need to train your GloVe model from your own corpus , 80%+ of your work will be deciding how to collect and condition your corpus to create your vocabulary and your co-occurrence matrix - you want to do this part very well . Justification for training on a specialized corpus in another domain is reported HERE , which was nice to find for encouragement to do the training work on a specialized corpus. I encourage anyone to evaluate whether or not this is necessary given your application. I'm in the process of having domain experts blindly evaluate pretrained models against the models trained on our corpora. I'll try to remember to update this post once I have those results.
