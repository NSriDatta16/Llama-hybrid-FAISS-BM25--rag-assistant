[site]: crossvalidated
[post_id]: 319746
[parent_id]: 319743
[tags]: 
What you are trying to achieve is very similar to adversarial attacks to neural networks. A recent paper was able to change the outputed class of a NN classifier by modifying just one pixel of an input image. The way this can be done (I think the above paper used a different approach), is to perform backpropagation. However instead of adapting the weights of your network, you want to adapt specific features in your input array. Not sure if this is an easy approach, since I have never tried to implement it. In case you do not want to go deep into the architecture of the NN and runtime does not matter to you, you can try wiggling the features you want to adapt around until you reach the desired output. Basically, you can perform manual gradient descent by going through each feature you allow to change, check what happens to the output if you increase/decrease it by a really small value (similar to the learning rate), and adapt all features in the right direction (going closer to "Win" output) and decreasing the "learning rate" in each iteration. Sorry, this is very informal. I hope the idea becomes clear.
