[site]: crossvalidated
[post_id]: 71418
[parent_id]: 71417
[tags]: 
Prior CV postings on the matter of GOF measures in generalized linear models: Find out pseudo R square value for a Logistic Regression analysis Which pseudo-$R^2$ measure is the one to report for logistic regression (Cox & Snell or Nagelkerke)? Addressing model uncertainty Compare classifiers based on AUROC or accuracy? "Goodness of fit" is an elusive notion. Any set of data can be perfectly fit with a complex, saturated model, but such a model will generally be useless despite being perfect. Application of such tests often completely ignores what the model that is being fit to. I find it rather strange that Anderson-Darling and Kolmogorov-Smirnov tests are being called "goodness of fit tests" when they are really being used as "tests of normality". Models need to be both validated and calibrated and the GOF measures generally tell you very little about those aspects. (It should be noted in passing that the 'rms' function print.cph also reports the Brier score along with a pseudo-R^2 and Somers-D as "discrimination indexes". And it does not report the c-index, perhaps because the Somers-D is equivalent and preceded it historically and Harrell is tired of people misusing it.) You will note that Frank told you that your proposed strategy in an earlier rhelp posting where you proposed taking a "best" glmnet model and then apply stepwise forward and backward reduction was bad statistical practice. Part of the problem is that you were taking a result from a method which is optimized for prediction (penalized glmnet) and then applying a procedure that was in all probability lowering its predictive capacity. Your low Brier score is something I see all the time in my research. I work with large datasets where the outcomes of interest are rather rare (mortality over 5-12 years for basically healthy people). Even a good model will only be predicting a mortality rate of 4-5% for most of the people who die and the "error rate" remains high despite many variables being highly significant. Model comparison measures (especially the deviance) are much better guides for decision making than any of the GOF or discrimination measures.
