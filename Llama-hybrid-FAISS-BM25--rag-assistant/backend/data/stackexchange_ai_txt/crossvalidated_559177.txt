[site]: crossvalidated
[post_id]: 559177
[parent_id]: 559152
[tags]: 
By default, sklearn logistic regression is penalized. From the documentation : penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’ Specify the norm of the penalty: 'none' : no penalty is added; 'l2' : add a L2 penalty term and it is the default choice; 'l1' : add a L1 penalty term; 'elasticnet' : both L1 and L2 penalty terms are added. The penalty is applied to the coefficients. Changing the scale of the data changes the coefficients, which implies a different penalty, which implies a different fit. To fit a model without a penalty, use penalty='none' . The maximum likelihood fit of the model will be the same regardless of (nonzero) scaling applied to the features. The sharp corner here is computational. Poorly-conditioned models may take many iterations to attain the maximum likelihood (OP has already discovered this!). If one model doesn't attain the maximum, then we shouldn't be surprised if it doesn't agree with a model that does.
