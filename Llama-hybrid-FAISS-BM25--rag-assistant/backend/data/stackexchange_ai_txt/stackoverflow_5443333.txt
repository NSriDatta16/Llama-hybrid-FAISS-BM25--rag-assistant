[site]: stackoverflow
[post_id]: 5443333
[parent_id]: 5436782
[tags]: 
The problem with something like this is the hard drive itself - depending upon many factors it can act as a funnel and essentially constrict the number of files you are able to interact with on the drive concurrently. With that said, I'd highly recommend you take a look at the TPL (task parallel library) in .NET v4.0. It's a framework that vastly simplifies the act of "spreading the work across all the available cores" of your processors. My computer has dual processors, each with 4 native cores (Intel Xeon's @ 3GHz) which gives me 8 cores. I have an application that downloads ~7,800 different URL's off the net and analyzes their content. Depending on the values it finds it will do some additional processing then store the results. This is somewhat similar to your situation in that we both share a restricting resource (for me it's the network) and we have to manually parse and evaluate the contents of the files we're working with. My program used to take between 26 to 30 minutes (on average) to process all those files. This was using a properly implemented multithreaded application. By switching the code over to the TPL it now only takes 5 minutes. A HUGE improvement. Take a look at the TPL and plan on having to make some changes to your code in order to maximize the potential improvements. But, the payoff can be fantastic if done correctly.
