[site]: crossvalidated
[post_id]: 376965
[parent_id]: 318227
[tags]: 
A little late but still can help some. I tested on almost the same sample as you, I just tested with only 1 selected variable (max_depth=1): library(h2o) data(iris) h2o.init() iris $Species=factor(ifelse(iris$ Species=="virginica", "virginica","other")) trainH2o This code returns: # [1] " double pred = (Double.isNaN(data[0]) || data[0 /* Sepal.Length */] Let's build manually the "Random forest": var="Sepal.Length" val=6.1492186 table(iris $Species) table(iris[iris[,var] Species) table(iris[iris[,var]>=val,]$Species) We obtain a distribution of each node (other ; virginica): Then the relative importance from h2o is based on the following calculation: \begin{align} RelativeImportance&=\frac{100*50}{100+50}-(\frac{84*11}{84+11}+\frac{16*39}{16+39}) &=12.26156 \end{align} Same result with H2O: h2o.varimp(rf) # Variable Importances: # variable relative_importance scaled_importance percentage # 1 Petal.Width 12.261563 1.000000 1.000000 # 2 Sepal.Length 0.000000 0.000000 0.000000 # 3 Sepal.Width 0.000000 0.000000 0.000000 # 4 Petal.Length 0.000000 0.000000 0.000000 The relative importance of a variable as a general is certainly the sum of the previous function applied on each node where the variable is used. I don't know how to interpret the function used, if someone can, it will be with pleasure. Hope it helped!
