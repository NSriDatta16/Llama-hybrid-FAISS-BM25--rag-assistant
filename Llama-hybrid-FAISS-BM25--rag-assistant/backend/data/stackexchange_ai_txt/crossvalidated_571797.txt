[site]: crossvalidated
[post_id]: 571797
[parent_id]: 215606
[tags]: 
If you’re comfortable using $R^2$ as a crude approximation for proportion of variance explained, knowing that it is not true in the nonlinear case like in a logistic regression (but you decide how good it is for your work as an easy-to-compute estimate that your audience thinks it understands), then it doesn’t matter if you’re using categorical or continuous features. The decomposition of the total sum of squares that leads to $R^2$ , which is given in the link, never explicitly mentions the features (yes, they’re in there implicitly through the predictions, $\hat y_i$ ), only the observations and predicted values. I actually think the bounty comments ask a different question than the original post. Since the bounty message will go away in a few days, I’ll include the text below, as I believe I am addressing the bounty question more than the original question. Additionally, the bounty asks for a reputable source. I’d expect most regression textbooks to give the decomposition of the total sum of squares to explain how $R^2$ winds up giving the proportion of variance explained (at least in OLS linear with an intercept). My professor used Agresti’s book, so that’s what I know. What you’re looking for is in chapter 2, pages 47-54. Agresti, Alan. Foundations of linear and generalized linear models . John Wiley & Sons, 2015. BOUNTY I can report an R2 as a crude indicator of the fraction of variation "explained" by numeric predictors, but how can I report a similar metric for categorical predictors? It feels like there ought to be a simple expression for this but I'm struggling to find a reference that expresses it!
