[site]: crossvalidated
[post_id]: 457384
[parent_id]: 
[tags]: 
Large state space and Markov decision process

I am working on a project where I have an MDP but with a very large state space (each state is described by a tuple (a,b,c,d) where a,b,c,d are integers in the range [0, 1000]). My goal is to compute the optimal policy (and I know the probability transitions), and of course it's doable using Dynamic Programming. However, this proves to be very slow given the really large state space. Therefore, I was wondering what kind of techniques I could use to speed up the process. I have seen value fitted iteration but even if I get the value function, I would have to look at the argmax and that would require looking at all the neighbour states. Just to be more precise my framework is as follows: my states are described by s = (n,u_1,u_2,u_3,u_4) where n corresponds to some kind of time, u_i are quantities remaining (they represent remaining stocks) and therefore when going from n to n+1 , our stocks will be decreasing depending on the action chosen. (that's why I was considering integers for my problems). THerefore it is some kind of inventory problems with no refilling. What would be some approximation I could make? Thank you in advance!
