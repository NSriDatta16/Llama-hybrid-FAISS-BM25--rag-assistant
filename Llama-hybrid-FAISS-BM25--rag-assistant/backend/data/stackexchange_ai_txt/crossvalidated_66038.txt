[site]: crossvalidated
[post_id]: 66038
[parent_id]: 66001
[tags]: 
Thirty years ago, John Emerson provided a simple explanation of an extremely useful generalization of this phenomenon. Here is the essence of it. Suppose you have batches of data (which could include a set of windows across a time series, for instance) and you summarize each with some measure of its "level" (a mean or median, perhaps) and a measure of its "spread" (a standard deviation or interquartile range, perhaps), with both statistics expressed in the same units as the data. We seek some monotonic, increasing transformation $\phi$ for which the spread of the transformed data is approximately constant: a spread-stabilizing transformation. We might as well pick a nice smooth transformation, so we are free to assume $\phi$ is analytic (can be expanded in a Taylor series). Emerson finds $\phi$ based on the apparent relationship between the median, $\nu$, and the interquartile range, $\tau$. The reason for using an IQR (or any symmetric measure of spread based on quantiles: quartiles work well but aren't essential) is that in any batch the $q^\text{th}$ quantile of the transformed data $\phi(x_j)$ coincides with $\phi$ applied to the $q^\text{th}$ quantile of the original data $(x_j)$. (This is not generally true for other measures of spread.) Using quantile-based statistics is not a serious limitation: if the batches of data have roughly the same shape, then the median and IQR will be in the same proportion to any other reasonable measures of location and spread, so Emerson's analysis will produce the correct $\phi$ to stabilize other measures of spread, such as the standard deviation. The idea is to approximate $\phi$ to second order at $\nu$ and track what it does to the spread $\tau(\nu)$. To that end, express the quartiles as displacements from the median, using the spread $\tau(\nu)$ as the natural measure of distance. The upper quartile can be written as $\nu+\lambda(\nu)\tau(\nu)$ with $0 \le \lambda(\nu) \le 1$; the lower quartile therefore must be $\nu-(1-\lambda(\nu))\tau(\nu)$. Applying $\phi$ and writing out its Taylor series we find that the new quartiles are $$\phi(\nu) + \phi'(\nu)\left(\lambda(\nu)\tau(\nu)\right) + \frac{1}{2!}\phi''(\nu)\left(\lambda(\nu)\tau(\nu)\right)^2 + o(\tau(\nu)^2)$$ and $$\phi(\nu) - \phi'(\nu)\left(1-\lambda(\nu)\tau(\nu)\right) + \frac{1}{2!}\phi''(\nu)\left(1-\lambda(\nu)\tau(\nu)\right)^2 + o(\tau(\nu)^2).$$ The new IQR is obtained by subtraction. The zeroth order terms cancel, the first order terms just multiply the original spread, and the second order terms give something that needs analyzing: $$\phi'(\nu)\tau(\nu) + \frac{1}{2!}\phi''(\nu)\left(2\lambda(\nu)\tau(\nu)-1\right) + o(\tau(\nu)^2).$$ At this point Emerson argues that the second-order term is negligible, for several reasons: If the median is roughly centered between the quartiles (that is, the middle half of each batch is roughly symmetric), then $\lambda(\nu)\approx 1/2 \approx 1 - \lambda(\nu)$, making $\left(2\lambda(\nu)-1\right)$ small. If $\phi$ is not too "strong," it shouldn't be terribly curved near the median, making $\phi''(\nu)$ also small. (As an example of (2) Emerson offers the case of $\phi = \log$ where $\nu=10$, pointing out that $\phi'(\nu) = 1/\nu = 0.1$ and $\phi''(\nu) = -1/\nu^2 = -0.01$, a "relatively small" value. This looks specious to me, for if we were merely to change the units of measure of the data (as from meters to kilometers) we might now find that $\nu=0.01$, for which $\phi'(\nu)=100$ and $\phi''(\nu)=10000$! The mistake here is that the values $100$ and $10000$ aren't even comparable: they are in different units. What we should be concerned about is the product $\phi''(\nu)\tau(\nu)^2$, because it overestimates how much $\phi$ will change between the two quartiles. To pursue Emerson's example, if the data are positive and their median is $\nu=10$, then likely the lower quartile is close to $10$ and we can hope the upper quartile isn't too far from it, either. In this case $\tau(10) \ll 10$, so $\phi''(10)\tau(10)^2 \ll 0.01 \times (10^2) \ll 1,$ justifying dropping the second-order term. Although this paragraph may seem technical, it provides insight into just why this analysis works and suggests how to identify cases where it might fail or at least should be mistrusted.) The upshot is that to stabilize the spread, the derivative of the transformation (applied at the middle of the batch, $\nu$) needs to be inversely proportional to the spread itself (provided the quartiles are not both asymmetrically placed and far from the median as a proportion of the median). Because this inverse proportion needs to hold for the entire range of locational values of the batches, we immediately obtain the general solution $$\phi(\nu) \propto \int^\nu \frac{dx}{\tau(x)}.$$ The situation posited in the question is that the spread is proportional to the level: $\tau(\nu) \propto \nu$. The solution is $$\phi(\nu) \propto \int^\nu \frac{dx}{x} = \log(\nu),$$ QED. To put this general result into practice, we make a spread-versus-level plot. Its objective, beyond visualizing how the spreads relate to the levels for the batches, often is to find a Box-Cox (power) transformation $\phi$. We easily see that if $\phi(\nu) \propto \nu^p$ for some power $p\ne 1$, then $\tau(\nu) \propto \nu^{1-p}$. When $p=1$, $\tau(\nu) \propto \log(\nu)$. Therefore, we should seek a power function fit to the spread ($\tau$)-versus-level ($\nu$) plot. A simple way to do this is to fit a straight line on log-log axes , preferably using a method that is resistant to outlying or unusual values. (A visual fit is usually fine but is hard to automate.) The slope of the line is the power $1-p$. For instance, when the spread is proportional to the level the line will have slope $1 = 1-p$ yielding $p=0$, corresponding to the logarithm. Here is a synthetic example. Let's generate independent samples of squared Poisson variates with different levels (theory tells us the variance-stabilizing power transformation is $p=1/4$). The figure shows the spread-vs-level plot, boxplots of the original batches (with medians removed so we can readily compare their spreads), and similar boxplots of the transformed batches. The improvement is clear. In this case the spread-vs-level method works spectacularly well: the slope of the plot is $3/4$, indicating $p=1-3/4=1/4$ is the spread-stabilizing power, exactly as predicted theoretically. (In my experience this method works more often than not, but still should be considered only as a guide or starting point for refining the Box-Cox parameter.) Here is the R code that produced this example. # # Create data. # set.seed(17) k Reference John D. Emerson, Mathematical Aspects of Transformation. In Hoaglin, David C., Frederick Mosteller, and John W. Tukey, eds, Understanding Robust and Exploratory Data Analysis . John Wiley & Sons, 1983.
