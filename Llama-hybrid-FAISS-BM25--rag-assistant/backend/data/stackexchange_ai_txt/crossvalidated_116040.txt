[site]: crossvalidated
[post_id]: 116040
[parent_id]: 116033
[tags]: 
The key question is whether you are likely to need estimates of the probability of class membership, a ranking, or whether you genuinely only interested in a binary classification. In my experience, you often do want the probabilities as the class frequencies, or the misclassification costs are unknown or variable in operation. If you have a probabilistic classifier you can compensate for these problems after training, if you have a discrete yes/no classifier you can't. One of the guiding principles behind the support vector machine was Prof. Vapnik's idea that in solving a particular problem, you should not solve a more general problem and then simplify the answer. In classification this would mean that if you are only interested in binary classification, then we should not estimate probabilities and then threshold them, because modelling efforts and resources are wasted estimating the changes in probability away from the decision boundary, where they are of no interest. This is a very reasonable idea, and I fully agree, provided you really are only interested in a discrete yes/no classification. As it happens, if you perform least-squares regression on 0/1 targets, you will asymptotically end up with estimates of the probabilities anyway. This is because least-squares results in the output being an estimate of the conditional mean of the target variable. If this is coded as 0/1 then the conditional mean is just the conditional probability of a 1, given the input vector. In short, which method you use depends on the needs of the application, if you need the probabilities or a ranking of the test data, use a probabilistic method (or least-squares etc. for ranking). If you only want the hard classification into discrete classes, use something designed especially for that problem, such as the SVM.
