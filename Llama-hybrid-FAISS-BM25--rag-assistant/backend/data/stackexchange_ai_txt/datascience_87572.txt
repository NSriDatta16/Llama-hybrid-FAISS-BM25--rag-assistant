[site]: datascience
[post_id]: 87572
[parent_id]: 87571
[tags]: 
That layer isn't required indeed as it also encodes the sequence, albeit in a different way than BERT. What I assume is that in a BERT-BiLSTM-CRF, setup, the BERT layer is either frozen or difficult to fine-tune due to its sheer size. Which is likely why the BiLSTM layer has been added there.
