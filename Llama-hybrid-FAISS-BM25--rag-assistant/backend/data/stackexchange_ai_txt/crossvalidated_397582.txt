[site]: crossvalidated
[post_id]: 397582
[parent_id]: 397565
[tags]: 
The own model will determine if the variable is important or not and if the best cut is >0 and ==0 . Take into account that random forest will start creating nodes using the variables that give most variance to the model, so if your variable appears as one of the most important I will also add it twice: one as a dummy 0 if not relevant and 1 as significative. With so many data and features I dont think it will create any issues of multicollinearity (being a non linnear model) or overfitting. I think It could be a good excercise of feature engineering. I will also consider xgboost if you are using R Best!
