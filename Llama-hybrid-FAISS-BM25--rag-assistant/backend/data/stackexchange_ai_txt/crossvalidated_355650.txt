[site]: crossvalidated
[post_id]: 355650
[parent_id]: 
[tags]: 
Cross Validation - Are folds and reps learner dependent?

If I read relevant papers I often get the advice to use 10 fold CV or repeated CV instead of a 5 fold or 3 fold CV for tuning a certain learner. The reason is that especially the 10 fold CV with repeats reduces the variance (overfitting) more effective than the other methods. However, I often made the experience that the number of folds is data dependent. For example, the results of the 5 fold CV seems to have less variance than the 10 fold CV/10 fold with repeats because it leads to better performance on the test data also over different seeds. My question is wether the CV method is also learner dependent? Do different learners benefit from different resampling methods on the same dataset? I ask because it´s very time consuming to tune learners like XGBoost or a deep neuronal network spot on with all those parameters which makes it hard to test this empirically. For an elastic net or an svm, it´s not an issue because Bayesian Optimization finds the maximum quiet quickly.
