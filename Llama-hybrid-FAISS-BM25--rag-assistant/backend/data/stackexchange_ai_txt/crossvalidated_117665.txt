[site]: crossvalidated
[post_id]: 117665
[parent_id]: 
[tags]: 
Appropriate non-parametric post-hoc test for baseline comparisons?

I want to evaluate several "classifiers" (machine-learning algorithms) with paired samples . I do not want to compare each algorithms' performance to every other (n x m comparison) but only compare the performance of each algorithm to one baseline (n x 1 comparison) . An often quoted paper in the field [1] uses the Friedman test for omnibus testing and suggests the following for post-hoc tests: When all classifiers are compared with a control classifier, we can instead of the Nemenyi test use one of the general procedures for controlling the family-wise error in multiple hypothesis test-ing, such as the Bonferroni correction or similar procedures. Can I thus use any test for the comparison of 2 groups with paired samples and apply a bonferroni (or less conservative) correction to the p-values? Is a Wilcoxon Signed-Rank test appropriate here? [1] Demsar, J. (2006). Statistical Comparisons of Classifiers over Multiple Data Sets. Journal of Machine Learning Research, 7, 1â€“30.
