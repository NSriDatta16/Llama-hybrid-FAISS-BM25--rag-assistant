[site]: crossvalidated
[post_id]: 497802
[parent_id]: 
[tags]: 
SVM loss function

I am going through Bishop's book and especially SVM. I am trying to understand the logic behind minimizing the specific loss $argmax_{\mathbf{w}} \frac{1}{2}||\mathbf{w}||^{2}$ . On page 327, in 7.3 we want to maximize the distance from the margin for all the data samples $\mathbf{x}_n$ . Actually, we want these samples that have the minimum distance to the margin (and the margin to be maximized). Then, why 7.4 and 7.5 are true? What is the logic behind it? $$t_n (\mathbf{w}^{T}\phi(\mathbf{x}_n) + b) = 1$$ and $$t_n (\mathbf{w}^{T}\phi(\mathbf{x}_n) + b) \geq 1, \ \text{with}, \ n = \{1, ..., N \}$$ What I could understand is that for 7.3 there are multiple different values for $\mathbf{w}$ that satisfy the constraint and one of these can be equal 7.4.
