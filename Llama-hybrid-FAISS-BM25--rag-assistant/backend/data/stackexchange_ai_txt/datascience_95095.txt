[site]: datascience
[post_id]: 95095
[parent_id]: 
[tags]: 
How to analyze neural network quality in case of overfitting?

I have a Keras neural network that has images both as input and reference data. My network demonstrates overfitting (for example, train accuracy is about 80% but test accuracy is only up to 70%) due to small amount of input data relatively to network size. Nevertheless, 70% test accuracy is pretty much fine for my problem and test accuracy doesn't start decreasing after overfitting begins -- it increases along with train accuracy, but is always several percent behind it. And model simplification doesn't allow me to reach such good accuracy. So, in my case it looks like overfitting is doing nothing bad, but I know that its observed effects may be quite different and I'd like to check if my model performs correctly. Could you please suggest some classical ways to analyze the model quality? May be special metrics or statistical methods are usually used or some sort of entropy parameters estimation needs to be performed? Is it possible to understand whether my model learned some useful patterns from input data or just memorized the data itself?
