[site]: crossvalidated
[post_id]: 158742
[parent_id]: 158696
[tags]: 
Remember that when doing computer vision and image processing you should assure that all images are taken in the same conditions. Preliminary preparation of data (exposure, resizing, lighting, filtering etc.) dramatically reduces problems that might occur later. Yes, choosing image pixels as an input features seems to be a reasonable choice. Remember that for even a relatively small image the number of features grows very fast (i.e. 256 x 256 px image resutls in 65 536 features). Therefore some dimension reduction technique should be applied (i.e PCA). You might use Python scikit-learn library that provides all necessary tools . I'm not sure about the performance of your approach - if your dataset does not have a representative amount of images of each class it would probably fail. You could consider experimenting with other features obtained from Gray Level Co-ocurance Matrix (enables many useful metrics, but your image should be represented in gray scale) or Zernike Moments to describe objects/shapes in an image (more info here ). Regards.
