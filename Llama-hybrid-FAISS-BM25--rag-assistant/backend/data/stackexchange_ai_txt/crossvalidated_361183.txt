[site]: crossvalidated
[post_id]: 361183
[parent_id]: 
[tags]: 
Smooth regression algorithms that produce zero training error

I am looking to fit three regression functions $f_1, f_2, f_3:\mathbb{R}^2 \to \mathbb{R}$ . For example, let's say $X_1$ is time, $X_2$ is geographic latitude, $f_1$ is the temperature, $f_2$ is the height of the water, and $f_3$ is the humidity. I observe a set of $\{(X_{1},X_{2}, Y)\}$ for each of temperature, height of water, and humidity. Note that the $X$ s are not the same between temperature, water height, and humidity. My original goal was to just use linear interpolation to estimate missing points in each of the $f_i$ . However, I realized the $f_i$ are correlated, and that each $f_i$ should be used to help interpolate the other $f_j, j\neq i$ . So I reformulated my problem as a regression of $F:\mathbb{R}^4\to\mathbb{R}$ , where the inputs are time, latitude, dummy for $f_2$ , and dummy for $f_3$ , and the output is temperature, water height, or humidity. I am looking for: A regression model (prediction that is continuous and real-valued) Generates zero training error on points we already know. In my application, I would like to have this property. Generates a smooth function as output (as opposed to tree-based algorithms, which tend to perform step-shaped functions) Generates error bars for predictions (frequentist or bayesian). Error bars should reflect zero uncertainty on points we already know. Must be able to handle ~300000 data points. My most promising candidate up to this point was Gaussian process regression. However, this became algorithmically impossible.
