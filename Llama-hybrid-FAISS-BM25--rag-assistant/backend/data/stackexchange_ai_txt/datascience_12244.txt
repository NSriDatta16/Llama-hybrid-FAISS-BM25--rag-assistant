[site]: datascience
[post_id]: 12244
[parent_id]: 12127
[tags]: 
There will be so many follow steps (based on results in step 1), for the objectives you mentioned. I am mentioning starting steps to take analysis to next level. For the first objective, you can calculate simple conditional probability for every node for some time window time frame. Here, you will get a view how each node is affecting other nodes. Also, explore Bayesian network on the data. For the second requirement, as recommended by Dan Levin, association rules are good point to start. To simplify process, you can start with two main events (may be mains failure and association path broken) from the available events. Fix the RHS in association rules to the two main events as mentioned. LHS will be events occurred before RHS events (consider some time window). Now run association rules on the data. You will be able to find some precursors for the two events considered. You can find implementation of association rules in Spark in the following paper: R-Apriori: An Efficient Apriori based Algorithm on Spark Link: http://www.iith.ac.in/~mkaul/papers/pikm09-rathee.pdf Further, to use association rule for prediction, considering the following points will help There must be a time lag between LHS and RHS, i.e. time gap between antecedent (if one node has mains failure) and consequent of the rule (next event would be node down) Prediction rule must have relatively stable confidence with respect to the time frame determined by application domain i.e. run association rules on overall 3 months data, you will get some rules with some confidence. Now run association rules by month wise and see the confidence of same rules, if confidence is consistent, you can use those rules in prediction with confidence ÔÅä For more details refer: http://link.springer.com/chapter/10.1007%2F11548706_11#page-1 You can also use association rules for objective 1 by considering node 1 in LHS and consider all events after nodel 1 event in RHS. Hope this helps!!!
