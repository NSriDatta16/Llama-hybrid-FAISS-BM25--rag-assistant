[site]: crossvalidated
[post_id]: 612927
[parent_id]: 
[tags]: 
Can two states have different actions in a deterministic policy? How to specify states which have probability linked with them in the policy?

The agent has two actions, a 0 and a 1 , whose effects in each state σ 0 ; . . . ; σ 3 are described in Figure 1. The edges from actions are labeled with the probability that this transition occurs. For example, Pr[s t+1 = σ 2 | s t = σ 0 ; a t = a 1 ] = 1; similarly, Pr[s t+1 = σ0 | s t = σ1, a t = a 0 ] = 1-p. If there is no edge from a state to an action, that action is not allowed in that state. Thus, choosing either a 0 or a 1 in σ 3 is not allowed ,and σ 3 is a sink state; similarly, action a 1 cannot be taken in state σ1. The rewards in each state are action-independent, and are r(σ 0 ) = r(σ 2 ) = 0; r(σ 1 ) = 1; r(σ 3 ) = 10. Q1) What are the possible (deterministic) policies are there for this MDP? When counting, ignore “degenerate” actions, i.e. ones that are not allowed in a given state. Doubt - Is the policy choosing a 0 at σ 0 and a 1 at σ 2 a deterministic policy? If yes, how do I write it mathematically as we have transition probabilities included with 2 states? Also, how do I write the value function for this policy?
