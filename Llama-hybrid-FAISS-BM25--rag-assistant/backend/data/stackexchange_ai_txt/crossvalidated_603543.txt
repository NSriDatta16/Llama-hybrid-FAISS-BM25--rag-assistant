[site]: crossvalidated
[post_id]: 603543
[parent_id]: 
[tags]: 
How to validate a Bayesian model using posterior predictive check

Prediction ability of a model is usually being used for model validation/evaluation. But in a high noise to signal ratio setting, and when you are not caring about prediction but inference, then prediction ability is not a good metric. Another option is to use posterior predictive checks. But I am not sure when we can declare a model as valid by comparing the posterior samples and the observed data. For example, look at the below posterior vs observed plot, would you accept this model? Or you would reject a paper that uses this model to do inference on the model parameters?
