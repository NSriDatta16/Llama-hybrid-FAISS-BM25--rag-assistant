[site]: crossvalidated
[post_id]: 108800
[parent_id]: 86097
[tags]: 
Answer: Well, it turns out the answer is simple: after I spent more time working with stochastic ANN architectures I found that it all has to do with the mean or probability of the unit turning on. When a hidden layer unit has a lower probability of turning on (such as a value under 0.5), it is more likely to be 0.0 than 1.0 when you use the unit probability to sample from the Bernoulli distribution. This means that if hidden unit activities given some input vector are generally all off as opposed to on, you can get hidden vector representations of all 0.0's--i.e. a meaningless/useless transformation of the data if you intend on building deep networks. So what have I learned that I can impart to those who read my posts regarding DL? Make sure your network is learning well during training: if you want to go with stochastic nets (as opposed to mean-field nets, where you can use the probabilities directly), pay attention to the probabilities of the hidden units and see what hidden layer "binary codes" your model is learning at each layer (beware the all 0.0's layer). I found that my dirty trick of adding noise to these "empty" vectors (the one in the original post) does stop the NaN problem from cropping up but can potentially hurt the net's performance.
