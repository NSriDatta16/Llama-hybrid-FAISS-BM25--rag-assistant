[site]: datascience
[post_id]: 40381
[parent_id]: 40371
[tags]: 
The answer to your question lies here . Personally, since I can see the high autocorrelation of your input signal x (obvious that x(t+1) = x(t) + 1), you could treat it as timeseries and use an LSTM -RNN to model the nonlinear function y. For simplicity, you could always treat your data as iid and, under this assumption, use an MLP .
