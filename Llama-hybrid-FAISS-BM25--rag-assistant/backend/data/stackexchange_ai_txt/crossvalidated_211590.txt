[site]: crossvalidated
[post_id]: 211590
[parent_id]: 
[tags]: 
Which non-parametric multiple-regression methods are computationally efficient with respect to the number of regressors?

I did some regression in R with random forests and got some decent results, $1-\sum{|e_i|}/\sum{|y_i-\bar{y}|}=0.692$, but I want to do better than this. Through my research, I have concluded that the category of regression methods I need are non-parametric, because $f(\vec{x})=y$ is nonlinear and I don't know an equation for $f$. Blindly, the next non-parametric method I tried was kernel regression (Nadaraya-Watson, I believe), using the np package in R. Unfortunately, this didn't work out, because the algorithm seems to have high complexity for the $n$ of regressors, which are so far 15 . Specifically, kernel regression computed in 142, 621, and 2064 seconds for 2, 3, and 4 variables respectively. Using the most important variables, as identified by random forests, the performance (according to the above metric) was only 0.22, 0.3209, and 0.3208 (actually worsening minutely with the addition of the 4th variable). This is in contrast to random forests, which computed in 26 seconds for 2000 trees and 15 variables, and has continued to reduce error slightly with the addition of variables. So, i'm wondering which non-parametric regression methods give good results and are also fast for a large $n$ of regressors. If it helps, I can probably afford methods that are relatively slow in the number of data points, which so far is only 1750.
