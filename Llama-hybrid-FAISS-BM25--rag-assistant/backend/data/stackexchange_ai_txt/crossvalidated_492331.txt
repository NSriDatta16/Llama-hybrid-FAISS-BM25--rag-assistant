[site]: crossvalidated
[post_id]: 492331
[parent_id]: 
[tags]: 
In XGboost are weights estimated for each sample and then averaged

The weights in XGBoost are determined by gradient boosting. So, each sample gets a weight and as each leaf has multiple samples, initially each leaf has multiple weights. But, as a single weight is needed for each leaf (based on the below thread, please correct me if my understanding is wrong), now are the multiple sample weights in a leaf averaged to get a single weight? How does gradient boosting calculate probability estimates?
