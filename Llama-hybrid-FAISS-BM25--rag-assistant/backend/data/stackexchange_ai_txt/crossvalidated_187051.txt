[site]: crossvalidated
[post_id]: 187051
[parent_id]: 
[tags]: 
Lift in Bayesian A/B-test with pyMC

I'm implementing an A/B-test in pyMC to determine which of two groups to bet on in terms of pageviews per uniqe user. Working code, but I would love some feedback on caveats that I might be missing due to weak stats background. From our website I've collected how many pageviews every user has made and binned them on that. Thus having two vectors on the form observations_X = [26912, 58046, 11846, ...] corresponding to clicks = [1, 2, 3, ...] . The histograms plotted below: Me knowingly, this does not look any probability distribution I know of (at least not any discrete distribution). Therefore I'm using a Multimodal distribution with all priors set to uniform. import pymc as pm import numpy as np import pandas as pd # Bins of how many users clicked 1 time, 2 times, 3 times, ... bins_A = [26912, 58046, 11846, 11295, 5499, 4965, 3266, 2869, 2283, 2062, 1706, 1541, 1348, 1340, 1096, 1062, 890, 849, 845, 734, 659, 584, 586, 570, 537, 554, 505, 502, 439, 421, 437, 378, 342, 389, 356, 333, 317, 298, 348, 296, 328, 287, 314, 269, 289, 260, 252, 256, 15434] bins_B = [26298, 58229, 11656, 11292, 5427, 5073, 3353, 3018, 2319, 2039, 1770, 1581, 1406, 1234, 1096, 1032, 919, 902, 852, 757, 710, 660, 568, 619, 573, 521, 497, 506, 477, 427, 398, 394, 373, 355, 365, 340, 300, 338, 304, 301, 298, 302, 283, 255, 263, 268, 232, 214, 15700] clicks = range(1, len(bins_A)) # Start with uniform probability over the bins p_A = pm.Dirichlet("p_A", theta=np.ones(len(bins_A))) p_B = pm.Dirichlet("p_B", theta=np.ones(len(bins_B))) # A multimodal dist. using the probabilitys of bins obs_A = pm.Multinomial("obs_A", p=p_A, n=sum(bins_A), value=bins_A, observed=True) obs_B = pm.Multinomial("obs_B", p=p_B, n=sum(bins_B), value=bins_B, observed=True) @pm.deterministic def percent_better(p_B=p_B, p_A=p_A, clicks=clicks): """ By multiplying each bins probability with what that bin is worth (number of clicks) and the summing, we get the expected number of clicks (right?). We then calculate the lift of B over A in percent """ exp_clicks_B = np.dot(p_B.astype(float)/sum(p_B), clicks) exp_clicks_A = np.dot(p_A.astype(float)/sum(p_A), clicks) return ((exp_clicks_B / exp_clicks_A) - 1)*100.0 model = pm.Model([p_A, p_B, obs_A, obs_B, percent_better]) map_ = pm.MAP(model) map_.fit() mcmc = pm.MCMC(model) mcmc.sample(120000, burn=20000) percent_better_samples = mcmc.trace("percent_better")[:] print "Probability B > A: {}".format((percent_better_samples > 0).mean()) print "Confidence interval of B:s lift over A:" print np.percentile(percent_better_samples, 2.5) print np.percentile(percent_better_samples, 97.5) Results: Probability B > A: 0.69087 Confidence interval of B:s lift over A: -0.649262232341 1.28610286933 This example of course shows that there no obvious lift of B over A. Any feedback on better approaches would be highly appreciated. Most literature I've found is only talking about binary data (click through rates) which is in my view not very interesting. I'm even all ears for frequentist approaches that handles non normal data like mine.
