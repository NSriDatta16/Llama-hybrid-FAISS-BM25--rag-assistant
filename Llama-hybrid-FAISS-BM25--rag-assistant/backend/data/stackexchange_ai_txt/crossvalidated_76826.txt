[site]: crossvalidated
[post_id]: 76826
[parent_id]: 76811
[tags]: 
You don't know the variance of the error term so you must estimate it. A population variance is just the average of the squared errors. The obvious estimate of that (and the maximum likelihood estimate) is the average squared residual, but the problem is that the fitted values are closer to the data than the true line and on average this value is too small; in particular it turns out to be $E(s^2_n) = \frac{n-p}{n}\sigma^2$, where here $p$ is the total number of terms in the regression including the intercept, if any. So just as with sample variances in univariate samples, reducing the denominator can make the value correct on average ; that is, $s^2 = \frac{n}{n-p}s^2_n = \frac{RSS}{n-p}=\frac{1}{n-p}\sum_{i=1}^n(y_i-\hat y_i)^2$. (Note that RSS there stands for 'residual sum of squares'; sometimes SSE - sums of squares of error - is used instead). If your eviews @var command calculates the usual $n-1$ denominator variance then it won't be the required unbiased estimate and you'll need to scale it.
