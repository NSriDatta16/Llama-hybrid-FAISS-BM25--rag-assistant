[site]: datascience
[post_id]: 125007
[parent_id]: 124955
[tags]: 
From my experience, as you model physical phenomena, neural networks should outperform any tree-based method. I don't even mean any error metric, but the issue is that the neural network's prediction might be smooth and the tree's not - it always will have a "steps-shaped" nature. If the quality of interpolation and modelling an actual phenomenon is important to you, you should stick to a neural network, in my view. However, relationships in your dataset might be pretty complex and vanilla NN might not be sufficient. For me is important to set such activation functions in your neural network to mirror relationships between input variables and the output variable . In a perfect case, if you did it well, it would even facilitate your model's extrapolation capabilities. You should start with the analysis of your data. You can start from: remove insignificant variables - if the random forest finds some variable unnecessary, it probably is handle highly correlated input variables - if a few variables have the same information, just one of them might be enough identify the most vital variables and visualise how they correlate with the output variable - it will help you identify what type of activation function you should use consider transforming some variables to help you predict better - it could be a difference or product of some features, try to understand them more thoroughly and apply this knowledge. Sometimes even changing a unit helps a lot. Besides, I can give you a few pieces of advice on how to build your network better: use regularization to generalise better - e.g. Dropout adjust the depth of your network - in many cases one hidden layer is not enough adjust the width of your network - it doesn't have to be very wide activation might be the key - I repeat remember to scale your data - BatchNormalization layer at the very beginning might be sufficient I hope something from this list will be helpful for you.
