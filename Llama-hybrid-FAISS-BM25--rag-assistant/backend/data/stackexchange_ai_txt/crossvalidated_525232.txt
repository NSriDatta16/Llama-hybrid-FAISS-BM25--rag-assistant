[site]: crossvalidated
[post_id]: 525232
[parent_id]: 
[tags]: 
Preventing certain weights from going to 0

I would like to use a convolutional neural network to study a time series data set. I have experimental measurements taken at three different time intervals. With this I plan to create an input that is $3 \times n \times 1$ . The only filter size that I can apply to this that would seem useful is a $3 \times 3$ filter. For a certain reason particular to my experiment, I want to ensure that there is no possibility that the network will learn the filter weights such that any two of the rows are all $0$ . In other words, I want to make sure that if the network works well, then it does so by making use of at least two of the time instances that I have measured. How can I ensure that it does this? One method I was thinking of is along the lines of padding. I can extend the input size to $6 \times n \times 1$ by copying the original input twice. Then, every weight of the filter matrix will at one point be overlaid with an element of the input from each time instance. Would this work? Are there other methods?
