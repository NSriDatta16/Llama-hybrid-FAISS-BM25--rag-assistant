[site]: datascience
[post_id]: 90453
[parent_id]: 
[tags]: 
Serving feature pipeline

Imagine, there is a service, providing credit history for customers in form of list of his loans. Let's call it my-loan-service . For the sake of simplicity - I can GET http://my-loan-service/42 (where 42 is my customer id) and get back json { "loans": [ { "loanId": 1, "creditLimit": 1000 }, { "loanId": 2, "creditLimit": 2000 } ] } Also, this service provide it's data for data analysis to some OLAP data storage. Shortly - we have a table customerId loanId creditLimit 42 1 1000 42 2 2000 There is also a data scientist - Bob - working with this data storage. And his task is to implement and serve a model, deciding to accept or reject new loan applications from customers based on data from my-loan-service . So far so good, Bob came up with 2 features - number of loans and total credit limit. Bob used plain numpy or pandas to transform raw data into his features and some popular framework (sklearn, tensorflow or any other) to train and test the model. Now, he can serialize his model and serve it using favorite model serving solution. And here is the culmination followed by the question: Any model serving instruments/frameworks or SaaS/PaaS solutions I looked into expects to get features as an input. But in our case I can't get features from my-loan-service - only raw-like data. Obviously, I can create another service - feature-calculation-service - just to get loans, count them, sum up credit limits and then pass these features to served model. This way, every time someone wants a new feature, I'll be forced to duplicate logic of its engineering in feature-calculation-service . And python currently not used for production web-services - only for data analysis. So I am asking for any tips, which can help me avoid duplicating logic of feature engineering for model serving.
