[site]: crossvalidated
[post_id]: 236960
[parent_id]: 236958
[tags]: 
I would say that the most important pre-requisites to Machine Learning are Linear Algebra , Optimization (both numerical and theoretical) and Probabilities . If you read at the details of the implementations of common machine learning algorithms (I have in mind the LASSO, Elastic Net, SVMs) the equations heavily relies on various identities (dual form of an optimization problem, various formulae stemming from linear algebra) and the implementation requires you to be familiar with techniques such as gradient descent. Probabilities are a must have both in the PAC Learning Framework and every time you study tests. Then, only then, functional analysis can come in handy. Especially when you are studying kernels (and use representation theorems). Regarding complex analysis, I am not aware of major use of important theorems stemming from this field in machine learning (someone correct me if I am wrong).
