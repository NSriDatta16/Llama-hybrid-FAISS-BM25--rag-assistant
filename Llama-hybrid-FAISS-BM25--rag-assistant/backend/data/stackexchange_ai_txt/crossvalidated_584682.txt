[site]: crossvalidated
[post_id]: 584682
[parent_id]: 
[tags]: 
Backwards model selection, model average and model prediction. I'm lost

I am trying to see whether two grouping variables and their interaction (let's call them B and C, where B has two levels and C has three levels) affect the behavior of an animal (described by A, a continuous variable). I also have three weather covariates which I use in my model, w1, w2 and w3, all continuous and I use the animal's individual identity as a random factor. The full model looks like this: A ~ B*C + B*C*w1 + B*C*w2 + B*C*w3 + (1|individual) I want to be able to use this model to predict how a future animal of the same species will behave under the same circumstances (which if I understand correctly means I am interested in model prediction). Following authors of leading papers in my field, I used backwards model selection, starting with the full model. The results are that the best model includes both grouping variables (B and C), but not their interaction. This might be great, except that when I compare the AIC of this "best" model with the AIC of the same model, but with the interaction of B and C, the AIC difference is smaller than 1. This is were I got lost because while the AIC difference between the two models is very small, the biological meaning of that difference is very big (i.e., if there is or isn't an interaction between the variables makes a big difference). According to what I know and read, backwards model selection is not perfect, but is the best method if I want to get model predictions. But, is it really true in my case? Could a difference of This got me thinking about using model averaging, but then there is a problem with creating predictions using the averaged model, right? Trying to summarize my questions: Does a AIC difference Can (and if so how) I use model averaging to get model predictions in this case?
