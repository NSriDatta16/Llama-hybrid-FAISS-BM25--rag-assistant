[site]: crossvalidated
[post_id]: 611790
[parent_id]: 
[tags]: 
How to estimate standard deviation from standard error?

We have a manufacturing process in which the finished products have the following requirements: individual unit must have a weight within Â± 10% of average weight (test with 10 random units). One of the in-process quality control test is: Take 10 units, determine their average weight (X) without measuring individual units. Let's say this test is repeated 100 times throughout the day. So each measurement X is the average of 10 units. From the data of X1, X2,...X100, we can calculate the mean of X and its standard deviation (standard error in this case since X is itself an average). My question is: Can you estimate the standard deviation and range of the population (individual units - 1 million in total) and the probability of passing the required finished tests, from this data and how? Can you use the formula SD = SE * sqrt (n)? (in this case n=10) If anyone can point me to documentation or guides i'm very thankful.
