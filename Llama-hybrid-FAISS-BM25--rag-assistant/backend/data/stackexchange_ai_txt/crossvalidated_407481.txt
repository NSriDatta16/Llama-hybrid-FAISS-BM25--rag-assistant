[site]: crossvalidated
[post_id]: 407481
[parent_id]: 407425
[tags]: 
Your Gaussian mixture model has encountered a singularity, which is a known problem when using a maximum likelihood approach to find the parameters of a GMM. Let's understand why this happens: The log-likehood function of $K$ -component GMM for some data $\textbf{X}$ is given by, $$ \text{ln} \: p(\textbf{X} \mid \pi, \mu, \Sigma) = \sum_{n=1}^{N} \text{ln} \left\{\sum_{k=1}^{K}\pi_k \mathcal{N}(x_n \mid \mu_k, \Sigma_k)\right\} $$ When the mean of one of the components, $\mu_k$ equals an observation $x_n$ , you get, $$ \mathcal{N}(x_n \mid x_n, \sigma_j^2\textbf{I}) = \frac{1}{(2\pi)^{1/2}} \frac{1}{\sigma_j} $$ As variance $\sigma_j \rightarrow 0$ , above term goes to infinity and drives the log-likelihood to infinity. Ways to deal with singularities: Take Bayesian approach You can prevent the log-likelihood from blowing up, by detecting when a singularity occurs and avoid $x_n$ to become equal to $\mu_k$ Reference: Pattern recognition and Machine Learning by Bishop
