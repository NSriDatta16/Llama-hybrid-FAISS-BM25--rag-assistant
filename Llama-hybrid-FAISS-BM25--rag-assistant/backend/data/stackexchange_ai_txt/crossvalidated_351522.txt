[site]: crossvalidated
[post_id]: 351522
[parent_id]: 351496
[tags]: 
I am trying to solve a classification problem where I have a set of known X values. I know the classification objective i.e. the discrete set of values the Y can take. However, I don't have any observations with labeled Y. I am hoping to have a user train a model by showing the user a subset of X values and using that train a model incrementally with each feedback from the user. After an initial set of cases where the user will explicitly provide the Y classification This sounds to me a bit like the " active learning " setting. In active learning, a system has a larger amount of unlabeled data, but can request accurate labels from an oracle / human expert / etc. for a (typically relatively low) number of instances. So that's probably a term you'll want to look up in existing research. the system should then switch to getting a reward from the user based on the classification accuracy. The system needs to learn perpetually. The setting where you don't necessarily get exact feedback (precise labels), but still get some feedback that correlates with your actions (e.g. positive rewards if you classified correctly, negative rewards if you classified incorrectly, without further feedback on exactly what the correct classification would have been) sounds more like a Multi-Armed Bandit / Reinforcement Learning setting. A paper that combines both of those settings is Adapting to Concept Drift in Credit Card Transaction Data Streams Using Contextual Bandits and Decision Trees (there is a link to Full Text pdf on that page). It's not exactly the same setting as yours, there are certainly differences, but maybe some of the ideas and/or Related Work may be useful. Disclaimer: I am an author on this paper.
