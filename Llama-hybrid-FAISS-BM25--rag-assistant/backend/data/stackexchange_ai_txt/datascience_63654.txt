[site]: datascience
[post_id]: 63654
[parent_id]: 63647
[tags]: 
What you are referring to as parameter is rather called hyper-parameter . I also assume that you are talking about weights as in a neural network, so that would be your model's parameters. Basically, the difference is that hyper-parameters are chosen by the user prior to learning (and affect the learning phase), while the parameters are computed by the algorithm during the learning process . Thus, the model's parameters depend on training data and the model's hyperparameters. Note: Things are not always that simple, because optimizing hyper-parameters is often mandatory, and in many cases you could say that they are learnt from the validation phase (model assessment over the validation dataset), so they may also depend on the dataset.
