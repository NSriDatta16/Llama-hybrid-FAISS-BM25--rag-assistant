[site]: crossvalidated
[post_id]: 374283
[parent_id]: 374248
[tags]: 
Think about the extreme cases: If your 12 features have no information in common, you would need 12 components to capture 100% of the information (each component just contains the information of one feature, and PCA is useless). If your 12 features have everything in common, you can fit 100% of the information into 1 component (that one component will be identical to the 12 identical features, so PCA is useless). Real-world data is usually somewhere in between, and a decision on whether PCA is worthwhile is usually based on context (what are the features?) and the loadings of each feature. You were wondering why the two most important components only account for 18% of the variance. The easy, general answer is that this group of 12 features don't seem to have a lot in common. A more nuanced explanation comes from looking at the loadings... ...and noticing that: Some features load relatively high on the first component but low on the second one (blue). Some features load very low on the first component and relatively high on the second one (red). Other features, like green, have relatively important proportions of their variance in both components. So, even though the group of features is not very homogeneous, we can see that some of them are more related to each other than others.
