[site]: crossvalidated
[post_id]: 175615
[parent_id]: 175614
[tags]: 
You have a lot of atypical parameters here and I believe it is causing a poor-fitting model that exhibits random performance oscillation. Though first notice that the AUC is increasing. So one answer to the question is that it is possible and even reasonable to have classification tradeoffs that yield decreasing performance by one metric and increasing by another. However, the oscillating performance may be the result of the parameter choices. If so, the parameter most likely to cause the performance issues is the mtries value of 2. This means that for each of the 100 trees you are building, a random 2 columns are picked for the entire tree. So it's quite likely that you get a poor model with just two columns, for most of those trees. If it happened to randomly choose two of the more powerful columns in a few of your first few models, it is very reasonable to get the output progression you have shown. The default is 1/3 of the columns for classification problems. The square root of the number of columns is a common default as well (used for regression problems in H2O). min_rows of 5000 is also very high. The default is 10, using up to 30 is fairly common. This means that the algorithm will avoid potentially useful splits of the data set if either of the resulting nodes has fewer than 5000 observations. At a depth of 12, you'd have to have over 20 million rows even with perfect splits. A nice feature of random forest is that the default parameters are fairly standard across implementations (e.g. R, scikit, H2O). I would suggest trying those out first. In general random forests improve as you add trees, as you expect. But each tree is independent, so I think you randomly got some more powerful columns sampled early.
