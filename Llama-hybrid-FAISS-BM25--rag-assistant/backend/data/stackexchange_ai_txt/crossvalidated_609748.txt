[site]: crossvalidated
[post_id]: 609748
[parent_id]: 570591
[tags]: 
I assume you mean why "macro" and "weighted" precision are same in the above example. "weighted" precision is actually a weighted version of "macro" precision. The above example illustrates the case where the classes are balanced (2 for each class: 0, 1, 2). However, if the classes are imbalanced (the code below), then the "macro" precision will be different for "weighted" one. y_true = [2, 2, 2, 2, 1, 0] y_pred = [2, 2, 1, 0, 2, 2] print(precision_score(y_true, y_pred, average='macro')) #0.167 print(precision_score(y_true, y_pred, average='weighted')) #0.333 Basically, the function precision_score will first calculate the precision for each class. Then, it uses np.average() with the weight attribute to be the number of positive examples in each class. If the classes are well-balanced, meaning the number of examples in each class is exactly the same, then "macro" and "weighted" precision will be the same. Otherwise, "weighted" precision will be higher than "macro" precision.
