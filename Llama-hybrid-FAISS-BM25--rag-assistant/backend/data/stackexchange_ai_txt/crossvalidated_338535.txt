[site]: crossvalidated
[post_id]: 338535
[parent_id]: 54821
[tags]: 
I'm working on something very similar as you. This is what I did: In my feature space I had two kinds of variables - count variables and measure variables. Example for count: "Number of times test x was taken in 2013". Example for measure: "[Average/Max/Min/Std] of test x for 2013". Now, if I had a missing value in a count variable I just transformed it to be 0, because missing-count and no-count are the same, if you assume that the hospital system works correctly. So yes, I assumed that if a patient is taking a lab test - it will be recorded and not get lost because someone had forgotten to input it to the computer. For measure variables you can't transform a missing value to 0 because 0 is itself a value, e.g. max_test_x_2013 = 0 has a scale meaning. So what I did is to transform each measure variable to a categorical variable in which each category was calculated based on the variable's distribution (basically binning the variable), and importantly - "missing" was a category of its own. In that way I converted the missingness to something that you can input to a model. In glmnet, each of these categories then was converted to a dummy. This results in a higher resolution feature selection in which particular ranges of features gets selected rather than the entire feature. For me it was enough that at least some range of the variable was selected to justify the inclusion of the whole variable later on in the model. On a side note, I now have the same problem when running the model (not for feature selection). My goal was more inference than prediction really, and so it is important for me to identify the most influential factors/coefficients of sorts. So now getting just some of the range of a certain variable as influential is not going to work because it is hard to explain it ("avg_test_x_2013_[6.0-7.8] really increases the chances of the outcome to occur" is difficult to explain..)
