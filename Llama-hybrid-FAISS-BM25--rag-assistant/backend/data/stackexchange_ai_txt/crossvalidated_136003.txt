[site]: crossvalidated
[post_id]: 136003
[parent_id]: 
[tags]: 
How to reduce dimension of the sampling procedure?

I am stuck with this problem for a long time, hopefully I can get help here! Basically, I want to sample from a posterior distribution that looks like, \begin{align*} X &\sim N(\mu(\theta),\Sigma(\theta))\\ \theta &\sim p(\theta) \end{align*} where $X = (x_1,...,x_d)$ for $d$ large saying at least thousands, and the dimension of the hyperparameter $\theta$ is not large, saying $p = 3 \sim 5$ or so. Therefore like the Gibbs sampling, at each time $i = 1,...,n$, I can do sample $\theta^{(i)}$ from $p(\theta)$ sample $X^{(i)}$ from $N(\mu(\theta^{(i)}),\Sigma(\theta^{(i)}))$ In such sampling procedure, the dimension of random numbers are $d+p$ which is large due to large d, since in the second step (2), it is usually done by sampling $z^{(i)} \sim N(0,I)$ and $x^{(i)} = L\,z^{(i)}$, $LL = \Sigma$. What I wanna is to reduce the dimension of the random samples of X to a relatively small number saying at most 10 or so while the uncertainty or main distributional characteristics can be remained. One simple way I can come up with is a 1 order approximation that sample $\theta^{(i)}\sim p(\theta)$ sample $\xi \sim N(0,1)$ $X^{(i)} = \mu(\theta^{(i)}) + \xi\cdot\text{diag}(\Sigma(\theta^{(i)}))$ so that the dimension of random numbers are reduced to only $p+1$ ($\theta$ and one scalar $\xi$).. But I doubt that: there is too much information lost in this simple procedure as (1) only marginal variance is used (2) the random number of each $x_j$, $j = 1,...,d$ are the same as $\xi$. There is also another way as truncated K-L or PCA, but in my case, the proportion of variance by truncating a small number saying 10 or even 20 is small around 30% or even less... Could it be possible anyone has any idea about this or similar problem has been investigated somewhere? Many thanks!
