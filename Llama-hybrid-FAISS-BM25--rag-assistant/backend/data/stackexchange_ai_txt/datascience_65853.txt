[site]: datascience
[post_id]: 65853
[parent_id]: 65815
[tags]: 
A few hints/ideas regarding your task: I would not kick out other explanatory variables $x$ too early. When I look at your correlation chart, I suspect that all variables (but serial no) have some impact on $y$ . If you kick out these variables, you may throw away important information. In case some $x$ are highly correlated, you may face the problem of multicollinearity . This can be a real problem with some methods, e.g. linear regression and related approaches. Other methods, such as Random Forest are not so prone to overfitting with highly correlated features, since the algorithm only takes into account few features in each forest, so that highly influencial or correlated features do not play a big role in each single tree. I suggest you check correlation first and possibly also the variance inflation factor from linear regression. This should give you a good idea on if the features are too strongly correlated to be considered jointly, e.g. in linear regression. Linear regression could also be a good baseline model here. In order to perform feature selection, you could use Lasso/Ridge regression , which works like an "automated" way of selecting features based on importance for prediction. In order to improve the model fit, you could also check generalised additive models (GAM) , which is a linear family, but allows you to add highly non-linear representations of $x$ to the model without much need for tuning and without long training times. In order to get a good start with ML , I suggest you have a look at " Introduction to Statistical Learning ". There are R and Python labs for the book. This will give you a very good start and a sound understanding of the most important problems regarding ML. For future reading (if you are interested): If you would work on a causal model (for statistical inference), your model would suffer from endogeneity. In this case you would need to take a different approach to solve the problem ( instrumental variable or IV estimation). But since you work on a predictive model, you have no problems here. Wooldridge ("Introductory Econometrics") is a good starting point for anyone who is interested in causal modeling.
