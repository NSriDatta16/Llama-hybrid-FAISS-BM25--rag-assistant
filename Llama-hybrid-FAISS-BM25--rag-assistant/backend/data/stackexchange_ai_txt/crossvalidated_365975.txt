[site]: crossvalidated
[post_id]: 365975
[parent_id]: 365659
[tags]: 
I'd assume that just as with k-means, the use of Bergman divergences is appropriate. Ward is not going to fail badly if you put other measures in it - it's just expecting values from squared deviations . And on binary vectors, Euclidean, squared Euclidean, and Hamming will be trivially equivalent. What matters is the kind of clusters found. K-means and Ward correspond to modeling clusters with means , and minimal squared deviations from these means. This is fine if squared deviations from an average make sense for your application . Which may, or may not, be the case. Most likely, there are other, more appropriate choices.
