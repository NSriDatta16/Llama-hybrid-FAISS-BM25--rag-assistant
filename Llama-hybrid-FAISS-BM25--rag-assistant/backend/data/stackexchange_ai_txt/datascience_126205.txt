[site]: datascience
[post_id]: 126205
[parent_id]: 
[tags]: 
Can't show images outputted by a VAE with pyplot.imshow - wrong dimensions

I'm trying to show images generated by a variational autoencoder using pyplot.imshow and make_grid. I can't show them, though, with the following error: "TypeError: Invalid shape (64, 530, 42) for image data". But I have these dimensions printed and they are 64, 64, 64, 3, just as necessary! The relevant code snippet is as follows: plt.subplot(1,2,2) plt.axis("off") plt.title("Fake Images") z_list_values = [5, 5] z_list = [z_list_values for i in range(64)] z_sample = torch.tensor(z_list, dtype=torch.float) x_decoded = model.decode(z_sample) image = x_decoded.detach().reshape(64, 64, 64, 3) print(image.shape) # torch.Size([64, 64, 64, 3])! #plt.imshow(np.transpose(vutils.make_grid(image, padding=2, normalize=True),(1,2,0))) plt.imshow(vutils.make_grid(image, padding=2, normalize=True)) # the error is here plt.show() It prints: torch.Size([64, 64, 64, 3])! The error is in the penultimate line. I've tried both options: with transpose and without it, so the error is somewhere else. I'm trying to show 64 images, 64x64x3. What's wrong with my code? How can it be that the dimensions, when printed for debugging, are 64, 64, 64, 3, just as necessary, but at the same time 64, 530, 42? Thanks in advance!
