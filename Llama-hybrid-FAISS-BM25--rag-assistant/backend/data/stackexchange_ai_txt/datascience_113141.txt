[site]: datascience
[post_id]: 113141
[parent_id]: 113134
[tags]: 
It would not overfit, but you won't get a better classifier than the one you have used to label them. Neural networks are Universal Approximators, thus the second classifier that you are going to train on that new labeled data, will approximate the function of the first NN (which itself was trying to approximate the "true" function) If you train a model on the data that itself has labeled, it will obviously have 0 loss, thus 0 gradient, thus 0 changes in the NN
