[site]: datascience
[post_id]: 17823
[parent_id]: 17783
[tags]: 
I would pick a different scoring function than accuracy; the problem with accuracy is that if you classify all the instances under the majority class, you will automatically end up with a very high accuracy score, which is rather meaningless! Usually, the area under the curve (AUC) of the precision-recall curve ( sklearn.metrics.average_precision_score() in Python) works well and is representative of the actual performance of the model when one is dealing with unbalanced data. The AUC of the receiver operating characteristic (ROC) curve is also another metric that is most often used. Having said this, it seems to me that you specifically want to maximize the recall score, which is the ratio of the number of true positives to the total number of actual positives. EDIT: As per @stmax's comment below, you don't want to maximize the recall score either.
