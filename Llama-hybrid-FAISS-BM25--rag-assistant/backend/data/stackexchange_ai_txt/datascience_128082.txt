[site]: datascience
[post_id]: 128082
[parent_id]: 128081
[tags]: 
Your model is likely overfitting and you get an inflated validation score of 98% because of a data leak. Your idea of setting aside 3 of the time series for testing is good, but you missed to do the same for the validation set where you do a random split of the training data. This will cause your validation data to be from time series your model have already seen training samples of. I would suggest you do something like the following. Split your 15 time series into 3 parts Training set - Data from 10 full time series Validation set - Data from 2 full time series Test set - Data from 3 full time series One thing to note is that this will not give you better performance, but will fix the issue where it looks like you are not overfitting. Looking at your model code does not help in this case. The error is likely in how you split/pre-process/generate data, so showing that kind of code would help more.
