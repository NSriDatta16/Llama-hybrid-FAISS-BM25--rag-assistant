[site]: crossvalidated
[post_id]: 354079
[parent_id]: 50932
[tags]: 
I am doing the similar thing with neuronal spikes. Some papers I am following did PCA and selected components that explain 90% variance then did LDA, with the main purpose being "avoiding singular matrix", which to some extent makes sense, but can be avoided by "eigen solver" and "shrinkage". There are 3 reasons why I chose not to do so: very practically, your dataset is temporal, if you perform PCA at each epoch you lose the potential to compare the change across time (or at least harder). It's also harder to track back to individual neurons, but I think in your case it's not that important. as is suggested by another answer, PCA may impair your decoding performance - it is unsupervised. More importantly, I think scientifically it is interesting to see how different regions collectively give rise to a function. I don't think PCA before a classifier will help it. while I'm typing this answer, I just thought of that people also pool the dimensions of trials and epochs together as sample dimension for PCA. If you perform PCA this way, then at each time point your components are not orthogonal, and you somehow still can compare different epochs.
