[site]: crossvalidated
[post_id]: 643838
[parent_id]: 
[tags]: 
How can I assess internal validation (discrimination, calibration) of a Fine-and-Gray competing risk model, fitted using a MFP-algoritm in Stata?

I'm a post-doc at Karolinska Institute, and I'm working on developing a Fine-and-Gray competing risk model to predict endometrial cancer recurrence/progression with death as a competing event. I have used a multiple fractional polynominal algorithm that simultaneously performs backwards elimination and selects fractional polynominals for continuous variables https://mfp.imbi.uni-freiburg.de/ . Since this algoritm is very computationally intensive I've expanded my dataset and assigned weights by using the stcrprep command by P C Lambert ( https://pubmed.ncbi.nlm.nih.gov/30542252/ ). By doing so the native Stata stcox command becomes a Fine-and-Gray model. However, I’ve been unable to get standard commands for assessing calibration, such as stcoxcal by P Royston ( https://journals.sagepub.com/doi/pdf/10.1177/1536867X1401400403 ) to work. One way to assess calibration is by using pseudo-values (described by Gerds https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6152 ), and recommended in Validation of prediction models in the presence of competing risks: a guide through modern methods by van Gerloven et al ( https://www.bmj.com/content/bmj/377/bmj-2021-069249.full.pdf ). I’ve got the code to work, almost. I can draw one calibration plot, but I have been unable to resample the dataset and repeat the calibration procedure. Since the calibration plot is working, for the first run, I’m thinking that the problem lies in my programming of the bootstrap resampling. Thus, a coding issue, not necessarily a statistical issue. What I want the code to do is resample the data, fit the model, spit out the results, store those in a separate file, repeat X-hundreds of times, and then analyse that file to assess calibration. A few weeks ago I posted my problem on Statalist, but still with zero replies statalistpost . To that post I attached a sample dataset with 10% of my data. clear all frames reset ************************************************ *CHOOSE WHICH DATASET TO USE******************** *10% OF DATA (FOR TRYING OUT THE CODE) OR FULL** ************************************************ *use "the database file pathway" Is it obvious to someone what I'm doing wrong? Can you help me fix it? Do you have any other suggestions (and code!) on how to assess discrimination and calibration with resampling techniques in my setting? Any help is greatly appreciated, and I will of course post any helpful replies also to Statalist. BR Rasmus Green
