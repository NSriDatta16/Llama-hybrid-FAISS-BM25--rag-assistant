[site]: crossvalidated
[post_id]: 574853
[parent_id]: 
[tags]: 
Should folds in k-fold CV actually be representative?

I have read somewhere that the k of the k -fold CV should be picked in such a manner as to have representative validation sets (folds). This seems to me to be contradictory since the leave-one-out CV has only one sample as a fold, which clearly can't be representative of the dataset (I refer to one fold only, the whole process is perfectly fine as it is averaged). Furthermore, LOOCV is less biased than the k -fold CV due to it practically using the whole dataset for model fitting, albeit more expensive computationally. Of course, a smaller fold usually also implies a larger variance in the error, but this does not seem relevant in this instance. Should each fold actually be representative?
