[site]: crossvalidated
[post_id]: 385452
[parent_id]: 385424
[tags]: 
It often happens that the name Kalman Filter is used, while actually it is a Kalman Predictor or Kalman Smoother. Kalman Predictor if we have no measurements from the present Kalman Filter when we make an estimate given the past and present measurements Kalman Smoother when we make an estimate acausally (using future measurements too) The optimality of Kalman Filter is nice, but it is only optimal if the right assumptions are met. The most difficult to get around is the linearity of the model, but the Gaussian nature of noise is also one that is often not met in practice. The Extended and Unscented Kalman Filters alleviate the linearity, but they don't guarantee optimality. To get more understanding of the Kalman Filter, it is really helpful to look at the derivation of the Kalman Filter from the perspective of recursive Bayesian estimation. It is nicely explained in Wikipedia , but I will discuss the more important points. Briefly, what the framework consists of is treating the measurements $ \mathbf{z} $ as quantities which reflect information about the true state $ \mathbf{x} $ of the system that we wish to know. What we wish to find is the most probable state given the previous measurements and states, $ p( \mathbf{x}_{k} | \mathbf{x}_{1:k-1}, \mathbf{z}_{1:k-1}) $ . I think what you are pointing at is the Markovian assumption of the framework, which is $$ p(\mathbf{x}_{k} | \mathbf{x}_{1:k-1} ) = p( \mathbf{x}_k | \mathbf{x}_{k-1} ),$$ so that the current state only depends on the previous state of the system. That is indeed some compression, but often quite a reasonable one, and makes the problem computationally tractable.
