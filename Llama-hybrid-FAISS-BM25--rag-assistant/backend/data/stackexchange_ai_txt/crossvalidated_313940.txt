[site]: crossvalidated
[post_id]: 313940
[parent_id]: 286386
[tags]: 
With time varying parameters, only the Kalman filter can be used. (Unless you find an innovative way to use SGD). Let's look at a situation where both algorithms would make sense: linear regression $Y=\beta X+\epsilon$. Call $n$ the length of vector $X$. SGD (for MLE) assumes a fixed $\beta$ and will just find it. It is an online method but does not handle time dependence at all. First, you must go over the dataset several times, most efficiently in a random order, which breaks time dependence. And you can't expect it will "forget" the influence of the past lines in a way you can control easily. The Kalman filter assumes time varying $\beta(t)$ that is called a "state" instead of parameter. The "parameters" here are the variance of $\epsilon$ and possibly how $\beta(t)$ is allowed to change with time: typically the variance of a step if it is a Gaussian random walk or Brownian motion. The Kalman filter computes an estimate for $\beta$ and a covariance matrix for this estimation at each time $t$. It goes over the dataset only once and importantly in an ordered time fashion. When $\beta$ is fixed, the Kalman filter is essentially useless, because it will just find the usual MLE estimation of $\beta$ that could be found easily with matrix inversion. One could argue that the Kalman filter has the advantage to be an online method but since you need to store an $n\times n$ matrix... it's infeasible with big $n$ where online methods are usually needed. And operations on the matrix are costly anyway. To summarize: Time varying $\beta(t)$: Kalman filter. Infeasible with big $n$. big $n$ : SGD. Infeasible with time varying parameter. The Kalman filter is also used in advanced learning with NN but I don't much about it. People are researching ways to mix the two algorithms but it does not seem very mature for the moment. (as far as I know). The Kalman filter with big $n$ is being researched, with advanced Bayesian method for weather forecast .
