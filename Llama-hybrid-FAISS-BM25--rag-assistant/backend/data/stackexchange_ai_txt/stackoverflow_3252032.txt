[site]: stackoverflow
[post_id]: 3252032
[parent_id]: 3250192
[tags]: 
Well I did a small test and I would definitely recommend using Memory Mapped Files. I Created a File containing 350M double values (2.6 GB as many mentioned before) and then tested the time it takes to map the file to memory and then access any of the elements. In all my tests in my laptop (Win7, .Net 4.0, Core2 Duo 2.0 GHz, 4GB RAM) it took less than a second to map the file and at that point accessing any of the elements took virtually 0ms (all time is in the validation of the index). Then I decided to go through all 350M numbers and the whole process took about 3 minutes (paging included) so if in your case you have to iterate they may be another option. Nevertheless I wrapped the access, just for example purposes there a lot conditions you should check before using this code, and it looks like this public class Storage : IDisposable, IEnumerable where T : struct { MemoryMappedFile mappedFile; MemoryMappedViewAccessor accesor; long elementSize; long numberOfElements; public Storage(string filePath) { if (string.IsNullOrWhiteSpace(filePath)) { throw new ArgumentNullException(); } if (!File.Exists(filePath)) { throw new FileNotFoundException(); } FileInfo info = new FileInfo(filePath); mappedFile = MemoryMappedFile.CreateFromFile(filePath); accesor = mappedFile.CreateViewAccessor(0, info.Length); elementSize = Marshal.SizeOf(typeof(T)); numberOfElements = info.Length / elementSize; } public long Length { get { return numberOfElements; } } public T this[long index] { get { if (index numberOfElements) { throw new ArgumentOutOfRangeException(); } T value = default(T); accesor.Read (index * elementSize, out value); return value; } } public void Dispose() { if (accesor != null) { accesor.Dispose(); accesor = null; } if (mappedFile != null) { mappedFile.Dispose(); mappedFile = null; } } public IEnumerator GetEnumerator() { T value; for (int index = 0; index (index * elementSize, out value); yield return value; } } System.Collections.IEnumerator System.Collections.IEnumerable.GetEnumerator() { T value; for (int index = 0; index (index * elementSize, out value); yield return value; } } public static T[] GetArray(string filePath) { T[] elements; int elementSize; long numberOfElements; if (string.IsNullOrWhiteSpace(filePath)) { throw new ArgumentNullException(); } if (!File.Exists(filePath)) { throw new FileNotFoundException(); } FileInfo info = new FileInfo(filePath); using (MemoryMappedFile mappedFile = MemoryMappedFile.CreateFromFile(filePath)) { using(MemoryMappedViewAccessor accesor = mappedFile.CreateViewAccessor(0, info.Length)) { elementSize = Marshal.SizeOf(typeof(T)); numberOfElements = info.Length / elementSize; elements = new T[numberOfElements]; if (numberOfElements > int.MaxValue) { //you will need to split the array } else { accesor.ReadArray (0, elements, 0, (int)numberOfElements); } } } return elements; } } Here is an example of how you can use the class Stopwatch watch = Stopwatch.StartNew(); using (Storage helper = new Storage ("Storage.bin")) { Console.WriteLine("Initialization Time: {0}", watch.ElapsedMilliseconds); string item; long index; Console.Write("Item to show: "); while (!string.IsNullOrWhiteSpace((item = Console.ReadLine()))) { if (long.TryParse(item, out index) && index >= 0 && index UPDATE I added a static method to load all data in a file to an array. Obviously this approach takes more time initially (on my laptop takes between 1 and 2 min) but after that access performance is what you expect from .Net. This method should be useful if you have to access data frequently. Usage is pretty simple double[] helper = Storage .GetArray("Storage.bin"); HTH
