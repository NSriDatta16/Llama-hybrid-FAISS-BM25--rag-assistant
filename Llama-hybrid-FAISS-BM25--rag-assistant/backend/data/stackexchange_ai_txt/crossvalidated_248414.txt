[site]: crossvalidated
[post_id]: 248414
[parent_id]: 248113
[tags]: 
This is an interesting idea, and I can see how it is intuitively compelling, but I think it is too vague to be true or false. Here are a couple of questions I would want the commenter to clear up: A confidence interval for what (a mean, a variance, something else)? How was the interval computed (using large sample theory, bootstrapping, etc.)? In what sense exactly would the 50% CI be "more robust" or "less sensitive", and to what assumptions? With different answers to those questions, I think we could make the statement clearly true or false. My guess is that the commenter is referring to: a confidence interval for the mean computed using large sample theory, where the data's distribution is not contaminated with outliers but does come from a distribution other than the normal that is similar to the normal in the middle, but not the tails, and the idea is that the true asymptotic coverage more closely approximates the nominal coverage. If those are what the commenter has in mind, depending on how the tails of the distribution trade off with its shoulders, the statement could be true. For example, consider a plot of the normal distribution's and several low-df $t$-distributions' CDFs (copied from Wikipedia ). A confidence interval based on the normal from $\Phi^{-1}(.25)$ to $\Phi^{-1}(.75)$ would have nearly the appropriate coverage for the low-df $t$s, if those represented the true sampling distributions of the statistic at issue. In fact, it looks like a 20% confidence interval would have nearly perfect coverage, even in the case of a Cauchy ($t_{df = 1}$) distribution:
