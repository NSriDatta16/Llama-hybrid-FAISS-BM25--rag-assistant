[site]: datascience
[post_id]: 32754
[parent_id]: 32726
[tags]: 
I think that finding the absolute dimension of expressivity is a difficult problem. Here are some important facts to consider when you come with a word embedding size. Make sure you leave enough dimensions for expressivity. You want to make sure that there is at least enough dimensions to express the complexity of the structure you are looking to encode That the number of dimensions is not too large so that you suffer some difficulties in computation. To conclude, finding the infimum can be done post-hoc, in the sense that you can evaluate the performance on the function and see which value of $d$ does not significantly decrease the performance and choose it this way. However, at a post-hoc level, the only way I can see of doing this is by evaluating the embedding space beforehand, I have not read too much literature about this. https://arxiv.org/pdf/1711.00331.pdf - Semantic Structure and Interpretability of Word Embeddings There is also a lot of work done to evaluate the embedding schemes that we have chosen. In the recent NAACL conference there has been work that has been done in this domain particularly.
