[site]: datascience
[post_id]: 86433
[parent_id]: 86427
[tags]: 
Interesting task :) I think even with a good amount of training data it will be difficult for a regular NER model to perform well with new books titles and authors: The book may contain persons names which are not authors. The book titles are difficult to identify as such in general. For example "the Republic" might or might not be about the book, and if the only indication the model can use is the capitalization it's probably going to make some errors. To be clear, I think it could work to some extent but it would probably make quite a lot of errors. On the other hand you could obtain a database of books, for instance from Wikipedia (there might be better resources), and you could use this in two ways: Directly identify the books/authors in the documents by simple string matching. I would imagine that even if the coverage of the resource is not perfect, this method would easily catch a majority of occurrences. In case the above method is not sufficient, it provides you with some good training data from which you could train a NER model in order collect titles which don't exist in the database. Note that there might be issues due to the unknown books being labelled as negative in the training data, so ideally you would have to go manually through the training data and annotate the remaining cases.
