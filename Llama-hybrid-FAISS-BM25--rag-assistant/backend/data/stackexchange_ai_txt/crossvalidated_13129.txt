[site]: crossvalidated
[post_id]: 13129
[parent_id]: 13014
[tags]: 
"I'm wondering what is the best way to combine these numbers in a way that will yield a final score that is (hopefully) more reliable than any single test." A very common way is to compute Cronbach's alpha and, more generally, to perform what some would call a "standard" reliability analysis. This would show to what degree a given score correlates with the mean of the 17 other scores; which tests' scores might be best dropped from the scale; and what the internal consistency reliability is both with all 18 and with a given subset. Now, some of your comments seem to indicate that many of these 18 are uncorrelated; if that is true, you may end up with a scale that consists of just a few tests. EDIT AFTER COMMENT: Another approach draws on the idea that there is a tradeoff between internal consistency and validity. The less correlated your tests are, the better their content coverage, which enhances content validity (if not reliability). So thinking along these lines you would ignore Cronbach's alpha and the related indicators of item-total correlation and instead use a priori reasoning to combine the 18 tests into a scale. Hopefully such a scale would correlate highly with your gold standard.
