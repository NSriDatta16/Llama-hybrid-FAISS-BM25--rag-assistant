[site]: crossvalidated
[post_id]: 397351
[parent_id]: 396923
[tags]: 
I realized that I made an error in generating the fake data here. The variable leaky is getting information about $x_1$ and $x_2$ which are mean 0 random variables. Leaking information about the realizations of pure noise in train is not going to help you predict pure noise in test. When I correct for this, the Random Forest does indeed find the interaction effect. n_samples = 10000 x1 = np.random.normal(loc=0.5, scale=1, size=(n_samples,)) x2 = np.random.normal(loc=0.75, scale=1, size=(n_samples,)) random_noise = np.random.normal(scale=5, size=(n_samples,)) y = x1 + x2 + random_noise elements = [0, 1] probabilities = [0.20, 0.80] flag = np.random.choice(elements, n_samples, p=probabilities) leaky = np.where(flag==0, y, np.random.normal(scale=10, size=(n_samples,))) X = np.column_stack([x1, x2, flag, leaky]) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) mod_reg = LinearRegression().fit(X_train, y_train) preds_reg = mod_reg.predict(X_test) mod_tree = RandomForestRegressor(n_estimators=1000, min_samples_leaf=3).fit(X_train, y_train) preds_tree = mod_tree.predict(X_test) print(mod_reg.score(X_test, y_test)) print(mod_reg.score(X_test[X_test[:, 2]==0], y_test[X_test[:, 2]==0])) 0.0610796852093 0.140946827667 print(mod_tree.score(X_test, y_test)) print(mod_tree.score(X_test[X_test[:, 2]==0], y_test[X_test[:, 2]==0])) 0.175594757301 0.999790235233
