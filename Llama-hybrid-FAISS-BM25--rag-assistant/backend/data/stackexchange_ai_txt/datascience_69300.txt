[site]: datascience
[post_id]: 69300
[parent_id]: 
[tags]: 
Reformulating the maximal margin classifier optimization problem

Ok, so I've been trying to read up on how SVM's work and started with maximal margin classifiers. At page $132$ in ESL (Elements of Statistical Learning) the authors "reformulates" the optimization problem but I can't seem to understand what they are doing from $(4.47)$ to $(4.48)$ . Does anyone know? Here is an excerpt: Edit: I guess, what I don't understand is why we can arbitrarly set the magnitude of beta to $\frac1M$ . What does a positively scaled multiple mean in this case? Just a multiple larger than $0$ ?
