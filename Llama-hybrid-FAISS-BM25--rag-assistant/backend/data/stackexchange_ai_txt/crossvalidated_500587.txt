[site]: crossvalidated
[post_id]: 500587
[parent_id]: 500489
[tags]: 
SVMs learn classification by defining a hyperplane using whatever kernel you are using (the case that is easiest to understand is a linear kernel where the hyperplane is just a linear plane). To visualize what would happen, you can take a look at the image below (for the simple example with only two classes and two predictor dimensions x and y) and imagine that you only have the observations with the red arrow pointing at them. You can see how SVM can still find a hyperplane (in this case, a line) to separate the two classes.
