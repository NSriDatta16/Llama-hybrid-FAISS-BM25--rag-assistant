[site]: crossvalidated
[post_id]: 559900
[parent_id]: 559896
[tags]: 
It is possible to compute a bound on the leave-one-out error of the SVM (I've used the Radius-Margin bound and the Span bound and found they work quite well). This is often better than using a validation set as it leaves more data for training, and is computationally efficient. If you are performing feature selection with the SVM, it may make generalisation performance worse rather than better, due to over-fitting the model/feature selection criterion (see also the paper by Ambroise and Maclachlan ). Personally I tend to tune the hyper-parameters from scratch each time I train it on a new sample of data (and adding or deleting features means it is a new sample). However, this can also lead to over-fitting the model selection criterion.
