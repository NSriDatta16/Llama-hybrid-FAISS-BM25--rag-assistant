[site]: crossvalidated
[post_id]: 555397
[parent_id]: 
[tags]: 
I would like to ask: the setting of the reward function in the reinforcement learning

I would like to ask: when the reward function is composed of different optimization objectives, assuming that the dimensions of these objectives are inconsistent, do you need to dimensionalize these objectives. Many thanks for you! Allow me to introduce an example first. In the paper (doi.org/10.1016/j.trc.2021.103489), the reward in Eq.(17) is compiled like this: r=w1ﾃ由1+w2ﾃ由2+w3ﾃ由3+w4ﾃ由4: where the r1 denotes the driving speed (m/s) while the r3 is the fuel consumption (kw/ton). Thus the two components have different dimensions. How can they be combined directly?
