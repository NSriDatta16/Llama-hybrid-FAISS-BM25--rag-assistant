[site]: crossvalidated
[post_id]: 289404
[parent_id]: 289182
[tags]: 
There are two popular ways to find the hyper-parameters. You already mentioned this, is brute force approach of doing a grid search or random search. This involves picking multiple hyper-parameters (either from a grid or at random) and finding the one that works best in a K-fold cross-validation / validation set. Random search works typically better than grid search. Ref: http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf Bayesian optimization, where you start at some initial best guess, and gradually move towards a solution based on a "cost function", each time running with a new set of hyper-parameters that probably improve the result over the previous set. This had some good references: https://arimo.com/data-science/2016/bayesian-optimization-hyperparameter-tuning/ Note, neither guarantee any theoretical guarantees to get to a good set of hyper-parameters, and require multiple runs (proportional to the number of hyper-parameters to tune).
