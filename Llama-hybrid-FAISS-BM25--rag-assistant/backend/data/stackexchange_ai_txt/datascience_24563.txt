[site]: datascience
[post_id]: 24563
[parent_id]: 24552
[tags]: 
The Capsule Networks by Geoff Hinton et al. are based on a similar idea to SIFT: in fact, if you look at the 2011 paper, Transforming Auto-Encoders by Hinton et al. they explicitly cite SIFT as an inspiration for Capsules. The main idea is that they construct a network with a new type of unit called a Capsule which outputs a vector (rather than neurons outputting scalars, as we know in traditional neural networks). You can think of these vectors as an analogue to the SIFT keypoints and feature descriptors, but with the benefit that they can be learned via back-propagation. There is a recent article, Dynamic Routing Between Capsules by Sabour, Frosst and Hinton elaborating on this which shows very promising results. I have written a short summary of Capsule Networks on the AI Stack Exchange, see the question What's the main concept behind Capsule Networks? .
