[site]: crossvalidated
[post_id]: 476553
[parent_id]: 475506
[tags]: 
The random effects in mgcv are proper random effects; there is a way to view random effects, penalized smooths, Gaussian processes, & Gaussian Markov Random Fields all as a Gaussian random field. From that viewpoint, all these things are the same general type of thing and it is only the small details of each specific thing that gives rise to the diversity of terms in this general class. In mgcv , GAMs are fitted via penalized likelihood where the penalty takes the form of $$\boldsymbol{\lambda} \boldsymbol{\beta}^{\prime}\boldsymbol{S}\boldsymbol{\beta}$$ where $\boldsymbol{\lambda}$ is a vector of smoothness parameters, $\boldsymbol{\beta}$ are the estimated model coefficients, and $\boldsymbol{S}$ are penalty matrices. In the normal smooth types in mgcv , with the default settings, the penalty matrix is defined such that $\boldsymbol{\beta}^{\prime}\boldsymbol{S}\boldsymbol{\beta}$ measures the wiggliness of the smooth, i.e. the integrated squared second derivative of the smooth. But we can imagine different forms for $\boldsymbol{S}$ that measure other types of "complexity" and random effects use one such form for the penalty matrix, an identity matrix. The identity matrix means we have a ridge penalty on the model coefficients (or those associated with the random effect "smooth" in a model with multiple terms) associated with the random effect term, that penalty measures how far the coefficients deviate from 0, which implies shrinkage in the model estimates towards 0. Just like in random effects in a mixed model. The smoothness parameter for random effects smooths is proportional to the variance parameter (IIRC it is actually related to the inverse of the variance parameter, the precision, rather than the variance itself). And the Bayesian view of smoothing (with model = "REML" or "ML" ) means that everything above is really a fancy set of random effects, whether you're using spline smooths, random effects, MRFs, etc. Why s() for random effects? I think this really just comes down to keeping the UI simple. Also, you wouldn't be able to combine, through tensor products, random effects if they had to be specified via their own function re() say. From the point of view of the model, these different types of effects are just due to variations in the form of the penalty matrix $\boldsymbol{S}$ . As such, it makes sens I think to just view the s() , te() , etc as setting up these more general Gaussian fields and not to think of them as smooths in the sense of splines. We can only set up a "smooth" using a factor if we declare that the basis type is the random effect basis ( bs = "re" ): if you don't declare this, you'll get an error for a factor. Do they work the same way as in a linear mixed effects model (such as lme4 )? Yes, but there is a difference if you start adding terms for say random intercepts and slopes. The default syntax in lme results in correlated random effects and you have to use a more complex syntax/formulation to get uncorrelated effects. mgcv * doesn't do correlated random effects, as far as I can tell. Assuming Region and Primary are factors, then these terms are adding random intercepts (deviations from the overall mean, the model constant term) for each level of the factors. If you plot the model ( plot(mod) ) you'll see QQ-plots for the two random effects terms, showing the estimated intercepts for the different levels, just as you would if you looked at a QQ plot of the random effects in a model fitted using lme4 . The edf column in the output is showing you an estimate of the complexity, effective degrees of freedom, for each term. The Ref.df column shows the reference values for the tests; the difference between the two for the random effects terms is due to the shrinkage of the random intercepts towards 0 (i.e. towards the model intercept). The test shown here for the random effects are specialised tests developed for random effects and where the reference distribution is corrected for testing on the boundary of the parameter space, unlike the GLRT tests in lme4 when comparing models that differ in terms of the random effects structure only.
