[site]: crossvalidated
[post_id]: 263803
[parent_id]: 
[tags]: 
Input data normalization

I saw it sometimes that the input data for Neural Networks was scaled to $[0, 1]$ (or $[-1, 1]$), but also sometimes that it was normalized. E.g. for a greyscale image the normalization was done using the distribution of the different pixel values of the specific input image. But this has the effect that different images (shifted images) result in the same input for the neural network? Isn't this bad? Or does it make sense to just insert a BatchNormalization-layer as the initial layer of a Neural Network? If not: Why not? Or should in general no normalization be done, but only scaling the data to a new specific range?
