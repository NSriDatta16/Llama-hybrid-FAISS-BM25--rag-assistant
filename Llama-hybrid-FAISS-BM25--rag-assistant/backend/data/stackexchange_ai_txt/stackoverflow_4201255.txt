[site]: stackoverflow
[post_id]: 4201255
[parent_id]: 
[tags]: 
Java Multi Link Checker Spider - improvements needed

I have following working code (changed here and there so you use your brain when you copy and paste it). I'd like to improve it so it detects all pages that are invalid including domains for sale. It works at about 89% efficiency. If you see anything I could improve by using additional existing libraries or little tweaks that would be awesome. List all = linkService.getAllLinks(); notValidLinks = new LinkedList(); final ArrayBlockingQueue queue = new ArrayBlockingQueue (39867); int poolSize = 90; int maxPoolSize = 100; long keepAliveTime = 40; ThreadPoolExecutor tpe = new ThreadPoolExecutor(poolSize, maxPoolSize, keepAliveTime, TimeUnit.SECONDS, queue); for (link : all) { Thread task = new CheckSite(link); tpe.execute(task); System.out.println("Task count:" + queue.size()); } class CheckSite extends Thread { Link link; CheckSite(Link link) { this.link = link; } public void run() { boolean notValid = false; try { log.info(link.getLink() + " " + link.getId()); URL u = new URL(link.getLink()); HttpURLConnection huc = (HttpURLConnection) u.openConnection(); HttpURLConnection.setFollowRedirects(false); huc.setConnectTimeout(40000); huc.setRequestMethod("GET"); huc.setRequestProperty("User-Agent", "Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.2) Gecko/20090729 Firefox/3.5.2 (.NET CLR 3.5.30729)"); huc.connect(); int code = huc.getResponseCode(); if (code != HttpURLConnection.HTTP_OK && code != HttpURLConnection.HTTP_MOVED_PERM && code != HttpURLConnection.HTTP_MOVED_TEMP ){ notValid = true; log.info("Invalid code: " + code + " - " + link.getLink()); } if (code == HttpURLConnection.HTTP_MOVED_PERM) { log.info(link.getLink() + " Perm move"); } if (code == HttpURLConnection.HTTP_MOVED_TEMP) { log.info(link.getLink() + " Temp move"); } try { if (!notValid) { BufferedReader reader = new BufferedReader(new InputStreamReader(huc.getInputStream())); StringBuilder stringBuilder = new StringBuilder(); String line; while ((line = reader.readLine()) != null) { stringBuilder.append(line); } notValid = StringUtils.containsIgnoreCase(Jsoup.parse(stringBuilder.toString()).text(), "Related Searches"); } } catch (Exception e) { log.error(e.getMessage()); } huc.disconnect(); } catch (MalformedURLException me) { log.info("Malformed URL:" + link.getLink()); notValid = true; } catch (IOException e) { log.info("Refused connection | Does not exist:" + link.getLink()); notValid = true; } if (notValid) { link.setApproved(false); link.setDateApproved(null); notValidLinks.add(linkService.save(link)); } log.debug("URL Finieshed!"); } }
