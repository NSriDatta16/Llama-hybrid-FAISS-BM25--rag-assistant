[site]: crossvalidated
[post_id]: 451202
[parent_id]: 215229
[tags]: 
We need to first clarify things here. The original derivation of Kalman filter is optimal for causal predictions. That means you predict at time $t$ given observations until time $t$ . Now for the maximum likelihood (ML) inference of parameters, assuming that these parameters are shared across time, during inference of hidden state variables you need to use the non-causal version of Kalman filter, that is the forward-backward Kalman filter (RTS smoothing). After that you carry out ML estimation as usual. This is an instance of the well-known Expectation-Maximization algorithm, applied within the context of Kalman Filtering as early as 1982! Therefore it is iterative, and you do not necessarily arrive at a global optimum. As typical with these models, starting from a sensible values of hyperparameters first and running the forward-backward algorithm thereon will give better results. This is the case with most Bayesian models that result in non-convex objective functions (EM, Variational Inference, ...). For further reference, check Appendix A.3 of the review paper by Roweis and Ghahramani: https://authors.library.caltech.edu/13697/1/ROWnc99.pdf
