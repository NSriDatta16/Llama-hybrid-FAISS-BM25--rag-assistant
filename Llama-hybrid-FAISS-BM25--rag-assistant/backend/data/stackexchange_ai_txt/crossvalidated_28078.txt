[site]: crossvalidated
[post_id]: 28078
[parent_id]: 25820
[tags]: 
I understand your question as asking about LDA, rather than about the mechanisms of Gibbs sampling. Thus, my answer to the question of why the Gibbs sampling algorithm works is that it is designed to do LDA: our goal is to fit the best possible LDA model given the data and our initial parameter settings. How many topics (that is, how much clustering) LDA does depends on the choice of the Dirichlet concentration parameters. I'm not an expert on using LDA, but so far as I know these parameters are usually fixed beforehand or drawn from a fixed distribution which makes the Gibbs sampling algorithm more convenient to sample. I read the quoted paragraph as saying, roughly, that if we decide to penalize models with many topics, we will force LDA to perform more clustering: it will have to find the best way to describe all the documents using the fewer topics.
