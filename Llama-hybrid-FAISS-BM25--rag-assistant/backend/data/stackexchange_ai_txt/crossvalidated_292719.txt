[site]: crossvalidated
[post_id]: 292719
[parent_id]: 
[tags]: 
Best practices to handle large-scale binary classification

I have a large training file (~2.4GB, ~31k rows). Each row contains around ~40k binary features, and the label is binary as well. I tried to use default sklearn logistic regression (loading dataset with pandas), but it is too slow (6 hours and still continue). What are some good practices to deal with this problem? Thank you very much,
