[site]: crossvalidated
[post_id]: 242141
[parent_id]: 241963
[tags]: 
I found this answer from The Stats Geek , which explains it quite well: Why is the standard estimate (estimator) of $r^2$ biased? One way of seeing why it can't be unbiased is that by its definition the estimates always lie between 0 and 1. From one perspective this a very appealing property - since the true $r^2$ lies between 0 and 1, having estimates which fall outside this range wouldn't be nice (this can happen for adjusted $r^2$). However, suppose the true $r^2$ is 0 - i.e. the covariates are completely independent of the outcome Y. In repeated samples, the $r^2$ estimates will be above 0, and their average will therefore be above 0. Since the bias is the difference between the average of the estimates in repeated samples and the true value (0 here), the simple $r^2$ estimator must be positively biased.
