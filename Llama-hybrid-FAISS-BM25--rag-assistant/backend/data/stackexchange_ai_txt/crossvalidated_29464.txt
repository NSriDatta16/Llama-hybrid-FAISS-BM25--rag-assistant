[site]: crossvalidated
[post_id]: 29464
[parent_id]: 29462
[tags]: 
Yes, it's definitely a Markov chain because the observed variables define the transition probabilities from every latent variable configuration to every other. (That is, they yield an $n \times n$ matrix of probabilities where $n$ is the number of latent variable configurations.) Usually you can say more about the Markov chain: If you're talking about Boltzmann machines, for example, then the Markov chain you get from iterating the variables is time-homogenous since time doesn't matter. This would also be true in a regular Markov model if you were to hold the observed nodes fixed. For Boltzmann machines, you also have ergodicity since all states are positive recurrent (for finite weights). You can often have the same property for a Markov model. If you have an ergodic, time-homogenous Markov chain, then the network converges to a steady state distribution.
