[site]: crossvalidated
[post_id]: 344508
[parent_id]: 
[tags]: 
What are attention mechanisms exactly?

Attention mechanisms have been used in various Deep Learning papers in the last few years. Ilya Sutskever, head of research at Open AI, has enthusiastically praised them: https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0 Eugenio Culurciello at Purdue University has claimed that RNNs and LSTMs should be abandoned in favor of purely attention-based neural networks: https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0 This seems an exaggeration, but it's undeniable that purely attention-based models have done quite well in sequence modeling tasks: we all know about the aptly named paper from Google, Attention is all you need However, what exactly are attention-based models? I've yet to find a clear explanation of such models. Suppose I want to forecast the new values of a multivariate time series, given its historical values. It's quite clear how to do that with an RNN having LSTM cells. How would I do the same with an attention-based model?
