[site]: crossvalidated
[post_id]: 52328
[parent_id]: 52323
[tags]: 
The most common approach is to apply PCA to the covariance (or correlation) matrix of the log changes in the data. It would not matter in this case if you indexed the data. In this case, you would be attempting to find the eigenvectors that explain the most of the variance of the underlying data. The purpose of this dimension reduction is usually to focus on the key factors and improve estimation of the covariance matrix. If you are dealing with data that has very different variances, then it is possible for the first eigenvalue to be dominated by the high variance variables. This is especially true if you are working with some data that you should take the log of (like equities or GDP) and data that you probably shouldn't take the log of (some confidence indicators that are bound between 0 and 100, interest rates). In this case, it can be helpful to take the PCA on the correlation matrix, which removes the impact of differing variances between variables. However, care should be taken when constructing factors based on these eigenvectors (instead of multiplying the returns by the eigenvectors, you would multiply the z-score of the returns by the eigenvectors to obtain uncorrelated factors). That's not to say that it is unreasonable to apply PCA to levels. It is possible to apply PCA on levels and consider the eigenvectors as potentially cointegrating vectors. So you can construct factors and apply cointegration tests to the factors and include them in an ECM if significant. So it depends on what you're trying to accomplish, but the most people apply PCA to the returns.
