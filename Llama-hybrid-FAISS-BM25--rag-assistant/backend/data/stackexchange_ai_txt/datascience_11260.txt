[site]: datascience
[post_id]: 11260
[parent_id]: 11247
[tags]: 
Mainly the accuracy depends upon pre-processing steps, features extracted and the learning model used. Pre-processing steps normally includes removal of stop words and that is fine. Features extraction is of various methods. Word embeddings is gaining its popularity in NLP, due to its interesting characteristics of vectors generated. Gensim provides a nice python library for word embeddings both word2vec as well as doc2vec models. For the detailed algorithm of how it works, read word2vec , doc2vec There are lot of learning models from naive bayes, svm to neural network models. The accuracy of it depends upon the dataset used and the features generated and so each models need to be tested under trial and error method. sklearn provides a nice support for ML models.
