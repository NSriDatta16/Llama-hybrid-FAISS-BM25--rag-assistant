[site]: datascience
[post_id]: 65726
[parent_id]: 
[tags]: 
How to explain the connection between the input layer and H1 of this CNN Architecture?

I am currently reading the paper proposed by LeCun et al. for handwritten zip code recognition. There is this figure below visualizing the CNN architecture. But I do not really understand how the connection between Layer H1 and input layer makes sense. If there are 12 kernels with size 5x5, shouldn't the layer H1 be 12x144? Or is there any downsampling taking place here too?
