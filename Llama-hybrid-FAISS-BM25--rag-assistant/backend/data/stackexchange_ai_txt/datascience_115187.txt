[site]: datascience
[post_id]: 115187
[parent_id]: 
[tags]: 
Can we train of a binary classifier with "A" to classify "a"?

I have a maybe naive question about the appropriateness of using binary classifications. This is a hypothetical example, so forgive me if it is too coarse. Let's say I want to train a support vector machine to classify the letter "a" from the letters "b" and "c". The problem is that I don't have letter "a" to train my SVM model, but I do have a lot of letters "A" which basically mean the same. It is a model like this valid? My real problem is within the realm of image processing. I have some pixels that I want to classify using texture but I don't have a "class" for those pixels. I do have ground truth for something very similar (that I know the class) and I have been using the same kind of texture (but from this similar pixels) to train a SVM and do the classification. This SVM works reasonably well (assessed with the visual inspection of the images) with some accuracies up to 90%. The problem I think is that this accuracy is tested with the training of "A" and not "a" Does this make any sense? Is something like this valid? or there is anything else that I can do to make this a valid classification? How do you test accuracy in something like this?
