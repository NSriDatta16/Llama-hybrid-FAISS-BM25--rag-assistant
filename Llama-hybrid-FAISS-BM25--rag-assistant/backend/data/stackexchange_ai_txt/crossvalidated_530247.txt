[site]: crossvalidated
[post_id]: 530247
[parent_id]: 418335
[tags]: 
This is more a comment than an answer, but I hope it may be of some help. A difficulty, more frequent than one might think, in answering a probability & statistical question is that the question itself is actually ill-defined. And unfortunately our language doesn't help us in recognizing this problem: the question we ask is grammatically correct and seem at first sight to have a meaning – but it actually doesn't. The situation often becomes even worse when the question is dressed in technical terms. "Which model is best?" – well, what do we mean by "best"? "How to compare these two models?" – well, what do we exactly mean with "compare"? (and what do we mean by "model"?) We can introduce metrics of various kinds to make this kind of questions more precise. Then the problem is the rational justification of that particular metric. In the end there's often a lot of subjectivity swept under the carpet. In your specific case, what I wonder first of all is why the whole dataset has not been used to obtain a unique distribution for the $\alpha$ s (or $\beta$ s), rather than dividing it into two copies of the same parametric model. The probability distribution for the model parameters would be sharper. A second point is that if we are uncertain between two models $M_1$ and $M_2$ , probability theory tells us that we should use a convex combination of the two, weighted by their probabilities given the data $D$ : $$\mathrm{p}[x \mid (M_1 \lor M_2) \land D] = \mathrm{p}(x \mid M_1 \land D) \ \mathrm{p}(M_1 \mid D) + \mathrm{p}(x \mid M_2 \land D) \ \mathrm{p}(M_2 \mid D)$$ this is called "model averaging". See for example Draper: Assessment and Propagation of Model Uncertainty (also here ) for an early reference. I believe that in your case this is equivalent to using just one copy of your model, with all data determining a distribution for its $\alpha$ s. A third, final point is that if you want to choose a single $x$ value then you have a decision-theory problem, so you should choose and justify an appropriate utility function – which makes precise what you mean with "best" $x$ – and make your choice by maximization of expected utility. See for example chapters 13–14 of Jaynes: Probability Theory: The Logic of Science (also here and here )
