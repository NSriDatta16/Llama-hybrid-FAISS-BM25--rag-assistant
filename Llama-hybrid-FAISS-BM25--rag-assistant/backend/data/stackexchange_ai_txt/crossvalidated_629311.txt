[site]: crossvalidated
[post_id]: 629311
[parent_id]: 629155
[tags]: 
This is a great question, similar ones arise all the time when modeling data. For example, user ratings on a scale of 1-5 and economic data binned by quintiles. They're certainly numbers. But they're not continuous so it's not obvious. I'll cut to the chase and suggest the following: if your model is susceptible to overfitting you'll most likely benefit from treating it as a single numeric feature if you have a lot of data and overfitting is less of a concern, I suggest starting with modeling as one feature with the decades, and 13 additional one-hot features, 1 for each decade. Then use feature selection to determine which representation is best. You may find that a few of the one-hot/indicator variables for are particularly important because of the unique (dare I say, categorical ) social, political, and economic circumstances of those decades. Here's why: all common models, from OLS to deep neural nets, apply continuous domain mathematical operations to your input data. All they see are floating-point numbers. Even random forests, which pick a pivot and recursively partition your data. It's the same operation regardless of whether every value is unique or 90% are 0s and 10% are 1s. So the real question isn't whether to model your data as numeric, it's what feature vectors you should give to the model, and what their numeric values should be. Setting aside transformations and PCA and other pre-processing steps, there are ultimately two choices: one feature with the decades as numbers, as your colleague suggests. This generally makes sense when math operations on your values make sense. For example, adding 10 to the 1970s is arguably the 1980s. The 1980s are arguably halfway between the 1970s and 1990s. This representation allows the model to more easily learn long-term temporal trends in your data if they exist. "Easily" meaning less model complexity and fewer FLOPs. considering the feature to be categorical and making a separate 1-hot feature for each category. This is done when math operations don't make sense on your data. Arguably it does not make sense to average the roaring 20's with the WW2 economy of the 1940's to get the Great Depression of the 1930's. The average of the 1970s music with 1990s music isn't 1980s hair metal. So in this case you instead want to make 1-hot vectors to indicate which decade each organization was founded in. This representation makes it easier for models to learn decade-specific behavior. A nonlinear model with enough flexibility can learn to isolate decades from each other from a single numeric decades feature, it will just require a more complex model and that complexity will expose you more to overfitting. Without knowing more about your dataset and what you aim to model, there's no way to tell which is best for sure. My instinct is that treating it as a continuous numeric feature is probably the best single-feature way to use it, but it's a false choice - your model can probably accommodate an arbitrary number of features. So I encourage you to try both numeric and categorical, use some feature and model selection techniques, and find out for sure which one is best (or a combination of both).
