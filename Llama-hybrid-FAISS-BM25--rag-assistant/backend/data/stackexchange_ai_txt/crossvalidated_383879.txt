[site]: crossvalidated
[post_id]: 383879
[parent_id]: 
[tags]: 
Neural network's weight reduction

Are there any algorithms/methods for taking a trained model and reducing its number of weights with as little negative effect as possible to its final performance? Say I have a very big (too big) model which contains X weights and I want to cut it down to have 0.9*X weights with as little damage as possible to the final performance (or maybe even to the highest possible gain in some cases). Weight reduction occurs either by changing the model's basic architecture and removing layers or by reducing feature depth in said layers. Obviously after reduction some fine-tuning of the remaining weights will be required.
