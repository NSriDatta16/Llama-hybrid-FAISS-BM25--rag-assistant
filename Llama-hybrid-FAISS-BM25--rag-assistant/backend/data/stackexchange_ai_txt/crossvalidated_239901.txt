[site]: crossvalidated
[post_id]: 239901
[parent_id]: 237768
[tags]: 
I've spent the past few days researching this and doing some experiments. It seems that evaluating the softmax only at the end of the sequence is less effective for predicting the next value in a sequence, but is necessary if your task involves classifying a sequence as a whole (sentiment analysis for example). Here is a comparison of the error over time for only evaluating the softmax at the end of the sequence (shown in green) and evaluating it at every step in the sequence (shown in blue) Here is an example I found of different types of architectures for different problems. The "many to many" would be evaluating an output for every step in the sequence, and the "many to one" would be only evaluating a final prediction. It all depends on your task. I wrote a more in depth explanation as an answer to a similar question I asked here Why back propagate through time in a RNN?
