[site]: crossvalidated
[post_id]: 637210
[parent_id]: 
[tags]: 
XGBoost Learning to Rank with XGBClassifier

I am trying to build a model trained on binary labels that has a high precision for the top k predicted instances, and don’t care too much about recall or precision more generally. I was then interested in the idea of ranking instances in my classification problem rather than looking at prediction probabilities, so thought I could play around with XGBRanker with a single query group. I noticed that Learning to Rank parameters can be passed to XGBClassifier without raising any errors, and in fact with a single query group XGBClassifier and XGBRanker seem to output the same results (see code below to reproduce in python with xgboost v2.0.3). Using XGBClassifier would be simpler here as it then doesn’t break sklearn compatibility, but I am unsure whether this is a correct usage. I've asked about this on the XGBoost forum , but also wondered if anyone here had any insight into whether using XGBClassifier with objective='rank:map' is actually equivalent to using XGBRanker with a single query group. from sklearn.datasets import make_classification import numpy as np import xgboost as xgb # Make a synthetic ranking dataset for demonstration seed = 1994 X, y = make_classification(random_state=seed) rng = np.random.default_rng(seed) n_query_groups = 1 qid = rng.integers(0, n_query_groups, size=X.shape[0]) # Sort the inputs based on query index sorted_idx = np.argsort(qid) X = X[sorted_idx, :] y = y[sorted_idx] qid_sorted = qid[sorted_idx] ranker = xgb.XGBRanker(lambdarank_num_pair_per_sample=8, objective="rank:map") ranker.fit(X, y, qid=qid_sorted) classif = xgb.XGBClassifier(lambdarank_num_pair_per_sample=8, objective="rank:map") classif.fit(X, y) rank_prediction = ranker.predict(X) classif_prediction = classif.predict(X) classif_prediction_proba = classif.predict_proba(X)[:, 1] assert np.array_equal(rank_prediction, classif_prediction_proba)
