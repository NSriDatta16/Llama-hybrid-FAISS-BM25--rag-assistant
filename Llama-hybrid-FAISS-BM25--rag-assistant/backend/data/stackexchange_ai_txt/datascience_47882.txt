[site]: datascience
[post_id]: 47882
[parent_id]: 47861
[tags]: 
When class labels are known, you can use Linear Discriminant Analysis (LDA) for visualization to see whether classes are linearly separable. LDA is similar to PCA but supervised. It tries to project the data in a way that maximizes the distance between classes (here is a how-to post for Matlab, R, Python . Here is a mult-class LDA for Matlab). Also, we can get a sense of linearity without any visualization. To this end, we can train/test a linear SVM on [sample of] data and if the test accuracy (assuming class numbers are balanced) is 90%, 95%, 99%, it is an increasingly good indication that classes are almost linearly separable. Please note that we cannot use non-linear dimensionality reduction methods such as IsoMap or t-SNE , since they are able to show a linearly separated visualization even for classes that are not linearly separable in the original space, hence the name non-linear . Here is the famous Swiss roll example:
