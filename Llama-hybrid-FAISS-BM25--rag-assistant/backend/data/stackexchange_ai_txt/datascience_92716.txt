[site]: datascience
[post_id]: 92716
[parent_id]: 92714
[tags]: 
There are no clear restrictions on can you cluster the data or not based on the data itself (in most of the cases), but you might face restrictions based on computational speed. The question is what you want to achieve in the end, but you can for sure cluster the data or reduce dimensions. You can also take a subset of your data, cluster it and then train ML model, something like catboost or lightgbm to predict clusters, instead of doing clustering on whole dataset. In my experience it will be faster to use model for cluster predictions. For dimension reduction, you can go for PCA or TruncatedSVD , here are some useful links: https://scikit-learn.org/stable/modules/unsupervised_reduction.html https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html But remember, that this techniques will reduce the number of features, not the rows, so you can still face computational issues. If you want a way to map your high-dimensional data (around ~50 dimensions or less usually), you can use t-SNE https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html
