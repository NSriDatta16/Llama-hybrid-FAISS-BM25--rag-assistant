[site]: crossvalidated
[post_id]: 310124
[parent_id]: 
[tags]: 
Is my model selection approach correct?

I am trying to find the best k for my kNN algorithm. I am using K Fold CV and Stratified K fold CV, with K = 5, 10 & 20. I run a K-Fold CV on my training dataset, for each k [1-50]. In the end, I have 50 cross-validated accuracy values (% of correctly classified labels). I only run the K-Fold CV once. Then, I do the same thing, but instead of using K-Fold CV, I use Stratified K-Fold CV. In the end, I once again have 50 cross-validated accuracy values (% of correctly classified labels). I only run the Stratified K-Fold CV once. Now, here are my questions: If I am doing both K-Fold CV and Stratified K-Fold CV, which one should I choose? I am going with Stratified, as each fold has same proportions of classes, so it should be less biased and have less variance, but I am not sure. Which K should I choose? My dataset is small (like 150 items), so should I choose the results from K = 10? As K = 5 will have higher bias, but lower variance and K = 20 will have lower bias, but higher variance, so I feel K = 10 is a good balance. I have calculated the standard error for each K/k combo, for K = 5, 10 and 20, and k = 1 - 50, so in total I have 50 SE values for each K . I used the formula of sample standard deviation/sqrt(K) to do calculate the SE. But I am not sure how to use the value. For example, in Stratified K-Fold CV, the k with the highest cross-validated accuracy has the lowest SE. In the end, for K-Fold CV, I have one k value for K = 5, 10 and 15 all three of them, that gives the highest cross-validated accuracy and lowest SE. For Stratified K-Fold CV, I have one k value for K = 5, 10 and 15 all three of them, that gives the highest cross-validated accuracy and lowest SE. The difference is that the best k obtained in K-Fold CV is different from the best k obtained from the Stratified K-Fold CV. Do I need to run my K-Fold CV multiple times and calculated the average cross-validated accuracy and average standard error? Does that even make sense i.e average of averages, as the cross-validated accuracy itself is an average of accuracies of the individual K folds. When I test on the independent test data I have, the best k value given by K-Fold CV return 100% accuracy, where as the best k given by Stratified K-Fold returns 93% accuracy. So I am a bit confused as to which value should I choose.
