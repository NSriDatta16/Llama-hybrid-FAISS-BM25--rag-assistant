[site]: datascience
[post_id]: 33823
[parent_id]: 33231
[tags]: 
You're taking on a really hard problem. Maybe try to break it down into easier sub-problems like: use a solution like Ms Vision of equivalent from Google or AWS to extract text/numeric data from invoice images figure out some categories you can split you invoices into (maybe by country and/or company type?) train some classifier (whatever trainable image classifier you find easier to configure and use, probably there's some easy to use one in Azure/AWS/Google machine learning APIs) to classify the invoices, by using their images not the previously extracted text data then have a "final model" that can be tuned to take into consideration stuff different for each "invoice class", that could contain even hand coded features and heuristics specific for eg. "invoices from country X", that takes as input test/numeric data extracted at first step plus invoice class classified by the image classifier The intuition is that there are probable N max invoicing software providers for each geographic are, and those software have an max M number of output configurations, so there should be a bunch of heuristic shortcuts you can exploit around here and incorporate into your step 4 model. But what that step 4 model should be I cannot tell, so this is just a bunch of hints, not a real answer, I know... And about: I was thinking x-y coordinate pairs of where the important information occurs on the image. I can just tell you this approach is probably bad, never heard of anyone getting anywhere with "extracted data + (x, y) of where it was extracted from image" approach. You either take on yourself the full task of going from [image data] to [extracted numeric features] which would be a gargantuan, practically impossible task (you'd basically need to reinvent a version of what Azure ML does, only that it would be specifically optimized for you task of invoice data extraction).
