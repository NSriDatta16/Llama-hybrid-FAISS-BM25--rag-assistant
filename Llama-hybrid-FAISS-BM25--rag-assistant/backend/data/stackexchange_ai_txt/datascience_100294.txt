[site]: datascience
[post_id]: 100294
[parent_id]: 100134
[tags]: 
In short, the answer is yes, your intuition is correct. The problem you are trying to solve is a Multiagent Reinforcement Learning problem and single-agent approaches don't work well here. One of the main obstacles is the non-stationary transitions of the environment's states. There are various settings (e.g. competitive and collaborative) and training techniques (decentralized and centralized) or combinations of them. You also need to be very careful how you will design the state space and the reward function of your problem. One approach that is commonly used in AC architectures is to use a centralized critic and decentralized actors. In other words, critic receives the full state of the environment whereas the actors receive the local state representation. For your specific problem, I suggest you to take a look at this review of Cooperative MARL, especially p. 16. 17 which reviews DQN and the role of the experience replay and then discusses centralized critic.
