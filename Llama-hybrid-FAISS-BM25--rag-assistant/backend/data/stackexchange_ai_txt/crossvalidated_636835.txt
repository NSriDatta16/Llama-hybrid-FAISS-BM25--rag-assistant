[site]: crossvalidated
[post_id]: 636835
[parent_id]: 636829
[tags]: 
First, I don't think it's helpful to get hung up on how p values are calculated in these different models. The calculation of p values is fairly straightforward from a given coefficient and its standard error. The more important issue is what each coefficient and standard error represent in these models. Also, the p value associated with ANY intercept is almost always useless: it is telling you how confident you can be that the intercept is different from zero , regardless of whether that is a plausible or meaningful value. Stats programs tend to report p values for intercepts because they can, but they rarely tell you anything useful. Second, I think you are getting tripped up by the admittedly confusing terminology surrounding the terms "random" and "fixed." Try thinking about it like this: In a linear regression model with one independent variable (say "weeks") there are two key parameters: the intercept, and the slope coefficient. To say that we are treating one of these parameters as "fixed" means that we use the data to estimate a specific value for the entire sample. This is what we would do to both the intercept and slope coefficient in a single level OLS model: calculate a single intercept and a single slope coefficient for the whole model. Now, as you note, this doesn't necessarily make sense in longitudinal data, where observations are "nested" within individuals. In particular, the idea that there would be just one intercept for the entire dataset seems wrong and might bias our estimates of both coefficients and standard errors (and thus p values). It seems more likely that we would want to allow each individual to have their "own" intercept. There are two ways of dealing with this. The first, is just to add a series of dummy variables to the model, one for each value of the person-level identifier variable (omitting one as the reference category). Basically we are treating the person ID variable the same way we would treat a categorical variables like race in a single level model), in effect, giving each individual their own intercept, which we estimate directly, just like any other coefficient. In the context of multilevel modeling this approach is called a "fixed effects model" because each intercept is estimated directly. Here you get a separate coefficient (and p value) for each intercept, but they are not very useful because they just tell you how far that intercept is away from the arbitrary reference category. The coefficient and p value for any independent variables in this model tells you the "effect" of that variable controlling for ALL person-level differences (basically, you are using each person's earlier values as their own "control"). One problem with these models though is that they don't allow you to control or any person level variables, because those variables will be perfectly colinear with the individual level intercepts. Also note that estimating all of these intercepts directly takes a lot of degrees of freedom, and thus increases standard errors. But there is an alternative. Instead of estimating the person-level intercepts individually, one by one, we could make the assumption that, in the population at large, these intercepts actually vary "randomly" (that is, according to a normal distribution) around some overall value. (this is the same assumption we make about the *error term in an OLS model - that individual errors vary normally around the regression line). We still estimate the overall value, but we don't actually try to compute a separate intercept for each person. Instead we use the data we have to compute the variance of the normal curve that we assume that these intercepts follow. These "random intercepts" (one per person) are what you could call the "random effects" in this model, but we don't estimate them directly, so we don't get coefficients (or p values) for them. As before we also get a coefficient (and p value) for any independent variables in the model. In this "random intercept" model, the random intercepts do account for the fact that some individuals have different starting points than others just due to random chance, but they do not account for systematic differences between individuals due to confounding variables (like SES or gender). But unlike in the fixed effects model we can account for those differences by including those variables as controls. So the coefficient we get for a particular independent variable (like weeks) may be biased due to omitted person-level confounders, although the estimate for the standard error around that coefficient does account for the nesting of observations within individuals, and does so more efficiently than the fixed effects model. To decide which of these three approaches is best for a given model is a complex task, too long to discuss here (there are tradeoffs between bias and efficiency). Google "hausman test" and "intraclass correlation coefficient" for more. Now we can also apply this same question to the coefficient of an independent variable in the model. Let's assume we've already decided to treat the intercept as a random effect. We could still just estimate a single slope coefficient for the entire sample like we normally do. Or we could allow the slope itself to also vary normally around an overall value. The assumption here is that there is an overall "average" effect for "weeks" but we assume that each individual's own slope varies according to a normal distribution around that average. Again, we don't estimate these person-specific slopes directly (so you won't get coefficients or p values for them), we just use the data we have to estimate the variance of that normal curve. Is this a good idea? This is actually somewhat tricky to figure out. The approach I use is to just run two versions of the same model, one with a random slope and one without, and calculate a likelihood ratio test to see if one has significantly better fit than the other.
