[site]: datascience
[post_id]: 24959
[parent_id]: 12554
[tags]: 
A remark on Sandeep's answer: Assuming 2 of your features are highly colinear (say equal 99% of time) Indeed only 1 feature is selected at each split, but for the next split, the xgb can select the other feature. Therefore, the xgb feature ranking will probably rank the 2 colinear features equally. Without some prior knowledge or other feature processing, you have almost no means from this provided ranking to detect that the 2 features are colinear. Now, as for the relative importance that outputs the xgboost, it should be very similar (or maybe exactly similar) to the sklearn gradient boostined tree ranking. See here for explainations.
