[site]: datascience
[post_id]: 62435
[parent_id]: 62433
[tags]: 
The latent vector $z$ is just random noise. The most frequent distributions for that noise are uniform: $z \sim U[-1,+1]$ or Gaussian: $z \sim \mathcal{N}(0, 1)$ . I am not aware of any theoretical study about the properties derived from different priors, so I think it's a practical choice: choose the one that works best in your case. The dimensionality of the noise depends on the architecture of the generator, but most of the GANs I've seen use a unidimensional vector of length between 100 and 256. In PyTorch, torch.Tensor.random_ and torch.randn can respectively be used to generate uniform and Gaussian noise.
