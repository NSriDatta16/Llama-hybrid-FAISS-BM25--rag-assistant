[site]: datascience
[post_id]: 115294
[parent_id]: 
[tags]: 
xgboost reduce float precision does not reduce train time

I expected that reducing the precision of my data (e.g., from int64 to int8) would speed up the training. But, even if I reduce the overall size of my dataset by 74%, I do not see an improvement. Is this expected?
