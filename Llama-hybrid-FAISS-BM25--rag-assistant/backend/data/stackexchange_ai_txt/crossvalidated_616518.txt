[site]: crossvalidated
[post_id]: 616518
[parent_id]: 616486
[tags]: 
I can think of different ways to do this. I think the most straightforward however is logistic regression, given your requirements (you need which items are most important and at the same time make class assignments for future datapoints). You could fit a logistic regression model to predict whether an individual is a member of group A or of group B, using the number of purchases of each item as features. (I'm assuming you have a wealth of individual-level data here). You can then calculate an odds ratio for each feature (i.e. how much each additional purchase of item X increases the odds of being Group B) and a 95% CI on that odds ratio. This functionality is standard in most software packages you can use to do logistic regression (e.g. in R or in statsmodels or scikit-learn in Python, see this StackOverflow for example ). This therefore simultaneously answers the question posed by your end users (which features are most important) and constructs a predictive model you can use on new data. Since your dataset is imbalanced (significantly more class A than class B datapoints), you'll need to use class weighting. You might also need to use L1 (promotes sparsity) or L2 (promotes small weight values) regularization. L1 regularization can be particularly useful if you want a sparse solution (i.e. want most of the weights to be zero so that only a small subset of the features are used, which I think is what you are after). A regularization technique that may be especially useful for your case is elastic net , which is a combination of L1 and L2 regularization. I would do some experiments (e.g. 5x cross validation ) on a small subset of your training data to see if regularization is beneficial and if so what hyperparameter setting you need. Alternatively, you might want to know which items offer the best differentiation between categories and then use only those as inputs to your logistic regression model, in other words, do feature selection before fitting. In this case, you could use a chi-square test at the level of each item (i.e. how many in group A purchased this item or did not and how many in group B purchased this item or did not) or mutual information to determine which items provide the best distinction between groups. Both of these are implemented as feature selection methods in the scikit-learn package in Python, and statsmodels of course has the chi-square test . (I guarantee all this can be done in R as well, although I use R less frequently and am therefore less familiar with all of the useful packages). I would be aware of course that if using the chi-square test, be careful about how you interpret the p-value since you are of course performing many statistical tests (since you have thousands of items) and therefore if you decide to use a p-value cutoff as some measure of significance, if you do not perform a multiple-test correction you have an increased chance of false positives. Also, if you are running cross-validation experiments when fitting your model, or if you assess your model on some validation or test set, you should perform the feature selection on the training data only to avoid over-estimating the performance of your model. There are other ways to model this data, but I think these are probably the simplest given what I think you're trying to do. EDIT : Another possible problem you may encounter involves highly correlated predictors. It is possible that some of the items you're tracking are highly correlated, in other words, people who buy tofu nearly always buy Impossible Burgers and almost never buy chicken, etc. There are a variety of ways you can deal with this. One approach is to do principal component analysis (PCA) if the data is number of items purchased (if it is instead one-hot encoded yes or no purchase, you can use MCA instead , although it sounds like this is number of items purchased); there are a lot of tutorials on PCA online, it's implemented in scikit-learn and any other common statistical package. In a nutshell, PCA uses the eigenvectors of the covariance matrix as a new basis set for the data. The share of the variance explained by a given principal component (eigenvector) is its associated eigenvalue divided by the sum of all the eigenvalues; so, the principal components can be sorted by eigenvalue and we can use the new features associated with the n largest eigenvalues as input to our model while discarding the rest. This will eliminate the multicollinearity problem (if present), but it's not ideal for your application, because now the odds ratios from logistic regression will be odds ratios for the principal components , each of which is a linear combination of the original items. This will somewhat complicate your analysis when you're trying to explain your insights to stakeholders. (Although maybe you can find a way to use this to give them an explanation that's sufficient for their needs). So, I think what I would suggest instead as a place to start is doing feature selection, e.g. using mutual information, which should give you a greatly reduced number of features. At that point, you can check for correlations among those features (e.g. using the Spearman's-r correlation coefficient if the data is the number of an item purchased by a customer). In any case where multiple items are very strongly correlated, you can keep one and eliminate the others as inputs to your logistic regression model. (This doesn't completely eliminate the possibility of multicollinearity but should significantly reduce the likelihood that it is a problem.) This way, when providing an interpretation to stakeholders, you can say "this is the odds ratio for tofu, we find that purchases of impossible meat are strongly correlated with tofu, i.e. customers who purchase the one nearly always purchase the other". Also, elastic net regularization (combined L1 / L2) is likely to be especially helpful if you have multiple correlated features. L1 regularization alone will help with this but it will tend to keep one of the correlated features and drop the others, whereas elastic net can avoid this problem. Again some experiments on a subset of your data might be helpful here.
