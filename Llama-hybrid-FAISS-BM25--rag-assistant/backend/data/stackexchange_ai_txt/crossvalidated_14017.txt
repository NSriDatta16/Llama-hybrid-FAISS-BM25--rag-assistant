[site]: crossvalidated
[post_id]: 14017
[parent_id]: 14002
[tags]: 
Classic Torgerson 's metric MDS is actually done by transforming distances into similarities and performing PCA (eigen-decomposition or singular-value-decomposition) on those. [The other name of this procedure ( distances between objects -> similarities between them -> PCA , whereby loadings are the sought-for coordinates) is Principal Coordinate Analysis or PCoA .] So, PCA might be called the algorithm of the simplest MDS. Non-metric MDS is based on iterative ALSCAL or PROXSCAL algorithm (or algorithm similar to them) which is a more versatile mapping technique than PCA and can be applied to metric MDS as well. While PCA retains m important dimensions for you, ALSCAL/PROXSCAL fits configuration to m dimensions (you pre-define m ) and it reproduces dissimilarities on the map more directly and accurately than PCA usually can (see Illustration section below). Thus, MDS and PCA are probably not at the same level to be in line or opposite to each other. PCA is just a method while MDS is a class of analysis. As mapping, PCA is a particular case of MDS. On the other hand, PCA is a particular case of Factor analysis which, being a data reduction, is more than only a mapping, while MDS is only a mapping. As for your question about metric MDS vs non-metric MDS there's little to comment because the answer is straightforward. If I believe my input dissimilarities are so close to be euclidean distances that a linear transform will suffice to map them in m-dimensional space, I will prefer metric MDS. If I don't believe, then monotonic transform is necessary, implying use of non-metric MDS. A note on terminology for a reader. Term Classic(al) MDS (CMDS) can have two different meanings in a vast literature on MDS, so it is ambiguous and should be avoided. One definition is that CMDS is a synonym of Torgerson's metric MDS. Another definition is that CMDS is any MDS (by any algorithm; metric or nonmetric analysis) with single matrix input (for there exist models analyzing many matrices at once - Individual "INDSCAL" model and Replicated model). Illustration to the answer . Some cloud of points (ellipse) is being mapped on a one-dimensional mds-map. A pair of points is shown in red dots. Iterative or "true" MDS aims straight to reconstruct pairwise distances between objects. For it is the task of any MDS . Various stress or misfit criteria could be minimized between o riginal distances and distances on the m ap: $\|D_o-D_m\|_2^2$ , $\|D_o^2-D_m^2\|_1$ , $\|D_o-D_m\|_1$ . An algorithm may (non-metric MDS) or may not (metric MDS) include monotonic transformation on this way. PCA-based MDS (Torgerson's, or PCoA) is not straight. It minimizes the squared distances between objects in the original space and their images on the map. This is not quite genuine MDS task; it is successful, as MDS, only to the extent to which the discarded junior principal axes are weak. If $P_1$ explains much more variance than $P_2$ the former can alone substantially reflect pairwise distances in the cloud, especially for points lying far apart along the ellipse. Iterative MDS will always win, and especially when the map is wanted very low-dimensional. Iterative MDS, too, will succeed more when a cloud ellipse is thin, but will fulfill the MDS-task better than PCoA. By the property of the double-centration matrix (described here ) it appears that PCoA minimizes $\|D_o\|_2^2-\|D_m\|_2^2$ , which is different from any of the above minimizations. Once again, PCA projects cloud's points on the most advantageous all-corporal saving subspace. It does not project pairwise distances , relative locations of points on a subspace most saving in that respect, as iterative MDS does it. Nevertheless, historically PCoA/PCA is considered among the methods of metric MDS.
