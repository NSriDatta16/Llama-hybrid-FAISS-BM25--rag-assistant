[site]: crossvalidated
[post_id]: 619372
[parent_id]: 619286
[tags]: 
There is no guarantee that that happens, but given sufficient training it will most likely happen. The weights of the embedding layers are updated as the network is trained (like any other wight containing neural network), and it is hoped that these updates will lead to words with similar meaning having similar embeddings. This should happen, as the the network benefits from "grouping" similar words close together, as it becomes easier to gather "guess" the correct context from them. For example if you would represent each word through a one-hot encoded vector. Each vector is orthogonal to each other, that means each word in the dataset is equally (dis)similar to each other. So queen is as similar to the word king as it is to the word rocket . However, in practise often the word king and queen have the (close to) identical meaning in sentences. So even if I would replace king with queen in a sentence it would still make sense, and it would often convey the same message. So if the representations/embeddings of king and queen are similar it makes it easier for the model for example to predict the next word (as an example, it depends on the precies training strategy of our word embeddings), as it does not need to learn that two complete two different vectors represent two very similar concepts.
