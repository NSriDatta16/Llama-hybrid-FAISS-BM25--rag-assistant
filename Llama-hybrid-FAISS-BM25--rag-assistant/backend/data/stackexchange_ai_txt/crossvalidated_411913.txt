[site]: crossvalidated
[post_id]: 411913
[parent_id]: 353116
[tags]: 
Precision is Pr = TP/(TP+FP) where is TP and FP are True positives and False positives. so, we use this metric to evaluate systems like classifiers to know how precisely we found positives. if your classifier marked an entry True even if it is False in real, it increases FP, which in turn decreases Pr. So your system is not precise. so, in case of classifiers we don't need to know which entry has the highest probability to belong to a class or things like that. where as let's say you built an app which searches for music videos. so, if a query is made about a song(lets say I want to break free), if the first 5 retrieved entries from query are not at all related to the song or the band 'Queen' and entries from 6 to 10 are related to them, then your app is utter waste. so, in these cases where the order matters, we calculate precision and recall(Re = TP/(TP+FN)) and the area under the curve is MAP (mean average precision) The intuition behind the idea is as follows, as the number of true entries in real are fixed, moving to a next entry either increases the recall(when you encounter true positive) or keeps it the same(when you encounter a false positive) where as precision decreases(if FP was encountered) and remains same or increases (if TP was encountered) so, if you get irrelevant results at the starting, the precision remains almost 0, which makes your MAP 0, where as if you find all the accurate results at the starting (which basically means zero FPs) so precision is close to 1, results in MAP close to 1. which certifies your system as the best one this article gives a detailed description with examples Breaking Down Mean Average Precision (mAP)
