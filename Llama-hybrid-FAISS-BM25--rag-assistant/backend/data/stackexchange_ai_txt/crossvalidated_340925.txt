[site]: crossvalidated
[post_id]: 340925
[parent_id]: 265982
[tags]: 
You could use embedding to transform your large number of categorical variables into a single vector. This compressed vector will be a distributed representation of the categorical features. The categorical inputs will be transformed into a relatively small vector of length N with N real-numbers that in some way represent N latent features that describe all the inputs. Consider the large number of words in the English dictionary. If this number is N, then we could represent each word as a one-hot-coded vector of length N. However, word-to-vec is able to capture virtually all this information in a vector of length between 200-300.
