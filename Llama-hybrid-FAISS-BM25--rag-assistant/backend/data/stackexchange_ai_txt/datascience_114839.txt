[site]: datascience
[post_id]: 114839
[parent_id]: 114833
[tags]: 
First, you can't use anything from the test set before training. This means that the scaling should be done using only the test set, otherwise there's a risk of data leakage. Then remember that scaling your features means that the model learns to predict with scaled features , therefore the test set should be passed after it has been scaled as well (using the same scaling as the training set, of course). Finally you could obtain the real price value by "unscaling" with inverse_transform . But instead I decided not to scale the target variable in the code below because it's not needed (except if you really want to obtain evaluation scores scaled). It's also simpler ;) full = pd.read_csv('train.csv') column = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt'] full = full[column] X = train.drop('SalePrice', axis=1) y = train['SalePrice'] # always split between training and test set first X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15) # Then fit the scaling on the training set # Convert Feature/Column with Scaler scaler = MinMaxScaler() # Note: the columns have already been selected X_train_scaled = scaler.fit_transform(X_train) # Calling LinearRegression model = LinearRegression() # Fit linearregression into training data model = model.fit(X_train_scaled, y_train) # Now we need to scale the test set features X_test_scaled = scaler.transform(X_test) y_pred = model.predict(X_test_scaled) # y has not been scaled so nothing else to do # Calculate MSE (Lower better) mse = mean_squared_error(y_test, y_pred) print("MSE of testing set:", mse) # Calculate MAE mae = mean_absolute_error(y_test, y_pred) print("MAE of testing set:", mae) # Calculate RMSE (Lower better) rmse = np.sqrt(mse) print("RMSE of testing set:", rmse) # ... evaluation etc. ```
