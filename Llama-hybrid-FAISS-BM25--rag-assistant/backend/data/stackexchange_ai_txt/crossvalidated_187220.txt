[site]: crossvalidated
[post_id]: 187220
[parent_id]: 187145
[tags]: 
Neither units do compare in absolute terms across models and data sets, so don't over interpret the absolute value too much. Use MeanDecreaseAccuracy (scaled/unscaled) to order your variables by expected usefulness. Highest number most important. If you like to drop some variables, it is likely best to start from the least important one(s). If your model will improve or not by dropping least useful variable(s), should be tested by checking if out-of-bag CV performance improves. If you perform multiple repeated variable selection by the OOB-CV performance, this measure becomes slightly over optimistic and you may want to embed the entire procedure in a outer 10-fold CV loop. MeanDecreaseGini is faster to compute, but unstable and quite biased, thus quite inferior. Just completely ignore MeanDecreaseGini. For a more in-depth answer read: Strobl et al , 'Bias in random forest variable importance measures: illustrations, sources and a solution' . My personal opinion (backed by some home-brewed simulations), is that the described biases of scaled permutation variable importance in the article are not an practical issue for data-sets of only 20 variables, but can be for (genetic) GWAS studies etc.
