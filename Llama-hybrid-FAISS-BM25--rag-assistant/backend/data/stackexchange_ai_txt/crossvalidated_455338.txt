[site]: crossvalidated
[post_id]: 455338
[parent_id]: 
[tags]: 
How do you get $\rm{var}(\Theta -\hat\theta) = \rm{var}(\Theta)$?

From this video on Bayesian Least Mean Square estimation: $$\mathbf E\left[(\Theta -\hat\theta)^2\right] = \rm{var}(\Theta -\hat\theta) + \left(\mathbf E[\Theta -\hat\theta]\right)^2 = \rm{var}(\Theta) + \left(\mathbf E[\Theta -\hat\theta]\right)^2$$ which is to say that $\rm{var}(\Theta -\hat\theta) = \rm{var}(\Theta)$ . I would like to ask how that comes about? Thanks. $\Theta$ is the random variable being estimated, and $\hat\theta$ is a constant estimate.
