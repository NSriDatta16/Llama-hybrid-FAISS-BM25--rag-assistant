[site]: crossvalidated
[post_id]: 34183
[parent_id]: 34174
[tags]: 
Both questions are hard, I'll give a shot at the first one. A straightforward approach to classify documents is to compute their tf-idf . In short, you consider the text is a bag of words, i.e. that it has no linear structure, and you compute a score that says how much the word is specific of a document. I explain a little bit about how to do this here . Once this is done, texts are often compared with the cosine similarity measure , which is the cosine of their tf-idf vectors. If they have a high similarity, they have similar specific words and you can guess they are about the same topic. You can compute cosines, but you can do all sorts of geometric operations. In particular you can fit Support Vector Machines which give good results in text classifications. Finally, a last idea would be to use keyword extraction tools, such as the Alchemy API to summarize your documents to 10-20 relevant keywords. You can then use standard classification techniques on this dataset of reduced dimension. As a good primer on text classification, I suggest Introduction to Information Retrieval (free), and Mining the Social Web ... not free but probably available from the best pirate sites ;-)
