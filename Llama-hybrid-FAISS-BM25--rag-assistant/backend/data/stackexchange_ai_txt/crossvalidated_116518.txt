[site]: crossvalidated
[post_id]: 116518
[parent_id]: 116294
[tags]: 
No! You must not use the same data to 1) perform clustering and 2) hunt for significant differences between the points in the clusters. Even if there's no actual structure in the data, the clustering will impose one by grouping together points which are nearby. This shrinks the within-group variance and grows the across-group variance, which biases you towards false positives. This effect is surprisingly strong. Here are the results of a simulation that draws a 1000 data points from a standard normal distribution. If we assign the points to one of five groups at random before running the ANOVA, we find that the p-values are uniformly distributed: 5% of the runs are significant at the (uncorrected) 0.05 level, 1% at the 0.01 level, etc. In other words, there is no effect. However, if $k$ -means is used to cluster the data into 5 groups, we find a significant effect virtually every time, even though the data has no actual structure . There is nothing special about a k-means or an ANOVA here--you would see similar effects using non-parametric tests or logistic regression and a decision tree, even just taking the min/max. After you impose some kind of structure on the data, you cannot to test whether some structure exists, since it obvious does!. As a result, validating clustering algorithms' performance is tricky, particularly if the data are not labelled. However, there are a few approaches to "internal validation", or measuring the clusters' quality without using external data sources. They generally focus on the compactness and separability of the clusters. This review by Lui et al. (2010) might be a good place to start.
