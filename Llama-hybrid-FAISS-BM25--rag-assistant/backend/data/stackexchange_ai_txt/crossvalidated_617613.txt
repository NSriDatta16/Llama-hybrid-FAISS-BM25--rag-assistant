[site]: crossvalidated
[post_id]: 617613
[parent_id]: 559814
[tags]: 
I would suggest considering a Gaussian Process regression (GPR). GPR has all the properties asked for namely non-linear, good differentiability and working well with relatively small samples. In that sense, if we are really into it, we can affect the differentiability of the resulting GP too via the hyperparameters of its kernels (e.g. via controlling the $\nu$ degrees of a Matern kernel). There are quite a few implementations of GPs in Python; GPyTorch seems the obvious one to try first if looking for something PyTorch based. Finally, it is worth mentioning there is a general view of " Deep Neural Networks as Gaussian Processes " by Li et al. (2018) in the work with that same name that provides a good theoretical background too; this work further generalised/extended in Neural Tangents: Fast and Easy Infinite Neural Networks in Python by Novak et al. (2021).
