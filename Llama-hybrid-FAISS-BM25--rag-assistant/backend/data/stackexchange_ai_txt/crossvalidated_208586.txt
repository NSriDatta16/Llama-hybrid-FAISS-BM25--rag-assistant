[site]: crossvalidated
[post_id]: 208586
[parent_id]: 
[tags]: 
What can I infer about my problem domain/input data from the hyperparameters producing the optimum network configuration?

I am new to neural networks and am trying to solve a binary classification problem with a neural network. I tried network configurations with 1 to 6 hidden layers, and 1-50 neurons per layer. The best results (ROC AUC) obtained corresponded to network configurations with 1-2 hidden layers and a low number of neurons per layer (2-5), but the best ROC AUC value was around 0.71. What does this say about my data? To me, a low number of neurons and hidden layers means that of the data that is separable, not a very complex function is needed to separate it. But this is strange because an AUC value around 0.71 means only some of the data is actually separable. But surely that means that a more complex function would be needed to separate more of the data? What could you say about the data if, say, 1 hidden layer with 20 neurons worked better than 2 hidden layers with 10 neurons in each? Thanks.
