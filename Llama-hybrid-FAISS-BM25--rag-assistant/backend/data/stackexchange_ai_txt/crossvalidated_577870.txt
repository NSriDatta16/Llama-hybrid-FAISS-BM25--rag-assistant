[site]: crossvalidated
[post_id]: 577870
[parent_id]: 
[tags]: 
Interpreting decision result for machine learning

My goal is to use ML-Agents (Unity's implementation of PyTorch) for the turnbased game of Splendor. While I have a found a few tutorials on how to use it for physical observations and interactions, none are really talking about it how to use them as roundbased AI and thus input/ output. I'm really new to the machine learning part and some of this might be like a total beginner question. Splendor can be broken down into two different actions (simplified): Picking some tokens/currencies from multiple stacks with certain rules Buying cards with those tokens returns some tokens back to the stack. Each bought card will reduce the future cost for other cards for one currency by one and award as well a certain amount of victory points. All information is visible to all players, there are 5 stacks of tokens with a limited amount and cards have a range cost/ victory points. Cheap cards might cost 3 tokens, expensive ones up to 15. The strategy is usually buying the cheap ones to easier afford the more expensive ones. The first part I'm trying to implement is that the agent is picking a valid combination of tokens. Per the rules you can get up to 3 each turn if they are of different color OR two of the same if the stack has 4 or more. Picking just one or two different ones is a valid move as well but not optimal. I think I understood how to get the observations right. According to the documentation, the observations are done by one-hot style observations for the enums and normalized for the amount, 8 being the maximum per stack, which would bring the input space size to 30. The currency stacks are having a random amount at the start of ach trainings episode and one episode lasts exactly one draw for now. //Located on the board public enum Currency{ Black=0, Red=1, Blue=2, Green=3, White=4 } public int[] boardCurrency = new int[Enum.GetValues(typeof(Currency)).Length]; //part of the agent private float NormalizeValue(float currentValue, float minValue, float maxValue) { return (currentValue - minValue) / (maxValue - minValue); } public override void CollectObservations(VectorSensor sensor) { var amount = Enum.GetValues(typeof(Currency)).Length; for (int index = 0; index Assuming I made no error for the reward function, I have something like this that for the actual decision public override void OnActionReceived(ActionBuffers actions) { List pickedUpCurrency = new List (); var amountOfDifferentCurrency = Enum.GetValues(typeof(Currency)).Length; for (int actionIndex = 0; actionIndex pickedCurrencies) { if (pickedCurrencies.Count == 0) return -1; int[] amount = new int[Enum.GetValues(typeof(Currency)).Length]; foreach (var currency in pickedCurrencies) { amount[(int) currency]++; } for (int index = 0; index = 4) return 1; return -1; } if (pickedCurrencies.Count == 3) { if (pickedCurrencies[0] != pickedCurrencies[1] && pickedCurrencies[0] != pickedCurrencies[2] && pickedCurrencies[1] != pickedCurrencies[2]) return 1; } return -1; } And here are my actual questions, mainly about the action part. Currently I'm using 3 discrete branches with a size of 5, 5 and 6. I'm mapping 0-5 for the token that should get picked and the 6 is if it should pick the third token at all. (That is excluding the option for now to only pick a single token). Is there a better way how I can get a list of currencies as decision result? My understanding of the discrete branch is that it would more correspond to a unique action and the size of the branch to the actual option. That would make the size something around 125 but it would grow fast if we would be allowed to draw one or two more per turn. The second question is really similar, how does the result of the decision should tell me the card to buy? The agent knows the card id as part of the observation, if it would be again it is own discrete branch, the size of it should match the amount of card id's. But would that not mean that I can't add more cards later since the branch size would not match the trainings size? The card data is always in the same format, a list of currency it costs, victory points, the currency it sponsors and the id. I hope I provided not too much information for two simple questions.
