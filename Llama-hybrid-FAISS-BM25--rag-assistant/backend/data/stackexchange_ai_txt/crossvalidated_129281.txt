[site]: crossvalidated
[post_id]: 129281
[parent_id]: 
[tags]: 
Confidence Interval of Calculating Precision

The problem I'm trying to solve has the following setting: Let $X_1, \dots, X_N$ be a data set where each $X_i \sim Categorical(p_{TP}, p_{FP}, p_{TN}, p_{FN})$ s.t. $\sum\limits_{k \in \{TP,FP,TN,FN\}} p_k = 1$. Essentially, these are a set of judgements about the decisions an agent have made on an arbitrary input set. Let $R_n(X_1, \dots, X_N) = \frac{\sum\limits_{i=1}^{N} \mathbb{1}(X_i=TP)}{\sum\limits_{i=1}^{N} \mathbb{1}(X_i \in \{TP,FP\})}$, the precision, be the statistic I'm interested in estimating. I'm interested in estimating $R_n$ by calculating it on a smaller sample of size $n \ll N$. Call this estimated statistic $\hat{R}_n$ My question is: how large should $n$ be so that the true precision $R_n$ falls inside an $\alpha$-confidence interval of $\hat{R}_n$ which is of width $\beta$? For example, how large should $n$ be for $R_n$ to fall in the interval $(\hat{R}_n - 0.01, \hat{R}_n + 0.01)$ with probability of 0.95? Here, $\alpha=0.05$ and $\beta=0.01$. Any ideas are very much appreciated.
