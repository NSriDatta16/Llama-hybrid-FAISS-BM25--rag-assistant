[site]: crossvalidated
[post_id]: 115009
[parent_id]: 
[tags]: 
How does one interpret the distribution over parameters in bayesian estimation?

I am new to Bayesian estimation. The assumption that the parameters are random variables seems a little unsettling to me. For example when considering a model for data, what physical interpretation can I provide to the equation $$ \begin{eqnarray*} P(Data) & = & \sum_{\theta} {P(Data,\theta)} \\ & = & \sum_{\theta} {P(Data|\theta)*P(\theta)} \end{eqnarray*} $$ This $P(\theta)$ i.e. probability over parameters, seems to be a bit awkward, after all how do I know what is the relative probability of the process of generation being a gaussian MM with this particular parameter combination instead of say a neural network with that parameter configuration. And further it is intuitive to think of one process generating the data, whose parameters we are guessing. But instead here we have multiple processes generating the data in tandem, i.e. a sense of a true model is lost.
