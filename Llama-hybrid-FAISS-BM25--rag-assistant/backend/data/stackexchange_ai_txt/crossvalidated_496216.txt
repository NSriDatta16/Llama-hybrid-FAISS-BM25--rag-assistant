[site]: crossvalidated
[post_id]: 496216
[parent_id]: 
[tags]: 
Can softmax probabilities be used for mixture classification?

I am trying to convince my peer about this model training and testing paradigm since it does not make sense. Let's say that you have two classes of signals in your training set, Class A and B. You can imagine them as intensity values over some features, e.g. frequency. You train a deep learning model that gives softmax outputs as classification predictions. Let's assume that the model learns this task and it generalizes over the test set that consists of samples from classes A and B. Here is the question, assume that I got a new class of these signals 0.6A + 0.4B which has mixtures with very small noise. If I have plenty of mixture signals (e.g. 10K), can I use my trained model to classify them from the probabilities that the network outputs? For instance, when I give the mixture samples as a test set, the mean of the 10K output probabilities will converge towards 0.6 and 0.4 for A and B. I do not think this is a valid approach since we do not optimize our decision boundary for this, but I could not convince him. Any advice?
