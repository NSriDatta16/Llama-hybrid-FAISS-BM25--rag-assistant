[site]: crossvalidated
[post_id]: 515824
[parent_id]: 
[tags]: 
Preferred way to sum different time series together (in software)

Is there a canonical/best approach to computationally summing different time series together? What I mean by that is the operation $$ \sum_i{s_i(t)} = S(t) $$ where $s_i(t)$ is the $i$ -th time series, and $S(t)$ is a resulting time series. In practice, a time series will be represented in software as something like an array of tuples [(t1,v1), ..., (tn,vn)] where the t 's are some kind of (date)timestamps and the v 's are the values that the series happens to have at the particular times t 's. The practical problem comes from the fact that usually we will have real time series which do not have exactly matching timestamps (especially if the timestamps are high-precision and contain time and not just dates), or some series may be missing some values at some timestamps that the others instead have. For example, I might have $n$ streams of data that contain the count of some HTTP requests of different instances of my application. I would like to have the "sum time series" out of all of them, i.e. a time series that shows the total amount of HTTP requests across all instances, over time. Or I might have a continuous metric instead of a discrete one, like prices, or memory usage, or any other thing that might make sense to sum across different similar series. What could be the best approach (soundest, from a mathematical point of view, and most efficient, from an algorithmic point of view) to achieve this? Are there renowned scientific libraries or pieces of data-manipulation software that implement operations like this one, and if so, what do they do? To give an example of something that one might try and of its shortcomings: A simple approach might be to round all timestamps to a high enough granularity so to have some big overlap among the series (for example, I round timestamps to the second, and I consider something like a data point that happened at 00:00:01.23456 to have happened at 00:00:01). This effectively is equivalent to perform binning with a small bin's width (1 second, in my example). There remain a couple of big "degrees of freedom" to lock before being able to actually sum the series now: 1) what do we do if multiple data points fall into the same bin? We need to aggregate their values into one somehow, and which aggregation to use might depend on our use case. It might be correct to sum their values, or it might be correct to take their average, etc. 2) how do we handle missing data? It might still be that, after binning, we got bins (timestamps) with no data (no value) inside, for some of the series. What should the resulting series have at that timestamp? No value? Or do we assign some default value to the series which have missing points? Also here, it seems that it might depend on the specific use case.
