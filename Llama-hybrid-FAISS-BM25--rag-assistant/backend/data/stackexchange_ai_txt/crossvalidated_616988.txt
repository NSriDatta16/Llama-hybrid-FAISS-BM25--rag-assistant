[site]: crossvalidated
[post_id]: 616988
[parent_id]: 616726
[tags]: 
If you have a model with behavior like an increasing function then often you do not get random behavior in the form of some additive noise term $\epsilon_i(t)$ , and instead it is more like the errors are correlated and with different type of functions. There are several different ways to perform a statistical analysis. For example Logistic regression and probit regression: Here the increasing curve can be a probability for some Bernoulli distributed variable. Here the error is incorporated by using binomial regression . Survival curves: Here the curve is the effect of an accumulation of risk which is necessarily an increasing function. The curve can be fitted by maximizing the likelihood function. When comparing multiple groups and assuming a constant relative risk ratio, then one can use Cox regression (the survival curve, a distribution for waiting time, is turned into a Bernoulli distribution, by comparing groups) Lorenz Curves : These curves plot a cumulative distribution. They can be distribution of wealth, and the related gini index, but also ROC curves . Often these are analysed with simplistic measures, like the area under the curve, but you can also analyse them if you have some mechanistic model underlying the curves. Frequency analysis of extreme events: Here one often plots the cumulative distribution function for events and the curve is expected to be some extreme value distribution . But you are not fitting the CDF as if you are doing least squares regression. Ideally you will be fitting the observed events with the PDF. (Although there might be considerations like the tails being difficult to predict, etc. and there all kind of ways to fit these distributions. Before there where fast and cheap computers, people used to plot the double logarithm to fit a Gumbel distribution, which becomes a straight line in such a plot.) Empirical distribution function : these are sometimes fitted by minimizing the Kolmogorov-Smirnov statistic or some other metric that describes the distance between the fitted distribution and the empirical distribution (I have no source here, but I believe that I have seen this done in some places). etcetera So it is possibly better to start analyzing your curve based on some underlying principle. What sort of process are you looking at and can you reason why you get an increasing curve? What sort of statistical variations may occur in the sampling/experiment and how dooes this influence the observed curve? With such questions you can figure out what sort of regression/fitting to use.
