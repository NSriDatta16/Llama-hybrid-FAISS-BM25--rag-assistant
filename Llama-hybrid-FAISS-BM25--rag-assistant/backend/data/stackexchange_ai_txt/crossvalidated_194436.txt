[site]: crossvalidated
[post_id]: 194436
[parent_id]: 194412
[tags]: 
SVM does not work on any image format directly. It just wants a set of variables, where each example has the same number of variables. So you will transform your inputs into equal size arrays. So, for example, a 3x3 greyscale image turns into $$X_1,X_2 ... X_9$$. Since this is an applied ML task, you should thing about preprocessing and feature engineering . For example, adjusting for various lighting conditions by centering and centering luminance. If color is important, maybe moving from RGB to HSV color space allows the SVN to consider color and luminance separately. Also keep in mind that more pixels may not always equal better performance. If the most important pixels for distinguishing are in a certain area, a scaled down, smaller image may capture the essence of the differences better because it smooths out misalignments. Keep in mind that once you convert the image to an input array, SVN loses any notion of adjacent pixels. Every pixel is a different dimension. You may want to do some feature extraction, such as a number for the overall contrast of the image. See Wikipedia's section on image feature extraction The idea is that you can summarize the important aspects of the image in some overall variables and if they are important, SVM will discover that.
