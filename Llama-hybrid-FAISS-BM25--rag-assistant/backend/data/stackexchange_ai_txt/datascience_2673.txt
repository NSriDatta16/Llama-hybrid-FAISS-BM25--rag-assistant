[site]: datascience
[post_id]: 2673
[parent_id]: 
[tags]: 
Training Neural Networks with unknown length of input

I'm currently going into the world of machine learning and Neural Networks, thanks to synaptic (js) that interests me a lot. So I read a lot, wikipedia links and synaptic's NN 101 , but there's a lot of basics questions that I don't understand (but I'd like to) in the use of machine learning (NN) and the point of these technologies. Let's say, I wan't my network to (kind of) learn (something like) gravity, so to train it I set in input 10 objects with a mass, and a position x, y (and z) and I set output the new x, y (and z) of each objects. I guess I should give it several configurations and everything but here is the question; can it, then, be able to compute the interactions between 10000, 100000 objects? At this stage in my learning, what I don't clearly get is what is the point of teaching/training neurons to compute XOR like it's shown in synaptic's documentation : var trainingSet = [ { input: [0,0], output: [0] }, { input: [0,1], output: [1] }, { input: [1,0], output: [1] }, { input: [1,1], output: [0] }, ]; var trainer = new Trainer(myNetwork); trainer.train(trainingSet); Were we just give it all the possible inputs and outputs to a XOR. Well, as I'm all new to the technologies I think my questions are full of non-sense and everything but thanks for reading and help you might bring :)
