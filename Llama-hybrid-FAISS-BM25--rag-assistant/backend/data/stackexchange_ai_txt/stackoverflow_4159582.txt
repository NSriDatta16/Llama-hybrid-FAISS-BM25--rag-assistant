[site]: stackoverflow
[post_id]: 4159582
[parent_id]: 
[tags]: 
Computing averages of records from multiple files with python

Dear all, I am beginner in Python. I am looking for the best way to do the following in Python: let's assume I have three text files, each one with m rows and n columns of numbers, name file A, B, and C. For the following, the contents can be indexed as A[i][j] , or B[k][l] and so on. I need to compute the average of A[0][0] , B[0][0] , C[0][0] , and writes it to file D at D[0][0] . And the same for the remaining records. For instance, let's assume that : A: 1 2 3 4 5 6 B: 0 1 3 2 4 5 C: 2 5 6 1 1 1 Therefore, file D should be D: 1 2.67 4 2.33 3.33 4 My actual files are of course larger than the present ones, of the order of some Mb. I am unsure about the best solution, if reading all the file contents in a nested structure indexed by filename, or trying to read, for each file, each line and computing the mean. After reading the manual, the fileinput module is not useful in this case because it does not read the lines "in parallel", as I need here, but it reads the lines "serially". Any guidance or advice is highly appreciated.
