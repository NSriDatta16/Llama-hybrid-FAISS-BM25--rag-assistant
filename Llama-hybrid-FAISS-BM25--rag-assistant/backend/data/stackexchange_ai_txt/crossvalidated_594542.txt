[site]: crossvalidated
[post_id]: 594542
[parent_id]: 594539
[tags]: 
The two arguments have competing definitions of "learn." A random forest can approximate a functional form with additive and multiplicative interaction terms, but it cannot reproduce either exactly, and will have a particularly hard time approximating the function outside the range of inputs provided during training. As a comment to the accepted answer in the linked question alludes ( reference link ), even the approximation on the training range is subject to caveats. Here I play around with XOR style interactions, and among other things show that when other effects are being modeled, the trees may get distracted from faithfully representing the interaction.
