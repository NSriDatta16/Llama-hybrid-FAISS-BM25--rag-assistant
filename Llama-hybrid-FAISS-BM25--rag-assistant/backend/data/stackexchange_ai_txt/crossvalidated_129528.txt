[site]: crossvalidated
[post_id]: 129528
[parent_id]: 129525
[tags]: 
A lot of economists use linear probability models, arguing that LPM provides the linear approximation of the conditional expectation function, which is often considered "good enough." Consistent (in large samples) standard errors can be gotten by using ``robust'' variance-covariance matrix estimators. This is an OK argument if you really just want $\beta$, and want it to be interpretable as a conditional expectation in the larger group. You don't want to do this if you have any interest in prediction. In reality though, arguing that $\beta$ increases a probability by a certain amount can only make sense on average (hence conditional expectation in the sample, which you generalize to the population). It can't be a description of what you would expect to happen to unit $i$ if you treat them. Because if $i$ has covariates that push them up or down, then adding $\beta$ to the effect of those covariates could lead to probabilities outside of 0/1, which wouldn't make any sense. That said, logit models involve assuming that the link between the predictors and the outcome is a logit. This can be restrictive. But you can interpret a simple logit coefficient as an odds ratio by exponentiating it. For example, if $\hat\beta=1$, then you're estimating that the treatment leads to a $e^1=2.7$-times more likely odds of $y$ equaling 1.
