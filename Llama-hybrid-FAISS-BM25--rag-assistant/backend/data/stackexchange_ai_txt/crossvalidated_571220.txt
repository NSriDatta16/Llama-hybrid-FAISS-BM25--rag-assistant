[site]: crossvalidated
[post_id]: 571220
[parent_id]: 
[tags]: 
What is the right approach to explain different usages rates of e-grocery when analysing survey using R?

I have collected data about users and non-user of e-grocery in two countries (amount of groceries bought online during 12 twelve months, household characteristics, sociodemographics, questions about what situations did or could lead to the use of e-grocery, personal preferences when shopping online regarding payment, device used etc. A whole bunch of variables (around 100 per person), whereof I deleted 9 due to correlation. A lot of the variables are binary, some categorical and some few are continuous. I've collected about 300 responses per country. What I would like to find out is what drives people in country A to use e-grocery, and what drives people in country B to use such. And then compare and explaing the different usage rates (3% vs. 20% total sales volumne) in these countries. In order to reduce variables, I first checked the p-values of each individual variable, when doing logistic regression with one variable at the time. I did this to delete the variables with p>10% (usually 5%, but here, it is just for a first selection of variables). Here is an example: glm(survey$egs_12months_used_regurarly ~ reason_egs_use_working_late_Q28, data = survey, family = binomial()) After that, I went for binomial logistic regression ( glm() ) using the same binary response variable as above (which distuinghises 0-to-low-users from low-to-heavy users of e-grocery) and built a model with all remaining variables (58) using the data of both countries (well, glm() makes more than 58 variables out of it because it does dummy variables ... I might end up having way to may variables in relation to cases, which is 300 per country). About 12 variables turned ou to be significant. Using rsq() , I get an adjusted R.square value of 41%. Of course, I would like to achieve a higher value (how?), but I am not sure how to proceed and whether the approach is correct or not. Deleting the non-significant variables from the model won't improve it. I thought about using decision trees, lasso or ridge regression, doing LOOCV or k-fold CV. I actually did all these in the past (exercises), but I lack the knowledge about what approach is the most suitable for my situation.
