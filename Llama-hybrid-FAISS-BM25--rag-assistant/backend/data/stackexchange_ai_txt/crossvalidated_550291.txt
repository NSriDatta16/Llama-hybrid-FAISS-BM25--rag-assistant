[site]: crossvalidated
[post_id]: 550291
[parent_id]: 505251
[tags]: 
I am quite sure you use the dataset in the related post here . So you are dealing with time series data. Therefore some of the suggestions made in the previous post can't be used, as regional variation was assumed. Nevertheless, your concrete questions were correctly answered. That's why I want to give you a more general suggestion, how you can analyse the dataset with regard to your research question - the relationship between Unemployment and Crime. First, when you have time series data, you should not treat it as cross-sectional data. Instead, time series data is more prone to draw false conclusions about the relationships between variables. At the beginning, you should always have a look at the development of your data over time: dat %>% pivot_wider(names_from = 2, values_from = 3) %>% mutate(Unemployment_rate_rescaled = Unemployment_rate * 10000) %>% select(-Unemployment_rate) %>% pivot_longer(cols = -1, names_to = "variable") %>% ggplot(aes(x = Date, y = value, col = variable)) + geom_line() As we can see, the unemployment rate is more or less stable until July 2020 and steadily increasing afterwards. The crime rates do not show any noticeable development after July 2020. So at least visually there is no clear relationship. However, visual analysis is subjective and only a starting point. So we need statistics to go further. As you are interested in the bivariate relationships between unemployment rate and occurrences per crime type, looking at the correlations is a good first step: dat %>% pivot_wider(names_from = 2, values_from = 3) %>% select_if(is.numeric) %>% cor %>% .[1,-1] # Anti-social behaviour Theft Violence and sexual offences # -0.1198733 -0.1421524 0.1414995 The correlation coefficients are obviously quite low. Nevertheless you might want to test for statistical significance. However, this requires some assumptions about the data to be fulfilled. The most important one is stationarity, see here . Thinking about it in a less technical way: You don't want to know if the time series follow a similar 'meta-pattern', e.g. sharing a similar long-term trend. A fast way to get rid of those effects and ensure you stationarize the time series is to estimate stationary ARIMA-models for each variable and then analyse the relationships between the residuals. By that you isolate the 'unexpected' changes in the time series and test for significant correlations between your variables of interest: library(forecast) get_arima_residuals % as.numeric() return(arima_res) } dat_res % pivot_wider(names_from = 2, values_from = 3) %>% mutate_if(is.numeric, get_arima_residuals) x_vars $Unemployment_rate, dat_wide_res[[.x]]) data.frame(variable = .x, estimate = cor_test$ estimate, p_value = cor_test$p.value) }) # variable estimate p_value # cor...1 Anti-social behaviour -0.15468638 0.4918640 # cor...2 Theft 0.16526242 0.4623521 # cor...3 Violence and sexual offences -0.04819431 0.8313429 So, to summarise, there is no statistically significant relationship between crime-occurrences and unemployment-rate.
