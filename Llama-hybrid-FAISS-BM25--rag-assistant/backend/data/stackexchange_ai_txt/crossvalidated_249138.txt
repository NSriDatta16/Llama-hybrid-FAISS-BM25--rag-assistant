[site]: crossvalidated
[post_id]: 249138
[parent_id]: 249121
[tags]: 
I think that shrinkage would not help in interpreting the data with PCA or reducing dimensionality of a given data set. The shrinkage will help to make your analysis robust, i.e. if you have to use the outcome of PCA on other data sets. When you estimate the covariance matrix of a small but high dimensional data set, the estimate becomes unstable, the estimation error is very high. So, if you apply what you have learned from this data set on other data sets, you may be up to an unpleasant surprise. Due to a sampling error you may see that your estimated covariance matrix doesn't match the new observations at all. So, shrinkage may help when there's some kind of a default or prior knowledge of the covariances, maybe theoretical asymptotthical limit etc. On the other hand if this sample is all that you have to use the PCA analysis for then you're dealing essentially with the population. Hence, the sample estimate becomes the population parameter, and you're fine. The example when a shrinkage works is in portfolio theory in finance. There are many strains of this beast, and some of them posit that the variables are highly correlated with common factors, while the residual correlatiuns between variables is small. This leads to a nice shrinkage target: a diagonal residual covariance matrix. It's not always that you have this kind of a case when you know to what to shrink your estimate though
