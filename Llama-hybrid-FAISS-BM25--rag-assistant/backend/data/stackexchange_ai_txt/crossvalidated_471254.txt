[site]: crossvalidated
[post_id]: 471254
[parent_id]: 471247
[tags]: 
Yes, repeated measurements do "affect prediction (even) if that is a singular goal of the modeling" . Repeated measurement matter because they reflect a structure in the underlying data. They effectively impose a clustering/nesting that we need to account for. If we do not account for this clustering we will have a two-fold issue: Our estimates about performance will be optimistically biased. We will unintentionally leak information about the within-cluster structure. Especially if we have longitudinal data this might be outright wrong as our training data might incorporate information for future values of our test data. Our predictions of unseen data will be suboptimal in terms of generalisability. We will use our model in a setting other than the one it has trained upon. Deploying the model will be problematic. New "clusters" will appear but our model was always taught to rely on some "cluster-specific" information (instead of learning how to generalise the known "cluster-specific" patterns to new unseen clusters), and in absence of this information it will not do a good job. Please note that the fix of this situation, in most cases, is relatively easy. We will treat as a unit of analysis, not an individual measurement, but rather the cluster of repeated measurements. If you have repeated measurements that are longitudinal, there are some more specific algorithms that might want to explore (I give more information about them in the thread: Xgboost and repeated measures ) but at first instance, sampling at "cluster"-level should be adequate to get a more realistic AUC-ROC value. Finally, it goes without saying that standard approaches for clustered data like GLMM s should always be considered too.
