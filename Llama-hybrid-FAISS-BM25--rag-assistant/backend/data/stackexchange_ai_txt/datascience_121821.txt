[site]: datascience
[post_id]: 121821
[parent_id]: 
[tags]: 
Extremely silly transformers fine-tuning doubt

Suppose say I have a TFT5ConditionalGenration model instantiated with tensor flow. When you do model.fit, the model will pass the inputs in a feed-forward way similar to a call method. The model will then generate the outputs, which include the logits, past key values, and all. The model will then compare the logits to the labels. My doubt is how does the model know to compare the logits against the labels ? Because when I normally create a model with functional API, The last layer will be a softmax or its equivalent of what I am going to compare my labels against. But here when I pass the inputs, I am getting multiple things as outputs like logits, past key values, How does the model correctly understand that my labels are to be matched against the logits ? I thought I needed to extend the model using functional API and make the final layers as model.logits How does model.fit work without doing any of this ? Kindly clarify this stupid question!
