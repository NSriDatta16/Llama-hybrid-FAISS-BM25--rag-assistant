[site]: crossvalidated
[post_id]: 580322
[parent_id]: 580314
[tags]: 
In comments, OP writes that the network uses batch-normalization . This explains the observed behavior, because neural networks with batch norm change how statistics are computed, depending on whether the network is in training mode or evaluation mode. During training, batch norm updates a running estimate of the mean and standard deviation of the inputs. When computing results outside of training (e.g. when applied validation or production data), these values are not changed by the input, so there will be a different result. In Keras, this behavior is exposed as the difference between model.fit() , model.evaluate() and model.predict() . See: https://stackoverflow.com/questions/44843581/what-is-the-difference-between-model-fit-an-model-evaluate-in-keras In pytorch, you can set this behavior using model.train() to set train mode, or model.eval() to set evaluation mode (colloquially "eval mode"). See: https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch More information can be found in Ioffe, Sergey, and Christian Szegedy. " Batch normalization: Accelerating deep network training by reducing internal covariate shift ." International conference on machine learning. PMLR, 2015.
