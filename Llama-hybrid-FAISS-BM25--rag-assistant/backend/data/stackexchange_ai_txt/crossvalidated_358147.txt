[site]: crossvalidated
[post_id]: 358147
[parent_id]: 355781
[tags]: 
Some comments on different terminology between MIT / Rice and Efron's book I think that EdM's answer does a fantastic job in answering the OPs original question, in relation to the MIT lecture notes. However, the OP also quotes the book from Efrom (2016) Computer Age Statistical Inference which uses slightly different definitions which may lead to confusion. Chapter 11 - Student score sample correlation example This example uses a sample for which the parameter of interest is the correlation. In the sample it is observed as $\hat \theta = 0.498$. Efron then performs $B = 2000$ non parametric bootstrap replications $\hat \theta^*$ for the student score sample correlation and plots the histogram of the results (page 186) Standard interval bootstrap He then defines the following Standard interval bootstrap : $$ \hat \theta \pm 1.96 \hat{se}$$ For 95% coverage where $\hat{se}$ is taken to be the bootstrap standard error: $se_{boot}$, also called the empirical standard deviation of the bootstrap values. Empirical standard deviation of the bootstrap values: Let the original sample be $\mathbf{x} = (x_1,x_2,...,x_n)$ and the bootstrap sample be $\mathbf{x^*} = (x_1^*,x_2^*,...,x_n^*)$. Each bootstrap sample $b$ provides a bootstrap replication of the statistic of interest: $$ \hat \theta^{*b} = s(\mathbf{x}^{*b}) \ \text{ for } b = 1,2,...,B $$ The resulting bootstrap estimate of standard error for $\hat \theta$ is $$\hat{se}_{boot} = \left[ \sum_{b=1}^B (\hat \theta^{*b} - \hat \theta^{*})^2 / (B-1)\right]^{1/2} $$ $$ \hat \theta^{*} = \frac{\sum_{b=1}^B \hat \theta^{*b}}{B}$$ This definition seems different to the one used in EdM' answer: The empirical/basic bootstrap uses the distribution of $(T^∗−t)$ among the $R$ bootstrap samples from $\hat F$ to estimate the distribution of $(T−\theta)$ within the population described by $F$ itself. Percentile bootstrap Here, both definitions seem aligned. From Efron page 186: The percentile method uses the shape of the bootstrap distribution to improve upon the standard intervals. Having generated $B$ replications $\hat \theta^{*1}, \hat \theta^{*2},...,\hat \theta^{*B}$ we then use the percentiles of their distribution to define percentile confidence limits. In this example, these are 0.118 and 0.758 respectively. Quoting EdM: The percentile bootstrap instead uses quantiles of the $T^∗_j$ values themselves to determine the CI. Comparing the standard and percentile method as defined by Efron Based on his own definitions, Efron goes to considerable length to argue that the percentile method is an improvement. For this example the resulting CI are: Conclusion I would argue that the OP's original question is aligned to the definitions provided by EdM. The edits made by the OP to clarify the definitions are aligned to Efron's book and are not exactly the same for Empirical vs Standard bootstrap CI. Comments are welcome
