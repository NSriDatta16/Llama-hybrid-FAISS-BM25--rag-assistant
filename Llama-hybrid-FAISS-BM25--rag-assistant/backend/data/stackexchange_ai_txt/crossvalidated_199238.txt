[site]: crossvalidated
[post_id]: 199238
[parent_id]: 
[tags]: 
Information entropy in a direct graph?

I have a directed graph, and each edge in the graph has a probability, representing certainty in the edge. How can I represent overall uncertainty in the network. I was thinking of using an information entropy-based approach. I thought of calculating entropy across all edge probabilities, but this would require enumerating all possible states of the graphs and calculating joint probabilities from all the edge-wise probabilities, which would get computationally infeasible really quickly. So instead I am calculating the marginal entropy for each edge and taking their average. But is there an computationally tractable approximation of the overall entropy? TLDR: Is their a computationally feasibly approximation of multivariate multinomial distribution? Edit: I should mention that the edges are not independent, but I am going to go ahead and assume for large networks that they practically are. In the independence case the individual entropies of the edges should add up to the overall network entropy, so my mean edge entropy is just about right. If someone disagrees I'd love to hear it.
