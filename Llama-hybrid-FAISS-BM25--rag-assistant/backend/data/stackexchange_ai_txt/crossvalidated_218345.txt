[site]: crossvalidated
[post_id]: 218345
[parent_id]: 
[tags]: 
Vector Outcome Logistic Regression

Question: What model (Likelihood/prior family) is appropriate to use when attempting to do inference on a vector of boolean outcomes given continuous factors? Elaboration: I am only aware of machine learning approaches to this at present (for instance, an Artificial Neural Network may have multiple output layer nodes). I am interested in learning Classical/Bayesian approaches to this problem. I would also greatly appreciate being directed to some resource demonstrating how to implement the model so I don't have to reinvent the wheel (MCMC or fisher scoring or whatever). Toy Example: In the FooBar Baseball League, there exist two Halls of Fame (A and B). I have historical information about players' batting averages, seasons played, and so on, which I will call my factors, and historical information on which players were accepted into the halls of fame (I don't know if this is a rare event in real life, but don't worry about that aspect). I would like to do inference on which players will be inducted in the future. It is known that the Hall of Fame leaders take different approaches in making their decisions (maybe A cares more about batting average than B). It is known that the Hall of Fame leaders play golf together on weekends, and often discuss which players they are thinking of inducting, meaning that they influence each other's decisions (that is, the events of being inducted into each hall are conditionally dependent given the factors). By request, here is what the data would look like: factors(X): Player || Batting Average || Seasons Played Jon A || 0.23 || 3 Ben C || 0.32 || 7 ... ... ... ... ... ... ... ... ... ... .. Response(Y): Player || Accepted (HoF A) || Accepted (HoF B) Jon A || NO || YES Ben C || YES || YES So the response is a matrix instead of a vector as is usual in logistic regression. Bonus: I am especially interested in being able to conduct sequential updating on this model (be it Bayesian or not).
