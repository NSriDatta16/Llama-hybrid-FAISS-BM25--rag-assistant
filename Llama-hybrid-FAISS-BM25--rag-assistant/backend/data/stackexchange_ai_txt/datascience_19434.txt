[site]: datascience
[post_id]: 19434
[parent_id]: 19430
[tags]: 
You can side step the paucity of training data, and indeed training altogether, by using pre-trained embeddings in numerous languages . After that you can calculate your document embeddings using one of these simple algorithms, which basically amount to running dimensionality reduction on the matrix of stacked word embeddings for each sentence using PCA/SVD: A Simple but Tough-to-Beat Baseline for Sentence Embeddings ( code ) Representing Sentences as Low-Rank Subspaces Note that word embeddings themselves emerge from similar calculations: Neural Word Embedding as Implicit Matrix Factorization
