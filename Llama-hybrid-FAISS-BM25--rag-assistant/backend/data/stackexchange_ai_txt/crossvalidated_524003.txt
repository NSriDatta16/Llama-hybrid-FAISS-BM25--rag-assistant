[site]: crossvalidated
[post_id]: 524003
[parent_id]: 
[tags]: 
Why does $V_{1,-1}V^{-1}_{-1,-1}V_{-1,1}=\sigma_1^2R_1^2$? (Covariance Matrix Property)

I'm told that $V_{1,-1}V^{-1}_{-1,-1}V_{-1,1}=\sigma_1^2R_1^2$ but I'm having a hard time seeing it. If I understand correctly, I can see that $V_{1,-1}V^{-1}_{-1,-1} = b_{-1}^T$ but I don't see the former. Understanding the notation: $V$ is the covariance matrix. The part of the matrix being specified is denoted by the subscripts. A positive number means that it includes that row (if it's the first number) or column (if that's the second number). A negative number means it includes all rows/columns except for that number. Thus $V_{1,-1}$ is the first row excluding the first element, V_{-1,1} excludes the first element of the first column, and $V^{-1}_{-1,-1}$ is the portion of the inverse covariance matrix that excludes the first row and column. I'm using a couple resources that use slightly different notation. It's probably easiest to become familiar with the problem by pulling up this article. The paragraph after equation (4) on page 1823 claims the result but I'd love some help seeing it and building some intuition Some Working Knowledge: $\beta = \frac{\sigma_{12}}{\sigma_1^2} = \frac{\sigma_{12}}{\sigma_1^2}\frac{\sigma_{2}}{\sigma_2} = \frac{\sigma_{12}}{\sigma_1\sigma_2}\frac{\sigma_{2}}{\sigma_1} = \rho \frac{\sigma_2}{\sigma_1}$ Another fact I'm aware of (although I'm not sure how to show it) is $\rho_{\hat y,y}^2 = R^2$ .
