[site]: crossvalidated
[post_id]: 493794
[parent_id]: 493729
[tags]: 
Here's a few ideas. This answer draws on a post by Norm Matloff , who fit log-linear models on the same dataset in R using loglin() to show how the paradox is related to the order in which the variables are considered. First we'll load the packages and data. I'll also set up deviation contrasts to mirror the output we'd get from a traditional log-linear analysis (as in the post above), but using glm() . # Import Packages library(tidyverse) # Import data ucb_tidy % mutate_at(c("Gender", "Dept", "Admit"), as.factor) # Specify Deviation Contrasts contrasts(ucb_tidy $Admit) Gender) Poisson Regression Now if you're interested in model fit, we can fit three nested models. The first will include admission by gender terms, while ignoring the effects of department. The second will also include department and department-admission interactions. The third will do the same, but also include an interaction between gender and department. We can then use likelihood ratio tests (using the lmtest package) to evaluate whether these additional department-interaction terms progressively improve our model fit. library(lmtest) # Model Building Approach m1 Incorporating the department as a predictor that also interacts with admissions (i.e. m2a ) improves the model fit relative to the model ignoring the department (i.e. m1 ), $\chi^2=1014.8, p . The model that additionally incorporates an interaction between gender and department (i.e. m2b ) improves model fit over and above this, $\chi^2=1128.7, p . We would therefore select m2b as our final model 1 , although you could continue on with the three-way interaction if you're feeling so bold (although this model would be saturated ). The 'paradox' is probably easier to understand though when you plot the model predictions. I'll use emmeans for this, and put the predictions on the numbers admitted scale (rather than the default log scale). The patchwork package just joins the two plots at the end using + . # Plot model predictions using emmeans and patchwork library(emmeans) library(patchwork) m1_plot While fewer women were applying overall in this UCB dataset (roughly half the number of men), the model that ignores which departments they were applying to would suggest the women were rejected at a higher rate relative to the men. The model that does include the department as a predictor though, and particularly the department-gender interaction, would suggest the opposite effect (when averaging over the departments). 2 You can check how close the model predictions were to the raw data using emmeans once more: # Predictions emmeans(m2b, ~ Dept:Admit + Dept:Gender, type = "response") # Observed ucb_tidy Logistic Regression Finally, it is indeed possible to model the proportions of people admitted by department and gender using logistic regression (rather than the raw counts, as in the poisson regression above). You'd do that like so: # Convert Data ucb_logit This plot shows the model can replicate the observed proportions in the dataset fairly well. 1 This model gives us identical parameter estimates to Norm's loglin() results. 2 Note that the scales are slightly different because including department in the model 2b weights the estimates differently.
