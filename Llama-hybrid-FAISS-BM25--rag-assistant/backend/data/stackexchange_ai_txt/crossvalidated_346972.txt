[site]: crossvalidated
[post_id]: 346972
[parent_id]: 
[tags]: 
Weight minority classes using XGBoost (Multiclass)

I'm dealing with a multiclass problem in R using XGBoost. The dataset has 3 Classes representing the following proportion: 20% - 75% - 5%. Given the description above, it would be awesome some tips of you guys regarding what I'm planning to do in the next steps: 1- Use Grid Search to find the best weights combination for each class, using the Class accuracy as a metric (at least in the first moment). Using something like 0.5 - 0.1 - 0.8 results in a not bad output (but still not a good one). Is there a better approach or rules to weight those classes? Should the weights for each sample sums 1 in total? 2- The baseline for this classification uses historical data with some groupings and the prediction comes from these groupings given the desired date. Because of that, the accuracy for the class 2 (majority) will over 95%, and my algorithm will never reach that. I do not think that's a problem since the classes of interest are 1 and 3 (minority), and there goes my question: Can I give more weight to thoses classes even if the class 2 accuracy reduce? Since the accuracy for the class 2 reduces, the misclassification samples would be part of one of the tow other classes, and beyond that other metrics would drop to the floor when I do that, is that right? Thanks in advance !!
