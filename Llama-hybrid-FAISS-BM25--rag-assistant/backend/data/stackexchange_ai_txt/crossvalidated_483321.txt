[site]: crossvalidated
[post_id]: 483321
[parent_id]: 52071
[tags]: 
This sounds like "data augmentation", which is often applied when training neural networks (perhaps because these classifiers have many parameters, and you want to avoid over-fitting to irrelevant properties of the limited training set). For example, if you are classifying images by subject, then to enlarge your training set you might try slight rotations, translations, rescaling or adding noise. (It probably involves a level of prior knowledge about the problem domain, to tell which transformations will simulate an equally-plausible sample of the same class .)
