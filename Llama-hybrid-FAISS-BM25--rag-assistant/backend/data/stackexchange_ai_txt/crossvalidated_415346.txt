[site]: crossvalidated
[post_id]: 415346
[parent_id]: 
[tags]: 
Why not to use Bayes theorem in the form $p(\theta | x) = \frac{L(\theta | x) p(\theta)}{p(x)}$?

There are a lot of questions (like this ) about some ambiguity with Bayesian formula in continuous case. $$p(\theta | x) = \frac{p(x | \theta) \cdot p(\theta)}{p(x)}$$ Oftentimes, confusion arises from the fact that definition of conditional distribution $f(variable | parameter) $ is explained as $f$ being function of $variable$ given fixed $parameter$ . Alongside with that, there is an equivalence principle stating that likelihood can be written as: $$ L(\theta | x) = p(x | \theta)$$ So why not to use Bayes rule for distributions in the following form: $$p(\theta | x) = \frac{L(\theta | x) \cdot p(\theta)}{p(x)}$$ to emphasize that we are dealing with functions of $\theta$ given observed data $x$ , and that the respective term is likelihood (at least, starting with $L$ )? Is this a matter of tradition, or is there something more fundamental in this practice?
