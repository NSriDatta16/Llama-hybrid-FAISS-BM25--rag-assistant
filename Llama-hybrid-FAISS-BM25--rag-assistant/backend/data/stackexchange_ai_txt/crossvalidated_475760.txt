[site]: crossvalidated
[post_id]: 475760
[parent_id]: 474958
[tags]: 
To look for equivalence one should compare the form of, $$\hat{\beta} = \underset{\beta}{\text{argmin}} -y\log(\hat{y}) - (1-y)\log(1-\hat{y}) + \lambda||\beta||_2^2,$$ with the posterior distribution whilst keeping a general expression for the prior. The posterior distribution has form, $$\pi(\beta|x) \propto \pi(\beta)L(\beta;x).$$ Where $\pi(\beta)$ is the prior and $L(\beta;x)$ is the likelihood. Noting that $\beta$ is $p\times1$ and that $x$ represents the data where $x_i$ is one observation and would be $p\times1$ . In logistic regression the model for the data is Bernoulli (more generally Binomial). So, $$y_i|\beta,x_i \sim Bernoulli(p_i)$$ where $p_i = \frac{\exp\{\beta^Tx_i\}}{1 + \exp\{\beta^Tx_i\}}.$ Let $f(\cdot)$ be the density function, then the posterior for $\beta$ becomes \begin{align*} \pi(\beta|x)&\propto\pi(\beta)\prod_{i=1}^{n}f(x_i|\beta) \\ &= \pi(\beta)\prod_{i=1}^{n}p_i^{y_i}(1-p_i)^{1-y_i}. \end{align*} The maximum-a-posterior (MAP) of $\beta$ is the mode of its posterior distribution and since $\log$ is monotone, $$\hat{\beta}_{MAP} = \underset{\beta}{\text{argmax}}\pi(\beta|x) = \underset{\beta}{\text{argmax}}\log\pi(\beta|x).$$ So taking, $$\log\pi(\beta|x) \propto \log\pi(\beta) + \sum_{i=1}^n\big\{y_i\log p_i + (1-y_i)\log(1-p_i)\big\}$$ and noting that $\hat{\beta}_{MAP} = \underset{\beta}{\text{argmax}}\log\pi(\beta|x) = \underset{\beta}{\text{argmin}}\big\{-\log\pi(\beta|x)\big\}$ we can see that, \begin{align*} \log\pi(\beta) &\propto - \lambda||\beta||_2^2 \\ \Rightarrow \pi(\beta) &\propto \exp\{-\lambda||\beta||_2^2\}. \end{align*} This can be seen as taking independent normal priors with mean zero and variance $\frac{1}{2\lambda}$ , $$\beta_j \sim N\left(0,\frac{1}{2\lambda}\right) \ \ j=1,\dots,p.$$
