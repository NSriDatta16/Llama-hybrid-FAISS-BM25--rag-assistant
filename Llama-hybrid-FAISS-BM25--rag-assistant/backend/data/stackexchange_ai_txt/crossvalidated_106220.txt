[site]: crossvalidated
[post_id]: 106220
[parent_id]: 106211
[tags]: 
For pointers to the literature, see the nice answer of @M. Berk. I have just a small comment, which might explain why such methods are not ubiquituous and probably won't be. From the first I would be unsure whether the result pays the effort. The standard argument for Bagging shows that the variance decreases, as long as the results are uncorrelated. More detailed (citing Hastie et. al., chapter 15), if you have $B$ i.i.d. random variables each with variance $\sigma$ and pair-wise correlation $\rho$, the variance of the average is $$\rho \sigma^2 + \frac{1-\rho}{B} \sigma^2.$$ If you now have a well tuned random forest ensemble, I guess any of those universal methods you mentioned will probably have a large correlation with the random forest prediction, and as a consequence you will hardly get an improvement. The same will probably hold for any other well tuned ensemble (let it be ANNs, SVMs, etc.). Moreover, putting more and more models in your ensemble can also lead to overfitting (if the ensemble is not properly regularized).
