[site]: crossvalidated
[post_id]: 594908
[parent_id]: 
[tags]: 
Chi-squareness of the interaction term of the sum of square

I'm learning 2 way layout ANOVA. $$ X_{ijk} = \mu + \alpha_i + \beta_j + \gamma_{ij} + u\\ u \sim \mathcal{N}(0,\sigma^2) $$ The total sum of squares can be decomposed as followings ( $*$ -index indicates the average about itself). $$ \sum_{ijk} (X_{ijk} - X_{***})^2\\ = \sum_{ijk} (X_{ijk}-X_{ij*})^2 + (X_{i**}-X_{***})^2 + (X_{*j*}-X_{***})^2 + (X_{ij*}-X_{i**}-X_{*j*}+X_{***})^2\\ = S_{e} + S_{\alpha} + S_{\beta} + S_{\gamma} $$ For the F-test,I want to proof some independencies and chi-squareness of them under null hypothesis( $\alpha_i = \beta_j = \gamma_{ij}=0$ ). I found useful the theorem such as: $Z_i \sim \mathcal{N}(0,1) \Rightarrow \sum_{i=1}^n(Z_i-Z_{*})^2 \sim \chi^2_{n-1}$ and independent from $Z_{*}$ Thanks to this theorem, $S_e,S_\alpha$ (or $S_e,S_\beta$ ) are independent chi-squares, and $S_\gamma$ is independent from $S_e$ at least. (because $S_\alpha,S_\beta,S_\gamma$ are consist of $X_{ij*}$ ) but, I can not prove chi-squareness of $S_\gamma = \sum_{ijk}(X_{ij*}-X_{i**}-X_{*j*}+X_{***})^2$ . It seems the theorem is not applicable to this as $S_\gamma$ is a little complicated. How can I prove this ? Is there any general method to prove chi-squareness of the sum of squares with complex averaging like this? Thanks.
