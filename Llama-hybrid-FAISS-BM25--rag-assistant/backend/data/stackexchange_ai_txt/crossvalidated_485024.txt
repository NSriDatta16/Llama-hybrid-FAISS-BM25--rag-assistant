[site]: crossvalidated
[post_id]: 485024
[parent_id]: 
[tags]: 
How to preprocess time series data with a high range for a neural network?

I have a multivariate time series where one feature ranges from 0 to 25 million while another simply goes from 0 to 800 thousand. Here is an example of my data: Giving these values to a neural network won't be of any use as it will not learn properly because of the high values. For this to work the data must be rescaled to something more suitable like [0,1] or [-1,1] but I don't know what is the best way to achieve this. Should I rescale the data as a whole or do it for each individual feature? If the latter then the model would think that 25000000 = 800000 as they would both be the highest point for their feature. Is it reasonable to assume that a small range of [0,1] can adequately represent 25 million integers? What about predicting numbers outside the range available in the dataset? Would this be possible if the data is constrained to a range? Other than normalisation and standardisation I thought of using the Box-Cox method to find the ideal transformation, however I don't understand how the results help. I assumed that the Box-Cox method would find the best parameter to normalise my data but when applied on one of the features (Confirmed) I get this: Isn't the Box-Cox method supposed to make the data fit the normal distribution therefore creating a bell shaped histogram? Given a time series with a large range what is the best method to scale it for a neural network?
