[site]: crossvalidated
[post_id]: 623350
[parent_id]: 
[tags]: 
Within a Random Forest, is there a way to detect which trees are more correlated with each other?

One common piece of advice given when you train a Random Forest model (RF) is, increasing the number of trees as much as possible, until the accuracy doesn't improves anymore. But, is quantity always better than quality ? Given that not all the randomly-grown estimators are equally correlated with each other, what if we could remove some of them â€”the less relevant ones? What if we could linearly compare among the many trees, and remove those ones that are similar to each other, ie. that are redundant and don't provide an information gain to the model? Additionally, if we could not remove them, could there be a way to assign weights to each of them? Instead of letting all the estimators having the same importance, which seems a mistake to me. I haven't seen anything related on this topic, that's why I ask. Thanks in advance.
