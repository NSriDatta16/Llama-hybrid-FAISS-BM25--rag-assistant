[site]: crossvalidated
[post_id]: 21794
[parent_id]: 21659
[tags]: 
There is a technique called weighted SVM (see ref below), that appears to be supported by LibSVM (which I've never actually used). Weighted SVM solves the problem of having two classes with unequal training data. In this case, classification is biased towards the class with more observations. To compensate, W-SVM sets the penalty parameter C in proportion to the size of the class. The same idea can be applied to confidence information by giving each observation its own C; though I'm not sure if LibSVM supports this. In this sense, you give a larger penalty to observations in which you have a lot of confidence, and a small penalty to observations with which you have little confidence. The end result is that the hyperplane is determined by weighting each observation by its confidence interval, as you desire. Huang, & Du (2005). Weighted support vector machine for classification with uneven training class sized. Proc. of the 4th Int. Conf. on Machine Learning and Cybernetics, 4365-4369. Retrieved from http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1527706
