[site]: datascience
[post_id]: 61245
[parent_id]: 61244
[tags]: 
No, they won't have neither the same performance nor the same architecture if you were to try to visualize it. An XGBoost with 100 n_estimators and a learning rate of 0.1 is a 100 trees grown sequentially, and each tree's output is multiplied by 0.1. The latter is a model of 50 trees grown the same way and the outputs are multiplied by 0.2, so your second model ( given the usual size of datasets nowadays ) will probably underfit the data, a low number of trees to learn from the data and a high learning rate which will make it somewhat innaccurate. Unless you're looking for another kind of similarity, this should explain it enough. I hope. If not, feel free to comment to clarify your question more.
