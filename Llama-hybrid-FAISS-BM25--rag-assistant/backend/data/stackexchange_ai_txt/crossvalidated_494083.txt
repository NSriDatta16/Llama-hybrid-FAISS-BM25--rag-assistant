[site]: crossvalidated
[post_id]: 494083
[parent_id]: 493898
[tags]: 
One big problem here is the combination of LASSO with a small number of cases. LASSO at its optimum penalty factor will typically retain a number of predictors close to the number that can be comfortably be assessed without overfitting. In a logistic regression, that's about 1 predictor for every 15 or so members of the minority class. With only 51 cases total there can be no more 25 members of the minority class, so LASSO will probably only return about 2 or 3 of your features with non-zero coefficients. The second big problem is that logistic regression suffers from a particularly bad type of omitted-variable bias . In logistic regression, if you omit a predictor that's associated with outcome you can tend to bias the magnitudes of coefficients of included predictors down toward 0 even for predictors not correlated with the omitted predictor. So any one-feature-at-a-time approach for logistic regression has substantial disadvantages (even putting aside the low sensitivity of AUC for distinguishing among models ). That provides an answer ("No") to your point 1. It sounds like you might be better off using a method that uses all of your features in some way, like ridge regression. An Introduction to Statistical Learning shows, in Section 6.6, how to use cross-validation directly to choose an optimal penalty value for ridge regression.* For a logistic regression you would be best off using the deviance criterion (or the equivalent log-loss criterion) for optimizing the penalty level via cross-validation rather than AUC. You might also consider a different approach to modeling class probabilities that can use all of your features while avoiding overfitting, say one that learns slowly like boosted regression trees. *or for LASSO if your still want to use that, providing answers to your points 2 and 3: you can and should choose the penalization factor through cross validation by optimizing an appropriate measure of model performance.
