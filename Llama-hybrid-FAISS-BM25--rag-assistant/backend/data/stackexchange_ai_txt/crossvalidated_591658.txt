[site]: crossvalidated
[post_id]: 591658
[parent_id]: 591657
[tags]: 
This is a multiple regression problem, addressable with either linear regression or a generalized linear model. I would start out with multiple linear regression, possibly including interactions between variables and do a bit of variable selection to find out which predictors are the most relevant. The best thing would be to split the dataset in a training and validation set, but your sample seems to be very small for this to be useful. In R , linear regressions can be fitted with the lm command. For variable selection, using the subset regression approach, you find an implementation in the olsrr package. R Appendix (with commentary) Install and load the olsrr package. install.packages("olsrr") library(olsrr) Load the data in R mydata I have shortened the names of the variables with respect to your original file: "Total Project Cost (in local currency)" -> cos "Total Building Floor Area (sq. m.)" -> area "Number of Floors" -> floors "Year of Construction" -> year "Proximity to the Fault Line (km)" -> fault_line "Liquefaction Potential (qualitative rating)" -> liquefaction "FEMA-154 Rating" -> FEMA_154 "SVR Version 1.1" -> SVR_v1.1 Then I do some housekeeping. In particular, I model the natural logarithm of cost but feel free to switch to the original scale if you are not convinced. It seems more natural to me to model cost in log scale since this typically causes the response to be less skewed, thus leading typically to more symmetric residuals. Furthermore, I scaled year variable to "time in years" computed as year - minimum of year. mydata $log_cost cost) # natural log of cost # remove the original cost var from the dataset mydata$cost $time_y year - min(mydata$year) # year is not needed anymore mydata$year $liquefaction liquefaction) Now the multiple regression. Without doing model selection, (as suggested by @seanv507) we can fit the multiple regression model by mod and then check the output (below the command I report also the output) > summary(model) Call: lm(formula = log_cost ~ ., data = mydata) Residuals: Min 1Q Median 3Q Max -1.19417 -0.33599 0.04854 0.41863 1.04916 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 17.1773984 2.6713375 6.430 5.80e-07 *** area 0.0003540 0.0001071 3.304 0.00261 ** floors 0.4967551 0.1057649 4.697 6.35e-05 *** fault_line -0.0227759 0.0753314 -0.302 0.76463 liquefactionLow 1.4190090 0.5696939 2.491 0.01895 * liquefactionModerate 0.3078771 0.4631636 0.665 0.51166 liquefactionSafe 0.7917331 0.4377499 1.809 0.08126 . FEMA_154 -0.5305908 0.4149623 -1.279 0.21152 SVR_v1.1 -0.0392504 0.0298238 -1.316 0.19882 time_y -0.0137031 0.0133730 -1.025 0.31428 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 0.5564 on 28 degrees of freedom Multiple R-squared: 0.7507, Adjusted R-squared: 0.6706 F-statistic: 9.37 on 9 and 28 DF, p-value: 2.095e-06 As you can see, the model does a pretty good job at describing the response (e.g. adjusted $R^2=67\%$ ), though some of the variables seem to be not relevant. Applying a variable selection procedure, here I'm using subset selection we get > ols_step_best_subset(model) Best Subsets Regression --------------------------------------------------------------------------- Model Index Predictors --------------------------------------------------------------------------- 1 area 2 floors liquefaction 3 area floors liquefaction 4 area floors fault_line liquefaction 5 area floors liquefaction FEMA_154 SVR_v1.1 6 area floors liquefaction FEMA_154 SVR_v1.1 time_y 7 area floors fault_line liquefaction FEMA_154 SVR_v1.1 time_y --------------------------------------------------------------------------- Subsets Regression Summary -------------------------------------------------------------------------------------------------------------------------------- Adj. Pred Model R-Square R-Square R-Square C(p) AIC SBIC SBC MSEP FPE HSP APC -------------------------------------------------------------------------------------------------------------------------------- 1 0.3070 0.2878 0.1304 43.8405 96.5277 -13.8828 101.4405 25.4360 0.7045 0.0191 0.7700 2 0.6401 0.5964 0.563 8.4333 77.6374 -34.5702 87.4630 13.6010 0.4092 0.0112 0.4217 3 0.7296 0.6873 0.6237 0.3758 68.7692 -41.1882 80.2323 10.5275 0.3248 0.0089 0.3340 4 0.7334 0.6818 0.5636 1.9513 70.2343 -39.0622 83.3350 10.7047 0.3384 0.0093 0.3474 5 0.7414 0.6810 0.5359 3.0509 71.0744 -37.2581 85.8127 10.7179 0.3471 0.0097 0.3556 6 0.7499 0.6809 0.5183 4.0914 71.7982 -35.3518 88.1741 10.7093 0.3551 0.0100 0.3630 7 0.7507 0.6706 0.4361 6.0000 73.6743 -32.7058 91.6878 11.0426 0.3747 0.0107 0.3822 -------------------------------------------------------------------------------------------------------------------------------- AIC: Akaike Information Criteria SBIC: Sawa's Bayesian Information Criteria SBC: Schwarz Bayesian Criteria MSEP: Estimated error of prediction, assuming multivariate normality FPE: Final Prediction Error HSP: Hocking's Sp APC: Amemiya Prediction Criteria From these results we can conclude that the "best" model, that is, the model with the best in-sample predictive performance is model 3 , which includes covariates area floors and liquefaction .
