[site]: crossvalidated
[post_id]: 114139
[parent_id]: 
[tags]: 
Inferring prior distribution

Suppose that we take a sample ($X_1, X_2, ... X_n$) from a distribution where we assume that $X_i $~$ Bin(n_i, p_i)$ and $n_i$ is known for every $i$. We also assume that $p_i$'s are independent and identically distributed, $p_i$ ~ $D$, where $D$ is some unknown distribution. $n_i$ cannot be assumed to be large. My goal is to get a Bayesian estimate (or a probability distribution) for $p_i$. But this requires coming up with a distribution for $D$. One option is to make an empirical distribution that uses frequentist estimates for each $p_i$ (i.e. $p_i = X_i/n_i$). This is a rather intuitive and potentially reasonable idea. Unfortunately, the presence of small $n_i$'s would make the tails heavier than they should be (lots of extreme values close to 0 or 1). I'm looking for another option that doesn't have the problems of the aforementioned solution. One possibility I have in mind is to use the following algorithm: Generate prior distribution as explained earlier. Get MAP or EAP estimate for every $p_i$. Generate new empirical prior from the probabilities obtained in 2. Go back to 2 (continue for a set number of steps, or possibly until convergence?) Is this method similar to any method out there? Is it reasonable?
