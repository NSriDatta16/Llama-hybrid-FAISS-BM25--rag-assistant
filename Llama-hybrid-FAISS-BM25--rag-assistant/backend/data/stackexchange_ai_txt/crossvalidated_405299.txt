[site]: crossvalidated
[post_id]: 405299
[parent_id]: 405268
[tags]: 
This is known as target-based encoding , and for high-cardinality categorical variables (such as your example), this is a better option as compared to other encoding approaches. One issue with target-based encoding is that some of the categories would have a very small number of samples in the training data, e.g., zipcodes with small population. This would make the average target (label) values for those small categories unstable . This leads to over-fitting, which would negatively impact the predictive accuracy of the model. One way to avoid this is to coalesce categories that have similar target rates. You can run two-sample means comparison tests (aka t-tests) among all zipcodes, and then combine the zipcodes that have target rates that are statistically not different. For example, if zipcodes 23233 and 23060 have statistically insignificant difference in their average target rates, then you would combine those two zipcodes into one group and calculate a combined target rate for this new group. You can perform several such iterations until you find groups of zipcodes that are statistically distinct from each other (in terms of their average target rates.) Alternatively, you can build a decision tree using zipcode as the independent variable and your outcome (label) as the dependent variable. The tree can be built using CART, which grows tree by using binary splits. Once the tree is grown (and pruned appropriately), you can use the leaf nodes to determine which zipcodes should be grouped together. The target rates in each leaf node are your transformation values. You can also build this tree using CHAID (Chi-Square Automatic Interaction Detection), which can produce multiple branches of a parent node.
