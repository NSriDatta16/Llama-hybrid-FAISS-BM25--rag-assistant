[site]: crossvalidated
[post_id]: 407005
[parent_id]: 407000
[tags]: 
If you have a perfect classifier , since it will make no mistakes, your FPR and TPR are $0$ and $1$ respectively, so, you're right on (0,1) point in the ROC plane. However, this isn't a curve ; classifiers are represented as points in ROC. The question should be restated for a perfect predictor as @AdamO pointed out, in which we really have the curve because now we have a set of classifiers, which represent a set of points in ROC plane, therefore a curve , going from (0,0) to (1,1) as it should be. We still start from the origin because perfect prediction is not perfect classification. It's all about the choice of the tuning parameter. Adam's example in his 3rd paragraph is the execution of this idea. Before editing this answer, I was actually thinking of a model $M$ with some tuning parameter (e.g. like threshold) having no effect on the result because it was meant to be a perfect classifier and try to visualize what happens when we change the tuning parameter. In that case, it starts from (0,1) , but it actually stays there and doesn't move towards (1,1) , simply because the parameter has no effect.
