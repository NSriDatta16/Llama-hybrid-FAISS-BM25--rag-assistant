[site]: crossvalidated
[post_id]: 445816
[parent_id]: 445263
[tags]: 
If I read your question correctly, you want to infer the distances between the plateau heights and the associated uncertainty of this inference. If it makes sense to think of this as a change point model where the location of the changes are of interest too, the mcp package may be of some use. It is a package for Bayesian change-point regression using MCMC sampling of the (joint) posteriors. The nice thing about such samples is that you can add and subtract to your liking while still correctly representing the uncertainty. So say you just have three plateaus: df = data.frame(width = seq(20, 35-0.1, 0.1), height = c(rnorm(2/0.1, 2.5, 0.1), rnorm(3/0.1, 2.0, 0.1), rnorm(10/0.1, 0.3, 0.1))) Now let's model this as three plateau segments: model = list( height ~ 1, ~ 1, ~ 1 ) We fit it and summarise: library(mcp) fit = mcp(model, data = df, par_x = "width") plot(fit) At this point, you can inspect the overall fit and individual parameters using summary(fit) and plot(fit) and plot_pars(fit) . But for testing specific differences, you can use hypothesis to add/subtract samples and get some inferential tests too: > hypothesis(fit, c("int_2 - int_3 > 0", "int_1 - int_3 > 0", "int_1 - int_2 > 0")) # hypothesis mean lower upper p BF # 1 int_2 - int_3 > 0 1.6038992 1.6211943 1.724851 0.9836667 60.22449 # 2 int_1 - int_3 > 0 2.1916182 2.1363059 2.265295 1.0000000 Inf # 3 int_1 - int_2 > 0 0.5877189 0.4546185 0.607359 1.0000000 Inf You can also test against specific values like "int_1 > 0.5" . Under the hood, hypothesis merely uses tidybayes::tidy_draws(fit$mcmc_post) and dplyr::summarise . Read more on the mcp website and the associated pre-print . Disclosure: I am the developer of mcp .
