[site]: crossvalidated
[post_id]: 70927
[parent_id]: 70925
[tags]: 
There is something very wrong with that model in terms of the fit to the actual data. It is always a good idea to look at plots of aspects of the model fit, particularly in this case for patterns in residuals and influential observations. To look at several diagnostics plots, do layout(matrix(1:4, ncol = 2)) plot(lm2) layout(1) This produces the plot below The clear patterns in the residuals suggests a missing covariate or term from the model. As the residuals aren't independent, that calls into question the inferences in the table produced by summary() . Note also the lower right plot, where most of your observations lie outside the the red (dashed) lines indicating strong influence and leverage on the model coefficients. Now we need to understand what might be causing this. If we reuse the scatterplot code but with resid(lm2) as the y-axis variable we can examine how the residuals vary with xval conditional upon the two factors scatterplot(resid(lm2) ~ xval | education, smooth = F, grid = T, spread = F, reg.line = T, data = e) scatterplot(resid(lm2) ~ xval | sex, smooth = F, grid = T, spread = F, reg.line = T, data = e) The two plots are shown below, first conditioned by education and next by sex This shows that the effect of xval on yval varies considerably (change of slope) depending which sets of observations we look at. If you were to plot the residuals vs sex or vs education (as boxplots, not shown here) they don't look too bad, so the issue looks to be with xval . As you mention you are doing this to look at the results of a mixed model, one assumes the observations are clustered by subject. This could account for the apparent differences in the slope of the relationship for xval on yval , where different individuals had different intercepts and slopes. To that end you should draw plots of the residuals conditioned on Subject . If there is no Subject effect in the data here, then the pattern of residuals suggests that there is another, unmeasured (or not provided here) factor that is modifying the relationship between yval and xval . But to answer the specific question, there are effects in the data that are not accounted for by the simple linear model fitted you fitted. One option to follow up upon is whether there are missing higher order interactions. For example, if we allow for 3-way interactions of the variables in the model, a strong 3-way interaction is observed and the xval term is now significant. lm4 summary(lm4) Call: lm(formula = yval ~ (xval + sex + education)^3, data = e) Residuals: Min 1Q Median 3Q Max -3.5394 -0.7318 0.0000 0.3379 4.8545 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) 1.0667 1.2218 0.873 0.38915 xval 2.3697 0.1969 12.034 2.03e-13 *** sexmale 96.0667 1.7279 55.598 The data are almost perfectly fitted now, all terms in the model are significant and the model diagnostics plots look a lot better, thought there are still some influential observations and the distribution of the residuals is alittle heavier in the tails: layout(matrix(1:4, ncol = 2)) plot(lm4) layout(1) which produces So not perfect, but perhaps illustrates the issue of missing predictors or terms from the original model quite nicely.
