[site]: crossvalidated
[post_id]: 548638
[parent_id]: 
[tags]: 
Intuition between loss and accuracy

I'm working on a multinomial classification model with approximately 3,000 distinct classes to predict in a single category. The model is a neural network and the loss is categorical cross-entropy. One thing I've noticed is that when I change some hyper parameter or add/remove some input feature, the validation loss gets lower (better) while the accuracy goes higher. And sometimes it's the opposite. These are examples of final values, when the model doesn't manage to improve the validation loss anymore. They are a bit contrived but not far from the reality. conditions validation loss validation accuracy feature A / hyperparam B 1.25 0.90 feature B / hyperparam A 1.05 0.85 feature C / hyperparam A 1.55 0.95 It is actually quite hard to find a combination of feature/params that improve both the loss and the accuracy in a significant manner. I must also say that overall the model is working pretty well, with the loss/acc metrics going smoothly as the training goes, and little overfitting. I'm curious of what is the intuition behind the loss going worse while the accuracy improves (or reciprocally), for the same validation data, after changing a parameter or a feature. Is one of them the sign of a "better" model? Which one should I focus on ultimately?
