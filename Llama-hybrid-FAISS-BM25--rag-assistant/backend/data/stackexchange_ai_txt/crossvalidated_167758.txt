[site]: crossvalidated
[post_id]: 167758
[parent_id]: 167756
[tags]: 
The correct procedure is to scale the data separately in the following way: Divide training and test data. For the training data, center and scale the data. Retain the values of the centering and scaling. Using the values from (2), subtract the center from the test data and divide by the scale. A reference for this in the context of support vector machines can be found here , "A Practical Guide to Support Vector Classification" Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin Department of Computer Science National Taiwan University. The reason for this is that we do not want information to spill over between the test and training sets. This is true in general of any ML procedure, not just SVM.
