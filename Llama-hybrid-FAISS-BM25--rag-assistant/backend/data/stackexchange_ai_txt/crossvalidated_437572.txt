[site]: crossvalidated
[post_id]: 437572
[parent_id]: 
[tags]: 
When is oversampling preferable to undersampling and vice versa?

When data is unbalanced, that is, when the distribution of classes being predicted is very uneven (e.g. 90%/10% for two classes or 10%/15%/75% for three classes), many machine learning models have difficulty in correctly predicting the classes because they tend to overpredict that unlabeled data will result in the largest class. Probably the two most common approaches to helping machine learning models to make better predictions is oversampling (randomly duplicating examples of the underrepresented classes until they match the proportion of the largest class) or undersampling (randomly removing examples of the larger classes until they match the proportion of the smallest class). I have read various questions related to my interest here, but I have not found one that asks the same thing: What problem does oversampling, undersampling, and SMOTE solve? When is unbalanced data really a problem in Machine Learning? My question is this: under which conditions is oversampling preferable to undersampling, and under which conditions is undersampling preferable to undersampling? As a corollary question, I realize that some algorithms like SMOTE have some advantages that I don't fully understand. If an answer could explain the superiority of alternate approaches (under which conditions) to both over- and undersampling, I would appreciate that also. I understand that the over- or undersampling technique should be done as part of the training of the models, not before any split. So, when I ask which is "preferable", I mean from the perspective of achieving highest accuracy in the test data. I do realize that it is possible that one or other of over- or undersampling might be preferable depending on if the priority is to predict overall accuracy versus highest accuracy of the minority class; I hope that answers might clarify such nuances.
