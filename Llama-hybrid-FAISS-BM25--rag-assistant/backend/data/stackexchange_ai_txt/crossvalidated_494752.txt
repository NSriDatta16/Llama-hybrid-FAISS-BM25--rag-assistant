[site]: crossvalidated
[post_id]: 494752
[parent_id]: 494748
[tags]: 
Transfer learning from a different task/larger dataset (what makes sense depends, e.g. for medical imaging transfer learning from imagenet is less valuable than from other similar imaging data) + data augmentation (either of the images or mixup - I do not mean generating artificial data using a GAN, but rather augmentations like rotation, cut-outs, color/color-saturation etc. changes) is the standard solution for this, more recently (if there is a lot of unlabeled images) semi-supervised learning (e.g. SimCLR, SimCLRv2 etc.) is another very successful approach. Avoiding data augmentation is probably not what you should aim for, rather it makes sense to discuss what augmentation would be appropriate for your data (e.g. would a rotation not change the label, what about color changes etc.). Most of these (the semi-supervised approaches are more recent, so packages are perhaps less mature) are very, very easy to implement with standard packages, so there's no reason to to use them. However, a big gain will also be achieved by collecting and labeling more data. Depending on what you are comfortable with/want to use, trying out the defaults in something like the fastai library might be a useful starting place (simply because a lot of sensible defaults are build in, not that e.g. the standard examples for keras would be a bad starting place). That being said, whether one can do something useful with such a small number of images will depend heavily on how easy the task is for a neural network. I'd guess you could get a pretty good dogs vs. trucks classifier with 50 dogs and 50 trucks (the differences are very clear and striking and the surface textures are very different, which CNNs find very helpful), while picking up some really nuanced thing might be hard.
