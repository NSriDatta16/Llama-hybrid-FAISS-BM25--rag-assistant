[site]: crossvalidated
[post_id]: 345185
[parent_id]: 
[tags]: 
Adapting a Crowd counting network for annotating objects

Good evening I have a deep learning related question, I'd be glad if somebody could share some ideas about my experiment :) Context I have created my own dataset consisting of 3D scenes containing objects (as seen in the picture below) and tried to apply a crowd counting network to count the number of objects in the samples. The dataset consists of images containing less than 20 objects. To achieve this, I made use of the Multi-Column CNN ( Zhang et al, 2016 ). This is a fully-convolutional network that aims to overcome 'depth' in images by using multiple columns of convolutional layers. This network takes the image as input and estimates a density map (basically a matrix with floating point values). The total number of objects can be calculated by summing up all values in this matrix (integrating). The dataset contains per image sample an array of pixel coordinates, so that a ground-truth density map can be generated beforehand. Goal I would like to adapt the network to estimate the original annotations, instead of estimating density maps. So, the network would then output a matrix consisting only of 0s and 1s. To that end, I introduced a straight-through-estimator as a final layer in the network. A straight through estimator uses a hard activation function (i.e. step function) in the forward pass, but uses a derivable function during backpropagation (i.e. sigmoid). I did not make any other alterations to the network. Problem The network was trained with MSE loss first, which resulted in all pixel predictions going towards 0. This seemed to make sense, as there are only a few pixels per sample that are 1 in the groundtruth. It is "safer" for the network to predict 0 instead of 1. I then tried to calculate the loss on pixels where groundtruth is 1 and pixels where groundtruth is 0 separately. The final loss is then a combination of these two losses, so that they both contribute equally to the loss. This approach also did not yield any favorable results, as way too many pixels remain white. The predictions stay in the hundreds. Question Are there other adaptations to the network that might help me reach my goal? Or is the loss function I tried still not sensible? Thanks for taking the time to read this. I hope my question was phrased well enough. If not, feel free to tell me so :)
