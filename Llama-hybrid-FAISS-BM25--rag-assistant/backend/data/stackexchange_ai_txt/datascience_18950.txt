[site]: datascience
[post_id]: 18950
[parent_id]: 758
[tags]: 
I've created and recently released an open source tool http://dvc.org or DVC that does exactly what you are trying to reach: [Tools for data version control.] DVC works on top of Git, adds data file version control (files are stored outside of Git) and tracks the dependencies between the code and the data files. DVC automatically derives the dependency graph (DAG) for code and data. [Tools enabling to reproduce stages and experiments.] dvc repro data/scores.csv reproduces all the required steps regarding DAG. [Protocol and suggested directory structure for such a project.] DVC required a data directory ( data by default) where you supposed to store all data files. However, DVC transparently moves the actual content to .cache directory and creates the symlinks (yeah, I made it to work on Windows as well). The .cache directory is not synced to Git but it could be synced through the cloud (S3 or GCP) by command dvc sync data/scores.csv (it syncs corresponded data file from cache like .cache/scores.csv_29de545 ) [Automated build/run tools.] See from the above. DVC tutorial is a good starting point - "Data Version Control: iterative machine learning" .
