[site]: crossvalidated
[post_id]: 351637
[parent_id]: 351212
[tags]: 
You can train a network with any loss function you like. Thus, approach 1, you can create a loss function that pushes the network to ensure that the distance between pairs in a mini-batch in the output equals that between pairs in the input. If you do it on a mini-batch basis, and batch-size is say 16 or 32, that seems not unworkable. Or you could sample a few pairs, and calculate the loss on those (same number of pairs each mini-batch, eg sampled randomly). As far as creating a non-linear network that is guaranteed to preserve distance, an approach 2, I think one approach could be to build the network out of blocks which themselves preserve distances, eg rotations. I'm not sure that this network could be anything other than a linear transformation, and just a rotation at that. Any non-linearity, such as a sigmoid squashing, would deform the distances. I think approach 1 sounds workable to me, although no guarantee that distances are always preserved, and they won't be very exactly preserved. The second approach sounds intuitively to me that you'd be limited to a single rotation transformation? Edit: to clarify. I'm answering the question "how can one make an auto-encoder preserve distance?". The implicit answer I'm giving to "Does an auto-encoder preserve distance?" is "Not by default; though you could put in a bunch of leg-work to encourage this to be the case, ie approach 1 above". Edit 2: @DeltaIV has a good point about dimension reduction. Note that the existence of t-SNE and so on, ie low-dimensional projections of high-dimensional space, shows both the limitations of trying to preserve distance (conflict between global distances and local distances; challenge of preserving distances in reduced dimensions), but also that it is somewhat possible, given certain caveats/compromises.
