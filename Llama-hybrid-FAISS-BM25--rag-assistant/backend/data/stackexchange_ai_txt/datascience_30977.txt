[site]: datascience
[post_id]: 30977
[parent_id]: 30973
[tags]: 
I will outline some points about the libraries and point you to some good comparisons that I have read. The GitHub star counts are just another reference point to help compare popularity. While I don't condone simply following the masses, those stars do help you see what a lot of other people think about the frameworks. Tensorflow is very well documented scales up into production, being able to use many GPUs or Google TPU s allows flexible creation of DL architectures, using basic building blocks is backed by Google has a very large following - just look at how many stars it has received over on GitHub! For reference, the awesome NumPy only has 7059 stars ! CNTK is gaining popularity (they started a bit later than Google) has very efficient implementations for specific use cases, such as the usage of CNNs and LSTMs in the text domain is nicely linked to other Micosoft products, like their Azure based toolkits scales well in production is backed by Microsoft has a good following on Github: Theano While still open source (and so able to be further developed by the community), the team behind Theano announced that they will no longer actively develop it. This means it will now likely fall even further behind other leading frameworks, and new functionality coming from ongoing research are not likely to make it into the library. We can see that many people admire Theano, but given that it is basically the oldest DL framework, the star count tells a tale: Additional points Have a look for some overviews and comparisons of the deep learning frameworks in general to get a better understanding of when you might use one over another. Here are some I found useful: Comparing top deep learning frameworks Battle of the deep learning frameworks Choosing a machine learning framework - has a good conclusion I would suggest reading about the difference between static and dynamic computational graphs. Tensorflow e.g. builds and compiles a static graph of your model and then pushes data through. PyTorch on the other hand allows you to create your model dynamically, giving more freedom during the development of new architectures. A common workflow would be to develop and do research with PyTorch, then try to write the final production code in Tensorflow for deployment. One last point - you should be aware of the library Keras. This is a wrapper around the base libraries, such as Tensorflow, Theano and CNTK - maybe more in the future). It is highger-level and easier to use that the others, but behind the curtains it is really just using one of the libraries you are asking about. It is just change on flag in a config file to swap between them! Just for completeness, the Keras GitHub star banner: [All gitHub star counts as of April 2018] I realise some of these points may become outdated and untrue over time. In which case, feel free to leave a comment and I can revise my post.
