[site]: crossvalidated
[post_id]: 595036
[parent_id]: 595031
[tags]: 
I believe the intended application of this preprocessing technique is to first standardize the data with mean zero then change its range to $[-1,1]$ for a neural network input. To quote this referece : You will get better initializations if the data are centered near zero and if most of the data are distributed over an interval of roughly [-1,1] However, in all cases, applying first a standardization technique to get zero mean and then apply a new data normalization to map your features to a certain range is meaningless... it is equivalent to normalizing only $X$ since the standardization step does not change the min/max values (check this question ). What I would suggest is only standardization to zero mean and unit variance like so $$ X_{i}{scaled} = \frac{X_{i} - \mu_{X_i}}{\sigma_{X_i}} $$ where $\mu_{X_i}$ and $\sigma_{X_i}$ are computed for every feature $i$ . Then if you really want to have a range of $[-1,1]$ and your data is Gaussian , you can simply filter them accordingly which according to a Gaussian distribution should give you about $68\%$ of your data. In the reference that I quote, they say ' most of the data' which in this case means $68\%$ if it is Gaussian. But this seems to me like an overkill since you loose too much data. On the other hand, if your data is not Gaussian then clipping values will result in an even greater loss of data (and information). So one should choose a better mapping (e.g. logarithmic, box-cox, and so on...) to make data Gaussian-like first, then standardize to zero mean and unit variance, then clip to $[-1,1]$ if necessary. An example using a simple logarithmic transformation for non Gaussian features: $$ X_i = log(X_i + \epsilon) $$ then $$ X_i = \frac{X_{i} - \mu_{X_i}}{\sigma_{X_i}} $$ See scikit-learn's implementation of standard scaler here and their implementation of non-linear data transformers here . Update: I found this scikit-learn page that discusses tips to tackle deep learning data preprocessing very useful. They do indeed mention that it is recommended to either scale data to $[-1,1]$ or standardize it to have zero mean and unit variance. Applying both is meaningless as shown in this answer that @Tim so kindly provided.
