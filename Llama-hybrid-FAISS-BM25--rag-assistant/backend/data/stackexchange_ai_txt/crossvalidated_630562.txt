[site]: crossvalidated
[post_id]: 630562
[parent_id]: 
[tags]: 
Why does my random forest regression model have a 'noisy' fit to training data and a terrible fit to testing data though there is no extrapolation?

I have multiple datasets from an experimental setup and I'm trying to predict one of the system variables using information from the others. I concatenated 80% of the datasets into training data and the rest into validation and testing equally. There is no problem of extrapolation here as all system runs have been similar so all datasets are in the same range. I made sure to check that the test set and validation set don't have data in unseen ranges. I was able to achieve a very good prediction using neural networks but wanted to see if I could use machine learning to do the same, just to have a baseline for comparison. I ran polynomial regression, random forest regression and SVR and found that the fit to the training data was 'noisy', but significantly worse for the testing data in all cases, but especially in random forest. I tested out each model before and after normalization as well as before and after hyperparameter tuning on the validation set and got the same results. I'm not sure on how to proceed with making a better model. The reason I know having an ML 'baseline' would work is because I was able to execute it previously with data from the same system. However the new data is throwing off the code entirely and I'm not sure how to troubleshoot this. I have attached the training plot for one of the training datasets that was in the concatenated train set, and testing plot for your reference. It appears as though the ranges are different but the overall training set has values in the 26-27 range. Thank you!
