[site]: crossvalidated
[post_id]: 222070
[parent_id]: 221873
[tags]: 
Here is a straightforward, if inelegant, way of achieving this. Let's say that the 2 parameters in question, i.e., those constrained to have opposite sign, are $a$ and $b$. Use a bound (or linearly constrained) least squares routine to solve two different problems, then pick the solution of those two which has the lowest sum of squared residuals. Problem 1: Constrain $a \ge 0, b \le 0$, and all other parameters unconstrained. Problem 2: Constrain $a \le 0, b \ge 0$, and all other parameters unconstrained. Problems having a large number of such constraints, and even more complicated relationships among the parameters, could be solved systematically using a mixed integer (quadratic programming or second order cone problem) solver to impose the needed constraints without resorting to multiple problem solves. EDIT: I don't disagree with the statements from @EdM and others regarding the need for judiciousness in deciding whether to impose constraints. I have merely stated how to do so if their imposition is appropriate.
