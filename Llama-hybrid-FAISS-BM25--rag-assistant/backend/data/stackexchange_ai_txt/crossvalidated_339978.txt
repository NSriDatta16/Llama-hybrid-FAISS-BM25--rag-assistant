[site]: crossvalidated
[post_id]: 339978
[parent_id]: 339969
[tags]: 
I am not familiar with SaS, but Kernels consume a good amount of memory, you may try dimensionality reduction with PCA, in order to improve memory utilization. Stochastic gradient descent shines in bigger datasets, I mean a neural network. Another recent option worth exploring is Gaussian Process which also uses kernels, I have better results with GP than Random Forest, there is a combination of variational inference for GPs that aims for cases like yours, one library to check is Gpflow, which relies on Tensorflow, well this is Python. I believe if you want to scale and have recent algorithms Python is a must, I hope this helps.
