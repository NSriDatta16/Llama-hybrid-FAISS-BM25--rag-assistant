[site]: datascience
[post_id]: 38778
[parent_id]: 38760
[tags]: 
As with most problems like this, it is always best to see the dataset upfront to gain a full understanding. That said, if your categorical dependent variable is between 0 and 1, have you ensured that the independent variables in your dataset have also been scaled in this way? From looking at your code, it doesn't look like this is the case. If your data has not been transformed to a common scale, then the neural network won't necessarily give you accurate results. In this regard, you might try scaling your x data with MinMaxScaler if you haven't done so already and see what you com up with. For instance, suppose you have variables x1 , x2 , and x3 . import numpy as np from sklearn.preprocessing import MinMaxScaler x=np.column_stack((x1,x2,x3)) x=sm.add_constant(x,prepend=True) x_scaled=MinMaxScaler().fit_transform(x) x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.2) Essentially, you are scaling the x variables between 0 and 1, so that the x variables now have the same scale as the y variable. It might be an idea to try this if you haven't already and see what you come up with.
