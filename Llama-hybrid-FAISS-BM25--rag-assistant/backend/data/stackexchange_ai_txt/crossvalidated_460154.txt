[site]: crossvalidated
[post_id]: 460154
[parent_id]: 460108
[tags]: 
A uniform function is simply a function that takes the same value for all its arguments. For example, $f(\theta)=1,\,\theta\in[0,1]$ is a uniform function. When you take such function as a prior distribution for an unknown parameter $\theta$ , you have a uniform prior , also called a flat prior . See wiki: Bayesian_inference for basic introduction into prior and posterior distributions for unknown parameters, the likelihood function, and the Bayes' theorem, which implies $$ \text{posterior} \propto \text{likelihood} \times \text{prior}. $$ One property of a uniform prior is that it does not move the mode of the likelihood function . In other words, the maximum likelihood estimate (MLE) for an unknown parameter coincides with its maximum a posteriori probability (MAP) estimate when the uniform prior is used (in MAP). Another useful property is that many distributions have the uniform distribution as its special case. Thus, starting with a flat prior, one can derive a conjugate prior for a given likelihood function.
