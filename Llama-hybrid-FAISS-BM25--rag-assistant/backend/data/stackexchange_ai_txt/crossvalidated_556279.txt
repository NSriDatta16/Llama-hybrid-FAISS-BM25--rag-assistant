[site]: crossvalidated
[post_id]: 556279
[parent_id]: 
[tags]: 
why do some use ν=n instead of ν=n-1 in the t distribution

I have always accepted that ν=n-1, but then I come across multiple authors showing a derivation of the t distribution by marginalizing out the variance from the normal-inverse-gamma distribution, or by marginalizing out the inverse variance (precision) from the normal-gamma distribution. The results of deriving the t distribution from the normal-inverse-gamma distribution require the use of ν=n and not ν=n-1. For example in the book "Bayesian Data Analysis: Third edition" on page 69, it derives $p(μ|μ_0,σ_0)=t(μ|μ=μ_n,σ=σ_n^2/κ_n,ν=ν_n)$ where $$ μ_n={κ_0\over κ_0+n}μ_0+{n\over κ_0+n}\bar y $$ $$ κ_n=κ_0+n $$ $$ ν_n=ν_0+ν $$ $$ ν_nσ_n=ν_0σ_0^2+(n-1)s^2+{κ_0n\over κ_0+n}(\bar y-μ_0)^2 $$ Since the least informative prior has $κ_0=ν_0=0$ therefore $ν_n=ν_0+n=n$ . For example when using a normal gamma distribution to derive the t distribution, the prior on the precision is $Γ(α=ν_0/2,β=ν_0σ_0^2/2)$ [1] where clearly the least informative prior is obtained in the limit as $ν_0$ approaches 0. Yet on page 66 ν=n-1 is derived, and seems to be correct. Even if $ν_n=ν_0+n$ is correct there is no way to obtain $ν=n-1$ without $ν_0=-1$ , which I can not make sense of, with a gamma or inverse gamma distribution. I clearly must have some fundamental misunderstanding. What is it? I thought that perhaps $σ_n$ would cancel out the different value of ν, but no, instead I get two different results depending on which derivation of the t distribution I use. How do I get the same results from the two different derivations of the t distribution?
