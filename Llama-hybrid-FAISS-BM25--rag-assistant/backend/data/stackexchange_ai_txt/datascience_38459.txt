[site]: datascience
[post_id]: 38459
[parent_id]: 
[tags]: 
What does GlobalMaxPooling1D() do to output of LSTM unit in Keras?

The keras model looks like this features_input = Input(shape=(features.shape[1],)) inp = Input(shape=(maxlen, )) x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp) x = Bidirectional(LSTM(num_filters, return_sequences=True))(x) max_pool = GlobalMaxPooling1D()(x) x = concatenate([x_h, max_pool,features_input]) outp = Dense(6, activation="sigmoid")(x) What does GlobalMaxPooling1D()(x) really do to the output of LSTM? I know the input to LSTM layer is of dimension (batch_size, steps, features). Does GlobalMaxPooling1D take max across num_filters/hidden units of each LSTM unit?
