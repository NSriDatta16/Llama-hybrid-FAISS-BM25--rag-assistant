[site]: crossvalidated
[post_id]: 282160
[parent_id]: 
[tags]: 
How is it possible that validation loss is increasing while validation accuracy is increasing as well

I am training a simple neural network on the CIFAR10 dataset. After some time, validation loss started to increase, whereas validation accuracy is also increasing. The test loss and test accuracy continue to improve. How is this possible? It seems that if validation loss increase, accuracy should decrease. P.S. There are several similar questions, but nobody explained what was happening there.
