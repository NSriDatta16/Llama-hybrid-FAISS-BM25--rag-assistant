[site]: crossvalidated
[post_id]: 307010
[parent_id]: 307000
[tags]: 
I know of three possible problem settings: 1. Detecting contextual anomalies in the time series - the anomalies are individual instances of the time series which are anomalous in a specific context, but not otherwise. For example: low temperature in the winter is cool but in the summer is anomalous. 2. Detecting anomalous sub sequence within a given time series(discord) - anomalous sub sequence with respect to a given long sequence. 3. Detecting anomalous time series with respect to a time series data base - when we have a lot of normal time series and we wish to compare one time series to them in order to decide if its normal. If you wish to use K-Means, I can think of these possible detection anomaly methods for each setting: 1. * Define each series as 24 points time series. * Construct a 24*3 representing vector per each series. * Cluster all series. * Per each cluster, cluster the instance(vectors of length 3). * Look for outlying clusters, instances who are far from their respective cluster centroid. 2. * Decide on discord length(number of consecutive instances), say n. * Construct n*3 representing vector per each subsequence(window). * Cluster these n*3 vector per each series separably. * Compare different cluster/instances distance to cluster, between series and decide on a anomaly heuristic(if distance > X, if cluster inner variance is Y, etc..). 3. * Define each series as 24 points time series. * Construct a 24*3 representing vector per each series. * Cluster all series. * Identify series which are anomalous, based on their distance to cluster, etc.. Depends on the metric you use for distance computing you might need to add normalization/scaling steps. By the way, there are other ways detecting anomalies in a time series. Using prediction models, Hidden Markov models and FSA. In continuation to comment - elaborating on method 1: Say we have fast-driving days and slow-driving days(low traffic/heavy traffic days) then an hour of driving at 10MPH has different meaning. In fast days it might be an anomaly and in slow days it wont. First we split our driving days into relevant clusters. Then at each cluster(sets the driving context) we look if a specific instance is an anomaly. Goal - identifying rows where driving instance diverged from normal. Driving instance is described by volume of traffic, line number and speed(possible hour of the day). Meaning, all driving instances "live" in 3(4) dimensional space. X - 0:1, Y - [1:max(line_number], Z - [0: max(speed)]. Under the assumption that each driving instance is depended on previous driving instance(time series structure) we cant "just" cluster all the instances. If we assume that one day(24 hours) driving instances are independent from next day driving instance(change of driver/car/long break/etc..) we can cluster each such bulk of 24 hours instances(described as the 24*3 vector). Using this clustering we can identify similar driving days. Under the assumption that in similar driving days, differences between driving instances describe real attributes of the in-day driving events, we can re cluster and look for instances with diverged attributes.
