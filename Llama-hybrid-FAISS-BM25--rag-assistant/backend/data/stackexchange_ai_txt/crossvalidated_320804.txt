[site]: crossvalidated
[post_id]: 320804
[parent_id]: 320734
[tags]: 
why don't we face that in practice? The predictions for multiclass classification are done by taking argmax over probability vector, so this is not really an issue. Do frameworks "terminate" the gradient descent algorithm earlier and handle this issue internally? In deep learning usually you don't have any convergence guarantee, so most frameworks just assume you specify number of iterations, or tolerance (for example you stop if log-loss changes less than $\epsilon$ between iterations). There is also the problem with being too confident, but Maxim covered that. For a concrete example you can see this paper .
