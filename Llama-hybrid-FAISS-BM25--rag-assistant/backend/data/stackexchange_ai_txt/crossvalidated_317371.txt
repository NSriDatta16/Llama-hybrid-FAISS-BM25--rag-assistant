[site]: crossvalidated
[post_id]: 317371
[parent_id]: 317359
[tags]: 
Generally speaking, outlier detection corresponds to low-probability density detection; i.e., reject points where the PDF is "small". Cook's Distance and Mahalanobis' Distance correspond to parametric model's in that they assume the data should correspond to some underlying distribution or model. There are many other possibilities out there, like LOF (local outlier factor), using some form of explicit density estimation followed by rejection, using one-class SVM, etc. If you know what is the underlying model that your data should follow, then you should definitely leverage that in terms of getting better results (i.e., parameteric density estimation will beat out non-parameteric if you have the right model).
