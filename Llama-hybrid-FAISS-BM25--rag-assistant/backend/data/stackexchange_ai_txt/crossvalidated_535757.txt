[site]: crossvalidated
[post_id]: 535757
[parent_id]: 48838
[tags]: 
Let $x$ be a state in some Markov chain. Consider the set $T(x)$ of all possible return times , that is, numbers $t$ such that there is a non-zero probability of returning to $x$ in exactly $t$ steps, starting from $x$ . Notice that this is a purely graph-theoretic, not probabilistic notion, in the sense that, if you draw the directed graph underlying the Markov chain (and don't draw any edges corresponding to zero-probability transitions), then $T(x)$ is just the set of all lengths of directed cycles starting at $x$ . The set $T(x)$ has a remarkable property, which is that it is eventually periodic . What I mean by this is that there is some number $P$ such that past a certain point, all members of $T(x)$ are multiples of $P$ , and all multiples of $P$ are in $T(x)$ . So if you visualize the set $T(x)$ as dots on a line, the dots eventually become perfectly evenly spaced. The number $P$ is known as the period of $x$ . When $P=1$ , this just means that past a certain point, all return times to $x$ are possible, and $x$ is said to be aperiodic . The proof that this is the case comes from the fact that $T(x)$ is closed under addition (if $t,s\in T(x)$ , then $t+s\in T(x)$ ), and it turns out any set of positive integers closed under addition has this property. That $T(x)$ is closed under addition should be obvious if you think about it (remember that when we talk about "returning to $x$ in $t$ steps", we don't require that we never visit $x$ in between time). That sets closed under addition have this periodicity property is related to BÃ©zout's identity . The period of $x$ , as it turns out, is also equal to the GCD of $T(x)$ (because taking the GCD of an infinite set of numbers makes perfect sense, if you think about it). However, simply defining the period to be the GCD is a terrible way of doing things, pedagogically, because unless you know about this periodicity property, there's no apparent reason why the GCD should be relevant to anything. If two states communicate , meaning it's possible to go from the first to the second and from the second to the first in some number of steps, then the two have the same period. This is easy to see. Since $x$ and $y$ communicate, it's possible to get from $x$ to $y$ in, say, $r$ steps, and from $y$ to $x$ in $s$ steps. Therefore if $t\in T(y)$ , $r+t+s=t+(r+s)\in T(x)$ . So if you shift $T(y)$ to the right by $r+s$ , you get a subset of $T(x)$ . For the same reason, if you shift $T(x)$ to the right by $r+s$ , you get a subset of $T(y)$ . Given that we know both of those sets are eventually evenly spaced, you can work out that this means the spacing on the two of them must be equal. Because of this, you can take a whole equivalence class of communicating states, and talk about the period of the class , and if you have an irreducible Markov chain (meaning all states communicate), then you can talk about the period of the Markov chain . The period of an irreducible Markov chain is important because it tells you about the long-term dynamics of the chain. Imagine millions of particles all individually running through the Markov chain independently. Picture a heat-map, where states are color coded according to the amount of particles in that state. What you're picturing is really just a visualization of $\mu_0 M^t$ , where $M$ is the transition matrix and $\mu_0$ the initial distribution of particles, the probability distribution of your state at time $t$ given that your starting point was chosen according to distribution $\mu_0$ . If the chain is irreducible, then it turns out that this heat map will eventually stabilize over time. It will stabilize in one of two ways: If the chain is aperiodic, then the heat map eventually essentially stops changing. The distribution of the particles is at equilibrium. If the chain has period $P$ , then after a while the heat map will be seen to cycle between $P$ different distributions, in a kind of "dynamic" equilibrium. The distribution of the particles washes back and forth like a pendulum, in a fixed pattern, forever. Note that in both cases, the particles are all still moving, and indeed each particle is still independently following the Markov chain and moving completely randomly. It's only the overall distribution of particles that becomes predictable. Above is a periodic Markov chain, with the time- $t$ distribution visualized as a heatmap (red means high, blue means low - with apologies to any colorblind readers). You can see an animated version to watch the distribution fall into its periodic dynamic equilibrium, starting with all particles concentrated in one state: Notice that you might naively think the period of the chain is $6$ , given the way it looks, but in fact it contains cycles of length both $6$ and $10$ , the GCD of which is $2$ , so the period of the chain is $2$ , as you will see if you watch the animation.
