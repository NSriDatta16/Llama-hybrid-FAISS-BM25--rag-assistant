[site]: datascience
[post_id]: 120139
[parent_id]: 110184
[tags]: 
Good afternoon @FOH, making a quick summary of the selection of resources would be to remove the resources that are not useful for anything. It does not improve model accuracy. It has no relationship with other attributes are in the set without need. Best way to interpret it would be to plot a graph for every type you got. Facilitating your analysis of the resources you are using to improve the model. Many of these features are noise, they can also be a burden for processing when we train the model taking more time. An interesting way to make a comparison is to put the whole set to train to capture time and measure its accuracy and then select the features with the best performance, pass the model again, perform the same captures and compare whether there is an improvement or not. Carrying out these observations you could see which will be the best to select. Searching I found a very good explanation for selection using SelectFromModel from SK-Learn, where you can perform the selection and analyze. Feature Selection Using Random forest SelectFromModel SK-Learn Another very good tool that can help you is yellowbrick this tool helps a lot. I'll put a link below has a very good example with Gradient Boosting Classifier YellowBrick Model Selection
