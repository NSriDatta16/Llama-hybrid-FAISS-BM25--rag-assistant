[site]: crossvalidated
[post_id]: 533938
[parent_id]: 90799
[tags]: 
I just saw this while looking for the answer to another question, and thought an answer to this might be informative for others, even if it is a little old... I'm not as expert on this as some people on here, so please pull me up if I got this wrong. What the random effect does, compared with the fixed effect, is to impose further assumptions on how the means of the factor levels will be distributed (specifically, that they are normally distributed). So, whereas the fixed effect is free to just go straight for the data, the random effect has certain constraints on it. What this means in practice, is that the fixed effect will (I think?) always be closer to your training data than the random effect (because it can just go and sit right on the mean of the values for that level). But, the random effect should (IF our assumptions are correct) capture the underlying mechanics better, and so (as if by magic) should be closer to your test data than a fixed effect would have been. See my answer here for an illustration of an extreme case, where it is clear that the random effect comes out miles away from the training data, but should be expected (on average) to be closer to future examples. This is really very much like any other overfitting example. The more assumptions we can make, the more constrained the model is. Which means it can't get as close to the training data, but (IF our assumptions are good) should get closer to future examples. Much like with a linear vs quadratic regression: the quadratic model can get closer to the data, but IF the true relationship is linear, the linear model will be a better predictor of future cases.
