[site]: crossvalidated
[post_id]: 592472
[parent_id]: 
[tags]: 
Modeling High Frequency Emergency Department Data

I'm working on a project where the objective is to determine whether there are factors that distinguish an emergency department (ED) encounter from a high-frequency patient (8 or more encounters per year) from all other encounters. My data is at the ED encounter level and contains data that is both specific to the encounter, which can vary at every encounter, and data specific to the patient, which usually does not vary with the encounter. Naturally, since some patients are high frequency patients, the data is imbalanced; some patients have more rows of data than others. Out of 40,000 encounters from a single year, the highest frequency user has 80 rows. I've read a few papers on the subject and based on what I've seen, my initial thought is to use a simple logistic regression, where the binary outcome variable is whether any given ED encounter was from a high frequency patient. I feel as though I should be worried about patient-level data from high frequency patients biasing the coefficients because they are over-represented in the data in terms of rows per patient. On the other hand these are the patients I want to know about so is this really a valid concern? I've also thought about a mixed model, with a random intercept for each patient, but this won't work because the outcome doesn't vary within patients. They're either high frequency or not. A few other notes: I'm not terribly interested in modeling the number of encounters. The goal of the model is to explain, more than to predict, and model coefficients should not be difficult to communicate to a lay audience with simple conversion (such as log odds to odds). I'm working in R What's the best modeling approach here? Are my concerns about bias valid?
