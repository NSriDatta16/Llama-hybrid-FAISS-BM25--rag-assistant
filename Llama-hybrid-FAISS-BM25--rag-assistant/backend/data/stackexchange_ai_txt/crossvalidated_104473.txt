[site]: crossvalidated
[post_id]: 104473
[parent_id]: 
[tags]: 
Difficulty identifying diminishing returns from additional SKUs

As a work assignment, I've been asked to determine the optimal SKU count for a product group. I've decided to tackle this Q using a simple linear regression with sales as my dependent variable and the # of SKUs and the # of SKUs squared as my independent variables. My data set is a cross section of store sales and SKU counts for each store. Trouble arises when I run the regression and get positive coefficients for both # of SKUs and # of SKUs squared (I think diminishing returns are identified by a negative coefficient for the squared variable). I suspect that sales for larger stores are proportionally higher than # of SKUs compared to smaller stores and maybe this is why my coefficient doesn't make sense. I'm looking for suggestions on either model specification or ways to standardize stores (if that's the solution). My data set has about 600 stores and I thought about restricting the group by store size but similarly sized stores also generally have the same number of SKUs. I also thought about using a time series, but my yearly data only goes back a decade or so. I'm also inexperienced in this area, and would be concerned I wouldn't model it properly. Thanks for any advice. Cheers,
