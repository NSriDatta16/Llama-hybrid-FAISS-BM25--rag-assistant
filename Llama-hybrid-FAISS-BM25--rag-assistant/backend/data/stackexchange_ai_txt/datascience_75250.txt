[site]: datascience
[post_id]: 75250
[parent_id]: 75238
[tags]: 
It would work, afterall ML is a lot about engineering and hacking the things together. However, it would perform not so well, as for example logistic regression. If you compare the a linear line and logistic regression you will notice that the gradients of their respective loss functions for points near the decision boundary ("threshold") and far away from it are quite different. While for logistic regression points, that lie close to the decision boundary or are wrongly classified the absolute value of the gradient is larger. As a consequence the optimization, if a gradient approach is chosen, will be impacted by these points the most. Thus, the curve will be fitted to improve the classification. Whereas in linear regression the distance of each point to the linear line is to be minimized, so independently of if the point is already classified correctly, it will impact the optimization. This leads to the optimization to be influenced a great deal by points that are already classified correctly and don't really need to influence the adjustement of the linear function. They suppress the importance of the points that are actually wrongly classified and that should impact the optimization at large.
