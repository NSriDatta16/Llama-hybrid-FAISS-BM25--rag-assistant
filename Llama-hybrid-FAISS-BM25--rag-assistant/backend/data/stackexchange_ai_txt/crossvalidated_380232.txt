[site]: crossvalidated
[post_id]: 380232
[parent_id]: 
[tags]: 
Reason for higher AUC from a test set than a training set using a random forest

I made a 70:30 split of the data to build a random forest model for binary classification. Although the prevalence of $Y=1$ was about 25% in both training and test sets, the two sets became imbalanced while building the model and making predictions due to missingness in covariates. I observed that the "complete" training set had half the $Y=1$ cases compared to the "complete" test set. The AUC for the training data was about 0.70 and the AUC of the test data was about 0.85. How should I explain that? I thought the training data would always show higher AUC than the test data because we used training data to build our model.
