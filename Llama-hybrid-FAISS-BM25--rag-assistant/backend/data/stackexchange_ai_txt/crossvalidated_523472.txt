[site]: crossvalidated
[post_id]: 523472
[parent_id]: 
[tags]: 
Iris data set actual results vs. "expectations"

I'm starting on ML with the Iris dataset (with the errors corrected). I've built a typical test harness in Python. X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=7) models = [] models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=1000))) models.append(('LDA', LinearDiscriminantAnalysis())) models.append(('KNN', KNeighborsClassifier())) models.append(('CART', DecisionTreeClassifier())) models.append(('NB', GaussianNB())) models.append(('SVM', SVC())) results = [] for name, model in models: kfold = KFold(n_splits=10, random_state=7, shuffle=True) cv = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy') results.append((name, cv)) knn = KNeighborsClassifier() knn.fit(X_train, Y_train) predictions = knn.predict(X_validation) I am using the following lib versions: python: 3.8.5 scipy: 1.5.2 numpy: 1.19.2 matplotlib: 3.3.2 pandas: 1.1.3 sklearn: 0.23.2 All the various tutorials and samples seem to indicate that KNN is the best algorithm for this data set. When I run this with either the original dataset with the 2 incorrect rows, or the fixed one, KNN gets 3 prediction errors. Playing around with the K value, I was able to get it down to 2. Even when I remove the random_state=7, 2 prediction errors was the best I could get it to. When I tried LDA, out of the box without any param tuning, I only get 1 prediction error. Am I missing something? Basically, I'm asking why everything I see says KNN should be better, but I'm seeing LDA is better. Or is there something I need to do with KNN?
