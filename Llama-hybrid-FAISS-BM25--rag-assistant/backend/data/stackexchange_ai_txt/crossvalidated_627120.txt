[site]: crossvalidated
[post_id]: 627120
[parent_id]: 
[tags]: 
Derivative-based effect size for Gaussian GAMs

It is often the realistic advice I have seen here that Gaussian GAMs are not regressions with which you can easily approximate an effect size for, as the effects are of course non-linear. However, we do not have this issue with respect to logistic GAMs, as we can estimate the predicted probability or odds ratios of the fit given specific regions of interest. #### Load Libraries and Data #### library(gamair) library(mgcv) data("wesdr") #### Fit Model #### k We can't quite do that here for Gaussian models. However, I was thinking of whether or not one can simply use the derivatives of certain portions of a Gaussian model to derive some magnitude of effect based on where the slice is. For example, if we have a Gaussian model here: #### Fit Gaussian Model #### library(MASS) library(gratia) library(tidyverse) #### Fit Gaussian Model #### b2 % filter(data > 17) # find point somewhere around here aug % filter(times > 17) # find point somewhere around here #### Plot Fit and Approximate First Derivative #### mcycle %>% ggplot(aes(x=times, y=accel))+ geom_smooth( method = "gam", formula = y ~ s(x, bs = "cr", k = 10) )+ geom_point()+ scale_x_continuous(n.breaks = 20)+ scale_y_continuous(n.breaks = 20)+ geom_segment( aes(x=17.6, xend=17.6, y=-86.6, yend=50) )+ geom_label( aes(x=17.6, y=52), label="First Derivative ~ -20.5" )+ labs(x="Times", y="Acceleration", title="Silverman Crash Data")+ theme_bw() From the best I can gather, the point here should have an approximate first derivative of -20.5, indicating that data in this neighborhood have a large magnitude decline in acceleration. A corresponding time of around 27.1 seconds seems to give an opposite first derivative of 20.9, which seems correct given the contrary relationship. My question is basically this: given we can find the derivative in this way, could we use this or some other formulation based on it as an informal metric of the magnitude of an effect? Of course, because of the variability of the slope given its a curve function, this can only be approximate. We also can't standardize the estimate (such as a standardized beta coefficient), so we can't really use it in a way similar to linear regression. However, I worry that if I use a Gaussian model in the future that some reviewers may ask for effect sizes of the predictors and all I can say is how the raw estimates move based off the fitted lines. My thinking is that this could be some sort of compromise to accommodate such a request. Otherwise I think in the future I would only report the model adjusted $R^2$ and descriptively explain the relationship by-location in the curve. For an idea of what I mean, the oddsratio package takes a similar approach with logistic GAMs where "slices" are taken from the function and then odds ratios are derived from those slices. What would be useful is finding something similar for Gaussian fits, for which I think perhaps the first derivatives could provide a clue as to how to do this given they are by definition the slope at a given point of a curve. Edit Something I hadn't considered until now is that while we normally wouldn't want to standardize the scores before entering them into a GAM (as it makes interpreting the GAM plots pretty difficult), it may be useful to do so for the purposes I mentioned here. Estimating the same model with z-scores and then getting their derivatives can be easily achieved like so: #### Standardize Scores #### zdata % mutate(times = scale(times), accel = scale(accel)) zdata #### Fit Gaussian Model #### b3 The derivatives sometimes do what I would expect here, but are made somewhat uninterpretable given the data is now estimated by z-score. It appears that some of the derivatives are greater than 1, which concerns me that this may not be helpful. This also doesn't reasonably average the overall effect size over a specific range, which I believe the oddsratio package does for logistic GAM(M)s. # A tibble: 200 Ã— 10 smooth var by_var fs_var data derivative se crit lower upper 1 s(times) times NA NA -1.73 -0.324 0.875 1.96 -2.04 1.39 2 s(times) times NA NA -1.71 -0.322 0.874 1.96 -2.04 1.39 3 s(times) times NA NA -1.69 -0.318 0.869 1.96 -2.02 1.39 4 s(times) times NA NA -1.67 -0.311 0.862 1.96 -2.00 1.38 5 s(times) times NA NA -1.65 -0.302 0.851 1.96 -1.97 1.37 6 s(times) times NA NA -1.63 -0.289 0.837 1.96 -1.93 1.35 7 s(times) times NA NA -1.61 -0.274 0.820 1.96 -1.88 1.33 8 s(times) times NA NA -1.59 -0.256 0.800 1.96 -1.82 1.31 9 s(times) times NA NA -1.57 -0.235 0.777 1.96 -1.76 1.29 10 s(times) times NA NA -1.54 -0.211 0.752 1.96 -1.68 1.26 Is there a plausible way of doing this? I'm still coming to a dead end on this.
