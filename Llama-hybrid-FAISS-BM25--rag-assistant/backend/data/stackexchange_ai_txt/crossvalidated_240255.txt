[site]: crossvalidated
[post_id]: 240255
[parent_id]: 240138
[tags]: 
It seems perfectly reasonable to me that the binary classification of a given pattern could be analogous to a hypothesis test, but it isn't necessarily. It also depends on exactly what situation you have in mind here. Let us assume that you have a classifier (hopefully a good one), and want to use it determine which class a given pattern belongs to. This should be a new pattern for which you don't already know the true class. It is common in machine learning to assess the value of your classifier by comparing its predicted classes to known (true) classes, but that is a different endeavor. Then, From within the Neyman-Pearson approach to hypothesis testing (cf., here ), you will act as though the null is correct unless there is sufficient evidence to reject it. To be clear, that does not mean that you have 'proven' the null to be true (cf., here ), you will eventually make errors in both directions. The key to this is deciding what long-run error rates you think you can live with. Typically, the null and alternative are not treated symmetricallyâ€”preference is given to the null. Thus for example, people will usually only reject the null if the evidence is sufficient that their long-run ' type I ' error rate is 5%. Generally, a study to test the hypothesis is constructed such that the null will be rejected 80% of the time when the alternative obtains. Those facts imply that people are more comfortable erring on the side of not rejecting the null, than the other way around. But that is a particular value judgment regarding the demerits of the different types of mistakes, there is nothing logically necessary about that. On the other hand, when classifying a novel pattern in machine learning, it is typical that all patterns are classified, and are classified as the maximum a-posteriori class. That is, a pattern will be classified as class A if the classifier suggests it is more likely to be an A than a not-A. This again is a value judgment. Classifiers can be 'weighted' so that they will prioritize sensitivity or specificity . Thus, these represent different cultural and conceptual frameworks, but can be put in correspondence with regard to the underlying logical structure of the two activities. There are other perspectives we could take on comparing and contrasting these as well. For example, we could discuss whether the classifier performs adequately (judged according to some criterion) based on how well the function the classifier embodies, $\hat f({\rm data})$ mimics the true underlying function $f({\rm data})$ , and whether / how closely the assumptions of the particular hypothesis test are met. Similarly, we could contrast how classifiers are trained in machine learning (e.g., by minimizing cross validation error), vs. how models are built to create a context within which a specific hypothesis can be tested. For a broader viewpoint, you may be interested in my answer here: What is the difference between data mining, statistics, machine learning and AI?
