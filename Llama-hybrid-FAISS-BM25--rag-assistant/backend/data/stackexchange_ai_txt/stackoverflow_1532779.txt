[site]: stackoverflow
[post_id]: 1532779
[parent_id]: 1532720
[tags]: 
md5 itself can't be run in parallel. However you can md5 the file in sections (in parallel) and the take an md5 of the list of hashes. However that assumes that the hashing is not IO-limited, which I would suspect it is. As Anton Gogolev suggests - make sure that you're reading the file efficiently (in large power-of-2 chunks). Once you've done that, make sure the file isn't fragmented. Also a hash such as sha256 should be selected rather than md5 for new projects. Are the zlib checksums much faster than md5 for 4Gb files?
