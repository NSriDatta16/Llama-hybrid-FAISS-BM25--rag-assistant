[site]: crossvalidated
[post_id]: 113645
[parent_id]: 112147
[tags]: 
Other answers criticise the performance of bootstrap confidence intervals , not bootstrap itself. This is a different problem. If your context satisfy the regularity conditions for the convergence of the bootstrap distribution (convergence in terms of the number of bootstrap samples), then the method will work if you use a large enough bootstrap sample. In case you really want to find issues of using nonparametric bootstrap, here are two problems: (1) Issues with resampling. One of the problems with bootstrap, either for small or large samples, is the resampling step. It is not always possible to resample while keeping the structure (dependence, temporal, ...) of the sample. An example of this is a superposed process . Suppose that there are a number of independent sources at each of which events occur from time to time. The intervals between successive events at any one source are assumed to be independant random variables all with the same distribution, so that each source constitutes a renewal process of a familiar type. The outputs of the sources are combined into one pooled output. How would you resample while keeping the dependence unknown structure? (2) Narrow bootstrap samples and bootstrap confidence intervals for small samples . In small samples the minimum and maximum of the estimators for each subsample may define a narrow interval, then the right and left end points of any confidence intervals will be very narrow (which is counterintuitive given the small sample!) in some models. Suppose that $x_1,x_2\sim \text{Exp}(\lambda)$, where $\lambda>0$ is the rate. Using the profile likelihood you can obtain an approximate confidence interval (the 95% approximate confidence interval is the 0.147-level profile likelihood interval) as follows: set.seed(1) x This method produces a continuous curve from where you can extract the confidence interval. The maximum likelihood estimator of $\lambda$ is $\hat{\lambda}=2/(x_1+x_2)$. By resampling, there are only three possible values that we can obtain for this estimator, whose maximum and minimum define the bounds for the corresponding bootstrap confidence intervals. This may look odd even for large bootstrap samples (you don't gain much by increasing this number): library(boot) set.seed(1) x In this case, the closer $x_1$ and $x_2$ are, the narrower the bootstrap distribution is, and consequently the narrower the confidence interval (which might be located far from the real value). This example is, in fact, related to the example presented by @GregSnow, although his argument was more empirical. The bounds I mention explain the bad performance of all the bootstrap confidence intervals analysed by @Wolfgang.
