[site]: crossvalidated
[post_id]: 615121
[parent_id]: 540092
[tags]: 
I agree with shimao. $y_i^{(j)}$ is $x_i^{(j)}$ , $\hat{y}_i^{(j)}$ is $\mu_i^{(j)}$ for jth datapoint. But the $\hat{y}_i^{(j)}$ (or $\mu_i^{(j)}$ ) should not be considered model output (estimated label). The model obtains the output by sampling in the distribution $N(x|\hat{\mu}_i^{(j)}, \hat{\sigma}_i^{(j)})$ . In VAE training, we don't need sampling in the decoder,no estimated label, we just maximize the reconstruction loss $p(x|z)$ ,this is a likelihood, as shimao said, this is equivalent to minimizing $\sum_i x_i^{j} - \mu_i^{j}$ , similar in form to MSE.
