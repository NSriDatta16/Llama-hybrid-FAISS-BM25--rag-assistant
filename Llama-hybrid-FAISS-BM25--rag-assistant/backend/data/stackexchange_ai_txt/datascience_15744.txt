[site]: datascience
[post_id]: 15744
[parent_id]: 15742
[tags]: 
Yes, this is classic sentiment analysis. You'll need training data in order to write this program. Typically, people will build a language modeling using the text data in the article, tweets, posts, etc. Most folks specify the language model using a Recurrent Neural Network with a Long Short Term Memory. Here's a blog post that has code linked to their github. Before diving into a more advanced deep neural network like an LSTM, it may be easier to start with a multilayer perceptron using n-grams . It seems like you may be asking for a couple of different things. So, let me be very explicit. The models I listed above take as input the articles and a label that evaluated the articles as either positive or negative sentiment, the model then returns the likelihood of a given article being positive or negative sentiment. It in no way returns a topic. To return the "topic" your best bet would be to run Latent Dirichlet Allocation , which would then return the likelihood of a given article being generated from a given topic that was previously learned. It's important to note that these will only be from topics learned on previous training data and not on new topics. There are standard algorithms available to visualize topic models (e.g., LDAVis ) and the embeddings of language models (e.g., word2vec visualizations ). It's worth noting that there is research being done in learning these items jointly (i.e., the latent topic and the classification of good/bad). I'd recommend reviewing this paper . It may be worth reviewing these items more thoroughly before actually diving into applying them. It sounds like you may not have a complete picture of what your goal is and how deep learning can help you.
