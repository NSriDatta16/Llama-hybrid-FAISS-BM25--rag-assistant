[site]: crossvalidated
[post_id]: 638103
[parent_id]: 
[tags]: 
Model comparison: with raw or normalized data?

I have developed a index of drug addiction risk whose formula is Index = 1/log10(a_given_variable). The raw values of the calculated Index range from -4 to 0. Since I wanted the Index to be expressed on a scale of 1 (lowest risk) to 10 (highest risk), I normalized the Index with the following min-max formula: Index_normalized = (xi - min(x)) / (max(x) - min(x)) Now I want to know if my index is a good predictor of drug addiction risk compared to log10( Literature_var ), which is a good predictor know from literature. To this end, I want to use logistic regression models, using a dataset where Addicted was the dependent variable (0 = non-addicted and 1 = addicted) and log10( Literature_var ) and my index are the independent continuous variables in distinct single-term models. In particular, I compared log10( Literature_var ) with both the raw and normalized version of my index, i.e. with both Index and Index_normalized , using the AIC to identify the most parsimonious model. In R: Model 1a: glm(Addicted ~ Index_normalized, data = df, family = "binomial") Model 1b: glm(Addicted ~ Index, data = df, family = "binomial") versus Model 2: glm(Addicted ~ log10(Literature_var), data = df, family = "binomial") I expected the same performance but obtained opposite results, with Index_normalized being better than log10( Literature_var ) (much lower AIC), and Index being worse (much higher AIC). My doubt is about which of the two proposed models (Model 1a or Model 1b) is the correct one. That is, should I compare Literature_var with the raw values of Index , or with the normalized values of the desired 1-to-10 Index_normalized ? Or maybe should I apply the same normalization formula to the other variable log10( Literature_var )? Thank you
