[site]: datascience
[post_id]: 18542
[parent_id]: 17885
[tags]: 
It may be the version of the 20 newsgroups data used. There are two versions of the dataset available from http://qwone.com/~jason/20Newsgroups/ : (1) the original (2) another with duplicates removed and headers removed that give away the actual group. This dataset is also already separated into train and test. When I load the original data set (with duplicates and headers) and use the code you reference I can get to ~93-95% after three epochs. When I load the second version of the dataset (training only), it takes many more epochs to converge, with a validation accuracy of only about 55% after 10 epochs. Validation accuracy was still on an upward trajectory, so you should be able to improve on these results. As such, I think that that the duplicates/filtering are significantly skewing the results from the blog you mentioned. The classification is easier when the header contains which news group in which it should be classified. The lesser accuracy is a more realistic evaluation of the data. Also note that if you load the dataset using scikit-learn (sklearn.datasets.fetch_20newsgroups), it loads the second version of the dataset. A tf-idf model with multinomial Naive Bayes gets to about 50% on the data, so the RNN is still out performing a baseline model. Though, 95% seems not realistic on the second version of 20 newsgroups.
