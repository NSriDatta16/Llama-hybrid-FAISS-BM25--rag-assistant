[site]: crossvalidated
[post_id]: 582068
[parent_id]: 581263
[tags]: 
Transformer data is B x N x D , where B is batch size, N is the max sentence length in the batch, and D is the dimension. There is no equivalent of the channel you get in image data ( B x C x W x H ). GroupNorm splits the channel dimension into groups, and finds the means and variance of each group. That pytorch doc page says: num_channels must be divisible by num_groups As num_channels is effectively 1 for a transformer, 1 is also the only possible value for num_groups , making it pointless. Additional: Even if you could, is there any reason to prefer it over LayerNorm? Answers on the link in the question mention that LayerNorm works well over a distributed model ( https://stats.stackexchange.com/a/511253/5503 ) and another references https://arxiv.org/abs/2201.03545 saying that LayerNorm works just as well as BatchNorm in ConvNet.
