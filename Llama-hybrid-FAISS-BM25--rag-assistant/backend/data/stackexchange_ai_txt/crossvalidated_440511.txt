[site]: crossvalidated
[post_id]: 440511
[parent_id]: 
[tags]: 
Finding a reliable P-value and pseudo $R^2$ for beta regression in R (betareg model)

I'm having trouble with finding a reliable P-value for my beta regression in R. I thought it was as easy as reading it from the summary table, but as it turns out it is not. This website https://rcompanion.org/handbook/J_02.html tells me that the appropriate test to find the p-value for a betareg model is the lrtest from the lmtest package. According to other forums and websites the p_value ( sjstats package), joint_tests ( emmeans package), and nagelkerke ( rcompanion package) could also be used. Let me first introduce you to my model. I am investigating the influence of percentage overhead cover on the proportion of birds foraging. For this question I have made up three data sets, 1) realistic data, 2) random data, and 3) extreme data. I made these data sets because I wanted to check the P-values (for which I assume only the realistic data must have a significant P-value, if any). These data + their betareg models look like this. My R script + output looks like this. df $ProportionBirdsScavenging ProportionBirdsScavenging*(length(df_realistic $ProportionBirdsScavenging)-1))+0.5)/length(df_realistic$ ProportionBirdsScavenging)) # Transform the data so all data is (0,1). mybetareg_realistic |z|) # (Intercept) 1.69853 0.02563 66.26 |z|) # (phi) 8.7909 0.1861 47.23 $Models # # Model: "betareg, ProportionBirdsScavenging ~ OverheadCover, df_realistic, pointWeight, logit" # Null: "betareg, ProportionBirdsScavenging ~ 1, df_realistic, pointWeight, logit" # # $ Pseudo.R.squared.for.model.vs.null # Pseudo.R.squared # McFadden -2.69615e+00 # Cox and Snell (ML) 1.00000e+00 # Nagelkerke (Cragg and Uhler) -1.53209e-24 # # $Likelihood.ratio.test # Df.diff LogLik.diff Chisq p.value # -1 -2587.3 5174.6 0 # # $ Number.of.observations # # Model: 35 # Null: 35 # # $Messages # [1] "Note: For models fit with REML, these statistics are based on refitting with ML" # # $ Warnings # [1] "None" # # Warning message: # In betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, control) : # no valid starting value for precision parameter found, using 1 instead lrtest(mybetareg_realistic) # Likelihood ratio test # # Model 1: ProportionBirdsScavenging ~ OverheadCover # Model 2: ProportionBirdsScavenging ~ 1 # #Df LogLik Df Chisq Pr(>Chisq) # 1 3 3546.9 # 2 2 959.6 -1 5174.6 $ProportionBirdsScavenging ProportionBirdsScavenging*(length(df_random $ProportionBirdsScavenging)-1))+0.5)/length(df_random$ ProportionBirdsScavenging)) mybetareg_random |z|) # (Intercept) -0.07481 0.04363 -1.715 0.0864 . # Random_OverheadCover -0.73184 0.06930 -10.561 |z|) # (phi) 1.37018 0.02466 55.57 $Models # # Model: "betareg, ProportionBirdsScavenging ~ Random_OverheadCover, df_random, pointWeight, logit" # Null: "betareg, ProportionBirdsScavenging ~ 1, df_random, pointWeight, logit" # # $ Pseudo.R.squared.for.model.vs.null # Pseudo.R.squared # McFadden -5.73902e-02 # Cox and Snell (ML) 9.57020e-01 # Nagelkerke (Cragg and Uhler) -1.46624e-24 # # $Likelihood.ratio.test # Df.diff LogLik.diff Chisq p.value # -1 -55.073 110.15 9.1055e-26 # # $ Number.of.observations # # Model: 35 # Null: 35 # # $Messages # [1] "Note: For models fit with REML, these statistics are based on refitting with ML" # # $ Warnings # [1] "None" # # Warning message: # In betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, control) : # no valid starting value for precision parameter found, using 1 instead lrtest(mybetareg_random) # Likelihood ratio test # # Model 1: ProportionBirdsScavenging ~ Random_OverheadCover # Model 2: ProportionBirdsScavenging ~ 1 # #Df LogLik Df Chisq Pr(>Chisq) # 1 3 1014.69 # 2 2 959.62 -1 110.15 $ProportionBirdsScavenging ProportionBirdsScavenging*(length(df_extreme $ProportionBirdsScavenging)-1))+0.5)/length(df_extreme$ ProportionBirdsScavenging)) mybetareg_extreme |z|) # (Intercept) -0.43280 0.02689 -16.09 |z|) # (phi) 1.33763 0.02393 55.91 $Models # # Model: "betareg, ProportionBirdsScavenging ~ Extreme_OverheadCover, df_extreme, pointWeight, logit" # Null: "betareg, ProportionBirdsScavenging ~ 1, df_extreme, pointWeight, logit" # # $ Pseudo.R.squared.for.model.vs.null # Pseudo.R.squared # McFadden -5.03454e-03 # Cox and Snell (ML) 2.41241e-01 # Nagelkerke (Cragg and Uhler) -3.69602e-25 # # $Likelihood.ratio.test # Df.diff LogLik.diff Chisq p.value # -1 -4.8312 9.6625 0.0018807 # # $ Number.of.observations # # Model: 35 # Null: 35 # # $Messages # [1] "Note: For models fit with REML, these statistics are based on refitting with ML" # # $ Warnings # [1] "None" # # Warning message: # In betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, control) : # no valid starting value for precision parameter found, using 1 instead lrtest(mybetareg_extreme) # Likelihood ratio test # # Model 1: ProportionBirdsScavenging ~ Extreme_OverheadCover # Model 2: ProportionBirdsScavenging ~ 1 # #Df LogLik Df Chisq Pr(>Chisq) # 1 3 964.45 # 2 2 959.62 -1 9.6625 0.001881 ** # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # Warning message: # In betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, control) : # no valid starting value for precision parameter found, using 1 instead joint_tests(mybetareg_extreme) # model term df1 df2 F.ratio p.value # Extreme_OverheadCover 1 Inf 9.668 0.0019 As far I can get from these outcomes we have the following P-values. Realistic data summary p_value 0 nagelkerke 0 lrtest joint_tests no output Random data summary p_value 4.509897e-26 nagelkerke 9.1055e-26 lrtest joint_tests No output Extreme data summary 0.00187 p_value 1.871710e-03 nagelkerke 0.0018807 lrtest 0.001881 joint_tests 0.0019 According to these outcomes, all P-values are significant ( 1) Which test is appropriate to find the p-value for my model? Is the pseudo R2 from the summary table reliable, or should I take that from an other test as well? 2) Should I look for a P-value, or is there a better coefficient which tells me the goodness of the model? Which coefficients should I report when writing up this research? 3) What does the following warning mean? Why does it only sometimes pop up? For example, if I run my entire script first and then do the tests again without removing the objects from the environment, the warning does not pop up. Warning message: In betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, control) : no valid starting value for precision parameter found, using 1 instead 4) Why is there only an output for the joint_tests for the extreme data? Sorry for the many questions, but I am in the deep here. Can somebody shed some light on this and help me?
