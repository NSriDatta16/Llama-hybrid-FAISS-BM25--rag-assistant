[site]: crossvalidated
[post_id]: 381946
[parent_id]: 332179
[tags]: 
I would like to add one more paper relating to this issue (I cannot comment due to my low reputation at the moment). In subsection 3.1 of the paper, the authors specified that they failed to train a straight implementation of VAE that equally weighted the likelihood and the KL divergence. In their case, the KL loss was undesirably reduced to zero, although it was expected to have a small value. To overcome this, they proposed to use "KL cost annealing", which slowly increased the weight factor of the KL divergence term (blue curve) from 0 to 1. This work-around solution is also applied in Ladder VAE. Paper: Bowman, S.R., Vilnis, L., Vinyals, O., Dai, A.M., Jozefowicz, R. and Bengio, S., 2015. Generating sentences from a continuous space . arXiv preprint arXiv:1511.06349.
