[site]: crossvalidated
[post_id]: 438080
[parent_id]: 
[tags]: 
Kernel density estimate vs Dirichlet process mixture

Nowadays the Dirichlet process mixture (DPM) seems to be the default Bayesian approach for density estimation. My question is why not simply use the kernel density estimate (KDE) to model the density? One can surely use a Bayesian sampler (e.g. MCMC) to infer the bandwidth of KDE and thus make it "Bayesian". I would argue that posterior draws from Bayesian KDE are easier to check convergence than DPM. What would be the theoretical benefits of DPM over KDE?
