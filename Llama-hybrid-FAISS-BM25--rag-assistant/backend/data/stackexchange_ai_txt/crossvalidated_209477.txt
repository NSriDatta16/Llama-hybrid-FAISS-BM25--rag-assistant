[site]: crossvalidated
[post_id]: 209477
[parent_id]: 
[tags]: 
Training a RNN on time series: How to cope with different sequence origins?

I am wondering if I should apply a recurrent neural network on my data. Data is EEG from sleep, and thus there is much information hidden in the temporal domain. Ergo, RNNs make sense. Intro: I have calculated and selected a set of features from the time signal, and averaged over samples so that each input to the network will be a vector and represent a second of sleep. Concern No. 1. Data is from several hundred different subjects, and naturally each subject will have a different nature of EEG. I will normalize the data of each individual subject to have zero-mean unit-variance. In a regular feed-forward neural network, I would randomize the order of inputs to speed up the training, but I guess that is not feasible with RNN due to the memory? Concern No. 2. Due to artefacts/noise in data, I might want to throw away certain segments in time of the data. Therefore, my input will not always be sequential. It can be illustrated like 1 2 3 4 5 6 7 + + - - + + + (+ are included in training data, - are thrown away) Thus, the data at time index 5 will have the memory of time index 2 and not 4. How do I cope with this? Will it just be considered noise? I imagine I am not the first in the world to consider this issue.
