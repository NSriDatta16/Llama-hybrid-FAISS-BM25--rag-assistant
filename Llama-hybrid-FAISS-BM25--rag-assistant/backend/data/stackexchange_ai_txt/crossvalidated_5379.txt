[site]: crossvalidated
[post_id]: 5379
[parent_id]: 5360
[tags]: 
In general, there are two problems of feature selection: minimal optimal , where you seek for smallest set of variables that give you the smallest error all relevant , where you seek for all variables relevant in a problem The convergence of predictor selection is in a domain of the all relevant problem, which is hell hard and thus requires much more powerful tools than logistic regression, heavy computations and a very careful treatment. But it seems you are doing the first problem, so you shouldn't worry about this. I can generally second whuber's answer, but I disagree with the claim that you should drop resampling -- here it won't be a method to stabilize feature selection, but nevertheless it will be a simulation for estimating performance of a coupled feature selection + training, so will give you an insight in confidence of your accuracy.
