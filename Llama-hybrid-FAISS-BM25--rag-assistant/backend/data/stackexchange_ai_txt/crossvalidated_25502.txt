[site]: crossvalidated
[post_id]: 25502
[parent_id]: 23761
[tags]: 
Kevin, please be carefull since I'll have to change your notation a little bit: your $z_i$'s are not my $z_i$'s. I think the following Bayesian solution is worth a try. Cook a random parameter $\Lambda>0$ and let $Z_1,\dots,Z_n$ be conditionally i.i.d., given $\Lambda=\lambda$, with $Z_i\mid\Lambda = \lambda \sim \textrm{Poisson}(\lambda)$. Use the notation $Z=(Z_1,\dots,Z_n)$. You already have a sample $z=(z_1,\dots,z_n)$ of the $Z_i$'s, with $n=2^{28}$. Define the random variables $$\Theta_i = P\{Z_i=k\mid \Lambda\} = \frac{e^{-\Lambda}\Lambda^k }{k!} \, , $$ for $i\geq 0$ (if this is not clear, take a look ). Now, in this formulation your quadratic forms $Q_i=Q_i(\Theta_0,\dots,\Theta_i) = Q_i(\Lambda)$ are functions of $\Lambda$. So, the $Q_i$'s are random and you want to determine the posterior probability $$ P\{Q_7 R !) and computing $$ \frac{1}{N} \sum_{i=1}^N I_{(-\infty,Q_6(\lambda_i))\cap(Q_8(\lambda_i),\infty)}(Q_7(\lambda_i)) \, , $$ which converges, by the strong law of large numbers, to $(*)$ almost surely. To get a "yes" to your original question, this posterior probability must be "big enough". With such a huge sample ($n=2^{28}$), I think it is possible to play with the values of $a$ and $b$ to make your prior choice not much "informative".
