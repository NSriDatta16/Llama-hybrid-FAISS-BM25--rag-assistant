[site]: crossvalidated
[post_id]: 541604
[parent_id]: 540113
[tags]: 
If you train Bayesian neural networks using back propagation(Bayes by backprop) we cannot backpropagate through a stochastic node, then we use the reparameterization trick . For the MC dropout, any variable follow a this distribution(the 1 and 0 mask): Here are some useful materials: Hands-on Bayesian Neural Networks - a Tutorial for Deep Learning Users . Probabilistic Deep Learning: with Python, Keras and Tensorflow Probability
