[site]: crossvalidated
[post_id]: 144773
[parent_id]: 
[tags]: 
Confused about transposes in kernel notation

I am studying machine learning and I ran into a challenge that does not make sense to me. Maybe it is a crazy or a simple question. If we have kernel $ \phi_1(x)=[x, x^2]^T $ and $ \phi_2(x)=[2x, 2x^2]^T $ and if $ \phi_2$ has greater margin than $ \phi_1$, can we say it is true for $ \phi_1(x)=[x, x^2] $and $ \phi_2(x)=[2x, 2x^2]$? Can we remove the transpose signs ($^T$)? Here is a screenshot of a problem to provide some context:
