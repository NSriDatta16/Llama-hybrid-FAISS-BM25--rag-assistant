[site]: crossvalidated
[post_id]: 58845
[parent_id]: 58582
[tags]: 
There are several procedures and measures that you can caluclate to describe the so-called inter-rater agreement. One of the most famous is Cohen's kappa . You can calculate it in R with the function kappa2 from the irr package. Another measure is the intraclass-correlation . You can calculate it in R with the icc function from the irr package. Here is a good intro to concordance analysis. For a visual comparison of two raters, Bland-Altman plots are often used. The R package ResearchMethods ( link ) provides an implementation of the Bland-Altman plot (the function BlandAltman ). One way I can think of doing it would be to create a binary variable which is 1 if the ratings are concordant and 0 if the ratings are discordant between the raters. Then, you could run a logistic regression with this new binary variable as dependent variable and the demographic variables as independent variables. This might provide some insight whether the concordance depends on demographic variables. The exponentiated coefficients are the odds ratios: $OR=e^{\beta}$. An odds ratios greater than 1 means that for one unit increase in a continuous demographic variable (like age), the odds for a concordant rating increase whereas the opposite istrue for odds ratios 1, this would mean that a concordant rating is more likely for people aged 30-40 years compared to persons aged 20-30 years. Here is a nice explanation of how to interpret the output of a logistic regression. Or maybe you could run two separate multivariate regressions for each rater independently with the rating as dependent and the demographic variables as independent variables. In this way you might identify differences in the importance of the demographic variables on the ratings of each rater: For rater1, age might play an important role in building the ratings whereas in rater2 age might be unimportant.
