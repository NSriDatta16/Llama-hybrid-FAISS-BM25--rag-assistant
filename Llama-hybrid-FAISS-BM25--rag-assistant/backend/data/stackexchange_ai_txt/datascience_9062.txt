[site]: datascience
[post_id]: 9062
[parent_id]: 9060
[tags]: 
What criteria should I mainly take into account before selecting a tool for analysing big data? There are a lot of criterion which are to be taken into account when the tool selection is concerned. The can be: Structure of the data. (The data model Ex: Hierarchical, tabular, etc) Type of data and what is the problem statement. (time series, or classification, etc) Speed Security Aim : To develop a software that analyses the data coming from the wind mills and generate reports. The software should be able to predict when a wind mill can fail based on the analysis. Almost all the existing analytics tools like Python, Julia, R, etc can do this. And is it also possible that I find an algorithm for predictive analysis without knowing what would be the results of the tool after analysis. Yes. The predictive algorithm or technique can be inferred by looking at the data and the contents of the data. It is not dependant on the tool. Some points which I would like to include which I believe would be useful to you: Select the database depending on your data, and it's type. According to your data, a NoSQL database would be more relevant and suitable. Select the algorithms and techniques only after you have a clear knowledge about the problem statement and takeaways and also after clearly looking at the data for an exploratory analysis . If you want more flexibility, then use a tool/programming language like Python, R and Julia. Else, you can use a tool like Knime, Orange (it has a Python library too.), RapidMiner, etc.
