[site]: datascience
[post_id]: 9992
[parent_id]: 9991
[tags]: 
The short answer is it depends on two things: what definition of information you use and if you really use that information. From information theory point of view, if your transformation is reversible than the information is there. This happens because you can apply the inverse transformation to recover the original. So nothing is lost. This is similar with what happens in various lose-less compression algorithms. So, information is there, but is encoded in another place, specifically in the transformation function. As a consequence, to learn also the position you have to create those new features to express that information. Not also that when you have a classical learner this information is not understood by learner. Take for example a linear model. There is no difference between $f_1 = \beta_0 +\beta_1 x_1 + \beta_2 x_2$ and $f_2 = \beta_2 x_2 + \beta_0 + \beta_1 x_1$. So learning with a simple linear model is impossible to use directly this locality information. This happens with most learners. So, even in the original space the locality is an information in your head, and not in the data. On the other hand if your neural net is tailored for images and expects to receive patches of images where the order of the values is important than yes, your neural net perhaps understands those relations and use them. Even so, perhaps that custom neural net has a custom way to specify the location information, so what you will have to do would be to encode this information in a format specific to that custom neural net. On the other hand if we are talking about a standard back propagation neural net, the order is irrelevant. The model is simply not able to use the location. As a conclusion, if you have a standard generic learning algorithm your only your only chance would be to encode this locality information somehow in the features. For example (this is a made-up example, I do not even know if that would word) one can add a new set of input variable, one for each square of 4 adjacent pixels and use the average of pixels intensity as value. You do not made that explicitly enough, but you created a new set of features which is created using the locality information.
