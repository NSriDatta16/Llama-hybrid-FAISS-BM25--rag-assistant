[site]: crossvalidated
[post_id]: 199312
[parent_id]: 199298
[tags]: 
I think part of the problem is that your notation is, to put it nicely, getting in your way. The symbol $\theta$ is usually used to denote the unknown probability of a head, but here you've written $p(\theta=h)$, which I would try to parse as "the probability that $\theta=h$." But $h$ is the outcome of a trial, not the probability of a head -- more directly, the occurrence of a head in a coin toss is not a probability. So that collection of symbols doesn't really make much sense in this problem. If your prior is $p(\theta=2/3)=1$, this is a dirac mass on $2/3$, and no amount of data will shift that prior. Can you see why? There's a very good reason that people typically use a beta prior for this problem, and that is that the beta prior has support over all valid probabilities and only over valid probabilities. Restated, the beta prior allocates some probability to $\theta=1/3$ and $\theta=2/3$ and $\theta=2/\pi$ and so on across the uncountably many real numbers in $[0,1].$ This means that the posterior of the experiment also allocates probability over the unit interval, with some probability that $\theta$ takes on each value in $[0,1]$. I recommend starting with a good probability textbook first, and then reading the first few chapters of Gelman's Bayesian Data Analysis.
