[site]: crossvalidated
[post_id]: 345211
[parent_id]: 
[tags]: 
Question 4.1 in Understanding Machine Learning: From Theory To Algorithms

For any learning algorithm $A$ , probability distribution $D$ , and a loss function $L$ whose range is $[0,1]$ , show that the following 2 statements are equivalent. For every $\epsilon, \delta > 0$ there exist $m(\epsilon,\delta)$ such that $\forall m \geq m(\epsilon, \delta)$ $$\mathbb{P}_{S \sim D^m}[L_D(A(S))> \epsilon] $\lim_{m \to \infty}\mathbb{E}_{S \sim D^m}[L_D(A(S))]= 0$ where $D^m$ is distribution over samples $S$ of size $m$ and $A(S)$ is hypothesis that $A$ returns after receiving sample $S$ . I'm stuck at proving $1 \rightarrow 2$ . Pick $\epsilon, \delta > 0$ . Assume $B = \{S: L(A(S)) > 0 \}$ - collection of samples such that the learner returns a hypothesis with nonzero loss over true $D^m$ . We have $$\mathbb{E}_{S \sim D^m}[L_D(A(S))] = \sum_{S \in B} L_D(A(S))P_{S \sim D^m}(S)$$ Now, we can also define $B_{\epsilon} = \{S: L(A(S)) > \epsilon \}$ , and so we get, by (1), $$\sum_{S \in B} L_D(A(S))P_{S \sim D^m}(S) = \sum_{S \in B - B_\epsilon} L_D(A(S))P_{S \sim D^m}(S) + \sum_{S \in B_{\epsilon}} L_D(A(S))P_{S \sim D^m}(S)$$ $$ \leq \epsilon + \delta\sum_{S \in B_{\epsilon}} L_D(A(S))$$ I am not sure how to bound the sum at this point. You can probably say that $B_{\epsilon} \to \emptyset$ since $m \to \infty$ (more datapoints to learn over), but I don't see how to make this more rigorous.
