[site]: crossvalidated
[post_id]: 50594
[parent_id]: 50592
[tags]: 
Conditioned on being from class C1, the observation $(X,Y)$ is a pair of independent $N(0,1)$ random variables, while conditioned on being from class C2, the observation $(X,Y)$ consists of independent $N(1,2)$ and $N(3,2)$ random variables. How do we know this? The random variables are given to be (conditionally) independent because their covariance matrix is $I$ or $2I$ and so we know that $\text{cov}(X,Y) = I_{1,2} = 0$ in one case, and $2I_{1,2} = 0$ in the other case. As has been discussed repeatedly on this stackexchange, uncorrelated jointly normal random variables are independent random variables. So, you can write down the conditional joint pdfs $f_1(x,y)$ and $f_2(x,y)$ under the two hypotheses as bivariate normal densities of independent random variables. The Bayesian decision boundary is the set of all points $(x,y)$ for which $$0.4f_1(x,y) = 0.6f_2(x,y).$$
