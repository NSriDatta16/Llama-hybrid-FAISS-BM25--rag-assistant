[site]: crossvalidated
[post_id]: 270559
[parent_id]: 270450
[tags]: 
I think the original poster (OP) is asking why Bayesian model comparison (using Bayes factors) marginalizes across the entire parameter space , but likelihood ratio tests consider only the isolated points in the two models' parameter spaces that maximize the fit. The answer is: The two approaches measure model fit differently, and that difference comes down to the role of the prior distribution. In a likelihood ratio test, only the best parameter point is considered to be "in" the model. In a Bayesian approach, the prior distribution is inherently part of the model. In a likelihood ratio test, there is no prior distribution on parameters, and the (maximum) likelihood of the data for model $m$ is the probability of the data at whatever point in parameter space maximizes the the probability. All points in parameter space are equally available candidates for fitting the data, but only the best one is actually considered to be "in" the best fit. In a Bayesian approach, on the other hand, the prior distribution is inherently part of the model . You can't specify a model without specifying the probability distribution across the parameter space. A model with a prior that loads a lot of probability mass over parameter values that nicely fit the data is a better model than a model with a prior that loads a lot of probability mass over parameter values that don't fit the data.
