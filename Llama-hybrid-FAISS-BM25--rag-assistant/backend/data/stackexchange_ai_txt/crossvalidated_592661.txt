[site]: crossvalidated
[post_id]: 592661
[parent_id]: 592647
[tags]: 
As you stated, we have: $$ KL(q(z) || p(z|x)) = \mathbb{E}_{z \sim q} \left[ \log \frac{q(z)}{p(z,x)}\right] + \log p(x), $$ where $-\mathbb{E}_{z \sim q} \left[ \log \frac{q(z)}{p(z,x)}\right]$ is also called the ELBO. And the goal is to minimize $KL(q(z) || p(z|x))$ . And you are right, since the log evidence is constant, minimizing the RHS means maximizing the ELBO, which in turn means approximating $p(x, z)$ with $q(z)$ . But note that, although we do know the functional form of the joint $p(x, z) = p_\theta(x, z)$ , we usually don't know the value for its parameter $\theta$ . The same goes for $q(z)$ : the functional form for $q(z) = q_\phi(z)$ is usually known (because it is chosen to be simple), but the parameter $\phi$ is not known. So the task is to find the parameters $\theta$ and $\phi$ by maximizing the ELBO. E.g., think of some state space model, where you want to use variational inference to obtain the posterior of the state space $z$ given the observations $x$ . You know that the state space model is defined by some parameters $\theta$ but those are not known to you. Next, you presume some function $q_\phi(z|x)$ that should approximate $p_\theta(z|x)$ . This $q_\phi$ , too, depends on some yet unknown parameters $\phi$ that need to be inferred (otherwise there would be nothing left to do since you then already know your approximation $q$ ). Another popular example would be the VAE where the parameters of the densities $p_\theta(x|z)$ and $q_\phi(z|x)$ like e.g. mean and covariance, are given by (deep) neural networks of prescribed architecture and the parameters $\theta$ and $\phi$ are the weights of the neural networks that need to be learned.
