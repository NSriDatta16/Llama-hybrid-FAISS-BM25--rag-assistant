[site]: crossvalidated
[post_id]: 366161
[parent_id]: 366148
[tags]: 
I just figured out what I was doing wrong here. Since I standardized the data before running PCA, there were additional arguments that I needed to set as false: pca = PCA(X_train,standardize=False, demean=False, normalize=False) This changed the numbers slightly, but now the results match up, as shown below. Goes to show how important reading the documentation thoroughly is, I missed these parameters earlier! In[139]: X_train_new = pd.DataFrame(np.dot(X_train,pca.eigenvecs),index=X_train.index).add_prefix('comp_') In[140]: X_train_new.head() Out[140]: comp_0 comp_1 comp_2 comp_3 comp_4 comp_5 comp_6 300 -0.488200 -0.808226 -0.015942 -0.457189 0.157613 -0.462587 0.105420 268 0.884898 -1.017663 0.856941 -0.491083 -0.577022 0.072337 0.115896 171 1.026580 0.747384 -1.251388 0.692950 -1.599866 0.724840 0.608394 233 0.481443 -0.526664 -0.827639 -0.909763 1.215789 0.262839 0.347564 48 10.107996 -4.378685 -3.698964 0.983697 -2.521392 -0.764460 0.198071 comp_7 comp_8 comp_9 300 0.264816 0.013475 -0.026100 268 0.006735 -0.209005 -0.018908 171 0.643124 0.061879 -0.017646 233 0.020724 0.033462 -0.035804 48 -0.192125 0.378399 -0.356084 In[138]: pca.scores.head() Out[138]: comp_0 comp_1 comp_2 comp_3 comp_4 comp_5 comp_6 300 -0.488200 -0.808226 -0.015942 -0.457189 0.157613 -0.462587 0.105420 268 0.884898 -1.017663 0.856941 -0.491083 -0.577022 0.072337 0.115896 171 1.026580 0.747384 -1.251388 0.692950 -1.599866 0.724840 0.608394 233 0.481443 -0.526664 -0.827639 -0.909763 1.215789 0.262839 0.347564 48 10.107996 -4.378685 -3.698964 0.983697 -2.521392 -0.764460 0.198071 comp_7 comp_8 comp_9 300 0.264816 0.013475 -0.026100 268 0.006735 -0.209005 -0.018908 171 0.643124 0.061879 -0.017646 233 0.020724 0.033462 -0.035804 48 -0.192125 0.378399 -0.356084
