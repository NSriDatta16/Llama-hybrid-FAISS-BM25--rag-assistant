[site]: crossvalidated
[post_id]: 235723
[parent_id]: 4417
[tags]: 
Actually, there are a range of possibilities: a closed form expression is available for the posterior (example: $Y\sim \text{Bin}(n,\pi)$, prior for $\pi$: $\text{Beta}(a,b)$ and the posterior $p(\pi|Y=y)$ is a $\text{Beta}(a+y,b+n-y)$ distribution), the posterior is tractable up to the normalizing constant (example: $Y\sim \text{Bin}(n,\pi)$, prior for $\log \pi$ is $N(\mu, \sigma^2)$ and $p(\pi|Y=y) \propto p(y|\pi) p(\pi)$) the data generating process is some complicated mechanism that is so complex that we cannot write down a likelihod (or if we can it takes forever to evaluate), but we can simulate from the data generating process (e.g. some kind of process for how certain properties develop over many generations in a population). To continue the example from above, in this case we would have no closed form expression for $p(y|\pi)$, but could simulate realizations of $Y$ given a specific value of $\pi$ (let's not even talk about the case where we have no idea how the data arises...). People usually mean something like (2) when they talk about an (analytically) non-tractable posterior and something like (3) when they talk about a non-tractable likelihood. It is the third case when approximate Bayesian computation is one of the options, while in the second case MCMC methods are usually feasible (which you may argue are in some sense approximate). I am not entirely sure, which of these two the quote your provided refers to.
