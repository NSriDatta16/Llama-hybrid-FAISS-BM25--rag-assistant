[site]: crossvalidated
[post_id]: 46184
[parent_id]: 46022
[tags]: 
If you're performing a ranking task, it might make more sense to evaluate your system in terms of area under the ROC curve! Accuracy, for ranking tasks, isn't necessarily what you want to optimize your system for, in my view. More to your question, how skewed is your data? There's been quite a bit of work on dealing with skewed data in biomedical classification (because this comes up a lot, in biomedicine). My PhD advisor wrote an algorithm called cost-proportionate rejection sampling that I think will address your needs--I'm fairly certain we ended up using it with LibSVM because of the same problem! Briefly, the algorithm addresses the issue of disproportionate costs of misclassification (e.g., if one document out of 100 describes a disease of interest, you don't want to miss that document). It resamples the data according to the cost function $$P(c)=\frac{{\rm Cost}(c)}{\max[\text{Cost}(c),\ \forall_{c}\in C]}$$ In words, each sample is included according to the probability $P$ of including a sample of class $c$ is determined by the misclassification cost ${\rm Cost}(c)$ for that sample, divided by the sample misclassification cost.
