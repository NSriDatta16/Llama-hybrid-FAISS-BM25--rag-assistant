[site]: crossvalidated
[post_id]: 256620
[parent_id]: 
[tags]: 
Manually right-censoring (top-coding) data for survival modeling: justified?

Say we have survival-time data that has a long right tail. Does it make analytical/statistical sense to set a time limit and then manually right-censor (top-code) all times-to-event that exceed this limit, then use survival analysis techniques to analyze this "censored" data? The censoring I'm asking about is not due to the actual data collection process. That is, it's not due to participants dropping out prematurely nor to the study ending. It's been decided that participants who are recorded with a time-to-event that seems too long should be capped at a reasonable value and considered to be censored. (This is often called top-coding in non-time applications.) On the one hand, I could say that this is no different from a study where the study period is significantly shorter than the average time-to-event, and where all participants enter at the start of the study. There will be a whole bunch of participants right censored at the end of the study, sharing the same censoring time. And the censoring time will be highly correlated with the time the participant was in the study. On the other hand, the studies I've seen this used for were longer than the average time-to-event, and participants entered at different times. So censoring at a particular time-to-event threshold seems to be more correlated and less "random" than actual data-collection-driven (i.e. calendar-time-based) censoring. Does this make any sense? Is right censoring after the fact, based on time-to-event and not a calendar time, reasonable? If it matters, I'm thinking of parametric survival models, and thus it seems that how well right censoring is handled depends on how accurately the survival time distribution is modeled.
