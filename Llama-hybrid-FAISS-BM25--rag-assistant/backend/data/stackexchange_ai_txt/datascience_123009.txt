[site]: datascience
[post_id]: 123009
[parent_id]: 122883
[tags]: 
It's even weird that you would use the old model tag as a target. Seems like some sort of complex knowledge distillation. Imo you should start by just statistical learning on default. starting with a simple model, then iterating to deal with the different problems (Feature engineering / imbalance / calibration in probability / upgrading to xgboost / explainability / eventual interface to exaplin the choice / documentation / evaluate out of sample / evaluate the gain to upgrade the old model...). The proportion of the limit used would make a good feature for exemple.
