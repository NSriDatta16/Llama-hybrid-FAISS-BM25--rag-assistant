[site]: crossvalidated
[post_id]: 19618
[parent_id]: 17932
[tags]: 
It sounds like you might be more interested in estimating errors using the maximum-entropy bootstrap , rather than cross-validation. This will allow you to generate multiple bootstraps of you data, which you can then split into as many train/test sets as you like to calculate confidence intervals for your forecasts. Rob Hyndman has some further discussion of time series cross-validation on his blog , where he implements several different methods of "rolling" and forecasting, but it's mostly focused on implementation. I have some further implementations on my blog as well. Maybe the simplest approach would be to average your error across all of the time windows, and therefore ignore and potential correlations in errors. As far as I can tell, the theoretical state of cross-validation for time-series data is somewhat behind the theoretical state of general cross-validation. Intuitively, I expect error to increase as the horizon increases, which suggests that you should expect correlated errors across various forecast horizons. Why does this worry you?
