[site]: crossvalidated
[post_id]: 590394
[parent_id]: 21551
[tags]: 
In case if you want to see the results directly: from sklearn.metrics import classification_report, confusion_matrix classification_report(y_test, y_pred) This would work in case you want average precision, recall and f-1 score from sklearn.metrics import precision_recall_fscore_support as score precision,recall,fscore,support=score(y_test,grid_predictions,average='weighted') print ('Precision : {}'.format(precision)) print ('Recall : {}'.format(recall)) print ('F-score : {}'.format(fscore))
