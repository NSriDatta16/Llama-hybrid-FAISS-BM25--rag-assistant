[site]: crossvalidated
[post_id]: 353156
[parent_id]: 
[tags]: 
How to infer the eigenvalue distribution from matrix where each entry has a known Gaussian distribution?

Problem Given $X \in \mathbb{R}^{n \times n}$ where $X_{ij} \sim \mathcal{N}(\mu_{ij}, \sigma_{ij}^2 I)$ Find the eigenvalue distribution using whatever you can. Background In my field, I have a Bayesian inference framework that will obtain the $X$ distribution, but what we really need is the eigenvalue distribution of the matrix $X$. Question Is this problem well defined? Is the only way to infer it through sampling in such high dimensional space and then for each realization of the matrix, do the eigenvalue decomposition?
