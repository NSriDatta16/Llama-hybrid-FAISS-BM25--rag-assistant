[site]: crossvalidated
[post_id]: 621095
[parent_id]: 621004
[tags]: 
From your answers to my first answer, I think I have a better idea of your issues and will try to improve my answer: Your loss for the regression task being $L_{KLD} + L_{regression}$ doesn't make sense to me. The KLD isn't too useful in this case, it could be seen as a form of regularization, but that's it. When you say that the t-SNE of the latent space for the reconstruction task shows a single sphere with no clusters, I am not surprised. Have you looked at the reconstructed output ? Is it similar to the input and is the reconstruction loss low ? I have the intuition that most of your issues are from the reparametrization trick: When you sample $\epsilon \sim \mathcal{N}(0, 1)$ to produce the embedding $z = \mu + \epsilon \times \sigma$ , the "noise" from $\epsilon$ is most likely too strong and your model fails to reconstruct and find an appropriate representation. You could try to pick $\epsilon \sim \mathcal{N}(0, eps\_w)$ with $eps\_w \in [0, 1]$ . So you could simply try to multiply $\epsilon$ by a scalar in [0, 1] to reduce it. The closer your scalar is to 0, the closer your architecture will be to a simple dense autoencoder, with an additional KLD regularization. I don't really get why you seek to find if a VAE can handle reconstruction and regression independently , ideally you should do both together, with an architecture like this: Regarding the anomalies in the gradient, it will be hard to tell without looking at the code. Note: Finally, you should consider that your code is working just fine, and your data simply doesn't have any natural clusters. So it is normal for you to find a single sphere of data in your latent space. This is plausible as your sensor data has a very large number of features that maybe don't vary too much for clusters to form naturally. To check, simply run a t-SNE on the original data, do you see clusters there ?
