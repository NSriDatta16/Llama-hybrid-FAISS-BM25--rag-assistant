[site]: crossvalidated
[post_id]: 164101
[parent_id]: 
[tags]: 
Multiple regression - High adjusted R^2 but the residuals are high

I used the multiple regression models to derive the outcomes after using AIC pairwise comparison and deleted the outliers, high leverage points. And it seems good, the adjusted R^2 acheived 0.9543, see below: Call: lm(formula = P ~ V + EF + W + H, data = PS) Residuals: Min 1Q Median 3Q Max -22.448 -14.576 2.949 12.524 26.034 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -2.186e+03 5.209e+02 -4.196 0.000201 *** V 1.511e-01 1.033e-02 14.633 9.96e-16 *** EF 1.183e+01 3.239e+00 3.653 0.000917 *** W -1.135e+00 4.205e-01 -2.698 0.011028 * H 3.192e+01 8.482e+00 3.763 0.000678 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 15.79 on 32 degrees of freedom (13 observations deleted due to missingness) Multiple R-squared: 0.9593, Adjusted R-squared: 0.9543 F-statistic: 188.8 on 4 and 32 DF, p-value: However, when I was inspecting the residuals, they are fairly high. With the R^2 higher than 0.95. I expect the residuals should be around 5% but actually not. It's kind of weird. See below for the (actual - fitted)/actual. tidy((PS$P-fitted(fita2))/PS$P) x 1 0.01778472 2 -0.19525412 3 -0.01824948 4 -0.24418585 5 -0.06475068 6 0.65211477 7 0.58158990 8 -0.14876657 9 -0.27050744 10 0.15220738 11 0.14239352 12 0.02274694 13 0.10920921 14 0.04696290 15 -0.07793881 16 -0.32173830 17 -0.60332883 18 -1.47499192 19 -0.70576325 20 -0.04088402 21 -1.11266825 22 -1.13704286 23 -0.72987082 24 -0.50573858 25 0.38938329 26 0.57790490 27 0.21233140 28 -0.42890622 29 0.27630390 Plot of Residuals vs Fitted: Normal Q-Q plot:
