[site]: crossvalidated
[post_id]: 179866
[parent_id]: 
[tags]: 
"Continuity" of SVM as a function of hyperparameters

Suppose we have some (large enough) labeled training set and use some exhaustive cross-validation technique (e.g. leave one out) for tuning hyperparameters of SVM (with some nonlinear kernel). Is it true, that if we replace one observation by some another, the best possible hyperparameters would not change much? I use the following technique: loss_function(parameters, data) mse = 0 for i=1 to n: model = train(data[all_but_i], parameters) mse = mse + (predict(model, data[i]) - y[i])^2 return mse for which I minimize the loss_function given data as a function of parameters. Am I right treating this as LOO?
