[site]: datascience
[post_id]: 114883
[parent_id]: 114871
[tags]: 
The best way to do a comparison like this is multi-facetted. The first component is to create an appropriate experiment which means being as completely random as you possibly can and serving an equal number of enhanced and typical advertisement campaigns. Be super sure that you are being even and fair across times of day, demographics and all possible fronts to limit bias as much as possible. Ideally I would prefer to have data from before and after the sales collected in both methods as well to give you a sense of how the enhancement works in both sale and non-sale periods of time. Once you have two sets of data, you need to prepare each set of experiments as a separate time series. You can all the things one might do with time series to explore them separately. But to do a comparison you can use a granger causality test ( here in python , here in R ). This test is a test of how well one time series predicts another. It looks at how well a point in set one at a given time is predictive of a value in set two at some time in the future ( some number of lag time increments in the future). The links explain how it work pretty well and it uses an F-statistic and a p-value like many a good statistical tests. The underlying idea in using two sets of samples drawn during the same periods with just a change in one dimension implies that a change in pattern is the result of the change in campaign method. I would use a test on data prior to the sale to see that you have created an experimental sampling method that is sufficiently random. If set one is predictive of set two presale, then you know that a change during the sale which makes set one not predictive of set two should mean that you are no longer sampling from the same population (the new campaign methods is having an affect).
