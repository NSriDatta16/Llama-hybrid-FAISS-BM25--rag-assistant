[site]: crossvalidated
[post_id]: 429741
[parent_id]: 429719
[tags]: 
If you mean representing every beta-distributed random variable as some simple function of the two parameters $\alpha,\beta$ and some "standard beta" random variable, then probably it cannot be done. One alternative to the simple standard way of parameterizing this family of distributions that has crossed my mind is as follows. The expected value is $\mu=\dfrac\alpha{\alpha+\beta}.$ The variance is $\dfrac{\frac\alpha{\alpha+\beta} \cdot \frac\beta{\alpha+\beta}}{\alpha+\beta+1} = \dfrac{\mu(1-\mu)}{\alpha+\beta+1} = \dfrac{\mu(1-\mu)}\kappa$ where the last equality defines $\kappa.$ So we have \begin{align} \mu & = \alpha/(\alpha+\beta), \\ \kappa & = \alpha+\beta+1. \\[12pt] \alpha & = (\kappa-1)\mu, \\ \beta & = (\kappa-1)(1-\mu). \end{align} $\mu$ is the mean and $\kappa$ is the concentration. With $\mu$ fixed, $\kappa$ is proportional to the reciprocal of the variance. Postscript: It has occurred to me that what I said in the first paragraph above is mistaken, and I've crossed it out. One can use the beta distribution with $\alpha=\beta=1,$ which is the same as the uniform distribution on $[0,1].$ If $X$ has that distribution, then $F^{-1}(X)\sim\operatorname{Beta}(\alpha,\beta),$ where $F$ is the c.d.f. of the $\operatorname{Beta}(\alpha,\beta)$ distribution. Postpostscript: The postscript above does not represent an alternative parametrization of the family of beta distributions, since the same pair of parameters still represents the same distribution.
