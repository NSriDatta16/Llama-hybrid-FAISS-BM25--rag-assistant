[site]: crossvalidated
[post_id]: 134500
[parent_id]: 132848
[tags]: 
In a case like yours, where you have a relatively simple, but "non-standard" generative model that you'd like to estimate parameters for, my first thought would be to use a Bayesian inference program like Stan . The description you've given would translate very cleanly to a Stan model. Some example R code, using RStan (the R interface to Stan). library(rstan) model_code n; // number of observations real y[n]; real x[n]; } parameters { real mu; // I've assumed mu is to be fit. // Move this to the data section if you know the value of mu. real a; real b; } transformed parameters { real sigma[n]; for (i in 1:n) { sigma[i] You'll get output that looks something like this (although your random numbers will probably be different to mine): Inference for Stan model: model_code. 4 chains, each with iter=2000; warmup=1000; thin=1; post-warmup draws per chain=1000, total post-warmup draws=4000. mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat a 2.3 0 0.7 1.2 1.8 2.2 2.8 3.9 1091 1 b 0.9 0 0.5 0.1 0.6 0.9 1.2 1.9 1194 1 mu 0.1 0 0.6 -1.1 -0.3 0.1 0.5 1.4 1262 1 Samples were drawn using NUTS(diag_e) at Thu Jan 22 14:26:16 2015. For each parameter, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat=1). The model has converged well (Rhat=1), and the effective sample size (n_eff) is reasonably large in all cases, so on a technical level the model is well-behaved. The best estimates of $a$, $b$ and $\mu$ (in the mean column) are also fairly close to what was provided.
