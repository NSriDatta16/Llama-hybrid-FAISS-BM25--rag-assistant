[site]: crossvalidated
[post_id]: 309033
[parent_id]: 
[tags]: 
Finding the top words in a text

(I have no actual background in data science or statistics, so please easy with the math and concept names). I have a text file (lets say 40k words), and I want to find the top 10 words with the highest weight (excluding the too common "the, at, a, ..."). I figured I'll split the data to (let's say) 200 chunks, and calculate the tf-idf of each word. I did this in Python. I got a 200 x 10k matirx (200 chunks, 10k words). Each word has it's TF-IDF calculated in it's row (chunks). This allows me to calculate the top 10 words only of one chunk in comparison to the others, but I can't really calculate the total tf-idf of each word. If I just sum the columns, it doesn't help. This is the post in Stack Overflow: https://stackoverflow.com/q/46694163/7252805 (nobody answered). I'd love some help.
