[site]: crossvalidated
[post_id]: 147392
[parent_id]: 
[tags]: 
What is the honesty condition for regression trees?

I have a question pertaining to Stefan Wager's "Asymptotic Theory for Random Forests": http://arxiv.org/pdf/1405.0352v1.pdf Wager first states that trees are "fully grown in the sense given training data $(X_i, Y_i)$, a tree makes predictions of the form $T(x) = Y_{i^*(x)}$ for some index $i^*(x)$. With this notation, he goes on define condition (9) as the following: $L(Y_{i^*(x)} | X_{i^*(x)} = x) \stackrel{d}{=} L(Y_i | X_i = x)$ I am not grasping the complete idea behind this condition, and I believe it relates to my confusion over the $i^*(x)$ index notation. Could someone help me understand this condition and how it leads to the condition that we cannot use training labels both to choose splits and make predictions? This condition is found at the top of page 8 in the paper.
