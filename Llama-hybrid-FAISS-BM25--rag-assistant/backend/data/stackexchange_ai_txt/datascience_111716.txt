[site]: datascience
[post_id]: 111716
[parent_id]: 
[tags]: 
Is TF-IDF for text classification transferable between corpuses?

I am using TF-IDF for text classification and my solution works well according to the performance metric of my choice (F1 macro). To speed up the training process I have used PCA to reduce the dimensionality of the document vectors. I am using this for a growing set of datasets and the datasets keep changing. Is there a way to reuse the TF-IDF vectorizer and the PCA transformation across different datasets? (for time efficiency) My initial idea is to share the vocabulary and documents of the datasets to create a universal TF-IDF+PCA transformation, but I am worried if 1) it would harm the performance of classification on individual datasets and 2) new datasets might have terms not present in the universal vocabulary. Are there existing solutions for reusing TF-IDF/PCA across multiple corpuses? and/or an actively changing corpus?
