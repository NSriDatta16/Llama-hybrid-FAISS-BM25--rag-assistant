[site]: crossvalidated
[post_id]: 200895
[parent_id]: 
[tags]: 
How much data for deep learning?

I am learning about deep learning (specifically CNNs), and how it typically requires an awful lot of data to prevent overfitting. However, I have also been told that the higher capacity / more parameters a model has, the more data is required to prevent overfitting. Therefore, my question is: Why can you not just reduce the number of layers / nodes per layer in a deep neural network, and make it work with a smaller amount of data? Is there a fundamental "minimum number of parameters" that a neural network requires until it "kicks in"? Below a certain number of layers, neural networks do not seem to perform as well as hand-coded features.
