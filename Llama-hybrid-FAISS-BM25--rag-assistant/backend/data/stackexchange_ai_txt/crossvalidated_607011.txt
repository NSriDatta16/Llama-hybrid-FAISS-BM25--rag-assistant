[site]: crossvalidated
[post_id]: 607011
[parent_id]: 606976
[tags]: 
The Pareto is indeed conjugate to the uniform, see e.g. Aside from the exponential family, where else can conjugate priors come from? . The posterior mean looks right, see also https://en.wikipedia.org/wiki/Pareto_distribution (in Wikipedia's notation, $\alpha>1$ is guaranteed as the present $\alpha$ is positive and the sample size $n\geq1$ ). The result that the posterior mean is a weighted average of prior mean and MLE (which the sample mean is not, though, so that I am not sure why to expect that in the first place?) is restricted to certain parametrizations in exponential families (and the uniform is not a member). See e.g. Can the posterior mean always be expressed as a weighted sum of the maximum likelihood estimate and the prior mean? or How does Prior Variance Affect Discrepancy between MLE and Posterior Expectation . We have that the maximum $X_{(n)}$ is consistent for $\theta$ . This follows from, e.g., https://math.stackexchange.com/questions/2905482/expectation-and-variance-of-y-maxx-1-ldots-x-n-where-x-is-uniformly-dis (slightly adapting the argument from a uniform on $[0,1]$ to one on $[0,\theta]$ ; essentially, work with cdf $y/\theta$ on $[0,\theta]$ instead of cdf $y$ on $[0,1]$ ) and noting that $E(X_{(n)})\to\theta$ and $V(X_{(n)})\to0$ , so mean square convergence which implies consistency. Also, $(n+\alpha)/(n+\alphaâˆ’1)\to1$ the posterior mean will tend to either the true $\theta$ or, when $\beta\geq X_{(n)}$ , to $\beta$ . [One could additionally consider the variance of the Pareto posterior, which is $\mathcal{O}(n^{-2})$ .] Asymptotically, the latter only seems possible when $\beta$ is larger than the true $\theta$ in view of consistency of $X_{(n)}$ for $\theta$ . In that case, the support of the prior does not include the true parameter so that the posterior mean cannot concentrate on the true value. Here is a little plot with posteriors for different $n$ and one prior choice for $\beta$ smaller (solid) and one larger than the true upper bound of the uniform (vertical black bar). We notice how the posterior concentrates around either the sample maximum or $\beta$ . library(EnvStats) theta Quibbles : The posterior mean is only "the" Bayes estimator when you working with the squared error loss function. Also, you could omit the lower indicator in the likelihood function since you know that all $X_i$ are nonnegative. To indicate that the posterior is proportional to some kernel of a distribution, it is more common to use $\propto$ than $\approx$ .
