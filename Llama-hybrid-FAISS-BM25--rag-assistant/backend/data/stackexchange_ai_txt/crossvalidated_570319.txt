[site]: crossvalidated
[post_id]: 570319
[parent_id]: 193793
[tags]: 
Well for example if you have a 2x2 convolution, (assuming one black-and-white color channel), then you never need more than 2x2=4 kernels, because with 4 kernels, you have one kernel per pixel, so e.g. it could literally be each pixel getting its own kernel: [[1,0],[0,0]],[[0,1],[0,0]],[[0,0],[1,0]],[[0,0],[0,1]]. Indeed, so long as you don't have any kernels that are simply multiples of other kernels, you can scale and combine them to produce any 2x2 grid of pixels. So that tells that you want somewhere between 0 and x kernels, where x is the number of parameters in a kernel. You want your kernels to essentially do lossy compression - to describe the underlying data well but not perfectly. Otherwise, you're not really doing anything. And if you have 0 kernels, you literally aren't doing anything . I've seen 16 kernels for a 3x3 convolution with 3 color channels. 3x3x3=27. 16/27 is about 0.6. That sounds reasonable. More than 50% coverage, less than 100%. I'm only getting started myself, with the MINST handwritten digits, but I'm going to try 66% and 75%, and see if that gets me about 90% coverage (meaning 10% residual).
