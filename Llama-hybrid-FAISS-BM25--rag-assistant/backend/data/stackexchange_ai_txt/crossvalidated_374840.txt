[site]: crossvalidated
[post_id]: 374840
[parent_id]: 374799
[tags]: 
There is enough information in the question to clear this up. lsmeans is simply using the coefficients to obtain the group predicted probabilities. So for the GLM, OP's implied model is: \begin{equation} \hat\pi=\frac{1}{1+e^{-(-1.9684+0.2139\times d)}} \end{equation} where $d$ is an indicator for membership in group 2. So the predicted probabilities are: $(1+e^{-(-1.9684)})^{-1}$ and $(1+e^{-(-1.9684+0.2139)})^{-1}$ for groups 1 and 2 respectively. These result in predicted probabilities of about $12.25\%$ and $14.75\%$ respectively. For the multilevel model (or GLMM), OP's implied model is: \begin{equation} \hat\pi=\frac{1}{1+e^{-(-3.0571+0.3915\times d+1.881\times \hat{u})}} \end{equation} where $\hat{u}$ is the random intercept assumed to be standard normal. The predicted probabilities from lsmeans assume a random intercept value of zero $(\hat{u}=0)$ resulting in: $(1+e^{-(-3.0571)})^{-1}$ and $(1+e^{-(-3.0571+0.3915)})^{-1}$ for groups 1 and 2 respectively. These result in predicted probabilities of about $4.49\%$ and $6.50\%$ respectively. These are the lsmeans GLMM results. An issue is the intercept in GLMM is the expected log-odds of success for someone who is "average" relative to others. So using this as a basis for reporting the whole model is an issue. About the other coefficient, one suggestion for why the group difference coefficient increases is that the model quality is better so the coefficient increases, search for collapsible on this website or see Is meta-analysis of odds ratios essentially hopeless? . To make the lsmeans GLMM results comparable to the lsmeans GLM results. We have to use the observed values of the random intercept, $\hat{u}$ . One can simulate random intercepts to match OP's specific model: set.seed(12345) u_hat In this simulated example, these values are a lot closer to the lsmeans GLM results. If you run something like the syntax below on your data: lm(fitted(model) ~ 0 + df$student_type) where model is the GLMM, you should get values quite close to the lsmeans values. I'm assuming that when you call fitted() on glmer() , it also includes the random intercept and the values that are returned are probabilities. In your situation where the groups are naturally occurring, an additional thing to explore in the data is the differing group variances on the random intercept, so a model like: glmer(cbind(total_correct, total_ans-total_correct) ~ (0 + student_type || student) + student_type, family = binomial, data = sub_df, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE)) might be worth exploring since right now, you're assuming the random intercept variances do not differ by group. I used the || so lme4 does not attempt to correlate the two random intercepts. I did not know that one could add a random intercept for each student when they essentially have only one row in the data. But I am rationalizing it away by assuming that the trial vs. failures per row amount to several rows in long form.
