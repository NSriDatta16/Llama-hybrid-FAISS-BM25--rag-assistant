[site]: crossvalidated
[post_id]: 555201
[parent_id]: 
[tags]: 
Bayesian optimization resulting in overfitting despite split test train

I am using XGBRegressor on a time series to predict the next periods value. I use sklearns TimeSeriesSplit to split the data into test and train. I use skopts BayesSearchCV to search through a parameter space to give me the best parameters. Unfortunately, I notice that when I run the bayesian search, the top set of parameters it returns are obviously overfitted. For example: model = XGBRegressor(alpha=0, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, eta=0.06566805511633206, gamma=0, reg_lambda=0, max_depth=5, min_child_weight=2, subsample=1, num_boost_round=3000) Based on the XGB documentation https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html The lower the: alpha, lambda, and gamma values are, the more prone the model is to overfitting. Similarly the higher the colsample, subsample, and max_depth values are, the more prone the model is to overfitting. What I fail to understand is how the overfitted parameters are scoring better than non-overfitted parameters in the test set, and how do I avoid this overfitting? I tried reducing the size of the training set to match the size of the testing set, but this doesn't work either, resulting in this:
