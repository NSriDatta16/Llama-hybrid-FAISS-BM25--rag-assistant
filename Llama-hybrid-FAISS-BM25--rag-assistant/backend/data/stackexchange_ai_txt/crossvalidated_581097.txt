[site]: crossvalidated
[post_id]: 581097
[parent_id]: 
[tags]: 
Comparing similarity between multivariate distributions

I'm a non-mathematician trying to get a better intiution into how we can go about saying if one distribution is closer, or further away from another. For example, if we have a set of patients who each have 20 blood test results and a multiclass label of diagnoses (A, B, C and D). How would one meaningfully say one class is closer or further away from another? I imagine you can quantify this using KNN or 2-D PCA in seeing how their features (when reduced in dimension) relate to each other and have specific metrics which can provide a quantitation of similarity/difference? In a similar fashion- would a model which performs well at differentiating between different classes given the features point towards there being is greater distance between classes? Finally I've come across information theory and Kullbackâ€“Leibler divergence - presumably this is also useful in saying whether and how much one (multivariate) distribution compares with another? Pointers on how to think about this much appreciated.
