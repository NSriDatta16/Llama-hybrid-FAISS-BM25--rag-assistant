[site]: crossvalidated
[post_id]: 263380
[parent_id]: 
[tags]: 
Extracting weight importance from One-Layer feed-forward network

may question involves a simple neural network architecture (as simple as my expertise in neural networks): $n_I$ input nodes (binary, ordinal, real, integers); $n_H$ hidden nodes; $n_O$ output nodes (count data). There are no cycles/loops in the neural network, all nodes from a layer are connected to the previous and next ones. The architecture is a classical feed-forward one. My question is this: I'm trying to understand which inputs are more relevant to each output. Is it sufficient to start from the output node of interest, look at the highest hidden node weights going into it and to the same between those hidden nodes found and the inputs? (I performed a standardization of the inputs of course ) Furthermore: If so: does one follow the same process when considering deeper nets? Thank you in advance
