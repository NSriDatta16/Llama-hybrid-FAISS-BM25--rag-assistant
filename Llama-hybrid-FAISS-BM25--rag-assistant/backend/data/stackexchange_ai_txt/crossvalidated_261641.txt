[site]: crossvalidated
[post_id]: 261641
[parent_id]: 261590
[tags]: 
Strategy 2 using Markov Chains $M$ - multiplier $S$ - point change in SR $p$ - probability of winning Model 1: Let us have an infinite Markov graph with vertices $X_{\epsilon}$ - starting state $X_0$ - state after 1 loss $X_{00}$ - state after 2 losses in a row $X_i$ - state after i-th win in a row Edges have natural probabilities, e.g. we have $X_i \to^{p} X_{i+1}$ and $X_i \to^{1-p} X_0$ and so on. Now we define $\mu_v$ - expected increase in SR travelling from state $X_v$ to $X_{00}$. We want to calculate $\mu_{\epsilon}$. We have $$\mu_{00} = 0,\ \mu_0 = p(\mu_1 + S) + (1-p)(-S),\ \mu_{\epsilon} = p(\mu_1 + S) + (1-p)(\mu_0 - S)$$ $$\mu_i = p(\mu_{i+1} + S + iM) + (1-p)(\mu_0 - S),\ i \ge 1$$ Now this is an infinite system of equations. It probably can be solved by some tricky partial formula, but, we can transform it into finite system of equations with infinite sums. Model 2 Definitions are the same. We have vertices $X_{\epsilon}$ - starting state $X_0$ - state after 1 loss $X_{00}$ - state after 2 losses in a row $X_1$ - state after 1 win We define new edges from state $X_1$. $X_1 \stackrel{1 - p}\longrightarrow X_0$ with value $-S$ $X_1 \stackrel{p^i(1-p)}\longrightarrow X_0, \ i \ge 1$ with value $(\sum_{k=1}^{i}kM) + (i - 1)S$ New edges from $X_1$ represent whole paths $X_1 \to X_{11} \to \dots \to X_{1^n} \to X_0$ in the old graph with adequate value. Now we have $$\mu_{00} = 0,\ \mu_0 = p(\mu_1 + S) + (1-p)(-S),\ \mu_{\epsilon} = p(\mu_1 + S) + (1-p)(\mu_0 - S)$$ $$\mu_1 = \sum_{i \ge 1}[p^i(1-p)(\mu_0 + \sum_{k=1}^{i}kM + (i - 1)S)] - (1-p)S $$ $$\mu_1 = \mu_0 + (1-p)M\sum_{i\ge1}(p^i\frac{i(i+1)}{2}) + S(1-p)\sum_{i\ge1}(p^i(i-1)) - (1-p)S$$ $$\mu_1 = \mu_0 + \frac{Mp}{(1-p)^2} + \frac{Sp^2}{1-p} - (1-p)S$$ And after solving the above with $p = 1/2$ we obtain $$\mu_0 = 2M,\ \mu_1 = 4M,\ \mu_{\epsilon} = 3M$$ So the expected gain in SR from starting state is indeed $3M$, for any $S$. Note: It's important to notice that $\mu_o = 2M$ is twice as much as in strategy 1 and it's no mistake, we model different things.
