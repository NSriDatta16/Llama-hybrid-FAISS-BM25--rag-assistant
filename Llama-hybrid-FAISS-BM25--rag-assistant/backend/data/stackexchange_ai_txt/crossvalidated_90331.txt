[site]: crossvalidated
[post_id]: 90331
[parent_id]: 
[tags]: 
Step by step implementation of PCA in R using Lindsay Smith's tutorial

I'm working in R through an excellent PCA tutorial by Lindsay I Smith and am getting stuck in the last stage. The R script below takes us up to the stage (on p.19) where the original data is being reconstructed from the (singular in this case) Principal Component, which should yield a straight line plot along the PCA1 axis (given that the data only has 2 dimensions, the second of which is being intentionally dropped). d = data.frame(x=c(2.5,0.5,2.2,1.9,3.1,2.3,2.0,1.0,1.5,1.1), y=c(2.4,0.7,2.9,2.2,3.0,2.7,1.6,1.1,1.6,0.9)) # mean-adjusted values d$x_adj = d$x - mean(d$x) d$y_adj = d$y - mean(d$y) # calculate covariance matrix and eigenvectors/values (cm = cov(d[,1:2])) #### outputs ############# # x y # x 0.6165556 0.6154444 # y 0.6154444 0.7165556 ########################## (e = eigen(cm)) ##### outputs ############## # $values # [1] 1.2840277 0.0490834 # # $vectors # [,1] [,2] # [1,] 0.6778734 -0.7351787 # [2,] 0.7351787 0.6778734 ########################### # principal component vector slopes s1 = e$vectors[1,1] / e$vectors[2,1] # PC1 s2 = e$vectors[1,2] / e$vectors[2,2] # PC2 plot(d$x_adj, d$y_adj, asp=T, pch=16, xlab='x', ylab='y') abline(a=0, b=s1, col='red') abline(a=0, b=s2) # PCA data = rowFeatureVector (transposed eigenvectors) * RowDataAdjust (mean adjusted, also transposed) feat_vec = t(e$vectors) row_data_adj = t(d[,3:4]) final_data = data.frame(t(feat_vec %*% row_data_adj)) # ?matmult for details names(final_data) = c('x','y') #### outputs ############### # final_data # x y # 1 0.82797019 -0.17511531 # 2 -1.77758033 0.14285723 # 3 0.99219749 0.38437499 # 4 0.27421042 0.13041721 # 5 1.67580142 -0.20949846 # 6 0.91294910 0.17528244 # 7 -0.09910944 -0.34982470 # 8 -1.14457216 0.04641726 # 9 -0.43804614 0.01776463 # 10 -1.22382056 -0.16267529 ############################ # final_data[[1]] = -final_data[[1]] # for some reason the x-axis data is negative the tutorial's result plot(final_data, asp=T, xlab='PCA 1', ylab='PCA 2', pch=16) This is as far as I've got, and all OK so far. But I can't figure out how the data is obtained for the final plot - the variance attributable to PCA 1 - which Smith plots as: This is what I've tried (which ignores adding the original means): trans_data = final_data trans_data[,2] = 0 row_orig_data = t(t(feat_vec[1,]) %*% t(trans_data)) plot(row_orig_data, asp=T, pch=16) .. and got an erronous: .. because I've lost a data dimension somehow in the matrix multiplication. I'd be very grateful for an idea what's going wrong here. * Edit * I wonder if this is the right formula: row_orig_data = t(t(feat_vec) %*% t(trans_data)) plot(row_orig_data, asp=T, pch=16, cex=.5) abline(a=0, b=s1, col='red') But I'm a little confused if so because (a) I understand the rowVectorFeature needs to be reduced to the desired dimensionality (the eigenvector for PCA1), and (b) it doesn't line up with the PCA1 abline: Any views much appreciated.
