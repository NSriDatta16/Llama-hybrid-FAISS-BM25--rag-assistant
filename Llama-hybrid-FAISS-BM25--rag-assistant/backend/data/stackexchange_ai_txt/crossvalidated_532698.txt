[site]: crossvalidated
[post_id]: 532698
[parent_id]: 532623
[tags]: 
Just a minor correction: after PCA, you use the projections onto the principal components as features, not the PCs themselves. But, you'll have reduced set of features as you mentioned, say 10. You'll set up a pipeline (e.g. you can utilize the Pipeline object in scikit-learn as I understand from your notation, you're using it) with steps PCA and GaussianNaiveBayes, and use grid search for hyper-parameter optimization (HPO). This is different your proposed solution. In your second and third steps, you also introduce some leakage to the validation folds because you did PCA & data scaling beforehand. As I mentioned above, you should think all the operations you performed as a single model/pipeline and apply CV to it. This is harder to implement in code if you don't use pipelines, but it's the right thing to do. Finally, with the best HPs selected, the final model (pipeline) will be fitted on the training set. This fitted model can predict the test set as well, because the pipeline has PCA step with PCs found for the training set, and there will be no dimension mismatch issue. To reiterate, you won't fit PCA or scaling to the test set, you'll use fitted models/objects on the training set to be applied on the test set.
