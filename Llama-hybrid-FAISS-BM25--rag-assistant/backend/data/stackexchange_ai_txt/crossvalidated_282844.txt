[site]: crossvalidated
[post_id]: 282844
[parent_id]: 
[tags]: 
Add more problematic samples to classifier training set

I have a binary classifier. I can see it systematically makes errors on some types of samples that are not represented in the training set too well. Is it a good idea to get more samples of such data points, add them to the training set and retrain the model? My concern is that it will make training data differ from real distribution. Are some classifiers suite better for it than others (currently I use random forest)?
