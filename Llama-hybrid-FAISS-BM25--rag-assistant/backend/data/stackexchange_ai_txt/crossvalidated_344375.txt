[site]: crossvalidated
[post_id]: 344375
[parent_id]: 
[tags]: 
Multi-task XGBoost

Is there a way to adapt the XGBoost algorithm to the multi-task case? Say there are related output variables and for some samples, some of those outcomes are missing. Is there a way to train XGBoost so that it lets information sharing across the different tasks? Even of there is no missing data, it would still be helpful to train multiple tasks at a time as we can do in multi-layer perceptron. Is there such an algorithm in the literature?
