[site]: datascience
[post_id]: 67318
[parent_id]: 
[tags]: 
Convolution layer dimensions in deeper layers?

I am trying to understand the CNN network dimensions: layer activation shape number of weights Input (25, 64, 1) 0 Conv2D(7x7, 1, 100) (25, 64, 100) 4.900 (7x7x100) MaxPool2D (13, 32, 100) 0 Conv2D(5x5, 1, 150) (13, 32, 150) 375.000 (5x5x150x100) ... The input dimension is 25x64, then first Conv layer applies 100 convolutions - so the output dimension is 25x64x100. Max pooling reduces this to 13x32x100. Second Conv layer applies 150 convolutions. What's unclear to me is the dimension after the second Conv layer. Shouldn't it be 13x32x150x100 (instead of just 13x32x150)? How is the convolution layer applied on a 3D input? Number of weights for the first Conv layer is 7x7x100, and for the second layer it is 5x5x150 x100 , meaning that weights are saved for each of the 100 input layers from the previous conv. This also leads me to think that output dimension should be 4D.
