[site]: crossvalidated
[post_id]: 273137
[parent_id]: 272942
[tags]: 
A couple of thoughts come to mind. First, I think Laplace Smoothing -- not to be confused with Laplacian Smoothing -- might be useful. Basically, you add a small value to every cell so there are no 0's. Second, (C/D)/(A/0) is actually zero: (C/D) * (0/A). But that's probably not helpful in this case. Still, a rearrangement of your algebra/comparison might be helpful. Third, if you can't do Laplace Smoothing and you want to do multinomial logistic regression, I wonder if a Bayesian multinomial logistic regression might help: you can set priors that keep coefficients from going to infinity. You may have to explain/understand/be comfortable with Bayesian methods, and the actual prior would take some thought, but it might be workable. (For example, in a straight-up binary logistic regression, you can keep the coefficients from blowing up if complete separation takes place. I'm not sure if this is good practice or helpful, but you can do it.) Fourth, if you use a multinomial logistic regression, can you break it into two parts: the baseline (where B is never chosen) and the rest (where B is chosen? Use, say, A as your reference level for both and exclude B from the first part. The problem here is that you really can't compare A's across the two parts. So maybe it's a bad idea.
