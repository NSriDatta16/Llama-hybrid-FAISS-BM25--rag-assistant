[site]: crossvalidated
[post_id]: 169068
[parent_id]: 169040
[tags]: 
You could assume that if there is any autocorrelation at all, there will definitely be autocorrelation at lag 1. The null hypothesis to test would be that the data are white noise, and the alternative is that there is autocorrelation including $\rho(1) \neq 0$. Therefore you can estimate the correlation at lag 1 and apply the standard t-based test for correlation . In the estimation you can only use non-overlapping pairs of samples $(1,2)$, $(3,4)$, … so that sample pairs are independent under H0. If you are worried about nonnormality, use Spearman correlation and use an appropriate test for that. To avoid having to use non-overlapping pairs of samples, you could also determine the null distribution empirically by comparing the actual correlation to the distribution that arises in timeseries that are generated by resampling with replacement (testing the null hypothesis that the time series is stationary white noise). Here are concrete results based on the actual data provided in a comment, analyzed using Matlab's corr and xcov . The timeseries of 197 samples is stored in the vector x . lag-1 autocorrelation: to compute without overlap, so that the sample pairs are independent under the null hypothesis of white noise: >> [rho, pval] = corr(x(1 :2: end - 1), x(2 :2: end)) rho = -0.0262418232219902 pval = 0.797571094920343 Looking at the data we find that there are three outliers that may influence the test implemented in corr , which is designed for normally distributed data. To double check, we use the test based on the Spearman rank correlation: >> [rho, pval] = corr(x(1 :2: end - 1), x(2 :2: end), 'type', 'Spearman') rho = -0.0431684721353655 pval = 0.67298135968005 The result is very similar to that based on Pearson correlation. We therefore have no evidence that there is autocorrelation at lag 1. autocorrelation function: But maybe our assumption – that there if there is any autocorrelation at all, this will include lag 1 – is not correct. Let's look at the autocorrelation function: [r, lags] = xcov(x, 'coeff'); figure plot(lags, r, 'b.-') ylim([-0.3 1.05]) xlabel lags ylabel correlation Now it looks like the autocorrelation at lag 1 is exceptionally small. The strongest autocorrelation is -0.215 at lag 21. Of course we cannot be sure that this is not just a randomly (negative-) large value. To test whether the autocorrelation at some other lag is significantly different from zero, we simulate stationary white noise with the same distribution as the data by resampling with replacement, and estimate the probability to find an autocorrelation larger than 0.215 or smaller than -0.215 at any non-zero lag: [r, lags] = xcov(x, 'coeff'); mar = max(abs(r(lags > 0))) for i = 1 : 100000 xb = x(randi(n, n, 1)); [rb, lags] = xcov(xb, 'coeff'); marb(i) = max(abs(rb(lags > 0))); end pval = mean(marb >= mar) The result is a p-value of 0.11 – much smaller, but still not significant w.r.t. the conventional level 0.05. From the distribution of simulated maximum-absolute-nonzero-lag-correlations marb we can determine the critical value of a test at a level of 0.05 >> rc = quantile(marb, 0.95) rc = 0.233023218494253 and visualize it To conclude, according to this analysis, your data do not show a statistically significant amount of autocorrelation.
