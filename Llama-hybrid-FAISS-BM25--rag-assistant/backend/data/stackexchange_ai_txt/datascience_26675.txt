[site]: datascience
[post_id]: 26675
[parent_id]: 
[tags]: 
Text understanding and mapping

I am looking at a problem where I have two documents, both are textual documents. The first one is a long (few pages long) textual document, while the second one contains about 10 short texts, each being a one liner. The problem is to automatically understand the 1st document and "map" key ideas from here to one or more short texts in the second document. I am not being able to get a good grip on the problem as to how to proceed. I tried the following approach: first collected as much similar documents as possible which are relevant; I have obtained 136 such documents, each few pages long. Then build a document level embedding using each sentence as a document (doc2vec). Then for each short sentence in the second document, inferred an embedding based on the document model I built. Then tried to find the most similar sentences for each of these short texts from the 2nd document. However the results are not good. Only about 30% match is what I am getting and the corresponding sentences are not much related to the target sentence. I am wondering if this is the right approach or are there any other approach available which I am not aware of. Your advice would be greatly appreciated. It may be the case that my explanation above is not adequate. Please let me know and I will try to improve it. Your input would be greatly appreciated. Thanks
