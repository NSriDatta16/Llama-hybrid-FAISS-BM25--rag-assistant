[site]: crossvalidated
[post_id]: 330191
[parent_id]: 
[tags]: 
Prediction error in Neural Networks

With Random Forests, one can estimate the prediction error using out-of-bag simulations. So for every sample in the training/test-set, one can estimate the predictive uncertainty. What would be the equivalent way to measure predictions error in Neural Nets? Does the oob-error quantify epistemic (model) of aleatoric (data) uncertainty? Can MC dropout here be seen as similar to oob-error?
