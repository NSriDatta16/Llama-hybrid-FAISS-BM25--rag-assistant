[site]: crossvalidated
[post_id]: 639089
[parent_id]: 638358
[tags]: 
The variance of a sum of $n$ variables, is the sum of the terms in their covariance matrix. If this sum of the terms increases relatively faster than $n$ , which is the variance of the sum of the error terms, then the bias will be reduced. For an AR1 process with marginal variance 1, this covariance matrix is a symmetric Toeplitz matrix with terms $\rho^0,\rho^1,\rho^2, \dots , \rho^{n-1}$ . And for the variance of a sum of $n$ AR1 variables we have: $$\text{var}\left(\sum{x}\right) = \left(n+ 2 \sum_{k=1}^{n-1} \frac{n-k}{n} \rho^k \right) = 2 \frac{\rho(\rho^n-1)}{(1-\rho)^2} + n \left(1+ \frac{2\rho}{1-\rho}\right) $$ If $x$ is highly autocorrelated and we take a larger rolling window, this increases the long-run variance, potentially outweighing $\text{var}(\mu)$ , which remains constant. Would this approach yield an estimate closer to the true coefficient $k$ ? The use of an average can decrease the bias somewhat, but because the behaviour towards infinity is still $O(n)$ , we can not decrease the bias indefinitely. The estimator is not consistent (unlike what I mentioned before in the comments)
