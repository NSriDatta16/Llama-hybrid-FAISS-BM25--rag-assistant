[site]: datascience
[post_id]: 110106
[parent_id]: 109961
[tags]: 
What sort of machine learning structures would work well for this sort of problem It's hard to answer this in general, and I expect using your domain knowledge - what $f$ is / does and what it's inverse might look like - will be more valuable than broad recommendations anyone could give here. Anyway, here's a partial answer assuming you use a deep neural network (NN). inverse direction You have $f$ , and you want a NN, " $q$ " that approximates $f^{-1 }$ . Using your notation if you can sample $g$ 's, then you can get $w = f(g)$ . In training your NN, you can compute a loss between $g$ and $q(w)$ , like MSE, and that will get you a $q$ such that $q(f(g)) = g$ "Standard" NN methods should work fine here, since it's a supervised learning problem (i.e. you don't need gradients of $f$ for this). It will depend on sampling $g$ well, of course. forward direction If you can sample $w$ 's you may also want that $f(q(w)) = w$ . Do you want this also? It's this direction where $f$ not being easily differentiable will make things more difficult. There are methods for this, but they're not "standard." Have a look at " Gradient free optimization " methods.
