[site]: datascience
[post_id]: 117198
[parent_id]: 117189
[tags]: 
I find this graph helpful: The X-axis here is a model complexity. The complexity is measured by the amount of weights/decisions/parameters that the model includes. In decision trees, it can be interpreted as tree depth. In neural networks, it is comparable to the number of weights (additional cells/hidden layers/other connections that require fitting). Let's stick with the DT example and assume that we have two models: a shallow tree (e.g. depth of 2) and a deep one (e.g. depth of 50). Because the shallow tree has a small number of decision rules that it can hold, no matter how much data we train it on its result may be far away from truth. This model has high bias error because it is simply not complex enough . If we train our deep tree with just a couple of records in a train set, we may find ourselves in the same area of a high bias , which is caused by underfitting - the model contains enough parameters to train but lacks data. Overfitting happens when the model is too complex for the amount of the train data . Parameters a fitted too much, which is expressed in significant (variance) errors of unseen datasets. We could rather train less (e.g. reduce the number of epochs), reduce the amount of train data (e.g. undersample for imbalanced problems), reduce the number of parameters (e.g. prune the tree, add dropout) or add penalty constraints (e.g. L1, L2).
