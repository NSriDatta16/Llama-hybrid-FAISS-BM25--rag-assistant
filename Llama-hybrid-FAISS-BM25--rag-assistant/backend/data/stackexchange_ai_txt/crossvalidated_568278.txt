[site]: crossvalidated
[post_id]: 568278
[parent_id]: 568274
[tags]: 
I want to avoid two problems with using [the Jeffrey's prior][1] (A Bayesian perspective on estimating mean, variance, and standard-deviation from data, Travis Oliphant). With the Jeffrey's prior, one does not have a well-defined MAP unless $n>3$ . And if the sum of squared deviances is 0, one's MAP estimate of $\sigma$ will also be 0. Why would avoiding those two problems be a problem? Do you have $n\leq 3$ or the sum of residuals equal to zero? These two situations are theoretical cases in which case statistics are not of much use anyway. Suppose I want to perform Bayesian estimation of the mean $\mu$ and standard deviation $\sigma$ of a Gaussian distribution. Is there a standard way to specify an informative prior over $\sigma$ ... You ask for a standard way to specify an informative prior but there is not a single standard. However, there are several standards. One example would be to use the conjugate prior , which makes computations easy. In this case, estimating the mean and variance, this would be the normal inverse gama distribution .
