[site]: crossvalidated
[post_id]: 603307
[parent_id]: 
[tags]: 
Propensity score non parametric estimation

In several papers, in the 'double machine learning' literature, the propensity score (a nuisance parameter) is estimated non parametrically. It is a bit unclear how this estimation is performed, as most often, only the properties of the nuisance estimation method are needed. Are there R packages that estimate propensity scores, or in general logistic regression function $T=f(X)+\epsilon$ , $T \in \left\{0,1\right\}$ non parametrically, in order to embody the non parametric methods mentioned in papers (Kernel Regression, Neural Nets, Regression Trees, LASSO (for high dimensional data)) to estimate the nuisance parameter? Edit : In the double machine learning literature, we often use non parametric methods to estimate the propensity score. I will focus on Chernozhukov et al. (2018) as a main example. The authors mention several methods to estimate the nuisance parameters in pages 22-23. (lasso,random forests, sparse neural nets, deep neural nets). I wanted to ask about how this estimation is happening, what are its parameters? what are its outputs? Let us suppose that I want to estimate the propensity score, in a partially linear model. For example :1) LASSO : What is the model used ? In the parametric case, one can consider a binary GLM with an $l_1$ penalty and fit it. 2) Random Forest : One wants to estimate the functional relation between the binary treatment $T$ and the covariates $X$ . (Suppose that the propensity model is $T=e(X)+v$ , where $\mathbb{E}[V|X]=0$ .) What is the random forest doing ? What loss is being used ? I asked whether some codes are available in order to see how this estimation is performed and to know what are the 'parameters' in these non parametric methods.
