[site]: crossvalidated
[post_id]: 185150
[parent_id]: 185133
[tags]: 
Yes. One simple, though not necessarily the most effective, way is to view it as $n$ regular univariate regression problems. In general, this is sometimes called multitask regression . There are many ways to share knowledge among the tasks. For example, Solnon, Arlot, and Bach, JMLR 2012 (which I've only skimmed) use kernel ridge regression with an estimated covariance structure on the dimensions of the output task. If you have sufficient data, it's particularly easy to phrase these problems as a neural network; just have multiple outputs at the end of your architecture, and use e.g. $L_2$ loss.
