[site]: crossvalidated
[post_id]: 238970
[parent_id]: 238931
[tags]: 
This depends what you want to use the validation result for: if you want to validate (measure performance) the SVM trained on the first 1k cases (and then want to use that model for prediction), do not subsample. However, as you then have 29k cases left out of training, use them for testing instead of doing k-fold cross validation. if you want to tune hyperparameters, best cover the variation of sets of 1000 cases out of your 30000 cases and subsample repeatedly. And if you are anyways going to subsample, why not repeat set (or hold-out) validation? In that case, do not forget to reserve independent test data for validation of the tuned model (e.g. an outer k-fold CV in which you nest the repeated set val). Also remember that your hyperparameters may be sensitive to the number of training cases .
