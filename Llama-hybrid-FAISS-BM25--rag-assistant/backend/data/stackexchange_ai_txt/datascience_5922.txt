[site]: datascience
[post_id]: 5922
[parent_id]: 5921
[tags]: 
What you are describing makes sense and relates to the naive Bayesian classifier. A useful tool in that respect is mutual information (MI) (and all its derivatives). MI was first proposed for feature selection by Battiti . MI is based on marginal and joint density estimations so you will need some pdf estimators for your continuous variables, like histograms, or kernel-based density estimators.
