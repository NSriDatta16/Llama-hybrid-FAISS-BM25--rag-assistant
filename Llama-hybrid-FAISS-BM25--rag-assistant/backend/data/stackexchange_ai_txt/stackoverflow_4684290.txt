[site]: stackoverflow
[post_id]: 4684290
[parent_id]: 
[tags]: 
When timing how long a quick process runs, how many runs should be used?

Lets say I am going to run process X and see how long it takes. I am going to save into a database a date I ran this process, and the time it took. I want to know what to put into the DB. Process X almost always runs under 1500ms, so this is a short process. It usually runs between 500 and 1500ms, quite a range (3x difference). My question is, how many "runs" should be saved into the DB as a single run? Every run saved into the DB as its own row? 5 Runs, averaged, then save that time? 10 Runs averaged? 20 Runs, remove anything more than 2 std deviations away, and save everything inside that range? Does anyone have any good info backing them up on this?
