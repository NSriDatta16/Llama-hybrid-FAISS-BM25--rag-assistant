[site]: crossvalidated
[post_id]: 24201
[parent_id]: 23860
[tags]: 
Let's focus on the business problem, develop a strategy to address it, and begin implementing that strategy in a simple way. Later, it can be improved if the effort warrants it. The business problem is to maximize profits, of course. That is done here by balancing the costs of refilling machines against the costs of lost sales. In its current formulation, the costs of refilling the machines are fixed: 20 can be refilled each day. The cost of lost sales therefore depends on the frequency with which machines are empty. A conceptual statistical model for this problem can be obtained by devising some way to estimate the costs for each of the machines, based on previous data. The expected cost of not servicing a machine today approximately equals the chance it has run out times the rate at which it is used. For example, if a machine has a 25% chance of being empty today and on average sells 4 bottles per day, its expected cost equals 25% * 4 = 1 bottle in lost sales. (Translate that into dollars as you will, not forgetting that one lost sale incurs intangible costs: people see an empty machine, they learn not to rely on it, etc. You can even adjust this cost according to a machine's location; having some obscure machines run empty for a while might incur few intangible costs.) It's fair to assume that refilling a machine will immediately reset that expected loss to zero--it should be rare that a machine will get emptied every day (don't you wish...). As time goes by, the expected loss starts to rise until eventually it reaches a limiting value equal to the expected daily sales: an example is shown in the second figure below. A simple statistical model along these lines proposes that fluctuations in a machine's use appear random. This suggests a Poisson model . Specifically, we may posit that a machine has an underlying daily sales rate of $\theta$ bottles and that the number sold during a period of duration $x$ days has a Poisson distribution with parameter $\theta x$. (Other models can be formulated to handle the possibility of clusters of sales; this one supposes that sales are individual, intermittent, and independent of each other.) In the present example, the observed durations are $x=(7, 7, 7, 13, 11, 9, 8, 7, 8, 10)$ and the corresponding sales were $y=(4, 14, 4, 16, 16, 12, 7, 16, 24, 48)$. Maximizing the likelihood gives $\hat{\theta} = 1.8506$: this machine has been selling about two bottles per day. The data history is not long enough to suggest that any more complicated model is needed; this is an adequate description of what has been observed so far. The red dots show the sequence of sales; the blue dots are estimates based on the maximum likelihood estimate of the typical sales rate. Armed with an estimated sales rate, we can go on to compute the chance that a machine may be empty after $t$ days: it is given by the complementary cumulative distribution function (CCDF) of the Poisson distribution, as evaluated at the machine's capacity (presumed to be 50 in the next figure and the examples below). Multiplying by the estimated sales rate gives a plot of the expected daily loss in sales versus time since last refill: Naturally this curve is rising fastest near the time at $50/1.85 = 27$ days when the machine is most likely to run out. What it adds to our understanding is to show that an appreciable rise actually begins a week earlier than that. Other machines with other rates will have steeper or shallower rises: that will be useful information. Given a chart like this for each machine (of which it seems there are a couple hundred), you can easily identify the 20 machines currently experiencing the greatest expected loss: servicing them is the optimal business decision. (Note that each machine will have its own estimated rate and will be at its own point along its curve, depending on when it was last serviced.) Nobody actually has to look at these charts: identifying the machines to service on this basis is easily automated with a simple program or even with a spreadsheet. This is just the beginning. Over time, additional data may suggest modifications to this simple model: you might account for weekends and holidays or other anticipated influences on sales; there may be a weekly cycle or other seasonal cycles; there may be long-term trends to include in the forecasts. You might want to track outlying values representing unexpected one-time runs on the machines and incorporate this possibility in the loss estimates, etc. I doubt, though, that it will be necessary to worry much about serial correlation of sales: it's hard to think of any mechanism to cause such a thing. Oh, yes: how does one obtain the ML estimate? I used a numerical optimizer, but in general you will get very close simply by dividing total sales over a recent period by the length of the period. For these data that's 163 bottles sold from 12/9/2011 through 2/27/2012, a period of 87 days: $\hat{\theta} = 1.87$ bottles per day. Close enough to $1.8506$, and extremely simple to implement, so anyone can start these calculations right away. (R and Excel, among others, will readily compute the Poisson CCDF: model the calculations after 1-POISSON(50, Theta * A2, TRUE) for Excel ( A2 is a cell containing the time since last refill and Theta is the estimated daily sales rate) and 1 - ppois(50, lambda = (x * theta)) for R.) The fancier models (which incorporate trends, cycles, etc) will need to use Poisson regression for their estimates. NB For the aficionados: I am purposely avoiding any discussion of uncertainties in the estimated losses. Handling these can significantly complicate the calculations. I suspect that directly using these uncertainties would not add appreciable value to the decision. However, being aware of the uncertainties and their sizes could be useful; that might be depicted by means of error bands in the second figure. In closing, I just want to re-emphasize the nature of that figure: it plots numbers that have a direct and clear business meaning; namely, expected losses; it does not plot more abstract things such as confidence intervals around $\theta$, which may be of interest to the statistician but will just be so much noise to decision maker.
