[site]: crossvalidated
[post_id]: 606526
[parent_id]: 606447
[tags]: 
The problem with information leakage is that for proper assessment of prediction quality in the test sample it is assumed that the information from the observations in the test sample is not used to construct the predictor by which they are predicted. In reality we have new observations to predict that cannot be used to construct the classifier, and the use of test and training sample should mimic that situation. Intuitively, the plain number of observations isn't really information that can help to predict the test observation better (whereas if they are used for missing values imputation or standardisation, not only their number is used but also their actual value). (Note: I only realised later that the question in fact is about using the class information for stratification, see the last paragraph for this.) If one wanted to show this mathematically, chances are it would be necessary to restrict oneself to specific models and prediction methods. In particular, I suspect that examples can be constructed in which the sample size per class is random and potentially informative (and used as such by the classifier). Showing how the test error/loss relates to the expected prediction error/loss is hard enough in standard situations, but I can well imagine that non-influence of stratification rules such as balancing can be shown in some simple standard situations. Even without that, in most (though not necessarily all) situations I'd rely on the intuition that sample size isn't informative to classify the individual observations. Note by the way that sample splitting/stratification in fact will have an influence on the characteristics of the prediction loss estimation (which is why people pay attention to this), but this is regardless of the values taken by the actual observations . If I think about it, it may be hard, even in a simple situation, to set up a theorem that proves that "there is no information leakage by stratification", because it may be hard to figure out what such a theorem should say in the first place. After having seen the change in the question title, I should also add that "stratification by target" uses the class information of the observations for splitting. Intuitively this may well still be harmless because it isn't informative about how the class relates to the other variables, which is what the classifier should assess. However chances are it is even harder to prove any positive result (that this does not do harm) in any situation.
