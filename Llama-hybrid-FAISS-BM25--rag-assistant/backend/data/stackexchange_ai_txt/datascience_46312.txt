[site]: datascience
[post_id]: 46312
[parent_id]: 
[tags]: 
What is the vector value of [CLS] [SEP] tokens in BERT

In BERT, They replace separator and start of sentence with special token labels. What are there corresponding values in embedding_matrix. Are they 0-vector? I wanted to replace the proper nouns like names, buildings, locations with similar approach. How should i go about masking the same?
