[site]: datascience
[post_id]: 97525
[parent_id]: 
[tags]: 
logistic regression or density estimation for binary dependent variable and binary (or categorical) features

I have a binary dependent variable $t$ and categorical features. We can even simplify to binary features since I can one-hot encode the categorical variables. In practice the one-hot encoding induces collinearity in the binary features so for simplicity let's pretend we only have $D$ binary features . The purpose is to estimate the probability of $t=1$ . In principle, I can use logistic regression. But, given the categorical nature of the input data they actually define a table of $2^D$ cells. So I could instead just estimate the proportion of $t=1$ samples in each cell (for example using maximum likelihood estimation). I think this should be similar to the logistic regression in that both approaches assume a binomial likelihood function. However the logistic regression assumes that the log odds are a linear function of the input variable (which is not assumed under the density estimation procedure). I think this assumption is not critical here given the binary nature of the inputs. So the question is, Are the two approaches different? If yes, in what aspect are they different? One difference would be of course that the estimation method for logistic regression is iterative so in some cases there might be convergence issues. One would be tempted to say that as $D$ increases many cells in the table will be (near to) empty. But I think logistic regression would suffer as well in those cases. As additional questions (connected to the first one): Is there anything wrong in my line of thought? Which of the two approaches should perform better?
