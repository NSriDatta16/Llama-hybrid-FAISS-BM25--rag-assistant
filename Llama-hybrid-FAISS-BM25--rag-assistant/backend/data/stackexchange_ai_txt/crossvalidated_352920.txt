[site]: crossvalidated
[post_id]: 352920
[parent_id]: 352858
[tags]: 
For me it makes sense using clustering as a method of feature engineering. Assuming your intuition on the relation between predictors clusters and target variable is correct, helping models finding possibly complicated relations between predictors(by using a clustering algorithm) is a solid step. In practice I would use the clustering results as features(cluster number- categorical) for the boosting algorithm. Your second question - "is it a good idea training a different model for each cluster". I cant think of a yes/no answer for this, but when I face these situations I try deciding based on the amount of shared relevant(to the problem) information between clusters. If I believe this shared information is far less than the noise shared I would consider separating models training. Another way tackling this issue is by using hierarchical models .
