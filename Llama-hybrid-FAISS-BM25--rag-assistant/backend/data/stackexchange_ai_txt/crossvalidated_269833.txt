[site]: crossvalidated
[post_id]: 269833
[parent_id]: 269298
[tags]: 
I think the answer to the question depends a lot on how you define "better." If I'm interpreting right, you want to know why it is that these norms appear so frequently as compared to other options. In this case, the answer is simplicity. The intuition behind regularization is that I have some vector, and I would like that vector to be "small" in some sense. How do you describe a vector's size? Well, you have choices: Do you count how many elements it has $(L_0)$? Do you add up all the elements $(L_1)$? Do you measure how "long" the "arrow" is $(L_2)$? Do you use the size of the biggest element $(L_\infty)$? You could employ alternative norms like $L_3$, but they don't have friendly, physical interpretations like the ones above. Within this list, the $L_2$ norm happens to have nice, closed-form analytic solutions for things like least squares problems. Before you had unlimited computing power, one wouldn't be able to make much headway otherwise. I would speculate that the "length of the arrow" visual is also more appealing to people than other measures of size. Even though the norm you choose for regularization impacts on the types of residuals you get with an optimal solution, I don't think most people are a) aware of that, or b) consider it deeply when formulating their problem. At this point, I expect most people keep using $L_2$ because it's "what everyone does." An analogy would be the exponential function, $e^x$ - this shows up literally everywhere in physics, economics, stats, machine learning, or any other mathematically-driven field. I wondered forever why everything in life seemed to be described by exponentials, until I realized that we humans just don't have that many tricks up our sleeve. Exponentials have very handy properties for doing algebra and calculus, and so they end up being the #1 go-to function in any mathematician's toolbox when trying to model something in the real world. It may be that things like decoherence time are "better" described by a high-order polynomial, but those are relatively harder to do algebra with, and at the end of the day what matters is that your company is making money - the exponential is simpler and good enough. Otherwise, the choice of norm has very subjective effects, and it is up to you as the person stating the problem to define what you prefer in an optimal solution. Do you care more that all of the components in your solution vector be similar in magnitude, or that the size of the biggest component be as small as possible? That choice will depend on the specific problem you're solving.
