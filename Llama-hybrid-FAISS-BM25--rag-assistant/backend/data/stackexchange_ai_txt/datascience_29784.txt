[site]: datascience
[post_id]: 29784
[parent_id]: 29775
[tags]: 
Spell checking is not really in the realm of train-and-predict models in data science. Mainly because embeddings require known words in the case of word2vec/GloVe, known contexts in the case of doc2vec or known stems in the case of Fasttext plus a significantly large training dataset. Spell checking is instead more traditional software engineering. It's broad but fortunately, you can start small and increase it bit by bit. If words are commonly known i.e. common nouns and pronouns you can use a package similar to autocorrect in Python but if you are looking for a specific list of words, in your case ports which are proper nouns, you must use a real spell check procedure. Since it's a broad topic you should start by following the answer provided by Stack Overflow about Peter Norvig's post and start building from there according to your needs.
