[site]: crossvalidated
[post_id]: 340643
[parent_id]: 
[tags]: 
Expected value of policy for an average reward MDP

We have that the average reward under a policy $\pi$ is defined as: $r(\pi) \doteq \lim_{t\rightarrow \infty} \mathbb{E}[R_t\mid A_{0:t-1}\sim\pi]$ With corresponding average reward return $G_t$ $G_t \doteq R_{t+1} - r(\pi) + R_{t+2} - r(\pi) + R_{t+3} - r(\pi) + \ldots$ and value function $v_\pi(s) \doteq \mathbb{E}[G_t\mid S_t=s]$. Does this mean that the value, under expectation of the different starting states $s_0\in \mathbb{S}_0$, is 0? I.e. $\sum_{\mathbb{S}_0} v(s_0) = 0$
