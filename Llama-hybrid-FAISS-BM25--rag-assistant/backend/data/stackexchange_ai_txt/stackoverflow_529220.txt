[site]: stackoverflow
[post_id]: 529220
[parent_id]: 450835
[tags]: 
I am not 100% sure this would work, at least not without trying. But it seems as if it should be possible, although technically challenging, to write a server-side HTML/CSS scrambler that takes as its input a normal html page + associated files, and outputs a more or less blank html page, along with an obfuscated javascript file that is capable of reconstructing the page. The javascript couldn't just print out straightforward DOM nodes, of course... but it could spit out a complex set of overlapping, absolute-positioned divs and paragraphs, each containing one letter, so it comes out perfectly readable. Bots won't be able to read it unless they have employ a complete rendering engine and enough AI to reconstruct what a human would be seeing. Then, because it's an automated process, you can re-scramble the site as often as you have the computational power for - every minute, or every ten minutes, or every hour, or even every page load. Granted, writing such an obfuscater would be difficult, and probably not worth it. But it's a thought.
