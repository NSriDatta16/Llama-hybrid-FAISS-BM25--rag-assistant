[site]: crossvalidated
[post_id]: 503790
[parent_id]: 
[tags]: 
Is there a way to increase the number of predictor in a logistic regression when sample size is small?

One of the dependent variables in my dataset is a binomial variable indicating whether an invasive species has been eradicated (with $n_{1}$ = 23) or not (with $n_{0}$ = 75) after the use of a certain control method. In order to highlight which factors affect the species eradication with this method, I would like to build a set of a priori logistic regression models with various combinations of explanatory variables for which I have biologically relevant hypotheses, and to select the "best" model(s) on the basis of something like an AIC (cf. Burnham & Anderson, 2002). From what I understood from this post and this one , with such a low frequency of success (i.e. number of 1 in my variable), I should not build models including more than 1 or 2 explanatory variables to avoid overfitting. I don't want to fit that many predictors at once, but having models with at least 3-4 explanatory variables seem to me mandatory to properly grasp the phenomenon I'm studying. My question is thus: is there a way to reasonably increase the number of parameters to be estimated in my models without affecting inferences and/or goodness of fit too badly? I wondered if perhaps approaches such as bootstraps, lasso or ridge-regression were not meant for this? Any alternative, suggestion, documentation and constructive criticism is welcome. I asked another quite related question here .
