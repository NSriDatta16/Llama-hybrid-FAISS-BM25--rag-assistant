[site]: crossvalidated
[post_id]: 498722
[parent_id]: 120362
[tags]: 
Suppose we have 20 null hypotheses, all of which happen to be true. Consider two cases: If 20 scientists each independently pick and test one of the null hypotheses at p=0.05, on average they will correctly accept 19 of the hypotheses and incorrectly reject 1. If a single scientist does one big study testing all 20 null hypotheses at p=0.05 each without the Bonferroni correction or another multiplicity correction, on average they will correctly accept 19 of the hypotheses and incorrectly reject 1. Then the scientists in case 1 are each Bonferroni correction-compliant, but the scientist in case 2 is not. Why should the second case be considered any different from the first? I suspect that studies testing many hypotheses are more likely to speculatively include hypotheses for which the relevant data happens to be available, e.g. "I know how strongly each person in my sample agrees with each of 20 opinions, guess I might as well check for correlation between every possible pair of opinions". So the average prior plausibility of the alternative hypotheses would be smaller. Ideally this would be handled by choosing a custom significance level to test each hypothesis at based on this prior plausibility. The Bonferroni correction could be seen as a step towards this.
