[site]: crossvalidated
[post_id]: 365469
[parent_id]: 365464
[tags]: 
Short answer: ROC won't help you . A robust approach is to apply k-fold cross validation and count how many times training set accuracy is better than test set accuracy. If training set "beats" test set in the majority of folds, then your model is most likely overfitting. Instead of majority voting, you can alternatively compare the average accuracy in all training sets to the average accuracy in all test sets. Long answer: For a more detailed answer see here .
