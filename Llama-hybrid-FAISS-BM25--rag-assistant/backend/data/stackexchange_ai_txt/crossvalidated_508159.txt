[site]: crossvalidated
[post_id]: 508159
[parent_id]: 508156
[tags]: 
First off, modify your algorithms so they don't output hard 0-1 classifications, but probabilistic classifications. Whether someone has a 99% chance of having a disease is a very different situation than if he has only a 51% chance. And even if he has a 20% chance, you probably want to do something, like run additional tests. I recommend this earlier thread . You can then assess your two probabilistic classifiers using proper scoring-rules . You may find that one is already so bad it should not be considered further. If both classifiers work reasonably well, you can combine their probabilistic classifications, e.g., by simply taking the average of their two predicted probabilities. This will again give you a probabilistic classifier, and you can again assess its classifications using proper scoring rules, and/or use (cost-driven!) cutoff thresholds to make decisions on further action. Combining models and classifications usually improves performance. You may be tempted to find "optimal" weights. This may or may not work ( Claeskens et al., 2016 ), so if you do so, make sure you compare the "optimally combined" classifier against a simple equally-weighted one.
