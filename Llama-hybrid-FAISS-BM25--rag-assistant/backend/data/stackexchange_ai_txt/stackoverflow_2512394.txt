[site]: stackoverflow
[post_id]: 2512394
[parent_id]: 2504539
[tags]: 
I got the following idea after reading chapter 6 from http://nlp.stanford.edu/IR-book/information-retrieval-book.html public class WHN implements Comparable { private HierarchNode node; private float weight; public HierarchNode getNode() {return node;} public float getWeight() {return weight;} public WHN(HierarchNode node, float weight) {this.node = node;this.weight = weight;} public int compareTo(WHN o) {return Float.compare(this.weight, o.weight); } } Map > map = new HashMap > for (HierarchNode n : cluster){ for (Map.Entry tw : n.tags.entrySet()){ Tag tag = tw.getKey(); Float weight = tw.getValue(); if (!map.ContainsKey(tag)){ map.put(tag,new ArrayList (); } map.get(tag).add(new WHN(n,weight)); } for(List l: map.values()){ Collections.Sort(l); } } Then for each node: you could limit the search to the union of the elements with the N highest weights for each tag (called champion lists) or you could keep a temporal dot product for each node and update the dot product for each tag, but only looping throught the nodes with weight higher than some fraction of the original node weight (you can find the start using Collection.binarySearch) I suggest you read the rest of the book, as it may contain a better algorithm.
