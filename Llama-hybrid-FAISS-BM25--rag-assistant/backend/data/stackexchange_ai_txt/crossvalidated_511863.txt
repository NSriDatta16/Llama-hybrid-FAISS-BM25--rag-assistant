[site]: crossvalidated
[post_id]: 511863
[parent_id]: 
[tags]: 
Would I get optimistic results if I use random forest twice on my training set?

I have a data with 209k instances with 32 features and 3 unbalanced target labels (0,1,2). I am planning to apply Random Forest classifier since I also want to have insights about importance of the features on prediction of my model. I want to have model that only contains meaningful features. I am planning to split my data into test and training sets (also includes validation set). Would I get over-optimistic model if I apply Random Forest with all the features on my validation set first, then reapply another Random Forest with only meaningful features by using importance scores of the first RF and use that model (if overachieve the former one) as the final model and find its generalization error on the test set ? And why ? How many times can I use the validation set ? How could cross-validation can serve me in that instance? It feels like everything I do in order to increase performance metrics on validation set would end up my model with overfit on the training set. Thank you
