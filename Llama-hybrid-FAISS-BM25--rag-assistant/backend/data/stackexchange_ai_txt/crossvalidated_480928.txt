[site]: crossvalidated
[post_id]: 480928
[parent_id]: 319170
[tags]: 
My guess is that "spacial aggregation" refers to a convolution operation. If you think about it, when you convolve a filter over an image (or a volume, in general), you multiply it with the underlying patches of the image and then sum the results. For instance, if the size of the filter is 3x3, you are de facto "spatially aggregating" the information contained in a 3x3 patch of the image. As far as dimensionality reduction is concerned, I too think they mean a reduction of the number of feature maps (or channels, depending on how you want to call them). Ultimately, I believe they're claiming that performing a 1x1 convolution to reduce the dimensionality before a 3x3 convolution does not impair the quality of the output feature maps. Notice that the presence of a spatial aggregation operator (i.e. the 3x3 convolution) is needed for this statement to be true, as mentioned by the authors of the paper: [...] the strong correlation between adjacent unit results in much less loss of information during dimension reduction, if the outputs are used in a spatial aggregation context .
