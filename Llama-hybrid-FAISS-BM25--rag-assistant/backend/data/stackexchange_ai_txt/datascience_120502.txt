[site]: datascience
[post_id]: 120502
[parent_id]: 
[tags]: 
Reinforcement learning with Q-learning doesn't seem to be learning

I'm learning reinforcement learning with Q-learning and I made a training script for Flappy Bird. The problem is that it doesn't seem to be learning and I'm not sure why. My guess is that there's something wrong in the Q-learning part where the model is trained, since it's something I didn't fully understand yet. I also tried a few other environments from Gymnasium but none of them trained, so I'm missing something fundamental about it. Can someone point out what I'm doing wrong? I've been reading about how Q-learning is hard to get it right and I'm more and more insecure about this method. Code: import gc import os import random from collections import deque from keras import backend as k import flappy_bird_gymnasium import gymnasium import numpy as np from keras import Sequential from keras.callbacks import Callback from keras.initializers.initializers_v1 import HeUniform from keras.layers import Dense from keras.losses import Huber from keras.optimizers import Adam from keras.saving.legacy.save import load_model def create_model(): learning_rate = 0.001 init = HeUniform() model = Sequential() model.add(Dense(24, input_dim=12, activation='relu', kernel_initializer=init)) model.add(Dense(12, activation='relu', kernel_initializer=init)) model.add(Dense(2, activation='linear', kernel_initializer=init)) model.compile(loss=Huber(), optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy']) return model def choose_action(model, epsilon, state, training_mode): if np.random.rand() 0 and up_pipe_position i: max_scores[i] += 1 break print(f'Best scores: {max_scores}') # Update target model if steps_to_update_target_model >= 100: target_model.set_weights(model.get_weights()) steps_to_update_target_model = 0 break env.close() This code is heavily based on this minDQN project and it uses this Flappy Bird environment and it's running on Windows 11 with Python 3.10. Thank you in advance!
