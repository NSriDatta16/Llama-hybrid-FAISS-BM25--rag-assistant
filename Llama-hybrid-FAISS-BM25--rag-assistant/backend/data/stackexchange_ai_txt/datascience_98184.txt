[site]: datascience
[post_id]: 98184
[parent_id]: 98164
[tags]: 
Well sure it's doable: the NLP part is just speech recognition + extracting the formal command from the text, it's very similar to "virtual assistants" like Apple Siri, Amazon Alexa, Ok Google. However the hard part is to formalize all the possible commands that can be given, and then train a model to correctly map voice commands to software instructions. I'm not convinced that it's very useful, because giving detailed instructions like "move object to position x=3.45678, y=-9.8765, z=1.2345" is not as intuitive as using a mouse to move the object. There's a fallacy in imagining that language commands are easier than learning to use a software or programming language: it works for very simple tasks, but as soon as one needs a bit of precision general language is too ambiguous.
