[site]: crossvalidated
[post_id]: 627493
[parent_id]: 
[tags]: 
Does increasing number of observations lead to the decreasing of Mean Square Error of consistent estimators?

I know that not all weakly consistent estimators exhibit MSE-consistency : https://stats.stackexchange.com/a/610835/397467 . Anyway, does increasing the sample size leads to a reduction in their mean squared error ? Specifically, I am trying to find a formal mathematical argument to explain why models such as Logistic Regression (that are based on maximizing likelihood) gives better estimation of their coefficients when we train them on a large dataset. Maximum Likelihood Estimators are known to be consistent but I haven't found properties on their MSE.
