[site]: crossvalidated
[post_id]: 30691
[parent_id]: 
[tags]: 
How to interpret OOB and confusion matrix for random forest?

I got a an R script from someone to run a random forest model. I modified and run it with some employee data. We are trying to predict voluntary separations. Here is some additional info: this is a classification model were 0 = employee stayed, 1= employee terminated, we are currently only looking at a dozen predictor variables, the data is "unbalanced" in that the term'd records make up about 7% of the total record set. I run the model with various mtry and ntree selections but settled on the below. The OOB is 6.8% which I think is good but the confusion matrix seems to tell a different story for predicting terms since the error rate is quite high at 92.79% Am I right in assuming that I can't rely on and use this model because the high error rate for predicting terms? or is there something also I can do to use RF and get a smaller error rate for predicting terms? FOREST_model print(FOREST_model) Call: randomForest(formula = theFormula, data = trainset, mtry = 3, ntree = 500, importance = TRUE, do.trace = 100) Type of random forest: classification Number of trees: 500 No. of variables tried at each split: 3 OOB estimate of error rate: 6.8% Confusion matrix: 0 1 class.error 0 5476 16 0.002913328 1 386 30 0.927884615 > nrow(trainset) [1] 5908
