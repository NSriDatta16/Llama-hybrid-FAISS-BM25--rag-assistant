[site]: crossvalidated
[post_id]: 80302
[parent_id]: 80275
[tags]: 
The use of a LASSO penalty term as Dadong Zhang suggests (+1) is a good place to start, I investigated this approach, but integrated the regularisation parameter out analytically using a reference prior, which worked fairly well for the datasets I investigated, the paper was published here: G. C. Cawley and N. L. C. Talbot, Gene selection in cancer classification using sparse logistic regression with Bayesian regularisation, Bioinformatics, volume 22, number 19, pages 2348-2355, October 2006. ( www ) MATLAB software here . The extension to multinomial classification was published here: G. C. Cawley, N. L. C. Talbot and M. Girolami, Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation, In Advances in Neural Information Processing Systems 19, B. Schölkopf, J. C. Platt and T. Hoffmann (eds), MIT Press, Cambridge MA USA, 2007. Software here . While this approach is unlikely to be the best for every microarray dataset, it would make a good baseline method for comparison with others as there are no hyper-parameters to tune, and so is fully automatic. Whatever you do, make sure you read this paper first: Christophe Ambroise and Geoffrey J. McLachlan, "Selection bias in gene extraction on the basis of microarray gene-expression data", PNAS, vol. 99, no. 10, pp. 6562–6566, 2002. ( www ) As a lot of research on this topic has been misguided due to incorrect performance evaluation.
