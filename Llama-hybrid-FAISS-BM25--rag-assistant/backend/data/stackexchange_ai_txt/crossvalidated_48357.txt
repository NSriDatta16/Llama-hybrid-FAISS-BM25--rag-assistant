[site]: crossvalidated
[post_id]: 48357
[parent_id]: 
[tags]: 
Treating non-stationarity of time series in seasonal adjusted data with R

I'm currently trying to use a variable x (and others) to explain a dependent variable y in a distributed lag model (with the long term goal of predicting variable y). The plot of variable x shows an evident seasonality at the end of the year: See https://i.stack.imgur.com/PbrJ5.png After having deseasonalized the data with decompose (with multiplicative components), adf and kpss tests indicate, that the seasonal adjusted data is still not stationary. Because there are more independent variables and I don't want to look deeper into investigation a cointegration relationship between those series, I thought it would be the most usual way to take the difference of both series (with the diff() function). Now there are 2 alternatives: Take the diff of the already seasonal adjusted data. The problem with this approach is, that I'm not sure if this a good idea because I don't see how you can reseasonalize the time series for a forecast result in an easy manner. Take the diff of the raw series. This leads to the following graph. See https://i.stack.imgur.com/OXhhd.png The time series is now stationary regarding adf and kpss tests, however there is still the seasonal pattern visible. Now I'm not sure if it is recommended to use decompose (with the multiplicative) method, to deseasonalize the diff of the time series, especially because there are zero values which have no effect when calculating the seasonal adjusted time series in the following way: decompose(x_diff, "mult")$x / decompose(x_diff, "mult")$season So, how should I proceed when I want to include (the diff of) x as a independent (and lagged) variable in a distributed lag model?
