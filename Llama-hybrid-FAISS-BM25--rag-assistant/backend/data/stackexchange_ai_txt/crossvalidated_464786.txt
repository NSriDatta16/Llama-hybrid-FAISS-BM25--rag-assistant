[site]: crossvalidated
[post_id]: 464786
[parent_id]: 464782
[tags]: 
All KPIs in classification can be important. (See the Wikipedia article on sensitivity and specificity for the entire zoo of common KPIs.) Which one is more important depends on the costs of correct and wrong classifications . Sometimes false positives are more costly than false negatives, or vice versa, and the relationships between these costs (and those of correct classifications) drive what we are most interested in. I have been arguing at great length that these KPIs, which try to optimize the statistical/machine learning aspect of the pipeline through a focus on the decision , which is a different part of the pipeline than the stats/ML one, is fundamentally misguided. Instead, we should be aiming for calibrated and sharp probabilistic classifications and assess these using proper scoring rules. Then , and only then, can we discuss what the optimal decision to take is when faced with a particular probabilistic classification - a discussion that should include the costs of correct and wrong decisions, of course. See my answer noted above as well as my answer to Why is accuracy not the best measure for assessing classification models? - note that every single criticism that is leveled there against accuracy applies equally to sensitivity, specificity and the other KPIs (AUROC is a slightly different case).
