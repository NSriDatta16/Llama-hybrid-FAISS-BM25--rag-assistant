[site]: crossvalidated
[post_id]: 570116
[parent_id]: 
[tags]: 
Is the mean posterior fit the same as the fit of the mean parameters?

Say we are fitting a parametric model $y(x, \theta)$ to some data (e.g. logistic regression). Given a prior distribution over the model parameters $\theta$ and observed data $x$ , we arrive at a posterior distribution for each of the parameters as well as predictive posterior distribution at any new point. Now suppose that at a given input point, we wish to calculate the mean model prediction. We have two options: We can sample the predictive posterior distribution at the point and find it's mean We can take the model value defined by the mean posterior values of the parameters Are these two options guaranteed to give the same results? I suspect not, and if that's the case, which is more correct to use? For example, in a logistic regression scenario, we have a model for $p$ : $$p = (1 + \exp(a+bx))^{-1}$$ Once we have a posterior, and some sample point $x_0$ we could simply take use the logistic model given at the mean parameters $\bar a$ and $\bar b$ (option 1), or find the mean posterior of $p$ at point $x_0$ (option 2). Since the mean isn't invariant to re-parameterization, I can imagine these two numbers being different, though intuitively these both seem to legitimate approaches to answering the same question.
