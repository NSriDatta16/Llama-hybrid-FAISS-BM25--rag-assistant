[site]: crossvalidated
[post_id]: 628680
[parent_id]: 628596
[tags]: 
The mean is a fraction The mean value consists of a fraction of the sum of individual observations. When expressed as a decimal, a fraction of the sum of individual observations can maintain the same units as individual observations without reflecting their real world constraint (indivisibility). $ (1 \text{ apple}+2 \text{ apples}) \div 2= \frac{1 \text{ apple}+2 \text{ apples}}{2} = \frac{3 \text{ apples}}{2} = 1.5 \text{ apples} $ Constraining the mean A real world constraint can be imposed according to which the solution must be a whole number, $\mathbb W$ (or whole numbers). The constrained solution can then be obtained from the dataset mean, $\bar x$ . $ f(\bar x)= \begin{cases} \bar x&\text{if }\, \bar x \in \mathbb W\\ a \text{ or } b&\text{if }\, \bar x \text{ is a decimal}\\ \end{cases} $ where $a=floor(\bar x)$ , $b=ceil(\bar x)$ If $\bar x$ is a decimal, the constrained answer becomes: "On average, people have $a$ or $b$ children". Individual observations in the dataset may or may not correspond to $a$ or $b$ . Constraining predictions from the mean In a different context, assuming $\bar x=1.136 \text{ children/woman}$ , you could simulate drawing groups of $10 \text{ women}$ from a Poisson distribution with $Î»=1.136$ . You could derive a prediction for the $\text{# of children}$ corresponding to $\text{10 women}$ drawn from the distribution directly from $\bar x$ . $ \text{prediction}_{\text{mean}} = \frac{1.136 \text{ children}}{\require{cancel} \cancel{\text{woman}}} \cdot 10 \require{cancel} \cancel{\text{women}} = 11.36 \text{ children} $ Your prediction will never be correct, because women produce whole children (not children fractions). As before, you can add a real world constraint (prediction or predictions must be $\mathbb W$ ) to make your prediction relevant. $ \text{relevant prediction}= \begin{cases} \text{prediction}_{\text{mean}}&\text{if }\, \text{prediction}_{\text{mean}} \in \mathbb W\\ A \text{ or } B&\text{if }\, \text{prediction}_{\text{mean}} \text{ is a decimal}\\ \end{cases} $ where $A=floor(\text{prediction}_{\text{mean}})$ , $B=ceil(\text{prediction}_{\text{mean}})$ Assuming a 50 points reward if the prediction is correct, and a points penalty corresponding to the absolute value of the difference if the prediction is incorrect, trends of cumulative points can be obtained over 250 simulation iterations.
