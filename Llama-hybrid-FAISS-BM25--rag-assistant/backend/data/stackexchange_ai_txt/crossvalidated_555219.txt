[site]: crossvalidated
[post_id]: 555219
[parent_id]: 429059
[tags]: 
The 2019 answer is basically correct but, considering the amount that's been published or become available on arXiv in the past two years, a more specific answer seems appropriate. My understanding is best practice is currently to check convergence of Sᵢ and Sᴛᵢ as a function of the Soboľ sample size N and the estimator used while estimating confidence intervals for Sᵢ and Sᴛᵢ from bootstrap sampling. In my experience, differences between estimators can be substantial and negative Soboľ indices may indicate bias or other structural issues within an estimator even if N appears sufficient for convergence. It's also my experience first order Sᵢ confidence intervals often aren't disjoint from Sᴛᵢ confidence intervals. With such overlaps, having one more central values of Sᵢ > Sᴛᵢ is expected whenever k (the number of model parameters) and the overlaps are large enough it becomes plausible such a sample occurs. This is, however, likely to be sensitive to the particular questions one's asking of the models one's working with. Documentation for Soboľ analysis packages should, I think, contain guidance in this direction. In a quick look at the SAFE toolbox mentioned in the question, though, I'm only seeing confidence intervals and not convergence. Additionally, a few of the sensitivity analysis researchers active at the moment are Arnald Puy , Andrea Saltelli , and Bertrand Iooss . It may be helpful to check their publications and citations for further developments. For example, quasirandom numbers may be a preferred default over Latin hypercube sampling.
