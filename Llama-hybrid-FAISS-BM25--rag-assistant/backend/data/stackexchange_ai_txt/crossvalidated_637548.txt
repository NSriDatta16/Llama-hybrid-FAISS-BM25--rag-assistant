[site]: crossvalidated
[post_id]: 637548
[parent_id]: 637447
[tags]: 
However, after replacing "not a number" (NaN) values with 0 and standardizing the data, the performance significantly improved: While I consider the project successful as it is, I'm curious if there are other "low-hanging fruits" that I should explore to further reduce the error. One thing that you could try is replace all NaN values with a number $x$ (different from zero) and and optimize by searching which $x$ makes your model perform better. (In a neural network this would be equivalent to an extra layer that performs a transformation of the data) ... that was an ironic answer. But, it shows the problem with the approach. The improvement that you made is not neccesarily a low hanging fruit and could have been simply overfitting. So, important in your considerations about more low-hanging fruits is that you try not to fall into the trap of data dredging . "Everything should be made as simple as possible, but not simpler"? we can consider that quote in reverse "Everything should be made as complex as possible, but not complexer"? You are trying to make something less simple. But is your current model too simple? For this you can consider hypothesis testing or information criteria . What exactly happened with your model is difficult to say . For example answering the question "Did the NN work better than linear regression?" is difficult to answer/discuss because you didn't compare both with the same conditions. One interesting aspect is what the NaN values mean and how they influence the model. This is difficult to assess with the information given. One potential explanation can be that the NaN values exclude a large part of the data to be taken into consideration, which reduces the information available to fit the model. Performing imputation by replacing the NaN values with zeros is a bit arbitrary, but it may have helped you because the advantage of adding data, albeit being of low quality, may improve the model.
