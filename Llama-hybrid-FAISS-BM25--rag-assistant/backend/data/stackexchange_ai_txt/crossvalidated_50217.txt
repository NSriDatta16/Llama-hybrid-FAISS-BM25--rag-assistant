[site]: crossvalidated
[post_id]: 50217
[parent_id]: 50213
[tags]: 
You aren't strictly taking the "mean" of the likelihood, because the Likelihood function isn't a probability distribution over x. It isn't even a probability distribution anyway, but assuming you have a likelihood function that you can normalize into a PDF then it would be the probability of $Y$ not of $X$. This is a likelihood weighted average of $X$. I think you have come across an ad hoc Bayes estimate here. If we note that $P(X|Y) = \frac{P(Y|X)P(X)}{P(Y)} \propto L(Y|X) P(X)$ Then by simply normalising the likelihood into a PDF you are creating the Posterior distribution using uniform priors for $X$. This may or may not be a sensible thing to do. By then integrating out this distribution you are taking the expected value of $X$ under the posterior distribution of $X$. This is therefore the posterior mean estimator, also the Minimum Mean Square Estimator (MMSE).
