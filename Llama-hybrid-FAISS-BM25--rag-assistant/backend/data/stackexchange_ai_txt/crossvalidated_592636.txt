[site]: crossvalidated
[post_id]: 592636
[parent_id]: 99988
[tags]: 
The other day, I came across a situational constraint where bootstrap analysis would not work on my presumed normally distributed sample. I was at the park with my four-year old daughter who started gathering acorns like they were treasures. Her hands were quickly full, so I gestured that it would be okay to deposit the acorns in my pocket. Well she turned my pants into a sumo suit, and we ended up going home with about 300 acorns. When we got home, I starting wondering what we could learn about the population of fallen acorns from the sample. I weighed the whole sample on a kitchen scale which came out to be about 1150g. Then I started thinking about what this sample might be able to say about the tree's population of acorns. The first thing that came to mind was doing a bootstrap analysis. However, the equipment I have on hand has an accuracy of 1g. I couldn't just weigh one acorn at a time, since an acorn weighing in at 4g might actually weigh 3g, 4g or 5g. In order to reduce the amount of scale error. I figured the per-acorn scale accuracy would only be off by a tiny amount if I weighed each sample group together. But this group weighing constraint means it was not possible to introduce sampling with replacement, since I could only weigh the acorns as a group. Apart from investing in a better scale it seemed the best option might be weighing 20 random acorns say 25 times. Then using the average of these sample means to approximate a population mean and make some inferences. Sampling without replacement seems like the only option under these conditions.
