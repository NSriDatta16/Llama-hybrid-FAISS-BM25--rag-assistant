[site]: datascience
[post_id]: 104902
[parent_id]: 
[tags]: 
Is binary classification the right choice in this case?

I am somewhat new to text classification and I have some questions if you folks can help: I have some text I need to be able to classify as belonging to a single class or not (usually 1-10 sentences long each). For the examples of the class, I have around 500 examples, but the non-class case can really be any text at all of which I have hundreds of documents with tens of thousands of sentences (which are not the class). What I have to do is be able to classify each of the sentences in each document as belonging to the class or not. The vast majority won't belong. I'm using a BERT based Binary Classifier (simpletransformer) to identify the text similar to (or exactly) the 500 class examples, does this seem reasonable/possible? How should I deal with the class imbalance of 500 to 10000's? I tried oversampling the minority class (my target), but it seems to overfit when I do that. What is the usual way of handling this particular use case? The 1-class anomaly detection doesn't seem to fit here, from what I can tell. Is there a similar NLP style training that works for this case? Or something else? Would it make sense to just do a semantic similarity comparison of some sort? That is, just take the class examples, and for each sentence in a document, test to see how similar it is to each class example and if the text is "close enough" to any of the class examples, then it's a "hit"? this would seem slow... Is there a standard/good library for semantic comparison?
