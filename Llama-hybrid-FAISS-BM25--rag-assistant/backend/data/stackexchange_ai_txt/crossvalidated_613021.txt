[site]: crossvalidated
[post_id]: 613021
[parent_id]: 613009
[tags]: 
While not many details are provided, here is a quick take for the three questions posed: No single algorithm is ever guarantee to outperform another, if that was the case we would invalidate the whole " No free lunch theorem " notion. That said, it appears that the data generating process (DGP) here is of polynomial form so unsurprisingly Group method of data handling (GMDH) is competitive as it is in some sense a polynomial neural network. In this case, we can increase mtry the number of variables randomly sampled as candidates at each split and more competitive results. Especially given that only 2 out of 5 variables are relevant and in many cases our candidate tree might contain only irrelevant variables that increased number of variables examined can be very helpful. Again there is not universal answer here but as mentioned in point 1, if we have a good understanding for the DGP, a method that seems to align with that DGP is a good first choice.
