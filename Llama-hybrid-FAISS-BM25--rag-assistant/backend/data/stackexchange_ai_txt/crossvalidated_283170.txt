[site]: crossvalidated
[post_id]: 283170
[parent_id]: 
[tags]: 
When is unbalanced data really a problem in Machine Learning?

We already had multiple questions about unbalanced data when using logistic regression , SVM , decision trees , bagging and a number of other similar questions, what makes it a very popular topic! Unfortunately, each of the questions seems to be algorithm-specific and I didn't find any general guidelines for dealing with unbalanced data. Quoting one of the answers by Marc Claesen , dealing with unbalanced data (...) heavily depends on the learning method. Most general purpose approaches have one (or several) ways to deal with this. But when exactly should we worry about unbalanced data? Which algorithms are mostly affected by it and which are able to deal with it? Which algorithms would need us to balance the data? I am aware that discussing each of the algorithms would be impossible on a Q&A site like this. I am rather looking for general guidelines on when it could be a problem.
