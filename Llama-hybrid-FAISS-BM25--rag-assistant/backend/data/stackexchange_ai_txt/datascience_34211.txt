[site]: datascience
[post_id]: 34211
[parent_id]: 
[tags]: 
Why is this Random Forest perfect?

I'm learning Random Forest Classifier from a video, where the instructor got a score of 0.44, while I'm getting 0.9985 ( But actually it's perfect). Did I overfit it? If so what is the next step? Shouldn't it 'forget' and 'relearn' every time I compile the code again? Please check the code below: import pandas as pd from sklearn.ensemble import RandomForestClassifier bird = pd.read_csv('image_attribute_labels.txt', sep= '\s+', header=None, error_bad_lines=False , warn_bad_lines = False, usecols= [0,1,2], names =['imgid', 'attid', 'present']) bird2 = bird.pivot(index = 'imgid', columns= 'attid', values ='present') imglbl = pd.read_csv('image_class_labels.txt', sep=' ', header=None, names= ['imgid', 'label']) imglbl =imglbl.set_index('imgid') #merging the two arrays df= bird2.join(imglbl) #Shuffling the array df= df.sample(frac=1) df_att = df.iloc[:,:312] df_lbl = df.iloc[:,312:] #choosing the train and test data df_train_att = df_att[:8000] df_train_lbl = df_lbl [:8000] df_test_att = df_att[8000:] df_test_lbl = df_lbl[8000:] df_train_lbl = df_train_lbl['label'] df_test_lbl = df_test_lbl ['label'] clf= RandomForestClassifier(max_features=50 , random_state= 0, n_estimators= 100) clf = clf.fit( df_train_att, df_train_lbl) print(df_train_lbl.head()) print(clf.predict(df_train_att.head())) score = clf.score (df_train_att, df_train_lbl) print (score) The output for three times was as follow: 1: imgid #] 4499 78 #| 7442 127 #| 3200 56 #| The actual data 7271 125 #| 2601 46 #] Name: label, dtype: int64 [ 78 127 56 125 46] # The predicted ones 0.99875 # The score 2: imgid 10982 187 11632 198 1536 28 5449 94 8503 145 Name: label, dtype: int64 [187 198 28 94 145] 0.9985 3: imgid 6782 116 10906 186 2465 43 6660 114 9257 158 Name: label, dtype: int64 [116 186 43 114 158] 0.9985
