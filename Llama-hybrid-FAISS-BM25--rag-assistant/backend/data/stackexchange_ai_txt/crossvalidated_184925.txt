[site]: crossvalidated
[post_id]: 184925
[parent_id]: 182734
[tags]: 
I wouldn't say there is any big philosophical difference between NN and DNN (in fact I would say DNN is just a marketing term to distinguish from 'failed' NN) . What has changed is the size of the data sets. Essentially neural networks are currently the best $O(n)$ statistical estimators, working well for high dimensional large datasets (e.g. imagenet). I think you should step back and see that this has created a resurgence in shallow AI -- e.g. bag of words for sentiment analysis and other language applications and visual bag of words was leading approach to image recognition before DNN. No one is saying bag of words is a true model of language, but it is an effective engineering solution. So I would say DNN are a better 'visual bag of words' -- see e.g. Szegedy et al. 2013 Intriguing properties of neural networks and Nguyen et al. Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images where it is clear that there is no higher order structures etc. being learned (or whatever is claimed for DNN).
