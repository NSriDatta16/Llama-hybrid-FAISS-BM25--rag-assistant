[site]: datascience
[post_id]: 124354
[parent_id]: 
[tags]: 
Align Vectors are Easy to Learn?

I have three vectors $x,y_1,y_2\in\mathbb{R}^{n\times 1}$ , where $x=y_1$ , $x\perp y_2$ . If I use $x$ as input of a 2-layer perceptron, will regressing $y_1$ be easier than $y_2$ (i.e., when fully trained, $\mathcal{L}_{(x,y_1)} )? If this is false, how about changing the perceptron to a 2-layer graph neural network (GNN)? I am expecting some rigorous math analysis, but I seem can not figure it out.
