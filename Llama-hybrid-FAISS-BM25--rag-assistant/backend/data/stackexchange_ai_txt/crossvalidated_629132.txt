[site]: crossvalidated
[post_id]: 629132
[parent_id]: 629066
[tags]: 
Another option I have used with some success is to do a permutation test on a test statistic that measures the degree of overlap between the truth and your ranking. One good measure is Average Overlap at Depth d: It’s defined by calculating the overlap size so far at each depth d and then taking the average of those. AO at d can handle non-conjoint lists and weights high-rank overlap more heavily than low-rank. In your example, AO at depth 4 is 0.917 on a $[0,1]$ scale. That is the second-highest overlap value in the set of all 24 possible permutations. You can treat that as an exact p-value of 0.083, so it is reasonably strong evidence against the null of random. In contrast, had your ranking been $ $ -- swapping the top two from the ground truth -- the p-value would be 0.2917. I would be curious to get some feedback on the merits of this approach. I don’t quite understand why the choice of distance function makes such a big difference compared to the two approaches. A good reference for AO at d, as well as other related measures, is: William Webber, Alistair Moffat, and Justin Zobel. 2010. A similarity measure for indefinite rankings. ACM Trans. Inf. Syst. 28, 4, Article 20 (November 2010), 38 pages. https://doi.org/10.1145/1852102.1852106
