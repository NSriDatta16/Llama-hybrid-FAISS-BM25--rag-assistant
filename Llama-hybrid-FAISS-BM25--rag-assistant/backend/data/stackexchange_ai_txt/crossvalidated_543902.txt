[site]: crossvalidated
[post_id]: 543902
[parent_id]: 543898
[tags]: 
I'd probably go for the Brier score (the mean squared error on the labels) rather than the cross-entropy loss as the cross-entropy loss is likely to be dominated by very confident miss-classifications, which are likely to be far from the decision boundary (so some proper scoring rules are better than others - you want one that gives relatively more attention to the region near the decision boundary). The validation set is usually rather small, so the accuracy is likely to be brittle (unreliable) and minimising the Brier score is likely to give better accuracy on the test set (rather than the validation set). If the validation set is large enough, then selecting based on the accuracy is likely to be better, IF accuracy is the most important metric for the needs of your application. I've found this approach is very effective for tuning the hyper-parameters of kernel learning methods ( www , pdf )
