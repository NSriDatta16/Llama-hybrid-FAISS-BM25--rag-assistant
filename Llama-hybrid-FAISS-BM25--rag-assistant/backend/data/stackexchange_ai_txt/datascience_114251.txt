[site]: datascience
[post_id]: 114251
[parent_id]: 113905
[tags]: 
I would agree with Brian's answer in the following sense: All the steps you perform ie embedding, clustering, retraining,.. do not represent, in principle, qualitatively different math operations than what a dedicated deep model with non-linearities can do. So, in this sense, I do not expect to get radically different performance than using a single NN model trained end-to-end. That being said, whatever approach one uses (as I expect them to be equivalent) one will possibly have to deal with class imbalance wisely.
