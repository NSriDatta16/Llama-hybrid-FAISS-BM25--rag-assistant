[site]: datascience
[post_id]: 32627
[parent_id]: 
[tags]: 
Python: Detect if data of a time series stays constant, increases or decreases

i need to analyse and later try to improve (integrate a filter) for measurement data that i compare to accurate reference data with python. First i want to calculate the mean offset and the standard deviation of the measurement data overall, during halt, increasing and decreasing state. How can i automatically detect and mark sections in which the reference system data stays constant, increases or decreases and use this information later for the statistical analysis. I already tried to write a simple algorithm myself but the problem is though the reference data is given precise enough so you can calculate the difference of two neighbouring data points and it is zero if no change takes place this case is also in the majority during sections of change (increase, decrease). So the algorithm can't really mark the state of the data points reliable. I already researched a little bit and here are some keywords that seemed interesting for my problem: time series analysis, anomaly detection, novelty detection, change point detection, structural changes, One-Class Support Vector Machines So my question would be if sb. could give me a pointer towards the right direction (correct method, python package, tutorial, example) so i can solve this problem myself.
