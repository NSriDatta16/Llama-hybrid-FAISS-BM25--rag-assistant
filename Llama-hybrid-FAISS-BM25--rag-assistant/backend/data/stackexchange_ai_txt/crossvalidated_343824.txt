[site]: crossvalidated
[post_id]: 343824
[parent_id]: 
[tags]: 
Bayesian modeling: likelihood function for continuous random variables, why is it not always 0?

For continuous random variables, evaluating p(x) for a specific value of x is always 0 as show here , here and here . So when we're calculating the likelihood for a random variable X that is represented by a continuous distribution we have: $$ P( \mid X) = P(x_1, x_2 ..., x_n \mid ) = \prod\limits_{i=1}^n = p(x_i \mid ) $$ There are two ways I consider thinking about. 1) The first is the intuitive definition of likelihood, e.g. how probable is a set of n draws for random variable X. Intuitively the likelihood seems like it calculates the probability of n draws occuring which, for any continuous random variable would be zero. This does not make much sense to me. 2) If we consider a gaussian distribution of Âµ = 0 and = 1 then p(0) = 0.4. This number doesn't represent anything concrete, but when used in the likelihood calculation, can serve as a relative reference for which model parameters fit our data better. In this scenario, likelihood is a bit of a misnomer as it isn't actually the probability of getting our observed data, but is a number that only draws meaning in reference to other likelihood calculations. This answer makes some really good points about interpreting a density function as density and not probability, which suggests that likelihood is indeed a bit of a misnomer. It's also somewhat confusing that the likelihood is expressed in terms of p(x), which I read as probability of x occurring.
