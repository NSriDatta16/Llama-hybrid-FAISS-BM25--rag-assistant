[site]: datascience
[post_id]: 101816
[parent_id]: 
[tags]: 
Deep Q-learning

I am working on the DDQN algorithm which is given in the following paper . I am facing a problem with the Q value. The author calculate Q value by this Q(s, a; θ , α, β) = V(s; θ , β) + A(s, a; θ , α). Q value is divided into two parts: the state–action value and action-advantage value. The action-advantage value is independent of state and environment noise, which is a relative action–value in each state relative to other unselected actions. Anyone can help me to understand state–action value and action-advantage value. Any help will be appreciated.
