[site]: crossvalidated
[post_id]: 510948
[parent_id]: 
[tags]: 
Testing for Cointegration with Dummy Variable (for outlier) in Cointegrating Equation

I have two time series $y_t, x_t$ which are both $I(1)$ . I am following the 2-step Engle-Granger approach for testing cointegration between the two series. However, for known reasons, I also want to include a dummy variable for additive type outlier (AO) for known time point in the long-term equation to get the residuals: \begin{equation} y_t = \beta_0 + \beta_1 x_t + \beta_2D_t + \mu_t \tag{1} \end{equation} I understand that in the usual case of no dummy I need to test for stationarity of $\hat \mu_t$ (residuals estimated using OLS) using the ADF test with critical values adjusted for estimated errors, as reported in Engle and Yoo (1987) table 3 for $N=2$ . But I am unsure whether I can continue to use these critical values in my case because of presence of a dummy variable. I saw this answer which addresses the issue of a regime shift in the long term equation. I also skimmed through this very relevant paper but it follows the VAR model with reduced rank regression method for testing cointegration rather than the two-step procedure (and for some specific reason I need to use the 2-step process instead). My question is whether it will be right to use the critical values from the Engle-Yoo table for N=2 or do I need to do simulations to derive critical values (and if yes, how)?
