[site]: datascience
[post_id]: 121333
[parent_id]: 121290
[tags]: 
This is a reasonable approach, it's basically the traditional use of cross-validation in order to better leverage the entire dataset for both training and testing rather than relying on a single train-test split. The distribution of the performance metrics across the test folds is useful itself, but is often summarized as the mean value. You may be best off explicitly stratifying the folds in order to make sure the models are comparable and learning from similar populations.
