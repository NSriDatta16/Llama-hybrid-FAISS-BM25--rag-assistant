[site]: crossvalidated
[post_id]: 262140
[parent_id]: 262129
[tags]: 
Power analysis is something you do when designing a study, not after you have collected the data. Your data seem amenable to a simple linear model (ANOVA) comparing the groups, as the standard deviations seem very similar among the groups. With large differences in numbers of cases the standard errors and confidence intervals will differ dramatically among groups, but the mean values are nevertheless comparable among groups. You just need to take the number of cases into account when you compare among groups. A proper linear model will share information about the residual errors among the groups more usefully than depending on SDs of individual groups, as you seem to be doing. Testing any pre-defined hypotheses about inter-group differences, or against a pre-defined threshold, would then be straightforward, and you can do general post-hoc tests of differences among groups, although the large differences in cases among groups might make some approaches to post-hoc analyses challenging. Even though you do not have the underlying raw data, the data in your table contain all that you need to do these analyses. The squared standard deviations about each of the mean values provide estimates of the residual sums of squares that can be pooled to provide an overall mean-square residual estimate. Overall ANOVA compares the variance among group means against the residual error. Comparisons among particular means then use that mean-square residual and the number of cases in each group in the equivalent of t-tests (with appropriate correction for multiple comparisons if you are not examining pre-defined hypotheses). This is pretty much how ANOVA was done with hand calculators in the "good old days" before computers and canned programs. You will, however, be limited in your ability to perform tests for outliers and leverage without the individual data points. You also might consider the way that you defined the 10 groups. You might consider re-defining the groups in a way that combines some of the lower-count groups, if that makes sense based on your knowledge of the subject matter. If you are using these data as a pilot guide to further data collection for studies of planned comparisons, then all you need is the pooled mean-square error estimate, and the outcome difference that you wish to be able to detect with a particular power at a particular significance level, as in your use of the pwr package. That should, however, best be a pre-determined difference, not the observed difference in this set of data. It can be risky to go back and just sample particular groups that seem to be too small in your data set to find some hoped-for "significant" difference between 2 groups. The power calculations are not designed to take such result-chasing into account. Also, you need to correct for multiple comparisons if you are not testing a small number of pre-planned (i.e., before you saw these data) hypotheses.
