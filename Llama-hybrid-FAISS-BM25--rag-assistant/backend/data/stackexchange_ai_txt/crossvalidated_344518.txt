[site]: crossvalidated
[post_id]: 344518
[parent_id]: 
[tags]: 
Policy estimation in Reinforcement learning setup

I am interested in the problem of estimating the policy parameters of a behaving agent, in the usual reinforcement learning setup (i.e. the agent goal is to maximize his cumulative reward and has no prior knowledge about the environment's dynamics and the reward function). While most literature is concerned with how to build this agent, I am interested in the in estimating the agent's policy by observing his behavior and interaction with the environment. In other words, imagine we add to the reinforcement learning setup an "observer", looking at the agent interacting with the environment, and his goal is to model the agent behavior. Note that we can assume that the observer has full knowledge about the environment dynamics. I assume that in the general case this problem is very difficult, however, under certain restrictions (assuming bandits or contextual bandits, small policy families, etc...), it may be computationally tractable. I tried to look for literature dealing with this problem and couldn't find, can anyone directing me in finding the correct keywords, problem name, or anything that can help me find related work.
