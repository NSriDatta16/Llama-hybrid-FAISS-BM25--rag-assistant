[site]: crossvalidated
[post_id]: 509218
[parent_id]: 
[tags]: 
Chain rule for KL divergence, conditional measures

The chain rule for KL divergence is widely seen in the theoretical machine learning literature and generally referenced to [1, Theorem 2.5.3]: $$ \text{KL}[p(x, y) \mid q(x, y)]= \text{KL}[p(x) \mid q(x)] + \text{KL}[p(y \mid x) \mid q(y \mid x)] $$ However, the proof here only appears to apply to the case of densities w.r.t. some finite set. Based on quoted results, I assume this holds more generally but have been unable to find a proof of this in under the more general (Radon-Nokodym) definition of KL divergence for probability measures on X: $$ \text{KL}[p \mid q] = \int_{X} \log\left(\frac{dp}{dq}\right) \ dp. $$ I am looking for a (reference to a) proof and the general conditions under which is possible, ideally without too much heavy measure-theoretic apparatus. My potential applications relate to hierarchical or mixture models so any intuition on that front would also be greatly appreciated. [1] Elements of Information Theory, Cover & Thomas. Clarification: Here $p(x)$ is the marginal distribution of $p(x, y)$ on $x$ and analogously for $q$ , as in [1], so $p$ and $q$ are measures on some product space $\mathcal{X} \times \mathcal{Y}$ . $p(x)$ and $q(x)$ (in this slight abuse of notation) are the marginals on $\mathcal{X}$ . Part of my question is then what further requirements there are on $p$ , $q$ , $\mathcal{X}$ and $\mathcal{Y}$ for the above decomposition.
