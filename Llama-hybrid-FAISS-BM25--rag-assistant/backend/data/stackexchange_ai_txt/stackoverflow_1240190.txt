[site]: stackoverflow
[post_id]: 1240190
[parent_id]: 1234485
[tags]: 
The fact that the URL has ".xml" in it doesn't mean that the server is going to give you XML. In the case of the URL you provided in your example, the server's emitting XHTML. (I also am not seeing the xml-stylesheet processing directive that you mention in your comment in that file, which makes me wonder if you're looking at two different things.) There's nothing you can do on the client side to change that. If there's a way of formulating the URL to get raw XML from the server, it's not documented on that site. They also seem to be serving up XHTML that isn't well-formed XML (judging on what happens when you try to parse it). That's not very nice of them. Edit: Okay, so the culprit here is that this site apparently checks the user agent to determine whether it should send XML or HTML. The answer here (any why, pray, isn't Martin Honnen on StackOverflow?) shows how to do it: string url = "http://eu.wowarmory.com/character-sheet.xml?r=Stormreaver&n=Sebassis"; HttpWebRequest httpRequest = (HttpWebRequest)WebRequest.Create(url); httpRequest.UserAgent = @"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)"; using (HttpWebResponse httpResponse = (HttpWebResponse)httpRequest.GetResponse()) { XmlDocument xmlDocument = new XmlDocument(); xmlDocument.Load(httpResponse.GetResponseStream()); Console.Write(xmlDocument.OuterXml); } I wish I could tell you why they're doing that, and why this user agent works while others don't, but it's a little outside my area of expertise. Maybe someone else can shed some light on this.
