[site]: crossvalidated
[post_id]: 554260
[parent_id]: 
[tags]: 
How many folds for (time series) cross validation

Question Is it more statistically robust to calculate the mean of the mean squared errors from many folds for time series cross validation? Is it true in general that more folds for any cross validation strategy (k-fold, etc.) would lead to more statistically robust estimators of model performance? If possible, please mention a journal article/textbook that supports your answer. Related Questions/Resources It appears my questions leads to a series of other questions. I have included the links to related questions for anyone else who finds themselves at my question: Optimal number of folds in K -fold cross-validation: is leave-one-out CV always the best choice? Choice of K in K-fold cross-validation Bias and variance in leave-one-out vs K-fold cross validation Journal Article: On the use of cross-validation for time series predictor evaluation ... this is a nice paper in general on cv for time series, and they just use 5-fold. Intuition My intuition is that the answer is "yes, more folds is better" because if I take the mean of the mean squared errors for 5 folds that would lead to more examples of model performance than if I were to take the mean of the mean squared errors for 3 folds. Context Time series (aka walkforward) cross validation maintains the temporal structure of a dataset by not shuffling it and iteratively adding to each of n-folds (denoted as :param n_splits: to sklearn's TimeSeriesSplit cross validator. See the image belowfrom Sklearn's Cross Validation Strategies Webpage to visualize the cross validation strategy.
