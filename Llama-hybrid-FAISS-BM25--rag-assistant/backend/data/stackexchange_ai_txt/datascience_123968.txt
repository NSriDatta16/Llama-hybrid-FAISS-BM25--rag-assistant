[site]: datascience
[post_id]: 123968
[parent_id]: 
[tags]: 
L2 regularisation included in Validation Loss is counter intuitive?

I have been trying to tune hyperparameters for a neural network - I noticed the validation data loss for tensorflow in particular includes the L2 regularisation loss as a measure of the total loss. Surely this is counter intuitive as we want to see how well the model performs on unseen data, not to again penalise it for high L2. We reduce the magnitude of the weights to prevent overfitting and increase generalisation ability of the model on unseen data - the best measure of this is pure loss on the validation data set, so why do we also then penalise it for high weight magnitude (surely this would be captured in the pure validation loss to an extent). Is this correct? Or is there a reason for why the L2 regularisation is included in the validation loss?
