[site]: crossvalidated
[post_id]: 628148
[parent_id]: 
[tags]: 
Mathematics of Random Forest Classifier

I was going through the this 2001 paper on Random Forest Classifier (RFC) . I understood most of the concepts but there are some probability equations that I am finding hard to understand. Definitions Random Forest - Collection of tree structured classifiers $\{h(X, \Theta_k), k=1,2,3...\}$ where $\Theta_i$ s (trees) are i.i.d random vectors. Each tree casts a unit vote to the output of input $X$ and the most popular output class is chosen. Raw Margin Function - $rmg(\Theta, X, Y) = \mathbf{I}(h(X, \Theta)=Y) - \mathbf{I}(h(X, \Theta)=\hat{j})$ where $\mathbf{I}$ is the identity function and $\hat{j} = argmax_{j \neq Y} P_\Theta(h(X, \Theta)=j)$ . Margin Function - $mr(X, Y) = \mathbf{E}_\Theta [rmg(\Theta, X, Y)] = P_\Theta(h(X, \Theta)=Y) - max_{j \neq Y} P_\Theta(h(X, \Theta)=j)$ . The margin measures the extent to which the average number of votes at $X,Y$ for the right class exceeds the average vote for any other class. Generalization error - $PE^* = P_{X, Y}(mr(X, Y) . THE RESULT I am referring to states that the performance of the RFC is dependent on the correlation between the trees and the individual accuracies. In mathematical terms this is, \begin{equation} PE^* \leq \hat{\rho} \left(\frac{1-s^2}{s^2}\right) \end{equation} I cannot understand the derivation of the above result . In the above inequality $s = \mathbf{E}_{X, Y}[mr(X, Y)]$ . Now using Chebychevâ€™s inequality, definition of $PE^*$ and $s$ we get, \begin{equation} PE^* \leq \frac{Var(mr)}{s^2} \end{equation} There is a identity that states for i.i.d random vectors $\Theta$ and $\Theta'$ , $\mathbf{E}_\Theta^2[f(\Theta)] = \mathbf{E}_{\Theta, \Theta'}[f(\Theta)(\Theta')]$ . Using the definition of $mr(X, Y)$ and the identity this gives $mr^2(X, Y) = \mathbf{E}_{\Theta, \Theta'}[rmg(\Theta, X, Y)rmg(\Theta', X, Y)]$ . Using this the following equations are derived. I need help understanding this section onwards. I cannot understand how these equations are derived and the form of $\hat{\rho}$ that is derived. \begin{align} Var(mr) &= \mathbf{E}_{\Theta, \Theta'}[cov_{X, Y}[rmg(\Theta, X, Y)rmg(\Theta', X, Y)]]\\ &= \mathbf{E}_{\Theta. \Theta'}[\rho(\Theta, \Theta')sd(\Theta)sd(\Theta')]\\ &= \hat{\rho}\mathbf{E}_\Theta^2[sd(\Theta)]\\ &\leq \hat{\rho}\mathbf{E}_\Theta[Var(\Theta)] \end{align} where, $\hat{\rho} = \frac{\mathbf{E}_{\Theta. \Theta'}[\rho(\Theta, \Theta')sd(\Theta)sd(\Theta')]}{\mathbf{E}_{\Theta, \Theta'}[sd(\Theta)sd(\Theta')]}$ which is the mean value of the correlation. Continuing on the troublesome section, \begin{align} \mathbf{E}_\Theta[Var(\Theta)] &\leq \mathbf{E}_\Theta[\mathbf{E}_{X, Y}^2[rmg(\Theta, X, Y)]] - s^2\\ &\leq 1-s^2 \end{align} Can someone please break down the steps of the section of the proof that I have mentioned above? NOTE : This is my first post here. So if you are downvoting the question then please let me know how I can improve the question.
