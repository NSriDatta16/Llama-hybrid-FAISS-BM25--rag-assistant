[site]: crossvalidated
[post_id]: 194214
[parent_id]: 194035
[tags]: 
The most important reason to use Frequentist approaches, which has surprisingly not yet been mentioned, is error control. Very often, research leads to dichotomous interpretations (should I do a study building on this, or not? Should be implement an intervention, or not?). Frequentist approaches allow you to strictly control your Type 1 error rate. Bayesian approaches don't (although some inherit the universal bound from likelihood approaches, but even then, error rates can be quite high in small samples and with relatively low thresholds of evidence (e.g., BF > 3). You can examine Frequentist properties of Bayes factors (see for example http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2604513 ) but that's still a Frequentist approach. I think very often, researchers care more about error control than about quantifying evidence per se (relative to some specific hypothesis), and I think at the very least, everyone cares about error control to some extent, and thus the two approaches should be used complementarily.
