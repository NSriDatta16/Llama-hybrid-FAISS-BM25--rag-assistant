[site]: crossvalidated
[post_id]: 363963
[parent_id]: 363611
[tags]: 
Since I want to adopt machine learning programs interacting better with the involving component and its accuracy assurance. I am learning about those problems for a couple of machine learning algorithms such as SVM for classification and regression. However, Regarding my question, I have found it to be nice to share what I have learned from my question and answer it with my experience in a particular example. As I asked I was trying to estimate an expensive variable to measure via using several weak explanatory variables. Therefore, I have employed SVM regression and I have found that transformation has a direct relation with choosing of the kernel. eg. Since I wanted a good approximation, I have transformed all the variables with 2 different transformation method (SQRT and Z score). after that, I have defined a radial kernel for nu-SVM and ignored the hyperparameter from this kernel and I fitted the model and the result was not satisfactory. therefore, I replaced with the linear kernel for computation and the result was incredibly better than before Transformation and even after using radial (Note: Since the method is linear I have checked the residual distribution and the K fold Cross-validation using RMSE for only Testset/unseen data individually for all 10fold). In conclusion, As mentioned in lots of literature choosing the kernel is regarding the distribution of the data and therefore, in a wanted case choosing the right transformation has priority before feeding the data into algorithms.
