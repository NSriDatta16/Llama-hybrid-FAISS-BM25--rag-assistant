[site]: datascience
[post_id]: 73829
[parent_id]: 
[tags]: 
Having trouble understanding the x and y axis in SVM when training and testing data

I wrote some code based on this article. In the code in the article they have created a partition of 80 percent test and 20 percent data #What percentage of data you want to keep for training percentage = 80 partition = int(len(hog_features)*percentage/100) Later they have created the following variables, the data frame is two dimensions np array --- data_frame[hog_features,labels] : x_train, x_test = data_frame[:partition,:-1], data_frame[partition:,:-1] y_train, y_test = data_frame[:partition,-1:].ravel() , data_frame[partition:,-1:].ravel() clf.fit(x_train,y_train) now what I don't understand is why for the second dimension of the array (the labels) for the x variables they're including everything except the last value and for the y variables the second dimension of the array is just including the last element of the array from what I can understand using array slicing (Maybe I'm wrong).
