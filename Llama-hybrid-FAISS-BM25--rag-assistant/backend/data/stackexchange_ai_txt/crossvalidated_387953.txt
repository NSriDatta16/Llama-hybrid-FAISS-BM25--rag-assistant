[site]: crossvalidated
[post_id]: 387953
[parent_id]: 387929
[tags]: 
Your utility function is basically $$ U(x) = \max(\$100, x) $$ so all the profits below \$100 are equally bad. Above this, the more profit, the better. The problem is that the function is flat below \$100, so the optimizer can get stuck in such region. To avoid this, you would need to use some kind of optimizer that is able to make "jumps" outside such region, rather then something that only makes incremental improvements (like gradient descent). This would possibly depend on initialization. I am not an expert in reinforced learning, so I don't feel I could give you more detailed hints. With that strategy, what guarantee that the agent will never make a buy/sell decision that results in less than $100 profit? Nothing would give you such guarantees. What you are describing is simply an if (profit block of code inside your agent, that reacts on profits below \$100 (e.g. fails and restarts).
