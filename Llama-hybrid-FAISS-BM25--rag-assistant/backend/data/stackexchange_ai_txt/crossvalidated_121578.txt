[site]: crossvalidated
[post_id]: 121578
[parent_id]: 121557
[tags]: 
First, you should carefully handle the terminology. Hastie et al. call this model a "single hidden-layer neural network". With the words you were using for it -- missing hidden-layer and using perceptron (without the additional word "multilayer") --the model could be confused with a standard perceptron, especially when you don't further specify the model. The single hidden-layer neural network model you specified has $M$ hidden nodes. $X$ denotes the input features, which inside a node are summed up using the corresponding weights and then subjected to a sigmoid function to produce the hidden-layer outputs $Z_m$. These are used as input to the output layer, which consists of $K$ nodes (as there are $K$ classes). Again, following the usual neural network approach, in the $k$-th node the inputs are summed up and the function $g_k$ is applied in order to produce the neural network output. $g_k$ therefore can be denoted the output-layer activation function . Finally, $f_k$ stands for the whole neural network model leading to the output of the $k$-th node. The vector of all $K$ functions $f_k$ then makes up the whole neural network. To summarize, here are my suggestions for the names: $T_k:$ output layer aggregation result $g_k:$ output layer activation function $f_k:$ single hidden-layer neural network corresponding to the $k$-th node
