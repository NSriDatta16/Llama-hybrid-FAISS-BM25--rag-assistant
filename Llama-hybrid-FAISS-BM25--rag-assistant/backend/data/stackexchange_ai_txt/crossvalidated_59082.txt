[site]: crossvalidated
[post_id]: 59082
[parent_id]: 59066
[tags]: 
This stems from your basic regression model. Two things. 1: In the context of regression we assume we have a perfect, complete model ready to go which explains, correctly, all covariability in the observed data for all variables. Implicit with this is that the model is assumed constant for all observed data. Intuitively we tend to think of a time series but the really basic OLS model is mostly assuming cross sectional data. As a consequence the error term which is left is nonsystematic. So it is not assumed to be some sort of bias or measurement error because a perfect model would correct that (the argument is actually not that the model could, but that it just doesn't exist and the model is therefore right, but anyway). So let's think about this: Why should a truly random, nonsystematic error be heterscedatic? At the very least this would imply some sort of "system" to the error. It can not be from the measurement, it can not be anything we have control over. We assume we have all differences of the data points included in our model. Therefore the consequence is that all which is left is that which we can not account for, a truly random influence to this cross sectional event. This should, intuitively, be the same process for all data points. An example: We put different animals into our measurement machine and measure. All external influences are identical, we account for all differences between the animals themselves. What is then left? It must be the same identical random process inherit to the measurement procedure. If there was, for example, a slight degradation of our sensors after 100 measurements which would increase the variance, we literally assume our model includes this. This is of course completely bonkers in reality and there is no reason to assume this at all. But it is the mathematical argument behind this. So in a perfect world, yeah, homoscedasticity makes sense. 2: Obvious reason is that is makes learning the basics of regression, intervals and testing (F/t/etc.) easy. How are you going to learn about hypothesis tests if you have at the same understand a White HK estimator... It also goes to show a basic premise in OLS which is often forgotten: It is assumed the model is truly correct. As this goes so completely against the reality there are many adjustments to be made, such as heteroscedastic error terms, but the ideal theory assumes this. In practice, many people just use these tests without understanding the implications...
