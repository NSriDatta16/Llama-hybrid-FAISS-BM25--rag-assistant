[site]: crossvalidated
[post_id]: 603151
[parent_id]: 
[tags]: 
solving for standard deviation of a difference from an F-test

In an old article (1990s), results are reported where 30 subjects respond to two kinds of words and reaction time in milliseconds (ms) is measured for every response. In an repeated measures analysis of variance, the two conditions (types of words) are compared (averaged over the about 10 items per condition). The statistical information reported is: F(1, 29) = 7.73 and it is reported that the mean difference between the conditions (delta) = 25 ms. I would like to know what the 95% confidence interval of the difference is, but this is not reported in the article. To get the 95% confidence interval, I need to know the standard deviation of the difference scores (Sd). I tried the following, could you comment whether this is correct? $F = t^2$ , therefore $t = \sqrt{F} = \sqrt{7.73} = 2.78$ t = $delta \over \frac{Sd}{\sqrt{n}}$ Therefore Sd = $\sqrt{30} \times 25/2.78 = 5.48 \times 8.99 = 49.27 ms$ Thanks and best, Jurriaan
