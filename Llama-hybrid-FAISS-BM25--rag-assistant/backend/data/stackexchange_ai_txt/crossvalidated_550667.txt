[site]: crossvalidated
[post_id]: 550667
[parent_id]: 550634
[tags]: 
This depends on what you care about. For forecast accuracy just use cross validation with the mse of test sets to select features. For inference then I would let any theory you have for the domain get you started and then what you do from there is, quite frankly, up for debate but a full bayesian treatment injecting as much domain knowledge into your priors would be my recommendation. Variables that are 'linked' begs the question of correlation vs causation. I will just assume correlation. For simplicity, you could just toss adjusted r squared and minimize the AIC or AICc or BIC. They have some nice qualities that r-squared does not. Minimizing AIC results in a model that approximates the best model from cross validation and BIC approximates 'True' model process if it exists as a subset of your variables (this is almost never the case). All have been shown to outperform R squared and Adjusted R squared on average for model selection in simulated studies from awhile back. Alternatively, you could use a LASSO regression to do variable selection and regularization. If you use scikitlearn you can just use the LassoCV class and it will handle everything for you. Variable coefficients will be 'shrunk' towards 0 and many may be 0 and therefore dropped from your equation. What's left would be variables that were more 'useful'. And finally, you could just feed it to a random forest and use the feature importance to grab the most 'relevant'. Definitely a looked down upon approach from a statistics standpoint but it has some nice-ities. Primarily it will handle feature interactions better than standard regressions so it is pretty useful as plug-and-play approach.
