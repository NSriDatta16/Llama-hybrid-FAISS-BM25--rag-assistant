[site]: crossvalidated
[post_id]: 413431
[parent_id]: 
[tags]: 
variance of the square of the bias on linear regression

Basic setting let the linear model be: $$ \mathbf{y}=\mathbf{X\beta}+\epsilon $$ where $\epsilon \sim N(0,\sigma^2\mathbf{I}_n)$ $n$ is the number of samples $p$ is the number of attributes. $\mathbf{y}\in\mathbb{R}^{n \times 1}$ , is known. $\mathbf{X}\in\mathbb{R}^{n \times p}$ , is known. $\mathbf{\beta}\in\mathbb{R}^{p \times 1}$ , is unknown. we estimate $\beta$ by minimizing the least squares,and we have: $$ \hat \beta = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}\mathbf{y} $$ question let $$ L_1^2 = (\hat \beta - \beta)^T(\hat \beta - \beta) $$ show that $$ Var(L_1^2)=2 \sigma^4 \text{Trace}((X^TX)^{-2}) $$ What I have known: $$ Var(\hat \beta)= \sigma^2 (X^TX)^{-1} $$ $$ E(L_1^2)=\sigma^2 \text{Trace}((X^TX)^{-1}) $$ I meet this question when I was reading Ridge regression: Biased estimation for nonorthogonal problems Hoerl, Arthur E;Kennard, Robert W Technometrics; Feb 2000; 42, 1; ProQuest pg. 80
