[site]: crossvalidated
[post_id]: 186902
[parent_id]: 
[tags]: 
Post-hoc correction of machine learning bias

I have been using a machine learning algorithm to predict a continuous variable, although am having an issue whereby whichever method I use, there is a systematic bias at low and high values of the variable. In the below, the orange represents the true=predicted line (the ideal outcome), and the blue dots are predictions from the trained model on an independent test set. I have added the black line to represent more-or-less, the average prediction of the model for a given true value. I have tried a number of techniques to avoid this over-prediction at low values of the variable, and under-prediction at high values, however they all suffer from the same issue. My question is: can I correct for this systematic bias in prediction by using this knowledge to post-hoc adjust my predictions from the ML algorithm? In other words, I get a given prediction, say y=8, from the algorithm. I then use the horizontal difference between the orange line and black line at this prediction value to upwardly-correct this value, moving it more towards 10 (perhaps the true value). Something in me doesn't feel quite right about doing this. I think that if there were this systematic bias in the machine learning predictions, then the algorithm (minimising RMSE) would have done its best to minimise this.
