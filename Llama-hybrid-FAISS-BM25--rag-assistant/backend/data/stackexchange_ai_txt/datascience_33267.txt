[site]: datascience
[post_id]: 33267
[parent_id]: 2504
[tags]: 
When you have such large data set you can play with any of the statistical and machine learning modelling techniques and that is highly encouraged. As other have suggested I would also recommend to take a few million random samples from data and play with that. Since this is a classification problem I would follow simple classification techniques first and then go on with more complex ones later. Logistic regression is great to start with. I wanted to add that generative models must also be tried out. Naive Bayes classifier is one of the simplest probabilistic classifiers and it outperforms many complex methods like support vector machines on many tasks. You can look at this simple implementation of NB and a this link for comparison of NB to logistic regression. One can build a Naive bayes (NB) classifier as a baseline model and then go for any machine learning technique like Support vector machines(SVM) or multilayer perceptrons (MLP). A trade off here is that NB is computationally less expensive than MLP so better performance from MLP is desired. Coming to your exact query: Deep learning and gradient tree boosting are very powerful techniques that can model any kind of relationship in the data. But what if in your case a simple logistic regression or NB is giving desired accuracy. So its always better to try out the simple techniques first and have a baseline performance. Then one can go for the complex models and compare with the baseline.
