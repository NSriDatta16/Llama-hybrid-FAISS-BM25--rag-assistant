[site]: crossvalidated
[post_id]: 596014
[parent_id]: 296828
[tags]: 
In a machine learning context, "gold" data usually refers to hand-labelled (and therefore) very high quality data. Readers may wonder "isn't all training and test data hand-labelled and known to be correct?" . (Ha ha ha) This is often not the case. ML techniques can be very data-hungry, and it's not uncommon to use all sorts of methods that trade off a little bit of data quality for a lot of data quantity. For example, if you're trying to replace an old production system with a new one, it makes sense to use the old one's predictions as training data to bootstrap the new system. Or you might use user-interaction signals to generate training data. Or perhaps you semi-automatically generate training data using some slow offline process over some enormous corpus with some minor curation of the results. However, in all of these cases, it would be foolish to assume these predictions are error free. Hence, it's useful to distinguish your (expensive, almost certainly correct) gold data from all your other training/test data.
