[site]: crossvalidated
[post_id]: 240374
[parent_id]: 
[tags]: 
When training an RNN, what are the important factors for deciding how many unrollings / unfoldings to use?

As far as I understand many RNN:s are trained with back propagation over a sequence of $k$ datapoints. The RNN is "unrolled" for each datapoint, i.e. its output is fed into itself together with the next datapoint, to compute the gradient of the loss function for these $k$ datapoints. How is this $k$ chosen? And what consequences does different choices of $k$ have? (If results are design-specific I am mostly interested in LSTM networks.)
