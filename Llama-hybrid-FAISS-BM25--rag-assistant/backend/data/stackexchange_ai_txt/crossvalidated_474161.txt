[site]: crossvalidated
[post_id]: 474161
[parent_id]: 411376
[tags]: 
I would like to extend the answer by Wolfgang on rescaling the measure. Consider some study. Let $X$ be the averaged mean, $l$ be the lower bound for the Likert scale, $u$ be the upper bound for the Likert scale (both bounds over all the answers) and $n_q$ be the number of items. We can split the lower and upper bound up into the number of items and the lower and upper bound for individual answers, denoted by $k_l$ and $k_u$ respectively. Then, the transformed mean $m_t$ can be obtained by using $$ m_t = \frac{X \cdot n_q - l}{u - l} = \frac{X \cdot n_q - (n_q \cdot k_l)}{(n_q \cdot k_u) - (n_q \cdot k_l)} = \frac{(X - k_l) \cdot n_q}{(k_u - k_l) \cdot n_q} = \frac{X - k_l}{k_u - k_l}. $$ This is known as min-max normalisation . To scale the standard deviations, we can use the equation for a linear transformation of the variance. According to Hogg et al. (2005): Let $X$ be a random variable with finite mean $\mu$ and variance $\sigma^2$ . Then for all constants $a$ and $b$ , $$ Var(aX + b) = a^2 \cdot Var(X). $$ So, for the variance of $\frac{X - k_l}{k_u - k_l}$ , $$ \begin{aligned} Var(\frac{X-k_u}{k_u - k_l}) &= Var((k_u - k_l)^{-1} \cdot (X - k_u)) \\ &= (k_u - k_l)^{-2} \cdot Var(X - k_u) \\ &= (k_u - k_l)^{-2} \cdot 1^2 \cdot Var(X) \\ &= \frac{Var(X)}{(k_u - k_l)^2}, \end{aligned} $$ and for the standard deviation $$ \begin{aligned} sd(\frac{X-k_l}{k_u - k_l}) &= \sqrt{Var(\frac{X-k_l}{k_u - k_l})} \\ &= \sqrt{\frac{Var(X)}{(k_u - k_l)^2}} \\ &= \frac{sd(X)}{k_u - k_l}. \end{aligned} $$ Note that I have not taken Bessel's correction into account which will be an issue for studies having small sample sizes. I'll add that later if I understand how I can take the correction into account. References Hogg, R. V., McKean, J., & Craig, A. T. (2005). Introduction to mathematical statistics. Pearson Education.
