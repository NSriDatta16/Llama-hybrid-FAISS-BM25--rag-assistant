[site]: crossvalidated
[post_id]: 239318
[parent_id]: 
[tags]: 
Gaussian Time Series variance

Suppose that {$X_t$} is a Gaussian stationary time series (i.e., strictly stationary) with mean µ = 0 and covariance function γ(h). We observe the data: {$X_1, X_2, ..., X_n$}. The sample autocovariance of lag h is defined as: $\hatγ (h) = \frac{1}{n} $$\sum_{t=1}^{n-h} X_t X_{t+h}$ We are going to find an expression for: $Var(\hatγ (h)) = E((\hatγ (h))^2) - (E(\hatγ (h)))^2$ Under the above assumptions, the following relationship was established about 100 years ago (it is actually more generally true): For t, s, h, and k: $E(X_t X_{t+h} X_s X_{s+k}) = E(X_t X_{t+h}) * E(X_s X_{s+k}) + E(X_t X_s) * E(X_{t+h} X_{s+k}) + E(X_t X_{s+k}) * E(X_{t+h} X_s)$ Show that: for h ≥ 0, $Var(\hatγ (h)) = \frac{1}{n} \sum_{m=-(n-h-1)}^{n-h-1} ({1- \frac{|m|+h}{n}})({γ^2(m) + γ(m+h) * γ(m-h)})$ So I think I'm supposed to write $E((\hatγ (h))^2)$ as a double summation to start. I've come up with: E[$(\frac{1}{n^2} \sum_{s=1} \sum_{t=1} X_t X_s] - [E(\frac{1}{n} \sum_{t=1}^{n-h} X_t X_{t+h})]^2$ From there, I'm not quite sure where to go.
