[site]: crossvalidated
[post_id]: 219814
[parent_id]: 219798
[tags]: 
So, you have a mixture of categorical boolean and numeric continuous variables. You want to cluster the variables (not data cases) based on their similarity. A correlation coefficient could be assumed the similarity measure. We could, for example, compute Pearson $r$. Given that boolean true/false is convertible into 1/0 binary values, $r$ is computable. $r \text {(numeric,numeric)}$ is classic $r$; $r \text {(binary,binary)}$ is point-point $r$ or Phi coefficient; $r \text {(numeric,binary)}$ is point-biserial $r$. All these are hypostasized Pearsonian correlation. You may go straightforward and do the analysis (cluster) based on those three kinds of correlation values collected in one matrix. You may do it if you see the boolean/binary data as profoundly dichotomous, where no underlying continuous variable is conceivable in the background. But then some critic might take a stance to say that there is no theoretical (philosophical) way at all to compare a similarity between categorical features with a similarity between scale features. That view would suggest you then to dichotomize your continuous variables - some way, and forget that they were scale before. So all the data are binary and you are fine. Whereas if you choose to accept the idea of underlying continuous variable then using the aforesaid initial correlation matrix directly in the analysis stambles against another snag. The problem is that - due to the fact that a manifest binary variable (i.e. dichotomized underlying one) is only 2-valued but a continuous manifest variable is many-valued - the magnitudes of the three coefficients is risky to compare directly. See, for example 2nd paragraph here . In short, coefficients including binary variable are heightened sensible to the cut point taken at the hypothetical dichotomization of its underlying precursor variable. One way out would be to try to "restore" (infer) correlation values which "existed" before dichotomizations. That means computation of tetrachoric correlations in place of point-point $r$s and biserial correlations in place of point-biserial $r$s. If needed, the whole matrix might be then "smoothed" towards positive-definitness. Another approach (not unquestionable, as any is) might be to rescale correlations in their empirically accessible range in the given data. This trick is, so to speak, atheoretical, it may or may not imply the existence of underlying continuous variable for dichotomous ones. The idea is simply to take away the effect of any skew of variables' marginal distributions on the coefficients. $r_{rescaled}=r/r_{max}$; for example if the observed $r$ is $.4$ and the maximal possible value for these two variables is $.95$ (which you get after sorting their data both ascendingly) then the rescaled value is $.42$. The whole matrix might call be "smoothed" into p.s.d. in the end. An approach alternative to the previous one (taking away the marginal effect) might be to compute nonparametric correlations instead of $r$ - such as rank-based Spearman rho or Kendall tau. It is also an option. And from this point we begin to sight, logically, having done a circle, the further option of dichotomizing the scale variables (instead of ranking them) - from what we started the discussion. After you compute correlations (or you would like other similarity measures?) you will have to decide on the clustering method - for example one of hierarchical methods. But here starts another story. You might also want to use Factor analysis in place of Cluster analysis: although factor analysis is not clustering but rather latent variable technique, it gives "clusters", in some sense.
