[site]: crossvalidated
[post_id]: 158774
[parent_id]: 47253
[tags]: 
I really appreciate the effort contributed by guest47, but I don't quite agree with his answer, in some minor aspects. I wouldn't directly pose my disagreements, but rather reflect them in this answer. In many cases, it is redundant to compute $\hat\theta s$ when we already know the true underlying parameter $\theta*$. However, it is still useful when we want to look at the accuracy and precision of $\hat\theta s$ in estimating $\theta*$. Besides, the first paragraph in your quoted passage will make it easier for you to understand the notion of "parametric bootstrap", which I will touch upon shortly after. Guest47 gives good answer. No need to elaborate more. In parametric bootstrapping, what you have is the observed data D. You come up with a parametric model to fit the data, and use estimators $\hat\theta$ (which is a function of data D) for the true parameters $\theta*$. Then you generate thousands of datasets from the parametric model with $\hat\theta$, and estimate $\hat\theta s$ for these models. In nonparametric bootstrapping, you directly use D, sample (for thousands of times) exactly from D, instead of from generated data.
