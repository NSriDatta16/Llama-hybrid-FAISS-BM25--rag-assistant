[site]: crossvalidated
[post_id]: 345208
[parent_id]: 
[tags]: 
Optimal hidden units size

Suppose we have a standard autoencoder with three layers (i.e. L1 is the input layer, L3 the output layer with #input = #output = 100 and L2 is the hidden layer (50 units)). I know the interesting part of an autoencoder is the hidden part L2. Instead of passing 100 inputs to my supervised model, it will feed it with 50 inputs. What is the optimal hidden units size? 50 is well, but why not using 51, 52 or 63 hidden units? Does 51 will perform better the supervised model than 50 hidden units? Suppose now that the number of inputs is 1,000,000. If N is the number of units, then I don't want to test out each possible value for N to find out the optimal N. I thought there exists at least an algorithm to do not be obligated to test each possible value or eliminate some of them. Could that question help?
