[site]: crossvalidated
[post_id]: 51012
[parent_id]: 
[tags]: 
Must I normalize inputs into a perceptron that uses a sigmoid activation function?

I am building a neural network. Each perceptron in the network uses a sigmoid activation function. Must I normalize my inputs (which currently range form 0 to 1200)? I ask this because the sigmoid function approaches 1 as the input to it approaches infinity. Hence, if my input is not between 0 and 1, I'm afraid that the sigmoid will always return 1.
