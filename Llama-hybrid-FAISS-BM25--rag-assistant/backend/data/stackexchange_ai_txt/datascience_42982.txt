[site]: datascience
[post_id]: 42982
[parent_id]: 42509
[tags]: 
For each bounding box you need p_c : any object / no object (background) b_x , b_y , b_w , b_h : x, y, width and height of the bounding box c_i : object i / no object i For e.g. 2 bounding boxes and 3 classes (e.g. car, person, traffic light) your input vector would look as follows (the superscript in brackets denote the index of the bounding boxes) \begin{bmatrix} p_{c}^{(1)}\\ b_{x}^{(1)}\\ b_{y}^{(1)}\\ b_{w}^{(1)}\\ b_{h}^{(1)}\\ c_{1}^{(1)}\\ c_{2}^{(1)}\\ c_{3}^{(1)}\\ p_{c}^{(2)}\\ b_{x}^{(2)}\\ b_{y}^{(2)}\\ b_{w}^{(2)}\\ b_{h}^{(2)}\\ c_{1}^{(2)}\\ c_{2}^{(2)}\\ c_{3}^{(2)}\\ \end{bmatrix} The whole image is fed into the model. That is essentially why YOLO is so fast. It looks at the whole image only once. This is done by the CNN . Basically each portion of a convolution corresponds to a grid cell. For example the upper right cell in an image would correspond to the upper right part of the filters in each layer. This is visualized at the left of this image: Yes they have to have the same size. That's what most CNNs expect. All images in the training set must have equal sizes and so do the images of the test set. The image gets shrinked and deformed into a square of size 608x608
