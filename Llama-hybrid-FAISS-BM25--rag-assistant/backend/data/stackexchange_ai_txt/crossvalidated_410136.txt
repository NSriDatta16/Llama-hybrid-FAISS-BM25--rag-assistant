[site]: crossvalidated
[post_id]: 410136
[parent_id]: 
[tags]: 
Model Not Performing Well On Validation Data - Customer Attrition Modeling

I am modeling customer churn for the online subscription. I looked back 90 days into customersâ€™ data, using number customer watching behavior etc. I get a pretty strong model based on test data. set.seed(42) split Summarize the target variables table(train_attr$Attrition) / nrow(train_attr) No Yes 0.95804365 0.04195635 Building XGBOOST Model ## Create train/test indexes ## preserve class indices set.seed(42) my_folds $Fold1 table(train_attr$ Attrition[i]) / length(i) ## Reusing trainControl my_control Predicting Test Data - xgboost > confusionMatrix(predict(model_xgb, test_attr[, -1]), test_attr$Attrition, positive = 'Yes') Confusion Matrix and Statistics Reference Prediction No Yes No 40582 516 Yes 0 1261 Accuracy : 0.9878 95% CI : (0.9867, 0.9888) No Information Rate : 0.958 P-Value [Acc > NIR] : However, when I tried to validate my results by labeling each user as having attrited or not attrited in the next 30 days. I did not get what I was expecting. I am getting all user wrongly labbled. I do understand case of imblance classes. I tried different sampling methods e.g. under/over/mix sampling but still no luck. Validation data ## Validation data = 1 month valid_attr % drop_na() ## Summarize the target variables for validation data table(valid_attr$Attrition) / nrow(valid_attr) No Yes 0.98638361 0.01361639 > confusionMatrix(predict(model_xgb, valid_attr[, -1]), valid_attr$Attrition, positive = 'Yes') Confusion Matrix and Statistics Reference Prediction No Yes No 213266 2944 Yes 0 0 Accuracy : 0.9864 95% CI : (0.9859, 0.9869) No Information Rate : 0.9864 P-Value [Acc > NIR] : 0.5049 Kappa : 0 Mcnemar's Test P-Value : Can anyone give me some insights so I can solve this problem. Or I should do different approach? Thanks in advance
