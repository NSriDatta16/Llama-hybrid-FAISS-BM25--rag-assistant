[site]: datascience
[post_id]: 96951
[parent_id]: 
[tags]: 
Convolutional autoencoder - why keras example is asymmetry model?

I'm looking on keras convolutional autoencoder example, and confused with the model structure: import keras from keras import layers input_img = keras.Input(shape=(28, 28, 1)) x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img) x = layers.MaxPooling2D((2, 2), padding='same')(x) x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x) x = layers.MaxPooling2D((2, 2), padding='same')(x) x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x) encoded = layers.MaxPooling2D((2, 2), padding='same')(x) # at this point the representation is (4, 4, 8) i.e. 128-dimensional x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded) x = layers.UpSampling2D((2, 2))(x) x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x) x = layers.UpSampling2D((2, 2))(x) x = layers.Conv2D(16, (3, 3), activation='relu')(x) x = layers.UpSampling2D((2, 2))(x) decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x) autoencoder = keras.Model(input_img, decoded) autoencoder.compile(optimizer='adam', loss='binary_crossentropy') The last layer of the encoder contains MaxPooling2D layer and the first layer of the decoder starts with Conv2D layer. Why it is not symmetry ? I assumed that if the last layer of the encoder is down sample layer that the first layer of the decoder will be up-sampling layer. What is the advantage of building the model as keras publish (instead of using up-sampling as first layer of the decoder) ? Is there a reason that some layers contains padding and other not ? (Is it because we want to get to same output size as the input size) ?
