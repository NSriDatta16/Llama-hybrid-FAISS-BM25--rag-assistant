[site]: crossvalidated
[post_id]: 192732
[parent_id]: 
[tags]: 
model fitting of data to multiple distributions

I have a set of numbers $ X = \{x_1, x_2,\ldots,x_n\}$ and I am interested in finding the most fitting combination of these numbers to multiple exponential distributions. Using predefined rules, I select $r$ disjoint subsets $X_1, X_2, \ldots, X_r$ of $X$ such that they completely cover $X$, and fit each such subset $X_i$ to an exponential distribution with MLE rate parameter $\lambda_i = 1/A_i$, where $A_i$ is the average (arithmetic mean) of $X_i$. For each subset $X_i$, fitting is done by computing the product $P_i$ of the PDF for each $x \in X_i$, i.e., $P_i = \prod_{x \in X_i}\lambda_i e^{-\lambda_i x}$. I compute an overall probability over all subsets as $P = \prod_{i=1}^r P_i$. Now, I take a different set of $k$ subsets $X'_1,\ldots,X'_k$ of $X$ (such that they cover $X$ completely). Those subsets can also differ in number, i.e., $k \neq r$. I compute the overall probability for this configuration, let's call it $P'$. My question is whether I can use the classic Metropolis-Hastings algorithm for an MCMC framework. I have a configuration (the first one I mentioned) fitting $r$ exponential distributions and the proposed one with $k$ exponential distributions. Can I use the Metropolis choice, i.e. $$\min\bigg(1,\frac{P'}{P}\frac{g(X'_1,\ldots,X'_k\mapsto X_1,\ldots,X_r)}{g(X_1,\ldots,X_r\mapsto X'_1,\ldots,X'_k)}\bigg)$$ assuming no prior information (i.e. uniform). $g$ is the proposal distribution and is derived from the predefined rules.
