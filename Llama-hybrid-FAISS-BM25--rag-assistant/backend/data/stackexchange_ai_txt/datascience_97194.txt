[site]: datascience
[post_id]: 97194
[parent_id]: 97186
[tags]: 
There is indeed a risk to overlearn the "unknown" class (due to the way larger amount) at the expense of the other classes, which could lead to false "unknown" results. It mainly depends on how close the "unknown" data to the "known" one is. Here are 3 potential solutions: A simple one is to use random "unknown" data in a larger amount than the average amount of "known" date (but not too large: twice as large for instance). A logic one is to have a representative sample from a multivariate normal distribution of unknown data. https://juanitorduz.github.io/multivariate_normal/ An advanced one is to get the "unknown" data that is closer to the "known" one thanks to an unsupervised classification model. https://scikit-learn.org/stable/unsupervised_learning.html Then add some more unknown data to generalize them better.
