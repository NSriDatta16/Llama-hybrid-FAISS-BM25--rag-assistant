[site]: crossvalidated
[post_id]: 337625
[parent_id]: 
[tags]: 
Should previously misclassified data be have a higher 'Sample Weight' than normally sourced training data when performing incremental learning?

I am currently developing a classifier with online/incremental learning. I am using scikit to create the model and run partial_fit after an initial training of the model. If their is a new class, or there is no model already, I run: clf = SGDClassifier(loss="log", penalty="l1", average=True) clf.fit(X, Y) and if there is only new data on classes that have already been initially trained, I run: clf = joblib.load(output_file) # load already trained model clf.partial_fit(X, Y) For both of these methods of training I then run: joblib.dump(clf, output_file) # save model I currently am receiving manual feedback on a classification when predicting : clf = joblib.load(output_file) # load model clf.predict(X1) I want the model to learn from its mistakes by retraining the model with the X1 data when it got the prediction wrong. Is it sufficient to just rerun clf.partial_fit(X1, Y) with the manual classification or would it be better to perhaps give it a heavier sample weight so it really makes sure it doesn't make that mistake again? Although all X training data in the first place will be manually classified and 100% accurate. Edit Moderators please may you at least explain what you do not understand?
