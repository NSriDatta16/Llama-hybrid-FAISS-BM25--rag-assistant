[site]: crossvalidated
[post_id]: 161960
[parent_id]: 161926
[tags]: 
The basic idea is that more variation in the regressors allows you to more confidently pin down the relationship between $y$ and $X$ in your regression. Recall that the slope coefficient of the estimated regression is to provide an answer to the question: "How does $y$ change, on average, when $X$ changes by one unit?" Now, in the limit, if $X$ does not vary at all, the sample is of course entirely uninformative about that question. If $X$ only varies a little, the slope will be estimated very imprecisely. For example, when you want to estimate the returns to more education in terms of additional salary, but your sample consists of, say, $n-1$ students with a BSc degree and one with an MSc, the return to completing an MSc will be estimated from that student alone. Since that student may have all sorts of pecularities, the effect on salary from completing an MSc will be estimated very poorly. Here is a simulated example where the purple dots are pairs $(x_i,y_i)$ where the regressors are uniform on $[0,1]$ , whereas the golden dots are from regressors uniform on $[-2,3]$ , thus their variation is larger. The true $\beta$ is .5 in both cases, and the errors are $N(0,0.5^2)$ (the code is below for completeness), $n=50$ . As we observe $X$ over a wider range in the golden case, regression finds it easier to spot the slope of the true regression line. We see that the estimated slope for the purple sample is quite off (in fact, even negative), whereas the golden one is quite good. Of course, the figure is for a single sample and thus only suggestive. You could run the code many times (aka, a simulation study) to assess the difference in precision for this (or of course other) design(s). One can also show this effect analytically: In a regression with constant (as in my example), the variance of the estimated slope coefficient is (with $\sigma^2$ the variance of the error terms) $$ Var(\hat{\beta})=\frac{\sigma^2}{\sum_{i=1}^n(x_i-\bar{x})^2} $$ We notice that as the variation in $X$ increases , the variance of the OLS estimate decreases . Code for the plot: n
