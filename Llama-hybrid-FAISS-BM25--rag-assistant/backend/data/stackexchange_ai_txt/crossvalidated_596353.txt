[site]: crossvalidated
[post_id]: 596353
[parent_id]: 596315
[tags]: 
There are (at least) three different approaches to compute the variance of $f(x)$ : Gauss' law of error propagation, which is in this case $(\Delta f)^2\approx \left(\left.\frac{\partial f}{\partial x}\right|_{x=\mu_x}\right)^2 (\Delta x)^2$ The Jackknife Variance: $\sigma_{JK}^2=\frac{n-1}{n}\sum_{i=1}^n (f_{(i)} - f_{(.)})^2$ , where $f_{(i)}^2$ is the value of $f$ computed with sample $i$ omitted, and $f_{(.)}$ is the mean of these leave-one-out values. A Bootstrap estimate of the variance, which is a Monte Carlo method and thus yields a random value, i.e. two researchers starting with the same data will obtain (somewhat) different results. Edit: Method 1 assumes that $f(x)\approx f(\mu_x)+f'(\mu_x)(x-\mu_x)$ in the region $\pm 2\sigma_x$ around $x=\mu_x$ , which you can check graphically. Note that if this does not hold and the function $f$ is not odd around $x=\mu_x$ , the approximation (which you presumably use) $\mu_f\approx f(\mu_x)$ does not hold either. Methods 2&3 are only applicable, if $\mu_x$ and $\sigma_x$ are empirical values and you still have the data $x_1,\ldots,x_n$ . If these are theoretical values and all you have is $\mu_x$ and $\sigma_x$ , but you are pretty sure that $x$ is normally distributed, then you can follow the suggestion in the comment by @whuber and calculate $\mu_f$ and $\sigma_f^2$ numerically from their exact definitions: $$\mu_f=\int_{-\infty}^{\infty} f(x)\,\varphi_{\mu_x,\sigma_x}(x)\,dx \quad\mbox{ and }\quad\sigma_f^2 =\int_{-\infty}^{\infty} (f(x)-\mu_f)^2\,\varphi_{\mu_x,\sigma_x}(x)\,dx$$ where $\varphi$ is the probability density of the normal distribution. Apart from a proper numerical integration, you can also use a Monte Carlo approach: simulate normally distrbuted $x_i$ and compute the mean value and variance of $f(x_i)$ . This is very slow to converge compared to proper numerical methods, but it has the advatnage that you also obtain an estimate of the distribution of $f$ and can compute confidence intervals therefrom. The confidence intervals $\mu_f\pm 2\sigma_f$ will have poor coverage probability, if the distribution of $f$ deviates considerably from normality.
