[site]: crossvalidated
[post_id]: 319481
[parent_id]: 319480
[tags]: 
This topic got much attention in the last few years, yet I don't know of any important proof in the field that says that deeper architectures are better than shallower ones for a given problem. Some works like this one show that certain deep networks learn functions that a shallow network (with only one hidden layer) would have to be exponentially large to learn them. Note that it is not the same as what you are looking for. The architectures that are considered state-of-the-art today are usually built with empirical trial-and-error combined with some insights from past successes.
