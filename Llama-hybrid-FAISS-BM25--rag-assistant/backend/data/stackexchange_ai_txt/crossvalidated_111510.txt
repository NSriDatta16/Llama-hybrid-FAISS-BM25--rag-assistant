[site]: crossvalidated
[post_id]: 111510
[parent_id]: 111445
[tags]: 
KL Divergence measures the information loss required to represent a symbol from P using symbols from Q. If you got a value of 0.49 that means that on average you can encode two symbols from P with the two corresponding symbols from Q plus one bit of extra information.
