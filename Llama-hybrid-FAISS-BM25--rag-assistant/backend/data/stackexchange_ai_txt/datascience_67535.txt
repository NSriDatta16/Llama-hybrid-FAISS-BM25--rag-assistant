[site]: datascience
[post_id]: 67535
[parent_id]: 67526
[tags]: 
I don't think your question deserves so many downvotes, but I can understand (well guess at least) why ML experts don't see it as a legitimate question: It's a bit naive: while ML has concepts such as reinforcement, reward, cost etc., and of course these terms are derived from their respective meaning in the general language, but in the ML context these have a specific formal meaning. In particular they are not meant to be assigned hard-coded values like you suggest. In the same idea, ML requires a precise, formal representation of concepts. What would be an action in this context? How would you represent an agent/person, and the interactions between them? Currently as far as I can see what you propose is a kind of simulation involving predefined mechanisms, there's no actual data involved. The only way to evaluate this would be to compare against real cases whether the simulation ends with the same results, and that would also be difficult to formalize properly. In my opinion why not? It could be an interesting idea, but there are a lot of details to clarify, and I suspect that psychological disorders are not the easiest thing to represent accurately in a formal setting.
