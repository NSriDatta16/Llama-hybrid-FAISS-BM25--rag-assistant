[site]: crossvalidated
[post_id]: 243201
[parent_id]: 14099
[tags]: 
There is nothing wrong with using blocks of "future" data for time series cross validation in most situations. By most situations I refer to models for stationary data, which are the models that we typically use. E.g. when you fit an $\mathit{ARIMA}(p,d,q)$, with $d>0$ to a series, you take $d$ differences of the series and fit a model for stationary data to the residuals. For cross validation to work as a model selection tool, you need approximate independence between the training and the test data. The problem with time series data is that adjacent data points are often highly dependent, so standard cross validation will fail. The remedy for this is to leave a gap between the test sample and the training samples, on both sides of the test sample . The reason why you also need to leave out a gap before the test sample is that dependence is symmetric when you move forward or backward in time (think of correlation). This approach is called $hv$ cross validation (leave $v$ out, delete $h$ observations on either side of the test sample) and is described in this paper. In your example, this would look like this: fold 1 : training [1 2 3 4 5h], test [6] fold 2 : training [1 2 3 4h h6], test [5] fold 3 : training [1 2 3h h5 6], test [4] fold 4 : training [1 2h h4 5 6], test [3] fold 5 : training [1h h3 4 5 6], test [2] fold 6 : training [h2 3 4 5 6], test [ 1] Where the h indicates that h observations of the training sample are deleted on that side.
