[site]: datascience
[post_id]: 25887
[parent_id]: 25883
[tags]: 
As a side note, you have not mentioned any regularisation parameters of xgboost, so I understand you donâ€™t use any. In general, it is not good and might lead to overfitting. Regarding your question, my hypothesis is that in your case xgboost classifier is simply more powerful than other two approaches and thus is more confident, which is indicated by higher probabilities assigned to particular classes. Maybe xgboost is even overconfident, i.e. overfits, but one cannot be sure without thorough testing on unseen test data.
