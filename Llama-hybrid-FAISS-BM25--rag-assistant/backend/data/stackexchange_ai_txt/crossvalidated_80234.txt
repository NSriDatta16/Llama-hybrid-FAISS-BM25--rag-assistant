[site]: crossvalidated
[post_id]: 80234
[parent_id]: 78291
[tags]: 
I think both options result in the correct answer. In general, I would prefer method 1 as that preserves the entire distribution. For method 1, bootstrap the parameter $k$ times within each of the $m$ MI solutions. Then simply mix the $m$ bootstrapped distributions to obtain your final density, now consisting of $k \times m$ samples that include the between-imputation variation. Then treat that as a conventional bootstrap sample to get confidence intervals. Use the Bayesian bootstrap for small samples. I know of no simulation work that investigates this procedure, and this is actually an open problem to be investigated. For method 2, use the Licht-Rubin procedure. See How to get pooled p-values on tests done in multiple imputed datasets?
