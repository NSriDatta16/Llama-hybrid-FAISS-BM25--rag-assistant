[site]: crossvalidated
[post_id]: 329956
[parent_id]: 264810
[tags]: 
This is essentially looking at different forecasting horizons, which is a very common exercise in forecasting. No, there is no commonly accepted error measure that takes horizons into account. What people typically do is calculate separate errors per horizon and then report those separately. The problem with calculating one grand unifying error or accuracy KPI is that it implicitly weights errors by how far out they are. How much worse is an absolute error of 5 at horizon $h_1$ compared to the same absolute error at horizon $h_2$? The problem mainly lies with the implicitness of this weighting. Much better to simply report errors by horizon and have the user decide which ones are how relevant. So you could calculate errors for predictions up to 10 minutes ahead, 10-20 minutes ahead, and so on. The added wrinkle in your case is what you do if your predicted and actual buckets do not match, e.g., you predict that the bus will arrive in eight minutes, but it actually does arrive in twelve. You might want to look at buckets organized both by predicted and actual waiting time and see whether there are any differences in what you see.
