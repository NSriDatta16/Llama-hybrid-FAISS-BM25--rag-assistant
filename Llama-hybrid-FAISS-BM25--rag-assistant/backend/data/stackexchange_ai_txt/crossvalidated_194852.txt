[site]: crossvalidated
[post_id]: 194852
[parent_id]: 
[tags]: 
Cost function: output layer should sum up to roughly 1

I have a convolutional neural network classifying some images for me. The output layer is not one-hot encoded but outputs a distribution around the predicted class (because neighboring classes are semantically related). For the learning step a perfect gaussian/normal distribution is feeded to the network - centered at the correct class ($y_{teach}$). My cost function is cross-entropy: $$-\bigr(y_{teach} * log(y_{out}) + (1 - y_{teach}) * (1 - y_{out})\bigr)$$ Before calculating the cross-entropy the output is softmax'ed but only for the learning step. The normal output of the output layer in a feedforward step is linear / "unfiltered". My hope was that the network not only generates activity bumps around the real classes ($y_{teach}$) but also tries to learn that the sum has to be roughly 1 in total. Unfortunately this doesn't really happen. The activity bumps are looking like a gaussian distribution in the first hundreds of epochs but with much noise. If I train for some thousands epochs the distributions reduce in noise and get really soft and nice but due to overfitting(?!) the bumps get really high..like an activation of 3 to 5 in one single class. So overall the network learns the right thing and predicts the right classes but the output layer does not sum up to 1 but to 100 or something like this after thousands of epochs (and this is not what I want, I want it to learn correct classes and that the sum of the output layer has to be roughly 1). How would I model my cost function to punish solutions which have a sum highly greater than 1? I thought of cross entropy plus something for punishing a sum greater one like this: $$-\bigr(y_{teach} * log(y_{out}) + (1 - y_{teach}) * (1 - y_{out})\bigr) + \bigr|1 - sum(y_{out})\bigl|$$ ...but now the network highly concentrates on the sum and more or less forgets about the distribution / classifier learning. Sometimes a nice distribution pops up but most of the time it just learns "crap" which sums up to 1. Any ideas?
