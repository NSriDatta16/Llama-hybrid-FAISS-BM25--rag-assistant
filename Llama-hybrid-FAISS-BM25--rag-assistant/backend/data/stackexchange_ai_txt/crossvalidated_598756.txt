[site]: crossvalidated
[post_id]: 598756
[parent_id]: 598749
[tags]: 
NB: Having just seen what looks like an extremely similar question on reddit, I suspect that your use of the word 'ratio' may be ambiguous/misleading; I assumed in my answer that by 'a ratio variable' you meant 'a variable which is a ratio of two other quantities' whereas I now suspect you meant a variable that would be considered ratio scale on Stevens typology (nominal/ordinal/interval/ratio). Further, I did not take your post to mean that it was the differences were skewed, but the original measurements. If either of those things is the case here, several parts of my answer don't apply or should alter. Can I still use parametric tests, or should I use non-parametric tests? Please note that you've likely been mislead about what these terms mean. Parametric tests do not in any sense imply that you're using a test that assumes a normal distribution. You might choose a test suited to a parametric distributional model that may be extremely skewed, and that would be a parametric test. https://en.wikipedia.org/wiki/Parametric_statistics The term is simply a reference to the number of unspecified parameters in the distributional model. If that number is finite and fixed (this doesn't preclude specifying some of them under H0 -- it's to guarantee that the number of parameters doesn't increase as the sample size increases, say), then it's a parametric model. You might well conclude that a t-test would be unsuitable but that doesn't preclude using some more suitable parametric model. There's two considerations here, and the CLT is really only somewhat related to one of them. It's not that you specifically want to use the central limit theorem; you're trying to ask whether using a t-test will still behave suitably when you're sampling from a very skewed population; that the CLT will likely apply doesn't answer that, since the CLT only talks about what happens in the limit when sample sizes go to infinity (and even then you'd need to use an additional theorem to deal with the fact that $s$ is not $\sigma$ ). (Edit related to your update: The skewness of the original variables is not particularly at issue, since you're doing a paired test... it's the distribution of pair-differences in the population you need to worry about; and specifically, that distribution when H0 is true when worrying about the significance level) The first of the two considerations (and often the only one people seem to pay attention to in this situation) is that you want the significance level to be very close to (or at the least, not much higher than) your chosen significance level in spite of the non-normality. The second issue relates to power. If the distribution is very non-normal your t-test might not have particularly good power properties (e.g. in that it would be easy to use a test with better power to detect a change). It's not really possible to say much about how much difference there would be for either, since your post contains little information, but generally if I have a ratio I wouldn't be using t-tests nor indeed, typically something based off pair-differences of ratios at all; I'd be inclined to consider ratios of ratios, or even differences of logs of ratios to measure deviation from equivalence. If I did stick to differences of ratios, I'd still be unlikely to use a paired t-test, though. If you're interested in testing means of differences of ratios nonetheless, you could always guarantee the significance level by using a permutation test but power may be quite poor compared to other choices. Note that if we assume no change in the distribution under the null, pair-differences of skewed variables will be symmetric; however, they may be quite heavy-tailed. This may result in some lowering of signficance level (a conservative test; again, power may be more of an issue), so even without the guarantee of a permutation test your significance level should at least tend to stay below the chosen type I error rate. I think a very careful consideration of (i) how the ratios would behave (rather than looking at the sample); (ii) what you want to find out (whether it's really related to a mean of differences of ratios) and how to best measure deviation from the null may help to choose a suitable model and/or test statistic.
