[site]: datascience
[post_id]: 126496
[parent_id]: 
[tags]: 
Why Prior VAE works very well on training but very suck in eval?

I'm doing a task with "Proir VAE" The Proir VAE Means it doing KL with a learned Prior encorder so that it can leverages it instead of normal distribution. And in inference time, it can generate latent z by this prior encoder. So my model looks like two encoder and one decoder. The loss is reconstruction loss and kl loss, The kl loss is based on mu and logvar of the two encoder. Loss Looks like this: mu1 and logvar1 is from post, mu2 and logvar2 is from prior. Heres my code: the encoder and decoder are all very simple three linear layer model.. So i didn't put them. class VAE(nn.Module): def __init__(self, cfg): super(VAE, self).__init__() self.representation_size = 32 self.encoder = AutoregressiveBoxEncoder(cfg['MODEL']['ENCODER']) self.decoder = AutoregressiveBoxDecoder(cfg['MODEL']['DECODER']) self.prior = Prior(cfg['MODEL']['PRIOR']) def sample(self, inference, mu1=None, logvar1=None, mu2=None, logvar2=None): std = torch.exp(0.5 * logvar1) eps = torch.randn_like(std) Z1 = eps.mul(std) + mu1 std2 = torch.exp(0.5 * logvar2) eps2 = torch.randn_like(std2) Z2 = eps2.mul(std2) + mu2 return Z1, Z2 def forward(self, x, condition, inference): mu1, logvar1 = self.encoder(x, condition) mu2, logvar2 = self.prior(condition) z1, z2 = self.sample(inference, mu1=mu1, logvar1=logvar1, mu2=mu2, logvar2=logvar2) pred_boxes = self.decoder(z1, condition) if not inference: pred_boxes = self.decoder(z1, condition) with torch.no_grad(): infe_boxes = self.decoder(z2, condition) sigma1 = logvar1.mul(0.5).exp() sigma2 = logvar2.mul(0.5).exp() kld = torch.log(sigma2/sigma1+1e-8) + (torch.exp(logvar1) + (mu1 - mu2)**2)/(2*torch.exp(logvar2)+1e-8) - 1/2 else: infe_boxes = self.decoder(z2, condition) kld = None return pred_boxes, infe_boxes, kld My model works pretty well on trainning part but really sucks on eval part. First of all, I think that's because I didn't add regularization term. But after that I realize that this is how SegVae do!!! They all didn't add regularization term. I'm really stuck at here, I can't understand why they work well in eval and test... without regularization term.
