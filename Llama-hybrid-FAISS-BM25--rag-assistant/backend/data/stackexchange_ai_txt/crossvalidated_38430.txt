[site]: crossvalidated
[post_id]: 38430
[parent_id]: 38419
[tags]: 
You have two major options: multilevel analysis that you must have been reading about; OLS with clustered standard errors (Peter Flom made a comment that OLS assumes that the errors are independent, but that assumption is easy to circumvent with the right choice of the covariance matrix estimator) Multilevel analysis surely is fancy and hot. That's also the reason it is misused a lot, because everybody seems to want to do something multilevel, no matter whether their data are suitable for it or not. My reaction to about 2/3 of the questions with this tag on this site is that the goals of the study (except for being published in a highly ranked journal, which is often THE goal of many studies) are better addressed by other methods. In multilevel analysis, you have to make strong assumptions: (i) that your random effects are normal (or, if you have random slopes as long as random intercepts, that the joint distribution is multivariate normal), (ii) that your model contains all relevant variables, so that you are safe assuming that errors and regressors are uncorrelated at all levels, (iii) you have enough observations at each level to really utilize the asymptotic theory results concerning the likelihood ratio test statistics and inverse of the information matrix as the estimator of the variances of the parameter estimates. These assumptions are swept under the carpet, most of the time, and rarely if ever checked. The methods that deal with them do exist, but they would require a Ph.D. in statistics to read them. There are also alternative Bayesian solutions which too require a solid stat sequence in Bayesian computing before you even dare to open these papers. OLS with clustered errors makes fewer assumptions: something like (ii) above, i.e., to be able to convince yourself that the regressors and errors are uncorrelated, and something like (iii), that you have enough clusters so that the variance-covariance estimate is obtained as a sum over sufficiently many independent terms. Note that you don't need to have asymptotics in terms of the number of observations per cluster, unlike multilevel models. An unpleasant side effect concerning OLS with clustered standard errors is that you may run out of degrees of freedom if you have a model with 40 variables and only 30 clusters. (Well if you have 30 clusters, you're screwed anyway.) An interesting feature of multilevel models is that they can address interactions between levels (e.g., how does the education and experience of a teacher affect the student gains?) It is messier, but possible, to address in OLS as well by explicitly constructing the interactions and using them as explanatory variables in your regression. With enough data, you can run both analyses and construct a Hausman specification test on the difference between the efficient estimator (multilevel model) and a less efficient and more robust estimator (OLS with clustered standard errors) for the parameters that both models estimate. Most of the time, I would trust the OLS with clustered standard errors more than I would multilevel analysis, frankly.
