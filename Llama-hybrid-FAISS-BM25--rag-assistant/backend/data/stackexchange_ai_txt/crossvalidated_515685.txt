[site]: crossvalidated
[post_id]: 515685
[parent_id]: 318930
[tags]: 
As I understand, performing nested CV means that you have two layers of CV, and you use each layer for one and only one thing: The outer layer, for estimating the quality of the models trained on the inner layer. The inner layer for selecting the best model (including parameters, hyperparameters and so on). One important distinction: in fact, you are not assessing the quality of the model, but of the procedure of model selection. What you are evaluating in the outer folds is that the procedure for model selection is consistent, so it does not mind that the hyperparameters are different (it should be better if they didn't differ much, but if the quality is comparable, it does not matter much). So, for each k-outer-fold, you will select one (and only one) inner model (the best one), trained on the training set for this k-outer-fold, and this model will be evaluated on the validation set for this k-outer-fold. After you vary the outer k, you will have k-outer estimates and you can average them to assess better the quality of the models. Another important thing: once you find the best hyperparameters for a particular loop, how can you select the model, if you have k-inner-folds models? You can do two things: create a new instance of the model with this parameters and fit it on the whole inner fold, or create an ensemble of all k-inner-fold models. Both can be ok. I have developed a Python package for practising nested cross validation. You might want to take a look. If you find it interesting, please tell me! Thanks in advance: https://github.com/JaimeArboleda/nestedcvtraining/blob/master/README.md
