[site]: datascience
[post_id]: 112645
[parent_id]: 112642
[tags]: 
There's too few different samples so XGBoost is unable to split the trees properly (you can check the actual trees using clf.get_booster().get_dump() ). Reducing the min_child_weight hyperparameter (e.g. clf = xgb.XGBClassifier(min_child_weight=0.5) ) should get you some traction.
