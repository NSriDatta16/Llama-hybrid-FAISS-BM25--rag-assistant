[site]: datascience
[post_id]: 115445
[parent_id]: 115416
[tags]: 
ROC curve is a parametric one. Each point has a respective third coordinate (classification threshold). The .predict_proba() method of sklearn models returns the class scores (the measure of a model's certainty of the prediction, or probability for well-calibrated models). By default, sklearn .predict() method predicts the class by comparing this score to 0.5 threshold. Neural network classifiers often similarly decide on the class by applying argmax to the scores. If we operate on scores directly however, we can try as much possible thresholds as there are unique score values (plus a zero one, which would classify everything as 1). Each possible threshold would yield a different confusion matrix. We start drawing the curve from the upper right (zero threshold), where most observations are classified as positive: that means perfect recall but also a high false positive rate. Towards the bottom left, more obervations are classified as negative: recall decreases, but so do false positives. A decent classifier with respect to this metric, obviously, should yield high recall and low FPR at at least some threshold.
