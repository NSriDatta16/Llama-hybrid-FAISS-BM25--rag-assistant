[site]: crossvalidated
[post_id]: 469187
[parent_id]: 
[tags]: 
Why is non-centered SVD accepted in LSA

In Latent Semantic Analysis (LSA) , we apply SVD to a term-document matrix $A$ , then choose to ignore all but $k$ largest singular values. The term-document matrix is not centered, or normalised, because we want to preserve sparseness of $A$ . Are there conditions under which the lack of centering is not considered a problem, given that it is known the results of PCA are misleading if the feature scales are different? (lots of good discussion here, e.g. How does centering make a difference in PCA (for SVD and eigen decomposition)? , PCA on correlation or covariance? ) Specifically, if $A$ were centered, we would be able to quantify how much variation is being lost for each choice of $k$ . Is it fair to say that, in LSA, $k$ is being chosen blindly?
