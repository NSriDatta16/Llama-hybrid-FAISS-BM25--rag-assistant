[site]: crossvalidated
[post_id]: 471679
[parent_id]: 
[tags]: 
Radiomics: Machine learning vs Classic Multivariate Statistics for small datasets and a lot of variables... which is better?

I'm currently working with radiomics in MRI for cancer diagnosis, and I need to solve a dilemma about the best approach to analyze my data, here's the problem: I have 80 patients with surgical resection of a tumor AND pre-surgical MRI images of the same tumor. Using python we are extracting a large number of image features: texture features, morphology features, intensity features, etc. In this particular case, we'll use 58 features , and we have two interest outputs: Malignancy (1/0) and percentage of fibrosis (measured on a continuous scale). A priori, I would solve this problem with ad-hoc classical statistic tools for the sample size: Classic regression and variable selection methods (I was planning to use dredge function of the R package MuMIn), setting the maximum number of possible variables in a model to 8-10 (for avoiding overfitting) and using corrected Akaike's Information Criterion for ranking models and selecting the best. Usually this would have been pretty straightforward, but for some reason I wasn't part of the project's initial planning and a couple of engineers that work with our team wrote the statistical analysis proposal: They proposed principal component analysis and Fisher's discriminant analysis for dimensionality reduction, and after that they wanted to use the best components within a Support vector machine algorithm for developing a predictive model. As I'm not a beginner with biostatistics nor machine learning, I'm having big concerns about the proposed approach (PCA, LDA, SVM) in this small dataset due to important overfitting issues with these techniques in small sample sizes. My problems: I haven't so much linear algebra background as an engineer for giving them really heavy arguments for avoiding the proposed approach (I'm an MD with an MSc in Health sciences research with focus on advanced statistics), and there is a lot of literature circulating in medical journals with approaches like this in small datasets without concerning on "spectacular" overtfitted results that have not applicability in real life. After some studying and research work, I would like to have more expert opinions about applying PCA and LDA on small datasets (80 individuals and 58 variables in this particular case), for taking a more informed decision (I've found a big heterogeneity of opinions on similar issues). What do you think guys? Thanks for your answers!!
