[site]: crossvalidated
[post_id]: 384883
[parent_id]: 
[tags]: 
Iterating Bayes rule over time

$\require{cancel}$ In a online bayesian inference procedure one is iteratively changing the prior with a new posterior, calculated given a new set of observations. Does it mean we capture time dependence in this manner? What actually changes, our belief about the system or the system itself? Can you say that time dependence emerges in our model from these sequential prior updates? EDIT Adding more rigor: Variables: $X$ - input, $Y$ - output, $\Theta$ - hidden parameters Observation $Y_i$ is independent of $Y_{i-1}$ given $X_i$ and $\Theta_i$ $(Y_i \bot Y_{i-1}|X_i,\Theta_i)$ Update rule for posterior is: $P(\Theta_{i+1}) = P(\Theta_i|Y_i,X_i) = \frac{P(Y_i|X_i,\Theta_i)P(\Theta_i)}{P(Y_i|X_i)}$ So we say that even if our model is time independent, time dependence can be captured implicitly within $X$ and $\Theta$ : $X_{i+1}\cancel{\bot} X_i$ and $\Theta_{i+1}\cancel{\bot} \Theta_i$ . Is it a correct assumptions to make?
