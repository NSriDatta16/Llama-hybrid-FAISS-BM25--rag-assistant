[site]: crossvalidated
[post_id]: 234683
[parent_id]: 234668
[tags]: 
In theory, this should not affect your ability to make predictions - after all, the only truly useless data would be a restated column (or a column whose values can be directly derived from some other - e.g. having radius and circumference in two columns). Just because your features are correlated does not mean they are not useful, in fact, this correlation could be valuable if your dataset is in fact representative of what is out there "in the wild". However, if your dataset is limited, then you may run into trouble, as highly correlated data will provide precious little extra information about the subject. PCA is a great candidate for this, as mentioned in the above comment. Random Forests are also promising, as they can inform you which columns play the biggest part in classifying your data. Gradient Boosting classifiers can also help with data that is resistant to classification by more elementary methods. At any rate, I'm curious to hear what your baseline is with basic classifiers!
