[site]: datascience
[post_id]: 5135
[parent_id]: 5119
[tags]: 
Naive Bayes is just one of the several approaches that you may apply in order to solve the Titanic's problem. The aim of the Kaggle's Titanic problem is to build a classification system that is able to predict one outcome (whether one person survived or not) given some input data. The survival table is a training dataset , that is, a table containing a set of examples to train your system with. As I mentioned before, you could apply Naive Bayes to build your classification system to solve the Titanic problem. Naive Bayes is one of the simplest classification algorithms out there. It assumes that the data in your dataset has a very specific structure. Sometimes Naive Bayes can provide you with results that are good enough. Even if that is not the case, Naive Bayes may be useful as a first step; the information you obtain by analyzing Naive Bayes' results, and by further data analysis, will help you to choose which classification algorithm you could try next. Other examples of classification methods are k-nearest neighbours, neural networks, and logistic regression, but this is just a short list. If you are new to Machine Learning, I recommend you to take a look to this course from Stanford: https://www.coursera.org/course/ml
