[site]: crossvalidated
[post_id]: 282042
[parent_id]: 
[tags]: 
Estimating error - residuals vs. fitted values plot

I just stumbled the residuals vs. fitted values plot which suppose to aid checking if the assumptions being made about the error $\epsilon$ hold. In particular: i. $\mathbb{E}\left[\epsilon\right]=0$ ii. $\forall\,\,i\,\,:\,\,Var\left(\epsilon_{i}\right)=\sigma^{2}$ (homoscedasticity) In order to check (i) we plot $y = 0$ and in order to check (ii) we examine if the spread of the dot's $y$ values changes as we move along the $x$ axis (assuming $e$ is an estimator for $\epsilon$). I wonder how it's even possible to get a plot that deviates from i + ii since from the mathematical construction of the OLS (with no statistical assumptions) we are assured that $\sum_{i}e_{i}=0$ - meaning the residuals will always average on $y = 0$, and $Cov\left(\hat{y},e\right)=0$ meaning we shouldn't see that a change in $\hat{y}$ effects $e$. This seems to make the Residuals Vs Fitted (RVF) plot tautological. I probably got wrong in the way, but not sure where.. Edit: A screen taken from lecture notes. From here it goes to plotting the RVF plot with the line $y=0$ to check if the mean of $e$ is centered around 0.
