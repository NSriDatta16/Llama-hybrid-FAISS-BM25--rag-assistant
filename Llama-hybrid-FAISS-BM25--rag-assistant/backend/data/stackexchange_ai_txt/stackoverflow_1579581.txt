[site]: stackoverflow
[post_id]: 1579581
[parent_id]: 710843
[tags]: 
Disclaimer: I am not a native English speaker nor an expert in the field, I am an amateur - expect imprecisions and/or errors in what follow. So, in the spirit of stackoverflow, don't be afraid to correct and improve my prose and/or my content. Note also that this is not a complete survey of automatic programming techniques ( code generation (CG) from Model-Driven Architectures (MDAs) merits at least a passing mention). I want to add more to what Varkhan answered (which is essentially correct). The Genetic Programming (GP) approach to Automatic Programming conflates, with its fitness functions , two different problems ("self-compilation" is conceptually a no-brainer): self-improvement/adaptation - of the synthesized program and, if so desired, of the synthesizer itself; and program synthesis . w.r.t. self-improvement/adaptation refer to Jürgen Schmidhuber's Goedel machines : self-referential universal problem solvers making provably optimal self-improvements . (As a side note: interesting is his work on artificial curiosity .) Also relevant for this discussion are Autonomic Systems . w.r.t. program synthesis , I think is possible to classify 3 main branches: stochastic (probabilistic - like above mentioned GP), inductive and deductive . GP is essentially stochastic because it produces the space of likely programs with heuristics such as crossover, random mutation, gene duplication, gene deletion, etc... (than it tests programs with the fitness function and let the fittest survive and reproduce). Inductive program synthesis is usually known as Inductive Programming (IP), of which Inductive Logic Programming (ILP) is a sub-field. That is, in general the technique is not limited to logic program synthesis or to synthesizers written in a logic programming language (nor both are limited to " ..automatic demonstration or language/taxonomy learning "). IP is often deterministic (but there are exceptions): starts from an incomplete specification (such as example input/output pairs) and use that to constraint the search space of likely programs satisfying such specification and then to test it ( generate-and-test approach ) or to directly synthesize a program detecting recurrences in the given examples, which are then generalized ( data-driven or analytical approach). The process as a whole is essentially statistical induction/inference - i.e. considering what to include into the incomplete specification is akin to random sampling. Generate-and-test and data-driven/analytical § approaches can be quite fast, so both are promising (even if only little synthesized programs are demonstrated in public until now), but generate-and-test (like GP) is embarrassingly parallel and then notable improvements (scaling to realistic program sizes) can be expected. But note that Incremental Inductive Programming (IIP)§, which is inherently sequential, has demonstrated to be orders of magnitude more effective of non-incremental approaches. § These links are directly to PDF files: sorry, I am unable to find an abstract. Programming by Demonstration (PbD) and Programming by Example (PbE) are end-user development techniques known to leverage inductive program synthesis practically. Deductive program synthesis start with a (presumed) complete (formal) specification (logic conditions) instead. One of the techniques leverage automated theorem provers : to synthesize a program, it constructs a proof of the existence of an object meeting the specification; hence, via Curry-Howard-de Bruijn isomorphism (proofs-as-programs correspondence and formulae-as-types correspondence), it extracts a program from the proof. Other variants include the use of constraint solving and deductive composition of subroutine libraries . In my opinion inductive and deductive synthesis in practice are attacking the same problem by two somewhat different angles, because what constitute a complete specification is debatable (besides, a complete specification today can become incomplete tomorrow - the world is not static). When (if) these techniques (self-improvement/adaptation and program synthesis) will mature, they promise to rise the amount of automation provided by declarative programming (that such setting is to be considered " programming " is sometimes debated ): we will concentrate more on Domain Engineering and Requirements Analysis and Engineering than on software manual design and development, manual debugging, manual system performance tuning and so on (possibly with less accidental complexity compared to that introduced with current manual, not self-improving/adapting techniques). This will also promote a level of agility yet to be demonstrated by current techniques.
