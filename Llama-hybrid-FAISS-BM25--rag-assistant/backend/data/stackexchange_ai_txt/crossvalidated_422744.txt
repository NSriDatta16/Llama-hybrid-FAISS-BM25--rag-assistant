[site]: crossvalidated
[post_id]: 422744
[parent_id]: 
[tags]: 
Loss magnitude showing 0 at first epoch yet predictions are completely off

I'm trying neural network for the first time. I'm getting a weird output - while loss magnitude is apporaching 0 at the first epoch itself, the predictions are trash! can some one explain what's going on. Here is the code I used - X_train, X_test, y_train, y_test = train_test_split(predictors, outcome, test_size=0.3, random_state=0) cs=StandardScaler() X_train_scaled = cs.fit_transform(X_train) X_test_scaled = cs.transform(X_test) l0 = keras.layers.Dense(units=5, input_shape=[30]) l1 = keras.layers.Dense(units=5,activation=tf.nn.relu) l2 = keras.layers.Dense(units=1) model=keras.Sequential([l0,l1,l2]) model.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(0.001)) history= model.fit(X_train_scaled, y_train,epochs=500,verbose=False)
