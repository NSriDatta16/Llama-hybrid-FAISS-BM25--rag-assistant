[site]: crossvalidated
[post_id]: 187900
[parent_id]: 187898
[tags]: 
It seems what you're trying to do is building an autoencoder (see here ), although I'm not sure what you mean by "dry" runs, I suspect you're just propagating the outputs as in normal backprop. What you could try, rather than setting your variables to zero when missing, is to create dummies from your variables (ie for an $X \in \{-1,1\}$, create two variables $X_1, X_{-1}$ with $X_{1} = 1$ if $X=1$, $0$ otherwise, and similarly with $X_{-1}$. Then missing values are simply the case where both are zero. This will increase dimensionality (doubles the number of variables), but as long as you are keeping a similar size for your hidden layer(s), it shouldn't matter. You could also try taking a look at Restricted Boltzmann Machines (see here ), which do a similar job for binary variables.
