[site]: crossvalidated
[post_id]: 569969
[parent_id]: 
[tags]: 
How to choose a fair gamma value when performing k-prototypes clustering?

In the k-prototypes clustering algorithm, the distance function consists of two dissimilarity components - one for the numerical elements of the observations, and one for their categorical elements. In pseudo-mathematical terms, we have: $$d(x, y) = d_1(x_{num}, y_{num}) + \gamma d_2(x_{cat}, y_{cat})$$ where $\gamma > 0$ is a weight that allows to favor more or less one of the two data types when building centroids. (Setting $\gamma$ =0 boils down to performing clustering on numerical variables only, whereas the greater the weight, the greater the impact of categorical variables on the final result.) In his introduction to k-modes and k-prototypes from 1998, Huang says the following: "Average standard deviation of numeric attributes may be used as a guidance in specifying $\gamma$ . [...] However, it is too early to consider this as a general rule." Have some clear mathematical results been found since then? How can I pick a $\gamma$ value so that my clustering procedure doesn't favor one data type over the other?
