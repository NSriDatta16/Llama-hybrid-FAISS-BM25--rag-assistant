[site]: crossvalidated
[post_id]: 614533
[parent_id]: 
[tags]: 
Machine learning regression using centered and scaled data

Imagine I have a large dataset of many variables and many observations. I would like to create a regression model to predict the values of new data. For the sake of ease, say I find a ridge regression model with some value $\lambda$ serves my needs best. For my model, I decided to center and scale (standardize) my data before fitting the model. I then divide my dataset into training values and testing values, the model is built on the training values. I then test my model using the testing values and I am satisfied with the outcome. Now, I observe a new observation and I don't know what the true outcome is, I decide to run it through the model I made. Before I feed the values into the model, I should 'standardize' this observation, correct? I.e. shift it by the mean of the data it was built on and then divide it by the standard deviation (not sure if this is correct, it is part of my question). Then I feed these values standardized values into the model and get an output, only I don't want the output in terms of being standardized, I want to be able to interpret it as it is 'naturally', I assume I multiply it by the standard deviation and then add the mean to it. I am unsure if this method is correct, can anyone offer some assistance with how we introduce new test values into standardized data?
