[site]: crossvalidated
[post_id]: 294929
[parent_id]: 
[tags]: 
How to estimate random-effects for new subjects for predictions (example in GNU R's lme4)

I'm wondering how to make predictions for new subjects from a fitted mixed-effects model (in a frequentist framework). Specifically, we have multiple observations on a set of subjects to which we can fit a mixed-effects model with subject-specific random-intercept and random-slope, across a range of time points (say 0-9). Now, we observe new subjects for a few initial time points (say 0-5). We want to make predictions for these new subjects at time points 6-9, using the fitted model. So, the steps I envisage are: Estimate a model using the first set of subjects, getting the fixed-effects and random-effect covariance. Using the fitted model, get estimates for the new subject random-intercept and random-slope on their observed data. Finally, make predictions for new subjects at unobserved times using their subject-specific random-effects. I'm unsure on how to proceed with step (2). I assume it would be possible to estimate the subject-specific random-effects using Maximum Likelihood (ML), and these estimates would be independent for each new subject - since we don't want any feedback from the new subjects into the inference for the model (step 2 should have no effect on step 1). However, it is typical to fit mixed-effects models in a Restricted Maximum Likelihood (REML) framework, since ML leads to biased estimated of the random-effects covariance... but will that be true for estimating a subject-specific random-effect conditional on the covariance, or is ML sufficient? For step (3), there is the obvious question of how much uncertainty will be propagated through this process. If we use ML to estimate the new subject-specific random-effects, we will be completely ignoring the uncertainty in the first model. We could bootstrap the whole process to get a distribution on the subject-specific random-effects. Plan B would be to switch to a Bayesian approach, although for now I'm interested in the frequentist version. To make this concrete, I present the following minimal working example using lme4 in GNU R and the in-built sleepstudy dataset R.Version()$version.string ## "R version 3.4.1 (2017-06-30)" library("lme4") packageVersion("lme4") ## ‘1.1.13’ library("merTools") packageVersion("merTools") ## ‘0.3.0’ data("sleepstudy") summary(sleepstudy) nlevels(sleepstudy$Subject) ## 18 subjects ## Fit model to "Observed" data (only 15 subjects) sleepstudy.reduced I've had a play with predict.merMod() , simulate.merMod() and predictInterval() from merTools -package, but I can't quite see how to use them to solve this problem. The next step, as I see it, would be to obtain the likelihood of observing the new subjects conditional on the fitted model.
