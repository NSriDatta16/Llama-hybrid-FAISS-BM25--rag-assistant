[site]: datascience
[post_id]: 62822
[parent_id]: 53512
[tags]: 
64 variables is a lot for linear regression and I'd worry deeply about collinearity, interdependen variables, etc. While a good basic assumption would be to go with the model with the fewest variables (adjusted R² being equal) I would urge you to go deeper here. Have you performed factor analysis or PCA on the predictor variables before, would a simplified model using components or factors perform stronger and be more interpretable? Regression really isn`t a good model to use if you just want to throw the bag at it. Depending on the motivation behind your problem (as @Spacedman pointed out) I would try more alternative models as well. E.g. why use RF only for feature selection, why not for the whole regression? If you aim for prediction and predictive quality R² wouldn't be your main metric to look at anyway and you could try more algorithms like XGboost as well.
