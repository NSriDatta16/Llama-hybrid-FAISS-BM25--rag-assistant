[site]: crossvalidated
[post_id]: 304118
[parent_id]: 303482
[tags]: 
The GAM, as represented in mgcv via penalized likelihood with quadratic penalties, is an empirical Bayes model. The penalties on splines can be thought of as improper Gaussian priors on (IIRC) variance parameters. If you use the $Xp$ matrix and draws from the posterior distribution of the parameter estimates you can generate draws from the posterior distribution. jagam() allows exactly the same thing to be done but using the full Bayesian machinery (via JAGs) and with proper priors on all aspects of the model. The Gibbs sampling approach employed in jagam() is not specifically designed for smooth model terms, so it is not the most efficient approach, but neither is bootstrapping GAMs. Software with samplers specially tailored to estimating GAMs would be more efficient such as BayesX and INLA, which have R interfaces.
