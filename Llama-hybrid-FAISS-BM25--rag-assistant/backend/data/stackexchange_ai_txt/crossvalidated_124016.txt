[site]: crossvalidated
[post_id]: 124016
[parent_id]: 
[tags]: 
Optimal Margin Classifer : Optimization Problem Setup

In the notes from Andrew Ng Machine Learning course, he writes the initial optimization problem as follows. I am confused by the notation and suspect I am missing something simple. Given the training set, it seems like $w$ and $b$ alone are sufficient to maximize the geometric margin $\gamma$, so why is $\gamma$ also listed under the arguments of the max operator? The thing being optimized for is also a parameter? What is the significance of the first constraint? Wont every functional margin be at least equal to or larger than the geometric margin given that the norm of $w$ is 1 and given that $\gamma$ is defined as
