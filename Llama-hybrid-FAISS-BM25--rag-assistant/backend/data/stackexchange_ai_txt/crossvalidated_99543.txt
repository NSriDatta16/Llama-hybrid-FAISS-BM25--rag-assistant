[site]: crossvalidated
[post_id]: 99543
[parent_id]: 
[tags]: 
How to prove the significance of features in classification?

I have a binary classification problem. I have extracted 500 features from a set of 5000 samples using my domain knowledge. In other words, I have got hand crafted features . I wish to prove that these features actually are enough for performing classification and they make the 2 classes of samples separable. i.e. When the samples are represented with these features, there is exists a (reasonable) decision boundary. Please advice on how I can prove this. Is there any statistically appropriate way of measuring the significance of the set of features as a whole (NOT the significance of individual features)? EDIT: Suppose if I observe that different families of classifiers such as kNN, DT, NB, ANN, SVM etc. (with 10 fold cross validation) offer reasonable accuracy, can I conclude that the features are meaningful?
