[site]: crossvalidated
[post_id]: 422672
[parent_id]: 
[tags]: 
Group level effects (odds ratio) - dummy coding vs. effect

I ran a logistic model in R 's brms , with a categorical variable (condition) with two levels as predictor. When interpreting the results, I realised I don't know how to deal with (the default) dummy coding $(0, 1)$ vs. effect coding $(-1, 1) or (-.5, .5)$ of my categorical variable. I know the intercept is that of condition $0$ for dummy coding, the mean of the two conditions for effect coding. And, as I understand it (I might be wrong here), the effect of the categorical predictor will be equivalent to switching from condition $0$ to $1$ for dummy coding (the intercept + the effect) and will denote the mean deviation from the (mean) intercept for sum coding. For deviation coding, I get the overall difference between the intercept of the two conditions. (At least this is my interpretation of this post .) However, I'm stuck regarding these matters: Group level effects How does the coding affect my random intercepts? Do I get the deviation of condition $0$ from its respective intercept with dummy coding? I.e. learn nothing about the variance of condition $1$ ? And, accordingly, get the overall deviation from the (mean) intercept of both conditions in the case of effect coding? Odds ratio Matters are complicated by the fact that my results are in odds ratio. I just tried dummy coding vs. effect coding, but the results slightly differ from what I expected. This will probably get clearer in the example below. Example and Output Using brms , I fit a model of the form dropout ~ cond + (1|ID) + (1|marker) , where dropout is the dropout rate in each trial ( family = bernoulli() ) and cond refers to the experimental condition, which could either be "mat" (mathematical) or "nonmat" (non-mathematical). I added group level effects in the form of random intercepts for each participant ( ID ) and each stimulus ( marker ). In the column dropout , 1 indicates a trial being considered for analysis, 0 indicates a dropped-out trial. The model output presented is already converted to odds ratio via exp() . Dummy coding (default) With the default dummy coding (i.e. brms automatically codes mat = 0 and nonmat = 1 ), I get the following output: .variable .value .lower .upper .width .point .interval 1 b_condnonmat 1.24 0.940 1.67 2.59 mean hdi 2 b_Intercept 42.6 24.4 78.1 2.59 mean hdi 3 sd_ID__Intercept 4.79 3.00 8.56 2.59 mean hdi 4 sd_marker__Intercept 1.38 1.00 1.72 2.59 mean hdi As I understand it, the odds of a trial being analysed (no dropout) are $42.6$ in the "mat" condition (i.e. $42.6 / (1 + 42.6) \approx 97.7 \%$ ). For the "nonmat" condition, the odds then change by the factor 1.24, meaning that the odds of a trial being analysed are $42.6 * 1.24 = 52.824$ in the "nonmat" condition ( $\approx 98.14 \%$ ). For the group level effects, I'd say that for each participant ( ID ) the odds of a trial being analysed in the "mat" condition vary, on average, by a factor of $4.79$ - but I'm unsure about that. Sum coding To check my assumptions, I coded "mat" as 1 and "nonmat" as -1 and ran the model again, which gives me: .variable .value .lower .upper .width .point .interval 1 b_cond 0.898 0.773 1.03 2.59 mean hdi 2 b_Intercept 47.7 27.7 86.2 2.59 mean hdi 3 sd_ID__Intercept 4.82 2.92 8.23 2.59 mean hdi 4 sd_marker__Intercept 1.39 1.01 1.74 2.59 mean hdi Here, my interpretation is that the odds of a trial being analysed, regardless of the experimental condition, are $47.7$ ( $\approx 97.95\%$ ). The condition means a deviation from these odds by the factor of $.898$ and since "mat" was coded as 1 , I assumed that I'd get to the odds of a trial being analysed in the "mat" condition with $47.7 * .898 = 42.8346$ . However, this is a slight deviation of the $42.6$ I got above. Am I making a mistake here or is this just due to rounding or slight deviations in the model fitting process? (I ran both models with the same seed.) Also, I don't know how to get to the odds for the "nonmat" condition in this case. The group level effects look slightly different in this model, but not much. I thought that in this model, they refer to the (overall) intercept, so for each participant ( ID ) the odds of a trial being analysed vary, on average, by a factor of $4.82$ . But since the estimates of the group level effects are so similar, I was wondering if they just happen to be similar for both coding types or if their interpretation is not affected by the coding of the predictor. I was also wondering if the coding changed the model fitting process ever so slightly (even though the seed was the same and it shouldn't matter in principle), which explains the different results. Deviant coding Lastly, I coded "mat" as .5 and "nonmat" as -.5 and ran the model again, which gives me: .variable .value .lower .upper .width .point .interval 1 b_cond 0.806 0.607 1.06 2.59 mean hdi 2 b_Intercept 48.2 27.0 86.2 2.59 mean hdi 3 sd_ID__Intercept 4.65 2.89 8.28 2.59 mean hdi 4 sd_marker__Intercept 1.40 1.02 1.76 2.59 mean hdi Since the intercept should have the same interpretation for sum and deviant coding, I assume that the mere change of the coding scheme also affects my model fitting process. Are there any guidelines for best practices? Any help for navigating through log land is much appreciated! Useful stuff I found The link mentioned above provides a great overview for the interpretation of different coding schemes - unfortunately, not for random effects. It does, however, mention this source where it gets evident that random effect interpretation does differ for different predictor coding schemes - it's just not clear to me how exactly.
