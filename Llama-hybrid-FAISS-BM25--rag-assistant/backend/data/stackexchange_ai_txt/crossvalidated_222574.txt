[site]: crossvalidated
[post_id]: 222574
[parent_id]: 
[tags]: 
Which approach is better in feature learning, deep autoencoders or stacked autoencoders

In order to extract some useful features from raw data (purely unsupervised tasks), we could use autoencoders. To me, there seem to be two approaches of training. We could do the training layer by layer and get a stacked auto encoder, say the raw data has 100 variables, the first autoencoder is developed using 50 hidden units. The resulting 50 activations are used as input for the second auto encoder, say using 10 hidden units. So now we have a stacked autoencoder and the 10 activations can be regarded as 10 new features for further use. Meanwhile, we could simply use a deep auto encoder architecture, and the architecture is like 100-50-10-50-100, where 50-10-50 are the hidden units in three hidden layers. Again, we could extract the 10 activations in the middle as new features. I am wondering what's the essential difference between these two approaches. Which one is better in learning features? Thanks in advance for any help.
