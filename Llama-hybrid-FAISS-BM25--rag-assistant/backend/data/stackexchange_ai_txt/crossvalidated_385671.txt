[site]: crossvalidated
[post_id]: 385671
[parent_id]: 385668
[tags]: 
It appears that both from your book, and Learning Bayesian Networks by Richard Neapolitan uses the same notations. I've never come across with the notation $I_P(..)$ while dealing with Bayesian Networks, but it turns out your book is not the only one. This notation simply means Independence in P (Neapolitan page ~29). For example, if $P(A|B)=P(A)$ , then $I_P(A,B)$ , which means $A$ and $B$ are independent . If $P(A|B,C)=P(A|C)$ (for all $a,b,c$ ), then $I_P(A,B|C)$ , which means $A$ and $B$ are independent conditioned on C . In your question, you ask for the conditional independences $I_P(A,B)$ and $I_P(A,C)$ , but according to the definitions there ask for usual independence, not conditional, which can still be referred as conditional independence on nothing . Anyway, either it is conditional or not, we have the full joint distribution and we can calculate any probability we want using the table. For example, a marginal and a two-variable joint can be calculated as follows: $$P(A=a)=\sum_b\sum_c{P(A=a,B=b,C=c)}$$ $$P(A=a,B=b)=\sum_c{P(A=a,B=b,C=c)}$$ A conditional probability can be calculated using Bayes Law: $$P(A=a|B=b)=\frac{P(A=a,B=b)}{P(B=b)}$$ $$P(A=a,B=b|C=c)=\frac{P(A=a,B=b,C=c)}{P(C=c)}$$ You just need to plug in the numbers and verify that $P(A,B)=P(A)P(B)$ for $I_P(A,B)$ for the first case, assuming it questions independence of $A$ and $B$ conditioned on nothing, based on the definitions in both books.
