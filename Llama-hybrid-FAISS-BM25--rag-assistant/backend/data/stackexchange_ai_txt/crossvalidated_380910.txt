[site]: crossvalidated
[post_id]: 380910
[parent_id]: 267944
[tags]: 
I think Jim's answer addresses all your points adequately, but I'll try to boil it down to the per-question points. 1) Are these two approaches appropriate and equally valid alternatives, depending on (non)normality? Definitely not. Regression, in general, seeks to describe the relationship between typical values of a random variable given known information. In their comment, whuber describes the (very different) purpose of the other two tests. 2) Even in case of non-normality, wouldn't a different GLM type be better than a combination of Wilcoxon rank sum tests and a Spearmanâ€™s rank correlation? (Not sure which type of GLM would be appropriate though, as the response is still continuous...gamma perhaps?) Definitely so. We would need more information about the variable to provide specific guidance. Residual plots are a good way to convey the presumed lack of normality. 3) In a GLM framework, aren't we worried about non-normality of residuals, rather than raw data (which is not always the same thing)? Correct. This is almost never the same thing. Residual plots are a good tool to explore this in linear regression. As Jim mentions, deviations from normality are not in and of themselves a great concern when you have a moderately sized sample and care only about the regression coefficients or mean predicted values. On the other hand, a more important condition that residual plots also allow you to assess is a mean value of zero for the residuals. If the residuals stray too far at times, it suggests the model may be misspecified. 4) Doesn't a GLM (generalized linear model) with "normal distribution and identity link" simply mean a general linear model (i.e. an ordinary linear model)? Not quite. A "general linear model" refers to a, well, general version of linear models. This generality also allows for multiple outcomes to be analyzed simultaneously. Generalized linear models only handle univariate outcomes. The normal-identity GLM could be described as "multiple linear regression". That makes it both a particular case of a GLM and of the general linear model. 5) Is this approach of using p-values from a full model (including all variables) appropriate, or would a variable selection (using AIC or similar) be more appropriate? A p-value only allows you to say whether a statistically significant difference was observed, not that it wasn't, but it fails at communicating anything beyond that. I suggest using the confidence intervals to describe the findings provided by the model, as they show the range of plausible values for the estimated parameters. Even if a variable is significant, a wide confidence interval can suggest that little useful information about that particular relationship was gleaned. Conversely, a non-significant variable with a narrow confidence interval suggests that the presumed relationship is either absent or small in magnitude. Using AIC for variable selection addresses a very different question. Selecting the AIC-best model will, on average, give you the model that makes the best predictions while also being as small as possible.
