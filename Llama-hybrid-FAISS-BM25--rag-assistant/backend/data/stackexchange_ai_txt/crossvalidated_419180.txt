[site]: crossvalidated
[post_id]: 419180
[parent_id]: 
[tags]: 
Validation loss much lower than training loss. Is my model overfitting or underfitting?

I am using a convolutional neural network to train a large set of spectral data, which has 653 classes. I am storing the loss values and the accuracy values per epoch in a list. the optimiser i am using is Adams with a learning rate=0.01. The loss function i am using is a weighted cross entropy loss function, and the test set was made using a leave one out scheme from the training data. I am normalising the losses by dividing them by number of samples in training and number of samples in validation, respectively. The other outputs i am printing every 5th epoch is as shown below:- What do you think might be happening here? Overfitting? Underfitting? Any and every help is appreciated.
