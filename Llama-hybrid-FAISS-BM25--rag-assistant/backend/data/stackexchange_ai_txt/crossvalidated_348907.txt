[site]: crossvalidated
[post_id]: 348907
[parent_id]: 348207
[tags]: 
There is no fundamental problem with having only censored data in your dataset, though if they are all censored at the same place you will not be able to differentiate between distributions with identical probabilities on either side of a single censoring point. Assuming you have censoring occurring at different points, you should be able to proceed using standard estimation techniques. Without loss of generality, I will assume you have a random split of data into a training set with $n$ data points and a test set with $m$ data points. Fitting your data on the training set: To facilitate your analysis, suppose your training set has $n$ data points with censored values $x_1, ..., x_n$ and corresponding indicators $c_1,..., c_n$, with $c_i=0$ for left-censoring and $c_i = 1$ for right-censoring. For an underlying Weibull distribution , this fully censored data yields the likelihood function: $$\begin{equation} \begin{aligned} L_{\mathbf{x}, \mathbf{c}}(k, \lambda) &= \prod_{i=1}^n F(x_i|k,\lambda)^{1-c_i} (1-F(x_i|k,\lambda))^{c_i} \\[6pt] &= \Big[ \prod_{c_i=0} F(x_i|k,\lambda) \Big] \Big[ \prod_{c_i=1} (1-F(x_i|k,\lambda)) \Big] \\[6pt] &= \Big[ \prod_{c_i=0} (1 - \exp(- (x_i/\lambda)^k) \Big] \Big[ \prod_{c_i=1} \exp(- (x_i/\lambda)^k) \Big]. \\[6pt] \end{aligned} \end{equation}$$ This likelihood function can be further simplified using the binomial expansion, and you can obtain estimates $\hat{k}$ and $\hat{\lambda}$ from your training data. This can be done via maximum-likelihood estimation, or Bayesian estimation, or other methods. Testing against the test set: Now suppose your test data contains $m$ data points with censored values $x_{n+1},...,x_{n+m}$ and corresponding indicators $c_{n+1},...,c_{n+m}$. The simplest test would be to treat the censoring values as fixed and test whether your training estimates give you reasonable predictions of which side of the censored value the observation falls (i.e., whether the data point is left-censored or right-censored). Based on your training set, you have estimated probabilities: $$\hat{p}_{n+i} \equiv \hat{\mathbb{P}}(c_{n+i} = 1|x_{n+i}) = 1-F(x_{n+i}|\hat{k},\hat{\lambda}) = \exp(- (x_{n+i}/\hat{\lambda})^\hat{k}).$$ You can compare these estimated probabilities against the observed values of $c_{n+1},...,c_{n+m}$ to see whether you are predicting the area where the variable falls correctly. This can be done by considering the $C$ values as Bernoulli random variables, and looking at your capacity to predict these accurately from your estimates from your training data.
