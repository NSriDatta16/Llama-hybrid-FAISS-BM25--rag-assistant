[site]: crossvalidated
[post_id]: 420991
[parent_id]: 7757
[tags]: 
Well, [0,1] is the standard approach. For Neural Networks, works best in the range 0-1. Min-Max scaling (or Normalization) is the approach to follow. Now on the outliers, in most scenarios we have to clip those, as outliers are not common, you don't want outliers to affect your model (unless Anomaly detection is the problem that you are solving). You can clip it based on the Empirical rule of 68-95-99.7 or make a box plot, observe and accordingly clip it. MinMax formula - (xi - min(x)) / (max(x) - min(x)) or can use sklearn.preprocessing.MinMaxScaler
