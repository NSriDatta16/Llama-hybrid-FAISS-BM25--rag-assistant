[site]: crossvalidated
[post_id]: 339736
[parent_id]: 
[tags]: 
Perform cross-validation on train set or entire data set

I am a bit confused concerning how I should perform cross-validation to evaluate a statistical learning model. If I have a data set of 500 observations, should i divide it in a train and test set with for example 375 (75%) train observations and 125 (25%) test observations, and perform cross-validation on the train set? Or should I perform the cross-validation on the entire data set? So long as the aim of performing cross-validation is to acquire a more robust estimate of the test MSE, and not to optimize some tuning parameter, my understanding is that you should use the entire data set. The reason for this is that you would not acquire a model that you can use to predict on unseen test observations, just a measure of MSE for the train set where cross-validation is performed. If I am mistaken, how could I use the cross-validation result to predict out of sample observations? Could someone be kind and clarify this for me? If relevant, the problem I am solving is performing cross-validation to assess the model performance of a random forest model in R. Thanks in advance!
