[site]: crossvalidated
[post_id]: 265247
[parent_id]: 
[tags]: 
Evaluating Models with Multiple Pieces in a Bayesian Framework

So, I'm trying to think about how to evaluate models composed of more than one equation in a Bayesian context. For example, consider the following as 'how the world works': $y2_i \sim dpois(\lambda_i)$ $log(\lambda_i) = \beta_0 + \beta_1 * y1_i$ $y1_i \sim dbinom(15, p_i)$ $logit(p_i) = \beta_3 + \beta_4 x1_i$ Now, as a researcher, say I collect data from this system for x1, y1, and y2. I'll even fake some for the purposes of evaluation: set.seed(609) testDF Now, let's say I have two alternate hypotheses. I'm going to leave off distributional forms and nonlinearities as I talk about them for the sake of ease of communication Model1: y1 ~ x1 y2 ~ y1 versus Model 2: y1 ~ x1 y2 ~ x1 + y1 So, a model with full versus partial mediation. And I want to evaluate them. In a linear normally distributed world, I could compute the covariance matrix of the data and use either likelihood or bayesian techniques to fit both models, evaluate the discrepancy between the modeled and observed covariance matrices, and based on that discrepancy compare model 1 versus model 2. Heck, I could even come up with a model 3 with, say, only a direct effect from x1 to y2 and compare all three using information criteria (AIC or WAIC). However, there's another approach to this problem - one that is flexible to error distributions and can accommodate mixed model approaches - graph theoretic Structural Equation Modeling, as outlines by Pearl, Jim Grace, Bill Shipley, and elegantly implemented by Jon Lefcheck's piecewiseSEM package. At the core of model evaluation, one evaluates the missing paths in a model (it's basis set). There are a well developed set of frequentist techniques for model evaluation using the evaluation of these missing paths that boil down to calculating a test statistic from the p-values of each element of the basis set. Bill Shipley has shown that this matches a likelihood, and as such can be used for the creation of an AIC. Once we abandon a frequentist approach, though, I'm at a loss of where to go next in terms of evaluation in a Bayesian context. True, we can look at the weight of a posterior for each element of a basis set that is opposite in sign to its point estimate (a Bayesian p-value), but, I'm at a loss as to how to translate that into an evaluation of model fit, or how to translate that into multi-model comparison. Or, is there a way to use the posterior likelihoods of each element of a single model to construct something for model comparison? Note, I feel like there is something obvious I'm missing by virtue of not having spent enough time in the Bayesian world yet, so, I'm open to "hey, bonehead, it's this!" answers. Perhaps to be practical, here's the two fit "models" to use for any dialogue. library(rstanarm) #model 1 mod1_eqn1_stan I'd love to hear any thoughts on how to compare these two (or more) models, bearing in mind that I'm trying to generalize up to models that are larger and hairier than these! References piecewiseSEM package - https://cran.r-project.org/web/packages/piecewiseSEM/README.html Bill Shipley's on evaluating equation-level estimation of SEMs - http://onlinelibrary.wiley.com/doi/10.1890/08-1034.1/full and http://onlinelibrary.wiley.com/doi/10.1890/12-0976.1/full Jim Grace's paper on graph theoretic approaches to SEM - http://onlinelibrary.wiley.com/doi/10.1890/ES12-00048.1/abstract
