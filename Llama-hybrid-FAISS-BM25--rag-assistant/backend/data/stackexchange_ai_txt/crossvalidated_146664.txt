[site]: crossvalidated
[post_id]: 146664
[parent_id]: 
[tags]: 
ARX model selection

I have an autoregressive model with exogenous variables: $S_{t} = \sum_{i=1}^{p} a_i S_{t-i} + \sum_q \sum_{i=1}^{r} b^q_i X^{q}_{t-i}$ where $S_t$ is the signal I want to predict and $X^q_t$ the qth external variable at lag $t$. I have three years of data ($S$ and $X$) and now I'm trying to predict the signal $S$ for the fourth year. For that I have in real time the $X^q_t$ time series but no $S_t$. So I have fitted the best $ARX(p,r)$ for the first three years, and use this lag configuration to predict the fourth year, where for it I assume that the first $p$ signal lags are zero, i.e., $S_1,S_2,...,S_p =0$. So, my question is: which criteria should I use to choose the best $(p,r)$ configuration? I tried to calculate AICc using: $AICc = NObs*ln(RSS/NObs)+2K+\frac{2K(2K+1)}{(NObs-K-1)}$ where $NObs$ is the total number of points I have for the first three years, $K$ the total number of parameters from $ARX(p,r)$ model and $RSS$ the residual sum of squares for the first three years. The problem is that the lowest resulted AICs values (which in fact are negative) are for a $(p,r)$ configuration that is clearly overfitting the problem. EDIT: The time granularity is weekly and it is "clearly overfitting" because the $RSS$ for the training set (first three years) is of order $10^{-7}$, i.e., there is a perfect fit, but the prediction is very bad. $NObs=27+37+37=101$
