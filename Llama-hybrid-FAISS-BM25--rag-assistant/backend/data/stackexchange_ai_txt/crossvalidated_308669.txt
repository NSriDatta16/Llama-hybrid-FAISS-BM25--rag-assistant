[site]: crossvalidated
[post_id]: 308669
[parent_id]: 
[tags]: 
Robust PCA vs. robust Mahalanobis distance for outlier detection

Robust PCA (as developed by Candes et al 2009 or better yet Netrepalli et al 2014 ) is a popular method for multivariate outlier detection , but Mahalanobis distance can also be used for outlier detection given a robust, regularized estimate of the covariance matrix . I'm curious about the (dis)advantages of using one method over the other. My intuition tells me that the greatest distinction between the two is the following: When the data set is "small" (in a statistical sense), robust PCA will give a lower-rank covariance while robust covariance matrix estimation will instead give a full-rank covariance due to the Ledoit-Wolf regularization. How does this in turn affect outlier detection?
