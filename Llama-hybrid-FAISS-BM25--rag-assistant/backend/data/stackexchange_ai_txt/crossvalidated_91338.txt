[site]: crossvalidated
[post_id]: 91338
[parent_id]: 
[tags]: 
$p(D)$ in Bayesian Statistics

Say I have the following obvious Bayesian computation: $$ p(\theta|D) = \frac{p(\theta) \cdot p(D|\theta)}{p(D)} $$ where $\theta$ is a model parameter that we try to infer and $D$ is observed data . I have always understood $p(D)$ to relate to knowledge that we have about the data $D$, but this concept has always been somewhat abstract. Many texts for example, simply ignore $p(D)$. Moreover, quite often, $p(D)$ is referred to as a normalizing constant . But if this is the case, why write $p(D)$ ? Is it always the case that $p(D)$ is a constant?
