[site]: datascience
[post_id]: 122604
[parent_id]: 
[tags]: 
What is the best way to approach anomaly detection on a data set using machine learning?

I am looking to help on where to start exploring machine learning when it comes to data processing. Say I have the following csv file with hundreds of thousands of rows of data: ID Amount Overdue (days) 1 2,140 6 2 3,183 8 ... ... ... Every day I read in a csv with this data. I would like a way to verify if there are any anomalies in the data before ingesting it into my database. For example, if the days overdue column is traditionally within a range of 3-9, how can I detect if one of the rows of data actually has a day that is 150 days? The reason I am thinking machine learning for this process is that overtime the values - ie. amount, overdue (days), etc - will change and can change significantly. What would be the best approach to solving this problem?
