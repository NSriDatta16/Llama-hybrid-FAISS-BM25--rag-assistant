[site]: stackoverflow
[post_id]: 3243227
[parent_id]: 
[tags]: 
"Crawl" a page / site for keywords

Last year I dabbed in a bit of perl programming. The first thing I wrote was a simple script that took a web page and found out how many times a word or name was on that page. I refer to this as "crawling" is that correct?. I was wondering If this is a native process for other languages like PHP and ROR. Essentially I want to build my own "API" for a site without a public "API" and possibly pass in the keywords dynamically from another "API" from another site (just for reading and organizing public data). Sorry for the high level of abstraction my head has just been in the clouds lately.
