[site]: crossvalidated
[post_id]: 155862
[parent_id]: 155855
[tags]: 
Tweedie distributions are a family of probability distributions which include the purely continuous normal and gamma distributions, the purely discrete scaled Poisson distribution, and the class of mixed compound Poisson–gamma distributions which have positive mass at zero, but are otherwise continuous. For any random variable Y that obeys a Tweedie distribution, the variance var( Y ) relates to the mean E( Y ) by the power law, $$\text{Var}(Y) = a[E(Y)]^p$$ where a is a scaling parameter and p the tail index parameter. They include a number of distributions, each being specified by the domain of p : normal distribution, p = 0, Poisson distribution, p = 1, compound Poisson–gamma distribution, 1 p gamma distribution, p = 2, positive stable distributions, 2 p inverse Gaussian distribution, p = 3, positive stable distributions, p > 3, and extreme stable distributions, p = ∞ For 0 p ( Wikipedia ) Tail indexes can be estimated via standard metrics such as the Hill and Pickands esimators but Xavier Gabaix's heuristic using OLS regression and log-ranks is pretty straightforward and has the advantage of not requiring numerical integration. See http://en.wikipedia.org/wiki/Tweedie_distribution for a general overview of Tweedies and Gabaix and Igragimov, RANK−1/2: A SIMPLE WAY TO IMPROVE THE OLS ESTIMATION OF TAIL EXPONENTS , 2009 All of that said and specifically wrt the issue of logistic regression residual diagnostics, I am aware of only one paper that treats this topic in any depth. It's by Daryl Pregibon and is titled simply Logistic Regression Diagnostics . https://projecteuclid.org/euclid.aos/1176345513
