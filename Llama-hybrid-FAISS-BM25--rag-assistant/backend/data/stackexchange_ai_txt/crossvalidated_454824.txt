[site]: crossvalidated
[post_id]: 454824
[parent_id]: 454768
[tags]: 
Actually, I think I figured it out. When the images are padded, the black area (the background) becomes larger. This area should be relatively easy for the autoencoder to learn how to recreate. Therefore, the average loss per pixel decreases, since the number of pixels increases but the difficulty does not increase. This is also confirmed by noting that the total loss (loss x number of pixels) on the original images was 0.099*28* 28 = 77.6, while the total loss on the padded images was 0.075*32*32 = 76.8, so even though one loss value was larger than the other, the actual loss was more or less the same. In other words, padding did not improve the autoencoder, but it modified the loss function, making the result at first seem better with padding than without.
