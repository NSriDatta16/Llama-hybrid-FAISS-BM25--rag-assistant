[site]: datascience
[post_id]: 47828
[parent_id]: 47809
[tags]: 
units : According to the official docs, it defines the output dimensionality. In simple words, the number of LSTM units which will be used. units: Positive integer, dimensionality of the output space. Units are nothing but the LSTM cells which will be used to process the inputs. stateful : According to the docs : stateful: Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch. If this argument is set to False then, the states or the memory of the LSTM cell will get reset at every sample which is passed through it. It follows this manner: Take a sample from the batch. The sample will pass through the LSTM and produce a state vector ( conditional memory ). The output is given If stateful=True then, the state vector will be used as the initial state for the 2nd sample. If stateful=False then, a new state vector will be used for the 2nd sample. Hence, the memory should migrate from one sample to another is decided by the stateful argument. unroll : According to the docs, unroll: Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences. It can thought as : RNNs, once unfolded in time, can be seen as very deep feedforward networks in which all the layers share the same weights. ( Deep Learning, Nature, 2015 ) You can read an excellent article here . The unrolling will the make the LSTM, a deep feed forward network which has shared weights. You can see and understand through this figure.
