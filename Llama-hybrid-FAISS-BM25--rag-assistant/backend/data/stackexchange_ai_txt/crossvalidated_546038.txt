[site]: crossvalidated
[post_id]: 546038
[parent_id]: 
[tags]: 
Optimizing stochastic loss functions informed by bayesian inference

Recently, I've been working on a design that uses Bayesian parameter estimation in conjunction with black box optimization. I haven't seen/read much about this approach so I'm not sure if it's principled or misguided. Say that I'm interested in choosing the best $\theta$ such that $p(y|x,\theta)$ maximizes a reward or minimizes loss where $\theta$ could represent one (or more latent parameters.) The general flow is use: Use Bayesian software (PyMC3, Stan, etc) to estimate $p(y|x,\theta)$ . Using the posterior chain derived, design a loss function, such that instead of using point estimates (like the mean), draw parameter values randomly from the posterior chain. Use any optimization algorithm (Bayesian optimization, genetic algorithm, etc.) such that given the sampled reward function from step 2. In my experience, this design has worked well. Rather than optimizing $\theta$ to maximize a reward signal / minimize a loss function based on a point estimate, the stochastic nature of using posterior chain parameter samples enables the optimization algorithm to get a sense for the variance around the optimal value. I'm curious, has anyone done this sort of design (Bayesian inference -> sampled loss function parameters -> optimization algorithm?) Are there any reasons why this might not be a good idea? Edit in response to request for clarification: Recently, I've worked on replicating results from a Google 2017 paper where they used carryover and saturation effects in a media mix model. In plain English, they learn for any given marketing channel, they infer the amount of spend that results in saturation (ie excess spend results in diminishing returns) and they model the time component (marketing spend today might reach peak consumer influence in x days.) The authors choose a bayesian inference design, however, a frequentist one likely could have been used instead. I give the above context because the reward function is not directly observed, it's latent and inferred through statistical inference. Simply using the mean saturation and carryover effect parameters is certainly one approach; it would create a discrete reward signal; but in my option this marginalizes a lot of the information gained via bayesian inference (the posterior samples.) So my solution was to draw from the saturation and carryover posterior chain in each optimization iteration to get a more holistic view of the parameter space when optimizing.
