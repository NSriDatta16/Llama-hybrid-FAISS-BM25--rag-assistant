[site]: datascience
[post_id]: 28604
[parent_id]: 
[tags]: 
Reinforcement Learning (Q Learning)

I was reading a paper on traffic flow optimization using Multi-Agent Q learning. the paper proposes the following method: Deploy a Reinforcement learning controller at each intersection with traffic lights. first the Q value equation is: $Q^{t}(s,a) = (1- \alpha )Q^{t-1}(s,a) + \alpha (R{t} + \gamma max_{a}(Q^{t-1}(s,a))$ second the state is: the sum of vehicle queues lengths at the current intersection and one hop intersections third the action space is: here the actions represent the possible moves of vehicles at the intersection. forth the reward at time t is $R^{t} = -( w_1\sum q_{current intersection} + w_2\sum q_{neighbors} )$ where the q refers to vehicle queues lengths, w1 and w2 are constants. fifth there is the algorithm in the image below where it acquires the action required for maximizing the Q value What I am trying to understand is, the reward calculation does not take an action as a parameter. How does it choose an action properly. I am a newbie to reinforcement learning, so please if you find my question naive, cosedire referring me to a proper textbook. Thanks
