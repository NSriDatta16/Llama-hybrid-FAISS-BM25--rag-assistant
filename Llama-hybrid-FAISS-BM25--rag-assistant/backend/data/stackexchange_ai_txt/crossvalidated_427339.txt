[site]: crossvalidated
[post_id]: 427339
[parent_id]: 
[tags]: 
How can one implement PCA using gradient descent?

I have to implement PCA using gradient descent and stop at convergence. I am not able to find the objective function. I know that the aim of PCA is to reduce the $n$ -dimensional matrix to $k$ dimensions (where $k ). I need to find $k$ such that the ratio of the average squared projection error to total variance is $\leq 0.01$ (as we need to minimise average squared projection error and maximise the spread of data). I am confused. Do we need to find $k$ or do we need to find the dimensionally reduced matrix as an output to gradient descent algorithm? Also, I need help with the objective function. I am stuck since yesterday and am not able to move.
