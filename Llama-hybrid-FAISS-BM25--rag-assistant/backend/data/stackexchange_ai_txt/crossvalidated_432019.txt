[site]: crossvalidated
[post_id]: 432019
[parent_id]: 431990
[tags]: 
An SVM learns the parameters $a$ , $b$ , $c$ and $d$ of a separating hyperplane in the new space $\phi(\mathbf{x}) = \phi(\begin{pmatrix} x_1 \\ x_2 \end{pmatrix}) = \begin{pmatrix} x_1^2 \\ \sqrt{2}x_1x_2 \\ x_2^2 \end{pmatrix} = \begin{pmatrix}X\\Y\\Z\end{pmatrix}$ , which has an equation of the form $aX+bY+cZ=d$ . Take the particular case where $a=c=1$ and $b=0$ , you obtain (with variables from the input space) the equation of a circle of radius $\sqrt{d}$ and center $(0, 0)$ : $x_1^2 + x_2^2=d$ . According to your figure, choose $d\approx0.7^2$ , and this hyperplane should separate your data. Note that the SVM will probably not learn exactly these particular parameters ( $a=c=1$ , $b=0$ , $d=0.7^2$ ). Based on the form of the kernel space, the SVM separating plane could be ellipses, hyperbolas or parabolas (see: https://en.wikipedia.org/wiki/Conic_section#General_Cartesian_form ). However the SVM will learn the curve that separates the data with the larger margin. So probably that the result of your SVM should be an ellipse close to a perfect circle (with the center exactly in $(0, 0)$ because you don't have terms in just $x_1$ or $x_2$ in the equation of the ellipse, and according to this page: https://en.wikipedia.org/wiki/Ellipse#General_ellipse ), and with radius between $0.6$ and $0.8$ or something like that (this is just by looking approximately on your figure).
