[site]: datascience
[post_id]: 101836
[parent_id]: 93066
[tags]: 
I had the same question, and according to this link : Grey represents the categorical values which cannot be scaled in high or low. Concerning the other questions, I found this link: https://github.com/slundberg/shap/issues/960 Where slundberg states: In the linear model SHAP does indeed give high importance to outlier feature values. For a linear (or additive) model SHAP values trace out the partial dependence plot for each feature. So a positive SHAP value tells you that your value for that feature increases the model's output relative to typical values for that feature. For example if you have systolic blood pressure of 150, the average BP is 120 and higher blood pressure is bad for you then you will get a positive SHAP value because your BP is worse than average. But if you have a BP of 110 you will get a negative SHAP value because your BP is better than average (lowers your risk relative to average). SHAP values tell you about the informational content of each of your features, they don't tell you how to change the model output by manipulating the inputs (other than what would happen if you "hide" those feature values). To know how the model will change as you change the inputs you would need to trace out a dependence_plot of many SHAP values.
