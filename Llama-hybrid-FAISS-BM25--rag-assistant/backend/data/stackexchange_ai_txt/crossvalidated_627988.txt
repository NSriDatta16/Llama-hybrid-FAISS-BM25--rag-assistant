[site]: crossvalidated
[post_id]: 627988
[parent_id]: 627982
[tags]: 
An activation function alone does not make a neural network into a GLM. There are three defining features of a GLM: The loss function. A GLM maximizes the likelihood of a probability model, so to make a NN into a GLM, we need to optimize the same function. No hidden layers. A G L M is a linear model, so our NN must also be a linear model. The link function. GLMs use a link function to relate the linear predictor to the likelihood, and we need the NN to match that. Here's an example of how to put these facts together to make a logistic regression NN. Is logistic regression a specific case of a neural network? And a general recipe for getting losses that correspond to exponential family losses, such as those used in GLMs How to construct a cross-entropy loss for general regression targets? But no particular regression model is a "general GLM," so there is no neural network that corresponds to a "general GLM."
