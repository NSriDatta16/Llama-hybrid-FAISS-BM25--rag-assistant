[site]: crossvalidated
[post_id]: 229634
[parent_id]: 
[tags]: 
Markov process with future knowledge

Let's say we have a discrete-time Markov chain with a transition matrix $P$. If we know the initial state $x_0$, we can predict the probabilities of future states by iterating the chain as $x_{t+1}$ = $x_t P$. But what if we know $x_0$ and also some future state $x_k$? What can we say about the probabilities of states $x_1..x_{k-1}$? Besides direct answers, I would appreciate pointers to relevant literature. My Google search was fruitless, probably because I don't know what to look for.
