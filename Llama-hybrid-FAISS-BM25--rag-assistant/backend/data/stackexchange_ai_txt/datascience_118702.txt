[site]: datascience
[post_id]: 118702
[parent_id]: 118644
[tags]: 
A simple one-way encoding (a hash) is very sensitive to noise. So where ML would come in is feature extraction: trying to extract the strong signal from an image and not any of the noise. But you are very unlikely to be able to do this perfectly. I believe even for the much-studied MNIST data set, state of the art is less than 100% (though there are a few mis-labelled examples, which doesn't help). BTW, another challenge is you will have very few data samples per label - you are going to have something like 60,000 iris photos for 55,000 people I imagine? Compared to MNIST with 60,000 samples for just 10 labels. Instead what you do is a nearest-neighbor search. So, your CNN (or whatever ML model you use) can give you say a 256-dim embedding instead of predicting a label. And then you use that to search your iris database, to find the closest match. If you search for approximate nearest neighbor search you will find a range of competing options. (The "approximate" is needed, because doing it naively is O(NÂ²) in the number of entries in your database.) Or for a more novel approach, A Neural Corpus Indexer for Document Retrieval is an interesting paper I read recently, which is doing something similar to what you want to do, though in the NLP domain. They are taking some features, and want to produce the document ID directly. There may be some ideas there.
