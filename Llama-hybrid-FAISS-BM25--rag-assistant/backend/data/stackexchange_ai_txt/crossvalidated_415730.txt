[site]: crossvalidated
[post_id]: 415730
[parent_id]: 415723
[tags]: 
The p-value of a relevant variable is not usually a good criteria to use for determining which predictor variables remain in a model. Ask yourself whether the information the variable carries is or should be an important contributor to the accuracy of your predictive statistical model. If the variable carries information essential to the model, I keep it. If you don't you could affect your pattern of effects and increase your error, thereby reducing your model's predictive ability. A way to more empirically determine whether a variable improves prediction of a model is to compare 2 models: 1 with and 1 without the variable in question in terms of their Akaike Information Criteria (AIC) and/or their Bayesian Information Criteria (BIC). Both of these information criteria work like a golf score: lower numbers are better and the numbers are somewhat arbitrary units that are only comparable if the two people you are comparing were playing on the same golf course. Lower AIC and BIC values are better and you can only compare models which analyzed the EXACT same dataset. AIC is more liberal and BIC is fairly conservative and penalizes models with higher complexity more than AIC. A meaningful change in AIC or BIC score is about 8. For example, if a model has and AIC of 3440 and another model of the same data has and AIC of 3432, the second model would be considered by most to be a model that better fits the data and, thus, is more accurate. Omitting a fixed (main) effect and keeping an interaction that includes the omitted variable creates a model with nesting in its structure. If the nesting has actually occurred, this is fine, but if it has not, your estimates will be affected. It doesn't seem to me like you have nesting here. But you could and I am less familiar with your data, so it is worth reading into more. Make sure your dummy variable is treated as a factor (two-level categorical variable) in your model. If it is being treated as a continuous variable (a number) this could generate the singularity you speak of. I would advise reporting back with an edit after you try that and see if it resolves your error. This way we know it is due to one of the predictor variables and not something intrinsic to your dataset. edit: If the variable was not treated as a factor in your previous analyses, your coefficient estimates and significance values may change.
