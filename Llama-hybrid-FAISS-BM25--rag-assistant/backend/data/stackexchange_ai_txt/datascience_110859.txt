[site]: datascience
[post_id]: 110859
[parent_id]: 110834
[tags]: 
You can create a sort of encoder-decoder network with two different inputs. latent_dim = 16 # First branch of the net is an lstm which finds an embedding for the (x,y,z) inputs xyz_inputs = tf.keras.Input(shape=(window_len_1, n_1_features), name='xyz_inputs') # Encoding xyz_inputs encoder = tf.keras.layers.LSTM(latent_dim, return_state=True, name = 'Encoder') encoder_outputs, state_h, state_c = encoder(xyz_inputs) # Apply the encoder object to xyz_inputs. city_inputs = tf.keras.Input(shape=(window_len_2, n_2_features), name='city_inputs') # Combining city inputs with recurrent branch output decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, name = 'Decoder') x = decoder_lstm(city_inputs, initial_state=[state_h, state_c]) x = tf.keras.layers.Dense(16, activation='relu')(x) x = tf.keras.layers.Dense(16, activation='relu')(x) output = tf.keras.layers.Dense(1, activation='relu')(x) model = tf.keras.models.Model(inputs=[xyz_inputs,city_inputs], outputs=output) optimizer = tf.keras.optimizers.Adam() loss = tf.keras.losses.Huber() model.compile(loss=loss, optimizer=optimizer, metrics=["mae"]) model.summary() Here you are, of course I inserted random numbers for layer, latent dimensions, etc. With such code, you can have different features to input with xyz and city features and these have to passed as arrays. Of course, to predict you have to give the model "xyz_inputs" and city features of the one you want to predict.
