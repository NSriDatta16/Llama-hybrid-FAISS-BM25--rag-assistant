[site]: crossvalidated
[post_id]: 361582
[parent_id]: 
[tags]: 
Logistic Model with Natural Response

Good Night to you all folks! I'm trying to fit a logistic regression model with a logit as link function to a set of data adding a parameter for a natural response (succes probability witout treatment). I'm trying to do the job with ML estimation, but don't really know how to include de dependence between $\vec\beta$ and $\pi$. Especifically, the set of observations have a binomial distribution and so the likelihood on $\vec\beta$ is: $$ L(\vec\beta) = \prod^{n}_{i=1}{{n_i}\choose{y_i}}(p_{i}^*)^{y_i}(1-p_i^*)^{n_i-y_i} $$ where $p_i^*=\pi + (1-\pi)p_i$, $p_i$ is the probability of succes due to treatment, and $\pi$ is the probability of natural succes (a.k.a the parameter i have to stimate along with $\vec\beta$ so the deviance is minimized) with a specific density function. How do i add $\pi$ in the likelihood? Also, which would be the best choice for the distribution of $\pi$? A truncated normal or beta distribution were my first thoughs, but i would really like your opinions about it. Thank you all for the help you coould give me. Edited: Trying to clarify a little. The experminet could be regarded as a treatment of different concentrations of a pesticide, and my response variable is a binary outcome depending on whether insects are dead or not. I count the number of dead insects and use of grouped binary data as the number of successes. I also have a control, without treatment. I was told that this shouldn't be included in the regression model because no treatment was applied to them, and the proportion of death insects in the control should be reflected as the natural response $ \pi $. Taking $ p_i^* = \pi + (1- \pi) p_i $ and the logit would be: $$ logit(p_i) = log(\frac{p_i^* - \pi}{1-p_i^*}) = \beta_0 + \beta_1D $$ where D is concentration of pesticide. Fitting this by ML, given that the observations come from a binomial distribution should give the likelihood function above. But, the thing is that i should estimate $ \pi $ too. I was asking: How should i do this by ML ?? In R i'm using this piece of code as my loss function: logitMod.loss } Is that right? That's how should i be doing the estimation ?? I want to know also, if $ Y_i | p_i ^ * \sim Binomial (n_i, p_i^*) $ and $ \pi \sim Beta(a_0, b_0) $, and knowing that $ p_i ^ * = \ pi + (1- \pi) p_i $. How should i write the probability of obtaining some observation $ y_i $ given $ p_i^* $ which depends on $ \pi $ ?? And finally, is it the beta distribution the best option as a prior for $ \pi $?
