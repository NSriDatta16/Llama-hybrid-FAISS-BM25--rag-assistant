[site]: crossvalidated
[post_id]: 299752
[parent_id]: 299354
[tags]: 
One approach you could consider is trying to learn a Markov Chain (MC) to represent each sequence and then predict future values based on this MC. MCs are a way of representing types of learning automata (LA) and can be used when the subsequent state of a system depends solely on the current state. They can be intuitively represented diagrammatically: This is a very simple LA. It has two states: one where the last number seen was a 1 and one where the last number seen was a 0. There are transition probabilities between the different states noted as well. For example, when the LA is in state 0 it will stay in state 0 with probability $x$ and will move to state 1 with probability $1-x$. This can also be shown in the form of a matrix: $\begin{bmatrix}x & 1-x \\ 1-y & y\end{bmatrix}$ Estimating from your example sequence, $1 1 1 1 0 0 1 1 1 1 1 0 0 0$, we might say that in this case $x = 0.6$ and $y = 0.77$. This kind of solution can also be extended; we could learn an LA with more states and more "memory." or $\begin{bmatrix}w & 0 & 1-w & 0 \\ x & 0 & 1-x & 0 \\ 0 & 1-y & 0 & y \\ 0 & 1-z & 0 & z\end{bmatrix}$ This LA has four states: 00, where two or more consecutive 0s have been seen; 0, where only one consecutive 0 has been seen; 1, where only one consecutive 1 has been seen; and 11, where two or more consecutive 1s have been seen. We can again estimate the corresponding probabilities from your example sequence and might say that $w = 0.33$, $x = 1$, $y = 1$ and $z = 0.71$.
