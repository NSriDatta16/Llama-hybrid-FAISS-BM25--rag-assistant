[site]: datascience
[post_id]: 25236
[parent_id]: 25221
[tags]: 
This is helpful when the data is not understandable and you don't have any data dictionary or you have too many columns which doesn't make any sense even after through investigation, then it is wise to go for Dimensionality Reduction . There is very good chance that you loose information at granular level, for example you gave 100 columns and you got 10 PC's(Applied PCA) which can explains most of the Data. As you can only get that much out of that technique. Feature Selection : If you miss even a single feature which is significant WRT target variable but you overlooked that feature then your model might not be able explain the most, you are even satisfied with the result but still there is window of improvement. You should be very careful and you need check as many times(many iterations) as possible to build a good/decent model and get the best results out of it. I hope this may help you.
