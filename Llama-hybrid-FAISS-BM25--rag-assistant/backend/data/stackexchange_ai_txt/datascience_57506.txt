[site]: datascience
[post_id]: 57506
[parent_id]: 57503
[tags]: 
Your first error is because Keras wants the batch size as first dimension. Given that your Y has 95751 observations, your X must be reshaped in order to have 95751 records in the first dimension, as you did in the second part. The code doesn't work because Keras has already put the first dimension (None = batch_size) for you (see model.summary() ), so you don't need to specify that in input_shape . You need to change this input_shape=(95751, 4) into this input_shape=(4, 1) Update after comment - working example Here's a working example of your code. First I define X and Y following your shapes. Here I use random numbers given that I don't have your data data1cnn = np.random.rand(95751, 4, 1) y = np.random.rand(95751,) I check the shapes to be sure that they are the same as the ones you have provided in your second part of the question print('X and Y shape') print(data1cnn.shape, y.shape) Output X and Y shape (95751, 4, 1) (95751,) Looks correct. Now I define the model: everything is the same as in your code but input_shape=(4, 1) modelcnn = Sequential() modelcnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(4, 1))) modelcnn.add(MaxPooling1D(pool_size=2)) modelcnn.add(Flatten()) modelcnn.add(Dense(50, activation='relu')) modelcnn.add(Dense(1)) modelcnn.compile(optimizer='adam', loss='mse') I print the summary print('Model summary') print(modelcnn.summary()) Output Model summary _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv1d_1 (Conv1D) (None, 3, 64) 192 _________________________________________________________________ max_pooling1d_1 (MaxPooling (None, 1, 64) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 64) 0 _________________________________________________________________ dense_1 (Dense) (None, 50) 3250 _________________________________________________________________ dense_2 (Dense) (None, 1) 51 ================================================================= Total params: 3,493 Trainable params: 3,493 Non-trainable params: 0 Then I train it using the same command you wrote in your question but verbose=1 to print some information during training modelcnn.fit(data1cnn, y, epochs=1000, verbose=1) and it trains without a problem given that I get as output Epoch 1/1000 95751/95751 [==============================] - 6s 60us/step - loss: 0.0844 Epoch 2/1000 95751/95751 [==============================] - 7s 76us/step - loss: 0.0833 Epoch 3/1000 95751/95751 [==============================] - 6s 59us/step - loss: 0.0832 Epoch 4/1000 95751/95751 [==============================] - 6s 66us/step - loss: 0.0831 Epoch 5/1000 95751/95751 [==============================] - 5s 54us/step - loss: 0.0831 Epoch 6/1000 95751/95751 [==============================] - 5s 54us/step - loss: 0.0830
