[site]: datascience
[post_id]: 31574
[parent_id]: 
[tags]: 
Is this the correct way to apply a recommender system based on KNN and cosine similarity to predict continuous values?

My data is: userID, gameID, rating (1.0 through 10.0) First, I normalize the values the ratings of each row. I use cosine similarity to create a similarity matrix where each cell represents similarity between a pair of userIDs (value 0.0 through 1.0). For each unrated gameID, I find the 10 most similar users that have rated the gameID. The predicted rating is equal to the sum of each neighbors rating times similarity, then divided by 10 (number of neighbors). This seems fine for finding the best predictions, just take the top N rating values, but for actually predicting the values it doesn't perform so well. Intuitively, the average of a group of similar userID's ratings would be an accurate prediction. When each rating is made smaller by multiplying by a value that is always less than 1.0, the predicted value is consistently smaller than expected. This seemed to follow formulas that I found, but I feel like I missed something. I am using Python, Pandas, and Numpy. Edit I am seeing that this final value is sometimes referred to as a "weighted predicted rating". I am wondering how to "de-weight".
