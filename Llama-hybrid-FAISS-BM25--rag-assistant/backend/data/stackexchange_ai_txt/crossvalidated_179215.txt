[site]: crossvalidated
[post_id]: 179215
[parent_id]: 179213
[tags]: 
The sum of two independent normal variables is normal random variable, e.g. $x\sim\mathcal{N}(\mu_x,\sigma_x^2)$ and $y\sim\mathcal{N}(\mu_y,\sigma_y^2)$ will get you $$\alpha x+(1-\alpha)y\sim\mathcal{N}(\alpha\mu_x+(1-\alpha)\mu_y,\alpha^2\sigma_x^2+(1-\alpha)^2\sigma_y^2)$$ Here, you could use $\alpha=\frac{1}{2}$ for an equal weight mean. If you assume that both instruments are unbiased , then you actually have a simpler situation: $$x\sim\mathcal{N}(\mu,\sigma_x^2)$$ $$y\sim\mathcal{N}(\mu,\sigma_y^2)$$ In this case you assume that in average both instruments are accurate (as defined by IUPAC), i.e. have no bias. However, their precision is different $\sigma_x,\sigma_y$. Let's construct a weighted estimator $$\hat\mu=\alpha x + (1-\alpha) y$$ Let's look at its characteristics: $$E[\hat\mu]=\alpha\mu+(1-\alpha)\mu=\mu $$ Good, it's unbiased regardless of the weight $\alpha$, i.e. it's accurate . Let's see what's its precision : $$Var[\hat\mu]=\alpha^2\sigma_x^2+(1-\alpha)^2\sigma_y^2$$ The independence assumption of normal variables is usually reasonable for instrument measurements unless they're affected with the same exact random shocks, which may happen in certain setups but not usually encountered. In this case the the optimal $$\alpha=\frac{\sigma_y^2}{\sigma_x^2+\sigma_y^2}$$ You can see that if the precisions are the same, the weight is $\alpha=1/2$. Otherwise, if the first instrument twice more precise, e.g. $\sigma_x=\sigma_y/2$ then you get $$\alpha=\frac{4}{4+1}=0.8$$
