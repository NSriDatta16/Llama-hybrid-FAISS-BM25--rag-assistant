[site]: crossvalidated
[post_id]: 52665
[parent_id]: 43871
[tags]: 
Yes, for a detailed explanation refer to the paper "A geometric interpretation of $\nu$-SVM Classifiers" by David J. Crisp and Christopher J.C. Burges. The idea is that $\nu$ is bounded by the amount $\nu \leq 2l_{min}/l$, where $l_{min}$ is the amount of sample points of the smallest set, and $l$ is the total amount of points. In an unbalanced problem this amount is very small. At the same time $\nu$ is an upper bound on the fraction of margin errors and a lower bound on the fraction of support vectors. So actually you might end up with a big number of SVs, because the fraction of margin errors is forced to the too low. See "A User's Guide to Support Vector Machines" by Asa Ben-Hur and Jason Weston for a method to deal with this problem.
