[site]: datascience
[post_id]: 8568
[parent_id]: 
[tags]: 
Does importance of SVM parameters vary for subsample of data?

I'm training a support vector machine classifier (SVM) on 100.000 observations. I'd like to try different parameter combinations (including kernel types) using cross-validation. However, it is computationally expensive to optimize over these different parameter values. Therefore, I'd like to test them on a subset of 5.000 observations on a validation set and then based on those results choose the parameters for the final model that is trained on 100.000 observations. My question is then whether there is something intrinsic in these parameters that will make this approach problematic. More specifically, is there a parameter, where training on the full data set will require a different value for optimal performance? I'm using the following kernels with their parameters in parentheses: rbf (gamma, C) poly (degree, C) sigmoid (gamma, C) linear (gamma).
