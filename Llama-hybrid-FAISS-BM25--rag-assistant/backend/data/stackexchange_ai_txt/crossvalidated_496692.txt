[site]: crossvalidated
[post_id]: 496692
[parent_id]: 
[tags]: 
verifying Asymptotic Distributions using simulation methods

I've created 10 thousand simulated time series with sample size $T = 200$ , simulated with a given autoregressive parameter ( $\theta_0$ = 0.3) and for each I've estimated the autoregressive parameter from the data. I want to look at the distribution of $\sqrt{T}(\hat{\theta} - \theta_0), $ which should be Normally distributed asymptotically speaking. If I look at $\frac{\sqrt{T}(\hat{\theta} - \theta_0)}{\hat{\sigma}}$ it should be $N(0, 1)$ distributed , where $\hat{\sigma}$ is the an estimate of the standard error of the parameter. I am not sure if I'm doing something wrong but when I multiply $\frac{(\hat{\theta} - \theta_0)}{\hat{\sigma}}$ by $\sqrt{T}$ the variance of the resulting distribution is equal to $\sqrt{T}.$ NOTE: I am using the standard deviation of the 10k samples as $\hat{\sigma}, $ is that correct? If I do not multiply by $\sqrt{T}$ the standard deviation is 1. What should I be doing differently?
