[site]: crossvalidated
[post_id]: 283949
[parent_id]: 283249
[tags]: 
The difference between using propensity scores (PS) and logistic regression to control for confounding has nothing to do with the predictive ability of the covariates or an estimated PS. What you have been discussing is variable selection for controlling confounding, and all findings that apply to regression or PS analysis apply to the other as well. Generally, the main difference between the two methods is whether you can reasonably accurately model the response surface of the outcome using a regression model; if not, regression will yield biased and inconsistent estimates. Many authors argue that you should use propensity scores to avoid this issue. Kang & Schafer (2008) discuss this at length. There are other considerations at play. If you want a marginal treatment effect (an estimate of the treatment effect in the population assuming your sample is a simple random sample from the population), only propensity scores and the other g-methods (g-estimation, the parametric g-formula) can provide this. If you want the conditional treatment effect (the effect of treatment holding constant other variables), you need logistic regression. There have also been studies showing that the number of events per confounder can determine whether logistic regression or PS will yield more accurate results. Also, in general PS methods will be less powerful than logistic regression because of the efficiency of maximum likelihood estimates in regression. But this added precision is only helpful if your logistic regression estimates are relatively unbiased, which, again, requires modeling the response surface correctly. PS methods will decrease your power and the precision of your estimate, but they will be less biased in general. It appears you have a common misunderstanding of propensity scores based on your question; you are assuming estimated PSs are model implied probabilities of treatment based on a sound and reasonable treatment selection model. In reality, they are a tool with no substantive interpretation or relevance whose sole purpose is to yield balance in confounders (i.e., through matching, weighting, or subclassification). So you should not take the estimates of your PS model seriously; a totally unrealistic selection model may in fact yield effective propensity scores. Many modern PS-related techniques such as entropy balancing (Hainmueller, 2012) and stable balancing weights (Zubizarreta, 2015) don't even consider a PS model; they balance covariates directly using weights that are asymptotically equal to the best balancing weights. A PS model is irrelevant here, and these techniques vastly outperform traditional PS methods that involve modeling a propensity score with logistic regression and MLE. So I would encourage you not to look at fit statistics or parameters in your PS model; consider only whether you have achieved balance after conditioning on the estimated PS. For variable selection, which is another issue entirely, these values may be meaningful, but are unrelated to the choice between PS and logistic regression.
