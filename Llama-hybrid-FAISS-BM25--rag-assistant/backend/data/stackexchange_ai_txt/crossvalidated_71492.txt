[site]: crossvalidated
[post_id]: 71492
[parent_id]: 71485
[tags]: 
Disclaimer: As in the comments, these are not ways to ensure best prediction , but rather the musings of an epidemiologist on model building for survival models trying to elucidate the relationship between an outcome O and an exposure E with a number of covariates: The goal of these is not actually to make the best predictive model, or the strongest association, but rather to come up with a model that contains all the variables necessary to have an unbiased estimate of the effect of E on O (given no residual confounding - i.e. we didn't forget/overlook/have no idea a particular thing is important), without including anything else. Because your models aren't "nested", i.e. you're not comparing "A, B and C" versus "A and B" versus "Just A", you really can't use a direct comparison of the log likelihoods, including the likelihood ratio test. Making your modeling decisions based on p-values is also fairly perilous - a huge amount of discussion could be made about this, but I'd suggest as starting literature checking out a copy of Modern Epidemiology 3rd Edition, or browsing some of the works of Sander Greenland, or perhaps Charles Poole. That should put you off p-value model selection fairly quickly :) If you're just looking for the "best fitting" version of non-nested Cox models, you could use something like Akaike information criterion (AIC) which Stata should report, or the Bayesian information criterion (BIC). These give you a decent picture of the relative strength of each model fit - you're looking for the model with the lowest AIC or BIC. These give you a picture of the predictive power of the model compared to the amount of variables in it, trying to give a balance between model parsimony and fit. I tend to use this if what I'm trying to decide on is the form of a variable to include (i.e. should I use A, or also include a term for A^2?). But not so much in the "Which variables do I include" stage. The way I decide on variables is using a mix of these: I build what I believe is a working causal model of the relationship using a Directed Acyclic Graph (DAG) to show all the relationships between E, O and my variables of interest. There are many introductions on how to do this, and some would argue that once you have done a DAG and found the variables you need to control for (see said online tutorials) you're done. My confidence in this varies based on whether or not I'm working in a known, well-studied area, or am paving new territory. If I don't want to be finished there, or I'm not sure about some of my choices, I might use a change-in-estimate approach, including variables that change my estimate of the association between E and O by more than 10% or something of that nature. This lets you keep the variables that have an impact on your estimate, but get rid of those that don't, even if they might theoretically have been important because of your DAG. Finally, sometimes I do just use a p-value cutoff, but I tend to make this extremely generous - I'm not looking to only include variables with small p-values, but any variable that even faintly shows that it might have importance, so my cutoff is something like p I'd again recommend a copy of Modern Epidemiology 3rd Edition, they've got a very good treatment of model selection.
