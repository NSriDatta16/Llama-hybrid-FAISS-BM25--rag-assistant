[site]: datascience
[post_id]: 74197
[parent_id]: 74196
[tags]: 
One thing you can do is train your model N times and report the average and standard deviation of the accuracy. Is the train/test split fixed? That means, do you use the same train set for every evaluation? And do you have a stratified split? That means the class imbalance of your data is also present in the train and test data. Since your data is imbalanced imagine you have a split where most of your train data consists of class 0, your model will learn to achieve a low train-loss with predicting 0 all the time, but you will have a high test-loss since you have way more samples of class 1 in your test set. It probably helps to check your predictions. Fix seeds and stratify your splits.
