[site]: crossvalidated
[post_id]: 25583
[parent_id]: 
[tags]: 
Autocorrelated predictors in linear models

I need to predict the outcomes of a time-series variable $Y$ based on two time-series predictors $X1$ and $X2$. For simplicity I will only illustrate $X1$ in the rest of this question. The correlation between the predictors and $Y$ at lag 0 is relatively high as illustrated by the cross-correlation function. However the lag 1 correlation is a lot lower and does not seem to have much prediction power: > ccf(as.numeric(X1), as.numeric(Y), lag.max = 3, plot = FALSE, na.action = na.pass) Autocorrelations of series 'X', by lag -3 -2 -1 0 1 2 3 0.015 0.008 -0.001 -0.415 -0.018 -0.002 -0.002 Indeed when I regress $Y_{t+1}$ against $X1_{t}$, $X2_{t}$, $R^2$ is very low. Now, looking at the $X1$ partial auto-correlation indicates that the predictor itself could be estimated using an AR model. The significance level for this series is around 0.01: > pacf(X1, plot = FALSE, na.action = na.pass, lag.max = 15) Partial autocorrelations of series 'X1', by lag 60 120 180 240 300 360 420 480 540 600 660 720 780 840 900 0.171 0.103 0.067 0.055 0.046 0.049 0.027 0.032 0.029 0.012 0.020 0.037 0.020 0.026 0.020 To resume, the correlation between $X1$ and $Y$ at lag 0 is high (but not for $X1_{t}, Y_{t+1}$) and $X1$ is significantly auto-correlated up to 10/15 periods. What would be the best approach to predict $Y$ and why? Estimate $X1_{t+1}$ using an AR(15) model, then use the estimated value as a predictor for $Y$. Fit all $X1_{t-15, ..., t}$ against $Y$. Use an exponential moving average of $X1$ ($\alpha = ~0.125$) as the predictor.
