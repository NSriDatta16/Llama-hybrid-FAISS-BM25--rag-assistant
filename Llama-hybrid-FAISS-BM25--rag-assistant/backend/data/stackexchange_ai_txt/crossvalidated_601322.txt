[site]: crossvalidated
[post_id]: 601322
[parent_id]: 601207
[tags]: 
If these are randomized trials, then with this data available, you can use an arm-based meta-analysis (that would be the term to search for to find more literature on this) instead of a "traditional" meta-analysis that uses differences as an input. I.e. you compare 85.1 ± 7.4 to 83.8 ± 10.0 kg within the study instead of using a difference of 1.3 ± 12.44. If you have only two arms in every trial and the same treatments compared in each trial, then in a frequentist analysis this is (for continuous data) equivalent to first calculating a difference + SE per study and secondly meta-analyzing those. Where the arm based approach can be preferable is in a few situations: When there are more then two arms per study (e.g. two doses of a drug vs. placebo) and you need to account for correlation due to comparing them to a common control (you cannot just treat this as two independent studies one with dose 1 vs. placebo and the other with dose 2 vs. placebo). In this setting an arm based approach deals with the issue very easily, while when using differences as your input it gets more complicated (but if you treat the two doses as completely equivalent you can often simplify your life by getting an estimate of the pooled doses vs. placebo, but that can be complicated if your input is e.g. hazard ratios). When a normal approximation for the sampling distribution of the treatment effect is questionable, you sometimes have the necessary information to instead use an appropriate likelihood in an arm-based analysis (e.g. rare binary events when you have number of patients with an event and total number of patients for each arm, exponential time-to-event when you have patients with an event and total follow-up until event or censoring for each arm, Poisson event counts when you have events and total follow-up per arm etc.). When you want to exploit that you have prior information about expected control group outcomes via a Bayesian approach. Or similarly, if you wanted to exchanged information between the placebo groups. This might sometimes be attractive in case of e.g. analyzing rare events. You can use an arm-based approach to adjust for group-level covariates in each arm. That would be the case in your situation. You would have a group-level covariate of 89.9 and 87.7 respectively (each arguably with a measurement error of ± 6.8 or ± 10.5, respectively). Going this route though will be a lot less efficient than adjusting for the covariate at an individual patient level, because for something like body weight there's an enormously high correlation between baseline and end of study, which the model "dose not know about" and thus, does not exploit. If you are not in one of those situations, then working with differences and their standard errors is more traditional and a lot of the standard tooling/literature is more oriented towards that (so your life might be a bit easier, if you go that route). The other reason to prefer differences would be if the presented group means are unadjusted for covariates (usually inefficient = inflated standard errors) or calculated based on a complete-case-analysis (serious risk of biased estimates), while the differences might be based on an appropriate handling of missing data + intercurrent events and with adjustment for covariates. In the case of body weight, I would expect adjustment for baseline to be extremely important, so a difference calculated adjusted for baseline would be a lot more efficient than unadjusted means. However, if you have model adjusted least-squares means or model adjusted least-squares means for the change from baseline, that would be just as efficient as adjusted differences. From what you wrote, I don't know about whether intercurrent events or missing data are an issue with your data, but some weight loss drugs are not so well tolerated so you could have a lot of that going on in your data. If your data is not from randomized trials, your life is a lot harder. Since you probably don't have the raw data from the study, you'd presumably want to use as your input something where the authors of each paper have done their best to account for all potential biases and confounders that may have affected the data in their non-randomized study. Most likely they would have primarily presented adjusted differences from some suitable analysis (although you would also face the hard challenge to decide what to do about studies that either completely failed to take into account the non-randomized nature of their data or inadequately handled it - and arguably you can always find some potential concerns they may have not accounted for, possibly because it was simply impossible for them to even get the necessary data).
