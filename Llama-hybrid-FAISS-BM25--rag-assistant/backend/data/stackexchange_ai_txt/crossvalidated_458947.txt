[site]: crossvalidated
[post_id]: 458947
[parent_id]: 
[tags]: 
$z_t=x_{t+7}/x_t$. Solve back for x. model is $z_t=alpha*z_{t-1}$

I want to create a model of x, Now my issue is that to get this fit I need to transform the original data such that $z=x_{t+7}/x_t$ the absolutely best fit I could get is by regressing $z_t=alpha*z_{t-1}$ . This gives me an R^2 of 0.92. Now I thought by having the parameter from this regression I could backsolve for $x_{t+7}=x_t*alpha*(x_{t+6}/x_{t-1}))$ , so I did this and then I looped though over x and I expected that the fit would be at the same level as the transformed equation, however, the fit is absolutely terrible. This means that I am either doing something wrong or one can not simply transform a time series by dividing by it's lag. Would anyone be able to explain what I've done wrong, why the fit becomes so much worse after transforming back, and what I should be doing?
