[site]: crossvalidated
[post_id]: 472690
[parent_id]: 471424
[tags]: 
The analogy suggested in this question--between a p-value statistical significance threshold and a Cox-Snell logistic regression pseudo- $R^2$ that represents a "good fit"--isn't apt. Think about ordinary least squares multiple linear regression. That produces both a p-value for the model as a whole and an $R^2$ value that is the fraction of variance in the outcome variable that is explained by the model. Those represent two different things. The p-value tells you how likely it is that your study has led you astray. If there really was no relationship between the outcome and the predictors and you did the study multiple times, a p-value of 0.05 says that you would have only found a relationship at least that strong by chance in fewer than 5 out of 100 cases. Without more information (e.g., about how many data points you have) it says nothing directly about the fraction of variance in the outcome that the predictors explain. The linear multiple regression $R^2$ provides that information about the fraction of variance explained by the model. But there is no single $R^2$ value that represents a "good fit"; that depends on the underlying subject matter. What's considered a "good fit" $R^2$ in a biomedical study might be considered woefully inadequate for a "good fit" in a physical-science study, even if a large number of observations provided a "statistically significant" p-value of p It's similar in logistic regression: the p-value tells you how likely you are to have found an apparent relationship even if there isn't really one. The value of a Cox-Snell pseudo- $R^2$ that represents a "good fit" will depend on what is being studied. Finally, a good argument can be made that pseudo- $R^2$ values shouldn't even be reported for logistic regression. Other measures more closely related to the purpose of the study are much more important.
