[site]: crossvalidated
[post_id]: 222493
[parent_id]: 
[tags]: 
Why do we use the Unregularized Cost to plot a Learning Curve?

I'm taking Andrew Ng's Machine Learning Course. In the section on determining the variance/bias of your model, he suggests the following. For a given regularization parameter and set of features Create differently sized subsets of your training data. For each training data subset, using regularization , ~ train a model, ~ then calculate the error on the subset and the error on the validation set. Once that's done, plot the unregularized cost for both training and validation sets as a function of the size of the training data subset. The idea is that, if the training error and validation error remain very different at large training set sample sizes then the model has high variance. If training error and validation error converge too quickly then the model has high bias. My question is... Since the models we're testing were calculated using a regularization constant, why aren't we plotting regularized cost as a function of the training data size?
