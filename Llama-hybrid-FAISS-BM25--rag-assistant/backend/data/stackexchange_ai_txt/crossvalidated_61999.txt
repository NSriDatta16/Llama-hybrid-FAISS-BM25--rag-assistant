[site]: crossvalidated
[post_id]: 61999
[parent_id]: 61994
[tags]: 
It is indeed possible to get the relative importance of features from any black box model. A way to do this is a partial dependency plot : Let $f$ be your black box function and $x_{i, s}$ the s'th feature of the i'th data point. Then we can look at the response of the black box where we average all other features $x_{i,-s}$ out over the data set: $$f(x_s) = {1 \over N} \sum_i^N f(x_s, x_{i, -s}).$$ Have a look at Greedy function approximation: a gradient boosting machine by Friedman for more details. With respect to the data size: it sounds a lot like a tough call to use neural nets for this. It depends on the data itself, but I must say that I'd rather go for a sparse linear model in your case with careful feature engineering. Backprop is just a way to calculate the gradients of a neural net. This is what what is used in practice most of the time.
