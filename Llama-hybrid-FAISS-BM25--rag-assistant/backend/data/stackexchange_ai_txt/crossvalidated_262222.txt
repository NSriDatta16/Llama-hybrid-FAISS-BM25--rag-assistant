[site]: crossvalidated
[post_id]: 262222
[parent_id]: 262220
[tags]: 
I have done some projects on text classification and relation extraction using CNN and RNN (specifically, LSTM and GRU): CNNs tend to be much faster (~5 times faster) than RNN. It's hard to draw fair comparisons: CNN and RNN have different hyperparameters (filter dimension, number of filters, hidden state dimension, etc.) there exist many sort of RNNs the running time depends on the implementation, especially RNNs. CNNs run faster with CuDNN + CNMeM. RNNs benefit less from them. etc. Nvidia has historically focused much more on CNN than RNN, as computer vision mostly employs CNN. One benchmark: https://github.com/baidu-research/DeepBench FYI: Benchmarks based on neural networks libraries to compare the performance between different GPUs Why doesn't training RNNs use 100% of the GPU?
