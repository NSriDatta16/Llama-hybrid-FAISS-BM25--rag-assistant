[site]: datascience
[post_id]: 85647
[parent_id]: 85619
[tags]: 
You can convert these strings into feature vectors using any regular NLP algorithm. You can then find the nearest-neighbour in dataset 2 for each address in dataset 1. You can define a cut-off beyond which the vectors are considered to be different. Alternatively you can mix the unique addresses in both the datasets together and k-means-cluster them with k=half of the total number of records. This way you get a nearest neighbour for every unique address. You can use this map for further processing. The first approach appears cleaner. Based on the vectorisation approach, you can try both Levenshtein or cosine similarities and see which one works better. Also bi-grams may work better here compared to unigrams for vectorisation
