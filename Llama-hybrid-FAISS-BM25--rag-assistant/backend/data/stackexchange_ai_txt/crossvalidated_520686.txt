[site]: crossvalidated
[post_id]: 520686
[parent_id]: 
[tags]: 
Difficulties with encoder while training VAE

A VAE is comprised of two parts: encoder and decoder. The encoder should take the input and then output a mean $\mu$ and a variance $\sigma^2$ . Then, sampling occurs with $\mathcal{N}(\mu,\sigma^2)$ and that passes to the decoder, which will try to reconstruct the original signal. The loss function has a KL divergence term between $\mathcal{N}(0,1)$ and $\mathcal{N}(\mu,\sigma^2)$ , where the goal is to make $\mu=0$ and $\log(\sigma) =0$ . In my case, when training the encoder neural network what happens is exactly that, but for all inputs, namely, $f_\mu(x)=0$ and $f_\sigma(x)=0$ for all $x$ , where $f_\mu,f_\sigma$ are the encoder network. Therefore, no matter what the input is in the encoder, the decoder will always output roughly the same because it is just sampling $\mathcal{N}(0,1)$ . Does anyone know how to deal with this problem? Thanks!
