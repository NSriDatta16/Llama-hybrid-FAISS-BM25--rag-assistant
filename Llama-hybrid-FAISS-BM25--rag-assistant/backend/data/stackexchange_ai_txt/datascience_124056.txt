[site]: datascience
[post_id]: 124056
[parent_id]: 
[tags]: 
How to implement 2d Rotary Position Embedding in PyTorch?

The original RoPE paper suggests that the Rotary Position Embedding it describes can easily be extended to two or more dimensions: 3.2.2 in https://arxiv.org/abs/2104.09864 . I'm trying to find a PyTorch implementation of this and I can't; I can only find implementations for a 1D embedding. Is anyone aware of any 2D implementations in PyTorch (or another framework, which I could translate to PyTorch)?
