[site]: crossvalidated
[post_id]: 307085
[parent_id]: 
[tags]: 
Adding training and validation set to increase accuracy after finding optimal parameters

General rule of thumb in splitting data in Machine Learning is in 3 parts training set, validation set and testing set. Well everybody knows that. So, to try out the performance of different algorithms we try using dev set as test set and training set as the training set. Now after finding correct hyperparameters of the model: Why don't we add validation and training sets together in order to obtain a bigger training set for the model to learn than the traditional model trained only on training set and validated on validation set? Will not the new training + validation set provide more features? And therefore increasing accuracy of model after testing on the test set? Because more data implies more features to learn for the model and hence will increase the performance on test set as well.
