[site]: crossvalidated
[post_id]: 643525
[parent_id]: 642803
[tags]: 
Preliminary Responses I provide an answer for now in case others do not respond. I first address some of your initial questions, then move on to more important matters that are visible in your modeling. The model: This model could be overfitted, and this is the first issue I am facing. However, the problem for me is how to identify this excess of covariates. You indeed have many variables here. I would first determine which of these variables is theoretically defensible to include. Indeed many "controls" are just artefacts of past literature which may not be that important (see section "Control Variables" in the references provided). If they absolutely need to be included, one could use a PCA reduction of the variables, but this comes at the cost of interpretability (e.g. what would the first principal component "mean" with respect to it's influence on the DV?). Multicollinearity? Following previous threads here by Ben Bolker, I went for creating the matrix and test the "linear combos" I'm wondering why you haven't first checked the variance inflation factor (VIF) of the model (see Miles, 2014 for a brief explanation). You can easily check by running check_collinearity(model) from the performance package in R. I'm not sure which threads you are referring to, so a link to his posts may be helpful. But the VIF should at the very least give you a quick look at what is going on there. If there is something more critical (such as a a perfect linear combination of two variables), than that can of course be addressed by removing one of the variables if it can be considered redundant. Unfortunately I don't speak Spanish and know fairly little about medical research, so you may need to determine that yourself. More Important Issues On to some important matters, as pointed out in the comments, your dependent variable appears to have a lot of missingness present. I would first determine what is causing this missingness, and then determine how to handle it (see Little et al., 2014 for a quick guide). In your code, you have chosen the na.omit option, which is probably not ideal. There may be some structural reasons for the missingness, and simply removing them isn't the best strategy. Using a missingness map/matrix may help a lot with identifying what is going on. It would also be helpful to show what your original convergence errors are in R, as these would offer some potential clues (I know that lme4 provides these explicitly). The last part of your code seems to imply more an error with respect to formulating lme . I'm not as familiar with lme or reformulate , but that seems to be more a technical error than something related to your data. I will anyway note that you shouldn't exclude what seems to be the one of the most critical parts of your model, time. For the others you excluded, it may be helpful to provide a lot more information about what your variables actually mean here, as the rest is just going to be guesswork. My hunch is this: based off the data I see, you only have two time points. If the patients do not vary much between time points, this may contribute to the model not converging. Given that you have already accounted for this in your model, I'm not entirely sure if it is even necessary to run random intercepts. I would check how much patients vary by time and see if that is contributing in some way. If you include a lot of missingness into the mix, I can only imagine this doesn't help with estimating the model (see section here which notes missingness as a potential contributor). The "Convergence" section is useful for your own purposes. References Control Variables Bartram, D. (2021). Age and life satisfaction: Getting control variables under control. Sociology, 55(2), 421–437. https://doi.org/10.1177/0038038520926871 Bernerth, J. B., & Aguinis, H. (2016). A critical review and best‐practice recommendations for control variable usage. Personnel Psychology, 69(1), 229–283. https://doi.org/10.1111/peps.12103 Cinelli, C., Forney, A., & Pearl, J. (2020). A crash course in good and bad controls. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3689437 Spector, P. E., & Brannick, M. T. (2011). Methodological urban legends: The misuse of statistical control variables. Organizational Research Methods, 14(2), 287–305. https://doi.org/10.1177/1094428110369842 Additional References Little, T. D., Jorgensen, T. D., Lang, K. M., & Moore, E. W. G. (2014). On the joys of missing data. Journal of Pediatric Psychology, 39(2), 151–162. https://doi.org/10.1093/jpepsy/jst048 Miles, J. (2014). Tolerance and variance inflation factor. WileyStatsRef: Statistics Reference Online. https://onlinelibrary.wiley.com/doi/full/10.1002/9781118445112.stat06593
