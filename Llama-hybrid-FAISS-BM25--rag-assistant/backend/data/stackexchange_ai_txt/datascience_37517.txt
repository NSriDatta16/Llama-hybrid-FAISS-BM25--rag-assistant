[site]: datascience
[post_id]: 37517
[parent_id]: 37513
[tags]: 
I will first list some examples of models you could look into. You can suggest me things I should learn about too. You can look at more classical regression type models, or go deeper in to deep neural networks, utilising Long Short Term Memory cells, which model relationships over time. Classical The main term that will help you search for related tutorials/documentation will be autoregressive , which is a fancy name for saying a target value is predicted from its recent history. How recent, is a parameter you can tune your model for, called lags . Have a look at the options in the statsmodels module for Python. More specifically, you might want to try out the ARIMA model class. For more details on ARIMA, check out this thread . There are many traditional models that you could use for a time-series problem. Terms you might consider searching for include: Here is an introduction article about these Generalised Linear Model (GLM) - Here is a variant, called General Additive Models (GAM) with a good walkthtough using R Deep Learning This is a much newer topic and is overall a fair bit complexer than the classical models discussed above. If you go this route, you would probably make progress quickest by using a Deep Learning framework such as Keras, which allows you to build complex models without too much time investment. It is a wrapper library that uses either Tensorflow, Theano or CNTK in the background (these are the available backends ). In a deep learning approach involving time-series analysis, you almost certainly want to start with an LSTM model. This stands for Long Short Term Memory, and uses a complex cell to monitor various states as you pass in your time-series data. It is a really big topic, so I will just provide: an introduction to the logic behind LSTM , and a nice tutorial on how to get things working If you decide to go this way (as opposed to classical models), then yes, you should understand backprop . This is a really broad problem that you have described and there are many many approaches. It is also likey very active in research within the fields of (self-)localisation.
