[site]: crossvalidated
[post_id]: 579539
[parent_id]: 578397
[tags]: 
You can also do an exact calculation. Let $K(x,y)$ be the transition probability for going from point $x$ to point $y$ in some Markov chain. For points $a,b$ , let $\tau_{a,b}$ be the expected time to go from $a$ to $b$ , with $\tau_{a,a}=0$ by convention. We then have the following recurrence relationships for $a \neq b$ : $\tau_{a,b} = 1 + \sum_{c} K(a,c) \tau_{c,b}$ by looking at what happens after one step. If your Markov chain has $n$ states, this gives you a collection of $\frac{n(n-1)}{2}$ equations in the same number of unknowns. You can solve using the usual linear algebra approach.
