[site]: crossvalidated
[post_id]: 101332
[parent_id]: 
[tags]: 
Standard deviation in Weibull distribution

I've have a script that creates Weibull distributions with a static shape parameter and a variable scale parameter, the scale parameter changing to yield a distribution that meets a specified mean while maintaining the shape parameter. I have calculated that the standard deviation for my distributions always equals 2*sqrt(5). This is really small for what I am doing: I am using the distribution to model webpage read-time based on a known average (calculated from the number of words on the page). Times, including standard deviation, are in seconds. 2*sqrt(5) doesn't seem like a whole lot of wiggle room for read-time variation when trying to emulate an "average" web browsing user. How can I approximate how many standard deviations "wiggle room" is appropriate for my application? I was surprised, since I thought that "standard" deviation implied that a majority of samples would be within one standard deviation of the mean. I can't believe it's so tight around my average. It doesn't seem like a "standard" deviation is "standard" at all, since in other distributions I've looked at, a large percentage of samples fall within one of them. This assumes I didn't make a calculation error -- I'm not finding an error yet at least. Thanks
