[site]: crossvalidated
[post_id]: 571030
[parent_id]: 
[tags]: 
"Centered" linear regression in point-slope form: pivot distribution and notation

I'm a "pure math" probabilist who's been roped into teaching an undergraduate statistics course, despite little experience with statistics per se, and I'm trying to stay one chapter ahead of the students. So apologies in advance if I have mistakes in terminology, notation, etc., or miss things that should be obvious. Anyway, the class is studying simple linear regression. The textbooks we're using ( Pishro-Nik , Evans and Rosenthal ) define it as assuming that the predictor $x$ and the response $Y$ are related by the following linear equation in slope-intercept form: $$Y_i = \beta_0 + \beta_1 x_i + \epsilon_i \tag{1}$$ where $\epsilon_i \sim N(0, \sigma^2)$ are iid with $\sigma^2$ unknown. (Evans and Rosenthal call the parameters $\beta_1, \beta_2$ instead.) We use the usual estimator $\hat{\beta}_1 = \frac{\sum (x_i - \bar{x}) (Y_i - \bar{Y})}{\sum (x_i - \bar{x})^2}$ for the slope, and then use it to estimate the $y$ -intercept $\beta_0$ by $\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{x}$ . Evans and Rosenthal go on to derive the distributions of pivotal quantities for $\hat{\beta}_1, \hat{\beta}_0$ which can be used to find confidence intervals or test hypotheses; they involve the "error sum-of-squares" $S^2 = \frac{1}{n-2} \sum (Y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2$ . What bothered me is that the slope-intercept form (1) seems unnatural. We were working through an example relating the weight $x$ of various models of cars to their fuel economy $y$ in miles per gallon (mpg), and when we computed the estimated $y$ -intercept $\hat{\beta}_0$ , a student asked me the meaning of this number. I had to say "it's the mpg that the model predicts for a car with zero weight", which is a pretty silly quantity to consider unless extrapolating is your hobby . Moreover, there's the issue that $\hat{\beta}_0, \hat{\beta}_1$ are very dependent. You could find confidence intervals for each of them, but looking at the endpoints of those intervals together would not give you a reasonable picture of the most "extreme" line consistent with the model. So it seemed to me that a "point-slope" form would be more appropriate: $$Y_i = \alpha + \beta_1(x_i - \bar{x}) + \epsilon_i \tag{2}$$ After a little searching, I guess this is called "centering", but I didn't find sources that work with this version in detail. So my first question is: is there a standard name and/or notation for the parameter I am calling $\alpha$ ? It represents the response predicted by the model for the average predictor value $\bar{x}$ (in our example, the predicted fuel economy of an average-weight car). Now the obvious estimator for $\alpha$ would be $\hat{\alpha} = \bar{Y} = \alpha + \bar{\epsilon}$ . I'd like to work out the corresponding pivotal quantity and its distribution. First, it appears to me that $\bar{Y}, \hat{\beta}_1, S^2$ are mutually independent , though I didn't actually prove it as it seems tedious. But is this true? Next, it seems clear that $\bar{Y} \sim N(\alpha, \sigma^2/n)$ , so it's an unbiased estimator of $\alpha$ , but of course $\sigma^2$ is unknown. However, we have the pivot $\frac{n-2}{\sigma^2} S^2 \sim \chi^2(n-2)$ . So if $S^2$ is indeed independent of $\bar{Y}$ , we ought to have $$\frac{\bar{Y} - \alpha}{S/\sqrt{n}} \sim t(n-2). \tag{3}$$ This would allow us to find a confidence interval for $\alpha$ . So have I got this right? I was hoping I would find this formula in a book somewhere to confirm it, but I haven't found it yet. References that discuss this "centered" or "point-slope" version would be welcome, especially if they are undergraduate-level.
