[site]: crossvalidated
[post_id]: 539632
[parent_id]: 7111
[tags]: 
If it helps someone, just adding on top of @raegtin's post, the following R code demonstrates how high-dimensional PCA can be done faster and more efficiently. For the following matrix $A_{m\times n}$ with $n>>m$ , the matrix $A^TA$ is a $n\times n$ matrix and not a full-rank matrix, having rank $=m$ , so that only the first $m$ eigenvalues are non-zero. Whereas $AA^T$ is a $m \times m$ matrix, which is a full-rank matrix, again with rank $m$ and $A^Tv$ is an eigenvector of $A^TA$ when $v$ is an eigenvector of $AA^T$ . But we have to keep in mind that $A^Tv$ computed that way will not be of unit length, so we need to normalize the eigenvectors computed this way. m $values vec1 vectors res $values vec2 vectors vec2 $values vec1 vectors }, "PCA_AAt" = { res $values vec2 vectors vec2
