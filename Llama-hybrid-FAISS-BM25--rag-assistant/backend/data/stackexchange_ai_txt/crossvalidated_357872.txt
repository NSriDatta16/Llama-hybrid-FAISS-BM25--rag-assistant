[site]: crossvalidated
[post_id]: 357872
[parent_id]: 
[tags]: 
What is the Identity of a convolution layer in a Neural Network?

I wanted to know what the identity of a convolutional layer of a neural network was. For standard convolution operation in mathematics the identity is the delta function, however, convolutions in neural networks is discrete and has biases in them and can have arbitrary stride and are applied to tensors (of images) usually. Despite those facts can a single convolutional layer with biases, have something equivalent/similar to an identity operation? Something easy to express as a (fake) tensor image or something like that? Some thoughts: I know that at least for simple matrices (no tensors) and the input is a 1D vector, the convolution can be expressed as some type of block-diagonal matrix. Having biases just means the last column is just a column of constants equal to the same bias. Thus, it seems simple for single filter, one can always try to compute pseudo-inverses (and I assume pseudo-inverses too) of some sort using SVDs or something like that. However, that doesn't seem to be as clean as just a delta function (e.g. a vector with a single entry of 1). Does something clean like that exist in general? In particular, at least for stride 1 and biases present in the layer? Actually I want something more like: $\| W_{conv} \star I \| = \| W_{conv} \|$ that preserves the norm of the filters of that conv layer.
