[site]: datascience
[post_id]: 123051
[parent_id]: 
[tags]: 
Is it a good idea to use attention in VAEs for image generation?

There are research papers and codebases on GitHub that deal with VAEs for image generation on popular datasets like CelebA, etc. While surfing through Google Scholar I found self-attention and other attention mechanisms improve performance of GANs, but no proper equivalent papers in case of VAEs. Is there any particular reason why? Could it be related to the fact that sampling is in any case done from a normal distribution? Or is it just because research hasn't gone that far? I found some papers that do use attention in VAEs but their objectives are very different, they deal with scene segmentation, image repainting, etc. but nothing that relates to generation capabilities. Nor did I find any articles against the use of it. Finally, if there's no issue in mixing the two, which part of the VAE should be best suited for using attention.
