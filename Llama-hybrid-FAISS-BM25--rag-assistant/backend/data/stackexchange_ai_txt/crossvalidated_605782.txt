[site]: crossvalidated
[post_id]: 605782
[parent_id]: 605774
[tags]: 
You have the right of it. You can do paired t-tests (which are not that different from RM-ANOVAs, actually), or if you have confounder variables you want to control, mixed-effect models with a random intercept for participant ID. A standard way to control for the number of tests is to apply multiple test correction - BH-FDR correction being one of the more popular ones. Is there a better way? Well, it depends on your data and your question. One approach would be to a priori identify primary and secondary outcomes of interest. First run your analyses on just the primary outcomes, correcting for multiple comparisons. Then run your analyses on all outcomes, including secondary, and correct for multiple comparisons. Probably you aren't equally interested in all outcomes, so this is the approach I'd most strongly recommend. Alternatively, if some of your outcomes are related, you could think about applying a data reduction procedure. Ideally this would be hypothesis-driven, so you could do a confirmatory factor analysis (CFA) to reduce related outcomes into one. Or you could use exploratory factor analysis (PCA, or one of it's variations) to reduce the data, if you aren't sure which outcomes are similar. But since you have repeated measures, you will want to be careful that you do it correctly.
