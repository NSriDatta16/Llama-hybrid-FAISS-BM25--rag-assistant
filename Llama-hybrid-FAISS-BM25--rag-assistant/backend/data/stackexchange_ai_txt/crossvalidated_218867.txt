[site]: crossvalidated
[post_id]: 218867
[parent_id]: 218852
[tags]: 
Let $a_i$ be an indicator as to whether individual $i$ takes the action. That is: $$ a_i = \left\{ \begin{array}{l} 1 \text{: if action taken} \\ 0 \text{: if action not taken}\end{array} \right\} $$ For each individual $i$, let $c_i$ denote the country, let $y_i$ denote the product, and let $z_i$ denote the device. You're interested in the probability of the action being taken (i.e. $a_i = 1$) conditional on your data $\{[c_i, y_i, z_i]\}$: $$ P(a_i = 1 \mid \; c_i, y_i, z_i)$$ This is a HUGELY common activity! There a bajillion different approaches to take, but I'll start with the classics Some ideas to start Many methods: Assume some functional form for $P(a_i = 1 \mid \; \mathbf{x}_i)$ (eg. linear) then Use your data to estimate parameters that describe the shape of that function (eg. estimate the coefficients of that linear function) For many of these methods, your right hand side variables (aka independent variables, regressors, etc...) probably should be indicator variables: Let $x_{1,i} = 1$ if individual $i$ comes from Canada (i.e. $c_i = \text{Canada}$) Let $x_{2,i} = 1$ if individual $i$ comes from Switzerland (i.e. $c_i = \text{Switzerland}$) etc... Do this for all possible values of your countries except one! ( See here for more explanation. You'll end up with a vector $\mathbf{x}_i$ of data for each individual. Now what to do? Ordinary least squares regression: Observe that since $a_i$ is an indicator variable, observe that $E[a_i \mid \mathbf{x}_i] = P(a_i = 1 \mid \mathbf{x}_i)$. If we assume that conditional expectation function is linear, we could estimate with classic, OLS regression . Run the regression: $$a_i = b_0 + b_1 x_{1,i} + b_2 x_{2,i} + b_3 x_{3,i} + \epsilon_i$$. Run a linear regression to estimate coefficients $\mathbf{b}$. Then you have estimated a linear conditional expectation function, which in your case would be a linear function for the probabilities. Logistic regression: For binary response data, a classic, widely used model is that the probability is the logistic function applied to $b_0 + b_1 x_{1,i} + b_2 x_{2,i} + b_3 x_{3,i}$. The model would be: $$P(a_i = 1 \mid c_i, y_i, z_i) = \frac{e^{t_i}}{1+e^{t_i}} \quad \quad t_i = b_0 + b_1 x_{1,i} + b_2 x_{2,i} + b_3 x_{3,i}$$ This is called logistic regression . There are a bajillion packages that will estimate this model for you, typically with maximum likelihood. One of many possible concerns: tons of predictors -> bad estimates This is what I think you're alluding to when you say, "The more metrics I add I have a smaller and smaller sample size..." What you're referring to is known as overfitting . If you try to estimate too many parameters relative to your data you'll often get amazing performance on your estimated sample but horrible performance on new data. So don't do that! And there are all tons of approaches to check for overfitting (eg. estimate model on 90% of sample then validate on holdout 10% of data.) Something too for your indicator variables is to use binning. Eg. Maybe group everyone using an iphone together, regardless of model. This will keep the number of parameters you're estimating down.
