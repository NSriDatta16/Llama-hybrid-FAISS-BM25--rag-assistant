[site]: crossvalidated
[post_id]: 422130
[parent_id]: 422117
[tags]: 
If you have the total sum of squares for the variable being predicted $$\mathrm{TSS}=\sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^2$$ and the residual sum of squares from the predictions from your model $$\mathrm{RSS}=\sum_{i=1}^{n}\left(y_{i}^{\,}-\hat{y}_i\right)^2$$ then you might say $$R^2 = 1-\frac{\mathrm{RSS}}{\mathrm{TSS}}$$ which makes sense as the sample $r^2$ in simple linear regression on one variable (the square of Pearson's correlation coefficient). You then might then decide to use this $R^2$ as a definition of a measure of goodness-of-fit for other models even if it ceases to be the square of anything special If your new model is in a sense worse than just using the average as a predictor, then you could have $\mathrm{RSS} \gt \mathrm{TSS}$ and so an apparent $R^2 \lt 0$ If the predicted values from your model are so bad that $\mathrm{RSS} \gt 2\,\mathrm{TSS}$ then you could have an apparent $R^2 \lt -1$
