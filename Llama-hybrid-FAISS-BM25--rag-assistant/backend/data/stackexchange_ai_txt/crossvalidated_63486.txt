[site]: crossvalidated
[post_id]: 63486
[parent_id]: 55711
[tags]: 
I would use a fixed effects ordered logit regression. If you have many observations per group, just throw in a dummy per group, and then a Wald test tells you whether, say, group A or group B receives significantly different ratings. I added the condition "many observations per group", because estimating group fixed effects via dummies is only valid asymptotically, as illustrated in this post . According to their simulations, you should have about 50 observations per group. Since you expect differences by reviewer, which is reasonable, you can also use reviewer fixed effects to account for time-invariant reviewer heterogeneity. This controls for the fact that particularly "grumpy" reviewers may review one group in particular, and without accounting for this, it would look as if that group is less important than it actually is. Adding reviewer fixed effects via dummy, however, makes the above problem more severe, because then you have more parameters to estimate with the same number of observations. Solutions on how to implement fixed effects ordered logit without relying on asymptotics are sketched here ; apparently, Stata has not implemented it officially. You can avoid the above incidental parameters problem with ordered logit if you are willing to assume your Likert scale is not merely ordinal, but cardinal. (Which implies, for example, that on average a 1 and 5 rating is as good as a 2 and 4 rating.) In this case you can simply use OLS fixed effects regression, again using fixed effects for reviewer and group. Testing the group dummies for differences will tell you whether some group is viewed as more important than another.
