[site]: crossvalidated
[post_id]: 469742
[parent_id]: 
[tags]: 
Model selection using nested cross validation

I am working on a school project using remote sensing data, for classification purposes. And I am trying to select the best model (models) for my data. The approach that I adopted is the following: Looping over different models and using K-fold cross-validation (k=10). Select the best performing model (models) Parameter grid search (or random search) for each of the models I chose in (2) Cross-validation using the best parameters I found in (3) Perform prediction Does this approach make sense? I am still in step 1 and it is already taking up so much time. I am new to machine learning, so I wanted to get some insight into how people in this domain usually tackle projects. Any advice would be highly appreciated.
