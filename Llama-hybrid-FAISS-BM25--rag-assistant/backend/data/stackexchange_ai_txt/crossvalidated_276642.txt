[site]: crossvalidated
[post_id]: 276642
[parent_id]: 276434
[tags]: 
If I understand correctly, you want to design a model which predicts best future outcomes. If so, you are not in the classical framework of machine learning, where one wants to predict $Y$ from $X$ where $Y$ given $X$ follows the same distribution as a sample of observations $(X_1,Y_1),...,(X_n,Y_n)$. In your case, the distribution might have changed since the previous observations, because of the time dependency. It seems to be the case when one looks at the graph you provided, showing the evolution of the accuracy over time. I guess you trained the random forest on the data from beginning Nov 16 (because of the 100% accuracy) and then tested it on each of the following weeks. One can see that the prediction accuracy degrades all the more as the data is more advanced in time. This is a clear indication that the distribution is time-dependent. Here are two recommendations to improve your model. 1. Tuning the parameters of the model I am surprised that you do not look for optimal parameters for your random forest. This algorithm has parameters whose values depend on the problem you consider. In particular, the depth of the trees has to be optimized, because too deep trees will lead to overfitting. It seems like the R-package you use builds trees with maximal depth by default. Classical approach: a grid-search. To tune the parameters is to test several values for the parameters (for example on a grid of values) and select the values which achieve the highest accuracy on the test set. A 100% accuracy on the training set is a sign that your model overfits. 2. Using the accuracy on a future test set to assess the performance of the model As you mentioned it, the classical approach is to randomly split the training set into two parts and use the accuracy on the test set to assess the performance of the model. In your case, since you want to maximize the prediction accuracy on future outcomes , I recommend that you rather split your training data temporally , ie . that you train the model on the first 70% observations (sorted chronologically) and test it on the last 30%. If you perform a grid-search (which I recommend), using this criterion will select the best set of parameters for future prediction.
