[site]: datascience
[post_id]: 52777
[parent_id]: 
[tags]: 
Text classification 'features imput'

I have a text classification task that consists of classifying text into classes (literary genres). I have computed the average word length and sentence length. Also, some POS relative frequency so that I can use these as features to train my model. I was thinking of using Decision Trees or another rule-based classifier. This is the first time that I created my own features for classification. Before, I relied on n-grams, vectorization, and BoW. My question is: How can I use shallow features in text classification using python ? I would like to know how the training set should look (in terms of features tabs in a csv file). Also, how can I instruct python to pick these features? This a bit of a procedure question. Thanks.
