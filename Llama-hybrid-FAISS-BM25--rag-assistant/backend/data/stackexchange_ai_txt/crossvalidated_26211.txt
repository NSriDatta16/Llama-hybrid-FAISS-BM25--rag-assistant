[site]: crossvalidated
[post_id]: 26211
[parent_id]: 26041
[tags]: 
I've always found the implicit updates framework (that includes the passive-aggressive algorithms mentioned in another answer here) to be unnecessarily more complex than the explicit updates framework (not to mention that implicit updates can be much slower than the explicit ones unless a closed-form solution for implicit update is available). Online Importance Weight Aware Updates is an example of a state-of-the-art explicit update algorithm which is simpler, faster, and more flexible (supporting multiple loss functions, multiple penalties, cost-sensitive learning etc.) than its implicit counterparts. The paper deals with linear models only though (linear svm corresponds to the case of hinge loss function with quadratic penalty) Since you need multi-class classification, one approach is to use the "reductions" functionality of vowpal wabbit (built on the top of the approach from the paper) which is not documented well unfortunately.
