[site]: crossvalidated
[post_id]: 633027
[parent_id]: 632935
[tags]: 
I first say that I'm not against Bayesian analyses in general. However I believe that there is too little talk about some issues with Bayesian analyses that in many situations make them less attractive than many seem to believe (which is of course no excuse to badly misuse and misinterpret NHST). Although a major selling point of Bayesian analyses is that background knowledge can be incorporated appropriately through the prior, in my experience the vast majority of papers presenting Bayesian analyses don't give any or only an extremely simplistic motivation of their prior choices (I often see priors that have many ingredients, distributional shapes, hyperpriors and whatnot, and justification is restricted to one parameter choice at one level of the analysis). In many cases it is rather easy to see how existing background knowledge (for example about dependencies) is not reflected in the chosen prior; it would be much harder to incorporate it properly. Generally choosing a prior that fully reflects the available knowledge and belief is very hard if you take into account all of its features instead of taking for example for granted exchangeability, that you can use a conjugate prior, and that outliers that won't fit the chosen base model don't need to be explicitly modelled (where experience often makes it close to certain that they will occur). People shrink back from doing it not only for fear of being seen as subjective, but also because it can well open a box of Pandora if you want to do it right. You often see general statements of the kind "if the sample size is large enough the prior doesn't matter", but often sample sizes are not large and/or models are complex (requiring far bigger samples). Also asymptotic theory won't normally tell you how big a sample you actually need for this to be true. Furthermore any theoretical statement of this kind requires exchangeability or a version of it, and if you don't want to assume this you are easily screwed. Proper sensitivity analyses running alternative priors that arguably are similarly compatible with the background knowledge are very rarely run (if I wanted to be mean I could suspect that they are more often run than published because the results are not as nice as people would like, but I don't really believe that it is even tried out very often; in any case, a Bayesian approach doesn't offer stronger insurance against cheating than a frequentist approach). There are issues with the basic assumption of exchangeability for Bayesian analyses. Exchangeability is a simplifying assumption "for mathematical convenience" (to paraphrase de Finetti) that nobody in most real situations would believe, as it implies an a priori commitment to ignore any information in the order of observations, i.e., you force yourself before seeing the data to predict the same next outcome after a potential sequence 001011000101110010 as if you observe 000011111111000000. I know that there are Bayesian models that don't require exchangeability, but usually such models still require exchangeability at some level or of some generalised kind (such as for innovations in a time series, rather than for the observations themselves). Furthermore, using proper Bayesian updating you can't get out of the model assumptions you made a priori unless you are willing to violate coherence, which is a basic requirement of subjective Bayesian probability. A coherent Bayesian can't learn that assumed exchangeability or normal (or whatever) distributional shape is inconsistent with the data. Although it is true that with frequentist model assumptions there are many very similar problems to those listed above, subjectivist Bayesian probabilities in fact do not model the real data generating process but rather subjective belief before seeing the data , so technically the data can't disprove your modelling and data will only redistribute probability in your assumed model class (and the philosophy will then state that if you properly believed in your choices a priori, you really should believe in the update whatever unexpected things can be seen in the data). The frequentist can just say "reality doesn't look like my model" and adapt it (although there are problems with this as well; in particular standard frequentist inference will be invalid if applied to the same data that caused you to change your model). There are issues with "objective"/informationless priors as well. In particular they may go against existing subject matter knowledge (in which case one could argue that the resulting posterior probabilities are "wrong" because they were based on a prior that doesn't reflect the belief in the given situation properly), but also they may have undesirable implications and may not agree with each other, see Kass and Wasserman "The Selection of Prior Distributions by Formal Rules" (https://doi.org/10.2307/2291752) . Personally I don't think science is about "believing", and I don't think the job of probability models is to be "true" in any sense. They are models and therefore idealisations that can be used as tools, but we should keep in mind that reality is different. Now a typical subjectivist Bayesian criticism of frequentism is that because in fact reality is not like a frequentist model (with which I agree), probability should refer to subjective belief rather than the data generating processes in reality themselves. This is a flawed idea in my view because (for the reasons given above) Bayesian models of subjective belief are simplifying idealisations as well (even though often not that simple;-). I'm as much against frequentists believing their models to be "true" as I am against Bayesians forgetting that their model deviates from their "true" belief and knowledge, but my observation is that for philosophical reasons frequentists are disposed to more easily reject and replace their models than subjectivist Bayesians, because subjectivist Bayesian philosophy suggests that the data can't falsify the model. (Note that "rejecting a model" is a binary decision often using a frequentist misspecification test; something that certain Bayesians such as George Box have embraced as well.) A Bayesian probability that the true value of parameter A in model B lies in set C in my view doesn't have a more straightforward interpretation than any frequentist probability statement once I doubt that model B is true and that there is any such thing as a true parameter value within it. I don't buy into the idea that Bayesian posterior probabilities "give the practitioner what they really want" as opposed to frequentist error probabilities, because these Bayesian probabilities concern parameters that don't exist in reality and are conditional on model choices that are hard to make (and that many practitioners are keen to avoid for often not so bad reasons, see above) and shouldn't be trusted regarding subjective belief. If we are interested in reality and we accept that models are not true regarding both real data generating processes and subjective belief, taking the detour via modelling subjective belief, incurring the requirement to specify a prior, to say something about reality doesn't look all too attractive to me - unless there is background knowledge that really helps and that can be convincingly translated into a prior. That said I state once more that I agree that misuse and misinterpretation of frequentist hypothesis tests are endemic, and that most of the problems listed above have analogous problems in frequentist inference. I am aware that a Bayesian analysis involving a well motivated prior can really help and do a good job in many situations. I have "accused" Bayesian models to be simplified idealisations above, but I'm not against using simplified idealisations at all, as long as we try to remain aware of what is "idealised away". I am also aware that the Bayesian can do certain things to deal with issues some listed above (not being too dogmatic and getting rid of a model that obviously doesn't fit is just one thing). I think that in both Bayesian and frequentist analysis it improves matters to be very conscious of the difference between models and reality and of problems that can be caused by this. One implication is that generally there is more uncertainty regarding our results and their interpetation than both frequentist and Bayesian inference will show us (which is still more than, say, journalists, politicians, or even certain scientists would want to communicate). What I like about frequentist tests is that, properly interpreted as making statements about compatibility between data and model, they do not require any belief in the model. (Of course this is ignored by many who use them.) By the way, shamelessly promoting my own work on understanding probability models without assuming them to be "true": C. Hennig: Probability Models in Statistical Data Analysis: Uses, Interpretations, Frequentism-As-Model
