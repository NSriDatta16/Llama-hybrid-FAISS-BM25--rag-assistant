[site]: crossvalidated
[post_id]: 540842
[parent_id]: 
[tags]: 
Conditional expectation on moving average errors

I'm currently solving a problem 2.2.29 (a) of textbook Mathematical Statistics: Basic Ideas And Selected Topics: 1 (Bickel, Doksum) 2nd edition, Volume I, p.147 . Let $e_i = (\epsilon_i + \epsilon_{i+1})/2, i = 1,\ldots,n$ where $\epsilon_1,\ldots,\epsilon_{i+1}$ are i.i.d. with mean zero and variance $\sigma^2$ . The $e_i$ are called moving average errors . Consider the model $Y_i = \mu + e_i, i = 1,\ldots,n$ . Show that $E(Y_{i+1} | Y_1,\ldots,Y_i)=\frac{1}{2}(\mu + Y_i)$ . That is, in this model the optimal MSPE predictor of the future $Y_{i+1}$ given the past $Y_1,\ldots,Y_i$ is $\frac{1}{2}(\mu + Y_i)$ . I was wondering whether the left hand side of the equation, which is $$E(Y_{i+1}|Y_1,Y_2,\ldots Y_i)\quad\quad\quad\quad (1)$$ is partially wrong. Instead, I think it should be $$E(Y_{i+1}|Y_i)\quad\quad\quad\quad (2)$$ With a little bit of calculation, the given equation $$E(Y_{i+1}|Y_1,Y_2,\ldots Y_i) = \frac{1}{2}(\mu+Y_i)$$ can be simplified into a equivalent form $$E(e_{i+1}|e_1,e_2,\ldots e_i)=\frac{1}{2}e_i \quad\quad\quad\quad (3)$$ But every attempt to derive the above equation (3) has failed. Instead, I think I found a counterexample to (3). Suppose that n=3 and $$\epsilon_1, \epsilon_2, \epsilon_3,\epsilon_4\overset{i.i.d}{\sim}N(0,\sigma^2)$$ Then, $$\begin{bmatrix}{e_1} \\ {e_2} \\ {e_3}\end{bmatrix} \sim N\left( \begin{bmatrix}{0} \\ {0} \\ {0}\end{bmatrix} , \begin{bmatrix}{\frac{\sigma^2}{2}} && {\frac{\sigma^2}{4}} && {0} \\ {\frac{\sigma^2}{4}} && {\frac{\sigma^2}{2}} && {\frac{\sigma^2}{4}} \\ {0} && {\frac{\sigma^2}{4}} && {\frac{\sigma^2}{2}}\end{bmatrix}\right)$$ Theorem $$\begin{bmatrix}{X_1} \\ {X_2}\end{bmatrix} \sim N\left( \begin{bmatrix}{\mu_1} \\ {\mu_2} \end{bmatrix} , \begin{bmatrix}{\Sigma_{11}} && {\Sigma_{12}} \\ {\Sigma_{21}} && {\Sigma_{22}} \end{bmatrix}\right)$$ Then, $$X_{2|X_1=x_1}\sim N(\mu_2+\Sigma_{21}\Sigma_{11}^{-1}(x_1-\mu_1),\Sigma_{22}-\Sigma_{21}\Sigma_{11}^{-1}\Sigma_{12})$$ By the above theorem, $$E(e_3|e_1,e_2)=-\frac{1}{3}e_1+\frac{2}{3}e_2$$ But if we put i=3 in equation (3), the result should be $$E(e_3|e_1,e_2)=\frac{1}{2}e_2$$ Am I missing something? Is my counterexample correct? If I'm wrong, could you please give any hint or reference that I can study to solve the problem?
