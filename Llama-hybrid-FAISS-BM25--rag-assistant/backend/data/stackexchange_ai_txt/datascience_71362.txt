[site]: datascience
[post_id]: 71362
[parent_id]: 
[tags]: 
Image classification model only predicting one class

I'm trying to build a deep learning model to predict image classes from the Kaggle competition . I'm using the Xception model as the top layers and then putting the last layer into a dense layer with the softmax output of 4. No matter what I try with the model, it only predicts one class, the first-class 'healthy', even on the training set which gets a high accuracy. The data set is imbalanced in the multiple_diseases class, but even when I use RandomOverSampler, I get the same problem. There has to be an error in the way I am uploading my images or feeding them into the model. predict function. Anyway, here is the code: healthy: 516 multiple_diseases: 91 rust: 622 scab: 592 train_df = pd.read_csv('train.csv') test_df = pd.read_csv('test.csv') targets = train_df[['healthy', 'multiple_diseases', 'rust', 'scab']] print(train_df.describe()) print(test_df.describe()) healthy multiple_diseases rust scab count 1821.000000 1821.000000 1821.000000 1821.000000 mean 0.283361 0.049973 0.341571 0.325096 std 0.450754 0.217948 0.474367 0.468539 min 0.000000 0.000000 0.000000 0.000000 25% 0.000000 0.000000 0.000000 0.000000 50% 0.000000 0.000000 0.000000 0.000000 75% 1.000000 0.000000 1.000000 1.000000 max 1.000000 1.000000 1.000000 1.000000 from keras.preprocessing.image import load_img from keras.preprocessing.image import img_to_array from tqdm.notebook import tqdm path = '/content/images/' num_img = train_df.shape[0] size = 224 train_images = np.ndarray(shape=(train_len, size, size, 3)) for i in tqdm(range(num_img)): img = load_img(path + f'Train_{i}.jpg', target_size=(size, size)) train_images[i] = np.float32(img_to_array(img)) test_images = np.ndarray(shape=(test_len, size, size, 3)) for i in tqdm(range(num_img)): img = load_img(path + f'Test_{i}.jpg', target_size=(size, size)) test_images[i] = np.float32(img_to_array(img)) from keras_preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator(rescale = 1./255, rotation_range=40, horizontal_flip=True, vertical_flip=True, fill_mode='nearest') validation_datagen = ImageDataGenerator(rescale = 1./255) train_generator = train_datagen.flow( x = x_train, y = y_train, batch_size = 32 ) validation_generator = validation_datagen.flow( x = x_test, y = y_test, batch_size = 32 ) def create_model(): pretrained_model = tf.keras.applications.Xception(input_shape=[*[224, 224], 3], include_top=False) pretrained_model.trainable = True model = tf.keras.Sequential([ pretrained_model, tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dense(4, activation='softmax') ]) model.compile( loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']) return model model = create_model() model.summary() Model: "sequential" _________________________________________________________________ Layer (type) Output Shape Param ================================================================= xception (Model) (None, 7, 7, 2048) 20861480 _________________________________________________________________ global_average_pooling2d (Gl (None, 2048) 0 _________________________________________________________________ dense (Dense) (None, 4) 8196 ================================================================= Total params: 20,869,676 Trainable params: 20,815,148 Non-trainable params: 54,528 _________________________________________________________________ epochs = 12 batch_size = 32 steps_per_epoch = 55 start_lr = 0.00001 min_lr = 0.00001 max_lr = 0.00005 rampup_epochs = 5 sustain_epochs = 0 exp_decay = .8 def lrfn(epoch): if epoch Same thing for training images: idx = 500 tester = np.reshape(train_images[idx], (1, size, size, 3)) print(tester.shape) print(train_df.iloc[idx,:]) probabilities = model.predict(tester) print(probabilities) [[1. 0. 0. 0.]] And it does that for all the training images. What is going on here? Edit: Including a description of the data set.
