[site]: crossvalidated
[post_id]: 43737
[parent_id]: 43716
[tags]: 
If the difference lies only in the relative class frequencies in the training and test sets, then I would recommend the EM procedure introduced in this paper: Marco Saerens, Patrice Latinne, Christine Decaestecker: Adjusting the Outputs of a Classifier to New a Priori Probabilities: A Simple Procedure. Neural Computation 14(1): 21-41 (2002) ( www ) I've used it myself and found it worked very well (you need a classifier that outputs a probability of class membership though). If the distribution of patterns within each class changes, then the problem is known as "covariate shift" and there is an excellent book by Sugiyama and Kawanabe . Many of the papers by this group are available on-line, but I would strongly recommend reading the book as well if you can get hold of a copy. The basic idea is to weight the training data according to the difference in density between the training set and the test set (for which labels are not required). A simple way to get the weighting is by using logistic regression to predict whether a pattern is drawn from the training set or the test set. The difficult part is in choosing how much weighting to apply. See also the nice blog post by Alex Smola here .
