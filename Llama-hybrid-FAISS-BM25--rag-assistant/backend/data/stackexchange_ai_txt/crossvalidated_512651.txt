[site]: crossvalidated
[post_id]: 512651
[parent_id]: 455351
[tags]: 
This study shows that We find that context does influence predictions, but the main factor driving high performance is learning the name tokens themselves. Then if we train a BiLSTM-CRF or BERT for such sake with not only pure named entities but also entities with context the performance would be good enough. One more option would be to extract more context from the data source and use that as a separate condition, as stated in that paper: context-only systems are sometimes correct even when humans fail to recognize the entity type from the context Our results suggest that designing models that explicitly operate over representations of local inputs and context, respectively, may in some cases improve performance
