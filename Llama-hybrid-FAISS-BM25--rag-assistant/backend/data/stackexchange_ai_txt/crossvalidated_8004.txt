[site]: crossvalidated
[post_id]: 8004
[parent_id]: 7975
[tags]: 
The same intuition as in cross-section regression can be used in time-series regression. It is perfectly valid to try to explain the trend using other variables. The main difference is that it is implicitly assumed that the regressors are random variables. So in regression model: $$Y_t=\beta_0+X_{t1}\beta_1+...+X_{tk}\beta_k+\varepsilon_t$$ we require $E(\varepsilon_t|X_{t1},...,X_{tk})=0$ instead of $E\varepsilon_t=0$ and $E(\varepsilon_t^2|X_{t1},...,X_{tk})=\sigma^2$ instead of $E\varepsilon_t^2=\sigma^2$. The practical part of regression stays the same, all the usual statistics and methods apply. The hard part is to show for which types of random variables, or in this cases stochastic processes $X_{tk}$ we can use classical methods. The usual central limit theorem cannot be applied, since it involves independent random variables. Time series processes are usually not independent. This is where importance of stationarity comes into play. It is shown that for large part of stationary processes the central limit theorem can be applied, so classical regression analysis can be applied. The main caveat of time-series regression is that it can massively fail when the regressors are not stationary. Then usual regression methods can show that the trend is explained, when in fact it is not. So if you want to explain trend you must check for non-stationarity before proceeding. Otherwise you might arrive at false conclusions.
