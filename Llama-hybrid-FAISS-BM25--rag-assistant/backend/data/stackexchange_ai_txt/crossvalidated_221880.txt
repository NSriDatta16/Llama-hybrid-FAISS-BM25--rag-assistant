[site]: crossvalidated
[post_id]: 221880
[parent_id]: 
[tags]: 
Why does lasso not converge on a penalization parameter?

To explore how the LASSO regression works, I wrote a small piece of code that should optimize LASSO regression by picking the best alpha parameter. I cannot figure out why the LASSO regression is giving me such unstable results for the alpha parameter after cross validation. Here is my Python code: from sklearn.linear_model import Lasso from sklearn.cross_validation import KFold from matplotlib import pyplot as plt # generate some sparse data to play with import numpy as np import pandas as pd from scipy.stats import norm from scipy.stats import uniform ### generate your own data here n = 1000 x1x2corr = 1.1 x1x3corr = 1.0 x1 = range(n) + norm.rvs(0, 1, n) + 50 x2 = map(lambda aval: aval*x1x2corr, x1) + norm.rvs(0, 2, n) + 500 y = x1 + x2 #+ norm.rvs(0,10, n) Xdf = pd.DataFrame() Xdf['x1'] = x1 Xdf['x2'] = x2 X = Xdf.as_matrix() # Split data in train set and test set n_samples = X.shape[0] X_train, y_train = X[:n_samples / 2], y[:n_samples / 2] X_test, y_test = X[n_samples / 2:], y[n_samples / 2:] kf = KFold(X_train.shape[0], n_folds = 10, ) alphas = np.logspace(-16, 8, num = 1000, base = 2) e_alphas = list() e_alphas_r = list() # holds average r2 error for alpha in alphas: lasso = Lasso(alpha=alpha, tol=0.004) err = list() err_2 = list() for tr_idx, tt_idx in kf: X_tr, X_tt = X_train[tr_idx], X_test[tt_idx] y_tr, y_tt = y_train[tr_idx], y_test[tt_idx] lasso.fit(X_tr, y_tr) y_hat = lasso.predict(X_tt) # returns the coefficient of determination (R^2 value) err_2.append(lasso.score(X_tt, y_tt)) # returns MSE err.append(np.average((y_hat - y_tt)**2)) e_alphas.append(np.average(err)) e_alphas_r.append(np.average(err_2)) ## print out the alpha that gives the minimum error print 'the minimum value of error is ', e_alphas[e_alphas.index(min(e_alphas))] print ' the minimizer is ', alphas[e_alphas.index(min(e_alphas))] ## >> plt.figsize = (15, 15) fig = plt.figure() ax = fig.add_subplot(111) ax.plot(alphas, e_alphas, 'b-') ax.plot(alphas, e_alphas_r, 'g--') ax.set_ylim(min(e_alphas),max(e_alphas)) ax.set_xlim(min(alphas),max(alphas)) ax.set_xlabel("alpha") plt.show() If you run this code repeatedly, it gives wildly different results for alpha: >>> the minimum value of error is 3.99254192539 the minimizer is 1.52587890625e-05 >>> ================================ RESTART ================================ >>> the minimum value of error is 4.07412455842 the minimizer is 6.45622425334 >>> ================================ RESTART ================================ >>> the minimum value of error is 4.25898253597 the minimizer is 1.52587890625e-05 >>> ================================ RESTART ================================ >>> the minimum value of error is 3.79392968781 the minimizer is 28.8971008254 >>> Why is the alpha value not converging properly? I know that my data is synthetic, but the distribution is the same. Also, the variation is very small in x1 and x2 . what could be causing this to be so unstable? The same thing written in R gives different results - it always returns the highest possible value for alpha as the "optimal_alpha". I also wrote this in R, which gives me a slightly different answer, which I don't know why? library(glmnet) library(lars) library(pracma) set.seed(1) k = 2 # number of features selected n = 1000 x1x2corr = 1.1 x1 = seq(n) + rnorm(n, 0, 1) + 50 x2 = x1*x1x2corr + rnorm(n, 0, 2) + 500 y = x1 + x2 filter_out_label The output from the R code above is: > source('~.....') [1] "the optimal alpha is 1e+06" In fact, no matter what I set for the line " alphas = logspace(-5, 6, 100) ", I always get back the highest value for alpha. I guess there are actually 2 different questions here : Why is the alpha value so unstable for the version written in Python? Why does the version written in R give me a different result? (I realize that the logspace function is different from R to python , but the version written in R always gives me the largest value of alpha for the optimal alpha value, whereas the python version does not). It would be great to know these things...
