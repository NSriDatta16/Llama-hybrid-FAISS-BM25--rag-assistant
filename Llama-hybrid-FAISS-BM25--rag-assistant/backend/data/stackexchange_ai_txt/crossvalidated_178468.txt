[site]: crossvalidated
[post_id]: 178468
[parent_id]: 178461
[tags]: 
There are lots of ways to analyse this information. Throwing stuff into a sophisticated but turnkey piece of software like SmartPLS expecting an answer to pop out is a recipe for shooting yourself in the foot. PLS is a sophisticated multivariate technique and you didn't indicate whether or not you've done any simple, exploratory groundwork that would build up to that level of complexity. I'm guessing that the two item sets you describe are drawn straight from the survey's framework and question flow. Given that, positive and negative associations are testable and (even if these items have been analyzed before) retestable assumptions. Why not do a factor analysis of those 20 items all at once to see if 1), you recover the item blocks in the survey and 2), where the redundancies are across all the questions. If you don't recover the original item block design, then there's no statistical reason to retain it and you can move to a cohesive treatment or pooling of the 20 items. Next, consider examining the pairwise relationships between your ordinal items and your dependent variables (DVs). Given the 0,1 nature of the DVs, logistic regression would be a more rigorous approach to use but, at this stage, there's nothing wrong with OLS regression either. One thing that might be interesting would be to rescale or collapse these two variables into one variable representing two things taken two at a time, i.e., no-no, no-yes, yes-no, yes-yes combinations. You can treat this new DV as having an ordinal relationship and run ordinal regression on it. The significance and strength of the pairwise associations will put a stake in the ground for the next, more sophisticated phase of the analysis -- predictive modeling. At this point, you should definitely partition your respondents into randomly assigned groups: one for calibrating your model and a second for out-of-sample model validation. K-fold cross-validation is another option. Whatever you do, in the absence of out-of-sample validation, any resulting predictive model will be unreliably optimistic. Having established that there are pairwise relationships, the question I'm left with concerns the best way to understand any "multivariate" relationships as in a predictive model. You're predisposed towards PLS and a factor analysis of the 20 items as input. I would like to challenge that assumption. The reasons for this are that, while you can do this, the resulting factors are harder to interpret -- you would lose the specificity and meaning of each unique item. That said, variable selection and importance is a field about which every statistician and their brother has either an opinion or a paper -- there are no shortage of possible methods. My preference is for the Lasso or random forests, but the decision is probably more a function of your level of understanding and what your software allows you to do. So, whatever you do, you will end up with a reduced set of model inputs -- typically between a few and 8 or so variables -- that need to be groomed into a final model. This is where the expertise of a good modeler really comes into play. As already noted, PLS and SEM are one option among a plethora of methodologies. Have a field day!
