[site]: crossvalidated
[post_id]: 405636
[parent_id]: 
[tags]: 
Efficiently normalize word embeddings

I'm using glove word embedding and would like to [-1,1] normalize it using python. The data is in the format of a dict with the word as key and a np array as value. Thus I would have to loop through all 2m entries, get the min and max and then loop again to normalize it. Is there a more efficient way to do that? Thanks in advance!
