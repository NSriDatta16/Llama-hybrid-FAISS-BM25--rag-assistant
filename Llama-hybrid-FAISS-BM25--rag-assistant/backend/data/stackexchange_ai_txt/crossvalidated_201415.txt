[site]: crossvalidated
[post_id]: 201415
[parent_id]: 
[tags]: 
Randomizing Class Labels during classification to asses the feature selection results

I have a binary classification problem with thousands of variables and less than a hundred data points and class labels. The class is imbalanced (24 positive 51 negative samples). I have selected some of the features using subset selection method. The AUC of classification using XGBOOST feature selection (10 variables) is approximately 85%. Just to make sure that the apparent accuracy is not overstated (biased from overfitting)?, I ran an experiment such that: I took all the 10 variables as it is and I just randomly shuffle the class labels such that the number of positive samples and negative samples are same. When I run such experiments 1000 times, I get highest AUC of 75% and the average peaks at around 60%. So, my question here is: When class labels are flipped (permuted) shouldn't the AUC of classification peak at 50%? Is the result shown in the density plot as expected? I also get the AUC values less than .50 using the following R code using ROCR package: predf I read that it means classification is negative. Can anybody explain in understandable terms, what that means?
