[site]: stackoverflow
[post_id]: 4077935
[parent_id]: 4077922
[tags]: 
Big O is standard. Although developed as a part of pure mathematics, this notation is now frequently also used in the analysis of algorithms to describe an algorithm's usage of computational resources: the worst case or average case running time or memory usage of an algorithm is often expressed as a function of the length of its input using big O notation.
