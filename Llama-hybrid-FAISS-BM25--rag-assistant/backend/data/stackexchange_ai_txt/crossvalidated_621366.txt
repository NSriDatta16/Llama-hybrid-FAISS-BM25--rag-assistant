[site]: crossvalidated
[post_id]: 621366
[parent_id]: 567964
[tags]: 
Your random forest and neural network models consider all sorts of (nonlinear) interactions between the raw features. For instance, a neural network can score extremely high on data like the following, with a $25$ -node MLP scoring an AUC of $0.9997$ . library(ggplot2) library(nnet) library(MASS) library(pROC) set.seed(2023) N However, the x1 and x2 features on their own have no ability to distinguish between red and blue. The marginal distribution of x1 is $U(0, 1)$ for both red and blue, and the marginal distribution of x2 is $U(0, 1)$ for both red and blue. It is only when you consider the joint distribution through an interaction between the features , which your SHAP plot appears not to show. I think this is what has happened, that no one feature is important, but some combination of features winds up being quite important and is discovered by the machine learning model that is meant to learn such relationships without being explicitly programmed. d10 $Group Group) p2
