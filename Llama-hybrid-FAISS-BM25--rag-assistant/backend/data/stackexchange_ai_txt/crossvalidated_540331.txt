[site]: crossvalidated
[post_id]: 540331
[parent_id]: 540304
[tags]: 
Your intuition is correct. I.i.d. errors is the ideal, and autocorrelation in their absolute values or squares violates that. For some models and some of their uses, uncorrelated errors may be good enough. E.g. in a regression with time series data, uncorrelated but dependent errors could yield consistent and unbiased estimates and prediction intervals that have correct coverage unconditionally (on average over time). This may be good enough. Meanwhile, i.i.d. errors could yield consistent, unbiased and efficient estimates and prediction intervals with correct coverage conditional on all available information . This is better. Examining autocorrelation in absolute values and/or squares of residuals is standard practice when one suspects presence of autoregressive conditional heteroskedasticity. This is common e.g. in financial variables such as stock prices or their logarithmic returns. Model such as GARCH are used to account for such autocorrelation.
