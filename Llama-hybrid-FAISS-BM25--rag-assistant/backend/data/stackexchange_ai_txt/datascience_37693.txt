[site]: datascience
[post_id]: 37693
[parent_id]: 37687
[tags]: 
I think you are confused on many levels here. Logistic regression is a classifier. It gives you the probability that given an $x_{i}$, the probability it belongs to a class or classes. So you will be having your evalinvest as classes, not continuous values. When you call predict method on top of trained LogisticRegression model, it predicts class for each $x_{i}$ in your test set. So you expect a single array of class labels they belong to. sklearn.metrics.confusion_matrix function takes in the original class values to the ones that are predicted by the model you had trained and returns what $x_{i}$ has been classified into what class. So it returns an n(c) x n(c) array where n(c) is the number of classes. So the diagonal of the matrix indicates the number of elements of class i being classified as class i . And an ideal model should be expected to get this numbers good. The mistake which you had made you sent in your X (train) matrix into it and y (labels) into it, which is wrong. You are supposed to send in y_true (true labels) and y_pred (predicted labels from the model). Check the documentation for more. Ideally the function should have thrown an error. But unfortunately you had only one row in your X and one in y and they both are of same size and it passed assert it had to make. And np.ravel converts an multi-dimensional array into 1D array. So if you doing a binary classification, you would be having a 2x2 matrix, whose flattened array would have been four elements and the assignment would have worked. But the ravelling you had made releases $n(c)^2$ elements. So there you go ValueError . See the docs I hope my other answer on confusion matrices may clear things a little more. Hope it clears some mistakes you are making.
