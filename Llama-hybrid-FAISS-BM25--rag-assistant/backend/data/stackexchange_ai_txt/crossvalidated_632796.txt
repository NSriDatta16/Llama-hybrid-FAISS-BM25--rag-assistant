[site]: crossvalidated
[post_id]: 632796
[parent_id]: 386369
[tags]: 
Shawn that is a wonderful answer but it’s important to point out a subtle problem with a small part of it. The “in the long run we should not often be wrong” statement of Neyman and Pearson is an example of a tragic logic error which Fisher also made at times and is addressed in the terrific book by Aubrey Clayton Bernoulli’s Fallacy . The chance of being wrong about an assertion that an effect is present is an unconditional probability with respect to the unknown parameter, i.e., the probability of a mistake is not conditional on $H_0$ . Yet the N&P and Fisher justifications go on to assume $H_0$ in describing the value and meaning of the procedure. The probability of making a mistake in asserting an effect needs to be conditional on the evidence used in making the assertion and not condition on the unknown value of an effect parameter. When $H_0$ is true then any assertion of an effect is a mistake by definition. The probability of a mistake is the Bayesian posterior probability that the effect is zero or is in the opposite direction. This gets the conditioning right. For example the probability that a regulatory agency makes a mistake in approving a drug to be marketed is the probability that the drug doesn’t work. It is not the probability of asserting that the drug works when it doesn’t work, as we are past that in the logic flow. If the drug was approved because the probability of efficacy was 0.96, the probability of in efficacy, i.e., the probability of an error, is 0.04.
