[site]: datascience
[post_id]: 52978
[parent_id]: 
[tags]: 
Is it OK to train a binary classifier using all the extremely imbalanced data if the majority class is negative?

I'm training a neural network as a binary classifier for text classification. The data is very imbalanced, where the ratio of TRUE:FALSE is approximately 100:10000 Intuitively, it feels like using all the negative samples would prevent the classifier from learning invalid patterns (that might otherwise be learned using undersampling, for example). Am I underestimating the effect of the imbalance on classifier performance?
