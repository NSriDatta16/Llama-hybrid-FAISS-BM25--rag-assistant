[site]: datascience
[post_id]: 81411
[parent_id]: 81377
[tags]: 
I think the other comments about improved feature engineering and sharing more about your problem statement are correct. I would just add that one helpful tip when thinking through these kinds of problems could be how you as an expert would classify these points by hand. If you would have trouble manually separating the two classes (which the distribution you have shown would lead us to believe), then almost any ML model will have the same trouble. Without knowing more I'd say that this is potentially related to the concept of Bayes error rate (the amount of intrinsic error which cannot be further reduced with better modeling). If you flip a fair coin, sometimes you will get heads and sometimes you will get tails. There are no better features which will help you decide how to map that action (flipping the coin) to a value (heads/tails), there will always be some intrinsic error because the process itself is random. In case you are interested: https://en.wikipedia.org/wiki/Bayes_error_rate
