[site]: datascience
[post_id]: 52596
[parent_id]: 52594
[tags]: 
If your model is simple and you don't have a lot of training data, then you need a model with few parameters to compare to, or else you won't be able to train it. Using standard CNN architectures may not be a good option in this case, because even if the point of using a CNN rather than a full-connected network is to reduce the parameters, they still have many millions of parameters. Depending on the details of the problem, I think you have to design something yourself. Have a look at this Kaggle guide on choosing a CNN architecture . If you have a lot of input data and a complex model that you're comparing to, I would recommend using a standard architecture that people are familiar with, such as VGG-16 or VGG-19, so that a performance comparison means something to the reader. You can get these models with pretrained weights, so you don't need to do any training necessarily. However, they are set up for multiclass classification and typically trained on ImageNet, so you need to adapt the classification part. The simplest way is to replace the last (output) layer with a single output node for your binary classification. To make a fair comparison you then need to train the entire model on the same training dataset used for your model, and evaluate on the same test set. But I would start by retraining the final FC layers first, to get a quick preview of how it's going. Then retrain the full model for the fair comparison.
