[site]: datascience
[post_id]: 23416
[parent_id]: 
[tags]: 
How to map ground truth to prediction for UNet architecture

I've gone through the paper describing the UNet convolutional neural network a number of times, but am still having trouble figuring out how to connect the output of the network to the ground truth targets. Below is an image depicting the architecture of the network. (source: uni-freiburg.de ) As can be seen from the figure, the output is a 388 x 388 x k matrix (where k is the number of classes). The target segmentation in this case should be 572 x 572 (same spatial dimensions as the input image). How do we match these up? Are we suppose to perform some kind of interpolation on the output feature map to get it to match the dimensionality of the input?
