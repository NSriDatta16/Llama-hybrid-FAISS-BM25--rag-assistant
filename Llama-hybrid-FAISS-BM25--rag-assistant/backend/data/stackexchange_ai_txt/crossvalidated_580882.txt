[site]: crossvalidated
[post_id]: 580882
[parent_id]: 
[tags]: 
What does the Cross-Validation procedure try to estimate?

Let's consider an untrained classifier $f$ (with fixed hyperparameters) and a dataset $S = (x_i, y_i)_{i=1...n}$ sampled i.i.d from some unknown distribution $P$ . What is the unknown quantity that a k-fold CV tries to estimate? Is it: the expected accuracy of the classifier $f_S$ trained on $S$ : $E_{(x_i,y_i)\sim P}[1-L(y_i, f_S(x_i))]$ , where $L$ is the 0-1 loss. In other words we don't care about the variability coming from the training set. the quantity above, but averaged over all training sets of size $n$ : $E_S E_{(x_i,y_i)\sim P}[1-L(y_i, f_S(x_i))]$ . The answer is not clear from the wikipedia page . My guess is that CV tries to estimate the second definition, as it seems more relevant for the purpose of model selection or algorithm comparison.
