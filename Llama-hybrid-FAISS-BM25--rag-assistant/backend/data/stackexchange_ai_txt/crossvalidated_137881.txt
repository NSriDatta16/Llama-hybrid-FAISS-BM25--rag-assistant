[site]: crossvalidated
[post_id]: 137881
[parent_id]: 137869
[tags]: 
Out-of-time validation is just out-of-sample validation on a later data-set than that on which you fitted your model; where application of a model to a population changing over time is the concern, rather than application to populations of different cities, species, materials, or whatever. So to do it you'd need samples from different times (& note that if you had those at the time of fitting the model it'd usually be more useful to use the whole data-set & include time in the model). It's anyone's guess whether it would have alerted you to a problem in this particular case. The calibration of a model often degrades much faster than its discrimination (I'd bet that changing the probability cut-off used to predict a churner would have resulted in greater accuracyâ€”are you monitoring discrimination & calibration?), so re-calibration once in a while can be helpful. See Steyerberg et al. (2004), "Validation and updating of predictive logistic regression: a study on sample size and shrinkage", Statistics in Medicine , 23 , p.2567.
