[site]: crossvalidated
[post_id]: 234343
[parent_id]: 232727
[tags]: 
You might consider interpreting your neural network as a probabilistic graphical model. From "An Introduction to Variational Methods for Graphical Models" , Jordan et al: Neural networks are layered graphs endowed with a nonlinear "activation" function at each node (see figure 5). Let us consider activation functions that are bounded between zero and one, such as those obtained from the logistic function $f(z) = 1/(1 + e^{âˆ’z})$. We can treat such a neural network as a graphical model by associating a binary variable $S_i$ with each node and interpreting the activation of the node as the probability that the associated binary variable takes one of its two values. [...] The advantages of treating a neural network in this manner include the ability to perform diagnostic calculations, to handle missing data, and to treat unsupervised learning on the same footing as supervised learning. Realizing these benefits, however, requires that the inference problem be solved in an efficient way. Later portions of the paper discuss how to do this efficiently. It would seem you could "highlight" a feature by changing the prior placed on its associated parameters.
