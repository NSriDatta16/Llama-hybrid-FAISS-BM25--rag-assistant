[site]: datascience
[post_id]: 32110
[parent_id]: 
[tags]: 
Automatic Semantic Clustering and Tagging of sentences using NLP

NLP Analysis for keyword clustering I have a set of keywords for search engines and I would like to create a python script to classify and tag them under unknown categories. To make it clear I should have an output like this one, without knowing the categories (Product, Colour, Accessory, Brand...): +----------------------------+------------+----------+--------------+-----------+ |.......Keywords............|.Product...|.Colour.|.Accessory.|.Brand...| +----------------------------+------------+----------+--------------+-----------+ |.red shoes with heels.|.shoes......|.red......|.heels.........|..............| |.Apple computer.........|.computer.|............|..................|.Apple....| |.Armani blue shoes....|.shoes......|.blue.....|..................|.Armani..| |.black mouse..............|.mouse.....|.black...|..................|..............| |.gaming laptop...........|.computer.|.............|..................|..............| +----------------------------+------------+----------+--------------+-----------+ Any suggestions on how I could be able to do it? I am currently using Word2Vec to find similarities between words and some APIs to recognize Brands and entities in the keywords model2 = models.Word2Vec.load('semantic_clustering/datasets/it/it.bin') with open('tmp/kw_msm.txt') as f: kwlist = f.readlines() kwlist = [x.strip() for x in kwlist # unique_words = list(set([word for word in kw.split(' ') for kw in kwlist])) freq_words = defaultdict(int) words = set() for kw in kwlist: for word in kw.split(' '): freq_words[word] += 1 words.add(word) sorted_freq_words = sorted(freq_words.items(), key=operator.itemgetter(1), reverse=True) # Creating Dataframe with words as columns df = pd.DataFrame(columns=words) df['keyword'] = kwlist for i, row in df.iterrows(): for w in row['keyword'].split(): df.loc[i, w] = 1 good_words = [w for w in words if kw_in_vocab(w, model2)] KW_MODEL = model2[good_words] NUM_CLUSTERS = 10 kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25) assigned_clusters = kclusterer.cluster(KW_MODEL, assign_clusters=True) clusters = {} for i, w in enumerate(good_words): clusters[w] = assigned_clusters[i] sorted_clusters = sorted(clusters.items(), key=operator.itemgetter(1)) for k in sorted_clusters: print(k) This is a snippet of code I am using, creating a sparse matrix of words and clustering the columns with a fixed number of clusters, it's only a first test
