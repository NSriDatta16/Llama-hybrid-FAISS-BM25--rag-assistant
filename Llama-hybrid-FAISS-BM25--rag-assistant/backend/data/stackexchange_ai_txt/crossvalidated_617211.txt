[site]: crossvalidated
[post_id]: 617211
[parent_id]: 
[tags]: 
How to properly visualize high-dimensional embeddings along with the decision boundary in 2D?

I have a number of embeddings (300-dimensional FastText vectors for each instance of each class) that I apply a classifier to (Logistic Regression for now). I want to visualize the embeddings as well as the decision boundary as part of model debugging so I can see which classes are not linearly separable, which instances are misclassified etc. I'm not sure if using PCA or K-PCA is a good idea here. Or even t-SNE (since it's non-linear when Logistic Regression is a Linear Model so maybe the separation found by t-SNE can't be achieved by LR?) I'm looking for a procedure that will maintain the same structure (if two instances are close in the higher dimension they should still be so in the 2-D one) while making sure that the decision boundary is still correct. How should I go about this? Thanks.
