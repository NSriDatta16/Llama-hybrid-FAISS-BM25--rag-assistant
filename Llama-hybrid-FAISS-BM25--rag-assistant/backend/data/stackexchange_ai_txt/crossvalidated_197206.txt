[site]: crossvalidated
[post_id]: 197206
[parent_id]: 155088
[tags]: 
Let's use the example of the SVM loss function for a single datapoint: $L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]$ Where $\Delta$ is the desired margin. We can differentiate the function with respect to the weights. For example, taking the gradient with respect to $w_{yi}$ we obtain: $\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) \right) x_i$ Where 1 is the indicator function that is one if the condition inside is true or zero otherwise. While the expression may look scary when it is written out, when you're implementing this in code you'd simply count the number of classes that didn't meet the desired margin (and hence contributed to the loss function) and then the data vector $x_i$ scaled by this number is the gradient. Notice that this is the gradient only with respect to the row of $W$ that corresponds to the correct class. For the other rows where $jâ‰ {{y}_{i}}$ the gradient is: $\nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i$ Once you derive the expression for the gradient it is straight-forward to implement the expressions and use them to perform the gradient update. Taken from Stanford CS231N optimization notes posted on github .
