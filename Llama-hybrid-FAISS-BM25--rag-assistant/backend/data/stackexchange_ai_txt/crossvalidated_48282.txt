[site]: crossvalidated
[post_id]: 48282
[parent_id]: 
[tags]: 
How to reliably estimate a random sum of unreliable elements?

This is an ill posed problem I'm faced with at work. I have observations $X_i$, $i = 1,2,3,...N > M$. I need want to compute $S = \sum_{i=1}^M X_i$. Unfortunately, $M$ is random, and extremely noisy. It turns out, I have some rough "goodness" measures, $w_i$ for each of the $X_i$. That is, $w_i$ low, means I don't trust $X_i$ very much, $w_i$ high, means I trust $X_i$ a lot. Moreover, "generally" as $i$ gets large, the $X_i$ get small. (There's a lot of dependence between $M$ and the $X_i$) In this application, it turns out that the average of the $X_i$ can very reliably (i.e. with relatively small standard deviation) be computed by: $A = \frac{\sum_{i=1}^M w_i X_i}{\sum_{i=1}^M w_i}$. We know the standard deviation of $A$ is relatively small by running a number of independent trials, and computing the sample standard deviation. But, I similarly need a "good" estimate (i.e. small standard deviation) of the straight sum of the $X_i$ and the obvious approach: $M * A$ has far too much variance for our application. Understand this is pretty vague, but any thoughts on how to proceed?
