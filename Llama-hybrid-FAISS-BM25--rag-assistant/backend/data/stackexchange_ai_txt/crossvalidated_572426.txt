[site]: crossvalidated
[post_id]: 572426
[parent_id]: 572416
[tags]: 
Yes, you can. There are several Bayesian optimization algorithms, but let's use the Gaussian process as an example as it is the most popular one. The Gaussian process learns to approximate the distribution of the functions that you want to optimize. Next, given the learned distribution you have some optimization criteria, the acquisition function, that is used to pick a candidate to check next. The candidate is evaluated "in the wild" and the result is fed to the Gaussian process so it can update with new data and generate a new candidate. The acquisition function is something like upper confidence bound, expected improvement, probability of improvement, etc, or out can use Thompson sampling ( Russo et al, 2017 ) and pick the candidate at random, with the probability proportional to the probabilities learned by the Gaussian process. Nothing prohibits you from picking the $k$ highest values according to the acquisition function or sampling $k$ values using Thompson sampling, instead of a single value. Same, you can do a Bayesian update of the learned distribution with multiple values, not only with a single value. The downside is that by checking a single value you can update your knowledge (the learned distribution) instantly, while with many values you update it in batch. What this means is that in exploration-exploitation you focus more on exploration. It can have pros and cons, with more data you gain more knowledge about the explored region of the distribution. On another hand, it can make you slower as you may unnecessarily check all those scenarios while checking a single one might be enough to learn that it was a bad idea. Using Thompson sampling in such a case would enable you to be more explorative.
