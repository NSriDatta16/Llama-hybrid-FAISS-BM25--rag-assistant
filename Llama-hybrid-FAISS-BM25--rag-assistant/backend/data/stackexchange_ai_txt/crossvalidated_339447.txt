[site]: crossvalidated
[post_id]: 339447
[parent_id]: 146092
[tags]: 
MSE (Mean Squared Error) is mean of squared error i.e. the difference between the estimator and estimated. MMSE (Minumum Mean Square Error) is an estimator that minimizes MSE. Hence LSE and MMSE are comparable as both are estimators.LSE and MSE are not comparable as pointed by Anil. There are some important differences between MMSE and LSE, theoretically. MMSE is optimal for all realizations of the process while LSE is optimal for the given data itself. This is because MMSE uses ensemble averages (expectation) while LSE uses time average. What it means practically is : 1. For MMSE you need to know the second order statistical properties of the data (crosscorrelation and autocorrelation), while for LSE you need only the data. Autocorrelation & crosscorrelation is computationally expensive and an accurate calculation needs a lot of data points/experiments. 2. MMSE coefficients are optimal for the process so it is optimal for all datasets of the process while LSE is optimal only for the particular data set. LSE coefficients will not remain optimal if dataset changes. Also please note that MMSE approaches LSE if the process is ergodic and the number of data points approaches infinity.
