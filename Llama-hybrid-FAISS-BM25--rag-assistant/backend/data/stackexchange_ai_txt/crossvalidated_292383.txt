[site]: crossvalidated
[post_id]: 292383
[parent_id]: 
[tags]: 
Image classification: Using image augmentation to resolve class imbalance

I am working on an image based classification task with some significant class imbalance in the training database of images (largest class: 4967 images, smallest class: 61 images). I will be experimenting with two different machine learning approaches for this purpose (SVM and CNN), and will need to use the same training data for each approach. I was planning on synthesizing additional training data by applying some simple transformations to the original images (rotation, flipping, and altering brightness), and think this is a good opportunity to also resolve the problem of class imbalance by creating more augmented images for the less frequent image classes. My query regarding this essentially has two elements: 1) Is there a sensible limit to how much data I can synthesize in this manner? Obviously I could increase the frequency of the least frequent class by a factor of 359 if I simply apply rotation transformations in 1 degree steps. However, I am concerned creating many similar images from the same source image will result in over-fitting, or have some other negative impact. 2) If there is a limit on the amount of data synthesis it is sensible to do: can any one offer advice on balancing the trade-off between not synthesizing too much data and reducing class imbalance via data augmentation? I would be particularly interested in input from anyone who has dealt with similar problems in practice before
