[site]: crossvalidated
[post_id]: 105711
[parent_id]: 105695
[tags]: 
I would like to know why 1/N * Summation of(y/x) is a worse estimator than average of y divided by average of x. The claim that it's worse is not necessarily true. Consider three situations, where $\beta$ represents some "population ratio" (in that for each, $\frac{_{E(Y|x)}}{^x} = \beta$): $y = \beta x + e;\quad \text{Var}(e)=\sigma^2\,,\quad$ equivalently $\text{Var}(\frac{Y|x}{x})=\sigma^2/x^2$ $y = \beta x + e;\quad \text{Var}(e)=\sigma^2x\,,\quad$ equivalently $\text{Var}(\frac{Y|x}{x})=\sigma^2/x$ $y = \beta x + e;\quad \text{Var}(e)=\sigma^2x^2\,,\quad$ equivalently $\text{Var}(\frac{Y|x}{x})=\sigma^2$ The optimal weights for a least squares estimate of $\beta$ ($\sum w_ix_iy_i/\sum w_ix_i^2$ ) are inversely proportional to variance, yielding the estimators: $\hat \beta = \sum x_iy_i/\sum x_i^2$ $\hat \beta = \sum y_i/\sum x_i= \bar{y}/\bar{x}$ $\hat \beta = \frac{1}{n}\sum y_i/x_i$ Note that all three estimators have the same expectation, $\beta$, so all are unbiased. However, if you use the wrong variance function, then (i) the estimator is suboptimal and (ii) the usual standard error of $\hat \beta$ will be biased. So which is better will depend on the circumstances - either may be better in the right situation, and in some situations, both may be worse than some other choice.
