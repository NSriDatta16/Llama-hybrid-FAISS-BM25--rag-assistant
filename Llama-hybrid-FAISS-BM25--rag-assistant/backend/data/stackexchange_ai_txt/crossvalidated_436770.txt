[site]: crossvalidated
[post_id]: 436770
[parent_id]: 436410
[tags]: 
Let $$ \hat{\mu}_h:= \dfrac{1}{N} \sum_{t=1}^{N} h(X_t)\,. $$ Suppose a CLT does not hold for $\hat{\mu}_h$ . In order to estimate the standard error, it must be finite. That is, even though a CLT does not hold $$ \sigma^2_h:=\lim_{N \to \infty} N\text{Var}_{\pi}(\hat{\mu}_h) As long as we are willing to assume $\sigma^2_h , then by Kipnis and Vardhan(1986) , Theorem 1.1, for reversible Markov chains $$ \dfrac{1}{\sigma^2_h \sqrt{N}} (N \hat{\mu}_g - \mu) \overset{d}{\to} N(0, 1)\,. $$ In order to construct confidence intervals etc, $\sigma^2_h$ must be estimated, and in order to ensure normality in the limit, a consistent estimator of $\sigma^2_h$ is required. Unfortunately, consistency of estimators of $\sigma^2_h$ typically requires geometric or polynomial ergodicity ( Jones et. al (2006) , Vats et. al. (2019) ). Thus, in order to estimate $\sigma^2_h$ consistently, we will typically need to make these stronger assumptions on the process. However, one can used "fixed batch" estimators which are not consistent, in which case the asymptotic distribution is non-normal, but one exists. This argument can be found in detail in Atchade(2014) .
