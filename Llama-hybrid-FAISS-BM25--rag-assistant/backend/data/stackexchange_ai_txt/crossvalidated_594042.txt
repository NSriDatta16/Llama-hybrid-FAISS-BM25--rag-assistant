[site]: crossvalidated
[post_id]: 594042
[parent_id]: 
[tags]: 
What have we learned from time series competitions (or Kaggle)?

What are the main takeaways we, as statistics community, learned from (time series) competitions? Kaggle, or the M.. competitions, seem such a valuable source, but the (only) main insight I remember is that boosting algorithms such as LightGBM or XGBoost tend to work very well. I am currently teaching a course on practical machine learning and want to tell the students the main insights gained in time series modeling in the wild. I am also wondering whether it still makes sense to talk about the theory behind ARIMA, for example (depending on whether the algorithm is still competitive in practice). Before raising this question, I had a look at the conclusions of the M5 competition , but some of the key takeaways, such as Exogenous/explanatory variables were important for improving the forecasting accuracy of time series methods. seem rather trivial. What I am looking for is a kind of meta-study aggregating the results of different competitions. Btw, this is (surprisingly) the only related question I found here.
