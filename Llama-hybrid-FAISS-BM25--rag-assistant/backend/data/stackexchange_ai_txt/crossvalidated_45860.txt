[site]: crossvalidated
[post_id]: 45860
[parent_id]: 
[tags]: 
Model to detect abnormalities in two-value data?

I have a question concerning data that oscillates between two primary value ranges, and how one might go about determining any performance metrics or abnormalities in that data. Example: I have a text file of values that cluster at approximately 6000, and approximately 12000; the low value, and the high value respectively. I wish to determine some useful metric to perform on this data over a time range, to determine times when the data was "abnormal." How would one go about determining variations in this data, plus or minus a certain percentage? My current tactic is to take an average just so I can display some kind of metric, but clearly this is not the way to go for this data set.
