[site]: crossvalidated
[post_id]: 505999
[parent_id]: 
[tags]: 
Lost in Bayes: constructing a learner/classifier with noisy training data/inputs to simulate experimental data

I'd like help with tackling this toy-problem inspired by an experimental design in the neuroscience literature, as an exercise in learning how to do this sort of thing, and as a way to investigate the questions posed in that literature. The main problem In this scenario, we have a Bayesian learner/classifier tasked with classifying whether a given stimulus belongs to one of two classes or concepts . For our purposes, these can be "quiet" and "loud". For some probability q, which is not fixed but may shift over time, a stimulus is drawn from one of two uniform distributions: $Uniform(0, k)$ and $Uniform(k, 2)$ , where $k = 1$ , with the values mapping to a relevant physical measurement of loudness (i.e. decibels). The catch is that learner does not have direct access to the stimulus value. Instead the learner's percept is drawn from some error distribution around the stimulus. In this example, assume that percept $p_i \sim Normal(x_i, s)$ for some fixed standard deviation $s$ , for stimulus value $x_i$ . The learner has access to this information. Therefore, the problem can be posed as follows. Given a percept $p_i = v$ what is the probability that the corresponding stimulus $x_i , conditioned on the prior probability of $x_i ? $$ P(x_i There are two sources of information that seem to need to be accounted for. How frequently $x_i$ is drawn from $Uniform(0, k)$ and $Uniform(k, 2)$ . e.g. if in your experience almost none of the stimuli ever meet your criterion for being loud, then any stimulus that happens to give rise to a percept above that threshold might be judged to have actually been below it. This suggests a binomial likelihood function. I have created (in code) Bayesian classifier that works this way, but it ignores the following second source of information: Given that $p_i \sim Normal(x_i, s)$ , the specific value of $p_i$ informs us about the relative likelihood of different values of $x_i$ and (therefore) the likelihood of $x_i . The probability of (subjective) misclassification increases the closer the percept is to k, and the noisier your measurement of the stimulus. For each possible value of x, one can obtain the likelihoods of obtaining the percept you did, and from that estimate the proportion that are on the other side of the threshold. How to combine (1) and (2)? Additional Complications In the end, I will want to introduce two additional complications: The percept distribution is unknown, but must be estimated. Specifically, for each stimulus $x_i$ , the agent samples the stimulus and obtains percepts $p_{i0} ... p_{in}$ . My feeling is that as long as the solution above does not explicitly depend on the properties of the normal distribution, then this won't really be much of a complication. The learner's subjective threshold value between the classes or concepts needn't be k == 1. For, example, the stimulus apparatus might use a volume threshold of 1, but the individual learner is likely to have a different concept of quiet and loud an so use a different threshold. Again, I feel like this may not be too troubling of an addition to the model, but I suppose that depends on the solution to the above.
