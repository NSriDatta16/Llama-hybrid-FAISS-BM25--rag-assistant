[site]: crossvalidated
[post_id]: 330731
[parent_id]: 
[tags]: 
Implementaion of Mini Batch K-Means

Planing to implement Mini Batch K-Means on a large scale dataset resembles to sklean.cluster.MiniBatchKMeans . In the first step, b samples are drawn randomly from the dataset, to form a mini-batch. These are then assigned to the nearest centroid. In the second step, the centroids are updated. In contrast to k-means, this is done on a per-sample basis. For each sample in the mini-batch, the assigned centroid is updated by taking the streaming average of the sample and all previous samples assigned to that centroid. sklean description (I might misunderstood the sklearn doc): In terms of first step, it says that only assign newly sampled data to their closest clusters. What about the samples drew from previous rounds, shouldn't we also update them. My understanding: In the first step, assign these newly drawn data along with all previous samples if any to the nearest centroid. Which would be a common implementaion for mini batch K-Means? Suppose, we do not update previous samples to their nearest clusters, will the K-Means converge?
