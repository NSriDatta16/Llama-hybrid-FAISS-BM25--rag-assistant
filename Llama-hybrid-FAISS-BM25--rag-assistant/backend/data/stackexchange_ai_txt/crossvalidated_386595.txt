[site]: crossvalidated
[post_id]: 386595
[parent_id]: 
[tags]: 
math behind polynomial regression

I am creating a polynomial regression model with Python sci kit learn package, and I was wondering how I can use the predict features in machine learning algorithms. To start with Python scikit-learn I am fitting the model ( shown in my other post ) and printing rsme & r2 which outputs: 2.359112756782707 0.9829246178225791 The plotted model is purple: If I print the coefficients: print(model.coef_) print(model.intercept_) I get an array: [[ 0.00000000e+00 -4.17544080e-01 2.87295974e-02 -2.06211620e-04]] [73.99115377] This may sound like a silly question, but how do I use this to predict values? For example, can I use my model to predict a y value? Would an x value of 40 according to my scatter plot equate to an approximate y value of ~90? Xnew = [[40]] ynew = model.predict(Xnew) ynew This gives me an error as I do not understand this concepts of linear algebra/vector.. I think I need a format that matches my print(model.coef_) like this below but I don't understand enough to put it to use. Any really basic 101 tips would be greatly appreciated... Xnew = [[...], [...], [...], [...]] ynew = model.predict(Xnew)
