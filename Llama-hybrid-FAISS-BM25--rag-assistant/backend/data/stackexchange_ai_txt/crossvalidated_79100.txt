[site]: crossvalidated
[post_id]: 79100
[parent_id]: 76962
[tags]: 
I agree with what others have said -- namely that "variance" is probably the wrong word to use (seeing as the function you are considering isn't a probability distribution but a time-series). I think you may want to approach this problem from a different perspective -- just fit the two time series with LOWESS curves. You can calculate 95% confidence intervals and qualitatively comment on their shapes. I'm not sure you need to do anything more fancy than this. I've written some MATLAB code below to illustrate what I'm saying. I'm in a bit of a rush but can provide clarifications soon. Much of what I did can be taken directly from here: http://blogs.mathworks.com/loren/2011/01/13/data-driven-fitting/ %% Generate Example data npts = 200; x = linspace(1,100,npts)'; y1 = (1e3*exp(-(x-25).^2/20) + 5e2*exp(-(x-65).^2/40)); y1_noisy = 50*randn(npts,1) + y1; y2 = (1e3*exp(-(x-25).^2/60) + 5e2*exp(-(x-65).^2/100)); y2_noisy = 50*randn(npts,1) + y2; figure; hold on plot(x,y1_noisy,'ob') plot(x,y2_noisy,'or') title('raw data'); ylabel('count'); xlabel('time') legend('y1','y2') You may want to normalize the two time-series to compare their relative trends rather than their absolute levels. %% Normalize data sets figure; hold on Y1 = y1_noisy./norm(y1_noisy); Y2 = y2_noisy./norm(y2_noisy); plot(x,Y1,'ob') plot(x,Y2,'or') title('normalized data'); ylabel('normalized count'); xlabel('time') legend('Y1','Y2') Now make LOWESS fits... %% Make figure with lowess fits figure; hold on plot(x,Y1,'o','Color',[0.5 0.5 1]) plot(x,Y2,'o','Color',[1 0.5 0.5]) plot(x,mylowess([x,Y1],x,0.15),'-b','LineWidth',2) plot(x,mylowess([x,Y2],x,0.15),'-r','LineWidth',2) title('fit data'); ylabel('normalized count'); xlabel('time') Finally, you can create 95% confidence bands as follows: %% Use Bootstrapping to determine 95% confidence bands figure; hold on plot(x,Y1,'o','Color',[0.75 0.75 1]) plot(x,Y2,'o','Color',[1 0.75 0.75]) f = @(xy) mylowess(xy,x,0.15); yboot_1 = bootstrp(1000,f,[x,Y1])'; yboot_2 = bootstrp(1000,f,[x,Y2])'; meanloess(:,1) = mean(yboot_1,2); meanloess(:,2) = mean(yboot_2,2); upper(:,1) = quantile(yboot_1,0.975,2); upper(:,2) = quantile(yboot_2,0.975,2); lower(:,1) = quantile(yboot_1,0.025,2); lower(:,2) = quantile(yboot_2,0.025,2); plot(x,meanloess(:,1),'-b','LineWidth',2); plot(x,meanloess(:,2),'-r','LineWidth',2); plot(x,upper(:,1),':b'); plot(x,upper(:,2),':r'); plot(x,lower(:,1),':b'); plot(x,lower(:,2),':r'); title('fit data -- with confidence bands'); ylabel('normalized count'); xlabel('time') Now you can interpret the final figure as you wish, and you have the LOWESS fits to back up your hypothesis that the peaks in the red curve are actually broader than the blue curve. If you have a better idea of what the function is you could do non-linear regression instead. Edit: Based on some helpful comments below, I am adding some more details about estimating peak widths explicitly. First, you need to come up with some definition for what you are considering a "peak" to be in the first place. Perhaps any bump that rises above some threshold (something like 0.05 in the plots I made above). The basic principle is that you should find a way from separating "real" or "notable" peaks from noise. Then, for each peak, you can measure its width in a couple of ways. As I mentioned in the comments below, I think it is reasonable to look at the "half-max-width" but you could also look at the total time the peak stands above your threshold. Ideally, you should use several different measures of peak width and report how consistent your results were given these choices. Whatever your metric(s) of choice, you can use bootstrapping to calculate a confidence interval for each peak in each trace. f = @(xy) mylowess(xy,x,0.15); N_boot = 1000; yboot_1 = bootstrp(N_boot,f,[x,Y1])'; yboot_2 = bootstrp(N_boot,f,[x,Y2])'; This code creates 1000 bootstrapped fits for the blue and red traces in the plots above. One detail that I will gloss over is the choice of the smoothing factor 0.15 -- you can choose this parameter such that it minimizes cross validation error (see the link I posted). Now all you have to do is write a function that isolates the peaks and estimates their width: function [t_peaks,heights,widths] = getPeaks(t,Y) %% Computes a list of times, heights, and widths, for each peak in a time series Y %% (column vector) with associated time points t (column vector). % The implementation of this function will be problem-specific... Then you run this code on the 1000 curves for each dataset and calculate the 2.5th and 97.5th percentiles for the width of each peak. I'll illustrate this on the Y1 time series - you would do the same for the the Y2 time series or any other data set of interest. N_peaks = 2; % two peaks in example data t_peaks = nan(N_boot,N_peaks); heights = nan(N_boot,N_peaks); widths = nan(N_boot,N_peaks); for aa = 1:N_boot [t_peaks(aa,:),heights(aa,:),widths(aa,:)] = getPeaks(x,yboot_1(:,aa)); end quantile(widths(:,1),[0.025 0.975]) % confidence interval for the width of first peak quantile(widths(:,2),[0.025 0.975]) % same for second peak width If you desire, you can perform hypothesis tests rather than calculating confidence intervals. Note that the code above is simplistic - it assumes each bootstrapped lowess curve will have 2 peaks. This assumption may not always hold, so be careful. I'm just trying to illustrate the approach I would take. Note: the "mylowess" function is given in the link I posted above. This is what it looks like... function ys=mylowess(xy,xs,span) %MYLOWESS Lowess smoothing, preserving x values % YS=MYLOWESS(XY,XS) returns the smoothed version of the x/y data in the % two-column matrix XY, but evaluates the smooth at XS and returns the % smoothed values in YS. Any values outside the range of XY are taken to % be equal to the closest values. if nargin x1(end)) = ys1(end); end
