[site]: datascience
[post_id]: 99931
[parent_id]: 99832
[tags]: 
TL;DR: I would ignore them. I research this area and have no idea what that means. "Sparse" and "dense" often refer to types of embeddings, the former refers to count-based embeddings (formed of word co-occurrence counts), which are typically sparse as many word pairs do not appear together, the latter refers to neural embeddings, e.g. word2vec, GloVe, etc. If there is some formal definition of sparse or dense text (based on some kind of information theoretic measure?), then it should be defined or referenced. Note that the wording above is different to the same work in this (presumably) peer-reviewed conference paper . (I don't know which came first).
