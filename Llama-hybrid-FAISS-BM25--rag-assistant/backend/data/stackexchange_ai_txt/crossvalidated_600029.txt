[site]: crossvalidated
[post_id]: 600029
[parent_id]: 600021
[tags]: 
The best way of looking at it is that outer cross-validation is estimating the performance of a method of fitting a model. In that case, this method involves hyper-parameter tuning and feature selection based on leave-one-out cross-validation. So to produce the final model, just apply that method to the full dataset. I wrote a paper on this topic (with Mrs Marsupial) that I hope will be useful: GC Cawley, NLC Talbot, On over-fitting in model selection and subsequent selection bias in performance evaluation, The Journal of Machine Learning Research 11, 2079-2107 (2010) ( pdf )
