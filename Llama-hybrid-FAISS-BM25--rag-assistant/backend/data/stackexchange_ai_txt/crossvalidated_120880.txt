[site]: crossvalidated
[post_id]: 120880
[parent_id]: 
[tags]: 
How to aggregate daily data, with a large amount of missing data?

I have a conceptual problem in a rather large study of the following design: technical details of a telephone connection are monitored daily, and at the end of the month a questionnaire is filled out by the participants to ask them about their experience. So, in theory I would have 28-31 daily recordings and a single measurement of the experience. In my mind, the best step to analyze the data would be to aggregate the daily recordings and use some form of regression to find relationships between the aggregated data and the experience. Unfortunately, the process to gather the technical details has a lot of faults, so a lot of the cases are missing, around 50% of all participants could be observed on 10 days or less. Even worse, the process which leads to missing data is not random at all, so simply doing some sort of replacement is out of the window. Has somebody an idea how to aggregate the data in a meaningful way? Even a simple average can be problematic because in some causes it's the average of 30 data points, in other only two data points. Even worse, there are a lot of variables like the total download volume where a sum would be great, but at the moment a sum would be misleading at best.
