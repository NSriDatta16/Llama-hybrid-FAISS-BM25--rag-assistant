[site]: crossvalidated
[post_id]: 586911
[parent_id]: 586872
[tags]: 
welcome to Cross Validated. My answer doesn't really answer your question the way you'd like, but it was too long to put into a comment. if O_1 and O_2 come from the same random variable how can they give different levels of information? Certainly, it is possible that P(X=1|O_1) is less than or greater for each observation, but that is because of the relationship between the random variable O to X, not the information contained in each sampled value of O. For example, suppose you ran a regression of O against X and got some linear relationship B, a O_2 is bigger and B is positive then the chances of X would indeed be higher, by B amount. But O_1 and O_2 would all contribute the same amount of information as each other and every other observation in the sample. The only way to make individual observations weigh more is to weigh them as such. This is perhaps the closest to what your question is asking for, but it's a stretch because but that's something you do to O, it does not depend on P(X=1|O). You can't make weights to get to a relationship B that you want. You can't weigh O_n based off of B, or P(X=1|O), itself. You could, for example, use inverse variance weights to lessen the volatility of your estimate of B, or inverse probability weights to account for differening response rates of O. So, with inverse probability weights, let's say you have heaps and heaps of survey responses from a dominant group, and you get another response from that group, it's less "valuable" than getting a response from a rare minority. So you find the census amount of that minority, and give each observation from that minority is (1/census amount)^-1. Because the census amount for the minority is much smaller than the dominant group, their weights will turn out to be much larger. And this will drag the estimate B up and down. But you weigh B to adjust for other things. Again, you don't weigh O_n based off of B, or P(X=1|O), itself. EDIT, to answer the edits: Thanks for clarifying, if I have interpreted you correctly, I think what you are looking for are the stock standard measures for evaluating a classification model. I.E. accuracy, or sensitivity and specificity, and precision and recall. This website has more than enough information on how to evaluate your model's predictions. But note, the accuracy of their predictions has nothing to do with what they predict (i.e. these conditional probabilities that are mentioned). For example, predicting 100% of rain tomorrow, doesn't mean there's a 100% chance of rain. That's the probability that sensor 1 thinks. if sensor 2 thinks there is only 10% chance of rain, and it turns out it doesn't rain tomorrow, sensor 2 is actually right. What needs to happen is they make a lot of predictions and you compare it against a lot of actual outcomes, and then evaluate the sensors using the aforementioned metrics. Pick the appropriate one for your situation. Again, this website is overflowing with posts in this area.
