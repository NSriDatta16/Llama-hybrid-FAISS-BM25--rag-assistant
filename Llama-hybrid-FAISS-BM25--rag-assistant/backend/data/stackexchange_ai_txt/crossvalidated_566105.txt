[site]: crossvalidated
[post_id]: 566105
[parent_id]: 2356
[tags]: 
Are there any examples where Bayesian credible intervals are obviously inferior to frequentist confidence intervals I'm going to say "any paper in experimental science". There's an XKCD cartoon that has made the rounds here before, which I've edited slightly: Okay, the stick figure on the left is nuts, and the one on the right is saner. But I want to focus on a different question: if this experiment were published, what would you want to see in the paper? You don't want the opinion of either of these guys. What you want is the information in the first panel, so you can form your own opinion. That's what the confidence interval tells you: the Universe—which we expect to lie to us about 5% of the time—just told us that the answer is somewhere in here. That isn't what you really want to know. What you really want to know is something like the credible interval. But it's what you want the paper to tell you: it's a concise summary of the result of this particular experiment. The calculation of the confidence interval still incorporates assumptions that may be wrong, invalidating it. But they're assumptions about the reliability of the equipment, the quality of the randomization, and other things that the experimenter can be expected to know better than you. Human bias can still creep in, but it's unavoidable that you have to trust the experimenter about these sorts of things. If you want to make a decision on the basis of this data, then you shouldn't treat the confidence interval as a credible interval, as the guy on the left does. You probably should do a Bayesian analysis. Proponents of Bayesianism often talk about winning bets, because Bayesian inference is good for that. But not everything is about winning bets.
