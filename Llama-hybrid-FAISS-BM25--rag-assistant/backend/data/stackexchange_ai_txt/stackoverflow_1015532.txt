[site]: stackoverflow
[post_id]: 1015532
[parent_id]: 1003734
[tags]: 
You can use support vector machines to do text classification. One idea is to break pages into different sections (say consider each structural element like a div is a document) and gather some properties of it and convert it to a vector. (As other people suggested this could be number of words, number of links, number of images more the better.) First start with a large set of documents (100-1000) that you already choose which part is the main part. Then use this set to train your SVM. And for each new document you just need to convert it to vector and pass it to SVM. This vector model actually quite useful in text classification, and you do not need to use an SVM necessarily. You can use a simpler Bayesian model as well. And if you are interested, you can find more details in Introduction to Information Retrieval . (Freely available online)
