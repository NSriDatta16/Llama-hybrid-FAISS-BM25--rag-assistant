[site]: crossvalidated
[post_id]: 230479
[parent_id]: 
[tags]: 
How to reduce the dimensionality of a similarity matrix (of categorical co-occurence counts)?

Our example person Azra has assigned (open-ended categories of her own choosing) to a fixed set of 35 items, recorded as logical values ( TRUE , FALSE ). We have summarised this data matrix into a co-occurence matrix of items x items , where each cell counts the number of categories that are assigned to both items of the item-pair in question . We interpret these counts as a measure of categorical similarity between items, and consequently set the diagonal to the maximum possible number of categories, 18 in Azra 's case. We then divide all cells by that maximum to scaled our cells to 1. (We also need to do this because there are other people than Azra who have less then 18 categories in total, so we want to make them comparable). Loosely speaking, we assume that our cells in this (scaled) co-occurence matrix can be interpreted as percentages of similarity , where 1 on the diagonal is – naturally – the maximum: item, say but-how with but-how obviously is completely similar. Here's Azra (sorry): Azra A plot is easily made, but not very informative for us, because it's overwhelming, so we need some kind of summry. library(ggplot2) ggplot(data = melt(Azra, varnames = c("x", "y")), mapping = aes(x = x, y = y, fill = value, )) + geom_raster() + scale_fill_continuous(low = "white", high = "steelblue") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) We want to be able to see which items Azra thought were categorically similar, and if so, what her dimensions (or clusters ?) of similarity are. What would be an appropriate, and informative method to summarise this kind of data? Specifically, we'd like to be able to use something akin to Horn's Parallel Analysis (from a PCA context) to decide just how many retainable dimensions there are in Azra s similarity matrix. Notes: We've looked at Multidimensional Scaling (MDS), but that seems to require the number of dimensions as an input , though to us, the number of dimensions on which Azra sees similarity is an empirical question. We've looked at Hierarchical Clustering Methods and respective dendrogram plots, but that seems to sit awkwardly with the fact that similarity is a multidimensional phenomenon; item censored might share category A with but-how , but category B with language-of-bees etc. We've looked at Principal Components Analysis (PCA) – mostly because we know it well, so everything starts looking like a nail ... – but that doesn't work with a similarity matrix, and even with a (converted) distance matrix only under some conditions about which we're not sure. (We tried anyway, see below). Here's our rough, hacky and probably just plain wrong/dumb way to do this: It doesn't give us any indication of how many dimensions we should be retaining. We first make a distance matrix as per the cosine theorem (?!): distances We then plug that into a (classical?) MDS and plot the result: md_scaled
