[site]: crossvalidated
[post_id]: 476441
[parent_id]: 476424
[tags]: 
The 'rule of thumb' that the standard deviation $S$ of a normal sample can be usefully approximated as sample range $D$ divided by $4$ (or $5$ or $6).$ The rule is typically "illustrated" by an example, contrived so the 'rule' gives a reasonable answer. In fact, the appropriate divisor depends crucially on sample size $n.$ n=100 set.seed(2020) s = replicate(10^5, sd(rnorm(n))) set.seed(2020) # same samples again d = replicate(10^5, diff(range(rnorm(n)))) mean(d/s) [1] 5.029495 summary(d/s) Min. 1st Qu. Median Mean 3rd Qu. Max. 3.581 4.678 4.984 5.029 5.330 7.756 For, $n = 25,$ dividing the range by $4$ works pretty well, and without great variation. For $n = 100$ and $500,$ respective denominators are on average $5$ and $6,$ but with widely decreasing precision for individual samples as sample size increases. A simulation in R for $n=100$ is shown above. Note: The idea of approximating $S$ as $D/c_n$ is not completely useless: For $n dividing the range by some constant $c_n$ (different for each $n)$ works well enough that makers of control charts often use range divided by the appropriate constant to get $S$ for chart boundaries.
