[site]: datascience
[post_id]: 22013
[parent_id]: 21945
[tags]: 
Following your code in your other thread: # Use tf (raw term count) features for LDA. print("Extracting tf features for LDA...") tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words='english') t0 = time() tf = tf_vectorizer.fit_transform(data_samples) print("done in %0.3fs." % (time() - t0)) print("Topic modelling with LDA...") lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5, learning_method='online', learning_offset=50., random_state=0) lda_x = lda.fit_transform(tf) # so lda_x is your doc-topic distribution that you can use for feature vector to your SVM model. # lda.components_ is your topic-word distribution. Hope this helps!
