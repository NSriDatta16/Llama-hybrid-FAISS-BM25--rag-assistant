[site]: stackoverflow
[post_id]: 4200981
[parent_id]: 4200637
[tags]: 
I've done this by keeping search performance counters in a table. Basically monitoring the average percentage of rows that the search filters and the run time. I then create a performance figure based on TotalNumberOfRowsToSearch * Percent_Not_Matched / RunTimeInSeconds This figure is a direct correlation of rows per second it can filter out. Averaged over thousands of runs, it is a rather good prediction. I then run each query in order with highest performance figure one first. If you're doing a logical AND on the total result, run each subsequent query only on the results of the previous query. If you're doing a logical OR, run each subsequent query only on the results NOT IN the combined previous search results. By doing it this way, your query will change based on indexes and types of data. If you want a less dynamic solution, simply calculate performance figures for each part of the search and use the better performing ones first. Remember a query that runs in 55ms but matches 99% of the results is not as useful as one that runs in 1 second and matches 1% of the results, so be wary that results may go against your initial ideas. Just look out for the divide by 0 error when calculating performance figures.
