[site]: stackoverflow
[post_id]: 4437710
[parent_id]: 4437687
[tags]: 
You can configure your robots.txt to allow certain robots, but not others: E.g.: User-Agent: * Disallow: /images User-Agent: Googlebot-Image Disallow: This is just an example. You can also allow other well-behaved robots. But that does nothing about badly behaved robots that just ignore robots.txt. there's really no solution for them, though authentication can help a little (you can throttle image access by account).
