[site]: datascience
[post_id]: 116268
[parent_id]: 
[tags]: 
Does fine-tuning require retraining the entire model?

Would it be necessary to retrain the entire model if we were to perform fine-tuning? Let's say we somehow got the GPT-3 model from OpenAI (I know GPT-3 is closed source). Would anyone with access to a couple of RTX 3080 GPUs be able to fine tune it if they got the GPT-3 model weights? Or would it need infrastructure like the big companies?
