[site]: crossvalidated
[post_id]: 489015
[parent_id]: 
[tags]: 
Intuitions behind item response theory?

I'm relatively new to Item Response Theory. After having read some materials on 1PL and 2PL, I have a few thoughts and questions. Say you have a questionnaire that a social psychologist will complete when evaluating a child age 12-24 months. The psychologist must record {0,1} for {yes, no} on the following, did the child use word, X? Where X consists of {"mom", "trash", and "yesterday"}. So, the child vector [0,0,0] signifies that the child used none of these words, whereas [1,1,1] signifies that the child used all three words. Given the above hypothetical setup, it's my understanding that IRT aims to measure two latent factors, child language proficiency and item difficulty. The ideas of entropy and information come to mind. If all questions receive the same response, 0 or 1, then the question is either too easy or too difficult; regardless, we learn very little about the child when asking said question (I would be very surprised if a 1-2 year old used the word "nuclei", so it probably doesn't belong in said language assessment.) 1PL essentially performs logistic regression with a single predictor variable x and response variable, y. Where this approach differs from logistic regression is that: (A) x is not known, it's latent and (B) more specifically, x = ability - difficulty . This feature is then sent to a sigmoid function, followed by a Bernoulli likelihood. Using MCMC methods, various values for the vectors, ability and difficulty, could be proposed/explored where individual vector elements correspond to specific children and specific questions, respectively. In the IRT resources I've viewed, a characteristic (sigmoid) curve is usually presented where the x-axis is relative easiness of the question (ability minus difficulty) and the y-axis represents correct answer to the question (or knowing the word in our case.) High x values indicate a very advanced child answering a very easy question, (y is virtually guaranteed to be 1 with very little variance) whereas low x values indicate a far less advanced child answering a very difficult question (y is virtually guaranteed to be 0 with very little variance.) Interestingly, moderate values of x indicate that the child and question are equally matched, and this where variance around outcome y is maximized. Q1. Is my understanding correct thus far? 2PL models build upon this paradigm by introducing a second parameter, in addition to the derived variable x. Namely, x= v * ability - difficulty . (I might be mistaken here.) To the best of my knowledge, the parameter, v, controls the slope of the function. And this might be desirable as it basically says, "how sensitive is y, the probability of correctly answering question q, to small changes in relative easiness of the question?" As discussed previously, when relative easiness is at moderate values, specifically 0.5, we maximize variance in the outcome, y. And this extra parameter, v, allows us to think in terms of "how rapidly does variance shrink as x departs from 0.5?" Q2. Is my formula for 2PL model accurate? I've seen multiple variations across resources, such as z = v * (ability - difficulty) . Q3. What does v capture? Child ability variance, question difficulty variance? Something else? Thank you in advance!
