[site]: crossvalidated
[post_id]: 74968
[parent_id]: 
[tags]: 
Confidence intervals and central estimates for a functional of an estimated function with uncertain parameters

I've got a problem that is leading me to dip my toes into Bayesian stats, and I've got a question about confidence (or, I suppose, credible) intervals: Say you want to know how $X$ maps to $y$. You fit a model $y=f(X)+\epsilon$. Then, you want to optimize $X$ to get the best $y$: $$y_{max} = argmax_X(\hat{f}(X),s.t. \text{whatever constraints}) $$ This gives you the model's best estimate of the optimal $X$ for getting the biggest $y$. But obviously $\hat{f}(X)$ is uncertain. If you take a Bayesian standpoint that $\beta$ is distributed multivariate normal, you can take samples from it, which gives new coefficients (see, for example, this ). Taking many samples, using them to pick new optimal values of $X$, one gets a distribution of $y_{max}$ that reflects uncertainty in $\hat{f}(X)$. Here is the problem: the central estimate of $y_{max}$ (i.e.: optimizing based on the parameter estimates of the fitted model) is not necessarily the mean or the median of the $y_{max}$ distribution that one gets when optimizing the functions based on the posterior draws. So what should I do with the "central estimate"? Which estimate should I consider to be my "best guess" of the value of $y_{max}$? Should it be $y_{max}$ at the (ML) parameter estimates? Should it be the mean or median of the posterior simulations of $y_{max}$? I don't know whether there is a right answer here: maybe this is a somewhat of a philosophical question? (Or am I making some relatively fundamental mistake, which makes my whole question moot? If so, I'd be grateful for replies that point it out.)
