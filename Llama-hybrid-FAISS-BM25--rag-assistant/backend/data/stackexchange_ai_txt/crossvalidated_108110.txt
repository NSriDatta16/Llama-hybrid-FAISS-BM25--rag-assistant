[site]: crossvalidated
[post_id]: 108110
[parent_id]: 29085
[tags]: 
Here goes: In my field (developmental science) we apply DFA to intensive multivariate time-series data for an individual. Intensive small samples are key. DFA allows us to examine both the structure and time-lagged relationships of latent factors. Model parameters are constant across time, so stationary time-series (i.e., probability distributions of stationarity of stochastic process is constant) is really what you are looking at with these models. However, researchers have relaxed this a bit by including time-varying covariates. There are many ways to estimate the DFA, most of which involve the Toeplitz matrices: maximum likelihood (ML) estimation with block Toeplitz matrices (Molenaar, 1985), generalized least squares estimation with block Toeplitz matrices (Molenaar & Nesselroade, 1998), ordinary least squares estimation with lagged correlation matrices (Browne & Zhang, 2007), raw data ML estimation with the Kalman filter (Engle & Watson, 1981; Hamaker, Dolan, & Molenaar, 2005), and the Bayesian approach (Z. Zhang, Hamaker, & Nesselroade, 2008). In my field DFA has become an essential tool in modeling nomothetic relations at a latent level, while also capturing idiosyncratic features of the manifest indicators: the idiographic filter. The P-technique was a precursor to DFA, so you might want to check that out, as well as what came after... state-space models. Read any of the references in the list for estimation procedures for nice overviews.
