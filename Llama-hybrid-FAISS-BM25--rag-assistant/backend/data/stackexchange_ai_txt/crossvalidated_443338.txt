[site]: crossvalidated
[post_id]: 443338
[parent_id]: 407921
[tags]: 
The computational cost of gradient descent depends on the number of iterations it takes to converge. But according to the Machine Learning course by Stanford University, the complexity of gradient descent is $O(kn^2)$ , so when $n$ is very large is recommended to use gradient descent instead of the closed form of linear regression. source: https://www.coursera.org/learn/machine-learning/supplement/bjjZW/normal-equation
