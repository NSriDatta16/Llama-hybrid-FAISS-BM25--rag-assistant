[site]: crossvalidated
[post_id]: 474138
[parent_id]: 474085
[tags]: 
Welcome to Cross Validated! Here are some thoughts about your questions: Firstly, it is difficult to say that a model is intrinsically "good" or "bad". As George Box said, "all models are wrong, but some are useful" ( see here for a detailed explanation of this aphorism ). When you don't know the ground truth model from which data were generated (which is usually the case when you perform model selection), the best solution is usually to define a family of plausible models and to compare their goodness of fit on the data and their complexity, so as to find the best model. This being said, what makes your first model ESPECIALLY bad is an identifiability problem. As mentioned in the comments, the first model is structurally not identifiable. Even if you had an infinity of noiseless data points (i.e. the complete likelihood function of $y$ under your model), you still would not be able to find the values of $A_1$ and $B_1$ , since any values for these parameters (given that their sum is constant) would do the job. Note that identifiability problem is different from overfitting: overfitting is what happens when you use a complicated model to fit simple data (hence violating Occam's rule), while identifiability is an intrinsic property of the model and does not depend on a given data set $y$ . Your first example is textbook example of what an ill-defined model looks like: non-identifiabilities in realistic and complex models might be hard to find. I recommend the following papers on this problem: Massonis, Gemma, and Alejandro F. Villaverde. "Finding and Breaking Lie Symmetries: Implications for Structural Identifiability and Observability in Biological Modelling." Symmetry 12.3 (2020): 469. Raue, Andreas, et al. "Structural and practical identifiability analysis of partially observed dynamical models by exploiting the profile likelihood." Bioinformatics 25.15 (2009): 1923-1929. On the other hand, your second model is identifiable and well defined, but raises the problem of overfitting. Since the ground truth model is linear, but your second model is a second order polynomial (except for the degenerate case where $A_2 = 0$ ), it is likely to overfit your data, in the sense that a simpler (i.e. linear) model would fit data equally well while respecting Occam's rule. Obviously, you usually don't know the ground truth model. To validate the quality of the different models you have at hand to fit $y$ , you can use classical tools such as the Bayesian Information Criterion or the Akaike Information Criterion , which are scores that compensate the goodness of fit of a model with its complexity.
