[site]: crossvalidated
[post_id]: 576776
[parent_id]: 
[tags]: 
how does `subsample` parameter work in boosting algorithms like xgboost and lightgbm?

From what I know, both of them are sequential learners and only the 1st tree in the sequence gets built on the data and all the following trees that get built are to correct the mistakes of previous tree, hence improving the performance or decreasing the bias. subsample parameters in xgboost and lightgbm dictates the percentage of rows used per tree building. So, with this context, if subsample is set to 0.75, first tree gets built with 75% of the data and all the following trees will focus on correcting mistakes. So, what happens to the remaining 25% of the data? will another set of sequential tress be built parallelly? or am I missing something here or got something wrong?
