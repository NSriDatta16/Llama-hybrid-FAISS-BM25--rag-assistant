[site]: datascience
[post_id]: 68941
[parent_id]: 68917
[tags]: 
You can weight the loss of each class with a suitable value which is inversely proportional to the class size. One example would be to use: (Total number of data points)/(number of data points of the class). For loss you can use the standard Binary Cross Entropy (BCE) loss. As for the metric, I would advise you to use AUROC (Area Under the Receiver Operating Characteristics) . You can generate an AUROC for each class to see the performance of the model on these individual class and average them to get an overall sense of your models performance. Edit: I noticed you have put a tag on f1 score so I would like to point out that AUROC should be preferred as the metric as they more robust to class imbalance as compared to f1 scores.
