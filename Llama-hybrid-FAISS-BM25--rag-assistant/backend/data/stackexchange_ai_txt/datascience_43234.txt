[site]: datascience
[post_id]: 43234
[parent_id]: 43116
[tags]: 
First of all, can you tell us a bit more about the classification, as in classify the texts into what classes? Now, to answer your question, You have input of text sentences which are articles related to HIV/AIDS. Now, you want to extract information from them. To do this, you'll need a model that "understands" the contextual meaning of the words in the text sentences. Hence, if you start by one-hot encoding the words in your sentences, this model will perform poorly as that encoding will not contain any information about context in the text. To solve this problem, you'll need Embedding layers. Embedding layers help in representing words with similar meanings in similar fashion. Word Embeddings are actually learned from text data. It is very common to see embeddings that are 256 or 512 dimensional. While one hot encoding would result in dimensionality of the size of your word-set, embeddings hold a lot of information in lesser dimension. There are 2 ways to use them in your model: To learn the embeddings while training your model.In this method, you start with random word vectors and learning them as you learn weights of your neural networks. Use pre-trained embeddings. These are pre computed embeddings which can be loaded into your model. Some examples of pre-trained word embeddings include : -> glove -> Word2Vec ->Fasttext Once you've converted the text into their embeddings using any of the above methods, now you can feed them to your neural network (RNN/LSTM/CNN) for your classification task. Hope this helps :)
