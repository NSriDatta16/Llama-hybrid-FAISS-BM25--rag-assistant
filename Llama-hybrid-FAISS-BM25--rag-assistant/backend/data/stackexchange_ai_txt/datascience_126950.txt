[site]: datascience
[post_id]: 126950
[parent_id]: 126946
[tags]: 
Fine-tuning means that you modify the model to adapt it to your data. Feature extraction means that you don't modify the model. In the case of RoBERTa, it means that you feed your data to the model, take the hidden states and use them for other thing (e.g. to keep them as vector representation to find other similar text, or as input to another model). Your statement "I want to train the pre-trained Roberta on my dataset but only use it to calculate contextual embeddings for each caption in the dataset by taking the last hidden state of the model" is incoherent, because you are mixing incompatible things: you cannot train RoBERTa and at the same time use it only to calculate contextual embeddings. If you train RoBERTa on your data, you are fine-tuning. If you only calculate contextual embeddings you are doing feature extraction. While it is technically possible to both fine-tune RoBERTa with your data in a masked LM task and then use the fine-tuned model for feature extraction, it does not make much sense, because, feature extraction with BERT-like models performs worse than fine-tuning. People use feature extraction just to avoid training the model. Therefore, it is a waste to train the model on a masked LM task (the same as the original RoBERTa pretraining) instead of fine-tuning it on your own downstream task (e.g. classification). In the article To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks , you can find a study about how BERT (predecessor of RoBERTa) behaves with fine-tuning and feature extraction on different tasks.
