[site]: datascience
[post_id]: 116305
[parent_id]: 116291
[tags]: 
You have not interpreted the problem correctly. I will try to explain using your example, with the array [1, 2, 3] . Because there are only 3 samples, the cross validation is called "leave one out". First fold, elements [1, 2] are used for training and [3] for testing. The mean of the train elements is 1.5, so the prediction is 1.5, so the absolute error is 3-1.5 = 1.5. Similarly we repeat by choosing 2 and 1 as the test elements and the other two as train. Mean of 1 and 3: 2, absolute error = 2-2 = 0 Mean of 2 and 3: 2.5, absolute error = |1 - 2.5| = 1.5 So, the mean absolute error will be mean([1.5, 0, 1.5]) = 1.0 . You tried to think about the problem as a usual machine learning problem with tabular data, but essentially your X is not a row (the problem statement mentions that the input is an array, but you define it as a 2D array in the code), it is a column which happens to be both your feature, and the target variable, and the model you have to use is simply y_pred = np.mean(x) . The following snippet does not use library functions (well, apart from np.mean ) and is easy to understand: import numpy as np def model(X): return np.mean(X) def cross_validation(X, model): errors = [] for i in range(len(X)): test_element = X[i] train_elements = X[0:i] + X[i+1:len(X)] prediction = model(train_elements) error = abs(prediction - test_element) errors.append(error) return np.mean(errors) arr1 = [1,2,3] arr2 = [2, 5, 4, 3, 4, 6, 7, 5, 8, 9] print(cross_validation(arr1, model)) print(cross_validation(arr2, model)) and produces 1.0 1.9555555555555557
