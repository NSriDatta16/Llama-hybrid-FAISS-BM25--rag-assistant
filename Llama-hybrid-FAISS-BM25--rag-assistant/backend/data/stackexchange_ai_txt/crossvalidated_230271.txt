[site]: crossvalidated
[post_id]: 230271
[parent_id]: 
[tags]: 
More feature leads to worse result in Random forest and adaboosting method

This is a problem that I met in real regression analysis using real data. I am using Random forest as well as Adaboost method to do regression. X has 5 dimension and y has 1 dimension. The sample size is 110k. However, if I add more feature into X (X has more dimension). Then the out of sample test of the model is reduced by 30%. My knowledge says this is very unlikely to happen but this indeed happened. I am wondering the underlying mechanisms and how shall we deal with this problem.
