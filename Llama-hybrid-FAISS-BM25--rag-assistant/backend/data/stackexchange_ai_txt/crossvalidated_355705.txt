[site]: crossvalidated
[post_id]: 355705
[parent_id]: 355602
[tags]: 
Is non-parametric test robust to Gaussian data? If you are asking about level robustness, yes; it doesn't matter what the distribution is. If you're asking if nonparametric tests have good power at the Gaussian, then it depends entirely on the test. Many have excellent power at the Gaussian, some are fully efficient or very close to it. Others are not. If power exactly at the Gaussian matters a lot to you, you need to check what it is for that test against the alternatives that matter to you. Is non-parametric test robust to parametric data? Please note that Gaussian is not the same thing as parametric ! There's no such thing as "parametric data". Data are just data. A model is (finite-)parametric (or it isn't). For example, see the opening paragraph here: Note the definition doesn't relate to normality (though some of the examples do). There are parametric procedures (a huge host of them) that do no assume normality. I'd guess I use one or another of them more often than I use procedures that assume normality. post-processed data is both parametric and non-parametric It's not clear what this means. Do you mean "normal" and "non-normal"? If so, how can you know something is normal? (Failure to reject in a goodness of fit test of normality doesn't tell you something is normal - it will almost never be the case that you have normality; what you have is a lack of power to detect whatever non-normality is present. Not every deviation from normality that's hard to detect is inconsequential!) In my case for example I always choose Mann Whitney U test instead of t The first considerations are what are your null and alternative? what assumptions are you prepared to make Note that testing your assumptions is not generally a good idea. In the case of testing normality, some of the issues are well explained here: Is normality testing 'essentially useless'? (though there are other issues) Similar issues apply to other tests of assumptions. They don't answer the question you actually need answered, and choosing between tests on the basis of such a test is frequently worse than not making an assumption you don't have some reasonable basis to assume before you see the data. test without checking the normality, as my initial assumption would be that my data would be non-Gaussian (although it might be Gaussian) It sounds like you have no good reason to assume normality. Why then would power at the normal matter much to you? Consider something like a two-sample t-test against a Wilcoxon-Mann-Whitney. The latter has about 96% power in large samples at the normal, but you only need very slightly heavier tails before that advantage completely disappears. There's no distribution for which the t does very strongly better that the W-M-W, but it can do much worse. This suggests that most of the location-difference information is already captured by ranks, when we're (in some sense) near the normal. Is it correct to choose non-parametric test if I have a low sample size (e.g. n=18) although the data is parametric? Again, it's not clear what you mean by parametric data; if you mean that the data are sampled from a normal distribution how do you know ? Merely on the basis that you have little power to detect it isn't? What good is that? There are two main issues with small samples you won't have much basis to assess whether your assumptions were wrong nonparametric tests don't offer good control of level at very small sample sizes; it's not so much a problem at say n=18 but at lower sample sizes you might be left with a choice between $\alpha = 0.058$ or $\alpha= 0.021$ when you want (say) a 5% test. You can do a randomized test but that has consequences many people find highly unsatisfactory (such as two different people coming to different conclusions using exactly the same test procedure on exactly the same data set using the same significance level). At very low sample sizes there might well be no test with a significance level below 10%. Since non-parametric test is more robust to outlier (as it used median instead of mean). Actually hardly any nonparametric tests are based on the median. None of the common ones are (e.g. the signed rank test and the Wilcoxon-Mann-Whitney are examples of tests which are not based on the median) If I prefer not to remove outlier, It's rarely a good idea to arbitrarily "remove outliers" unless you have some clear basis for concluding that they should not have been part of your sample. This is also an issue from the point of view of choosing your analysis on the basis of the appearance of your data. It does make sense to use procedures that are not badly impacted by potential outliers. That doesn't necessarily restrict you to nonparametric tests; suitably robustified parametric tests may do quite well for example. is it justified to just use non-parametric? Not all nonparametric tests are robust to outliers (if you mean to ask about their power rather than their significance level). Some are , but you can't just assume that because a test is nonparametric it retains good power in the presence of outliers. An example of a nonparametric test that can be badly impacted by outliers is the Tukey-Duckworth Quick test (though there are ways to improve that) You should not be choosing tests on the basis of the appearance of your sample. This impacts the behaviour of the distribution of the test statistic and so your p-values no longer carry their usual meaning. Instead, you should understand the behaviour of your variables as well as possible ahead of time and make reasonable assumptions where it makes sense to do so, while (where possible) avoiding highly consequential assumptions you don't have a good basis for.
