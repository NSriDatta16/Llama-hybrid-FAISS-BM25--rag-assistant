[site]: datascience
[post_id]: 49719
[parent_id]: 49718
[tags]: 
Depends on what is your goal with the data. If you are trying to model your variable "outcome" as a classification problem (I am supposing this) then it depends on the modelling technique you are expecting to use. Some techniques use scalled data as input because they have a functional form which allows them to perform better if the scale is the same for the variables (the canonic example could be Neural Networks). Some techniques do not need to have scalled inputs, mostly because their functional form does not depend on relationships (interactions) with other variables just as random trees. There are other techniques like logistic regression where scalling is optional because they work fine without scalling, the result is the same but sometimes you need to compare the resulting $\beta$ 's and the only way to do this is if the $X$ s have the same scale. The process you are doing is ok, but make sure you actually need to do it.
