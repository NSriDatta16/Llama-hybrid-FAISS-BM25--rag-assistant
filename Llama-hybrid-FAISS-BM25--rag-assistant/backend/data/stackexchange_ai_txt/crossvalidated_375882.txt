[site]: crossvalidated
[post_id]: 375882
[parent_id]: 375784
[tags]: 
If you truly know nothing then logic dictates that totally uninformative priors should be used. But they have the annoying habit of being improper. But is it ever true that you know literally nothing? When you think about it you may conclude that you can say something, perhaps something vague about bounds. That would lead to some minimally informative prior. A further point to consider is that statistical modelling is a process not a one-shot gun. A model is constructed, run, checked, revised and run again, and so on. You might start with some extremely vague prior, run your model, and then find that the results defy sense. Maybe the model is wrong, but just as plausible is that the priors are too uninformative. Finally, looking at the history of Bayesian inference, there are clear signs that some Bayesians wished to avoid the criticism that their conclusions were subjective by seeking priors that were objective, and in most cases of interest that pushed them towards priors that were as minimally informative as possible. The MaxEnt school, promoted by E T Jaynes, sought a means of forming objective informative priors, but those methods seem not to be regarded as universally workable, because there are kinds of prior knowledge that are in practice very difficult to capture through MaxEnt methods. Andrew Gelman has written extensively setting out his arguments that Bayesian inference ought to be seen as wholly consistent with the falsificationist view of scientific discovery. In line with that view, weakly informative priors are one component of setting up scientific theories that might be falsified by later work.
