[site]: crossvalidated
[post_id]: 276717
[parent_id]: 165
[tags]: 
First, we should explain Monte-Carlo sampling to the layperson. Imagine when you don't have the exact form of a function (for example, $f(x,y)=z=x^2+2*x*y$ ) but there is a machine in Europe (and Los Alamos) that replicates this function (numerically). We can put as many $(x,y)$ pairs into it and it will give us the value z. This numerical repetition is sampling and this process is a Monte-Carlo simulation of $f(x,y)$ . After 1,0000 iterations, we almost know what the function $f(x,y)$ is. Assuming the layperson knows the Monte-Carlo, in MCMC you don't want to waste your CPU efforts / time when you are sampling from a multi-dimensional space $f(x,y,z,t,s,...,zzz)$ , as the standard Monte-Carlo sampling does. The key difference is that in MCMC you need to have a Markov-chain as a map to guide your efforts. This video (starting at 5:50) has a very good statement of intuition. Imagine you want to sample points that are on the green (multi-dimensional) branches in this picture. If you throw points all over the black super-space and check their value, you are WASTING a lot sampling (searching) energy. So it would make more sense to control your sampling strategy (which can be automated) to pick points closer to the green branches (where it matters). Green branches can be found by being hit once accidentally (or controlled), and the rest of the sampling effort (red points) will be generated afterward. The reason the red gets attracted to green line is because of the Markov chain transition matrix that works as your sampling-engine. So in layman's terms, MCMC is an energy-saving (low cost) sampling method, especially when working in a massive and 'dark' (multi-dimensional) space.
