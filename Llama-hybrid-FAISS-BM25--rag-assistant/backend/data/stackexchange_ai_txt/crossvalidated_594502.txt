[site]: crossvalidated
[post_id]: 594502
[parent_id]: 593692
[tags]: 
Class imbalance causes tremendous confusion when it really shouldn’t. Briefly, the likely explanation is that you should not do anything about the class imbalance. Do your modeling of the imbalanced data while evaluating your probability predictions using proper scoring-rules . As is discussed within material cited within these links, a major driver of class imbalance seeming like a problem comes from using discontinuous, improper scoring rules like accuracy. Once you have good probability predictions, you might choose to set a threshold (perhaps not the software-default of $0.5$ ) to make hard classifications, depending on whether the predicted probability is above or below the threshold. However, when you do real machine learning, there is a cost associated with incorrect classifications, and the decisions that optimize cost might even involve multiple thresholds , despite the original problem being binary. For the record, I say that even accuracy can be wrestled with to be perfectly descriptive, even in the presence of considerable imbalance , yet accuracy is problematic, even with perfectly balanced classes . (That Stephan Kolassa in a few of the linked answers has written extensively about this topic, and he is one of the people from whom I learned about this topic.) Splitting your out-of-sample data into multiple groups could make sense if your goal is to get an idea for the variability of your performance. A competing approach could be to bootstrap that one out-of-sample set and apply your trained model on each of those bootstrap samples. Alternative approaches using bootstrap exist, too , at the expense of computing time, and there are debates about this beyond computing time . However, I think you’ve made a mistake in handling the imbalance before you reach that point.
