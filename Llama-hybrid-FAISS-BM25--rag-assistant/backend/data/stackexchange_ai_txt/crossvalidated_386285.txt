[site]: crossvalidated
[post_id]: 386285
[parent_id]: 386267
[tags]: 
Random Forest is good for sort of "catching" joint effects of 2 or more variables, meaning if feature 1 is above some threshold and feature for example below some other threshold, they will have different effect on target variable then you could model with linear relationship due to linear regression being additive model (you just sum up portion of effects of each feature). This means that random forest can outperform linear models in prediction, but since RF is ensamble method (comprised of many trees voting for the final prediction) it means you cannot interpret how each feature variable is affecting target variable.
