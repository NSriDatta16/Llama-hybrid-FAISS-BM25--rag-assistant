[site]: datascience
[post_id]: 47971
[parent_id]: 
[tags]: 
why do we need row sampling in random forests?

In random forests, where our estimators are decision trees, we do column (feature) sampling without replacement within an estimator, and with replacement in between estimators. This is perfectly fine as we are trying to reduce the high variance of individual decision trees. But what is the need to do row sampling? Usually more the data, the better it is for a model to learn, and even if i dont have any computational resource limitation, why do we have to do row sampling in estimators for random forest classifier?
