[site]: crossvalidated
[post_id]: 233920
[parent_id]: 233912
[tags]: 
In this situation you will fit: Five full gradient boosted models, each on $\frac{4}{5}$ of the available training data. Each tree trained within these five boosters has access to all and only $\frac{4}{5}$ of the training data, and it's the same $\frac{4}{5}$ for each tree. Within each of these five boosted models, each tree will be trained on a different $\frac{1}{2}$ of the in-fold training data. This works out to $\frac{4}{5} \times \frac{1}{2} = \frac{2}{5}$ of the total available training data. The subsampling only serves to diversify the trees fit in a single boosted model, it plays no role in evaluating the model. The curves pictured are the average out-of-fold error, with the average taken over the five full boosted models created during cross validation.
