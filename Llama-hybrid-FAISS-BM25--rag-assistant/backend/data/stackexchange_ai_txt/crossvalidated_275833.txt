[site]: crossvalidated
[post_id]: 275833
[parent_id]: 
[tags]: 
Combining ranked lists of true and false positives gives strange result. Is there a general principle here?

Apologies if this question is too general. I'm happy to edit it as needed. That said, I've come across this counterintuitive result twice now, and I'd like to know if there's a known, general solution to it. When I work with lots of biology data, I often do some combination of: scoring a list of potential hits, e.g. "what are the most probable proteins in my sample, from most to least likely?" collecting multiple replicates combining the scored lists across replicates applying a multiple comparison correction, e.g. an FDR cutoff. The problem is that when I combine lists from multiple replicates, I sometimes find fewer hits after the multiple comparison correction. That is, counterintuitively, more data makes my results worse . I believe this is because the true positives tend to overlap between lists (they're real) while the false positives don't (they're random, spurious hits). Therefore, when combining, the false positives accumulate faster than the true positives. Here's an example: List 1 and List 2 have three TPs and two FPs (precision = 3 / 5 = 60% ), and, if we applied a 50% FDR cutoff, we'd return all five hits from each list. The combined list on the other hand has a total precision of 50% ; applying a 50% FDR cutoff gives four hits . By both measures the combined list is worse. And it just looks worse, e.g. there are fewer TPs near the top. The effect is obviously dependent on how I chose to combine lists. For one, the combined list is non-redundant (e.g. A only appears once), and two, I combined scores by taking the maximum value (instead of e.g. the average). From what I've seen both of these are common choices, although I'm pretty sure this is where my error is. My solutions so far are ad hoc, e.g. different rules for combining scores. Question 1: Is there a general principle at work here? Like I said I've come across this twice... (there must be a thesis on it!) Question 2: Could I combine scores in a "Bayesian way"? I don't know what that means in practice, although "accumulating evidence" makes me think "Bayesian".
