[site]: crossvalidated
[post_id]: 625392
[parent_id]: 625384
[tags]: 
Take this answer with a grain of salt...as I suggested in the comments, I'm no Yves Rosseel at structural equation modeling. However, I am familiar with the normal fit indices of SEM and can at least comment about what they are and why they should be sufficient in your case. As the names imply, fit indices give an approximation of how well your model fits the data, but they operate in different ways, and this sometimes gets lost in SEM courses. Chi-Square The chi-square is probably the most contentious of the fit indices but is nonetheless important. Assuming the model has fit the population of interest perfectly , a p-value of the test indicates it "passes" if it is above the typical alpha level cutoff of $a = .05$ . Passing this test, however, doesn't mean the model has satisfactory local fit (the individual regression paths), only global fit (the model as a whole). It also says nothing of prediction accuracy, doesn't say much about the severity of model mis-specification, is sensitive to sample size, and a number of other factors. It is for this reason that people don't use it alone in determining goodness-of-fit, though strangely, a good number of people simply ignore it, which isn't good practice (Hayduk in particular wrote an article about this cited below) and the other fit indices are anyway sensitive to other issues as well (which just as weirdly aren't normally discussed). To address the issues presented by a chi-square statistic, absolute fit indices and incremental fit indices were formulated to get a better sense of how well models are fit. RMSEA and SRMR The root mean square error approximation (RMSEA) is an absolute fit index, which means that it tries to explain how well the model explains the data independent of any reference points (this is achieved by comparing the observed covariance matrix (i.e., the collected data) to the implied covariance matrix). That distinction isn't intuitive though, as many would normally call the RMSEA a "badness of fit" index, in that higher values indicate your model sucks. As an aside, it already penalizes complex models, though it is not a parsimony-adjusted index like the PNFI. The standardized root mean square residual (SRMR) is similar...it is an absolute fit / badness of fit index but is approximated in terms of the correlation residuals. Using both, you get a sense of how bad the model fits the data, but one is slightly better at penalizing complexity. CFI and TLI CFI and TLI are incremental fit indices, in that they directly compare a baseline model to the model chosen...in that sense their approximation signifies that higher values = better fitting models, so they are somewhat opposite to RMSEA and SRMR. While CFI does not account for model complexity, the TLI does via the chi-square to degree of freedom ratio. So in general, these measures are similar to those described in the preceding paragraph, only that they specify how "healthy" your model is instead. What this Means for Parsimony-Adjusted Indexes In my domain, these are rarely reported, so take that as you may. In any case, parsimony-adjusted indices simply compare the model degrees of freedom to the maximum possible number of degrees of freedom available in the data. The ratio therefore indicates how parsimonious the model is compared to what is possible. However, we have already noted that we essentially have essentially five indices that approximate the health of the model, some of which already account for model complexity. What does this mean for you? When in doubt, there is nothing wrong with reporting more rather than less, and in fact it may guard you against some of the pitfalls of biased reporting of these indices. However, I wouldn't get upset about one of the more niche fit indices being less than ideal when you pass the rest of the criterion with flying colors and there isn't a great established cutoff for PNFI anyway. Kline in particular, who wrote a whole book on this subject, seemed to really only stress the chi-square, the SRMR, and the CFI. Others who disagree with my answer my post in the comments and I will correct what is said here. Citations Hayduk, L. A. (2014). Shame for disrespecting evidence: The personal consequences of insufficient respect for structural equation model testing. Medical Research Methodology, 14(1), Article 124. Hu, L., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. Structural Equation Modeling: A Multidisciplinary Journal, 6(1), 1â€“55. https://doi.org/10.1080/10705519909540118 Kline, R. B. (2023). Principles and practice of structural equation modeling (5th ed.). The Guilford Press. Stone, B. M. (2021). The ethical use of fit indices in structural equation modeling: Recommendations for psychologists. Frontiers in Psychology, 12. https://doi.org/10.3389/fpsyg.2021.783226
