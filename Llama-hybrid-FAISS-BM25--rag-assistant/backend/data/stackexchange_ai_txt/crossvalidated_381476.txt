[site]: crossvalidated
[post_id]: 381476
[parent_id]: 381461
[tags]: 
This is probably a bit opinion based, but I would normally expect that many of the usual arguments for using Bayesian methods may not apply. E.g. bringing in extra information to compensate for low sample size (usually one can just simulate more) and wanting to use prior information (firstly, exact prior information may be hard to come but and it may be less controversial to just simulate more) would not seem like strong arguments. On the other hand, using a Bayesian method to get an easy to compute approximation to (exact) frequentist confidence intervals using percentiles of the beta distribution may be a reasonable idea - as long as you have enough simulations that your exact choice of prior will be uncontroversial. Putting too strong a prior on a desirable result (e.g. using a Beta(95,5) prior for the coverage probability of 95% credible intervals) might end up being hard to defend, while I would guess most people would not have much of a problem using vague priors such as e.g. Beta(1/3, 1/3), Beta(0.5, 0.5) or the uniform Beta(1, 1) prior, if you have a decent number of simulations. The obvious frequentist alternative is something like an exact Clopper-Pearson confidence interval. I have never had anyone questioning (e.g. on the basis of methodological incoherence) me using one those for simulation studies, even when I was evaluating Bayesian methods. In a way, you are after all evaluating the frequentist properties of a method (repeat sampling performance). Around that I dimly recall some quote (perhaps by Rubin?) that you use the Bayesian approach to construct methods and evaluate these properties in a frequentist way (and that they usually turn out to have good frequentist properties). On the specifics of your project, 500 simulations seems like a pretty low number for the coverage probability of credible intervals (unless they are e.g. 50% intervals, certainly quite low for 95% ones). Even if you observe exactly 95% of simulations with the CI covering your true value, your credible interval for the credible interval coverage under a Beta(0.5, 0.5) prior would be from 92.8% to 96.7% (2500 simulations would get you to 94.1% to 95.8% and 10,000 to 94.6 to 95.4%). I guess if that level of uncertainty is fine in your case that may not be an issue.
