[site]: crossvalidated
[post_id]: 204285
[parent_id]: 82267
[tags]: 
Well actually, this isn't always true - supervised methods are not always better than unsupervised methods. This is a variant of the no free lunch theorem, denying our one-fits-all preferences for methods. Recent results in deep learning involve effectively predicting the data and smoothing the model, and have lead to unsupervised models (clusters essentially) that beat all the supervised algorithms hands down. This applies particularly to (spoken and optical) character recognition and other language related problems. What it comes down to is whether you believe your model more or less than the gold standard. For example with language learning, nobody really has any idea what is going on in people's heads so a good model for unsupervised learning may be giving correct answers and the arbitrary answers of gold standards may be wrong. In some specific cases, I have documented gold standards as being wrong 90% of the time (not overall but for these specific cases that they always get wrong because the creators cheated and used a model + learning to produce the gold standard, or in some cases multiple models, or even the results generated by the first batch of entries to a competition).
