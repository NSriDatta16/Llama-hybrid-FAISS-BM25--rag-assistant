[site]: datascience
[post_id]: 80966
[parent_id]: 80962
[tags]: 
Well, in general case, machines do not understand the text, but they understand the numbers. Thus, we always tokenize the text followed by converting them to some form of numbers. We build a vocabulary of words from the given document, where each word can be assumed as a number corresponding to its index in the vocabulary. Further, this number is converted to one-hot vector representations. Since, you already have sequence of numbers instead of words, you can make an assumption that you can convert them directly to it's one-hot vectors. Or in a advanced way, you can use a embedding layer to learn the embeddings (especially if you are using the neural networks.)
