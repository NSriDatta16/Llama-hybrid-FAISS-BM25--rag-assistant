[site]: crossvalidated
[post_id]: 623054
[parent_id]: 
[tags]: 
DNN: Does mini-batching of grouped data during training introduce information leakage?

I am trying to replicate a deep neural network from this notebook, which works with the French MTPL dataset. The NB is in R and mine is in Python. The dataset contains policy entries with the same features but different claim number and exposure (target value). The NB says, ...we split the dataset into train and test. Due to the potential grouping of rows in policies we can not just do a random split. They assigned GroupIDs for entries with similar features and split the dataset so that a GroupID belongs to either the training or the testing set, but not both. I used GroupShuffleSplit() to replicate this step. However, during the training, the dataset was further subdivided into random batches of 10,000. Wouldn't this disregard the group information and possibly cause information leakage?
