[site]: crossvalidated
[post_id]: 412028
[parent_id]: 412015
[tags]: 
Generally, it's useless to plot the distribution of your outcome and hope you learn something about what distribution to use. Especially so for survival analysis because some values are truncated, so the empirical distribution != the actual outcome distribution. Furthermore, most models assume not that Y has any particular form, but that Y | X has some form. This is only possible to check after regression. (Here's another QA about this: How to choose "family" in Generalized Additive Model (GAM) ). Specifically to your problem, if your goal is prediction, then the assumptions don't matter. All you care about building is the best $F$ s.t. $F(x)$ is as close to $y$ as possible. So your strategy of trying all the models, and picking the one with the highest score¹ is fine. Now, correcting assumptions can improve prediction (ex. transforming a term into a log-term so that is satisfies a linear assumption), but tweaks like this fall under feature engineering more generally. ¹ Of course, you should cross validate these models, see some new stuff in lifelines to make this easier: compatibility with sklearn
