[site]: stackoverflow
[post_id]: 671499
[parent_id]: 671491
[tags]: 
Why? Anyone doing evil (e.g., gathering email addresses to spam) will just ignore robots.txt. So you're only going to be blocking legitimate search engines, as robots.txt compliance is voluntary. But — if you insist on doing it anyway — that's what the User-Agent: line in robots.txt is for. User-agent: googlebot Disallow: User-agent: * Disallow: / With lines for all the other search engines you'd like traffic from, of course. Robotstxt.org has a partial list.
