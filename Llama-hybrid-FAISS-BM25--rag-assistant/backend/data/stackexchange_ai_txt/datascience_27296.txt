[site]: datascience
[post_id]: 27296
[parent_id]: 
[tags]: 
Does it make sense to parallelize machine learning algorithms as part of PhD research?

I'm developing machine learning algorithms to aid in the diagnosis and prognosis of various cancers for my PhD. My lab is an Nvidia teaching center (CUDA). My supervisor thinks that I need to also optimize ML by parallelizing it in CUDA. However, as I see it, a model is trained once and there is no need to train again. Testing a model is also not time consuming. My interests are in ML, not Parallel Processing. 1) Should I spend a large chunk of my time parallelizing with CUDA? 2) Is CUDA still a viable framework for research? 3) In the world outside of research, will this make it easier to get a ML job?
