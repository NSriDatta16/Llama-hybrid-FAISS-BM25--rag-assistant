[site]: crossvalidated
[post_id]: 341817
[parent_id]: 198629
[tags]: 
I'm very much of the opinion that these terms should be separated. Although many people use over-fitting as a catch-all term, it doesn't really capture what is happening in a machine learning setting. That is because many machine learning implementations aren't actually FITTING anything (e.g. as in linear regression or GAM where you're trying to find an equation that best fits the data). There are also no 'goodness of fit' tests performed in most of the machine learning world (although there are metrics used to measure model accuracy). An overly complicated model in machine learning is over-LEARNED or over-TRAINED however in that the method may have learned exactly all the relationships in the dataset perfectly, but it isn't generalized enough for inference or prediction.
