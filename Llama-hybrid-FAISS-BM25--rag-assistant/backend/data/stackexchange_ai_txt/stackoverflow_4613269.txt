[site]: stackoverflow
[post_id]: 4613269
[parent_id]: 2895559
[tags]: 
I guess there has to be a compromise somewhere or the other. If the numbers are really getting so large then few digits of lower orders (say lower 5 digits) might not affect the result as much. Another issue is where you don't really know the size of the dataset coming in, especially in stream/real time cases. Here I don't see any solution other then the (previousAverage*oldCount + newValue) / (oldCount Here's a suggestion: *LargestDataTypePossible* currentAverage; *SomeSuitableDatatypeSupportingRationalValues* newValue; *int* count; addToCurrentAverage(value){ newValue = value/100000; count = count + 1; currentAverage = (currentAverage * (count-1) + newValue) / count; } getCurrentAverage(){ return currentAverage * 100000; }
