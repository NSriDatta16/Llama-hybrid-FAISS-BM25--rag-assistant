[site]: crossvalidated
[post_id]: 487239
[parent_id]: 487212
[tags]: 
If $\beta_1=1$ , the regression equation becomes $y=x+\beta_0+\epsilon$ . That means, in average, all trees grow $\beta_0$ inches (or whatever unit you are using), regardless of their size in 1990. If $\beta_1>1$ , then the trees that started big in 1990 grew more than those that were small in 1990 (since the growth is $y-x=(\beta_1-1)x+\beta_0$ ). This could be due to the bigger trees getting more resources like sunlight and nutrients and therefore growing more. On the other hand, if $\beta_1 , then the smaller trees grew more the big trees. This would be a odd behavior, but it could the case that the big trees from 1990 already reached their full height, while the little ones still have much growing to do. (disclaimer: I have no idea if this is biologically plausible, this is just a possible interpretation of such a result) One could also check if $\beta_0=0$ . That would mean $y=\beta_1x$ , meaning that tree height at 1996 is directly proportional to tree height in 1990 (all trees would grow $(\beta-1)\times100\%$ ). Usually, when doing regression, the hypothesis of interest is $H_0:\beta_1=0$ ..In this case, though, $\beta_1=0$ corresponds to a pretty odd scenario: $y=\beta_0$ . It would mean that, whatever height the trees were in 1990, they all converge to an average height given by $\beta_0$ . The hypothesis $\beta_1=1$ looks like a better null hypothesis, don't you think? Now, about checking if the trees grew significantly, I would probably refer to a paired t-test instead of regression analysis. However, I see a few cases where regression could nicely answer your question: if you have $\beta_1\approx1$ , you could simply check if $\beta_0>0$ , and if you have $\beta_0\approx0$ , you could check if $\beta_1>1$ . Hope I was helpful!
