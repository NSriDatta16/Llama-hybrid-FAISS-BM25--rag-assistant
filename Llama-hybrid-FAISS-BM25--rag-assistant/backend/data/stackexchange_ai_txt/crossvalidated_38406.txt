[site]: crossvalidated
[post_id]: 38406
[parent_id]: 38389
[tags]: 
I don't necessarily see this as being easily treated as a time series problem. To comment on the way you detect outliers, Pierce and Chauvenet are flawed procedures that should be discussed only for historical purposes and never used. Outlier detection involves more than just knowning what the variance should be, the underlying population distribution needs to be assumed. Dixon's test and Grubbs' test assume normality and are desined for single outliers. In their original form they can be very sensitive to masking. But Dixon has variants that enable you to detect multiple outliers as long as the number of outliers is small. Also as I have mentioned in other post Dixon's test is robust to departures from normality. In your case 10 is small enough but I worry about trying to detect as many as four out of a sample of only 10. There is a little bit of a time dependence with you knowing why the outliers are likely to be among the first few measurements. But as Bill Huber pointed out in comments the sequence of 10 is too short to do any sophisticated time series modelling. Normally I argue that outliers should not be rejected but studied further. Here you seem to have a physical reason for higher variability and or trends with the early measurements. CUSUM charts are good for detecting trends but the sequence may be too short to do much. It may be that something informal such as dropping the first four out of ten will work as a practical matter even though it is not a formal statistical test.
