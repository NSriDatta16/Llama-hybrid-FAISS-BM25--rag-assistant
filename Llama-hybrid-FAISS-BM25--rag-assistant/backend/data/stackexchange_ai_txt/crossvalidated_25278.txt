[site]: crossvalidated
[post_id]: 25278
[parent_id]: 25271
[tags]: 
It definitely makes sense in the case of values between 0 and 1. Consider if you have training data with identical X but different Y. If you average the Ys for those X (and keep the proportion of those samples the original data set unchanged), you'll arrive at the same optimal solution. Another way of thinking about it is that your labels are inherently probabilistic. For example, you are trying to summarize or speed up an existing complicated function with a log linear one. Say you have an expensive Monte Carlo simulation solution to a problem, and you want to make a fast approximation to it. You could use the simulation to generate data to train a logistic regressor, and here your labels are not going to be exactly 0 or 1. On the other hand, trying to predict outcomes outside of the [0, 1] interval seems wrong, since they are out of the domain of the logistic function.
