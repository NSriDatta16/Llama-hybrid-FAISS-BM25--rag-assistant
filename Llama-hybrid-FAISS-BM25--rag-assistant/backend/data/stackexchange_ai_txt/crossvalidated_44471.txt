[site]: crossvalidated
[post_id]: 44471
[parent_id]: 
[tags]: 
Nonparametric Bayesian priors on mean $0$ distributions?

Is there any standard way of putting a prior on the mean $0$ distributions? I'm interested in this from the perspective of robustly modelling the error distribution in a regression. So for instance I have some covariates $X$ and I want to specify $E[Y] = \mu(X | \beta)$ where $\mu(\cdot | \beta)$ is of a prespecified form and $Y$ takes values in $\mathbb R$. A simple solution would be to confound the error distribution with the intercept and use a Dirichlet process mixture, i.e. write $Y_i = \mu(X | \beta) + \eta_i$ where $$ \eta_i \sim f(\cdot | \theta), \\ \theta \sim F, \\ F \sim DP(\gamma H). $$ Then I can write $\epsilon_i = \eta_i - E(\eta_i | F)$ and put $\alpha = E(\eta_i | F)$ so that $Y_i = \alpha + \mu(X_i | \beta) + \epsilon_i$. The glitch here is that I don't want the error distribution to be independent of $X$ . I've had a few ideas on how to fix this up, but they seem round-about and hopefully someone here knows of some mainstream solution.
