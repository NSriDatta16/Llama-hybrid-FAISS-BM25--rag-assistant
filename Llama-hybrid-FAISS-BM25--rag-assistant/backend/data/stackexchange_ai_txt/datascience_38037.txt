[site]: datascience
[post_id]: 38037
[parent_id]: 
[tags]: 
Can RL learn to mimic a hash function?

Theoretically, is this possible: When you have a given input string, there are a set of permutations and bit operations to do. The problem is, when you choose an approach like reinforcement learning, the model could do these kind of actions again and again , and could only reach its destination by chance. When there is an upper limit of steps (timesteps), you cannot tell how far the model is from reaching its goal because you just don't know what to do next. The reward is always 0 when the goal has not been reached and 1 when it has been reached. Thus, since the reward is basically always 0 , the algorithm cannot learn. Any ideas as to why it is so?
