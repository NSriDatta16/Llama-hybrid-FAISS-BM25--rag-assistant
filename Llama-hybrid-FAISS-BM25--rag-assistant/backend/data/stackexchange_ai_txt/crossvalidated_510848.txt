[site]: crossvalidated
[post_id]: 510848
[parent_id]: 510817
[tags]: 
The phrase you’re looking for is data sparsity . What you’re modeling here is $p(\mathrm{outcome} \mid \mathrm{website}, \mathrm{advert})$ . (Or, sure, you could model the joint distribution.) With sparse data, this can be challenging. You only have a few points from the joint space to look at. How do we fix this? The go-to is to introduce some form of smoothing . This lets you leverage the observations you do have to help predict unseen observations. A common way is to compute features of the website and advert, which may be shared across observations. For instance, you could have “is this website about commerce?” as a binary (yes/no) feature. The simplest features are “identity features”—“is this website example.com?”, but you can see how this wouldn’t generalize. When you provide these features to a model like logistic regression, information about things you’ve seen will inform predictions about things you haven’t. I’m trying not to be too formal here, but it’s helpful to point out relevant terminology.
