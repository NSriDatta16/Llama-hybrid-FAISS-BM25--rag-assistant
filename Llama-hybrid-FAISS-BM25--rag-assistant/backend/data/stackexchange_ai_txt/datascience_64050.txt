[site]: datascience
[post_id]: 64050
[parent_id]: 
[tags]: 
Can a convention convolution neural network train correctly with different training image size and ratio?

For example the task of transformation, the model consist convolutional layer and pooling layer only, take input of image, and output a feature map (loss MSE, trying to produce feature map that exactly match feature map in label) The forward pass can take any image size and output a feature with size = [w/(n_max_pooling*2), h/(n_max_pooling*2)] Thus, with batch size of 1 , there are no "dimension mismatch error" when we feed different image size, different ratio. The network just output a feature map, due to the nature of convolutional layer and max pooling layer. For example: (batch_size, channel, width, height) Sample 1: 1x3x128x128 => target 64x64 Sample 2: 1x3x768x1024 => target 368x512 .... I would like to know in that case of inconsist input shape, will the network be able to train and update it weight correctly ?
