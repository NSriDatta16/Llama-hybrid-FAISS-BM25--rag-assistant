[site]: crossvalidated
[post_id]: 244417
[parent_id]: 
[tags]: 
Classifier score is higher on test set than on training set. Is this an error?

I am currently getting used to scikit-learn and I trained a simple logistic regression model on the iris dataset. One interesting thing I noticed was when I looked at the classifier.score, namely: classifier.score(X_test, y_test) 0.97368421052631582 classifier.score(X_train, y_train) 0.9553571428571429 I split my dataset in the traditional 75%-25% manner and I was expecting the score on the training data to be higher. Is this not always the case ? If not, why not?
