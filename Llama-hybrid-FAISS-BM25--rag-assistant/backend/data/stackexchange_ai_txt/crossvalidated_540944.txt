[site]: crossvalidated
[post_id]: 540944
[parent_id]: 540916
[tags]: 
Let's Think About Restrictions If you want to the predictions of each quadrant to sum to the total, you have to incorporate that restriction into the model. Presently, there is nothing relating the 4 regressions and hence there is no requirement that the restriction be satisfied. Consider an alternative model. The total at timestep $i$ is $$ N_{total, i} = \sum_j \mathbf{q}_{j, i}$$ We can think of the four quadrants at the $i^{th}$ timestep as a vector (call it $\mathbf{q}_i$ ) constrained to sum to $N_{total,i}$ . Hence, it may be plausible to consider the count in each quadrants as a draw from a multinomial distribution $$\mathbf{q}_i \sim \operatorname{Multinomial}({\theta}_i)$$ Here, $\theta_i$ is the multinomial parameter. It is a vector in which the components sum to 1. Each component of $\theta_i$ can be comprised of a regression on enso for each quadrant, and then forced to sum to 1 using a softmax function. Hence, the $j^{th}$ component of $\theta_i$ would be $$ \theta_{j, i} = \dfrac{e^{X_i\beta_j}}{\sum_j e^{X_i\beta_j}}$$ Here $\beta_j$ is a vector of regression coefficients, one for each quadrant, and $X_i$ is the $i^{th}$ row of a design matrix (basically a matrix with a column of 1s and whatever other variables you want to regress on). This is quite the model. Let's recapitulate the model here for posterity. Remember, $i$ is the time step. The Model $$ N_{total, i} = \sum_j \mathbf{q}_{j, i}$$ $$\mathbf{q}_i \sim \operatorname{Multinomial}({\theta}_i)$$ $$ \theta_{j, i} = \dfrac{e^{X_i\beta_j}}{\sum_j e^{X_i\beta_j}}$$ I'm not sure how to fit this in a frequentist framework, but we can use MCMC and Stan to fit this in a Bayesian framework. A Stan Model model_code = " data{ int N; int quadrants[N, 4]; matrix[N, 2] X; } parameters{ vector[2] beta_ne; vector[2] beta_nw; vector[2] beta_se; vector[2] beta_sw; } transformed parameters{ vector[N] theta_ne = X*beta_ne; vector[N] theta_nw = X*beta_nw; vector[N] theta_se = X*beta_se; vector[N] theta_sw = X*beta_sw; matrix[4, N] theta; for(i in 1:N){ theta[:, i] = softmax([theta_ne[i], theta_nw[i], theta_se[i], theta_sw[i]]'); } } model{ beta_ne ~ std_normal(); beta_nw ~ std_normal(); beta_se ~ std_normal(); beta_sw ~ std_normal(); for(i in 1:N){ quadrants[i] ~ multinomial(theta[:,i]); } } generated quantities{ int quad_ppc[4, N]; for(i in 1:N){ quad_ppc[:,i] = multinomial_rng(theta[:,i], sum(quadrants[i])); } } " Let's massage some of the data you've posted so we can use it with Stan library(tidyverse) library(cmdstanr) library(tidybayes) ### Setting up the four quadrants genesis_nw % mutate(total = ne + nw + se + sw) model_data = list( N = nrow(d), quadrants = d %>% select(ne, nw, se, sw) %>% as.matrix(), X = cbind(rep(1, nrow(d)), d$enso) ) Now we can fit the model with cmdstanr tmp = write_stan_file(model_code) model = cmdstan_model(tmp) fit = model$sample(model_data ) The Fit Here are the predictions with associated 95% credible intervals This may not look like a great fit, but remember we are comparing the estimated mean with the observed data. Let's take a look at prediction intervals Many of the observed data fall within the 95% posterior predictive interval. That is a good sign, but not completely abdicating of any criticism. We might need to think of ways to check the model which are not available to me because I don't have the necessary domain expertise on your problem. We could also check that the predictions sum to $N_{total,i}$ at each time step, but this is unnecessary because the model forces this to be the case. This answer is meant to demonstrate how one might fit such a model to satisfy your constraints. In reality, much thought should be put into model criticism and model priors before using such a model.
