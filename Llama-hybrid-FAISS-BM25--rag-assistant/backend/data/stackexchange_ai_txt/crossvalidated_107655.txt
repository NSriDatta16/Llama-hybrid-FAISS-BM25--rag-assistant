[site]: crossvalidated
[post_id]: 107655
[parent_id]: 
[tags]: 
100% confidence interval for mean

Is it possible to apply the law of the iterated logarithm (e.g. http://en.m.wikipedia.org/wiki/Law_of_the_iterated_logarithm ) to derive non-trivial (i.e. bounded) 100% confidence intervals for population averages? An abstract ( http://www.tandfonline.com/doi/pdf/10.1080/10485250410001713963 ) gives at least such hint. However, its first reference by Robbins ( http://projecteuclid.org/euclid.aoms/1177696786 ) does not seem to cover such result, as pointed out in @whuber's comment. Edit: After justified comments by @whuber, I reformulated the question.
