[site]: crossvalidated
[post_id]: 351870
[parent_id]: 
[tags]: 
Appropriate statistical or machine learning measure to find important IDs within array of t-tests

I have an array of data that contains ~600 protein name identifiers, and each ID holds an accompanying four hundred t-test scores from interrelated experiments. So it's a 600x400 matrix, let's say. I've been investigating basic machine learning and want to try my hand at regression/classification tests in order to answer the following questions here: In addition, I want to know whether or not specific IDs are biasing the overall results - if they are consistently significant (below 0.05) across many vertical states, then that's an indication these IDs are over-represented within my total sample. I think what I am after is a clustering method that is a little more complex than a simple (A|B) classification. I want to figure out a decent measure by which I can either say, in machine learning language: the following IDs are consistently significant in more than X% of the total t-test states. Should I go for a k-means method, random forests, or should I try a regression method like a linearSVC?
