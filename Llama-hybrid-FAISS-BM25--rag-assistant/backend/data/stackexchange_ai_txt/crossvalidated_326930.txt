[site]: crossvalidated
[post_id]: 326930
[parent_id]: 326926
[tags]: 
The training loss becomes zero when your model becomes "perfect" at giving predictions for the training data. However, it is the validation loss , i.e., the loss on data that were not used for training, that tells you how good the model really is. Unless the validation error is also low, you are experiencing overfitting . In that case search for some of many available methods to perform neural network regularization . For a comprehensive overview of regularization methods you can refer to my article Regularization for Deep Learning: A Taxonomy .
