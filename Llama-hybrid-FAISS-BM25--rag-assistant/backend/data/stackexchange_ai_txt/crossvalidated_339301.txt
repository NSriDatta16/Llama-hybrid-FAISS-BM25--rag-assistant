[site]: crossvalidated
[post_id]: 339301
[parent_id]: 339283
[tags]: 
You are essentially applying a recurrent neural network to solve a Markov problem. The neural network can be trained to learn a so-called hidden Markov model, in your time data. You try to predict the probabilities of the possible next states at time $t$, given the current state $t-1$, the previous states (represented by feature variables), and state information: $t-2$, $t-3$, $\ldots$. One first question you need to address, is whether the state at $t-2$ has any extra predictive power as to which next state is being reached. As the underlying mechanism is assumed to be unknown, you ought to experiment with this - adding or retracting historic, previous state information from your recurrent neural network. There are basically two alternative strategies to follow: They both involve training the RNN to convolve along the time/state axis. According to one strategy, you ridirect the output vector of the RNN to special input units, which exist alongside the regular feature-input nodes. According to the other strategy, you provide the vector of hidden-node values to the special input units. The implicit assumption of both these approaches is that you are dealing with a first-order Markov chain. State-information before $t-1$ is completely incorporated into the current state. Keep a subset of your data as a separate test set.
