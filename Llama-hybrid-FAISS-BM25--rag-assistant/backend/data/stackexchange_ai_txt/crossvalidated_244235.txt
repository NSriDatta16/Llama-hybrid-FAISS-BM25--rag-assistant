[site]: crossvalidated
[post_id]: 244235
[parent_id]: 
[tags]: 
uniform distribution - computing the squared error for an estimator?

Background: I'm trying to follow ML lesson about Bayesian inference . They have n samples from a uniform distribution $U(0, \theta)$, and they suggest 2 estimators: 2 times the average $2\frac{\sum{x_i}}{n}$ largest sample $x_{(n)}$ Question: They claim that the squared errors of each estimator is: $E[(2\frac{\sum{x_i}}{n} - \theta)^2] = ... = \frac{\theta^2}{12n}$ $E[(x_{(n)} - \theta)^2] = ... = \frac{2\theta^2}{(n+1)(n+2)}$ I can follow the derivation (denoted by ...), but I'm not sure what's the meaning of the left hand sides of those 2 formulas? why isn't it $E[(x_{i} - \theta)^2]$ always? it looks as if they subtract each estimator from itself :S
