[site]: stackoverflow
[post_id]: 5683972
[parent_id]: 
[tags]: 
C++ heap memory performance improvement

I'm writing a function where I need a significant amount of heap memory. Is it possible to tell the compiler that those data will be accessed frequently within a specific for loop, so as to improve performance (through compile options or similar)? The reason I cannot use the stack is that the number of elements I need to store is big, and I get segmentation fault if I try to do it. Right now the code is working but I think it could be faster. UPDATE: I'm doing something like this vector > vec(node_vec.size()); for(uint i = 0; i threshold ) { vec[i].insert(j); vec[j].insert(i); } some details: - I used hash_set, little improvement, beside the fact that hash_set is not available in all machines I have for simulation purposes - I tried to allocate vec on the stack using arrays but, as I said, I might get segmentation fault if the number of elements is too big If node_vec.size() is, say, equal to k, where k is of the order of a few thousands, I expect vec to be 4 or 5 times bigger than node_vec. With this order of magnitude the code appears to be slow, considering the fact that I have to run it many times. Of course, I am using multithreading to parallelize these calls, but I can't get the function per se to run much faster than what I'm seeing right now. Would it be possible, for example, to have vec allocated in the cache memory for fast data retrieval, or something similar?
