[site]: crossvalidated
[post_id]: 525085
[parent_id]: 
[tags]: 
If the curse of dimensionality exists, how does embedding search work?

The curse of dimensionality tells us if the dimension is high, the distance metric will stop working, i.e., everyone will be close to everyone. However, many machine learning retrieval systems rely on calculating embeddings and retrieve similar data points based on the embeddings. These embedding dimensions can be 512, 1024 or 2048, which is very high. My question is: If the curse of dimensionality exists, how does embedding search work?
