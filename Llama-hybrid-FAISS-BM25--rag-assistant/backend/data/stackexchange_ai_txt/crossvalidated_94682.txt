[site]: crossvalidated
[post_id]: 94682
[parent_id]: 94609
[tags]: 
Maybe your data just doesn't contain clusters? Not all data (or data representations!) is clustered. Random numbers, for example, aren't. Maybe, a large part of your data just is a large blob? This happens, and you may have to live with this... If 99% of your users are of type A, I would expect the largest cluster to have 99% of objects. Are your sure your data is supposed to consist of groups of equal size? Maybe you have a lot of outliers Also a very common thing, and that causes many methods to fail. k-means for example is known to be not very robust against outliers... and in single-link clustering, you usually get a lot of singleton objects (clusters with a single member), before you find any really interesting cluster. In real data, even when you have clusters A, B and C, you may still have 10% or more objects that are neither of type A, B or C! Your data representation may be distracting / unhelpful If you have 5500 features, chances are that some of them are useless. If too many are useless, this may just ruin your analysis. You may need to spend more time preprocessing your data. For example, if you have 5500 attributes corresponding to colors (blue, light blue, navy blue, royal blue, night sky blue, dark blue, ...) you may need to merge similar attributes first! Similar with text, it is a best-practise to do e.g. stemming to merge different variants of the same word (go, going, gone, goes, ...) into one feature. Preprocessing is usually key to get good results! Consider other tasks Maybe you aren't actually looking for clusters, but e.g. association rules. On sparse binary data, association rules often provide more insight than clusters; in particular if the clusters are based on averaging and strict partitions. Association rules may for example overlap - a single item can exhibit two common traits (= rules). Or none (i.e. noise, singleton, ...)
