[site]: crossvalidated
[post_id]: 278013
[parent_id]: 97557
[tags]: 
It looks like your objective is prediction, in which case stepwise might not be too bad but be wary of calling the resulting model 'optimal' unless you're clear about what 'optimal' actually means to you in this case. Even still, I'd say the LASSO is a better option. I would strongly advocate a Bayesian approach to these 'variable selection' problems if you want to use regression. You really need a very full picture of the uncertainty in your estimates in these situations and the usual confidence intervals etc. are not really appropriate. There are Bayesian versions of the LASSO (including fused/grouped LASSO) as well as the Horseshoe prior, which is supposedly better at separating strong and weak signals (large effects remain unshrunk, which is not the case with the LASSO). You can implement these methods fairly straightforwardly using the R packages rstanarm and/or brms if you're doing (generalised) linear modelling. You can also use the package loo to perform approximate leave one out cross validation for model comparison, which might be appropriate here. You could try a non-parametric approach like a regression forest or a boosting machine, both of which can be implemented in caret (along with literally hundreds of other methods) and provide 'variable importance' measures. You should not do any of this blindly, though. Don't just throw this at glmnet and take the results as gospel, think about whether your results make sense . If they don't, there are possibly some variables you can discount before even starting -- if you get results that make you think, "well, that predictor should definitely not be important", just scrap that predictor to begin with. Tibshirani and Hastie are the main frequentist authors for this stuff (see their papers and especially their book 'Elements of Statistical Learning'). For Bayesian, I'd recommend starting from the Horseshoe paper .
