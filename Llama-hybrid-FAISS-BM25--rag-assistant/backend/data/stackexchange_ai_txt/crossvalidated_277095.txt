[site]: crossvalidated
[post_id]: 277095
[parent_id]: 227125
[tags]: 
Think about the following problem. You have a huge matrix (with let say 1000 rows and 1000 columns). In each cell of this matrix you have one or no values. You need to create a predictive model that predicts the value in a cell given by the row ID and column ID. The described problem faces the same problem as you do: As input you have only categorical variables (row ID and column ID are categorical) and each categorical variable has many possible values (number of rows and number of columns). How does this problem is solved? One standard way to solve this problem is a matrix factorization . You basically assign different numerical vectors to each row and each column and then you calculate the value in the cell by applying a function to the vectors corresponding to the selected row and column. For example, in the case of the Non-Negative Matrix Factorization this function is just scalar product of the row-vector and column-vector. So, if you want to apply the same approach to your problem, you need to map each value of each categorical variable into a numerical vector. And then you use these vectors as inputs to your model-function and as output you get your predictions. The exact mapping from categorical variables to vectors and / or shape of the function are decided by the model-training. Another way to approach your problem is inspired by collaborative filtering. To predict a value for a given row and column you need to find similar rows and columns and get values from them. Basically, in your cases it translates to a sort of k-NN (nearest neighbor) approach. Use values of the categorical variables to find row with similar values of categorical variables. Then take the values of the targets from the "neighbors" and combine them (for example by averaging them out, maybe with the weights proportional to similarity measure).
