[site]: crossvalidated
[post_id]: 357643
[parent_id]: 
[tags]: 
Representing an unordered set of vectors as a single vector for neural networks

I am working on a sequence-to-sequence task. My input values at each time set consist of an unordered set of small zero/one vectors. For instance, at time step t my input could be {[0,1,0,1], [1,0,0,1]}, and that would be equivalent to {[1,0,0,1], [0,1,0,1]}, but not to {[0,1,0,1], [0,0,1,1]}. How should I represent these inputs so that it learns to generalize beyond ordering? EDIT: I initially asked about one-hot vectors, but realized that a) my application actually requires sets of dense 0/1 vectors, and b) as Tom pointed out, one-hots are not so interesting because they could be summed together. Sorry about the change!
