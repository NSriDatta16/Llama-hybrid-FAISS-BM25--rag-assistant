[site]: crossvalidated
[post_id]: 352652
[parent_id]: 
[tags]: 
Is a 'Type 1 error' an indication of error, a probability of error, a measure of error or all of the above?

I have come across two definitions of 'Type 1 error' in dictionaries published by Oxford University Press: In hypothesis testing, the incorrect rejection of the null hypothesis when it is true. Alternatively termed false-positive. A Dictionary of Business Research Methods (2016) The probability of being wrong in rejecting a null hypothesis about a parameter in a model. A Dictionary of Social Research Methods (2016) I am not a statistician, but these seem to me to be two different definitions. After further reading, I'm led to believe that there are two different approaches to hypothesis testing: A 'classical' method of conducting hypothesis testing which produces one of two results : either True or False. A Bayesian factor approach which produces a probability as its result, rather than returning either True or False. I suppose I have two related questions: Am I correct in thinking that the two different approaches to hypothesis testing I note above exist? If so, is the Type 1 error as probability a measure of how erroneous the error is, or how probable it is that there is an error in the first place? The reason I ask my second question is that in my language we use a different word for an error (='mistake') and error (='measure of error', or literally 'astrayness'). In other words, senses 1.1 and 1.2 here use different words in my language, and if the probability-based Type 1 error is a measure of error, we would have to use a different term for it than that used for the true/false Type 1 error. Thanks for taking the time to read. Any help will be gratefully received!
