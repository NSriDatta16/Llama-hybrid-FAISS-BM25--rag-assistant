[site]: crossvalidated
[post_id]: 199577
[parent_id]: 
[tags]: 
Ranking of neurons of bottleneck layer in AutoEncoder network, similar to components in PCA

When using Principal Component Analysis (PCA) for dimension reduction, the extracted components (basis vectors) are sorted based on the eigenvalues of the covariance matrix of data, i.e. we have the first principal component, second principal component, etc. Where kth principal component corresponds to the direction of kth largest variance in data. In practice, the first components are more important than the later ones in describing the data, so we can keep the first L components and project the data points on them. Since Autoencoder neural network (with bottleneck layer), also called non-linear PCA, is also a method of dimension reduction, does an analogous interpretation exist for Autoencoder? I mean, is there a way to sort the neurons of Autoencoder bottleneck layer based on their importance in describing the data? Actually, I want to use Autoencoder to find some manifolds in feature space which capture the largest variations in the data (like basis vectors of PCA, but nonlinear). If it is not possible in Autoencoder, maybe there is an extension of Autoencoder network which is suitable for my purpose?
