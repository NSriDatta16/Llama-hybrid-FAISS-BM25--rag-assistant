[site]: crossvalidated
[post_id]: 446867
[parent_id]: 
[tags]: 
Why is that in reinforcement learning, the policy is a function of the state (but not the or just the reward?)

In reinforcement learning, we seek an optimal policy which is defined as a mapping $\pi: s \mapsto a$ from the set of states to the set of actions, or a mapping $\pi: s \mapsto p(a|s)$ , $p(a|s)$ is a probability distribution over my actions, given a certain state. However, this almost seems counter-intuitive if not unrealistic for many real-world scenarios. In real-life, it seems that we simultaneously take state and reward into consideration or even just the reward. Why we don't even need the state Consider the following, I am playing rock-paper-scissors against an opponent, then when my action is chosen (Rock/Paper/Scissor), if I am beaten, then it is almost as if I receive a negative reward, if I win, a positive reward, if we tie, then no change. Hence my brain tries to produce a policy $\pi: r \mapsto a$ . For instance, if I receive a consecutive negative reward, then I would change my strategy. There is just mapping from reward to action. Defining a state seems to be redundant here. In a even more extreme case. I don't even know my state. All I have on my screen is a stream of reward (or actual $$), say 1,4,2,5,8,0,3,4. I hit some keys on my keyboard, and the numbers change. I want press key in such a way to get the biggest number. There is no need for a state here. So the mathematical definition of $\pi$ doesn't even make sense because the state space is the empty set! Why we might need both the state and the reward From a mathematical perspective, $\pi(s_t) = \text{argmax}_a Q(s_t,a_t)$ , but the $Q$ function is defined as a function of the reward! In fact, it is the expectation over the current reward $r_t + \text{ other terms }$ So even from a purely mathematical perspective, $\pi$ should be a function of both the state and the reward, as it simply just depends on $r_t$ . That's just composition of functions man! Am I over thinking this issue? Can someone who is expert in this area let me know how people even think about the policy when 1. the state is not defined, 2. when reward also needs to be taken into account
