[site]: crossvalidated
[post_id]: 476709
[parent_id]: 435825
[tags]: 
The classical, discrete-time, linear Kalman filter is the optimal estimator of the states $x(k)$ in the state-space model $$ x(k) = A x(k-1) + B u(k) + v(k), \quad v(k) \sim \mathcal{N}(0, \Sigma_v) \\ y(k) = C x(k) + w(k), \quad w(k) \sim \mathcal{N}(0, \Sigma_w).$$ The KF assumes the whole state-space model, i.e., the matrices $A,B,C,\Sigma_v,\Sigma_w$ , to be known a priori. It is simply not applicable (without suitable modifications, some of which I will mention below) if the system is either nonlinear, any component of the system is unknown, or the noise is non-Gaussian. Note that the solution can be calculated exactly in the linear, Gaussian case, because a Gaussian can simply be parameterized by the mean and covariance, and because a linear transformation of a Gaussian variable is again Gaussian. In other words, any quantity to be estimated in the filter will be Gaussian as well. If the state-space system is nonlinear , i.e., $$ x(k) = f(x(k-1) + g(u(k)) + v, \quad v\sim\mathcal{N}(0, \Sigma_v) \\ y(k) = h(x(k)) + w, \quad w\sim\mathcal{N}(0, \Sigma_w),$$ then exact inference is intractable and one must resort to approximate solutions, i.e., an extended Kalman filter (which simply linearizes any nonlinearity around the mean of the input variable), an unscented Kalman filter (which performans a statistical linearization around the input variable distribution), or a particle filter (which does not linearize at all). These are listed in increasing order of accuracy. An UKF is essentially preferrable in all cases to an EKF, whereas a particle filter is computationally much more demanding. A particle filter is essentially the time-series version of a Monte Carlo approach. All of these approaches still assume the nonlinear state-space model to be known! If parts of the system are unknown, then you're performing joint state and parameter inference , which is a much harder problem and subject of current research. There are many solutions proposed for different cases, a good overview can be found in Simo Särkkä's book "Bayesian filtering and smoothing" . He mentions three approaches: a) direct likelihood optization, b) expectation maximization, and c) Markov chain Monte Carlo (MCMC) methods. An overview of nonlinear system identification (which is what you need to do if you're uncertain about the nonlinear state-space model) can be found in the recent paper by Schoukens and Ljung . One approach that currently enjoys some popularity is to use a Gaussian process model for estimating the nonlinearity, see, e.g. this NeurIPS paper .
