[site]: stackoverflow
[post_id]: 744789
[parent_id]: 715840
[tags]: 
My only issue with code coverage and unit tests is that unit tests only test what they were originally designed to test, and they, by definition, are code and prone to the same functional software-rot that plagues regular code. (they are only good for what they are written for, and after a while, that's not enough) But high quality unit tests will obviously provide some protection. So these are my important factors for software rot: Number of external data interface points (extDataIntfPts) Quality of data/error handling, unit tests (codeQuality) Dependency on underlying implementations such as OS/VM. (osDep) Number of external implementation interface point such as plugins. (extIntfPts) Complexity of code/simple volume of code (linesOfCode) As a system lives in production, it is exposed to a greater variety of data inputs as the dataset it has collected grows. This by definition exposes the codebase to a greater number of edge cases and sequences. This can be mitigated by the quality of the data processing, error handling, and unit tests. There's also the moving targets of the underlying environment that the system operates in. One way to moderate this is to put the application in a VM. If the system implements plugins, I could see the codebase facing a greater chance of failure as more plugins are developed. Complex code != elegant code. If it's elegant, it's probably simple. I'm going with the simple point here that the more code there is, the less likely it is that it is well tested, but I suppose it could be turned around. So, here's my equation: bitrot=((linesofcode/codeQuality)*(extDataInfPts+(osDep/change)+extIntfPts)*numberOfSecondsDeployed) Judging codeQuality would probably involve the metric of what the code coverage in the unit tests is. You could run a static analysis program against it to determine potential bugs and that would probably be some help as well. I mean, at some point, it's really hard to score because multi-threading code should be weighted a lot heavier than a POJO. And yes, refactoring ought to be figured in, but only where there are evidences of software rot. In the end, it's a pseudo-science. Here's my contribution to pseudo-science.
