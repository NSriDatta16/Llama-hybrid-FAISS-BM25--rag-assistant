[site]: crossvalidated
[post_id]: 346821
[parent_id]: 344914
[tags]: 
EDIT: For linear regression , if the variability in the errors of observation of X are small relative to the range of X then it is not much of a concern when fitting model. Therefore, you may not have to adjust your fitting procedure to account for error in inputs. You are interested in prediction error, but you have few data points and can only fit the model once. You can't divide your dataset into training and test sets because you do not have enough data. You can't perform cross-validation because you can't refit the model several times. Therefore, I believe you can not estimate the prediction error. If you can estimate the prediction error through cross validation, then you can use a MCS to get the distribution of error at two prediction locations and therefore the distribution of differences in predictions. ORIGINAL: I think you are interested in the prediction error. The simplest and most widely used method for estimating prediction error is cross-validation. You should be able to use cross-validation to get an idea of how accurate your model is for species A and B. To incorporate input uncertainty you may consider using a Monte-Carlo Simulation where you generate model predictions with uncertainty estimates for a distribution of possible inputs. Then you can summarize the distributions of outputs for species A and B and compare. However, the above approach will not account for model error that may arise due to not accounting for error in model inputs when fitting your model. You might consider "training with jitter" where you add some noise to your training data to improve generalization of model predictions. I am not very familiar with this approach. See "Machine Learning with Known Input Data Uncertainty Measure" by Czarnecki and Podolak for more information.
