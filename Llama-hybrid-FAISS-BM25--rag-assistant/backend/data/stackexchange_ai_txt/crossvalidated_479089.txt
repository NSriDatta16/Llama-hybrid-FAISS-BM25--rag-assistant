[site]: crossvalidated
[post_id]: 479089
[parent_id]: 
[tags]: 
Dealing with differing number of replicates of measurements pr sample?

Here's a question that I haven't come across in any statistics classes or books. Imagine I have $n$ number of samples and I subject them to a series of different tests to characterise them. For fun's sake let's say it's beer. For each sample I do sensory analyses and get e.g. 5 observations pr samples. I measure pH in duplicate. I measure viscosity in triplicate. I measure another variable in quadruples and so on to obtain the dataframe below: How to best combine these results in a dataframe (rows as observations, columns as variables) for further analysis (i.e. multivariate) and have the same number of observations pr variable? The variables with lower number of measurements will inevitably have missing values (NAs) but they aren't as such "missing", there just aren't that many observations. I see these solutions: I average the measurements with lower number of replicates and paste it. In order to retain the distribution of data (and not effectively falsify data) for further analyses I randomly distribute (copy paste) the lower replicate measurements to obtain the higher number of observations (e.g. 12). (or 2.b) I replace all NAs by the mean. (or 3.c) I calculate the mean and sd of the lower replicate measurements and use rnorm (or similar) to create randomly normally distributed observations (i.e. 12 in this case). This is assuming normally distributed sample populations and gets tricky when dealing with e.g. duplicate measurements. I do all measurements 12 times. Each solution has definite drawbacks and possible ethical complications. Loss of variance (information), something suspiciously close to falsifying data (although replacing NAs by the mean is common practice), time and money issues etc. In cases where there are e.g. 100s or more observations for one variable and 2 and 3 for other variables it becomes very tricky. What do other researchers do? Is there some standardised way of doing this since I can't be the first researcher to deal with this issue.
