[site]: datascience
[post_id]: 111782
[parent_id]: 111780
[tags]: 
It is not a question of "noise", but rather granularity. Typically, first few Conv layers learn low-level features (e.g. corners, edges, …etc.), and as you go deeper, the network learns more high-level features (e.g. nose, eye, …etc.). I think you are more interested in Saliency maps, which reflect the importance of regions in the image in influencing the decision (i.e. the output of the model). This is meant to reflect how humans focus on certain aspects of images. To deduce the number of optimal conv layers, you would need to use cross-validation. For example, you could try removing one layer at a time and see how the performance is affected. Typically, you would need choose the simplest model with highest empirical performance. On a side note, I suggest you use, or at least get inspiration from, existing CNN architectures when designing your own CNN. There is virtually infinite ways to put your layers together, it's kind of like legos but with continuous numbers. This would save you time putting together a good-performing model faster.
