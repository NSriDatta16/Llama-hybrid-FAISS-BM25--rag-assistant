[site]: crossvalidated
[post_id]: 572314
[parent_id]: 572213
[tags]: 
In theory, no. In practice, probably. The loss function you are minimizing is basically $$ \min \ \frac{1}{N}\sum_{i=1}^{N}\sum_{k=1}^{K} (y_{ik} - f_k(x_i))^2 $$ where $x$ is features, $y$ is $K$ -dimensional output. Scaling the $y$ 's makes no difference at all in terms of the global minima. However in practice and as you've noticed, the differing scales means that in the gradient steps the larger outcomes contribute "more" (gradients are larger) to the loss function. Thus a tiny improvement in the last output may be the same as a huge improvement in the first output where the scale is much smaller. Whether this actually makes a difference largely depends on the dataset and your optimizer (for example if you are decaying the learning rate it might not matter much). Since neural networks generally converge to local minima and there's no downside to it, I would normalize the outputs for more stable training.
