[site]: crossvalidated
[post_id]: 531113
[parent_id]: 
[tags]: 
best loss function to fit model if observations contain montecarlo noise?

I have observations on the sphere and I'm trying to fit spherical-harmonic coefficients to best approximate and interpolate the observations. I'm using a solver library for non-linear least squares problems to find the coefficients that minimize the sum of least squares error of all observations against the resulting spherical-harmonics function. If my observations are accurate, this works very well. However, my observations are generated by a different process which employs monte-carlo sampling. This means that my observations would first need to be averaged and resampled over the sphere (for example, create some grid on the sphere, take all samples in each cell, take the average value of all observations within each cell and then replace them with a single averaged observation for this cell. This works, but it seems there is quite some loss of information in this step (if I make the grid too coarse then a lot of detail is lost, if I make the grid too dense, then the resulting resampled values still contain noise). So I wonder if I could optimally fit my model directly to the monte-carlo observations without first resampling them? Is there a loss function that can achieve this? I thought about using L1 regression instead of L2, but this probably could only work if the resulting spherical harmonics could perfectly represent the ground truth... generally I have a lot more (monte carlo noise containing-)samples than frequencies my sh can represent.
