[site]: crossvalidated
[post_id]: 448478
[parent_id]: 
[tags]: 
When to use graph clustering (by constructing a graph from raw data) vs conventional clustering methods?

This is a conceptual question. Say I have some tabular data, and a known similarity function i want to use to compare records in this tabular data. Records correspond to members of a MileageProgram, for example, and columns have categorical features corresponding to each member (Name, Membership tier, Country of Origin, City of residence, Color of hair, etc...). I could approach this in two (and there may be more, but I'm interested in comparing these two for the moment): Approach 1: One hot encode categorical variables (or find another way to embed/encode them). Use the known distance measure/function to calculate pairwise distances among the N members in my dataset. Then perform clustering using whatever makes sense for the structure of the data (e.g. K-means, DBSCAN, whatever...). Maybe throw in some dimensionality reduction Approach 2: Use the known distance measure/function to calculate pairwise distances among the N members in my dataset. Apply a threshold to create linkages based on these calculated distance values, and create linkages when distances are lower than some threshold T. Employ community detection methods on graphs (correct one, TBD). Is there a rule of thumb to understand when to prefer Approach 1, and when to prefer Approach 2? What are the pros and cons of choosing one approach vs the other? I can see why thresholding might be a coarse step (in Approach 2) but there must be some scenarios where Approach 2 is the better approach to take?
