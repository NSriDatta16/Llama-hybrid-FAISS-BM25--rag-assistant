[site]: crossvalidated
[post_id]: 572053
[parent_id]: 531630
[tags]: 
When you are multiplying $X_1$ and $t$ , then you are using something like an interaction effect . You could apply such an effect in your regression, but based on the correlation alone it is difficult to judge whether you have exactly an interaction effect, where the magnitude of the coefficient associated with $X_1$ varies for different values of $t$ . Instead, the situation could also be that the coefficient remains the same for different values of $t$ , but you have a decreasing correlation because the noise or other parameters change. What are the coefficient values for the different buckets? Could you plot these? Also, even if we would see a variation in the coefficient as function of the bucket $t$ , then it might be that you need to apply it to multiple variables at the same time. If correlation of $X_1$ and $Y$ are close to zero, Shoudln't the coefficient be close to zero, thus smaller? And how else can I leverage this feature? The coefficients size is not the same as correlation $\rho$ . In simple linear regression it is for instance $\beta = \rho \frac{\text{var}Y }{\text{var} X_1}$ . And for the more general ordinary linear regression there are even more factors involved. Thanks. Then what else can I do to "condition" $X_1$ to enhance my regression? Seems a bit wasteful not to use this phenomenon? It is not necessarily possible that you could 'enhance' the regression. It might be that you just have a fixed deterministic part of the model (not dependent on $t$ ) but noise that is not constant in time. In that case you could 'enhance' the regression by using weighted regression giving points with different $t$ different weights, but it is not gonna show much in the regression statistics like lower $R^2$ . In fact, the $R^2$ will get worse because you focus on the part of the data with lower variance. Below is an example with the model $$z = a + b \sin(15 \pi t) + \text{noise}(t)$$ where the correlation changes depending on the time frame. For $t>10$ the correlation is lower, but the coefficient remains the same. The change in correlation is in this example due to the different noise. When we want to make use of this 'phenomenon' then we could use for instance a weighted least squares model. This will reduce the impact of the noisy points on the estimate. This is useful because the fit with the weighted least squares is closer to the 'true' model. However, the red line based on a regular least squares fit, results in a higher $R^2$ (because it fits the noise). You might consider that a better performance, but it is deceptive and it is just a better fit of the noise and not a better fit of the underlying model. set.seed(1) x = seq(0,1,0.01) * 15 * pi sig = c(rep(0.3,floor(length (x)/3)), rep(2,length(x) - floor(length (x)/3))) noise = rnorm(length(x), 0, sig) y = sin(x) z = y + noise plot(x,z, pch=21, col=1, bg=1,cex=0.7) lines(x,y) mod = lm(z~y) lines(x,predict(mod), col = 2) mod2 = lm(z~y, weights = 1/sig^2) lines(x,predict(mod2), col = 3) legend(0,5, c("true model", "least squares fit", "weighted least squares fit"), cex = 0.7, lty = 1, col = c(1,2,3))
