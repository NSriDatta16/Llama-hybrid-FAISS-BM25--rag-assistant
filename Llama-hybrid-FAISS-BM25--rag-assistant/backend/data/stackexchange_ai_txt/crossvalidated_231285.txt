[site]: crossvalidated
[post_id]: 231285
[parent_id]: 
[tags]: 
Dropping one of the columns when using one-hot encoding

My understanding is that in machine learning it can be a problem if your dataset has highly correlated features, as they effectively encode the same information. Recently someone pointed out that when you do one-hot encoding on a categorical variable you end up with correlated features, so you should drop one of them as a "reference". For example, encoding gender as two variables, is_male and is_female , produces two features which are perfectly negatively correlated, so they suggested just using one of them, effectively setting the baseline to say male, and then seeing if the is_female column is important in the predictive algorithm. That made sense to me but I haven't found anything online to suggest this may be the case, so is this wrong or am I missing something? Possible (unanswered) duplicate: Does collinearity of one-hot encoded features matter for SVM and LogReg?
