[site]: crossvalidated
[post_id]: 502271
[parent_id]: 424804
[tags]: 
This is a fairly old question but since it has no accepted answer I will give my two cents. In logistic regression, it is typical to have a reference group, meaning we drop one category from the variable and lump it into the interpretation of the intercept. Consider a categorical variable with three levels: a,b, and c. Suppose that by recursive feature elimination that you determine category c should be dropped. What is the effect of this? By removing category c, you automatically change all observations of level c to level a. Since the variables are all dummied, the observations from category c have 0s in columns for a and b. Remove the column c, and you automatically make all observations of category c into category a. This can result in large bias. If you are going to select categorical variables you need to select/eliminate groups of dummy variables at a time. Either the model has all the variables from that category, or it doesnâ€™t.
