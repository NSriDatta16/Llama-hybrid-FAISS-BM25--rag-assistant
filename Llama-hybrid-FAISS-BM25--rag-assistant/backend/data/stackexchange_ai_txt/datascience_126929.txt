[site]: datascience
[post_id]: 126929
[parent_id]: 126919
[tags]: 
This could be solved with a sequence-to-sequence model, but I feel this might be overkill for your use case. In your case, it seems that you are trying to label part of the phonetic transcription as a name, which fits more with named-entity recognition. For NER, I'd recommend using SpaCy for this ( https://spacy.io/universe/project/video-spacys-ner-model-alt ), but of course, you could implement it in PyTorch or another framework. I also believe you could just use some regex and try to find known names with pattern matching, which is easy to do with SpaCy. In SpaCy, this could look like this* Prepare your dataset TRAIN_DATA = [ ("m a j n e j m ɪ z s ʌ m i ɹ z o w ʃ i", {"entities": [(18, 38, "NAME")]}), # Add more examples... ] Add known cases as rules import spacy from spacy.matcher import PhraseMatcher import re # Initialize spaCy nlp = spacy.blank("en") # List of known names (for demonstration) known_names = ["Alice", "Bob", "Charlie"] # Convert the list of names into spaCy Doc objects patterns = [nlp.make_doc(name) for name in known_names] # Initialize the PhraseMatcher matcher = PhraseMatcher(nlp.vocab, attr="ORTH") # Add the patterns to the matcher matcher.add("KNOWN_NAMES", patterns) # Test text text = "Alice and Bob are friends, but Charlie is not." # Process the text with spaCy doc = nlp(text) # Use the matcher on the doc matches = matcher(doc) # Iterate over the matches for match_id, start, end in matches: span = doc[start:end] # The matched span print(span.text) Train a model import spacy from spacy.training import Example # Load a pre-existing spaCy model or create a blank one nlp = spacy.blank("en") # For example, start with a blank English model # Add the NER pipeline component if "ner" not in nlp.pipe_names: ner = nlp.create_pipe("ner") nlp.add_pipe("ner", last=True) else: ner = nlp.get_pipe("ner") # Add the new label to ner ner.add_label("NAME") # Start the training nlp.begin_training() # Training loop for itn in range(10): # Number of iterations random.shuffle(TRAIN_DATA) losses = {} for text, annotations in TRAIN_DATA: doc = nlp.make_doc(text) example = Example.from_dict(doc, annotations) nlp.update([example], drop=0.5, losses=losses) print(losses) Use your model doc = nlp("n y uː ɛ k s æ m p ə l") for ent in doc.ents: print(ent.text, ent.label_) *this is untested code, but it should be close enough to something that would work
