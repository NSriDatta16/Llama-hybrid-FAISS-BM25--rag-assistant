[site]: crossvalidated
[post_id]: 381724
[parent_id]: 381720
[tags]: 
I don't think there's a precise definition or an exhaustive list of local methods in data science. I bet that the term local ( nonlocal is the opposite) came either from physics or mathematics into what you call a data science. In physics local means that an object is influence only by its immediate surroundings. In the old days locality was restricted to a literal collision or some sort of hard connection between objects through some kind of a medium like ether . This was before the notion of forces such as gravity, and their modern understanding where there's no need for any medium at all, the fields go through vacuum too. So, today the meaning of locality in physics could be linked to the speed of information transfer. For instance, Earth and Moon interact still locally despite being somewhat far away. Here we mean that their movements are described by gravity force/field, and the disturbances would be passed along by speed of light, and, consequently proximity matters. Ceteris paribus, distant objects impact us less than objects in close proximity. This is very convenient, because although every object interacts with every other object in the universe through gravity force, you need to account for only a handful of bodies to calculate the trajectory of the satellites. Hence, by analogy the local method in data science would be those where you deal with immediate surroundings , whatever it means in the context. For instance, kernel methods would be one example. Here, although all observations go in, they are weighted by the distance to the given observation: farther the distance, the smaller is the weight. This way, we make the interactions local . Nearest neighbors methods are obviously quite local by construction. There are nonlocal phenomena in physics, where the disturbance would be transferred faster than the speed of light. For instance, entanglement in quantum mechanics can be interpreted as such.
