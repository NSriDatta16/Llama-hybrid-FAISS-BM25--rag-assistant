[site]: stackoverflow
[post_id]: 217589
[parent_id]: 217531
[tags]: 
It is typical for indexes to sacrifice insert speed for access speed. You can find that out from a database table (and I've seen these in the wild) that indexes every single column. There's nothing inherently wrong with that if the number of updates is small compared to the number of queries. However, given that: 1/ You seem to be concerned that your writes slow down to 5/ms (that's still 5000/second), 2/ You're only writing a few integers per record; and 3/ You're queries are only based on time queries, you may want to consider bypassing a regular database and rolling your own sort-of-database (my thoughts are that you're collecting real-time data such as device readings). If you're only ever writing sequentially-timed data, you can just use a flat file and periodically write the 'index' information separately (say at the start of every minute). This will greatly speed up your writes but still allow a relatively efficient read process - worst case is you'll have to find the start of the relevant period and do a scan from there. This of course depends on my assumption of your storage being correct: 1/ You're writing records sequentially based on time. 2/ You only need to query on time ranges.
