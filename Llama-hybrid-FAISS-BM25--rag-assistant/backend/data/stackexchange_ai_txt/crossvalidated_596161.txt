[site]: crossvalidated
[post_id]: 596161
[parent_id]: 568814
[tags]: 
In time series forecasting, we want to predict future values of the time series. And to do so, we normally have only its past values. To forecast using traditional machine learning models, like for example, a linear regression, we need to create input features that we can use to train those models. To create suitable input features, we use past values of the time series. We can create for example "lag features", which consist of simply using past values of the time series to predict future values. We can also create window features, which consist in applying aggregation operations, like the mean, max, std, etc, to windows of past data. We can use rolling windows, which have constant size, or expanding windows. I would use a rolling window when the data points closer to the point of forecast are more relevant to the forecast. If the data is too volatile, we could use larger rolling windows or expanding windows instead. Whether to use one or the other depends on the nature of the time series: seasonality, trend, also granularity and size. One approach would be to craft the features after data analysis. A second approach would be to just create lots of features, with various rolling windows and expanding windows, and then use feature selection to find the most suitable. Feature-engine has started to offer support for the automatic creation of rolling and expanding windows There are also some examples in this repo .
