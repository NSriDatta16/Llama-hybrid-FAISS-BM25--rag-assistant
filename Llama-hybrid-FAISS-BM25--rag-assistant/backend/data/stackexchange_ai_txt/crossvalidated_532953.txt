[site]: crossvalidated
[post_id]: 532953
[parent_id]: 
[tags]: 
How do i calculate the gradients for the bayes-by-backprop algorithm in R?

UPDATE - edits with my code progress are added at the end of this post. I'm trying to create a neural network in R based on the bayes-by-backprop model as described in this paper . As inspiration for the code i'm using the python description on this website . However, in this paper they use an autograd function and i'm trying to calculate the gradient manually. The important algorithm from the paper is this one: I think i've got most of the code ready, but i'm getting stuck on calculating the partial derivatives needed to calculate the gradients for mu (mean) and rho (parameter of the standard deviation). This is the backpropagation function that i'm trying to make. I'm trying to adapt it from a regular neural network that i created before. The parameters are: y = ground truth Wn = list, every entry represents a layer of the network, containing a sample of the probability distributions in that layor Un = list similar to Wn, the mus (mean) of the probability distributions in the posterior Rn = list similar to Wn, the rhos (parameter used to define the standard deviation) sigma = list similar to Wn, the standard deviation eps = list similar to Wn, the random variable that is used for the reparametrization trick ff = a list of the outputs of each feedforward layer, the last output is the model prediction. backpropagate How do i calculate the gradients of mu and rho? I can do partial derivatives on polynomial and exponential functions but mu and rho are defined here only as probability distributions. The loss function is defined as the $$posterior - prior * likelihood$$ but how do i take the derivative w.r.t. mu and rho of those? $$posterior = \log(P(w)) = \sum_i \log(N(w_i | \mu, \sigma^2)) $$ $$prior = \log(q(w|\theta)) = \sum_i \log(N(w_i | 0, 1)) $$ $$likelihood = \log(P(D|w)) = y * log(softmax(\hat{y})) $$ For reference: My main training function looks like this: train And then my feedforward plus helper functions: feedforward EDIT: here's the code that i've tried in Torch for R so far. I think i have everything correct up to the point where i need to calculate the posterior and prior for the loss function. I don't know how i can call the gaussian function in torch to generate the distributions for the posterior and the prior. For the posterior, i need to generate a distribution for every neuron with mean $\mu$ and standard deviation $\sigma$ , which are the parameters for each neuron. For the prior, i need to generate a distribution for every neuron with mean $0$ and standard deviation $1$ . The code is basically adapted from this page on the torch website. library(torch) ### generate training data ----------------------------------------------------- # input dimensionality (number of input features) d_in $mm(w1)$ clamp(min = 0) $mm(w2)$ clamp(min = 0) ### -------- Likelihood -------- likelihood $sum() if (t %% 10 == 0) cat("Epoch: ", t, " Loss: ", loss$ item(), "\n") ### -------- Backpropagation -------- # compute gradient of loss w.r.t. all tensors with requires_grad = TRUE loss$backward() ### -------- Update weights -------- # Wrap in with_no_grad() because this is a part we DON'T # want to record for automatic gradient computation with_no_grad({ mu1 $sub_(learning_rate * mu1$ grad) mu2 $sub_(learning_rate * mu2$ grad) rho1 $sub_(learning_rate * rho1$ grad) rho2 $sub_(learning_rate * rho2$ grad) # Zero gradients after every pass mu1 $grad$ zero_() mu2 $grad$ zero_() rho1 $grad$ zero_() rho2 $grad$ zero_() }) } EDIT2: This is the R code that i have right now, using torch. the log_gaussian function is copied directly from this website . I create 100 observations with 3 features, with a hidden layer of 32 neurons and a single output. the output is either 1 or 0. It seems to be working, but after 20 or so iterations the loss suddenly returns NaN and the network stops learning. I have some debugging still to do. library(torch) library(Rlab) ### generate training data ----------------------------------------------------- # input dimensionality (number of input features) d_in $exp()$ add(1) $log()$ multiply(eps1) $add(mu1) w12 exp() $add(1)$ log() $multiply(eps3)$ add(mu1) w2 $exp()$ add(1) $log()$ multiply(eps2) $add(mu2) w22 exp() $add(1)$ log() $multiply(eps4)$ add(mu2) b1 $exp()$ add(1) $log()$ multiply(beps1) $add(bmu1) b12 exp() $add(1)$ log() $multiply(beps3)$ add(bmu1) b2 $exp()$ add(1) $log()$ multiply(beps2) $add(bmu2) b22 exp() $add(1)$ log() $multiply(beps4)$ add(bmu2) ### -------- Forward pass -------- softmax $mm(w1)$ add(b1) $clamp(min = 0)$ mm(w2) $add(b2)) y_hat2 mm(w12) $add(b12)$ clamp(min = 0) $mm(w22)$ add(b22)) ### -------- Likelihood -------- likelihood $log()$ multiply(y) $sum() likelihood2 log() $multiply(y)$ sum() ### -------- Prior -------- prior1 $subtract(w1)$ square() $divide(2)$ subtract(torch_log(2*pi)) $sum() prior2 subtract(w2) $square()$ divide(2) $subtract(torch_log(2*pi))$ sum() prior3 $subtract(b1)$ square() $divide(2)$ subtract(torch_log(2*pi)) $sum() prior4 subtract(b2) $square()$ divide(2) $subtract(torch_log(2*pi))$ sum() prior $add(prior2)$ add(prior3)$add(prior4) prior12 $subtract(w12)$ square() $divide(2)$ subtract(torch_log(2*pi)) $sum() prior22 subtract(w22) $square()$ divide(2) $subtract(torch_log(2*pi))$ sum() prior32 $subtract(b12)$ square() $divide(2)$ subtract(torch_log(2*pi)) $sum() prior42 subtract(b22) $square()$ divide(2) $subtract(torch_log(2*pi))$ sum() priort2 $add(prior22)$ add(prior32)$add(prior42) ### -------- Posterior -------- posterior1 $subtract(mu1)$ square() $divide(s1$ square() $multiply(2))$ subtract(s1 $log())$ subtract(torch_log(2*pi)) $sum() posterior2 subtract(mu2) $square()$ divide(s2 $square()$ multiply(2)) $subtract(s2$ log()) $subtract(torch_log(2*pi))$ sum() posterior3 $subtract(bmu1)$ square() $divide(bs1$ square() $multiply(2))$ subtract(bs1 $log())$ subtract(torch_log(2*pi)) $sum() posterior4 subtract(bmu2) $square()$ divide(bs2 $square()$ multiply(2)) $subtract(bs2$ log()) $subtract(torch_log(2*pi))$ sum() posterior $add(posterior2)$ add(posterior3)$add(posterior4) posterior12 $subtract(mu1)$ square() $divide(s1$ square() $multiply(2))$ subtract(s1 $log())$ subtract(torch_log(2*pi)) $sum() posterior22 subtract(mu2) $square()$ divide(s2 $square()$ multiply(2)) $subtract(s2$ log()) $subtract(torch_log(2*pi))$ sum() posterior32 $subtract(bmu1)$ square() $divide(bs1$ square() $multiply(2))$ subtract(bs1 $log())$ subtract(torch_log(2*pi)) $sum() posterior42 subtract(bmu2) $square()$ divide(bs2 $square()$ multiply(2)) $subtract(bs2$ log()) $subtract(torch_log(2*pi))$ sum() posteriort2 $add(posterior22)$ add(posterior32)$add(posterior42) ### -------- compute loss -------- loss $subtract(prior)$ subtract(likelihood) $add(posteriort2$ subtract(priort2) $subtract(likelihood2)) if (t %% 10 == 0 | t item(), "\n") ### -------- Backpropagation -------- # compute gradient of loss w.r.t. all tensors with requires_grad = TRUE loss$backward() ### -------- Update weights -------- # Wrap in with_no_grad() because this is a part we DON'T # want to record for automatic gradient computation with_no_grad({ mu1 $sub_(learning_rate * mu1$ grad) mu2 $sub_(learning_rate * mu2$ grad) rho1 $sub_(learning_rate * rho1$ grad) rho2 $sub_(learning_rate * rho2$ grad) bmu1 $sub_(learning_rate * bmu1$ grad) bmu2 $sub_(learning_rate * bmu2$ grad) brho1 $sub_(learning_rate * brho1$ grad) brho2 $sub_(learning_rate * brho2$ grad) # Zero gradients after every pass mu1 $grad$ zero_() mu2 $grad$ zero_() rho1 $grad$ zero_() rho2 $grad$ zero_() bmu1 $grad$ zero_() bmu2 $grad$ zero_() brho1 $grad$ zero_() brho2 $grad$ zero_() })
