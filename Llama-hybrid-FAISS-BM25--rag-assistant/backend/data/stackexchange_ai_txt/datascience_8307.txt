[site]: datascience
[post_id]: 8307
[parent_id]: 8303
[tags]: 
This will depend on the type of task you want to perform: Object recognition is a wide task than can be approached in different ways such as: [Multi-part OR][1] [Multi-scale OR][2] Multi-class OR [Multi-label OR][4] [Multi-modal OR] Each approach (and its combinations) uses different representations for feature vectors extracted from the images. Most typical representations try to be invariant to certain conditions on the images depending on it purpose, such as scale, rotation and illumination changes. Some successful representations are: Bag of Visual Words [5] Histogram of visual words [8] Haar-like features [2] Statistical-based structures (Active shape models, active appearance models) [9][10] With the rise of deep networks, surprising results are being obtained feeding the images just as the raw pixels that represent them [6]. However, you will likely need hundreds of thousands of images to proper train a network that can abstract features to further recognize objects. You can actually take a look to the highly successful VGG Convolutional Network implementation at [Find actual links here][2] The previous approaches will typically required that you have each example labeled with target value (cat, dog, etc). In case of deep learning you are being able to learn first representation of images with unsupervised data (not labeled) and the being able to train a classifier on top of the network in a supervised way (with labeled data) You may find most of the references below at: [Google Scholar][3] [1]: [Xin Chen and Shen(2009)] Xiaohua Hu Xin Chen and Xiajiong Shen. Spatial weighting for bag-of-visual-words and its application in content-based image retrieval. Advances in Knowledge Discovery and Data Mining, 2009 [2]: [Viola and Jones(2004)] Paul Viola and Michael J. Jones. Robust realtime face detection. Int. J. Comput. Vision, 57(2):137–154, May 2004. ISSN 0920-5691. [4]: [Jia Deng and Fei-Fei(2014)] Jonathan Krause Michael Bernstein Alex Berg Jia Deng, Olga Russakovsky and Li Fei-Fei. Scalable multi-label annotation. ACM Conference on Human Factors in Computing Systems, 2014. [5]: [Xin Chen and Shen(2009)] Xiaohua Hu Xin Chen and Xiajiong Shen. Spatial weighting for bag-of-visual-words and its application in content-based image retrieval. Advances in Knowledge Discovery and Data Mining, 2009. [7]: [Krizhevsky et al.(2012)Krizhevsky, Sutskever, and Hinton] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In P. Bartlett, F.c.n. Pereira, C.j.c. Burges, L. Bottou, and K.q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 1106–1114. 2012. [8]: [Lowe(2004)] David G. Lowe. Distinctive image features from scaleinvariant keypoints. Int. J. Comput. Vision, 60(2):91–110, November 2004. [9]: [van Ginneken(2002)] A.F. Staal J.J. ter Haar Romeny B.M. van Ginneken, B.Frangi. Active shape model segmentation with optimal features. Medical Imaging, IEEE Transactions on. Volume 21, 2002. [10]: [Matthews and Baker(2004)] Iain Matthews and Simon Baker. Active appearance models revisited. International Journal of Computer Vision. Volume 60., 2004.
