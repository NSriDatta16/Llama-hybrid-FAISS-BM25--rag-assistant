[site]: stackoverflow
[post_id]: 2281159
[parent_id]: 
[tags]: 
how do i calculate the centroid of the brightest spot in a line of pixels?

i'd like to be able to calculate the 'mean brightest point' in a line of pixels. It's for a primitive 3D scanner. for testing i simply stepped through the pixels and if the current pixel is brighter than the one before, the brightest point of that line will be set to the current pixel. This of course gives very jittery results throughout the image(s). i'd like to get the 'average center of the brightness' instead, if that makes sense. has to be a common thing, i'm simply lacking the right words for a google search.
