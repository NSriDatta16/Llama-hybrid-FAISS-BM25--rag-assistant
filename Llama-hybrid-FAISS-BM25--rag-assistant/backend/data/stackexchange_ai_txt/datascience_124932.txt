[site]: datascience
[post_id]: 124932
[parent_id]: 124928
[tags]: 
I recently had a long argument with YOLO regarding a somewhat similar problem. In my case the application was product label classification and segmentation in order to feed particular line items from particular labels to an OCR script to turn into text. I found that more specific labels worked better than broader ones personally. Some labels I was working with have changed substantially over time, and I got much better performance when I segregated labels by brand and era, rather than just by brand. Now, this doesn't mean that will always be the case, or that it will be the case for you. One thing I think it helps to do is think about what a CNN is actually doing, in broad strokes, to get a result. Yolo is running your image through a matrix that is compressing it down into a series of feature vectors, which are then further compressed into fingerprint vectors used to classify regions of the image. You want to clump images into classes so that the features they return will be 1) similar and 2) meaningful. The trade off you want to make between those two parameters is dependent on your application. In my case, I was looking at logos and text printed on paper. Even if two labels represented the same company at different times in history, that didn't matter to the neural network if their logos and fonts had changed so much as to have no meaningful connection to one another in terms of image features. It could still deal with them, since it will still train in both sets of features during the training process, but it worked better when these very different labels were in their own classes. On the other hand, if I were trying to build something to classify dog breeds or edible plants or something, well then I would have a massive amount of variation within each class pretty much no matter how I split them up and what I really care about is that the classification it returns is meaningful, so I would just need to make my classes eat that diversity and provide enough data to match. It kind of seems like your case might be closer to the latter, but I'm not sure exactly what you are trying to do and so can't be sure. I do want to point out one other possible technique that might be useful, just in case it applies to your situation. So, if you are just trying to classify the broad categories of things taken out of a given store, then splitting them into classes like "bottle", "can", etc. is a good way to go. However, the way this is written makes me think that what you might really want to do is identify things on a product level, but it isn't feasible to train a neural net with 100,000 classes, so you are trying to find a way to clump things together. If that is the case, I would actually recommend something more unsupervised that can get you to that product level classification. Something like that I've done involved taking a pretrained neural network and then chopping off the classification layer to turn it into a vectorizer, then running my whole dataset through that vectorizer and clustering the resultant vectors using k-means, using the clusters as classes that I would train on. Then I would periodically re-cluster and retrain until I was confident that the thing had learned the features needed to work with my data. The classes didn't actually matter. Instead, I ran stock images of every product I wanted to identify through the trained vectorizer, hashed the resultant vectors using Random Hyperplane Projection, and then could compare new product images that popped up in production to that hash table to get it's nearest matches, comparing the full images in this smaller neighborhood to get a more accurate match if necessary or just returning the images represented by the closest hashes. In this way, I can actually take a picture of something, and then get a match to a specific product out of hundreds of thousands of them without needing to train a neural network on hundreds of thousands of classes. That last bit may have been totally useless to you, but I ran down a bunch of blind alleys building my product matcher where I was trying to use a classifier to narrow down options and none of them ended up panning out great because I didn't actually care about the classes so other solutions worked better but I was sort of in a "when the only tool you have is a hammer" situation, so when it seemed like there was a possibility that a similar road was being tread here, I wanted to suggest a possible alternate solution if classification isn't really what you are ultimately after.
