[site]: crossvalidated
[post_id]: 397190
[parent_id]: 397129
[tags]: 
A 100% accuracy on the training set may be a sign of a gross error in modeling process, not just of overfitting, but that depends on the model/algorithm used in training. Namely, predicting with a random forest classifier on the training set will give you a 100% accuracy, but that's because of RF's inner working. In this case 'fitted' values are exactly the same as the response, but that's not a problem. On the other hand if your stats linear regression model, for example, had fitted values all the same as the data points, that would be a definitive sign of gross overfitting. To answer your second question through an example -- assume your first method is a random forest (100% and 75% accurate on training and test sets, respectively) and the second method is logistic regression model (65% / 65% accuracy) -- then using RF over logistic regression would be justified.
