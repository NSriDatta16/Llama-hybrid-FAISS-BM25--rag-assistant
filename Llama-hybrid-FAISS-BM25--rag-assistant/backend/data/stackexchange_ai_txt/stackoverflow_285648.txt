[site]: stackoverflow
[post_id]: 285648
[parent_id]: 285614
[tags]: 
Surely this is a prime case for wrapping up into a procedure and using two sql statements - the first to select the latest ID and subtract 20,000, then the second to delete all rows with ID's lower than this. However it does on the face of it sound like you're going to end up with a lot of fragmentation going with this approach and that might be a good argument for creating a new table, inserting the latest 20,000 records into it, deleting the old one and renaming the new. It might even be worthwhile putting the table in a different database and creating a view from your main database to facilitate access. Myself I generally tend to do this with tables used for data load and audit. It's very difficult to tell without knowing your actual data volumes and behavior, but it could well be that globally your inefficiencies will arise more from this than the delete method you use. If you're only collecting a thousand or less records a day then a delete is probably ok combined with running a data optimization maintenance plan, but more and I'd be looking at the more drastic approach.
