[site]: crossvalidated
[post_id]: 589548
[parent_id]: 589545
[tags]: 
In most cases regression models only include a SINGLE dependent/outcome variable. You can include any number of independent variables (binary or continuous) but each model can only "predict" a single thing. All of that is true regardless of what type of model you are using. The different "flavors" of models are designed to analyze different types of dependent variables: you use a logit if the dependent variable is binary, an OLS if it is continuous and more or less normally distributed, a tobit model if it is continuous but censored etc. There are "multivariate" regression models that include more than one dependent variable (an example in Stata here ). However, these methods may be more complicated than what it sounds like you have in mind - especially if the different outcomes variables are not all on the same scale. The simplest option would just be to run a separate model on each outcome, and choose the right model for the job each time. For likert scale items (e.g. "not at all, a little, somewhat, very much") use an ordered logit model and for binary ones use a binary logit model. It might be that different things predict different outcomes. An alternative would be to try and COMBINE a set of outcomes into a single dependent variable, which could then be predicted using a single regression model. But if you want to do this you really want to first confirm that all of the observed variables are all measuring the same underlying construct, like "intelligence" (this could be done via factor analysis or PCA). Once you have done that then you could combine the variables in some way (either with a simple average, or by generating factor scores from the factor analysis, or some other method) to create a new (continuous) variables that could then be used as the dependent variable in an OLS model. However, if some of those variables are binary and others are continuous then you can't just compare them in a factor analysis or average them together, because they are on different scales. One solution to that problem might to be to take the z-score of all the items before averaging them together. A simpler approach would be to dichotomize the ordinal items first, but this involves throwing away useful data. There are various complications involved here...
