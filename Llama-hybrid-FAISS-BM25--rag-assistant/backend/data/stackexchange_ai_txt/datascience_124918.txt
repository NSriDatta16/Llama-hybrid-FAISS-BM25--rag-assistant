[site]: datascience
[post_id]: 124918
[parent_id]: 124906
[tags]: 
The sort of deep neural networks most commonly referred to today as "AI" are going to be of limited use on something like a rover. When you are programming a rover, your software needs to be 1) reliable and 2) lightweight, neither of which modern "AI" models really are. Any mistake that a rover makes needs to be completely comprehensible. You need to be able to work back through the processes it used to make that decision and figure out exactly where it went wrong, and you need to be able to stick as much as possible onto the relatively sparse hardware present on the rover. However, there are a couple of caveats to this. The first is that neural nets aren't the end all and be all of AI, and if you want to work in fields like image and signal processing, you need to also understand the more basic methods used to do things like extract information from an image. In a professional context, even if you are working with neural nets, these methods still need to be used in conjunction with them to do anything cool anyway. The solution to a problem is rarely "feed the data into a neural net and swirl it around until it does something useful". You usually need to employ a bunch of additional optimization and feature selection techniques alongside your pretty dense matrix. And when it comes to these sorts of things, rovers (and pretty much any robotics application) will use them too, whether there is a neural net to be found or not. The rover has cameras mounted on it, for instance, and it needs to be able to use the inputs coming in from those cameras to "see". This means identifying objects of interest, stitching images together to extend its field of view and provide it with depth perception, and figuring out where obstacles are, among numerous other tasks. All this stuff uses GOFAI (Good Old Fashioned AI), and the techniques involved remain foundational to robotics as well as to more modern AI techniques. Looking into the techniques behind these sorts of basic computer vision tasks might be an interesting start if you have an interest in robotics. Mess around with convolution filters to isolate an object, like a coin or baseball card, in an image. Look into feature selection algorithms like SIFT, ORB, and BRIEF, and use that information to stitch two images of an object from different angles into a panorama. Maybe try taking those feature vectors and applying a technique like Locality Sensitive Hashing to them, and then using those hashes to return a neighborhood of images most similar to a given query image. All these sorts of techniques are used by everything from the Mars Rover to your Roomba to find their way around a space, figure out what's in front of them, and keep from bumping into things, and they are also used by AI algorithms to do things like give you song suggestions on Spotify or find your face in order to put a duck bill on it on Tik Tok. The second caveat is that, while I doubt AI will be on rovers any time soon, I am sure it's already finding applications in mission control. Back on earth where you have limitless processing power and memory, it would be about as silly not to employ AI as it would be to employ it on the limited hardware of a Rover stranded on mars. These applications are likely similar to other data science applications, and if you are interested in this sort of thing I'd say go play around on kaggle. Whatever you decide to play with will end up being useful.
