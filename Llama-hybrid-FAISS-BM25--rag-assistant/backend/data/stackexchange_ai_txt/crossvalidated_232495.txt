[site]: crossvalidated
[post_id]: 232495
[parent_id]: 232356
[tags]: 
Really interesting question! I'd put myself in the frequentist camp when it comes to understanding and interpreting probability statements, although I am not quite so hard-line about the need for an actual sequence of iid experiments to ground this probability. I suspect most people who don't buy the thesis that "probability is a subjective measure of belief" would also think about probability this way. Here's what I mean: take our usual "fair" coin, with assignment $P(H)=0.5$. When I hear this, I form an image of someone tossing this coin many times and the fraction of heads approaches $0.5$. Now, if pressed, I would also say that the fraction of heads in any random sample from a finite sequence of such coin tosses will also approach $0.5$ as the sample size grows (independence assumption). As has been stated by others, the biggest assumption is that this limit exists and is correct (i.e., limit is $0.5$), but I think just as importantly is the assumption that the same limit exists for randomly chosen sub-samples as well. Otherwise, our interpretation only has meaning wrt the entire infinite sequence (e.g., we could have strong autocorrelation that gets averaged out). I think the above is pretty uncontroversial for frequentists. A Bayesian would be more focused on the experiment at hand and less on the long run behavior: they would state that their degree of belief that the next toss will be heads is $P(H) = 0.5$...full stop. For a simple case such as coin tossing, we can see that the frequentist and Bayesian approaches are functionally equivalent, albeit philosophically very different. As Dikran Marsupial has pointed out, the Bayesian may in fact be utilizing the fact that empirically we see coins come up heads about as often as we see them come up tails (long run/large sample frequency as a prior). What about things that cannot possibly have long run frequencies? For example, what is the probability North Korea will start a war with Japan in the next 10 years? For frequentists, we are really left in the lurch, since we cannot really describe the sampling distributions required to test such a hypothesis. A Bayesian would be able to tackle this problem by placing probability distribution over the possibilities, most likely based on eliciting expert input. However, a key question comes up: where do these degrees of belief (or assumed value for the long run frequency) come from? I'd argue from psychology and say that these beliefs (especially in areas far from experimental data) come from what is referred to as the availability heuristic and representativness heuristic . There are slew of others that likely come into play. I argue this because in the absence of data to calibrate our beliefs (towards the observed long run frequency!), we must rely on heuristics, however sophisticated we make them seem. The above mental heuristic thinking applies equally to Frequentists and Bayesians. What is interesting to me is that regardless of our philosophy, at the root, we place more belief in something that we think is more likely to be true, and we believe it to be more likely to be true because we believe there are more ways for it to be true, or we imagine that the pathways leading to it being true would happen more often (frequently:-) than those that would make it not true. Since it's an election year, let's take a political example: What belief would we place in the statement "Ted Cruz will propose a ban assault rifles in the next 4 years". Now, we do have some data on this from his own statements, and we'd likely place our prior belief in the truth of this statement very near zero. But why? Why does his prior statements make us think this way? Because we think that highly ideological people tend to "stick to their guns" more than their pragmatist counterparts. Where does this come from? Likely from the studies done by psychologists and our own experiences with highly principled people. In other words we have some data and the belief that for most cases where someone like Cruz could change their mind, they will not (again, a long-run or large-sample assessment of sorts). This is why I "caucus" with the frequentists. It's not my dislike of Bayesian philosophy (quite reasonable) or methods (they're great!), but that if I dig deep enough into why I hold beliefs that lack strong large-sample backing, I find that I am relying on some sort of mental model where outcomes can be tallied (if implicitly) or where I can invoke long-run probabilities in a particular sub-process (e.g., Republicans vote against gun control measures X% of the time) to weight my belief one way or another. Of course, this not really true frequentism, and I doubt that there are many people who subscribe to the von Mieses-esque interpretation of probability to the letter. However, I think it shows the underlying compatibility between Bayesian and Frequentist probability: Both are appealing to our inner heuristics regarding availability or what I call the "Pachinko" principle about frequencies along a chain of causation. So perhaps I should call myself an "availabilist", to indicate that I assign probabilities based on how often I can imagine an event occurring as the outcome of a chain of events (with some rigor/modelling of course). If I have a lot of data, great. If I don't, then I will try to decompose the hypothesis into a chain of events and use what data I have (anecdotal or "common sense", as need be) to assess how often I would imagine such an event to occur. Sorry for the longish post, great question BTW!
