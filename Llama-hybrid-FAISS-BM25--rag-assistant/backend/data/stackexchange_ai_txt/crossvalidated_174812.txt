[site]: crossvalidated
[post_id]: 174812
[parent_id]: 8000
[tags]: 
Another possibility are Historical Consistent Neural Networks (HCNN) . This architecture might be more appropriate for the above mentioned setup because they eliminate the often arbitrary distinction between input- and output-variables and instead try to replicate the full underlying dynamics of the whole system via training with all observables. When I was working for Siemens I published a paper on this architecture in a book by Springer Verlag: Zimmermann, Grothmann, Tietz, von Jouanne-Diedrich: Market Modeling, Forecasting and Risk Analysis with Historical Consistent Neural Networks. Just to give an idea about the paradigm here is a short excerpt: In this article, we present a new type of recurrent NN, called historical consistent neural network (HCNN). HCNNs allow the modeling of highly-interacting non-linear dynamical systems across multiple time scales. HCNNs do not draw any distinction between inputs and outputs, but model observables embedded in the dynamics of a large state space. [...] The RNN is used to model and forecast an open dynamic system using a non-linear regression approach. Many real-world technical and economic applications must however be seen in the context of large systems in which various (non-linear) dynamics interact with each other in time. Projected on a model, this means that we do not differentiate between inputs and outputs but speak about observables. Due to the partial observability of large systems, we need hidden states to be able to explain the dynamics of the observables. Observables and hidden variables should be treated by the model in the same manner. The term observables embraces the input and output variables (i. e. $Y_τ := (y_τ, u_τ)$ ). If we are able to implement a model in which the dynamics of all of the observables can be described, we will be in a position to close the open system. ...and from the conclusion: The joint modeling of hidden and observed variables in large recurrent neural networks provides new prospects for planning and risk management. The ensemble approach based on HCNN offers an alternative approach to forecasting of future probability distributions. HCNNs give a perfect description of the dynamic of the observables in the past. However, the partial observability of the world results in a non-unique reconstruction of the hidden variables and thus, different future scenarios. Since the genuine development of the dynamic is unknown and all paths have the same probability, the average of the ensemble may be regarded as the best forecast, whereas the bandwidth of the distribution describes the market risk. Today, we use HCNN forecasts to predict prices for energy and precious metals to optimize the timing of procurement decisions. Work currently in progress concerns the analysis of the properties of the ensemble and the implementation of these concepts in practical risk management and ﬁnancial market applications. The paper is now finally available in full here: Zimmermann, Grothmann, Tietz, von Jouanne-Diedrich: Market Modeling, Forecasting and Risk Analysis with Historical Consistent Neural Networks .
