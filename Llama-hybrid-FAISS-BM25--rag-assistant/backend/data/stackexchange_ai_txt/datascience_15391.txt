[site]: datascience
[post_id]: 15391
[parent_id]: 15314
[tags]: 
I am staying quite generic since you asked for enlightenment, just mentioning some possible directions that you can explore. You have basically two possibilities: Classification of the text (Supervised learning). Supervised means that you need first to externally apply labels (for example manually by humans) to examples of texts (labels could be "politics" or "show") and then use one of the classification algorithms. You have extracted words from the text, so you could use a "bag of words" approach for classifying. There exist adaptations of classification algorithms (multi-label classification) in order to provide multiple labels (such as one text is labelled both with "music" and "movie"). You can find text corpora already pre-labelled, to train the algorithm and partly avoid the manual effort. Clustering the text, topic modelling (unsupervised learning). In this case you do not need to provide examples with labels but the algorithm will cluster the texts according to parameters like the similarity of two texts or on keywords/topics extracted from the texts. Although this method do not require labeled examples, the clusters you get as output will require fine tuning, e.g. number of clusters to produce, names of the clusters, etc. Since you mentioned SKlearn, you can find some directions on their web site: Text Feature Extraction . Here is a comprehensive (bit older) summary: Machine Learning in Automated Text Categorization by Fabrizio Sebastiani
