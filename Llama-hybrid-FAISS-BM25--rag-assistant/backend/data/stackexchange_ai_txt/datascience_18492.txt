[site]: datascience
[post_id]: 18492
[parent_id]: 18488
[tags]: 
I stumbled upon some rules of thumb for dataset sizes, but not specific to the ratio of features / samples. Also, it seems easier to guess to the "positive" side, i.e. "might it work?" then "might it fail?". I witnessed both small datasets ( The stage in the processing pipeline to tackle this, is the feature selection one. I'd start with gathering all of your make-sense features and playing with different k-best values for the feature selection object to find. (ranges like: 10, 50, 100, ..) You didn't mention a specific research environment, but I'd like to suggest scikit-learn sklearn.feature_selection.SelectKBest running inside a GridSearchCV pipeline. This way the grid object will help you choose the closest k-best featues out of a given list. Something like: from sklearn.feature_selection import SelectKBest from sklearn.pipeline import make_pipeline from sklearn.model_selection import GridSearchCV from sklearn.svm import LinearSVC pipe = [] pipe.append(SelectKBest()) pipe.append(LinearSVC()) est_pipe = make_pipeline(*pipe) print 'all possible grid params: {0}'.format(est_pipe.get_params().keys()) param_grid = { # some svc grid params.., 'selectkbest__k': [5, 10, 50, 100] } grid = GridSearchCV(est_pipe, param_grid=param_grid) grid.fit(X, y)
