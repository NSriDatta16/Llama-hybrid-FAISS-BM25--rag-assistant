[site]: crossvalidated
[post_id]: 371427
[parent_id]: 
[tags]: 
Convergence of predictions of an autoregressive model

I have performed a simple autogregressive model with lag 2 on a time series data. After obtaining the coefficients, I have computed the predictions. Since the lag is 2 in model, the first prediction $\hat{y}$ is computed using the last 2 available data, i.e. $\hat{y}_1 = \theta_0 + \theta_1 y_{-1}\theta_2 y_{-2}$ , where $y_{-1}$ and $y_{-2}$ are the last two observations and $\theta$ are the parameters. The second prediction is computed as $\hat{y}_2 = \theta_0 + \theta_1\hat{y}_1 + \theta_2 y_{-1}$ , and so on so forth. After 2 steps, I am no longer using known data to compute the predictions $\hat{y}$ , i.e. I only used the previously computed predictions. I have performed a simple analysis on Excel and I saw that the predictions converge to a certain value. Why is this happening? To which value are the predictions converging? It does not seem to be a simple mean of the coefficients. Moreover, even if I change the initial known data (i.e. $y_{-1}$ and $y_{-2}$ ) the predictions still converge to the same value. What I don't get is why are AR models used if after very few steps they converge to a certain value; this prediction is not realistic nor useful. Or am I making a huge mistake somewhere? You can find a screenshot of my excel sheet. The green colored values on cells B2 and B3 correspond to the known data, the other values on the B columns are the predictions $\hat{y}$ . The values on the B Column are computed as $A\$2*B2+\$A\$3*B3+\$A\$4
