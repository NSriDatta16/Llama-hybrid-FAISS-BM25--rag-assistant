[site]: datascience
[post_id]: 42230
[parent_id]: 42217
[tags]: 
Without further details, my guess is that your dataset is unbalanced (not the same number of samples in both classes), so that duplicating the data increases the # samples in the most represented class. Depending on how you configured the Random Forest, it may aim at predicting correctly the most represented class and have less concern about the under represented one. In this case, by duplicating the dataset, you put even more pressure on predicting the most represented class and that's what it does, thus increasing accuracy. As a note, I believe this would not happen if you were training on a dataset and testing on a different one (samples of the test set, on which you assess performance, should be different from the ones in the train set).
