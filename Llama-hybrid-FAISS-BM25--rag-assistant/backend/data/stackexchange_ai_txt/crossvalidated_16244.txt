[site]: crossvalidated
[post_id]: 16244
[parent_id]: 16194
[tags]: 
Within the value-function approximation model (which you've adopted?), you can opt to use a compressed encoding of the state-action space instead of a tessellation. Neural networks are sometimes used for this purpose. What you might try with the critic is to use a supervised clustering algorithm over all states which were recently fed to the actor with the actions as the classes. You could then plunk a new state-action pair into the clustering model. If it flops down in the middle of a pure cluster, and is of the wrong class, it's worth training on. If it's of the right class, you can probably skip it. If it's in an impure cluster, or significantly outside of any dense cluster, probably keep it.
