[site]: stackoverflow
[post_id]: 1567433
[parent_id]: 1567335
[tags]: 
1) Make your own web crawler ? looks like you can easily use all your available time just for this task. Try using a standard solution for that : it's not the heart of your program. You still will have the opportunity to make your own or try another one afterwards (if you have time left !). Your program should work only on local files so as not to be tied to a specific crawler/API. Maybe you'll even have to use different crawlers for different sites 2) Hashing whole paragraphs is possible. You can just hash any string. But of course that means you can only check for whole paragrpahs copied exactly. Maybe sentences would be a better unit to test. You probably should "normalize" (tranform) the sentences/paragrpahs before hashing to sort out minor differences like uppercase/lowercase. 3) MySQL can store a lot of data. The usual advice is : stick to standard SQL. If you discover you have way too much data you will still have the possibility to use another SQL implementation. But of course if you have too much data, start by looking at ways to reduce it or at least to reduce what's in mySQL. for example you could store hashes in MySQL but original pages (if needed) in plain files.
