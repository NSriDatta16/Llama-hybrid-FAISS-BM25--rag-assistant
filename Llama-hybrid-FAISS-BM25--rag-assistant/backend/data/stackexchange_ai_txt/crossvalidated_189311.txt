[site]: crossvalidated
[post_id]: 189311
[parent_id]: 
[tags]: 
random forest case sampling strategy for model with maximum positive predictive value

I want to create a binary classifier that gets as many true positives with the lowest possible false positive rate. False negatives and true negatives dont matter, just the false positive rate has to be minimized. lets assume I have a dataset of n = 100.000 10.000 positives 90.000 negatives what sampling strategy will most likely get me the best model for my needs? e.g. just regular sample (10% positives) 50% positives 90% positives 10% negatives Or is this the wrong approach and I should think about weighting the positive cases more?
