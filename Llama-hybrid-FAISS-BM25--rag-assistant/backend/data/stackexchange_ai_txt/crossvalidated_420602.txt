[site]: crossvalidated
[post_id]: 420602
[parent_id]: 
[tags]: 
Comparing residual deviance to null deviance in a logistic regression model: Is percentage reduction fallacious?

If I run a logistic regression model in R...for example summary(glm(data, formula = dichotomous.outcome.variable ~ age + hpv,family = binomial(link = "logit"))) I get an output such as this Null deviance: 142.18 on 417 degrees of freedom Residual deviance: 112.42 on 415 degrees of freedom (1 observation deleted due to missingness) AIC: 118.42 Number of Fisher Scoring iterations: 9 Is there any value to looking at (142.18-112.42)/142.18 = 0.21? Could one say, "The intercept represents the baseline model where it simply predicts for every case, the baseline probability. So if 5% were TRUE then it simply predicts 5% chance for every case. Or put differently, since only 5% were TRUE, the baseline model could predict that every case was FALSE and it would only be wrong 5% of the cases?" Now we come along with our best model. Can we say, "Our model explains 21% of the variability"? Is there great value, little value or zero value (or maybe even dangerously contradictory value) to looking at the percent reduction of the null deviance? Please disavow me of any misconceptions that I may harbor.
