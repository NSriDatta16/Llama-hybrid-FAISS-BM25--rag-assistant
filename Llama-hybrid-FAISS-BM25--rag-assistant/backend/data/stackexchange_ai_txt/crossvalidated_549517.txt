[site]: crossvalidated
[post_id]: 549517
[parent_id]: 
[tags]: 
Is it "sound" to use a class-wise sigmoid as the confidence score for neural network outputs?

I've read a few papers and blog posts regarding confidence and calibration but I still don't fully understand how the "confidence score" is obtained in the first place and am under the impression that people usually use the softmax function. Rather than that I'm curious if I could simply take the class-wise sigmoid output and use that as a confidence measure. I don't believe I've seen this before (if I'm wrong feel free to point it out) and have mostly only seen the softmax being used - which is also apparently not sound. Edit Here's an example of what I mean. Let's say that I have a multiclass classification problem with three classes. Let's also say that the output logits from my neural network are [-0.2312, 0.5667, 0.1234] . Taking the softmax of these logits would result in [0.2152, 0.4780, 0.3068] . What I mean is to use the sigmoid function for each class's logit, which would result in [0.4425, 0.6380, 0.5308] . If I were to only keep the "most confident" predictions and set the threshold at 0.5, then using the softmax would result in not selecting anything where the sigmoid case would select class 2 and 3. I'm wondering if the latter (i.e., the sigmoid method) is valid and even heard of.
