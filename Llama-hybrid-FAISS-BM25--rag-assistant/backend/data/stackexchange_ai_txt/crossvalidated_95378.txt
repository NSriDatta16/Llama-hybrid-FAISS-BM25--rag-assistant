[site]: crossvalidated
[post_id]: 95378
[parent_id]: 
[tags]: 
Logistic Regression in R - Steps and Output

I am doing statistics for the first time in my life and I am not quite sure what to include and how to interpret the results. I am doing a logistic regression in R. Here is what I have so far: GLM with family = binomial (dependent ~ indep1 + indep2 + ...+ indep7 +0) If I dont include the 0 I get NA for my last independent variable in the summary output.. Update the model (indep2 has a p-value > 0.05 and is left out) I am applying anova anova(original_model,updated_model, test="Chisq") Resid.Df Resid.Dev Df Deviance Pr(>Chi) 1 34067 18078 2 34066 18075 1 2.4137 0.1203 Here I am not sure how to interpret it. What tells me if the simplification of the model is significant? the p-value is with 0.12 bigger than 0.05, does this mean that the simplification is not significant? make a cross-table (compare predicted (probability >0.5) - observed) fit FALSE TRUE No 30572 68 yes 3407 31 I'd say that 31 values are predicted correctly (yes-true), resp 68 (no-true) but that most values are classified wrong, which means that the model is really bad? then I make a wald test for each independent variable for the first independent variable it would look like this: > wald.test(b = coef(model_updated), Sigma = vcov(model_updated), Terms > = 1:1) here I only look if the p-values are significant and if they are it means that all variables contribute significantly to the predictive ability of the model I calculate the odds with their confidence intervals (this is basically exp(estimate) oddsCI For all odds smaller than 1 i do 1/odd Estimate Odds Ratio Inverse Odds -0.000203 0.999801041 1.000198999 0.000332 1.000326571 odd bigger than 1 -0.000133 0.999846418 1.000153605 -3.48 0.008696665 114.9866056 -4.85 0.029747223 33.61658319 -2.37 0.000438382 2281.113996 -8.16 0.110348634 9.062187402 -2.93 0.062668509 15.95697759 -3.65 0.020156889 49.61083057 -5.45 0.033996464 29.41482359 -4.02 0.004837987 206.6975334 This O would interpret like that for the "odd bigger than 1" the case is over 1 times more likely to occur. (Is is incorrect to say that, or not?) Or for the last row you could say that t for every subtraction of a unit, the odds for the case to appear decreases by a factor of 206. Then I look at with(model_updated, null.deviance - deviance) #deviance with(model_updated, df.null - df.residsual) #degrees of freedom # pvalue with(Amodel_updated, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)) logLik(model_updated) But I don't really know what this tells me. In a last step I do stepAIC(model_updated, direction="both") but also here I don't know how to interpret the outcome. I see that it looks at all interactions between my independent variables but I don't know what it tells me. After this, I can make a prediction by using the updated model and by separating it into training data and validation data I suppose?
