[site]: crossvalidated
[post_id]: 238016
[parent_id]: 
[tags]: 
deep learning - word embedding with parts of speech

I'm building a sentence classifier with a Convolutional Neural Network (CNN) architecture. I would like to do the word embedding outside of my CNN using a pre-trained model such as GoogleNews (which is based on word2vec). I'm wondering if it is worthwhile to add part-of-speech information to this model and if so, how? I see the following options: Use just word2vec to embed words into 300-features vectors Use two channels in my CNN - one for word2vec and one for part-of-speech tag. Do I have to then embed the part of speech tag into 300 features too? Embed the part-of-speech tag to some other number of features (say 20 features) and concatenate this 20-feature vector to the word2vec vector (resulting with 320-feature vectors) If #2 or #3 are preferable, which methods are available to embed a POS tag to a vector representation?
