[site]: crossvalidated
[post_id]: 325818
[parent_id]: 
[tags]: 
What is the standard definition of a non-parametric machine learning algorithm?

According to my experience, the non-parametric term usually refers to algorithms complying the following definition from a clasic textbook [1]: A learning model that summarizes data with a set of parameters of fixed size (independent of the number of training examples) is called a parametric model. No matter how much data you throw at a parametric model, it wonâ€™t change its mind about how many parameters it needs. Under this definition, algorithms like PCA, LogisticRegression and Linear SVMs are parametric, while k-NN is non-parametric. However, I recently met some researchers specialized in the field of dimensionality reduction, and for them the term non-parametric refers to an algorithm which cannot be applied on test samples without retraining the whole model (e.g., t-SNE). My questions are: 1) Are these two definitions compatible or connected somehow, or they just refer to different and unrelated aspects of algorithms? 2) Are you aware of a formal reference (e.g., textbook or paper) for the second definition of non-parametric algorithms? [1] Russell, S. J., Norvig, P., Canny, J. F., Malik, J. M., & Edwards, D. D. (2003). Artificial intelligence: a modern approach (Vol. 2, No. 9). Upper Saddle River: Prentice hall. (page 737)
