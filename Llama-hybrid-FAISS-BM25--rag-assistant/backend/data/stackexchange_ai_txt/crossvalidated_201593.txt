[site]: crossvalidated
[post_id]: 201593
[parent_id]: 
[tags]: 
Can a Piecewise Linear Regression Approximate a Neural Network?

I have a piecewise linear regression model that performs quite well (CVd) on subsets of a small data set (Ns between 30 and 90 for the subsets, with a total of 222 records). So there are separate models for each subset of the records -- with different variables in each, and different weights for variables that appear in multiple models. In addition, the original variables were segmented into sub-variables using loess plots and familiarity with the data. (This was done intuitively -- I didn't discover piecewise linear regression or the related R packages until recently. I expect the results may be improved by more precise segmentation.) Anyhow, neural nets could do absolutely nothing with the data. (Possibly due to the # of weights vs the sample sizes?) So what I'm trying to get my head around is whether my model (the four sub-models considered as a whole), with localized variable selection and localized variable weights, represents an approximation of what a neural network might find if there were enough data to build a good one? Or is that the wrong way to think about what's happening? In other words, how is subsetting the records and segmenting the variables like/not like a neural network? I apologize if my terms are loose or vague -- as I'm sure is apparent I'm not a statistician.
