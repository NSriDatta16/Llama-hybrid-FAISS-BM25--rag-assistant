[site]: datascience
[post_id]: 115545
[parent_id]: 
[tags]: 
"Inverted" correlation of the amount of the loan and the probability of default

My task is to make a machine learning model for predicting the probability of default when taking a loan (binary classification). But I also want to predict the loan amount. Something like: if the client is very good, then you can give him more money than we usually give. Now the amount is billed based on experience and intuition by the loan portfolio analysts. The problem with adding the "loan amount" feature to the model and training it again is that historically we have given more money to clients who had a low probability of default. Something like: group max Probability of default max money 1 0.05 100 2 0.1 50 3 0.15 25 4 1 0 (reject) Because of this, the model will observe an 'inverted' correlation. The more money, the more likely the customer will pay back! Although the real situation is exactly the opposite. The more money we give the client, the less likely he is to pay it back, so only good clients should be given large sums. Can you advise me how to correct this situation, what area of scientific knowledge should be studied, what A/B tests should be performed?
