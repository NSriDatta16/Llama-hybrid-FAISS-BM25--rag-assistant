[site]: crossvalidated
[post_id]: 365472
[parent_id]: 365467
[tags]: 
Your problem is probably that the data you are trying to use for prediction (youtube audio and data recorded by you) comes from a quite different distribution then the data on which the algorithm was trained and evaluated. It can be caused by using different microphone, people talking different dialect or audio can contain sounds that didn't appear in trainset nor devset. The data in your dev/test set should always be as close as possible to the data you care about (in your case probably sounds recorded by you). Otherwise your dev/test set doesn't tell you accurately how your algorithm will perform in your task. If possible the same should be for your trainset, but you usually don't have so much data and it helps to add to trainset every data you can get from other datasets. You can read more about this problem in chapter 6 of Machine Learning Yearning book by Andrew Ng.
