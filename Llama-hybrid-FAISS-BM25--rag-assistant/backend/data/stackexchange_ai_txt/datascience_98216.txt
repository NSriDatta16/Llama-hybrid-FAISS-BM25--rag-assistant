[site]: datascience
[post_id]: 98216
[parent_id]: 98189
[tags]: 
It seems very complex to me to give you a correct size of batch, time of sending and memory, because very high frequency problems depends on every small operation in the algorithm you use to detect anomalies. In addition to that, I don't know if the anomaly could be detected on a single or a multiple set of values (or both), and the minimum range of values to detect an anomaly. But you can easily define those limits by starting by quite simple anomaly detection algorithms that doesn't require lot of calculations, like autoregressive models, ideally autoregressive integrated moving average models (ARIMA). Those algorithms would help you defining the right parameters and the best batch size based on their prediction quality.
