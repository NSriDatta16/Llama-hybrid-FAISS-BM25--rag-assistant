[site]: crossvalidated
[post_id]: 510637
[parent_id]: 510621
[tags]: 
Based on your comment, the probability distribution of the source symbols $1,2,3,4,5,$ and $6$ is: $$ p(x) = \begin{cases} \frac{1}{8}, & x = 1,2,3,4 \\ \frac{2}{8}, & x = 5,6 \end{cases} $$ Two types of source codes that you can construct are fixed-length source codes and variable-length source codes. The one that you listed in your question is an example of a fixed-length source code. An advantage of fixed-length source codes is that they will always be uniquely decodable. In other words, if you concatenate any combination of the codewords together, you will always be able to decode them back into source symbols. In the case of fixed-length source codes, you can do this since you already know that all codewords will be of the same length. However, they are generally less efficient than variable-length codes in terms of the average length of the codewords. For variable-length source codes, it is important that each codeword in the code is uniquely decodable. One way to ensure that this happens is by constructing a prefix code . An optimal way of constructing a prefix code, in the sense that it minimizes the average codeword length, is by constructing a Huffman code . As @whuber mentioned in their comment, one possible Huffman code is: $$ 1 \rightarrow 000 \\ 2 \rightarrow 001 \\ 3 \rightarrow 010 \\ 4 \rightarrow 011 \\ 5 \rightarrow 10 \\ 6 \rightarrow 11 $$ Notice that no codeword is a prefix of any other codeword. Hence, this is a prefix code and it is uniquely decodable. Also, this code achieves an average codeword length (aka rate of compression) of $2.5$ bits per source symbol, which is the lowest possible average codeword length.
