[site]: crossvalidated
[post_id]: 153518
[parent_id]: 
[tags]: 
Error on histogram computed on autocorrelated time series

I am struggling to find an answer to this quite basic question. When computing a histogram on a time series which has some correlations (i.e. measurements are not independant ), how to estimate the uncertainty on the number of count for each bin? In the case of independant measurement, the result is well known. The number of count $N$ in each bin follows a Poisson distribution and the uncertainty is $\sim \sqrt{N}$. However, when the data are correlated, it turns out that the uncertainty grows with the degree of correlation. Is it possible to quantify this effect? Does anyone can provide references that address this issue please?
