[site]: datascience
[post_id]: 44044
[parent_id]: 43436
[tags]: 
Although there is no data provided I'll try to share my ideas. Stacking We stack models by making several predictions with hold-out data sets and then collecting these predictions to form a new data set, where you can fit a new model on it Often times the stacked model (also called 2nd-level model) will outperform each of the individual models due its smoothing nature and ability to highlight each base model where it performs best and discredit each base model where it performs poorly Model diversity But one of the most important thong in stacking is model diversity, how different a model is to each other. You should consider what is the new information each model brings into the table? It will find why one of your model is good, and when another one is bad or fairly weak. You don't need to worry too much to make all the models really strong. Therefore, what you really need to focus is what information does this model brings, even though it is generally weak? Such models bring in new information that the meta model could leverage. Normally, you introduce diversity from two forms: By choosing a different algorithm or by . Which makes sense, certain algorithms capitalize on different relationships within the data. For example, a linear model will focus on a linear relationship, a non-linear model can capture better a non-linear relationships. So predictions may come a bit different Running the same model, but you try to run it on different transformation of input data, either less features or completely different transformation. For example, in one data set you may treat categorical features as one-hot encoding. In another, you may just use label encoding, and the result will probably produce a model that is very different. So you need to test different models. As @Aditya said - the improvement isn't guaranteed either ways until and unless you have strong baselines
