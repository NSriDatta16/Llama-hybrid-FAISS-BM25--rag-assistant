[site]: crossvalidated
[post_id]: 609982
[parent_id]: 609933
[tags]: 
There are lots of different ways. A classic example is polynomial expansions - you take all powers of your input variables ( https://en.wikipedia.org/wiki/Stone%E2%80%93Weierstrass_theorem from 1885) Fourier series ( https://en.wikipedia.org/wiki/Fourier_series ) These are roughly equivalent to the https://en.wikipedia.org/wiki/Universal_approximation_theorem of neural networks. Note that being able to represent a function doesn't mean you have "learnt" the function. eg the parity function: 1 if the (integer) number is odd or 0 if the number is odd. This can be represented on any fixed interval eg [0,100] by a suitable polynomial). however, there is no generalisation -eg train on [0,50] test on [51,100]. Similarly with tree based methods (trees/random forest/xgboost etc).
