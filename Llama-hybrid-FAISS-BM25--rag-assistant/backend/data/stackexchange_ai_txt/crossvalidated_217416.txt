[site]: crossvalidated
[post_id]: 217416
[parent_id]: 
[tags]: 
GBM: impact of the loss function

I'm familiar with Random Forest and Adaboost and if I understand well the advantage of GBM on these algorithms is we can use different lost functions. Is it correct to say: Using square loss means building trees on the raw residual of the previous tree. Using absolute loss means replacing residuals by theirs signs, ie - 1 for negative residuals and 1 for positive residuals and build the next tree on these transformed residuals. This reduces the impact of outliers If these statements are correct don't you think it's misleading to use the term square loss to describe something which just use the raw residuals? For instance in OLS regression square means what we expect which is residuals are really squared.
