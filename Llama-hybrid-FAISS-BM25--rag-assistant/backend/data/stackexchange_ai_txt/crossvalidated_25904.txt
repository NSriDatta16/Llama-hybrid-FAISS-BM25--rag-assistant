[site]: crossvalidated
[post_id]: 25904
[parent_id]: 25824
[tags]: 
It seems that your problem calls for Gaussian model with expectation being your function, that you know apriori from the nature of physical phenomena. Suppose, that physics tells you, that having covariate $X$ with measurements $X = (X_{1},...,X_{n})$ (e.g. temperature, pressure, etc.) the response is a function $E[Y|X]=f(X;\theta)$, where $Y$ is a measurements of response, $\theta$ is model parameters and suppose that $Y \in R$. In addition, suppose that your measurements have Gaussian errors with variance $ \sigma^{2}$. I would really suggest you to employ Bayesian modelling, since posterior distributions fully account for uncertainties in your model (even in small samples!!). If you also do not know the values of this covariance matrix, you can put a noninformative prior distribution on it, e.g. Jeffreys prior: $$\pi \left ( \sigma \right )\propto \left (\sigma \right )^{-1}$$ And noninformative priors for regression parameters could be: $$\pi(\theta)\propto1$$ So, we have a model: $$Y_{i}\sim N\left ( f\left ( X_{i} \right ),\sigma \right ), i=1,2,...,n$$ $$\pi \left ( \sigma \right )\propto \left (\sigma \right )^{-1}$$ From this model, construct posterior: $$\pi(\theta, \sigma|Y)\propto L(Y;\theta)\pi(\sigma)\pi(\theta)$$ Then obtain samples from this posterior by MCMC. To obtain prediction at specific covariate value $X^{*}$ use this MCMC sample of parameters $\theta$ and $\sigma$ to generate random variables from your Gaussian model. When this sample is obtained you could use its average as estimate of the prediction and the prediction interval can be constructed by constructing empirical cdf. I would really suggest you to use "Bayesian analysis" by Andrew Gelman.
