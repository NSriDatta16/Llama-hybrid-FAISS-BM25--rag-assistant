[site]: crossvalidated
[post_id]: 487750
[parent_id]: 
[tags]: 
Why does my Deep Learning Network converge to mean value of series when trying to fitting & predicting a time series?

There's a task requiring me to predict selling price of a product with provided external data containing historical purchasing prices and selling prices of competitors (positive correlated). Illustrations of BRENT (Competitor's), PURCHASING PRICES and ACTUAL SELLING PRICE are as follows: After filling NA values, I tried to make these time series stationary by $$ln(\frac{x_{t+1}}{x_t}+1)$$ and the stationary time series are illustrated as follows: Then I made some moving windows whose sizes are all 6, indicating that each window contains data, including selling prices , of past 6 days. For each window, it had one response : selling price of the 7 th day's. By moving the window, I could get a data set of 3-dimension: $(window\_num, window\_size=6, variable\_num=20)$ , and the shape of response set is $(window\_num, 1)$ . With these preparations I started to fit the response set by corresponding data set. The model I used was Transformer implemented by Keras from an instance of its official site. The network's structure was as follows: After training for 500 epochs, loss and MAE were stable and MAE is illustrated as follows: However, compared with the actual response and origin price , which are shown as follows: The upper ones of these two plots are from fitting the training data, and the lower ones are predicting using validation data. It is shown that the outputs of my model converge to one straight line, and thus it could not seize any volatility of the response . In another trial using NARX with MATLAB's NEURAL TIME SERIES , the series predicting result could be far more better ( AT LEAST IT SOMEWHAT CATCHES THE TREND ), so I considered the bad performance of my model was not caused by the data itself. I have been confused for a couple of weeks, could anyone help? Thanks so much for your patience and assistance.
