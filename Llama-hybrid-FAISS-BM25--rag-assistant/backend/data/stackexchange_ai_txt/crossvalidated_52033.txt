[site]: crossvalidated
[post_id]: 52033
[parent_id]: 
[tags]: 
Battery of random forest models for each class

I have a dataset which consists of roughly 40,000 observations grouped into 12 classes. I did a quick random forest run on a single split of 80% training and 20% testing (Dont bring up the discussion on wether or not it is necessary to split data in random forests, this is just a quick experiment) and got the following precision on the test set: I then train a RF model for each class, creating a dichotomus variable 'belongs to class': yes/no. I get, for example, these precisions on the test set for class number 1 and class number 5: Which would seem more precise. Is training several models a viable option? It may be cumbersome but if you predict each observation with all the models and choose maybe the highest membership probability a la linear discriminant analysis could you get a better precision than a single random forest? I hope this question isnt dumb, I dont know why I think about such things.
