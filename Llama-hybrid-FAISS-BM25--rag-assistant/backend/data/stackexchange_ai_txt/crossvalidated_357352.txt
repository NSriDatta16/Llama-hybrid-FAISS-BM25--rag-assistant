[site]: crossvalidated
[post_id]: 357352
[parent_id]: 14955
[tags]: 
You could use affinity propagation or better adaptive affinity propagation. Here is the Wikipedia link . There are two main advantages for your case and another third one that I think is an advantage but may not be of importance to you. You do not supply the number of clusters. The final number of clusters depends on the preference value and the similarity matrix values. The easiest way to work with the preference values is either to use the minimum value of the similarity matrix (that isn't zero) to get the smallest number of clusters, then try e.g. the maximum for the most clusters possible and continue with the median value and so on... OR Use the adaptive affinity propagation algorithm and have the preference determined by the algorithm. You can supply any similarity measure you can come up with or take the inverse of a distance measure (maybe guard against dividing by zero when you do that). 3.(extra point) The algorithm chooses an exemplar representing each cluster and which examples belong to it. This means the algorithm doesn't give you an arbitrary average but an actual datapoint. However you can still calculate averages later of course. AND this also means that the algorithm doesn't used intermittent averages! Software: There are several packages listed for Java, Python and R on the Wikipedia page. If you love MATLAB, like I do, then here is an implementation.
