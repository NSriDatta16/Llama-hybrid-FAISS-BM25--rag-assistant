[site]: datascience
[post_id]: 102396
[parent_id]: 15882
[tags]: 
I realize that this question is old, but it may still be of interest, as XGBoost still doesn't provide quantile regression out-of-the-box. You tried to solve this by using a user-defined loss function, which is the obvious approach here. To employ a user-defined loss function in XGBoost, you have to provide the first and second derivative (called grad and hess in your code, probably for gradient and Hessian). In this point, XGBoost differs from the implementations of gradient boosted trees that are discussed in the NIH paper you cited. Unfortunately, the derivates in your code are not correct. The correct ones are as follows: pred = 0, 1-qr_alpha, qr_alpha) hess But even these are slightly wrong, because both derivates don't exist when preds=labels. Moreover, the fact that the second derivate is constant is also a problem. A constant second derivative doesn't contain any information that the XGBoost's optimization algorithm could use. Both problems can be solved, but that requires more than just a custom objective function. That is probably the reason quantile regression has never been implemented in XGBoost, although the corresponding feature request is already five years old at the time of writing this. If you're looking for a modern implementation of quantile regression with gradient boosted trees, you might want to try LightGBM. It supports quantile regression out of the box. Their solution to the problems mentioned above is explained in more detail in this nice blog post .
