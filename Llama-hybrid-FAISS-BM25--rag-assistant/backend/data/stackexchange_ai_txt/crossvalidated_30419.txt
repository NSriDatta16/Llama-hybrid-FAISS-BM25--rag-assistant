[site]: crossvalidated
[post_id]: 30419
[parent_id]: 
[tags]: 
Small dimensional classification (< 20 features), one (or two) dominant predictors

I am trying to learn a logistic regression classifier using glm on a dataset of Q1. Are the posterior probabilities/predictions still valid? Q2. How should I reduce the effect of the strong predictor so that the contributions from other variables are taken into account during inference? Right now, they are completely overpowered by the one predictor.
