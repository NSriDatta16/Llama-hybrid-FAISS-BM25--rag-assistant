[site]: crossvalidated
[post_id]: 364980
[parent_id]: 200420
[tags]: 
Two classifiers which do 0 vs 1 and 0 vs 2 classifications intuitively should perform better than a classifier which has to distinguish between all three at once. The intuition being, that the choice of which 2-classifier to use for a given sample is also to be learned when doing the 0 vs 1 vs 2 classification problem. I nice paper I found which might help was Fitted Learning: Models with Awareness of their Limits . It takes a simple neural network, the Feed forward kind but the key idea is that instead of teaching it to predict a vector [0,0,1], [0, 1, 0] or [1, 0, 0] you teach it to predict another vector. You choose an arbitrary number (say 2) and then the targets you need to predict for each class follow a simple mapping. [0, 0, 1] -> [0, 0, 0.5, 0, 0, 0.5] [0, 1, 0] -> [0, 0.5, 0, 0, 0.5, 0] [1, 0, 0] -> [0.5, 0, 0, 0.5, 0, 0] That allows you to learn a much cleaner classification. I'd recommend going through the paper and seeing if it helps your problem.
