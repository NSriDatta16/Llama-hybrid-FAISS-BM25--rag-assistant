[site]: datascience
[post_id]: 60706
[parent_id]: 
[tags]: 
How do I handle with my Keras CNN overfitting

In my CNN, I have 700 images of class 0, 700 images of class 1, and 72 validation images. My code: visible = Input(shape=(256,256,3)) conv1 = Conv2D(16, kernel_size=(3,3), activation='relu', strides=(1, 1))(visible) conv2 = Conv2D(32, kernel_size=(3,3), activation='relu', strides=(1, 1))(conv1) bat1 = BatchNormalization()(conv2) conv3 = ZeroPadding2D(padding=(1, 1))(bat1) pool1 = MaxPooling2D(pool_size=(2, 2))(conv3) drop1 = Dropout(0.30)(pool1) conv4 = Conv2D(32, kernel_size=(3,3), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.01))(drop1) conv5 = Conv2D(64, kernel_size=(3,3), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.01))(conv4) bat2 = BatchNormalization()(conv5) pool2 = MaxPooling2D(pool_size=(1, 1))(bat2) drop1 = Dropout(0.30)(pool2) conv6 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.01))(pool2) conv7 = Conv2D(128, kernel_size=(2,2), activation='relu', strides=(1, 1), padding='valid')(conv6) bat3 = BatchNormalization()(conv7) pool3 = MaxPooling2D(pool_size=(1, 1))(bat3) drop1 = Dropout(0.30)(pool3) flat = Flatten()(pool3) drop4 = Dropout(0.50)(flat) output = Dense(1, activation='sigmoid')(drop4) model = Model(inputs=visible, outputs=output) opt = optimizers.adam(lr=0.001, decay=0.0) model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy']) data, labels = ReadImages(TRAIN_DIR) test, lt = ReadImages(TEST_DIR) data = np.array(data) labels = np.array(labels) perm = np.random.permutation(len(data)) data = data[perm] labels = labels[perm] #model.fit(data, labels, epochs=8, validation_data = (np.array(test), np.array(lt))) aug = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, horizontal_flip=True) # train the network model.fit_generator(aug.flow(data, labels, batch_size=32), validation_data=(np.array(test), np.array(lt)), steps_per_epoch=len(data) // 32, epochs=7) model.save('model.h5') It returns these numbers: Epoch 1/7 43/43 [==============================] - 1004s 23s/step - loss: 1.8090 - acc: 0.9724 - val_loss: 1.7871 - val_acc: 0.9861 Epoch 2/7 43/43 [==============================] - 1003s 23s/step - loss: 1.8449 - acc: 0.9801 - val_loss: 1.4828 - val_acc: 1.0000 Epoch 3/7 43/43 [==============================] - 1092s 25s/step - loss: 1.5704 - acc: 0.9920 - val_loss: 1.3985 - val_acc: 1.0000 Epoch 4/7 43/43 [==============================] - 1062s 25s/step - loss: 1.5219 - acc: 0.9898 - val_loss: 1.3167 - val_acc: 1.0000 Epoch 5/7 43/43 [==============================] - 990s 23s/step - loss: 2.5744 - acc: 0.9222 - val_loss: 2.9347 - val_acc: 0.9028 Epoch 6/7 43/43 [==============================] - 983s 23s/step - loss: 1.6053 - acc: 0.9840 - val_loss: 1.3299 - val_acc: 1.0000 Epoch 7/7 43/43 [==============================] - 974s 23s/step - loss: 1.6180 - acc: 0.9801 - val_loss: 1.5181 - val_acc: 0.9861 When I predict some test images, the result is always 0. I already tried various things like adding more dropouts (or making the dropout rate bigger), data augmentation, batch normalization etc. and none of these have made it work properly. What should I do?
