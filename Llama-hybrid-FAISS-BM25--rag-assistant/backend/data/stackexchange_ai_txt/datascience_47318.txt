[site]: datascience
[post_id]: 47318
[parent_id]: 
[tags]: 
Keras regularizers (kernel, bias and activity) vs tf.contrib.layers.apply_regularization

I have a DCGAN set up in tensorflow that is working well on the faces in the wild dataset. As an experiment, I tried using the same architecture in keras to better understand the difference in implementation. Performance so far is much worse in keras, but there are a few things I'm uncertain about how they translate, esp regularizer. In tf, I apply the regularizer with tf.contrib.layers.apply_regularization Which is just applied to the whole network it seems. However in keras this must be specified in each layer, and there are three different kinds, kernel, bias and activity regularizer. I'm trying to udnerstand how they differ, if tf regularizer applies one of the 3 keras types, and how to implement it the same way - do I call it in each convolutional layer including the final output layer? which of the 3 is equivalent of the default regularizer in tf? Thanks
