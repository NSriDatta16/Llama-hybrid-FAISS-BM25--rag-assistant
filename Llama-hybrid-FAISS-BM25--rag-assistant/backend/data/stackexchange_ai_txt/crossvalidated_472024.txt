[site]: crossvalidated
[post_id]: 472024
[parent_id]: 
[tags]: 
What loss function should I use?

With a toy neural network, I'm trying to predict a series, which has a problem. The serie is reported cases of coronavirus, but the cases are not reported the day they are detected. Part of the values are reported almost periodically, days later after detection (the accumulated cases are reported). It causes the error function to have high errors on a small number of days, because for some scarce values, there are huge peaks, and for the rest of values (most of them), the series has lower values than the real ones. For that reason, I cannot use a loss function like the square of errors, because the peaks dominate the error. I also tried to use the square root of the error, which ignores extreme values, but that error function has lots of local minima. I also tried to use the accumulated values, because they tend to have the right numbers periodically, self correcting itself, but it also doesn't works well. Maybe I should be distributing the peaks across the previous days, but that would be a blind deconvolution, requiring so many parameters than the series would be easily over fit, since the data is short, and everyday would have a different dconvoluton kernel (for example, on Sundays, more cases are delayed than on the rest of the week). So a single deconvolution kernel would not do the work. Each weekday requires a different kernel. I cannot treat the series as noisy, because the peaks are not noise. They are delayed values. Using as loss function (measured values/predicted values)Â²-1 tends to overfit the data, but that's not really so wrong, since not all cases are detected, so the real cases should be higher. But is possible to do better?
