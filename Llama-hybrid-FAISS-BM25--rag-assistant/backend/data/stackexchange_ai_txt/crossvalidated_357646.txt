[site]: crossvalidated
[post_id]: 357646
[parent_id]: 357608
[tags]: 
It's easier to understand on a concrete example. Suppose, you want to predict the precipitation based on the temperature of a site. So, you posit a model: $$y_i=\beta_0+\beta x_i+\varepsilon_i$$ Here, $y_i$ average precipitation and $x_i$ - average temperature in town. Do you think that the prediction uncertainty is the same regardless of a town? If you do, then you assume that the errors are homoscedastic. However, one could make an argument that the uncertainty is not the same for all geographies. Maybe for some reason this model forecasts better for Ulanbaator than for Washington DC. In this case the error variances will be larger for Washington, and smaller for Ulanbaator, i.e. heteroscedastic errors I suspect that you naturally consider the errors $\varepsilon_i$ as realizations of some random variable $\varepsilon$. Hence, you think of a variance $\sigma^2$ as a variance of that variable $Var[\varepsilon]$. It seems to fit the intuition. However, in reality each error terms $\varepsilon_i$ is a random variable itself . Each one of these have their own variance $Var[\varepsilon_i]=\sigma_i^2$, they don't need to be the same
