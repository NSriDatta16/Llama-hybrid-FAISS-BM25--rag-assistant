[site]: crossvalidated
[post_id]: 414177
[parent_id]: 24659
[tags]: 
I understand that this question has been sitting here for years, but still, the following ideas may be useful: If there are links between variables (and the theoretical formula does not work so well), PCA can be used to look for (linear) dependencies in a systematic way. I will show that this works well for the given data in this question. Given there is not much data (112 numbers in total), only a few model parameters can be estimated ( e.g. fitting full seasonal effects is not an option), and trying a custom model may make sense. Here is how I would make a forecast, following these principles: Step 1. We can use PCA to reveal dependencies in the data. Using R, with the data stored in x : > library(jvcoords) > m m PCA: mapping p = 4 coordinates to q = 4 coordinates PC1 PC2 PC3 PC4 standard deviation 0.18609759 0.079351671 0.0305622047 0.0155353709 variance 0.03463231 0.006296688 0.0009340484 0.0002413477 cum. variance fraction 0.82253436 0.972083769 0.9942678731 1.0000000000 This shows that the first two principal components explain 97% of the variance, and using three components covers 99.4% of the variance. Thus, it will be enough to make a model for first two or three PCs. (The data approximately satisfy $W = 0.234\, wd - 1.152\, wc - 8.842 \,p$ .) Doing PCA involved finding a $4\times 4$ orthogonal matrix. The space of such matrices is 6-dimensional, so we have estimated 6 parameters. (Since we only really use PC1 below, this may be fewer "effective" parameters.) Step 2. There is a clear trend in PC1: > t plot(m $y[,1], type = "b", ylab = "PC1") > trend y[,1] ~ t) > abline(trend) I create a copy of the PC scores with this trend removed: > y2 y2[,1] Plotting the scores of the other PCs reveal no clear trends, so I leave these unchanged. Since the PC scores are centred, the trend goes through the centre of mass of the PC1 sample and fitting the trend only corresponds to estimating one parameter. Step 3. A pair scatter plot shows no clear structure, so I model the PCs as being independent: > pairs(y2, asp = 1, oma = c(1.7, 1.7, 1.7, 1.7)) Step 4. There is a clear periodicity in PC1, with lag 13 (as suggested by the question). This can be seen in different ways. For example, the lag 13 autocorrelation shows up as being significantly different from 0 in a correlogram: > acf(y2[,1]) (The periodicity is visually more striking when plotting the data together with a shifted copy.) Since we want to keep the number of estimated parameters low, and since the correlogram shows lag 13 as the only lag with a significant contribution, I will model PC1 as $y^{(1)}_{t+13} = \alpha_{13} y^{(1)}_t + \sigma \varepsilon_{t+13}$ , where the $\varepsilon_t$ are independent and standard normally distributed (i.e. this is an AR(13) process with most coefficients fixed to 0). An easy way to estimate $\alpha_{13}$ and $\sigma$ is using the lm() function: > lag13 lag13 Call: lm(formula = y2[14:28, 1] ~ y2[1:15, 1] + 0) Coefficients: y2[1:15, 1] 0.6479 > a13 s13 As a plausibility test, I plot the given data (black), together with a random trajectory of my model for PC1 (blue), ranging one year into the future: t.f The blue, simulated piece of path looks like a reasonable continuation of the data. The correlograms for PC2 and PC3 show no significant correlations, so I model these components as white noise. PC4 does show correlations, but contributes so little to the total variance that it seem not worth modelling, and I also model this component as white noise. Here we have fitted two more parameters. This brings us to a total of nine parameters in the model (including the PCA), which does not seem absurd when we started with data consisting of 112 numbers. Forecast. We can get a numeric forecast by leaving out the noise (to get the mean) and reversing the PCA: > pc1.f y.f x.f rownames(x.f) x.f W wd wc p 29 4.456825 4.582231 3.919151 0.5616497 30 4.407551 4.563510 3.899012 0.5582053 31 4.427701 4.571166 3.907248 0.5596139 32 4.466062 4.585740 3.922927 0.5622955 33 4.327391 4.533055 3.866250 0.5526018 34 4.304330 4.524294 3.856824 0.5509898 35 4.342835 4.538923 3.872562 0.5536814 36 4.297404 4.521663 3.853993 0.5505056 37 4.281638 4.515673 3.847549 0.5494035 38 4.186515 4.479533 3.808671 0.5427540 39 4.377147 4.551959 3.886586 0.5560799 40 4.257569 4.506528 3.837712 0.5477210 41 4.289875 4.518802 3.850916 0.5499793 Uncertainty bands can be obtained either analytically or simply using Monte Carlo: N $W, xlim = range(t, t.f), ylim = range(x$ W, bands), type = "b", ylab = "W") for (b in 1:5) { lines(c(28, t.f), c(x$W[28], bands[b,]), col = "grey") } The plot shows the actual data for $W$ , together with 60% (inner three lines) and 95% (outer two lines) uncertainty bands for a forecast using the fitted model.
