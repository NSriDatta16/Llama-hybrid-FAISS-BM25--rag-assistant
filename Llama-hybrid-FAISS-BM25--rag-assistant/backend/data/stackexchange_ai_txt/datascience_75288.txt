[site]: datascience
[post_id]: 75288
[parent_id]: 10250
[tags]: 
From my knowledge from the Deep Learning book (Ian Goodfellow), the cost function, error function, objective function and loss function are the same. In statistics, we use the term objective function which is to be optimised(maximised or minimised). Since the objective functions in ML almost always deals with the error generated by the model, it must be minimised only. Thus the term cost function came. Also since objective function calculates the error(equivalent term is loss-diff between actual and predicted values), it also has the names error function and loss function.
