[site]: crossvalidated
[post_id]: 621463
[parent_id]: 621453
[tags]: 
The decoder represents a multidimensional probability distribution. If your "reconstruction loss" (the negative log-likelihood term) is the mean squared error, or variants thereafter, the decoder represents a multivariate Gaussian distribution. This form implies a constant diagonal covariance (which is not usually estimated, and is assumed to be the same for every sample). Then, the 'output' is the mean of such a distribution (which completely parametrizes a multivariate Gaussian with assumed known covariance) If you optimize instead for "cross-entropy loss" (the Bernoulli negative loglikelihood), then the decoder represents a Bernoulli distribution. In this case, the 'output' is the probability of a single trial (i.e., being 1 instead of 0). Theoretically, you could sample from the decoder (see Is the output of a variational autoencoder meant to be a distribution that can be sampled, or a sample directly? ), since it is a conditional distribution.
