[site]: datascience
[post_id]: 29479
[parent_id]: 
[tags]: 
LSTM with keras/tensorflow implementation

I'm trying to learn a sufficient statistic from data. My input are sequences of samples x_samples which are real numbers. The length of the input sequence varies and has no fixed value. There is no memory between the sequences - each sequence is completely independent from all the others. The output y is the sufficient statistic given by the sum of log(p_1(x)/p_2(x)) for all the samples in a given sequence (thus a RNN is needed). p_1 and p_2 are two unknown functions (they are the PDFs of some process). For example if a sequence has 3 samples x1,x2,x3 the output is given by y = log(p_1(x1)/p_2(x1)) + log(p_1(x2)/p_2(x2)) + log(p_1(x3)/p_2(x3)) . I am wondering how to input the sequences into my network. I've seen a few solutions to this problem but none of them seem relevant for me. I don't want to use zero padding. The reason is that the sequence has no maximum length - it depends on other factors independent of this problem and may theoretically take any value. The LSTM is part of a bigger RL system. The data is generated along the way so i don't have a fixed data set. I don't want to use 1 hot encoding for my input since x_samples are just real values. It is possible to quantize the input but i think this is a bad solution. I think it makes sense to input the the samples one by one with a start and end tokens for each sequence. Does this make sense? Additionally I wonder if during the training I should reset the memory of the LSTM in the end of each sequence (with model.reset_states() , have I understood it correctly?) or it is enough to set a start and end tokens in the begging and the end of every sequence.
