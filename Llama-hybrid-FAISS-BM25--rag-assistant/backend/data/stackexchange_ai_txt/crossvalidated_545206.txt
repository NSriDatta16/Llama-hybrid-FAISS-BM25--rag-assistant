[site]: crossvalidated
[post_id]: 545206
[parent_id]: 
[tags]: 
how to set the cost parameter of SVM as a function of the sample size?

this is a follow up to: SVM parameter dependence on number of samples please, is there any progress since the above post was answered, with respect to literature or current practice, on how to set C in SVM? are there research papers detailing how C should decay as a function of the number of samples in the training set? according to the above post, The $C$ parameter for most SVM implementations scales approximately linearly with the number of training patterns, so if you train with a subset, you will need to multiply $C$ by a factor of $N_s/N_t$ where $N_t$ is the number of training patterns and $N_s$ is the subset size for the parameter optimization. This is only an approximation though, so it may not give as good an estimate as performing model selection with the full training set. are there any more specific details about this answer? by the way, in the above comment, should we replace $N_s/N_t$ by $N_t/N_s$ ?
