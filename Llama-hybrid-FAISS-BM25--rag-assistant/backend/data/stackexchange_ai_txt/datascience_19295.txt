[site]: datascience
[post_id]: 19295
[parent_id]: 19268
[tags]: 
You can test each model with default parameters, and keep the model that seems best. Or, for each model, you can tune the parameters for that model, to see what is the best that's achievable for each model (by separately tuning its parameters) -- then keep the best model. This takes more computation power but might be slightly better. Yes, parameter tuning depends on the model. Each model may have a very different set of parameters, with entirely different meaning. You can't take parameters for a random forest and then try to use them as parameters for a SVM (for instance); that doesn't even make sense, as they have different parameters. Yes, there are many possibilities on what order you do feature selection vs choosing a model vs parameter tuning. I don't know what the "feature weights of FeatureUnion" are, so I can't answer that part.
