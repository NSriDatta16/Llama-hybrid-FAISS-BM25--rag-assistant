[site]: datascience
[post_id]: 77131
[parent_id]: 
[tags]: 
how to build lstm with functinal api?

I am having a time series prediction problem and the data set has 4 variables. My data set is like below: import numpy as np import pandas as pd df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD')) df.columns=['var1','var2','var3','var4'] The timestamp is the index of my original data frame and I only take the values in the sorted order. From this var1 is my target variable to predict.I also need to key in 3-time lags so I prepare the dataset by below function: # convert series to supervised learning def series_to_supervised(data, n_in=1, n_out=1, dropnan=True): n_vars = 1 if type(data) is list else data.shape[1] df = pd.DataFrame(data) cols, names = list(), list() # input sequence (t-n, ... t-1) for i in range(n_in, 0, -1): cols.append(df.shift(i)) names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)] # forecast sequence (t, t+1, ... t+n) for i in range(0, n_out): cols.append(df.shift(-i)) if i == 0: names += [('var%d(t)' % (j+1)) for j in range(n_vars)] else: names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)] # put it all together agg = pd.concat(cols, axis=1) agg.columns = names # drop rows with NaN values if dropnan: agg.dropna(inplace=True) return agg #take the 3 lags for each row reframed = series_to_supervised(df,3, 1) train_X=reframed.drop(['var1(t)'],axis=1) train_y=reframed[['var1(t)']] # design network model = Sequential() model.add(LSTM(20, input_shape=(train_X.shape[1], train_X.shape[2]))) model.add(Dense(1)) model.compile(loss='mae', optimizer='adam') So here the shape will be (97, 16) where 97 is the row count since the first three timesteps will not have 3 lags and the 16 is the overall columns with 3 lags plus the current time stamp. Now in my case the value of var1(t) is also influenced by the var2(t) , var3(t) , var4(t) . So my training shape of the data will be train_X shape (97, 15) train_y shape (97, 1) Now the problem is how to reshape this into [samples, timesteps, features] .Because I can only do this if I drop var2(t) , var3(t) , var4(t) then I can reshape as [97,3,4] but in my case, I also want to include the current timestamp's remaining variable. So then I found out that I can use the keras functional API to overcome this . I created the model with keras functional API but something is wrong in the shape of the tensors. def createFunctionalKerasLSTM(): visible = Input(shape=(train_X.shape[0],train_X.shape[1])) hidden1 = LSTM(20)(visible) hidden2 = Dense(10, activation='relu')(hidden1) output = Dense(1, activation='sigmoid')(hidden2) model = Model(inputs=visible, outputs=output) model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_squared_error']) return model Error ValueError: Input 0 of layer lstm_14 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 15] I am not sure how to reshape in this case .because for normal LSTM I can drop the var2(t) , var3(t) , var4(t) and then reshape it (97,12) into (97,3,4) But here y shape is (97,15) so a bit confused how to reshape it properly to the input of the network. Any help is appreciated!
