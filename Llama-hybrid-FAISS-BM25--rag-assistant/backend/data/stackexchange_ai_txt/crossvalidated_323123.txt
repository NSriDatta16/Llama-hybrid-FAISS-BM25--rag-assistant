[site]: crossvalidated
[post_id]: 323123
[parent_id]: 
[tags]: 
Keyword Spotting: How to train a model with general speech corpus?

I am trying to find a correct way to train a DNN based keyword spotting (Deep KWS) with general speech corpus (VS data) described in this paper (Chen, Guoguo, Carolina Parada, and Georg Heigold. "Small-footprint keyword spotting using deep neural networks." In Acoustics, speech and signal processing (icassp), 2014 ieee international conference on, pp. 4087-4091. IEEE, 2014.) In section 2.2 Transfer learning , it said we use a deep neural network for speech recognition with suitable topology to initialize the hidden layers of the network. All layers are updated in training. Transfer learning has the potential advantage that the hidden layers can learn a better and more robust feature representation by exploiting larger amounts of data and avoiding bad local optima. Later in section 4.1 Data , it said The first set is a general speech corpus, which consists of 3,000 hours of manually transcribed utterances (referred to as VS data). The second set is a keyword specific data (referred to as KW data), which included around 2.3K training examples for each keyword, and 133K negative examples, comprised of anonymized voice search queries or other short phrases My question is: how do I train a feature representation layers? AFAIK, the training procedures are using general speech corpus to train feature extraction layers at first, and using keyword (KW) data to train a keyword specific model. But I don't know how to undertake the first step. For example, currently I have Wall Street Journal (WSJ) dataset which has about 18000 lexicons. Does it mean that I have to use 18000+1 (1 for silence state) output labels (classes) when undertaking the first step?
