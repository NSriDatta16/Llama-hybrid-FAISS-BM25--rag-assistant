[site]: crossvalidated
[post_id]: 160620
[parent_id]: 160558
[tags]: 
I'd suggest leave-one-out cross-validation. With 45 observations, use 44 to fit the model and calculate the error on the 45th. By leaving out each observation in turn and calculating the average error (e.g. RMS), you should get an unbiased estimate of performance. You can repeat this for different combinations of predictors, different model classes etc. Some more background here: http://robjhyndman.com/hyndsight/crossvalidation/ One advantage of small data sets is that you can use methods that are often too computationally expensive to be useful. Finally, be aware that building 1000's of models and picking one with the lowest error can lead to overfitting, even if every model's error was calculated using cross-validation. The selection of one model among many can introduce a bias.
