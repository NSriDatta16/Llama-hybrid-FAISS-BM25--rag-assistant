[site]: datascience
[post_id]: 45740
[parent_id]: 
[tags]: 
Is a good shuffle random state for training data really good for the model?

I'm using keras to train a binary classifier neural network. To shuffle the training data I am using shuffle function from scikit-learn. I observe that for some shuffle_random_state (seed for shuffle() ), the network gives really good results (~86% accuracy) while on others not so much (~75% accuracy). So i run the model for 1-20 shuffle_random_states and choose the random_state which gives the best accuracy for production model. I was wondering if this is a good approach and with those good shuffle_random_state the network is actually learning better?
