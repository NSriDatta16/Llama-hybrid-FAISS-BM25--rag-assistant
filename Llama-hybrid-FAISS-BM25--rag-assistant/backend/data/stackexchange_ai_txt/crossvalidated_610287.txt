[site]: crossvalidated
[post_id]: 610287
[parent_id]: 
[tags]: 
Continuous retraining a model on a increasing database

I have successfully developed an image classifier using Deep Learning, in particular I have used a ResNet50V2 network with fine tuning transfer learning. I built up a database from the available imagine and then I tune the parameters. I split the database in train and test sets and using crossvalidation to investigate the hyperparameters. It works fine and I am happy. Now, my supervisor said that in production the database will be increased in time. That is, after the action of a machine, the camera will takes some photos and then they will be added in the database. My supervisor asks if the database can be retrained after one or more addition to the database. Sure, it is possible, but the hyperparameters should be redefined and the training should be done on the entire database. It is a heavy time consuming process. Am I correct? Are there smarter ways to tackle this problem?
