[site]: crossvalidated
[post_id]: 449366
[parent_id]: 
[tags]: 
Do these plots show that the model is overfitted?

Recently I had a discussion with one of my colleagues regarding the concept of overfitting. I have a model that shows the following training behavior. The first plot shows how the value of loss changes as the model is trained over several data folds. The second plot shows the evolution of the F1 metric. I think that these curves imply that the model is overfitting. We have clear divergence of the curves between the training and validation phases and a considerable gap between the performance of a model during these two phases. Also, the validation loss starts increasing after some point, while the training loss keeps improving. However, the colleague argues that as far as the model still improves its quality during the training phase, it means that it hasn't yet overfitted the training dataset . So we should keep trying to overfit it by reaching the F1 score equal to 1.0 to make sure that the model complex enough and then start regularizing it. I've never encountered this kind of approach before. My thinking is that as soon as you have a model that shows too good performance on the training dataset but fails on the validation, it means we hit the overfitting condition and should start thinking about possible regularization methods, or do some additional feature engineering. Is my understanding of the concept of overfitting not correct? Are there different ways to approach this concept?
