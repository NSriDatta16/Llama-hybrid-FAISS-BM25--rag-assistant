[site]: crossvalidated
[post_id]: 302039
[parent_id]: 302008
[tags]: 
The L2 norm of a matrix (also called the Frobenius norm) is equivalent to the L2 norm of its vectorized form. So for a standard machine learning algorithm what you'd want to do is simply vectorize all your matrices and then normalize them as you normally would. That said, most matrix-variate data is a matrix for a reason (which is to say, there is likely some structure in the ordering of rows and/or columns). If this is true, then you may want to consider a normalization approach that is more appropriate to the data that you have -- for example, you could normalize each entry individually, or each column, etc.
