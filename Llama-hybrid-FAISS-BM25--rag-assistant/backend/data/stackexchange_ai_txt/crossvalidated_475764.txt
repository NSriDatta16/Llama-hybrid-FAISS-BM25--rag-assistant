[site]: crossvalidated
[post_id]: 475764
[parent_id]: 475017
[tags]: 
This answer takes the same framework as @kevin012's answer, but I'd like to try to be more precise in some of the definitions. I have no trouble with the definition of the bootstrap, or resampling data with replacement and computing the statistic from the Monte Carlo samples. a) Let's say there's as confidence level, $1-\alpha$ , and that this is our "nominal coverage level" as well. Now b) a $1-\alpha * 100\%$ confidence interval is, in theory, an interval that contains the test statistic computed from $1-\alpha * 100\%$ of random samples from the population (i.e. there is an $\alpha * 100\%$ chance of drawing a random sample from the population with a test statistic outside the confidence interval). The key here is that lots of CI don't actually work this way; because it's hard to get that right without pivotal quantities and continuous statistics. c) There are lots of bootstrap confidence intervals. Below is an example with the Basic Bootstrap CI as implemented in the R package boot Statistical coverage is the [expected] frequency that a so-called "confidence interval" actually contains its target value. It is not the case that various bootstrap CI always work as advertised. Below is some R code showing that the coverage of the 95% basic bootstrap CI is woefully low for 50 Bernoulli trials with $p=0.1$ . It is around 86%, when of course it should be 95% by definition. library(boot) library(tidyverse) n $basic[4], upr=ci$ basic[5])) }) outside $lwr)+sum(p>ci$ upr))/length(ci$lwr) } cov_obs
