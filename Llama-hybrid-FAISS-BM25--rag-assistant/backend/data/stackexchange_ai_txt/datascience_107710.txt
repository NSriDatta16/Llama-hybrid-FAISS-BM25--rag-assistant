[site]: datascience
[post_id]: 107710
[parent_id]: 9783
[tags]: 
In the past few years, some researchers have worked on breaking the "black-box" character of Machine Learning Models, by building tools allowing for understanding why your chosen model makes certain decisions. Some of implementation include, but are not limited to: SHAP Values ( Recommended , and generally recognized as the most complete) LIME eli5 sklearn's permutation_feature_importance While all with distinct characteristics, these tools offer insights as to "what's happening under the hood" of the model's computation, therefore shedding great light on the predictive nature of the features.
