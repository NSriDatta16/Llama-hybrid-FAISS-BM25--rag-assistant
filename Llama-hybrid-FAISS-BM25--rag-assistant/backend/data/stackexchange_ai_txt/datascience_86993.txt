[site]: datascience
[post_id]: 86993
[parent_id]: 
[tags]: 
XGBoost feature importance has all features but decision tree doesn't

I have used XGBoost to train a model with 400 features. My understanding is that since the max_depth is default at only 6, and 2^6 How come when I output the feature importance chart, it shows every single feature with above 0 importance? The decision tree output clearly shows that not every feature has been used in the final tree.
