[site]: crossvalidated
[post_id]: 593916
[parent_id]: 
[tags]: 
What is the correct method for training NLP models with augmented data?

I have a very small dataset (~50 rows) for a text classification problem. I found some open source data that's similar to the problem I'm trying to solve. Should I... Train the (BERT) model on the open data, then fine-tune again on the original (small) dataset. Combine the two datasets and fine tune the entire thing (also on BERT). Also, what should be my validation/hold-out set be in either case?
