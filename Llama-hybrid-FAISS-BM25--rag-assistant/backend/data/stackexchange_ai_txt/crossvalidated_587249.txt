[site]: crossvalidated
[post_id]: 587249
[parent_id]: 31867
[tags]: 
The other answers do a good job explaining this topic, but I think there's room for a more motivated explanation. What is the probability of rolling a 1 with a fair six-sided die? The traditional answer would be 1 in 6, because no one side is favored over another. This concept can be extended to the principle of indifference , which was stated by Keynes (1921): If there is no known reason for predicating of our subject one rather than another of several alternatives, then relatively to such knowledge the assertions of each of these alternatives have an equal probability. Thus equal probabilities must be assigned to each of several arguments, if there is an absence of positive ground for assigning unequal ones. And so we find the probability of pulling any card from a deck is 1 in 52, the probability of flipping heads with a fair coin is 1 in 2, the probability of pulling a 5 from a random number generator which gives single digit integers from 0 to 9 is 1 in 10. We know that, with sufficient information about the system, the result could always be predicted exactly, and so there is no "chance" involved, only lack of complete knowledge. But unless we have evidence that a particular outcome is more likely, we must consider all equally. We can now distinguish two types of probability: Subjective probability , which is the degree of belief of an actor based on a priori knowledge Objective probability , the theoretical chance or propensity of an event Presumably, our goal is to better define the concept of objective probability, or to limit ourselves to subjective probabilities through which we infer something like the objective probability. In both cases, we wish to develop a model for the events of interest. We will work towards understanding probability from the perspective of Bayesion probability (subjective probability based on observations) and frequentist probability (objective probability based on the idea that, in the limit, the relative frequencies obtained by random sampling give the probability of the respective events). But first, we must give evidence that the principle of indifference is flawed if misapplied. The principle of indifference is subject to paradoxes, one of which is Bertrand's paradox (see e.g. here , slightly modified). It goes as follows: Consider an equilateral triangle inscribed in a circle. Suppose a chord of the circle is chosen at random. What is the probability that the chord is longer than a side of the triangle? A key idea here is that the domain of possibilities is infinite , there are an infinite number of possible chords we can choose, and many ways we can "randomly" select them. For example: Random endpoints - Select two random points on the circumference of the circle and connect them; the probability that the chord is longer than the side of an equilateral triangle inscribed in the circle is 1 in 3 Random radials - Select a radius line of the circle, choose a point on the radius, and construct the chord through this point and perpendicular to the radius. The probability of the chord being longer than a side is 1 in 2. Random midpoints: Select a random point as the midpoint of a chord. The probability that the chord is longer is 1 in 4. There are other considerations (e.g. the role of diameter lines, the "maximum ignorance" principle), but by the classical theory of probability, the problem as stated above has no unique solution. While Bertrand's paradox is still considered by some as unresolved, whether you believe that or not the paradox still illustrates issues with naively adapting the principle of indifference. Another problem in probability which the traditional interpretation of probability fails to answer is this: what is the probability that the sun will rise tomorrow? There is no natural symmetry by which to reason, so the traditional approach is difficult to apply. The question can be interpreted in different ways, but we seek to answer what the probability should be. As an example, I [or humans in general] have experienced the sun rising every day since I have been alive, therefore my degree of belief that the sun will rise tomorrow is very high. Alternatively, the physical mechanism behind the sun "rising" is well-known, and no observations have been made which would lead us to think that the Earth will stop rotating, so there is a very small probability that the sun will not rise, the only plausible reason for denying this being a lack of absolute information about all possible astronomical events in the next 24 hours. Laplace first posed this problem, and describes the probability as follows. Assume the sun rises on $p\%$ of days, where $p$ can only be inferred from experience. We wish to calculate the probability that $p$ is in a given range, based on the number of days we have actually seen the sun rise. Initially (at the beginning of Earth time, say), we have no information about $p$ , therefore we assume a uniform distribution from 0 to 100%. That is, the probability that the sun will rise can be anywhere in the range $[0,100\%]$ with equal likelihood. (Careful to note: that's the probability of a probability.) Now, every day on record where the sun has risen is evidence in favor of the statement "the sun will rise tomorrow." Therefore, the distribution of $p$ is calculated from the conditional probability of the sun rising tomorrow given that the sun has risen $k$ times previously . The initial distribution (the uniform distribution) of the probability $p$ is called the a priori distribution , or prior distribution . From Bayes' rule, this conditional probability can be calculated from the prior distribution and the observations. Taking this idea further, the Bayesian interpretation of probability states that any probability is a conditional probability given knowledge about the population. Bayesian probability frames problems in e.g. statistics in quite a different way, which the other answers discuss. The Bayesian system seems to be a direct application of the theory of probability, which seeks to avoid inferring anything which is not already known, and only inferring based on exactly what has been observed. Initially, it was only considered within the domain where this kind of reasoning was desirable (like the sunrise problem), while problems with random sampling and statistical inference were considered in their own domain. But, in the mid-20th century, the assumptions of the statistical approach of random sampling began to be understood. Most of the early 20th century statistical techniques followed an approach to probability similar to the following: given an exactly defined random experiment, which can be repeated without subjectivity, one may estimate the probability of the event occurring in general, and as the number of observations increases, the objective probability of the event is approached. The fact that this was an alternative interpretation of the concept of probability was not immediately obvious, but it grew to be well accepted. Because of the role of relative frequencies of events occurring, this was described as the frequentist interpretation of probability . Returning to the sunrise problem. From the Bayesian perspective, we began with a prior distribution (uniform probability) for the probability $p$ that the sun will rise tomorrow, and we used the repeated experiences of the sun rising, combined with Bayes' rule, to obtain a conditional probability. The probability is only what we can obtain by starting with ignorance and working towards understanding. From the frequentist perspective, the experiment is not the well-defined random experiment necessary, so we cannot directly apply the concept. But if we want to force it, we also consider the past experiences, considering these as a sample of the sample space (all times the sun will or will not rise in the morning). With an imperfect understanding of the experiment and underlying mechanism, we would be forced to infer that because the sun has always risen in the past, that it will always continue to rise in the future, within some confidence interval. This problem clearly favors a Bayesian approach. Compare this with any of the random experiments featured in statistical textbooks (random number generators, whether a die is loaded or fair, presence of genetic traits in plant or animal populations). Before the rise of modern computing, calculating the Bayesian probability of events was almost impossible. But in the last few decades, Bayesianism has seen a marked rise in popularity, especially in problems where it is most applicable (as to which problems those are, sometimes it's clear, but generally it's an open problem).
