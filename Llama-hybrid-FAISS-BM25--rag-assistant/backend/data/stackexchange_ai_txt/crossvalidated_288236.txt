[site]: crossvalidated
[post_id]: 288236
[parent_id]: 
[tags]: 
What does this learning curve show ? And how to handle non representativity of a sample?

I am trying a random forest regressor for a machine learning problem (price estimation of spatial points). I have a sample of spatial points in a city. The sample is not randomly drawn since there are very few observations downtown. And I want to estimate prices for all addresses in the city. I splitted the dataset with the train_test_split function of sklearn . I have a good cross validation score (absolute mean squared error) and also a good test score. But predictions for the other dataset with all the spatial points are very bad. What could explain this results ? I plotted the learning curves : cross validation score increases with number of instances (that sounds logical), training score remains high (should it decrease ?) ... What do these learning curves show ? And in general how do we "read" learning curves ? Moreover, I suppose that the sample is not representative. I tried to make the second dataset spatially similar to the train set by drawing whitout replacement according to proportions of observations in each district for the train set. But this didn't change the result. How can I handle this non representativity ? Last but not least, why do I have a big difference in predictions between the test set cleverly extracted from the first dataset and the second dataset for which I want predictions while the two are seen as new data ? Thanks in advance for any help
