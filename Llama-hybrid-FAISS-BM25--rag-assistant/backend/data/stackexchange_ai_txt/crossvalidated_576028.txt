[site]: crossvalidated
[post_id]: 576028
[parent_id]: 
[tags]: 
How to manage out of sample data in the long run?

For example, you are interested in testing an investment strategy and there is data from 1950 to 2022. So you split it into a train and test set, say 1950-2000 and 2000-2022. Then you build your model using the train set and proceed to successfully validate it on the test set. What does the completion of this analysis mean for the data that is used? If you had a new idea at some point in the future, wouldn't your memory of the test results of the previous research influence your current model building, and wouldn't the test set have to be considered in-sample since you have already used it? I am particularly curious how this is approached in organizations (e.g. hedge funds) that (I assume) are always working on new ideas.
