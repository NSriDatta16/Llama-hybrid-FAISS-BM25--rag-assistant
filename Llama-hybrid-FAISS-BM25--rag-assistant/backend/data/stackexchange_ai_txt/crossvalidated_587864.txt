[site]: crossvalidated
[post_id]: 587864
[parent_id]: 
[tags]: 
Plot Latent-Space of VAE with embedding or just z_mean?

My model is build on this architecture from github: https://github.com/arogers1/VAE_LSTM_Text_Encoding/blob/master/vae_lstm.py The parameters I found the best results with, included a latent_dim of 16. Now, I want to visualize each encoded test example. My question is: When I run the encoder prediction, I receive z_mean, z_log_sigma in the shape of (2, No. Samples, 16). When I want to visualize this, am I correct that I need to manually call the sampling function from the model? def _get_sampling_layer(self): def sampling(args): z_mean, z_log_sigma = args epsilon = K.random_normal(shape=(self.batch_size, self.latent_dim), mean=0., stddev=self.epsilon_std) return z_mean + z_log_sigma * epsilon return Lambda(sampling, output_shape=(self.latent_dim,))([self.z_mean, self.z_log_sigma]) I am asking, because in my head, it would make most sense to "just" feed the z_mean values into a tsne and plot the results, as the embedding (aka z_log_sigma * epsilon ) would add unnecessary noise to the plot?
