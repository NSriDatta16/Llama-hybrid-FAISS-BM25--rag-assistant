[site]: crossvalidated
[post_id]: 557571
[parent_id]: 557491
[tags]: 
Assigning class weights does not allow for the use of Accuracy-like metrics that require balanced datasets. That is because strictly speaking no performance metrics requires balance datasets to be calculated - a particular metric (e.g. Accuracy, or Precision) might be almost totally uninformative when applied on a highly imbalanced dataset but that does not mean it doesn't do what it say "on the tin". When we use class weights based on the relative occurrence rates, we effectively try to assign our misclassification costs such that they balance each other out. That is one approach but not the only approach and it can be argued that it is likely not the best approach either. When working with imbalanced data what happens is that we cannot ignore the fact that the utility of our algorithm (i.e. the decision we will take based on its predictions) will likely not coincide with the abstract metrics we used when performing model fitting. That is a fact of life. Re-weighting our instances might allow us to have a metric that represents our final utility somewhat better but that weight selection needs to be thought carefully rather than be assumed to be correct just because it balances the misclassification costs exactly. If we don't, we one again fall in the traps mentioned in the links provided by Dave on: Are unbalanced datasets problematic, and (how) does oversampling (purport to) help? Why is accuracy not the best measure for assessing classification models? When working with our imbalanced dataset our final utilities might come by the identification of risk scores, anomaly detections or simply direct ranking of the top- $k$ instances. Finally please note that AUC-ROC and Accuracy are not directly comparable. AUC-ROC does not need to do hard-class assignment (i.e. it doesn't have to make a decision on class class label) to be evaluated, that is in contrast with AUC-ROC/AUC-PR/Brier score/etc. that allow for evaluating the classifiers output directly. (They are some classifiers, like SVMs, that do hard-class assignment by default but I don't consider them in this context)
