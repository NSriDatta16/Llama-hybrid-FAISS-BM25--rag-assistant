[site]: datascience
[post_id]: 43
[parent_id]: 38
[tags]: 
Hadoop is not a database , hadoop is an entire ecosystem. Most people will refer to mapreduce jobs while talking about hadoop. A mapreduce job splits big datasets in some little chunks of data and spread them over a cluster of nodes to get proceed. In the end the result from each node will be put together again as one dataset. Let's assume you load into hadoop a set of with the population of some neighborhoods within a city and you want to get the average population over the whole neighborhoods of each city(figure 1). figure 1 [new york, 40394] [new york, 134] [la, 44] [la, 647] ... Now hadoop will first map each value by using the keys (figure 2) figure 2 [new york, [40394,134]] [la, [44,647]] ... After the mapping it will reduce the values of each key to a new value (in this example the average over the value set of each key)(figure 3) figure 3 [new york, [20264]] [la, [346]] ... now hadoop would be done with everything. You can now load the result into the HDFS (hadoop distributed file system) or into any DBMS or file. Thats just one very basic and simple example of what hadoop can do. You can run much more complicated tasks in hadoop. As you already mentioned in your question, hadoop and noSQL are complementary. I know a few setups where i.e. billions of datasets from sensors are stored in HBase and get then through hadoop to finally be stored in a DBMS.
