[site]: datascience
[post_id]: 112552
[parent_id]: 112540
[tags]: 
I have figured out how to fix it, posting to help others :) import pandas as pd from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.preprocessing import FunctionTransformer from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from sklearn.pipeline import Pipeline import re from lime.lime_text import LimeTextExplainer from IPython.core.interactiveshell import InteractiveShell InteractiveShell.ast_node_interactivity = "all" # Loading GitHub Repos data containing code and comments from 2.8 million GitHub repositories: DATA_PATH = r"/Users/stevesolun/Steves_Files/Data/github_repos_data.csv" data = pd.read_csv(DATA_PATH, dtype='object') data = data.convert_dtypes() data = data.dropna() data = data.drop_duplicates() # Train/Test split X, y = data.content, data.language X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y) # Model params to match: # 1. Variable and module names, words in a string, keywords: [A-Za-z_]\w*\b # 2. Operators: [!\#\\\$%\&\*\+:\-\./ \?@\\\^_\|\~]+ # 3. Tabs, spaces and Brackets: [ \t\(\),;\{\}\[\]`"'] # with the following regex: token_pattern = r"""(\b[A-Za-z_]\w*\b|[!\#\\\$%\&\*\+:\-\./ \?@\\\^_\|\~]+|[ \t\(\),;\{\}\[\]`"'])""" def preprocess(x): """ Clean up single-character variable names or ones constituted of a sequence of the same character """ return pd.Series(x).replace(r'\b([A-Za-z])\1+\b', '', regex=True)\ .replace(r'\b[A-Za-z]\b', '', regex=True) # Pipe steps: # Define a transformer: transformer = FunctionTransformer(preprocess) # Perform TF-IDF vectorization with our token pattern: vectorizer = TfidfVectorizer(token_pattern=token_pattern, max_features=1500) # Create Random Forest Classifier: clf = RandomForestClassifier(n_jobs=-1) pipe_RF = Pipeline([ ('preprocessing', transformer), ('vectorizer', vectorizer)] ) # Setting best params (after performing GridSearchCV) best_params = { 'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_split': 3, 'n_estimators': 300 } clf.set_params(**best_params) # Here I am preprocessing the data: X_train = pipe_RF.fit_transform(X_train).toarray() X_test = pipe_RF.transform(X_test).toarray() # Fitting the model outside the pipe - feel free to show if possible to do it inside the pipe + fit_transform the train and test sets. clf.fit(X_train, y_train) # Evaluation print(f'Accuracy: {clf.score(X_test, y_test)}') user_input = """ def fib(n): a,b = 0,1 while a
