[site]: crossvalidated
[post_id]: 243926
[parent_id]: 243921
[tags]: 
The "usual" result for Markov Chains is the Birkhoff Ergodic Theorem, which says that $$\frac{1}{n}\sum_{i=1}^nf(X_i)\rightarrow E_{\pi}[f],$$ where $\pi$ is the stationary distribution, and $f$ satisfies $E|f(X_1)| Unfortunately the fluctuations of this convergence are generally quite difficult. This is mainly due to the extreme difficulty of figuring out total variation bounds on how quickly $X_i$ converge to the stationary distribution $\pi$. There are known cases where the fluctuations are analogous to the CLT, and you can find some conditions on the drift which make the analogy hold: On the Markov Chain Central Limit Theorem -- Galin L. Jones (See Theorem 1). There are also stupid situations, for example a chain with two states, where one is absorbing (i.e. $P(1\rightarrow 2)=1$ and $P(2\rightarrow 1)=0$. In this case there are no fluctuations, and you get convergence to a degenerate normal distribution (a constant).
