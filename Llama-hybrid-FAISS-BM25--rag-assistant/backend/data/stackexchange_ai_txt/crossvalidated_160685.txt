[site]: crossvalidated
[post_id]: 160685
[parent_id]: 160497
[tags]: 
The answers to the original question are fairly straightforward. For a LASSO fit, the degrees of freedom remaining after the fit are supposed take into account the parameters estimated in the model, but there may be some disagreement about just how to determine Df for LASSO and similar regression approaches. Residual sum of squares, as far as I know, is as with any regression. The $C_p$ statistic is an estimate of the mean-square error in a model based on a selected subset of predictors, corrected for the number of predictors. For a Gaussian linear regression, it's equivalent to the AIC. For variable selection in a way that reliably generalizes beyond your particular data sample, however, you need to do more than perform a single LASSO fit. Typically cross-validation is performed to estimate the prediction error of the model when applied to the underlying population. Performing this at multiple values of the penalty parameter shows the prediction error as a function of the penalty parameter, which in LASSO is effectively the number of predictor variables maintained in the model. You then have to use your knowledge of the subject matter, along with the results of the cross-validations, to select the final model. A plot of cross-validation error versus the penalty parameter is very informative. Typically the model that minimizes the cross-validation error is selected. You indicate that minimizing $C_p$ might be a better choice for the number of cases you have in your example; I haven't thought about this issue. Rather than just relying on a formula, think about other considerations you might have, such as the types of errors you can tolerate and the costs of obtaining information when using your model for predictions. For example, you might have particular considerations for the bias-variance tradeoff inherent in this type of model building. Would you rather have a prediction model that on the average gives the true population value but might have high errors in individual samples (low bias, high variance), or one that has less variability from sample to sample but might have a consistent difference on average from the true population value (higher bias, lower variance)? If you want to minimize the number of variables in the model, you might consider choosing the "least complex model within one standard error of the best" (Fig. 3.7, The Elements of Statistical Learning ). If you have two correlated predictors with one much more expensive to obtain, should the relative costs enter into your variable-selection criteria? Only you can make those types of judgments. Extending this approach to time series, as your last comment indicates, is a bit more difficult and beyond my expertise. Cross-validating time series is not straightforward. See this and this Cross Validated page, or search for lasso time series on this site, for introduction to the issues and some guidance.
