[site]: crossvalidated
[post_id]: 464600
[parent_id]: 
[tags]: 
Markov Chain Converge then Unconverge?

I have a MCMC algorithm for which I know the transition matrix $T(x_{t+1},x_t)$ . If the Markov chain has converged such that $x_{t-1} \sim \pi$ , how do I show that $x_i$ is marginally distributed according to $\pi$ also? My initial reaction is that I don't really understand the question. If the Markov chain has converged to $\pi$ at timestep $t$ then,by definition of convergence, how could it have any distribution other than $\pi$ at timestep $t+1$ ? What do I actually need to do to show this? Is it a case of showing that there is a unique stationary distribution? Or is it detailed balance? I don't really understand what is being asked here. Thanks.
