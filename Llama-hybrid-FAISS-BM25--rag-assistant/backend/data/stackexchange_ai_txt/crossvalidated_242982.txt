[site]: crossvalidated
[post_id]: 242982
[parent_id]: 
[tags]: 
10 fold cross validation: taking the average of the test error or taking the sum?

I have two probabilistic model, $A$ and $B$. I am using MLE to estimate the parameters in both models. Then I run the following 10-fold cross validation. I randomly chopped the data set into 10 chunks, in each iteration, I use MLE to fit the 2 models on the training data set and get my estimates, so I will have 2 training Loglikihoods for 2 models. Then, I apply these 2 models with their estimates of the parameters to the test data set and get 2 test loglikihoods. I go through all 10 iterations, then I could (1) take the average of 10 test loglikihoods for each model, then compare these 2 average; Or I could (2) sum all the 10 test loglikihoods for each model, then compare the sum. I think in order to tell one model is better than the other, both of these 2 methods are equivalent. However, I feel that the first one, i.e., take the average is more meaningful, while the 2nd one (i.e., take the sum) is just mathematically equivalent but not very meaningful. But I couldn't tell why. Can someone provide some comments?
