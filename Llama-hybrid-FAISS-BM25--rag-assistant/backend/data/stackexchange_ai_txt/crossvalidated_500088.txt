[site]: crossvalidated
[post_id]: 500088
[parent_id]: 385713
[tags]: 
From the answer in Deriving Bellman's Equation in Reinforcement Learning , I think we can get at the problem by juggling some of the terms. First, some notation: $G_{t+1}$ is a random variable that can take on values $g \in \Gamma$ . By definition we have the first line here: $$\begin{align} \gamma \mathbb{E}_{\pi}\left[ G_{t+1} | S_t = s \right] & \doteq \gamma \sum_{g \in \Gamma} g p(g|s) & (1)\\ & = \gamma \sum_{r \in \mathcal{R}} \sum_{s' \in \mathcal{S}} \sum_{a \in \mathcal{A}} \sum_{g \in \Gamma} g p(g,s',a,r|s) & (2) \\ & = \gamma \sum_{r \in \mathcal{R}} \sum_{s' \in \mathcal{S}} \sum_{a \in \mathcal{A}} \sum_{g \in \Gamma} g p(g|s',a,r,s) p(s',a,r|s) & (3) \\ & = \gamma \sum_{r \in \mathcal{R}} \sum_{s' \in \mathcal{S}} \sum_{a \in \mathcal{A}} \left( \sum_{g \in \Gamma} g p(g | s') \right) p(s', r | a, s) \pi(a | s) & (4)\\ & = \gamma \sum_{r \in \mathcal{R}} \sum_{s' \in \mathcal{S}} \sum_{a \in \mathcal{A}} \mathbb{E}_{\pi}\left[ G_{t+1} | S_{t+1} = s' \right] p(s', r | a, s) \pi(a | s) & (5) \end{align}$$ The manipulations are as follows: (1) The definition of expectation (2) "un-marginalize" the expectation to include $s'$ , $a$ , and $r$ (3) Use the law of multiplication to manipulate the p() term from line (2) (4) Use the Markovian property to take $p(g|s',a,r,s) = p(g|s')$ , the law of multiplication to change $p(s',a,r|s) = p(s',r|a,s) p(a|s)$ , and adapt to Sutton and Barto's notation with $\pi(a|s) \doteq p(a|s)$ (5) Recognize that, again by definition , that the term in parenthesis on line (4) is $\mathbb{E}_{\pi}\left[ G_{t+1} | S_{t+1} = s' \right]$
