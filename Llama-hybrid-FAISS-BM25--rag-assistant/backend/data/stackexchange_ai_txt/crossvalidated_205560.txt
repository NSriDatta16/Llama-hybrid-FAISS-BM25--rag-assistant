[site]: crossvalidated
[post_id]: 205560
[parent_id]: 204515
[tags]: 
The most common evaluation metric for Multilabel tasks is, I believe, F1-score. There are two variants. Macro F1 is the average F1 score for all labels, while micro F1 score is the average F1 score for all instances predicted.
