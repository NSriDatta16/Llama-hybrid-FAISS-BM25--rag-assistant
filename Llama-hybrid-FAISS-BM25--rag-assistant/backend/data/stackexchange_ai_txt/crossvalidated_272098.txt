[site]: crossvalidated
[post_id]: 272098
[parent_id]: 
[tags]: 
Bootstrap estimate for standard error in linear regression

I came across the bootstrap concept in the book Introduction to statistical learning, wherein the standard error for the linear regression coefficients is estimated both by the formula and the bootstrap process, and then following this paragraph (page 196): Now although the formula for the standard errors do not rely on the linear model being correct, the estimate for $\sigma^2$ does. We see [...] that there is a non-linear relationship in the data, and so the residuals from a linear fit will be inflated, and so will $\hat\sigma^2$. [...] The bootstrap approach does not rely on any of these assumptions, and so it is likely giving a more accurate estimate of the standard errors of $\hat\beta_0$ and $\hat\beta_1$ than is the summary() function. [Emphasis added.] So my question is why are the assumptions reducing the reliability or accuracy of the estimates? Because more is the residual error more is your standard error of estimates (indirectly due to inflated $\hat\sigma^2$) this assumption doesn't seem wrong to me.
