[site]: crossvalidated
[post_id]: 559914
[parent_id]: 
[tags]: 
Minimizing hard and soft margin objective functions in a one dimensional SVM

Given a one dimensional training dataset with 3 points, 2 negative points at -1 and 1, and a positive point at 0(as in the picture above): (a) What solution would minimize the linear Hard Margin SVM objective function on the data? Is there more than 1 solution? (b) Derive a solution to the linear soft margin SVM primal and dual objective functions for the dataset. For (a), since it's a hard margin objective function, no possible value seems to solve the objective (Unless we happen to ignore misclassified points, but the hard margin objective function doesn't allow that) For (b) I'm not sure how to proceed from the dual form of the objective function.
