[site]: crossvalidated
[post_id]: 606392
[parent_id]: 
[tags]: 
What's the difference between a Permutation and a Perturbation?

I frequently come across the terms Permutation and Perturbation within the field of explainable AI. I understand that both terms refer to methods that make changes to a sample's features. However, I'm not certain of the difference between the two. From mathematics, a permutation is a rearrangement of elements in a set. This makes me think permutation methods draw their changes from other samples in the dataset. From physics, a perturbation is a minor change to a model that disturbs its usual output. This makes me think perturbation methods can make any change to the sample regardless of what values are held in other samples. If that's true then permutation methods would be special cases of perturbation methods. Have I got this right, or is there more to the distinction? Example situation To avoid confusion, consider the example of a single sample, which is part of a highly localised dataset. The high locality of the dataset implies there are many other samples nearby. Permutation will therefore produce samples close to the single sample. Similarly, perturbing the single sample will produce multiple samples close to the dataset. In this situation it's possible the two methods would produce overlapping samples, the only difference being the permutation samples are more restricted than the perturbation samples. In the above example, wouldn't that make permutation a special case of perturbation? Related What is perturbation in Machine Learning? Permutation Feature Importance
