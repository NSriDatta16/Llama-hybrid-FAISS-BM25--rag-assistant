[site]: crossvalidated
[post_id]: 244018
[parent_id]: 
[tags]: 
How to compare multivariate forecasting methods?

Let $X$ be a multivariate time series of $N$ variables and $T$ observations. Let split $X$ into two separate datasets : $X_{train}$ : a train set with $N$ variables and $T_{train}$ observations $X_{test}$ : a test set with $N$ variables and $T_{test}$ observations We train different forecasting methods ($k$-NN, $VAR$, etc.) on $X_{train}$. Then, for each method, we perform a one step forecast on $X_{test}$. We then want to compare the forecasting performance of the different methods. We could compute the RMSE for each variable, but given the differences in amplitude between variables: we cannot average the RMSE over the variables in order to get a unique score for each method. I thought of two alternatives: compute MASE instead of RMSE for each forecasting methods, count the number of variables for which it has (strictly or almost) the lowest RMSE. Do you know other ways to compare forecasting performance of several methods â€“ either in a quantitative manner like I did or in a more qualitative manner? The number of variables is high (~600); this is why I tried to summarize the results into a single evaluation criterion.
