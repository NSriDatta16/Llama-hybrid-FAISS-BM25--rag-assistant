[site]: datascience
[post_id]: 73267
[parent_id]: 31173
[tags]: 
Great question, and yes it is possible (as you alluded in point #2) to re-weight your loss function to accomplish your objective. In fact, training on a subsample is a special case of this. However, we’ll first have to assume that your loss function is additively-separable (which is the case for 95% of popular machine learning models). Let’s say your loss function is $f$ and your model parameter is $x$ . Then, to get your optimal model parameter $x_*$ , you would solve the problem $$x_* = \text{argmin}_x f(x)$$ Now let’s say $f$ is additively-separable $$f(x) = \sum_i^n f_i (x)$$ where $i$ indexes observations from your data set—this is the case for linear regression, logistic regression, SVM, and many more. Well, it naturally follows that $$x_* = \text{argmin}_x f(x) = \text{argmin}_x \sum_i^n f_i(x) = \text{argmin}_x \sum_i^n \alpha_i f_i(x)$$ where $\alpha_i = 1$ for all $i$ . You can think of $\alpha_i$ being the importance of the $i^{th}$ observation: as $\alpha_i$ gets larger, you are essentially biasing the parameter $x_*$ towards that observation. In fact, if you set $\alpha_i$ negative, then observation $i$ is now treated as a counterexample for the model. And when $\alpha_i$ is set to 0, it’s as if you trained your model without observation $i$ included—a special case of withholding data from the model as mentioned in other answers. You can manipulate the set of weights $\{\alpha_i\}_1^n$ if you have reason to believe that not all observations in your dataset are equally important. A real world example would be setting $\alpha_i$ proportional to the monetary losses caused by some fraudulent event. Then the model isn’t just trying to accurately predict fraud, but moreso to accurately predict costly fraud events.
