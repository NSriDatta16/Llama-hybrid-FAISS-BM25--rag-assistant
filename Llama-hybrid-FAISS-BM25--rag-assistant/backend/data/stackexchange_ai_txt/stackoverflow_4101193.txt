[site]: stackoverflow
[post_id]: 4101193
[parent_id]: 4096861
[tags]: 
1 . Is F# an appropriate tool for HPC computations on such servers? It (F#), as a language, can encourage code which works well in parallel -- at least part of this is a reduction of state mutability and higher-order functions -- this is a can and not a will . However, with HPC there are many specialty programming languages/compilers and/or ways of load distribution (e.g. shared unified memory or distributed micro-kernels). F# is merely a general-purpose programming language: it may or may not have access (e.g. bindings may or may not exist) to the various techniques. (This applies even to non-distributed parallel computing.) 2 . Is it realistic to use up to 100% of CPU for a real world problem? It depends on what the limiting factor is. Talking to my friend who does 5k+ 100k+ core HPC research and development, the exchange of data and idle times are normally the limiting factor (of course, this is a much higher n :-) and so even small improvements in IO reduction (efficiency or different algorithm) can lead to significant gains. Don't forget the cost of simply moving data between CPUs/caches on the same machine! And, of course, the ever-slow disk IO... 3 . What should I do to obtain a high speed up? Everything is in one big parallel for loop so I would expect that it is all what I should do... Find out where the slow part(s) is(are) and fix it(them) :-) E.g. run a profile analysis. Keep in mind it may require using an entirely different algorithm or approach. 4 . If F# is NOT an appropriate language, what language is? While I am not arguing for it, my PhD friend uses/works on Charm++ : it is a very focused language for distributed parallel computing (not the environment in question, but I'm trying to make a point :-) -- F# tries to be a decent general-purpose language.
