[site]: datascience
[post_id]: 71919
[parent_id]: 71908
[tags]: 
Generally, the notation $\mathbb{E}_{x\sim p}f(x)$ or $\mathbb{E}_{x\sim p(x)}f(x)$ refers to the expectation of $f(x)$ with respect to the distribution $p$ for variable $x$ (e.g. see the explanation in the notation section in "Pattern Recognition and Machine Learning" by Bishop). In the context of GANs, it means that for an objective function such as $$\mathbb{E}_{x\sim p_{data}(x)}[logD(x)] + \mathbb{E}_{z\sim p_z(z)}[log(1 - D(G(z)))]$$ the first summand is the expectation with regards to $x$ coming from the data and the second summand is the expectation with regards to $z$ which you sample from $p_z$ as an input for G. Since the first summand stands for correctly classified real data (coming from $p_{data}$ ) and the second summand stands for correctly as fake classified images coming from G using $z$ sampled from $p_z$ , D tries to maximize this expression. And G does the opposite.
