[site]: crossvalidated
[post_id]: 536011
[parent_id]: 
[tags]: 
How does one ensure Machine Learning doesn't come to correct classifications via the wrong ways?

I got good results on a radiation exposure prediction problem using SVM and DT where the ultimate goal is to predict the radiation dose an individual was exposed to using data about individual related to their health. Overall, the feedback was positive but one comment was interesting to me: How does one ensure Machine Learning doesn't come to correct classifications via the wrong ways? How did you exclude this? I took all the necessary precautions to make sure things like class imbalance, overfitting, etc. weren't an issue, so I'm certainly under the impression this is more related to the fundamentals of the field rather than an ML methodology question. How would one begin to approach this question from an ML perspective where I feel the answer basically boils down to the fact that, after doing all necessary procedures that can be done to optimize model performance (regularization, cross validation, etc.), there is no such thing as "coming to the right classifications the wrong way"? I feel like this is actually a question that needs a good answer for any technical communication to audiences perhaps not as conversant with ML in general (or who perhaps are but want to hear our thoughts nonetheless).
