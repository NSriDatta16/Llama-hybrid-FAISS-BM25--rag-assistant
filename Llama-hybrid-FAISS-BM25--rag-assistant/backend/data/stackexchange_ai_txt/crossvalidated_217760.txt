[site]: crossvalidated
[post_id]: 217760
[parent_id]: 217755
[tags]: 
Your code doesn't do what you think it does because: you put some exogenous variable ClassResids instead of Data in your call to np.transpose() . you are multiplying by np.sqrt(w[0]) which is not necessary. v[:, 0] is equal to facs[0, :] np.linalg.eig() doesn't return eigenvectors in any particular order, but the scikit pca() method does. That means that the elements of v will be the same as the elements of facs , but the arrangement of the matrices will be different. PCA decompositions of these types are invariant to sign-flips on all the eigenvalues. This code (which btw is reformatted to conform to python standards by lowercasing variable names and using spaces around commas and operators) does what I think you want. import numpy as np from sklearn.decomposition.pca import PCA def test_pca_eigenvector_equivalence(seed, n_dim = 2): """ Determine if np.linalg.eig returns the same results as sklearn PCA method. """ def almost_equal(arr1, arr2): return np.all(np.isclose(arr1, arr2)) def sorted_abs_elements(arr): return np.sort(np.abs(arr.reshape(-1))) np.random.seed(seed) data = np.random.rand(50, n_dim) pca = PCA() pca.fit(data) w, v = np.linalg.eig(np.cov(data.transpose())) # test matrix equivalence: do matrices have the same elements at each position matrix_equivalence = almost_equal(pca.components_, v.transpose()) # test element equivalence: is a sorted 1D list of absolute values of elements the same? elements_v = sorted_abs_elements(v) elements_pca = sorted_abs_elements(pca.components_) element_equivalence = almost_equal(elements_v, elements_pca) return matrix_equivalence, element_equivalence seed_list = range(10) [test_pca_eigenvector_equivalence(s) for s in seed_list] The output is: [(False, True), (True, True), (False, True), (False, True), (False, True), (False, True), (False, True), (False, True), (False, True), (True, True)] So for 10 random tests of 2-dimensional data, the v and facs matrices were precisely identical two times. However, every time, no matter what the random data used was, the elements of v were the same as the elements of facs (except for possible sign changes).
