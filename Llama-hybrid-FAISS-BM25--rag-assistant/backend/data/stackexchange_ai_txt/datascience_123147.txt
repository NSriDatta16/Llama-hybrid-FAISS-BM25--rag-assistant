[site]: datascience
[post_id]: 123147
[parent_id]: 
[tags]: 
How would you treat imbalanced training data, and you don't know how test data distribution looks like in deep learning?

I posted this question on another place, but I want to get many tips, so I post here too. I am building deep learning classification model in bioinformatics. I made training dataset by merging 12 datasets, each dataset has some common features, and some common label, and there are uncommon features and labels. So I outer-joined the data for training. But this training data is quite imbalanced itself (31%, 20%, 15%, 7%, 6%, 1%, ... 0.1 % for each class), this is quite challenging to me already, but even more, I can't even suppose test dataset's distribution (which means test dataset or real-world data that I should predict can be very different from training dataset distribution of class, as far as I know deep learning classification model trained by specific distribution can predict well if only data to predict has same distribution.), test dataset now I am using is quite imbalanced, has different distribution compared to training dataset, even more some of labels are missing. What kind of approach, and deep learning model should I take? Or is there any good paper for these kind of problems?
