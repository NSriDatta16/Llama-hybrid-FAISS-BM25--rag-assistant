[site]: crossvalidated
[post_id]: 494047
[parent_id]: 
[tags]: 
Model Architectures for functional graph or data series type data regression problems using PyTorch, FastAi or TensorFlow

For a university assignment, I am currently trying to build an optical sensor to supervise chemical reactions in pipes. Two sensors are installed in the pipe, around 1mm apart from each other, and depending on the contents of the pipe they will yield a float value with a frequency of 1kHz. I am planning to bin the measurements of both sensors for 5 seconds in a 2 x 5000 tensor (real-time, continuous feed would be even better) and feed that into a neural network to yield the desired interpreted values. So basically, the feed data are two graphs of values plotted against the time axis. The desired output parameters are the average length of detected peaks, the distance between peaks, and the average time offset between the two graphs - in other words, 3 float type outputs. I am relatively new to machine learning, but I know this should be a type of problem a GNN is most fit to solve, probably... The focus of every guide or tutorial I could find is mostly image-based CNN's or tabular regressions. So far I have checked the TensorFlow, PyTorch, and FastAi documentation because I would like to use one of these to solve the problem, but could not find anything related. As a beginner, I would be thankful for any suggestions regarding the libraries, API, models/ architectures used, as well as recommendations of suitable guides and tutorials regarding Graph type multi-label regression problems. Comment: I know this could also be solved using regular code or integrated circuits, this is part of a machine learning project though and one of the main goals is to compare the computational and material effort the ML approach requires to the traditional way of supervising such systems. So, please only suggest solutions involving machine learning! Edit: as Shimao pointed out, I was confusing the type of graphs (networks) that GNN's run on with functional graphs. So far I have figured out that an LSTM (Long Short Term Memory) incorporating NN would probably yield the best results and seem to be the norm for time-series like data. I would not even need to bin my data and could just feed it as simple tabular data if I understand it correctly, since the time variable is stored in the LSTM Layer. I would be thankful for any input concerning this idea.
