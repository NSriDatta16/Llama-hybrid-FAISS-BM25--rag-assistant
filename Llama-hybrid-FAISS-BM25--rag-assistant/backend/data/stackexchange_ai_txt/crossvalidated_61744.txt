[site]: crossvalidated
[post_id]: 61744
[parent_id]: 61740
[tags]: 
The link in question talks about SAS too. But in fact nothing in this question, except possibly the poster's own focus, limits it to those particular named programs. I think we need to separate out quite different kinds of problem here, some of which are illusory and some of which are genuine. Some programs do, and some do not, subtract 3 so that the kurtosis measure reported is 3 for Gaussian/normal variables without subtraction and 0 with subtraction. I have seen people puzzled by that, often when the difference turns out to be say 2.999 and not exactly 3. Some programs use correction factors designed to ensure that kurtosis is estimated without bias. These correction factors approach 1 as sample size $n$ gets larger. As kurtosis is not well estimated in small samples any way, this should not be of much concern. So, there is a small issue of formulas, #1 being a much bigger deal than #2, but both minor if understood. The advice clearly is to look at the documentation for the program you are using, and if there is no documentation explaining that kind of detail to abandon that program immediately. But a test case as simple as a variable (1, 2) yields kurtosis of 1 or 4 depending on #1 alone (with no correction factor). The question then asks about interpretation, but this is a much more open and contentious matter. Before we get to the main area of discussion, an often reported but little known difficulty is that kurtosis estimates are bounded as a function of sample size. I wrote a review in Cox, N.J. 2010. The limits of sample skewness and kurtosis. Stata Journal 10(3): 482-495. http://www.stata-journal.com/article.html?article=st0204 Abstract: Sample skewness and kurtosis are limited by functions of sample size. The limits, or approximations to them, have repeatedly been rediscovered over the last several decades, but nevertheless seem to remain only poorly known. The limits impart bias to estimation and, in extreme cases, imply that no sample could bear exact witness to its parent distribution. The main results are explained in a tutorial review, and it is shown how Stata and Mata may be used to confirm and explore their consequences. Now to what is commonly regarded as the nub of the matter: Many people translate kurtosis as peakedness, but others emphasise that it often serves as a measure of tail weight. In fact, the two interpretations could both be reasonable wording for some distributions. It is almost inevitable that there is no simple verbal interpretation of kurtosis: our language is not rich enough on comparisons of sums of fourth powers of deviations from the mean and sums of second powers of the same. In a minor and often overlooked classic, Irving Kaplansky (1945a) drew attention to four examples of distributions with different values of kurtosis and behaviour not consistent with some discussions of kurtosis. The distributions all are symmetric with mean 0 and variance 1 and have density functions, for variable $x$ and $c = \sqrt{\pi}$, $(1)\ \ \ (1 / 3c) (9/4 + x^4) \exp(-x^2)$ $(2)\ \ \ (3 / (c \sqrt8)) \exp(-x^2 / 2) - (1 / 6c) (9/4 + x^4) \exp(-x^2)$ $(3)\ \ \ (1 / 6c) (\exp(-x^2 / 4) + 4 \exp(-x^2))$ $(4)\ \ \ (3 \sqrt3 / 16c) (2 + x^2) \exp(-3x^2 / 4)$ The kurtosis (without subtraction) is (1) 2.75 (2) 3.125 (3) 4.5 (4) 8/3 $\approx$ 2.667: compare the Gaussian or normal value of 3. The density at the mean is (1) 0.423 (2) 0.387 (3) 0.470 (4) 0.366: compare the Gaussian value of 0.399. It's instructive to plot these densities. Stata users can download my kaplansky program from SSC. Using a logarithmic scale for density may help. Without giving away the full details, these examples undermine any simple story that low or high kurtosis has a clear interpretation in terms of peakedness or indeed any other single contrast. If the name Irving Kaplansky rings a bell, it is likely because you know his work in modern algebra. He (1917-2006) was a Canadian (later American) mathematician and taught and researched at Harvard, Chicago and Berkeley, with a wartime year in the Applied Mathematics Group of the National Defense Council at Columbia University. Kaplansky made major contributions to group theory, ring theory, the theory of operator algebras and field theory. He was an accomplished pianist and lyricist and an enthusiastic and lucid expositor of mathematics. Note also some other contributions to probability and statistics by Kaplansky (1943, 1945b) and Kaplansky and Riordan (1945). Kaplansky, I. 1943. A characterization of the normal distribution. Annals of Mathematical Statistics 14: 197-198. Kaplansky, I. 1945a. A common error concerning kurtosis. Journal, American Statistical Association 40: 259 only. Kaplansky, I. 1945b. The asymptotic distribution of runs of consecutive elements. Annals of Mathematical Statistics 16: 200-203. Kaplansky, I. and Riordan, J. 1945. Multiple matching and runs by the symbolic method. Annals of Mathematical Statistics 16: 272-277.
