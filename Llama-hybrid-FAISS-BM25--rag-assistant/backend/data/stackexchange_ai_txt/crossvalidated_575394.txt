[site]: crossvalidated
[post_id]: 575394
[parent_id]: 575375
[tags]: 
The standard counting-process setup used to handle time-varying covariate values works here in principle , as that also represents left-truncated starting times with events or right censoring at the end of the time period. That is, with the construction Surv(startTime,stopTime,status) , the startTime is considered left truncated and status represents either an event or censoring at stopTime . I'm not sure that's a good idea in your case, however. First, when you use birth as time = 0 and have left-truncated survival times, you can get very weird results. Unlike a more typical survival model with everyone at risk at time = 0 , only those with the earliest entry dates are at risk at the earliest event times. It's even possible to have survival curves drop to 0 if those early-entry cases have events before others enter the risk set at later ages. See Section 4.6 of Klein and Moeschberger . They suggest: Rather than estimating the unconditional survival function, we estimate the conditional probability of surviving beyond age t , given survival to age a . An alternative that I would tend to prefer would be to use age at inclusion as a covariate (modeled flexibly with a regression spline) and using time since inclusion as your time to event or right censoring. If inclusion was based on a clinical diagnosis of the disease near the time of inclusion, that would make sense. For example, that's how age is typically handled in cancer survival studies. You'll have to apply your understanding of the subject matter to decide if that makes sense for you. Second, if you only have 5 follow-up times then a Cox model assuming continuous time probably isn't a wise choice. If the evaluation of the "ability decline" event is only made at follow-up times, then your event times are themselves interval censored: you only have lower and upper limits for the actual elapsed time from time = 0 to the event. If the 5 follow-up intervals are the same for all individuals (e.g., every 6 months), you might use a discrete-time survival model, which is essentially a set of binary regressions. With your paired data that might be done via a set of conditional logistic regressions (which end up being solved with Cox survival routines for stratified data via the clogit() function), but I haven't thought that through carefully. Otherwise you need to use a model that handles interval-censored survival data. The standard R survreg() function can handle interval censoring in a parametric survival model. The R icenReg package provides additional ways to handle interval censoring, although I'm not sure how it handles things like your clusters. The package vignette explains interval censoring pretty clearly and shows examples; the package author also visits this site. Third, consider whether an all-or-none "ability decline" event designation is the best way to proceed. "Ability decline" is typically a process graded over time. Modeling a quantitative measure of "ability" over time could be much more powerful and informative.
