[site]: crossvalidated
[post_id]: 550033
[parent_id]: 549432
[tags]: 
Look once more at the model definition, in the simplest case, it predicts the rating for $u$ -th user and $i$ -th item $\hat r_{ui}$ using $$ \hat r_{ui} = f(\boldsymbol{q}_u \cdot \boldsymbol{p}_i + b_u + b_i) $$ where $\boldsymbol{q}_u$ and $\boldsymbol{p}_i$ are latent representations per user and item, while $b_u$ and $b_i$ are bias terms. Bias term for user $b_u$ is the "default" or "average" rating the user gives, bias term for the item is the "default" rating for the item. Notice that the part $\boldsymbol{q}_u \cdot \boldsymbol{p}_i$ depends on the interaction of a particular user with a particular item, it tells you how well does the item matches the person. On another hand, $b_u$ is the base rating by the user regardless of everything else, and $b_i$ is the base rating for the item regardless of everything else. If the latent representations for user and item are orthogonal, $\boldsymbol{q}_u \cdot \boldsymbol{p}_i$ would be equal to zero, so the rating would reduce to $f(b_u + b_i)$ . To give an example, say that you are Netflix and your user Bob likes watching sci-fi movies, so a romantic comedy probably would not be a great fit for him. On another hand, if it is a multi-category Oscar winner, so it may make sense to "bump" the predicted rating by the fact that the movie has a very high average rating $b_i$ . Another user, Anna is very critical and rarely gives thumbs-up to the movies, so $b_u$ would be negative for her, always decreasing the predicted ratings by a constant. Additionally, same as in linear regression , intercepts improve the numerical stability of the algorithm and are beneficial when training the model. Including additional features, such as metadata, does not change the interpretation.
