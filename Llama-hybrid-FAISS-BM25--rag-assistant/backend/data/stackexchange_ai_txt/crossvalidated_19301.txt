[site]: crossvalidated
[post_id]: 19301
[parent_id]: 17800
[tags]: 
To sum up the long series of comments: Yes, your working is correct. More generally, if $X$ and $Y$ are independent normal random variables with means $\mu_X$ , $\mu_Y$ respectively and variances $\sigma_X^2$ and $\sigma_Y^2$ respectively, then $aX+bY$ is a normal random variable with mean $a\mu_X+b\mu_Y$ and variance $a^2\sigma_X^2 + b^2\sigma_Y^2$ . The various comments by whuber, cardinal, myself, and the Answer by Tai Galili are all occasioned by the fact that there are at least three different conventions for interpreting $X \sim N(a,b)$ as a normal random variable. Usually, $a$ is the mean $\mu_X$ but $b$ can have different meanings. $X \sim N(a,b)$ means that the standard deviation of $X$ is $b$ . (This is the convention you are using). $X \sim N(a,b)$ means that the variance of $X$ is $b$ . (Some people write $b$ as $\left(\sqrt b \right)^2$ to emphasize that the second parameter is the variance, not the standard deviation). $X \sim N(a,b)$ means that the variance of $X$ is $\dfrac{1}{b}$ . (In a comment on the Question, Moderator whuber says that $b$ is called the precision, especially in a Bayesian context, and is often written as $\dfrac{1}{\sigma^2}$ where $\sigma$ denotes the standard deviation). Fortunately, $X \sim N(0,1)$ (which is what you asked about) means that $X$ is a standard normal random variable in all three of the above conventions!
