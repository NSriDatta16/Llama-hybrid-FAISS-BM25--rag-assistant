[site]: crossvalidated
[post_id]: 323403
[parent_id]: 
[tags]: 
How can Precision-Recall (PR) curves be used to judge overall classifier performance when Precision and Recall are class based metrics?

How can Precision-Recall (PR) curves be used to judge overall classifier performance when Precision and Recall are class based metrics? Since in a binary classifier, there are two classes, often labelled positive (+1) and negative (-1). Yet, the classifier performance metrics [y] precision (PPV) and [x] recall (TPR) which are used to plot PR curves can have different values for each of the two classes (if you swap the positive and negative classes). In almost all examples of PR curves, there is usually only a single curve, when there should surely be at least two curves (one curve per class)? More specifically: Does the PR curve really only represent the precision and recall of a single class, or has some operation been done (e.g. averaging) to combine the precision and recall of both classes? Does it make sense to judge a classifier's performance based on only looking at the PR curve for the positive class? Why are the metrics TNR and NPV not somehow integrated into the curve or graph, for a better overview of classifier performance?
