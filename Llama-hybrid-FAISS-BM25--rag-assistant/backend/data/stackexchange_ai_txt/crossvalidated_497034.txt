[site]: crossvalidated
[post_id]: 497034
[parent_id]: 497031
[tags]: 
Considering this came up in a work context, perhaps there was some confusion on what the goal of the analysis was. If the goal is to identify who to market to people likely to click -- as in the case of uplift analysis or similar-- then a predictive model should be fine. In uplift, the goal is to target only those people who are likely to open the email/click the ad/whatever. The mechanism of why they clicked is irrelevant. You just want to know who is most likely to click and that is a prediction problem. If, however, the goal is to take a customer who is unlikely to click intervene on them in such a way to cause them to click the ad, then a causal approach is needed. "Data-driven recommendations to improve customer experience " seems causal to me, at least in the way you're written it, so I'm willing to think this is the context we find ourselves in. OK, but that doesn't answer the question. Why should we draw dags and do our causal analysis this way rather than just throw everything in a regression model? Richard McElreath gives some pretty compelling examples of why "Causal Salad" -- his pejorative name for throwing everything in a linear or machine learning model -- doesn't work. In chapters 5 & 6 of Statistical Rethinking, Richard gives several examples through simulation in which the true causal mechanism is poorly estimated when you don't draw the dag. I won't take the time to regurgitate those examples here as I wouldn't do them justice. Suffice to say, you can very easily think your intervention is helpful when in reality it is hurtful if you don't take the time to draw your assumptions before your conclusions. So your approach is technically wrong, but the danger is presently unknown. For example, assume you estimated a positive treatment effect but in reality the effect was null. Nothing gained, nothing lost -- except money.
