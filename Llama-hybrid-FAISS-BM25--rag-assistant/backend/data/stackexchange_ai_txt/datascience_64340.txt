[site]: datascience
[post_id]: 64340
[parent_id]: 
[tags]: 
How do I interpret loss in a neural network?

I am studying how to evaluate the performances of a convolutional neural network, and in particular I have seen that we have to look both at accuracy and loss. I don't understand why do we have to look also at the loss, and honestly I haven' t understand really clearly what the loss is. I have understood that it is something that we want to minimize and the lower the loss, the better the performances are. But also I have seen that if the loss is to low we are overfitting, and also that there is a sort of relationship between loss and accuracy, but I have not clear what it really means. To me this loss concept and how to interpret it both alone and with respect to the accuracy seems an abstract concept at the moment. Can somebody help me clarify this concepts? Thanks in advance. [EDIT] For example, I obtain this plot : How do I interpret this? From what I can see, it seems that the loss decreases both for train set and test set at the same rate, and we have that if this happens the model is good, otherwise we encouter overfitting or also underfitting. But I don't understand, why we have this? So why if the are close and decrease at same pace we are doing well, otherwise not? Thanks.
