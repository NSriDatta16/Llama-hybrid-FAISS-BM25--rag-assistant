[site]: crossvalidated
[post_id]: 581846
[parent_id]: 
[tags]: 
Optimal combination of correlated estimations

Consider two random unbiased estimates $\hat X_1,$ , $\hat X_2$ of a parameter (complex number) $x$ , with estimation errors $E_1 = \hat X_1-x$ , $E_2 = \hat X_2-x$ . If the random variables $E_1$ , $E_2$ are i.i.d. , it is well known that averaging the two estimates, $\hat X = (X_1+X_2)/2$ , achieves a smaller error variance (by a factor 1/2) than that of $\hat X_1$ or $\hat X_2$ . If $E_1$ , $E_2$ are independent with different variances , the linear combination $\hat X = w_1 X_1 + w_2 X_2$ that minimizes the error is no longer given by $w_1, w_2=1/2$ , but it is easy to compute the optimal weights in terms of the error variances. This is also well known, I think. Lastly, if $E_1$ , $E_2$ are correlated with covariance matrix $\mathbf C$ , I have obtained the weights that minimize the error variance, subject to the condition that $\hat X$ retains unbiased. Specifically (unless I have made some mistake), $$ w_1 = \frac{C_{22} - \mathrm{Re}\, C_{12}}{C_{11}+C_{22}-2\,\mathrm{Re}\, C_{12}}, \\ w_2 = \frac{C_{11} - \mathrm{Re}\, C_{12}}{C_{11}+C_{22}-2\,\mathrm{Re}\, C_{12}}, $$ where " $\mathrm{Re}$ " denotes "real part"; and the variance of the resulting error is indeed smaller than that in each individual estimate. My question is: is this result for the correlated case well known? Is there some theorem , perhaps generalizing this to more than $2$ estimates? Or any name or pointer I could use to search for this? I want to use this result, and I would rather reference it if possible than reinvent the wheel.
