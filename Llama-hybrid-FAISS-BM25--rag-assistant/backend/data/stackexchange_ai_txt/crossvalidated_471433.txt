[site]: crossvalidated
[post_id]: 471433
[parent_id]: 471323
[tags]: 
@Tim has given a useful link to show you that there are several possible distributions other than normal that could give the same max, min, mean, and SD as for your mystery dataset of size 20. However, real data aren't likely to have many of the distributional shapes in that link. If you're familiar with data types in the particular field involved, you might know whether the normal distribution is a reasonably good bet. Normal populations are symmetrical and the often produce random samples that are also symmetrical. So if $\bar X$ is near to the midrange $(\max + \min)/2.$ then that would be typical of a normal distribution. (Other distributions too of course, but they may occur less commonly in your field.) Two questions with possibly helpful answers: In a normal sample of size 20, how many standard deviations apart are $\bar X$ and the midrange likely to be? Call this number d . If this matches your sample, that might be a clue you data is normal. In a normal sample of size 20, what is the ratio of the range to the standard deviation? Call this number k . If this matches you sample, that's another favorable clue. We can get a rough answers to both questions by simulation. (Since all normal distributions have fundamentally the same shape, We can simulate using standard normal distributions and get a general answer.) Let's look at a matrix with 100,000 rows, each row a standard normal sample of size 20. set.seed(610) # for reproducibility m = 10^5; n = 20; x = rnorm(m*n) MAT = matrix(x, nrow = m) a = rowMeans(MAT) # sample means mx = apply(MAT, 1, max) mn = apply(MAT, 1, min) mr = (mx + mn)/2 rg = mx - mn sd = apply(MAT, 1, sd) d = abs(mr - a)/sd summary(d); quantile(d, .8) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.0000048 0.0942946 0.2010860 0.2418298 0.3470557 1.3465423 80% 0.3885165 k = rg/sd summary(k); quantile(k, c(.1,.9)) Min. 1st Qu. Median Mean 3rd Qu. Max. 2.531 3.496 3.758 3.785 4.046 5.580 10% 90% 3.288026 4.323373 par(mfrow=c(1,2)) hist(d, prob=T, col="skyblue2") hist(k, prob=T, col="skyblue2") par(mfrow=c(1,1)) Here are histograms of the simulated values of $d$ and $k$ for normal samples of size 20. So now you have a possibly normal sample of size 20 with min=110, max=160. Suppose also that $\bar X = 140$ and $S = 13.2.$ Then I have $d = (140 - 135)/13.2 = 0.38$ and $k = 50/13.2 = 3.8.$ Our $d$ is not terribly far above average for normal data, and our $k$ is just about average for normal data. Having "reasonable" values of $d$ and $k$ is certainly not 'proof' that the data are normal. However, 'passing' normality tests such as a Shapiro-Wilk test is also not proof of normality. Admittedly, maybe failing to reject a S-W test may be a better indication than my method with $d$ and $k,$ but even in ideal circumstances where you have all the data, you're never going to know for sure. And knowledge from your field which kinds of data are often normal is an important consideration. Sometimes when a researcher wonders whether data are normal, it's OK to say they're "near enough" to normal for the purpose at hand. However, for your purpose, you really might like to be sure a normal distribution is a good fit. You say you want to do simulations with the distribution to "find the probability of drawing a particular sample at least this large." I'm not sure what you mean by that. If you want to test the null hypothesis something like $\mu \ge 130$ against the one sided alternative that $\mu then you could use the given $\bar X$ and $S$ to do a t test: the test statistic would be $T = \frac{\bar X - 130}{S/\sqrt{n}} = \frac{10}{13.2/\sqrt{10}} = 3.388$ and you would not reject the null hypothesis. However, if you want to know the chances of getting a maximum value greater than 160 from the next dataset, then you might use $\mathsf{Norm}(\mu = 140, \sigma = 13.2)$ as a guide and compute the probability as about 6.5%, and I wouldn't want to bet much based on that computation, because extreme values such as the maximum are very sensitive to the exact shape of the distribution. . 1 - pnorm(160, 140, 13.2) [1] 0.06486702
