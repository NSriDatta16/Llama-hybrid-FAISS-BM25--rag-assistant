[site]: crossvalidated
[post_id]: 512590
[parent_id]: 512580
[tags]: 
Hello and welcome to the community :-) GridSearch searches the best estimator. Period. Thats the fundamental difference between RandomizedSearchCV and GridSearchCV ... and why GridSearch takes so awkwardly long. It may be that you will get slightly different params when using different random states, but all in all a pipeline and the hyperparameter tuning is just for finding your optimal combination of parameters. After that you tak these combinations AND FIT 1.) on the whole data for deployment 2.) Train_data for deployment The latter makes sense, if data is massive and neural network is so complex that training takes a considerable amount of time (e.g. imagine you get new data for a complex NN and get new data points e.g. 1.000.000 you won't fit your model every week, that too exhaustive.) and you dont want to get the well other 10-20% also into the set, that is if you have e.g. 1.000.000 data points, the other few percent wont budge the model at the end so hard, that train data may be enough, but it depends on the case/model. So all the guy does is using the optimal combination and fitting on the whole data, which is some sort of get my final results for deployment. If you predict with this line, you will get the best predict from gridsearch +/- a slightly deviation depending on random_state in the previous pipeline
