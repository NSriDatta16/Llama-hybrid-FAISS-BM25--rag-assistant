[site]: datascience
[post_id]: 118775
[parent_id]: 
[tags]: 
How do I improve the accuracy of a BERT-based multilabel text classification model?

I have a database table with 79,512 rows, each of which describes a category. Each row has a title and a description, and can even have a supercategory. Often, supercategories have categories. I'm trying to train a model to predict each category's supercategory, to be used in a later model that will categorize other data. However, I never get more than a 20% accuracy on this model. My target is 84% accuracy. These are multilingual datasets I am working with, so the pretrained model I use is also multi-lingual. However, it is also case-sensitive. By my count, there are an average 9.86 supercategories per category. How do I improve the accuracy? EDIT: I suppose I had better clarify: There is a wide variety of languages here, none of them comprising more than 50% of the whole dataset. Perhaps I should translate the data?
