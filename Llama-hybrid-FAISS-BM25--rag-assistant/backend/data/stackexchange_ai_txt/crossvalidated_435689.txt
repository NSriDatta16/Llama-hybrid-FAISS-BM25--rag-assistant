[site]: crossvalidated
[post_id]: 435689
[parent_id]: 
[tags]: 
what does mixture mean in the context of Gaussian Naive Bayes classifier?

This CMU Machine Learning Text Book is talking about naive bayes. Of course we must also estimate the priors on Y as well $Ï€_k = P(Y = y_k)$ The above model summarizes a Gaussian Naive Bayes classifier, which assumes that the data X is generated by a mixture of class-conditional (i.e., dependent on the value of the class variable Y) Gaussians. Does mixture here mean is a Gaussian mixture model, which is a probabilistic model that assumes all the data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters?
