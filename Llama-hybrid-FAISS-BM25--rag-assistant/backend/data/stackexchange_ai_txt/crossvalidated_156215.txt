[site]: crossvalidated
[post_id]: 156215
[parent_id]: 
[tags]: 
Modelling time varying volatility when GARCH(1,1) coefficients sum to value greater one

First of all I have to admit that I am not a time-series expert so any help is highly appreciated. I have a financial time-series (a fixed income total return index measured on a weekly basis) for which I would like to fit an AR model. However, I would like to take into account the time varying volatility of the series. In particular, the volatility of the series is very low at the beginning of the series, increases sharply at the end of 2008 and shrinks again: The log returns exhibit this even more clearly: I decided upon the order of the AR model by using different information criteria which lead me to an AR(1) model for the log return time-series. After that I tested for ARCH effects using a Lagrange-Multiplier-Test. It turned out that ARCH effects are significant for all tested 12 lags. Considering the high order of the lags I considered a GARCH(1,1) for the conditional volatility. The problem is that the estimated coefficients sum to a value greater than one ($\alpha_1+\beta_1=0.97+0.56=1.53)$ implying that volatility is growing without bounds which is clearly undesirable and also is contradictory to the graph. So my questions are: Which alternative model could I use to model this behavior of the volatility of the series considering that my primarily interest is in the coefficient values for the AR(1) ? When modelling the conditional mean of the series the classic approach would be to integrate the series. Is there a similar approach considerable for the volatility? As the series has only 534 observations how likely is this to be the reason for the sum of the mentioned coefficients to be greater than 1? I would be also very happy about any hint to a particular Stata or R command that seem promising to model the volatility of this time series. However, I think this is primarily an econometrics question. Thanks for your time and effort!
