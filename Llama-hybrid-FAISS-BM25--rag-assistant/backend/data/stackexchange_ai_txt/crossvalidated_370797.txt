[site]: crossvalidated
[post_id]: 370797
[parent_id]: 364584
[tags]: 
What you may be overlooking in how self-training works is that: It's iterative, not one-shot. You use a classifier that returns probabilistic values. At each iteration, you only add psuedo-labels for the cases your algorithm is most certain about. In your example, perhaps the first iteration is only confident enough to label one or two points very near each of the labeled points. In the next iteration the boundary will rotate slightly to accommodate these four to six labeled points, and if it's non-linear may also begin to bend slightly. Repeat. It's not guaranteed to work. It depends on your base classifier, your algorithm (how certain you have to be in order to assign a pseudo-label, etc), your data, and so on. There are also other algorithms that are more powerful if you can use them. What I believe you're describing is self-training, which is easy to code up, but you're using a single classifier that's looking at the same information repeatedly. Co-training uses multiple classifiers that are each looking at different information for each point. (This is somewhat analogous to Random Forests.) There are also other semi-supervised techniques -- such as those that explicitly cluster -- though no overall "this always works and this is the winner". IN RESPONSE to the comment: I'm not an expert in this field. We see it as very applicable to what we typically do with clients, so I'm learning and don't have all the answers. The top hit when I search for semi-supervised learning overviews is: Semi-Supervised Learning Literature Survey , from 2008. That's ages ago, computer-wise, but it talks about the things I've mentioned here. I hear you that a classifier could rate unlabeled points that are farthest from the labeled nodes with the most certainty. On the other hand, our intuitions may fool us. For example, let's consider the graphic you got from Wikipedia with the black, white, and gray nodes. First, this is in 2D and most realistic problems will be in higher dimensions, where our intuition often misleads us. High-dimensional space acts differently in many ways -- some negative and some actually helpful. Second, we might guess that in the first iteration the two right-most, lower-most gray points would be labeled as black, since the black labeled point is closer to them than the white labeled point. But if that happened on both sides, the vertical decision boundary would still tilt and no longer be vertical. At least in my imagination, if it were a straight line it would go down the diagonal empty space between the two originally-labeled points. It would still split the two crescents incorrectly, but it would be more aligned to the data now. Continued iteration -- particularly with a non-linear decision boundary -- might yield a better answer than we anticipate. Third, I'm not sure that once-labeled, always-labeled is how it should actually work. Depending on how you do it and how the algorithm works, you might end up first tilting the boundary while bending it (assuming non-linear), and then some of the misclassified parts of the crescents might shift their labels. My gut is that those three points, combined with appropriate (probably higher-dimensional) data, and appropriate classifiers can do better than a straight-up supervised with a very small number of training (labeled) samples. No guarantees, and in my experiments I've found -- I blame it on datasets that are too simple -- that semi-supervised may only marginally improve over supervised and may at times fail badly. Then again, I'm playing with two algorithms that I've created that may or may not actually be good.
