[site]: crossvalidated
[post_id]: 400417
[parent_id]: 400413
[tags]: 
One note: by adding more data (rows or examples, not columns or features) your chances of overfitting decrease rather than increase. The two paragraph summary goes like this: Adding more examples, adds diversity. It decreases the generalization error because your model becomes more general by virtue of being trained on more examples. Adding more input features, or columns (to a fixed number of examples) may increase overfitting because more features may be either irrelevant or redundant and there's more opportunity to complicate the model in order to fit the examples at hand. There are some simplistic criteria to compare quality of models. Take a look for example at AIC or at BIC. They both show that adding more data always makes models better, while adding parameter complexity beyond the optimum, reduces model quality.
