[site]: crossvalidated
[post_id]: 191414
[parent_id]: 
[tags]: 
Autoencoder maximal activation

I am trying to visualize what change each hidden unit of my autoencoder represents in my input space. So I was wondering, why do people only look at the maximal activation of a hidden unit in an autoencoder (i.e. here under "Visualizing a Trained Autoencoder") and never at the minimal activation? The weight matrix of a hidden unit can have positive and negative values which will obviously counteract each other when multiplied with a data example. So should we not be looking at the change/difference between the inputs that cause maximal and minimal activation of a hidden unit to see what that hidden unit encodes?
