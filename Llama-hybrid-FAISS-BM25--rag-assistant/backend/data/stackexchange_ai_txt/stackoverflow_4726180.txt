[site]: stackoverflow
[post_id]: 4726180
[parent_id]: 
[tags]: 
Can you help me with linear activation of my Simple Classifier Neural Network in pyBrain?

I'm trying a very simple case using a Python library called pyBrain and I can't get it to work. There is likely to be a very simple reason, so, I hope someone can help! 1) A simple XOR works fine. 2) Classifying the led's displayed on a digital clock to the numerical output value works fine. e.g. [ 1. 1. 1. 0. 1. 1. 1.] => [ 0.] [ 0. 0. 1. 0. 0. 1. 0.] => [ 1.] [ 1. 0. 1. 1. 1. 0. 1.] => [ 2.] [ 1. 0. 1. 1. 0. 1. 1.] => [ 3.] [ 0. 1. 1. 1. 0. 1. 0.] => [ 4.] [ 1. 1. 0. 1. 0. 1. 1.] => [ 5.] [ 1. 1. 0. 1. 1. 1. 1.] => [ 6.] [ 1. 0. 1. 0. 0. 1. 0.] => [ 7.] [ 1. 1. 1. 1. 1. 1. 1.] => [ 8.] [ 1. 1. 1. 1. 0. 1. 1.] => [ 9.] 3) Classifying a numerical value to the led output to drive a digital display doesn't work. e.g. [ 0.] => [ 1. 1. 1. 0. 1. 1. 1.] etc etc (as above but reversed). I'm using a simple linear activator with 10 inputs, 1 output and i've tried >12 neurons in the hidden layer. My confusion is that, shouldn't the network be able to remember the pattern with 10 neurons in the hidden layer? I'm sure there is something obvious I'm missing, so, please feel free to enlighten my stupidity!
