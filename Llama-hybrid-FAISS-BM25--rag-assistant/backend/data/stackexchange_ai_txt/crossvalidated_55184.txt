[site]: crossvalidated
[post_id]: 55184
[parent_id]: 
[tags]: 
Performance worse with new observations

I come from the computer science area but am new to machine learning / stats, so this question may be fundamental and easy. I have time-series data (biological data), and, without getting into the problem domain, I am trying to predict future values from some set of features. One subset of my features are previous values along the timecourse. For example, at time t , I add a specified number of t-i values in the timecourse, with the idea being that the algorithm will be able to pick up on velocity, acceleration, etc. I have noticed that My model performs worse as I add more and more observations into the training phase My model performs worse as I increase the number of previous time values into my feature set. I'm not looking for a solution necessarily, just an understanding. Is this because my features are poorly chosen or uncorrelated to the target variable, and may in fact be adding noise? I am using these features into an SVM trained to classify certain future values in the time series (ie, will the position increase or decrease from the previous value), and the SVM implementation is from a third-party library, so I don't think implementation is the issue.
