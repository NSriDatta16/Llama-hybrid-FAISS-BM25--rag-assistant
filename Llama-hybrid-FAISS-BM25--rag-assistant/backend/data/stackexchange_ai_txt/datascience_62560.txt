[site]: datascience
[post_id]: 62560
[parent_id]: 62369
[tags]: 
You are indeed correct in using basic feature engineering to transform your data. Most of the approaches of using deep learning for time series forecasting do the same. Suppose your time series data contains only one variable other than the timestamp and you are pretty sure with the assumption of your data having a periodicity of 1 week, you can transform your data to include all previous 7 days and let your machine learning model learn to give appropriate weights to each of the previous 7 days. Your columns will then look as follows - timestamp | value_at_t_1 | value_at_t_2 | ... | value_at_t_7 | day_of_the_week | current_value If your data contains more than one variable for each timestamp , you can create a dataset where each training sample is a sequence - a sequence of data points where each data point contains the original constituent variables. In your case, the sequence length will be 7, as the periodicity of your data is one week and each timestamp is a day. Suppose your original dataset had shape=(M, N) where M is the number of timestamps and N is the number of variables corresponding to each timestamp then your transformed dataset will have shape=(num_samples, seq_len, N) where num_samples depends on your sampling technique ( M/seq_len for non-overlapping samples, M-seq_len+1 for overlapping ones). After this dataset is created you can train an LSTM-RNN which can predict the needed independent variable given data for past seq_len timesteps. Hope this helps!
