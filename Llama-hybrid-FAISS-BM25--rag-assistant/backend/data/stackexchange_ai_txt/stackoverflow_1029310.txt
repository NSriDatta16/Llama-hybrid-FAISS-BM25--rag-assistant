[site]: stackoverflow
[post_id]: 1029310
[parent_id]: 1029280
[tags]: 
Highly doubtful. If you are serving different content based on IP address or User-Agent from the same URL, it's cloaking, regardless of the intentions. How would a spider parse two sets of content and figure out the "intent"? There is intense disagreement over whether "good" cloakers are even helping the user anyway. Why not just add a sitemap?
