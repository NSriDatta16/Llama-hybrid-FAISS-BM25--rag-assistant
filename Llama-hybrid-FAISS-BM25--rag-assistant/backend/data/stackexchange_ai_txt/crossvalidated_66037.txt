[site]: crossvalidated
[post_id]: 66037
[parent_id]: 
[tags]: 
Multicollinearity and regression intercept

I have two continuous variables $x_1$ and $x_2$, such that their sum is a constant: $x_1+x_2=c$. Clearly, I cannot run the following OLS model due to perfect multicollinearity: Model (1): $y = \alpha + \beta_1 x_1 + \beta_2 x_2 + \epsilon$ If I run the Model (2) below, $\beta_1$ is significantly negative: Model (2): $y = \alpha + \beta_1 x_1 + \epsilon$ I have reason to believe that $x_2$ is also a determinant of $y$ and must be in the regression model alongside $x_1$. In Model (3), which constrains the intercept to zero, $\beta_1$ is significantly positive: Model (3): $y = \beta_1 x_1 + \beta_2 x_2 + \epsilon$ Models (2) and (3) reach opposite conclusions regarding $\beta_1$. Model (3) yields the theoretically predicted result ($\beta_1>0$). My question is whether I can rely on Model (3), since it excludes the intercept in order to include $x_2$ alongside $x_1$. To address the comments, think of $c$ as the size of a pie that is equal for everyone, and each individual slices the pie into two pieces $x_1$ and $x_2$, such that $x_1+x_2=c$. What I'm investigating is whether one type of slice $x_2$ matters more than the other $x_1$. In other words, whether $\beta_2>\beta_1$ in Model (3). To be more specific, $c$ is the average lottery return, which is decomposed into two parts for each individual as follows: $c = o_i r_{oi} + p_i r_{pi}$ where $o_i$ ($p_i$) is the proportion of lotteries individual $i$ observes (plays), such that $o_i+p_i=1$, and $r_{oi}$ ($r_{pi}$) is the average return of the lotteries that are observed (played) by individual $i$. Finally, $x_1\equiv o_i r_{oi}$ and $x_2\equiv p_i r_{pi}$, such that $x_1+x_2=c$; and $y$ is the future participation rate in the lotteries. Rational learning theories predict that individuals will give equal importance to the returns that they observe ($x_1$) versus those that they experience ($x_2$): $\beta_1=\beta_2>0$. On the other hand, reinforcement learning theories predict personally experienced outcomes matter more: $\beta_2>\beta_1>0$. That is why I'm trying to find out whether Model (3) is an appropriate way of testing these two theories.
