[site]: crossvalidated
[post_id]: 189085
[parent_id]: 187463
[tags]: 
I am not sure if the kappa-squared is a good measure of mediation effect size (see Wen & Fan, 2015). Since there are only two studies, there is no need to apply meta-analysis. If the measures are the same in these data sets (the two assumptions listed by jsakaluk), we may test the equality of the unstandardized indirect effects by imposing a nonlinear constraint $H_0: \alpha^{(1)}\beta^{(1)}=\alpha^{(2)}\beta^{(2)}$, where $\alpha$ and $\beta$ are the population parameters of the paths $a$ and $b$, and the superscript represents the group. The models with and without this constraint are nested. A likelihood ratio test with 1 df may be used to test this null hypothesis. If your SEM program does not allow nonlinear constraint, we may compute a function of the parameters, say $p=a^{(1)}b^{(1)}-a^{(2)}b^{(2)}$. A Wald test can be used to test whether the population value of p is 0 (see Cheung, 2007). When there are many groups or studies, meta-analytic methods are better than the multiple-group SEM to synthesize indirect effect. Cheung and Cheung (in press) consider two approaches. The first approach is applying the meta-analytic structural equation modeling (MASEM) to estimate a pooled correlation matrix with a random-effects multivariate meta-analysis. A mediation model is then fit on this pooled correlation matrix in the stage two analysis. This approach can only test the "average" indirect effect. However, it does not test whether the indirect effects are homogeneous. The second approach is to calculate the standardized indirect effect (and possibly the standardized direct effect) in each study. These effect sizes are meta-analyzed with a multivariate meta-analysis. The main advantage of this approach is that it quantify the heterogeneity of the indirect and direct effects. Cheung and Cheung (in press) discuss the advantages and limitations of these two approaches. One cautionary note on calculating the sampling variance/covariance of the standardized indirect effect in the second approach is that the standard errors calculated by standardizing the variables are likely incorrect (Cheung, 2009; Yuan & Chan, 2011). It is preferable to use the indirectEffect function in the metaSEM package implemented in R to calculate the correct standard errors for the standardized indirect and direct effects. References Cheung, M. W.-L. (2007). Comparison of approaches to constructing confidence intervals for mediating effects using structural equation models . Structural Equation Modeling: A Multidisciplinary Journal , 14(2) , 227–246. http://doi.org/10.1080/10705510709336745 Cheung, M. W.-L. (2009). Comparison of methods for constructing confidence intervals of standardized indirect effects . Behavior Research Methods , 41(2) , 425–438. http://doi.org/10.3758/BRM.41.2.425 Cheung, M. W.-L., & Cheung, S. F. (in press). Random-effects models for meta-analytic structural equation modeling: Review, issues, and illustrations . Research Synthesis Methods . Wen, Z., & Fan, X. (2015). Monotonicity of effect sizes: Questioning kappa-squared as mediation effect size measure. Psychological Methods , 20(2) , 193–203. http://doi.org/10.1037/met0000029 Yuan, K.-H., & Chan, W. (2011). Biases and standard errors of standardized regression coefficients. Psychometrika , 76(4) , 670–690. http://doi.org/10.1007/s11336-011-9224-6
