[site]: crossvalidated
[post_id]: 304517
[parent_id]: 304511
[tags]: 
The most straightforward answer is No ! You can't train and predict on the same data without biasing. Nevertheless you can use a technique called K-fold cross validation which involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are combined (e.g. averaged) over the rounds to estimate a final predictive model . You may also like to check this Udacity video on K-Fold Cross Validation.
