[site]: crossvalidated
[post_id]: 477918
[parent_id]: 406131
[tags]: 
Another reason for breaking up the temporal sequence of the training data, which I have oddly never seen in the modern literature, is due to the stiffness of the continuous neural network: if you train on nearby successive states, this may significantly distort the already learned mapping across huge regions of the training data space that are quite far from the current data. This is why in the old days we used radial basis functions: new data only affected the mapping fairly locally.
