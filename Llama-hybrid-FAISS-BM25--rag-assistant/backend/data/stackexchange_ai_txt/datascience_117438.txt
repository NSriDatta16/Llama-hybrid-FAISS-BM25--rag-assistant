[site]: datascience
[post_id]: 117438
[parent_id]: 26424
[tags]: 
No they are not comparable. In each run you are embedding the user/item data into a different vector space. Instead, focus on scaling out your computation - use more machines and cores, and make sure your data is partitioned enough to use those cores. Or, use a smaller latent rank (embedding dimension) or fewer iterations.
