[site]: crossvalidated
[post_id]: 359511
[parent_id]: 
[tags]: 
Mean centering and normalization along every dimension or over whole dataset

I'm working a side project which involves using a pre-trained CNN and I came across a piece of code that made me question some of my recently gained knowledge around mean centering and normalization. In particular, I've red on cs231n that you can apply mean centering per each image dimension of an image OR you can calculate an overall mean value and subtract that from each pixel in an image. I have come across yet another case here where an author calculates a mean across ALL RGB channels and subtracts it from each pixel of an image. The author of the code does the same thing when normalizing with stddev which is calculated for the whole image and then applied to each pixel. What's the difference between all three methods? When it comes to RGB image, wouldnt it make sense to do the normalization per each RGB channel i.e. calculate mean/stddev for each channel and use those particular values for normalization of particular channel it was calculated from as opposed to calculating one overall value of mean and stddev of the whole image?
