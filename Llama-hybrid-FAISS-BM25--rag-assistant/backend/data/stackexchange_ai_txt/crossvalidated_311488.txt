[site]: crossvalidated
[post_id]: 311488
[parent_id]: 
[tags]: 
Summing feature importance in Scikit-learn for a set of features

I have built a random forest using a set of features (~100), and I want to compare the feature importance for two subsets of features. In scikit-learn, the feature importance sums to 1 for all features, in comparison to R which provides the unbounded MeanDecreaseGini, see related thread Relative importance of a set of predictors in a random forests classification in R . My question is, is it possible to simply sum the feature importance of a set of features, or should one do similar to the R solution and use some weighted average? I have used the Gini-impurity as a splitting criteria, and how RF uses that measure to estimate the feature importance is unclear to me.
