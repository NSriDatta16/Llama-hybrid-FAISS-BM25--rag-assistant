[site]: crossvalidated
[post_id]: 81681
[parent_id]: 
[tags]: 
How to model a conditional probability without estimating joint PDF?

I've around 3e3 two-dimensional data points, x, d 1 1, 0.1 2 3, 0.1 3 2, 0.2 4 1, 0.5 range(x) = [-600, 600], range(d) = [0, 1] We are trying to model d with a probability model. I believe the distribution of d should be dependent on x . So I'm up to model $Pr(d|x)$ rather than $Pr(d)$. To do this, I am now using kernel density distribution to estimate the joint distribution of $Pr(d, x)$ and divide it by $Pr(x)$. However, the number of data is enough to model $Pr(d)$ with kernel density estimation while insufficient to model $Pr(d,x)$. So I'm wondering about this: Is there any model you suggest that can model d in a conditional way without modeling the joint distrubution? I have the following thoughts: I can use SVM to deal with the short of data. However is there a way to train a "conditional SVM"?
