[site]: crossvalidated
[post_id]: 558713
[parent_id]: 
[tags]: 
Proof that the Sample Mean of the Predicted Response from a Generalized Linear Model (GLM) Fit Via MLE Equals the Sample Mean of the Response

Is there a simple proof that the sample mean of the predicted response from a Generalized Linear Model (GLM) fit via maximum likelihood estimation equals the sample mean of the response? That is, a proof that $$ \frac{1}{n} \sum_{i = 1}^{n} g^{-1}(x_{i}^{T}\hat{\beta}) = \frac{1}{n} \sum_{i = 1}^{n} Y_{i} $$ where $g$ is the link function and $\hat{\beta}$ is the MLE for $\beta$ . This is trivially true for the Gaussian GLM, so I mean for other GLMs like logistic and Poisson regression. I first noticed this for logistic regression, e.g. set.seed(42) n [1] "0.47999999999999998224" [1] "0.48000000000192888372" where the mean of the predicted response and the mean of the outcome are equal to within floating-point fuzz. The same is not true before convergence to the MLE: mod Warning: glm.fit: algorithm did not converge [1] "0.47999999999999998224" [1] "0.48023472280308265869"
