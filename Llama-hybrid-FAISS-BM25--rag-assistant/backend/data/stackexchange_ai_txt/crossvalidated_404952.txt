[site]: crossvalidated
[post_id]: 404952
[parent_id]: 
[tags]: 
Best linear prediction as a projection in a Hilbert space $L^2$

Consider two random variables $Y$ and $X$ . In the context of the best linear prediction, if we would like to predict $Y$ given $X$ known, we derive the solution solving the following minimize problem \begin{equation} \hbox{min}_{a,b}\,\, E[(Y - (aX + b))^2] \end{equation} Using the first order conditions, we conclude that: $$a =\frac{cov(X,Y)}{V(X)},\quad b= E[Y] - a E[X]$$ I would like to get the same solution in the context of the $L^2$ space as Hilbert Space. We know that $ := E[XY]$ is a inner product. If I define the space spaned by $X, 1$ as $F$ , I would like to get the same coeficients $a, b$ projecting $Y$ in $F$ . In other words, if we know that $$p_F(Y) = \frac{ }{ }1 + \frac{ }{ }X$$ We would have $$a = \frac{ }{ }, \quad b = \frac{ }{ }$$ Or $$a = \frac{E[YX]}{E[XX]}, \quad b = E[Y]$$ . But I can reach my goal only if $E[X]= 0$ . Some ideias?
