[site]: crossvalidated
[post_id]: 571436
[parent_id]: 
[tags]: 
How to implement logistic regression deviance from scratch

As a learning exercise, I'm trying to implement the deviance for logistic regression from scratch. I understand the deviance to be: $\mathcal{L}_S - \mathcal{L}_M$ , where $\mathcal{L}_s$ is equal to the likelihood of the saturated model (the ground truth values we're predicting) and $\mathcal{L}_m$ is equal to the values predicted by our logistic regression model under maximum likelihood estimation. Deviance is therefore a measurement of the fit of the model -- of the "deviance" of the residuals. Mathematically, the deviance is equal to: $-2 \sum_{i=1}^K [y_i \log({{\hat{p}_i} \over{y_i}}) + (1 - y_i) \log({{1 - \hat{p}_i} \over{1 - y_i}})]$ My Python implementation is the following, where I've multiplied by $-1$ and inverted the logits: from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression from sklearn import metrics _X, _y = load_iris(return_X_y=True) X, y = [], [] for i in range(len(_y)): if _y[i] In short, my understanding is the deviance is composed of left-hand and right-hand sides, where each side corresponds to the true Bernoulli outcome of the observation. One side should be "zereoed-out" because if $y_i = 0$ , then the left-hand side is equal to zero. If $y_i = 1$ , then the right-hand side is equal zero. However, my deviance calculation does not match the deviance calculation from sklearn: 2 * metrics.log_loss(y, model.predict_proba(X), normalize=False) My calculation gives 394.967593909003 . The sklearn value is about 4.5 . Even if I average over my estimate, the result is still off: I get 3.94 vs. 4.52 What did I do wrong? It seems close but not quite right..
