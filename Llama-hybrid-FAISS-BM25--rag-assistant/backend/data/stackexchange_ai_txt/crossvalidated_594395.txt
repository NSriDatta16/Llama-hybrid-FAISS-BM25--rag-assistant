[site]: crossvalidated
[post_id]: 594395
[parent_id]: 
[tags]: 
Why is the notion of a batch problematic for RNNs?

This paper says that the notion of a batch problematic for RNNs (page 9) (which is why you can't apply batch normalization for RNNs?). Why is it hard to talk about batches for RNNs? Eg. the Pytorch API even has a parameter to control the batch size, so batches "clearly" make sense for RNNs (and, therefore, batch normalization also make sense). What's going on?
