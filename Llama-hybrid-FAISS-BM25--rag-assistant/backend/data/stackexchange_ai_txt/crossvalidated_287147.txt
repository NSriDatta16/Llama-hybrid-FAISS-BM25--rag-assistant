[site]: crossvalidated
[post_id]: 287147
[parent_id]: 287143
[tags]: 
MinMax tells you how far the model's prediction is off. For a perfect model, this measure is 1.0. The lower the measure, the worse the model, based on out-of-sample performance. Just look at the formula and how it's implemented in R. If predict (the column predicteds in your data frame) exactly equals actual ( actuals ) for every instance of the test set, the row minimum would be the same as the row maximum, so the ratio would be 1.0 for all rows. If your model is terrible, sometimes its prediction is too high, other time too low, the min/max ratio would be much less than 1.0. So the average of that would be less than 1.0.
