[site]: datascience
[post_id]: 118124
[parent_id]: 
[tags]: 
How to extract embeddings from an audio file using wav2vec along with context

I am trying to use wav2vec embeddings from the XLSR model for emotion recognition on the EMODB dataset. How can I extract embeddings using wav2vec? I want to use the XLSR model pre-trained with wav2vec, but I am not sure how to extract embeddings from audio files to use for emotion recognition. I have made attempt like following but they are not correct, this results in random mappings. feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('facebook/wav2vec2-large-xlsr-53') #XLSR is for SR, not specifically Emotion Rec. input_audio, sample_rate = librosa.load(emodb + file, sr=16000) extraction = feature_extractor(input_audio, sampling_rate=16000, return_tensors="np", padding="max_length", max_length=max_len).input_values Are there any series of steps to follow or libraries or methods I can use to extract the embeddings? Are there any examples or tutorials that I can follow to get started?
