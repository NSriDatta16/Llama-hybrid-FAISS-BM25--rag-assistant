[site]: crossvalidated
[post_id]: 545972
[parent_id]: 545965
[tags]: 
Comment: Here are a few reasons why a frequentist statistician might use a Bayesian approach. Computational convenience, as @Fiodor1234 says, may not be high on the list. One such example might be use of the Jeffreys posterior probability interval as a confidence interval for a binomial proportion. For example, if you have $x = 42$ successes in $n=100$ trials, the asymptotic Wald interval is not the best choice because of the small sample size. The Agresti-Coull interval is easy to compute and comes close to more accurate intervals that are somewhat intricate to compute. The Jeffreys interval, based on the noninformative Bayesian prior $\mathsf{Beta}(.5, .5)$ , is easy to compute in R and has good frequentist properties. p.hat = 42/100 CI.Wald = p.hat + qnorm(c(.025,.975))*sqrt(p.hat*(1-p.hat)/100) round(CI.Wald,4) [1] 0.3233 0.5167 p.est = (42+2)/(100+4) CI.Agr = p.est + qnorm(c(.025,.975))*sqrt(p.est*(1-p.est)/104) round(CI.Agr,4) [1] 0.3281 0.5180 CI.Jeff = qbeta(c(.025,.975), 42+.5, 100-42+.5) round(CI.Jeff,4) [1] 0.3267 0.5179 Proper support of distribution. In an attempt to find the prevalence of a disease from screening test data, traditional methods can give an interval for prevalence that extends beyond $(0,1).$ By using a Gibbs sampler with a beta prior distribution, it is possible to get a useful interval estimate for prevalence. (Since the beta prior has the unit interval as support, then the posterior distribution will also.) See example. . 'Simulate' latent data. Sometimes one wants to test or to give a parameter estimate for latent data, which can be reliably reconstructed using a Gibbs sampler. One simple example is to know the variability of groups in a one-way random-effects ANOVA. Observed values from the groups are available, but the components of variance due to the various groups (separate from overall variance) are typically latent.
