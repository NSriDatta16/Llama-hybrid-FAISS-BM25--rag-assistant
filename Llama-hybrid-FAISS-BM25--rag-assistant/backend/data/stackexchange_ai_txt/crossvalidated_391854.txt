[site]: crossvalidated
[post_id]: 391854
[parent_id]: 
[tags]: 
Can the r-scale value (for Bayes Factor) be directly based on Cohen's d?

I want to set an r-scale value for a Bayesian t-test (i.e. to calculate Bayes Factor likelihood ratio) based on previous results (i.e., from a posterior). But I simply cannot find a straightforward official explanation about how to do it. The only sensible description I found is in a blog post by D. Lakens: http://daniellakens.blogspot.com/2016/01/power-analysis-for-default-bayesian-t.html This says that the r-scale should basically have the same value as the expected Cohen's d (i.e., standardized mean difference; based on the previous result). However, I could not find support (or explanation) for this anywhere else. I also tried it in R, and it doesn't work as I'd expect. I would imagine that if I use the original data from which I get the posterior, and give it as prior r-scale, I should get maximum BF. But in fact the peak always seems to be with a somewhat lower r-scale value. library(MBESS) library(BayesFactor) var1 = c(9,8,6,7,8,6,5,7,8,8) var2 = c(3,4,5,6,7,5,3,2,4,5) ttest = t.test(var1, var2, paired=T) ci.sm(ncp = ttest $statistic, N = length(var1), conf.level = .95)$ Standardized.Mean # this gives effect size as d = 1.494293 as.vector( ttestBF(var1, var2, paired = T, rscale = 1.494293) ) # with actual effect size as r-scale, BF = 43.78086 However, the peak is actually when I give r-scale at around 1.30: as.vector( ttestBF(var1, var2, paired = T, rscale = 1.50) ) # smaller: 43.7633 as.vector( ttestBF(var1, var2, paired = T, rscale = 1.30) ) # larger: 44.07731 as.vector( ttestBF(var1, var2, paired = T, rscale = 1.25) ) # again smaller: 44.03929 So shouldn't the peak be at rscale = 1.494293 ?
