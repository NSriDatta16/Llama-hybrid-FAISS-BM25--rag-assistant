[site]: crossvalidated
[post_id]: 422163
[parent_id]: 421979
[tags]: 
I don't think what you describe can be done while avoiding multiple comparison correction. With many outcome measures, on average some of your hypothesis tests will turn out significant even if none of the treatments have any effect. Correction for multiple comparisons is designed to protect you from drawing the (false) conclusion that your treatment does have some effect. Since you are fitting a linear model in your comment, I will assume that your outcome data are actually normally distributed, not uniformly as in your data example. Assuming additionally that the scale (including variance) of the outcome measures is the same (or that they can be rescaled so that they are), you can do a single test to see which treatment has the biggest effect overall. One option here would be a classical MANOVA: # set seed for reproducibility set.seed(12345) # generate sample data data_ex $manipulation_new manipulation * data_ex$man_onoff) # manova requires a matrix on the left side of the formula depvars If you find a significant effect overall you could then follow up with suitable post-hoc tests. Two caveats: MANOVA would be sensitive to effects in both directions (e.g., if the treatment makes an outcome much worse that would also show up) MANOVA has some specific assumptions (in particular multivariate normality of dependent variables), and is quite sensitive to deviations from these assumptions. Another option would be to run this as a linear mixed model: # set seed for reproducibility set.seed(12345) # generate sample data data_ex $pnum] data_ex[,grep('^score_', names(data_ex))] manipulation == 2 & data_ex $man_onoff == 1,grep('^score_', names(data_ex))] manipulation == 2 & data_ex $man_onoff == 1,grep('^score_', names(data_ex))], 2, manip2_effect, "+") # collect outcome variables outcomes ', names(data_long))] $', names(data_long))] manipulation_new $manipulation * data_ex$ man_onoff) # load lme4 library(lme4) library(lmerTest) # assuming you need p-values my_mixed_model Again, if you find any significant effects you could then follow up with appropriate post-hoc tests. Note that one advantage of the linear mixed model approach is that it deals easily with missing data, whereas MANOVA requires complete cases (at least per session). On the other hand, there is much debate regarding the validity of p-values for the mixed-model approach (even when ignoring the current debate regarding the use of p-values generally).
