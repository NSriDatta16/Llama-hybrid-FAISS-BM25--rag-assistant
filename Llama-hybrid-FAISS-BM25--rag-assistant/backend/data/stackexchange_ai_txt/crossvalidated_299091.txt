[site]: crossvalidated
[post_id]: 299091
[parent_id]: 
[tags]: 
Dealing with violated linearity assumption in Logistic Regression

As I understand from "Discovering Statistics using R" by Andy Field (et. al), in logistic regression we assume that there is a linear relationship between any continuous predictors and the log of the outcome variable. This can be tested by seeing if the interaction term between the predictor and its log transformation is significant (if the interaction term is significant then the linearity assumption is violated). When conducting a logistic regression analysis myself I use four continuous predictors. Upon testing the linearity assumption of logistic regression, I have now experienced that all of the continuous predictor interaction terms are significant (i.e., violate the linearity assumption for logistic regression). How can we deal with the violation of the linearity assumption in logistic regression when using these four continuous predictors? Would it for instance be possible to transform the variables from continuous to categorical (ordinal) to not have to worry about violating the linearity assumption? Are there other options that people use? Here is an example of creating an interaction term in R: neventsInt $nevents) * ds$ nevents Running the logistic regression, now including the four interaction terms to test the linearity assumption: fit Here is the output regarding the significance of all the predictor interaction terms, after including them in the logistic regression: Coefficients: Estimate Std. Error z value Pr(>|z|) neventsInt -7.409e-05 8.098e-06 -9.148 As an aside, I have wanted to combine three of the continuous predictors into one factor (through factor analysis) for use in subsequent logistic regression. Am I correct in assuming that if the predictors violate the independence assumption separately then they will also violate it when combined into a factor?
