[site]: crossvalidated
[post_id]: 60849
[parent_id]: 60747
[tags]: 
The standard approach for support vector machine tuning is to tune on the full training set through cross-validation, e.g. your second approach. We use cross-validation to ensure that training and testing is always done on independent data. There is no need to split the training set further just for tuning. The problem of overfitting is already alleviated through cross-validation. You won't get any benefit from making a separate tuning set as per your first approach. In fact, your final model is likely to be worse, considering you would use less data to train the final model. The main context in which tuning sets are used for SVMs is when the full training set is huge which would make the tuning phase last way too long.
