[site]: crossvalidated
[post_id]: 314919
[parent_id]: 314902
[tags]: 
I don't know of a perfectly intuitive explanation. I just remember that when I first learnt the central limit theorem, I was puzzled by the term $1/\sqrt N$ while it has actually a simple explanation that does not require understanding the full theorem. Consider $N$ independent variables of variance $\sigma^2$. The variance of the sum if the sum of the individual variances: $N\sigma^2$. The standard deviation of the sum is $\sqrt{N\sigma^2}=\sqrt N\sigma$. The average is the sum divided by $N$ thus its standard deviation is $\sqrt N\sigma/N=\sigma/\sqrt N$. The standard deviation of the average thus decreases in $1/\sqrt N$: how much the empirical average is different from the mean varies in $1/\sqrt N$. Everything relies on the fact that for independent variables the variance of sum if the sum of the variances . This is the mathematical statement to describe how independent errors sum: sometimes constructively, sometimes destructively, resulting in summing the squares. It works like sound. When you hear two (uncorrelated) noises with the same intensity $I$, the global noise has intensity $\sqrt 2 I$ because of how constructive and destructive interferences alternate. A choir of $N$ persons is as loud as $\sqrt N$.
