[site]: crossvalidated
[post_id]: 379285
[parent_id]: 
[tags]: 
How can I improve my classification model(s), when it gives training, cross validation and test accuracies all close to 68%-69% only?

I'm performing a binary classification with both logistic regression and SVM, where I've 80%-20% train-test split of the 10000 samples, each with 11 features. In my problem, the features are the data related to a car application, e.g. the time a ride request was made, the time the corresponding booking request(s) was/were made, the latitudes and lognitudes of the rider and the driver etc. The response variables are driver's response 1 (ride request accepted) or 0(ride request not accepted). After classification, I'm getting around 68% accuracies for all of training, cross validation and classifcation, and out of the response {0,1}, about 64% are 1 and 36% is 0. When I perform a grid search to find the best parameters for both linear and kernel SVM, I still get around 69% accuracies.I also tried logistic regression and Na√Øve Bayes, but the accuracy range in all cases were between 65%-69%. From a high level, my question is: what should I do next to find a better model? For example, 1) should I worry about class imbalance , since the classes are 64%-36% distributed? 2) a. since the number of features (11) is much less than that of samples (10000), do I still need to do PCA to improve accuracy ? b. Should I do PCA in any case to get better understanding of the 2D projected data? 3) I'm not sure if there's lot of noise, as the data features are the car data as described; but if there's noise, how can I identify them? Any help will be highly appreciated?
