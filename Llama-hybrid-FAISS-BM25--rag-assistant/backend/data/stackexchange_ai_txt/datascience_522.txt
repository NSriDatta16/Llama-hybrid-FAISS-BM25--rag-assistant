[site]: datascience
[post_id]: 522
[parent_id]: 516
[tags]: 
I have been able to optimize very strange functions with simulated annealing, and it does not require a gradient. Instead, it uses random numbers in a way very similar to Markov Chain Monte Carlo, which helps it avoid getting stuck in local optima. A decent explanation that gives the intuition behind it can be found in this lecture: Simulated Annealing . scipy 0.14 includes this algorithm in its optimization module: scipy.optimize.anneal .
