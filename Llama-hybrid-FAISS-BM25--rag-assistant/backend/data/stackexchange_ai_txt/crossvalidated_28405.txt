[site]: crossvalidated
[post_id]: 28405
[parent_id]: 28375
[tags]: 
If you feel like you are getting good results, what is the problem? Are you not identifying enough true positives? Are you identifying too many false positives? If it's one or the other, choose a more liberal or conservative threshold for predicting the classes. If it's both, there's probably not all that much you can do without getting more data or creating derived features. If you are using a SVM, then it would be natural to try using various kernels, since using a kernel is implicitly creating derived features. As far as the modifications you suggest: removing outliers should not help you since one of the properties of SVM is that it effectively ignores all the data that is far from the decision boundary (assuming that the two classes are linearly separable in your feature space. If not, then you do need to worry about outliers).
