[site]: stackoverflow
[post_id]: 798972
[parent_id]: 798800
[tags]: 
EDIT: Here's what I finally suggest, I tried it and it provides quite satisfying results: I have a zero initialized array for each download speed between 0 - 500 kB/s (could be higher if you expect such speeds) in 1 kB/s steps. I sample the download speed momentarily (every second is a good interval), and increment the coresponding array item by one. Now I know how many seconds I have spent downloading the file at each speed. The sum of all these values is the elapsed time (in seconds). The sum of these values multiplied by the corresponding speed is the size downloaded so far. If I take the ratio between each value in the array and the elapsed time, assuming the speed variation pattern stabalizes, I can form a formula to predict the time each size will take. This size in this case, is the size remaining. That's what I do: I take the sum of each array item value multiplied by the corresponding speed (the index) and divided by the elapsed time. Then I divide the size left by this value, and that's the time left. Takes a few seconds to stabalize, and then works preety damn well. Note that this is a "complicated" average, so the method of discarding older values (moving average) might improve it even further.
