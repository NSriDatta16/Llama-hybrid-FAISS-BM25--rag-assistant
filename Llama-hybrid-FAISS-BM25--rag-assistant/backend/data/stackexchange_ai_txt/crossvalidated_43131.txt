[site]: crossvalidated
[post_id]: 43131
[parent_id]: 
[tags]: 
Cross validation and parameter optimization

I have a question about the parameter optimization when I use the 10-fold cross validation. I want to ask that whether the parameters should fix or not during every fold's model training , i.e. (1) select one set of optimized parameters for every fold's average accuracy. or (2) I should find the optimized parameter for every fold and then every fold uses different optimized parameters to train its model then test on the fold's test data respectively, and finally average every fold's accuracy as result? Which one is the correct method for cross validation? Thanks a lot.
