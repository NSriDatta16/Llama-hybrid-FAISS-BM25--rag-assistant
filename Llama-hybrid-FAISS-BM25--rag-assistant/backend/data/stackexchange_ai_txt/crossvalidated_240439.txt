[site]: crossvalidated
[post_id]: 240439
[parent_id]: 240418
[tags]: 
If you are really want to create higher order features to a logistic regressor then I would suggest you expand your features with interaction between features $X_1*X_2$, nonlinear features like $log(X_1)$ and $X_1^2$. Everything exactly like you proposed. Finally to avoid over-fitting and at the same time doing variable selection apply a LASSO regularizer, it will both penalize model complexy and also induce sparsity. Only the subset of features, high order features that are of higher importance will be kept by the model. You might also want to consider non linear models, they try to discover the optimal non-linearity by themselves (e.g. neural networks).
