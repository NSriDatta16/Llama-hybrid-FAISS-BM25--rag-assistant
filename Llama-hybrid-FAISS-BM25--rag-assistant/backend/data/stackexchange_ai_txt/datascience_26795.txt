[site]: datascience
[post_id]: 26795
[parent_id]: 26776
[tags]: 
Actually there is the possibility of overfitting the validation set. This because the validation set is the one where your parameters (the depth in your case) perform at best, but this does not means that your model will generalize well on unseen data. That's the reason why usually you split your data into three set: train, validation and test . You train on the training set, tune the parameters on the validation set, and finally, when you are happy with the parameters, you test your model as a whole with the test set. And usually, the error on the test set will be higher than the error on the validation test. If this difference is small, you accept the model. But if it's big, you need to act: 1) reorganizing the three sets, because maybe you have a variance problem between the sets; 2) adding some penalty on your model, acting on the regularization parameters; or lowering the depth of the trees, if you are interested only on it
