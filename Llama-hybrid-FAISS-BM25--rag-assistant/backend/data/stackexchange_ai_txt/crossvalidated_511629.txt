[site]: crossvalidated
[post_id]: 511629
[parent_id]: 
[tags]: 
Captions are better, yet validation loss is increasing

I am training and validating an image captioning model with the following architecture: Encoder: ResNet-101 Pre-trained on ImageNet Decoder: GRU (1-Layer) Embeddings: Last BERT hidden state I optimize the Cross Entropy at each time-step of caption generation on a vocabulary of size $|V|$ . I evaluate my generated captions using the CIDER score which is a representative for better generated captions (I also checked the captions generated for validation split and they are actually good). Though the behavior of validation loss is strange: As you see both the captioning metric and my loss are increasing. As I have never seen such a behavior from Cross Entropy, I am curious to know why this is happening! Any help is much appreciated.
