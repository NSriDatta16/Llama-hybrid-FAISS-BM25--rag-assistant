[site]: crossvalidated
[post_id]: 418672
[parent_id]: 418653
[tags]: 
I would just use a likelihood ratio test between your model with and without random effects (on the papers or specifications) where you retain in both models the usual fixed effects for study type etc. Some cursory discussion is in the article Interpretation of random effects meta-analyses . Here is step by step instruction: Estimate a maximum likelihood model, with whatever fixed effects you want to include on study characteristics — usually you will have things like study type (i.e panel vs x section, random trial vs natural experiment), statistical technique (OLS vs logit etc.), sample characteristics (time, sex, age, race, income etc.) and perhaps publication details (time of publication, top-tier journal or not etc.) estimate as per 1., but add random effects on the papers — you are now estimating a mixed model. Apply Wilks' D test to test for significance of the random effects. If (as is almost certain) you find the random effects are significant, you can either use the random effects model, or if you like, use likelihood weighted model averaging over the fixed effects and mixed models.
