[site]: crossvalidated
[post_id]: 71873
[parent_id]: 
[tags]: 
Practically handling many non-stationary forecasting predictors

This question is about specific strategies to deal with non-stationary variables in forecasting. This problem usually rears its ugly head when you have a predictor whose levels are relevant to the response, but whose first difference carries very different information. Generally, if there is one or two of these in my model, it suffices to use intercept dummies that are one when the nonstationary levels predictor is 'high'. Similarly, it can sometimes suffice to interact these dummies with various other predictors so I don't have to have the nonstationary variable as a regressor. But what if I have 15-20 of these nonstationary predictors whose levels are all highly relevant to the response? For example, consumer demand being 'high' may be critically relevant to the model; by first differencing I can't incorporate this information into my model anymore. Now consider the case where there are 15-20 other similar variables where the level is critical. What is a sophisticated strategy to dealing with this other than using silly amounts of dummy variables, chucking it into a statistical learning algorithm, or chucking them all down the bin? Perhaps this problem requires a traditional machine learning solution? Something like random forests make sense, but I am looking to keep the number of parameters down since the speed at which I can get forecasts out of the model is important. To given an example of where levels are important and can't be capture by first differences, look at the following example predictor in R : plot(sin(1:400/50)+sin(1:400),type='l') What's important to my $Y$ is if this predictor is near a peak versus the opposite case of being near a trough. But there is no way to integrate this information into my model by using the first difference of this predictor.
