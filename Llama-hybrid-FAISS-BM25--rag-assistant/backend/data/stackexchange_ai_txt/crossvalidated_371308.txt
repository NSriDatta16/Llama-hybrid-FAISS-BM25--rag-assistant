[site]: crossvalidated
[post_id]: 371308
[parent_id]: 
[tags]: 
SVM optimization problem with constraint

I am studying SVM from Andrew ng machine learning notes. I don't fully understand the optimization problem for svm that is stated in the notes. So we have optimization problem $$\max_{\gamma, w, b}\gamma$$ s.t. : $$y^{(i)}(w^Tx^{(i)}+b)\geq\gamma, i=1,\dots m,\\||w||=1.$$ I get a little bit confused here, as i don't see why we should need this first constraint. Isn't it enough only to maximize $\gamma$ and in that case we already have the maximal margin hyperplane where observations are at least $\gamma$ away from the decision boundry (because $\gamma$ is already defined this way)? I think I don't understand something simple here. If you have any explanation for this I would appreciate it very much.
