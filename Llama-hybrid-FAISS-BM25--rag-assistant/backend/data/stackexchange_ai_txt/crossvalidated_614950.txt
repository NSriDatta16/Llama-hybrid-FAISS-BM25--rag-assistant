[site]: crossvalidated
[post_id]: 614950
[parent_id]: 614948
[tags]: 
I have mainly seen people using GANs for image generation and claiming that the network learns the PDFs. But all the claims about the learned PDFs are qualitative, such as claiming that the generated images look good enough. Is there any demonstration of the actually matching PDFs. Such as 1D or 2D datapoints that can be easily visualized. It is easy for me to imagine that the generated samples are from some areas in the total distribution (like the orange samples that I am generating above) but it does not capture the total distribution at all. One of the issues with being strictly quantitative in the comparison of the PDFs is that they aren't the same, and large sample sizes will catch small differences when they are brought to hypothesis tests (as they should, I argue ). Thus, how close the distributions have to be for the GAN to be useful comes down to a judgment call. Sure, that can be quantified with something like KL divergence, but KL divergence lacks the intuition that you get from looking at synthetic images that a human cannot distinguish from real images, particularly when the litmus test probably is if a human can tell the difference.
