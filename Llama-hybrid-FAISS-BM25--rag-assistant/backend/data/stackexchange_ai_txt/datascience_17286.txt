[site]: datascience
[post_id]: 17286
[parent_id]: 
[tags]: 
CNN memory consumption

I'd like to be able to estimate whether a proposed model is small enough to be trained on a GPU with a given amount of memory If I have a simple CNN architecture like this: Input : 50x50x3 C1 : 32 3x3 kernels, with padding (I guess in reality theyre actually 3x3x3 given the input depth?) P1 : 2x2 with stride 2 C2 : 64 3x3 kernels, with padding P2 : 2x2 with stride 2 FC : 500 neurons Output : softmax 10 classes Mini batch size of 64 Assuming 32bit floating point values, how do you calculate the memory cost of each layer of the network during training? and then the total memory required to train such a model?
