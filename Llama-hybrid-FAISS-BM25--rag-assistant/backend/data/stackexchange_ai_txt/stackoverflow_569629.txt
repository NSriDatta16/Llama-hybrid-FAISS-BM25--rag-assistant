[site]: stackoverflow
[post_id]: 569629
[parent_id]: 
[tags]: 
Graceful degradation outside the domain of web applications: how significant a problem is it?

Apologies for the long intro - just trying to suitably set the scene to avoid ambiguities and confusion. Web applications have grown from being dumb browser-based interfaces for server-side logic to being fully browser-based applications with minimal need for server-side logic. It is possible to describe this evolution through identifying clear generations of web applications. Let's just consider, for the moment, just two generations: pre- and post-ajax. There certainly are other factors, such as those relating to CSS support and Access Control headers, but let's start off simple. Starting from a style-less JavaScript-less simple system, adding layers of gracefully-degrading enhancements and finishing with a ajax-packed, highly-responsive contemporary application is a challenging and error-prone task. It is by no means easy. To whichever generation a web application may appear to belong depends on the means through which the application is accessed. The very same web application would appear to be a first generation app if accessed through Lynx and a latest generation app if accessed through FireFox 3.1, with a few levels in-between depending on the user agent used to access the app. The problem of creating a web application that gracefully degrades depending on the capabilities of the user agent, where something created to take advantage of current browser features would revert back to the functionality of something created perhaps fifteen years ago when faced with Lynx, is very hard. I can't imagine a desktop application facing such a variance in operating environment. A single executable (as opposed to a set of OS-specific variants) capable of taking advantage of features in Vista may well cope adequately when run under XP and when lacking certain Vista features. To degrade over a comparable distance as a web app, the same desktop application would still have to function, albeit in a less fancy fashion, when run in a command-line-only environment such as DOS. Run it under Lynx, it's a first generation web app. Run the same under FireFox 3.1, it's a fancy, shiny contemporary web app. If faced with such a problem, you'd consider it challenging, tricky but feasible. Run it under DOS, it's a command-line app. Run it same under Vista, it's a fancy, shiny contemporary web app. If faced with such a problem, you'd consider it insane. Or would you? Do desktop applications ever face such a breadth of variance in operating environments as web applications can? Is this problem (the breadth of variance, not the variance itself) unique to the domain of web applications, or can it be found in desktop development?
