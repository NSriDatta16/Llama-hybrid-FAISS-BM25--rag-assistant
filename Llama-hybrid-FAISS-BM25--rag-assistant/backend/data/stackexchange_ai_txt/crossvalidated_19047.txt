[site]: crossvalidated
[post_id]: 19047
[parent_id]: 12161
[tags]: 
In Machine Learning, many algorithms directly minimise a loss function with some form of capacity control (regularisation). This gives a direct measure of the performance of the classifier on future data, through the use of the loss function that was being minimised. If the specific problem you are dealing with can be framed in an optimisation framework, then a measure may fall out naturally from the loss function. For example, Kristin Bennett in this paper showed that PLS can be formulated as $$ \min_w \left\| \bf{X} - \bf{y}\bf{w}' \right\|_2, \; s.t. \bf{w}'\bf{w} = 1, $$ which they later show bounds the usual least squares loss. More complex predictive models can be phrased in terms of composite loss functions - see for example these slides from Mike Jordan.
