[site]: crossvalidated
[post_id]: 278481
[parent_id]: 
[tags]: 
Random forest: when could adding a perfectly collinear variable improve performance?

I am training a random forest model with ~100 features (call them X1 through X100 ). Then I add a new feature X101 = A * X100 , where A is a positive constant. X101 is perfectly collinear with X100 and in principle adds no new information. However, training/testing the model with this new set of "independent" variables results in an apparent improvement in the model predictions, in the sense that the new model has a small but significant increase in AUC. Under what circumstances could this happen?
