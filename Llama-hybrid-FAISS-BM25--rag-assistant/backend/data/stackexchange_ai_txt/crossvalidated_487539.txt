[site]: crossvalidated
[post_id]: 487539
[parent_id]: 
[tags]: 
When will I use cross validation and what will be my final model?

I have read a lot about k-fold cross validation and I am getting more and more confused. I am training neural networks and I have little training data. This suggests the use of k-fold. Up to this point, ok. I read that k-fold will help me choose the best parameters for the networks (number of neurons, learning rate, etc.). Right? Let's suppose that I trained networks with 50 and 100 neurons from the hidden layer. I did cross-validation and found that with 100 neurons I have better results. And now? I have K neural networks with 100 neurons. I have K models (number of folds). How do I use this in the real world? How do I combine these models? In some places they say to carry out a new training using all the data (training and validation) with the parameters that were found to be the best. That way I would have only one model. Is that correct? In my real work I am doing hold-out and k-fold validation. The first one says that my model gets 95% of the ratings right and with k-fold that drops to 80%. It is a very big drop. Furthermore, it is not clear whether I can use early stop and bagging (resampling) with k-fold Edit: Can anyone tell me if this is the correct procedure? I divide the data in training\test (80/20 for example) I use the training data with k-fold (say 10 folds). From that step, I determine which is the best algorithm and/or the best parameters for an algorithm. I train a new model with all the training data (without k-fold) using the parameters that I found to be the best in step 2 . Finally, I use the test data (from step 1) to confirm that this is a good model. Is that correct? I only use the test data at the end when I have found a single model (theoretically the best model) and I don't use it during the k-fold validation process, correct?
