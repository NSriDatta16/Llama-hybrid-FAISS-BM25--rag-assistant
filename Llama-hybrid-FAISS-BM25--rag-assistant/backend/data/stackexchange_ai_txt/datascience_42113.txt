[site]: datascience
[post_id]: 42113
[parent_id]: 42051
[tags]: 
We know an MLP can compute any function on a compact support (up to any degree of accuracy). I'm not a neural network expert, but my intuition says that you could try to model it with a network with a hidden layer containing say 100 hidden neurons. Then just feed it the data you mentioned: for each age $a$ feed it the training data $\{(0, a),\ (1, a-1), \ \ldots,\ (a, 0)\}$ . I'm not sure binning the results would be helpful in this case. It might be helpful to first take a known distribution such as the Gaussian distribution (which of course life expectancy is not), generate some training data from that, and see if you can approximate it.
