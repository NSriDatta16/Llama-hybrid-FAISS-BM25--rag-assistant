[site]: datascience
[post_id]: 117132
[parent_id]: 
[tags]: 
How an image is represented by a tensor?

I have been reading a little bit about Deep Learning and particularly the part of tensors, but I have a doubt about how an image or other object is represented by a tensor; particularly when is used as an input to a neural network. For example, if we consider the MNIST dataset I read that the information is distributed in rows where each row represents the pixel density value. So if each image has from pixel 1 to pixel 783 then we can transform these into a 28*28 array. For what I know when one uses scikit for NN we can feed the NN with each row of 784 values or pixels and perform the necessary operations, but I have the doubt how is this procedure performed when one uses tensors. I read for example the following: Here I got confused, if I want to represent a mnist digit using tensors I suppose that it will not have the form of a matrix, 28*28, but because of the sample_size this would have the form of a cube. For example, in the form of an array I will have: However, I just do not get still what would be the value of sample_size, is it 1? is it 28*28=784? ; also for me it seems that it would always be a constant number, so what is the reason to have this sample_size number? Any help? Thanks
