[site]: crossvalidated
[post_id]: 86572
[parent_id]: 
[tags]: 
Is it possible for a bayesian model to "forget" about some points?

Say you are doing some online bayesian inference over observations. You want to infer $\mu, \sigma$ for $X$, with a model $X \sim \mathcal{N}(\mu, \sigma)$. Now everytime you observe a $X_i$, you update your prior with your new posterior and get a new estimate $\mu_i, \sigma_i$. That becomes the prior for your next observation, etc etc. Now after $n$ observations, your estimates $\mu_n, \sigma_n$ come from applying "recursively" bayes to your priors $\mu_0, \sigma_0$, where : $$P(\mu_n, \sigma_n) \propto P(\mu_{n-1}, \sigma_{n-1}) \times P(X_n \sim \mathcal{N}(\mu_{n-1},\sigma_{n-1}) | \mu_{n-1},\sigma_{n-1})$$ Now is it possible to make your bayesian model "forget" about old points without having to recalculate the whole chain ? In other words, if you wanted to apply this model to a stream of data (because you have lots of points), can you make it forget about old points ? I hope I'm clear enough with my question, I'll edit as comments come if needed. Thanks a lot
