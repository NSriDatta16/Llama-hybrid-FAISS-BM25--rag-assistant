[site]: datascience
[post_id]: 123467
[parent_id]: 122164
[tags]: 
The short answer is that a Supervised Fine Tuning Trainer (SFTTrainer) is used for Instruct Fine Tuning. The HuggingFace library SFTTrainer has also support for training with QLoRA (4-bit Quantised model forward pass and LoRA adapters), and also saving the model with that. From the source code the actual work is done by the Trainer baseclass. Note that both the classes are Supervised in that they use the next label (Causal LM ) as the target. Instruction Tuning concept is a higher-level training concept introduced by this paper FineTuned Language Models Are Zero shot Learners (FLAN). Example dataset for the QloRa paper implementation - https://huggingface.co/datasets/mlabonne/guanaco-llama2/viewer/default/train?row=0
