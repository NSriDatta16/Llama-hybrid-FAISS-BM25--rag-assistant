[site]: crossvalidated
[post_id]: 530106
[parent_id]: 
[tags]: 
Dealing with outliers and correlated features for a deep learning based classification problem

I am working on a multi-label multi-class classification problem that required me to use deep learning based approach. The data has around 17000 examples where each example has 42 numerical features and 2 labels. I have no additional information about the features like what they are and where they have been collected from. All I have is numbers. The 1st label has 10 classes while the second label has 2 classes. There are a couple of things that I have found upon exploring the data which are mentioned below: The numerical features have wildly varying ranges. For example, there are some features with a minimum of 0 and a maximum of around 60 and on the other hand, there are some features that have a minimum of 30 and a maximum of 10^7. However, the minimum for all the features is around 25-30. There are several features that contain lots of outliers. I am attaching the box plots for such features below. There are also certain other features that do not contain any outliers. There are some features that are highly correlated to each other (correlation coefficient ranging from 0.8 to 1). Now, I have trained the model with different neural network models. Initially, I approached the problem by using two separate models for 2 label. Here I acheived fairly decent results for both labels. Later on, I combined the two labels by simply concatenating the one hot vectors of two labels and treating it as a multi-label classification. Here, acheive very poor results on the test set even though i used cross validation techniques. (I scaled the data to bring the features into a common range). I am looking for some advice about approaching this problem, particularly about dealing with outliers and correlated features for better performance. Thanks.
