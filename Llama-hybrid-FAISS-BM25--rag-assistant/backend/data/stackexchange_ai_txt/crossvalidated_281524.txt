[site]: crossvalidated
[post_id]: 281524
[parent_id]: 
[tags]: 
Which is better: predict ignoring past values or not?

In a time series, I want to predict $ b_{i+1} $ and I know $ ...,x_{i-1},x_i, x_{i+1} $ and $ ...b_{i-2},b_{i-1},b_i $. I know by prior knowledge that they have a linear relationship: $\alpha * x_i = b_i$ Normally I would just make a linear regression to understand the constant $ \alpha $ and find: $ E[b_{i+1}] = \alpha * x_{i+1}$ But, instead of that what happens if I do this: $\frac{\alpha * x_{i+1}}{\alpha *x_i } = \frac{b_{i+1}}{b_i}$ Or: $\frac{x_{i+1}}{x_i} = \frac{b_{i+1}}{b_i}$ $E[b_{i+1}]=b_i*\frac{x_{i+1}}{x_i}$ Instead of estimating the constant $\alpha$, I am in this case estimating the growth rate $\frac{x_{i+1}}{x_i}$. Simulating this millions of time the standard deviation is the same in the two above models. Example, normal model: b = > 2,4,8,11,12,15,19,22,31,40 x = > 1,2,4,5 ,6 ,8 ,10,11,15,20 Example, changed model: b = > 4, 8, 11, 12, 15, 19, 22, 31, 40 x = > 2*2/1, 4*4/2, 8*5/4, 11*6/5, 12*8/6, 15*10/8, 19*11/10, 22*15/11, 31*20/15 My question is: should we predict using past values or is better to ignore $b_i$ despite having it as information? Although $b_i$ is an observed value, not an expected, it is still a real life data. Shouldn't be better for a model to adapt to the real life data?
