[site]: crossvalidated
[post_id]: 532498
[parent_id]: 
[tags]: 
What value of predictions minimizes the binary cross entropy loss function? Is it 0.5?

I saw some examples of Autoencoders (on images) which use sigmoid as output layer and BinaryCrossentropy as loss function. The input to the Autoencoder is normalized $[0..1]$ . The sigmoid outputs values (value of each pixel of the image) $[0..1]$ I tried to evaluate the output of BinaryCrossentropy and I'm confused. Assume for simplicity we have a [2x2] image and we run Autoencoder and get 2 results. One result is close to the True value and the second is same as the true value: import numpy as np import tensorflow as tf bce = tf.keras.losses.BinaryCrossentropy() y_true = [0.5, 0.3, 0.5, 0.9] y_pred = [0.1, 0.3, 0.5, 0.8] print(bce(y_true, y_pred).numpy()) y_pred = [0.5, 0.3, 0.5, 0.9] print(bce(y_true, y_pred).numpy()) Results: 0.71743906 0.5805602 As you can see, the second example (which is the same as the true value) gets a low score (which is ok, low score of loss function, but it is not zero and its not far away from the first example). It seems that using BinaryCrossentropy as loss function won't give us the best results. Will the best value be close to 0.5? What am I missing?
