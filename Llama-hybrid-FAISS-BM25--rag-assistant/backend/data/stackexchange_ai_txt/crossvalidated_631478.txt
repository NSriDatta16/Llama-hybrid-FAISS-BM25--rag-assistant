[site]: crossvalidated
[post_id]: 631478
[parent_id]: 
[tags]: 
increasing the capacity of an autoencoder

I have an autoencoder model with 5 layers in encoding and 5 layers in the decoding section. I am using this model for signal processing the problem is that it is making the signal way more smooth that I need it to be, losing some important information. I have tried increasing the number of layers in the encoding and decoding part, and the number of filters in the convolution layers to increase the model complexity to be able to capture more details of the signal. I have also tried increasing the number of epochs of training but none of this shows a significant increase in the learning capacity. Is there anything else I can try to do for learning more details of my signal? Thank u in advance :) Here is my model: # Define the input layer input_layer = Input(shape=(500, 1)) # Assuming 1 channel (e.g., for time series data) # Encoding layers encoded1 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(input_layer) encoded1 = MaxPooling1D(2, padding='same')(encoded1) encoded2 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(encoded1) encoded2 = MaxPooling1D(2, padding='same')(encoded2) encoded3 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(encoded2) encoded3 = MaxPooling1D(2, padding='same')(encoded3) encoded4 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(encoded3) encoded4 = MaxPooling1D(2, padding='same')(encoded4) encoded5 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(encoded4) encoded5 = MaxPooling1D(2, padding='same')(encoded5) # Decoding layers (symmetric to the encoding layers) decoded5 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(encoded5) decoded5 = UpSampling1D(2)(decoded5) decoded4 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(encoded4) decoded4 = UpSampling1D(2)(decoded4) decoded3 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(encoded3) decoded3 = UpSampling1D(2)(decoded3) decoded2 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='same')(decoded3) decoded2 = UpSampling1D(2)(decoded2) decoded1 = Conv1D(256, 3, activation='relu',kernel_initializer='he_uniform', padding='valid')(decoded2) decoded1 = UpSampling1D(2)(decoded1) output_layer = Conv1D(1, 3, activation='tanh',kernel_initializer='he_uniform', padding='same')(decoded1) # 1 channel for reconstruction # Create the autoencoder model autoencoder = Model(input_layer, output_layer) # Compile the autoencoder autoencoder.compile(optimizer='adam', loss='mean_squared_error') # Print the summary of the autoencoder model autoencoder.summary()
