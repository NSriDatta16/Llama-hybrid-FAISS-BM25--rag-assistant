[site]: crossvalidated
[post_id]: 284363
[parent_id]: 
[tags]: 
Is it possible to improve training error by removing features in a GBT?

The case for test data is clearly explained in many places, but I'm just thinking about training error here. I believe it's impossible in a decision tree, and possible (though unlikely) in a random forest, but have no clue about how to think for a Gradient Boosted Tree. Appropriate noise might be selected for a split, but is it optimized when we consider the entire chain of trees?
