[site]: crossvalidated
[post_id]: 446874
[parent_id]: 446854
[tags]: 
Yes, increasing the number of hidden neurons should improve the capacity of the model to learn the best function. There's a couple a things you could do. First, I would recommend using one of the more common tools for deep learning, like PyTorch . This will give you more control over what happens inside the neural network. Also, the deep learning performs best when you have multiple layers, as one of the points of deep learning is that the composition of functions leads to better representations of the data from which it can extract information from. Third, try using ReLu activations instead; these are more common in industry now because they give computationally easier gradients and reduces vanishing/exploding gradients, which works better for deeper layers. Try some regularization too, such as dropout layers.
