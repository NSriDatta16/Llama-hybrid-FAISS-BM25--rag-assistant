[site]: crossvalidated
[post_id]: 129989
[parent_id]: 
[tags]: 
How to combine normal distributions in two-dimensional data

My goal is to estimate the click-ability (the percentage of viewers who clicked) of a specific advertisement in a new web-page based on historical data. The nature of my data is such that each web page is categorized by two parameters - The site the page is in (e.g. stackoverflow.com), and type of the page (sports, entertainment, etc..). I know the clickability of my ad in many pages from my historical data, and would like to predict it for a new page which I don't have enough data on. Since each web page is characterized by two parameters, I can summarize my data in a two dimensional sample matrix M'(X,Y), where each data point in the matrix is the click-ability of the ad in the specific combination of website and page type. For example if I know that the average of the click-rates in pages of type Programming in Stackoverflow.com is 0.5, when I get a new page which fits those parameters I will "guess" 0.5 as the click-rate of my ad in that page. When I look at the distribution of click-rates in a specific combination of site and page type, it is distributed normally in a nice bell shape - So in fact my guess is the mean estimator of the normal distribution that is specific to those parameters. My problem arises when I don't have enough information in a specific coordinate in the matrix M'(X,Y) to get a robust estimate of the mean estimator - For example when I have historical data only for 2 web pages of type entertainment in stackoverflow. In that case, and assuming that I have new page in Stackoverflow that is an entertainment page - I can estimate the normal distribution of that advertisement in stackoverflow and independently estimate the distribution in pages of type entertainment in all websites (Not just stackoverflow). The question is how to combine the two normal mean estimators? Here is a concrete example: Each number in the matrix represents what is the click-rate of my advertisement in a specific webpage, base on previous data in which I counted views and clicks in that specific webpage. Each coordinate in the matrix represents the click rates in all the web pages in the specific combination of site and page type. For simplicity I made the number of web pages in each combination of parameters small, but usually it is of size between 0 and 1000. My goal is to obtain the mean and variance parameters that best describes a specific coordinate, even for coordinates with little or no data (such as stackoverflow/entertainment or cnn/programming). For example the mean estimation for stackoverflow and programming would be ~0.5 with a standard deviation of around 0.1. How might this be achieved? Is there a "correct way" to combine the the estimators for each dimension? Most solutions I found on the internet related on how to combine two samples of the same normal distribution - for example the inverse variance method. This doesn't seem quite right in my case - since each normal distribution describes a separate dimension of 2-dimensional data. Another possible solution which doesn't seem right is Combination of two Gaussians . If one dimension has data for 1 million web pages and the other has 1000 - The first one would dominate the combined result, despite the fact that 1000 web pages is enough to get a robust statistic and thus should get the same weight as the other dimension when combining them. Is there any sound solution to this problem?
