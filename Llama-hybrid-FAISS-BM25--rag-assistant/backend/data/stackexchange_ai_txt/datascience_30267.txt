[site]: datascience
[post_id]: 30267
[parent_id]: 
[tags]: 
Policy gradient on data only, without emulators

It is too costly for my team to emulate the agent (executing the action and assessing the reward), meaning our only option is to learn the optimal policy on our dataset. The good thing is that we have a lot of data, that represents a sequence of state, action, reward. We can train our agent on this data. We also need continuous actions, as the set of actions is big. Policy gradient is therefore the way to go but it generally uses an actor-critic that requires an emulator. We can not emulate, what would be the other options?
