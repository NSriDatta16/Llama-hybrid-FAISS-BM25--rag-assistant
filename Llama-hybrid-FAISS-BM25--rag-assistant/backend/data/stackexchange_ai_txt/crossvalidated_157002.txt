[site]: crossvalidated
[post_id]: 157002
[parent_id]: 
[tags]: 
Nested Cross Validation

I am training a linear classifier using SVM. I used nested cross validation. Inner loop is used to estimate the best C (cost parameter) and out loop uses the best C to train and test the classifier. I generated random data X1 X2 and also Y is generated independent of X1 and X2, hence the classification accuracy should be 50%. My problem is that the nested CV and the ordinary CV give the accuracy closer to 50%. In theory Ordinary CV should have an optimistic bias. It is not the case here. Why? In the ordinary CV, first I generated the dataset and the used CV to estimate the C. then again separate CV (using the same data) was run with the estimated C to get the accuracy. Does anybody know what is going on here? Moreover can both ordinary and nested CV give almost the same results given that hyper-parameters are there to estimate?
