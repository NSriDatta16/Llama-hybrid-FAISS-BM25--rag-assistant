[site]: crossvalidated
[post_id]: 113780
[parent_id]: 
[tags]: 
Estimating $n$ and $p$ for Binomial distribution, repeated counting of partly hidden population

A brief motivation: $n$ critters live in an aquarium, where sadly they often hide in, under or behind things. When the aquarium is observed, each critter is only seen with probability $p$ (independently), so the number of critters spotted is $X\sim \operatorname{Bin}(n,p)$. The observer takes repeated counts $X_1, X_2, ... , X_k$. Assume the time interval between counts is long enough that the critters have had time to rearrange themselves, so that $X_i$ and $X_{i+1}$ may be regarded as independent, but not so long that critters are born or die, so that $n$ is fixed. A first issue - I'll call it case (i) - is how $n$ and $p$ might be estimated solely from the vector of observations $(x_1, ..., x_k)$. That's basically this question here . There are method-of-moments and maximum likelihood estimators available. Neither seems good! How could a Bayesian estimation proceed without additional information, is there any sensible prior for $n$? A more interesting, and practical, scenario provides a sort of "anchor" for $n$. Suppose in case (ii) that a while before the observations were made, it was known there were $n_0$ critters, though there may have been births or deaths since. In the absence of any observations, in some sense $n_0$ remains the "best guess" for $n$. Once observations $x_i$ are available, this guess can be updated to reflect new information. This sounds more amenable to a Bayesian approach. Is there a good choice of prior? On the other hand I can't see how knowledge of $n_0$ would affect classical estimates of $n$ - not least because I haven't specified the relationship between $n_0$ and $n$. (It's unrealistic for the observer to know much more than that $n$ is likely near $n_0$.) Now consider case (iii), where critters may die but can't give birth in captivity. The fact there were $n_0$ critters in the past now provides an upper bound on $n$. An obvious non-informative prior for $n$ has probability $\frac{1}{n_0}$ for $n = 1, 2, ..., n_0$ and zero otherwise; perhaps another prior is more useful, but the constraint $n \leq n_0$ means it should look different to case (ii). For classical estimation, the likelihood of $n$ above $n_0$ is zero, so clearly MLE calculations proceed differently. Maybe other estimators can give absurd results with $\hat{n} > n_0$ - could their performance be improved by capping them at $n_0$? I hope the three cases are similar enough to bring together as a single question. In all three, a rough-and-ready $\hat{n}$ would be the maximum observation $x_i$, an approach that would be reasonably successful, albeit downwardly biased (it can't be an overestimate), if the sample size $k$ were large, and particularly if the probability $p$ of a critter being seen was near 1. But case (iii) is distinctive in that, if $x_i = n_0$ for any $i$, we can conclude with certainty that $n$ is $n_0$. I'd be interested in any practical approach, classical or Bayesian, to estimating $n$ and $p$, how such an approach is adapted between the cases, and how well such approaches can be expected to perform. Intuitively they will all struggle when $p$ is low, for instance, but some quantification of that would be brilliant. I'm sure the scenario described here is a well-studied practical problem - features like the partially-observed population of unknown size remind me of the German tank problem - but I can't find a name or discussion of it.
