[site]: datascience
[post_id]: 90354
[parent_id]: 90352
[tags]: 
The code you provided only performs the forward propagation of a neural network without using gradient descent to backpropagate the loss. This means that your network parameters do not change, i.e. your model is not learning anything. The model will always output the same value for an input in your training data and the loss will always stays the same.
