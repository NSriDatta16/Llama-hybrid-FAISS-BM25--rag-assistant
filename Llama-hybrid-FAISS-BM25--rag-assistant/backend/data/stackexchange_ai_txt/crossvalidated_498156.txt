[site]: crossvalidated
[post_id]: 498156
[parent_id]: 498096
[tags]: 
Note this answer used to be much longer, but was also very verbose. So I have deleted all of it. If you like to read more then check version 2 of this post Why do we need p-values? We need them for the cases when the experiment is subject to variability. Our measurements are not just clear examples of some observed effects. Often, measurements are noisy and random behavior is underlying observations. In such cases, we may wish to express/quantify how unlikely it would be that a certain effect is being observed if the null (no effect) hypothesis would be true. The p-value is an indication for the type I error probability. In most settings, the estimated effect corresponds to the maximum likelihood estimate (or some method that is similar). So in this setting, there is no situation that "couldn't we have a similar or even lower likelihood..." because the effect is the effect/theory for which the likelihood is maximized. The reason that we use the p-value is to express how precise the measurement/experiment is, by expressing how likely a measurement of this effect size could have occurred by pure chance. If the observed effect (or anything of similar size) could have likely occurred even when there is no effect present, then the experiment is not very accurate. See for some related topics: Power of a test Mendelian paradox Prosecutor's fallacy Sagan standard likelihood-ratio test Who first used/invented p-values?
