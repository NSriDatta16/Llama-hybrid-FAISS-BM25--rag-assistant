[site]: datascience
[post_id]: 12589
[parent_id]: 
[tags]: 
Can we use a model that overfits?

I am on a binary classification problem with the AUC metrics. I did a random split 70%, 30% for training and test sets. My first attempts using random forest with default hyper-parameters gave me auc 0.85 on test set and 0.96 on training set. So, the model overfits. But the score of 0.85 is good enough for my business. I also did a 5-folds cross validation with the same model and same hyper-parameters and the test set results were consistently something between 0.84 and 0.86 My question is: can I believe on the score 0.85 and use this model in production?
