[site]: datascience
[post_id]: 68494
[parent_id]: 
[tags]: 
Basic questions about hamming network

I'm reading Hogan et al's Neural Network Design book very closely. I have run into a couple of questions about its presentation on Hamming networks. In particular, it says: The next network we will consider is the Hamming network [Lipp87]. It was designed explicitly to solve binary pattern recognition problems (where each element of the input vector has only two possible values â€” in our example 1 or ). OK I guess. That's sort of not what is meant by "binary classification", but they use a slightly different phrase, so I'll give them the benefit of the doubt. So can a Hamming network do multiclass classification or not? Certainly, this quote does not exclude that possibility. If so, what does the weight matrix look like in the recurrent layer? The example they show is for binary classification (apples and oranges), and give $$ W^2 = \begin{bmatrix} 1 & -\varepsilon \\ -\varepsilon & 1 \\ \end{bmatrix} $$ where there are some constraints on $\varepsilon$ . Can someone confirm that, in the multiclass case, this generalizes to the matrix defined by $$ W^2_{i,j} = \begin{cases} 1, \text{ if } i = j \\ -\varepsilon, \text{ otherwise} \end{cases} $$
