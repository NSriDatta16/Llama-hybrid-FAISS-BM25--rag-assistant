[site]: datascience
[post_id]: 77922
[parent_id]: 77916
[tags]: 
As rightly pointed out by @erwan, it is a bad idea to use data augmentation with 'text data' The problem of 'training with less data' can be approached in many ways, here I enlist two ways which helped me with significant impact: (a) One approach would be to use semi-supervised approach. There are open sourced language models trained on insanely massive datasets, that can be used to perform a specific task like custom NER or sentence classification. Transfer learning is more useful today then ever. (b) Anyways if we want to go ahead with Data augmentation, 'Sentence‚ÄêChain Based Seq2seq Model for Corpus Expansion' is one of the proven methods to proceed. Please find the link to paper here . I will strongly recommend to experiment with BERT before moving to Corpus Expansion. For introduction to transfer learning, BERT etc. please visit here .
