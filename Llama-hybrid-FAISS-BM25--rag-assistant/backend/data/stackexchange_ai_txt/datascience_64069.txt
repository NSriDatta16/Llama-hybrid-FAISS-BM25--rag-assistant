[site]: datascience
[post_id]: 64069
[parent_id]: 
[tags]: 
Conv Net Model is overfitting

So I made a convolution neural network to classify between different phonemes. My input datasets are a series of 0.4-second long spectrograms, the labels are each an individual phoneme that happens at every 1/100th of a second. So a 10-second long video would have 1000 labels. If I pick frame 100, the input would be a spectrogram starting from frame 80 and ending at frame 120. The longest phoneme lasts for 20 frames but the extra length is kept for context. The structure of the model is one convolution layer with 30 filters, RELU, max-pooling, and finally one fully-connected layer to act as the output layer. There is also a 35% drop-out on the convolution layer. My dataset is a 26-minute video of me speaking the first third of the sponge bob movie script (not very professional, I know). I used incremental learning by splitting the dataset into 1-minute pieces. For each training iteration, it made 10 batches, with each batch being 64 random frames from 1 specific minute of the dataset. If the model got above 70% on one 'minute', and the model accuracy didn't change by over 3% within 30 batches, it moved on to the next minute. Unfortunately, even if the model got around 70% on the training data, it still underperformed on the testing data as it consistently got around 30%. I have run out of ideas to solve this sever overfitting problem, any suggestions would help.
