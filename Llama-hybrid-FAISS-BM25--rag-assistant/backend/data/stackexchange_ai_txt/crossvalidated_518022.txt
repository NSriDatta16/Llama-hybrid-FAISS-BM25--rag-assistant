[site]: crossvalidated
[post_id]: 518022
[parent_id]: 
[tags]: 
Can I set batch size to 1

I am trying to train a T5 (t5_large) transformer model on some data. Since it's out of cuda memory, I was forced to set batch_size to 1 so that I can run the model on my computer. Now, my question is what other consideration I must take into account. Should I check the model convergence? if yes how? Then, should I increase the epochs? It's currently 1 epoch.
