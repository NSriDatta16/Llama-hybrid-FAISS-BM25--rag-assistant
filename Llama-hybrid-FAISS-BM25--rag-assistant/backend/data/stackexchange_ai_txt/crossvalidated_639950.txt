[site]: crossvalidated
[post_id]: 639950
[parent_id]: 
[tags]: 
Is this a known or valid divergence between two densities?

I am testing various metrics for learning a density estimate. Specifically, I have a sample of data from a distribution $p$ , and am learning a function $f$ to estimate $p$ by minimizing a distance or divergence between the two (via Monte Carlo integration over the sample $p$ ). The usual metrics such as Cramer-von Mises, Kolmogorov-Smirnov, Mean Integrated Squared Error, etc. are working well as expected. One metric I tried that is yielding surprisingly good results is: $$d(f, p) = 1 - \int_{\mathcal X} f^\gamma(x) p(x) \, dx$$ where $\mathcal{X}$ is the support of the densities and $\gamma$ is a small value, i.e. close to zero. Note that $p$ is not being raised to the power of $\gamma$ as $p$ is known only through the sample. Is this a valid or known divergence? Edit: Uploaded an animation of a neural network learning a target density (mixture of 3 Gaussians) via this metric when $\gamma = 10^{-5}$ . Edit 2: I believe this may be working because it is (potentially) approximating a more general class of statistical divergences given by $$d(f, p) = 1 - \int_{\mathcal X} f^\gamma(x) p^{1-\gamma}(x) \, dx$$ where $0 . It may be working because when $\gamma$ is close to zero, $p^{1-\gamma} \approx p$ . Under this more general formulation, the squared Hellinger distance ( $H^2$ ) is a special case when $\gamma=\frac{1}{2}$ : $$H^2(f, p) = 1 - \int_{\mathcal X} f^\frac{1}{2}(x) p^{1-\frac{1}{2}}(x) \, dx$$ . I'm unsure of what the effects are of varying the value of $\gamma$ when using this divergence measure for density estimation. But, going back to my original question, is this (either the general formulation or the specific case when $\gamma$ is close to zero) a known or valid divergence?
