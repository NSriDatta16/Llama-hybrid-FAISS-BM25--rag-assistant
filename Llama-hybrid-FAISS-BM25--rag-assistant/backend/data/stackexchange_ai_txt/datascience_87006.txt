[site]: datascience
[post_id]: 87006
[parent_id]: 
[tags]: 
Calculating Uncertainty for categorical predictions

I am wondering what is the best way to calculate the uncertainty for my categorical predictions. I have created a model that predicts what rating a movie is getting based on certain keywords and the amount of times these key words are mentioned. I have trained the model with a small data matrix and now I am running it though a bigger data matrix that has data from over 20,000 reviews. I have used different models and different variations of my dataset (feature engineering and feature selection) and now that I have my results from my best model/dataset combination, I want to learn how to calculate the uncertainty of my results per rating. Could I use the confusion matrix or other metrics (sensitivity etc) to calculate the uncertainty? Example Predictions: Rating1: 1000 Rating2: 25 Rating3: 59 Rating4: 599 Rating5: 3569 Thank you!
