[site]: crossvalidated
[post_id]: 494264
[parent_id]: 494263
[tags]: 
Apparently, Tensorflow computes the average of the negative log likelihood terms rather than their sum: import tensorflow as tf def categorical_ce(y, logit, reduce_mean=True): cce = \ -tf.reduce_sum( tf.math.log( tf.nn.softmax(logit) ) * tf.one_hot( tf.cast(y, tf.int32), logit.shape[1] ), axis=-1 ) if reduce_mean: cce = tf.reduce_mean(cce) return cce A quick check bellow reveals that the result matches the one computed by SparseCategoricalCrossentropy : >>> print(logit) tf.Tensor( [[-0.07976019 1.4097637 0.31711328 -0.56984025 -0.2769775 0.14477172 0.6587809 0.03351004 0.24701062 0.55834836] [ 0.07477544 0.7773567 -0.09413219 0.00184567 0.0491263 0.19461593 0.47267246 0.02392993 0.56105083 0.22566506]], shape=(2, 10), dtype=float32) >>> print(y) [9 0] >>> tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(y, logit) >>> categorical_ce(y, logit) As jkpate points out , this average is an estimate of the cross-entropy of the model probability and the empirical probability in the data, which is the expected negative log probability according to the model averaged across the data. Moreover, computing the average effectively de-couples mini-batch size and learning rate, see Mean or sum of gradients for weight updates in SGD .
