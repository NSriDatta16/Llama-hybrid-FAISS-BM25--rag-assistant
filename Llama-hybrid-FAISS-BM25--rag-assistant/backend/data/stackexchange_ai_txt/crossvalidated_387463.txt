[site]: crossvalidated
[post_id]: 387463
[parent_id]: 387067
[tags]: 
I do not know where people get the idea that one cannot use least squares to fit time series models. Not only can one use least squares, oftentimes one should use least squares to fit these models. It is not just me saying this; see, for example, the definitive reference in the field , or just wikipedia . Least squares estimation has nothing to do whatsoever with the type of data being analyzed, whether it is correlated or not, since it is fundamentally an application of the normal equation from linear algebra. The only property of data that prevents least squares estimation is that of perfect multicollinearity , and if this is occurring in your data, there are other, larger problems at work. Since you want some practical advice on how to estimate linear time series models, I will give you some. Suppose that you want to estimate the stable $N$ -dimensional vector autoregressive process $$ \begin{aligned} y_t = c + \sum_{p=1}^P A_py_{t-p} + u_t, \end{aligned} $$ where $u_t \sim \mathcal{N}(0,\Sigma)$ , and $A_p,\ \Sigma \in \mathbb{R}^{N \times N}$ with $\Sigma$ positive semidefinite (as a covariance matrix must be). We suppose there is data for this model for all $t \in \{1,2,...,T\}$ . What we do to solve this problem using ordinary least squares is write the process in matrix notation : $$ Y = XB + U, $$ where $Y = (y_p,y_{p+1},...,y_T)^T$ , $B = (c, A_1,...,A_p)^T$ , $$ X = \begin{pmatrix} 1 & y_{p-1} & \cdots & y_0\\ 1 & y_p & \cdots & y_1\\ \vdots & \vdots & \ddots & \vdots\\ 1 & y_{T-1} & \cdots & y_{T-p} \end{pmatrix}, $$ and $U = (u_p, u_{p+1}, \cdots, u_{T})^T$ . Now this is a standard problem in linear algebra, as I commented above: $$ \begin{aligned} Y \simeq XB \implies X^TY = X^TXB \implies B = (X^TX)^{-1}X^TY, \end{aligned} $$ the usual least squares estimator. When you code this up, you will of course use the most numerically-stable pseudoinverse that you can instead of the real inverse of the matrix. I will note that, in my own work, the only time I do not use least squares to estimate a VAR model is when I want to incorporate prior assumptions. I will briefly outline an example model for you. For example, suppose that we have some beliefs about covariance matrix $\Sigma$ , as well as beliefs about the mean of the coefficient matrix $B$ . Then we can define a simple hierarchical model as $$ \begin{aligned} \sigma \sim \mathrm{Log}\mathcal{N}(0, 1)\\ \Sigma \sim \mathrm{LKJ}(\sigma, \eta=1)\\ B \sim \mathcal{MN}(\mu, 1)\\ Y \sim \mathcal{N}(XB, \Sigma). \end{aligned} $$ Here we have introduced the LKJ distribution , which is a sensible choice for priors over covariance matrices, and the matrix-normal distribution $\mathcal{MN}(\mu, \sigma)$ with mean matrix $\mu$ .
