[site]: crossvalidated
[post_id]: 536189
[parent_id]: 
[tags]: 
Is feature crossing actually useful in deep learning, which uses activation functions?

So i know feature crossing is a way to transform the data such that it can be linearly separated, which makes it useful for things like classification. But in a DNN, activation functions replicate non-linearity as well. So is feature crossing really useful in Deep Learning? EDIT: this question is not asking about feature crossing with traditional ml methods, like linear-regression or SVM. I am asking about deep neural networks, which automatically transform features and generate non-linearity
