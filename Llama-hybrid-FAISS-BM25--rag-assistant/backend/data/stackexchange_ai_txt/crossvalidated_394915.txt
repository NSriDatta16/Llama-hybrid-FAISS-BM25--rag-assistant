[site]: crossvalidated
[post_id]: 394915
[parent_id]: 
[tags]: 
Log or MSE loss for hyperparameter tuning of probabilistic NN

I am building a predictive model of a dynamical system using a NN whose output neurons enconde the mean and diagonal covariance of a Gaussian distribution. For training, the negative log prediction probability is used as the loss function. I wish to use bayesian optimization to tune various hyperparameters (number of hidden layers, neurons per layer, etc). For such hyperparameter optimization, would it be best to minimize MSE or log prediction probability over the testing data? I know that for predictive models MSE is usually used, but I am afraid that by using this metric the probabilistic aspect of the NN will be disregarded during the hyperparameter optimization. Thank you.
