[site]: datascience
[post_id]: 36970
[parent_id]: 
[tags]: 
Is it appropriate to use polar images as input to CNNs? Or must they be Cartesian transformed first?

I have built a convolutional neural net which trains on data originally represented in polar space (measurements are a function of angle and distance). My pipeline begins by converting coordinates to a Cartesian grid and re-projecting the images. This however results in a significant increase in the data dimensions (i.e. pixel size of the input images) and requires interpolation steps which I would prefer to avoid. Is there an appropriate method (implemented in keras/tensorflow) I can use for performing (2D) convolutions on the raw polar data? I have followed the cs231n course, so I have some background but am not yet an expert, especially on the theory side. Thanks!
