[site]: crossvalidated
[post_id]: 440880
[parent_id]: 440876
[tags]: 
What you are describing is the most basic Markov Chain approach, which is kinda naive (in the technical sense). You can only decompose the terms like that if each token is strictly dependent only on the previous token. The whole advancement had been brought about models that are higher-order. For example, you could then decompose the probability of 'jumped' as: $p('jumped'|'the\ cat') = p('jumped'|'the') + p('jumped'|'cat')p('cat'|'the')p('the')$ This is just an order-2 example since it's the maximum we can get with three words; it gets increasingly more baroque as you expand the context window.
