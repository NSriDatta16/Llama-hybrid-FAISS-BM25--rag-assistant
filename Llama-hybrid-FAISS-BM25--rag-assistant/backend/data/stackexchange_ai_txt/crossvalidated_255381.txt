[site]: crossvalidated
[post_id]: 255381
[parent_id]: 255375
[tags]: 
I think the question is not specific enough to be answered. Scikit-learn is a big library for machine learning with python, different algorithms have different optimization problems. And in most problems tol are used as a stopping criteria for the optimization. BUT in different model / algorithm, the tol can be different. For example, in Lasso , the documentation says The tolerance for the optimization: if the updates are smaller than tol, the optimization code checks the dual gap for optimality and continues until it is smaller than tol. This tol can only be used in Lasso, since it checks "dual gap", if you are training a neural network, the "dual gap" definition does not exist. On a very high level, many machine learning task can be formulated into a "iterative process" to get all the parameters in the model, but when should we stop the iteration? There are different ways to stop. Limit number of iterations Check if the parameters converge (do not change over iterations) Check some other metrics (such as gradient, gap be beteween primal and dual) Many more When we do checking, tol can be used.
