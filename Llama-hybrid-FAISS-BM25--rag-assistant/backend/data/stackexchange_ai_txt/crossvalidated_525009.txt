[site]: crossvalidated
[post_id]: 525009
[parent_id]: 
[tags]: 
How to interpret "place gaussian process prior directory on sigmoid function"

In the Gaussian process for machine learning book, under the classification section it states that we can have: $f(x) = w^{\top}x$ , the probability of the class being 1 or -1 as $\pi(x) = \sigma(x) = \frac{e^x}{e^x + 1}$ , and that for classification we place a Gaussian prior on $\mathbf f$ resulting in the re-definition of the probability as $\pi(x) = \sigma(f(x))$ Concretely, what does this tell one to do? Do I assume $f(x)$ is still $w^{\top}x$ , with the $w$ drawn from $N(0, K)$ , (N denotes the Gaussian density with mean vector 0 and covariance K) where $K$ is the kernel matrix of the inputs $x$ ?
