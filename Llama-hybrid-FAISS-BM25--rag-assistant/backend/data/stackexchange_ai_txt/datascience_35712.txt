[site]: datascience
[post_id]: 35712
[parent_id]: 35694
[tags]: 
I'm not exactly sure of cvpartition 's routine, so I'll try to provide a more generalised answer. "Whole set" v "full data set" These are the same in this instance. Model hyperparameter tuning can be done by feeding the full / whole / complete data set into a cross validation process. Inside this cross validation, the data is split into k folds, where (k - 1) folds are used to build a model, and the remaining fold is used to test the model (since the remaining data is essentially unseen to the model). This is repeated k times; results can be averaged and standard deviation calculated. Seen v unseen data (a.k.a. modelling and hold out samples) This is essentially a variation on the cross validation approach above, except the split is done only once: the full data is split into two subsets - Xtrain and Xtest in your case. In this approach, you would build a model using Xtrain only and test it on Xtest (there is no repetition). So, what's the difference? Both approaches attempt to do the same thing - somehow validate a model's performance and ability to generalise on unseen data. Cross validation is arguably the stronger technique, especially on smaller data sets. Once you've successfully parameterised your model (using either approach), building your model on the whole data set is advisable since more data > less data.
