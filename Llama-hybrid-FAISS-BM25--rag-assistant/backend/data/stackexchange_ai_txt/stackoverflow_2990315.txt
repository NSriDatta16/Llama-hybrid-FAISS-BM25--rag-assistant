[site]: stackoverflow
[post_id]: 2990315
[parent_id]: 
[tags]: 
question about Littles Law

I know that Little's Law states (paraphrased): the average number of things in a system is the product of the average rate at which things leave the system and the average time each one spends in the system, or: n=x*(r+z); x-throughput r-response time z-think time r+z - average response time now i have question about a problem from programming pearls : Suppose that system makes 100 disk accesses to process a transaction (although some systems require fewer, some systems will require several hundred disk access per transaction). How many transactions per hour per disk can the system handle? Assumption: disk access takes 20 milliseconds. Here is solution on this problem Ignoring slowdown due to queuing, 20 milliseconds (of the seek time) per disk operation gives 2 seconds per transaction or 1800 transactions per hour i am confused because i did not understand solution of this problem please help
