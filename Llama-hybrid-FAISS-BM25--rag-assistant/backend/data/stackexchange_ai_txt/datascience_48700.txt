[site]: datascience
[post_id]: 48700
[parent_id]: 48645
[tags]: 
I did not find a conclusive answer to your question. I present the closest content that I found, and my personal thoughts. The closest I got was finding these well-cited papers: 1997 How the brain learns to see objects and faces in an impoverished context Our results support psychological theories that perception is a conjoint function of current sensory input interacting with memory and possibly attentional processes. 2004 The reverse hierarchy theory of visual perceptual learning , RHT proposes that na√Øve performance is based on responses at high-level cortical areas, where crude, categorical level representations of the environment are represented. Hence initial learning stages involve understanding global aspects of the task. Subsequent practice may yield better perceptual resolution as a consequence of accessing lower-level information via the feedback connections going from high to low levels ( wiki page on Perceptual learning ). which lack the required comprehensiveness to answer the question. By going through the citations, I would say there is not yet a satisfying, and well-received answer to your question, which would usually lead to a highly-cited paper with a catchy title! Among projects, I came across Project Prakash which seems interesting and related: The goal of Project Prakash is to bring light into the lives of curably blind children and, in so doing, illuminate some of the most fundamental scientific questions about how the brain develops and learns to see ( from here ). along with an interesting (but addressed as controversial) TED talk that shows how well blind adults that are cured recently manage to detect objects by putting emphasis on the role of motion (which objection detection methods based on single image lack). Here is an example of distinct objects that they detect, which is possibly worse than artificial neural networks. Here are my thoughts regarding "the task" (which overlaps with @PedroHenriqueMonforte nicely put answer about evolution): A "task" has an objective, a goal. What is the goal of brain at the highest level? To serve the gene for survival and reproduction. What if brain (eye, heart, etc.) fails at this task? The gene will be removed from the pool. This is meta-learning, learning to learn. A pool of learners (genes that create brains that can learn to see) are constantly struggling to survive, where better (faster) learners have a higher chance of achieving the goal. This is the main supervision . At the extreme, the gene pool can get the job done by merely guessing the initial brain weights! The most important take away here is that brains are evolving for about 450 million years. I think this alone suggests that not all of the visual understanding happens after birth. That is, animals are being born with good architectures and initial weights to begin with, analogous to being handed a network that is pre-trained on the task of survival and reproduction . From this perspective, visual training based on visual input would be more like a fine-tuning.
