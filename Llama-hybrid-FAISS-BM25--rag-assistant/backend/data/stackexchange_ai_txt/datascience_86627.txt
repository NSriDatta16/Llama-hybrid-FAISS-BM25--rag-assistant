[site]: datascience
[post_id]: 86627
[parent_id]: 
[tags]: 
Finding and ranking best semantic matches between two sets of phrases

I'm looking for a proper definition for what sort of problem this is, so I can further research it on my own - though I will, for sure, appreciate any specific advice on what are industry standard ways for working on this. While I'm fairly inexperienced with NLP or recommender systems, I've done a fair amount of classical ML before, in case that matters. The problem - given a "search" query with a list of inputs and a list of expected outputs, retrieve and rank up to N best semantic match for each input. Constraints: All inputs and outputs are anywhere between a word and a sentence. Number of outputs >= number of inputs. All inputs and outputs are unique within themselves, but there can be outputs that are identical to inputs. Every input is guaranteed to have at least one "good enough" output present. Every output is guaranteed to be the best match for at most one input. Labelled data is available, i.e. human-tagged queries. Inputs are sparse, i.e. inputs for queries targeting identical or very similar output sets can be very different. Data is in English, and I work in Python - if that matters for your suggestions. An example: Inputs (1) Truck (2) Assortment of lemons, limes, and oranges. (3) Apples, pears, and oranges. (4) A tool with broad blade, used for digging. Outputs (a) Citrus fruits (b) Portable telephone that can make and receive calls over a radio frequency. (c) Fruits traditionally grown in Germany. (d) Vehicles used for cargo transportation. (e) Shovel (f) Motor vehicle used for transportation. Desired result (numbers are arbitrary, for illustrative purposes) 1 - d (100%), f (75%) 2 - a (95%), c (60%) 3 - c (87%), a (45%) 4 - e (100%) Similar question suggestions by Stack Exchange are not answering my question, and searching for the answer elsewhere just pits me into endless stream of articles about sentiment analysis of IDMB or Twitter datasets.
