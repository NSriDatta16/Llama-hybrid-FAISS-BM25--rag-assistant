[site]: crossvalidated
[post_id]: 79158
[parent_id]: 7134
[tags]: 
I haven't had to do battle with any bad reviewers yet, so I wouldn't claim any knowledge of how to get out of a battle that's already begun. However, if their objections are a mere matter of obstructive ignorance, a little preemptive diversion might do the trick. If $p$ values are in fact necessary to report despite their non-negligible invalidity in a problematic study (a class into which all too many published articles fall), one might downplay them implicitly. Consider focusing your narrative instead—maybe even exclusively—on effect sizes. If your study is sufficiently representative to be usefully informative (this shouldn't necessitate perfectly random sampling, only caution in the generality of interpretations), your effect sizes ought to have broader implications than merely indicating the existence and directions of relationships or differences anyway. Focusing one's discussion on effect sizes can facilitate a deeper understanding of how much the relationships or differences matter in a practical sense, though this still needs to be considered in the context of the subject of study (e.g., one cannot conclude by size alone that an $r = .03$ is necessarily unimportant if it might pertain to a matter of life and death; Rosenthal, Rubin, & Rosnow, 2000) . You can do this by discussing results in terms of "weak," "moderate," or "strong" relationships or "small" or "large" differences instead of referring to them as "significant" and "insignificant"; the latter two words shouldn't be necessary whatsoever to make most of the points researchers want to make. If the $p$ values are necessary, let them speak for themselves. Do meta-analysts a favor and just sandwich them in more comprehensive reports of valuable statistics: effect sizes, confidence intervals, and test statistics. Maybe hope for a day when readers and reviewers will ignore $p$ values and demand confidence intervals, so that the $p$ values can be ditched entirely. (Or maybe not! See post-postscript!) Another, potentially complementary option would be to expand on your footnote. Both your descriptions of the problem as reviewers have experienced it, and the presently accepted answer on this page, suggest that not enough information is conveyed to explain your motivation for including the footnote, nor enough to motivate the reader to follow your citation to the reference that you use to explain it so tersely. A single, additional sentence, even a brief quote from your reference, could go a long way toward explaining the value of your footnote and motivating readers to read deeper. Evidently, your footnote as is sooner motivates a simple, negative, dismissive reaction toward your understated attempt to disrupt their complacency about their improper assumptions. Readers might be a little less intellectually lazy if you spoonfeed them one or two of the main points about problems that they probably overlook routinely. Also, for many particular problems with $p$ values, consider citing not just that book, but also a fairly concise journal article that's freely available online presently (e.g., Goodman, 2008 , Wagenmakers, 2007 ) . That might help reduce any resistance due to the difficulty of obtaining a book and finding the relevant info within. P.S. Thanks to @rpierce for Wagenmakers (2007) and much of the logic of my answer, and to @FranciscoArceo for Goodman (2008) ! See also Francisco's loosely related answer , as well as some other popular posts here on Cross Validated about interpreting $p$ values properly: What is the meaning of p values and t values in statistical tests? Understanding p-value P.P.S. @MichaelLew's counterpoint is also worth considering before tossing the $p$ values out entirely! See Senn (2001) and Lew (2013) for some rare and valuable (but only partial) defenses of $p$. [Edit]: Also, I brought up this question in a new question, " Why are 0.05 " In discussing my answer, the OP brought up Hurlbert and Lombardi (2009) , which I brought up with my colleagues, one of whom then brought up Nuzzo (2014) , a brand new Nature News article that led to even more references ( Goodman, 2001 , 1992; Gorroochurn, Hodge, Heiman, Durner, & Greenberg, 2007 ) ...I am obviously not keeping up at this point, but Michael is just as clearly not alone in defending the possibility of extracting useful information from exact $p$ values (when they do "strictly apply", at least). References - Goodman, S. N. (1992). A comment on replication, P ‐values and evidence. Statistics in Medicine, 11 (7), 875–879. - Goodman, S. N. (2001). Of P -values and Bayes: A modest proposal. Epidemiology, 12 (3), 295–297. Retrieved from http://swfsc.noaa.gov/uploadedFiles/Divisions/PRD/Programs/ETP_Cetacean_Assessment/Of_P_Values_and_Bayes__A_Modest_Proposal.6.pdf . - Goodman, S. (2008). A dirty dozen: Twelve P -value misconceptions. Seminars in Hematology, 45 (3), 135–140. Retrieved from http://xa.yimg.com/kq/groups/18751725/636586767/name/twelve+P+value+misconceptions.pdf . - Gorroochurn, P., Hodge, S. E., Heiman, G. A., Durner, M., & Greenberg, D. A. (2007). Non-replication of association studies: “pseudo-failures” to replicate? Genetics in Medicine, 9 (6), 325–331. Retrieved from http://www.nature.com/gim/journal/v9/n6/full/gim200755a.html . - Hurlbert, S. H., & Lombardi, C. M. (2009). Final collapse of the Neyman–Pearson decision theoretic framework and rise of the neoFisherian. Annales Zoologici Fennici, 46 (5), 311–349. Retrieved from http://xa.yimg.com/kq/groups/1542294/508917937/name/HurlbertLombardi2009AZF.pdf . - Lew, M. J. (2013). To P or not to P: On the evidential nature of P-values and their place in scientific inference. arXiv:1311.0081 [stat.ME]. Retrieved from http://arxiv.org/abs/1311.0081 . - Nuzzo, R. (2014, February 12). Scientific method: Statistical errors. Nature News, 506 (7487). Retrieved from http://www.nature.com/news/scientific-method-statistical-errors-1.14700 . - Rosenthal, R., Rosnow, R. L., & Rubin, D. B. (2000). Contrasts and effect sizes in behavioral research: A correlational approach. Cambridge University Press. - Senn, S. (2001). Two cheers for P-values? Journal of Epidemiology and Biostatistics, 6 (2), 193–204. Retrieved from http://www.phil.vt.edu/dmayo/conference_2010/Senn%20Two%20Cheers%20Paper.pdf . - Wagenmakers, E. J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin & Review, 14 (5), 779–804. Retrieved from http://www.brainlife.org/reprint/2007/Wagenmakers_EJ071000.pdf .
