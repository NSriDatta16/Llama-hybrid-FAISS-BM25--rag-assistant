[site]: crossvalidated
[post_id]: 10426
[parent_id]: 10423
[tags]: 
What you've hit on here is the curse of dimensionality or the p>>n problem (where p is predictors and n is observations). There have been many techniques developed over the years to solve this problem. You can use AIC or BIC to penalize models with more predictors. You can choose random sets of variables and asses their importance using cross-validation . You can use ridge-regression , the lasso , or the elastic net for regularization . Or you can choose a technique, such as a support vector machine or random forest that deals well with a large number of predictors. Honestly, the solution depends on the specific nature of the problem you are trying to solve.
