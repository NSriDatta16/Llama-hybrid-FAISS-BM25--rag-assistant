[site]: crossvalidated
[post_id]: 483146
[parent_id]: 
[tags]: 
What is the distinction between bias in prediction and parameter estimation?

I am trying to understand the distinction between bias in prediction and parameter estimation. This example in Gelman, Bayesian Data Analysis , 2nd ed. 2004 pp. 255-256 is very confusing to me. Why do you get the estimate $\hat{y} = 160 + 0.25(\theta - 160)$ given fixed $\theta$ and $\hat{\theta} = 160 + 2(y - 160)$ under repeated sampling of $y$ conditional on $\theta$ ? I'm not sure where these equations are coming from. Does the problem here stem from the fact that the distribution is bivariate (normal) rather than $y$ having a distribution based on each $\theta$ ?
