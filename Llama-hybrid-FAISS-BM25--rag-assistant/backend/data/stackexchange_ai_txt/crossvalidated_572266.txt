[site]: crossvalidated
[post_id]: 572266
[parent_id]: 565212
[tags]: 
The question depends on how you model the learning target. If you model the possibility of the current target to be the next item given the context . The question becomes a binary classification problem, the output targets are given as input. For example, the input will be, first your sequential input [item1, item2, item3, ...], then the possible target [itemk]. However, this could lead to another question, too many input pairs has to be computed, and thus decrease the efficiency of training and prediction process. That's where comes the cascading ranking, and it's adopted in most companies. First the matching stage, retrieve the possible items based on user's preferences, item tags, matching models, etc., reduce the number of targets from billions to thousands. Then the pre-ranking stage, reduce the number of items from thousands to hundreds. After that the ranking stage, reduce the number of items from hundreds to tens. In the ranking stage, the number of input pairs will be easily acceptable, right? If you model the possibility of next item given the context and all target . Then the questions become a multi-target classification problem, the output vector is quite big and nearly impossible to train and predict. Candidate sampling is a necessary tool to speed up the training process, it approximates the softmax distribution by sampling the target, and training only on a small proportion of targets. After training, it's idiomatic to retrieve the softmax weight matrix as item embedding, and import it to fasis or vearch to use a nearest neighbor search. These tools are highly optimized, and could speed up the prediction greatly.
