[site]: crossvalidated
[post_id]: 420358
[parent_id]: 419277
[tags]: 
I wouldn't worry so much about internal structural decisions like which activations to use - for these there is no "right answer", and you can just test multiple architectures with a hyperparameter search as normal. That said, it would probably be helpful to supplement your network with auxiliary outputs (if possible) to help train each input processing architecture in isolation. To use your example of the CLEVR dataset, you could include an auxiliary output to the natural language processing layers which tries to output a representation of the corresponding "functional program". Likewise, if there are some annotations of the image content, add these as an auxiliary output to the image processing layers. Otherwise, the only major thing to get right is to process your inputs correctly so they make the most sense possible to the rest of the network. That means processing sequential data with a sequential layer, image data with convolution layer/s etc. You can then concatenate different inputs and pass them through some dense layers as you wish. Here's a simple example from the keras documentation which combines sequential test data with auxiliary (non-sequential) data. To once again use the example of the CLEVR dataset, you could: Replace this auxiliary input with a CNN giving a dense representation of the image Replace the LSTM auxiliary output with a representation of the functional program Add an auxiliary output to the CNN which outputs information about the content of the image (if this is available)
