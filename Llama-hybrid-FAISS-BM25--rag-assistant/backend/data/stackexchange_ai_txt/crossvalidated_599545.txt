[site]: crossvalidated
[post_id]: 599545
[parent_id]: 599508
[tags]: 
I can see no reason that one-hot encoding (dummy encoding) could lead to data leakage. This is really a simple data transformation, fully determined by the predictor variables, and in no need of estimation or training. It is comparable to calculating the logarithm of a positive variable, no need of any training. There is no choices involved, no use of the $Y$ variable. So doing this before or after train/test split should give exactly the same result. But if the transformations are more involved, maybe target encoding Strange encoding for categorical features which uses the response variable $Y$ . Then doing this before split would use the response variable also from the test set, so data leakage. So maybe what to look at is if your encoding uses the response variable, such encodings might be more used in machine learning than in traditional statistics, explaining this strange advice you refer to.
