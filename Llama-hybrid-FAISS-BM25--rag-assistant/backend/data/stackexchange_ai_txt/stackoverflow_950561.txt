[site]: stackoverflow
[post_id]: 950561
[parent_id]: 950471
[tags]: 
I haven't worked on any scenario as you have here. However, I have in the past discussed a similar issue and here is the outcome of the discussion. (Though I confess I haven't ever seen the implementation). Also, I am afraid there may not be any simple straight forward solution. Assumptions: i. The data to be written is sorted. Solution: i. Fragment your data store into multiple files. Allot a range of the sorted values to each file. eg. record 1-10000 in file 1, record 100001-20000 in file 2 and so on. ii. When you write/read data, you know the range before hand so you can meet point 2. iii. It will also solve point 3 as long as the chance of two or more processes requesting the exact same data is less. To be able to provide more accurate solution we need more information on what you are trying to achieve.
