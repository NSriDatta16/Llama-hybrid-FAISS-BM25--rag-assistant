[site]: crossvalidated
[post_id]: 250273
[parent_id]: 
[tags]: 
Benefits of stratified vs random sampling for generating training data in classification

I would like to know if there are any/some advantages of using stratified sampling instead of random sampling, when splitting the original dataset into training and testing set for classification. Also, does stratified sampling introduce more bias into the classifier than random sampling? The application, for which I would like to use stratified sampling for data preparation, is a Random Forests classifier, trained on $\frac{2}{3}$ of the original dataset. Before the classifier, there is also a step of synthetic sample generation (SMOTE [1]) which balances classes' size. [1] Chawla, Nitesh V., et al. " SMOTE: synthetic minority over-sampling technique. " Journal of Artificial Intelligence Research 16 (2002): 321-357.
