[site]: crossvalidated
[post_id]: 122580
[parent_id]: 
[tags]: 
backward selection but regression coefficients not significative?

I'm running a logistic regression with backard selection method. I get coefficients with p-values>.10. Here's an example: DF Estimate Error Chi-Square Pr > ChiSq Estimate Exp(Est) Intercept 1 -30,32 11,48 6,97 0,01 - v1 1 0,001 0,00 9,70 0,00 0,10 1,00 v2 1 -0,001 0,00 2,84 0,09 -0,07 1,00 v3 1 0,000 0,00 0,12 0,73 0,01 1,00 v4 1 -0,000 0,00 0,11 0,74 -0,01 1,00 v5 1 -0,000 0,00 0,74 0,39 -0,03 1,00 v6 1 0,000 0,00 0,58 0,45 0,02 1,00 v7 1 -0,005 0,00 3,98 0,05 -0,07 1,00 v8 1 0,002 0,01 0,04 0,84 0,01 1,00 v9 1 -0,016 0,05 0,09 0,76 -0,02 0,98 v10 1 0,014 0,03 0,29 0,59 0,03 1,01 v11 1 0,102 0,03 14,77 0,00 0,09 1,11 v12 1 0,009 0,01 1,27 0,26 0,05 1,01 v13 1 -0,017 0,01 2,39 0,12 -0,05 0,98 v14 1 -0,005 0,01 0,48 0,49 -0,03 1,00 My question is, if the algorithm selects best variables, how is it be possible that keeps the variables that have p-values greater than 0.1? I know that the effect is reflected in the value of the coefficient but the pvalue shows the probability that having that value in that coefficient is only a coincidence, and the coefficient is 0 (considering all the other variables). So why is still keeping those?
