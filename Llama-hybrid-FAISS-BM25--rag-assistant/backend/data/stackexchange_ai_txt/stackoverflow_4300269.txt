[site]: stackoverflow
[post_id]: 4300269
[parent_id]: 4299987
[tags]: 
The hardest part of NLP is getting data you can use. Everything else is just math. It may be hard to find a large collection of news articles other than on each news source's website because of all the copyright issues involved. If you don't need recent news, your best bet is probably to look at the Linguistic Data Consortium's English Gigaword corpus ; if you are at a university, there may already be an existing relationship for you to use the data for free. If you need to actually crawl and parse websites, for now you'll probably find you have to write specific parsers for the various news websites to make sure you get the right text. However, once more websites start using HTML5, it will be easier to pull out the relevant text through the use of the article tag . To do the actual crawling, this previous question can point you in some useful directions.
