[site]: crossvalidated
[post_id]: 139084
[parent_id]: 
[tags]: 
Conditional expectation to define causal effect

I'm reading these notes which are discussing the NRCM approach to analyzing causal relationships, that is to say, treats the causal inference problem like a missing data problem (where the missing data are the counter-factual events). So suppose that we use a binary treatment $D_{i}=0,1$ and we have a measurable effect $Y_{i}=Y_{i}(1)D_{i}+Y_{i}(0)(1-D_{i})$, and we define the causal effect of treatment to be $\tau_{i} = Y_{i}(1)-Y_{i}(0)$, and we assume independence and positivity, $$ \big( Y_{i}(0),Y_{i}(1) \big) \perp D_{i}$$ $$ 0 Then we get $$ E[\tau_{i}] = E[Y_{i}(1)] - E[Y_{i}(0)] = E[Y_{i}|D_{i}=1] - E[Y_{i}|D_{i}=0]$$ and I think I understand the logic here: Because of the independence assumption, we can conditionalize on $D_{i}=0$ or $1$ and the expectation of $Y_{i}(0)$ should be unchanged and likewise for $Y_{i}(1)$. However, later in the notes it claims that, if we don't have the independence assumption, we could instead derive $$E[Y_{i}|D=1] - E[Y_{i}|D=0] = E[Y_{i}(0)+\tau_{i}|D_{i}=1]-E[Y_{i}(0)|D_{i}=0]$$ $$ = E[\tau_{i}|D_{i}=1]+\big( E[Y_{i}(0)|D_{i}=1] - E[Y_{i}(0)|D_{i}=0] \big)$$ which is identified as the average treatment effect plus the selection bias. My questions : Why is it that $E[Y_{i}|D_{i}=0]=E[Y_{i}(0)|D_{i}=0]$? Didn't we need the independence assumption to get this? Or is this just because, conditional on $D_{i}=0$, we get $Y_{i} = Y_{i}(0)$? Also, whatever the answer to that question is, why does it not also imply that $E[Y_{i}|D_{i}=1]=E[Y_{i}(1)|D_{i}=1]$? It's my impression that, if independence fails, we shouldn't get the result that $E[\tau_i]=E[Y_i|D_i=1]−E[Y_i|D_i=0]$. This would mean that you could conduct a test using a non-independent treatment and still just average the results of treatment and non-treatment and compute the difference. But intuitively, that shouldn't be correct. However, since we know that $E[\tau_i]=E[Y_i(1)−Y_i(0)]=E[Y_i(1)]−E[Y_i(0)]$ since expectation is linear, then we shouldn't be able to always equate this with $E[Y_i|Di=1]−E[Y_i|D_i=0]$. So I'm trying to figure out exactly where it is that the failure of independence interrupts the usual proof, and I was assuming it would be at the step where $E[Y_i|D_i=1]$.
