[site]: crossvalidated
[post_id]: 617900
[parent_id]: 617637
[tags]: 
There are many good answers with formulas and plots, but I will add a simple intuitive answer. Consider summing independent samples of some noisy signal. Yes, the variance does sum. And so the noise does increase. However, the signal also increases because you take a sum of several samples. And it turns out that the signal increases quicker than the noise, so that the relative value of noise to signal, the signal-to-noise ratio, does in fact decrease. More formally: assume you sum $n$ independent samples. The variance grows proportional to $n$ , and so does the value of the signal (the expected value). However, you can not directly compare the variance to the value, because the variance is related to the square of the value, it has different units than the value. You can calculate standard deviation, which is square root of variance, and it can be directly compared to the value of the signal. And then you see that standard deviation grows proportional to $\sqrt{n}$ (because it is the square root of variance, which grows proportional to $n$ ), while the signal value grows proportional to $n$ , that is, much faster. So the signal-to-noise ratio decreases proportional to $\sqrt{n}$ . So much for the sum of samples. You can also take average of the samples, not simple sum. The average is the sum divided by $n$ . Then the signal value (the expected value) does not change and does not grow. However, the variance in this case does decrease , because the variance of the sum of $n$ samples grows proportional to $n$ , but then we divide the sum by $n$ to take the average, which means that the variance is divided by $n^2$ (remember that variance is related to the square of value). So in the end the variance decreases proportional to $n$ , and the standard deviation decreases proportional to $\sqrt{n}$ .
