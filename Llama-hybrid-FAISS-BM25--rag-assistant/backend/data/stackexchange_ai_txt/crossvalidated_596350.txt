[site]: crossvalidated
[post_id]: 596350
[parent_id]: 596347
[tags]: 
YES Generalized linear models with appropriate “link” functions can force predictions to be positive. For instance, logistic and probit regression squeeze into $(0,1)$ the values given by the linear prediction. Other link functions can allow for different allowed prediction values, such as a $\log$ link forcing values to be positive (but any positive number is possible). Notably, this is different from transforming the outcome variable. Remember that you are (probably) estimating an expected value. For a nonlinear link function $g$ : $$ \mathbb E\left[g\left( Y\vert X=x\right)\right] \ne g\left( \mathbb E\left[ Y\vert X=x \right] \right) $$ Therefore, using a link function is not equivalent to transforming the outcome. This idea can be extended to models such as generalized additive models and neural networks. If $R$ is the regression function that has unconstrained outputs (so $R(X)=X\beta$ for a generalized linear model), you can take $ g(R(X)) $ to assure yourself of positive values.
