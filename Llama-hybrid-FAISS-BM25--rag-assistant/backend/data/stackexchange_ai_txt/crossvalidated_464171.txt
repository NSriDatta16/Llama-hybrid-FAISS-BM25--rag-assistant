[site]: crossvalidated
[post_id]: 464171
[parent_id]: 464153
[tags]: 
I can think of the following: Friedman, J. (2001). Greedy boosting approximation: a gradient boosting machine. Ann. Stat. 29, 1189–1232. doi: 10.1214/aos/1013203451 link Friedman, J., Hastie, T., and Tibshirani, R. (2000). Additive logistic regression: a statistical view of boosting. Ann. Stat. 28, 337–407. doi: 10.1214/aos/1016218222 link J. H. Friedman. Stochastic gradient boosting. Computational Statistics and Data Analysis, 38(4):367–378, 2002. link Friedman, Hastie, and Tibshirani (2000) paper discusses the first successful boosting algorithm, Adaboost from a statistical point of view. Friedman (2001) and the companion paper Friedman (2002) extended the work to generalize Adaboost to Gradient Boosting in order to handle a variety of loss functions. There is a paper I came across but haven't had the chance to go in depth: (May 4) David Mease and Abraham Wyner (2008). Evidence contrary to the statistical view of boosting. Journal of Machine Learning Research, vol 9, pp 131--156 link
