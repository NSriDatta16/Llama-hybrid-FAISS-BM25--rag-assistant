[site]: crossvalidated
[post_id]: 606280
[parent_id]: 606262
[tags]: 
In a Bayesian context, parameter estimation is traditionally based on the concept of a loss function. Using your notation, this a function $L(\theta,\Theta(X))$ which represents the penalty incurred as a result of the difference between the estimated value $\Theta(X)$ and the true value $\theta$ . If we want a point estimator of $\theta$ , we can then choose the $\Theta(X)$ which minimises the expected loss under the posterior distribution of $\theta$ . For example, if the chosen loss function is $L(\theta,\Theta(X))=(\theta - \Theta(X))^2$ (quadratic loss), we minimise its expectation by taking $\Theta(X) = \mathbb{E}(\theta|X)$ , i.e. the posterior mean of $\theta$ .
