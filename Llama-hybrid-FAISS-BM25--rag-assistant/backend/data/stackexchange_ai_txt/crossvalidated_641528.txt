[site]: crossvalidated
[post_id]: 641528
[parent_id]: 
[tags]: 
MCMC seems very sensible to the evidence

currently starting to study bayesian ML, and specifically MCMC, in order to compute the posterior: $$ P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)} $$ Now, I see how the acceptance ratio makes sense considering the detailed balance definition of the Markov Chain. However, the final result doesn't really sound too good to me. In particular, considering the case where the proposal distribution is symmetric ( $N(0,1)$ say), it seems to me that the algorithm is very sensible to the evidence ( $P(D)$ ) In particular, given the acceptance probability being: $$ A(\theta|\theta') = \min\left(\frac{\tilde{P}(\theta|D)}{\tilde{P}(\theta'|D)}, 1\right) $$ It occurs to me that we are highly sensible to the evidence $P(D)$ . Specifically, if the evidence is very far from $1$ : $P(D) >> 1$ then the unnormalized posterior is very "stretched", and thus the ratio between samples when moving to a less likely area, easily gets to $0$ $P(D) \approx 0$ then the unnormalized posterior is very "uniform", and thus the ratio between samples when moving to a less likely area, easily gets close to $1$ Now, I see how this theoretically speaking still works, but practically, it seems like that the algorithm is sensitive to that evidence estimation So the question is: is this even true or am I seeing unicorns? Why don't we do some sort of "Monte Carlo" estimate of the evidence beforehand in order to "attenuate" this illconditioning? (I tried to look it up but I cant find a way to estimate the normalizing constant via MCMC, otherwise maybe a "running estimate" might help)
