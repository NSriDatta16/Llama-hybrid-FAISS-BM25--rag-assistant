[site]: crossvalidated
[post_id]: 535200
[parent_id]: 
[tags]: 
What does "Expectation with respect to true unknown parameter" mean?

I am trying to study the asymptotic properties of MLE, but I am having trouble understanding an expression that seems to be consistently used in all lecture notes available online ( page 93 , page 18 , page 5 ): $$\frac{1}{n}\sum_{i=1}^n l(\theta;X_i) \rightarrow E_{\theta_0}\left[ l(\theta;X) \right]$$ as $n \rightarrow \infty$ . $l$ is a likelihood function, $X_i$ is a sample, $\theta_0$ is the ground truth parameter value. In one of the notes, it says $E_{\theta_0}$ means "expectation with respect to true unknown parameter", but what does this exactly mean? When there is a subscript on $E$ , I always thought it should be a random variable. For example, $E_X[f(X)]$ means $f(X)$ averaged over a distribution of $X$ . But $\theta_0$ (the true parameter value) is not a distribution, but instead, a particular value. Also, shouldn't it be $E_X$ instead of $E_{\theta_0}$ in the above expression, since we are summing over all possible values of $X$ according to its probability?
