[site]: crossvalidated
[post_id]: 449224
[parent_id]: 449220
[tags]: 
As @Henry notes in a comment, this is really a question about how you evaluate the relative costs of false-positive and false-negative classifications. That relative cost directly corresponds to your choice of a probability cutoff. Considerations of accuracy without taking into account relative costs are not very helpful. The "common cut-off value" of 0.5 only makes sense if both types of misclassification are equally costly. Say that the cost of a false positive and that of a false negative are scaled proportionately to sum to 1 and that your model is close to the true model. Then with the cost of a false-positive classification being c , and the cost of a false negative thus (1- c ), you choose c as the probability cutoff value from your model to minimize your overall cost. (See this paper by Buja et al on proper scoring rules, page 13, which also suggests ways to improve performance by using other loss functions in your model to focus attention near particular prior choices of c .) To answer your questions in this context: Your model should be evaluated based on its ability to predict probabilities of class membership or net misclassification costs, rather than its accuracy at any particular choice of classification cutoff c . Choose a cutoff value c that represents the relative costs. With a good model, if you set a cutoff of c = 0.998 you have the corresponding cost of a false negative as 0.002, and you are evaluating the cost of a false positive as almost 500 times that of a false negative. If that makes sense for your application, use it. If not you should use a cutoff that more closely represents the estimated relative costs. As your model is not necessarily close to the true model, consider @Henry's suggestion to use cross-validation, or alternatively bootstrapping, to find the choice of c that minimizes costs.
