[site]: crossvalidated
[post_id]: 396304
[parent_id]: 396258
[tags]: 
Suppose you have three times of actions: A , which takes no arguments, B x which takes one argument x , and C x y which takes two arguments. Assume these arguments are chosen from a discrete candidate set (such as your list of coordinates). Your network can output a categorical distribution $S$ across the 3 actions, a categorical distribution $Q$ across all possible arguments, and a categorical distribution $R$ across all ordered pairs of arguments. To sample an action from this policy, first sample from $S$ . If it's action A , you're done -- you can ignore all the other network outputs. If it's action B , then sample your argument x from distribution $Q$ . If action C , then sample your two arguments x y from $R$ . Note that it's insufficient to use two categorical distributions across your candidate set instead of a distribution across ordered pairs of sets. To cover some edge cases: What if some of the coordinates in the candidate set are not valid for a particular action? Then keep sampling from your distribution until you get a valid coordinate. What if you have a lot of coordinates and an action with a lot of arguments and it's not feasible to output a softmax across them all? Then you use an RNN to model the distribution of arguments. What if the candidate set of arguments isn't fixed? (for example, suppose you must pick some turn t in the game -- obviously, it doesn't really make sense to have a softmax across turns in a game). But even this can be dealt with using Pointer Networks
