[site]: datascience
[post_id]: 11923
[parent_id]: 11919
[tags]: 
For a specific model you feed it data, choose the features, choose hyperparameters etcetera. Compared to the reality it makes a three types of mistakes: Bias (due to too low model complexity, a sampling bias in your data) Variance (due to noise in your data, overfitting of your data) Randomness of the reality you are trying to predict (or lack of predictive features in your dataset) Ensembles average out a number of these models. The bias due to sampling bias will not be fixed for obvious reasons, it can fix some of the model complexity bias, however the variance mistakes that are made are very different over your different models. Especially low correlated models make very different mistakes in this areas, certain models perform well in certain parts of your feature space. By averaging out these models you reduce this variance quite a bit. This is why ensembles shine.
