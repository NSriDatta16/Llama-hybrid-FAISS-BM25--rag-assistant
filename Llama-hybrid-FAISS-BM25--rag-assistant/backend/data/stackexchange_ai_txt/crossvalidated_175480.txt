[site]: crossvalidated
[post_id]: 175480
[parent_id]: 175470
[tags]: 
If I treat the predictors as separate variables, I get strange results (i.e. second friend is highly significant but not first.) I think this is probably because there is high correlation between them? Further, there is a fair number of observations that don't list 3 friends (~25%) which can't be used in such an analysis. Looks like you're having a hard time finding the right representation. If you tried a linear combination of features, you could also try a quadratic other combinations of features (e.g friends). Or, what if I told you that you can do this automagically? You could train a neural network with one hidden layer. These are universal function approximators: https://en.wikipedia.org/wiki/Multilayer_perceptron There are many implementations. If I collapse them into one proportion (What proportion of the friends do action X?) the results are pretty clean, but I lose information about the ranking. If you need to rank the features, then compute the derivative of the outputs, according to the inputs. See for example: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.4570&rep=rep1&type=pdf
