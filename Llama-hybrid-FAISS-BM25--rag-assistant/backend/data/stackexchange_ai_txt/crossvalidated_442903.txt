[site]: crossvalidated
[post_id]: 442903
[parent_id]: 115186
[tags]: 
As you point out, the Bayesian approach to dealing with an unknown variance is to use a prior distribution for this value, and then derive the resulting marginal distribution of the value to be sampled. This gives you a "mixture distribution" which is a mixture of normal distributions with different variances, with the "weights" for that mixture being determined by the prior distribution. You might be interested in a well-known mixture distribution of this kind, which is the Student's T distribution . If we take $X|\lambda \sim \text{N}(0,\tfrac{1}{\lambda})$ and $\lambda \sim \text{Ga}(\tfrac{\varphi}{2},\tfrac{\varphi}{2})$ then we obtain the marginal distribution: $$\text{St}(t|\varphi) = \int \limits_0^\infty \text{N}(t|0,\tfrac{1}{\lambda}) \text{Ga}(\lambda|\tfrac{\varphi}{2},\tfrac{\varphi}{2}) \ d \lambda.$$ This is a distributional form that is a "mixture" of normal distributions, where the variance parameter has an inverse gamma distribution.
