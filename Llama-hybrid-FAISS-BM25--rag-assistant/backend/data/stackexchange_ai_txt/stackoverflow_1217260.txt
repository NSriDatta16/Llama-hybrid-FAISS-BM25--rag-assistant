[site]: stackoverflow
[post_id]: 1217260
[parent_id]: 1217153
[tags]: 
The edges of the image itself look jagged because they are being placed into a pixel grid directly, and not being interpolated. Nearest Neighbor Interpolation is the simplest kind of interpolation, where if you have pixel grid A and you move your image to pixel grid B, the pixels in grid B are chosen by simply choosing the closest pixel from grid A. Other forms of interpolation choose a weighted average of the closest pixels to arrive at the pixel value in grid B. Your image, with its jagged edges, looks like it's using nearest neighbor interpolation, which may be the default type of interpolation on an affine transform on an iphone. When you use some other interpolation scheme other than nearest neighbor, you'll get aliasing effects, where the subsampling isn't perfect as you transfer from one pixel grid to another. That effect makes edges in the image itself seem blurrier than they otherwise would.
