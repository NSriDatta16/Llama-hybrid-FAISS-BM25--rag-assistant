[site]: datascience
[post_id]: 67889
[parent_id]: 67811
[tags]: 
Reason for the discrepancy Two aspects have to be considered regarding the split: Is the split done in a stratified manner? (it should) Is the data shuffled? (it should) The line X_train, X_test, y_train, y_test, i_train, i_test = train_test_split(feature_matrix, y, indices, test_size=0.33, random_state=random_state) splits the data in a stratified manner by default (see parameter stratify ) and it does shuffle by default (see parameter shuffle ): see: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html The line scores = cross_val_score(clf, feature_matrix, y, cv=5, scoring='f1_macro') also splits the data in a stratified manner (see parameter cv : For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. ), but it does not shuffle. This causes the bad results for this line. see: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html Solution Option 1: Shuffle the data beforehand: import sklearn scores = cross_val_score(clf, *sklearn.utils.shuffle(feature_matrix, df.eClass, random_state=42), cv=5, scoring='f1_macro') Option 2: use appropriate cross-validaton object I also looked into using an appropriate cross-validation sheme by using a different object: import sklearn skf = sklearn.model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42) for train_index, test_index in skf.split(X, y): print("TRAIN:", train_index, "TEST:", test_index) X_train, X_test = X[train_index], X[test_index] y_train, y_test = y.iloc[train_index], y.iloc[test_index] clf.fit(X_train, y_train.values) print('--------------------------------------') predicted_train = clf.predict(X_train) predicted_test = clf.predict(X_test) print('Train Accuracy: ' + str(np.mean(y_train == predicted_train))) print('Test Accuracy: ' + str(np.mean(y_test == predicted_test))) print('Test F1 micro: ' + str(f1_score(y_test, predicted_test, average='micro'))) print('Test F1 macro: ' + str(f1_score(y_test, predicted_test, average='macro'))) print('Test F1 weighted: ' + str(f1_score(y_test, predicted_test, average='weighted'))) print('--------------------------------------') see: https://scikit-learn.org/stable/modules/cross_validation.html https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html
