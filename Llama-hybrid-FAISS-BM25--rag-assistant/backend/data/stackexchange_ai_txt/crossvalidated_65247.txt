[site]: crossvalidated
[post_id]: 65247
[parent_id]: 65186
[tags]: 
My general thoughts: So when you are evaluating different models, you may want to tune them, try different types of pre-processing etc until you find what you think is a good model. Resampling can help guide you in the right direction during that process. However, there is still the chance of over-fitting and the odds of this happening is greatly influenced by how much data (and predictors) you have. If you have a little bit of data, there are a few ways to think about this: Use all the data for training since every data point adds significantly to how well the model does. Set aside a small test set as a final check for gross errors due to over-fitting. The chances of over-fitting with a small samples size is not small and gets bigger with the number of samples. I fall into the second camp but the first isn't wrong at all. If you have a ton of data then it doesn't really matter much (unless you ave a small event rate). For you: You have a DOE. The type of design would help answer the question. Are you trying to interpolate between design points or predict design points that have not been tested so far? You have one replicate. I fell like random forest is hitting a nail with a sledge hammer and might result in over-fitting. I would try something smoother like an SVM or (gasp) neural network. Max
