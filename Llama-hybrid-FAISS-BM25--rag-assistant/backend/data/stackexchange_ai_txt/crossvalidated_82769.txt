[site]: crossvalidated
[post_id]: 82769
[parent_id]: 74505
[tags]: 
I do think that those 90 columns of binary data can be reduced to some smaller number of columns, so that the computational time can be reduced significantly This assumption seems unfounded to me. Since the computational time of calculating pairwise dissimilarities corresponds O(n^2) the effect of dimensionality reduction will be merely noticeable . I mean if it takes two days, you wouldn't mind 2-3 hours less. What I have in mind is Do you really need all pairwise dissimilarities? Often one actually doesn't. Therefore a spatial index can be used. If you do need them all: Do you need to update them often? How about keeping the dissimilarities. Adding a single item will take few time Anyway you should try to reformulate the problem. 10 or 100 variables will make little difference in accomplishing your current approach.
