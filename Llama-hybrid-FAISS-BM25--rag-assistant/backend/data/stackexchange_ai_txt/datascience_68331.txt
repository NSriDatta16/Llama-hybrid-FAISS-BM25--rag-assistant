[site]: datascience
[post_id]: 68331
[parent_id]: 
[tags]: 
Keras Sequential model returns loss 'nan'

I'm implementing a neural network with Keras, but the Sequential model returns nan as loss value. I have sigmoid activation function in the output layer to squeeze output between 0 and 1, but maybe doesn't work properly. This is the code: def data_generator(batch_count, training_dataset, training_dataset_labels): while True: start_range = 0 for batch in batch_count: end_range = (start_range + batch[1]) batch_dataset = training_dataset[start_range:end_range] batch_labels = training_dataset_labels[start_range:end_range] start_range = end_range yield batch_dataset, batch_dataset mlp = keras.models.Sequential() # add input layer mlp.add( keras.layers.Input( shape = (training_dataset.shape[1], ) ) ) # add hidden layer mlp.add( keras.layers.Dense( units=training_dataset.shape[1] + 10, input_shape = (training_dataset.shape[1] + 10,), kernel_initializer='random_uniform', bias_initializer='zeros', activation='relu') ) # add output layer mlp.add( keras.layers.Dense( units=1, input_shape = (1, ), kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='sigmoid') ) print('Compiling model...\n') mlp.compile( optimizer='adam', loss=listnet_loss ) mlp.summary() # print model settings # Training with tf.device('/GPU:0'): print('Start training') #mlp.fit(training_dataset, training_dataset_labels, epochs=50, verbose=2, batch_size=3, workers=10) mlp.fit_generator(data_generator(groups_id_count, training_dataset, training_dataset_labels), steps_per_epoch=len(training_dataset), epochs=50, verbose=2, workers=10, use_multiprocessing=True) How can I do?
