[site]: crossvalidated
[post_id]: 587634
[parent_id]: 
[tags]: 
How to calculate the Transposed Convolution?

Studying for my finals in Deep learning. I'm trying to solve the following question: Calculate the Transposed Convolution of input $A$ with kernel $K$ : $$ A=\begin{pmatrix}1 & 0 & 1\\ 0 & 1 & 0\\ 1 & 0 & 1 \end{pmatrix},\quad K=\begin{pmatrix}1 & 0\\ 1 & 1 \end{pmatrix} $$ I can't seem to find the formula which is used to calculate the Transposed Convolution (found only the formula to calculate the dimension). I know that the Convolution formula is: $$ G(i,j)=\sum_{u=-k}^{k}\sum_{v=-k}^{k}K(u,v)A(i-u,j-v) $$ But how to calculate the Transposed Convolution? In a video I saw the following example: Which is easy for $2\times2$ kernel and image to see that: $$ \begin{align*} &K_{0,0}\star^{T}A=2\star^{T}\begin{pmatrix}3 & 1\\ 1 & 5 \end{pmatrix}=\begin{pmatrix}6 & 2 & 0\\ 2 & 10 & 0\\ 0 & 0 & 0 \end{pmatrix}&&K_{0,1}\star^{T}A=0\star^{T}\begin{pmatrix}3 & 1\\ 1 & 5 \end{pmatrix}=\begin{pmatrix}0 & 0 & 0\\ 0 & 0 & 0\\ 0 & 0 & 0 \end{pmatrix}\\&K_{0,1}\star^{T}A=4\star^{T}\begin{pmatrix}3 & 1\\ 1 & 5 \end{pmatrix}=\begin{pmatrix}0 & 12 & 4\\ 0 & 4 & 20\\ 0 & 0 & 0 \end{pmatrix}&&K_{1,1}\star^{T}A=1\star^{T}\begin{pmatrix}3 & 1\\ 1 & 5 \end{pmatrix}=\begin{pmatrix}0 & 0 & 0\\ 0 & 3 & 1\\ 0 & 1 & 5 \end{pmatrix} \end{align*} $$ Then you have: $$ A'=\begin{pmatrix}6 & 2 & 0\\ 2 & 10 & 0\\ 0 & 0 & 0 \end{pmatrix}+\begin{pmatrix}0 & 12 & 4\\ 0 & 4 & 20\\ 0 & 0 & 0 \end{pmatrix}+\begin{pmatrix}0 & 0 & 0\\ 0 & 0 & 0\\ 0 & 0 & 0 \end{pmatrix}+\begin{pmatrix}0 & 0 & 0\\ 0 & 3 & 1\\ 0 & 1 & 5 \end{pmatrix}=\begin{pmatrix}6 & 14 & 4\\ 2 & 17 & 21\\ 0 & 1 & 5 \end{pmatrix} $$ But I can't seem to figure how to make it for $3\times 3$ image and $2\times 2$ kernel. I do know that the dim of the output should be $4\times 4$ because: $$ \begin{cases} H=(3-1)\cdot1+2-2\cdot0=4\\ W=(3-1)\cdot1+2-2\cdot0=4 \end{cases} $$
