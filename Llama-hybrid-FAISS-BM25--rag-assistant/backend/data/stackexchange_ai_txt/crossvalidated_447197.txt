[site]: crossvalidated
[post_id]: 447197
[parent_id]: 
[tags]: 
Meaningful way to use Dimensional Reduction and Euclidean Distance for clustering variables?

How do I find the hierarchical interrelationships between variables after dimensional reduction since PCA dimensional reduction is sensitive to the ordering of the columns in source data? I made a test input file p=30 and n=569 from a pre-made dataset from sklearn.datasets import load_breast_cancer cancer = load_breast_cancer() cancer.keys() df = pd.DataFrame(cancer['data'],columns=cancer['feature_names']) df.to_csv(r'input file',index=False) Then I applied a PCA transformation on the covariance matrix and reduced the n=30 dimensions to n=4 since just 4 components are needed to explain 99.9% of the variance. Then I tried to find the hierarchical relationships between variables. I found the pairwise euclidean distance between each variable with the other variables. The euclidean distance used each of the 4 PCA components for every variable in feature space. import pandas as pd import numpy as np daily_series = pd.read_csv (r'input path') sd = daily_series[daily_series.columns[0:daily_series.shape[1]]] scaled_data = sd #unscaled from sklearn.decomposition import PCA pca = PCA(n_components=daily_series.shape[1]) pca_model = pca.fit(scaled_data) components = ['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12','PC13','PC14','PC15','PC16','PC17','PC18','PC19','PC20','PC21','PC22','PC23','PC24','PC25','PC26','PC27','PC28','PC29','PC30'] variables = daily_series.columns[0:daily_series.shape[1]] Matrix = pd.DataFrame(pca_model.components_, columns=components, index=variables) Matrix.to_csv(r'output path', index=True) red_components = ['PC1','PC2','PC3','PC4'] distance = np.asmatrix([[np.NaN for i in range(cols)] for j in range(cols)]) distance_norm = np.asmatrix([[np.NaN for i in range(cols)] for j in range(cols)]) red_Matrix = Matrix[red_components] for i in range(0,cols): for j in range(0,cols): a = np.asarray(red_Matrix.iloc[i,:]) b = np.asarray(red_Matrix.iloc[j,:]) distance[i,j] = math.sqrt(sum([(a[k]-b[k]) ** 2 for k in range(len(b))])) for i in range(0,cols): for j in range(0,cols): distance_norm[i,j] = distance[i,j]/np.max(distance)*100 Distance = pd.DataFrame(distance_norm, columns=variables, index=variables) Distance = np.transpose(Distance) Distance.columns = variables Distance.to_csv(r'distanceoutput path') Cluster without dimensional reduction (30/30 components): Clusters with dimensional reduction (4/30 components): Clusters with dimensional reduction (4/30 components) with different ordering of columns in source data: Clearly dimensional reduction is necessary. And clearly the order of the columns is impacting the results so my clusters (made with Ward 2 method in R) are not reliable. How can I cluster the variables in a way that reflects interrelationships between variables?
