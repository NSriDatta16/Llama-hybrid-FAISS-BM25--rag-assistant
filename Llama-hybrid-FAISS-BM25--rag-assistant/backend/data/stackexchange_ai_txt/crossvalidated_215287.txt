[site]: crossvalidated
[post_id]: 215287
[parent_id]: 215154
[tags]: 
In several well known cases, yes, variable selection is not necessary. Deep learning has become a bit overhyped for precisely this reason. For example, when a convoluted neural network ( http://cs231n.github.io/convolutional-networks/ ) tries to predict if a centered image contains a human face, the corners of the image tend to have minimal predictive value. Traditional modeling and variable selection would have the modeler remove the corner pixels as predictors; however, the convoluted neural network is smart enough to essentially discard these predictors automatically. This is true for most deep learning models that try to predict the presence of some object in an image (e.g., self drivings cars "predicting" lane markings, obstacles or other cars in frames of onboard streaming video). Deep learning is probably overkill for a lot of traditional problems such as where datasets are small or where domain knowledge is abundant, so traditional variable selection will probably remain relevant for a long time, at least in some areas. Nonetheless, deep learning is great when you want to throw together a "pretty good" solution with minimal human intervention. It might take me many hours to handcraft and select predictors to recognize handwritten digits in images, but with a convoluted neural network and zero variable selection, I can have a state-of-the-art model in just under 20 minutes using Google's TensorFlow ( https://www.tensorflow.org/versions/r0.8/tutorials/mnist/pros/index.html ).
