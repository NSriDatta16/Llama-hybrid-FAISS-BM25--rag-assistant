[site]: crossvalidated
[post_id]: 264095
[parent_id]: 262808
[tags]: 
It's not depend on Gaussian distribution,its depend on the MODEL that used this features. The result of standardization (or Z-score normalization) is that the features will be rescaled so that they’ll have the properties of a standard normal distribution with μ=0 and σ=1 that help in different cases such as when you want to compute measure the distance between to variable with different units,or more important one,when your algorithm use need this,for example when it use gradient descent,if the features not on same scale,some of features may update faster then the others. these algorithms like: k-nearest neighbors with an Euclidean distance measure k-means (see k-nearest neighbors) logistic regression, SVMs, perceptrons, neural networks etc in the other hand we have Z-score normalization (or standardization) is the so-called Min-Max scaling.in this approach, the data is scaled to a fixed range - usually 0 to 1(not always). now the question : Z-score standardization or Min-Max scaling? There is no obvious answer to this question: it really depends on the application. i have some example for you : in clustering analyses, standardization may be especially crucial in order to compare similarities between features based on certain distance measures. Another prominent example is the Principal Component Analysis, where we usually prefer standardization over Min-Max scaling, since we are interested in the components that maximize the variance. However, this doesn’t mean that Min-Max scaling is not useful at all! A popular application is image processing, where pixel intensities have to be normalized to fit within a certain range (i.e., 0 to 255 for the RGB color range). Also, typical neural network algorithm require data that on a 0-1 scale.
