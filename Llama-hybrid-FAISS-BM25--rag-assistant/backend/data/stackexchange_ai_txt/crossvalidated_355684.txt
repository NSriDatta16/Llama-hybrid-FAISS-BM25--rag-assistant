[site]: crossvalidated
[post_id]: 355684
[parent_id]: 
[tags]: 
Is there existing research on - or even a name for - an autoencoder neural net with additional inputs?

An autoencoder predicts a set of variables using those same variables as inputs, with hidden layers in between which usually act as a bottleneck, forcing the inputs to load on to a smaller set of nodes that then do the predicting. It occurs to me that one could easily throw in additional inputs, without adding them as outputs; it wouldn't, strictly speaking, be an autoencoder anymore, but it would work (wouldn't it?). What would it be? Has this been done anywhere before? I have in mind the use of an autoencoder to estimate underlying qualities, rankings, scores, etc., as in https://mfeldstein.com/college-rankings-revisited-might-artificial-intelligence-think/ . You want and need the outputs to be all available real measures of quality -- job placement rates for schools, for example -- and you want to include those as inputs as well, but it makes a lot of sense to include other inputs that may or may not actually relate to true underlying quality -- for example, whether a school is public or private. You can't just include those in the autoencoder as normal, however, because then you're assuming that they do in fact relate to quality, and requiring the scoring algorithm to treat them as such. MWE: library(neuralnet) library(NeuralNetTools) library(ISLR) dat
