[site]: crossvalidated
[post_id]: 419569
[parent_id]: 154194
[tags]: 
I could use p-values for the predictors as a rough measure of importance, though am not sure if that will be accurate. It won't. P values say nothing about how important a variable is. A better measure would be the effect size. Coefficient values could be another option to compare relative importance, but given that different variables may be on different scales it won't be an apple-to-apple comparison Better. You could always standardize covariates to have mean 0 and standard deviation 1. That puts things on the same scale. I tend to prefer the the list of important variables that the Random Forest algorithm generates (for e.g. using the VarImp function in the randomForest package in R) This is fine, but there are more interpretable models than a random forest. If prediction is your main concern and not inference, I think a penalized model (a la LASSO or Ridge Regression) is the way to go. You can examine what variables are most important by tuning the penalty parameter and seeing what drops out of the model last.
