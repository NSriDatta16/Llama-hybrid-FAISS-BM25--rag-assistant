[site]: crossvalidated
[post_id]: 295398
[parent_id]: 
[tags]: 
Scalar-on-function regression with random initial time

I was trying to answer this question Estimating the effect of different histories of exposure, on a scalar response measured at the end of a study Executive summary if you don't want to read the original thread: OP has data for a cohort of $\sim 20000$ subjects. For each subject we have a vector of covariates $\mathbf{x}_i$ (age, smoking habit, social class, etc.), the time history $\mathcal{X}_i(t) \colon [t_i, T]\to\mathbb{R}$ of exposure to a certain environmental variable, and a blood pressure $y$ measurement t the end of the study (time $T$). Blood pressure at time $t_i$ (i.e., when recording of exposure started for subject $i$) wasn't measured, unfortunately. OP wants to estimate the effect of $\mathcal{X}_i(.)$ on $y$, when controlling for $\mathbf{x}_i$. I proposed to use a linear scalar-on-function regression model (see also here for a freely downloadable copy): $$y_i=\alpha_0+\boldsymbol{\alpha}^T\mathbf{x}_i+\int_0^T\beta(s)\mathcal{X}_i(s)\text{d}s+\epsilon_i, \qquad i=1,\dots,N$$ Some explanations are in order here: $\alpha_0$ is the intercept, and $\boldsymbol{\alpha}$ is the vector of coefficients for the scalar covariates $\mathbf{x}_i$ $\beta(t)$ is called a coefficient function, and like $\alpha_0$ and $\boldsymbol{\alpha}$, it must be estimated finally, $\epsilon_i$ are iid, mean 0, constant variance errors, usually assumed to be normally distributed The issue here is that actually this model assumes that all time series start at at the same time. Instead, here measurements of the exposure variables started at different times for different subjects. I can see two ways out of this: One can make all time series start at the same time, maybe $t_{min}=\min\limits_{i=1,\dots,N} t_i$, and treat the missing measurements as missing data. I don't know if this is feasible and if it has ever been done before for scalar-on-function regression. I'm not thrilled by this approach, because obviously data won't be missing at random (for each subject, all measurements $t\mid t_{min} Another possibility: a multilevel model where we give some prior on $t_i$ (maybe derived by looking at the data, which would make this an Empirical Bayes approach), and then, conditional on $t_i$, we model $y_i|t_i$ as $$y_i|t_i=\alpha_0+\boldsymbol{\alpha}^T\mathbf{x}_i+\int_{t_i}^T\beta(s)\mathcal{X}_i(s)\text{d}s+\epsilon_i, \qquad i=1,\dots,N$$ Does it makes sense? How could one fit such a model? I'm open to other suggestions.
