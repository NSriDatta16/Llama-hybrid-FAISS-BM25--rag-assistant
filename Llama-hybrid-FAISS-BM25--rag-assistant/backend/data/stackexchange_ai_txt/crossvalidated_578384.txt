[site]: crossvalidated
[post_id]: 578384
[parent_id]: 
[tags]: 
Where to start creating a -synthetic 3D object- based neural network in combination with sensor data?

I have a question on where to start with a project of mine. It includes a wide variety of expertise, so I am not sure if am at the right part of stack exchange. My project is as such: I have a cube that has a known defect on the inside and I have an ultrasonic sensor. I would like to create synthetic data of cubes with varying shapes and internal damages and simulate the sensor response. I know how to draw a 3D model in Catia or Inventor, how to acquire sensordata in Matlab and how to program a neural network in Python. I want to randomize 3D objects and use these models to create a virtual sensor response. Can I use the software described above, or should I maybe use something like a game engine for this? I have found that blender could be used to create the 3D models and that I can use pytorch 3D to run a machine learning algorithm on meshes. My initial thought is that Simulink would be best used to do the sensor simulations, but I am hesitant because I expect that it also requires the Simulink 3D animation, the model-based Calibration Toolbox and a lot of other costly add-ons. Can anybody share his or her experience with combining 3D models, sensor data and machine learning?
