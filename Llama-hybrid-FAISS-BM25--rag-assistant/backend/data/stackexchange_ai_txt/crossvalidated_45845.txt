[site]: crossvalidated
[post_id]: 45845
[parent_id]: 
[tags]: 
What's the optimal way of measuring the error of quantitative estimates, across question sets?

My research relates to situations in which individuals make a quantitative estimate and then make a second quantitative estimate, perhaps after some manipulation. Minimally I am interested in comparing: A) The error of a first estimate B) The error of a second estimate C) The error of the average of the first and second estimates. I want to compare the efficacy of different manipulations, and also the extent to which changing question sets affects the efficacy of a particular manipulation. The question sets vary widely; in some question sets you can get responses that are huge outliers (e.g. answers to a question like "How many kilograms of fuel were on the Space Shuttle orbiter at take-off?") while with other question sets big outliers can't really exist (e.g. answers to a question like "What percentage of the world's airports are in the United States?"). I've seen the Mean Squared Error frequently used in this context (e.g. this paper ), and also the Root Mean Square Error. Others have favoured a method based on the median (e.g. this paper ), and I've also seen the Mean Absolute Deviation used (e.g. this paper ). I'm keen to know which method should be preferred, or if no method is preferable over the others how I could make some principled argument that that is the case.
