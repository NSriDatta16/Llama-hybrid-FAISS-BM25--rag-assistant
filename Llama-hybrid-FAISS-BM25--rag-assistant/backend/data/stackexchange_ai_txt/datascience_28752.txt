[site]: datascience
[post_id]: 28752
[parent_id]: 28737
[tags]: 
You can think of a multimodal distribution as a union of multiple unimodal distributions. In the case of GANs for image processing, each mode could be a category of images. To significantly simplify what's going on to motivate the idea, if you have a dataset of cat pictures and dog pictures, you can think of that as bimodal. Just cat pictures, that's unimodal. Training a GAN on a multimodal dataset of images means that it should be able to generate members of any image category in your dataset, and it should generate different categories with the same frequency with which they appeared in the training data. GANs are trained by taking a random vector as input and attempt to construct a feasible member of the data distribution as output. In effect, the GAN learns a (surjective) mapping from the random space onto the multimodal distribution, such that random inputs will generate samples from the multimodal data distribution as outputs.
