[site]: crossvalidated
[post_id]: 363002
[parent_id]: 362988
[tags]: 
The answer by @Shehryar Malik is correct (+1), but it sounds a bit confusing, especially for people new to convolutional neural networks. In the usual CNN scenario, each layer has its own set of convolution kernels that has to be learned . This can be easily seen in the following (famous) image: The left block shows learned kernels in the first layer. The central and right block show kernels learned in deeper layers 1 . This is very important feature of convolutional neural networks: At different layers the network learns to detect stuff at different levels of abstraction. Therefore the kernels are different. In theory, nothing prevents you from using the same kernels at each layer. In fact, that thing is called recurrent convolutional neural network . 1 More precisely, they show to what kind of image features these kernels respond to, since visualizing kernel with shape 3 $\times$ 3 $\times$ 256 is not very easy/intuitive/useful.
