[site]: crossvalidated
[post_id]: 262953
[parent_id]: 
[tags]: 
Neural network weight initialization?

I'm trying to understand neural network weight initialization but i need help to decipher the language people use to describe fan-in. "N (where n is the number of the neurons inputs)"... or this definition... fan-in (the number of connections feeding into the node)", however in the Xavier Glorot paper http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf "n is the size of the previous layer (the number of columns of W)" which sounds to me like biases are excluded. So, does "N" aka? "fan-in" include bias connections or not. For example, consider a neuron whose inputs are two other neurons and a bias node from the previous layer. Is the fan-in two or three?
