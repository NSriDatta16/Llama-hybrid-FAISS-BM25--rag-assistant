[site]: crossvalidated
[post_id]: 281167
[parent_id]: 
[tags]: 
K-Fold Cross validation ambiguity?

I am using K-Fold cross validation to test my trained model.But i was amazed that for every K-fold the accuracy is different.For instance if use 5-K fold ,every fold has different accuracy.So which fold should i select?Does averaging of 5 fold results is ultimate choice?.Secondly,why the data-set split ratio(70:30) is different in case of 5 fold and 10 fold cross validation.It should be same.
