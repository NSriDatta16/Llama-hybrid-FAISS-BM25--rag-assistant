[site]: crossvalidated
[post_id]: 642574
[parent_id]: 642430
[tags]: 
You have answered your own question when you state "I do not expect much relationship between censoring and events", which means you are assuming censoring is non-informative for the event of interest. The KM estimator of the survival curve $S(t)$ has an asymptotic normal law with mean $S(t)$ at each $t$ if censoring is non-informative. Thus if censoring is informative to some extent, I understand this to mean the KM estimator might be biased at some $t$ , that is the possibility exists for bias, even with "infinite" numbers of events. Similarly the log rank test which is often used to compare two survival functions is often based on asymptotic inference, this time a chi-squared law for the log rank statistic, which is a valid result only under non-informative censoring within each group. Again incorrect inference may result if censoring is informative, even with large sample sizes. To understand if censoring has an effect, in RCTs anyway, typically alternate methods are specified such as not censoring, i.e. ignoring the potential censoring event (if censoring event is possible to be ignored, such as taking a non-permitted medication); or imputing an event in accordance with the current (at that time) observed event rate in the group that subject is randomised to, or imputing the placebo group rate. More elaborate methods might be to do an ICPW analysis to try and create a "counterfactual" scenario where censoring did not occur. The above approaches are simple in the sense that, if results are different from censoring, we conclude censoring has an effect, and we obviously hope for not much difference. Typically we also specify the strategy that we believe will most protect the treatment effect, whilst regulatory agencies typically demand alternate approaches that lead to some null bias. In the RCT arena the censoring event is called an intercurrent event (occurs post-randomisation and either precludes the event of interest being observed, or affects the probability of the event occurring) and ignoring, censoring, imputing, IPCW are particular strategies to "handle" the intercurrent events. This all rejoices under the "estimands framework" which is really an un-necessary new invented language for old concepts, however it comes from regulatory agencies and has the good effect of forcing non-statistical folk to sit up and pay attention to what stats folk are trying to explain to them. These strategies for intercurrent events do not often capture directly the correlation between the intercurrent event and the event of interest, and some not at all. For instance imputing the event probabilities based on (say) a logistic regression model regressing the intercurrent event on the binary event response at that time point gives useful information, but only affects the analysis model through the imputed data. Similar for IPCW, the derivation of weights is a modelling step preceding the analysis model. Imputing based on observed rates and ignoring the intercurrent event tell use nothing about this correlation. Methods that do permit the correlation between the intercurrent event and the event of interest are called "joint modelling". They often are of more academic interest in the RCT field and play "second fiddle" to the simple approaches outlined here, although they do sometimes get used.
