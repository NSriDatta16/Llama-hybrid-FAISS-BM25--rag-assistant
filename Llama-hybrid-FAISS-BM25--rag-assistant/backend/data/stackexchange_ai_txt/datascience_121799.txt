[site]: datascience
[post_id]: 121799
[parent_id]: 
[tags]: 
pytorch: implementing logistic regression: input dimension of torch.nn.Linear is input.flatten(start_dim=1)

I tried to implement a logistic regression class using pytorch. The following implementation worked. class LR(torch.nn.Module): def __init__(self, input_dim, output_dim): """ Initializes internal Module state. """ super(LR, self).__init__() self.input_dim = input_dim self.output_dim = output_dim self.linear = torch.nn.Linear(input_dim, output_dim) def forward(self, x): x = x.flatten(start_dim=1) x = self.linear(x) outputs = x return outputs I expected it to work with x = x.view(-1, self.input_dim) instead of x = x.flatten(start_dim=1) . I thought torch.nn.Linear(input_dim, output_dim) only accepts inputs of shape (any shape, input_dim) . x = x.flatten(start_dim=1) reshapes to (batch_size, flattened_size) with flattened_size being the product of all dimensions of x starting from dimension 1. how would this not raise an error?
