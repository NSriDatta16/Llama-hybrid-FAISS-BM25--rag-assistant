[site]: crossvalidated
[post_id]: 101507
[parent_id]: 101349
[tags]: 
I will try to answer some of your questions here regarding Probabilistic Graphical Models (PGMs). Before I start, an excellent course to follow is the one offered here by Daphne Koller and her book also on the topic. If you want a very nice to read book with intuitive detailed explanations and examples, I would advise her book. Let me now answer some of the question. 1- "what kind of priors to use?" Priors are related to the previous knowledge you have about an experiment that you experienced or a domain expert has. If this is not the case, it is not easy to come up with a good prior. Basically, it will be a guess from your side. Nevertheless, even if you do not have a previous knowledge to the experiment, priors are sometimes used to smooth the probability scores or to avoid the " probability of zero " problem where priors are also known as pseudocounts . Moreoever, some set-ups for priors like in Bayesian Parameter Learning, make their effect less sensitivite with the more outcomes you get from different experiments as @Arbias pointed somehow. Simply, you start with a prior or a guess and as you run more experiment you tend to learn the real probability in a way where you account less for the prior you had. 2-"what do we learn from the data?" PGMs offer you the ability to learn the relationship between variables and this really helps in describing a specific phenomena. Whether the graph is directed or undirected, there will be a sort of dependency between the variables which you can infer. In the directed PGMs like Bayesian Network, the dependency is based on a parent-child relationship. On the other hand, in undirected PGMs like Markov Random Fields where the information between two variables flow in both directions, you can infer a cyclic dependency . 3- "how to do prediction?" The main problems of PGMS are structure learning, parameter learning and inferencing . Prediction in many cases is a kind of extension over the PGM but not one of its major problems in my own opinion. For example, you can run two queries about a desired variable in the graph and then, compute a ratio that gives you an indication of a prediction or decision. Finally, I would advise with general tips for such kind of problems. 1- Define the hypothesis that you have and make sure that PGMs are the best ones to help you in testing this hypothesis. In general, if modeling relationships among variables is of importance for you or if you prefer a generative approach over a discriminative one , you may consider PGMs. 2- Understand the domain of the variable and define clearly the outcomes of your experiments. This will help you in defining a relevant likelihood function and to choose properly a probability distribution function to compute your parameters. 3- For PGMs, it will be always an advantage if you have a clue about the dependency between your variables. Otherwise, structure learning (i.e. learning the dependency that you do not know or have a clue about) is a super-exponential problem and it may happen that the learned graph structure is of no meaning. PGMs and especially the undirected ones are picking a momentum right now, application wise. They really worth considering and good luck !
