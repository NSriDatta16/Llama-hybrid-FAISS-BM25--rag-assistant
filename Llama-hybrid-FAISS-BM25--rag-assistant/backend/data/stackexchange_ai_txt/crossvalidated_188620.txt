[site]: crossvalidated
[post_id]: 188620
[parent_id]: 184952
[tags]: 
Here is an interesting book Neural Networks: Tricks of the Trade , an updated 2012 version of the book. Lots of articles by some of the pioneers of neural networks. ypx beautifully touched on a lot of practical issues with training, so to touch upon the other issues you raised: a lot of the elite industrial labs still publish their results. For example Microsoft Research's team just won ImageNet 2015 and they released a technical report describing their new deep net module: Deep Residual Learning for Image Recognition , Google's team published their Inception architecture as well, Going Deeper with Convolutions . To a non-trivial degree there is still a culture in machine learning (for now) of sharing the big innovations. Possibly because the key is access to the data. Google and Facebook simply have access to data that we do not. Hard to say how much credit goes to raw algorithmic innovation and how much goes to massive amounts of data. With regards to what will happen in the future? Hard to say. It's an issue that lots of people have raised given how valuable these data driven companies have become and how competitive the market is. But for now, I think there is a good enough balance of what industrial research labs share and don't share. I understand them not sharing their exact code implementation. But they do share some very novel innovations. Find researchers who publish important results and read, read, read. I believe in Yann LeCun's AMA on Reddit he mentioned that he is a voracious reader. I believe this is the most important thing. And to the extent that it is practical, try to recreate their benchmarks, or apply their method to a dataset that is within your budget. I think regardless of where you are or what your station in life is, this is the best way to stay sharp and continue to develop your skills. Be a voracious reader and implement things and build intuition. I personally do not have the resources to participate in ImageNet competitions, but reading all the top performing ImageNet group's articles has helped me tremendously.
