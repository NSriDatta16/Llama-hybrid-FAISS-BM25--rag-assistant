[site]: datascience
[post_id]: 78543
[parent_id]: 78542
[tags]: 
Decision Tree is very useful if you want to be able to explain where your result comes from you can often print the tree and see how your model came to this answer. Random Forest can also provide such information, but you'll have to browse all trees and make some "stats" into them, which is not as easy. But Random Forest often give better results than Decision Tree (except on easy and small datasets). Finally, XGBoost could give a better result than Random Forest, if well-tuned, but you can't explain it easily. It's also harder to tune, and takes a lot more time to train. If you don't mind about results-explanation, I'd suggest you to try both XGBoost and RandomForest, with a bit on tuning, to see which one is best fitting on your dataset.
