[site]: crossvalidated
[post_id]: 4742
[parent_id]: 4737
[tags]: 
Weights can arise in data analysis through various mechanisms, each of which requires its own formulas: A dataset with many duplicate results can be summarized by listing each unique result together with its frequency of occurrence. This is the definition @drknexus assumes in order to provide a definite answer (after recognizing that other definitions are possible). When datasets represent averages or other statistics, their values have known (or at least pre-estimated) levels of uncertainty. The weights can represent those levels. (Typically the appropriate weight to use is the inverse of the variance.) These are incorporated in methods like weighted least squares regression . Many datasets obtained through observational studies in the social and biological sciences arise from complex sampling schemes in which units/subjects have differing chances of being selected. The appropriate weights to use in estimates are usually the inverses of the selection probabilities, as in the Hansen-Hurwitz Estimator and the Horvitz-Thompson Estimator . Various robust methods , such as IRLS regression , iteratively reweight data in order to de-emphasize atypical values. These weights can enter into formulas in ways that differ from (1) - (3) above. Thus, you need first to decide what your weights mean and what the purpose of computing the weighted statistics might be.
