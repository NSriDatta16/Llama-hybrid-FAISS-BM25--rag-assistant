[site]: crossvalidated
[post_id]: 42960
[parent_id]: 42956
[tags]: 
In general, you cannot interpret the coefficients from the output of a probit regression (not in any standard way, at least). You need to interpret the marginal effects of the regressors, that is, how much the (conditional) probability of the outcome variable changes when you change the value of a regressor, holding all other regressors constant at some values. This is different from the linear regression case where you are directly interpreting the estimated coefficients. This is so because in the linear regression case, the regression coefficients are the marginal effects . In the probit regression, there is an additional step of computation required to get the marginal effects once you have computed the probit regression fit. Linear and probit regression models Probit regression : Recall that in the probit model, you are modelling the (conditional) probability of a "successful" outcome, that is, $Y_i=1$, $$ \mathbb{P}\left[Y_i=1\mid X_{1i}, \ldots, X_{Ki};\beta_0, \ldots, \beta_K\right] = \Phi(\beta_0 + \sum_{k=1}^K \beta_kX_{ki}) $$ where $\Phi(\cdot)$ is the cumulative distribution function of the standard normal distribution. This basically says that, conditional on the regressors, the probability that the outcome variable, $Y_i$ is 1, is a certain function of a linear combination of the regressors. Linear regression : Compare this to the linear regression model, where $$ \mathbb{E}\left(Y_i\mid X_{1i}, \ldots, X_{Ki};\beta_0, \ldots, \beta_K\right) = \beta_0 + \sum_{k=1}^K \beta_kX_{ki}$$ the (conditional) mean of the outcome is a linear combination of the regressors. Marginal effects Other than in the linear regression model, coefficients rarely have any direct interpretation. We are typically interested in the ceteris paribus effects of changes in the regressors affecting the features of the outcome variable. This is the notion that marginal effects measure. Linear regression : I would now like to know how much the mean of the outcome variable moves when I move one of the regressors $$ \frac{\partial \mathbb{E}\left(Y_i\mid X_{1i}, \ldots, X_{Ki};\beta_0, \ldots, \beta_K\right)}{\partial X_{ki}} = \beta_k $$ But this is just the regression coeffcient, which means that the marginal effect of a change in the $k$-th regressor is just the regression coefficient. Probit regression : However, it is easy to see that this is not the case for the probit regression $$ \frac{\partial \mathbb{P}\left[Y_i=1\mid X_{1i}, \ldots, X_{Ki};\beta_0, \ldots, \beta_K\right]}{\partial X_{ki}} = \beta_k\phi(\beta_0 + \sum_{k=1}^K \beta_kX_{ki}) $$ which is not the same as the regression coefficient. These are the marginal effects for the probit model, and the quantity we are after. In particular, this depends on the values of all the other regressors, and the regression coefficients. Here $\phi(\cdot)$ is the standard normal probability density function. How are you to compute this quantity, and what are the choices of the other regressors that should enter this formula? Thankfully, Stata provides this computation after a probit regression, and provides some defaults of the choices of the other regressors (there is no universal agreement on these defaults). Discrete regressors Note that much of the above applies to the case of continuous regressors, since we have used calculus. In the case of discrete regressors, you need to use discrete changes. SO, for example, the discrete change in a regressor $X_{ki}$ that takes the values $\{0,1\}$ is $$ \small \begin{align} \Delta_{X_{ki}}\mathbb{P}\left[Y_i=1\mid X_{1i}, \ldots, X_{Ki};\beta_0, \ldots, \beta_K\right]&=\beta_k\phi(\beta_0 + \sum_{l=1}^{k-1} \beta_lX_{li}+\beta_k + \sum_{l=k+1}^K\beta_l X_{li}) \\ &\quad- \beta_k\phi(\beta_0 + \sum_{l=1}^{k-1} \beta_lX_{li}+ \sum_{l=k+1}^K\beta_l X_{li}) \end{align} $$ Computing marginal effects in Stata Probit regression : Here is an example of computation of marginal effects after a probit regression in Stata. webuse union probit union age grade not_smsa south##c.year margins, dydx(*) Here is the output you will get from the margins command . margins, dydx(*) Average marginal effects Number of obs = 26200 Model VCE : OIM Expression : Pr(union), predict() dy/dx w.r.t. : age grade not_smsa 1.south year ------------------------------------------------------------------------------ | Delta-method | dy/dx Std. Err. z P>|z| [95% Conf. Interval] -------------+---------------------------------------------------------------- age | .003442 .000844 4.08 0.000 .0017878 .0050963 grade | .0077673 .0010639 7.30 0.000 .0056822 .0098525 not_smsa | -.0375788 .0058753 -6.40 0.000 -.0490941 -.0260634 1.south | -.1054928 .0050851 -20.75 0.000 -.1154594 -.0955261 year | -.0017906 .0009195 -1.95 0.051 -.0035928 .0000115 ------------------------------------------------------------------------------ Note: dy/dx for factor levels is the discrete change from the base level. This can be interpreted, for example, that the a one unit change in the age variable, increases the probability of union status by 0.003442. Similarly, being from the south, decreases the probability of union status by 0.1054928 Linear regression : As a final check, we can confirm that the marginal effects in the linear regression model are the same as the regression coefficients (with one small twist). Running the following regression and computing the marginal effects after sysuse auto, clear regress mpg weight c.weight#c.weight foreign margins, dydx(*) just gives you back the regression coefficients. Note the interesting fact that Stata computes the net marginal effect of a regressor including the effect through the quadratic terms if included in the model. . margins, dydx(*) Average marginal effects Number of obs = 74 Model VCE : OLS Expression : Linear prediction, predict() dy/dx w.r.t. : weight foreign ------------------------------------------------------------------------------ | Delta-method | dy/dx Std. Err. z P>|z| [95% Conf. Interval] -------------+---------------------------------------------------------------- weight | -.0069641 .0006314 -11.03 0.000 -.0082016 -.0057266 foreign | -2.2035 1.059246 -2.08 0.038 -4.279585 -.1274157 ------------------------------------------------------------------------------
