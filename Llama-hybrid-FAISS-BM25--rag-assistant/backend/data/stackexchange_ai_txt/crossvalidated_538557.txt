[site]: crossvalidated
[post_id]: 538557
[parent_id]: 538540
[tags]: 
The first thing here is that there are different concepts about what a model even means. Are we talking about a frequentist/aleatory interpretation of probability, where the model refers to a real process with repeatable observations, or are we talking about an epistemic interpretation of probability, in which a model refers to the uncertainty of an observer/researcher given certain knowledge? In most Bayesian literature probabilities are epistemic, but many use Bayesian model averaging with a more frequentist idea in mind; some even mix the interpretations up, interpreting the lower level models in a frequentist manner, and the higher level distribution averaging over the models in an epistemic manner. The meaning of the question actually depends on this. But even though this is so, my basic answer is the same in all cases. Models are idealisations and no model is ever meant to "hold" precisely. This applies both to frequentist and to epistemic models (although in epistemic modelling the modeller can basically choose to say that the model holds for them , as they are the one to be modelled; not that this solves many problems...). The concept of "approximation" of reality by a model is not unproblematic either. Most notions of approximation are still based on assumptions that in reality are not true or not verifiable (e.g., the idea that an assumed cdf should approximate the empirical one assumes i.i.d. data and nothing in the world is really i.i.d. nor at least exchangeable when thinking about Bayesian assumptions). If we assume a single model, we basically choose to look at the phenomenon of interest through the lens of a single model, and we need to be careful because we may miss something or may be led astray because of this. Averaging over a well defined set of models, our view is broader, allowing for several models to be considered, but this doesn't mean it is ever perfect or exhaustive. Ultimately the task is pragmatic: We're making model assumptions and we should always have in mind that these model assumptions will be violated in one way or another, and think about realistic ways in which this could happen. What is particularly important is to think about potential issues with the model that may mislead results (such as outliers, in many situations). This can lead to extension of the model class (acknowledging that even such an extension will never be exhaustive), to alternative approaches such as robust estimation, or to just to healthy caution when interpreting results. One could say that averaging over several models is better because it gives us a better chance to get things "approximately right", however obviously this relies on further assumptions (regarding the prior), and it isn't progress if people who do this think that they need to be cautious with a single model, but when averaging models everything relevant can be safely covered.
