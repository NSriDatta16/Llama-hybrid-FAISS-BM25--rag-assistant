[site]: crossvalidated
[post_id]: 222241
[parent_id]: 
[tags]: 
improving classification using examples from 'other' classes

I'm trying to classify a a small dataset of around 150 patients each with one of four different diseases. For each patient I have around 70 different features. I also have an "extra" dataset of patients with 'other' diseases (not belonging to the 4 I need to classify). These are all different diseases that the classifier is not supposed to work on. I was wondering if I can use this extra dataset to somehow regularize the classifier for those four specific diseases that I do care about. So far these are the ideas I came up with: 1) Do softmax regression and input the extra dataset with labels [0.25,0.25,0.25,0.25]. This way I'm telling the classifier that these extra patients have labels that are "equally different" from the labels it needs to classify. 2) Use logistic regression and input the extra dataset with labels [0,0,0,0]. This way I'm telling the classifier the the extra patients have labels that are not of any of the labels that it should classify. I'd like to hear other methods/opinions about the methods above/any other tips you might think are relevant to the problem.
