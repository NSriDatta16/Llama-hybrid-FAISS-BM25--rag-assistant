[site]: datascience
[post_id]: 12700
[parent_id]: 12697
[tags]: 
No. of features that you choose? Its depends on the number of classes you have to predict, let's explain this with example: consider we have 5 classes(labels) in our dataset and we choose only one feature, so tree has only one parent node and two leaf node which will accommodate only two classes and hence the accuracy decrease sharply, similarly if we choose only two features then we can only accommodate three classes and so one, so you have to consider more number of features as of classes and there after you have to test it with accuracy till there is no change in accuracy by adding extra features in the model. Does the score(Variable Importance) matter when you choose? Yes, the score matter when deciding the features that you choose, since its depends on the Variable Importance of a feature is computed as the average decrease in model accuracy on the out of bag samples when the values of the respective feature are randomly permuted, so if you choose only the lower score variables for features then the accuracy sharply decreases.
