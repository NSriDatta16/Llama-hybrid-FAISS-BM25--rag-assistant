[site]: crossvalidated
[post_id]: 523116
[parent_id]: 
[tags]: 
How to compute a 95% credible interval for a small sample size with little prior information?

Say I have the following empirically measured data describing a parameter of interest: x = c(12, 4, 6, 8, 5, 12, 12, 10, 6) where x is a continuous random variable. My goal is to estimate the median value and a 90% credible interval for the parameter being measured. I would like to be able to report that "there is a 90% chance that this parameter does not exceed U" where U is the upper bound of the 90% credible interval. Let's say I have very little prior knowledge about this parameter of interest, other than that it cannot be less than or equal to 0 and likely does not exceed 50. Past research relevant to this question: I read through How to find 95% credible interval? , but I don't seem to have the px in that scenario (the density estimates). I'm also a bayesian neophyte, so I may well have misunderstood that question/answer. However, that makes me think that what I'd like to do is not feasible, or, at least, I don't know how to get density estimates in this case. It seems like once I got density estimates, I could follow Tim's answer in that question. Is that true? Current attempt to solve this problem Could I simply use something like this (R code)? x = c(12, 4, 6, 8, 5, 12, 12, 10, 6) px = density(x) and then follow instructions from the answer linked above? This seems like a naive solution: it seems like I could easily go wrong using the wrong arguments (or just relying on defaults) for the density() function. If this is the recommended solution, is there a recommended way to select the right kernel and bandwidth?
