[site]: datascience
[post_id]: 123737
[parent_id]: 17367
[tags]: 
For images the best would likely be to implement DeepLDA, from the paper Deep Linear Discriminant Analysis by Matthias Dorfer et.al (2015). Several implementations in PyTorch can be found on Github, for example liyu10000/DeepLDA . In PyTorch you would implement the learning loop yourself, so it should be possible to do this with mini-batches. Another alternative would be to use a pretrained neural network for images to extract feature-vectors. Usually, it is possible to reduce output dimensionality to 128 dimensions (or lower). This greatly reduces memory usage. Depending on the number of images, it might become realistic to hold all of them in memory, and use a standard LDA implementation such as the one in sciki-learn. Subsampling the data might also be useful, and one can analyze the performance sensitivity wrt number of samples (learning curve) to see whether one might be leaving any performance on the table.
