[site]: crossvalidated
[post_id]: 323838
[parent_id]: 270450
[tags]: 
I don't think OP is talking about the standard likelihood ratio test that one would use to compute a p-value. I believe s/he is talking about the generalized test. One could argue that the generalized test has more in common with Bayesian statistics than it does with frequentist, as one who uses the generalized test might be called a 'likelihoodist'. Although the typical use of the generalized test would be to compare a model based on the observations to a null model, and would give answers related to p-values (albeit much more intuitive ones), the approach also allows one to specify two predictive models a priori, neither of which would depend on the observations for their point estimates (though the likelihood ratio would still normally be computed assuming the models share the variance found in the observations). In this sense, likelihood ratios are model comparison approaches just as Bayesian analyses are, and as such have the same desirable property of being statistically symmetrical inasmuch as the evidence can be used to support either model. In comparison, p-values using NHST test only one model (the null) and infer the evidence for the alternative model based on the evidence against the null. Further, evidence for the null itself is logically unobtainable as one can only 'fail to reject' it, never 'accept' it. It is a very odd way of testing models. As far as the differences between parametrization of likelihood ratios and Baeysian models are concerned, the main difference is that only the Bayesian model assumes a prior distribution, and use the data to update one's prior beliefs. The likelihood ratio instead makes no such assumption but simply tests the two models. John Kruschke above explained how the parameter space is used by each model in a clear way. The only thing I would add to that is that the LR does not necessarily need to use the observed data to set the parameters of the alternative model, but could use any pre-specified value, for example, the size of an effect predicted by a theoretical model, which would not necessarily match the size observed in the data.
