[site]: crossvalidated
[post_id]: 512535
[parent_id]: 477761
[tags]: 
I would like to compute the uncertainty of my deep learning model using MC dropout. To use MC dropout to compute the uncertainty of a model, you are calculating the posterior. The posterior is proportional to the likelihood times the prior P(θ|D) ∝ P(D|θ) ⋅ P(θ). My original model contains already one dropout and I am satisfied with its performance. I think you mean that you have applied dropout to your model in your training. To apply the MC dropout you only need to apply it in test mode as we can see from the original paper : In practice this is equivalent to performing T stochastic forward passes through the network and averaging the results. You pass the same data through the neural network several times and take the average of the corresponding results.
