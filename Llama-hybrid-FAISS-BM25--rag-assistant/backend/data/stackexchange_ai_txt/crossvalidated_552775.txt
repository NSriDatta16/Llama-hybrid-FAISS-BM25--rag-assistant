[site]: crossvalidated
[post_id]: 552775
[parent_id]: 
[tags]: 
Does a larger sample size increase multi-collinearity between predictors, after imputation of missing data?

I have two datasets that have exactly the same 1701 predictors, but one has 936 subjects and the other has 547 subjects. (The initial rationale for creating these two different datasets was to see whether the conclusions would depend on the sample size and the percentage of missing data.) I then put both datasets through the same machine learning pipeline that comprises the following steps: Scaling Imputation of missing data with K-nearest neighbours Dropping of predictors with zero variance Dropping of predictors with a variance inflation factor (VIF) >= 5.0 Encoding of ordinal and categorical predictors Feature selection using recursive feature elimination Machine learning model I then noticed that the 4th step - the dropping of collinear predictors using VIF - resulted in the number of predictors dropping from 1641 to 954 for the larger dataset (with 936 subjects), but the number of predictors didn't budge at all (1604 to 1604) for the smaller dataset (with 547 subjects). For the latter, I verified that the intermediate dataset entered into the VIF algorithm indeed led to all calculated VIFs being That brings me to my question: Does having a larger sample size (more subjects) somehow result in an increase in multi-collinearity amongst a dataset's predictors, after missing data imputation with K-nearest neighbours (or any other imputation method)? I tried looking for answers on this forum as well as via a Google search, but couldn't find anything relevant. I'd be really grateful for any advice on this matter. Thank you very much! ======================= Addendum made after Ian Barnett's answer: I've experimented using the code kindly written by Ian Barnett, and it seems that increasing sample size doesn't appear to affect the degree of post-imputation collinearity in that particular example, but increasing the percentage of missing data does. (Hope I'm doing this correctly - I noticed that increasing pmiss led to an unexpected increase in the frequencies (height of the histogram) that made them appear 'saturated', as shown in the images).
