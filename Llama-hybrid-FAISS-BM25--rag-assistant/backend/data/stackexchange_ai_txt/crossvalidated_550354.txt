[site]: crossvalidated
[post_id]: 550354
[parent_id]: 
[tags]: 
Estimating average of a random variable with lower variance is faster to converge than a variable with higher variance?

I have a fallowing problem: I have to estimate average of 2 random variables $X$ and $Y$ based on average of two other. Where the $X$ and $Y$ are some $n$ by $n$ matrices. $$ X = 0.5\cdot(A+B) $$ $$ Y = 0.5\cdot(C+D) $$ If I'm not wrong I can do it either way: Estimate averages of variables $A$ , $B$ , $C$ , $D$ exponential moving average as $E[A], E[B], E[C], E[D]$ . Then estimate variables $X$ and $Y$ as $E[X] = 0.5\cdot(E[A]+E[B])$ , and $E[Y] = 0.5\cdot(E[C]+E[D])$ . Or I have an option to do this another way, which seems to work better, because the variance of the estimated variables $X$ and $Y$ seems to be lower. $X = 0.5\cdot(A+B)$ , and $Y = 0.5\cdot(C+D)$ . Then estimate average of variables $X$ and $Y$ as $E[X] = 0.5\cdot(E[A]+E[B])$ , and $E[Y] = 0.5\cdot(E[A]+E[B])$ using exponential moving average. Nevertheless, I don't know which would be theoretically more valid and converge faster, when exponential moving average is used
