[site]: crossvalidated
[post_id]: 461761
[parent_id]: 
[tags]: 
Can someone explain why neural networks are highly parameterized?

I understand that neural networks by definition, are a parametric model. If I am correct, Parametric methods make an assumption about the functional form, or shape, of f. For a neural network, what is the assumption of its form? I have interpreted them (Albeit, only one introductory data mining course) as a Blackbox model. What further pushed me to ask this question is the greater necessity for a large sample size, which is consistent with a nonparametric method!
