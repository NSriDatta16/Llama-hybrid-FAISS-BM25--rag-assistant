[site]: stackoverflow
[post_id]: 4340952
[parent_id]: 4340506
[tags]: 
One possibility for cache-use improvement is to modify your pattern of access to array and otherArray . When you read array[i][j] your machine will, of course, move a 'line' of memory into cache. When you read otherArray[i][j] your machine will, of course, move a 'line' of memory into cache. It is possible that to read the second 'line' the first has to be flushed from cache into RAM. And then you make the situation even worse (potentially) by reading a value from yetAnotherArray . What actually happens depends a lot on what else is going on at the same time, what else is in cache and any other operations being carried out. This can be very difficult to figure out. If your (dominant) pattern of array access is to require element[i][j] from both (or all 3) arrays at the same time then you want to arrange matters such that they are in the same 'line' of memory which is read. One way to do this is to merge the 3 arrays into a single m*n*3 array, in which superArray[i][j][1] is next to superArray[i][j][2] which is next to superArray[i][j][3] and in which the 3 planes of the array each represent one of the original arrays. Of course, this only works if I've got the index ordering right, so give it more thought than I have. Finally: this may transform your elegant program into a spaghetti mess -- but that's a small price to pay for improved speed ! by 'line' I mean whatever chunk your platform loads from RAM to cache in one go. Google around for loop tiling and strip mining . Compilers are not terrifically good at this yet and any help you can provide should be rewarded in improved execution speed.
