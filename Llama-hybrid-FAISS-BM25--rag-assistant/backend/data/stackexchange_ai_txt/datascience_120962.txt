[site]: datascience
[post_id]: 120962
[parent_id]: 
[tags]: 
Fine tune Flan T5 to build a SlackBot

I want to create a Slack chatbot that will be able to "somehow" mock a "ChatGPT like" behavior. I want the bot to be able: answer questions understand from context summarize info I don't want to use OpenAI as I don't want to expose the data externally. I've the relevant HW (GPUs) dedicated VM so at this aspect I'm good. I took a look at this Notebook: https://github.com/amrrs/LLM-QA-Bot/blob/main/LLM_Q%26A_with_Open_Source_Hugging_Face_Models.ipynb and thought using it as a guidance but the results are not good. Basically I'm scrapping the history (conversations) from relevant channels and turn them into txt documents. I feel like I'm missing something so I must ask this "very newbie" question: Does fine-tuning a model mean adding more data to the model? In my example it's very likely there will be new terms that are not in the original model. Do I need to do something about it? Is this article addresses this issue https://www.philschmid.de/fine-tune-flan-t5 ? I feel like I'm very confused by it and every direction will be great.
