[site]: stackoverflow
[post_id]: 767553
[parent_id]: 767392
[tags]: 
This does sounds like fragmentation. Fragmentation is caused by you allocating objects on the stack, say: object1 object2 object3 object4 And then deleting some objects object1 object3 object4 You now have a hole in the memory that is unused. If you allocate another object that's too big for the hole, the hole will remain wasted. Eventually with enough memory churn, you can end up with so many holes that they waste you memory. The way around this is to try and decide your memory requirements up front. If you've got particular objects that you know you are creating many of, try and ensure they're the same size. You can use a pool to make the allocations more efficient for a particular class... or at least let you track it better so you can understand what's going on and come up with a good solution. One way of doing this is to create a single static: struct Slot { Slot() : free(true) {} bool free; BYTE data[20]; // you'll need to tune the value 20 to what your program needs }; Slot pool[500]; // you'll need to pick a good pool size too. Create the pool up front when your program starts and pre-allocate it so that it is as big as the maximum requirements for your program. You may want to HeapAlloc it (or the equivalent in your OS so that you can control when it appears from somewhere in you application startup). Then override the new and delete operators for a suspect class so that they return slots from this vector. So, your objects will be stored in this vector. You can override new and delete for classes of the same size to be put in this vector. Create pools of different sizes for different objects. Just go for the worst offenders at first. I've done something like this before and it solved my problem on an embedded device. I also was using a lot of STL, so I created a custom allocator (google for stl custom allocator - there are loads of links). This was useful for records stored in a mini-database my program used.
