[site]: crossvalidated
[post_id]: 271144
[parent_id]: 
[tags]: 
Why can't this function be used as a loss function?

In a discussion, a friend mentioned that the function below cannot be optimized so it can't be used in a learning algorithm. $$E_{in} = \frac{1}{N} \sum_{n=0}^N (h(x_n) \ne f(x_n))$$ Why can't this function be used as a loss function? The Context This is about machine learning and minimizing the error on a dataset $D$ of size $N$. I'm talking about comparing the algorithm predictions against the actual outcome recorded from the real world. Comparing a prediction against its real value using a cost function. $f$ is the "true" mapping and $h$ is my "model". $h$ should approximate $f$. Would someone, please, explain why it isn't differentiable as well?
