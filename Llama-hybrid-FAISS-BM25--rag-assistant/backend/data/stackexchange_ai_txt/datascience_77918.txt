[site]: datascience
[post_id]: 77918
[parent_id]: 
[tags]: 
2 Phase Prediction and Refinement Pipeline - Deep RL Design Question

At a high level, the problem I am currently facing is a coverage maximization problem within a mobile sensing network. I am working with decentralized mobile sensors that aim to maximize their coverage of mobile units (let's call them "nodes"). The sensors have a limited sensing radius in which they can observe nodes and other sensors within that radius and a node is considered to be "covered" if they are within the radius of a sensor. I desire to use a protocol where each sensor acts as an independent agent and uses a neural network (or a pipeline of multiple networks) to predict where to move during the next timestep such that total coverage of the entire node system is maximized. I have encountered a research paper that discusses the principle of maximizing total reward (total coverage in this case) within a system of decentralized agents. It mentions a 2 phase method: Phase 1. Each sensor observes the current state of its surroundings (sensors and nodes included). It predicts where it should move during the next timestep using a reward function that measures the total observable coverage within its sensing radius. Phase 2. Each sensor shares its move prediction with neighboring sensors. Then each sensor uses the move predictions of all neighboring sensors as well as current node positions to refine the move prediction it made within phase 1. I am relatively new to the RL field and am a little dubious/torn between ideas of using a separate network for each phase, using a system of intermediate inputs and outputs on one network, or using a time series style input structure (notably phase 1 and phase 2 have the same input shape). I seek recommendations on a neural network or system of multiple neural networks that would satisfy the following requirements: I would like phase 2 to "refine" the proposed move prediction generated in phase 1 to a limitable/configurable extent as opposed to "generate" a completely independent prediction. In other words, I would like phase 2's output to be a configurable level of similar to phase 1's output because if each sensor moves completely disjointly to its move prediction within phase 1, the implication is that the phase 2 output was generated using disjoint/incorrect data. I would like the sensors to have an ability to base its move prediction on a pattern of node movement, as opposed to a static node position (the nodes move by a heuristic-based distribution and not randomly). I'm considering achieving this requirement by passing in state from previous timesteps such that the sensor model can observe the "trend" of past node movements. I really only need phase 1 because I want the sensors to have a semblance of where other sensors are moving in the next timestep when it generates its actual move action within phase 2. Right now the problem seems intuitively implementable with two networks, one for each phase. Is there a cleaner/more artful way for agents to generate action predictions, pass these predictions amongst themselves, and update their actions based on other agents' initial predictions?
