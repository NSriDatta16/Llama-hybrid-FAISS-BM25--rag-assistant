[site]: crossvalidated
[post_id]: 143486
[parent_id]: 143327
[tags]: 
To evaluate the significance of the peak you have to formulate your a priori knowledge on the individual time series you are measuring as a null hypothesis. A likely null hypothesis would be that your time series have the amplitude and frequency spectrum that they have and are uncorrelated to each other (and thus should not exhibit any peaks when averaged). In this case, you can make use of time-series surrogates to generate a dataset that complies with your null hypothesis per construction. In particular, every prominent peak in the average of these surrogate time series would be due to chance. Now, employ some measure for the prominence of your peak, such as its height or steepness in relation to the mean and standard deviation of your average. Apply this measure to both, your original peak in the average time series and the most prominent peak in the average time series of your surrogate data set. Repeat this with many surrogate data sets. If the prominence measure for your actual peak exceeds that for each of the surrogate data sets, you can assign your peak a significance based on the number of surrogate datasets you regarded. If your peak is as prominent as the one you showed in your example (and unless you have a priori knowledge of your time series that is highly beneficial for the generation of such peaks), this approach might be overkill though. Also, if you want to estimate a very low significance level, you need a lot of surrogate datasets and thus a lot of computing time.
