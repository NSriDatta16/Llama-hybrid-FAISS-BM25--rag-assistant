[site]: crossvalidated
[post_id]: 482391
[parent_id]: 
[tags]: 
What is considered "normal" in a dataset, relative to other datasets and through time?

I currently have time series datasets of GDP across countries (lets say USA, Australia, and Japan). I want to be able to create a number from -1 to 1 for some point in time that both considers how large the GDP is at that day in time and how large the growth of the GDP is. In order to do this, I need to think about what is thought of as "normal" levels for each of these countries both relative to themselves, each other, and across time (a "normal" value at one time, may not be the "normal" value at another time). Additionally, I need to consider how a country's value/growth is relative to other countries. I'm confused how to go about standardizing/normalizing my datasets, in order to compare the differences (?) between them, and to come out with a value. Here's what I'm thinking right now (I've bolded some of my main questions — would be much appreciated if someone could give me some guidance on them). Consider the average value of the GDP over the past 1 year, and that will be the "normal" value for the GDP for the past year. Thus, I can compare the current value of the GDP with this past 1 year average, and see if it is bigger/smaller ( how do I go about determining how to quantify how much bigger/smaller it is — looking at the mean/SD of the entire historical dataset? ). Similarly, how do I go about comparing the values of the GDP across countries? Do I look at the percent changes across time, and compare them?
