[site]: crossvalidated
[post_id]: 642697
[parent_id]: 642683
[tags]: 
They serve different purposes. Standard deviation describes variability in a population. Standard error describes variability in an estimated parameter. Do you want to make a statement about how precisely your experiment quantified the mean among replicates? Or do you want to make a statement about how much variability there was among the replicates? Suppose you're selling some new technology that quantifies some value. You'd probably want to report the standard deviation among replicates to give people a sense how much variability they can expect when applying your tool. Reporting the standard error wouldn't mean much, as you can always make the standard error go down simply by collecting more data from the same population. A low standard error may not imply a highly precise tool, but a low standard deviation would. On the other hand, if you're applying the tool in practice, you may want to report standard error to give a sense of how well you're quantifying different populations under study. Standard error is more closely linked to whether populations are "significantly different" or not, as that comes down to how well you've estimated the population parameter. Oftentimes the goal of applying such quantification tools is to describe whether populations are on average different in both a statistical and meaningful sense, even if those populations are quite variable.
