[site]: datascience
[post_id]: 37193
[parent_id]: 
[tags]: 
Taking Neural Network's false positives as the recommendation system result?

I am creating a recommendation system and considering two parallel ways of formalizing the problem. One classical, using proximity (recommend the product to the customer if a majority vote of 2k+1 customers closest by has the product), and another one that I have trouble understanding but seems valid to some extent. The approach I'm thinking about is: 1) Fit a highly regularized neural network (to make sure it doesn't overfit the training set) for a classification task that can predict if the person does or doesn't have given product 2) Make sure test accuracy is as close to train accuracy as possible 3) Take false positives (customers who don't have the product originally but the NN predicted that they have it) predicted on the whole dataset (the training set as well) as the result - the people I should recommend the product to Now, I am aware of why in general one wouldn't want to take that approach but I also can't exactly explain why it wouldn't return people 'close by' to each other that 'should' have given product in a similar sense like the KNN-based approach. I'm not sure how to analyse this problem exactly to validate, modify or reject the idea altogether.
