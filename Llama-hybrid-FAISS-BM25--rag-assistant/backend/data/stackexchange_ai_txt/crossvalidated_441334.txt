[site]: crossvalidated
[post_id]: 441334
[parent_id]: 
[tags]: 
How to recursively filter sequential predictions of binary classifier?

Problem My goal is to estimate binary state using entire observation history. Observations are coming sequentially with fixed interval (~1 sec). I have xgboost model which predicts the state given a single observation; I treat this prediction directly as conditional probability $P(x_t = 1 | z_t)$ . Observations are noisy, so each prediction alone does not tell much about real situation. Important point is that state can change with time. What is the best theoretical way to estimate $x_t$ knowing $P(x_t | z_t)$ and $z_{1:t}$ ? I tried discrete bayes filter, but it has some not obvious parameters: aprior distribution of states and probability of transition between states, is there a method not requiring knowledge of this? Current work I used discrete bayes filter algorithm from "Probabilistic robotics" book Assume following notation $x_t \in \{0, 1\}$ - state at time $t$ $z_t$ - observation at time $t$ $P_{k,t} = P(x_t = k | z_{1:t})$ - result of filter, $P_{k,0} = P(x_0 = k)$ $\hat{P}_{k,t} = P(x_t = k | z_{1:t-1})$ $P(x_t = 1 | z_t)$ - prediction of xgboost model $$ \hat{P}_{0,t} = P(x_{t} = 0 | x_{t-1} = 0) P_{0,t-1} + P(x_{t} = 0 | x_{t-1} = 1) P_{1,t-1} \tag{1} $$ $$ \hat{P}_{1,t} = P(x_{t} = 1 | x_{t-1} = 0) P_{0,t-1} + P(x_{t} = 1 | x_{t-1} = 1) P_{1,t-1} \tag{2} $$ $$ P_{0,t} = \alpha P(z_t | x_t = 0) \hat{P}_{0,t} \tag{3} $$ $$ P_{1,t} = \alpha P(z_t | x_t = 1) \hat{P}_{1,t} \tag{4} $$ $$ \alpha \text{ is a normalization constant such that } P_{0,t} + P_{1,t} = 1 $$ To use this algorithm with $P(x_t = 1 | z_t)$ I need to modify it using bayes rule $$ P(z_t | x_t = 1) = \frac{P(x_t = 1 | z_t)P(z_t)}{P(x_t = 1)} \tag{5} $$ Now $$ P_{0,t} = \alpha \frac{P(x_t = 0 | z_t)P(z_t)}{P(x_t = 0)} \hat{P}_{0,t} \tag{6} $$ $$ P_{1,t} = \alpha \frac{P(x_t = 1 | z_t)P(z_t)}{P(x_t = 1)} \hat{P}_{1,t} \tag{7} $$ To cancel $P(z_t)$ $$ \frac{P_{1,t}}{1 - P_{1,t}} = \frac{P(x_t = 1 | z_t) P(x_t = 0) \hat{P}_{1,t}}{P(x_t = 0 | z_t) P(x_t = 1) \hat{P}_{0,t}} = K \tag{8} $$ $$ P_{1,t} = \frac{K}{1 + K} \tag{9} $$ Are my derivations correct? Seems strange that the bigger $P(x_t = 0)$ is, the bigger $P_{1,t}$ will be. This algorithm is not very convenient as soon as it requires many parameters ( $P(x_t)$ , $P(x_t | x_{t-1})$ ) and also does not give any confidence estimate, are there better examples of such algorithms?
