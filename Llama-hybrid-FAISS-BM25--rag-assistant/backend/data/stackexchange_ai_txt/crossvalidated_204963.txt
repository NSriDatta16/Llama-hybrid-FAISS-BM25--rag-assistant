[site]: crossvalidated
[post_id]: 204963
[parent_id]: 204930
[tags]: 
Nice example that can help for your question was provided by Andrew Gelman and David K. Park (2012). Let's stick to your example of predicting the price of house $Y$ given it's area $X$. For this we use simple linear regression model $$ Y = \beta_0 + \beta_1 X + \varepsilon $$ For sake of simplicity, let's forget about the intercept $\beta_0$, you can check this thread to learn why is it important . This data can be visualized on a scatterplot. What is scatterplot? Imagine two-dimensional space (it could be a room), the datapoints are "scattered" around the place, where values of both variables mark their $y$-axis and $x$-axis positions. What you already know, is that it somehow translates to the linear regression model. To make it clear, lets simplify this example even more -- as Gelman and Park did. The simplification that they proposed is to divide the $X$ variable, i.e. area of the house, into three groups: "small", "medium", and "big" houses (they describe how to optimally make such decision, but this is of lesser importance). Next, calculate the average size of "small" house and average size of "big" house. Calculate also average price of "small" house and of "big" one. Now, reduce your data to two points -- the centers of the clouds of datapoints for small and big houses scattered in the space and remove all the datapoints about "medium" houses. You are left with two points in two-dimensional space. Regression line is the line that connects the points -- you can think of it as a direction from one point to the another. The slope $\beta_1$ of this line tells us about amount of change between small and big houses in their prices. The same happens when we have more points, scattered around the space: regression line finds her way by minimizing it's square distance to every point. So the line is going exactly through the center of the cloud of points scattered in the space. Instead of connecting two points, you can think of it as connecting unlimited number of such central points. Gelman, A., & Park, D. K. (2012). Splitting a predictor at the upper quarter or third and the lower quarter or third. The American Statistician, 62(4), 1-8.
