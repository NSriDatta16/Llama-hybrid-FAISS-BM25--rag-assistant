[site]: datascience
[post_id]: 32217
[parent_id]: 
[tags]: 
How is the LSTM RNN forget gate calculated?

I understand that the LSTM recurrent neural network has a forget gate, input gate, and output gate. However, I do not understand how the equation below calculates 'forget' information (from Chris Olah's LSTM post ) How does this forget gate decide which information is discarded from the previous cell state? In other words, what is forgotten or not. It appears to me that this equation just takes $x_t$ from the current state and $h_{t-1}$ from the previous state. Can someone explain how this equation works as a forget gate to retain or discard cell state?
