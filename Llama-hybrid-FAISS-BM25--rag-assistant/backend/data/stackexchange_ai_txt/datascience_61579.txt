[site]: datascience
[post_id]: 61579
[parent_id]: 
[tags]: 
Is it faster and better to train a GAN on just one digit as opposed to the whole mnist dataset?

When going through an introductory GAN tutorial to generate mnist like handwritten digits I wondered whether the systematic variance in the training data due to the different digits makes the model harder to train. Would't it be easier to train a model if all real samples would be 1s instead of 0-9s? My question Would an approach where I train a separate model to generate each digit (0-9) separately using only training data of one type of digit be feasible at all? Would training those models for just one digit be faster (i.e. need less epochs to reach a certain accuracy/quality) than a model using all of mnist. Edit I found an acceptable answer for me (see below) but obviously I am happy for anyone else to chime in.
