[site]: crossvalidated
[post_id]: 297212
[parent_id]: 
[tags]: 
Should we use multiply learning rate by x or $\sqrt(x)$ when batch size is multiplied by x?

According to this paper, One weird trick for parallelizing convolutional neural networks ( https://arxiv.org/abs/1404.5997 ), it is suggested that we multiply learning rate by $\sqrt(x)$, but according to Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour ( https://arxiv.org/abs/1706.02677 ), it is suggested that we do linear scaling. It seems that the first paper has more theoretical underpinnings to it, but I am confused as to which approach I should take in practice. So, should we use multiply learning rate by x or $\sqrt(x)$ when batch size is multiplied by x when training a convolutional neural network?
