[site]: crossvalidated
[post_id]: 466019
[parent_id]: 466010
[tags]: 
What I understand, you are building a Bayesian version of the matrix factorization model described in Matrix Factorization Techniques for Recommender Systems by Koren, Bell and Volinsky. The original paper described how the model can be estimated using either stochastic gradient descent, where you iterate over the observed training samples and for each rating $r_{iu}$ by user $u$ and item $i$ we calculate the error $$ e_{iu} = r_{iu} - q_i^Tp_u $$ and update the parameters $$ q_i \leftarrow q_i + \gamma (e_{ui} p_u-\lambda q_i) \\ p_u \leftarrow p_u + \gamma (e_{ui} q_i-\lambda p_u) $$ I'm mentioning this, because I'm not sure if your code is correct. What are the ratings stored in rating matrix? It should be a $n \times k$ matrix, where $n$ is the number of users and $k$ items, where some of the ratings are missing (otherwise nothing to predict). I would expect to see rather something like a for loop: for (j in 1:m) { rating[j] ~ normal(W[u[j], :] * Z[i[j], :], 1); } where rating , u , and i are vectors of length m , rating stores the ratings (non-missing!), while user and item stores the $u$ and $i$ indexes. By the way, this was mentioned by one of the core Stan developers, Bob Carpenter on StackOverflow . Finally, as mentioned in the comment, you have a lot of parameters and a lot of observed values, so it probably can be quite slow.
