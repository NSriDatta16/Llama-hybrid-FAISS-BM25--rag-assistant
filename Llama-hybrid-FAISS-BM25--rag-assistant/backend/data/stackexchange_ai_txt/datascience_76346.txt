[site]: datascience
[post_id]: 76346
[parent_id]: 76318
[tags]: 
If you mean "how many times the same feature can appear in an [individual] tree", then you can use max_depth to indirectly limit the number of features included in a single tree, even down to one feature. Since XGBoost is designed to use weak learners, having a lower depth value is ok. model = XGBClassifier(max_depth=n) However, I think the problem is not that XGBoost is getting stuck on a single feature. For example, maybe the other columns contain little or no correlation to the label. How does your model perform when you remove that column entirely. That should tell you if you only have one good feature in your dataset.
