[site]: crossvalidated
[post_id]: 569806
[parent_id]: 569801
[tags]: 
Your example of $\mathcal{P}=\| \theta \|_2^2$ is called L2 regularization (or "weight decay"), and has been very well-studied in the context of neural networks (for example, Goodfellow et al, Deep Learning (2016), or Hastie et al, The Elements of Statistical Learning (2009)). It can make problems that are not strictly convex into problems that are strictly convex. One example of this is a neural network with 0 hidden layers and 1 or more output neurons; this is typically called ridge-regression and any $\lambda >0$ has exactly one $\theta$ that minimizes the loss in $(2)$ . Ridge regression is one method to estimate unique regression coefficients when the design matrix is rank-deficient. But you probably have in mind the more usual neural network setting where the network is composed of several hidden layers with nonlinear, monotonic activation between them. In this setting, $\mathcal{P}$ doesn't fix non-convexity because the problem doesn't arise from rank deficiency. The convexity problem arises from non-identifiability. Consider the case of a neural network with 1 hidden layer and 2 neurons, and you have found a minimum $\theta^*$ . You can permute neuron 1 and neuron 2 without changing the likelihood. You can also negate the weights in neuron 1 and the corresponding weights in either the previous or subsequent layers. If the loss is a minimum at $\theta_{(1)}^*$ , then it must also be under a permutation or a reflection of the weights $\theta_{(2)}^*$ (in both cases, they compute the same function). Notably, in both cases, the value of $\| \theta_{(i)}^* \|_2^2$ is identical (change of sign or permutation of elements doesn't change the norm), so this choice of $\mathcal{P}$ does not change the non-convexity of $\mathcal L$ . In other words, making an unrestricted neural network into a convex problem implies discarding the concept of hidden layers and then the problem becomes convex. However, this would mean that we're losing all of power of compounding latent representations -- essentially, we're back to doing regression. We can generalize this result by using the definition of convexity. What follows is a proof by contradiction. If we denote the minimization $(2)$ as $$ f(\theta) = \mathcal L(\theta; y, X) + \lambda \mathcal P(\theta) $$ then we see that $f$ has two parts, $\mathcal L(\theta)$ and $\mathcal P (\theta)$ . Assuming for the moment that $f$ is convex, we know that for for $0 \le t \le 1$ and all $\theta$ in a convex subset, we can write $$\begin{align} f (t\theta_1 + (1-t)\theta_2) &\le t f (\theta_1) + (1-t) f(\theta_2) \\ \mathcal L (t\theta_1 + (1-t)\theta_2) + \lambda \mathcal P (t\theta_1 + (1-t)\theta_2) &\le t \lambda \mathcal P (\theta_1) + (1-t) \lambda \mathcal P(\theta_2) + t \mathcal L (\theta_1) + (1-t) \mathcal L(\theta_2) \end{align}$$ From the statement of the problem, $\mathcal P$ is convex, which implies $ 0 \le t \lambda \mathcal P (\theta_1) + (1-t)\lambda \mathcal P(\theta_2) - \lambda \mathcal P (t\theta_1 + (1-t)\theta_2) = \lambda C$ , so we can rewrite this as $$\begin{align} \mathcal L (t\theta_1 + (1-t)\theta_2) &\le t \mathcal L (\theta_1) + (1-t) \mathcal L(\theta_2) + \lambda C \end{align}$$ so we have the definition of convexity, but we've added a non-negative constant to the right-hand side. However, we know from the statement of the problem that $\mathcal{L}$ is not convex, so we can't write down this inequality. We know there is some $\theta_1, \theta_2$ that violates the definition of convexity. By the non-convexity of $\mathcal L$ we know that $$\begin{align} \mathcal L (t\theta_1 + (1-t)\theta_2) &\gt t \mathcal L (\theta_1) + (1-t) \mathcal L(\theta_2) + \lambda C \end{align},$$ for at least one pair $\theta_1, \theta_2$ . At this level of generality, there's not necessarily anything that can be done. We can give a flavor of this by considering some simpler functions. If we have $\mathcal L(\theta) = - \theta^3$ and $\lambda \mathcal P =\lambda \theta^2$ , then our $f(\theta) = -\theta^3 + \lambda \theta^2$ , so for some fixed $\lambda$ , there exist $\theta_1, \theta_2$ that violate the definition of convex. In other words, the second derivative changes with $\theta$ , so you can't bound it. But your question asks about some restricted set $\theta \in \Theta$ . That's not the usual framing for a neural network optimization task; usually, this is an unconstrained optimization. But let's see where a constrained optimization on some convex set $\Theta$ takes us. In this setting, we can bound $\mathcal L (t\theta_1 + (1-t)\theta_2)$ , so we could just increase $\lambda$ until the inequality flips. That's all well and good from an optimization perspective. But it's possible, or perhaps even likely, that we this will result in under-fitting . Underfitting (and its cousin, overfitting ) are discussed all over the machine learning and neural networks literature, including in the Hastie et al text cited above. In the context of this problem, under-fitting means at least one of the following: The chosen $\lambda$ is so large that the neural network does not fit the data well enough to solve any particular problem. As with a ridge regression, setting $\lambda$ too large will give a function that is too biased towards $\mathcal P$ to be helpful. (It may also be hard to know the smallest $\lambda$ such that the Hessian of $f$ is PD, depending on the network and the data.) The set of $\Theta$ is so restricted that the neural network does not fit the data well enough to solve any particular problem. (It might also be challenging to know how to choose $\Theta$ in this way, depending on the form of the network.) In the specific case of $\mathcal{P} = \| \theta \|_2^2$ , the fact that you can reflect or permute the weights in a certain way without changing $f$ tells us that adjusting $\lambda$ by itself is not enough to create a convex $f$ . If we want convex $f$ , then we will need to choose a specific convex set $\Theta$ so that reflections and permutations of weights are excluded. In general, this seems challenging. At the end of the day, people don't use neural networks for the joy of optimizing functions, people use them to solve some problem with data. If the restricted $\Theta$ or large $\lambda$ is not flexible enough to solve a real problem, we haven't really made much progress. Conversely, if some (possibly non-optimal) $\theta$ found using a non-convex neural network from $(1)$ solves your problem, you've done all the work that you need to do. Most research focuses on $(1)$ because these are the most flexible models and provide generic frameworks to train models.
