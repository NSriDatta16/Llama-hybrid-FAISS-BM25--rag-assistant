[site]: crossvalidated
[post_id]: 435159
[parent_id]: 435140
[tags]: 
Let me try to clear things up a bit if I can. First of all, GANs are not made specifically for generating images, but all kinds of data. In fact the first paper, which you get your figure from, isn't referring to images. In the figure you gave 3 curves: The black dots . These are your training samples $x$ . If you connect the dots you can form a line (I will refer to this as the black line even if it isn't visible in the figures). This is the data-generating distribution $p_x$ , which is the theoretical distribution from where your data is sampled. The green line . This is the distribution that your generator has learned, $p_g$ . When training your discriminator you need real and fake samples. The real ones are the black dots, while the fake ones are sampled from the green distribution. The blue line . This is the output of the discriminator, i.e. the probability that an image will be classified as real or fake. Also the black $x$ horizontal line shows the range from which we can draw $x$ samples, while the black $z$ horizontal line shows the same thing with the latent variable $z$ . When drawn these will follow their respective distributions (black and green lines). Now on to what each figure tells us: The first figure (a) shows how the distributions look before training. The generator doesn't produce realistic samples (i.e. the green line is far away from the black line) and the discriminator doesn't know how to discriminate properly (i.e. the blue line has a lot of fluctuations). The second figure (b) is at a point where $D$ has learned to discriminate between the two types of samples (i.e. real and fake). The blue line now resembles a sigmoid. This is needed so that $G$ can have accurate feedback on how its samples fair. The third figure (c) is at a point where $G$ is beginning to learn how to generate realistic samples. Note how the green line is closer to the black line now. Even though $D$ is also good (the blue line aligns with half of the distance between the two distributions), its job is much harder now. The fourth figure (d) is at the end of training. $G$ can now produce fully-realistic samples (i.e. the green and black lines are one). Because of this $D$ can't discriminate any more, so it predicts randomly if an image is real or fake (i.e. $P(D) = 1/2$ everywhere)
