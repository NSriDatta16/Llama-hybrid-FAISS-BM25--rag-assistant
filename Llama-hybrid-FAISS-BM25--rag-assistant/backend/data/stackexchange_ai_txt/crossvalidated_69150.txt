[site]: crossvalidated
[post_id]: 69150
[parent_id]: 
[tags]: 
Picking and permuting over randomized reference set from large amount of data

I have a question about different strategies for randomly picking up a reference set for statistical testing from a large amount of data (and permuting over the random picking/testing). For illustration purposes, we could assume that the data is e.g. time series data (could be something else as well), where different phenomena (either continuous or binary) has been collected densely over a long period of time. What I want to do is: Given a set of time periods (test set), see if the measured phenomena is enriched in the set when compared to the data (reference set). Practical example of this could be: There is a data set that contains temperature measurements measured every 1 second for the last 50 years Given a set of time periods (test set), ranging from a couple of seconds to a couple of days, test if the temperatures in the test set is statistically different from the temperatures in the general data. For the purpose of this question we can assume that the test itself is some basic statistical test such as t-test or linear regression. My naïve solution would be to calculate all permutations of test set time period length in the data, and compare the test set to those values. Because of the massive amounts of the data and permutations, this would not be computationally feasible (not to mention that the test set can contain time periods of greatly varying lengths). The second and more feasible option would be to randomly pick a reference set from the data, consisting of time periods of similar length as in the test set. It just sounds that doing this random selection of reference set once is not enough, the obvious choice to me is to perform the random selection and testing several times.. And then to the actual question, is this feasible at all, and if so, what should I actually do with the results from the repeated testing, assuming that the end result I want would be: Measurement of statistical significance (i.e. p-value) Measurement of effect size Yet again naïve solutions I can come up are: Take the mean of the p-value/t-score for each randomized test Set up some kind of threshold for the testing, e.g. p All help/ideas will be greatly appreciated! TL;DR I have a large set of data, and want to test a set of given ranges against it through randomly selecting reference set multiple times. How do I combine results from these multiple tests into a single values.
