[site]: crossvalidated
[post_id]: 629854
[parent_id]: 629773
[tags]: 
On Nonlinearity and Diagnostics First off, I wan to begin by saying that ignoring linearity is not advisable. It is, mathematically, the most important assumption to meet in a linear regression (Gelman et al., 2022). What the statistics consultant said on this point seems to gloss over the importance of this assumption. If your data can be sufficiently represented as linear, fine. But the consultant and your plots seem to indicate that it may be more useful to model this without a linear assocation. Whatever DV3 represents, it basically has no relation to your IV. The scatterplots clearly show that there is no relation, and whatever concerns there are about linearity or homoscedascity of errors is not important in that sense. DV1 also seems to be fairly irrelevant, even with the factor shifts in the association (I assume thats what F means) shown in the scatterplot. Perhaps jittering the points on the scatterplot can show why the loess curves are weighted different between factors, but I'm not convinced it matters. Loess curves are typically not as flexible with data as they seem to show given they use a weighted least squares estimation of the data (Jacoby, 2000; Simpson, 2018), and in my experience can often overfit heavily weighted regions of the data distribution. The most interesting association here is DV2. There definitely appears to be a nonlinear association, but not a complex one. Something you can consider is a polynomial regression. This maps nonlinear relationships in the data via squared, cubed, or quadratic terms (anything above that tends to over-interpolate). If that doesn't fit your data well, a spline-based method could also work, and often does. If you seek to do so within a multiple linear regression framework, generalized additive models (GAMs) may be your friend, because they are typically more flexible. I would also consider modeling this data with an error distribution that is not Gaussian (the default). Since your most relevant variable D2 seems right skewed, I would consider a beta distribution. After doing all of that, I would move away from typical residual plots for discrete values like yours and try to use a simulation-based approach, such as posterior prediction checks or DHARMa residuals. Residual plots for non-Gaussian models can be wonky, particularly when random effects are introduced into the model. Using a simulation based approach typically provides better inference. It may also help to quantify what zero means in your DV. I think perhaps it may be okay, but if they actually mean an absence of a measure, you may want to consider how to model/interpret your data. I'm guessing because it is likert scaled, the assumption is more that somebody lacks something in the measure rather than a total absence. A couple references I add below discuss some particulars about likert scaled data that may be helpful to consider. References Gelman, A., Hill, J., & Vehtari, A. (2022). Regression and other stories. Cambridge University Press. Jacoby, W. G. (2000). Loess: A nonparametric, graphical tool for depicting relationships between variables. Electoral Studies, 19, 577–613. https://doi.org/10.1016/S0261-3794(99)00028-1 Norman, G. (2010). Likert scales, levels of measurement and the “laws” of statistics. Advances in Health Sciences Education, 15(5), 625–632. https://doi.org/10.1007/s10459-010-9222-y Simpson, G. L. (2018). Modelling palaeoecological time series using generalised additive models. Frontiers in Ecology and Evolution, 6(149), 1–21. https://doi.org/10.3389/fevo.2018.00149 Sullivan, G. M., & Artino, A. R. (2013). Analyzing and interpreting data from likert-type scales. Journal of Graduate Medical Education, 5(4), 541–542. https://doi.org/10.4300/JGME-5-4-18
