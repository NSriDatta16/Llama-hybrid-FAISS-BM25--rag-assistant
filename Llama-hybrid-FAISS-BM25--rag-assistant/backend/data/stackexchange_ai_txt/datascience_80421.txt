[site]: datascience
[post_id]: 80421
[parent_id]: 
[tags]: 
Very low cross-val score for regression with big .corr() between feature and result

Im trying to make regression with sklearn between one feature and one result. This is the dataset that I have: bruto ukupno gradjevinski din 0 2494.98 857951.27 1 2912.60 694473.11 2 3397.50 1310529.72 3 2678.00 199688.14 4 4310.00 1377366.95 5 2086.28 569312.33 6 3061.80 660803.42 7 4095.00 1187732.61 8 3997.00 1304793.08 9 6503.88 1659629.13 10 6732.00 1264178.31 11 940.10 172497.94 12 1543.00 598772.40 13 5903.85 809681.19 14 2861.61 333983.85 15 3682.76 1430771.50 16 2802.00 1145812.21 17 3032.00 356840.54 18 2635.00 543912.80 19 3749.00 1004940.27 20 4300.50 1889560.55 21 9722.00 2137376.95 22 3823.33 891633.50 23 1648.21 335115.40 24 24575.00 19273129.14 25 3926.00 1223803.28 26 3228.00 874000.00 27 4062.00 1090000.00 28 1316.24 332718.54 29 2497.99 519398.70 30 12123.94 2504783.69 31 2057.50 957042.37 32 2495.00 857951.27 33 3770.73 1743978.85 34 864.00 251269.48 35 774.71 192487.26 I have found the correlation between feature and result with .corr(): bruto ukupno gradjevinski din bruto 1.000000 0.878914 ukupno gradjevinski din 0.878914 1.000000 I have corr of 0.87 and I think that that is very decent for regression, but when I make regression model and when i get cross-val score, i get value for cross-val score thats negative and bigger then 1 (sometimes -50.23) and thats very strange to me. I have tried with a lot of different models and with different number of folds but the results are the same. This is the code for regression: features = df[['bruto']] results = df[['ukupno gradjevinski din']] regressors = [["Linear Regression", LinearRegression(normalize=False)], ["Lasso Regression", Lasso(normalize=False)], ["Gaussian Process Regressor", GaussianProcessRegressor()], ["SVR linear", SVR(kernel = 'linear', gamma='scale', max_iter = 1500)], ["SVR poly 2", SVR(kernel = 'poly', degree=2, gamma='scale', max_iter = 1500)], ["SVR poly 3", SVR(kernel = 'poly', degree=3, gamma='scale', max_iter = 1500)], ["SVR poly 4", SVR(kernel = 'poly', degree=4, gamma='scale', max_iter = 1500)], ["SVR poly 5", SVR(kernel = 'poly', degree=5, gamma='scale', max_iter = 1500)], ["SVR rbf C=0.01", SVR(kernel = 'rbf', C=0.01, gamma='scale', max_iter = 1500)], ["SVR rbf C=0.1", SVR(kernel = 'rbf', C=0.1, gamma='scale', max_iter = 1500)], ["SVR rbf C=0.5", SVR(kernel = 'rbf', C=0.5, gamma='scale', max_iter = 1500)], ["SVR rbf C=1", SVR(kernel = 'rbf', C=1, gamma='scale', max_iter = 1500)], ["SVR rbf C=10", SVR(kernel = 'rbf', C=10.0, gamma='scale', max_iter = 1500)], ["SVR rbf C=20", SVR(kernel = 'rbf', C=20.0, gamma='scale', max_iter = 1500)], ["SVR rbf C=50", SVR(kernel = 'rbf', C=50.0, gamma='scale', max_iter = 1500)], ["SVR sigmoid", SVR(kernel = 'sigmoid', gamma='scale', max_iter = 1500)], ["GradientBoostingRegressor", GradientBoostingRegressor()], ["RandomForestRegressor", RandomForestRegressor(n_estimators = 150)], ["DecisionTreeRegressor", DecisionTreeRegressor(max_depth=10)], ["Bagging Regressor TREE", BaggingRegressor(base_estimator = DecisionTreeRegressor(max_depth=15))], ["Bagging Regressor FOREST", BaggingRegressor(base_estimator = RandomForestRegressor(n_estimators = 100))], ["Bagging Regressor linear", BaggingRegressor(base_estimator = LinearRegression(normalize=True))], ["Bagging Regressor lasso", BaggingRegressor(base_estimator = Lasso(normalize=True))], ["Bagging Regressor SVR rbf", BaggingRegressor(base_estimator = SVR(kernel = 'rbf', C=10.0, gamma='scale'))], ["Extra Trees Regressor", ExtraTreesRegressor(n_estimators = 150)], ["K-Neighbors Regressor 1", KNeighborsRegressor(n_neighbors=1)], ["K-Neighbors Regressor 2", KNeighborsRegressor(n_neighbors=2)], ["K-Neighbors Regressor 3", KNeighborsRegressor(n_neighbors=3)], ["AdaBoostRegressor", AdaBoostRegressor(base_estimator=None)], ["AdaBoostRegressor tree", AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15))], ["AdaBoostRegressor forest", AdaBoostRegressor(base_estimator=RandomForestRegressor(n_estimators = 100))], ["AdaBoostRegressor lin reg", AdaBoostRegressor(base_estimator=LinearRegression(normalize=True))], ["AdaBoostRegressor lasso", AdaBoostRegressor(base_estimator = Lasso(normalize=True))]] for reg in regressors: try: scores = cross_val_score(reg[1], features, results, cv=5) scores = np.average(scores) print('cross val score', scores) print() except: continue I have tried to scale my features with Normalizer, StandardScaler and MinMaxScaler but results are the same. Any help?
