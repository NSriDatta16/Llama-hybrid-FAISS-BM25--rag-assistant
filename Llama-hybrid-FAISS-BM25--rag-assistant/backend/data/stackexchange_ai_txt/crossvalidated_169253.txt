[site]: crossvalidated
[post_id]: 169253
[parent_id]: 169157
[tags]: 
A not irrelevant digression, to validate also my comment about $\gamma$: We are considering an expression where in the numerator we have the sum of Bernoulli random variables, i.e. dichotomous discrete random variables taking the values $\{0,1\}$. So we have to consider whether the event "sum of Bernoullis is zero" has strictly positive probability. The probability that all draws will be zero is equal to $$\Pr \left(\text{\{All b_i's are zero\}}\right) = \left(1-\frac {1}{N^{\gamma}}\right)^N$$ Then for example, if $\gamma =1$ we have $$\lim_{n\rightarrow \infty}\Pr \left(\text{\{All b_i's are zero\}}\right) = \lim_{n\rightarrow \infty}\left(1-\frac {1}{N}\right)^N = 1/e \approx 0.37$$ and a very high probability indeed. Informally you can check that if $\gamma >1$ the sum will have limiting probability of being zero equal to unity, while only if $\gamma Another way to explore this is to remember that the sum of i.i.d Bernoullis is a Binomial random variable, $$\sum_{i=1}^{N}b_{i} \sim \text{Bin}\big(\mu_n = N^{1-\gamma}, \sigma^2_n = N^{1-\gamma}-N^{1-2\gamma}\big)$$ If $\gamma at the limit (because for finite $N$ this can still very well be the case). Assuming from here on that $\sum_{i=1}^{N}b_{i} \neq 0$, we can define $$w_i = \frac {b_i}{\sum_{i=1}^{N}b_{i}},\;\; \sum_i^N w_i = 1,\;\; \forall N$$ and the expression of interest becomes $$\sum_{i=1}^N w_ix_i$$ which is a weighted average, and more importantly, a convex combination of the $x_i$'s, but with the weights being random variables . This is a rather advanced technical issue, that nevertheless has been studied. A bit informally, and exploiting the fact that the weights relate to Bernoullis, note that the values each weight can take are two, $$w_i \in \left\{0, \frac 1{\sum_{i=1}^Nb_i}\right\}$$ We wonder whether $$\sum_{i=1}^N w_ix_i - \frac 1N\sum_{i=1}^N x_i \xrightarrow{p}0 \;\;???$$ Denote $M$ the number of Bernoullis that take the value $1$. This means that $\sum_{i=1}^N b_i =M$. Then we can write $$\sum_{i=1}^N w_ix_i - \frac 1N\sum_{i=1}^N x_i = \sum_{w_i \neq 0}w_ix_i - \frac 1N\sum_{i=1}^N x_i $$ $$=\frac {1}{\sum_{i=1}^N b_i}\sum_{w_i \neq 0}x_i - \frac 1N\sum_{i=1}^N x_i$$ $$=\frac {1}{M}\sum_{w_i \neq 0}x_i - \frac 1N\sum_{i=1}^N x_i$$ Now $M$ is not a number but the Binomial random variable we described before. Still we have that $M\leq N$, and if $M\rightarrow \infty$ the two sums above will have the same probability limit, $\mu$, and the assertion of the question is verified. Intuitively, if, as $N$ becomes "very large", $M$ will tend to take very large values also, the first sum will behave like a proper sample average of the $x$'s. So the condition we require is that $$M=\sum_{i=1}^Nb_i \rightarrow \infty$$ By looking at its mean and variance, we see that as long as $\gamma $$\gamma A quick simulation supports this: I generated $50,000$ samples from a chi-square with $3$ degrees of freedom (so its expected value is $3$), and the same number of samples from a Bernoulli with $p = (50,000)^{-1/2}$ (so $\gamma = 1/2$ here). I then calculated the expression of interest and I obtained $$\frac{\sum_{i=1}^{N}b_{i}x_{i}}{\sum_{i=1}^{N}b_{i}} = 3.016$$
