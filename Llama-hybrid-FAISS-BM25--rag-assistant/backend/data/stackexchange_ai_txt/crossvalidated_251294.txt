[site]: crossvalidated
[post_id]: 251294
[parent_id]: 
[tags]: 
Model construction in epidemiology

I have a biostatistics background and epidemiology interests me. I've never taken a course in epidemiology, so I'm not familiar with this field. My question is related to multivariate model construction in epidemiology. Suppose that we want to analyse the relationship between one outcome and several explanatory variables which all are interesting individually. It appears to me that a common way to do it is to provide crude estimates for each predictor, estimate a multivariate model with all or a subset of the predictors, and provide the adjusted estimates with 95% CIs and possibly p-values. With what I've learned, I would rather do some log likelihood ratio test, use AIC and BIC or use cross-validation to build the multivariate model. Maybe a model without all of the predictors is better. I assume the rationale for the initial approach is that each of the predictors is intended to control for potential cofounding. However, the approach strikes me as different from the approaches that are used in machine learning. Is my understanding of multivariate modeling for diseases and exposures in epidemiology correct? If so, is it possible that a model selection approach based on AIC/BIC or cross-validation is more accurate/generalizable?
