[site]: stackoverflow
[post_id]: 4172728
[parent_id]: 4172336
[tags]: 
The idea is to make the AJAX applications crawlable. According to the HTTP specifications, URLs refer to the same document regardless of the fragment identifier (the part after the hash mark). Therefore search engines ignore the fragment identifier: if you have a link to www.example.com/page#content , the crawler will simply request www.example.com/page . With the new schemes, when you use the #! notation the crawler knows that the link refers to additional content. The crawler transforms the URL into another (ugly) URL and requests it from your web server. The web server is supposed to respond with static HTML representing the AJAX content. EDIT Regarding the original question: if you already had regular links to static pages, then this scheme doesn't help you.
