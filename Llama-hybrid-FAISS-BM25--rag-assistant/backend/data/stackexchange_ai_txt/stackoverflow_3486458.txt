[site]: stackoverflow
[post_id]: 3486458
[parent_id]: 
[tags]: 
How do I disallow specific page from robots.txt

I am creating two pages on my site that are very similar but serve different purposes. One is to thank users for leaving a comment and the other is to encourage users to subscribe. I don't want the duplicate content but I do want the pages to be available. Can I set the sitemap to hide one? Would I do this in the robots.txt file? The disallow looks like this: Disallow: /wp-admin How would I customize to the a specific page like: http://sweatingthebigstuff.com/thank-you-for-commenting
