[site]: crossvalidated
[post_id]: 416679
[parent_id]: 416667
[tags]: 
It depends on exactly how precise you want to be. Intuitively, we should expect the strength of the observed evidence to be proportional to the square root of sample size, so $\hat{\mu}=[\bar{x_s}\sqrt{n}+{\bar{x_p}}]/[\sqrt n +1] $ where $n$ is the sample size, $\bar{x_p}$ is the overall observed mean, $\bar{x_p}$ is the sample mean for the subset, and $\hat{\mu}$ is your estimate of the subset mean, will be good enough for a rough rule of thumb, and will be sufficient to both satisfy Cromwell's Rule (for $n=0$ , you just use $\bar{x_p}$ , and as long as $\bar{x_p}>0$ and $\bar{x_s}\ge 0$ , $\hat{\mu}$ will be positive), and for large $n$ your $\hat{\mu}$ will go to $\bar{x_s}$ . One can argue that there should be a more complicated expression than just $\sqrt n$ , but if you want a precise calculation, you need to have not only a prior distribution on $\mu$ , but also a prior for how likely you think it is for a subset to be different. For instance, if you find that the sample mean for widgets that are exposed to high temperatures is different from the general population, you might want to give a stronger weight to that than if the sample mean for widgets made on Tuesday is different. Note that I said "distribution". Bayesian updates take evidence $E$ and hypothesis $H$ and compare $P(E|H)$ to $P(E|\neg H)$ . You seem to be thinking of the number of failures as $E$ and whether the next widget will fail as $H$ . But that doesn't work: if each widget fails independently, then $P(E|H) = P(E|\neg H)$ . Instead, what you have to do is, for each possible value of $\mu$ , assign a value of how likely you think it is that that is the correct value. It is then this distribution, rather than a particular estimate of $\mu$ , that gets updated. So you'll start with a prior distribution for widgets in general, update that based on the overall failure rate, use that distribution to create a prior distribution for a particular manufacturer, then update that distribution based on the data for that manufacturer. There is the further complication that if the overall failure rate includes data from the manufacturer currently under consideration, then you're "double counting" that data, and there will be independence considerations. You can find a discussion here on how to use Beta distributions to model uncertainty regarding failure rates. Or do a web search on "bayesian updating binomial distribution".
