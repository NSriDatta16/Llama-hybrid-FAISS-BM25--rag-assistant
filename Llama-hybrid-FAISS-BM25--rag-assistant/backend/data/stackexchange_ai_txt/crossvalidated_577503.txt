[site]: crossvalidated
[post_id]: 577503
[parent_id]: 575001
[tags]: 
I respond by quoting elements from the two references on $\beta$ -VAE, that you should read for much more details if you haven't. Disentanglement as defined in Understanding disentangling in $\beta$ -VAE by C. Burgess is defined as A disentangled representation can be defined as one where single latent units are sensitive to changes in single generative factors, while being relatively invariant to changes in other factors. To tend towards this behaviour, conclusions that higher values of $\beta$ are required are made in $\beta$ -VAE: Learning basic visual concepts with constrained variational framework by I. Higgins. These constraints limit the capacity of $z$ , which, combined with the pressure to maximise the log likelihood of the training data x under the model, should encourage the model to learn the most efficient representation of the data. Finally, it is hard to say what is happening in your own experiment. Perhaps you could investigate a disentanglement metric as proposed in the second article, or maybe you just had a scaling problem between your two terms in your ELBO....
