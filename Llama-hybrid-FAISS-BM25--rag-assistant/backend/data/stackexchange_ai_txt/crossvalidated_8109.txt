[site]: crossvalidated
[post_id]: 8109
[parent_id]: 8106
[tags]: 
The idea here is that in logistic regression, we predict not the actual probability that, say, a southerner votes Republican, but a transformed version of it, the "log odds". Instead of the probability $p$, we deal with $\log p/(1-p)$ and find linear regression coefficients for the log odds. So for example, let's assume that an urban Northeasterner has probability 0.3 of voting for a Republican. (This would of course be part of the regression; I don't see it reported in this table, although I assume it's in the original paper.) Now, $x = 1/(1+e^{-z})$ gives $z = \log {x \over 1-x}$; that is, $f^{-1}(x) = \log {x \over 1-x}$, the "log odds" corresponding to $x$. These "log odds" are what behaves linearly; the log odds corresponding to $0.3$ are $\log 0.3/0.7 \approx -0.85$. So the log odds for an urban Southerner voting Republican are this (what Wikipedia calls the intercept, $\beta_0$) plus the logistic regression coefficient for the South, $0.903$ -- that is, $-0.85 + 0.904 = 0.05$. But you want an actual probability, so we need to invert the function $p \to \log p/(1-p)$. That gives $f(0.05) \approx 1/(1+e^{-0.05}) \approx 0.51$. The actual odds have gone from $0.43$ to $1$, to $1.05$ to $1$; the ratio $1.05/0.43$ is $e^{0.903}$, the exponential of the logistic regression coefficient. Furthermore, the effects for, say, region of the country and urban/suburban/rural don't interact. So the log odds of a rural Midwesterner voting Republican, say, are $-0.85 + 0.37 + 0.68 = +0.20$ according to this model; the probability is $f(0.20) = 1/(1+e^{-0.20}) = 0.55$.
