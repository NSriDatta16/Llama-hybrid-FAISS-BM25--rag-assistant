[site]: crossvalidated
[post_id]: 406235
[parent_id]: 406213
[tags]: 
Or will they be fed separately one after the other into the network? The 4-frame "stack" is processed one frame at a time, so the tensor has 3 dimensions: it has shape (frame height, frame width, number of frames). It's not clear from your post, but the blog is probably referencing "Playing Atari with Deep Reinforcement Learning" by Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller which explains these choices and provides some citations for further reading. do we avoid using the Max-pooling stage? This depends on the specific model. Reading the primary literature about a model should clearly explain how it works. Can anyone recommend a good implementation resource of Deep Q-learning, written from scratch (in Python), i.e. without the use of out-of-the-box libraries, like PyTorch, Keras and Scikit-learn ..etc, for a game, where image frame feeds from the game is required as states input. There are lightweight implementations of reinforcement learning topics. One can be found in https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On which is the code companion to Maxim Lapan's Deep Reinforcement Learning Hands-On . However, this repository still uses pytorch for all of the generic neural network pieces. The reason is that there's simply no point to reinvent the wheel in terms of network construction, autograd, backprop and all the other standard neural network operations. The reinforcement learning portions of the code are very clearly written, although there is the occasional bug.
