[site]: crossvalidated
[post_id]: 135590
[parent_id]: 135438
[tags]: 
I'll answer from an applied field that is maybe in between classical statistics and machine learning: chemometrics, i.e. statistics for chemical analyses. I'll add two different scenarios where hold-out is not as important as it is in typical machine learning classes. Scenario 1: I think one crucial point here is to realize that there is a fundamental difference in what is small sample size for training vs. testing: For training, typically the ratio of number of cases : model complexity (number of parameters) matters (degrees of freedom) For testing, the absolute number of test cases matters. (The quality of the testing procedure must be independent of the model: that is treated as a black box by validation with independent test cases) The second point I'm going to need for my argumentation is that the situation where independent test cases are crucial is overfitting. If the model is not complex enough (bias $\gg$ variance, so under fitting), residuals can tell you as much about total prediction error as independent cases. Now, statistics lectures on "classical" linear models often emphasise univariate models very much. For a univariate linear model, the training sample size is likely not small: training sample sizes are typically judged in comparison to model complexity, and the linear model has just two parameters, offset and slope. In analytical chemistry, we actually have a norm that states you should have at least 10 calibration samples for your univariate linear calibration. This ensures a situation where model instability is reliably not an issue, so hold-out is not needed. However, in machine learning, as well as with modern multi-channel detectors in chemical analysis (sometimes 10‚Å¥ "channels" e.g. in mass spectrometry), model stability (i.e. variance) is an important issue. Thus, hold-out or better resampling is needed. Scenario 2: A completely different situation is that hold-out may be skipped in favor of a combination of an easier (residuals) plus a more sophisticated performance measurement. Note that hold-out in the sense of (randomly) setting aside part of a data set and excluding this from training is not equivalent to what independent testing can achieve. In analytical chemistry, dedicated validation experiments may be conducted that will include e.g. measuring the performance degradation over time (instrument drift) which cannot be measured by hold-out and establishing e.g. the performance of the sensor in the actual industrial environment (whereas the sensor calibration was done in the lab on calibration samples). See also https://stats.stackexchange.com/a/104750/4598 for more details on independent testing vs. hold-out.
