[site]: datascience
[post_id]: 128334
[parent_id]: 
[tags]: 
deal with diarization problem for very long sequences -using msdd and spectral clustering

my name is Gal. I'm a novice data scientist, currently grappling with the challenge of diarizing exceptionally long audio sequences. My trials with Nemo MSDD on a 1.5-hour audio file resulted in disappointing outcomes, as it only identified a single speaker. In an effort to pinpoint the issue, I segmented a brief 1.5-minute portion of the audio and observed that the model performs adequately on shorter clips, suggesting that the problem might stem from the sheer volume of data. Upon delving into the MSDD paper [https://arxiv.org/pdf/2203.15974.pdf] and its source code, I discovered their methodology entails: 1.Performing voice activity detection to segment the audio as per these detections. 2.Extracting multi-scale segments from the VAD-filtered data and generating embeddings for each via Tita-Net. 3.Employing normalized maximum eigengap spectral clustering for the initial phase of clustering. 4.Using a multi-scale diarization decoder to confirm the presence of specific speakers in particular segments. My hypothesis leans towards the spectral clustering step underperforming due to the high volume of segments, though my grasp on the algorithm’s foundational theory is somewhat lacking. I’d highly value any assistance in understanding how to manage clustering with an abundance of segments effectively. Suggestions for either tweaking the spectral clustering approach or exploring alternative methods better suited to address this issue are welcome. I’m particularly keen on comprehending the algorithm’s mechanics, especially the role of applying eigenvectors to the Laplacian matrix, or any adjustments that might enhance the algorithm’s capacity to handle numerous segments with greater efficiency.
