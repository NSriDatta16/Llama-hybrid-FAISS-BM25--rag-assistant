[site]: crossvalidated
[post_id]: 596128
[parent_id]: 
[tags]: 
Standard Error of Mean in Panel Data

Consider a panel with data $(y_{i,t})$ for $i\in\{1,...,N\}$ and $t\in\{1,...,T\}$ . Problem: I want to know how the cross-sectional average of $y$ behaves in an average time period. My approach: For each $t$ , I calculate the cross-sectional average of $y_{i,t}$ : $\bar{y}_t=\frac{1}{N}\sum\limits_i y_{i,t}$ . I take the time series mean of that series: $\bar{\bar{y}}=\frac{1}{T}\sum\limits_t \bar{y}_t$ . The standard error of $\bar{\bar{y}}$ is $\frac{\sigma}{\sqrt{T}}$ , where $\sigma=\sqrt{\frac{1}{T-1}\sum\limits_t (\bar{y}_t-\bar{\bar{y}})^2}$ . Question: The standard error of $\bar{\bar{y}}$ takes the variation across time periods into account, but not the cross-sectional variation. If there is large variation across entities but little variation across time, wouldn't my standard error be misleading? Indeed, the standard errors of the cross-sectional means (depending on the sample size $N$ ) are irrelevant for the standard error of the time series average. Consider the extreme case: every time period is identical: $y_{i,t}=y_{i,t'}$ for all $t,t'\in\{1,...,T\}$ . Then, the standard error of $\bar{\bar{y}}$ would be zero, regardless of how dispersed $y_{i,t}$ is in the cross-section. Instead, I would almost like to calculate the time series mean of the standard errors of $\bar{y}_t$ to get a feeling for how much $y_{i,t}$ varies cross-sectionally in the average time period?
