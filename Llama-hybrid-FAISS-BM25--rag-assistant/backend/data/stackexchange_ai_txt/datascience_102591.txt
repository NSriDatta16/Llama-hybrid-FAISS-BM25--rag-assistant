[site]: datascience
[post_id]: 102591
[parent_id]: 73413
[tags]: 
your use case isn't entirely clear but if i may make some assumptions the company ID in both tables refer to the same company (so ID 0 is the same company in both table) you already have a good idea of feature engineering and know which algo to use for your final classification BUT i am going to treat it like i am modeling it if i were you, i would use 2 parallel models one model takes in the annual input data and passes it through a bunch of dense / feedforward layers ( after necessary pre processing) model # 2 will take the entire data of 1 year for a company and pre process it in a way that can be fed into an LSTM / RNN / GRU ..basically the daily data is nothing but a sequence of time steps that adds up to a year (like words in a seq forming a sentence and , more imp, a context ) ..now pass the rnn output through a dense layer or 2 finally concatenate outputs of both (using add / mean / simple concatenate) and then pass through a dense layer or 2 with softmax at the end .. basically the model will backpropagate the error and ensure relevant weights given to each model (so they are trained together)..but based on the variety in the data one of the models just might end up with a very small weight so you will also need to validate it by training these 2 models separately and ensure the sum is greater than the parts
