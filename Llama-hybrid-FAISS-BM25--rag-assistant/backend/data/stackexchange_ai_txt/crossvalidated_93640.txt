[site]: crossvalidated
[post_id]: 93640
[parent_id]: 
[tags]: 
Rough estimates for training time of deep belief networks

I'm still learning about deep learning. However I'm currently interested to know if deep learning architectures scale well or not. Suppose I have a dataset with 1 million training examples, can you give me some rough estimates how much time would it take to train a deep architecture on such a dataset? I know there are lot of hyper-parameters that affect the training time (#layers...etc), but I just want some rough mean estimates since I'm still at the beginning and not aware of all parameters and so on. I just want to know how well they scale to large datasets.
