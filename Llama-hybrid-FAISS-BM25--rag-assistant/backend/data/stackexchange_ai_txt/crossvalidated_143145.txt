[site]: crossvalidated
[post_id]: 143145
[parent_id]: 
[tags]: 
How to measure convergence of data?

I am running a word-game simulations that assign values to words. In short, a computer is self-playing games of Scrabble and each move is recorded as (word, point value of the word). One value usually lies in (1,50) range, is always non-negative, but in extreme cases can reach 150-200 (sorry, I haven't calculated the distribution, but it is an interesting question in itself). After playing many games, we can determine the cumulative value of words, i.e. the more often the word was played, the more valuable it is. The list is sorted by values: DZET,10938 SŁAŃ,10926 ZSADŹ,10925 BZYG,10925 ĆELĘ,10924 LWY,10910 ONĄ,10909 PAN,10906 NIW,10903 WÓŁ,10886 DNI,10882 GÓR,10878 ZWĘ,10877 Sample results after 1, 2 and 3 iterations: 1 , 2 , and 3 . Real files are ~1e6 lines long and 50k games are played in between them, so the average increment per game is ~1 point for top words. For low-ranked words it will be much smaller. The convergence is reached when the ranking doesn't change any more, i.e. when we determined the best-valued words. Can you recommend a good way to measure convergence of these lists? I would like to know how many iterations is enough for the words to stay on their positions. The points don't matter, only the position of a word on the list (their rank). I can think of a very simple measure: for n in (number of iterations), take the differences between ranks in (n) and (n+1), and sum them. My knowledge of statistics is too sparse to tell whether it is a proper way though. For the top words, the difference will quickly become 0, but the further we are down the list, the longer it takes to converge (this is my assumption which I would like to confirm). The question is tool-independent, but FYI I'll be using python pandas to do this.
