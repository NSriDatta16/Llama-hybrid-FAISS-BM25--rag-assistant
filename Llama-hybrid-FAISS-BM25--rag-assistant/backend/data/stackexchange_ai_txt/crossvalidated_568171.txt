[site]: crossvalidated
[post_id]: 568171
[parent_id]: 
[tags]: 
Bayesian estimator under transformation of the parameters

Suppose we have $x=(x_1,...,x_n)|\mu,\sigma^2\sim f(x_i|\mu,\sigma^2)$ $iid$ , also let $\mu\sim p(\mu)$ and $\sigma^2\sim \pi(\sigma^2)$ be prior distributions. Here $f,p,\pi$ are generic distributions. Then the posterior is $$ p(\mu,\sigma^2|x)= c\times L(\mu,\sigma^2)p(\mu)\pi(\sigma^2), $$ where $c$ is the normalizing constant and $L(\mu,\sigma^2)=f(x|\mu,\sigma^2)$ is the likelihood function. Suppose I want to estimate $\phi=\phi(\mu,\sigma^2)=\mu/\sigma^{3/2}$ , what is the Bayesian estimator of $\phi$ ? Can I just compute $$ E(\phi|x)=\int\int \phi\times p(\mu,\sigma^2)d\mu d\sigma^2. $$ or, do I have to obtain the posterior distribution of $\phi$ first, then compute the posterior expectation of $\phi$ ? In which cases I can obtain Bayes' estimator of a function of the parameters directly from the joint posterior distribution of those parameters? My doubt is due to the fact that the Bayesian estimator under quadratic loss (which is the posterior expectation) is not invariant under transformation. So, I would be glad if somebody could clarify this for me.
