[site]: crossvalidated
[post_id]: 465913
[parent_id]: 464845
[tags]: 
In simple terms, NO. This is because the losses in GAN models are not very intuitive and can be misleading at times. However, one thing that can be monitored is whether, over the period of training, the losses have converged. Here again, the value does not matter because it is difficult to say that they will converge to a small value (which is typically the case in NNs). Remember that the concept of the original GAN is based on a zero-sum game - one's gain is another's loss. Instead of looking at the trend of the validation loss, a better way is to observe the samples generated after the completion of the training. The quality of the samples helps judge the generator's ability to learn a diverse representation of the input data distribution. Almost no one uses the loss curves as a reliable metric for GANs. Some of the well-known quantitative methods for evaluating GAN performance are Inception score and FID score to name a few. I am not sure what you mean by "memorization in a discriminator" here. If at all there is any memorization happening, a well-known name given to it is "Mode Collapse", wherein, the generator finds one particular image (or a set of images from a particular distribution) that is able to fool the discriminator and only keeps on generating that image (or slight variations of it). While it is difficult to pinpoint the cause, here is an intuitive understanding: Since both generator and discriminator are playing a game, striking a balance is crucial for GAN training. From the generator's perspective, it has realized that its opponent is too strong and hence it tries to win the game by exploiting the weakness of the discriminator, which happens by finding the one image that fools the discriminator and keeps generating that. A test for understanding whether a GAN has memorized the data distribution or learned a disentangled representation is to perform a "random walk" in the latent space (also called latent space interpolation). More on this can be found in the DCGAN paper . Apart from this, many versions of GANs and even different training techniques have been proposed that stabilize the GAN training and help the generator produce more diverse samples, thereby decreasing memorization. Wasserstein GANs and WGAN-LP are two examples that produce diverse samples without collapsing. The DCGAN paper gives a list of steps that lead to a stable training.
