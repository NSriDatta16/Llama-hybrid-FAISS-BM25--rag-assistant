[site]: datascience
[post_id]: 66612
[parent_id]: 66610
[tags]: 
In order to understand why it is a good value to use when determining new weight, we have to understand the maths behind backpropagation and what happens by updating weights at each iteration. Backpropagation uses the chain rule method to calculate the new weights. At each iteration, the weights are updated with the hope that we are converging towards an optimal set of weights were the neural network performs best. In other words, by updating the weight at each iteration backpropagation is searching for optimal parameters in a very high dimensional space. Each parameter's influence on total error can differ at every iteration. But by repeating this process over a set of training data after multiple epochs, backpropagation is able to optimize all those parameters (to some extent). The parameters which have less influence on error will change less often by definition of the chain rule .
