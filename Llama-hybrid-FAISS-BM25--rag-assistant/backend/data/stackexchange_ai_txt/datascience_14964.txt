[site]: datascience
[post_id]: 14964
[parent_id]: 
[tags]: 
Feature Selection for K Nearest Neighbour and Decision Trees

I have 2 digits numbers and 9 features. I must pick 2 features, so decided to plot the features against each other to see whether I can get any insight on the best features to train my algorithm. The plot colours indicates the two digits. Algorithms I considered to use were, K-Nearest Neighbour and Decision Tree. I am very new to machine learning, I chose these two algorithms simply because I have come across them. Feature matrix of f1 to f9 against f1 to f9 Decision Tree decision boundary I have a few questions: Will choosing the feature x against feature y with the least amount of overlap will help achieve the optimal decision boundary? When I look at features should I initially consider linear data separation. Then work my way up to use an algorithm that can deal with non-linear separated feature points? What important visual properties should I look out for when choosing optimal features for training? How can I visualise the tree in sklearn python? Thanks.
