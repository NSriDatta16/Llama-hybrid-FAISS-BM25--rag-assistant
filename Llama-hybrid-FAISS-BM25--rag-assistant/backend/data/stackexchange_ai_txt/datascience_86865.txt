[site]: datascience
[post_id]: 86865
[parent_id]: 
[tags]: 
Use feature-importance to decide what features to increase to increase target

(Please suggest another title for this question if you like - I find it rather difficult to phrase) Say I have an ice-cream stand and I record 3 features of my customers f1,f2,f3 to predict the amount of purchases. Say we train a logistic regression, logreg , and calculate the feature importance using e.g SHAP and denote i(f_n) the importance of feature n . It turns out that i(f2)>i(f1)>i(f3) , see the table below Feature | Importance rank | correlation with target | --------+-----------------+-------------------------- f1 2 + f2 1 - f3 3 + Based on that one might say that "To increase the purchase we just need to maximize f2 and reduce f1 ". That way we can draw some very wrong decisions, since f2 might increase the abillity to predict the target (amount of purchases) but we aren't sure that just by increasing f2 we increase the amount of purchases. For instance; the number of ice creams sold is correlated with the number of people who drowns; we cannot save people from drowning just by not allowing people to sell icecream (which would be bad for my ice-cream stand as well) - there is a latent/hidden variable here called "temperature" which we have not taken into account. Further more the table above might change if we add other features (or chose another model e.g RegressionTree). So, my question is; can we ever use things such as feature importance to "reverse engineer" i.e say: "if we want more of our target, we need to increase feature f1 " and not just say " f1 is positively correlated with y and has a high predictive power"?
