[site]: crossvalidated
[post_id]: 350314
[parent_id]: 350304
[tags]: 
Off-The-Shelf Solution, in R The cubist package by the legendary Max Kuhn does almost exactly this. Quoting from the documentation : A tree is grown where the terminal leaves contain linear regression models. These models are based on the predictors used in previous splits. Also, there are intermediate linear models at each step of the tree. It also includes a boosting-esque scheme called Ensembles By Committees , which can increase model accuracy. I have used cubist myself, and achieved accuracy similar to a Random Forest on my dataset. Your mileage may vary. In Python Based on some googling, you'll likely have to write it yourself, either by building decision trees and then extracting subsetting rules with which to fit linear models, or by porting/wrapping the C code that cubist is based on - available here . If I could volunteer a name, I'd suggest cubpyist . You might be able to join forces with this project , which seems to have just started.
