[site]: crossvalidated
[post_id]: 639888
[parent_id]: 
[tags]: 
Maximum Mean Discrepancy (MMD) implementation as a metric to measure GAN performance

I am trying to evaluate the performance of the GAN model, I have trained. I found that there exist two major choices FID (Fr√©chet inception distance) and MMD (Maximum Mean Discrepancy) for comparing the similarity of the training set and generated set data distributions. The nature of the data I have is coordinate points, in a plane with (number_of_samples, number_of_points, 2) shape. Of the two choices, I felt that MMD is the most appropriate for the point kind of data while the other is good for the image kind of data. Also, I read that MMD possess better properties than FID from https://doi.org/10.48550/arXiv.2401.09603 I see that MMD can be used as a loss function and/or as a metric to gauge the performance while training a GAN. In my case, I am interested in using it as a metric to measure GAN performance. After going through the literature and a few implementations, I wrote the following piece of code. It is expected to evaluate MMD taking numpy arrays of the training set true data and generated synthetic data. I am not seeing any decreasing trend of MMD during training, despite of visibly increasing quality of synthetic data. import numpy as np def mmd_rbf(true_ds: np.ndarray, synthetic_ds: np.ndarray, band_width=10.0): sd, td = synthetic_ds[:, -1], true_ds[:, -1] # flattening non-batch dimensions xx = np.matmul(sd, sd.T) xy = np.matmul(sd, td.T) yy = np.matmul(td, td.T) # evaluate squared similarity matrices rx = np.tile(np.diag(xx)[None, ...], [xx.shape[0], 1]) ry = np.tile(np.diag(yy)[None, ...], [yy.shape[0], 1]) ssm_xx = rx - (2.0 * xx) + rx.T ssm_xy = ry - (2.0 * xy) + rx.T ssm_yy = ry - (2.0 * yy) + ry.T # Evaluate components of the MMD gamma = 1 / (2.0 * band_width ** 2) xx = np.exp(-gamma * ssm_xx) xy = np.exp(-gamma * ssm_xy) yy = np.exp(-gamma * ssm_yy) return np.mean(xx - (2.0 * xy) + yy) My questions are : Is the above implementation correct? Also, is there any benchmark to validate this implementation? I see that in FID and MMD implementation, the samples are transformed (known as embeddings) before evaluating the MMD, which I am not doing at the moment. Is it necessary to do such a transformation or what is its purpose? If such a transformation is necessary, what are the alternatives for point kind of data?
