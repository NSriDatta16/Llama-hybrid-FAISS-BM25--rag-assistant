[site]: crossvalidated
[post_id]: 88445
[parent_id]: 88125
[tags]: 
A Gaussian model for word counts wouldn't fit well because of the zero counts you'd almost certainly have. If you had a very small vocabulary, then perhaps you could use the square root transformation and do well with the Gaussian as an approximation. But in reality, "as a document generally uses only a small subset of the entire dictionary of term generated for a given database, most of the elements of a term-by-document matrix are zero" (from Matrices, Vector Spaces, and Information Retrieval ). You can't transform your way out of zero! That's why exact distributions like multinomial are a better choice in word-count modeling situations like yours. If you consider Wikipedia an "official" source, the page on the Normal Approximation should convince you that the conditions are not met for word counts. The probability is too small relative to the number of words; you're getting zeros most of the time.
