[site]: crossvalidated
[post_id]: 503314
[parent_id]: 
[tags]: 
Are Stack GANs fully trained when a new module is added, or are previous modules kept the same?

As my understanding goes, Stack GANs ( StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks by Zhang et al.) are trained in different stages. On each of those, a new "block" that increases the resolution is added. The core idea is that trying to make GANs learn an image with spatial coherence and detail is too difficult at first. So it seems better to train a small model that generates more consistent "base images", and when that works correctly, train a model that uses the previously trained block as an input. My question then is, when a new block is added, this new block has randomly initialized weights while the previous one is capable of generating consistent images. Are both of them trained on the second phase, or are the weights of the previous block frozen ? It would make sense to me that the previous block is set to not be trainable to avoid catastrophical forgetting of the spatially coherent images it's capable to produce.
