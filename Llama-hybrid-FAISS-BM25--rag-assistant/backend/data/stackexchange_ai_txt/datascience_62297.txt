[site]: datascience
[post_id]: 62297
[parent_id]: 62294
[tags]: 
Computationally, there is just no way to use the data with the values missing. You do still have a whole three options, though: Drop the rows. This is "listwise deletion." Like you said, you don't want to do that - and it can cause biased results, as the observations with missing values may be ones that speak against some theory, or (in more general terms) represent some consistent data-generating pattern. Drop the column. This will eliminate any bias due to the above, at the cost of inefficiency. It may also be a non-starter if the effect of this variable is what you're concerned with anyway. Impute. You can fill in the missing values with your best guesses (i.e. the maximum-likelihood point-predictions of an imputation model - or even just the "null model", i.e. the global column means) and treat them like real values, though this is bad practice because it doesn't reflect the inherent uncertainty about imputed vs. actually observed values. Standard practice is to ensure your imputation model produces a best-fit distribution for each observation, generate 5 versions of your dataset with 5 sets of random draws from those observation-specific distributions, fit the same model to each of those datasets, and average the results. Note, though, that if the model is an arbitrarily complicated machine-learning algorithm (i.e. a universal approximator like a neural net), then you can just fill in the missing values in each column with any "free" value - one that's not actually present in the data, and won't be - and the model will learn to treat those values not just differently but appropriately. It will effectively do its own imputation, in fact. But still, you can't have the actual inputs as missing values.
