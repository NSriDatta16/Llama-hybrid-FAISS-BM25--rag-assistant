[site]: crossvalidated
[post_id]: 503136
[parent_id]: 
[tags]: 
Approximate marginal posterior distribution via sampling

I'm a beginner in Bayesian inference and I have some confusion about posterior distributions, in particular sampling from it vs. approximating its value at some given point. Suppose I have a model with parameters $\theta = (\theta_1, \theta_2)$ , and observed data $y$ . Suppose I can sample from the posterior distribution $p(\theta| y)$ , and let $\mathcal S = \{\theta^{(s)} = (\theta_1^{(s)}, \theta_2^{(s)}):s=1,\ldots, S\}$ be samples. Then, regarding the posterior predictive distribution $$p(\widetilde y| y) = \int p(\widetilde y|\theta)p(\theta|y)d\theta$$ I can (taking from Hoff's Bayesian Statistical Method Section 4.3 ): Sample from $p(\widetilde y|y)$ : starting from samples $\mathcal S$ I draw $\widetilde y^{(s)} \sim p(\widetilde y|\theta^{(s)})$ obtaining samples $\{(\widetilde y^{(s)}, \theta^{(s)})\}$ from the joint posterior $p(\widetilde y, \theta|y)$ and then I just ignore the $\theta$ 's obtaining a sample $\{\widetilde y^{(s)}\}$ from the posterior predictive distribution. Approximate the value of $p(\widetilde y|y)$ for any given $\widetilde y$ by Monte Carlo approximation: since $$p(\widetilde y|y) = \int p(\widetilde y|\theta)p(\theta|y)d\theta = \mathrm E_{p(\theta|y)}[p(\widetilde y|\theta)] \approx \frac{1}{S}\sum_{s=1}^Sp(\widetilde y| \theta^{(s)})$$ My question is if a similar argument allows to approximate the marginal posterior distribution \begin{equation} p(\theta_1|y) = \int p(\theta_1|\theta_2, y)p(\theta_2|y)d\theta_2\tag{1} \end{equation} How do I approximate the value of $p(\theta_1|y)$ for a given value of $\theta_1$ ? Reasoning as above: Sampling from $p(\theta_2|y)$ : take $\mathcal S$ and just ignore the $\theta_1$ 's, obtaining a sample $\{\theta_2^{(s)}\}$ from the posterior marginal $p(\theta_2|y)$ Approximating $p(\theta_1|y)$ for a given $\theta_1$ : my guess is that I can consider $p(\theta_1|y) = \mathrm E_{p(\theta_2|y)}[p(\theta_1|\theta_2,y)]$ so that again by Monte Carlo simulation I can approximate $p(\theta_1|y) \approx \frac{1}{S}\sum_{s=1}^Sp(\theta_1|\theta_2^{(s)}, y)$ . Is this argument correct? It seems to me that this case is analogous to the above for $p(\widetilde y|y)$ however I could not find this clearly stated in books so I wonder if I am missing something basic. For example in BDA3 , Section 3.1 they say: We rarely evaluate integral (1) explicitly [...]. Posterior distributions [i.e., $p(\theta_1, \theta_2|y)$ ] can be computed by marginal and conditional simulation, first drawing $\theta_2$ from its marginal posterior distribution [i.e., $p(\theta_2| y)$ ] and then $\theta_1$ from its conditional posterior distribution [i.e., $p(\theta_1|\theta_2, y)$ ] given the drawn value of $\theta_2$ . In this way the integration embodied in (1) is performed indirectly I don't understand in which sense this amounts to computing the integral (1) for some given value of $\theta_1$ , it looks like a way to sample from the distribution it defines. I would greatly appreciate any reference (I guess it could appear as well when integrating nuisance parameters).
