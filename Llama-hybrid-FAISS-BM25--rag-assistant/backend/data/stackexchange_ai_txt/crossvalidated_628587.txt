[site]: crossvalidated
[post_id]: 628587
[parent_id]: 628585
[tags]: 
Yes you can do a) data augmentation with noise on the input so that the model does not react so strongly on changes on the inpuut. People do it for example in adversarial Training and add noise which is especially tricking your model in the wrong direction (proportional to the steepest gradient ascent of the to be minimized lose) b) penalize large gradients in the loss function. c) do other regularization than b) by penalizing large weights which can result in steep gradients There is a lot of literature about robust machine learning and potentially other people can add some more strategies here. I am not aware that typically you would add additional label noise since your model tries to estimate the conditional mean (in the case of MSE loss) anyway.
