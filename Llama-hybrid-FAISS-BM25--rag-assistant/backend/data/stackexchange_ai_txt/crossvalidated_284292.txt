[site]: crossvalidated
[post_id]: 284292
[parent_id]: 
[tags]: 
Are model diagnostics necessary for linear model run on matched data?

On https://cran.r-project.org/web/packages/cem/vignettes/cem.pdf , it mentions that "Using the output from cem, we can estimate SATT via the att function. The simplest approach requires a weighted difference in means (unless k2k was used, in which case no weights are required). For convenience, we compute this as a regression of the outcome variable on a constant and the treatment variable, where the SATT estimate is the coefficient on the treated variable. The function att allows for Râ€™s standard formula interface and, by default, uses a linear model to estimate the att using the weights produced by cem. In other situations, with some coarsening, some imbalance remains in the matched data... Thus, a reasonable approach in this common situation is to attempt to adjust for the remaining imbalance via a statistical model...To apply a statistical model to control for the remaining imbalance, we use the formula interface in att." Here, the SATT is sample average treatment effect on the treated and the k2k means one to one matched data rather than one to many. It is clear that the coefficient of lm with one predictor (the treated variable) is basically a difference in means. However, when there are other predictors, in the cem vignette, they go on to run a linear model using R's formula interface and use the coefficient on the treated variable only. In fact, only the coefficient on the treated variable is presented in the att function output. My question is if I am manually doing this through the lm function, when doing analysis on matched data, using either propensity scores or coarsened exact matching, what part of the statistical machinery for the linear model run on the matched data should still be checked (i.e., diagnostics, etc.)? Because in the vignette, they don't present coefficients of other variables, does it mean it is OK for there to be, for example, many variables that were non-significant still present? Should we be checking things like multicollinearity via the variance inflation factor (vif)? They also don't seem to do any residual analysis. Is it because the variables are simply there to remove some remaining imbalance? My primary objective is the weighted difference in means (treated = 1 vs. treated = 0), i.e., the coefficient of the treated, not the coefficients of the other variables for the linear model. However, residual analysis would show if the p-values obtained on the assumption of normality of the residuals makes sense or not. What if residual analysis showed that the residual qq plot looked way off? Should I bootstrap (or use something like MASS::rlm) on the matched data or again, simply concern myself with the coefficient of the treated variable?
