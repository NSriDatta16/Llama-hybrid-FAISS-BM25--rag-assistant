[site]: crossvalidated
[post_id]: 249843
[parent_id]: 249417
[tags]: 
Accuracy metrics of cross-validation are difficult because it lives in a statistical gray zone where the samples aren't coming from the same model, but the models aren't independent either since most of the training data are the same. Ideally, you should avoid the situation all together by setting aside an explicit testing set. If that is not possible (ex. the dataset is too small to set any aside and still do CV), it is generally better to avoid aggregation and report the statistics for each fold. This can tell you a lot about the stability of the model because an average accuracy of 80% where half the folds have an accuracy of 100% and half have an accuracy of 60% has a very different interpretation than one where every fold is 80%. You can additionally report the aggregate measures, but make it clear what you are doing. Putting the aggregate along side a plot of the individual folds usually does this well.
