[site]: crossvalidated
[post_id]: 157516
[parent_id]: 157502
[tags]: 
As explained in detail in this other answer , kNN is a discriminative approach. In order to cast it in the Bayesian framework, we need a generative model, i.e. a model that tells how samples are generated. This question is developed in detail in this paper (Revisiting k-means: New Algorithms via Bayesian Nonparametrics). The approach follows two steps: first finding a smooth version of k-means (GMM) and then use the Dirichlet Process (DP) to model the mixture of Gaussians. The first step builds upon the asymptotic relationship between kmeans and GMM. This is necessary in order to have an efficient model of the conditional probabilities, for which we have efficient sampling algorithms. As already said, the DP models the distribution of Gaussian mixtures which could have generated the observed data. Initially one may even have an infinite number of components!. The goal is then to find the likeliest values that could have generated the data.
