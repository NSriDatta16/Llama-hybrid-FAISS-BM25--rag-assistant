[site]: datascience
[post_id]: 108261
[parent_id]: 
[tags]: 
How do companies handle changing natural language

I am assuming large social medias like Twitter handle hashtags using some sort of embedding, so that similar tweets can be found or suggested. Maybe this is a bad assumption- maybe someone can clarify. However, the question I have is how they handle new vocabulary being added? For example, whenever a new hashtag becomes trending, it is likely or at least possible that that exact string had not been included in the vocabulary of the embedding before then. Since embedding vocabulary cannot be changed after the fact, is it possible that they simply retrain their model every few hours? That seems to be intractable.
