[site]: crossvalidated
[post_id]: 594136
[parent_id]: 
[tags]: 
Calculating performance scores by subtracting the Shapley feature effects from predictions

One of my friends has done the following: He trained an XGBoost model let's call it Model 1 and then calculated the feature effects using Shapley for the different features, let's say Feature_1, Feature_2, Feature_3 . He then calculated the performance scores using the following combinations: Prediction 1 = Effect Feature_1 + Effect Feature_2 + Effect Feature_3 Prediction 2 = Effect Feature_1 + Effect Feature_2 Prediction 3 = Effect Feature_1 + Effect Feature_3 He found out that Prediction 3 is the one that it is better than all in terms of performance. For me it's wrong what he did since XGBoost is a correlation model and by changing the training data you change the correlation among the features so if you train a model using only the Feature_1 and Feature_3 then the predictions will not be equal to Prediction 3 . I was planning to prepare a dummy example for him by training a model Model 2 with only the Feature_1 and Feature_3 and show that the predictions of Model 2 are not equal to Prediction 3 but I wanted to ask the following: Do you have any resource that can explain it further and in a more scientifically sound way? And lastly but most importantly, is there a case where what he did actually holds true? Thank you!
