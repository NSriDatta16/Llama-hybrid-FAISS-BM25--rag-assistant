[site]: crossvalidated
[post_id]: 266343
[parent_id]: 266304
[tags]: 
Loading in factor analysis or in PCA ( see 1 , see 2 , see 3 ) is the regression coefficient, weight in a linear combination predicting variables (items) by standardized (unit-variance) factors/components. Reasons for a loading to exceed $1$: Reason 1: analyzed covariance matrix. If analyzed were standardized variables, that is, the analysis was based on correlation matrix, then after extraction or after orthogonal rotation (such as varimax) - when factors/components remain uncorrelated - loadings are also the correlation coefficients. That is the property of linear regression equation: with orthogonal standardized predictors, parameters equal Pearson correlations. So, in such a case loading cannot be beyond [-1, 1]. But if analyzed were just centered variables, that is, the analysis was based on covariance matrix, then loadings don't have to be confined to [-1, 1] because regression coefficients is such model need not be equal to correlation coefficients. They are, actually, covariances. Note that it were raw loadings. There exist "rescaled" or "standardized" loadings (described in the links I gave in the 1st paragraph) which are rescaled not to leave the [-1, 1] band. Reason 2: oblique rotation. After oblique rotation such as promax or oblimin we have two types of loadings: pattern matrix (regression coefficients, or loadings per se) and structure matrix (correlation coefficients). They are not equal to each other because of the reason given above: correlated predictors' regression coefficients are different from Pearson correlations. Thus, a pattern loading can easily lie beyond [-1, 1]. Note that it is true even when correlation matrix was the analyzed matrix. So, that is how when factors/components are oblique. Reason 3 (rare): Heywood case. Heywood case ( pt 6 ) is a difficulty in factor analysis algorithms when on iterations loading exceeds the theoretically permitted magnitude - it occurs when the communality gets beyond the variance. Heywood case is a rare situation and is encountered on some datasets typically when there are too few variables to support the requested number of factors. Programs inform that there's Heywood case error and either stop or try to resolve it.
