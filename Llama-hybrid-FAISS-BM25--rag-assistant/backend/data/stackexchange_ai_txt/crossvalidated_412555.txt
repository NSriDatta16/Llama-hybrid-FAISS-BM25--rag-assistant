[site]: crossvalidated
[post_id]: 412555
[parent_id]: 412507
[tags]: 
The mclust package terminology is definitely not standard, but it has some heuristic meaning. I'll try to keep the algebra as painless as possible We need some algebra for background. When we conduct latent profile analysis with Gaussian indicators, we are assuming that each indicator $y_i$ in each class $c$ has a normal distribution. We estimate the mean of each indicator in each class. Let's go with the diabetes dataset referenced in your link for an example. There, we're using these 3 indicators: blood glucose after a glucose tolerance test, the area under the plasma insulin curve, and steady state plasma glucose. The algebra I've seen associated with LPAs is much like a linear regression setup. If you fit a linear regression to each indicator with no predictors, that's basically just a mean for each indicator, and the algebra is: $y_i = \alpha_i + \epsilon_i$ Where $\alpha_i$ is just an intercept. For LPAs, we are doing this process for each latent class. So: $\overline y_{ic} = \alpha_{ic} + \epsilon_{ic}$ Another way to think about things is this. A normal distribution is characterized by two parameters: mean and variance. The intercepts $\alpha_{ic}$ are the means. The variances are controlled by the error terms $\epsilon_{ic}$ . Orientation = Correlation If I plot two normally distributed random variables that are correlated, I'll have a slanted ellipse. the For example, see structure EEE in fig 2. All those ellipses are slanted. So there are 3 classes where the two indicators are correlated. If I have two uncorrelated normal random variables, I have an ellipse that's lying flat - I'm not sure what the technical term is, but see structure EEI for an example. The authors call this "coordinate axis" orientation. Another thing: this package apparently allows you to have correlated indicators, but to constrain the correlations to be equal across latent classes. I don't see this feature in Stata, the software I'm familiar with. Shape and Volume = Variance of each indicator Now, I know this may not immediately be obvious, but when the mclust authors say shape and volume, I believe they're referring to various assumptions about the class-specific variances, i.e. the error terms. When they say shape and volume equal, they mean you constrain the error terms to be equal across latent classes. So, that means the variances are equal. You can heuristically think of LPA as if you have a magic, multidimensional cookie cutter. Let's keep this analogy in 2D. Variance equal means you are telling it to go to your data and to cut out $k$ equally sized ellipses out of the data. Variable shape or volume seems to mean variances of the indicators are not equal across latent classes. So, your magic cookie cutter will cut $k$ ellipses, but they can be of different sizes. Verify this for yourself by comparing structure EEI to VEI in their figure 2. I'm less sure how to distinguish shape and volume in the mclust context. I think that when they say shape equal, they mean that all the latent classes have the same type of distribution: spherical, diagonal, or ellipsoidal. I think that spherical implies that the variance of each indicator is equal within class, which seems like a strict assumption. I think that when they say "diagonal", they mean an ellipse that's aligned with the x-y axes, i.e. the indicators are un -correlated. When they say "ellipsoidal", they seem to mean the indicators are correlated and the correlation is not zero. Honestly, this is confusing terminology. Kathryn Masyn wrote a chapter on latent class and profile models in the Oxford Quant Handbook. She makes only two distinctions: class-invariant vs -varying (i.e. are the indicator variances equal across classes or not?) and correlation structure (are the indicators uncorrelated or correlated in each class?). Should you start modeling with a less constrained LPA or a more constrained one? I'm going to issue some speculation here, and this actually contradicts what Masyn wrote in her handbook. She seems to have a PhD in actual biostatistics, whereas I'm just an applied statistician. She said you should explore all 4 possible model structures implied by the paragraph above, and basically compare the BIC (it's more complicated, read her chapter). However, reality is complex. Why do we not just start with the least constrained model? That means we assume the indicators are correlated and estimate the class-specific correlations. It also means we assume that the variance of each indicator varies by class, and we estimate that. If we see that the correlations are generally zero, or if we have substantive knowledge that indicates that they should be zero, then we issue the appropriate constraint. Same for the indicator variance. It's hard for me to imagine a scenario where I would have that knowledge in my own field, but who knows (that doesn't mean a scenario like that doesn't exist, though). I can't really talk concisely about what you should do in the mclust context. Many of their structures are even more constrained than the most constrained case in Masyn's writing.
