[site]: crossvalidated
[post_id]: 402391
[parent_id]: 
[tags]: 
Why the performance of random forest is related to the order of training samples?

everyone! I find that the performance of random forest classifier in python seems to be related to the order of training samples. Can anyone help me to figure out the reason? Thanks very much! from sklearn.ensemble import RandomForestClassifier import numpy as np from sklearn.datasets import load_digits def shuffle_train(): digits = load_digits() # print digits.data.shape cls = RandomForestClassifier(random_state=0,class_weight='balanced') ind = np.arange(1000) # take the first 1000 samples as training dataset np.random.shuffle(ind) training_data = digits.data[ind, :] training_label = digits.target[ind] # shuffle the training dataset cls.fit(training_data, training_label) testing_data = digits.data[1000:, :] testing_label = digits.target[1000:] testing_pred = cls.predict(testing_data) print np.sum(testing_label==testing_pred) if __name__ == '__main__': for i in range(20): shuffle_train() # try 20 times and get different results And this is the output: 714 715 708 701 702 719 708 712 710 714 723 725 726 722 734 714 701 717 717 689
