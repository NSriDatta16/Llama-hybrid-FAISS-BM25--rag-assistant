[site]: crossvalidated
[post_id]: 438722
[parent_id]: 438662
[tags]: 
Typically, loss functions for forecasts are computed for each horizon separately. This is partly because performance usually degrades the further out you go, and any improvements in the short term loss might be difficult to pick up when the long term loss is numerically much larger. Each horizon is effectively a different target and it makes sense to consider the model's performance on each one separately. There's nothing stopping you from averaging loss across horizons if that is meaningful for your problem domain, though. However, either way, you should repeat your training/testing split on a recursive or rolling basis, obtaining multiple loss values from different origins for each horizon, and average those. The single train/test split you have gives you effectively just one observation of performance for each horizon. This is true for any loss measure (not just pinball loss). You can interpret a "pure" point forecast (with no associated prediction interval) as predicting a degenerate distribution with a mass at that point, i.e. $P[X_{t+h} = x] = 1$ , where $x$ is your point forecast. In that case, for any $0 , the predicted $\alpha$ -quantile is simply $x$ . This will probably not be a very good predicted quantile, but it does allow you to compare a point forecast method with other more complicated methods. It would not be unusual to find that a point forecast method gets a bad pinball loss in the tails but an actually better loss in the middle of the distribution than a model that tries to accurately reproduce all quantiles. What you have there looks fine, aside from the fact that you will get better loss estimates from doing this from multiple origins. You should try plotting the result across quantile levels to see which parts of the distribution each model captures best. For example, here's your syph_ts[,1] and the performance for a normal white noise model, a normal AR(1) model, and the degenerate point forecast from the AR(1) model, where each model was first trained on the first 100 points, and then rolled forward 1 period at a time, and then the loss is averaged across folds for each horizon separately. This is the result one step ahead (here QS stands for quantile score, which is just twice the pinball loss): And 10 steps ahead: We can see that the AR(1) model dominates the white noise process in the short term but not the long term, and that the degenerate point forecast is worse in the tails but not too bad as an estimate in the 50-85% range (this is because the point forecast is biased high...). If you are not really interested in the performance of the forecast at individual quantile levels, you might want to look at the continuous ranked probablity score (CRPS), which is the integral of the quantile score across quantile levels:
