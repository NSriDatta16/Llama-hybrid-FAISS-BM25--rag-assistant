[site]: datascience
[post_id]: 79569
[parent_id]: 78511
[tags]: 
Reason for the difference is - GridSearchCV uses Cross-Validation techniques. When you don't provide any value i.e. None, it will use CV = 5. cv : int , cross-validation generator or an iterable, default=None Determines the cross-validation splitting strategy. Possible inputs for cv are: None, to use the default 5-fold cross validation It means Training/testing is happening on 80/20 and 5-Fold average. But when you are testing, you are calculating the score on test data. Even though if you change it to Train, it will continue to show this behavior. That is explained in the 2nd point. Iris data set is very small i.e. one record ~ 1%. and at the same time it is very simple to Classify, so very C value is able to achieve similar results. So, when GridSearchCV tries with 5-Fold on train data it sees a C which is almost 98% accurate. But on actual Test data, the same C misses 1-2 records, and the score dip by 1-2%. If you try multiple times, we will also get a consistent result a few times. What is needed - - Try GridSearchCV on a bigger dataset - And there should be a value of the grid which gives clearly better score. May happen when the grid has 4-5 parameters
