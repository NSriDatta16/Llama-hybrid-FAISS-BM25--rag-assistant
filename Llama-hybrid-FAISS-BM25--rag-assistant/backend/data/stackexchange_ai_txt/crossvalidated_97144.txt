[site]: crossvalidated
[post_id]: 97144
[parent_id]: 
[tags]: 
testing for differences in means after an experimental change

I have a set of Mechanical Turk-like workers who have been paid $0.25 per task to complete tasks from a finite, but very large, pool of tasks, and I have data on how many tasks they've completed and how accurately/quickly they've completed them for the last year. On April 1, I dropped the price paid to the workers per task to $0.15. I now have a month's worth of data on the volume of tasks completed, the accuracy of completion, and the time for completion. I'd like to test whether the drop in price paid per task has had any effect on volume of task completion, accuracy, and time. My instinct here is to use a Wilcoxon signed-rank test to compare monthly average data from the 12 months before the price drop and the month of data I have after the price drop. Is this the right test to be using? In particular, I thought the Wilcoxon signed-rank test was particularly applicable here because I'm comparing outcomes on the same sample and because the non-parametric nature of the test lets me not actually make any assumptions, unlike Student's t-test. Is it reasonable for me to compare average monthly data for the 12 months before the drop to the month of data after the drop? Is there a better approach to be taken when trying to detect if the price drop had any change on outcomes?
