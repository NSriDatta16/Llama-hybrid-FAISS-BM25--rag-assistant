[site]: datascience
[post_id]: 100149
[parent_id]: 92427
[tags]: 
It is worth considering using a "deterministic" classifier if all of the following conditions are met: the false-positive and false-negative misclassification costs are known beforehand and are either fixed, or you don't mind retraining your model when the change; the relative class frequencies in operation are known beforehand and are either fixed, or you don't mind retraining your model when they change; ou don't need a "reject" option (although there are ways around that). In those situations, you might want to use a classifier like the Support Vector Machine that focusses on solving the classification problem directly. The reason for this is that a probabilistic classifier tries to predict the probability accurately everywhere , and will expend modelling resources doing so. A discrete/deterministic classifier, on the other hand, only focuses resources on estimating the position of one particular contour of probability, as that gives the optimal decision boundary, so in principle it can make better use of the available data. The nice thing about probabilistic classifiers is that you can adjust for changes in misclassification costs, or changes in relative class frequencies, or implement a "reject" option easily and without having to retrain the model. The downside is they make slightly less good use of the data as they consider features of the data distribution that are not relevant to the optimal classification, see my example of that here: https://stats.stackexchange.com/questions/312780/why-is-accuracy-not-the-best-measure-for-assessing-classification-models/538524#538524 . So if you don't need/want any of those nice properties of probabilistic classifiers, you might get better results using a discrete classifier (and the success of the SVM gives evidence that is true in a variety of practical applications). In short, have both sets of tools in your data science toolbox as both are useful.
