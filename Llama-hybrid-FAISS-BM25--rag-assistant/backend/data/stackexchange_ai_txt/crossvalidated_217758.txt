[site]: crossvalidated
[post_id]: 217758
[parent_id]: 217736
[tags]: 
A '3d network' might commonly be described as a network with 2d layers. It's not fundamentally different from any other network because the principles of activation are the same. The activation of each unit is a linear combination of its inputs, passed through a (typically nonlinear) activation function. In one sense, the dimensionality is just a property of the drawing. You could draw the units anywhere you wanted (using however many dimensions you wanted) and the function would be the same. Instead, it's the connectivity that matters. There are a couple reasons to 'organize' networks layers into well defined shapes. One is for convenience in thinking about things (e.g. in the case of processing 2d inputs like images). This is particularly the case when connectivity is constrained. For example, in a convolutional network that processes images, each unit receives connections from a local 'patch' of units in the previous layer. Thinking about the layers as 2d makes intuitive sense here because it lets us talk about things like 'local patches'. But, as before, you could completely scramble the 'locations' and the function would be the same as long as connectivity is the same. In convolutional networks (e.g. for image processing), there's an additional benefit to representing the layers in 2d. Because of the way these networks constrain the weights/connectivity, representing the layers in 2d makes it possible to use the 2d convolution operation when computing the activations of all units in a layer. Although it doesn't change the fundamental function of the network, it's a very computationally efficient way of implementing things. This is just one example, and there could be other cases where representing units on a grid with some dimensionality makes it possible to play computational tricks that speed things up (e.g. in the blog post you linked). Actually, the network in the blog post is a different beast because it's a spiking network that tries to emulate biological neurons slightly more closely than a standard artificial neural net. But, that's a whole different issue.
