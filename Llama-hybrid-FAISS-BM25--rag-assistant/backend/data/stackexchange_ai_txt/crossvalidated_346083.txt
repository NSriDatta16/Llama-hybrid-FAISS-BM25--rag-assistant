[site]: crossvalidated
[post_id]: 346083
[parent_id]: 
[tags]: 
NN Accuracy and Understanding tensorflow-graphs

If I test accuracy using the below code while training, then it works well. If however, I use a separate function then it outputs the wrong value (about 20 times too small). There must be something about the fundamentals of graphs which I'm not grasping. Hopefully, one of you can spot it. pred = tf.nn.softmax(fc_layer_4) prediction = tf.cast(tf.equal(tf.argmax(pred,1), tf.argmax(yph,1)),tf.float32) accuracy_scores = [] acc = sess.run(prediction, feed_dict = {xph:x_mini, yph:y_mini}) accuracy_scores.extend(acc) accuracy = np.average(np.array(accuracy_scores)) Some added background: I need a separate method so that I can test accuracy in training, test and dev sets when required without rerunning the main model function. Also, I need to run the accuracy in batches as my machine is not powerful enough to handle it otherwise. This is the separate accuracy method I am using: def accuracy(X, Y, parameters): tf.reset_default_graph() xph, yph = createPlaceholders(28,10) fc_layer_4 = forwardprop(xph, yph, parameters) pred = tf.nn.softmax(fc_layer_4) prediction = tf.cast(tf.equal(tf.argmax(pred,1), tf.argmax(yph,1)),tf.float32) accuracy_scores = [] mini_batches = random_batches(X,Y, batch_size=2048) init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) for batch, (x_mini, y_mini) in enumerate(mini_batches,1): acc = sess.run(prediction, feed_dict = {xph:x_mini, yph:y_mini}) accuracy_scores.extend(acc) accuracy = np.average(np.array(accuracy_scores)) return accuracy
