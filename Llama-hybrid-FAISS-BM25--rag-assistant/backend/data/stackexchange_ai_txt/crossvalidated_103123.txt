[site]: crossvalidated
[post_id]: 103123
[parent_id]: 103084
[tags]: 
There is an excellent post ( Obtaining predicted values (Y=1 or 0) from a logistic regression model fit ) about the break-even point of precision (or sensitivity) and specificity . The latter is not the same as recall, but it should be easy to generalize from there. If you look at the plot you will see a point where the metrics cross, this is your optimal cutoff point. EDIT I have updated the code to include precision, recall, and F1 perf = function(cut, mod, y) { yhat = (mod$fit>cut) w = which(y==1) sensitivity = mean( yhat[w] == 1 ) specificity = mean( yhat[-w] == 0 ) c.rate = mean( y==yhat ) d = cbind(sensitivity,specificity)-c(1,1) d = sqrt( d[1]^2 + d[2]^2 ) # F-score retrieved
