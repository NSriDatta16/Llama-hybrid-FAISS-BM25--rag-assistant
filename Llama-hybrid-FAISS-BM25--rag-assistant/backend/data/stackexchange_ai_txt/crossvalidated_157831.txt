[site]: crossvalidated
[post_id]: 157831
[parent_id]: 
[tags]: 
Expected number of times you spent in a state of an absorbing markov chain, given the eventual absorbing state

It's well known that, if $Q$ is the matrix of transient state transition probabilities, and $$ N = \sum_{n=0}^{\infty} Q^n = (I - Q)^{-1}$$ then $N_{ij}$ describes the expected number of times the chain is in state $j$, given that it starts in state $i$. (source: Wiki absorbing markov chain). I'm looking for the expected number of times the chain is in state $j$, given that it starts in state $i$ $\textbf{and}$ eventually absorbs in state $k$. Motivation: I'm trying to model the spread of a mutant gene throughout a population, and to do this, I'm using a markov chain. The absorbing states are $0$ and $M$ to represent the gene dying or existing in every member of the population. I want to calculate the number of times a specific amount of people have this gene before it dies out, given that it dies out.
