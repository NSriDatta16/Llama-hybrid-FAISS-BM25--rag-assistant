[site]: crossvalidated
[post_id]: 217439
[parent_id]: 216241
[tags]: 
Expanding on AlexR.'s comment, the notation $P(X_0, \cdot)$ denotes the transition kernel of the Markov chain starting at $X_0$. In other works, it denotes the probability distribution of the Markov chain after 1 step. Here '$\cdot$' denotes a stand-in set. So for a set $A$ in the state space, $$P(X_0, A) = Pr(X_1 \in A \mid X_0 = X_0). $$ Similarly, $P^t(X_0, \cdot)$ denotes the probability distribution after $t$ steps for the Markov chain starting at $X_0$, i.e $$P^t(X_0, A) = Pr(X_t \in A \mid X_0 = X_0). $$ Once you understand this notation, you will realize that in the equation for the total variation distance, $d_{TV}(P^t(X_0, \cdot), P^t(Y_0, \cdot) )$ measures the distance between these two probability distributions . So you have two Markov chains starting at $X_0$ and $Y_0$, each goes $t$ steps, and updates the distribution of the Markov chain. This distance metric measures how far are these two Markov chains.
