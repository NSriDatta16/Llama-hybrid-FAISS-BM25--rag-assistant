[site]: datascience
[post_id]: 37369
[parent_id]: 37363
[tags]: 
If I understand your meaning: you are modelling by proxy. In other words, it could be seen as using a common autoregressive , simply with the autoregressive part itself removed. I won't get into the details of RNNs and Keras, but let me first explain with a common model used for time-series analysis, ARIMA: ARIMA X stands for: A utoreg r essive - model a variable using its own historic values I ntegrated - use differences between values over timesteps (not the raw values) M oving A verage - include historic values of the actual forecast errors X - common final letter to show we use e x ogenous variables, variable apart from our target ARIMA is characterised by three parameters, which tell us how many previous timesteps of the first three terms above are used: ARIMA(p, d, q). p is for AR terms, d for I terms and q for MA . Within this framework, your problem would be equivalent to setting p = 0 . We can see on the Wikipedia site linked above, or here , that doing so makes the ARIMA model essentially an exponential smoothing model! You could start by analysing how correlated your variables X1 and X2 are with the target variable X3 , in order to assess how well (or badly) they might explain the target. If you follow some tutorials on setting up an experiment for ARIMA, it will only be technicalities to feed the same data into an RNN, or anything else you might build using Keras. You need to feed blocks of data into the model, leaving out previous timesteps of the target variable itself... although if you have them and can use them for validation/testing, I would wonder why you aren't using them to improve the model!
