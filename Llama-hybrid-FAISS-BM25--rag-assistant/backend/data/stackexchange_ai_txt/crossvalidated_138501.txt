[site]: crossvalidated
[post_id]: 138501
[parent_id]: 138490
[tags]: 
It does not really seem that you can justify the "X, Y and Z are best predictors" sentence in this case. At least because all predictors are best for purpose, i.e. are they so specific that they can be used as the final truth in diagnosis, or are they so sensitive that given some predictor values, no cases will be missed, or maybe those perform better than others on average? What you can state is exactly what you obtained: X, Y and Z scored best on the scale of variable importance of the RandomForest algorithm. It looks that you studied the association of various predictors with the outcome, a type of study that many researchers do, so I would encourage you to use the de facto standard of reporting association in medical and biological research, namely the combination of odds ratio (effect size) and the p-value for exact Fisher's test. Such measures are reported very often (if not always) and allow other researchers to compare results between papers. Of course the importance metric will not hurt anyone if you add it to the most commonly used two.
