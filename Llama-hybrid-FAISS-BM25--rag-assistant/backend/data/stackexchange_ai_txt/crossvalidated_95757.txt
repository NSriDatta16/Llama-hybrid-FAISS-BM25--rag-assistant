[site]: crossvalidated
[post_id]: 95757
[parent_id]: 
[tags]: 
Identifying patterns in data streams with minimal state

I could not pick a more generic title for this question I guess. Here is what I am dealing with: I have a time series data stream coming in from multiple measurement endpoints. The number of endpoints is between 2 to 200. The resolution is 10 seconds but I am using the 1 minute aggregate. The data is CPU utilization, the unit is percentage. Something like: [endpointA: 10, endpointB: 12, endpointC: 5, ... endpointZ: 12] [endpointA: 6, endpointB: 20, endpointC: 17, ... endpointZ: 5] [endpointA: 3, endpointB: 9, endpointC: 19, ... endpointZ: 20] I need to identify misbehaving endpoints. The undesired behavior is the have different CPU utilization pattern than the rest of the nodes. It quite obvious just by looking at the graph, but I need to translate that obvious human recognizable pattern to a software. My first approach was to generate the STD for every minute and use the 1.4 * (STD + mean) for misbehaving nodes but this captures too many false positives because the data is very spiky. I am wondering what is the best approach to avoid false positives but capture all of the bad guys. My current ideas: Every iteration (minute) just feeds into a hashmap that has counters for each node it sees. If you see a node alarming you increment the counter, if you don't see it decrement the counter. If a node reaches count number 3 you identify it as a bad node. Instead of using the STD for every minute, I keep an accumulated STD across N nodes (N If you have any better way to deal with spiky data streams please share it. Thank you in advance.
