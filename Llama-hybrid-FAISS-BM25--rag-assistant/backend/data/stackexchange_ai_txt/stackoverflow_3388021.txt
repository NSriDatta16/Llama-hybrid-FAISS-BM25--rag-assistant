[site]: stackoverflow
[post_id]: 3388021
[parent_id]: 3387895
[tags]: 
I have done the something similar to fetch info from a website. I cannot give you a exact answer. But the idea is to send login info to the page with form values. If the site is relying on cookies, you can use this cookie aware WebClient: public class CookieAwareWebClient : WebClient { private CookieContainer cookieContainer = new CookieContainer(); protected override WebRequest GetWebRequest(Uri address) { WebRequest request = base.GetWebRequest(address); if (request is HttpWebRequest) { (request as HttpWebRequest).CookieContainer = cookieContainer; } return request; } } You should be aware that some sites rely on a session id being passed so the first thing I did was to fetch the session id from the page: var client = new CookieAwareWebClient(); client.Encoding = Encoding.UTF8; var indexHtml = client.DownloadString(*index page url*); string sessionID = fetchSessionID(indexHtml); Then I had to log in to the page which you can do by uploading values to the page. You can see the specific form elements with "view source" but you have to know a little HTML to do so. var values = new NameValueCollection(); values.Add("sessionid", sessionID); //Fetched session id values.Add("brugerid", args[0]); //Username in my case values.Add("adgangskode", args[1]); //Password in my case values.Add("login", "Login"); //The login button //Logging in client.UploadValues(*url to login*, values); //If all goes perfect, I'm logged in now And then I could download the page I needed. In your case you may use DownloadFile(...) if the file always have the same url (something like Export.aspx?From=2010-10-10&To=2010-11-11) or UploadValues(...) where you specify the values as before but saves the result. string html = client.DownloadString(*url*); It seems you have a lot more steps than I did. But the principle is the same. To see what values your send to the site to login etc. you can use programs such as Fiddler (windows) which can capture the activity going on. Essential you just do exactly the same thing but watch out for session id etc. which is temporary. The best idea is really to use some native way to fetch data, but if don't got the code, database etc. you have to do it the ugly way. You may also need a HTML parser to fetch the data ( ups, you don't because you export to a file ). And last but not least, keep in mind that pages can change and there is great potential to fail to login, parse etc. Please ask for if you are uncertain what is going on. ADDITION The CookieAwareWebClient is not my code: http://code.google.com/p/gardens/source/browse/Montrics/Physical.MyPyramid/CookieAwareWebClient.cs?r=26 Using CookieContainer with WebClient class I also found some relevant threads: What's a good tool to screen-scrape with Javascript support? http://forums.asp.net/t/1475637.aspx
