[site]: datascience
[post_id]: 28757
[parent_id]: 
[tags]: 
two autoencdoers learned by two similar vectors (each one with its own). Similarity of hidden layer vectors will be the same?

If I will train one autoencoder with one vector only and a second autoencoder with a second vector only, does it mean if vectors were similar, that the hidden layer vectors of both autoencoders will be similar as well? Autoencoder structure is identical. The quantity of hidden layer neurons is smaller than input. So I want to reduce dimensionality. I understand that it will be overfitting. But for me, it looks like you do not learn features but just mimic your input function with the smaller dimensional vector while losing information. So you receive a kind of low dimensional approximation of the learned vector. So if vector V1 was similar to V2 and I will use V1 to train Autoencoder A1 and V2 to train Autoencoder A2, does it mean that the hidden layer vector of A1 and hidden Layer vector of A2 won't be that similar like V1 and V2 but still approximately quite similar?
