[site]: crossvalidated
[post_id]: 391291
[parent_id]: 391222
[tags]: 
This has way too many questions, enough to write a whole manuscript, you need to do more research. I will only give you some basic information: Two options: dimensionality reduction (PCA, FA, ...) or feature selection, I would recommend the second approach, since it is much easier to interpret and comes built-in some models Gower distance should be fine, it can be used in all clustering algorithms, not just hierarchical Elbow method or GAP statistic is fine Normalization, if done, would be done before Gower, standardization is fine normalization -> feature selection -> gower -> clustering -> number of clusters Regression after clustering does not make sense. Also, there is a clustering algorithm that was made with exactly high-dimensional data in mind, PAM (Partitioning Around Medoids or Nearest Shrunken Centroids), which performs a lot of these steps for you. Have a look at the pamr package.
