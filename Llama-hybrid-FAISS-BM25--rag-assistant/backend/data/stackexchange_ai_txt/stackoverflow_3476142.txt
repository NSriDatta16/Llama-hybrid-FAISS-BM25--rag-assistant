[site]: stackoverflow
[post_id]: 3476142
[parent_id]: 3476031
[tags]: 
I can give you two answers, but they're not practical. In real life you'll use a loop to read the bytes. Valid answer 1 public byte[] readWithNoLoop(InputStream in, int size) { byte[] result = new byte[16777216]; // 16 MByte byte b = 0; if ((b = in.read()) >= 0) result[0] = b; if ((b = in.read()) >= 0) result[1] = b; if ((b = in.read()) >= 0) result[2] = b; // ... if ((b = in.read()) >= 0) result[16777215] = b; return b; } Valid answer 2 use a massive parallel systems that can read the file in parallel. You need 16777216 processing units and a supporting file storage system but you can read in O(1) (theoretically). If you encounter massive perfomance problems while reading the file, check if you use a BufferedInputStream, reading bytes from a 'normal' stream kills performance. ( Example ) If it still doesn't help, then have a look at the java.nio classes. They can map files to memory. The Grep example should give you a direction.
