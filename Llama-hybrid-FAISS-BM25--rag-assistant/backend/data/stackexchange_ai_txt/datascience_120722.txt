[site]: datascience
[post_id]: 120722
[parent_id]: 73193
[tags]: 
Try lazy regressor, it easily gives the performance of a number of different regressor models: https://pypi.org/project/lazypredict/ from lazypredict.Supervised import LazyRegressor from sklearn import datasets from sklearn.utils import shuffle import numpy as np boston = datasets.load_boston() X, y = shuffle(boston.data, boston.target, random_state=13) X = X.astype(np.float32) offset = int(X.shape[0] * 0.9) X_train, y_train = X[:offset], y[:offset] X_test, y_test = X[offset:], y[offset:] reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None) models, predictions = reg.fit(X_train, X_test, y_train, y_test) print(models) | Model | Adjusted R-Squared | R-Squared | RMSE | Time Taken | |:------------------------------|-------------------:|----------:|------:|-----------:| | SVR | 0.83 | 0.88 | 2.62 | 0.01 | | BaggingRegressor | 0.83 | 0.88 | 2.63 | 0.03 | | NuSVR | 0.82 | 0.86 | 2.76 | 0.03 | | RandomForestRegressor | 0.81 | 0.86 | 2.78 | 0.21 | | XGBRegressor | 0.81 | 0.86 | 2.79 | 0.06 | | GradientBoostingRegressor | 0.81 | 0.86 | 2.84 | 0.11 | | ExtraTreesRegressor | 0.79 | 0.84 | 2.98 | 0.12 | | AdaBoostRegressor | 0.78 | 0.83 | 3.04 | 0.07 | | HistGradientBoostingRegressor | 0.77 | 0.83 | 3.06 | 0.17 | | PoissonRegressor | 0.77 | 0.83 | 3.11 | 0.01 | | LGBMRegressor | 0.77 | 0.83 | 3.11 | 0.07 | | KNeighborsRegressor | 0.77 | 0.83 | 3.12 | 0.01 | | DecisionTreeRegressor | 0.65 | 0.74 | 3.79 | 0.01 | | MLPRegressor | 0.65 | 0.74 | 3.80 | 1.63 | | HuberRegressor | 0.64 | 0.74 | 3.84 | 0.01 | | GammaRegressor | 0.64 | 0.73 | 3.88 | 0.01 | | LinearSVR | 0.62 | 0.72 | 3.96 | 0.01 | | RidgeCV | 0.62 | 0.72 | 3.97 | 0.01 | | BayesianRidge | 0.62 | 0.72 | 3.97 | 0.01 | | Ridge | 0.62 | 0.72 | 3.97 | 0.01 | | TransformedTargetRegressor | 0.62 | 0.72 | 3.97 | 0.01 | | LinearRegression | 0.62 | 0.72 | 3.97 | 0.01 | | ElasticNetCV | 0.62 | 0.72 | 3.98 | 0.04 | | LassoCV | 0.62 | 0.72 | 3.98 | 0.06 | | LassoLarsIC | 0.62 | 0.72 | 3.98 | 0.01 | | LassoLarsCV | 0.62 | 0.72 | 3.98 | 0.02 | | Lars | 0.61 | 0.72 | 3.99 | 0.01 | | LarsCV | 0.61 | 0.71 | 4.02 | 0.04 | | SGDRegressor | 0.60 | 0.70 | 4.07 | 0.01 | | TweedieRegressor | 0.59 | 0.70 | 4.12 | 0.01 | | GeneralizedLinearRegressor | 0.59 | 0.70 | 4.12 | 0.01 | | ElasticNet | 0.58 | 0.69 | 4.16 | 0.01 | | Lasso | 0.54 | 0.66 | 4.35 | 0.02 | | RANSACRegressor | 0.53 | 0.65 | 4.41 | 0.04 | | OrthogonalMatchingPursuitCV | 0.45 | 0.59 | 4.78 | 0.02 | | PassiveAggressiveRegressor | 0.37 | 0.54 | 5.09 | 0.01 | | GaussianProcessRegressor | 0.23 | 0.43 | 5.65 | 0.03 | | OrthogonalMatchingPursuit | 0.16 | 0.38 | 5.89 | 0.01 | | ExtraTreeRegressor | 0.08 | 0.32 | 6.17 | 0.01 | | DummyRegressor | -0.38 | -0.02 | 7.56 | 0.01 | | LassoLars | -0.38 | -0.02 | 7.56 | 0.01 | | KernelRidge | -11.50 | -8.25 | 22.74 | 0.01 | ```
