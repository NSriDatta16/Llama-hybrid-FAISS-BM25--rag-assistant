[site]: crossvalidated
[post_id]: 543320
[parent_id]: 542172
[tags]: 
This approach does work, to a degree, in low-dimensional $\mathbb{R}^n$ spaces, certainly in $\mathbb{R}^2$ and $\mathbb{R}^3$ . A $k$ -d tree is basically a data structure for ordering points along a space-filling curve. The common reason why/when tree-based techniques work is because they turn a decision among $\mathcal{O}(m)$ choices into a sequence of $\mathcal{O}(\log m)$ decisions among $\mathcal{O}(n)$ choices. That's useful as long as $n\ll m$ , but it becomes utterly counterproductive when $n$ is similar or bigger than $m$ . Oftentimes, the spaces for which the curse of dimensionality applies are not just high-dimensional, but conceptually infinite -dimensional, which makes a direct space-filling approach hopeless. Nevertheless, I wouldn't say it's completely futile to work in that direction, because even in such problems the data is in reality often confined to a finite-, perhaps even low-dimensional submanifold, and subdividing only that manifold in $k$ -d fashion might well have its merits. The real problem is finding that manifold in the first place; that's what dimensionality reduction is all about.
