[site]: crossvalidated
[post_id]: 5442
[parent_id]: 1995
[tags]: 
Here's an example where a multilevel model might be "essential." Suppose you want to rate the "quality" of the education provided by a set of schools using students' test scores. One way to define school quality is in terms of average test performance after taking student characteristics into account. You could conceptualized this as, $$y_{is} = \alpha_s + X_{is}'\beta_s + \epsilon_{is},$$ where $y_{is}$ is the continuous test score for student $i$ in school $s$, $X_{is}$ are student attributes centered at school means, $\beta_s$ is a school-specific coefficient on these attributes, $\alpha_s$ is a "school effect" that measures school quality, and $\epsilon_{is}$ are student level idiosyncrasies in test taking performance. Interest here focuses on estimating the $\alpha_s$'s, which measure the "added value" that the school provides to students once their attributes are accounted-for. You want to take student attributes into account, because you don't want to punish a good school that has to deal with students with certain disadvantages, therefore depressing average test scores despited the high "added value" that the school provides to its students. With the model in hand, the issue becomes one of estimation. If you have lots of schools and lots of data for each school, the nice properties of OLS (see Angrist and Pischke, Mostly Harmless... , for a current review) suggest that you would want to use that, with suitable adjustments to standard errors to account for dependencies, and using dummy variables and interactions to get at school level effects and school specific intercepts. OLS may be inefficient, but it's so transparent that it might be easier to convince skeptical audiences if you use that. But if your data are sparse in certain ways---particularly if you have few observations for some schools---you may want to impose more "structure" on the problem. You may want to "borrow strength" from the larger-sample schools to improve the noisy estimates that you would get in the small-sample schools if the estimation were done with no structure. Then, you might turn to a random effects model estimated via FGLS, or maybe an approximation to direct likelihood given a certain parametric model, or even Bayes on a parametric model. In this example, the use of a multilevel model (however we decide to fit it, ultimately) is motivated by the direct interest in the school-level intercepts. Of course, in other situations, these group level parameters may be nothing more than nuisance. Whether or not you need to adjust for them (and, therefore, still work with some kind of multilevel model) depends on whether certain conditional exogeneity assumptions hold. On that, I would recommend consulting the econometric literature on panel data methods; most insights from there carry over to general grouped data contexts.
