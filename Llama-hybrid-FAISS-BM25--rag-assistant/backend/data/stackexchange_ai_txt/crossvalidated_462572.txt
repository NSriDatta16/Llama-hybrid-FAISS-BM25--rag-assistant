[site]: crossvalidated
[post_id]: 462572
[parent_id]: 
[tags]: 
What advantages does Naive Bayes have over the "not naive" Bayes?

Repeating the question What advantage does Naive Bayes have over "not naive" Bayes? Considering the fact that the assumption about conditional independence is often violated, why do we make it? As pretty much any source on the internet states, assumption about conditional independence between features rarely holds. To make things more concrete, consider following example Define $$Y := \{\text{boys}\}$$ $$X_1 := \{\text{people that have big muscles}\}$$ $$X_2 := \{\text{people that have short hair}\}$$ Then $P(X_2 \mid Y \cap X_1) = \frac{1}{2}$ but $P(X_2 \mid Y ) = \frac{2}{3}$ , implying that $X_1$ and $X_2$ are not conditionally independent. So repeating the question : Why do we assume conditional independence when using Bayesian classifier? What advantages does Naive Bayes have over the "not naive" Bayes (i.e algorithm that doesn't assume cond. independence)?
