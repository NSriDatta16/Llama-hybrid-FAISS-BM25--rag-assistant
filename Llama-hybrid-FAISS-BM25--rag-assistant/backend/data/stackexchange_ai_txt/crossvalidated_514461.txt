[site]: crossvalidated
[post_id]: 514461
[parent_id]: 
[tags]: 
When will $\text{Variance}=\text{Bias}^2$ hold for the optimal model?

Let us consider the bias-variance decomposition in the context of model selection. The picture below suggests the optimal model (the one minimizing the expected squared prediction error) will have $\text{Variance}=\text{Bias}^2$ . This looks like a very special case, as corresponding diagrams in machine learning textbooks are often asymmetric. See e.g. James et al. "Introduction to Statistical Learning" Figure 2.12: I think the curious result of the initial picture rests on the curves of variance and squared bias being convex and rather symmetric. The convexity is probably sensible, but I am not so sure about the approximate symmetry. Question: What are some concrete settings (model classes and data generating processes) in which $\text{Variance}=\text{Bias}^2$ could be expected to hold (at least approximately) for the optimal model? P.S. There is no need to address the question of whether the initial picture must hold in general, as that may lead this thread off track. The answer is clearly negative, as indicated above and in Stephen Kolassa's answer.
