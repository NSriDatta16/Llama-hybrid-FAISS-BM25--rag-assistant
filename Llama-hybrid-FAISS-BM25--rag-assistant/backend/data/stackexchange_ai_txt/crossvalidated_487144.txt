[site]: crossvalidated
[post_id]: 487144
[parent_id]: 
[tags]: 
AB testing - normalizing for a group's historic performance? Bayes Factors?

If you split traffic on a website in order to conduct an AB test, optimizing/ monitoring conversion, and you split users by evens/ odds, and have the following information before the test is conducted: group total_recs n_success conversion_rate control 1091653 162424 0.148787 treatment 1098513 153955 0.140149 where the control group has a 6.16% relative improved conversion rate over the treatment group for > 1,000,000 samples (even though this is relatively unlikely, since there's no reason odd id users would convert more than evens etc..) If we then run an AB test for 2 weeks and obtain the following results: group total_recs n_success conversion_rate control 46812 7198 0.153764 treatment 47128 7294 0.154770 where the treatment group shows a relative improvment of 0.65%, intuitively, this suggests that the treatment is an improvement. Assume that the null cannot be rejected, and that for whatever reason, no more data can be collected. Is there some way to adjust for this? I.e. normalize current results based on historic evidence? And if so, how can you do this? Additionally; is this something that actually makes sense to do? Instead, if you were to use a Bayesian approach for model comparison, and incorporate MCMC sampling to generate posterior probabilities, how can the Bayes Factors be calculated from the posterior probabilities? Cheers, Appreciate responses!
