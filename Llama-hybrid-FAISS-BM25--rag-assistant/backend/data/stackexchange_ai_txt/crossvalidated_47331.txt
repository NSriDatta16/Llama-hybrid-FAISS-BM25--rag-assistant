[site]: crossvalidated
[post_id]: 47331
[parent_id]: 
[tags]: 
The coefficient of determination , usually symbolized by $R^2$, is the proportion of the total response variance explained by a regression model. In the case of simple linear regression it is the square of the Pearson product-moment correlation coefficient between the predictor and response variables. It is equivalently calculated as: $$ R^2 = \frac{SS_{\rm total} - SS_{\rm resid}}{SS_{\rm total}} $$ $R^2$ tends to increase (i.e., look better) when variables are added to a multiple regression model, even if those variables are irrelevant. To counteract this, an adjusted $R^2$ statistic has been developed: $$ R^2_\text{adj} = 1-(1-R^2)\frac{N-1}{N-p-1} $$ $R^2$ in the form given above is appropriate for models with normally distributed errors. It is not appropriate for other models, such as logistic regression. A variety of ' pseudo-$R^2$ ' statistics have been developed to provide similar information outside the context of linear models.
