[site]: datascience
[post_id]: 121202
[parent_id]: 
[tags]: 
Question about GPT-2 causal masking for downstream tuning

I'm currently finetuning a pre-trained GPT-2 model for image captioning. Using a ViT for image encoding, the output embeddings are then fed into the GPT-2 model (from HuggingFace) as inputs_embeds , concatenated with a token and the caption. The input is like this: [img_features]...[img_features] [caption_embeds]...[caption_embeds] My question is, is the input_embeds part masked by a casual mask during the forward process? If so, can this part be separately masked (no mask) aside from the caption inputs? Thanks for any advice/comments/discussion!
