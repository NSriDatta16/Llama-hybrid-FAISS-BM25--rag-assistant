[site]: datascience
[post_id]: 118388
[parent_id]: 118385
[tags]: 
firstly welcome to Data Science Stack Exchange. In terms of question as to whether to perform minority oversampling before collapsing the number of classes or after: good question. By oversampling before, you will ensure that, in the context of the nine classes, that each class is balanced. Then by collapsing them into 2 classes, we might bring about class imbalance again. Therefore, my overall suggestion would be to collapse first into the 2 classes and then perform minority oversampling over the data, such that the class with the fewest number of examples obtains more artificial examples to be equal the number of the majority class.
