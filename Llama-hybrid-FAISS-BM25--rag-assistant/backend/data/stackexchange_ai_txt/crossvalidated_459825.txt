[site]: crossvalidated
[post_id]: 459825
[parent_id]: 
[tags]: 
Using (summaries of) multiple time series as the independent variable in a regression

I am faced with quite a challenge. I would like to run a regression to see if variable X can predict variable Y. Variable Y (DV) is continuous (0-100) and I have 120 data points, so it's all simple here. Variable X (IV), however, is trickier. Each of the 120 data points of X is actually a time series. Of course, I could just get the (weighted) average of each of the time series and use those values as the IV. The problem here is that, I suspect, the trends in the time series of X have an impact on Y, so a lot of potentially very insightful data would be lost if I were to simply use the average values of the time series. Does anyone know of an analysis that could account for the trends in the time series? Or perhaps there is a smart way of summarizing a time series into a single value? I've also considered building a machine learning model and see if I can predict Y better than chance based on the time series values of X. That could perhaps serve as some kind of indicator of the relationship between the variables, if they exist. But it'd be great if there was a more 'statistical' approach. I'd really appreciate any input you have! Vlad
