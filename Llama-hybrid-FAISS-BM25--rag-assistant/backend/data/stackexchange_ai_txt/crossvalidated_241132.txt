[site]: crossvalidated
[post_id]: 241132
[parent_id]: 241111
[tags]: 
You could simply try both approaches and see if re-balancing helps. Adjusting the cutoff is probably a good idea as well. It would be better to completely reshuffle your training and test set every time you change something to the algorithm. Also, if you want to have statistically significant comparisons, you need an experimental setup that produces multiple sample points. On the other hand, logistic regression with its hyperplane separation doesn't have a high risk of overfitting. It can't come up with non-linear separation surfaces. So this rigorous approach is less crucial here than with neural nets for example.
