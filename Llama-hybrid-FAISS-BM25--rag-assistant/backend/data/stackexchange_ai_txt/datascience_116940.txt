[site]: datascience
[post_id]: 116940
[parent_id]: 116928
[tags]: 
I assume you are using a seq2seq transformer like T5. And the input -> output is probably defined as -> question: ..., answer: ... . Since you do not have any ground truth, I would use another model, a Gold Standard/SOTA if you may, in Question Answering, where its input -> output is question:... , context:... -> . Hence, I would use the answers of your LLM and evaluate it against the Gold standard where I would use a BLEU score (or something else for text generation) between the answer of your LLM and the answer of the QA Gold Standard. Of course, in the limitations you should acknowledge the fact that this evaluation is not ideal, since you do not have ground truth. Or maybe you could try using a few QA models and average. You should be careful with the hyper-parameters. Imagine one's sequence output length is less than the other.
