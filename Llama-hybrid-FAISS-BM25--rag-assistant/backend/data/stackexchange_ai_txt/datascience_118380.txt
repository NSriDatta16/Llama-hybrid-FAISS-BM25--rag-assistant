[site]: datascience
[post_id]: 118380
[parent_id]: 
[tags]: 
Visualizing convolutional neural networks embedding

In this article , the author creates a graph (at the end of the post) from the embeddings of different words found by transformer model. I would like to do a similar thing for a convolutional neural network in order to be able to evaluate clusters. The final objective is to be able to identify similar images in the train set to a given image. I thought about extracting the hidden representation created by one of the hidden layers and reduce the dimensions to 2 using something like PCA. I have some doubts: Is this strategy sound? Which layer should I use? Should I use the last one, as when creating a Global Class Activation map?
