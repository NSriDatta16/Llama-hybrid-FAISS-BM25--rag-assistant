[site]: crossvalidated
[post_id]: 148928
[parent_id]: 
[tags]: 
Given two absorbing Markov chains, what is the probability that one will terminate before the other?

I have two different Markov chains, each with one absorbing state and a known starting position. I want to determine the probability that chain 1 will reach an absorbing state in fewer steps than chain 2. I think I can calculate the probability of reaching an absorbing state in a particular chain after n steps: given a transition matrix $P$ the probability of being absorbed after $n$ steps is $P^n_{ij}$ where $i$ is the starting state and $j$ is the absorbing state. I'm not certain where to go from here though. Analogous problems I've seen involve dice (e.g., rolling a sum of 7 before a sum of 8), but that is easier to solve because the probability of rolling a particular sum is constant and independent of the number of steps taken so far.
