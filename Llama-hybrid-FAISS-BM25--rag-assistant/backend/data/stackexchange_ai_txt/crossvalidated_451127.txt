[site]: crossvalidated
[post_id]: 451127
[parent_id]: 
[tags]: 
Equivalence of Deep Feed-Forward Neural Network to Single-Layer Network

I am new to Deep Learning, and I was going through some lecture notes I found online. It said that a feed-forward neural network with $n$ hidden layers and only linear activation functions is equivalent to a linearly activated neural network with no hidden layers. I am having some trouble proving this assertion.
