[site]: crossvalidated
[post_id]: 232504
[parent_id]: 
[tags]: 
Struggling to understand threshold(b) update step in SMO

Currently reading Platt's paper, Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines , I got stuck in section 2.3 Computing the Threshold : SVM notation objective function: \begin{array}{1} \max _{\alpha }\sum _{i=1}^{n}\alpha _{i}-{\frac {1}{2}}\sum _{i=1}^{n}\sum _{j=1}^{n}y_{i}y_{j}K_{ij}\alpha _{i}\alpha _{j}\\ 0\leqslant \alpha_i \leqslant C : Lagrange multipliers\\ \sum_{i=1}^Nyi\alpha_i=0\\ \end{array} KKT condition: \begin{array}{l} \quad {a_i} = 0 \quad \Leftrightarrow \quad {y_i}u_i \ge 1\\ 0 $b$: threshold in SVM model $w^Tx-b$ $u_i=\sum_{j=1}^Ny_j\alpha_jK_{ij}-b$: predict value using SVM $E_i=u_i-y_i$: difference between target and prediction $K_{ij}=K(x_i, x_j)=K(x_j,x_i)$: the kernel matrix Brief description about SMO According to Platt, SMO optimize two Lagrange multipliers one time, for example: $y_1\alpha_1+y_2\alpha_2=-\sum_{i=3}^Ny_i\alpha_i=Const$ ... Update $\alpha_i$ ... The question if $\alpha_i$ is not at bound, threshold $b$ can be computed by forcing the output to be $y_i$: $b_i=E_i+y_i(\alpha^{new}_1-\alpha_1)K_{11}+y_2(\alpha_2^{new,clipped}-\alpha_2)K_{12}+b^{old}$ (eq.1) if both $\alpha_1$ and $\alpha_2$ are at bound, then using eq.1 computing $b_1$ and $b_2$, all thresholds between $b_1$ and $b_2$ are consistent with KKT conditions. I understand case 1 since $0
