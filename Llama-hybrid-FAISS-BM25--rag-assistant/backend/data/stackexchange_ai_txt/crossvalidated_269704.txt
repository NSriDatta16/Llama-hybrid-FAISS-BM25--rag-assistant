[site]: crossvalidated
[post_id]: 269704
[parent_id]: 
[tags]: 
Embedding Phrase using Recurrent Neural Network

I am trying to get a word2vec embedding of a given phrase using an LSTM RNN encoder. For example, "How are you?" => [some word2vec representation] I have pretrained model of word2vec(i already wrote an implementation for this) which gives me the word2vec of words but I am not sure how to get the word2vec given a phrase(which is a sequence) using a lstm encoder. I am trying to use TensorFlow(in Python) to do this. Lets say I have the word2vecs of each word in the phrase how do i find the word2vec of the entire phrase using an lstm encoder(in TensorFlow with Python)?
