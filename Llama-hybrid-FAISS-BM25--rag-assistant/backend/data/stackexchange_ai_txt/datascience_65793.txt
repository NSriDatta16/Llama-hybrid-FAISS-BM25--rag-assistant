[site]: datascience
[post_id]: 65793
[parent_id]: 
[tags]: 
Facial recognition architecture

Image recognition uses deep learning, and in particular CNNs to train on and recognise faces. Usually, this entails training on lots of data. However, recently, we have seen face recognition being deployed everywhere, and being used for passport control, for example, and some airlines have deployed in lieu of boarding pass scanners. How is this accomplished? How can they achieve such accuracy without having hundreds of pictures of everyone? How can, for example, governments, with a quick scan of my face, recognise me and identify my name and identity without having any picture of me besides the ones available from my official ids? There is a link here which, however, does not really explain it technically. Is it done using neural nets? What is their architecture. Are there papers describing it (technically) anywhere?
