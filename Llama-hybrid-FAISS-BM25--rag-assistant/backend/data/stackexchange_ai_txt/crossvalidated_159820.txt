[site]: crossvalidated
[post_id]: 159820
[parent_id]: 
[tags]: 
Distance between Vectors with Confidence Intervals

I have a machine learning application where I extract numerical features $a_{i1}, a_{i2}, \dots, a_{ik}$ for each object $a_i$ to study. Objects are then compared using standard euclidean distance. The problem is that the features entail uncertainty. The good message is that I have confidence intervals, meaning that I can tell with probability $\alpha$ that $a_{ij}-c_{ij} \le a_{ij} \le a_{ij}+c_{ij}$. Since these confidence intervals are independent of each other, I end up with k-dimensional boxes instead of k-dimensional points (see below). My question is whether there's a standard approach to extend euclidean distance to account for uncertainty. The right way to go is probably using standard euclidean distance, and deriving new confidence intervals for that distance. Maybe it wouldn't even be too hard to derive them, but I'm also interested in a paper that I could cite.
