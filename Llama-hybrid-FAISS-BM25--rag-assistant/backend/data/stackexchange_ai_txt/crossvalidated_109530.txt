[site]: crossvalidated
[post_id]: 109530
[parent_id]: 108417
[tags]: 
Below are my responses: You could do K fold cross validation/ leave one out cross validation as follows for time series regression: if you have 100 time series observation, first determine how many minimum# of observation is required to build your model. Lets say you need at least observations 1 to 50 to build your model. Build a model on the first 50 observations. Test your model on the next n (say 10 observations). Now rebuild the model on the 50 + 10 (n) = 60 time ordered data. Test the model on 61 to 70 observations. Repeat the steps 1 to 3 by increment the training dataset by 10 data points. If you did this and calculate the prediction error you would have done the k (5) fold validation of your model. It is very important to note that the data should be time ordered and should not be shuffled or selected randomly. In the example above, observation 1 would be your earliest time data, while your 100th observation would be your last data point, sorted in an ascending order so that your lag structure in the model is not disturbed. A variation of the above approach would be, if you only want 50 observations in your training data to build model, you need to drop the first 10 observation as you keep adding l0 observations at last, as an example: Step 1: Train on 1 to 50 observations, test on 51 to 60. Step 2: Train on 11 to 60, test on 61 to 70. .... and so on, This could be easily expanded to leave one out cross validation. Here is the problem you might face, while you have nicely arranged the train and test sets, machine learning methods, randomly shuffle the data to build models. Example, random forest will not care if it is time ordered or not. it will randomly shuffle the dataset to build models. At the end it doesn't matter if you use a time series cross validation or a regular cross validation, as long as your residuals of the model is not correlated. In your case I think it will not be autocorrelated unless if you have different time periods for a single city in you dependent variable as an example: $valueA_t = valueB-1 + valueB-2 + valueB-3 + valueB-4 + valueC-1 + valueC-2 + valueC-3 + valueC-4$ where $t = time$ The key is suffix $t$ in your dependent variable. If you have time dependency in your dependent variable the you have to do a time series cross validation. But based on your problem statement, your are NOT doing a time series regression, since your dependent variable doesn't have time dependency/serial dependance on previous observation i.e obs 2 (time 1) is dependent on obs 1 (time 2), and they are independent of each other, so you should be fine using a regular cross validation. See the following link on how to do proper cross validation for time series data for forecasting. http://robjhyndman.com/hyndsight/tscvexample/ In case you are in fact doing a time series regression, then I would be using tradition statistical based time series models such as ARIMAX models or regression with arima errors because, machine learning methods are notoroiusly know to perform extremely poorly on time series data and there is no known empirical evidence that using random forest/neural network is known to improve prediction. As shown in the neural network forecasting competition, statistical time series methods significantly out performed neural networks. http://www.neural-forecasting-competition.com/NN3/results.htm Again in your case, I dont think you are doing a time series regression, so you should be fine using machine learning methods.
