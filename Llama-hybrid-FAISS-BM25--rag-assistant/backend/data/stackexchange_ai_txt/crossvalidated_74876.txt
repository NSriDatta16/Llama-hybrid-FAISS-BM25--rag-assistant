[site]: crossvalidated
[post_id]: 74876
[parent_id]: 8729
[tags]: 
As CHL has already explained the use of center and scale to obtain standardized variables, I'll address collinearity: There is good reason to reduce collinear variables when clustering. Curse of Dimensionality The more dimensions you use, the more likely you are to fall victim of Bellman's 'curse of dimensionality' . In brief, the greater the number of dimensions, the greater the total volume, and the greater the sparsity of your data within it. (See the link for more detail.) Dimension Reduction --- manually by inspecting of pairwise collinearity... You mention that you have already reduced variables from some larger number down to 5 using pairwise collinearity measures. While this will work, it is quite tedious, since in general you will have $n\choose 2$ number of pairs to check. (So for example with 10 variables, you would have ${10 \choose 2} = 45$ different pairs to examine -- a few too many to do manually in my opinion! Dimension Reduction --- automatically using Principal Components Analysis (PCA)... One way to handle this automatically is to use the PCA (principle components analysis) algorithm . The concept is more or less what you're doing manually -- ranking the variables by how much unique information each variable is contributing. So you provide PCA your $n$-variable dataset as input, and PCA will rank order your variables according to the greatest variance each explains in the data -- essentially picking out the non-collinear variables. Depending on whether you want 2-D or 3-D clusters, you would use the top 2 or 3 variables from PCA. Principal Components in R The PCA algorithm is available (built-in) from R. Actually there are several functions in R that do principal components. I've had success with prcomp() . Standard Reference available free online One of the best references available is the classic: Elements of Statistical Learning , by Trevor Hastie, Robert Tibshirani, and Jermoe Friedman The authors have graciously made the entire book available (for free) as a PDF download from their Stanford website. There are excellent chapters on Clustering, Principal Comoonents, and a great section on the curse of dimensionality.
