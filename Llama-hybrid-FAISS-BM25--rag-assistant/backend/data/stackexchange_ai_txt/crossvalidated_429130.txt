[site]: crossvalidated
[post_id]: 429130
[parent_id]: 
[tags]: 
Expressing one-sided p values of directional hypothesis tests as Bayes factors

Assume we want to test the directional hypothesis that $µ . From a frequentist angle we use a one-tailed $t$ -test and imagine we obtain a 1-sided $p$ value of say 0.07, which then would imply that our mean is not significantly smaller than 0 at the 0.05 level (some might still refer to it as "marginally significant"). Now I was reading the paper "Three Insights from a Bayesian Interpretation of the One-Sided P Value" by Marsman & Wagenmakers (2017), which notes that one-sided $p$ values of 1-tailed tests (i.e. of directional tests) can readily be converted to Bayes factors $K$ of a Bayesian test for direction under a symmetric prior around $µ$ based on the formula $K = (1-p)/p$ In this example, this would give us a Bayes Factor $K$ of $µ$ being = 0 of (1-0.07)/0.07 = 13, which would imply that there would be 13 times more support for $µ$ being $µ$ being >= 0. Following Jeffreys (1998) as well as Kass and Raftery (1995), this would be regarded as "strong evidence" for there being a negative effect as opposed to a positive one as this $K > 10$ . In fact their cutoff for a strong effect $(K=10)$ would then correspond with a one-sided $p$ value of 1/11 = 0.09. Decisive evidence they consider to correspond to $K > 100$ , which would then imply a one-sided $p$ value of 1/101 = 0.001. Am I correct stating this, and does it illustrate the arbitrariness and lack of concordance of such proposed cutoffs in the frequentist and Bayesian literature? That is, in this case implying a nonsignificant result from a frequentist angle, but a strong effect from a Bayesian one (under a noninformative prior, which I would be happy with in the context of my analysis)? I was a little surprised by the lower bar that Bayesians would put on inferring a strong effect than frequentists, given that I've also regularly seen the argument that $p$ values around 0.05 would correspond to quite modest Bayes factors, and that the $p$ value cutoff for significance should therefore be taken as more stringent than 0.05. For example, in this paper, "Evidence From Marginally Significant t Statistics" (Johnson 2019). Am I correct that this difference in conclusion is due to the fact that Marsman & Wagenmakers (2017) consider directional tests (H0: effect in one direction, Ha: no effect or effect in the opposite direction), whereas Johnson (2019) consider tests for the existence of an effect (H0: there is no effect, Ha: there is an effect)? [This is what I gathered based on my reading of Held & Ott, 2018, "On p-Values and Bayes Factors" at least] I was also wondering, given that maximum likelihood estimates coincide with the MAP estimate in a Bayesian analysis under a non-informative prior (and that Bayesian 95% credible intervals are numerically very close to 95% MLE confidence intervals derived under a non-informative prior ), whether $p$ values deriving from maximum likelihood analyses (and most frequentist tests can be stated in MLE terms) can not always be restated as Bayes factors derived under a non-informative prior? If so, is MLE then not merely a special case of Bayesian analysis, and what's the big deal of pitting those two school of thoughts against each other (aside from their choice of a different prior, which in MLE is taken as non-informative based on the lack of information you have about this, and in Bayesian analysis can be specified in a somewhat more subjective way, taking into account your subjective beliefs)?
