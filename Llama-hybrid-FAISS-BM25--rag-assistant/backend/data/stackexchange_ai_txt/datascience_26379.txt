[site]: datascience
[post_id]: 26379
[parent_id]: 26377
[tags]: 
I think second job will benefit more from spark than the first one. The reason is machine learning and predictive models often run multiple iterations on data. As you have mentioned, spark is able to keep data in memory between two iterations while Hadoop MapReduce has to write and read data to file system. Here is a good comparison of the two frameworks : https://www.edureka.co/blog/apache-spark-vs-hadoop-mapreduce
