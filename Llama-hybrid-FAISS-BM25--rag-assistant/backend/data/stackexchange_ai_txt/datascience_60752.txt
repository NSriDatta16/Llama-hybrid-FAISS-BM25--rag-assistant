[site]: datascience
[post_id]: 60752
[parent_id]: 60744
[tags]: 
I don't know the method you're using but I suspect that what you observe here is a common problem with supervised learning: models tend to favour predictions close to the mean, that is avoid extreme predictions because these are usually more risky (higher loss if it's a mistake). As a consequence the std deviation of the predictions is often significantly smaller than the s.d. of the ground truth. Afaik there's no perfect solution. Typically you could try to encourage risky predictions a bit more in the loss function, if that's an option with your method. But in most applications it's safer to learn to live with this issue.
