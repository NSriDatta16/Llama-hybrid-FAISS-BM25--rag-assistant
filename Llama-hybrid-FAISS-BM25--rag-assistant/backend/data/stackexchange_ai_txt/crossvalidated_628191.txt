[site]: crossvalidated
[post_id]: 628191
[parent_id]: 628189
[tags]: 
The idea of ​​a “true equivalence test” is somewhat paradoxical. In statistical hypothesis testing (in the frequentest paradigm), it is important to understand that we never "accept" a null hypothesis; we only "fail to reject" it. Regarding equivalency testing, the objective is to demonstrate that there is no meaningful difference between groups. This is inherently difficult because proving a negative (i.e., proving something does not exist) is a challenging proposition in statistics. To declare definitively that two treatments are equivalent would require considering all possible sources of variation and all possible patients requiring an infinite sample size. Any test performed on finite samples can only limit differences between groups to a certain extent and can never completely eliminate the possibility that differences exist. Instead of testing for true equivalency, what is often done in practice is a non-inferiority test. Here, the goal is to demonstrate that a new treatment (or drug) is not worse than an existing treatment by more than a pre-specified margin, $ \Delta $ . This is a more achievable goal with finite samples. The hypotheses for such a test are typically: $ H_0: \mu_1 - \mu_2 \leq -\Delta $ (i.e., Drug 1 is inferior by at least $ \Delta $ ) $ H_a: \mu_1 - \mu_2 > -\Delta $ In the context of assessing similarity between treatments, a Bayesian approach would involve defining a "similarity region" which delineates the range of differences between treatments that are deemed to be practically equivalent. Then, using prior information and the collected data, one computes the posterior probability that the true, but unknown, treatment effect lies within this similarity region. A high posterior probability would suggest strong evidence for the treatments being similar, while a low probability would suggest otherwise.
