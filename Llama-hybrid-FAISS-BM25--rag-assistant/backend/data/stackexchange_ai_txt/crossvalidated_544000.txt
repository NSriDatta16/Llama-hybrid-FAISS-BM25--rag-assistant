[site]: crossvalidated
[post_id]: 544000
[parent_id]: 543994
[tags]: 
Should predicting on your training set always throw out a very a high accuracy? Or would that indicate overfitting? No, not always. The reason some models perform better than others is due to the bias/variance tradeoff. Logistic regression is a linear model, and hence is high bias. A random forest is capable of learning non-linear effects (low boas) of variables, but this comes at the cost of more variance. This increase in accuracy is likely due to the lower bias of random forests. Can I learn something from these stated measures? Not particularly, the training error is a poor measure of performance since you're testing on things the algorithm has already seen. The model has to fit the data as best as possible, so the training error is ultimately uninformative as to future performance. If the model generalises well should the accuracy of predicting on training set and test set, be roughly the same? Maybe . Models can generalize well and still be slightly overfit.
