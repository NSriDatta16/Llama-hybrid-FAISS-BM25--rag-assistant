[site]: crossvalidated
[post_id]: 560452
[parent_id]: 560437
[tags]: 
First of all, not only neural networks are universal approximators . There is nothing special about them, they just proved to work quite well for a class of problems. Kernel based methods generally don't scale well. Neural networks gained popularity in the time when we (a) improved our computers, so we were able to run bigger neural networks and do this in reasonable time, (b) with Internet, we gained access to large amounts of data (images, text) to train them. Kernel methods don't scale for large datasets, while in many cases it is the data not the algorithms that lead to improvements ( Halevy, Norvig, and Pereira, 2009 ). Neural networks do scale. Neural networks gained popularity because they flourished for tasks related to image classification and natural language processing, traditional machine learning, including kernel based methods, don't generally do well for such tasks. Those are also the tasks where neural networks do well today, while for example for tabular data traditional machine learning seems to be commonly used.
