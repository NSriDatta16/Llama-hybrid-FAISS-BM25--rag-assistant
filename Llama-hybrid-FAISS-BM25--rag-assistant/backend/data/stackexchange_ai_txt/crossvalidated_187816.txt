[site]: crossvalidated
[post_id]: 187816
[parent_id]: 
[tags]: 
Sufficient statistic for expectation of exponential family

True or false: Let X $\sim$ f, where f is element of an exponential family. Then, $\frac{\sum_{i=1}^n x_i}n$ is a sufficient statistic for $E(X)$ . For either case, please provide the necessary proofs / derivations. If the statement is false: Is it true for the natural exponential family? My thoughts: The Pitman-Koopman-Darmois-Theorem ensures existence of sufficient statistic $T(x)$ with ${\rm dim}(T(x)) = p$ , where $p$ equals the number of parameters. If one of those sufficient statistics is the identity, then I can use the first derivative of the log-normalizer to determine the mean as a function of parameter vector $\theta$ . Now one thing that greatly irritates me: Looking at Wikipedia, the sufficient statistics for the Gamma are $T = \left(\prod_{i=1}^n x_i, \; \sum_{i=1}^n x_i \right)$ . But in the Gamma-Poisson model in Bayesian updating, we have that $(\alpha, \beta)|x = (\sum x_i, n)$ where I neglected the hyperparameters. Especially, we have that $E(X) = \alpha/\beta = \overline{X}$ . Isn't this a contradiction? In the Bayesian setting, the sample mean plus the number of observations was sufficient for both the parameters and the expectation. On Wikipedia I am told I need the sum plus the product of all observations.
