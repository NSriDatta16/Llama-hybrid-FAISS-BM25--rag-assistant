[site]: crossvalidated
[post_id]: 270313
[parent_id]: 270187
[tags]: 
In short, C is the penalty on the slack variables, which measure the degree to which the margin constraints are violated. A training pattern violates the margin constraint if the kernel expansion (i.e. the output of the SVM) has a value between -1 and +1, and all patterns violating this constraint will be support vectors. If you increase C, a greater penalty is put on violation of the constraint, the solution will change to reduce the size of the violations (and hence the number of violations) so the margin is made narrower, and less patterns will fall inside it, so there are fewer support vectors. The expected error rate depends on both the margin and also on the sum of the slack variables, so in practice generalisation is maximised by a compromise between the two qualities, giving an intermediate value of C.
