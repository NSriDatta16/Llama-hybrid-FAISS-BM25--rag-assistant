[site]: crossvalidated
[post_id]: 191109
[parent_id]: 
[tags]: 
Ridge Regression Centering Proof

This is a ridge regression problem. The following two problems are equivalent: $(w_t, b_\lambda ) = argmin_{w,b}\{\sum_{i=1}^m (y_i-b-w^Tx_i)^2+\lambda w^Tw\} $ $(w_t, b_\lambda )= argmin_{w,b}\{\sum_{i=1}^m (y_i-b-w^T(x_i-\bar x))^2+\lambda w^Tw\} $ where: $\bar x$ is the average of the input data. $\lambda$ defines a trade-off between the error on the data and the norm of the vector $w$ (degree of regularization) I'm assuming $b$ is a bias term I can't work out why, mathematically, centering the data, has no effect. Not looking for the answer, just a push in the right direction. Intuitively, I understand that offsetting each data point will have no effect on the final $w$ vector, because the relationships between the data points remains unchanged. Showing this mathematically, however, I'm unsure.
