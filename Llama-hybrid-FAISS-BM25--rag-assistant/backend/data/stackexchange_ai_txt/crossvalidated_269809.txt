[site]: crossvalidated
[post_id]: 269809
[parent_id]: 269625
[tags]: 
I don't agree with the characterization of the distinction between machine learning and statistics. Both machine learning and statistics are about both prediction and explanation and have tools for both. Arguably machine learning is a branch of computational statistics, so the distinction between the two isn't straightforward either. As to "Why is it so hard to both predict the future and explain the present?", in my opinion it is mostly because we are only capable of understanding (relatively) simple explanations (e.g. smallish decision trees, linear models) which may not be sufficiently complex to represent the true underlying behaviour of the system being modelled. "All models are wrong, but some are useful" - one way in which they can be useful is by being simple enough that we can understand them, another is being complicated enough that they give accurate predictions. Horses for courses. Obviously there are some examples where the optimal explanatory model and the optimal predictive model coincide, e.g. classification problems where theory suggests the class conditional densities are Gaussian, a linear model will be both explanatory and likely to give good predictive performance (as it is the Bayes optimal model). However in most circumstances this won't be the case as the problem is less well constrained and model assumptions unlikely to be completely valid. "Everything should be as simple as possible, but no simpler", attributed to Albert Einstein comes to mind! BTW when seeking an explanatory model, it is often a good idea to fit a complex "machine-learning" black-box model as well, if only to get an indication of the amount the explanatory model is not explaining.
