[site]: stackoverflow
[post_id]: 3741484
[parent_id]: 3690195
[tags]: 
Your problem is called word tokenization. Take a look here: http://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html Stanford is a very famous NLP laboratory. They produces one of the most efficient parser for English. The page outlines some common tokenization problems like Unusual domain specific token: M A S*H, C++, IP address ... Hyphenation: co-education, Hewlett-Packard Collocation: San Francisco, Los Angeles Specific syntax ... Advertisements for air fares "San Francisco-Los Angeles" Omitted spaces etc... The Penn Treebank Project also provides a simple sed script for word tokenization "that does a decent enough job on most corpora" here .
