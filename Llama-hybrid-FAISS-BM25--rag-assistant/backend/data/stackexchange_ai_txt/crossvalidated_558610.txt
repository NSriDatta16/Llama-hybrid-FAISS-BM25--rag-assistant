[site]: crossvalidated
[post_id]: 558610
[parent_id]: 
[tags]: 
How does Deep Reinforcement Learning remove the need to map or explore every state, action pair for an agent?

I am interested in using Deep Reinforcement Learning to teach an AI how to play a game, where the AI knows the model of the game at the start (so I would use model-based deep reinforcement learning?) But, the number of possible states and actions combinations that can be taken is very large, and I can't map every pair out. I heard that Deep Reinforcement Learning is a solution for this very large states space, but I'm not sure how exactly the Neural Net can be trained which action to take at any (future) state, if it hasn't experienced each possible state yet. Could anyone please provide clarification on this subject?
