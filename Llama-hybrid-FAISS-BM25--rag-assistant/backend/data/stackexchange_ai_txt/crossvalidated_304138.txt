[site]: crossvalidated
[post_id]: 304138
[parent_id]: 
[tags]: 
Bayesian model comparison using cross-validation when models are functions of different variables

I'm trying to compare the predictive power of different models (in PyMC3) using Leave-One-Out Cross-Validation. Most models are in the form $y = f(x)$, but one important model is in the form $x = g(y)$. The latter does happen to fit well, but the LOO score is an order of magnitude better, which is unrealistic. I assume it is because $x \in [0, 0.5)$ while $y \in [0, 500)$, roughly, so the magnitudes of the errors of the two kinds of models differ significantly. Is it possible to use LOO-CV (or information criteria) for such a case?
