[site]: crossvalidated
[post_id]: 33000
[parent_id]: 32971
[tags]: 
It's not unusual to see, with a relatively weak model, that the correct classfication rate (CCR) does not improve, or even drops, from what it was with a null (baseline) model. A lot of authors and analysts rely on other indicators of a model's predictive power and disregard the CCR as a general policy because it oversimplifies: it turns predictive information at the level of probability for each observation (continuous, from 0 to 1) into a binary decision (correct or incorrect classification). However, if you find the CCR to be an important indicator in your context, you might improve results by changing your threshold for identifying a case as "1" as opposed to "0". SPSS's default is to call a case "1" if the predicted probability is over .5, but you may decide to use a threshold of, say. .4 or .35. I say this realizing that it can take on the aspect of "cherry picking" and may open you to criticism. It's best to change this threshold only if you have a theoretical basis for doing so--not merely to improve the CCR after the fact. Another approach is to examine ROC curves, which you can obtain from SPSS in a different menu if you first save each observation's logistic regression predicted probabilities. Through the ROC procedure you can check those probabilities' matchup with the values on the binary outcome variable.
