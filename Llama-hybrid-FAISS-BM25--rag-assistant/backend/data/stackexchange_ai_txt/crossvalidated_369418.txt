[site]: crossvalidated
[post_id]: 369418
[parent_id]: 
[tags]: 
Solution of $\int p_\theta(z) \log q(z) dz $ of Gaussian case

Following is from the original paper of concept of VAE(variational autoencoder) by Kingma,Welling 2014 B. Solution of $D_{KL}(p_\phi(z)||q_\theta(z))$ of Gaussian case The variational lower bound (the objective to be maximized) contains a KL term that can often be integrated analytically. Here we give the solution when both the prior $q_{\theta}(z) = N (0, I)$ and the posterior approximation $p_\phi(z|x^{ (i)})$ are Gaussian. Let $J$ be the dimensionality of $z$ . Let $\mu$ and $\sigma$ denote the variational mean and standard deviation evaluated at datapoint $i$ , and let $\mu_j$ and $\sigma_j$ simply denote the $j$ -th element of these vectors. Then: $$\int p_\theta(z) \log q(z) dz\\ = \int N (z; \mu,\sigma^2 ) \log N (z; 0, I) dz\\ = − {J\over 2} \log(2\pi) − {1\over 2} \sum_{j=1}^{J} (\mu_j{^2} + \sigma_j^2 )$$ At the equation above can't understand how the second equality calculated. Any hint to understand those eqaulity?
