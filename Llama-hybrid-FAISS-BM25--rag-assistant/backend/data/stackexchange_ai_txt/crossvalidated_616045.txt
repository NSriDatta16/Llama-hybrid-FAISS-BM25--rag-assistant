[site]: crossvalidated
[post_id]: 616045
[parent_id]: 58230
[tags]: 
Overall, degrees of freedom appear when we evaluate some objetive within a mathematical system that may or may not have constraints. That is why the most simple answer usually is: "variables - independent parameters". However, I would argue that many students studying statistics, data science, machine learning, phycology (etc) would probably not be satisfied with this answer because there is a lot of things happening behind the "n-1" idea, although it does come simply from a mathematical restriction (for example: we know the mean and want to estimate an statistic like the sample variance). I believe a good way to illustrate all this and empower the audience would be to first explain Dimension, Basis, and Subspaces in an easy way. After all, many things in data science and statistics can be viewed within that domain. Then, move to the idea of restriction within a space. Then, the degrees of freedom idea would arise. Maybe illustrate the concept with the geometry of a Linear Regression, the vector of residuals, and the estimated variance. This would probably be a good way to start. I don't have much time now, but I'll get back to it when I can.
