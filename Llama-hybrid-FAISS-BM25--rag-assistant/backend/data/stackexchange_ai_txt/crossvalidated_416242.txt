[site]: crossvalidated
[post_id]: 416242
[parent_id]: 
[tags]: 
Are "improper uniform priors" in Bayesian analysis equivalent to maximum likelihood estimations?

The improper uniform distribution for parameter $\theta$ is : $p(\theta)=1,\ for -\infty . It is called "improper" since it does not integrate to 1. Because Bayesian theorem is : $p(\theta|y)\propto L(\theta;y)p(\theta)\tag{1}$ when we use improper uniform distribution (i.e., $p(\theta)=1$ ), then the Equation (1) becomes: $p(\theta|y)\propto L(\theta;y)\tag{2}$ I think Equation (2) means that: when using "improper uniform priors" in Bayesian analysis, it is equal to the maximum likelihood estimates (MLE). My question is: (1) Am I right? (2) If right, what is the advantage by using Bayesian technique if it is the same as MLE? Because I find in some situations, the "uniform" prior distribution is used widely such as Example 6.1.1 in this book (i.e., ... ~ dflat() ). I attached this example below for better illustration. (3) But the value of sigma2 is not the same ( 71.3 in MLE, but 149.8 in WinBUGS for Bayesian). Why does it happen, while alpha and beta are the same in these two methods? Appendixï¼š Gelfand et al. (1990, p.978) examine growth data from 30 young rats whose weights were measured weekly for five weeks. In this example we fit a linear regression to the 9th rat's data. The response variable $y_{i},\ i=1,...,5$ is the weight, in grams, on day $x_{i}$ . \begin{align} Y_{ij} &\sim \mathcal N(\alpha_i+\beta_i x_{ij},\sigma^2_c)\qquad i=1,\ldots,k\ j=1,\ldots,n\\ \left(\begin{matrix}\alpha_i\\\beta_i\end{matrix}\right)&\sim \mathcal N\left(\left(\begin{matrix}\alpha_c\\\beta_c\end{matrix}\right),\Sigma_c \right)\qquad i=1,\ldots,k\\ \mu_c &\sim \mathcal N(\mu,C)\\ \Sigma_c &\sim \mathcal W((\rho R)^{-1},\rho)\\ \sigma_c^2 &\sim \mathcal {IG}(\nu_0/2,\nu_0\tau^2_0/2) \end{align} They specify improper uniform priors for all parameters, and so the posterior mode will be equal to the maximum likelihood estimates: $\alpha = 284.8$ , $\beta = 7.31$ , $\sigma^{2} = 71.3$ . The WinBUGS code is: model{ for (i in 1:5) { y[i] ~ dnorm(mu[i], tau) mu[i] I check the values of the maximum likelihood estimates using R, and I think the values in the book is right (i.e., 284.8, 7.31, 71.3). y The paper of Gelfand et al. (1990) can be found here . The example is in Section 6 "A Hierarchical Model", whose data is given in Table 3. $\alpha$ means the 9th rat's weight on the mean of the whole duration (22 day in this example); $\beta$ means the unit increase of weight when passing one day.
