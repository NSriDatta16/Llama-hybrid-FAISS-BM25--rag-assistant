[site]: crossvalidated
[post_id]: 221358
[parent_id]: 
[tags]: 
How to deal with hierarchical / nested data in machine learning

I'll explain my problem with an example. Suppose you want to predict the income of an individual given some attributes: {Age, Gender, Country, Region, City}. You have a training dataset like so train Now suppose I want to predict the income of a new person who lives in City 7. My training set has a whopping 3 samples with people in City 7 (assume this is a lot) so I can probably use the average income in City 7 to predict the income of this new individual. Now suppose I want to predict the income of a new person who lives in City 2. My training set only has 1 sample with City 2 so the average income in City 2 probably isn't a reliable predictor. But I can probably use the average income in Region 1. Extrapolating this idea a bit, I can transform my training dataset as Age Gender CountrySamples CountryIncome RegionSamples RegionIncome CitySamples CityIncome 1: 23 M 4 52.25 3 48.00 2 36.5000 2: 48 F 4 52.25 3 48.00 2 36.5000 3: 62 M 4 52.25 3 48.00 1 71.0000 4: 63 F 4 52.25 1 65.00 1 65.0000 5: 25 M 4 60.00 2 50.50 1 50.0000 6: 41 F 4 60.00 2 50.50 1 51.0000 7: 45 M 4 60.00 2 69.50 2 69.5000 8: 19 F 4 60.00 2 69.50 2 69.5000 9: 37 F 4 43.75 4 43.75 3 50.6667 10: 41 F 4 43.75 4 43.75 3 50.6667 11: 31 F 4 43.75 4 43.75 3 50.6667 12: 50 M 4 43.75 4 43.75 1 23.0000 So, the goal is to somehow combine the average CityIncome, RegionIncome, and CountryIncome while using the number of training samples for each to give a weight/credibility to each value. (Ideally, still including information from Age and Gender.) What are tips for solving this type of problem? I prefer to use tree based models like random forest or gradient boosting, but I'm having trouble getting these to perform well. UPDATE For anyone willing to take a stab at this problem, I've generated sample data to test your proposed solution here .
