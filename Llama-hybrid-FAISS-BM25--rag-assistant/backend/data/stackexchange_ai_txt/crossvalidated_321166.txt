[site]: crossvalidated
[post_id]: 321166
[parent_id]: 304958
[tags]: 
I'm happy that you care about these diagnostic messages. I'm responsible for that specific warning message. WAIC doesn't have a good way to diagnose the reliability and that 0.4 threshold is empirically chosen. Pareto k diagnostic in PSIS-LOO is much better. You did not mention the specific k values, but if they are larger than 1, then theory and experiments show that the error can be arbitrary large (see Aki Vehtari, Andrew Gelman and Jonah Gabry (2017). Pareto smoothed importance sampling. https://arxiv.org/abs/1507.02646 ). WAIC and PSIS-LOO are connected so that if PSIS-LOO fails then WAIC fails even more (Aki Vehtari, Andrew Gelman and Jonah Gabry (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. In Statistics and Computing, 27(5):1413â€“1432, https://arxiv.org/abs/1507.04544 ). Thus, if even one p_waic can have arbitrary large error, then the total WAIC can have arbitrary large error and should not be trusted for final results. Since you have a large difference in WAIC, it's likely that the difference is similar with more accurate/robust approach (e.g. k-fold-CV), but you cannot be sure without computing that more accurate/robust result. In your case it is likely that WAIC and PSIS-LOO fail because you have a flexible model and some of the observation are highly influential, that is, the full data posterior and leave-one-out-posterior are so different that using full posterior as the proposal distribution in importance sampling LOO fails. WAIC uses instead Taylor series approximation, which also fails in case of highly influential observations (which explains why p_waic is used as the ad-hoc diagnostic).
