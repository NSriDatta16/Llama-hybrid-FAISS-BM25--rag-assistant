[site]: crossvalidated
[post_id]: 50780
[parent_id]: 15426
[tags]: 
Flagging outliers is not a judgement call (or in any case need not be one). Given a statistical model, outliers have a precise, objective definition: they are observations that do not follow the pattern of the majority of the data. Such observations need to be set apart at the onset of any analysis simply because their distance from the bulk of the data ensures that they will exert a disproportionate pull on any multivariable model fitted by maximum likelihood (or indeed any other convex loss function). It is important to point out that multivariable outlier s can simply not be reliably detected using residuals from a least square fit (or any other model estimated by ML, or any other convex loss function). Simply put, multivariable outliers can only be reliably detected using their residuals from a model fitted using an estimation procedure not susceptible to be swayed by them. The belief that outliers will necessary stand out in the residuals of a classical fit ranks somewhere up there with other hard to debunk statistical no-no's such as interpreting p-values as measure of evidence or drawing inference on a population from a biased sample. Except perhaps that this one may well be much older: Gauss himself recommended the use of robust estimator such as the median and the mad (instead of the classical mean and standard deviations) to estimate the parameters of a normal distribution from noisy observations (even going so far as deriving the consistency factor of the mad(1)). To give a simple visual example based on real data, consider the infamous CYG star data . The red line here depicts the least square fit, the blue line the fit obtained using a robust linear regression fit. The robust fit here is namely the FastLTS (2) fit, an alternative to the LS fit which can be used to detect outliers (because it uses an estimation procedure that ensures that the influence of any observation on the estimated coefficient is bounded). The R code to reproduce it is: library(robustbase) data(starsCYG) plot(starsCYG) lm.stars Interestingly, the 4 outlying observations on the left do not even have the largest residuals with respect to the LS fit and the QQ plot of the residuals of the LS fit (or any of the diagnostic tools derived from them such as the Cook's distance or the dfbeta) fail to show any of them as problematic. This is actually the norm: no more than two outliers are needed (regardless of the sample size) to pull the LS estimates in such a way that the outliers would not stand out in a residual plot. This is called the masking effect and it is well documented. Perhaps the only thing remarkable about the CYGstars dataset is that it is bivariate (hence we can use visual inspection to confirm the result of the robust fit) and that there actually is a good explanation for why these four observations on the left are so abnormal. This is, btw, the exception more than the rule: except in small pilot studies involving small samples and few variables and where the person doing the statistical analysis was also involved in the data collection process, I have never experienced a case where prior beliefs about the identity of the outliers were actually true. This is by the way quiet easy to verify. Regardless of whether outliers have been identified using an outlier detection algorithm or the researcher's gut feeling, outliers are by definition observations that have an abnormal leverage (or 'pull') over the coefficients obtained from an LS fit. In other words, outliers are observations whose removal from the sample should severely impact the LS fit. Although I have never personally experienced this either, there are some well documented cases in the literature where observations flagged as outliers by an outlier detection algorithm were latter found to have been gross errors or generated by a different process. In any case, it is neither scientifically warranted nor wise to only remove outliers if they can somehow be understood or explained. If a small cabal of observations is so far removed from the main body of the data that it can single handedly pull the results of a statistical procedure all by itself it is wise (and i might add natural) to treat it apart regardless of whether or not these data points happens to be also suspect on other grounds. (1): see Stephen M. Stigler, The History of Statistics: The Measurement of Uncertainty before 1900. (2): Computing LTS Regression for Large Data Sets (2006) P. J. Rousseeuw, K. van Driessen. (3): High-Breakdown Robust Multivariate Methods (2008). Hubert M., Rousseeuw P. J. and Van Aelst S. Source: Statist. Sci. Volume 23, 92-119.
