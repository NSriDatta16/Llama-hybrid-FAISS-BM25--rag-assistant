[site]: crossvalidated
[post_id]: 100720
[parent_id]: 100670
[tags]: 
The outputs are different for a variety of reasons, not the least of which is that they test different things in different ways. Further, not every regression and ANOVA output tests the same thing. It looks like those are R outputs so I'll focus on them in particular rather than generalize your question much. Your regression output is the coefficients of tests of each of the values against a specific value ConnectivityLOW:SusceptibilityLOW (CLOW:SLOW). It is the unique contribution of each item, removing the variance accounted for by other items simultaneously. Keep in mind that because an interaction is included you're not seeing the overall, or average, main effects but only their effect when the other value is 0. These may (looks like would) be different values if the interaction was removed from the model and you examined the main effects in isolation but this usually isn't much of an issue with categorical predictors. The coefficient for the interaction isn't as obvious because it's the test between of (CHIGH:SLOW - CLOW:SLOW) - (CHIGH:SHIGH - CLOW-SLOW). With a simple 2x2 design it's relatively easy to generate one number to represent the interaction but there isn't one for more complex interactions and you cannot trust the output of the regression coefficients for more complex situations, whether significant or not, because they test simpler effects than the full interaction. So, in this case you could use the interaction coefficient. The ANOVA tells you variance accounted for by each variable with each one added in sequence to the model. If there were no correlations among your predictor variables this would have p-values very similar to (identical to) your regression coefficients for main effects. Your effect of C is an independent effect of C not accounting for S. The effect of S is the effect of S with C already entered into the model and therefore has more in common with the coefficient for S in the table of regression coefficients. The interaction is a test of the explanatory power of the subtraction score mentioned above and will have a very similar outcome to that direct test. But more importantly, it will be a test of the complete interaction in more complex designs rather than show tests of simpler components of the interaction. It's your arbiter of whether the interaction is significant. That's the answer for your example but you really need to study regression a bit to better understand this for situations with with continuous variables as well and more complex designs.
