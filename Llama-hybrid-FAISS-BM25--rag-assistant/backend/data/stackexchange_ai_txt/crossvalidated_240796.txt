[site]: crossvalidated
[post_id]: 240796
[parent_id]: 
[tags]: 
How to learn 'end of sequence' for continuous sequence?

Consider Autoregressive model (i.e. RNN Language model) which try to output next token given all previous tokens. When generating sequence with this model, model need to learn when should be end of sequence. In case of discrete sequence, model is usually trained to maximize softmax output distribution with (= End of sequence) token when sequence reaches at the end. For continuous sequence case (such as speech), which technique can we use to teach model learning where end of sequence is?
