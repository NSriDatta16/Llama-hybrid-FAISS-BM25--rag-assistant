[site]: crossvalidated
[post_id]: 377518
[parent_id]: 377515
[tags]: 
If your predictors A and B are both continuous and they interact in their effect, then your binary logistic regression model is: $$ \text{log(p/(1-p))} = \beta_0 + \beta_1 A + \beta_2 B + \beta_3 A \times B $$ where p is the conditional probability of "success" given A and B. (In other words, p is the conditional probability that your binary outcome variable takes the value 1 rather than 0 given A and B, where 1 = "success" and 0 = "failure".) Furthermore, p/(1-p) denotes the conditional odds of "success" given A and B. Assume you are now interested in the effect of A on the (conditional) log odds of "success"; because A and B interact, the effect of A depends on the (effect of) B and you can determine it by re-expressing the above model like this: $$ \text{log(p/(1-p))} = \beta_0 + (\beta_1 + \beta_3 B) A + \beta_2 B $$ Thus, via exponentiation of the coefficient of A in the above model re-expression, you can determine that a 1-unit increase in the value of A changes the odds of "success" by a multiplicative factor of $exp(\beta_1 + \beta_3 B)$ . You can give B certain values to see more explicitly how this multiplicative factor describing the effect of A on the odds of success gets affected by the values of B - for example, consider values for B such as mean(B) - sd(B), mean(B), mean(B) + sd(B) if the distribution of B is roughly symmetric and unimodal. A similar argument as described above can be used to quantify the effect of B on the odds of success as a function of (the effect of) A.
