[site]: crossvalidated
[post_id]: 225764
[parent_id]: 223005
[tags]: 
I think you are on the right track (feature weights make sense). I am assuming that the goal here is to find the 20 neighbors (based on the features) with the closest price. One thing to point out right away is that you can test the model with cross validation: take a hold out test sample and perform the nearest neighbor search over the remaining training sample. That way you can empirically determine whether a given set of feature weights leads to finding good neighbors. This should be your approach to determining the best weights. You can then try your idea of using linear regression and see how it performs vs not setting any feature weights. Assuming the relationship is truly linear, I think this should perform well (you should standardize the features first though). I would also try just using simple correlations of the features with the DV. A more sophisticated approach is to use something like boosted trees or random forest instead (these are popular for determining feature importance).
