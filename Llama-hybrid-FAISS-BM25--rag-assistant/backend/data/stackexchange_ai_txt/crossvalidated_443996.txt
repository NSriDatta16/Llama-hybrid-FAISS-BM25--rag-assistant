[site]: crossvalidated
[post_id]: 443996
[parent_id]: 443711
[tags]: 
It probably means PLS outperforms OLS even in the presence of unrelated variables. I would definitely check regression coefficients of PLS model to see whether the the unrelated variables have relatively low absolute magnitudes. However, if the unrelated variables are related to each other, then the regression coefficients can be deceiving. The lower RMSE of PLS may be explained by this multicollinearity. Even small amounts of dependency (not only within variables pairs but also within multiple variables) can benefit from regularization provided by PLS. Since generally the low sample count combined with multicollinearity of variables results in high RMSE for OLS. Thus I would also perform dimension reduction techniques such as PCA to observe how much the eigenvalues decreases. If you have single or multiple almost 0 eigenvalues it indicates your variables are in fact related.
