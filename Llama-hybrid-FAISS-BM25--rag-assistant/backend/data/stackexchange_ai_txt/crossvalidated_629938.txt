[site]: crossvalidated
[post_id]: 629938
[parent_id]: 
[tags]: 
Expected improvement for bayesian linear regression with unknown noise variance

My question is basically if the expected improvement for a bayesian linear regression with unknown noise variance, i.e. we place a prior on the noise variance -> predictive distribution may not be gaussian, does have a closed form solution? The expected improvement has well known closed form solution for gaussian processes. $$ \alpha_{EI}(x) = \sigma(x) (\gamma \Phi(\gamma) + \phi(\gamma) $$ where $\gamma = \frac{\mu(x) - f^*}{\sigma(x)}$ . As far as I know bayesian linear regression, can be seen as a special case of gaussian processes and the predictive distribution is gaussian, as long as one assumes that variance of additive noise $\epsilon$ around the targets $y$ , is known. In cases where the variance of the noise is not known, one can use e.g. an inverse gamma prior. In this case the predictive distribution is no longer gaussian but rather follows a student-t distribution (See e.g. machine learning - a probabilistic perspective 2nd edition advanced topics, section 15.2.2.2). Does the expected improvement still have closed form solution for this scenario? The paper "Upgrading from Gaussian Processes to Student's-T Processes" derives a closed form for student-t processes. Is the above bayesian linear regression model a special case of these?
