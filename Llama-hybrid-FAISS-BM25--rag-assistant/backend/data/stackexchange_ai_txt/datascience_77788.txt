[site]: datascience
[post_id]: 77788
[parent_id]: 
[tags]: 
How to do embedding for nested dictionary with varying size?

I'm working on an RL task in which the agent needs have some observation. Instead using images, I want to use available information of the environment as the observation. The information regarding the environment is about the info of the objects that exist in the environment and is stored as a list of nested dictionary: [ {'name': 'TennisRacket_de7db8d2', 'position': {'x': -1.667, 'y': 0.0, 'z': 0.818}, 'rotation': {'x': 90.0, 'y': 29.999939, 'z': 0.0}, 'cameraHorizon': 0.0, 'visible': False, 'receptacle': False, 'toggleable': False, 'isToggled': False, ...}, {'name': 'Laptop_f5306a34', 'position': {'x': -1.39652, 'y': 0.8289251, 'z': -1.89688826}, 'rotation': {'x': 0.0, 'y': 19.242403, 'z': 0.0}, 'cameraHorizon': 0.0, 'visible': False, ...} ...] So the task now is to do an embedding on this data. I have thought about putting encoding(eg. utf-8) for non-numerical characters into an vector, using averaged word2vec and doc2vec but they all seem not suitable for the following reasons: for directly using encoding, the dictionary might contain different numbers of observed objects so the length of the dictionary will vary, but the observation requires a vector of the constant size and shape. for averaged word2vec and doc2vec, it is highly likely the case that some of the objects has much more importance, so I think it is better to be able to differentiate them individually and I thing both averaged word2vec and doc2vec will aggregate everything together and hence lose the individual object's info. Can someone suggest a embedding method that both preserves of the shape/size of the embedded vector regardless of the size of the input while keeping the information of individual objects? Thanks for replying.
