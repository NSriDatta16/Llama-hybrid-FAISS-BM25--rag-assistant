[site]: crossvalidated
[post_id]: 130969
[parent_id]: 
[tags]: 
Using Bayesian Graphical Models to reconstruct duplicated damaged data

I am a computer science student specialised in machine learning. Recently I fell in love with Probabilistic Graphical Models (and probabilistic programming) because of the flexibility to focus on model engineering rather than choosing amount a handfull of problem specific algorithms. the ability to do quick model prototypes to test what works and what does not work. the ability to infer structures or series of variables that depend on each other. the ability to be able to write a "story" about how the data was generated by stochastic variables, and the reverse the process to infer the variables. I imagine that Probabilistic Graphical Models would be well suited for data reconstruction in cases where you have multiple inconsistent (missing or conflicting) samples measured from the same real world object. However I cannot seem to find any literature on this. Is there something I am missing? Does it makes sense to use probabilistic graphical models this way?
