[site]: crossvalidated
[post_id]: 503106
[parent_id]: 503102
[tags]: 
It is not true that hidden layers are always larger. One example of networks that use hidden layers of smaller size than output, and input, are autoencoders (see Wikipedia , here , or here ). The point of using autoencoders is dimensionality reduction. Thanks to autoencoders you can train a model that is able to compress your data to smaller representation, or use it for de-noising.
