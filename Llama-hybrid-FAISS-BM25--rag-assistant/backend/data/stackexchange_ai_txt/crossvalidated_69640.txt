[site]: crossvalidated
[post_id]: 69640
[parent_id]: 43943
[tags]: 
Check out section 2.3.2 of this paper by Chapelle and Zien. They have a nice heuristic to select a good search range for $\sigma$ of the RBF kernel and $C$ for the SVM. I quote To determine good values of the remaining free parameters (eg, by CV), it is important to search on the right scale. We therefore fix default values for $C$ and $\sigma$ that have the right order of magnitude. In a $c$-class problem we use the $1/c$ quantile of the pairwise distances $D^\rho_{ij}$ of all data-points as a default for $\sigma$. The default for $C$ is the inverses of the empirical variance $s^2$ in features space, which can be calculated by $s^2 = \frac{1}{n} \sum_i K_{ii} - \frac{1}{n^2}\sum_{i,j} K_{ij}$ from a $n\times n$ kernel matrix $K$. Afterwards, they use multiples (e.g. $2^k$ for $k\in \{-2,...,2\}$) of the default value as search range in a grid-search using cross-validation. That always worked very well for me. Of course, we @ciri said, normalizing the data etc. is always a good idea.
