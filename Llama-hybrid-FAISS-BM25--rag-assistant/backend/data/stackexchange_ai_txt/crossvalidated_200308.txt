[site]: crossvalidated
[post_id]: 200308
[parent_id]: 200276
[tags]: 
On one hand, I agree with @Dougel, that you should use stochastic gradient solvers. I would suggest http://leon.bottou.org/projects/sgd . Some improvement may be first applying dimensional reduction on the dataset. A popular go-to is just throw PCA to it and see if it goes well before thinking too hard about it. Assuming static structure of dataset, the eigen-dimensions you get should be valid for incoming data too. Well, maybe you need to recompute every month or so... On the other hand, I think 870000 samples and 39 features are some rather manageable numbers given today's technologies. And if you have access to a workstation, leaving the code to run for 50 hours ~= 2 days isn't that bad for an offline evaluation of a model.
