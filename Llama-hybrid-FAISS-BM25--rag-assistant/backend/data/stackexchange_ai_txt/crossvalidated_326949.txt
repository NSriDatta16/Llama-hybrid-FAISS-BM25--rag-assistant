[site]: crossvalidated
[post_id]: 326949
[parent_id]: 326867
[tags]: 
I'm not sure if I can answer your question, but let me try. Whether 5^15 states is acceptable is dependent on your requirements for speed and the specs of your machine. To me, it sounds like a lot. Don't forget your action space adds another dimension to your Q-matrix, which then holds some 5^16th elements (10 actions). During training, all of these state-action-pairs should be visited at least a few times before being able to generate 'wise' actions during play. I was in a similar situation a short while ago in my thesis work and I dropped discrete state-action descriptions and opted for value function approximation instead. Especially when there is similarity between neighboring states, using approximative methods can be of help. Check out David Silver's lectures on these methods for a more thorough explanation. I developed a set of parameters to describe my state and during learning trained a very basic neural network (NN) to predict Q(s,a). The parameters formed the input to the NN.
