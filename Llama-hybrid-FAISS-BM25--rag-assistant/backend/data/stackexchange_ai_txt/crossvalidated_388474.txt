[site]: crossvalidated
[post_id]: 388474
[parent_id]: 388431
[tags]: 
This appears to be a ranking problem. Therefore it would be more relevant to look at metrics like the (normalised) Discounted Cumulative Gain , Precision@K and other information retrieval performance metrics. Ranking is a very different beast compared to both regression and classification; I would suggest one to first read upon information retrieval a bit to built some intuition. In the modelling task described, users are the documents to be retrieved. I have found reading a bit upon Bradley-Terry models helpful as they address a somewhat similar problem but taking an approach that is conceptually closer to a "standard probabilistic classification" modelling task. Another thing that helped things "click" for me was the difference between list-wise and pair-wise metrics; the paper by Li on A Short Introduction to Learning to Rank was a very good intro on the matter. You mention XGBoost; XGBoost natively supports rank-related learning objectives as well as evaluation metrics like the NDCG and other rank-related indicators so it should play nicely to the requirements of this task. The XGBoost GitHub repo has a ranking tutorial that should help you getting started.
