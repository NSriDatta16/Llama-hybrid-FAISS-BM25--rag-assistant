[site]: crossvalidated
[post_id]: 468957
[parent_id]: 
[tags]: 
Is it possible and if so how to build a neural network such that it doesn't backpropagate in certain regions of the NN?

I had an idea to improve a neural network I'm currently using, but I'm quite new to machine learning so I don't know if it's possible to implement or how difficult it is or simply if isn't worth. The idea is this. I have a sample of images and I have to classificate them between signal and background (0 or 1). The thing is that these images, which have a variable x associated, are quite correlated to this variable, meaning that two images with a similar value of x in general will be much more similar to two images with very separated values of x. So I thought that maybe it would be a good idea to kind of train this sample into minisamples, each image taking more into account the weights trained by images with a similar x. And this is how I thought to implement it (maybe this implementation isn't really viable so if you know a more viable way feel free to tell me): For now I am using a Convolutional Neural Network for the whole sample, using Keras, and it's like this: def buildCNN(input_shape): model = Sequential() model.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=input_shape)) model.add(Conv2D(64, (3,3), activation='relu')) model.add(MaxPooling2D(pool_size=(2,2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128,activation='relu')) model.add(Dropout(0.5)) model.add(Dense(1, activation='sigmoid')) return model My idea is to arrange the sample into for example 20 minisamples of similar x, and use this same CNN for every one of these minisamples (maybe reducing a bit the number of parameters), and then connect these different CNNs with some weights and biases. Then, when training and comparing the output with the actual value, when backpropagating I would like to only take into account for the training these external weights along with the CNN corresponding with the range of x corresponding to the image being trained, leaving the values of the parameters of the rest of the CNNs untouched. Now, I don't know if something like this exists and if so how it can be implemented to Keras. You can see in my code that it's quite simple, and don't know much about Keras, so if you have any idea how to do this I would also need specifically how it can be implemented using Keras (and if it's impossible with Keras then say if other options are possible and how). (By the way, a bonus question, doesn't relate for anything with the main question so it's not necessary to answer, but if you know something about it it would help. The images I'm using have a shape of (40, 40), so they have low resolution. They are not the type of images that can pass through a filter augmenting its resolution, so I have no other option but to work with this resolution. The thing is that the CNN that I'm using for now works fine, but I think it could be improved if a specific architecture for low resolution images was used, but I haven't been able to find anything about it. If you know something about this please comment it too.) Edit: To understand better what I'm trying to do I'll explain exactly what my type of input is and how I want to treat it. My input are 40x40x1 images (no colour). In these images actually there are only a few pixels that are not 0, which usually come in clusters. The thing is that the signal and the background images tend to form different types of clusters, which is a perfect task for the CNN. Also, the shape of these clusters depends on this mentioned variable x, meaning that if you have learned to discriminate between signal and background images at large x, this knowledge may not be of use (actually it has some use) for lower x. That's why I want to organize these samples into smaller samples such that when training a specific image, this training only affects on the weights of its CNN (i.e. the ability to discriminate better of its CNN), and only affect the other CNNs via these weights that connect them, such that the shape of this specific image doesn't distort the discrimination ability of images of the specific range of x for other CNNs.
