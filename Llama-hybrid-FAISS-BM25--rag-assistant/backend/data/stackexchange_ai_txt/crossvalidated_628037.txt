[site]: crossvalidated
[post_id]: 628037
[parent_id]: 628030
[tags]: 
how do I know my model is the "best possible"? We can't. Cross-validation and other model selection approaches are useful tools, but none of them are perfect. Generalizing from a finite sample is inherently difficult. CV can do a decent job of weeding out unsuitable models, but cannot guarantee that you chose the "best" or "true" model even if there is one. Could it not be that I have overfitted when training on the whole dataset, and would not have been better to retain one (assuming there was a way to select) of the k surrogate models using the best set of hyperparameters? It depends! There's under/overfit in the choice of hyperparameters during CV itself, and then there's under/overfit in the model parameters and predictions on new data . If you plan to re-train on the whole dataset, it's actually possible that CV will under -fit the hyperparameters. Your surrogate models were trained on samples of size $n*(k-1)/k$ , not $n$ . So they were trying to find optimal hyperparameters for datasets smaller than your whole dataset. With smaller datasets, we can only afford to fit less-flexible models, so they likely chose hyperparameters that are less flexible (i.e. more under-fitting) than the optimal ones for your full dataset. On the other hand, choosing the hyperparameters which optimize performance is a noisy problem. We are trying to find the location of the minimum (or maximum) of a curve, when there's noise in the height of the curve, which means that the apparent min (or max) is not the true one. And the error is not equally likely in either direction: People have shown that the hyperparameters that "win" on a particular CV run are more likely to be too flexible (i.e., over-fitting) for samples of size $n*(k-1)/k$ . But that's about CV's choice of hyperparameters -- not about re-training on the whole dataset. In short: CV often chooses hyperparameters that overfit slightly for samples of size $n*(k-1)/k$ , but might still underfit for samples of size $n$ . Yet, regardless of what hyperparameters CV chooses: when you fit a model with those chosen parameters to a larger dataset, it ought to reduce variance in the predictions without increasing bias. Is there a rigorous justification for the procedure sketched above? Is one needed at all, and the argument "more data -> better prediction when facing a new datapoint" is obvious? The argument is "obvious" in the sense that more data leads to better predictions on average . More data will reduce the variance in fitting your chosen model & consequently reduce the variance in the fitted model's predictions, without increasing the bias (assuming your data really are representative of the population). That said, we cannot guarantee it will be true in individual instances.
