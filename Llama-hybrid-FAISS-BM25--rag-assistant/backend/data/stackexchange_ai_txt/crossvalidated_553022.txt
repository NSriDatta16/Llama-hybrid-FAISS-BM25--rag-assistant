[site]: crossvalidated
[post_id]: 553022
[parent_id]: 
[tags]: 
OLS variance simulation in matrix form

Im trying to do a OLS simulation in matrix form for the simple linear regression model yi=β0+β1xi1+ui, and I think I got the beta hats correct. However, I also want to simulate the variances and standard errors. I'm aware of the formula, but Im not sure how to proceed. Any help would be appreciated :) beta_0 = -1 # Intercept beta_1 = 1 # Slope set.seed(123) # Seed n = 20 # Sample size r = 10000 # Number of experiments/iterations ## Storage slope = rep(0,r) intercept = rep(0,r) Betas_matrix = cbind(intercept, slope) for (i in 1:r){ # r is the number of iterations # Generate data U_i = rnorm(n, mean = 0, sd = 1) # Error X_i = rnorm(n, mean = 1, sd = 2) # Independent variable Y_i = beta_0 + beta_1*X_i + U_i # Dependent variable int = rep(1,n) X_i = cbind(int,X_i) beta_hat = solve(t(X_i) %*% X_i) %*% (t(X_i) %*% Y_i) # OLS in matrix form # Extract coefficients slope[i] = beta_hat["X_i",1] intercept[i] = beta_hat["int",1] }
