[site]: crossvalidated
[post_id]: 437467
[parent_id]: 63826
[tags]: 
I'd like to plug in my understanding here in very simple words. For the CRFs we need to calculate the probability of each sequence of the ground truth tags. How can we calculate the probabilities? We can calculate the potential of the sequence(numerator) and the total potentials(denominator/normalization) of all possible sequences somehow like that we do in logistic regression. Let me apply that to the logistic regression first(when $|y|>2$ it becomes the Multi-class Logistic Regression/or Softmax Regression, but they are the same thing in nature). The total potentials of the logistic regression is $$Z(x) = \sum\limits_y \exp(\sum\limits_{k=1}^K \lambda_{y,k}x_k ) $$ and the sequence potential(here more appropriately the label potential or logit) is $$\exp( \sum\limits_{k=1}^K \lambda_{y,k}x_k )$$ with the sequence length of just 1, then we can divide the sequence potential by they total potentials to get the probability: $$P(y|X) = \frac{1}{Z(X)} \exp( \sum\limits_{k=1}^K \lambda_{y,k}x_k )$$ Now that we have obtained the probability of the right tag/label we can calculate the negative log likelihood using this: $- \log P(y|X)$ (the loss for a sample). We can easily see that the logistic regression(here the general multi-class logistic regression) is very simple because the label sequence length is just one, then it is very natural for us to ask if we can combine several logistic regressions together to form a sequence of tags given the observed X(condition)? The answer is yes, and we get the CRF. The difference lies in that in logistic regressions we have only unary potentials/scores(|y| logits) but in CRFs we have a binary potentials between each two sets of unary potentials for each two continuous time-steps, and the binary potentials form the transformation matrix(only one matrix for all two continuous time-steps) meaning the transition potentials/scores from each tag in one time-step to each next tag in the next time-step. Here the key points come, that is how can we calculate the probability of a sequence of ground truth tags? It's very simple with the transition scores(binary potentials). We just multiply all the potentials in the path of the ground truth sequence tags as the numerator and the sum of all possible paths(multiplications) as the denominator. But the denominator seems very expensive to compute since there are $|y|^{|sequence\_length|}$ (here we ignore the start and end symbol) possible paths. But we can utilize the math tool named generalized distributive law and implement it using the programming tool named dynamic programming. Once we have got the probability of the ground truth tag sequence we can use the negative log likelihood as the loss for each sample to train the weights for the features(like those in the logistic regression for the unary potentials or unary scores or emission scores or logits) and the weights in the transition matrix(binary potentials or binary scores). Hope this helps to some extent.
