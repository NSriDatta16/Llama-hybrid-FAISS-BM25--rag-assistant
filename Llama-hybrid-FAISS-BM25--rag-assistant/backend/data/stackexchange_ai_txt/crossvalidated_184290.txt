[site]: crossvalidated
[post_id]: 184290
[parent_id]: 
[tags]: 
How to verify that an implementation of a neural network works correctly?

I wonder what some useful techniques are to check whether an implementation of a neural network works correctly. Below are some checks I am aware of, I would be interested to know more of them: Plotting some metrics (F1-score, accuracy, some cost, etc.) on the train/test/valid sets against the batch or epoch number. Looking at the evolution of matrix weights across epoch. In case of multiple layers, removing some layers and see if it still learns something. Using the network on some data sets that it should be able to learn (though I am not aware of any good list of reference data sets to test neural network implementations , which would be a valuable resource, faster than looking for reference points in the literature.) Performing gradient checking . Checking that the gradient doesn't explode or vanish. Some plots exemplifying the previous checks: plotting train/test/valid set vs epoch number: Good (quickly overfitting though, but at least the network is able to learn): Bad: Looking at the evolution of matrix weights across epoch: Epoch 0: Epoch 50: Hard to tell whether the changes in the weight matrix are good or bad (without looking at the cost), but at least most of them have changed, and they are not stuck at 0.
