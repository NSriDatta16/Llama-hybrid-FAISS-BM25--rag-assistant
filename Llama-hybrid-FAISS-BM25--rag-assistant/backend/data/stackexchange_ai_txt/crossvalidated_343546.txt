[site]: crossvalidated
[post_id]: 343546
[parent_id]: 343496
[tags]: 
Even though the 10 neural networks are different, they are built using the same principle on samples of data from the same population. Hence, you will reveal the performance of the prediction procedure (comprised of model selection, tuning, training and the like) on data from the given population. You will expect similar performance on a new sample from the same population predicted with the same procedure. If your sample is homogenous (all points coming from the same population) and you split randomly between the training and test subsamples, then the test subsample will not be systematically biased. If you cross-validate model performance for every given hyperparameter, it is unlikely that the results will be far away from reality. You may be lucky (or unlucky) on one split between training and testing but what are the chances that you will be off on ten splits on average?
