[site]: crossvalidated
[post_id]: 361227
[parent_id]: 361219
[tags]: 
$\pi(a|s)$ represent a policy rule. The value function is a mean reward that agent could get out from the environment, starting from state s and following policy $\pi$ onward. The value function is defined simply as an expected return, conditioned on the state an agent currently stands in. The given equation consist of two parts - policy stochasticity $\sum_{a} \pi(a|s)$ and environmental stochasticity $\sum_{r,s'} p(r,s'|s,a)$ Another way to understand $\pi(a|s)$ is to visualize this domain using backup diagram (Slides of Practical RL course )
