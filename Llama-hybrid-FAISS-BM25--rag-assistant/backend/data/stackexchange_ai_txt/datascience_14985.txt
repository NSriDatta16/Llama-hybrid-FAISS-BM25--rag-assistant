[site]: datascience
[post_id]: 14985
[parent_id]: 14975
[tags]: 
This assumes you’re happy with neural networks. If you’re not, this answer probably isn’t of much use to you. Firstly, a little bit about anomaly detection via autoencoders. Apologies if you’re already familiar with this. An autoencoder is a neural network which learns to reproduce its own input when compressed through a “bottleneck” layer. For example, you may want to find a lower-dimensional feature representation of a set of 100 x 100 images. Your neural network architecture has an input layer of 10,000 elements, an output layer of 10,000 elements, and one of its hidden layers will be relatively narrow compared to the input space: say 100 nodes. The objective is to train the network to produce an output as close to the input as possible, while throwing away all but 100 nodes’ worth of activation. You are trying to produce as lossless a compression of the input as possible, so those 100 nodes should be a very information-rich representation of the kind of data you trained it on. “How does this have any bearing on anomaly detection?” I hear you ask. Well, if you train your autoencoder on non-anomalous data, it will learn a non-anomalous lower-dimensional feature representation. This will mean the reconstruction error from pushing something through the autoencoder will be lower for data similar to what it was trained on than it will for other arbitrary data. If it receives input that is substantively different from what it was trained on, the reconstruction error will be higher. So, given a set of novel inputs, those inputs with the highest reconstruction error are the most anomalous, as they are poorly reconstructed from the non-anomalous feature representation. If your data has a temporal structure, and you have plenty of training samples, you might want to consider constructing an autoencoding LSTM. An LSTM is a neural network architecture for encoding and decoding sequentially dependent data, and a full description of how this works is beyond both the scope of this post and my own abilities. There are many magnificent resources available online for getting to grips with this. Here is a relevant paper on using LSTMs for anomaly detection in time series in general. It may be that LSTMs are unnecessary for your purposes if the data isn’t strongly sequentially dependent.
