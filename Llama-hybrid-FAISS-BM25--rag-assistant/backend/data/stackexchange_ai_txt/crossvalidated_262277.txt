[site]: crossvalidated
[post_id]: 262277
[parent_id]: 
[tags]: 
Why would you predict from a mixed effect model without including random effects for the prediction?

This is more of a conceptual question, but as I use R I will refer to the packages in R . If the aim is to fit a linear model for the purposes of prediction, and then make predictions where the random effects might not be available, is there any benefit to using a mixed effects model, or should a fixed effect model be used instead? For example, if I have data on weight vs. height with some other information, and build the following model using lme4 , where subject is a factor with $n$ levels ($n=no.samples$): mod1 Then I want to be able to predict weight from the model using new height and age data. Obviously the by-subject variance in the original data is captured in the model, but is it possible to use this information in the prediction? Let's say I have some new height and age data, and want to predict weight, I can do so as follows: predict(mod1,newdata=newdf) # newdf columns for height, age, subject This will use predict.merMod , and I can either include a column for (new) subjects in newdf , or set re.form =~0 . In the first instance, it is not clear what the model does with the 'new' subject factors, and in the second instance, will the by-subject variance captured in the model simply be ignored (averaged over) for the prediction? In either case it would seem to me that a fixed effect linear model might be more appropriate. Indeed, if my understanding is correct, then a fixed effect model should predict the same values as the mixed model, if the random effect is not used in the prediction. Should this be the case? In R it is not, for example: mod1 predict(mod1,newdata=newdf, re.form=~0) # newdf columns for height, age, subject yields different results to: mod2 predict(mod2,newdata=newdf) # newdf columns for height, age
