[site]: crossvalidated
[post_id]: 22858
[parent_id]: 22849
[tags]: 
I don't believe that normalization is what you want here. What you want to do is let your model account for the variance associated with the effect of word length on gaze duration. I presume all of this occurs in the context of interest in the effect of other predictor variables on gaze duration, and you simply find the variance associated with word length to be nuisance variance. In this case, I suggest you look into using mixed effects models with crossed random effects (participants and word). This so far doesn't have anything to do with word-length effects, but as discussed here , you should be able to soak up a lot of nuisance variance associated with both participants and words by this approach. To account for the possibly non-linear effect of word length, I suggest you use generalized additive mixed effects modelling, which should automatically figure out what degree of non-linearity is supported by the data. If you use the dev version of my R package ez , you can specify word length as a covariate via: my_mix = ezMixed( data = my_data , dv = .(gaze_duration) , random = .(participant,word) , fixed = .(predictor1,predictor2) , covariates = .(word_length) ) print(my_mix$summary) However, note that using word length as a covariate assumes that: word length isn't correlated with any of your other predictors of interest the effect of word length doesn't interact with any of your other predictors of interest. Assumption #1 might be assessed by: my_mix = ezMixed( data = my_data , dv = .(word_length) , family = poisson #because word length is a count , random = .(participant,word) , fixed = .(predictor1,predictor2) ) print(my_mix$summary) and assumption #2 might be assessed by: my_mix = ezMixed( data = my_data , dv = .(gaze_duration) , random = .(participant,word) , fixed = .(word_length,predictor1,predictor2) ) print(my_mix$summary) Addendum You followed up that you wanted to account for the word length effect then use the subsequent word-length-eliminated data as features in a machine learning context. To do this, I'd run a gam and use the residuals as your features data: library(mgcv) fit = gam( data = my_data , formula = gaze_duration ~ s(participant,bs='re') + s(word,bs='re') + s(word_length,k=max(my_data$word_length),bs='ts') ) my_data$resid = residuals(fit)
