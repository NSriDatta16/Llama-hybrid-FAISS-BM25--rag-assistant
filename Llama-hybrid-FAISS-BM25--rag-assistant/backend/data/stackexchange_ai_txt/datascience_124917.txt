[site]: datascience
[post_id]: 124917
[parent_id]: 124915
[tags]: 
You're noticing that the magnitude of the loss value influences the magnitude of the gradient. This is true, but not necessarily something you need to adapt the learning rate around. Neural networks struggle with wide ranges of values. It tends to lead to numerical instability, or large magnitude loss terms dominating small magnitude loss terms. Typically, we deal with this by preprocessing the data to have a more reasonable value range. For example, your toy dataset { x, y } = {{ 1, 2 }, { 100, 200}} crosses several orders of magnitude in both the input and output values. We might preprocess the data by transforming it with x' = log(x+1) . This would give us a processed dataset of { x, y } = {{ 0.693, 1.098 }, { 4.615, 5.303}} With the un-normalized dataset: w = nn.Parameter(torch.tensor(1.)) x = torch.tensor([1, 100]).float() y = torch.tensor([2, 200]).float() y_pred = x*w loss = nn.functional.mse_loss(y_pred, y) loss.backward() w.grad >tensor(-10001.) With normalization w = nn.Parameter(torch.tensor(1.)) x = torch.tensor([1, 10]).float().log1p() y = torch.tensor([2, 20]).float().log1p() y_pred = x*w loss = nn.functional.mse_loss(y_pred, y) loss.backward() w.grad >tensor(-1.8316) You can also control the magnitude of the gradient with gradient clipping.
