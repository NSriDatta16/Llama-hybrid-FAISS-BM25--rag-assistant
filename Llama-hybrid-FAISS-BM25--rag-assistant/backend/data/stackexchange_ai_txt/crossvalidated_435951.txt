[site]: crossvalidated
[post_id]: 435951
[parent_id]: 435935
[tags]: 
I can't comment since I don't have enough reputation, but I will try to give a small answer. Essentially, the reduced dimensions of t-SNE are not intended to carry meaning (although they might be correlated to something meaningful by chance). t-SNE is mostly used as a visualization technique, and its use as a dimensionality reduction technique is muddled. In addition, since t-SNE is non-convex and depends on initialization, your final dimensions might have different "meaning" every time you re-run it. It is entirely dependent on the run and your full dataset (part of the reason why sklearn's tSNE does not provide a transform function, only fit_transform). The original t-SNE paper discusses this and how t-SNE dimensionality reduction is not clear for reduced components of dimensionality d>3. In addition, distances in the reduced space do not mean much as t-SNE is trying to minimize KL-divergence. See this question and this one too
