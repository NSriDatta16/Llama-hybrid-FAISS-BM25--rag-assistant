[site]: crossvalidated
[post_id]: 374316
[parent_id]: 
[tags]: 
Truncated count model -- including information about the number of unobserved realisations

Background Suppose we have a model such that $Y \sim \mathcal{M}(\theta)$ is a discrete random variable taking values in $[0, 1, \ldots]$ . We would like to make inference about $\theta$ from a collection of observations $\boldsymbol y = \{y_1, y_2, \ldots, y_J\},\: y_i >0$ , i.e., we only observe realisations of $Y$ if they are non-zero. There is some literature from the sixties on performing inference when $\mathcal{M}$ is a Poisson distribution, for instance. I have a question for which I haven't seen a Bayesian treatment, which is most likely due to my own ignorance and/or poor Googling skills. Suppose I have some (imperfect) knowledge about the size of the "population", $N = J + n_0$ (see below). First question is (i) should I include this information into the model? and (ii) how should I do that? Below I discuss my partial answers to these. What I am asking for is : feedback as to whether these are correct and where in the literature I can find more information. An attempt at a solution Let $\pi(\theta)$ be a joint prior on the parameters and let $L(\boldsymbol y | \theta)$ be the likelihood, such that the joint posterior is $p(\theta | \boldsymbol y) \propto L(\boldsymbol y | \theta)\pi(\theta)$ . We can use a "compressed" likelihood of the form $\prod_{i = 0}^U \text{Pr}(i | \theta)^{n_i}$ , where $n_i$ is number of occurrences of $i$ in the sample $\boldsymbol y$ and $U$ is the maximum such value. It seems to me that we can see $n_0$ as an extra parameter in the model and assign it a prior $\pi_K(n_0)$ . I wonder if we can then use $L^\prime(\boldsymbol y | \theta) := \prod_{i = 1}^U \text{Pr}(i | \theta)^{n_i}\sum_{j=J+1}^\infty \text{Pr}(0 |\theta)^j \pi_K(j)$ as the new likelihood. Summation could also be from $J + 1$ to $N$ (instead of $\infty$ ). I choose to marginalise over $n_0$ to get around having to simulate the discrete parameter $n_0$ , which is important for fitting the model in Stan, for instance.
