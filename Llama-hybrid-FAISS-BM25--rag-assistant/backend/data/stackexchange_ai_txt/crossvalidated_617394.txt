[site]: crossvalidated
[post_id]: 617394
[parent_id]: 
[tags]: 
Testing homogeniety within a bin of scores given max number of bins

I have a score (ranging from 0 to 1000) which predicts a binary event. The score is based on a regression. Scores are binned. There should be a maximum of $x$ (e.g. $10$ ) bins. Predicitions within a bin should be homogenous meaning they have a similar average rate of the target. This is normally tested by splitting all observations of a bin into two parts according to the score and then a z-test or t-test with $$ H_0: AR_{bin_i part_1} = AR_{bin_i part_2} $$ is applied. In case $H_0$ cannot be rejected it is conluded that they are similar enough. This works well in case the score is not too perfect nor the sample extremly large. As the sample size increases the score naturally gets better and the test above will start to reject $H_0$ more often if the number of bins does not increase at the same time. How can the test be altered to show that scores within a bin are as homogeneous as it gets, knowing that at max I am willing to have $x$ number of bins? A completely different approach for testing homogenity within buckets given a fixed number of bins is also welcome.
