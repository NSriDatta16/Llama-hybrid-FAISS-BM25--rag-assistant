[site]: crossvalidated
[post_id]: 388954
[parent_id]: 341739
[tags]: 
Basic units of LSTM networks are LSTM layers that have multiple LSTM cells. Cells do have internal cell state, often abbreviated as "c", and cells output is what is called a "hidden state", abbreviated as "h". Regular RNNs do have just the hidden state and no cell state. It turns out that RNNs have difficulty of accessing information from a long time ago. For instance, check these two long sentences: Cows , that eat green green ... green grass are OK. Cow , that eat green green ... green grass is OK. It would be very hard for RNN to learn the singular/plural dependency, but LSTM are capable of doing that.
