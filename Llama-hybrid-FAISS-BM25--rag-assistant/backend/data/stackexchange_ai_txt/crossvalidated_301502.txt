[site]: crossvalidated
[post_id]: 301502
[parent_id]: 
[tags]: 
Transforming time series as percentage of total series

In this problem I am looking at many thousands of time-series for ad campaigns of varying length, with varying rate structures impacting daily revenue, and therefore total campaign revenue. So Campaign 1 may last 20 days and pull in 20,000 dollars, and Campaign 2 may last 30 days and pull in 10,000 dollars, so on and so forth. Here is am example data structure that omits other variables such as indicators of rate type: Obsv Date Day_of_Campaign Campaign1DailyRe Campaign2DailyRev 1 2017-01-01 1 80 0 2 2017-01-02 2 75 0 . . . 20 2017-01-20 20 50 0 21 2017-01-15 1 0 25 . . . 51 2017-02-14 30 0 30 Assuming that each series: Is stationary around its own mean. I will control for rate-type because each campaign of a certain rate-type may exhibit behavior unique from other rate types. The end-question is: given that the magnitude of each campaign can vary by large amounts (e.g., Campaign 521 could be 500,000 and Campaign 603 could be 100,000), but behavior like seasonality could potentially be shared regardless of campaign magnitude, would it be statistically valid to transform the data such that each daily value is instead viewed as a percentage of the total, therefore levelizing the analysis for each campaign ? Are there any other approaches that I should consider?
