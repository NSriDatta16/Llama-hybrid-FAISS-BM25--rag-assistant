[site]: datascience
[post_id]: 20094
[parent_id]: 17471
[tags]: 
Typically to extract features, you can use the top layer of the network before the output. The intuition is that these features are linearly separable because the top layer is just a logistic regression. For GANs, you can use the features from the discriminator. These features are supposed to give a probability if the input came from the training dataset, "real images". In Radford's DCGAN paper , they use all the convolutional layers of the discriminator and run a max pooling layer extract features for CIFAR-10. To evaluate the quality of the representations learned by DCGANs for supervised tasks, we train on Imagenet-1k and then use the discriminator’s convolutional features from all layers, maxpooling each layers representation to produce a 4 × 4 spatial grid. These features are then flattened and concatenated to form a 28672 dimensional vector and a regularized linear L2-SVM classifier is trained on top of them.
