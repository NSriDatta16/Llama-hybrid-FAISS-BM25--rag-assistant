[site]: crossvalidated
[post_id]: 612323
[parent_id]: 610231
[tags]: 
Suppose the control data matrix is $Z$ and for tidyness suppose that each column has mean zero. Let the control correlation matrix is $R$ and assume it is not singular. Let $R^{-1/2}$ be a square root of the inverse of $R$ . The matrix $R^{-1/2}Z$ has uncorrelated columns; its correlation matrix is the identity, $R^{-1/2}RR^{-1/2}$ Now let $Y$ be the case data matrix, also with each column centred at zero. The matrix $R^{-1/2}Y$ would have uncorrelated columns if the correlations were the same, so its correlation matrix is a summary of the 'extra' correlations in the cases. Note that if we write $S$ for the correlation matrix of $Y$ , $R^{-1/2}SR^{-1/2}$ is symmetric with non-negative eigenvalues and so is suitable for PCA. Or you could just do singular-value decomposition on $R^{-1/2}Y$ . (I think I'd actually prefer doing this with covariances rather than correlations, so that differences in variance between the two groups don't look like differences in correlation)
