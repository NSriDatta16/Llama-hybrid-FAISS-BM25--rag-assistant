[site]: crossvalidated
[post_id]: 254139
[parent_id]: 254039
[tags]: 
I think there is a little misunderstanding here: logistic regression (LR), by itself, is not exactly a classifier, but a model for the conditional probability $P(Y=k|X=x)$, where $k=0,1$ maps to your class labels {No Cancer, Cancer}. In ML terminology, I think you would call it a discriminative model , since it models the conditional probability, as opposed to a generative model , such as for example LDA, which models the joint probability $P(Y=k,X=x)$. LR only becomes a classifier when you couple it with a decision rule, which usually is something like if (phat > alpha) yhat = 1 else yhat = 0 And then you set $\alpha$ by cross-validation to optimize your accuracy metric, which is what you're doing. The cost function is already the "right one" for LR, because it's just maximum likelihood estimation, under the assumption that the training data is a random sample. To use another cost function would mean that either you're not estimating the $\theta$ by using MLE, or that you're using another model for the conditional probability of $Y$ given $X$ . As a matter of fact, (regularized) hinge loss, which is a different cost function, is the correct cost function for SVM, which is a different model with respect to LR. Thus you're left with basically two choices: you keep using your cost function and your procedure to select $\alpha$. At most, you could add ($L_2-$ or $L_1-$) regularization to your cost function and see if that improves test error for the CV-selected value of the regularization parameter $\lambda$. I would expect this to make a improvement on your current procedure only if either classes are close to linearly separable, or if you have a number of predictors which is close to or larger than the number of training points, i.e., either when the estimated parameters of nonregularized model have large variance, or when the nonregularized model cannot be fitted at all. BTW, $L_2- $regularization corresponds to MAP estimate (instead than MLE) with a Gaussian uncorrelated prior for the parameters, while $L_1- $regularization corresponds to a Laplace uncorrelated prior. you add new models to your pool of models. For example, you try fitting also LDA or SVM, and compare them to LR using cross-validation. These are different models, and using MLE you arrive at objective functions which are different from the log-loss you were using. However, you do it in a principled way. If you used different cost functions to estimate the LR model, you wouldn't be doing MLE anymore. EDIT the OP was modified as a consequence of my answer, and it's now different. I try to take into account the new requests, but I don't think estimating the model parameters based on skill scores is smart. I'd still go with trying to estimate the conditional or joint probability as accurately as possible, and only then trying to find thresholds (by cross-validation) which optimize skill scores. Let $u(x)$ denote the step function: $$\begin{align} u(x) &= \left\{ \begin{array}{l} 1 \quad x\ge0 \\ 0 \quad x If $\mathbf{X}=(1,x_1,\dots,x_d)$ is a vector of predictors (note that, with an abuse of notation, I included the constant $1$ in the vector of predictors) and $\boldsymbol{\beta}=(\beta_0,\dots,\beta_d)$ a vector of parameters, $u(\boldsymbol{\beta}^T\mathbf{X})$ is a linear classifier. We could find the $\boldsymbol{\beta}$ which minimize, for example, the FAR on the training set $\{(\mathbf{x}_i,y_i)\}_{i=1}^N$, i.e. $$\min_{\boldsymbol{\beta}}\sum_{i=1}^N (1-y_i)u(\boldsymbol{\beta}^T\mathbf{x}_i)$$ Now, this objective function is obviously discontinuous, so optimization will be an hassle. Not only that, but there are infinitely many solutions - just consider that, whatever the training set , $\boldsymbol{\beta}=(\beta_0,0,\dots,0)$ minimizes FAR as long as $\beta_0 Of course, you could repeat similar considerations for other skill score-based loss functions: I don't think you would get much better results. In particular, I expect the issue of non-uniqueness to reappear. The reason why I expect that, is that skill scores are all discrete loss functions, i.e., they all take values in a finite set of size $N$. The parameter vector $\boldsymbol{\beta}$ instead is a continous variable: intuitively, if there's a $\boldsymbol{\beta}^*$ which minimizes the skill score, then there are infinitely many (for example, think of the values of $x$ which minimize $u(x)$). Thus, even if you consider a skill score for which there is not such a trivial solution as there is for FAR, you will still have to deal with discontinuity of the loss function, and non-uniqueness of the parameters estimate. You could try to fix the last issue with regularization.
