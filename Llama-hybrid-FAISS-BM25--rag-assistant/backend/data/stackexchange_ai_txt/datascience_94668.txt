[site]: datascience
[post_id]: 94668
[parent_id]: 94649
[tags]: 
Based on your post (my emphasis): The problem I'm facing is that the some of the predictors have changed over time, for example the pressure in the machine was increased. This influenced some of the other predictors, but hasn't influenced my target . So to be clear, the input parameters changed but made no impact on the output parameter? There are two possibilities: The data is part of a single population, then the change in the input parameters (over that range) has little or no impact on the output parameter. This can be addressed by creating a new feature, which is a delta from some baseline and see if that new feature is a better fit for your model. Pressure Piston Position Leakage Flow (Out) 10 20 30 11 22 30 12 23 33 The inputs into row 2 have changed relative to row 1 but no change in output. Therefore a small change in parameter 1 and 2 has no impact on output (physical examples include say overcoming hysteresis or localised energy storage or data buffer or a bucket that has to be filled with water before spilling over). In this case the output isn't sensitive to the small changes and perhaps they're a function of the original value. So new features could be: Pressure Piston Position Leakage Flow (Out) F1 F2 10 20 30 0 0 11 22 30 0 0 12 23 33 1 1 So F1 only increases if the difference between row 1 and the other rows is greater than 1 otherwise it's 0 etc. The data is part of more than one population. As an example, say you're taking measurements of a product. Over time the measurement device loses calibration and you see a drift in the measurement. The only real fix is to determine the drift due to a loss of accuracy and apply a corrective factor as function of time or base value.
