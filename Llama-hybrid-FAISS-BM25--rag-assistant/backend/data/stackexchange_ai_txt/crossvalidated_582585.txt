[site]: crossvalidated
[post_id]: 582585
[parent_id]: 582574
[tags]: 
What you see on the plot is not exactly a noise reduction. What is shown is the predictions made using only the first component of PCA. Using the first component of PCA leads to reducing multi-dimensional data to a single dimension. The new representation is less rich in information because to create it we disregarded the information that was represented in the other components. This can lead to noise reduction, but this also removes the non-noise, relevant information. Moreover, it doesn't necessarily need to remove the noise. As an example, let's use a thought experiment: if you used PCA on completely "random" data (noise-only), the first component (or components) would contain something, as the algorithm forces them to be something. The algorithm in such a case wouldn't do anything to remove the noise, it would rather "overfit" to some bogus patterns. Also keep in mind that what you see for PCA, or other dimensionality reduction algorithms, would also hold for any other machine learning algorithm that doesn't completely overfit the data. If the predictions by the machine learning model won't perfectly fit the data (they usually won't), it would produce predictions that are "simpler" and "smoother" than the observed data, because the algorithm needed internally to create a simplified representation of the data (it has fewer parameters than data points). Again, this doesn't necessarily remove the actual noise and whatever algorithm you would use for noise reduction, this is something to be verified when validating the model.
