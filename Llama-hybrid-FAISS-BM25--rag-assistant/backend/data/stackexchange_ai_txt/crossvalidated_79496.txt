[site]: crossvalidated
[post_id]: 79496
[parent_id]: 79490
[tags]: 
Cross validation is mainly used for evaluation purposes (for instance no clearly defined train/test split, a desire to calculate statistical significance, etc.) When making a final model, it would make more sense to train on the entire data set and not average the weights - see: Averaging weights learned during backpropogation Averaging weights can sometimes be useful though - like in averaged perceptron, but just not in the case of NNs. Note that in training NNs what is often done is to hold out some data and after each epoch test on this held out set. When performance on the set decreases then you are beginning to overfit and should stop training
