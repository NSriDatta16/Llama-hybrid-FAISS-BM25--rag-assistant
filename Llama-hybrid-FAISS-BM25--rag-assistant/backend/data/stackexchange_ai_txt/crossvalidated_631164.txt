[site]: crossvalidated
[post_id]: 631164
[parent_id]: 508234
[tags]: 
This problem is not exactly a binary comparison problem. The binary comparison problem would be the comparison of two vectors of binary values. In term of machine learning, what you call a binary comparison correspond to the binary classification score . Here you want to compare matrices . You can continue to see a matrix as a point-by-point stuff, but you can also see it row-wise or column-wise, or globally. What should be done is a comparison of either point-wise comparison (it seems it's what you have done already) vector-wise comparison (when you calculate e.g. the cosine similarity between rows) : this ends up with a row-by-row sized matrix, that eventually leads to global score (by e.g. averaging over all cosine similarities) column- or row-wise comparison, by supposing statistical independence among the column and or rows (see below) global-wise comparison, by comparing the entire matrix structure among the different matrices Note a few things: what applies to rows can apply to columns (you can do the cosine similarity of columns, why not?) one can construct the contingency/ confusion matrix for data point-wise, simply by counting the number of times $\delta\left(A_{ij}=1\right) = \delta\left(B_{ij}=1\right)$ (true positive), $\delta\left(A_{ij}=1\right) = \delta\left(B_{ij}=0\right)$ (false negative or false positive) $\delta\left(A_{ij}=0\right) = \delta\left(B_{ij}=1\right)$ (false positive or false negative, respectively) and $\delta\left(A_{ij}=0\right) = \delta\left(B_{ij}=0\right)$ (true negative), where $\delta$ is the indicatrice function (it is counting after all) one can construct the contingency/confusion matrix for row-wise structure, by counting over columns e.g. $\delta\left(A_{i\cdot}=1\right)=\delta\left(B_{i\cdot}=1\right)$ , ... This procedure ends up with a true positive like vector of size given by the number of rows of $A$ or $B$ (both having the same size), and $A_{i\cdot}$ is the marginal laws regarding rows one can construct the contingency/confusion matrix for column-wise structure, by counting over rows e.g. $\delta\left(A_{\cdot j}=1\right)=\delta\left(B_{\cdot j}=1\right)$ , ... This procedure ends up with a true positive like vector of size given by the number of columns of $A$ or $B$ (both having the same size), and $A_{\cdot j}$ is the marginal laws regarding columns A nice approach to understand all these concepts is the multi-label classification task , that naturally ends-up with the comparison of two matrices. In its simplest form the multi-label classification correspond to the comparison of two binary matrices (I mean matrices where only $0$ or $1$ appears, some multi-label classification may have higher values as well). In the classification terminology, if $A$ is the true matrix and $B$ is the predicted matrix, then the true/false positive/negative naming follows the first convention given above.
