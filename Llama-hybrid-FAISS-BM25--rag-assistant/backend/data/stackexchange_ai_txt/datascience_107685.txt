[site]: datascience
[post_id]: 107685
[parent_id]: 107630
[tags]: 
I have something of an answer from a Neural Network context. If you consider a Neural Network set up for classification with a softmax activation on it's output layer, the outputs could be interpreted as something of a confidence. Practically, your loss function during training would probably choose a level of "confidence" well below 1.0 as the network choosing something. Which does not give an incentive to choose 1.0 but maybe with the right loss function. In my experience getting fancy with loss functions it just made the network be boldly incorrect or make no strong predictions for fear of being wrong. In a softer network (one which tries to predict a future value, not just classify it) you could maybe try to include an output neuron representing confidence which you multiply by the incorrectness of the prediction for your loss. I don't know if a network will ever converge on this function practically. I have done Erwan's answer of building another network with a softmax output classification of whether or not it thinks the first network will be wrong. With a softmax type activation you can choose to only act on predictions which are 1.0. How often this happens and how often a perfect confidence is correct is something only one's data can only bear out.
