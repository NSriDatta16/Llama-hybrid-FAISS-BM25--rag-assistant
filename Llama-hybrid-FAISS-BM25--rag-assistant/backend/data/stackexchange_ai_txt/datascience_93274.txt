[site]: datascience
[post_id]: 93274
[parent_id]: 93224
[tags]: 
Yes, this could be possible if your dev/test data comes from the same domain as the training data, in which case word2vec will encounter fewer OOV tokens that mess up the loss. This could also mean that the benefits of BERT - subword tokenization to handle OOV characters in generalized domains - are lost. If your vocabulary size is small, your word2vec model needs to capture relationships between fewer tokens and can model those relationships better than a subword model which loses the relationships between fixed tokens in your data and instead tries to generalize relationships across >30K subword tokens (in the bert-based-uncased model), which could lead to noise.
