[site]: datascience
[post_id]: 10050
[parent_id]: 
[tags]: 
Simple ANN visualisation

TLDR: Please help me understand the graph representation of the network in the image below. Hi, this is pretty stupid, but I'm just have trouble visualising what I'm actually doing with this neural network. I've read about neural networks and multilayer perceptrons for some time and I'm just getting started with actually using them. I started with a super simple example, just to get warmed up but now I've confused myself. I artificially generated some data and used nntools in matlab to attempt to "predict" the results. I built a neural network with the following parameters: feed forward backprop network. Gradient Descent training algorithm. Gradient Descent learniing algorithm. Performance/loss function of mean squared error. two layers: first with three neurons and Tansig activation function. the second with one neuron and linear activation. I end up with something looking like this: However, I don't know what this actually represents, I'm all sorts of confused right now. Could someone please explain/upload an image/draw some ascii to represent the neurons and edges in the above network? It would really help clear my head. Currently I think it's like this: T L o / \ / \ IN > o--o--o--o > OUT \ / \ / o With linear activations in columns L and Tanh activations in columns T. Is that right? Doesn't make sense to me.
