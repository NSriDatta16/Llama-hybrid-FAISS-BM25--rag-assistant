[site]: crossvalidated
[post_id]: 435877
[parent_id]: 
[tags]: 
Singular state transition probability matrix in David Silver's UCL Lesson 2

I'm studying David Silver's second lesson on reinforcement learning: https://www.youtube.com/watch?v=lfHX2hHRMVQ&list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ&index=2 and the state transition probability matrix is defined as However, with this python code: import numpy as np P = np.matrix([[0, 0.5, 0, 0, 0, 0.5, 0], [0, 0, 0.8, 0, 0, 0, 0.2], [0, 0, 0, 0.6, 0.4, 0, 0], \ [0, 0, 0, 0, 0, 0, 1], [0.2, 0.4, 0.4, 0, 0, 0, 0], [0.1, 0, 0, 0, 0, 0.9, 0] ,[0, 0, 0, 0, 0, 0, 1]]) np.linalg.det(P) I'm getting a determinant of 0 and thus a singular matrix. The issue is that David then defines the Bellman Function to get the vectorized value functions as: And thus if P can't be inverted, neither can (1-gamma*P) and I can't get V. Any tip on what am I doing wrong? :)
