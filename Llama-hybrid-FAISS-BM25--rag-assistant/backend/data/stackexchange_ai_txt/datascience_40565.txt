[site]: datascience
[post_id]: 40565
[parent_id]: 
[tags]: 
No accuracy in Keras RNN Model with Bitcoin Data

I am very new to machine-learning and have made an RNN-LSTM model with no accuracy. My data has been normalized with MinMaxScaler from Sklearn and has a shape of has an input of shape (3, 2)... My normalization steps: def get_data(currency): url=f'https://coinmarketcap.com/currencies/{currency}/historical-data/?start=20130428&end={time.strftime("%Y%m%d")}' data=pd.read_html(url, flavor='html5lib')[0] data=data.assign(Date=pd.to_datetime(data['Date'])) data['Volume']=(pd.to_numeric(data['Volume'], errors='coerce').fillna(0)) data.columns=[col.lower() for col in data.columns] data.columns=[col.strip('*') for col in data.columns] return data df=get_data('bitcoin') df=df.sort_values(by='date') def split_data (data, trainsize): return np.array(data[:int(trainsize*len(data))]), np.array(data[int(trainsize*len(data)):]) scaler=MinMaxScaler(feature_range=(0,1)) def create_inputs(data, window): inputs=[] for i in range(len(data)-window): inputs.append(data[i:(i + window)].values) close,volume=[],[] for x in range(len(inputs)): close.append(inputs[x][:,0]) volume.append(inputs[x][:,1]) close=np.array(close) close=scaler.fit_transform(close) volume=np.array(volume) volume=scaler.fit_transform(volume) inputs=[] for i in range(len(close)): rows=[] for x in range(len(close[i])): row=[close[i][x], volume[i][x]] rows.append(row) inputs.append([rows]) inputs=np.vstack(inputs) return inputs def create_outputs(data, window): return scaler.fit_transform(data['close'][window:].values.reshape(-1,1)) # VARIABLES df=df.filter(['date', 'close', 'volume'], axis=1) df=df.sort_values(by='date') df[df.columns] = df[df.columns].apply(pd.to_numeric, errors='coerce') train,test=split_data(df,0.8) train=pd.DataFrame(train, columns=df.columns) test=pd.DataFrame(test, columns=df.columns) train=train.drop('date',1) test=test.drop('date',1) xtrain,ytrain=create_inputs(train, 3), create_outputs(train, 3) xtest,ytest=create_inputs(test, 3), create_outputs(test, 3) Here is part of my training data (1607, 3, 2) fetched from CoinMarketCap's Bitcoin History after scaling: [[[0.01363717 0. ] [0.01577874 0. ] [0.01463021 0. ]] [[0.01577874 0. ] [0.01463021 0. ] [0.01006721 0. ]] [[0.01463021 0. ] [0.01006721 0. ] [0.00762504 0. ]]...] My model has 3 Layers with 1024 LSTM Cells, and Dense layer with 1 neuron: model = keras.models.Sequential() model.add(keras.layers.CuDNNLSTM(1024, input_shape=(3,2), return_sequences=True, name='input')) model.add(keras.layers.Dropout(0.2)) model.add(keras.layers.CuDNNLSTM(1024, return_sequences=True, name='lstm1')) model.add(keras.layers.Dropout(0.2)) model.add(keras.layers.CuDNNLSTM(1024, name='lstm2')) model.add(keras.layers.Dropout(0.2)) model.add(keras.layers.Dense(1, activation='tanh', name='output')) # Compile model model.compile( loss='mse', optimizer='adam', metrics=['accuracy'], ) history=model.fit(xtrain, ytrain, batch_size=64, epochs=1000, validation_data=(xtest, ytest), verbose=1)
