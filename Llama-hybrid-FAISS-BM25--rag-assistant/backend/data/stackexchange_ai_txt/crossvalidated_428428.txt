[site]: crossvalidated
[post_id]: 428428
[parent_id]: 128970
[tags]: 
This is a classic case in Bayesian analysis, where you have an exchangeable sequence of observations that are conditionally independent given the underlying parameters, but they are not marginally independent when you do not condition on the parameters. You can find simple explanations of this phenomenon, discussing the Bernoulli model as an example, in O'Neill (2009) . You can also find some more aspects of Bayesian analysis of this Bernoulli model in a related series of papers ( O'Neill and Puza 2005 , O'Neill 2012 , and O'Neill 2015 ). From the properties of the Bernoulli distribution, you have the conditional mean $\mathbb{E}(X_i|P) = P$ . Using the law of iterated expectations , you have: $$\begin{equation} \begin{aligned} \mathbb{E}(S_n) = \mathbb{E} \Big( \mathbb{E}(S_n|P) \Big) &= \mathbb{E} \Bigg( \mathbb{E} \Bigg( \frac{1}{n} \sum_{i=1}^n X_i \Bigg| P \Bigg) \Bigg) \\[6pt] &= \mathbb{E} \Bigg( \frac{1}{n} \sum_{i=1}^n \mathbb{E} (X_i | P ) \Bigg) \\[6pt] &= \mathbb{E} \Bigg( \frac{1}{n} \sum_{i=1}^n P \Bigg) \\[6pt] &= \mathbb{E} ( P ). \\[6pt] \end{aligned} \end{equation}$$ Similarly, you have: $$\begin{equation} \begin{aligned} \mathbb{E}(X_i) = \mathbb{E} \Big( \mathbb{E}(X_i|P) \Big) &= \mathbb{E}(P). \\[6pt] \end{aligned} \end{equation}$$ This establishes the equivalence of the expected values asserted by your professor. For the latter problem, you will need to prove that $\mathbb{E}((S_n-P)^2) \rightarrow 0$ as $n \rightarrow \infty.$ I will not give you a solution here, but as a hint, I recommend that you use the law of iterated expectation to get an expression for the expectation in the statement. You should then be able to show that this expression converges to zero in the limit, which would establish convergence in quadratic mean.
