[site]: crossvalidated
[post_id]: 337479
[parent_id]: 
[tags]: 
A simple Neural Network, finding weights to achieve 100% accuracy

So I've been watching lectures and doing the problem sheets from the class CS 229 2017, taught at Stanford by Andrew Ng. In problem sheet 3 he puts forward the following question: $\textbf{So this is what I did in part a)}$ What we have is: $\sigma(z) = \frac{1}{1+e^{-z}}$ and it's derivative is $\sigma'(z)=\sigma(z)(1-\sigma(z))$ $l=\frac{1}{n} \sum^{n}_{i=1} (o^{i}-y^{i})^2$ From this we can calculate: $\textbf{Then for part b)}$ Here I'm completely lost. I'm guessing the triangle that he talks about is the following: However, I don't understand how I would choose the weights in such a way that I would achieve 100% accuracy. Any help or hint would be very well appreciated!
