[site]: crossvalidated
[post_id]: 273585
[parent_id]: 
[tags]: 
dealing with computationally expensive feature selection within nested cross-validation

I am building a binary SVM classifier that uses genomic data as features. Because of the large number of features, I have employed a statistical method designed specifically for handling this type of data to filter features that are significantly different between my two class groups prior to building the model. I've read a lot over the past week about different methods of cross validation and it seems that nested cross validation is the method of choice for model evaluation in conjunction with model selection, which is what I'd like to do. The issue I am running into is that my feature filtering step is fairly computationally expensive, and if I select features within a nested CV as is recommended, I end up having to do this computationally expensive step 2500 times (10xrepeated,5-fold CV). To give you an idea of the scale, this would end up taking a 20 core machine ~30 days. While I could spend some effort coding up a method to run this on more processors to speed it up, it would cost hundreds of dollars in compute costs. I have already performed a 10xrepeated,5-fold CV without nested loops for parameter tuning, but I have read that this method can lead to overly optimistic estimates of performance due to optimizing the parameters on the testing data. My question is: Are there any alternatives to nested CV that will allow me to perform less iterations of feature filtering/model building while still evaluating my model? If not, would it be okay to go forward with a normal 10xrepeated,5-fold Cross Validation and just mention in my methods that I did not perform nested CV due to the computational cost?
