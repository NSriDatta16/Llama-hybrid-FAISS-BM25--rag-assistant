[site]: datascience
[post_id]: 62886
[parent_id]: 
[tags]: 
Andrew Ngs Class - Why Did He Change up the Cost Function?

I am taking Andrew Ng's Machine Learning Intro class . Looks like he changed the cost function without any explanation in the second week. Specifically: He no longer squares each deviation between the estimated and the actual value He no longer divides the sum of deviations by 2 (I guess because he doesn't square it, but that leaves the question of why for both He multiplies the whole thing by the first number in the sample for which he is finding the delta between estimated and actual. Why? This image might explain it better for those familiar with the class: Also, which of the two is "correct"? Or if there is no "correct" answer, what is the use case for each?
