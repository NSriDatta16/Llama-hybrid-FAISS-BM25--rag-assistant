[site]: crossvalidated
[post_id]: 229215
[parent_id]: 
[tags]: 
Why is this activation function nonlinear in the parameters but linear in the variables?

I am taking a course on machine learning. My textbook says that a certain category of activation function of the following form, are linear in the variable vector x, but nonlinear in the parameters: y(x) = f(w^T x + w0) Why is the function nonlinear in the parameters but linear in the variables, even though in the above equation we can just substitute the variables with the parameters without changing the functional form? here is the relevant excerpt: f( · ) is known as an activation function. [...] The decision surfaces correspond to y(x) = constant, so that wTx + w0 = constant and hence the decision surfaces are linear functions of x, even if the function f(·) is nonlinear. [...] Note, however, that in contrast to the models used for regression, they are no longer linear in the parameters due to the presence of the nonlinear function f(·) .
