[site]: crossvalidated
[post_id]: 354504
[parent_id]: 196670
[tags]: 
Coding the targets as $\{0.1, 0.9\}$ is an example of label smoothing. It's one of the tricks highlighted in this review and it appears to originate in " Rethinking the Inception Architecture for Computer Vision " by Christian Szegedy et al. as a certain kind of regularization. It's used as a regularization strategy to discourage a neural network from giving over-confident predictions in the outcome, because the predicted probabilities cannot be improved by becoming arbitrarily close to 1 for the true class; instead, the lowest loss value occurs at 0.9 for the true class. The standard approach is to not use label smoothing. When we estimate a logistic regression (a 0-hidden layer neural network with sigmoid activations on the last layer), we never do this; the problem is left "as is" for Newton's Method to solve. Provided that the usual conditions are satisfied (design matrix is full-rank, perfect separation is not present), we have no problem estimating the regression coefficients. Likewise, neural networks trained on binary problems proceed in the same way! Nonlinearities and multiple layers make the optimization more challenging, but the core concept is the same. However, neural networks are more flexible models, and are able to find more complex relationships compared to logistic regression. This means that they are also more prone to giving uncalibrated outcomes (the predicted probabilities do not strongly correspond to the true probabilities), a trend that is remarked upon in " Your classifier is secretly an energy-based model, and you should treat it like one " by Will Grathwohl, et al. (which also has citations to other papers making similar observaitons).
