[site]: stackoverflow
[post_id]: 4937432
[parent_id]: 4936620
[tags]: 
Lets see: It's not so clear form your question, but I'm assuming now that you'll like to improve significantly this kind of averaging. import numpy as np from numpy.lib import stride_tricks as st def mf(A, k_shape= (3, 3)): m= A.shape[0]- 2 n= A.shape[1]- 2 strides= A.strides+ A.strides new_shape= (m, n, k_shape[0], k_shape[1]) A= st.as_strided(A, shape= new_shape, strides= strides) return np.sum(np.sum(A, -1), -1)/ np.prod(k_shape) if __name__ == '__main__': A= np.arange(100).reshape((10, 10)) print mf(A) Now, what kind of performance improvements you would actually expect? Update: First of all, a warning: the code in it's current state does not adapt properly to the 'kernel' shape. However that's not my primary concern right now (anyway the idea is there allready how to adapt properly). I have just chosen the new shape of a 4D A intuitively, for me it really make sense to think about a 2D 'kernel' center to be centered to each grid position of original 2D A. But that 4D shaping may not actually be the 'best' one. I think the real problem here is the performance of summing. One should to be able to find 'best order' (of the 4D A) inorder to fully utilize your machines cache architecture. However that order may not be the same for 'small' arrays which kind of 'co-operates' with your machines cache and those larger ones, which don't (at least not so straightforward manner). Update 2: Here is a slightly modified version of mf . Clearly it's better to reshape to a 3D array first and then instead of summing just do dot product (this has the advantage all so, that kernel can be arbitrary). However it's still some 3x slower (on my machine) than Pauls updated function. def mf(A): k_shape= (3, 3) k= np.prod(k_shape) m= A.shape[0]- 2 n= A.shape[1]- 2 strides= A.strides* 2 new_shape= (m, n)+ k_shape A= st.as_strided(A, shape= new_shape, strides= strides) w= np.ones(k)/ k return np.dot(A.reshape((m, n, -1)), w)
