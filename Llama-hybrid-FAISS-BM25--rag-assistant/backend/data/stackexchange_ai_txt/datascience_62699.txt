[site]: datascience
[post_id]: 62699
[parent_id]: 
[tags]: 
Results are too good.. what is wrong? How to predict correctly?

I am about to evaluate a neural network and want to check whether the predictions make sense. The variables: X_train1.shape > (1700, 2) X_val1.shape > (339, 2) X_test1.shape > (701, 2) hold in [:, 0] the x-values (in this case time formats respectively hour-values) and in [:, 1] the corresponding y-values (in this case current values): X_train1[0:3] > array([[-1.72694903, 0.63332341], [-1.71673039, 1.00769389], [-1.70651176, 1.14177968]]) You can't see time formats in the first column because I had to convert the time formats to numeric values according to df_train1["timestamp"] = pd.to_timedelta(df_train1['timestamp']).dt.total_seconds() Beware that I want to make use of an AutoEncoder , where X=Y : y_train1 = X_train1 and visually: First, I search the best hyperparameters: grid_result = grid_obj.fit(X_train1, y_train1) Then I use the best parameters: grid_best = grid_result.best_estimator_ Now I want to predict: prediction = grid_best.predict(X_test1) in principle this works but I get way too good results though I can see deviations. But I wonder if my concept is meaningful. For example, all the time before, I used predict() to predict new y on X . When I try to do the same above, means: grid_best.predict(X_test1[:, 0]) I receive: Error when checking input: expected input_152 to have shape (2,) but got array with shape (1,) These are the results: I train on a period of time of 3 months and predict on 1 month. Why I think that's too good is because I only use five neurons here: (Input 2, latent space 1, output 2). When I use six neurons, it is almost perfect..
