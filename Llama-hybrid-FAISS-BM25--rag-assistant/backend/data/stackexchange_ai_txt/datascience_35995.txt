[site]: datascience
[post_id]: 35995
[parent_id]: 35953
[tags]: 
Do I understand correctly that you do actually have the data for all segments? Or do you only have the mean and standard deviation of each subset? In this case, it is possible to compute the estimate standard deviation over the entire collection of subsets! As is explained in the second answer to that question on CrossValidated (and as you noted), computing the mean over your entire segment is as simple as taking the mean of the means i.e. the simple average of all your $\mu$-values. If the former is true (you have all the data), then it is possible to compute the variance (i.e. the standard deviation squared) of the combined data, in a similar way in which you compute the mean. Think about what it means to compute the sample variance. In words: First compute the mean of the population. Next, sum up the squared difference between every single sample and the population mean. Divide this by the number of samples in the population (minus 1). The formula is as follows: $$\bar{\sigma}^2 = \frac{1}{N - 1} \sum_{i=1}^{N} (x_i - \bar{\mu})^2$$ where $\bar{\mu}$ is the sample mean (over one of your subsets) and $\bar{\sigma}^2$ is the sample variance (over one of your subsets). Have a look at this answer on Math Overflow . To scale up the variance estimate over multiple subsets, however, you must account for the difference in variances between groups. The way we can do this is to use the mean of the global population $\mu_{global}$ (over all your subsets). Imagine two of your subSegments are $A$ and $B$, then the formula to compute the aggregated variance would be: $$\sigma_{A+B}^2 = \frac{1}{N - 1} \left( \sum_{i=1}^{N_A} (A_i - \mu_{global})^2 + \sum_{i=1}^{N_B} (B_i - \mu_{global})^2 \right)$$ where the $\mu_{global}$ is what you already compute, the average of the means, here it'd be: $$\mu_{global} = \frac{1}{2} (\mu_A + \mu_B)$$ To get the standard deviation, just take the square root of the $\sigma_{A+B}$ value above. To relate this back to the description of the variance computation above, all we are changing now is the mean value that we are subtracting! If you are curious as to why we divide by $N-1$ when computing averages here: it helps ensure the estimate we compute is not biased. It is called Bessel's correction . One downside, is that it will increase the mean squared error of the estimate you compute, which becomes clear when you think about a tiny subset of data, where that $-1$ makes a large impact.
