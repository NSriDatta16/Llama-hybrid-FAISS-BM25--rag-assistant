[site]: stackoverflow
[post_id]: 4288690
[parent_id]: 4178166
[tags]: 
As you've pointed out, this is pretty much impossible in the manner in which you're hoping. Depending on the larger context of your situation, you have some options. In fact, that article gives you some help. Here are some ideas that come to mind when I read that article: Embed the filter criteria in your text Check out the "Consider embedding filter conditions as keywords in the indexed text" bullet in the article. This essentially says you could consider putting your date as an easily-locatable string in the text. E.g., " " Something you can strip out before processing the text. Probably not great for ranges, though the workaround for this is a coarser grained filter term. I.e., instead of DateAdded:YYYYMMDD, use WeekAdded:YYYYWW, then you're pulling 7-14 days' worth off FTS and your added_date predicate can further narrow it. Probably stops being practical well before 100 search terms. Adding a filter criteria means running an update to add it to all 7m+ records Otherwise, this seems closest in spirit to what you are after Two tables - horizontal partition If you chiefly look back only a few days, you can try simply keeping a second table with FTS with only the last n days of records. May be a PITA to maintain. Two tables - vertical partition Split your table into 1 with the values you're going to filter by in SQL and another with the FTS text. Then use CONTAINSTABLE to bring them together. You are still doing 2 table hits. The one benefit, though, is that your reduced table will be tighter, with more records per page, allowing less IO. Admittedly, this improvement might not even be noticeable. And for all that a covering index might be as good. Live with it Do you have the performance numbers to show that this double-read is resulting in a big loss in performance? Assuming your PK is Do any of these work for your particular situation?
