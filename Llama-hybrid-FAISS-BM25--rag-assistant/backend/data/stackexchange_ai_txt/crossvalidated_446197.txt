[site]: crossvalidated
[post_id]: 446197
[parent_id]: 
[tags]: 
Approximating the number of lines in an arbitrarily large file and calculating error/confidence?

First off, let me know if this is in the wrong stack exchange I wasn't sure where exactly to ask this. Okay so I came up with a scheme to figure out how to how many lines are in an arbitrarily large file: Sample X number of random lines from a file Find the average length (size in bytes) of the sampled lines (i.e. bytes of sample / X ) Find the number of lines in the file using the approximated average length (i.e. bytes of entire file / avg bytes per line) So basically, how can I figure out what the the error is and how accurate this strategy is? And is there a way to figure out what X should be? Thanks so much and sorry if I'm butchering terminology! EDIT: Got rid of the previous edits that got this question a little off topic.
