[site]: crossvalidated
[post_id]: 397058
[parent_id]: 396829
[tags]: 
Why does penalising larger values of $W$ affect the "bias/variance trade-off" of a model? Could someone give me an intuitive explanation for why we would prefer smaller values of $Wij$ and why it's relevant to the bias/variance trade-off? A penalty term is generally an hyper-parameter of the model -- a larger penalty term reduces the complexity of the resulting function . A common example is weight decay used with neural networks and linear regression also known as ridge regression -- in that case the $L_2$ norm of the parameters are added to the loss function, which basically leads to smaller parameter magnitudes. In terms of neural networks -- increasing the penalty term i.e. increasing the weight decay hyper-parameter corresponds to reducing the effective capacity by forcing the solution to be in a zero-centered hyper-sphere of smaller radius -- which may improve generalization . Improvement in generalization can be seen as decrease in the expected error from the model -- which is composed of bias, variance and irreducible error. So, basically you trade an increase in bias for decrease in variance, hopefully more decrease on the variance side -- don't underfit! For some intuition: Bayesian interpretation: A regularization term can also be interpreted as an a-priori probability distribution on $F$ -- a set of functions from which one can be picked to minimize the expected generalization error of the chosen function-- in which case the weight decay is a scale parameter (inverse variance) of that distribution. And, by varying the scale you can make the distribution more concentrated or more dispersed.
