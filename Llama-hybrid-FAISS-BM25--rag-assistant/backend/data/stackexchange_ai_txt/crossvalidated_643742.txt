[site]: crossvalidated
[post_id]: 643742
[parent_id]: 
[tags]: 
Normalization of time-series data with time-varying variance

I'm building a neural network (CNN) model for a regression problem with time-series data. Both input and output are multi-variate zero-mean timeseries data with time-varying variance. Currently, I am normalizing manually using a scale and shift approach such that the input and output data is between [0, 1], since I know the maximum values that usually occur in the data. Since the data contains spikes, I cannot apply the classical min/max scaling approach as it would shift the samples to different means. However, I wonder whether there is a better normalization approach that takes into account that the data has a time-varying varying standard deviation/variance. Since input examples can have different lengths and variance, the network might struggle to predict to the correct output distribution.
