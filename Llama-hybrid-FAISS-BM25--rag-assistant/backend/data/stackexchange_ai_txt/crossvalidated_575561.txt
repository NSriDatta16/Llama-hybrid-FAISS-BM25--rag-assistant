[site]: crossvalidated
[post_id]: 575561
[parent_id]: 573336
[tags]: 
The purpose of Bayesian optimization is to find global minima of functions that have many local minima. More typical optimizers are "local," in the sense that they follow some procedure until they find the gradient is zero, and then stop, whether or not there is an even lower value elsewhere. Almost immediately, this simple statement of the problem exposes the core tension that Bayesian optimization is designed to navigate: We might exploit our current best estimate to find a better function value nearby our current "best estimate" of the lowest value; alternatively, we might explore a region far away from what we've already visited to find a better value -- but these locations are the ones where we have the least information. This is really no different than deciding what to make for dinner. You could make the same meal you made last night, and it would probably be about as enjoyable. Alternatively, you could experiment and make a new meal, but that's a gamble. It could be better, or it could be worse. If you want to optimize your enjoyment of dinner, you're immediately confronted with a choice about whether you want to do something reliable or take the chance that you might be able to make something better (but, by the same token, it might be worse). Gaussian processes are flexible in that they can exactly interpolate the observed data, but they also reflect increasing uncertainty about the function value as you move away from the observed values. (GPs are a prior over functions, so the further you move from observed data, the more the behavior becomes dominated by the prior.) If we don't ever explore areas that are far away from our current best estimate, then it's possible that we're skipping over the optimal portion of the space. Moreover, the surrogate function we estimate using the GP and the observed data is not going to be a perfect representation of the true function under optimization. Especially early in the optimization procedure, the minimum identified in the surrogate is unlikely to correspond to the minimum of the true function. The purpose of the acquisition function is to assign a numerical value that will govern the tradeoff between exploration and exploitation. We want that numerical value to both incorporate the local information about our estimates of the function values, and our uncertainty about those estimates. The acquisition function tells us which function inputs are the most valuable to visit. Because acquisition functions are designed to be cheap to compute and reflect the uncertainty of the surrogate model's estimates, it summarizes the value and uncertainty estimates from the GP into a single value. Since your bounty asks for an authoritative source, here's a quote from a peer-reviewed publication: Using the Gaussian process model, an acquisition function is constructed to represent the most promising setting for the next experiment. Acquisition functions are mainly derived from the $\mu(x)$ and $\sigma(x)$ of the GP model, and are hence cheap to compute. The acquisition function allows a balance between exploitation (sampling where the objective mean $\mu(\cdot)$ is high) and exploration (sampling where the uncertainty $\sigma(\cdot)$ is high), and its global maximizer is used as the next experimental setting. from S. Greenhill, S. Rana, S. Gupta, P. Vellanki and S. Venkatesh, " Bayesian Optimization for Adaptive Experimental Design: A Review ," in IEEE Access, vol. 8, pp. 13937-13948, 2020, doi: 10.1109/ACCESS.2020.2966228. The whole article is very accessible and worth reading if you're interested in Bayesian optimization.
