[site]: datascience
[post_id]: 101868
[parent_id]: 
[tags]: 
Reducing Validation loss for Triplet Loss Embeddings

I'm trying to create a facial recognition detector using triplet loss followed by a kNN algorithm. I have roughly 10000 input images with 3 different classes, input size is 80x80. Model structure uses resnet with imagenet weightings, followed by a few dense layers for embeddings: base_cnn = resnet.ResNet50( weights="imagenet", input_shape=image_input_shape, include_top=False ) trainable = False for layer in base_cnn.layers: layer.trainable = trainable x = Flatten()(base_cnn.output) x = Dense(128, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) output = Dense(embedding_size)(x) embedding = Model(base_cnn.input, output, name="Embedding") The problem is that the training loss is small, but the validation loss is barely decreasing (if at all): I assume this is due to overfitting, however I've added in everything I can think of to prevent this (dropout, regularisation and I've played with the learning rate). I'm guessing that the dataset size is the problem, but hoped by using transfer learning I'd be able to get decent results with this dataset. Any suggestions on how to interpret this, and how to improve validation loss? Thanks in advance.
