[site]: crossvalidated
[post_id]: 625788
[parent_id]: 
[tags]: 
Correct statistical test to model user preferences among multiple models

My problem involves comparing the performance of machine learning models to how good each model's recommendation is. The way I'll design the experiment is as follows: I'll send out a form to multiple people. Ask them which model's recommendation they like out of the four options. Store the data somewhere. Do statistical analysis to declare which model is better. I have the data as shown above (I manually created this on google sheets). This is toy data which will later come from an actual data collection process as described previously. You see that there are four models and each model has gotten votes from a total of 20 users (NOTE: each user is asked to vote on four models). The total number of votes adds up to 100 because the form provides each user with a list of 100 'trials' to vote on. The data that you see here is artificial and therefore you might see some bias in the data (because I manually entered the numbers). My question and thought process. I think the right test to use here is the kruskal-wallis because I'm not assuming the data follows a distribution and I have multiple collections for each model from many users. I could also use a chi-squared test for independence which uses the totals of the votes for each model to calculate a p-value. Besides these two tests, can I use other tests that might fit the problem setting? I understand that choosing any of the above will NOT tell me which of the models is 'better', but will tell me that there's a significant difference among these models. Assume that I have established a significant difference that exists using any of the above two tests, How do I get the 'best' model? As far as I understand, I need to compare two groups at a time, and maybe use a t-test or something like that but I want to know what my options are. If more information is needed, let me know :)
