[site]: datascience
[post_id]: 57326
[parent_id]: 
[tags]: 
How to use a ragged tensor with a convolutional layer?

I have textual data of various lengths for which ragged tensors seems well suited. For instance my data could look as follows : x = tf.ragged.constant([[1,2,3,4,5,6,7], [5,6,1,2]]) I would like provide this ragged tensor to a model composed by some convolutional filters, let's say at least one filter as follows : model = Sequential([Embedding(alphabet_size, embedding_dim), Conv1D(filters=10, kernel_size=10), GlobalMaxPooling1D()]) I tried to use tf.ragged.map_flat_values however I am not sure that it does what I would like, i.e : embedding each text line of the batch, convolving it, and then taking the max over each text line. Is there a workaround to make this model work on (very) variable lengths texts (except of course using 3d tensors batches)?
