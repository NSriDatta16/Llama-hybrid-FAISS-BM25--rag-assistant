[site]: crossvalidated
[post_id]: 483764
[parent_id]: 
[tags]: 
Neural Network: Matlab uses different activation functions for different layers - why?

I have trained on matlab an Artificial Neural Network with one input layer, one hidden layer and one output layer (my output is values between zero and one, which I turn into 0 or 1 according to a treshold of 0.5). I have noticed that, by default , matlab used the 'tansig' transfer function for the hidden layer and then 'logsig' transfer function for the output layer . Can anyone give me an explanation for this? Thank you in advance!
