[site]: crossvalidated
[post_id]: 64873
[parent_id]: 64856
[tags]: 
It sounds like what you're trying to achieve in this problem is unsupervised feature based clustering, where each of your 10 "dimensions" (AKA features) are observed in a sample of individuals. This is often used to form recommender systems, such as in the Netflix data where each feature was a movie rating and each row was a viewer. The goal of such models is to predict one or more features in a randomly observed individual for which some subset of features are observed. You'd be surprised how often Euclidean based distance functions are used to create predictions from such data, as is the case with SVD and PCA. Conversely, a dearth of less obvious clustering algorithms have proven to be useful despite not giving any explicit distance measures. In both cases, models are usually validated using measures of classification accuracy (PPV, Sens/Spec eg) in split sample validation. So if you use distance to measure prediction uncertainty, it will not tell you much.
