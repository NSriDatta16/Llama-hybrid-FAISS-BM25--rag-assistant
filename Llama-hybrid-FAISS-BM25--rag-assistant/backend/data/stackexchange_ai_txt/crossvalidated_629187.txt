[site]: crossvalidated
[post_id]: 629187
[parent_id]: 
[tags]: 
Encoder-decoder Transformer model makes outputs predictions almost perfectly but fails to autoregressively decode

The model's sample predictions that I'm printing during training are almost perfect but the model generates meaningless tokens during evaluation. For training I'm feeding it the source and target sequences as was introduced in the original paper, and for autoregressive decoding I'm feeding a source sequence and a BOS token as the target input (the targets during training and both inference start with BOS tokens). The specific code I have looks like this: # Specific code used during training inside a loop. batch["src"] = batch["src"].to("cuda") batch["tgt"] = batch["tgt"].to("cuda") output = model(**batch) loss = criterion( output.view(-1, args.vocab_size), batch["tgt"].view(-1).long() ) step_loss += loss.item() epoch_loss += loss.item() loss.backward() optimizer.step() output_probs = F.softmax(output, dim=-1) predictions = torch.argmax(output_probs, dim=-1) # Evaluation and autoregressive decoding. def decode_autoregressive(model, src): outputs = torch.ones(size=(src.shape[0],)).reshape(-1, 1) * 2 if torch.cuda.is_available(): src = src.to("cuda") outputs = outputs.to("cuda") generation_mask = torch.ones(size=(src.shape[0],), dtype=torch.bool).to(src.device) for _ in range(src.shape[1]): prediction = F.softmax(model(src, outputs), dim=2) prediction = torch.argmax(prediction, dim=2)[:, -1] eos_idxs = prediction == 3 generation_mask[eos_idxs] = False prediction[~generation_mask] = 0 outputs = torch.cat((outputs, prediction.view(-1, 1)), dim=-1) return outputs[:, 1:] The logic of the decoding is that if the EOS token is output, then we'll replace any subsequent outputs with the padding token. I'm creating a causal mask inside my Transformer model. What could be some potential problems? I'm searching the web and am under the impression that my training itself may not be optimal and there may be a discrepancy between training and evaluation but I'm not sure.
