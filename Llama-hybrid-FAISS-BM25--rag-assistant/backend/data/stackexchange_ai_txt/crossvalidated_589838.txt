[site]: crossvalidated
[post_id]: 589838
[parent_id]: 
[tags]: 
Connection Between Bayesian Prior and Variable Selection in Lasso

I am interested in learning more about the Bayesian interpretation of the Lasso model. The Lasso model assumes a Laplace distribution of coefficients and the optimal coefficients maximize the posterior distribution. However, it is not clear to me why a Laplace prior would do feature selection, compared to a Normal prior in Ridge regression. They both put a large mass at zero. But the difference is that the Laplace prior is not smooth at zero. But why this property would do feature selection?
