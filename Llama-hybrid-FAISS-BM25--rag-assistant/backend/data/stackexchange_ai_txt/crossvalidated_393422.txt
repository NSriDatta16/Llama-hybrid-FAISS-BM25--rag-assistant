[site]: crossvalidated
[post_id]: 393422
[parent_id]: 
[tags]: 
Retuning hyperparameters of the baseline when comparing it with a new model

I have a baseline model which has certain hyperparameters to tune (it's actually a neural network, but I don't know if it's important in this context). I want to compare it with my own extension of the baseline model, which is built on top of it and has some additional hyperparameters to tune. Should I tune baseline parameters when evaluating the baseline and tune both types of parameters (baseline + specific for the extension) when evaluating my new model? Or should I "freeze" the best set of baseline parameters taken from the first evaluation when evaluating the new model and tune only the specific ones?
