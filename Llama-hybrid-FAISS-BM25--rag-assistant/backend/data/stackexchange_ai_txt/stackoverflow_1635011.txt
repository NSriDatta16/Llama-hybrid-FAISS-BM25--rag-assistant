[site]: stackoverflow
[post_id]: 1635011
[parent_id]: 1634995
[tags]: 
There's no quick one sentence explanation. Quick sort is actually O( n 2 ) in the worst case but it is O( n log n ) on average, so if you try to analyze it you will not be able to prove that it is always O( n log n ). It is only O( n log n ) on average , averaged across all possible data sets. For any particular list it might be worse. If the pivots end up being really, really bad then quick sort will perform very badly. This can happen on already sorted data, for instance, if you always choose a fixed element at the beginning or end of the array as the pivot element. Other sorting algorithms like merge sort and heap sort, on the other hand, are always O( n log n ). They do not have pathological cases where their performance degrades to O( n 2 ). This makes them preferable if what you desire is consistent, predictable performance at all times. The advantage of quick sort is that is overall a faster algorithm on average, just not always so. Edit : Indeed, as @pst says, merge sort requires O( n ) space when sorting arrays (scratch space for the merges), which is less than ideal. That's a point against it. But then another point against quick sort is that it is an unstable sort. Elements that are equal to each other may be shuffled around after the sort. Timsort is an awesome new search algorithmâ€”well, less new, more a great combination of existing algorithms plus a lot of fine tuning and clever optimizations (the galloping thing is money). Read that text file for a glimpse of Great Programming.
