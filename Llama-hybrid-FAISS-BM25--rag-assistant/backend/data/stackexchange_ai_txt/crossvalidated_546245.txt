[site]: crossvalidated
[post_id]: 546245
[parent_id]: 
[tags]: 
Conceptual questions about standardization/preprocessing

I have a datset consisting of: float column (seems like continuous variable with some outliers in range $[1000, 20000]$ . I plotted its density curve, looks like close to normal) integer column (seems like discrete variable with range in $[0, 100]$ . categorical column with categories like $"x . Note that these categories have a natural order. another categorical column with a total of 4 categories, but the categories here are simple labels, which don't have any natural order. target column is binary (0/1) I'll try to fit KNN on this dataset but before doing that, I have the following conceptual concepts on data preprocessing: I'm definitely going to standardize the float column (subtract mean and divide by standard deviation) Should I standardize the integer column? If I do this, then it would change from integer to float column. This is where I'm struggling to understand whether or not it is justified to touch this column. How do I treat the first categorical columns where categories have natural order? How do I translate the categories $"x or $"10 \leq x so that I can feed it into sklearn's KNeighboursClassifier ? I'm going to do one hot encoding for the second categorical column, because I couldn't find anything better. Note that before preprocessing my data, I'm going to train_test split it. So after training my model, how should I evaluate it on my test set. Will it be fine if I use the same mean/std obtained from train set to scale the float column of the test dataset, and treat the categorical columns of test set the same way I did for train set? Please help me with these doubts as I'm a beginner in Machine Learning.
