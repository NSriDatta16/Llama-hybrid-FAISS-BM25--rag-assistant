[site]: datascience
[post_id]: 66759
[parent_id]: 
[tags]: 
Assistance needed on what machine learning approach to use

I'm currently writing my Master's Thesis on Subjective tagging of sounds and I feel that I've been stuck with the same problem for quite a time now and need assistance to progress. I'll, in short, describe my goal and what I've accomplished so far. I'm writing a program that lets users manually tag audio files with a single label according to their own, i.e. subjective , perception. The tags are always adjectives , like happy , spooky or spacy . The goal is to have the program automatically tag similar sounds with the correct label by finding related sounds using machine learning. The program currently looks like this: Usage of the program goes like this: The user adds sounds to be labeled. The program analyses the files and searches for related sounds using Algorithm 1 . The user tags a sound and the program automatically tags related sounds using Algorithm 2 . The user can verify tags given by the program and choose to accept them or give the sound a new tag. Repeat from step 1 or step 3. By looking at the program flow above I've been able to implement step 1 using AudioCommons Timbral Models to convert sounds to a usable data format, and step 2 with Algorithm 1 using Mean shift to find groups of related sounds. The idea is to use the groups found by Algorithm 1 as a starting point when no tag has yet been given to a group. When one of the sounds in the group is tagged, all the sounds receive the same tag. My problem, however, lies in step 3 with Algorithm 2 and step 4. I've tried a few different approaches, but they all seem a bit off and not quite fit for the job. My goal is to have the program continuously or recursively learn from user validation, hence improving over-usage. My thought process is to have a verified flag on each sound, which the user can use to say if a tag given to a sound by the program is correct or not. Algorithm 2 should (re)learn from verified sounds in step 4 so that when step 3 is repeated, the automatic tagging of sounds done by the program is more accurate according to the user's choices. So my question is: What kind of algorithm(s) is suitable for step 3 and 4 in place of Algorithm 2 ? I've tried to make myself as clear as possible, but I'm quite new to machine learning, so feel free to point out confusing sections or errors. In hope of assistance, Andreas Notes: I've used tag and label interchangeably throughout the text; they refer to the same thing. I want all machine learning to occur in isolation for a user, i.e. I don't want to learn from other user's input (like Collaborative filtering ).
