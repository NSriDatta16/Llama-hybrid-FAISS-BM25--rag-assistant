[site]: crossvalidated
[post_id]: 625744
[parent_id]: 625741
[tags]: 
Fisher's method for independent p-values works like so : back-calculate the chi-square test statistic that would have produced such a value, sum these chi-square values together, and recalculate the p-value according to the new chi-square distribution with updated degrees of freedom: i.e. $2k$ or two times the number of tests. Let's see if we can replicate Python's result. > x x [1] 9.21034 > pchisq(x, lower.tail = F, df=4) [1] 0.0560517 Based on a quick read of this, one should not view Fisher's combined $p$ as a method to pool results, even if the inference is described as a kind of meta-analysis (note: pooling and meta-analysis are also, in fact, overlapping but distinct methods). The Fisher method reduces a lot of $p$ -values to one $p$ -value which is interpreted as a simultaneous test, a kind of way to reduce FDR (false discovery rate). $p means at least one null hypothesis is false. If all null hypotheses are true, we expect Fisher's combined $p$ will still conserve the nominal alpha level of the test. If the first sample is very consistent with the null hypothesis, it will drag attenuate the combined $p$ -value. This seems intuitive with the test description. You could explore the operating characteristics of using $$\text{sup}_{i; i \le k) (p_i)$$ as a combined $p$ -value. But I doubt this would have a well conserved false positive error rate. I don't think I can understand how a $p$ would get more precise except if what you are looking for is a kind of pooled test.
