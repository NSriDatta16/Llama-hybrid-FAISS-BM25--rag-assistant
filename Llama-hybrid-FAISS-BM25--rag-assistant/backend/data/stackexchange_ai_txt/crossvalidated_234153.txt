[site]: crossvalidated
[post_id]: 234153
[parent_id]: 219815
[tags]: 
Typically, the population statistics are taken from the training set. If you include the test set, at test time, you will have information that technically, you shouldn't have access to (information about the whole dataset). For the same reason, the validation set shouldn't be used to compute those statistics. Keep in mind that due to the fact that batch-normalization isn't only at the input layer, the population's statistics will vary from epoch to epoch, as the network learns and changes its parameters (and therefore, its outputs at each layer). Therefore the common way to compute these statistics is to keep a (exponentially decaying or moving) averages during training. This will smoothen out the stochastic variations due to mini-batch training, and stay up to date to the current status of learning. You can see an example of this in the torch code for batch norm : https://github.com/torch/nn/blob/master/lib/THNN/generic/BatchNormalization.c#L22 The paper mentions that they use moving averages instead of just keeping the last computed statistics : Using moving averages instead, we can track the accuracy of a model as it trains. For your second question, they are saying that they use that unbiased estimate to estimate the population variance (for future inference).
