[site]: datascience
[post_id]: 9827
[parent_id]: 
[tags]: 
Is there an appropriate sequence of parameters to be considered when building a pipeline in Scikit learn?

DISCLAIMER: I understand this could be considered a subjective type of question, but I'm hoping it is specific enough to not be flagged. Please give it a chance. I am doing a GridSearch in scikit-learn on a corpus of 50 books (all kinda average commercially published texts...each ~200 pages of text). As I began playing with GridSearch, I got to thinking. Surely there must be some sort of 'best practices' for building a pipeline? Sure, I can include and remove parameters, but I'm really just sorta stabbing around in the dark for the best score. Possibly, it could make sense to create a smaller, exploratory pipeline using the larger, more effective parameters first. After running this basic pipeline, more parameters that have a smaller effect (in general) could be run next. For example, say I'm GridSearching a TfidfTransformer. I am assuming that flipping the use_idf switch on or off is going to make a real impact on the scoring, whereas perhaps specifying alpha=0.000010 versus alpha=0.000015 won't. In general, when using a pipeline, is there an alternative to "throw in the kitchen sink" that results in a more cognizant, informative (and possibly faster) experience?
