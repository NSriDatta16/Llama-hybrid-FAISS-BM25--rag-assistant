[site]: datascience
[post_id]: 16235
[parent_id]: 
[tags]: 
In text classification, how can I use a neural network on word embeddings?

I have read some papers on text classification but they are pretty abstract. I fail at understanding how to train a multi layer perceptron with data made of sentences -> label. A perceptron takes a vector input of size m and outputs a vector. As a first step I reduced the dimensions and I map each word to a vector of n features, where n is a constant. Now how do I mix the words in a sentence to make an input of size m ? Each word maps to a vector of size n but then what ? Knowing that every sentence has a different number of words. Thanks
