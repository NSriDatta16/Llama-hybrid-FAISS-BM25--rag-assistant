[site]: crossvalidated
[post_id]: 395154
[parent_id]: 394454
[tags]: 
The data drives the parameters of the neural networks towards a task. So I think, when you alter your dataset, the solution in parameter space is converged to a distinctively. In your case, you had 200 features originally, that would have perfectly captured the variation in the data. But, when you selected only 100 features, without checking their importance in the dataset, your model would not perform better. The loss values indicate the same in your case. I would suggest, trying PCA and get first 100 features ranked by the variance explained. In that case, you may see a better loss than 0.3. But it could still be more than zero. Assuming all other network settings are the same.
