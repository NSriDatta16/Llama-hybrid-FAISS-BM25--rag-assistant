[site]: datascience
[post_id]: 86327
[parent_id]: 
[tags]: 
Understanding of number of cells in layers of sequential models

I am trying to teach myself RNN, but I have a question. And so, imagine 2 layers: an input layer with three neurons $(x1, x2, x3)$ and a classic recurrent layer with 2 neurons and an activation function f. I will write out the outputs of each neuron of the recurrent layer. $ht1 = f (W * [x1, [0, 0, N]] + b) ht2 = f (W * [x2, ht1] + b)$ . It turns out that $x3$ is not used, what to do in this case? And also, let's imagine a slightly different RNN architecture. An input layer with two neurons $(x1, x2)$ and a classic recurrent layer with 3 neurons and an activation function f. I will write out the outputs of each neuron of the recurrent layer. $ht1 = f (W * [x1, [0, 0, N] + bias]) ht2 = f (W * [x2, ht1] + bias)$ . It turns out that the 3rd neuron of the RNN layer is not used, what to do in this case? Please help me figure out how the neural network works in these cases. Thanks! UPD: I realized that i don't know how recurrent neural networks work if number of neurons in recurrent layer doesn't equal(!=) number of inputs I have one thought: number of inputs has to always be equal number of neurons in RNN layer. But code below contradicts with my guess. model = Sequential() model.add(Embedding(maxWordsCount, 256, input_length = inp_words)) model.add(SimpleRNN(128, activation='tanh')) model.add(Dense(maxWordsCount, activation='softmax')) model.summary() That's model for predicting next word.
