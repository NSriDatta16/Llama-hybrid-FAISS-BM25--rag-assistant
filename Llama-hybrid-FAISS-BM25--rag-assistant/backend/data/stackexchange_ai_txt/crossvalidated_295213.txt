[site]: crossvalidated
[post_id]: 295213
[parent_id]: 295206
[tags]: 
I was using Spearman's correlation because the data is not normally distributed. I did it and weirdly, there was a high correlation between one of the variables and the sum, but much lower correlation with the other variables. Can you kindly explain how this is possible? Spearman 's checks the correlations between the ranks, in this case, of some $X_i$ and $\sum_k X_k$ . Suppose one of the variables $X_i$ has much larger magnitude than the others (this could happen, for example, if all of the variables are i.i.d., and then one is multiplied by $1000 n$ ). Then the higher the rank of $X_i$ , the higher the rank of the sum very strongly, but weaker for $X_j$ where $j \neq i$ . Is it good practice to add to a model an independent variable that was created by summing several variables, along with some of the variables, assuming that there is no high correlation between them? This is essentially a form of linear dimensionality reduction. You could just include the variables themselves, and let the model learn whether the sum, as opposed to some other function, is a good feature. Alternatively, if that would be too many features for your instances, you could use some linear feature reduction technique such as PCA or random projections .
