[site]: stackoverflow
[post_id]: 4939092
[parent_id]: 
[tags]: 
Resolving a 'model empty' error in cross-validation for SVM classification when using the CMA Bioconductor package for R

I am using the Bioconductor package CMA to perform internal, Monte Carlo cross-validation (MCCV) on SVM classifiers in a microarray dataset. CMA internally uses the e1071 R package for the SVM work. The dataset has 387 variables (attributes) for 45 samples (observations) which belong to one of two classes (labels 0 or 1; at about 1:1 proportion). All data is numerical with no NAs. I am trying a 1000-iteration MCCV with 15 variables selected for SVM using the limma statistics for differential gene expression analysis. During MCCV, a fraction of the 45-sample set is used for training an SVM classifier, which is then used to test the remaining fraction, and I am trying different values for the training-set fraction. CMA also performs inner-loop validations (3-fold cross-validation within the training sets, by default) to fine-tune the classifiers to be used for cross-validation against the test-sets. All this is done from within the CMA package. Sometimes, for low training-set sizes, CMA shows an error in the console and halts the rest of the code for classification from getting executed. [snip]tuning iteration 575 tuning iteration 576 tuning iteration 577 Error in predict.svm(ret, xhold, decision.values = TRUE) : Model is empty! It occurs even when I use a test other than limma's for variable selection, or use two instead of 15 variables for classifier generation. The R code I use should ensure that the training-sets always have members of both classes. I would appreciate any insight on this. Below is the R code I use, with Mac OS X 10.6.6, R 2.12.1, Biobase 2.10.0, CMA 1.8.1, limma 3.6.9, and WilcoxCV 1.0.2. The data file hy3ExpHsaMir.txt can be downloaded from http://rapidshare.com/files/447062901/hy3ExpHsaMir.txt . Everything goes OK until g is 9 in the for(g in 0:10) loop (for varying the training/test-set sizes). # exp is the expression table, a matrix; 'classes' is list of known classes exp Output for traceback(): 20: stop("Model is empty!") 19: predict.svm(ret, xhold, decision.values = TRUE) 18: predict(ret, xhold, decision.values = TRUE) 17: na.action(predict(ret, xhold, decision.values = TRUE)) 16: svm.default(cost = 0.1, kernel = "linear", type = "C-classification", ... 15: svm(cost = 0.1, kernel = "linear", type = "C-classification", ... 14: do.call("svm", args = ll) 13: function (X, y, f, learnind, probability, models = FALSE, ...) ... 12: function (X, y, f, learnind, probability, models = FALSE, ...) ... 11: do.call(classifier, args = c(list(X = X, y = y, learnind = learnmatrix[i, ... 10: classification(X = c(83.5832768669369, 83.146333099001, 94.253534443549, ... 9: classification(X = c(83.5832768669369, 83.146333099001, 94.253534443549, ... 8: do.call("classification", args = c(list(X = Xi, y = yi, learningsets = lsi, ... 7: tune(grids = list(cost = c(0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50... 6: tune(grids = list(cost = c(0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50... 5: do.call("tune", args = c(tuninglist, ll)) 4: classification(X, y = as.numeric(y) - 1, learningsets = learningsets, ... 3: classification(X, y = as.numeric(y) - 1, learningsets = learningsets, ... 2: classification(t(exp), factor(classes), learningsets = lsets, ... 1: classification(t(exp), factor(classes), learningsets = lsets, ...
