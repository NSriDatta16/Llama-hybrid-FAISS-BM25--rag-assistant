[site]: crossvalidated
[post_id]: 249896
[parent_id]: 
[tags]: 
lsmeans for mixed lmer model - error estimates

I am curious as to why standard error estimates on lsmeans depend greatly on whether certain other factors in a model are treated as fixed or random effects. For example, I have measured the fish species richness (FishTaxa) at different statuses of streams and controlling for Site and Station nested within Site. There are three levels of Status at each station: pre-degradation, post-degradation, and post-restoration, and FishTaxa is measured several times at each Station during each level of Status. I am waffling as to whether Site should be fixed or random. Because I have reason to believe that Sites (2 levels) differ in mean FishTaxa, and I want to know how much, I at first included it as a fixed effect. FishTaxa.1 = lmer(FishTaxa~ Status + Site + (1|Site:Station), data = Restoration) > Anova(FishTaxa1) Analysis of Deviance Table (Type II Wald chisquare tests) Response: FishTaxa Chisq Df Pr(>Chisq) Status 20.752 2 3.117e-05 *** Site 21.199 1 4.140e-06 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 I am mainly interested in the effect of Status, so: > lsmeans(FishTaxa1, pairwise ~ Status, adjust = "none") $lsmeans Status lsmean SE df lower.CL upper.CL Post-degradation 8.58895 1.1493805 40.36 6.266612 10.91129 Post-restoration 12.42125 0.9556837 20.59 10.431366 14.41113 Pre-degradation 12.52084 0.9650306 21.38 10.516134 14.52554 Results are averaged over the levels of: Site Confidence level used: 0.95 $contrasts contrast estimate SE df t.ratio p.value Post-degradation - Post-restoration -3.8322998 0.9055777 163.26 -4.232 Notice the SE column of the lsmeans table. Then I tried it with Site as a random effect: FishTaxa.2 = lmer(FishTaxa~ Status + (1|Site) + (1|Site:Station), data = Restoration) > Anova(FishTaxa2) Analysis of Deviance Table (Type II Wald chisquare tests) Response: FishTaxa Chisq Df Pr(>Chisq) Status 20.774 2 3.082e-05 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 > lsmeans(FishTaxa2, pairwise ~ Status, adjust = "none") $lsmeans Status lsmean SE df lower.CL upper.CL Post-degradation 8.586036 4.189446 1.06 -37.90015 55.07222 Post-restoration 12.417805 4.140499 1.01 -38.63466 63.47027 Pre-degradation 12.522325 4.142663 1.02 -38.30922 63.35387 Confidence level used: 0.95 $contrasts contrast estimate SE df t.ratio p.value Post-degradation - Post-restoration -3.8317698 0.9055658 163.26 -4.231 Notice the lsmeans are virtually identical, but the SE are much larger. And look at those confidence limits! When plotted in a bar graph, the error bars would suggest the differences between levels aren't significant, but they are according to the contrast, which are again basically the same as with Site as a fixed effect. I did notice when Site was included as a fixed effect, lsmeans notifies my "Results are averaged over the levels of: Site". Why would it not do this when it is a random effect? For inference, at least in this example, I get the same result either way, but for displaying the results, those SE and CI are really weird. Help understanding what is going on and the best way to present this would be appreciated.
