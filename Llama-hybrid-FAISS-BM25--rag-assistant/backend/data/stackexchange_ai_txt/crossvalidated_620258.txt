[site]: crossvalidated
[post_id]: 620258
[parent_id]: 618818
[tags]: 
This is an incorrect comparison. The loss, probably crossentropy loss, evaluates the raw predictions made by the model. The accuracy evaluates a two-stage pipeline that first uses the neural network to make predictions and then uses some decision rule to classify those raw predictions into discrete categories, typically a threshold (at least in the binary case). Especially if you go with a software-default decision rule of taking the category with the highest predicted probability, you could wind up with results that seem to contradict each other. In fact, the results do not contradict each other; they just concern different models (one of which has a decision rule on top of the neural network). If you have a good loss value but a poor accuracy value, perhaps consider changing the decision rule for how to use the predictions made by that model with a low loss value. The easiest way to do this is by changing the threshold for classification (at least in a binary problem). A more sophisticated approach would be to use the raw model predictions, which are useful. Frank Harrellâ€™s blog has two good posts explaining why. Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules Classification vs. Prediction Specific to your particular setup, if you do any oversampling (it is not clear that you should) , leave the natural class ratio in the test data (only apply the oversampling to training data).
