[site]: crossvalidated
[post_id]: 360870
[parent_id]: 
[tags]: 
Parameter tuning trick in Reinforcement Learning

In normal deep learning, there requires a lot of training tricks such as inserting a normalization after maxpooling layer or augment the input image by swirling the original input. However, parameter tuning in reinforcement learning is uniquely special for the following reasons: 1) There is no validation set for reinforcement learning. 2) We usually fake target labels in the reinforcement learning, therefore the loss sometimes did not indicate the real training performance. I am wondering what parameter tuning experience you can share in the reinforcement learning task, e.g., the initialization setting, the reward setting, the loss setting, etc.
