[site]: crossvalidated
[post_id]: 118605
[parent_id]: 
[tags]: 
Cross validation with unequal sample size for the left out sets

I am trying to do cross validation on several (20) subsets of samples, which all have unequal sample size. I cannot subsample so that sizes are equal. Example: batch 1: 500 samples batch 2: 400 samples batch 3: 250 samples ... When I compute the likelihood on all but one of these batches, training and testing accuracy will be affected by training and testing sample sizes. I suspect just taking an average of the testing likelihoods will not do. A weighted average may be closer to right, but how to chose the weights? I could weight by test sample size, but that does not take into account the fact that when I have a smaller test set, I train on a larger train set, which makes the learned model more accurate. Any suggestions/references?
