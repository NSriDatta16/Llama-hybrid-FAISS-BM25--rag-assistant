[site]: datascience
[post_id]: 40771
[parent_id]: 
[tags]: 
not quite sure about the difference between RNN and feed forward neural net

I'm a bit confused after reading this paper: https://arxiv.org/abs/1705.09851 on page 22, the author writes response: \begin{equation} Y = softmax(Z^{L-1}) \end{equation} and hidden state \begin{equation} Z^\ell = max(W^\ell *Z^{\ell-1} + b^\ell, 0) \end{equation} which is a relu But, to me, this looks like a regular feed forward neural net- you multiply your input by a matrix, add a bias unit, then activate. Alternatively, your hidden layer is equal to the activation of the sum of a bias and the previous hidden layer times a weight matrix. What am I missing?
