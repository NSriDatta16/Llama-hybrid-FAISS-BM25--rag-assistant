[site]: crossvalidated
[post_id]: 592008
[parent_id]: 52976
[tags]: 
@Zen's answer plus @whuber's comment to @Konstantin's answer provide a complete proof. Nevertheless, I'll rephrase the proof by trying to place more statistical emphasis. Indeed, one can say that the sample covariance matrix $S$ is always positive and semi-definite because it can be seen as the variance of a suitable univariate variable, which is always non-negative. In detail, let $x_1,\ldots,x_n$ be the observed sample, with $x_i = (x_{i1},\ldots,x_{ik})^\top$ , $i=1,\ldots,n$ . The sample covariance matrix is $$ Q = n^{-1}\sum_{i=1}^n(x_i-\bar x)(x_i-\bar x)^\top, $$ where $\bar x=n^{-1}\sum_{i}x_i$ is the sample average. Consider now any vector $a = (a_1,\ldots,a_k)^\top$ and take the $y_i$ , linear combination of $x_i$ with coefficients $a_i$ , i.e. $$ y_i = a^\top x_i = a_1x_{11}+\cdots+a_{k}x_{ik},\quad\text{for all } i. $$ Let $\bar y$ be the sample average of $y_i$ 's and note that $\bar y = a^\top \bar x$ . The variance of $y_i$ is \begin{align*} 0\leq s_{y}^2 &= n^{-1}\sum_i(y_i-\bar y)^2 = n^{-1}\sum_{i}(y_i-\bar y)(y_i-\bar y)^\top\\ & = n^{-1}\sum_{i} (a^\top x_i - a^\top \bar x)(a^\top x_i - a^\top \bar x)\\ & = a^\top\left(n^{-1}\sum_{i} (x_i - a^\top \bar x)(x_i -\bar x)\right)a\\ & = a^\top S a. \end{align*} Since $a$ was arbitrary, this completes the proof.
