[site]: crossvalidated
[post_id]: 257154
[parent_id]: 251892
[tags]: 
1-3) It depends on how you normalize your image dataset. I guess, you will want to use the same normalization for the PCA. 4) Correct. 5) Correct. However, you could experiment with different std's to control the magnitude of the perturbation. Also note that the $a_j$'s are only sampled once for transforming a given image ! Whatever the colour_channel_weights are, they are definitely not the Eigenvalues. Indeed, the Eigenvalues of a covariance matrix are always non negative! To get a feeling for the magnitude of the perturbations constructed in this way, assume for a moment that the colour channels are independently distributed (over the training data). In this case, the Eigenvectors and Eigenvalues are just the RBG-channels and their respective variances. The perturbations $p_R, p_B, p_G$ of the red,blue and green channel respectively, are then given by \begin{align} p_R&=a_1 \cdot(\text{Variance of red channel}), \\ p_B&=a_2 \cdot(\text{Variance of blue channel}), \\ p_G&=a_3 \cdot(\text{Variance of green channel}). \end{align}
