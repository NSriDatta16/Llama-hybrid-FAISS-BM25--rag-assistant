[site]: crossvalidated
[post_id]: 633351
[parent_id]: 
[tags]: 
Metropolis sampling with stochastic estimation of component of probability density

Consider the probability distribution \begin{align} p(x) = \frac{1}{Z} x^2 e^{-x^2 / 2} \end{align} where $x \in \mathbb{R}$ and $Z$ is a normalization factor so that $\int_{-\infty}^{\infty} dx \, p(x) = 1$ . I want to use a Markov Chain Monte Carlo algorithm (e.g. a Metropolis algorithm, for which we don't need to know the normalization factor $Z$ ) to sample from this distribution, but I want to stochastically estimate the $x^2$ factor outside of the exponential by noticing that \begin{align} x^2 = \int \mathcal{D}\phi \; e^{- \frac{\phi^2}{x^2}} \end{align} where $\phi \in \mathbb{C}$ and $\mathcal{D}\phi \equiv \frac{d\Re \phi}{\sqrt{\pi}} \frac{d\Im \phi}{\sqrt{\pi}}$ . Therefore I want to sample from the new joint distribution density \begin{align} p(x, \phi) = \frac{1}{Z} e^{-\frac{x^2}{2} - \frac{\phi^2}{x^2}} \end{align} knowing that expectation values of a function $f(x)$ over $p(x,\phi)$ will be the same as those over $p(x)$ , i.e. $\mathbb{E}_{p(x,\phi)}[f(x)] = \mathbb{E}_{p(x)}[f(x)]$ . The following Random Walk Metropolis algorithm, where I use a normal distribution $\mathcal{N}(0,1)$ to propose the next sample $x'$ of the Markov chain, seems to generate a Markov chain following the correct distribution: Generate $\eta \sim \mathcal{CN}(0,1)$ , where $\mathcal{CN}$ denotes a complex normal distribution. Do a change of variables to set $\phi = x \eta$ where $\phi$ will be constant throughout the Metropolis step. Propose a new sample $x' = x + \epsilon$ , where $\epsilon \sim \mathcal{N}(0,1)$ and $x$ is the previous sample in the Markov chain. Accept the new sample with probability $p_{\text{acc}}=\min \left\{ 1, \frac{p(x',\phi)}{p(x,\phi)} \right\}$ Iterating these steps seems to correctly generate a Markov chain of samples following $p(x)$ : A modification of this algorithm using Hamiltonian Monte Carlo instead of the random walk is used in High Energy Particle Physics, particularly in Lattice QCD simulations, where one needs to stochastically estimate a matrix determinant (which depends on $x$ ) in the same way as we are estimating the $x^2$ factor outside of the exponential in this toy example. The words that are normally used to describe this algorithm are something like "sampling $x$ with an additional background field $\phi$ ". I would like to know if there is a formal way to address this algorithm where part of the probability density needs to be estimated stochastically, and also which conditions are needed for the algorithm to sample correctly from the distribution, maybe giving an intuition of why this should work. I thought it was similar to slice sampling , but doesn't seem to be quite the same thing. Some references would be appreciated as well.
