[site]: stackoverflow
[post_id]: 2455351
[parent_id]: 
[tags]: 
Inserting Large volume of data in SQL Server 2005

We have a application (written in c#) to store live stock market price in the database (SQL Server 2005). It insert about 1 Million record in a single day. Now we are adding some more segment of market into it and the no of records would be double (2 Millions/day). Currently the average record insertion per second is about 50, maximum is 450 and minimum is 0. To check certain conditions i have used service broker (asynchronous trigger) on my price table. It is running fine at this time(about 35% CPU utilization). Now i am planning to create a in memory dataset of current stock price. we would like to do some simple calculations. Currently i am using xml batch insertion method. (OPENXML in Storred Proc) I want to know different views of members on this. Please provide your way of dealing with such situation.
