[site]: datascience
[post_id]: 87783
[parent_id]: 
[tags]: 
How to detect misclasification data after multiclass classification?

I have trained a neural network multi-class classification model with around 150 classes having around 85% accuracy. Once the model is trained and deployed, it's predicting on new data and I am saving the logs. Now I have to detect those data-points which is wrongly predicted by the model. For example, The model predicted on 10 data-points, out of which there might be 3 data-points which are wrongly classified by the model. Is there any way to get those data-points? I have the following data. The deployed model. The data-points. Corresponding predicted classes by the model. Confidence scores on the prediction. I know that using confidence score I might get some idea on wrong prediction, but I am thinking is there any other way to get that?
