[site]: datascience
[post_id]: 38024
[parent_id]: 
[tags]: 
Making inferences from incomplete data

I have data which have complete information. Each record has one class assigned. On production, I won't be able to get so many information from a user, so I want to create a model which will be able to make inferences from incomplete data and making more and more reliable predictions with getting more information from a user. For Example: Say, Training data - 200 binary features, In rows in average 11 of them are marked as 1, another 189 as 0. Production - We give our user list of features to mark which of them is most common(Let's suppose that user picked 3 of them), then I want to make some inferences and ask good questions to get more accurate predictions. My second problem is that my dataset assumed that user can belong only to one class, whereas in fact user on production can be multi label. Say, in my dataset there is situation that: -class 1 has 5 features annotated as true at random(allways the same), rest always false -class 2 has 5 DIFFRENT features annotated as true at random(allways the same), rest always false Notice, I have a list of possible features for each class, so I can easily calculate conditional probability of class depends on features, so I tried to use Naive Bayes, but my features are not independent. On production can occur situation that user will be in class 1 and 2 and will have some features from class 1 and some from class 2. I want to that my algorithm will figure it out that it is in class 1 and class 2. What algorithm should I use? I was thinking about decision trees, but in that, I cannot give user choice what is the most common for him and in that situation. Thanks in advance for your help!
