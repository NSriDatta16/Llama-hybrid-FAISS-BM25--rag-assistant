[site]: crossvalidated
[post_id]: 264870
[parent_id]: 264863
[tags]: 
This is only a partial answer: Transformation in linear regression can be used to improve model fit if residuals are not normally distributed (e.g. skewed), or if the relationship between predictor and dependent variable is not linear. However, for the latter other modeling strategies exist (quadratic terms, or using non-linear regression) In logistic regression residuals are not assumed to be normally distributed but to follow a binomial distribution. Furthermore, the relationships between predictor and dependent variable is not assumed to be linear, yet the relationship between predictor and the predicted logits is assumed to be linear. Logits are: ln(p(y=1)/(1-p(y=1))) Thus, I would assume that if those assumptions are violated, a transformation might improve model fit the same way as in linear regression. However, that is only my statistical intuition, and I have no prove of that. Furthermore, you can only transform the predictors (the dependent variable has to be binary). A more modern approach would be to use generalized linear models. By this, you can choose the distribution of the residuals freely. Non-linearity can be modeled by including non-linear terms into the model. However, I am not an expert on that topic, but hopefully some of my answers will give you some first hints into the correct direction. ;)
