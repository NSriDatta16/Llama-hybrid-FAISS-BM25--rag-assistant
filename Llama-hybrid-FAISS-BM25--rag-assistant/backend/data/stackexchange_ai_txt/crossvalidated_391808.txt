[site]: crossvalidated
[post_id]: 391808
[parent_id]: 
[tags]: 
Statistically compare which of the two time series data sets is "ahead" of another and how closely they match

We have two data sets which are essentially stock prices of single security as they change throughout the day. As stocks in the US and other countries are simultaneously traded on multiple exchanges during the day, there is a large number of price changes distributed by various exchanges. Millions of such messages are received and processed through the day. The systems built to receive and process these messages are designed to make sure the systems are very quick to process this information. Due to the extremely large number of messages, especially during bursts of activity, the output of any two systems built to process and disseminate this information may not be exactly the same. Frequently there is a need to compare the output of any of such two systems, deployed for receiving the information from exchanges, to see which of the two systems under consideration is generating the output faster and how closely the output matches. Due to the nature of this processing, the relative speed of two systems changes throughout the day and changes based on the characteristic of input data. e.g. let's say the system A generates a time series output : [ 34, 34, 34, 35, 36, 37, 32, 32, 32, 31, 30] And system B generates : [ 34, 34, 34, 34, 34, 35, 36, 37, 32, 32, 32, 30] These points are prices at a particular time. As you can see the system A generates the price change of security from 34 to 35 ahead of system B, we can say that system A is faster as it conveys the latest price of the security ahead of system B How we statistically analyze this ( preferably in python) so we can say Which series is statistically faster how much is price fluctuation across the two are there any big statistical mismatches pointing to the fact that one or both systems may have bugs in their processing?
