[site]: crossvalidated
[post_id]: 466359
[parent_id]: 466322
[tags]: 
Bimodal data for illustration. It looks as if sample sizes of your groups are large. Here are two simulated bimodal samples to use for illustration. set.seed(2020) x1 = c(rexp(2000, 1/5), rnorm(1000, 14, 3)) x2 = c(rexp(2000, 1/5.2), rnorm(1000, 16, 3)) summary(x1); sd(x1) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.0031 2.4675 7.1910 8.2074 13.3121 34.6807 [1] 6.117899 summary(x2); sd(x2) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.00077 2.51898 7.10989 8.83952 14.97832 38.29866 [1] 6.89922 mx = max(x1,x2) par(mfrow=c(2,1)) hist(x1, br=40, xlim=c(0,mx), col="skyblue2") hist(x2, br=50, xlim=c(0,mx), col="skyblue2") par(mfrow=c(1,1)) For large samples, use Welch 2-sample t test. It is probably OK to to a two-sample Welch t test to see if we can a find significant differences in sample means between two such large bimodal samples. The difference is sample means for my simulated data is highly significant with a P-value far below 5%. x = c(x1,x2) g = rep(1:2, each=3000) t.test(x ~ g) t.test(x ~ g) Welch Two Sample t-test data: x by g t = -3.7545, df = 5913.4, p-value = 0.0001753 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -0.9621210 -0.3020553 sample estimates: mean in group 1 mean in group 2 8.207435 8.839523 The Welch two-sample t test does not assume that the two population variances are equal. With large samples the sample means will tend to be nearly normally distributed. The Central Limit Theorem works for bimodal distributions. To verify that averages of samples as large as ours tend to be normal, we can re-sample from x1 . Ten thousand averages, re-sampled (with replacement) of size 3000, are nearly normally distributed as shown in the histogram below. The red normal curve is a reasonably good fit to the histogram. a = replicate(10^4, mean(sample(x1, 3000, rep=T))) hist(a, prob=T, br=50, col="skyblue2") curve(dnorm(x, mean(a), sd(a)), add=T, lwd=2, col="red") Welch 2-sample t test on rank-transformed data. If there are doubts about the normality of averages of samples from your bimodal distributions, there are options other than a two-sample t test to compare population means. One method is to transform the observations, replacing numerical values in the vector x of the combined samples, with their corresponding ranks from 0 through 6000. Of course, ranks are not normally distributed, but the span of their values is limited in a way that often gives near normal averages even with problematic data. The Welch t test on rank-transformed data also shows a significant difference in sample mean for my simulated data. t.test(rank(x) ~ g) Welch Two Sample t-test data: rank(x) by g t = -3.1079, df = 5945.1, p-value = 0.001893 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -226.51287 -51.28447 sample estimates: mean in group 1 mean in group 2 2931.051 3069.949 Two sample nonparametric 2-sample Wilcoxon test. Another possibility is to use rank-based nonparametric tests to compare the two sample means for statistical significance. Here the appropriate test would be a two-sample Wilcoxon rank sum test. It has a P-value very similar to that of the t test on rank-transformed data. wilcox.test(x ~ g) Wilcoxon rank sum test with continuity correction data: x by g W = 4291700, p-value = 0.001899 alternative hypothesis: true location shift is not equal to 0 Depending on the sizes of your samples and the shapes of the bimodal distributions you want to compare, one of the methods illustrated above should be appropriate in your situation. (You should choose one of the tests. It would be inappropriate to run all three and pick the one with the smallest P-value.)
