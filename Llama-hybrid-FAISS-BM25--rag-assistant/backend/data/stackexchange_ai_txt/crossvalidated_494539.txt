[site]: crossvalidated
[post_id]: 494539
[parent_id]: 494302
[tags]: 
Your problem is related to the problem of simulating Boolean circuits that take inputs with a separate probability of being 0 or 1. This is called the stochastic logic problem. In this sense, Qian and Riedel (2008) proved that a function can arise this way if and only if it's a polynomial whose Bernstein coefficients all lie in [0, 1]. In fact these are the same polynomials that are possible in the traditional Bernoulli factory problem, and although I have no proof of this, it perhaps follows that a "multivariate Bernoulli factory" function can be simulated this way if and only if two sequences of polynomials of the kind just given exist that converge from above and below to that function (Łatuszyński et al. 2009/2011). See also Qian et al. 2011. Another related problem is the Dice Enterprise problem first given by Morina et al. 2019/2020, which involves simulating a m -faced die with a n -faced die, where the faces have separate probabilities of occurring. This is not the same as the problem in your question, though, as these probabilities are interrelated rather than independent. REFERENCES: Qian, W. And Riedel, M.D., 2008, June. The synthesis of robust polynomial arithmetic with stochastic logic. In 2008 45th ACM/IEEE Design Automation Conference (pp. 648-653). IEEE. Weikang Qian, Marc D. Riedel, Ivo Rosenberg, "Uniform approximation and Bernstein polynomials with coefficients in the unit interval", European Journal of Combinatorics 32(3), 2011, https://doi.org/10.1016/j.ejc.2010.11.004 http://www.sciencedirect.com/science/article/pii/S0195669810001666 Łatuszyński, K., Kosmidis, I., Papaspiliopoulos, O., Roberts, G.O., "Simulating events of unknown probabilities via reverse time martingales", arXiv:0907.4018v2 [stat.CO], 2009/2011. Morina, G., Łatuszyński, K., et al., " From the Bernoulli Factory to a Dice Enterprise via Perfect Sampling of Markov Chains ", arXiv:1912.09229 [math.PR], 2019/2020. A very relevant paper was just made available and came to my attention: Niazadeh, R., Leme, R.P., Schneider, J., " Combinatorial Bernoulli Factories: Matchings, Flows, and Polytopes ", arXiv:2011.03865v1 [cs.DS], Nov. 7, 2020. (Edited Apr. 4): Let $f:\mathcal{P}\to [0, 1]$ be a function. In the traditional Bernoulli factory problem, we have a coin with unknown probability of heads $\lambda$ and we seek to sample the probability $f(\lambda)$ . In this case, the domain $\mathcal{P}$ is either $[0, 1]$ or a subset thereof. The paper cited above, however, studies Bernoulli factories when $f$ has a different domain: namely when $\mathcal{P}$ is a "polytope contained in the unit hypercube", that is, either $[0,1]^n$ or a subset thereof. Now the Bernoulli factory problem is as follows: Define a polytope $\mathcal{P}$ as above. We have $n$ coins with unknown probabilities of heads of $\lambda_1, ..., \lambda_n$ . These probabilities form a vector $x = (\lambda_1, ..., \lambda_n)$ lying on inside the polytope. Assign a specially-designed coin to each vertex of $\mathcal{P}$ . Sample a vertex (coin) of the polytope such that the expected value equals $x$ . For example, given two coins the vector is $x = (\lambda_1, \lambda_2)$ , and one possible choice of $\mathcal{P}$ is $[0, 1]\times[0, 1]$ . In that case, there are four vertices, namely $(0, 0)$ , $(0, 1)$ , $(1, 0)$ , and $(1, 1)$ . When this procedure is done enough times, the sampled vertices average to $x$ . The main question studied in this paper is whether and how a polytope of the kind just given admits a Bernoulli factory. (They show a polytope that lies entirely in $[0, 1]^d$ admits a Bernoulli factory if and only if every point in the polytope is an affine combination of a constant vector.) Unfortunately, this is a different problem from the Bernoulli factory problem you give in your question, where the goal is to sample the probability $f((\lambda_1, \lambda_2, ..., \lambda_n))$ given $n$ coins each with unknown probability of heads of $\lambda_1, ..., \lambda_n$ as the case may be. Moreover, the use of the term "Bernoulli factory" as studied in the paper may be misleading, because the output of the algorithm is not necessarily a Bernoulli random variable. (This is so even though the paper defines "one-bit Bernoulli factories" similarly to traditional Bernoulli factories.) As a result, the paper didn't study any conditions on $f$ that are necessary for a Bernoulli factory of the kind you give in your question, such as whether $f$ has to be continuous or bounded away from its domain. Nacu & Peres found algorithms to solve the Bernoulli factory problem using approximation theory. Currently, polynomials and rational functions are the main kinds of multivariate functions I am aware of that have Bernoulli factory algorithms (Morina et al.) Many multivariate analytic functions are also taken care of by the composition rule (e.g., proposition 14(ii) of Nacu and Peres). However, although the function $g = \min(\lambda_0, \lambda_1)$ is continuous, it's not differentiable, which presents an apparent difficulty. But by the Stone--Weierstrass theorem, any continuous function on $[0, 1]^d$ can be approximated arbitrarily well by polynomials, so I suspect the following: The necessary conditions of Keane and O'Brien extend to multivariate functions: the function must be continuous on $[0, 1]^d$ and either constant or polynomially bounded, which seems to be the case for $g$ . I also suspect that similarly to the proof of Keane and O'Brien, any such function $f$ can be simulated by finding multivariate, continuous and polynomially bounded functions $f_k$ that approximate $f$ from below, although the algorithm in that proof is far from practical as it requires finding the degree of approximation for each function $f_k$ . Since an approximate polynomial exists for any such continuous function, the algorithm for simulating polynomials given by Goyal and Sigman can be easily extended to the multivariate case: flip each coin n times, count the number of heads for each coin, then return 0 with probability equal to the chosen monomial's coefficient. There may be an algorithm that works similarly in the multivariate case to the general Bernoulli factory algorithms in the univariate case, including the one by Nacu & Peres. This will require looking at the research on multivariate polynomial approximation (especially research that gives bounds on the approximation error with polynomials, especially multivariate polynomials in Bernstein form). It's also possible that for the particular function $g$ , a series expansion exists whose terms can be "tucked" under a discrete probability mass function, which enables an algorithm to simulate $g$ via convex combinations (Wästlund 1999, Theorem 2.7), as is the case for $\min(\lambda, 1/2)$ , for example . EDIT (Sep. 28, 2021): Also, see chapter 3 of G. Morina's doctoral dissertation (2021), which shows that multivariate Bernoulli factories require the function to be continuous and polynomially bounded. EDIT (Feb. 18, 2022): A new paper by Leme and Schneider (2022), " Multiparameter Bernoulli Factories ", deals with the problem you're asking about. Among other things, they show that a function $f(p_1, ..., p_n)$ admits a Bernoulli factory if and only if $f$ is continuous and meets a polynomial boundedness condition that reduces in the 1-dimensional case to that found in Keane and O'Brien. REFERENCES: Goyal, V. And Sigman, K., 2012. On simulating a class of Bernstein polynomials. ACM Transactions on Modeling and Computer Simulation (TOMACS), 22(2), pp.1-5. Wästlund, J., " Functions arising by coin flipping ", 1999. Morina, Giulio (2021) Extending the Bernoulli Factory to a dice enterprise. PhD thesis, University of Warwick.
