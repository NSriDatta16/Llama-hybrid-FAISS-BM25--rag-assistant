[site]: crossvalidated
[post_id]: 338568
[parent_id]: 
[tags]: 
K-Means and clustering

I am doing a course about machine learning this semester, and while reading a tutorial I came across this question: \begin{align} X &\sim U[0,d] \\ N &\rightarrow \inf \\ \delta &\rightarrow 0 \end{align} I need to show that for k=2, the k-means algorithm convergent to the minimum of the square error. In the solution they wrote the following: $$x^{(0)} = \frac{\mu^{(0)}_1+\mu^{(0)}_2}{2} = \alpha d \tag{*}$$ where $\mu$ is the centroid of a group $a$ between $[0, 1]$. \begin{align} \mu_1^{(1)} &= \frac{1}{2} \alpha d \tag{*} \\ \mu_2^{(1)} &= \alpha d + \frac{}{2} = \frac{1+\alpha}{2}d \tag{*} \\ x^{(1)} &= \frac{\mu_1^{(1)}+\mu_2^{(1)}}{2} = \frac 1 2 \alpha d + \frac 1 4 d \tag{*} \\ \\ \mu_1^{(n)} &= \frac 1 2 x^{(n-1)} \tag{*} \\ \mu_1^{(n)} &= \frac{x^{(n-1)}+d} 2 \tag{*} \end{align} Can please explain me what they did in the starred equations? The photo at the top is the question itself. As for the first starred equation, I thought that what they wrote means that given $\mu$ 1 and 2, $X$ will be approximately the average between them. $(n)$ means iteration number $n$. As for the lower set of starred equations, I don't understand how they calculated the centroids for every iteration from the definition of the centroid.
