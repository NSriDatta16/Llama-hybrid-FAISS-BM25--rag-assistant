[site]: crossvalidated
[post_id]: 583380
[parent_id]: 
[tags]: 
Advice on computing contrasts of categorical predictor across range of interacting continuous predictor fitted with a restricted cubic spline #rms

Background After fitting a logistic regression model, I am trying to produce a series contrasts between levels of a categorical variable, x1, across the values of an interacting continuous variable, x2, fitted with a restricted cubic spline. Using the contrast() function in the rms package in R I did: con where vals is a vector of values for the continuous variable x2. Aim I would like to present the contrasts as a graph with x2 on the x horizontal axis and the contrast (or odds ratio) on the vertical y axis so that we get a smooth curve and confidence bands over the entire range of x (or e.g. 95% of the values). So something that looks like this: Example of options Suppose x2 ranges from 0 to 100, we could compute contrasts at: x2 = 0,1,2,...,100. Or we could use less values of x2, but still cover its range e.g. compute contrasts at x2 = 0,10,20,...,100. In both cases we can get the smooth contrast curve I decribed above. In the former, the curve will be "smoother" since we have more x2 values to plot, though confidence bands will be wider since we have adjusted for having done multiple contrasts (conf.type="simultaneous" in the above R code). In the latter, the curve will be less smooth, but the confidence bands will be narrower since we have done fewer contrasts and hence the penalty applied is less. Question How do we select which values of x2 to use when computing the contrasts i.e. in the 'vals' vector above? It seems from my description above that there is a tradeoff between the smoothness of the "contrast curve" and the width of the confidence bands (assuming we are adjusting for simultaneous inference). How does one approach this problem? Update: Here is an example where we want contrasts over the range of x2 (here called visit_no.) from 0 to 10. In the first dataframe k, we use all integers, in the second, k2 only a few. The point estimates are the same but the confidence intervals are not.
