[site]: stackoverflow
[post_id]: 4844613
[parent_id]: 4839466
[tags]: 
well using your second method is the much easier one, since you know where from the GPS coordinates and you know which way you're facing (since most mobile devices have an integrated compass and accelerometer). This is used by several Augmented Reality browsers already - if you use Android you might wanna have a look at "Layar"... The more user friendly way would be via photography, since not every phone has GPS and they always need to turn it on first... First of all you'd need to get the most salient structures and features of the buildings. OpenCV has some methods for that. Feature extraction is a big topic in image processing. You should probably extract edges on your image, take the prominent features/points and compare these to a database of the features of all the buildings you have. You could use a neural network for training, but you'd still need a lot of reference pictures to extract data from to get a learning process. (For comparing with the whole database of other objects you might even wanna have a look at a server-side calculation instead of doing all this on the phone) Hope that helps...
