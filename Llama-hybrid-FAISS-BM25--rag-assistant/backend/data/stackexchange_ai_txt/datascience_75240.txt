[site]: datascience
[post_id]: 75240
[parent_id]: 
[tags]: 
The exact meaning of cost function ? (Machine Learning)

I'm reading the "Python Machine Learning" book by Sebastian Raschka, and we use different cost functions. For Adaline model (with a linear activation function) we use the MSE error : (Phi is the activation function and y the target) $$ Err(w) = \frac{1}{2}\sum(\phi(z) - y)^2 $$ But for the Logistic Regression model we use another cost function : $$ Err(w) = \sum[-y\log(\phi(z)) - (1-y)\log(1-\phi(z))] $$ I just want to know what does the cost funciton really mean, it's a probability ? Or just something arbitrary and convex ? Is there a way to find "the best" cost function for a specific activation function ?
