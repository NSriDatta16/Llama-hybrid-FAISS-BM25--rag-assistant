[site]: crossvalidated
[post_id]: 523431
[parent_id]: 523348
[tags]: 
So, I think it is important for these sorts of "gotcha" problems to think clearly about what we are being asked to do. This is my best attempt to distill the problem down to something we can actually analyze In repeated samples, what proportion of the time $q$ will Bob win the game when the score is 5-3? Provide an estimate $\widehat q$ of this probability. In order to answer this question, we need to be explicit about what a "repeated sample" is. There are two natural interpretations: Consider many replications of the entire experiment: we roll the ball, Alice and Bob play the game, and we find ourselves in the situation where Alice has 5 points and Bob has 3. The exact same, but we don't reroll the ball. The point is that, in scenario 1, nothing is unknown and the answer is just an application of Bayes theorem. Frequentists are allowed to use Bayes theorem, there is nothing inherently Bayesian about it, and doing anything else would basically just be wrong if you are a Frequentist. Note that this is the scenario which is dealt with by the simulations. So there is no disagreement in scenario 1, and we can assume without loss of generality that we are in scenario 2. In this case, $q = (1 - p)^3$ . The Bayesian reports $\widehat q = 1/11$ while the Frequentist reports $(1 - 5/8)^3$ (assuming we use the MLE, which we are not obliged to do, but I'll just note that using MLE is a choice which is orthogonal to Bayes/Frequentist issues). Which one is correct? Well, that depends on what $p$ is . If we are addressing this problem from the Frequentist perspective, $p$ is a fixed-but-unknown quantity, and we have fixed this for eternity by stating that a replication of the experiment would not involve re-rolling the ball. Modeling this experiment would involve taking your threshold outside the loop, and the relative performance of the two methods will now depend on what $p$ you happen to sample. To be clear, the only way for there to be any disagreement between the two methods is if you are in scenario 2. Scenario 1 is a strawman because, from the Frequentist perspective, there are no unknown parameters - we know exactly what happens under repeated sampling, so there is nothing to estimate. Possibly the confusion is related to the conflation between Bayesian statistics (a theory of uncertainty quantification) and Bayes theorem (a theorem of probability which is applicable to both Frequentist and Bayesian interpretations of probability). The seemingly bad behavior of Frequentist versus Bayes in this example is attributable to the fact that we force the Frequentist to use an estimator from scenario 2 but adopt scenario 1 to judge their answer. An analogy: it's like asking a Bayesian and a Frequentist to estimate the area of the circle but allowing a Bayesian use $\pi$ while forcing the Frequentist to throw darts to estimate $\pi$ , and concluding from the result that Frequentist statistics is bunk because their dart-throwing estimator does a bad job.
