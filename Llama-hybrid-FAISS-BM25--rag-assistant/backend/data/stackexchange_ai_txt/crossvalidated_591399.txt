[site]: crossvalidated
[post_id]: 591399
[parent_id]: 591398
[tags]: 
Itâ€™s a garbage in, garbage out scenario. What machine learning models do, is they learn to recognize patterns in the data and act when finding the patterns at prediction time. If you have garbage data, the model would make garbage predictions no matter how sophisticated your machine learning model is. This is what Andrew Ng means by data-centric AI , when he talks that our major concern should be the qualify of the data, rather than the models. If you know that the quality of the data is low, you should be spending most of the time getting better data, as working on improving the model is an unlikely cure. As others noticed in the comments, the above statement may be too strong. Indeed, our usual assumption is that the data is noisy and most of the models would be able to overcome some degree of noise, mislabeled samples, etc. We even have specialized models like the errors-in-variables model. Still, if there are known issues with data quality, the usually more efficient approach would be to gather better data (or improve it by re-labeling it, etc) than hoping that the model would be able to overcome the issues by itself.
