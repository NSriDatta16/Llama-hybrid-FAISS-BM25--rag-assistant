[site]: crossvalidated
[post_id]: 498515
[parent_id]: 
[tags]: 
In machine learning, especially deep learning, is it a principle to only do linear projections to a smaller dimension size?

Linear projection (or fully connected layer) is perhaps one of the most common operations in deep learning models. When doing linear projection, we can project a vector $x$ of dimension $n$ to a vector $y$ of dimension size $m$ by multiplying a projection matrix $W$ of shape $n \times m$ . My question is, is it a principle that $n$ should always be larger than or equal to $m$ ? In another word, it does not make much sense to project a vector to a space with even larger dimension size. If it is true, is there any theory foundation for such kind of 'bottleneck' operations?
