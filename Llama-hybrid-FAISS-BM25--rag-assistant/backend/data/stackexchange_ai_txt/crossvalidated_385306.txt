[site]: crossvalidated
[post_id]: 385306
[parent_id]: 
[tags]: 
What is the integral of the False Positive Rate over the False Positive Rate, compared to the AUC?

In machine learning the Area Under the Receiver Operating Characteristic Curve ( $AUC$ ) can be illustrated in a plot of the True Positive Rate ( $TPR$ ) against the False Positive Rate ( $FPR$ ). Formally, it can also be expressed as the expected value of the $TPR$ , given a uniform distribution of $FPR$ : \begin{align} AUC = \int_{0}^{1}TPR\ dFPR \end{align} This can also be expressed as as a function of $TPR$ and a decision threshold $k$ (assuming that first, a scoring function estimates the probability of belonging to the positiv class and an indicator function then assigns the class based on a decision threshold $k$ ): \begin{align} \label{eq:auc} AUC = \int_{0}^{1}TPR\ dFPR = \int_{-\infty}^{\infty} TPR_{k}\ f_{o}(k)dk \end{align} where $f_{o}(k)$ is the probability that the scoring function $F(X)$ produces a score of exactly $k$ in the instances that have a negative class label (see Hand 2009 ). I am wondering what is the value of integrating the $FPR$ over the $FPR$ : \begin{align} \int_{-\infty}^{\infty}FPR\ f_{0}(k)dk = \int_{-\infty}^{\infty}FPR\ dFPR \end{align} Dalessandro et al. (2014) suggest that \begin{align} \int_{-\infty}^{\infty}FPR\ f_{0}(k)dk = \int_{-\infty}^{\infty}FPR\ dFPR = 0.5 \end{align} but this is not very intuitive to me and causes contradictory results in my further proceedings. References: HAND, D. J. (2009): “Measuring classifier performance: a coherent alternative to the area under the ROC curve”, Machine Learning, 77, 103–123. DALESSANDRO, B., C. PERLICH, AND T. RAEDER (2014): “Bigger is Better, but at What Cost? Estimating the Economic Value of Incremental Data Assets”, Big data, 2, 87–96.
