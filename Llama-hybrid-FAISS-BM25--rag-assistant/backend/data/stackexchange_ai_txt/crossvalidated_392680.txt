[site]: crossvalidated
[post_id]: 392680
[parent_id]: 392485
[tags]: 
So, the two mistakes I made were 1) Making a one-tailed, rather than two-tailed t-test, and 2) using the number of degrees of freedom in the model (5). With 150 data points and 5 model parameters, the correct number is instead 145. The code below correctly computes the same p-values as the ones given by statsmodels. The reason the Z-test appeared to give correct results for some parameters is that the t-distribution is very close to the normal distribution for large df's, but as the t-distribution is wider than the normal, the difference grows for larger values of t, consistent with z- and t-tests giving very different results only for the last two parameters above. from sklearn import datasets import statsmodels.api as sm from scipy import stats # Load data data = datasets.load_iris() X = data.data X = sm.add_constant(X) y = data.target # Fit the logistic regression est = sm.OLS(y, X) res = est.fit() n_datapoints = X.shape[0] dim = X.shape[1] df = n_datapoints - dim for t, p in zip(res.tvalues, res.pvalues): # Print t- and p-values returned by statsmodels print("Fit t-value=%.2g" % t) print("Fit p-value=%.10g" % p) # Compute p-value from the returned t-values p_manual = stats.t.sf(abs(t), df=res.df_resid)*2 print("t-test Calculated p-value=%.10g" % p_manual) print()
