[site]: datascience
[post_id]: 94413
[parent_id]: 94342
[tags]: 
Disclaimer: my knowledge about neural networks is very limited, so my answer is only based on general ML principles. Hopefully somebody will provide a more informed answer. In supervised learning, the assumption is that the training set is a representative sample of the data, i.e. a random subset of the whole sample space. From this point of view it's easy to explain why your model doesn't generalize the function outside the training range: the model expects only points in the same range as the training set. You and I know that the function is periodic over $\mathbb{R}$ , but the model has no way to know that. For example the function could perfectly be "if x I'm aware of at least two other interesting questions on the topic of the generalization ability of neural networks: Can a neural network compute y=xÂ²? Can machine learning learn a function like finding maximum from a list? Imho it's quite revealing that, based on the answers, the two questions appear to be quite controversial. It might also be of interest to note that in both questions there's an answer ( here and there ) which points out the theoretical limitation that the target function needs to be defined on a compact subset of $\mathbb{R}^n$ . Another vaguely related remark: a technique used with some [many? most? I don't know] forecasting problems is to explicitly train the model to predict the next point (or some point in the future) based on past data. By analogy, if the goal of the task is to predict points outside a particular range then the training data should be made of instances which represent a sequence of values so that the model can learn to predict the next point in a sequence. This design makes more sense with respect to providing a representative sample as training set. My guess is that a periodic function would be more likely to be correctly approximated in this way, but I didn't test the idea.
