[site]: crossvalidated
[post_id]: 485356
[parent_id]: 484511
[tags]: 
Edit Thanks for the clarifying point. In this case, the vector model (Approach #2) is the correct one, and the dummy variable model (Approach #1) is wrong. This is because Approach #1 doesn't fit the assumptions of the Schwarz criterion, because the distribution of the observations $z$ does not follow a distribution from the exponential family. Because of the dummy variable $d$ , the distribution of $z$ would actually be a mixture of two normal distributions, one for boys with mean $x + y$ and the other for girls with mean $x$ . Mixture models are not generally members of the exponential family, see the last paragraph of the "Examples" section of the Wikipedia article for the exponential family . Approach #2, on the other hand, has $z$ distributed according to the normal distribution $$ \mathcal{N}\left( \left[ \begin{matrix} x + y \\ x \end{matrix} \right] , \left[ \begin{matrix} \sigma^2 & 0 \\ 0 & \sigma^2 \end{matrix} \right] \right)$$ which is a member of the exponential family. So Approach #2 is the correct one, and the correct number of observations is $n = 100$ . Original Answer The data is not allowed to differ when using the Schwarz criterion to compare two models. To quote from Schwarz's original paper In a general parameter space, there is no intrinsic linear structure. We therefore assume that observations come from a Koopman-Darmois [Exponential] family, i.e., relative to some fixed measure on the sample space they possess a density of the form $$ f(x, \theta) = \exp(\theta \cdot y(x) - b(\theta)). $$ where $\theta$ ranges over the natural parameter space $\Theta$ , a convex subset of the $K$ -dimensional Euclidean space, and $y$ is the sufficient $K$ -dimensional statistic. The competing models are given by sets of the form $m_j \cap \Theta$ where $m_j$ is a $k_j$ -dimensional linear manifold embedded in $\mathbb{R}^K$ for each $j$ . The two models in your question don't satisfy the assumptions for this setup, because you are changing the data $x$ between the two models (notice that $x$ does not have a $j$ subscript in the above). If you want to use the Schwarz information criterion (BIC) then you have to compare two models that satisfy these assumptions, which includes using the same data $x$ . In particular, $$ \{ b(1), g(1), b(2), g(2), ..., b(100), g(100) \} \ne \left\{ \left[ \begin{matrix} b(1) \\ g(1) \end{matrix} \right] , \left[ \begin{matrix} b(2) \\ g(2) \end{matrix} \right], ..., \left[ \begin{matrix} b(100) \\ g(100) \end{matrix} \right] \right\}. $$
