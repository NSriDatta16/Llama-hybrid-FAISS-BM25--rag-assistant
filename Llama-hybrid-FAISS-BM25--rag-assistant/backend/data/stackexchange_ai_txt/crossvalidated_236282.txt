[site]: crossvalidated
[post_id]: 236282
[parent_id]: 233946
[tags]: 
It depends on what is shown on the y-axis: score or error. The scikit-learn example you linked to shows the score (mean accuracy in the case of Naive Bayes and SVM) as a function of the number of training examples. As you would expect, as the number of training examples grows, training accuracy decreases and CV accuracy increases. If you were to plot the error on the y axis instead, you get the opposite behaviour: training error increases and CV error decreases as the number of training examples grows. I suspect the learning curve used in the ML course shows the error (MSE if I remember correctly) as a function of the number of training examples. Hence the different plots.
