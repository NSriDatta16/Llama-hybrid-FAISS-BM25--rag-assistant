[site]: crossvalidated
[post_id]: 197559
[parent_id]: 197529
[tags]: 
In feature extraction, you are generally starting with a high dimensional set of data, with the intent of finding the (hopefully) important, lower dimensional set of factors in your data. As such, you are throwing away some information in your data (assuming you don't have a trivial problem, i.e. one variable is a perfect linear combination of the other variables). There is no way to definitively known that some aspect is unimportant; if you knew exactly what was important, you wouldn't need a statistical model in the first place! To give a concrete example, consider Principal Components Analysis (PCA). Each component is a linear combination of the original covariate space. These components are usually presented as ordered, where the first component explains more of the total variance in your data than the next, all the way down to the last principal component, which explains the least of your variance. It is a very common assumption that the first few components are the most important, as they contain the information that explains the most amount of the total variance in data. As such, the feature extraction is to keep the first $k$ components, and this is usually justified with something like "Well, the first 3 components contain 95% of the variance, so we will only consider these variables". However, it's also quite possible that the last set of principal components are really important: these are the linear combinations that are the most reliable (i.e. lowest variance). It's not hard to imagine that throwing away information about a set of variables that almost always are consistent, except in a few rare cases, might be a very bad idea in certain situations! In summary: feature extraction is typically concerned with taking high dimensional data and representing it in a lower dimensional space. This means removing some of the information in your data. In general, you can't know exactly a priori what information is important and what is not, so you naturally will lose some information during the feature extraction process.
