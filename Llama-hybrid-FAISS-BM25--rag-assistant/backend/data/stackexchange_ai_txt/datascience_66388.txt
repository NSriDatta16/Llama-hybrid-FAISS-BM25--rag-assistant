[site]: datascience
[post_id]: 66388
[parent_id]: 
[tags]: 
What is the formula to calculate the precision, recall, f-measure with macro, micro, none for multi-label classification in sklearn metrics?

I am working in the problem of multi-label classification tasks. But I would not able to understand the formula for calculating the precision, recall, and f-measure with macro, micro, and none. Moreover, I understood the formula to calculate these metrics for samples. Even, I am also familiar with the example-based, label-based, and rank-based metrics. For instance, import numpy as np from sklearn.metrics import hamming_loss, accuracy_score, precision_score, recall_score, f1_score from sklearn.metrics import multilabel_confusion_matrix y_true = np.array([[0, 1, 1 ], [1, 0, 1 ], [1, 0, 0 ], [1, 1, 1 ]]) y_pred = np.array([[0, 1, 1], [0, 1, 0], [1, 0, 0], [1, 1, 1]]) conf_mat=multilabel_confusion_matrix(y_true, y_pred) print("Confusion_matrix_Train\n", conf_mat) Confusion matrix output: [[[1 0] [1 2]] [[1 1] [0 2]] [[1 0] [1 2]]] Macro score print("precision_score:", precision_score(y_true, y_pred, average='macro')) print("recall_score:", recall_score(y_true, y_pred, average='macro')) print("f1_score:", f1_score(y_true, y_pred, average='macro')) Macro score output: precision_score: 0.8888888888888888 recall_score: 0.7777777777777777 f1_score: 0.8000000000000002 Micro score print("precision_score:", precision_score(y_true, y_pred, average='micro')) print("recall_score:", recall_score(y_true, y_pred, average='micro')) print("f1_score:", f1_score(y_true, y_pred, average='micro')) Micro score output: precision_score: 0.8571428571428571 recall_score: 0.75 f1_score: 0.7999999999999999 Weighted score print("precision_score:", precision_score(y_true, y_pred, average='weighted')) print("recall_score:", recall_score(y_true, y_pred, average='weighted')) print("f1_score:", f1_score(y_true, y_pred, average='weighted')) Weighted score output: precision_score: 0.9166666666666666 recall_score: 0.75 f1_score: 0.8 Samples score print("precision_score:", precision_score(y_true, y_pred, average='samples')) print("recall_score:", recall_score(y_true, y_pred, average='samples')) print("f1_score:", f1_score(y_true, y_pred, average='samples')) Samples score output: precision_score: 0.75 recall_score: 0.75 f1_score: 0.75 None score print("precision_score:", precision_score(y_true, y_pred, average=None)) print("recall_score:", recall_score(y_true, y_pred, average=None)) print("f1_score:", f1_score(y_true, y_pred, average=None)) None score output: precision_score: [1. 0.66666667 1. ] recall_score: [0.66666667 1. 0.66666667] f1_score: [0.8 0.8 0.8] Thanks in advance for your help.
