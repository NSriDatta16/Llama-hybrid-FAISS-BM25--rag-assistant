[site]: crossvalidated
[post_id]: 447871
[parent_id]: 
[tags]: 
Breaking biased feedback loops in machine learning models

If a ML model is trained to predict conversions of a lead, and the company introduces a set of behavior based on those predictions, then a feedback loop can be created. If I only call the top 10% of my leads and don't call the bottom 90%, then over time my top 10% will have a much higher conversion rate even if my model was garbage. If I want to train a new model, it will pick up my old model's behavior because my actions towards those leads changed based on the old model. How would I train a new model without that bias?
