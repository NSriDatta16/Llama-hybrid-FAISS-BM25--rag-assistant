[site]: crossvalidated
[post_id]: 624467
[parent_id]: 
[tags]: 
Violation of i.i.d assumption of supervised learning models with time series data

I am trying to develop a model that predicts the number of cable and joint faults in a distribution grid on a daily basis. These faults seem to increase during very hot and arid summer days (Heatwaves). My dataset includes daily fault numbers as the dependent variable and daily maximum power flow, daily temperature values, daily relative humidity values for June and July months of several years as independent variables. The first thing that comes to my mind is to add the lagged versions of the target variable as inputs and include time features such as 'day of the year', 'day of the week' to convey the time dependancy of the data and "convert" this problem to one that supervised machine learning can model. Although, I am dealing with time-related features such as temperature, power, humidity, the fact that I am going to be given these variables and predict the number of the faults for that specific day makes me lean more towards to supervised machine learning approach instead of time-series forecasting. However, is this approach valid given that supervised machine learning algorithms expect i.i.d data and time series data is obviously not i.i.d ? Is using lagged versions of target variable as inputs allowed in supervised machine learning ?
