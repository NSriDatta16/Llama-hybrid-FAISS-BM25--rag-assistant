[site]: crossvalidated
[post_id]: 60883
[parent_id]: 60881
[tags]: 
It sounds like what you have are clusters of high influence points where, due to the correlation structure of observed predictors, you may have very large effect sizes that are associated with very small differences in the predicted values in intermediate ranges, but could hypothetically produce ludicrous fitted values for outlying ranges of these predictors. There are many reasons why we may not care to ameliorate this issue: If the interest is in inference, then by adequately adjusting for the desired stratification variables, we conserve the interpretation of the regression coefficient for our parameter of interest. That is, that "a unit difference in $X$ is associated with a $\beta$ difference in $Y$ holding $U_1$, $U_2$, ... fixed. Despite the possibility for generating large values in prediction, these variable ranges are implausible or downright silly extrapolations (such as testosterone levels in pregnant men). It is important with any prediction model to validate that model in independent data. If you are actually able to sample data from an independent validation dataset, then that's an issue of representativeness of the training sapmle. If used for prediction, the model achieves an alternative purpose effectively. For instance, with risk prediction for breast cancer, we may have horribly calibrated models for which the estimated risk in women does not reflect their actual event rates. However, if we dichotomize the risk prediction, we may identify a very high risk stratification for which screening therapies can be effectively recommended. This risk stratification does not require a model to be calibrated at all. To test for these issues, it may be worthwhile to look at a histogram of leverage, influential points to determine whether specific observations are driving trends. I do not discard such points. Jackknife and bootstrapped standard errors can also be used to assess sensitivity to model based assumptions about the distribution of error terms. You can trim points based on their leverage/influence to obtain some outlier robust regression parameter estimates, but I never advocate doing this.
