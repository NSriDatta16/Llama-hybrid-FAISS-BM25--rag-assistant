[site]: crossvalidated
[post_id]: 70585
[parent_id]: 
[tags]: 
How to rate successive predictions of the outcome of an event which are made while it is taking place?

Consider the scenario of making successive predictions about the outcome of a sporting event while it is taking place. I will use tennis as a concrete example because it has clearly defined moments at which it is sensible to make a new prediction (i.e. after every point is played) but I am also interested in cases such as soccer where predictions can be made with arbitrary frequency (e.g. every five seconds). After every point of the tennis match is played, a model makes a prediction giving the probability that each player will go on to win the match. In a match with $N$ points played, $N$ predictions are made and my question is how should the performance of these $N$ predictions be summarised to give a single value for the performance of the model on this match? An obvious starting point would be the Brier Score , i.e. the average squared error of the predictions. However, taking this approach may not adequately penalise outliers - e.g. a single terrible prediction among otherwise good ones. At the other extreme, the maximum absolute error might favour a consistently mediocre set of predictions over a set of very good predictions and one terrible prediction. Which of these possibilities is more tolerable is open to debate but I seem to have described a general problem with summary statistics. What I am more interested in learning about are approaches that are specifically tailored to my scenario, i.e. which take into account the fact that these predictions are all made on the same outcome and each prediction is made with successively more information.
