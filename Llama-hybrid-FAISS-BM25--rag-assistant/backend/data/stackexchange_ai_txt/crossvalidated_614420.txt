[site]: crossvalidated
[post_id]: 614420
[parent_id]: 
[tags]: 
How can I generate bootstrap confidence intervals for a multivariate regression network?

I am reading "Confidence Intervals and Prediction Intervals for Feed-Forward Neural Networks" by Richard Dybowski. In this paper, an ensemble of neural networks are trained on bootstrapped data samples so that a confidence interval can be estimated. I will try to briefly summarize the method below: Assume that our training data is modeled by the stochastic function $$ y = \mu_y(\mathbf{x}) + \epsilon, \quad y\in\mathbb{R}, \mathbf{x}\in\mathbb{R}^m$$ where $\mu_y$ is the unknown function to be approximated. We have access to a finite sample of $N$ training pairs $\mathbf{S} = \{(\mathbf{x}^{(1)}, y^{(1)}), \dots, (\mathbf{x}^{(N)}, y^{(N)})\}$ only. We generate $B$ bootstrapped samples $\{ (\mathbf{x}^{(*b, 1)}, y^{(*b, 1)}), \dots, (\mathbf{x}^{(*b, N)}, y^{(*b, N)}) \}_{b=1}^B$ , and train $B$ neural networks $\{\hat{\mu}_y(\mathbf{x}; \hat{\mathbf{w}}^{(*b)})\}_{b=1}^B$ . Then the bootstrap estimate of $\mu_y(\mathbf{x})$ is given by the mean provided by the ensemble of neural networks $$ \hat{\mu}_{y, \text{boot}}(\mathbf{x}) = \frac{1}{B} \sum_{b=1}^B \hat{\mu_y}(\mathbf{x}; \hat{\mathbf{w}}^{(*b)} )$$ and the bootstrap estimate of the standard error of $\hat{\mu}_y(\mathbf{x}; \hat{\mathbf{w}})$ is given by $$\hat{\mathrm{SE}}_\text{boot} (\hat{\mu}_y (\mathbf{x}; \cdot)) = \sqrt{ \frac{1}{B-1} \sum_{b=1}^B [ \hat{\mu}_y ( \mathbf{x}; \hat{\mathbf{w}}^{(*b)} ) - \hat{\mu}_{y, \text{boot}}(\mathbf{x})]^2 }$$ Assuming a normal distribution for $\hat{\mu}_y ( \mathbf{x}; \hat{\mathbf{w}} )$ over the space of all possible $\hat{\mathbf{w}}$ , we have $$\hat{\mu}_{y, \text{boot}}(\mathbf{x}) \pm t_{.025}\hat{\mathrm{SE}}_\text{boot}(\hat{\mu}_y(\mathbf{x}; \cdot))$$ as the 95% confidence interval for $\mu_y(\mathbf{x})$ . 1. How would I compute the 95% confidence interval without assuming a normal distribution for $\hat{\mu}_y ( \mathbf{x}; \hat{\mathbf{w}} )$ ? 2. How would I generalise this method to a vector output $\mathbf{y} \in \mathbb{R}^m$ ?
