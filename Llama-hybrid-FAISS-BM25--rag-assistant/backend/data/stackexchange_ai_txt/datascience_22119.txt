[site]: datascience
[post_id]: 22119
[parent_id]: 
[tags]: 
Tensor Decomposition for Higher-Order Context-Aware Recommender Systems

Let me motivate my problem with an example. Let's assume our observations concern ratings a user give to different items, while navigating through item catalog. The user begins rating item1 (may be relevance), and proceeds to item2 to give (or not) a rating to that item. The user may return back to item1 to give yet another score (recursive nature). I am interested in learning a recommender (say, collaborative) which predicts a score based on the context (traversal path) (s)he is in (or learn some kind of a general transfer function which predicts based on past context). A use case would be to find the true user-item rating score. Another would be to recommend an item to a user with the highest rated score based on the contexts (traversal history) of that user. The observations can be encoded as: $$ User \times Context_1 \leftarrow Score \\ User \times Context_1 \times Context_2 \leftarrow Score \\ \vdots \\ User \times Context_1 \times \ldots \times Context_N \leftarrow Score $$ where any of the two contexts can be the same, eg. $(u_1, it_1, it_2, it_1) = 5$ I have been looking at Tensors to incorporate contextual information for collaborative filtering. On one hand, the resulting tensor has very high number of dimensions (longest possible traversal path of the observed data) and extremely sparse. On the other hand, since the length of traversal history for each user is different, the resulting tensor for unobserved dimensions is incomplete. $$ User \times Context_1 \times Score_1 \times ... \times Context_N \times Score_N \leftarrow \{0,1\} $$ Is the tensor decomposition the right technique to tackle this problem? Are deep models such as RNNs better fit for this kind of nested recursive contextual problems. If TD is the way to go, what is the best approach to deal with the dimensions of the problem? I do know there has been some new techniques such as Tensor-Train or Hierarchical Tucker decomposition for dealing with the `curse of dimensionality'. Any insights into this problem or pointers is highly appreciated.
