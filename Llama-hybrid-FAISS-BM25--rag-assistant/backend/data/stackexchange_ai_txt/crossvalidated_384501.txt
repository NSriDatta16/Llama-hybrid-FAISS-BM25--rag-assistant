[site]: crossvalidated
[post_id]: 384501
[parent_id]: 94118
[tags]: 
I like both Pablo and Marc answers. One additional point: In the paper cited by Marc there is written (section 4) "The motivation of $\nu$ -SVR is that it may not be easy to decide the parameter $\epsilon$ . Hence, here we are interested in the possible range of $\epsilon$ . As expected, results show that $\epsilon$ is related to the target values $y$ . [...] As the effective range of $\epsilon$ is affected by the target values $y$ , a way to solve this difficulty for $\epsilon$ -SVM is by scaling the target values before training the data. For example, if all target values are scaled to $[-1,+1]$ , then the effective range of $\epsilon$ will be $[0, 1]$ , the same as that of $\nu$ . Then it may be easier to choose $\epsilon$ ." That brings me to think that it should be easier to scale your target variables and use $\epsilon$ -SVR, than trying to decide whether to use $\epsilon -$ or $\nu -$ SVR. What do you think?
