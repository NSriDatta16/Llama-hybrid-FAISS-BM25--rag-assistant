[site]: crossvalidated
[post_id]: 639689
[parent_id]: 
[tags]: 
VAE latent variables apper highly correlated

I am attempting to train a Beta-VAE on historical interest rate curves to map interest rate curves to a lower dimension latent space. I have chosen to use VAE over PCA or autoencoders because I want a regularized latent space to make a generative process possible (continuity and completeness) The problem I have is that the encoded latent space my model produces shows highly correlated latent variables. In the first plot below, I have chose to find a latent space of dimension n=2, and after training, I extract the latent space as the encoded mus (means). You can clearly see the high degree of correlation, suggesting that this latent space is far from independent. However, in the training process, we sample the latent space through the reparameterization trick. These sampled latent variables are what drives the loss functions, including KLD. If I extract "sampled" latent variables from the trained model using the forward pass (that is, I introduce the sampling noise), my latent variables (now sampled form respective mu and logvar) now appear as two independent Gaussian variables (second figure) So it seems during training that the model is doing what it is supposed to do, but ultimately leaving me with a deterministic mapping (the encoded mu) that does not have the desired regularization. I am asking for any insights on this phenomenon and potential solutions or alternatives. I want to find a deterministic mapping of my original dataset to a regularized latent space. My understanding is that the sampling step in VAE plays a big part in that regularization, forcing the latent space towards one that has the desirable properties of continuity and completeness. I have tried training with varying choices of Beta hyperparameter and network architecture, but results always follow the same pattern.
