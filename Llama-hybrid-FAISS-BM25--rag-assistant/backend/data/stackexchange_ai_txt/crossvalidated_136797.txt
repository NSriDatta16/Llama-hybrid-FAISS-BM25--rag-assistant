[site]: crossvalidated
[post_id]: 136797
[parent_id]: 30959
[tags]: 
@h_bauer has provided a good answer. Let me add a small complementary point: You can also test for a curvilinear relationship by adding curvilinear terms and performing a nested model test. For example, imagine you have $X_1$ as an explanatory variable, but you aren't sure whether the relationship between it and the link transformed expectation is a straight line. You could form a new model by adding $X_1^2$ , and $X_1^3$ , and then test to see if your new model fits better than your original model. Another assumption of generalized linear models, like the multinomial logistic, is that the link function is correct. Strictly speaking, multinomial logistic regression uses only the logit link, but there are other multinomial model possibilities, such as the multinomial probit . Many people (somewhat sloppily) refer to any such model as "logistic" meaning only that the response variable is categorical, but the term really only properly refers to the logit link. For more on links, it may help you to read my answer here: Difference between logit and probit models . Regarding addressing violations of these assumptions, it is mostly self-explanatory. If the observations are not independent, you can add the relevant fixed or random effects to make them so. If the relationship with a predictor is not linear, you can add transformed variables so that it is linear in the augmented predictor space. If the link is not appropriate, you can change it, etc. In general, multinomial logistic regression does not make very constraining assumptions.
