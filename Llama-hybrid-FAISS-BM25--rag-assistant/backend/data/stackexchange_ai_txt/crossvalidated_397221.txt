[site]: crossvalidated
[post_id]: 397221
[parent_id]: 397215
[tags]: 
For translational invariance, you can follow the discussion here . In general, pooling layer is the important player in local translational invariance by removing the spatial dimension in, for example, max-pooling. For instance, if an object slightly moves towards some direction, max-pooling still captures the max element and the same output will appear after the pooling. The convolutional layer is actually equivariant in translation. Neither layers are rotation-invariant. Though, the network can exhibit this behavior if the properties of the data, and the overall architecture permit. A NIPS paper addresses this issue and use Spatial Transformers to improve CNNs invariance to rotation, scale and translation.
