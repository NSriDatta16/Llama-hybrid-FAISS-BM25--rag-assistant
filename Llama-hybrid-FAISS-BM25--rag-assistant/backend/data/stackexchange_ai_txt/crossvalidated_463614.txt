[site]: crossvalidated
[post_id]: 463614
[parent_id]: 424069
[tags]: 
I think that the validation you are doing is how one determines the best model. Average all of those scores, and the model with the highest average score is the better one. I've done that for you here: Huber: 0.504 Linear: 0.581 Without seeing your dataset, I am not sure why you are getting a negative score. Generally that means that the model you have fit is worse than the null hypothesis, that a straight line with slope of 0 is a better fit than the model you created. That being said, you notice that shuffle=True causes only positive results. cv1 = KFold(n_splits=10, shuffle=True) If your target is ordered in the dataframe, such as from smallest to largest, you might get a bad fit, resulting in a negative score. Shuffling the data will fix that by causing you to build a model that represents a random sample of your data. In this case your folds would be representative of the entire dataset, instead of some small, statistically distinct region. Check the averages from the KFold validation using the shuffle, and see how they compare to those without a shuffle. I'd recommend using the shuffled values to determine which model you should use.
