[site]: datascience
[post_id]: 68956
[parent_id]: 68945
[tags]: 
Given that the environment is somewhat consistent throughout all samples, is there a ballpark number / rule of thumb for a decent number of samples to use per class? (100 train / 100 test)? This is a proof of concept project, so I'm just looking for something with reasonable accuracy (80%+) This really differs from problem to problem. The number of observations needed to reach a given threshold of quality depends on how easy it is for a Neural Network to classify them correctly. Unfortunately, only a person with your specific domain knowledge can say that. I have seen CNN multi-classification tasks made on few hundres of observations per class. In that case, a massive amount of data agumentation would be fundamental. A good rule of thumb is to be at least in the order of thousands. However, hundreds of obs. per class + data augmentation might work, I suggest you to try with a smaller dataset, and increase its size in case it's not enough. After I've captured my images (let's say via smartphone) are there any preprocessing steps (other than annotating) that are necessary before using as training data? (i.e resize the images, reduce file size, format) Image size is the most important issue. CNNs require an input of constant size (height, width, channels). Conv layers can already take care of zero padding of smaller images. However, you might rescale larger ones. You can create an input pipeline to preprocess image data, that can then be fed into the CNN. The main purpose of this pipeline is to keep the images in an acceptable size (depending largely on you computational power).
