[site]: crossvalidated
[post_id]: 496283
[parent_id]: 
[tags]: 
How to force logistic regression weights to be always positive in pytorch? (equivalent of keras NonNeg in pytorch)

I am solving a binary classification task, and I need my logistic regression's learned weights to be all positive. This is my current classifier implemented in pytorch : class LogisticRegression(torch.nn.Module): def __init__(self, input_dim, output_dim): super(LogisticRegression, self).__init__() self.linear = torch.nn.Linear(input_dim, output_dim) def forward(self, x): outputs = self.linear(x) return outputs So how should I change the code to force the weights to be always positive? EDIT : Keras has an option that can cause the weights of the model to be non negative : tf.keras.constraints.NonNeg() https://keras.io/api/layers/constraints/ basically my question is : what is the equivalent of this in pytorch?
