[site]: crossvalidated
[post_id]: 623873
[parent_id]: 623871
[tags]: 
If I understand you correctly, you select Ax and Bx based on all N instances taken together, rather than using the best performing A and B for each instance separately. What you do violates independence between instances (as assumed by the test), so one can argue that it is invalid. That said, I tend to argue that the idea is wrong that model assumptions need to be literally fulfilled for statistical inference to be valid, because nothing in life is really perfectly independent of anything else, and if we insist in model assumptions to be perfectly fulfilled, we can't ever do anything. The really relevant issue is always whether model assumptions are violated in a way that would with too large probability mislead conclusions from the inference . This in general depends on what exactly is done and how conclusions are to be interpreted. As a first reaction I was thinking that maybe violations of independence are not critical here, but thinking a bit more about it, I now think they could be. Consider a situation in which A1, B1, B2 and B3 are equally good, and much better than A2 and A3. This means that A1 will win the A-competition easily, whereas there will be a random winner in the B-competition. The winner in the B-competition can be expected to have performed better on the given instances than it should be on average, because it was selected against equally good alternatives. Therefore it will have an advantage against A1 which could just win the A-competition on a normal performance. So no, this is invalid. It may be possible to devise a resampling/permutation scheme that could test Ax against Bx in a valid manner based on the Wilcoxon (or any other) test statistic, but for the moment I'm too lazy trying to design it.
