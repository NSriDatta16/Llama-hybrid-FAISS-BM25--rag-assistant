[site]: datascience
[post_id]: 39809
[parent_id]: 39808
[tags]: 
If you need to re-train the model to classify new faces, this will not scale well to registering new people routinely. You may also suffer from glitches in accuracy during new registrations unless the training routines are carefully monitored. Instead, recognition systems that need to register new items typically don't re-train. They are trained on the general task of separating objects - identifying whether they are different or what is different about them. One common way to achieve this separation is to use the NN to map images of faces to a descriptive vector, and match each new image according to distance to stored vectors of profile pictures. The distance, even to the closest stored vector, should be small in order to consider it a successful match. Registering a new user is then a matter of saving a new vector embedding calculated from the neural network. Matches can be done with database lookups - they are still limited by how fast you can do the distance calculations looking for a match, but you only need run the NN forward once. The distance calculations can be fast and batched - it should be easy to use e.g. tensorflow or torch to calculate 1000 potential matches in a fraction of a second. To ensure that faces are well categorised according to their differences, ignoring lighting, pose, hairstyle etc, the network needs to be trained with this objective in mind. One way to do this is to train with triplet loss using two pairs of images, one that should match, another that should not. Andrew Ng's course on CNNs covers this approach very well, starting from this lecture .
