[site]: crossvalidated
[post_id]: 595049
[parent_id]: 
[tags]: 
What's the role of the commitment loss in VQ-VAE?

I'm reading about VQ-VAE , and trying to understand the commitment loss $\beta||z_e(x) - sg(e)||^2$ , described in the following sentence: Finally, since the volume of the embedding space is dimensionless, it can grow arbitrarily if the embeddings $e_i$ do not train as fast as the encoder parameters. To make sure the encoder commits to an embedding and its output does not grow, we add a commitment loss, the third term in equation 3 what do they mean by the embedding space volume being dimensionless? and what would happen if we omit this term? aren't we covered by the reconstruction loss term?
