[site]: crossvalidated
[post_id]: 84214
[parent_id]: 
[tags]: 
Multiple Linear Regression with Combined Variables

Question: Suppose we have an ordinary household scale such as might be used in a kitchen. When an object is placed on the scale, the reading is a combination of the true weight plus a random error. You have two coins of unknown values B1 and B2. To estimate the weights of the coins, you take four observations: Put coin 1 on the scale and observe y1 Put coin 2 on the scale and observe y2 Put both coins on the scale and y3 Put both coins on the scale and observe y4 (a) Write a linear model in matrix form and find the least-squares estimate of the coins using the usual formula (X'X)^-1 X'y. Regarding the question from letter (a), my understanding is that for either B1 or B2, they can be estimated by averaging the weights (for example, for B1 it would be adding the weights from y1, y3 and y4). Is this assumption valid? I thought it was, and so I tried to set up the formula for B1: B1 = 1/3*K1*Y1 + 0*K2*Y2 + 1/6*K3*Y3 + 1/6*K4*Y4 + e1 + e2 + e3 + e4, and B2 = 0*K1*Y1 + 1/3*K2*Y2 + 1/6*K3*Y3 + 1/6*K4*Y4 _ e1 + e2 + e3 + e4, where Ki is the slope parameter estimate for the ith coin and ei is the residual for the ith coin. The numbers 1/3 and 1/6 (1/3 * 1/2) to find the average weight of B1 . Am I totally off base with this reasoning and subsequent setup of my linear model? Can I also assume that y3 is found by simply adding y1 and y2 ? I didn't think I could, because the readings would probably be different and thus have different residuals. Does the y in the formula correspond with the estimated column vector containing predicted B1 and B2 ?
