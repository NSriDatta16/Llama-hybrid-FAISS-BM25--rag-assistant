[site]: crossvalidated
[post_id]: 291552
[parent_id]: 
[tags]: 
Why do we sample from log space when optimizing learning rate + regularization params?

Since I took Karpathy's CS231n I used the method he mentions on the 5th lecture for hyperparameter optimization of neural networks which samples the learning rate and regularization parameters from the log space randomly. It seems to work great from experience, but I never understood why that's the right thing to do from the lecture. I would appreciate an intuitive explanation about why the log space is where we sample from.
