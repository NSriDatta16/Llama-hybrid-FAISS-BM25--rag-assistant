[site]: crossvalidated
[post_id]: 190459
[parent_id]: 189183
[tags]: 
Since it looks unlikely that your question will get an answer soon, I decided to have a go. This is part answer and part request for further clarification. The things I seek clarification of may give you some idea why you didn't get answers (besides the reduced presence of people around the start of January). (Besides answering some of the question, this must go into an answer because there are far too many questions to fit into a comment, or even two.) I now want to calculate different things. mean of the distribution - easy, done. Well, no , it's not done. You calculated something, sure, but it almost certainly wasn't what you just said. You can't calculate the mean of the distribution from which the data were drawn ( $\mu$ ) unless you have the population -- and from your description it sounds like you have some kind of sample. So the thing you calculated would be a sample mean. If that sample was a random sample* from the population of interest (and I'm not sure this is the case from your brief description) then your sample mean would be a reasonable way to estimate the population mean (the mean of the distribution). For a random sample, the estimator $\bar{X}$ has the desired expected value ( $E(\bar{X})=\mu$ ). * certain kinds of non-random samples (e.g. where one identifies the subpopulations you indicate are present and then samples randomly within each of those) can be used but I'll avoid discussion of that unless it turns out to be necessary. statistical error of the overall mean. That depends on what "statistical error" means (it's not an especially standard term in statistics). If you mean "the standard error of the estimate of the population mean", that would be $\sigma/\sqrt{n}$ , but note that you don't know $\sigma$ any more than you knew $\mu$ . You can estimate it from the sample of course (typically by the sample standard deviation $s$ ), subject to the same requirement of random sampling. there we argued that natural quantities are always Gaussian-distributed That would seem highly unlikely to me (some such quantities would presumably be necessarily positive, for example). What was the basis of this argument? Now this here is a technical measurement. Your terminology is unfamiliar. Can you either avoid the jargon or explain its meaning? What's a technical measurement? What's a natural quantity? Why is there a distinction between them with respect to estimating a mean? *Edit (much later): it occurs to me that you might be referring to a measurement using an instrument that has some measurement error . Is that the kind of thing you mean?* I do not see how I could apply the Gaussian errors or the central limit theorem here as we don't sum independent random variables. Now I am really confused. When you calculated a sample mean you didn't sum the observations along the way? Or are you saying the observations you averaged were dependent? (Or perhaps you mean to say that you didn't have very many values, in which case standardized means would not be close to normally distributed.) measurements can have upper and lower technical limits I'm not 100% sure what you're saying there. Do you just mean the variable being measured may be bounded (e.g bounded below, for things that are necessarily positive)? how can subsampling What kind of subsampling are you talking about? What is it precisely you're proposing to do?
