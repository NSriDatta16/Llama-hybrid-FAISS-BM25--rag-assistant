[site]: datascience
[post_id]: 38852
[parent_id]: 
[tags]: 
How to compare slope of two time series

Suppose we have the 2 sets of time series data L1,M1 sampled at the same 1000 points of time t[t1,t2,...t1000]. Lets assume before hand that that the L1 can be given as L1 = tX+a where X is the slope and a is the noise and M1 can be give as M1 = tY+b Now I want to know how to formulate a parameter that measures the difference between slopes of L1 and M1 from their respective 1000 sampled points. I am a novice when it comes to statistics, so any help or hints would be deeply appreciated.
