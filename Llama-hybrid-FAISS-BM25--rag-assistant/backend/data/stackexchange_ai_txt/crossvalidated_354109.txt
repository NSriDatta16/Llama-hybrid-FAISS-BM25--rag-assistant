[site]: crossvalidated
[post_id]: 354109
[parent_id]: 354084
[tags]: 
One obvious possibility for dealing with having very little information in the dataset you analyze is to use Bayesian methods, particularly if you have prior information on the question under analysis. In most programming languages there are packages that allow you to do that (e.g. rstan , or perhaps easier rstanarm or brms in R, proc mcmc in SAS). In fact, the Firth penalized likelihood regression is equivalent to Bayesian maximum a-posteriori estimation with Jeffreys prior. Note that without informative priors you will struggle to do much with very sparse data (such as just 12 cases out of 600), unless you are only investigating a single factor that is associated with a huge effect size. By the way, exact logistic regression does not normally use MCMC sampling, you simply can approximate it quite well using MCMC sampling. Perhaps the impression that this is the standard approach arises, because there simply is no R package that implements any other approach? In contrast e.g. SAS or StatXact have "real" exact logistic regression.
