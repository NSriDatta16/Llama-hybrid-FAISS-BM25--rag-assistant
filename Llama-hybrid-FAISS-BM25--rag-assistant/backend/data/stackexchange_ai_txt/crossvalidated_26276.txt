[site]: crossvalidated
[post_id]: 26276
[parent_id]: 
[tags]: 
Cross entropy and the fitness function

I'm training some neural networks using NEAT C++, and would like to use the cross-entropy error function: $$E = -t\ln(y) -(1-t)\ln(1-y)$$ to train a network for a two-class classification problem. NEAT C++ is a C++ library that allows one to use a special kind of neuro evolution (namely that of augmenting topologies ) to train the networks. Yet to be able to use it, one needs to define a fitness function (and not an error function, such as the one above). Question: How can I construct a fitness function from the cross-entropy error function? Everything below this line is wrong I guess because $E\in [0,\infty]$, and thus it's impossible to define a maximum. How should I do it then? I was thinking about this: calculate the maximum error $E_{\text{max}}$ somehow and define the fitness, given a certain network output $y$, as: $$f(y)=E_{\text{max}} - E(y)$$ This way the fitness will be $0$ when $E(y)=E_{\text{max}}$ and it should reach a maximum if $E(y)=0$. Is this the right method? If so how do I calculate the maximum error $E_{\text{max}}$? note: NEAT does not allow the use of negative fitness functions, so using $f(y)=-E(y)$ would not work. Also I would like to refrain from using arbitrary stuff such as $f(y)=10000000 - E(y)$ .
