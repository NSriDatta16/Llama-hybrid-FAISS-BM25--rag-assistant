[site]: datascience
[post_id]: 102786
[parent_id]: 
[tags]: 
Steps of multiclass classification problem

So this question is more theoretical, than a practical one. I got a dataframe with 4 classes of cars' body types (e.g. sedan, hatchback, etc.) and different characteristics (doors, seats, maximum speed, etc.). The goal is to build a model, which predicts class by means of provided features. The steps, which I've applied are the following: Encode classes of body types into variables (0, 1, 2, 3 Check if classes are balanced and in case of imbalance correct this issue Feature selection based on the results of Pearson, Chi-2, RFE, logistic regression and XGBoost Applying k-fold cross-validation with XGBoost on the whole dataset. What is the correct order of implementing steps from the second one and so on? Should I firstly balance classes, then pick features and then apply XGBoost? Furthermore, should I split dataset into train and test and only then apply CV or may I stack XGBoost with CV on the whole dataset? UPD: the class distribution is below 1 0.512228 2 0.282609 0 0.118207 3 0.086957
