[site]: datascience
[post_id]: 74347
[parent_id]: 
[tags]: 
How would you - on-the-fly - prevent a neural network from overfitting using a Keras callback?

I have a neural network that starts to overfit in that the validation loss begins to increase while the training loss stays ~ flat with epochs. Is there a generic algorithm - obvious or otherwise, well-known or not - to stop the training early if overfitting is somehow detected? I note that catboost implements such an algorithm but I have found it nowhere else. https://catboost.ai/docs/concepts/overfitting-detector.html Is this all simply a matter of rolling my own callback function and stopping when the training and validation losses start to diverge..? Preference for TF, Keras, python3, ... Thanks as ever
