[site]: crossvalidated
[post_id]: 439938
[parent_id]: 
[tags]: 
Percents of Random Samples

I have three sets $A,B,C$ of sizes $N_A=2508$ , $N_B=36211$ and $N_C=2296$ respectively, containing binary values. I took 200 samples of each set to produce point estimates of the averages: $\hat p_A=0.245$ , $\hat p_B=0.04$ , $\hat p_C=0.035$ . I approximated the respective standard deviations using the usual proportion standard deviation formula with finite population correction. I am interested in the percent of ones in each distribution relative to the total number of ones in all distributions. For instance, an estimate of the proportion of ones that exist in population $A$ relative to all distributions is $$\frac{N_A\hat p_A}{N_A\hat p_A+N_B\hat p_B+N_C\hat p_C}\times 100\% = 28.7\%$$ (Note that I have found multiple ones in each set, so the percent is well-defined.) I want to quantify the uncertainty of this percent. I have tried using standard "propagation of error" formulas for computing standard deviation under addition and division (apparently corresponding to the formulas from addition and division of normal variables), but these don't take into account that the term on the numerator ( $N_a\hat p_A$ in the example above) appears in the denominator. To illustrate the issue, note that naive usage of the division formula would not conclude that $p_A/p_A$ is unity with a standard deviation of 0. Thus I am getting a wider standard deviation than necessary using this formula. How could I quantify the uncertainty of the percent accurately?
