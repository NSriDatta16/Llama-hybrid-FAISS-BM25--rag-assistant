[site]: crossvalidated
[post_id]: 124922
[parent_id]: 124235
[tags]: 
In the scenario depicted in your example, you could permute the $Y$'s. But note that this only works because the $Y$ themselves do not have any temporal dependence on each other, once you condition on the average of the $X$. In general, with time series, you need to make assumptions about how the correlations will manifest in $X$ and $y$. This is because it is these assumptions that tell you what the "independent units" are to resample. If $Y$ was an AR-1 process (so has a memory of its previous value, beyond what the $X$ dictate), then simple permutation on $Y$ wouldn't work. I would suggest consulting a book on bootstrapping and permutation if you think this is the case--there are developed methods out there for bootstrapping time-series that I am not familiar with enough to comment on there. One good book is " Bootstrap methods and their application " by AC Davidson. Anyways, if you believe that your $Y$ really are independent realizations (at least given some feature in your model), I would recommend a blocked procedure, where you loop through your features for a fixed permutation of $Y$ Form your features $X_1, X_2, \dotsc, X_m$ For p = 1, ..., P: a. Permute $Y$ b. For each feature $X_1, \dotsc, X_m$, calculate your favorite measure of association, ie, $R^2$, Kendall's $\tau$, whatever. Tabulate your association statistics. If you want to control the probability of falsely finding any one of the features to be associated, then over each permutation, take the maximum association you find across features. Methodological Comment Also, I should comment that if your goal really is to "identify time periods that are significantly correlated with the target" variable, there are other approaches besides this one that you should research. In particular, smoothing splines and wavelet bases for $X$ would be two areas that I'd investigate. There's a whole host of literature out there under the rubric of "functional linear regression."
