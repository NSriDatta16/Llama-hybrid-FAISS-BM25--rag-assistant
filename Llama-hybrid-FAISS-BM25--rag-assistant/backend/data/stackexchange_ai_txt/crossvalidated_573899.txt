[site]: crossvalidated
[post_id]: 573899
[parent_id]: 259858
[tags]: 
From the comments, it is evident that you mean some kind of predictive accuracy measurement, any of which would be a function of the predictions and the true observations. Multicollinearity cannot affect the true observations, since they are the observations even if you don't do any modeling, so for multicollinearity to influence the predictive accuracy, multicollinearity must influence the predictions. Let's do a simulation where we do a logistic regression on two correlated variables, regress on a transformation of those variables that retains all of the information while removing the correlation, and comparing predictions. library(MASS) set.seed(2022) N Aside from floating point arithmetic issues out past the $14^{\text{th}}$ decimal place, the predictions are the same. In GLMs, multicollinearity can affect interpretations, p-values, and confidence intervals, but multicollinearity does not affect the predicted values . Some people also dislike multicollinearity because they think they can drop some variables and retain most of the information while lowering the parameter count. As much as that makes sense, it is not perfect and might even be fairly problematic.
