[site]: crossvalidated
[post_id]: 474730
[parent_id]: 474499
[tags]: 
BLEU to some extent captures the word order well. You can get a better idea by trying BLEU- $n$ metric, where $n$ means the longest $n$ -gram being consider. (In the early days of image captioning, the typical evaluation metric was BLEU-1). But as you noted, it becomes less efficient with the growing length of the text. But if you could reasonably sentence-split the documents, it should work well. Alternatively, I would suggest measuring perplexity with respect to a language model. If you worry that the perplexity would be too much influence with the lexical choice, you might consider a language model trained on sequences of POS tags.
