[site]: crossvalidated
[post_id]: 365210
[parent_id]: 
[tags]: 
Finding chain of observations using homogeneous Markov chain

I am reading about Markov chain and I understand how to find stationary distribution of a Markov chain and the transition probability matrix at some time t. But what I fail to understand how can one use it to get a chain of observations. So let's say I have 2 different states (s1,s2) some initial distribution and some transition probability matrix for these two states. And I want to output a string of states(s1, s2) of some desired length. Is there a formula for it? How can do that?
