[site]: crossvalidated
[post_id]: 619328
[parent_id]: 
[tags]: 
Learning Curve on two classifiers

I am using a logistic regression classifier and Gridsearch to optimize negative log loss. After generating its learning curve to test for overfitting/underfitting, my model seems to return this learning curve. Note that my y-axis is log loss, and my x-axis is my iterations. Is this a sign of good fit? I wasn't sure as my training score curve looked a bit odd since its started to rise again at the 5000th iteration. I also have the same data set trained on a XGBoost classifier, and after using Gridsearch to optimize hyper parameters for negative log loss, I was achieving this for my learning curve. This is most definitely overfitting correct? What is the best way I can utilize GridSearch to both optimize negative log loss, yet also prevent overfitting/underfitting. EDIT: The code I used to plot the Learning Curve. #learning curve train_sizes, train_scores, val_scores = learning_curve( model, X_train, y_train, cv=5, scoring='neg_log_loss', train_sizes=np.linspace(0.1, 1.0, 10) ) # Calculate the mean and standard deviation of the training and validation scores train_scores_mean = np.mean(train_scores, axis=1) train_scores_std = np.std(train_scores, axis=1) val_scores_mean = np.mean(val_scores, axis=1) val_scores_std = np.std(val_scores, axis=1) # Plot the learning curve plt.figure(figsize=(8, 6)) plt.title("Learning Curve") plt.xlabel("Training Examples") plt.ylabel("Log Loss") plt.grid() plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r") plt.fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.1, color="g") plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training Score") plt.plot(train_sizes, val_scores_mean, 'o-', color="g", label="Validation Score") plt.legend(loc="best") plt.show()
