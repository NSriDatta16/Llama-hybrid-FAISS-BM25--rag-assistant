[site]: datascience
[post_id]: 67476
[parent_id]: 67474
[tags]: 
There are multiple ways to tackle this. I'll suggest two here. [1] The one that probably requires the least amount of preprocessing work is to throw the event data into a recurrent neural net that can handle variable sequence lengths. Map the event categories to a small embedding space and run it through the RNN. You can then concatenate the remaining static features and put a feed-forward classifier on top. This would take care of 1) and 2). In order to account for 3) there are several tricks. You can append the time to event to the embedding vectors You can multiply the embedding vectors with a "time mask" (i.e. feed the sequence of event lagging times into a RNN with sigmoid activation und multiply element-wise. The idea is that the sigmoid activation will put a weight on the event based on the time passed, e.g. an event many months ago will be unimportant and therefore receive an activation close to 0). See section 3.1. in this paper That paper also suggests another solution where you can learn a joint embedding of time and event (section 3.2). Note that both methods report only minor (but consistent) gains over standard RNNs. [2] Given that your number of event categories is low you could also just one-hot encode the event or use a tree-based method like gradient boosting and feed the events, the time between events and your remaining features as separate inputs into the model. Unless your dataset is very huge this will perform equally well if not better because you don't have to learn embeddings and have a lot less model parameters. The only difficulty is that you will now have to fix the sequence length. But you can pad shorter sequences with N/A or 0 values and I would not expect any performance decrease because of it!
