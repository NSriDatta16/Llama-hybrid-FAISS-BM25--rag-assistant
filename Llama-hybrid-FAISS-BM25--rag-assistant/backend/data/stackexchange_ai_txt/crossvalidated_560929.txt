[site]: crossvalidated
[post_id]: 560929
[parent_id]: 
[tags]: 
How does neural network learn feature functions?

I was wondering if there is some intuitive way of thinking about the fact that neural networks learn the feature function $\phi(x_i)$ along with the feature weights $\theta$ . Because this is really the point of using a net: they will find the relevant feature functions and tune their weights to obtain decent results. But when you're training a net you're only updating the weights matrices $W^{(l)}$ of the net. I was thus wondering what exactly is referred (in terms of maths) when we say that the neural net is learning the feature function? The goal would be to somehow compare this intuition with the standard regression $ \hat{y}_i = \theta^T \phi(x_i)$ . Where we have to define ourselves the feature function and regression techniques take care of finding the appropriate weights $\theta$ .
