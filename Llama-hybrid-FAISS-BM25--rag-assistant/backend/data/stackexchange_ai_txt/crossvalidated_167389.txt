[site]: crossvalidated
[post_id]: 167389
[parent_id]: 
[tags]: 
What statistical test should I run to select "explicative" features in my dataset?

I have a database with more than 500 samples with 22 quantitative features each and I would like to predict a categorical variable (0 or 1). I am trying to fit a logistic regression model and a neural network in R using glm and the neural net package. By selecting different features I noted that I get different results in terms of ability of my two models to predict the test set (another 500+ samples database) a +-10% in accuracy depending on how many and what features are used (using the same test set). Essentially the models seems to get worse using more than 12 features on average but of course I cannot try all the combinations and I'd rather not use random features as a blind guess. Also the neural network seems a little bit picky on features and does not always converge (however this is a minor issue). What tests could I run in R to select the most "explicative" features? (By the way, is "explicative" the right terminology?)
