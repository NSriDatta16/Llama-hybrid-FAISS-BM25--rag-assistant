[site]: crossvalidated
[post_id]: 467876
[parent_id]: 
[tags]: 
Why do Bayesian hierarchical models converge where frequentist models do not?

I am analysing an experiment looking at abstinence rates among participants in a clinical drug and alcohol trial. There were two groups, those who received the new treatment and those who received placebo. Abstinence during the previous week was measured at 0 (baseline), 4, 8, 12, and 24 weeks. There was a high rate of attrition/missing data over the course of the trial so that of the 128 that commenced the trial, only 55 supplied data at follow-up. I want to estimate the group difference in odds of abstinence at each time point, controlling for the other time points. I am especially interested in the difference in odds of abstinence at week 24 (controlling for all the other timepoints). Here is the data. df The proportions of the observed cases who were abstinent over time look like this Which, on face value, looks like a decent treatment effect, especially at week 24. Here is the model in brms , a package that runs stan models using lme4 -based syntax. The priors for the fixed effects of group and time on log-odds of abstinence are wide, normal distributions centred on zero. m Now this same model fails to converge in packages that use frequentist methods, such as geepack , lme4 , GLMMadaptive and glmmTMB packages. What I want to know is why does the Bayesian model converge when the frequentist versions fail and return error messages? Is it because the regularising priors help guide the algorithm which values to spend its time exploring? Despite its converging, the result of this model trouble me. Especially concerning is the size of the log-odds coefficient for the grouptreatment:time24 effect. Exponentiating 4.26 yields an odds ratio of 70.8! This does not seem like a reliable estimate to me, given that the proportion abstinent at this time point in the placebo group is 6/29 = 20.7% and the proportion in the treatment group is 14/26 = 53.8% So my second question is why are these log-odds coefficients so high? The output calls them 'population-level' effects but is it possible they in fact subject-specific effects of the sort usually returned by frequentist version of these models (see here ?) Another possibility that occurred to me is that the estimates at week 24 are unstable because there are so few data at this time point (n=55) compared to week 0 (n=128). I have run frequentist repeated-measures logistic regressions before and not encountered convergence problems. So I guess another supplementary question I have is why do the frequentist models fail to converge in the first place? I guess my problem is I don't run a whole lot of panel models with binary outcomes. Maybe the estimates of the week-24 group effect are fine and the odds of abstinence at week 24 in the treatment group controlling for all other time points are actually seventy times higher than in the placebo group, but my gut tells me they're not. I just need some advice from people with more experience with these sorts of models, frequentist, Bayesian or otherwise.
