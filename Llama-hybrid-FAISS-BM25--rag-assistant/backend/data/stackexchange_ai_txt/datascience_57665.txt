[site]: datascience
[post_id]: 57665
[parent_id]: 57641
[tags]: 
It appears that you are training your model and generating predictions on the same dataset (X_new). You should not attempt to evaluate your model's performance using this output - because you are applying the model to the same data you trained it on, your evaluation will be over-optimistic. You need to set a portion of your dataset aside as test data, train the model on the remainder, and then apply the model to the independent test data. You can then calculate performance metrics like MSE or MAE as mentioned in the other answers, which will give you an unbiased estimate of how your model performs on unseen data. Cross-validation is another way to get an unbiased estimate of performance, which is essentially repeating train-test splits in a way to leverage all the available data.
