[site]: crossvalidated
[post_id]: 281240
[parent_id]: 
[tags]: 
Why is the cost function of neural networks non-convex?

There is a similar thread here ( Cost function of neural network is non-convex? ) but I was not able to understand the points in the answers there and my reason for asking again hoping this will clarify some issues: If I am using sum of squared difference cost function, I am ultimately optimizing something of the form $ \Sigma_{i=1}^{N}(y_i - \hat{y_i})^2$ where $y$ is the actual label value during training phase and $\hat{y}$ is the predicted label value. As this has a square form, this should be a convex cost function. So what is it that could make it non-convex in a NN?
