[site]: crossvalidated
[post_id]: 338938
[parent_id]: 
[tags]: 
Cost complexity pruning and prediction error

I am reading the book titled "An Introduction to Statistical Learning" by James et al. There it is mentioned on page 309 that we pick the cost complexity parameter α to minimize the average Mean Squared Prediction Error. Then on page 326, the following is mentioned: "We use the argument FUN=prune.misclass in order to indicate that we want the classification error rate to guide the cross-validation and pruning process, rather than the default for the cv.tree() function, which is deviance." My question is when using cross-validation to choose α, which criterion should we use then? Average Mean Squared Prediction Error or Classification error rate? It seems that at one place it is mentioned that we need to look at the average mean squared prediction error and at another place it is mentioned that we need to use classification error.
