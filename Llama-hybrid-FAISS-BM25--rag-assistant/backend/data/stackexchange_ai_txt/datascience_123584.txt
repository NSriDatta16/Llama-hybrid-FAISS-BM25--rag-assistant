[site]: datascience
[post_id]: 123584
[parent_id]: 123501
[tags]: 
By looking at your plot, and because it is a Continuous Time Markov Model (CTMM) I think the holding time in each state is exponentially distributed. There is no specific name for it. It is probably the simplest case for a CTMM (simplest in the sense, that fitting the model and computing future states is more simple vs some other distribution). For CTMM you still have many variants. 2.a. In the simplest case you can assume, there is a common distribution for holding time that does not depend on the state. You can just fit an exponential distribution to the holding times (exponential distribution has only one parameter: lambda). Then you also need to estimate transition probabilities of the Markov Chain. This is also easy, because you just need the count of state transitions for that (0->1; 1->0,1->2; 2->1,2->3; etc.) Let's call this the training/fitting of the MM. As a result you get the transition probability matrix. 2.b. The model becomes more complicated if you assume a different holding time distribution for each state. Depending on the application/data/requirements you can work with discretized times. If within-day transitions are not important, or perhaps granularity of your data is just daily/hourly use a DTMM. One essential difference is that now you don't have to fit/calculate the holding time distribution only the state transition matrix (this time probability of 0->0; 1->1; 2->2 state transitions will be non zero). But now of course your state predictions are on a daily/hourly granularity. Based on your description first I would go with a simple DTMM. No hidden states (DT HMM). You mention next state "may have some dependence on earlier states". This might be an indicator of hidden state, but I suggest to start with a simple model. RNNs are hidden state models, but require lot's of data, the model is a black box (as opposed to a MM, which is well interpretable). Predictions: Yes, after training the model you can just generate/simulate many sequences. Note, that since MM are stochastic models, predictions are not certain. In the simplest cases you can also analytically compute the probability of a certain state (or all states) at a specific time point. Or you can compute the probability of a certain state sequence. For these computations you just need the initial state and the transition probability matrix (which you estimated when you trained/fitted the model). More detailes here: Markov Chain Wikipedia Page Check carefully what is the requirement. "Predicting future state sequence" can mean lots of things. Maybe you just need something very simple. Like "the probability, that state 4 will be reached within 7 days".
