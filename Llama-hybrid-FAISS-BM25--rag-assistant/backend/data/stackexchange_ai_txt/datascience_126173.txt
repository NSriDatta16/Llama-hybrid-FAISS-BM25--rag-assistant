[site]: datascience
[post_id]: 126173
[parent_id]: 
[tags]: 
My model combines EffcientNetB0 and LSTM with X_train size is (150,150,3), model does not fitâ€¦

input_shape=(150,150,3) effnet = EfficientNetB0(weights=None,include_top=False,input_shape=input_shape effnets=effnet.input_shape#(150,150,3) Res_model = effnet.output print(Res_model.shape) #(None, 5, 5, 1280) model = tf.keras.layers.GlobalAveragePooling2D()(Res_model) print(model.shape) #(None, 1280) model= tf.keras.layers.Dense(512, activation = "relu")(model) print(model.shape) #(None, 512) model = tf.keras.layers.Dropout(rate=0.5)(model, training=True) print(model.shape) #(None, 512) model = tf.keras.layers.Dense(32,activation='softmax')(model) print(model.shape) #(None, 32) model = tf.keras.models.Model(inputs=effnet.input, outputs = model) #print(model.input_shape) #(None, 150, 150, 3) #print(model.output_shape) #(None, 32) #LSTM from tensorflow.keras.models import Model # Define the input shape for the sequence data sequence_input = Input(shape=(150,150)) print(sequence_input.shape) # Instantiate the LSTM model lstm_model = LSTM(32)(sequence_input) print(lstm_model.shape) # Concatenate the output of the EfficientNetB0 model and the LSTM model concatenated = Concatenate()([model.output, lstm_model]) # Add a dense layer to the concatenated output output = Dense(2, activation='sigmoid')(concatenated)#input_shape=[(None, 5, 5, 1280), (None, 32)] # Define the final model model1 = Model(inputs=(Res_model,sequence_input), outputs=output) model1.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy']) history = model1.fit((X_train,y_train), batch_size=32, epochs = 2, validation_split=0.1,verbose=1) ValueError: Failed to find data adapter that can handle input: , ( containing values of types {" "})
