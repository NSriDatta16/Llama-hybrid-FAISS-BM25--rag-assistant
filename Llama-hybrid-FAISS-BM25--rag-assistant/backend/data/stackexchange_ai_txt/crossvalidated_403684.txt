[site]: crossvalidated
[post_id]: 403684
[parent_id]: 403542
[tags]: 
With a decay of 0.01 / a momentum of 0.99, it takes several hundred iterations for the moving averages of the batch statistics to get burned in. This is easy to see because $(1-0.01)^{100} \approx 1/e$ . Note that this is several hundred iterations AFTER training has converged and the batch statistics stop wildly moving around. Therefore using batch norm in test mode before this is premature and will result in strange outputs. Usually batch norm is operated in train mode for validation during training. While setting the decay to a large value solves this, it will produce suboptimal results since you never end up with a good estimate of the mean batch statistics. I would not try to use anything under 0.99 momentum.
