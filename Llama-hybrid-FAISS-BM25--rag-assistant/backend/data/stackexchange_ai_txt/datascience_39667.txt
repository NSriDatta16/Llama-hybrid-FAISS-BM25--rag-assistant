[site]: datascience
[post_id]: 39667
[parent_id]: 
[tags]: 
Depth of a Neural network

I was self-teaching myself. I totally understand why depth of a neural network affects the learning and how it differs than its width. But I am looking for some theoretical justification about it. Papers I could come up with, e.g., Benefits of depth in neural networks or The Power of Depth for Feedforward Neural Networks are unfortunately is too deep and long. I am not also super good at Mathematics, however, I believe there must be a plain, short and compact math behind it. Can someone point me to some tutorials/articles/papers/reports, where I can easily understand it?
