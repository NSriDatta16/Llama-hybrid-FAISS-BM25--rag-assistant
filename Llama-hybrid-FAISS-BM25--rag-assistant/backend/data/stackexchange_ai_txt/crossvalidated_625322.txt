[site]: crossvalidated
[post_id]: 625322
[parent_id]: 
[tags]: 
Can cross-validation be involved in model-building rather than validation?

I have a general idea in mind that would go like this: randomly split the data into training/testing build a model on the training data by choosing from among candidate predictors evaluate it on the testing data repeat n times Find the model that did the best job predicting the testing data. In this way, cross-validation is involved in the model-building stage. Is there a name for this approach that I can Google (and hopefully find an R package for)? I am aware of some similar approaches: Best Subsets will try every possible regression model and find the best one. However, as far as I am aware, this process doesn't involve cross-validation. LASSO uses cross-validation to optimize tuning parameters, but not for variable selection per se. Random Forests will again try various combinations of predictors, but afaik doesn't involve cross-validation in the process.
