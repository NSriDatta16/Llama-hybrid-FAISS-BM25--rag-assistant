[site]: crossvalidated
[post_id]: 478458
[parent_id]: 
[tags]: 
What is the most sound way to perform variable selection on an lmer() model?

Suppose I have 25 candidate predictors in an lmer model. I want to find out which ones are genuine predictors of the dependent variable. What is the best way to perform variable selection on that lmer model? I have read about the drawbacks of stepwise regression, and so I assume that is not the best approach. Though, I have read that some stepwise approaches are better than others (e.g., AIC). I've used penalized regression in the past but I'm not sure if this can be done with an lmer model. I've also recently read about using a Bayesian approach that places laplace priors on each predictor, essentially acting like a LASSO regression and shrinking most of them to 0. I've also heard about random forests but don't believe this can be implemented for an lmer model. I also know that the best way is to use theory to test specific predictors. But in this case, other than one predictor, I don't have theoretical reasons to believe some predictors should matter more than others. I would rather use a data driven approach to find the ones that do matter, rather than testing them all based on very loose assumptions I hold. What would you suggest?
