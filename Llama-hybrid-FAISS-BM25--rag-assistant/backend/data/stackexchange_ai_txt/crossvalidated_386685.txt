[site]: crossvalidated
[post_id]: 386685
[parent_id]: 386683
[tags]: 
Under-sampling, over-sampling and hybrid methods (by combining both) are valid ways to handle unbalanced data, specially on classifiers overly-sensitive to this (such as Neural Networks). If the train and test distributions are different in the target , by experience I advise using such techniques. Otherwise , using some data preprocessing techniques can help your model. For numerical features, you can use scalers according to the original distribution of the training set. For categorical features, you can create rules for handling categories in the test set never seen in the train. Nonetheless, there is nothing like testing the performance of these techniques on some cross-validated training data!
