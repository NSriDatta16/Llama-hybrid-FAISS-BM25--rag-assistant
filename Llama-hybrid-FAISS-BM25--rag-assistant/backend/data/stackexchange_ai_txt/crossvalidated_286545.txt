[site]: crossvalidated
[post_id]: 286545
[parent_id]: 286463
[tags]: 
Peter Ellis has a very simple example where linear regression performs better than regression trees, extrapolating beyond the observed values in the sample. In this image the black points are the observed values, and the colored points are the predicted values. The actual data are generated according to a simple line with some noise, so linear regression and the neural network do a good job of extrapolating beyond the observed data. The tree based models do not. Now, with 60 million data points you might not be worried about this. (The future always manages to surprise me though!) But it is an intuitive illustration as to one situation in which trees will fail.
