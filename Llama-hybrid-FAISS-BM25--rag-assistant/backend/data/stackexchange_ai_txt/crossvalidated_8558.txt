[site]: crossvalidated
[post_id]: 8558
[parent_id]: 8557
[tags]: 
Is the question of curiosity, i.e. you are not satisfied by my answer here ? If not... The further investigation of this tricky question showed that there do exist a commonly used rule-of-thumb, that states two models are indistinguishable by $AIC$ criterion if the difference $|AIC_1 - AIC_2| . The same you actually will read in wikipedia's article on $AIC$ (note the link is clickable!). Just for those who do not click the links: $AIC$ estimates relative support for a model. To apply this in practice, we start with a set of candidate models, and then find the models' corresponding $AIC$ values. Next, identify the minimum $AIC$ value. The selection of a model can then be made as follows. As a rough rule of thumb, models having their $AIC$ within $1–2$ of the minimum have substantial support and should receive consideration in making inferences. Models having their $AIC$ within about $4–7$ of the minimum have considerably less support, while models with their $AIC > 10$ above the minimum have either essentially no support and might be omitted from further consideration or at least fail to explain some substantial structural variation in the data. A more general approach is as follows... Denote the $AIC$ values of the candidate models by $AIC1$ , $AIC2, AIC3, \ldots, AICR$ . Let $AICmin$ denotes the minimum of those values. Then $e^{(AICmin−AICi)/2}$ can be interpreted as the relative probability that the $i$ -th model minimizes the (expected estimated) information loss. As an example, suppose that there were three models in the candidate set, with $AIC$ values $100$ , $102$ , and $110$ . Then the second model is $e^{(100−102)/2} = 0.368$ times as probable as the first model to minimize the information loss, and the third model is $e^{(100−110)/2} = 0.007$ times as probable as the first model to minimize the information loss. In this case, we might omit the third model from further consideration and take a weighted average of the first two models, with weights $1$ and $0.368$ , respectively. Statistical inference would then be based on the weighted multimodel. Nice explanation and useful suggestions, in my opinion. Just don't be afraid of reading what is clickable! In addition , note once more, $AIC$ is less preferable for large-scale data sets. In addition to $BIC$ you may find useful to apply bias-corrected version of $AIC$ criterion $AICc$ (you may use this R code or use the formula $AICc = AIC + \frac{2p(p+1)}{n-p-1}$ , where $p$ is the number of estimated parameters). Rule-of-thumb will be the same though.
