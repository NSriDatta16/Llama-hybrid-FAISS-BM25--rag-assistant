[site]: crossvalidated
[post_id]: 52638
[parent_id]: 52632
[tags]: 
Short answer - yes, they have a statistical basis. The choice of the basic form of rule (difference between medians as a proportion of overall visual spread) is based on trying to find a simple rule than works 'in the classroom', while the numbers within that rule are based on simulation using normal samples, and then checked against somewhat skew and heavy tailed distributions (the rules - as would be expected - are robust to such changes). More detailed answer: From: Wild, C. J., Pfannkuch, M., Regan, M., & Horton, N. (2011). Towards more accessible conceptions of statistical inference (with Discussion). Journal of the Royal Statistical Society: Series A (Statistics in Society) , 174(2), pp247-295. Quote of the relevant paragraph on page 263: 3.4.3. Milestone 2 At the milestone 2 level all of the milestone 1 points (a)–(e) should be reinforced. Two new ingredients are stressed at milestone 2: first, that sample size matters when making the call and, second, a moving of attention towards distance between centres as a proportion of a spread. Our first attempt at this guideline compared the distance between medians with the sum of the interquartile ranges but we were told by the teachers whom we were consulting that this was too difficult for their students and this conversation led us to the ‘overall visible spread’ idea that is shown in the diagram. We obtained the very simple cut-off proportions that are depicted by using simulations with normal data. The type I error rates are about 8% at the anchor sample sizes. There is a trade off between more conventional type I error rates at memorable sample sizes (30 is ‘traditional classroom size’) and having an extremely simple rule. We gave more weight to the latter. The round number sample sizes with approximate 5% type I error rates are $n=40$ for $\frac{1}{3}$ , $n=80$ for $\frac{1}{4}$ and $n=125$ for $\frac{1}{5}$ . The type I error rates with data from the strongly skewed $\chi^2_4$ -distribution and the heavy tailed $t_4$ -distribution are very similar to those from the normal distribution at the anchor sample sizes. Despite the milestone 2 guidelines being transitional as far as formal significance testing is concerned, they have lasting value as rough rules of thumb for exploratory data analysis. (emphasis mine) From other things I've been looking at, it looks like these rules are intended to apply where both samples have 'approximately this sample size'. These rules look pretty reasonably grounded while being fairly simple and reasonably memorable. I plan to incorporate them into my own toolbox alongside several other rules of thumb I already possess, and would happily teach both the milestone 2 and milestone 3* rules of thumb to adults. *(not shown here, but they're more 'standard' rules related to notched boxplots that I've seen before) Several edits in here: Note that the rule you have there is based on a smaller sample size (30, not 40, and 100 not 125). The 30 and 100 are what is referred to as 'anchor sample sizes' The type I error rate for the rule you have is not going to be 5% but the higher figure of 8%. (I've checked using simulation and the mentioned figures of 5% and 8% are fairly close.) From my simulations, the results are robust to differences in spread (in fact the significance level drops a little, so it's mildly conservative for unequal spread). Do you need some of the terms in the quote explained?
