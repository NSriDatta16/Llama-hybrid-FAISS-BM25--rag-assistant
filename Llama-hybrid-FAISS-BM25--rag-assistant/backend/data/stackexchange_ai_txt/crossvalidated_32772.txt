[site]: crossvalidated
[post_id]: 32772
[parent_id]: 32767
[tags]: 
I would say the answer to your first question is "no, this is not an appropriate way to sum the estimates of time for individual tasks". It would be appropriate if the random element of the time taken to complete each task were independent of the randomness in the other tasks; but this seems unlikely. Obvious sources of dependence would include: the initial estimates were all biased in the same direction due to the project manager's pessimism or optimism a key resource that is used in more than one task on the critical path is under or over performing, leading to several tasks taking more or less time than predicted How much of a problem this is is entirely a pragmatic matter and depends on the usual size of the covariance of task times (ie how much dependence there is in the way they differ from their estimates). On your second question re t v Z statistics when there are less than 30 estimates of task time to add (I wouldn't call this a "sample" as your reference seems to - it's a bit counter-intuitive, although it could be justified if you twist your brain around enough). I would say that in fact the t distribution should be used all the time because the variances are all estimated. However, as n becomes bigger the t distribution becomes effectively identical to a normal distribution. Wikipedia's article on the t distribution has a table of the critical values, or any stats program (even Excel) can provide it. As you're only worried about exceeding a certain threshhold, you can use the one-sided values (and this seems to be how you do your Z estimates). The appropriate degrees of freedom is a bit of a guess (because of the way variances are estimated in the first place) but is probably the number of tasks for which you are adding estimates, minus one. You'll see that as the degrees of freedom go up, the values of the t distribution approach the Z values you refer to in your comments.
