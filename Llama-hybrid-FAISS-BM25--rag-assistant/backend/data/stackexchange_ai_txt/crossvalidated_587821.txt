[site]: crossvalidated
[post_id]: 587821
[parent_id]: 
[tags]: 
Mean of $t$ in the logistic regression model

The question comes from a sentence of page 208 of Christopher M. Bishop's "Pattern Recognition and Machine Learning". The sentence is excerpted as follows: My questions are mainly two: Why $\mathbb E[t]=\sigma({\bf x})$ ? As explained in section 1.5 on page 38, the training samples for classification are drawn from joint distribution $p({\bf x},t)$ . So I think the $t$ here is the $t$ in $p({\bf x},t)$ on page 38, the random variable representing target value. This $t$ conforms to Bernoulli distribution, so its expectation is known to be the probability of $t=1$ (Eq (2.3) on page 69), which I think should be unconditional probability $p(\mathcal C_1)$ . On the other hand, I am guessing $\sigma({\bf x})$ denotes "the activation function with input vector ${\bf x}$ " as mentioned under Eq (4.117) on page 212. That is, $p(\mathcal C_1|{\bf\phi})$ , according to Eq (4.87) on page 205, which is a conditional probability. In general, unconditional probability $p(\mathcal C_1)$ is not equal to conditional probability $p(\mathcal C_1|{\bf\phi})$ . So, why can we write $\mathbb E[t]=\sigma({\bf x})$ ? This is the first thing that confuses me. Still for equation $\mathbb E[t]=\sigma({\bf x})$ . $\mathbb E[t]$ , as an expectation, is a deterministic constant. The right side, $\sigma({\bf x})$ , however, is a function of random variable $\bf x$ in $p({\bf x},t)$ on page 38, so it should be a random variable too. So, how can we equate a random variable with a deterministic number? Thank you for your help with my questions.
