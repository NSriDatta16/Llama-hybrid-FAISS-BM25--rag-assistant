[site]: crossvalidated
[post_id]: 642699
[parent_id]: 
[tags]: 
How to come up with a probability score for each predicted value from a neural networks model?

I have some python code that creates and trains a neural networks model for predicting the column 'Cost'. It takes in a bunch of inputs and predicts the cost. Now, I'm trying to convert the predicted cost into a probability (more specifically, the probability of encountering this error (relative difference between expected and predicted cost) or larger). Here's what i did: # Y_Actual is the actual cost (it is an array) # predictions_array is an array of the predictions of cost that came from the neural networks model error_list = ((abs(Y_Actual - predictions_array)) / Y_Actual) * 100 # I used the trimmed mean and trimmed sd to control for possible outliers error_mean = trim_mean(error_list, 0.05) trimmed_data = stats.trimboth(error_list, 0.05) error_sd = np.std(trimmed_data) prob_score_all = [] for i in error_list: z_score = (i - error_mean) / error_sd desiredProb = 1 - stats.norm.cdf(z_score) prob_score_all.append(desiredProb) This generally works well. That being said, if for example the actual cost is $3 and the predicted cost is $15 , this isn't a very significant difference. But the probability that gets assigned to it is so small because the code determines that the predicted cost is 5 times away from the actual cost. So, it ends up getting assigned a much smaller probability. On the other hand, if for example i had an actual cost of $1,000,000 and predicted cost of $700,000 it has a much larger probability compared to the previous example. Is there any way i can address this issue. I know this seems like a programming question but it's actually a statistical question on how to convert predicted values from machine learning models into probabilities.
