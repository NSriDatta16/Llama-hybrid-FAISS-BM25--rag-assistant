[site]: crossvalidated
[post_id]: 64337
[parent_id]: 64335
[tags]: 
The first thing I would do is trying to visualize the datasets. Start to plot histograms of all the features. That will tell you much more than some sterile numbers, also about the similarity of the two datasets. Furthermore plot the correlations between two features, either 2D-histograms, profile plots or scatter plots. After that you will have quite a good feeling, much better than "0.794 similarity". EDIT: If you would like to automatize the procedure, here is an idea: It is more or less a classification problem. Can I classify if a sample is from dataset A or B given the features. The similarity is then the separation power of the classifier. If the classifier is able to separate the items from A from the items of B, then the two datasets are quite different. If it is not possible, the datasets are more or less the same. There are several metrics describing the separation power, a starting point is wikipedia http://en.wikipedia.org/wiki/Statistical_classification#Evaluation . These metrics normally depend on the prior ratio of A and B, therefore you need to correct for this if your datasets are different in size, see e.g. Uncertainty_coefficient . As a classifier you can use any algorithm out there, neural networks, svm, boosted decision trees, ... Just choose one or try several.
