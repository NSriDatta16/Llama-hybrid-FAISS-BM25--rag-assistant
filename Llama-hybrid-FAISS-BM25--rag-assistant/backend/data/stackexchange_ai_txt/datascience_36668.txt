[site]: datascience
[post_id]: 36668
[parent_id]: 36651
[tags]: 
In general I think you've understood both concepts. I'll try to address both of them in more detail. Input layer size In Neural Networks (NN), the size of the input layer is always equal to the number of variables (or features as we usually call them in Machine Learning) in your data. Batch size This refers to how many samples of data the network will see before updating its weights. Normally, when performing gradient descent (i.e. the algorithm that trains the NN), the network would be input all of the samples in order to calculate the loss and update the weights. However, especially in Deep Neural Networks (DNNs) this is infeasible, as the size of the dataset is too big and even if the network had enough memory the computation of the gradients would be inefficient. What we do instead is pass a few samples (called a batch ) at a time and train the model on them. Then another batch is passed, and so on. The number of samples we input to the model at each iteration is called the batch size . Relationship between the two In theory, if you have many features (in the thousands) you can't use a large enough batch size and the more features you have the less of a batch size you can use. However, in practice I have found the two to be practically unrelated ! In Deep Neural Networks, the batch size is primarily governed by the size of the model. An easy (but not always accurate) way of estimating this size is through the number of trainable parameters in a model. More parameters, mean more memory for the model (and longer gradient computations), leading to a smaller batch size. In DNNs, that have multiple layers, only a fraction of the parameters are those of the input layer. Thus, the number of features plays a minor part in the selection of the batch size. Example In your example you say you have 50 rows and 4 columns, out of which 3 are the input variables. The number of neurons in the input layer will be 3, to match the number of input variables (or features). This we cannot change, even if we wanted to! The batch size is something we can change. Let's say we use a batch size of 5. 1st iteration: In the first iteration, the NN will be given the first 5 rows of data. For each, the first three columns will be passed to the first layer of the network, which will calculate an output. After all 5 outputs are generated, they will be compared with the first 5 rows of the 4th column, to calculate a loss. Using this loss, the network will compute the gradients and perform the updates. Again, this loss corresponds to the first 5 samples , not just the 5th. 2nd iteration: The rows 6-10 will be passed to the network, which will do the same procedure as in the first step. 10th iteration: The rows 45-50 will be passed to the network. This marks the point where the NN has seen every sample of data once. In the context of Machine Learning, we call this an epoch . At this point, the data are shuffled and the 1st iteration of the 2nd epoch begins. Note: In most frameworks the samples in each batch are processed in parallel by the network and not sequentially. This makes no difference to the result, I just wanted to point this out.
