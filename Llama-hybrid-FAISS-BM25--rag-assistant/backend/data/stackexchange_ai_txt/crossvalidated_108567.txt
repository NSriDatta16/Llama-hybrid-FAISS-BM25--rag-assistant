[site]: crossvalidated
[post_id]: 108567
[parent_id]: 
[tags]: 
AIC, BIC and GCV: what is best for making decision in penalized regression methods?

My general understanding is AIC deals with the trade-off between the goodness of fit of the model and the complexity of the model. $AIC =2k -2ln(L)$ $k$ = number of parameters in the model $L$ = likelihood Bayesian information criterion BIC is closely related with AIC.The AIC penalizes the number of parameters less strongly than does the BIC. I can see these two are used everywhere historically. But generalized cross validation (GCV) is new to me. How GCV can relate to BIC or AIC? How these criteria, together or separate used in selection of penalty term in panelized regression like ridge ? Edit: Here is an example to think and discuss: require(lasso2) data(Prostate) require(rms) ridgefits = ols(lpsa~lcavol+lweight+age+lbph+svi+lcp+gleason+pgg45, method="qr", data=Prostate,se.fit = TRUE, x=TRUE, y=TRUE) p
