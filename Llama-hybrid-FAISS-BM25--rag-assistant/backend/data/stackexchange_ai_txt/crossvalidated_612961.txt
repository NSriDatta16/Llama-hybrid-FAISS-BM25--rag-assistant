[site]: crossvalidated
[post_id]: 612961
[parent_id]: 
[tags]: 
Why is the gradient not depending on the loss?

I was reading this paper , which uses a sampling attention ( $a$ is the net that gives the distribution of attention, $f$ takes the samples and classifies them), and derives the gradient as follows: Which means that if we consider $f$ , we have that the gradient wrt to itself is just the usual one, where instead if we consider $a$ we have: $$ \nabla_\theta\log a(x;\theta)f(x) $$ however, this does not makes total sense to me, as for the usual REINFORCE estimator, we should use the "score" to increase the probability of high scores, and decrease those with low scores... here instead they are using $f$ , which is just the classifier... what am i missing? In my opinion, the gradient should be: $$ \nabla_{\theta_a} L \approx [-L(y, f(x))]\nabla\log a(x;\theta_a) $$ thus "pushing up" the probability proportionally to the negative loss (so low loss pushes probs up, and high loss pushes probs down)
