[site]: crossvalidated
[post_id]: 410936
[parent_id]: 410596
[tags]: 
Based on the graph you posted, I would say you are falling into the "my fancy neural network is really just a random walk with drift" trap. If you look closely, you will notice that your forecasts are shifted by one step from the actuals: Your neural network just learned to copy the last value it saw and use it as the most likely next value $\pm$ a noise component (which is why it isn't an exact copy of the last value). I don't have an exact answer, but here are two considerations: You said you had better results with NNETAR with only one hidden layer? So why are you using 2 hidden layers then? That will only lead to overfitting. Unless you are modeling a really complex and/or multivariate time series, I do not recommend using multiple hidden layers for a forecasting problem. Try training on multiple steps ahead instead of one step ahead, in my experience that led to better results and generally avoided the "random walk trap" which is so common when dealing with neural networks for forecasting.
