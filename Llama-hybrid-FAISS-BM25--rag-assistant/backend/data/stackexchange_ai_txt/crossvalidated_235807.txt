[site]: crossvalidated
[post_id]: 235807
[parent_id]: 235600
[tags]: 
I had similar experiments comparing to Franck's answer. Please check this post. Do all machine learning algorithms separate data linearly? In the post we use tree, boosting and K nearest neighbor on spiral data. KNN is most intuitive one, it make the classification according to a given point's neighbors. So, spiral data would not "break the neighbor rule" For tree and boosting model, you can understand it as a "really complicated model that can achieve complied decisions". That is why you can see it can roughly learn the pattern, with some errors. Finally you may search for special clustering or kernel PCA in google to see how can we deal with "connected components".
