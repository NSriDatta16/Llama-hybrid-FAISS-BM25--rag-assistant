[site]: datascience
[post_id]: 122754
[parent_id]: 
[tags]: 
Learning curve - Why does the train learning curve is flat?

I implemented a model in which I use Random Forest as classifier and I wanted to plot the learning curves for both training and test sets to decide what to do next in order to improve my model. Dataset details: 107 radiomics feature extracted from 580 CT image. The training dataset has 406 records. The testing dataset has 174 records. The Code: X_train, X_test, y_train, y_test = train_test_split(df[df.columns.difference(['label'])], df['label'], test_size=0.3, random_state=42) over = SMOTE(sampling_strategy='auto') #OverSampling Minority class clf = RandomForestClassifier() steps = [('over', over), ('model', clf)] pipeline = Pipeline(steps=steps) plot_learning_curves(X_train, y_train, X_test, y_test, pipeline,scoring='precision') plt.show() My results are in the below image I wonder why does the training Curve is flat? (Also other training metrics Curve are flat) Is my model overfits?
