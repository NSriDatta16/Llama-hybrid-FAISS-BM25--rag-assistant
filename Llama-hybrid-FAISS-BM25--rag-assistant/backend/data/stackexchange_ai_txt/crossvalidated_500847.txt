[site]: crossvalidated
[post_id]: 500847
[parent_id]: 500505
[tags]: 
I got an answer from my supervisor, so I thought I would post it here since a few people upvoted. Firstly, always good to be remember that "layer" is a bit or an overload term. For example, there might be many low-level layers in each high-level layer of SRCNN. At a high level, it appears that SRCNN maps the raw pixel data to an input feature vector, then maps that input feature vector to an output feature vector, and then maps that output feature vector back to an image. You will see this pattern quite often in machine learning. That is: (1) encode unstructured high-dimensional data as a low-dimensional input feature vector, (2) map the input feature vector to an output feature vector, and then (3) decode/map the low-dimensional output feature vector to the final prediction (e.g. output image). In practice, this is because the non-linear mapping tools of deep learning work better with low-dimensional feature vectors than they do with high-dimensional inputs (such as raw pixel data), but there is also lots of theory to back up why this is a good thing to do. With regards to your follow-up question: it's a mix. Some of the ideas for the design of an architecture will come from theory, some from intuition built up from practical experience, and some from experimenting and trying different things.
