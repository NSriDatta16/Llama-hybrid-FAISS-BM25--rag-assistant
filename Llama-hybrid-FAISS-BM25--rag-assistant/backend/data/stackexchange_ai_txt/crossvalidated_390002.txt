[site]: crossvalidated
[post_id]: 390002
[parent_id]: 
[tags]: 
Are there any research papers documenting or formulating the behavior of training loss based on the complexity of the neural network?

When I made the neural network more deeper and trained it for the same number of epochs, the training loss decreased but started increasing after a certain threshold. Shouldn't the training loss keep on decreasing and overfit the data? Is the relation of training or validation loss with the complexity of the network documented, like a theorem or formula. edit- Trained for same epochs with the same training hyperparameters but the networks made deeper, the training loss decreases but begins to increase again after a threshold
