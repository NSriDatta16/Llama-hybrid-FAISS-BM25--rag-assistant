[site]: datascience
[post_id]: 85219
[parent_id]: 85176
[tags]: 
One thing you could check is wether using the vectorizer on the whole text could be an issue. The test set should be "new" unseen data and should not necessarily be vectorized together with the training data. You can "refit" a vectorizer on new text (the test set) using the "old" vocabulary (from train set). However, I'm not sure if this really is an issue in your case. Essentially you would need to use the "old" vocabulary (from the train set) to prepare your (unseen) test data. Minimal example with TfidfVectorizer() : from sklearn.linear_model import LogisticRegressionCV from sklearn.feature_extraction.text import TfidfVectorizer # Corpus (X train) and target (y train) from a pandas df corpus = df[['text']].values[:,0].astype('U').tolist() ytrain = pd.Series(df['yvar']) # Prepare tfidf vectorizer tf = TfidfVectorizer(analyzer='word', ngram_range=(1,2), lowercase = True, max_features = 20000) tf_transformer = tf.fit(corpus) xtrain = tf.fit_transform(corpus) # Save transformer pickle.dump(tf_transformer, open(mypath + "tfidf.pkl", "wb")) # Do classification clf = LogisticRegressionCV(n_jobs=2, penalty='l2', solver='liblinear', cv=10, scoring = 'accuracy', random_state=0) clf.fit(xtrain, ytrain) # Save classifier with open(mypath + 'clf.pkl', 'wb') as f: pickle.dump(clf, f) ##### New text (test data) # Load classifier with open(modelpath + "clf.pkl", 'rb') as f: clf = pickle.load(f) # Load transformer (I use the "old" vocabulary from tf1 here to generate tf1_new) tf1 = pickle.load(open(modelpath + "tfidf.pkl", 'rb')) tf1_new = TfidfVectorizer(analyzer='word', ngram_range=(1,2), lowercase = True, max_features = 20000, vocabulary = tf1.vocabulary_) # Predict classifier on tf1_new... xtest = tf1_new.fit_transform([mynewtext]) res = clf.predict_proba(xtest) Also find the code here: https://github.com/Bixi81/Python-ml
