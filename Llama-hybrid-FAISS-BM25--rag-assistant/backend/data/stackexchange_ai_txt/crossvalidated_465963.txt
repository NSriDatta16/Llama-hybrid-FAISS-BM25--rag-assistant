[site]: crossvalidated
[post_id]: 465963
[parent_id]: 
[tags]: 
Machine Learning: Why do I have this pattern of train and validation accuracy?

I am trying to understand what would generate this pattern of accuracy in train and validation dataset (second and third plot below). I am training a network to recognize 6 types of faces (they are stylized faces, basically a grey circle with black features inside). The key features are the eyes shape (circle, cross, square) and the mouth (triangle pointing up, and triangle pointing down) generating a total of 6 classes. Noise is applied to the features (on their position, length, etc.), and each face is presented on all translation across canvas. The faces are randomly generated for training and validation, so they may randomly repeat across the two datasets. As you can see, the validation seems to go pretty fine until some point, and then it just goes crazy. I am not sure how to interpret this pattern. Is it validation? Or there is something wrong conceptually on my dataset? The network is a VGG. I tried with VGG 11 and VGG 19, both with batch norm. EDIT: I have done some digging. I have tried to evaluate the validation accuracy with the same dataset as training, and I still got massive oscillation. I remember that validation is computed with the network in eval mode. In fact, setting the network in train mode, gives a non-oscillating validation. Thus the problem is batch norm. I have been asked to share some example of my dataset, which now seems to be really relevant. Notice how the are placed on different position of a white canvas. I have tried to reduce the contrast of the image: But it doesn't seem to help much. EDIT2: I am now using a gray background and changing the image to gray-scale (and changing the network to get as an input a 1-channel image). The results are better, but still bad. My next step is to try to lower the batchNorm momentum. Any suggestion is appreciated!
