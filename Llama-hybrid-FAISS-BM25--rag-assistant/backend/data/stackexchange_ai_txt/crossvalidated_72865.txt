[site]: crossvalidated
[post_id]: 72865
[parent_id]: 
[tags]: 
"Bayesglm", p-values and degrees of freedom?

I am trying to perform some logistic regressions (and I am a neophyte user of R). Initially I used "glm" to compute coefficients, AIC and p-values; this worked great until I ran across a data set suffering from complete separation . In [1], Gelman et alia suggest using an (informative) prior to address this problem; the corresponding algorithm is implemented in R as "bayesglm" (in the ARM package). Here is my problem. Previously, with "glm", I would compute p-values as follows: mylogit There are 53-48=5 degrees of freedom: Null deviance: 71.188 on 53 degrees of freedom Residual deviance: 37.862 on 48 degrees of freedom However, if I use "bayesglm" instead of "glm", the resulting degrees of freedom are a bit surprising to me: Null deviance: 22.279 on 53 degrees of freedom Residual deviance: 39.030 on 54 degrees of freedom If I plug in the preceding formula for a p-value, I have -1 degrees of freedom! Can someone help me get a more sensible answer (or help me interpret this)? By the way, the documentation on the "bayesglm" command includes the following ominous comment: We include all the glm() arguments but we havenâ€™t tested that all the options (e.g., offests, contrasts, deviance for the null model) all work. [1] Gelman, Andrew, et al. "A weakly informative default prior distribution for logistic and other regression models." The Annals of Applied Statistics (2008): 1360-1383.
