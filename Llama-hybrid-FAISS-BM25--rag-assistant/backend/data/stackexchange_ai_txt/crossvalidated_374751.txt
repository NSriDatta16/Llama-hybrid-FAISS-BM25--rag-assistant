[site]: crossvalidated
[post_id]: 374751
[parent_id]: 353137
[tags]: 
The inclination of some collaborators is to go with the complete case type analysis, where only subjects with full data are used, but this makes me slightly nervous, as I feel like those missing data patterns might have an impact. I would argue that your intuition is correct, missing data can have strong predictive power which should not be thrown away. The question is what to do with the missing data, and here are two options (out of many) Use a decision tree based algorithm which can deal with missing data. In particular it will treat missing categorical data as a category of its own. For example XGboost, Light GBM, Catboost or any other advanced tree algorithm For other algorithms that can't deal with NAN (e.g. logistic regression, neural networks etc): use some form of imputation on missing data: this will depend on the shape and specifics of the distribution of data. The mean is not always the best idea, and the mode, or a percentile is sometimes better If you are mostly interested in predictive power then I suggest using tree based algorithms which have become the norm in Kaggle competitions (with great success)
