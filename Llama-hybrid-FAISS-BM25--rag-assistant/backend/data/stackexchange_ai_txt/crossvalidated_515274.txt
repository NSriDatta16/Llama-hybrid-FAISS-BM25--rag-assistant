[site]: crossvalidated
[post_id]: 515274
[parent_id]: 
[tags]: 
Understanding step in proof of GAN algorithm convergence, involving convexity

I am reading the original paper on GANs, https://arxiv.org/abs/1406.2661 . The proof of proposition 2, on the convergence of the gradient descent algorithm reads Consider $V(G, D) = U(p_g, D)$ as a function of $p_g$ as done in the above criterion. Note that $U(p_g, D)$ is convex in $p_g$ ... here (I think) $V(G,D) = \mathbb{E}_{x \sim p_{\text{data}(x)}} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 âˆ’ D(G(z)))]$ is the value function of the GAN, and the 'above criterion' is that $p_g$ is updated so that the value function decreases (for the generator). Details are in the paper, it is not long. What does it mean for $U$ to be convex in $p_g$ ? $U$ is a function of a distribution, and I can't interpret what convexity means in this context, even making assumptions on what $p_g$ is (e.g Gaussian)
