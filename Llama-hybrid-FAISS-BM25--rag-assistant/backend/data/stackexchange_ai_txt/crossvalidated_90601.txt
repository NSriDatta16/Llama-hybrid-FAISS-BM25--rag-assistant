[site]: crossvalidated
[post_id]: 90601
[parent_id]: 
[tags]: 
Variational inference engines

After doing some research on the topic, I have noticed a surprising deficit of inference packages and libraries that rely on message-passing or optimization methods for Python and R. To the best of my knowledge, these methods are extremely useful. For example, for a Bayes Network (directed, acyclic) belief-propagation alone should be able to give exact answers. However, most inference software that is available online (e.g. STAN, BUGS, PyMC) rely on MCMC methods. In the Python case, to the best of my knowledge, neither PyMC, scikit-learn or statsmodels include variational inference algorithms such as belief propagation, message-passing methods or any of their variants. Why is that? Are these methods less used in practice because they are seen not as powerful or generic as their MCMC counterparts? or Is it simply a matter of lack of manpower and time?
