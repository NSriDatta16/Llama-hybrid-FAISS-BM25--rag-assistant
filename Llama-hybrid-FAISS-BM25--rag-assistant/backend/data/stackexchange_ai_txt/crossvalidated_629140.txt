[site]: crossvalidated
[post_id]: 629140
[parent_id]: 628939
[tags]: 
To give this problem some notational structure, suppose we stipulate that we have an observable sequence $y_1,y_2,y_3, \cdots$ consisting of function outputs $f(x_0) \in \{ 0,1 \}$ using repeated inputs of $x_0$ . We will use a Bernoulli model with $y_1,y_2,y_3, \cdots \sim \text{IID Bern}(\theta)$ with unknown probability $0 \leqslant \theta \leqslant 1$ . Let $\mathscr{D}$ denote the hypothesis that the function is deterministic --- i.e.: $$\mathscr{D} \quad \quad \iff \quad \quad y_1 = y_2 = y_3 = \cdots.$$ One possible approach here would be to use a Bayesian model with prior probability $\pi_0 = \mathbb{P}(\mathscr{D})$ and a beta prior $\theta | \bar{\mathscr{D}} \sim \text{Beta}(\alpha, \beta)$ . (We will also assume that if the function is deterministic then there is an equal chance that it is deterministic to a zero or one.) Letting $s_n \equiv \sum_{i=1}^n y_i$ we then have: $$\begin{align} p(y_1,...,y_n|\bar{\mathscr{D}}) &= \int \limits_0^1 p(y_1,...,y_n|\theta) \cdot p(\theta|\mathscr{D}) \ d\theta \\[6pt] &= \frac{1}{\text{B}(\alpha, \beta)} \int \limits_0^1 \theta^{\alpha+s_n-1}(1-\theta)^{\beta+n-s_n-1} \ d\theta \\[16pt] &= \frac{\text{B}(\alpha+s_n, \beta+n-s_n)}{\text{B}(\alpha, \beta)}, \\[22pt] p(y_1,...,y_n|\mathscr{D}) &= \frac{1}{2} \cdot \mathbb{I}(y_1 = \cdots = y_n). \\[6pt] \end{align}$$ where $\text{B}$ refers to the beta function . We then have the posterior probability: $$\begin{align} \mathbb{P}(\mathscr{D} | y_1,...,y_n) &= \frac{p(y_1,...,y_n|\mathscr{D}) \cdot \mathbb{P}(\mathscr{D})}{p(y_1,...,y_n|\mathscr{D}) \cdot \mathbb{P}(\mathscr{D}) + p(y_1,...,y_n|\bar{\mathscr{D}}) \cdot \mathbb{P}(\bar{\mathscr{D}})} \\[12pt] &= \frac{\text{B}(\alpha, \beta) \cdot \pi_0}{\text{B}(\alpha, \beta) \cdot \pi_0 + 2 \text{B}(\alpha+s_n, \beta+n-s_n) \cdot (1-\pi_0)} \cdot \mathbb{I}(y_1 = \cdots = y_n), \\[12pt] \end{align}$$ which can be written in log-space (for $y_1 = \cdots = y_n$ ) as: $$\begin{align} \log \mathbb{P}(\mathscr{D} | y_1,...,y_n) &= -\text{log1pexp} \bigg( \begin{matrix} \log \text{B}(\alpha+s_n, \beta+n-s_n) - \log \text{B}(\alpha, \beta) \\ + \log 2 + \log(1-\pi_0) - \log (\pi_0) \end{matrix} \bigg). \\[12pt] \end{align}$$ You can program the vectorised posterior probability function in R as follows: POSTERIOR
