[site]: crossvalidated
[post_id]: 623047
[parent_id]: 
[tags]: 
Combining two success runs in parallel

The goal is to calculate the reliability of a process. Here reliability is defined as follows: Definitions and tests I used Let $X$ be a random variable that is equal to $1$ when no defect is present on a fabricated piece and is equal to $0$ when a defect is present. Then, the reliability $R$ of the process is the probability that $X = 1$ : $R = \mathbb{P}(X = 1)$ . To compute $R$ , I use the Bayesian success run theorem, it says that the $(1-\alpha)$ -lower bound $r$ for $R$ after having test $N$ pieces in a row without having detected any defaults is given by: $$ r = \alpha^\frac{1}{n+1}. $$ The problem Two tests in parallel are carried out for the same process on different samples: test A and test B to obtain respectively the reliability $R_A$ and $R_B$ . Test A respectively test B consists in observing $N_A$ respectively $N_B$ pieces in a row and then applying the success run theorem: $$ R_A = \alpha^\frac{1}{N_A+1}, $$ and $$ R_B = \alpha^\frac{1}{N_B+1}. $$ The question Since these two tests are runned on different samples coming from the same process, can I combined the sample size to obtain the following results for the overall reliability $R$ of the process: $$ R = \alpha^\frac{1}{N_A + N_B+1}. $$ Does it make sense to do it?
