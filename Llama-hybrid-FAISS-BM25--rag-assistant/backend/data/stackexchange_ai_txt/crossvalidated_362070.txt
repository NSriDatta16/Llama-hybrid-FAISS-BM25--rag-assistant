[site]: crossvalidated
[post_id]: 362070
[parent_id]: 360874
[tags]: 
One approach could be segmenting each text into paragraphs (if you have some formatting clues like double end-of-line) or sentences. Then for each chunk (paragraph / sentence), you can compare if it is similar with your questions. For similarity, you need to vectorize both question and chunk and here word embeddings can help although you need to come up with vectors for these chunks / questions, so more like doc2vec approach or manually averaging word vectors. In the latter case, I would suggest weighing with tf-idf of words.
