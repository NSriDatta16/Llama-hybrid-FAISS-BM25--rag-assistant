[site]: crossvalidated
[post_id]: 510322
[parent_id]: 510149
[tags]: 
It seems you are comparing two models. The first one is an intercept-only model (rodent ~ 1), and it simply predicts the value of rodent by using the average. Then, your second model is adding a predictor, pershrub. Your sample size is 25. By fitting an intercept-only model, your degrees of freedom for Model 1 is 24 (you are only estimating an intercept). By adding a predictor, your degrees of freedom for Model 2 is 23 (you are estimating an intercept and a slope for the single predictor). The model fit improves (your residual deviance goes down from 34.617 to 25.538 when you added the predictor). The difference in model fit between two models is 9.2591. So, by adding the predictor, you lose one degree of freedom, but you improve the fit by 9.2591. The difference in deviance between two models follow a chi-square distribution with the degrees of freedom 1 (because you are only adding one more predictor) under the assumption that two models have equivalent fit. So, you can evaluate how likely to observe an improvement of 9.2591 in deviance under the assumption that the two models provide equivalent fit. pchisq(9.2591,1,lower.tail=FALSE) This returns a p-value, 0.002343, you can use to reject or retain the null (two models are equivalent, and adding the predictor pershrub doesn't improve the model, or doesn't contribute to the prediction). At some pre-specified significance level (e.g., .01), you can say that this is not true, and pershrub indeed contributes and significantly improves the model fit.
