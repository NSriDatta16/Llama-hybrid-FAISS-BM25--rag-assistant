[site]: crossvalidated
[post_id]: 631048
[parent_id]: 628521
[tags]: 
Sample size calculations for clinical trials, particularly superiority trials, can be complicated and is dependent on a number of characteristics and assumptions. In your scenario, you calculated the sample size for a two-arm trial comparing two medications with a binomial outcome using three distinct methods. Each strategy takes into account various aspects of trial design and statistical concerns. Here's a quick rundown of why these strategies could produce different results: TrialSize package for R : This approach computes the sample size for a non-inferiority/superiority study with a fixed design that does not take into account interim analysis. It takes into account alpha, beta, projected response rates, and superiority margin. This method is simple, but it does not account for the intricacies of group sequential designs or interim analyses, which can have a considerable impact on sample size. rpact package for R : This method employs a group sequential design with a 30% information rate interim analysis (a pre-planned point for interim analysis when a certain portion - in this case, 30% - of the total data required for the trial's final analysis has been gathered.). Interim analyses in group sequential designs enable for the trial to be stopped early for efficacy, futility, or harm, influencing the overall sample size. This approach is more sophisticated and practical for many clinical trials since it accounts for the possibility of early termination of the experiment, resulting in a higher sample size. gsDesign package for R : This method also employs a group sequential design, but the assumptions or spending functions for the interim analysis differ. The expenditure function controls how the alpha level is distributed between intermediate analyses, which influences the total sample size. Different assumptions about the expenditure function or intermediate analysis settings can result in various sample size computations. Which One is Correct? Depends on Trial Design and Assumptions : Each strategy is deemed "correct" based on its underlying assumptions and the particular trial design it is employed for. The optimal approach is contingent upon the specific configuration of your experiment and the objectives you seek to accomplish. Regulatory Requirements and Trial Objectives :**The sample size calculation for a real-world clinical trial must be aligned with the trial's objectives, the statistical power required, ethical issues, and regulatory guidelines. Consult with a Statistician: Given the discrepancies in the computations, consulting with a statistician or clinical trial design expert is strongly advised. They may assist you in determining the best approach for your individual trial by taking into account all important elements, such as the possibility of interim analysis and the ramifications of different sequential designs. Alternative Bayesian approach. As mentioned by Frank Harrell in the first comment on the question, note that the above three R packages use frequentist approaches to the problem. In the frequentist framework, there is a higher likelihood of observing extreme data when examining data more frequently. In the Bayesian framework, the likelihood of the truthfulness of an assertion is unaffected by the number of times it has been previously made. Bayesian analysis in sequential testing does not involve multiplicity corrections. These methods tend to employ the same formulas for all interim analyses as they do for the final analysis. Adopting a Bayesian approach in conjunction with group sequential designs can offer additional flexibility and insights. The R package gsbdesign is specifically tailored for implementing Bayesian group sequential designs. In this framework, Bayesian statistics are used to update the probability distributions of the treatment's effectiveness as data is collected throughout the trial. This approach allows for a more dynamic and continuous assessment of the data, incorporating prior knowledge and real-time data analysis, potentially leading to smaller sample sizes needed. Bayesian methods can be particularly advantageous in interim analyses, such as at the 30% information rate, where they provide a probabilistic interpretation of the results. This interpretation can be crucial for decision-making, especially when considering early stopping for efficacy, futility or harm. By integrating Bayesian methods, researchers can gain a more nuanced understanding of the treatment's effects at each stage of the trial, potentially leading to more informed and timely decisions about the trial's continuation or modification. Here is a fantastic introduction to Bayesian sequential analysis by Frank Harrell.
