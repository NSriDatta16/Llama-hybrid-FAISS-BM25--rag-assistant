[site]: crossvalidated
[post_id]: 555990
[parent_id]: 526500
[tags]: 
Let's interpret the question as asking "At any given time $t,$ what is the chance that $k=5$ or more out of $n=10$ servers are running Task B?" This interpretation is interesting due to the strange-looking behavior of the answer: there are times at which it's impossible (or highly improbable) to find many servers running Task B and other times at which it is much more likely to find many servers running Task B. The solution is straightforward to obtain, albeit potentially terrible to compute, because the general solution requires time proportional to the number of permutations of the tasks. (Any speedup would require exploiting the summation relationships among the times; namely $5+10=15$ and $5+10+15=30.$ ) In general, order the task times into an array $d=(d_1,d_2, \ldots, d_m)$ where $m$ is the number of tasks and "Task B" is indexed at position $1.$ First consider any specific server. The chance that Task B is running at time $t$ is the chance that this task began in the interval of times $(t-d_1, t].$ Suppose Task B was $k^\text{th}$ in the order, so that $k-1\ge 0$ tasks preceded it and ran to completion. Let those task indexes be the subset $S\subset \{2,3,\ldots, m\}$ and define $$d(S) = \sum_{i\in S} d_i$$ to represent the total time taken by those tasks. We have to count the number of permutations $\sigma$ of $\{1,2,\ldots, m\}$ for which $d(\{\sigma(1),\sigma(2),\ldots,\sigma(k-1)\}\}\in (t-d_1,t]$ and $\sigma(k) = 1.$ When the $d_i$ are arbitrary durations, potentially there are as many distinct values of these $d(S)$ as there are permutations of $\{2,3,\ldots, m\}$ and $m$ cases have to be considered (for $k=1,2,\ldots, m).$ Thus the computing time cannot, in general, be reduced below $m!.$ It remains only to find a reasonably clear, efficient, and correct implementation of this calculation. One way is to generate all $(m-1)!$ of the permutations of the remaining tasks $\{2,3,\ldots, m\}.$ For each such permutation $\sigma$ find the cumulative sums of the sequence $0, d_{\sigma(2)}, d_{\sigma(3)}, \ldots, d_{\sigma(m)}.$ The value of their empirical cumulative distribution function, $F,$ at time $t$ gives the chance that a randomly chosen ordered subset of the remaining tasks will be completed by time $t$ before "Task B" is run. Let's call this the "permutation ECDF." The relevant part of its graph for the data in the question looks like this: Thus (because time is continuous), the chance that Task B is running at time $t$ must be $F(t) - F(t-d_1).$ Here is an R implementation. Given an array of times times and the index of "Task B," it returns the permutation CDF (as a function): p.F 1)) d[c(1, index)] Assuming the tasks are independently ordered in each server, this chance defines a Bernoulli $(F(t)-F(t-d_1))$ distribution. Any questions about how many servers are running "Task B" at time $t$ can therefore be answered in terms of the Binomial $(n, F(t)-F(t-d_1))$ distribution. Here is a plot of those chances for the specifics of the question (on a log probability axis): It is the graph of this R function g determined by k (equal to 5 servers), d (equal to 10 minutes), and n.servers (equal to 10 servers): g For instance, the expression g(23) returns $0.01546197$ for the chance at least $5$ of the $10$ servers are running Task B when the time is $t=23$ minutes. I checked this by simulating the experiment 10,000 times, in each iteration noting at which times on a fine grid "Task B" was running on five or more of the servers. The next figure plots those results in blue over the preceding chart (shown now on a linear probability scale). The agreement is good: The structure of these plots is curious, but a little thought suggests the huge variations in probabilities are correct: after all, for half or more of the servers to be running a ten-minute task at a given intermediate time, there aren't many combinations of the remaining task times that would permit that: the occurrence of one or more of the longer tasks makes it almost impossible for this ten-minute task to be running then. And since the entire problem is the same when time is run backwards, these graphs must be symmetrical. To see what the situation might look like without such a nice discretization of task times (into multiples of five minutes in the present case), here are the results (theoretical and simulated) for five randomly generated times of lengths $d=(3.4, 0.7, 0.3, 4.2, 3.9, 1.2)$ (so that "Task B" lasts 3.4 minutes).
