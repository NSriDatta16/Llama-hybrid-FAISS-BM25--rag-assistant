[site]: datascience
[post_id]: 55464
[parent_id]: 
[tags]: 
"Understanding Machine Learning: From Theory to Algorithms" the universal approximation theorem

I'm readying on "Understanding Machine Learning: From Theory to Algorithms" the Universal approximation theorem: ..."Networks are universal approximators. That is, for every fixed precision parameter, $\epsilon >0 $ , and every Lipschitz function $f : [−1; 1]^{n} \rightarrow [−1; 1]$ , it is possible to construct a network such that for every input $\textbf{x} \in [−1; 1]^{n}$ , the network outputs a number between $f(x) − \epsilon$ and $f(x) + \epsilon$ ". It seems to me that the function $f : [−1; 1]^{n} \rightarrow [−1; 1]$ is Boolean. I think that the n-dimensional unit hypercube ${\displaystyle [-1,1]^{n}}$ can be replaced with a compact set of $ \mathbb{R} ^ {n} $ but the codomain makes me puzzled. I was expecting a function: $f : \mathbb { R } ^ { n } \rightarrow \mathbb { R }$
