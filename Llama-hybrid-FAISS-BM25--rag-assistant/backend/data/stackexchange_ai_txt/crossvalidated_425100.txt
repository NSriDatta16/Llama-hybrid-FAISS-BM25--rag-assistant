[site]: crossvalidated
[post_id]: 425100
[parent_id]: 425095
[tags]: 
The paragraph by @JohnRos seems to refer to a regression context. To simplify things, let's say that we have a single predictor $X$ in our regression model and that the model can be formulated like this: $Y = f(X) + \epsilon$ where $\epsilon$ is a normally distributed error term such that $E(\epsilon) = 0$ and $Var(\epsilon) = \lambda(X)^2$ , where both $f()$ and $\lambda()$ are unknown functions. If we are willing to assume that both $f()$ and $\lambda()$ have parameteric forms, then the model itelf can be referred to as parametric. For example, $f(X) = \beta_0 + \beta_1*X$ and $\lambda(X) = \sigma$ . But if we think either $f()$ or $\lambda$ to be unknown, smooth, possibly nonlinear functions of $X$ , whose underlying shapes will be determined from the data, then our model would include one nonparametric component and it would be incorrect to refer to it as a parametric model. I believe this simple example invalidates @whuber's first statement. A model such as the one above is determined by specificying the functional form of both $f()$ and $\lambda()$ . Only when both of these components are specified as parametric can we refer to the entire model as parametric.
