[site]: crossvalidated
[post_id]: 21156
[parent_id]: 
[tags]: 
Gesture recognition with HMM

I'm approaching at pattern recognition with HMM (with c++ or python). My data are x and y coordinate (normalized between -1,1) of the hand in a recorded video and I want to recognize. This is what I have understand to classify a hand that make a gesture (for example a circle): I need some train data (for example N different video with an hand that make a circle) of the same size (X coordinate (x,y) of the hand) I have to initialize one HMM (called HMM_circle) with BAUM-WELCH algorithms (or something interative EM-based algorithm) and find the parameters of HMM_circle. HMM_circle has X observed states and Y hidden states. Record some new observation (some new coordinate of a gesture to classify) new_OBS. Size of new_OBS must be X. Find the likelihood of new_OBS given the hidden markov model HMM_circle with BACKWARD-FOREWARD algorithm. This likelihood is a number between 0 and 1. If it is major than a threashold (for example 0.8) it is classified as a circle. Now, I have something not clear. How many hidden states in my HMM_circle (Y)? how long the train data (X)? How many train data (N)? Why? Sorry, I've just began to learn machine learning.
