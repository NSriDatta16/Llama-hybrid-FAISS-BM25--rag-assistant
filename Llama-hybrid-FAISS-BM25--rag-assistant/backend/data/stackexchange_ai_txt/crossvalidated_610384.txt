[site]: crossvalidated
[post_id]: 610384
[parent_id]: 610383
[tags]: 
I totally disagree with this. Many common estimators are biased. Ever calculated $S = \sqrt{\dfrac{\overset{n}{\underset{i=1}{\sum}}\left(X_i-\bar X\right)^2}{n-1}}$ as the standard deviation? That is a biased estimator for the standard deviation. Ever fit a logistic regression? You used a biased estimator of the true coefficients. Despite this, however, you probably felt comfortable interpreting those statistics (as is reasonable). Consider asking your colleague about these. (I concede that the Workplace Stack Exchange might advise otherwise.) If your colleague protests, "But they are consistent," so are ridge and LASSO. (Yes, that requires some assumptions, but OLS unbiasedness requires assumptions, too.) This is subtle, but I dispute the idea that you are interpreting the estimator. You interpret the model parameters, and you use estimators to guess what those unknown parameters are. The ridge and LASSO estimators are just estimating the $\beta$ parameter vector of $\mathbb E\left[Y\vert X\right] = X\beta$ , same as OLS. It might be that you are in a situation where ridge or LASSO has inferior properties compared to the OLS estimator (maybe a reviewer insists on an unbiased estimator), but all of these are just ways of guessing the true values of the parameters. If you have a reason to estimate a certain way (ridge, LASSO, OLS, something else), I say that you estimate that way and interpret using your guess of the parameter(s).
