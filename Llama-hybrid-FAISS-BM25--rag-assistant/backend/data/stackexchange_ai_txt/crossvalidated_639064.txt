[site]: crossvalidated
[post_id]: 639064
[parent_id]: 638358
[tags]: 
I have worked with a device (a pressure transducer) with a built-in feature to take multiple measurements very fast and then average them to reduce measurement errors exactly for the reasons you stated. One difference you need to pay attention to is that the measurements are taken much faster than the process physical time. In that case (where autocorrelation ~ 1) it's a great idea. You seem to imply , as it wasn't stated directly, that the measurements are equispaced and in a time scale relevant to your physical process. In this case you should consider what you're doing carefully as averaging effectively changes the time of the sample: $$ (y_{t-1} + y_{t-2})/2 \approx y_{t-1.5} $$ and for 3: $$ (y_{t-1} + y_{t-2}+ y_{t-3})/3 \approx y_{t-2} $$ so the longer the average the farther back in time your apparent measurement will be. Another way you should consider introducing past samples is with autoregression. Instead of the simple model you stated: $$ y_t=kx_t+b+e_t $$ you want to use a mean for $x_t$ : $$ y_t=k(x_t+x_{t-1})/2+b+e_t.$$ Well then the question is, why force the weight of $x_t$ and $x_{t-1}$ to be equal? Why not just use $$ y_t=k_1x_t+k_2x_{t-1}+b+e_t?$$ This naturally allows you to treat the effect of the time lag between samples. In case you just want to find the coefficients $k$ and $b$ then no averaging is needed as it's already accounted for in the OLS and your uncertainty in the coefficients.
