[site]: stackoverflow
[post_id]: 4737151
[parent_id]: 
[tags]: 
architecture for high availability

I have this scenario: You have a factory process line which runs 24/7. Downtime is extremely expensive. The software controlling all different parts must use a shared form of database storage The main reason for this is to know in which state the factory is in. For example some products can be mixed when using the same set of equipement and others DEFINITELY not. requirements: I want to the software be able to detect that an error in one part of the plant must result in some machine shutdown more then 1 km away. so stoing data in the plc's is not an option. Updates and upgrades to the factory environment are frequent load (in computer terms) will be really low. The systems handles a few hunderd assignments a day for which calculations / checks are done followed by instructions send for the factory machines. Systems will be bored most of the time. Most important requirement is the central computer system must be correct and always working. I was thinking to use a dynamo based database (riak or cassandra) where data gets written to multiple machines with each machine having the whole database When one system goes down it will go down unoticed. A Traditional sql databse might be more of a pain to upgrade when tables changes and this master slave is harder to configure. What would be your solution? Network has been made redundant and most other single points of failure to. The database system is critical because downtime of the db means downtime for the entire plant not just one of the machines which is acceptable. How to solve shared state problem. complexity in the database will not be a problem. I will be more like a simple key value store to get the most current and correct data.
