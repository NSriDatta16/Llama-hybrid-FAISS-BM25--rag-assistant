[site]: stackoverflow
[post_id]: 5279874
[parent_id]: 5269789
[tags]: 
Since by definition the perceptron is a binary classifier even in it's simplest incarnation you can think of it as having a bias/threshold of 0: y = f( w n * x n > 0 ? 1 : 0 ) But since 0 is a pretty arbitrary value the bias/threshold is explicitly introduced into the model as a variable: y = f( w n * x n > b ' ? 1 : 0 ) or y = f( w n * x n + b > 0 ? 1 : 0 ) The problem is that now the model another variables ( b [which is a scalar] apart from the original w n [which is a vector]) that needs to be taken into account when training. There are many ways to do that, the naive way being to just pick some of the possible values of b and for each train the model on w n and keep the ( b , w n ) pair that produced the best result. A more elegant way is to just think of the bias/threshold variable b as being a weight that is attached to an input that is always 1 which basically brings the model back to the original form with only 1 variable w except that now the vectors x and w have n + 1 elements: y = f( w n + 1 * x n + 1 > 0 ? 1 : 0 )
