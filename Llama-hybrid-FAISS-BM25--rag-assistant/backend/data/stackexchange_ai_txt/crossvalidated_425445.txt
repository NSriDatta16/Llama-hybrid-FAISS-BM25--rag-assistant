[site]: crossvalidated
[post_id]: 425445
[parent_id]: 394366
[tags]: 
Any $q > 1$ would define an estimator which performs group-wise selection and is the minimizer of a convex function. When $q=1$ , the estimator reduces to a (weighted) lasso which does not perform group-wise selection. When $q , the objective function is non-convex. In the original paper, Yuan, M., & Lin, Y. (2006). Model selection and estimation in regression with grouped variables. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 68(1), 49-67. the motivation is given (in figure 1) that the penalty looks like the lasso's penalty for coefficients in different groups while looking like the ridge regression's penalty for coefficients within the same group. This suggests that an explanation for why the group lasso uses $q=2$ reduces to an explanation for the utility of ridge regression over other $\ell_q$ penalized regression estimators. The standard intuition for this is that in ridge regression the coefficients are treated as being neutrally, in that they are neither being encouraged to be nearly sparse (as when $q ) or to be nearly equal to each other (as when $q > 2$ ). A more practical explanation for why $q=2$ could just be that the statistical community is comfortable with $\ell_2$ penalization and that the choice $q=2$ made possible deriving a LARS-type algorithm for fast computation. In the time when this paper was published, it was standard for new convex penalized regression estimators to be accompanied with a LARS-type algorithm. Fig. 1.:
