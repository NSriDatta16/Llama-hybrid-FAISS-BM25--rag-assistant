[site]: crossvalidated
[post_id]: 538746
[parent_id]: 
[tags]: 
Deep Learning: Should I dot product (input, weight) or dot(weight, input)? Does it even matters?

I've been following through Neural Networks from Scratch and found that the author switches the order of dot(input, weight) from time to time. The calculation shows that the dot product gives different answers, but does it matters when performing deep learning? input = generate_2d_random_numbers_to_list(3, 4) weight = generate_2d_random_numbers_to_list(4, 3) print(np.dot(input , weight )) print(np.dot(weight , input )) Outputs: [[-0.17752432 0.8954122 0.90645726] [ 0.63064018 0.67478076 -0.28574945] [ 0.31089983 1.3015615 -0.26077905]] [[-0.58014457 -0.86012428 -0.6136864 -0.66298195] [ 0.22580815 1.3400082 1.30939685 0.89712584] [ 0.80068436 0.46175544 0.06031708 0.43434225] [ 0.18267677 -0.04059971 -0.5704223 -0.5837033 ]]
