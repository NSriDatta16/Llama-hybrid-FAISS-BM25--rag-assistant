[site]: crossvalidated
[post_id]: 45923
[parent_id]: 
[tags]: 
What does #iter mean in libsvm when using RBF as a kernel?

I have a dataset with 60,000 training examples. I tried the following command under windows and with libsvm: svm-train.exe -t 2 -g 0.07 -c 1 images.train and it started giving multiple outputs for example: .....*..* optimization finished, #iter = 7090 nu = 0.117216 obj = -667.069565, rho = -0.055205 nSV = 4702, nBSV = 26 ....*..* optimization finished, #iter = 6485 nu = 0.100224 obj = -565.615150, rho = -0.198917 nSV = 4342, nBSV = 29 ..*.* optimization finished, #iter = 3671 nu = 0.027754 obj = -176.698407, rho = -0.838783 nSV = 2560, nBSV = 52 ....*..* optimization finished, #iter = 6192 nu = 0.104976 obj = -604.912230, rho = -0.284038 nSV = 4109, nBSV = 96 ......^C I stopped it because I didn't understand what was going on. I searched online in the libsvm website however I did not find any explanation on why I get multiple outputs and what these outputs mean exactly. I tried running the heart_scale and I only got one output: svm-train.exe -t 2 -g 0.07 -c 1 heart_scale * optimization finished, #iter = 134 nu = 0.433785 obj = -101.855060, rho = 0.426412 nSV = 130, nBSV = 107 Total nSV = 130 so does the amount of training samples have anything to do with this and if so what's the exact correlation? thanks Thank you in advance
