[site]: crossvalidated
[post_id]: 565595
[parent_id]: 
[tags]: 
Native method to calculate confidence upper bounds for the mean of a Poisson Distribution

Reading about how to calculate confidence intervals for Poisson distributions, one says that if the unknown mean is high you can use the Normal distribution approximation and use $\widehat\lambda\pm c\sqrt{\widehat\lambda/n}$ , where $\widehat\lambda$ is the mean of your sample of size $n$ and $c$ is to adjust your coverage. For example, for a 95% confidance interval, you use $c=1.96$ . If your unknown mean is not high enough, you then use $\chi^2$ tables. But, why can't one deduce a formula for confidence intervals without relaying on other distributions? Let's try. For simplification, I'm focusing on calculating the upper bound of the interval. For the normal approximation, it's $\boxed{f_\mathcal{N}(\widehat\lambda, n, c)=\widehat\lambda+c\sqrt{\widehat\lambda/n}}$ . Finding the exact upper bound Given $X_1, \ldots, X_n$ where each $X_i\sim\text{Pois}(\lambda)$ with $\lambda$ unknown, estimate an upper bound for $\lambda$ with confidence level $p$ . Let's call $$X=\sum_{i=1}^n X_i,\qquad \widehat\lambda=\frac{X}{n}$$ We know that $X\sim\text{Pois}(n\lambda)$ . Now we find the $c$ such that: $$ \Pr\left[X\leq n\lambda+c\sqrt{n\lambda}\right]=p $$ $\lambda$ and $n$ are unknown but using that expression the probability approaches $p$ depending only on $c$ . For example, for $c=2$ , the probability approaches $97.5\%$ as $n\lambda$ grows, and for $c=4$ , it goes to $\approx 1$ (the blue area isn't actually an area, just an effect of the distribution being discrete) Now, solving the second degree equation on $\sqrt{n\lambda}$ (taking the possitive side of $\pm$ , because its negative side yields a negative fraction): $$X\leq n\lambda+c\sqrt{n\lambda}\ \Longrightarrow\ \sqrt{n\lambda}\geq \frac{-c+\sqrt{c^2+4X}}{2} \Longrightarrow\ \lambda\geq\frac{(-c+\sqrt{c^2+4X})^2}{4n}$$ Taking the lower bound of the inequation and simplifying: $$ \boxed{f_\text{Pois}(\widehat\lambda, n, c)=\widehat\lambda+\frac{c}{2n}\left(c+\sqrt{c^2+n\widehat\lambda}\right)} $$ Comparing $f_\mathcal{N}$ and $f_\text{Pois}$ So, how good is the $f_\mathcal{N}$ approximation? Let's define: $$ g_n(\widehat\lambda, c) = \frac{f_\mathcal{N}(\widehat\lambda, n, c)}{f_\text{Pois}(\widehat\lambda, n, c)}=\frac{\widehat\lambda+ c\sqrt{\widehat\lambda/n}}{\widehat\lambda+\frac{c}{2n}\left(c+\sqrt{c^2+n\widehat\lambda}\right)} $$ which is the overestimation ratio of $f_\mathcal{N}$ over $f_\text{Pois}$ . It turns out that: $$ g_n(\widehat\lambda, c) = g_1(n\widehat\lambda, c)\ \Longrightarrow\ g_1(\widehat\lambda, c) = g_n(\widehat\lambda/n, c) $$ It implies that to analize the overestimation behaviour of $f_\mathcal{N}$ , you only need to analize it for samples of size 1 (or in other words, for single Poisson variables), and then scalate the results for bigger sample sizes. The function $g_1$ looks like that (for $c=1.96$ and $c=4$ respectively): For any $c$ , the function starts at $0$ and increases very fast until reaching the maximum value of $1.082954$ , and then decreases very slowly, having $1$ as horizontal asymptote. That means that for low values of $\widehat\lambda$ , $f_\mathcal{N}$ underestimates $f_\text{Pois}$ , a bit later they become equal, then it starts overestimating it until reaching that maximum value of $+8.295\%$ , and then they become more and more close to each other as $\widehat\lambda$ increases. The green vertical lines are the values of $\widehat\lambda$ for each $c$ where $g_1$ reaches that maximum value of $+8.295\%$ . A higher $n$ (a higher sample size) just speeds up that behaviour by a factor of $/n$ . For example, for $n=10$ , both curves look now like: So given that $f_\mathcal{N}$ always have a worst case of a $+8.295\%$ for some $\widehat\lambda$ , isn't it better to just use the exact $f_\text{Pois}$ , or was everything I did totally wrong? NOTE: Tables of $g_n(\widehat\lambda, c)$ values, for $c=1.96$ and $c=4$ . For each $c$ , I give two tables, the first one is the overestimation percentage for different $\widehat\lambda$ 's ( L ) and $n$ 's, and a second table indexed by $\%$ instead (to know the minimum $\widehat\lambda$ 's yielding overestimations below each percentage). In both tables, the first column is the sample size, and the other columns the calculated values. For $c = 1.96$ , | n\L | 1 | 2 | 5 | 10 | 25 | 50 | 100 | 250 | 500 | 1000 | |-----------------------------------------------------------------------------------------------------------| | 1 | -41.70% | -24.13% | -4.60% | 4.06% | 8.13% | 8.03% | 6.87% | 5.03% | 3.80% | 2.81% | | 2 | -24.13% | -8.60% | 4.06% | 7.71% | 8.03% | 6.87% | 5.47% | 3.80% | 2.81% | 2.05% | | 5 | -4.60% | 4.06% | 8.13% | 8.03% | 6.42% | 5.03% | 3.80% | 2.54% | 1.84% | 1.33% | | 10 | 4.06% | 7.71% | 8.03% | 6.87% | 5.03% | 3.80% | 2.81% | 1.84% | 1.33% | 0.95% | | 25 | 8.13% | 8.03% | 6.42% | 5.03% | 3.45% | 2.54% | 1.84% | 1.19% | 0.85% | 0.61% | | 50 | 8.03% | 6.87% | 5.03% | 3.80% | 2.54% | 1.84% | 1.33% | 0.85% | 0.61% | 0.43% | | 100 | 6.87% | 5.47% | 3.80% | 2.81% | 1.84% | 1.33% | 0.95% | 0.61% | 0.43% | 0.31% | | 1000 | 2.81% | 2.05% | 1.33% | 0.95% | 0.61% | 0.43% | 0.31% | 0.19% | 0.14% | 0.10% | | 10000 | 0.95% | 0.68% | 0.43% | 0.31% | 0.19% | 0.14% | 0.10% | 0.06% | 0.04% | 0.03% | | n\% | +0.00% | +8.30% | +5.00% | +3.00% | +1.00% | +0.50% | +0.10% | |-------------------------------------------------------------------------------------------| | 1 | 6.83 | 33.16 | 253.87 | 862.37 | 9016.61 | 37252.68 | 954626.98 | | 2 | 3.41 | 16.58 | 126.93 | 431.18 | 4508.31 | 18626.34 | 477313.49 | | 5 | 1.37 | 6.63 | 50.77 | 172.47 | 1803.32 | 7450.54 | 190925.40 | | 10 | 0.68 | 3.32 | 25.39 | 86.24 | 901.66 | 3725.27 | 95462.70 | | 25 | 0.27 | 1.33 | 10.15 | 34.49 | 360.66 | 1490.11 | 38185.08 | | 50 | 0.14 | 0.66 | 5.08 | 17.25 | 180.33 | 745.05 | 19092.54 | | 100 | 0.07 | 0.33 | 2.54 | 8.62 | 90.17 | 372.53 | 9546.27 | | 1000 | 0.01 | 0.03 | 0.25 | 0.86 | 9.02 | 37.25 | 954.63 | | 10000 | 0.00 | 0.00 | 0.03 | 0.09 | 0.90 | 3.73 | 95.46 | For $c=4$ , | n\L | 1 | 2 | 5 | 10 | 25 | 50 | 100 | 250 | 500 | 1000 | |-----------------------------------------------------------------------------------------------------------| | 1 | -71.01% | -58.58% | -37.09% | -19.68% | -1.76% | 5.44% | 8.07% | 7.79% | 6.51% | 5.11% | | 2 | -58.58% | -42.71% | -19.68% | -5.28% | 5.44% | 8.07% | 8.08% | 6.51% | 5.11% | 3.87% | | 5 | -37.09% | -19.68% | -1.76% | 5.44% | 8.28% | 7.79% | 6.51% | 4.68% | 3.51% | 2.59% | | 10 | -19.68% | -5.28% | 5.44% | 8.07% | 7.79% | 6.51% | 5.11% | 3.51% | 2.59% | 1.88% | | 25 | -1.76% | 5.44% | 8.28% | 7.79% | 6.05% | 4.68% | 3.51% | 2.34% | 1.69% | 1.22% | | 50 | 5.44% | 8.07% | 7.79% | 6.51% | 4.68% | 3.51% | 2.59% | 1.69% | 1.22% | 0.87% | | 100 | 8.07% | 8.08% | 6.51% | 5.11% | 3.51% | 2.59% | 1.88% | 1.22% | 0.87% | 0.62% | | 1000 | 5.11% | 3.87% | 2.59% | 1.88% | 1.22% | 0.87% | 0.62% | 0.40% | 0.28% | 0.20% | | 10000 | 1.88% | 1.35% | 0.87% | 0.62% | 0.40% | 0.28% | 0.20% | 0.13% | 0.09% | 0.06% | | n\% | +0.00% | +8.30% | +5.00% | +3.00% | +1.00% | +0.50% | +0.10% | |-------------------------------------------------------------------------------------------| | 1 | 28.44 | 138.09 | 1057.35 | 3591.70 | 37553.58 | 155154.84 |3975955.77 | | 2 | 14.22 | 69.05 | 528.67 | 1795.85 | 18776.79 | 77577.42 |1987977.89 | | 5 | 5.69 | 27.62 | 211.47 | 718.34 | 7510.72 | 31030.97 | 795191.15 | | 10 | 2.84 | 13.81 | 105.73 | 359.17 | 3755.36 | 15515.48 | 397595.58 | | 25 | 1.14 | 5.52 | 42.29 | 143.67 | 1502.14 | 6206.19 | 159038.23 | | 50 | 0.57 | 2.76 | 21.15 | 71.83 | 751.07 | 3103.10 | 79519.12 | | 100 | 0.28 | 1.38 | 10.57 | 35.92 | 375.54 | 1551.55 | 39759.56 | | 1000 | 0.03 | 0.14 | 1.06 | 3.59 | 37.55 | 155.15 | 3975.96 | | 10000 | 0.00 | 0.01 | 0.11 | 0.36 | 3.76 | 15.52 | 397.60 |
