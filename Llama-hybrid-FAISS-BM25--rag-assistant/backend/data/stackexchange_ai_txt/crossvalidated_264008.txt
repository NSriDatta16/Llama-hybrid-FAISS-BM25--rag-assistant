[site]: crossvalidated
[post_id]: 264008
[parent_id]: 263999
[tags]: 
No, you should not. Hyperparameters are variables which control some high-level aspect of an algorithm's behavior. As opposed to regular parameters, hyperparameters cannot be automatically learned from training data by the algorithm itself. For this reason, an experienced user will select an appropriate value based on his intuition, domain knowledge and the semantic meaning of the hyperparameter (if any). Alternatively, one might use a validation set to perform hyperparameter selection. Here, we try to find an optimal hyperparameter value for the entire population of data by testing different candidate values on a sample of the population (the validation set). Regarding the random state, it is used in many randomized algorithms in sklearn to determine the random seed passed to the pseudo-random number generator. Therefore, it does not govern any aspect of the algorithm's behavior. As a consequence, random state values which performed well in the validation set do not correspond to those which would perform well in a new, unseen test set. Indeed, depending on the algorithm, you might see completely different results by just changing the ordering of training samples. I suggest you select a random state value at random and use it for all your experiments. Alternatively you could take the average accuracy of your models over a random set of random states. In any case, do not try to optimize random states, this will most certainly produce optimistically biased performance measures.
