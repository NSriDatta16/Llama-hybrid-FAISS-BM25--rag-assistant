[site]: datascience
[post_id]: 32457
[parent_id]: 
[tags]: 
GridSearchCV results are different to directly applied default model (SVM)

I run a Support Vector Machines model on part of my train set with following result: alg = sk.svm.SVC(probability=True, gamma='auto') cv_results = model_selection.cross_validate(alg, X_pca, labels, cv =4) but when I am trying to tune the parameters, with following method: model=sk.svm.SVC() params = {'C' : [0.01, 0.1, 1, 10], 'gamma' : [0.1, 1, 'auto'], 'probability' : [True] } clf = GridSearchCV(model, params, cv=2, return_train_score=False).fit(X_pca, labels) pd.DataFrame(clf.cv_results_).loc[:, ['mean_test_score', 'rank_test_score', 'params']].sort_values(by='rank_test_score') So not only all results looks scetchy because they are the same. but also in one of the rows I have C:1, gamma:auto and probability: True which is the same parameters as in first table. I want to also say, that the same logic I am using for the rest of my 15 ML algorithms and only SVM showed this kind of weird behavior. Wondering that maybe I have some stupid mistake in how I create X_pca and labels data table, I copied code from other algorithm and just replaced second code but it gave the same results. Can you spot something wrong?
