[site]: crossvalidated
[post_id]: 302632
[parent_id]: 
[tags]: 
Is it logical to test with large test data and small train data in machine learning?

I have a data frame of [1722153 X 51] out of which my data is distributed as below value indicates classes and count indicates the number of samples for each class aggregate(data.frame(count = no_dup$id), list(value = no_dup$id), length) value count 1 0 1709912 (control) 2 1 5064 (cases) 3 2 1037 (cases) 4 3 5644 (cases) 5 4 496 (cases) I am taking a subset of the class label 0 for training the machine learning model to avoid the data imbalance issue. Below the total size, I am considering to train the machine learning model. aggregate(data.frame(count = New_data$OVERBILL), list(value = New_data$OVERBILL), length) value count 1 0 4913 (control) 2 1 5064 (cases) 3 2 1037 (cases) 4 3 5644 (cases) 5 4 496 (cases) But Can I use the remaining samples of the class 0 to test the model? Will my model face any issue wrt to classification? Is there any possible approach that can be implemented so that I can test the remaining records?
