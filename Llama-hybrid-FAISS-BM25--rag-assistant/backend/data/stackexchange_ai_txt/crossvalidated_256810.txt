[site]: crossvalidated
[post_id]: 256810
[parent_id]: 
[tags]: 
How can I solve the sequence prediction problem?

Let's say I'm given a stream of characters, one at a time. Some example strings of characters that could occur might be "01234" or "hello how are". They might even be encodings of waveforms as integers from 0-255 encoded into ascii. My goal is to train a model to predict the next character in the sequence (or more than one character if possible). Each character generated is drawn from a distribution that may be dependent on any number of previous things I have seen, but not necessarily adversarialy. How well can I do/how can I do this? I don't think there is one best approach and am generally just looking for methods I can try so multiple different answers are fine.The three methods I am aware of are recurrent neural nets, (potentially hidden) markov chains, and prediction of the next item using a traditional classifier on a fixed window. These have their own benefits and drawbacks (which might be nice to discuss here), but what else is there?
