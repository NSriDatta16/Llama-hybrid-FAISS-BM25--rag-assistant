[site]: crossvalidated
[post_id]: 134616
[parent_id]: 
[tags]: 
What does the input matrix for deep learning architechture look like

I am somewhat new to deep learning and trying to understand the different architectures. There are a couple things that confuse me greatly with regards to setting up the input: i) I believe the input data is usually vectorized or flattened; how then is the local 2D structure (in the case of an image) or 3D structure (for video data) accounted for. ii) how does one arrange the input matrix -- there are patches within a single image that are used as well as the entire training set. For instance, say we use a 100 images from the MNIST dataset as a training set. There are 10 classes and let us say 10 images for each class. Each image has a 28 x 28 pixel dimension. Is the input data set then organized as: -- vectorize the image -- 28 x 28 = 784 ---So for 100 images will we have a 784 x 100 matrix? ---What about if we train on several 10 x 10 patches randomly sampled from each image? I understand there are different architectures. Explaining the input for any one of them will help me greatly. I am reading this paper for instance: http://ai.stanford.edu/~wzou/cvpr_LeZouYeungNg11.pdf I don't understand the inputs and therefore the convolution fully.
