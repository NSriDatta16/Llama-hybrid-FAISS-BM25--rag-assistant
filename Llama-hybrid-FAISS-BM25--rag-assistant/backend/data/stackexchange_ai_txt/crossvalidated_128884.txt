[site]: crossvalidated
[post_id]: 128884
[parent_id]: 128843
[tags]: 
That is one heck of a contorted sentence! The problem is that it tries to present a half dozen ideas all at once. Let's unpack it into comprehensible pieces, devoting one (much shorter) sentence to each idea. For context, let's begin with this paragraph, which sets everything up. PCA is mathematically defined as an orthogonal linear transformation that transforms the data ... Consider a data matrix, X, with column-wise zero empirical mean (the sample mean of each column has been shifted to zero), where each of the n rows represents a different repetition of the experiment, and each of the p columns gives a particular kind of datum (say, the results from a particular sensor). Translation into English: When each repetition of an experiment yields the same number of distinct values $p$ (such as the results from various sensors), the data can be arranged into a matrix $X$ . Its $n$ rows record the experimental results (in any order). Its $p$ columns correspond to the different values, or variables. Often, before applying PCA, $X$ is modified by "centering" the variables: the mean of each column is subtracted from each value in that column. Now for the problematic sentence: Mathematically, the transformation is defined by a set of p-dimensional vectors of weights or loadings $\mathbf{w}_{(k)} = (w_1, \dots, w_p)_{(k)}$ that map each row vector $\mathbf{x}_{(i)}$ of X to a new vector of principal component scores $\mathbf{t}_{(i)} = (t_1, \dots, t_p)_{(i)}$ , given by $${t_{k}}_{(i)} = \mathbf{x}_{(i)} \cdot \mathbf{w}_{(k)}$$ in such a way that the individual variables of t considered over the data set successively inherit the maximum possible variance from x, with each loading vector w constrained to be a unit vector. Translation into English: PCA converts $X$ into a matrix $T$ of the same dimensions. It replaces each row of experimental results $\mathbf{x}_{(i)} = (x_1, \ldots, x_p)_{(i)}$ by a row of "principal component scores," which are the values of new variables $\mathbf{t}_{(i)} = (t_1, \dots, t_p)_{(i)}$ . Each score is a linear combination of the entries in its row, written as the dot product with a "loading vector" $\mathbf{w}_{(k)} = (w_1, \dots, w_p)_{(k)}$ , $${t_{k}}_{(i)} = \mathbf{x}_{(i)} \cdot \mathbf{w}_{(k)}.$$ $\mathbf{w}_{(1)}$ is chosen to be any unit vector that maximizes the variance of the column of scores $t_{1(i)}$ it produces. (The choice is not unique). $X$ is then modified by subtracting the score-scaled loading vectors $t_{1(i)}\mathbf{w}_{(1)}$ from the rows. This process is repeated until all $p$ of the loading vectors and the $p$ associated scores have been found.
