[site]: crossvalidated
[post_id]: 628026
[parent_id]: 
[tags]: 
Alternatives to spatial and temporal aggregation of time series to discover more learnable patterns

Given taxi demand time series of towns in a country. I would like to do demand forecasting. I noticed that when the town's time series is zero inflated the prediction is poor. However, when these sparse time series are spatially and temporally aggregated into fewer time series, trend and seasonal patterns start to emerge in the fewer time series. I would like to come up with a Dataset Quality Maintenance System (DQMS). I want to improve the quality of the training dataset fed to the demand forecasting model. We notice that the raw input data is sparse and does not have clear trend and seasonal patterns. This makes it difficult for the model to learn. Therefore, we do spatial and temporal aggregation to improve the data quality. This new data has more patterns that can be learnt, and the prediction accuracy is better. However, the downside of this method is the spatial and temporal aggregation is done arbitrarily (based on heuristics). E.g. nearby stations are aggregated and minutes are aggregated to hours etc. I would like to propose a more systematic way to aggregate sparse demand time series dynamically using static and dynamic covariate information. The spatial aggregation may NOT be based on proximity alone. Temporal aggregation may NOT be the same resolution/period (e.g. 1 hour) for all the time series. The ultimate goal is to perform some data wrangling/transformation on the raw data so that it leads to discovery of more (most) statistical patterns (trend, seasonality etc. ). This will lead to the model learning these patterns so eventually translating this into better prediction results. I know machine learning models learn latent patterns (human incomprehensible) etc.. but my idea is to discover all human discernable/interpretable patterns and feed it to the model so that we are confident that we provided some learnable patterns to the data. I want to avoid feeding random data and getting good prediction results which are not properly explainable. This Dataset Quality Maintenance System (DQMS) runs in real-time and triggers model retraining when a new data wrangling/transformation leads to better pattern detection.
