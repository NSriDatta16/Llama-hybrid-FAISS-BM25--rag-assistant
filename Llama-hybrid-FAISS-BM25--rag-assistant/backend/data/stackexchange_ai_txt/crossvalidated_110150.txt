[site]: crossvalidated
[post_id]: 110150
[parent_id]: 110145
[tags]: 
Yes, you can use random forests to get predictions, but it's not something that you can easily do "by hand" as for a classification tree. Random forests generate a large number of classification trees, and then does a majority vote to generate prediction so you don't get a single "set of rules" like in a classification tree. For instance: library(randomForest) # Set RNG seed, for reproducibility set.seed(12345) # We'll use the iris data # Let's split it into 30% test set and 70% training set training.set Which gives: OOB estimate of error rate: 3.81% Confusion matrix: setosa versicolor virginica class.error setosa 37 0 0 0.00000000 versicolor 0 32 3 0.08571429 virginica 0 1 32 0.03030303 Now, to test it on the test set res If you want to look at single trees used by your random forest you can use the getTree function. You may also want to have a look at: How to actually plot a sample tree from randomForest::getTree()?
