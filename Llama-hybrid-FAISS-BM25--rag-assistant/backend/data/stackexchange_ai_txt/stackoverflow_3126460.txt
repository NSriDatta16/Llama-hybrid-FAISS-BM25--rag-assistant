[site]: stackoverflow
[post_id]: 3126460
[parent_id]: 3098907
[tags]: 
Let me check my assumptions, if for no other reason than to guide my thinking about the problem: The matrix is highly redundant, not necessarily sparse. We want to minimize storage (on disk and RAM). We want to be able to multiply A[m*n] by vector B[n*1] to get to AB[m*1] without first decompressing either (at least not more than required to do the calculations). We don’t need random access to any A[i*j] entry --all operations are over the matrix. The multiplication is done online (as needed), and so must be as efficient as possible. The matrix is static. One can try all kinds of clever schemes to detect rectangles or self similarity etc, but that is going to end up hurting performance when doing the multiplication. I propose 2 relatively simple solutions. I am going to have to work backwards a bit, so please be patient with me. If the data is predominantly biased towards horizontal repetition then the following may work well. Think of the matrix flattened into an array (this is really the way it is stored in memory anyway). E.g. A | w0 w1 w2 | | x0 x1 x2 | | y0 y1 y2 | | z0 z1 z2 | becomes A’ | w0 w1 w2 x0 x1 x2 y0 y1 y2 z0 z1 z2 | We can use the fact that any index [i,j] = i * j. So, when we do the multiplication we iterate over the “matrix” array A’ with k = [0..m*n-1] and index into the vector B using (k mod n) and into vector AB with (k div n). “div” being integer division. So, for example, A[10] = z1 . 10 mod 3 = 1 and 10 div 3 = 3 A[3,1] = z1. Now, on to the compression. We do normal run of the mill Run Length Encoding (RLE), but against the A’, not A. With the flat array there will be longer sequences of repetition, hence better compression. Then after encoding the runs we do another process where we extract common substrings. We can either do a form of dictionary compression, or process the run data into some form of space optimized graph like a radix tree/suffix tree or a device of your own creation that merges tops and tails. The graph should have a representation of all the unique strings in the data. You can pick any number of methods to break the stream into strings: matching prefixes, length, or something else (whatever suits your graph best) but do it on a run boundary, not bytes or your decoding will be made more complicated. The graph becomes a state machine when we decompress the stream. I’m going to use a bit stream and Patricia trie as an example, because it is simplest, but you can use something else (more bits per state change better merging, etc. Look for papers by Stefan Nilsson ). To compress the run data we build a hash table against the graph. The table maps a string to a bit sequence. You can do this by walking the graph and encoding each left branch as 0 and right branch as 1 (arbitrary choice). Process the run data and build up a bit string until you get a match in the hash table, output the bits and clear the string (the bits will not be on a byte boundary, so you may have to buffer until you get a sequence long enough to write out). Rinse and repeat until you have processed the complete run data stream. You store the graph and the bit stream. The bit stream encodes strings, not bytes. If you reverse the process, using the bit stream to walk the graph until you reach a leaf/terminal node you get back the original run data, which you can decode on the fly to produce the stream of integers that you multiply against the vector B to get AB. Each time you run out of runs you read the next bit and lookup its corresponding string. We don’t care that we don’t have random access into A, because we only need it in B (B which can be range / interval compressed but doesn’t need to be). So even though RLE is biased towards horizontal runs we still get good vertical compression because common strings are stored only once. I will explain the other method in a separate answer as this is getting too long as it is, but that method can actually speed up calculation due to the fact that repeat rows in matrix A multiplies to the same result in AB.
