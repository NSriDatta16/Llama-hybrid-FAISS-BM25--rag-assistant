[site]: crossvalidated
[post_id]: 318308
[parent_id]: 317969
[tags]: 
Probably the most common method is k-fold cross validation . Lately I've been combining k-fold cross-validation with bagging . The algorithm is as follows: Assign folds $1:K$ to your data. For each $k$ in $K$: Select hyperparameters (weight decay, dropout, number of layers/nodes, etc.) to minimize prediction error on $k$th fold, using data not in $k$th fold. Step 2 provides $K$ networks. When predicting, average the predictions of all $K$ models. Averaging reduces the variance of the prediction. Another motivation for this sort of averaging is that you avoid "throwing away" all of the work you did in each fold. This can be computationally-intensive however when working with large datasets. With N = 200 however, do you really think that a neural net is the best tool for your problem?
