[site]: datascience
[post_id]: 89391
[parent_id]: 
[tags]: 
Regression and Classification in one Neural network

For example consider object localization problem. Here NN will have 5 ouputs. output[0] will tell probability of object present in image, other 4 will tell bounding box coordinates. As we see that output[0] has to use classification loss like cross entropy and output[1] to output[4] will have to use regression loss like Mean-squared-error. So Total loss is something like this: loss=Cross_entropy(output[0],Y[0])+MSE(output[1:5],Y[1:5]) #Y is true value Are loss like that backprogationable in vectorised form? Can I implement that kind of loss in tensorflow? If yes, how does tensorflow do that? Does it perform differentiation on each element of vector or matrix instead of whole thing at once?
