[site]: datascience
[post_id]: 126574
[parent_id]: 
[tags]: 
Dataset with replicates: aggregation or not?

I am currently developing a neural network tailored to a regression problem using a synthetic dataset derived from an experimental simulation campaign. Given the stochastic nature of both the simulated system and the model, the simulation was intentionally replicated multiple times to systematically observe the variability arising from the inherent stochasticity of the system. As a result, despite having identical inputs (features for my neural network), the corresponding outputs values (target for my neural network) vary across replicates. Given this, I am concerned with the most effective approach to dealing with this variability. Specifically, I am considering whether to use aggregation techniques, such as calculating the average of the target values, or to use the raw data. In the former scenario, for a given set of input features, the data set would reflect the average target value across all samples with those input features. On the other hand, in the latter scenario, the data set would include multiple samples, each associated with different target values for a given set of input features.
