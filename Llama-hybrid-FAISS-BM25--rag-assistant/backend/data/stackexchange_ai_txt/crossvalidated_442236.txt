[site]: crossvalidated
[post_id]: 442236
[parent_id]: 415914
[tags]: 
Since my similar question was flagged as duplicate (good debate in the comments!), I came across Simon Kuttruf's explanation on Medium : for integer orders of differencing only a (small) finite set of past values is reflected in the resulting differenced series: the preceding value in first order differencing, two preceding values for second order differencing etc. While for fractional orders of differencing, all coefficients take on (asymptotically small) non-zero values and so past values get mixed into the differenced series, up to some chosen cutoff. This phenomenon is here referred to as ‘long memory’ (or ‘wipe-out of memory’ resp). If the fraction $d = .5$ , then the first four coefficients (check my calculations) according to the recursive formula (see Simon's article ) $$ w_k = -w_{k - 1} \left( \frac{d - k + 1}{k} \right), $$ the first four values would be 1, -.5, -1/8, and -1/16, leading to the transformation $$z_t = y_t - \frac{1}{2} y_{t - 1} - \frac{1}{8} y_{t - 2} - \frac{1}{16} y_{t - 3} + \ldots$$ According to the terminology, the "memory is preserved" because the coefficients are positive for infinitely many past values of $y_{t-k}$ . The one example I can think of where memory is clearly lost by a first difference but without any apparent consequences is a true random walk. Where $\epsilon_i$ are i.i.d. $N(0, 1)$ random variables, let $$ \begin{align} y_1 &= \epsilon_1, \\ y_2 &= \epsilon_1 +\epsilon_2, \\ y_3 &= \epsilon_1 + \epsilon_2 + \epsilon_3, \\ y_4 &= \epsilon_1 +\epsilon_2 + \epsilon_3 +\epsilon_4. \end{align} $$ Then the first difference $y_4 - y_3 = \epsilon_4$ losses all of $y_4$ 's information about $\epsilon_1, \ldots, \epsilon_3$ , whereas the fractional differencing transformation would contain a bit of all of the epsilons. Not that they'd help you to forecast. Another maybe more profound example where "memory" matters is a conintegrated time series regression problem described in page 11 of these notes by Eric Sims . There, taking first differences of two cointegrated random walks results in bias in the estimation stage, because the error in the difference vs difference regression includes a correction term to bring things in line with the long run relationship. If you rid yourself of that long term cointegrating relationship by differencing, you'll suffer bias.
