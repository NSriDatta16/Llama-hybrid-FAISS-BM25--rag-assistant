[site]: crossvalidated
[post_id]: 221576
[parent_id]: 
[tags]: 
A few clarifications regarding convolutional neural networks

When reading about the transforming the fully connected layer into convolutional layer, posted in http://cs231n.github.io/convolutional-networks/#convert . I just feel confused about the following two comments: It turns out that this conversion allows us to "slide" the original ConvNet very efficiently across many spatial positions in a larger image, in a single forward pass. A standard ConvNet should be able to work on any size image. The convolutional filter can slide across the image grid, so why do we need to slide the original ConvNet in any spatial positions in a larger image? And Evaluating the original ConvNet (with FC layers) independently across 224x224 crops of the 384x384 image in strides of 32 pixels gives an identical result to forwarding the converted ConvNet one time. What does "strides of 32 pixels" mean here? Does that refer to the filter size? When talking about 224*224 crops of the 384*384 image, does that mean we use a receptive field of 224*224? I marked these two comments as red in the original context.
