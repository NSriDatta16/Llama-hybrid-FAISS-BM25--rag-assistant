[site]: crossvalidated
[post_id]: 514081
[parent_id]: 514080
[tags]: 
I've never heard of a Box-Tildwell test. There easier ways in my opinion to assess model fit. Here is one way... One approach you could use is a deviance goodness of fit test. Roughly, this is an omnibus test for goodness of fit so you actually want to fail to reject the null. Let me set up some fake data here library(tidyverse) set.seed(0) N = 120 x = sample(1:5, size = N, replace = T) eta = x - 0.8 p = plogis(eta) y = rbinom(N, 1, p) d = tibble(letters_provided=x, recalled=y) There is a strong relationship between the letters provided and the probability of recall in this example. Note that the true effect really is linear. To do the deviance goodness of fit test, first fit a logistic regression in which we group the data by the letters provided (very natural since you only provide a finite number of letters) grouped_d = group_by(d, letters_provided) %>% summarise(n = n(), y = sum(recalled)) model = glm(cbind(y, n-y) ~ letters_provided, data = grouped_d, family = binomial()) and then analyze the residual deviance statistic deviance_gof = function(model){ # Deviance has asymptotic chi square distribution dev = model $deviance dof = model$ df.residual # Manual calculation of the p value for the test p.value = pchisq(dev, dof, lower.tail=F) p.value } deviance_gof(model) [1] 0.6443274 Failure to reject the test roughly means that the model is a good fit. So, if you fail to reject this test, you can conclude that the assumption of linearity is good (or maybe more carefully, that you can not conclude that linearity is not a good assumption from the data. It may be there are non-linear effects which require more data to estimate precisely). If you crank up the sample size in this example, the deviance usually tends to the degrees of freedom which is the median for the chisquare. Hence the p value will hover around if the model you've chosen is the right model. However, more data can come back to bite since even modest non-linearity can be precisely estimated and ruin the test. If you had lots of data an on the logit scale the data had functional form $\log(x/10) + 1.5$ then you would reject the null of the deviance goodness of fit test even though linearity is a fine assumption to make. Its funny you mention splines and their inappropriateness. If you have no reason to suspect a non-linear relationship, that means either the effect is 0 or it is linear. If you're willing to assume it is linear, why would you want to test for a linear effect? In my opinion, splines would be a good approach because in the worst case scenario you spend a few degrees of freedom to estimate a linear effect. That isn't so big a deal as the other option; the effect is truly non-linear and you introduce a ton of bias by not modelling it as non-linear. Additionally, you could perform a chunk test to determine if the non-linear terms reduce additional variation in the data. THAT would be a hell of a way to address the assumption of linearity. Here is how to do a chunk test in R with rms model2 = lrm(recalled ~ rcs(letters_provided,3), data = d) anova(model2) Wald Statistics Response: recalled Factor Chi-Square d.f. P letters_provided 7.82 2 0.0201 Nonlinear 4.13 1 0.0422 TOTAL 7.82 2 0.0201 You can see that the nonlinear test has a significant p value (although not too significant, so the result is suspect IMO and is likely due to the small sample size of 120) meaning that the non-linearities seem to result in a better fit. TL;DR Do a deviance goodness of fit test or do splines and do a chunk test for the non-linear terms.
