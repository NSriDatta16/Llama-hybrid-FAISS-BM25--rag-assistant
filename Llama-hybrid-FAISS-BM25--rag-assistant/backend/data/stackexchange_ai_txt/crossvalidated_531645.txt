[site]: crossvalidated
[post_id]: 531645
[parent_id]: 
[tags]: 
What's the meaning of using Bootstrap? Why should resampling from sample set have any difference?

I just learned Bootstrap Method from my Statistics course. The teacher says that the whole population is unknown, however we have some sample set $\mathcal{D}$ with sample size $N$ . Then we use this sample set $\mathcal{D}$ as population and sample from $\mathcal{D}$ with replacement to compute all statistics we want (like mean, variance, median, or train a ML model from resampled set, etc.). We will have a fantatic result from this method (average result from all resampled sets). However, I totally cannot understand the spirit of resampling from $\mathcal{D}$ . For example, the actual distribution is Bernoulli distribution with $p = 0.5$ . I get a sample set $\mathcal{D}$ with sample size $100$ from this distribution with $52$ of one and $48$ of zero. If I resample with replacement from $\mathcal{D}$ , it just means that I have a Bernoulli distribution with $p = 0.52$ . My Questions: Why shouldn't I directly compute all statistics I want from $\mathcal{D}$ ? No matter how many times of resampling, I can only get converged $\text{mean} = 0.52$ and $\text{var} = 0.52 * 0.48$ . I don't think I can get any improvement from resampling or I can even recover the underlying distribution. Am I right? What's the loophole of my arguments? What's the advantage of Bootstrap? For example, is there anything I cannot get from sample set $\mathcal{D}$ but from $Bootstrap$ ?
