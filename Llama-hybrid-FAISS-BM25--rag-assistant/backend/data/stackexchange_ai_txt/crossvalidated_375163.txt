[site]: crossvalidated
[post_id]: 375163
[parent_id]: 
[tags]: 
Why in $Q$-Learning, policy $\pi$ is evaluated through another policy $u$?

I've been watching David Silver's courses about Reinforcement Learning. According to his lectures, policy $\pi$ is evaluated by evaluating another policy $\mu$ . But I cannot understand: why is it so? I would really appreciate if somebody could explain it to me.
