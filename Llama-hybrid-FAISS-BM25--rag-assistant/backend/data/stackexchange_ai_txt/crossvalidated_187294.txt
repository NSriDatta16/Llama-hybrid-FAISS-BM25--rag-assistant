[site]: crossvalidated
[post_id]: 187294
[parent_id]: 187261
[tags]: 
if I compare regression models (with K parameters), I should use the N-K denominator I think the more general description (see your Wiki link) is that the denominator are the degrees of freedom. So if you calculate MSE of your training data, then $k$ degrees of freedom are already used for the parameters. For MSE calculated for pure test data, the denominator should be $n$, yes: you did not use any degrees of freedom here as you subtract reference values. Another way of plausibly explaining this is that testing is totally agnostic of the model, it is treated as a black box that somehow produces predictions each time you input new data. The (potentially) unknown complexity of the black box then cannot enter the calculation of the MSE. Moreover, an independent test is a test run of the true application, it differs only in that you obtain and compare to reference values. So if you are interested in the average squared error for real predictions, you simulate this by averaging the squared error for the test predictions. From this point of view, the $\frac{1}{n - k}$ training version of MSE tries to correct for the bias introduced by the double use of the data - which you don't have for real tests (nor for proper cross validation). Whether your cross validated MSE is biased or not will in practice depend more on whether your cross validation was set up correctly (splits independent for all influencing factors) and whether your data is representative (particularly, if you want to extrapolate from unknown to unknown future cases). (Same for hold-out test sets!)
