[site]: crossvalidated
[post_id]: 220878
[parent_id]: 
[tags]: 
Learning just a decoder (autoencoder without encoder)

I am trying to do something quite unusual: learning a latent representation of some data just by optimizing a decoder. Basically, a probabilistic model of a neural network autoencoder without the encoder. My approach is to set a prior on the latent codes and then minimize the negative log likelihood via SGD. Ideally this will find the best weights and the best settings for the latent variables. The purpose is to learn a latent manifold in a simpler way than with an autoencoder. I think this would work because the lower-dimensionality latent representation, combined with a network with a low number of hidden nodes, will enforce "locality" (is this the correct term?), which means that similar datapoints will be located in nearby values in the lower-dimensional manifold. In my experiments the latent representations are updated mostly in the very early epochs (first or second), while the weights of the neural network are being updated with a larger degree even in later epochs. The question is: do you have any suggestions on why this would or would not work? Any pointers in literature that describe similar models and similar phenomena?
