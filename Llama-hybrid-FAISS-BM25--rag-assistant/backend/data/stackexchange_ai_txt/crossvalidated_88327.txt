[site]: crossvalidated
[post_id]: 88327
[parent_id]: 88290
[tags]: 
As @Scortchi said, it's probably not a good idea, especially if all you're trying to accomplish is as you've described it. You seem to have a cluster of data in the $X=[18–23],Y=[2.2–2.7]$ range ; that might be influencing your LOESS model. You seem convinced that those data aren't meaningful, but be careful not to discount them if only because they complicate your model. If you have better reasons to discount them in mind, it may be unnecessary to model them at all. Still, excluding them might not make a big difference. It looks like your $Y$ range is restricted and causing some ceiling and floor effects . If you model $Y(X)$ as a polynomial function of at least degree three (or a LOESS model, clearly), you'll pick up that flattening of the otherwise monotonic function beyond the values of $X$ for which $Y(X)\approx0\text{ or }4$. In case you don't have an idea of how $Y(X)$ would work as a polynomial function of degree three, I've tweaked a model in WolframAlpha: $Y=.2-.15X+.055X^2-.002X^3$ Pretty close, no? Yet I wonder if it would make sense for $Y(25) You might want to explore alternatives for handling ceiling / floor effects in regression, if that's really what's going on here, and if you're sure that odd patch of observations beyond $X>17$ is negligible. Some other useful questions about models of bounded dependent variables exist here, including: Is a pretest-posttest ANOVA with quartiles of pretest efficacy as an IV reasonable? : @PeterFlom recommended beta regression for bounded dependent variables here, and also here: Extending logistic regression for outcomes in the range between 0 and 1 How to model this odd-shaped distribution (almost a reverse-J) : @whuber argued that several methods including binning "would just compound the error" of "clamping" the DV distribution artificially, hence, "You would be better off telling us about these data and where they came from." Censored regression might be what you need, and it's described very well in whuber's answer. @GregSnow and @AndyW's answers describe other models briefly and why they might or might not be appropriate, including Tobit, quantile, and cautions about beta regression. If you become curious about the Tobit model, see Tobit model explanation . On quantile regression, cf. Logistic quantile regression – how to best convey the results . Also, Dealing with regression of unusually bounded response variable . Since you asked about polychotomization , here are some points on why to not do it : What is the benefit of breaking up a continuous predictor variable? : Scortchi's commented link @FrankHarrell's page on the topic, which Scortchi also referenced . Justification for low/high or tertiary splits in ANOVA : @Glen_b listed lots of good references How to choose between ANOVA and ANCOVA in a designed experiment? : @gung makes a good argument against categorization here. @Florian also cited Cohen (1983) against dichotomization. Nonetheless, I don't want to leave you thinking that your ideas are unmanageable, indefensible, or otherwise just plain terrible...(and I also want to offer those I've tagged here something to mull over!) You can smooth the dummy coefficients for a polytomous, ordinal, independent variable so that adjacent values don't differ too sharply using penalized regression, which (thanks yet again to Scortchi) I've mentioned in answers to these two questions: Continuous dependent variable with ordinal independent variable , and originally, Effect of two demographic IVs on survey answers (Likert scale) For this, I also cited Tsuruta and Bax (2006) , whose article is a little more relevant here. They describe the $C$ index "as a measure of the predictive ability of an independent regressor variable" that has been polychotomized. Unfortunately, I don't see them using it on models of continuous outcomes – only binary – so I'm not sure if it (maybe after modifications?) can quantify the harm done by polychotomization for your case. Regardless, it's a nice example of when one could want to polychotomize something badly enough to develop such an index for optimizing the process. You've probably got better options, but that may not always be so. References - Cohen, J. (1983). The cost of dichotomization. Applied Psychological Measurement, 7 (3), 249–253. Retrieved from http://www.unc.edu/~rcm/psy282/cohen.1983.pdf . - Tsuruta, H., & Bax, L. (2006). Polychotomization of continuous variables in regression models based on the overall C index. BMC Medical Informatics and Decision Making, 6 (41). Retrieved from http://www.biomedcentral.com/1472-6947/6/41/ .
