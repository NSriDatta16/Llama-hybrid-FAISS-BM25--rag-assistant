[site]: datascience
[post_id]: 80301
[parent_id]: 
[tags]: 
Faster RCNN-RPN NETWORK

I already asked this question in stack overflow, but got response from experts, to post this question here, please help me to understand this concept... I am trying to understand RPN network in Faster RCNN. I understand the concept of RPN network, Pass the input images to the pre trained CNN, and get the output as feature maps Make fixed size of the feature maps Extract anchors (3 different scales and ratio for every sliding window) from the fixed size feature maps. Use two 1Ã—1 Fully connected NN to find the background or object and the bounding box coordinates (4 values) Calculate IOU for Anchors bounding box with Ground Truth bounding box, if IOU>0.7, then the anchor has object, otherwise, the anchor has background. The theme for RPN is to give the region proposals which have objects. But, I do not understand the input and the output structure. For example, I have 50 images, each images having 5 to 6 objects, and labeling informations(coordinates of each objects). How do I generate target values, to train PRN Network... In all the blogs, they shows the architecture as feed the entire image to the pre trained CNN. And, the output of RPN, the model has to tell whether the anchor has object or not, and also predict the bounding box for the object in the anchor. For this, how to prepare the input and target/output values like we do in dog/cat or dog/cat/car classification problem. Let me correct if I am not correct, Is that, we have to crop all the objects in every image and do binary classification as object vs background for classifying the anchor has object or not And, Is that, we have to give the ground truth value as target for every cropped objects from all images in the dataset, so that the RPN network trained well to predict the bounding box for the object in every anchor. Hope, I clearly explained my doubts. Help me to learn this concept, Thank you
