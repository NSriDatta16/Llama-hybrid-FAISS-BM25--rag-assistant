[site]: crossvalidated
[post_id]: 339049
[parent_id]: 338759
[tags]: 
To test whether there is a linear relationship between the predictors and the logit of the dependent variable I have included an interaction term between the predictor and their associated natural logarithm. If there is an interaction between predictors ($X_1$, $X_2$) we can say a couple of things about their relationship with a response ($Y$). That the relationship between $X_1$ and $Y$ varies across values of $X_2$. That the model for $Y$ adjusting for $X_1$ and $X_2$ but not their interaction, summarizes the "average" adjusted response. To report the first finding, it is useful to show the associations between $X_1$ and $Y$ and between $X_2$ and $Y$ for some fixed levels of $X_2$ and $X_1$ respectively. The R command coplot can do this well. If the shape of the sigmoid curve changes direction or shifts drastically, we can conclude that the interaction has a strong magnitude of effect. Usually, we don't see such a strong relationship, and can conclude that the model was powered to detect small interactions and found one. If that holds, then the second model, omitting the interaction term, can be reasonably presented. Since there is an extent of model misspecification, it is useful to use a robust variance estimate. I use the Huber-White estimator implemented in the sandwich package by Achim Zeileis. When interaction is mild, the message of the data analysis usually remains unchanged, and the implications for policy or research remain unchanged. However, if the interaction is so strong that notably different, heterogeneous effects are observed between subgroups, there is a new hypothesis generated by the data analysis. We have a hypothesis about the presence of subgroups for which the exposures achieve a desired effect (or the groups for which the exposure is harmful).
