[site]: crossvalidated
[post_id]: 358552
[parent_id]: 358537
[tags]: 
Sorry, the following is only correct if $k=1$. In kNNs, as in many others ML models, indeed a loss function is minimised. Say we have data $(x_i, y_i)_{i=1}^I$, where $x_i$ are the vectors of independent variables and $y_i$ contains the class of $x_i$. The kNN constructs a function $f$, such that $\mathrm{Loss}(f(x_i),y_i,i=1,...,I)$ is minimised. In this case, any loss function can be taken that is always positive and that is zero if and only if $f(x_i)=y_i, i=1,...,I$. Any can be taken means, the results would be equivalent for any of them. However, as opposed to linear or logistic regression, the function $f$ cannot be fully described by the $\mathrm{Loss}()$ function, since it also depends on the distance function that you choose to determine the neighbours.
