[site]: crossvalidated
[post_id]: 108393
[parent_id]: 
[tags]: 
Achieving high recall for smaller class in unbalanced linear svm

I have an svm-related question. I have an unbalanced dataset, meaning classA could be 1/10 to 1/35 of classB. Well I am interested in getting a linear svm which would separate the data and would achieve the greatest possible recall of classA. Let me show some examples to be more specific: If 1000 samples are mapped to classA by the hyperline I want to have 80%-90% of classA. This does not mean that classA would have only 1000 samples, it could have 2000 or 10000. I am not interested in the accuracy of classA, i.e. the standard criterion to get the more samples of classA by svm out of the total samples belonging to classA. If I can get 100 samples of classA and no of classB it would be preferable than getting 500 samples of classA and 500 of classB. My question is how do I choose this hyperplane. I have tried the following: I used unbalanced weights for the samples (inverting the class cardinalities) but I can get high classA accuracy but low recall. I tries to use the default weights, i.e. for all being 1, but I got peculiar results: when run on train set for all samples it gets an accuracy of 95% (as expected since dataset is unbalanced). BUT if checked in classA members it gives 0%! So have you got any ideas besides playing around with weights? P.S.1 I am using liblinear (in matlab if that matters). P.S.2 I know svm optimization criterion basically does not account for what I am looking for since margin maximization maximizes accuracy but I thought I would give it a try.
