[site]: crossvalidated
[post_id]: 468651
[parent_id]: 
[tags]: 
Why do you need a balanced test set?

It seems to be the consensus that, if possible, both train and test set for binary classification should be balanced over the two classes, especially if using classifiers like SVM. Whilst I understand why that's the case in the train set, why does the test set need to be balanced? My understanding is that each sample would be a separate problem and predicted on its own, so why would the overall distribution impact the prediction? Practical context: I am working on a biological problem for which I have access to positives and can "make up" negatives for my classifier, and so I can achieve a perfectly balanced train set. However, the practical real-life application would be on sets that contain overwhelmingly more negatives than positives because of the nature of the problem.
