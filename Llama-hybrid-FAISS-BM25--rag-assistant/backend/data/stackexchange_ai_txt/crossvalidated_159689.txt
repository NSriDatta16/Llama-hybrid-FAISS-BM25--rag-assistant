[site]: crossvalidated
[post_id]: 159689
[parent_id]: 159678
[tags]: 
You should read Doing Bayesian Data Analysis 2e from John K. Kruschke: https://sites.google.com/site/doingbayesiandataanalysis/ It is easy to read, and easy to understand. In the Bayes Rule (chapter 4, page 106), you read: $$\underbrace{p(\theta|D)}_{\large\text{posterior}} = \underbrace{p(D|\theta)}_{\large\text{likelihood}} \quad \underbrace{p(\theta)}_{\large\text{prior}} \; / \quad\underbrace{p(D)}_{\large\text{evidence}}$$ I am quoting from the same page: The "prior,", $p(\theta)$ is the credibity of the $\theta$ values without the data $D$. The "posterior," $p(\theta|D)$ is the credibility of $\theta$ values with the data $D$ taken into account. The "likelihood," $p(D|\theta)$, is the probability that the data could be generated by the model with parameter value $\theta$. The "evidence" for the model, $p(D)$, is the overall proability of the data according to the model, determined by averaging across all possible parameter values weighted by the strength of belief in those parameter values.
