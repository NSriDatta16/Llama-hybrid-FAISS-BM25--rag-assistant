[site]: datascience
[post_id]: 37747
[parent_id]: 37738
[tags]: 
The current standard is essentially: Given this input data, can any other system or approach classify it or estimate a quantity of interest? If so, then a machine learning approach may be able to achieve the same. This is basically how machine learning challenges in computer perception can be treated as tractable. We have humans and other animals as working models, and make the assumption that the process can be automated. A similar approach can be made on any machine learning system which attempts to re-create the behaviour of an expert - provided we use the exact same input data, and enough of it, the ML system can learn what the expert does through statistical approximation. The "expert" can be a statistician/data scientist looking at the data, using any tool. Exploratory plots of features and measures of correlation are a good way to assess whether a data set might be amenable to training a ML model for prediction. If you can visually separate classes on a scatter plot using some combination of features, then it is likely that a suitable ML model will be able to separate those classes too. There are hard cases, where it seems on the surface like there is no pattern. Perhaps a relationship could be teased out and shown to exist with statistical analysis, but you could eschew that and directly throw some non-linear ML model at the problem in the hope that it finds it for you with the correct hyper-parameters. Of course you don't know in advance whether that is a worthwhile approach, and this carries some risks. But it is not that expensive to do once you have some data - just throw a fairly robust non-linear model at the problem, like XGBoost, and see what happens. Of course, ML is not magic. If there is nothing to find, it will tend to find nothing. Worse than that, it can find spurious correlations, or patterns due to prejudice inherent in the data collection or labelling. Those issues are a problem regardless of evidence on whether it was theoretically possible to achieve a result at all. However, the kind of thinking that drives "let's throw some neural networks at this" has led to some published works which are quite terrifying and wrong on many levels. An example of such a system was a NN which classified a person as criminal or not according to a picture of their face - luckily flaws were pointed out in data collection on that one, but the original story made headline news in many places, despite essentially being a modern re-birth of Phrenology.
