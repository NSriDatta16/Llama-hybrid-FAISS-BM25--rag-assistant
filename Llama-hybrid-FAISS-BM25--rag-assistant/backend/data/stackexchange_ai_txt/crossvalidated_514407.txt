[site]: crossvalidated
[post_id]: 514407
[parent_id]: 514396
[tags]: 
I would advance that statistical level thresholds are ultimately really arbitrary and driven more by the requirements of the relevant Journal publishers, peer-reviewers, model validators. Thus, in academia or business often the choice is not subject to the model developer but to the relevant peer-reviewing audience that will validate the model. Within this community some require alpha p-value thresholds of = If you get a p-value of 0.11, the peer-reviewing community will typically jump all over it for no truly valid reason. A colleague of mine stated to me "is a 89% bet that materially different fro a 90% bet?" What is probably far more important than statistical threshold cut-offs is the underlying logic and explanatory power of an exogenous variable. In my own modeling effort, I often encounter variables that get selected based on statistical significance threshold criteria, but enter the model with the wrong coefficient signs. Thus, logic and directional explanatory power considerations should always play a preponderant role in variable selection over just considering statistical significance alone. With 7 variables and a very small sample size of 25 observations, you have very few degrees of freedom left (18). You are hell bent on keeping all 7. I would relax your mandate. I would build a sequence of models with the best first variable, than 2, 3, etc. At each step I would observe how much the Adjusted R Square increase. I would also test your model in-Sample and Out-of-Sample and observe how well your model predicts. By including all 7 variables you may run into several problems: Well, the more variable you add, often the more you dilute the statistical significance of any of the included variables. A model with 3 variables may disclose very strong statistical significance for all 3 variables. When you add the next 4 variables, you may observe that the statistical significance of the first 3 has dropped markedly. That happens very often; Overfitting. When adding variables your Adjusted R Square typically always increases. Even AIC, BIC scores will improve suggesting that everything is all right. But, it is not necessarily the case. When you conduct some Out-of-Sample testing, your simpler model with fewer variables may perform a lot better in prediction. And, that is what really matters. Multicollinearity or near-multicollinearity. True multicollinear variables are rare. They should have a correlation of 0.90 or above to be multicollinear. In such a case, it be silly to include both within a model since they pretty much impart the same information. But, even variables that have lower correlations than 0.90 can be truly superfluous to a model and impart more Noise than Signal after conducting out-of-Sample testing on such a model. As a side note, Roberto Pedace, PhD, professor in the Department of Economics, Scripps College, within his excellent book "Econometrics for Dummies" states that it is perfectly ok to have a combination of statistically significant and not-statistically significant variable within an econometrics model, as long as the underlying logic, directional sign, explanatory power of the variables make sense. I fully agree with him. But, I have yet to meet a peer-reviewer with such a nuanced and enlightened approach to variable statistical significance.
