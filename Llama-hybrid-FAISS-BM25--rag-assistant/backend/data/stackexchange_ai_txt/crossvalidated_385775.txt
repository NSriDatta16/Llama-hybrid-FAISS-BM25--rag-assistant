[site]: crossvalidated
[post_id]: 385775
[parent_id]: 
[tags]: 
Normalizing vs Scaling before PCA

I know there's a lot of content about PCA pre-processing, but I am still somewhat confused. I have a dataset that contains some clear patterns: 1 variable is whether a person has financial resources (Yes/No), another is the volume of financial_resources (=0 for people that have no resources), then others are variables that tend to be correlated with the volume of financial resources. The dataset also contains several dummified variables, and some discrete variables ranging between 0 and 5. I would assume I would find two clusters: one for people with no resources, another for people with resources. When applying PCA with two components, I had two approaches: - Scale , then apply PCA - Normalize , then apply PCA This leads to completely different results. I know that scaling is a standard pre-processing step to PCA. But does normalizing make any sense? I figure I have done something close to a Sparse PCA, where I captured the most significant patterns first then fitted the PCA. Can you give me some insights on this? Note that the goal of my PCA is to visualize the results of a clustering algorithm. Fig 1 - Top 2 components with scaling Fig 2 - Top 2 components with normalizing
