[site]: crossvalidated
[post_id]: 371218
[parent_id]: 371012
[tags]: 
After digging through the code, I think its safe to say that using predict and setting predcontrib to TRUE is preferable to using the xgboostExplainer functions. The following code demonstrates that the discrepancy between the two packages disappears when you set approxcontrib to TRUE . library(xgboost) library(xgboostExplainer) ## binary classification: data(agaricus.train, package='xgboost') data(agaricus.test, package='xgboost') train $data, label = train$ label, max_depth = 2, eta = 0.5, nthread = 2, nrounds = 5, objective = "binary:logistic") pred $data) pred_contr data, predcontrib = TRUE, approxcontrib = FALSE) pred_approx_contr $data, label = train$ label) xgb.test.data $data, label = test$ label) explainer = buildExplainer(bst, xgb.train.data, type="binary", base_score = 0.5, trees = NULL) pred_xgboostExplainer = explainPredictions(bst, explainer, xgb.test.data) #similarly shaped outputs dim(pred_xgboostExplainer) dim(pred_contr) dim(pred_approx_contr) #discrepancy between prediction contributions when approxcontrib = FALSE summary(as.numeric(pred_contr[1,]) - as.numeric(pred_xgboostExplainer[1,])) # Min. 1st Qu. Median Mean 3rd Qu. Max. # -0.2982 0.0000 0.0000 0.0000 0.0000 0.1712 #discrepancy disappears when approxcontrib = TRUE summary(as.numeric(pred_approx_contr[1,]) - as.numeric(pred_xgboostExplainer[1,])) # Min. 1st Qu. Median Mean 3rd Qu. Max. # -4.525e-08 0.000e+00 0.000e+00 3.522e-10 0.000e+00 6.590e-08 #final prediction values all agree with output of predict function summary(qlogis(pred) - rowSums(pred_xgboostExplainer)) # Max ~ 1e-07 summary(qlogis(pred) - rowSums(pred_approx_contr)) # Max ~ 1e-07 summary(qlogis(pred) - rowSums(pred_contr)) # Max ~ 1e-07 So now I think I can answer the two questions posed above. Why the discrepancy between the two methods? The approximation is the "path" method developed in this blog post and was likely the inspiration for the xgboostExplainer blog post . Lundberg et al note that the path method just takes the single ordering defined by descending the tree, whereas their method (which is what is used in the xgboost package) is the average of the path method computed over all permutations of possible variable orderings. By only considering a single ordering, the path method runs into inconsistency problems as shown in Fig 1 of Lundberg et al. Is there a preferred method when calculating the contribution of each feature in an xgb classifier? Because predict can calculate everything that xgboostExplainer can and more, I think its safe to say that predict should be preferred. It is 100x faster and available natively in the xgboost package, whereas xboostExplainer is not available on CRAN. Also you should probably set approxcontrib to FALSE unless you have a good reason not to. (That said, I still like the waterfall plotting functions in xgboostExplainer.)
