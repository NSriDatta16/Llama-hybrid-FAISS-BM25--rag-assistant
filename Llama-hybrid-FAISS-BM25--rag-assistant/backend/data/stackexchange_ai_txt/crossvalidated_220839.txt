[site]: crossvalidated
[post_id]: 220839
[parent_id]: 
[tags]: 
Variance of an unbiased estimator is 0 when the sample size goes to infinity

So I would like a proof for the following but I can't seem to do it myself. I have a random variable $X$ and I draw $n$ samples($\{X_1, \ldots, X_n\}$) from it and I have $$ Z_n = \frac{\sum_{i = 1}^{n}(X_i - \overline{X_n})^2}{n-1} $$ so the random variable for the unbiased estimator for the variance. $\overline{X_n} = \frac{\sum_{i = 1}^{n}X_i}{n}$ is the variable for the sample average. I would like to prove the following: $$ \lim_{n \to \infty}Var(Z_n) = 0 $$ I would like to prove this since it would mean that it worth to take large/larger samples since a variance of zero means that the random variable is equal to the mean with a probability of 1.
