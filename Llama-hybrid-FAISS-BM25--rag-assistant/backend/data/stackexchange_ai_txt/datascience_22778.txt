[site]: datascience
[post_id]: 22778
[parent_id]: 22766
[tags]: 
As far as I know, the usp of CNN is the fact that location of a pattern doesnt matter. This is not true. Some options used in CNN architecture, such as max pooling, or strided convolutions, can add a moderate amount of translation invariance. However this will not cover larger translations - anything that is a significant percentage of the image width/height. CNNs also support translation equivariance , which is where image textures and motifs that appear repeatedly but in different locations (lines, corners, curves) are learned efficiently and appear in the feature maps. This is probably closer to the USP of CNNs, that they learn the "representation language" of a signal, such as photograph, where it is consistent across the dimensions that are being convolved. The cause of your problem is therefore very likely that your training set does not include enough images with the more central translation, or enough variations with the separate images. To cover large translations you could look at one or more of: Image pre-processing. In your supplied examples it looks very feasible to centre the digits. Data augmentation. Generate translated versions of your training data to cover expected range of input translations in test. Network architecture. A RNN or RNN/CNN hybrid could probably consume the images using smaller overlapped tiles of the images in sequence, and be trained to output the captcha string at the end. You might also be able to do this without a RNN, but that would require labelling each tile for the separate digits.
