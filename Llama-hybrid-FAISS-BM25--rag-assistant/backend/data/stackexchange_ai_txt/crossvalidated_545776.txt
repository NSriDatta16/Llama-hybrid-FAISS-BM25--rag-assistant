[site]: crossvalidated
[post_id]: 545776
[parent_id]: 
[tags]: 
SMOTE for logistic regression model had a worse result compared to original?

Not sure why using more sample from SMOTE() could lower the overall accuracy: over = SMOTE(sampling_strategy=0.4) X, y = over.fit_resample(X, y) counter = Counter(y) print(counter) Counter({'no': 19548, 'yes': 7819}) from sklearn.linear_model import LogisticRegression # Instantiate the logistic regression classifier: logreg logreg = LogisticRegression() # Fit it to the training data logreg.fit(X_train,y_train) y_pred = logreg.predict(X_test) # Compute and print the confusion matrix and classification report print(confusion_matrix(y_test, y_pred)) print(classification_report(y_test, y_pred)) [[3616 293] [ 964 601]] precision recall f1-score support no 0.79 0.93 0.85 3909 yes 0.67 0.38 0.49 1565 accuracy 0.77 5474 macro avg 0.73 0.65 0.67 5474 weighted avg 0.76 0.77 0.75 5474 the original result without SMOTE() [[3897 41] [ 514 48]] precision recall f1-score support no 0.88 0.99 0.93 3938 yes 0.54 0.09 0.15 562 accuracy 0.88 4500 macro avg 0.71 0.54 0.54 4500 weighted avg 0.84 0.88 0.84 4500 (I used get_dummies and MinMaxScaler) Thanks a lot!!
