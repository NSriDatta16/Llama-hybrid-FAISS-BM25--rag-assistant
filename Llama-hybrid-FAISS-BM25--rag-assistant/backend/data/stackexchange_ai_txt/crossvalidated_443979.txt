[site]: crossvalidated
[post_id]: 443979
[parent_id]: 443954
[tags]: 
Personally, I find it very hard to draw a line between the two, as there is clearly some overlapping. Machine Learning is a field that is based on classical statistics and USES statistic models heavily. Also, the mathematics behind Machine Learning can get extremely complicated, so I really would not use the mathematical argument as a discriminant. One important difference, at least to my eyes, is the one of the "modeling vs data-driven". Statistics usually requires the statistician to make assumptions about the structure and/or distribution of the data, trying to guess the relationships between the variables in order to write an appropriate model. A Machine Learning approach, on the other hand, will try to limit assumptions to a minimum and it will let the data "speak for itself". I will try to give an example with an algorithm that belongs to both statistical and machine learning literature: linear regression. A statistical approach would be to look at the variables at hand, and based on the knowledge on their meaning, try to understand which ones might interact and which ones might have a non-linear dependency, building a model accordingly. A fully ML approach would instead be to use a backward elimination process of features starting from a model containing every interaction and every polinomial expansion up to a certain degree, letting the data decide which ones are relevant. Of course these two approaches meet in the middle most of the time - statisticians also use forward and backward processes to build their models, as well as ML practicioners often work on the feature engineering in order to give them a better meaning. But this also leads back to the point that you made earlier: Statistics is more often about trying to understand the structure behind the data in an understandable manner, and explainablility is a big factor; Machine Learning on the other hand often focuses more on the prediction, and this allows it to avoid make models that would "oversimplify" the relationships to make them understandable, and instead use the data to infer the most efficient structure possible to forecast new values. Finally - on bootstrapping, MCMCs and so on: as Bryan mentioned before me, these are computational techniques, and they are used in both approaches. Also Cross Validation is a computational technique that is used in statistics, and the fact that it relies on iterations it does not make it ML. I would not put a label on every single algorithm, since Statistics and Machine Learning are deeply intertwined and use many common tools, such as the computational techniques that you mentions or many many models, so in the end when you're in the gray area between the two, the fact of "doing Statistics" or "doing Machine Learning" often depends on the mentality that you use when approaching the problem.
