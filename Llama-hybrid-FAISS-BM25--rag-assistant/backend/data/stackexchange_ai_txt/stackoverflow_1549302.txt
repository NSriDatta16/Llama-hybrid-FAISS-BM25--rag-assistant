[site]: stackoverflow
[post_id]: 1549302
[parent_id]: 1549265
[tags]: 
I don't think time will help figure out it's complexity class. Times can be very different even on exactly the same task (depends on the scheduler or other factors.) Look at how many more steps it takes as your input get's larger. So if you had a sorting algorithm that took 100 steps to sort 10 items and 10000 steps to sort 100 items you'd say sorted in big O ( N^2 ) since Input Steps 10 100 (which equals 10*10) 100 10000 (which equals 100*100) It's not about averaging but looking for a function that maps the input to the number of steps and then finding what part of that function grows the fastest ( N^2 grows faster than N so if your function was N^2 + N you classify it as N^2). At least that's how I remember it, but it's been ages!! :) EDIT: Now that there are more details in your question, here is what I'd do, with the above in mind. Don't think about averaging anything, just think about how f(100) = 300, f(200)=604, and f(400)=1196. And it doesn't have to be exact, just in the ball park. So a simple linear function (such as f(x)=3*N ) where f(100)=300, f(200)=600, and f(400)=1200 that would describe the complexity of the algorithm you could say the complexity class of the algorithm was linear or big O(N). Hope that helps!
