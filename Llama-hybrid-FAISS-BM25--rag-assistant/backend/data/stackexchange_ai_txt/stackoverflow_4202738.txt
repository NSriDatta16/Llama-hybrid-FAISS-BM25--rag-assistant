[site]: stackoverflow
[post_id]: 4202738
[parent_id]: 4202715
[tags]: 
You can use Robots.txt : User-agent: * Disallow: / But it's not 100% reliable, not all crawlers will respect this. From what i have learned recently the only 100% reliable way is to make all your pages secure.
