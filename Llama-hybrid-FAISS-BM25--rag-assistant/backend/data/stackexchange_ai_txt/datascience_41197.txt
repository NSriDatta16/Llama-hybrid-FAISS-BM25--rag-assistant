[site]: datascience
[post_id]: 41197
[parent_id]: 41185
[tags]: 
Assume you have features wich lie in a $R^n$ space, e.g. your input is a picture with $28 \times 28$ pixels, then $n$ would be $28 \times 28 = 784$ . Now you can "embedd" your features into another $R^d$ space, where often $d . This way you learn a rich representation of your input. When you compress your $784$ input-pixels to, lets say $64$ you compressed your input by more than a factor $10$ and can elimnate redundant/useless features. This embedding learning is of course done in such a way, that you could fully restore your original $784$ pixels out of your $64$ compressed pixels.
