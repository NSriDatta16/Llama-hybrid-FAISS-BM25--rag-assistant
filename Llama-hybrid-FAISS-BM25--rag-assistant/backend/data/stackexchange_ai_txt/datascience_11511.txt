[site]: datascience
[post_id]: 11511
[parent_id]: 
[tags]: 
In random forest, what happens if I add features that are correlated?

I'm training a random forest, trying to predict market shares of future stores on geographical areas. I have many features for these areas, some of which tell similar but different things about one thing. For example, I know the total number of $accommodations$ in the area, and I also have 5 others columns which are all linked in the following way: $main \space accommodations + secondary \space accommodations + holiday \space accommodations = houses + flats = accommodations$ I have the feeling that including them all in my model would be wrong... but including them might be important... Any hint on how I should handle this? Would it be a good idea to include $accommodations$ as absolute value and include all the other five but as % (of $accommodations$) and not as absolute values? In a similar fashion, I also have the total number of $households$ of the area, the $total \space income$ of the area, and the $average \space income$ of households in the area (so that $households * average \space income = total \space income$). I have the feeling using the average and not the total income would be a better idea, but how can I be sure I'm right ? (I guess I could train three random forests using the average income only, the total income only, and both, and see how they perform on cross validation, but is there a rule of thumb that I should know of which can make me go faster ?) (In case it's relevant, I'm using R and the randomForest package)
