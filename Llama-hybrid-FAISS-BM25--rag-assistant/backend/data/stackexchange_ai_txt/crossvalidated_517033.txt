[site]: crossvalidated
[post_id]: 517033
[parent_id]: 
[tags]: 
Are there some supervised machine learning methods that learn to rank the features?

For example, given training data/features $$ \mathbf{X}^{(1)} = \{\mathbf{x}_1^{(1)}, \mathbf{x}_2^{(1)}, \mathbf{x}_3^{(1)}, \dots, \mathbf{x}_{l_1}^{(1)}\} \\ \mathbf{X}^{(2)} = \{\mathbf{x}_1^{(2)}, \mathbf{x}_2^{(2)}, \mathbf{x}_3^{(2)}, \dots, \mathbf{x}_{l_2}^{(2)}\} \\ \dots \\ \mathbf{X}^{(n)} = \{\mathbf{x}_1^{(n)}, \mathbf{x}_2^{(n)}, \mathbf{x}_3^{(n)}, \dots, \mathbf{x}_{l_n}^{(n)}\} $$ In this case, each sample is a matrix/set that contains multiple vectors (the exact number of vectors could be different, denoted as $l_i$ ). Each vector has $k$ values, i.e., $\mathbf{x}_i^{(j)} \in \mathcal{R}^k$ . These values are aligned features (i.e., the first value of $\mathbf{x}_i^{(j)}$ denotes the same thing as the first value of $\mathbf{x}_p^{(q)}$ denotes). We hope to train a machine learning model $f: \mathcal{R}^k \rightarrow \mathcal{R}$ that takes in this feature vector and outputs a scalar that can be used to rank these vectors. And we hope to train this model in a supervised manner with information such as: $$ y_2^{(1)} > y_7^{(1)} > y_9^{(1)} > \dots, > y_{3}^{(1)} \\ y_4^{(2)} > y_2^{(2)} > y_1^{(2)} > \dots, > y_{6}^{(2)} \\ \dots \\ y_4^{(n)} > y_5^{(n)} > y_3^{(n)} > \dots, > y_{2}^{(n)} \\ $$ Therefore, when there are future test data (each sample is a set of vectors) the model can learn to rank these vectors. I wonder if there are machine learning model can suit this need. Or where I can start to look at techniques like this?
