[site]: crossvalidated
[post_id]: 241522
[parent_id]: 
[tags]: 
random forests: feature importance changes with each run

I have 309 samples [tumors] and 3234 features [genes]. I used scikit-learn python library to run random forest with one parameter n_estimators=100 . I also used train_test_split to spit my dataset into 70-30 . When I run the model several times, i.e, each time - randomly split data as 70-30 and predict feature importances; I get different features ranked as important. Sometimes there is an overlap while most of the times there is none - often new features that were NOT found in the original run show up. Also the most top 10 ranked feature scores are within 0.01-0.03 . There are highly correlated features in this dataset (as genes are often co-regulated - or, features are often inter-linked in an organic network). Is this commonly noted and if so, are there ways to come to a consensus important feature by averaging the "feature_importance_score" across 10-20 random runs? If this is not common, any suggestions where I may be going wrong?
