[site]: crossvalidated
[post_id]: 588240
[parent_id]: 588233
[tags]: 
In general, if you fit a model on data from one group (population), you cannot expect it to work well on data from another group/population. I presume that, while the groups are all different, you expect them to be similar to a certain degree, such that models trained on one group are not completely off with respect to another of your groups. And in the same way, completely new groups are still somehow similar to your ten training groups. If that wasn't the case, i.e. if your groups were really completely unrelated, there would be no point in learning models. In other words, I presume that your ten groups are samples from a density over the set of datasets that doesn't have too large a variance. In this situation, I would learn a neural network on the combined data of groups. Split your ten groups into one group for testing and the other nine groups to do cross-validation on. Choose e.g. each of those nine groups once as validation data and train on the combination of the remaining eight groups. If you have enough data this should work. Just make sure that you properly regularize your NN: if you don't, they might overfit and then only work well on the training groups. As always with cross-validation, don't forget to, in the end, fit a final model to all of your nine non-test groups. This final model then is tested against the hold-out test group.
