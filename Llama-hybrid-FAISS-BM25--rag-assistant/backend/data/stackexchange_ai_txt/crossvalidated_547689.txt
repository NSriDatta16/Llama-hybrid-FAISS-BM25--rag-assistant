[site]: crossvalidated
[post_id]: 547689
[parent_id]: 547663
[tags]: 
If you are tuning computationally intensive algorithms like neural networks, you wouldn't usually use $k$ -fold cross-validation, because the computations would take too long. Instead, you would use held-out validation and test sets, so you would train the algorithm only once and validate only on a single test dataset. In fact, this is what Andrew Ng recommends in his course. To find the best parameters you usually shouldn't use grid search, but random search , or even better, bayesian optimization . Those methods would enable you to search for the hyperparameters more efficiently.
