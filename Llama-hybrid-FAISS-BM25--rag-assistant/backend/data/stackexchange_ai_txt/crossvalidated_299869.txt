[site]: crossvalidated
[post_id]: 299869
[parent_id]: 299859
[tags]: 
The complete algorithm is outlined in the xgboost paper, which also provides this summary: We summarize an approximate framework, which resembles the ideas proposed in past literatures, in Alg. 2. To summarize, the algorithm first proposes candidate splitting points according to percentiles of feature distribution (a specific criteria will be given in Sec. 3.3). The algorithm then maps the continuous features into buckets split by these candidate points, aggregates the statistics and finds the best solution among proposals based on the aggregated statistics. Since it's finding the best solution (feature and split) from some set of proposed solutions, we can infer that it is (approximately) optimizing some metric, and that the selection of features and splits is not at random. More complete information is provided in the paper. It's also worth noting that random forest doesn't simply select features at random -- for each split, random forest selects a subset of features, and then chooses the best split from among the random subset.
