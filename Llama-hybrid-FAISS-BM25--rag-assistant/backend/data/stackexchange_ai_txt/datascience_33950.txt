[site]: datascience
[post_id]: 33950
[parent_id]: 33948
[tags]: 
No. Both standards CNNs and ResNets are highly vulnerable to adversarial examples; neither one is particularly better than the other. "Open source" is not really relevant here. If you're asking about ability to craft adversarial examples when the attacker doesn't have access to the model itself, you might be interested in black-box algorithms for generating adversarial examples. There are ways known that an adversary can find adversarial examples without having access to the model. Broadly speaking, there are two common attack approaches: Exploit transferability: Generate adversarial examples for some other model that is known; then they will often fool the secret model as well. Exploit API access: if you can make queries to the model (send it an input and get back the label that the classifier outputs), then there are new attack algorithms that are able to find adversarial examples. ZOO is one example, but there are more recent advances as well. Broadly speaking, there is no known defense for adversarial examples that seems to be very effective in general.
