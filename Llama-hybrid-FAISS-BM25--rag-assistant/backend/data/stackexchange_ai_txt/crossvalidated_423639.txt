[site]: crossvalidated
[post_id]: 423639
[parent_id]: 
[tags]: 
why mean=50 instead of 0 and why is it even needed in this rnorm function? (From ISL book)

I'm new to the field of data science and I've started off by going through the Introduction to Statistical Learning book. In there I am going through the introduction to R section and have come across the following: x=rnorm(50) y=x+rnorm(50,mean=50,sd=.1) cor(x,y) I understand that x and y , being vectors of size 50, have a very close correlation (about 99.5%) due to y just being a small shift in x of standard deviation 0.1. However I do not understand why, for y , the mean is explicitly set to 50? Should the mean not be 0 like it is for x (by default)? From what I can see the values within the y matrix are also within the range of -2 and 2, giving a mean of roughly 0. Thanks in advance.
