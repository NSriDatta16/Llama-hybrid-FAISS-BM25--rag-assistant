[site]: crossvalidated
[post_id]: 535110
[parent_id]: 535101
[tags]: 
I understand that you worry that you don't know the historical performance of the experts, so you don't know how reliable are their responses. It's a valid worry, but think of it in terms of wisdom of a crowd , their aggregate opinion should outweigh their individual biases and mistakes. For this to work, you would want the opinions to be made independently of each other (experts don't consult each other opinions), and best if the experts would not be a very heterogeneous group, though those are rather nice-to-haves. So you can just count the votes and sort the individuals by counts. But let's say that you worry that some of the experts can be biased, for example, they tend to be very generous when voting, or the opposite, they pick very few individuals by default. You might want to use a statistical model to correct those biases. One of the models used in such cases is the Rasch model $$ P(Y_{ij} = 1) = \frac{\exp(\theta_i - \beta_j)}{1+\exp(\theta_i - \beta_j)} $$ Where the probability of seeing the $i$ -th individual picked by $j$ -th expert is coded as a binary variable $Y_{ij}$ and modeled in terms of the two parameters for the true attribute $\theta_i$ of the individual and the expert's bias $\beta_j$ . Notice that the model is just a generalized mixed-effects logistic regression model. You can use such a model for your data and treat the $\theta_i$ as the "distilled" attribute scores. There are also more complicated Item Response Theory models, such models are commonly used for modeling what is called the examiner effect , I encourage you to search for the term to learn more. Notice that this is very similar to matrix factorization , used by recommender engines . In matrix factorization, you would decompose the $n \times k$ matrix of the binary picks by $k$ experts for $n$ individuals into two components $P$ and $Q$ of the dimensions $n \times m$ and $m \times k$ $$ Y \approx PQ $$ In such a case, you created embedding vectors for the data, where $P_{i\cdot}$ can be thought of as a vector of $m$ latent features describing the individual, relevant to the $Y_{i\cdot}$ votes they got. In the recommender system, you could use the embeddings for making the "people similar to you liked this" kind of recommendations. Here you don't need such a feature, as you don't really need to "recommend" the experts, but still, the $Y_{i\cdot}$ vector can be used for ranking or clustering the individuals. I'm describing this to show how a similar idea is used in a different field, so it can serve as an inspiration. The recommender systems literature can also give you some hints about scaling this if you are dealing with a big sample size $n$ .
