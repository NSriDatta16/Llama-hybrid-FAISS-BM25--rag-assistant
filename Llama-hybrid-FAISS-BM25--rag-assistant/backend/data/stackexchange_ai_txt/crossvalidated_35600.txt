[site]: crossvalidated
[post_id]: 35600
[parent_id]: 35597
[tags]: 
The correct way to approach this problem is to assign costs to false positive and false negative errors, and set the regularisation parameter C to different values for each class in order to minimise the expected loss. I wrote a paper on this some years ago, there is probably something more up to date available now. The fact that "not classifying 40% of the documents is unacceptable from a business point of view" strongly suggests that false-positive and false-negative costs are not equal. This problem can crop up frequently in multi-class problems with a large number of classes, which means that individual two-class SVMs end up with a dataset with hardly any positive examples. Again the best you can do with SVMs is probably to tune the ratio of C for positive and negative patterns via cross-validation to minimise the expected loss. For converting the output of an SVM to a probability, there are many methods, but Platt's method is the most commonly used. However, if you want probabilities, then why not just use regularised logistic regression? In practice there generally isn't much to choose performance-wise between linear SVMs and RLR, provided the regularsation parameters are properly tuned. If you want probabilities, then RLR seems closer to Vapnik's maxim of always solving the problem directly, rather than using a more general method and simplifying (or on this case, a less general method and post-processing it to get a probability). HTH
