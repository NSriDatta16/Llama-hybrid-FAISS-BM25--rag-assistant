[site]: crossvalidated
[post_id]: 625405
[parent_id]: 
[tags]: 
Area under the ROC curve when there is imbalance: is there a problem, and if not, why does this rumor exist?

THE BOUNTY As promised, a bounty of $250$ points has been issued. A bounty-worthy answer should address the apparent controversy in the answers here that ROC curve interpretation does not depend on class ratio, yet ROC curves likely do not address the questions of interest in an imbalanced problem, especially in light of the relationship between ROC curves and Wilcoxon testing the predictions made for each of the two categories (a rather reasonable measure of how well the categories are distinguished from each other). ORIGINAL QUESTION Cross Validated has a rather thorough debunking of class imbalance being an inherent problem that must be fixed in order to do quality predictive modeling of categorical outcomes [ 1 , 2 ]. However, there are measures of model performance that can be misleading when there is imbalance. The obvious one, whose (mis)use seems to drive many misconceptions about class imbalance, is that high classification accuracy need not correspond with a quality model. Yes, $99\%$ classification accuracy sounds like an $\text{A}$ in school, yet if the imbalance is $1000$$:$$1$ , you could score higher classification accuracy just by predicting the majority category every time. Another measure of performance that has been claimed to have issues in imbalanced problems is the area under the receiver-operator characteristic (ROC) curve. I struggle to see why this would be the case. The imbalance is just the prior probability of class membership, and altering the prior leads to a monotonic transformation of the predicted probability values, leaving the ROC curve unchanged. When I have simulated ROC curves under imbalance, I have gotten basically the same curves no matter the class ratio. Area under the ROC curve is related to Wilcoxon testing the two groups of predictions, and there is nothing inherently wrong with using a Wilcoxon test when the group sizes are uneven. Finally, Fawcet (2006) says that ROC curves are not sensitive to the class ratio (see the beginning of section 4.2 as well as figure 5). Despite this, data science seems to believe that ROC curves are problematic or illegitimate when the categories are imbalanced. Even Cross Validated and the Data Science Stack seem to give mixed results on this topic. The accepted answer here argues against ROC curves in imbalanced settings. Harrell's answer here argues that there is no issue. A post on data science argues that ROC curves are problematic in imbalanced settings, citing an ACM publication that states this. The accepted answer here says that the ROC curve does not depend on the class ratio but that PR curves may answer the more interesting questions. Have I missed something about why ROC curves are problematic when the classes are imbalanced? If my stance is correct that imbalance poses no problem for ROC curves, why does this misconception exist and persist? My guesses for why this misconception exists and persists (if it is a misconception) are: There is a general misunderstanding of class imbalance among practitioners, perhaps disliking the very real possibility of a high AUC yet all observations classified as the majority class according to the software-default argmax decision rule. Class imbalance is associated with issues that do degrade ROC curves, even if the imbalance isnâ€™t the direct cause. For instance, if imbalance leads to neural network optimization not converging like it would with balanced classes, there is a sub-optimal solution for the model parameters, leading to worse predictions (in some sense) and, perhaps, affecting the ROC curve. In this case, the ROC curve would be fine if we let the optimization run forever and reach the global minimum that we want it to reach, but we train our models in finite time and get predictions from those suboptimal models. REFERENCE Fawcett, Tom. "An introduction to ROC analysis." Pattern Recognition Letters 27.8 (2006): 861-874. EDIT I have found a few articles online about why ROC curves are problematic when there is imbalance. So far, they leave me with one of two thoughts. If you find ROC curves problematic in the imbalanced setting but fine in the balanced setting, you're using ROC curves in the balanced setting to tell you something that they do not claim to tell you. For instance, this article claims that precison-recall curves are more useful than ROC curves if you view your task as information retrieval. However, this is not a matter of class imbalance: if you want to view your task as selecting the $A$ s from a mix of $A$ s and $B$ s, then precision-recall curves might just be more informative. There are issues when the raw count of the minority class is small, not when there are just relatively few of one category vs the other. For instance, this article gives an example with just ten observations of the minority category, and this article says that "a small number of correct or incorrect predictions can result in a large change in the ROC Curve or ROC AUC score," the effect of which will be lessened by increasing the sample size. I could buy this as being an example of what I wrote earlier about the imbalance itself not being a problem but imbalanace being associated with a problem, in this case, a low count of minority-class observations.
