[site]: crossvalidated
[post_id]: 14954
[parent_id]: 14636
[tags]: 
One approach to choosing the cutoff value $\epsilon$ for ABC rejection sampling is the following (similar to Aniko's answer). Simulate several test data sets from known parameter values which are vaguely similar to your observed data (e.g. by performing ABC with a relatively large $\epsilon$). From the ABC output for a test data set, some criterion of performance compared to the true parameters can be calculated, such as mean squared error. Calculate this for all test data sets at many $\epsilon$ values, and choose $\epsilon$ to optimise the mean criterion (as this is a Monte Carlo estimate of its expectation). This requires many repetitions of the ABC algorithm, but can be done efficiently by using the same $N$ data simulations in every ABC algorithm (although this introduces some dependency between simulations). In general, there is not a lot of published work on the choice of $\epsilon$. I think the approach above has been used somewhere and I will edit if I remember the references. An alternative is in "Choosing the Summary Statistics and the Acceptance Rate in Approximate Bayesian Computation" by Michael Blum. Other methods that I'm aware of apply only to SMC or MCMC methods.
