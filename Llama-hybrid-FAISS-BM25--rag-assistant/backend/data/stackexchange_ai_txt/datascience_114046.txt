[site]: datascience
[post_id]: 114046
[parent_id]: 
[tags]: 
Different result of classification with same classifier and same input parameters

I did a binary classification using "Random Forest". The code block is clf = RandomForestClassifier() clf.fit(X_train, y_train) R_y_pred = clf.predict(X_test) print(classification_report(y_test, R_y_pred)) The result is precision recall f1-score support 0 0.91 0.98 0.94 1023 1 *0.79 0.48* 0.60 185 accuracy 0.90 1208 macro avg 0.85 0.73 0.77 1208 weighted avg 0.89 0.90 0.89 1208 When I apply clf.get_params() command to see the default parameters, I got {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False} Now in another code, I defined the criterion for RandomForestClassifier The code block is cri_clf = RandomForestClassifier(criterion = 'gini') cri_clf.fit(X_train, y_train) cri_y_pred = cri_clf.predict(X_test) print(classification_report(y_test, cri_y_pred)) The result is precision recall f1-score support 0 0.91 0.98 0.94 1023 1 *0.80 0.46* 0.59 185 accuracy 0.90 1208 macro avg 0.86 0.72 0.77 1208 weighted avg 0.89 0.90 0.89 1208 So, you can see that there is a slight difference in the result of precision and recall when I define a criterion explicitly with not defining a criterion. If all the parameters are the same for two codes why do I get the differences between the two results? Thank you.
