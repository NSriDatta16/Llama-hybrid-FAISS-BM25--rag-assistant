[site]: crossvalidated
[post_id]: 238831
[parent_id]: 
[tags]: 
Neural Network Ensemble Averaging

I have the following question: Assume I am given a function $f(x)$ that I want to do neural network regression on (for some subset of $x$), and further assume that I can get as many $(x,f(x))$ pairs as I want for training. Given that I train $N$ neural networks ($NN_i(x)$, $i=1,...,N$) independently using random initial weights and MSE as my loss, am I guaranteed that as $\underset{N \to \infty}{lim} ~ |f(x) - \frac{1}{N}\sum_i^N{NN_i(x)}| = 0 ~ ~ \forall x~ ~$? If yes, why? If not, what assumptions are necessary for the statement to hold? Thank you, Mr.Red EDIT: Maybe to make the answer more meaningful, let's assume f(x) is continuous and the nn is single layered with as many neurons as desired and training is done via some gradient descent method.
