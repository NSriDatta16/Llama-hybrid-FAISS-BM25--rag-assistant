[site]: crossvalidated
[post_id]: 625002
[parent_id]: 
[tags]: 
Why do we need the Markovian property in Markov chains Monte Carlo?

Adaptive Markov Chains Monte Carlo (MCMC), unlike traditional MCMC methods that rely on fixed proposal distributions, dynamically adjust their proposal distribution based on the information gathered during the sampling process. This adaptivity aims to improve the exploration of the state space (shorter mixing time), leading to faster convergence to the target probability distribution. Because of the proposal distribution optimization happening during the sampling, these chains are usually not Markovian. Under certain assumptions ( Diminishing Adaptation and Containment [1]) these chains are proven to be ergodic and the weak law of large numbers holds: $$\frac{\sum_{i=1}^n g(X_i)}{n} \rightarrow \pi(g)=\int g(x)\pi(dx) \qquad for \qquad n \rightarrow \infty$$ where $X_1, X_2, ..., X_n$ is a Markov chain samples sequence, $\pi$ is the target probability distribution, $g$ is a function $g:\chi \rightarrow \mathbb{R}$ and $\chi$ is the state space. My questions are: Is ergodicity , together with reversibility (the chain satisfies the detailed balance condition), sufficient conditions to ensure the convergence of the chain to the desired target probability distribution (the one satisfying the detailed balance), even if the chain is not Markovian? If the answer to the first question is yes, then why do we need the Markov property in MCMC? Is it a desirable property simply because it makes the theoretical analysis of MCMC easier? Or does it have any other purpose? [1] G.O. Roberts and J.S. Rosenthal. Coupling and ergodicity of adaptive Markov chain Monte Carlo algorithms. Journal of Applied Probability, 2007.
