[site]: crossvalidated
[post_id]: 611302
[parent_id]: 
[tags]: 
Python Statsmodel logit nan p-value (vs glm model)

I'm using Python statsmodel to do logistic regression. I'm trying out their glm(family=sm.families.Binomial()) and logit() models. Please correct me if I'm wrong but technically they should be the same model. Here are the full sample code for reference glm_model = sm.formula.glm("Y ~ X1 + X2 + ... + Xn", family=sm.families.Binomial(), data=df_train).fit() logit_model = sm.formula.logit("Y ~ X1 + X2 + ... + Xn", data=df_train).fit() So 2 things Why are the coefficients between the 2 models inverted? I assume the logit model one makes more sense (in the context of the training data), but I'm curious if there's an argument in the glm() function which I'm missing Why do some coefficients in the logit model have nan p-value while the glm model doesn't? Thanks for your help! I normally use R but I'm moving to Python now. If I replicate this in R it does mimic the result of the logit model here, but without nan p-values.
