[site]: crossvalidated
[post_id]: 612663
[parent_id]: 
[tags]: 
How are custom kernel functions in Gaussian processes statistically justified?

I am confused about one aspect of the use of Gaussian processes for Bayesian inference. I understand that it relies on the assumption that your train and test data points form a multivariate normal distribution where you define a prior mean and covariance for the distribution. What I don't understand is that I believed covariance had a strict statistical definition $\text{cov}(X, Y) = \mathbb{E}\left(X-\mu_X)(Y-\mu_Y)^\top\right)$ . How is it justified statistically to just use what seems like any old function we like? I am pretty new to this so would appreciate if anyone could direct me to good resources on the topic too.
