[site]: crossvalidated
[post_id]: 622270
[parent_id]: 
[tags]: 
What are more sophisticated measures for word similarity than cosine similarity?

I am trying to compute measures of word/sentence similarity from word embeddings that I would like to use for classification. However, cosine similarity often runs counter to how I as a human would judge word similarity. Are there any other, more sophisticated measures for word similarity? For example, I used Open AI embeddings (text-embedding-ada-002) and cosine similarity to find out which of the following three expressions is most similar to "meet a person": "meet a requirement" "visit Portugal" "visit grandma" The corresponding similarity values are highest for "meet a requirement" (0.8671411 vs. 0.7871252 and 0.8226740 for 2) and 3)) although I would argue that it describes quite a different concept, despite the word "meet". Chat GPT (which I assume uses similar word embeddings somewhere in its architecture) supports my view: The expression that is most similar to "meet a person" is "visit grandma." Both "meet a person" and "visit grandma" involve physically encountering or being in the presence of someone. In the case of "meet a person," it refers to meeting someone for the first time or having a face-to-face encounter with them. Similarly, "visit grandma" implies going to see one's grandmother in person. Both expressions involve a direct interpersonal interaction. On the other hand, "meet a requirement" and "visit Portugal" do not involve direct personal encounters with individuals. "Meet a requirement" is related to fulfilling a condition or expectation, and "visit Portugal" is about traveling to a specific country, not meeting a person. So I am wondering whether there is some measure that is more in line with Chat GPT's judgment but still computationally reproducible, like cosine similarity. I am equally grateful for any intuition why the embeddings do not seem to pick up the semantic differences in this case.
