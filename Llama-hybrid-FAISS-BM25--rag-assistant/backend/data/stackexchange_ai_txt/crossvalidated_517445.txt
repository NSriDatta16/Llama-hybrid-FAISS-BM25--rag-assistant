[site]: crossvalidated
[post_id]: 517445
[parent_id]: 517422
[tags]: 
If input data is not normalized (or standardized), it will not work in a Neural Network. This is actually a numerical problem, due to the gradient update but in general one has to normalize or standardize data when dealing with deep learning. So probably that it will work if you normalize your data and make the last layer a linear one rather than sigmoid. Even if your data does not fit in memory, you can find ways to normalize. If your input are images then you simply divide every pixel by 255.0. In keras you can do this using generator, you can find an exemple here: https://medium.com/@mrgarg.rajat/training-on-large-datasets-that-dont-fit-in-memory-in-keras-60a974785d71
