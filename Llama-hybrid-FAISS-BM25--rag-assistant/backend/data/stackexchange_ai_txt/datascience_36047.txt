[site]: datascience
[post_id]: 36047
[parent_id]: 
[tags]: 
Fill missing values AND normalise

I have two columns of training data for a neural net which are missing values. (There are many other columns which aren't missing values.) For example Height | Weight 180 | 70 175 | N/A N/A | N/A I want to fill missing values and normalise the columns. The data is heights and weights so I thought a good fill value would be 0 or -1. This is based on the book Deep Learning in Python : In general, with neural networks, it's safe to input missing values as 0, with the condition that 0 isn't already a meaningful value. EDIT I assumed 0 wasn't meaningful in a dataset with values from 150-200 I was also recommended to normalise the data by subtracting the mean and dividing by the std for each column. Both of those are fine on their own - I understand how and why to do them. What I don't get is how to combine them. I can either ... Fill missing values then normalise, but then a) my zeros will no longer be zeros (will my network still learn they are a special value?), and b) the zeros will affect the mean/std to a degree determine by how many values are missing. I suppose I'm concerned this would give a weird distribution Normalise then fill missing values. But after I've normalised my data, 0 is now the mean of my column and so isn't a fill value of the same kind. I'd rather let the network know the values are unfilled than assume they all take the mean value I'm using Keras, Numpy and Pandas with Dense layers for a multiclass classification problem.
