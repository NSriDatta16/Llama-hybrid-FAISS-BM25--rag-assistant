[site]: crossvalidated
[post_id]: 245946
[parent_id]: 245934
[tags]: 
Say that I want to train a CNN model that consists of $\sim1.5M$ hyperparameters (i.e., total number of filters weights and fully-connected layers coefficients) where the input layer is a $256\times256$ grayscale image. Filters weights and fully-connected layers coefficients are parameters, not hyperparameters. So I am wondering is there an exact minimum number of training images that I can use to claim that my model is not overfitting regardless whether I use dropout layers or not. To claim that my model is not overfitting, the typical way is to plot the performance of your network for the valid and train set vs. epoch number. See How to Identify Overfitting in Convolutional Neural network? and How few training examples is too few when training a neural network?
