[site]: crossvalidated
[post_id]: 539533
[parent_id]: 539529
[tags]: 
You need to distinguish between a hazard ratio and an absolute hazard. A hazard ratio needs a reference category: it's the ratio relative to some other situation. If weight had been coded as a continuous linear predictor in units of kg, the hazard ratio usually reported by software for weight would be the hazard ratio per 1 kg increase in weight. So you can't specify a hazard ratio for a 55-kg individual. The ratio has to be relative to some other value of weight. To calculate such a ratio, it's best to start with the Cox regression coefficient, the log-hazard change per 1 kg increase in weight (in the situation described in the previous paragraph). To estimate the hazard ratio between an individual of 55 kg versus an individual of 50 kg, take that coefficient, multiply it by the difference in kg (5 kg in this case), and then exponentiate to get the hazard ratio. If you want an absolute hazard, for example to get an estimated survival curve over time for a cohort of 55-kg individuals, you have to estimate the cumulative baseline hazard, multiply by the hazard ratio relative to those baseline conditions to get the estimated cumulative hazard $\hat H(t)$ , then use the formula $\hat S(t) = \exp(-\hat H(t))$ to get the estimated survival curve over time. This thread among others on this site shows how that is done. Software packages can differ in their choices of baseline conditions. Setting continuous predictors to values of 0 for the baseline can lead to numerical instability when actual values are far from 0, so a "typical" or "average" set of predictor values is used for the baseline. There is no general rule about that choice, so you have to read the manual.
