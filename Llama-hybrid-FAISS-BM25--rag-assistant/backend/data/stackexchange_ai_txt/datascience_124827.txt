[site]: datascience
[post_id]: 124827
[parent_id]: 
[tags]: 
Is it bad to average several MAEs calculated from chunks of a big test dataset?

In my regression problem, I am using Mean Absolute Error (MAE) as a metric for my network. My test dataset is too big to fit in memory, so I am reading the test dataset in chunks and then Keras' evaluate() the chunk. with pd.read_csv('test_data.csv', chunksize=chunk_size, sep=';') as reader: for chunk in reader: # get X and y from chunk loss, mae = model.evaluate(X, y) # ... Can I save the MAE from each chunk of data and then average them out to point out that this value is the MAE of my model? P.S. I understand I can use Keras' predict() to save the predictions and then calculate MAE myself, but I am curious about my original question.
