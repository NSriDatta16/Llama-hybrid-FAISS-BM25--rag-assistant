[site]: datascience
[post_id]: 11901
[parent_id]: 11812
[tags]: 
Apart from the approach @Rolf Schorpion mentioned, there are others. For example, you could use a deep neural network, specifically, an auto-encoder (see here for a tutorial). But there's an important catch to all purely "data-driven" approaches: if the figure of 30 time series you mention in the comments is a typical order of magnitude for your training set, the results will be more or less arbitrary. If you don't define "accordance" in any way, this is a classification problem with only positive training data which consists of 30 data points with more than 100 features each. Unless your data is very, very special (e.g., all time series are identical), there is just too much freedom in the solution of this problem. Different algorithms (or different parameter sets for the same algorithm) will use this freedom in very different ways. So you will probably see very different solutions when you experiment with different methods. So if you don't want to do more or less arbitrary experiments and choose from the solutions afterwards, you have to use a method in which you somehow define the meaning of "in accordance" in advance. You may try and use traditional time series techniques to find a common model that fits each of the time series well. You could then postulate that "accordance" is a good fit to this model. Or you might just do some exploratory analysis of your data to decide upon a simple rule which could be used to detect accordance. There's lots of possibilities, and without further details on the application it's difficult to decide which one is appropriate. Delegating the decision of what's "in accordance" to some algorithm doesn't seem to be a good choice in this case, though.
