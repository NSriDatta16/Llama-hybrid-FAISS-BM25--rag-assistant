[site]: crossvalidated
[post_id]: 618602
[parent_id]: 
[tags]: 
VAE with only forward diffusion enhancement ** experiment **

I wanted to get some opinions with an idea that I have explored for a little bit. This is an experiment and I would like to know if this is mathematically plausible or not. Imagine $\bar{x}$ is the reconstruction of $x$ in a typical vanilla VAE. Since the VAE output is considered lossy, we can assume that the pixels from a training data example $x$ at $t=0$ diffused into $\bar{x}$ at $t=T$ ; so we can say that there is some underlying diffusion between encoder and decoder. Lets say for example max T=1. There is diffusion mode called Ornsteinâ€“Uhlenbeck process which is considered mean reverting. This means that that the process will eventually go to the value of $\mu$ . The OU eq. is the following: $$ dx = -\theta(mu - x)dt + \sigma dw $$ Okay so in this setup - the forward pass is through the VAE, there is no reverse pass, however, we simultaneously train a neural network to learn the noise which would produce the mean of the OU-process and approximately the mean of the training data for each pixel. Here is the sudo code $ $ diffusion_steps(x0_bar, x_bar): for step in max_steps: diffusion_time = step + 1 # no zeros time_decay = exp^(-step / 2) # exp. decay // noise_nn - predicting noise noise = noise_nn([x0_bar, x_bar, diffusion_time]) // - predicted noise has to be such that // the diffusion converges to the mean // of training data (mean of each pixel) mu_bar = (x_bar - noise) # mu approx. alpha = mu_bar * (1 - time_decay) # drift beta = sigma * time_decay # diffusion dw = sqrt(dt) * normal(0, 1) dx_bar = (alpha * dt) + (sqrt(beta) * dw) x_bar = x_bar + dx_bar return x_bar // then loss function x_star = diffusion_steps(x0_bar, x_bar) diffusion_loss = mse(data, x_bar) Note thay I am not sure about the time decays but they seem to help. So the thought is that while we train the VAE, we also train the diffusion model to enhance the lossy output. For inference, one would sample from the latent space, pass through the decoder, and then through the diffusion for enhancement. The OU process seems somewhat mechanically analogous to the "reverse diffusion process" which should be called conditioned diffusion in my opinion. I have a working code but training is very slow - and honestly there are so many tricks that make the diffusions models work that I wouldn't even know if this was plausible or not. I hope someone can give me a deeper mathematical insight or suggest any improvements. If there are any ambiguities I can update my post.
