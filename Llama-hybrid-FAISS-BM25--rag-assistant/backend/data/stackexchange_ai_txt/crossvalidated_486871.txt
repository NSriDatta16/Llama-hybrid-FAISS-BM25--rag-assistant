[site]: crossvalidated
[post_id]: 486871
[parent_id]: 486602
[tags]: 
I think you have a minor confusion on Bayesian and Frequentist paradigms. The particular case you are referring to is inference over $\mu$ for $x_i \sim N( \mu , \sigma^2 )$ with $\sigma^2$ is known. In this case, which belongs to an example of conjugate families , the posterior mean ( $\mu_p$ ) from the posterior distribution becomes a convex combination between the prior mean and $\overline{x}$ (The MLE estimator) as a function of the prior variance $\sigma_{\mu}^2$ and the known variance $\sigma^2$ . This estimator has some cool asymptotic qualities, like when $n \longrightarrow \infty$ (all else the same) then $\mu_p \longrightarrow \overline{x}$ . To see the actual computations I recommend this paper . However this is not always the case for conjugate families, as posterior parameters do not behave as in the gaussian case. Additionally when using MCMC techniques we do not have a closed analytic form for the posterior parameters.
