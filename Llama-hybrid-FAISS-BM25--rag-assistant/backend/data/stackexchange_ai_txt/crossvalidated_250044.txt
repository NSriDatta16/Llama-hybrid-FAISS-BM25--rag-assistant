[site]: crossvalidated
[post_id]: 250044
[parent_id]: 250034
[tags]: 
The linear case has been extremely well studied in econometrics, and is known as an autoregressive model. This is probably the most highly developed sub-topic in terms of model estimation, and is typically expanded to include the ARIMA framework. For the nonlinear case, iterated nonlinear maps such as the logistic map have historically been popular in the " nonlinear dynamics/chaos " physics community, but to my knowledge most of these efforts use existing models (commonly "toy" heuristic models intended to distill known dynamics). There has been a bit of work on "attractor reconstruction" via delay-embedding , which can apply to arbitrary data (i.e. it is "model free"), but this has not developed very much in practical applications to my knowledge. For most of these classical approaches, the forward-model part is well summarized at Wikipedia here . One other branch of "classical" approaches is state space modeling , which has been highly developed in engineering and robotics, including recursive Bayesian estimation (Kalman/Particle filters) for data assimilation , feedback control , and system identification . These classical approaches have generally focused on estimation of a known (and commonly very sophisticated) model, rather than black box "machine learning". However the sub-field of Hidden Markov Models (HMMs) has perhaps more of a machine learning flavor, including estimation methods . Among newer "black box" techniques, Recurrent Neural Networks (RNNs) are fairly well developed. Recently the "deep" variants have shown very good results in diverse application domains, and are starting to displace some of the classical approaches such as HMMs (similar to ConvNets in Computer Vision).
