[site]: crossvalidated
[post_id]: 72473
[parent_id]: 72451
[tags]: 
It appears you are confusing results that hold for a collection of random variables with the case of one random variable. When you have a series of observations, $x_1,...,x_n$, then if they are contemporaneous , ($x_{1t},...,x_{nt}$) they are considered as realizations of n distinct random variables (that may be identically and independently distributed, or not). You cannot , in this case, assume that all are realizations of the same random variable, because a random variable is a real-valued function: this means that at a specific point in time, it can have only one realization (take one value), otherwise it wouldn't be a function but a correspondence: this is why when we have a cross-sectional sample of size $n$, we say that "it is comprised of the realization of $n$ random variables", and not "$n$ realizations of the same random variable". Note carefully that "same" does not just mean "identically distributed", but ontologically equal. Assume now that you have a time-series, and the index $1,...,n$ represents different points in time. Can you say that they are all realizations of the same random variable? Well in principle you can, but here too, we tend to view a time series as a stochastic process of distinct random variables (one for each point in time), that, again, may be identically distributed. So in general, when looking at a sample, be it cross-sectional or time series, it is advisable to think of it as a collection of realizations of many random variables. Now, when we subtract the mean from a random variable, and divide by the standard deviation, we create the "standardized" version of the variable, that has mean zero and variance (and standard deviation) unity. This is irrespective of the distribution that this variable follows, because, by standard universal properties of these distribution moments $$Z = \frac {X-\mu}{\sigma} \Rightarrow E(Z) = \frac {1}{\sigma}E(X) - \frac {\mu}{\sigma} = 0$$ and $$ \text {Var}(Z) = \text {Var}\left(\frac {X-\mu}{\sigma}\right) = \frac {1}{\sigma^2}\text {Var}(X) = \frac {\sigma^2}{\sigma^2} =1$$ The standardized version $Z$ of one random variable $X$ follows a distribution that belongs to the same family as the distribution of $X$, with different said parameters - the distribution family does not change. So if you don't know the distribution by other means, the distribution of the standardized version will remain unknown. Now consider the random variable $S_n = \frac 1n\sum_{i=1}^nX_i$. It is for this and like quantities that the various Central Limit Theorems talk about and tell that they approach a normal distribution asymptotically.
