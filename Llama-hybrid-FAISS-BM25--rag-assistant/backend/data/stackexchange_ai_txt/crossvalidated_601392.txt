[site]: crossvalidated
[post_id]: 601392
[parent_id]: 
[tags]: 
Standard error, standard deviation and error propagation

I measured a quantity 100 times to get 100 measurements denoted as $x_1$ , $x_2$ , ..., $x_{100}$ , with uncertainties as $e_1$ , $e_2$ , ..., $e_{100}$ . Now if I want to report the average of these 100 measurements, how should I report the uncertainty of this average value? I'm particularly confused as several ways seem reasonable to me. Method A: Report the sample standard deviation, namely, $\sigma_x=\sqrt{\frac{\sum_{i}(x_{i}-\bar{x})^2}{n-1}}$ , where $n$ is 100 since we have 100 measurements. Method B: Report the standard error of the mean, namely, $s=\sigma / \sqrt{n}$ , where $\sigma$ is the standard deviation of the distribution where the measurements were taken from. To my understanding, $\sigma$ here should be the population standard deviation, which is unknown in this case and should be estimated by the sample standard deviation, $\sigma_x$ . That is, the reported uncertainty should be $s\approx \sigma_x/\sqrt{n}=\sigma_x=\sqrt{\frac{\sum_{i}(x_{i}-\bar{x})^2}{n(n-1)}}$ Method C: Perform error propagation, namely, $\frac{1}{100}\sqrt{e_{1}^2 + e_{2}^2 + ... + e_{100}^2}$ . Which method is correct? Or actually, none of them is correct?
