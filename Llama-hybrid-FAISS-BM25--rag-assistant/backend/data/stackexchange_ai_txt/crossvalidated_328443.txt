[site]: crossvalidated
[post_id]: 328443
[parent_id]: 
[tags]: 
Choosing, evaluating, and reporting data imputation

I have read about model checking for multiple imputation MI ( https://ete-online.biomedcentral.com/articles/10.1186/s12982-017-0062-6 ), but I am not sure how one can check their model for a general imputation using random forests, hotdeck... More generally, when imputing data, how do researchers decide the best imputation model to use, how do they evaluate that model, and how do they report it in literature? I suppose one way is to try out multiple methods, and use whichever one leads to the lowest Cross validation CV error (or whatever other metric). Is it then necessary to say in a paper for example, MICE led to the lowest CV error of x% so we used MICE to impute our data. Please provide official sources I can reference for your answers. If you link a large book on data imputation, cite specific pages that target my questions. (I have seen a lot of sources on data imputation, R examples, but had trouble finding sections that target my questions related to choosing, evaluating, and reporting)
