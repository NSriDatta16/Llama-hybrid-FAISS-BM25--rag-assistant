[site]: crossvalidated
[post_id]: 449692
[parent_id]: 
[tags]: 
How can I separate the common from the idiosyncratic in a related group of time series?

Strictly by coincidence, I have two problems at the moment with quite similar structure, though they arise in very different settings. I suspect this is a well-known problem with a named solution, but I have not previously encountered it. In both problems, I have a number of time series. Each time series is composed of two components, one that is shared by all the series, and the other idiosyncratic to each individual series Both the common and the idiosyncratic factors have errors with time series structure â€“ minimally autocorrelation, and perhaps a full ARIMA or ARFIMA error process. My first concrete problem is constructing a daily GDP price deflator. Major price deflators are issued quarterly, with corrections continuing for another three to six months, so the lag can be substantial. The goal here is to construct a daily deflator based on daily data, specifically the exchange rates for the currency in question with each of a group of major trading partners. The idea is to treat the common component of the of the change over time of each individual series as the value of the common currency. (I think that, incidentally, you need to estimate the time series aspects of the error process on the common and the idiosyncratic errors). The observed value in each series is the ratio of the common currency with the individual currencies, where the levels are not (meaningfully) observed. The observed values are linear in the (unobserved) logs of the common and the individual currencies. The second problem has almost the same structure though it arises in a very different context. We have a sealed container full of a murky, turbulent fluid with a complex internal structure and an evolving chemical composition. Among the chemicals in the fluid with a time-varying concentration is substance X. X efficiently absorbs light of a certain precise frequency Y. We wish to know the concentration of X in a particular physical location, and how that concentration evolves over time.. We shine 3 (or more) beams of light of frequency Y through the container so that each passes through our area of interest to a sensor on the opposite side. The light is sampled at a rate which is high enough to preclude discontinuous changes in the concentration of X, in both the area of interest and in the remainder of each beam. Thus, with appropriate scaling of time, those changes will have errors with time series characteristics. Absorption in each beam (observed) is linear in absorption within the common area of interest (unobserved) plus absorption in the rest of the beam (unobserved). If it was not for the time series features on the errors, I believe both of these problems could be modeled as straight factor analysis. But I think the time series features here can not be dispensed with. One more observation about these problems. Neither the common nor the individual factors can be taken as any linear combination of the individual series. Consider this example: out of ten series, nine make a sudden large jump, while one does not. Now it could be that all nine coincidentally made idiosyncratic jumps, so that only the tenth represents the true, stable value of the common factor. But it is more likely in such a case that the simultaneous changes represent a change in the shared factor. But this is true for any nine series that jump vs one that does not, symmetrically. So there is no single weighting that can capture the division across all cases. The weighting on the common factor increases with the covariance of the innovation.
