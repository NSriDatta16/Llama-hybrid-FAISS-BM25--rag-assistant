[site]: datascience
[post_id]: 54219
[parent_id]: 54210
[tags]: 
What you want to do to boost the performance of one of your classes is to add class weights to your loss function. This will essentially tell your network to pay more attention to some classes (note that this might deteriorate performance on the rest of the classes). How to compute the weights. To see what weight you'll give to each class you can either put it yourself or you can let scikit-learn help you. The problem is that your data is imbalanced . This means that you have much more samples in class 2 than you have in classes 0, 1 and 3. Through the use of class weights you can make it so that your model pays more attention to the under-represented classes, so that they appear balanced. Scikit-learn has a function that calculates what weights you should give each sample. from sklearn.utils.class_weight import compute_class_weight weight_array = compute_class_weight('balanced', np.unique(y) y) # y is the array containing your labels weight_dict = dict(zip(np.unique(y), weight_array)) # dictionary containing your weights Keras In keras you can also add class weights in the fit method (which trains the model). This is easier as you just need to pass a dictionary with the weight of each class (i.e. what we calculated previously) model.fit(X_train, y_train, class_weight=weight_dict, ...) TensorFlow In TensorFlow you can do this simply by using this softmax_cross_entropy loss instead of the one you are currently using. This supports class weights ( weights attribute). This requires you to pass a Tensor with a shape of (batch_size,) where its elements are the weight you want to pass to each sample. What you need to do is to see what samples batch_y has and give them the respective weight! batch_weights = [weight_dict(x) for x in batch_y] # assuming that your batch_y is a numpy array that is not one-hot encoded # if it is one-hot encoded: batch_weights = [weight_dict(x) for x in np.argmax(batch_y, axis=1)] # assuming batch y is a numpy array # if batch_y is not a numpy array you need to get it through batch_y_arr = sess.run(batch_y) Then pass the batch_weights to the weights attribute of the loss (through a placeholder using the feed_dict - like you do with batch_x and batch_y )
