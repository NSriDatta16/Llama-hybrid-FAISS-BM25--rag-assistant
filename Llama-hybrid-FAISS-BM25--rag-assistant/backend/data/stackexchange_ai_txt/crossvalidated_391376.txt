[site]: crossvalidated
[post_id]: 391376
[parent_id]: 
[tags]: 
Error on mean from measurements made from a distribution with a possible long tail

I am using Langevin dynamics simulations to measure a first hitting time of particles leaving a region in parameter space. I would like to measure the mean first hitting time (and not the median for example) because after making some simplifying assumptions, I can calculate the mean of the first hitting time explicitly (but not the whole distribution), and want to compare this with data to test whether those simplifying assumptions put me in the right ball park. My problem is that the mean first hitting time measured from my simulation seems to increase with the time that I run for (more time means more trajectories/samples used in calculating this mean). Between a run of length $T$ and a run of length $\sim 1.2T$ , the mean increased by more than 3 standard errors. A similar increase exists between a run of length $\sim 0.8T$ and $T$ . So the tail of the empirical distribution seems to affect the mean, and there seems to be a systematic underestimation of both the mean and the standard error, which made me wonder about a long tailed distribution. However theoretically it is impossible for a set of non-zero measure of trajectories to remain inside the region forever, therefore the mean time of exit must be finite. The histogram of my current samples looks like this, the average is ~1.4: I am limited in computational power as to how long I can run my simulation for. I expect that if I were to continue to run my simulations, the mean would eventually asymptotically reach some value, however this is not yet visible from my current samples. Given the data that I have, is there a way to generate the confidence intervals on my current mean to ensure that this asymptotic value is included in the interval? A few more details about the simulation/system: The region the particles are escaping from is inhomogenous and has other occupants, so theoretically it is a black box where not much can be done theoretically other than the few simplifying assumptions I am trying to test out. Multiple particles are escaping at the same time, however they interact minimally with each other and their density inside the region is low, so low chances of encountering another particle. Therefore the exit times of two particles is not exactly independent, but any correlations between the times of two particles will be extremely weak. The system is also at steady state, so on average there is the same number of particles inside the region for all times.
