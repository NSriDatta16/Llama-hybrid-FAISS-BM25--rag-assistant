[site]: datascience
[post_id]: 109391
[parent_id]: 
[tags]: 
Which is the difference between the two Greek BERT models?

I want to use the Greek BERT which can be found here https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1 However I am confused about which model should I use and which are the differences. The tokenizer is the same tokenizer = AutoTokenizer.from_pretrained('nlpaueb/bert-base-greek-uncased-v1') but we have two models model = AutoModel.from_pretrained("nlpaueb/bert-base-greek-uncased-v1") model = AutoModelWithLMHead.from_pretrained("nlpaueb/bert-base-greek-uncased-v1") Which one should I use?
