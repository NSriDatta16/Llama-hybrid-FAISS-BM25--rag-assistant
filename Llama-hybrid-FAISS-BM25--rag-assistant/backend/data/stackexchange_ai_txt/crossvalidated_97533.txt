[site]: crossvalidated
[post_id]: 97533
[parent_id]: 97515
[tags]: 
I cannot explain the meaning of the quotation, but for maximum-likelihood estimation, it does not matter whether we choose to find the maximum of the likelihood function $L(\mathbf x; \theta)$ (regarded as a function of $\theta$ or the maximum of $aL(\mathbf x; \theta)$ where $a$ is some constant. This is because we are not interested in the maximum value of $L(\mathbf x; \theta)$ but rather the value $\theta_{\text{ML}}$ where this maximum occurs, and both $L(\mathbf x; \theta)$ and $aL(\mathbf x; \theta)$ achieve their maximum value at the same $\theta_{\text{ML}}$. So, multiplicative constants can be ignored. Similarly, we could choose to consider any monotone function $g(\cdot)$ (such as the logarithm) of the likelihood function $L(\mathbf x; \theta)$, determine the maximum of $g(L(\mathbf x;\theta))$, and infer the value of $\theta_{\text{ML}}$ from this. For the logarithm, the multipliative constant $a$ becomes the additive constant $\ln(a)$ and this too can be ignored in the process of finding the location of the maximum: $\ln(a)+\ln(L(\mathbf x; \theta)$ is maximized at the same point as $\ln(L(\mathbf x; \theta)$. Turning to maximum a posteriori probability (MAP) estimation, $\theta$ is regarded as a realization of a random variable $\Theta$ with a priori density function $f_{\Theta}(\theta)$, the data $\mathbf x$ is regarded as a realization of a random variable $\mathbf X$, and the likelihood function is considered to be the value of the conditional density $f_{\mathbf X\mid \Theta}(\mathbf x\mid \Theta=\theta)$ of $\mathbf X$ conditioned on $\Theta = \theta$; said conditional density function being evaluated at $\mathbf x$. The a posteriori density of $\Theta$ is $$f_{\Theta\mid \mathbf X}(\theta \mid \mathbf x) = \frac{f_{\mathbf X\mid \Theta}(\mathbf x\mid \Theta=\theta)f_\Theta(\theta)}{f_{\mathbf X}(\mathbf x)} \tag{1}$$ in which we recognize the numerator as the joint density $f_{\mathbf X, \Theta}(\mathbf x, \theta)$ of the data and the parameter being estimated. The point $\theta_{\text{MAP}}$ where $f_{\Theta\mid \mathbf X}(\theta \mid \mathbf x)$ attains its maximum value is the MAP estimate of $\theta$, and, using the same arguments as in the paragraph, we see that we can ignore $[f_{\mathbf X}(\mathbf x)]^{-1}$ on the right side of $(1)$ as a multiplicative constant just as we can ignore multiplicative constants in both $f_{\mathbf X\mid \Theta}(\mathbf x\mid \Theta=\theta)$ and in $f_\Theta(\theta)$. Similarly when log-likelihoods are being used, we can ignore additive constants.
