[site]: crossvalidated
[post_id]: 58381
[parent_id]: 
[tags]: 
Mathematically modeling neural networks as graphical models

I am struggling to make the mathematical connection between a neural network and a graphical model. In graphical models the idea is simple: the probability distribution factorizes according to the cliques in the graph, with the potentials usually being of the exponential family. Is there an equivalent reasoning for a neural network? Can one express the probability distribution over the units (variables) in a Restricted Boltzmann machine or a CNN as a function of their energy, or the product of the energies between units? Also, is the probability distribution modelled by an RBM or Deep belief network (e.g. with CNNs) of the exponential family? I am hoping to find a text that formalizes the connection between these modern types of neural networks and statistics in the same way that Jordan & Wainwright did for graphical models with their Graphical Models, Exponential Families and Variational Inference . Any pointers would be great.
