[site]: datascience
[post_id]: 53916
[parent_id]: 
[tags]: 
Principal component analysis

I have a data set that looks like the following: Time V1 V2 V3 ... V40 13:00 0.44 0 0.33 0.55 13:01 0.55 0 0.34 0.52 13:02 0.58 1 0.20 0.58 . . . 15:01 0.57 0 0.24 0.70 Where V2 is the binary equivalent of on/off switches. Currently, I am still pre-processing my data and normalized the data-set from (0,1) using sklearn.preprocessing . I am wondering if applying dimensionality reduction/PCA to my dataset will affect the outcome of my model and whether if it is advisable to use it to process my data.
