[site]: crossvalidated
[post_id]: 292759
[parent_id]: 
[tags]: 
Maximum Likelihood: Two alternating Markov processes

I have a time series of discrete observations $X_s$. In total there are N observations. I have some assumption about the underlying data-generating process (it is a Markov process) and thus I know the density of the model $f(X_{s+1}|X_s,\theta)$ for model parameters $\theta$. Actually, I assume that there are two different processes with different parameters $\theta_1$ and $\theta_2$ such I have the densities $f(X_{s+1}|X_s,\theta_1)$ and $f(X_{s+1}|X_s,\theta_2)$. I assume that both processes take turns such that in some periods, the first process generates the data and in other periods the second one does it (I have concrete assumptions about when this should happen; sometimes a direct alternation is possible). I want to estimate the parameters $\theta_1$ and $\theta_2$ via maximum likelihood. My idea therefore is: $$ \max \sum_{s=1}^{i=N} \log f(X_{s+1}|X_s,\theta) = \max \left[\sum_{i \in Q_1} \log f(X_{i+1}|X_i,\theta_1) + \sum_{j \in Q_2} \log f(X_{j+1}|X_j,\theta_2)\right]$$ where $Q_1$ and $Q_2$ are disjunct subsets of {1,...,N}. To get the parameters, I now maximize $$\max \sum_{i \in Q_1} \log f(X_{i+1}|X_i,\theta_1)$$ and $$\max \sum_{j \in Q_2} \log f(X_{j+1}|X_j,\theta_2)$$ separately such that I obtain $\theta_1$ and $\theta_2$. Is my proceeding sensible and mathematically correct? Or do I harm some preconditions? Thank you very much for your answer!
