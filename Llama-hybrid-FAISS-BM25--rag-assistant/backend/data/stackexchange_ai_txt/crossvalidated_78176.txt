[site]: crossvalidated
[post_id]: 78176
[parent_id]: 78152
[tags]: 
I assume the $n$ predictions refer to the same target, a binare variable $Y \in \{0,1\}$ , and your goal is to merge it into a single prediction. Note that the $p_i$ s are (Bernoulli) distributions. The stats literature knows many ways of aggregating a set of $n$ distributions into a single ("conensus") one, see e.g. Link Taking the mean prediction is called a linear prediction pool (LOP). The mean and variance of the LOP are as follows ( http://en.wikipedia.org/wiki/Mixture_distribution ): Mean = $p_c = \sum_{i=1}^n \omega_i p_i,$ Variance = $\sigma^2_c = \sum_{i=1}^n \omega_i \sigma^2_i + \sum_{i=1}^n \omega_i (p_i-p_c)^2,$ where the $\omega_i$ s are the weights for each model (required to be nonnegative and sum to one), and $\sigma_i^2 = p_i(1-p_i)$ is the variance of prediction $i$ . Intuitively, the first sumand for the variance term reflects the average variance, whilst the second term is the disagreement among the $n$ individual forecasts. Both contribute to the uncertainty of the combined forecast.
