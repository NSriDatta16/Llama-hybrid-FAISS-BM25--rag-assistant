[site]: crossvalidated
[post_id]: 193811
[parent_id]: 193805
[tags]: 
In R, this is your dataset: > dataset Each of your user_id s is a member of one or more classes. So just create dummy variables for all possible classes and put in a 1 (or TRUE) if that user_id is a member of that class. Again in R: > foo bar dataset.new dataset.new target user_id value1 category Ab Be Ck Ju Po 1 0 1 .425 Ab|Be 1 1 0 0 0 2 0 2 .325 Ab 1 0 0 0 0 3 1 3 .26 Ab|Ck 1 0 1 0 0 4 1 4 .28 Be|Ck|Ju|Po 0 1 1 1 1 5 0 5 .56 Ab|Ck 1 0 1 0 0 6 1 6 .25 Ck 0 0 1 0 0 Now you can start classifiying, including membership in the various classes (and value1 ) as predictors. (Make sure your 0-1 target is interpreted as class memberships, not numerics.) > dataset.new$target library(randomForest) > model model Call: randomForest(formula = target ~ value1 + Ab + Be + Ck + Ju + Po, data = dataset.new) Type of random forest: classification Number of trees: 500 No. of variables tried at each split: 2 OOB estimate of error rate: 50% Confusion matrix: 0 1 class.error 0 3 0 0 1 3 0 1 > model$importance MeanDecreaseGini value1 1.05986667 Ab 0.47546667 Be 0.11180000 Ck 0.45940000 Ju 0.09733333 Po 0.10820000
