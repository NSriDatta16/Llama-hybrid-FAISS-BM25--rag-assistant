[site]: datascience
[post_id]: 126645
[parent_id]: 
[tags]: 
Anomaly Detection in Log Data using LSTM

Problem Overview: I am currently working on a project involving anomaly detection in log data. The anomalies are defined by deviations from historical patterns. The log data has a simple structure: [timestamp: log_statement] . Dataset Details: The dataset consists of logs in the format [timestamp: log_statement] and have 10k+ logs Each log_statement has been processed to generate keys (k1, k2, ...) for uniqueness after that it became 200-250 unique keys. Current Approach: I have preprocessed the log data to extract log statements and assigned unique keys to them. Utilized LSTM for training with a window-based approach, considering past logs for predictions (similar to next word prediction by looking past words). Anomalies are detected by comparing predicted and actual log statements within the specified window. Specific Questions: Is the current approach suitable for capturing temporal patterns in log data, am I right converting each log_statement to keys: k1,k2..etc ? How can I ensure that the LSTM model is effectively learning and representing the patterns? Are there alternative methods, either statistical, machine learning-based, deep-learning based, that might offer better results and more interpretable ? Also are there any ways, where I can tell after training that I am confident about these keys(say k1,k2) these are predictable and rest are not. I thought to compare True positive and True negative of each key, but it will heavily dependent on the model.
