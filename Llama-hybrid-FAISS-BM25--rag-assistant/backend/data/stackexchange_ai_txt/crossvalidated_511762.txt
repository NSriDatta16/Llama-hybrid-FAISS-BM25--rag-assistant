[site]: crossvalidated
[post_id]: 511762
[parent_id]: 
[tags]: 
ARIMA variance of the residual values estimation in Python

I'm trying to estimate the variance of the error term in the best ARIMA(p,0,q) -- I'm making the hypotesis that my time series is stationary -- with 'statsmodels.tsa.arima.model' command in Python. After running from statsmodels.tsa.stattools import arma_order_select_ic res1 = arma_order_select_ic(data_frame, max_ar = 5, max_ma = 5, ic = ['bic'], fit_kw={'method':'css-mle'}, trend = 'c' ) I get that ARIMA(4,0,0) is the best one, and then, I run the following code: from statsmodels.tsa.arima.model import ARIMA model = ARIMA(data_frame, order = (res1.bic_min_order[0], 0, res1.bic_min_order[1]) ) res = model.fit() My main goal here is try to estimate $\hat{\sigma}_{\varepsilon}^2$ from : $$y_t = \alpha + \phi_1 y_{t-1} + \phi_2 y_{t-2}+ \phi_3 y_{t-3}+ \phi_4 y_{t-4} + \varepsilon_t \qquad \varepsilon_t \sim iidN(0, \sigma_{\varepsilon}^2) \quad \forall t$$ And as far as understood, the coefficient 'sigma2' would give me this estimative (according to this https://stackoverflow.com/questions/56817200/python-arima-output-interpreting-sigma2 ). SARIMAX Results ============================================================================== Dep. Variable: cons_pcapta No. Observations: 6 Model: ARIMA(4, 0, 0) Log Likelihood 20.365 Date: Mon, 01 Mar 2021 AIC -28.729 Time: 13:06:42 BIC -29.979 Sample: 0 HQIC -33.731 - 6 Covariance Type: opg ============================================================================== coef std err z P>|z| [0.025 0.975] ------------------------------------------------------------------------------ const -0.0013 0.003 -0.422 0.673 -0.007 0.005 ar.L1 0.1244 0.305 0.408 0.683 -0.473 0.722 ar.L2 -0.7638 0.331 -2.304 0.021 -1.413 -0.114 ar.L3 0.1433 0.294 0.488 0.626 -0.432 0.719 ar.L4 -0.9818 0.028 -34.577 0.000 -1.037 -0.926 sigma2 1.551e-06 3.77e-06 0.411 0.681 -5.85e-06 8.95e-06 =================================================================================== Ljung-Box (L1) (Q): 0.43 Jarque-Bera (JB): 2.65 Prob(Q): 0.51 Prob(JB): 0.27 Heteroskedasticity (H): 0.09 Skew: -1.58 Prob(H) (two-sided): 0.17 Kurtosis: 3.83 But trying to confirm it (mainly because I think it is a low value), I tried to estimate this variance by hand using $$\hat{\sigma}_{\varepsilon}^2 = \frac{\sum_{t=0}^{N-1}( y_t-\hat{y_t} )^2}{N-5}$$ wich gives me sum( (newdf - res.predict())**2 )/(len(newdf) - 5) Out[26]: 0.0014486559274494817 A quite different value. I know that in statsmodel the parameter estimation is made by state space representation (using Kalman Filter, I guess -- https://www.statsmodels.org/stable/statespace.html ), but the results for $\hat{\sigma}_{\varepsilon}^2$ shouldn't be closer at least? Thanks in advace
