[site]: crossvalidated
[post_id]: 171691
[parent_id]: 
[tags]: 
Too many variables in logistic regression makes it a poor model?

Sorry, I am new to everything, so any and all answers would be very helpful, just to help guide me in the right direction for reading. I have a table of 20 independent variables (17 binary, 3 continuous) with a binary dependent outcome. I have ~600 observation subjects, each with these 20 independent variables and 1 dependent variable. In total, for my dependent variable I have 37 events with "poor signal" presumably caused by the 20 variables prior. I already calculated each categorical data with chisquare and odds ratios with a 2 x 2 table. Many of my variables showed significance by itself in these calculations. I wanted to assess the effects of these variables on the outcomes when combined. Therefore, I applied the logit regression via glm command in R. When I do my calculations, say for just gender, I get: Gender1 Estimate 0.9433 Std Error 0.3692 Z-value 2.555 Pr(>|z|) 0.0106 * which actually equals to the same P-value I calculated for odds-ratio for Gender. I do this, because I have a lot of NA values for certain variables, and wanted to make sure the calculation was okay. However, when I start adding multiple variables together, what was once significant started to become insignificant. Also, what once was correlated with a poor signal (dependent variable), was now correlated with a good signal. In otherwords, a positive Estimation becomes a negative Estimate (which I assume are the regression coefficients). So, my question is how do I optimize this model? How do I choose which variables to include because including all 20 is not helpful. I read somewhere about "LASSO". Is this something that applies here? Thanks Edit: Also, is this something I should be using Breslow-Day test for homogenity? Or stepwise regression?
