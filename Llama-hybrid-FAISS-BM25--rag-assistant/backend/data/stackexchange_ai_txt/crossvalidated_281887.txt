[site]: crossvalidated
[post_id]: 281887
[parent_id]: 
[tags]: 
If softmax is used as an activation function for output layer, must the number of nodes in the last hidden layer equal the number of output nodes?

Let us assume that I have the following neural network architecture: Input-Layer: 12 nodes 1st Hidden Layer: 9 nodes 2nd Hidden Layer: 6 nodes Output Layer: 3 nodes Can I use Softmax activation function on the output layer for the above architecture? If so, how? Because, in the Softmax formula how will I get the numerator properly if the number of nodes in the last hidden layer and the output layer are not same? In the architecture above, I will get 6 weighted inputs $(x_i)$ at the output layer. Then the softmax output for $j$th output node is: $$\frac{e^{x_j}}{S}$$, where, $$S=\sum{e^{x_i}}$$ But this will only work if the range of $i$ and $j$ are same. That is only possible if the last hidden layer and the output layer have the same number of nodes. Have I understood this correctly?
