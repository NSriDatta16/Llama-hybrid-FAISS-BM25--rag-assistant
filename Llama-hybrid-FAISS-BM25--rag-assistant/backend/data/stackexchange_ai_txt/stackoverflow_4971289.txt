[site]: stackoverflow
[post_id]: 4971289
[parent_id]: 4971156
[tags]: 
The multiply by 100, divide by 100 solution is right. But this can end up with deceiving results because of the nature of floating-point datatypes. Nice round numbers in base-10, like "1.23" do not always translate to the base-2 floating point storage format. So you may find that rounding "1.2345" ends up as "1.23" as expected, but "1.1234" will end up as "1.11989589285982959295892859289582958295" or something crazy. For this reason, if this kind of accuracy is important - especially if you are using these rounded numbers in any calculation, then you should consider operating in integers. For example, when working with money, developers often work in cents instead of dollars. So, "$1.75" is represented as "175". This guarantees accuracy to the cent. Only divide by 100 when you want to display it to the user then.
