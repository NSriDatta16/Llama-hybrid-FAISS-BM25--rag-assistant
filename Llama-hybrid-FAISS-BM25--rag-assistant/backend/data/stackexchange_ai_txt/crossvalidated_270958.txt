[site]: crossvalidated
[post_id]: 270958
[parent_id]: 
[tags]: 
Why StackingRegressor doesn't catch the trend?

I just reviewed very good example of fitting StackingRegressor from mlxtend package. from mlxtend.regressor import StackingRegressor from sklearn.linear_model import LinearRegression from sklearn.linear_model import Ridge from sklearn.svm import SVR import matplotlib.pyplot as plt import numpy as np # Generating a sample dataset np.random.seed(1) X = np.sort(5 * np.random.rand(40, 1), axis=0) y = np.sin(X).ravel() y[::5] += 3 * (0.5 - np.random.rand(8)) # Initializing models lr = LinearRegression() svr_lin = SVR(kernel='linear') ridge = Ridge(random_state=1) svr_rbf = SVR(kernel='rbf') stregr = StackingRegressor(regressors=[svr_lin, lr, ridge], meta_regressor=svr_rbf) # Training the stacking regressor stregr.fit(X, y) stregr.predict(X) # Evaluate and visualize the fit print("Mean Squared Error: %.4f" % np.mean((stregr.predict(X) - y) ** 2)) print('Variance Score: %.4f' % stregr.score(X, y)) with plt.style.context(('seaborn-whitegrid')): plt.scatter(X, y, c='lightgray') plt.plot(X, stregr.predict(X), c='darkgreen', lw=2) plt.show() But, when I changed one line of generating the dataset, like: y = np.sin(X).ravel() * np.cos(X).ravel() I got totally bad fit of the StackerRegressor. Please don't block that question and help me to understand. Thank you!
