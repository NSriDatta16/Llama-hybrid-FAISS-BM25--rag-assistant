[site]: crossvalidated
[post_id]: 113863
[parent_id]: 46780
[tags]: 
Variable Importance Measures (VIMs) from Random Forests might be what you are looking for. A brief overview over two of these is given in a paper Overview of Random Forest Methodology and Practical Guidance with Emphasis on Computational Biology and Bioinformatics by Boulesteix et al. The idea for the Gini VIM is that you get some statistics of how often a random forest has made use of a certain attribute as the splitting criterion. Informative features are chosen more often here. The permutation VIM is based on the idea that the error-estimates of the RF-classifier are compared between the original dataset and an artificial dataset where values for ONE attribute have been permuted. The resulting error-estimate-difference will be big for important features. As far as I remember, VIMs can also be used to discover dependencies between features.
