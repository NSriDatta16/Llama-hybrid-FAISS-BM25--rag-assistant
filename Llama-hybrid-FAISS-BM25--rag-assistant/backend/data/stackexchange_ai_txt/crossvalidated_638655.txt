[site]: crossvalidated
[post_id]: 638655
[parent_id]: 637986
[tags]: 
I can show you how to derive the discrete-space result, and the extension to the continuous-space result is essentially a limiting version of this. Distribution of absorption time: The formula you give in your question is for the discrete phase-type distribution corresponding to a Markov chain with a finite number of states and an absorbing state. Without further loss of generality, suppose we have $n$ states in the Markov chain with a single absorbing state (so $n-1$ transient states). Varying your notation slightly, we can write the $n \times n$ transition probability matrix for such a chain as: $$\mathbf{p} = \begin{bmatrix} \mathbf{T} & \mathbf{T}_0 \\ \mathbf{0}^\text{T} & 1 \end{bmatrix} = \begin{bmatrix} \mathbf{T} & (\mathbf{I}-\mathbf{T}) \mathbf{1} \\ \mathbf{0}^\text{T} & 1 \end{bmatrix},$$ where $\mathbf{T}$ is the $(n-1) \times (n-1)$ upper-left block for the transition probabilities between the transient states and $\mathbf{0}$ and $\mathbf{1}$ are $(n-1) \times 1$ column-vectors of zeroes and ones respectively. (The remaining vector $\mathbf{T}_0 \equiv (\mathbf{I}-\mathbf{T}) \mathbf{1}$ is the $(n-1) \times 1$ upper-right block for the transition probabilities from the transient states to the absorbing state.) You can see from this form of transition matrix that the first $n-1$ states are the transient states and the last state is the absorbing state. Suppose we let $X_t$ denote the state of the Markov chain at time $t=0,1,2,...$ . As is standard in Markov chain analysis, we can use the law of total probability to write the relevant multi-step transition probabilities in terms of the powers of the transition probability matrix, which are given by: $$\begin{align} \mathbf{p}^k &= \begin{bmatrix} \mathbf{T} & (\mathbf{I}-\mathbf{T}) \mathbf{1} \\ \mathbf{0}^\text{T} & 1 \end{bmatrix}^k \\[6pt] &= \begin{bmatrix} \mathbf{T}^k & (\mathbf{I}-\mathbf{T}^k) \mathbf{1} \\ \mathbf{0}^\text{T} & 1 \end{bmatrix}. \\[6pt] \end{align}$$ Suppose we denote the initial probabilities for the transient states of the chain as the row vector $\boldsymbol{\tau} = [\tau_1,...,\tau_{n-1}]$ where $\tau_i \equiv \mathbb{P}(X_0 = i)$ , and we then have the full initial probability vector: $$\boldsymbol{\tau}_* = \begin{bmatrix} \boldsymbol{\tau} & & 1- \boldsymbol{\tau} \mathbf{1} \end{bmatrix}$$ We can use the law of total probability to get the marginal state probabilities: $$\begin{align} \begin{bmatrix} \mathbb{P}(X_{k} = 1) & \cdots & \mathbb{P}(X_{k} = n) \end{bmatrix} &= \sum_{i=1}^n \mathbb{P}(X_{k} = j| X_0 = i) \cdot \mathbb{P}(X_0 = i) \\[6pt] &= \begin{bmatrix} \boldsymbol{\tau} & & 1- \boldsymbol{\tau} \mathbf{1} \end{bmatrix} \begin{bmatrix} \mathbf{T}^k & (\mathbf{I}-\mathbf{T}^k) \mathbf{1} \\ \mathbf{0}^\text{T} & 1 \end{bmatrix} \\[6pt] &= \begin{bmatrix} \boldsymbol{\tau} \mathbf{T}^k & & \boldsymbol{\tau} (\mathbf{I}-\mathbf{T}^k) \mathbf{1} + (1- \boldsymbol{\tau} \mathbf{1}) \end{bmatrix} \\[12pt] &= \begin{bmatrix} \boldsymbol{\tau} \mathbf{T}^k & & \boldsymbol{\tau} \mathbf{1} - \boldsymbol{\tau} \mathbf{T}^k \mathbf{1} + 1- \boldsymbol{\tau} \mathbf{1} \end{bmatrix} \\[12pt] &= \begin{bmatrix} \boldsymbol{\tau} \mathbf{T}^k & & 1 - \boldsymbol{\tau} \mathbf{T}^k \mathbf{1} \end{bmatrix} \\[6pt] \end{align}$$ In particular, the probability that absorption has occurred is: $$\mathbb{P}(X_{k} = n) = 1 - \boldsymbol{\tau} \mathbf{T}^k \mathbf{1}.$$ Now, the absorption time for the Markov chain is the hitting time for the absorbing state $n$ , which we can denote as $K = \min \{ k =0,1,2,... | X_k = n \}$ . We can easily establish the following logical equivalence: $$X_k = n \quad \quad \iff \quad \quad K \leqslant k.$$ Using the initial probability vector we have $\mathbb{P}(K = 0) = 1- \boldsymbol{\tau} \mathbf{1}$ which is the probability that the chin starts in the absorbing state. The probability of first absorption at any later time $k>0$ is then given by: $$\begin{align} \mathbb{P}(K = k) &= \mathbb{P}(K \leqslant k) - \mathbb{P}(K \leqslant k-1) \\[6pt] &= \mathbb{P}(X_{k} = n) - \mathbb{P}(X_{k-1} = n) \\[6pt] &= (1 - \boldsymbol{\tau} \mathbf{T}^k \mathbf{1}) - (1 - \boldsymbol{\tau} \mathbf{T}^{k-1} \mathbf{1}) \\[6pt] &= \boldsymbol{\tau} (\mathbf{T}^{k-1} - \mathbf{T}^k) \mathbf{1} \\[6pt] &= \boldsymbol{\tau} \mathbf{T}^{k-1} (\mathbf{I} - \mathbf{T}) \mathbf{1} \\[6pt] &= \boldsymbol{\tau} \mathbf{T}^{k-1} \mathbf{T}_0. \\[6pt] \end{align}$$ This is the result asserted in the formula you gave in your question for the discrete case. The extension to the continuous case requires some further work; it can be established either through taking relevant limits to the discrete case or directly from the rules for continuous-state Markov chains. Moments of absorption time: The moments of the absorption time can be computed using a recursive method. The $r$ th raw moment of the absorption time is: $$\begin{align} \mathbb{E}(K^r) &= \sum_{k=0}^\infty k^r \cdot \mathbb{P}(K = k) \\[6pt] &= (1- \boldsymbol{\tau} \mathbf{1}) \cdot \mathbb{I}(r=0) + \sum_{k=1}^\infty k^r \cdot \boldsymbol{\tau} \mathbf{T}^{k-1} \mathbf{T}_0 \\[6pt] &= (1- \boldsymbol{\tau} \mathbf{1}) \cdot \mathbb{I}(r=0) + \boldsymbol{\tau} \Bigg[ \sum_{k=1}^\infty k^r \cdot \mathbf{T}^{k-1} \Bigg] \mathbf{T}_0 \\[12pt] &= (1- \boldsymbol{\tau} \mathbf{1}) \cdot \mathbb{I}(r=0) + \boldsymbol{\tau} \mathbf{M}_r, \\[6pt] \end{align}$$ where we use the quantities: $$\mathbf{M}_r \equiv \Bigg[ \sum_{k=1}^\infty k^r \cdot \mathbf{T}^{k-1} \Bigg] \mathbf{T}_0.$$ The values of $\mathbf{M}_r$ can be computed recursively in $r$ using the method shown in Dayar (2005) , which involves LU factorisation of the matrix $\mathbf{I}-\mathbf{T}$ .
