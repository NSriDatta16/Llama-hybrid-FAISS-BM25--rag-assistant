[site]: crossvalidated
[post_id]: 277978
[parent_id]: 
[tags]: 
Choosing a prior distribution for logistic regression coefficients

For an image pixel classification task (a pixel can be either class 1 or class 0), I am fitting a logistic regression model using six features related to a specific pixel's color space properties (red channel, green channel, blue channel, hue, etc). I am interested in learning how to incorporate prior information (in the sense of a bayesian prior distribution for each model coefficient) about the behavior of these predictive features into a logistic regression model. As an example, I know that in the images related to my problem, for each image, most pixels have a certain distribution for each color channel and for each class. However, I am not seeing very clearly how to encode/relate this information in terms of the model coefficients. Most of the literature that I've seen is on how to set a weakly informative prior for logistic regression coefficients; but given that I know how these variables behave for each one of the classes, is there a way I can use this information? In summary, my questions are: How can I translate prior knowledge of the distribution of each predictive feature in terms of the model coefficients? If I fit a "frequentist" logistic regression just to see how the coefficients behave in order to derive my prior distributions, would this be "cheating" since I am already taking a look at the data? As a side note, I'm aware that a bayesian LR may not be the optimal solution to perform this kind of pixel classification, but I am doing this more as a learning experiment to understand how to do modelling under the bayesian perspective.
