[site]: datascience
[post_id]: 52405
[parent_id]: 
[tags]: 
training neural nets for OCR

we are trying to build an in house OCR system to extract alphanumeric strings from images (kindly note, most of our clients cant afford to send their data onto the cloud so it rules out any API from the googles and microsofts..and also tesseract is way too slow for our purpose ..we are talking 10's of users simultaneously uploading images .. tesseract, i guess was never designed to be used as such). We have already started using a CTC based approach to train on our data sets but there's a fundamental/conceptual issue. By definition, CTC finds a happy path to the most probable unit (in this case, a word) but alphanumeric strings by definition DO NOT have a pattern ! So i have a feeling CTC will not work for us. But juxtaposed to that is the multiclass classification approach (where we just predict every individual char) which has this big problem about how to split any image into specific characters before passing it to a CNN layer. We are a little clueless about the approach to be taken here. Any pointers will be heartily appreciated :)
