[site]: crossvalidated
[post_id]: 566736
[parent_id]: 
[tags]: 
How to find the MLE for $\theta$ in terms of K and n

this is my first question here :) This was seen in a machine learning exam: Suppose that $X_1 ...X_n$ are n i.i.d random variables with the following distribution: $f(x;\theta) = \begin{cases} \theta & x=-1\\ (1-\theta)^2\theta^x & x=0,1,2,... \end{cases}$ Suppose that K is the number of times observations are equal to -1 . Find a compact expression for the maximum likelihood estimator of $\theta$ in terms of K and n . The problem Is that I can not find a way to represent the likelihood function. I tried to approach it as a binomial distribution and multiply the two probabilities with a binomial coefficient but I did not succeed and it might be stupid. I am a little bit confused by the meaning of K and the $x_i$ , K is the number of times we saw -1, but $x_i$ is actually the number we have seen, combining those two things in one formula is what I failed to do. can you please guide me to the right way to think about it?
