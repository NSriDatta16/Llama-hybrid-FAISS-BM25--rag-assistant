[site]: crossvalidated
[post_id]: 476049
[parent_id]: 
[tags]: 
Relationship between singularities and non-identifiability in neural networks

What's a singularity in the context of non-identifiability of neural networks? For example, I read here : Skip connections made the training of very deep networks possible and have become an indispensable component in a variety of neural architectures. A completely satisfactory explanation for their success remains elusive. Here, we present a novel explanation for the benefits of skip connections in training very deep networks. The difficulty of training deep networks is partly due to the singularities caused by the non-identifiability of the model . Several such singularities have been identified in previous works: (i) overlap singularities caused by the permutation symmetry of nodes in a given layer, (ii) elimination singularities corresponding to the elimination, i.e. consistent deactivation, of nodes, (iii) singularities generated by the linear dependence of the nodes. These singularities cause degenerate manifolds in the loss landscape that slow down learning. We argue that skip connections eliminate these singularities by breaking the permutation symmetry of nodes, by reducing the possibility of node elimination and by making the nodes less linearly dependent. The abstract assumes that there is a known connection between non-identifiability and singularities and they argue that skip connections help with this problem. But I don't understand what they even mean by "singularity" here. Is a singularity a point where the gradient vanishes? Perhaps when the loss or the gradient is not defined? Or something else altogether?
