[site]: crossvalidated
[post_id]: 40722
[parent_id]: 40687
[tags]: 
Yes, a Naive Bayes model would be a good start to approaching this problem. A classic use of Naive Bayes is to classify emails as spam or not spam. http://en.wikipedia.org/wiki/Bayesian_spam_filtering Your problem is similar but the categories are inclusion and exclusion. So you would begin by creating a numerical representation for each description field. A common way to do this is to create a 'bag' of the most common words in all your descriptions. Then for each description field check to see if it contains the words in the 'bag'. Create a vector that has an entry for each word in the bag, 1 if the description contains the word and 0 if it doesn't. Then use these vectors to train a Naive Bayes classifier. Then you can use it to classify descriptions in your larger data set. If your description fields have considerably variable length you may want to try a tf-idf representation instead of binary. You might also try using Logistic Regression or Support Vector Machine classifiers as well to see what works best. Many languages have packages for these classifiers. For example in python you can use the sklearn package.
