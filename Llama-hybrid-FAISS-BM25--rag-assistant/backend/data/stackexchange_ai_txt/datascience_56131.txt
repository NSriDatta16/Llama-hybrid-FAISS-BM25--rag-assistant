[site]: datascience
[post_id]: 56131
[parent_id]: 54922
[tags]: 
First, you should consider not balancing the dataset. It may well be unnecessary for this problem. Now to your actual question. In sklearn , each decision tree reports the probability and these are averaged across the trees (as opposed to trees reporting their decisions and voting). So we can just understand how weighting affects these probabilities. In each leaf during training, the score given is $$\#\text{ positives in leaf}\ /\ \#\text{ total in leaf.}$$ With the shorthand $n_1$ and $n_0$ as the number of positives and negatives in the leaf, we can rewrite as $$p=\frac{n_1}{n_0+n_1} = \frac{1}{1+\frac{n_0}{n_1}}.$$ And weighting has the effect of transforming this quantity to instead $$p'=\frac{1}{1+\frac{0.526n_0}{10n_1}}.$$ (See e.g. [1] , [2] .) Just a bit of algebra then gives $$p = \frac{1}{1+\frac{10}{0.526}(\frac{1}{p'}-1)}.$$ It's worth noting that this implies $$\textrm{Adjusted odds} = \frac{p}{1-p} = \frac{0.526}{10}\left(\frac{p'}{1-p'}\right) = \frac{0.526}{10}\cdot\textrm{Weighted model's odds}.$$ This lines up with a resampling adjustment that is well-known for logistic regression models, but less so for other models. As for class weights in general: Is There a Way to Re-Calibrate Predicted Probabilities After Using Class Weights? Finally, random forests are not generally well-calibrated, i.e. the probability scores you get out won't necessarily align well with the true proportions. (In particular, predictions tend to shy away from 0 and 1.) For this, you can apply calibration methods as @Maia mentions (which obviates the above adjustment).
