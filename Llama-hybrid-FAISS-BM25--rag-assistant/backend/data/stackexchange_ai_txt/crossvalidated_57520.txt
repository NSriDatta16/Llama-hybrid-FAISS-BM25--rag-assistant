[site]: crossvalidated
[post_id]: 57520
[parent_id]: 57422
[tags]: 
It makes perfect sense for model 2 to be better . I didn't even have to look at the AIC. Look at the variance of your random effects. model1 and model3 are barely hanging to have impact as high as your residuals variance (measurement error if you like) and model2 has higher variance. It is a no-brainer. Also check out the correlation between your intercept and $TL$, 1 ? That's plain wrong, you definitely need to remove something (ie. give more freedom to your model). At best your design caused lme4 not to optimize properly. More specifically: How do I interpret the contribution of PC1 to model2 without p values? you don't need $p$-values to tell you a model is correct. Interpreter it as it is. And if someone is really picky on that matter (so doesn't really understand what $p$-value is in the context of LME.) just feed him the result of an ANOVA between the two models to get a $p$-value (I wouldn't believe it be true but hey, some guys just love their $p$-values). I would suggest just to say your model came out as the best model based on an $AIC$ selection criterion. (Because really that's why you just said you looked at in the first place and it is a very reasonable to do indeed in a lot of cases.) Just take notice that if you have difference in the AIC scores of the two models that is smaller than 2 you can't reject a model instead of the other. I don't know if it still works but you could look into MCMC generated $p$-values, using mcmcsamp , those are pretty much the golden standard (if the chain mixes well that is). I try to report those if ever possible. This analysis is telling me how PC1 affects intercepts of (Y~TL) among sites, correct? Correct. However, slopes of this relationship could also vary with PC1. How do I check this? Use interaction term as ndoogan says. (*) For "standard visualization" you can check the following thread: What would be an illustrative picture for linear mixed models? but as ndoogan says, if you are slightly more specific you'll get better answers when it comes to your visualization. (*) I just realized you have a problem. I didn't read your initial model specification R-code but now that I do I see that the summary of Model 2 you are presenting is not the summary of model2 you define. You define model2 but your fitted model is Y ~ TL + PC1 + (1 | Site) so you have eaten up your TL slope. Are you sure you don't have a mistake? Both answers you got so far are perfectly valid but it really looks like you are not comparing models with the same random effects structure. (I actually think that your "accidental" structure is the correct one)
