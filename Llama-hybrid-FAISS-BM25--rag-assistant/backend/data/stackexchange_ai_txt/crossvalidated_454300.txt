[site]: crossvalidated
[post_id]: 454300
[parent_id]: 
[tags]: 
Feature Engineering : combine a categorical Feature and a continuous Feature

When we analyze data, we can observe several variables that may contain mutual information. For an example, there can be a binary variable such as $Y=\text{Have you ever smoked?}$ . Then there will be a follow up question such as (in this case it is a continuous variable) "How old were you when you first smoked?" For the variable X that measures "How old were you when you first smoked?", \begin{align} X_1 &= \begin{cases} 0 & \text{if never smoked} \\ 1 & \text{if smoked} \end{cases} \\ X_2 &= \begin{cases} 0 & \text{if } x_1 = 0 \geq 0 & \text{if } x_1 = 1 \end{cases} \end{align} So the distribution of $X_2$ will be like this: That means it contains several zeros, as it is depends on the previous question ( $X_1$ ). One way to deal with this type of problem is calculate the age of first smoke ( $X_2$ ) only for users (i.e., eliminating zeros). Then the drawback is that it will reduce the sample size with respect to $X_2$ variable. Another way to model $X_2$ is convert it to a categorical variable. For an example someone can do like this: \begin{equation} X_2^{\text{categorized}} = \begin{cases} \text{Never Smoke} & X_2 = 0 \\ \text{Young} & 0 But is there way to model $X$ by preserving the continuous nature using a mixture distribution? I mean mixture distribution in the sense that, this may be something like the product of $X_2$ and $X_1$ . However, I am not sure how to do this. Since in this case $X_1$ is binary, taking the product of $X_2$ and $X_1$ seems to make sense. But I am not sure how this will work in general, i.e., when $X_1$ has more than 2 categories.
