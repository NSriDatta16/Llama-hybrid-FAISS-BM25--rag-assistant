[site]: crossvalidated
[post_id]: 141416
[parent_id]: 
[tags]: 
Example of sample $X_1,X_2,\ldots,X_n$

In the book Statistical Inference by George Casella , it is written that An experimenter uses the information in a sample $X_1,X_2,\ldots,X_n$ to make inferences about an unknown parameter $\theta$. I have always read "Suppose $X$ is a random variable and we take a sample $x_1,x_2,\ldots,x_n$." That is, $X$ can take some values randomly and $x_1,x_2,\ldots,x_n$ are some observed values of $X$. Capital letter $X$ denotes random variable and small letter $x$ denotes a realization from $X$. But in the book mentioned above it is written "sample $X_1,X_2,\ldots,X_n$", which seems to me if I have $N$ random variables, then I took $n$ random variables randomly from $N$ random variables. But different random variables cannot infer one unknown parameter $\theta$. How can I explain "sample $X_1,X_2,\ldots,X_n$" by real life example? Someone tried to give me the example that suppose you want to estimate average height of students in your class. You took 10 students randomly. Now before observed, your height itself a random variable. But I have not understood "Is the statement true that your height itself a random variable?". When my height is observable (not observed) one can think of my height as 5.5', 5.6', 5.4', etc. But when it is observed it becomes fixed. It is not clear to me that my height itself a random variable.
