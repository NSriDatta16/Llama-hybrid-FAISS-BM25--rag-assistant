[site]: datascience
[post_id]: 109035
[parent_id]: 109028
[tags]: 
A majority baseline classifier would have 67% accuracy just by predicting every instance as class 0, so 73% accuracy is not especially good. The AUC is a more informative measure, but an AUC of 0.5 is actually the minimum a classifier can do. And indeed, apparently this classifier is not doing much more than a baseline classifier: Recall for class 1 is 0.02, so the number of True Positives (TP) is 67734*0.02=1355. Precision for class 1 is 0.36 so the number of predicted positives (TP+FP) is 1355/0.36=3763. This means that the classifier predicts only 3763/(184508+67734)=1.5% of the instances as class 1, even though the imbalance is not severe. So what happens in this: most of the time the classifier doesn't succeed distinguishing the two classes, so it just predicts the majority class 0 (98.5% of the time). Without any detail it's impossible to know why, maybe the features are not good enough indicators, maybe there is overfitting, maybe logistic regression is not the right approach for this dataset...
