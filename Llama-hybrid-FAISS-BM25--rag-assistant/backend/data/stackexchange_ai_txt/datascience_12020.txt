[site]: datascience
[post_id]: 12020
[parent_id]: 
[tags]: 
Why do we calculate partial derivative of Error w.r.t output of Neural Network during backpropagation?

As seen in this image we calculate partial derivative of Error w.r.t output of the output neuron. Shouldn't it be normal derivative? Does not that particular error is determined by only that output?
