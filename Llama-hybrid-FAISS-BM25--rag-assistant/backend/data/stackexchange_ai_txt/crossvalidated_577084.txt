[site]: crossvalidated
[post_id]: 577084
[parent_id]: 
[tags]: 
Is it true that the type of ML model used is irrelevant?

I am training a model on a dataset and all types of relevant algorithms I have used converge close to the same accuracy score, meaning that no one is significantly better performing than the other. For example, if you're training a random forest and a neural network on MNIST, you'll observe an accuracy score of around 98%. Why is this the case, that bottlenecks in performance seem to be dictated by input data rather than the choice of the algorithm?
