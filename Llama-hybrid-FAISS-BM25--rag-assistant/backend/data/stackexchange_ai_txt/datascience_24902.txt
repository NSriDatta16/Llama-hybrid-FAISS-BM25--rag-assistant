[site]: datascience
[post_id]: 24902
[parent_id]: 24843
[tags]: 
Your asking for a layman's explanation, and the phrasing of your question, suggests to me that you are getting tangled up in the semantics, and I totally get that. So let's let go of the usual terms as much as we can, and speak in concepts. You have a bunch of observations -- or maybe even only one observation. This is your data. Maybe you are one of the particularly inquisitive ancients, and you notice some sort of relationship between lunar patterns and tides. While tracking this data, you start getting a sense for what sort of forces might be at work that would explain the apparent cause-and-effect relationship. The set of rules that you eventually develop becomes your model. The more correct your rules, the better you will be able to predict the tide tomorrow, next month, and next year. This concept you've developed -- probably something to do with gravity -- may be even more generally useful. If the general concept is re-used with different numbers, it can also help explain Earth's annual cycle. And why we see the Morning Star (Venus) with certain patterns. In the cases where we are re-using the concept, we are "fitting the model to the data" -- we are testing whether the set of rules we've developed -- the model -- can explain the apparent forces at work in the observations -- the data -- that we have. In the usual applications of regression (or any statistical method), we're not trying to formulate the laws of physics, we're trying to find rules that sufficiently govern complex systems -- often human behaviour -- and so we're unlikely to explain observations perfectly. But a model is useful to the extent that it successfully predicts future observations. Rather than waiting for the future, though, we typically perform analysis on part of a data set, and test for predictive power with the remainder of the data set. A specific instance of regression analysis might be in trying to explain housing prices. There are many many possible factors -- square meterage (footage), number of floors, swimming pool or not, size of property, shape of property, age, likelihood of flooding, distance to neighbours, energy rating, economic conditions, quality of the local school, etc, etc, etc. Which factors are most important? Do one, two, three of the factors explain 95% of the variation in housing prices? Can we come up with an equation that will predict a house's selling price reasonably well, rather than relying on a real estate agent's recommendation -- and having to second-guess what his/her agenda is -- how they might be playing us? And if you will humour a little editorializing: There are countless examples of reliance on experts proving to be a mistake (Nate Silver's "The Signal and the Noise", Daniel Kahneman's "Thinking Fast, Thinking Slow", Philip Tetlock's "Superforecasting") -- Data Science is about finding ways to derive insight from the data, rather than experts' opinions. But many data scientists get caught up in the mechanics, and lose sight of the purpose. It's not just about razzle-dazzle infographics. As Hamming puts it: "the purpose of computing is insight, not numbers". So I applaud your effort to seek a layman's explanation, rather than technical speak, to understand regression.
