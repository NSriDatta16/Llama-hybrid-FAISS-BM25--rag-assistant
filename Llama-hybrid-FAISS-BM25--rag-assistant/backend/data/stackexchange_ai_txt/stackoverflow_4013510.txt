[site]: stackoverflow
[post_id]: 4013510
[parent_id]: 4013363
[tags]: 
I think your problem lies in a lack of polymorphism in your operations, which you would like to have a closed parametric type (works for all data supporting the following arithmetic primitives) instead of having a type parameter representing a fixed data type. However, it's a bit difficult to ensure it's exactly this, because your code is not self-contained enough to test it. Assuming the given type for primitives : type 'a primitives = 'a; mul : 'a -> 'a; sub : 'a -> 'a; > You can use the first-order polymorphism provided by structures and objects : type op = { op : 'a . 'a -> 'a primitives -> 'a } let map = [ "add", { op = fun d c -> c # add d } ; "sub", { op = fun d c -> c # sub d } ; "mul", { op = fun d c -> c # mul d } ];; You get back the following data-agnostic type : val map : (string * op) list Edit: regarding your comment about different operation types, I'm not sure which level of flexibility you want. I don't think you could mix operations over different primitives in the same list, and still benefit from the specifities of each : at best, you could only transform an "operation over add/sub/mul" into an "operation over add/sub/mul/div" (as we're contravariant in the primitives type), but certainly not much. On a more pragmatic level, it's true that, with that design, you need a different "operation" type for each primitives type. You could easily, however, build a functor parametrized by the primitives type and returning the operation type. I don't know how one would expose a direct subtyping relation between different primitive types. The problem is that this would need a subtyping relation at the functor level, which I don't think we have in Caml. You could, however, using a simpler form of explicit subtyping (instead of casting a :> b , use a function a -> b ), build second functor, contravariant, that, given a map from a primitive type to the other, would build a map from one operation type to the other. It's entirely possible that, with a different and clever representation of the type evolved, a much simpler solution is possible. First-class modules of 3.12 might also come in play, but they tend to be helpful for first-class existential types, whereas here we rhater use universal types. Interpretive overhead and operation reifications Besides your local typing problem, I'm not sure you're heading the right way. You're trying to eliminate interpretive overhead by building, "ahead of time" (before using the operations), a closure corresponding to a in-language representation of your operation. In my experience, this approach doesn't generally get rid of interpretive overhead, it rather moves it to another layer. If you create your closures na√Øvely, you will have the parsing flow of control reproduced at the closure layer : the closure will call other closures, etc., as your parsing code "interpreted" the input when creating the closure. You eliminated the cost of parsing, but the possibly suboptimal flow of control is still the same. Additionnaly, closures tend to be a pain to manipulate directly : you have to be very careful about comparison operations for example, serialization, etc. I think you may be interested in the long term in an intermediate "reified" language representing your operations : a simple algebraic data type for arithmetic operations, that you would build from your textual representation. You can still try to build closures "ahead of time" from it, though I'm not sure the performances are much better than directly interpreting it, if the in-memory representation is decent. Moreover, it will be much easier to plug in intermediary analyzers/transformers to optimize your operations, for example going from an "associative binary operations" model to a "n-ary operations" model, which could be more efficiently evaluated.
