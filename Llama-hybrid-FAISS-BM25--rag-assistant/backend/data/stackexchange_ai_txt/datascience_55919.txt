[site]: datascience
[post_id]: 55919
[parent_id]: 
[tags]: 
What happens if you add a constant value to all input data points to neural networks?

I have a somewhat basic question about neural networks. What would be the effect on the performance of a neural network if we add a constant value to all data points? For example, suppose you have temperature data in degree Celcius which is not an SI unit. Will it make any difference to the model if your input is in degree Celcius or Kelvin? If yes, then in what way? I have a dataset where one feature values are in nanometers for example 35nm , 42nm , etc. If the answer to the above question is No then you can simply divide all of them by 100 to reduce them between 0 and 1 and it shouldn't matter to the model? Does it make more sense to divide it by 100 or the maximum value? What do you do if your input is limited by neither 100 nor the maximum value? Thanks for your help in advance.
