[site]: crossvalidated
[post_id]: 479408
[parent_id]: 
[tags]: 
Find the minimum of two variables jointly (to select an optimal model)

Suppose that we have a few machine learning models and would like to perform model selection. Let's assume that I have tuples representing (prediction_time, prediction_error) for each model, so I'd like to find the optimal model, i.e. the one with the lowest time and error at the same time: The solution I came up with is to solve it like an optimization problem: scale time and error vectors and then multiply their values for each model ( time * error ), that'd be the ranking metric for the model. Then just sort them. Here is an example: import numpy as np def minmax_scale (X, min, max): X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) X_scaled = X_std * (max - min) + min return X_scaled # a is the original (time,error) list a = [(2,3), (1,4), (3,2), (2,5), (8,3), (1,7), (3, 6)] # scale time and error to the range (1,5) time = minmax_scale(np.array([tup[0] for tup in a]), 1, 5) error = minmax_scale(np.array([tup[1] for tup in a]), 1, 5) # opt_a is the list of multiplied values opt_a = [t*e for t,e in zip(time,error)] print(opt_a) sorted_idx = sorted(range(len(opt_a)), key=lambda k: opt_a[k]) print(sorted_idx) Questions : First of all, are there any better ways to consider such a trade-off? I'd like to assume that the prediction error and prediction time are equally important, but can obviously give them some weights too Secondly, is the min-max scaling useful here? as shown in the example, after scaling (8,3) and (3, 6) result in the same value, because time and error have different ranges. I guess this should be okay, but still wondering if there are other common solutions / best practices.
