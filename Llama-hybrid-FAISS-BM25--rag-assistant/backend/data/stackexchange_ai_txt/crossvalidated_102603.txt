[site]: crossvalidated
[post_id]: 102603
[parent_id]: 101590
[tags]: 
The first sentence of this question, incorporates another (related) fallacy: "As we all know, if you flip a coin that has an equal chance of landing heads as it does tails, then if you flip the coin many times, half the time you will get heads and half the time you will get tails ." No we won't get that, we won't get heads half the time and tails half the time. If we were to get that, then the Gambler would not be so mistaken after all . The mathematical expression for this verbal statement is as follows: For some "large" (but finite) $n'$, we have $n_{h} = \frac {n'}{2}$, where evidently $n_{h}$ denotes the number of times the coin lands heads. Since $n'$ is finite, then $n'+1$ is also finite and a distinct value from $n'$. So what happens after the $n'+1$ flip has been made? Either it landed heads, or not. In both cases, $n_h$ has just stopped being equal to "half the number of tosses". But perhaps what we really meant was an "unimaginably large" $n$? Then we state $$\lim_{n\rightarrow \infty}n_{h} = \frac n{2}$$ But here, the RHS ("right-hand side")contains $n$ which by the LHS ("left-hand-side"), has passed over to infinity. So the RHS is also infinity, and so what this statement says is that the number of times the coin will land heads is equal to infinity, if we toss the coin an infinite number of times (the division by $2$ is negligible) : $$\lim_{n\rightarrow \infty}n_{h} = \frac n{2} = \infty$$ This is an essentially correct, but useless statement , and obviously not what we have in mind. In all, the statement in the question does not hold, irrespective of whether "total tosses" is considered finite or not. Perhaps then we should state $$\lim_{n\rightarrow \infty}\frac {n_{h}}{n} = \frac 1{2} \;\;?$$ First, this translates into "The ratio of the number of landed heads over total number of tosses tends to the value $1/2$ when the number of tosses tends to infinity", which is a different statement - no "half of the total tosses" here. Also, this is how probability is still sometimes perceived -as a deterministic limit of relative frequencies. The problem with this statement is that it contains in the LHS an indeterminate form: both numerator and denominator go to infinity. Hmmm, let's bring in the random variable arsenal. Define a random variable $X_i$ as taking the value $1$ if the $i$-th toss came up heads, $0$ if it came up tails. Then we have $$ \frac {n_{h}}{n} = \frac 1n \sum_{i=1}^nX_i$$ Can we now at least state $$\lim_{n\rightarrow \infty}\frac 1n \sum_{i=1}^nX_i = \frac 1{2} \;\;?$$ No . This is a deterministic limit. It permits all possible realizations of the sequence of the $X$'s, and so it does not even guarantee that a limit will exist, let alone it being equal to $1/2$. In fact such a statement can only be seen as a constraint on the sequence, and it would destroy the independence of the tosses. What we can say, is that this average sum converges in probability ("weakly") to $1/2$ (Bernoulli -Weak Law of Large Numbers), $$\lim_{n\rightarrow \infty}\text {Pr}\left(\left|\frac 1n \sum_{i=1}^nX_i-\frac 12 \right| 0$$ and in the case under consideration, that it also converges almost surely ("strongly") (Borel -Strong Law of Large Numbers) $$\text {Pr}\left(\lim_{n\rightarrow \infty}\frac 1n \sum_{i=1}^nX_i=\frac 12 \right) =1 , \;\;\;$$ But these are probabilistic statements about the probability associated with the difference between $n_h/n$ and $1/2$, and not about the limit of the difference $n_h-n_t$ (which according to the false statement should be zero - and it is not). Admittedly, it takes some dedicated intellectual effort to really understand these two statements, and how they differ (in "theory" and in "practice") from some of the previous ones -I do not claim such deep understanding for myself as yet.
