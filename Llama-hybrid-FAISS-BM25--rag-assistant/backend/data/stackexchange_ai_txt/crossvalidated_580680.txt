[site]: crossvalidated
[post_id]: 580680
[parent_id]: 
[tags]: 
Running model on full dataset or just test set?

I'm new to using XGBoost and I'm confused about how we should obtain the XGBoost predicted values for each data point. For example, the process for fitting and evaluating an XGBoost model is: # STEP 1: Splitting dataframe between target variable and predictor variables X = df.drop(['Target'], 1) y = df['Target'] # STEP 2: Splitting the data into training (80%) & test sets (20%) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # STEP 3: Initiating XGBoost Regression model model = xgb.XGBRegressor() # STEP 4: Fitting model to training data model.fit(X_train, y_train) # STEP 5: Generating Predictions on test set y_pred_test = model.predict(X_test) # STEP 6: Generating test set RMSE rmse_test = np.sqrt(MSE(y_test, y_pred_test)) print("RMSE: %f" % (rmse_test)) At this point, we have our model and have evaluated the model performance. If we then wanted to obtain the model predictions for each data point (i.e. a table showing each row and columns of the actual target variable and the predicted target variable), would we run the model on the full data set X ? Or only on the test set? Slightly confused here so any help would be appreciated?
