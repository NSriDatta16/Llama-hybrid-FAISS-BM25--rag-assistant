[site]: datascience
[post_id]: 33199
[parent_id]: 33192
[tags]: 
If your error stays at about 20%, it sounds like your features are not really helping. It is likely the case that your relationship in data/features is not simple, so you need to allow your SVM model more flexibility and/or train for longer. This will of course bring in the danger of overfitting, but should improve things... you'll need to try out a few different things. If you are using SciKit Learn, this might equate to using a radial basis function with a high value of argument C (giving much more flexibility to the model) and also try a higher value for the argument gamma , which will reduce the radius of influence of each individual data point. Check out this example for further explanation. Think of the classic example of flipping an unbiased coin: we would expect to get 50% heads and 50% tails. So in this binary prediction, any time you make a prediction, you have 50-50 odds and so a model with more than 50% error is worse than a random guess! If you are getting 20% error, it sounds like your model is just predicting black. A simple way to see and understand this - and why it really makes sense perhaps - would be to plot the data. If in your feature speace, the points all look like a big mixture, a cloud, where the majority of points are black, then even a human would likely just predict black: So two options: Allow the model higher flexibility (as described above), which will let it (over-)fit a line that cleanly cuts out the sparse red points from the black Get new features, or preprocess your features in such a way that a plot might end up looking something more like thi the image below, which will allow a simpler model to classify the red from the black with e.g. a straight line.
