[site]: crossvalidated
[post_id]: 621461
[parent_id]: 621459
[tags]: 
The Widely Applicable Information Criterion (WAIC, Watanabe, (2010) "Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory". Journal of Machine Learning Research 11 , 3571–3594.), is a fully Bayesian approach for estimating the expected log pointwise predictive density for a new dataset starting with the computed log pointwise posterior predictive density and then adding a correction for the effective number of parameters to adjust for overfitting. In Watanabe’s original definition, WAIC is the negative of the average log pointwise predictive density (assuming the prediction of a single new data point), thus it can take on negative values as the AIC, DIC or the BIC. Note however that the WAIC in this original definition is not comparable with the AIC or DIC since it is not on the deviance scale. To bring it on the deviance scale you will have to multiply by $-2n$ ; for more details check Gelman et al. (2014) "Understanding predictive information criteria for Bayesian models", Statistics and Computing 24 , 997–1016.
