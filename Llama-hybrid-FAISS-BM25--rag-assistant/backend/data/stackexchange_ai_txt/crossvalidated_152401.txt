[site]: crossvalidated
[post_id]: 152401
[parent_id]: 
[tags]: 
Automated detection of outliers in one dimensional data

I have several datasets that I need to be able to fit (the goal is to find the outliers). The datasets were created by groups of images and the x is an index number of the image and y is a focus measure of an image. When I am plotting x vs y(focus measure) every set looks like the trend has a different shape (it could be 2 peaks (Gaussians or Lorentzians) or one peak (Gaussian) because of the structure of the image (these are complicated images and they have different structures which accounts for the differences). When I look at the plots there are several points that are very far away from the main trend, it is very easy to see them by eye, but what I want is to fit the data so that I can find the data points (using a program) that are further away than 3 standard deviations from the fit line. Because there are thousands of those datasets, I can not look at them one at a time and decide which curve shape fits the best, I need a more generic way to fit the data. I am using Matlab to do that. Is there a way to find the best curve fit programmatically without knowing the shape of the curve? I am not very familiar with Machine Learning but this might be something that I can do using ML but I am hoping of a suggestion of a specific method to do that.
