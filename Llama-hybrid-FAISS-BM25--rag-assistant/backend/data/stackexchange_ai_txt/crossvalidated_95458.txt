[site]: crossvalidated
[post_id]: 95458
[parent_id]: 95451
[tags]: 
You are right. I suspect that the conceptual mistake of your friend is that he visualizes the $75$%-$25$% "random guessing" as an "agnostic draw from the bag" and compares this with the "model accuracy". But this is not what "model accuracy" measures. "Model accuracy" quantifies a two-step procedure where first you predict and then you draw to see whether your prediction was correct. Without the model, you would have only the unconditional probabilities to go on (accepting that sample proportions are close estimates of them). So, as you clarified in the comments, you would flip a $75$%-$25$% coin to make your prediction. So the "accuracy" you should expect on average in this situation would be $$\Pr [\{\text{"coin lands bad"}\},\{\text{"draw gives bad"}\}] + \Pr [\{\text{"coin lands good"}\},\{\text{"draw gives good"}\}]$$ These are independent events so the above joint probabilities split: $$\Pr [\{\text{"coin lands bad"}\}]\cdot\Pr [\{\text{"draw gives bad"}\}] \\+ \Pr [\{\text{"coin lands good"}\}]\cdot\Pr [\{\text{"draw gives good"}\}]$$ $$ = (0.75)^2 + (0.25)^2 = 0.5625 + 0.0625 = 0.625$$ You are telling us that, using the model, you have $$\Pr [\{\text{"model says bad"}\},\{\text{"observation is bad"}\}] + \Pr [\{\text{"model says good"}\},\{\text{"observation is good"}\}] = 0.75$$ So your model improved your chances of predicting correctly. Note that the model does not "draw" from the bag of $Y$'s but from the bag of $X$'s. The model does not use the fact that you have a $75$% probability of drawing $X'$s that are related to a "bad" $Y$, -it uses the numerical values of the $X$'s. P.S. Greg Snow's answer correctly points out that your model does not perform better compared to a prediction strategy "always guess bad". But this strategy cannot be considered "random". Still, this remark would be a valid criticism against the practical usefulness of your model in general (and not only compared to "random guessing").
