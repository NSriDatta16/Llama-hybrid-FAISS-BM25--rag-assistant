[site]: crossvalidated
[post_id]: 389511
[parent_id]: 
[tags]: 
Totally confused about input_shape dimension of stateful LSTM Network with keras

let's say I've got 2500 time series of class A, and 2500 time series of class B, both 1000 time steps long. There is only one numerical feature per time series. I want to train a LSTM using Keras to classify the time series into one of the two classes. They can be easily distinguished using features which require the LSTM to understand the time correlation between the data, like one class has a seasonal pattern, while the other hasn't. Therefore I want to use a stateful LSTM. But I'm totally confused about how to construct the input_dimensions for Keras. As far as I understand it the input for the LSTM is defined as (samples, time steps, features). Is my X now (5000,1000,1) and I call model.fit() exactly once? When do I call model.reset_states()? Or do I show the time series each time step at a time, so my input is (1,1,1) and I just show it then 5000 times for each time series 1000 times per each time step the single feature, so call model.fit() 5,000,000 times?! I would then call after I'm finished with one time series the model.reset_states() method to forget everything for the new time series, right? Or is it (1,1000,1), and I call model.reset_states() after calling fit() 5000 times (per time series)?
