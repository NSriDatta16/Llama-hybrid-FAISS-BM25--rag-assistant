[site]: crossvalidated
[post_id]: 565425
[parent_id]: 
[tags]: 
Kernel transformation in Machine Learning

I understand kernels allow us to linearly separate non-linearly separable data in a higher-dimensional space. Given a feature vector $\bar x = [x1,x2,..xn]^T$ , we can apply the transformation $\phi(\bar x)$ , and apply the usual regression $ y = \bar w^T\phi(\bar x)$ . However, I do not understand the notation in the following question: Given N data points $(x,t)$ (scalars), fit an th degree polynomial using polynomial and Gaussian kernels, and study goodness of fit. To be more specific, what function $\phi$ do I use in the Polynomial and Gaussian kernels to obtain the transformed input vector?
