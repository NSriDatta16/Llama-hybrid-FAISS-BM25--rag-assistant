[site]: datascience
[post_id]: 123521
[parent_id]: 
[tags]: 
Similiar reconstruction for Pytorch VAE

This is my first question here, so if I don't offer enough information for my question to be answered, please let me know. I am currently working on my Bachelor Thesis, in which I aim to integrate different neural data modalities of the ABIDE Dataset in a shared latent space using crossmodal VAEs based on this paper . One of those modalities is functional connectivity. Basically, I computed the Pearson product-moment correlation coefficients of fMRT activation for individuals, resulting in a 392x392 correlation matrix, of which I then extract the lower triangle, resulting in a flat 76.636 point array, used as one of my input modalities, subject to reconstruction by the VAE. The model is a fairly simple fully connected VAE, which yields great results for reconstruction for other modalities (namely cortical thickness and brain area). class FC_VAE(nn.Module): """Fully connected variational Autoencoder""" def __init__(self, n_input, nz, n_hidden=1024): super(FC_VAE, self).__init__() self.nz = nz self.n_input = n_input self.n_hidden = n_hidden self.encoder = nn.Sequential(nn.Linear(n_input, n_hidden), nn.ReLU(inplace=False), nn.BatchNorm1d(n_hidden), nn.Linear(n_hidden, n_hidden), nn.BatchNorm1d(n_hidden), nn.ReLU(inplace=False), nn.Linear(n_hidden, n_hidden), nn.BatchNorm1d(n_hidden), nn.ReLU(inplace=False), nn.Linear(n_hidden, n_hidden), nn.BatchNorm1d(n_hidden), nn.ReLU(inplace=False), nn.Linear(n_hidden, n_hidden), ) self.fc1 = nn.Linear(n_hidden, nz) self.fc2 = nn.Linear(n_hidden, nz) self.decoder = nn.Sequential(nn.Linear(nz, n_hidden), nn.ReLU(inplace=False), nn.BatchNorm1d(n_hidden), nn.Linear(n_hidden, n_hidden), nn.BatchNorm1d(n_hidden), nn.ReLU(inplace=False), nn.Linear(n_hidden, n_hidden), nn.BatchNorm1d(n_hidden), nn.ReLU(inplace=False), nn.Linear(n_hidden, n_hidden), nn.BatchNorm1d(n_hidden), nn.ReLU(inplace=False), nn.Linear(n_hidden, n_input), ) def forward(self, x): mu, logvar = self.encode(x) z = self.reparametrize(mu, logvar) res = self.decode(z) return res, z, mu, logvar def encode(self, x): h = self.encoder(x) return self.fc1(h), self.fc2(h) def reparametrize(self, mu, logvar): std = logvar.mul(0.5).exp_() if torch.cuda.is_available(): eps = torch.cuda.FloatTensor(std.size()).normal_() else: eps = torch.FloatTensor(std.size()).normal_() eps = Variable(eps) return eps.mul(std).add_(mu) def decode(self, z): return self.decoder(z) model_func = FC_VAE(n_input=76636,nz=128).to(device) # setup optimizer opt_netfunc = torch.optim.Adam(params=list(model_func.parameters()), lr=1e-4) # loss criteria criterion_reconstruct = nn.MSELoss() criterion_classify = nn.CrossEntropyLoss() Training loop is straightforward as well: def compute_KL_loss(mu, logvar): if args.lamb>0: KLloss = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) return args.lamb * KLloss return 0 def train_autoencoders(func_inputs): model_func.train() model_func.zero_grad() func_recon, func_latents,func_mu, func_logvar = model_func(func_inputs) func_recon_loss = criterion_reconstruct(func_inputs, func_recon) kl_loss = args.beta*(compute_KL_loss(func_mu,func_logvar)) loss = func_recon_loss+ kl_loss # backpropagate and update model loss.backward() opt_netfunc.step() summary_stats = {'func_recon_loss': func_recon_loss,'KL_loss':kl_loss.item()} return summary_stats I then just iterate for X epochs over my dataloader. However, my reconstruction loss doesn't seem to overfit, but rather approximate some number significantly higher than zero, regardless of latent dimensions or model size (here: 128 latent dimensions as a bottleneck) If I then look at the reconstructions (transformed back to correlation matrices), they all look pretty much the same, but not alike the original. Do you have any ideas on how I could improve the reconstruction? I've played around with the weighing of the KL Term, but it does not seem to have any impact. Thank you so much for your time! Felix
