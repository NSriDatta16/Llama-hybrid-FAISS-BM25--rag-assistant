[site]: datascience
[post_id]: 126768
[parent_id]: 
[tags]: 
Feature selection or hyperparameter tuning first for 30 feature data

I have about 30 variables and trying to create a Random Forest model. All the variables are expected to be predictors of outcome. I want to find the best model based on a C-stat score with any number of features. Shall I do feature selection first or hyperparameter tuning? I read that people prefer feature selection first, but they do have a few hundred features. I only have 30. I am leaning towards hyperparameter tuning before going into feature selection.
