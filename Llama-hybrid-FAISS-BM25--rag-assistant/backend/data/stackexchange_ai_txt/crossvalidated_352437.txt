[site]: crossvalidated
[post_id]: 352437
[parent_id]: 350814
[tags]: 
1-5 are ideal, but I do not believe are 100% required. Some will rightfully cringe at that sentence. The most important thing to remember is the "no free lunch theorem", which reminds us that ML is based on theories, hypotheses, and/or assumptions at every stage of the pipeline. We can only define whether ML will help us in our task if we assume that some set of input features are independent of our target (dependent variable). I won't make this an essay (nvm), so I'll comment on each item and add a few to your list. My answer is written as a discussion, not do's and don'ts. Please at least upvote if you find it helpful. (Disclaimer: All notes below were written with supervised ML in mind). 1) We must have some assumed ground truth, but we cannot always quantify accuracy of our labels. The labels may reflect perception and opinion (e.g. data came from human input) or unexplainable randomness from nature. Random and balanced sampling is preferred for fair experimental setup, but not required to use ML. Some algorithms can handle minority labels (e.g. by adding weights), although most will do poorly if you do not reasonably balance (up/down sample) the data. Some algorithms (e.g. Breiman's Random Forest and the derivative Extra Trees) are designed to be robust against unexplained variance and others (Logistic Regression and Naive Bayes) are designed to be probabilistic. 2) In easier problems, the distribution of input/output will remain constant. In many hard problems, it is not. Image, audio, text and time series are great examples. Stock market predictions are heavily influenced by recent data and are not likely to respect the global distribution. That doesn't mean we can't make good predictions. e.g. Amazon stock has grown slightly faster than linear over the last 5 years and it will probably continue this rate of growth for a long while. 3) Ideally, the target will completely depend on the input. For example, Y = f(x) = 2x+1. In reality, we are modeling something like Y = f(x,z) = 2x+1 + g(z), where z represents independent signals (just think of this as features if you are not sure what this means) that would explain the error of our model, but are not available and may only exist in theory (e.g. a person's thought process at an instance of time caused an action that effected the result of the target, i.e. string theory). It might be more correct to say that the input must have some correlation to the output and we will assume that the output is a function of the input. 4) Yes, good description. Simpler, we just need "enough" data to make a reasonable prediction. How much is enough? It could actually be five samples for all we know. If we create a learning curve and see that the performance meets our objective when we have N samples and is not much better with N+M samples, that is enough. There are many scenarios where we would like more data and it would make significant improvements in the result, but it's too expensive to either collect or to process. So in this case, the number of samples is also reflected by cost, even if that means our data science objective becomes extremely difficult. So the requirement comes down whether the output can be inferred from the input to some degree and we will assume that there is enough data because we want a system that quickly, cheaply, automatically and consistently does inference. 5) Yes and @schem is also right. The output must be somewhat measurable against our desired outcome, otherwise how do we optimize and know how well did we did? "Measurable" does not have to mean a numeric loss function by the way. I could make a loss function with fuzzy metrics that are ordinal, but not numeric, for example my not-fun-to-use loss function outputs "the estimate is [too cold, cold, just right, hot, too hot]" or [good, ok, bad]. That is why I mean "somewhat measurable". Added items: 6, 7, 8, ...) Ideally, the cost (time, money, compute, ...) of building a ML solution and using it should be significantly less than humans or programming an explicit solution. The value to be achieved by deploying ML should improve quality, consistency or cost. You should read about the four V's ( http://www.ibmbigdatahub.com/infographic/extracting-business-value-4-vs-big-data ) and the absurd followup, the 42 V's ( https://www.elderresearch.com/blog/42-v-of-big-data ), which also has many good points related to this discussion. I'll edit this later as I remember what else I wanted to write. If this question is just for you, then I recommend reading a bit from the "Data Mining" book by Witten, Frank and Hall. It gives great discussion on this topic. If you will be making training material, giving a presentation or similar communications, I recommend simplifying this list a lot for a new to ML audience. A creative data scientist will deal with what they have, invent solutions (e.g. build logical simulations of the problem when you have too little data to directly use ML and use the available real data to validate the simulation exercise) and break the rules. Our assumptions, our satisfaction with experimental results and 5-8 govern whether ML was appropriate. The quality of the data is not super high importance * (grain of salt) if you remember the law of "garbage in, garbage out".
