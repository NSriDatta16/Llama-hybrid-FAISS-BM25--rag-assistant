[site]: crossvalidated
[post_id]: 454800
[parent_id]: 454370
[tags]: 
My intuition is that you should apply cross validation as if it is a time series. Although, like you said you are only predicting from individual time points, your validation accuracy will be biased due to autocorrelation in your samples. For example, lets say you train a NN on days 0-4.5 and test on days 4.5-5. The problem here is that the last training example will likely be very similar to the first test example if there is strong autocorrelation (which there would be with temperature assuming time spacing of 5days/1million = 0.43s apart). Therefore this is a little bit like having some of the same samples in your test set as what you trained on and so you you are likely to calculate a better validation score than you would if you just had random samples in your test set. This in turn is likely to make you overtrain your network. If you were looking for a quick way to reduce this you could cross validate by leaving a gap in time between your training set and you test set. For example lets say it takes 1hr to get rid of the autocorrelation. You could then train on hours 1-107.999 (days 1-4.5) and test on hours 109-119.999. If you wanted to test on a fold in the middle of the sequence you could leave an hour gap on both sides. And to evaluate how long you should leave as a gap you could test this. Like train a network and plot the validation score vs gap left. I would expect this curve to tend towards a lower and more reliable value as the gap is increased.
