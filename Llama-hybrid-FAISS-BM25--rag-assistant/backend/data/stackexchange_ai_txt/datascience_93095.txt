[site]: datascience
[post_id]: 93095
[parent_id]: 
[tags]: 
Differentiating vector with different operation on each elements

I have some idea about how backpropagation would work for a loss function like: loss=summation(predicted-true)^2 Where predicted and true are vectors of the same length and same operation throughout the elements. Now in object localization problem my neural network's output vector's $0^{th}$ element would denote probability of particular object being in image and rest 4 would tell about bounding box. Now my loss function would be roughly something like this: loss=CategoricalCrossentropy(pred[0],true[0])+MSE(pred[1:4]-true[1:4]) This loss function worked fine in tensorflow and my NN localized the object as I expected. My problem is that I am not able to understand how mathematically differentiation would work when different operations are applied on different elements.
