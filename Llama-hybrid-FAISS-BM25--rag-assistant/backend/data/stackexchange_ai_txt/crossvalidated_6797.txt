[site]: crossvalidated
[post_id]: 6797
[parent_id]: 6791
[tags]: 
Apply empirically-based rescaling formula: If you can administer both versions of the scale to a subsample, you could estimate what the corresponding scores are on the two response formats. Then you could apply a conversion formula that is empirically justified. There are several ways that you could do this. For instance, you could get 100 or so participants (more is better) to answer the set of questions twice (perhaps counterbalanced for order) using one response format and then the other. You could then experiment with different weightings of the old scale that yield identical means and standard deviations (and any other characteristics of interest) on the new scale. This could potentially be setup as an optimisation problem. Apply a "common-sense" conversion" : Alternatively, you could apply a "common-sense" conversion. One naive conversion involves rescaling so that the min and max of the two scales are aligned. So for you 5-point to 9-point conversion, it would be 1 = 1; 2 = 3; 3 = 5; 4 = 7; 5 = 9. A more psychologically plausible conversion might consider 1 on 9-point scale to be more extreme than a 1 on a 5-point scale. You could also consider the words used for the response options and how they align across the response formats. So for instance, you might choose something like 1 = 1.5, 2 = 3, 3 = 5, 4 = 7, 5 = 8.5, with a final decision based on some expert judgements. Importantly, these "common sense conversions" are only approximate. In some contexts, an approximate conversion is fine. But if you're interested in subtle longitudinal changes (e.g., did employees less satisfied in Year 2 compared to Year 1), then approximate conversions are generally not adequate. As a broad statement (at least within my experience in organisational settings) changes in item wording and changes in scale options are likely to have a greater effect on responses than any actual change in the attribute of interest.
