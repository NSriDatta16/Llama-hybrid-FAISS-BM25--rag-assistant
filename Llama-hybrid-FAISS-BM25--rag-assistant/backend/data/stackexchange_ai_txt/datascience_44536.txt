[site]: datascience
[post_id]: 44536
[parent_id]: 44530
[tags]: 
If I'm understanding you correctly, you have a bunch of sets of 20 3D points, and for each set of points you have three metrics associated with it. Yes, it's definitely possible to learn which points are most predictive for each metric. I would recommend that you split your data such that the point sets are in one numpy array which looks like x1_1, y1_1, z1_1, x1_2, y1_2, z1_2, ..., x1_20, y1_20, z1_20 x2_1, y2_1, z2_1, x2_2, y2_2, z2_2, ..., x2_20, y2_20, z2_20 ... and then create one 1D numpy array for each of your metrics which contain the value of each metric for every point set. Then, you can use something like a RandomForestRegressor to try to predict the metrics individually from the points. Once you have the random forest trained with the fit(X, y) method, you can extract the importances of each coordinate in the points by getting the feature_importances_ . For example, something like this: rf1 = RandomForestRegressor(n_estimators=1000) rf1.fit(points, metric1) print(rf1.feature_importances_) rf2 = RandomForestRegressor(n_estimators=1000) rf2.fit(points, metric2) print(rf2.feature_importances_) rf3 = RandomForestRegressor(n_estimators=1000) rf3.fit(points, metric3) print(rf3.feature_importances_) Hope this points you in the right direction!
