[site]: crossvalidated
[post_id]: 562008
[parent_id]: 561997
[tags]: 
Welcome to Cross Validated! Like any statistical test, the Granger Causality test has certain assumptions that need to be met for the results of the test to be valid/useful. For the Granger Causality test, the assumptions are: (i) that it is covariance stationary (i.e., the mean and variance of each time series do not change over time), and (ii) that it can be adequately described by a linear model. source (You will find that these two assumptions are common among many time-series statistical tests). That's for time series. You also ask for non-timeseries, and the problem is the same. "Correlation" is also a linear measure (meaning it does not capture, or captures poorly, any non-linear pattern like quadratic, polynomial, logarithmic, stepwise etc.) . Additionally, linear regression has various other assumptions (like normality and independence of samples). Note, autocorrelation violates the "independence" assumption of linear regression, so you can't directly apply it to an autocorrelated timeseries. There are dedicated timeseries techniques (ARMA and ARIMA models) to address this. With all of this in mind, the answer to your question is: No, it is not useless to try to model the relationship between two or more variables using complex (or any) methods if there is a failure to reject the Granger Causality test, or failure to find a high correlation. Granted, if the correlation is low that probably generally means it's less likely you'll find an easy pattern there. But it really depends on the problem and the kinds of relationships that exist in your data. Maybe there's some kind of complex conditional relationship between the dependent variables etc. To be honest, I don't fully understand your last question there after "So im thinking about this:", but I hope that my answer also coincidentally answers that question too. Essentially, it's often worth trying out some different analysis methods even if Granger Causality test fails, but do so carefully, because failure of a test like that does indicate (most of the time) that you have some complex relationship going on (if any at all). Side note: You don't always need to jump to things as complex and resource-hungry as neural networks. Try out time series techniques like the ones I mentioned, maybe find a way to normalize your time series and remove autocorrelation (like differencing the series) and try regular linear regression on the differences etc. Maybe try a less deep/complicated machine learning method like RandomForest. There are many options besides neural nets, and depending on the task, they might work out equally well for less hassle. EDIT: I'm adding this based on OP's adding some information to the question. Please see my comment under the question for critical info, mainly regarding the fact that 60-120 rows of data is barely enough for a good linear regression, much less any kind of machine learning or deep learning (which requires at least an order of magnitude more data). You mentioned adding month/day. With so little data, I wouldn't bother with that. Unless your data is weekly or something, you don't have enough of it to discern different patterns dependent on day of the year, day of the month etc. Think about it, if you added month but your data (for example) only spans two months.. it's quite unlikely you'll find a usable monthly pattern within 2 months.
