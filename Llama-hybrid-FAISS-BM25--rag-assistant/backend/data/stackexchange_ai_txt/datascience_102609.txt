[site]: datascience
[post_id]: 102609
[parent_id]: 102605
[tags]: 
Maybe you should train the model for more epochs Or use the Weighted Binary Cross Entropy loss with a bigger weight to the Positive label It would be easier to visualize with an input-output example, but by what you said you have a 1D vector of input features and a 1D vector of binary labels Up to epoch 3 your model is still predicting positive labels, given by the false_positive rate > 0, it just doesn't get it right, and it is predicting less values as positives each epoch Given the epoch log we can see that the target class is rare , on the first epoch you show FN:2539 FP:121536 TP:131 TN:2377794 which gives P = FN+TP = 2539+131 = 2670 N = FP+TN = 121536+2377794 = 2499330 So the positive class is rougthly 0.1% of the cases Given that, a model that always predict Negative doesn't seem so bad And you can see both the loss and the average error are decreasing However, there will be a point where this can't get any better and the model may start to get things right, you just need to give it more than 10 epochs. It also depends on the quality of the previous model that extracts the features.
