[site]: crossvalidated
[post_id]: 172411
[parent_id]: 172163
[tags]: 
Trees in RF and single trees are built using the same algorithm (usually CART). The only minor difference is that a single tree tries all predictors at each split, whereas trees in RF only try a random subset of the predictors at each split (this creates independent trees). Also, each tree in a RF is built on a bootstrap sample of the original training data, rather than on the full training set. This makes each tree in the forest an expert on some domains of the data space, and bad elsewhere. So, for these reasons, it makes no sense to extract a single tree from a Random Forest in order to use it as a classifier. Depending on its domains of expertise, it could give you better results than a traditional tree built with CART on the full dataset, or much worse. The thing that allows a RF to be much better than a single tree is that it grows many decorrelated trees and averages their output. Only when the committee of experts comprises enough members (usually between 200 and 2000) is variance reduced. But individually, each tree of a RF would be weaker than a single tree built via traditional CART. You can certainly extract a tree from a RF to get a feel for what's going on in the forest (see the link that I provided in my comment above). Just don't use this single tree as a classifier.
