[site]: crossvalidated
[post_id]: 589090
[parent_id]: 
[tags]: 
Why doesn't adding additional explanatory variables in a logistic regression model decrease our primary explanatory variables variance?

Imagine a clinical trial setting where we have binary outcome Y and we are interested in the effects of treatment X. Lets say we also have additional explanatory covariates Z and W. Thus our logistic regression model is: $$ p_i = Logistic( \mu + X_i + W_i + Z_i ) $$ What's confusing me is that in simulations where you assume Z and W are completely independent of each other (and X) and are randomly distributed their inclusion into the model seems to have no meaningful impact on our variance estimate for the beta coefficient for X. That is the model $$ p_i = Logistic( \mu + X_i) $$ Produces the same point estimate and SE for said estimate. My expectation was that including additional explanatory terms into the model would have reduced the SE as we would be more confident in the value for X as we have controlled for other sources of variability. At least this is what happens in a standard linear model. Simulation code for reference: https://gist.github.com/gowerc/4191a8f7237f1e08c932f4a3ed4a1231 I am curious as to why this is happening ?
