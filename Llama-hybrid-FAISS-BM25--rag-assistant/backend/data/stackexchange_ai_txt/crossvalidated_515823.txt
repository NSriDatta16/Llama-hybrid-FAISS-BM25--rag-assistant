[site]: crossvalidated
[post_id]: 515823
[parent_id]: 515821
[tags]: 
An excellent, approachable review that unifies these approaches is A Unifying Review of Linear Gaussian Models by Roweis and Ghahramani, published in Neural Computation . The first two sentences of the abstract are Factor analysis, principal component analysis, mixtures of gaussian clusters, vector quantization, Kalman filter models, and hidden Markov models can all be unified as variations of unsupervised learning under a single basic generative model. This is achieved by collecting together disparate observations and derivations made by many previous authors and introducing a new way of linking discrete and continuous state models using a simple nonlinearity. While it doesn't go into DBNs, it does cover HMMs, Kalman filters, and Bayesian networks in general.
