[site]: datascience
[post_id]: 26851
[parent_id]: 
[tags]: 
Privacy through moving averages?

I am considering the following hypothetical situation: I have a time series of data. In general, 'the public' should have access to features of this data. However, making the time series available would constitute a privacy leak. I am considering making a moving average available instead. Can anyone recommend either some literature on this, or some alternative methods? I understand that this is a case by case question. However, I think there should be a general answer available along the following lines: 1) Privacy leaks occur because you can match up the time stamp to an individual, by using outside information. 2) Therefore, you want to make it so that each window aggregates the data of several individuals. (The data is of a form where the mean is a meaningful quantity.) There are of course ways to break this privacy, if one is sufficiently determined. I think in this case no one is. So I'm looking for literature that deals with some real world case studies, if possible. (This situation is hypothetical. I do not have access to the data. I am 'the public' that wants the data, and I want to suggest a reasonable approach for aggregation.) I also asked this question over on cross validated: https://stats.stackexchange.com/questions/324204/privacy-through-moving-averages
