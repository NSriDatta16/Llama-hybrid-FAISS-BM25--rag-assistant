[site]: crossvalidated
[post_id]: 367970
[parent_id]: 367639
[tags]: 
An alternative to Romain's answer is to not look at the spectrum as a vector of size $n$ (to me that seems to give too much problems in finding out how the errors will be correlated and how to deal with those correlated errors to compute probability for a class). Instead, you could use some dimension reduction technique and use the result of that to define some lower dimensional feature space. In that space you could perform more easily classification. (indirectly the dimension reduction computes the correlation for errors in the larger space) This method makes sense because you can think of your spectrum as being the linear sum of several features, like presence of certain components, molecules, bonds, or whatever creates the spectrum. PCA is used a lot in analyzing spectra. https://scholar.google.com/scholar?q=pca+spectrum+classification
