[site]: crossvalidated
[post_id]: 621384
[parent_id]: 1
[tags]: 
I've had training in and used the SHELF framework , which does do some of the good things other responses have already mentioned. Many good practices are discussed in the materials available from the SHELF webpage and also this book on Eliciting Experts' Probabilities . Why am I writing another answer, when there's already other goods ones mentioning many good points? The main reason is that what's not mentioned much, yet, is the multivariate nature of the problem, which I think you cannot ignore. The issue is that "prior distributions from experts when fitting a Bayesian model" would usually require you to obtain prior distributions for multiple model parameters. It turns out that you should not elicit priors for e.g. each coefficient of a regression model independently. You may get a sensible marginal prior for each coefficient, but you still end up with a combined prior belief that makes no sense and that you would reject. The reason is that extreme values in the independent priors on multiple coefficients "can combine" so as to assign way too much prior density to predicted outcomes that are almost impossible. Prior predictive checks certainly seem to be a good tool for getting a feeling for whether there is a problem in this respect. To resolve this potential problem, it seems like one ought to elicit how the prior beliefs about different model parameters are correlated. With two parameters this is rather doable ( arxiv link ), but with more parameters it becomes complex (e.g. keeping elicited correlation matrices valid is tricky) and definitely a bit time consuming. In contrast ideas like automatically setting correlation to keep the prior predictive distribution within a range elicited from experts would be easier to implement, but also requires an idea about the distribution of covariates. More importantly, I worry that this might ignore that the experts' beliefs about some coefficients might be much more strongly correlated than for others. If the experts can't really say or don't have any strong beliefs, then this might be a promising idea, because experts probably can say something about the the predictive distribution.
