[site]: crossvalidated
[post_id]: 348097
[parent_id]: 344691
[tags]: 
You have several options: 1) Loading trained model Frameworks like sklearn make it easy to persist the trained estimator to disk, and then to load it up afterwards. One would distribute a Python script which uses the trained model, as well as doing any data pre and post-processing. The training data is then not needed. From the sklearn documentation : Training from sklearn import ensemble, datasets from sklearn.externals import joblib iris = datasets.load_iris() X, y = iris.data, iris.target clf = ensemble.RandomForestClassifier() clf.fit(X, y) joblib.dump(clf, 'rf-model.pkl') Predictions from sklearn.externals import joblib clf = joblib.load('rf-model.pkl') clf.predict(Xnew) Implementations of Random Forest will have a way to get the trained cofficients, but the details vary a lot. Fundamentally a Random Forest classifier is a number of trees. Each tree does classification by executing a bunch of if-else statements, each checking whether one of the variables is below. At the leaf is the returned class label. The trees are combined using (weighted) majority voting. 2) Generating code Using emtrees one can export random forests trained with sklearn as C code. A bit simplified, it looks like: int32_t digits_predict_tree_0(int32_t *features, int32_t features_length) { if (features[36] The same could be done for other languages, theoretically even an Excel macro. 3) Providing webservice A modern alternative is to set up a simple webservice where users can drop their input data (as .CSV/.xsl), and then download the returned predictions as a new file.
