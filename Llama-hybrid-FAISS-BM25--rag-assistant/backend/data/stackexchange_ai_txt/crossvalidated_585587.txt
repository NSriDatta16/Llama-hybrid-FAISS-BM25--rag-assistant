[site]: crossvalidated
[post_id]: 585587
[parent_id]: 
[tags]: 
Why does the CNN model accuracy vary too much when the dataset is the same?

I have been working on a project where I have a lot of time series data(3000 csv file) from 6 different devices and I am trying to convert those data to an image array so that I can use them in CNN to do a classification task. My goal is to train the model with existing data and then predict from which device the data came from. As the first experiments, I have decided to classify between two devices and picked 100 files each from both devices. I have converted all the data to an image array and it looks like the following image: below is the code to convert them to image array and my CNN model #Converting to numpy array X = np.array(device_list) y = np.array(device_label) #Train test split from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.30,random_state=0) #Adding 1 dimension for grayscale image X_train = X_train.reshape(X_train.shape[0],14,100,1) X_test = X_test.reshape(X_test.shape[0],14,100,1) #scaling data from 0 to 1 X_train_scaled = X_train/36 #Max voltage value 36 X_test_scaled = X_test/36 #Buiding a model model_2 = tf.keras.Sequential([ tf.keras.layers.Conv2D(filters=3, kernel_size=3, strides=1, padding="same", activation="relu",input_shape=(X_train_scaled[0].shape)), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Conv2D(6,3, padding="same", activation='relu'), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Conv2D(12,3, padding="same", activation='relu'), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(72, activation='relu'), tf.keras.layers.Dense(36, activation='relu'), tf.keras.layers.Dense(2, activation= 'softmax') #Output layer ]) #Training the model model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) model_2.fit(X_train_scaled, y_train, epochs=300) #Accuracy and loss loss, accuracy= model_2.evaluate(X_test_scaled, y_test) print(f'Loss: {loss}, Accuracy: {accuracy}') It needs to mentioned here the image size is not square but 14x100 pixel. Each image is of the same size. After adding 1 dimension the shape of the data: The model summary is shown below: In my code I have used sklearn train test split package and used random_state=0 and 42 both. But the problem is I am getting varying range of accuracy starting from 50% to 100% even. If I run the model like 10-15 times then I will almost get varying accuracy from 50% to 100%. Since the my data is same and I have used random_state=0 and 42 which keeps train and test set same for different run, then why I am having such kind of different accuracy. Different accuray: If the accurcy of the model is low, that is not a problem but if the accuracy is not stable that is a problem. Could someone tell me if there is anything wrong with my model, if there is any mistake with the coding or any kind suggestion on how can I fix this issue?
