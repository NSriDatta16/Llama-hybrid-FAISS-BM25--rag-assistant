[site]: crossvalidated
[post_id]: 261882
[parent_id]: 120485
[tags]: 
Psychologists, as well as experiment, have shown people do not produce random numbers--they don't even come close. But there are ways to combine your efforts to produce sequences of numbers that are "more random" than either of you is likely to produce individually. You and your wife can be modeled as "black boxes" that output numbers. To simplify the analysis, we may either ask you both to output only zeros and ones, or else we may force that by rounding your outputs and reducing mod $2$ (that is, looking only at the parity). As such, you each produce sequences of binary digits. In order to make much progress, we have to ensure these sequences average 50% zeros and 50% ones in the long run. People cannot do that on their own without undue mental burden. Unless you are unwittingly regular in your production, though, the simple expedient of inverting every other output (turning a zero into a one and a one into a zero) will accomplish this. Any black box that emits a sequence of bits can be used to emit a sequence of random integers within a given interval $0,1,\ldots,m-1$. For instance, if you select a power of two for $m$, say $m=2^f$, you can just collect the output in non-overlapping blocks of $f$ bits and interpret them in binary. In the following account, think of your output as forming the sequence $X$ and your wife's output as forming the sequence $Y$. In his classic The Art of Computer Programming (Volume 2, section 3.2.2, Algorithm M) Donald Knuth explains There are reasonably efficient ways to combine two sequences into a third one that should be haphazard enough to satisfy all but the most hardened skeptic. Suppose we have two sequences $X_0, X_1, \ldots,$ and $Y_0, Y_1, \ldots$ of random numbers between $0$ and $m-1$, preferably generated by two unrelated methods. Then we can, for example, use one random sequence to permute the leements of another, as suggested by M. D. MacLaren and G. Marsaglia [JACM 12 (1965), 83-89; see also Marsaglia and Bray, CACM 11 (1968), 757-759]: Knuth proceeds to present "Algorithm M." It is simple. You fill a buffer array $V$ of size $k$ (to be selected according to your needs, often around $100$) with the first $k$ elements of $X$. Subsequently, to generate a new random output, you take the next element of $Y$, use it to form a random index $j$ into $V$, output the number $V[j]$ located there, and replace it by the next element of $X$. Knuth remarks, On intuitive grounds it appears safe to predict that the sequence obtained by applying Algorithm M to [an example sequence] will satisfy virtually anyone's requirements for randomness in a computer-generated sequence, because the relationship between nearby terms of the output has been almost entirely obliterated. Furthermore, the time required to generate this sequence is only slightly more than twice as long as it takes to generate the sequence $X$ alone. When computers were much less capable than now and good random number generators were hard to come by (and all of them were suspect), I used to employ this MacLaren-Marsaglia combinator by coding a simple linear congruential generator for $Y$ and using the built-in generator for $X$. Altogether such a program takes under a dozen lines in almost any language. This R code illustrates. I'll end by remarking that Knuth's analysis does not strictly apply to random number generators created by people--but the intuition behind it strongly suggests that combining their output in this way ought to improve the appearance of randomness substantially. # # Combine two pseudo RNGs. # Knuth Vol. II, 3.2.2, Algorithm M: Randomizing by Shuffling. # RNG.combine
