[site]: datascience
[post_id]: 51908
[parent_id]: 
[tags]: 
sklearn FeatureUnion vs ColumnTransformer

I am trying to build a sklearn pipeline which does different transformations on numerical data, and different transformation on categorical data. In the process, I compare the results from ColumnTransformer vs FeatureUnion, and they are not the same. Please advise if the following are equivalent, if not what the problem is. The data is from kaggle https://www.kaggle.com/ronitf/heart-disease-uci from sklearn.model_selection import train_test_split cat_attribs = ['sex','cp','fbs','restecg','exang','ca','thal'] num_attribs = ['trestbps','chol','thalach','oldpeak','slope'] X_train,X_test,y_train,y_test = train_test_split(heart_df,y,test_size=0.25,random_state=100) Approach #1, using column transformer from sklearn.compose import ColumnTransformer ct = ColumnTransformer([('oneHot', OneHotEncoder(categories='auto'),cat_attribs) , ('minMax',MinMaxScaler(),num_attribs)]) ct_result = ct.fit_transform(X_train) Approach #2, using FeatureUnion from sklearn.base import BaseEstimator, TransformerMixin from sklearn.pipeline import FeatureUnion from sklearn.pipeline import Pipeline class DataFrameSelector(BaseEstimator, TransformerMixin): def __init__(self, attribute_names): self.attribute_names = attribute_names def fit(self, X, y=None): return self def transform(self, X): return X[self.attribute_names].values num_pipeline = Pipeline([('selector', DataFrameSelector(num_attribs)), ('minMax',MinMaxScaler())]) cat_pipeline = Pipeline([('selector', DataFrameSelector(cat_attribs)), ('oneHot',OneHotEncoder(categories='auto'))]) full_pipeline = FeatureUnion(transformer_list=[ ('num_pipeline', num_pipeline), ('cat_pipeline', cat_pipeline)]) fp_result= full_pipeline.fit_transform(X_train)
