[site]: crossvalidated
[post_id]: 74202
[parent_id]: 74190
[tags]: 
I can give you a probabilistic/Bayesian interpretation of why this is not helpful. A probabilistic model for data $X$ and parameters $\theta$ is defined by a likelihood $P(X|\theta)$ and a prior $P(\theta)$. Now imagine I have some training data $X_\text{train}$ and want to make predictions about future data $X_\text{future}$, which means I need to calculate, or approximate $$ P(X_\text{future}|X_\text{train}) = \int P(X_\text{future}|\theta) P(\theta|X_\text{train}) d\theta $$ where $P(\theta|X_\text{train})$ is the posterior. What you suggest is to sample predictions $X_\text{pred}$ from $P(X_\text{pred}|X_\text{train})$ (which can be represented in the same way as the above equation). However, since $X_\text{pred}$ is not observed you can integrate it away and your posterior on $\theta$ will be unchanged. Conditioning on $X_\text{pred}$ is therefore not a reasonable thing to do. To speculate on the typical effect it might have: if you sample from $P(X_\text{pred}|X_\text{train})$ then you are both adding noise to your estimate, and reducing the uncertainty in the estimate of $\theta$ (so you would probably be both overconfident and more wrong!), whereas if you optimise $P(X_\text{pred}|X_\text{train})$ I expect the main effect would be reducing the uncertainty in the posterior and thereby making your predictions overly confident (i.e. overfitting).
