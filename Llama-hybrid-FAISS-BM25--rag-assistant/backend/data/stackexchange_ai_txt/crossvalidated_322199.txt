[site]: crossvalidated
[post_id]: 322199
[parent_id]: 
[tags]: 
Understanding Expected Value of observed responses in Regression

I have a quick question about the following is a discussion on the online Penn State Regression methods course: Recall that, in fitting a regression model to data, we attempt to estimate the average—or expected value—of the observed responses $E(y_i)$ at any given predictor value x. That is, $E(y_i)$ is the population regression function. Because the average of the observed responses depends on the value of x, we might also denote this population average or population regression function as $\mu_{Y|x}$ Now, if there is no bias in the predicted responses, then the average of the observed responses $E(y_i)$ and the average of the predicted responses $E(\hat y_i)$ both equal the thing we are trying to estimate, namely the average of the responses in the population $μ_{Y|x}$. On the other hand, if there is bias in the predicted responses, then $E(y_i)$ = $μ_{Y|x}$ and $E(\hat y_i)$ do not equal each other. The difference between $E(y_i)$ and $E(\hat y_i)$ is the bias $B_i$ in the predicted response, i.e $B_i$=$E(y_i)−E(\hat y_i)$ (See "Bias in predicted responses" section here for context). My question here is about the average/expected value of observed responses, $E(y_i)$ that we're talking about. Could someone intuitively explain to me what this means? How can observed y-values in a sample have a "true" population value, or am I looking at it the wrong way?
