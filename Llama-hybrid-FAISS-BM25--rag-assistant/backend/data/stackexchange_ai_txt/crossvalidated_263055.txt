[site]: crossvalidated
[post_id]: 263055
[parent_id]: 263046
[tags]: 
Without getting into the philosophy of what randomness means, no, this is pretty deterministic. But does it matter? Let us recap why you do such things. You typically do it because you want the left out fold to be an unbiased estimate of your generalisation error. So if your aim is to optimise some loss function $\ell(x)$ on you data set $\mathcal{D} = \{x_i\}$, you typically do that because you want to minimize the empirical risk: $$\mathbb{E}[\ell(x)]_{x \sim p(x)},$$ where $p(x)$ is the empirical distribution , representing the source of your data. E.g. if you have a data set consisting of 1000 cat pictures, you can interpret this to be a sample from the distribution that generates cat pictures. We typically approximate the risk by a finite sample $$\mathbb{E}[\ell(x)]_{x \sim p(x)} \approx \frac{1}{|F|} \sum_{i \in F} \ell(x_i),$$ where $F$ is the set of samples in the current fold. Back to your question. Is taking every i'th sample from your data giving you a reliable sample of the generalisation error? That is the case if it is an unbiased sample of your empirical distribution. Whether this is the case is of course tough to answer without knowing where the data comes from. But even if you know where the data comes from, you might just be wrong. To be on the save side, creating $F$ by sampling with replacement from $\mathcal{D}$ is preferred. Additional care has to be taken that the samples you use to select your model (i.e. $\mathcal{D} \setminus F$) have to be independent of the samples you use to evaluate it (i.e. $F$). This can be challenging in some context, e.g. time series. When you train a model to predict stocks, you don't want to just sample randomly with replacement because samples from the same day will be highly correlated.
