[site]: crossvalidated
[post_id]: 191401
[parent_id]: 191394
[tags]: 
Yes, you should perform hyper-parameter tuning on the whole dataset for the best model that was selected by nested cross validation. The reason is you want to make your final model as good as possible (since generally, the more the training data, the better the outcome model). So the following procedure is (after nested cross validation), Do cross validation on the whole dataset using your best model. Choose one best hyperparameter. Train your best model again on the whole dataset using the best hyper-parameter. The model you get is the final model. If the future data distributes the same as your data currently in hand, in average (you do such things many times), your final model should perform better than that shown by the outer cross validation in model selection. This is because it was trained on more data.
