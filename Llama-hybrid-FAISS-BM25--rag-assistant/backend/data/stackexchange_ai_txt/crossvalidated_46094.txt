[site]: crossvalidated
[post_id]: 46094
[parent_id]: 
[tags]: 
Computing posterior distribution of bayesian lasso

I have a model: $$ \mathbf{y} = \mu\mathbf{1}_n + \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon} $$ where $\boldsymbol{\epsilon} \sim N(\mathbf{0},\sigma^2\mathbf{I}_n)$. I have a joint prior: $$ \pi(\boldsymbol{\beta}, \sigma^2, \mu) = \pi(\mu) \pi(\sigma^2) \prod\limits_{j=1}^{p}\frac{\lambda}{2\sqrt{\sigma^2}}e^{-\lambda|\beta_j|/\sqrt{\sigma^2}} $$ where $\pi(\mu) \propto 1$. I want to compute joint posterior $\pi(\boldsymbol{\beta}, \sigma^2, \mu |\mathbf{y})$ and then marginalize out $\mu$. MY SOLUTION: According to me, likelihood function is: $$f(\mathbf{y} |\boldsymbol{\beta}, \sigma^2, \mu) = \frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}} \exp\left( -\frac{1}{2\sigma^2}\parallel \mathbf{y}- \mu \mathbf{1}_n -\mathbf{X}\boldsymbol{\beta}\parallel_2^2 \right)$$ Using the Bayes theorem, I got the conclusion that joint log-posterior is proportional to: $$ \underbrace{\ln[\pi(\mu)]}_{\to \text{const.}} + \ln[\pi(\sigma^2)]-\frac{p+n}{2}\ln(\sigma^2) - \lambda \parallel \beta \parallel_1 \frac{1}{\sqrt{\sigma^2}} - \frac{1}{2\sigma^2}\parallel \mathbf{y}- \mu\mathbf{1}_n - \mathbf{X}\boldsymbol{\beta} \parallel_2^2 $$ HOWEVER, in paper about Bayessian Lasso (2008) written by Park and Casella they got: $$ \ln[\pi(\sigma^2)]-\frac{p+n-1}{2}\ln(\sigma^2) - \lambda \parallel \beta \parallel_1 \frac{1}{\sqrt{\sigma^2}} - \frac{1}{2\sigma^2}\parallel \mathbf{\tilde{y}}-\mathbf{X}\boldsymbol{\beta} \parallel_2^2 $$ where $\mathbf{\tilde{y}} = \mathbf{y} - \bar{y}\mathbf{1}_n$ Can someone tell me, what is the next step which will lead to a nice marginalization of $\mu$ and getting their result?
