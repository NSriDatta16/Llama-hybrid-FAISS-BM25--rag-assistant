[site]: crossvalidated
[post_id]: 347537
[parent_id]: 347530
[tags]: 
I think you have a valid question. To give you a proper answer you will have to understand the probabilistic nature of the problem. In general the problem we are trying to solve is the following: Given data $D$ what is the distribution of hypotheses that explains this data. When we say hypothesis we mean a PDF (at least in this context). And a distribution of hypotheses is a PDF of PDFs, i.e., $p(H | D)$ . $p(H | D)$ is a distribution over hypotheses given $D$ . If we can find this then we can select one among these hypotheses, for example the one with the highest probability, or we may choose to average over all of them. A somewhat easier approach is to attack the problem from a different direction using the Bayes' Theorem. $$p(H|D) = \frac{p(D|H)\times p(H)}{p(D)}$$ $p(D|H)$ is one of the hypothesis, it is also called likelihood. $p(H)$ is the distribution of the hypotheses in our universe of hypotheses before observing the data. After we observe the data we update our beliefs. $p(D)$ is the average of the hypotheses before we updated our beliefs. Now if we take the $-\log$ of both sides of Bayes' equation we get: $$-\log [p(H|D)] = -\log [p(D|H)] -\log [p(H)] + \log [p(D)]$$ Usually $p(D)$ is difficult to calculate. The good thing is it doesn't affect the result. It is simply a normalization constant. Now for example if our set of hypotheses $p(D|H)$ is a bunch of Gaussians with $p(y|X,\theta)\sim N(\theta X,\sigma)$ where we don't know $\theta$ , but assume to know $\sigma$ (or at least assume that it is a constant), and moreover hypotheses themselves are distributed as a Gaussian with $p(H) = p(\theta) \sim N(0,\alpha^{-1} I)$ then plugging everything above looks something like: $$-\log [p(H|D)] = \text{bunch of constants} + \frac{1}{2}(y-\theta X)^2 + \frac{1}{2}\alpha||\theta||^2 + {\rm constant}$$ Now if we minimize this expression we find the hypothesis with the highest probability. Constants don't affect the minimization. This is the expression in your question. The fact that we used Gaussians doesn't change the fact the regularization term is additional. It must be additive (in log terms or multiplicative in probabilities), there is no other choice. What will change if we use other distributions is the components of the addition. The cost/loss function you have provided is optimal for a specific scenario of Gaussians.
