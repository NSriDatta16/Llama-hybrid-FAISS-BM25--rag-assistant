[site]: crossvalidated
[post_id]: 643240
[parent_id]: 643226
[tags]: 
Sextus Empiricus answered your core question very well. However, I think this part deserves more attention: but the model's predictions were all below 0.5 This is not a problem at all, and "addressing" this "issue" will make your model worse. Suppose we are modeling and predicting whether I have an accident while driving on any given day. Thus, the outputs from our logistical regression are the probabilities for such an accident. In good conditions, my probability for an accident might be very low, e.g., 0.0001. In worse conditions, like icy roads, my probability to have an accident might be dramatically higher - but still below 0.5 , like 0.2. (Even on icy roads, most people do not have an accident.) If our model outputs correct probabilities, this is fine! If the model tells me my probability for an accident is 0.9 when it actually is 0.2, then the model is simply wrong! It is important here to note the distinction between the probabilistic model prediction and the subsequent decision. Even if I am more likely not to have an accident on icy roads, it may make sense not to drive today, because if I do have an accident, the hassle is much more painful than the cost of not driving. We operationalize this by using a decision threshold that is different from 0.5 and which accounts for costs of decisions and outcomes. Or we might even use more than one threshold. See Reduce Classification Probability Threshold . Finally, unbalanced data are usually not a problem, and reweighting is similar to over-/undersampling in that it biases your predictions in the way you describe: Are unbalanced datasets problematic, and (how) does oversampling (purport to) help?
