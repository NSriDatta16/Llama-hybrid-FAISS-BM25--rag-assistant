[site]: crossvalidated
[post_id]: 358185
[parent_id]: 355920
[tags]: 
First, I would just fit some black box models (e.g. GBM or random forest) which directly take into account the time variable $T$, e.g. $Y_t=F(X_t^1, \ldots, X_d^t; T)$. It might be helpful to test various granularity of $T$, such as measured in calendar years (2016, 2018), months passed since 2016, etc. Then, in order to assess the importance of $T$ one could either look at variable importance plots (see e.g. Section “15.3.2 Variable Importance” in Elements of Statistical Learning ) or simply drop the $T$ variable, refit the model and compare the model performance. Alternatively, you could stick to your model (Gaussian process) and compare the 2016 and 2018 residuals. I agree with your intuition that the comparison of distribution of in-sample (2016) and out-of-sample (2018) residuals would get misleading results. However, this can be fixed quickly by partitioning your data as follows: split 2016 data into training subset (used to fit the model) and validation subset (used to assess the quality of your model), also define the second validation dataset using subset of 2018 data. Then, just fit your model using training subset and test the performance (calculate residuals, MSE, etc) on two validation subsets (2016 and 2018). In order to rule out chance (your result might differ just because of bad luck) you might want to repeat the whole exercise (splitting data, fitting model, assessing performance on validation datasets) several times. Also, as you mentioned, you could fit two different models (one based on 2016 data, another based only on 2018 data). In this case I would also split the data for each year into training and validation subsets and assess the model performance based on the validation subsets. As a measure of similarity you could use: RMSE, QQ-plots, statistical tests you mentioned or calculating the confidence intervals for predictions coming from both models and checking whether the confidence intervals overlap.
