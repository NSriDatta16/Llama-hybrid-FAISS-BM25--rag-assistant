[site]: crossvalidated
[post_id]: 604640
[parent_id]: 
[tags]: 
In a muddle with Paired Samples t-tests on pre vs during vs post

I have used paired samples t-tests to compare 3x time-point measurements, A/ B/ C. A and B t(102)=4.988 p=.000 A and C t(102)=4.939 p=.000 B and C t(102)=.346 p=.730 A, B, and C were all significant on the Kolmogorov-Smirnov, so none were normally distributed. My understanding is that this is not a problem due to the t-test being robust to normality violations when sample size is above 20. My concern is that these significance results are erroneous due to not having corrected the alpha level via Bonferroni to accommodate the extra (one) comparison, to avoid a higher than 5% chance of a Type I error. Am I wrong? Does the strong p value get me off the hook? I have already written up and submitted my dissertation :( Maybe a Friedman's should have been used. **In response to Glen_b Thanks for your response. I did the dissertation 2 years ago so I'm trying to remember why I didn't do a correction. Would I be correct in saying, a Bonferroni adjustment in this case would be: alpha level divided by number of tests. Therefore is that .05/2=.025? and in that case, even if I were to apply a Bonferroni adjustment, wouldn't my significant results still stand? Therefore making the Bonferroni redundant? I have stated in the text I wanted to avoid Type II error because I wanted to increase the chance of a significant finding (now that I read it it sounds outrageous!).. I had read a paper by Armstrong (2014) who cited Perneger's (1998) six reasons for not doing the Bonferroni. Doesn't it feel illogical to think that doing two separate isolated tests have anything to do with eachother. Isn't it like spinning a roulette wheel twice, in that it starts from scratch each time!
