[site]: crossvalidated
[post_id]: 47638
[parent_id]: 27120
[tags]: 
A summary from this useful discussion at MetaOptimize regarding the general issue of L1 versus L2 regularization: L1 (e.g. Lasso): choose for a sparse model / feature selection as Shea Parkes mentions above, especially when n >> m L2 (e.g. SVM): choose when seeking rotational invariance and there are plenty of samples L1+L2 (e.g. elastic-net): if you want to combine both
