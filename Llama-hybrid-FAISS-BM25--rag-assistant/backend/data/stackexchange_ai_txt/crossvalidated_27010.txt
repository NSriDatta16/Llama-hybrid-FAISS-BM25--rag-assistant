[site]: crossvalidated
[post_id]: 27010
[parent_id]: 27004
[tags]: 
This is explained in Gelman et al (1996) section 2.3 and 2.4. The dependence of discrepancy statistics on $\theta$ is the key generalization over Rubin's (1984) early writing on posterior predictive checks. The posterior predictive p-value will integrate out the $\theta$ using simulations. That's equation 9 in the linked to paper. Specifically, $p_b(y) = \int p(\chi^{2}_n â‰¥ \chi^2(y;\theta)p(\theta | H, y)d\theta.$ Given K simulations, $\theta_k$, calculate the discrepancy statistic for each and check whether it's more extreme than the known $\chi^2_n$ distribution. The posterior predictive p-value is the average of these binary $K$ variables.
