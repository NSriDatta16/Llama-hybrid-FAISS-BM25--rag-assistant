[site]: crossvalidated
[post_id]: 264269
[parent_id]: 264253
[tags]: 
This topic is quite broad, so the answer depends on the kind of data you have (labelled, unlabelled, intersecting labels, partial labels). So, actually I could recommend several approaches. Hope it will help. Assuming you have some kind of unsupervised (like auto-encoders) or semi-supervised CNN and talking about some kind of "context" (compressed features). Learning important features basically means getting rid of noise. The definition of noise depends on the way you regularize or supervise your network (it might be "oversized" features, "changing too fast", "doesn't help classification" etc.), so the the behavior of your CNN. In order to get real-valued outputs you have to use CNN for regression instead of classification - so no sigmoid "outputs" (for context) then. Another option is to encode "levels" of width as classes (if you don't need precise results). So now, you have to extract some meaning from it... In order to return something understandable, the network has to know something about what you actually mean by "meaningful representation". So I guess you need to provide targets for some of your data: you could provide width and other known metrics as a target (you'll have to scale it in advance) you can label existing output features, learned in unsupervised way if they correlate with features of interest. The important thing here is to specify some prior knowledge with regularization (for instance adversarial examples that randomly change irrelevant metrics). if one output-feature represents several features of interest - you can apply ICA (independent component analysis) in order to separate them. If you care about actual objects (want to manipulate with one particular object from your image) - you can subtract feature-vectors (vector-of-interest "minus" vector-extracted-from-irrelevant-data) in order to get only related features. If you don't provide any targets - you'll have to find correlations with real-data manually. If you work with CNN-based classifier and want to know where exactly classified object is on the scene, you'll probably need "Scene Labeling" - it labels every pixel with a class - so you can get a complete "mask" for your object (and simply extract metrics from it). Example of adding labels to pixels: Convolutional Networks in Scene Labelling Another example is cat metrics converted to images . It's based on the adversarial training, so instead of supervision, you could just modify your data in a way that makes features of interest most important.
