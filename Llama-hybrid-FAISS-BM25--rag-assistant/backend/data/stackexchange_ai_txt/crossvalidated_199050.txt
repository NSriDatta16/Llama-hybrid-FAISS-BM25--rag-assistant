[site]: crossvalidated
[post_id]: 199050
[parent_id]: 116858
[tags]: 
You can downsampling or upsampling but these are vary naive approaches. You could try to intelligently sample the data in order to "re-balance" the dataset. However, in any case: imbalanced data is very tricky and requires a lot of domain knowledge. Always measure accuracy with the AUC: This denotes the probability that you can correctly classify a random positive instance and a random negative instance. There is no issue of imbalance here. Coevolution with the genetic algorithm works well. You are evolving sub-models to collaborativley work together to solve the given task at hand. Bayesian methods also work well here. Provided that you have a good prior distribution Honestly - that's the best I can think of. Imbalanced classes are lame.
