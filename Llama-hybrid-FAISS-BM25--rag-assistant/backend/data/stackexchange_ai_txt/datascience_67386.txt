[site]: datascience
[post_id]: 67386
[parent_id]: 67264
[tags]: 
It seems you are working on a regression problem with a strictly positive target and use MAPE as the loss function to train the neural network. This loss function could be the culprit. As illustrated nicely in this answer , minimizing MAPE leads to predictions that are biased towards smaller values. This is a consequence of the asymmetry between errors in the positive and negative directions (negative errors are 100% at worst, while positive errors are unbounded). A possible alternative is to minimize the mean absolute error computed with the logarithm of the target. It will converge to the logarithm of the target's median.
