[site]: crossvalidated
[post_id]: 630552
[parent_id]: 
[tags]: 
Trained network always predicts zero

I have an encoder model and I'm training it with a dataset of signals with size (500,1). The data set is normalized and then used to train the model but the problem is that after the model is trained, the model predicts very close to zero values(from 1e-5 to 1-e11) which does not make sense according to the dataset. I have tried changing the learning rate to smaller and larger values and also trained for more or less epochs, but the problem still holds. Can anyone help me with the issue? This is the model: input_layer = Input(shape=(500, 1)) # Assuming 1 channel (e.g., for time series data) # Encoding layers encoded1 = Conv1D(32, 3, activation='relu', padding='same')(input_layer) encoded1 = MaxPooling1D(2, padding='same')(encoded1) encoded2 = Conv1D(64, 3, activation='relu', padding='same')(encoded1) encoded2 = MaxPooling1D(2, padding='same')(encoded2) encoded3 = Conv1D(128, 3, activation='relu', padding='same')(encoded2) encoded3 = MaxPooling1D(2, padding='same')(encoded3) # Decoding layers (symmetric to the encoding layers) decoded3 = Conv1D(128, 3, activation='relu', padding='same')(encoded3) decoded3 = UpSampling1D(2)(decoded3) decoded2 = Conv1D(64, 3, activation='relu', padding='same')(decoded3) decoded2 = UpSampling1D(2)(decoded2) decoded1 = Conv1D(32, 3, activation='relu', padding='valid')(decoded2) decoded1 = UpSampling1D(2)(decoded1) output_layer = Conv1D(1, 3, activation='sigmoid', padding='same')(decoded1) # 1 channel for reconstruction # Create the autoencoder model autoencoder = Model(input_layer, output_layer) # Compile the autoencoder autoencoder.compile(optimizer='adam', loss='mean_squared_error') And this is training the model: model.fit( noisy_train, clean_train, epochs=10, batch_size=32, validation_split= 0.1) model.compile(optimizer='adam', loss='mean_squared_error') model.optimizer.learning_rate = 1e-8 a = model.predict(noisy_train)
