[site]: datascience
[post_id]: 82287
[parent_id]: 56296
[tags]: 
Anomaly detection is often treated as an unsupervised problem (no labels used for training). This can be clustering, density estimation, or one-class classification . For time-series there exists dedicated methods for anomaly detection, such as autoencoders on sliding analysis windows. But it is always smart to try a non-time-series method first, as they are much simpler and usually more familiar. With time-as-context modelling then you can use one of the standard anomaly/outlier models in scikit-learn . Split the time into its components, for example: time_of_day, weekday, weeknumber Depending on model you may want to one-hot-encode the weekday, as it can be seen as an ordinal feature. Alternatively you can split into just is_workday/not (and include holidays also). The choice of time-interval to compute the features on can be quite important to good performance. If there is considerable natural variation, then 5 minutes might be too often. I would consider every 60, 30 or 15 minutes. You can then compute some summary statistics of the measurement points (5 mins or lower), and use those as the features. queries_mean, queries_std, queries_min, queries_max Run one of the above scikit-learn models on these features from historical data get the anomaly scores. Plot the scores as a histogram, and set a threshold on the value to become your decision function for anomaly-or-not. You should also plot the anomaly scores as a time-series, together with the input features and threshold, and see if known anomalies in the past were picked up OK. Aside: It is highly desirable to have/build up a set of labeled anomalies for a validation set and testing set. To do hyper-parameter optimization (like selecting threshold) and estimating
