[site]: crossvalidated
[post_id]: 259679
[parent_id]: 259594
[tags]: 
The OP's question about splines can be generalized as a question about model selection , or re-instantiated in multiple regression where it's called the question of variable selection . In multiple regression, which of several candidate predictors should be included in the "best" model? Or for nested models more generally, which subset of parameters should be included in the "best" model? The answer to this sort of question is not brief, and is addressed by many different methods (in frequentist and Bayesian approaches). One Bayesian approach is to incorporate an inclusion parameter with every parameter of interest. An inclusion parameter is discrete and takes on values of zero or one, and is a multiplier on the corresponding model parameter. Bayesian inference yields the posterior probability that the inclusion parameter is one, that is, the posterior probability of including the corresponding model parameter. It's actually a posterior probability on the joint space of all combinations of parameter inclusions, so it's a posterior probability distribution of inclusions combinations. Unfortunately in practice it can be difficult to do the computations, especially in MCMC, because the chains won't mix well, that is, won't smoothly jump across models. But you can give it a try; see Section 18.4 of DBDA2E regarding variable selection in multiple linear regression for examples and caveats. As I said, this is a huge topic, and I've only suggested one conceptual approach.
