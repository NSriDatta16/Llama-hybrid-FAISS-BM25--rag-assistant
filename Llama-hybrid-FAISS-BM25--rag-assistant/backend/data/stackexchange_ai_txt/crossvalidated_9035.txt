[site]: crossvalidated
[post_id]: 9035
[parent_id]: 8800
[tags]: 
Ok, as far as I see your central question can be summarized in the following way: I transform one feature F in my dataset, but only for those rows where the label is "flower", the rest of the rows remain unchanged. I evaluate NB,C4.5 and Logistic Regression before and after the transformation. The results obtained via NB and C4.5 did not change, but the result via LogisticRegression. Why ? In general, the transformation of values of one feature (and additionally, restricted only to a subset of the data), may cause nearly anything. Imagine for example that one replaces the old value by a constant or values mainly occurring in another class. In this cases the predictive power of the feature may decrease rapidly. On the other hand, if the values do not overlap with the values of F of the other classes before AND after the transformation, the predictive power is not afflicted at all. So in general it is hard to explain your results without knowing the whole dataset + algorithm parameterization/implementation. I wonder on the other hand whether the results differ significantly, given that the flower class only occurs 15 times in 5000. Did you analyse the confusion matrix ? However, I can provide some hints: NB in my experience is rather robust. So it may that F has less impact because other features have more predictive power and have already sealed the deal ;). You can e.g. calculate InformationGainRatio to estimate the predictive power before and after the transformation. C4.5: Do the trees differ ? If F is not selected as split node or removed during pruning, the results won't be affected at all. If F has been selected it would be interesting to see whether the new split-point can be inverse transformed to get the old splitpoint. Maybe the overlapping of classes at this point (i.e. given the restriction of the dataspace when F is selected as split-node) has not changed. Logistic Regression: My knowledge is not thaaat solid here, in the implementations I used the coefficients are evaluated via an evolutionary approach. Maybe the results differ because it ran into a local minima ? In this case on can rerun the learner multiple times (before and after the transformation) to see if/how the results change. Regarding the second question: Since the two questions differ extremely, I recommend to open a new question for IDS. Meanwhile you may some of these links interesting.
