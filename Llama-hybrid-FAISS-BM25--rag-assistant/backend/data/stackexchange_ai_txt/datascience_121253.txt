[site]: datascience
[post_id]: 121253
[parent_id]: 
[tags]: 
Ordinal logistic regression prediction and accuracy using statsmodels

I am trying to do a ordinal logistic regression analysis using statsmodels. However, the predictions I'm getting are vastly different from that I get when using SciKit-Learn LogisticRegression . I'm using a dataset similar to the following. The aim is to predict the quality (on a scale of 1-10 ) based on the composition of chlorides and sulphates . chlorides sulphates quality 0.076 0.56 5 0.098 0.68 5 0.092 0.65 5 0.075 0.58 6 0.076 0.56 5 ... ... ... The code I'm using: import numpy as np from sklearn import metrics from sklearn.model_selection import train_test_split from statsmodels.miscmodels.ordinal_model import OrderedModel y = df['quality'] X = df[['chlorides', 'sulphates']] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=20) mod_probe = OrderedModel(y_train, X_train, distr='logit') res_log = mod_probe.fit(method='bgfs') predicted = res_log.model.predict(res_log.params, np.array(X_test)[:, None]) predicted sample: array([[[0.00394536, 0.02194635, 0.32950146, 0.47302334, 0.15847723, 0.01310626]], [[0.01405662, 0.07326043, 0.57761266, 0.2806573 , 0.05073693, 0.00367607]], [[0.02683372, 0.12930636, 0.63716285, 0.17780338, 0.02698959, 0.0019041 ]], ..., When I do metrics.accuracy_score(y_test, predicted) I get the error ValueError: Classification metrics can't handle a mix of multiclass and unknown targets I have done many hours of searching on this but can't seem to crack it. Any help would be highly appreciated. Many thanks.
