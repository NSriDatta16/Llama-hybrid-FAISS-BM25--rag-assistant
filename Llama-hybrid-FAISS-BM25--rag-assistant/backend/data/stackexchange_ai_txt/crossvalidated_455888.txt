[site]: crossvalidated
[post_id]: 455888
[parent_id]: 
[tags]: 
Bayes' Theorem: modeling conditional probabilities of some event given aggregated data, using multiple factors

I want to determine the likelihood someone purchases my product, given three binary inputs: whether the prospective buyer is female, has an income above $75k, and owns a cat. However, I only have aggregated data on my sample, so data like this, in a sample of 1,000 individuals: Rate of females (females who purchased): 53% (75%) Rate of income above $75k (income above $75k who purchased): 24% (50%) Rate of cat ownership (cat owners who purchased): 10% (5%) The overall event rate (purchasing my product) is 10%. I want to use these priors to estimate at an individual level whether someone will buy my product. If I had independent and dependent variables at an individual level, I would just use a logistic regression (or some other classification model). However, since these data are aggregated, I'm thinking I'll have to use something like Bayes' Theorem to "back into" a logit model. I want to model this simple example and extend the approach to all possible combinations of these binary inputs in my "dataset": P(purchase | female & income above $75k) . I don't think the solution to this problem is as simple as P(purchase | female) * P(purchase | income above $75k) = 0.75 * 0.5 = 0.375 , is it?
