[site]: crossvalidated
[post_id]: 251079
[parent_id]: 249881
[tags]: 
Your questions "I want to know if it's possible to run the optimization on only a small part of the dataset to improve the runtime?" As usual: "depends on the data". If you do this, try to make the smaller sample so that it has a similar distribution of labels ("stratified sampling"). This is a valid approach and can work well if your subset is sampled well. "Also are the kernel parameters have any correlation with the C parameter? is it possible to firstly tune the C parameter and only after one was found continue and optimize the kernel parameters?" I cannot give you a perfectly qualified answer here, but i know from personal experience: The C-parameter can have a big impact on the runtime (assuming a fixed epsilon here). So if you did a full run once, you could at least remember some rough bounds for the C-value per kernel. Maybe you could avoid some "obviously unnecessary" combinations this way. Bayesian Optimization You could try Bayesian optimization [*]. The speedup will be greater, the more hyperparameter combinations (Kernal / C / epsilon) you have. The more combinations, the more crossvalidations have to be performed. Bayesian optimization attempts to minimizes the number of evaluations and incorporate all knowledge (= all previous evaluations) into this task. Minimizing the number of evaluations also means fewer crossvalidations. So this is probably what you want. There is even an implementation available (**) with Jasper Snoek, first author of the mentioned paper, involved (i do knot if the other authors are involved as well). *: https://arxiv.org/abs/1206.2944 **: https://github.com/JasperSnoek/spearmint Disclaimer: I have studied this for the last few weeks and am really enthusiastic about this ;) I also have experience with SVMs, unfortunately i have not tried both BO and SVM in combination.
