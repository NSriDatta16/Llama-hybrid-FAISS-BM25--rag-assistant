[site]: crossvalidated
[post_id]: 434813
[parent_id]: 
[tags]: 
How to conduct the derivation/proof from the general version of chain rule to the Conditional Independent version?

I am aware of the general chain rule for random variables ${\displaystyle {\begin{aligned}\mathrm {P} (X_{4},X_{3},X_{2},X_{1})&=\mathrm {P} (X_{4}\mid X_{3},X_{2},X_{1})\cdot \mathrm {P} (X_{3},X_{2},X_{1})\\&=\mathrm {P} (X_{4}\mid X_{3},X_{2},X_{1})\cdot \mathrm {P} (X_{3}\mid X_{2},X_{1})\cdot \mathrm {P} (X_{2},X_{1})\\&=\mathrm {P} (X_{4}\mid X_{3},X_{2},X_{1})\cdot \mathrm {P} (X_{3}\mid X_{2},X_{1})\cdot \mathrm {P} (X_{2}\mid X_{1})\cdot \mathrm {P} (X_{1})\end{aligned}}}$ this CMU Machine Learning Course gives this form, with Conditional Independence assumption How to conduct the derivation/proof from the general version to the Conditional Independent version pointed out by red rectangle?
