[site]: datascience
[post_id]: 70039
[parent_id]: 
[tags]: 
Clarifying Probability Mass Function (PMF)

I am currently reading Deep Learning book , and I want to get better understanding of probability theory. In chapter 3.3.1 of Deep Learning book it states that: Often we associate each random variable with a diï¬€erent probability mass function and the reader must infer which PMF to use based on the identity the random variable, rather than on the name of the function;P(x) is usually not the same as P (y). And not many paragraphs latter, it saids the following: Probability mass functions can act on many variables at the same time. Such a probability distribution over many variables is known as a joint probability distribution.P(x=x, y=y) denotes the probability that x=x and y=y simultaneously. We may also write P (x, y) for brevity I am having hard time grasping these two paragraphs. What do they mean when they say that P(x) is USUALLY not the same as P(y) . As I understood, random variable is basically a random phenomenon from a real world that we wish to model. And each random phenomenon has its own Probability Mass function. Does this mean that the first paragraph indicates that random variable y represents a different phenomenon, and in the second paragraph random variable y represents the same type of phenomenon as x and that is why we use the same probability mass function? Thanks in advance!
