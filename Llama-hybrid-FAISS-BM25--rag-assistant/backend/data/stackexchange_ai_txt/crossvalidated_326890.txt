[site]: crossvalidated
[post_id]: 326890
[parent_id]: 326876
[tags]: 
Although I am no expert on NLP, I believe you could use a fully convolutional network followed by a max-pooling operation. The big advantage of FCNs is that they can work with arbitrary input sizes, so it does not matter how long the input sentence is. I don't know the details of the network architecture you are referencing, but I suppose it contains some conv layers followed by a fully connected ones. In that case, you can use the conv layers you already have and then add a 1x1x4 conv-layer (the kernels are representing classes 'contains-yes', 'does-not-contain-yes', 'contains-no', 'does-not-contain-no') and some global max pooling aggregating the information from the whole sentence. Then using a separate softmax on 'yes' channels and 'no' channels, you can get a probability that the sentence contains 'yes' and 'no'.
