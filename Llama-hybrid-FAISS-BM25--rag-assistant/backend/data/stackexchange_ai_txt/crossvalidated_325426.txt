[site]: crossvalidated
[post_id]: 325426
[parent_id]: 
[tags]: 
Value of relative importance metrics vs. beta coefficients of multiple linear regression

I am using multiple linear regression to analyze the significance and impact that independent variables can have on a dependent variable. After selecting my ideal model, I am able to determine the associated beta coefficients for my model. I understand the interpretation of these values ("for every 1 unit increase in IV - holding all other IVs constant -, this corresponds to a Y increase in the DV"). These results will also output the R^2 value which tells me how variation these IVs are able to account for. The workflow that I run also encourages me to run a relative impact analysis. I use the R relaimpo package to do so... My question is the following: Why do I care how much each of the IVs can explain R^2? I do not understand their application (in a business setting), nor do I understand what value they provide to me for critiquing my model. As an example - if a statistically significant IV has a high impact (i.e. for every 1 point increase in satisfaction, this corresponds to $50 additional spend), how should I interpret the importance of this statistic if it only corresponds to a relative importance analysis that shows that this IV only accounts for
