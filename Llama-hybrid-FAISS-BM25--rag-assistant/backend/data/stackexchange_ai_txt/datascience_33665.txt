[site]: datascience
[post_id]: 33665
[parent_id]: 33622
[tags]: 
Debugging neural networks is quite an empirical task. Have you tried one of the following techniques: Reducing the number of layers, neurons of your neural networks. The logistic regression model has 39 features to optimize while given the shape of your artificial networks has 40*48 + 49*48 + 49 * 2 = 4370 parameters. Adding some regularization such as dropout. One more detail, sigmoid activation functions tend to be less and less used these days. More dynamic activation function such as RELU often give better results. Just one last question to be certain. I suppose your data is not equally distributed between the positive and negative class. Am I right ?
