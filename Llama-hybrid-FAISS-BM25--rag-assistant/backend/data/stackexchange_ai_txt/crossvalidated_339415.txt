[site]: crossvalidated
[post_id]: 339415
[parent_id]: 339401
[tags]: 
In a Bayesian perspective, the predictive distribution is constructed by incorporating a new value of the observable $t_\text{new}$ as a part of the unknowns, hence aggregating it with the parameter $w$. The predictive distribution is thus derived by marginalising over the parameter: $$p(t_\text{new}|{\cal D})=\int p(t_\text{new},w|{\cal D})\, \mathrm{d} w \propto \int p(t_\text{new}|w)p({\cal D}|w) p(w)\, \mathrm{d} w$$ Hence, in the logistic case $$pr(t_\text{new}=1|{\cal D})=\int pr(t_\text{new}=1,w|{\cal D})\, \mathrm{d} w \propto \int pr(t_\text{new}=1|w)p({\cal D}|w) p(w)\, \mathrm{d} w$$or $$pr(t_\text{new}=1|{\cal D})=\mathbb{E}^\pi[pr(t_\text{new}=1|w)|{\cal D}]$$
