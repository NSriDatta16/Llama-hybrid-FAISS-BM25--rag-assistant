[site]: crossvalidated
[post_id]: 407224
[parent_id]: 407212
[tags]: 
I think your problem are the parameters of your SVM-modell. In your example you converge to 176. You can see this by plotting with: val = 0 for (i in 1:400){ val You need to change your gamma values and the cost. In the tutorials they often take easy data samples, but adjusting them is not an easy task. From the python scikit documentation : When training an SVM with the Radial Basis Function (RBF) kernel, two parameters must be considered: C and gamma. The parameter C, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly. gamma defines how much influence a single training example has. The larger gamma is, the closer other examples must be to be affected. .In you example i achieve with gamma = 0.001 and cost = 1000 more reasonable values: fit = svm(Duration.s. ~ DataSizeMB + NumEx + ExCore, data=training_set, type = 'eps-regression', gamma = 0.001, cost= 1000) output: But then another problem occurres. Your values are completly dependent of your datasize, if you try using other parameters, they is nearly no influence. This happens, since the values are in completly different dimensions (check here ) Finding correct gamma and cost values is not an easy task. You can try using GridSearch functions (i think for prediction it's GridSearchCV ) or adjust it manual. Also try to understand the SVM model and how your data behaves in your Model, since this can bring other problems, like i mentioned above.
