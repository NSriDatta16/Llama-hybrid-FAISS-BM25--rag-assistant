[site]: crossvalidated
[post_id]: 485158
[parent_id]: 302725
[tags]: 
Although I am very late to the conversation maybe I can add something helpful: It seems to me that the OP wants to know why (what for) we would need a pooled variability estimate $\hat\sigma_{pooled}$ as a weighted average of two samples (be it variance or standard deviation). As far as I am aware the main practical need for this kind of dispersion measure arises from wanting to compare means of (sub-)groups: so if I want to compare the average nose length for 1) people who did not undergo a gene therapy, 2) people who underwent gene therapy A and 3) people who underwent gene therapy B. To be better able to compare the amount of the mean differences in length (mm) I divide the mean difference, say, $e=\bar x_{Control}-\bar x_{GTA}=30mm-28mm=2mm$ by the variability estimate (here standard deviation). Depending on the size of the square root of pooled variance (pooled standard deviation) we can better judge the size of the 2mm difference between those groups (e.g., $d=2mm/0.5mm=4$ vs. $d=2mm/4mm=0.5$ --> Does gene therapy A do something to the nose length? And if so, how much? When $d=4$ or $2 \pm 0.5mm$ there seems to be a "stable" or "consistent" or "big" (compared to the variability) difference between the mean nose lengths, when $d=0.5$ or $2 \pm 4mm$ it does not seem so much, relatively speaking. In case all values within both groups are the same and therefore there is no variability within the groups, $d$ would not be defined but the interpretation would be $2 \pm 0mm=2mm$ exactly). This is the idea of effect size (first theoretically introduced by Neyman and Pearson as far as I know, but in one kind or another used well before, see Stigler, 1986, for example). So what I am doing is comparing the mean difference between groups with the mean differences within those same groups, i.e weighted average of variances (standard deviations). This makes more sense than to compare the mean difference between (sub-)groups with the mean difference within the "whole" group, because, as you (Hanciong) have shown, the variance (and standard deviation) of the whole group contains the difference(s) of the group means as well. The theoretical need for the measure arises from being able to use the $t$ -distribution to find the probability for the observed mean difference or a more extreme one, given some expected value for the mean difference (p-value for e.g., Null-Hypothesis-Significance-Test, NHST, or Neyman-Pearson hypothesis test or Fisher hypothesis test, confidence intervals etc.): $p(e \ge e_{observed}|\mu_e=0)$ . As far as I know the p-value obtained by the $t$ -distribution (and especially the $F$ -distribution in cases with more than 2 means to compare) will give correct estimates for the probability only when both (or all) samples are drawn from populations with equal variances (homogeneity of variance, as pointed out in the other answers already; this should be described in (more) detail in most statistics textbooks). I think all distributions based on the normal distribution ( $t$ , $F$ , $\chi^2$ ) assume a variance of more than 0 and less than $\infty$ , so it would be impossible to find the p-value for a case with a within variability of 0 (in this case you would obviously not assume to have drawn your sample from a normal distribution). (This also seems intuitively reasonable: if I want to compare two or more means then the precision of those means should be the same or at least comparable: if I run my gene therapy A on people whose nose lengths are quite similar, say $\bar x \pm 0.5mm$ but have a group of people with high variability in nose lengths in my control group, say $\bar x \pm 4mm$ it doesn't seem fair to directly compare those means, because those means do not have the same "mean-meaning"; in fact the very much higher variance/standard deviation in my control group could be indicating further subgroups, maybe differences of nose lengths due to differences on some gene.)
