[site]: crossvalidated
[post_id]: 600838
[parent_id]: 
[tags]: 
In machine learning, why do we say "curve fitting" when really fit the hypersurface?

Curve and surface are distinct concepts yet they seem to be used interchangeably in the context of model fitting. For a single argument function f(x) the concept of curve fitting is clear. The function defines a curve. So function fitting is curve fitting. However, for a function with multiple arguments f(x1, x2, x3, ...) that we expect to be defined for all domain values (as it is the case in machine learning), I can't see how a curve could do. My understanding is we really fit a hypersurface yet we still say "fitting the curve". Example from "Deep Learning with Python" book: [...] deep learning is about taking a big, complex curve - a manifold - and incrementally adjusting its parameters until it fits some training data points. But then again, manifold is a type of (hyper)surface (in >1D) and curve is a curve. What's going on here?
