[site]: crossvalidated
[post_id]: 632388
[parent_id]: 
[tags]: 
Model test sensitivity to ability

I have a set of tests and a population of agents whose ability I want to assess. Each agent has taken some of the tests. The agents have no memory of the tests they have taken, so each time an agent takes a test it can be treated as an independent sample. The tests' outcomes are binary: zero or one. The tests and the agents are stochastic. At one extreme we can consider a maximally stochastic test, for example the agent flips a coin and is rewarded with one on heads and zero on tails. On the other hand, we could imagine a test in which the agent has to demonstrate some ability to pass. Perhaps half the agents have this ability and so this test's outcome also has maximum entropy. I would like to jointly model the outcomes so as to rank the agents by their overall ability and also to assess which tests are most informative for this ranking. I'm thinking of a model where each test $t$ has a difficulty $\theta_t$ and each agent $a$ has an ability $\phi_a$ . Now I can model the outcome of the $i$ 'th time agent $a$ takes test $t$ as Bernoulli $(\sigma(\theta_t + \phi_a + c))$ where $\sigma$ is the sigmoid function and $c$ is some intercept. However this model ignores how sensitive the outcome of the test is to the agent's ability. Perhaps a better model would incorporate this as Bernoulli $(\sigma(\theta_t + \gamma_t \phi_a + c))$ where $\gamma_t \ge 0$ models this sensitivity. In any case, I suppose I can fit models such as these (modulo any identifiability issues) but before I break out Stan (or similar) I was wondering if there are any existing models or packages for this sort of data. I did not find any with a quick search. Also I would be curious to learn if the models I sketched above are sensible or if there are simpler, easier, or better ways to rank the agents and the tests.
