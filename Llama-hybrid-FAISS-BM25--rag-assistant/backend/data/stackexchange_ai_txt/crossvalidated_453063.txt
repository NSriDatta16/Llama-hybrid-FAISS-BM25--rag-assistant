[site]: crossvalidated
[post_id]: 453063
[parent_id]: 453042
[tags]: 
Regarding terminology, you are working with the "objective function" of neural networks, i.e., the equation(s) that reveals how well a network works, as well as how the error is minimized and learning accomplished. "Loss functions" and cost functions are objective functions. Don't get tripped up by the comment that mentioned ReLU, since that evokes a highly-specific type of "activation" function in neural networks, which you are not interested in for this question. For neural networks, cross-entropy error is typically recommended as the loss function (objective function) for classification problems, while mean-square-error (MSE) is recommended for function approximation (predicting a specific outcome value) like regression analysis. Any neural network book by Christopher Bishop will help navigate through the learning.
