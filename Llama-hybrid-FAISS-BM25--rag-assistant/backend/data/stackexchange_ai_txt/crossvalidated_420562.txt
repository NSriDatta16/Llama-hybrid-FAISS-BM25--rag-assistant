[site]: crossvalidated
[post_id]: 420562
[parent_id]: 
[tags]: 
Stop-gradient operator in VQ-VAE

In the vector-quantized variational autoencoder (VQ-VAE), the objective function (Eq. (3) here ) contains $$\left\lVert \mathrm{sg}[z_e(x)] - e \right\rVert^2 + \left\lVert z_e(x) - \mathrm{sg}[e] \right\rVert^2,$$ where $\mathrm{sg}$ is the stop-gradient operator. (Note: The second term can have a weighting factor $\beta$ , but "the results did not vary for values of $β$ ranging from $0.1$ to $2.0$ . We use $β = 0.25$ ", so let's assume $\beta=1$ .) What are the advantages of this objective over directly optimizing $$\left\lVert z_e(x) - e \right\rVert^2$$ instead?
