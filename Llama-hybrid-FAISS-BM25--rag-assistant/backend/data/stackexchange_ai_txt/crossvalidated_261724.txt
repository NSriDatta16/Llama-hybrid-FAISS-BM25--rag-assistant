[site]: crossvalidated
[post_id]: 261724
[parent_id]: 233129
[tags]: 
To clarify, one uses classification for predicting categorical responses, and regression for predicting quantitative responses. This is 100% a function of the response you're trying to predict - and often, this goes without saying - in SAS Enterprise Miner, if you use a regression node, it automatically goes with either linear or logistic depending on the target of interest (as, when adding the data source, it was set to be either quantitative or categorical). Attempts to use classification for a quantitative variable aren't necessarily ideal because you get a discrete response at the end - there are simply point estimates for various subsets, when intuitively, you want a continuous function of variables. Attempts to use (linear) regression for categorical responses break down in short order - let's suppose in your example you've coded the response to 0 and 1 - well, what happens if your model predicts values like -1, 0.5, or 2, values that make absolutely no sense in this case? As far as regression is concerned, we can resolve this by using logistic regression instead of linear regression - but now we're predicting the probability of an event, in your case, buying a car. To answer your first specific question - it's not that classification is better than regression in that case, so much as regression is either invalid or answers 'the probability of' rather than 'yes or no'. In this fashion - asking between classification or regression for time series or any other variant of data coming in as a predictor is entirely pointless. Similarly, algorithms can be used for either regression or classification - I've mentioned the case with linear vs. logistic regression - but here's a treatment with support vector machines . Here's another with neural networks. You can't generally say that any given algorithm is generally better - all you can do is run them all in a given case and compare on some measure.
