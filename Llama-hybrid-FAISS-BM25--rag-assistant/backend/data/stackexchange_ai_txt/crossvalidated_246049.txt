[site]: crossvalidated
[post_id]: 246049
[parent_id]: 
[tags]: 
Repeated Measures ANOVA for different parameter combinations/methods and their combination

I am going to donduct an experiment in the field of Biomedical Engineering/Brain Computer Interfaces, i.e., the detection of specific different "patterns" in the electroencephalogram, so-called "event-related potentials" (ERPs) using signal processing (SP) and machine learning (ML) techniques. There are various different ERPs that can be detected in the eeg. However, every ERP requires the application of different SP/ML methods to obtain an optimal classification accuracy. The actual goal is to combine the detection of different ERPs in a specific application. Accordingly, the evaluation is divided into two parts: 1) find the optimal combination of SP/ML methods for a specific ERP 2) test if the combination of the detection of different ERPs results in a better application performance than the usage of a single one. The data has been previously acquired and is stored in a database. I compare the methods and combinations on this data. Accordingly, I use a repeated measures ANOVA for comparison of the results. For eample, if I have the ERPs $E_1$, $E_2$, $E_3$. The different SP/ML method combinations are $M_1^1, \ldots, M_1^n$ for $E_1$, $M_2^1, \ldots, M_2^m$ for $E_2$, and $M_2^1, \ldots, M_2^k$ for $E_3$. Part 1) would be to find the optimal $M_1^*,M_2^*,M_3^*$ Part 2) would be to compare the combinations of methods $\{M_1^*,M_2^*\},\{M_1^*,M_3^*\},\{M_2^*,M_3^*\},\{M_2^*,M_2^*,M_3^*\}$ with each other and the single optimal methods $M_1^*,M_2^*,M_3^*$. Is it legitimate to do the statistical comparison in two separate evaluations as well? I.e., perform an rANOVA and the corresponding post-hoc tests to determine $M_1^*,M_2^*,M_3^*$, and subsequently another rANOVA for part 2?
