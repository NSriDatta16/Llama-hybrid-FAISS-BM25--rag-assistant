[site]: datascience
[post_id]: 74113
[parent_id]: 
[tags]: 
Is it necessary to transform data to normal distribution when removing outliers for xgboost?

sorry if this is statistics 101 but i cannot find a similar question. I am wanting to use xgboost to classify my data in two classifications. my data is numerical (financial statement data) and i can see that the distributions for each numerical column is very skewed. there is a need to remove outliers for xgboost (since based on residuals) so i would like to remove them. my intended method is as follows: 1) transform all columns to normal distribtuon using box cox (not log transform as i have some negative fieds in my columns e.g. -4567. 2)remove outliers using quantile based method.. does the above seem along the right lines? note i know in practice you should not drop outliers but surely this depends on your model. since xgboost fits a loss function on the residials i think it makes sense to remove these values.
