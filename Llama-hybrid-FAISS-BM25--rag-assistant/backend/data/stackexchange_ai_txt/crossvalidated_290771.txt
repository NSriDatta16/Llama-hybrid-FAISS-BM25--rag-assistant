[site]: crossvalidated
[post_id]: 290771
[parent_id]: 290736
[tags]: 
If I had to guess what you were asking I would say that you claim to have read in some source that random forest does not perform optimally on a dataset which shows symptoms of multicollinearity. You have built a similarity matrix using Manhattan distance in order to filter out features which are "too close", and you are wondering whether this is the best method to get rid of those highly correlated variables. Am I right so far? First things first: I don't know what you've read and where but there is nothing in the Random Forest algorithm (nor simple CART) which can theoretically have its performance affected by highly correlated features. In practice, though, you may need to fine tune hyperparameters (such as the number of trees in the forest) to make up for the added variance that highly correlated variable may introduce to the model in the form of noise. If you keep a large number of trees, this should not be an issue. Secondly, if you really need to remove highly correlated variables then your approach of using the L1-norm is completely wrong as it does not really measure correlation to begin with. In order to do this right you may either: perform univariate linear regression between all features to assess the statistical significance of their pairwise correlations apply a multivariate method for dimensionality reduction such as principal component analysis. I would go for the second method.
