[site]: crossvalidated
[post_id]: 367272
[parent_id]: 
[tags]: 
Difference between Mean/average accuracy and Overall accuracy

I just got confusion while reading the paper "Local Binary Pattern-Based Hyperspectral Image Classification With Superpixel Guidance". They mentioned that they repeated each experiment 10 times and calculated both mean and standard deviation. after that they also mentioned they calculated overall accuracy. in the results they mentioned mean and std accuracy of each class and then overall accuracy. What is the difference between average/meanMean and overall accuracy? isn't should be same? Table where mean accuracy of each class is calculated I found this link that explain about different method to accuracy . Is the sensitivity calculated in that method for each class is same as mean accuracy? An example confusion matrix to calculate Class Accuracy and Overall Accuracy: According to the references given in answer mean accuracy can be calculated as: Mean Accuracy of Class N: 1971/ (1971 + 19 + 1 + 8 + 0 + 1) = 98.55% Overall accuracy = (1971 + 1940 + 1891 + 1786 + 1958 + 1926) / (2000 + 2000 + 2000 + 2000 + 2000 + 2000) = 95.60
