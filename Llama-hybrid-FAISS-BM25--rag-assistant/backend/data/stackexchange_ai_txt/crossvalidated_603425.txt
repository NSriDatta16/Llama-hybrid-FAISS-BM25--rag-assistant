[site]: crossvalidated
[post_id]: 603425
[parent_id]: 
[tags]: 
Possibility priors in Bayesian analysis?

A couple of trains of thought have come together for a model I am designing. Let's start with the first part: Bayesian inference doesn't update strongly enough. One of the parameters $\theta$ is an angle on a unit circle. For a standard Bayesian treatment I would pick a weakly-informative prior over $[0,2\pi)$ , but I think I should be able to do better than that in this case. The system I am studying has a physical constraint in which the possible angles will always fall within an interval $\theta \in [a,b]$ where $b-a = \pi$ . I could include a parameter representing a translation of $[0+\tau, \pi + \tau]$ , but the Bayesian update is not aggressive enough. There will be a very small uncertainty in $a$ and $b$ due to measurement error, and anything outside of this interval is (in the context of this system) obviously a physical impossibility. On the one hand, I actually don't know ahead of time which interval $[a,b]$ it will be. But once I take measurements of $[a,b]$ it becomes quite obvious that either of the above choices do not adequately account for the obvious impossibility of the parameter being outside of $[a,b]$ . This brings us to the second part: prior possibility. Ben's post introduced me to the idea of possibility measure. In this question I would like to consider a classic possibility measure . Analogous to putting scientifically justified prior probabilities on parameters in a Bayesian context, I am hoping to choose priors on possibilities. Declaring before seeing data that there will be impossible values for $\theta$ is what I want to argue to justify the following approach: I would like to use a truncated normal distribution for $\theta$ and priors on the interval $[a,b]$ representing a teeny-tiny measurement error ( $\epsilon_c \sim \mathcal{N}(\mu_c, \sigma_c)$ where $c\in\{a,b\}$ ) in those boundaries. A subtly here is that it really is impossible for $\theta$ to be outside of $[a,b]$ , but $[a,b]$ are not known perfectly. The less standard aspect of my thinking here is to directly set $\mu_a$ and $\mu_b$ to be set to the observed values of $a$ and $b$ . This is kind of an empirical Bayes method , but I am wondering if there is a way to formalize this choice explicitly in terms of a prior classic possibility measure.
