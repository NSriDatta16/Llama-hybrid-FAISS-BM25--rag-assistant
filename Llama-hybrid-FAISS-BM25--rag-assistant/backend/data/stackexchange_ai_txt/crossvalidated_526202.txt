[site]: crossvalidated
[post_id]: 526202
[parent_id]: 
[tags]: 
How are parameters in graphical models learnt?

This is a request of a good reference. I wanted to have a better understanding of graphical models and I am reading "Pattern recognition and machine learning" of Bishop. chap. 8 (Graphical Models). It spends a long time talking about Bayesian nets and markov random fields, as a way to build "structured" density functions for multidimensional random variables. Than it discusses a lot inference algorithms, like sum-product algorithm, etc. . Inference algorithms are very useful to read/compute expectation values/correlations/... out of the fitted density once the parameters of the Bayesian Nets or of the markov random fields are fixed. But the book does not say much about how one learns the parameters. Is there a standard way to do this for graphical models ? Is there a good reference ? Thanks a lot,
