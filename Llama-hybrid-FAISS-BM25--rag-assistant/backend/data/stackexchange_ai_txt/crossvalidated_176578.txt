[site]: crossvalidated
[post_id]: 176578
[parent_id]: 
[tags]: 
Separation of points clouds via classification methods

I have multiple images from a 3D-Scanner in point cloud form. Part of the image is a fixture to hold the object to be scanned. I want to extract the object itself by classifying the fixture and the object in two separate classes = estimating a discriminant hyperplane, that cuts the cloud exactly at the points where the fixture touches the object. 2D Image of an SVM estimation (via the excellent klaR package) as an example: Some bullet points about the external conditions: The objects vary in shape and size. The position of the fixture varies a bit between images, since it is flexible The origin of the images varies, since the calibration is sometimes off (due to temparature changes etc.) The problem resulting from this : The absolute position of an estimated hyperplane is the same, independent of the data. The point, where the point cloud of the object ends and the point cloud of the fixture begins, varies, but this is the point where the hyperplane is needed in every picture. Optimally, they would change position dependent on the data. Some bullet points about what i have tried so far: Despite knowing I exclude myself from excellent libraries such as PCL, I use R Clustering works rather badly, since the point where the fixture touches the object is too large so it separates them not very well. LDA, QDA, RPart, KNN and SVMLight give me between 70-90% accuracy when comparing to a manual classification, when centering and standardizing the images by themselves My Question(s): What would you propose could be done about the fix hyperplanes? Do you think one could derive some sort of parameter from the image so the planes will be moved accordingly? Is there maybe another Discriminant analysis method, that would be better suited here, preferrably with an R implementation? Is there a feature that i should calculate, that could help me in the separation when added as a discriminating variable?
