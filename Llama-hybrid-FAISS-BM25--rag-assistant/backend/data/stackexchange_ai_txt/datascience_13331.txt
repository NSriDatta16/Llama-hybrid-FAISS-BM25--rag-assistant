[site]: datascience
[post_id]: 13331
[parent_id]: 
[tags]: 
Random Forest where objective is not to replicate past classifications

Normally when I train a random forest to classify observations into multi-class buckets the objective is to correctly predict which bucket an observation will fall into based on historical (training) data. Instead, I want to train the random forest to classify observations on some other criteria, such as profit maximization. Is this possible? Here's an example: Imagine that we have data on Dropbox subscriptions over the past 1 year. Some Dropbox leads (potential customers) had 1 of 3 possible coupons, other leads did not have a coupon. In this scenario I want to determine which (if any) coupon I should should offer to a lead to maximize net revenue, considering their likelihood of purchasing a subscription, their predicted retention (# of months they will continue their subscription) and the effect of the coupon on purchase price. Theoretically some leads who are likely to purchase a subscription and be retained will not need a coupon to do so. Others might produce higher net revenue from a coupon for "$5 off per month" or "first month free", etc. I presume the dependent variable should still be coupon type, i.e. Y = No Coupon, Coupon A, Coupon B, Coupon C, Coupon D Is it possible to make the random forest work in this way? You can consider this question language-agnostic, though if I have a choice I will try to do this in R. I know that in the case of eXtreme Gradient Boosting in either R or Python I can specify a custom objective function.
