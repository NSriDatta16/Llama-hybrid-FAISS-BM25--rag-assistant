[site]: crossvalidated
[post_id]: 455710
[parent_id]: 
[tags]: 
Bayesian prior update feedback

Consider a standard Bayesian MCMC inference problem with $\theta_n$ free parameters. I know very little about their distributions, so I solve using uniform priors. Then I take, for example, the mean and standard deviation of their estimated distributions, and use them as Gaussian priors in a new run. I keep doing this until some stopping condition. I'm certain I'm not the first to come up with this idea, but I can't find the "proper" name for this process. It almost feels like I'm "bootstrapping" my Bayesian setup. Can (should) this be done?
