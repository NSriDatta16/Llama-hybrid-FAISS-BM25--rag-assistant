[site]: crossvalidated
[post_id]: 255469
[parent_id]: 242122
[tags]: 
At worst, the resulting models should still be approximately equal since this is a convex optimization problem. Their paper at JMLR 1 mentions "LIBLINEAR implements a trust region Newton method" for L2-SVM. Reading the guide 2 , in Apendix C.3 the following problem is discussed: C.3 Number of instances â‰« number of features As the number of features is small, one often maps data to higher dimensional spaces (i.e., using nonlinear kernels). However, if you really would like to use the linear kernel, you may use LIBLINEAR with the option -s 2. When the number of features is small, it is often faster than the default -s 1. Consider the data [http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/covtype.libsvm.binary.scale.bz2]. The number of instances 581,012 is much larger than the number of features 54. We run LIBLINEAR with -s 1 (default) and -s 2. \$ time liblinear-1.21/train -c 4 -v 5 -s 2 covtype.libsvm.binary.scale Cross Validation Accuracy = 75.67% 67.224s \$ time liblinear-1.21/train -c 4 -v 5 -s 1 covtype.libsvm.binary.scale Cross Validation Accuracy = 75.6711% 452.736s Clearly, using -s 2 leads to shorter training time. See the cross validation accuracy is approximately the same. So it's mostly a matter of training time. [1] Fan, Rong-En, et al. "LIBLINEAR: A library for large linear classification." Journal of machine learning research 9.Aug (2008): 1871-1874 . [2] Hsu, Chih-Wei, Chih-Chung Chang, and Chih-Jen Lin. "A practical guide to support vector classification"(http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf." (2003).
