[site]: crossvalidated
[post_id]: 490511
[parent_id]: 490506
[tags]: 
This is a lot easier if you make each model explicit. I'll assume id refers to participants. m0 : Intercepts differ between participants, but the effect of A is the same for all participants, and is 0 . m1 : Intercepts and the effect of A differ between participants, and the average effect of A across across participants (the fixed effect) is not necessarily 0 . m1a : Intercepts differ between participants, the effect of A is the same for all participants, and the effect of A is not necessarily 0 . m1 is significantly better than m0 , meaning that either the overall effect of A isn't zero, or the effect of A isn't the same for every participant. m1a isn't significantly better than m0 , meaning that your data are consistent with the overall effect of A being zero. Therefore, it's probably the case that while the overall effect of A is zero, some participants have positive effects, and some have negative effects. This suggests the best model overall would actually be lmer(dv ~ 1 + (1 + A|id), data = df, REML=F)
