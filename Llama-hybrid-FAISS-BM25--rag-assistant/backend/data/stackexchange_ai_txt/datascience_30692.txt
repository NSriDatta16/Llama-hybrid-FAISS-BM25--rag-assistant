[site]: datascience
[post_id]: 30692
[parent_id]: 
[tags]: 
What kind of neural network structure is suitable for image to image learning?

There exists a mapping from input image to out image. Say input image is a piece of paper with a square hole in the center, and output image is the shadow of the input image when light shines on the paper, which also looks like a square, but with some blurs and different in size. (The real pattern is far more complicated than this square hole) I'm trying to implement a neural network that can learning this kind of mapping, when given the input image, the network can predict the "shadow" of the input image. I've tried to use a convolutional autoencoder-like structure (like this https://blog.keras.io/building-autoencoders-in-keras.html ) by replace the target image from the input image it self to the output image training set. But it didn't looks work well. I would like to know what kind of neural network is suitable for this task? And what kind of loss function is suitable?
