[site]: stackoverflow
[post_id]: 5054482
[parent_id]: 5054027
[tags]: 
After the discussions in the comments my proposal would be like so: Create a partition on your data server, about 5GB for safety. Create a Windows Service Project in C# that would monitor your data driver / location. When a file has been modified then create a local copy of the file, containing the same directory structure and place on the new partition. Create another service that would do the following: Monitor Bandwidth Usages Monitor file creations on the temporary partition. Transfer several files at a time (Use Threading) to your FTP Server, abiding by the bandwidth usages at the current time, decreasing / increasing the worker threads depending on network traffic. Remove the files from the partition that have successfully transferred. So basically you have your drives: C: Windows Installation D: Share Storage X: Temporary Partition Then you would have following services: LocalMirrorService - Watches D: and copies to X: with the dir structure TransferClientService - Moves files from X: to ftp server, removes from X: Also use multi threads to move multiples and monitors bandwidth. I would bet that this is the idea that you had in mind but this seems like a reasonable approach as long as your really good with your application development and your able create a solid system that would handle most issues. When a user edits a document in Microsoft Word for instance, the file will change on the share and it may be copied to X: even though the user is still working on it, within windows there would be an API see if the file handle is still opened by the user, if this is the case then you can just create a hook to watch when the user actually closes the document so that all there edits are complete, then you can migrate to drive X: . this being said that if the user is working on the document and there PC crashes for some reason, the document / files handle may not get released until the document is opened at a later date, thus causing issues.
