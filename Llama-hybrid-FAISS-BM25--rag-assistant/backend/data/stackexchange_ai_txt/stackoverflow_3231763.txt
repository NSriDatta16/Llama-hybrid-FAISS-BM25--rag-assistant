[site]: stackoverflow
[post_id]: 3231763
[parent_id]: 3231674
[tags]: 
Set request.Accept = "text/html"; as well and it will work. I don't know why they are configured that way, might be deliberate to discourage some bots. You might want to check their terms of service whether you may query their site automatically. Edited to add: Still convinced that my answer was correct in this case, I can reproduce the 403 every time if I don't set the Accept header. The ContentType is superfluous, but not harmful. In any case, you'll also want to change your function to properly dispose the response, and to read the response with the correct character encoding: void MyFunction(string url) { HttpWebRequest request = (HttpWebRequest)WebRequest.Create(url); request.UserAgent = ".NET Framework Test Client"; request.Accept = "text/html"; Logger.WriteMyLog("application/x-www-form-urlencoded"); // execute the request using (HttpWebResponse response = (HttpWebResponse)request.GetResponse()) { // we will read data via the response stream Stream resStream = response.GetResponseStream(); StreamReader streamReader = new StreamReader( resStream, Encoding.GetEncoding(response.CharacterSet) ); httpData = streamReader.ReadToEnd(); } }
