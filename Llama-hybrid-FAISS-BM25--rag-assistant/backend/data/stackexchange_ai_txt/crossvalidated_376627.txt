[site]: crossvalidated
[post_id]: 376627
[parent_id]: 376522
[tags]: 
I think another way to approach this problem is to model the game as a Markov chain with the following transition probability matrix, $M$ : $$ \begin{matrix} & \text{From state} \\ \text{To state} & {\begin{array}{r|ccccccc} & 0 & 1 & 2 & 3 & 4 & \text{win} & \text{lose} \\ \hline 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 1 & 1/4 & 0 & 0 & 0 & 0 & 0 & 0 \\ 2 & 1/4 & 1/4 & 0 & 0 & 0 & 0 & 0 \\ 3 & 1/4 & 1/4 & 1/4 & 0 & 0 & 0 & 0 \\ 4 & 1/4 & 1/4 & 1/4 & 1/4 & 0 & 0 & 0 \\ \text{win (5)} & 0 & 1/4 & 1/4 & 1/4 & 1/4 & 1 & 0 \\ \text{lose (5+)} & 0 & 0 & 1/4 & 2/4 & 3/4 & 0 & 1 \end{array}} \end{matrix} $$ Note that this is a reducible Markov chain: once we reach the win or lose state, we will be stuck there forever. Our starting state is: $$ v = {\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 \end{bmatrix}}^{\top} $$ Since we know that the game will end after five draws at most, we can calculate the probability distribution over the states after five draws by left multiplying $M$ with the initial state vector $v$ five times: $$ M \times M \times M \times M \times M \times v $$ Implementation in R : library(expm) M Output: [,1] 0 0.0000000 1 0.0000000 2 0.0000000 3 0.0000000 4 0.0000000 win 0.3603516 lose 0.6396484 The probability for the win state is consistent with $\frac{369}{1024}$ . P.S. I do wonder though if there is a way to derive the distributions over the final states analytically without carrying out the matrix multiplications.
