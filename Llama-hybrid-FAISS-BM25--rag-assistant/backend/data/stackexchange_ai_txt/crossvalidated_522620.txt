[site]: crossvalidated
[post_id]: 522620
[parent_id]: 
[tags]: 
Comparing two noisy probability measurements

I have two sampled probability values (sequence P = [p0, p1..pn] and sequence Q = [q0, q1,...qn]. Both of them are evaluated on time t0, t1...tn (equidistant). For simplicity, P is probability that price of a stock will go up in the next tick and Q is the probability that price of a stock will go down in next tick. The data is pretty noisy (sudden spikes in each of those and sudden drops in each of those). P and Q are somewhat negatively correlated (Pearson coeff is -0.10 to -0.2 for example) I am trying to see what would be the ideal way to smooth, remove noise with each of these considering they are probabilities. While simply averaging historical probabilities would be the easiest one, it poses lot of issues because the smoothing window becomes a hyper parameter that would be difficult to be tuned without data leakage. The other area I came across was JS divergence which could potentially be used to avoid areas where P and Q do not diverge enough (but it has not worked for me so far since the JS divergence value tends to small with no clear regions of separation). I would appreciate any pointers to areas that could help here.
