[site]: crossvalidated
[post_id]: 548245
[parent_id]: 
[tags]: 
Using scores instead of unbounded losses to better find weight for regularizers

In machine learning and fitting of statistical models, we often want to avoid overfitting by, e.g., adding regularization to the model. Example: Let's suppose we want to do a linear regression, where the model is $y=a\times x+b$ , as loss, we use the sum of squared residuals. Now, to avoid too steep of a slope, we'll add as a regularization term $\lambda\times a^2$ (i.e., ridge regression, where $\lambda$ is a weight), to impose that penalty. The overall formulation then is: $$ \begin{aligned} m(x)&=a\times x+b, \\[1ex] \mathcal{L}(\mathbf{x})^{\text{resid}}&=\sum_{i=1}^{|\mathbf{x}|}\,\left(m(x_i)-y_i\right)^2, \\[1ex] \mathcal{L}(a)^{\text{reg}}&=\lambda\times a^2, \\[1ex] \mathcal{L}(\mathbf{x},a)&=\mathcal{L}(\mathbf{x})^{\text{resid}}+\mathcal{L}(a)^{\text{reg}}. \end{aligned} $$ Question : How to choose $\lambda$ ? This seems to be especially difficult for when, e.g., the number of points in $\mathbf{x}$ increases, or when their absolute values (and hence the differences) are very large. Actual Question : Wouldn't it be better to use a bounded score for both, the loss over the residuals, and the regularizer, instead of a dimension-less measure? Example: Using Pearson's sample correlation coefficient for $\mathcal{L}(\mathbf{x})^{\text{resid}}$ , and by recognizing that that the slope is already bound to be in the interval $(-1,1)$ , we can simple re-define the two losses as scores, for example: $$ \begin{aligned} \mathcal{L}(\mathbf{x})^{\text{residscore}}&:\mathbb{R}^n\to[0,1]=\frac{1-\operatorname{Cor}\left(m(\mathbf{x}),\mathbf{y}\right)}{2} \\[1ex] \mathcal{L}(a)^{\text{regscore}}&:\mathbb{R}\to[0,1]=a^2, \\[1ex] \mathcal{L}(\mathbf{x},a)^{\text{score}}&:\mathbb{R}^n,\mathbb{R}\to[0,1]=\frac{\mathcal{L}(\mathbf{x})^{\text{residscore}}+\mathcal{L}(a)^{\text{regscore}}}{2} \end{aligned} $$ (Note that even though I wrote score , a lower value is still better in this example) So, in other words, why don't we choose loss functionals and regularizers always in a way that eliminates finding weights that fit the current data? I left out $\lambda$ in my second example, but in a model formulation like this, we only would need to set the weights for each loss or regularizer once, according to our preference. Then, this model would work for any kind of data and find an appropriate trade-off. Or am I wrong?
