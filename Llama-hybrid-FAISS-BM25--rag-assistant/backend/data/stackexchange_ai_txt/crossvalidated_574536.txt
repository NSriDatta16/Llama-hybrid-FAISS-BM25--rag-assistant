[site]: crossvalidated
[post_id]: 574536
[parent_id]: 
[tags]: 
How to use the parameters estimated by MCMC?

Considering this example, taken from the coursera course "Bayesian Statistics: Techniques and Models", Dataset: # This is the "badhealth" dataset from `library("COUNT")` in R From German health survey data for the year 1998 only. Format A data frame with 1,127 observations on the following 3 variables. numvisit number of visits to doctor during 1998 badh 1=patient claims to be in bad health; 0=not in bad health age age of patient: 20-60 The model in jags: model { for (i in 1:length(numvisit)) { numvisit[i] ~ dpois(lam[i]) log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i] } int ~ dnorm(0.0, 1.0/1e6) b_badh ~ dnorm(0.0, 1.0/1e4) b_age ~ dnorm(0.0, 1.0/1e4) b_intx ~ dnorm(0.0, 1.0/1e4) } i.e. we are using the Poisson regression to model the numvisit . After running jags.model() and coda.samples() using the data and the model, we got a list of parameter estimates: b_age b_badh b_intx int [1,] 0.007849244 1.488192 -0.009732432 0.3903787 [2,] 0.006821275 1.520971 -0.008907179 0.3839672 [3,] 0.006969045 1.496611 -0.009697216 0.4127674 [4,] 0.006941290 1.557291 -0.009249318 0.4048429 [5,] 0.007139250 1.536305 -0.011444426 0.4213547 ... total of N rows Suppose that we want to answer the question: We have two people aged 35, one in good health and the other in poor health. What is the posterior probability that the individual with poor health will have more doctor visits? This includes sampling numvisit using the estimated model parameters, there are few choices: using the mean or median of the MC samples of the parameters, i.e. mean(b_age) , mean(b_badh) as our estimates, calculate the corresponding lambda (poisson's paramter), and sample N (the row count of the parameters) numvisit using these estimates sample one numvisit from each row of the sampled model parameters The author uses the later approach, justifying it with: Because we used our posterior samples for the model parameters in our simulation, this posterior predictive distribution on the number of visits for these two new individuals naturally takes into account our uncertainty in the model estimates. This is a more honest/realistic distribution than we would get if we had fixed the model parameters at their MLE or posterior means and simulated data for the new individuals. The question: I can see that there is certain logic to it, but I cannot get a better grasp of it, why it is "better" to sample once for different models, than sample many times from a single model? I can see that sample from different models gives you more variability (or does it? e.g. in the case of infinite of samples), but is there any rigorous theory says that, in this specific case, we want the variability introduced by sampling from different models? Or is this a experience/educated guess thing?
