[site]: crossvalidated
[post_id]: 168060
[parent_id]: 100785
[tags]: 
As a Bayesian, I often find myself interpreting experiments as positive evidence for the null hypothesis. I would ask the following things: It's a mean difference of \$2,000, but what is that in terms of a standardized mean difference? How big of a (standardized) mean difference would you have expected to observe if this intervention worked? How precise is your estimate? If the estimate is +\$2000 +/- \$20,000, then you have not learned much -- perhaps there's too much variability to know if your intervention worked. Now that you have observed this seemingly null effect in a pretty healthy sample of 30,000, might it be time to argue that you know place less probability in the intervention being effective? Many considerations apply, of course. If you are looking at p = .02 when your traditional cutoff is .01, it would be foolish to conclude that the null hypothesis is true, as the data are probably fairly equiprobable under the two hypotheses. Thus, I would suggest looking at Zoltan Dienes' webpage and his Bayes Factor calculator . By specifying your parameter estimate, its precision, and a plausible range of parameter values if your intervention worked, you could get a Bayes Factor telling you whether this is evidence that your intervention works or doesn't work, or whether there is no evidence one way or the other. Of course, the other commenters' replies are important, too: check your model, check your data, etc. to make sure the parameter estimate you have is appropriate.
