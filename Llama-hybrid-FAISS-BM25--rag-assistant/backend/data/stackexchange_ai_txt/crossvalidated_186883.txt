[site]: crossvalidated
[post_id]: 186883
[parent_id]: 139411
[tags]: 
To test if your previous predictor has become non-significant you make a new model without it and do the anova(model0,model1). You might end up doing a lot of anovas, hence the issue with Type 1 errors that alesc mentions. A better method might be to try model averaging - build all possible models, and then build a weighted average using the AIC scores. This is relatively quick/straightforward to do using the package MuMIn. One of the benefits is that it avoids decisions about what predictors to include, which can end up being somewhat arbitrary. It also allows a rough significance test for each predictor based on the estimate, and whether the confidence intervals cross zero or not.
