[site]: stackoverflow
[post_id]: 2405191
[parent_id]: 2366814
[tags]: 
As you say, The problem I have is with the "usually instantly" part. If I do not get a response quick enough, I think it will throw off the whole timing of my algorithm. What is a better way to handle this situation? In an ideal world your computer's clock is perfect, garbage collection is atomic, instantaneous and in O(1), networks have no delay, OS have no interrupts and Murphy is sound asleep. Since you are dealing with a real-world situation, you need to adjust for the uncertainty typical of it. First, you need statistics . Surely Java GC is never guaranteed to be real-time, but you can have a fairly good approximation that works 90% of the time. The remaining 10% can be handled by another 'plan B', so on and so forth. In other words: run your system and try to hinder it as much as you can; collect usage statistics; work on the best workarounds for those circumstances. For example, insert random delays in your simulation's simulation and see how it responds ( unit test !); perhaps you want to run the run() method every 500ms? use an observer pattern (as suggested elsewhere); have as little code as possible run in the run() method; perhaps run it every 1sec - epsilon , where epsilon is a small enough interval that accounts for the delay with the highest variance in a large enough sample have two separate threads run simultaneously, keep them in sync using a lock, average their running time to get a better clock In a pinch, there's no exact solution as there is no exact 'real' world. Add noise, get ready for the worse, average out the rest.
