[site]: crossvalidated
[post_id]: 485014
[parent_id]: 
[tags]: 
Improve XGBoost performance in a huge dataset with a lot of missing values

I have a dataset with around 250 features and 4 Millions samples and we obtained a model with Xgboost that has acceptable performance. The dataset has a high percentage of missing value, for an important number of variables. I aim to improve model's performance. As there is a big number of features, I though first to apply some techniques of feature selection, such embedded methods with random forest. But if the percentage of missing values is not a problem for Xgboost, I know that for other algorithms it's not well. How can I do? Are there any techniques to select features even when missing values are present? Or do I have to apply some techniques to handle missing values first, and which ones? (the option of drop columns is not possible). It's a classification problem with two very imbalanced classes (predict credit default). Thanks so much for your help :)
