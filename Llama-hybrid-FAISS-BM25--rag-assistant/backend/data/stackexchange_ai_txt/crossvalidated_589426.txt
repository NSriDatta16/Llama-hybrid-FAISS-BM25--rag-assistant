[site]: crossvalidated
[post_id]: 589426
[parent_id]: 589401
[tags]: 
If you stick really close to the data generating process, these are repeated binary decisions. I.e. each participants makes three decisions of choosing the local product or not (each time a 1/0 outcome). It's not count data, because the counts cannot reach any arbitrary number. Arguably, it could be truncated (at 3) count data or ordinal data, but that's not exactly how the data arose. That does not mean that you could not create a useful model by considering it that way, especially an ordinal model may indeed be useful. However, an ordinal model ignores that participants are asked to make a very similar choices - possibly with some known differences between questions - each time. If one goes down the repeated binary route, then it matters what we wish to assume/what detailed data we have on each decision. E.g. when asked about the products, the product might sometimes have been a vegetables, exotic fruit, or clothes. People might tend to prefer buying vegetables locally, think that exotic fruits are so much better from further away and be more mixed about clothes. Or perhaps you think people might change their answer based on something else (e.g. is it the first question they get asked, participant's age, favorability rating 0-100 for globalization etc.). In that case modeling each binary choice (with explanatory variables like type of choice, participant age etc. as a fixed effect) and accounting for decisions being by the same participant (e.g. participant random effect) would be an option. Or, perhaps the choices were really all the same, in which one can reduce this to a binomial outcome (i.e. number of yes answers out of 3 with the same probability applying to all of them). Thus, I'm arguing for the use of (random effects) logistic regression (which is well supported e.g. in R using the lme4 or brms packages).
