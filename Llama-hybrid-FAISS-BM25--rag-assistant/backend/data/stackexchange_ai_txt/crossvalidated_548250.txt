[site]: crossvalidated
[post_id]: 548250
[parent_id]: 548166
[tags]: 
The rule of thumb is: the more difficult the classification is for you as a human being, the more complex model you would need. Can you guess the label from the presence of few keywords? → If yes, it is probably enough to use a BoW representation (e.g., TF-IDF) and your favorite traditional ML algorithm. Can you guess the label from the words in the sentence, but it seems it would be hard to come up with a list of keywords? → If yes, word embeddings (probably without stopwords) + your favorite traditional ML algorithm or a feed-forward neural net should be enough. Can you guess the label the presence of few word phrases, and and need to be aware of simple negations? → If yes, word embeddings (pre-trained or not) + convolutional classifier will be a good choice. Do you need the structure of the sentence (know who is the subject, who does what, etc.) to assign the label correctly? → If yes, do some serious deep learning. Currently, the best choice is the pre-trained Transformers (such as BERT or RoBERTa). Their main advantage is that fine-tuning requires much less training data than training the models from scratch, which you would probably need to in the case of RNNs.
