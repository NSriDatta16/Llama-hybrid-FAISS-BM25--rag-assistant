[site]: crossvalidated
[post_id]: 461136
[parent_id]: 
[tags]: 
How to identify the most impactful features in a ML model, i.e. the predictor variables that can drive the biggest change in the target variable?

I have built a machine learning model using Random Forest in Sklearn (RandomForestRegressor). The model has up to 473 predictor variables and 1 target variable (all predictor and target variables are numeric). I wanted to identify the most impactful features, i.e. which predictor variables can result in the biggest change in the target variable. Using feature importance, I can find the variables that have the most predicting power (53 features account for 90%+ feature importance). However, this is different from being the most impactful. Ideally, I want to be able to make a statement saying "if we are to change all variables by the same percentage, these 3 variables will produce the biggest amount of change in the target variable". I figured I could use the same concept as in deep learning, i.e. to find the derivatives of all predictor variables and then the variables with the biggest derivative values would be the most impactful variables. Here are my questions: How would I be able to do this when what I have is a sklearn ML model and not an actual math function? Maybe I need to use tensorflow gradienttape? What if the predictor variables are not independent? i.e. when one variable changes, others may also change. Can I still make the above statement if I use the derivative method mentioned?
