[site]: crossvalidated
[post_id]: 108857
[parent_id]: 108280
[tags]: 
As discussed in the comments, here is my Stan model for an Ordered Logistic Regression. It takes long format data (one observation per row) and estimates the following parameters: coefficients for dummy-coded predictors (you can for example use Rs model.matrix ) from the matrix preds as fixed effects, and also "maximal" (intercept + slope for all terms plus all interaction) random subject and item effects. It does not estimate or disallow correlated random effects. It should give you the coefficients for your predictor matrix (in beta) and the cutoff points. data{ int K; // number of outcomes int n_conds; // e.g. 32 (5 factors and all interactions) int n_obs; // e.g. 12000 (observations) int A[n_obs]; // outcomes (e.g. Likert scale rankings, 1-4) matrix[n_obs,n_conds] preds; // predictor matrix of 0s and 1s int Ss; // e.g. 190 (subjs) int Is; // e.g. 2560 (items) int S[n_obs]; // subj per observation int I[n_obs]; // item per observation } parameters{ vector[n_conds] r_subj[Ss]; // random effects subject vector[n_conds] r_item[Is]; // random effects item real sigma_s; // one sigma for all subjs real sigma_i; // one sigma for all items real sigma; // one sigma for all fixed ordered[K-1] c; // cut points vector[n_conds] beta; // fixed effects } model { sigma ~ cauchy(0,5); // rather narrow prior for all sigmas sigma_s ~ cauchy(0,5); sigma_i ~ cauchy(0,5); beta ~ normal(0,sigma); // moderate prior for effects for (s in 1:Ss) // prior for subj rand. eff. r_subj[s] ~ normal(0,sigma_s); for (i in 1:Is) // prior for item rand. eff. r_item[i] ~ normal(0,sigma_i); for (n in 1:n_obs) // loop to estimate using ordered logistic regr. A[n] ~ ordered_logistic( preds[n] * beta // fixed + preds[n] * r_subj[S[n]] // random s + preds[n] * r_item[I[n]] // random i , c); // cut points After you've specified all values asked for in the data part of the code in a list dat , you can run it, e.g. via fit , and print the values via print(fit,"beta") . I can't promise this works as intended, but I've compared it with simple ordinal regression using clmm and "maximal" linear regression using lme4 and the results are qualitatively very similar!
