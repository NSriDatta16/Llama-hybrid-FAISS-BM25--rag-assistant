[site]: crossvalidated
[post_id]: 97731
[parent_id]: 
[tags]: 
Real World Cross Validation Problem

Hello , first of all I've got to confess that I'm not a statistician and therefore wouldn't mind if an answer is a bit more explicit than it usually would be among statisticians. The Context To predict energies of arbitrary patterns of a certain physical system, I settled to use the MAPS code (as it is described in detail in this paper ). This code iteratively constructs a data set of known energies $E_i$, which provide the dependent variable . Those should be explained by the independent variables , given by the so called "correlations" $\langle \prod_{j \in \alpha^\prime}\sigma_j \rangle_{\alpha^\prime}$ (which are $\in \left[-1,1\right]$) averaged over all "clusters" $\alpha^\prime$ which are symmetrically equivalent to a specific cluster $\alpha$ included in a specific truncation. The set of all "clusters" $\alpha$ included in the cluster expansion define the truncation by limiting $\sum_\alpha$. That way, each energy of a structure described completely by $\vec{\sigma}_i$ contributes a row to the problem as per $$ E_i = E\left\lbrace\vec{\sigma}_i\right\rbrace = \sum\limits_\alpha J_\alpha m_\alpha \langle \prod_{j \in \alpha^\prime}\sigma_j \rangle_{\alpha^\prime}, $$ such that $J_\alpha m_\alpha$ is the set of regression coefficients . As the aforementioned paper describes, to prevent overfitting to our finite set of known energies, (a weighted version of) the cross validation score as given by $$ CV^2 = \frac{1}{n}\sum\limits_{i=1}^n\left(\frac{E_i - \hat E_i}{1-X_{i\cdot}\left(X^TX\right)^{-1}X_{i\cdot}^T}\right)^2 $$ is calculated/minimized to measure/maximize the prediction power of the truncation. Here, $\hat E_i$ is the estimation of $E_i$ using a specific truncation, and $X$ the $n\times c$ regression matrix for $n$ known energies/structures (rows) and their $c$ "correlations"/clusters (columns). The Problem However, iteratively adding structures and testing truncations leads to a system that suspiciously often (as in "the vast majority of tested truncations") yields $CV^2 \rightarrow \infty$ becaucse $X_{i\cdot}\left(X^TX\right)^{-1}X_{i\cdot}^T \rightarrow 1$ in contributions from several different structures i. In some sense, $X$ seems to become "orthogonal" at some point in the sense that $X^TX = \lVert X_{i\cdot} \rVert^2\cdot\mathbb{1}$ but I fail to make real sense of that currently. The Question(s) Now, I assume the predictive power of a given truncation isn't estimated in a useful way by such a diverged CV score and I suspect there is a deeper, statistical reason for this to happen so often. Therefore I'd like to ask: Does such a divergent CV score signal something statistically important and, if so, what would that be? Is there another way to access the predictive power of a truncation aside from the CV score? Please find a problematic regression matrix $X \in \left[-1,1\right]^{71\times 15}$ and the corresponding dependent variable vector $\vec{E} \in \mathbb{R}^{71\times 1}$ here . In case there are any additional information of interest missing in the post above, please don't hesitate to ask me - I'll gladly provide them then. Thank you very much in advance!
