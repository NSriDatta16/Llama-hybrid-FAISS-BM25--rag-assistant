[site]: crossvalidated
[post_id]: 23439
[parent_id]: 
[tags]: 
Modern neural networks that build their own topology

A limitations of standard neural net algorithms (like backprop) is that you have to make a design decision of how many hidden layers and neurons-per-layer you want. Usually, the learning rate and generalization is highly sensitive to these choices. This has been the reason, why neural net algorithms like cascade correlation have been generating interest. It starts with a minimal topology (just input and output unit) and recruit new hidden units as learning progresses. The CC-NN algorithm was introduced by Fahlman in 1990, and the recurrent version in 1991. What are some more recent (post 1992) neural net algorithms that start with a minimal topology? Related questions CogSci.SE: Neural networks with biologically plausible accounts of neurogenesis
