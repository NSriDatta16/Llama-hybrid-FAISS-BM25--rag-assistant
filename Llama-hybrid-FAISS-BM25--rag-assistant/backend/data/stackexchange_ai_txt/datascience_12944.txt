[site]: datascience
[post_id]: 12944
[parent_id]: 454
[tags]: 
As mentioned above, the best way is to repeatedly sample the majority class N times(sampling without replacement) and for each time, the size of negative class should be equal to the size of positive class. Now, N different classifiers can be trained and the average can be used to evaluate it. Another way is to use the technique of bootstrapping. This might introduce overfitting, but worth trying and then if neeeded can regularize the model to avoid overfitting.
