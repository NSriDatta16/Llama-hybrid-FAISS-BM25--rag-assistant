[site]: crossvalidated
[post_id]: 439759
[parent_id]: 
[tags]: 
Relationship between generalization error and prior variance

Suppose that we have a Bayesian linear regression with prior on the weights $p(w)=N(0,\sigma_{w}^{2})$ Our goal is to use that Bayesian linear regression for future predictions. In order to do that we fit the weights on a data set $(x_{n},y_{n})_{n=1}^{N}$ . My question is what is the relationship between the $\sigma_{w}^{2}$ and the Generalization error of the model (i.e how well will predict new unobserved values). My thoughts are the following: For large $\sigma_{w}^{2}$ we will have a flat prior thus our model will be dominated by the data. For small $\sigma_{w}^{2}$ we may underfit because we don't let the data to involve so much into the predictions. We also know that for Gaussian priors the variance can be seen as an L2 regularization. Thus, maybe we can say that with big $\sigma_{w}^{2}$ we may overfit ?? So is there a relationship between generalization error and $\sigma_{w}^{2}$ ??
