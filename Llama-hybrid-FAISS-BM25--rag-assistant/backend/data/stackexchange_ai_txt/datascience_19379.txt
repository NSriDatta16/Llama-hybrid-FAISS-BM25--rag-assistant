[site]: datascience
[post_id]: 19379
[parent_id]: 19378
[tags]: 
It looks like when you say "way of assigning the weights", that you mean "what order are weights counted in, so that I know which weights connect between which neurons". There is no formal "correct" way of doing this for all neural networks. However, in practice for feed-forward networks like your diagram, you would choose to use a matrix, not a vector, to represent the weights connecting layers. That is how pretty much all standard libraries will represent weights. A matrix uses two indices (call them $i,j$ in this case) to identify a single scalar value. If we call the weight matrix $W$, then an individual weight is $W_{ij}$. To determine how the weights connect between neurons, then you index the input layer neuron with $i$ and the output layer neuron with $j$. In math notation, looking at your diagram, call each input value $x_i$ and each hidden value $h_j$, then the formula for calculating a single $h_j$ would be: $h_j = f(b_j + \sum_{i=1}^{N} W_{ij}x_{i})$ Where $f()$ is a transfer function (such as sigmoid), $N$ is the number of input features, and $b_j$ is the bias for hidden layer neuron $j$. You will also often see this written using matrix notation: $\mathbf{h} = f(W\mathbf{x} + \mathbf{b})$ . . . this is not only clear and simple notation, but using matrix maths like this to describe a neural network is what allows us to use high performance libraries on GPUs such as TensorFlow.
