[site]: crossvalidated
[post_id]: 625093
[parent_id]: 421935
[tags]: 
This is a concept that is the heart of the Transformer architecture and is difficult to explain or grasp. We can say that in the process of learning the correct 'next' token to predict, three sets of weights per token are learned by backpropagating the loss - the Key , the Query and the Value weights. These form the base of the "Attention" mechanism. The video beautifully explains this at this location . The concept of Vector dot produc t is used to calculate the Value Vectors, which is the sum of the contribution of the dot product of Query and Key vectors. The intuition is that similar vectors in the Vector embedding space will have a larger dot product value and higher contribution. The Weights are then adjusted via Backpropagation which means that the learned weights represent a better Contextual Vector Embedding space for each token. ( Key and Query weights are multi-dimensional and there are multiple attention heads, so it is not one vector space but many) In Transformers, there are multiple attention heads, so, which attention head to weightage more can also be tuned via weights. Basically Transformer network is this architecture, where the intuition of causal relationship between tokens is encoded as learnable weights in linear neural net layers. I have tried to explain this in a simplified image below. It may not be fully accurate, but the overall high-level mechanism is right
