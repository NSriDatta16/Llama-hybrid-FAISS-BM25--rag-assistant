[site]: crossvalidated
[post_id]: 246474
[parent_id]: 
[tags]: 
Test for the significance of the effect of an intervention in a time series

I am looking for the best approach to test for the significance of the effect of an intervention that occurred at a known time on a time series data. Using a toy dataset as an example, I have come up with two approaches. Data y 1. Piecewise regression Fitting two linear regression models to subsets of data before and after the intervention. df1 10) m2 Using the formula for comparing slopes from this answer . b1 And calculating the corresponding P-value. 2*pnorm(-abs(Z)) [1] 1.395998e-08 (By the way, is there a more elegant function that does the above?) This P-value is highly significant and the one to be reported for the effect of an intervention. The result is shown graphically by plotting two regression lines before and after. (Since lm showed that the slope of relationship at x=1:10 is not significantly different from 0, the line is at y=mean(1:10) ) ggplot(df, aes(x,y)) + geom_point() + geom_vline(xintercept = 10.5) + scale_x_continuous(breaks=df$x) + stat_smooth(method="lm", data=df2, se=F, colour="royalblue1", size = 0.75) + geom_segment(x = 1, xend = 10, y = mean(df1$y), yend = mean(df1$y),colour="royalblue1", size=0.75) 2. Dynamic regression with ARIMA Fitting two ARIMA models, one without and one with a regressor that codes for the intervention. library(forecast) y Summary shows that auto.arima chose ARIMA(0,1,0) as the best model. Hence, fitting ARIMA(0,1,0) with a regressor using the Arima function. a2 Then using the LRT test to compare the two models to get the P-value associated with the effect of an intervention. library(lmtest) lrtest(a1, a2) Obviously, the P-value is highly significant. One advantage of dynamic regression is that it can be used to get forecasts. intf Questions Are both methods adequate and adequately executed? Are there any other methods? Which method would be the preferred one?
