[site]: crossvalidated
[post_id]: 12552
[parent_id]: 12529
[tags]: 
There are two questions here: (1) how to determine the probability that the two samples are from the same distribution and (2) what kind of distance metric could be used to measure their overlap. For the first, one simple way would be to determine the distribution of the first sample (perhaps it's multivariate normal?) and then calculate the posterior density of the second sample under the assumption of the distribution of the first. I like this approach because the interpretation is very straightforward. For the second, I wouldn't do what you're suggesting with EMD unless you have some natural pairing of individuals in samples 1 and 2 (see @whuber's questions above). One common point between Hausdorff and EMD is that both let you specify an arbitrary distance metric for the points, e.g., euclidean or cosine, so you don't have to average the points (I'd go further and say you shouldn't if you use these methods). The downside is that your results will depend on your choice of the distance metric so you need some way of justifying your choice. Because of the downside of the distance metric being arbitrary, I'd consider, instead, the Bhattacharyya distance or perhaps mutual information, provided you can make some information choice about what the distributions are.
