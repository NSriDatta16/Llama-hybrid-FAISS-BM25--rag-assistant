[site]: crossvalidated
[post_id]: 154025
[parent_id]: 147348
[tags]: 
Averaging Pearson and Spearman is an original idea, but in practice it just avoids the key issue of what you should be estimating in an arbitrary way. Why not use weights other than equal weights, such as 0.7 Spearman and 0.3 Pearson or Spearman 0.3 and Pearson 0.7? There is nothing automatic about the choice of weights 0.5 and 0.5, outside an appeal to simplicity. It's not as if there is a Platonic entity which we call "the correlation" that we are seeking, like the Holy Grail. The perspective "What are we estimating here?" is always worth following and the answer would have to be that the average of Spearman and Pearson is just estimating the same measure in the population. As that is a highly non-standard procedure (meaning, I've never seen this proposal before) you would have to explain that and sell it to an audience or readership. Whenever Spearman and Pearson correlation disagree, as is very common, the key question is which correlation makes more sense for the analysis and whether other approaches make more sense in turn. Working with one or other variable on a transformed scale is one common way forward. Note. How to get P-values is to me a secondary issue as I don't see that this is a good idea any way. If you were determined, you could try bootstrapping to get confidence intervals. But when there is an outlier present, then bootstrap samples will divide sharply into those containing no copies of the outlier and those containing one, two, ... copies of the outlier. The sampling distribution is thus going to be multimodal.
