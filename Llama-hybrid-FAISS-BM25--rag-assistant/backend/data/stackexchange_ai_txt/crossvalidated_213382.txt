[site]: crossvalidated
[post_id]: 213382
[parent_id]: 213372
[tags]: 
The algorithms are completely different. The only common thing between them is that they both are clustering algorithms. K-means searches for K centers, and attachment of points to them, such that: each point is attached to the closest center each center is the average (center of gravity) of all points attached to it It is done iteratively. We start from random centers, attach each point to the closest center, move each center to the average of points attached to it, reattach each point to the closest center, move each center the average of points attached to it now, and so on until the iterations converge. At the end we have K centers, each one "owns" all points which are closer to it than to any other center. The hidden assumption is that there are K "real" clusters, each one is normally distributed around its center, and all normal distributions are spherical and have the same radius. Support vector clustering has the following idea: let us transform the points from their space to a higher dimensionality feature space . Find a minimal enclosing sphere in this feature space. In the original space, the sphere becomes a set of disjoing regions. Each region becomes a cluster. (There are also important details like how we choose the feature space, and how we do the transformation, and how we define disjoint regions.) These disjoint regions are completely different from the regions around K centers in the K-means algorithm. For example, in 2 dimensions, the K-means regions are polygons. The regions of SVC are amoeba-like areas.
