[site]: crossvalidated
[post_id]: 188209
[parent_id]: 188125
[tags]: 
It is not gross over fitting (depending on definition). Target information of test set is preserved. Semi-supervised allow to generate an extra synthetic data set to train the model on. In the described approach, original training data is mixed unweighted with synthetic in ratio 4:3. Thus, if the quality of the synthetic data is poor, the approach would turn out disastrous. I guess for any problem where predictions are uncertain, the synthetic data set would be of poor accuracy. If the the underlying structure is very complex and system has low noise, it may help to generate synthetic data, I guess. I think semi-supervised learning is quite big within deep learning (not my expertise), where the feature representation is to be learned also. I have tried to reproduce increased accuracy with semi.supervised training on several data sets with both rf and xgboost without any positive result. [Feel free to edit my code.] I notice the actual improvement of accuracy using semi-supervised is quite modest in the kaggle report, maybe random? rm(list=ls()) #define a data structure fy2 = function(nobs=2000,nclass=9) sample(1:nclass-1,nobs,replace=T) fX2 = function(y,noise=.05,twist=8,min.width=.7) { x1 = runif(length(y)) * twist helixStart = seq(0,2*pi,le=length(unique(y))+1)[-1] x2 = sin(helixStart[y+1]+x1)*(abs(x1)+min.width) + rnorm(length(y))*noise x3 = cos(helixStart[y+1]+x1)*(abs(x1)+min.width) + rnorm(length(y))*noise cbind(x1,x2,x3) } #define a wrapper to predict n-1 folds of test set and retrain and predict last fold smartTrainPred = function(model,trainX,trainy,testX,nfold=4,...) { obj = model(trainX,trainy,...) folds = split(sample(1:dim(trainX)[1]),1:nfold) predDF = do.call(rbind,lapply(folds, function(fold) { bigX = rbind(trainX ,testX[-fold,]) bigy = c(trainy,predict(obj,testX[-fold,])) if(is.factor(trainy)) bigy=factor(bigy-1) bigModel = model(bigX,bigy,...) predFold = predict(bigModel,testX[fold,]) data.frame(sampleID=fold, pred=predFold) })) smartPreds = predDF[sort(predDF$sampleID,ind=T)$ix,2] } library(xgboost) library(randomForest) #complex but perfect separatable trainy = fy2(); trainX = fX2(trainy) testy = fy2(); testX = fX2(testy ) pairs(trainX,col=trainy+1) #try with randomForest rf = randomForest(trainX,factor(trainy)) normPred = predict(rf,testX) cat("\n supervised rf", mean(testy!=normPred)) smartPred = smartTrainPred(randomForest,trainX,factor(trainy),testX,nfold=4) cat("\n semi-supervised rf",mean(testy!=smartPred)) #try with xgboost xgb = xgboost(trainX,trainy, nrounds=35,verbose=F,objective="multi:softmax",num_class=9) normPred = predict(xgb,testX) cat("\n supervised xgboost",mean(testy!=normPred)) smartPred = smartTrainPred(xgboost,trainX,trainy,testX,nfold=4, nrounds=35,verbose=F,objective="multi:softmax",num_class=9) cat("\n semi-supervised xgboost",mean(testy!=smartPred)) printing prediction error: supervised rf 0.007 semi-supervised rf 0.0085 supervised xgboost 0.046 semi-supervised xgboost 0.049
