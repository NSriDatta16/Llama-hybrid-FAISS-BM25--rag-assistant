[site]: datascience
[post_id]: 124324
[parent_id]: 
[tags]: 
How to use additional features in image captioning?

I have the following question - is it possible to train a model based on Transformer architecture to use additional attributes to generate a caption for an image? For example, I have a dataset with the following fields: painting description, painting author, genre, date of creation, historical era, etc. I want to generate a caption for the picture not only the text from the description of the picture, but also other attributes. I was thinking of creating separate classifiers for the attributes, but maybe there is a way to use one model for this purpose.
