[site]: crossvalidated
[post_id]: 243816
[parent_id]: 243802
[tags]: 
It's up to the practitioner, but typically only the hidden states are used by the layer above. One can use RNN to have one output, or a sequence of output, as this figure ( source ) illustrates: Each rectangle is a vector and arrows represent functions (e.g. matrix multiply). Input vectors are in red, output vectors are in blue and green vectors hold the RNN's state (more on this soon). From left to right: (1) Vanilla mode of processing without RNN, from fixed-sized input to fixed-sized output (e.g. image classification). (2) Sequence output (e.g. image captioning takes an image and outputs a sentence of words). (3) Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment). (4) Sequence input and sequence output (e.g. Machine Translation: an RNN reads a sentence in English and then outputs a sentence in French). (5) Synced sequence input and output (e.g. video classification where we wish to label each frame of the video). Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like. Also you can add some attention mechanism, in which case even many to one and many to many architectures will use all hidden states (unless it is hard attention), and not just the last one.
