[site]: crossvalidated
[post_id]: 8436
[parent_id]: 
[tags]: 
Logistic regression for bounds different from 0 and 1

I have some data; it's a proportion $y$ of some stuff relative to everything, so it's bounded between 0 and 1 by definition. The proportion changes over time. Besides fairly high variance there is a step-like change about the middle of the time period; the step isn't very large, but it's there, and it happens pretty fast relative to the whole time period. So I have an S-curve, and I want to (and was told to) do logistic regression. But: (1) this is not monotone, not even close, because of the high variance. (2) it does not go from 0 to 1. Rather, it goes from about 0.2 to about 0.8, if you look at the means. So it would seem that the right thing to do will be to fit something like $a\phi(x)+b$, where $\phi$ is the usual logistic S-curve, so we have 4 parameters altogether. What bothers me is that I've never seen an example of logistic regression used like that (I'll admit to not seeing too many). It's not that I'm not sure how to implement this -- I'm pretty confident I can figure that out, although specific pointers will be appreciated -- but I am afraid that the assumption that the data is bounded by the limits of the S-curve is important for all the estimates afterward, like goodness of fit, significance of the step, confidence intervals, etc. So: Are my fears justified? Can you point me to a relevant example in the literature? Not necessarily statistical literature, if some biologists (or whoever) use it, that's fine. Or even just someone mentioning this possibility. If there are indeed problems with this approach, what are the alternatives? Update: Well, I was so ignorant that I could not even ask the questions properly. I was looking for multinomial (aka polytomous) regression.
