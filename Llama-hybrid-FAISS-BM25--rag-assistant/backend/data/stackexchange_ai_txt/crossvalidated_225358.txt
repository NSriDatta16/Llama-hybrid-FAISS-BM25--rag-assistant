[site]: crossvalidated
[post_id]: 225358
[parent_id]: 225295
[tags]: 
Neither PCA nor FDA are configured to answer that question. PCA and FDA transform the full data set to another set of the same dimension. Intuitively, we imagine that the data depend on a small number of vectors, and that the rest of the variation in the sample is noise. However, if you attempt to formulate this intuition and solve it, what you get is factor analysis, not PCA. Therefore, using PCA to reduce the dimension of the problem always relies on rules of thumb and ad hoc thinking. To me, I would look at the proportion of total variance explained. I would also look at the coefficients to see if they had an obvious and meaningful interpretation, and stop when the eigenvectors stop making sense. There is a useful function in the psych package, fa.parallel, that uses a graphical method to determine the number of components for PCA and FA. Again, it's a rule of thumb, but it seems to produce sensible results most of the time. I would expect the number of components selected for PCA to be the same, or similar, to the number of components selected for FDA. FDA is sort of like working with an oblique transformation of the basis of the data space, which shouldn't impact the underlying dimensionality of the problem.
