[site]: crossvalidated
[post_id]: 375189
[parent_id]: 
[tags]: 
Dynamic Programming vs Hidden Markov Models

I've just been introduced to machine learning, and one of the first topics I'm covering is an introduction to finite state transitions and their models. Specifically, right now, I'm on Hidden Markov Models (HMM). Reading this paper by Mark Stamp , he states that in finding the "most likely" sequence of hidden states, given a sequence of observations, that we must distinguish between two types of most likely. Please check my understanding of what he's saying. I believe he's saying (in my own words): There's a way to interpret "most likely" as the sequence of states most likely to generate our sequence of observations . And there's another way of interpreting "most likely" that corresponds to finding the largest number of correct states , that is, those that match what actually happened. For the latter, doesn't this mean we would have to know what the actual states were? And in that regard, does that mean this model would have to be trained? And secondly, the main reason I'm posting is in regards to the following passage from the paper: What does the author mean, when he says that the HMM solution does not require valid state transitions? But more importantly, to me, why would we be okay with non-valid state transitions?
