[site]: crossvalidated
[post_id]: 288871
[parent_id]: 
[tags]: 
About depth in convolution layers

I am trying to build a CNN from scratch to understand how it works. I am having problems designing the convolution layers, specifically with its depth. Suppose that each image I put at the input is in grayscale and of size 256x256. That means that the initial dimension is 256x256x1. According to what I've read and understood so far, at each convolution layer one can exctract several feature maps (i.e. convolve the image with a different number of kernels). That number equals the depth. Therefore, if I decide to use 3 kernels per layer , and assuming I zero-pad the image so that the convolution yields an image of the same size and that the stride equals 1: At the output of the first convolution layer, I'll have an output of 256x256x3. After 2x2 max pooling, I'll have 128x128x3. That pattern enters the next convolution layer, which will have 3 kernels as well, thus the output will be 128x128x9. My questions are: Is the last description okay? If I use three kernels per layer, will the third dimension at the output of the $N$-th layer be equal to $3^N$? Can I represent these 'cubic' matrices (i.e. with third dimension greater than 1) as vectors at the input of the fully-connected network? For instance, if I have a matrix of dimensions 8x8x27 at the end of the convolution stages, can I order those numbers as a vector of dimension 1x1728 ($8\cdot8\cdot27=1728$) so that the fully-connected network is easier to implement?
