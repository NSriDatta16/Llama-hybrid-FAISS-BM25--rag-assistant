[site]: crossvalidated
[post_id]: 498057
[parent_id]: 275677
[tags]: 
Both null and alternative hypothesis are models, and as such different from reality and never true. A rejection of the null hypothesis says that the data are not compatible with the null hypothesis, because if the null hypothesis were true, such data would not normally be observed. A non-rejection of the null hypothesis says that the data are compatible with the null hypothesis, meaning that if data are generated from the null hypothesis, they could very well look like the data we have. But all data is compatible with many models. For example, if our null hypothesis is ${\cal N}(0,1)$ and we observe data with mean 0.01 and sample variance 1.13, data are surely also compatible with a ${\cal N}(0.01,1.13)$ distribution (and all kinds of other distributions "in between"), even though they will (if the sample size is not excessively large) not reject ${\cal N}(0,1)$ . Furthermore the data will be compatible with lots of non-normal models with similar expected values and variances, and with all kinds of distributions with dependence or non-identity structures that fit the data well as they are (including a crazy dependence structure that says that if we observe the first observation as it is, all else will happen as it happened with probability 1). In reality nothing is really identical and nothing is really independent, and for sure nothing is really normally distributed, so really the best we can say is that data are compatible with the $H_0$ , which means that nobody claiming anything substantially different can use them as argument. This issue by the way is not specific to tests and null hypotheses, and the only way Bayesian analysis can get around it is by going 100% subjective. Surely if a Bayesian says that the probability that model X is true is 87.5%, that's nonsense. The probability that any model is really true is zero. They are models and not reality after all.
