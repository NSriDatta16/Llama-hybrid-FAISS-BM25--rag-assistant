[site]: crossvalidated
[post_id]: 472321
[parent_id]: 472284
[tags]: 
$\newcommand{\E}{\operatorname{E}}$ Here's a more formal perspective which I think can be helpful for being clear about what's random and what isn't. We have a probability space $(\Omega,\mathscr F, P)$ and random variables $X$ and $Y$ with $X: \Omega \to \mathbb R^{p}$ and $Y:\Omega\to\mathbb R$ . You're asking about regression specifically so I'm going to focus on that, rather than different notions of modeling like selecting a measure from an indexed collection $\{P_\theta : \theta\in\Theta\}$ . We want to come up with some function $h$ that "explains" $Y$ using $X$ , thus we seek a $(\mathbb B^p, \mathbb B)$ -measurable $h : \mathbb R^p\to\mathbb R$ such that $h\circ X$ is "close" to $Y$ . It can be shown that $h\circ X$ is $(\sigma(X),\mathbb B)$ -measurable. This addresses part of your question (1): by going from $Y$ to $h\circ X$ , we have changed from being $(\mathscr F, \mathbb B)$ -measurable to $(\sigma(X),\mathbb B)$ -measurable. It is always the case that $\sigma(X)\subseteq\mathscr F$ but if $X$ is not very complex then this can provide a great simplification. I think this is a more precise way to look at the "information" here. In order to actually produce such an $h$ we'll need some way to measure its performance. We can appeal to decision theory and do this via a loss function $L(Y, f(X))$ , and since this is a random variable we'll actually use the risk functional $$ R[h] = \E[L(Y, h(X))]. $$ In practice we'd never want to minimize this over all $(\mathbb B^p, \mathbb B)$ -measurable functions as those functions can be quite complicated and that would be a hopeless business (we also would have many functions with identical values on the training set and we wouldn't be guaranteed to have our empirical risk minimizer converge on the true minimizer). Instead we'll want to restrict our attention to some nicer function space $\mathcal F$ and then pick $\hat h$ from there. Our choice of $\mathcal F$ is a modeling decision. For example, we could fix some basis functions $h_1,\dots,h_m$ and take $$ \mathcal F = \text{span}\{h_1,\dots,h_m\} $$ so we're considering functions of the form $$ x\mapsto \sum_{i=1}^m \beta_ih_i(x). $$ In this case we can reasonably select a $\hat h$ based on a finite sample and then we're modeling $Y$ as $\hat h\circ X$ . This includes linear regression and fancier things like splines. If we allow the basis functions to also have parameters in them (i.e. be "adaptive") then we can view neural networks and many other models from this perspective too. Note that if the $h_i$ are nice enough (i.e. continuous) then if $f,g\in \mathcal F$ are equal almost surely they are in fact equal everywhere, so we don't need to deal with issues of functions being defined almost everywhere. This also touches on how there are two approximations happening here: first we're restricting the true $h$ to be in $\mathcal F$ , and then we're approximating it with $\hat h$ , the one we actually found. If no element of $\mathcal F$ is actually a good fit then we'll have a large error in that step even if $\hat h$ is really the best element in $\mathcal F$ . Assuming $Y$ is integrable, it can be shown that $\E(Y|X)$ is the a.s.-unique minimizer of $\E((Y-Z)^2)$ over $(\sigma(X), \mathbb B)$ -measurable $Z$ . It also can be shown that there is a Borel $h$ such that $\E(Y|X) = h\circ X$ ; we can use this result to define $\E(Y|X=x) = h(x)$ which means we don't need to refer to $\Omega$ (see e.g. Lemma 1.2 in section 1.4.1 of Jun Shao's Mathematical Statistics for more on this). Thus if we choose to use squared loss, the actual minimizer is the conditional expectation. And since $\E(Y|X=x) = h(x)$ , when we restrict $h$ to being in our friendly $\mathcal F$ we're actually directly modeling $\E(Y|X=x)$ as belonging to this space. A lot of this has been from a machine learning perspective since I think that kind of signal modeling is intuitive. But if we want to think of making distributional assumptions, saying $Y = h\circ X$ induces the distribution of $Y$ based on $X$ so we could approach things from that way. Making distributional assumptions on $\varepsilon$ is not necessary for doing this. We can always run our algorithm and get a model. It's more that without understanding the error we won't have a sense of when our procedure is doing well or not.
