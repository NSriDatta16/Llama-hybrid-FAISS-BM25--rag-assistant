[site]: crossvalidated
[post_id]: 143941
[parent_id]: 
[tags]: 
Errors vs measurement errors

I'm reading about how to fit a straight line with measurement errors in both coordinates ($x$ and $y$). Let the true unobserved variables be $x_{t,i}$ and $y_{t,i}$ and the observed variables be $x_i$ and $y_i$. The relationship between the observed and the unobserved data is: $$ x_i = x_{t,i} + e_{x,i} $$ where $e_{x,i}$ represents unknown error component. And it is assumed that $e_{x,i}$ ~$ N(0, \sigma_{x,i}^2) $. Unfortunately, this is where I get lost. Can someone please explain to me what is the difference between: 1. Error $e_{x,i}$ 2. Variance $\sigma_{x,i}^2$ and 3. Measurement errors (also known as measurement uncertainties?) My data is obtained by fitting models to the observed light curve. An MCMC approach is used to calculate the uncertainties (measurement errors). I didn't do the model, I simply downloaded the available data in its final form from an online database. For example, my data look something like the following: dip in the light curve = $ 3 \pm 0.03$ Obviously, my observed parameter: $x_i = 3 $ Measurement error (also known as uncertainty) = $ \pm 0.03 $ Let's suppose that the true unobserved parameter $x_t = 8 $ Is the error $ e = x - x_t = 3 - 8 = -5$? What about the variance $\sigma_{x}^2$? How can I calculate it? Finally, how can I assume that my errors are normally distributed? I know I'm asking basic statistical question, unfortunately I read a lot of references, none where clear about the difference of these 3 different parameters. All the tutorials on regression simply outlined the above and went on with explaining the rest of the problem. Sorry if this is a stupid question.
