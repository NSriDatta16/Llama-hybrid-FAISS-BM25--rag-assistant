[site]: crossvalidated
[post_id]: 108631
[parent_id]: 
[tags]: 
Neural networks - are local minima bad?

I hear a lot about local minima for neural networks. I understand the theory behind it - but if my neural network finds weights in a local minimum, is that a bad thing? I understand that finding global minima (in Neural Networks) is usually a bad thing as well, since global minima usually overfits. However I am still a bit confused. Do convergence to local minima give us bad solutions? Lastly, does convergence to local minima overfit to our training data?
