[site]: crossvalidated
[post_id]: 160401
[parent_id]: 
[tags]: 
What is the point of graphical models?

I spent the day learning about the bnlearn package in R only to discover that Bayesian models do not work with undirected graphs. I'm trying to learn about the Markov Random Field Network, and so far all I have been able to do is create the graphical structure using a graphical LASSO. In directed graphs, there seems to be two stages: "structural learning" performed by some method, and then "parameter learning" performed by another method. My sense is that parameter learning tells you about the edge weights between each variable (feature) included in your model. My question is... so what? What do you do with a graph with edge weights? If I have a dataset that is observations by features, and my graph's nodes are the features from this dataset (gleaned from the graphical LASSO trying to emulate the inverse of the covariance matrix), what can I learn from this? Can I compare cohorts of my data (separated by target class value) and assign some sort of p-value analysis with the nodes? I am confused, I think, about the big picture of graphical models.
