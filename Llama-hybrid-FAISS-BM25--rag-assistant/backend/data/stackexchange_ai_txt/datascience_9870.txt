[site]: datascience
[post_id]: 9870
[parent_id]: 9850
[tags]: 
This answer is on the general side of cost functions, not related to TensorFlow, and will mostly address the "some explanation about this topic" part of your question. In most examples/tutorial I followed, the cost function used was somewhat arbitrary. The point was more to introduce the reader to a specific method, not to the cost function specifically. It should not stop you to follow the tutorial to be familiar with the tools, but my answer should help you on how to choose the cost function for your own problems. If you want answers regarding Cross-Entropy, Logit, L2 norms, or anything specific, I advise you to post multiple, more specific questions. This will increase the probability that someone with specific knowledge will see your question. Choosing the right cost function for achieving the desired result is a critical point of machine learning problems. The basic approach, if you do not know exactly what you want out of your method, is to use Mean Square Error (Wikipedia) for regression problems and Percentage of error for classification problems. However, if you want good results out of your method, you need to define good , and thus define the adequate cost function. This comes from both domain knowledge (what is your data, what are you trying to achieve), and knowledge of the tools at your disposal. I do not believe I can guide you through the cost functions already implemented in TensorFlow, as I have very little knowledge of the tool, but I can give you an example on how to write and assess different cost functions. To illustrate the various differences between cost functions, let us use the example of the binary classification problem, where we want, for each sample $x_n$ , the class $f(x_n) \in \{0,1\}$ . Starting with computational properties ; how two functions measuring the "same thing" could lead to different results. Take the following, simple cost function; the percentage of error. If you have $N$ samples, $f(y_n)$ is the predicted class and $y_n$ the true class, you want to minimize $\frac{1}{N} \sum_n \left\{ \begin{array}{ll} 1 & \text{ if } f(x_n) \not= y_n\\ 0 & \text{ otherwise}\\ \end{array} \right. = \sum_n y_n[1-f(x_n)] + [1-y_n]f(x_n)$ . This cost function has the benefit of being easily interpretable. However, it is not smooth; if you have only two samples, the function "jumps" from 0, to 0.5, to 1. This will lead to inconsistencies if you try to use gradient descent on this function. One way to avoid it is to change the cost function to use probabilities of assignment; $p(y_n = 1 | x_n)$ . The function becomes $\frac{1}{N} \sum_n y_n p(y_n = 0 | x_n) + (1 - y_n) p(y_n = 1 | x_n)$ . This function is smoother, and will work better with a gradient descent approach. You will get a 'finer' model. However, it has other problem; if you have a sample that is ambiguous, let say that you do not have enough information to say anything better than $p(y_n = 1 | x_n) = 0.5$ . Then, using gradient descent on this cost function will lead to a model which increases this probability as much as possible, and thus, maybe, overfit. Another problem of this function is that if $p(y_n = 1 | x_n) = 1$ while $y_n = 0$ , you are certain to be right, but you are wrong. In order to avoid this issue, you can take the log of the probability, $\log p(y_n | x_n)$ . As $\log(0) = \infty$ and $\log(1) = 0$ , the following function does not have the problem described in the previous paragraph: $\frac{1}{N} \sum_n y_n \log p(y_n = 0 | x_n) + (1 - y_n) \log p(y_n = 1 | x_n)$ . This should illustrate that in order to optimize the same thing , the percentage of error, different definitions might yield different results if they are easier to make sense of, computationally. It is possible for cost functions $A$ and $B$ to measure the same concept , but $A$ might lead your method to better results than $B$ . Now let see how different costs function can measure different concepts. In the context of information retrieval, as in google search (if we ignore ranking), we want the returned results to have high precision , not return irrelevant information have high recall , return as much relevant results as possible Precision and Recall (Wikipedia) Note that if your algorithm returns everything , it will return every relevant result possible, and thus have high recall, but have very poor precision. On the other hand, if it returns only one element, the one that it is the most certain is relevant, it will have high precision but low recall. In order to judge such algorithms, the common cost function is the $F$ -score (Wikipedia) . The common case is the $F_1$ -score, which gives equal weight to precision and recall, but the general case it the $F_\beta$ -score, and you can tweak $\beta$ to get Higher recall, if you use $\beta > 1$ Higher precision, if you use $\beta . In such scenario, choosing the cost function is choosing what trade-off your algorithm should do . Another example that is often brought up is the case of medical diagnosis, you can choose a cost function that punishes more false negatives or false positives depending on what is preferable: More healthy people being classified as sick (But then, we might treat healthy people, which is costly and might hurt them if they are actually not sick) More sick people being classified as healthy (But then, they might die without treatment) In conclusion, defining the cost function is defining the goal of your algorithm. The algorithm defines how to get there. Side note: Some cost functions have nice algorithm ways to get to their goals. For example, a nice way to the minimum of the Hinge loss (Wikipedia) exists, by solving the dual problem in SVM (Wikipedia)
