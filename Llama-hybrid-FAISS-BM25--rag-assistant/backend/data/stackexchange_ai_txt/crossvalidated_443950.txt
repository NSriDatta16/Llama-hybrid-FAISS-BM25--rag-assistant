[site]: crossvalidated
[post_id]: 443950
[parent_id]: 421153
[tags]: 
Based on those definitions: Nonparametric :Algorithms that do not make strong assumptions about the form of the mapping function are called nonparametric machine learning algorithms. By not making assumptions, they are free to learn any functional form from the training data. EX: k-Nearest Neighbors, Decision Trees Parametric :Assumptions can greatly simplify the learning process, but can also limit what can be learned. Algorithms that simplify the function to a known form are called parametric machine learning algorithms. EX: Logistic Regression, Linear Discriminant Analysis And in my knowledge I can: Yes, Bayesian Belief Networks with discrete variables are indeed nonparametric , because they are probabilistic models based conditional dependencies between their variables. I worked with those models (discrete) in ecology. BUT ,Bayesian networks with continuous variables make strong assumptions about their data (I believe one of them is that the variables follow a Gaussian distribution). These models themselves are parametric.
