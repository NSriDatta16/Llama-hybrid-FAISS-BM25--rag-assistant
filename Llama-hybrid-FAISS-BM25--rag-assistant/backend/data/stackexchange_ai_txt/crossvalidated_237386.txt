[site]: crossvalidated
[post_id]: 237386
[parent_id]: 
[tags]: 
Which part will save time if training neural network using GPU?

There are many work for training a deep neural network using GPU. From optimization perspective, which part saves time? Objective function evaluation? Gradient calculation? or something else? And and why? Is Certain matrix operations (say matrix multiplication) faster in GPU than CPU? In convex optimization Appendex C. We have flops count for each operation. In GPU are these changed? or GPU has much fast flops operations.
