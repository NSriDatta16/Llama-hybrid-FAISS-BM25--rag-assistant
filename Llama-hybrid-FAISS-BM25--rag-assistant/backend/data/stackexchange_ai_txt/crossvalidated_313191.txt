[site]: crossvalidated
[post_id]: 313191
[parent_id]: 311988
[tags]: 
This sounds like a good case for using a Bayes approach. For this to work well, you need some prior information. A convenient prior to use is a dirichlet. From the perspective of estimation, this amounts to adding "pseudo observations" to the observed counts. A simple way is to add $\frac {1}{C} $ counts to each category ($C $ is # categories), giving $p_i=\frac {n_i+C^{-1}}{1+\sum_jn_j}$. This is adding 1 data point worth of information, so wouldn't be dragging your estimate too far away from the observed data. It has the advantage of giving a non-zero estimate for each category, unlike the mle. If an even distribution is more what you expect, then you should increase the pseudo observation count. This means you have $p_i=\frac {n_i+C^{-1}m}{m+\sum_jn_j}$ where $m $ is the weight applied to the even distribution. $m=C$ is the "uniform" prior (also rule of succession), and $m=\frac {C}{2} $ is the jeffreys prior. These are standard non-informative priors, but they have problems in large dimensions. A better approach would be to add some hierarchy and structure to your model. All you have at present is a multinomial random variable with a large number of categories. You will need to think about the context of your problem more to decide which categories are similar in terms of how the symbols are generated. Hope this helps!
