[site]: crossvalidated
[post_id]: 353650
[parent_id]: 
[tags]: 
Sklearn logistic regression top coefficients meaning for sentiment analysis

I have a term document matrix, where each element represents the tf-idf value for the given term and document. There are 5000 features (terms) as columns which represents the top 5000 words, and each label is either 1 (positive sentiment) or 0 (negative sentiment). How do I interpret feature coefficients ( coef_ ) in sklearn's logistic regression for sentiment analysis? Are the largest positive coefficients most predictive of positive sentiment and the smallest coefficients most predictive of negative sentiment? For example, I found the following code that returns the top k features. However, I want to know what these actually represent. Additionally, this code only returns the features/terms that contribute to classifying the positive class and not the negative class, right? So if I wanted to do this, I would have to get the smallest coefficient values as well to see features are most predictive of the negative class? I want to make sure my understanding is correct. Thanks! # get the top features (terms) that contribute to prediction task def print_topk(vectorizer, clf, k): feature_names = vectorizer.get_feature_names() topk = np.argsort(clf.coef_[0])[-k:] # get the highest coefficient values print(" ".join(feature_names[j] for j in topk))
