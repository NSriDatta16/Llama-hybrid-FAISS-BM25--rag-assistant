[site]: crossvalidated
[post_id]: 377811
[parent_id]: 376664
[tags]: 
You're using so-called "feature importance" metrics derived from a tree-based model to determine the inputs to a linear method, just as in the linked post. Using a linear method doesn't make much sense when there are relevant nonlinear terms in the phenomenon you are studying; to a linear method, the nonlinearity is "invisible." By using GBM, your thesis is that the outcome is a nonlinear function of the inputs and is well-approximated by a tree structure. But by using PCA to tease out subpopulations, your thesis is that you just need to rotate the data. These are not consistent. A cousin to this problem (replacing gradient-boosted trees with random forest, and replacing PCA with a GLM), with an answer elaborating about how linear and nonlinear models can give different answers to the same question, can be found in Can a random forest be used for feature selection in multiple linear regression?
