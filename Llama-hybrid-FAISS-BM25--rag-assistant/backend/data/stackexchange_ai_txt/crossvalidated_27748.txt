[site]: crossvalidated
[post_id]: 27748
[parent_id]: 
[tags]: 
Relationship between two time series: ARIMA

Given the following two time series ( x , y ; see below), what is the best method to model the relationship between the long-term trends in this data? Both time series have significant Durbin-Watson tests when modelled as a function of time and neither are stationary (as I understand the term, or does this mean it only needs to be stationary in the residuals?). I have been told that this means I should take a first-order difference (at least, maybe even 2nd order) of each time series before I can model one as a function of the other, essentially utilising an arima(1,1,0), arima(1,2,0) etc. I don't understand why you need to detrend before you can model them. I understand the need to model the auto-correlation, but I don't understand why there needs to be differencing. To me, it appears as though detrending by differencing is removing the primary signals (in this case the long-term trends) in the data that we are interested in and leaving the higher-frequency "noise" (using the term noise loosely). Indeed, in simulations where I create an almost perfect relationship between one time series and another, with no autocorrelation, differencing the time series gives me results that are counterintuitive for relationship detection purposes, e.g., a = 1:50 + rnorm(50, sd = 0.01) b = a + rnorm(50, sd = 1) da = diff(a); db = diff(b) summary(lmx In this case, b is related strongly with a , but b has more noise. To me this shows that differencing doesn't work in an ideal case for detecting relationships between low frequency signals. I understand that differencing is commonly used for time-series analysis, but it appears to be more useful for determining relationships between high-frequency signals. What am I missing? Example Data df1
