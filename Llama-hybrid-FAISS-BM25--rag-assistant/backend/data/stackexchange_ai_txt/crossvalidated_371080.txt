[site]: crossvalidated
[post_id]: 371080
[parent_id]: 
[tags]: 
Question about the latent variable in EM algorithm

In mixture models, Expectation maximization algorithm (EM) is a commonly used method to estimate the model parameters. Suppose that I have bivariate mixture model with two mixture components, with mixture weights, $\pi_1$ and $\pi_2$ , respectively. EM introduces a $z$ variable which takes 1 if the point is come from the first mixture component, and takes 0 otherwise. These variables are assumed to be i.i.d and are distributed from multinomial ( $\pi_1$ , $\pi_2$ ). Is that correct? If yes, how they can have only {0,1} values and in the sometimes they have multinomial distribution? Here is the paragraph from the source: here is the link 3.2. EM algorithm In this section, we describe the EM algorithm (Dempster et al., 1977) to obtain the estimates for the parameters θ in a mixture of M-component D-vine densities, given the data set and the number of components M. The determination of M will be discussed later in Section 3.3. Assume that N observations, say $x_k = (x_{k,1}, . . . , x_{k,N} )$ where $k = 1, . . . , d$ , drawn randomly from a $M$ -component. Let us denote latent variables $z_{n} = (z_{n1}, . . . , z_{nm}, . . . , z_{nM})$ , where $z_{nm} = 1$ if $x_{n}$ comes from the $m$ -th component and $z_{nm}$ = 0 otherwise. Assume that $z_{n}$ is independent and identically distributed from a multinomial distribution, that is, $z_{n} ∼ Mult(M, π = (π_{1}, . . . , π_{M}))$ . Any help, please?
