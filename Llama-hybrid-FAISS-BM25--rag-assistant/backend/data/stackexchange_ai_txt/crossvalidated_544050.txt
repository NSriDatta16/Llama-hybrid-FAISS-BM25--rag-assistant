[site]: crossvalidated
[post_id]: 544050
[parent_id]: 
[tags]: 
Appropriate Use of Linear Mixed Model for Inference?

In this case, I have multiple samples of a particular enzyme that is stored in different conditions (2 storage conditions) over a period of time, and the concentrations of this enzyme in the samples are measured at different points in time. There are also three "types" of samples: QC standards that are made at various concentrations Samples from subjects known to have a condition that affects the concentration of the enzyme Samples from subjects that are known to not have this condition What we are interested in asking is: Does the change over time of the concentration of this enzyme (realistically, degradation or decrease in concentration) differ between sample types 1 and 3, and sample types 2 and 3? Does the change over time of the concentration of this enzyme differ depending on the starting enzyme concentration of the sample? Does the change over time of the enzyme concentration depend on the storage condition? I cannot really share the data, but what it basically looks like is the following: Sample_num concentration sample_type storage time initial_concentration Sample_num is just an ID for the sample, and all measurements on the same sample have the same number. Concentration is the measured concentration of the enzyme at that particular measurement time (which is in days). Sample_type is a factor with three levels corresponding to the three types of samples, with sample type 3 (as described above) as the reference. Storage refers to one of the two conditions under which the sample was stored. Initial_concentration is the initial concentration measurement for that sample number (at time = 0). To try to answer our questions, I tried to fit a linear mixed-effects model on this repeated measures data using lme4 in R. For storage, I set the dry storage conditions as the reference and created the dummy "ambient" variable. For sample type, I used sample type 3 above as the reference, and created dummy variables "sample_t_1" and "sample_t_2" . lmer_dat I included a random intercept term to allow the intercept to vary among the different samples, which seemed to make sense to me based on the very different starting concentrations among the samples. I did try to include a random slope for time using (time|sample_num) . I received a warning that my model was nearly unidentifiable with a very large eigenvalue, and the model failed to converge. In the process of fitting this model, I had a few questions: Is it appropriate to include the initial_concentration (and the initial_concentration x time interaction term) in the model? I think we'd expect the baseline measurement to be less "impactful" on the current measurement as time goes on, so if we were to include the initial concentration, I'd think we'd also want to include the initial_concentration x time interaction. From what I've read, people have also cautioned about adding baseline measurements in linear mixed models. When done in the correct settings, it can improve the efficiency of estimates, but when done incorrectly, it can lead to estimates for other fixed effects that apparently do not evaluate the effect that you think it would. In addition, one of the primary ways that the three samples type differ is the initial concentration of the sample. The QC standards cover a wide range of concentrations, and those who have this condition are known to have more of the enzyme than those who do not. If I do not include the initial concentration, what could be another way to investigate whether the change over time in concentration differs depending on starting concentration? Should I apply a log transformation to the concentration measurements, and/or should I perhaps use glmer() and use a different link function and family? Looking at a residuals vs fitted values plot (using plot(lmer_dat) ), it seems pretty clear that the variances of the error terms aren't equal, since the width of the band of the residuals is increases as the fitted values do. I'm not really sure what I should do here, if anything. I have tried applying a log transformation to the concentration values, which was attractive to the other clinicians as they liked exponentiating the beta coefficients to get multiplicative changes. However, I have also seen people caution against applying a log transformation to the response variable, but I am not quite understanding the general reasoning. Since the response variable is a measured concentration, which are real numbers from 0 to infinity, perhaps an identity link function with a Gaussian is not appropriate, but then I'm not sure what would be. A log link function is often used with a Poisson distribution, but this isn't count data. Once I have a reasonable model, I was planning to compare fixed effects using likelihood ratio tests. First, I would compare the above model (or whatever model is appropriate) with the nested model that excludes all of the fixed interaction terms. Then, if that was significant, I would individually perform likelihood ratio tests comparing the model that excludes all of the fixed interaction terms with the model that adds in one of the fixed interaction terms, and then apply a Bonferroni correction for the total number of tests I do. I have read that the p-values generated by the likelihood ratio tests for fixed effects are approximate and tend to be too small. Ultimately, if this whole linear mixed model and likelihood ratio test approach is not appropriate, I would be interested in learning about another approach to answer the three questions. Thank you so much.
