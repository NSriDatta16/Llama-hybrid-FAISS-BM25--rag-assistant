[site]: datascience
[post_id]: 78209
[parent_id]: 78189
[tags]: 
As you already know, a precision score (or recall, or f-score) is for a single class, and in the function the argument pos_label says which class. Now I'm going to guess that when pos_label is not provided and instead average is provided the function probably calculates the metric for every class and then returns the average of these values . A weighted average can be calculated with any number of classes, and since no pre-defined weights are provided we can reasonably assume that the function takes the proportion of the two classes as weights. So the result of: metrics.recall_score(test_sentiments,predicted_sentiments,average='weighted') is probably the weigthed average (by proportion of instances) of: metrics.recall_score(test_sentiments,predicted_sentiments,pos_label='positive') metrics.recall_score(test_sentiments,predicted_sentiments,pos_label='negative') If I'm not mistaken, this is equivalent to the micro-average recall.
