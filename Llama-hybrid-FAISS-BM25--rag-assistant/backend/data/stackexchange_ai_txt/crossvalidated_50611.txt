[site]: crossvalidated
[post_id]: 50611
[parent_id]: 45118
[tags]: 
The SVM is designed to determine the optimal decision boundary for only one ratio of false-positive and false-negative misclassification costs, so it is not really a fair comparison to change the threshold to adjust the sensitivity. A better approach would be to tune the regularisation parameters (C or nu) for each class independently (some packages support this, some don't) by optimising a cross-validation estimate of your statistic of interest. Note that to get an unbiased performance estimate, you will need to perform a nested cross-validation. Logistic regression doesn't suffer from this problem as the loss function is intended to minimise the error in estimating the posterior probability of class membership everywhere, rather than merely for p=0.5 (or some other value depending on the ratio of misclassification costs). I no longer use the SVM very much because for most applications, I do actually want the probabilities that logistic regression provides, however I use regularised logistic regression (which gives similar over-fitting avoidance you get with the SVM) and kernel logistic regression if I want a non-linear model (or Gaussian Process Classifiers for a Bayesian equivalent - although the difference in performance between GPC and KLR is generally quite small).
