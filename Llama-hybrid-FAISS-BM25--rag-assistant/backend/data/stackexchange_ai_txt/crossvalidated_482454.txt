[site]: crossvalidated
[post_id]: 482454
[parent_id]: 
[tags]: 
Why can't we use Monte carlo approximation for normalising constant in Baye's theorem

The normalising constant $Z$ in baye's theorem is the probability that the model generates the data $D$ . $$\begin{align}P(D) &= \int P(D|\theta)P(\theta)d\theta \\ &= E_{\theta \sim p(\theta)}[P(D|\theta)] \\ &= \frac{1}{N}\sum_{i=1}^NP(D|\theta)\end{align}$$ We can sample $\theta$ from the prior distribution and average the likelihood of $P(D|\theta)$ over many samples to estimate $Z$ . Can we use this method to approximate $Z$ ? Once we have $Z$ we have the whole posterior distribution $p(\theta|D)$ already ?
