[site]: crossvalidated
[post_id]: 251163
[parent_id]: 251156
[tags]: 
$Y$ has two possible values for any given value of $X$. According to the assumptions, $$\Pr(X=x|Y=0) = \exp(-\lambda_0) \frac{\lambda_0^x}{x!}$$ and $$\Pr(X=x|Y=1) = \exp(-\lambda_1) \frac{\lambda_1^x}{x!}.$$ Therefore (this is a trivial case of Bayes' Theorem) the chance that $Y=1$ conditional on $X=x$ is the relative probability of the latter, namely $$\Pr(Y=1|X=x) = \frac{\exp(-\lambda_1) \frac{\lambda_1^x}{x!}}{\exp(-\lambda_1) \frac{\lambda_1^x}{x!} + \exp(-\lambda_0) \frac{\lambda_0^x}{x!}}= \frac{1}{1 + \exp(\beta_0 + \beta_1 x)}$$ where $$\beta_0 = \lambda_1 - \lambda_0$$ and $$\beta_1 = -\log(\lambda_1/\lambda_0).$$ That indeed is the standard logistic regression model.
