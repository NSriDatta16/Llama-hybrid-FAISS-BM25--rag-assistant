[site]: crossvalidated
[post_id]: 370226
[parent_id]: 322109
[tags]: 
You are not limited by K bootstrap samples. You may create sampled subsets out of your training set as many times as you wish â€“ 100 times is considered to be enough. For every bag you get predictions for the test set, then you average them. And this is your output for the k-th fold. You repeat the procedure K times and average again to see the predictive power of your model. A bagging loop within a CV loop. The reason why we use CV is to reduce overfitting. If you only split your data train/val one time and then will search the best hyperparameters, you will likely overfit if your dataset is too small for the used architecture. What I see you doing in your scheme is to overfit K times and average these bad fits to get something new. I doubt if will be any better than... well, average. What we do in CV is to use the same architecture on different subsets and average their models' predictions. The aim is to get a better idea about this particular architecture than we could have using a single train/val split. But since your data is very small, there is a need of further decrease in test variance. Hence bagging within every fold. upd What you may do is to have two CV loops. One for hyperparameters tuning, and one for the resulting architecture evaluation.
