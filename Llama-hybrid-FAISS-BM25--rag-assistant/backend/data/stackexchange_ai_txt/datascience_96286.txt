[site]: datascience
[post_id]: 96286
[parent_id]: 95238
[tags]: 
I think the root confusion is the nuance between linear and affine relationships, which is not something that becomes a problem in most of data science (we generally allow affine relationships even if we use the word "linear"). The matrix $X$ has full rank: the columns demonstrate an affine relationship ( $x_2=10x_1+10$ ), but not a linear one. So $X^T X$ (which is $2\times2$ ) is indeed invertible, and everything proceeds normally. If you add an all-ones column to $X$ (to incorporate an intercept to the OLS), you elevate the affine relationship to a linear one, and you'll find that $X^T X$ is not invertible. The StandardScaler (in addition to scaling) centers the features, which again rips away the bias/shift, and turns the affine relationship to a linear one (of course, it's the identity relationship).
