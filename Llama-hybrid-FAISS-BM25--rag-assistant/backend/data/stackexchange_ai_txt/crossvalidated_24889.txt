[site]: crossvalidated
[post_id]: 24889
[parent_id]: 
[tags]: 
Bayesion priors in ridge regression with scikit learn's linear model

I'm using scikit learn's linear model to do ridge regression . Ridge regression penalizes parameters for moving away from zero. I want to penalize for moving away from a certain prior, with each parameter having a different prior. Is this possible with scikit learn's linear model? I know there's a BayesianRidge module there, but I'm not sure what it does.
