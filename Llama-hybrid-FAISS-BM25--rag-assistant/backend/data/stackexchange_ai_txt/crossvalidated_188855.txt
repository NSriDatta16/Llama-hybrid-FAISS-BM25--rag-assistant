[site]: crossvalidated
[post_id]: 188855
[parent_id]: 188848
[tags]: 
Yes, you should keep your test set for testing the model and your training set for training it if you are partitioning. Cross-validation can and should be applied to the training set during training- it's a way of doing your "peeking" without violating the metaphorical virginity of your test set. It seems to me that your issues with cross-validation regarding your time series forecast model result from insufficient customization of the cross validation method to the forecast method- i.e. it shouldn't be difficult to imagine a cross-validation which only uses prior data to the forecasted value. One such implementation in R is discussed here: http://robjhyndman.com/hyndsight/tscvexample/ And another has been implemented in the caret package, discussed here: http://www.r-bloggers.com/time-series-cross-validation-5/ Perhaps implementing a time-series-appropriate method such as these would help to allow you to avoid the temptation to go all the metaphorical way before it is appropriate to do so.
