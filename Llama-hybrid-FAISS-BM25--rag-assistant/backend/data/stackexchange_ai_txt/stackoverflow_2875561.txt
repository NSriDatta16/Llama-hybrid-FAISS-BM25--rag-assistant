[site]: stackoverflow
[post_id]: 2875561
[parent_id]: 2874640
[tags]: 
If memory permits store your data in a 2d array (really 3d, but I'll get to that later). This array will be indexed by (product_id, time_period). If your processing of the data permits it each element of the 2D array could be an accumulator of the new data so you read in a data element and then adjust the corresponding element of the the 2D array to reflect it. If this method works your data will be processed when you finish reading it in. If your processing requires you to have data from each data element present at one time then you could make each element of your 2D array a list (this is the 3rd D). It could be a variable length list if you don't know how many customer entries will be present for each (product_id, time_period). After you have read in your data you will need to revisit each element of the 2D array to process each list. How you arrange your array and how you visit the elements will matter for performance. You will probably want to declare this dynamically, but for this example struct element_t element[NUMBER_OF_PRODUCTS][NUMBER_OF_TIME_PERIODS]; // don't forget to initialize these elements to empty ... for (p = max_product_id; p >= 0; p--) { for (t = max_time_period; t >= 0; t--) { process(element[p][t]); } } Will work better if you want to process each product before moving to the next because. You can swap the declaration's row,column and the loops to achieve better cache hits if you want to process each time period (for all products) before moving to the next. You should note that this does the sorting for you without saying "sort this data". If memory does not permit, then you will probably want to store parts of your data to files as you read it in. This will have the same issues as the array/loop organization/cache hit optimization mentioned above, but it will be magnified many times over. At the end of reading in your main data you would want to be able to process all data from a particular temp file (possibly containing all data for a given product (xOR for a given time period)) before moving to the next. The main bad part of trying to do this is that when you are reading in the data it is very likely that you will have to deal with not being able to have every temp file open at the same time. This might require you to come up with a way of doing open file swapping (same as memory swapping, except what you are swapping is open files rather than memory pages). This would be a whole other problem, though.
