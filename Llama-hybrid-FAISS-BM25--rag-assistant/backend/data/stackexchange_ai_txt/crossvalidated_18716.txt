[site]: crossvalidated
[post_id]: 18716
[parent_id]: 13797
[tags]: 
I think this is another case where frequentist statistics can't give a direct answer to the question you actually want to ask, and so answers a (no so) subtly different question, and it is easy to misinterpret this as a direct answer to the question you actually wanted to ask. What we would really like to ask is normally what is the probability that the alternative hypothesis is true (or perhaps how much more likely to be true is it than the null hypothesis). However a frequentist analysis fundamentally cannot answer this question, as to a frequentist a probability is a long run frequency, and in this case we are interested in the truth of a particular hypothesis, which doesn't have a long run frequency - it is either true or it isn't. A Bayesian on the other hand can answer this question directly, as to a a Bayesian a probability is a measure of the plausibility of some proposition, so it is perfectly reasonable in a Bayesian analysis to assign a probability to the truth of a particular hypothesis. The way frequentists deal will particular events is to treat them as a sample from some (possibly fictitious) population and make a statement about that population in place of a statement about the particular sample. For example, if you want to know the probability that a particular coin is biased, after observing N flips and observing h heads and t tails, a frequentist analysis cannot answer that question, however they could tell you the proportion of coins from a distribution of unbiased coins that would give h or more heads when flipped N times. As the natural definition of a probability that we use in everyday life is generally a Bayesian one, rather than a frequentist one, it is all too easy to treat this as the pobability that the null hypothesis (the coin is unbiased) is true. Essentially frequentist hypothesis tests have an implicit subjectivist Bayesian component lurking at its heart. The frequentist test can tell you the likelihood of observing a statistic at least as extreme under the null hypothesis, however the decision to reject the null hypothesis on those grounds is entirely subjective, there is no rational requirement for you to do so. Essentiall experience has shown that we are generally on reasonably solid ground to reject the null if the p-value is suffciently small (again the threshold is subjective), so that is the tradition. AFAICS it doesn't fit well into the philosophy or theory of science, it is essentially a heuristic. That doesn't mean it is a bad thing though, despite its imperfections frequentist hypothesis testing provides a hurdle that our research must get over, which helps us as scientists to keep our self-skepticism and not get carried away with enthusiasm for our theories. So while I am a Bayesian at heart, I still use frequentists hypothesis tests on a regular basis (at least until journal reviewers are comfortable with the Bayesain alternatives).
