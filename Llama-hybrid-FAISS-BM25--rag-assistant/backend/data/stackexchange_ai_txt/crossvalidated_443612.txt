[site]: crossvalidated
[post_id]: 443612
[parent_id]: 401402
[tags]: 
This is likely because the transformer shares the weights of the embedding layer and the output softmax. The scales you would use for the embeddings is different than the scale you use for a fully connected layer.
