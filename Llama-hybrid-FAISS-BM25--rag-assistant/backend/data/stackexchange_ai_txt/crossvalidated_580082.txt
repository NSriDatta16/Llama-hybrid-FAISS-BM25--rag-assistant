[site]: crossvalidated
[post_id]: 580082
[parent_id]: 495935
[tags]: 
Scoring rules are cost functions that evaluate how far probabilistic predictions deviate from observations. Proper scoring rules have minimum cost when true probabilities are reported; strictly proper scoring rules have minimum cost only when true probabilities are reported. The choice of scoring rule is closely connected to "how to translate these results into real-world decision making." If misclassification costs are scaled so that the cost of a false positive is $c$ and that of a false negative is $(1-c)$ , then the minimum-cost cutoff for classification is at a probability of $c$ .* The Wikipedia section on Interpretation of proper scoring rules is worth quoting in detail, as it shows how this idea extends over the entire probability range to construct proper scoring rules: All proper scoring rules are equal to weighted sums ... of the losses in a set of simple two-alternative decision problems that use the probabilistic prediction, each such decision problem having a particular combination of associated cost parameters for false positive and false negative decisions. A strictly proper scoring rule corresponds to having a nonzero weighting for all possible decision thresholds. Any given proper scoring rule is equal to the expected losses with respect to a particular probability distribution over the decision thresholds; thus the choice of a scoring rule corresponds to an assumption about the probability distribution of decision problems for which the predicted probabilities will ultimately be employed... So the choice of scoring rule comes down to how much weight you want to place on different portions of the probability scale or, equivalently, at different relative false-positive and false-negative costs. For example, the log-loss used in logistic regression puts a lot of weight on correct probabilities at the extremes. That might not always be the best choice. I've found " Loss Functions for Binary Class Probability Estimation and Classification: Structure and Applications ," by Andreas Buja, Werner Stuetzle, and Yi Shen (2005) to be very helpful in thinking through these issues. Some of it is perhaps a bit more heavily mathematical than this question asks for, but there is enough non-mathematical content to make the fundamental issues pretty clear. Those authors show how to fit linear models with proper scoring rules via iteratively reweighted least squares. They also describe a family of scoring rules related to beta functions that can differentially weight regions of the probability scale, and how several scoring rules--boosting loss, log loss, squared error (Brier score)--and even misclassification error (as a limiting case) can be expressed within that family. That family is implemented in the scoring package to which you link, although perhaps not very clearly explained there (it's a fam option in the calcscore() function). There is a less mathematical, more application-oriented presentation by E. C. Merkle (package author) and M. Steyvers, " Choosing a Strictly Proper Scoring Rule ," Decision Analysis Vol. 10, No. 4, December 2013, pp. 292â€“304. That paper explains other families of scoring rules implemented in the package, and should be a good starting point for study. * That answer also shows how to incorporate gains from correct classifications into this schema, following O'Brien et al, " Cost-sensitive Multi-class Classification from Probability Estimates ," Proceedings of the 25th International Conference on Machine Learning, Helsinki, Finland, 2008.
