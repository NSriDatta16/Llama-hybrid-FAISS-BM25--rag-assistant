[site]: crossvalidated
[post_id]: 627495
[parent_id]: 
[tags]: 
prior distribution for iid gaussian, with a known variance

I have been reading Pattern Recognition and Machine Learning by Bishop, and I have a question regarding the prior distribution of an iid Gaussian with known variance. The relationship $\dfrac{n}{\sigma^2} + \dfrac{1}{\sigma^2_0} = \dfrac{1}{\sigma^2_n}$ is derived in the text. The derivation stems from the fact that you have Gaussian likelihood, coupled with a Gaussian prior. Hence, the posterior is also of Gaussian form. In the relationship, variance is known, while the mean is unknown. I believe (and you correct me if this is wrong) $\sigma^2_0$ is the prior variance, $\sigma^2_n$ is the variance of the data set (?) My question is: I thought the variance is known. Why are we solving this relationship? Or this can be used in sequential learning as the data are slowly trickling in (with known variance), we can use $\sigma^2_0$ as the prior variance. As the $n-$ th data point comes in, $\sigma^2$ is the variance of the past $n-1$ data points, and your posterior variance is $\sigma^2_n$ . Please clarify this?
