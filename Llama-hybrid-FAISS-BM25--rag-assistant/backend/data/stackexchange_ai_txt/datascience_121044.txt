[site]: datascience
[post_id]: 121044
[parent_id]: 38540
[tags]: 
The currently accepted answer by @lads is outdated and the answer of @zijun is too complex. This is what I used (mix of the 2 answers) : import math import torch from transformers import GPT2LMHeadModel, GPT2TokenizerFast tokenizer = GPT2TokenizerFast.from_pretrained('distilgpt2') model = GPT2LMHeadModel.from_pretrained('distilgpt2') model.eval() def score(sentence): tokenize_input = tokenizer.tokenize(sentence) tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)]) loss = model(tensor_input, labels=tensor_input)["loss"].item() return math.exp(loss) a=['there is a book on the desk', 'there is a plane on the desk', 'there is a book in the desk'] print([score(i) for i in a]) # > [156.42900910254363, 289.88481709498836, 186.85249335013398] ```
