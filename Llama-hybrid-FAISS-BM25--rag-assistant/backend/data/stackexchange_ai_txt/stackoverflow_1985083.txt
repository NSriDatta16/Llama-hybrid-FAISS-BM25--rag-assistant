[site]: stackoverflow
[post_id]: 1985083
[parent_id]: 1984871
[tags]: 
The nit-picking answer is that you should compare it to idiomatic Python: The original code takes 34 seconds on my machine. A for loop ( FlorianH's answer ) with += and xrange() takes 21 . Putting the whole thing in a function reduces it to 9 seconds! That's much faster than Perl (15 seconds on my machine)! Explanation: Python local vars are much faster than globals . (For fairness, I also tried a function in Perl - no change) Getting rid of the j variable reduced it to 8 seconds: print sum(1 for i in xrange(100000000)) Python has the strange property that higher-level shorter code tends to be fastest :-) But the real answer is that your "micro-benchmark" is meaningless. The real question of language speed is: what's the performance of an average real application? To know that, you should take into account: Typical mix of operations in complex code. Your code doesn't contain any data structures, function calls, or OOP operations. A large enough codebase to feel cache effects â€” many interpreter optimizations trade memory for speed, which is not measured fairly by any tiny benchmark. Optimization opportunities : after you write your code, IF it's not fast enough, how much faster can you easily make it? E.g. how hard is it to offload the heavy lifting to effecient C libriries? PyPy's benchmarks and Octane are good examples of what realistic language speed benchmarks look like. If you want to talk number crunching, Python IS surprisingly popular with scientists. They love it for the simple pseudo-math syntax and short learning curve, but also for the excellent numpy library for array crunching and the ease of wrapping other existing C code. And then there is the Psyco JIT which would probably run your toy example well under 1 second, but I can't check it now because it only works on 32-bit x86. EDIT : Nowdays, skip Psyco and use PyPy which a cross-platform actively improving JIT.
