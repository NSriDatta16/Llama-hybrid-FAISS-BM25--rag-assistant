[site]: crossvalidated
[post_id]: 260167
[parent_id]: 260166
[tags]: 
To answer your overall question, you put multiple features created out of one raw feature into a linear model so that the linear model can capture non-linear relationships between the feature and response. There are bad ways to do this, ok ways to do this, and good ways to do this. This person seems to fall into the "not-awful, but not good" bucket. It's a GLM model but I don't think that's relevant here. It's definitely relevant. This kind of thing is much less important when you are using a totally non-parametric learning algorithm like a random forest or gradient boosted tree model. In those, it's the job of the algorithm itself to fit to the shape of the feature / response relationship. It's going to be hard for someone to counter We iterated through a bunch of features and these gave the best result. because, looking at the model, it appears that's almost certainly what was done. This is standard in some industries (insurance in the US being one I have a lot of background in), but is not a very good way to do things. Better would be to use non-parameteric fits like a cubic spline, and then use cross validation to tune both the number of knots (similar to the degree of the polynomial in your example), and a regularization parameter. Why not throw in log(log(Issue Age)) and (Issue Age)^3 too? Probably the person fitting the model had the good sense to stop before they drastically overfit their data, even if their over all methodology is not great. The most important thing in all this is, however you want to choose your transformations of predictors, you need to stringently validate that you are making good decisions. The best tools of the trade here are regularization, cross validation, and the bootstrap, and all modelers should be using them.
