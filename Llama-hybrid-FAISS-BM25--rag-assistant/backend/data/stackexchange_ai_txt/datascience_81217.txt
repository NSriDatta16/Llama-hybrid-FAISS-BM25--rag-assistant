[site]: datascience
[post_id]: 81217
[parent_id]: 81197
[tags]: 
There are lots of experiment u can try. One might not decide the overfitting and underfitting based on the confusion matrix completely. Deal with imbalance data : First prepare a smooth sampling of your data where u need to keep thing in mind to take uniform number of sample in each class and run it and evaluate its accuracy. Because sometime due to imbalance data it seems it gives good accuracy but it have been biased model. Feature Engineering : If playing with random forest than try to find out gini index or entropy value of each and every feature (in your case is 12). Where u will see which feature is prominent each class. That's how u might neglect some of the features and run new experiment and check out results.
