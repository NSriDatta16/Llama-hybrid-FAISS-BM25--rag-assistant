[site]: crossvalidated
[post_id]: 284622
[parent_id]: 
[tags]: 
Q-Learning Reward function racing game

I have written a deep Q-learning algorithm with this website (without terminal state) for a car racing game where you get reset when get of the track. I got input of speed, some distance sensors and the progress of the track in percent. Output is the acceleration of the car and the steering angle. My question is how should is set the reward and the function to get target Q-Value. The neural net accepts values in range $(0,1]$ as input and target, so my idea was to set the reward to progressInPercent/2 + 0.5 (or + 0.01) when the car was reset. My problem is since the neural net (Q-Function) can only take $(0,1]$ as target, how do I make sure these values don't grow over 1? Using tt = rr + γmaxa’Q(ss’, aa’) as training target doesn't work. Or should I take something else as reward?
