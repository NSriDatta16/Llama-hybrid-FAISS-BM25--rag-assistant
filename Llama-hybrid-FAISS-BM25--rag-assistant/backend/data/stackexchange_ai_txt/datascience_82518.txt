[site]: datascience
[post_id]: 82518
[parent_id]: 
[tags]: 
Confusion matrix to check results

I am a new user in StackExchange and a new learner of Data Science. I am working on better understanding how to estimate the results collected, specifically fake users extracted from a dataset running some analysis. Using a specific algorithm, I found some users User_Alg user1 user2 user3 user28 user76 user67 and I would like to estimate accuracy of my algorithm comparing with the dataset which contains all the fake users manually labelled: User_Dat user1 user5 user28 user76 user67 user2 user29 As you can see, there are some users, in my extracted list ( User_Alg ), who are missing, i.e. not included in the list manually labelled (all the fake users in the dataset; User_Dat ). I have thought to use a confusion matrix to check the accuracy, but I would like to know from people with more experience in statistics and machine learning than me, if such method can be ok and how it looks like, or if you recommend another approach. Thanks for your attention and your time.
