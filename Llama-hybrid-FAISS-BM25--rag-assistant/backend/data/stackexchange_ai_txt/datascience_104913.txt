[site]: datascience
[post_id]: 104913
[parent_id]: 
[tags]: 
Smoothing target variable

I am training a regression model (using quantile regression forest) to forecast crop yield deviations from trend (residuals) using weather variables with different lag times. Trying to improve the accuracy and confidence of my results, I recently tested replacing the target variable with a smoothed version of it (computed with locally weighted scatterplot smoothing, LOWESS) using as independent variable a feature with no lag time (i.e., with lag time = 0) trying to remove noise from the measured data. In the figure below, the crosses represent the observed values, the red dots are outliers, and the gray line is the smoothed version of the dependent variable. I got significant improvements in the result, but something doesn't seem right with this approach. I have been looking into the use of smoothing techniques in machine learning and have found that, indeed, smoothing is a technique used in data preprocessing, feature engineering, and data mining for noise filtering (e.g., here or here ; or here , applied for time series forecasting). On the one hand, it sounds logical to remove noise from the target variable to estimate "true values" derived from the process I am trying to model; however, I've learned that the preprocessing is applied to features (explanatory variables) and I am not sure that smoothing the target variable is a valid procedure. To summarize: Is it valid to replace the target variable with a smoothed version of it? If it is, given that the independent variable used to smooth the target variable is not available a priori, how should I proceed? a. train the model with the smoothed target variable and test it with the raw target variable; or b. train and test the model with the smoothed target variable. Any thoughts will be appreciated.
