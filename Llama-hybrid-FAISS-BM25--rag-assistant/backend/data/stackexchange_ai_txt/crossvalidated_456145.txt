[site]: crossvalidated
[post_id]: 456145
[parent_id]: 
[tags]: 
R - how to use `structural.em()` (from package `bnlearn`) to implement hidden variable learning in simple Bayesian network

I want to use the function structural.em() to infer a hidden variable. As an example, consider the following code. library(bnlearn) n Result: A B C 1 0.3671696 5.815983 1.219824527 2 1.5497029 7.367819 -4.746303052 3 -0.6208338 4.866273 -0.001548993 4 0.2813009 4.920910 1.060921207 5 -0.2560889 4.665860 0.241103140 6 -0.7785561 2.378321 8.488789586 Mathematically, we have $$\begin{align*} A &\sim N(0,1)\\ B|A=a &\sim N(5+2a,1)\\ C|B=b &\sim N(10-2b,1)\\ \end{align*} $$ I am able to learn the structure: learned Result Bayesian network learned via Score-based methods model: [A][B|A][C|B] nodes: 3 arcs: 2 undirected arcs: 0 directed arcs: 2 average markov blanket size: 1.33 average neighbourhood size: 1.33 average branching factor: 0.67 learning algorithm: Hill-Climbing score: BIC (Gauss.) penalization coefficient: 3.107304 tests used in the learning procedure: 7 optimized: TRUE And then train the network dag.bnlearn.1 Result Bayesian network parameters Parameters of node A (Gaussian distribution) Conditional density: A Coefficients: (Intercept) -0.04004687 Standard deviation of the residuals: 1.076409 Parameters of node B (Gaussian distribution) Conditional density: B | A Coefficients: (Intercept) A 4.992321 1.883480 Standard deviation of the residuals: 0.9608345 Parameters of node C (Gaussian distribution) Conditional density: C | B Coefficients: (Intercept) B 10.917354 -1.974601 Standard deviation of the residuals: 1.026824 which accurately learns the parameters for the network. I cannot find an example of using structural.em() on hidden varaibles. I successfully implemented an example with missing data by doing mydata2 Result Bayesian network learned from Missing Data model: [A][B|A][C|B] nodes: 3 arcs: 2 undirected arcs: 0 directed arcs: 2 average markov blanket size: 1.33 average neighbourhood size: 1.33 average branching factor: 0.67 learning algorithm: Structural EM score-based method: Hill-Climbing parameter learning method: Maximum Likelihood imputation method: Posterior Expectation (Likelihood Weighting) penalization coefficient: 3.107304 tests used in the learning procedure: 31 optimized: TRUE Notice, how this example works as well. But if I try, all missing, then I get an error mydata3 Result Error in check.data(x, allow.levels = TRUE, allow.missing = TRUE, warn.if.no.missing = TRUE, : at least one variable has no observed values. I checked the documentation using help("structural.em",package="bnlearn") . The documentation says If at least one of the variables in the data x does not contain any observed value, the start network must be specified and it must be a bn.fit object. Otherwise, structural.em() is unable to complete the first maximization step because it cannot fit the corresponding local distribution(s). But if I try to fit a bn.fit object and then input it in the start argument, I get the following error dag.bnlearn.2 Result Error in distribution(fitted = fitted, nodes = event, evidence = evidence, : all weights are NA, the probability of the evidence is impossible to compute. Where am I going wrong? Can someone show me how to implement this toy example so that I can use the hidden learning feature of structural.em() properly to infer A from the data of B and C?
