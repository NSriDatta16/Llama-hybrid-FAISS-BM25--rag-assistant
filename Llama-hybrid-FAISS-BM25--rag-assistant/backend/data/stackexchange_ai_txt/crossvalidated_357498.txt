[site]: crossvalidated
[post_id]: 357498
[parent_id]: 355781
[tags]: 
There are some difficulties that are common to all nonparametric bootstrapping estimates of confidence intervals (CI), some that are more of an issue with both the "empirical" (called "basic" in the boot.ci() function of the R boot package and in Ref. 1 ) and the "percentile" CI estimates (as described in Ref. 2 ), and some that can be exacerbated with percentile CIs. TL;DR : In some cases percentile bootstrap CI estimates might work adequately, but if certain assumptions don't hold then the percentile CI might be the worst choice, with the empirical/basic bootstrap the next worst. Other bootstrap CI estimates can be more reliable, with better coverage. All can be problematic. Looking at diagnostic plots, as always, helps avoid potential errors incurred by just accepting the output of a software routine. Bootstrap setup Generally following the terminology and arguments of Ref. 1 , we have a sample of data $y_1, ..., y_n$ drawn from independent and identically distributed random variables $Y_i$ sharing a cumulative distribution function $F$ . The empirical distribution function (EDF) constructed from the data sample is $\hat F$ . We are interested in a characteristic $\theta$ of the population, estimated by a statistic $T$ whose value in the sample is $t$ . We would like to know how well $T$ estimates $\theta$ , for example, the distribution of $(T - \theta)$ . Nonparametric bootstrap uses sampling from the EDF $\hat F$ to mimic sampling from $F$ , taking $R$ samples each of size $n$ with replacement from the $y_i$ . Values calculated from the bootstrap samples are denoted with "*". For example, the statistic $T$ calculated on bootstrap sample j provides a value $T_j^*$ . Empirical/basic versus percentile bootstrap CIs The empirical/basic bootstrap uses the distribution of $(T^*-t)$ among the $R$ bootstrap samples from $\hat F$ to estimate the distribution of $(T-\theta)$ within the population described by $F$ itself. Its CI estimates are thus based on the distribution of $(T^*-t)$ , where $t$ is the value of the statistic in the original sample. This approach is based on the fundamental principle of bootstrapping ( Ref. 3 ): The population is to the sample as the sample is to the bootstrap samples. The percentile bootstrap instead uses quantiles of the $T_j^*$ values themselves to determine the CI. These estimates can be quite different if there is skew or bias in the distribution of $(T-\theta)$ . Say that there is an observed bias $B$ such that: $$\bar T^*=t+B,$$ where $\bar T^*$ is the mean of the $T_j^*$ . For concreteness, say that the 5th and 95th percentiles of the $T_j^*$ are expressed as $\bar T^*-\delta_1$ and $\bar T^*+\delta_2$ , where $\bar T^*$ is the mean over the bootstrap samples and $\delta_1,\delta_2$ are each positive and potentially different to allow for skew. The 5th and 95th CI percentile-based estimates would directly be given respectively by: $$\bar T^*-\delta_1=t+B-\delta_1; \bar T^*+\delta_2=t+B+\delta_2.$$ The 5th and 95th percentile CI estimates by the empirical/basic bootstrap method would be respectively ( Ref. 1 , eq. 5.6, page 194): $$2t-(\bar T^*+\delta_2) = t-B-\delta_2; 2t-(\bar T^*-\delta_1) = t-B+\delta_1.$$ So percentile-based CIs both get the bias wrong and flip the directions of the potentially asymmetric positions of the confidence limits around a doubly-biased center . The percentile CIs from bootstrapping in such a case do not represent the distribution of $(T-\theta)$ . This behavior is nicely illustrated on this page , for bootstrapping a statistic so negatively biased that the original sample estimate is below the 95% CIs based on the empirical/basic method (which directly includes appropriate bias correction). The 95% CIs based on the percentile method, arranged around a doubly-negatively biased center, are actually both below even the negatively biased point estimate from the original sample! Should the percentile bootstrap never be used? That might be an overstatement or an understatement, depending on your perspective. If you can document minimal bias and skew, for example by visualizing the distribution of $(T^*-t)$ with histograms or density plots, the percentile bootstrap should provide essentially the same CI as the empirical/basic CI. These are probably both better than the simple normal approximation to the CI. Neither approach, however, provides the accuracy in coverage that can be provided by other bootstrap approaches. Efron from the beginning recognized potential limitations of percentile CIs but said: "Mostly we will be content to let the varying degrees of success of the examples speak for themselves." ( Ref. 2 , page 3) Subsequent work, summarized for example by DiCiccio and Efron ( Ref. 4 ), developed methods that "improve by an order of magnitude upon the accuracy of the standard intervals" provided by the empirical/basic or percentile methods. Thus one might argue that neither the empirical/basic nor the percentile methods should be used, if you care about accuracy of the intervals. In extreme cases, for example sampling directly from a lognormal distribution without transformation, no bootstrapped CI estimates might be reliable, as Frank Harrell has noted . What limits the reliability of these and other bootstrapped CIs? Several issues can tend to make bootstrapped CIs unreliable. Some apply to all approaches, others can be alleviated by approaches other than the empirical/basic or percentile methods. The first, general, issue is how well the empirical distribution $\hat F$ represents the population distribution $F$ . If it doesn't, then no bootstrapping method will be reliable. In particular, bootstrapping to determine anything close to extreme values of a distribution can be unreliable. This issue is discussed elsewhere on this site, for example here and here . The few, discrete, values available in the tails of $\hat F$ for any particular sample might not represent the tails of a continuous $F$ very well. An extreme but illustrative case is trying to use bootstrapping to estimate the maximum order statistic of a random sample from a uniform $\;\mathcal{U}[0,\theta]$ distribution, as explained nicely here . Note that bootstrapped 95% or 99% CI are themselves at tails of a distribution and thus could suffer from such a problem, particularly with small sample sizes. Second, there is no assurance that sampling of any quantity from $\hat F$ will have the same distribution as sampling it from $F$ . Yet that assumption underlies the fundamental principle of bootstrapping. Quantities with that desirable property are called pivotal . As AdamO explains : This means that if the underlying parameter changes, the shape of the distribution is only shifted by a constant, and the scale does not necessarily change. This is a strong assumption! For example, if there is bias it's important to know that sampling from $F$ around $\theta$ is the same as sampling from $\hat F$ around $t$ . And this is a particular problem in nonparametric sampling; as Ref. 1 puts it on page 33: In nonparametric problems the situation is more complicated. It is now unlikely (but not strictly impossible) that any quantity can be exactly pivotal. So the best that's typically possible is an approximation. This problem, however, can often be addressed adequately. It's possible to estimate how closely a sampled quantity is to pivotal, for example with pivot plots as recommended by Canty et al . These can display how distributions of bootstrapped estimates $(T^*-t)$ vary with $t$ , or how well a transformation $h$ provides a quantity $(h(T^*)-h(t))$ that is pivotal. Methods for improved bootstrapped CIs can try to find a transformation $h$ such that $(h(T^*)-h(t))$ is closer to pivotal for estimating CIs in the transformed scale, then transform back to the original scale. The boot.ci() function provides studentized bootstrap CIs (called "bootstrap- t " by DiCiccio and Efron ) and $BC_a$ CIs (bias corrected and accelerated, where the "acceleration" deals with skew) that are "second-order accurate" in that the difference between the desired and achieved coverage $\alpha$ (e.g., 95% CI) is on the order of $n^{-1}$ , versus only first-order accurate (order of $n^{-0.5}$ ) for the empirical/basic and percentile methods ( Ref 1 , pp. 212-3; Ref. 4 ). These methods, however, require keeping track of the variances within each of the bootstrapped samples, not just the individual values of the $T_j^*$ used by those simpler methods. In extreme cases, one might need to resort to bootstrapping within the bootstrapped samples themselves to provide adequate adjustment of confidence intervals. This "Double Bootstrap" is described in Section 5.6 of Ref. 1 , with other chapters in that book suggesting ways to minimize its extreme computational demands. Davison, A. C. and Hinkley, D. V. Bootstrap Methods and their Application, Cambridge University Press, 1997 . Efron, B. Bootstrap Methods: Another look at the jacknife, Ann. Statist. 7: 1-26, 1979 . Fox, J. and Weisberg, S. Bootstrapping regression models in R. An Appendix to An R Companion to Applied Regression, Third Edition (Sage, 2019). Revision as of 21 September 2018 . DiCiccio, T. J. and Efron, B. Bootstrap confidence intervals. Stat. Sci. 11: 189-228, 1996 . Canty, A. J., Davison, A. C., Hinkley, D. V., and Ventura, V. Bootstrap diagnostics and remedies. Can. J. Stat. 34: 5-27, 2006 .
