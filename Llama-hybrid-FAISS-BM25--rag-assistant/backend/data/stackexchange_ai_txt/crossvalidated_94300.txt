[site]: crossvalidated
[post_id]: 94300
[parent_id]: 94295
[tags]: 
Many SVM implementations address this by assigning different weights to positive and negative instances. Essentially you weigh the samples so that the sum of the weights for the positives will be equal to that of the negatives. Of course, in your evaluation of the SVM you have to remember that if 95% of the data is negative, it is trivial to get 95% accuracy by always predicting negative. So you have to make sure your evaluation metrics are also weighted so that they are balanced. Specifically in libsvm , which you added as a tag, there is a flag that allows you to set the class weights ( -w I believe, but check the docs ). Finally, from personal experience I can tell you that I often find that an SVM will yield very similar results with or without the weight correction.
