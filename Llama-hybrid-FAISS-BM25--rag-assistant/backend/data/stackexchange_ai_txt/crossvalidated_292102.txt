[site]: crossvalidated
[post_id]: 292102
[parent_id]: 292013
[tags]: 
The answer to this question can boil down to one's personal opinion, so here is my personal opinion: as a statistician, I must, whenever possible, report standard errors. MCMC standard errors are no exception. If only the results are replicable and the seed is provided, the authors are assuming that the standard errors serve the purpose of reproducibility, which is only a secondary benefit. The primary purpose of standard errors in MCMC is to ensure enough samples were obtained to estimate the quantity of interest. That is, there were enough samples to ensure that the standard error was small. The paper Markov Chain Monte Carlo: Can We Trust the Third Significant Figure? almost entirely addresses this question. They discuss how very few academic journals report MCMC standard errors, and that this must change. They then go on to explain how these errors can be calculated and reported. Since in MCMC, standard errors can theoretically be made arbitrarily small, they ask you to simulate samples until the standard error is less than some pre-specified number. In this case you don't have to directly report standard errors, since it is evident that the standard errors are small. The theory for the above paper comes from Jones et.al (2006) . Much work has been done since the above paper(s). New work has indicated that for multivariate problems, since standard errors are matrices, it doesn't make sense in reporting them. Instead, one can simulate until the multivariate effective sample size is smaller than a pre-specified lower bound (check my answer here ). To conclude, it is important to report standard errors in one form or the other. Since in MCMC, standard errors can be made arbitrarily small, one can replace reporting standard errors with reporting effective sample size as well. (see Vats et. al ).
