[site]: crossvalidated
[post_id]: 267545
[parent_id]: 267539
[tags]: 
The short answer is that it can go pretty badly, but only if one or both tails of the sampling distribution is really fat . This R code generate a million sets of 30 gamma-distributed variables and take their mean; it can be used to get a sense of what the sampling distribution of the mean looks like. If the normal approximation works as intended, the results should be approximately normal with mean 1 and variance 1/(30 * shape) . f = function(shape){replicate(1E6, mean(rgamma(30, shape, shape)))} When shape is 1.0, the gamma distribution becomes an exponential distribution , which is pretty non-normal. Nevertheless, the non-Gaussian parts mostly average out and so Gaussian approximation isn't so bad: There's clearly some bias, and it would be good to avoid that when possible. But honestly, that level of bias probably won't be the biggest problem facing a typical study. That said, things can get much worse. With f(0.01) , the histogram looks like this: Log-transforming the 30 sampled data points before averaging helps a lot, though: In general, distributions with long tails (on one or both sides of the distribution) will require the most samples before the Gaussian approximation starts to become reliable. There are even pathological cases where there will literally never be enough data for the Gaussian approximation to work, but you'll probably have more serious problems in that case (because the sampling distribution doesn't have a well-defined mean or variance to begin with).
