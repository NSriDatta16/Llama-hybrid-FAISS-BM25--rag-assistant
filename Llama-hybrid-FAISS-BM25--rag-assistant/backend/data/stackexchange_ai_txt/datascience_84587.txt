[site]: datascience
[post_id]: 84587
[parent_id]: 
[tags]: 
Bug in sentiment analysis and classification for unlabeled text

I'm working on the transcript of Trump and Biden's debate and want to analyze the sentences and classify negative, positive, or neutral comments, but I ran into one problem. I used both TextBlob and the transformers pipeline to analyze the sentiment but unfortunately in both ways, there are some very disastrous flaws! For example,I found that TextBlob recognizes -0.70 polarity in "fewer people are dying every day" (negative comment) or the transformers pipeline recognizes "The audience here in the hall has promised to remain silent." as a negative comment with 0.99 percent certainty ! Why do you think it's happening? Is there any way we can prevent this? Is there any way better than this for analyzing the sentiment of unlabeled text? Also, I'm not comfortable with sentences like "Oh, Really?!" being classified as neutral. It's more of a sarcastic or negative comment I think. Here's my colab notebook , I've added one "Problem" markdown where I've observed these examples.
