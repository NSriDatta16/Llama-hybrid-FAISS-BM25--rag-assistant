[site]: crossvalidated
[post_id]: 271265
[parent_id]: 
[tags]: 
Skewness, Kurtosis and Box-Cox for Censored Data?

I am currently working on a classification plus regression problem on a dataset with over 500 predictors. Each predictor has on average 15% in-range values (above a defined threshold of signal detection. The rest of the values are simply represented as "out-of-range". This represents a scenario of censored data . I would like to know if it is highly important to bring my predictor distributions close to Normal distribution through Box-Cox transform before I can work on scaling and dimensionality reduction. Or, is the need for bringing the predictor distributions closer to Normality dependent on the machine learning model I will be applying? I know for linear models, it would be helpful but kind of confused for other models. Please let me know if you need any other information.
