[site]: datascience
[post_id]: 2455
[parent_id]: 2268
[tags]: 
NLP is very vast and varied. Here are a few basic tools in NLP: Sentence splitting: Identifying sentence boundaries in text Tokenization: Splitting a sentence into individual words Lemmatization: Converting a word to its root form. E.g. says, said, saying will all map to root form - say Stemmer: It is similar to a lemmatizer, but it stems a word rather than get to the root form. e.g. laughed, laughing will stem to laugh. However, said, saying will map to sa - which is not particularly enlightening in terms of what "sa" means POS tagger: Tags a word with the Part of Speech - what is a noun, verb, preposition etc. Parser: Links words with POS tags to other words with POS tags. E.g. John ate an apple. Here John and apple are nouns linked by the verb - eat. John is the subject of the verb, and apple is the object of the verb. If you are looking for the state of the art for these tools, check out StanfordCoreNLP , which has most of these tools and a trained model to identify the above from a document. There is also an online demo to check out stanfordCoreNLP before downloading and using it with your application. NLP has several subfields. Here are a few of them: Machine Translation: Automatic Translation from one language to another Information Retrieval: Something like a search engine, that retrieves relevant information from a large set of documents based on a search query Information Extraction: Extract concepts and keywords - such as names of people, locations, times, synonyms etc. Deep Learning has lately become a new field of NLP, where a system tries to understand a document like a human understands it.
