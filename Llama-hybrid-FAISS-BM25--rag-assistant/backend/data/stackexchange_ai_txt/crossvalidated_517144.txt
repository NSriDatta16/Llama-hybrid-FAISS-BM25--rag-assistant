[site]: crossvalidated
[post_id]: 517144
[parent_id]: 517107
[tags]: 
You could use a multilevel model, allowing you to evaluate mean improvement on the exercises over time, as well as the individual students' improvements: > ## Generate some example data: > set.seed(42) > student_id exercise occasion pre_means pre post data head(data) student_id occasion result 1 1 0 51 2 1 0 51 3 1 0 52 4 1 0 51 5 1 0 49 6 1 0 49 > tail(data) student_id occasion result 359 13 1 57 360 13 1 57 361 13 1 57 362 13 1 58 363 13 1 59 364 13 1 58 Fit a multilevel model and inspect results: > library("lme4") > mod summary(mod) Linear mixed model fit by REML ['lmerMod'] Formula: result ~ occasion + (occasion | student_id) Data: data REML criterion at convergence: 1106.9 Scaled residuals: Min 1Q Median 3Q Max -2.9752 -0.6869 -0.0289 0.7411 3.4557 Random effects: Groups Name Variance Std.Dev. Corr student_id (Intercept) 1.3601 1.1662 occasion1 1.4492 1.2038 0.23 Residual 0.9892 0.9946 Number of obs: 364, groups: student_id, 13 Fixed effects: Estimate Std. Error t value (Intercept) 50.5275 0.3317 152.31 occasion1 10.1374 0.3498 28.98 Correlation of Fixed Effects: (Intr) occasion1 0.169 The fixed intercept gives us the mean performance at the pre assessment (fixed effect (Intercept) ). The fixed slope gives us the mean increase in score over time (fixed effect occasion1 ). Thus, on average, the students scores 50.53 at the pre assessment, and 50.53+10.14=60.67 at the post assessment. I also included a random intercept and slope w.r.t. student through specification of (occasion | student_id) . This allows us to evaluate the deviation of each student from the means at the pre and post assessments: > ranef(mod) $student_id (Intercept) occasion1 1 0.63710704 1.0109655 2 -1.27956242 0.2978854 3 0.07244512 0.5224094 4 0.43161216 0.9322671 5 -0.15613902 0.0578274 6 -0.55199220 -2.0837120 7 1.12865296 0.2775566 8 -0.96452167 1.0888319 9 1.42650490 1.8997896 10 -0.78622053 -1.5240657 11 0.51396430 -1.0470807 12 1.73538894 -0.7678323 13 -2.20723960 -0.6648423 with conditional variances for “student_id” > coef(mod) $student_id (Intercept) occasion1 1 51.16458 11.148328 2 49.24791 10.435248 3 50.59992 10.659772 4 50.95908 11.069630 5 50.37133 10.195190 6 49.97548 8.053651 7 51.65613 10.414919 8 49.56295 11.226195 9 51.95398 12.037152 10 49.74125 8.613297 11 51.04144 9.090282 12 52.26286 9.369530 13 48.32023 9.472520 attr(,"class") [1] "coef.mer" The result of ranef provides the deviation of each student from the fixed effects. The result of coef provides the fixed effects, added to the students' deviations from it. Thus, student 7 scored 1.13 above the mean at the pre assessment, and 0.28 above the mean at the post assessment, corresponding to a mean score of 51.66 at the pre assessment, and the mean score having increased with 10.41 at the post assessment. Further possibilities: You could also estimate the difficulty of the exercises, and have students' ability estimates corrected for the difficulty of the exercises. This would be similar to a Rasch model (although you have a continuous response for each exercise, and in a Rasch model the response is dichotomous). See e.g, https://www.jamesuanhoro.com/post/2018/01/02/using-glmer-to-perform-rasch-analysis/ (section Multilevel logistic regression or MML; you can just replace glmer with lmer ). The exercises are scored 1-100, if this is a percentage, a beta regression might be more appropriate. For multilevel beta regression, see e.g., Model Assumptions: LMER / GLMER Model where Dependent Variable is a Percentage
