[site]: crossvalidated
[post_id]: 30767
[parent_id]: 30763
[tags]: 
Your question sounds confusing. When you say accuracy of the model, are you just referring to how well it predicts or do you mean how well it simulates the behavior of weather in New York City? I don't think you can assess the latter. As to the former, I would compute the mean square prediction error. By that I mean use the model to predict the mean annual temperature for each of the 30 years (presumably based on available inputs that the mode needs to get the estimates) and take the average squared difference between it and the actual recorded mean annual temperatures. This gives you an estimate but not the accuracy of the estimate. So you may have a standard for the accuracy and you want to test the hypothesis that accuracy is better than a certain level. Now I can give a somewhat vague description of how to do this. It is admittedly vague because I do not know what inputs go into the model to make the prediction. The idea would be to make small perturbations to the input and see how these perturbations affect the accuracy of the prediction. This would give you a distribution of mean square errors from which you could estimate a p-value for your hypothesis. All this assumes that you have a sensible way to perturb the inputs that would characterize the sampling variability in the inputs. The resulting estimates would then provide a representation of the variability of the individual predictions and from that the variability in the estimated means square error of prediction.
