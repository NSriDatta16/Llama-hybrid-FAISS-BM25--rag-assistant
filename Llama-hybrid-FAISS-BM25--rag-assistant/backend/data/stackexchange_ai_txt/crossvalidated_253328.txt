[site]: crossvalidated
[post_id]: 253328
[parent_id]: 253322
[tags]: 
It is an artifact of the methodology that you are using. You could avoid this by using a Bayesian model with a prior probability of non-positive variance of zero percent. Technically, an impossible answer is impossible using a Bayesian methodology. It is possible to get impossible answers using a Frequentist methodology. The defense of this is that you are protected against false positives $1-\alpha$ percent of the time, but the price is that you can get strange or impossible answers from time to time. The literature is full of weird effects you can create. Technically, a negative variance would imply the data is drawn from the complex numbers, but the complex numbers are not ordered so you couldn't create an ordinary probability distribution over them. In practice it is due to small samples, bad models or weird outliers. I would go down the bad model path. SAS provides a brief explanation at https://v8doc.sas.com/sashtml/stat/chap69/sect12.htm You can dig through their bibliography to get original source material. Still, if I were you I would presume you had a bad model. There are many problems out there in real world models that people often miss and you see them as weird results. It could be a weird sample or too small a sample, but I am prejudiced toward presupposing bad models. It is so simple for there to be something hidden in the real world that has an impact on a calculation. Frequentist models can be fragile or robust. The same is true for Bayesian models. This should be a warning of a fragility. Bayesian models cannot give impossible answers if they are properly formed, but they can have other sources of fragility. If I were you, I would assume that something in your model made it fragile. Think of a new way to ask a similar question.
