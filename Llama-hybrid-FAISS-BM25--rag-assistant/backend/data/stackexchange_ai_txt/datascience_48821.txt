[site]: datascience
[post_id]: 48821
[parent_id]: 
[tags]: 
Why real-world output of my classifier has similar label ratio to training data?

I trained a neural network on balanced dataset, and it has good accuracy ~85%. But in real world positives appear in about 10% of the cases or less. When I test network on set with real world distribution it seems to assign more positive labels than needed tending to balanced proportion as in training set. What can be the reason of such behavior and what should I do solve it? I'm using Keras and combination of LSTM and CNN layers.
