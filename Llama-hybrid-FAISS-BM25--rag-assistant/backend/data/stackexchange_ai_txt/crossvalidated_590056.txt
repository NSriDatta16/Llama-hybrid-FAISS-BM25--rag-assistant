[site]: crossvalidated
[post_id]: 590056
[parent_id]: 
[tags]: 
How to *formalize mathematically* that a binary classifier has no predictive performance?

The objective of supervised learning is to induce a function $f_\theta$ , where $f_\theta$ is from a family of functions $f_\theta \in F$ , from a training set $D^{tr}=\{(x_0^{tr},y_0^{tr})\ldots, (x_n^{tr},y_n^{tr})\} \subseteq \mathcal{X} \times \mathcal{Y}$ where $\mathcal{X} \times \mathcal{Y}$ denote the domain of the predictors $X$ , and the target $Y$ respectively. Now I want to start a theorem stating that the predictive performance of the model $f_\theta$ is the one of a random classifier, regardless of the model $f_\theta$ used. So no predictive performance. I believe, using the AUC=0.5 can be an option, but is there any more elegant way to state this? Edit I am referring specifically to binary classification. My question applies to the math formulation.
