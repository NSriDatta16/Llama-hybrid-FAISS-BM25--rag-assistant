[site]: crossvalidated
[post_id]: 119773
[parent_id]: 118707
[tags]: 
We have a variable A which denotes a percentage between 0 and 1. The variable is not normally distributed but has a very left skewed distribution. About 5% of the observations are zero, most observations are below 0.02, the others are below 0.04. There is a second nominally scaled variable B with four factors. We want to know if A and B are independent. The t-Test (test if the mean of A within a subgroup of B differs from the overall mean) or ANOVA seem to be inappropriated because A is not normally distributed. i) The assumption is not about the marginal distribution but the conditional (within-factor-level) distribution. ii) it's relatively easy to avoid the normality assumption; simply choose a reasonable measure of association, and you can test the null of no association against the alternative of some association. Moreover the χ2-Goodness-Of-Fit-Test (test if the means of A over each subgroup of B fit a equally distributed variable) should not be used because the expected values are below 5 (actually they are between 0.02 and 0.03). That's not how the chi-squared test works at all. That restriction about expected values applies to the distribution of counts . If you're doing a chi-square based on something other than counts, you must proceed very carefully (it doesn't work to do $\sum_i (O_i-E_i)^2/E_i$ , for starters). The next idea is to transform the variable A into an ordinal variable (e.g. [0.0,0.01) [0.01,0.02) ...) and to apply the χ2-Test of independency. However, by this way some information is lost. Certainly; it would be better to keep the ordering in A. Is there any other way to test if A and B are correlated Yes. Which measure of correlation would you like? or if the means and the variances of the subgroups differ significantly? Yes. Do you want to test means and variances separately, or in some combined way? Or are you just interested in some more general measure of difference of distribution than means alone would suggest? Is there any correlation measure between a categorial and a interval scaled variable when the later is not normally distributed? To calculate a measure doesn't require a normal distribution. The assumption of normality makes the calculation of the null-distribution of test statistics easier, but you don't need to it simply calculate correlation. But, yes, there are a number of suitable correlation measures you might choose. It really depends on what question you're more interested in answering about your data, and then it's down to what kinds of things you prefer. The overall goal is to analyse if A depends on B. In a first step it would be good to show that the within-subgroup-means are (not) significantly different. Normal distribution of variable A: A is neither normally distributed at all nor within the subgroups of B. It looks to me like this could be done with a permutation test, essentially akin to an ANOVA but without requiring a particular distributional assumption. You could instead consider multinomial logistic regression perhaps, to see if B category membership is related to A (i.e. interchanging the role of predictor and response from an ANOVA-like analysis. One can assume that "10 hours" is a count -- no, one can't. It's an interval of time, not a count of events, and more crucially, I see no basis to think it has the properties of a count that would be required to make the usual form of chi-squared work. So no. If you had a basis on which to assume normality, you could perhaps still construct a form of chi-square, but it would be different in form from the kind applied to counts. Correlation: We want to have some sort of "index" which measures the interrelation between A and B, a measure comparable to Pearson product-moment correlation coefficient or the point-biserial correlation coefficient. Unfortunately we have not found such a coefficient for the special case where one variable is nominal scaled and the other interval scaled. There's a measure called the eta coefficient, the eta correlation ratio, and a variety of other names. It's a measure of nonlinear association. Assumptions it is stated that ANOVA assumes that "the distributions of the residuals are normal." We wonder if the assumption is violated by A? Your answers already indicates that it is, but that shouldn't be a problem.
