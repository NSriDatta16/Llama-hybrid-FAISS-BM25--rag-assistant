[site]: crossvalidated
[post_id]: 158341
[parent_id]: 158267
[tags]: 
"Embedding" in the machine learning data visualization context typically means finding a map from the source objects (usually either high-dimensional vectors or arbitrary objects endowed with some kind of distance/similarity function) to a 2- or 3-dimensional space for visualization purposes. The goal here isn't usually to make distances easy to calculate in the new space; instead, it's so they can be visualized. For example, "locally linear embedding" is a fairly popular technique. This is related to the general notion of metric embeddings, that is representing objects in one metric space by another metric space so as to minimally change the distances. One common use of that in recent machin learning work is approximate kernel embeddings. It's possible some of the things you've seen refer to this more general sense, though without references we can't know.
