[site]: datascience
[post_id]: 73408
[parent_id]: 
[tags]: 
What information does output of [SEP] token captures in BERT?

After reading around on the web I came to understand that the output representation of the special token [CLS] captures the representation of a sentence (am I correct?). My primary question is what information does the output embedding of [SEP] token (T_SEP) captures? My other doubt is if I input a bunch of sentences into BERT separated by [SEP] does the output embedding of [CLS] contain information about all the sentences?
