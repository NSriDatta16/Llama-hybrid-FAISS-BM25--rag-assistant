[site]: datascience
[post_id]: 88177
[parent_id]: 
[tags]: 
Machine translator giving only on character as output for all the words

I had trained a machine translation model using 1.4 million examples.( hindi to english ). strangely the loss plateaus at the same point 0.8301 and while trying the inference the output is always the same no matter what the input is. i am using GRU both in encoder and decoder. class Encoder(tf.keras.Model): def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz): super(Encoder, self).__init__() self.batch_sz = batch_sz self.enc_units = enc_units self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform') # @tf.function( # input_signature=[[ # tf.TensorSpec(shape=[None, 55], dtype=tf.int32), # tf.TensorSpec(shape=[None, embedding_dim], dtype=tf.float32) # ]] # ) # @tf.function def call(self, inputs): x, hidden = inputs x = self.embedding(x) print(x.shape) print(hidden.shape) output, state = self.gru(x, initial_state = hidden) return output, state def model(self): a = tf.keras.Input(shape=(55)) b = tf.keras.Input(shape=(256)) return tf.keras.Model(inputs=[a, b], outputs=self.call(a, b)) def initialize_hidden_state(self): return tf.zeros((self.batch_sz, self.enc_units)) class BahdanauAttention(tf.keras.layers.Layer): def __init__(self, units): super(BahdanauAttention, self).__init__() self.W1 = tf.keras.layers.Dense(units) self.W2 = tf.keras.layers.Dense(units) self.V = tf.keras.layers.Dense(1) def call(self, query, values): # query hidden state shape == (batch_size, hidden size) # query_with_time_axis shape == (batch_size, 1, hidden size) # values shape == (batch_size, max_len, hidden size) # we are doing this to broadcast addition along the time axis to calculate the score query_with_time_axis = tf.expand_dims(query, 1) # score shape == (batch_size, max_length, 1) # we get 1 at the last axis because we are applying score to self.V # the shape of the tensor before applying self.V is (batch_size, max_length, units) score = self.V(tf.nn.tanh( self.W1(query_with_time_axis) + self.W2(values))) # attention_weights shape == (batch_size, max_length, 1) attention_weights = tf.nn.softmax(score, axis=1) # context_vector shape after sum == (batch_size, hidden_size) context_vector = attention_weights * values context_vector = tf.reduce_sum(context_vector, axis=1) return context_vector, attention_weights class Decoder(tf.keras.Model): def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz): super(Decoder, self).__init__() self.batch_sz = batch_sz self.dec_units = dec_units self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform') self.fc = tf.keras.layers.Dense(vocab_size, activation='softmax') # used for attention self.attention = BahdanauAttention(self.dec_units) # @tf.function( # input_signature=[[ # tf.TensorSpec(shape=[None, 1], dtype=tf.int32), # tf.TensorSpec(shape=[None, embedding_dim], dtype=tf.float32), # tf.TensorSpec(shape=[None, 55, embedding_dim], dtype=tf.float32) # ]] # ) # @tf.function def call(self, inputs): x, hidden, enc_output = inputs # enc_output shape == (batch_size, max_length, hidden_size) context_vector, attention_weights = self.attention(hidden, enc_output) # x shape after passing through embedding == (batch_size, 1, embedding_dim) x = self.embedding(x) # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size) x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # passing the concatenated vector to the GRU output, state = self.gru(x) # output shape == (batch_size * 1, hidden_size) output = tf.reshape(output, (-1, output.shape[2])) # output shape == (batch_size, vocab) x = self.fc(output) return x, state, attention_weights def model(self): a = tf.keras.Input(shape=(1)) b = tf.keras.Input(shape=(256)) c = tf.keras.Input(shape=(55, 256)) return tf.keras.Model(inputs=[a, b, c], outputs=self.call(a, b, c)) BATCH_SIZE = 8 embedding_dim = 256 units = 256 vocab_inp_size = len(inp_lang.word_index)+1 vocab_tar_size = len(targ_lang.word_index)+1 target_tensor_train)).shuffle(BUFFER_SIZE) trainTextGenerator = DataGenerator().sequentialImageGenerator('training',trainData,trainTarget,BATCH_SIZE) testTextGenerator = DataGenerator().sequentialImageGenerator('testing',testData,testTarget,BATCH_SIZE) what are the possible reasons due to which the output is same all the time?
