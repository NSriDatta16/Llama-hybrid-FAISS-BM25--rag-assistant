[site]: crossvalidated
[post_id]: 584080
[parent_id]: 584063
[tags]: 
I agree with your mentor that this is a bad idea. By randomly selecting the split that you will evaluate, you put the different actual hyperparameter values on unequal footings: maybe K =5 is best, but it got selected with the hardest split and so its accuracy was poor in the search. Indeed, since you mention the sklearn classes, note that you cannot easily do what you describe using RandomizedSearchCV . For each hyperparameter point (randomly) selected, models are always fitted-and-scored on every split, and those metrics averaged over folds. As for your question (1), it depends on how much computational expense you can handle. If you can and desire to search over all the values of $K$ , then do the grid search. If that'll take too much time (or if you want to search over other hyperparameters), then do a randomized search (or something more clever like a line search or Bayesian search).
