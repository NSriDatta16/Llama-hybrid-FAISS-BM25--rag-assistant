[site]: crossvalidated
[post_id]: 313981
[parent_id]: 
[tags]: 
How do you check if a neural network has the exploding gradient problem?

Given a formula for a particular RNN, is there a mathematical way to determine if it will suffer from the exploding/vanishing gradient problem? For example I might try an RNNs in which the hidden state gets updated via: $$h_{t+1} = \frac{1}{2}(h_t + \tanh( W[h_t,x_t] + b )$$ or $$h_{t+1} = tanh(h_t + \tanh( W[h_t,x_t] + b )$$ where $x$ is the input, $W$ are weights and $b$ is a bias. How would I check if any of these formulas would suffer from the gradient problem?
