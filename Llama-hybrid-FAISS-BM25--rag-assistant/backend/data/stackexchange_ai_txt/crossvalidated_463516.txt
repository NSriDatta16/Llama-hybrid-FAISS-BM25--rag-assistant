[site]: crossvalidated
[post_id]: 463516
[parent_id]: 
[tags]: 
Why are neural networks better at avoiding local minima?

In simulated annealing , from my understanding, it is a process where it stochastically searches the whole landscape at the beginning for the global minima and then hones down on the best solution it can find. With neural networks , how does it do this when you set the weights only once and randomly. Changes fall straight into local minima with gradient descent . How does it get out of this and find a better solution?
