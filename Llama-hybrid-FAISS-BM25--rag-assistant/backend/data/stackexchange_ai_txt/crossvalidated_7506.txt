[site]: crossvalidated
[post_id]: 7506
[parent_id]: 7497
[tags]: 
Gelman et al. (2003) say: there has long been a desire for prior distributions that can be guaranteed to play a minimal role in the posterior distribution. Such distributions are sometimes called 'reference prior distributions' and the prior density is described as vague, flat, or noninformative .[emphasis from original text] Based on my reading of the discussion of Jeffreys' prior in Gelman et al. (2003, p.62ff, there is no consensus about the existence of a truly non-informative prior, and that sufficiently vague/flat/diffuse priors are sufficient. Some of the points that they make: Any prior includes information, including priors that state that no information is known. For example, if we know that we know nothing about the parameter in question, then we know something about it. In most applied contexts, there is no clear advantage to a truly non-informative prior when sufficiently vague priors suffice, and in many cases there are advantages - like finding a proper prior - to using a vague parameterization of a conjugate prior. Jeffreys' principle can be useful to construct priors that minimize Fisher's information content in univariate models, but there is no analogue for the multivariate case When comparing models, the Jeffreys' prior will vary with the distribution of the likelihood, so priors would also have to change there has generally been a lot of debate about whether a non-informative prior even exists (because of 1, but also see discussion and references on p.66 in Gelman et al. for the history of this debate). note this is community wiki - The underlying theory is at the limits of my understanding, and I would appreciate contributions to this answer. Gelman et al. 2003 Bayesian Data Analysis, Chapman and Hall/CRC
