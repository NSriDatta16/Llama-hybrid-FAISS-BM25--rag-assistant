[site]: datascience
[post_id]: 88545
[parent_id]: 
[tags]: 
How to combine two logistic regression models trained on different set of data?

My data has a hierarchy structure - meaning that there is an N class at level 1 and an M class at level M . After training both models separately with a different set of data (both are Logistic regression but can be changed) I want to predict to N + M classes . Currently, I am solving it by collecting all data before training and adding examples from level 2 to level 1 results in (N + 1) classes (+ 1 meaning all examples from level 2) and if the model at level 1 predicts that "+1" class then a send the query to the second model. But collecting the examples before training is costly and also the training set is unbalanced after collecting. Pseudocode: clf1 = LogisticRegression() clf1.fit(X1 + X2, Y1 + ["ID of +1 class"] * len(Y2)) clf2 = LogisticRegression() clf2.fit(X2, Y2) if cl1.predict(X_test_example) == ["ID of +1 class"]: clf2.precict(X_test_example) But I need to preserve this hierarchical structure so the merging the two models directly is not possible. Is there a way to combine two outputs of classification models (in a form of the probability distribution) to get meaningful output are avoid problems with the overconfidence of models? Pseudocode: clf1 = LogisticRegression() clf1.fit(X1, Y1) clf2 = LogisticRegression() clf2.fit(X2, Y2) combined_clf = clf1 + clf2
