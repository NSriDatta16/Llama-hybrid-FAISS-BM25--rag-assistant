[site]: datascience
[post_id]: 24643
[parent_id]: 
[tags]: 
How to average classifiers with AUC metric?

I am modeling a binary classification and my loss function is the gini function (normalized area under the curve). Here's my implementation: Split the data with k-folds Train k classifiers Now I have k classifiers, but I need one classifier. So the naive approach is: $$prediction_i = \frac{prediction_{i1} + prediction_{i2} + ... + prediction_{ik} }{k}$$ There may be possible problems with this combining technique. For example, gini is scale invariant. I could take prediction1 and scale it with exp(p_i) and then scale prediction2 with sqrt(p_i). These would have zero affect on scoring the individually but it would mess up my combining step. What is the most appropriate combining function?
