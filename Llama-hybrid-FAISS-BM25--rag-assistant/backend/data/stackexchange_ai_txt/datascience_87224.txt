[site]: datascience
[post_id]: 87224
[parent_id]: 87193
[tags]: 
Having 2 uncorrelated normal variables $x_1 \sim N(0, 1)$ and $x_2 \sim N(0, 1)$ , one can correlate them through a linear transformation: $$A = \begin{bmatrix}a & b \\ c & d\end{bmatrix}$$ $$X' = AX$$ The covariance matrix of the transformed correlated variables $X'$ is given by: $$\Sigma' = A A^T$$ For a rotation by an angle $\theta$ , and scaling for adding individual standard deviations, the transform is (sign is same as that given): $$A = \begin{bmatrix}cos(\theta) & sin(\theta) \\ -sin(\theta) & cos(\theta)\end{bmatrix} \begin{bmatrix}\sigma_1 & 0 \\ 0 & \sigma_2\end{bmatrix}$$ This produces the covariance matrix $\Sigma'$ as: $$\Sigma' = \begin{bmatrix}\sigma_1cos(\theta) & \sigma_2sin(\theta) \\ -\sigma_1sin(\theta) & \sigma_2cos(\theta)\end{bmatrix} \begin{bmatrix}\sigma_1cos(\theta) & -\sigma_1sin(\theta) \\ \sigma_2sin(\theta) & \sigma_2cos(\theta)\end{bmatrix}$$ The cross-variance component is given by: $$\Sigma'_{12} = \sigma_1\sigma_2(cos^2(\theta)-sin^2(\theta))+(\sigma_2^2-\sigma_1^2)cos(\theta)sin(\theta)$$ This is the relation of cross-variance on angle $\theta$ . Setting $\theta = 45^\circ$ we get: $$\Sigma'_{12} = \frac{\sigma_2^2-\sigma_1^2}{2}$$ Setting $\sigma_1 = 0.333$ and $\sigma_2 = 1$ then $\Sigma'_{12} = 0.445$ Note $n = \frac{1}{tan(\theta)} \ne \Sigma'_{12}$ does not represent the covariance component as shown by analysis above. PCA decomposes the covariance matrix into un-correlated components. In other words it undoes the rotation (the scaling remains), since the rotation correlated the components in the first place. Explicitly PCA decomposes the covariance matrix into: $$\Sigma' = U S U^T$$ where $U$ is an orthogonal matrix of eigen-vectors and $S$ is a diagonal matrix which represents individual variances. Going back to $\Sigma' = A A^T$ and representing the rotation by $R$ we have: $$\Sigma' = R \begin{bmatrix}\sigma_1^2 & 0 \\ 0 & \sigma_2^2\end{bmatrix} R^T$$ Thus the orthogonal matrix of eigen-vectors $U$ corresponds to the (orthogonal) rotation matrix $R$ . Thus the eigen-vectors should ( precisely in theory, approximately in practise ) correspond to the rotation matrix (up to some sign factor and permutation which remains arbitrary). For further info see: Bivariate normal distribution Understanding the Covariance Matrix Interesting Properties of the Covariance Matrix
