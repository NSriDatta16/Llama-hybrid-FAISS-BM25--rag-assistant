[site]: crossvalidated
[post_id]: 55073
[parent_id]: 
[tags]: 
Taking average of linear regression results

Say I have a very large sample of observations, like a thousand of them, and I want to do (multiple) linear regression on them, i.e., regressing the response variable on the predictors. Now instead of doing so, I would randomly sample a subset of that large sample (say half of it, or a third of it, or even a fourth) and do regression analysis on that subset only. So I do this for $n$ times and each time I have a set of results, like coefficient estimates, $p$-values, etc. Finally I take the average of all the $n$ independent sets of results to get the final regression results. The question is: Would this rather "awkward" method be equivalent to the straightforward one (doing regression on all the observations that I have)? By "equivalent" I mean the coefficient estimates (signs and magnitudes) and $p$-values resulted from the two methods are the same, or insignificantly different. My second question is, as we all know, that in order to have a good regression analysis, it is often required to have a sufficiently large number of observations. What about the other way round? If I have too large a sample, like thousands of observations, should I just fit them all or should I sample a subset from it and fit?
