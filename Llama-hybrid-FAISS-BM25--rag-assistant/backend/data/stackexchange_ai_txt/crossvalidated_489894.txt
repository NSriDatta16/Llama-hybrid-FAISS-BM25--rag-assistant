[site]: crossvalidated
[post_id]: 489894
[parent_id]: 
[tags]: 
Does anyone in practice actually develop supervised model from scratch outside of classroom setting?

I have a question in regards to why bother with developing a model from scratch and perform hyperparameter tuning when you can just use transfer learning for supervised learning. The way that a machine learning model for supervised learning is developed is (provided that we have a good dataset), come up with some architecture train the model using first-order method validate using validation set tune the network to get good validation set performance test And tuning the network involves adjusting the learning rate, batch-size, which is fine because these are model independent (no part of the model is affected). But then there are also things like changing the number of hidden layers, number of neurons in each layer, and the choice of activation function, which is model dependent, because you are completely changing the model itself. The question then becomes, since we are changing our model anyways, why not just grab an off-of-the-shelf model (such as VGG, GoogLeNet, etc.) which are known to perform well and start there to begin with, thereby potentially saving us a lot of work? It doesn't seem logical for us to develop a model from scratch (as typically taught to students) which often times we have a feeling that it might not work so well, then gradually switch to more complicated architectures through a trial-and-error process of tuning, when you can directly start with the complicated architecture and do tuning on top of it. Does anyone in practice actually develop model from scratch outside of classroom setting?
