[site]: crossvalidated
[post_id]: 319364
[parent_id]: 227173
[tags]: 
Besides the already mentioned autoencoders, one can try exploiting Johnson-Lindenstrauss' lemma with random projections or random subspace methods. Random projections are $\mathcal{O}(k d N)$, with $N$ the number of samples of dimension $d$ and $k$ the target dimension, cf [1]. A bit of googling will get you some very recent results, in particular for sparse datasets. [1] Random projection in dimensionality reduction: applications to image and text data .
