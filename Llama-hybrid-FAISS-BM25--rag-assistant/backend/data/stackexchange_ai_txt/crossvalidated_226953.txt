[site]: crossvalidated
[post_id]: 226953
[parent_id]: 
[tags]: 
Convolutional Neural Network - how to ensure filters of same layer learn different features?

Reference: http://deeplearning.net/tutorial/lenet.html To form a richer representation of the data, each hidden layer is composed of multiple feature maps, $\{h^{(k)}, k=0..K\}$. The weights W of a hidden layer can be represented in a 4D tensor containing elements for every combination of destination feature map, source feature map, source vertical position, and source horizontal position. What I can't understand: let's say we slide 2 3-D filters across image, producing two feature maps. How we can be sure, that parameters of our 2 filters won't move close to same value through backpropagation? So that we won't obtain from 3 channels (RGB) two channels, which are highly correlated? And the more filters I want to introduce, the less obvious for me that some of them (at least) or many of them (in worst case) won't be basically similar vectors in weights space ($w_{1}, w_{2}, w_3 ... w_n .$)
