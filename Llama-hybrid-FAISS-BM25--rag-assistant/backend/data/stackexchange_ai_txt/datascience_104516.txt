[site]: datascience
[post_id]: 104516
[parent_id]: 
[tags]: 
How to implement ID3

I'm trying to follow the suggested outline form implementing ID3 # Step 1- Calculate MC (Message Conveyed) for the given dataset (let us call it file TF) in reference to the class attribute # MC(TF) = -p1*log2(p1) - p2*log2(p2) # For n classes MC(TF) = -p1log2(p1) - p2*log2(p2)-...-pn*log2(pn) # The probabilities are approximated by relative frequencies. # Step 2- Calculate Gain for every attribute in the training set . # Loop 1: # For each attribute (Aj) Do: # Consider the attribute is a node from which k branches are emanating, # where k is the number of unique values in the attribute # Temporarily, split the file TF into K new files based on the unique values in the attribute Aj. # Let us call these new files F1, . . ., Fk # Total =0; # Loop 2 # for each new file Fi Do: # Calculate MC for the file and call it MC(Fi). # Calculate weight for file Fi and call it Weight(Fi) Weight(Fi) = |Fi|/|TF| # Calculate the weighted MC (WMC) for file Fi # WMC(Fi) = Weight(Fi) * MC(Fi) # Total = Total + MC(Fi) # End of loop 2 # Calculate Gain of Aj # Gain(Aj) = MC(TF) – Total; # End of Loop 1 # The attribute with the highest gain is the winner. # Permanently split the file TF into K new files based on the K unique values of the winner attribute. # Remove the winner attribute from all new K files. # Now you have the root of the tree (the winner attribute) and this tree has k leaves, and each leaf has its own dataset. # Step 3- Examine dataset of each leaf. # If the attribute class has the same value for all the records in the leaf’s dataset, then mark the leaf as “no split” else mark it as “split”. # Step 4- For each leaf’s dataset that is marked “Split” Do. # The dataset become the new TF TF = leaf’s dataset # Go to Step 1; The code that I have written for this program is written as follows: from numpy.core.defchararray import count import pandas as pd import numpy as np import numpy as np from math import ceil, floor, log2 from sklearn.decomposition import PCA from numpy import linalg as LA from sklearn.tree import DecisionTreeClassifier from sklearn.naive_bayes import GaussianNB def calculate_metrics(tp, tn, fn, p, n, fp): # calculate the accuracy, error rate, sensitivity, specificity, and precision for the selected classifier in reference to the corresponding test set. accuracy = tp + tn /(p+n) error_rate = fp + fn /(p + n) sensitivity = tp/ p precision = tp/ (tp+fp) specificity = tn/n display_metrics(accuracy, error_rate, sensitivity, precision, specificity) def display_metrics(accuracy, error_rate, sensitivity, precision, specificity): print(f'Accuracy: {accuracy}, Error_rate:{error_rate}, Sensitivity:{sensitivity}, Precision:{precision}, specificity:{specificity}') def mc(columnName,training_set): column = training_set[columnName] probs = column.value_counts(normalize=True) messageConveyed = -1*np.sum(np.log2(probs)*probs) # print(f'mc {messageConveyed}') return messageConveyed def isUnique(s): a = s.to_numpy() # s.values (pandas maximum): attribute = F maximum = gain print(f"gain: {gain} for {F}") print(f'attribute {attribute} has the max gain of {gain}') print(f'removing {attribute}') root = attribute print(f'new root {root} has branches {training_set[root].unique()}') print(f'root is {root}') print("******************************************") print("************** ROOT ******************") print(f"TF is {root}**********************") print("******************************************") unique_values = training_set[root].unique() datasets = [] for unique_value in unique_values: print(f'processing for file : {unique_value} ') df_1 = training_set[training_set[attribute] > unique_value] df_2 = training_set[training_set[attribute] The goal of this program is to classify the training data in a decision tree like so Veriety / \ Volume Location ect.. The dataset for this program are the following: Assignment 2--Training set for ID3.csv Venue,color,Model,Category,Location,weight,Veriety,Material,Volume 2,6,4,4,4,2,2,1,1 1,2,4,4,4,1,6,2,6 1,5,4,4,4,1,2,1,6 2,4,4,4,4,2,6,1,4 1,4,4,4,4,1,2,2,2 2,4,3,3,3,2,1,1,1 1,5,2,1,4,1,6,2,6 1,2,3,3,3,1,2,1,6 2,6,4,4,4,2,3,1,1 1,4,4,4,4,1,2,1,6 1,5,4,4,4,1,2,1,4 1,4,5,5,5,1,6,2,4 2,5,4,4,4,2,3,1,1 1,5,5,5,5,1,6,2,5 2,6,5,5,5,2,2,1,4 Assingment 2-- Test set for ID3.csv Venue,color,Model,Category,Location,weight,Veriety,Material,Volume 1,6,4,4,4,1,1,1,6 2,5,4,4,4,2,6,1,1 1,6,2,1,4,1,4,2,4 1,6,2,1,4,1,2,1,2 2,6,5,5,5,2,2,1,2 1,5,4,4,4,1,6,2,2 1,3,3,3,3,1,6,2,2 1,5,2,1,1,1,2,1,2 1,4,4,4,1,1,5,3,6 1,4,4,4,4,1,6,4,6 I would sincerely appreciate any help with this. I do not have a clear understanding of what the end result of the program should be. If I could understand the process I'd be able to work through the program.
