[site]: datascience
[post_id]: 72325
[parent_id]: 
[tags]: 
Low training and validation loss but bad predictions

what does it mean if in a neural network, the training and validation losses are low but the predictions (so use model on test set) are bad? Neural network architecture: model = tf.keras.Sequential() model.add(Masking(mask_value=0., input_shape=(timesteps, features))) model.add(Bidirectional(LSTM(units=100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5), input_shape=(timesteps, features))) model.add(Dense(1, activation='sigmoid')) My loss function is: def get_top_one_probability(vector): return (K.exp(vector) / K.sum(K.exp(vector))) def listnet_loss(real_labels, predicted_labels): return -K.sum(get_top_one_probability(real_labels) * tf.math.log(get_top_one_probability(predicted_labels))) Fitting settings: model.fit(training_dataset, training_dataset_labels, validation_split=0.2, batch_size=1, epochs=number_of_epochs, workers=10, verbose=1, callbacks=[SaveModelCallback(), keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=3)]) Thanks in advance.
