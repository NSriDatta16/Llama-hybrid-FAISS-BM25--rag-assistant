[site]: crossvalidated
[post_id]: 44172
[parent_id]: 44109
[tags]: 
In linear regression when both covariates and outcome are sampled together, the parameter being estimated can be thought of as $$ \mathbf{\beta}=\mathrm{Var}[\,\mathbf{X}\,]^{-1}\mathrm{Cov}[\,Y,\mathbf{X}\,], $$ which you can further break out into terms in the $\mathrm{Corr}[\,Y,X\,]$, $SD[\,Y\,]$ and $SD[\,X\,]$ if you like. In your setting it sounds like you have extra information on some of those terms, but not all. Taking a Bayesian approach, incorporating extra information about e.g. the $SD[\,Y\,]$ term into your posterior about $\beta$ would be straightforward, assuming you can quantify what the extra data tells you about that term (or terms) via a likelihood. Any component parts of $\beta$ for which you don't have extra information would just be updated in the usual way. If you don't want to use Bayes, you could construct an estimate of $\beta$ that made the best use of the available data for each component, and then multiply them all together to get some $\hat\beta$. Getting an appropriate standard error estimate for this $\hat\beta$ would be some work, but I imagine e.g. the bootstrap would work reasonably well. I don't see the need to standardize here... but I may be missing something.
