[site]: crossvalidated
[post_id]: 362480
[parent_id]: 
[tags]: 
Object localization with CNN

I am interested in locating the center of a playing card on the surface of a table: I have written a script so that I can generate images like this, where the card is moved around and rotated. My idea was to generate 10,000 images and train a CNN on them. The CNN would be provided the image as input and the coordinates of the center of the card as output. I have tried several different architectures, such as NetChain[{ ConvolutionLayer[32, 3], Ramp, ConvolutionLayer[32, 3], Ramp, PoolingLayer[2, 2], ConvolutionLayer[64, 3], Ramp, ConvolutionLayer[64, 3], Ramp, PoolingLayer[2, 2], FlattenLayer[], LinearLayer[128], Ramp, LinearLayer[2] }, "Input" -> NetEncoder[{"Image", {300, 225}, "Grayscale"}], "Output" -> 2 ] The code is written in Wolfram Language but should be self-explanatory. Ramp is the ReLu function. The pooling layers are max pooling layers. Linear layers are fully connected layers. I have also tried other architectures and different numbers of neurons. The loss function that I use is the mean squared error. The input has been normalized to the range [0, 1]. Output has been normalized and not normalized, it makes no difference. My networks don't improve over time except for a not nearly large enough improvement in the very beginning, where essentially the network just learns to output values in the correct range. They remain as useless as they were to begin with, why? What can I do to solve this problem? Ultimately, I would like to find the corners of the card. Finding the center is a first step towards this goal. This is also part of an even larger problem with more complicated images, which is why I'm trying to use a CNN instead of simpler methods which could surely work on this problem.
