[site]: crossvalidated
[post_id]: 406910
[parent_id]: 
[tags]: 
Is it valid to make a fraction out of output of naive bayesian classifiers?

I'm working on a model of a twitter network that attempts to determine the likelihood of a tweet being retweeted. For every user in the network, I have a list of all of the tweets by all of the users they are following. I then broke down all of the tweets into words and assigned a word a probability of being positive or negative based on the frequency of it's occurrence in retweets and frequency of occurrence in non-retweets. This model is very simplistic, and I know the words are not independent, but I'm hoping it will give a decent rough idea of what's likely to be retweeted. However, as of right now, it seems like there are currently two problems with my model. I'm new to bayesian classifiers, so apologies if I'm butchering any terminology here. The first problem is that words that have not appeared or only appear very infrequently heavily bias the results. Is there a way I can bias the model in favor of probabilities that have more datapoints vs probabilities that have less datapoints? I'm thinking I can just multiply each factor by the total number of occurrences (positive or negative), but I'm not sure if that makes sense. The second problem is that I don't really want a tweet to always garner the same result. I'd prefer if this spit out a probability of a tweet being retweeted rather than classifying it. I'm thinking I can just divide the value spit out for the positive classifier over the sum of the value spit out for the negative classifier plus the positive classifier. Again, I'm not really sure if that makes sense theoretically/if I'm violating any assumptions by doing that. If there are more appropriate, but still relatively simple to understand ways to do what I'm trying to do here, feel free to point me in that direction. I'm sure there are more sophisticated ways of doing the analysis I'm talking about here, but I'd like to keep this project manageable. Thanks. EDIT: The first problem was mostly a problem when there was a zero factor in the denominator. I was originally setting denominator to 1 in that case, which distorted the results, but I ended up just using the average probability for the class in that case and seem to be getting better values.
