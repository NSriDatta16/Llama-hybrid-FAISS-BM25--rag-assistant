[site]: crossvalidated
[post_id]: 380262
[parent_id]: 
[tags]: 
Do neural networks with binary output learn representations that are linearly separable?

Support Vector machines employ the kernel trick in order to find a space where the data is mostly linearly separable and then determine what the appropriate hyperplane. However, back in the original space, the hyperplane would look non-linear. Neural networks also learn a non-linear decision boundary through the use of the non-linear activation functions. However, the output representation of the final layer is therefore the representation that will be used to finally classify the data. In the case of a binary classification task, it the case that the best representation that can be learned is likely to one that allows data to be linearly separable?
