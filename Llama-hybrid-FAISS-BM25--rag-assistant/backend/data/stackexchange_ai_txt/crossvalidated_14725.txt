[site]: crossvalidated
[post_id]: 14725
[parent_id]: 14721
[tags]: 
I have typically seen the uniform prior used in either "instructive" type examples, or in cases in which truly nothing is known about a particular hyperparameter. Typically, I see uninformed priors that provide little information about what the solution will be, but which encode mathematically what a good solution probably looks like. For example, one typically sees a Gaussian prior ($\mu=0$) placed over a regression coefficient, encoding the knowledge that all things being equal, we prefer solutions in which the coefficients have lower magnitudes. This is to avoid overfitting a data set, by finding solutions that do maximize the objective function but which don't make sense in the particular context of our problem. In a sense, they provide a way to give the statistical model some "clues" about a particular domain. However, this isn't (in my opinion) the most important aspect of Bayesian methodologies. Bayesian methods are generative, in that they provide a complete "story" for how the data came into existence. Thus, they aren't simply pattern finders, but rather they are able to take into account the full reality of the situation at hand. For example, consider LDA (latent Dirichlet allocation), which provides a full generative story for how a text document comes to be, that goes something like this: Select some mix of topics based on the likelihood of particular topics co-occurring; and Select some set of words from the vocabulary, conditioned based on the selected topics. Thus, the model is fit based on a very specific understanding of the objects in the domain (here, text documents) and how they got created; therefore, the information we get back is tailored directly to our problem domain (likelihoods of words given topics, likelihoods of topics being mentioned together, likelihoods of documents containing topics and to what extent, etc.). The fact that Bayes Theorem is required to do this is almost secondary, hence the little joke, "Bayes wouldn't be a Bayesian, and Christ wouldn't be a Christian." In short, Bayesian models are all about rigorously modeling the domain objects using probability distributions; therefore, we are able to encode knowledge that wouldn't otherwise be available with a simple discriminative technique.
