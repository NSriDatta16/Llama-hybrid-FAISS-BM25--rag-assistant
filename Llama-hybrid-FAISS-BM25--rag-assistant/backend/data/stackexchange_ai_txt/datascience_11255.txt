[site]: datascience
[post_id]: 11255
[parent_id]: 
[tags]: 
Why for logistic regression the error is given by [y ln(sigma(x)) + (1 − y) ln(1 − sigma(x)]

Why for logistic regression, with target values 0 or 1, it will not work to take the sum of the squares of the difference between target value and prediction, but rather: $$ error({\bf w}) = -1/m * \sum_{i=1}^{m} [ y_i \ln (\sigma({x_i})) + (1-y_i) \ln (1 - \sigma({x_i} ) ] $$
