[site]: crossvalidated
[post_id]: 407794
[parent_id]: 407580
[tags]: 
You can do this, but be careful not to mess up the time dependence. You cannot just delete one or more observations from your time series. But you can construct your design matrix of lagged variables and append the dependent variables as additional columns. Then mark the outliers and delete all rows with outliers (they will be in different rows for different columns). Then split the additional columns from the rest of the columns, these will be your dependent variable and the design matrix. You can then use OLS and other least-squares based estimation methods. Illustration with a bivariate VAR(1) for time series $x$ and $y$ : Suppose $x^\top=(x_1,x_2,NA,x_4,x_5)$ and $y^\top=(y_1,y_2,y_3,y_4,y_5)$ . Construct a matrix $A:=[x_{-1};y_{-1};x_{-5};y_{-5}]$ : $$ A=\begin{pmatrix} x_2 & y_2 & x_1 & y_1 \\ NA & y_3 & x_2 & y_2 \\ x_4 & y_4 & NA & y_3 \\ x_5 & y_5 & x_4 & y_4 \\ \end{pmatrix}. $$ Delete all rows containing NA : $$ A'=\begin{pmatrix} x_2 & y_2 & x_1 & y_1 \\ x_5 & y_5 & x_4 & y_4 \\ \end{pmatrix}. $$ Your dependent variables are the first two columns of the $A'$ matrix, and your regressors are the last two columns of the $A'$ matrix: $x'=A_{\cdot 1}$ , $y'=A_{\cdot 2}$ , $x\text{lag}'=A_{\cdot 3}$ , $y\text{lag}'=A_{\cdot 4}$ . Now you can estimate the bivariate VAR(1) by, say, equation-by-equation OLS using the regular OLS routines such as lm in R. The first equation would be lm(x~xlag+ylag) , the second lm(y~xlag+ylag) . Of course, in this example the sample is too small when adjusted for NA s, but with more realistic samples sizes it should work fine.
