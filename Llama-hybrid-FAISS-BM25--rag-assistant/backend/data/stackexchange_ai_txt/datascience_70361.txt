[site]: datascience
[post_id]: 70361
[parent_id]: 
[tags]: 
Feature selection and Model structure for object detection in TensorFlow

So I'm making a TensorFlow model to detect an enemy player on screen (if present) and return me its position. I'm using transfer learning with some fine tuning because it's much faster than training my own network. However, I'm unsure how to structure my data and my output layer. Currently my output data is 3 units with a relu activation function. The labels look like this: [enemyx, enemyy, enemypresent] e.g [500.0, 200.0, 1.0] currently. If the enemy player is not present, then it looks like [0.0, 0.0, 0.0]. The training loss is very high (~24000). I am using the MobileNetV2 with imagenet weights, with an input size of 224 x 224 x 3. The x and y of the enemy are between 0 and 900 because I have resized 900 x 900 images down to 224 x 224 in order to use MobileNetV2. I need help structuring my model to do this detection effectively (activation functions, data structuring, etc) Here is the model code: base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights="imagenet") base_model.trainable = False global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output) prediction_layer = tf.keras.layers.Dense(units=3, activation="relu")(global_average_layer) model = tf.keras.models.Model(inputs=base_model.input, outputs=prediction_layer) model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.003), loss="mse", metrics=["accuracy"]) model.fit(X, y, epochs=30, batch_size=128, validation_split=0.1)
