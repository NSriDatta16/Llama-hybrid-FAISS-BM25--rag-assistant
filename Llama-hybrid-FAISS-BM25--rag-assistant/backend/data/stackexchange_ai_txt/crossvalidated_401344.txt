[site]: crossvalidated
[post_id]: 401344
[parent_id]: 401304
[tags]: 
This is polynomial kernel with degree $d=2$ and $c=0$ , which is commonly used for higher dimension transformations for SVM. Another similar one is RBF kernel. Since SVM is a linear model, such transformations are used to separate nonlinearly separable data, as in your example. Normally, the data points $x,y$ have dot product $K(x,y)=x^Ty$ . This is called as linear kernel, and there is no transformation. If we want to see these dot products in another form, e.g. as in polynomial kernel here $K(x,y)=(x^Ty+c)^d$ , we apply some transformation to the data, i.e. $x\rightarrow \phi(x)$ such that you create the desired kernel, i.e. $K(x,y)=(x^Ty+c)^d=\phi(x)^T\phi(y)$ . The question here is to find this transformation. In this problem, $\phi(x)$ is $[x_1^2 \ \sqrt{2}x_1x_2\ x_2^2]^T$ . If we want to verify it: $$\phi(x)^T\phi(y)=x_1^2y_1^2+x_2^2y_2^2+2x_1x_2y_1y_2=(x_1y_1+x_2y_2)^2=(x^Ty)^2$$ where $x=[x_1 \ x_2]^T, y = [y_1\ y_2]^T$ .
