[site]: stackoverflow
[post_id]: 3602532
[parent_id]: 3602079
[tags]: 
I did a mini unscientific benchmark just measuring the difference in GetTickCount() calls when calling the function in a loop from 0 to MAX_LONG times under the VS 2010 compiler. Here's what I saw: This took 11497 ticks inline int len(uint32 val) { if(val While this took 14399 ticks inline int len(uint32 val) { return 4 - ((val & 0xff000000) == 0) - ((val & 0xffff0000) == 0) - ((val & 0xffffff00) == 0) ; } edit: my idea about why one was faster is wrong because: inline int len(uint32 val) { return 1 + (val > 0x000000ff) + (val > 0x0000ffff) + (val > 0x00ffffff) ; } This version used only 11107 ticks. Since + is faster than - perhaps? I'm not sure. Even faster though was the binary search at 7161 ticks inline int len(uint32 val) { if (val & 0xffff0000) return (val & 0xff000000)? 4: 3; return (val & 0x0000ff00)? 2: 1; } And fastest so far is using the MS intrinsic function, at 4399 ticks #pragma intrinsic(_BitScanReverse) inline int len2(uint32 val) { DWORD index; _BitScanReverse(&index, val); return (index>>3)+1; } For reference - here's the code i used to profile: int _tmain(int argc, _TCHAR* argv[]) { int j = 0; DWORD t1,t2; t1 = GetTickCount(); for(ULONG i=0; i Had to print j to prevent the loops from being optimized out.
