[site]: crossvalidated
[post_id]: 562651
[parent_id]: 
[tags]: 
How to scale accumulative data for machine learning?

I am trying to create a machine learning model that should be able to decide whether to help a user in a serious game which aims to learn programming. It will be a binary classifier. The features (independent variables) are a count of the actions performed by the user since the beginning of the current level. For example: number of times the explanatory content "for loop" has been consulted (integer values: 0, 1, 2, etc.) number of times the student has copied the "for loop" content (integer values: 0, 1, 2, etc.) number of times the student implemented a "for loop" (integer values: 0, 1, 2, etc.) number of syntax errors (integer values: 0, 1, 2, etc.) [...] time passed since the beginning of the level (number of milliseconds: 123,345 ms) The label of the instances (dependent variable) is: Student was helped (Boolean value: 0 = No / 1 = Yes) For information, the dataset is highly imbalanced, because the ratio of positive instances oscillates between 0.1% and 0.5% depending on the level. Here are the histograms of my features: I am trying different kinds of binary classifiers: Random Forest, SVM, Logistic Regression, etc. Some of them require the data to be scaled. My features are accumulative, so they do not follow a normal distribution. Which method should I use for scaling? Normalization, standardization? Other? Thanks in advance for your help! Matthieu As a beginner, I really need help and expert insight to create my machine learning model. My features are cumulative action counts over time. For example: level_time_spent = 15,340 ms nb_for_simple_viewed = 2 nb_for_counter_0_copied = 0 nb_syntactic_error = 3 nb_if_branch_concept_implemented = 3 notion_help_received (label) = 0 or level_time_spent = 123,340 ms nb_for_simple_viewed = 5 nb_for_counter_0_copied = 1 nb_syntactic_error = 8 nb_if_branch_concept_implemented = 0 notion_help_received (label) = 1 I wonder what distribution my random variables have? Is it a Poisson distribution? Is this kind of distribution compatible with machine learning techniques? I need to scale the features for some algorithms (in particular SVM and linear Regression). The standardization is obviously not adapted (non-normal distribution). Can the min-max scaler do the job? Should I use Box-Cox transform or Yeo-Johnson transform? Thanks for helping me, I'm a bit lost! Matthieu
