[site]: datascience
[post_id]: 85341
[parent_id]: 85340
[tags]: 
Because the data is time series while only Dense layers are used in the model , the problem is caused by model initialization . A model with a 'bad' initialization will constantly predict zero, as you will see by running the script below. import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import MinMaxScaler from tensorflow.keras.models import Model,Sequential from tensorflow.keras.layers import Dense import numpy as np import tensorflow as tf # fix keras random state # https://stackoverflow.com/a/52897216/8366805 seed_val = 94 np.random.seed(seed_val) tf.set_random_seed(seed_val) # Configure a new global `tensorflow` session session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf) tf.compat.v1.keras.backend.set_session(sess) # main def series_to_supervised(data,n_in,n_out): df = pd.DataFrame(data) cols = list() for i in range(n_in,0,-1): cols.append(df.shift(i)) for i in range(0, n_out): cols.append(df.shift(-i)) agg = pd.concat(cols,axis=1) agg.dropna(inplace=True) return agg.values n_in,n_out = 14,1 data = np.load('data.npy') scaler = MinMaxScaler(feature_range=(0, 1)) scaler = scaler.fit(data) scaled_data=scaler.transform(data) DATA = series_to_supervised(scaled_data[:-10], n_in, n_out) X, Y = DATA[:, :-n_out], DATA[:, n_in:] X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.1,random_state=49) model = Sequential() n_nodes = 10 model.add(Dense(4*n_nodes,activation='relu',input_dim=n_in,name='dense_0')) model.add(Dense(2*n_nodes,activation='relu',name='dense_1')) model.add(Dense(n_nodes,activation='relu',name='dense_2')) model.add(Dense(n_out,activation='relu')) model.compile(loss='mse',optimizer='adam',metrics=['mse']) # fit history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=20,) pred = model.predict(X,) print('model prediction, mean %.3f, std %.3f' % (np.mean(pred),np.std(pred))) for ind in range(3): intermediate_layer_model = Model(inputs=model.input,outputs=model.get_layer('dense_%i' % ind).output) pred = intermediate_layer_model.predict(X) print('layer %i, mean %.3f, std %.3f, min %.3f, max %.3f' % (ind,np.mean(pred),np.std(pred),np.min(pred),np.max(pred))) In this script, I saved the array data in OP's post, to data.npy , which can be found in this repo , for simplicity. Besides, I fixed the random seeds of keras and train_test_split , therefore, you will reproduce the scenario in which the trained model constantly predicts zero. In fact, as you mentioned in your post, similar scenarios are not rare (and try a shallower model does not help), I think the problem is Dense is simply not capable of dealing with time series, you need LSTM instead. Try the code below, in which I replaced Dense with LSTM + Dropout , besides, I changed the activation function of the output layer to tanh . import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import MinMaxScaler from tensorflow.keras.models import Model,Sequential from tensorflow.keras.layers import Dense,LSTM,Dropout from matplotlib import pyplot as plt import numpy as np import tensorflow as tf from tensorflow import keras # main def series_to_supervised(data,n_in,n_out): df = pd.DataFrame(data) cols = list() for i in range(n_in,0,-1): cols.append(df.shift(i)) for i in range(0, n_out): cols.append(df.shift(-i)) agg = pd.concat(cols,axis=1) agg.dropna(inplace=True) return agg.values n_in,n_out = 14,1 data = np.load('data.npy') scaler = MinMaxScaler(feature_range=(0, 1)) scaler = scaler.fit(data) scaled_data=scaler.transform(data) DATA = series_to_supervised(scaled_data[:-10], n_in, n_out) X, Y = DATA[:, :-n_out], DATA[:, n_in:] X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.1,random_state=49) X_train = X_train[:,None,:] X_test = X_test[:,None,:] wrong_ind = 0 for ind in range(100): print('working on %i' % ind) keras.backend.clear_session() model = Sequential() model.add(LSTM(4,name='lstm_0')) model.add(Dropout(0.2,name='dropout_0')) model.add(Dense(n_out,activation='tanh')) model.compile(loss='mse',optimizer='adam',metrics=['mse']) # fit n_epoch = 5 if ind the output is
