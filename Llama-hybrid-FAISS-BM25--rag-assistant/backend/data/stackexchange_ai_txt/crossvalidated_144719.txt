[site]: crossvalidated
[post_id]: 144719
[parent_id]: 
[tags]: 
Isolating influence of sampling from actual change

Say I want to evaluate teams' batting coaches in a hypothetical baseball league. It's an unusual league in that there is no control over (and large fluctuation within) the number of at-bats each player will get in a given week. The goal metric is: "To what extent is each batting coach improving their respective team's batting averages"? The problem is that the fluctuations of at-bats drives most of the week-over-week variation in team batting averages. For instance, a star player hitting 20/50 (0.400) one week, but 2/4 (0.500) the next, could actually cause the team's average to drop, despite that player's average going up. I need a methodology that accounts for the impact of at-bat-flucation, and separates that "noise" from the "signal" of actual changes in performance. Using following example data to shed light on the challenge (and my proposed approach). +--------------------------+ |wk|team|player|hits|atbats| +--------------------------+ |1 |T1 |P1 |3 |10 | |1 |T1 |P2 |5 |20 | |1 |T1 |P3 |10 |200 | |2 |T1 |P1 |4 |10 | |2 |T1 |P2 |6 |20 | |2 |T1 |P3 |21 |400 | |1 |T2 |P1 |3 |10 | |1 |T2 |P2 |5 |20 | |1 |T2 |P3 |10 |200 | |2 |T2 |P1 |2 |10 | |2 |T2 |P2 |4 |20 | |2 |T2 |P3 |4 |50 | +--------------------------+ Both teams have same batting avg first week (0.078). Team T1 is experiencing a clear improvement: all players' individual averages climbed from week 1 to week 2 (but overall team batting average fell to 0.072). Team T2 is experiencing a clear decline: all players' individual averages fell (but overall team batting average climbed to 0.125). This alone shows that it's not sufficient to just look at weekly team averages the evaluation should be on the coaches' ability to improve the team batting average. I should also note that the fluctuation of at-bats is not totally random. There is general consistency of # of at-bats. Most of the time, players who have a high number of at-bats one week will have a relatively high number of at-bats the next. As such, it's not sufficient to just ask, "which team had the most players improve?" or "which team had individual players improve the most?", because batting-coaches who improve a few highly-active players a little may be "more valuable" than those who improve a large number of highly-inactive players a lot. In this hypothetical, batting coaches should know which players to focus on and work to improve the hitting of those players (though the effect of improving lots of highly-inactive players a lot shouldn't be neglected). Is there a well-defined statistical method which would allow me to define the desired evaluation metric, and track that metric week-over-week? I think I get the right idea with this approach: Taking each player's week1 batting average and multiplying it by that player's (week1_atbat + week2_atbat), calling this "week1_adjusted_hits" Taking each player's week2 batting average and multiplying it by that player's (week1_at_bat + week2_atbat), calling this "week2_adjusted_hits" Compute adjusted team average for week1 by summing up week1_adjusted_hits for all players on the team, and dividing by the sum of (week1_atbat + week2_atbat) for all players on the team. Compute adjusted team average for week2 by summing up week2_adjusted_hits for all players on the team, and dividing by the sum of (week1_atbat + week2_atbat) for all players on the team. Using this methodology gives following "adjusted" team averages: +---------------------------------------------------------------+ |wk|team|adjusted_hits|week1_plus_week2_atbats|adjusted_team_avg| +---------------------------------------------------------------+ |1 |T1 |46 |660 |0.070 | |2 |T1 |51.5 |660 |0.078 | |---------------------------------------------------------------| |1 |T2 |31 |360 |0.086 | |2 |T2 |24 |360 |0.067 | +---------------------------------------------------------------+ These adjusted averages clearly reflect the fact that team T1's batting improved and team T2's batting got worse. The last step is to use the ratio of wk2:wk1 adjusted_team_avg as an index. Setting WK1 as the "zero month", I compute/display WK1 team averages with index of "1" (i.e. just using plain hits vs at-bats). I then compute each team's "WK1->WK2 index" as the ratio (WK2 ADJUSTED_TEAM_AVG)/(WK1_ADJUSTED_TEAM_AVG). Finally, I compute each team's WK2-indexed-average as the multiplication of (WK1 actuals) * (WK1->WK2 index). So the results I'd ultimately present would be: +------------------------------+ |wk|team|index|indexed_team_avg| +------------------------------+ |1 |T1 |1 |0.078 | |2 |T1 |1.12 |0.088 | |------------------------------| |1 |T2 |1 |0.078 | |2 |T2 |0.77 |0.061 | +------------------------------+ Same indexing approach would be used going forward: for WK3, I'd compute new WK2->WK3 team indexes by repeating this process for WK2 and WK3, then showing WK3-indexed-average = (WK2-indexed-average) * (WK2->WK3 index). I wouldn't even deign to call myself an "amateur" statistician. Nevertheless, this approach feels "right" intuitively (or at least, something that gets "close" to right). My question for the pros: is this a sound methodology? Does it yield a meaningful/trustworth metric - would it be reliable as a means for determining salary increases for those batting-coaches who show up favorably by such an analysis? Are there any pitfalls I should look out for (I haven't explored this yet, but I'm particularly concerned about whether the method reliably accounts for impact of players dropped/added to the teams over time).
