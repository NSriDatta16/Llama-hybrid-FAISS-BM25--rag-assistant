[site]: crossvalidated
[post_id]: 157016
[parent_id]: 156463
[tags]: 
Thanks to some simple R simulations, I came up with a satisfying answer to my own question. The question asks what is the right way of estimating the true / global set of parameters of a given model, given the model has been fitted to N different datasets, yielding N vectors of parameters. The answer is : calculate vector average from these N vectors. How I came up with this answer that contradicts what I though at first is quite well demonstrated by a simulation (= backing up my answer with personal experience) : Let's imagine we observe two variables X (independent variable), and Y (dependent variable). Assuming Y is linearly dependent on X, we can construct the following linear model : Y = a * X + b Assume we know by construction that a_TRUE = 2 and b_TRUE = 10. In the case of a and b being orthogonal to each other, one can draw a sample of N "a" values, and another sample of N "b" values. a_sample here is one possible plot of the true equation (black solid) and all 10 individual equations (dashed red) : By construction, a_TRUE can be estimated by averaging all individual vectors. Here (sorry, I forgot to set seed so it is not reproducible), b_estimate = 9.7 +- 0.7 (95% CI), and a = 1.5 +- 0.8 By analogy, in the nonlinear case, it seems OK to average over all 4 (a,b) vectors. However, with only four values to average by parameter, it is likely that 95% confident intervals will be huge. I don't know, thought, if this is still OK when the parameters are correlated. Comments are welcome.
