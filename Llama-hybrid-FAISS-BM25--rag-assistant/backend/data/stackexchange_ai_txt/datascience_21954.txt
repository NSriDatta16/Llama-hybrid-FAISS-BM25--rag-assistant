[site]: datascience
[post_id]: 21954
[parent_id]: 
[tags]: 
Which is better: Out of Bag (OOB) or Cross-Validation (CV) error estimates?

I have seen other posts in this forum but didn't find any convincing answer. Random Forest has an another way of tuning hyperparameter via OOB by design. OOB and CV are not the same as OOB error is calculated based on a portion of trees in Forest rather by full Forest. So what are the advantages and disadvantages of using OOB instead of a CV? Is getting to train on more data by using OOB correct to say?
