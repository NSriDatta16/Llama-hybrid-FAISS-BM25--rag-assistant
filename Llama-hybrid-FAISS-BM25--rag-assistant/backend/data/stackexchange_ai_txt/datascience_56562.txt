[site]: datascience
[post_id]: 56562
[parent_id]: 
[tags]: 
What is the correct formatting of the input tensor for multi-variate LSTM on Pytorch?

I am working on a LSTM to predict a financial time series using 10 other financial time series. The 10 financial time series form my training dataset. Several examples I have seen for univariate prediction use a rolling window approach. This would make sense as for each target value, only a certain amount of the training data is likely to have a predictive ability (say the 100 time steps prior to it). What I would like to have is an LSTM which would have the 10 features and a window size of the 100 time-steps, which is associated with one target value. And then this would be rolled along for the full duration of the financial time series say (5000 values). But I'm having issues with this tensor dimensions. In the Pytorch documentation, it describes the input_size arg as the "number of expected features". Which I would have thought would be the number of time series (10). But I haven't seen many multi-variate implementations of LSTMs and pretty much all of them have used the window size (e.g 100) as the input_size arg. In Keras it would be as simple as shaping your input into [samples, timesteps, features]. Any advice or thoughts would be appreciated thanks!
