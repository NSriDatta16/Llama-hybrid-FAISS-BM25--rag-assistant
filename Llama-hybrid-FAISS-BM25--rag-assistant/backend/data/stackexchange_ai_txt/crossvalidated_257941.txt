[site]: crossvalidated
[post_id]: 257941
[parent_id]: 257857
[tags]: 
The way you've written the problem, I think $X=2$ in your example (the algorithm terminates after the 2nd failure). Otherwise I think your example is correct, though things are simple because you picked a simple problem. What theorems are you expecting to use? The way you account for the history dependence is that you have a different number of terms in each product (corresponding to the number of steps the algorithm takes). More generally, you could compute the distribution using a Markov chain where you have states that encode the history of failures into them (note that this means you'll end up with a lot of states). Specifically, you will have $X+1$ copies of each state. $s_i^x$ corresponds to the state "running step $i$ with $x$ cumulative failures in the past". The chain progresses from $s_i^x$ to $s_{i+1}^x$ with the probability step $m_i$ succeeds, and from $s_i^x$ to $s_i^{x+1}$ with the probability that $m_i$ fails. There are $I(X+1)$ terminal states, corresponding to the $I$ ways the algorithm can terminate early, and the $IX$ ways the algorithm can successfully finish. Using this chain you can make a (large) state transition matrix, and multiply it until it converges to get the distribution over the terminal states. If you actually try to do this, be sure to use sparse representations of your transition matrix since each row and column only has two entries (but there are an exponential number of rows and columns).
