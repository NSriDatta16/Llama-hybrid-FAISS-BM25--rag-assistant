[site]: crossvalidated
[post_id]: 547065
[parent_id]: 547058
[tags]: 
We fix $k$ and let $p_{n,i}$ denote the probability that after $n$ draws, we have drawn exactly $i$ unique categories. Thus, what we are interested in is $p_{n,k}$ . We will calculate $p_{n,i}$ dynamically, filling a matrix with $n$ rows and $k$ columns. For the first row, we have $p_{1,1}=1$ and $p_{1,i}=0$ for $2\leq i\leq k$ . For rows below the first ( $n\geq 2$ ), we first consider $i=1$ . We can only have drawn $1$ category after $n$ draws if we have had exactly $1$ category after $n-1$ draws and drawn the same category again, with a probability of $\frac{1}{k}$ . Thus, $$ p_{n,1} = p_{n-1,1}\times\frac{1}{k}. $$ For $i\geq 2$ , we can arrive at having drawn exactly $i$ categories after $n$ draws in one of two mutually exclusve ways: We have already drawn $i$ categories after $n-1$ draws, and re-drew one of these in the $n$ -th draw, for a total probability of $p_{n-1,i}\times\frac{i}{k}$ . We have drawn $i-1$ categories after $n-1$ draws, and drew one of the previously undrawn categories in the $n$ -th draw, for a total probability of $p_{n-1,i-1}\times\frac{k-(i-1)}{k}$ . Overall, $$ p_{n,i} = p_{n-1,i}\times\frac{i}{k} + p_{n-1,i-1}\times\frac{k-(i-1)}{k}. $$ This is easily calculated, and a simulation gives results that match closely. In R: kk Result: > probs[nn,] 1 2 3 4 5 0.000000512 0.001046528 0.057323520 0.419082240 0.522547200 > table(factor(sims,levels=1:kk))/length(sims) 1 2 3 4 5 0.00000 0.00102 0.05739 0.42157 0.52002 Essentially, what we are doing is a Markov Chain with $n$ steps through a state space with $k$ possible states, the $i$ -th state meaning "we have drawn $i$ unique categories". Something similar would probably be possible for your more general question about having seen each category $m$ times, but there, we would need to keep track of how often we have already drawn each category, so we have to look at far more possible states.
