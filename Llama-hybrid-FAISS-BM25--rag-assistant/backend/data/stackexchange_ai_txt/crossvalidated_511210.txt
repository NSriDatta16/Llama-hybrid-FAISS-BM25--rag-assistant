[site]: crossvalidated
[post_id]: 511210
[parent_id]: 144826
[tags]: 
+1 to Kjetil b halvorsen. His answers are enlightening and this one is no exception. I do think that there is something additional to be contributed here because the question asks about "treating regressors as fixed" (as in a hypothetical intervention to use Pearl's language) but also touches on "fixing the regressors" (as in a real design experiment). This is where it gets confusing. Let's distinguish between 3 different paradigms: You design an experiment. You will set the level of fertilizer to either 1, 2, 3 units (this is the regressor) and then observe the yield (this is the outcome variable). This is a REAL experiment. You performed it. The regressor in this case is non-random because you determined how much fertilizer to put on each plot and not the roll of a dice or some other random experiment. You have an observational dataset on yield and fertilizer and you are not sure how yield was assigned to the plots, so you cannot assume that it was assigned randomly. You are interested in $E[$ yield|fertilizer $=3]-E[$ yield|fertilizer $=2]$ . This amounts to a filtering of your dataset to the plots that were assigned 3 units of fertilizer and calculating their average yield then filtering the dataset to the plots that were assigned 2 units of fertilizer and calculating their average yield and then take the difference of the 2 averages. In this case conditioning amounts to filtering. It is key to note that this is not the causal effect of increasing fertilizer from 2 to 3. It is just a summary of your existing dataset. You have an observational dataset on yield and fertilizer and you do know that plots in sunnier areas were applied more fertilizer and your knowledge of agriculture tells you that more sun translates into a higher yield. Suppose that nothing else determined jointly both how the fertilizer was assigned and the outcome, so that you can assume that your causal DAG is complete and correct. Suppose you are interested in the causal effect of fertilizer on yield when the amount of fertilizer was increased from 2 to 3. Using Judea Pearl's do operator this question can be equivalently written as: $$E[yield|do(fertilizer=3)]-E[yield|do(fertilizer=2)]$$ In words, this question asks for the difference in the average yield if we performed a hypothetical experiment in which we first assigned every plot 2 units of fertilizer and computed the average yield, then applied every plot 3 units of fertilizer and computer the average yield and then took the difference between these 2 averages. To answer this question we'll have to condition Y=yield on both X=fertilizer and Z=sunniness of the plot. In the 3rd case, you are imagining an alternative world , different that reality; you are imagining something counterfactual . This is where you imagine a world in which the level of the regressor had been fixed to a particular value. In the 2nd case, you accept/observe the reality as is and want to summarize it . The regressor is random and you condition on it to get a summary of your filtered dataset. In the 1st case you create the reality . You fix the regressors in the real world and will have to get some dust on your boots as well because you are actually performing the experiment. That is not quite correct. When regressors are deterministic/non-random, yes they are not random variables. However, the OLS estimators are still very much random variables because they are linear combinations of $Y_i$ , and the $Y_i$ are random variables (even if all regressors are deterministic) because $\epsilon_i$ are random variables. Yes, when x is non-random: $$E[Y|x]=\beta_0+\beta_1x+E[\epsilon|x]=\beta_0+\beta_1x+E[\epsilon]=E[Y]$$ but when X is random: $$E[Y|X]=\beta_0+\beta_1X+E[\epsilon|X]\not=\beta_0+\beta_1E[X]+E[\epsilon]=E[Y]$$ This is a key difference.
