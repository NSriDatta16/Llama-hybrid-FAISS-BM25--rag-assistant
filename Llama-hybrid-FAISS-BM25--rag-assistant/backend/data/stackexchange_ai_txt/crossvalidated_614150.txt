[site]: crossvalidated
[post_id]: 614150
[parent_id]: 
[tags]: 
How to account for bias in experiment data when quantifying treatment efficacy?

Say my randomization wasn't very effective, so I have two groups, each with 100 individuals and the difference in success rates is 3% before the treatment has ever been administered. I want to know the lift in success rate that can be attributed to the treatment exposure. A statistician on my team proposed a regression model where we include $X={group, exposure}$ . And we include both experiment data as well as pre-experiment data. This should de-couple the bias in the control group, as distinct from the effect of treatment exposure. (However, it would not explain the source of bias, which is obviously of interest, too.) Then the difference in binomial model / logistic regression predictions could be used to determine the lift due to treatment exposure. $$ X=\{1, treatment, exposure\} $$ $$ B = [intercept,\quad \theta_{group} \quad, \theta_{exposure}]$$ $$ Z = Binomial(n,k | sigmoid(B*X)) $$ $$ lift = Z(treatment=1, exposure=1) - Z(treatment=1, exposure=0)$$ I'm curious, is this an established design for measuring lift when experiment data is biased? Does it have a name? And how would you explain why this makes sense to a non-technical audience? I've read that 'difference in difference' method might be what I'm describing but I'm not certain of this.
