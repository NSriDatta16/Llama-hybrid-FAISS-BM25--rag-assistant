[site]: crossvalidated
[post_id]: 600948
[parent_id]: 
[tags]: 
Codebook Perplexity in VQ-VAE

I am working on VQ-VAE experiments, and I have noticed that perplexity has been used as an evaluation measure for VQ codebook. Also, most of the work including codebook perplexity as a evaluation measure assumes higher perplexity better, though I feel higher perplexity is not very wanted in my intuition. For example, lower perplexity indicates a better language model in general cases. The questions are (1) What exactly are we measuring when we calculate the codebook perplexity in VQ models? (2) Why would we want to have large codebook perplexity? What is the ideal perplexity for VQ models? Sorry if my questions are unclear.
