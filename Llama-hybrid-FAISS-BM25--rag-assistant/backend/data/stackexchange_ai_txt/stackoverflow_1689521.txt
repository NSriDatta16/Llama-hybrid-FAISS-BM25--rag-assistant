[site]: stackoverflow
[post_id]: 1689521
[parent_id]: 1665613
[tags]: 
Two trains of thought: a) if those restraints are really, absolutely, truly founded in common sense, and doable in the way you propose in the nth edit, it seems the presupplied data is not huge. So how about trading storage for precomputation to time. How big would the table(s) be? Terabytes are cheap! b) This sounds a lot like a employer / customer request that is not well founded in common sense. (from my experience) LetÂ´s assume the 15 minutes of computation time on one core. I guess thats what you say. For a reasonable amount of money, you can buy a system with 16 proper, 32 hyperthreading cores and 48 GB RAM. This should bring us in the 30 second range. Add a dozen Terabytes of storage, and some precomputation. Maybe a 10x increase is reachable there. 3 secs. Are 3 secs too slow? If yes, why?
