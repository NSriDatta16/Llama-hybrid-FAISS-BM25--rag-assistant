[site]: datascience
[post_id]: 67016
[parent_id]: 66944
[tags]: 
As a general answer for hyperparameter tuning, you have to try both and see what works better for your problem. I suspect that some (if not most) of general tuning rule have been observed on a given problem / with a given architecture. (for exemple the He paper is about vision, including convolutional layers). As for keras choice, sometimes, for practical reasons, it is easier to implement an unique default option than to adapt the default option to the activation. Given your Hands-on machine learning citation, it's not hard to see why they would implement Glorot as the default.
