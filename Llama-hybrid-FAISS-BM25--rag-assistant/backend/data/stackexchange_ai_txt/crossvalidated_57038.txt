[site]: crossvalidated
[post_id]: 57038
[parent_id]: 35089
[tags]: 
This is the problem of limited sampling bias . The small sample estimates of the densities are noisy, and this variation induces spurious correlations between the variables which increase the estimated information value. In the discrete case this is a well studied problem. There are many techniques to correct, from the fully Bayesian ( NSB ), to simple corrections. The most basic (Miller-Madow) is to subtract $(R-1)(S-1) / 2N\ln2$ from the value. This is the difference in degrees of freedom between the two implicit models (full joint multinomial vs the product of independent marginals) - indeed with sufficient sampling $2N\ln(2)I$ is the likeilhood ratio test of indepenence ( G-test ) which is $\chi^2$ distributed with $(R-1)(S-1)$ d.o.f. under the null hypothesis. With limited trials it can even be hard to estimate R and S reliably - an effective correction is to use a Bayesian counting procedure to estimate these (Panzeri-Treves or PT correction). Some package implementing these techniques in Matlab include infotoolbox and Spike Train Analysis Toolkit . For the continuous case, estimators based on nearest neighbour distances reduuce the problem.
