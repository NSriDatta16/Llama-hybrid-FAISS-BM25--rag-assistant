[site]: crossvalidated
[post_id]: 271839
[parent_id]: 
[tags]: 
Smart sampling to learn a space partitioning

Given a compact feature space, I want to partition the space according to some classification. The first method that comes to mind is to use SVMs. For the classification I have in mind, the space partitioning is very neat; points that are close together usually have the same class label. The only miss-classifications in my test set occur around the decision boundaries. I have a specific luxury; it is possible to generate labels for specific feature vectors through a 'slow' method (the goal of the SVM is to speed up the classification). It would be great if this luxury could be exploited to generate samples close to decision boundaries to improve accuracy. Are there methods to achieve this? I am also open to completely different methods to improve accuracy, but inference for each of these methods should be in the millisecond range for feature vectors of length ~40 and up to 500 classes (yes, many classes). This constraint is important, because otherwise there is no speed up compared to the earlier-mentioned 'slow' method.
