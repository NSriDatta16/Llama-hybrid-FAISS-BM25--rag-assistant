[site]: crossvalidated
[post_id]: 7160
[parent_id]: 7152
[tags]: 
Zeros in tables are sometimes classified as structural, i.e.zero by design or by definition, or as random, i.e. a possible value that was observed. In the case of a study where no instances were observed despite being possible, the question often comes up: What is the one-sided 95% confidence interval above zero? This can be sensibly answered. It is, for instance, addressed in "If Nothing Goes Wrong, Is Everything All Right? Interpreting Zero Numerators" Hanley and Lippman-Hand. JAMA. 1983;249(13):1743-45. Their bottom line was that the upper end of the confidence interval around the observed value of zero was 3/n where n was the number of observations. This "rule of 3" has been further addressed in later analyses and to my surprise I found it even has a Wikipedia page . The best discussion I found was by Jovanovic and Levy in the American Statistician . That does not seem to be available in full-text in the searches, but can report after looking through it a second time that they modified the formula to be 3/(n+1) after sensible Bayesian considerations, which tightens up the CI a bit. There is a more recent review in International Statistical Review (2009), 77, 2, 266–275 . Addenda: After looking more closely at the last citation, above I also remember finding the extensive discussion in Agresti & Coull "The American Statistician", Vol. 52, No. 2 (May, 1998), pp. 119-126 informative. The "Agresti-Coull" intervals are incorporated into various SAS and R functions. One R function with it is binom.confint {package:binom} by Sundar Dorai-Raj. There are several methods for dealing with situations where an accumulation of "zero" observations distort an otherwise nice, tractable distribution of say costs or health-care usage patterns. These include zero-inflated and hurdle models as described by Zeileis in "Regression Models for Count Data in R" . Searching Google also demonstrates that Stata and SAS have facilities to handle such models. After seeing the citation to Browne (and correcting the Jovanovic and Levy modification), I am adding this snippet from the even more entertaining rejoinder to Browne: "But as the sample size becomes smaller, prior information becomes even more important since there are so few data points to “speak for themselves.” Indeed, small sample sizes provide not only the most compelling opportunity to think hard about the prior, but an obligation to do so. "More generally, we would like to take this opportunity to speak out against the mindless, uncritical use of simple formulas or rules." And I add the citation to the Winkler, et al paper that was in dispute.
