[site]: crossvalidated
[post_id]: 229513
[parent_id]: 229506
[tags]: 
If one wants to see how much variance there is in the responses that various subjects give to a single rating measure, why are measures any more sophisticated than a mere box plot, or error bar with SEMs needed? If that's what you want to look at, then you don't need inter-rater reliability. In fact, you don't even need multiple raters. Measures of inter-rater reliability tell you something completely different; namely, they are about inter-rater association. Box plots tell you nothing about this. You can have perfect inter-rater reliability with big dispersion in each rater; you can have low IRR with small dispersion in each rater, or any other combination. The answer to your question in the middle paragraph is "No, that's not it". The answer to your question in the last paragraph is also "No, that's not it". EDIT: It appears I misunderstood. The question was about a boxplot of the differnces between raters. That makes more sense. However, it's still quite different from a measure of interrater reliability, just as a (regular) boxplot is not the same as the standard deviation; one is a number, the other a graph.
