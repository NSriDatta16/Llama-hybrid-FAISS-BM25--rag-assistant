[site]: stackoverflow
[post_id]: 2538566
[parent_id]: 2538147
[tags]: 
By specifying pre-multiplied alpha - kCGImageAlphaPremultipliedLast - am I - inadvertently - telling CoreGraphics to multiply the r g b channels by alpha or - what I have assumed - am I merely indicating that the format of the incoming image has pre-multiplied alpha? Neither one. You specified the format of the destination (the context), not the source. The source—the image object—knows whether its pixels' colors are premultiplied or not, and Quartz will use that knowledge to do the right thing when it draws the source image into the context. This means that the pixels in your buffer will be premultiplied—not twice , but they will be premultiplied in the context buffer, whether the source colors were premultiplied or not (if they were, no need to multiply again; if they weren't, then it will multiply for the first time). I don't know enough OpenGL to know whether that's a problem, and if it is, there is probably no solution for this code: On the Mac, at least, Quartz does not support unpremultiplied colors in bitmap contexts . You might try this storage format instead.
