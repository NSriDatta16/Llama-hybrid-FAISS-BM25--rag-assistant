[site]: crossvalidated
[post_id]: 274710
[parent_id]: 
[tags]: 
Tuning for hyperparameters, sample size and test-train performance with Sklearn

I'm performing model evaluation of my sklearn Pipeline, looking for: optimal hyperparameters: the model is a random forest so in this case: number of trees and tree max depth (using grid search ) train size: size of the training set (using validation_curve ) train/test performance: to check for high bias / high variance (using learning_curve ) My question is: In which order should I perform these steps? Let say I start with train size, which hyperparameters should I use? Or if I start with hyperparamter tuning, should I use the whole dataset (it's huge) even if it takes forever to train?
