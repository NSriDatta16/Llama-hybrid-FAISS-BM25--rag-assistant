[site]: datascience
[post_id]: 36649
[parent_id]: 36312
[tags]: 
Based on the description of your question, it seems that you want the probability of outcome of each class (in multiclass-classification ). I would suggest you to use XGBoost to get output based on your requirement. By setting the value of objective parameter to multi:softprob , you can get probability of prediction of each and every class. If you set the value of objective parameter to multi:softmax , then you will only get the class with maximum probability among other classes. Here, I am writing a example for your reference and to explain this description in a better way. You can get output by printing y_test_preds . import xgboost as xgb xgb_class = xgb.XGBClassifier(**params) bst = xgb.train(params, dtrain, num_rounds) y_test_preds = bst.predict(dtest) By the following way, you can set the parameters for XGBoost. I would strongly suggest you to modify these parameters (except objective ) based on your data and requirements. params = { 'objective' : 'multi:softprob', 'max_depth' : 6, 'silent' : 1, 'eta' : 0.4, 'num_class' : 3, 'n_estimators' : 500, 'learning_rate' : 0.1, 'num_rounds' : 15 } Note: In XGBoost , you have to use DMatrix instead of DataFrame . You can also get the DMatrix from DataFrame by this way. dtrain = xgb.DMatrix(X_train.values, label = y_train.values) dtest = xgb.DMatrix(X_test.values, label = y_test.values) If you are new to XGBoost , then I would recommend you to go through this link once. https://xgboost.readthedocs.io/en/latest/get_started.html
