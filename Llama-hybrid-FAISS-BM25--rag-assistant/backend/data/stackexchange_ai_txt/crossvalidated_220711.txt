[site]: crossvalidated
[post_id]: 220711
[parent_id]: 
[tags]: 
Training a neural network on one answer only

Let's say, I have a neural network and I'd like to learn it to determine weather a player (in any first person shooter of choice) is using an aim bot or not. I started thinking of a way to make training sets. The only problem; players who are actually using an aim bot definitely won't tell me and will continue to deny so they won't get banned. Yes, I could allow a certain group of players to play with an aim bot, but then I can't take it to such a large scale as I'd hoped. Training a neural network on one answer only The answer the neural network should give would be either 1 (NO) and the rest for YES (answering the question: "Is the player using an aim bot?"). I can easily get my hands on thousands of training sets of players not using an aim bot. If I'd simply train the neural network to answer NO for all these training sets, would it answer YES (something different than 1) when I give it an unknown example, which would probably be an aim bot? Common sense Using common sense I know this isn't possible this way, because the output neuron will simply be trained to always answer 1 regardless the answer. Why I think this might be possible somehow I think this might somehow be possible because humans are capable of this as well. If I'd show you a circle a thousand times and make you answer YES (given the answer options either YES or NO). You probably won't answer YES when you suddenly see a square. How is this possible?
