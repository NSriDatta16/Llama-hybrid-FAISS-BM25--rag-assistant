[site]: crossvalidated
[post_id]: 584220
[parent_id]: 451279
[tags]: 
Here you are basically computing the correlation of a matrix. I think it is correct that the correlations are different. Try to do correlation computations by hand: first the mean of Sample1, then the sum of differences from the mean, (following the definition ) >>> s1_mean=(1+1-2)/3 >>> s1_mean 0.0 >>> ((1-s1_mean)+(1-s1_mean)+(-2-s1_mean)) 0.0 >>> while for the transformed data: >>> s1_mean=(1-1-2)/3 >>> s1_mean -0.6666666666666666 >>> ((1-s1_mean)+(-1-s1_mean)+(-2-s1_mean)) -4.440892098500626e-16 Beware that you are changing the sign of a single covariate, but then you are transposing the matrix before computing correlations. This yields a new set of covariates in which each one has a single element multiplied by -1. If you remove the transpose the covariances between PC1 and PC3 will be the same, and the covariances between PC1/3 and PC2 will have opposite sign > cor(PCA_1) PC1 PC2 PC3 PC1 1.0000000 -0.8910421 -0.9819805 PC2 -0.8910421 1.0000000 0.9607689 PC3 -0.9819805 0.9607689 1.0000000 > cor(PCA_2) PC1 PC2 PC3 PC1 1.0000000 0.8910421 -0.9819805 PC2 0.8910421 1.0000000 -0.9607689 PC3 -0.9819805 -0.9607689 1.0000000 Note that (Xi − X)(Yi − Y) is positive if and only if Xi and Yi lie on the same side of their respective means. Thus the correlation coefficient is positive if Xi and Yi tend to be simultaneously greater than, or simultaneously less than, their respective means https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#Interpretation If you change the sign of one of two variates, and the two variates before were lying on the same side of the respective means, now they are lying on opposite sides.
