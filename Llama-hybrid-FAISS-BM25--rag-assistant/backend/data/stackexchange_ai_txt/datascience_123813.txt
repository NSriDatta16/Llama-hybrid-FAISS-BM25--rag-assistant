[site]: datascience
[post_id]: 123813
[parent_id]: 
[tags]: 
How to train a CNN when the shape of the training images are too different?

I want to build a CNN model for classifying cracks. The dataset I am using has been prepared from a raw dataset. (I don't have access to that) Now the problem is, in the dataset, each image is of a different size and some images are way too different in size. For example, one image is 190 * 1000 in size and one image is 340 * 340 size. Now if I resize the vertical image (190 * 1000) size to a square shape (say 340 * 340 size), the crack in the vertical image will be too stretched. My question is, If I resize them to a common shape while stretching the image, will it affect the model to learn that data? If so, then how can I reshape the images? I have added two example images for your understanding.
