[site]: stackoverflow
[post_id]: 4959412
[parent_id]: 4959171
[tags]: 
There are several (memory usage) optimizations you can make here... A few tricks to keep in mind are: Most numpy functions take an out parameter than can be used to specify the output array instead of returning a copy. E.g. np.sqrt(x, x) will take the square root of an array in-place. x += 1 uses half the memory that x = x + 1 does, as the latter makes a temporary copy. When it's possible, try to split calculations up into *= , += , /= , etc. When it's not, use numexpr, as @eumiro suggested. (Or just used numexpr regardless... It's quite handy in many cases.) So, first off, here's your original function's performance with a 10000x10000 array of random data and a filtsize of 3: Memory Usage Profile of Original Function What's interesting are the big spikes at the end. These occur during your numpy.select(...) bit. There a plenty of places where you're inadvertently creating additional temporary arrays, but they're mostly irrelevant, as they're overwhelmed by what goes on during the call to select . At any rate, if we replace your original (clean and compact) code with this rather verbose version, you can significantly optimize your memory usage: import numpy import scipy.ndimage def main(x=None): if x is None: ni, nj = 10000, 10000 x = numpy.arange(ni*nj, dtype=numpy.float32).reshape(ni,nj) filtsize = 3 nlooks = 10.0 dfactor = 10.0 x = enh_lee(x, filtsize, nlooks, dfactor) return x def moving_average(Ic, filtsize): Im = numpy.empty(Ic.shape, dtype='Float32') scipy.ndimage.filters.uniform_filter(Ic, filtsize, output=Im) return Im def moving_stddev(Ic, filtsize): Im = numpy.empty(Ic.shape, dtype='Float32') scipy.ndimage.filters.uniform_filter(Ic, filtsize, output=Im) Im *= -1 Im += Ic Im **= 2 scipy.ndimage.filters.uniform_filter(Im, filtsize, output=Im) return numpy.sqrt(Im, Im) def enh_lee(Ic, filtsize, nlooks, dfactor): # Implementation based on PCI Geomatica's FELEE function documentation Ci = moving_stddev(Ic, filtsize) Im = moving_average(Ic, filtsize) Ci /= Im Cu = numpy.sqrt(1 / nlooks).astype(numpy.float32) Cmax = numpy.sqrt(1 + (2 * nlooks)).astype(numpy.float32) W = Ci.copy() W -= Cu W *= -dfactor W /= Cmax - Ci W = numpy.exp(W, W) If = Im * W W *= -1 W += 1 W *= Ic If += W del W # Replace the call to numpy.select out = If filter = Ci = Cmax numpy.putmask(out, filter, Ic) return out if __name__ == '__main__': main() Here's the resulting memory profile for this code: Memory Usage Profile of Numpy-based Optimized Version So, we've greatly reduced memory usage, but the code is somewhat less readable (i.m.o.). However, those last three peaks are the two numpy.where calls... If numpy.where took an out parameter, we could further reduce the peak memory usage by another ~300Mb or so. Unfortunately, it doesn't, and I don't know of a more memory-efficient way to do it... We can use numpy.putmask to replace the call to numpy.select and do the operation in-place (Thanks to @eumiro for mentioning this in an entirely different question .) If we optimize things with numexpr, we get considerably cleaner code (compared to the pure-numpy version above, not the original). You could probably whittle the memory usage down a bit in this version... I'm not terribly familiar with numexpr, beyond having used it a few times. import numpy import scipy.ndimage import numexpr as ne def main(x=None): if x is None: ni, nj = 10000, 10000 x = numpy.arange(ni*nj, dtype=numpy.float32).reshape(ni,nj) filtsize = 3 nlooks = 10.0 dfactor = 10.0 x = enh_lee(x, filtsize, nlooks, dfactor) return x def moving_average(Ic, filtsize): Im = numpy.empty(Ic.shape, dtype='Float32') scipy.ndimage.filters.uniform_filter(Ic, filtsize, output=Im) return Im def moving_stddev(Ic, filtsize): Im = numpy.empty(Ic.shape, dtype='Float32') scipy.ndimage.filters.uniform_filter(Ic, filtsize, output=Im) Im = ne.evaluate('((Ic-Im) ** 2)') scipy.ndimage.filters.uniform_filter(Im, filtsize, output=Im) return ne.evaluate('sqrt(Im)') def enh_lee(Ic, filtsize, nlooks, dfactor): # Implementation based on PCI Geomatica's FELEE function documentation Ci = moving_stddev(Ic, filtsize) Im = moving_average(Ic, filtsize) Ci /= Im Cu = numpy.sqrt(1 / nlooks).astype(numpy.float32) Cmax = numpy.sqrt(1 + (2 * nlooks)).astype(numpy.float32) W = ne.evaluate('exp(-dfactor * (Ci - Cu) / (Cmax - Ci))') If = ne.evaluate('Im * W + Ic * (1 - W)') del W out = ne.evaluate('where(Ci = Cmax, Ic, out)') return out if __name__ == '__main__': main() And here's the memory-usage profile for the numexpr version: (Note that the execution time has been more than halved compared to the original!) Memory Usage Profile of Numexpr-based Optimized Version* The largest memory usage is still during the calls to where (replacing the call to select ). However, the peak memory usage has been significantly cut. The easiest way to further reduce it would be to find some way to select operate in-place on one of the arrays. It would be fairly easy to do this with cython (nested loops would be rather slow in pure python, and any sort of boolean indexing in numpy will create an additional copy). You may be better off by simply chunking the input array as you've been doing, though... Just as as side note, the updated versions produce the same output as the original code. There was a typo in the original numpy-based code...
