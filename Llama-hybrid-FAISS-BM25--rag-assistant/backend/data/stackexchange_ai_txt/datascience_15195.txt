[site]: datascience
[post_id]: 15195
[parent_id]: 15187
[tags]: 
activity_regularizer are used to control the output of a neural network. They tend to make the output smaller. Suppose the loss function is give as : loss function = DataLoss + regularizationLoss Then for weight_regularizer, regularizationLoss = f(Weights in a network) . But for activity_regularizer, regularizationLoss = f(Predicted outputs from a network) . Activity regularizers are generally used when you are quite aware of the distribution of the test dataset. For your second argument, I would say you are pretty wrong. ANN as well as CNN both can suffer from overfitting. In order to prevent the model to overfit, we generally use a lot of regularization techniques among which Dropout is quite popular.
