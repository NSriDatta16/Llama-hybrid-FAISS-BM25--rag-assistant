[site]: crossvalidated
[post_id]: 465600
[parent_id]: 
[tags]: 
Limitations of indirectly comparing meta-analysis Effect Sizes (ES)

I'm reviewing meta-analyses (MAs) for a college assignment and am trying to locate a reference to help me make sense of why indirectly comparing different treatment Effect Sizes (ESs) is potentially problematic. To use an example to explain what I mean by 'indirectly comparing different treatment ESs': One MA generates an average ES from five studies that compare Treatment A to Waitlist controls, and say the ES is Hedges g = 0.80 in favour of Treatment A. In the same MA they generate an average ES from five different studies that compare Treatment B to Waitlist controls, and say the ES is Hedges g = 0.60 in favour of Treatment B. This MA then statistically compares the 0.80 ES for Treatment A to the 0.60 ES for Treatment B, and states that the results indicates that Treatment A is more effective than Treatment B. My understanding is that this is an indirect way of comparing these treatments to each other, because neither treatment was actually compared directly with the other - only their ESs when compared to different waitlist control conditions was compared. My understanding is that the ideal situation would be that Treatment A and Treatment B would be directly compared to one another in a single study and then hopefully lots of single studies do the same to provide enough data for a MA; and for my research focus I have found a number of meta-analyses that have found such studies and generated ESs for these direct comparisons. However, I am trying to find a reference so that I can (1) understand the limitations of the indirect way of comparing ESs and (2) have a justifiably rationale why I would exclude the MAs that only carried out the indirect comparisons (or perhaps I shouldn't be excluding them at all?).
