[site]: crossvalidated
[post_id]: 384679
[parent_id]: 250517
[tags]: 
Bagging works as follows: You resample your training data $m$ times, create $m$ estimators, fit each estimator to a resampled training set, and then average their predictions over new data. Logistic regression is not a method which uses bagging, but you can bag a bunch of logistic regressions. The "GB" in XGBoost stands for "Gradient Boosting" which is a different technique.
