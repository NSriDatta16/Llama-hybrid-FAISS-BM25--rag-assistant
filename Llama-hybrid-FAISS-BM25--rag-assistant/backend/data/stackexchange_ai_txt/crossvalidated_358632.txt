[site]: crossvalidated
[post_id]: 358632
[parent_id]: 
[tags]: 
Number of samples vs timesteps for LSTM

I'm working on time series forecast program and working with a rnn based on LSTM. If I have, for example, a price series of the last 100 days, with just one feature (the price), does it make sense to shape the series as (100,1,1) if I'm working with an LSTM? I've read this would be equal to flattening the data and passing it through a Dense layer. I've tried using a TimeseriesGenerator but it's overcomplicating things for me. How should I reshape the sets if I want to add a sliding window? This is my code: train_x_scaled = np.reshape(train_x_scaled, (train_x_scaled.shape[0], 1, train_x_scaled.shape[1])) test_x_scaled = np.reshape(test_x_scaled, (test_x_scaled.shape[0], 1, test_x_scaled.shape[1])) model = Sequential() model.add(LSTM(units = 16, input_shape=(train_x_scaled.shape[1], train_x_scaled.shape[2]), activation='tanh')) model.add(Dense(units = 1, activation = 'linear')) model.compile(optimizer = 'adam', loss = 'mean_squared_error') early_stopping_monitor = EarlyStopping(monitor='val_loss',patience=10,verbose=1) history = model.fit(train_x_scaled, train_y_scaled, validation_split=0.2, epochs = 300,callbacks=[early_stopping_monitor],shuffle=False,verbose=1)
