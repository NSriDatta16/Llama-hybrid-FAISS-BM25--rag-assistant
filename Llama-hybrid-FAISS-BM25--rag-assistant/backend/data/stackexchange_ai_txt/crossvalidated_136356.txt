[site]: crossvalidated
[post_id]: 136356
[parent_id]: 136354
[tags]: 
Classification accuracy throws out valuable information. Consider a simplified example: Model one predicts half the subjects to have probability 0.75 of success and the other half a probability of 0.25. Model two predicts (for those that model 1 predicted 0.75) half at 0.9 and half at 0.6 while for those that model 1 predicted at 0.25 it predicts half at 0.1 and half at 0.4. Now if we only look at the "Classification accuracy" by calling everyone with a prediction > 0.5 a success then the 2 models are identical, but that ignores the additional information that can be significant. But 0.4 is closer to 0.6 than it is to 0.1. Think about if you are considering surgery and the doctor uses a logistic regression to predict your chances of having a successful surgery, would you really consider a 0.51 probability and a 0.99 probability the same (and a 0.49 probability different from a 0.51)?
