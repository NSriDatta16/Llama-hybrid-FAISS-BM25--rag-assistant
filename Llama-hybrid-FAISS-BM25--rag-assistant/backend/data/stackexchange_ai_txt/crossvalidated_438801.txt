[site]: crossvalidated
[post_id]: 438801
[parent_id]: 438759
[tags]: 
"Standalone" logistic regression can indeed only draw a straight line, as it defines a linear relationship between the predictors and the log of the odds (our response). Overfitting can occur in logistic regression in exactly the same way that it can occur for regular linear regression. The reason it's hard to picture it using those diagrams is that you're only visualizing two dimensions, where the idea of over fitting isn't as intuitive. So linear model overfitting is difficult to visualize precisely because it occurs when you are working in too many dimensions. So this might be side stepping your question, but I think it's actually best to not try and directly visualize it, but just think through an example step by step. Imagine that we're trying to predict someone's weight. We can create a simple linear model that is a decent fit using just their height, and that should generalize fairly well. If we add gender, that should will improve the fit, and also generalize well. But if we also add 26 binary variables based on whether or not they have a given first letter in their last name ("A", "B", "C", etc), well, in a small data set we might improve our fit (maybe the lone "Quinn" in our data set is very heavy, and we capture that), but it probably won't generalize very well (as we don't think there's any real association there). Hence, we are overfitting. While that was using binary variables (starting letter, gender), it's the exact same concept, and still a linear model (but binary variables can be a little easier to visualize). The fact is, linear models over fit when they involve too many dimensions, relative to the actual sources of variability you're trying to capture in the observed data set. The concept of overfitting in logistic regression is the exact same, the only difference is your target (the log of the odds, not just any continuous response variable).
