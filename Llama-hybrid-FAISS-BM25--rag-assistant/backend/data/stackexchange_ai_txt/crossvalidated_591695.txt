[site]: crossvalidated
[post_id]: 591695
[parent_id]: 
[tags]: 
Conditions for Poisson regression to outperfom OLS in linear inverse problems

Suppose I have some problem typical linear inverse problem, where I have a relation $Ax = \vec{b}$ , and want to solve for $x$ in terms of $A$ and $\vec{b}$ . Furthermore, assume that $\vec{b}$ is a composed of independent heteroskedastic Poisson distributed terms. Given this information, OLS shouldn't be applicable. Yet when I run simulations, I find that OLS and Poisson regression produce closely comparable results. The experiments in detail: Start with some known (say 30x2) matrix $A$ and some true (2x1) vector $\vec{x}$ , and multiply them out to get a no noise true value for $\vec{b}$ . Then, replace each $b_i$ with a random number drawn from a Poisson distribution with mean $b_i$ (simulating Poisson noise). Finally, using the noisy $\vec{b}$ value and the matrix $A$ , attempt to recover as closely as possible the vector $\vec{x}$ . Repeat steps 2 and 3 many times, and evaluate the mean of the error and the standard deviation of the error. When I do this experiment, the average standard deviation for the ols model errors is in some cases lower than the standard deviation for the Poisson. Is there an analytical reason for this? Can I predict when this will happen based on the matrix $A$ ?
