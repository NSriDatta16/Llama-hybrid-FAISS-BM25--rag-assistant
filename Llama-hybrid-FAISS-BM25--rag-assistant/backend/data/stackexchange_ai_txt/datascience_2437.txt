[site]: datascience
[post_id]: 2437
[parent_id]: 
[tags]: 
How does the supposed "Unified Architecture for NLP" from Collobert and Weston 2008 really works?

In this paper ( here ) they suppose a "unified architecture for NLP" with deep neural networks with multitask learning My problem is to understand the layered architecture in figure 1, see below: Is someone able to give me a concrete, reproducible example of how this architecture processing 3 sentences through their layers? What are the outputs after each layer? Why they choose which layer?
