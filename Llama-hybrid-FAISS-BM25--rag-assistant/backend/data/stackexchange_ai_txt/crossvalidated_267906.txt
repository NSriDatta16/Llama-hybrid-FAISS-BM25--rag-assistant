[site]: crossvalidated
[post_id]: 267906
[parent_id]: 267899
[tags]: 
I think that we mustn't care about the errors in the data. Because simply, it is not my problem. What if the data was collected with a bias? For example, say you want to learn people's voting habits. You send out a survey and get thousands of responses back, so you think its a representative sample. However, it turns out that only people with incomes greater than $100K responded. But you don't know that. That will surely impact your analysis. But no one actually made a mistake, per se, did they? Are you suggesting that you shouldn't care about this? This is the problem of customers/researchers who are measuring the data. I mean their job to decrease the noise using Digital Signals Processing or any other tools. Who are you in this situation? A customer may not have to care, but a researcher or practitioner certainly should. Secondly, we don't separate this field from other fields. I'm not sure what you're trying to say here. Can you elaborate what "this field" and "other fields" mean and why they aren't separate? Thirdly, I think by modeling the noise in the target variables, we are just telling people that ML field is a tool to solve problems from A to Z regardless of where the data came from. Of course, there is a reason to build that noise, but I can't find it. If you're suggesting that ML requires domain knowledge of the data generating process, then I definitely agree. Modeling the noise in the target variable does not preclude this from being true. Why would it? Can you give me a practical example where we should model the noise, otherwise our machine learning system will fail? What does it mean for our machine learning system to "fail"? Fail at minimizing some objective function? Imagine we build a model that minimizes CV error, so by many measures it's "successful". Then the data changes over time in ways that our model failed to account for because it wasn't robust enough (due to data error/bias or because we didn't model the noise accurately). Now, on new data, it will fail. Perhaps we can retrain it to the new data, but that's just one approach to dealing with poor modeling choices. How often will you need to retrain? Will it even "work" anymore on new data if that new data contradicts your modeling assumptions? In short, one cannot overestimate the importance of modeling error. One could argue that the field of Statistics is based on this premise.
