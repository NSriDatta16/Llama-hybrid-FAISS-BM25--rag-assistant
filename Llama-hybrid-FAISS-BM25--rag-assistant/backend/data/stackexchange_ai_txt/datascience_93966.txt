[site]: datascience
[post_id]: 93966
[parent_id]: 93964
[tags]: 
One-Shot Learning refers to the problem when you only have very few or a single sample for some classes in your training dataset. A common application is, for example, face recognition. Here you may have only a single image per person in your dataset. Nevertheless, you'd like your neural net to be able to recognize that person from new images. A good intro is provided by Andrew Ng here . A popular example are Siamese Nets introduced by Koch et al . The basic idea is to learn a latent representation of the images in your training set. When a new image is presented during inference the net calculates the latent representation of that new image and searches for the image in your training set whose latent representation is most similar to the one of the new image and predicts the corresponding class. When you do not have any sample of a specific class available this is considered Zero-Shot Learning . However, in this case the neural net requires the dataset to include some auxiliary information for all images. The most popular being the Animals with Attributes (AWA) dataset: Initial approaches to solve the Zero-Shot Learning problem did so in two steps: For a given image learn to predict the attributes Learn to predict the class based on the attributes For details you may refer to the paper Attribute-Based Classification for Zero-Shot Visual Object Categorization . More recent approaches take another route though. However, both approaches require, as always in Deep Learning, large datasets to learn.
