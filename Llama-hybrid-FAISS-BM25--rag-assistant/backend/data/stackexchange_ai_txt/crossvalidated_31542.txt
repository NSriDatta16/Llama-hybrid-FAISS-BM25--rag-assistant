[site]: crossvalidated
[post_id]: 31542
[parent_id]: 31190
[tags]: 
Remember CV is an estimate only and can never represent the 'real' generalisation error. Depending on your sample size (which will impact your number of folds or fold size) you can be severely limited in your ability to calculate any parameter estimates of the distribution of the generalisation error. In my opinion (and I've seen it purported in various text books, 'Knowledge Discovery with Support Vector Machines'-Lutz Hamel)you can do some bootstrapping variant of CV to estimate the distribution of the generalisation error, but a standard 10-1 (for example) once off CV will not give you enough data points to make inferences about the true gen-error. Bootstrapping requires you to take multiple samples with replacement from your training/test/val effectively doing multiple (say 1000 or so) 10-1 (or whatever) CV tests. You then take your sample distribtion of averages for each CV test as an estimate of the sampling distribution of the mean for the population of CV errors and from this you can estimate distributional parameters i.e. mean, median, std min max Q1 Q3 etc... It's a bit of work, and in my opinion only really required if your application is important/risky enough to warrant the extra work. i.e. perhaps in a marketing environment where the business is simply happy to be better than random then maybe not required. BUT if you are trying to evaluate patient reactions to high risk drugs or predict income expectations for large investments you may well be prudent to carry it out.
