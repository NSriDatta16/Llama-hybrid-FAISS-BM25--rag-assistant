[site]: crossvalidated
[post_id]: 452386
[parent_id]: 452298
[tags]: 
Looks like you answered most of your own questions already! Where I am struggling is then how to take the next step and evaluate the posterior, since the parameter is a product of multiple parameters. Bayes theorem still holds with joint distributions, all you would have to do is to specify a joint distribution for the set of parameters. Typically in a Bayesian model, this could be defined as a product of conditionals and marginals. In your scenario, it might be reasonable to define them as a product of marginals of $\pi_i$ 's distributions. The simplest way of doing this would be to simply assume a conjugate prior on λ and treat each of the π parameters as fixed, but in practice we will have some amount of information on each of those parameters ... That's right, in that case you would probably use a beta prior for each of these $\pi_i$ s. However, your posterior $P_{all} = P(\lambda, \pi_c, \pi_e, \pi_y| Y)$ is not going to look pretty. This is where Markov chain Monte Carlo (MCMC) methods come in. If you're interested, I suggest studying the Metropolis algorithm (or Metropolis-Hastings, slightly different). In short: you sample from the posterior to approximate the distribution (e.g., you would have 10000 points of $(\lambda^{(t)}, \pi_c^{(t)}, \pi_e^{(t)},\pi_y^{(t)})$ , for $t=1,2,...,10000$ whose distribution is approximately $P_{all}$ . To obtain the marginal posterior $P(\lambda | Y )$ , you would have to integrate over $\pi_c,\pi_e,\pi_y$ from $P_{all}$ . That is $P(\lambda | Y) = \int_{[0,1]^3}P(\lambda, \pi_c,\pi_e,\pi_y| Y)d\pi_cd\pi_ed\pi_y$ . Suppose you have approximated the posterior $P_{all}$ via MCMC, then deriving the marginal distribution of $P(\lambda | Y)$ simply comes down to ignoring the $\pi_c,\pi_e,\pi_y$ samples (summing over discrete samples). Here's how you would derive the posterior (and/or marginals) $$P(\lambda, \pi_c,\pi_e,\pi_y | Y) = \frac{P(Y,\lambda,\pi_c,\pi_e,\pi_y)}{P(Y)} \\ = \frac{ P(Y|\lambda, \pi_c, \pi_e,\pi_y) P(\lambda)P(\pi_c)P(\pi_e)P(\pi_y)}{\int_{\lambda,\pi_c,\pi_e,\pi_y} P(Y|\lambda, \pi_c, \pi_e,\pi_y) P(\lambda)P(\pi_c)P(\pi_e)P(\pi_y)d\lambda d\pi_c d\pi_e d\pi_y}$$ $$P(\lambda| Y) = \int_{\pi_c,\pi_e,\pi_y}P(\lambda, \pi_c, \pi_e,\pi_y | Y) d\pi_c d\pi_e d\pi_y $$ $$P(\pi_c| Y) = \int_{\lambda,\pi_e,\pi_y}P(\lambda, \pi_c, \pi_e,\pi_y | Y) d\lambda d\pi_e d\pi_y $$
