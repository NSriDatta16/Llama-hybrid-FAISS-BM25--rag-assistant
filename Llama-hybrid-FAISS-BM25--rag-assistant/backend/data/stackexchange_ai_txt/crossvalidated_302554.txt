[site]: crossvalidated
[post_id]: 302554
[parent_id]: 302553
[tags]: 
Projection to a lower dimension (or same dimension) can be achieved by matrix multiplication . In your example, the original data matrix $X$ is $150 \times 3$ (in the definition of "data matrix", each row is one data point, and number of columns are number of features.). If we want to project all the data into 2D space, we will use a $3 \times 2$ matrix $P$. The result of $XP$ is $150 \times 2$ matrix. Here is an example of using PCA to do dimension reduction. Please note how the projection matrix $P$ ($3 \times 2$) is defined. > d=iris[,1:3] > pr.out=prcomp(d, scale=T) > # reduce to 2D > P=pr.out$rotation[,1:2] > P PC1 PC2 Sepal.Length 0.6290662 -0.43339843 Sepal.Width -0.3611443 -0.89806788 Petal.Length 0.6883680 -0.07509912 > head(as.matrix(scale(d)) %*% P) PC1 PC2 [1,] -1.850964 -0.4227153 [2,] -1.588617 0.7121722 [3,] -1.945261 0.4090196 [4,] -1.860383 0.6588919 [5,] -2.009789 -0.5764188 [6,] -1.837503 -1.4166620 We can check our manual projection $XP$ and PCA output. They are the same. (Comparing to the first two column / 2D of pr.out$x ) > head(pr.out$x) PC1 PC2 PC3 [1,] -1.850964 -0.4227153 -0.12939389 [2,] -1.588617 0.7121722 -0.26157290 [3,] -1.945261 0.4090196 -0.03136284 [4,] -1.860383 0.6588919 0.07069857 [5,] -2.009789 -0.5764188 0.00614575 [6,] -1.837503 -1.4166620 -0.01014686
