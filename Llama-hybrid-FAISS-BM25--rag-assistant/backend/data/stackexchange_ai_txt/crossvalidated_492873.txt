[site]: crossvalidated
[post_id]: 492873
[parent_id]: 
[tags]: 
Need help understanding how C hyperparameter influences $w $ in regularized SVM

I am following Andrew Ng's lecture notes on SVM from CS229. What I am having trouble understanding is the new objective function. $min_{γ,w,b} \frac{1}{2} ||w||^2 + C\sum_{i = 1}^{m}ξ_i$ From what I understand, if we increase C to have really high value, the objective function will be large, and to compensate for that w need to be small. Now we know that reducing w results in the larger margin and vice versa. Therefore, in this case the margin should be large, but it isn't. For high values of C, the margin is small and its a Hard margin classification. Similarly, for smaller values of C, it becomes a soft margin classification. I don't understand how the C influences the value of w and maybe I am missing something here. I'd really appreciate if someone can give me a clear and intuitive understanding of how w, C and the concept of margin are interrelated to each other. Thanks.
