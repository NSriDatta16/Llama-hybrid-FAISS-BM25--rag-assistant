[site]: datascience
[post_id]: 121654
[parent_id]: 
[tags]: 
How can models like Mosaic's MPT-7b or Bloombergs BLOOMGPT take in so many tokens?

I've read the paper on ALiBi , and I understand that these models are biasing the values made in the query/key multiplication. But from my understanding, when I build the actual model I give it N input nodes. When I train a model I give it vectors of length N . How then at inference can I give it vectors of length greater than N ? Am I misunderstanding how the multiplication of key and query works? Can there be keys of any length? Edit: I guess my question includes, why isn't there a multiplication error when I use longer keys in my inference?
