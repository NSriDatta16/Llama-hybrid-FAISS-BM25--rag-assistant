[site]: crossvalidated
[post_id]: 177749
[parent_id]: 
[tags]: 
Equivalent definition of persistence of state in Markov Chain

Let $E_j$ be a particular state in a sequence of finite states that qualify to follow the Markov Chain Property. If $E_j$ is persistent then by definition, \begin{equation} f_{jj}=\sum_{n=1}^{\infty} f_{jj}^{(n)}=1 \end{equation} where $f_{jj}^{(n)}$ is the probability of occurrence of $E_{j}$ for the first time in $n$ steps, therefore $f_{jj}$ is the probability of recurrence of the event $E_{j}$. From the above can we conclude that $E_j$ is reachable from initial state $E_j$ or mathematically, $\exists n>0$ such that $p_{jj}^{(n)} > 0$, where $p_{jj}^{(n)}$ is the occurrence of $E_{j}$ after $n$ steps starting from $E_{j}$ initially. Will the converse of the above statement hold true in general?
