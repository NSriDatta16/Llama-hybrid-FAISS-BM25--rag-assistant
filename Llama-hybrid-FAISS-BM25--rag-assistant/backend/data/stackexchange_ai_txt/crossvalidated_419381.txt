[site]: crossvalidated
[post_id]: 419381
[parent_id]: 410191
[tags]: 
While human behavior is extremely complex and probably can't be described by any simple model, there are good attempts to model and explain common behaviors. You might be interested is the Rescorla-Wagner model of classical conditioning. With that in mind let's examine some of your questions. We don't look at are current state right now, and consider the values of all the possible future trajectories. We basically choose the action that maximizes our "reward" at our current state. I don't think this is entirely true. For example if i'm at the bank, the action which greedily maximizes reward is to conduct a bank robbery, but this probably wouldn't end up well for me. So even though I'm not consciously enumerating through every possible action I might take, that doesn't mean there isn't a mechanism in the brain which selects actions considering the cumulative return of the entire future trajectory. The fact that humans are often nearsighted when it comes to decision making can often be explained by hyperbolic discounting rather than true lack of foresight. Paraphrasing your other question: Would it be possible to run your life according to some reinforcement learning algorithm? I would argue that you are already doing this, and whatever learning algorithm humans use is far more powerful and flexible than anything else we have. Every single time you make a decision (to eat that tub of ice cream or not -- to buy that new car or a used one), you are implicitly deciding one action or another, hopefully based on some reasonable evaluation of which one will result in a higher cumulative return. Perhaps for most decisions you don't explicitly compute out how many units of cumulative return each action will likely result in -- although if you've ever played poker, this is crucial! -- but the computation is happening nonetheless. As for the question of what the reward function should be -- well, that is the domain of philosophy.
