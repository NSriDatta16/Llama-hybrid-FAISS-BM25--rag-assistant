[site]: datascience
[post_id]: 25996
[parent_id]: 
[tags]: 
How do I tell my model about the sample size of input statistics?

Let's say I am trying to predict whether a cat will be adopted, and I have found the ratio purred_when_petted / total_times_petted aka p / n to have predictive power. However, for some cats I have much more data than others. For example: Cat A: p: 1 n: 1 Cat B: p: 9 n: 10 I would like my neural network to consider that there is more data for Cat B and possible consider that it is more likely to be adopted. How should I tell it about both the ratio and the sample size? Here are some ideas I have so far: Use ratio as input feature and don't worry about sample size Use ratio and sample size as separate input features Use $p$ and $n$ as separate input features, and let the NN do what it wants with them. Use an average of the cat statistic and the average population statistic over all $M$ cats weighted by number of samples: $$ x_i = \beta * (\frac{p_i}{n_i}) + (1-\beta) * (\frac{1}{M}\sum_{j=1}^{M}\frac{p_j}{n_j}) $$ where $\beta \in [0,1]$ is an increasing function of sample size $n_i$. Use a Binomial proportion confidence interval Is there a standard way to do this? I am most interested in neural networks but also open to advice relevant to any other type of model. Note that I also have other categorical and numeric features such as color and age that also need to be fed in to my model.
