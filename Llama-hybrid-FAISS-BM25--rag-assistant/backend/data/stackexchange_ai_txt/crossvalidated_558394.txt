[site]: crossvalidated
[post_id]: 558394
[parent_id]: 
[tags]: 
Can I interpret the p-value of a statistic test as a part in Bayesian Formula?

Suppose we have a hypothesis test: $$H_0: \thetaâ‰¥\theta_0 ~~~ vs~~~ H_1:\theta With the observation $X$ , the p-value is calculated by $p = P(X|H_0)$ . Which means the sum of probability for less or equal likely events. The p-value tells us the likelihood of this set of observation to happen given the Null hypothesis. But usually, what we really want to know is how likely my hypothesis is right , given the observed data. Which, I think, should be $P(H_0|X)$ . Then I recall the Bayes' Formula, where I can derive $P(H_0|X)$ from $P(X|H_0)$ . $$P(H_0|X) = \frac{P(X|H_0) ~P(H_0)}{P(X)}$$ So in this perspective, p value is merely a term in the formula. Am I wrong? If I'm right, why don't we use Bayes' Formula to fix our hypothesis test?
