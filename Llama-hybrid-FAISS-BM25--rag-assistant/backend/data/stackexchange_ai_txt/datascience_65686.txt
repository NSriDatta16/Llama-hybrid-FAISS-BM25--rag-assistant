[site]: datascience
[post_id]: 65686
[parent_id]: 
[tags]: 
Variational Autoencoder: Negative log likelihood not optimized

I am using the auto encoding variational Bayes algorithm for one unsupervised object detection task. In the loss function, the reconstruction loss is calculated as the log likelihood of the original image pixel points by assuming the generated pixel points as the mean of one Gaussian distribution. In other words, if the decoder network is generating an image Y and the main image is X, then each pixel of Y is taken as a mean of a Gaussian distribution and the log of the probability density function for that corresponding pixel value of the original image is taken as the reconstruction error. I am using Adam optimizer. All the KL divergences associated with the distributions are decreasing but the negative log likelihood is not getting optimized. Can someone point out where I am going wrong? This is the line where I am using this log likelihood.
