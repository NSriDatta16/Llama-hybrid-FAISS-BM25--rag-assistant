[site]: stackoverflow
[post_id]: 1836601
[parent_id]: 1836415
[tags]: 
An important part of programming is knowing when you're in over your head. If the CTQ's you've posted are real, specifically the concurrent access requirement, then you're in for a world of hurt. Even those of us with quite a lot of time in the trenches are going to be in a world of hurt with that sort of requirement. I'd tackle the problem with the following mindset: I'm going to get this wrong in more ways that I can currently imagine. Knowing this much, the simpler you keep this architecture, the more likely it is to scale . However, the company I work for is absolutely massive and I doubt even we have any systems that truely have 20,000 concurrent users. So don't bite off more than you can chew. Design your architecture to be simple and robust (a tall order) and you'll find it will scale naturally until you eventually need to call in the big guns. I can suggest that you should at least spend money on access to SQL Server 2008. With that version your problem should be fairly elementary for starters. Use the FILESTREAM storage for the files. No serialization necessary. This will store the files on an NTFS file system and will maximize your ease of programming, maintenance, and scalability. If you for some reason only have SQL Server 2005, you'll have to deal with BLOB s which isn't exactly difficult, but is somewhat messy. I suggest you read To BLOB or Not to BLOB from Microsoft Research to make the decision if storing the data in SQL Server 2005 is the best bet for you. If so, there are plenty of articles detailing how to put files into SQL Server BLOB s. Just be aware this is rarely the most efficient or scalable solution.
