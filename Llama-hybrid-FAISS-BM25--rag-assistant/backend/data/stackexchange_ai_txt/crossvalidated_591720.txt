[site]: crossvalidated
[post_id]: 591720
[parent_id]: 591697
[tags]: 
If you were interested in doing a test as such, then the chi-squared test (at least as you show the statistic) works for counts and expected counts, not proportions and expected proportions. If you divide counts by the total $N$ , to get proportions, the variance used in the test will be wrong. You can adjust for this effect as long as you know what that divisor was . If you're just trying to compare fits and choose the best one, given the same data in every case, the adjustment would not be necessary, since the relative sizes of the statistics would be the same, as long as you treat the possible $\lambda$ values the same - e.g. use the same categories for all of them (you can't drop a category for one and not another). However this would not give you a goodness of fit test , just a comparison of relative fit. Now the reason why your statistics don't agree with your visual impression is that you're visually assessing lack of fit by seeing the big raw differences as more important than the small ones, but the small differences have smaller standard error, which the chi-squared will adjust for; it's going to pay more attention to the very small differences at small expected values and less to the larger differences at large expected values. That makes sense when the variation about the expectation is positively related to the expected value (or equal to it in a Poisson) However, there's a variety of other issues with what you seem to be doing. I'll mention a few points (but there's more going on here): (i) "if $χ^2$ is greater than our significance level ( $α$ )" -- this is not correct. You don't compare the test statistic with the significance level. You can either compare a test statistic with a critical value or a p-value with a significance level. Further note that $\alpha$ is not "5" but $0.05$ . (ii) the chi-squared test is not so suitable for extremely small expected counts, especially when you also have some large expected counts. You appear to have discerned there's a problem here but your approach is ad hoc (and screws up the behavior of the test, if you're actually interested in testing). (iii) the way you've done it (trying only integer $\lambda$ ), this is not a great way to obtain a suitable parameter value in a Poisson model; you can estimate the parameter directly from the data and a good estimate of $\lambda$ will not be integer . A typical estimator for the Poisson rate would simply be the mean of the original data (though it's not clear that the data you have is necessarily suitable for that; do you have varying exposure/observation times for each subject, for example? If so, you need to account for the effect of time to get a rate per unit time). (iv) The data appear to be bimodal, and by the look of it, you seem to have a lot of data (large N), so that appearance probably isn't just random variation. If that's the case, no Poisson model would suit. Indeed, before seeing any data, I would expect this kind of data to be heterogeneous in a population unless you were considering an already homogeneous subset, so I would not expect the Poisson to be a great fit in any case. (v) you should not expect that a simple model will be a correct description of real data. If you have enough data, a goodness of fit test - even a fairly inefficient one, as long as it's consistent - will nearly always reject any simple hypothesized model like this. At very large sample sizes standard errors will be very small and even trivial deviations from a simple model can be discerned from random variation. A goodness of fit test does not tell you whether or not a model would be reasonable or useful for some purpose ; in very large samples it will "complain about" lack of fit that may not be at all consequential. What we seem to have here is an example of an X-Y problem -- you're asking about issues with your attempt to solve some problem rather than describing what you were really trying to achieve in the first place. This will often lead to poor advice (as well as a lot of wasted time trying to 'fix' something that doesn't really deal with your original problem in a useful way). It's better to describe the underlying problem you set out to solve (which as far as I can tell seems to be about estimating a Poisson parameter and assessing the suitability of the fit), but you should go back one step further still to describe the data and how it was obtained; there's several potential issues there.
