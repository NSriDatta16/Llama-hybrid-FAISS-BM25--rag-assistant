[site]: crossvalidated
[post_id]: 629626
[parent_id]: 
[tags]: 
Question about Silhouette index calculation using scikit

I am currently working with continuous data measured from different sensors (thermometers and voltmeters). I have a matrix whose columns represent the sensors and the rows are normalized measurements (one each second). I have been asked to check if these sensors behave in the same way. Thus, I have used clusterization for the data. I have used DBSCAN with Euclidean and Manhattan distances. I have also used hierarchical clustering with Ward and average linkages and K-means using the elbow method to find the most suitable amount of clusters. Now, I want to use the silhouette index to check which one of my clusterizations is the best. My question is as follows: when I calculate the Silhouette index, should I use always euclidean distance? As an example, in the hierarchical case: from scipy.cluster.hierarchy import dendrogram, linkage, fcluster from sklearn.metrics import silhouette_score ... Clustering_H=linkage(data_state_normalized, 'average') clusters=fcluster(Clustering_H, t=4, criterion="distance") silhouette_avg = silhouette_score(data_state_normalized, clusters, metric='euclidean') I think that this is logical because it wouldn't make any sense to use euclidean as metric in the DBSCAN euclidean case and Manhattan in the DBSCAN Mankattan case. This way, all clusters will be measured in the same way. Is this right? Besides, in the example presented, I cannot use average as metric in silhouette_score.
