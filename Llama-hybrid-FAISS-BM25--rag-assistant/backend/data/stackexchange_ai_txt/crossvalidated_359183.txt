[site]: crossvalidated
[post_id]: 359183
[parent_id]: 359013
[tags]: 
Your claim that the MSE of the average prediction is the average of the MSE is wrong, and this is the source of the confusion. In fact, it depends a lot on the estimators themselves. Estimators that are more diverse in some sense tend to have better performing ensemble. Let $f_1, \ldots, f_m$ be the predictors. Then the MSE of the ensemble satisfies $$ \mathbb{E}\left[ \left( \frac{1}{m} \sum_{i=1}^{m} f_i \left(X\right) - Y\right)^2 \right] = \frac{1}{m^2} \sum_{i=1}^{m} \mathbb{E}\left[ \left( f_i \left(X\right) - Y\right)^2 \right] + \frac{1}{m^2} \sum_{i \neq j}\mathbb{E}\left[ \left( f_i \left(X\right) - Y\right) \left( f_j \left(X\right) - Y\right)\right] $$ So, when the classifiers errors are uncorrelated, and there is no regressor that is much better than the rest, the ensemble outperforms the individual predictor, as in that case, $$ MSE_{ens} = \frac{1}{m} \left(\frac{1}{m} \sum_{i=1}^{m} MSE_{f_i}\right) $$ So, the MSE is much smaller than the average MSE of the predictors. The first equation also suggests what cases we can't expect the ensemble to preform well. In fact, the best ensemble is usually a weighted average, with weights depending on the individual MSE and error correlation between the predictors. For a more detailed discussion, you might consider reading chapter 4 of Combining Pattern Classifiers by Kuncheva.
