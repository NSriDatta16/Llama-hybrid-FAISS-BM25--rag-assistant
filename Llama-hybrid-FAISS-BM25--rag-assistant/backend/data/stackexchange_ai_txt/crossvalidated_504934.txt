[site]: crossvalidated
[post_id]: 504934
[parent_id]: 
[tags]: 
Why minimizing the ||w|| penalty term in SVM definition makes the overfitting less probable?

I understand overfitting and why we want our classifier to be reasonably simple. If we introduce more complexity to the predictor, we are risking that we fit it too closely to data, thus overfit, and the estimation error will increase, yielding very bad results when used on new data. However I don't understand why the penalty term in the SVM looks like this: https://i.stack.imgur.com/HTIAg.png Why we care about the distance/length of the vector of weights/parameters denoted w? Imagine 2D example. If w=(1,1) , then 1/2||w||^2 = 1/2 . If w=(2,2) , then 1/2||w||^2 = 2 . However if we calculate the dot products between examples X embedded to the feature map, we get the same line in the space for both weight vectors. So the way I understand it, we are penalizing our predictor more even though it is basically the same one in both cases. Am I incorrect? If not, why does it work like this? Also when I think about it more, when imagining cases with w=(1,1) or w=(3,1) the only difference is just the tilt of the classifier line yet in either case the considered penalty term is different which seems to me just so weird.
