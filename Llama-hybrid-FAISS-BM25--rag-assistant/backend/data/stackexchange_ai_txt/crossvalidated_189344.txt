[site]: crossvalidated
[post_id]: 189344
[parent_id]: 
[tags]: 
Choosing Random Forests' parameters

I am new to machine learning and would like to know if it makes sense to fix the number of estimators and the maximal depth of a random forest with cross validation ? My intuition would be that yes, as cross validation enables one to determine models' hyper parameters. Nevertheless, I think I heard a professor saying that it is illogical to estimate random forests hyperparameters with such procedures... Maybe because the number of estimators would be chosen based on the training data, and then there would be a kind of overfitting as the training and testing datasets are not of the same size, and for instance, having a bigger set size might permit one to consider deeper trees, or maybe averaging on more trees would be necessary to reduce the variance... What are the other possible ways to determine Random Forests hyper-parameters to use ? More generally, what are the main model selection procedures in machine learning ?
