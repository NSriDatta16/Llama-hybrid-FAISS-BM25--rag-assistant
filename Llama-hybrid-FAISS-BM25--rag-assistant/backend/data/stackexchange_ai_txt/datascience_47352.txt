[site]: datascience
[post_id]: 47352
[parent_id]: 
[tags]: 
How can I implement a deep/machine learning algorithm for this?

I have a known matrix, $\bf C$ of size $N\times B$ . Each row has a fixed number of non-zero elements. The demand vector is given by $d$ of size $1\times B$ . The supply vector $s$ of size $1\times B$ is given by $s=\sum_{i=1}^T C_i\alpha_i$ . Here. $C_i$ is the $i$ th row vector of known matrix, $\bf C$ . I have a large set of data for $d$ and corresponding $\alpha_i$ s and $s$ . Now, I want a machine/deep learning algorithm that gives me $\alpha_i$ s for a given $d$ . How can I implement a deep learning algorithm for this?
