[site]: crossvalidated
[post_id]: 458707
[parent_id]: 458194
[tags]: 
The degree of overfitting/underfitting is measured by the complexity between your proposed model and the true model. We cannot know whether the model will overfit/underfit by simply changing the number of data points. Suppose the only tuning parameter of the model complexity is the number of predictors, $k$ . Further suppose you have a training set, which is a dataset for estimating the parameters of your model, and a validation set, which is a dataset just for evaluating the accuracy of the predicted response and tuning your model. You can then find the accuracy, which is a metric of closeness between the all true responses and their corresponding predictions of the data in a dataset, for both the training set and the validation set. In the context of machine learning, you can say that your proposed model with number of predictors $k$ : overfits if you observe that the training accuracy is higher than the validation accuracy underfits if you observe that the training accuracy is less than the validation accuracy
