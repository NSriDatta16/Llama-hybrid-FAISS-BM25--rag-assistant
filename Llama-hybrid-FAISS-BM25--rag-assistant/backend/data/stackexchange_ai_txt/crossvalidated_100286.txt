[site]: crossvalidated
[post_id]: 100286
[parent_id]: 100267
[tags]: 
The idea that you cannot prove a positive scientific proposition, but only disprove one, is a principle of Popper's falsificationism . I do agree that you cannot prove an effect is exactly equal to any given point value (cf., my answer here: Why do statisticians say a non-significant result means "you cannot reject the null" as opposed to accept the null hypothesis? ). But so what? People (or at least I ) complain a lot about hypothesis testing. This is because $p$-values are commonly misunderstood, and hypothesis tests are used for tasks they logically cannot accomplish. For example, hypothesis testing should not be used to generate hypotheses or to select variables. Moreover, with observational data essentially all 'nil' null hypotheses must be false, so testing such makes little sense. However, scientists often do have a-priori hypotheses suggested by current theories that they want to test, and in a true experiment a nil null could be true, so testing it is perfectly reasonable. Typically, researchers do have some reason to suspect that the null might be false, so a significant result in conjunction with a strong experiment is a valid piece of information. You can always form confidence intervals to get a clearer picture of the precision of your estimate, and continue to collect more data to increase its precision. Nonetheless, in economic terms you will get diminishing returns . At some point, you simply do not believe the null hypothesis provides a reasonable account of the phenomenon under study. In which case, why are you bothering? If there are others in your field who are not yet convinced, but would be with more (of the same) data, then you could continue, but this seems like an uncommon situation. It seems more likely to me that the skeptics have other, substantive concerns regarding whether that line of inquiry is sufficiently informative about the underlying question. Thus, you need to determine the nature of those concerns, and if you think they merit the work, seek out different data that more adequately address the issues at hand. For example, you might try to replicate the finding using a different measure, in a different setting, and/or with different control conditions. On the other hand, everyone (more or less) may be satisfied with your data and conclusions (congratulations!). Under such happy circumstances, there are two directions you could pursue to further your research program: A reductionist approach would seek to understand the mechanisms that produce the effect you have established. In statistical terms, you would often be seeking mediators and/or a refining of the pattern of causal forces that connect the variables you have shown to be related. You could also move in the other direction by seeking to integrate your findings into a larger pattern. This is a kind of systems thinking . G.H. Hardy once defined the elegance of a theory as the range of phenomena that it could explain in conjunction with the ease and magnitude of the epistemic shift it induced. Of course, you may not be so lucky that the phenomenon you have established is quite that deep , however it can still be part of something bigger than itself. Establishing a link between $B$ and $C$ that makes it possible to see that $A$ unifies disparate phenomena can be just as important to the process, and just as much a crystallizing moment, as the discovery of $A$ itself. tl;dr: If you have sufficient evidence for your purposes that the null is false, figure out what other theoretically motivated questions you could try to answer and move on.
