[site]: crossvalidated
[post_id]: 493443
[parent_id]: 493412
[tags]: 
# the collected data ages.16.35 Let the new data be coded as $D=\{v_1, v_2, \ldots, v_5\}$ where $v_i$ is 1 if the video $i$ was liked, 0 otherwise. In the example you give, that is $D=\{0,1,1,0,1\}$ . # the new data new.data Concerning video $j$ for age category $i$ , we model its binary response as a Bernoulli, $$v_j \sim \text{Bern}(\theta_{ij})$$ $\theta_{ij}$ means the probability of liking video $j$ for category $i$ . I will assume that, for a given age category, liking a video is independent of liking or not any other video. Now we consider the existence of three models, $\mathcal{M_i}$ , one per age category. Applying Bayes theorem, $$p(\mathcal{M}_i~|~D) \propto p(D~|~\mathcal{M}_i)p(\mathcal{M}_i)$$ The priors for models $\mathcal{M}_i$ can be either the uniform $p(\mathcal{M_i}) = 1/3$ or we assume that the collected data is representative of the company's clients and use, $$p(\mathcal{M}_1) = \frac{100}{200} = 0.5; p(\mathcal{M}_2) = 0.3; p(\mathcal{M}_3) = 0.2$$ In the next computations, I'm using this second option. For the likelihood, we plug the Bernoulli probability mass functions together with the independence assumption and get: $$p(D~|~\mathcal{M}_i) = \prod_{j=1}^5 \theta_{ij}^{v_j} (1-\theta_{ij})^{1-v_j}$$ Ok, let's R it: thetas The output: [1] 56.67 42.87 0.45 If you want to dig deeper in the Bayesian rabbit hole, use the collected data to assign priors for the $\theta_{ij}$ parameters. The model would become, $$v_{ij} \sim \text{Bern}(\theta_{ij})$$ $$\theta_{ij} \sim \text{Beta}(k_{ij}+1,n_i-k_{ij}+1)$$ where $k_{ij}$ is the total of likes for video $j$ for age category $i$ , and $n_i$ is the total of persons at age category $i$ . One last thing. The probabilities that you get after the model fit have uncertainties (as described by the posteriors distributions, if you use Stan or similar software tools). The decision of assigning the new data to an age category is not the model's responsibility. Decision comes after inference in a Bayesian workflow. You need to think if the costs of false positives are the same for all age categories. Perhaps assigning an older person to a younger category is twice as costly. That should have impact in your final classification.
