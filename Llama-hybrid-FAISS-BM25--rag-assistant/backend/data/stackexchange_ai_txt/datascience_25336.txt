[site]: datascience
[post_id]: 25336
[parent_id]: 
[tags]: 
Document classification - optimal classifier & embedding

Planning a classifier to recognize specific documents based on text. Categories are mutually exclusive and include: job application resumes, paychecks, quarterly financial reports etc, and data is text extracted from doc, pdf, xls etc. At the feature engineering stage, with questions in mind: One Multiclass classifier or a number of One vs. Rest (one per category)? Word embedding (Word2Vec/GloVe) - one embedding for all categories or a separate embedding for each category? My tendency is towards a number of one vs. rest classifiers (to allow for dynamic use of just some of the categories), and one embedding for all categories (to save prediction time). Project architecture : initially basic LogReg, but will soon develop to CNN / CNN+RNN. Project scale : Training: a few hundreds per category Prediction: millions of files Please feel free to share any insights or references, thank you
