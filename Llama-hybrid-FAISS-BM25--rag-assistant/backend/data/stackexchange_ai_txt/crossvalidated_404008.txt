[site]: crossvalidated
[post_id]: 404008
[parent_id]: 
[tags]: 
Uncertainty in calibration/curve-fitting parameters

Let me preface with saying I have an idea of a solution, but I am interested in other ones I am interested in the a way to quantify the uncertainty in a calibration/curve-fit parameter. For all intents and purposes, lets assume it is non-linear and block-box. My current thinking as as follows: let $F(x)$ be my "true" function where $x$ is is my data. Let $\tilde{F}(x,\theta)$ be my model (or curve-fit) of the data where $\theta$ is a vector of my parameters. I find $\theta'$ as: $$ \theta' = \min_{\theta} \|F(x) - \tilde{F}(x,\theta) \|^2$$ First Idea One intuitive way to understand this is to look at the hessian of $\|F(x) - \tilde{F}(x,\theta) \|^2$ since you would expect a larger curvature to mean a more-certain optimal value. However, this is (a) expensive and (b) gets complex when you consider diagonal values. Also, I am not sure how to quantitatively interpret these values (including the fact that they could be on different scales and, of course, different units) Alternative The second idea is to use a Bayesian approach and define the liklihood as: $$\mathcal{L}=\exp\left ( -\frac{\|F(x) - \tilde{F}(x,\theta) \|^2}{2\sigma^2}\right )$$ and use a Jeffery's Prior on $\sigma$ (and something reasonable but uninformative on $\theta$ ). Then I can apply some MCMC algorithm and get distributions of each $\theta$ value. However, they would be (a) correlated and (b) be conflated with $\sigma$ (I think). I guess the correlations would be analogous to the off-diagonal hessian values This approach though is very time consuming and takes some art as well (e.g. defining proposal distributions, etc) Final Thought I do seem to recall doing something like this in undergrad with finding the hyper-surface of $\chi^2$ being unity away from the minimum (I may have this wrong) but I cannot find any notes on this. Any other thoughts? Am I over-thinking this?
